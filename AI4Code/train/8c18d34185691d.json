{"cell_type":{"f52c174e":"code","8fb8f9ba":"code","e861d7e3":"code","f3e15108":"code","8662671e":"code","e9a5b953":"code","57e71010":"code","bd14b3c5":"code","86ee0fbf":"code","e03496cd":"code","1e354aee":"code","6a07e7ea":"code","dc6e3a21":"code","16d08546":"code","2d34aada":"code","8fe53d05":"code","418ebade":"code","474e2815":"code","b681494c":"code","33d7224c":"markdown","8715f79d":"markdown","c6d68de1":"markdown","efd22407":"markdown","4ab3dc50":"markdown","47347498":"markdown","19e98385":"markdown","5a74cd72":"markdown","1a163b53":"markdown","3003b559":"markdown"},"source":{"f52c174e":"from google.cloud import bigquery\nclient = bigquery.Client()\ndataset_ref = client.dataset('noaa_icoads', project='bigquery-public-data')\ndset = client.get_dataset(dataset_ref)","8fb8f9ba":"[i.table_id for i in client.list_tables(dset)]","e861d7e3":"icoads_core_2017 = client.get_table(dset.table('icoads_core_2017'))\n[i.name+\", type: \"+i.field_type for i in icoads_core_2017.schema]","f3e15108":"schema_subset = [col for col in icoads_core_2017.schema if col.name in ('year', 'month', 'day', 'hour', 'latitude', 'longitude', 'sea_level_pressure', 'sea_surface_temp', 'present_weather')]\nresults = [x for x in client.list_rows(icoads_core_2017, start_index=100, selected_fields=schema_subset, max_results=10)]","8662671e":"for i in results:\n    print(dict(i))","e9a5b953":"def estimate_gigabytes_scanned_h(query, bq_client):\n    # see https:\/\/cloud.google.com\/bigquery\/docs\/reference\/rest\/v2\/jobs#configuration.dryRun\n    my_job_config = bigquery.job.QueryJobConfig()\n    my_job_config.dry_run = True\n    my_job = bq_client.query(query, job_config=my_job_config)\n    BYTES_PER_GB = 2**30\n    print(\"This query takes \"+str(round(my_job.total_bytes_processed \/ BYTES_PER_GB, 2))+\" GB of quota.\")\n    \ndef estimate_gigabytes_scanned(query, bq_client):\n    # see https:\/\/cloud.google.com\/bigquery\/docs\/reference\/rest\/v2\/jobs#configuration.dryRun\n    my_job_config = bigquery.job.QueryJobConfig()\n    my_job_config.dry_run = True\n    my_job = bq_client.query(query, job_config=my_job_config)\n    BYTES_PER_GB = 2**30\n    return my_job.total_bytes_processed \/ BYTES_PER_GB","57e71010":"estimate_gigabytes_scanned_h(\"SELECT sea_level_pressure FROM `bigquery-public-data.noaa_icoads.icoads_core_1662_2000`\", client)\nestimate_gigabytes_scanned(\"SELECT sea_level_pressure FROM `bigquery-public-data.noaa_icoads.icoads_core_1662_2000`\", client)","bd14b3c5":"QUERY = \"\"\"\n        SELECT latitude, longitude, sea_surface_temp, wind_direction_true, amt_pressure_tend,  air_temperature, sea_level_pressure, wave_direction, wave_height, timestamp\n        FROM `bigquery-public-data.noaa_icoads.icoads_core_2017`\n        WHERE longitude > -74 AND longitude <= -44 AND latitude > 36 AND latitude <= 65 AND wind_direction_true <= 360\n        \"\"\"","86ee0fbf":"estimate_gigabytes_scanned_h(QUERY, client)\n","e03496cd":"import pandas as pd","1e354aee":"df = client.query(QUERY).to_dataframe()","6a07e7ea":"df.size","dc6e3a21":"df.head(10)","16d08546":"print(df.latitude.size, df.longitude.size)","2d34aada":"from mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt\nimport numpy as np\n# set up orthographic map projection with\n# perspective of satellite looking down at 50N, 100W.\n# use low resolution coastlines.\nmap = Basemap(projection='ortho',lat_0=45,lon_0=-60,resolution='l')\n# draw coastlines, country boundaries, fill continents.\nmap.drawcoastlines(linewidth=0.25)\nmap.drawcountries(linewidth=0.25)\nmap.fillcontinents(color='coral',lake_color='aqua')\n# draw the edge of the map projection region (the projection limb)\nmap.drawmapboundary(fill_color='aqua')\n# draw lat\/lon grid lines every 30 degrees.\nmap.drawmeridians(np.arange(0,360,30))\nmap.drawparallels(np.arange(-90,90,30))\n# make up some data on a regular lat\/lon grid.\nlats = df['latitude'].values\nlons = df['longitude'].values\nx, y = map(lons, lats)\n# contour data over the map.\ncs = map.scatter(x,y)\nplt.title('contour lines over filled continent background')\nplt.show()","8fe53d05":"df_nans = df.isnull().sum(axis = 0)\nprint (\"Number of NaN's by column:\\n\\n\", df_nans, sep = \"\") # \\n means newline, sep = \"\" removes space between elements of print command\n# Now I want to know the percentage of NaN's in each column, so I need to get values of df_nans and divide by number of recordings in df. Let's look what type df_nans has\nprint (\"\\nType of df_nans:\\n\\n\", type(df_nans), sep = \"\")\n# After looking at the output of dir() command excluding built-in and private elements I understood that values of df_nans are accessable with .values element\n# (uncomment next command to look at dir() output), also full dir() available if you want to look at built-in and private elements\n# print ([f for f in dir(df_nans) if not f.startswith('_')]) # print (dir(df_nans))\n# Let's divide df_nans by df row vount and output it with per cent sign\ndf_nans_perc = 100*df_nans\/len(df.index)\npd.options.display.float_format = '{:,.2f}%'.format\nprint(\"\\nPer cent of NaN's by column:\\n\\n\", df_nans_perc, sep = \"\")\npd.options.display.float_format = '{:,.2f}'.format","418ebade":"#Let's create separate dataset with latitude, longitude, sea_surface_temp, wind_direction_true, air_temperature, sea_level_pressure, timestamp:\ndf_no_nans =df[['latitude', 'longitude', 'sea_surface_temp', 'wind_direction_true', 'air_temperature', 'sea_level_pressure', 'timestamp']]\n#And now let's remove all rows with NaN elements:\nprint(\"Rows in df_no_nans:\\nBefore dropping NaN's:\", len(df_no_nans.index))\ndf_no_nans = df_no_nans.dropna()\nprint(\"After:                \", len(df_no_nans.index))","474e2815":"list(df_no_nans)","b681494c":"import seaborn as sns\nsns.heatmap(df_no_nans.corr(), \n        xticklabels=df_no_nans.corr().columns,\n        yticklabels=df_no_nans.corr().columns)","33d7224c":"Obviously, air temperature correlates with sea surface temperature.\n\nAs little region was chosen, a correlation between coordinates also has place and there is a little anticorrelation between latitude and temperature of sea surface and air.","8715f79d":"In this notebook I will have a closer look at the ocean-related variables.\n\nFirst, let's create an object for accessing the dataset","c6d68de1":"Let's count how much [NaN](https:\/\/en.wikipedia.org\/wiki\/NaN) values we have in each column:","efd22407":"And, to finish inspectation, let's have a look at some data","4ab3dc50":"Let's look one more time at the tables present in it","47347498":"Also let's have a look at the field names and types","19e98385":"Let's have a look at the Gulf Stream region","5a74cd72":"Let's draw coordinates according to [instruction](https:\/\/matplotlib.org\/basemap\/users\/examples.html)","1a163b53":"Let's execute our QUERY and put result into Pandas dataframe.\n(**uncomment for execution**)","3003b559":"As we have a 5TB per month quota, it is a good practice to analyze what amount of data the SQL query will scan (not return!!!)\n\nFirst function returns same information as second, but in human-readable format"}}