{"cell_type":{"e7ac25d8":"code","d16fbddb":"code","4bf19955":"code","3a1144fe":"code","295c9cae":"code","ea7eb048":"code","7f983fcf":"code","ee79a862":"code","d93e6cd1":"code","9a643f23":"code","f9026ba9":"code","09f57232":"code","bde68592":"code","2c400013":"code","84d33fd1":"code","32d779ea":"code","8b88d22c":"code","9a39491c":"code","55005807":"code","755e4e64":"code","77c9d604":"code","03309538":"code","e0e54f09":"code","2a4fe4f1":"code","ef425e61":"code","7623fa12":"code","184101a7":"code","31af1d14":"code","31fd8306":"code","3a9859ca":"code","52f14542":"markdown","4536aec2":"markdown","cd6c9a55":"markdown","fea21b03":"markdown"},"source":{"e7ac25d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d16fbddb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n%matplotlib inline","4bf19955":"df=pd.read_table('..\/input\/fruits-with-colors-dataset\/fruit_data_with_colors.txt')","3a1144fe":"df.head()","295c9cae":"df.info()","ea7eb048":"df.describe()","7f983fcf":"#to check corrupted cells\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis') #no empty cells","ee79a862":"df.fruit_name.value_counts()","d93e6cd1":"df.fruit_subtype.value_counts()","9a643f23":"px.sunburst(df,path=['fruit_name','fruit_subtype'],color='mass',values='width')","f9026ba9":"px.scatter_3d(df,x='width',y='height',z='mass',color='color_score')","09f57232":"px.scatter(df,x='width',y='height',color='fruit_name',marginal_y='violin',marginal_x='box')","bde68592":"px.scatter_matrix(df,dimensions=['fruit_name','mass','width','height'],color='color_score')","2c400013":"plt.plot(df['height'],label='Height')\nplt.plot(df['width'],label='Width')\nplt.legend()","84d33fd1":"predicting=dict(zip(df.fruit_label.unique(), df.fruit_name.unique()))","32d779ea":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier","8b88d22c":"X=df[['mass','width','height']]\ny=df['fruit_label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)","9a39491c":"knn=KNeighborsClassifier()","55005807":"knn.fit(X_train,y_train)","755e4e64":"from sklearn.metrics import classification_report,confusion_matrix","77c9d604":"print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))","03309538":"pred=knn.predict(X_test)","e0e54f09":"print(classification_report(y_test,pred))","2a4fe4f1":"training_accuracy=[]\ntest_accuracy=[]\nneighbors_settings = range(1, 11)\nfor n_neighbors in neighbors_settings:\n    clf=KNeighborsClassifier(n_neighbors=n_neighbors)\n    clf.fit(X_train,y_train)\n    training_accuracy.append(clf.score(X_train,y_train))\n    test_accuracy.append(clf.score(X_test,y_test))\n\nplt.plot(neighbors_settings,training_accuracy,label='Training Accuracy')\nplt.plot(neighbors_settings,test_accuracy,label='Test Accuracy')\nplt.xlabel(\"Accuracy\")\nplt.ylabel('n_neighbors')\nplt.show()","ef425e61":"knn1 = KNeighborsClassifier(n_neighbors=1)\n\nknn1.fit(X_train,y_train)\npred = knn1.predict(X_test)\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","7623fa12":"knn6 = KNeighborsClassifier(n_neighbors=6)\n\nknn6.fit(X_train,y_train)\npred = knn6.predict(X_test)\nprint('WITH K=6')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","184101a7":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","31af1d14":"knn4 = KNeighborsClassifier(n_neighbors=4)\n\nknn4.fit(X_train,y_train)\npred = knn6.predict(X_test)\nprint('WITH K=4')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","31fd8306":"prediction1=knn4.predict([[100,6.3,8]])\npredicting[prediction1[0]]","3a9859ca":"prediction2=knn4.predict([[105,6.1,6]])\npredicting[prediction2[0]]","52f14542":"From this graph we can conclude that K with 4,5 and 12 values cause minimum error, let's try with k=4.","4536aec2":"# KNN Classifier","cd6c9a55":"# Basic Operations","fea21b03":"# Exploratory Data Analysis"}}