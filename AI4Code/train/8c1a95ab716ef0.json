{"cell_type":{"f11a66d8":"code","2d002c78":"code","65806be4":"code","8432e628":"code","569e5872":"code","fd809c12":"code","eca79b3b":"code","c3e75390":"code","64fed2bd":"code","6464c5d5":"code","bc1c5107":"code","411ff803":"code","176d6bb5":"code","e8c9134b":"code","3270b8cc":"code","71c208fe":"code","5c8fd5cd":"code","18205bbc":"code","a6a2f3c1":"code","bf768495":"code","e59c5835":"code","e9a97f45":"code","4c10b9e5":"code","97db14cc":"code","d194b499":"code","68139169":"code","785d253a":"code","de78c06d":"markdown","e7a2d708":"markdown","6666ebc5":"markdown","a600e152":"markdown","b1204e47":"markdown","eb755caf":"markdown","50cfc9cb":"markdown","e6edc338":"markdown","67223387":"markdown","4f300357":"markdown","85ae1d47":"markdown"},"source":{"f11a66d8":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport pydicom\nfrom tqdm import tqdm_notebook\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom skimage.transform import resize\nimport PIL\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n","2d002c78":"img_size = 256","65806be4":"tr = pd.read_csv('..\/input\/siim-train-test\/siim\/train-rle.csv')","8432e628":"tr.head()","569e5872":"#These are the functions provided by kaggle to convert a mask to rle and vice-versa.\nimport numpy as np\n\ndef mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor: \n                if currentColor >= 127:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    \n    mask= np.zeros(width* height)\n    if rle == ' -1' or rle == '-1':\n        return mask.reshape(width,height)\n    array = np.asarray([int(x) for x in rle.split()])\n    \n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","fd809c12":"plt.imshow(rle2mask(tr[' EncodedPixels'][5],1024,1024))\nplt.show()","eca79b3b":"def get_mask(encode,width,height):\n    if encode == [] or encode == ' -1':\n        return rle2mask(' -1',width,height)\n    else:\n        return rle2mask(encode[0],width,height)       ","c3e75390":"def image_n_encode(train_images_names,encode_df):\n    train_imgs = [] \n    train_encode = []\n    c = 0\n    for f in tqdm_notebook(train_images_names):\n        if c >= 2000:\n            break\n        try:\n            img = pydicom.read_file(f).pixel_array\n            c += 1\n            encode = list(encode_df.loc[encode_df['ImageId'] == '.'.join(f.split('\/')[-1].split('.')[:-1]),\n                               ' EncodedPixels'].values)\n            \n            encode = get_mask(encode,img.shape[1],img.shape[0])\n            encode = resize(encode,(img_size,img_size))\n            train_encode.append(encode)\n            img = resize(img,(img_size,img_size))\n            train_imgs.append(img)\n        except pydicom.errors.InvalidDicomError:\n            print('come here')\n        \n    return train_imgs,train_encode\n        \n        \n        ","64fed2bd":"#getting path of all the train and test images\nfrom glob import glob\ntrain_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-train\/*\/*\/*.dcm'))\ntest_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-test\/*\/*\/*.dcm'))\n\nprint(len(train_fns))\nprint(len(test_fns))","6464c5d5":"images,mask_e = image_n_encode(train_fns,tr)","bc1c5107":"print(len(images),len(mask_e))","411ff803":"plt.imshow(images[102],cmap = 'gray')\nplt.show()\nplt.imshow(mask_e[102])\nplt.show()","176d6bb5":"#Evaluation metric\n#ref https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","e8c9134b":"def build_model(input_layer, start_neurons):\n    #ref: https:\/\/www.kaggle.com\/phoenigs\/u-net-dropout-augmentation-stratification\n    # 128 -> 64\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    # 64 -> 32\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    # 32 -> 16\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    # 16 -> 8\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    # 8 -> 16\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n    # 16 -> 32\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n    # 32 -> 64\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n    # 64 -> 128\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n\n    #uconv1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer\n\ninput_layer = Input((img_size, img_size, 1))\noutput_layer = build_model(input_layer, 16)\n","3270b8cc":"model = Model(input_layer, output_layer)","71c208fe":"model_checkpoint = ModelCheckpoint(\".\/unet_best1.model\", \n                                   mode = 'max', save_best_only=True, verbose=1)","5c8fd5cd":"model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[dice_coef])","18205bbc":"model.summary()","a6a2f3c1":"model.fit(np.array(images).reshape(-1,img_size,img_size,1),np.array(mask_e).reshape(-1,img_size,img_size,1),validation_split = 0.1,\n          epochs = 1,batch_size = 16,\n         callbacks = [model_checkpoint])","bf768495":"del images,mask_e","e59c5835":"gc.collect()","e9a97f45":"print(preds[0])","4c10b9e5":"#print(preds[10])\nprint(len(preds),len(ids))","97db14cc":"submission = pd.DataFrame({'ImageId':ids,'EncodedPixels':preds})","d194b499":"submission.head()","68139169":"submission.to_csv('submission.csv',index = False)","785d253a":"from IPython.display import HTML\nhtml = \"<a href = unet_best1.model>d<\/a>\"\nHTML(html)","de78c06d":"<h4> Predicting the mask and converting it into rle <\/h4>","e7a2d708":"<h4>Converting are rle into masks<\/h4>","6666ebc5":"Thanks to @seesee for uploading [this dataset.](https:\/\/www.kaggle.com\/seesee\/siim-train-test)","a600e152":"preds,ids = test_images_pred(test_fns)","b1204e47":"<h4>Work in progress. I will update it.<\/h4>\n<h3>Any suggestion. Let me know in comments.<\/h3>\n","eb755caf":"def test_images_pred(test_fns):\n    pred_rle = []\n    ids = []\n    for f in tqdm_notebook(test_fns):\n        img = pydicom.read_file(f).pixel_array\n        img = resize(img,(img_size,img_size))\n        img = model.predict(img.reshape(1,img_size,img_size,1))\n        \n        img = img.reshape(img_size,img_size)\n        ids.append('.'.join(f.split('\/')[-1].split('.')[:-1]))\n        #img = PIL.Image.fromarray(((img.T*255).astype(np.uint8)).resize(1024,1024))\n        img = PIL.Image.fromarray((img.T*255).astype(np.uint8)).resize((1024,1024))\n        img = np.asarray(img)\n        #print(img)\n        pred_rle.append(mask2rle(img,1024,1024))\n    return pred_rle,ids\n        ","50cfc9cb":"<h3>Building our model<\/h3>","e6edc338":"<h4>Gettting image and corresponding mask<\/h4>\nI am using only 2000 train images due to time and memory contraint. Moreover I am checking everything works fine.","67223387":"<h1>Let's Get started<\/h1>\n","4f300357":"**What is given?**     \nTrain images and test images which we have to download using Healthcare API. And train_rle.csv which have image id and corresponding rle. Beware all train image don't have rle.","85ae1d47":"Importing the required libraries."}}