{"cell_type":{"56a3e190":"code","031052fb":"code","81310610":"code","e28fff30":"code","092dbf81":"code","8aaa4a0d":"code","95c8bd02":"code","a4ebcc4c":"code","95aa593e":"markdown","814f1b9a":"markdown","bc2af567":"markdown","216154c5":"markdown","f97a3e97":"markdown"},"source":{"56a3e190":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\nimport numpy as np \nimport pandas as pd \nimport pandas as pd \nimport numpy as np \nimport scipy as sp \nimport sklearn\nimport random \nimport time \n\nfrom sklearn import preprocessing, model_selection\n\n\nfrom keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.utils import shuffle","031052fb":"data = pd.read_csv('..\/input\/Iris.csv')\ndata = data.drop(['Id'], axis =1)","81310610":"data = shuffle(data)\n\n\ni = 8\ndata_to_predict = data[:i].reset_index(drop = True)\npredict_species = data_to_predict.Species \npredict_species = np.array(predict_species)\nprediction = np.array(data_to_predict.drop(['Species'],axis= 1))\n\ndata = data[i:].reset_index(drop = True)\n\n\n\n","e28fff30":"X = data.drop(['Species'], axis = 1)\nX = np.array(X)\nY = data['Species']\n\n\n","092dbf81":"# Transform name species into numerical values \nencoder = LabelEncoder()\nencoder.fit(Y)\nY = encoder.transform(Y)\nY = np_utils.to_categorical(Y)\n#print(Y)\n\n# We have 3 classes : the output looks like : \n#0,0,1 : Class 1\n#0,1,0 : Class 2\n#1,0,0 : Class 3","8aaa4a0d":"train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)\n\n","95c8bd02":"input_dim = len(data.columns) - 1\n\nmodel = Sequential()\nmodel.add(Dense(8, input_dim = input_dim , activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(3, activation = 'softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n\nmodel.fit(train_x, train_y, epochs = 10, batch_size = 2)\n\nscores = model.evaluate(test_x, test_y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","a4ebcc4c":"predictions = model.predict_classes(prediction)\nprediction_ = np.argmax(to_categorical(predictions), axis = 1)\nprediction_ = encoder.inverse_transform(prediction_)\n\nfor i, j in zip(prediction_ , predict_species):\n    print( \" the nn predict {}, and the species to find is {}\".format(i,j))","95aa593e":"\nIt is time to make predictions with the small sample removed from the base at the beginning.\nTo train the neural network it was necessary to convert the species into vectors. So after the prediction it is necessary to carry out the opposite operation to recover the name of the associated species","814f1b9a":"\nWe must transform the column of classes, because we have a format 'str', and it is a multiclass situation. We must first convert the names of species into numerical values, then into vectors for the output of the neuron network. \n","bc2af567":"\nWe are going to separate the data. One part will be used to make predictions in the end, the other part, the most important will be used for training and testing the neural network.\nThis part is not mandatory, but it is for fun, and especially to show how to predict from an input.","216154c5":"\nThis is a very basic example of a construction of a neural network that allows for a multiclass classification with tensorflow keras.","f97a3e97":"\nIt's time to build our neural network. The dimension in input is the number of features of the dataframe (without the class to predict!).\n\nWe are on a multiclass classification situation, so the activation function for the last most suitable layer is \"softmax\", and \"categorical_crossentropy\" for the loss.\n\nWe have to do several tests to find the best architecture, but this one works pretty well"}}