{"cell_type":{"52ff493f":"code","af06b873":"code","64edd0b4":"code","851d5aa6":"code","a635b815":"code","89268352":"code","1872c165":"code","85302909":"code","0799af7d":"code","e018fc33":"code","e2fd3129":"code","63cae930":"code","34b075db":"code","c22cfc65":"code","85e409db":"code","d2127878":"code","49e9d8df":"code","24b72073":"code","5dcdc757":"code","8a8737ef":"code","2c3ea7a4":"code","a288141e":"code","a250bec2":"code","ffd6f712":"code","dd1b0912":"code","25357f9f":"code","eb58edc0":"code","becfe9b7":"code","c284c642":"code","cab94fc4":"code","0a334c61":"code","ee1c60f1":"code","76f96af2":"code","009b8dc4":"code","d590043b":"code","7a634baa":"code","91d07ef8":"code","a104a7e2":"code","eea9b64f":"code","86eb3a8f":"code","618bde16":"code","edbd0231":"code","b84f58bd":"code","849aca3f":"code","af5b1100":"code","013e0671":"code","8d17e78f":"code","57939046":"code","71a6e094":"code","b512a77c":"code","b25bb6a9":"code","262450d4":"code","35949a91":"code","1ef31e04":"code","32900fb3":"code","97b4dbf9":"markdown","21d8a4c7":"markdown","617a0095":"markdown","af853126":"markdown","162b6787":"markdown","35c3981c":"markdown","827b924f":"markdown","6f215e05":"markdown","385a8e33":"markdown","cc60b5c6":"markdown","c8f2cb32":"markdown","590a8a80":"markdown","505c103e":"markdown","50dfb5dd":"markdown","f26a391d":"markdown","72c88715":"markdown","8ebcab37":"markdown","9c738ddb":"markdown","37ed325a":"markdown","e7c3a8c8":"markdown","b94a6484":"markdown","0c65208c":"markdown","8e2aa4f9":"markdown","334a4438":"markdown","36388712":"markdown","013afdcd":"markdown","ec805049":"markdown","b4c51193":"markdown","f0f9c2b4":"markdown","1499cb83":"markdown","138078b3":"markdown","cea9cef6":"markdown","48b3cf4e":"markdown","b582c3f4":"markdown"},"source":{"52ff493f":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af06b873":"import warnings\nwarnings.filterwarnings(action='ignore')\n\nimport os\nfrom os.path import isfile, join\n\nimport re\nimport string\nimport nltk\nfrom textblob import TextBlob\n\nimport random\nimport numpy as np\nimport pandas as pd\n\nfrom wordcloud import STOPWORDS as stopwords_wordcloud\nfrom wordcloud import WordCloud\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","64edd0b4":"%%time\n\ndf_anchor_thumbnails = pd.read_csv('..\/input\/chai-time-data-science\/Anchor Thumbnail Types.csv')\ndf_description = pd.read_csv(\"..\/input\/chai-time-data-science\/Description.csv\")\ndf_episodes = pd.read_csv(\"..\/input\/chai-time-data-science\/Episodes.csv\", parse_dates=['recording_date', 'release_date'])\ndf_youtube_thumbnails = pd.read_csv(\"..\/input\/chai-time-data-science\/YouTube Thumbnail Types.csv\")","851d5aa6":"print(f\"Shape of df_anchor_thumbnails:\\t{df_anchor_thumbnails.shape}\")\nprint(f\"Shape of df_description:\\t{df_description.shape}\")\nprint(f\"Shape of df_episodes:\\t\\t{df_episodes.shape}\")\nprint(f\"Shape of df_youtube_thumbnails:\\t{df_youtube_thumbnails.shape}\")","a635b815":"def extract_timestamp_info(timestamp, get_hours=False, get_mins=False, get_secs=False):\n    \"\"\" Extract timestamp data \"\"\"\n    timestamp = str(timestamp)\n    if len(timestamp) <= 5:\n        hours = 0\n        mins, secs = timestamp.split(':')\n    elif len(timestamp) == 7:\n        hours, mins, secs = timestamp.split(':')\n    if get_hours:\n        return int(hours)\n    if get_mins:\n        return int(mins)\n    if get_secs:\n        return int(secs)\n    return None\n\n\ndef get_timestamp_in_secs(timestamp):\n    \"\"\"\n    Convert timestamp string into integer indicating number of seconds denoting said timestamp.\n    Eg: If `timestamp` is '1:12:52', then `timestamp_in_secs` will be (1 x 3600) + (12 * 60) + (52)\n    \"\"\"\n    timestamp = str(timestamp)\n    timestamp_split = timestamp.split(':')\n    if len(timestamp_split) == 2:\n        hours = 0\n        mins, secs = timestamp_split\n    elif len(timestamp_split) == 3:\n        hours, mins, secs = timestamp_split\n    timestamp_in_secs = (int(hours) * 3600) + (int(mins) * 60) + int(secs)\n    return timestamp_in_secs\n\n\ndef read_subtitle_data(filepath=\"..\/input\/chai-time-data-science\/Cleaned Subtitles\/\"):\n    \"\"\"\n    Reads the cleaned subtitle files into one Pandas DataFrame, and adds some transformations to it.\n    NOTE: Make sure you leave a trailing slash '\/' for the filepath.\n    \"\"\"\n    df_subtitles_data = pd.DataFrame()\n    filenames = [filename for filename in os.listdir(filepath) if isfile(join(filepath, filename))]\n    counter = 0\n    for filename in filenames:\n        episode_number = int(filename.split('.')[0][1:])\n        df_temp = pd.read_csv(f\"{filepath}{filename}\")\n        df_temp['Episode'] = episode_number\n        df_temp['NumSpeakersForThisEpisode'] = df_temp['Speaker'].nunique()\n        df_subtitles_data = pd.concat(objs=[df_subtitles_data, df_temp], ignore_index=True, sort=False)\n        counter += 1\n    \n    # Sort by timestamps inside each episode\n    df_subtitles_data['Hours'] = df_subtitles_data['Time'].apply(extract_timestamp_info, get_hours=True)\n    df_subtitles_data['Mins'] = df_subtitles_data['Time'].apply(extract_timestamp_info, get_mins=True)\n    df_subtitles_data['Secs'] = df_subtitles_data['Time'].apply(extract_timestamp_info, get_secs=True)\n    \n    df_subtitles_data.sort_values(by=['Episode', 'Hours', 'Mins', 'Secs'], ascending=[True, True, True, True], inplace=True)\n    df_subtitles_data = df_subtitles_data.reset_index(drop=True)\n    df_subtitles_data.drop(labels=['Hours', 'Mins', 'Secs'], axis=1, inplace=True)\n    \n    # Add TimestampInSecs (Convert string timestamp into interger denoting the number of seconds passed)\n    df_subtitles_data['TimestampInSecs'] = df_subtitles_data['Time'].apply(get_timestamp_in_secs)\n    \n    # Add TalkTimeInSecs (Talk time of each person in the conversation, by episode)\n    df_subtitles_data_altered = pd.DataFrame()\n    episodes = df_subtitles_data['Episode'].unique().tolist()\n    counter_talktime = 0\n    for episode in episodes:\n        df_temp = df_subtitles_data[df_subtitles_data['Episode'] == episode]\n        df_temp['TalkTimeInSecs'] = (df_temp.iloc[::-1]['TimestampInSecs'].diff()).apply(round, args=[4]).abs().tolist()[::-1]\n        df_subtitles_data_altered = pd.concat(objs=[df_subtitles_data_altered, df_temp], ignore_index=True, sort=False)\n        counter_talktime += 1\n    \n    print(\n        f\"Successfully read {counter} files containing subtitles, and concatenated into one DataFrame.\",\n        f\"Successfully added 'TalkTimeInSecs' column for {counter_talktime} episodes.\"\n    )\n    return df_subtitles_data_altered","89268352":"%%time\ndf_subtitles = read_subtitle_data()","1872c165":"df_subtitles.info()","85302909":"df_subtitles.head()","0799af7d":"df_anchor_thumbnails","e018fc33":"df_youtube_thumbnails","e2fd3129":"df_description.info()","63cae930":"df_description.head()","34b075db":"df_episodes.info()","c22cfc65":"df_episodes.head()","85e409db":"def generate_random_hex_code():\n    \"\"\" Generates random 6-digit hexadecimal code \"\"\"\n    choices = '0123456789ABCDEF'\n    random_hex_code = '#'\n    for _ in range(6):\n        random_hex_code += random.choice(choices)\n    return random_hex_code\n\n\ndef plot_donut(title, labels, values):\n    \"\"\"\n    Plots donut chart.\n    Parameters:\n        - title (str): Title of chart\n        - labels (list): Categorical labels\n        - values (list): Numerical values\n    \"\"\"\n    colors = [generate_random_hex_code() for _ in range(len(labels))]\n    _, ax1 = plt.subplots()\n    ax1.pie(x=list(values), labels=list(labels), colors=colors, autopct='%1.1f%%', startangle=40)\n    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n    fig = plt.gcf()\n    fig.gca().add_artist(centre_circle)\n    ax1.axis('equal')  \n    plt.tight_layout()\n    plt.title(f\"{str(title)}\", fontsize=15)\n    plt.show()\n    return None\n\n\ndef plot_bar_sns(title, x_column, y_column, data, orient, hue=None):\n    \"\"\"\n    Plots vertical\/horizontal bar chart using Seaborn.\n    Parameters:\n        - title (str): Title of chart\n        - x_column (str): Name of column representing data for x-axis\n        - y_column (str): Name of column representing data for y-axis\n        - data (Pandas DataFrame): Dataset\n        - orient (str): 'v' | 'h'\n        - hue (str): Name of column by which you want to color hue (optional)\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    sns.barplot(data=data,\n                x=x_column,\n                y=y_column,\n                orient=orient,\n                hue=hue)\n    plt.title(f\"{str(title)}\", fontsize=24)\n    plt.xlabel(x_column, fontsize=16)\n    plt.ylabel(y_column, fontsize=16)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.show()\n    return None\n\n\ndef plot_bar(title, x_column, y_column, data=None, x_vals=None, y_vals=None, horizontal=False, annotate=True):\n    \"\"\"\n    Plots bar chart or horizontal bar chart.\n    Parameters:\n        - title (str): Title of chart\n        - x_column (str): Name of column representing data for x-axis\n        - y_column (str): Name of column representing data for y-axis\n        - data (Pandas DataFrame): Dataset (optional)\n        - x_vals (list): Values\/Labels for the x-axis (optional)\n        - y_vals (list): Values\/Labels for the y-axis (optional)\n        - horizontal (bool): True for horizontal barchart; False for vertical barchart. Default: False\n        - annotate (bool): True to use annotations; False otherwise. Default: True\n    Usage:\n        This function can be called by either of the following 2 ways.\n        - By passing `data`, along with `x_column` and `y_column`\n        - By passing `x_vals` and `y_vals`, along with `x_column` and `y_column`\n        - Setting `horizontal` accordingly\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    if type(data) == pd.core.frame.DataFrame:\n        colors = [generate_random_hex_code() for _ in range(len(data))]\n        if horizontal:\n            plt.barh(y=data[y_column], width=data[x_column], color=colors)\n        else:\n            plt.bar(x=data[x_column], height=data[y_column], color=colors)\n        # Annotations\n        if type(data[x_column].iloc[0]) == str:\n            numerical_column = y_column\n        else:\n            numerical_column = x_column\n        if annotate:\n            for i, v in enumerate(data[numerical_column]):\n                plt.text(x = v + 0.04, y = i, s = str(v), fontweight='bold', fontsize=12, color='black')\n    else:\n        x_vals, y_vals = list(x_vals), list(y_vals)\n        colors = [generate_random_hex_code() for _ in range(len(x_vals))]\n        if horizontal:\n            plt.barh(y=y_vals, width=x_vals, color=colors)\n        else:\n            plt.bar(x=x_vals, height=y_vals, color=colors)\n        # Annotations\n        if type(x_vals[0]) == str:\n            numerical_column = y_vals\n        else:\n            numerical_column = x_vals\n        if annotate:\n            for i, v in enumerate(numerical_column):\n                plt.text(x = v + 0.04, y = i, s = str(v), fontweight='bold', fontsize=12, color='black')\n    plt.title(f\"{str(title)}\", fontsize=24)\n    plt.xlabel(x_column, fontsize=16)\n    plt.ylabel(y_column, fontsize=16)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.show()\n    return None\n\n\ndef plot_valuecounts(title, data, column, normalize=False):\n    \"\"\"\n    Plots value-counts.\n    Parameters:\n        - title (str): Title of chart\n        - data (Pandas DataFrame): Dataset\n        - column (str): Name of column for which you want to plot value-counts\n        - normalize (bool): True for percentages; False for absolutes. Default: False\n    \"\"\"\n    if normalize:\n        dictionary_valuecounts = data[column].value_counts(normalize=True).mul(100).apply(round, args=[2]).to_dict()\n        x_column = 'Percentage of occurences'\n    else:\n        dictionary_valuecounts = data[column].value_counts().to_dict()\n        x_column = 'Count of occurences'\n    plot_bar(title=title,\n             x_column=x_column,\n             y_column=column,\n             x_vals=dictionary_valuecounts.values(),\n             y_vals=dictionary_valuecounts.keys(),\n             horizontal=True)\n    return None\n\n\ndef plot_timeseries(title, x_column, y_column, data=None, x_vals=None, y_vals=None, area=False):\n    \"\"\"\n    Plots timeseries or timeseries-like line\/area chart, given ascendingly sorted DataFrame and\/or list-like data.\n    Parameters:\n        - title (str): Title of chart\n        - x_column (str): Name of column representing data for x-axis, usually the element of time\n        - y_column (str): Name of column representing data for y-axis\n        - data (Pandas DataFrame): Dataset (optional)\n        - x_vals (list): Values\/Labels for the x-axis, usually the element of time (optional)\n        - y_vals (list): Values\/Labels for the y-axis (optional)\n        - area (bool): True for area-chart; False for line-chart. Default: False\n    Usage:\n        This function can be called by either of the following 2 ways.\n        - By passing `data`, along with `x_column` and `y_column`\n        - By passing `x_vals` and `y_vals`, along with `x_column` and `y_column`\n        - Setting `area` accordingly\n    \"\"\"\n    color = '#135FB6'\n    linewidth = 2.5\n    if area:\n        fill_color = 'skyblue'\n        fill_alpha = 0.4\n    \n    plt.figure(figsize=(12, 5))\n    if type(data) == pd.core.frame.DataFrame:\n        if area:\n            plt.fill_between(data[x_column], data[y_column], color=fill_color, alpha=fill_alpha)\n        plt.plot(data[x_column], data[y_column], color=color, linewidth=linewidth)\n        # Set 'n' equidistant points for xticks, instead of all points\n        xticks = list(map(np.floor, list(np.linspace(start=1, stop=len(data), num=5))))\n    else:\n        if area:\n            plt.fill_between(list(x_vals), list(y_vals), color=fill_color, alpha=fill_alpha)\n        plt.plot(list(x_vals), list(y_vals), color=color, linewidth=linewidth)\n        # Set 'n' equidistant points for xticks, instead of all points\n        xticks = list(map(np.floor, list(np.linspace(start=1, stop=len(x_vals), num=5))))\n    plt.title(f\"{str(title)}\", fontsize=24)\n    plt.xlabel(x_column, fontsize=16)\n    plt.ylabel(y_column, fontsize=16)\n    plt.xticks(xticks, fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.grid()\n    plt.tight_layout()\n    plt.show()\n    return None\n\n\ndef plot_scatter(title, x_column, y_column, data=None, x_vals=None, y_vals=None, alpha=None, size=80):\n    \"\"\"\n    Plots scatter chart, given DataFrame and\/or list-like data.\n    Parameters:\n        - title (str): Title of chart\n        - x_column (str): Name of column representing data for x-axis, usually the element of time\n        - y_column (str): Name of column representing data for y-axis\n        - data (Pandas DataFrame): Dataset (optional)\n        - x_vals (list): Values\/Labels for the x-axis, usually the element of time (optional)\n        - y_vals (list): Values\/Labels for the y-axis (optional)\n        - alpha (float): Values between 0 and 1 for transparency (optional)\n        - size (int): Size of scatter points. Default: 80\n    Usage:\n        This function can be called by either of the following 2 ways.\n        - By passing `data`, along with `x_column` and `y_column`\n        - By passing `x_vals` and `y_vals`, along with `x_column` and `y_column`\n    \"\"\"\n    color = 'g'\n    \n    plt.figure(figsize=(12, 5))\n    if type(data) == pd.core.frame.DataFrame:\n        plt.scatter(x=data[x_column], y=data[y_column], c=color, s=size, alpha=alpha)\n    else:\n        plt.scatter(x=list(x_vals), y=list(y_vals), c=color, s=size, alpha=alpha)\n    plt.title(f\"{str(title)}\", fontsize=24)\n    plt.xlabel(x_column, fontsize=16)\n    plt.ylabel(y_column, fontsize=16)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.grid()\n    plt.tight_layout()\n    plt.show()\n    return None\n\n\ndef plot_histogram(title, column, data=None, array=None, bins=10, grid=True, color='#2B88CA'):\n    \"\"\"\n    Plots histogram, given DataFrame and\/or list-like data.\n    Parameters:\n        - title (str): Title of chart\n        - column (str): Name of column representing data for the histogram\n        - data (Pandas DataFrame): Dataset (optional)\n        - array (list): Values for the histogram to plot (optional)\n        - bins (int): Number of bins for the histogram. Default: 10\n        - grid (bool): True to plot grid, False otherwise. Default: True\n        - color (str): Color of histogram bins. Hex-codes can be used. Default: '#2B88CA' (shade of blue)\n    Usage:\n        This function can be called by either of the following 2 ways.\n        - By passing `data`, along with `column`\n        - By passing `array`, along with `column`\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    if type(data) == pd.core.frame.DataFrame:\n        plt.hist(x=data[column], bins=bins, color=color)\n    else:\n        plt.hist(x=array, bins=bins, color=color)\n    plt.title(f\"{str(title)}\", fontsize=24)\n    plt.xlabel(column, fontsize=16)\n    plt.ylabel(\"Frequency\", fontsize=16)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    if grid:\n        plt.grid()\n    plt.tight_layout()\n    plt.show()\n    return None","d2127878":"def clean_text(text):\n    \"\"\"\n    Make text lowercase, remove text in square brackets, remove links, remove punctuations\n    and remove words containing numbers.\n    \"\"\"\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\n# def preprocess_text(text):\n#     \"\"\"\n#     Cleaning and parsing the text.\n#     \"\"\"\n#     tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n#     text_cleaned = clean_text(text)\n#     tokenized_text = tokenizer.tokenize(text_cleaned)\n#     # remove_stopwords = [word for word in tokenized_text if word not in stopwords.words('english')]\n#     combined_text = ' '.join(tokenized_text)\n#     return combined_text","49e9d8df":"def describe_missing_data(data, show_all=False):\n    \"\"\"\n    Definition:\n        Takes in raw DataFrame, and returns DataFrame with information about missing values (by variable)\n    Parameters:\n        - data (Pandas DataFrame): Pandas DataFrame of dataset\n        - show_all (bool): True to show variables without missing values; False otherwise. Default: False\n    Returns:\n        Returns Pandas DataFrame with information about missing values (by variable).\n        Columns include: ['Variable', 'NumMissingValues', 'PercentMissingValues', 'DataType']\n    \"\"\"\n    # Datatype info\n    df_dtypes = pd.DataFrame()\n    data.dtypes.to_frame().reset_index()\n    df_dtypes['Variable'] = data.dtypes.to_frame().reset_index()['index']\n    df_dtypes['DataType'] = data.dtypes.to_frame().reset_index()[0]\n    \n    # Missing value info\n    rename_dict = {\n        'index': 'Variable',\n        0: 'NumMissingValues',\n        '0': 'NumMissingValues'\n    }\n    df_missing_values = data.isnull().sum().to_frame().reset_index()\n    df_missing_values.rename(mapper=rename_dict, axis=1, inplace=True)\n    df_missing_values.sort_values(by='NumMissingValues', ascending=False, inplace=True)\n    df_missing_values = df_missing_values[df_missing_values['NumMissingValues'] > 0].reset_index(drop=True)\n    percent_missing_values = (df_missing_values['NumMissingValues'] \/ len(data)).mul(100).apply(round, args=[3])\n    df_missing_values['PercentMissingValues'] = percent_missing_values\n    \n    # Merge everything\n    df_description = pd.merge(left=df_missing_values, right=df_dtypes, on='Variable', how='outer')\n    df_description.fillna(value=0, inplace=True)\n    if not show_all:\n        df_description = df_description[df_description['NumMissingValues'] > 0]\n    df_description['NumMissingValues'] = df_description['NumMissingValues'].astype(int)\n    return df_description\n\n\ndef get_episode_number(episode_id):\n    return int(str(episode_id)[1:])\n\n\n# def is_podcast(episode_id):\n#     return (str(episode_id).strip()[0].upper() == 'E')\n\n\n# def split_data_by_episode_type(data):\n#     \"\"\"\n#     Definition:\n#         There are 2 types of episodes: Podcasts and Educational.\n#         The `episode_id` of Podcasts are prefixed by 'E'.\n#         The `episode_id` of Educational videos are prefixed by 'M'.\n#         This function takes in the episodes DataFrame, splits by the two episode types\n#         (Podcasts and Educational videos), and returns dictionary of split data.\n#     \"\"\"\n#     data['is_podcast'] = data['episode_id'].apply(is_podcast)\n#     data_podcast = data[data['is_podcast'] == True].reset_index(drop=True)\n#     data_educational_video = data[data['is_podcast'] == False].reset_index(drop=True)\n#     dictionary_data_by_episode_type = {\n#         'podcast': data_podcast,\n#         'educational': data_educational_video\n#     }\n#     return dictionary_data_by_episode_type","24b72073":"plot_bar(title=\"Percentage of missing values by variable\",\n         x_column='PercentMissingValues',\n         y_column='Variable',\n         data=describe_missing_data(data=df_episodes),\n         horizontal=True)\n\nplot_bar(title=\"Number of missing values by variable\",\n         x_column='NumMissingValues',\n         y_column='Variable',\n         data=describe_missing_data(data=df_episodes),\n         horizontal=True)","5dcdc757":"df_episodes.head()","8a8737ef":"df_episodes_with_heroes = df_episodes[df_episodes['heroes'].notna()]\ndf_episodes_without_heroes = df_episodes[df_episodes['heroes'].isna()]","2c3ea7a4":"df_episodes_with_heroes['category'].value_counts()","a288141e":"df_episodes_without_heroes['category'].value_counts()","a250bec2":"df_episodes_with_heroes['episode_number'] = df_episodes_with_heroes['episode_id'].apply(get_episode_number)\ndf_episodes_with_heroes = df_episodes_with_heroes.sort_values(by='episode_number', ascending=True).reset_index(drop=True)\n\ndf_episodes['episode_duration_mins'] = round((df_episodes['episode_duration'] \/ 60), 2)\ndf_episodes_with_heroes['episode_duration_mins'] = round((df_episodes_with_heroes['episode_duration'] \/ 60), 2)\ndf_episodes_without_heroes['episode_duration_mins'] = round((df_episodes_without_heroes['episode_duration'] \/ 60), 2)","ffd6f712":"categories_valuecount = df_episodes_with_heroes['category'].value_counts()\nplot_donut(title=\"Podcasts by Category (With heroes)\",\n           labels=categories_valuecount.index,\n           values=categories_valuecount.values)\n\ncategories_valuecount = df_episodes['category'].value_counts()\nplot_donut(title=\"Podcasts by Category (All)\",\n           labels=categories_valuecount.index,\n           values=categories_valuecount.values)\n\nplot_valuecounts(title=\"Podcasts (having heroes) by Category\",\n                 data=df_episodes_with_heroes,\n                 column='category',\n                 normalize=False)\n\nplot_valuecounts(title=\"Podcasts (all) by Category\",\n                 data=df_episodes,\n                 column='category',\n                 normalize=False)","dd1b0912":"plot_bar(title=\"Average podcast duration (in mins) with heroes vs without heroes\",\n         x_column='Average podcast duration (in mins)',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['episode_duration_mins'].mean(), 2),\n                 round(df_episodes_without_heroes['episode_duration_mins'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=True)\n\nplot_bar(title=\"Average YouTube CTR with heroes vs without heroes\",\n         x_column='Average YouTube CTR',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['youtube_ctr'].mean(), 2),\n                 round(df_episodes_without_heroes['youtube_ctr'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average YouTube views with heroes vs without heroes\",\n         x_column='Average YouTube views',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['youtube_views'].mean(), 2),\n                 round(df_episodes_without_heroes['youtube_views'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average YouTube impressions with heroes vs without heroes\",\n         x_column='Average YouTube impressions',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['youtube_impressions'].mean(), 2),\n                 round(df_episodes_without_heroes['youtube_impressions'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average YouTube likes with heroes vs without heroes\",\n         x_column='Average YouTube likes',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['youtube_likes'].mean(), 2),\n                 round(df_episodes_without_heroes['youtube_likes'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average Spotify streams with heroes vs without heroes\",\n         x_column='Average Spotify streams',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['spotify_streams'].mean(), 2),\n                 round(df_episodes_without_heroes['spotify_streams'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average Spotify listeners with heroes vs without heroes\",\n         x_column='Average Spotify listeners',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['spotify_listeners'].mean(), 2),\n                 round(df_episodes_without_heroes['spotify_listeners'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Average Apple listeners with heroes vs without heroes\",\n         x_column='Average Apple listeners',\n         y_column='Hero present?',\n         x_vals=[round(df_episodes_with_heroes['apple_listeners'].mean(), 2),\n                 round(df_episodes_without_heroes['apple_listeners'].mean(), 2)],\n         y_vals=['With heroes',\n                 'Without heroes'],\n         horizontal=True,\n         annotate=False)","25357f9f":"dict_gender_valuecount = df_episodes_with_heroes['heroes_gender'].value_counts().to_dict()\n\nplot_donut(title='Guest appearances by Gender',\n           labels=dict_gender_valuecount.keys(),\n           values=dict_gender_valuecount.values())","eb58edc0":"pct_guests_working_abroad = round((df_episodes_with_heroes['heroes_nationality'] != df_episodes_with_heroes['heroes_location']).mean() * 100, 3)\n\nplot_donut(title=\"Is the guest working abroad? (Not in country of origin)\",\n           labels=['Yes', 'No'],\n           values=[pct_guests_working_abroad, 100-pct_guests_working_abroad])","becfe9b7":"dict_nationality_valuecount = df_episodes_with_heroes['heroes_nationality'].value_counts().head(10).to_dict()\nplot_donut(title='Guest appearances by nationality',\n           labels=dict_nationality_valuecount.keys(),\n           values=dict_nationality_valuecount.values())\n\nplot_valuecounts(title=\"Count of guest-appearances by nationality\",\n                 data=df_episodes_with_heroes,\n                 column='heroes_nationality')","c284c642":"plot_valuecounts(title=\"Tea flavour consumed (With heroes)\",\n                 data=df_episodes_with_heroes,\n                 column='flavour_of_tea')\n\nplot_valuecounts(title=\"Tea flavour consumed (Without heroes)\",\n                 data=df_episodes_without_heroes,\n                 column='flavour_of_tea')\n\nplot_valuecounts(title=\"Tea flavour consumed (Overall)\",\n                 data=df_episodes,\n                 column='flavour_of_tea')","cab94fc4":"plot_valuecounts(title=\"Time of recording (With heroes)\",\n                 data=df_episodes_with_heroes,\n                 column='recording_time',\n                 normalize=False)\n\nplot_valuecounts(title=\"Time of recording (Without heroes)\",\n                 data=df_episodes_without_heroes,\n                 column='recording_time',\n                 normalize=False)\n\nplot_valuecounts(title=\"Time of recording (Overall)\",\n                 data=df_episodes,\n                 column='recording_time',\n                 normalize=False)","0a334c61":"plot_timeseries(title=\"Duration of episodes (in mins) - With heroes\",\n                x_column='episode_number',\n                y_column='episode_duration_mins',\n                data=df_episodes_with_heroes,\n                area=False)\n\nplot_timeseries(title=\"Duration of episodes (in mins) - All episodes\",\n                x_column='episode_id',\n                y_column='episode_duration_mins',\n                data=df_episodes.sort_values(by='release_date', ascending=True),\n                area=False)","ee1c60f1":"columns_of_interest = ['episode_id', 'episode_name', 'heroes', 'heroes_nationality', 'category', 'youtube_views', 'episode_duration_mins']\ndf_by_episode_duration = df_episodes_with_heroes[df_episodes_with_heroes['episode_duration_mins'] >= 85].sort_values(by='episode_duration_mins', ascending=False)\ndf_by_episode_duration.reset_index(drop=True, inplace=True)\ndf_by_episode_duration[columns_of_interest]","76f96af2":"# # Inspection\n# sort_by = 'apple_avg_listen_duration'\n\n# columns_of_interest = ['episode_id', 'heroes', 'heroes_twitter_handle', 'heroes_nationality', 'category',\n#                        'youtube_watch_hours', 'youtube_views', 'youtube_impressions', 'spotify_streams',\n#                        'episode_duration_mins']\n\n# if sort_by not in columns_of_interest:\n#     columns_of_interest.append(sort_by)\n\n# df_most_popular_by = df_episodes_with_heroes.sort_values(by=sort_by, ascending=False)\n# df_most_popular_by[columns_of_interest].head(10)","009b8dc4":"plot_bar(title=\"Podcast duration by hero (in mins) - Longest\",\n         x_column='episode_duration_mins',\n         y_column='heroes',\n         data=df_episodes_with_heroes.dropna().sort_values(by='episode_duration_mins', ascending=False).head(),\n         horizontal=True,\n         annotate=False)\n\nplot_bar(title=\"Podcast duration by hero (in mins) - Shortest\",\n         x_column='episode_duration_mins',\n         y_column='heroes',\n         data=df_episodes_with_heroes.dropna().sort_values(by='episode_duration_mins', ascending=False).tail(),\n         horizontal=True,\n         annotate=False)","d590043b":"plot_bar(title=\"YouTube views by hero\",\n         x_column='youtube_views',\n         y_column='heroes',\n         data=df_episodes.dropna().sort_values(by='youtube_views', ascending=False).head(),\n         horizontal=True,\n         annotate=True)\n\nplot_bar(title=\"Spotify views by hero\",\n         x_column='spotify_streams',\n         y_column='heroes',\n         data=df_episodes.dropna().sort_values(by='spotify_streams', ascending=False).head(),\n         horizontal=True,\n         annotate=True)","7a634baa":"plot_bar(title=\"YouTube CTR (Click-through rate) by hero\",\n         x_column='youtube_ctr',\n         y_column='heroes',\n         data=df_episodes.dropna().sort_values(by='youtube_ctr', ascending=False).head(15),\n         horizontal=True,\n         annotate=True)","91d07ef8":"plot_bar(title=\"YouTube likes by hero\",\n         x_column='youtube_likes',\n         y_column='heroes',\n         data=df_episodes.dropna().sort_values(by='youtube_likes', ascending=False).head(15),\n         horizontal=True,\n         annotate=True)","a104a7e2":"title = \"YouTube views by hero\"\n\nplt.figure(figsize=(12, 5))\nplt.scatter(data=df_episodes.dropna().sort_values(by='youtube_views', ascending=False).head(20),\n            x='heroes', y='youtube_views', s='youtube_views', alpha=0.5, c='g')\n\nplt.title(f\"{str(title)}\", fontsize=24)\nplt.xlabel('Hero', fontsize=16)\nplt.ylabel('youtube_views', fontsize=16)\nplt.xticks(rotation=70, fontsize=12)\nplt.yticks(fontsize=12)\nplt.ylim(0, df_episodes.dropna()['youtube_views'].max() * 1.1)\nplt.grid()\nplt.show()","eea9b64f":"plot_histogram(title=\"Episode duration (in mins)\",\n               column='episode_duration_mins',\n               data=df_episodes)","86eb3a8f":"plot_timeseries(title=\"Which episodes brought in YouTube views?\",\n                data=df_episodes_with_heroes,\n                x_column='episode_number',\n                y_column='youtube_views',\n                area=False)\n\ncolumns_of_interest = ['episode_id', 'episode_name', 'heroes', 'heroes_nationality', 'category', 'youtube_views']\ndf_yt_views = df_episodes_with_heroes[df_episodes_with_heroes['youtube_views'] >= 1000].sort_values(by='youtube_views', ascending=False)\ndf_yt_views.reset_index(drop=True, inplace=True)\ndf_yt_views[columns_of_interest].style.background_gradient(cmap='Greens')","618bde16":"plot_timeseries(title=\"Which episodes brought in subscribers?\",\n                data=df_episodes_with_heroes,\n                x_column='episode_number',\n                y_column='youtube_subscribers',\n                area=False)\n\ncolumns_of_interest = ['episode_id', 'episode_name', 'heroes', 'heroes_nationality', 'category', 'youtube_subscribers']\ndf_bringing_yt_subscribers = df_episodes[df_episodes['youtube_subscribers'] >= 40].sort_values(by='youtube_subscribers', ascending=False)\ndf_bringing_yt_subscribers.reset_index(drop=True, inplace=True)\ndf_bringing_yt_subscribers[columns_of_interest].style.background_gradient(cmap='Greens')","edbd0231":"plot_timeseries(title=\"Which episodes brought in more YouTube watch hours?\",\n                data=df_episodes_with_heroes,\n                x_column='episode_number',\n                y_column='youtube_watch_hours',\n                area=False)\n\ncolumns_of_interest = ['episode_id', 'episode_name', 'heroes', 'heroes_nationality', 'category', 'youtube_watch_hours']\ndf_yt_watch_hours = df_episodes_with_heroes[df_episodes_with_heroes['youtube_watch_hours'] >= 100].sort_values(by='youtube_watch_hours', ascending=False)\ndf_yt_watch_hours.reset_index(drop=True, inplace=True)\ndf_yt_watch_hours[columns_of_interest].style.background_gradient(cmap='Greens')","b84f58bd":"plt.figure(figsize=(6, 4))\nsns.boxplot(data=df_episodes, x='youtube_thumbnail_type', y='youtube_ctr')\nplt.title(\"YouTube CTR vs YouTube thumbnail type\", fontsize=15)\nplt.xlabel('youtube_thumbnail_type', fontsize=12)\nplt.ylabel('youtube_ctr', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(6, 4))\nsns.boxplot(data=df_episodes, x='youtube_thumbnail_type', y='youtube_views')\nplt.title(\"YouTube views vs YouTube thumbnail type\", fontsize=15)\nplt.xlabel('youtube_thumbnail_type', fontsize=12)\nplt.ylabel('youtube_views', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(6, 4))\nsns.boxplot(data=df_episodes, x='youtube_thumbnail_type', y='youtube_avg_watch_duration')\nplt.title(\"YouTube avg-watch-duration vs YouTube thumbnail type\", fontsize=15)\nplt.xlabel('youtube_thumbnail_type', fontsize=12)\nplt.ylabel('youtube_avg_watch_duration', fontsize=12)\nplt.show()","849aca3f":"def get_talktimes_by_speaker(data):\n    \"\"\"\n    Gets data about talktimes of host and guests, given the subtitles DataFrame.\n    \"\"\"\n    host_name = 'Sanyam Bhutani'\n    episodes = data['Episode'].unique().tolist()\n    list_talktimes = []\n    for episode in episodes:\n        df_by_episode = data[data['Episode'] == episode]\n        avg_host_talktime = df_by_episode[df_by_episode['Speaker'] == host_name]['TalkTimeInSecs'].mean()\n        avg_guest_talktime = df_by_episode[df_by_episode['Speaker'] != host_name]['TalkTimeInSecs'].mean()\n        dict_talktimes = {\n            'Episode': episode,\n            'AvgHostTalkTime': avg_host_talktime,\n            'AvgGuestTalkTime': avg_guest_talktime\n        }\n        list_talktimes.append(dict_talktimes)\n    return pd.DataFrame(data=list_talktimes)","af5b1100":"df_subtitles.head()","013e0671":"df_talktimes = get_talktimes_by_speaker(data=df_subtitles)\ndf_talktimes.head()","8d17e78f":"linewidths = 3\n\nplt.figure(figsize=(12, 5))\nplt.plot(df_talktimes['Episode'], df_talktimes['AvgGuestTalkTime'], label='Guest', color='green', linewidth=linewidths)\nplt.plot(df_talktimes['Episode'], df_talktimes['AvgHostTalkTime'], label='Host', color='blue', linewidth=linewidths)\nplt.title(\"TalkTimes of Host vs Guest\", fontsize=24)\nplt.xlabel(\"Episode Number\", fontsize=16)\nplt.ylabel(\"AvgTalkTimeInMins\", fontsize=16)\nplt.legend(loc='best', fontsize=12)\nplt.grid()\nplt.show()","57939046":"def generate_wordcloud(title, corpus):\n    \"\"\"\n    Generates WordCloud from corpus of text.\n    \"\"\"\n    corpus = str(corpus)\n    stopwords = list(set(stopwords_wordcloud))\n    corpus_cleaned = clean_text(text=corpus)\n    tokens = corpus_cleaned.split(' ')\n    comment_words = \"\"\n    comment_words = comment_words + \" \".join(tokens) + \" \"\n    \n    wordcloud = WordCloud(width=800, height=800,\n                          background_color='black',\n                          stopwords=stopwords,\n                          min_font_size=10).generate(comment_words)\n\n    plt.figure(figsize=(8, 8), facecolor=None)\n    plt.imshow(wordcloud)\n    plt.title(str(title), fontsize=15)\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    plt.show()\n    return None","71a6e094":"# Let's learn about the following guests' word usage!\nguests = ['Jeremy Howard', 'Abhishek Thakur', 'Parul Pandey', 'Shivam Bansal',\n          'Edouard Harris', 'Robbert Bracco', 'Rohan Rao']\n\nfor guest in guests:\n    dialogs = df_subtitles[df_subtitles['Speaker'] == guest]['Text'].tolist()\n    corpus = \"\"\n    for dialog in dialogs:\n        corpus += str(dialog) + \" \"\n    generate_wordcloud(title=f\"WordCloud for {guest}\", corpus=corpus)","b512a77c":"def get_talking_speed(corpus, talktime_in_mins):\n    \"\"\"\n    Calculates talking speed, given corpus of text and talk-time (in mins).\n    Returns talking speed in words per minute.\n    \"\"\"\n    words = str(corpus).split(' ')\n    num_words_used = len(words)\n    words_per_min = round(num_words_used \/ talktime_in_mins, 2)\n    return words_per_min\n\n\ndef get_vocab_size(corpus, remove_stopwords=False):\n    \"\"\"\n    Calculates size of vocabulary used from corpus of text.\n    \"\"\"\n    corpus_cleaned = clean_text(text=corpus)\n    words = corpus_cleaned.split(' ')\n    vocabulary = list(set(words))\n    if remove_stopwords:\n        vocabulary = [word for word in vocabulary if word not in stopwords_wordcloud]\n    return int(len(vocabulary))","b25bb6a9":"%%time\n\nguests = ['Jeremy Howard', 'Abhishek Thakur', 'Parul Pandey', 'Shivam Bansal',\n          'Edouard Harris', 'Robbert Bracco', 'Rohan Rao']\n\ndf_speaker_stats = pd.DataFrame()\nfor guest in guests:\n    df_subtitles_by_guest = df_subtitles[df_subtitles['Speaker'] == guest]\n    dialogs = df_subtitles_by_guest['Text'].tolist()\n    total_talktime_mins = round(df_subtitles_by_guest['TalkTimeInSecs'].sum() \/ 60, 2)\n    corpus = \"\"\n    for dialog in dialogs:\n        corpus += str(dialog) + \" \"\n    talking_speed = get_talking_speed(corpus=corpus, talktime_in_mins=total_talktime_mins)\n    vocab_size = get_vocab_size(corpus=corpus, remove_stopwords=True)\n    df_temp = pd.DataFrame(data={\n        'Speaker': guest,\n        'TalkingSpeedInWPM': round(talking_speed, 2),\n        'VocabularySize': vocab_size\n    }, index=[0])\n    df_speaker_stats = pd.concat(objs=[df_speaker_stats, df_temp], ignore_index=True, sort=False)","262450d4":"df_speaker_stats.style.background_gradient(cmap='Greens')","35949a91":"%%time\n\nguests = ['Jeremy Howard', 'Abhishek Thakur', 'Parul Pandey', 'Shivam Bansal',\n          'Edouard Harris', 'Robbert Bracco', 'Rohan Rao']\n\ndf_sentiment = pd.DataFrame()\n\nfor guest in guests:\n    df_subtitles_by_guest = df_subtitles[df_subtitles['Speaker'] == guest]\n    dialogs = df_subtitles_by_guest['Text'].tolist()\n    total_talktime_mins = round(df_subtitles_by_guest['TalkTimeInSecs'].sum() \/ 60, 2)\n    corpus = \"\"\n    for dialog in dialogs:\n        corpus += str(dialog) + \" \"\n    corpus_cleaned = clean_text(text=corpus)\n    \n    corpus_textblob_obj = TextBlob(corpus_cleaned)\n    df_temp = pd.DataFrame(data={\n        'Speaker': guest,\n        'Corpus': corpus_cleaned,\n        'Polarity': corpus_textblob_obj.sentiment.polarity,\n        'Subjectivity': corpus_textblob_obj.sentiment.subjectivity\n    }, index=[0])\n    df_sentiment = pd.concat(objs=[df_sentiment, df_temp], ignore_index=True, sort=False)","1ef31e04":"df_sentiment","32900fb3":"plt.figure(figsize=(10, 8))\nfor index, guest in enumerate(df_sentiment['Speaker']):\n    df_sentiment_by_guest = df_sentiment[df_sentiment['Speaker'] == guest]\n    polarities = df_sentiment_by_guest['Polarity'].iloc[0]\n    subjectivities = df_sentiment_by_guest['Subjectivity'].iloc[0]\n    plt.scatter(x=polarities, y=subjectivities, color='blue', s=100)\n    plt.text(x=polarities+0.001, y=subjectivities+0.001, s=df_sentiment['Speaker'].iloc[index], fontsize=10)\nplt.title(\"Sentiment Analysis\", fontsize=24)\nplt.xlabel('Polarity', fontsize=16)\nplt.ylabel('Subjectivity', fontsize=16)\nplt.grid()\nplt.show()","97b4dbf9":"- Looks like Jeremy Howard is quite subjective and quite positive!\n- Shivam Bansal seems like a highly objective person!","21d8a4c7":"- Most guests seem to be Americans.","617a0095":"### Important metrics\n\n- Views\n- Subscribers\n- Watch hours","af853126":"- In the episodes dataset, the `category` column with label 'Other' signifies that there was no hero for that particular episode.\n- Podcasts with no 'heroes' are categorized as 'Other'! They contain tutorial-like\/educational videos.\n- Let's split up the dataset based on whether or not there was a hero.","162b6787":"### Which hero's podcast lasted the longest\/shortest?","35c3981c":"### Podcasts by category, and with\/without heroes","827b924f":"### Guests by gender\n\nSeems like a male dominated guest list.","6f215e05":"### What data do we have?\n\nWe have 4 DataFrames namely:\n- df_anchor_thumbnails\n- df_description\n- df_episodes\n- df_youtube_thumbnails","385a8e33":"### Data cleaning","cc60b5c6":"- Most episodes last around an hour.","c8f2cb32":"### Feature engineering\n- Let us engineer a feature called `episode_number` for the subset of data with heroes as guests on the show.\n- Let us engineer a feature called `episode_duration_mins` from the `episode_duration` column, as the latter is in seconds. We can create the former as it's easier to interpret.","590a8a80":"# Basic insights","505c103e":"### Nationality of heroes","50dfb5dd":"# Notebook by [Nishant Rao](https:\/\/twitter.com\/nishant173)\n\n### Notes\n- We shall analyze the episodes of the podcast after splitting the data available based on whether or not a hero (guest) was present on the podcast.\n- We shall see the contrast between the two situations (with hero vs without hero).\n- We shall also delve into the various social media streaming related features like YouTube\/Spotify\/Apple CTR, views, likes etc.\n- This dataset can also be split by the episode type from the `episode_id` column. Certain episode IDs are prefixed with 'E', others with 'M'. The former ('E') has guests on the podcast, while the latter ('M') is mostly educational content.","f26a391d":"# Social media influence","72c88715":"# About the guests' speaking mannerisms\n\n- Frequency of words used\n- Talking speed\n- Size of vocabulary\n- Sentiment","8ebcab37":"### Reading data","9c738ddb":"### The world of WordClouds","37ed325a":"### Duration of episodes","e7c3a8c8":"### Metrics with\/without heroes","b94a6484":"### Talking tea\n\n- Sanyam really likes Ginger tea and Masala tea","0c65208c":"### How long do guests speak for as opposed to the host?","8e2aa4f9":"### Stay tuned! More to come!\n\n### If you like this kernel, leave a like! Cheers!","334a4438":"### Visualization utilities\nI decided to use some utility plotting functions that I had written earlier. [Source is here](https:\/\/github.com\/Nishant173\/data-utils).","36388712":"### How many guests work outside their country of origin?\n\nAbout 70% of the guests say *Home sweet home*","013afdcd":"### Sentiment analysis","ec805049":"### NLP utilities\nI've copied this snippet from [Parul Pandey](https:\/\/www.kaggle.com\/parulpandey)'s starter [notebook](https:\/\/www.kaggle.com\/parulpandey\/how-to-explore-the-ctds-show-data). Will improve this later.","b4c51193":"### What's missing?","f0f9c2b4":"Wow! That's a lot of views for Jeremy Howard on YouTube!","1499cb83":"# Analyzing the subtitles","138078b3":"### Analyzing YouTube thumbnails used versus various metrics","cea9cef6":"- We can clearly see that the guests aka 'Heroes' make a significant difference regarding viewer attraction!","48b3cf4e":"Jeremy Howard is very likeable!","b582c3f4":"### Popular recording timings\n\n- Most of the fast.ai recordings are done in the night-time IST"}}