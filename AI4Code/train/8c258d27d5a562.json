{"cell_type":{"8997dddb":"code","6e5944fe":"code","baecccab":"code","cf70e7c7":"code","36559e6a":"code","717aeb8e":"code","945c0e51":"code","940aedb6":"code","9b106c5c":"code","2de45f0a":"code","815aaefa":"code","315af550":"code","291c587e":"code","c446eafa":"code","23130811":"code","54b3dc7c":"code","0921d7a3":"code","860352a9":"code","80969553":"code","32108c6c":"code","ad5d3bce":"code","acf5926e":"code","e47b3428":"code","10c95e9f":"code","786f166d":"markdown","ede43fd8":"markdown","1de56ad8":"markdown","2bd4f7bf":"markdown","09de1c24":"markdown","eab4947d":"markdown","0f0755cd":"markdown","8c4aae46":"markdown","67bbbefc":"markdown","3ad4b77b":"markdown","eeceb7a1":"markdown","70f9d28e":"markdown","bf682129":"markdown"},"source":{"8997dddb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e5944fe":"# for basic visualizations\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\n# for advanced visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff","baecccab":"#loading english module\nnlp = spacy.load('en')","cf70e7c7":"#reading the csv file\ndata = pd.read_csv('\/kaggle\/input\/amazon-alexa-reviews\/amazon_alexa.tsv', delimiter = '\\t', quoting = 3)","36559e6a":"#display data\ndata.head()","717aeb8e":"#number of rows and columns present in the dataset.\ndata.shape","945c0e51":"data[\"variation\"].head()","940aedb6":"txt = data[\"verified_reviews\"][1009]\ntxt","9b106c5c":"data.describe()","2de45f0a":"#to see any null data is there\ndata.isnull().any().any()","815aaefa":"doc = nlp(txt)    \nolist = []\nfor token in doc:\n    l = [token.text,\n        token.idx,\n        token.lemma_,\n        token.is_punct,\n        token.is_space,\n        token.shape_,\n        token.pos_,\n        token.tag_]\n    olist.append(l)\n    \nodf = pd.DataFrame(olist)\nodf.columns= [\"Text\", \"StartIndex\", \"Lemma\", \"IsPunctuation\", \"IsSpace\", \"WordShape\", \"PartOfSpeech\", \"POSTag\"]\nodf","315af550":"doc = nlp(txt)\nolist = []\nfor ent in doc.ents:\n    olist.append([ent.text, ent.label_])\n    \nodf = pd.DataFrame(olist)\nodf.columns = [\"Text\", \"EntityType\"]\nodf","291c587e":"from spacy import displacy\ndef explain_text_entities(text):\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')\nfor i in range(15, 50):\n    one_sentence = data['verified_reviews'][i]\n    doc = nlp(one_sentence)\ndisplacy.render(doc, style='ent', jupyter=True)","c446eafa":"doc = nlp(data[\"verified_reviews\"][1009])\nolist = []\nfor token in doc:\n    olist.append([token.text, token.dep_, token.head.text, token.head.pos_,\n          [child for child in token.children]])\nodf = pd.DataFrame(olist)\nodf.columns = [\"Text\", \"Dep\", \"Head text\", \"Head POS\", \"Children\"]\nodf","23130811":"displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})","54b3dc7c":"nlp = spacy.load('en_core_web_lg')","0921d7a3":"from scipy import spatial\n\ncosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n\nlove = nlp.vocab['love'].vector\ncomputed_similarities = []\nfor word in nlp.vocab:\n    # Ignore words without vectors\n    if not word.has_vector:\n        continue\n    similarity = cosine_similarity(love, word.vector)\n    computed_similarities.append((word, similarity))\n\ncomputed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\nprint([w[0].text for w in computed_similarities[:10]])","860352a9":"queen = nlp.vocab['love']\nhappy = nlp.vocab['happy']\nfun = nlp.vocab['fun']\nkids = nlp.vocab['kids']\nking = nlp.vocab['King']\n \nprint(\"Word similarity score between love and happy : \",queen.similarity(happy))\nprint(\"Word similarity score between love and funn : \",queen.similarity(fun))","80969553":"ratings = data['rating'].value_counts()\n\nlabel_rating = ratings.index\nsize_rating = ratings.values\n\ncolors = ['pink', 'lightblue', 'aqua', 'gold', 'crimson']\n\nrating_piechart = go.Pie(labels = label_rating,\n                         values = size_rating,\n                         marker = dict(colors = colors),\n                         name = 'Alexa', hole = 0.3)\n\ndf = [rating_piechart]\n\nlayout = go.Layout(\n           title = 'Distribution of Ratings for Alexa')\n\nfig = go.Figure(data = df,\n                 layout = layout)\n\npy.iplot(fig)","32108c6c":"feedbacks = data['feedback'].value_counts()\n\nlabel_feedback = feedbacks.index\nsize_feedback = feedbacks.values\n\ncolors = ['yellow', 'lightgreen']\n\nfeedback_piechart = go.Pie(labels = label_feedback,\n                         values = size_feedback,\n                         marker = dict(colors = colors),\n                         name = 'Alexa', hole = 0.3)\n\ndf2 = [feedback_piechart]\n\nlayout = go.Layout(title = 'Distribution of Feedbacks for Alexa')\n\nfig = go.Figure(data = df2,layout = layout)\n\npy.iplot(fig)","ad5d3bce":"from sklearn.feature_extraction.text import CountVectorizer\n\n\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(data.verified_reviews)\nsum_words = words.sum(axis=0)\n\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\nplt.style.use('fivethirtyeight')\ncolor = plt.cm.ocean(np.linspace(0, 1, 20))\nfrequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\nplt.title(\"Most Frequently Occuring Words - Top 20\")\nplt.show()","acf5926e":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = 'lightcyan', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n\n#plt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\n#plt.title(\"Vocabulary from Reviews\", fontsize = 20)\nplt.show()","e47b3428":"data['length'] = data['verified_reviews'].apply(len)\n\ndata.groupby('length').describe().sample(10)","10c95e9f":"trace = go.Scatter3d(\n    x = data['length'],\n    y = data['rating'],\n    z = data['variation'],\n    name = 'Amazon Alexa',\n    mode='markers',\n    marker=dict(\n        size=10,\n        color = data['rating'],\n        colorscale = 'Viridis',\n    )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'feedback vs Variation vs Ratings',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    )\n    \n)\nfig = go.Figure(data = df, layout = layout)\niplot(fig)","786f166d":"## Data Visualization","ede43fd8":"## Named Entity Recognition:\n\nA named entity is a \"real-world object\" that's assigned a name \u2013 for example, a person, a country, a product or a book title.\n\nWe also get named entity recognition as part of spacy package. It is inbuilt in the english language model and we can also train our own entities if needed.","1de56ad8":"## **Importing basic packages and modules**","2bd4f7bf":"Here again we are going to analyze the Pie Chart representing the Distribution of feedback for Amazon Alexa which says that around 92% people gave a positive feedback to Amazon Alexa and only 8% people gave negative feedback to Amazon Alexa. This Suggests that Amazon Alexa is a popular product amongst so many people and only few people did not like it for some unforeseeable factors.","09de1c24":"* Text: The original token text.\n* Dep: The syntactic relation connecting child to head.\n* Head text: The original text of the token head.\n* Head POS: The part-of-speech tag of the token head.\n* Children: The immediate syntactic dependents of the token.","eab4947d":"Now we can use the cosine similarity to find the words that are similar to the word \"Love\"","0f0755cd":"By looking at the above pie chart, we can infer that most of the Ratings are good for alexa. Around 72.6% people have given Alexa 5 Star rating, which is very good. 14.4% people have given Alexa a 4 Star Rating, which is also good. that means 72.6+14.4 = 87% people have given alexa good rating.\n\n4.38% people have given alexa an average rating of 3 stars. 3.05% people did not like alexa and chose to give only 2 star ratings to alexa whereas 5.11% people hated alexa and decided to give alexa only 1 Star Rating. This a total of 3.05+5.11 = 8.16% people did not like alexa.","8c4aae46":"Plotting a wordscloud for the Words to see all the words, The Larger the words the larger is the frequency for that word.","67bbbefc":"## Word Similarity:\n\nSpacy has word vector model as well. So we can use the same to find similar words. ","3ad4b77b":"## Dependency Parser\n\nA dependency parser analyzes the grammatical structure of a sentence, establishing relationships between \"head\" words and words which modify those heads \n\nSpacy can be used to create these dependency parsers which can be used in a variety of tasks.","eeceb7a1":"Word level attributes :","70f9d28e":"Just calling the function \"nlp\" on the text column gets us a lot of information. The details are as follows:\n\n* Text - Tokenized word\n* StartIndex - Index at which the word starts in the sentence\n* Lemma - Lemma of the word (we need not do lemmatization separately)\n* IsPunctuation - Whether the given word is a punctuation or not\n* IsSpace - Whether the given word is just a white space or not\n* WordShape - Gives information about the shape of word (If all letters are in upper case, we will get XXXXX, if all in lower case then xxxxx, if the first letter is upper and others lower then Xxxxx and so on)\n* PartOfSpeech - Part of speech of the word\n* POSTag - Tag for part of speech of word","bf682129":"The Above Bar plot represents the most frequnt words in the reviews so that we can get a rough idea about the reviews and what people think of the product.\n\nWe can see that love is the most frequent word in the word suggesting that most of the people absolutely love alexa. Other frequent words that suggest alexa is doing well are amazing, like, great, works etc."}}