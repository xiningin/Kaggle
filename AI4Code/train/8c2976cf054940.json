{"cell_type":{"3d56b92f":"code","3e4bcfc4":"code","421197e2":"code","557d6386":"code","2f851a22":"code","efd25a7d":"code","0ee7eaed":"code","9951b8ea":"code","300148fe":"code","b53605c2":"code","1c1ec027":"code","cd28de56":"code","0d4424a0":"code","d907d70b":"code","8dbe9942":"code","05e8f30b":"markdown","5bcf9006":"markdown","6fa1ba63":"markdown","c2618b86":"markdown","23a2819d":"markdown","9e676962":"markdown","39433833":"markdown","f69a417a":"markdown","8bae044f":"markdown","de1ae5e5":"markdown","472812c4":"markdown","e9aa0282":"markdown","349a61f0":"markdown","211df51a":"markdown","21be8000":"markdown","fd733f3e":"markdown","9dc1bf6e":"markdown","47f1f474":"markdown"},"source":{"3d56b92f":"# Import some libraries\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # graphing\nimport os\nfrom datetime import datetime, timedelta # Used to subtract days from a date\nimport seaborn as sb\n\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n\n# Import environment\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","3e4bcfc4":"# Import training dataset\n(market_train_df, _) = env.get_training_data()","421197e2":"# Heat map with market_train_df\nC_mat = market_train_df.corr()\nfig = plt.figure(figsize=(15,15))\nsb.heatmap(C_mat,vmax=0.5,square=True,annot=True)\nplt.show()","557d6386":"def remove_outlier(df,column_list,lower_percentile,upper_percentile):\n    for i in range(len(column_list)):\n        #upper_bound = np.percentile(df[column_list[i]],upper_percentile)\n        #lower_bound = np.percentile(df[column_list[i]],lower_percentile)\n        df = (df[(df[column_list[i]]<np.percentile(df[column_list[i]],upper_percentile)) & (df[column_list[i]]>np.percentile(df[column_list[i]],lower_percentile))])\n    return df\n#outlier_removal_list = ['returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10','returnsOpenPrevMktres10','returnsOpenNextMktres10']\noutlier_removal_list = [ 'returnsClosePrevRaw1',\n                         'returnsOpenPrevRaw1',\n                         'returnsClosePrevRaw10',\n                         'returnsOpenPrevRaw10',\n                         'returnsOpenNextMktres10']\n\nmarket_data_no_outlier = remove_outlier(market_train_df,outlier_removal_list,2,98)\nprint(\"Number of data decreased from \",len(market_train_df['returnsOpenNextMktres10']),\" to \",len(market_data_no_outlier['returnsOpenNextMktres10']))\n\nC_mat = market_data_no_outlier.corr()\nfig = plt.figure(figsize=(15,15))\nsb.heatmap(C_mat,vmax=0.5,square=True,annot=True)\nplt.show()","2f851a22":"# proces data\ndef process_merged_data(df):\n    # Drop rows with NaN values\n    df = df.dropna()\n    # Let's choose our features#\n    features = ['time','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10','returnsOpenPrevMktres10']\n    x = df[features]\n    y = df[['time','returnsOpenNextMktres10']]\n    return x,y\n\nmarket_data_no_outlier,market_data_no_outlier_target = process_merged_data(market_data_no_outlier)","efd25a7d":"from sklearn.preprocessing import StandardScaler\ndef scale_data(df,features):\n    scaler = StandardScaler()\n    df[features]=scaler.fit_transform(df[features])\n    return df\nfeatures = ['returnsClosePrevRaw1',\n         'returnsOpenPrevRaw1',\n         'returnsClosePrevMktres1',\n         'returnsOpenPrevMktres1',\n         'returnsClosePrevRaw10',\n         'returnsOpenPrevRaw10',\n         'returnsClosePrevMktres10',\n         'returnsOpenPrevMktres10']    \nmarket_data_no_outlier_scaled = scale_data(market_data_no_outlier,features)","0ee7eaed":"# Heat map with merged_data\nfeatures = ['returnsClosePrevRaw1',\n         'returnsOpenPrevRaw1',\n         'returnsClosePrevMktres1',\n         'returnsOpenPrevMktres1',\n         'returnsClosePrevRaw10',\n         'returnsOpenPrevRaw10',\n         'returnsClosePrevMktres10',\n         'returnsOpenPrevMktres10']\ntemp_show = market_data_no_outlier_scaled[features]\ntemp_show['target']=market_data_no_outlier_target['returnsOpenNextMktres10']\nC_mat = temp_show.corr()\nfig = plt.figure(figsize=(15,15))\nsb.heatmap(C_mat,vmax=0.5,square=True,annot=True)\nplt.show()\ndel temp_show","9951b8ea":"# Splits data for training. Takes out 30 days worth of data between training and validation set to prevent data leakage\ndef split_train_test(x,y,test_size):    \n    # Splits data as specified test_size and creates a gap of 30 days between train and test. This helps data leakage so that the model doesn't know the future when training\n    X_train = x[x['time']<(x['time'][int(len(x)*(1-test_size))]-timedelta(days=30))]\n    y_train = y[y['time']<(y['time'][int(len(x)*(1-test_size))]-timedelta(days=30))]\n    X_test = x[x['time']>x['time'][int(len(x)*(1-test_size))]]\n    y_test = y[y['time']>y['time'][int(len(y)*(1-test_size))]]   \n    # Final Features to be used\n    #features = ['returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10','returnsOpenPrevMktres10'] \n    features = ['returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10']\n    \n    X_train1 = X_train[features].copy()\n    y_train1 = y_train['returnsOpenNextMktres10'].copy()\n    train_time = y_train['time']\n    \n    X_test1 = X_test[features].copy()\n    y_test1 = y_test['returnsOpenNextMktres10'].copy()\n    test_time = y_test['time']\n    return X_train1,X_test1,y_train1,y_test1,train_time,test_time\n\nX_train,X_test,y_train,y_test,train_time,test_time = split_train_test(market_data_no_outlier_scaled,market_data_no_outlier_target,0.1)\nprint(\"Test data percentage : {} %\".format(len(X_test)\/(len(X_train)+len(X_test))*100))\n","300148fe":"# Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,BatchNormalization,Input\nfrom keras.optimizers import Adam\n\n# Initialize Model\nmodel = Sequential()\n# Input layer & hidden layer\nmodel.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dense(32,activation='relu'))\n# Output layer\nmodel.add(Dense(1))\n# Compile the architecture and view summary\noptimizer = Adam(lr=0.001)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\nmodel.summary()\n","b53605c2":"from keras.callbacks import ModelCheckpoint,EarlyStopping\n\n# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_acc', verbose = 1, save_best_only = True, mode ='auto')\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto',restore_best_weights=True)\ncallbacks_list = [early_stopping]\n#callbacks_list = [checkpoint,early_stopping]","1c1ec027":"model.fit(x=X_train.values,y=y_train.values, epochs=20,shuffle=True,validation_data=(X_test.values, y_test.values),callbacks=callbacks_list)# validation_split=0.2)#) #, callbacks=callbacks_list)","cd28de56":"data = {'y_real':y_test[:20],'y_pred':(model.predict(X_test.values[:20])).reshape(1,-1)[0]}\npd.DataFrame(data)","0d4424a0":"def make_my_prediction(x):\n    my_pred = (model.predict(x)).reshape(1,-1)[0]\n    my_pred[my_pred>0]=1\n    my_pred[my_pred<0]=-1\n    return my_pred","d907d70b":"# sigma_score function is considered as a custom evaluation metric for xgboost\n# example of how custom evaluation function is incorporated into xgboost's training can be found here : https:\/\/github.com\/dmlc\/xgboost\/blob\/master\/demo\/guide-python\/custom_objective.py\ndef sigma_score(preds,dval,df):\n    \n    # get y_target values\n    labels = dval\n    # call time parameter to be used for grouping, so that we can add x_t values for each day\n    df_time = df\n    \n    #calculate x_t and score as specified by the competition\n    x_t = pd.Series(preds*labels)\n    x_t_sum = x_t.groupby(df_time).sum()    \n    score = (x_t_sum.mean())\/(x_t_sum.std())\n    return 'sigma_score', round(score,5)\n\nmy_pred_test = make_my_prediction(X_test.values)\nprint(\"test : \",sigma_score(my_pred_test,y_test,test_time))\n\nmy_pred_train = make_my_prediction(X_train.values)\nprint(\"train : \",sigma_score(my_pred_train,y_train,train_time))","8dbe9942":"for (market_obs_df, _, predictions_template_df) in env.get_prediction_days():  \n    features = ['returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10']\n    market_obs_df_scaled = scale_data(market_obs_df,features)    \n    x_submission = market_obs_df_scaled[features].copy()\n    # fill in NaN values with mean of rest of the values\n    for i in range(len(features)):\n         x_submission[features[i]]= x_submission[features[i]].fillna(x_submission[features[i]].mean())\n    predictions_template_df['confidenceValue'] = make_my_prediction(x_submission)\n    env.predict(predictions_template_df)\n    del x_submission\nprint('Done!')\n# Write submission file    \nenv.write_submission_file()","05e8f30b":"# Standardize Data","5bcf9006":"# Some 2 cents of mine","6fa1ba63":"|# 10.) For Final Submission","c2618b86":"# Split Data for Training and Validation(Testing) & Choose Final Features","23a2819d":"# Import Environment","9e676962":"I did some feature engineering and correlation analyasis on news data compared to the target 'returnsOpenNextMktres10', but didn't find strong correlations.\n\nNow, I believe that the values from market_train_df already incorporate news.","39433833":"# View Correlation Heatmap Pre-processing","f69a417a":"### Simple ConfidenceValue Creation Function from Prediction Values","8bae044f":"### Sigma Score","de1ae5e5":"### Define Model","472812c4":"# Load Initial Market & News Train Data","e9aa0282":"# View Correlation Heatmap after removing outliers","349a61f0":"# Process Market Data - Drop Rows with NaN Values","211df51a":"### Sanity Check. Real vs Pred values","21be8000":"### Early stopping callback :","fd733f3e":"# Deep Neural Network","9dc1bf6e":"# View Final Correlation Heatmap before Training","47f1f474":"### Train the model"}}