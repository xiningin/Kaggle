{"cell_type":{"a3ea6de3":"code","0b7df192":"code","efd001ed":"code","1e267541":"code","6b534c47":"code","9492e086":"code","7cf37f32":"code","594b10af":"code","fb4a9576":"markdown","fc581791":"markdown","1348949a":"markdown"},"source":{"a3ea6de3":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport spacy\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","0b7df192":"# Load the model to get the vectors\nnlp = spacy.load('en_core_web_lg')\n\nwiki_movie_plots_deduped = pd.read_csv(\"..\/input\/wikipedia-movie-plots\/wiki_movie_plots_deduped.csv\")\nwiki_movie_plots_deduped.head()","efd001ed":"#we are only using plot and genre\nfeatures=['Plot','Genre']\ndf=wiki_movie_plots_deduped[features]\ndf.head()","1e267541":"reviews = df[:100] # [:100] means we take 100 rows and 300 columns\n# We just want the vectors so we can turn off other models in the pipeline\nwith nlp.disable_pipes():\n    vectors = np.array([nlp(wiki_movie_plots_deduped.Plot).vector for idx, wiki_movie_plots_deduped in reviews.iterrows()])\n    \nvectors.shape","6b534c47":"from sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(vectors, wiki_movie_plots_deduped['Genre'][:100], \n                                                    test_size=0.1, random_state=1)\n\n# Create the LinearSVC model\nmodel = LinearSVC(random_state=1, dual=False)\n# Fit the model\nmodel.fit(X_train,y_train)\n\n# Uncomment and run to see model accuracy\nprint(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')\n","9492e086":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n#from xgboost import XGBRegressor\n\n\nmodel2 = RandomForestClassifier(n_estimators=150, max_depth=4, random_state=1)\nmodel_0 = GradientBoostingClassifier(random_state=1)\nmodel3 = DecisionTreeClassifier(max_depth=3, random_state=1)\n#model=SGDClassifier(random_state=1)\n#model=ExtraTreesClassifier(random_state=1)\n#model = XGBRegressor()\n# Define the models\nmodel_1 = RandomForestClassifier(n_estimators=50, random_state=0)\nmodel_2 = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel_3 = RandomForestClassifier(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_4 = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=1)\n\n\n\nmodel_0.fit(X_train,y_train)\n\n\nprint(f'Model test accuracy: {model_0.score(X_test, y_test)*100:.3f}%')","7cf37f32":"model2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model2.score(X_test, y_test)*100:.3f}%')\nmodel3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model3.score(X_test, y_test)*100:.3f}%')","594b10af":"model_1.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_1.score(X_test, y_test)*100:.3f}%')\nmodel_2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_2.score(X_test, y_test)*100:.3f}%')\nmodel_3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_3.score(X_test, y_test)*100:.3f}%')\nmodel_4.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_4.score(X_test, y_test)*100:.3f}%')","fb4a9576":"![image.png](attachment:image.png)","fc581791":"# Disclaimer! This kernel is only for educational purposes and made for fun therefor the content of the kernel should not be taken to seriously.","1348949a":"This is not the best way I think. It might be because a lack of preprocessing. If you have any tips it whould be nice. "}}