{"cell_type":{"e0199579":"code","1c0401ee":"code","cffd00ef":"code","858bf060":"code","fea79941":"code","b1ffdbd6":"code","f21edf5d":"code","ce65d1b9":"code","cae91e36":"code","c9756645":"code","565747a8":"code","78a86bc7":"code","de350f5b":"code","ae2ab806":"code","d8166b09":"markdown","349813cb":"markdown","24529657":"markdown"},"source":{"e0199579":"!pip install pycocotools\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load","1c0401ee":" !pip install 'git+https:\/\/github.com\/PyTorchLightning\/lightning-flash.git#egg=lightning-flash[image]' icevision","cffd00ef":"import os, sys\nimport numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport pycocotools\n#import pycococreatortools\nfrom pycocotools.coco import COCO\nimport skimage.io as io","858bf060":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fea79941":"# the path is\n#..\/input\/ultrasmallcoco-overlapping-chromosomes\n#\nIMAGE_DIR = '\/kaggle\/input\/ultrasmallcoco-overlapping-chromosomes'#'.\/data'\n\n#print(path.ls()) # prints subdirectories\nos.listdir(IMAGE_DIR)\nimage_directory = IMAGE_DIR\nannotation_file = IMAGE_DIR + '\/labels_overlappchromosomes_2021-07-05-09-18-52.json'\nexample_coco = COCO(annotation_file)\nprint(example_coco.info())\ncategories = example_coco.loadCats(example_coco.getCatIds())\ncategory_names = [category['name'] for category in categories]\nprint('Custom COCO categories: \\n{}\\n'.format(' '.join(category_names)))\n\n#category_names = set([category['supercategory'] for category in categories])\n#print('Custom COCO supercategories: \\n{}'.format(' '.join(category_names)))\n\ncategory_ids = example_coco.getCatIds(catNms=['chromosome'])\nimage_ids = example_coco.getImgIds(catIds=category_ids)\nimage_data = example_coco.loadImgs(image_ids[np.random.randint(0, len(image_ids))])[0]\n\nprint('category_ids:', category_ids)\nprint('number of images:',len(image_ids))\nprint('image_data:',image_data)","b1ffdbd6":"# load and display instance annotations\nimage = io.imread(image_directory + '\/'+ image_data['file_name'])\nplt.Figure(figsize=(80.0,80.0))\n#plt.subplot(131)\nplt.imshow(image, cmap=plt.cm.gray ); plt.axis('off')\n#pylab.rcParams['figure.figsize'] = (8.0, 10.0)\nannotation_ids = example_coco.getAnnIds(imgIds=image_data['id'], catIds=category_ids, iscrowd=None)\nannotations = example_coco.loadAnns(annotation_ids)\n\nprint(\"annotations ids:\",annotation_ids)\n\nexample_coco.showAnns(annotations)","f21edf5d":"from flash import Trainer\nfrom flash.image import InstanceSegmentation, InstanceSegmentationData","ce65d1b9":"IMAGE_DIR = '\/kaggle\/input\/ultrasmallcoco-overlapping-chromosomes'\nDEST_FOLDER = '\/kaggle\/input'\nannotation_file = IMAGE_DIR + '\/labels_overlappchromosomes_2021-07-05-09-18-52.json'\nwidth = image_data['width']\nheight = image_data['height']\ndatamodule = InstanceSegmentationData.from_coco(train_folder= IMAGE_DIR, \n                                                train_ann_file= annotation_file,\n                                                predict_folder= DEST_FOLDER,\n                                                transform_kwargs=dict(image_size=(width, height)),\n                                                batch_size=2,)","cae91e36":"datamodule.num_classes","c9756645":"datamodule.labels","565747a8":"model = InstanceSegmentation(num_classes=datamodule.num_classes)","78a86bc7":"trainer = Trainer(fast_dev_run=True)","de350f5b":"trainer.fit(model, datamodule=datamodule)","ae2ab806":"trainer.predict(model, datamodule=datamodule)","d8166b09":"## Acces to small dataset overlapping chromosomes images and their annotations with pycococeator:\n\nThe validity of the annotation file can be tested with waspinator's code mildly adapted:\n","349813cb":"# Now it remains to train an instance segmentation model ...\nLet's try to use [ligthning flash](https:\/\/github.com\/PyTorchLightning\/lightning-flash\/discussions\/1132#discussioncomment-2042223). The requirements are :\n\n* a train folder\n* a json file containing the annotations (segmented chromosomes)\n\nThe code given as example is:\n\n```Python\n\n>>> from flash import Trainer\n>>> from flash.image import InstanceSegmentation, InstanceSegmentationData\n>>> datamodule = InstanceSegmentationData.from_coco(\n...     train_folder=\"train_folder\",\n...     train_ann_file=\"train_annotations.json\",\n...     predict_folder=\"predict_folder\",\n...     transform_kwargs=dict(image_size=(128, 128)),\n...     batch_size=2,\n... )\n>>> datamodule.num_classes\n3\n>>> datamodule.labels\n['background', 'cat', 'dog']\n>>> model = InstanceSegmentation(num_classes=datamodule.num_classes)\n>>> trainer = Trainer(fast_dev_run=True)\n>>> trainer.fit(model, datamodule=datamodule)  \nTraining...\n>>> trainer.predict(model, datamodule=datamodule)  \nPredicting...\n```","24529657":"# Load and display a randomly chosen image from the COCO format overlapping chromosomes dataset:\nThe dataset can be found on github https:\/\/github.com\/jeanpat\/DeepFISH\/tree\/master\/dataset. The COCO version is a very small subset of 125 images. Originaly the groundtruth is greyscaled image. The annotation files was generated with online annotator tool https:\/\/www.makesense.ai\/"}}