{"cell_type":{"33d64592":"code","75f58daa":"code","a350c61d":"code","1225ef76":"code","a0199161":"code","a09f163d":"code","d9e26b11":"code","a084b605":"code","e26107a7":"code","54121ffc":"code","19a606b6":"code","31c8b865":"code","e05ee601":"markdown","872b97e0":"markdown","e56369f2":"markdown","8920d9eb":"markdown","2bd185c6":"markdown","09ba3a62":"markdown","d22d05c0":"markdown"},"source":{"33d64592":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport statistics as s ","75f58daa":"#import dataset and specify X (independent variables) and y (dependent variable)\ndf_icn = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/ICN_numbers.csv')\ndf_fnc = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/fnc.csv')\ndf_loading = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/loading.csv')\ndf_reveal = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/reveal_ID_site2.csv')\ndf_sample = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv')\ndf_train = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv')","a350c61d":"#impute missing training values\nfrom sklearn.impute import KNNImputer\n\n#separate Id column and attributes\ndf_train2 = df_train[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']]\n\n#impute\nimputer = KNNImputer(n_neighbors = 3, weights=\"uniform\")\ndf_train2 = imputer.fit_transform(df_train2)\n\n#convert the 2d array back to the dataframe and add back the Id column\ndf_train2 = pd.DataFrame(df_train2, columns = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'])\ndf_train2 = pd.concat([df_train['Id'], df_train2], axis =1)\n\ndf_train_imputed = df_train2.copy()\n\ndf_train_imputed","1225ef76":"#specify the datasets to be tested in the model, \n\n#option 1\ndf_combine_fnc = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\n\n#option 2\ndf_combine_loading = df_train_imputed.join(df_loading.set_index('Id'), on = 'Id')\n\n#option 3\ndf_combine = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\ndf_combine = df_combine.join(df_loading.set_index('Id'), on = 'Id')\n\n#current testing\ndf = df_combine\nfrom termcolor import colored\ntext = colored('Currently testing ICs and FNCs as predictors',  'red', attrs=['reverse', 'blink'])\nprint(text)","a0199161":"#X for df_combine_fnc\nX = df.iloc[:, 6:]\n\n#specify the y's\ny = df.iloc[:, 0:6]\ny_age = df.iloc[:, 1]\ny_1_1 = df.iloc[:, 2].round(2)\ny_1_2 = df.iloc[:, 3]\ny_2_1 = df.iloc[:, 4]\ny_2_2 = df.iloc[:, 5]","a09f163d":"#less importance to fnc dataframe\nFNC_SCALE = 1\/350\n\nX = df.iloc[:, 6:]\nX.iloc[:,:1378] *= FNC_SCALE\nX","d9e26b11":"#specify features to predict\ntargets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\n\n#weights from TRENDS\nweights = [.3, .175, .175, .175, .175]","a084b605":"#framework to be able to run different models on each feature\nfrom sklearn.model_selection import train_test_split\n\n#select models \nfrom sklearn.svm import SVR\n\n#score holding\nscores_storage = []\n\nfor i in targets:\n    #split the data\n    X_train, X_test, y_train, y_test = train_test_split(X, i, test_size=0.3, random_state=0)\n    \n    #run the model\n    if i.equals(y_age):\n        model = SVR(kernel='linear')\n    elif i.equals(y_1_1):\n        model = SVR(kernel='linear')\n    elif i.equals(y_1_2):\n        model = SVR(kernel='linear')\n    elif i.equals(y_2_1):\n        model = SVR(kernel='linear')\n    elif i.equals(y_2_2):\n        model = SVR(kernel='linear')\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    #get scores of each target\n    unweighted_score = (abs(y_test-y_pred)).sum()\/y_pred.sum()\n    scores_storage.append(unweighted_score)\n\n#multiple scores with weights and sum for final score\ngrand_score = [scores_storage[i] * weights[i] for i in range(len(scores_storage))]\nsum(grand_score)","e26107a7":"#get the ID's of the submission\ndf_sub_id = df_sample.copy()\n\ndf_sub_id['Id'] = df_sub_id['Id'].str.slice(0,5,1)\ndf_sub_id = df_sub_id['Id'].unique()\n\ndf_sub_id = pd.DataFrame({'Id' : df_sub_id , 'hold' : np.zeros(len(df_sub_id))})\ndf_sub_id['Id'] = df_sub_id['Id'].astype(int)","54121ffc":"#create the features dataframe for submission Ids\ndf_sub_combine = df_fnc.join(df_loading.set_index('Id'), on = 'Id')\ndf_sub_combine = df_sub_combine.join(df_sub_id.set_index('Id'), on = 'Id')\ndf_sub_combine = df_sub_combine.dropna()\n\n#create the features only dataframe for submission Ids\ndf_sub_test = df_sub_combine.drop(columns = ['Id', 'hold'])\n\n#less importance to fnc portion\nFNC_SCALE = 1\/350\ndf_sub_test.iloc[:,:1378] *= FNC_SCALE\ndf_sub_test","19a606b6":"#model\ntargets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\ntargets_names = ['y_age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\ntarget_models = [SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear')]\n\nint_index = [0, 1, 2, 3, 4]\n\n#create empty submission dataframe\nsubmission = pd.DataFrame()\n\n#create submission \nfor i in int_index:\n    #for i in targets:\n\n    #train the model on the training set\n    model = target_models[i]\n    model.fit(X, targets[i])\n\n    #predict \n    y_pred = model.predict(df_sub_test)\n    \n    #add predictions by column\n    submission[targets_names[i]] = y_pred\n    \nsubmission","31c8b865":"#turn dataframe prediction values into one long series\npredicted = pd.Series([], dtype = 'float')\nfor i in range(submission.shape[0]):\n    row_values = pd.Series(submission.iloc[i].values)\n    predicted = predicted.append(row_values, ignore_index= True)\n\n#add the series to the submission file\ndf_submission_ensemble = df_sample.copy()\ndf_submission_ensemble['Predicted'] = predicted\ndf_submission_ensemble.to_csv('submission_ensemble_linear.csv', index = False)\ndf_submission_ensemble","e05ee601":"### Scaling the fnc data","872b97e0":"This submission will focus on submission predictions, particularly using different datas, and different models for each feature. Please look at my previous notebook on Domain Explanation and Visualizations below:\n\nhttps:\/\/www.kaggle.com\/dhuang718\/domain-explanation-visualization-modeling\n    ","e56369f2":"### Import the datasets","8920d9eb":"### Ensemble Model - Diferrent Models for Each y's","2bd185c6":"### Submission","09ba3a62":"### Preprocessing","d22d05c0":"### Import Libraries"}}