{"cell_type":{"6b5145dc":"code","aa8f5ddd":"code","59856551":"code","025e3701":"code","9a197d1a":"code","275ac123":"code","1c44c13a":"code","6883e46e":"code","09221bed":"code","07ad164c":"code","9b0216ba":"code","28657a1e":"code","50969dd7":"code","469854e6":"code","7b7879c6":"code","6bafc319":"code","6f34cd05":"code","03598ec4":"code","36a6cec9":"code","4e717749":"code","343386c6":"code","9ac76c5f":"code","15a6411f":"code","cb51a69e":"code","0b45a1c2":"code","cce50e46":"code","b7448a54":"code","197d9c52":"code","eb43b536":"code","d754c49e":"code","86f915ea":"code","539b12f1":"code","bba3ade8":"code","9e908f80":"code","d50194cd":"code","5f479445":"code","b8815178":"code","c8b59bc9":"code","cd077275":"code","c4558790":"code","5b246e7a":"code","f5a5d144":"code","30465ffd":"code","a6ae8400":"code","0856dba9":"code","3f4ca9fd":"code","e69a5c35":"code","9068b8dc":"code","492fc8a5":"code","93b11e6c":"code","56a88e47":"code","68573e46":"code","e14a132d":"code","d047f6c2":"code","6a795de7":"code","16a8ea14":"code","fb3cd75f":"code","9bea3848":"code","d1149828":"code","0ac5e47e":"markdown","c36be94a":"markdown","dacb2d6a":"markdown","d602abf6":"markdown","69626be5":"markdown","b8bcd448":"markdown","4c4075dd":"markdown","2c27f3cc":"markdown","d2e9c845":"markdown","5256dbaa":"markdown","53bdf36f":"markdown","91c62119":"markdown","f56fc945":"markdown","ce7f5dd4":"markdown","7494e5cf":"markdown","c44109b8":"markdown","7fe386e7":"markdown","5642751d":"markdown","9b9e2888":"markdown","d3504a89":"markdown","2b5901ee":"markdown","60bdd86d":"markdown","e9c2baae":"markdown","d86ae675":"markdown","b57de203":"markdown","0b3bf4b3":"markdown","e0f60fd7":"markdown","d192fb56":"markdown","9ac078d6":"markdown","743141f2":"markdown","39f8ade5":"markdown"},"source":{"6b5145dc":"# basic python libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport plotly\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nfrom matplotlib import cm\nfrom collections import OrderedDict\nmatplotlib.rcParams['figure.dpi'] = 200\nmatplotlib.rcParams['figure.figsize'] = (15, 5)\nfrom scipy.stats import norm, shapiro\nfrom scipy import stats\n\n\n# sklearn libraries\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\nfrom sklearn.model_selection import GridSearchCV\n\n# feature selection library\nfrom mlxtend.feature_selection import SequentialFeatureSelector\n\n# model building libraries\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier,VotingClassifier,StackingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import BernoulliNB, GaussianNB\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# warning library\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# setting basic options\npd.set_option('display.max_columns', None)\n%matplotlib inline","aa8f5ddd":"# color maps\ngreens = sns.light_palette(\"green\", as_cmap=True)\npurples = sns.light_palette(\"purple\", as_cmap=True)\nblues = sns.light_palette(\"blue\", as_cmap=True)\n# Define color sets of paintings\nnight_colors = ['rgb(56, 75, 126)', 'rgb(18, 36, 37)', 'rgb(34, 53, 101)',\n                'rgb(36, 55, 57)', 'rgb(6, 4, 4)']\nsunflowers_colors = ['rgb(177, 127, 38)', 'rgb(205, 152, 36)', 'rgb(99, 79, 37)',\n                     'rgb(129, 180, 179)', 'rgb(124, 103, 37)']\nirises_colors = ['rgb(33, 75, 99)', 'rgb(79, 129, 102)', 'rgb(151, 179, 100)',\n                 'rgb(175, 49, 35)', 'rgb(36, 73, 147)']\ncafe_colors =  ['rgb(146, 123, 21)', 'rgb(177, 180, 34)', 'rgb(206, 206, 40)',\n                'rgb(175, 51, 21)', 'rgb(35, 36, 21)']","59856551":"# importing dataset\ndata = pd.read_csv(r'..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv', error_bad_lines = False)\nprint(\"Shape of the data is {}.\".format(data.shape))","025e3701":"data.head().style.background_gradient(cmap=purples)","9a197d1a":"# getting the death event distribution\nlabels = data.DEATH_EVENT.value_counts(normalize = True)*100 \nfig = px.pie(labels, values= 'DEATH_EVENT', names = ['Alive', 'Dead'], title='Target Distribution across whole dataset')\nfig.show()","275ac123":"# Stratified Shuffle Train Test Split\nsss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15 ,random_state = 42) #2-fold cross validation\nfor train_index, test_index in sss.split(data.iloc[:, :-1], data.iloc[:,-1]):\n    print(\"Intersection of train index and test index:\", list(set(train_index) & set(test_index)))\n    train = data.iloc[train_index, :]\n    test = data.iloc[test_index, :]\n    print(\"Shape of train data is {}\".format(train.shape))\n    print(\"Shape of test data is {}\".format(test.shape))","1c44c13a":"# getting the death event distribution in train set\ntrain_labels = train.DEATH_EVENT.value_counts(normalize = True)*100 \ntest_labels = test.DEATH_EVENT.value_counts(normalize = True)*100 \n\n# Create subplots, using 'domain' type for pie charts\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=['Train Target', 'Test Target'])\nlabels = [\"Alive\", \"Dead\"]\n\n# Define pie charts\nfig.add_trace(go.Pie(labels=labels, values=train_labels, name=\"Train target\", scalegroup='one',\n                     marker_colors=night_colors), 1, 1)\nfig.add_trace(go.Pie(labels=labels, values=test_labels, name='Test Target', scalegroup='one',\n                     marker_colors=cafe_colors), 1, 2)\n\n# Tune layout and hover info\nfig.update_traces(hoverinfo='label+percent+name', textinfo='percent+label')\nfig.update(layout_title_text='Distribution of target values across train and test set respectively',\n          layout_showlegend=False)\n\nfig = go.Figure(fig)\nfig.show()","6883e46e":"# checking for null values in train set\ntrain.isnull().sum()","09221bed":"# checking for null values in test set\ntest.isnull().sum()","07ad164c":"# distribution of column values\nf,ax = plt.subplots(6,2,figsize=(15,25))\nsns.distplot(train['age'].dropna(),ax=ax[0,0],kde=True,color='b')\nsns.distplot(train['serum_creatinine'].dropna(),ax=ax[0,1],kde=True,color='g')\nsns.distplot(train['creatinine_phosphokinase'].dropna(),ax=ax[1,0],kde=True,color='r')\nsns.distplot(train['platelets'].dropna(),ax=ax[1,1],kde=True,color='m')\nsns.distplot(train['ejection_fraction'].dropna(),ax=ax[2,0],kde=True,color='burlywood')\nsns.distplot(train['serum_sodium'].dropna(),ax=ax[2,1],kde=True,color='chartreuse')\nsns.countplot('anaemia',data=train,ax=ax[3,0], palette='husl')\nsns.countplot('diabetes',data=train,ax=ax[3,1], palette='RdBu')\nsns.countplot('high_blood_pressure',data=train,ax=ax[4,0], palette=sns.color_palette(\"muted\"))\nsns.countplot('sex',data=train,ax=ax[4,1], palette=sns.color_palette(\"ch:2.5,-.2,dark=.3\"))\nsns.countplot('smoking',data=train,ax=ax[5,0], palette=sns.color_palette(\"RdBu\", n_colors=7))\nsns.distplot(train['time'],kde = True,ax=ax[5,1], color = '#0FFF7C')","9b0216ba":"# describing age\ntrain.age.describe().to_frame().style.background_gradient(cmap=greens)","28657a1e":"sum_Age = train[[\"age\", \"DEATH_EVENT\"]].groupby(['age'],as_index=False).sum()\navg_Age = train[[\"age\", \"DEATH_EVENT\"]].groupby(['age'],as_index=False).mean()\n\n# plotting the dataframes\nfig, (axis1,axis2,axis3) = plt.subplots(3,1,figsize=(20,10))\nsns.barplot(x='age', y='DEATH_EVENT', data=sum_Age, ax = axis1)\nsns.barplot(x='age', y='DEATH_EVENT', data=avg_Age, ax = axis2)\nsns.pointplot(x = 'age', y = 'DEATH_EVENT', data=train, ax = axis3)","50969dd7":"# bin the age according to the quantiles\ntrain['age_bin'] = pd.qcut(train['age'], q=4, labels = [0,1,2,3])\ntest['age_bin'] = pd.qcut(test['age'], q=4, labels = [0,1,2,3])\nprint(\"Shape of train is: \", train.shape)\nprint(\"Shape of test is: \", test.shape)","469854e6":"# getting the distribution\nage_dist = train.groupby(['age_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0).reset_index()\nage_dist['per_death'] = age_dist[1]\/(age_dist[0]+age_dist[1])*100\nage_dist.plot(kind = 'bar')","7b7879c6":"# distribution of anaemia with age\nanaemia_grp = train.groupby(['age_bin', 'anaemia'])['DEATH_EVENT'].mean().unstack().reset_index()\nanaemia_grp.plot(kind = 'bar')","6bafc319":"# distribution of anamenia and DEATH_EVENT\nanaemia_grp = train.groupby(['anaemia', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack()\nanaemia_grp.plot(kind='bar')","6f34cd05":"# getting the distribution\ndist = train.groupby(['anaemia','diabetes', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","03598ec4":"# getting the distribution\ndist = train.groupby(['anaemia','age_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","36a6cec9":"# description of creatinine_phosphokinase\ntrain.creatinine_phosphokinase.describe().to_frame().style.background_gradient(cmap='viridis')","4e717749":"# making a column for having normal range\ntrain['normal_creatinine_phosphokinase'] = train['creatinine_phosphokinase'].apply(lambda x: 1 if (x > 10 and x <=120) else 0)\ntest['normal_creatinine_phosphokinase'] = test['creatinine_phosphokinase'].apply(lambda x: 1 if (x > 10 and x <=120) else 0)","343386c6":"# quantile binning\ntrain['creatinine_phosphokinase_bin'] = pd.qcut(train['creatinine_phosphokinase'], q=4, labels = [0,1,2,3])\ntest['creatinine_phosphokinase_bin'] = pd.qcut(test['creatinine_phosphokinase'], q=4, labels = [0,1,2,3])","9ac76c5f":"# getting the distribution\ndist = train.groupby(['creatinine_phosphokinase_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0).reset_index()\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist.plot(kind = 'bar')","15a6411f":"# getting the distribution\ndist = train.groupby(['normal_creatinine_phosphokinase', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0).reset_index()\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist","cb51a69e":"# getting the distribution\ndist = train.groupby(['creatinine_phosphokinase_bin','smoking', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist.plot(kind='bar', stacked = True)","0b45a1c2":"# getting the distribution\ndist = train.groupby(['normal_creatinine_phosphokinase','smoking', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')","cce50e46":"# getting the distribution\ndist = train.groupby(['normal_creatinine_phosphokinase','anaemia', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","b7448a54":"# getting the distribution\ndist = train.groupby(['normal_creatinine_phosphokinase','age_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","197d9c52":"# getting the distribution\ndist = train.groupby(['normal_creatinine_phosphokinase','diabetes', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","eb43b536":"# getting the distribution\ndist = train.groupby(['diabetes', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","d754c49e":"# getting the distribution\ndist = train.groupby(['diabetes','smoking', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","86f915ea":"# getting the distribution\ndist = train.groupby(['diabetes', 'sex'])['sex'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","539b12f1":"# getting the distribution\ndist = train.groupby(['diabetes','sex', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","bba3ade8":"dist = train.groupby(['diabetes','high_blood_pressure', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","9e908f80":"# getting the distribution\ndist = train.groupby(['diabetes', 'smoking','anaemia', 'normal_creatinine_phosphokinase','high_blood_pressure', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","d50194cd":"# describe\ntrain.ejection_fraction.describe().to_frame().style.background_gradient(cmap='PuBuGn')","5f479445":"# binning\ntrain['EF_bin'] = pd.cut(train['ejection_fraction'], bins=[0,36,40,55,81,101], labels = [0,1,2,3,4])\ntest['EF_bin'] = pd.cut(test['ejection_fraction'], bins=[0,36,40,55,81,101], labels = [0,1,2,3,4])","b8815178":"# getting the distribution\ndist = train.groupby(['EF_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","c8b59bc9":"# getting the distribution\ndist = train.groupby(['diabetes','smoking','EF_bin', 'DEATH_EVENT'])['DEATH_EVENT'].count().unstack().fillna(0)\ndist['per_death'] = dist[1]\/(dist[0]+dist[1])*100\ndist[['per_death']].plot(kind='bar')\ndist[[0,1]].plot(kind='bar', stacked=True)","cd077275":"# serum_creatinine\ntrain.serum_creatinine.describe().to_frame().style.background_gradient(cmap='twilight_shifted')","c4558790":"# serum_sodium\ntrain.serum_sodium.describe().to_frame().style.background_gradient(cmap='twilight')","5b246e7a":"train.columns.tolist()","f5a5d144":"# parallel plot for continuous variable\nfig = px.parallel_coordinates(train, color=\"DEATH_EVENT\",\n                              dimensions=['age',\n 'creatinine_phosphokinase',\n 'ejection_fraction',\n 'platelets',\n 'serum_creatinine',\n 'serum_sodium',\n                                          'DEATH_EVENT'\n                                         ],\n                              color_continuous_scale=px.colors.diverging.Tealrose,\n                              color_continuous_midpoint=2)\nfig.show()","30465ffd":"sns.heatmap(train.corr())","a6ae8400":"# getting the train columns\ntrain.columns.tolist()","0856dba9":"continuous_variables = [\n 'age',\n 'creatinine_phosphokinase',\n 'ejection_fraction',\n 'platelets',\n 'serum_creatinine',\n 'serum_sodium'\n]\n\ntarget = ['DEATH_EVENT']\n\ncategorical_variables = [\n 'anaemia',\n 'diabetes',\n 'high_blood_pressure',\n 'sex',\n 'smoking',\n 'time',\n 'age_bin',\n 'normal_creatinine_phosphokinase',\n 'creatinine_phosphokinase_bin',\n 'EF_bin'\n]","3f4ca9fd":"# scaling the continuous variables\nautoscaler = PowerTransformer()\ntrain[continuous_variables] = autoscaler.fit_transform(train[continuous_variables])\ntest[continuous_variables] = autoscaler.transform(test[continuous_variables])","e69a5c35":"# visualising the final transformed continuous variables.\n# Group data together\nhist_data = [train.age, train.creatinine_phosphokinase, train.ejection_fraction, \n             train.platelets, train.serum_creatinine, train.serum_sodium]\n\ngroup_labels = ['Age', 'Creatinine Phosphokinase', 'Ejection Fraction', 'Platelets', 'Serum Creatinine', \n                'Serum Sodium']\n\ncolors = ['#FA93A0', '#19FFFA', '#51F04B',\n                '#F06318', '#A018F0', '#3222E3']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, bin_size=.4, colors = colors, show_hist=False)\nfig.show()","9068b8dc":"# remove highly correlated features\n# Create correlation matrix\ncorr_matrix = train[continuous_variables].corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.70\nto_drop = [column for column in upper.columns if any(upper[column] > 0.70)]\n\n# print the columns to be dropped off\nto_drop","492fc8a5":"# train datatypes\ntrain.dtypes","93b11e6c":"# changing to int type\ntrain['age_bin'] = train['age_bin'].astype(int)\ntrain['creatinine_phosphokinase_bin'] = train['creatinine_phosphokinase_bin'].astype(int)\ntrain['EF_bin'] = train['EF_bin'].astype(int)\n\ntest['age_bin'] = test['age_bin'].astype(int)\ntest['creatinine_phosphokinase_bin'] = test['creatinine_phosphokinase_bin'].astype(int)\ntest['EF_bin'] = test['EF_bin'].astype(int)","56a88e47":"features = [\n 'age',\n 'creatinine_phosphokinase',\n 'ejection_fraction',\n 'platelets',\n 'serum_creatinine',\n 'serum_sodium',\n 'anaemia',\n 'diabetes',\n 'high_blood_pressure',\n 'sex',\n 'smoking',\n 'time',\n 'age_bin',\n 'normal_creatinine_phosphokinase',\n 'creatinine_phosphokinase_bin',\n 'EF_bin'\n]","68573e46":"# Choosing best base model for trainset.\nensembles = []\nensembles.append(('GBM', GradientBoostingClassifier(n_estimators = 300)))\nensembles.append(('RF', RandomForestClassifier(n_estimators = 300)))\nensembles.append(('ET', ExtraTreesClassifier()))\nensembles.append(('XGB', XGBClassifier(n_estimators = 300, n_jobs=-1)))\nensembles.append(('LR', LogisticRegressionCV(cv = 5)))\nensembles.append(('GNB', GaussianNB()))\nensembles.append(('BNB', BernoulliNB()))\nensembles.append(('KNN', KNeighborsClassifier(n_neighbors = 3)))\nensembles.append(('DT', DecisionTreeClassifier()))\nensembles.append(('LGMB', LGBMClassifier(n_estimators = 300, class_weight = 'balanced', n_jobs = -1)))\n#ensembles.append(('CBC', CatBoostClassifier(cat_features = categorical_variables, class_weights = 'SqrtBalanced')))\n\ntrain_set = train[features]\ntest_set = test[features]\n\nresults = []\nnames = []\nfor name, model in ensembles:\n    kfold = StratifiedKFold(n_splits=3, shuffle = True, random_state=42)\n    cv_results = cross_val_score(model, train_set, train[target],\n                                 cv=kfold, scoring='roc_auc')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n    model = model.fit(train_set, train[target])\n    # validating the training results on validation sets.\n    predicted_result = model.predict(test_set)\n    print(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\n    print(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")","e14a132d":"# lets lokk at how catboost classifier is doing on this small dataset.\nmodel = CatBoostClassifier(cat_features = categorical_variables,\n                          loss_function = 'Logloss',\n                           custom_metric = ['AUC', 'F1'],\n                           eval_metric = 'AUC',\n                           bootstrap_type = 'Bernoulli',\n                           use_best_model = True,\n                           leaf_estimation_method = 'Newton',\n                           auto_class_weights = 'SqrtBalanced',\n                           boosting_type = 'Ordered'\n                          )\nmodel = model.fit(train_set, train[target], eval_set = (test_set, test[target]))\n# validating the training results on validation sets.\npredicted_result = model.predict(test_set)\nprint(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\nprint(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")","d047f6c2":"# lets try voting classifier by ensembling some moderately and best performing models.\n# voting ensembler soft and hard for dataset\nensembles = []\nensembles.append(('RF', RandomForestClassifier(n_estimators = 300)))\nensembles.append(('XGB', XGBClassifier(n_estimators = 300, n_jobs=-1)))\nensembles.append(('LGMB', LGBMClassifier(n_estimators = 300, class_weight = 'balanced', n_jobs = -1)))\nensembles.append(('LR', LogisticRegressionCV(cv = 3)))\n\n# Voting classifier soft\nvc_soft = VotingClassifier(estimators=ensembles, voting='soft', flatten_transform=True)\nvc_soft.fit(train_set, train[target])\n# validating the training results on validation sets.\nprint(\"###### Voting Classifier - Soft #######\")\npredicted_result = model.predict(test_set)\nprint(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\nprint(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")\n\n# Voting classifier hard\nprint(\"###### Voting Classifier - Hard #######\")\nvc_hard = VotingClassifier(estimators=ensembles, voting='hard')\nvc_hard.fit(train_set, train[target])\npredicted_result = model.predict(test_set)\nprint(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\nprint(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")","6a795de7":"# forward selections\n# getting the features from forward selection methods\nprint(\"**************************************************\")\n# initialising the SequentialFeatureSelector\nkfold = StratifiedKFold(n_splits=3, shuffle = True, random_state=42)\nsfs = SequentialFeatureSelector(LGBMClassifier(n_estimators = 300, class_weight = 'balanced', n_jobs = -1), \n           k_features=5, \n           forward=True, \n           floating=False,\n           scoring='roc_auc',\n           cv=kfold)\n\n# fit the object to the training data.\nsfs.fit(train_set, train[target])\n\n# print the selected features.\nselected_features = train_set.columns[list(sfs.k_feature_idx_)]\nprint(selected_features)\n\n# print the final prediction score.\nprint(sfs.k_score_)\nprint(\"**************************************************\")\nsfs.subsets_","16a8ea14":"filtered = [\n   'ejection_fraction',\n   'serum_creatinine',\n   'sex',\n   'time',\n   'creatinine_phosphokinase_bin'\n]","fb3cd75f":"# trying embedded methods also\n# Embedded Feature Selection usinf RF classifier.\n\nmodel = LGBMClassifier(n_estimators = 300, class_weight = 'balanced', n_jobs = -1)\n\n# fit the model to start training.\nmodel.fit(train_set[filtered], train[target])\n\n# get the importance of the resulting features.\nimportances = model.feature_importances_\n\n# create a data frame for visualization.\nfinal_df = pd.DataFrame({\"Features\": train_set[filtered].columns, \"Importances\":importances})\nfinal_df.set_index('Importances')\n\n# sort in ascending order to better visualization.\nfinal_df = final_df.sort_values('Importances')\n\n# plot the feature importances in bars.\nfinal_df.plot.bar(x = 'Features') \n\n# predict the result\npredicted_result = model.predict(test_set[filtered])\nprint(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\nprint(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")","9bea3848":"# training the hypertuned model\nmodel = LGBMClassifier(boosting_type = 'gbdt',\n                       class_weight = 'balanced',\n                       learning_rate = 0.1,\n                       n_estimators = 300,\n                       n_jobs = -1,\n                       num_leaves = 31,\n                       objective = 'binary',\n                       reg_alpha = 0,\n                       reg_lambda = 0)\n\nmodel = model.fit(train_set[filtered], train[target])\n# predict the result\npredicted_result = model.predict(test_set[filtered])\nprint(\"Confusion Matrix: \", confusion_matrix(test[target], predicted_result), \"\\n\")\nprint(\"Classification Report: \\n\", classification_report(test[target], predicted_result), \"\\n\")","d1149828":"test['predicted_result'] = predicted_result\ntest['predicted_result'].head().to_frame().style.background_gradient(cmap='OrRd_r')","0ac5e47e":"__serum_creatinine__","c36be94a":"# <font color='#EB365D'> HEART FAILURE PREDICTION <\/font>\n***","dacb2d6a":"__diabetes__","d602abf6":"***\n## <font color = 'blue'>Exploratory Data Analysis<\/font>\n***         ","69626be5":"<font color='blue'>Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.\nHeart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.\n\nMost cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies.\n\nPeople with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.<\/font>\n\n_______\n\n<font color = 'rgb(33, 75, 99)'><b>Author of this Notebook:<\/b><\/font>\n<b>Rudra Narayan Mishra<\/b>","b8bcd448":"__creatinine_phosphokinase__","4c4075dd":"***\n## <font color='#52254E'>Feature Selection, Model Building and Hyper Parameters Tuning<\/font>\n***","2c27f3cc":"In here, we can see a pure set, where the person has diabetes, is smoking and falls under the EF_bin of 3 which is normal range, has death percentage as 100%. But this is not helpful as the number of persons is very less so we cannot say that this is a pattern.","d2e9c845":"<font color = 'green'>There is no null value present in test set.<\/font>","5256dbaa":"__AGE__","53bdf36f":"***\n## <font color = \"#FF1DBB\">Train Test Split<\/font>\n***","91c62119":"<font color = '#FF16A7'><h2>Columns Used In This Dataset: <\/h2><\/font>\n<ol>\n  <li><font color = '#FF173D'><b>Age:<\/b><\/font>age of the patient<\/li>\n  <li><font color = '#FF173D'><b>anaemia:<\/b><\/font>Decrease of red blood cells or hemoglobin (boolean)<\/li>\n  <li><font color = '#FF173D'><b>creatinine_phosphokinase:<\/b><\/font>Level of the CPK enzyme in the blood (mcg\/L)<\/li>\n  <li><font color = '#FF173D'><b>diabetes:<\/b><\/font>If the patient has diabetes (boolean)<\/li>\n  <li><font color = '#FF173D'><b>ejection_fraction:<\/b><\/font>Percentage of blood leaving the heart at each contraction (percentage)<\/li>\n  <li><font color = '#FF173D'><b>high_blood_pressure:<\/b><\/font>If the patient has hypertension (boolean)<\/li>\n  <li><font color = '#FF173D'><b>platelets:<\/b><\/font>Platelets in the blood (kiloplatelets\/mL)<\/li>\n  <li><font color = '#FF173D'><b>serum_creatinine:<\/b><\/font>Level of serum creatinine in the blood (mg\/dL)<\/li>\n  <li><font color = '#FF173D'><b>serum_sodium:<\/b><\/font>Level of serum sodium in the blood (mEq\/L)<\/li>\n  <li><font color = '#FF173D'><b>sex:<\/b><\/font>Woman or man (binary)<\/li>\n  <li><font color = '#FF173D'><b>smoking:<\/b><\/font>If the patient smokes or not (boolean)<\/li>\n  <li><font color = '#FF173D'><b>time:<\/b><\/font>Follow-up period (days)<\/li>\n  <li><font color = '#FF173D'><b>DEATH_EVENT:<\/b><\/font>If the patient deceased during the follow-up period (boolean)<\/li>\n<\/ol>\n    ","f56fc945":"<font color = 'green'><b>This is the final predictions of the dataset. I reached an ROC AUC score of 0.91 and accuracy of 87%!!!<\/b><\/font>\n***\nHope you enjoyed it!!!\n***\n# THE END\n***","ce7f5dd4":"***\n## <font color = \"#992CF6\">Basic Analysis<\/font>\n***","7494e5cf":"<font color = 'green'>There is no null value present in train set.<\/font>","c44109b8":"Now we can get a fairly normal distributions of continuous variables, we can now move onto the feature selection phase.","7fe386e7":"***\n## <font color = \"#B339A2\"> Importing Libraries <\/font>\n***","5642751d":"Now, we can see that the StratifiedShuffleSplit() did a great help in splitting the train and test set according to our needs.","9b9e2888":"***\n## <font color = \"#BD2CF6\"> Importing Dataset<\/font>\n***","d3504a89":"It is not doing great, though it reduces overfitting but the overall score is very bad.","2b5901ee":"***\n## <font color = '#A018F0'> Feature Engineering <\/font>\n***","60bdd86d":"__MULTIVARIATE ANALYSIS__","e9c2baae":"Again, we can see that the voting classifier is also not doing great.","d86ae675":"After getting some insights from the internet about this particular column regarding heart failure, I found that: \n\nEjection Fraction (EF) 55% to 70%\n\nPumping Ability of the Heart: Normal.\nLevel of Heart Failure\/Effect on Pumping: Heart function may be normal or you may have heart failure with preserved EF (HF-pEF).\nEjection Fraction (EF) 40% to 54%\n\nPumping Ability of the Heart: Slightly below normal.\nLevel of Heart Failure\/Effect on Pumping: Less blood is available so less blood is ejected from the ventricles. There is a lower-than-normal amount of oxygen-rich blood available to the rest of the body. You may not have symptoms.\nEjection Fraction (EF) 35% to 39%\n\nPumping Ability of the Heart: Moderately below normal.\nLevel of Heart Failure\/Effect on Pumping: Mild heart failure with reduced EF (HF-rEF).\nEjection Fraction (EF) Less than 35%\n\nPumping Ability of the Heart: Severely below normal.\nLevel of Heart Failure\/Effect on Pumping: Moderate-to-severe HF-rEF. Severe HF-rEF increases risk of life-threatening heartbeats and cardiac dyssynchrony\/desynchronization (right and left ventricles do not pump in unison).\n\nThis will help in binning purposes.","b57de203":"Total CPK normal values: 10 to 120 micrograms per liter (mcg\/L)","0b3bf4b3":"There is a very little pattern in this scenario so I will bin the age column according to quantile range.","e0f60fd7":"The data is slightly imbalanced. So, we will split the dataset using StratifiedShuffleSplit(), so as to have the same level of imbalanced ratio in both train and test set.","d192fb56":"__ANAEMIA__","9ac078d6":"__ejection_fraction__","743141f2":"<font color='green'><b>Here, LGBM is giving an auc score of 0.904 which is great and the accuracy is 82%!!<\/b><\/font>","39f8ade5":"<font color = 'green'><b>LGBMClassifier is performing quite well so I will pick that as my base model.<\/b><\/font>"}}