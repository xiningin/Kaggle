{"cell_type":{"d8a7c6ca":"code","a8942eaf":"code","8eb165b6":"code","1bc1c8c1":"code","b447e3cc":"code","a16a188d":"code","2d8ae6ae":"code","321a8941":"code","c1aa0e29":"code","dda12733":"code","b8b3036d":"code","9d20a196":"markdown","c78041e6":"markdown","9a37dd4a":"markdown","52bb9a3f":"markdown","b5dd6657":"markdown","0b3bfac1":"markdown"},"source":{"d8a7c6ca":"# Import packages\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\n%matplotlib inline","a8942eaf":"# Import dataset and show all keys\nfrom sklearn.datasets import load_breast_cancer\ncancerdata = load_breast_cancer()\ncancerdata.keys()","8eb165b6":"# Show the description of the dataset\nprint(cancerdata['DESCR'])","1bc1c8c1":"# Create dataframe\ndf = pd.DataFrame(np.c_[cancerdata['data'],cancerdata['target']], columns = np.append(cancerdata['feature_names'],['target']))\ndf.head()","b447e3cc":"# Plot features against eachother to see if there is separation between cancerous and benign cells\n\ndistinctfeature = cancerdata['feature_names'][:10] # Only use first 10 features as these are mean.\nsns.pairplot(df,hue='target',vars=distinctfeature)","a16a188d":"# Heatmap to show correlation\nplt.figure(figsize=(15,6))\nsns.heatmap(df.corr())","2d8ae6ae":"# Separate class variable from all others. \nX = df.drop(['target'],axis=1)\ny = df['target']","321a8941":"# Split data into train and test datasets (70% train and 30% test).\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)","c1aa0e29":"# Scale features to standardise them.\nsc = StandardScaler()\nX_trainScaled = sc.fit_transform(X_train)\nX_testScaled = sc.transform(X_test)","dda12733":"# Train model using scaled train dataset. \nclf_svc = SVC()\nclf_svc.fit(X_trainScaled,y_train)\nscaled_ypred = clf_svc.predict(X_testScaled)\nprint(classification_report(y_test,scaled_ypred))\nprint(confusion_matrix(y_test,scaled_ypred))","b8b3036d":"# Visualise confusion matrix \ncm1 = confusion_matrix(y_test,scaled_ypred)\n\ndef confusion_matrix_1(CM):\n    fig, ax = plot_confusion_matrix(conf_mat=CM)\n    plt.title(\"Confusion Matrix\")\n    plt.ylabel(\"Actual\")\n    plt.xlabel(\"Predicted\")\n    plt.show()\n\n    print(\"The accuracy is \"+str((CM[1,1]+CM[0,0])\/(CM[0,0] + CM[0,1]+CM[1,0] + CM[1,1])*100) + \" %\")\nconfusion_matrix_1(cm1)\n\nplt.show()","9d20a196":"This gives an idea of how correlated features are to eachother. High correlation between 2 features is not good as this means both features are giving the same information and we can do without one of them.  ","c78041e6":"The description tells us there are 10 distinct features which are shown here: \n\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 \/ area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry\n        - fractal dimension (\"coastline approximation\" - 1)\n\nEach of these features have 3 attributes making up a total of 30 attributes that are used to detect cancer. \n\nThere are 569 cells in the dataset. ","9a37dd4a":"Most features are separable. ","52bb9a3f":"**Objective :**\n\nIdentify whether the sample tumor cell taken for test is cancerous or benign. Normally, the procedure is for the doctor to look at the sample of blood under a microscope, and decide whether the cell is cancerous or not based on the features of each cell. Here, we will use a machine learning model called Support Vector Machine (SVM) for classification. ","b5dd6657":"The SVM has performed well with getting a very high number of cases correct. One thing to be vary of is the cost of misclassification. If a cell is predicted as canceruous when it actually isn't, the patient will be upset but its better to be safe than sorry. If a cell is predicted to be benign when its actually cancerous, that has a much higher cost compared to the alternative. \n\nIn this case, there were 2 cells where the model predicted benign when the cell was actually cancerous. A possible solution to this is to change the sensitivity of the model which will give more false alarms (cancerous when actually benign) but will reduce the number of cancerous cells missed. ","0b3bfac1":"Now we have a table that shows each cell as a row and all attributes in columns"}}