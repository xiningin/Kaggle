{"cell_type":{"fe088654":"code","d386b375":"code","dc382d44":"code","f93676d9":"code","b1f8b6f7":"code","835cc026":"code","1d57e71d":"code","6060f3f1":"code","ce25e4ce":"code","0840497e":"code","b13f7536":"code","8c3fa1fb":"code","c2c1ace5":"code","0cc6e23b":"code","cb25fb0f":"code","79cf207e":"code","10b24edf":"code","474b9a75":"code","55a59f31":"code","65538f6d":"code","d766dee1":"code","e0d88e44":"code","8e927f29":"code","43552584":"code","d60965e3":"code","72bed8bd":"code","cde384ac":"code","68076428":"code","a5a8351e":"code","d3c45083":"code","406029b4":"code","19246531":"code","81675142":"code","cd7fe78d":"code","c1893169":"code","79365443":"code","14b1eebb":"code","15222f53":"code","01940819":"code","366ffaab":"code","643345d4":"code","410ace7f":"code","7e1d2353":"code","03e8a4c2":"code","6896d5d2":"code","e9a2d7b6":"markdown","015db2bc":"markdown","9bb2f59d":"markdown","0bf456ac":"markdown","5808153c":"markdown","f90f6cf4":"markdown","7f871a8a":"markdown","55b1d162":"markdown","66700237":"markdown","acb45fec":"markdown","279216b4":"markdown","fb3ebc09":"markdown"},"source":{"fe088654":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None","d386b375":"import os\nos.listdir(\"..\/input\/zillow-prize-1\")","dc382d44":"train_df = pd.read_csv('..\/input\/zillow-prize-1\/train_2017.csv', parse_dates=[\"transactiondate\"])\ntrain_df.head()","f93676d9":"train_df.shape","b1f8b6f7":"train_df.logerror.values","835cc026":"plt.figure(figsize=(8, 6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index')\nplt.ylabel('logerror')\nplt.show()","1d57e71d":"upper_limit = np.percentile(train_df.logerror.values, 99)\nlower_limit = np.percentile(train_df.logerror.values, 1)\nupper_limit, lower_limit","6060f3f1":"train_df.loc[train_df['logerror'] > upper_limit, 'logerror'] = upper_limit\ntrain_df.loc[train_df['logerror'] < lower_limit, 'logerror'] = lower_limit","ce25e4ce":"plt.figure(figsize=(8, 6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index')\nplt.ylabel('logerror')\nplt.show()","0840497e":"plt.figure(figsize=(12, 8))\nsns.distplot(train_df.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()","b13f7536":"train_df['transaction_month'] = train_df['transactiondate'].dt.month\n\nindex_of_months = train_df['transaction_month'].value_counts().index\nunique_months_vals = train_df['transaction_month'].value_counts().values\n\nplt.figure(figsize=(12, 6))\nsns.barplot(index_of_months, unique_months_vals, alpha=0.8, color=color[2])\nplt.xlabel('Months of transaction')\nplt.ylabel('Number of Transactions')\nplt.show()","8c3fa1fb":"temp_df = train_df['parcelid'].value_counts().reset_index()\ntemp_df['parcelid'].value_counts()","c2c1ace5":"prop_df = pd.read_csv(\"..\/input\/zillow-prize-1\/properties_2017.csv\")\nprop_df.shape","0cc6e23b":"prop_df.head()","cb25fb0f":"prop_df.isnull().sum().reset_index()","79cf207e":"missing_df = prop_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\n\nmissing_df = missing_df.ix[missing_df['missing_count'] > 0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nfig, ax = plt.subplots(figsize=(12, 18))\nrects = ax.barh(ind, missing_df.missing_count.values)\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","10b24edf":"plt.figure(figsize=(12, 12))\nsns.jointplot(x = prop_df.latitude.values, y = prop_df.longitude.values, size=10)\nplt.ylabel('Longitude', fontsize=12)\nplt.xlabel('Latitude', fontsize=12)\nplt.show()","474b9a75":"train_df = pd.merge(train_df, prop_df, on='parcelid', how='left')\ntrain_df.head()","55a59f31":"pd.options.display.max_rows = 65\n\ndtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df","65538f6d":"dtype_df.groupby(\"Column Type\").count().reset_index()","d766dee1":"train_df.mean(axis=0)","e0d88e44":"train_df = train_df.fillna(0)\n\nx_cols = [col for col in train_df.columns if col not in ['logerror'] if train_df[col].dtype == 'float64']\n\nlabels = []\nvalues = []\n\n# check corr of each col wrt 'logerror' col\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df[col].values, train_df.logerror.values)[0,1])\n\ncorr_df = pd.DataFrame({'col_labels': labels, 'corr_values': values})\ncorr_df = corr_df.sort_values(by='corr_values')\n\nind = np.arange(len(labels))\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='r')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","8e927f29":"corr_zero_cols = ['assessmentyear', 'storytypeid', 'pooltypeid2', 'pooltypeid7', 'pooltypeid10', 'poolcnt', 'decktypeid', 'buildingclasstypeid']\n\nfor col in corr_zero_cols:\n    print(col, train_df[col].nunique())","43552584":"corr_df.loc[(corr_df['corr_values'] > 0.02) | (corr_df['corr_values'] < -0.01), ('col_labels', 'corr_values')]","d60965e3":"corr_df_sel = corr_df.ix[(corr_df['corr_values']>0.02) | (corr_df['corr_values'] < -0.01)]\ncorr_df_sel","72bed8bd":"cols_to_use = corr_df_sel.col_labels.tolist()\n\ntemp_df = train_df[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\n\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(corrmat, vmax=1., square=True)\nplt.title(\"Important variables correlation map\", fontsize=15)\nplt.show()","cde384ac":"cols_to_use","68076428":"col = 'finishedsquarefeet12'\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\n# train_df[col].ix[train_df[col] > upper_limit] = upper_limit\n# train_df[col].ix[train_df[col] < lower_limit] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[2])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Finished Square Feet 12', fontsize=12)\nplt.title(\"Finished square feet 12 Vs Log error\", fontsize=15)\nplt.show()","a5a8351e":"col = \"calculatedfinishedsquarefeet\"\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[4])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Calculated finished square feet', fontsize=12)\nplt.title(\"Calculated finished square feet Vs Log error\", fontsize=15)\nplt.show()","d3c45083":"train_df['bathroomcnt'].value_counts()","406029b4":"col = \"bathroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(x = col, data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bathroom', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bathroom count\", fontsize=15)\nplt.show()","19246531":"plt.figure(figsize=(12,8))\nsns.boxplot(x = col, y='logerror', data=train_df)\nplt.ylabel('Log error', fontsize=12)\nplt.xlabel('Bathroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"How log error changes with bathroom count?\", fontsize=15)\nplt.show()","81675142":"col = \"bedroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(col, data = train_df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bedroom count\", fontsize=15)\nplt.show()","cd7fe78d":"train_df.loc[train_df['bedroomcnt'] > 7, 'bedroomcnt'] = 7","c1893169":"col = \"bedroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(col, data = train_df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bedroom count\", fontsize=15)\nplt.show()","79365443":"plt.figure(figsize=(12,8))\nsns.violinplot(x='bedroomcnt', y='logerror', data=train_df)\nplt.xlabel('Bedroom count', fontsize=12)\nplt.ylabel('Log Error', fontsize=12)\nplt.show()","14b1eebb":"col = \"taxamount\"\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[6])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Tax Amt', fontsize=12)\nplt.title(\"Tax Amount Vs Log error\", fontsize=15)\nplt.show()","15222f53":"train_df.columns","01940819":"train_y = train_df['logerror'].values\ncat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\n\ntrain_df = train_df.drop(['parcelid', 'logerror', 'transactiondate', 'transaction_month'] + cat_cols, axis=1)\n\nfeat_names = train_df.columns","366ffaab":"from sklearn import ensemble\n\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_df, train_y)","643345d4":"model.estimators_","410ace7f":"model.feature_importances_","7e1d2353":"importances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","03e8a4c2":"import xgboost as xgb\n\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1,\n    'seed' : 0\n}\n\ndtrain = xgb.DMatrix(train_df, train_y, feature_names=train_df.columns.values)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)","6896d5d2":"fig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","e9a2d7b6":"There are few variables at the top of this graph without any correlation values.","015db2bc":"Identify and replace the outliers","9bb2f59d":"Let us take the variables with high correlation values ","0bf456ac":"The important variables themselves are very highly correlated.","5808153c":"Now visualizing each cols against 'logerror' col","f90f6cf4":"Normal distribution obtained.","7f871a8a":"Seems the range of logerror narrows down with increase in finished square feet 12 variable. Probably larger houses are easy to predict","55b1d162":"Here as well the distribution is very similar to the previous one. No wonder the correlation between the two variables are also high.","66700237":"Replace the outlier vals with upper and lower limit vals","acb45fec":"Now to find corr among cols which are highly correlated to 'logerror' col","279216b4":"Almost all are float variables with few object (categorical) variables","fb3ebc09":"After counting appearance of each parcel id.\nIt is seen that most parcelid appear only once in the dataset"}}