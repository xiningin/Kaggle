{"cell_type":{"8b0e3b99":"code","7d864562":"code","2645210a":"code","b4600449":"code","5eb18f86":"code","86854b88":"code","12c692c3":"code","87af1fb9":"code","710691a4":"code","6abba5c5":"code","4a1be514":"code","43e340c5":"code","1c2ea0dd":"code","e93ff282":"code","d5d1dc21":"code","9be7ee15":"code","39f84de2":"code","aa8f7db0":"markdown","b5ebc63a":"markdown","d2b9f378":"markdown","d6aba912":"markdown","038e34bb":"markdown","ea2846a6":"markdown","0ee8876e":"markdown","8d58692c":"markdown","34319a5c":"markdown","1b537feb":"markdown","1b1a09b0":"markdown","4e1f0499":"markdown","a357320e":"markdown","5ea97f71":"markdown","f3c569b3":"markdown"},"source":{"8b0e3b99":"import os\nimport gc\nimport random\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, auc\nfrom sklearn.utils import class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.metrics import categorical_accuracy\nimport tensorflow_addons as tfa\n\nfrom tensorflow.keras.callbacks import (\n    ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rc('xtick', labelsize=8)\nplt.rc('ytick', labelsize=8)\nplt.rcParams[\"axes.grid\"] = False\nfrom matplotlib.ticker import MaxNLocator\n%config InlineBackend.figure_format = 'svg'\n# PANDAS SETTINGS\npd.options.display.max_rows = 5\npd.options.display.max_colwidth = 100","7d864562":"# MODEL PARAMETERS\nIMG_SIZE = 224\nCHANNELS = 1\nNUM_CLASS = 2\nEPOCHS = 60\nBATCH_SIZE = 10\nVAL_SIZE = 0.2 # VAL\/(VAL+TRAIN)\nCLASS_WEIGHTS = True\nOUTPUT_BIAS = -1.10\nOPTIMIZER = tf.optimizers.Adam(lr=1e-4)  # tf.keras.optimizers.SGD(lr=5e-5, momentum=0.9, decay=1e-3\/EPOCHS)\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# FIX THE SEEDS FOR REPRODUCABILITY\nSEED = 38\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\n# DATA DIRECTORIES\nBASE_DIR = '..\/input\/labeled-chest-xray-images\/chest_xray'","2645210a":"def df_generator(pattern='\/train\/*\/*', num_class=NUM_CLASS):\n    df = tf.io.gfile.glob(BASE_DIR + pattern)\n    df = pd.DataFrame(df, columns=['Path']).sample(frac=1, random_state=SEED)\n\n    if num_class == 2:\n        df['Label'] = df['Path'].map(lambda x: x.split('\/')[-2])\n    elif num_class == 3:\n        df['Label'] = df['Path'].map(lambda x: x.split('\/')[-1].split('0')[0])\n    else:\n        raise ValueError('DEFINE NUM_CLASS!')\n    return df\n\n\ntrain_df = df_generator('\/train\/*\/*')\ntest_df = df_generator('\/test\/*\/*')\n\n# READ UNTIL THE END OF THE NOTEBOOK, UNCOMMENT THE FOLLOWING LINES, AND RERUN IT TO PEFORME THE EXPERIMENT MENTIONED.\n# all_df = pd.concat([train_df, test_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n# X_train, X_test, y_train, y_test = train_test_split(all_df.Path, all_df.Label, test_size=0.1)\n# train_df = X_train.to_frame().join(y_train.to_frame()).reset_index(drop=True)\n# test_df = X_test.to_frame().join(y_test.to_frame()).reset_index(drop=True)\n# del all_df, X_train, y_train, y_test\n# gc.collect()\n\n\ndef train_val_split(df=train_df):\n    X_train, X_val, y_train, y_val = train_test_split(df.Path,\n                                                      df.Label,\n                                                      test_size=VAL_SIZE,\n                                                      stratify=df['Label'])\n    train = X_train.to_frame().join(y_train.to_frame()).reset_index(drop=True)\n    val = X_val.to_frame().join(y_val.to_frame()).reset_index(drop=True)\n\n    return train, val\n\ntrain_df, val_df = train_val_split(train_df)\ntrain_size = len(train_df)\nval_size = len(val_df)\ntest_size = len(test_df)\ntotal_sample = val_size + train_size\n\nprint('Sample Size')\nprint('----'*3)\nprint(f'Train: %d (%.1f %%)' % (train_size, train_size\/total_sample*100))\nprint(f'Validation: %d (%.1f %%)' % (val_size, val_size\/total_sample*100))\nprint(f'Test: %d' % (test_size))","b4600449":"def plot_distributions(train_df, val_df, test_df):\n    fig, axs = plt.subplots(1, 3, figsize=(10, 3.5))\n\n    cmap = plt.get_cmap(\"tab20c\")\n    colors = cmap(np.arange(3) * 4)\n\n    train_df['Label'].value_counts(normalize=True).rename_axis('Type').to_frame('Counts'\n    ).plot(kind='pie', y='Counts', autopct='%1.1f%%',\n           title='Train', legend=None,\n           colors=colors, wedgeprops=dict(width=0.99, edgecolor='w'), ax=axs[0])\n    axs[0].set_ylabel('')\n    val_df['Label'].value_counts(normalize=True).rename_axis('Type').to_frame('Counts'\n    ).plot(kind='pie', y='Counts', autopct='%1.1f%%',\n           title='Validation', legend=None,\n           colors=colors, wedgeprops=dict(width=0.99, edgecolor='w'), ax=axs[1])\n    axs[1].set_ylabel('')\n    test_df['Label'].value_counts(normalize=True).rename_axis('Type').to_frame('Counts'\n    ).plot(kind='pie', y='Counts', autopct='%1.1f%%',\n           title='Test', legend=None,\n           colors=colors, wedgeprops=dict(width=0.99, edgecolor='w'), ax=axs[2])\n    axs[2].set_ylabel('')\n    fig.suptitle('Label Distribution')\n\nplot_distributions(train_df, val_df, test_df)","5eb18f86":"le = LabelEncoder()\nle.fit(train_df.Label)","86854b88":"class_weights = train_df['Label'].value_counts().sum() \/ train_df['Label'].value_counts() \/ 2.\nprint(class_weights.to_frame('Weights'))\nclass_weights.index = le.transform(class_weights.index)\nclass_weights = class_weights.to_dict()","12c692c3":"# Convert string Labels into integer Labels\ndef label_encode(*args):\n    for arg in args:\n        arg['Label'] = le.transform(arg.Label)\n\nlabel_encode(train_df, val_df, test_df)","87af1fb9":"def decode_img(img):\n    img = tf.image.decode_jpeg(img, channels=CHANNELS)  # Convert compressed string into uint8\n    img = tf.image.convert_image_dtype(img, tf.float32)  # Normalize the data\n    return tf.image.resize(img, (IMG_SIZE, IMG_SIZE)) # Resize the image to the desired size.\n\ndef process_path_label(file_path, label):\n    img = tf.io.read_file(file_path) # load the raw data from the file as a string\n    img = decode_img(img)\n    return img, label\n\ndef image_generator(df):\n    ds = tf.data.Dataset.from_tensor_slices((df.Path, tf.one_hot(df.Label, depth=NUM_CLASS)))\n    ds = ds.map(process_path_label, num_parallel_calls=AUTOTUNE)\n    return ds","710691a4":"def show_random_images():\n    fig, axs = plt.subplots(3, 4, subplot_kw={'xticks': [], 'yticks': []}, figsize=(6, 5))\n    samples = list(image_generator(train_df).shuffle(250).batch(12).take(1))\n    for i in range(12):\n        axs[i \/\/ 4, i % 4].imshow(samples[0][0][i].numpy().reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n        axs[i \/\/ 4, i % 4].set_title(le.inverse_transform(np.argmax([samples[0][1][i].numpy()], axis=-1))[0])\n    plt.tight_layout(w_pad=0.01, h_pad=1)\n    plt.show()\n\nshow_random_images()","6abba5c5":"for i in image_generator(train_df).batch(1).take(1):\n    print(i)","4a1be514":"def conv2d_block(inputs, filters, kernel_size, maxpool, batchnorm=True):\n    x = tfa.layers.WeightNormalization(tf.keras.layers.Conv2D(filters, kernel_size, kernel_initializer='he_uniform', use_bias=False))(inputs)\n    if batchnorm:\n        x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.nn.swish(x)\n    return tf.keras.layers.MaxPooling2D(maxpool)(x)\n\ndef dense_block(inputs, units, batchnorm=True):\n    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, use_bias=False))(inputs)\n    if batchnorm:\n        x = tf.keras.layers.BatchNormalization()(x)\n    return tf.nn.swish(x)\n\n# MODEL\ndef MyNet(input_shape, num_class, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    \n    inputs = tf.keras.Input(shape=input_shape)\n    x = conv2d_block(inputs, 8, 3, 2)\n    x = conv2d_block(x, 16, 3, 2)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = dense_block(x, 200, batchnorm=False)\n    x = tf.keras.layers.Dropout(0.6)(x)\n    x = dense_block(x, 64, batchnorm=False)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    outputs = tf.keras.layers.Dense(NUM_CLASS, activation='softmax', bias_initializer=output_bias)(x)\n    \n    return tf.keras.models.Model(inputs=inputs, outputs=outputs)","43e340c5":"model = MyNet((IMG_SIZE, IMG_SIZE, 1), NUM_CLASS, output_bias=OUTPUT_BIAS)\n\nMETRICS = [tf.keras.metrics.AUC(), 'accuracy']\n\ncallback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\nmodel.compile(\n    optimizer=tfa.optimizers.Lookahead(OPTIMIZER, sync_period=10),\n    loss='categorical_crossentropy',\n    metrics=METRICS\n)\n\ntrain_ds = image_generator(train_df).cache().shuffle(50).batch(BATCH_SIZE).prefetch(2)\nval_ds = image_generator(val_df).cache().batch(val_size)\ntest_ds = image_generator(test_df).batch(test_size)\n\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    class_weight=class_weights,\n    callbacks=[callback_es, reduce_lr_loss]\n)","1c2ea0dd":"def plot_model_performance(history=history):\n    fig, axs = plt.subplots(1, 3, figsize=(10,4))\n    fig.suptitle('Fit Statistics', fontsize=16, y=1.1)\n    axs[0].plot(history.epoch, history.history['loss'], label='Train')\n    axs[0].plot(history.epoch, history.history['val_loss'], label='Validation')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_ylabel('Loss')\n    axs[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n    axs[0].legend()\n\n    axs[1].plot(history.epoch, history.history['accuracy'], label='Train')\n    axs[1].plot(history.epoch, history.history['val_accuracy'], label='Validation')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_ylabel('Accuracy')\n    axs[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n    axs[1].legend()\n    \n    axs[2].plot(history.epoch, history.history['auc'], label='Train')\n    axs[2].plot(history.epoch, history.history['val_auc'], label='Validation')\n    axs[2].set_xlabel('Epoch')\n    axs[2].set_ylabel('AUC')\n    axs[2].xaxis.set_major_locator(MaxNLocator(integer=True))\n    axs[2].legend()\n    fig.tight_layout()\n    plt.show()","e93ff282":"plot_model_performance(history)","d5d1dc21":"# Confusion Matrix\ndef extract_trues_preds(val_ds, test_ds):\n    valid_pred = model.predict(val_ds)\n    valid_pred = np.argmax(valid_pred, axis=-1)\n    valid_true = np.array([i for i in val_ds.map(lambda x, y: y)]).reshape(-1, NUM_CLASS)\n    valid_true = np.argmax(valid_true, axis=-1)\n    \n    test_pred = model.predict(test_ds)\n    test_pred = np.argmax(test_pred, axis=-1)\n    test_true = np.array([i for i in test_ds.map(lambda x, y: y)]).reshape(-1, NUM_CLASS)\n    test_true = np.argmax(test_true, axis=-1)\n    return valid_pred, valid_true, test_pred, test_true\n\nvalid_pred, valid_true, test_pred, test_true = extract_trues_preds(val_ds, test_ds)","9be7ee15":"def plot_confusion_matrix(valid_pred, valid_true, test_pred, test_true):\n    fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n    cm_valid = confusion_matrix(valid_pred, valid_true)  # Order of the arrays is important. First True, then Predicted.\n    sns.heatmap(cm_valid, annot=True, cmap='binary', cbar=False, fmt='d', ax=ax[0])\n    # for t in ax[0].texts: t.set_text(t.get_text() + \" %\")\n    ax[0].set_xlabel('True Labels')\n    ax[0].set_ylabel('Predicted Labels')\n    ax[0].set_title('Validation')\n    ax[0].set_xticklabels(le.classes_, va='center')\n    ax[0].set_yticklabels(le.classes_, va='center')\n    \n    cm_test = confusion_matrix(test_pred, test_true)  # Order of the arrays is important. First True, then Predicted.\n    sns.heatmap(cm_test, annot=True, cmap='binary', cbar=False, fmt='d', ax=ax[1])\n    # for t in ax[1].texts: t.set_text(t.get_text() + \" %\")\n    ax[1].set_xlabel('True Labels')\n    ax[1].set_ylabel('Predicted Labels')\n    ax[1].set_title('Test')\n    ax[1].set_xticklabels(le.classes_, va='center')\n    ax[1].set_yticklabels(le.classes_, va='center')\n    \n    fig.suptitle('Confusion Matrix', fontsize=16, y=1.1)\n    \n    fig.tight_layout(w_pad=5.0)\n    plt.show()\nplot_confusion_matrix(valid_pred, valid_true, test_pred, test_true)","39f84de2":"# Precision: It's about prediction\n# Recall: It's about true values.\nprint('Classification Report - Validation')\nprint(classification_report(valid_true, valid_pred, target_names=le.classes_))\nprint('')\nprint('Classification Report - Test')\nprint(classification_report(test_true, test_pred, target_names=le.classes_))","aa8f7db0":"All plots are looking great! To be honest, it took me a dozen of trainings to get them.\n\nHow do we know these results are acceptable?\n1. A learning model yields a training loss with a decreasing trend. Yes, our training loss has done so.\n\n2. The train and validation losses are ideally expected to be on top of each other or at least as close as possible. This ensures that our model is well generalizing for the distribution of the validation data. Yes, our training and validation losses seem to have done that too.\n\n3. Our other performance metrics from train and validation sets (e.g. accuracy and AUC) are expected to be as high as possible and similiar to each other. Our accuracies are 98% and 97% for the train and validation sets, respectively. Not so bad.\n\nLet's our model's performance on the test model. This is kind of exciting!\n\nWhat else can be done?\n\nOur model performs excellent on the validation set. However, this validation set is much smaller than the train set. One thing that could be done is to create a different validation set use the same model configuration and check whether we get the same metric results.","b5ebc63a":"### 4. Model Performance\n\nNow that we have trained our model, we can inspect our model's performance. During the training we saved the loss, AUC, and accuracy parameters for each epoch for both our train and validation sets. Their evolutions are shown in the figures below.","d2b9f378":"The above code calculated the weights with the formulas below:\n\n$w_{PNEUMONIA} = \\frac{1}{2}\\frac{N_{PNEUMONIA}}{N_{TOTAL}}$\n\n$w_{NORMAL} = \\frac{1}{2}\\frac{N_{NORMAL}}{N_{TOTAL}}$,\n\nwhere $N_{PNEUMONIA}$ is the total count of PNEUMONIA images in the training set, $N_{PNEUMONIA}$ is the total count of NORMAL images in the training set, and $N_{TOTAL}$ is the total count of all images in the training set. We will apply these weights to the loss function and 1\/2 factors will keep the loss function's normalization unaltered.","d6aba912":"### Training\n\nWe will use categorical cross entropy as our loss function because the labels are one hot encoded by our input pipeline. The optimization will be done with the stochastic gradient descent. Its parameters are as configured at the beginning of the notebook.\n\nWe will use an early stopping mechanism not to waste time on overfitting or underfitting. The training will stop if the validation loss does not improve in 5 consecutive epochs. We will also restore the weights from the best validation loss epoch.\n\nLet's run the code below to train our model.\n","038e34bb":"Our train set has an imbalanced label distribution - the PNEUMONIA class is 3 times more than the NORMAL class. The validation distribution follows the same distribution. That's because we split the train data in a stratified manner to ensure that the validation sample represents the train data properly. The test data also has an imbalanced label distribution but with a slightly different ratio.\n\nThe class imbalance has to be addressed in the model training. Otherwise, the model will likely learn the majority class better than the minority class; and hence, the minority class will likely be more missclassified than the majority class.\n\nThe easiest solution to address the imbalance problem is to assign some weights to the classes and use them in the loss function. Let's calculate the weights and encode our string labels into integers with the following code:","ea2846a6":"The images above confirm that the input pipeline is doing its job: majority of the images are from pneumonia class as expected.\n\nJust in case let's also check if the images are also normalized.","0ee8876e":"### 3. Model\n\nThe medical chest X-ray images are single channel images. We will use the custom model below instead of doing transfer learning as the popular pretrained models are trained on 3 channel images.","8d58692c":"## Computer Vision: Pneumonia Detection with Convolutional Networks\n\nThis notebook demonstrates how to build a pneumonia detector with the Tensorflow deep learning framework.\n\nThe steps include constructing an input data pipeline, making and training a model, and interpreting the model performance.","34319a5c":"### 4. TEST RESULT","1b537feb":"Since we have constructed the data pipeline, we can also inspect the images visually and see whether the data is generated in the desired format.","1b1a09b0":"### 1. Data\nThe X-ray images were split into train and test sets. While it is good to have the train and test sets split beforehand, training a neural network also requires a validation set to track the learning process.\n\nTo make a validation set, we will split the training set with the standard train:validation ratio of 0.8:0.2. The code below will do this and print the sample sizes for all of the three datasets.","4e1f0499":"The ratio of the train:validation split seems OK. It is also relieving to see that we have enough data to train a neural network. Now, let's check the label distribution in all three of our datasets with the code below.","a357320e":"Well well well... While our model did an excellent job on the validation set, it didn't do well on the test set as can be seen from all of the metrics.\n\nWhat can be the reason?\n\nIt seems like the train and test sets come from different distributions. To confirm this idea, I mixed the train and test sets, created a new train-validation-test sets, and trained the same model with same parameters. As a result of this exercise, the metrics turned out to be similar for all datasets with very excellent results. To see the results uncomment the piece of code in the 3 code block from top and run the notebook.","5ea97f71":"### 2. Input Pipeline\n\nThe image_generator function defined below will take the paths and labels of the images from a pandas dataframe, and do all of the reading, normalization, resizing processes.","f3c569b3":"It seems like the images are normalized. So we are good to go to the next step."}}