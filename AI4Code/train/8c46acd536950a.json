{"cell_type":{"cad5c2f2":"code","d56556e1":"code","4b11c2c1":"code","bb801bfa":"code","351a7281":"code","36cdc7a8":"code","78d743c5":"code","10a29fba":"code","6fa6d4c0":"code","213a784b":"code","47a696bb":"code","45115c72":"code","0edf515a":"code","0dba6387":"code","b69facf1":"code","3a3ebdb0":"code","fcbad4ec":"code","b17f3f17":"code","5e7f2bff":"code","d8a872d5":"code","dcb9921f":"code","c875923b":"code","426a108e":"code","f34fb9f9":"code","8761038a":"code","72456a59":"code","9483015f":"code","0af2074b":"code","251231f8":"code","46c578c2":"code","f78cd565":"code","4d754806":"code","64e84a20":"code","d6966046":"code","eec45c29":"code","2cc5850b":"markdown","258ae64d":"markdown","a5fd0e57":"markdown","73f6d55b":"markdown","3fd543d5":"markdown","a61cd1d7":"markdown","83f5964d":"markdown","5d4816b0":"markdown","df6ffc10":"markdown","7aa5ce68":"markdown","7ee52ae6":"markdown","cae92cb8":"markdown","f4f4ddba":"markdown","8f5d6f40":"markdown","4db22ed5":"markdown","a1529af7":"markdown","43129e16":"markdown","5b7d44af":"markdown","11e391d5":"markdown","a9bc6c0e":"markdown","99de4b48":"markdown","8c7a6e5b":"markdown","0360f7be":"markdown","027f20e0":"markdown","5402fcd9":"markdown","73e5d6b8":"markdown"},"source":{"cad5c2f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d56556e1":"df_mx = pd.read_csv('..\/input\/youtube-new\/MXvideos.csv', engine='python', encoding = 'latin1')\ndf_mx.info()","4b11c2c1":"#Change Category Title as str\ndf_mx['category_id'] = df_mx['category_id'].astype('str')\ndf_mx.info()","bb801bfa":"df_mx.head()","351a7281":"import json\n# leo el json\nwith open('..\/input\/youtube-new\/MX_category_id.json') as f:\n    data = json.load(f)","36cdc7a8":"cats = {}\nfor item in data['items']:\n    cats[item['id']] = item['snippet']['title']","78d743c5":"df_cat_mx = pd.DataFrame().from_dict(cats, orient='index')\ndf_cat_mx.head()","10a29fba":"df_cat_mx = df_cat_mx.rename_axis('category_id').reset_index()","6fa6d4c0":"df_cat_mx.rename(columns ={0:'categoria'},inplace=True)\ndf_cat_mx.info()\ndf_cat_mx","213a784b":"df_cat_mx.loc[31] = ['29','Otros']\ndf_cat_mx","47a696bb":"df = pd.merge(df_mx, df_cat_mx, on = 'category_id', how = 'left')\ndf.info()","45115c72":"df.isnull().sum()","0edf515a":"# Dataset final \n\ndf = df.drop(columns = ['trending_date','category_id','publish_time','tags','thumbnail_link','video_error_or_removed','description'])\ndf.head()","0dba6387":"df.describe().round(1)","b69facf1":"df.describe(include = 'object')","3a3ebdb0":"df.groupby(\n    'title')['title'].count().sort_values(ascending = False).head(10)","fcbad4ec":"df = df.sort_values('views', ascending = False).drop_duplicates(subset = 'title')","b17f3f17":"import plotly.express as px","5e7f2bff":"px.histogram(df,x= 'views')","d8a872d5":"v_1q  = df[df['views'] <= np.quantile(df['views'],0.25)]\npx.histogram(v_1q,x= 'views',nbins=90)","dcb9921f":"v_2q  = df[(df['views'] > np.quantile(df['views'],0.25)) & (df['views'] <= np.quantile(df['views'],0.50))]\npx.histogram(v_2q,x= 'views',nbins=90)","c875923b":"v_3q  = df[(df['views'] > np.quantile(df['views'],0.50)) & (df['views'] <= np.quantile(df['views'],0.75))]\npx.histogram(v_3q,x= 'views',nbins=90)","426a108e":"v_4q  = df[(df['views'] > np.quantile(df['views'],0.75)) & (df['views'] <= np.quantile(df['views'],0.99))]\npx.histogram(v_4q,x= 'views',nbins=90)","f34fb9f9":"v_5q  = df[(df['views'] > np.quantile(df['views'],0.90)) & (df['views'] <= np.quantile(df['views'],0.99))]\npx.histogram(v_5q,x = 'views',nbins=90)","8761038a":"px.box(v_4q, y = 'views', x ='categoria' ) ","72456a59":"df_a = v_4q[v_4q['categoria'].isin(\n    ['Autos & Vehicles','Science & Technology','Education','Pets & Animals','Travel & Events'])]","9483015f":"df_a['p_likes'] = round((df_a['likes']\/df_a['views'])*100,2)\ndf_a['p_dislikes'] = round((df_a['dislikes']\/df_a['views'])*100,2)\ndf_a['p_comment'] = round((df_a['comment_count']\/df_a['views'])*100,2)","0af2074b":"df.groupby('categoria')['categoria'].agg('count').sort_values(ascending = False)","251231f8":"df_a.groupby(\n    'channel_title')['channel_title'].count().sort_values(ascending = False).head(10)","46c578c2":"df_a.groupby(\n    'categoria')[['views','p_likes','p_dislikes','p_comment']].mean().round(1).sort_values('views', ascending = False) ","f78cd565":"px.histogram(df_a, x = 'p_comment',color = 'categoria')\npx.histogram(df_a, x = 'p_dislikes',color = 'categoria')\npx.histogram(df_a, x = 'p_likes',color = 'categoria')","4d754806":"px.histogram(df_a, x = 'p_likes',facet_col = 'categoria',facet_col_wrap=1).update_yaxes(matches=None)","64e84a20":"px.scatter(df_a,'views','p_likes', facet_col=\"categoria\",facet_col_wrap=5).update_yaxes(matches=None).update_xaxes(matches=None)","d6966046":"px.scatter(df_a,'views','p_likes', color = 'categoria')","eec45c29":"df_a[df_a.ratings_disabled == True]","2cc5850b":"* Ploting only the last 25% quantile","258ae64d":"* Ploting only the second 25% quantile","a5fd0e57":"* The last 25% quartile is still big, so i decide to use only the 10% bigger","73f6d55b":"# Merge in order to have name of categories","3fd543d5":"\n## Top Videos\n\n### Videos by Category\n* Categories that i choosed before have less videos but big views impact","a61cd1d7":"### Deleting duplicates, sorted by numb of views (most viewed = lastdate)","83f5964d":"##### Videos by Channel - top 10","5d4816b0":"* parto las categorias y el index que quiero, estos tienen forma de diccionario","df6ffc10":"#### 1. Numerical features \n* 4 variables numericas\n* 40k + registros\n* On views 50%Q lower than mean \n* Very high desvest","7aa5ce68":"### Detectando si hay null en el dataset\n* Solo hay null en algunas descripciones, que en este analisis no los voy a usar","7ee52ae6":"### 3. Outlider\n","cae92cb8":"* Transformo el el diccionario a DF para oder unirlo con el df original","f4f4ddba":"### 2. Categorical features\n* video_id is unique\n* Many titles are duplicate\n* Most view channel Cracks\n* Most view category Entertainment","8f5d6f40":"* Ploting only the third 25% quantile","4db22ed5":"# Starting EDA","a1529af7":"* The histogram show us that views are right-skewed","43129e16":"# Upload CSV with only MX info","5b7d44af":"## Generate final dataset only whith features that i need","11e391d5":"## Cargo el json con los datos de categoria de MX","a9bc6c0e":"#### Inserto una celda con category_id 29 para poder hacer elmerge y no queda vacio","99de4b48":"* Ploting only the first 25% quantile","8c7a6e5b":"### Boxplot only for the 10%\n* There are some categories that doesnt have extremaly outliders, maybe those videos have the same behaviour\n* Im going to analyze the behaviour of ** Autos & Vehicles, Science & Tecnology, Education, Pets & animals and Travel & Events**\n* i'm going to analyze MUSIC out of the group that i choosed\n* Im excluing Otros because i dont know the  real category of that\n","0360f7be":"#### Videos by title\n* Al parecer hay videos que tienen el mismo nombre pero diferente ID","027f20e0":"# Creating new df for categories that i choose\n* Add %likes, %dislike and %comment in order to have better viz","5402fcd9":"# Analyzing only categories selected\n\n* Means of principal variables by category\n* comment's percentage have the same behaviour in all categories\n* dislike's percentage have the same behaviour in all categories\n* categories with more views have less like's percentage","73e5d6b8":"* Cambio los nombres de las columnas para hacer mas facil el merge"}}