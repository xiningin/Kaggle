{"cell_type":{"0a71836e":"code","f5e5b0db":"code","336a2fb9":"code","99e5617b":"code","02940178":"code","ea1f7ed2":"code","bcc6b4e5":"code","b2e8b8c2":"code","8a81ecdb":"code","2a698299":"code","6b0c579b":"code","6a0f01bc":"code","83500e43":"code","c4b893a7":"code","59c683a4":"code","0de2da7f":"code","daa65677":"code","6a5793c5":"code","11da3776":"code","38513db9":"code","7a9e1186":"code","82720db5":"code","ea09a395":"code","58299661":"code","6c224e00":"code","623aedc8":"code","92546408":"code","97a5ebd0":"code","dce93894":"code","8e6a089f":"code","ba695bd3":"code","47a748c4":"code","e5f8e836":"code","035834fc":"code","edc11b8c":"code","bfd68977":"markdown","a082a8e8":"markdown","d35c0ac8":"markdown"},"source":{"0a71836e":"# DATA_PATH = '..\/input\/'\nDATA_PATH = '..\/input\/shopee-product-matching\/'\n","f5e5b0db":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import normalize\nimport math\nimport torch\nfrom torch.optim.lr_scheduler import StepLR\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\n\n# \u5b9a\u4e49\u8bc4\u4ef7\u51fd\u6570\uff1a\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\uff0cF1\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]))\n        if len(row[col])==0:\n            p = 0\n        else:\n            p = n\/len(row[col])\n        if len(row.target) == 0:\n            r = 0\n        else:\n            r = n\/len(row.target)\n        return p, r, 2*n\/(len(row.target)+len(row[col]))\n    return f1score","336a2fb9":"from contextlib import contextmanager\nimport os, sys, time, psutil\n\n# \u8ba1\u7b97\u5f53\u524d\u4ee3\u7801\u6240\u4f7f\u7528\u7684\u5185\u5b58\u548c\u65f6\u95f4\n@contextmanager\ndef timer_memory(name):\n    t0 = time.time()\n    yield\n    print(f'Memory: {(psutil.Process(os.getpid()).memory_info().rss\/2**30):.02f}GB')\n    print(f'{name} done in {time.time()-t0:.0f}s')","99e5617b":"COMPUTE_CV = True\ndevice = 'cuda'\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\nwith timer_memory('Reading CSV'):\n    if COMPUTE_CV:\n        train = pd.read_csv(DATA_PATH + 'train.csv')\n        train['image'] = DATA_PATH + 'train_images\/' + train['image']\n        tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n        train['target'] = train.label_group.map(tmp)\n    else:\n        train = pd.read_csv(DATA_PATH + 'test.csv')\n        train['image'] = DATA_PATH + 'test_images\/' + train['image']\n    \nprint('train shape is', train.shape )\ntrain.head()","02940178":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","ea1f7ed2":"len(train.label_group.unique())","bcc6b4e5":"mappingdic={}\nmappingback={}\nfor a in range(len(train.label_group.unique())):\n    mappingdic[train.label_group.unique()[a]]=a\n    mappingback[a]=train.label_group.unique()[a]\n\n","b2e8b8c2":"train['map_label'] = train.label_group.map(mappingdic)","8a81ecdb":"train.head()","2a698299":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n","6b0c579b":"train['oof_hash'] = train.image_phash.map(tmp)","6a0f01bc":"if COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","83500e43":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass SHOPEEDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.image)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n                \n        img = img.astype(np.float32)\n       # print('i am the img',img.shape)\n        img = img.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img).float()\n        else:\n            return torch.tensor(img).float(), torch.tensor(row.map_label).float()\n\nclass ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s = 10, m = 0.5):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n        print('i am self weight',self.weight.shape)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        print('i am arc output',outputs.shape)\n        return outputs\n    \n    \nclass SHOPEEDenseNet(nn.Module):\n\n    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=True):\n        super(SHOPEEDenseNet, self).__init__()\n        self.channel_size = channel_size\n        self.out_feature = out_feature\n        \n        if backbone == 'resnet18':\n            self.backbone = models.resnet18(False)\n            self.in_features = self.backbone.fc.in_features\n            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n            self.fc1 = nn.Linear(self.in_features * 7 * 7 , self.channel_size)\n      \n        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n        self.bn1 = nn.BatchNorm2d(self.in_features)\n        self.dropout = nn.Dropout2d(dropout)\n        self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n    def forward(self, x, labels=None):\n        print(x.shape,'i am faetures')\n\n        features = self.backbone(x)\n        print(features.shape,'i am faetures')\n\n        features = self.dropout(features)\n        features = features.view(features.size(0), -1)\n        print(features.shape,'i am faetures1')\n        features = self.fc1(features)\n        print(features.shape,'i am faetures2')\n\n        features = F.normalize(features)\n        \n        print(features.shape,'i am faetures3')\n        print(features,'i am faetures3')\n\n        #margin=self.margin(features, labels)\n        #print(margin,'i am margin')\n\n        if labels is not None:\n            return self.margin(features, labels)\n        return features\n    \n    def test(self):\n        x = torch.rand(1, 3, 224, 224).cuda()\n        print(self.forward(x))\n","c4b893a7":"model = SHOPEEDenseNet(512, 11014, backbone='resnet18')\nmodel.to('cuda')","59c683a4":"ll ..\/input","0de2da7f":"model.load_state_dict(torch.load('..\/input\/shopee-models\/baseline_fold0_densenet_224_epoch50.pth'))\nmodel.to('cuda')","daa65677":"model = SHOPEEDenseNet(512, 11014, backbone='resnet18')\nmodel.load_state_dict(torch.load('..\/input\/shopee-models\/baseline_fold0_densenet_224_epoch30.pth'))\nmodel.to('cuda')","6a5793c5":"def generate_test_features(test_loader):\n    model.eval()\n    bar = tqdm_notebook(test_loader)\n    \n    FEAS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for batch_idx, (images) in enumerate(bar):\n            print('ddddd',batch_idx)\n            #images = images.to('cuda')\n            features = model(images)\n            FEAS += [features.detach().cpu()]\n            if batch_idx==1:\n               break\n                \n    FEAS = torch.cat(FEAS).cpu().numpy()\n    return FEAS","11da3776":"# !mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\/\n# !cp ..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth \/root\/.cache\/torch\/hub\/checkpoints\/","38513db9":"import albumentations\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize()\n])\n\ndataset_test = SHOPEEDataset(train, 'test', transform=transforms_valid)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, \n                                          shuffle=False, num_workers=4, pin_memory=True)\nimagefeat = generate_test_features(test_loader)\nimagefeat = torch.tensor(imagefeat)","7a9e1186":"import albumentations\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize()\n])\ndataset_test = SHOPEEDataset(train, 'train', transform=transforms_valid)\ntrain_loader = torch.utils.data.DataLoader(dataset_test, batch_size=16, \n                                          shuffle=False, num_workers=4, pin_memory=True)","82720db5":"max_epoch = 50\nlr = 1e-1  # initial learning rate\nlr_step = 10\nlr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\nweight_decay = 5e-4\noptimizer_p = 'sgd'\nloss_p=''","ea09a395":"if loss_p == 'focal_loss':\n        criterion = FocalLoss(gamma=2)\nelse:\n        criterion = torch.nn.CrossEntropyLoss()\n\nif optimizer_p == 'sgd':\n   optimizer = torch.optim.SGD(model.parameters(),\n                                    lr=lr, weight_decay=weight_decay)\nelse:\n   optimizer = torch.optim.Adam( model.parameters(),\n                                     lr=lr, weight_decay=weight_decay)\nscheduler = StepLR(optimizer, step_size=lr_step, gamma=0.1)","58299661":"start = time.time()\n\nfor i in range(max_epoch):\n        scheduler.step()\n\n        model.train()\n        for ii, data in enumerate(train_loader):\n            data_input, label = data\n            data_input = data_input.to(device)\n            label = label.to(device).long()\n            output = model(data_input, label)\n            loss = criterion(output, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            iters = i * len(train_loader) + ii\n\n            if iters % 100 == 0:\n                output = output.data.cpu().numpy()\n                output = np.argmax(output, axis=1)\n                label = label.data.cpu().numpy()\n                # print(output)\n                # print(label)\n                acc = np.mean((output == label).astype(int))\n                speed = 100 \/ (time.time() - start)\n                time_str = time.asctime(time.localtime(time.time()))\n                print('{} train epoch {} iter {} {} iters\/s loss {} acc {}'.format(time_str, i, ii, speed, loss.item(), acc))\n                if False:\n                    visualizer.display_current_results(iters, loss.item(), name='train_loss')\n                    visualizer.display_current_results(iters, acc, name='train_acc')\n\n                start = time.time()\n\n        if i % 10 == 0 or i == max_epoch:\n            save_model(model, '.\/', 'resenet', i)\n\n        model.eval()","6c224e00":"for ii, data in enumerate(test_loader):\n    print(ii,data)\n    print(len(data))\n    print(data[0].size())\n    print(data[1].size())\n\n    if ii==1:\n       break","623aedc8":"imagefeat = imagefeat.cuda()","92546408":"print('Finding similar images...')\n\npreds = []\npreds_index = []\nCHUNK = 1024*4\n\nCTS = len(imagefeat)\/\/CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\n\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n    distances = distances.data.cpu().numpy()\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        # IDX = cupy.where(distances[k,]>0.95)[0]\n        IDX = np.where(distances[k,]>0.9)[0][:]\n        o = train.iloc[IDX].posting_id.values\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        preds_index.append(IDX)\n        \n# del imagefeat, imgmodel","97a5ebd0":"train['oof_cnn'] = preds\nprint(train['oof_cnn'].apply(len).mean())\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","dce93894":"from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(train.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","8e6a089f":"text_embeddings = torch.from_numpy(text_embeddings)\ntext_embeddings = text_embeddings.cuda()","ba695bd3":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)\/\/CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nCTS_index = 0\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = cts.data.cpu().numpy()\n    print(cts.shape)\n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.7)[0]\n        # IDX = np.where(cts[k,list(preds_index[CTS_index])]>0.7)[0]\n        # IDX = [preds_index[CTS_index][x] for x in IDX]\n        o = train.iloc[IDX].posting_id.values\n        preds.append(o)\n        CTS_index += 1\n# del model, text_embeddings","47a748c4":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_text'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","e5f8e836":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","035834fc":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    \n    train['cv_score'] = train.apply(getMetric('oof'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())\n    \ntrain['matches'] = train.apply(combine_for_sub,axis=1)","edc11b8c":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","bfd68977":"# image hash","a082a8e8":"# image CNN","d35c0ac8":"# title TFIDF"}}