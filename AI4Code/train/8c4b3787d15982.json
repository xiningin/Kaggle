{"cell_type":{"7c0c2abb":"code","12df87ab":"code","22c03cfa":"code","05dc0a17":"code","58c673a5":"code","8ee5929a":"code","ccb790f5":"code","8b2d6edd":"code","b9798587":"code","d81d2176":"code","c6d00a2d":"code","4707acca":"code","707249ff":"code","1c997481":"code","180d5d56":"code","33b85ea3":"code","a509425b":"code","8137e572":"code","c3af5335":"code","25e98e79":"code","45d1b57d":"code","1ee372d5":"code","022ef3f3":"code","119787e9":"code","859ff822":"code","41ab6486":"code","efe4931a":"code","a297e507":"code","033b7e8f":"code","7708d312":"code","35fe923c":"code","248b9b7a":"code","dcfe06f5":"code","c5e87217":"code","1cd2086f":"code","fd39dc09":"code","f296634e":"code","15978363":"code","3d57e2f8":"code","e0c2412d":"code","48eff887":"code","d407ab4d":"code","f7bb5844":"code","9a6a4d37":"code","757a64f3":"code","99e2d2f2":"code","752a0f01":"code","872b33eb":"code","d75359c4":"markdown","ddb6e8a2":"markdown","a8efd140":"markdown","985aef6e":"markdown","cd0f81ee":"markdown","eb44ba28":"markdown","dcabc9a1":"markdown","37ad1b47":"markdown","27620671":"markdown","1f38fb1d":"markdown","4479cfb6":"markdown","dc1fe602":"markdown","4ba47f2b":"markdown","d76aa432":"markdown","32581e2f":"markdown","7867e9e7":"markdown","dee7e1c4":"markdown","f5ca297f":"markdown","a5ef857f":"markdown","3322d2e9":"markdown","5db661da":"markdown","0393f049":"markdown","6249940c":"markdown","c10e4f79":"markdown","a3032eb2":"markdown"},"source":{"7c0c2abb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","12df87ab":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","22c03cfa":"# df = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/ML Self-Projects\/Predict Test Scores of students\/Data\/test_scores.csv')\ndf = pd.read_csv('\/kaggle\/input\/predict-test-scores-of-students\/test_scores.csv')\ndf.head()","05dc0a17":"df","58c673a5":"df.info()","8ee5929a":"df['school'].unique()","ccb790f5":"plt.figure(figsize=(20,10))\nplt.title('Value counts of Schools')\nsns.countplot(data=df, x='school');","8b2d6edd":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores')\nsns.scatterplot(data=df, x='posttest', y='pretest');","b9798587":"plt.figure(figsize=(20,10))\nplt.title('Plot of Schools vs Pre Test Scores')\nsns.boxplot(data=df, x='pretest', y='school');","d81d2176":"plt.figure(figsize=(20,10))\nplt.title('Plot of Schools vs Post Test Scores')\nsns.boxplot(data=df, x='posttest', y='school');","c6d00a2d":"print(f'Mean of Pre test scores: { df[\"pretest\"].mean() }')\nprint(f'Mean of Post test scores: {df[\"posttest\"].mean()}')","4707acca":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores vs School Setting')\nsns.scatterplot(data=df, x='posttest', y='pretest', hue='school_setting', s=70, alpha=0.7);","707249ff":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores vs School Type')\nsns.scatterplot(data=df, x='posttest', y='pretest', hue='school_type', s=70, alpha=0.7);","1c997481":"plt.figure(figsize=(20,10))\nplt.title('Classroom Value Count')\nplt.xticks(rotation=90)\nsns.countplot(data=df, x='classroom');","180d5d56":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores vs teaching Method')\nsns.scatterplot(data=df, x='posttest', y='pretest', hue='teaching_method', s=70, alpha=0.7);","33b85ea3":"plt.figure(figsize=(20,10))\nplt.title('Number of student Value Count per class')\nplt.xticks(rotation=90)\nsns.countplot(data=df, x='n_student');","a509425b":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores vs Gender')\nsns.scatterplot(data=df, x='posttest', y='pretest', hue='gender', s=70, alpha=0.7);","8137e572":"plt.figure(figsize=(20,10))\nplt.title('Plot of Post Test Scores vs Pretest Scores vs Qualifies for lunch')\nsns.scatterplot(data=df, x='posttest', y='pretest', hue='lunch', s=70, alpha=0.7);","c3af5335":"df.info()","25e98e79":"df_backup = df.copy()","45d1b57d":"df = df.drop('student_id', axis=1)","1ee372d5":"df.info()","022ef3f3":"df = pd.get_dummies(df, drop_first=True)","119787e9":"df.head()","859ff822":"X = df.drop('posttest', axis=1)\ny = df['posttest']\nlen(X)","41ab6486":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","efe4931a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","a297e507":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor","033b7e8f":"def fit_and_score(models, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train,y_train)\n        model_scores[name] = model.score(X_test,y_test)\n\n    model_scores = pd.DataFrame(model_scores, index=['Accuracy'])\n    model_scores = model_scores.transpose().sort_values('Accuracy')\n\n    return model_scores","7708d312":"models = {'Ridge' : Ridge(),\n         'Lasso': Lasso(),\n         'ElasticNet': ElasticNet(),\n         'KNeighborsRegressor': KNeighborsRegressor(),\n         'SVR': SVR(),\n         'DecisionTreeRegressor': DecisionTreeRegressor(),\n         'RandomForestRegressor':RandomForestRegressor(),\n         'GradientBoostingRegressor': GradientBoostingRegressor(),\n         'AdaBoostRegressor': AdaBoostRegressor()}","35fe923c":"baseline_model_scores_df = fit_and_score(models, X_train, X_test, y_train, y_test)","248b9b7a":"baseline_model_scores_df.sort_values('Accuracy')","dcfe06f5":"plt.figure(figsize=(20,10))\nsns.barplot(data=baseline_model_scores_df.T)\nplt.title('Baseline Model Accuracy Score')\nplt.xticks(rotation=90);","c5e87217":"from sklearn.model_selection import GridSearchCV\nfrom warnings import filterwarnings","1cd2086f":"filterwarnings('ignore')","fd39dc09":"def gridsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_gs_scores = {}\n    model_gs_best_param = {}\n    \n    for name, model in models.items():\n        gs_model = GridSearchCV(model,\n                                param_grid=params[name],\n                                scoring='neg_mean_squared_error',\n                                n_jobs=-1,\n                                cv=5,\n                                verbose=2)\n        \n        gs_model.fit(X_train,y_train)\n\n        model_gs_scores[name] = gs_model.score(X_test,y_test)\n        model_gs_best_param[name] = gs_model.best_params_\n\n    model_gs_scores = pd.DataFrame(model_gs_scores, index=['neg_mean_squared_error'])\n    model_gs_scores = model_gs_scores.transpose().sort_values('neg_mean_squared_error')\n        \n    return model_gs_scores, model_gs_best_param","f296634e":"models = {'Ridge' : Ridge(),\n         'KNeighborsRegressor': KNeighborsRegressor(),\n         'RandomForestRegressor':RandomForestRegressor(),\n         'GradientBoostingRegressor': GradientBoostingRegressor()}\n         \nparams = {'Ridge' : {'alpha' : np.linspace(0,1,20),\n                     'normalize': [True, False]},\n          'KNeighborsRegressor': {'n_neighbors':[1,2,5,10,20]},\n          'RandomForestRegressor': {'n_estimators' : [50,100,200],\n                    'criterion' : ['mse','mae'],\n                    'oob_score' : [True,False]},\n          'GradientBoostingRegressor': {'criterion': ['mse', 'friedman_mse'],\n                                        'loss': ['ls','lad','huber','quantile']}\n          }","15978363":"model_gs_scores_1, model_gs_best_param_1 = gridsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","3d57e2f8":"model_gs_scores_1","e0c2412d":"model_gs_best_param_1","48eff887":"models = {'Ridge' : Ridge(),\n         'KNeighborsRegressor': KNeighborsRegressor(),\n         'RandomForestRegressor':RandomForestRegressor(),\n         'GradientBoostingRegressor': GradientBoostingRegressor()}\n         \nparams = {'Ridge' : {'alpha' : np.linspace(0.5,1,20),\n                     'normalize': [False]},\n          'KNeighborsRegressor': {'n_neighbors':[4,5,6,7]},\n          'RandomForestRegressor': {'n_estimators' : [150,200,300],\n                    'criterion' : ['mse'],\n                    'oob_score' : [False]},\n          'GradientBoostingRegressor': {'criterion': ['mse'],\n                                        'loss': ['ls'],\n                                        'n_estimators' : [150,200,300]}\n          }","d407ab4d":"model_gs_scores_2, model_gs_best_param_2 = gridsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","f7bb5844":"model_gs_scores_2","9a6a4d37":"model_gs_best_param_2","757a64f3":"model = Ridge(alpha=1.0,normalize=False)\nmodel.fit(X_train, y_train)\ny_preds = model.predict(X_test)","99e2d2f2":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","752a0f01":"r2 = r2_score(y_test,y_preds)\nmae = mean_absolute_error(y_test, y_preds)\nmse = mean_squared_error(y_test, y_preds)\nrmse = np.sqrt(mse)","872b33eb":"print(f'R2 Score: {r2}')\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Square Error: {mse}')\nprint(f'Root Mean Square Error: {rmse}')","d75359c4":"# 4. Features\n\nIt contains information about a test written by some students. It include features such as: School setting, School type, gender, pretetest scores among others.\n\n## Features \/ inputs\n\n    1. school - Name of the school the student is enrolled in.\n    2. school_settings - The location of the school\n    3. school_type - The type of school. Either public or non-public\n    4. classroom - The type of classroom\n    5. teaching_method - Teaching methods: Either experimental or Standard\n    6. n_student - Number of students in the class\n    7. student_id - A unique ID for each student\n    8. gender - The gender of the students: male or female\n    9. lunch - Whether a student qualifies for free\/subsidized lunch or not\n    10. pretest - The pretest score of the students out of 100\n\n## Label \/ Output\n    11. posttest - The posttest scores of the students out of 100","ddb6e8a2":"# 5. Modelling","a8efd140":"This is interesting, the plot shows that usually standard teaching method is scores higher in pre test scores then Experimental teaching method.","985aef6e":"Going to take the following approach:\n\n1. Problem definition\n2. Data\n3. Evaluation\n4. Features\n5. Modelling\n6. Model Evaluation","cd0f81ee":"## Hyperparameter Tuning via Grid Search CV","eb44ba28":"### Grid Search CV model 1","dcabc9a1":"# Predict Test Scores of students\n\n\nThis notebook is a work flow for various Python-based machine learning model for predicting test scores of students.","37ad1b47":"### Grid Search CV model 2","27620671":"# 3. Evalutation\n\nCreating a Regression Model that we will evalute using the Root Mean Square Error (RMSE), R2 Score and Mean Absolute Error (MAE)","1f38fb1d":"Using a Ridge Model we have evaulated the model of a Root Mean Square Error of 2.8626409815834273, a R2 Score of 0.957754777599356 and a Mean Absolute Error: 2.2527079714433427","4479cfb6":"## Data Exploration (Exploratory Data Analysis (EDA) )","dc1fe602":"From the Above Bar plot and the two mean scores, we can see that students usually perfrom better at the post test scores","4ba47f2b":"## Importing Models","d76aa432":"As student_id is unique to per student, we will be dropping it.","32581e2f":"## Data cleaning","7867e9e7":"With the scoring of the baseline model, we will use the following models to tune the hyperparameter:\n\n    1. KNeighborsRegressor \t0.942739\n    2. RandomForestRegressor \t0.945066\n    3. GradientBoostingRegressor \t0.948113\n    4. Ridge \t0.957755","dee7e1c4":"## Baseline models and scores","f5ca297f":"# 2. Data\n\nPredicting the posttest scores of students from 11 features by Kwadwo Ofosu\n\nSource: https:\/\/www.kaggle.com\/kwadwoofosu\/predict-test-scores-of-students","a5ef857f":"From the Grid Search CV using the neg mean squared error, we can see that the Ridge model is performing the best with a result of 8.194713.","3322d2e9":"From the plot we can see that students who Does not qualifty for lunch usually does better in both Pre test and Post test Scores","5db661da":"# 6. Model Evaluation","0393f049":"From the plot we can see that the Urban schools and Suburban schools are more tightly in clusters then Rural Schools in term of both scores","6249940c":"## Standard imports","c10e4f79":"# 1. Problem Definition\n\nGiven the set of parameters, can we predict a test score of a student?","a3032eb2":"### Getting Dummies Vars"}}