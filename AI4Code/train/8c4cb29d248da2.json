{"cell_type":{"7983355c":"code","780f14f2":"code","0edffaaa":"code","9736b2ce":"code","464c6339":"code","c4ce1606":"code","1ac9ab3e":"code","400687d3":"code","e50d921c":"code","29e4b79b":"code","e4de2f04":"code","3fa72d05":"code","1876fa78":"code","e8c95b30":"code","98fa84ff":"code","3fde7788":"code","28a0a16f":"code","f1259cda":"code","e801cb6d":"code","44466173":"code","ad0a018d":"code","2c4144f2":"code","437d1f44":"markdown","18b24027":"markdown","3f4b49c6":"markdown","d04736d0":"markdown","65d6e8b2":"markdown","a4dd883a":"markdown","8652ded8":"markdown","9cc802b5":"markdown"},"source":{"7983355c":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow.keras.backend as K\nimport yaml\n\nimport wandb\nfrom wandb.keras import WandbCallback\nfrom kaggle_secrets import UserSecretsClient\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","780f14f2":"config = {}\n\n# Tabular data file paths\nconfig['TRAIN_DATA_PATH'] = '..\/input\/pawpularity-folds\/train_5folds.csv'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\n# Image data directories\nTRAIN_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/train'\nTEST_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/test'","0edffaaa":"# Parameters for processing tabular data\nTARGET_NAME = 'Pawpularity'\nconfig['SEED'] = 541\nconfig['FOLDS'] = 5\nconfig['DEBUG'] = False","9736b2ce":"# TensorFlow settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nconfig['IMG_SIZE'] = 299\nconfig['BATCH_SIZE'] = 64\nconfig['DROPOUT_RATE'] = 0.2\nconfig['LEARNING_RATE'] = 1e-3\nconfig['DECAY_STEPS'] = 100\nconfig['DECAY_RATE'] = 0.96\nconfig['EPOCHS'] = 100\nconfig['PATIENCE'] = 4\nconfig['USE_WANDB'] = False\nconfig['WANDB_PROJECT'] = 'pawpularity'\nconfig['WANDB_MODE'] = 'offline'","464c6339":"# Pretrained image classification model EfficientNetB0\n# from tf.keras.applications with global average pooling as a final layer.\n# In this notebook the model is loaded from a public dataset on Kaggle\n# at https:\/\/www.kaggle.com\/ekaterinadranitsyna\/keras-applications-models\nconfig['IMG_MODEL'] = '..\/input\/keras-applications-models\/EfficientNetB4.h5'","c4ce1606":"with open(r'config.yaml', 'w') as file:\n    yaml.dump(config, file)","1ac9ab3e":"def use_wandb():\n    if config['WANDB_MODE'] == 'offline':\n        os.environ[\"WANDB_MODE\"] = \"offline\"\n        key='X'*40\n        wandb.login(key=key)\n    else:\n        user_secrets = UserSecretsClient()\n        wandb_api = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=wandb_api)\n\n    run = wandb.init(project=config['WANDB_PROJECT'], \n                     job_type='train',\n                     config = config)\n\n    return run\n\ndef set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, config['IMG_SIZE'], config['IMG_SIZE']), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None, type='train') -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    \n    \n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        if type=='train':\n            ds = ds.shuffle(buffer_size=1024)\n\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(config['BATCH_SIZE']).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(config['BATCH_SIZE']).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['score_root_mean_squared_error']\n    val_rmse = hist.history['val_score_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","400687d3":"set_seed(config['SEED'])\nset_display()\n\nif config['USE_WANDB']:\n    run = use_wandb()","e50d921c":"# Train data set\ndata_train = pd.read_csv(config['TRAIN_DATA_PATH'])\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","29e4b79b":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","e4de2f04":"# Reconstruct the paths to train and test images.\n\n\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\nif config['DEBUG']:\n    data_train = data_train.head(50)\n    data_test = data_test.head(50)\n    config['EPOCHS'] = 1\n\n# # Keep a portion of the labeled data for validation.\n# train_subset, valid_subset = train_test_split(\n#     data_train[['path', TARGET_NAME]],\n#     test_size=VAL_SIZE, shuffle=True, random_state=SEED\n# )","3fa72d05":"def get_model():\n    # Pretrained image classification model\n    feature_model = tf.keras.models.load_model(config['IMG_MODEL'])\n\n    # Freeze weights in the original model\n    feature_model.trainable = False\n\n    # This model takes in 224 x 224 images, applies random horizontal flip\n    # (only in the train mode), passes image arrays through pretrained\n    # feature extraction model and applies batch normalization, dropout\n    # and activations to get the target score.\n    \n    input_layer = tf.keras.layers.Input(shape=(config['IMG_SIZE'], config['IMG_SIZE'], 3))\n    random_flip = tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal')(input_layer)\n    feature_model = feature_model(random_flip)\n    bn = tf.keras.layers.BatchNormalization()(feature_model)\n    dropout = tf.keras.layers.Dropout(config['DROPOUT_RATE'], name='top_dropout')(bn)\n    fc1 = tf.keras.layers.Dense(32, activation='relu', name='embedding')(dropout)\n    fc2 = tf.keras.layers.Dense(1, name='score')(fc1)\n    \n    image_model = tf.keras.Model(inputs=input_layer, \n                            outputs=[fc1,fc2])\n\n    # To gradually decrease learning rate\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=config['LEARNING_RATE'],\n        decay_steps=config['DECAY_STEPS'], decay_rate=config['DECAY_RATE'],\n        staircase=True)\n\n\n    # Compile the model\n    image_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                        loss={'embedding':None, 'score':tf.keras.losses.MeanSquaredError()},\n                        metrics={'embedding': None, 'score':tf.keras.metrics.RootMeanSquaredError()})\n\n    return image_model","1876fa78":"image_model = get_model()\nimage_model.save_weights('default_weights.h5')","e8c95b30":"image_model.summary()","98fa84ff":"tf.keras.utils.plot_model(image_model, show_shapes=True,show_dtype=True)","3fde7788":"! mkdir 'preds'","28a0a16f":"from sklearn import metrics","f1259cda":"test_ds = get_dataset(x=data_test['path'])\nhistory_objs = []\nscores = []\n\n# To monitor validation loss and stop the training.\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=config['PATIENCE'], restore_best_weights=True)\n\n\nfor fold in range(config['FOLDS']):\n    K.clear_session()\n    print(\"##\"*50)\n    print(f\"##### Training for fold {fold}:\")\n    train_subset = data_train[data_train['kfold'] != fold][['path', TARGET_NAME]].reset_index(drop=True)\n    valid_subset = data_train[data_train['kfold'] == fold][['path', TARGET_NAME]].reset_index(drop=True)\n    \n    # Create TensorFlow datasets\n    train_ds = get_dataset(x=train_subset['path'], y=train_subset[TARGET_NAME], type='train')\n    valid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[TARGET_NAME], type='valid')\n    \n    bm = tf.keras.callbacks.ModelCheckpoint('paw_fold_'+str(fold)+'.h5',\n                                            verbose=1, \n                                            monitor='val_loss', \n                                            mode='min', \n                                            save_best_only=True, \n                                            save_weights_only=False)\n    image_model = get_model()\n    image_model.load_weights('default_weights.h5')\n    callbacks=[early_stop, bm]\n    if config['USE_WANDB']:\n        callbacks.append(WandbCallback(save_model=False))\n    \n    history = image_model.fit(train_ds, validation_data=valid_ds,\n                          epochs=config['EPOCHS'], callbacks = callbacks,\n                          use_multiprocessing=True, workers=-1)\n\n    K.clear_session()\n    image_model.load_weights('paw_fold_'+str(fold)+'.h5')\n    print(f\"##### Predicting for fold {fold}:\")\n    \n    train_preds = image_model.predict(\n    train_ds, use_multiprocessing=True, workers=os.cpu_count())\n    valid_preds = image_model.predict(\n    valid_ds, use_multiprocessing=True, workers=os.cpu_count())\n    train_subset['predicted_score'] = train_preds[1]\n    embeddings = pd.DataFrame(train_preds[0])\n    train_subset = pd.concat([train_subset, embeddings], axis=1)\n    valid_subset['predicted_score'] = valid_preds[1]\n    \n    print(f\"##### Score for fold {fold}:\", metrics.mean_squared_error(valid_subset.predicted_score.values, valid_subset[TARGET_NAME].values, squared=False))\n    \n    scores.append(metrics.mean_squared_error(valid_subset.predicted_score.values, valid_subset[TARGET_NAME], squared=True))\n    train_subset.to_csv('preds\/train_preds'+str(fold)+'.csv', index=False)\n    valid_subset.to_csv('preds\/valid_preds'+str(fold)+'.csv', index=False)\n    \n    del train_subset\n    del valid_subset\n    del train_ds\n    del valid_ds\n    \n    print(f\"##### Predicting for fold {fold} on Test Set:\")\n    data_test[TARGET_NAME+'_fold'+str(fold)] = image_model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count())[1]\n    \n    \n    history_objs.append(history)\n    \ndata_test.to_csv('preds\/test_preds.csv', index=False)","e801cb6d":"print(scores)","44466173":"print(\"CV:\",np.sqrt(np.sum(scores)\/config['FOLDS']))  ","ad0a018d":"for idx, history in enumerate(history_objs):\n    print(f\"##### Fold {idx} training:\")\n    plot_history(history)","2c4144f2":"pred_columns = [col for col in list(data_test.columns) if col.startswith( TARGET_NAME+'_fold')]\ndata_test[TARGET_NAME] = np.mean(data_test[pred_columns], axis=1)\ndata_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\nprint(\"All Done!\")\n\nif config['USE_WANDB']:\n    run.finish()","437d1f44":"## Functions","18b24027":"Original Version: https:\/\/www.kaggle.com\/ekaterinadranitsyna\/pretrained-feature-model-keras\n\nPlease respect the original work and upvote the original work too. Credits: (https:\/\/www.kaggle.com\/ekaterinadranitsyna)","3f4b49c6":"## What all is different from original work:\n\n1. Converting to N-fold training\n2. EfficientNetB4 as pretrained model\n3. Saving Models, Training Preds and Valid Preds for experiments with boosting models and tabular data.\n4. Wandb Integration\n5. Saving config for future reference.\n6. Support for saving Image Embeddings.\n7. Changing From Sequential API to Functional API for multioutput.\n8. Shuffle during Training","d04736d0":"# Using a Pretrained EfficientNet to Predict Pet Popularity","65d6e8b2":"## Modelling","a4dd883a":"Pretrained **EfficientNetB4 model from Keras applications** is used to extract features from images resized to 224 x 224. Popularity score is estimated based solely on images. Tabular data is ignored. Since image quality affects the target value only horizontal flip is used for data augmentation.","8652ded8":"## Generating Submission File","9cc802b5":"## Data Processing"}}