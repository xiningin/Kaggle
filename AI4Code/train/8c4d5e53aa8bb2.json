{"cell_type":{"499484f7":"code","cf6da633":"code","19a450ab":"code","c1cb5db9":"code","78367c6d":"code","69288256":"code","97e582f2":"code","623bebea":"code","2633305f":"code","b0ef65b7":"code","6a64c995":"code","4a34eb00":"code","a0959513":"code","18ba9fe6":"code","92d70f38":"code","5f5cd876":"code","1e088902":"code","fcc840ab":"code","24ef0878":"code","62d439e0":"code","a5ef190b":"code","3229ec64":"code","372bb54e":"code","5f95850f":"code","860d87b3":"code","244a714e":"code","5553e044":"code","00363f46":"code","4f2c4b37":"code","5fa92770":"code","c53067e5":"code","b54f9a3f":"code","e4add4d9":"code","ae3b623f":"code","a4c49794":"code","40f4d457":"code","8a8ebe25":"code","dd1b8d3a":"code","c6823f0c":"code","d877e6e5":"code","4260f80e":"code","320c0488":"code","f31142ee":"code","48e9c3d7":"code","7df6e684":"code","fc2e8708":"code","f2cf8509":"code","d36728c4":"code","4556bcd5":"code","8abc76be":"code","0120d05f":"code","6ec42aa2":"code","fcf17a22":"code","df2f2413":"code","ea161b99":"code","255aea57":"markdown","293999c2":"markdown","4766c160":"markdown","b6347d81":"markdown","960a2334":"markdown","d08d948f":"markdown","17b802a9":"markdown","f4da0f2a":"markdown","3478489e":"markdown","0707497a":"markdown","d078a90d":"markdown","273c7ee2":"markdown","d8d3ae87":"markdown"},"source":{"499484f7":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Importing Text Analysis Libraries:\nfrom textblob import TextBlob\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import PorterStemmer\n!pip install textblob \nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download()\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as vader\nprint('Libraries Imported')","cf6da633":"sns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 10\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'","19a450ab":"c1=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Disclosing\/2018_Cities_Disclosing_to_CDP.csv')\nc2=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Disclosing\/2019_Cities_Disclosing_to_CDP.csv')\nc3=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Disclosing\/2020_Cities_Disclosing_to_CDP.csv')\nc21=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Responses\/2018_Full_Cities_Dataset.csv')\nc22=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Responses\/2019_Full_Cities_Dataset.csv')\nc23=pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Responses\/2020_Full_Cities_Dataset.csv')","c1cb5db9":"\nc1","78367c6d":"c2","69288256":"c3","97e582f2":"c21.head()","623bebea":"c22.head()","2633305f":"c23.head()","b0ef65b7":"c1['Country'] = c1['Country'].replace(['United States of America'],'USA')\nc2['Country'] = c2['Country'].replace(['United States of America'],'USA')\nc3['Country'] = c3['Country'].replace(['United States of America'],'USA')\nc1['Country'] = c1['Country'].replace(['Republic of Korea'],'S.Korea')\nc2['Country'] = c2['Country'].replace(['Republic of Korea'],'S.Korea')\nc3['Country'] = c3['Country'].replace(['Republic of Korea'],'S.Korea')\nc1['Country'] = c1['Country'].replace(['United Kingdom of Great Britain and Northern Ireland'],'UK')\nc2['Country'] = c2['Country'].replace(['United Kingdom of Great Britain and Northern Ireland'],'UK')\nc3['Country'] = c3['Country'].replace(['United Kingdom of Great Britain and Northern Ireland'],'UK')\nc1['Country'] = c1['Country'].replace(['Bolivia (Plurinational State of)'],'Bolivia')\nc2['Country'] = c2['Country'].replace(['Bolivia (Plurinational State of)'],'Bolivia')\nc3['Country'] = c3['Country'].replace(['Bolivia (Plurinational State of)'],'Bolivia')\nc1['Country'] = c1['Country'].replace(['Taiwan, Greater China'],'Taiwan')\nc2['Country'] = c2['Country'].replace(['Taiwan, Greater China'],'Taiwan')\nc3['Country'] = c3['Country'].replace(['Taiwan, Greater China'],'Taiwan')\nc1['Country'] = c1['Country'].replace(['Democratic Republic of the Congo'],'DR Congo')\nc2['Country'] = c2['Country'].replace(['Democratic Republic of the Congo'],'DR Congo')\nc3['Country'] = c3['Country'].replace(['Democratic Republic of the Congo'],'DR Congo')\nc1['Country'] = c1['Country'].replace(['China, Hong Kong Special Administrative Region'],'Hong Kong')\nc2['Country'] = c2['Country'].replace(['China, Hong Kong Special Administrative Region'],'Hong Kong')\nc3['Country'] = c3['Country'].replace(['China, Hong Kong Special Administrative Region'],'Hong Kong')\nc1['Country'] = c1['Country'].replace(['United Republic of Tanzania'],'Tanzania')\nc2['Country'] = c2['Country'].replace(['United Republic of Tanzania'],'Tanzania')\nc3['Country'] = c3['Country'].replace(['United Republic of Tanzania'],'Tanzania')\nc1['Country'] = c1['Country'].replace(['Russian Federation'],'Russia')\nc2['Country'] = c2['Country'].replace(['Russian Federation'],'Russia')\nc3['Country'] = c3['Country'].replace(['Russian Federation'],'Russia')\nc1['Country'] = c1['Country'].replace(['United Arab Emirates'],'UAE')\nc2['Country'] = c2['Country'].replace(['United Arab Emirates'],'UAE')\nc3['Country'] = c3['Country'].replace(['United Arab Emirates'],'UAE')\nc1['Country'] = c1['Country'].replace(['Venezuela (Bolivarian Republic of)'],'UAE')\nc2['Country'] = c2['Country'].replace(['Venezuela (Bolivarian Republic of)'],'UAE')\nc3['Country'] = c3['Country'].replace(['Venezuela (Bolivarian Republic of)'],'UAE')\nc1['Country'] = c1['Country'].replace(['State of Palestine'],'Palestine')\nc2['Country'] = c2['Country'].replace(['State of Palestine'],'Palestine')\nc3['Country'] = c3['Country'].replace(['State of Palestine'],'Palestine')","6a64c995":"plt.figure(figsize=(20,25))\nplt.subplot(1,2,1)\nsns.countplot(y=c1['Country'],order = c1['Country'].value_counts().index,palette='rainbow')\nplt.ylabel('COUNTRY',fontsize=25)\nplt.xlabel('COUNT',fontsize=30)\nplt.title('2018', fontsize= 20);\n\nplt.subplot(1,2,2)\nsns.countplot(y=c2['Country'],order = c2['Country'].value_counts().index,palette='rainbow')\nplt.ylabel('',fontsize=10)\nplt.xlabel('COUNT',fontsize=30)\nplt.title('2019',fontsize= 20);","4a34eb00":"plt.figure(figsize=(10,25))\nsns.countplot(y=c3['Country'],order = c3['Country'].value_counts().index,palette='rainbow')\nplt.ylabel('COUNTRY - 2020',fontsize=40)\nplt.xlabel('COUNT',fontsize=30)","a0959513":"plt.figure(figsize=(30,30))\nplt.subplot(3,1,1)\nsns.countplot(y=c1['CDP Region'],order = c1['CDP Region'].value_counts().index,palette='rocket')\nplt.ylabel('REGION - 2018',fontsize=40)\nplt.xlabel('COUNT',fontsize=25)\nplt.yticks(fontsize=15);\n\nplt.subplot(3,1,2)\nsns.countplot(y=c2['CDP Region'],order = c2['CDP Region'].value_counts().index,palette='rocket')\nplt.ylabel('REGION - 2019',fontsize=40)\nplt.xlabel('COUNT',fontsize=25)\nplt.yticks(fontsize=15);\n\n\nplt.subplot(3,1,3)\nsns.countplot(y=c3['CDP Region'],order = c3['CDP Region'].value_counts().index,palette='rocket')\nplt.ylabel('REGION - 2020',fontsize=40)\nplt.xlabel('COUNT',fontsize=25)\nplt.yticks(fontsize=15);\n","18ba9fe6":"plt.figure(figsize=(20,5))\nplt.subplot(1,3,1)\nsns.countplot(c1['Access'],palette='summer')\nplt.ylabel('COUNT',fontsize=20)\nplt.title('2018', fontsize= 20);\n\nplt.subplot(1,3,2)\nsns.countplot(c2['Access'],palette='summer')\nplt.ylabel('')\nplt.title('2019', fontsize= 20);\n\nplt.subplot(1,3,3)\nsns.countplot(c3['Access'],palette='summer')\nplt.ylabel('')\nplt.title('2020', fontsize= 20);","92d70f38":"c21.head()","5f5cd876":"c21.columns","1e088902":"c21.shape","fcc840ab":"plt.figure(figsize=(10,7))\nsns.countplot(y=c21['Parent Section'],order = c21['Parent Section'].value_counts().index,alpha=0.7,palette='spring')\nplt.yticks(fontsize=10)\nplt.ylabel('PARENT_SECTION - 2018', fontsize='22')\nplt.xlabel('COUNT', fontsize='15')","24ef0878":"plt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nsns.countplot(y=c22['Parent Section'],order = c22['Parent Section'].value_counts().index,alpha=0.7,palette='spring')\nplt.yticks(fontsize=10);\nplt.ylabel('PARENT_SECTION - 2019', fontsize='20')\nplt.xlabel('COUNT', fontsize='15')\n\nplt.subplot(2,1,2)\nsns.countplot(y=c23['Parent Section'],order = c23['Parent Section'].value_counts().index,alpha=0.7,palette='spring')\nplt.yticks(fontsize=10);\nplt.ylabel('PARENT_SECTION - 2020', fontsize='20')\nplt.xlabel('COUNT', fontsize='15')","62d439e0":"plt.figure(figsize=(10,15))\nsns.countplot(y=c21['Section'],order = c21['Section'].value_counts().index,alpha=0.7,palette='magma')\nplt.yticks(fontsize=10);\nplt.ylabel('SECTION - 2018', fontsize='50')\nplt.xlabel('COUNT', fontsize='25')","a5ef190b":"plt.figure(figsize=(10,15))\nsns.countplot(y=c22['Section'],order = c22['Section'].value_counts().index,alpha=0.7,palette='magma')\nplt.yticks(fontsize=10);\nplt.ylabel('SECTION - 2019', fontsize='50')\nplt.xlabel('COUNT', fontsize='25')","3229ec64":"plt.figure(figsize=(10,15))\nsns.countplot(y=c23['Section'],order = c23['Section'].value_counts().index,alpha=0.7,palette='magma')\nplt.yticks(fontsize=10);\nplt.ylabel('SECTION - 2020', fontsize='50')\nplt.xlabel('COUNT', fontsize='25')","372bb54e":"print(c21['Question Name'].duplicated().sum())\nprint(c22['Question Name'].duplicated().sum())\nprint(c23['Question Name'].duplicated().sum())","5f95850f":"c211 = c21['Question Name']\nc211 = c211.drop_duplicates().reset_index()\nc211 = c211.drop('index',axis=1)\nc222 = c22['Question Name']\nc222 = c222.drop_duplicates().reset_index()\nc222 = c222.drop('index',axis=1)\nc233 = c23['Question Name']\nc233 = c233.drop_duplicates().reset_index()\nc233 = c233.drop('index',axis=1)","860d87b3":"c31 = c211.merge(c222, on='Question Name', how='right')\nc32 = c31.merge(c233,on='Question Name', how='right')\nc32","244a714e":"c32['Question Name'] = c32['Question Name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\nc32['Question Name'].head()","5553e044":"c32['Question Name'] = c32['Question Name'].str.replace('[^\\w\\s]','')\nc32['Question Name'].head()","00363f46":"stop = stopwords.words('english')\n\nc32['Question Name'] = c32['Question Name'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop));\nc32['Question Name'].head()","4f2c4b37":"freq = pd.Series(' '.join(c32['Question Name']).split()).value_counts()[:10]\nfreq","5fa92770":"freq = list(freq.index)\nc32['Question Name'] = c32['Question Name'].apply(\n    lambda x: \" \".join(x for x in x.split() if x not in freq))\nc32['Question Name'].head()","c53067e5":"freq = pd.Series(' '.join(c32['Question Name']).split()).value_counts()[-15:]\nfreq","b54f9a3f":"freq = list(freq.index)\nc32['Question Name'] = c32['Question Name'].apply(\n    lambda x: \" \".join(x for x in x.split() if x not in freq))\nc32['Question Name'].head()","e4add4d9":"st = PorterStemmer()\nc32['Question Name'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))","ae3b623f":"c32['sentiment'] = c32['Question Name'].apply(lambda x: TextBlob(x).sentiment[0] )\nc32[['Question Name','sentiment']].head()","a4c49794":"vader=vader()","40f4d457":"c32['scores'] = c32['Question Name'].apply(lambda x: vader.polarity_scores(x))\nc32['compound']=c32['scores'].apply(lambda score_dict: score_dict['compound']) \nc32['pos']=c32['scores'].apply(lambda score_dict: score_dict['pos'])\nc32['neg']=c32['scores'].apply(lambda score_dict: score_dict['neg']) \nc32['neu']=c32['scores'].apply(lambda score_dict: score_dict['neu'])\nc32=c32.drop('scores',axis=1)\nc32","8a8ebe25":"c32['sentiment']=c32['sentiment'].astype(float)\nc32.sentiment[c32.sentiment>0]=1\nc32.sentiment[c32.sentiment<0]=-1;","dd1b8d3a":"c32","c6823f0c":"c41=c21['Response Answer']\nc42=c22['Response Answer']\nc43=c23['Response Answer']","d877e6e5":"c41=c41.drop_duplicates().reset_index()\nc42=c42.drop_duplicates().reset_index()\nc43=c43.drop_duplicates().reset_index()","4260f80e":"c41=c41.drop('index', axis=1)\nc42=c42.drop('index', axis=1)\nc43=c43.drop('index', axis=1)","320c0488":"c51 = c41.merge(c42, how='right',on='Response Answer')\nc52 = c51.merge(c43, how='right',on='Response Answer')","f31142ee":"c53 = c52.dropna()\nc53","48e9c3d7":"c53['Response Answer'] = c53['Response Answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\nc53['Response Answer'].head()","7df6e684":"c53['Response Answer'] = c53['Response Answer'].str.replace('[^\\w\\s]','')\nc53['Response Answer'].head()","fc2e8708":"stop = stopwords.words('english')\n\nc53['Response Answer'] = c53['Response Answer'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop));\nc53['Response Answer'].head()","f2cf8509":"freq = pd.Series(' '.join(c53['Response Answer']).split()).value_counts()[:10]\nfreq","d36728c4":"freq = list(freq.index)\nc53['Response Answer'] = c53['Response Answer'].apply(\n    lambda x: \" \".join(x for x in x.split() if x not in freq))\nc53['Response Answer'].head()","4556bcd5":"freq = pd.Series(' '.join(c53['Response Answer']).split()).value_counts()[-10:]\nfreq","8abc76be":"freq = list(freq.index)\nc53['Response Answer'] = c53['Response Answer'].apply(\n    lambda x: \" \".join(x for x in x.split() if x not in freq))\nc53['Response Answer'].head()","0120d05f":"st = PorterStemmer()\nc53['Response Answer'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\nc53['Response Answer'].head()","6ec42aa2":"c53['sentiment'] = c53['Response Answer'].apply(lambda x: TextBlob(x).sentiment[0] )\nc53[['Response Answer','sentiment']].head()","fcf17a22":"c53['scores'] = c53['Response Answer'].apply(lambda x: vader.polarity_scores(x))\nc53['compound']=c53['scores'].apply(lambda score_dict: score_dict['compound']) \nc53['pos']=c53['scores'].apply(lambda score_dict: score_dict['pos'])\nc53['neg']=c53['scores'].apply(lambda score_dict: score_dict['neg']) \nc53['neu']=c53['scores'].apply(lambda score_dict: score_dict['neu'])\nc53=c53.drop('scores',axis=1)\nc53","df2f2413":"c53['sentiment']=c53['sentiment'].astype(float)\nc53.sentiment[c53.sentiment>0]=1\nc53.sentiment[c53.sentiment<0]=-1;","ea161b99":"plt.figure(figsize=(20,8))\nplt.subplot(1,2,1)\nax=sns.countplot(c32['sentiment'],palette='winter')\nax.set_xticklabels(['Negative','Neutral','Positive']);\nplt.ylabel('SENTIMENTAL DISTRIBUTION', fontsize=25)\nplt.title('QUESTION NAME', fontsize=15)\n\nplt.subplot(1,2,2)\nax=sns.countplot(c53['sentiment'],palette='winter')\nax.set_xticklabels(['Negative','Neutral','Positive'])\nplt.title('RESPONSE ANSWER', fontsize=15)\nplt.ylabel('')","255aea57":"#### 2018 - In 2018, around one third of the responce status access was restricted to public.\n#### 2019 - In 2019, the restriction for a public to access responce status got reduced comparatively with the               year 2018.\n#### 2020 - In 2019, the restrcition was removed and made it entirely public. ","293999c2":"### SECTION DISTRIBUTION","4766c160":"## **CITIES DISCLOSING**","b6347d81":"### **CDP OPERATION DISTRIBUTION BASED ON REGION (YEAR - 20-18,19,20)**","960a2334":"## **CDP OPERATION DISTRIBUTION BASED ON COUNTRY(YEAR - 20-18,19,20)**","d08d948f":"## **PROBLEM STATEMENT**\nDevelop a methodology for calculating key performance indicators (KPIs) that relate to the environmental and social issues that are discussed in the CDP survey data. Leverage external data sources and thoroughly discuss the intersection between environmental issues and social issues. Mine information to create automated insight generation demonstrating whether city and corporate ambitions take these factors into account.","17b802a9":"## **CITIES RESPONSES**","f4da0f2a":"## **CITIES:**","3478489e":"## **SENTIMENTAL ANALYSIS ON QUESTION \/ RESPONSE ANSWER:**","0707497a":"## **DESCRIPTION**\n\nCDP is a\u202fglobal\u202fnon-profit that drives companies and governments to reduce their greenhouse gas emissions, safeguard water resources, and protect forests. Each year, CDP takes the information supplied in its annual reporting process and scores companies and cities based on their journey through disclosure and towards environmental leadership.\n\nCDP houses the world\u2019s largest, most comprehensive dataset on environmental action. As the data grows to include thousands more companies and cities each year, there is increasing potential for the data to be utilized in impactful ways. Because of this potential, CDP is excited to launch an analytics challenge for the Kaggle community. Data scientists will scour environmental information provided to CDP by disclosing companies and cities, searching for solutions to our most pressing problems related to climate change, water security, deforestation, and social inequity.\n\nHow do you help cities adapt to a rapidly changing climate amidst a global pandemic, but do it in a way that is socially equitable?\n\nWhat are the projects that can be invested in that will help pull cities out of a recession, mitigate climate issues, but not perpetuate racial\/social inequities?\n\nWhat are the practical and actionable points where city and corporate ambition join, i.e. where do cities have problems that corporations affected by those problems could solve, and vice versa?\n\nHow can we measure the intersection between environmental risks and social equity, as a contributor to resiliency?","d078a90d":"## **PERFORMING SENTIMENTAL ANALYSIS ON QUESTION NAME AND RESPONSE ANSWER:**","273c7ee2":"### PARENT SECTION DISTRIBUTION","d8d3ae87":"### **DISTRIBUTION OF CDP RESPONSE STATUS - PRIVATE\/PUBLIC (YEAR - 20-18,19,20)**"}}