{"cell_type":{"53f93d9d":"code","fc9b64fb":"code","8dd5ec96":"code","6983564a":"code","00e115db":"code","54ce9489":"code","11f13925":"code","53759544":"code","1f10b171":"code","62af5b1b":"code","30d66d30":"code","e1aa8f89":"code","73acb2e2":"code","d7600005":"code","5c31de06":"code","bed891db":"code","b2308533":"code","72044915":"code","da0b9d70":"code","a0d50fa9":"code","edbaa4a7":"code","41eda0d6":"code","75644ca0":"code","fe4feb7a":"code","ed673cd9":"code","8677e7dd":"code","b7337a69":"code","bebead7a":"code","a3b04350":"code","ff5d209a":"code","da5e2bdc":"code","bf8246f4":"code","6d3f92dd":"code","83d6788b":"code","3e520054":"code","1f3b296a":"code","c40b6126":"code","40f3c70d":"code","7c32cbd0":"code","ef54bcbc":"code","3d1b3004":"code","e34e0bf9":"code","387cc6ac":"code","6b876917":"code","f3e935dd":"code","4c25a850":"code","7c021c8d":"code","8a928ab8":"code","49dab9e7":"code","ad9b257e":"code","c6be87e7":"code","1909338b":"code","6ab911b2":"code","8915df41":"code","faddee49":"code","54cdb988":"code","3f716c40":"code","3ee85efb":"code","dc93ba39":"code","c67f66f9":"code","9e955b7d":"code","fff57903":"code","19ea29a3":"code","c6852a70":"code","52d84a21":"code","e333991e":"code","2819b787":"code","1774a7f9":"code","4e2144ce":"code","72323306":"code","c5ce67d4":"code","ed98d613":"code","021196dc":"code","40c8ee5a":"code","2586036f":"code","d964f98a":"code","aee16828":"code","022d5dd3":"code","ae0d62f3":"code","ebf6a396":"code","20990165":"code","9b377d7d":"code","3c59a65a":"code","d5780d63":"code","1f3fa8ce":"code","537736c0":"code","8728ae5d":"code","6bbf781e":"code","d0f9c23b":"code","3e9f4d64":"code","3f33cc31":"code","50507a3f":"code","c22a15fe":"code","8ba69cdb":"code","e831b3a0":"code","6c0e4656":"code","9125ba9d":"code","89f58d05":"code","51329d4b":"code","b171b216":"markdown","61d0c901":"markdown","165d9497":"markdown","78cf6cf0":"markdown","aad5b64f":"markdown","62bcf152":"markdown","a4339d19":"markdown","5f980770":"markdown","73a29975":"markdown","db0e1402":"markdown","90381587":"markdown","274077ee":"markdown","7eed5d80":"markdown","0251a415":"markdown","b5ddb241":"markdown","c4f10d16":"markdown","58c9eb93":"markdown","1ec5baf9":"markdown","98f0044c":"markdown","b27e171d":"markdown","1be3d955":"markdown","a2a8875e":"markdown","d4f2f80c":"markdown","e445d59c":"markdown","b709b48e":"markdown","432f2c38":"markdown","67794b71":"markdown","192a9432":"markdown","3dd91071":"markdown","ebbf27d5":"markdown","785812de":"markdown","ebf7f390":"markdown","21fcb2fc":"markdown","f179aa9b":"markdown","83ebdff3":"markdown","e6ec9dfe":"markdown","f7798433":"markdown"},"source":{"53f93d9d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport cufflinks\nfrom matplotlib.colors import ListedColormap\ncufflinks.go_offline()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nsns.set()","fc9b64fb":"df=pd.read_csv('\/kaggle\/input\/employees-evaluation-for-promotion\/employee_promotion.csv')","8dd5ec96":"df.head(15).style.background_gradient(cmap='YlGnBu',text_color_threshold=0.5)","6983564a":"df.describe().drop(['25%','50%','75%'])","00e115db":"df.info()","54ce9489":"plt.figure(figsize=(15,9))\nsns.heatmap(df.isnull(),cmap='cividis',yticklabels=False,cbar=False)\nplt.title('Heatmap of NaN Values',size=18)\nplt.xticks(rotation=45);","11f13925":"df.isnull().sum()","53759544":"df.dropna(thresh=len(df.columns)-1,inplace=True)\ndf[df.isnull().any(axis=1)]","1f10b171":"df.drop(df[df['education'].isnull()].index,inplace=True)\ndf[df.isnull().any(axis=1)]","62af5b1b":"def refill_score(row):\n    dep=row[0]\n    score=row[1]\n    if pd.isnull(score):\n        return df[df['department']==dep]['avg_training_score'].mean()\n    else:\n        return score","30d66d30":"def refill_rating(row):\n    dep=row[0]\n    rating=row[1]\n    if pd.isnull(rating):\n        return df[df['department']==dep]['previous_year_rating'].mean()\n    else:\n        return rating","e1aa8f89":"%%time\ndf['previous_year_rating']=df[['department','previous_year_rating']].apply(refill_rating,axis=1)","73acb2e2":"%%time\ndf['avg_training_score']=df[['department','avg_training_score']].apply(refill_score,axis=1)","d7600005":"df.reset_index(drop=True,inplace=True)\ndf","5c31de06":"plt.figure(figsize=(15,9))\nsns.heatmap(df.isnull(),cmap='cividis',yticklabels=False,cbar=False)\nplt.title('Heatmap of NaN Values',size=18)\nplt.xticks(rotation=45);","bed891db":"df.drop('employee_id',axis=1,inplace=True)","b2308533":"px.pie(df, values=df['department'].value_counts(), names=df['department'].unique(), title='Departments',width=1000,height=750,color_discrete_sequence=px.colors.sequential.Sunset)","72044915":"plt.figure(figsize=(15,9),dpi=65)\ngp=sns.countplot(data=df,x=df['is_promoted'],hue='gender',palette='Set1')\nfor p in gp.patches:\n    value=p.get_height() \n    if value <0:\n        continue\n    x = p.get_x()+.18\n    y = p.get_y() + p.get_height()+ 750\n    gp.text((x), (y), int(value), fontsize=14,bbox=dict(facecolor='#ccddee', edgecolor='black', boxstyle='round', linewidth=0.65))\nplt.ylabel('Count',size=15)\nplt.xlabel('Not Promoted - Promoted',size=15)\nplt.title('Gender Distribution',size=20)\nplt.legend(title='Gender' ,labels=['Female', 'Male']);","da0b9d70":"fig,axes=plt.subplots(ncols=3,nrows=2,figsize=(15,9),dpi=65)\nax=[axes[0,0],axes[0,1],axes[0,2],axes[1,0],axes[1,1],axes[1,2]]\ntmp_df=df.groupby('is_promoted').mean().reset_index()\n\nfor a,c in zip(ax,tmp_df.iloc[:,1:].columns):\n    gp=sns.barplot(data=tmp_df,y=c,x='is_promoted',ax=a,palette='winter')\n    for p in a.patches:\n            x = p.get_x() + p.get_width()-.48\n            y = p.get_y() + p.get_height()\n            value = str(p.get_height())[:5]\n            a.text(x, y, value, ha=\"left\",fontsize=14,bbox=dict(facecolor='#ccddee', edgecolor='black',boxstyle='round', linewidth=0.45))\n            a.set_xlabel('Not Promoted - Promoted',size=12)\n            \nfig.suptitle('Mean Values', fontsize=20)\nplt.tight_layout();","a0d50fa9":"px.box(df, x='department', y='avg_training_score',color='is_promoted',notched=True,title='Avg Training Scores')","edbaa4a7":"plt.figure(figsize=(18,9),dpi=65)\ngp=sns.countplot(x=df['region'],palette='gnuplot2')\nfor p in gp.patches:\n    value=p.get_height() \n    if value <0:\n        continue\n    x = p.get_x()\n    y = p.get_y() + p.get_height()+ 300\n    gp.text((x), (y), (value), fontsize=12,bbox=dict(facecolor='#ccddee', edgecolor='black', boxstyle='circle', linewidth=0.9))\nplt.xlabel('Regions',size=15)\nplt.ylabel('Counts',size=15)\nplt.title('Region Distribution',size=20)\nplt.xticks(rotation=90);","41eda0d6":"plt.figure(figsize=(15,9))\nsns.heatmap(df.corr(method='pearson'),yticklabels=False,cbar=False,cmap='inferno',annot=True,linewidths=1)\nplt.title('Pearson Correlation',size=20);","75644ca0":"plt.figure(figsize=(15,9))\nsns.heatmap(df.corr(method='spearman'),yticklabels=False,cbar=False,cmap='inferno',annot=True,linewidths=1)\nplt.title('Spearman Correlation',size=20);","fe4feb7a":"plt.figure(figsize=(15,9),dpi=65)\nsns.violinplot(data=df,x=df['education'],y='previous_year_rating',hue='is_promoted',palette='PuBu')\nplt.title('Previous Year Ratings of Educations',size=20);","ed673cd9":"px.scatter(df, x=\"avg_training_score\", y=\"age\", color=\"is_promoted\", marginal_y=\"violin\",\n           marginal_x=\"box\", template=\"simple_white\",height=750,title='Age and Average Training Score')","8677e7dd":"plt.figure(figsize=(15,9),dpi=65)\ngp=sns.histplot(data=df,x='previous_year_rating',bins=5,hue='is_promoted',palette='magma',alpha=.5)\nfor p in gp.patches:\n    value=p.get_height() \n    if value <0:\n        continue\n    x = p.get_x()+.33\n    y = p.get_y() + p.get_height()+ 300\n    gp.text((x), (y), (value), fontsize=14,bbox=dict(facecolor='#ccddee', edgecolor='black', linewidth=0.9))\nplt.title('Previous Year Ratings with Promotion',size=20)\nplt.xlabel('Ratings',size=15);","b7337a69":"values=[]\nfor i in df['region'].unique():\n    not_promoted=df[df['region']==i]['is_promoted'].value_counts()[0]\n    promoted=df[df['region']==i]['is_promoted'].value_counts()[1]\n    score=promoted\/(promoted+not_promoted)\n    values.append(score)\n    ","bebead7a":"plt.figure(figsize=(15,20))\ngp=sns.barplot(y=df['region'].unique(),x=values)\nfor p in gp.patches:\n    value=p.get_width() \n    if value <0:\n        continue\n    x = value\/2\n    y = p.get_y() + p.get_height()-.28\n    gp.text((x), (y), str(value)[:7], fontsize=11,bbox=dict(facecolor='#ccddee', edgecolor='black', boxstyle='round', linewidth=0.2))\nplt.title('Promotion Percentage',size=20)\nplt.legend(loc='upper right' ,labels=['Best = region_4', 'Worst = region_9'])\nplt.ylabel('Regions',size=15)\nplt.xlabel('%',size=15);","a3b04350":"df_r4=df[df['region']=='region_4'].reset_index(drop='True')\n","ff5d209a":"px.parallel_coordinates(df_r4.drop(['age'],axis=1),color='is_promoted',title='Parallel Value Plot of Region 4',color_continuous_scale=px.colors.diverging.Tropic)","da5e2bdc":"px.parallel_categories(df_r4.drop(['region','age','no_of_trainings','previous_year_rating','length_of_service','avg_training_score'],axis=1),title='Parallel Categories Plot of Region 4',color='is_promoted',color_continuous_scale=px.colors.diverging.oxy)","bf8246f4":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()","6d3f92dd":"\ndf_final=pd.get_dummies(df,drop_first=True)","83d6788b":"df_final.head()","3e520054":"sc.fit(df_final.drop('is_promoted',axis=1))\ndf_sc=pd.DataFrame(sc.transform(df_final.drop('is_promoted',axis=1)),columns=df_final.drop('is_promoted',axis=1).columns)\ndf_sc['is_promoted']=df['is_promoted']\n","1f3b296a":"df_sc","c40b6126":"from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV","40f3c70d":"X=df_final.drop(['is_promoted'],axis=1)\ny=df_final['is_promoted']","7c32cbd0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","ef54bcbc":"X_train.shape,y_train.shape,X_test.shape,y_test.shape","3d1b3004":"y_test.value_counts()","e34e0bf9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_roc_curve,plot_precision_recall_curve,roc_auc_score,roc_curve,precision_recall_curve, average_precision_score,plot_precision_recall_curve","387cc6ac":"classifiers=[LogisticRegression(solver='sag'),\n             KNeighborsClassifier(),\n             DecisionTreeClassifier(),\n             RandomForestClassifier(),\n             GradientBoostingClassifier(),\n             QuadraticDiscriminantAnalysis(),\n             LinearDiscriminantAnalysis()]\nnames=[str(i).split('(')[0] for i in classifiers]\n","6b876917":"\ndef predict(clf_list):\n    scores=[]\n    for i in clf_list:\n        i.fit(X_train,y_train)\n        print('                ',i)\n        print('Score =',i.score(X_test,y_test))\n        scores.append(i.score(X_test,y_test))\n        print(confusion_matrix(y_test,i.predict(X_test)))\n        print(classification_report(y_test,i.predict(X_test)))\n        print('*'*80)\n    for i in(scores):\n        print(i)\n    ","f3e935dd":"%%time\npredict(classifiers)","4c25a850":"models=[{'model':LogisticRegression(solver='sag'),\n        'name':'Logistic Regression'},\n        {'model':KNeighborsClassifier(),\n        'name':'KNN'},\n       {'model':DecisionTreeClassifier(),\n        'name':'Decision Tree'},\n       {'model':RandomForestClassifier(),\n        'name':'Random Forest'},\n       {'model':GradientBoostingClassifier(),\n        'name':'Gradient Boosting'},\n       {'model':QuadraticDiscriminantAnalysis(),\n        'name':'Quadratic Discriminant'},\n       {'model':LinearDiscriminantAnalysis(),\n        'name':'Linear Discriminant'}]","7c021c8d":"%%time\nfig, axes = plt.subplots(ncols=1,nrows=2,figsize=(15,24),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\n    \n           \n              \naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve with Default Parameters',size=20)\naxes[0].legend(prop={'size': 15});\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve with Default Parameters',size=20)\naxes[1].legend(prop={'size': 15});\nplt.tight_layout();","8a928ab8":"grid=GridSearchCV(LogisticRegression(),param_grid={'penalty':('l1', 'l2', 'elasticnet', 'none'),\n                                                   'C':[0.00001,0.0001,0.001,0.01,0.1,1],\n                                                   'solver' :('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n                                                   'max_iter':[100,200,300]})","49dab9e7":"grid.fit(X_train,y_train)","ad9b257e":"grid.best_params_","c6be87e7":"{'C': 1e-05, 'max_iter': 100, 'penalty': 'none', 'solver': 'newton-cg'}","1909338b":"models=[{'model':LogisticRegression(solver='sag'),\n         'name':'Logistic Regression'},\n        {'model':LogisticRegression(C= 1e-05, max_iter= 100, penalty= 'none', solver= 'newton-cg'),\n        'name':'Logistic Regression GridSearch'}]\n","6ab911b2":"fig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","8915df41":"grid=GridSearchCV(KNeighborsClassifier(),param_grid={ 'weights' : ('uniform', 'distance'),\n                                                       'metric':('minkowski','manhattan','chebyshev','euclidean'),\n                                                   'algorithm':('auto','ball_tree', 'kd_tree', 'brute' )})","faddee49":"%%time\ngrid.fit(X_train,y_train)","54cdb988":"grid.best_params_","3f716c40":"{'algorithm': 'auto', 'metric': 'manhattan', 'weights': 'uniform'}","3ee85efb":"%%time\nerror_rate=[]\nfor i in np.arange(1,35,3):\n    \n    knn_model=KNeighborsClassifier(n_neighbors=i,metric='manhattan',algorithm='auto',weights='uniform')\n    knn_model.fit(X_train,y_train)\n    y_pred_i=knn_model.predict(X_test)\n    error_rate.append(np.mean(y_pred_i !=y_test))\nimport plotly.express as px\n\nfig = px.line(pd.DataFrame(error_rate),markers=True,title='Error Rate')\n\nfig.show()","dc93ba39":"models=[{'model':KNeighborsClassifier(),\n         'name':'KNeighbors Classifier'},\n        {'model':KNeighborsClassifier(n_neighbors=7,metric='manhattan',algorithm='auto',weights='uniform'),\n        'name':'KNeighborsClassifier GridSearch'}]","c67f66f9":"%%time\nfig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","9e955b7d":"grid=GridSearchCV(DecisionTreeClassifier(),param_grid={'criterion' : ('gini', 'entropy'),\n                                                       'max_depth':range(1,30,2),\n                                                       'splitter':('best','random'),\n                                                       'min_samples_split':np.arange(1,25,2),\n                                                      })","fff57903":"grid.fit(X_train,y_train)","19ea29a3":"grid.best_params_","c6852a70":"{'criterion': 'entropy',\n 'max_depth': 15,\n 'min_samples_leaf': 5,\n 'min_samples_split': 29,\n 'splitter': 'random'}","52d84a21":"models=[{'model':DecisionTreeClassifier(),\n         'name':'Decision Tree Classifier'},\n        {'model':DecisionTreeClassifier(criterion= 'entropy',\n max_depth= 11,\n min_samples_split= 23,\n splitter= 'best'),\n        'name':'Decision Tree Classifier GridSearch'}]","e333991e":"fig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=18)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=18)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","2819b787":"grid=GridSearchCV(RandomForestClassifier(),param_grid={'criterion' : ('gini', 'entropy'),\n                                                       'max_depth':range(1,30,2),'n_estimators':[25,50,100,125,150,250,500],\n                                                        'min_samples_split':[3,11,19,27]})","1774a7f9":"%%time\ngrid.fit(X_train,y_train)","4e2144ce":"grid.best_params_","72323306":"{'criterion': 'entropy',\n 'max_depth': 29,\n 'min_samples_split': 3,\n 'n_estimators': 500}","c5ce67d4":"models=[{'model':RandomForestClassifier(),\n         'name':'Random Forest Classifier'},\n        {'model':RandomForestClassifier(criterion= 'entropy',\n max_depth= 29,\n n_estimators=500,\n    min_samples_split=3),\n        'name':'Random Forest Classifier GridSearch'}]","ed98d613":"%%time\nfig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","021196dc":"grid=GridSearchCV(GradientBoostingClassifier(verbose=1),param_grid={'loss':('deviance', 'exponential'),'n_estimators':[100,500],\n                                                           'criterion' : ('friedman_mse', 'mse')\n                                                           })                                        ","40c8ee5a":"%%time\ngrid.fit(X_train,y_train)","2586036f":"grid.best_params_","d964f98a":"{'criterion': 'mse', 'loss': 'exponential', 'n_estimators': 500}","aee16828":"models=[{'model':GradientBoostingClassifier(),\n         'name':'Gradient Boosting Classifier'},\n        {'model':GradientBoostingClassifier(n_estimators=500,loss= 'exponential',criterion='mse'),\n        'name':'Gradient Boosting Classifier GridSearch'}]","022d5dd3":"%%time\nfig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","ae0d62f3":"grid=GridSearchCV(QuadraticDiscriminantAnalysis(),param_grid={'reg_param':[0.0,.1,.11,.13,.15,.17,.19,.2,.3,.4,.5,.6,.7,.8,.9],\n                                                             'store_covariance':(True,False)\n                                                             })","ebf6a396":"grid.fit(X_train,y_train)","20990165":"grid.best_params_","9b377d7d":"{'reg_param': 0.13, 'store_covariance': True}","3c59a65a":"models=[{'model':QuadraticDiscriminantAnalysis(),\n         'name':'Quadratic Discriminant Analysis'},\n        {'model':QuadraticDiscriminantAnalysis(reg_param=.13,store_covariance=True),\n        'name':'Quadratic Discriminant Analysis GridSearch'}]","d5780d63":"fig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","1f3fa8ce":"grid=GridSearchCV(LinearDiscriminantAnalysis(),param_grid={'solver' : ('svd', 'lsqr', 'eigen'),\n                                                          'n_components' : ['none',1,5,10]})","537736c0":"grid.fit(X_train,y_train)","8728ae5d":"grid.best_params_","6bbf781e":"{'n_components': 1, 'solver': 'svd'}","d0f9c23b":"models=[{'model':LinearDiscriminantAnalysis(),\n         'name':'Linear Discriminant Analysis'},\n        {'model':LinearDiscriminantAnalysis(n_components=1,solver='svd'),\n        'name':'Linear Discriminant Analysis GridSearch'}]","3e9f4d64":"fig, axes = plt.subplots(ncols=2,nrows=1,figsize=(15,9),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve',size=20)\naxes[0].legend(prop={'size': 14})\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve',size=20)\naxes[1].legend(prop={'size': 14})\nplt.tight_layout();","3f33cc31":"classifiers=[LogisticRegression(C= 1e-05, max_iter= 100, penalty= 'none', solver= 'newton-cg'),\n             KNeighborsClassifier(n_neighbors=7,metric='manhattan',algorithm='auto',weights='uniform'),\n            DecisionTreeClassifier(criterion= 'entropy',\n max_depth= 11,\n min_samples_split= 23,\n splitter= 'best'),\n             RandomForestClassifier(criterion= 'entropy',\n max_depth= 29,\n n_estimators=500,\n    min_samples_split=3),\n             GradientBoostingClassifier(n_estimators=500,loss= 'exponential',criterion='mse'),\n             QuadraticDiscriminantAnalysis(reg_param=.13,store_covariance=True),\n             LinearDiscriminantAnalysis(n_components=1,solver='svd')]","50507a3f":"%%time\npredict(classifiers)","c22a15fe":"models=[{'model':LogisticRegression(C= 1e-05, max_iter= 100, penalty= 'none', solver= 'newton-cg'),\n        'name':'Logistic Regression'},\n        {'model':KNeighborsClassifier(n_neighbors=7,metric='manhattan',algorithm='auto',weights='uniform'),\n        'name':'KNN'},\n       {'model':DecisionTreeClassifier(criterion= 'entropy',\n max_depth= 11,\n min_samples_split= 23,\n splitter= 'best'),\n        'name':'Decision Tree'},\n       {'model':RandomForestClassifier(criterion= 'entropy',\n max_depth= 29,\n n_estimators=500,\n    min_samples_split=3),\n        'name':'Random Forest'},\n       {'model':GradientBoostingClassifier(n_estimators=500,loss= 'exponential',criterion='mse'),\n        'name':'Gradient Boosting'},\n       {'model':QuadraticDiscriminantAnalysis(reg_param=.13,store_covariance=True),\n        'name':'Quadratic Discriminant'},\n       {'model':LinearDiscriminantAnalysis(n_components=1,solver='svd'),\n        'name':'Linear Discriminant'}]","8ba69cdb":"%%time\nfig, axes = plt.subplots(ncols=1,nrows=2,figsize=(15,24),dpi=65)\nfor m in models:\n    \n        m['model'].fit(X_train,y_train)\n        y_pred=m['model'].predict(X_test) \n        fpr, tpr, thresholds = roc_curve(y_test, m['model'].predict_proba(X_test)[:,1])\n        precision, recall, _ = precision_recall_curve(y_test,  m['model'].predict_proba(X_test)[:,1])\n        auc = roc_auc_score(y_test,y_pred)\n        ap = average_precision_score(y_test, y_pred)\n        axes[0].plot(fpr,tpr, label=str(m['name'])+'-Auc='+str(auc)[:7])\n        axes[1].plot(recall,precision, label=str(m['name'])+'-AP='+str(ap)[:7])\n    \n           \n              \naxes[0].set_ylabel('True Positive Rate',size=15)\naxes[0].set_xlabel('False Negative Rate',size=15)\naxes[0].set_title('ROC Curve with GridSearch Parameters',size=20)\naxes[0].legend(prop={'size': 15});\naxes[1].set_ylabel('Precision',size=15)\naxes[1].set_xlabel('Recall',size=15)\naxes[1].set_title('Precision-Recall Curve with GridSearch Parameters',size=20)\naxes[1].legend(prop={'size': 15})\nplt.tight_layout();","e831b3a0":"scores=[0.9348908464189966, \n 0.9204327843738032, \n 0.9360398314821907, \n 0.9332631175794714, \n 0.9390080428954424, \n 0.919858291842206, \n 0.9345078513979318]","6c0e4656":"models=(str(i).split('(')[0] for i in classifiers)","9125ba9d":"df_=pd.DataFrame(data=scores,columns=['Score'],index=models)","89f58d05":"df_","51329d4b":"plt.figure(figsize=(15,9),dpi=65)\ngp=sns.barplot(x='Score',y=df_.index,data=df_*100)\nfor p,s in zip(gp.patches,scores):\n        value = str(s*100)[:6]\n        x = p.get_x()+s*100-8\n        y = p.get_y() + p.get_height()-.3\n        \n        gp.text(x, y, value, ha=\"left\",fontsize=15,bbox=dict(facecolor='#ffffff', edgecolor='black',boxstyle='round', linewidth=0.25))\nplt.xlabel('Score',size=15)\nplt.ylabel('Models',size=15)\nplt.title('Accuracy',size=20);","b171b216":"# *Import Libraries*","61d0c901":"## *Parallel Plots of Region 4*","165d9497":"## *Promotion Rate of Regions*","78cf6cf0":"### *Getting Dummies*","aad5b64f":"### GridSearch for Linear Discriminant Analysis\n","62bcf152":"## *Region Distribution*","a4339d19":"# *Exploratory Data Analysis*","5f980770":"### GridSearch for Random Forest","73a29975":"## *Previous Year Ratings of Educations*","db0e1402":"## *Average Training Scores of Departments*","90381587":"### GridSearch for Quadratic Discriminant Analysis","274077ee":"### *Scaling*","7eed5d80":"### GridSearch For KNeighbors Classifier","0251a415":"## *Department Distribution*","b5ddb241":"# *Predictions*","c4f10d16":"## *Correlation*","58c9eb93":"#### *Drop unnecessary column*","1ec5baf9":"## *Average Training Scores with Age*","98f0044c":"### GridSearch for Logistic Regression\n","b27e171d":"# *Handling Missing Values*","1be3d955":"# *Dataset Info*","a2a8875e":"### GridSearch for Decision Tree","d4f2f80c":"# *Preprocessing Data*","e445d59c":"### *Predictions with Default Parameters*","b709b48e":"## *Gender Distribution*","432f2c38":"### *ROC and Precision-Recall Curves*","67794b71":"# *Train-Test Split*","192a9432":"*  employeeid = Unique ID for the employee \n*  department = Department of employee \n*  region = Region of employment (unordered) \n*  education = Education Level \n*  gender = Gender of Employee \n*  recruitmentchannel = Channel of recruitment for employee\n*  no_ of_ trainings = no of other trainings completed in the previous year on soft skills, technical skills, etc.\n*  age = Age of Employee\n*  previous_ year_ rating = Employee Rating for the previous year\n*  length_ of_ service = Length of service in years\n*  awards_ won = if awards won during the previous year then 1 else 0\n*  avg_ training_ score = Average score in current training evaluations\n*  is_promoted = (Target) Recommended for promotion","3dd91071":"### GridSearch for Gradient Boosting","ebbf27d5":"#### *Drop rows that has at least 2 NaN values*","785812de":"## *Mean Values of Columns*","ebf7f390":"# *GridSearchCV*","21fcb2fc":"#### Seems like region_4 has the highest rate.","f179aa9b":"#### *Filling NaN values of previous_year_rating and avg_training score via department*","83ebdff3":"## *Previous Year Rating Distribution*","e6ec9dfe":"### *Import ML Models*","f7798433":"#### *Drop rows where education is Nan*"}}