{"cell_type":{"8ec0d483":"code","def0b21f":"code","1902d24d":"code","bbf38fa3":"code","831267ba":"code","dc17db04":"code","30c962ef":"code","83197b37":"code","3c7374ee":"code","e883c268":"code","6b36e3b0":"code","b0c5f27b":"code","e2dbf2e2":"markdown","9b73de39":"markdown","4da7fe08":"markdown","7bad699b":"markdown","1b4951eb":"markdown","f04f92ea":"markdown","5bad0db6":"markdown","62b63ef8":"markdown","07fe41d1":"markdown","2f08ab5f":"markdown"},"source":{"8ec0d483":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-darkgrid')\nplt.rcParams['figure.figsize'] = (15, 13)\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom plotly import express as px, graph_objects as go\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\nimport gc\ngc.enable()","def0b21f":"%%time\ntrain = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\nsample = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')","1902d24d":"train.drop(['Id', 'Soil_Type7', 'Soil_Type15'], axis = 1, inplace = True)\ntest.drop(['Id', 'Soil_Type7', 'Soil_Type15'], axis = 1, inplace = True)","bbf38fa3":"train = train.loc[train.Cover_Type != 5].reset_index(drop = True)\ntrain","831267ba":"le = LabelEncoder()\ntrain['Cover_Type'] = le.fit_transform(train['Cover_Type'])","dc17db04":"def reduce_memory_usage(df, verbose=True):\n    from tqdm.auto import tqdm\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in tqdm(df.columns):\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","30c962ef":"train = reduce_memory_usage(train)\ntest = reduce_memory_usage(test)","83197b37":"y = train.pop('Cover_Type')\ny","3c7374ee":"FOLDS = 15\nskf = StratifiedKFold(n_splits = FOLDS, random_state = 5, shuffle = True)","e883c268":"help(RandomForestClassifier) # Dokumentasi Random Forest, berisi parameter apa saja yang bisa diubah-ubah supaya bisa mengoptimalkan akurasi.","6b36e3b0":"test_preds = []\nval_preds = pd.Series()\nscores = []\nfor i, (t, v) in enumerate(skf.split(train, y)) :\n    xtrain = train.loc[t, :]\n    xval = train.loc[v, :]\n    xtest = test.copy()\n    ytrain = y.loc[t]\n    yval = y.loc[v]\n    \n    rf = RandomForestClassifier(random_state = 5, n_jobs = -1, verbose = 2, max_depth = None, n_estimators = 150)\n    rf.fit(xtrain, ytrain)\n    yhat = pd.Series(rf.predict(xval), index = v)\n    val_preds = val_preds.append(yhat)\n    ypred = rf.predict(xtest)\n    test_preds.append(ypred)\n    score = accuracy_score(yval, yhat)\n    scores.append(score)\n    print(f'Accuracy {i} : {score}')\n    del xtrain\n    del xval\n    del xtest\n    del ytrain\n    del yval\n    del rf\n    gc.collect()\nval_preds = val_preds.sort_index()\nfrom scipy.stats import mode\ntrain['rf_preds'] = val_preds\ntest['rf_preds'] = mode(test_preds, axis = 0)[0][0]\ntrain.to_csv('rf_train.csv', index = False)\ntest.to_csv('rf_test.csv', index = False)","b0c5f27b":"from scipy.stats import mode\nypreds = mode(test_preds, axis = 0)[0][0]\nsample['Cover_Type'] = le.inverse_transform(ypreds)\nsample.to_csv('submission.csv', index = False)","e2dbf2e2":"# Mengambil Data","9b73de39":"### Ada label yang hanya mengandung 1 sampel, maka di-drop saja","4da7fe08":"### Menghapus kolom yang tidak diperlukan","7bad699b":"# Modelling","1b4951eb":"### Merata - rata hasil dari prediksi menggunakan K-Fold","f04f92ea":"# Import Library","5bad0db6":"### Memisah data yang untuk dibaca dan data yang untuk divalidasi","62b63ef8":"Semangat ;)","07fe41d1":"### Meng-encode label supaya bisa dibaca oleh komputer","2f08ab5f":"### Function untuk mengurangi penggunaan memori karena data ini memakai > 3GB memori"}}