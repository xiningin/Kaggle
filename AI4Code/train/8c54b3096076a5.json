{"cell_type":{"5a33c6d5":"code","1a58f3b8":"code","a133f985":"code","d6e6999b":"code","0c4d6c50":"code","f58b1824":"code","4ed57b39":"code","cacbf4ac":"code","9b6cff98":"code","bcceef0b":"code","8856a747":"code","ea02b286":"code","91e6bc11":"code","9ba7e05d":"code","34d6e0f1":"code","98e5f791":"code","27fd89c4":"code","3db6d4e4":"code","10b68bdd":"code","5c099d30":"code","712d55fb":"code","688d3b6d":"code","1f249ccf":"code","7593232d":"code","c2a3c493":"code","8b96445b":"code","44984cc7":"code","2647def3":"code","343206e9":"code","51828dbc":"code","a9385abe":"code","bf3d1f91":"code","7c9bddd7":"code","5707e1bc":"code","7583ce0d":"code","6f75eb5a":"code","68f4f71b":"code","9b2abfd6":"code","8c5741d8":"code","03b2fc39":"code","f1851ccd":"code","2c7e61c5":"code","0aa415e2":"code","22fc1ffb":"code","2683e076":"code","00e8a50d":"markdown","f281d8ba":"markdown","0ad83d90":"markdown","4eb498fb":"markdown","10460500":"markdown","b5019bb9":"markdown","7cd69a1c":"markdown","6691376d":"markdown","34bf8788":"markdown","c0815fe6":"markdown"},"source":{"5a33c6d5":"import pandas as pd","1a58f3b8":"train_df = pd.read_csv(\"..\/input\/train.csv\")","a133f985":"train_df.head()","d6e6999b":"#Divided the whole table into two sub tables: survived and non-survived\nis_survived_filter = train_df[\"Survived\"] == 1\nnon_survived_filter = train_df[\"Survived\"] == 0\nsurvived = train_df[is_survived_filter]\nnon_survived = train_df[non_survived_filter]","0c4d6c50":"survived.head()","f58b1824":"non_survived.head()","4ed57b39":"train_df.info()","cacbf4ac":"train_df.describe()","9b6cff98":"train_df.describe(include=['O']) ","bcceef0b":"#drop the variable name, because it not relevant to the prediction of survival\n#figure out relevant between survived and each variable (including numerical and caregorical)\n#firstly, discovery the relationship between discrete variables and survived. Including Pclass, Sex, Sibsp, Parch, and Embark.\n#relationship between pclass and survived\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n# there are some correlation between the pclass and survived, so keep the variable pclass","8856a747":"#relationship between sex and survived\ntrain_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n# there are some correlation between the sex and survived, so keep this variable into final model.","ea02b286":"#relationship between sibsp and survived\ntrain_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#do not have any clear correlation, hence drop the Sibsp variable","91e6bc11":"#relationship between parch and survived\ntrain_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#do not have any clear correlation, hence drop the Parch variable ","9ba7e05d":"#relationship between embarked and survived\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n# there are some correlation between the embarked and survived, so keep the embarked variable","34d6e0f1":"# Secondly, print out the relationship between the continuous variable and survived. Including Age and Fare.\n# utilize table (survived and non-survived)","98e5f791":"#the relationship between the age and survived\n#survived passenger age\nage_survived_df = survived.ix[:,['Age', 'Survived']]\nage_survived_df\nhist_survive_age = age_survived_df.hist(column = \"Age\")","27fd89c4":"#non-survived passenger age\nage_non_survived_df = non_survived.ix[:,['Age', 'Survived']]\nage_non_survived_df\nhist_non_survived_age = age_non_survived_df.hist(column = \"Age\")\n#According to compare two histogram of age, we can figure out large part of child (0 to 10) and old people (older than 75) are survived. Hence, the age variable is relevant to the survived.","3db6d4e4":"#relationship between fare and survived\n#survived passenger fare\nfare_survived_df = survived.ix[:,['Fare', 'Survived']]\nfare_survived_df\nhist_survive_fare = fare_survived_df.hist(column = \"Fare\")","10b68bdd":"#non survived passenger fare\nfare_non_survived_df = non_survived.ix[:,['Fare', 'Survived']]\nfare_non_survived_df\nhist_non_survive_fare = fare_non_survived_df.hist(column = \"Fare\")\n#According to compare two histogram of fare, we can figure out passengers who's fare is larger than 250 are almost survived. Hence, the fare variable is relevant to the survived","5c099d30":"#dealing with the missing value\uff0c utilizing mean of each column to impute the missing value\n\nfill_train_df = train_df.fillna(train_df.mean())","712d55fb":"fill_train_df.head()","688d3b6d":"#preparation of the data frame\n\nfill_train_df['Sex'] = fill_train_df['Sex'].map({'female': 1, 'male': 0}).astype(int)\n\nfill_train_df['Embarked'] = fill_train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","1f249ccf":"data_train_df = fill_train_df.drop(columns = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'])","7593232d":"X_train = data_train_df[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\nY_train = data_train_df['Survived']","c2a3c493":"X_train = X_train.fillna(X_train.mean())","8b96445b":"data_train_df.head()","44984cc7":"test_df = pd.read_csv(\"..\/input\/test.csv\")","2647def3":"test_df.head()","343206e9":"test_df['Sex'] = test_df['Sex'].map({'female': 1, 'male': 0}).astype(int)\ntest_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","51828dbc":"data_test_df = test_df.drop(columns = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'])","a9385abe":"final_test_df = data_test_df.fillna(train_df.mean())","bf3d1f91":"combine = [data_train_df, final_test_df]","7c9bddd7":"X_test = final_test_df","5707e1bc":"X_train.shape, Y_train.shape, X_test.shape","7583ce0d":"X_train.head()","6f75eb5a":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier","68f4f71b":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)","9b2abfd6":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier","8c5741d8":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)","03b2fc39":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier","f1851ccd":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)","2c7e61c5":"models = pd.DataFrame({\n    'Model': ['Stochastic Gradient Decent', \n              'Random Forest',\n              'Decision Tree'],\n    'Score': [acc_sgd, acc_random_forest,\n              acc_decision_tree]})\nprint(models.sort_values(by='Score', ascending=False))","0aa415e2":"#because random forest with the highest score, choose the random forest\nrf = RandomForestClassifier(n_estimators=250, max_depth=5, criterion='gini')\nrf.fit(X_train, Y_train)\nY_pred = rf.predict(X_test)","22fc1ffb":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","2683e076":"submission.to_csv(\"submission.csv\")","00e8a50d":"**Take a look of data dictionary**\nPassenger ID\uff1ais not useful variable for prediction of survival\nSurvived: Survival (0 = Not survived, 1 = Survived)\nPclass: Ticket class (1 = 1st class, 2 = 2nd class, 3 = 3rd class)\nName: Paasenger Name\nSex: passenger gender (male \/ female)\nAge: Age in years\nSibSp: # of siblings \/ spouses aboard the Titanic\nParch # of parents \/ children aboard the Titanic\nTicket: Ticket number\nFare: Passenger fare\nCabin: Cabin number\nEmbarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n\n","f281d8ba":"**take a look at numerical data **\n","0ad83d90":"## References\n\nThis notebook has been created based on great work done solving the Titanic competition and other sources.\n\n- [Titanic Data Science Solutions] https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions","4eb498fb":"**upload the test.csv**","10460500":"## Model choosing and comparing\n\ntry to test these three models: Stochastic Gradient Descent, Decision Tree, and Random Forest","b5019bb9":"Titanic Data Science Solutions\nTitanic sinking is one of the most infamous shipwrecks in history. \"On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\" After this disaster, someone collected the data about almost all of passengers personal detail informatin and whether they survive in the end. The following codes are about some analysis of what sorts of people were likely to survive. And I applyied some tools of machine learning to predict which passengers survived the tragedy.\n\nThe following is my code:","7cd69a1c":"## Dig into relationship between each variables and survived data","6691376d":"**take a look at categorical data**","34bf8788":"**According to the analysis about variables seperately, I chose to keep the following variables in the final model: Pclass, Sex, Age, Fare and Embarked**\n\nAnd then, dealing with missing values","c0815fe6":"**First step, upload the train.csv file.**"}}