{"cell_type":{"a3b36d96":"code","754d6fba":"code","ff828364":"code","be9abbb4":"code","deb47e5a":"code","e59f7a88":"code","66bb85c7":"code","e4515f3e":"code","3d8a1791":"code","9bdecd66":"code","80140564":"code","9403882d":"code","dd8e49ad":"code","e7739787":"code","ba6044e5":"code","0fd9c83e":"code","6737d46c":"code","702433f4":"code","cd56f5b7":"code","bfdabd1f":"code","616f85bc":"code","41df7a31":"code","c5d151ae":"code","dbbb855d":"code","93ac0bc7":"markdown","3bfcc361":"markdown","46561819":"markdown","de6443fa":"markdown","0c290ae5":"markdown","982cccb4":"markdown","84e6e38b":"markdown","c088ed9c":"markdown","7999c6cb":"markdown","36153c50":"markdown","9b459ef5":"markdown","5f1336ec":"markdown","d222915d":"markdown","61a97b9e":"markdown","fdafebfe":"markdown","b5409fd1":"markdown","75c99184":"markdown","b8560306":"markdown","aa4f352a":"markdown","3e49f54a":"markdown","f773c5fa":"markdown","a7739110":"markdown","9e5cc99c":"markdown","646b14d6":"markdown","e7f75ed6":"markdown"},"source":{"a3b36d96":"import random, os\nimport numpy as np\nimport torch\nfrom fastai.vision.all import *","754d6fba":"path = Path('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'); path.ls()","ff828364":"data = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\ndls = data.dataloaders(path)","be9abbb4":"dls.valid.show_batch(max_n=12, nrows=2)","deb47e5a":"print(dls.vocab)","e59f7a88":"len(dls.train_ds), len(dls.valid_ds)","66bb85c7":"learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\nlearn.fine_tune(6)","e4515f3e":"learn.save('model_1')","3d8a1791":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","9bdecd66":"interp.plot_top_losses(3, nrows=3)","80140564":"learn = cnn_learner(dls, resnet18, metrics=error_rate)\nlr_min,lr_steep = learn.lr_find()","9403882d":"print(f\"Minimum\/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")","dd8e49ad":"learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\nlearn.fine_tune(6, base_lr=5e-3)","e7739787":"learn.save('model_2')","ba6044e5":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","0fd9c83e":"interp.plot_confusion_matrix(normalize=True, norm_dec=3)","6737d46c":"interp.most_confused(min_val=1)\n\n# Shown is 'ACTUAL, PREDICTED, COUNT'","702433f4":"interp.plot_top_losses(3, nrows=3)","cd56f5b7":"learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\nlearn.fit_one_cycle(3, 5e-3)","bfdabd1f":"learn.unfreeze()","616f85bc":"learn.lr_find()","41df7a31":"learn.fit_one_cycle(5, lr_max=1e-6)","c5d151ae":"learn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\nlearn.fit_one_cycle(3, 5e-3)\nlearn.unfreeze()\nlearn.fit_one_cycle(8, lr_max=slice(5e-3,1e-3))","dbbb855d":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","93ac0bc7":"Now we can find a new learning rate","3bfcc361":"**Fantastic results.**\n\nThis is often why **training a model quickly is a good place to start**. \n\nWhy? Well, it prompts a number of questions:\n\n* Is this score good enough already? \n\n* Do we have time to train more models? \n\n* Is optimization necessary?\n\nThese are all questions the may or may not provide direction in your specific domain. \n\nA fantastic course relevant to my point above is **\"Structuting Machine Learning Projects\"** by **Andrew Ng** on Coursera. \n\nIt focuses on the practical realities of ML tools & products, optimization, setting a basline, and it is a fantastic resource. \n\nHere's a link:\n\nhttps:\/\/www.coursera.org\/learn\/machine-learning-projects\n\n\n\nIn a medical domain, I'd say it is worth spending time to see if we can optimize further, but in some cases, a model such as the one above would be more than sufficient.\n\nNow, where did we go wrong (and right)?","46561819":"Next, unfreeze the model...","de6443fa":"This can be an opportunity to *fix* issues in your dataset. For instance, if an image is incorrectly labelled. \n\nIf you're using scraped data, for instance, this can be a problem. I built a classifier that can classify the Big Cats of Africa, and the amount of domestic cats that snuck in to the dataset was a real headache, so this can be a very important & useful step.\n\nThis relies on **domain expertise** though, so for this case I wouldn't attempt it. However, it is curious that the large white mass in the chest area on those incorrectly classified above do look very similar to the test batch we showed earlier.","0c290ae5":"# Getting the data\n\nI'll get the path for the dataset. This saves reading in data in the usual way, clogging up your notebook with thosands of image paths.","982cccb4":"Observations from these images will be noted below. First, I'll do some more checks to confirm our **categories** are just 'Normal' and 'Pneumonia':","84e6e38b":"And our **dataset length**","c088ed9c":"Fantastic, our model has **improved our accuracy due to changing the learning rate**.\n\nAs an aside, the default value that FastAI uses is 1e-3.","7999c6cb":"# Improving the model\n\nAdjusting the learning rate. If our learning rate is too low, it can take an age train our model. In addition, it means that we might overfit, because every time we do a complete pass through the data, we give our model a chance to memorize it. \n\nSeeing as the model did so well with ResNet18, I will continue to use that.","36153c50":"# Observations\n\nTo the **untrained** eye it is difficult to say with certainty, looking at an X-ray, what visual distinctions there are between 'Normal' and those with 'Pneumonia'.\n\nPerhaps the larger white mass in the chest is indicative of pneumonia, but this is conjecture on my part.\n\nAlso, our validation set is quite a lot smaller than our training set, but this isn't a problem. Actually, we often want our training set to be as large as possible!","9b459ef5":"Again, let's view the **top 3 losses**","5f1336ec":"DataLoader is a class that provides batches of a few items at a time - let's do that","d222915d":"We can also normalize this plot to view the percentages.\n\nThis can be useful to gain perspective. \n\nFor instance, we now see that our **recall is close to 100%** and that **False Negatives only occur 0.02% of the time**","61a97b9e":"We certainly **didn't improve on our earlier results** - although 98% accuracy still can't be considered a poor result!","fdafebfe":"# Discriminative Learning Rates\n\nFastAI lets you pass a Python slice object anywhere that a learning rate is expected. The first value passed will be the learning rate in the earliest layer of the neural network, and the second value will be the learning rate in the final layer. \n\nI'll select a range here based on the plot above. \n\nI will then train for a while to see how the model performs. When our scores are already so high, it is hard to improve, so I am not expecting much improvement, if any, but I want to try this additional step","b5409fd1":"The model didn't perform as well as the models above. \n\nI will now try another method...","75c99184":"# Interpreting the Learner\n\nThe aim is to pick a learning rate that is not too high, and not too low.\n\nThe graph above helps us to ensure we acheive that.\n\nIdeally, we want to pick a point where the Loss is still decreasing, and has not started to increase. Above, that happens at around 10^-1.\n\nThe decrease in Loss starts around 10^-4. I will pick between 10^-3 and 10^-2. \n\nNote that the Learner is on a logarithmic scale, which is why the middle point between 10^-3 and 10^-2 is between 3e-3 and 4e-3. \n\nLet's **re-train the model** for the same number of epochs but with the **new learning rate.**","b8560306":"# Baseline\n\nLet's train a model.\n\nFastAI has several ResNet models in readily available:\n\n* Resnet18\n* Resnet34\n* Resnet50\n* Resnet101\n* Resnet152\n\nThey vary in size, with ResNet152 being trained on the most amount of images. \n\nFor the basline, I will use **ResNet18**","aa4f352a":"Let's save this model, too","3e49f54a":"The results are very good. We managed to **reduce the number of False Positives**. \n\nHowever the False Negatives are still the same. \n\n**We did improve the model** though, which was our aim.\n\nThese misclassifications are shown below explicitly:","f773c5fa":"# Results\n\nWe were able to acheive an **accuracy score of over 99%**\n\nThis was accompanied by high precision & recall, with close to 100% of those with Pneumonia being detected successfully.\n\nFirst, I set a baseline - which scored incredibly highly at the outset. From there, I knew it would be a challenge to improve the score.\n\nNext, I adjuted the learning rate of the model and managed to improve the accuracy by nearly a full percentage point. This happens to be our final model.\n\nI also tried unfreezing the base model, and also implementing disriminative learning rates. Though both of these still scored highly, neither matched up to earlier results. \n\nOverall, I am happy the the model is a success.\n\n# **Thank you for reading**\n\nPlease consider upvoting if you found this notebook helpful.\n\n# Some of my other work\n\n**EDA & Prediction using SMOTE [HR Dataset]**\n\nhttps:\/\/www.kaggle.com\/joshuaswords\/awesome-hr-data-visualization-prediction\n\n\n**Stroke Prediction & Model Interpretation with SHAP, LIME, and ELI5**\n\nhttps:\/\/www.kaggle.com\/joshuaswords\/predicting-a-stroke-shap-lime-explainer-eli5\n\n\n**Beautiful EDA & Clustering [World Happiness Index 2021]**\n\nhttps:\/\/www.kaggle.com\/joshuaswords\/awesome-eda-2021-happiness-population\n\n\n**EDA & Gold Price Prediction using Prophet**\n\nhttps:\/\/www.kaggle.com\/joshuaswords\/eda-gold-price-prediction-prophet\n","a7739110":"I'll save this model now","9e5cc99c":"So we can see here that the **model did very well**. \n\nThe main issuse the model has is producing **False Positives**. 20 Patients would be predicted to have pneumonia when in fact they do not. However, the more important metric in this case is **False Negatives**, of which there are 3. Not perfect, but a very good result overall.\n\nWe do note that we got some incorrect, we can view these explicitly.\n\nHere, I'll choose the **top 3 losses**","646b14d6":"# **Computer Vision using FastAI**\n\nThis notebook will use the FastAI library to complete a computer vision task. \n\nI cannot reccommend the FastAI course highly enough. It's a great entry point in to Neural Networks and Deep Learning in general. Many of the explanations I provide below are snippets from the course.\n\nYou can find more information here:\n\nhttps:\/\/www.fast.ai\/\n\nand the course here:\n\nhttps:\/\/course.fast.ai\/\n\nI reccommend using Google Collab for the course, rather the a jupyter notebook.\n\n# **Project: Pneumonia Prediction**\n\nThe problem: **Can we correctly classify chest X-Rays of patients that have pneumonia & those that do not?**\n\n# Project plan\n\nHere are the steps I plan to follow in this project:\n\n* Import libraries & data\n\n* Data overview - Show a few images, check classes, length of dataset etc.\n\n* Train a model as a basline\n\n* Assess model misclassifications\n\n* Model tuning:\n    - Plot learning rates\n    - Unfreeze the ResNet model\n    - Use discriminative learning rates\n    \nIt's also worth noting that I am following the above steps in order to gain more experience with FastAI - the particular steps I take may or may not be neccesary, I just want to utilise the various tools that FastAI offers.\n\n\n# Importing the libraries","e7f75ed6":"# How many epochs to train for?\n\nYour first approach to training should be to simply pick a number of epochs that will **train in the amount of time you're willing to wait**.\n\nThen look at the training and validation loss plots and in particular **your metrics**. If you see that they are still getting better even in your final epochs, then you know that you have not trained for too long.\n\n**Remember, it's not just that we're looking for the validation loss to get worse, but the actual metrics**. This is an important realisation and can change how you approach machine learning & deep learning problems. If your desired metrics are improving, on the validation or test set, then that is the most important factor.\n\nThe loss function is just something that we use to allow our optimizer to have something it can differentiate and optimize; it's not actually the thing we care about in practice.\n\n# Unfreezing the model\n\nA pre trained model, such as the ResNet model we are using here, can be used on data other than the data it was trained on - this is **transfer learning**\n\n\n\nBecause the model was trained on some other dataset, we might be able to improve it by effectivley removing the final linear layer of the model - which is specifically designed to classify the categories in the original pretraining dataset - and replace it with a layer specific to our dataset.\n\n\nFrom FastAI:\n\n*We want to train a model in such a way that we allow it to remember all of these generally useful ideas from the pretrained model, use them to solve our particular task, and only adjust them as required for the specifics of our particular task.*\n\n*Our challenge when fine-tuning is to replace the random weights in our added linear layers with weights that correctly achieve our desired task without breaking the carefully pretrained weights and the other layers. There is actually a very simple trick to allow this to happen: tell the optimizer to only update the weights in those randomly added final layers. Don't change the weights in the rest of the neural network at all. This is called freezing those pretrained layers.*\n\nWhen we call the fine_tune method FastAI does two things:\n\n* Trains the randomly added layers for one epoch, with all other layers frozen\n* Unfreezes all of the layers, and trains them all for the number of epochs requested\n\nLet's try that..."}}