{"cell_type":{"4fca1e3f":"code","503ad775":"code","db5e9f6d":"code","1b5c1a56":"code","332cc0e6":"code","90470c33":"code","7159be77":"code","a685cf57":"code","0d2e0509":"code","b3c6b214":"code","3912cbd9":"code","92775a87":"code","726f18ed":"code","9d1f1622":"code","17266444":"code","3bd8cd83":"code","13d01b77":"code","ca997ba9":"code","028ae2bc":"code","78da76f5":"markdown","a0674bbd":"markdown","324ed2f3":"markdown","785ce092":"markdown","4ba2aaa5":"markdown","7a49c11e":"markdown","c2df0c40":"markdown","f7a409af":"markdown","3ad56f9f":"markdown","5812e84b":"markdown","7c267c00":"markdown","f8b54577":"markdown","17c152d6":"markdown","6a439b9b":"markdown","d9b60d1a":"markdown","56e9419f":"markdown","7df3ea6e":"markdown","1fd2aaf8":"markdown","10c60613":"markdown","b5195326":"markdown","fb44b6a4":"markdown","8e327e1a":"markdown","970bd527":"markdown","eca0b766":"markdown","40194fd5":"markdown"},"source":{"4fca1e3f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statistics import mean, stdev\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) ","503ad775":"diabetes = pd.read_csv(\"\/kaggle\/input\/diabetes-data-set\/diabetes.csv\")","db5e9f6d":"diabetes.head()","1b5c1a56":"diabetes.info()","332cc0e6":"diabetes.describe()","90470c33":"diabetes.drop_duplicates()","7159be77":"#first store the features in a seperate dataframe.\nfeatures = diabetes.drop(\"Outcome\",axis = 1).copy()\n#Now plot a boxplot to identify the outliers in our features.\nsns.boxplot(data = features, orient = 'h', palette = 'Set3', linewidth = 2.5 )\nplt.title(\"Features Box Plot\")","a685cf57":"\nsns.boxplot(x = diabetes[\"Outcome\"], orient = 'h', linewidth = 2.5 )\nplt.title(\"Target Column Box Plot\")\nplt.show()","0d2e0509":"from scipy import stats\ndef removeoutliers(df=None, columns=None):\n    for column in columns:\n        Q1 = df[column].quantile(0.25)\n        Q3 = df[column].quantile(0.75)\n        IQR = Q3 - Q1\n        floor, ceil = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n        df[column] = df[column].clip(floor, ceil)\n        print(f\"The columnn: {column}, has been treated for outliers.\\n\")\n    return df\ndiabetes = removeoutliers(diabetes,[col for col in features.columns])","b3c6b214":"sns.boxplot(data = diabetes, orient = 'h', palette = 'Set3', linewidth = 2.5 )\nplt.title(\"Box Plot after treating outliers\")","3912cbd9":"diabetes.hist(bins = 10, figsize = (10,10))\nplt.show()","92775a87":"sns.countplot('Outcome',data=diabetes)","726f18ed":"print('Outcome Class Ratio:',sum(diabetes['Outcome'])\/len(diabetes['Outcome']))","9d1f1622":"#plot the heatmap\nsns.heatmap(diabetes.corr())","17266444":"y = diabetes.loc[:,'Outcome']\nX = diabetes.drop(['Outcome'],axis = 1).copy()\nX.head()","3bd8cd83":"scaler = StandardScaler()\nscaled_X = scaler.fit_transform(X)","13d01b77":"def train_model(model_name,model):\n  \n    # Create StratifiedKFold object.\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n    accuracy = []\n  \n    for train_index, test_index in skf.split(X, y):\n        x_train_fold, x_test_fold = scaled_X[train_index], scaled_X[test_index]\n        y_train_fold, y_test_fold = y[train_index], y[test_index]\n        model.fit(x_train_fold, y_train_fold)\n        accuracy.append(model.score(x_test_fold, y_test_fold))\n  \n    # Print the output.\n    print(f'The model {model_name} has an Average Accuracy:',round(mean(accuracy)*100,2), '%')\n    print('\\nMaximum Accuracy that can be obtained:',round(max(accuracy)*100,2), '%')\n    print('\\nStandard Deviation:', stdev(accuracy))\n    print('\\n\\n\\n')","ca997ba9":"models = {}\nmodels[\"'Logistic Regression'\"] = LogisticRegression(random_state = 12345)\nmodels[\"'K Nearest Neighbour'\"] = KNeighborsClassifier()\nmodels[\"'Decision Tree'\"] = DecisionTreeClassifier(random_state = 12345)\nmodels[\"'Random Forest'\"] = RandomForestClassifier(random_state = 12345)\nmodels[\"'SVM'\"] = SVC(gamma='auto', random_state = 12345)\nmodels[\"'XGB'\"] = GradientBoostingClassifier(random_state = 12345)\nmodels[\"'LightGBM'\"] = LGBMClassifier(random_state = 12345)\n","028ae2bc":"for key, values in models.items():\n    train_model(key,values)","78da76f5":"#### 6.1 Remove the target column from the dataset","a0674bbd":"#### 6.3 Stratified KFold \n\nWe will use Stratified KFold to split our data because our dataset is small and the Outcome column is inbalanced. The Stratified KFold splits the data into equal portions of test train data according to the ration of target column.","324ed2f3":"#### 6.2 Normalize the feature values\n\nNow we will normalize the feature values using sklearn Standard Scaler for effective computations.","785ce092":"From the heatmap, we can see that the Glucose column has the strongest correlation with our target column.","4ba2aaa5":"Our target column does not contain outliers. Now let's treat our feature columns for outliers.","7a49c11e":"#### 5.2 Checking the Correlation of columns with each other","c2df0c40":"#### 4.1 Outliers\nChecking for outliers using the box plot.","f7a409af":"## 7. Building the Classification Models","3ad56f9f":"In this section we will plot the distribution of each column and see which column has uniform distribution,skew or semi skewed distributions.","5812e84b":"## 2. Loading the Dataset","7c267c00":"By inspection, dataset has no missing values. Let's check out for Duplicates and Outliers.","f8b54577":"Our Outcome column is inbalanced. The number of people that don't have diabetes are in higher ratio than the number of people that have diabetes. We can calculate the ratio using the following method.","17c152d6":"## 4. Data Preprocessing","6a439b9b":"#### 5.1 Distribution of our dataset columns","d9b60d1a":"## 6. Preparing the Data for Model Building\n\n","56e9419f":"Now we will find the correlation of our features with each other and with the target column using the seaborn heatmap library.","7df3ea6e":"# Diabetes Prediction using Top Classification Models \n\nThe objective of this project is to predict whether a patient have diabetes or not using the features given in the dataset.","1fd2aaf8":"## Data Description\n\nSeveral constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\nNumber of Instances: 768 <br>\nNumber of Attributes: 8 plus class <br>\nFor Each Attribute: (all numeric-valued)\n\n* **Pregnancies:** Number of times pregnant\n* **Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* **BloodPressure:** Diastolic blood pressure (mm Hg)\n* **SkinThickness:** Triceps skin fold thickness (mm)\n* **Insulin:** 2-Hour serum insulin (mu U\/ml)\n* **BMI:** Body mass index (weight in kg\/(height in m)^2)\n* **DiabetesPedigreeFunction:** Diabetes pedigree function\n* **Age:** Age (years)\n* **Outcome:** Class variable (0 or 1)\n\n","10c60613":"Our features contain so many outliers. Let's check our target column for outliers using the boxplot.","b5195326":"## 3. Inspecting the Dataset","fb44b6a4":"## 1. Import the important Libraries","8e327e1a":"Now since we have cleaned and explored out data, we can now build up our model.","970bd527":"## 5. Exploratory Data Analysis","eca0b766":"We can see that the Glucose, Blood Pressure, and BMI columns have the normal distribution while the rest have skewed distributions.","40194fd5":"The Data Cleaning part is done here. Now we will move to Exploratory Data Analysis part."}}