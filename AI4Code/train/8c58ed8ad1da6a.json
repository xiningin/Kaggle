{"cell_type":{"1a1b666f":"code","e82d8187":"code","13bf1d3f":"code","a50e0c48":"code","5f4bf178":"code","1525803c":"code","065647c8":"code","81db6fa5":"code","dba75d05":"code","7b9a8e3e":"code","bf855c9b":"code","6b6d0059":"code","99d8d344":"code","8b276d56":"code","20bd6863":"code","4d495338":"code","ce0575b9":"code","d6c5f183":"code","e788de50":"code","4d610672":"code","6a7628ac":"code","301054cc":"code","bf143fd4":"code","6d054cb4":"code","29e4bb81":"code","3a27d979":"code","68de3a9d":"code","e1bce074":"code","450bc280":"code","f4719c71":"code","7b3c6d19":"code","273e9f13":"code","5a699b8e":"code","24366d4d":"code","0e55420f":"code","563ff4ad":"code","14c01208":"code","b3cfc872":"code","4be93c9a":"code","12af67cd":"code","45d5c28a":"code","8bb91aba":"code","d13d93c1":"code","c7c35866":"code","e812cb13":"code","7760646c":"code","1e51901c":"code","279cadb1":"code","c64a13db":"code","db6a8317":"code","699dd29f":"code","b238e17a":"code","2c7143ec":"code","c9315fc0":"code","5eccdf4d":"code","c261a63b":"code","7683bf26":"code","dd0e2fe0":"code","9d509e87":"code","87ee16dd":"markdown","cc2d0261":"markdown","a4571a91":"markdown","3870a729":"markdown","b8f74835":"markdown","7986a09c":"markdown","deecf64e":"markdown","b24d58fc":"markdown","8edbb0ce":"markdown","194e0702":"markdown","3eed9ebf":"markdown"},"source":{"1a1b666f":"# Import all necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","e82d8187":"df=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","13bf1d3f":"df.head()","a50e0c48":"df.drop(['Id'],axis=1)","5f4bf178":"df.corr()['SalePrice'].sort_values()","1525803c":"#removing outliers which are founded in the previous notebook\nindex_drop=df[df['SalePrice']>650000 ].index\ndf=df.drop(index_drop, axis=0)\nindex_drop1=df[(df['OverallQual']>8) & (df['SalePrice']<200000)].index\ndf=df.drop(index_drop1, axis=0)","065647c8":"df.corr()['SalePrice'].sort_values()","81db6fa5":"#Dealing with Missing Data\n#number of missing Data in each columns:\ndf.isnull().sum().sort_values()","dba75d05":"#Make a Function to calculate the percent of missing data in each columns (feature) and then sort it\ndef missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","7b9a8e3e":"nan_percent= missing_percent(df)","bf855c9b":"plt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","6b6d0059":"#removing the row with missing Data of Electrical:\ndf=df.dropna(axis=0, subset=['Electrical'])","99d8d344":"#filling a missing Data with 0 for integer feature and None for object one:\ndf['MasVnrType']= df['MasVnrType'].fillna('None')\ndf['MasVnrArea']= df['MasVnrArea'].fillna(0)","8b276d56":"bsm=['BsmtQual','BsmtCond','BsmtFinType1','BsmtExposure','BsmtFinType2']\ndf[bsm]=df[bsm].fillna('None')","20bd6863":"garage=['GarageType','GarageFinish','GarageQual','GarageCond']\ndf[garage]=df[garage].fillna('None')","4d495338":"#replace the amount of missing Data with mean of the GarageYrBlt:\ndf['GarageYrBlt']=df['GarageYrBlt'].fillna(value=df['GarageYrBlt'].mean())","ce0575b9":"df.groupby('Neighborhood')['LotFrontage'].mean()","d6c5f183":"df['LotFrontage']=df.groupby('Neighborhood')['LotFrontage'].transform(lambda val: val.fillna(val.mean()))","e788de50":"df['FireplaceQu']= df['FireplaceQu'].fillna('None')","4d610672":"df=df.drop(['Fence','Alley','MiscFeature','PoolQC'],axis=1)","6a7628ac":"nan_percent= missing_percent(df)\nnan_percent","301054cc":"#Dealing with Categorical Data\n#Convert to String:\ndf['MSSubClass']= df['MSSubClass'].apply(str)","bf143fd4":"# B- Creating Dummy Variables:\ndf.select_dtypes(include='object')","6d054cb4":"df_num= df.select_dtypes(exclude='object')\ndf_obj= df.select_dtypes(include='object')","29e4bb81":"# Converting:\ndf_obj= pd.get_dummies(df_obj, drop_first=True)","3a27d979":"#merge numeial and objective dataframes together:\nFinal_df= pd.concat([df_num, df_obj], axis=1)\nFinal_df.head()","68de3a9d":"#Determine the Features & Target Variable\nX=Final_df.drop('SalePrice',axis=1)\ny=Final_df['SalePrice']","e1bce074":"# Preprocessing\nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_converter=PolynomialFeatures(degree=2, include_bias=False)\npoly_features=polynomial_converter.fit(X)\npoly_features=polynomial_converter.transform(X)","450bc280":"# Split the Data to Train & Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","f4719c71":"# Train the Model\nfrom sklearn.linear_model import LinearRegression\npolymodel=LinearRegression()\npolymodel.fit(X_train, y_train)","7b3c6d19":"# Predicting Test Data\ny_pred=polymodel.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred, 'Residuals':(y_test-y_pred) }).head(5)","273e9f13":"# Evaluating the Model\nfrom sklearn import metrics\nMAE_Poly = metrics.mean_absolute_error(y_test,y_pred)\nMSE_Poly = metrics.mean_squared_error(y_test,y_pred)\nRMSE_Poly = np.sqrt(MSE_Poly)\n\npd.DataFrame([MAE_Poly, MSE_Poly, RMSE_Poly], index=['MAE_Poly', 'MSE_Poly', 'RMSE_Poly'], columns=['metrics'])","5a699b8e":"So linear Regression can work better on this dataset","24366d4d":"del df","0e55420f":"# Adjusting Model Parameters\n# Train List of RMSE per degree\ntrain_RMSE_list=[]\n#Test List of RMSE per degree\ntest_RMSE_list=[]\n\nfor d in range(1,3):\n    \n    #Preprocessing\n    #create poly data set for degree (d)\n    polynomial_converter= PolynomialFeatures(degree=d, include_bias=False)\n    poly_features= polynomial_converter.fit(X)\n    poly_features= polynomial_converter.transform(X)\n    \n    #Split the dataset\n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n    #Train the Model\n    polymodel=LinearRegression()\n    polymodel.fit(X_train, y_train)\n    \n    #Predicting on both Train & Test Data\n    y_train_pred=polymodel.predict(X_train)\n    y_test_pred=polymodel.predict(X_test)\n    \n    #Evaluating the Model\n    \n    #RMSE of Train set\n    train_RMSE=np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    \n    #RMSE of Test Set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n      #Append the RMSE to the Train and Test List\n    \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","563ff4ad":"pd.DataFrame({'train_RMSE_list': train_RMSE_list,'test_RMSE_list':test_RMSE_list})","14c01208":"#**Plot the Polynomial degree VS RMSE**\n\nplt.plot(range(1,3), train_RMSE_list[:13], label='Train RMSE')\nplt.plot(range(1,3), test_RMSE_list[:13], label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","b3cfc872":"#Preprocessing\nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_converter= PolynomialFeatures(degree=1, include_bias=False)\npoly_features= polynomial_converter.fit_transform(X)","4be93c9a":"# Split the Data to Train & Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","12af67cd":"# Scaling the Data\nfrom sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(X_train)\nX_train= scaler.transform(X_train)\nX_test= scaler.transform(X_test)","45d5c28a":"#Train the Model\nfrom sklearn.linear_model import Ridge\nridge_model= Ridge(alpha=10)\nridge_model.fit(X_train, y_train)","8bb91aba":"#predict Test Data\ny_pred= ridge_model.predict(X_test)","d13d93c1":"#Evaluating the Model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nMAE_Ridge= mean_absolute_error(y_test, y_pred)\nMSE_Ridge= mean_squared_error(y_test, y_pred)\nRMSE_Ridge= np.sqrt(MSE_Ridge)\npd.DataFrame([MAE_Ridge, MSE_Ridge, RMSE_Ridge], index=['MAE_Ridge', 'MSE_Ridge', 'RMSE_Ridge'], columns=['metrics'])","c7c35866":"#Ridge Regression (Coosing an alpha value with Cross-Validation\n #Train the Model\nfrom sklearn.linear_model import RidgeCV\nridge_cv_model=RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error')\nridge_cv_model.fit(X_train, y_train)","e812cb13":"ridge_cv_model.alpha_","7760646c":"#Predicting Test Data\ny_pred_ridge= ridge_cv_model.predict(X_test)","1e51901c":"MAE_ridge= mean_absolute_error(y_test, y_pred_ridge)\nMSE_ridge= mean_squared_error(y_test, y_pred_ridge)\nRMSE_ridge= np.sqrt(MSE_ridge)\npd.DataFrame([MAE_ridge, MSE_ridge, RMSE_ridge], index=['MAE_ridge_CV', 'MSE_ridge_CV', 'RMSE_ridge_CV'], columns=['Ridge Metrics'])","279cadb1":"ridge_cv_model.coef_","c64a13db":"from sklearn.linear_model import LassoCV\nlasso_cv_model= LassoCV(eps=0.01, n_alphas=100, cv=5)\nlasso_cv_model.fit(X_train, y_train)","db6a8317":"lasso_cv_model.alpha_","699dd29f":"y_pred_lasso= lasso_cv_model.predict(X_test)\nMAE_Lasso= mean_absolute_error(y_test, y_pred_lasso)\nMSE_Lasso= mean_squared_error(y_test, y_pred_lasso)\nRMSE_Lasso= np.sqrt(MSE_Lasso)","b238e17a":"pd.DataFrame([MAE_Lasso, MSE_Lasso, RMSE_Lasso], index=['MAE_Lasso', 'MSE_Lasso', 'RMSE_Lasso'], columns=['Lasso Metrics'])","2c7143ec":"lasso_cv_model.coef_","c9315fc0":"from sklearn.linear_model import ElasticNetCV\nelastic_model= ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],cv=5, max_iter=100000)\nelastic_model.fit(X_train, y_train)","5eccdf4d":"elastic_model.l1_ratio_","c261a63b":"y_pred_elastic=elastic_model.predict(X_test)","7683bf26":"MAE_Elastic= mean_absolute_error(y_test, y_pred_elastic)\nMSE_Elastic= mean_squared_error(y_test, y_pred_elastic)\nRMSE_Elastic= np.sqrt(MSE_Elastic)","dd0e2fe0":"pd.DataFrame([MAE_Elastic, MSE_Elastic, RMSE_Elastic], index=['MAE_Elastic', 'MSE_Elastic', 'RMSE_Elastic'], columns=['Elastic Metrics'])","9d509e87":"elastic_model.coef_","87ee16dd":"Now there is no missing data anymore.","cc2d0261":"1- Dealing with Outliers","a4571a91":"**3- Elastic Net**","3870a729":"**2- Lasso Regression**","b8f74835":"**Starting Regularization:**","7986a09c":"# Starting Polynomial Model","deecf64e":"This notebook is a continuation of my previous notebook 'Data preparation & regression1(exercise)' and studies Polynomial regression and regularization on 'house-prices-advanced-regression-techniques' Dataset. ","b24d58fc":"According the result of model's metrics ,the linear regression is the best.","8edbb0ce":"\n**1- Ridge Regression**","194e0702":"\n            Quantity\nMAE_linear\t0.089358\n\nMSE_linear\t0.017944\n\nRMSE_linear\t0.133957","3eed9ebf":"It shows polynomial cant not help to redious errores"}}