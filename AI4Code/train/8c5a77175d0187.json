{"cell_type":{"65d1a58a":"code","c11022d1":"code","3f3092ed":"code","1706a6e6":"code","c0683528":"code","57d7f1e7":"code","7451bdbc":"code","7e141766":"code","38241bbc":"code","9577c42e":"code","ad304607":"code","d8e71dae":"code","77141961":"code","07f409bf":"code","bc011f90":"code","6019b7e0":"code","4f0d8b56":"code","877a95e8":"code","a533f968":"code","464e8958":"code","71367ec5":"code","f6b7714c":"markdown","5be0a6fa":"markdown","a2cc7f13":"markdown","49cb0bf1":"markdown","43dba21f":"markdown","a7079167":"markdown","bd97571e":"markdown","7f6a6d04":"markdown","8e48c719":"markdown","33c4300d":"markdown","b91df041":"markdown","0327acda":"markdown","4e6cb744":"markdown"},"source":{"65d1a58a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c11022d1":"from os import getcwd, chdir\nimport pathlib\npath = '\/kaggle\/input\/'\nchdir(path)\nprint(getcwd())\n\n#Current Directory","3f3092ed":"data_root = pathlib.Path(getcwd()+'\/intel-image-classification\/seg_train\/seg_train')\nprint ()","1706a6e6":"import random\n\n# create list of all image paths under data_root in 'pathlib.PosixPath' type\nall_image_paths = list(data_root.glob('*\/*'))\nprint(type(all_image_paths[0]))\nprint(all_image_paths[0])\n# convert path list from 'pathlib.PosixPath' type to string\nall_image_paths = [str(path) for path in all_image_paths]\nprint(type(all_image_paths[0]))\nprint(all_image_paths[0])\n# shuffle up image paths. This is mostly to view a variety of images during data\n# investigation. Final dataset will be shuffled again during training\nrandom.seed(0)\nrandom.shuffle(all_image_paths) \n\nimage_count = len(all_image_paths)\nimage_count","c0683528":"all_image_paths[:10] # Verify paths are as expected","57d7f1e7":"import IPython.display as display\nfor n in range(3):\n  image_path = random.choice(all_image_paths)\n  display.display(display.Image(image_path))\n  print(image_path)\n  print()","7451bdbc":"# Importing the Keras libraries and packages\n\nfrom keras.models import Sequential   \nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras import regularizers\nfrom keras import optimizers as Optimizer\nfrom keras.layers import Dropout\n\n\nfrom keras.models import load_model\nimport keras.backend as K\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom matplotlib import image\nimport matplotlib.pyplot as plt\n","7e141766":"\n#Sequential function is used to initialize the neural networks [CNN]\nmodel = Sequential()","38241bbc":"#Three Convolution Layers are built below\n\n#Convolution layer is built\nmodel.add(Conv2D(128, (5, 5), activation='relu',input_shape=(150, 150, 3),padding='same',kernel_regularizer=regularizers.l2(0.0025)))\n#Input Shape is 150 * 150 as the dimension is same and the thrid layer is 3 as this is a RGB scenario\n#Feature maps: Input Image * Featue detector [128 in this case]\n#Dimension of feature detecor taken: No of Rows and Coloumn in Feature Detectors [5*5]\n#Activation Layer: Rectfier\n#Rectifier is applied to increase nonlinearity to our network\n#Padding is used instead of Strdie and Regularization is also used \n\n\nmodel.add(MaxPooling2D((3, 3)))\n#Max Pooling helps us to preserve major features despite reducing the 75% of content\n#Max Pooling reduces the no of parameters and helps to prevent over fititng\n#Max pooling of 3*3 is used here\n\nmodel.add(Dropout(0.5))\n#Dropout Regularization is used to reduce overfitting if needed\n#In each iteration, some neurons from ANN are randomly disabled to prevent any form of interdepedency\n","9577c42e":"#Two more layers are built similarly\nmodel.add(Conv2D(128, (5, 5), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.0025)))\nmodel.add(MaxPooling2D((5, 5)))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(256, (5, 5), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.0025)))\nmodel.add(MaxPooling2D((2, 2)))","ad304607":"model.add(Flatten())\n#All the ouputs of convolution layer is converted to 1D array by flattening\n#This Array will be feaded to hidden layer as inputs","d8e71dae":"#Fully connected Dense layer \nmodel.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.002)))\n#Units: 256\n#Usually taken on the basis of Average of Input and Output. Output is 6 in our case \n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.002)))\nmodel.add(Dense(6, activation='softmax'))\n#Last layer activation is softmax as the output categories is more than two","77141961":"model.compile(loss='categorical_crossentropy',\n              optimizer=Optimizer.Adam(lr=0.0008),\n              metrics=['acc'])\n\n#Optimizier: Adam\n#Stochastic Gradient Descent is used\n#Loss: Categorical cross entropy as the depedent variable is more than two\n#Regularization is used","07f409bf":"model.summary()","bc011f90":"#Data Augmentation is done on the training set below\n\n#Image Augmentation is used to increase the variations of images by fliping, rotating, shifting and etc\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\n\n#train_datagen = ImageDataGenerator(rescale=1.\/255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,)\n\ntrain_dir = 'intel-image-classification\/seg_train\/seg_train'\ntrain_validation = 'intel-image-classification\/seg_test\/seg_test'\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=100,\n    class_mode='categorical')\n\n","6019b7e0":"# Note that the validation data shouldn't be augmented!\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\nvalidation_generator = test_datagen.flow_from_directory(\n        train_validation,\n        target_size=(150, 150),\n        batch_size=100,\n        class_mode='categorical')\n\n#Until now the neural network is built without any connection. The fit function helps to connect with the training set\n#Batch size is 100\n#Epochs: How many time the model must run\n#Epochs: 100 in our case \n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=14000\/100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=3000\/100)\n","4f0d8b56":"#Plotting Training and Validation Accuracy and Losses\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n","877a95e8":"from os import getcwd, chdir\nimport pathlib\n\n\nlabel_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\ntrain_size = sum([len(list(pathlib.Path(train_dir,label).iterdir())) for label in label_names])\nval_size = sum([len(list(pathlib.Path(train_validation,label).iterdir())) for label in label_names])","a533f968":"\nfrom keras.models import load_model\nimport keras.backend as K\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom matplotlib import image\nimport matplotlib.pyplot as plt\n\n\n#val_size = sum([len(list(Path(validation_dir,label).iterdir())) for label in label_names])\n\nsteps_per_epoch = train_size \/ 100\nvalidation_steps = val_size \/ 100\nprint(steps_per_epoch)\nprint(validation_steps)\n\n\n\n\ntest_labels = validation_generator.labels\ntest_images = np.array([image.imread(fpath) for fpath in validation_generator.filepaths])\npredictions = model.predict_generator(validation_generator, steps=validation_steps)\npred_labels = np.argmax(predictions, axis = 1)","464e8958":"#Confusion Matrix\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n \n\n#This function prints and plots the confusion matrix.\n#Normalization can be applied by setting `normalize=True\n        \n    \n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized\")\n    #else:\n        #print('Not Normalized')\n\n    #print(cm)\n    fig, ax = plt.subplots()\n    #fig = plt.figure(figsize=(15,5))\n    #plt.subplot(1,2,1)\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n            \n    fig.tight_layout()\n    return ax","71367ec5":"# Note the mountain\/glacier, building\/street, sea\/glacier confusion. \nplot_confusion_matrix(test_labels, pred_labels, classes=label_names, title='Not Normalized')\nplot_confusion_matrix(test_labels, pred_labels, classes=label_names, normalize=True, title='Normalized')","f6b7714c":"                                                    Hidden Layer\n\n![image.png](attachment:image.png)","5be0a6fa":"                         Input image conversion to rows and column of 0's and 1's\n\n\n![image.png](attachment:image.png)\n\n                                                                         Source: Towards Data Science\n","a2cc7f13":"                                                Flattening\n\n![image.png](attachment:image.png)","49cb0bf1":"                                               Pooling\n\n![image.png](attachment:image.png)","43dba21f":"CNN Steps\n\n> Step 1: Intializing Neural Network\n\n> Step 2: Adding Convolution Layers \n\n> Step 2a: Adding ReLu Layer\n\n> Step 3: Pooling\n\n> Step 4: Flattening\n\n> Step 5: Building Hidden Layer","a7079167":"![image.png](attachment:image.png)","bd97571e":"                                                CNN intuition","7f6a6d04":"                                               ReLu Layer\n\n![image.png](attachment:image.png)","8e48c719":"![image.png](attachment:image.png)","33c4300d":"                                               Convolution Step\n\n![image.png](attachment:image.png)","b91df041":"Data Preprocessing\n\n> Checking if the directory is set correctly \n\n> Checking the total no of images in Training dataset\n\n> Printing random images from Training dataset","0327acda":"                                       Neural Network until now","4e6cb744":"A basic CNN model is built using keras in the below kernel\n\nTheory of CNN is explained with images (Source: Towards Data Science) and the model is built later\n"}}