{"cell_type":{"0418aa82":"code","c67d19d1":"code","4b67c82e":"code","50e9b3cf":"code","e6be7302":"code","da2a983a":"code","fdb70b11":"code","f5acd304":"code","0d838f4b":"code","9e17e4f3":"code","40271abc":"code","7690a99a":"code","96ce7b07":"code","c2e83f39":"code","c3090336":"code","e94f4de1":"markdown","d9cd2357":"markdown","f5709352":"markdown","bcb81a9e":"markdown","68a1f7e7":"markdown","49683697":"markdown","613c4440":"markdown","f9114c36":"markdown","487fb04e":"markdown","98bf3707":"markdown"},"source":{"0418aa82":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pandas_profiling as pp\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\nfrom sklearn.model_selection import train_test_split, cross_validate\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)","c67d19d1":"df = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","4b67c82e":"pp.ProfileReport(df)","50e9b3cf":"def correlated_map(dataframe, plot=False):\n    corr = dataframe.corr()\n    if plot:\n        sns.set(rc={'figure.figsize': (10, 10)})\n        sns.heatmap(corr, cmap=\"gist_yarg_r\", annot=True, linewidths=.7)\n        plt.xticks(rotation=60, size=10)\n        plt.yticks(size=10)\n        plt.title('Correlation Map', size=20)\n        plt.show()\n\ncorrelated_map(df, plot=True)","e6be7302":"def label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]\nlen(binary_cols)","da2a983a":"for col in binary_cols:\n    label_encoder(df, col)\n\ndf.head()","fdb70b11":"def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\ndf = one_hot_encoder(df, ohe_cols, drop_first=True)\ndf.head()","f5acd304":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","0d838f4b":"scaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\ndf","9e17e4f3":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nlog_model = LogisticRegression().fit(X, y)\n\n\ncv_results = cross_validate(log_model,\n                            X, y,\n                            cv=5,\n                            scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"])\n\ny_pred = log_model.predict(X)","40271abc":"print(classification_report(y, y_pred))","7690a99a":"def plot_confusion_matrix(y, y_pred):\n    acc = round(accuracy_score(y, y_pred), 2)\n    cm = confusion_matrix(y, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\".0f\")\n    plt.xlabel('y_pred')\n    plt.ylabel('y')\n    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n    plt.show()\n\nplot_confusion_matrix(y, y_pred)","96ce7b07":"y_prob = log_model.predict_proba(X)[:, 1]\nroc_auc_score(y, y_prob)","c2e83f39":"X.columns\n\nrandom_user = X.sample(1, random_state=44)\n\nlog_model.predict(random_user)","c3090336":"feature_imp = pd.DataFrame({'Value': log_model.coef_[0], 'Feature': X.columns})\nplt.figure(figsize=(10, 10))\nsns.set(font_scale=1)\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:8])\nplt.title('Features')\nplt.tight_layout()\nplt.show()","e94f4de1":"## **<font color=\"darkcyan\">EDA<\/font>**","d9cd2357":"> # **<font color=\"darkcyan\">Label Encoding<\/font>**","f5709352":"> # **<font color=\"softblue\">Confusion Matrix<\/font>**","bcb81a9e":"> # **<font color=\"darkcyan\">Standart Scaler<\/font>**","68a1f7e7":"> # **<font color=\"darkcyan\">Analysis of Correlation<\/font>**","49683697":"> # **<font color=\"softblue\">ROC AUC<\/font>**","613c4440":"> # **<font color=\"darkcyan\">One-Hot Encoding<\/font>**","f9114c36":"> # **<font color=\"darkcyan\">Importing Libraries<\/font>**","487fb04e":"> # **<font color=\"softblue\">Logistic Regression<\/font>**","98bf3707":"> # **<font color=\"softblue\">Prediction for A New Observation<\/font>**"}}