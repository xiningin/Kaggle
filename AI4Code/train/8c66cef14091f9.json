{"cell_type":{"6198b36b":"code","f35c1daa":"code","fcb459e0":"code","549fe853":"code","63ac5341":"code","d28489bd":"code","7d41bd9d":"code","b577a854":"code","5b7846fd":"code","aa8e4638":"code","ec31bade":"code","20b552c2":"code","66e3cf8a":"code","e72868bb":"code","af660371":"code","d85a94a4":"code","6c84db0d":"code","c63b60fe":"code","a8472858":"code","5174c743":"code","0247dc6e":"code","42a2239a":"markdown","d247af1e":"markdown","7ddf0a55":"markdown","25121640":"markdown","32d72ff9":"markdown","b7582af7":"markdown","88a2683f":"markdown","4b1c3769":"markdown","da8ac9a2":"markdown","4ed3974a":"markdown","c9b92368":"markdown","fc6112fa":"markdown","a6e7738f":"markdown","4004d54d":"markdown","1d10ef73":"markdown","826b4eba":"markdown"},"source":{"6198b36b":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport cv2\ntrain_set = pd.read_csv(\"..\/input\/how-am-i-feeling-tb2109\/data\/train_set.csv\")\ntrain_set['array'] = train_set['path'].apply(lambda x: cv2.imread(\"..\/input\/how-am-i-feeling-tb2109\/data\/train\/\" + x))\ntrain_set","f35c1daa":"test_set = pd.read_csv(\"..\/input\/how-am-i-feeling-tb2109\/data\/test_set.csv\")\ntest_set['array'] = test_set['path'].apply(lambda x: cv2.imread(\"..\/input\/how-am-i-feeling-tb2109\/data\/\" + x))\ntest_set","fcb459e0":"drama = cv2.imread(\"..\/input\/how-am-i-feeling-tb2109\/data\/train\/\" + train_set.path[0], 0) \ndrama.shape","549fe853":"plt.imshow(drama, cmap = 'gray')\nplt.show()","63ac5341":"from sklearn import preprocessing\n\ntrain_set[train_set.label == \"happy\"].index\ntrain_set[train_set.label == \"sadness\"].index\n\nle = preprocessing.LabelEncoder()\nle.fit(train_set.label)\ny = le.transform(train_set.label)\ny = y.reshape(-1,1)\ny.shape\nX = train_set['array']\nX = np.array(X)\nX = np.stack(X)\n\nX_test = test_set['array']\nX_test = np.array(X_test)\nX_test = np.stack(X_test)","d28489bd":"X_scaled = X\/255 \nX_test_scaled = X_test\/255","7d41bd9d":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=42)","b577a854":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","5b7846fd":"from tensorflow import keras\nvgg = keras.applications.VGG16(weights='imagenet', include_top=False)\nvgg.input_shape","aa8e4638":"model = keras.models.Sequential()\n\n\nmodel.add(keras.layers.GaussianNoise(.2,input_shape=(48, 48,3)))\nmodel.add(vgg) # <== convolution layers\n\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dropout(.4)) #to avoid overfitting\nmodel.add(keras.layers.Dense(units = 512,\n                            activation='relu'))\n\nmodel.add(keras.layers.Dropout(.4)) #to avoid overfitting\nmodel.add(keras.layers.BatchNormalization())# to speed up learing\nmodel.add(keras.layers.Dense(units = 256,\n                            activation='relu'))\nmodel.add(keras.layers.Dropout(.2)) #to avoid overfitting\nmodel.add(keras.layers.Dense(units = 2,\n                            activation='softmax'))\n\nmodel.summary()","ec31bade":"model.compile(\n    optimizer = keras.optimizers.Adam(1e-5),\n    loss = keras.losses.SparseCategoricalCrossentropy(),\n    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n)\n","20b552c2":"earlystop = keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=5, verbose=1,\n    mode='auto', restore_best_weights=True\n)","66e3cf8a":"history = model.fit(\n    X_train,\n    y_train,\n    batch_size = 64,\n    epochs = 60,\n    validation_data = (X_test,y_test),\n    callbacks=[earlystop] #to prevent overfitting\n)","e72868bb":"plt.plot(history.history['loss'][1:])\nplt.plot(history.history['val_loss'][1:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","af660371":"test_loss, test_acc = model.evaluate(X_test, y_test)\nprint(\"final accuracy : \",test_acc)","d85a94a4":"predictions = model.predict(X_test_scaled).round(3)","6c84db0d":"plt.figure()\nplt.title(\"predicted : \"+le.inverse_transform([np.argmax(predictions[3000])])[0])\nplt.imshow(X_test_scaled[3000])\nplt.show()","c63b60fe":"plt.figure()\nplt.title(\"predicted : \"+le.inverse_transform([np.argmax(predictions[3001])])[0])\nplt.imshow(X_test_scaled[3001])\nplt.show()","a8472858":"plt.figure()\nplt.title(\"predicted : \"+le.inverse_transform([np.argmax(predictions[3003])])[0])\nplt.imshow(X_test_scaled[3003])\nplt.show()","5174c743":"plt.figure()\nplt.title(\"predicted : \"+le.inverse_transform([np.argmax(predictions[3005])])[0])\nplt.imshow(X_test_scaled[3005])\nplt.show()","0247dc6e":"predictions.argmax(axis=1)\nle.inverse_transform(predictions.argmax(axis=1))\nsubmission_prediction = pd.DataFrame(data = test_set, columns = ['id_img'])\nsubmission_prediction['label'] = le.inverse_transform(predictions.argmax(axis=1))\nsubmission_prediction.to_csv('submission.csv', index=False)","42a2239a":"From :\n\nEquipo 2 \ud83e\udddc\u200d\u2640\ufe0f (female power!)\n\nJennifer, Silvia & Marta. ","d247af1e":"# pls Upvote if you liked it =D","7ddf0a55":"# **This is a correction of \"how_am_i_feeling_v9\" imporved but not to much =D**","25121640":"# Convert img to grayscale","32d72ff9":"# **Import Data**","b7582af7":"![](https:\/\/miro.medium.com\/max\/1050\/1*NNifzsJ7tD2kAfBXt3AzEg.png)\n\nSource : The architecture of VGG16 , Researchgate.net","88a2683f":"# **Learning graphs**","4b1c3769":"Earlystop to avoid overfitting","da8ac9a2":"# I just take the convolutions layers add my MLP classifier","4ed3974a":"# **Making model using vgg16 pretrained on imagenet**","c9b92368":"# VGG needs 3 channels inputs","fc6112fa":"# Split Data to 80% training and 20% test","a6e7738f":"# Scaling data to [0;1] ","4004d54d":"# **Training**","1d10ef73":"# Convert labels to numbers","826b4eba":"# **Submission**"}}