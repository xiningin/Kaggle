{"cell_type":{"07bfbcdb":"code","3d9c4c13":"code","166ee9c1":"code","d098cd6d":"code","0788d7e0":"code","bbc1cf7e":"code","561c4781":"code","f2366000":"code","c313a83b":"code","ff159f6e":"code","5626afc8":"code","f0d2604a":"code","28240649":"code","ef7549a8":"code","2b33191c":"code","aba8acc2":"markdown","04de7c57":"markdown","da887280":"markdown","1207261f":"markdown"},"source":{"07bfbcdb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns #for visualization\nimport matplotlib.pyplot as plt #\n\nfrom sklearn import metrics # For metrics such as R2 and explained variance score\nfrom tqdm import tqdm # Progress bar\nfrom sklearn.ensemble import RandomForestRegressor #simple model\nimport pickle","3d9c4c13":"#data loading\ndata = pd.read_csv('\/kaggle\/input\/pro-data-2020\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/pro-data-2020\/test.csv')\n\nprint(data.shape[0])\nprint(test_data.shape[0])\n\n#join two data for preprocessing\ndata = data.append(test_data)\nprint(data.shape[0])","166ee9c1":"data.isnull().sum().plot.bar(figsize=(15, 7), title='Missing values')","d098cd6d":"#Count all categorical values\ndata.select_dtypes(include=['object']).T.apply(lambda x: x.nunique(), axis=1)[:12]","0788d7e0":"def one_hot_encode_pipeline(df: pd.DataFrame, \n                            train_shape: int, \n                            test_shape: int) -> [pd.DataFrame, pd.DataFrame]:\n    \n    #one hot encoding for categorical values\n    def get_one_hot_dataset(df, exception: list) -> pd.DataFrame:\n        all_features = []\n        for column in tqdm(df.columns):\n            if column not in exception:\n                one_hot = pd.get_dummies(df[column])\n                df = df.drop(columns=[column])\n                all_features.append(one_hot)\n            else:\n                continue\n        features = pd.concat(all_features, axis=1)\n        return pd.concat([df, features], axis=1)\n    \n    # Imputing missing values\n    df[df.iloc[:, 12:].columns] = df.iloc[:, 12:].fillna(0)  #filling zero for one hot values\n    df = df.interpolate(method='pad', inplace=False) #imputing numerical values\n    \n    exceptions = df.select_dtypes(exclude=['object']).columns #filtering non - categorical values\n    df = get_one_hot_dataset(df=df, exception=exceptions) #transforming categorical into one_hot \n    \n    #return train, test\n    return df.head(train_shape), df.tail(test_shape)","bbc1cf7e":"train, test = one_hot_encode_pipeline(df=data, \n                                      train_shape=data.shape[0]-test_data.shape[0], \n                                      test_shape=test_data.shape[0])","561c4781":"print(train.shape[0])\nprint(test.shape[0])","f2366000":"#check missing values\ntrain.isnull().sum()[train.isnull().sum()>0]","c313a83b":"X_train, y_train = train.drop(train.columns[0], axis=1), train[train.columns[0]]\nX_test, y_test = test.drop(train.columns[0], axis=1), test[train.columns[0]]","ff159f6e":"#define model\nmodel = RandomForestRegressor(n_estimators=1500, \n                              max_depth=1000, \n                              max_leaf_nodes=300, \n                              max_features='sqrt', \n                              n_jobs=-1, \n                             bootstrap=True)","5626afc8":"#train model\nmodel.fit(X_train.values, y_train.values)\n#get prediction\ny_hat = model.predict(X_test.values)\n\nprint(\"R2: \", metrics.r2_score(y_test, y_hat))\nprint(\"Explained variance score: \", metrics.explained_variance_score(y_test, y_hat))","f0d2604a":"type(model)","28240649":"submission = pd.DataFrame({\n    'Id':np.arange(y_hat.shape[0]),  #Id is necessary \n    'Predicted':y_hat  # Predicted  is also necessary\n})","ef7549a8":"submission.to_csv(\"my_first_submission.csv\", index=False) #always index=False","2b33191c":"pickle.dump(model, open('random_forest.sav', 'wb')) #for later check the accuracy model","aba8acc2":"## Model saving","04de7c57":"## Preparing submission","da887280":"## Pipeline","1207261f":"## Modelling"}}