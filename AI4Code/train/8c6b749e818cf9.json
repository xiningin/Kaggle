{"cell_type":{"2f03be27":"code","1f0b5bf9":"code","484fb0a3":"code","5714ce71":"code","e19a8da8":"code","60c65b5c":"code","2b3cd9bc":"code","710ce65b":"code","719e7b7d":"code","f704c784":"code","898f92b3":"code","43fcdf2c":"code","1024ee6c":"code","6408874a":"code","c72cd6dd":"code","b870cbfe":"code","2a7bd136":"code","83cf774b":"code","c2d7e9da":"code","4792fd5e":"code","c43fb28c":"code","0dd07919":"code","e707b429":"code","11e21829":"code","9f0e4b7f":"code","aa5deba3":"code","2df610c8":"code","fcd19800":"code","cbcc2dca":"code","3edca2cd":"code","92b9c324":"code","abbca33a":"code","a004ef23":"code","14feda53":"markdown","4fb3c707":"markdown","c7f8e237":"markdown","7ebb8d1f":"markdown","b7cfc823":"markdown","c69b40af":"markdown","0e7bbdc2":"markdown","5c49eb10":"markdown","56a7b8ba":"markdown","97b97b2f":"markdown","4e501a84":"markdown","48e1fd6f":"markdown","53658fb9":"markdown","48607fc2":"markdown","c06256f6":"markdown","b66d86c8":"markdown","d66367f6":"markdown","99cbaf5f":"markdown","04a7c079":"markdown"},"source":{"2f03be27":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1f0b5bf9":"df = pd.read_csv('..\/input\/cars-germany\/autoscout24-germany-dataset.csv')","484fb0a3":"pd.options.display.max_rows = 1000","5714ce71":"df","e19a8da8":"df.corr()['price'].sort_values()\n#As seen the most correlated property is 'hp' vis-\u00e0-vis the price.","60c65b5c":"sns.scatterplot(x='hp',y='price', data = df)","2b3cd9bc":"sns.scatterplot(x='year',y='price', data = df)","710ce65b":"df[(df['price']>600000)]\n#These three cars are outliers due to their prices.","719e7b7d":"drop_ind = df[(df['price']>600000)].index\ndf = df.drop(drop_ind, axis = 0)","f704c784":"sns.scatterplot(x='hp',y='price', data = df)\n#The data is dispersed especially after the 600 hp, but the current version is better to work on.","898f92b3":"df.info()\n#We have some null values in our dataset. We need to either get rid of them, or fill them with some rational values.","43fcdf2c":"df.isnull().sum()\n#This is a better representation of our null data.","1024ee6c":"100 * df.isnull().sum() \/ len(df)","6408874a":"df['model'] = df['model'].fillna('None')\ndf['gear'] = df['gear'].fillna('None')\n100 * df.isnull().sum() \/ len(df)","c72cd6dd":"df['hp'].mean()","b870cbfe":"df['hp'] = df['hp'].fillna(132)","2a7bd136":"100 * df.isnull().sum() \/ len(df)","83cf774b":"my_object_df = df.select_dtypes(include = 'object')\nmy_numeric_df = df.select_dtypes(exclude = 'object')\nmy_object_df","c2d7e9da":"df_objects_dummies = pd.get_dummies(my_object_df, drop_first = True)\ndf_objects_dummies\n#So we have created dummy variables, instead of having them as strings.","4792fd5e":"final_df = pd.concat([my_numeric_df,df_objects_dummies],axis=1)\nfinal_df\n#We are concatenating the dummy variables with the numeric columns.","c43fb28c":"final_df.info()\n#Let's see the final version of our dataframe.","0dd07919":"X = final_df.drop('price', axis = 1)\ny = final_df['price']","e707b429":"from sklearn.model_selection import train_test_split\n#At this stage, we are certainly importing train_test_split module from sklearn.","11e21829":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)","9f0e4b7f":"from sklearn.preprocessing import StandardScaler\n#For this we are going to need StandScaler module from sklearn library.","aa5deba3":"scaler = StandardScaler()","2df610c8":"scaled_X_train = scaler.fit_transform(X_train)","fcd19800":"scaled_X_test = scaler.transform(X_test)","cbcc2dca":"from sklearn.linear_model import LinearRegression\n#We are importing LinearRegression module in order to create and run our linear regression.","3edca2cd":"reg = LinearRegression()\nreg.fit(X_train, y_train)","92b9c324":"reg.score(X_train,y_train)\n#Our regression score is around 0.924. Does not seem so bad I guess.","abbca33a":"reg.fit(X_test,y_test)","a004ef23":"reg.score(X_test,y_test)","14feda53":"# Can we predict the price of a car based on its properties?","4fb3c707":"## Feature Engineering","c7f8e237":"## Creating the Dummy Variables","7ebb8d1f":"Let's detect, if any, outliers and get rid of them.","b7cfc823":"## Scaling our X Features","c69b40af":"Let's plot the data, to visually see the outliers, again if any.","0e7bbdc2":"In order not to remove the rows where 'hp' data is missing, I will adopt a very unorthodox approach and fill these data with the average values of 'hp', which we will later on see that it is '132'.","5c49eb10":"## Creating our Features (X) and Target (y)","56a7b8ba":"## Creating our Training and Test Sets","97b97b2f":"## Creating our Linear Regression","4e501a84":"Then, we are opening our dataset, again as usual.","48e1fd6f":"Can we predict the price of a car based on the dataset we have through a linear regression?\nA somewhat classical example of a linear regression, I will be working on a dataset where some properties of more than 45k cars to predict their price.","53658fb9":"So, we should start as usual with importing the relevant libraries.","48607fc2":"Our test score is around 0.9277. This implies some overfitting, since I would expect the test score to be a little lower than the training regression score. But in overall, I think the linear regression model gave a satisfactory result.","c06256f6":"### Outliers","b66d86c8":"So, we do have a few outliers, as visually seen from the graphs. We will remove them from our dataset.","d66367f6":"Let's see the current version of our dataset.","99cbaf5f":"1)As seen from the table, there are 3 features containing null values. We are more interested in 'make', 'mileage', 'hp' and 'year'.\n\n2)In order to have as many data as possible, I will try to fill these values rather than simply removing them. \n","04a7c079":"Let's see if these null values are meaningful."}}