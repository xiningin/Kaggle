{"cell_type":{"e7a53bb9":"code","2e2be5d8":"code","acde53bb":"code","6b5edec8":"code","6762b5a4":"code","92909016":"code","3a492ba8":"code","ae5244e7":"code","6b2887e0":"code","c0d8b3f4":"code","71089791":"code","6652ba32":"code","4acab047":"code","c0eb243e":"code","bb44da85":"code","e7bbafae":"code","695d293b":"code","368ffc82":"code","a107eea8":"code","34f62a8d":"code","fe4d9941":"code","221d4a2a":"code","6d24506b":"code","478f4ddb":"code","b4077cbf":"code","3de1ab09":"code","9f14a0d6":"code","b5b398b7":"code","58846d4d":"code","52dd4e12":"code","d5865bea":"code","c07ffa6d":"markdown","df6fe74a":"markdown","054ba644":"markdown","856cbd8c":"markdown","a43afc1b":"markdown","f73a6e53":"markdown","bc2ec77d":"markdown","2ffca5e0":"markdown","68b43e48":"markdown","ba30666d":"markdown","748bb788":"markdown","e05bba98":"markdown"},"source":{"e7a53bb9":"import pandas as pd\nimport numpy as np\nimport os\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.metrics import roc_auc_score as aucroc\n# load libraries\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap","2e2be5d8":"datapath = \"..\/input\/older-dataset-for-dont-overfit-ii-challenge\"\ntrain = pd.read_csv(os.path.join(datapath,\"train.csv\"))\ntest = pd.read_csv(os.path.join(datapath,\"test.csv\"))","acde53bb":"train.head(10)","6b5edec8":"train.set_index('id')\ntest.set_index('id')\ntrain['target'].describe()","6762b5a4":"labels = train.pop('target')\ntrain = train.drop([\"id\"],axis=1)\ntest=test.drop([\"id\"],axis=1)","92909016":"missing_series = train.isnull().sum() \/ train.shape[0]","3a492ba8":"#to be sure there r no missing data in any column\ntrain.isnull().sum().sum()","ae5244e7":"# identify columns with single unique values\nunique_counts = train.nunique()\nunique_stats = pd.DataFrame(unique_counts).rename(columns =\n                                                  {'index': 'feature', 0: 'nunique'})\nunique_stats = unique_stats.sort_values('nunique', ascending = True)\nrecord_single_unique = pd.DataFrame(unique_counts[unique_counts == 1]).reset_index().rename(columns =\n                                                                                            {'index': 'feature', 0: 'nunique'})","6b2887e0":"# drop column if it have unique values\nto_drop = list(record_single_unique['feature'])\nto_drop","c0d8b3f4":"corr_matrix = train.corr()\n# Extract the upper triangle of the correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\nupper","71089791":"# Select the features with correlations above the threshold\n# Need to use the absolute value\ncorrelation_threshold = 0.5\nto_drop = [column for column in upper.columns if any(upper[column].abs() >= correlation_threshold)]\n\n# Dataframe to hold correlated pairs\nrecord_collinear = pd.DataFrame(columns = ['drop_feature', 'corr_feature', 'corr_value'])","6652ba32":"for column in to_drop:\n\n    # Find the correlated features\n    corr_features = list(upper.index[upper[column].abs() > correlation_threshold])\n\n    # Find the correlated values\n    corr_values = list(upper[column][upper[column].abs() > correlation_threshold])\n    drop_features = [column for _ in range(len(corr_features))]    \n\n    # Record the information (need a temp df for now)\n    temp_df = pd.DataFrame.from_dict({'drop_feature': drop_features,\n                                     'corr_feature': corr_features,\n                                     'corr_value': corr_values})\n\n    # Add to dataframe\n    record_collinear = record_collinear.append(temp_df, ignore_index = True)\n\nrecord_collinear","4acab047":"# ANOVA feature selection for numeric input and categorical output\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n# generate dataset\nX, y =train, labels\n# define feature selection\nfs = SelectKBest(score_func=f_classif, k=30)\n# apply feature selection\nX_selected = fs.fit_transform(X, y)\ntrain_df = pd.DataFrame(X_selected)\nprint(X_selected.shape)","c0eb243e":"train_df = pd.DataFrame(train_df)\ntest_df =(pd.DataFrame(fs.transform(test)))","bb44da85":"train_df","e7bbafae":"# std = StandardScaler()\n# train_df = std.fit_transform(train_df)","695d293b":"X_train, X_test, y_train, y_test = train_test_split(train_df, labels, test_size=0.20)","368ffc82":"kfold = model_selection.KFold(n_splits=10, random_state=42)\nbest_parameters = {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n\nestimators = []\nmodel1 = LogisticRegression(solver=\"liblinear\"); est1 = RFE(model1, 25, step=1);estimators.append(('logistic', est1))\nmodel2 = DecisionTreeClassifier(); est2 = RFE(model1, 25, step=1);estimators.append(('cart', est2))\nmodel3 = SVC(); estimators.append(('svm', model3))\nensemble = VotingClassifier(estimators)\n# selector = RFE(ensemble, 25, step=1)\nresults = model_selection.cross_val_score(ensemble, X_train, y_train, cv=kfold)\nprint(); \nprint(\"Result Mean:{}\".format(results.mean()))","a107eea8":"ensemble.fit(X_train, y_train)\nprint(\"Score:{0}\".format(ensemble.score(X_train, y_train)))","34f62a8d":"prediction = ensemble.predict(test_df)\nsubmission = pd.read_csv(\"..\/input\/older-dataset-for-dont-overfit-ii-challenge\/sample_submission.csv\")\nsubmission['target'] = prediction\nsubmission.to_csv('submission.csv', index=False)","fe4d9941":"perm = PermutationImportance(ensemble, random_state=42).fit(train_df, labels)","221d4a2a":"submission = pd.read_csv(\"..\/input\/older-dataset-for-dont-overfit-ii-challenge\/sample_submission.csv\")\nsubmission['target'] = perm.predict(test_df)\nsubmission.to_csv('submission_perm.csv', index=False)","6d24506b":"submission.shape","478f4ddb":"model1 = LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear', tol=0.00001,dual=False)\nest1 = RFE(model1, 25, step=1)\nest1.fit(train_df,labels)\nprint(\"Score:{0}\".format(est1.score(train_df,labels)))","b4077cbf":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs","3de1ab09":"sfs1 = SFS(est1, k_features=(10, 15), forward=True, floating=False,verbose=1,scoring='roc_auc',cv=5,n_jobs=-1)\nsfs1 = sfs1.fit(X_train, y_train)","9f14a0d6":"plt.figure(figsize=(20,8))\nfig1 = plot_sfs(sfs1.get_metric_dict(), color = \"red\",kind='std_dev', marker=\"p\")\nplt.ylim([0.8, 1])\nplt.title('Sequential Forward Selection (w. StdDev)')\nplt.grid()\nplt.show()","b5b398b7":"sfseatures = list(sfs1.k_feature_names_)","58846d4d":"train_1 = train_df[sfseatures]\ntest_1 = test_df[sfseatures]","52dd4e12":"model1 = LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear', tol=0.00001,dual=False)\nest1 = RFE(model1, 25, step=1)\nest1.fit(train_1,labels)\nprint(\"Score:{0}\".format(est1.score(train_1,labels)))","d5865bea":"submission = pd.read_csv(\"..\/input\/older-dataset-for-dont-overfit-ii-challenge\/sample_submission.csv\")\nsubmission['target'] = est1.predict(test_1)\nsubmission.to_csv('submission_sfs.csv', index=False)","c07ffa6d":"# Load data","df6fe74a":"# choosing data","054ba644":"# Taining model","856cbd8c":"**2- unique**","a43afc1b":"it's seems no solution except using toolers for feature seliction and dimentionality reduction","f73a6e53":"# EDA","bc2ec77d":"There r no unique column to drop -_-","2ffca5e0":"# **way one**","68b43e48":"**3- collinear**","ba30666d":"there r no missing values in the data","748bb788":"# **Way two**","e05bba98":"**1- nulls**"}}