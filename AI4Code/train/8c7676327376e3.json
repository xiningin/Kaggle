{"cell_type":{"ba29d1e8":"code","212fb692":"code","1011aa2d":"code","b1d9e698":"code","cc0ea6de":"code","9c4c28a7":"code","ca2873c5":"code","82c8cd4c":"code","4b8c62dc":"code","8fb0e2f6":"code","caf60961":"code","d2280e93":"code","93e5cb7f":"code","085ee83e":"code","88499dc2":"code","033bd9bb":"code","4bc0f638":"code","fc540cd7":"code","69e88b77":"code","e03908b7":"code","c5346d66":"code","4363346b":"code","7e5bb5f8":"code","d1f9c18b":"code","c6188608":"code","5f8b5dff":"code","1f737759":"code","77604f66":"markdown","d9388a59":"markdown","60f53eaf":"markdown"},"source":{"ba29d1e8":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow_addons as tfa\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n\n\n\nprint(\"TensorFlow Version:\", tf.__version__)","212fb692":"base_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/\"\nroot_dir = \".\/\"\ntest_dir = base_dir + \"test\/\"\ntrain_dir = base_dir + \"train\/\"\nwork_dir = root_dir + \"dataset\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","1011aa2d":"WORK_DIR = '.\/dataset\/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 176\nIMAGE_SIZE = [176, 176]\nDIM = (IMG_SIZE, IMG_SIZE)","b1d9e698":"#Performing Image Augmentation to have more data samples\n\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = IDG(rescale = 1.\/255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)","cc0ea6de":"def show_images(generator,y_pred=None):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, 6400)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen)","9c4c28a7":"show_images(train_data_gen)","ca2873c5":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","82c8cd4c":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","4b8c62dc":"#Performing over-sampling of the data, since the classes are imbalanced\n\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)","8fb0e2f6":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","caf60961":"def conv_block(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","d2280e93":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","93e5cb7f":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(16, 3, activation=act, padding='same'),\n        Conv2D(16, 3, activation=act, padding='same'),\n        MaxPool2D(),\n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        Dropout(0.15),\n        conv_block(256),\n        Dropout(0.15),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","085ee83e":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#EarlyStopping callback to make sure model is always learning\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)","88499dc2":"#Defining other parameters for our CNN model\n\nmodel = construct_model()\n\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback]\n    \nmodel.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n              metrics=METRICS)\n\nmodel.summary()","033bd9bb":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 200\n\nhistory = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","4bc0f638":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","fc540cd7":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n#val_scores = model.evaluate(val_data, val_labels)\ntest_scores = model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","69e88b77":"#Predicting the test data\n\npred_labels = model.predict(test_data)","e03908b7":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","c5346d66":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","4363346b":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","7e5bb5f8":"#Saving the model for future use\n\nmodel_dir = work_dir + \"alzheimer_cnn_model\"\nmodel.save(model_dir, save_format='h5')\nos.listdir(work_dir)","d1f9c18b":"pretrained_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\nplot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)","c6188608":"!pip install visualkeras","5f8b5dff":"import visualkeras\nvisualkeras.layered_view(model)","1f737759":"visualkeras.layered_view(model, to_file=work_dir + 'output.png') # write to disk","77604f66":"### Training & Testing the Model","d9388a59":"### Data Pre-Processing","60f53eaf":"### Constructing a Convolutional Neural Network Architecture"}}