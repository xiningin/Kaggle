{"cell_type":{"08040cb7":"code","a4d95d36":"code","7cef3125":"code","3189478a":"code","3f96d96d":"code","076b1dbb":"code","0acc958d":"code","1c9ca9b4":"code","fe8e8116":"code","b90cd00d":"code","76747877":"code","169d62a3":"code","68d9b886":"code","69a1443b":"code","e22ceef0":"code","33b7e3d7":"code","dc80d590":"code","7f5b71a5":"markdown","070de693":"markdown","0ec55e32":"markdown","4009f1bb":"markdown","9c18b25a":"markdown","67da4f5a":"markdown"},"source":{"08040cb7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#for clustering\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom scipy.stats import itemfreq\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport math\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a4d95d36":"df = pd.read_csv('..\/input\/Absenteeism_at_work.csv', delimiter=',')\ndf.head()","7cef3125":"df1 = pd.DataFrame(df)\nsplit = np.random.rand(len(df)) < 0.67\ntrain_data = df[split]\ntest_data = df[~split]","3189478a":"train_data.head()","3f96d96d":"test_data.head()","076b1dbb":"import math\n#Calculating Euclidean diastance\ndef Edistance(inst1, inst2, dimensions):\n    distance = 0\n    for i in range(dimensions):\n        distance += pow(int(inst1[i] - inst2[i]), 2)\n    return math.sqrt(distance)","0acc958d":"import operator\n#Returning K nearest neighbours based on distance\ndef Neighbors(train, test, k):\n    distances = []\n    length = len(test)-1    #length of 1 test data\n    for x in range(len(train)):\n        dist = Edistance(test, train[x], length)\n        distances.append((train[x], dist))\n    distances.sort(key=operator.itemgetter(1))\n    neighbors = []\n    for x in range(k):\n        neighbors.append(distances[x][0])\n    return neighbors","1c9ca9b4":"#Choosing the classes obtained from Neighbours\ndef Response(neighbors):\n    Choices = {}\n    for x in range(len(neighbors)):\n        response = neighbors[x][-1]\n        if response in Choices:\n            Choices[response] += 1\n        else:\n            Choices[response] = 1\n    sortedChoices = sorted(Choices.items(), key=operator.itemgetter(1), reverse=True)\n    return sortedChoices[0][0]","fe8e8116":"#Calculating Accuracy\ndef Accuracy(testSet, predictions):\n\tcorrect = 0\n\tfor x in range(len(testSet)):\n\t\tif testSet[x][-1] == predictions[x]:\n\t\t\tcorrect += 1\n\treturn (correct\/float(len(testSet))) * 100.0","b90cd00d":"#Combining all functions to get KNN\ntrainingSet = train_data.values.tolist()\ntest = test_data.values.tolist()\nprint(\"Train set size: \",len(trainingSet))\nprint(\"Test set size: \",len(test))\npredictions=[]\nk = 19  #no. of neighbors\ncount=0\nfor x in range(len(test)):\n    count+=1\n    neighbors = Neighbors(trainingSet, test[x], k)\n    result = Response(neighbors)\n    predictions.append(result)\naccuracy = Accuracy(test, predictions)\nprint(\"Accuracy: \",accuracy)","76747877":"#the train data has outliers \n#kmeans method will vary greatly for outliers\n#finding outlier and removing it\n\nQ1 = train_data['Absenteeism time in hours'].quantile(0.25)\nQ3 = train_data['Absenteeism time in hours'].quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR,Q1,Q3)\nmask = train_data[\"Absenteeism time in hours\"].between(Q1-IQR,Q3+IQR)\nfiltered_train=train_data[mask]\n\n# printing unique values in filtered train data\nprint(np.unique(filtered_train[\"Absenteeism time in hours\"]))","169d62a3":"def myFunc(data):\n    resu=data.iloc[:, [14]]\n    arr=resu.values\n    l=[]\n    for i in arr:\n        if i in range(0,5):\n            l.append(0)\n        if(i in range(5,10)):\n            l.append(1)\n        if(i in range(10,20)):\n            l.append(2)\n        if(i in range(20,30)):\n            l.append(3)\n        if(i in range(30,50)):\n            l.append(4)\n        if(i in range(50,100)):\n            l.append(5)\n        if(i in range(100,200)):\n            l.append(6)\n    print(len(data))\n    se=pd.Series(l)\n    data['Cluster']=se.values\nmyFunc(filtered_train)\nmyFunc(train_data)\nmyFunc(test_data)","68d9b886":"# print(list(df.columns.values))\nsns.set_style('whitegrid')\nsns.lmplot('Distance from Residence to Work','Reason for absence',data=df, hue='Absenteeism time in hours',palette=\"coolwarm\",size=6,aspect=1,fit_reg=False)\n\nsns.set_style('whitegrid')\nsns.lmplot('Distance from Residence to Work','Reason for absence',data=train_data, hue='Cluster',palette=\"coolwarm\",size=6,aspect=1,fit_reg=False)","69a1443b":"sns.set_style('whitegrid')\nsns.lmplot('Reason for absence','Work load Average\/day ',data=train_data, hue='Cluster',palette='coolwarm',size=6,aspect=1,fit_reg=False)","e22ceef0":"def root_mean_squared_error(y_actual,y_predicted):\n    errorsquare=(y_actual-y_predicted)**2\n    sum_of_error_square=np.mean(errorsquare)\n    rmse=np.sqrt(sum_of_error_square)\n    return(rmse)\n    \n# rmse = root_mean_squared_error(data_train, avg_rating)\n# rmse","33b7e3d7":"X=filtered_train.drop([\"Absenteeism time in hours\",\"ID\",\"Cluster\"],1)\nwcss = []\nfor i in range(1,15):\n    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,15),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.savefig('elbow.png')\nplt.show()\n# print(X)","dc80d590":"# X=train.drop([\"Absenteeism time in hours\"],1)\nk_means = KMeans(n_clusters=7, max_iter=600, algorithm = 'auto')\nk_means.fit(X)\npredict=k_means.predict(test_data.iloc[:,1:14])\ntype(predict[1])\na=test_data.iloc[:,15]\ntype(a)\na=test_data[\"Cluster\"].values\nprint(a[1])\n# print(a.columns.values)\nerr=root_mean_squared_error(a,predict)\nprint(err)\n# print((kmeans.labels_))\nprint(np.unique(train_data[\"Cluster\"]))\n\nfrom sklearn.metrics import confusion_matrix,classification_report\nprint(confusion_matrix(filtered_train[\"Cluster\"],k_means.labels_))\nprint(classification_report(filtered_train[\"Cluster\"],k_means.labels_))","7f5b71a5":"KNN Classification","070de693":"K-Means Clustering","0ec55e32":"We choose n_clusters based on the elbow method used to find the best possible number for the data points to be clustered into.","4009f1bb":"Spiltting the dataset into train set and test set","9c18b25a":"Team: Zenith\nTeam members: Ashwin Ashok (01FB16ECS0780), Debanik Mishra (01FB16ECS105), Gajendra K S (01FB16ECS120)","67da4f5a":"The number of clusters for choosen to be 19 based on the number of unique values in the column \"Absenteeism time at hours'"}}