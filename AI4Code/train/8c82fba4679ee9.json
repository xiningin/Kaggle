{"cell_type":{"80c47193":"code","987c58db":"code","a5284a0a":"code","7a7eb750":"code","38c362fc":"code","7572e7fe":"code","5a9b9b0b":"code","2777b5a6":"code","98f781e6":"code","2d1cf176":"code","9ee7cb42":"code","13f6ea3c":"code","893e3eae":"code","2d360568":"code","b6a5beed":"code","27ea06fc":"code","9983345f":"code","d6d9758f":"code","b721f95f":"code","d1c65674":"code","519fda5f":"code","e33543e8":"code","9a42bc1d":"code","55150c2e":"code","162b6338":"code","47e80b64":"code","527b9384":"code","83e84a63":"code","f5fbe0e1":"code","5927c9fb":"code","b3979ea2":"code","42f584d9":"code","1e45c69f":"code","bb6790d5":"code","241b34cf":"code","b4715726":"markdown","224d89c8":"markdown","50ec2143":"markdown","85e920a6":"markdown","02b6c0ec":"markdown","b9e522e8":"markdown","e0fad64c":"markdown","37773b4b":"markdown","8f99d10a":"markdown","cb0e1eba":"markdown","42b1e18f":"markdown","de42e589":"markdown","c7371189":"markdown","7701efd0":"markdown","bba21dd3":"markdown","f9690de5":"markdown","078f41c9":"markdown","40adfcef":"markdown","4362a7f7":"markdown","f0665f39":"markdown","dfa0dd6e":"markdown","141cf670":"markdown","b09ed3a0":"markdown","be33ed66":"markdown","fe2e1ca7":"markdown","b717a96b":"markdown","06140137":"markdown","2d6ca9ec":"markdown","f2b39e36":"markdown","148a4122":"markdown","7fe055fb":"markdown"},"source":{"80c47193":"!pip install yfinance    ","987c58db":"import yfinance as yf\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","a5284a0a":"#Packages for model evaluation and classification models\nfrom sklearn.model_selection import train_test_split, KFold,\\\ncross_val_score, GridSearchCV\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix,\\\naccuracy_score","7a7eb750":"df_AAPL = yf.download(\"AAPL\", start=\"2010-02-01\", end=\"2020-05-10\")","38c362fc":"df_AAPL['short_mavg'] =df_AAPL['Close'].rolling(window=10, min_periods=1,\\\ncenter=False).mean()","7572e7fe":"df_AAPL['long_mavg'] =df_AAPL['Close'].rolling(window=60, min_periods=1,\\\ncenter=False).mean()","5a9b9b0b":"df_AAPL['signal'] = np.where(df_AAPL['short_mavg'] > df_AAPL['long_mavg'], 1.0, 0.0)","2777b5a6":"df_AAPL['short_mavg'] = df_AAPL['Close'].rolling(window=10, min_periods=1,center=False).mean()","98f781e6":"df_AAPL['long_mavg'] = df_AAPL['Close'].rolling(window=60, min_periods=1,center=False).mean()","2d1cf176":"def EMA(df, n):\n    EMA = pd.Series(df['Close'].ewm(span=n, min_periods=n).mean(), name='EMA_'\\\n    + str(n))\n    return EMA\ndf_AAPL['EMA10'] = EMA(df_AAPL, 10)\ndf_AAPL['EMA30'] = EMA(df_AAPL, 30)\ndf_AAPL['EMA200'] = EMA(df_AAPL, 200)","9ee7cb42":"def ROC(df, n):\n    M = df.diff(n - 1)\n    N = df.shift(n - 1)\n    ROC = pd.Series(((M \/ N) * 100), name = 'ROC_' + str(n))\n    return ROC\ndf_AAPL['ROC10'] = ROC(df_AAPL['Close'], 10)\ndf_AAPL['ROC30'] = ROC(df_AAPL['Close'], 30)","13f6ea3c":" def MOM(df, n):\n    MOM = pd.Series(df.diff(n), name='Momentum_' + str(n))\n    return MOM\ndf_AAPL['MOM10'] = MOM(df_AAPL['Close'], 10)\ndf_AAPL['MOM30'] = MOM(df_AAPL['Close'], 30)","893e3eae":"def RSI(series, period):\n    delta = series.diff().dropna()\n    u = delta * 0\n    d = u.copy()\n    u[delta > 0] = delta[delta > 0]\n    d[delta < 0] = -delta[delta < 0]\n    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n    u = u.drop(u.index[:(period-1)])\n    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n    d = d.drop(d.index[:(period-1)])\n    rs = u.ewm(com=period-1, adjust=False).mean() \/ \\\n    d.ewm(com=period-1, adjust=False).mean()\n    return 100 - 100 \/ (1 + rs)\ndf_AAPL['RSI10'] = RSI(df_AAPL['Close'], 10)\ndf_AAPL['RSI30'] = RSI(df_AAPL['Close'], 30)\ndf_AAPL['RSI200'] = RSI(df_AAPL['Close'], 200)","2d360568":"def STOK(close, low, high, n):\n    STOK = ((close - low.rolling(n).min()) \/ (high.rolling(n).max() - \\\n    low.rolling(n).min())) * 100\n    return STOK\ndef STOD(close, low, high, n):\n    STOK = ((close - low.rolling(n).min()) \/ (high.rolling(n).max() - \\\n    low.rolling(n).min())) * 100\n    STOD = STOK.rolling(3).mean()\n    return STOD\ndf_AAPL['%K10'] = STOK(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 10)\ndf_AAPL['%D10'] = STOD(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 10)\ndf_AAPL['%K30'] = STOK(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 30)\ndf_AAPL['%D30'] = STOD(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 30)\ndf_AAPL['%K200'] = STOK(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 200)\ndf_AAPL['%D200'] = STOD(df_AAPL['Close'], df_AAPL['Low'], df_AAPL['High'], 200)","b6a5beed":"def MA(df, n):\n    MA = pd.Series(df['Close'].rolling(n, min_periods=n).mean(), name='MA_'\\\n    + str(n))\n    return MA\ndf_AAPL['MA21'] = MA(df_AAPL, 10)\ndf_AAPL['MA63'] = MA(df_AAPL, 30)\ndf_AAPL['MA252'] = MA(df_AAPL, 200)","27ea06fc":"df_AAPL","9983345f":"df_AAPL.describe()","d6d9758f":"df_AAPL[['Close']].plot(grid=True)\nplt.show()","b721f95f":"df_AAPL=df_AAPL.dropna()","d1c65674":"df_AAPL.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))\nplt.show()","519fda5f":"correlation = df_AAPL.corr()\nplt.figure(figsize=(15,15))\nplt.title('Correlation Matrix')\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')","e33543e8":"fig = plt.figure()\nplot = df_AAPL.groupby(['signal']).size().plot(kind='barh', color='pink')\nplt.show()","9a42bc1d":"Y= df_AAPL[\"signal\"]\nX = df_AAPL.loc[:, df_AAPL.columns != 'signal']\nvalidation_size = 0.2\nseed = 1\nX_train, X_validation, Y_train, Y_validation =train_test_split(X, Y, test_size=validation_size, random_state=1)","55150c2e":"# test options for classification\nnum_folds = 10\nscoring = 'accuracy'","162b6338":"models = []\nmodels.append(('LR', LogisticRegression(n_jobs=-1)))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))","47e80b64":"models.append(('NN', MLPClassifier()))","527b9384":"models.append(('AB', AdaBoostClassifier()))\nmodels.append(('GBM', GradientBoostingClassifier()))","83e84a63":"models.append(('RF', RandomForestClassifier(n_jobs=-1)))","f5fbe0e1":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","5927c9fb":"cv_results","b3979ea2":"fig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nfig.set_size_inches(15,8)\nplt.show()","42f584d9":"n_estimators = [20,80]\nmax_depth= [5,10]\ncriterion = [\"gini\",\"entropy\"]\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth, \\\ncriterion = criterion )\nmodel = RandomForestClassifier(n_jobs=-1)\nkfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, \\\nscoring=scoring, cv=kfold)\ngrid_result = grid.fit(X_train, Y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_,\\\ngrid_result.best_params_))","1e45c69f":"# prepare model\nmodel = RandomForestClassifier(criterion='gini', n_estimators=80,max_depth=10)\n#model = LogisticRegression()\nmodel.fit(X_train, Y_train)\n# estimate accuracy on validation set\npredictions = model.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))","bb6790d5":"Importance = pd.DataFrame({'Importance':model.feature_importances_*100}, index=X.columns)\nImportance.sort_values('Importance', axis=0, ascending=True).plot(kind='barh', color='b' )\nplt.xlabel('Variable Importance')\nplt.figure(figsize=(10, 20))","241b34cf":"backtestdata = pd.DataFrame(index=X_validation.index)\nbacktestdata['signal_pred'] = predictions\nbacktestdata['signal_actual'] = Y_validation\nbacktestdata['Market Returns'] = X_validation['Close'].pct_change()\nbacktestdata['Actual Returns'] = backtestdata['Market Returns'] *\\\nbacktestdata['signal_actual'].shift(1)\nbacktestdata['Strategy Returns'] = backtestdata['Market Returns'] * \\\nbacktestdata['signal_pred'].shift(1)\nbacktestdata=backtestdata.reset_index()\nbacktestdata.head()\nbacktestdata[['Strategy Returns','Actual Returns']].cumsum().hist()\nbacktestdata[['Strategy Returns','Actual Returns']].cumsum().plot()","b4715726":"### **Feature importance**\n\nThe momentum indicators like RSI, MOM, ROC for the 30 days period shows highest importance followed by stochastic oscillator %K and %D. \n","224d89c8":"**Regression and tree regression models**","50ec2143":"### **Model tuning and grid search**\n\nRandom forest is optimised by varying the number of estimators and maximum depth as below.","85e920a6":"### **Backtesting**\n\nA column for strategy returns by multiplying the daily returns by the position that was held at the close of business the previous day and compare it against the actual returns.","02b6c0ec":"### **Apple share dataset**\n\nThe Apple dataset for shares is downloaded from 2010 till date from yahoo finance.","b9e522e8":"**2. Bagging methods**","e0fad64c":"**Create signals**","37773b4b":"**Short simple moving average over the short window**","8f99d10a":"### **Histogram**\n\nFolowing is the histogram for various columns of dataset.","cb0e1eba":"### **Conclusion**\n\nBactesting results confirmed that our model doesn't deviate fom the actual market return. The momentum indicators has helped to improve the accuracy of the model. But it is not 100% as the accuracy calculated above is about 97.69% so a few losses were made compared to the actual returns.","42b1e18f":"# **Apple shares - trading**\n\nIn this notebook a trading signal is generated based on various parameters which indicate when to buy or sell Apple share. **This notebook is for educational purpose only and not for any type of financial advice.**\n![image.png](attachment:665e7791-27cb-4622-976c-58ff29dc6e69.png)","de42e589":"### **Stochastic osillator (STOK)**\n\nIt is a momentum indicator that compares the closing price of a security to a range of its previous prices over a certain period of time. %K and %D are fast and slow indicators. The fast indicator is more sensitive than the slow indicator to changes in the price of the underlying security and will likely result in many transaction signals.","c7371189":"## **Feature Engineering**\n\nDifferent features are generated from the dataset which are used for the signal geenration when to buy or sell the share.","7701efd0":"### **Correlation**","bba21dd3":"### **Compare algorithm results**\n\nNote that the y-axis is the accuracy parameter, so higher the better. Random forest gives us better accuracy than the rest, also the  problem is non linear and have high number of variables.","f9690de5":"### **Accuracy**\n\nThe model performs well with the accuracy of 97.69 %","078f41c9":"**Neural Network**","40adfcef":"**Long simple moving average over the long window**","4362a7f7":"### **Buy\/Sell signal**\n\nA binary label is attached o the signal. The decision is based on the short term and long term moving avaerage of closing price of Apple share. The short term is based on 10 days moving average and the long term is based on 60 days moving average. When the short term moving average increases compared to the long term, the signal is 1(buy). 0(sell) if short term decreases as compared to the long term.\n\n\n\n","f0665f39":"### **Exponential moving average (EMA)**\n\nIt is a weighted moving avaerage, where more importance\/weight is given to the recent price data. It is taken over 10, 30 and 200 days period.","dfa0dd6e":"**1. Boosting methods**","141cf670":"### **Models**\n\nTen fold cross validation (CV) have been used to optimise the various parameters of models. The model performance is decided by measuring the mean square error. The following models are implemented using sklearn package.","b09ed3a0":"**Test and train split of dataset**","be33ed66":"### **Relative strength index (RSI)**\n\nIt is a momentum indicator which indicates whether the asset is overbought or overold according to the recent prioce change of the asset. It ranges from 0 to 100. An asset is considered overbought when RSI reaches 70, that is an asset is overvalued and a good indicator of pullback.  When RSI approaches 30, it is an indicator that the asset is oversold and hence undervalued.","fe2e1ca7":"### **Moving average**\n\nCalculated for 10, 30 and 200 period.","b717a96b":"### **Price momentum (MOM)**\n\nThis is the rate of acceleration of a security\u2019s price or volume\u2014that is, the speed\nat which the price is changing.","06140137":"**Ensemble Models**","2d6ca9ec":"### **Long simple moving average**\n\nTaken over 60 days period.","f2b39e36":"### **Signal distribution**\n\nThe buy signal 1 is about 66% of the time so we have more buy signal.","148a4122":"### **Short simple moving average**\n\nShort term moving avaerage is taken over 10 days period. Moving average smooths out the data and provides an indication of price trend.","7fe055fb":"### **Rate of change (ROC)**\n\nThis is a momentum oscillator that measures the percentage change between the current price and the n period past prices (in this case n is 10 and 30). Assets with higher ROC values are considered more likely to be overbought; those with lower ROC, more likely to be oversold.\n\n"}}