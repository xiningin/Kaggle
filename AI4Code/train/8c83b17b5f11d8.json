{"cell_type":{"2bd6ab08":"code","3f497db4":"code","6d0b8cbb":"code","ba47020e":"code","96e7e9e5":"code","5659f017":"code","b76323f2":"code","30bd142a":"code","1efc5eba":"code","fc766609":"code","5b84864d":"code","6ccffc19":"code","42191e23":"code","a1475d26":"code","2bf1bd50":"code","f0966fb6":"code","14cfcc87":"code","e624e040":"code","264473d7":"code","8a793df9":"code","02fa97e3":"code","7e9772f2":"code","f67a920a":"code","41a1df13":"code","d1fc7d0f":"code","6a886bbe":"code","da4eb89c":"code","69fc79ed":"code","4b226b90":"code","2ffb7e75":"code","afa898bc":"code","a8535ec8":"code","1e70ecee":"markdown","f6eddf71":"markdown","0efc09fa":"markdown","87a91e9b":"markdown","d1fe1eff":"markdown","b77474e5":"markdown","a2b4276a":"markdown","e2d01d71":"markdown","f6c0eda0":"markdown","819b0334":"markdown","34acb301":"markdown","431c21c9":"markdown","3663dc47":"markdown","9b7af169":"markdown","2aa10c3e":"markdown","c0f62df1":"markdown"},"source":{"2bd6ab08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3f497db4":"#Get the data and all the null value removal\n\ndata = pd.read_csv(\"..\/input\/train.csv\")\nmetadata = pd.read_excel(\"..\/input\/LCDataDictionary.xlsx\")\nnew_data = data.dropna(axis = 1,thresh= data.shape[0]*92\/100)\nnot_useful_columns = [\"id\", \"member_id\",\"url\"]\nnew_data.drop(not_useful_columns, axis = 1, inplace = True)\n\nnew_data = new_data[new_data[\"loan_status\"] != \"Current\"]\nnew_data = new_data[new_data[\"loan_status\"] != \"Issued\"]\n","6d0b8cbb":"for col_name in new_data.columns:\n    if new_data[col_name].dtype == \"object\":\n        mode_var = new_data[col_name].mode()[0]\n        new_data[col_name].fillna(mode_var,inplace = True)\n    else:\n        mean_var = new_data[col_name].mean()\n        new_data[col_name].fillna(mean_var,inplace = True)","ba47020e":"new_data.columns","96e7e9e5":"%matplotlib notebook\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig,ax = plt.subplots(1,3,sharey = True)\n\nsns.distplot(new_data[\"loan_amnt\"], ax = ax[0],kde=False)\nsns.distplot(new_data[\"funded_amnt\"],ax = ax[1],kde=False)\nsns.distplot(new_data[\"funded_amnt_inv\"],ax = ax[2],kde=False)\nplt.figure()\nsns.distplot(new_data[\"annual_inc\"],kde=False)\nplt.figure()\nsns.distplot(new_data[\"int_rate\"])","5659f017":"plt.figure()\nsns.boxplot(\"annual_inc\",data = new_data, color = \"blue\")","b76323f2":"plt.figure(figsize = (7,7))\ng = sns.countplot(new_data[\"loan_status\"])\n\"\"\"\nto sort the plot.. we cannot use sns countplot\nWe can rather use pandas inbuilt plot function as \nnew_data.values_count().plot(\"bar\")\n\"\"\"\nplt.xticks(rotation = 90)\nplt.tight_layout()","30bd142a":"def converts(x):\n    values = \"\"\"Fully Paid\nCharged Off\nLate (31-120 days)\nIn Grace Period\nLate (16-30 days)\nDoes not meet the credit policy. Status:Fully Paid\nDefault\nDoes not meet the credit policy. Status:Charged Off\"\"\".split(\"\\n\")\n    is_it_positive = [1,0,0,0,0,1,0,0]\n    for this_string,ret_value in zip(values,is_it_positive):\n        if x == this_string:\n            return ret_value\n\n\nnew_data[\"labels\"] = new_data[\"loan_status\"].apply(converts)","1efc5eba":"plt.figure()\nnew_data.groupby([\"labels\"])[\"loan_amnt\"].sum().plot(kind =\"bar\")","fc766609":"plt.figure(figsize = (7,7))\nsns.scatterplot(x = \"loan_amnt\", y = \"annual_inc\", hue = \"loan_status\", data = new_data)\nplt.legend(loc = \"best\")","5b84864d":"plt.figure(figsize = (7,7))\nsns.scatterplot(x = new_data[\"loan_amnt\"], y = new_data[new_data[\"annual_inc\"] < 400000][\"annual_inc\"], hue = \"loan_status\", data = new_data)\nplt.legend(loc = \"upper right\",bbox_to_anchor=(1.45, 0.8))","6ccffc19":"plt.figure(figsize = (7,7))\ntrunc_new_data = new_data[new_data[\"annual_inc\"] < 400000]\nsns.regplot(x = \"loan_amnt\", y = \"annual_inc\", data = trunc_new_data, scatter_kws = {'alpha': 1})\n","42191e23":"kws = dict(alpha = 0.1)\n\ncanv1 = sns.FacetGrid(data = trunc_new_data,row= \"loan_status\",height=5)\ncanv1 = canv1.map(sns.scatterplot, \"loan_amnt\", \"annual_inc\",**kws)\n\n\"\"\"\nthis maps sns.scatter for those two parametes on every facetgrid combination\n\"\"\"","a1475d26":"new_data['years'] = pd.to_datetime(new_data[\"issue_d\"]).dt.year\nnew_data['month'] = pd.to_datetime(new_data[\"issue_d\"]).dt.month","2bf1bd50":"plt.figure()\nsns.barplot(\"years\",\"loan_amnt\",data = new_data)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","f0966fb6":"plt.figure(figsize = (7,7))\nsns.barplot(\"years\",\"loan_amnt\",hue = \"loan_status\",data = new_data,ci = None)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","14cfcc87":"plt.figure()","e624e040":"new_data.groupby([\"years\",\"loan_status\"]).mean()[\"loan_amnt\"].unstack().plot(kind = \"line\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","264473d7":"#Borrowed from another kernel by Janio\n\nclusters_by_regions = {\"west\" : ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID'],\n\"south_west\" : ['AZ', 'TX', 'NM', 'OK'],\n\"south_east\" : ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ],\n\"mid_west\" : ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND'],\n\"north_east\" : ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']}","8a793df9":"def statify(x):\n    global clusters_by_regions\n    for region in clusters_by_regions.keys():\n        if x in clusters_by_regions[region]:\n            return region\nnew_data[\"region\"] = new_data[\"addr_state\"].apply(statify)","02fa97e3":"plt.figure()\nnew_data.groupby([\"years\", \"region\"])[\"loan_amnt\"].mean().unstack().plot(kind = \"line\")","7e9772f2":"#Total in each region\nplt.figure()\nnew_data.groupby([\"years\", \"region\"])[\"loan_amnt\"].sum().unstack().plot(kind = \"line\")","f67a920a":"#Total in each region\nplt.figure()\nnew_data.groupby([\"region\",\"labels\"])[\"loan_amnt\"].sum().unstack().plot(kind = \"bar\")","41a1df13":"#Total in each region\nplt.figure()\nnew_data.groupby([\"region\",\"labels\"])[\"loan_amnt\"].mean().unstack().plot(kind = \"bar\")","d1fc7d0f":"#Total in each region\nplt.figure()\nsns.countplot(new_data[\"region\"])","6a886bbe":"new_data.groupby([\"addr_state\"])[\"annual_inc\"].mean().sort_values(ascending = False).head(15)","da4eb89c":"new_data.groupby([\"addr_state\"])[\"loan_amnt\"].mean().sort_values(ascending = False).head(15)","69fc79ed":"canvas2 = sns.FacetGrid(new_data,col=\"labels\")\ncanvas2.map(sns.distplot,\"int_rate\")\ncanvas2.fig.suptitle(\"For all people in my data\")\n\n\ncanvas3 = sns.FacetGrid(trunc_new_data,col=\"labels\")\ncanvas3.map(sns.distplot,\"int_rate\")\ncanvas3.fig.suptitle(\"For all <4L salary ppl\")\n\n\ncanvas3 = sns.FacetGrid(new_data[new_data[\"annual_inc\"] > 400000],col=\"labels\")\ncanvas3.map(sns.distplot,\"int_rate\")\ncanvas3.fig.suptitle(\"For all >4L salary ppl\")","4b226b90":"new_data[\"emp_length\"].unique()\n\nnew_data[\"employ_exp\"] = new_data[\"emp_length\"].replace(['10+ years', '8 years', '3 years', '2 years', '< 1 year', '1 year',\n       '5 years', '7 years', '6 years', '9 years', '4 years'],[10,8,3,2,0.5,1,5,7,6,9,4])\n\npairplot_cols = [\"annual_inc\",\"loan_amnt\", \"employ_exp\", \"term\",\"int_rate\",\"years\"]","2ffb7e75":"trunc_new_data = new_data[new_data[\"annual_inc\"] < 200000]\nsns.pairplot(trunc_new_data[pairplot_cols])","afa898bc":"#The labelwise counts of purposes\npur_lab = new_data.groupby(by = [\"purpose\",\"labels\"])[\"loan_amnt\"].count().sort_values(ascending= False)\npur_lab","a8535ec8":"new_data.groupby([\"purpose\",\"labels\"])[\"loan_amnt\"].count().sort_values(ascending= False).unstack().plot(kind=\"bar\",)","1e70ecee":"This means..that on an average we have higher demands from the observed three regions thats why the sum was higher but the means look same\n\nWell, if this is a random sample of population, we can understand the income patterns (totally unrelated to loan lending problem but relevant to strategy\/ PR\/ targetted marketting)\n\n","f6eddf71":"Most income values are between 0-2,00,000 ! (Obviously! $2L is Rs. 1.4Cr.. Dont expect a lot of people to have salaries beyond that! (and the population sampled seems like a wealthy one given that the median hovers around 100,000).  Might be useful later\n\n\nNow I know only about the loan amounts.. how about what people's status is?","0efc09fa":"There is a small slope there! Its not completely unrelated!.. Thats a relief we truncated and saw the entire regplot. What this tells us is, there is an association between the income of the person and the loan they take up. Plotting positive classes and negative classes seperately\n","87a91e9b":"If this was a random population that was sampled, and because we have a huge dataset, we can determine that the annual incomes can be approximated from our data. We can try targetted offers for each state depending on average income!.. A better way to visualise is to plot on map. It is very inconvinient to plot on map and this does the work..so why not!!","d1fe1eff":"About $80,00,00,000 ($80crore) is with defaulters now. Hope their company makes a lot of profit on the interests of non defaulters.\n\nAnother interesting plot to see would be, income of people vs their loan amount. An additional interesting information to look could be..whats the status when we see it! ","b77474e5":"The company is owed a lot from west, south east and north east! Why is that?","a2b4276a":"Wow..no correlation between these values! They look as if there isnt any relation between them\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n.... or is there?\nWhen you see the scale on the y axis, it is 10^7, which means one tick on y is 1,00,00,000 but on x it is only 5000! Let us bring them to same scale before we decide","e2d01d71":"### Formal Introduction of the Loan dataset\n#### Company Information:\nLending Club is a peer to peer lending company based in the United States, in which **investors provide funds** for potential borrowers and investors earn a profit depending on the risk they take (the borrowers credit score). Lending Club provides the \"bridge\" between investors and borrowers. \n\nThus\n\nBorrower requests loan -> Investor invests in that borrower (on his\/her own risk) -> as borrower returns the amount investor earns.\n\nWe have a code for removing all null values.. we will remove them and get a clean dataset. We won't be converting categorical values to numeric as the numbering is alphabetic and does not follow \n    \n    ","f6c0eda0":"Well..it looks like our regions all have similar mean values for good and bad loans and previous observation is again validated!. Defaulters have a higher loans!","819b0334":"Understanding from the above plots:\n1. Range of loan amount, how much it was funded and how much investors invested in your loan: 0 - 35000\n2. Investors seem to invest in the last bin almost 100% (see the heights being almost same.. which is very different than the mode bin around 10k)\n3. Few people of high income are in our data! Let us box-whisker plot it and see the distribution\n4. Interest rates seem to be between 5% - 27% \n5. Median int_rate between 12-15%","34acb301":"## EDA\n\nWhat is EDA:\n1. Analysing data beyond the regular hypothesis testing and model building. \n2. Exploring and exploiting properties of data for model building and hypothesis testing. \n3. Changing the structure of the data to be collected\n\nFormal definition:\n> Procedures for **analyzing data**, techniques for **interpreting results** of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data.\n\n_-\"Future of Data Analysis\"_,[https:\/\/projecteuclid.org\/download\/pdf_1\/euclid.aoms\/1177704711](http:\/\/), _John Tukey, Princeton University._\n\n","431c21c9":"Above plot is for each different type of default seperated and plotted as a scatterplot of loan_amt vs annual income. There are postive trends in all of them. \nLearnings\n1. Distribution of defaulters with respect to their annual income vs loan amt\n2. The negative vs positive class graphs show different density regions\n3. The color is simply a reminder that few classes are more populated than the other\n\nNow we know the general trends of income and loan data. Let us move towards the other parameters! I see issue_d definition says its the date the loan was issued. Let get a hold of when were loans disbursed \n","3663dc47":"Observations\n1. Classes present since 2007 are fully or charged off. Classes 'Does not meet the credit policy. Status:Charged Off' and 'Does not meet the credit policy. Status:Fully Paid' do not occur after 2010\n2. \"Late\" parameters have started after 2011.\n3.  Average loan amount for defaulters\/charged off is well above the average fully charged amount. People are taking larger loans and are unable to pay them! That could explain why mean of defaulters\/charged off\/etc are above on the graph! (You cant say this company is gonna close because they have many many current and fully paid people!..remember this while plotting mean. )\n4.  All the defaulters are showing convergence of mean loan amount near 15000! Can we use this information in model building?? If yes..how!\n5. An interesting bump at 2011- 2013 !! I would like to hear your hypothesis why this could be!!! \n\n\n### What are the other parameters doing? \nLets see how does the state information interact.. They have 51 states in USA. It will be cluttered to plot 51 lines\/bargraphs\/boxplots.. First clustering them together as regions (thats what most companies do..they have regional management heads) ","9b7af169":"## Throwing in more parameters!\n\nLet start looking at \ninterest rates, terms, employment, years of exp, etc","2aa10c3e":"Learnings\n1. The bump on the graph reappeared on regionwise plot. Seems like a countrywide phenomenon \/ companywide phenomenon","c0f62df1":"Well seems either their algorithm which accepts a person's request works good.. or .. we just have good demography paying off their loans regularly!\n1.6L people paid off their loans and ~40k people were charged off! (the system gave up on them). Shall we go ahead and see what is our demography like? What do they work, how are the other variables interacting with each other. Firstly, the company is owned a lot of data from charged off, defaulters, and late payers! How much is it!?"}}