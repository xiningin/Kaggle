{"cell_type":{"da0d3564":"code","62098282":"code","48f4556b":"code","c5feb9fa":"code","34761027":"code","e031aeb1":"code","5aff3ecf":"code","27a435e2":"code","ac758c89":"code","ce97d872":"code","7719230e":"code","f5cb2fd6":"code","32f9938c":"code","77477502":"code","3a8c3648":"code","6b798eaf":"code","45d1bfb3":"code","d95cf6d4":"code","32ba9eb7":"code","21a4eeec":"code","9c9516d2":"code","9ac62d8d":"code","7b4f9f3e":"code","cd759543":"code","eeee7332":"code","1f90fb0f":"code","a794c7dc":"code","5f17d3f0":"code","30c536e9":"code","f53f9345":"code","eee8f935":"code","31da1bf9":"code","0a1b8ac2":"code","31828ff0":"code","4919770e":"code","d1aa7d45":"code","72dd7c21":"code","8c7447a1":"markdown","0e132062":"markdown"},"source":{"da0d3564":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62098282":"import matplotlib.pyplot as plt\n\nplt.style.use('fivethirtyeight')\nplt.style.use('dark_background')\n\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nimport imblearn\n\nfrom scipy.stats import probplot, kurtosis, skew, gmean\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.ensemble import RandomTreesEmbedding","48f4556b":"df_train=pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ndf_train","c5feb9fa":"df_test=pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')\ndf_test","34761027":"sns.kdeplot(df_train['song_popularity'])","e031aeb1":"df_test.info()","5aff3ecf":"train_df=df_train.copy()\ntrain_df=train_df.drop('song_popularity',axis=1)","27a435e2":"df_unified=pd.concat([train_df,df_test],ignore_index=True)\ndf_unified","ac758c89":"df_unified.info()","ce97d872":"cols=df_unified.columns\nnan_cols=[]\nfor column in cols:\n    if df_unified[column].isnull().sum()!=0:\n        nan_cols.append(column)","7719230e":"for column in nan_cols:\n    df_unified[column]=df_unified[column].fillna(df_unified[column].median())","f5cb2fd6":"df_unified.info()","32f9938c":"plt.figure(figsize=(100,120))\ni=1\nfor column in cols:\n    plt.subplot(5,3,i+1)\n    sns.kdeplot(df_unified[column],data=df_unified)\n    plt.title(column)\n    i=i+1\n    \nplt.savefig('distribution_plot')","77477502":"sns.kdeplot(df_unified['energy'],data=df_unified)","3a8c3648":"df_unified['energy'].values[0]","6b798eaf":"\nq3=np.quantile(df_unified['energy'],0.75)\nq1=np.quantile(df_unified['energy'],0.25)\niqr=q3-q1\nupper_limit=q3+1.5*iqr\nlower_limit=q1-1.5*iqr\nctr=0\n\nfor i in range(df_unified.shape[0]):\n    if (df_unified['energy'].values)[i]>upper_limit:\n        \n        (df_unified['energy'].values)[i]=upper_limit\n\n    elif (df_unified['energy'].values)[i]<lower_limit:\n        \n        (df_unified['energy'].values)[i]=lower_limit\n    else:\n        \n        (df_unified['energy'].values)[i]=(df_unified['energy'].values)[i]\n","45d1bfb3":"q3=np.quantile(df_unified['acousticness'],0.75)\nq1=np.quantile(df_unified['acousticness'],0.25)\niqr=q3-q1\nupper_limit=q3+1.5*iqr\nlower_limit=q1-1.5*iqr\n\nfor i in range(df_unified.shape[0]):\n    if (df_unified['acousticness'].values)[i]>upper_limit:\n        (df_unified['acousticness'].values)[i]=upper_limit\n    elif (df_unified['acousticness'].values)[i]<lower_limit:\n        (df_unified['acousticness'].values)[i]=lower_limit\n    else:\n        (df_unified['acousticness'].values)[i]=(df_unified['acousticness'].values)[i]\n","d95cf6d4":"sns.heatmap(df_unified.corr())","32ba9eb7":"sns.heatmap(df_train.corr())","21a4eeec":"df_unified.columns","9c9516d2":"from sklearn.preprocessing import PowerTransformer\nskew_cols=['acousticness','instrumentalness','loudness','audio_mode','speechiness']\nfor column in skew_cols:\n    pt = PowerTransformer(method='yeo-johnson')\n    df_unified[column]=pt.fit_transform(df_unified[column].values.reshape(-1,1))","9ac62d8d":"df_train['song_popularity'].value_counts()","7b4f9f3e":"train=df_unified.head(df_train.shape[0])\ntrain=train.drop('id',axis=1)\ntest=df_unified.tail(df_test.shape[0])","cd759543":"target=df_train.song_popularity","eeee7332":"train.shape","1f90fb0f":"test=test.drop('id',axis=1)\ntest.shape","a794c7dc":"target.shape","5f17d3f0":"from sklearn.model_selection import train_test_split\nX_train , X_valid , y_train , y_valid = train_test_split(train,target,test_size=0.1,stratify=target,random_state=42)","30c536e9":"from imblearn.over_sampling import SMOTE,ADASYN,SVMSMOTE,BorderlineSMOTE\n\n# oversample = SMOTE()\n# oversample = ADASYN()\n# oversample = SVMSMOTE()\n# oversample = BorderlineSMOTE()\n# X_train, y_train = oversample.fit_resample(X_train, y_train)","f53f9345":"y_train.shape","eee8f935":"import lightgbm as lgb","31da1bf9":"import optuna\nimport optuna.integration.lightgbm as optuna_lgb\n\ndtrain = optuna_lgb.Dataset(X_train, label=y_train)\ndvalid = optuna_lgb.Dataset(X_valid, label=y_valid)\ndtest = optuna_lgb.Dataset( test )\n\nlgb_params = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 3,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':5000,\n    'colsample_bytree':0.1107\n    }\n\nbest_params_, history = {}, []\nmodel = optuna_lgb.train( lgb_params , dtrain , valid_sets=dvalid,\n                        verbose_eval=False, num_boost_round=10000,\n                        early_stopping_rounds=100 )","0a1b8ac2":"best_params = model.params\nprint(\"Best params:\", best_params)\nprint(\"  Params: \")\nfor key, value in best_params.items():\n    print(\"{}: {}\".format(key, value))","31828ff0":"preds_valid = model.predict(X_valid,num_iteration=model.best_iteration)\ntest_predict = model.predict(test,num_iteration=model.best_iteration)\nprint('test score:',roc_auc_score(y_valid,preds_valid))","4919770e":"test1 = df_unified.tail(df_test.shape[0])","d1aa7d45":"test1['song_popularity']=0\ntest1['song_popularity']=test_predict\ndf_sub=test1[['id','song_popularity']]\ndf_sub","72dd7c21":"df_sub.to_csv('optuna_lgb_sub.csv',index=False)","8c7447a1":"# MODELLING","0e132062":"# Preprocessing+EDA"}}