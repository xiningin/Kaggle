{"cell_type":{"7a5f8247":"code","b78666ee":"code","4c80ecf9":"code","b46ca45d":"code","78389d9b":"code","4c2bbc20":"code","d2fd0a4e":"code","eea6df76":"code","c2a4844c":"code","3706fb9e":"code","afe09d0c":"code","5866b4c2":"code","d1101387":"code","beb3e010":"code","29e91d84":"code","9dbf2f72":"code","96aa10ab":"code","dba30f0d":"code","a49e6592":"code","f7d07448":"code","80864625":"markdown","984b304d":"markdown","3eaaf9bf":"markdown","4ec4eb12":"markdown","864fe60f":"markdown","91ab48af":"markdown","a23d5dab":"markdown","22465c2f":"markdown","608599bb":"markdown","047c8097":"markdown"},"source":{"7a5f8247":"# importing libraries\nimport numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split","b78666ee":"# Read the data\ntrain = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","4c80ecf9":"# print first five rows\ntrain.head()","b46ca45d":"# column names\ntrain.columns","78389d9b":"# columns with null values\ntrain_col_null = train.columns[train.isnull().any()==True].tolist()\n# null values in these columns\ntrain[train_col_null].isnull().sum()","4c2bbc20":"# print first five rows\ntest.head()","d2fd0a4e":"# column names\ntest.columns","eea6df76":"# columns with null values\ntest_col_null = test.columns[test.isnull().any()==True].tolist()\n# null values in these columns\ntest[test_col_null].isnull().sum()","c2a4844c":"# Remove rows with missing target\nX = train.dropna(axis=0, subset=['SalePrice'])\n\n# separate target from predictors\ny = X.SalePrice              \nX.drop(['SalePrice'], axis=1, inplace=True)","3706fb9e":"# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y,\n                                                                train_size=0.8,\n                                                                test_size=0.2,\n                                                                random_state=0)","afe09d0c":"# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n\nlow_cardinality_cols = [cname for cname in X_train_full.columns \n                        if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]","5866b4c2":"# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns\n                if X_train_full[cname].dtype in ['int64', 'float64']]","d1101387":"# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\n\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\n\n# for test data also\nX_test = test[my_cols].copy()","beb3e010":"# One-hot encode the data\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\n\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","29e91d84":"# Define the model\nxgb =  XGBRegressor(n_estimators=1000,\n                    learning_rate=0.05)","9dbf2f72":"# Fit the model\nxgb.fit(X_train, y_train)","96aa10ab":"# Get predictions\ny_pred = xgb.predict(X_valid)","dba30f0d":"# Calculate MAE\nmae = mean_absolute_error(y_pred, y_valid)\nprint(\"Mean Absolute Error:\" , mae)","a49e6592":"# prediction\nprediction = xgb.predict(X_test)","f7d07448":"# Submission file\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': prediction})\noutput.to_csv('submission.csv', index=False)\noutput.head()","80864625":"## Exploratory Data Analysis","984b304d":"#### Train data","3eaaf9bf":"## Feature Engineering","4ec4eb12":"#### Test data","864fe60f":"## Model Fitting and Prediction","91ab48af":"Upvote if you like this notebook\n### Thank You","a23d5dab":"## Introduction","22465c2f":"This is my submission to the [Housing Prices Competition for Kaggle Learn Users](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course\/overview). I have used **XGBoost** for prediction. As I'm writing this , I am ranked among the **top 3%** of all Kagglers. \n\nI hope you enjoy while reading it! And if you liked this kernel feel free to **upvote** and leave **feedback**, thanks!","608599bb":"Let's start...","047c8097":"![Housing Prices Competition](https:\/\/i.imgur.com\/JRIWMD2.png)"}}