{"cell_type":{"8873104f":"code","af914daf":"code","dd4f0891":"code","d782f4cd":"code","90379be1":"code","19b55954":"code","fd4760c2":"code","7ffe4291":"code","1607c65e":"code","f8b249f1":"code","fb4a8b50":"code","846a289b":"code","3795cd4f":"code","b167488f":"code","48feb793":"code","64ec8a3b":"code","5c271dd1":"code","307def81":"code","e8ab4099":"code","6037de1f":"code","51ffb43e":"code","0dc0e167":"code","89d2d3b5":"code","22e32256":"code","b164879e":"code","947a293c":"code","54bb2303":"code","69cc56e9":"code","edaaeee3":"code","55948a45":"code","fc05b4fb":"code","e2a949aa":"code","7662f024":"code","76eb3eb0":"code","c791a5f7":"code","07476e4f":"code","443f8d67":"markdown"},"source":{"8873104f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","af914daf":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n","dd4f0891":"#load dataset\ndata=pd.read_csv('..\/input\/train_ship_segmentations.csv')","d782f4cd":"import os\n","90379be1":"PATH='..\/input\/'","19b55954":"#get the train and test images\ntrain_imgs=os.listdir(PATH+'train')\ntest_imgs=os.listdir(PATH+'test')","fd4760c2":"#lets peek\ntrain_imgs[:5]","7ffe4291":"#lets peek\ntest_imgs[:5]","1607c65e":"#ffunction to show images\ndef show_img(PATH):\n    plt.figure(figsize=(10,7))\n    img=plt.imread(PATH)\n    plt.imshow(img)\n    plt.show()","f8b249f1":"#lets look at some training samples\nfor i in train_imgs[:5]:\n    show_img(PATH+'train\/'+i)","fb4a8b50":"#lets look at some testing samples\nfor i in test_imgs[:5]:\n    show_img(PATH+'test\/'+i)","846a289b":"#a peek at data\ndata.head()","3795cd4f":"#lets look at some samples from dataset\nfor i in data['ImageId'].head():\n    show_img(PATH+'train\/'+i)","b167488f":"#make path for images\nmake_path=lambda x: PATH+'train\/'+x\ndata['ImagePath']=make_path(data['ImageId'].values)","48feb793":"data.head()","64ec8a3b":"#check for any missing values\ndata.isnull().sum()\/data.shape[0]*100.0","5c271dd1":"# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","307def81":"def rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","e8ab4099":"data.shape","6037de1f":"data['ImageId'].value_counts().shape","51ffb43e":"from sklearn.model_selection import train_test_split","0dc0e167":"from skimage.segmentation import mark_boundaries\nfrom skimage.util.montage import montage2d as montage\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n","89d2d3b5":"from skimage.morphology import label\ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n","22e32256":"def masks_as_image(in_mask_list):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)","b164879e":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nrle_0 = data.query('ImageId==\"000155de5.jpg\"')['EncodedPixels']\nimg_0 = masks_as_image(rle_0)\nax1.imshow(img_0[:, :, 0])\nax1.set_title('Image$_0$')\nrle_1 = multi_rle_encode(img_0)\nimg_1 = masks_as_image(rle_1)\nax2.imshow(img_1[:, :, 0])\nax2.set_title('Image$_1$')\nprint('Check Decoding->Encoding',\n      'RLE_0:', len(rle_0), '->',\n      'RLE_1:', len(rle_1))","947a293c":"data['ships'] = data['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\nunique_img_ids = data.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\nunique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\nunique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])","54bb2303":"data.head()","69cc56e9":"unique_img_ids.head()","edaaeee3":"from sklearn.model_selection import train_test_split\ntrain_ids, valid_ids = train_test_split(unique_img_ids, \n                 test_size = 0.3, \n                 stratify = unique_img_ids['ships'])\ntrain_df = pd.merge(data, train_ids)\nvalid_df = pd.merge(data, valid_ids)\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')","55948a45":"train_ids.head()","fc05b4fb":"train_df.head()","e2a949aa":"BATCH_SIZE = 32\nEDGE_CROP = 16\nGAUSSIAN_NOISE = 0.1\nUPSAMPLE_MODE = 'SIMPLE'\n# downsampling inside the network\nNET_SCALING = (1, 1)\n# downsampling in preprocessing\nIMG_SCALING = (2, 2)\n# number of validation images to use\nVALID_IMG_COUNT = 600\n# maximum number of steps_per_epoch in training\nMAX_TRAIN_STEPS = 150\nAUGMENT_BRIGHTNESS = False","7662f024":"def make_image_gen(in_df, batch_size = BATCH_SIZE):\n    all_batches = list(in_df.groupby('ImageId'))\n    out_rgb = []\n    out_mask = []\n    while True:\n        np.random.shuffle(all_batches)\n        for c_img_id, c_masks in all_batches:\n            rgb_path = os.path.join(train_image_dir, c_img_id)\n            c_img = imread(rgb_path)\n            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n            if IMG_SCALING is not None:\n                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n            out_rgb += [c_img]\n            out_mask += [c_mask]\n            if len(out_rgb)>=batch_size:\n                yield np.stack(out_rgb, 0)\/255.0, np.stack(out_mask, 0)\n                out_rgb, out_mask=[], []","76eb3eb0":"train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+2)\/\/3)\nbalanced_train_df = train_df.groupby('grouped_ship_count').apply(lambda x: x.sample(1500))\nbalanced_train_df['ships'].hist()\n","c791a5f7":"balanced_train_df.head()","07476e4f":"balanced_train_df.shape","443f8d67":"57%  segmented values are missings .\n"}}