{"cell_type":{"63e20ce6":"code","ad43628f":"code","143675d9":"code","69da6a6e":"code","6d6c91ec":"code","f16232b8":"code","7d066c7d":"code","ebe6b561":"code","6c58e7fc":"code","61fcd3bb":"code","f12a1f3e":"code","548f13a0":"code","c367c824":"code","5bf2b9d7":"code","f5eb1d69":"markdown","23ae5df5":"markdown","7bacb23e":"markdown","bee9b553":"markdown","f5677667":"markdown","3f712fd3":"markdown","e13f59b5":"markdown","39d35c6c":"markdown","7ca0744c":"markdown","f694498e":"markdown"},"source":{"63e20ce6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\n%matplotlib inline","ad43628f":"df = pd.read_csv('..\/input\/heart.csv')\ndf.head()","143675d9":"df.info()","69da6a6e":"df.describe()","6d6c91ec":"sb.set_style('whitegrid')\nplt.figure(figsize=(30,15))\nsb.pairplot(df, hue='target', palette='coolwarm')","f16232b8":"for col in df.drop(['target'], axis=1).columns:\n    sb.lmplot(data=df, x=col, y='target', fit_reg=False, hue='target',palette='Set2', legend=False, scatter_kws={'alpha':0.5})","7d066c7d":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","ebe6b561":"X = df.drop(['target'], axis=1)\ny = df['target']\n\nfrom sklearn.preprocessing import StandardScaler\nstds = StandardScaler()\nX = stds.fit_transform(X)\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=101)\n","6c58e7fc":"def knnprediction(k, Xtrain, ytrain, Xtest):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(Xtrain, ytrain)\n    pred = knn.predict(Xtest)\n    return pred","61fcd3bb":"error_mean = []\nfor k in range(1, 41):\n    pred_i = knnprediction(k, Xtrain, ytrain, Xtest)\n    error_mean.append(np.mean(pred_i != ytest))","f12a1f3e":"plt.plot(range(1,41), error_mean, linestyle='dashed', color='b', marker='o', markerfacecolor='r', markersize=10)\nplt.title('K-Value vs Error Mean')\nplt.show()","548f13a0":"pred = knnprediction(14, Xtrain, ytrain, Xtest)","c367c824":"cm = confusion_matrix(ytest, pred)\nprint('True Negative : ' + str(cm[0][0]))\nprint('False Positive : ' + str(cm[0][1]))\nprint('False Neagtive  : ' + str(cm[1][0]))\nprint('True Positive : ' + str(cm[1][1]))","5bf2b9d7":"print(classification_report(ytest, pred))","f5eb1d69":"> # Prediction using KNN model after standardization and finding best K value.","23ae5df5":"## Exploratory Data Analysis","7bacb23e":"## Applying Standardization and Spliting data into training data and test data","bee9b553":"## Adding Required Libraries","f5677667":"## Loading Libraries required for Prediction","3f712fd3":"# Here we can see that precision, recall and f1-score is > 0.85 so we can consider that the prediction is pretty accurate. ","e13f59b5":"## Searching for best K value to use for prediction.","39d35c6c":"### As k = 14 yields minimum error mean, so we are going to use k=24 for predicting target field.","7ca0744c":"## Showing evaluation of prediction.","f694498e":"## Applying best k value i.e. 14 for prediction"}}