{"cell_type":{"0bbd94ac":"code","b9e1419f":"code","926b9063":"code","9b41cdbe":"code","a9858443":"code","aed018e8":"code","ac1915b9":"code","5c7be2ab":"code","55acbe04":"code","3f50932d":"code","d1e1b67d":"code","42fdb61e":"code","c71f1125":"code","bd746f64":"markdown"},"source":{"0bbd94ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b9e1419f":"import keras\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D,Dense,Dropout,Softmax,Input,Flatten\nfrom keras.optimizers import Adam,RMSprop,SGD\nfrom keras.layers.merge import add\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import BatchNormalization","926b9063":"from sklearn.metrics import roc_auc_score,roc_curve,accuracy_score,recall_score\nfrom keras.metrics import categorical_accuracy\n%matplotlib inline\nfrom keras.preprocessing.image import ImageDataGenerator","9b41cdbe":"from tensorflow import set_random_seed\nos.environ['PYTHONHASHSEED'] = \"0\"\nnp.random.seed(1)\nset_random_seed(2)","a9858443":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\",\n                 input_shape=(64,64,1)))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=0.4))\nmodel.add(Dense(2, activation=\"softmax\"))","aed018e8":"model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","ac1915b9":"gen = ImageDataGenerator()\ntrain_batches = gen.flow_from_directory(\"..\/input\/chest_xray\/chest_xray\/train\",model.input_shape[1:3],color_mode=\"grayscale\",shuffle=True,seed=1,\n                                        batch_size=16)\nvalid_batches = gen.flow_from_directory(\"..\/input\/chest_xray\/chest_xray\/val\", model.input_shape[1:3],color_mode=\"grayscale\", shuffle=True,seed=1,\n                                        batch_size=16)\ntest_batches = gen.flow_from_directory(\"..\/input\/chest_xray\/chest_xray\/test\", model.input_shape[1:3], shuffle=False,\n                                       color_mode=\"grayscale\", batch_size=8)","5c7be2ab":"model.fit_generator(train_batches,validation_data=valid_batches,epochs=3)","55acbe04":"model.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit_generator(train_batches,validation_data=valid_batches,epochs=3)","3f50932d":"p = model.predict_generator(test_batches, verbose=True)\npre = pd.DataFrame(p)\npre[\"filename\"] = test_batches.filenames\npre[\"label\"] = (pre[\"filename\"].str.contains(\"PNEUMONIA\")).apply(int)\npre['pre'] = (pre[1]>0.5).apply(int)","d1e1b67d":"recall_score(pre[\"label\"],pre[\"pre\"])","42fdb61e":"roc_auc_score(pre[\"label\"],pre[1])","c71f1125":"tpr,fpr,thres = roc_curve(pre[\"label\"],pre[1])\nroc = pd.DataFrame([tpr,fpr]).T\nroc.plot(x=0,y=1)","bd746f64":"A simple and fast cnn model, very easy to use.  It's not the best score, do some little changes and more round training  it will have better result. "}}