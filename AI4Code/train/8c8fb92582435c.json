{"cell_type":{"64fa74bb":"code","f086d720":"code","6808cf41":"code","f364f307":"code","d9698cdd":"code","fdbf61e4":"code","3b621ffe":"code","8de6e2e2":"code","19514654":"code","08607966":"code","f4b5d312":"code","d0ca0318":"code","24ab5956":"code","2f427645":"code","126fec75":"code","31b2c1ef":"code","af5d6e88":"code","d7432537":"code","90bb9591":"code","3770f1cb":"code","ccc7514b":"code","8bd4d1e3":"code","485c2267":"code","e48e8467":"code","d6ca3d59":"code","81df5c69":"code","e7311f02":"code","e7f5c58b":"code","eba5dcb5":"code","fe913fd3":"code","1641aad2":"code","516b4d61":"code","ac5c885b":"code","c25d583c":"code","7e5e8c68":"code","67b5dede":"code","fa39d1bc":"markdown","d2563ec8":"markdown","44b07bc4":"markdown","b27c14af":"markdown","6c3e3a61":"markdown","81b3489d":"markdown","b455eb79":"markdown","632686bc":"markdown","01b309b3":"markdown","32c3d599":"markdown","2e123bcb":"markdown","8a770432":"markdown","2e6ed8aa":"markdown","8af4d749":"markdown","102bc560":"markdown","baeceb6f":"markdown","d47a622f":"markdown","e48954d7":"markdown","31b22fc2":"markdown","e7883857":"markdown","7da4f31f":"markdown","39f33490":"markdown","dbca06dd":"markdown","a6802cb1":"markdown","4ca12f3d":"markdown","79f2fca4":"markdown"},"source":{"64fa74bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f086d720":"# submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\n# df_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n# df_test.index == submission.index","6808cf41":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf.head(3)","f364f307":"df.info()","d9698cdd":"df.head(10)\n# df.tail()","fdbf61e4":"df.columns","3b621ffe":"# df.isnull()\nprint(df.isnull().sum())\nprint(df.isnull().sum()\/len(df))","8de6e2e2":"# df.head()","19514654":"df = df.drop(['Cabin'], axis=1)\ndf.info()","08607966":"df.head()\ndf.tail(3)","f4b5d312":"# try to proceed it with non-null logic\ndf = df[df['Embarked'].notnull()].reset_index(drop=True)\ndf.info()","d0ca0318":"# df['Age'] = df['Age'].replace(np.nan, np.median(df['Age']))\ndf['Age'] = df['Age'].replace(np.nan, np.mean(df['Age']))\ndf.info()","24ab5956":"# np.median(df['Age'].dropna())","2f427645":"df.columns\ndf = df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\ndf.head()","126fec75":"import matplotlib.pyplot as plt\nimport seaborn as sn\n\ncorr_matrix = df.corr()\nprint(corr_matrix)\nsn.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\")\nplt.show()","31b2c1ef":"plt.scatter(df['SibSp'], df['Parch'])\nplt.xlabel(\"SibSp\")\nplt.ylabel(\"Parch\")","af5d6e88":"df['Survived'].value_counts()","d7432537":"df['Survived'].value_counts().plot.bar()\nplt.xlabel(\"if survived\")\nplt.ylabel(\"counts\")\n# try others, and say what did you see.  'Pclass', 'Sex', 'Embarked'","90bb9591":"def draw_barchart(df, col_name):    \n    result = df[col_name].value_counts()\/len(df)\n    result.plot.bar()\n    plt.xlabel(col_name)\n    plt.ylabel(\"ratio\")\n    plt.show()\n    \ndraw_barchart(df, 'Pclass')\n# draw_barchart(df, 'Sex')\n# draw_barchart(df, 'Embarked')","3770f1cb":"df['Age'].hist(bins=16)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Counts\")\nplt.show()","ccc7514b":"df['Fare'].hist(bins=3)\nplt.xlabel(\"Fare\")\nplt.ylabel(\"Counts\")\nplt.show()","8bd4d1e3":"stats = df['Fare'].describe()\nprint(stats)\nQ1 = stats['25%']\nQ3 = stats['75%']\nIQR = Q3 - Q1\nupper_bound = Q3 + 1.5*IQR\nlower_bound = Q1 - 1.5*IQR\nupper_bound, lower_bound","485c2267":"# df.boxplot(column = ['Age', 'Fare'], backend = 'matplotlib')\ndf.boxplot(column = ['Fare'], backend = 'matplotlib')\nplt.show()\ndf.boxplot(column = ['Age'], backend = 'matplotlib')\nplt.show()","e48e8467":"CATEGORICAL_COL = ['Pclass', 'Sex', 'Embarked']\nNUMERICAL_COL = ['Age', 'SibSp', 'Parch', 'Fare']","d6ca3d59":"df.info()","81df5c69":"df['Pclass'] = df['Pclass'].astype(str)\ndf.info()","e7311f02":"CATEGORICAL_COL = ['Pclass', 'Sex', 'Embarked']\ndf_category = df.loc[:,CATEGORICAL_COL]\n\ndf_category = pd.DataFrame(pd.get_dummies(df_category))\ndf_category.head()","e7f5c58b":"# drop redundant columns\ndf_category = df_category.drop(['Pclass_1', 'Sex_female', 'Embarked_C'], axis=1)","eba5dcb5":"df_numeric = df.loc[:, NUMERICAL_COL]\ndf_numeric.head()","fe913fd3":"df_final = pd.concat([df_category, df_numeric], axis=1)\ndf_final.info()\ndf_final.head()","1641aad2":"from sklearn.model_selection import train_test_split\n\nX = df_final\ny = df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=777)","516b4d61":"X_train.columns","ac5c885b":"# standarization z-score\nfrom sklearn.preprocessing import StandardScaler\nX_train_std = StandardScaler().fit_transform(X_train[['Age', 'SibSp', 'Parch', 'Fare']])\nX_train_std = np.concatenate((X_train[['Pclass_2', 'Pclass_3', 'Sex_male', 'Embarked_Q', 'Embarked_S']], X_train_std), axis=1)\nX_test_std = StandardScaler().fit_transform(X_test[['Age', 'SibSp', 'Parch', 'Fare']])\nX_test_std = np.concatenate((X_test[['Pclass_2', 'Pclass_3', 'Sex_male', 'Embarked_Q', 'Embarked_S']], X_test_std), axis=1)\nprint(pd.DataFrame(X_train_std).head())\n# scaling 0~1\nfrom sklearn.preprocessing import MinMaxScaler\nX_train_scale = MinMaxScaler().fit_transform(X_train)\nX_test_scale = MinMaxScaler().fit_transform(X_test)\nprint(pd.DataFrame(X_train_scale).head())","c25d583c":"from sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=10).fit(X_train_std, y_train)\ny_pred = clf_knn.predict(X_test_std)\n\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","7e5e8c68":"from sklearn import tree\nclf_dtree = tree.DecisionTreeClassifier().fit(X_train_std, y_train)\ny_pred = clf_dtree.predict(X_test_std)\n\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","67b5dede":"# tree.plot_tree(clf_dtree)\n\n# parameter-tuning","fa39d1bc":"## Experiment with different Hyperparameters","d2563ec8":"# Section 1\n\n\n![](https:\/\/i.imgur.com\/MUmsK8j.gif)\n\n\n## [Titanic Intro](https:\/\/www.youtube.com\/watch?v=2e-eXJ6HgkQ)","44b07bc4":"## What does each column mean?","b27c14af":"# 1. Load Data\n\nWe use package pandas to load our data into datafame. But here are some questions we might have:\n![](https:\/\/www.publicdomainpictures.net\/pictures\/130000\/nahled\/forklift-truck-loading-up.jpg)\n\n## what is pandas?\n\n![](https:\/\/storage.ning.com\/topology\/rest\/1.0\/file\/get\/1157930838?profile=original)\nsource: https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Fwww.datasciencecentral.com%2Fprofiles%2Fblogs%2Fpython-machine-learning-libraries&psig=AOvVaw3y-HmtpOXQkRj4dRpGhRfv&ust=1594621503219000&source=images&cd=vfe&ved=0CAMQjB1qFwoTCNCS4piKx-oCFQAAAAAdAAAAABAN\n\n## what is dataframe?\n\n![](https:\/\/www.w3resource.com\/w3r_images\/pandas-data-structure.svg)\nsource: https:\/\/www.w3resource.com\/python-exercises\/pandas\/index.php\n\n## where is our data? It's a csv file, but what is csv? <br>\nComma Separated Values (CSV)\n\n![image.png](attachment:image.png)","6c3e3a61":"## Histogram for Numerical Variables","81b3489d":"# Section 2\n\n![](https:\/\/www.newworldai.com\/wp-content\/uploads\/Machine-learning-715x400.jpg)","b455eb79":"## Normalization\n* z = (x - u) \/ s\n\n* (X - X.min(axis=0)) \/ (X.max(axis=0) - X.min(axis=0))","632686bc":"## [Group Discussion] What did you see from the table below?","01b309b3":"# hello\n## hello\n### hello\n\n* hello","32c3d599":"# 2. Understand Data\n![figure](https:\/\/miro.medium.com\/max\/1400\/1*0YKaiRfOSRQGtjObCQmxIA.png)\n\n## How many records and columns we have? Tell us what you see.","2e123bcb":"## Label Encoding and Onehot Econding","8a770432":"## Split Data","2e6ed8aa":"Missing Ratio of Columns:\n* Age: 19.87%\n* Cabin: 77.10%\n* Embarked: 0.22%\n\nWe either drop the missing values or impute them.\nLet's drop missing values of Embarked since it is less than 1% of total data volume.","8af4d749":"### KNN\ntry differen values of n_neighbors, what did you see?","102bc560":"![figure](https:\/\/miro.medium.com\/max\/1400\/1*0YKaiRfOSRQGtjObCQmxIA.png)\n\n## [Group Discussion] Why do this project?\n![](https:\/\/s3.amazonaws.com\/pas-wordpress-media\/content\/uploads\/2020\/01\/16152228\/bigstock-Flat-Design-Concept-Of-Consult-311989798-min.jpg)\n\n* Supervised or unsupervised?","baeceb6f":"* explain mean, mode, median","d47a622f":"## Drop Useless Columns","e48954d7":"# 4. Visualize Data\n## Correlation Matrix:\n![](https:\/\/cdn.corporatefinanceinstitute.com\/assets\/correlation1.png)","31b22fc2":"## Decision Tree\n\n* criterion: measure the quality of split\n* max_depth\n* min_samples_split","e7883857":"* 'PassengerId'\n* 'Survived'\n* 'Pclass'\n* 'Name'\n* 'Sex'\n* 'Age'\n* 'SibSp'\n* 'Parch'\n* 'Ticket'\n* 'Fare'\n* 'Cabin'\n![](https:\/\/i.imgur.com\/8btFWrz.png)\n* 'Embarked'\n![](https:\/\/i.imgur.com\/nDyDuqu.png)","7da4f31f":"## Barchart for Categorical Variables","39f33490":"## Box Plot:\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/1\/1a\/Boxplot_vs_PDF.svg\/939px-Boxplot_vs_PDF.svg.png)","dbca06dd":"* 64-bits (8-bytes) space in the memory","a6802cb1":"# 3. Clean Data\n![figure](https:\/\/miro.medium.com\/max\/1400\/1*0YKaiRfOSRQGtjObCQmxIA.png)\n\n## Let's start with missing values","4ca12f3d":"# Build and Train Model","79f2fca4":"## Any Questions?"}}