{"cell_type":{"138c4756":"code","45b01704":"code","902e02c2":"code","a488e732":"code","7d253042":"code","7cfa66e3":"code","f647a9f8":"code","4aa5cbf1":"code","49c6c8cb":"code","7630fb80":"code","c03064ea":"code","8a4ea3c9":"code","31408617":"code","f6bd7f8a":"code","50082f5e":"code","dc66fa50":"code","5484030d":"code","37667a12":"code","d8c87181":"code","f78e7ffc":"code","638c05d4":"code","df8d989e":"code","a186c972":"code","de523fd4":"code","1a86259d":"code","33dc6dc5":"code","433da3c0":"code","614098b4":"code","9de0a17d":"code","af0b582c":"code","bcb14a19":"code","851b8e46":"code","0190c303":"code","e3a9be5b":"code","ab7b3d98":"markdown","b6e8b54a":"markdown","400aad88":"markdown","3ddbaf64":"markdown","e6b2a19f":"markdown","fee4ec8d":"markdown","5af2e8c9":"markdown","18425b33":"markdown","686f29eb":"markdown","9c34751b":"markdown","ce09a926":"markdown","631825c3":"markdown","a143e11f":"markdown","57e6b4a3":"markdown","69bfff78":"markdown","e521f8b8":"markdown","b9a64f11":"markdown","91844834":"markdown","f5ceb4d4":"markdown","098f3c97":"markdown","fc4c56a3":"markdown","acda59f3":"markdown","38e0a62b":"markdown","d0408a07":"markdown","56eea94b":"markdown","7382b876":"markdown","97a23d39":"markdown","f2f3f684":"markdown","7e4b6eaa":"markdown","bf40b623":"markdown","2d0a874d":"markdown","0233a290":"markdown","973c529f":"markdown","23dd6376":"markdown","23f5fc45":"markdown","18a67c7b":"markdown","94a20013":"markdown","f87bf4c2":"markdown","81afdf94":"markdown","f6a8e4b4":"markdown","ece5859f":"markdown","eb6aa2c2":"markdown","ed9f9295":"markdown","4739490c":"markdown","08e6687f":"markdown","35f479c5":"markdown","b7d3354c":"markdown","39f71069":"markdown","8b21447a":"markdown","33ff09d3":"markdown","a3c60c8b":"markdown","ea50c2ee":"markdown","79621396":"markdown","1f06f5ca":"markdown","3c86f394":"markdown","91bd7f92":"markdown","e3eef2dd":"markdown","b84bf65f":"markdown","e5fa97e0":"markdown","fe535139":"markdown","8e476a12":"markdown","b6bba0bf":"markdown","3da3ac17":"markdown","25c71d3c":"markdown","cbc39b2a":"markdown","b0f7ec33":"markdown","16c763f5":"markdown"},"source":{"138c4756":"import numpy as np\nimport pandas as pd\n\n# Reading the csv file into a DataFrame\ndf = pd.read_csv('..\/input\/youtube-new\/USvideos.csv')\ndf","45b01704":"df[['video_id', 'title']]","902e02c2":"df.loc[:, ['video_id', 'title']]","a488e732":"df.loc[:, ['channel_title']].drop_duplicates()","7d253042":"df.loc[:, ['video_id', 'title']].head(5)","7cfa66e3":"df.loc[:, ['video_id', 'title']].tail(5)","f647a9f8":"df.loc[:, ['views']].min()","4aa5cbf1":"df.loc[:, ['views']].max()","49c6c8cb":"df.loc[:, ['views']].count()","7630fb80":"df.loc[:, ['views']].mean()","c03064ea":"df.loc[:, ['views']].sum()","8a4ea3c9":"new_df = df.loc[:, ['likes']].max().rename({'likes': 'MAX(likes)'})\nnew_df['MIN(dislikes)'] = df.loc[:, ['dislikes']].min().values[0]\nnew_df","31408617":"df.loc[df['likes'] >= 1000000, ['video_id', 'title']]","f6bd7f8a":"df.loc[(df['likes'] >= 1000000) & (df['dislikes'] <= 5000), ['video_id', 'title']].drop_duplicates()","50082f5e":"df.loc[~pd.isnull(df['description']), ['video_id', 'title']].drop_duplicates()","dc66fa50":"import re\n\ndef like(x, pattern):\n    r = re.compile(pattern)\n    vlike = np.vectorize(lambda val: bool(r.fullmatch(val)))\n    return vlike(x)\n\ndf_notnull = df.loc[~pd.isnull(df['description']), :]\ndf_notnull.loc[like(df_notnull['description'], '.* math .*'), ['video_id', 'title']].drop_duplicates()","5484030d":"df.loc[df['likes'] >= 1000000, ['video_id', 'title']].sort_values(by=['title'], ascending=True).drop_duplicates()","37667a12":"df.loc[:, ['channel_title', 'views', 'likes', 'dislikes']].groupby(['channel_title']).sum()","d8c87181":"g = df.groupby(['channel_title'])\ng = g.filter(lambda x: x['video_id'].count() > 100)\ng = g.loc[:, ['channel_title', 'views', 'likes', 'dislikes']].groupby(['channel_title']).mean()\ng","f78e7ffc":"new_row = pd.DataFrame({'video_id': ['EkZGBdY0vlg'],\n                        'channel_title': ['Professor Leonard'],\n                        'title': ['Calculus 3 Lecture 13.3: Partial Derivatives']})\ndf = df.append(new_row, ignore_index=True)\ndf","638c05d4":"df.drop(np.where(~(df['channel_title'] == '3Blue1Brown'))[0])","df8d989e":"df['like_ratio'] = df['likes'] \/ (df['likes'] + df['dislikes'])","a186c972":"df","de523fd4":"del df['comments_disabled']","1a86259d":"df","33dc6dc5":"df.loc[df['channel_title'] == 'Veritasium', ['title', 'likes']]","433da3c0":"df['likes'] = np.where(df['channel_title'] == 'Veritasium', df['likes']+100, df['likes'])","614098b4":"df.loc[df['channel_title'] == 'Veritasium', ['title', 'likes']]","9de0a17d":"df_titles = df.loc[:, ['video_id', 'title']].drop_duplicates()\ndf_titles","af0b582c":"df_stats = df.loc[:, ['video_id', 'views', 'likes', 'dislikes']].groupby('video_id').max()\ndf_stats = df_stats.reset_index()\ndf_stats","bcb14a19":"df_titles.join(df_stats.set_index('video_id'), on='video_id', how='inner')","851b8e46":"df_titles.join(df_stats.set_index('video_id'), on='video_id', how='outer')","0190c303":"df_titles.join(df_stats.set_index('video_id'), on='video_id', how='left')","e3a9be5b":"df_titles.join(df_stats.set_index('video_id'), on='video_id', how='right')","ab7b3d98":"This SQL keyword is used to sort the results in ascending or descending order.  \nIt is straightforward to translate this to pandas, you just call the `.sort_values(by=['col1', ...], ascending=True\/False)` method on a dataframe.","b6e8b54a":"`SELECT col1, col2, ... FROM table ORDER BY col1, col2 ASC|DESC`","400aad88":"In order to show examples of joins I need at least two tables, so I will split the data frame used so far into two smaller tables.","3ddbaf64":"## 3. ORDER BY","e6b2a19f":"`SELECT col1, col2, ... FROM table`","fee4ec8d":"## 9. UPDATE","5af2e8c9":"A JOIN clause is used to combine rows from two or more tables based on a related column between them.","18425b33":"Below are examples of these types of joins of the two data frames above on 'video_id' column.","686f29eb":"Doing joins in pandas is straightforward: it has a `.join()` method that we can use like this:   \n`df1.join(df2.set_index('key_column'), on='key_column')`","9c34751b":"```sql\nSELECT column_name(s)\nFROM table1\nRIGHT JOIN table2\nON table1.column_name = table2.column_name;\n```","ce09a926":"The LIKE keyword can be used in a WHERE clause to test if a column matches a pattern.  \nIn pandas we can use python's native re module for regular expressions to accomplish the same thing, or even more as the python's re module allows for a richer set of patterns to be tested rather than SQL's LIKE.   \n\nWe will create a function `like(x, pattern)` where x is an array-like object and pattern is a string containing the pattern which we want to test for. This function will first compile the pattern into a regular expression object, then we can use the `.fullmatch(val)` method to test the `val`'s value against our pattern. In order to apply this test to each element in our x vector we will use numpy's `vectorize(func)` function to create a vector equivalent for our operation of regex matching. Finally we apply this vectorized function to our x input vector. Then all we need to do is to pass `like(df['column'], pattern)` as pirst parameter in `.loc[]`.   \n  \nAs an example the below code returns all videos that contains the word 'math' in their description.","631825c3":"Note that the reason for which we could do what we did above (`df['likes'] >= 1000000`) is that pandas has overwritten the default behavior for >= operator so that it applies the operator element-wise and returns an array of booleans of the shape that we need (number of rows).  \nBut the operators **and, or, not** don't work like that. So, we will use **&** instead of **and**, **|** instead of **or**, **~** instead of **not**.","a143e11f":"SQL's MIN(), MAX(), COUNT(), AVG(), and SUM() functions are pretty straightforward to translate to pandas:","57e6b4a3":"```sql\nSELECT column_name(s)\nFROM table1\nINNER JOIN table2\nON table1.column_name = table2.column_name;\n```","69bfff78":"`SELECT col1, col2, ... FROM table WHERE condition`","e521f8b8":"## 5. HAVING","b9a64f11":"`SELECT TOP number col1, col2 FROM table`  \nor  \n`SELECT col1, col2, ... FROM table LIMIT number`","91844834":"This is how the data looks before:","f5ceb4d4":"`SELECT MIN(col) FROM table`","098f3c97":"Using equality and inequality operators **==, <, <=, >, >=, !=** in conditions is straightforward. For example, to return only rows that have number of likes >= 1000000 we can use:","fc4c56a3":"The same thing can be made with the following syntax which makes easier to translate WHERE statements later:","acda59f3":"There are more types of joins: inner, full, left, and right joins.  \n- INNER JOIN: returns rows that have matching values in both tables\n- FULL (OUTER) JOIN: returns rows that have matching values in any of the tables\n- LEFT JOIN: returns all rows from the left table, and the matched rows from the right one\n- RIGHT JOIN: returns all rows from the right table, and the matched rows from the left one  ","38e0a62b":"## 10. JOIN","d0408a07":"`SELECT col1, col2, ... FROM table GROUP BY colN HAVING condition`","56eea94b":"`SELECT DISTINCT col1, col2, ... FROM table`","7382b876":"The GROUP BY statement groups rows that have the same value for a specific column. It is often used with aggregate functions (MIN, MAX, COUNT, SUM, AVG).  \nIn pandas it is as simple as calling the `.groupby(['col1', ...])` method, followed by a call to one of `.min()`, `.max()`, `.count()`, `.sum`, `.mean()` methods.","97a23d39":"## 6. INSERT","f2f3f684":"The SELECT DISTINCT statement returns only unique rows form a table.  \nIn a data frame there may be duplicate values. If you want to get only distinct rows (remove duplicates) it is as simple as calling the `.drop_duplicates()` method. Judging based on this method's name you may think that it removes duplicate rows from your initial data frame, but what it actually does is to return a new data frame with duplicate rows removed.","7e4b6eaa":"This SQL statement deletes a column.  \n`del df['column']` is how we do this in pandas.","bf40b623":"`SELECT MAX(col) FROM table`","2d0a874d":"Pandas operations, by default, don't modify the data frame which you are working with; they just return other data frames which you need to assign to a variable if you want to save the changes. For most examples below we don't change our original data frame, we just show the returned result.","0233a290":"## 7. DELETE","973c529f":"If you want to learn more about pandas please refer to their [documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/frame.html).  \n\nI hope you found this information useful and thanks for reading!","23dd6376":"And after:","23f5fc45":"`ALTER TABLE table ADD column`","18a67c7b":"The TOP or LIMIT keyword in SQL is used to limit the number of returned rows from the top of the table.  \nIn pandas this is very easy to do with `.head(number)` method. Pandas also has the `.tail(number)` method for showing the rows from the end of data frame.","94a20013":"Now, what if we want to do something like this:  \n`SELECT MAX(likes), MIN(dislikes) FROM table`?  \nWe need to do this in more steps:","f87bf4c2":"# Pandas equivalent of 10 useful SQL queries\n### ... or Pandas for SQL developers","81afdf94":"In SQL you can use `IS NULL` or `IS NOT NULL` to get rows that contain\/don't contain null values.","f6a8e4b4":"```sql\nUPDATE table_name\nSET column1 = value1, column2 = value2, ...\nWHERE condition;\n```","ece5859f":"How to check for null values in pandas?  \nWe will use `isnull(array-like)` function from pandas package to do that. Note that this is not a method of data frame objects, don't use `df.isnull(...)`; instead do `pd.isnull(df['column'])`. So be careful.","eb6aa2c2":"Recall the syntax we used so far for selecting columns:  \n`df.loc[:, ['col1', 'col2']]`  \nInside the square brackets of `.loc` there is place for two parameters; so far we only used the second one which is used to specify what columns you want to select. Guess for what is the first parameter? Is for selecting rows. Pandas data frames expect a list of row indices or boolean flags based on which it extracts the rows we need. So far we used only the `:` symbol which means \"return all rows\". If we want to extract only rows with indices from 50 to 80 we can use `50:80` in that place. For extracting rows based on some condition, most often we will pass there an array of boolean flags returned by some (vectorized) boolean operation. The rows on positions where we will have False will not be included in the result, only those rows with True on their positions will be returned.","ed9f9295":"`SELECT col1, col2, ... FROM table GROUP BY colN`","4739490c":"`SELECT col1, col2, ... FROM table WHERE colN IS NOT NULL`","08e6687f":"```sql\nSELECT column_name(s)\nFROM table1\nFULL OUTER JOIN table2\nON table1.column_name = table2.column_name\nWHERE condition;\n```","35f479c5":"`ALTER TABLE table DROP COLUMN column`","b7d3354c":"In case you don't know, pandas is a python library for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. The name is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals.[[1]](https:\/\/en.wikipedia.org\/wiki\/Pandas_(software) Basically, it is a way of working with tables in python. In pandas tables of data are called `DataFrame`s.  \nAs the title suggests, in this article I'll show you the pandas equivalents of some of the most useful SQL queries. This can serve both as an introduction to pandas for those who already know SQL or as a cheat sheet of common pandas operations you may need.","39f71069":"## 4. GROUP BY","8b21447a":"For the examples below I will use [this](https:\/\/www.kaggle.com\/datasnaek\/youtube-new#USvideos.csv) dataset which consists of data about trending YouTube videos in the US.","33ff09d3":"## 1. SELECT","a3c60c8b":"The SELECT statement is used to select columns of data from a table.  \nTo do the same thing in pandas we just have to use the array notation on the data frame and inside the square brackets pass a list with the column names you want to select.","ea50c2ee":"`DELETE FROM table WHERE condition`","79621396":"`SELECT AVG(col) FROM table`","1f06f5ca":"## 2. WHERE","3c86f394":"The UPDATE statement is used to change values in our table based on some condition.  \nFor doing this in python we can use numpy's `where()` function. We also saw this function a few lines above when we used it to convert boolean array to indices array. That is what this function does when given just one parameter. This function can receive 3 arrays of the same size as parameters, first one being a boolean array. Let's call them c, x, y. It returns an array of the same size filled with elements from x and y choosen in this way: if c[i] is true choose x[i] else choose y[i].  \nTo modify a data frame column we can do: `df['column'] = np.where(condition, new_values, df['column'])`.  \nIn the example below we increase the number of likes by 100 where channel_title == 'Veritasium'.","91bd7f92":"The WHERE clause is used to extract only the rows that fulfill a specified condition.","e3eef2dd":"`SELECT col1, col2, ... FROM table WHERE colN LIKE pattern`","b84bf65f":"DELETE statement is used to delete existing rows from a table based on some condition.  \nIn pandas we can use `.drop()` method to romove the rows whose indices we pass in. Unlike other methods this one doesn't accept boolean arrays as input. So we must convert our condition's output to indices. We can do that with `np.where()` function.  \nIn the example below we deleted all the rows where *channel_title != '3Blue1Brown'*.","e5fa97e0":"`SELECT SUM(col) FROM table`","fe535139":"## 8. ALTER","8e476a12":"This SQL statement is used to insert new rows in the table.  \nIn pandas we can use the `.append()` method to append a new data frame at the end of an existing one. We will use `ignore_index=True` in order to continue indexing from the last row in the old data frame.","b6bba0bf":"`INSERT INTO table (column1, column2, ...) VALUES (value1, value2, ...)`","3da3ac17":"`SELECT COUNT(col) FROM table`","25c71d3c":"To specify which type of join you want in pandas you can use the **how** parameter in `.join()` method. This parameter can be one of: 'inner', 'outer', 'left', 'right'.","cbc39b2a":"The HAVING keyword is used to filter the results based on group-level conditions.  \nIn pandas we have the `.filter(func)` method that can be called after a `groupby()` call. We need to pass to this method a function that takes a data frame of a group as a parameter and returns a boolean value that decides whether this group is included in the results or not.   \nBut if we want to do more things at once in pandas, e.g. apply aggregate functions on columns and filter results based on group-level conditions, we need to do this in more steps. Whereas in SQL we could have done this in only one query.  \nIn the example below we want to group by *channel_title*, allow only channels that have at least 100 different videos in the table, and apply average function on *views*, *likes*, and *dislikes*.  \n\nIn SQL this would be:  \n```sql\nSELECT channel_title, AVG(views), AVG(likes), AVG(dislikes)\nFROM videos_table\nGROUP BY channel_title\nHAVING COUNT(video_id) > 100;\n```","b0f7ec33":"This SQL statement adds new columns.  \nIn pandas we can do this by: `df['new_column'] = array-like`.   \n\nBelow we add a new column 'like_ratio':","16c763f5":"```sql\nSELECT column_name(s)\nFROM table1\nLEFT JOIN table2\nON table1.column_name = table2.column_name;\n```"}}