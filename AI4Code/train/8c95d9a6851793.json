{"cell_type":{"de6b657b":"code","1758164b":"code","0ab7d185":"code","e61b1883":"code","26e368bf":"code","42195624":"code","e2ca9adb":"code","86324857":"code","742cfc67":"code","e6996b91":"code","54af02b9":"code","88a828c1":"code","0aaaf44e":"code","498e466d":"code","1d638fb0":"code","aa260301":"code","b35e6f8e":"code","d063d635":"code","c6e3d8f6":"code","1b651970":"code","276b2641":"code","62889e33":"markdown","156ab5dc":"markdown","ca9ed104":"markdown","ffd0f551":"markdown","2fe3b60a":"markdown"},"source":{"de6b657b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.set_option('display.max_columns', 500)","1758164b":"DEBUG = False","0ab7d185":"train = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/sample_submission.csv')","e61b1883":"if DEBUG:\n    train = train[:10000]","26e368bf":"train.head()","42195624":"# to check if the number of unique character in object series is same in test and series\nobj_col = [col_name for col_name in train.columns if 'cat' in col_name]\nprint(f'list of all object type columns in train {obj_col}')\nfor cat_col in obj_col:\n    print(f'{cat_col} is being examined')\n    extra_variables_test = set(test['cat0'].unique()) - set(train['cat0'].unique())\n    if len(extra_variables_test)==0:\n        print(f'no extra variable to deal with in {cat_col}')\n    else:\n        print(f'***** {extra_variables_test} more in {cat_col}')\n    print(f'number of unique in {cat_col} is {train[cat_col].nunique()}')\n    print('___________________________________________________________________')","e2ca9adb":"low_cardinal_col = []\nhigh_cardinal_col = []\nfor cat_col in obj_col:\n    if train[cat_col].nunique()>5:\n        high_cardinal_col.append(cat_col)\n    else:\n        low_cardinal_col.append(cat_col)\n        \nprint(f'cols with high cardinality {high_cardinal_col}')\n\nprint(f'cols with low cardinality {low_cardinal_col}')","86324857":"train.describe()\n# the mean of all variables are around 0.5, doest look like scaling is required, \n# our first model will just take them as it is","742cfc67":"train.info() # no null values","e6996b91":"test.info() # all is good","54af02b9":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score","88a828c1":"#preprocessor = ColumnTransformer(\n#    transformers=[\n#        ('enc', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = 7), high_cardinal_col),\n#        ('ohe', OneHotEncoder(handle_unknown='ignore'), low_cardinal_col)\n#    ],\n#    remainder = 'passthrough')\n\n# this gave error __init__() got an unexpected keyword argument 'handle_unknown'","0aaaf44e":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('ohe', OneHotEncoder(handle_unknown='ignore'), obj_col)\n    ],\n    remainder = 'passthrough')","498e466d":"XGBoost_model = XGBRegressor()","1d638fb0":"first_submission_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', XGBoost_model)\n                             ])\n","aa260301":"feature_columns = list(train.columns)\nfeature_columns.remove('target')\nfeature_columns.remove('id')\nprint('all features for training ->',feature_columns)","b35e6f8e":"X_train, X_valid, y_train, y_valid = train_test_split(train[feature_columns], train['target'], test_size=0.33, random_state=42)","d063d635":"scores = -1 * cross_val_score(first_submission_pipeline, train[feature_columns], train['target'],\n                              cv=5, scoring='neg_root_mean_squared_error')\nscores","c6e3d8f6":"first_submission_pipeline.fit(train[feature_columns], train['target'])\ny_predict = first_submission_pipeline.predict(test[feature_columns])\ny_predict","1b651970":"sample_submission['target'] = y_predict","276b2641":"sample_submission.to_csv('first_submit.csv', index=False)","62889e33":"**now let us see how we deal with continours variable**","156ab5dc":"**no extra variables are there in the train set, now dealing with categorical variable we will need to encode them, three ways of dealing with them are : #dropping the series #OrdinalEncoder #OneHotEncoder **\n\n**In OneHotEncoding we will need to choose which variables to encode as nunique in high in a few of the object series, for first submission we shall encode variable with nunique with less than 5 (cardinality)\n**","ca9ed104":"**# use of pipelines and XGBoost**","ffd0f551":"# Pipeline works begins","2fe3b60a":"Checking for NULL values in train and test"}}