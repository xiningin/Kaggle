{"cell_type":{"1e5b9108":"code","8ba77309":"code","598dbf62":"code","e03b0dfc":"code","4c3be55a":"code","b2aecd57":"code","e43fc3c1":"code","13072c67":"code","cfa8a02e":"code","a97bf22b":"code","028fb0cc":"code","b323d698":"code","7de249ec":"code","ab3a33eb":"code","466e974c":"code","11ecb22d":"code","b8410cfd":"code","41af5b11":"code","fcc8d5b8":"code","8277e55f":"code","ed485abd":"code","40f03577":"code","257de7e1":"code","a9e94155":"code","59e3d11e":"code","6990b3e2":"code","ef14d1fa":"code","817df0e0":"code","c5ea2540":"code","4848f92a":"code","7faae5ac":"code","0c4ded1d":"code","f52fe757":"code","f859fe02":"code","78ef4cab":"code","e80fcf8c":"code","71928c2a":"code","504da8b4":"code","1ccd04c6":"code","7557e87b":"code","5b2b5eb4":"code","fbe480e5":"code","b807de45":"code","250e4e99":"code","9d70feba":"code","5e24c03d":"code","9b0d036e":"code","895d3082":"code","9d886b5d":"code","440b3108":"code","41e429c9":"code","2a255762":"code","6bf4295c":"code","ebe8fa46":"code","4005968b":"code","11cf761b":"code","66a1294d":"code","3fa09f37":"code","be4c04ba":"code","ca0ee09d":"code","c737c09c":"code","f3ad8524":"code","d869279e":"code","06b44a53":"code","e219bd8a":"code","1b982ed9":"code","5da72b21":"code","d6fc4ecb":"code","cfb578c2":"code","7a4efba5":"code","319d7a90":"code","2523542f":"code","6b2c844e":"code","c7aff719":"code","49b3e302":"code","2e217e80":"code","d0cfb842":"code","d808b1a9":"code","bd94bace":"code","34b01140":"code","d2610e28":"code","24e3694c":"code","b1d1bb75":"code","0cc7c575":"code","b0e1d4b3":"code","8d6eca77":"code","2857866c":"code","24ce63e2":"code","bd9c2bcf":"code","72d3a787":"code","bf9160e4":"code","d26f189f":"code","2b8bc73d":"code","f2c69265":"markdown","191f58d5":"markdown","f637d601":"markdown","75a2066b":"markdown","52f99481":"markdown","d484e9b3":"markdown","f920d049":"markdown","99e4783e":"markdown","272dc005":"markdown","d0f1fcce":"markdown","78b7dbe0":"markdown","a34835d1":"markdown","09d59d72":"markdown","ec04a925":"markdown","44cf4b85":"markdown","b717960b":"markdown","8407e2f7":"markdown","6934f3a5":"markdown","abb3475d":"markdown","3067cc18":"markdown","2913b22d":"markdown","3be435fe":"markdown","9b1a45fe":"markdown","a8c9e2fc":"markdown","11f8dde3":"markdown","4ea14cc9":"markdown","3ed88562":"markdown","091c3568":"markdown","05822e3c":"markdown","a6cff02f":"markdown"},"source":{"1e5b9108":"TRAIN_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/test.csv'","8ba77309":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","598dbf62":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom scipy.stats import mode\nimport matplotlib\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom datetime import datetime\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","e03b0dfc":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntrain_df.head(10)","4c3be55a":"matplotlib.rcParams.update({'font.size': 14})","b2aecd57":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","e43fc3c1":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","13072c67":"train_df = reduce_mem_usage(train_df)","cfa8a02e":"train_df.dtypes","a97bf22b":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","028fb0cc":"print('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0440\u0435\u0439\u043d\u0435:', train_df.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435', test_df.shape[0])","b323d698":"train_df.shape[1] - 1 == test_df.shape[1]","7de249ec":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","ab3a33eb":"plt.figure(figsize = (16, 8))\n\nplt.subplot(121)\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('count')\nplt.xlabel('Price')\n\nplt.suptitle('Distribution of Price')\nplt.show()\n","466e974c":"target_mean = round(train_df['Price'].mean(), 2)\ntarget_median = train_df['Price'].median()\ntarget_mode = train_df['Price'].mode()[0]","11ecb22d":"plt.figure(figsize = (16, 8))\n\nsns.distplot(train_df['Price'], bins=50)\n\ny = np.linspace(0, 0.000007, 10)\nplt.plot([target_mean] * 10, y, label='mean',  linewidth=4)\nplt.plot([target_median] * 10, y, label='median',  linewidth=4)\nplt.plot([target_mode] * 10, y, label='mode', linewidth=4)\n\nplt.title('Distribution of Price')\nplt.legend()\nplt.show()","b8410cfd":"df_num_features = train_df.select_dtypes(include=['float64', 'float32', 'float16'])\ndf_num_features.drop('Price', axis=1, inplace=True)","41af5b11":"df_num_features.hist(figsize=(16,16), bins=20, grid=False);","fcc8d5b8":"df_num_features.loc[df_num_features['KitchenSquare'] > 1000, 'KitchenSquare'].\\\n    hist(figsize=(4,4), bins=10, grid=False);","8277e55f":"df_num_features.loc[df_num_features['LifeSquare'] > 1000, 'LifeSquare'].\\\n    hist(figsize=(5,5), bins=5, grid=False);","ed485abd":"df_obj_features = train_df.select_dtypes(include='object')\ndf_obj_features.head()","40f03577":"train_df['Ecology_2'].unique()","257de7e1":"train_df['Ecology_3'].unique()","a9e94155":"train_df['Shops_2'].unique()","59e3d11e":"df_bin_features = train_df.select_dtypes(include=['int8','int16', 'int32'])\ndf_bin_features.head()","6990b3e2":"train_df[(train_df['HouseYear'] <= 1900) | (train_df['HouseYear'] > 2020)]","ef14d1fa":"train_df.describe()","817df0e0":"train_df['Rooms'].value_counts()","c5ea2540":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntrain_df.head()","4848f92a":"train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1\ntrain_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = train_df['Rooms'].median()","7faae5ac":"train_df['Rooms'].value_counts()","0c4ded1d":"train_df[(train_df['LifeSquare'] > train_df['Square'].max())]","f52fe757":"train_df['SquareOutlier'] = 0\ncondition = (train_df['LifeSquare'] > train_df['Square'].max())\ntrain_df.loc[condition, 'SquareOutlier'] = 1\ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","f859fe02":"train_df[(train_df['LifeSquare'] > train_df['Square'].max())]","78ef4cab":"train_df[(train_df['LifeSquare'] > train_df['Square'])]","e80fcf8c":"train_df['temp'] = train_df['Square']\ntrain_df.loc[train_df['Square'] < train_df['LifeSquare'], 'SquareOutlier'] = 1\ntrain_df.loc[train_df['SquareOutlier']==1, 'Square'] = train_df.loc[train_df['SquareOutlier']==1, 'LifeSquare']\ntrain_df.loc[train_df['SquareOutlier']==1, 'LifeSquare'] = train_df.loc[train_df['SquareOutlier']==1, 'temp']\ndel train_df['temp']","71928c2a":"train_df['KitchenSquare'].value_counts()","504da8b4":"train_df['KitchenSquare'].quantile(.99), train_df['KitchenSquare'].quantile(.025)","1ccd04c6":"condition = (train_df['KitchenSquare'].isna()) \\\n             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.99))\n\ntrain_df['KitchenSquareOutlier'] = 0\ntrain_df.loc[condition, 'KitchenSquareOutlier'] = 1 \n    \ntrain_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].median()\n\ntrain_df.loc[(train_df['KitchenSquare'] < 3) & (train_df['Square'] > 6), 'KitchenSquare'] = 3","7557e87b":"train_df['KitchenSquare'].value_counts()","5b2b5eb4":"train_df[(train_df['KitchenSquare'] > train_df['LifeSquare'])]","fbe480e5":"condition = (train_df['KitchenSquare'] > train_df['LifeSquare'])\ntrain_df['LifeSquareOutlier'] = 0\ntrain_df.loc[condition, 'LifeSquareOutlier'] = 1\ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","b807de45":"train_df[(train_df['KitchenSquare'] > train_df['LifeSquare'])]","250e4e99":"train_df['HouseFloor'].sort_values().unique()","9d70feba":"train_df['Floor'].sort_values().unique()","5e24c03d":"(train_df['Floor'] > train_df['HouseFloor']).sum()","9b0d036e":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1","895d3082":"train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()","9d886b5d":"floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\nfloor_outliers","440b3108":"train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\\\n                                                .apply(lambda x: random.randint(1, x))","41e429c9":"(train_df['Floor'] > train_df['HouseFloor']).sum()","2a255762":"train_df['HouseYear'].sort_values(ascending=False)","6bf4295c":"train_df.loc[train_df['HouseYear'] > 2020, 'HouseYear'] = 2020","ebe8fa46":"train_df.isna().sum()","4005968b":"train_df.drop('Healthcare_1', axis=1, inplace=True)","11cf761b":"train_df['LifeSquare_nan'] = train_df['LifeSquare'].isna() * 1\n\ncondition = (train_df['LifeSquare'].isna()) \\\n             & (~train_df['Square'].isna()) \\\n             & (~train_df['KitchenSquare'].isna())\n        \ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","66a1294d":"train_df.isna().sum()","3fa09f37":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.99)\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        #Square\n        X['SquareOutlier'] = 0\n        condition = (X['LifeSquare'] > X['Square'].max())\n        X.loc[condition, 'SquareOutlier'] = 1\n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] \\\n                                            - X.loc[condition, 'KitchenSquare'] - 3\n        \n        X['temp'] = X['Square']\n        X.loc[X['Square'] < X['LifeSquare'], 'SquareOutlier'] = 1\n        X.loc[X['SquareOutlier']==1, 'Square'] = X.loc[X['SquareOutlier']==1, 'LifeSquare']\n        X.loc[X['SquareOutlier']==1, 'LifeSquare'] = X.loc[X['SquareOutlier']==1, 'temp']\n        del X['temp']\n        \n        #KitchenSquare, LifeSquare\n        condition = (X['KitchenSquare'].isna()) \\\n             | (X['KitchenSquare'] > self.kitchen_square_quantile)\n\n        X['KitchenSquareOutlier'] = 0\n        X.loc[condition, 'KitchenSquareOutlier'] = 1 \n    \n        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']\n\n        X.loc[(X['KitchenSquare'] < 3) & (X['Square'] > 6), 'KitchenSquare'] = 3\n        \n        condition = (X['KitchenSquare'] > X['LifeSquare'])\n        X['LifeSquareOutlier'] = 0\n        X.loc[condition, 'LifeSquareOutlier'] = 1\n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] \\\n                                            - X.loc[condition, 'KitchenSquare'] - 3\n               \n        #HouseFloor, Floor\n        \n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n                \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        condition = (X['LifeSquare'].isna()) & \\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        \n        return X\n       ","be4c04ba":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","ca0ee09d":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size.head()","c737c09c":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","f3ad8524":"(train_df['DistrictSize'] > 100).value_counts()","d869279e":"train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)","06b44a53":"train_df['SquarePrice'] = train_df['Price'] \/ train_df['Square']","e219bd8a":"med_price_by_district = train_df.groupby(['DistrictId'], as_index=False).agg({'SquarePrice':'median'})\\\n                            .rename(columns={'SquarePrice':'MedPriceByDistrict'})\n\nmed_price_by_district.head(10)","1b982ed9":"train_df = train_df.merge(med_price_by_district, on='DistrictId', how='left')\ntrain_df.head()","5da72b21":"def floor_to_cat(X):\n\n    X['floor_cat'] = 0\n\n    X.loc[X['Floor'] == 1, 'floor_cat'] = 1  \n    X.loc[(X['Floor'] > 1) & (X['Floor'] <= 5), 'floor_cat'] = 2\n    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n    X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n\n    return X\n\n\ndef floor_to_cat_pandas(X):\n    bins = [0, 3, 5, 9, 15, X['Floor'].max()]\n    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n    \n    X['floor_cat'].fillna(-1, inplace=True)\n    return X\n\n\ndef year_to_cat(X):\n\n    X['year_cat'] = 0\n\n    X.loc[X['HouseYear'] <= 1941, 'year_cat'] = 1\n    X.loc[(X['HouseYear'] > 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n    X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n\n    return X\n\n\ndef year_to_cat_pandas(X):\n    bins = [0, 1941, 1945, 1980, 2000, 2010, X['HouseYear'].max()]\n    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n    \n    X['year_cat'].fillna(-1, inplace=True)\n    return X","d6fc4ecb":"train_df = year_to_cat(train_df)\ntrain_df = floor_to_cat(train_df)\ntrain_df.head()","cfb578c2":"med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'SquarePrice':'median'}).\\\n                                            rename(columns={'SquarePrice':'MedPriceByFloorYear'})\nmed_price_by_floor_year.head()","7a4efba5":"train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\ntrain_df.head()","319d7a90":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        self.SquarePrice = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n         \n        # Target encoding\n        ## District, Square\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            df['SquarePrice'] = df['Price'] \/ df['Square']\n            self.med_price_by_district = df.groupby(['DistrictId'], as_index=False).agg({'SquarePrice':'median'})\\\n                                            .rename(columns={'SquarePrice':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df['SquarePrice'] = df['Price'] \/ df['Square']\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'SquarePrice':'median'}).\\\n                                            rename(columns={'SquarePrice':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n    def transform(self, X):\n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n\n        # Target encoding\n                      \n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X.fillna(self.med_price_by_floor_year_median, inplace=True)\n              \n        return X\n    \n    def floor_to_cat(self, X):\n        X['floor_cat'] = 0\n        X.loc[X['Floor'] == 1, 'floor_cat'] = 1  \n        X.loc[(X['Floor'] > 1) & (X['Floor'] <= 5), 'floor_cat'] = 2\n        X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n        X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n        X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X\n    \n   ","2523542f":"train_df.columns.tolist()","6b2c844e":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'SquareOutlier', 'KitchenSquareOutlier', 'LifeSquareOutlier',\n                     'HouseFloor_outlier', 'LifeSquare_nan', 'DistrictSize', 'IsDistrictLarge',\n                     'MedPriceByDistrict', 'year_cat', 'floor_cat', 'MedPriceByFloorYear']\n\ntarget_name = 'Price'","c7aff719":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]\n","49b3e302":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=21)","2e217e80":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","d0cfb842":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","d808b1a9":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","bd94bace":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","34b01140":"gb_model = GradientBoostingRegressor(criterion='mse',\n                                     max_depth=3,\n                                     n_estimators=200,\n                                     min_samples_leaf=10,\n                                     random_state=42)\ngb_model.fit(X_train, y_train)","d2610e28":"# %%time\n# params = {'n_estimators':[10, 50, 100, 200], \n#           'max_depth':[3, 5, 7, 10]}\n\n# gs = GridSearchCV(gb_model, params, \n#                   scoring='r2', # \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \n#                   cv=KFold(n_splits=5,   # k (\u043a\u043e\u043b-\u0432\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439\/\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0439) \u0432 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n#                            random_state=21, \n#                            shuffle=True),\n#                   n_jobs=-1\n#                   )\n# gs.fit(X_train, y_train)","24e3694c":"# res = pd.DataFrame(gs.cv_results_)\n# res.head(2)","b1d1bb75":"# gs.best_params_","0cc7c575":"# gs.best_score_","b0e1d4b3":"y_train_preds = gb_model.predict(X_train)\ny_test_preds = gb_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","8d6eca77":"cv_score = cross_val_score(gb_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))\ncv_score","2857866c":"cv_score.mean()","24ce63e2":"feature_importances = pd.DataFrame(zip(X_train.columns, gb_model.feature_importances_), \n                                   columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","bd9c2bcf":"test_df.head()","72d3a787":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","bf9160e4":"predictions = gb_model.predict(test_df)\npredictions","d26f189f":"submit['Price'] = predictions\nsubmit.head()","2b8bc73d":"submit.to_csv('gb_submit.csv', index=False)","f2c69265":"\u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","191f58d5":"\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n\nId - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b\nDistrictId - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\nRooms - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\nSquare - \u043f\u043b\u043e\u0449\u0430\u0434\u044c\nLifeSquare - \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\nKitchenSquare - \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\nFloor - \u044d\u0442\u0430\u0436\nHouseFloor - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0434\u043e\u043c\u0435\nHouseYear - \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\nEcology_1, Ecology_2, Ecology_3 - \u044d\u043a\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\nSocial_1, Social_2, Social_3 - \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\nHealthcare_1, Helthcare_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043e\u0445\u0440\u0430\u043d\u043e\u0439 \u0437\u0434\u043e\u0440\u043e\u0432\u044c\u044f\nShops_1, Shops_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432, \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u0446\u0435\u043d\u0442\u0440\u043e\u0432\nPrice - \u0446\u0435\u043d\u0430 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","f637d601":"# \u041a\u0443\u0440\u0441\u043e\u0432\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0442 \u0434\u043b\u044f \u043a\u0443\u0440\u0441\u0430 \"Python \u0434\u043b\u044f Data Science\"\n","75a2066b":"# 2. \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","52f99481":"# 7.\t\u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","d484e9b3":"\u0422\u0430\u043a\u0436\u0435 \u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0433\u0434\u0435 \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u0431\u043e\u043b\u044c\u0448\u0435 \u043e\u0431\u0449\u0435\u0439 \u043f\u043b\u043e\u0449\u0430\u0434\u0438 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","f920d049":"Dummies","99e4783e":"\u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0442\u0438\u043f\u043e\u0432","272dc005":"HouseFloor, Floor","d0f1fcce":"# 3.2. \u0410\u043d\u0430\u043b\u0438\u0437 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","78b7dbe0":"# 8.\t\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","a34835d1":"# 9. \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435","09d59d72":"\u041c\u0435\u043d\u044f\u0435\u043c \u043c\u0435\u0441\u0442\u0430\u043c\u0438 ","ec04a925":"\u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","44cf4b85":"\u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b 641.065193 (\u0437\u0430\u0433\u0443\u0433\u043b\u0438\u043b\u0430 \u0442\u0430\u043a\u0438\u0435 \u0431\u044b\u0432\u0430\u044e\u0442).\n\u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0433\u0434\u0435 \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u0431\u043e\u043b\u044c\u0448\u0435 \u044d\u0442\u043e\u0439 \u0446\u0438\u0444\u0440\u044b","b717960b":"KitchenSquare","8407e2f7":"# 1. \u041f\u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0434\u0430\u0447\u0438:\n\n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0434\u0430\u043d\u043d\u044b\u0435 \u0438\u0437 train.csv, \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0446\u0435\u043d \u043d\u0430 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u044c (\u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b).\n\u0421 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \u0446\u0435\u043d\u044b \u0434\u043b\u044f \u043a\u0432\u0430\u0440\u0442\u0438\u0440 \u0438\u0437 \u0444\u0430\u0439\u043b\u0430 test.csv.\n\n\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f:\nPrice\n\n\u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430:\nR2 - \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438 (sklearn.metrics.r2_score)\n\n\u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430:\nMSE - \u0441\u0440\u0435\u0434\u043d\u044f\u044f \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430 (sklearn.metrics.mean_squared_error)\n","6934f3a5":"# 5.\t\u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","abb3475d":"\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\n\nRooms","3067cc18":"\u0423\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043c\u0430 \u043f\u0430\u043c\u044f\u0442\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u0434\u0430\u0442\u0430\u0441\u0435\u0442","2913b22d":"\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","3be435fe":"\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","9b1a45fe":"DistrictSize, IsDistrictLarge","a8c9e2fc":"\u0420\u0430\u0441\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u044e\u044e \u0446\u0435\u043d\u0443 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043d\u043e\u0433\u043e \u043c\u0435\u0442\u0440\u0430","11f8dde3":"HouseYear","4ea14cc9":"\u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f","3ed88562":"Square, LifeSquare","091c3568":"# 3.1. \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 ","05822e3c":"# 3. \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","a6cff02f":"# 6.\t\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432"}}