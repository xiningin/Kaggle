{"cell_type":{"eb751b16":"code","a33671a3":"code","4b0d97c7":"code","0528e715":"code","ac0e6265":"code","7918d2d9":"code","7d6a2bee":"code","88c019ae":"code","40d1e0f7":"code","a2038790":"code","99d532cd":"code","e32ce9dd":"code","4eb20fb3":"markdown","a2990e77":"markdown","66c49e26":"markdown","55aa6e6c":"markdown","4b6b6ff9":"markdown"},"source":{"eb751b16":"import numpy as np\nimport pandas as pd\nimport pathlib\nimport os\nimport gc\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.metrics import confusion_matrix\nfrom fastai import *\nfrom fastai.vision import *\n","a33671a3":"DATA_DIR='..\/input\/frutas\/classes'","4b0d97c7":"os.listdir(f'{DATA_DIR}')","0528e715":"torch.cuda.is_available()","ac0e6265":"data = ImageDataBunch.from_folder(DATA_DIR, train=\".\", \n                                  valid_pct=0.2,\n                                  size=224, bs=10, \n                                  num_workers=0).normalize(imagenet_stats)","7918d2d9":"print(f'Classes: \\n {data.classes}')","7d6a2bee":"data.show_batch(rows=3, figsize=(7,6))","88c019ae":"learnR50 = create_cnn(data, models.resnet50, metrics=accuracy, model_dir=\"\/tmp\/model\/\")\nlearnV16 = create_cnn(data, models.vgg16_bn, metrics=accuracy, model_dir=\"\/tmp\/model\/\")\nlearnALX = create_cnn(data, models.alexnet, metrics=accuracy, model_dir=\"\/tmp\/model\/\")","40d1e0f7":"learnR50.fit_one_cycle(5)\nlearnV16.fit_one_cycle(5)\nlearnALX.fit_one_cycle(5)","a2038790":"interpR = ClassificationInterpretation.from_learner(learnR50)\ninterpV = ClassificationInterpretation.from_learner(learnV16)\ninterpA = ClassificationInterpretation.from_learner(learnALX)","99d532cd":"interpR.plot_top_losses(9, figsize=(15,11))\ninterpV.plot_top_losses(9, figsize=(15,11))\ninterpA.plot_top_losses(9, figsize=(15,11))","e32ce9dd":"interpR.plot_confusion_matrix(figsize=(8,8), dpi=60)\ninterpV.plot_confusion_matrix(figsize=(8,8), dpi=60)\ninterpA.plot_confusion_matrix(figsize=(8,8), dpi=60)","4eb20fb3":"Base de dados: https:\/\/www.kaggle.com\/cactus3\/basicshapes\n\nKernel de refer\u00eancia: https:\/\/www.kaggle.com\/kageyama\/fastai-shape-recognition-using-vgg16","a2990e77":"# Treino do modelo","66c49e26":"# Leitura dos dados","55aa6e6c":"# Verificando os resultados","4b6b6ff9":"# Constru\u00e7\u00e3o do modelo\n\nTrecho retirado de https:\/\/docs.fast.ai\/vision.models.html\n\n\nThe fastai library includes several pretrained models from torchvision, namely:\n\n* resnet18, resnet34, resnet50, resnet101, resnet152\n* squeezenet1_0, squeezenet1_1\n* densenet121, densenet169, densenet201, densenet161\n* vgg16_bn, vgg19_bn\n* alexnet"}}