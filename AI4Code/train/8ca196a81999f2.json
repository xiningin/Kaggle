{"cell_type":{"783db96a":"code","ebc3b2b8":"code","74d1fece":"code","6ad764df":"code","be4cc7aa":"code","18f16469":"code","3c58463b":"code","3855b335":"code","8f4c99e8":"code","2c6b7b03":"code","6e88e072":"code","b79837b2":"code","2b5efcff":"code","3e2f63e6":"code","f1dfd544":"code","f9848b15":"code","f79bc9a6":"code","720ce7be":"code","191dd1cf":"code","ef4823ed":"code","154779e3":"code","860a56ef":"code","2981a054":"code","7feca98b":"code","01af4c8e":"code","ca8fa2cb":"code","f4e2ba86":"code","a1597098":"code","e676d17f":"code","db0092aa":"code","e6bc3ba4":"code","23419aa4":"code","8c60c352":"code","756c4f60":"code","32fdd135":"code","4622e497":"code","d916ed6e":"code","95a5491d":"code","4bac9ccc":"code","2b9d30a4":"markdown","98f0ae7e":"markdown","b56a80e9":"markdown","2a159056":"markdown","9f132263":"markdown","23e89c8c":"markdown"},"source":{"783db96a":"import pandas as pd\nimport pandas_profiling as pp\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport tkinter\nimport seaborn as sns\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n","ebc3b2b8":"data = pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","74d1fece":"data.head()","6ad764df":"data.describe()","be4cc7aa":"pp.ProfileReport(data)","18f16469":"data.quality.unique()","3c58463b":"# Distribution of wine quality\n# inline is required for placing the graph in motebook itself\n%matplotlib inline\n\nsns.countplot(x=\"quality\", data=data)","3855b335":"# alchol value - wine quality\nsns.violinplot(x=data[\"alcohol\"])","8f4c99e8":"sns.violinplot(x=data[\"sulphates\"])\n","2c6b7b03":"sns.violinplot(x=data[\"volatile_acidity\"])\n","6e88e072":"sns.catplot(x=\"quality\",y=\"alcohol\",data=data)","b79837b2":"sns.catplot(x=\"quality\",y=\"sulphates\",data=data)","2b5efcff":"sns.catplot(x=\"quality\",y=\"volatile_acidity\",data=data)","3e2f63e6":"bins=[0,4,6,10]\nlabels=[0,1,2]\ndata['wine_quality']=pd.cut(data['quality'],bins=bins,labels=labels)","f1dfd544":"sns.countplot(x=\"wine_quality\", data=data)","f9848b15":"data.columns","f79bc9a6":"# Bucketization of labels\nfeatures = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n       'pH', 'sulphates', 'alcohol'] \nlabel = ['wine_quality']","720ce7be":"data = shuffle(data)\nX = data[features]\ny = data[label]","191dd1cf":" X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)","ef4823ed":"print('Training Feature Shape', X_train.shape)\nprint('Validation Feature Shape', X_val.shape)\n\nprint('Label Training Shape', y_train.shape)\nprint('Label Validation Shape', y_val.shape)","154779e3":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)","860a56ef":"print('Training Feature Shape', X_train.shape)\nprint('Validation Feature Shape', X_val.shape)","2981a054":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier \n","7feca98b":"model = SVC()\nparam = {\n    'kernel':['rbf'],\n    'C':[1,5,10,15, 20],\n    'coef0':[0.001, 0.01,0.1, 0.5, 1]\n}","01af4c8e":"%%time\ngsc = GridSearchCV(\n        estimator=model,\n        param_grid=param,\n        cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\ngrid_result = gsc.fit(X_train, y_train)\nprint('Best Param', grid_result.best_params_)","ca8fa2cb":"y_pred = grid_result.best_estimator_.predict(X_val)","f4e2ba86":"print(y_pred.shape)\nprint('Accuracy', accuracy_score(y_val, y_pred))\nprint(\"classification Report:\\n\",classification_report(y_val,y_pred))\nprint('Confusion Matrix \\n' , confusion_matrix(y_val, y_pred))","a1597098":"model = DecisionTreeClassifier()\nparam = {\n    'max_depth':[2,4,6,9,10,15],\n}","e676d17f":"%%time\ngsc = GridSearchCV(\n        estimator=model,\n        param_grid=param,\n        cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\ngrid_result = gsc.fit(X_train, y_train)\nprint('Best Param', grid_result.best_params_)","db0092aa":"y_pred = grid_result.best_estimator_.predict(X_val)","e6bc3ba4":"print(y_pred.shape)\nprint('Accuracy', accuracy_score(y_val, y_pred))\nprint(\"classification Report:\\n\",classification_report(y_val,y_pred))\nprint('Confusion Matrix \\n' , confusion_matrix(y_val, y_pred))","23419aa4":"model = RandomForestClassifier()\nparam = {\n    'n_estimators':[2,4,6,9,10,15,20],\n}","8c60c352":"%%time\ngsc = GridSearchCV(\n        estimator=model,\n        param_grid=param,\n        cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\ngrid_result = gsc.fit(X_train, y_train)\nprint('Best Param', grid_result.best_params_)","756c4f60":"y_pred = grid_result.best_estimator_.predict(X_val)","32fdd135":"print(y_pred.shape)\nprint('Accuracy', accuracy_score(y_val, y_pred))\nprint(\"classification Report:\\n\",classification_report(y_val,y_pred))\nprint('Confusion Matrix \\n' , confusion_matrix(y_val, y_pred))","4622e497":"## Neural Network Using Tensorflow - Keras\n### Sequential Model \n\ninput_dimension = X_train.shape[1] # this represent number of features\n\n### hyper parameters\nepochs = 20\nbatch_size = 100\n\n### model\nmodel = Sequential()\nmodel.add(Dense(12, input_shape=(input_dimension,), activation='relu', kernel_regularizer= tf.keras.regularizers.l1(0.001)))\nmodel.add(Dense(5, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()\n\n","d916ed6e":"history = model.fit(X_train, y_train.values, epochs=epochs, batch_size=batch_size,\n          validation_data=(X_val, y_val.values))","95a5491d":"print('\\nhistory dict:', history.history)","4bac9ccc":"plt.plot( history.history['accuracy'], color='skyblue', linewidth=2, label='training acc')\nplt.plot( history.history['val_accuracy'], color='green', linewidth=2, label='val acc')\n\nplt.plot( history.history['loss'], color='skyblue', linewidth=2, linestyle='dashed', label=\"training loss\")\nplt.plot( history.history['val_loss'], color='green', linewidth=2, linestyle='dashed', label=\"val loss\")\nplt.legend()\n","2b9d30a4":"### Tags\n\n- Multiclass Classification\n- Numeric Data analysis\n- Seaborn Basics\n- Decision Tree, Random Forest Tree, SVM\n- Convolution matrix to undertand the result of classification\n- Accuracy, Precision, Recall and F1 Score\n- Tensorflow - Keras - Multiclass classification\n- Validation graph vs traning graph\n- Simple data normalization and manipulation using Sklearn","98f0ae7e":"### Label Engineering Analysis\n- there are 6 lable in total\n- value mostly concentrated for 5 and 6\n- since the number of examples are very less, and quality value varies from 1 - 10. we will convert quality in different bucket.\n    - 1-4 : bucket 0 [bad]\n    - 5-7 : bucket 1 [ok]\n    - above 7 : bucket 2 [good]","b56a80e9":"### Data Visualization","2a159056":"### Machine Learning Alorithm Comparision\n- State Vector Machine\n- Decision Tree\n- Random Forest Tree\n- Simple Neural Network Using Tensorflow and Keras. [Deep Learning]","9f132263":"### Feature Engineering\n- shuffle the data \n- bucketize the label into new buckets.\n- finalized the features columns and labels.\n- normalize the feature columns\n- deivide the dataset in training and validation set.\n- analyse the input feature dimension.","23e89c8c":"### Data Initial Understadning\n\n- all the features are numeric value.\n- since features are numeric , they can be normalized. (Normalized data converge faster and better)\n- number of examples are not very large, only 1599 rows. (Simple machine learning algo can be enough)\n- number of features are not very large, so need for dimensionality resunction. (No need of PCA kind of data conversion)\n- no null values are present , so no pre processing required for filling null values.\n- based on the correlation diagram \n    - sulphate, alcohol, and citric acid most closely related to wine quality in negative relation\n    - volatile acidity, chloride, total sulphur dioxide, density related to wine quality in positive relation.\n    "}}