{"cell_type":{"a27e918f":"code","26fa086d":"code","3e5d9d4f":"code","bb95067f":"code","3cbfaba5":"code","5e60bb6f":"code","15857de3":"code","7ea1ab0d":"code","c2aa8a5b":"code","85322560":"markdown","45f87a4f":"markdown","e790a3fb":"markdown","d2dd794e":"markdown","1be6cab7":"markdown","bb053fb9":"markdown","4b69810e":"markdown","b723b86b":"markdown","4cd214bf":"markdown","fc3a63e1":"markdown","e2b5e097":"markdown","6ed91ae4":"markdown","a9a82aa0":"markdown"},"source":{"a27e918f":"import datetime\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow_cloud as tfc\nimport tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nfrom sklearn.model_selection import train_test_split","26fa086d":"# Note: Please set GCP_PROJECT_ID to your own Google Cloud project ID.\nGCP_PROJECT_ID = 'rosbo-personal'\n\n# Note: Please set GCS_BUCKET to your own Google Cloud Storage (GCS) bucket.\nGCS_BUCKET = 'tf-cloud-rosbo-test' # used to save models & docker images\n\n# Note: Please change the job name to reflect the work you are doing.\nJOB_NAME = 'kaggle-example'\n\nif not tfc.remote():\n    from kaggle_secrets import UserSecretsClient\n    UserSecretsClient().set_gcloud_credentials(project=GCP_PROJECT_ID)\n\ngcs_base_path = f'gs:\/\/{GCS_BUCKET}\/{JOB_NAME}\/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'","3e5d9d4f":"# These settings apply when running in this Kaggle notebook.\nNUM_EPOCHS = 1 # Train a single epoch to test the training code works.\ncallbacks = None\n\n# These settings apply when running on TensorFlow Cloud\nif tfc.remote():    \n    NUM_EPOCHS = 100 # Train more epochs on TensorFlow Cloud\n    \n    callbacks = [\n        # TensorBoard will store logs for each epoch & graph performance for us.\n        tf.keras.callbacks.TensorBoard(log_dir=f'{gcs_base_path}\/tensorboard', histogram_freq=1),\n        # ModelCheckpoint will save models after each epoch for retrieval later.\n        tf.keras.callbacks.ModelCheckpoint(gcs_base_path + '\/checkpoints\/save_at_{epoch}'),\n    ]","bb95067f":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nx_train = train.iloc[:,1:].values.astype('float32') \/ 255.0\ny_train = tf.keras.utils.to_categorical(train.iloc[:,0].astype('int32'))\nx_train = x_train.reshape(-1, 28, 28, 1)\n\nprint(\"Splitting input in train and validation sets...\")\nx_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.10)\nprint(\"Training:\", x_train.shape, y_train.shape)\nprint(\"Validation:\", x_validation.shape, y_validation.shape)","3cbfaba5":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.compile(\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n\nprint(model.summary())\n\nprint(\"Training...\")\nmodel.fit(x_train, y_train, epochs=NUM_EPOCHS, batch_size=32)\nprint(\"Training complete\")","5e60bb6f":"model.evaluate(x_validation, y_validation, return_dict=True)","15857de3":"if tfc.remote():\n    model.save(f'{gcs_base_path}\/model')","7ea1ab0d":"print(\"Training on TensorFlow Cloud...\")\ntfc.run(\n    distribution_strategy='auto',\n    docker_image_bucket_name=GCS_BUCKET,\n    chief_config=tfc.MachineConfig(\n        cpu_cores=16,\n        memory=60,\n        accelerator_type=tfc.AcceleratorType.NO_ACCELERATOR,\n        accelerator_count=0\n    ),\n    job_labels={\"job\": JOB_NAME},\n)","c2aa8a5b":"if tfc.remote():\n    print(\"Your model trained by TensorFlow Cloud is saved at:\")\n    print(\"MODEL_PATH =\", f'{gcs_base_path}\/model')","85322560":"## Step 2: Setup Google Cloud credentials\n\nAdd the \"Google Cloud SDK\" addon from the \"Add-ons\" menu bar above to allow scheduling an AI training job in your Google Cloud project.\n\n**NOTICE**: TensorFlow Cloud will run the training job in your Google Cloud project. **You will be billed ($$$)** for the resources consumed by this training job.\n\n![52xZHgn3Na33F4d.png](attachment:52xZHgn3Na33F4d.png)\n","45f87a4f":"## Step 5: Find the path to your trained model\n\nNow that you're model has been trained on Cloud AI Platform, you can access the logs of your training job to get the path to your model.\n\nSearch for `MODEL_PATH` in the training jobs logs.\n\n![Kapture%202020-11-24%20at%2016.59.29.gif](attachment:Kapture%202020-11-24%20at%2016.59.29.gif)","e790a3fb":"## Step 1: Import Packages (including TensorFlow Cloud)","d2dd794e":"### Read & Prepare Training Data\n\nThe model will be trained to recognize handwritten digits on the Kaggle MNIST dataset used in the [Kaggle Digit Recognizer competition](https:\/\/www.kaggle.com\/c\/digit-recognizer).","1be6cab7":"# Train model with TensorFlow Cloud\n\n[TensorFlow Cloud](https:\/\/github.com\/tensorflow\/cloud) is a Python package that provides APIs for seamless transition from local training to distributed training in Google Cloud.\n\nThis notebook will show you how to train your TensorFlow model from a Kaggle notebook and using a Kaggle dataset.","bb053fb9":"## Step 3: Add Your TensorFlow Training Code","4b69810e":"### Save model\n\nWe save the trained model to Cloud Storage **only when running in the Cloud**.","b723b86b":"### Evaluate\n\nThe model is evaluated against the validation set.","4cd214bf":"For this example, we use a single machine with 16 cores & 60 GB of memory.\n\nYou can use larger machines, add accelerators or add additional machines to perform the training. To learn more about this, you can read the [TensorFlow Cloud cluster & distribution strategy configuration](https:\/\/github.com\/tensorflow\/cloud#cluster-and-distribution-strategy-configuration) documentation.\n\n**IMPORTANT**: TensorFlow Cloud will use the same environment (packages, drivers, etc) than your notebook. If you are using TensorFlow Cloud with machines with accelerators, make sure to select \"GPU\" in the accelerator setting in the right panel of this notebook.","fc3a63e1":"## Step 4: Train model on TensorFlow Cloud","e2b5e097":"## Next Step\n    \n- [Test & Deploy your model trained with TensorFlow Cloud to Google Cloud AI Platform](https:\/\/www.kaggle.com\/rosebv\/test-deploy-tensorflow-model-to-ai-platform)","6ed91ae4":"### Specify Parameters\n\nTensorFlow Cloud will run all the cells in this notebook in the Cloud.\n\nYou can call `tfc.remote()` to check whether you are running in the Cloud or not and set different value for parameters (e.g. number of epochs). This allows you to easily debug your training code locally before sending the larger training job to the Cloud.","a9a82aa0":"### Define & Train TensorFlow Model"}}