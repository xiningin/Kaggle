{"cell_type":{"7374a240":"code","9e0744be":"code","c4f3d11f":"code","ca8f718d":"code","87d80a62":"code","39a9b6ba":"code","55ff973c":"code","1d0e7c4f":"markdown","ff47b5eb":"markdown","1158aeee":"markdown","1b75027a":"markdown","3c08bf9e":"markdown","8eca1763":"markdown","552a5dc0":"markdown"},"source":{"7374a240":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns, numpy as np","9e0744be":"data = pd.read_csv(\"..\/input\/diabetes-dataset\/diabetes2.csv\")\ndata.head()","c4f3d11f":"data['Outcome'].value_counts()","ca8f718d":"sns.distplot(data['Outcome'],bins=3,kde=False)\nplt.title(\"Analysing ZeroR\")\nplt.xticks([0,1])\nplt.show()","87d80a62":"# Our criteria:\n# 0 = young, 1 = mid, 2 = old\n\ncolumn_age = []\n\nfor age in data['Age']:\n    if(age < 25):\n        column_age.append(\"0\")\n    elif(age>25 and age<45):\n        column_age.append(\"1\")\n    else:\n        column_age.append(\"2\")\n\n# adding a new column\ndata[\"Age_Categorical\"] = column_age        ","39a9b6ba":"data.head()","55ff973c":"for i in range(0,3):\n    print(\"If Age Category: \", i, \" , number of outcomes(0): \", len( data[ (data['Age_Categorical'] == str(i)) & (data['Outcome'] == 0) ]) )\n    print(\"If Age Category: \", i, \" , number of outcomes(1): \", len( data[ (data['Age_Categorical'] == str(i)) & (data['Outcome'] == 1) ] ) ,\"\\n\")\n    ","1d0e7c4f":"Now, if i say that I have a rule to classify the dataset. The rule is :\n\n`Outcome = 0 `\n\nHow much accurate is it? Note that 500 times the outcome is 0 and 268 times it is 1.\n\n    = 500 \/ (500+268)\n    \n    = 500 \/ 768\n\n    = 0.651\n\nThus, the accuracy is 65.1% . Other classifers will have to do better than this.\n\n**Note** : I have not divided the data set into training and test-set to make everything simple and easy to understand.","ff47b5eb":"## ZeroR Classifier ##\n\nZeroR or zero rule classifier is a naive approach to classify a dataset. It is purely based on the target and ignores the other independent attributes. \n\nApplication: The ZeroR classifier is used as a baseline for other classifiers. Other classifiers should do better than this to proove their capabilities.\n\nLet's see an example of this.","1158aeee":"## OneR Classifier ##\n\n","1b75027a":"# References\n\n1. [Saed Sayad , Zero R ](https:\/\/www.saedsayad.com\/zeror.htm)\n2. [How To Estimate A Baseline Performance For Your Machine Learning Models in Weka](https:\/\/machinelearningmastery.com\/estimate-baseline-performance-machine-learning-models-weka\/)\n3. [Saed Sayad OneR](https:\/\/www.saedsayad.com\/oner.htm)\n4. [Youtube: MLCollab OneR](https:\/\/www.youtube.com\/watch?v=Bhc838MCSDY)\n","3c08bf9e":"# ZeroR and OneR ##\n\nWe are using diabetes dataset to try several approaches for classification. The aim of this project is to understand these basic approaches\/algorithms rather than achieving high accuracies. The algorithms which we are going to learn about are:\n\n1. [ ZeroR Classifier](#ZeroR-Classifier)\n2. [ OneR Classifier](#OneR-Classifier)\n\nLet's get started","8eca1763":"So, If we have a set of rules only for attribute `Age_Categorical` which says:\n\n    if, Age_Categorical = 0 then Outcome=0\n    if, Age_Categorical = 1 then Outcome=0\n    else Age_Categorical = 2 then Outcome=0,\n    \nthe accuracy of the model will be: \n\n    = (188 + 211 + 101) \/ (188 + 31 + 211 + 157 + 101 + 80)\n    = 500\/768\n    = 0.651\n    \nThe accuracy will be 65.1% . Same as the zeroR . Hmmmm     ","552a5dc0":"Unlike zeroR, oneR considers each of the attributes. It make rules for each attribute, and selectes the rule which generates highest accuracy. The algorithm is:\n\n            \n    For each predictor,\n\n         For each value of that predictor, make a rule as follows;\n\n               Count how often each value of target (class) appears\n\n               Find the most frequent class\n\n               Make the rule assign that class to this value of the predictor\n\n         Calculate the total error of the rules of each predictor\n     \n    Choose the predictor with the smallest total error\n\n\n[Algorithm Source: Saed Sayad OneR](https:\/\/www.saedsayad.com\/oner.htm)\n\n`It basically generates one level dicision tree.`\n\nLet's see it in action:\n\n**Note**:\n1. As we have `numerical data` over a wide range, there can be many rules. Like for attribute 'Age', rule can be age<17, age<12, age<24, age<34 ... etc. Thus, we will make 3 categories :\n\n    0 = young, 1 = mid, 2 = old\n    \n2. The code will become complex and uncessarily lengthy, thus, using only `Age` attribute.    "}}