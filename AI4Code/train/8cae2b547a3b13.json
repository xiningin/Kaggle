{"cell_type":{"a6e0df93":"code","b9dc2a74":"code","fb527dee":"code","c0eec3e6":"code","efd5f67f":"code","4704dfeb":"code","72913e5c":"code","998dd2c0":"code","3b7a2a38":"code","0ac7f04e":"code","76d34056":"code","2dedd6e8":"code","6d774fa0":"code","3f879704":"code","9fc1813c":"code","d320180d":"code","20649e4a":"code","8c86108b":"code","92302ac7":"code","b887dfa0":"code","e2b11253":"code","9076caa6":"code","93ffc4a5":"code","a6efceae":"code","501f7d2f":"code","96f5af33":"code","e440198c":"code","b2f09083":"code","d163702b":"code","25a2d42c":"code","2ccdbb28":"code","3816e081":"code","b2390b9c":"code","721ede78":"code","060ae995":"code","7141c994":"markdown"},"source":{"a6e0df93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9dc2a74":"df = pd.read_csv('..\/input\/real-estate-dataset\/data.csv')","fb527dee":"df.head()","c0eec3e6":"df.isna().sum()","efd5f67f":"df['RM']=df['RM'].fillna(df['RM'].mean())","4704dfeb":"df.shape","72913e5c":"{columns : len(df[columns].unique()) for columns in df.select_dtypes('int')}","998dd2c0":"df['CHAS'].value_counts()","3b7a2a38":"sns.pairplot(df)","0ac7f04e":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(16,10))\nfor i in range (len(df.columns)):\n    plt.subplot(3,5,i+1)\n    sns.boxplot(df[df.columns[i]])","76d34056":"from scipy import stats\n\ndef find_outliers(df, threshold):\n    \n    threshold_z_score = stats.norm.ppf(threshold)\n    \n    z_score = pd.DataFrame(np.abs(stats.zscore(df)), columns = df.columns)\n    \n    return (z_score > threshold_z_score). sum(axis=0)\n    ","2dedd6e8":"stats.norm.ppf(0.5)","6d774fa0":"find_outliers(df, 0.9999)","3f879704":"def remove_outliers(df, threshold):\n    \n    threshold_z_score = stats.norm.ppf(threshold)\n    \n    z_score = pd.DataFrame(np.abs(stats.zscore(df)), columns = df.columns)\n    \n    z_score = (z_score > threshold_z_score)\n    \n    # get the indecies\n    \n    outliers =  z_score.sum(axis=1)\n    outliers = outliers > 0\n    outliers_index = df.index[outliers]\n    \n    df =df.drop(outliers_index, axis =0).reset_index(drop=True)\n    \n    return df\n    ","9fc1813c":"df=remove_outliers(df,0.9999)","d320180d":"df.shape","20649e4a":"x = df.drop('CHAS', axis =1)","8c86108b":"y = df['CHAS']","92302ac7":"from sklearn.model_selection import train_test_split","b887dfa0":"x_train,x_test,y_train,y_test = train_test_split(x,y, train_size = 0.7, random_state = 1)","e2b11253":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(x_train)\n\nx_train = pd.DataFrame(sc.transform(x_train),columns = x.columns)\nx_test = pd.DataFrame(sc.transform(x_test),columns = x.columns) ","9076caa6":"# treating imbalanced dataset \n\nfrom imblearn import over_sampling, under_sampling\nfrom imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state = 33)","93ffc4a5":"x_train_smote, y_train_smote = smote.fit_sample(x_train,y_train)","a6efceae":"import seaborn as sns\nsns.countplot(y_train_smote)","501f7d2f":"from sklearn.neighbors import KNeighborsClassifier\nKnn = KNeighborsClassifier()\nKnn.fit(x_train_smote, y_train_smote)","96f5af33":"print(Knn.score(x_train_smote, y_train_smote))\nprint(Knn.score(x_test,y_test))","e440198c":"predict = Knn.predict(x_test)","b2f09083":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","d163702b":"print( confusion_matrix(y_test, predict))","25a2d42c":"print(classification_report(y_test, predict))","2ccdbb28":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\nfrom sklearn.svm import SVC","3816e081":"parameter = [\n  {'C': [0.01, 0.05, 0.5, 1], 'kernel': ['linear']},\n  {'C': [0.01, 0.05, 0.5, 1], 'kernel': ['rbf']},\n]\n\n# Create a classifier object with the classifier and parameter candidates\nGSCV = GridSearchCV(estimator=svm.SVC(), param_grid=parameter, n_jobs=-1)\n\n# Train the classifier on data1's feature and target data\nGSCV.fit(x_train_smote, y_train_smote)","b2390b9c":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits=10, random_state=10)\nscore = cross_val_score(GSCV,x_train_smote, y_train_smote, cv=kfold, scoring='accuracy')\nprint(score)\nprint(score.mean())","721ede78":"print('Best score :', GSCV.best_score_)","060ae995":"print('Best C:',GSCV.best_estimator_.C) \nprint('Best Kernel:',GSCV.best_estimator_.kernel)","7141c994":"**Preprocess**"}}