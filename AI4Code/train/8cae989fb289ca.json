{"cell_type":{"f04761ae":"code","c724cc2f":"code","1c3c0126":"code","2db6a26d":"code","42a38c4b":"code","cdefa422":"code","64d46aa6":"code","ae5e080a":"code","ecc0065a":"code","9caabc92":"code","73990946":"code","54280dc5":"code","0124c3b4":"code","88dad936":"code","1dc17d5d":"code","f67b6a3f":"code","02a76f08":"code","5e434bd4":"code","a948e42d":"code","233dc44e":"code","777d2cc4":"code","3437058c":"code","84e6e86e":"code","b578c828":"code","48a6f01e":"code","e70428ef":"markdown","7b9f13e5":"markdown","9c2a8c1e":"markdown","ffcf4dca":"markdown","ae50e629":"markdown","7de53dc1":"markdown"},"source":{"f04761ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c724cc2f":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\", index_col=0)\ndf.head()","1c3c0126":"print('Dataset shape: ', df.shape)\nprint('Survived: {}, Not Survived: {}'.format(df[df['Survived']==1]['Survived'].count(), df[df['Survived']==0]['Survived'].count()))","2db6a26d":"print(df.dtypes)\ndf.isnull().sum()","42a38c4b":"print('Unique values for SibSp column: ', df['SibSp'].unique())\nprint('Unique values for Parch column: ', df['Parch'].unique())\nprint('Unique values for Embarked column: ', df['Embarked'].unique())","cdefa422":"print(df['Age'].describe())\ndf['Age'].hist()","64d46aa6":"df[df['Embarked'].isnull()==True]","ae5e080a":"df['Pclass'].corr(df['Fare'])","ecc0065a":"df['Embarked'] = df['Embarked'].fillna('N') # Embarked column = substitute with a new 'N' category","9caabc92":"df['Sex'] = df['Sex'].apply(lambda x: 0 if x == 'male' else 1)\ndf = pd.concat([df,pd.get_dummies(df['Embarked'], prefix='Embarked')],axis=1).drop(['Embarked', 'Embarked_N'],axis=1)\ndf.head()","73990946":"# creating a new feature from Parch and SibSp\n# if there are some values in those features other than 0, then passenger is not alone, otherwise 0\ndef isAlone(df):\n    if df['SibSp']==0 and df['Parch']==0:\n        return 1\n    else: return 0\n\n# constructing the new column\ndf['isAlone'] = df.apply(isAlone, axis=1)\ndf.drop(['SibSp', 'Parch', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True) # dropping all the other columns\ndf.head()","54280dc5":"print(df.corrwith(df['Survived']))","0124c3b4":"#in this cell, you have to fill-in the NaN Age column values...\n#df[df['Age'].notnull()].head()\n\nmeanAge = df['Age'].mean()\ndf.fillna(meanAge, inplace=True)\ndf.isnull().sum()","88dad936":"titanic_y = df['Survived']\ntitanic_X = df.drop(['Survived'], axis=1)","1dc17d5d":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score\n\n# code here\n# splitting the training and testing set: 80-20 separation\n# with stratify property to resolve class imbalances of the target inside the splits\nX_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.2, random_state=42, stratify=titanic_y)\n\n# initialising classifiers\/models\n# SVC = Support Vector Machine Classifier\n# LR = Logistic Regression\n# DT = Decision Tree Classifier\n# RF = Random Forest Classifier\nclf_svc = SVC(random_state=0, max_iter=1000)\nclf_lr = LogisticRegression(solver='lbfgs', random_state=0, max_iter=1000)\nclf_dt = DecisionTreeClassifier(random_state=0)\nclf_rf = RandomForestClassifier(random_state=0)\n\n# building the model pipelines for each model\/classifier  including preprocessing, e.g., standardisation when needed\npipeline_svc = Pipeline([('std', StandardScaler()), ('clf_svc', clf_svc)])\npipeline_lr = Pipeline([('std', StandardScaler()), ('clf_lr', clf_lr)])\npipeline_dt = Pipeline([('clf_dt', clf_dt)])  # no rescaling or standardization is required for DT\npipeline_rf = Pipeline([('clf_rf', clf_rf)])  # no rescaling or standardization is required for RF\n\n# setting up the parameter grids for each classifier\/model\nparameter_grid_svc = [{'clf_svc__kernel': ['rbf'], 'clf_svc__C': np.logspace(-4, 4, 9), 'clf_svc__gamma':np.logspace(-4, 0, 4)},\n                  {'clf_svc__kernel':['linear'], 'clf_svc__C': np.logspace(-4, 4, 9)}]\nparameter_grid_lr = [{'clf_lr__penalty': ['l1', 'l2']},\n                  {'clf_lr__C': np.logspace(0, 4, 10)}]\nparameter_grid_dt = [{'clf_dt__criterion': ['gini', 'entropy']},\n                  {'clf_dt__max_depth': [4,6,8,12]}]\nparameter_grid_rf = [{'clf_rf__n_estimators': [10, 50, 100, 250, 500, 1000]},\n                  {'clf_rf__max_features': ['sqrt', 'log2']},\n                  {'clf_rf__min_samples_leaf': [1, 3, 5]}]","f67b6a3f":"import warnings\nwarnings.filterwarnings('ignore')\n\n# code here\n# setting up multiple GridSearchCV instances: one for each model\/classifier\n# used 5x2 nested cross validation\ngridcvs = {}\ninnerCV = StratifiedKFold(n_splits=2, shuffle=True, random_state=2) # stratified inner (2) fold\n\nfor pgrid, est, alg in zip((parameter_grid_svc, parameter_grid_lr, parameter_grid_dt, parameter_grid_rf),\n                            (pipeline_svc, pipeline_lr, pipeline_dt, pipeline_rf),\n                            ('SVM', 'LogisticRegression', 'DecisionTree', 'RandomForest')):\n#for pgrid, est, alg in zip((parameter_grid_lr, parameter_grid_dt, parameter_grid_rf),\n#                            (pipeline_lr, pipeline_dt, pipeline_rf),\n#                            ('LogisticRegression', 'DecisionTree', 'RandomForest')):\n  gcv = GridSearchCV(estimator=est, param_grid=pgrid, scoring='accuracy', n_jobs=1, cv=innerCV, verbose=0, refit=True)\n  gridcvs[alg] = gcv\n\n# outer (5) cross validation folds: note the stratified nature again\nouterCV = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\nouterScores = {}\nfor alg, est in sorted(gridcvs.items()):\n  nestedScore = cross_val_score(est, X=X_train, y=y_train, cv=outerCV, n_jobs=1)\n  outerScores[alg] = nestedScore\n  print(f'{alg}: outer accuracy {100*nestedScore.mean():.2f} +\/- {100*nestedScore.std():.2f}')","02a76f08":"from sklearn.model_selection import learning_curve\n\n# plotting the learning curves to demonstrate bias and variance during the model selection\/evaluation process\ndef plot_learning_curve(ax, i, estimator, clf, X, y, ylim=None, cv=None, train_sizes=None):\n    ax[i].set_title(f'Learning Curves ({clf})')\n    ax[i].set_ylim(*ylim)\n    ax[i].set_xlabel(\"Training samples\")\n    ax[i].set_ylabel(\"Score\")\n    train_sizes, train_scores, validation_scores = learning_curve(\n        estimator, X, y, cv=cv, train_sizes=train_sizes)\n    # computes the training and validation scores\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_mean = np.mean(validation_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n\n    # filling the curve with +\/- standard deviation area\n    ax[i].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"black\")\n    # filling the curve with +\/- standard deviation area\n    ax[i].fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n                     validation_scores_mean + validation_scores_std, alpha=0.1, color=\"blue\")\n    ax[i].plot(train_sizes, train_scores_mean, 'o-', color=\"black\",\n             label=\"Training score\")\n    ax[i].plot(train_sizes, validation_scores_mean, 'o-', color=\"blue\",\n             label=\"Cross-validation score\")\n\n    ax[i].legend(loc=\"lower right\")\n    ax[i].grid(True)\n    return\n\n# subplots for the learning curves of the four algorithms tried\nfig, ax = plt.subplots(1, 4, figsize=(20, 5))\ntrain_sizes = np.linspace(.1, 1.0, 5)\nylim = (0.70, 1.03)\ncv = 5\n\n# calling the learning curve drawing function for four different algorithms\nplot_learning_curve(ax, 0, pipeline_svc, \"SVC\", X_train, y_train, \n                    ylim=ylim, cv=cv, train_sizes=train_sizes)\nplot_learning_curve(ax, 1, pipeline_lr, \"Logistic Regression\", X_train, y_train, \n                    ylim=ylim, cv=cv, train_sizes=train_sizes)\nplot_learning_curve(ax, 2, pipeline_dt, \"Decision Tree\", X_train, y_train, \n                    ylim=ylim, cv=cv, train_sizes=train_sizes)\nplot_learning_curve(ax, 3, pipeline_rf, \"Random Forest\", X_train, y_train, \n                    ylim=ylim, cv=cv, train_sizes=train_sizes)\nplt.show()","5e434bd4":"# fit \"best\" algorithm on the full training set\nbestModel = 'SVM'\nmodel = gridcvs[bestModel]  # getting the model parameters or loading the best model\nmodel.fit(X_train, y_train) # fitting it to the whole training set (including the validation set)\ntrain_acc = accuracy_score(y_true=y_train, y_pred=model.predict(X_train)) # running for the training set\ntest_acc = accuracy_score(y_true=y_test, y_pred=model.predict(X_test))  # running for unseen testing set: generalised performance\n\n# evaluate performance and compare to cross-validation results\nprint(f'Accuracy (mean cross-vaidated score of the best_estimator): {100*model.best_score_:.2f}')\nprint(f'Best Parameters: {gridcvs[bestModel].best_params_}')\n\n# showing both training and testing accuracy\nprint(f'Training Accuracy: {100*train_acc:.2f}')\nprint(f'Test Accuracy: {100*test_acc:.2f}')","a948e42d":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\", index_col=0)\ndf.head()","233dc44e":"df['Age'] = df['Age'].fillna(meanAge) # Age column = substitute with mean value\ndf['Embarked'] = df['Embarked'].fillna('N') # Embarked column = substitute with a new 'N' category\ndf['Sex'] = df['Sex'].apply(lambda x: 0 if x == 'male' else 1)\ndf = pd.concat([df,pd.get_dummies(df['Embarked'], prefix='Embarked')],axis=1).drop(['Embarked'],axis=1)\n\n# constructing the new column\ndf['isAlone'] = df.apply(isAlone, axis=1)\ndf.drop(['SibSp', 'Parch', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True) # dropping all the other columns\ndf.head()","777d2cc4":"df[df['Fare'].isnull()==True]","3437058c":"# filling the fare with pclass mean value and from where the passenger has embarked...\ndf['Fare'].fillna(df[(df['Embarked_S']==1) & (df['Pclass']==3)]['Fare'].mean(), inplace=True)","84e6e86e":"df.isnull().sum()","b578c828":"y_pred = model.predict(df)\ny_pred","48a6f01e":"df['Survived'] = y_pred # appending to the new 'Survived' column: the results\ndf = df.filter(['Survived']) # only the Passengerid and Survived columns...\ndf.to_csv('output.csv')","e70428ef":"<h3>Findings<\/h3>\nThere are names and tickets columns as objects (strings). A lot of Cabin entries have NaN values.\nEmbarked has 2 missing values - some of the age values are also missing (177 of them).\n\nSibsb and Parch have categorial values (ordered) - number of other family members inside the ship. May be required to maintain this or just transform into a boolean feature (Yes or No)?","7b9f13e5":"<h1>Evaluation<\/h1>\nLoad the test data. Compute the evaluation metrics.","9c2a8c1e":"<h1>Improvements<\/h1>\n<strong>Age<\/strong> column's NaN values were replaced by training set's Mean - regression or looking into other class or parents\/child\/sibling association, a more targeted value could be sought?\n<strong>Name<\/strong> column is dropped, the title could be retrieved and see if that is of any helpful feature.","ffcf4dca":"<h1>Modelling<\/h1>\nTrain-Test-Split. Hypermeter tuning with Built-in GridSearchCV.","ae50e629":"<h1>Initial Data Analysis<\/h1>\nRead the train.csv file, and make the 'Passengerid' as the index.","7de53dc1":"<h1>Exploratory Data Analysis<\/h1>\n<ul>\n    <li>Expected more negative correlation between <strong>Pclass<\/strong> and <strong>Fare<\/strong> column.<\/li>\n    <li>For the <strong>Age<\/strong> column, need more exploration - may be regression?<\/li>\n    <li>For the <strong>Embarked<\/strong> column, we subsitute the two NaNs with a new category 'N'.<\/li>\n    <li>Drop <strong>Name, Ticket, Cabin<\/strong> columns?<\/li>\n    <li>Use one-hot encoding to transform <strong>Sex, Embarked<\/strong> columns.<\/li>\n<\/ul>"}}