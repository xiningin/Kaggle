{"cell_type":{"1a97b887":"code","d6f40d5b":"code","a999a84e":"code","d6b2e51e":"code","f626f1e0":"code","5af23d7a":"code","8f5fa965":"code","8f2a4baa":"code","b991ba3a":"code","0d6403b9":"code","ed389f6a":"code","26e4ea41":"code","a28d13ed":"code","3cab73ad":"code","ae9c3e1f":"code","2f7ccfa4":"code","3676b6a8":"code","a677de00":"code","01c2b808":"code","67dfd6f3":"code","5cc03e33":"code","555c4829":"code","31fc415b":"code","c0e12fec":"code","7aa45926":"code","65a67e72":"code","8086d534":"code","654e5e96":"code","b31c0601":"code","4e62337b":"code","f485a315":"code","8d0d3bb8":"markdown"},"source":{"1a97b887":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6f40d5b":"#\ud559\uc2b5\ubaa8\ub378\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import VotingClassifier\n\n#\uc804\ucc98\ub9ac \ubc0f \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n#\uacb0\uacfc\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n#\uc2dc\uac01\ud654\n\nimport matplotlib.pylab as plt\n%matplotlib inline\n\n#tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import layers","a999a84e":"wine = pd.read_csv('..\/input\/wineuci\/Wine.csv',header=None)\nwine.head()","d6b2e51e":"wine.columns = ['class','alcohol','malicAcid','ash',\\\n                'ashalcalinity','magnesium','totalPhenols','flavanoids',\\\n                'nonFlavanoidPhenols','proanthocyanins','colorIntensity','hue','od280_od315',\\\n                'proline']\nwine","f626f1e0":"wine.info()","5af23d7a":"wine.isnull().sum()","8f5fa965":"X = wine.drop(['class'],axis=1)\ny = wine['class']","8f2a4baa":"X.head()","b991ba3a":"y.head()","0d6403b9":"scaler = StandardScaler() # \uc2a4\ucf00\uc77c\ub9c1\nx = scaler.fit_transform(X)","ed389f6a":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)","26e4ea41":"lr = LogisticRegression()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nnb = GaussianNB()\n\neclf_h =VotingClassifier(estimators = [('lr',lr),('dt',dt),('rf',rf),('nb',nb)],voting='hard')\neclf_s =VotingClassifier(estimators = [('lr',lr),('dt',dt),('rf',rf),('nb',nb)],voting='soft')\nmodels = [lr,dt,rf,nb,eclf_h,eclf_s]","a28d13ed":"for model in models:\n  model.fit(x_train,y_train)\n  predictions = model.predict(x_test)\n  score = model.score(x_test,y_test)\n  print(classification_report(y_test,predictions),'\\n')\n# lr,dt,rf,nb,eclf_h,eclf_s","3cab73ad":"x.shape,y.shape","ae9c3e1f":"x[1].shape","2f7ccfa4":"y = pd.get_dummies(y)\ny.columns = ['class1','class2','class3']\ny","3676b6a8":"x_train_all,x_test,y_train_all,y_test = train_test_split(x,y,test_size=0.2)\nx_train,x_val,y_train,y_val = train_test_split(x_train_all,y_train_all,test_size=0.2)","a677de00":"regular = 0.00001 #regularization","01c2b808":"model = tf.keras.Sequential()","67dfd6f3":"x[1].shape","5cc03e33":"model.add(layers.Dense(12, input_shape = x[1].shape,activation='relu',\\\n          kernel_regularizer = tf.keras.regularizers.l2(regular),\\\n          activity_regularizer = tf.keras.regularizers.l2(regular)))\nmodel.add(layers.Dense(8,activation = 'relu'))\nmodel.add(layers.Dense(16,activation = 'relu'))\nmodel.add(layers.Dense(128,activation = 'relu'))\nmodel.add(layers.Dense(64,activation = 'relu'))\nmodel.add(layers.Dense(32,activation = 'relu'))\nmodel.add(layers.Dense(3,activation = 'softmax'))\n\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nhist = model.fit(x_train,y_train,epochs =100,validation_split=0.2)\nmodel.evaluate(x_test,y_test)\ny_pred =model.predict(x_test)    \n\ny_test_class=np.argmax(y_test.values,axis=1)\ny_pred_class=np.argmax(y_pred,axis=1)\n","555c4829":"y_train","31fc415b":"print(classification_report(y_test_class,y_pred_class))\nconfusion_matrix(y_test_class,y_pred_class)","c0e12fec":"hist.history.keys()","7aa45926":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])","65a67e72":"plt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])","8086d534":"y_test_class.shape,y_pred_class.shape","654e5e96":"weights, biases = model.layers[1].get_weights()","b31c0601":"weights","4e62337b":"weights.shape, biases.shape","f485a315":"plt.plot(weights,'x')\nplt.plot(biases,'o')\nplt.title('L2 - 0.00001')","8d0d3bb8":"# Classification"}}