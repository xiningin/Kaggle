{"cell_type":{"bf17f3f3":"code","f269a55e":"code","df051fd0":"code","7629f3f7":"code","f3691bd9":"code","da5355dc":"code","091289e2":"code","acbf547e":"code","4e4ee2a9":"code","50e39a3d":"code","10466f0a":"code","956fa8eb":"code","c9067b28":"code","2f6f1277":"code","a227e6da":"code","b53526e6":"code","f55a8d5f":"code","229526f6":"code","8dd65650":"code","b593d28f":"code","c859b11d":"code","133ec199":"code","da9d0f4a":"code","cff13133":"code","e725c926":"code","806ff267":"code","0a5cd9ce":"code","0c519e78":"code","4dde97c7":"code","dacb560c":"code","36ce9477":"code","4424fd51":"code","133eb785":"markdown","3ceb7ad0":"markdown","4b9b546b":"markdown","d9eea259":"markdown","cf342896":"markdown","08cfb1bb":"markdown","83e0f20d":"markdown","c2475fd4":"markdown","496a5081":"markdown","654150a3":"markdown","9ca7fa9c":"markdown","1d6ca24c":"markdown","f407d31f":"markdown","bfa143f4":"markdown","ac4f849d":"markdown"},"source":{"bf17f3f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f269a55e":"df = pd.read_csv(\"\/kaggle\/input\/brooklyn99-scripts\/B99_1x1(1).csv\", delimiter=',', encoding='utf8')\ndf.head(10)","df051fd0":"df.isnull().sum()","7629f3f7":"import nltk \nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB","f3691bd9":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'red',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Name\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Brookyn 99 characters\")\nplt.show()","da5355dc":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'blue',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Text\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Brookyn 99 Text\")\nplt.show()","091289e2":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","acbf547e":"#https:\/\/stackoverflow.com\/questions\/51534586\/add-and-remove-words-from-the-nltk-stopwords-list\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\n#add words that aren't in the NLTK stopwords list\nnew_stopwords = ['off', 'in', 'the', 'of']\nnew_stopwords_list = stop_words.union(new_stopwords)\n\n#remove words that are in NLTK stopwords list\nnot_stopwords = {'breathe', 'job', 'alive'} \nfinal_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n\nprint(final_stop_words)","4e4ee2a9":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef processText(x):\n    x= removePunctuation(x)\n    #x= removeStopwords(x)\n    return x","50e39a3d":"from nltk.tokenize import sent_tokenize, word_tokenize\nB99 = pd.Series([word_tokenize(processText(x)) for x in df['Text']])\nB99.head(10)","10466f0a":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\n#num_features = 300    # Word vector dimensionality                      \nmin_word_count = 40   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(B99, workers=num_workers, #size=num_features,  was removed\n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","956fa8eb":"from gensim import utils\nimport gensim\nimport logging\nfrom timeit import default_timer\nimport threading\nfrom six.moves import range\nfrom six import itervalues, string_types\nfrom gensim import matutils\nfrom numpy import float32 as REAL, ones, random, dtype\nfrom types import GeneratorType\nfrom gensim.utils import deprecated\nimport os\nimport copy","c9067b28":"#I don't know where I found this snippet\n\ndef most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):\n        \"\"\"Deprecated, use self.wv.most_similar() instead.\n        Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n        \"\"\"\n        return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)","2f6f1277":"model.wv.most_similar('Peralta')","a227e6da":"df[\"Name\"].value_counts()","b53526e6":"labels = 'JAKE', 'HOLT', 'AMY', 'ROSA', 'GINA'\nsizes = [337, 149, 136, 79, 56]  #must have same number labels, sizes and explode\nexplode = (0, 0.2, 0, 0, 0)  # only \"explode\" the 2nd slice \n\nfig1, ax1 = plt.subplots(figsize=(10,10))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","f55a8d5f":"#Since most similar is now in KeyedVectors I copied the snippet below\n#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nfrom gensim import models\nfrom gensim.models import KeyedVectors\n\n\nimport gensim.downloader as api\nword_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data \n# Check the \"most similar words\", using the default \"cosine similarity\" measure.\nresult = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","229526f6":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['speech', 'breathe'], negative=['weirdo'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\") ","8dd65650":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['best', 'good'], negative=['never'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","b593d28f":"#Third row, Name, 2nd Column Text\n\ndf.iloc[3,1]","c859b11d":"#Second row, Name, 2nd Column Text\n\ndf.iloc[2,1]","133ec199":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport re","da9d0f4a":"doc_1 = \"I'm doing the best speech from Donnie Brasco. Actually,ten of me are doing the best speech from Donnie Brasco. Sup?\"\ndoc_2 = \"What are you doing, weirdo?\"","cff13133":"words_doc1 = {'I', 'm', 'doing', 'the', 'best', 'speech', 'are', 'doing', ' the', 'best', 'speech'}\nwords_doc2 = {'What', 'are', 'you', 'doing', 'weirdo'}","e725c926":"#Code by https:\/\/studymachinelearning.com\/jaccard-similarity-text-similarity-metric-in-nlp\/\n\ndef Jaccard_Similarity(doc1, doc2): \n    \n    # List the unique words in a document\n    words_doc1 = set(doc1.lower().split()) \n    words_doc2 = set(doc2.lower().split())\n    \n    # Find the intersection of words list of doc1 & doc2\n    intersection = words_doc1.intersection(words_doc2)\n\n    # Find the union of words list of doc1 & doc2\n    union = words_doc1.union(words_doc2)\n        \n    # Calculate Jaccard similarity score \n    # using length of intersection set divided by length of union set\n    return float(len(intersection)) \/ len(union)","806ff267":"doc_1 = \"I'm doing the best speech from Donnie Brasco. Actually,ten of me are doing the best speech from Donnie Brasco. Sup?\"\ndoc_2 = \"What are you doing, weirdo?\"\n\nJaccard_Similarity(doc_1,doc_2)","0a5cd9ce":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df['Text'])\nprint(tfidf_matrix.shape)","0c519e78":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","4dde97c7":"indices = pd.Series(df.index, index=df['Name']).drop_duplicates()\nprint(indices)","dacb560c":"idx = indices['ROSA']\nprint(idx)","36ce9477":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n\n    return df['Name'].iloc[movie_indices]","4424fd51":"get_recommendations('JAKE & CHARLES BOTH')","133eb785":"#To avoid error:\n\n\"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"  \n\nInstead of writting just one name of the characters I wrote the last one from input 15, since it's different from the others. On the snippet below get_recommendations.   ","3ceb7ad0":"#Let's try some Jaccard Similarity","4b9b546b":"#Really???? Peralta is not present in Brooklyn-99? Sorry Gensim, wrong answer\/error. ","d9eea259":"![](https:\/\/ih1.redbubble.net\/image.813616034.4209\/st,small,507x507-pad,600x600,f8f8f8.jpg)redbubble.com","cf342896":"#Get the set of unique words for each document.","08cfb1bb":"\"Return of the King\" is the fifteenth episode of the sixth season of the American television police sitcom series Brooklyn Nine-Nine, and the 127th overall episode of the series. The episode was written by Phil Augusta Jackson and directed by main cast member Melissa Fumero, in her directorial debut. It aired on May 2, 2019 on NBC.\"\n\n\"The episode 'Return Of The King' is honestly a bit of a disappointment. As enjoyable as every plot is, there is honestly a lot of steam in a version of this episode that, like 'Four Movements,' is focused more squarely on Gina (and the rest of the Nine-Nine as extensions of that).\n\nhttps:\/\/en.wikipedia.org\/wiki\/Return_of_the_King_(Brooklyn_Nine-Nine)","83e0f20d":"<iframe width=\"699\" height=\"393\" src=\"https:\/\/www.youtube.com\/embed\/1MAgBWStblo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","c2475fd4":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQzAJi8AFwy9iKRiX-A5tVn69RXw6v3AGYvtw&usqp=CAU)unilad.co.uk","496a5081":"#The Jaccard similarity between doc_1 and doc_2 is 0.058823529411764705.","654150a3":"#That's all for now.","9ca7fa9c":"size=num_features Was removed from model= word2vec.Word2Vec(B99, workers=num_workers, size=num_features.........","1d6ca24c":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:white;\">Shh! Not a Doctor: Brooklyn Nine Nine<\/b><\/h1><\/center>\n\n\n\"Brooklyn Nine-Nine is an American Procedural Comedy Television Series by Dan Goor and Michael Scur. Moreover, it is currently in its 7th Season while the 8th Season has been confirmed.\"\n\nNot a Doctor, shh!\n\n\"Are you even a Brooklyn Nine-Nine fan if you don\u2019t call out \u201cShh! Not a Doctor\u201d at the end of every episode? Interestingly, a fan once tweeted Executive Producer Dan Goor, asking for the BTS story behind this phrase, to which he replied, \u201cI was a biochemistry major in college and I was enrolled in med-school, but about two weeks before it started, I got a job writing for The Daily Show.\u201d So, that\u2019s where the name \u2018Dr. Goor Productions\u2019 and it\u2019s catchphrase \u2018Shh\u2026Not a Doctor\u2019 comes from.\"\n\nhttps:\/\/duexpress.in\/10-secret-facts-every-brooklyn-nine-nine-fan-b99-must-know-about\/","f407d31f":"#Cheddar\n\n\"Cheddar Holt-Cozner is the Pembroke Welsh Corgi owned by Raymond Holt and Kevin Cozner. He is well-trained, can do tricks, and apparently likes wedding cake.\"\n\n\"Cheddar seems to have some degree of power over the squad, as in Season 3, Episode 18 \"Cheddar\", Charles refers to him as the alpha dog.\"\n\nhttps:\/\/brooklyn99.fandom.com\/wiki\/Cheddar\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTp0SdKX5dQTMyK7Daf4NWBH6GMFiwMUAKVxg&usqp=CAU)teepublic.com","bfa143f4":"![](https:\/\/static1.purebreak.com.br\/articles\/8\/93\/71\/8\/@\/363175--brooklyn-nine-nine-vote-no-seu-person-diapo-3.jpg)purebreak.com.br","ac4f849d":"#Now, an attempt with Cosine Similarity."}}