{"cell_type":{"0ab805e0":"code","04c7c463":"code","655f2288":"code","e3405730":"code","ca6c413d":"code","e84a13eb":"code","765b875d":"code","3175b25c":"code","1b6eb04e":"code","115d257c":"code","f187336b":"code","0c570992":"code","f18bca5f":"code","3e219a2a":"code","e7382578":"code","064008e9":"code","15f17505":"code","df19f141":"code","bea5cdfb":"code","c01e759d":"code","170824ce":"code","cd92f173":"code","9d75e94a":"code","a4ef0735":"code","f365481f":"code","5124360b":"code","a75d423c":"code","f4f62344":"code","22a297c2":"code","4e752e80":"code","74bb2cdb":"code","ddaedaa0":"code","2dc797f2":"code","106a915f":"code","46119dd2":"code","24a2f2b4":"code","1a0013a6":"code","8dd63582":"code","32484143":"code","254d183b":"code","61a3a750":"code","ccf63e3c":"code","6dc5666a":"markdown","045089de":"markdown","5def1a3b":"markdown","c4edb837":"markdown","34769be6":"markdown","93722b95":"markdown","008ed556":"markdown","6bf3eacf":"markdown","a58722e5":"markdown","3f6c8eda":"markdown"},"source":{"0ab805e0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","04c7c463":"data=pd.read_csv('..\/input\/insurance.csv')","655f2288":"data.head()","e3405730":"data.shape","ca6c413d":"data.info()","e84a13eb":"#convert columns to catgorical columns\n#Not needed \n#data['sex']=pd.Categorical(data['sex'])\n#data['region']=pd.Categorical(data['region'])\n#data['smoker']=pd.Categorical(data['smoker'])","765b875d":"data.describe()","3175b25c":"sns.pairplot(data)","1b6eb04e":"#create new column based on healthiness\n\n#data=data.drop(columns='healthy')\ndata['healthy'] =np.nan","115d257c":"def fun(bmi_str):\n    if (bmi_str >=18.5 and bmi_str <= 24.9) :\n        return 1\n    else:\n        return 0\n\ndata['healthy']=data['bmi'].apply(fun)","f187336b":"data.info()","0c570992":"#only if its in object format it can be processed using one hot encoding\ndata['healthy']=data['healthy'].astype(object)","f18bca5f":"data.info()","3e219a2a":"sns.distplot(data['age'])","e7382578":"sns.distplot(data['bmi'])","064008e9":"sns.distplot(data['children'])","15f17505":"pd.value_counts(data['smoker'])","df19f141":"sns.boxplot(y='charges',x='smoker',data=data)","bea5cdfb":"#This tab is not used. Anova is used while comaring \n\ndata_smoker=data[data['smoker']=='yes']\ndata_no_smoker=data[data['smoker']=='no']\ndata_smoker=(data_smoker['charges']).astype(int)\ndata_no_smoker=(data_no_smoker['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(data_smoker)\nplt.subplot(1,2,2)\nsns.distplot(data_no_smoker)\n\n#these are independent columns,\nfrom scipy.stats import mannwhitneyu\nz_statistic,p_value=mannwhitneyu(data_no_smoker,data_smoker)\nprint(z_statistic,p_value)\n\n#Since p<0.05 ,null hyp is rejected. Thus both columns are from different population(Different mean)","c01e759d":"pd.value_counts(data['sex'])","170824ce":"sns.boxplot(y='charges',x='sex',data=data)","cd92f173":"#This tab is not used. Anova is used while comaring \n\ndata_male=data[data['sex']=='male']\ndata_female=data[data['sex']=='female']\ndata_male=(data_male['charges']).astype(int)\ndata_female=(data_female['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(data_male)\nplt.subplot(1,2,2)\nsns.distplot(data_female)\n\n#these are independent columns,\nfrom scipy.stats import mannwhitneyu,ttest_ind\nz_statistic,p_value=mannwhitneyu(data_male,data_female)\nz_statistic_ttest,p_value_ttest=mannwhitneyu(data_male,data_female)\nprint(z_statistic,p_value)\nprint(z_statistic_ttest,p_value_ttest)\n\n#Since p>0.05 ,null hyp is accepted. Thus both columns are from same population(same mean)","9d75e94a":"pd.value_counts(data['region'])","a4ef0735":"sns.boxplot(y='charges',x='region',data=data)","f365481f":"#This tab is not used. Anova is used while comaring \n\ndata_reg1=data[data['region']=='southeast']\ndata_reg2=data[data['region']=='southwest']\ndata_reg3=data[data['region']=='northwest']\ndata_reg4=data[data['region']=='northeast']\ndata_reg1=(data_reg1['charges']).astype(int)\ndata_reg2=(data_reg2['charges']).astype(int)\ndata_reg3=(data_reg3['charges']).astype(int)\ndata_reg4=(data_reg4['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(2,2,1)\nsns.distplot(data_reg1)\nplt.subplot(2,2,2)\nsns.distplot(data_reg2)\nplt.subplot(2,2,3)\nsns.distplot(data_reg3)\nplt.subplot(2,2,4)\nsns.distplot(data_reg4)\n\n#these are independent columns,Following ANOVA - since there are more than 2 categories(columns)\nfrom statsmodels.formula.api import ols \nfrom statsmodels.stats.anova import anova_lm\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n\nformula = 'charges ~ C(region)'\nmodel = ols(formula, data).fit()\naov_table = anova_lm(model)\nprint(aov_table)\n\n\n#Since p<0.05 ,null hyp is rejected. So we must use multi comparison(Refer one way anova- golf exapmle)\n\nmc = MultiComparison(data['charges'], data['region'])\nresult = mc.tukeyhsd()\n \nprint(result)\nprint(mc.groupsunique)\n\n#for all other case except last one - 0 is in between lower and upper bound values. So accept null hyp(mean is equal) \n#for those and reject for last case. \n","5124360b":"pd.value_counts(data['healthy'])","a75d423c":"sns.boxplot(y='charges',x='healthy',data=data)","f4f62344":"sns.boxplot(y='charges',x='children',data=data)","22a297c2":"#find correlation in case of categorical data\n\nfrom scipy.stats import chisquare,chi2_contingency\n\nprint(chisquare(data[\"sex\"].value_counts()))\nprint(chisquare(data[\"smoker\"].value_counts()))\nprint(chisquare(data[\"region\"].value_counts()))\nprint(chisquare(data[\"healthy\"].value_counts()))","4e752e80":"# Goodness of Fit Test between 2 categorical variables\n\n# H0: The two categorical variables are independent\n# Ha: The two categorical variables are dependent\n\n# Creating contingency table\ncont = pd.crosstab(data[\"sex\"],\n                   data[\"smoker\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.006 < 0.05 hence we conclude that the 2 categorical variables are dependent","74bb2cdb":"cont = pd.crosstab(data[\"smoker\"],\n                   data[\"region\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.06 > 0.05 hence we conclude that the 2 categorical variables are independent","ddaedaa0":"cont = pd.crosstab(data[\"smoker\"],\n                   data[\"healthy\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.46 > 0.05 hence we conclude that the 2 categorical variables are independent","2dc797f2":"cont = pd.crosstab(data[\"sex\"],\n                   data[\"healthy\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.40 > 0.05 hence we conclude that the 2 categorical variables are independent","106a915f":"correlation=data.corr()\ncorrelation","46119dd2":"data.head()\ndata.info()","24a2f2b4":"# Convert categorical variable into dummy\/indicator variables. As many columns will be created as distinct values\n# This is also kown as one hot coding. The column names will be America, Europe and Asia... with one hot coding\n# Like feature scaling\n\n#Replace 1 and 0 with values in healthy column\ndata['healthy'] = data['healthy'].replace({0:'not_healthy', 1:'healthy'})","1a0013a6":"#one hot coding\ndata=pd.get_dummies(data,columns=['sex','smoker','region','healthy'],drop_first='True')","8dd63582":"data.head()","32484143":"#PREPROCESSING DATA - Standardization and training data split\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX=data.drop(columns='charges')\ny=data['charges']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=1)\n\n# Create the Scaler object\nscaler = preprocessing.StandardScaler()\n\n#feature scaling in dependent and independent columns\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n\n        #Gets some error\n#y_train=scaler.fit_transform(y_train)\n#y_test=scaler.transform(y_test)\n\nlinear_reg=LinearRegression()\nlinear_reg.fit(X_train,y_train)\n\nlinear_reg.score(X_test,y_test)","254d183b":"#Using SKLEARN  - Without Standardized\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX=data.drop(columns='charges')\ny=data['charges']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=1)\nlinear_reg=LinearRegression()\nlinear_reg.fit(X_train,y_train)\n\nlinear_reg.score(X_test,y_test)","61a3a750":"#Using OLS method\n\nfrom statsmodels.formula.api import ols   \n\nformula='charges ~ healthy_not_healthy +  smoker_yes + sex_male + children + age + bmi'\nmodel=ols(formula,data).fit()\nmodel.summary()","ccf63e3c":"#Polynomial regression\n\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n\nX1=data.drop(columns='charges')\ny1=data['charges']\n\nX_poly_train,X_poly_test,y_poly_train,y_poly_test=train_test_split(X1,y1,test_size=0.25,random_state=1)\n\npoly = PolynomialFeatures(degree=2, interaction_only=True)\n\nX1_poly_train=poly.fit_transform(X_poly_train)\nX1_poly_test=poly.fit_transform(X_poly_test)\n\nlin=linear_model.LinearRegression()\nlin.fit(X1_poly_train,y_poly_train)\n\ny_pred=lin.predict(X1_poly_test)\n\nlin.score(X1_poly_test,y_poly_test)","6dc5666a":"# Chi Square Testing","045089de":"# EDA","5def1a3b":"# Polynomial Regression","c4edb837":"Thus by using this we get higher value.","34769be6":"# Data preprocessing","93722b95":"# Linear Regression - 2 types","008ed556":"# Explaining ANOVA - not used in the code","6bf3eacf":"# Checking normality and correlation","a58722e5":"# Basic Done Right","3f6c8eda":"# Data visualization"}}