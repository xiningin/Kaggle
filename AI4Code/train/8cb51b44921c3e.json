{"cell_type":{"03c4a9c9":"code","83d7b2cd":"code","63e729a5":"code","20990420":"code","b4ffbe36":"code","7599d94c":"code","ffaa35a3":"code","a78f83ae":"code","84fc8d00":"code","6c6433e6":"code","398797ab":"code","938e03e0":"code","01f7693f":"code","0aec217d":"code","a43d3ebd":"code","82c60903":"code","d7b0f0f2":"markdown","6b833493":"markdown","da565efe":"markdown","71d58798":"markdown","296f9b7d":"markdown","7b4e77c0":"markdown","b598619e":"markdown","753a28a9":"markdown","faf5d6ac":"markdown","1328e9bd":"markdown","a842b529":"markdown","643996bd":"markdown"},"source":{"03c4a9c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83d7b2cd":"# import logging\nimport json\nimport re\n\n# JSON formatting functions\ndef convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n    training_data = []\n    lines=[]\n    with open(dataturks_JSON_FilePath, 'r') as f:\n        lines = f.readlines()\n\n    for line in lines:\n        data = json.loads(line)\n        text = data['content'].replace(\"\\n\", \" \")\n        entities = []\n        data_annotations = data['annotation']\n        if data_annotations is not None:\n            for annotation in data_annotations:\n                #only a single point in text annotation.\n                point = annotation['points'][0]\n                labels = annotation['label']\n                # handle both list of labels or a single label.\n                if not isinstance(labels, list):\n                    labels = [labels]\n\n                for label in labels:\n                    point_start = point['start']\n                    point_end = point['end']\n                    point_text = point['text']\n\n                    lstrip_diff = len(point_text) - len(point_text.lstrip())\n                    rstrip_diff = len(point_text) - len(point_text.rstrip())\n                    if lstrip_diff != 0:\n                        point_start = point_start + lstrip_diff\n                    if rstrip_diff != 0:\n                        point_end = point_end - rstrip_diff\n                    entities.append((point_start, point_end + 1 , label))\n        training_data.append((text, {\"entities\" : entities}))\n    return training_data\n\ndef trim_entity_spans(data: list) -> list:\n    \"\"\"Removes leading and trailing white spaces from entity spans.\n\n    Args:\n        data (list): The data to be cleaned in spaCy JSON format.\n\n    Returns:\n        list: The cleaned data.\n    \"\"\"\n    invalid_span_tokens = re.compile(r'\\s')\n\n    cleaned_data = []\n    for text, annotations in data:\n        entities = annotations['entities']\n        valid_entities = []\n        for start, end, label in entities:\n            valid_start = start\n            valid_end = end\n            while valid_start < len(text) and invalid_span_tokens.match(\n                    text[valid_start]):\n                valid_start += 1\n            while valid_end > 1 and invalid_span_tokens.match(\n                    text[valid_end - 1]):\n                valid_end -= 1\n            valid_entities.append([valid_start, valid_end, label])\n        cleaned_data.append([text, {'entities': valid_entities}])\n    return cleaned_data","63e729a5":"data = trim_entity_spans(convert_dataturks_to_spacy(\"..\/input\/resume-entities-for-ner\/Entity Recognition in Resumes.json\"))\ndata[0]","20990420":"# def clean_entities(training_data):\n    \n#     clean_data = []\n#     for text, annotation in training_data:\n        \n#         entities = annotation.get('entities')\n#         entities_copy = entities.copy()\n        \n#         # append entity only if it is longer than its overlapping entity\n#         i = 0\n#         for entity in entities_copy:\n#             j = 0\n#             for overlapping_entity in entities_copy:\n#                 # Skip self\n#                 if i != j:\n#                     e_start, e_end, oe_start, oe_end = entity[0], entity[1], overlapping_entity[0], overlapping_entity[1]\n#                     # Delete any entity that overlaps, keep if longer\n#                     if ((e_start >= oe_start and e_start <= oe_end) \\\n#                     or (e_end <= oe_end and e_end >= oe_start)) \\\n#                     and ((e_end - e_start) <= (oe_end - oe_start)):\n#                         entities.remove(entity)\n#                 j += 1\n#             i += 1\n#         clean_data.append((text, {'entities': entities}))\n                \n#     return clean_data\n\n# data = clean_entities(data)","b4ffbe36":"!pip install spacy==2.1.4","7599d94c":"# from spacy.lang.en import English  # Or whichever language you need\n# from spacy.gold import biluo_tags_from_offsets\n\n# def bilou_tags(data):\n    \n#     docs  = []\n#     annots = []\n#     nlp = English()\n#     for text, annotations in data:\n#         offsets = annotations[\"entities\"]\n#         doc = nlp(text)\n#         tags = biluo_tags_from_offsets(doc, offsets)\n#         docs.append([token.text for token in doc])\n#         annots.append(tags)\n        \n#     df_data = pd.DataFrame({'docs': docs, 'annots': annots})\n\n#     return df_data\n\n# df_data = bilou_tags(data)\n# df_data","ffaa35a3":"# for i in range(len(df_data)):\n#     if \"-\" in df_data.loc[i, \"annots\"]:\n#         df_data.drop(i, axis = \"index\", inplace = True)\n# df_data.reset_index(inplace = True)\n# len(df_data)","a78f83ae":"# data = []\n\n# for i in range(len(df_data)):\n#     resume = df_data.loc[i, \"docs\"]\n#     annots = df_data.loc[i, \"annots\"]\n#     example = []\n#     for word, annot in zip(resume, annots):\n#         if not(word.isalnum() or len(word) > 1):\n#             annot = \"O\"\n#         example.append((word, annot))\n#     data.append(example)\n# data[0]","84fc8d00":"# data = [[(doc, annot) for doc, annot in zip(df_data[\"docs\"][i], df_data[\"annots\"][i]) if doc.isalnum() or len(doc) > 1] for i in range(len(df_data))]\n\n# spacy_data = []\n# for example in data:\n#     text = \"\"\n#     entities = []\n#     start = 0\n#     for w, t in example:\n#         text += w + \" \"\n#         if t != \"O\":\n#             entities.append((start, start + len(w), t[2: ]))\n#         start += len(w) + 1\n#     spacy_data.append((text, {\"entities\": entities}))\n\n# spacy_data[0]","6c6433e6":"# from itertools import groupby\n\n# spacy_data_no_dup = []\n\n# for i in range(len(spacy_data)):\n#     text = spacy_data[i][0]\n#     ents = spacy_data[i][1][\"entities\"]\n#     ents_no_dup = []\n#     key_func = lambda x: x[2]\n#     for key, group in groupby(ents, key_func):\n#         grp = list(group)\n#         first = grp[0]\n#         last = grp[-1]\n#         ents_no_dup.append((first[0], last[1], first[2]))\n        \n#     spacy_data_no_dup.append((text, {\"entities\": ents_no_dup[::-1]}))\n\n# spacy_data_no_dup[0]","398797ab":"import random\nimport math\n\ndef train_test_split(data, test_size, random_state):\n\n    random.Random(random_state).shuffle(data)\n    test_idx = len(data) - math.floor(test_size * len(data))\n    train_set = data[0: test_idx]\n    test_set = data[test_idx: ]\n\n    return train_set, test_set","938e03e0":"train_data, test_data = train_test_split(data, test_size = 0.1, random_state = 42)","01f7693f":"import spacy\n\ndef train_spacy():\n    \n    nlp = spacy.blank('en')  # create blank Language class\n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if 'ner' not in nlp.pipe_names:\n        ner = nlp.create_pipe('ner')\n        nlp.add_pipe(ner, last=True)\n        \n    # add labels\n    for _, annotations in train_data:\n         for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n            \n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        optimizer = nlp.begin_training()\n        for itn in range(10):\n            print(\"Statring iteration \" + str(itn))\n            random.shuffle(train_data)\n            losses = {}\n            for text, annotations in train_data:\n                nlp.update(\n                    [text],  # batch of texts\n                    [annotations],  # batch of annotations\n                    drop=0.2,  # dropout - make it harder to memorise data\n                    sgd=optimizer,  # callable to update weights\n                    losses=losses)\n            print(losses)\n    return nlp","0aec217d":"nlp = train_spacy()","a43d3ebd":"from spacy.gold import GoldParse\nfrom itertools import groupby\n\ndef doc_to_bilou(nlp, text):\n    \n    doc = nlp(text)\n    tokens = [(tok.text, tok.idx, tok.ent_type_) for tok in doc]\n    entities = []\n    for entity, group in groupby(tokens, key=lambda t: t[-1]):\n        if not entity:\n            continue\n        group = list(group)\n        _, start, _ = group[0]\n        word, last, _ = group[-1]\n        end = last + len(word)\n        \n        entities.append((\n                start,\n                end,\n                entity\n            ))\n\n    gold = GoldParse(nlp(text), entities = entities)\n    pred_ents = gold.ner\n    \n    return pred_ents\n\ny_test = []\ny_pred = []\n\nfor text, annots in test_data:\n    \n    gold = GoldParse(nlp.make_doc(text), entities = annots.get(\"entities\"))\n    ents = gold.ner\n    pred_ents = doc_to_bilou(nlp, text)\n    \n    y_test.append(ents)\n    y_pred.append(pred_ents)\n    \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom itertools import chain\n\ndef ner_report(y_true, y_pred):\n    \"\"\"\n    Classification report for a list of BIO-encoded sequences.\n    It computes token-level metrics and discards \"O\" labels.\n    \n    Note that it requires scikit-learn 0.15+ (or a version from github master)\n    to calculate averages properly!\n    \"\"\"\n    lb = LabelBinarizer()\n    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n        \n    tagset = set(lb.classes_)\n    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n    \n    return classification_report(\n        y_true_combined,\n        y_pred_combined,\n        labels = [class_indices[cls] for cls in tagset],\n        target_names = tagset\n    ), accuracy_score(y_true_combined, y_pred_combined)\n    \nreport, accuracy = ner_report(y_test, y_pred)\nprint(report)","82c60903":"print(accuracy)","d7b0f0f2":"### Removing Mislabeled Examples","6b833493":"### From BILOU to SpaCy","da565efe":"### Processing Indexes","71d58798":"# Named Entity Recognition Dataset","296f9b7d":"### Training SpaCy","7b4e77c0":"## Dataset","b598619e":"### Entity Aggregation","753a28a9":"### Overlapping Entities","faf5d6ac":"### Entity Mapping","1328e9bd":"\n## Modeling","a842b529":"## Cleaning Entities","643996bd":"### Train Test Split"}}