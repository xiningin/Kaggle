{"cell_type":{"a919598f":"code","879cf360":"code","beea6cf3":"code","6d1e7903":"code","617da280":"code","298ba314":"code","1b6b0489":"code","1582d21d":"code","c5bc7d9b":"code","158072bf":"code","6b324ae9":"code","8ddf1ae1":"code","b5508758":"code","4b84249f":"code","083e9a5c":"code","41d8292f":"code","2d02f559":"code","eb84777b":"code","d32d12ae":"code","758beae6":"code","a4600ba4":"code","f35b66ca":"code","0ea69b59":"code","fefd7e59":"code","bebdc0be":"code","79b56406":"code","05537425":"code","eec5a59e":"code","227b1ae4":"code","31f7fc75":"code","a910ab25":"code","65e51c8b":"code","04300f9d":"code","87c5bc13":"code","e9eae75e":"code","db6139cd":"markdown","0c56b6df":"markdown","774307e7":"markdown","a2bd230b":"markdown","c59ef6f6":"markdown"},"source":{"a919598f":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nimport pandas as pd\nimport json\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport matplotlib.cm as cm\nfrom matplotlib import rcParams\nfrom prettytable import PrettyTable\n\nimport nltk \nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.isri import ISRIStemmer\nfrom collections import Counter \nimport itertools\nimport re\nimport string\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nfrom joblib import dump, load","879cf360":"df = pd.read_csv(\"\/kaggle\/input\/arabic-classification\/arabic_dataset_classifiction.csv\/arabic_dataset_classifiction.csv\")\n\ndf","beea6cf3":"print(np.sum(df.isnull().any(axis=1)))\n\nclean_df = df.dropna()\nprint(np.sum(clean_df.isnull().any(axis=1)))","6d1e7903":"print (df.notnull().any(axis = 0))","617da280":"def remove_hashtag(df, col = 'text'):\n    for letter in r'#.][!XR':\n        df[col] = df[col].astype(str).str.replace(letter,'', regex=True)\n    \n\n        \nremove_hashtag(clean_df)\nclean_df","298ba314":"arabic_punctuations = '''`\u00f7\u00d7\u061b<>_()*&^%][\u0640\u060c\/:\"\u061f.,'{}~\u00a6+|!\u201d\u2026\u201c\u2013\u0640'''\nenglish_punctuations = string.punctuation\npunctuations_list = arabic_punctuations + english_punctuations\n\ndef remove_punctuations(text):\n    translator = str.maketrans('', '', punctuations_list)\n    return text.translate(translator)","1b6b0489":"def normalize_arabic(text):\n    text = re.sub(\"[\u0625\u0623\u0622\u0627]\", \"\u0627\", text)\n    text = re.sub(\"\u0649\", \"\u064a\", text)\n    text = re.sub(\"\u0629\", \"\u0647\", text)\n    text = re.sub(\"\u06af\", \"\u0643\", text)\n    return text","1582d21d":"def remove_repeating_char(text):\n    return re.sub(r'(.)\\1+', r'\\1', text)","c5bc7d9b":"def processDocument(doc, stemmer): \n\n    #Replace @username with empty string\n    doc = re.sub(r'@[^\\s]+', ' ', doc)\n    doc = re.sub(r'_', ' ', doc)\n    doc = re.sub(r'\\n', ' ', doc)\n    doc = re.sub(r'[a-z,A-Z]', '', doc)\n    doc = re.sub(r'\\d', '', doc)\n    #Convert www.* or https?:\/\/* to \" \"\n    doc = re.sub('((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))',' ',doc)\n    #Replace #word with word\n    doc = re.sub(r'#([^\\s]+)', r'\\1', doc)\n    # remove punctuations\n    doc= remove_punctuations(doc)\n    # normalize the tweet\n    doc= normalize_arabic(doc)\n    # remove repeated letters\n    doc=remove_repeating_char(doc)\n    #stemming\n    doc = stemmer.stem(doc)\n    \n    return doc\n\nstemmer = ISRIStemmer()\nclean_df[\"text\"] = clean_df['text'].apply(lambda x: processDocument(x, stemmer))\nclean_df","158072bf":"tokenizer = RegexpTokenizer(r'\\w+')\nclean_df[\"text\"] = clean_df[\"text\"].apply(tokenizer.tokenize)\n# print(clean_df['text'].values[0])\nclean_df","6b324ae9":"stopwords_list = stopwords.words('arabic')\nlistToStr = ' '.join([str(elem) for elem in stopwords_list]) \nprint(listToStr)","8ddf1ae1":"clean_df[\"text\"] = clean_df[\"text\"].apply(lambda x: [item for item in x if item not in stopwords_list])\nclean_df","b5508758":"def countPropetries(df):\n    all_words = [word for tokens in df[\"text\"] for word in tokens]\n    sentence_lengths = [len(tokens) for tokens in df[\"text\"]]\n\n    VOCAB = sorted(list(set(all_words)))\n\n    print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n    print(\"Max sentence length is %s\" % max(sentence_lengths))\n    return all_words","4b84249f":"culture_df = clean_df.loc[clean_df[\"targe\"] == 0]\ndiverse_df = clean_df.loc[clean_df[\"targe\"] == 1]\neconomy_df = clean_df.loc[clean_df[\"targe\"] == 2]\npolitic_df = clean_df.loc[clean_df[\"targe\"] == 3]\nsport_df = clean_df.loc[clean_df[\"targe\"] == 4]\n\nprint(\"Culture : \")\nculture_words = countPropetries(culture_df)\nprint(\"\\nDiverse : \")\ndiverse_words = countPropetries(diverse_df)\nprint(\"\\nEconomy : \")\neconomy_words = countPropetries(economy_df)\nprint(\"\\nPolitics : \")\npolitic_words = countPropetries(politic_df)\nprint(\"\\nSport : \")\nsport_words = countPropetries(sport_df)","083e9a5c":"def plot(all_words, title):\n    counted_words = Counter(all_words)\n\n    words = []\n    counts = []\n    for letter, count in counted_words.most_common(25):\n        words.append(letter)\n        counts.append(count)\n\n    colors = cm.rainbow(np.linspace(0, 1, 10))\n    rcParams['figure.figsize'] = 20, 10\n\n    plt.title(title)\n    plt.xlabel('Count')\n    plt.ylabel('Words')\n    plt.barh(words, counts, color=colors)","41d8292f":"plot(culture_words, 'Top words in Culture')","2d02f559":"plot(diverse_words, 'Top words in Diverse')","eb84777b":"plot(economy_words, 'Top words in Economy')","d32d12ae":"plot(politic_words, 'Top words in Politics')","758beae6":"plot(sport_words, 'Top words in Sport')","a4600ba4":"sns.countplot(data= clean_df, x = \"targe\")\nplt.show()","f35b66ca":"y = clean_df['targe']\nX = clean_df['text']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)","0ea69b59":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    ngram_range=(1, 1),\n    max_features =10000)","fefd7e59":"model = Pipeline([\n                    (\"tfidf\", word_vectorizer), # convert words to numbers using tfidf\n                    (\"clf\", SVC()) # model the text\n])\n\n# Fit the pipeline to the training data\nmodel.fit(X_train.astype('str'), y_train)","bebdc0be":"dump(model, \"svm_model.joblib\")","79b56406":"def calculate_results(y_true, y_pred):\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results\n\ny_pred = model.predict(X_test.astype('str'))\nresult = calculate_results(y_test, y_pred)\nresult","05537425":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    fig = plt.figure(figsize = (10,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd' \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 fontsize=20,\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=20)\n    plt.xlabel('Predicted label', fontsize=20)\n\ncm = confusion_matrix(y_test, y_pred)\nplot_confusion_matrix(cm, ['culture', 'diverse', 'economy', 'politic', 'sport'])","eec5a59e":"data = json.load(open(\"\/kaggle\/input\/twitterdata-dev-morocco\/arabic.json\", encoding='utf-16'))\ndf = pd.DataFrame(data, columns=[\"date\", \"content\"])\n\ndf","227b1ae4":"def prepareData(df):\n    remove_hashtag(df, 'content')\n    df[\"content\"] = df['content'].apply(lambda x: processDocument(x, stemmer))\n    tokenizer = RegexpTokenizer(r'\\w+')\n    df[\"content\"] = df[\"content\"].apply(tokenizer.tokenize)\n    stopwords_list = stopwords.words('arabic')\n    df[\"content\"] = df[\"content\"].apply(lambda x: [item for item in x if item not in stopwords_list])\n    return df\n\nprepared_df = prepareData(df)\nprepared_df","31f7fc75":"model = load(\"..\/input\/svm-model\/svm_model.joblib\")","a910ab25":"y_pred = model.predict(prepared_df[\"content\"].astype('str'))\n\nax = sns.histplot(y_pred, discrete=True)\nax.set_xticklabels([\"\", \"culture\", \"diverse\", \"economy\", \"politics\", \"sport\"])","65e51c8b":"y_culture = y_pred[y_pred == 0]\ny_diverse = y_pred[y_pred == 1]\ny_economy = y_pred[y_pred == 2]\ny_politics = y_pred[y_pred == 3]\ny_sport = y_pred[y_pred == 4]","04300f9d":"table = {\n    \"label\" : [\"culture\", \"diverse\", \"economy\", \"politics\", \"sport\"],\n    \"count\" : [len(y_culture), len(y_diverse), len(y_economy), len(y_politics), len(y_sport)],\n    \"percentage\" : [(len(y_culture) \/ len(y_pred)) * 100,\n                    (len(y_diverse) \/ len(y_pred)) * 100,\n                    (len(y_economy) \/ len(y_pred)) * 100,\n                    (len(y_politics) \/ len(y_pred)) * 100,\n                    (len(y_sport) \/ len(y_pred)) * 100]\n}\n\nstat = pd.DataFrame(table)\nstat","87c5bc13":"result = [[], [], [], [], []]\nfor i in range(2):\n    for index in range(len(y_pred)):\n        if y_pred[index] == 0:\n            result[0].append(index)\n        elif y_pred[index] == 1:\n            result[1].append(index)\n        elif y_pred[index] == 2:\n            result[2].append(index)\n        elif y_pred[index] == 3:\n            result[3].append(index)\n        elif y_pred[index] == 4:\n            result[4].append(index)","e9eae75e":"for i in range(5):\n    print(table[\"label\"][i] + \" :\\n\" + df.iloc[random.choice(result[i])][\"content\"] + \"\\n\\n\")","db6139cd":"# Normalize","0c56b6df":"# Machine learing model training","774307e7":"# Remove repetitions","a2bd230b":"# Punctuation tretment","c59ef6f6":"# Model Evaluation"}}