{"cell_type":{"fde53df8":"code","6694e721":"code","7d07ef39":"code","1769d81c":"code","47eb4e05":"code","053399a6":"code","478133db":"code","7d4b6766":"code","11e85ae1":"code","a89a8523":"code","3ac8adb4":"code","ff5f0321":"code","ee3bfffb":"code","5c6dd067":"code","f1d8b1d8":"code","15ee68b9":"code","6a88fa4f":"code","651ed512":"markdown","36bd73d9":"markdown","d6a264a3":"markdown","9c4548d0":"markdown","30d3d722":"markdown","300a4799":"markdown","594621dc":"markdown","18d51c55":"markdown","ed633ab8":"markdown","96f783ea":"markdown"},"source":{"fde53df8":"! pip install pyspark","6694e721":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7d07ef39":"from pyspark.sql import SparkSession, functions as F, DataFrame\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer, VectorIndexer, Bucketizer, OneHotEncoderEstimator\nfrom pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GeneralizedLinearRegression, RandomForestRegressor, GBTRegressor\nfrom pyspark.ml.pipeline import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nspark = SparkSession.builder.getOrCreate()\nspark","1769d81c":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","47eb4e05":"PATH = '\/kaggle\/input\/house-prices-advanced-regression-techniques'\nsdf_train = spark.read.csv(f'{PATH}\/train.csv', inferSchema=True, header=True)\n# 1460 rows \u00d7 81 columns\n\nsdf_test = spark.read.csv(f'{PATH}\/test.csv', inferSchema=True, header=True)\n# 1459 rows \u00d7 80 columns\n\nsdf_sample_submission = spark.read.csv(f'{PATH}\/sample_submission.csv', \n                                       inferSchema=True, header=True)\ncol_sample_submission = ['Id','SalePrice']\n# sdf_sample_submission.toPandas()","053399a6":"pdf = sdf_train.toPandas() # limit(5).\nsdf_train.printSchema()","478133db":"pdf['SalePrice'].plot.line()","7d4b6766":"pdf.groupby('SaleType').count().plot.bar()","11e85ae1":"str_features = [] \nint_features = []\nfor col in  sdf_train.dtypes:\n    if col[1] == 'string':\n        str_features += [col[0]]\n    else:\n        int_features += [col[0]]\n#     print(col)\nprint(f'str_features : {str_features}')\nprint(f'int_features: {int_features}')\n# print(features)\nsdf_train_filter = sdf_train.select(int_features + str_features)\nint_features.remove('SalePrice')\nsdf_test_filter = sdf_test.select(int_features + str_features)","a89a8523":"# sdf_train.select(str_features).limit(5).toPandas().T","3ac8adb4":"# sdf_test_filter.printSchema()\ndef _cast_to_int(_sdf: DataFrame,col_list: list) -> DataFrame:\n    for col in col_list:\n        _sdf = _sdf.withColumn(col, _sdf[col].cast('int'))\n    return _sdf\n\nsdf_test_typecast = _cast_to_int(sdf_test_filter, \n                                int_features)","ff5f0321":"# sdf_test.select([F.count(F.when(sdf_test[c] == 0 ,c )).alias(c) for c in int_features]).toPandas().T\n# sdf_test_typecast.printSchema()","ee3bfffb":"_stages = []\n# Imputer not needed as no missing features\n# null_impute = Imputer(inputCols= int_features, outputCols=int_features) \n# _stages += [null_impute]\n\nstr_indexer = [StringIndexer(inputCol=column,\n                           outputCol=f'{column}_StringIndexer',\n                            handleInvalid='keep') \n               for column in str_features]\n_stages += str_indexer\n\nassembler_input = [f for f in int_features] \nassembler_input += [f'{column}_StringIndexer' \n                    for column  in str_features] \nfeature_vector = VectorAssembler(inputCols=assembler_input, \n                                 outputCol='features', \n                                 handleInvalid = 'keep' )\n_stages += [feature_vector]\n\n\nvect_indexer = VectorIndexer(inputCol='features', \n                             outputCol= 'features_indexed', \n                             handleInvalid = 'keep' )\n_stages += [vect_indexer]\n\nLR = LinearRegression(featuresCol='features_indexed', \n                      labelCol= 'SalePrice',\n                     maxIter=10,\n                     regParam=0.3,\n                     elasticNetParam=0.8)\n_stages += [LR]\n\n# DTR = DecisionTreeRegressor(featuresCol='features_indexed', labelCol= 'SalePrice') #0.223\n# _stages += [DTR]\n\n# GLR = GeneralizedLinearRegression(family='guissian',link= 'identity', maxIter=10, regParam=0.3)\n# _stages += [GLR]\n# IllegalArgumentException: 'GeneralizedLinearRegression_b8172476d09e parameter family given invalid value guissian.'\n\n# RFR = RandomForestRegressor(featuresCol='features_indexed', labelCol='SalePrice') #0.18353\n# _stages += [RFR]\n\n\n# GBTR = GBTRegressor(featuresCol='features_indexed', labelCol='SalePrice', maxIter =10) #0.19474\n# _stages += [GBTR]\n# _stages","5c6dd067":"ml_pipeline = Pipeline(stages=_stages)\nmodel = ml_pipeline.fit(sdf_train_filter)\n","f1d8b1d8":"sdf_predict = model.transform(sdf_test_typecast)","15ee68b9":"sdf_predict.limit(5).toPandas().T","6a88fa4f":"\nsdf_predict.withColumnRenamed('prediction','SalePrice')\\\n            .select('Id','SalePrice')\\\n            .coalesce(1)\\\n            .write.csv('submission',mode='overwrite',header=True)\nprint(os.listdir('submission'))","651ed512":"# 1. Get pyspark lib","36bd73d9":"# 5. Start predicting, run Pipeline","d6a264a3":"Ref:\nhttps:\/\/www.kaggle.com\/jesucristo\/1-house-prices-solution-top-1#Models\n","9c4548d0":"<a href='submission\/part-00000-c1528d69-7c6f-4916-b7a0-37f7c2e5a703-c000.csv'>submission<\/a>","30d3d722":"# 6. Prepare submission file","300a4799":"## String features\n","594621dc":"[PySpark linear-regression](https:\/\/spark.apache.org\/docs\/latest\/ml-classification-regression.html#linear-regression)","18d51c55":"# 4. Model selection and Pipeline building","ed633ab8":"# 3. Feature selection","96f783ea":"# 2. Load data"}}