{"cell_type":{"9ab1de41":"code","91a93a56":"code","4123c4fc":"code","b9811d68":"code","4c8be644":"code","0bb3193a":"code","c69851d8":"code","4e86a30b":"code","2793aada":"code","31854681":"code","2cfed2fe":"code","086ebe32":"code","de7a65ec":"code","5c07db89":"code","b4bffed8":"code","0ceb3a0a":"code","58363738":"code","56522797":"code","beffbf2b":"code","53c3e1a8":"code","d7ea825e":"code","882219bd":"code","a0dcb8f9":"code","b834b493":"code","460ece9f":"code","75049372":"code","edea0d5c":"code","d9c1d580":"code","0c9391ed":"code","5f02a189":"code","3a3d973a":"code","da806bac":"code","5144cd3f":"code","88b8a76b":"code","d2ec4117":"code","611e5a49":"code","1cb2e9d8":"code","ebffe8a8":"markdown","66a84219":"markdown","80cfb78c":"markdown","99f4099b":"markdown"},"source":{"9ab1de41":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nSUB = False","91a93a56":"train_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv', parse_dates=['date'])\ntest_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv', parse_dates=['date'])\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')","4123c4fc":"train_df.head()","b9811d68":"test_df.head()","4c8be644":"train_df.shape, test_df.shape","0bb3193a":"def train_test_split(df, n):\n    if isinstance(n, float):\n        n = int(df.shape[0] * n)\n    \n    return df.iloc[0:df.shape[0] - n], df.iloc[df.shape[0] - n:]\n\n\ndef split_X_y(df, target='num_sold'):\n    return df.drop(target, axis=1), df[target]\n\n\ndef add_datepart(X, feat):\n            \n    X[feat] = pd.to_datetime(X[feat])\n    attrs = ['year', 'month', 'day', 'dayofweek', 'quarter', 'dayofyear']\n    for attr in attrs:\n        X[attr] = getattr(X[feat].dt, attr.lower())\n        \n    return X.drop(feat, axis=1)","c69851d8":"train_df = add_datepart(train_df, 'date')","4e86a30b":"year_sales = train_df.groupby(['country', 'store', 'product', 'year'])['num_sold']\nmean_year_sales = year_sales.mean().to_dict()\nmax_year_sales = year_sales.max().to_dict()\nmin_year_sales = year_sales.min().to_dict()\n\nmonth_sales = train_df.groupby(['country', 'store', 'product', 'year', 'month'])['num_sold']\ntotal_month_sales = month_sales.sum().to_dict()\nmean_month_sales = month_sales.mean().to_dict()\nmax_month_sales = month_sales.max().to_dict()\nmin_month_sales = month_sales.min().to_dict()\n\nday_sales = train_df.groupby(['country', 'store', 'product', 'year', 'month', 'day'])['num_sold']\n\n\nfor i, record in enumerate(train_df[['country', 'store', 'product', 'year', 'month']].to_records(index=False)):\n    record[-2] -= 1\n    \n    if record[-2] >= 2015:\n        # Add last year's monthly records\n        for m in range(1, 13):\n            record[-1] = m\n            tuple_record = tuple(record)\n            train_df.loc[i, f'total_last_year_{m}_sales'] = total_month_sales[tuple_record]\n            train_df.loc[i, f'mean_last_year_{m}_sales'] = mean_month_sales[tuple_record]\n            train_df.loc[i, f'max_last_year_{m}_sales'] = max_month_sales[tuple_record]\n            train_df.loc[i, f'min_last_year_{m}_sales'] = min_month_sales[tuple_record]        ","2793aada":"# for col in train_df.columns:\n#     if train_df[col].isna().any():\n#         train_df.loc[:, f'{col}_na'] = train_df[col].isna().astype(int)\n\ntrain_df = train_df.fillna(0)","31854681":"train_df.tail()","2cfed2fe":"if not SUB:\n    dev_df, val_df = train_test_split(train_df, test_df.shape[0])\n    print(dev_df.shape, val_df.shape)\n    \nelse:\n    dev_df = train_df\n    print(dev_df.shape)","086ebe32":"# Check no overlapping row_ids\nif not SUB:\n    assert set(dev_df.row_id).intersection(val_df.row_id) == set()","de7a65ec":"# Drop 2015 from training set\ndev_df = dev_df[dev_df.year > 2015]","5c07db89":"X_train, y_train = split_X_y(dev_df)\n\nif not SUB:\n    X_val, y_val = split_X_y(val_df)","b4bffed8":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n\ndef preprocess_dataset(X, encoders={}):\n        \n#     X = add_datepart(X, 'date')\n    \n#     for country in ['Finland', 'Norway', 'Sweden']:\n#         X[country + '_prog'] = ((X.row_id \/\/ 18) + 1) * (X['country']==country).astype(int)\n#         X[country + '_prog^2'] = (X[country + '_prog']**2)\n#         X[country + '_prog^3'] = (X[country + '_prog']**3)\n    \n    feats = ['country', 'store', 'product']\n    if not encoders:\n        encoders = {feat: LabelEncoder().fit(X[feat]) for feat in feats}\n    \n    for feat in feats:\n        X[feat] = encoders[feat].transform(X[feat])\n    \n    return X, encoders","0ceb3a0a":"X_train, encoders = preprocess_dataset(X_train)\n\nif not SUB:\n    X_val, _ = preprocess_dataset(X_val, encoders)","58363738":"def print_scores(model, X_train, y_train, X_val, y_val, scorer):\n    scores = [model.score(X_train, y_train),\n              scorer(y_train, model.predict(X_train)),\n              model.score(X_val, y_val),\n              scorer(y_val, model.predict(X_val))]\n    if hasattr(model, 'oob_score_'):\n        scores.append(model.oob_score_)\n        \n    print(scores)\n    \n\n    \ndef SMAPE_score(y_true, y_pred):\n    return 100 \/ len(y_true) * np.sum((np.abs(y_true - y_pred) \/ ((np.abs(y_true) + np.abs(y_pred)) \/ 2)))","56522797":"weights = dev_df.groupby(['country', 'store', 'product'])['row_id'].transform(lambda x: np.arange(1, len(x) + 1)[::-1])\nweights = np.exp(-0.007 * weights)","beffbf2b":"weights.plot();","53c3e1a8":"%%time\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=500, min_samples_leaf=30, max_features=0.9, n_jobs=-1)\nmodel.fit(X_train, y_train, sample_weight=weights)","d7ea825e":"if not SUB: print_scores(model, X_train, y_train, X_val, y_val, SMAPE_score)","882219bd":"ft_imp = pd.DataFrame({'features': X_train.columns, \n              'score': model.feature_importances_}).sort_values('score', ascending=False)","a0dcb8f9":"ft_imp.plot(x='features', y='score', kind='barh', figsize=(15, 10));","b834b493":"# model = RandomForestRegressor(n_estimators=500, min_samples_leaf=20, n_jobs=-1)\n\n# ft_keep = ft_imp.query('score > 0.01').features\n\n# model.fit(X_train[ft_keep], y_train)\n# if not SUB: print_scores(model, X_train[ft_keep], y_train, X_val[ft_keep], y_val, SMAPE_score)","460ece9f":"# model = RandomForestRegressor(n_estimators=500, min_samples_leaf=15, n_jobs=-1)\n\n# ft_keep = ft_imp.query('score > 0.01').features\n\n# model.fit(X_train[ft_keep], y_train)\n# print_scores(model, X_train[ft_keep], y_train, X_val[ft_keep], y_val, SMAPE_score)","75049372":"model = RandomForestRegressor(n_estimators=2000, min_samples_leaf=30, n_jobs=-1)\n\nft_keep = ft_imp.query('score > 0.01').features\n\nmodel.fit(X_train[ft_keep], y_train, sample_weight=weights)\nif not SUB: print_scores(model, X_train[ft_keep], y_train, X_val[ft_keep], y_val, SMAPE_score)","edea0d5c":"# ft_imp2 = pd.DataFrame({'features': X_train[ft_keep].columns, \n#               'score': model.feature_importances_}).sort_values('score', ascending=False)","d9c1d580":"# ft_imp2.plot(x='features', y='score', kind='barh', figsize=(15, 10));","0c9391ed":"test_df = add_datepart(test_df, 'date')","5f02a189":"for i, record in enumerate(test_df[['country', 'store', 'product', 'year', 'month']].to_records(index=False)):\n    record[-2] -= 1\n    \n    if record[-2] >= 2015:\n        # Add last year's monthly records\n        for m in range(1, 13):\n            record[-1] = m\n            tuple_record = tuple(record)\n            test_df.loc[i, f'total_last_year_{m}_sales'] = total_month_sales[tuple_record]\n            test_df.loc[i, f'mean_last_year_{m}_sales'] = mean_month_sales[tuple_record]\n            test_df.loc[i, f'max_last_year_{m}_sales'] = max_month_sales[tuple_record]\n            test_df.loc[i, f'min_last_year_{m}_sales'] = min_month_sales[tuple_record] ","3a3d973a":"# for col in test_df.columns:\n#     if train_df[col].isna().any():\n#         test_df.loc[:, f'{col}_na'] = test_df[col].isna().astype(int)\n\ntest_df = test_df.fillna(0)","da806bac":"X_test, _ = preprocess_dataset(test_df, encoders)\nX_test.head()","5144cd3f":"# X_test.shape[1] == X_train.shape[1]","88b8a76b":"submission['num_sold'] = model.predict(X_test[ft_keep])\nsubmission.head()","d2ec4117":"submission.to_csv('submission.csv', index=False)","611e5a49":"# import itertools\n\n# countries = X_train.country.unique()\n# stores = X_train.store.unique()\n# products = X_train['product'].unique()\n\n# combinations = list(itertools.product(countries, stores, products))\n\n# preds = {}\n\n# for comb in combinations:\n#     y_train_avg = y_train[\n#         (X_train['country'] == comb[0]) & \n#         (X_train['store'] == comb[1]) & \n#         (X_train['product'] == comb[2])\n# #         (X_train['Month'] == 12)\n#     ].values[-500:].mean()\n# #     print(y_train_avg); break\n    \n#     preds[comb] = y_train_avg\n    ","1cb2e9d8":"# preds_val = []\n\n# for row in X_val[['country', 'store', 'product']].values:\n#     preds_val.append(preds[tuple(row)])\n    \n# preds_val = np.array(preds_val)","ebffe8a8":"### The model has improved.","66a84219":"### Drop features below 0.01 importance","80cfb78c":"### Features I think can improve predictions:\n1. Sales last year today\n2. Total sales last year\n3. Min sales last year\n4. Max sales last year\n5. Average sales last year\n6. Average quarter sales last year\n7. Average monthly sales last year\n\n### I think playing on those features can improve the model performance in addition to using the features of different products with each other.","99f4099b":"## Submission"}}