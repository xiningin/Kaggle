{"cell_type":{"132f3e59":"code","04ce7352":"code","f70d3e06":"code","39a58432":"code","bcdf6fc5":"code","50caa8a1":"code","01539022":"code","4798b0df":"code","12ebc0b7":"code","c6a7b649":"code","49dfabe3":"code","3a674ea7":"code","309a5e1f":"code","39da62c0":"code","06e203a1":"code","5b11a317":"code","63684b30":"code","2e1a35a7":"code","9b7fa0f6":"code","7d2c94ff":"code","437f4913":"code","ea9829ab":"code","471ab254":"code","3ab54bc6":"code","d3e8f4f5":"code","e79f6013":"code","6bd9cc79":"code","bee53448":"code","f5ad04ba":"markdown","53a811b3":"markdown"},"source":{"132f3e59":"import pandas as pd \nimport numpy as np\nimport xgboost as xgb\nimport matplotlib.pyplot as plt","04ce7352":"train_dataset = pd.read_csv(\"..\/input\/train.csv\")\ntest_dataset = pd.read_csv(\"..\/input\/test.csv\")","f70d3e06":"train_dataset.head()","39a58432":"train_dataset.shape # 1460x81","bcdf6fc5":"test_dataset.drop_duplicates().shape # no duplicates","50caa8a1":"train_dataset.columns","01539022":"print(set(train_dataset.columns) - set(test_dataset.columns))\n# we need to split SalePrice","4798b0df":"train_Y = train_dataset[\"SalePrice\"]\ntrain_dataset = train_dataset.drop([\"SalePrice\"], axis=1) ","12ebc0b7":"# There is also no need of Id column\ntrain_dataset = train_dataset.drop([\"Id\"], axis=1)\ntest_dataset = test_dataset.drop([\"Id\"], axis=1)","c6a7b649":"# Next step: to combine these two datasets for processing\ndataset = pd.concat([train_dataset, test_dataset])\ndataset.shape","49dfabe3":"# function-helper for getting null columns\ndef getNullsOf(dataframe):\n    df = dataframe.isnull().sum().sort_values(ascending=False)\n    df = df[df > 0] # keeping values that > 0\n    return df","3a674ea7":"null_cols = getNullsOf(dataset)\n# we'll remove all cols with more than 50% null. Because there are cannot be helpful due to missing majority of data\n(null_cols\/len(dataset) * 100)","309a5e1f":"# we'll drop these values:\nto_drop = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"]\ndataset = dataset.drop(to_drop, axis=1) \n# we droped 4 unnecessary columns\ndataset.shape","39da62c0":"numeric_cells = dataset._get_numeric_data()\ngetNullsOf(numeric_cells)","06e203a1":"# filling numeric columns with mean() data\nprint(\"Before:\\n\", dataset[\"LotFrontage\"].head(20))\ndef fillWithMean(name):\n    numeric_cells[name] = numeric_cells[name].fillna(numeric_cells[name].mean())\n    dataset[name] = numeric_cells[name]\nfor name in getNullsOf(numeric_cells).index.tolist():\n    fillWithMean(name)\nprint(\"After:\\n\", dataset[\"LotFrontage\"].head(20))","5b11a317":"# categorical cells\ncategorical_cells = list(set(dataset.columns) - set(numeric_cells.columns))\ncategorical_cells[:5] #printing first 5 categorical columns","63684b30":"categorical_df = dataset[categorical_cells] # dataframe of cat. values\nnull_cat_cells = getNullsOf(categorical_df)\nnull_cat_cells","2e1a35a7":"null_cat_cells = null_cat_cells.index.tolist()\ndataset[null_cat_cells].describe()\n# here we can see top values with which we'll replace nulls","9b7fa0f6":"for cell in null_cat_cells:\n    dataset[cell] = dataset[cell].fillna(dataset[cell].mode()[0])","7d2c94ff":"getNullsOf(dataset) # all data is cleaned!","437f4913":"train_dataset = dataset.iloc[:train_dataset.shape[0], :]\ntest_dataset = dataset.iloc[train_dataset.shape[0]:, :]","ea9829ab":"print(train_dataset.shape, test_dataset.shape)","471ab254":"train_Y.describe()","3ab54bc6":"train_Y.plot(kind=\"hist\")\nplt.show()","d3e8f4f5":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()","e79f6013":"for category in categorical_cells:\n    train_dataset[category] = encoder.fit_transform(train_dataset[category])\ntrain_dataset.head()","6bd9cc79":"xgb_regressor = xgb.XGBRegressor()\nxgb_regressor.fit(train_dataset,  train_Y)","bee53448":"from sklearn.metrics import mean_squared_error\ny_pred = xgb_regressor.predict(train_dataset)\nnp.sqrt(mean_squared_error(train_Y, y_pred))","f5ad04ba":"### Let's make a preprocessing of dataset\n#### Firstly, we should drop unnecessary columns\n#### Next, we should fill numerical nulls with mean values\n#### After that we should care about categorical data","53a811b3":"### Training the model\n#### 1) we should split dataset\n#### 2) train our model\n#### 3) get the result!"}}