{"cell_type":{"5e55a953":"code","3b6762b6":"code","69b373e9":"code","d3ececc2":"code","0cc42b52":"code","e91d9b73":"code","1ba01a73":"code","045273ea":"code","e1e57b38":"code","ea6a7b10":"code","633d8820":"code","f2b8bb34":"code","3eec0408":"code","4ab6b0d4":"code","a3f5b09f":"code","795535b1":"code","5b2bd4d3":"code","dd69e2ff":"code","c6d46be4":"code","eb3ac9eb":"code","e48f8b69":"markdown"},"source":{"5e55a953":"import os\nimport numpy as np\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom math import floor\nimport pandas as pd \nimport cv2\nimport matplotlib.gridspec as gridspec\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as layers\n\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom numpy.random import randn\n\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\n\n","3b6762b6":"BATCH_SIZE=2","69b373e9":"GCS_PATH=KaggleDatasets().get_gcs_path()\n\nmonet_filenames=tf.io.gfile.glob(str(GCS_PATH+'\/monet_tfrec\/*.tfrec'))\nphoto_filenames=tf.io.gfile.glob(str(GCS_PATH + '\/photo_tfrec\/*.tfrec'))\n\nprint('monet_filenames',len(monet_filenames))\nprint('photo_filenames',len(photo_filenames))\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE \nprint(tf.__version__)\n\n\n\nimage_size=[256,256]\ndef decode_img(img):\n    img=tf.image.decode_image(img,channels=3)\n    img=(tf.cast(img,tf.float32)\/127.5)-1\n    img=tf.reshape(img,[*image_size,3])\n    return img\n\n\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_img(example['image'])\n    return image\n\ndef load_dataset(filenames,labeled=True,ordered=False):\n    dataset=tf.data.TFRecordDataset(filenames)\n    dataset=dataset.map(read_tfrecord,num_parallel_calls=AUTOTUNE)\n    return dataset\n\n\nmonet_ds=load_dataset(monet_filenames,labeled=True).batch(BATCH_SIZE)\nphoto_ds=load_dataset(photo_filenames,labeled=True).batch(BATCH_SIZE)\n\n\n\n\n\n\n\n\n","d3ececc2":"\ndef Plot(arr1,arr2,flag):\n\n    arr1=next(iter(arr1))\n    arr1 = (arr1 + 1) \/ 2.0\n    fig, axes = plt.subplots(2, 2)\n    fig.set_size_inches(10,6)\n    count = 0\n   \n    for j in range(2):\n            axes[0, j].imshow(arr1[count])\n            axes[0, j].axis('off')\n            count += 1\n\n    if flag==True:    \n        arr2=next(iter(arr2))\n        arr2 = (arr2 + 1) \/ 2.0\n    count = 0\n    for i in range(2):\n       \n            axes[1, i].imshow(arr2[count])\n            axes[1, i].axis('off')\n            count += 1\n\n    plt.tight_layout() \n    plt.show()\n    \n","0cc42b52":"Plot(monet_ds,photo_ds,True)","e91d9b73":"Plot(monet_ds,photo_ds,True)","1ba01a73":"def Generator():\n  \n    inputs = layers.Input(shape=[256,256,3,])\n    \n    init= RandomNormal(mean=0.0, stddev=0.02)\n    gamma_init =keras.initializers.RandomNormal(mean=0.0, stddev=0.02)    \n    \n    conv1 = layers.Conv2D(32,4,strides=2,padding='same',kernel_initializer=init)(inputs)\n    conv1=layers.BatchNormalization(gamma_initializer=gamma_init)(conv1)\n    #conv1=layers.Dropout(0.5)(conv1)\n    conv1=layers.LeakyReLU()(conv1)\n    \n    \n    conv2 = layers.Conv2D(64,4,strides=2,padding='same',kernel_initializer=init)(conv1)\n    conv2=layers.BatchNormalization(gamma_initializer=gamma_init)(conv2)\n   # conv2=layers.Dropout(0.5)(conv2)\n    conv2=layers.LeakyReLU()(conv2)\n   \n    \n    conv3 = layers.Conv2D(128,4,strides=2,padding='same',kernel_initializer=init)(conv2)\n    conv3=layers.BatchNormalization(gamma_initializer=gamma_init)(conv3)\n   # conv3=layers.Dropout(0.5)(conv3)\n    conv3=layers.LeakyReLU()(conv3)\n\n    \n    conv4 = layers.Conv2D(256,4,strides=2,padding='same',kernel_initializer=init)(conv3)\n    conv4=layers.BatchNormalization(gamma_initializer=gamma_init)(conv4)\n   # conv4=layers.Dropout(0.5)(conv4)\n    conv4=layers.LeakyReLU()(conv4)\n  \n    \n    \n    conv5 = layers.Conv2D(512,4,strides=2,padding='same',kernel_initializer=init)(conv4)\n    conv5=layers.BatchNormalization(gamma_initializer=gamma_init)(conv5)\n    #conv5=layers.Dropout(0.5)(conv5)\n    conv5=layers.LeakyReLU()(conv5)\n    \n    \n     \n    up1 = layers.Conv2DTranspose(256,4,strides=(2,2),padding='same',kernel_initializer=init)(conv5)\n    up1=layers.BatchNormalization(gamma_initializer=gamma_init)(up1)\n    #up1=layers.Dropout(0.5)(up1)\n    up1=layers.LeakyReLU()(up1)\n    merge1 = layers.concatenate([up1, conv4], axis=3) \n    \n\n    \n    up2 = layers.Conv2DTranspose(128,4,strides=(2,2),padding='same',kernel_initializer=init)(merge1)\n    up2=layers.BatchNormalization(gamma_initializer=gamma_init)(up2)\n    #up2=layers.Dropout(0.5)(up2)\n    up2=layers.LeakyReLU()(up2)\n    merge2 = layers.concatenate([up2, conv3], axis=3) \n    \n\n\n    up3 = layers.Conv2DTranspose(64,4,strides=(2,2),padding='same',kernel_initializer=init)(merge2)\n    up3=layers.BatchNormalization(gamma_initializer=gamma_init)(up3)\n    up3=layers.Dropout(0.5)(up3)\n    up3=layers.LeakyReLU()(up3)\n    merge3 = layers.concatenate([up3, conv2], axis=3) \n   \n\n   \n    \n    up4 = layers.Conv2DTranspose(32,4,strides=(2,2),padding='same',kernel_initializer=init)(merge3)\n    up4=layers.BatchNormalization(gamma_initializer=gamma_init)(up4)\n    up4=layers.Dropout(0.5)(up4)\n    up4=layers.LeakyReLU()(up4)\n    merge4 = layers.concatenate([up4, conv1], axis=3) \n    \n   \n \n    x = layers.Conv2DTranspose(3, 4, strides=(2,2),activation = 'tanh', padding = 'same')(merge4)  # tanh to get values between 1 and -1 same as monet images\n\n    generator = keras.Model(inputs=inputs, outputs=x)\n\n    generator.summary()\n\n    return generator","045273ea":"def Discrimnator():\n    discriminator_input = layers.Input(shape=[256, 256, 3], name='input_image')\n    init= RandomNormal(mean=0.0, stddev=0.02)\n    \n    x = layers.Conv2D(64, 4,kernel_initializer=init)(discriminator_input)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(0.2)(x)\n  \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n  \n    x = layers.Flatten()(x)\n  \n    x = layers.Dense(1, activation = 'sigmoid')(x)\n  \n    discriminator = keras.models.Model(discriminator_input, x)\n    discriminator.summary()\n\n    return discriminator\n","e1e57b38":"generator=Generator()\ndiscriminator=Discrimnator()","ea6a7b10":"intial=generator(next(iter(photo_ds)),training=False)\nPlot(photo_ds,intial,False)","633d8820":"class GAN(keras.Model):\n    \n    def __init__(self, gen, disc):\n        super().__init__()\n        self.gen = gen\n        self.disc= disc\n\n    def compile(self,gen_optimizer,disc_optimizer,gen_loss_fn,disc_loss_fn):\n        super().compile()\n        self.gen_optimizer = gen_optimizer\n        self.disc_optimizer = disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n       \n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n       \n            generated_images = self.gen(real_photo, training=True)\n            \n            real_output = self.disc(real_monet, training=True)\n            fake_output = self.disc(generated_images, training=True)\n            \n            gen_loss = self.gen_loss_fn(fake_output)\n            disc_loss =self.disc_loss_fn(real_output,fake_output)\n            \n       \n        generator_gradients = tape.gradient(gen_loss,self.gen.trainable_variables)\n        discriminator_gradients = tape.gradient(disc_loss,self.disc.trainable_variables)\n        \n        self.gen_optimizer.apply_gradients(zip(generator_gradients, self.gen.trainable_variables))\n        self.disc_optimizer.apply_gradients(zip(discriminator_gradients,self.disc.trainable_variables))\n\n        \n        return {\n            \"gen_loss\": gen_loss,\n            \"disc_loss\":disc_loss\n        }\n\n\n\n\n","f2b8bb34":"generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#generator.compile(optimizer = generator_optimizer, loss = 'categorical_crossentropy')\n\ndiscriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#discriminator.compile(optimizer = discriminator_optimizer,loss='binary_crossentropy')\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","3eec0408":"def Get_Noise_Batch():\n    random_latent_vectors = randn(latent_dim * batch_size)\n    # update to have the range [-1, 1]\n    random_latent_vectors = -1 + random_latent_vectors * 2\n    random_latent_vectors = random_latent_vectors.reshape((batch_size, latent_dim))\n    \n    return random_latent_vectors","4ab6b0d4":"def Get_True_Batch(idx):\n    real_images=original[idx:idx+batch_size]\n    return real_images","a3f5b09f":"def G_loss(fake_output):\n     return cross_entropy(tf.ones_like(fake_output), fake_output)","795535b1":"def D_loss(real_output,fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    return real_loss+fake_loss","5b2bd4d3":"model = GAN(generator,discriminator)\nmodel.compile(generator_optimizer,discriminator_optimizer,G_loss,D_loss)\n","dd69e2ff":"model.fit(tf.data.Dataset.zip((monet_ds, photo_ds)),epochs=60)\n\n\n","c6d46be4":"perd=generator(next(iter(photo_ds)),training=False)\nPlot(photo_ds,perd,False)  ","eb3ac9eb":"import PIL\n! mkdir ..\/images\ni = 1\n\nfor img in photo_ds:\n    prediction = generator(img, training=False).numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    \n    im = PIL.Image.fromarray(prediction[0])\n    im.save(\"..\/images\/\" + str(i) + \".jpg\")\n    i += 1\n    im = PIL.Image.fromarray(prediction[1])\n    im.save(\"..\/images\/\" + str(i) + \".jpg\")\n    i += 1\n    \nimport shutil\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","e48f8b69":"0. Importing Necessary libraries :"}}