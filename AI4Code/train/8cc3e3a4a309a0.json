{"cell_type":{"f508e2b7":"code","b5137598":"code","1aa21940":"code","0e8e44cc":"code","04b50be5":"code","598a1c71":"code","d481bbf9":"code","b7965729":"code","00e3191e":"code","e332b2c3":"code","51bb9cf0":"code","b6a4a22e":"code","7e658c6a":"code","71d533d8":"code","b4cf4237":"code","46c0d764":"code","51f8cc2a":"code","8dd780d7":"code","7665c982":"code","75602719":"code","aafce88f":"code","3b86147b":"code","c2b76afd":"code","776093b8":"code","5570f052":"code","57cf6398":"code","c8381d03":"code","c2ee1af5":"code","b84aac40":"code","7bc416e5":"code","5cf99727":"code","19ed1f5d":"code","bd0906ea":"code","81b96a0e":"code","48601c0e":"code","b5a4d6ac":"code","abafc5f4":"markdown","ef46585a":"markdown","1517fc5a":"markdown"},"source":{"f508e2b7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","b5137598":"data_orig = pd.read_csv(\"..\/input\/data-mining-assignment-2\/train.csv\", sep=',')\ndata = data_orig","1aa21940":"data.head()","0e8e44cc":"data.info()","04b50be5":"#CHECKING FOR DUPLCATE COLMNS\ndata.duplicated().sum()","598a1c71":"#CHECKING FOR NULL COLMNS\nnull_columns = data.columns[data.isnull().any()]\nnull_columns","d481bbf9":"import seaborn as sns\nf, ax = plt.subplots(figsize=(30, 24))\ncorr = data.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax, annot = True);","b7965729":"#DROPPING ID COLMN\ndata = data.drop(['ID'], axis = 1)","00e3191e":"data.head()","e332b2c3":"#FINDING OUT THE OBJECT COLMNS\nobj_cols=data.columns[data.dtypes=='object']\nobj_cols=np.array(obj_cols)\nobj_cols","51bb9cf0":"#SEARCHING FOR UNIQUE VALUES IN EACH OF THE OBJECT COLMNS\ncol_nos=[2,11,37,44,56]\nfor i in col_nos:\n  print(str(i)+\":\"+str(data[\"col\"+str(i)].unique()))","b6a4a22e":"#DROP ALL THE OBJECT COLUMNS\ndata2=data.drop(['col2','col11','col37','col44','col56'],axis=1)\n#data2=pd.get_dummies(data2, columns=[\"Col189\"]) #for one hot encoding\ndata2.head()","7e658c6a":"data2.info()","71d533d8":"#SEPERATING X AND Y AND DROPPING Class COLMN\ny=data2['Class']\nX=data2.drop(['Class'],axis=1)\nX.head()","b4cf4237":"#NORMALIZATION\n\nfrom sklearn import preprocessing\n#Performing Min_Max Normalization\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\nX_N = pd.DataFrame(np_scaled) #new dataframe is made\nX_N.head()","46c0d764":"#SPLITTING THE TRAIN AND TEST\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_N, y, test_size=0.20, random_state=42)","51f8cc2a":"np.random.seed(42)","8dd780d7":"from sklearn.ensemble import RandomForestClassifier\n\nscore_train_RF = []\nscore_test_RF = []\n\nfor i in range(5,20,1):\n    rf = RandomForestClassifier(n_estimators = 100, max_depth=i)\n    rf.fit(X_train, y_train)\n    sc_train = rf.score(X_train,y_train)\n    score_train_RF.append(sc_train)\n    sc_test = rf.score(X_test,y_test)\n    score_test_RF.append(sc_test)","7665c982":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(5,20,1),score_train_RF,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(5,20,1),score_test_RF,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score,test_score],[\"Train Score\",\"Test Score\"])\nplt.title('Fig4. Score vs. No. of Trees')\nplt.xlabel('max_depth')\nplt.ylabel('Score')","75602719":"from sklearn.utils.class_weight import compute_class_weight\ncw=compute_class_weight(\"balanced\",[0,1,2,3],y)\nprint(cw)","aafce88f":"wt_dict={0:0.77777778,1:3.80434783,2:0.79545455,3:0.83732057}\nrf = RandomForestClassifier(n_estimators=1000, max_depth = 11,class_weight=wt_dict)\nrf.fit(X_train, y_train)\nrf.score(X_test,y_test)","3b86147b":"rf.fit(X_train, y_train)\nrf.score(X_test,y_test)","c2b76afd":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\ny_pred_RF = rf.predict(X_test)\nconfusion_matrix(y_test, y_pred_RF)","776093b8":"print(classification_report(y_test, y_pred_RF))","5570f052":"#READING THE TEST DATAFRAME WHICH HAS NO CLASS LABELS\ntest_orig = pd.read_csv(\"..\/input\/data-mining-assignment-2\/test.csv\", sep=',')\ndata_test = test_orig","57cf6398":"data_test.head()","c8381d03":"data_test.info()","c2ee1af5":"#CHECKING FOR DUPLCATE COLMNS\nprint('duplicate rows',data_test.duplicated().sum())\n\n#CHECKING FOR NULL COLMNS\nnull_columns = data.columns[data.isnull().any()]\nprint('# of null colmns',null_columns)\n\n#DROPPING ID COLMN and ALSO MAKING THE FINAL TO BE SUBMITTED DATAFRAME\ndf_final=pd.DataFrame()\ndf_final['ID']=data_test['ID']\nmy_data_test = data_test.drop(['ID'], axis = 1)\n\n#DROP ALL THE OBJECT COLUMNS\ndata2_test=my_data_test.drop(['col2','col11','col37','col44','col56'],axis=1)\n#data2=pd.get_dummies(data2, columns=[\"Col189\"]) #for one hot encoding\n\n#NAMING IT AS X_unseen\nX_unseen=data2_test\n\n#NORMALIZATION\n\nfrom sklearn import preprocessing\n#Performing Min_Max Normalization\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X_unseen)\nX_unseen_N = pd.DataFrame(np_scaled) #new dataframe is made\n","b84aac40":"X_unseen_N.head()","7bc416e5":"X_unseen_N.info()","5cf99727":"y_pred=rf.predict(X_unseen_N)","19ed1f5d":"y_pred.shape","bd0906ea":"df_final['Class']=y_pred","81b96a0e":"df_final.tail()","48601c0e":"# df_final.to_csv('sub33.csv',index=False)","b5a4d6ac":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(df_final)","abafc5f4":"TESTING STARTED","ef46585a":"**RANDOM FOREST**","1517fc5a":"REPORT"}}