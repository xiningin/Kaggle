{"cell_type":{"2697f115":"code","f9f0dd32":"code","fac8f8bc":"code","7723f9e0":"code","2ce95eb0":"code","a44eeb99":"code","2a19746e":"code","6ca43c9c":"code","bd9f490d":"code","134a1dca":"code","6f3ae7ac":"code","e5b9b951":"code","0d2ca87f":"code","0410acd4":"code","c24fc3f6":"code","640e0404":"code","4ad3c377":"code","96c6f4a8":"code","7b5abadf":"code","fe72f3c2":"code","03918dd3":"code","52918359":"code","59a3a937":"code","176c8187":"code","c4cee1f1":"code","9fcf0039":"code","505edaae":"code","bdf64614":"code","3cb11625":"code","4c20eb5f":"code","dd835ffd":"code","b482e6f9":"code","083dc6ae":"code","85fb4b60":"code","720f3580":"code","cd6630a5":"code","65a82559":"code","7c10d153":"code","d1ccee7a":"code","3c8ecd60":"code","465ba7e4":"code","3e928102":"code","43a3ee84":"code","f45828d1":"code","5c08d963":"code","4890ce3c":"code","f0ab711d":"code","b130d248":"code","3a8a0991":"code","9398a4fa":"code","174e4e60":"code","c132649e":"code","7d7359e1":"code","047ed5ef":"code","a6d39ef8":"code","b1ac06a8":"code","b3331203":"code","2bb01148":"code","e2594857":"code","43f5e1da":"code","1b205ba2":"code","c3b2e7f8":"code","ca8b0e36":"code","7ed61066":"code","4cfa603f":"code","1f0ddd82":"code","0c5cb8f5":"code","71c739c7":"code","d457b5b3":"code","5f5759d8":"code","da108262":"code","88e6943a":"code","bcbb34f8":"code","92da2812":"code","f945635b":"markdown","787e2697":"markdown","82095a1e":"markdown","c7993827":"markdown","1c87e824":"markdown","430742fc":"markdown","bad6175a":"markdown","1dd6d172":"markdown","acd368f1":"markdown","4633a292":"markdown","d27f4c07":"markdown","f7eaa082":"markdown","2f2a6047":"markdown","0a694f16":"markdown","b0086511":"markdown","6f4dd4a5":"markdown","3c53fe1e":"markdown","affe2c6a":"markdown","fae12c4a":"markdown","93162292":"markdown","d2b5fd35":"markdown","c523e1c4":"markdown","c0e94054":"markdown","c4362d14":"markdown","e4b1eed7":"markdown","e6695636":"markdown","4ea1c7d2":"markdown","4f8ddff9":"markdown","9976dcd7":"markdown","6a2b893c":"markdown","92bbc82e":"markdown","10bf9fab":"markdown","5ac42797":"markdown","5f1da40a":"markdown","255ee9fd":"markdown","d2c4b889":"markdown","60dde9fe":"markdown","d23494ca":"markdown","8d6470cf":"markdown"},"source":{"2697f115":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f9f0dd32":"adverse_reactions = pd.read_csv('\/kaggle\/input\/patientstreatmentdatasets\/adverse_reactions.csv')\npatients = pd.read_csv('\/kaggle\/input\/patientstreatmentdatasets\/patients.csv')\ntreatments_cut = pd.read_csv('\/kaggle\/input\/patientstreatmentdatasets\/treatments_cut.csv')\ntreatments = pd.read_csv('\/kaggle\/input\/patientstreatmentdatasets\/treatments.csv')","fac8f8bc":"adverse_reactions.head(10)","7723f9e0":"print(patients.shape)\nprint(treatments.shape)\nprint(adverse_reactions.shape)","2ce95eb0":"adverse_reactions.info()","a44eeb99":"patients.info()","2a19746e":"treatments.info()","6ca43c9c":"adverse_reactions","bd9f490d":"## Checking duplicated values into the four dataframes\n\nadverse_reactions.duplicated().sum()","134a1dca":"patients.duplicated().sum()","6f3ae7ac":"treatments_cut.duplicated().sum()","e5b9b951":"treatments.duplicated().sum()","0d2ca87f":"treatments[treatments.duplicated()]","0410acd4":"patients.sample(5)","c24fc3f6":"patients[patients['address'].duplicated()]","640e0404":"patients[patients['address'].isnull()]","4ad3c377":"# Creating copies\n\npatients_copy=patients.copy()\ntreatments_copy=treatments.copy()\nadverse_copy=adverse_reactions.copy()\ntreatments_cut_copy = treatments_cut.copy()","96c6f4a8":"patients_copy[patients_copy['address'].isnull()]","7b5abadf":"patients_copy.describe()","fe72f3c2":"patients_copy.info()","03918dd3":"patients_copy[patients_copy['contact'].isnull()]","52918359":"patients_copy['country'].isnull().sum()","59a3a937":"patients_copy['address'].isnull().sum()","176c8187":"## dropping the Nan values from the dataset\n\n\npatients_copy = patients_copy.dropna(axis=0, how='any', inplace=False)","c4cee1f1":"patients_copy","9fcf0039":"patients_copy.shape","505edaae":"patients_copy.duplicated().sum()","bdf64614":"patients_copy[patients_copy['address'].duplicated()]","3cb11625":"patients_copy[patients_copy['contact'].duplicated()]","4c20eb5f":"df = patients_copy.copy()","dd835ffd":"patients_copy[patients_copy['contact'].duplicated()]","b482e6f9":"drop_indices=[]\nfor i in range(0,8):\n    index_val=patients_copy[patients_copy['contact'].duplicated()].index[i]\n    drop_indices.append(index_val)\npatients_copy=patients_copy.drop(drop_indices,axis=0,inplace=False)","083dc6ae":"patients_copy","85fb4b60":"patients_copy.info()","720f3580":"patients_copy['contact'].duplicated().sum()","cd6630a5":"patients_copy['address'].duplicated().sum()","65a82559":"## removing the duplicated entry\n\ntreatments_copy[treatments_copy.duplicated()]","7c10d153":"treatments_copy = treatments_copy.drop_duplicates()","d1ccee7a":"treatments_copy","3c8ecd60":"treatments_cut_copy","465ba7e4":"dataframes = [treatments_copy,treatments_cut_copy]\n\ntreatments_table = pd.concat(dataframes, axis=0, join='outer', ignore_index=True, keys=None,\n          levels=None, names=None, verify_integrity=False, copy=True)","3e928102":"treatments_table","43a3ee84":"## Define\n\n# Subtract hba1c_start from hba1c_end to get hba1c_change","f45828d1":"## Code\n\n\ntreatments_table['hba1c_change']=treatments_table['hba1c_start']-treatments_table['hba1c_end']","5c08d963":"## Test\n\ntreatments_table['hba1c_change'].isnull().sum()","4890ce3c":"treatments_table.describe()","f0ab711d":"treatments_table.info()","b130d248":"treatments_table","3a8a0991":"treatments_table.given_name","9398a4fa":"import copy\nfor i in range(0,349):\n    treatments_table.given_name[i]=treatments_table.given_name[i].capitalize()\n\ntreatments_table.given_name","174e4e60":"for i in range(0,349):\n    treatments_table.surname[i]=treatments_table.surname[i].capitalize()\n\ntreatments_table.surname","c132649e":"treatments_table","7d7359e1":"df=treatments_table.copy()","047ed5ef":"## Define\n\n# Novodra and Aurolin using the melt function","a6d39ef8":"## Code\n\ntreatments_table=pd.melt(treatments_table, id_vars=['given_name', 'surname', 'hba1c_start', 'hba1c_end', 'hba1c_change'],\n                           var_name='treatment', value_name='dose')","b1ac06a8":"treatments_table=treatments_table[treatments_table['dose']!='-']","b3331203":"treatments_table","2bb01148":"treatments_table['start_of_dose'],treatments_table['end_of_dose']=treatments_table['dose'].str.split('-').str","e2594857":"treatments_table.drop(columns={'dose'}, inplace=True)","43f5e1da":"## Test\n\ntreatments_table","1b205ba2":"df=treatments_table.copy()","c3b2e7f8":"treatments_table['adverse_reaction']=\"No effect\"","ca8b0e36":"treatments_table","7ed61066":"for i in range(0,33):\n    for j in range(0,349):\n        name_train = treatments_table.given_name.iloc[j]\n        name_test = adverse_copy.given_name.iloc[i].capitalize()\n        if name_train==name_test:\n            treatments_table['adverse_reaction'].iloc[j]=adverse_copy.adverse_reaction.iloc[i]\n        else:\n            continue","4cfa603f":"treatments_table","1f0ddd82":"df=treatments_table.copy()","0c5cb8f5":"adverse_copy","71c739c7":"df_copy=patients_copy.copy()","d457b5b3":"df_copy['contact_no']=''\ndf_copy['email']=''","5f5759d8":"df_copy","da108262":"import copy\nimport re\n\nfor i in range(0,df_copy.shape[0]):\n    iso_num = ''\n    pass_phrase=''\n    var1=''\n    var2=''\n    var3=''\n    var4=''\n    var5=''\n    var6=''\n    var_alpha=''\n    var_beta=''\n    var7=''\n    var8=''\n    var_cred=''\n    var_creds=''\n    pass_phrase_alpha=''\n    pass_phrase_beta=''\n    pass_phrase_creds=''\n    df_copy['email'].iloc[i]=[]\n    df_copy['contact_no'].iloc[i]=[]\n    iso_num=df_copy['contact'].iloc[i]\n    elements=['+','1','2','3','4','5','6','7','8','9','0','1 ']\n    elemental_creds=['1','2','3','4','5','6','7','8','9','0']\n    \n    ## str1 = \"MingHsu@armyspy.com+1 (508) 526-3432\"\n\n    if iso_num[0]!='+':\n        count=0\n        for a in range(0,len(iso_num)):\n            if iso_num[a]=='+':\n                count+=1\n\n        ##print(str1.split('e',2))\n\n        ##print(str1.rsplit('e',3))\n        count\n        if count==1:\n            var1,var2=iso_num.split('+',2)\n\n        df_copy['email'].iloc[i]=var1\n        df_copy['contact_no'].iloc[i]=var2\n    if i==(df_copy.shape[0])-1:\n        i=0\n        break\nfor i in range(0,df_copy.shape[0]):\n    iso_num = ''\n    pass_phrase=''\n    var1=''\n    var2=''\n    var3=''\n    var4=''\n    var5=''\n    var6=''\n    var_alpha=''\n    var_beta=''\n    var7=''\n    var8=''\n    var_cred=''\n    var_creds=''\n    pass_phrase_alpha=''\n    pass_phrase_beta=''\n    pass_phrase_creds=''\n    iso_num=df_copy['contact'].iloc[i]\n    elements=['+','1','2','3','4','5','6','7','8','9','0','1 ']\n    elemental_creds=['1','2','3','4','5','6','7','8','9','0']\n        ## iso_num = '+1 (320) 951-719-9170ZoeWellish@superrito.com'\n    if (df_copy['email'].iloc[i]=='')&(df_copy['contact_no'].iloc[i]==''):\n        if iso_num[0]=='+':\n\n            num=''\n            element=''\n\n            ## matcha = re.search(r'(1 ([\\d]+) ([\\d]+)-([\\d]+)-([\\d]+)(\\b)?)', iso_num)\n            match = re.search(r'(([\\d]+)-([\\d]+)-([\\d]+)(\\b)?)', iso_num)\n            if match:\n                pass_phrase=match.group()\n            var3,var4=iso_num.split(pass_phrase,2)\n            df_copy['email'].iloc[i]=var4\n            df_copy['contact_no'].iloc[i]=pass_phrase\n\n            ## print(match.group())\n        if i==(df_copy.shape[0])-1:\n            i=0\n            break\nfor i in range(0,df_copy.shape[0]):\n    iso_num = ''\n    pass_phrase=''\n    var1=''\n    var2=''\n    var3=''\n    var4=''\n    var5=''\n    var6=''\n    var_alpha=''\n    var_beta=''\n    var7=''\n    var8=''\n    var_cred=''\n    var_creds=''\n    pass_phrase_alpha=''\n    pass_phrase_beta=''\n    pass_phrase_creds=''\n    iso_num=df_copy['contact'].iloc[i]\n    elements=['+','1','2','3','4','5','6','7','8','9','0','1 ']\n    elemental_creds=['1','2','3','4','5','6','7','8','9','0']\n\n    ## str2 = \"KarenJakobsen@jourrapide.com1 979 203 0438\"\n    ## buffer=[1,2,3,4,5,6,7,8,9,0]\n    if (df_copy['email'].iloc[i]=='')&(df_copy['contact_no'].iloc[i]==''):\n        if iso_num[0]!='+':\n            count2=0\n\n            for b in range(0,(len(iso_num)-1)):\n                if (iso_num[b]=='1')&(iso_num[b+1]==' '):\n                    count2+=1\n\n            ##print(str1.split('e',2))\n\n            ##print(str1.rsplit('e',3))\n            if count2==1:\n                var5,var6=iso_num.split('1 ',2)\n                df_copy['email'].iloc[i]=var5\n                df_copy['contact_no'].iloc[i]=var6\n        if i==(df_copy.shape[0])-1:\n            i=0\n            break  \n    \nfor i in range(0,df_copy.shape[0]):\n    iso_num = ''\n    pass_phrase=''\n    var1=''\n    var2=''\n    var3=''\n    var4=''\n    var5=''\n    var6=''\n    var_alpha=''\n    var_beta=''\n    var7=''\n    var8=''\n    var_cred=''\n    var_creds=''\n    pass_phrase_alpha=''\n    pass_phrase_beta=''\n    pass_phrase_creds=''\n    iso_num=df_copy['contact'].iloc[i]\n    elements=['+','1','2','3','4','5','6','7','8','9','0','1 ']\n    elemental_creds=['1','2','3','4','5','6','7','8','9','0']\n    if (i==11) & (i==20):\n        continue\n    if (df_copy['email'].iloc[i]=='')&(df_copy['contact_no'].iloc[i]==''):\n        if iso_num[0]!='+':\n            match_zh = re.findall(r'([\\d.-]+)', iso_num)\n            if match_zh=='':\n                match_zh = re.search(r'(([\\d]+)-([\\d]+)-([\\d]+)(\\b)?)', iso_num)\n            elif len(match_zh)==2:\n                if match_zh[1]!='':\n                    pass_phrase_beta=match_zh[1]\n                    var7,var8=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n                elif match_zh[0]!='':\n                    pass_phrase_beta=match_zh[0]\n                    var7,var8=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n            elif len(match_zh)==3:\n                if (len(match_zh[2])==1)&(len(match_zh[1])==1):\n                    pass_phrase_beta=match_zh[0]\n                    var7,var8=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n                elif match_zh[0]!='':\n                    pass_phrase_beta=match_zh[0]\n                    var7,var8,var9=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n            elif len(match_zh)==5:\n                if match_zh[0]=='.':\n                    pass_phrase_beta=match_zh[1]+' '+match_zh[2]+' '+match_zh[3]+' '+match_zh[4]\n                else:\n                    pass_phrase_beta=match_zh[0]+' '+match_zh[1]+' '+match_zh[2]+' '+match_zh[3]\n                var7,var8=iso_num.split(pass_phrase_beta,2)\n                if var7=='':\n                    df_copy['email'].iloc[i]=var8\n                else:\n                    df_copy['email'].iloc[i]=var7\n                df_copy['contact_no'].iloc[i]=pass_phrase_beta\n            elif match_zh[0]=='-':\n                try:\n                    pass_phrase_beta=match_zh[2]+' '+match_zh[3]+' '+match_zh[4]+' '+match_zh[5]\n                    var7,var8=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n                except:\n                    pass_phrase_beta=match_zh[2]\n                    var7,var8=iso_num.split(pass_phrase_beta,2)\n                    if var7=='':\n                        df_copy['email'].iloc[i]=var8\n                    else:\n                        df_copy['email'].iloc[i]=var7\n                    df_copy['contact_no'].iloc[i]=pass_phrase_beta\n                \n            else:\n                if match_zh=='':\n                    match_zh = re.search(r'(([\\d]+)-([\\d]+)-([\\d]+)(\\b)?)', iso_num)\n                    if match_zh:\n                        pass_phrase_beta = match_zh.group()\n                var7,var8=iso_num.split(pass_phrase_beta,2)\n                if var7=='':\n                    df_copy['email'].iloc[i]=var8\n                else:\n                    df_copy['email'].iloc[i]=var7\n                df_copy['contact_no'].iloc[i]=pass_phrase_beta\n                \n            if i==(df_copy.shape[0])-1:\n                i=0\n                break\n    \n        ## iso_num3 = 'VuCamNuong@fleckens.hu516-720-5094'\nfor i in range(0,df_copy.shape[0]):\n    iso_num = ''\n    pass_phrase=''\n    var1=''\n    var2=''\n    var3=''\n    var4=''\n    var5=''\n    var6=''\n    var_alpha=''\n    var_beta=''\n    var7=''\n    var8=''\n    var_cred=''\n    var_creds=''\n    pass_phrase_alpha=''\n    pass_phrase_beta=''\n    pass_phrase_creds=''\n    iso_num=df_copy['contact'].iloc[i]\n    elements=['+','1','2','3','4','5','6','7','8','9','0','1 ']\n    elemental_creds=['1','2','3','4','5','6','7','8','9','0']\n    \n\n    elements=['+','1','2','3','4','5','6','7','8','9','0']\n    if (df_copy['email'].iloc[i]!='')&(df_copy['contact_no'].iloc[i]!=''):\n        count_elements=0\n        for sym in elemental_creds:\n            if iso_num[0]==sym:\n                count_elements+=1\n        try:\n            if count_elements!=0:\n                match_for = re.search(r'(([\\d]+)-([\\d]+)-([\\d]+)(\\b)?)', iso_num)\n                if match_for:\n                    pass_phrase_alpha = match_for.group()\n                var_alpha,var_beta=iso_num.split(pass_phrase_alpha,2)\n                df_copy['email'].iloc[i]=var_beta\n                df_copy['contact_no'].iloc[i]=pass_phrase_alpha\n            if i==(df_copy.shape[0])-1:\n                i=0\n                break\n        except:\n            continue\n","88e6943a":"df_copy.sample(12)","bcbb34f8":"patients_copy=df_copy.copy()","92da2812":"patients_copy.info()","f945635b":"#### Messy data","787e2697":"#### Completeness issues","82095a1e":"So, we can the duplicated row has been removed as the number of rows becomes 279 from 280.","c7993827":"#### When the data has structural issue it is known as Messy or untidy data.","1c87e824":"#### Hence, there is no null value present in the column.","430742fc":"#### 1. Dirty Data\n##### When the data has following kinds of issues:\n- Duplicated data\n- Missing Data\n- Corrupt Data\n- Inaccurate Data\n\n##### This kind of data is known as Dirty data","bad6175a":"- There is no duplicated value present in adverse_reaction dataset.","1dd6d172":"### coping dataset for better resolution and minimize the errors","acd368f1":"### For treatments datasets","4633a292":"### Data Wrangling steps have been executed...\/\/ End of Session","d27f4c07":"### Hence, adverse_reaction and treatment dataframes have been successfully merged to form a new treament table.","f7eaa082":"As, it is a very short dataframe so we can proceed for dropping values as shown below,","2f2a6047":"##### Missing data","0a694f16":"#### After cleaning datasets there exist only two datasets which are 'patients' and 'treatment_table' for working purposes of the next step of Machine Learning.","b0086511":"#### As, the above two dataframes are identical for address and contact columns both.\n#### Hence, we need to drop these values for the respective row indices.","6f4dd4a5":"And, hence, if we drop these values it will affect our results.","3c53fe1e":"\n#### Dirty Data -\n- Hence there is one duplicated value present only into the treaments dataset and no other dataset contains duplicated entry (by an entire column).\n- As we are dealing with the patients'information and hence, we should be very much confident about the patient's address and contact number so that no duplicated entries are made in the corresponding datasets.\n- But while checking, a few duplicated values are being come  from the dataset in case of patient's address field.\n","affe2c6a":"### As, these two columns has no duplicated value. Hence, we can confidently say that the overall procedure of removing duplicate values from the patient dataframe has been complited.","fae12c4a":"Therefore, all null values have been removed from patients dataset.","93162292":"### **Tidiness**\n\n#### **Patients**\n- Phone and email together in one col i.e. contact\n\n#### **Treatments**\n- 3 variables stored in auralin and novodra cols\n\n#### **Adverse Reactions**\n- No point of using this table in case of tidiness issues as it is well defined from the starting.\n","d2b5fd35":"##### Duplicated data","c523e1c4":"#### Here, it is not showing any duplicate values.\n\n#### Let's check for the columns of it also to ensure properly.","c0e94054":"The Corresponding observations for these type of error i.e. the errors related due to messy datas, are to be considered in the Conclusion section and evaluated there by manual approach.","c4362d14":"#### Creating two columns contact_no and email_id and filling the respective columns with its appropriate values subsequently.","e4b1eed7":"#### b. Tidiness Issues\n\n- Phone + email in contact col patients\n- Novodra and Aurolin col treatment\n- Merge the adverse table to treatment table\n\n#### Note - \n- There must be very probably four types of data entries into the contact column of patients dataset as -\n- i. 908-884-4247RenzoLucchese@dayrep.com\t\n- ii. IvonaJaksic@einrot.com+1 (501) 636-4058\t\n- iii. LovreGalic@gustr.com1 813 355 9476\n- iv. CecilieNilsen@superrito.com308-496-7837\n- v. +1 (501) 636-4058IvonaJaksic@einrot.com","e6695636":"#### Removing Nan values and inserting the correct calculations of 'hba1c_change' entirely.","4ea1c7d2":"### Cleaning data","4f8ddff9":"### Importing data","9976dcd7":"Hence, we can from the .describe() and .info() methods that in case of address, zip code, country, and contact columns there are a few values is Nan values and hence we need to drop those values from the dataset because if there is a person is coming for treatment then the system should take his\/her phone number or address or zip_code atleast.","6a2b893c":"## Conclusions","92bbc82e":"## Hence, separation of numbers and email id has been successfully completed for the entire mixing values of 'contact' column of Patients dataset...","10bf9fab":"#### Now we have to merge the two dataset 'treaments' and 'treatments_cut' to form one dataset for patients treatment.","5ac42797":"### Accessing data\n\n#### Types of Unclean Data\n##### There are 2 kinds of unclean data\n- (Data with Quality issues): Dirty data, also known as low quality data. Low quality data has content issues.\n- (Data with tidiness issues): Messy data, also known as untidy data. Untidy data has structural issues.","5f1da40a":"### **Quality**\n\n#### [Completeness, Validity, Accuracy, Consistency]\n\n#### ***Patients***\n- Zip code col is not stored in Integer format-----------------------------------------------[V]\n- Certain zip codes of 4 digits--------------------------------------------------------------[V]\n- For the state col sometimes full names are use and other times short forms are used--------[IC]\n- Missing values for contact details of 12 patients------------------------------------------[C]\n- Incorrect data types for assigned_sex and birthdate cols-----------------------------------[V]\n- Erroneous data for weights and heights-----------------------------------------------------[Accuracy]\n- Inconsistent way of storing phone numbers in contact col-----------------------------------[IC]\n- Duplicate and not useful data in dataset---------------------------------------------------[IC]\n\n#### Notes - \n- We have an tremendous relationship between the address and contact columns of the patients dataset.\n  That if any value is duplicated for any of these two column then the other value will be also duplicated with\n  respect to the row index and hence we sh\n\n#### ***Treatments*****\n- hba1c_change col has missing values--------------------------------------------------------[C]\n- Novodra and Auralin cols has u attached to numbers-----------------------------------------[V]\n- Only 280 rows are there, instead of 350----------------------------------------------------[C]\n- Name and surname col is in lower case------------------------------------------------------[IC]\n- Incorrect data type for auralin and novadra cols-------------------------------------------[V]\n- hba1c_change values has many calculation errors where 9 is written instead of 4------------[Accuracy]\n- use of dashes instead of Nan in aurolin and novodra cols-----------------------------------[IC]\n- There is a duplicated entry at row no 136.-------------------------------------------------[V]\n- There is two dataset for treatment of a patient but it should merged into a single dataset\n  for gathering treatment related informationd of a patient. --------------------------------[IC]\n\n#### *Adverse Reactions*****\n- Name and surname col is in lower case------------------------------------------------------[IC]\n\n#### Note - \n      \n      C --> Completeness Issues\n      V -- Validity Issues\n      A --> Accuracy issues\n      IC --> Incosistent issues","255ee9fd":"##### Tidy data has the following properties:\n- Each variable forms a column\n- Each observation forms a row\n- Each observational unit forms a table\n\n##### If a data violates any one of the above it is known as untidy data\n##### It is generally a mixing type data with different alphanumeric components.","d2c4b889":"### Cleaning data","60dde9fe":"### Removing the duplicated datas","d23494ca":"#### a. Completeness Issues\n\n- Missing values for contact details of 12 patients\n- Only 280 rows are there, instead of 350\n- hba1c_change col has missing values","8d6470cf":"#### Tidiness issues"}}