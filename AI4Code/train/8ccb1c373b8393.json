{"cell_type":{"f88ee43c":"code","c6ddd6b1":"code","367e4a07":"code","f962fefa":"code","95f8026d":"code","0953c5dc":"code","26cdd720":"code","8c319b12":"code","fb15055a":"code","a9bd019f":"code","dd21f7e3":"code","cadd6095":"code","3cf764d5":"code","42174453":"code","5b6890ff":"code","4c4df9c1":"code","015a6e1a":"code","e38850ff":"code","50a6b2f4":"code","676413d4":"code","14d4f1e6":"code","cbf44358":"code","3c77f93d":"code","60f4b15e":"code","c8d3977f":"code","c6bb2da5":"code","25016c23":"code","2caae515":"code","f7189fbe":"code","15e130f0":"code","4dd578e7":"code","e6e43b14":"code","9c426496":"code","020730d5":"code","d1f2ea32":"code","fd6f146f":"code","449e0756":"code","624e8532":"code","1d1c2dc0":"code","fb3f694d":"code","777947f8":"code","665475cd":"code","e64e49ba":"code","44f610fc":"code","82ea247b":"code","0394a0f3":"code","18ca89fe":"code","808152aa":"code","613b4725":"code","81f8790f":"code","93620096":"code","1ed50705":"code","978db19a":"code","ba390e43":"code","53c1347c":"code","f0861a7d":"code","384d9bfb":"code","eed91179":"code","b274384a":"code","e3a26abd":"code","569fa20e":"code","211f3315":"code","7f6a596f":"code","350bca28":"code","891d1d77":"code","266a8a82":"code","8f8fbad6":"code","092a25e3":"code","2ab13f38":"code","a26727ac":"code","613871e9":"code","94be9dbc":"code","61bd63de":"code","18651c97":"code","83ae44cd":"code","688c658c":"code","8a7d4098":"code","c66ec6a4":"markdown","b36dd8ad":"markdown","747354bc":"markdown","1087a90f":"markdown","207d1ff0":"markdown","f9ffac00":"markdown","a113679a":"markdown","87c06f32":"markdown","fcc658d9":"markdown","33683018":"markdown","d0c4e492":"markdown","433b4b1e":"markdown","2c2e4628":"markdown","2d28ef4d":"markdown","0dda083e":"markdown"},"source":{"f88ee43c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c6ddd6b1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","367e4a07":"df=pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ndf.head()","f962fefa":"df.shape","95f8026d":"df['Response'].value_counts()","0953c5dc":"df.columns","26cdd720":"df.info()","8c319b12":"df.isnull().sum().sum() #There are no null values.","fb15055a":"df=df.drop(\"id\",axis=1)","a9bd019f":"df['Driving_License']=df['Driving_License'].astype('object')\ndf['Previously_Insured']=df['Previously_Insured'].astype('object')\ndf['Response']=df['Response'].astype('object')","dd21f7e3":"df_num=df.select_dtypes(exclude='object')\ndf_cat=df.select_dtypes(include='object')","cadd6095":"#Lets see the skewness and distribution of numerical columns\nfor i in df_num.columns:\n    print(i)\n    print(df_num[i].skew())\n    sns.distplot(df_num[i])\n    plt.show()","3cf764d5":"df_cat.columns","42174453":"df_num.columns","5b6890ff":"sns.countplot(df_cat['Response'])\nplt.show() #There is a huge data imbalance","4c4df9c1":"for i in df_cat.columns[0:-1]:\n    sns.countplot(x=df_cat[i],hue=df_cat['Response'])\n    plt.show()","015a6e1a":"for i in df_num.columns:\n    sns.boxplot(x=df_cat['Response'],y=df_num[i])\n    plt.show()  ","e38850ff":"sns.scatterplot(x=df_num['Annual_Premium'],y=df_num['Vintage'],hue=df_cat['Response'])\nplt.show()","50a6b2f4":"sns.boxplot(y=df_num['Age'],hue=df_cat['Vehicle_Damage'],x=df_cat['Response'])\nplt.show()","676413d4":"plt.figure(figsize=[14,10])\nsns.boxplot(x=df_cat['Response'],y=df_num['Annual_Premium'],hue=df_cat['Previously_Insured'])\nplt.show()","14d4f1e6":"#As we observed earlier in EDA that some of the mean values of numerical columns were same so now we can \n#Perfom some statistical test and observe some evidence to drop them.","cbf44358":"from scipy.stats import stats","3c77f93d":"for i in df_num.columns:\n    df_1=df[df['Response']==1][i]\n    df_0=df[df['Response']==0][i]\n    print(i)\n    tsats,pval=stats.ttest_ind(df_1,df_0)\n    print(pval)\n    tstas,pval=stats.mannwhitneyu(df_1,df_0)\n    print(pval)","60f4b15e":"#AS we can see that vintage column is passing both the test so if we take the significance level of 5%\n#the for vintage column we fail to reject h0 which means mean value of vintage days are same hence we \n#can drop the column.","c8d3977f":"#We can drop the columns like regional code and policy sales channel as it will not have any effect\n#on the response of the customer beacause thease values are just the way of communications.","c6bb2da5":"df_num=df_num.drop(['Vintage','Policy_Sales_Channel','Region_Code'],axis=1)","25016c23":"df_cat.columns","2caae515":"df_num.columns","f7189fbe":"from sklearn.preprocessing import PowerTransformer\npt=PowerTransformer()\ndf_num_pt=pt.fit_transform(df_num)\ndf_num_pt=pd.DataFrame(df_num_pt)\ndf_num_pt.columns=df_num.columns\ndf_num_pt.head()","15e130f0":"df_cat=df_cat.drop('Response',axis=1)\ndf_cat_dum=pd.get_dummies(df_cat,columns=list(df_cat.columns),drop_first=True)\ndf_cat_dum.head()","4dd578e7":"X=pd.concat([df_cat_dum,df_num_pt],axis=1)\ny=df['Response']","e6e43b14":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif=pd.DataFrame()\nvif['VIF']=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\nvif['feature']=X.columns\nvif.sort_values('VIF',ascending=False)\n#Multicollinearity is in acceptable range.","9c426496":"y.value_counts() #There is a huge data imbalance so we will have to treat that.","020730d5":"from sklearn.model_selection import train_test_split","d1f2ea32":"y=y.astype('int64')","fd6f146f":"xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.3,stratify=y)","449e0756":"from imblearn.over_sampling import SMOTENC","624e8532":"X.head()","1d1c2dc0":"ytrain.value_counts()","fb3f694d":"smotenc = SMOTENC([0,1,2,3,4,5])\nX_oversample,y_oversample = smotenc.fit_resample(xtrain,ytrain)","777947f8":"y_oversample.value_counts()","665475cd":"X_oversample.tail()","e64e49ba":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()\nlog.fit(X_oversample,y_oversample)","44f610fc":"from sklearn.metrics import  accuracy_score , classification_report , confusion_matrix , plot_roc_curve","82ea247b":"ypred=log.predict(xtest)\nprint(classification_report(ytest,ypred))","0394a0f3":"plot_roc_curve(log , xtest , ytest)\nplt.show()","18ca89fe":"from sklearn.model_selection import KFold,cross_val_score\nkf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(log , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","808152aa":"from sklearn.naive_bayes import GaussianNB\nNB = GaussianNB()\nNB.fit(X_oversample,y_oversample)","613b4725":"ypred=NB.predict(xtest)\nprint(classification_report(ytest,ypred))","81f8790f":"plot_roc_curve(NB , xtest , ytest)\nplt.show()","93620096":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(NB , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","1ed50705":"from sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier()\nKNN.fit(X_oversample,y_oversample)","978db19a":"ypred=KNN.predict(xtest)\nprint(classification_report(ytest,ypred))","ba390e43":"plot_roc_curve(KNN , xtest , ytest)\nplt.show()","53c1347c":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(KNN , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","f0861a7d":"knn_tuned=KNeighborsClassifier(n_neighbors=96,weights='uniform')\nknn_tuned.fit(X_oversample,y_oversample)","384d9bfb":"ypred=knn_tuned.predict(xtest)\nprint(classification_report(ytest,ypred))","eed91179":"plot_roc_curve(knn_tuned , xtest , ytest)\nplt.show()","b274384a":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(knn_tuned , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","e3a26abd":"from sklearn.tree import DecisionTreeClassifier\ndt_tuned = DecisionTreeClassifier(max_depth=110,criterion='entropy')\ndt_tuned.fit(X_oversample,y_oversample)","569fa20e":"ypred=dt_tuned.predict(xtest)\nprint(classification_report(ytest,ypred))","211f3315":"plot_roc_curve(dt_tuned , xtest , ytest)\nplt.show()","7f6a596f":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(dt_tuned , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","350bca28":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=200)\nrf.fit(X_oversample,y_oversample)","891d1d77":"ypred=rf.predict(xtest)\nprint(classification_report(ytest,ypred))","266a8a82":"plot_roc_curve(rf , xtest , ytest)\nplt.show()","8f8fbad6":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(rf , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","092a25e3":"from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nGBoost=GradientBoostingClassifier(n_estimators=100)\nGBoost.fit(X_oversample,y_oversample)","2ab13f38":"ypred=GBoost.predict(xtest)\nprint(classification_report(ytest,ypred))","a26727ac":"plot_roc_curve(GBoost , xtest , ytest)\nplt.show()","613871e9":"kf = KFold(shuffle=True , n_splits=5 , random_state=7)\nscore = cross_val_score(GBoost , X , y , cv=kf , scoring='roc_auc')\nbias1 = np.mean(1-score)\nvariance1 = np.std(score , ddof=1)\nprint(bias1 , variance1)","94be9dbc":"ypred_train = GBoost.predict(xtrain)\nypred_test = GBoost.predict(xtest)","61bd63de":"accuracy_score(ytrain , ypred_train)","18651c97":"accuracy_score(ytest , ypred_test)","83ae44cd":"#If we compare the above results and bias,variance error which has been previously calculated we can\n#say that model is not overfit.","688c658c":"print(confusion_matrix(ytest,ypred_test))","8a7d4098":"ytest.value_counts()","c66ec6a4":"# **Statistical Test**","b36dd8ad":"# **Problem Statement-**\nOur client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.","747354bc":"The mean age of the customer is high who have the history of vehicle damage irrespective of their response for vehicle insurance. ","1087a90f":"Conclusion-\n1. Mean age is higher for those who are interested in vehicle insurance as compare to who are not.\n2. Mean Regional code is same for both response.\n3. Mean annual income is same for both response.\n4. Mean policy channels are different for both response.\n5. Mean vintage days are same for both response.","207d1ff0":"If we want to compare the annual premium with previously insured and their response then we can observe that mean annnual premium is high for those who do not have previous insurance and we can observe that there are customer who already have insurance and they are still interesed in it. Mean annual premium is same for those people who are not interested in vehicle response irrespective of the status of their previous insurance.","f9ffac00":"Conclusion-\n1. Slightly more number of male are interested in having vehicle insurance as compare to female.\n2. Those, who do not have driving license are not interested in vehicle insurance.\n3. There are people who already have vehicle insurance , they are not interested in it.\n4. There are more number of people whose vehicle age is between 1 to 2 years and interested in vehicle\n   insurance.\n5. out of all the people who are interested in vehicle insurance, almost all of them have the history      of vehicle damage.","a113679a":"# **Multicollinearity**","87c06f32":"There is no relationship between vintage days of customer and annual premium. There are very few people who are paying very high premium and the people who are interested in vehicle insurance, there annual premium are low.","fcc658d9":"# **Conclusion-**\n1. As per our problem statement we want to predict the staus of customer wheather they are interested      in vehicle insurance so we need higher recall for that. As we know that Recall is the ratio of TP      and (TP+FN) and we want FN negative to be minimum for the class 1(who are interested in insurance).\n2. So among all the above model built there are 2 models which are giving us the best results. which      are KNN tuned and Gradient Boosting.\n3. We will choose Gradient boosting because its recall score is slightly better than KNN tuned with        slightly increament in Roc Auc Score. ","33683018":"# **Basic Data Cleaning**","d0c4e492":"# **Model Building**","433b4b1e":"As we can see the above results we can say that we are able to predict 70% of the class correctly. our Roc auc score is 85% which means that model is able to distinguish between the negative and positive classes. we can see the confusion metrix that the number of false negatives are very very less which is addressing our problem statement. In test data set there are 14013 customers who are interested in vehicle insurance and out of that 12845 have been classified correctly.","2c2e4628":"# **Evaluation of Final Model**","2d28ef4d":"# **Data Imbalance Treatment using smote NC**","0dda083e":"# **Exploratory Data Analysis**"}}