{"cell_type":{"ee6e8d81":"code","ad85f1c9":"code","4836dc99":"code","11844712":"code","9d68b914":"code","42ccab78":"code","c6d2eaa9":"code","b74311f3":"code","b1b71d41":"code","311f5c50":"code","ec391395":"code","54d43fb4":"code","b2e4e70a":"code","19c39b00":"code","17d7cbb1":"code","71f10453":"code","8d71a65e":"code","79dab2ef":"code","8ee633ac":"code","5a58a148":"code","d1763509":"code","6d3d6a98":"code","aa4b593b":"markdown"},"source":{"ee6e8d81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad85f1c9":"#import necessary libraries\nfrom pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\n\nfrom fancyimpute import KNN\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb","4836dc99":"train=pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")","11844712":"train.drop([\"Unnamed: 0\"],axis=1,inplace=True)\ntest.drop([\"Unnamed: 0\"],axis=1,inplace=True)","9d68b914":"#missingno is library to visulaize missing data\nimport missingno as msno\nmsno.bar(train)","42ccab78":"#PandasProfiling is a very handy tool for EDA\ntrainprofile = ProfileReport(train,'EDA')\ntrainprofile","c6d2eaa9":"import plotly.express as px\nfig = px.histogram(train[['age','gender','diabetes_mellitus','bmi']].dropna(), x=\"age\", y=\"diabetes_mellitus\", color=\"gender\",\n                   marginal=\"box\", hover_data=train[['age','gender','diabetes_mellitus','bmi']].columns)\nfig.show()","b74311f3":"#Seperate categorical and numerical variables\ncattrain=train.select_dtypes('object')\ncattest=test.select_dtypes('object')\nnumtrain=train.select_dtypes('number')\nnumtest=test.select_dtypes('number')","b1b71d41":"#encoding categorical train variables\n\nencoder = OrdinalEncoder()\nimputer = KNN()\n# create a list of categorical columns to iterate over\ncat_cols = cattrain.columns\n\ndef encode(data):\n    '''function to encode non-null data and replace it in the original data'''\n    #retains only non-null values\n    nonulls = np.array(data.dropna())\n    #reshapes the data for encoding\n    impute_reshape = nonulls.reshape(-1,1)\n    #encode data\n    impute_ordinal = encoder.fit_transform(impute_reshape)\n    #Assign back encoded values to non-null values\n    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n    return data\n\n#create a for loop to iterate through each column in the data\nfor columns in cat_cols:\n    encode(cattrain[columns])","311f5c50":"#encoding categorical test variables\n\nencoder = OrdinalEncoder()\nimputer = KNN()\n# create a list of categorical columns to iterate over\ncat_cols = cattest.columns\n\ndef encode(data):\n    '''function to encode non-null data and replace it in the original data'''\n    #retains only non-null values\n    nonulls = np.array(data.dropna())\n    #reshapes the data for encoding\n    impute_reshape = nonulls.reshape(-1,1)\n    #encode data\n    impute_ordinal = encoder.fit_transform(impute_reshape)\n    #Assign back encoded values to non-null values\n    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n    return data\n\n#create a for loop to iterate through each column in the data\nfor columns in cat_cols:\n    encode(cattest[columns])","ec391395":"train1=pd.concat([cattrain,numtrain], axis=1)\ntest1=pd.concat([cattest,numtest], axis=1)","54d43fb4":"#imputing missing values using SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(train1)\ntrainfinal = pd.DataFrame(imputer.transform(train1))","b2e4e70a":"trainfinal.columns=train.columns","19c39b00":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(test1)\ntestfinal = pd.DataFrame(imputer.transform(test1))","17d7cbb1":"testfinal.columns=test.columns","71f10453":"y=trainfinal['diabetes_mellitus']\ntrainfinal.drop(['diabetes_mellitus'], axis=1, inplace=True)","8d71a65e":"# Split into training and validation set\nx_train, x_val, y_train, y_val = train_test_split(trainfinal, y, test_size = 0.25, random_state = 1)","79dab2ef":"#Model building\nd_train = lgb.Dataset(x_train, label=y_train)\nparams = {}\nparams['learning_rate'] = 0.003\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 100\nparams['min_data'] = 50\nparams['max_depth'] = 10\nclf = lgb.train(params, d_train, 100)","8ee633ac":"#Prediction\ny_pred=clf.predict(x_val)\ny_pred1=np.round(y_pred)","5a58a148":"#Prediction on Test variables\npred_on_test=clf.predict(testfinal)","d1763509":"solution = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/SolutionTemplateWiDS2021.csv\")","6d3d6a98":"solution.diabetes_mellitus = pred_on_test\nsolution.to_csv(\"submissionlgbm.csv\", index=0)","aa4b593b":"**In this notebook I have done EDA and model prediction with LightGBM. Minimal feature engineering has been done. This notebook will be further enhanced to add feature engineering and other models for prediction**"}}