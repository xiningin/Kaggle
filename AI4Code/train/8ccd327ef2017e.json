{"cell_type":{"e8c34a3c":"code","110a49bf":"code","f3196d98":"code","a66d3693":"code","fa08ce2d":"code","ae6f5b9f":"code","06b66de3":"code","99f789a2":"code","89ae6c9a":"code","909aeed4":"code","58002afe":"code","002b2c98":"code","d786891d":"code","8e4b7460":"code","e26c2a06":"code","980148b2":"code","1ccbb28c":"code","b453ce2f":"code","ece56cc0":"code","add78141":"code","901e53c8":"code","6b42246e":"code","96a9630e":"code","8e8d85c4":"code","8dd59523":"code","1c7da706":"code","64026a49":"code","89f1803b":"code","ecae3f31":"code","06248fb6":"code","1ec955af":"code","f249a893":"code","2ee16f19":"markdown","2cd87283":"markdown","e3bf4cf2":"markdown","e226fc90":"markdown","56f645ab":"markdown","8f9a2644":"markdown","a9d0a639":"markdown","cea313b4":"markdown","0d39dc2d":"markdown","f00fc538":"markdown","a5f42d4f":"markdown","23278ae9":"markdown","b5777b5a":"markdown"},"source":{"e8c34a3c":"# scientific calculation and data analysis\nimport numpy as np\nimport pandas as pd\n \n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# missingno\nimport missingno\n\n# SKLearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n## Model\nfrom sklearn.naive_bayes import GaussianNB\n\n# NLP\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\n\n# WordCloud\nfrom wordcloud import WordCloud\n\n# basic imports\nimport string","110a49bf":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","f3196d98":"train.head()","a66d3693":"test.head()","fa08ce2d":"# train missing matrix\nmissingno.matrix(train)\nplt.show()","ae6f5b9f":"# test missing matrix\nmissingno.matrix(test)\nplt.show()","06b66de3":"# missing bar plot train\nmissingno.bar(train)\nplt.show()","99f789a2":"# missing bar plot test\nmissingno.bar(test)\nplt.show()","89ae6c9a":"# null count in train and test\nnull_vals = pd.DataFrame(columns=['train', 'test'])\nnull_vals['train'] = train.isnull().sum()\nnull_vals['test'] = test.isnull().sum()\nnull_vals","909aeed4":"# drop location features\ntrain.drop('location', axis=1, inplace=True)","58002afe":"# drop nan rows\ntrain.dropna(axis=0, inplace=True)","002b2c98":"# check missing value in train dataset\ntrain.isnull().sum()","d786891d":"fig, ax = plt.subplots(1,2)\nsns.countplot(x='target', data=train, ax=ax[0])\nax[1].pie(train.target.value_counts(), labels=['Not Real', 'Real'], autopct='%1.1f%%')\nplt.show()","8e4b7460":"# create remove_punctuation functionabs\ndef remove_punctuations(text):\n    return \"\".join([c for c in text if c not in string.punctuation])","e26c2a06":"# Apply to text feature\ntrain['text'] = train['text'].apply(lambda x: remove_punctuations(x))","980148b2":"# create lower_apha_num: convert to lower case and remove numerucal value\ndef lower_alpha_num(text):\n    return [word for word in word_tokenize(text.lower()) if word.isalpha()]","1ccbb28c":"# Apply lower_apha_num\ntrain['text'] = train['text'].apply(lambda x: lower_alpha_num(x))","b453ce2f":"def remove_stopword(text):\n    return [w for w in text if w not in stopwords.words('english')]","ece56cc0":"train['text'] = train['text'].apply(lambda x: remove_stopword(x))","add78141":"train.head()","901e53c8":"# Initiate Lamitizer\nlemmatizer = WordNetLemmatizer()\n\ndef word_lemmatizer(text):\n    lem_text = \" \".join([lemmatizer.lemmatize(i) for i in text])\n    return lem_text","6b42246e":"train['text'] = train['text'].apply(lambda x: word_lemmatizer(x))","96a9630e":"train.head()","8e8d85c4":"X = train['text']\ny = train['target']","8dd59523":"vectorizer_tfidf = TfidfVectorizer()","1c7da706":"X = vectorizer_tfidf.fit_transform(X)","64026a49":"pd.DataFrame(X.A, columns=vectorizer_tfidf.get_feature_names()).head()","89f1803b":"X_train, X_val, y_train, y_val = train_test_split(X.A, y, test_size=0.3)","ecae3f31":"classifier = GaussianNB()","06248fb6":"classifier.fit(X_train, y_train)","1ec955af":"classifier.score(X_train, y_train)","f249a893":"classifier.score(X_val, y_val)","2ee16f19":"### Lemmatizing","2cd87283":"### Missing Value","e3bf4cf2":"Real\/Fake tweets: Let's plot count plot and Pie plot","e226fc90":"## Data Pre-processing","56f645ab":"### TFIDF","8f9a2644":"## Data Cleaning","a9d0a639":"### Train Test Split","cea313b4":"## Imports","0d39dc2d":"## Load Data","f00fc538":"1. Remove punctuations\n2. Lowercase and alphanumeric\n3. Remove stopword","a5f42d4f":"## Exploratory data analysis","23278ae9":"## Model","b5777b5a":" The output shows <b>location<\/b> has many null value and <b>keyword<\/b> are few."}}