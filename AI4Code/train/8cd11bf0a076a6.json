{"cell_type":{"d5c2af96":"code","b477f924":"code","0f104d25":"code","e41b209b":"code","9d8931ce":"code","6d261a74":"code","96fe67f7":"code","511730c3":"code","ed0f3721":"code","3fe3b59f":"code","d2396b1f":"markdown","41328fe9":"markdown","94d49905":"markdown","ab9f7e72":"markdown"},"source":{"d5c2af96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b477f924":"df_train_1 = pd.read_csv('..\/input\/cleaned-toxic-comments\/train_preprocessed.csv')\ndf_test_1 = pd.read_csv('..\/input\/cleaned-toxic-comments\/test_preprocessed.csv')\ndf_train_2 = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')\n# df_test_2 = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')","0f104d25":"df_train_1.sample(3)","e41b209b":"def basic_preprocess(data):\n    data = str(data)\n    data = data.lower()\n    '''\n    Credit goes to https:\/\/www.kaggle.com\/gpreda\/jigsaw-fast-compact-solution\n    '''\n    punct = \"\/-'?!.,#$%\\'()*+-\/:;<=>@[\\\\]^_`{|}~`\" + '\"\"\u201c\u201d\u2019' + '\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014\u2013&'\n    def clean_special_chars(text, punct):        \n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = clean_special_chars(data, punct)\n    return data","9d8931ce":"df_train_1['clean'] = df_train_1['comment_text'].apply(basic_preprocess)\ndf_test_1['clean'] = df_test_1['comment_text'].apply(basic_preprocess)\ndf_train_2['clean'] = df_train_2['comment_text'].apply(basic_preprocess)\n# df_test_2['clean'] = df_test_2['comment_text'].apply(basic_preprocess)","6d261a74":"all_text = list(df_train_2['clean'] + df_train_1['clean'] + df_test_1['clean'])\n\nall_text = list(map(lambda s: str(s).split(' '), all_text))\nall_text = list(map(lambda s: list(filter(lambda w: str(w).strip() != \"\", s)), all_text))\n\nall_text[:3]","96fe67f7":"import gensim","511730c3":"%%time\n\ngensim_model = gensim.models.Word2Vec(all_text, size=300, min_count=1, iter=25, window=5)","ed0f3721":"gensim_model.wv.most_similar(\"khadr\")","3fe3b59f":"gensim_model.save('jigsaw_w2v_model')","d2396b1f":"To train gensim we need to prep the data. This is a 3 part process\n\n- concatenate the data into a single list\n- split each string into a list of words\n- filter out some junk\n\nAt that point we have a list of lists","41328fe9":"Here is a w2v model trained over the two jigsaw toxic comment competitions. As you can see I've not included the test data from the lastest competition - as you can see it doesn't include the test data from the lastest comp. Feel free to fork and add it if you need","94d49905":"Note (again) - deliberately don't use test2 here","ab9f7e72":"We need to be careful with the default parameters of gensim. We want a vector size of 300 dimensions, a min occurance count of 1 and a window size (for training) of 5"}}