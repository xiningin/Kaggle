{"cell_type":{"4e3c46f5":"code","108fd4f0":"code","d5fb9ef6":"code","bc545972":"code","2fa18296":"code","80599a32":"code","bd551ba4":"code","710d3e8d":"code","b217db14":"code","deeb0606":"code","e3af5bb3":"code","cf1ceafb":"code","bf6f9b16":"code","6c61a887":"code","fad3a179":"code","89edf3d1":"code","5af0260b":"code","0ecf4f7f":"code","4c725765":"code","2fc0da2f":"code","aa59b5d8":"code","7d553824":"code","66eed833":"markdown"},"source":{"4e3c46f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","108fd4f0":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf","d5fb9ef6":"df.info()","bc545972":"df.describe().T","2fa18296":"import plotly \nimport plotly.express as px","80599a32":"px.histogram(df, x='Pregnancies', color=\"Outcome\", width=350, height=250)","bd551ba4":"px.histogram(df, x='Glucose', color=\"Outcome\", width=350, height=250)","710d3e8d":"px.histogram(df, x='BloodPressure', color=\"Outcome\", width=350, height=250)","b217db14":"px.histogram(df, x='SkinThickness', color=\"Outcome\", width=350, height=250)","deeb0606":"px.histogram(df, x='Insulin', color=\"Outcome\", width=350, height=250)","e3af5bb3":"px.histogram(df, x='BMI', color=\"Outcome\", width=350, height=250)","cf1ceafb":"px.histogram(df, x='DiabetesPedigreeFunction', color=\"Outcome\", width=350, height=250)","bf6f9b16":"px.histogram(df, x='Age', color=\"Outcome\", width=350, height=250)","6c61a887":"from mlxtend.preprocessing import minmax_scaling\n\ndf = minmax_scaling(df, columns = df.columns)\ndf","fad3a179":"X = df.drop([\"Outcome\"], axis=1)\ny = df['Outcome']","89edf3d1":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","5af0260b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nLR_model = LogisticRegression()\nLR_model_params = {'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n                   #'penalty': ['l1', 'l2', 'elasticnet'],\n                   'max_iter': [25,50,100,200],\n                   'C': list(np.random.random_sample((10,))),\n                   'random_state': [42, 74]\n                  }\n\nLR_grid = GridSearchCV(LR_model,\n                       LR_model_params,\n                       cv = 5,\n                       n_jobs = -1,\n                       verbose = 1\n                      )\n\nLR_grid.fit(X, y)\nprint(LR_grid.best_params_)","0ecf4f7f":"LR = LogisticRegression(C=0.6817155191673481, max_iter= 25, random_state= 42, solver='lbfgs')\nLR.fit(X_train,y_train)\nprint(LR.score(X_test,y_test))","4c725765":"LR = LogisticRegression(C=0.5, max_iter= 25, random_state= 42, solver='lbfgs')\nLR.fit(X_train,y_train)\nprint(LR.score(X_test,y_test))","2fc0da2f":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvm_model = SVC()\nsvm_model_params = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n                    'gamma': ['scale', 'auto'], \n                    'degree': [2,3,4],\n                    'C': list(np.random.random_sample((10,))),\n                    'random_state': [42, 74]\n                   }\n\nsvm_grid = GridSearchCV(svm_model,\n                        svm_model_params,\n                        cv = 5,\n                        n_jobs = -1,\n                        verbose = 1\n                       )\n\nsvm_grid.fit(X, y)\nprint(svm_grid.best_params_)","aa59b5d8":"svm = SVC(C=0.1925055745754316, kernel= 'poly', degree= 2, gamma='scale', random_state= 42)\nsvm.fit(X_train,y_train)\nprint(svm.score(X_test,y_test))","7d553824":"svm = SVC(C=0.25, kernel= 'poly', degree= 3, gamma='scale', random_state= 42)\nsvm.fit(X_train,y_train)\nprint(svm.score(X_test,y_test))","66eed833":"**hmmm! min value of some attributes is zero! But we know it can not be; for example, BMI value can not be zero. So, we can understand miss values fill with 0 values before**"}}