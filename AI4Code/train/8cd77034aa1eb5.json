{"cell_type":{"25887f3a":"code","f75b6e82":"code","0fea21db":"code","b873dfc5":"code","9dbdcf37":"code","c24b3a07":"code","bca3ae7c":"code","b0e89077":"code","73a76a1a":"code","56f2ad01":"code","2b2a7b43":"code","cf012263":"code","f15a3581":"code","3bd98e66":"code","03f4233b":"markdown","8ccc1cbb":"markdown","5e68eab5":"markdown","bd9a06b1":"markdown","3e8b195c":"markdown","3c6c99ee":"markdown","727c7ec1":"markdown","605963c6":"markdown","58fd62ba":"markdown"},"source":{"25887f3a":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nSEED = 42","f75b6e82":"# Loading data\ndf = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")\ndf.head(10)","0fea21db":"# Dropping \"Id\" column since, in this case, it is useless\ndf = df.drop([\"Id\"], axis = 1)","b873dfc5":"# Getting some information\ndf.info()","9dbdcf37":"# Checking for duplicate rows\ndf.duplicated().sum()","c24b3a07":"# Dropping them\ndf = df.drop_duplicates(keep = \"first\")","bca3ae7c":"df.describe().T","b0e89077":"df.describe(include = \"O\").T","73a76a1a":"# Preparing the data\nx = df.drop([\"Species\"], axis = 1).copy()\ny = df[\"Species\"].copy()\n\nle = LabelEncoder()\ny = le.fit_transform(y)","56f2ad01":"def get_gscv_test_score_list():\n    splits_test_score = [\"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"split3_test_score\", \"split4_test_score\", \"split5_test_score\", \"split6_test_score\", \"split7_test_score\", \"split8_test_score\", \"split9_test_score\"]\n    gscv_test_score_list = []\n    for n in splits_test_score:\n        gscv_test_score_list.append(gscv.cv_results_[n][gscv.best_index_])\n    return gscv_test_score_list\n\n# Setting graph style\nsns.set_style(\"whitegrid\")","2b2a7b43":"dtc = DecisionTreeClassifier(random_state = SEED)\n\n# Getting the default parameters of DecisionTreeClassifier\ndefault_params = dtc.get_params(deep = True)\n\n# Filtering only the ones that we are going to adjust\ndefault_params = {\"criterion\" : default_params[\"criterion\"], \n                  \"max_depth\" : default_params[\"max_depth\"],\n                  \"max_features\" : default_params[\"max_features\"]}\n\n# Getting the scores of each cross-validation run\ndefault_dict = cross_validate(dtc, x, y, cv = 10, return_train_score = True) \n\ndefault_train_score_mean = default_dict[\"train_score\"].mean()\ndefault_test_score_mean = default_dict[\"test_score\"].mean()\ndefault_test_score_std = default_dict[\"test_score\"].std()\n\n\n# Defining possible parameters for DecisionTreeClassifier\nparams = {\"criterion\" : [\"gini\", \"entropy\"],\n          \"max_depth\" : [2, 3, 4, 5],\n          \"max_features\": [2, 3, 4]}\n\n# Finding the parameters that give the best result\ngscv = GridSearchCV(estimator = dtc, param_grid = params, cv = 10, return_train_score = True)\ngscv.fit(x, y)\nnew_params = gscv.best_params_\n\nnew_train_score_mean = gscv.cv_results_[\"mean_train_score\"][gscv.best_index_]\nnew_test_score_mean = gscv.cv_results_[\"mean_test_score\"][gscv.best_index_]\nnew_test_score_std = gscv.cv_results_[\"std_test_score\"][gscv.best_index_]\n\n# Printing results\nprint(\"Decision Tree\\n\")\nprint(\"using default hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(default_params, default_train_score_mean, default_test_score_mean, default_test_score_std))\nprint(\"using new hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(new_params, new_train_score_mean, new_test_score_mean, new_test_score_std))\nprint(25*\"-\", \"\\n\")\nprint(\"train score mean: {0:.4f} -> {1:.4f}\\ntest score mean: {2:.4f} -> {3:.4f}\\ntest score std: {4:.4f} -> {5:.4f}\".format(default_train_score_mean, new_train_score_mean, default_test_score_mean, new_test_score_mean, default_test_score_std, new_test_score_std))\n\nplt.figure(figsize = (9, 6))\nsns.lineplot(data = default_dict[\"test_score\"])\nsns.lineplot(data = get_gscv_test_score_list())\nplt.title(\"Test Accuracy of Each Cross-Validation Run\", size = 16)\nplt.legend([\"Before\", \"After\"])\nplt.show()","cf012263":"rfc = RandomForestClassifier(random_state = SEED)\n\n# Getting the default parameters of RandomForestClassifier\ndefault_params = rfc.get_params(deep = True)\n\n# Filtering only the ones that we are going to adjust.\ndefault_params = {\"criterion\" : default_params[\"criterion\"], \n                  \"max_depth\" : default_params[\"max_depth\"],\n                  \"max_features\" : default_params[\"max_features\"],\n                  \"n_estimators\" : default_params[\"n_estimators\"]}\n\n# Getting the scores of each cross-validation run\ndefault_dict = cross_validate(rfc, x, y, cv = 10, return_train_score = True) \n\ndefault_train_score_mean = default_dict[\"train_score\"].mean()\ndefault_test_score_mean = default_dict[\"test_score\"].mean()\ndefault_test_score_std = default_dict[\"test_score\"].std()\n\n\n# Defining possible parameters for RandomForestClassifier\nparams = {\"criterion\" : [\"gini\", \"entropy\"],\n          \"max_depth\" : [2, 3, 4, 5],\n          \"max_features\": [2, 3, 4],\n          \"n_estimators\" : [20, 30, 40, 50]}\n\n# Finding the parameters that give the best result\ngscv = GridSearchCV(estimator = rfc, param_grid = params, cv = 10, return_train_score = True)\ngscv.fit(x, y)\nnew_params = gscv.best_params_\n\nnew_train_score_mean = gscv.cv_results_[\"mean_train_score\"][gscv.best_index_]\nnew_test_score_mean = gscv.cv_results_[\"mean_test_score\"][gscv.best_index_]\nnew_test_score_std = gscv.cv_results_[\"std_test_score\"][gscv.best_index_]\n\n# Printing results\nprint(\"Random Forest\\n\")\nprint(\"using default hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(default_params, default_train_score_mean, default_test_score_mean, default_test_score_std))\nprint(\"using new hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(new_params, new_train_score_mean, new_test_score_mean, new_test_score_std))\nprint(25*\"-\", \"\\n\")\nprint(\"train score mean: {0:.4f} -> {1:.4f}\\ntest score mean: {2:.4f} -> {3:.4f}\\ntest score std: {4:.4f} -> {5:.4f}\".format(default_train_score_mean, new_train_score_mean, default_test_score_mean, new_test_score_mean, default_test_score_std, new_test_score_std))\n\nplt.figure(figsize = (9, 6))\nsns.lineplot(data = default_dict[\"test_score\"])\nsns.lineplot(data = get_gscv_test_score_list())\nplt.title(\"Test Accuracy of Each Cross-Validation Run\", size = 16)\nplt.legend([\"Before\", \"After\"])\nplt.show()","f15a3581":"svc = SVC()\n\n# Getting the default parameters of SVC\ndefault_params = svc.get_params(deep = True)\n\n# Filtering only the ones that we are going to adjust\ndefault_params = {\"C\" : default_params[\"C\"], \n                  \"kernel\" : default_params[\"kernel\"]}\n\n# Getting the scores of each cross-validation run\ndefault_dict = cross_validate(svc, x, y, cv = 10, return_train_score = True) \n\ndefault_train_score_mean = default_dict[\"train_score\"].mean()\ndefault_test_score_mean = default_dict[\"test_score\"].mean()\ndefault_test_score_std = default_dict[\"test_score\"].std()\n\n\n# Defining possible parameters for SVC\nparams = {\"C\" : [0.01, 0.1, 1, 10, 100],\n          \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n\n# Finding the parameters that give the best result\ngscv = GridSearchCV(estimator = svc, param_grid = params, cv = 10, return_train_score = True)\ngscv.fit(x, y)\nnew_params = gscv.best_params_\n\nnew_train_score_mean = gscv.cv_results_[\"mean_train_score\"][gscv.best_index_]\nnew_test_score_mean = gscv.cv_results_[\"mean_test_score\"][gscv.best_index_]\nnew_test_score_std = gscv.cv_results_[\"std_test_score\"][gscv.best_index_]\n\n# Printing results\nprint(\"Support Vector Machine (SVM)\\n\")\nprint(\"using default hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(default_params, default_train_score_mean, default_test_score_mean, default_test_score_std))\nprint(\"using new hyperparameters {0}\\n\\ntrain score mean: {1:.4f}\\ntest score mean: {2:.4f}\\ntest score std: {3:.4f}\\n\".format(new_params, new_train_score_mean, new_test_score_mean, new_test_score_std))\nprint(25*\"-\", \"\\n\")\nprint(\"train score mean: {0:.4f} -> {1:.4f}\\ntest score mean: {2:.4f} -> {3:.4f}\\ntest score std: {4:.4f} -> {5:.4f}\".format(default_train_score_mean, new_train_score_mean, default_test_score_mean, new_test_score_mean, default_test_score_std, new_test_score_std))\n\nplt.figure(figsize = (9, 6))\nsns.lineplot(data = default_dict[\"test_score\"])\nsns.lineplot(data = get_gscv_test_score_list())\nplt.title(\"Test Accuracy of Each Cross-Validation Run\", size = 16)\nplt.legend([\"Before\", \"After\"])\nplt.show()","3bd98e66":"knc = KNeighborsClassifier()\n\n# Getting the default parameters of KNeighborsClassifier\ndefault_params = knc.get_params(deep = True)\n\n# Filtering only the ones that we are going to adjust\ndefault_params = {\"n_neighbors\" : default_params[\"n_neighbors\"], \n                  \"p\" : default_params[\"p\"],\n                  \"weights\" : default_params[\"weights\"]}\n\n# Getting the scores of each cross-validation run\ndefault_dict = cross_validate(knc, x, y, cv = 10) \n\ndefault_test_score_mean = default_dict[\"test_score\"].mean()\ndefault_test_score_std = default_dict[\"test_score\"].std()\n\n\n# Defining possible parameters for KNeighborsClassifier\nparams = {\"n_neighbors\" : list(range(1,16)), \n          \"p\" : [1, 2],\n          \"weights\" : [\"uniform\", \"distance\"]}\n\n\n# Finding the parameters that give the best result\ngscv = GridSearchCV(estimator = knc, param_grid = params, cv = 10)\ngscv.fit(x, y)\nnew_params = gscv.best_params_\n\nnew_test_score_mean = gscv.cv_results_[\"mean_test_score\"][gscv.best_index_]\nnew_test_score_std = gscv.cv_results_[\"std_test_score\"][gscv.best_index_]\n\n# Printing results\nprint(\"k-Nearest Neighbors (k-NN)\\n\")\nprint(\"using default hyperparameters {0}\\n\\ntest score mean: {1:.4f}\\ntest score std: {2:.4f}\\n\".format(default_params, default_test_score_mean, default_test_score_std))\nprint(\"using new hyperparameters {0}\\n\\ntest score mean: {1:.4f}\\ntest score std: {2:.4f}\\n\".format(new_params, new_test_score_mean, new_test_score_std))\nprint(25*\"-\", \"\\n\")\nprint(\"test score mean: {0:.4f} -> {1:.4f}\\ntest score std: {2:.4f} -> {3:.4f}\".format(default_test_score_mean, new_test_score_mean, default_test_score_std, new_test_score_std))\n\nplt.figure(figsize = (9, 6))\nsns.lineplot(data = default_dict[\"test_score\"])\nsns.lineplot(data = get_gscv_test_score_list())\nplt.title(\"Test Accuracy of Each Cross-Validation Run\", size = 16)\nplt.legend([\"Before\", \"After\"])\nplt.show()","03f4233b":"In this notebook, i'm going to show the importance of **hyperparameter** tuning. But... what hyperparameters are? \n\nHyperparamters are values that the algorithm can not estimate (e.g. \"n_estimators\" in Random Forest, \"C\" in SVM and \"n_neighbors\" in k-NN). We can choose these values, or just leave them as default. But how can we know which one is the best? This is what we are going to see here.","8ccc1cbb":"# Conclusion","5e68eab5":"# k-Nearest Neighbors (k-NN)","bd9a06b1":"# Exploratory Data Analysis","3e8b195c":"# Decision Tree","3c6c99ee":"# Random Forest","727c7ec1":"# Introduction","605963c6":"# Support Vector Machine (SVM)","58fd62ba":"As expected, all models perfomed better with hyperparamter tuning (ignoring the time factor). The test score increased and the standard deviation decreased. In some cases, use default parameters caused a possible overfitting (Decision Tree and Random Forest), but with some adjusts this was fixed."}}