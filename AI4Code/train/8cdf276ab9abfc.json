{"cell_type":{"b9f8b634":"code","d7e0ea78":"code","b072989f":"code","76dd2dc4":"code","a29968e5":"code","0513dd0c":"code","d74d9c71":"code","2fa4cc7a":"code","0deff3ff":"code","c5482553":"code","be5c55ba":"code","27a9a096":"code","b44769c9":"code","ce36ce7c":"code","47aa102f":"code","a48c47c5":"code","7f898384":"code","c8cd4f29":"code","57a51d06":"code","febc335a":"code","d6ef7d0c":"code","8add1f9c":"code","340a785c":"code","e9f6c7f8":"code","70d48e21":"code","96ca2790":"markdown","a5df35e2":"markdown","e031defb":"markdown","59a9812e":"markdown","3a79866a":"markdown","ccba01d7":"markdown","c63c9c6b":"markdown","663c880c":"markdown","812b1040":"markdown","4a06c980":"markdown"},"source":{"b9f8b634":"import os \nprint(os.listdir('\/kaggle\/input\/textdata'))","d7e0ea78":"filename = '\/kaggle\/input\/textdata\/deu-eng.txt' # English-to-Deutsche\n\nf = open(filename, mode='rt', encoding='utf-8')\ndata = f.read()\nf.close()","b072989f":"# split a text into sentences\ndef to_lines(text):\n    sents = text.strip().split('\\n')\n    sents = [i.split('\\t') for i in sents]\n    return sents","76dd2dc4":"import numpy as np\nimport string\n\ndeu_eng = to_lines(data)\ndeu_eng = np.array(deu_eng)    #total = 150,000 sentences\ndeu_eng = deu_eng[:50000,:] #train =  50,000 sentences \n\n# Remove punctuation\ndeu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\ndeu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]","a29968e5":"# convert text to lowercase\nfor i in range(len(deu_eng)):\n    deu_eng[i,0] = deu_eng[i,0].lower()\n    deu_eng[i,1] = deu_eng[i,1].lower()","0513dd0c":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# empty lists\neng_l = []\ndeu_l = []\n\n# populate the lists with sentence lengths\nfor i in deu_eng[:,0]:\n    eng_l.append(len(i.split()))\n\nfor i in deu_eng[:,1]:\n    deu_l.append(len(i.split()))\n\nlength_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n\nlength_df.hist(bins = 30)\nplt.show()","d74d9c71":"# function to build a tokenizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ndef tokenization(lines):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(lines)\n    return tokenizer","2fa4cc7a":"# prepare english tokenizer\neng_tokenizer = tokenization(deu_eng[:, 0])\neng_vocab_size = len(eng_tokenizer.word_index) + 1\n\neng_length = 8\nprint('English Vocabulary Size: %d' % eng_vocab_size)","0deff3ff":"# prepare Deutch tokenizer\ndeu_tokenizer = tokenization(deu_eng[:, 1])\ndeu_vocab_size = len(deu_tokenizer.word_index) + 1\n\ndeu_length = 8\nprint('Deutch Vocabulary Size: %d' % deu_vocab_size)","c5482553":"# encode and pad sequences\ndef encode_sequences(tokenizer, length, lines):\n    seq = tokenizer.texts_to_sequences(lines)               # integer encode sequences    \n    seq = pad_sequences(seq, maxlen=length, padding='post') # pad sequences with 0 values\n    return seq","be5c55ba":"from sklearn.model_selection import train_test_split\n\n# split data into train and test set\ntrain, test = train_test_split(deu_eng, test_size=0.1, random_state = 12) # test = 10%, train = 90%\n\n# prepare training data\nX_train = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\nY_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\nprint(X_train.shape)\nprint(Y_train.shape)\n\n# prepare validation data\nX_test = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\nY_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\nprint(X_test.shape)\nprint(Y_test.shape)","27a9a096":"import tensorflow.keras as keras\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint","b44769c9":"in_vocab     = deu_vocab_size\nout_vocab    = eng_vocab_size\nin_timesteps = deu_length\nout_timesteps= eng_length","ce36ce7c":"# Build Model\nmodel = models.Sequential()\nmodel.add(layers.Embedding(in_vocab, 512, input_length=in_timesteps, mask_zero=True))\nmodel.add(layers.LSTM(512))\nmodel.add(layers.RepeatVector(out_timesteps))\nmodel.add(layers.LSTM(512, return_sequences=True))\nmodel.add(layers.Dense(out_vocab, activation='softmax'))\n\nmodel.summary()","47aa102f":"# Compile Model\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])","a48c47c5":"keras.utils.plot_model(model = model , to_file = 'Seq2Seq.png')","7f898384":"#model_path = \".\/seq2seq_chkpt.h5\"\n#checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')","c8cd4f29":"num_epochs = 50\nbatch_size = 512","57a51d06":"# Train Model\nhistory = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1),\n        epochs=num_epochs, batch_size=batch_size, validation_split = 0.1, verbose=1) #, callbacks=[checkpoint])","febc335a":"# Save Model\nmodels.save_model(model, \".\/seq2seq_deu-eng.h5\")","d6ef7d0c":"# Show Train History\nkeys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","8add1f9c":"# Test Model\npreds = model.predict_classes(X_test)","340a785c":"def get_word(n, tokenizer):\n    for word, index in tokenizer.word_index.items():\n        if index == n:\n            return word\n    return None","e9f6c7f8":"# convert predictions into text\t  \npreds_text = []\nfor item in preds:\n    temp = []\n    for j in range(len(item)):\n        t = get_word(item[j], eng_tokenizer)\n        if j > 0:\n            if (t == get_word(item[j-1], eng_tokenizer)) or (t == None):\n                temp.append('')\n            else:\n                temp.append(t)\n        else:\n            if(t == None):\n                temp.append('')\n            else:\n                temp.append(t) \n    preds_text.append(' '.join(temp))","70d48e21":"pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\nprint(pred_df.sample(15)) # print 15 rows randomly","96ca2790":"### Convert predictions into text","a5df35e2":"## Prepare Dataset","e031defb":"# Neural Machine Translation","59a9812e":"## Train Model","3a79866a":"## show Training History","ccba01d7":"## Read Dataset","c63c9c6b":"## Build Model","663c880c":"## Test Model","812b1040":"## Preprocessing Data (Tokenize)","4a06c980":"## Save Model"}}