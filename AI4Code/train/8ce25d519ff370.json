{"cell_type":{"b4655064":"code","72a61177":"code","4162ba2a":"code","c91b2d1e":"code","3ba861e8":"code","d1c60ac1":"code","5b66bce2":"code","3b1431af":"code","1bcfb128":"code","34fead5c":"code","091b2e25":"code","e6ced86d":"code","f0d18bba":"code","14be37a8":"code","4fa876ed":"code","977c2773":"code","1c52b6a1":"code","ef5c63e2":"code","4401f9f3":"code","20cb3bef":"code","540340c7":"code","9e707234":"code","09652617":"code","9ed5a158":"code","62592bf2":"code","74574253":"code","c02de851":"code","11dda324":"code","57117ae4":"code","8ac58ea8":"code","9f4ecef4":"code","e82ca2a4":"code","fb752156":"code","699b4d5f":"code","1b44776b":"code","d1046008":"code","74650694":"code","821eb582":"code","e795b684":"code","4737a61a":"code","ea514b2d":"code","017dc973":"code","a431fd18":"code","5f4545f8":"code","e4f47803":"code","4b933528":"code","6de45f7e":"code","cbd51427":"code","e8e72d7e":"code","33080793":"code","725fab52":"code","eaaded35":"markdown","eee6fae1":"markdown","7393b189":"markdown","4b15bc17":"markdown","0803da42":"markdown","7b394f0c":"markdown","3c01a784":"markdown","770626f2":"markdown","0298c308":"markdown","f626ae87":"markdown","41ae1768":"markdown","ab14fad4":"markdown","b950f07a":"markdown","a8a8cc84":"markdown","0ea21d65":"markdown","7296c2e2":"markdown","b5775e06":"markdown","2cb95ff7":"markdown","71acbae1":"markdown","fce1a0d9":"markdown","4c4ad40b":"markdown","38c08f57":"markdown","87601715":"markdown","809a0dd6":"markdown","29db543e":"markdown","66d67bfe":"markdown","d517e82c":"markdown","8d7535c4":"markdown"},"source":{"b4655064":"import numpy as np\n#NumPy is a python library used for working with arrays.\n#It also has functions for working in domain of linear algebra, fourier transform, and matrices.\n#We have lists that serve the purpose of arrays, but they are slow.NumPy aims to provide an array object that is up to 50x faster that traditional Python lists.\n\nimport pandas as pd \n#Why pandas: you want to explore a dataset stored in a CSV on your computer. Pandas will extract the data from that CSV into a DataFrame \u2014 \n#a table, basically \u2014 then let you do things like:\n#Calculate statistics and answer questions about the data, like: What's the average, median, max, or min of each column?\n#Does column A correlate with column B?\n#What does the distribution of data in column C look like?\n#Clean the data by doing things like removing missing values and filtering rows or columns by some criteria\n#Visualize the data with help from Matplotlib. Plot bars, lines, histograms, bubbles, and more.\n#Store the cleaned, transformed data back into a CSV, other file or database\n\nimport os\n#The OS module in python provides functions for interacting with the operating system.\n#This module provides a portable way of using operating system dependent functionality.\n#The *os* and *os.path* modules include many functions to interact with the file system.\n\nimport matplotlib.pyplot as plt\n#Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\nplt.style.use(\"seaborn-whitegrid\")\n#plt.style.available : To see all the available style in matplotlib library\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n#UTF-8 is a variable-width character encoding standard \n#that uses between one and four eight-bit bytes to represent all valid Unicode code points.\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","72a61177":"# Read datas\nhouse_income = pd.read_csv('\/kaggle\/input\/fatal-police-shootings-in-the-us\/MedianHouseholdIncome2015.csv', encoding=\"windows-1252\")\npercentage_people_below_poverty= pd.read_csv('\/kaggle\/input\/fatal-police-shootings-in-the-us\/PercentagePeopleBelowPovertyLevel.csv', encoding=\"windows-1252\")\npercent_over_25= pd.read_csv('\/kaggle\/input\/fatal-police-shootings-in-the-us\/PercentOver25CompletedHighSchool.csv', encoding=\"windows-1252\")\nrace = pd.read_csv('\/kaggle\/input\/fatal-police-shootings-in-the-us\/ShareRaceByCity.csv', encoding=\"windows-1252\")\nkill = pd.read_csv('\/kaggle\/input\/fatal-police-shootings-in-the-us\/PoliceKillingsUS.csv', encoding=\"windows-1252\")","4162ba2a":"race.head()","c91b2d1e":"percentage_people_below_poverty.head()","3ba861e8":"percentage_people_below_poverty.info()","d1c60ac1":"percentage_people_below_poverty['Geographic Area'].unique()","5b66bce2":"percentage_people_below_poverty.poverty_rate.replace(['-'],0.0,inplace = True)\npercentage_people_below_poverty.poverty_rate.value_counts()","3b1431af":"percentage_people_below_poverty.poverty_rate = percentage_people_below_poverty.poverty_rate.astype(float)\n#race - kill - percent_over_25 - percentage_people_below_poverty - house_income","1bcfb128":"area_list = list(percentage_people_below_poverty['Geographic Area'].unique())\narea_poverty_ratio = []\nfor i in area_list:\n    x = percentage_people_below_poverty[percentage_people_below_poverty['Geographic Area']==i]\n    area_poverty_rate = sum(x.poverty_rate)\/len(x)\n    area_poverty_ratio.append(area_poverty_rate)\ndata = pd.DataFrame({'area_list': area_list,'area_poverty_ratio':area_poverty_ratio})\nnew_index = (data['area_poverty_ratio'].sort_values(ascending=False)).index.values\nsorted_data = data.reindex(new_index)\n\n# visualization\nplt.figure(figsize=(15,10))\nsns.barplot(x=sorted_data['area_list'], y=sorted_data['area_poverty_ratio'])\nplt.xticks(rotation= 0)\nplt.xlabel('Geographic Area')\nplt.ylabel('Poverty Rate')\nplt.title('Poverty Rate Given States')","34fead5c":"kill.head()","091b2e25":"kill.name.value_counts()","e6ced86d":"# The zip() function returns a zip object, which is an iterator of tuples where the first \n# item in each passed iterator is paired together, and then the second item in each passed iterator are paired together etc.\n# If the passed iterators have different lengths, the iterator with the least items decides the length of the new iterator.\n# If a single iterable is passed, zip() returns an iterator of tuples with each tuple having only one element.\n# If multiple iterables are passed, zip() returns an iterator of tuples with each tuple having elements from all the iterables.\nname = [ \"Manjeet\", \"Nikhil\", \"Shambhavi\", \"Astha\" ] \nroll_no = [ 4, 1, 3, 2 ] \nmarks = [ 40, 50, 60, 70 ] \n  \n# using zip() to map values \nmapped = zip(name, roll_no, marks) \nmapped = list(mapped) \nprint (\"The zipped result is : \",end=\"\") \nprint (mapped) \nprint(\"\\n\") \n  \n# unzipping values \nnamz, roll_noz, marksz = zip(*mapped) \n\nprint (\"The unzipped results: \\n\") \n  \nprint (\"The name list is : \",end=\"\") \nprint (namz) \nprint (\"The roll_no list is : \",end=\"\") \nprint (roll_noz) \nprint (\"The marks list is : \",end=\"\") \nprint (marksz) ","f0d18bba":"# Python Counter is a container that will hold the count of each of the elements present in the container. \n# The counter is a sub-class available inside the dictionary class.\n# The Counter holds the data in an unordered collection, just like hashtable objects.\n# Arithmetic operations like addition, subtraction, intersection, and union can be easily performed on a Counter.\n\nlist1 = ['x','y','z','x','x','x','y', 'z']\nprint(Counter(list1))\nprint(\"*****\")\nmy_str = \"Welcome to Guru99 Tutorials!\"\nprint(Counter(my_str))","14be37a8":"# Most common 15 Name or Surname of killed people\nseparate = kill.name[kill.name != 'TK TK'].str.split()  # I don't want to show TK TK. #Convert to string and split the names.\na,b = zip(*separate)                     \nname_list = a+b                      \nname_count = Counter(name_list)          \nmost_common_names = name_count.most_common(15)  \nx,y = zip(*most_common_names)\nx,y = list(x),list(y)\n\n\nplt.figure(figsize=(15,10))\nax= sns.barplot(x=x, y=y,palette = sns.cubehelix_palette(len(x)))\nplt.xlabel('Name or Surname of killed people')\nplt.ylabel('Frequency')\nplt.title('Most common 15 Name or Surname of killed people')","4fa876ed":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","977c2773":"percent_over_25.head()","1c52b6a1":"percent_over_25.info()","ef5c63e2":"# High school graduation rate of the population that is older than 25 in states\npercent_over_25.percent_completed_hs.replace(['-'],0.0,inplace = True)\npercent_over_25.percent_completed_hs = percent_over_25.percent_completed_hs.astype(float)\n\narea_list = list(percent_over_25['Geographic Area'].unique())\narea_highschool = []\n\nfor i in area_list:\n    x = percent_over_25[percent_over_25['Geographic Area']==i]\n    area_highschool_rate = sum(x.percent_completed_hs)\/len(x)\n    area_highschool.append(area_highschool_rate)\n    \n# sorting\ndata = pd.DataFrame({'area_list': area_list,'area_highschool_ratio':area_highschool})\nnew_index = (data['area_highschool_ratio'].sort_values(ascending=True)).index.values\nsorted_data2 = data.reindex(new_index)\n\n# visualization\nplt.figure(figsize=(15,10))\nsns.barplot(x=sorted_data2['area_list'], y=sorted_data2['area_highschool_ratio'])\nplt.xticks(rotation= 0)\nplt.xlabel('States')\nplt.ylabel('High School Graduate Rate')\nplt.title(\"Percentage of Given State's Population Above 25 that Has Graduated High School\")","4401f9f3":"race.head()","20cb3bef":"race.info()","540340c7":"# Percentage of state's population according to races that are black,white,native american, asian and hispanic\nrace.replace(['-'],0.0,inplace = True)\nrace.replace(['(X)'],0.0,inplace = True)\nrace.loc[:,['share_white','share_black','share_native_american','share_asian','share_hispanic']] = race.loc[:,['share_white','share_black','share_native_american','share_asian','share_hispanic']].astype(float)\narea_list = list(race['Geographic area'].unique())\n\nshare_white = []\nshare_black = []\nshare_native_american = []\nshare_asian = []\nshare_hispanic = []\n\nfor i in area_list:      #Find the for each state\n    x = race[race['Geographic area']==i]\n    share_white.append(sum(x.share_white)\/len(x))\n    share_black.append(sum(x.share_black) \/ len(x))\n    share_native_american.append(sum(x.share_native_american) \/ len(x))\n    share_asian.append(sum(x.share_asian) \/ len(x))\n    share_hispanic.append(sum(x.share_hispanic) \/ len(x))\n    \n# visualization\nf,ax = plt.subplots(figsize = (9,15))\nsns.barplot(x=share_white,            y=area_list,   color='green',    alpha = 0.5,    label='White' )\nsns.barplot(x=share_black,            y=area_list,   color='blue',     alpha = 0.7,    label='African American')\nsns.barplot(x=share_native_american,  y=area_list,   color='cyan',     alpha = 0.6,    label='Native American')\nsns.barplot(x=share_asian,            y=area_list,   color='yellow',   alpha = 0.6,    label='Asian')\nsns.barplot(x=share_hispanic,         y=area_list,   color='red',      alpha = 0.6,    label='Hispanic')\n\nax.legend(loc='lower right',frameon = True)     # legend opacity\nax.set(xlabel='Percentage of Races', ylabel='States', title = \"Percentage of State's Population According to Races \")    \n","9e707234":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","09652617":"sorted_data.head()","9ed5a158":"sorted_data2.head()","62592bf2":"# High school graduation rate vs Poverty rate of each state\nsorted_data['area_poverty_ratio'] = sorted_data['area_poverty_ratio']\/max( sorted_data['area_poverty_ratio'])\nsorted_data2['area_highschool_ratio'] = sorted_data2['area_highschool_ratio']\/max( sorted_data2['area_highschool_ratio'])\n# ^^^ [1,2,3,4,5] vs  [600,700,800,900,1000] we should have similar scale, we need to normalize the data ^^^\n# Divide to max number 0< [1,2,3,4,5]\/5 <1  0< [600,700,800,900,1000]\/1000 <1\n\ndata = pd.concat([sorted_data,sorted_data2['area_highschool_ratio']],axis=1)  #concatenation\ndata.sort_values('area_poverty_ratio',inplace=True)","74574253":"data.head()","c02de851":"data.columns","11dda324":"# visualize\nf,ax1 = plt.subplots(figsize =(20,10))\nsns.pointplot(x='area_list',     y='area_poverty_ratio',      data=data,    color='lime',   alpha=0.8)\nsns.pointplot(x='area_list',     y='area_highschool_ratio',   data=data,    color='red',    alpha=0.8)\n\nplt.text(40,0.6,   'high school graduate ratio',  color='red',   fontsize = 17,   style = 'italic')\nplt.text(40,0.55,  'poverty ratio',               color='lime',   fontsize = 18,   style = 'italic')\n\nplt.xlabel('States',fontsize = 15,color='blue')\nplt.ylabel('Values',fontsize = 15,color='blue')\nplt.title('High School Graduate  VS  Poverty Rate',fontsize = 20,color='blue')\nplt.grid()","57117ae4":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","8ac58ea8":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\n\n# pearsonr= if it is 1, there is positive correlation and if it is, -1 there is negative correlation.\n# If it is zero, there is no correlation between variables\n\n#sorted_data['area_poverty_ratio'] = sorted_data['area_poverty_ratio']\/max( sorted_data['area_poverty_ratio'])\n#sorted_data2['area_highschool_ratio'] = sorted_data2['area_highschool_ratio']\/max( sorted_data2['area_highschool_ratio'])\n\n# Show the joint distribution using kernel density estimation \ng = sns.jointplot(data.area_poverty_ratio, data.area_highschool_ratio, kind=\"kde\", size=7)\nplt.savefig('graph.png')\nplt.show()","9f4ecef4":"# We use the same data, so define data = \"data name\"\ng = sns.jointplot(\"area_poverty_ratio\", \"area_highschool_ratio\", data=data,    size=5,   ratio=3,    color=\"r\")","e82ca2a4":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","fb752156":"kill.head()","699b4d5f":"kill.race.value_counts()","1b44776b":"# Race rates according in kill data \nkill.race.dropna(inplace = True)\nlabels = kill.race.value_counts().index\ncolors = ['grey','blue','red','yellow','green','brown']\nexplode = [0,0,0,0,0,0]\nsizes = kill.race.value_counts().values\n\n# visual\nplt.figure(figsize = (7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.title('Killed People According to Races',color = 'blue',fontsize = 15)","d1046008":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\n# Show the results of a linear regression within each dataset\nsns.lmplot(x=\"area_poverty_ratio\", y=\"area_highschool_ratio\", data=data)\nplt.show()","74650694":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\nsns.kdeplot(data.area_poverty_ratio, data.area_highschool_ratio, shade=True, cut=3)\nplt.show()","821eb582":"# Show each distribution with both violins and points\n# Use cubehelix to get a custom sequential palette\npal = sns.cubehelix_palette(2, rot=-.5, dark=.3)\nsns.violinplot(data=data, palette=pal, inner=\"points\")\nplt.show()","e795b684":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","4737a61a":"data.corr()","ea514b2d":"# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code\nf,ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(data.corr(), annot=True, linewidths=0.5,linecolor=\"red\", fmt= '.1f',ax=ax)\nplt.show()","017dc973":"kill.head()","a431fd18":"kill.manner_of_death.unique()","5f4545f8":"sns.boxplot(x=\"gender\", y=\"age\", hue=\"manner_of_death\", data=kill, palette=\"PRGn\")\nplt.show()","e4f47803":"sns.swarmplot(x=\"gender\", y=\"age\",hue=\"manner_of_death\", data=kill)\nplt.show()","4b933528":"data.head()","6de45f7e":"sns.pairplot(data)\nplt.show()","cbd51427":"#race - kill - percent_over_25 - percentage_people_below_poverty - house_income   - DATA","e8e72d7e":"kill.gender.value_counts()","33080793":"sns.countplot(kill.gender)\n#sns.countplot(kill.manner_of_death)\nplt.title(\"gender\",color = 'blue',fontsize=15)","725fab52":"armed = kill.armed.value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(   x=armed[:7].index,   y=armed[:7].values  )\n\nplt.ylabel('Number of Weapon')\nplt.xlabel('Weapon Types')\nplt.title('Kill weapon',color = 'blue',fontsize=15)","eaaded35":"Draw a combination of boxplot and kernel density estimate.\n\nA violin plot plays a similar role as a box and whisker plot. It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. Unlike a box plot, in which all of the plot components correspond to actual datapoints, the violin plot features a kernel density estimation of the underlying distribution.\n\nThis can be an effective and attractive way to show multiple distributions of data at once, but keep in mind that the estimation procedure is influenced by the sample size, and violins for relatively small samples might look misleadingly smooth.","eee6fae1":"Show point estimates and confidence intervals as rectangular bars.\n\nA bar plot represents an estimate of central tendency for a numeric variable with the height of each rectangle and provides some indication of the uncertainty around that estimate using error bars. Bar plots include 0 in the quantitative axis range, and they are a good choice when 0 is a meaningful value for the quantitative variable, and you want to make comparisons against it.","7393b189":"Draw a plot of two variables with bivariate and univariate graphs.\n\nThis function provides a convenient interface to the JointGrid class, with several canned plot kinds. This is intended to be a fairly lightweight wrapper; if you need more flexibility, you should use JointGrid directly.\n\nseaborn.jointplot(x, y, data=None, kind='scatter', stat_func=None, color=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs)","4b15bc17":"Plot pairwise relationships in a dataset.\n\nBy default, this function will create a grid of Axes such that each numeric variable in data will by shared in the y-axis across a single row and in the x-axis across a single column. The diagonal Axes are treated differently, drawing a plot to show the univariate distribution of the data for the variable in that column.\n\nIt is also possible to show a subset of variables or plot different variables on the rows and columns.","0803da42":"seaborn.countplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)\n\nShow the counts of observations in each categorical bin using bars.\n\nA count plot can be thought of as a histogram across a categorical, instead of quantitative, variable. The basic API and options are identical to those for barplot(), so you can compare counts across nested variables.\n\n","7b394f0c":"A violin plot plays a similar role as a box and whisker plot. It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. Unlike a box plot, in which all of the plot components correspond to actual datapoints, the violin plot features a kernel density estimation of the underlying distribution.\n\nThis can be an effective and attractive way to show multiple distributions of data at once, but keep in mind that the estimation procedure is influenced by the sample size, and violins for relatively small samples might look misleadingly smooth.","3c01a784":"Draw a box plot to show distributions with respect to categories.\n\nA box plot (or box-and-whisker plot) shows the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable. The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be \u201coutliers\u201d using a method that is a function of the inter-quartile range.","770626f2":"seaborn.kdeplot(data, data2=None, shade=False, vertical=False, kernel='gau', bw='scott', gridsize=100, cut=3, clip=None, legend=True, cumulative=False, shade_lowest=True, cbar=False, cbar_ax=None, cbar_kws=None, ax=None, **kwargs)\n\nFit and plot a univariate or bivariate kernel density estimate.","0298c308":"<a id = \"9\" ><\/a>\n# 9. Box Plot","f626ae87":"<font color = \"blue\" >\n    Plot Contents:\n        \n   1. [Bar Plot](#1)\n   2. [Point Plot](#2)\n   3. [Joint Plot](#3)\n   4. [Pie Chart](#4)\n   5. [Lm Plot](#5)\n   6. [Kde Plot](#6)\n   7. [Violin Plot](#7)\n   8. [Heatmap](#8)\n   9. [Box Plot](#9)\n   10. [Swarm Plot](#10)\n   11. [Pair Plot](#11)\n   12. [Count Plot ](#12)  ","41ae1768":"<a id = \"6\" ><\/a>\n# 6. Kde Plot","ab14fad4":"<a id = \"12\" ><\/a>\n# 12. Count Plot","b950f07a":"<a id = \"1\" ><\/a>\n# 1. Bar Plot","a8a8cc84":"<a id = \"10\" ><\/a>\n# 10. Swarm Plot","0ea21d65":"<a id = \"8\" ><\/a>\n# 8. Heatmap ","7296c2e2":"Show point estimates and confidence intervals using scatter plot glyphs.\n\nA point plot represents an estimate of central tendency for a numeric variable by the position of scatter plot points and provides some indication of the uncertainty around that estimate using error bars.\n\nPoint plots can be more useful than bar plots for focusing comparisons between different levels of one or more categorical variables. They are particularly adept at showing interactions: how the relationship between levels of one categorical variable changes across levels of a second categorical variable. The lines that join each point from the same hue level allow interactions to be judged by differences in slope, which is easier for the eyes than comparing the heights of several groups of points or bars.","b5775e06":"<a id = \"3\" ><\/a>\n# 3. Joint Plot","2cb95ff7":"> \u201cVisualization gives you answers to questions you didn\u2019t know you had.\u201d ","71acbae1":"<a id = \"7\" ><\/a>\n# 7. Violin Plot","fce1a0d9":"<a id = \"5\" ><\/a>\n# 5.  Lm Plot","4c4ad40b":"<a id = \"11\" ><\/a>\n# 11. Pair Plot","38c08f57":"<a id = \"4\" ><\/a>\n# 4. Pie Chart","87601715":"<a id = \"2\" ><\/a>\n# 2. Point Plot","809a0dd6":"Plot data and regression model fits across a FacetGrid.\n\nThis function combines regplot() and FacetGrid. It is intended as a convenient interface to fit regression models across conditional subsets of a dataset.\n\nWhen thinking about how to assign variables to different facets, a general rule is that it makes sense to use hue for the most important comparison, followed by col and row. However, always think about your particular dataset and the goals of the visualization you are creating.","29db543e":"The heatmap is a way of representing the data in a 2-dimensional form. The data values are represented as colors in the graph. The goal of the heatmap is to provide a colored visual summary of information.\n\nHeat maps display numeric tabular data where the cells are colored depending upon the contained value. Heat maps are great for making trends in this kind of data more readily apparent, particularly when the data is ordered and there is clustering.","66d67bfe":"Draw a categorical scatterplot with non-overlapping points.\n\nThis function is similar to stripplot(), but the points are adjusted (only along the categorical axis) so that they don\u2019t overlap. This gives a better representation of the distribution of values, but it does not scale well to large numbers of observations. This style of plot is sometimes called a \u201cbeeswarm\u201d.\n\nA swarm plot can be drawn on its own, but it is also a good complement to a box or violin plot in cases where you want to show all observations along with some representation of the underlying distribution.\n\nArranging the points properly requires an accurate transformation between data and point coordinates. This means that non-default axis limits must be set before drawing the plot.","d517e82c":"# Information about Dataset(Fatal Police Shootings in the US)\n\n# Fatal police shootings in the US since 2015 with additional US census data\n\nThe 2014 killing of Michael Brown in Ferguson, Missouri, began the protest movement culminating in Black Lives Matter and an increased focus on police accountability nationwide.\n\nSince Jan. 1, 2015, The Washington Post has been compiling a database of every fatal shooting in the US by a police officer in the line of duty.\nIt's difficult to find reliable data from before this period, as police killings haven't been comprehensively documented, and the statistics on police brutality are much less available. As a result, a vast number of cases go unreported.\n\nThe Washington Post is tracking more than a dozen details about each killing - including the race, age and gender of the deceased, whether the person was armed, and whether the victim was experiencing a mental-health crisis. They have gathered this information from law enforcement websites, local new reports, social media, and by monitoring independent databases such as \"Killed by police\" and \"Fatal Encounters\". The Post has also conducted additional reporting in many cases.\n\nThere are four additional datasets. These are US census data on poverty rate, high school graduation rate, median household income, and racial demographics.\n\nSource of census data:\nhttps:\/\/factfinder.census.gov\/faces\/nav\/jsf\/pages\/community_facts.xhtml\n","8d7535c4":"# Data Visualization\n\nData visualization is the discipline of trying to understand data by placing it in a visual context so that patterns, trends and correlations that might not otherwise be detected can be exposed.\n\nPython offers multiple great graphing libraries that come packed with lots of different features. No matter if you want to create interactive, live or highly customized plots python has an excellent library for you.\n\n**Matplotlib** from beginners in data science to experienced professionals building complex data visualizations, matplotlib is usually the default visualization Python library data scientists turn to.\nmatplotlib is known for the high amount of flexibility it provides as a 2-D plotting library in Python.Matplotlib supports all the popular charts (lots, histograms, power spectra, bar charts, error charts, scatterplots, etc.) right out of the box. There are also extensions that you can use to create advanced visualizations like 3-Dimensional plots, etc.\nWhat I personally like about matplotlib is that because it\u2019s so flexible, it lets the user control aspects of the visualization at the most granular level, from a single line or dot in the graph to the entire chart. This means you can customize it at the highest levels.\n\n**Seaborn** is built on top of matplotlib and provides a very simple yet intuitive interface for building visualizations. When using Seaborn, you will also notice that many of the default settings in the plots work quite well right out of the box.The first unique feature of Seaborn is that it is designed in such a way that you write way lesser code to achieve high-grade visualizations. Here is an example of this simplicity. Notice how we can create a complex visualization with just a single line of plotting code.The second useful feature of Seaborn is that it supports a plethora of advanced plots like categorical plotting (catplot), distribution plotting using kde (distplot), swarm plot, etc. right out of the box. Seaborn is built on top of matplotlib, it is highly compatible with it. So that means when building visualizations, you can start with advanced plots that seaborn already supports and then customize them as much as you want with the help of matplotlib.\n\n**Bokeh** is a library designed to generate visualizations that are friendly on the web interface and browsers. And that\u2019s what this visualization library specifically targets.You will also notice that the visualizations generated from Bokeh are interactive in nature, which basically means you can convey information in a more intuitive way through your plots.Bokeh supports unique visualizations like Geospatial plots, Network graphs, etc. right out of the box. If you want to show these visualizations in a browser, there are options available to export them and you can also use it through JavaScript itself.\n\n**Altair** is a declarative library for data visualization. Its principle is that rather than focusing on the code part, one should focus on the visualization part and write as less code as possible and still be able to create beautiful and intuitive plots.Since Altair uses a declarative style to create plots, it becomes very easy and quick to iterate through visualizations and experiments at a rapid pace when using this library.\n\n**Plotly** this data visualization library is by far my go-to library whenever I want to create visualizations that need to be highly interactive for the user. Plotly is highly compatible with Jupyter Notebook and Web Browsers. This means whatever interactive plots you create can easily be shared in the same manner with your teammates or end-users.Plotly supports a gamut of plots right from basic chart types, Seaborn-like beautiful and advanced plots, 3-D plots, Map-based visualizations, scientific plots, etc.Plotly\u2019s plots can also support animation capabilities as well.\n\n**ggplot** is the Python version of the famous ggplot2 of R and the Grammer of Graphics language.  ggplot is also a declarative style library like Bokeh but is also tightly coupled with Pandas. This means you can easily build visualizations using your Pandas dataframe itself."}}