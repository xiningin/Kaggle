{"cell_type":{"18e7a7d0":"code","983eeb63":"code","5b3ea276":"code","ecc9301a":"code","efe526e2":"code","27839f5f":"code","74c034a4":"code","d836f991":"code","712ba9ea":"code","cb80d7b3":"code","3a7aadea":"code","18e89858":"code","bb88c9d2":"code","32dbe4c6":"code","e9d66c8f":"code","bc550649":"code","8100c96c":"code","34beaaff":"code","e16e07d7":"code","3c3899f0":"code","67e49cf5":"code","519f8db5":"code","23527003":"code","59f701e2":"code","b6819f0e":"code","e7ea675c":"code","e0f5ef7e":"code","ae9e448b":"code","e2918520":"code","f458400b":"code","8b094590":"code","ee76f292":"code","d479a048":"code","b3141933":"code","ab015c49":"code","739165c3":"code","3141f828":"code","5ed65457":"code","30a55f3a":"code","e16c9c21":"code","c43295a2":"code","d3287447":"code","938ef50c":"code","c08729f3":"code","965ebe37":"code","07ef5857":"code","0b96f7dd":"code","ea63e859":"code","ea0dc536":"code","a1df997d":"code","92856ec4":"code","8b23a032":"code","cfb01276":"code","5adbf44c":"code","196f4278":"code","47b84699":"code","dc51a551":"code","73e6739e":"code","b7a0cf2a":"code","fc768dc4":"code","682d9be3":"code","77e0141f":"code","321be7ec":"code","cf502b03":"code","7750a96a":"code","ec0c8172":"code","c60f39d6":"code","241aa92e":"code","25a0bfb7":"code","63dab17d":"code","97d71b7c":"code","d29a792f":"code","a8591570":"code","38bc7b7f":"markdown","44cab371":"markdown","31192d9a":"markdown","5205dc32":"markdown","7341ad03":"markdown","ccc3cf03":"markdown","31fd7e32":"markdown","ade97792":"markdown","02309ea6":"markdown","6066e229":"markdown","ceadf94e":"markdown","ed3e8eeb":"markdown","d29afac5":"markdown","8ee7da8b":"markdown","89238520":"markdown","5e25a1f7":"markdown","e2645659":"markdown","3c559b0d":"markdown","5c6f4a4a":"markdown","06a5f710":"markdown","beaa9fe3":"markdown","a440a66f":"markdown","ac9de53f":"markdown","29a75115":"markdown","3aeb4083":"markdown","8588c3b3":"markdown","55ab21b4":"markdown","b1b3df6b":"markdown","388f62fe":"markdown"},"source":{"18e7a7d0":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom datetime import datetime\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score","983eeb63":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nprint(train.shape)\ntrain.head()","5b3ea276":"train.info()","ecc9301a":"train.describe()","efe526e2":"print(\"Number of people who died: \",train['Survived'].value_counts()[0])       # Imbalanced Data\nprint(\"Number of people who survived: \",train['Survived'].value_counts()[1])","27839f5f":"sns.heatmap(train.isnull()==True)","74c034a4":"train.drop(labels= ['Cabin','PassengerId','Name'], axis = 1,inplace = True)","d836f991":"train['Ticket'].nunique() #there are 681 unique values of tickets available but there are 891 passengers.","712ba9ea":"train[train['Ticket']== \"349909\"]","cb80d7b3":"# Summing up the no. of siblings, spouse, parents ,children to get the total no. of family members onboard.\ntrain['Family_onboard'] =  train['SibSp']+train['Parch']  ","3a7aadea":"train.drop(labels=['Ticket'],axis = 1,inplace = True)   #Dropping the Ticket  column","18e89858":"train.head()","bb88c9d2":"print('No. of null values in the Age column:',train[train['Age'].isnull()==True].shape[0]\n      ,\"i.e\",train[train['Age'].isnull()==True].shape[0]\/891 *100,\"%\")","32dbe4c6":"grp = train.groupby(['Sex','Pclass'])","e9d66c8f":"grp['Age'].median()    # Grouping the data by sex and passenger class and finding median age of the class.","bc550649":"train['Age'].fillna(value = 0,inplace = True)","8100c96c":"#Filling the appropriate age where there were null values in the age column with median values of that sex and class.\nstart = datetime.now()\nfor i in range(0,891):\n    if(train['Sex'][i]=='male' and train['Pclass'][i]==1):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 40.0\n            continue\n    elif(train['Sex'][i]=='male' and train['Pclass'][i]==2):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 30.0\n            continue\n    elif(train['Sex'][i]=='male' and train['Pclass'][i]==3):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 25.0\n            continue\n    elif(train['Sex'][i]=='female' and train['Pclass'][i]==1):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 35.0\n            continue\n    elif(train['Sex'][i]=='female' and train['Pclass'][i]==2):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 28.0 \n            continue\n    elif(train['Sex'][i]=='female' and train['Pclass'][i]==3):\n        if(train['Age'][i]==0):\n            train['Age'][i] = 21.0\n            continue\nprint(\"All the null values of the age column have been handled successfully!\")\nprint(\"Time taken to run this cell: \",datetime.now()-start)","34beaaff":"sns.boxplot(train['Age'])","e16e07d7":"print(\"No. of Children onboard:\",train[train['Age']<=18]['Age'].count())\nprint(\"No. of Adults onboard:\",train[train['Age']>18]['Age'].count())","3c3899f0":"train['Age'].hist(bins = 30)","67e49cf5":"data = [train]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 7\n    \n    dataset['Age'] = dataset['Age'].astype(str)\n    dataset.loc[ dataset['Age'] == '0', 'Age'] = \"Children\"\n    dataset.loc[ dataset['Age'] == '1', 'Age'] = \"Teens\"\n    dataset.loc[ dataset['Age'] == '2', 'Age'] = \"Youngsters\"\n    dataset.loc[ dataset['Age'] == '3', 'Age'] = \"Young Adults\"\n    dataset.loc[ dataset['Age'] == '4', 'Age'] = \"Adults\"\n    dataset.loc[ dataset['Age'] == '5', 'Age'] = \"Middle Age\"\n    dataset.loc[ dataset['Age'] == '6', 'Age'] = \"Senior\"\n    dataset.loc[ dataset['Age'] == '7', 'Age'] = \"Retired\"","519f8db5":"train['Age'].value_counts()","23527003":"train.head()","59f701e2":"train['Pclass'].value_counts()\n# Maximum number of passengers belonged to the 3rd class and were probably crew members and staff","b6819f0e":"train['Pclass'].hist(by=train['Survived'])","e7ea675c":"train['Pclass'].hist(by=train['Sex'])","e0f5ef7e":"data = [train]\n\nfor dataset in data:\n    dataset['Pclass'] = dataset['Pclass'].astype(str)\n    dataset.loc[ dataset['Pclass'] == '1', 'Pclass'] = \"Class1\"\n    dataset.loc[ dataset['Pclass'] == '2', 'Pclass'] = \"Class2\"\n    dataset.loc[ dataset['Pclass'] == '3', 'Pclass'] = \"Class3\"","ae9e448b":"train.head()","e2918520":"train['Embarked'].hist()  # Most of the passengers boarded the titanic at Southampton","f458400b":"train['Embarked'].hist(by=train['Survived'])","8b094590":"train['Embarked'].value_counts()","ee76f292":"train['Embarked'].fillna(train['Embarked'].mode(),inplace = True)","d479a048":"# train['Embarked'] = train['Embarked'].map({\"S\":0,'C':1,'Q':2})\n# train['Embarked_C'] = train['Embarked'].map({\"S\":0,'C':1,'Q':0})\n# train['Embarked_Q'] = train['Embarked'].map({\"S\":0,'C':0,'Q':1})\n# train.drop(labels = ['Embarked'],axis=1,inplace = True)","b3141933":"train['Fare'].describe() # Maximum fare on the titanic is 512.32 Euros.","ab015c49":"train[train['Fare']==512.329200]    # All 3 of these are 1st class passengers and hence paid the highest Fare.","739165c3":"grp = train.groupby(['Pclass'])\ngrp['Fare'].mean() ","3141f828":"data = [train]\n\nfor dataset in data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    dataset['Fare'] = dataset['Fare'].astype(str)\n    dataset.loc[ dataset['Fare'] == '0', 'Fare'] = \"Extremely Low\"\n    dataset.loc[ dataset['Fare'] == '1', 'Fare'] = \"Very Low\"\n    dataset.loc[ dataset['Fare'] == '2', 'Fare'] = \"Low\"\n    dataset.loc[ dataset['Fare'] == '3', 'Fare'] = \"High\"\n    dataset.loc[ dataset['Fare'] == '4', 'Fare'] = \"Very High\"\n    dataset.loc[ dataset['Fare'] == '5', 'Fare'] = \"Extremely High\"","5ed65457":"train['Family_onboard'].unique()","30a55f3a":"train['is_alone'] = train['Family_onboard'].map({1:0,  0:1,  4:0,  2:0,  6:0,  5:0,  3:0,  7:0, 10:0})","e16c9c21":"sns.heatmap(train.corr(),annot = True)  # Checking for multicollinearity in the data.","c43295a2":"train.drop(labels=['SibSp','Parch','Family_onboard'],axis =1,inplace = True)\ntrain['is_alone']=train['is_alone'].map({0:\"no\",1:'yes'})","d3287447":"col_list = list(train.select_dtypes(include=['object']).columns)\nfor i in col_list:\n    train = pd.concat([train,pd.get_dummies(train[i], prefix=i)],axis=1)\n    train.drop(i, axis = 1, inplace=True)","938ef50c":"train.head()","c08729f3":"train.columns","965ebe37":"X = train[['Pclass_Class1', 'Pclass_Class2', 'Pclass_Class3',\\\n       'Sex_female', 'Sex_male', 'Age_Adults', 'Age_Children',\\\n       'Age_Middle Age', 'Age_Retired', 'Age_Senior', 'Age_Teens',\\\n       'Age_Young Adults', 'Age_Youngsters', 'Fare_Extremely High',\\\n        'Fare_Extremely Low', 'Fare_High', 'Fare_Low', 'Fare_Very High',\\\n        'Fare_Very Low', 'Embarked_C', 'Embarked_Q', 'Embarked_S','is_alone_no', 'is_alone_yes']]\ny = train['Survived']","07ef5857":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","0b96f7dd":"print(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","ea63e859":"y_train.value_counts()   # we will have to give weights to make the classes balanced.","ea0dc536":"y_test.value_counts()","a1df997d":"# This function trains the specified classifier with default parameters and prints train and test accuracy.\n\ndef basic_train_eval(classifier,xtrain,xtest,ytrain,ytest):\n    model = classifier\n    model.fit(xtrain,ytrain)\n    train_pred = model.predict(xtrain)\n    test_pred = model.predict(xtest)\n    print(\"Training and predicting on default parameters: \\n\")\n    print(\"Accuracy on train data: \",accuracy_score(ytrain,train_pred))\n    print(\"Accuracy on test data: \",accuracy_score(ytest,test_pred))\n    print(\"\\n\")\n    print(classification_report(ytest,test_pred))\n    print(confusion_matrix(ytest,test_pred))","92856ec4":"basic_train_eval(LogisticRegression(class_weight='balanced'),X_train,X_test,y_train,y_test)","8b23a032":"basic_train_eval(SVC(),X_train,X_test,y_train,y_test)  # OVERFITTING","cfb01276":"basic_train_eval(GaussianNB(),X_train,X_test,y_train,y_test)","5adbf44c":"basic_train_eval(KNeighborsClassifier(),X_train,X_test,y_train,y_test) # OVERFITTING","196f4278":"basic_train_eval(RandomForestClassifier(),X_train,X_test,y_train,y_test) # OVERFITTING","47b84699":"basic_train_eval(xgb.XGBClassifier(),X_train,X_test,y_train,y_test) # OVERFITTING","dc51a551":"# This function takes the classifier and parameter grid as parameters and performs Grid Search and 5 fold Cross Validation\n# and gives us the best score.\n\ndef grid_tuning(classifier,param_grid):\n    start = datetime.now()\n    grid = GridSearchCV(estimator = classifier,param_grid=param_grid,cv=5)\n    grid.fit(X_train,y_train)\n    print(\"Best Parameters: \",grid.best_params_,\"\\n\")\n    train_pred = grid.predict(X_train)\n    test_pred = grid.predict(X_test)\n    print(\"Accuracy on train data: \",accuracy_score(y_train,train_pred))\n    print(\"Accuracy on test data: \",accuracy_score(y_test,test_pred),\"\\n\")\n    print(classification_report(y_test,test_pred))\n    print(confusion_matrix(y_test,test_pred),\"\\n\")\n    print(\"Time taken to run this cell: \",datetime.now()-start)","73e6739e":"lr_param = {'penalty':['l1','l2'],'C':[0.0001,0.001,0.01,0.1,1,10],'solver':['liblinear'],'class_weight':['balanced']}\ngrid_tuning(LogisticRegression(),param_grid=lr_param)","b7a0cf2a":"svc_param={\"C\":[0.001,0.01,0.1,1,10],'class_weight':['balanced']}\ngrid_tuning(SVC(),param_grid=svc_param)   ","fc768dc4":"rfc_param= {'n_estimators':[5,10,20,40,70,100,150,200],\"criterion\":['gini','entropy'],'class_weight':['balanced'],\\\n            'max_depth':[3,4,5,6,7,8]}\ngrid_tuning(RandomForestClassifier(),param_grid=rfc_param)   ","682d9be3":"xgb_param = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\ngrid_tuning(xgb.XGBClassifier(),param_grid=xgb_param)   ","77e0141f":"test= pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","321be7ec":"test.info()","cf502b03":"test['Fare'].fillna(value=20,inplace = True)","7750a96a":"test.info()","ec0c8172":"passId = test['PassengerId']","c60f39d6":"# Performing all the preprocessing steps on the test data to get it in the right format for prediction.\nstart = datetime.now()\ntest.drop(labels=['PassengerId','Name','Ticket','Cabin'],axis = 1,inplace=True)\ntest['Age'].fillna(value = 0,inplace = True)\nfor i in range(0,test.shape[0]):\n    if(test['Sex'][i]=='male' and test['Pclass'][i]==1):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 40.0\n            continue\n    elif(test['Sex'][i]=='male' and test['Pclass'][i]==2):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 30.0\n            continue\n    elif(test['Sex'][i]=='male' and test['Pclass'][i]==3):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 25.0\n            continue\n    elif(test['Sex'][i]=='female' and test['Pclass'][i]==1):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 35.0\n            continue\n    elif(test['Sex'][i]=='female' and test['Pclass'][i]==2):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 28.0 \n            continue\n    elif(test['Sex'][i]=='female' and test['Pclass'][i]==3):\n        if(test['Age'][i]==0):\n            test['Age'][i] = 21.0\n            continue     \nprint(\"Null values of Age column handled successfully!!\\n\")            \ndata = [test]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 7\n    \n    dataset['Age'] = dataset['Age'].astype(str)\n    dataset.loc[ dataset['Age'] == '0', 'Age'] = \"Children\"\n    dataset.loc[ dataset['Age'] == '1', 'Age'] = \"Teens\"\n    dataset.loc[ dataset['Age'] == '2', 'Age'] = \"Youngsters\"\n    dataset.loc[ dataset['Age'] == '3', 'Age'] = \"Young Adults\"\n    dataset.loc[ dataset['Age'] == '4', 'Age'] = \"Adults\"\n    dataset.loc[ dataset['Age'] == '5', 'Age'] = \"Middle Age\"\n    dataset.loc[ dataset['Age'] == '6', 'Age'] = \"Senior\"\n    dataset.loc[ dataset['Age'] == '7', 'Age'] = \"Retired\"   \nprint('Converted Age column to categorical successfully!!\\n')\nfor dataset in data:\n    dataset['Pclass'] = dataset['Pclass'].astype(str)\n    dataset.loc[ dataset['Pclass'] == '1', 'Pclass'] = \"Class1\"\n    dataset.loc[ dataset['Pclass'] == '2', 'Pclass'] = \"Class2\"\n    dataset.loc[ dataset['Pclass'] == '3', 'Pclass'] = \"Class3\" \nprint('Converted Pclass column to categorical successfully!!\\n')\nfor dataset in data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    dataset['Fare'] = dataset['Fare'].astype(str)\n    dataset.loc[ dataset['Fare'] == '0', 'Fare'] = \"Extremely Low\"\n    dataset.loc[ dataset['Fare'] == '1', 'Fare'] = \"Very Low\"\n    dataset.loc[ dataset['Fare'] == '2', 'Fare'] = \"Low\"\n    dataset.loc[ dataset['Fare'] == '3', 'Fare'] = \"High\"\n    dataset.loc[ dataset['Fare'] == '4', 'Fare'] = \"Very High\"\n    dataset.loc[ dataset['Fare'] == '5', 'Fare'] = \"Extremely High\"  \nprint('Converted Fare column to categorical successfully!!\\n')    \ntest['Family_onboard'] =  test['SibSp']+test['Parch']    \ntest['is_alone'] = test['Family_onboard'].map({1:0,  0:1,  4:0,  2:0,  6:0,  5:0,  3:0,  7:0, 10:0})\ntest.drop(labels=['SibSp','Parch','Family_onboard'],axis =1,inplace = True)\ntest['is_alone']=test['is_alone'].map({0:\"no\",1:'yes'})\ncol_list = list(test.select_dtypes(include=['object']).columns)\nfor i in col_list:\n    test = pd.concat([test,pd.get_dummies(test[i], prefix=i)],axis=1)\n    test.drop(i, axis = 1, inplace=True)     \nprint('Preprocessing Completed Successfully!\\n')\nprint('Time Taken in preprocessing: ',datetime.now()-start)","241aa92e":"# Training the XGBoost model on best obtained parameters.\nxgbc = xgb.XGBClassifier(colsample_bytree= 0.7, gamma= 0.1, learning_rate=0.05, max_depth= 4, min_child_weight= 5)\nxgbc.fit(X,y)\nxgbc_train_pred = xgbc.predict(X)\n# xgbc_test_pred = xgbc.predict(X_test)\nprint(\"Training Accuracy: \",accuracy_score(y,xgbc_train_pred))\n# print(\"Test Accuracy: \",accuracy_score(y_test,xgbc_test_pred))","25a0bfb7":"result = xgbc.predict(test)","63dab17d":"sub1 = pd.DataFrame(passId,columns = ['PassengerId'])\nsub1['Survived'] = result\nsub1.to_csv(\"Sub1.csv\",index = False)","97d71b7c":"gxgb = GridSearchCV(xgb.XGBClassifier(),param_grid=xgb_param,cv = 5)\ngxgb.fit(X,y)","d29a792f":"result_new = gxgb.predict(test)","a8591570":"sub2 = pd.DataFrame(passId,columns = ['PassengerId'])\nsub2['Survived'] = result_new\nsub2.to_csv(\"Sub2.csv\",index = False)","38bc7b7f":"**Dropping the cabin column as it has very less data and dropping the passenger id column as it does not provide any useful information to us.**","44cab371":"#### Data = Titanic Dataset from kaggle.com","31192d9a":"### Univariate Analysis on Age column","5205dc32":"### Importing necessary Libraries","7341ad03":"**From the given example we can see that these 4 passengers were from the same family and were travelling together. Therefore they have same ticket number and also the same fare.**\n\n**Mrs. Nils was the mother along with her 3 children.**","ccc3cf03":"**From this we can see that most of the people who died were of 3rd class.**","31fd7e32":"**Changing Pclass column into categoical column with strings.**","ade97792":"### Univariate analysis on Embarked Column.","02309ea6":"**Changing Fare column to categorical from continuous.**","6066e229":"## Hyperparameter Tuning ","ceadf94e":"# Titanic Survival Prediction","ed3e8eeb":"# EDA and Data Preparation","d29afac5":"**Changing age to a categorical column:**","8ee7da8b":"**Having the same ticket gives us same information as having a family member on board.**","89238520":"**Task - Using the given data predict whether a passenger will survive the incident or not.**","5e25a1f7":"### Importing Test Data and Generating Submission File","e2645659":"**How can the ticket number of 2 passengers be same?**\n\nAns. Passengers travelling together have same ticket number.","3c559b0d":"## Univariate Analysis on Fare Column.","5c6f4a4a":"### Splitting the data into Train and Test set.","06a5f710":"**On futher reasearch on the internet we found that Miss Annie was employed as a personal maid to the wealthy widow Charlotte\nDrake Cardeza. Mr. Thomas was Mrs Cardeza's son and Gustave Lesurer was Mr Thomas's manservant. They boarded the titanic \ntogether at Cherbourg on 10 April 1912 with picely fare of 512 euros.**","beaa9fe3":"### One Hot Encoding the features","a440a66f":"**Evaluation Metric = Accuracy**","ac9de53f":"### Importing Data into Dataframes.","29a75115":"* **survival:**\tSurvival\t0 = No, 1 = Yes\n* **pclass:**\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* **sex:**\tSex\t\n* **Age:**\tAge in years\t\n* **sibsp:**\tNumber of siblings \/ spouses aboard the Titanic\t\n* **parch:**\tNumber of parents \/ children aboard the Titanic\t\n* **ticket:**\tTicket number\t\n* **fare:**\tPassenger fare\t\n* **cabin:**\tCabin number\t\n* **embarked:**\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton","3aeb4083":"### Univariate Analysis on Ticket column","8588c3b3":"**Attribute Information:**","55ab21b4":"### Checking for null values in the data.","b1b3df6b":"**As Sibsp, Parch and Family onboard and is_alone are highly correlated therefore keeping only is_alone column and drop others.**","388f62fe":"### Univariate Analysis on Passenger Class column"}}