{"cell_type":{"b588bbd7":"code","adb9596f":"code","3257fcfc":"code","ac7ecb5d":"code","84d6c95d":"code","48f20535":"code","eda040df":"code","4e184255":"code","57e9aa68":"code","b111349f":"code","c0792097":"code","b08f038a":"code","663249d7":"code","efa23f47":"code","19615cfa":"code","ec03aac8":"code","995384e8":"code","3d72f7ca":"code","00c1c9cb":"code","518721d0":"code","68c96d4b":"code","88852187":"code","c51559f5":"code","a797407d":"code","fc432237":"code","992603cb":"code","54e49e15":"markdown","56cebb26":"markdown","b3354d46":"markdown"},"source":{"b588bbd7":"import pandas as pd\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split, cross_val_score\nnltk.download('punkt')\nnltk.download('stopwords')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools","adb9596f":"df = pd.read_csv('..\/input\/fake-news\/train.csv')\ndf.head()","3257fcfc":"df.shape","ac7ecb5d":"data = df.copy()","84d6c95d":"data.head()","48f20535":"data.isna().sum()","eda040df":"data.dropna(inplace=True)","4e184255":"data.reset_index(inplace=True)","57e9aa68":"data.head(10)","b111349f":"x=  data.drop('label',axis=1)\ny= data['label']","c0792097":"import re","b08f038a":"pr = PorterStemmer()\n\ncorpus = []\n\nfor i in range(0,len(data)):\n  review = re.sub('[^a-zA-Z]', ' ', data['title'][i])\n  review = review.lower()\n  review = review.split()\n  review = [pr.stem(word) for word in review if word not in set(stopwords.words('english'))]\n  review = ' '.join(review)\n  corpus.append(review)","663249d7":"corpus[:6]","efa23f47":"cv = CountVectorizer(max_features=5000, ngram_range=(1,3))\nx = cv.fit_transform(corpus).toarray()","19615cfa":"x.shape","ec03aac8":"y = data['label']\ny.head()","995384e8":"x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.30, random_state=42)","3d72f7ca":"len(x_train), len(y_train)","00c1c9cb":"# feature names\ncv.get_feature_names()[:20]","518721d0":"classifier = MultinomialNB().fit(x_train,y_train)\ny_preds = classifier.predict(x_test)","68c96d4b":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","88852187":"cm = confusion_matrix(y_test, y_preds)\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","c51559f5":"accuracy_score = accuracy_score(y_test,y_preds)\nprint(f'Accuracy Score: {accuracy_score}')","a797407d":"cross_val_score = cross_val_score(classifier,\n                x,\n                y,\n                n_jobs=-1,\n                cv=5,\n                verbose=True,\n                scoring='accuracy')","fc432237":"cross_val_score.mean()","992603cb":"print(classification_report(y_test,y_preds))","54e49e15":"### train test split","56cebb26":"## Converting to vectors using Bag of words","b3354d46":"## Modeling"}}