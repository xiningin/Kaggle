{"cell_type":{"419353ef":"code","31ed0948":"code","2ad2ceda":"code","cff9eeca":"code","f4b20cc8":"code","5f46233a":"code","036232bc":"code","03a0b7b8":"code","bfe8cfb6":"code","7ddcffa6":"code","bddc5450":"code","0a2873cc":"code","bb8a2c27":"code","f1c567c8":"code","b8bec51a":"code","f42a14db":"code","63512c10":"code","8be97796":"code","67db388a":"code","0679955d":"code","3eca455e":"code","09c4a917":"code","769b95e0":"code","1aa26844":"code","8c5d96c8":"code","e18958e2":"code","b1690715":"code","7819fa71":"code","932b2634":"code","5efec5b9":"code","d9999482":"code","cd87c066":"code","5e08f368":"code","798a074b":"code","513f5eb6":"code","9bf4d55e":"code","5dea84b3":"code","c33fad85":"code","e8add587":"code","1db058f5":"code","d3a3f06a":"code","f2f204ef":"code","930281f4":"code","2dceff39":"code","8811bd17":"code","e90b5b9b":"code","aa815ef9":"code","497ceef2":"code","47203d7b":"markdown","1e2cdea5":"markdown","c94e6075":"markdown","f0eb413c":"markdown","8c8c2c14":"markdown","a9a32cd6":"markdown","0dd01f6d":"markdown","a0a7df9c":"markdown","4fe4bbe4":"markdown","61843679":"markdown","cf5ee587":"markdown","550a8f61":"markdown","7db93a71":"markdown","738b0cdf":"markdown","63f753fe":"markdown","43a43c5e":"markdown","a8fbf0ad":"markdown","9ac117f3":"markdown","c514fc74":"markdown","72b53ac6":"markdown","deef09ad":"markdown","8ddeb6be":"markdown","be8706cb":"markdown","0adf4296":"markdown","6f2b7c94":"markdown"},"source":{"419353ef":"import pandas as pd\nimport numpy as np\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","31ed0948":"train.head()","2ad2ceda":"train.describe()","cff9eeca":"train.info()","f4b20cc8":"class_surv = train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\nclass_surv","5f46233a":"plt.pie(class_surv['Survived'], labels=class_surv['Pclass'], autopct='%0.0f%%', shadow=True, explode=[0.05,0.05,0.05], startangle=90)\nplt.title('Survival percentage depending on passengers class (P. Class)')\nplt.show()","036232bc":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","03a0b7b8":"sex_survived = train[['Sex', 'Survived']].groupby('Sex', as_index=False).mean()\nsex_survived ","bfe8cfb6":"plt.pie(sex_survived['Survived'], labels=sex_survived['Sex'], autopct='%0.0f%%', shadow=True, explode=[0.05,0.05], startangle=90)\nplt.title('Survival percentage depending on passengers sex (Sex)')\nplt.show()","7ddcffa6":"grid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","bddc5450":"sibsp_train = train[['SibSp', 'Survived']].groupby('SibSp', as_index=False).mean()\nsibsp_train","0a2873cc":"bar1 = plt.bar(sibsp_train['SibSp'], sibsp_train['Survived']*100)\nplt.xticks(sibsp_train['SibSp'])\nplt.ylabel('Survival rate (%)')\nplt.title('Survival percentage depending on number of siblings\/spouses aboard (# Sib\/Sp)')\n\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        plt.annotate('%0.1f%%' %height,\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  \n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(bar1)\n\n\nplt.show()","bb8a2c27":"parch_train = train[['Parch', 'Survived']].groupby('Parch', as_index=False).mean()\nparch_train","f1c567c8":"bar1 = plt.bar(parch_train['Parch'], parch_train['Survived']*100)\nplt.xticks(parch_train['Parch'])\nplt.ylabel('Survival rate (%)')\nplt.title('Survival percentage depending on number of parents\/children aboard (# Par\/Ch)')\n\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        plt.annotate('%0.1f%%' %height,\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  \n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(bar1)\n\n\nplt.show()","b8bec51a":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","f42a14db":"train_df = train.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test.drop(['Ticket', 'Cabin'], axis=1)","63512c10":"combined = [train_df, test_df]\n","8be97796":"for dataset in combined:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\npd.crosstab(train_df['Title'], train_df['Sex'])","67db388a":"for dataset in combined:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","0679955d":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combined:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","3eca455e":"train_df = train_df.drop(['Name','PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombined = [train_df, test_df]","09c4a917":"for dataset in combined:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","769b95e0":"guess_ages = np.zeros((2,3))\nguess_ages","1aa26844":"for dataset in combined:   \n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","8c5d96c8":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean()","e18958e2":"for dataset in combined:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ntrain_df.head()","b1690715":"train_df = train_df.drop(['AgeBand'], axis=1)\n","7819fa71":"combined = [train_df, test_df]","932b2634":"for dataset in combined:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\n","5efec5b9":"train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","d9999482":"for dataset in combined:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","cd87c066":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","5e08f368":"freq_port = train_df.Embarked.dropna().mode()[0]","798a074b":"freq_port","513f5eb6":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()","9bf4d55e":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","5dea84b3":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","c33fad85":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","e8add587":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","1db058f5":"test_df.head(10)","d3a3f06a":"X_train = train_df.drop(['Survived'], axis=1)\ny_train = train_df['Survived']\nX_test = test_df.drop(['PassengerId'], axis=1)\ny_test = gender_submission['Survived']","f2f204ef":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","930281f4":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nprint('Score: ', logreg.score(X_train, y_train))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n","2dceff39":"rfor = RandomForestClassifier(n_estimators=100)\nrfor.fit(X_train, y_train)\ny_pred = rfor.predict(X_test)\nprint('Score: ', rfor.score(X_train, y_train))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","8811bd17":"dtr = DecisionTreeClassifier()\ndtr.fit(X_train, y_train)\ny_pred = dtr.predict(X_test)\nprint('Score: ', dtr.score(X_train, y_train))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","e90b5b9b":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\nprint('Score: ', gnb.score(X_train, y_train))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","aa815ef9":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": y_pred\n    })","497ceef2":"submission","47203d7b":"#### Map Sex category","1e2cdea5":"### Analyze age of survived passengers\n","c94e6075":"#### create and map bands for Age","f0eb413c":"##### drop Parch, SibSp, and FamilySize","8c8c2c14":"### Analyze survival rate depending on a Pclass         \n","a9a32cd6":"#### Random Forest","0dd01f6d":"### Analyze survival rate depending on Sex ","a0a7df9c":"##### Create feature isAlone","4fe4bbe4":"### Analyze survival rate depending on parents\/children aboard      \n","61843679":"#### Remove Name ad ID columns","cf5ee587":"#### Decision Tree","550a8f61":"##### create bond","7db93a71":"#### Logistic Regression","738b0cdf":"##### replace missing values","63f753fe":"#### Visualization ","43a43c5e":"#### Extract Title from name","a8fbf0ad":"#### map Embarked and replace missing values","9ac117f3":"#### Gaussian Naive Bayes","c514fc74":"### Wrangle data\n","72b53ac6":"#### create and map bands for Fare","deef09ad":"### Modeling","8ddeb6be":"#### Visualization ","be8706cb":"#### combine Parch and SibSp","0adf4296":"### Analyze survival rate depending on siblings\/spouses aboard      \n","6f2b7c94":"#### replace missing values for Age"}}