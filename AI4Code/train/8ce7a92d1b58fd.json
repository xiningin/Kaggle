{"cell_type":{"b0e475cf":"code","2943c6ae":"code","01b32156":"code","3f5c7627":"code","4311f4dc":"code","9be2e08e":"code","95746e27":"code","eedd6412":"code","c94f3012":"code","03a7be91":"code","8ea9871e":"code","042ab6d6":"code","f4aca9b8":"code","44c987a2":"code","58ce17da":"code","c19cd42c":"code","5be8c8e2":"code","6beda002":"code","63105a2c":"code","af1e82c1":"code","f62f7adf":"code","bfe8d5aa":"code","e7d4cbe8":"code","5d409495":"code","80629b6f":"code","5f3bc122":"code","df21d0e0":"code","73d4b5a8":"code","9a7a3216":"code","0c4a0e64":"code","0c994ed0":"code","3dc00772":"code","d1f559c9":"code","6d5a6ebf":"code","ac1bff29":"code","fb94d863":"code","481db7c2":"code","36773e10":"code","6b89896d":"code","0b5b263b":"code","c8b0a052":"code","3f963e17":"code","a1ee8706":"code","c42cc89c":"code","93600652":"code","a7329400":"code","8b996df7":"code","6a36a9d7":"code","3bdbb1ec":"code","3b500a41":"code","942d1427":"code","ba082de6":"code","5f0f7f9f":"code","8b60474a":"code","7ed37d8e":"code","4e215fa7":"code","a74d856a":"code","5efd62cc":"code","ca5937d8":"code","6a13f767":"code","04478979":"code","56fa26d4":"code","5f722f18":"code","4ea6a30d":"code","41cce7fc":"code","3cc72f8e":"code","88314b68":"code","32bd1032":"code","467cf4f3":"code","daaf32ff":"code","bf3f1587":"code","df3540d8":"code","708690bd":"code","5f8007a1":"code","8d50eb1c":"code","c486657c":"code","905b8965":"markdown","56ed10f4":"markdown","3783a5a0":"markdown","1ddbd9bc":"markdown","243d6064":"markdown","3a3d553a":"markdown","69c32be7":"markdown","888d2ac5":"markdown","62bb768e":"markdown","ebcae0be":"markdown","faa4fef3":"markdown","910117ce":"markdown","0ab41162":"markdown","d15a1bb8":"markdown","f7fba4fa":"markdown","ab0fad43":"markdown","1dfccd73":"markdown","3c3cd01f":"markdown","c856d518":"markdown","7935219b":"markdown","e15976f0":"markdown","2489edb3":"markdown","9c0f0a81":"markdown","e6c8d36a":"markdown","a5246520":"markdown","0487f3a0":"markdown","f8c50c09":"markdown","0db6cb29":"markdown","365f70dc":"markdown","784bbc3f":"markdown","912009c6":"markdown","3bd92aa8":"markdown","5a5c810a":"markdown","25228a18":"markdown","c8f0e5af":"markdown","dba9eb6e":"markdown","f910cf50":"markdown","51461916":"markdown","6ba51d5e":"markdown","387c7fc1":"markdown","2a2d291d":"markdown","48c3357b":"markdown","d33823ef":"markdown","8430fe49":"markdown","872f4c46":"markdown","36478220":"markdown","e370ac0a":"markdown","ba5907d2":"markdown","f0b10277":"markdown","78816a19":"markdown","a2f89e85":"markdown","bc681ba8":"markdown","30cea462":"markdown","ea1f34c4":"markdown","f5f2b1ca":"markdown","02979d1c":"markdown"},"source":{"b0e475cf":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","2943c6ae":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","01b32156":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","3f5c7627":"df.head(10)","4311f4dc":"df.columns","9be2e08e":"from IPython.core.display import HTML # permet d'afficher du code html dans jupyter\ndisplay(HTML(df.head(10).to_html()))","95746e27":"df.shape","eedd6412":"df.describe()","c94f3012":"df.columns","03a7be91":"df = df.drop(['Unnamed: 32'], axis=1)","8ea9871e":"df.diagnosis.value_counts()","042ab6d6":"malin = df.diagnosis=='M'\nbenin = df.diagnosis=='B'","f4aca9b8":"sns.jointplot(\"perimeter_worst\", \"area_worst\", df, kind='kde');","44c987a2":"plt.figure(figsize=(12,12))\nsns.kdeplot(df.perimeter_worst, df.area_worst,  shade=True)","58ce17da":"plt.figure(figsize=(12,12))\nsns.kdeplot(df[malin].perimeter_worst, df[malin].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\nsns.kdeplot(df[benin].perimeter_worst, df[benin].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)","c19cd42c":"sns.boxplot(x=\"diagnosis\", y=\"perimeter_worst\", data=df)","5be8c8e2":"sns.violinplot(x=\"diagnosis\", y=\"perimeter_worst\", data=df)","6beda002":"fig = sns.FacetGrid(df, hue=\"diagnosis\", aspect=3, palette=\"Set2\") # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"perimeter_worst\", shade=True)\nfig.add_legend()","63105a2c":"sns.lmplot(x=\"radius_mean\", y=\"texture_mean\", data=df, fit_reg=False, hue='diagnosis')","af1e82c1":"#sns.pairplot(df, hue=\"diagnosis\")","f62f7adf":"data_train = df.sample(frac=0.8, random_state=1)          # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)     # le reste des donn\u00e9es pour le test","bfe8d5aa":"X_train = data_train.drop(['diagnosis'], axis=1)\ny_train = data_train['diagnosis']\nX_test = data_test.drop(['diagnosis'], axis=1)\ny_test = data_test['diagnosis']","e7d4cbe8":"plt.figure(figsize=(9,9))\n\nlogistique = lambda x: np.exp(x)\/(1+np.exp(x))   \n\nx_range = np.linspace(-10,10,50)       \ny_values = logistique(x_range)\n\nplt.plot(x_range, y_values, color=\"red\")","5d409495":"from sklearn.linear_model import LogisticRegression","80629b6f":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","5f3bc122":"y_lr = lr.predict(X_test)","df21d0e0":"from sklearn.metrics import accuracy_score, confusion_matrix","73d4b5a8":"lr_score = accuracy_score(y_test, y_lr)\nprint(lr_score)","9a7a3216":"# Matrice de confusion\ncm = confusion_matrix(y_test, y_lr)\nprint(cm)","0c4a0e64":"pd.crosstab(y_test, y_lr, rownames=['Reel'], colnames=['Prediction'], margins=True)","0c994ed0":"df.columns","3dc00772":"df = df.drop(['id'], axis=1)","d1f559c9":"df.head()","6d5a6ebf":"data_train = df.sample(frac=0.8, random_state=1)          # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)     # le reste des donn\u00e9es pour le test","ac1bff29":"X_train = data_train.drop(['diagnosis'], axis=1)\ny_train = data_train['diagnosis']\nX_test = data_test.drop(['diagnosis'], axis=1)\ny_test = data_test['diagnosis']","fb94d863":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","481db7c2":"y_lr = lr.predict(X_test)","36773e10":"lr_score = accuracy_score(y_test, y_lr)\nprint(lr_score)","6b89896d":"pd.crosstab(y_test, y_lr, rownames=['Reel'], colnames=['Prediction'], margins=True)","0b5b263b":"fig = sns.FacetGrid(df, hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"perimeter_worst\", shade=True)\nfig.add_legend()","c8b0a052":"fig = sns.FacetGrid(df[df.perimeter_worst>110], hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"texture_mean\", shade=True)\nfig.add_legend()","3f963e17":"fig = sns.FacetGrid(df[(df.perimeter_worst>110) & (df.texture_mean>17)], hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"concave points_mean\", shade=True)\nfig.add_legend()","a1ee8706":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nprint(accuracy_score(y_test, y_dtc))","c42cc89c":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","93600652":"dtc1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\ndtc1.fit(X_train,y_train)","a7329400":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc1, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","8b996df7":"y_dtc1 = dtc1.predict(X_test)\nprint(accuracy_score(y_test, y_dtc1))","6a36a9d7":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","3bdbb1ec":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","3b500a41":"pd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","942d1427":"importances = rf.feature_importances_\nindices = np.argsort(importances)","ba082de6":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df.columns[indices])\nplt.title('Importance des caracteristiques')","5f0f7f9f":"df = sns.load_dataset(\"iris\")","8b60474a":"df.head()","7ed37d8e":"sns.pairplot(df, hue=\"species\")","4e215fa7":"df.species.value_counts()","a74d856a":"df.columns","5efd62cc":"\ndata_train = df.sample(frac=0.7, random_state=1)         \ndata_test = df.drop(data_train.index)    ","ca5937d8":"X_train = data_train.drop(['species'], axis=1)\ny_train = data_train['species']\nX_test = data_test.drop(['species'], axis=1)\ny_test = data_test['species']","6a13f767":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","04478979":"y_lr = lr.predict(X_test)","56fa26d4":"print(accuracy_score(y_test, y_lr))","5f722f18":"pd.crosstab(y_test, y_lr, rownames=['Reel'], colnames=['Prediction'], margins=True)","4ea6a30d":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nprint(accuracy_score(y_test, y_dtc))","41cce7fc":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc, feature_names=X_train.columns, class_names=['setosa','versicolor','virginica'], fontsize=14, filled=True)  ","3cc72f8e":"fig = sns.FacetGrid(df, hue=\"species\", aspect=3)\nfig.map(sns.kdeplot, \"petal_width\", shade=True)\nfig.add_legend()","88314b68":"fig = sns.FacetGrid(df, hue=\"species\", aspect=3)\nfig.map(sns.kdeplot, \"sepal_width\", shade=True)\nfig.add_legend()","32bd1032":"dtc1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\ndtc1.fit(X_train,y_train)","467cf4f3":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc1, feature_names=X_train.columns, class_names=['setosa','versicolor','virginica'], fontsize=14, filled=True)  ","daaf32ff":"y_dtc1 = dtc1.predict(X_test)\nprint(accuracy_score(y_test, y_dtc1))","bf3f1587":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","df3540d8":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","708690bd":"pd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","5f8007a1":"importances = rf.feature_importances_\nindices = np.argsort(importances)","8d50eb1c":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df.columns[indices])\nplt.title('Importance des caracteristiques')","c486657c":"print('Ga\u00ebtan Duyck M2 MFSI | IAE LILLE')","905b8965":"Les **violins plots** sont similaires aux box plots, except\u00e9 qu\u2019ils permettent de montrer la courbe de densit\u00e9 de probabilit\u00e9 des diff\u00e9rentes valeurs. Typiquement, les violins plots pr\u00e9sentent un marqueur pour la m\u00e9diane des donn\u00e9es et l\u2019\u00e9cart interquartile, comme dans un box plot standard.","56ed10f4":"On a les informations suivantes :\n1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)  \nb) texture (standard deviation of gray-scale values)  \nc) perimeter  \nd) area  \ne) smoothness (local variation in radius lengths)  \nf) compactness (perimeter^2 \/ area - 1.0)  \ng) concavity (severity of concave portions of the contour)  \nh) concave points (number of concave portions of the contour)  \ni) symmetry  \nj) fractal dimension (\"coastline approximation\" - 1)  \n  \nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.  \n  \nAll feature values are recoded with four significant digits.","3783a5a0":"<img src=\"https:\/\/i.stack.imgur.com\/gKyb9.png\">","1ddbd9bc":"Et la matrice de confusion :","243d6064":"La colonne **'Unnamed: 32'** est vide : on va la supprimer ","3a3d553a":"On veut maintenant pr\u00e9dire l'esp\u00e8ce \u00e0 partir de toutes les caract\u00e9ristiques, et \u00e9valuer la qualit\u00e9 de cette pr\u00e9diction en utilisant la r\u00e9gression logistique d\u00e9finie dans la librairie *sklearn* :","69c32be7":"<img src=\"https:\/\/infinitescript.com\/wordpress\/wp-content\/uploads\/2016\/08\/Random-Forest-Example.jpg\">","888d2ac5":"On a un *faux positif* et deux *faux n\u00e9gatifs*","62bb768e":"## Le dataset Breast Cancer Wisconsin","ebcae0be":"cf par exemple :  \nhttps:\/\/fr.wikipedia.org\/wiki\/For%C3%AAt_d%27arbres_d%C3%A9cisionnels  \nhttps:\/\/www.biostars.org\/p\/86981\/  \nhttps:\/\/infinitescript.com\/2016\/08\/random-forest\/","faa4fef3":"## Score et matrice de confusion","910117ce":"*jointplot* permet de visualiser dans un plan les distributions d'un couple de param\u00e8tres :","0ab41162":"On peut tracer ce type de graphique avec des couleurs :","d15a1bb8":"Le dataset est accessible sur :  \nhttps:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data  \nhttp:\/\/archive.ics.uci.edu\/ml\/datasets\/breast+cancer+wisconsin+%28diagnostic%29  \n(on peut utiliser pd.read_table pour lire un fichier .dat)","f7fba4fa":"On peut aussi utiliser la m\u00e9thode **crosstab** de **Pandas** (plut\u00f4t que la m\u00e9thode confusion_matrix de sklearn) pour afficher la matrice de confusion :","ab0fad43":"## Machine learning","1dfccd73":"### Exercice : les iris","3c3cd01f":"## Random forests","c856d518":"### Importance des caract\u00e9ristiques","7935219b":"Pour construire un arbre de d\u00e9cision \u00e0 partir d'un ensemble d'apprentissage, on va choisir une variable qui s\u00e9pare l'ensemble en deux parties les plus distinctes en fonction d'un crit\u00e8re. Sur les iris par exemple, on peut utiliser la largeur du p\u00e9tale pour s\u00e9parer l'esp\u00e8ce Setosa des autres.","e15976f0":"Autrement dit, cela revient \u00e0 trouver une s\u00e9paration lin\u00e9aire des caract\u00e9ristiques qui minimise un crit\u00e8re d'erreur.","2489edb3":"Pour plus de d\u00e9tails, cf par exemple :  \nhttp:\/\/eric.univ-lyon2.fr\/~ricco\/cours\/cours\/pratique_regression_logistique.pdf","9c0f0a81":"La mesure de pertinence compte le nombre de fois o\u00f9 l'algorithme a fait une bonne pr\u00e9diction (en pourcentage) :","e6c8d36a":"Pour avoir l'ensemble du tableau, on peut utiliser un affichage au format HTML :","a5246520":"Appliquer les m\u00e9thodes de visualisation et de machine learning vues pr\u00e9c\u00e9demment sur ce dataset","0487f3a0":"On obtient un arbre un peu diff\u00e9rent :","f8c50c09":"On peut visualiser ces degr\u00e9s d'importance avec un graphique \u00e0 barres par exemple :","0db6cb29":"On s\u00e9pare les donn\u00e9es d'apprentissage (*X_train*) et la cible (*y_train*, la colonnes des donn\u00e9es *classe*)","365f70dc":"L'indice *GINI* mesure avec quelle fr\u00e9quence un \u00e9l\u00e9ment al\u00e9atoire de l'ensemble serait mal class\u00e9 si son \u00e9tiquette \u00e9tait s\u00e9lectionn\u00e9e al\u00e9atoirement depuis la distribution des \u00e9tiquettes dans le sous-ensemble.","784bbc3f":"## Librairies utiles","912009c6":"On s\u00e9pare le dataset en deux parties :\n- un ensemble d'apprentissage (entre 70% et 90% des donn\u00e9es), qui va permettre d'entra\u00eener le mod\u00e8le\n- un ensemble de test (entre 10% et 30% des donn\u00e9es), qui va permettre d'estimer la pertinence de la pr\u00e9diction","3bd92aa8":"Les **diagrammes en bo\u00eete** (ou **bo\u00eetes \u00e0 moustaches** ou **box plot**) r\u00e9sument quelques caract\u00e9ristiques de position du caract\u00e8re \u00e9tudi\u00e9 (m\u00e9diane, quartiles, minimum, maximum ou d\u00e9ciles). Ce diagramme est utilis\u00e9 principalement pour comparer un m\u00eame caract\u00e8re dans deux populations de tailles diff\u00e9rentes. Il s'agit de tracer un rectangle allant du premier quartile au troisi\u00e8me quartile et coup\u00e9 par la m\u00e9diane. On ajoute alors des segments aux extr\u00e9mit\u00e9s menant jusqu'aux valeurs extr\u00eames.  \nPar exemple pour la r\u00e9partion des esp\u00e8ces selon la longueur du s\u00e9pale :","5a5c810a":"On veut tracer un nuage de points selon le rayon et la texture de la tumeur, en diff\u00e9renciant la couleur des points selon le diagnostic :","25228a18":"On peut pr\u00e9dire les valeurs sur l'ensemble de test avec le mod\u00e8le entra\u00een\u00e9 :","c8f0e5af":"### Exercice  \nLe r\u00e9sultat est-il satisfaisant ?  \nQuel pourrait \u00eatre le probl\u00e8me ?","dba9eb6e":"## R\u00e9gression logistique","f910cf50":"<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQM3aH4Q3AplfE1MR3ROAp9Ok35fafmNT59ddXkdEvNdMkT8X6E\">","51461916":"## Visualisations","6ba51d5e":"On a les informations suivantes :\n- longueur du s\u00e9pale (en cm)\n- largeur du s\u00e9pale\n- longueur du p\u00e9tale\n- largeur du p\u00e9tale\n- esp\u00e8ce : Virginica, Setosa ou Versicolor","387c7fc1":"On peut tracer la courbe de r\u00e9gression logistique pour pr\u00e9dire l'esp\u00e8ce Virginica \u00e0 partir de la longueur du s\u00e9pale avec la fonction *lmplot* :","2a2d291d":"Le dataset des iris est pr\u00e9d\u00e9fini dans seaborn :","48c3357b":"L'attribut *feature_importances_* renvoie un tableau du poids de chaque caract\u00e9ristique dans la d\u00e9cision :","d33823ef":"## Arbres de d\u00e9cision","8430fe49":"Un arbre de d\u00e9cision permet de faire \u00e0 chaque \u00e9tape un choix entre deux possibilit\u00e9s, pour arriver \u00e0 une r\u00e9ponse sur les feuilles (cf. Akinator)  \n<img src=\"https:\/\/fr.akinator.com\/bundles\/elokencesite\/images\/akitudes_670x1096\/defi.png?v95\">","872f4c46":"Pour plus de d\u00e9tails sur les arbres de d\u00e9cision :  \nhttps:\/\/zestedesavoir.com\/tutoriels\/962\/les-arbres-de-decisions\/comprendre-le-concept\/#1-les-origines  \nhttp:\/\/cedric.cnam.fr\/vertigo\/Cours\/ml2\/tpArbresDecision.html  \nhttp:\/\/perso.mines-paristech.fr\/fabien.moutarde\/ES_MachineLearning\/Slides\/coursFM_AD-RF.pdf  ","36478220":"La fonction logistique $\\frac{e^{x}}{1+e^{x}}$ varie entre $-\\infty$ et $+\\infty$ pour $x$ variant entre $0$ et $1$.  \nElle est souvent utilis\u00e9e pour \"mapper\" une probabilit\u00e9 et un espace r\u00e9el","e370ac0a":"On peut afficher les 10 premi\u00e8res lignes du dataset :","ba5907d2":"# Breast cancer Wisconsin","f0b10277":"La r\u00e9gression logistique consiste \u00e0 trouver une fonction lin\u00e9aire C(X) qui permette d'estimer la probabilit\u00e9 de $Y=1$ connaissant $X$ :\n$$p(Y=1|X) = \\frac{e^{C(X)}}{1+e^{C(X)}}$$","78816a19":"On peut modifier certains param\u00e8tres :  Le param\u00e8tre *max_depth* est un seuil sur la profondeur maximale de l\u2019arbre. Le param\u00e8tre *min_samples_leaf* donne le nombre minimal d\u2019\u00e9chantillons dans un noeud feuille.","a2f89e85":"*pairplot* affiche les nuages de points associ\u00e9s \u00e0 tous les couples de param\u00e8tres :","bc681ba8":"## Donn\u00e9es","30cea462":"Une mesure plus fine consiste \u00e0 compter le nombre de **faux positif** (valeur pr\u00e9dite 1 et r\u00e9elle 0) et de **vrai n\u00e9gatif** (valeur pr\u00e9dite 0 et r\u00e9elle 1). On utilise une **matrice de confusion** :","ea1f34c4":"*FacetGrid* permet de superposer des graphiques selon une ou plusieurs caract\u00e9ristiques. On cr\u00e9e une structure avec *FacetGrid*, et on trace ensuite les graphiques avec *map*","f5f2b1ca":"On entra\u00eene le mod\u00e8le de r\u00e9gression logistique avec *fit* :","02979d1c":"On veut pr\u00e9dire une variable al\u00e9atoire $Y$ \u00e0 partir d'un vecteur de variables explicatives $X=(X_1,...,X_n)$\nOn \n"}}