{"cell_type":{"c1e73490":"code","96195bf5":"code","3015357c":"code","d07c7c84":"code","03bed787":"code","68b86ea0":"code","c26c217d":"code","2bbcbaa8":"markdown","a45e56eb":"markdown","76134f2d":"markdown","27e37234":"markdown","c500a513":"markdown","006406d6":"markdown","60c66ebe":"markdown","9e83c8b5":"markdown"},"source":{"c1e73490":"import numpy as np\nimport tensorflow as tf","96195bf5":"# creating the input data to our neural network\n# Are four elemtents of x1 and x2 columns\ndata_input_x = np.array([[0.0, 0.0], \n                         [0.0, 1.0],\n                         [1.0, 0.0],\n                         [1.0, 1.0]])\ndata_input_x","3015357c":"# creating the classification that we know to out input data ('classe' column)\n# XOR\ndata_y = np.array([[0], [1], [1], [0]])\ndata_y","d07c7c84":"# Define the variables used during de processing\n# Two weights to only one neuron\n# Weights are initialized with zero\ninput_neurons = 2\nhidden_neurons = 3\noutput_neurons = 1\n\nweights = { \n            # 3x2 matrix for weights between input layer and hidden layer\n            # initialize weights using randomic \n            'hidden_layer': tf.Variable(tf.random_normal([input_neurons,hidden_neurons]), name='weights_hidden_layer'), # 2x3 matrix\n    \n            # 2x3 matrix for weights betwwen hidden layer and ouput layer\n            'output_layer': tf.Variable(tf.random_normal([hidden_neurons, output_neurons]), name='weights_output_layer') # 3x1 matrix\n          }\n\n# define the bias\nbias = {\n        'hidden_layer': tf.Variable(tf.random_normal([hidden_neurons]), name='bias_hidden_layer'),\n        'output_layer': tf.Variable(tf.random_normal([output_neurons]), name='bias_output_layer')\n       }\n\n#\nrecords = len(data_input_x)\nx_placeholder = tf.placeholder(tf.float32, [records, input_neurons], name='xph')\ny_placeholder = tf.placeholder(tf.float32, [records, output_neurons], name='yph')\n\n# define our hidden layer calculation adding a bias\nhidden_layer = tf.add(tf.matmul(x_placeholder, weights['hidden_layer']), bias['hidden_layer'])\nhiddel_layer_activation = tf.sigmoid(hidden_layer)\n\n# define our outputlayer calculation\noutput_layer = tf.add(tf.matmul(hiddel_layer_activation, weights['output_layer']), bias['output_layer'])\n\n# define our activation function to transform the output layer values into knowed classes (0 or 1)\npredictions = tf.sigmoid(output_layer)\n\n# define score function to evaluate the accuracy\nerror = tf.losses.mean_squared_error(y_placeholder, predictions)\n\n# define function used to adjust the weights during the training\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(error)\n\n# Create the initializer function TensorFlow Variables used during the processing\ninit = tf.global_variables_initializer()","03bed787":"with tf.Session() as s:\n    s.run(init)\n    for epoch in range(10000):\n        mean_error = 0\n        _, cost = s.run([optimizer, error], feed_dict={ x_placeholder: data_input_x, y_placeholder: data_y})\n        if epoch % 200 == 0:\n            mean_error += cost \/ records\n            print('Epoch: ', epoch+1, ' - Mean Error: ', mean_error)\n            \n    best_weights, best_bias = s.run([weights, bias])","68b86ea0":"print('\\n\\nWeights to the best accuracy: \\n', best_weights)\nprint('\\n\\nBias to the best accuracy: \\n', best_bias)","c26c217d":"hidden_layer_test = tf.add(tf.matmul(x_placeholder, best_weights['hidden_layer']), best_bias['hidden_layer'])\nhiddel_layer_activation_test = tf.sigmoid(hidden_layer_test)\noutput_layer_test = tf.add(tf.matmul(hiddel_layer_activation_test, best_weights['output_layer']), best_bias['output_layer'])\npredictions_test = tf.sigmoid(output_layer_test)\nwith tf.Session() as s:\n    s.run(init)\n    print('Classes: \\n', s.run(predictions_test, feed_dict = { x_placeholder: data_input_x }))\n    # values very close to 0, 1, 1 and 0 as our XOR knowed classes value.","2bbcbaa8":"## TensorFlow implementation\n\n### Definitions\n","a45e56eb":"![XOR-Multi-Layer-Perceptron-with-TensorFlow](https:\/\/i.imgur.com\/nK0nPZK.png)\nSource: https:\/\/www.udemy.com\/tensorflow-machine-learning-deep-learning-python","76134f2d":"### Execution","27e37234":"## Import libraries","c500a513":"## Creating the data","006406d6":"### After trained, checking the final weights","60c66ebe":"### Evaluate","9e83c8b5":"# Multilayer Perceptron Neural Network with TensorFlow from zero\n\n## Introduction\n\n***This is a simple kernel to show on TensorFlow an implementation from zero of a multilayer perceptron solving a XOR and binary classification problem.***\n\nA XOR problem is more complex problem because it's not possible to separate the classes using a single line. \n\n## Scenario\n\nWe will implement a scenario represented by the image:\n    \n![Multi-Layer-Perceptron-with-TensorFlow](https:\/\/i.imgur.com\/BHSV7gc.png)\nSource: https:\/\/www.udemy.com\/tensorflow-machine-learning-deep-learning-python\n\nAnd, considering a non-linear problem (XOR)\n\n![XOR-Multi-Layer-Perceptron-with-TensorFlow](https:\/\/i.imgur.com\/nK0nPZK.png)\nSource: https:\/\/www.udemy.com\/tensorflow-machine-learning-deep-learning-python\n\n"}}