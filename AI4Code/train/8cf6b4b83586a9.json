{"cell_type":{"d7f71c40":"code","745e80b7":"code","b3790ec6":"code","a23df456":"code","2df2f48a":"code","ac89c657":"code","de5773ca":"code","505cb476":"code","6a2b52e2":"code","388848a9":"code","4996da35":"code","700bf179":"code","3b7e74e1":"code","4ab79356":"code","2cbbe3a1":"code","218fcf4d":"code","e4da4595":"code","d25840aa":"code","1adda0a1":"code","bad4bd23":"code","d26bc0e9":"code","46031745":"code","2f416527":"code","583c83d7":"code","457322d2":"code","d8b16561":"code","8752a6dd":"code","42ab52e6":"code","17c09f07":"markdown","0dda2163":"markdown","84dd2a5a":"markdown","2f422196":"markdown","8ab1eae0":"markdown","2e251c25":"markdown","433b3b79":"markdown","617160ee":"markdown","e3740b6a":"markdown","20bf70dc":"markdown","dddde181":"markdown","7a1e9bac":"markdown","ba2f6926":"markdown","2695cfda":"markdown","9da84de5":"markdown"},"source":{"d7f71c40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","745e80b7":"# import the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b3790ec6":"# read the dataset\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","a23df456":"# print shape of datasets\nprint('Shape of the train dataset : ', train_data.shape)\nprint('Shape of the test dataset : ', test_data.shape)","2df2f48a":"# let's check that if there is missing values in the dataset\nprint('Missing Values in Train Dataset : ', train_data.isnull().sum().sum())\nprint('Missing Values in Test Dataset : ', test_data.isnull().sum().sum())","ac89c657":"train_data.target.hist()","de5773ca":"# There are 258 attributes in the train dataset, which is infact not desirable\n# we need to select only a subset of columns (dimensionality reduction)\n# for that let's check that if there strong correlation exist between them\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = train_data.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","505cb476":"# handlng the categorical features\ntrain_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).columns","6a2b52e2":"labels = train_data['target']\ntrain_data = train_data.drop(['id','target'], axis=1)","388848a9":"# let us try a logistic regression model on the dataset\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size = 0.25, random_state = 0)","4996da35":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","700bf179":"# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","3b7e74e1":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","4ab79356":"from sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, y_pred)\nprint('ROC AUC for LR =',round(auc,5))","2cbbe3a1":"train_data['target'] = labels\n","218fcf4d":"# the medians of columns when we group the data by 'target' feature\ntarget_medians = train_data.groupby(\"target\").median()\ntarget_medians","e4da4595":"# let's calculate the difference b\/w row-1 and row-2\nsorted_target_distance = np.abs(target_medians.iloc[0]-target_medians.iloc[1]).sort_values(ascending=False)","d25840aa":"sorted_target_distance.head() # they do posses large difference b\/w the medians","1adda0a1":"sorted_target_distance.tail()","bad4bd23":"fig, ax = plt.subplots(2,2,figsize=(20,10))\nsns.distplot(train_data.loc[train_data.target==0, \"wheezy-myrtle-mandrill-entropy\"], color=\"Blue\", ax=ax[0,0])\nsns.distplot(train_data.loc[train_data.target==1, \"wheezy-myrtle-mandrill-entropy\"], color=\"Red\", ax=ax[0,0])\nsns.distplot(train_data.loc[train_data.target==0, \"wheezy-copper-turtle-magic\"], color=\"Blue\", ax=ax[0,1])\nsns.distplot(train_data.loc[train_data.target==1, \"wheezy-copper-turtle-magic\"], color=\"Red\", ax=ax[0,1])\nax[1,0].scatter(train_data[\"wheezy-myrtle-mandrill-entropy\"].values,\n                train_data[\"skanky-carmine-rabbit-contributor\"].values, c=train_data.target.values,\n                cmap=\"coolwarm\", s=1, alpha=0.5)\nax[1,0].set_xlabel(\"wheezy-myrtle-mandrill-entropy\")\nax[1,0].set_ylabel(\"skanky-carmine-rabbit-contributor\")\nax[1,1].scatter(train_data[\"wheezy-myrtle-mandrill-entropy\"].values,\n                train_data[\"wheezy-copper-turtle-magic\"].values, c=train_data.target.values,\n                cmap=\"coolwarm\", s=1, alpha=0.5)\nax[1,1].set_xlabel(\"wheezy-myrtle-mandrill-entropy\")\nax[1,1].set_ylabel(\"wheezy-copper-turtle-magic\");","d26bc0e9":"# consider the distribution of first three attributes from above list\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfeat1 = \"wheezy-myrtle-mandrill-entropy\"\nfeat2 = \"skanky-carmine-rabbit-contributor\"\nfeat3 = \"thirsty-carmine-corgi-ordinal\"\n\nN = 10000\n\ntrace1 = go.Scatter3d(\n    x=train_data[feat1].values[0:N], \n    y=train_data[feat2].values[0:N],\n    z=train_data[feat3].values[0:N],\n    mode='markers',\n    marker=dict(\n        color=train_data.target.values[0:N],\n        colorscale = \"Jet\",\n        opacity=0.3,\n        size=2\n    )\n)\n\nfigure_data = [trace1]\nlayout = go.Layout(\n    title = 'The turtle place',\n    scene = dict(\n        xaxis = dict(title=feat1),\n        yaxis = dict(title=feat2),\n        zaxis = dict(title=feat3),\n    ),\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    ),\n    showlegend=True\n)\n\nfig = go.Figure(data=figure_data, layout=layout)\npy.iplot(fig, filename='simple-3d-scatter')","46031745":"# consider the distribution of first two attributes and the last one 'wheezy-copper-turtle-magic' from above list\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfeat1 = \"wheezy-myrtle-mandrill-entropy\"\nfeat2 = \"skanky-carmine-rabbit-contributor\"\nfeat3 = \"wheezy-copper-turtle-magic\"\n\nN = 10000\n\ntrace1 = go.Scatter3d(\n    x=train_data[feat1].values[0:N], \n    y=train_data[feat2].values[0:N],\n    z=train_data[feat3].values[0:N],\n    mode='markers',\n    marker=dict(\n        color=train_data.target.values[0:N],\n        colorscale = \"Jet\",\n        opacity=0.3,\n        size=2\n    )\n)\n\nfigure_data = [trace1]\nlayout = go.Layout(\n    title = 'The turtle place',\n    scene = dict(\n        xaxis = dict(title=feat1),\n        yaxis = dict(title=feat2),\n        zaxis = dict(title=feat3),\n    ),\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    ),\n    showlegend=True\n)\n\nfig = go.Figure(data=figure_data, layout=layout)\npy.iplot(fig, filename='simple-3d-scatter')","2f416527":"# let's check the distribution of 'wheezy-copper-turtle-magic'\ntrain_data['wheezy-copper-turtle-magic'].hist()","583c83d7":"train_data['wheezy-copper-turtle-magic'].describe()","457322d2":"# INITIALIZE VARIABLES\ncols = [c for c in train_data.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\ninteractions = np.zeros((512,255))\noof = np.zeros(len(train_data))\npreds = np.zeros(len(test_data))","d8b16561":"from sklearn.model_selection import StratifiedKFold\n\n# BUILD 512 SEPARATE MODELS\nfor i in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train_data[train_data['wheezy-copper-turtle-magic']==i]\n    test2 = test_data[test_data['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n    \n    skf = StratifiedKFold(n_splits=25, random_state=42)\n    for train_index, test_index in skf.split(train2.iloc[:,1:-1], train2['target']):\n        # LOGISTIC REGRESSION MODEL\n        clf = LogisticRegression()\n        clf.fit(train2.loc[train_index][cols],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train2.loc[test_index][cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[cols])[:,1] \/ 25.0\n        # RECORD INTERACTIONS\n        for j in range(255):\n            if clf.coef_[0][j]>0: interactions[i,j] = 1\n            elif clf.coef_[0][j]<0: interactions[i,j] = -1\n    if i%25==0: print(i)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train_data['target'],oof)\nprint('LR with interactions scores CV =',round(auc,5))","8752a6dd":"# submit results\ntest_data['target'] = preds\nresult_data = test_data[['id', 'target']]\nresult_data.head()","42ab52e6":"result_data.to_csv('sample_submission.csv')","17c09f07":"### Logistic Regression","0dda2163":"### Logistic Regression With Interactions","84dd2a5a":"The distribution of <b>wheezy-copper-turtle-magic<\/b> is between (0, 512)","2f422196":"#### Distribution Of Classes In Label Column","8ab1eae0":"#### Step back and Start again","2e251c25":"Which shows that there is no correlation at all. Hmm, so what are the hidden patterns that I'm looking at!\n","433b3b79":"From the graph it is clear that there is no class imbalance problem.","617160ee":"#### First things first, Let's handle the missing values from dataset.","e3740b6a":"### The effect of 'wheezy-copper-turtle-magic'","20bf70dc":"We will create seperate 512 model for the unique values of the <b>wheezy-copper-turtle-magic<\/b>","dddde181":"Zero! What's happening here?","7a1e9bac":"The 2nd and 4th graph shows that the distribution of <b>wheezy-copper-turtle-magic<\/b> is spread across the space around it.","ba2f6926":"It is ~ 0.5, which says the model will predict an ouput with 50% confidence. <br>\nInfact a random value generator can perform better than this. <br>\nWhich shows that this is the worst case that can happen. <br>\nWhy do we get such a kind of result ? Does it have anything to do with the results of the correlation matrix ?","2695cfda":"To understand the effect of these distribution let us comapare the 2nd attribute and last one to the attribute in 1st solution.","9da84de5":"Previous LR model does not consider the interactions between the attributes. It treats the attributes as Independant Variables. <br> So we need to create an LR model by considering the interactions."}}