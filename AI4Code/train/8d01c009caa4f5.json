{"cell_type":{"cc9c5b7e":"code","85ea7f89":"code","1096793c":"markdown"},"source":{"cc9c5b7e":"from __future__ import print_function\nimport numpy as np\n\nfrom keras.preprocessing import sequence\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Embedding, SpatialDropout1D\nfrom keras.layers import LSTM, SimpleRNN, GRU\nfrom keras.regularizers import l2\nfrom keras.constraints import maxnorm\nfrom keras.datasets import imdb\n\nfrom keras import optimizers\n\nfrom keras import backend as K\nfrom keras import activations, initializers, regularizers, constraints\nfrom keras.layers import Layer, InputSpec\n\nfrom keras.utils.conv_utils import conv_output_length\n\ndef _dropout(x, level, noise_shape=None, seed=None):\n    x = K.dropout(x, level, noise_shape, seed)\n    x *= (1. - level) # compensate for the scaling by the dropout\n    return x\n\nclass QRNN(Layer):\n    '''Quasi RNN\n    # Arguments\n        units: dimension of the internal projections and the final output.\n    # References\n        - [Quasi-recurrent Neural Networks](http:\/\/arxiv.org\/abs\/1611.01576)\n    '''\n    def __init__(self, units, window_size=2, stride=1,\n                 return_sequences=False, go_backwards=False, \n                 stateful=False, unroll=False, activation='tanh',\n                 kernel_initializer='uniform', bias_initializer='zero',\n                 kernel_regularizer=None, bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None, bias_constraint=None, \n                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n                 **kwargs):\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.units = units \n        self.window_size = window_size\n        self.strides = (stride, 1)\n\n        self.use_bias = use_bias\n        self.activation = activations.get(activation)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = dropout\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.input_dim = input_dim\n        self.input_length = input_length\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_length, self.input_dim)\n        super(QRNN, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_dim = input_shape[2]\n        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n        self.state_spec = InputSpec(shape=(batch_size, self.units))\n\n        self.states = [None]\n        if self.stateful:\n            self.reset_states()\n\n        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n        self.kernel = self.add_weight(name='kernel',\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(name='bias', \n                                        shape=(self.units * 3,),\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        length = input_shape[1]\n        if length:\n            length = conv_output_length(length + self.window_size - 1,\n                                        self.window_size, 'valid',\n                                        self.strides[0])\n        if self.return_sequences:\n            return (input_shape[0], length, self.units)\n        else:\n            return (input_shape[0], self.units)\n\n    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            return mask\n        else:\n            return None\n\n    def get_initial_states(self, inputs):\n        # build an all-zero tensor of shape (samples, units)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n        initial_states = [initial_state for _ in range(len(self.states))]\n        return initial_states\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        if not self.input_spec:\n            raise RuntimeError('Layer has never been called '\n                               'and thus has no states.')\n\n        batch_size = self.input_spec.shape[0]\n        if not batch_size:\n            raise ValueError('If a QRNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 'state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, self.units)) +\n                                     ', found shape=' + str(value.shape))\n                K.set_value(state, value)\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is not None:\n            if hasattr(initial_state, '_keras_history'):\n                # Compute the full input spec, including state\n                input_spec = self.input_spec\n                state_spec = self.state_spec\n                if not isinstance(state_spec, list):\n                    state_spec = [state_spec]\n                self.input_spec = [input_spec] + state_spec\n\n                # Compute the full inputs, including state\n                if not isinstance(initial_state, (list, tuple)):\n                    initial_state = [initial_state]\n                inputs = [inputs] + list(initial_state)\n\n                # Perform the call\n                output = super(QRNN, self).__call__(inputs, **kwargs)\n\n                # Restore original input spec\n                self.input_spec = input_spec\n                return output\n            else:\n                kwargs['initial_state'] = initial_state\n        return super(QRNN, self).__call__(inputs, **kwargs)\n\n    def call(self, inputs, mask=None, initial_state=None, training=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_states = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_states = self.states\n        else:\n            initial_states = self.get_initial_states(inputs)\n\n        if len(initial_states) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_states)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        if self.unroll and input_shape[1] is None:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n\n        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n                                            initial_states,\n                                            go_backwards=self.go_backwards,\n                                            mask=mask,\n                                            constants=constants,\n                                            unroll=self.unroll,\n                                            input_length=input_shape[1])\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout < 1:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            return outputs\n        else:\n            return last_output\n\n    def preprocess_input(self, inputs, training=None):\n        if self.window_size > 1:\n            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n\n        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n                          padding='valid',\n                          data_format='channels_last')\n        output = K.squeeze(output, 2)  # remove the dummy dimension\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format='channels_last')\n\n        if self.dropout is not None and 0. < self.dropout < 1.:\n            z = output[:, :, :self.units]\n            f = output[:, :, self.units:2 * self.units]\n            o = output[:, :, 2 * self.units:]\n            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n            return K.concatenate([z, f, o], -1)\n        else:\n            return output\n\n    def step(self, inputs, states):\n        prev_output = states[0]\n\n        z = inputs[:, :self.units]\n        f = inputs[:, self.units:2 * self.units]\n        o = inputs[:, 2 * self.units:]\n\n        z = self.activation(z)\n        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n        o = K.sigmoid(o)\n\n        output = f * prev_output + (1 - f) * z\n        output = o * output\n\n        return output, [output]\n\n    def get_constants(self, inputs, training=None):\n        return []\n \n    def get_config(self):\n        config = {'units': self.units,\n                  'window_size': self.window_size,\n                  'stride': self.strides[0],\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'use_bias': self.use_bias,\n                  'dropout': self.dropout,\n                  'activation': activations.serialize(self.activation),\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'input_dim': self.input_dim,\n                  'input_length': self.input_length}\n        base_config = super(QRNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","85ea7f89":"import keras\n\nmax_features = 20000\nmaxlen = 80  # cut texts after this number of words (among top max_features most common words)\nbatch_size = 32 \n\nprint('Build model...')\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(QRNN(128, window_size=3, dropout=0.2, \n               kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4), \n               kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10)))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n# try using different optimizers and different optimizer configs\nopt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\nprint('Loading data...')\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(X_train), 'train sequences')\nprint(len(X_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nX_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nX_test = sequence.pad_sequences(X_test, maxlen=maxlen)\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\n\nprint('Train...')\nmodel.fit(X_train, y_train, batch_size=batch_size, epochs=7,\n          validation_data=(X_test, y_test))\nscore, acc = model.evaluate(X_test, y_test,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","1096793c":"# QRNN In Keras\n\nThis is a Kaggle kernel of an implementation of a Quasi-Recurrent Neural Network developed by James Bradbury, Stephen Merity, Caiming Xiong and Richard Socher from [Salesforce research] [1]. It was published at ICLR 2017 and a pdf of the paper can be found on [arXiv.] [2] The original Pytorch implementation of the QRNN found [here] [3] requires pynvrtc and CuPy making it harder to run on a kernel. Therefore, this kernel is based on a Keras implementation found [here] [4].\n\n### Why Does a  QRNN Work:\n\nThe sequential nature of RNNs doesn't allow the model to fully utilize the gpu. Since the activations of each timestep are fed into the inputs to find the activations of the next timestep, each timestep must be processed sequentially. A QRNN tries to limit the amount of sequential processing by using 1d convolutional layers to compute gate vectors concurrently and computing the outputs of the model sequentially in pooling layers. The effect of doing most of the computation concurrently in the conv layers and leaving the less computationally intensive tasks to the sequential pooling layers lets you speed up the speed of the network by up to 16 times! \n\nFor more information of QRNNs, please refer to [this] [5] blog post\n\n### Training\n\nThis model is trained on the IMDB movie reviews dataset to try to predict the sentiment of a particular movie review. An Adam Optimizer is used with the binary crossentropy loss.  After 7 epochs with no tuning, this model reaches a train accuracy of 0.95 and a test accuracy of 0.71. \n\n### Citation:\n\n> James Bradbury, Stephen Merity, Caiming Xiong, and Richard Socher. 2016.  \n> Quasi-Recurrent Neural Networks\n\n\n[1]: https:\/\/einstein.ai\/research\/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding\n[2]: https:\/\/arxiv.org\/abs\/1611.01576\n[3]: https:\/\/github.com\/salesforce\/pytorch-qrnn\n[4]: https:\/\/github.com\/DingKe\/nn_playground\/blob\/master\/qrnn\/README.md\n[5]: http:\/\/mlexplained.com\/2018\/04\/09\/paper-dissected-quasi-recurrent-neural-networks-explained\/"}}