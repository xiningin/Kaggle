{"cell_type":{"44313168":"code","d24e5101":"code","5cf72e65":"code","0efa016f":"code","8a89a738":"code","d4db2e2a":"code","1c131a38":"code","3635bad8":"code","65956e6f":"code","1cb3c01c":"code","14864cde":"code","d358cd90":"code","1bdcd912":"code","24895426":"code","b4048e93":"code","c10f533f":"code","536e9ed8":"code","cc5582fe":"code","4ce7618b":"code","775d6a6f":"code","02eee03c":"code","e536068f":"code","954aa373":"code","0c16e6ed":"code","0e23589a":"code","d0e661e5":"code","a1eae790":"code","848a73b1":"code","88748164":"code","097ff9b0":"code","2cbc0bc3":"code","c205fa64":"code","4ce52053":"code","420c9ffb":"code","b6418152":"code","b22a4cb3":"code","6b18206c":"code","36a33d27":"code","91e44605":"code","effda00e":"code","f6f2110c":"code","3fb57a17":"code","ee06e82c":"code","2bbf8662":"code","5f1978d6":"code","c046a746":"code","06144916":"code","908441cf":"code","fdcd84c5":"code","6f0ebbf9":"code","42217246":"code","ef633b62":"code","16d4db83":"code","d147035f":"code","faad7096":"code","2f8a3be2":"code","48857f77":"code","d436013c":"code","2ecdabab":"code","0434560f":"code","a5d7b065":"code","91005880":"markdown","dd8ec17b":"markdown","e85fc95d":"markdown","a3da703e":"markdown","dc76c4f4":"markdown","980d2425":"markdown","da8792e4":"markdown","8b391825":"markdown","7cc189f1":"markdown","cda0d51a":"markdown","a98598b3":"markdown","6b519756":"markdown","ee95d3a4":"markdown","a53c8e3c":"markdown","a4b4d356":"markdown","12e7a91f":"markdown","dfa21d9d":"markdown","43aa856b":"markdown","36572249":"markdown","bd9f437d":"markdown","bdd52ff6":"markdown","6269cdc2":"markdown","084f363d":"markdown","63bf70cc":"markdown","bdc6e543":"markdown","8e1b485c":"markdown","ad855403":"markdown","c221d006":"markdown","256f46ec":"markdown","0141c79b":"markdown","fff11cce":"markdown","08046fb1":"markdown","ac96897f":"markdown","8c7d8bf8":"markdown","37f2b6cb":"markdown","a5ce0d55":"markdown","7f58b7b1":"markdown","2dd51fff":"markdown","2ea6974e":"markdown","4de2d0a1":"markdown","20b9c0fd":"markdown","8c928b1c":"markdown","d34fdacd":"markdown","0cf8898e":"markdown"},"source":{"44313168":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf=pd.read_csv(\"..\/input\/data.csv\")\ndf.head()","d24e5101":"df.isnull().sum()\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","5cf72e65":"sns.countplot(x='target',data=df,palette='rainbow')","0efa016f":"sns.countplot(x='target',data=df,palette='rainbow',hue='mode')","8a89a738":"sns.countplot(x='target',data=df,hue='time_signature',palette='rainbow')","d4db2e2a":"df.info()","1c131a38":"df1=df.drop(['song_title','artist'],axis=1)","3635bad8":"df1.info()","65956e6f":"y=df1['target']\nx=df1.drop(['target'],axis=1)\ny.shape","1cb3c01c":"plt.figure(figsize=(15,5))\nsns.heatmap(df1.corr(),annot=True)","14864cde":"# split X and y into training and testing sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=0)","d358cd90":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","1bdcd912":"predictions = logmodel.predict(X_test)\npredictions[1:10]","24895426":"#plt.scatter(y_test,predictions)\nsns.distplot(predictions-y_test,hist=True,vertical=False,color='r')","b4048e93":"logmodel.coef_\nlogmodel.intercept_","c10f533f":"#Calculate Accuracy \nfrom sklearn import metrics\nmetrics.accuracy_score(y_test,predictions)","536e9ed8":"1-metrics.accuracy_score(y_test,predictions)","cc5582fe":"y_test.value_counts()","4ce7618b":"# calculate the percentage of ones\ny_test.mean()","775d6a6f":"# calculate the percentage of zeros\n1-y_test.mean()","02eee03c":"# calculate null accuracy (for binary classification problems coded as 0\/1)\nmax(y_test.mean(), 1 - y_test.mean())","e536068f":"#print first 20 actual value and its corresponding predictions value \u00b6\n\nprint('20 Actual Value:',y_test.values[0:20])\nprint('20 Predicted Value:',predictions[0:20])","954aa373":"from sklearn import metrics\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\nlist1 = [\"Actual 0\", \"Actual 1\"]\nlist2 = [\"Predicted 0\", \"Predicted 1\"]\npd.DataFrame(confusion_matrix, list1,list2)","0c16e6ed":"# save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_test, predictions)\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nprint('TN:',TN)\nprint('TP:',TP)\nprint('FN:',FN)\nprint('FP:',FP)","0e23589a":"Accuracy_Score=(TP+TN)\/(TP+TN+FP+FN)\nAccuracy_Score","d0e661e5":"metrics.accuracy_score(y_test,predictions)","a1eae790":"Misclassification_Rate=(FP+FN)\/(TP+TN+FP+FN)\nMisclassification_Rate","848a73b1":"1-metrics.accuracy_score(y_test,predictions)","88748164":"Sensitivity=TP\/(TP+FN)\nSensitivity","097ff9b0":"metrics.recall_score(y_test, predictions)","2cbc0bc3":"Specificity=TN\/(TN+FP)\nSpecificity","c205fa64":"FPR=FP\/(FP+TN)\nFPR","4ce52053":"FNR=FN\/(FN+TP)\nFNR","420c9ffb":"Precision=TP\/(TP+FP)\nPrecision","b6418152":"metrics.precision_score(y_test,predictions)","b22a4cb3":"Prevalence = (TP+FN)\/(TP+FN+FP+TN)\nPrevalence","6b18206c":"FDR= FP\/(TP+FP)\nFDR","36a33d27":"FOR = FN\/(TN+FN)\nFOR","91e44605":"NPV = TN\/(TN+FN)\nNPV","effda00e":"PLR = Sensitivity\/FPR\nPLR","f6f2110c":"NLR=FNR\/Specificity\nNLR","3fb57a17":"DOR=PLR\/NLR\nDOR","ee06e82c":"F1_Score=2\/((1\/Sensitivity)+(1\/Precision))\nF1_Score","2bbf8662":"#print first 20 actual value and its corresponding predictions value \u00b6\n\nprint('10 Actual Value:',y_test.values[0:10])\nprint('10 Predicted Value:',predictions[0:10])","5f1978d6":"# print the first 10 predicted probabilities of class membership\nlogmodel.predict_proba(X_test)[:10]\n\n#predict_proba gives you the probabilities for the target (0 and 1 in your case) in array form. \n#The number of probabilities for each row is equal to the number of categories in target variable 4\n#(2 in your case).\n\n# i.e. prob of 0 is 0.55004114 and prob of 1 is 0.44995886 hence in logmodel.predict(X_test)[0:10] will give \n# output as 0 as class variable(0) has dominancy in terms of probablity value","c046a746":"# print the first 10 predicted probabilities for class 0\nprint(logmodel.predict_proba(X_test)[0:10, 0])\n\nprint(\"$$$$$$$$$$$$$$$$$$$$$$#####################$$$$$$$$$$$$$$$$\")\n\n# print the first 10 predicted probabilities for class 1\nprint(logmodel.predict_proba(X_test)[0:10, 1])","06144916":"# store the predicted probabilities for class 1\ny_pred_prob_1 = logmodel.predict_proba(X_test)[:, 1]\n\n# store the predicted probabilities for class 0\ny_pred_prob_0 = logmodel.predict_proba(X_test)[:, 0]\n\ny_pred_prob=logmodel.predict_proba(X_test)","908441cf":"plt.figure(figsize=(15,5))\nplt.hist(y_pred_prob_1,bins=8,color='g')\nplt.xlim(0, 1)\nplt.title('Histogram of predicted probabilities of music like')\nplt.xlabel('Predicted probability whether i would like music')\nplt.ylabel('Frequency')\n\n\nplt.figure(figsize=(15,5))\nplt.hist(y_pred_prob_0,bins=8,color='r')\nplt.xlim(0, 1)\nplt.title('Histogram of predicted probabilities of donot likemusic')\nplt.xlabel('Predicted probability whether i would not like music')\nplt.ylabel('Frequency')","fdcd84c5":"# predict like or dislike of music if the predicted probability is greater than 0.3\nfrom sklearn.preprocessing import binarize\ny_pred_class = binarize([y_pred_prob_1], 0.3)[0]","6f0ebbf9":"# print the first 10 predicted probabilities\nprint(y_pred_prob[0:10])\n\nprint(\"##############################################\")\n\n\n# print the first 10 predicted classes with the lower threshold\nprint(y_pred_class[0:10])","42217246":"# previous confusion matrix (default threshold of 0.5)\nprint(confusion)\n\n# new confusion matrix (threshold of 0.3)\nprint(metrics.confusion_matrix(y_test, y_pred_class))","ef633b62":"# sensitivity has increased (used to be  0.5830618892508144)\nprint(\"Before:\",179\/ float(179 + 128))\n\n# sensitivity has increased (used to be  0.5830618892508144)\nprint(\"Now at 0.3 threshold:\",307\/ float(307 + 0))\n\n# specificity has decreased (used to be 0.46488294314381273)\nprint(\"Specificity Before:\",139 \/ float(139 + 160))\n\n# specificity has decreased (used to be 0.46488294314381273)\nprint(\"Specificity at 0.3 threshold:\",0 \/ float(0 + 299))","16d4db83":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\nFPR, TPR, thresholds = metrics.roc_curve(y_test, predictions)\nplt.plot(FPR, TPR)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","d147035f":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(y_test, predictions))","faad7096":"# calculate cross-validated AUC\nfrom sklearn.cross_validation import cross_val_score\ncross_val_score(logmodel, x, y, cv=10, scoring='roc_auc').mean()","2f8a3be2":"plt.figure(figsize=(15,5))\nsns.heatmap(df1.corr(),annot=True)\n\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(df1, alpha=0.2, figsize=(20,20), diagonal='kde')\ndf1.corr(method='pearson', min_periods=1)","48857f77":"df.info()","d436013c":"df2=df\ny1=df2['target']\nx1=df2.drop(['song_title','artist','target','loudness','energy','danceability','instrumentalness'],axis=1)\nplt.figure(figsize=(15,5))\nsns.heatmap(x1.corr(),annot=True)","2ecdabab":"# split X and y into training and testing sets\nfrom sklearn.cross_validation import train_test_split\nX1_train, X1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.30,random_state=0)\n\nfrom sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X1_train,y1_train)\n\npredictions1 = logmodel.predict(X1_test)\npredictions1[1:10]","0434560f":"#Calculate Accuracy \nfrom sklearn import metrics\nmetrics.accuracy_score(y1_test,predictions1)","a5d7b065":"from sklearn import metrics\nconfusion_matrix=metrics.confusion_matrix(y1_test,predictions1)\nlist1 = [\"Actual 0\", \"Actual 1\"]\nlist2 = [\"Predicted 0\", \"Predicted 1\"]\npd.DataFrame(confusion_matrix, list1,list2)","91005880":"** Important Formula **\nNegative Likelyhood Ratio : (LR-)   It is ratio of Miss Rate to the Specificity or Selectivity","dd8ec17b":"<h5> Try to Find Classification accuracy means percentage of correct prediction, false \n    predictions and then print first 20 actual value and its corresponding predictions value <\/h5>","e85fc95d":"**Classification Accuracy:** Overall, how often is the classifier correct?","a3da703e":"**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n\n- How \"sensitive\" is the classifier to detecting positive instances?\n- Also known as \"True Positive Rate\" or \"Recall\"","dc76c4f4":"**Classification Error:** Overall, how often is the classifier incorrect?\n\n- Also known as \"Misclassification Rate\"","980d2425":"<h5> Missing Data  <\/h5>","da8792e4":"<h8> there is no missing data in our dataset <\/h8>\n<h9> Let's continue on by visualizing some more of the data! and learn about our dataset <\/h9>","8b391825":"** False Omission Rate ** It is False Negative out of Predicted Condition Negative\n\nFOR = FN\/(TN+FN)","7cc189f1":"<h8> An estimated overall time signature of a track. The time signature (meter) is a notational convention \nto specify how many beats are in each bar (or measure). <\/h8>","cda0d51a":"- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself","a98598b3":"**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?","6b519756":"**Conclusion:**\n\n- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n\n**Which metrics should you focus on?**\n\n- Choice of metric depends on your **business objective**\n- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)","ee95d3a4":"<h8> Converting Categorical Features <\/h8>\n<h9> We'll need to convert categorical features to dummy variables using pandas! \nOtherwise our machine learning algorithm won't be able to directly take in those features as inputs. <\/h9>\n\n<h10> since we have categorical variable song_title, artist which doesnot impact more as this is just  <\/h10>","a53c8e3c":"** Negative Predicted Value ** ","a4b4d356":"## Metrics computed from a confusion matrix","12e7a91f":"**Basic terminology**\n\n- **True Positives (TP):** we *correctly* predicted that i *do* have interest or like music\n- **True Negatives (TN):** we *correctly* predicted that i *do* have interest or does not like music\n- **False Positives (FP):** we *incorrectly* predicted that i *do* have interest or like music (a \"Type I error\")\n- **False Negatives (FN):** we *incorrectly* predicted that i *do* have interest or does not like music(a \"Type II error\")","dfa21d9d":"<h8> <b> Classification accuracy <\/b> : percentage of correct predictions <\/h8>","43aa856b":"** False Discovery Rate ** It is False Positive out of Predicted Condition Positive\n\nFDR = FP\/(TP+FP)","36572249":"<h8> <b> Classification accuracy <\/b> <\/h8> : percentage of incorrect predictions","bd9f437d":"## ROC Curves and Area Under the Curve (AUC)\n\n**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n\n**Answer:** Plot the ROC curve!","bdd52ff6":"**Confusion matrix advantages:**\n\n- Allows you to calculate a **variety of metrics**\n- Useful for **multi-class problems** (more than two response classes)\n\n**ROC\/AUC advantages:**\n\n- Does not require you to **set a classification threshold**\n- Still useful when there is **high class imbalance**","6269cdc2":"**Precision:** When a positive value is predicted, how often is the prediction correct?\n\n- How \"precise\" is the classifier when predicting positive instances?","084f363d":"** Important Formula **\nDiagnostic Odds Ratio :  It is ratio of LR+ to the LR-","63bf70cc":"**Specificity:** When the actual value is negative, And model also predicts negative meaning how often is the prediction correct in that case?\n\n- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?","bdc6e543":"AUC is the **percentage** of the ROC plot that is **underneath the curve**:","8e1b485c":"<h5> Spotify Song Attributes <\/h5>\nAn attempt to build a classifier that can predict whether or not I like a song","ad855403":"**Conclusion:**\n\n- Classification accuracy is the **easiest classification metric to understand**\n- But, it does not tell you the **underlying distribution** of response values\n- And, it does not tell you what **\"types\" of errors** your classifier is making","c221d006":"** Important Formula **\nPositive Likelyhood Ratio : (LR+)   It is ratio of Sensitivity or recall to the Fall out or \n                                    Probability of False Alarm","256f46ec":"** Important Formula **\nF1-Score :  2\/((1\/Recall)+(1\/Precision))","0141c79b":"<h8> Energy and loudness can be removed as both variables have dependency\non each other.. however we will try this later <\/h8>","fff11cce":"<h5> Fitting The Model <\/h5>","08046fb1":"<h5> Train Test Split <\/h5>","ac96897f":"**It seems there is no change in confusion matrix hence we can only increase model efficiency by transformation**","8c7d8bf8":"- Every observation in the testing set is represented in **exactly one box**\n- It's a 2x2 matrix because there are **2 response classes**\n- The format shown here is **not** universal","37f2b6cb":"<h8> Now check Examine the class distribution of the testing set <\/h8> ","a5ce0d55":"<h5> <b> Building a Logistic Regression model <\/b> <\/h5>","7f58b7b1":"***  Iterations Number 2 ***\n- After plotting correlation matrix we can see that loudeness and energy are highly correlation hence causing \n multicolinearity hence we will remove say loudness variable and will keep energy only","2dd51fff":"**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier","2ea6974e":"**Conclusion:**\n\n- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n- Threshold can be **adjusted** to increase sensitivity or specificity\n- Sensitivity and specificity have an **inverse relationship**","4de2d0a1":"## Confusion matrix\n\nTable that describes the performance of a classification model","20b9c0fd":"**False Negative Rate:** When the actual value is positive, how often is the prediction incorrect?","8c928b1c":"Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc.","d34fdacd":"**Prevalence:** How many positive are there out of total Population\n- Prevalence = Condition Positive (TP+FN) \/ Total Population(TP+FN+FP+TN)","0cf8898e":"- AUC is useful as a **single number summary** of classifier performance.\n- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."}}