{"cell_type":{"44c9b197":"code","cad04047":"code","64b57ac4":"code","057cfff0":"code","f38a3bdf":"code","421ac9cf":"markdown","03309c2f":"markdown","7e5dc892":"markdown","ae886e25":"markdown","028060b3":"markdown"},"source":{"44c9b197":"# Imports for Deep Learning\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# ensure consistency across runs\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)\n\n# Imports to view data\nimport cv2\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom numpy import floor\nimport random\n\ndef plot_three_samples(letter):\n    print(\"Samples images for letter \" + letter)\n    base_path = '..\/input\/asl_alphabet_train\/asl_alphabet_train\/'\n    img_path = base_path + letter + '\/**'\n    path_contents = glob(img_path)\n    \n    plt.figure(figsize=(16,16))\n    imgs = random.sample(path_contents, 3)\n    plt.subplot(131)\n    plt.imshow(cv2.imread(imgs[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(imgs[1]))\n    plt.subplot(133)\n    plt.imshow(cv2.imread(imgs[2]))\n    return\n\nplot_three_samples('A')","cad04047":"plot_three_samples('B')","64b57ac4":"data_dir = \"..\/input\/asl_alphabet_train\/asl_alphabet_train\"\ntarget_size = (64, 64)\ntarget_dims = (64, 64, 3) # add channel for RGB\nn_classes = 29\nval_frac = 0.1\nbatch_size = 64\n\ndata_augmentor = ImageDataGenerator(samplewise_center=True, \n                                    samplewise_std_normalization=True, \n                                    validation_split=val_frac)\n\ntrain_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\nval_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")","057cfff0":"my_model = Sequential()\nmy_model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims))\nmy_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\nmy_model.add(Dropout(0.5))\nmy_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\nmy_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\nmy_model.add(Dropout(0.5))\nmy_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\nmy_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\nmy_model.add(Flatten())\nmy_model.add(Dropout(0.5))\nmy_model.add(Dense(512, activation='relu'))\nmy_model.add(Dense(n_classes, activation='softmax'))\n\nmy_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])","f38a3bdf":"my_model.fit_generator(train_generator, epochs=15,steps_per_epoch=100,validation_data=val_generator,validation_steps=50)","421ac9cf":"# Intro\nKaggle provides free access to NVidia K80 GPUs in kernels. \n\nThe following text shows how to enable a GPU and gives details on the benchmark.\n\n\n# Adding a GPU\nWe set up this kernel to run on a GPU by first opening the kernel controls.\n\n![Imgur](https:\/\/i.imgur.com\/WY2p6bH.png)\n___\nSelect the **Settings** tab. Then select the checkbox for **Enable GPU**. Verify the GPU is attached to your kernel in the console bar, where it should show **GPU ON** next to your resource usage metrics.\n\n![Imgur](https:\/\/i.imgur.com\/F9Hd3DN.png)\n___\n*GPU backed instances have less CPU power and RAM. Moreover, many data science libraries cannot take advantage of a GPU.  So, GPU's will be valuable for some tasks (especially when using deep learning libraries like TensorFlow, Keras and PyTorch).  But you are better off without a GPU for most other tasks.*","03309c2f":"# Data Processing Set-Up","7e5dc892":"# The data\n\nThe dataset contains images with 29 different signs in American Sign Language. These are the 26 letters (A through Z) plus the signs for *space*, *delete* and *nothing*. Our model will view these images and learn to classify what sign is made in each image.\n\nSample images below\n","ae886e25":"# Model Fitting","028060b3":"# Model Specification"}}