{"cell_type":{"4ad9b5d8":"code","7ebc4c29":"code","52a9184e":"code","1860c5fa":"code","8ff4f8fb":"code","43fd2006":"code","8f935644":"code","c779ac79":"code","2647c717":"code","1029e6fb":"code","4c2b2d20":"code","153e9d69":"code","7a2dd5cb":"code","6418bd55":"code","96402423":"code","f7fe6d31":"code","597c0c71":"code","be39c6cb":"code","09bcbd6c":"code","eb24405c":"code","c1d92d88":"code","bb4249eb":"code","ea3a0b72":"code","1195884b":"code","19bb90d8":"code","04f12adf":"code","e1960441":"code","667d48b4":"code","5becb14a":"code","ef4f49c8":"code","5cc085c5":"code","84f3a28a":"code","51198ca1":"code","7d0e17b9":"code","a94780c2":"code","01b33a3e":"code","418ae29a":"markdown","f9d2fc9e":"markdown"},"source":{"4ad9b5d8":"import os\nimport random\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader","7ebc4c29":"data_dir = '..\/input\/brain-tumor-mri-dataset\/Training'\ntest_dir = '..\/input\/brain-tumor-mri-dataset\/Testing'\nclasses = os.listdir(data_dir)\nprint(classes)\nprint(len(classes))","52a9184e":"train_transform=transforms.Compose([\n        transforms.RandomRotation(10),      # rotate +\/- 10 degrees\n        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n        transforms.Resize(80),             # resize shortest side\n        transforms.CenterCrop(80),         # crop longest side\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n])","1860c5fa":"dataset = ImageFolder(data_dir, transform=train_transform)\ntestset = ImageFolder(test_dir, transform=train_transform)","8ff4f8fb":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(img.shape)","43fd2006":"# function for the showing the image.\ndef show_image(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1,2,0))","8f935644":"show_image(*dataset[20])","c779ac79":"show_image(*dataset[100])","2647c717":"torch.manual_seed(10)\nval_size = len(dataset)\/\/10\ntest_size = len(testset)\ntrain_size = len(dataset) - val_size","1029e6fb":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\ntest_ds = testset\nlen(train_ds), len(val_ds), len(test_ds)   ","4c2b2d20":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)","153e9d69":"for images, labels in train_loader:\n    fig, ax = plt.subplots(figsize=(18,10))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n    break","7a2dd5cb":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","6418bd55":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","96402423":"torch.cuda.is_available()","f7fe6d31":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","597c0c71":"device = get_default_device()\ndevice","be39c6cb":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","09bcbd6c":"input_size = 3*80*80\noutput_size = len(classes)","eb24405c":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                   # Generate predictions\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","c1d92d88":"class CnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 100, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(100, 150, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Conv2d(150, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(200, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Conv2d(200, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(250, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Flatten(), \n            nn.Linear(25000, 64),  \n            nn.ReLU(),            \n            nn.Linear(64, 32),  \n            nn.ReLU(),            \n            nn.Linear(32, 16),           \n            nn.ReLU(),\n            nn.Linear(16, 8),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(8, output_size))\n        \n    def forward(self, xb):\n        return self.network(xb)","bb4249eb":"model = CnnModel()\n#model.cuda()","ea3a0b72":"model","1195884b":"for images, labels in train_loader:\n    out = model(images)\n    print('images.shape:', images.shape)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","19bb90d8":"device = get_default_device()\ndevice","04f12adf":"train_dl = DeviceDataLoader(train_loader, device)\nval_dl = DeviceDataLoader(val_loader, device)\nto_device(model, device)","e1960441":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","667d48b4":"model = to_device(CnnModel(), device)","5becb14a":"history=[evaluate(model, val_loader)]\nhistory","ef4f49c8":"num_epochs = 30\nopt_func = torch.optim.Adam\nlr = 0.001","5cc085c5":"history+= fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","84f3a28a":"#history+= fit(num_epochs, lr\/10, model, train_dl, val_dl, opt_func)","51198ca1":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","7d0e17b9":"plot_accuracies(history)","a94780c2":"plot_losses(history)","01b33a3e":"evaluate(model, test_loader)","418ae29a":"# Brain Tumor MRI Torch Conv2d","f9d2fc9e":"# Conv2d Model"}}