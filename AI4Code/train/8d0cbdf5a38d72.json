{"cell_type":{"4f21d04b":"code","2072a929":"code","c56e2c83":"code","26918be0":"code","8985d602":"code","b3469ced":"code","d5e8c25a":"code","2771ce89":"code","e7badb43":"code","f7c6cd88":"code","fc82afab":"code","64fc241b":"code","6dca6e92":"code","8ae022f5":"code","b4dde739":"code","10543d5d":"code","87d1869b":"code","c17f8659":"code","376ef0c7":"code","2f080a8b":"code","bd2face5":"code","f263c164":"code","3fd2286b":"code","553287ab":"code","92b639fe":"code","47a4056b":"code","cfbe619d":"code","c729325b":"code","89505f5f":"code","19c28d92":"code","9f548de4":"code","58bb28ab":"code","c15bbce7":"code","fe695616":"code","5f229592":"code","42a343b5":"code","786ef963":"code","8c1f1248":"code","9f414ca3":"code","97057bd5":"code","3bd74259":"code","968c2341":"code","a980cbeb":"code","d2cee477":"code","facbc846":"code","dd079a8d":"code","52383ba4":"code","4e436ed6":"code","50bf4a13":"code","82d00ce1":"code","f2b497c0":"code","b458d24d":"code","a59581e3":"code","28baa3bc":"code","b7ad6fc2":"code","d9d83c50":"code","acd12b32":"code","db6b983c":"code","de571be4":"markdown","72cf2920":"markdown","fae7c8c6":"markdown","c221cd79":"markdown","d31f62b2":"markdown","aa99d395":"markdown","b40d47d3":"markdown","3e89c585":"markdown"},"source":{"4f21d04b":"import numpy as np \nimport pandas as pd","2072a929":"data = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","c56e2c83":"df= data.copy()","26918be0":"df.head()","8985d602":"df.tail()","b3469ced":"df.shape","d5e8c25a":"df.info()","2771ce89":"df.describe().T","e7badb43":"df.isna().sum()","f7c6cd88":"import seaborn as sns","fc82afab":"sns.boxplot(df['age'])","64fc241b":"sns.boxplot(df['trestbps'])","6dca6e92":"sns.boxplot(df['chol'])","8ae022f5":"sns.boxplot(df['thalach'])","b4dde739":"sns.boxplot(df['oldpeak'])","10543d5d":"all_outliers=['trestbps','oldpeak','thalach','chol']","87d1869b":"from numpy import quantile\nfor outlier in range(len(all_outliers)):\n    med= df[all_outliers[outlier]].median()\n    q15= df[all_outliers[outlier]].quantile(0.25)\n    q85= df[all_outliers[outlier]].quantile(0.75)\n    IQR= (q85-q15)*1.5\n    low, upp= q15-IQR, q85+IQR\n    df[all_outliers[outlier]]= df[all_outliers[outlier]].apply(lambda x: med if x<low else x)\n    df[all_outliers[outlier]]= df[all_outliers[outlier]].apply(lambda x: med if x>upp else x)","c17f8659":"df.head(2)","376ef0c7":"df.head(2)","2f080a8b":"# 0 --> not having heart disease\n# 1 --> having heart disease","bd2face5":"import matplotlib.pyplot as plt","f263c164":"categ=['sex','cp','fbs','restecg','exang','slope','ca','thal','target']\nfor i in range(len(categ)):\n    sns.countplot(df[categ[i]])\n    plt.show()","3fd2286b":"sns.distplot(df['age'])","553287ab":"plt.figure(figsize=(15,6))\nsns.countplot(x=df['age'],hue=df['target'],data=df,palette=\"Set3\")","92b639fe":"sns.violinplot(x=df['target'],y=df['age'])","47a4056b":"sns.violinplot(x=df['target'],y=df['chol'])","cfbe619d":"sns.distplot(df['thalach'])","c729325b":"sns.violinplot(x=df['target'],y=df['thalach'])","89505f5f":"plt.figure(figsize=(20,15))\nsns.catplot(data=df,orient='h')","19c28d92":"df.head(2)","9f548de4":"df['sex'].value_counts()","58bb28ab":"sns.violinplot(x=df['sex'],y=df['target'])","c15bbce7":"sns.countplot(x='sex',data=df,hue='target')","fe695616":"sns.violinplot(x=df['target'],y=df['trestbps'])","5f229592":"sns.violinplot(x=df['target'],y=df['oldpeak'])","42a343b5":"df['fbs'].value_counts()","786ef963":"sns.violinplot(x=df['target'],y=df['fbs'])","8c1f1248":"sns.countplot(x=df['fbs'],data=df,hue='target')","9f414ca3":"col=['sex','cp','fbs','restecg','exang','slope','ca','thal']\ndf_new=pd.get_dummies(df, columns=col)\ndf_new.head()","97057bd5":"df_new.corr()","3bd74259":"plt.figure(figsize=(22,22))\nsns.heatmap(df_new.corr(),cmap='coolwarm',annot=True)","968c2341":"plt.figure(figsize=(14,6))\ndf_new.drop('target', axis=1).corrwith(df_new.target).plot(kind = 'bar', grid = True,title = \"Correlation with target\")","a980cbeb":"df_new.head(1)","d2cee477":"X=df_new[['thalach','oldpeak','cp_0','exang_0','exang_1','ca_0','thal_2','thal_3']]\nX.head()","facbc846":"y=df_new['target']\ny.head()","dd079a8d":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score","52383ba4":"x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=40)","4e436ed6":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","50bf4a13":"x_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","82d00ce1":"x_train","f2b497c0":"x_train.shape, y_train.shape","b458d24d":"# logistic regression\n\nlog=LogisticRegression()\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of LogisticRegression model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of LR model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of LR model   --->   ',f1_score(y_test,pred))","a59581e3":"# RandomForestClassifier\nl=[]\nj=[]\nfor i in range(1,150):\n    log=RandomForestClassifier(n_estimators=i)\n    log.fit(x_train,y_train)\n    pred=log.predict(x_test)\n    ac=round((accuracy_score(pred,y_test)*100),2)\n    l.append(ac)\n    j.append(i)\nmaxi=l.index(max(l))\nind=j[maxi]\n# print(max(l),ind)\n\nlog=RandomForestClassifier(n_estimators=ind)\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of RandomForestClassifier model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of RandomForestClassifier model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of RandomForestClassifier model   --->   ',f1_score(y_test,pred))","28baa3bc":"# SVC\n\nlog=SVC(kernel='sigmoid',C=0.1)\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of SVC model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of SVC model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of SVC model   --->   ',f1_score(y_test,pred))","b7ad6fc2":"# DecisionTreeClassifier\n\nlog=DecisionTreeClassifier()\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of DecisionTreeClassifier model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of DecisionTreeClassifier model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of DecisionTreeClassifier model   --->   ',f1_score(y_test,pred))","d9d83c50":"# KNeighborsClassifier\nl=[]\nj=[]\nfor i in range(1,100):\n    log=KNeighborsClassifier(n_neighbors=i)\n    log.fit(x_train,y_train)\n    pred=log.predict(x_test)\n    ac=round((accuracy_score(pred,y_test)*100),2)\n    l.append(ac)\n    j.append(i)\nmaxi=l.index(max(l))\nind=j[maxi]\nlog=KNeighborsClassifier(n_neighbors=ind)\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of KNeighborsClassifier model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of KNeighborsClassifier model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of KNeighborsClassifier model   --->   ',f1_score(y_test,pred))","acd12b32":"# XGBClassifier\n\nlog=XGBClassifier()\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of XGBClassifier model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of XGBClassifier model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of XGBClassifier model   --->   ',f1_score(y_test,pred))\n# sns.heatmap(confusion_matrix(y_test,pred),cmap='coolwarm',annot=True)","db6b983c":"# GradientBoostingClassifier\n\nlog=GradientBoostingClassifier(max_depth=4, n_estimators=700)\nlog.fit(x_train,y_train)\npred=log.predict(x_test)\nacc=round((accuracy_score(pred,y_test)*100),2)\nprint('Accuracy of LogisticRegression model is  --->  ',acc)\nprint('\\n')\nprint('Confusion Matrix   ---->  \\n',confusion_matrix(y_test,pred))\nprint('\\n')\nprint('precision_score of LR model   --->   ',precision_score(y_test,pred))\nprint('\\n')\nprint('f1score of LR model   --->   ',f1_score(y_test,pred))","de571be4":"# Data Correlation","72cf2920":"**Taking threshold correlation of data features with target as greater than 0.4 or less than -0.4 we concludes that features --> ['thalach','oldpeak','cp_0','exang_0','exang_1','ca_0','thal_2','thal_3'] are highly important**","fae7c8c6":"# TRAINING AND TESTING THE DATA USING ML MODELS","c221cd79":"**checking null value if any**","d31f62b2":"# WE HAVE ACHIEVED HIGHEST ACCURACY  OF 93.42 % USING KNN MODEL","aa99d395":"**Removing outliers**","b40d47d3":"**Checking outliers**","3e89c585":"# Exploratory Data Analysis(EDA)"}}