{"cell_type":{"e72c2ef1":"code","0d46e043":"code","7a246e49":"code","1c98bd14":"code","3ba8f83a":"code","cfec06de":"code","7c2402dd":"code","1bd34956":"code","88a20e57":"code","8f72249a":"code","d183b82a":"code","ee8117bf":"code","f9c68ef7":"code","d4a3e5b9":"code","26ab9020":"code","4c5ed6e7":"code","fdc94b84":"code","15403783":"code","3917923a":"code","f40e86e9":"code","deb04b58":"code","a3624d16":"code","1946d58e":"code","6257e6a1":"code","d4e6a80f":"code","c7cc79e8":"code","39c036df":"markdown","0df591ea":"markdown","e853a24c":"markdown","42180cb0":"markdown","77dccaf7":"markdown","bdc836bd":"markdown","e303a10d":"markdown","36239c1d":"markdown","0787d467":"markdown","c8bf502f":"markdown","1cb6a9c3":"markdown","80b3ebe1":"markdown","04ada21b":"markdown","b233c061":"markdown","5bc3882b":"markdown","df623fa0":"markdown","aef00782":"markdown","9e88b13a":"markdown","d7f37ea6":"markdown","21b8561b":"markdown","5a481e41":"markdown","05513942":"markdown"},"source":{"e72c2ef1":"!pip install scikit-learn-intelex --progress-bar off >> \/tmp\/pip_sklearnex.log\nfrom sklearnex import patch_sklearn\npatch_sklearn()","0d46e043":"import os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split","7a246e49":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv', index_col='PassengerId')\ntest = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv', index_col='PassengerId')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv', index_col='PassengerId')\n\ntarget = train.pop('Survived')","1c98bd14":"train.head()","3ba8f83a":"train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","cfec06de":"train.info()","7c2402dd":"test_prepared = test.copy()\ntrain_prepared = train.copy()\n\ntest_prepared['Age'].fillna((train['Age'].median()), inplace=True)\ntrain_prepared['Age'].fillna((train['Age'].median()), inplace=True)\n\ntest_prepared['Fare'].fillna((train['Fare'].median()), inplace=True)\ntrain_prepared['Fare'].fillna((train['Fare'].median()), inplace=True)\n\ntest_prepared['Embarked'].fillna('S', inplace=True)\ntrain_prepared['Embarked'].fillna('S', inplace=True)","1bd34956":"train_prepared.info()","88a20e57":"test_prepared.info()","8f72249a":"for col in ['Pclass', 'Sex', 'Embarked']:\n    le = LabelEncoder()\n    le.fit(train_prepared[col])\n    train_prepared[col] = le.transform(train_prepared[col])\n    test_prepared[col] = le.transform(test_prepared[col])","d183b82a":"train_prepared.head()","ee8117bf":"train_prepared.describe()","f9c68ef7":"train_prepared_scaled = train_prepared.copy()\ntest_prepared_scaled = test_prepared.copy()\n\nscaler = StandardScaler()\nscaler.fit(train_prepared)\ntrain_prepared_scaled = scaler.transform(train_prepared_scaled)\ntest_prepared_scaled = scaler.transform(test_prepared_scaled)\n\ntrain_prepared_scaled = pd.DataFrame(train_prepared_scaled, columns=train_prepared.columns)\ntest_prepared_scaled = pd.DataFrame(test_prepared_scaled, columns=train_prepared.columns)","d4a3e5b9":"train_prepared_scaled.describe()","26ab9020":"X_train, X_valid, y_train, y_valid = train_test_split(train_prepared_scaled, target, test_size=0.1, random_state=0)","4c5ed6e7":"%%time\nlinear_svc = LinearSVC(random_state=0, C=0.01, loss='hinge')\nlinear_svc.fit(X_train, y_train)\ny_pred = linear_svc.predict(X_valid)\naccuracy_score(y_pred, y_valid)","fdc94b84":"%%time\nfinal_pred = linear_svc.predict(test_prepared_scaled)","15403783":"submission['Survived'] = np.round(final_pred).astype(int)\nsubmission.to_csv('svc_kernel_linear.csv')","3917923a":"%%time\nsvc_kernel_rbf = SVC(kernel='rbf', random_state=0, C=0.01)\nsvc_kernel_rbf.fit(X_train, y_train)\ny_pred = svc_kernel_rbf.predict(X_valid)\naccuracy_score(y_pred, y_valid)","f40e86e9":"%%time\nfinal_pred = svc_kernel_rbf.predict(test_prepared_scaled)","deb04b58":"submission['Survived'] = np.round(final_pred).astype(int)\nsubmission.to_csv('svc_kernel_rbf.csv')","a3624d16":"%%time\nsvc_kernel_poly_3 = SVC(kernel='poly', degree=3, random_state=0, C=0.01)\nsvc_kernel_poly_3.fit(X_train, y_train)\ny_pred = svc_kernel_poly_3.predict(X_valid)\naccuracy_score(y_pred, y_valid)","1946d58e":"%%time\nfinal_pred = svc_kernel_poly_3.predict(test_prepared_scaled)","6257e6a1":"submission['Survived'] = np.round(final_pred).astype(int)\nsubmission.to_csv('svc_kernel_poly_3.csv')","d4e6a80f":"%%time\nn_folds = 10\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\ny_pred = np.zeros(test.shape[0])\n\nfor fold, (train_index, valid_index) in enumerate(kf.split(train_prepared_scaled, target)):\n    print(\"Running Fold {}\".format(fold + 1))\n    X_train, X_valid = pd.DataFrame(train_prepared_scaled.iloc[train_index]), pd.DataFrame(train_prepared_scaled.iloc[valid_index])\n    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n    svc_kernel_rbf = SVC(kernel='rbf', random_state=0, C=0.01)\n    svc_kernel_rbf.fit(X_train, y_train)\n    print(\"  Accuracy: {}\".format(accuracy_score(y_valid, svc_kernel_rbf.predict(X_valid))))\n    y_pred += svc_kernel_rbf.predict(test_prepared_scaled)\n\ny_pred \/= n_folds\n\nprint(\"\")\nprint(\"Done!\")","c7cc79e8":"submission['Survived'] = np.round(y_pred).astype(int)\nsubmission.to_csv('svc_kernel_rbf_10_folds.csv')","39c036df":"The Public LB score for the following submission file is **0.79062**, \"which is an improvement from our previous score\". \ud83d\ude0f","0df591ea":"We are good to go! :)\n\nLet's split the train set into 90% training and 10% validation data.","e853a24c":"The Public LB score for the following submission file is **0.79062**, the same obtained with only one split.","42180cb0":"Prediction is now very fast with scikit-learn-intelex. Without it, the followging cell would take about 5 minutes.","77dccaf7":"Now let's see if we have missing data.","bdc836bd":"The Public LB score for the following submission file is **0.78505**. After some investigation I realized that this classifier is pratically using only the variable **Sex** for classification. Specifically, it predicts that all women survive and all men die. So the SVC with a linear kernel does not help us at all. But hey, we had to try it!","e303a10d":"# Load libraries and data","36239c1d":"We do. Here we take a simple approach and just fill **Age** and **Fare** with their median value (using the train data). For **Embarked**, we fill the NAs with its most frequent value, which is 'S'.","0787d467":"# SVC with polynomial kernel\n\nAnother popular choice is to use a polynomial kernel. Here I tried a 3rd degree polynomial, but other values could be used as well. \n\nThe Extension **scikit-learn-intelex** did not speed up the computations in this case. The following cell will take several minutes to run.","c8bf502f":"The Public LB score for the following submission file is **0.76709**, \"which is *not* an improvement from our previous score\". In fact, it's even worse than what we obtained with a linear kernel. \ud83d\ude10","1cb6a9c3":"# **Support Vector Machines**\n\nI have not seen anyone using a Support Vector Classifier in this competition yet, so how about we try it and see how it performs? \ud83d\udc40\n\nIf this method is new to you, I strongly recommend the following videos from the great **StatQuest** channel. They will give you a good grasp of what is going on.\n\n* [Support Vector Machines: Main Ideas!!!](https:\/\/www.youtube.com\/watch?v=efR1C6CvhmE)\n* [Support Vector Machines: The Polynomial Kernel](https:\/\/www.youtube.com\/watch?v=Toet3EiSFcM)\n* [Support Vector Machines: The Radial (RBF) Kernel](https:\/\/www.youtube.com\/watch?v=Qc5IyLW_hns)\n\nIf you are curious about other ML techniques as well, check the other videos in the channel. They are clear and also funny. BAM!!! \ud83d\ude03","80b3ebe1":"Prediction will also take a few minutes here.","04ada21b":"## Preprocessing\n\nThe features **Name**, **Ticket** and **Cabin** don't seem to be useful, so let's drop them.","b233c061":"The last preprocessing step will be scaling all variables because Support Vector Machines do not work well with variables in different scales.","5bc3882b":"# Conclusion\n\nI found it interesting that the Support Vector Classifier with a linear kernel seems to be influenced only by one of the variables. If you have an explanation (or a guess) for this fact, please leave a comment.\n\nThis was the first time that I used this technique and it was fun to play with it. Hope you enjoyed this brief notebook too! \ud83d\ude09","df623fa0":"# Final submission with 10 folds\n\nTo finish off, let's predict survival with 10-fold cross-validation using the RBF kernel. The following cell will take over 2 hours to run.","aef00782":"By glancing at the train dataframe, it seems like we have missing data and some features that we may not need.","9e88b13a":"### Updates\n\n**Version 4**: added 10-fold cross validation.\n\n**Version 5**: added *scikit-learn-intelex* extension, reccomended by @napetrov (see [this notebook](https:\/\/www.kaggle.com\/napetrov\/tps04-svm-with-intel-extension-for-scikit-learn)).","d7f37ea6":"Now the data is complete. Let's encode the categorical variables **Pclass**, **Sex** and **Embarked**.","21b8561b":"# SVC with RBF kernel\n\nLet's now use the *kernel trick* with an RBF kernel. For this, we need to use the class SVC and set `kernel='rbf'`. The parameter `C` did not have an influence for some of the values I tested, but it ran faster when I set it to low values, so that's why I chose 0.01.\n\nBefore Version 5 of this notebook, the following cell would take 10 minutes to run. With **scikit-learn-intelex** enabled, it takes less than a minute.","5a481e41":"# SVC with linear kernel\n\nIf we want to use a linear kernel, `LinearSVC` is the recommended class because of its speed. Here it runs in a fraction of a second!","05513942":"## Enabling scikit-learn-intelex"}}