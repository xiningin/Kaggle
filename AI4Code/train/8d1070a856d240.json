{"cell_type":{"3575c50b":"code","282f4934":"code","d681dc10":"code","4f36aca7":"code","c1c511b7":"code","53e77904":"code","cd5898f4":"code","4cfd7f76":"code","ab70e321":"code","c8301e8f":"code","55e54c80":"code","c5447124":"code","c6fa6f12":"code","abe236ba":"code","217739da":"code","e982c920":"code","1023206b":"code","8b194d5a":"markdown","49b8dc77":"markdown","98fb82cd":"markdown","5b64888a":"markdown","4d6b677a":"markdown","6b624781":"markdown","8efd791a":"markdown","b1384361":"markdown"},"source":{"3575c50b":"KAGGLE = True","282f4934":"IPATH = '..\/input\/detectron-05\/whls'\nif KAGGLE:\n    !pip install {IPATH}\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n    !pip install {IPATH}\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n    !pip install {IPATH}\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n    !pip install {IPATH}\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls \n    !pip install ..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\/ -f .\/ --no-index","d681dc10":"import os\nimport cv2\nimport json\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport detectron2\nfrom tqdm.auto import tqdm\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.evaluation import inference_on_dataset\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.data import DatasetCatalog, build_detection_test_loader\nimport pycocotools.mask as mask_util\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom fastcore.all import *\nfrom ensemble_boxes import *\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' if KAGGLE else '1'\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\n    print('GPU is available')\nelse:\n    DEVICE = torch.device('cpu')\n    print('CPU is used')\nprint('detectron ver:', detectron2.__version__)","4f36aca7":"config1 = 'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml'\nconfig2 = 'Misc\/cascade_mask_rcnn_R_50_FPN_3x.yaml'\nconfig3 = 'COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml'\n\nmdl_path1 = \"..\/input\/best-transfer-100k\"\n#mdl_path2=\"..\/input\/best-100k-firstrun\"\n\nbest_models=(\n  \n        {'file': 'model_x101_pseudo.pth','LB score': 0.314, 'CV Score': 0.298, 'ths':[.19, .39, .67],'config':config3},\n        {'file': 'model_cascade_pseudo.pth','LB score': 0.311, 'CV Score': 0.292, 'ths':[.19, .39, .73],'config':config2},\n         # {'file': 'model_mask_r50.pth','LB score': 0.307, 'CV Score': 0.3079, 'ths':[.15, .35, .58],'config':config1},\n            )\n\n\nDATA_PATH = \"..\/input\/sartorius-cell-instance-segmentation\"\nMODELS = []\nBEST_MODELS =[]\nTHSS = []\nID_TEST = 0\nSUBM_PATH = f'{DATA_PATH}\/test'\nSINGLE_MODE = False\nNMS = True\nMIN_PIXELS = [75, 150, 75]\nIOU_TH = .4\n\nfor model in best_models:\n    model_name=model[\"file\"]\n    model_ths=model[\"ths\"]\n    config=model['config']\n    BEST_MODELS.append(model_name)\n    THSS.append(model_ths)\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(config))\n    cfg.INPUT.MASK_FORMAT = 'bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n    cfg.MODEL.WEIGHTS = f'{mdl_path1}\/{model_name}'  \n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n\n    cfg.TEST.FLIP = True\n    cfg.TEST.PRECISE_BN.NUM_ITER = 200\n    \n    MODELS.append(DefaultPredictor(cfg))\nprint(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')","c1c511b7":"def rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) \n                       for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef pred_masks(file_name, path, model, ths, min_pixels):\n    img = cv2.imread(f'{path}\/{file_name}')\n    output = model(img)\n    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n    pred_class = max(set(pred_classes), key=pred_classes.count)\n    take = output['instances'].scores >= ths[pred_class]\n    pred_masks = output['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    result = []\n    used = np.zeros(img.shape[:2], dtype=int) \n    for i, mask in enumerate(pred_masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result\n\ndef ensemble_preds(file_name, path, models, ths):\n    img = cv2.imread(f'{path}\/{file_name}')\n    classes = []\n    scores = []\n    bboxes = []\n    masks = []\n    for i, model in enumerate(models):\n        output = model(img)\n        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n        pred_class = max(set(pred_classes), key=pred_classes.count)\n        take = output['instances'].scores >= ths[i][pred_class]\n        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n    scores, classes, bboxes, masks = zip(\n        *sorted(zip(scores, classes, bboxes, masks), \n                reverse=True))\n    return classes, scores, bboxes, masks\n\ndef nms_predictions(classes, scores, bboxes, masks, \n                    iou_th=.5, shape=(520, 704)):\n    he, wd = shape[0], shape[1]\n    boxes_list = [[x[0] \/ wd, x[1] \/ he, x[2] \/ wd, x[3] \/ he]\n                  for x in bboxes]\n    scores_list = [x for x in scores]\n    labels_list = [x for x in classes]\n    nms_bboxes, nms_scores, nms_classes = nms(\n        boxes=[boxes_list], \n        scores=[scores_list], \n        labels=[labels_list], \n        weights=None,\n        iou_thr=iou_th\n    )\n    nms_masks = []\n    for s in nms_scores:\n        nms_masks.append(masks[scores.index(s)])\n    nms_scores, nms_classes, nms_masks = zip(\n        *sorted(\n            zip(nms_scores, nms_classes, nms_masks), \n            reverse=True))\n    return nms_classes, nms_scores, nms_masks\n\ndef ensemble_pred_masks(masks, classes, min_pixels, shape=(520, 704)):\n    result = []\n    pred_class = max(set(classes), key=classes.count)\n    used = np.zeros(shape, dtype=int) \n    for i, mask in enumerate(masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result","53e77904":"test_names = os.listdir(SUBM_PATH)\nprint('test images:', len(test_names))","cd5898f4":"encoded_masks_single = pred_masks(\n    test_names[ID_TEST], \n    path=SUBM_PATH, \n    model=MODELS[0],\n    ths=THSS[0],\n    min_pixels=MIN_PIXELS\n)","4cfd7f76":"classes, scores, bboxes, masks = ensemble_preds(\n    file_name=test_names[ID_TEST] , \n    path=SUBM_PATH, \n    models=MODELS, \n    ths=THSS\n)\nif NMS:\n    classes, scores, masks = nms_predictions(\n        classes, \n        scores, \n        bboxes,\n        masks, \n        iou_th=IOU_TH\n    )\nencoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)","ab70e321":"'''_, axs = plt.subplots(2, 2, figsize=(14, 8))\naxs[0][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[0][0].axis('off')\naxs[0][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks_single:\n    dec_mask = rle_decode(en_mask)\n    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[0][1].axis('off')\n    axs[0][1].set_title('single model')\naxs[1][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[1][0].axis('off')\naxs[1][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks:\n    dec_mask = rle_decode(en_mask)\n    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[1][1].axis('off')\n    axs[1][1].set_title('ensemble models')\nplt.show()\n'''","c8301e8f":"# create dict key from bbox\ndef bbox_to_key(bbox):\n    return str(np.round(bbox, 6))\n\n# TTA inputs:\n# file: image to process\n# predictor_list: list of predictors to use, single or multiple for ensembling\n# aug_list: list of augmentations to perform. Augmentations must be \"bidirectional\" - applying twice will get back to original.\n#           Also augmentations must support image, bboxes and masks\ndef TTA(file, predictor_list, aug_list=[None]):\n    boxes = []\n    box_scores = []\n    masks = []\n    masks_lkup =[]\n    pclass = []\n    im = cv2.imread(file)\n    for predict in predictor_list:\n        for aug in aug_list:\n            # perform augmentations\n            if aug is not None:\n                transform = aug\n                ima = transform(image=im)['image']\n            else:\n                ima = im\n            # make prediction\n            pred = predict(ima)\n            h, w = pred['instances'].image_size[0], pred['instances'].image_size[1]\n            classes = pred['instances'].pred_classes.cpu().numpy()-1\n            if len(pclass) == 0:\n                pclass = classes\n            else:\n                pclass = np.concatenate((pclass, classes))\n            # get box predictions, and nomrmalize to 0-1 range\n            pred_boxes = [A.normalize_bbox(box, h, w) for box in pred['instances'].pred_boxes.tensor.cpu().numpy()]\n            # transform back to original\n            if aug is not None:\n                pred_boxes = transform(image=ima, bboxes=pred_boxes)['bboxes']\n            # get mask prediction\n            pred_masks = pred['instances'].pred_masks.cpu().numpy()*1\n            # transform back to original\n            if aug is not None:\n                pred_masks = transform(image=ima, masks=pred_masks)['masks']\n            # lookup table for bbox to mask index reference\n            pred_dict = {}\n            for i in range(len(pred_boxes)):\n                pred_dict[bbox_to_key(pred_boxes[i])] = i\n            # append results to list\n            boxes.append(np.array(pred_boxes))\n            box_scores.append(np.array(pred['instances'].scores.detach().cpu().numpy()))\n            masks.append(np.array(pred_masks, dtype=np.uint8))\n            masks_lkup.append(pred_dict)\n    \n            del pred, pred_boxes, pred_masks, ima, pred_dict\n    \n    del im\n    gc.collect()\n    predicted_class = stats.mode(pclass)[0][0]\n    return boxes, box_scores, masks, masks_lkup, predicted_class","55e54c80":"predictor20 = MODELS[0]\nfrom detectron2.utils.visualizer import Visualizer","c5447124":"TITLES = ['Original', 'Horizontal flip', 'Vertical flip', 'Rotation 180']\n\ndef plt_pred(file):\n    fig = plt.figure(figsize=(20,15))\n    im = cv2.imread(file)\n    # org\n    fig.add_subplot(2, 2, 1)\n    plt.tight_layout()\n    outputs = predictor20(im)\n    v = Visualizer(im[:, :, ::-1])\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.title(TITLES[0])\n    plt.imshow(out.get_image()[:, :, ::-1]);\n    # flip horizontal\/vertical\/both\n    for i in range(1, -2, -1):\n        imh = cv2.flip(im, i)\n        fig.add_subplot(2, 2, 3-i)\n        plt.tight_layout()\n        outputs = predictor20(imh)\n        v = Visualizer(imh[:, :, ::-1])\n        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n        plt.title(TITLES[2-i])\n        plt.imshow(out.get_image()[:, :, ::-1]);\n\nFILE = '..\/input\/sartorius-cell-instance-segmentation\/test\/7ae19de7bc2a.png'\nplt_pred(FILE)","c6fa6f12":"import albumentations as A\nimport gc\nfrom scipy import stats","abe236ba":"AUGMENTATIONS = [None, A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0), A.Rotate(limit=(180,180), p=1.0)]\n\nimg_org = cv2.imread(FILE)\nboxes, box_scores, masks, masks_lkup, pred_class = TTA(FILE, [MODELS[0]], AUGMENTATIONS)\n\ndef show_boxes(im, boxes_list, h, w, color=(31, 119, 180), orig=False):\n    thickness = 2\n    idx = 0\n    if orig:\n        idx = 4\n    for i in range(len(boxes_list)):\n        x1 = int(h * boxes_list[i][idx])\n        y1 = int(w * boxes_list[i][idx+1])\n        x2 = int(h * boxes_list[i][idx+2])\n        y2 = int(w * boxes_list[i][idx+3])\n        cv2.rectangle(im, (x1, y1), (x2, y2), color, thickness)\n    return im\n\nfig = plt.figure(figsize=(20, 15))\ncolumns = 2\nrows = (len(AUGMENTATIONS)\/\/columns) + (len(AUGMENTATIONS) % 2)\nfor i in range(1,len(AUGMENTATIONS)+1):\n    fig.add_subplot(rows, columns, i)\n    plt.tight_layout()\n    img = img_org\n    img = show_boxes(img, boxes[i-1], img.shape[1], img.shape[0])\n    plt.title(TITLES[i-1])\n    plt.imshow(img)\n    \nplt.show();","217739da":"def show_masks(im, masks_list, h, w):\n    m = np.zeros((w,h), dtype=np.uint8)\n    for i in range(len(masks_list)):\n        m = np.logical_or(m, masks_list[i])\n    return im * np.dstack([m]*3)\n\nfig = plt.figure(figsize=(20, 15))\ncolumns = 2\nrows = (len(AUGMENTATIONS)\/\/columns) + (len(AUGMENTATIONS) % 2)\nfor i in range(1,len(AUGMENTATIONS)+1):\n    fig.add_subplot(rows, columns, i)\n    plt.tight_layout()\n    img = img_org\n    plt.imshow(show_masks(img, masks[i-1], img.shape[1], img.shape[0]))\n    plt.title(TITLES[i-1])\nplt.show();","e982c920":"subm_ids, subm_masks = [], []\nfor test_name in tqdm(test_names):\n    FILE = test_name\n    boxes, box_scores, masks, masks_lkup, pred_class = TTA(SUBM_PATH+'\/'+FILE, [MODELS[0]], AUGMENTATIONS) #, MODELS[1]\n    encoded_masks=[]\n\n    for mask in masks:\n        enc_mask  = rle_encode(mask)\n        subm_masks.append(enc_mask)\n        subm_ids.append(test_name[:test_name.find('.')])","1023206b":"pd.DataFrame({\n    'id': subm_ids, \n    'predicted': subm_masks\n}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()\n","8b194d5a":"Based on these excellent notebooks [Positive score with Detectron 2\/3 - Training](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-2-3-training) and [Positive score with Detectron 3\/3 - Inference](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-3-3-inference). Please upvote them.\n\n[Weighted boxes fusion](https:\/\/github.com\/ZFTurbo\/Weighted-Boxes-Fusion) library is also used.","49b8dc77":"# Detectron: ensemble inference with NMS","98fb82cd":"## Config load","5b64888a":"## Utils","4d6b677a":"## Inference","6b624781":"## Acknowledgements","8efd791a":"## Demo inference","b1384361":"## Install and import libraries"}}