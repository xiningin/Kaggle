{"cell_type":{"9734ddc3":"code","0bcb7f02":"code","8753f8b2":"code","eea4be60":"code","d047835f":"code","19460b1c":"code","3c187d96":"code","26b66641":"code","7420d39a":"code","1699a314":"code","cf9805d3":"code","d5974b91":"code","dce0aee2":"code","74cf624b":"code","0629a612":"code","539934bc":"code","3728e530":"code","d1c2fe25":"code","b25e359d":"code","f7a118ae":"code","e8f02c0c":"code","96864a39":"code","644ee081":"code","92e379ba":"code","5360327d":"code","cea9160f":"code","e2c9603e":"code","3e0782ba":"code","96c28407":"code","b1c3bd0e":"code","3f1ea3ed":"code","bfe0cc8d":"code","8b1ff2bf":"code","9addc20e":"code","aa731c5b":"code","2f5dde80":"code","ff59480e":"code","84c31af6":"code","5c9fc360":"code","ec773126":"code","50af5dcc":"code","e6b8a79c":"code","6fb58ac7":"code","13c43a83":"code","d2cbd922":"code","f3e7370c":"code","4b968e19":"markdown","f65087d8":"markdown","73900dc0":"markdown","599bf8a7":"markdown","0b18b05f":"markdown","16a9dfc8":"markdown","03aff32d":"markdown","1f636caf":"markdown","ef25a415":"markdown","0aaa6990":"markdown","68ab290a":"markdown","7b305611":"markdown","447fe68f":"markdown","021f8151":"markdown","1f6879b4":"markdown","296b4907":"markdown","75457baa":"markdown","90a7b741":"markdown","2ea27dd9":"markdown","63e14e8b":"markdown","ff071088":"markdown","25956134":"markdown","179ca37b":"markdown","4c71f53a":"markdown","324874b4":"markdown","4c1fb09d":"markdown","98e11c35":"markdown","27eb6ebf":"markdown","7e1d72b1":"markdown","93b976a2":"markdown"},"source":{"9734ddc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0bcb7f02":"# Carregando o arquivo\ndf = pd.read_csv('\/kaggle\/input\/hmeq-data\/hmeq.csv')\n\ndf.shape","8753f8b2":"df.head(20).T","eea4be60":"# Tipos e quantidades\ndf.info()","d047835f":"# Apagar as linhas que aparecen Nan na coluna Reason\ndf = df.dropna(subset=['REASON'])\ndf.head(20).T","19460b1c":"# Para coluna JOB eu vou imputar o dado \"Other\" nas linhas que tiverem Nan\ndf.update(df['JOB'].fillna('Other'))\ndf.head(20).T","3c187d96":"# Preenchendo o restante dos valores Nan com 0\n\ndf.fillna(0, inplace=True)","26b66641":"df.info()","7420d39a":"df.describe().T","1699a314":"# Quantidade de inadimplentes e empr\u00e9stimo reembolsado\n\ndf['BAD'].value_counts().plot.bar()","cf9805d3":"# Os 10 maiores pedidos de empr\u00e9stimos\n# DebtCon = consolida\u00e7\u00e3o da d\u00edvida\n\ndf.nlargest(10, 'LOAN')[['REASON', 'YOJ', 'LOAN']].style.hide_index()","d5974b91":"# Top 5 com maior tempo de empresa\ndf.nlargest(5, 'YOJ')[['MORTDUE', 'YOJ']].style.hide_index()","dce0aee2":"# M\u00e9dia de tempo de trabalho no emprego atual por tipo de trabalho\ndf.groupby('JOB')['YOJ'].mean()","74cf624b":"# Quantitativo por JOB\ndf['JOB'].value_counts().plot.bar()","0629a612":"plt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nfig=sns.boxplot(x='LOAN', data=df, orient='v', color='#ffffb2')\nfig.set_title('BoxPlot de Empr\u00e9stimo (LOAN)')\nfig.set_ylabel('Valores de Empr\u00e9stimos')","539934bc":"plt.figure(figsize=(12,6))\nplt.subplot(1,2,2)\nfig=sns.boxplot(x='MORTDUE', data=df, orient='v', color='#54278f')\nfig.set_title('BoxPlot de Hipoteca (MORTDUE)')\nfig.set_ylabel('Valores de Hipotecas')","3728e530":"plt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nfig = df.LOAN.hist(bins=25)\nfig.set_title('Distribui\u00e7\u00e3o de Empr\u00e9stimos (LOAN)')\nfig.set_ylabel('Quantidade de Observa\u00e7\u00f5es com os Empr\u00e9stimos no eixo X')","d1c2fe25":"# Correla\u00e7\u00e3o entre vari\u00e1veis\n\nf, ax = plt.subplots(figsize=(25,12))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', linecolor='black', ax=ax, lw=.7)","b25e359d":"# Importando o m\u00e9todo do scikitlearn para divis\u00e3o\nfrom sklearn.model_selection import train_test_split","f7a118ae":"# Dividir a base\ntrain, valid = train_test_split(df, random_state=42)","e8f02c0c":"# Verificando tamanhos\ntrain.shape, valid.shape","96864a39":"# Selecionando as colunas que iremos usar como entrada\n\n# Lista das colunas n\u00e3o usadas\nremoved_cols = ['BAD', 'REASON', 'JOB']\n\n# Criar a lista das colunas de entrada\nfeats = [c for c in train.columns if c not in removed_cols]","644ee081":"# Usando o modelo Random Forest\n\n# Instanciar o modelo\nfrom sklearn.ensemble import RandomForestRegressor","92e379ba":"# Instanciar o modelo\nrf = RandomForestRegressor(random_state=42, n_jobs=-1)","5360327d":"df['BAD'] = pd.to_numeric(df['BAD'])","cea9160f":"# Treinando o modelo\nrf.fit(train[feats], train['BAD'])","e2c9603e":"# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npreds = rf.predict(valid[feats])","3e0782ba":"# Verificando as previsoes\npreds","96c28407":"# Verificando o real\nvalid['BAD'].head(3)","b1c3bd0e":"# Importando a metrica\nfrom sklearn.metrics import mean_squared_error","3f1ea3ed":"# Aplicando a metrica\nmean_squared_error(valid['BAD'], preds)**(1\/2)","bfe0cc8d":"# Vamos prever com base nos dados de treino\n\ntrain_preds = rf.predict(train[feats])\n\nmean_squared_error(train['BAD'], train_preds)**(1\/2)","8b1ff2bf":"# Criando dummys para a colunas JOB, NINQ e REASON\ndf = pd.get_dummies(df, columns=['JOB','NINQ','REASON'], dtype=int)","9addc20e":"df.shape","aa731c5b":"# Correla\u00e7\u00e3o ap\u00f3s dummies\n\nf, ax = plt.subplots(figsize=(25,12))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', linecolor='red', ax=ax, lw=.7)","2f5dde80":"# Instanciando um novo modelo\nrf2 = RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=400,\n                           min_samples_leaf=4)\n\n# Treinando o modelo\nrf2.fit(train[feats], train['BAD'])\n\n# Fazendo as previs\u00f5es na base de valida\u00e7\u00e3o\npreds2 = rf2.predict(valid[feats])\n\n# Aplicando a metrica\nmean_squared_error(valid['BAD'], preds2)**(1\/2)","ff59480e":"#from sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf3 = RandomForestClassifier(n_estimators=200, min_samples_split=5, max_depth=4, random_state=42)\nrf3.fit(train[feats], train['BAD'])\naccuracy_score(valid['BAD'], rf3.predict(valid[feats]))","84c31af6":"# previs\u00f5es para os dados de valida\u00e7\u00e3o\npreds_val = rf3.predict(valid[feats])","5c9fc360":"# importando a bilbioteca para plotar o gr\u00e1fico de Matriz de Confus\u00e3o\n import scikitplot as skplt","ec773126":"# Matriz de Confus\u00e3o - Dados de Valida\u00e7\u00e3o\nskplt.metrics.plot_confusion_matrix(valid['BAD'], preds_val)","50af5dcc":"# Feature Importance com RF\npd.Series(rf3.feature_importances_, index=feats).sort_values().plot.barh()","e6b8a79c":"from sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(train[feats], train['BAD'])\naccuracy_score(valid['BAD'], gbm.predict(valid[feats]))","6fb58ac7":"# Feature Importance com GBM\npd.Series(gbm.feature_importances_, index=feats).sort_values().plot.barh()","13c43a83":"from xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\nxgb.fit(train[feats], train['BAD'])\naccuracy_score(valid['BAD'], xgb.predict(valid[feats]))","d2cbd922":"# Feature Importance com XGB\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","f3e7370c":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(xgb, train[feats], train['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","4b968e19":"## Random forest Classifier","f65087d8":"Visando avaliar o quantitativo de pessoas por tipo de trabalho, identificou-se que a maior parte dos cadastros foram feitos considerando a op\u00e7\u00e3o \"Other\".","73900dc0":"## Verificando o resultado do modelo com rela\u00e7\u00e3o a m\u00e9trica","599bf8a7":"No bloxplot abaixo, podemos verificar a m\u00e9dia de valores de empr\u00e9stimos, bem como perceber outliers.\n\nNo boxplot de hipoteca, pode-se perceber que a m\u00e9dia \u00e9 bem inferior ao valor de empr\u00e9stimos solicitados.","0b18b05f":"## Feature Engineering","16a9dfc8":"Abaixo ser\u00e1 apresentado o quantitativo de inadimplentes e os que possuem empr\u00e9stimo reembolsado.\n\nRessalta-se que a quantidade de inadimplentes \u00e9 muito superior \u00e0 quantidade de empr\u00e9stimos pagos.","03aff32d":"Abaixo apresento a distribui\u00e7\u00e3o do total de empr\u00e9stiomos solicitados, onde percebemos que o maior volume de solicita\u00e7\u00f5es s\u00e3o na base de 10.000 a 20.000.","1f636caf":"Para confirma\u00e7\u00e3o do desempenho do modelo, iremos utilizar a valida\u00e7\u00e3o cruzada fim de verificar o comportamento do mesmo modelo ao lidar com observa\u00e7oes diferentes.","ef25a415":"As florestas de decis\u00e3o aleat\u00f3ria ou random forest s\u00e3o um m\u00e9todo de aprendizado conjunto para classifica\u00e7\u00e3o, regress\u00e3o e outras tarefas que operam construindo uma infinidade de \u00e1rvores de decis\u00e3o no momento do treinamento e produzindo a classe que \u00e9 o modo das classes (classifica\u00e7\u00e3o) ou previs\u00e3o m\u00e9dia (regress\u00e3o) das \u00e1rvores individuais. Uma grande vantagem do random forest \u00e9 a diminui\u00e7\u00e3o da possibilidade de overfitting.\nAbaixo iniciamos o modelo realizando a divis\u00e3o da base entre base de treino e valida\u00e7\u00e3o (teste). ","0aaa6990":"## Cross validation","68ab290a":"## 5. Previs\u00f5es","7b305611":"## GBM","447fe68f":"## Dividindo a Base","021f8151":"## Random Forest Regressor","1f6879b4":"## 4. An\u00e1lise Explorat\u00f3ria","296b4907":"## 3. Tratamento dos Dados","75457baa":"Visando avaliar a correla\u00e7\u00e3o entre as vari\u00e1veis, abaixo apresentamos o gr\u00e1fico de correla\u00e7\u00e3o, onde podemos perceber que a maioria das v\u00e1ri\u00e1veis tem correla\u00e7\u00e3o correla\u00e7\u00e3o fraca com as outras.","90a7b741":"Conforme apresentado no gr\u00e1fico abaixo, o maior valor de empr\u00e9stimo solicitado foi de 89.900, sendo que a raz\u00e3o para solicita\u00e7\u00e3o foi para consolida\u00e7\u00e3o de d\u00edvida.","2ea27dd9":"Apesar de os dados iniciais possu\u00edrem muitos missings, ap\u00f3s realiza\u00e7\u00e3o do tratamento de dados n\u00e3o houve dificuldades na implementa\u00e7\u00e3o dos modelos. Foram realizadas as an\u00e1lises iniciais com o random forest regressor que apresentou o desvio padr\u00e3o dos res\u00edduos de 0,26, enquanto que, ap\u00f3s a implementa\u00e7\u00e3o de Feature Engineering o desvio padr\u00e3o de res\u00edduos passou a 0,27.\nNos modelos random forest classifier a acur\u00e1cia ficou em 87%, no GBM 89% e o XGBoost com 91%.\nE para concluir, ainda foi realizado o cross validation e a matriz de confus\u00e3o para avaliar o desempenho dos modelo.","63e14e8b":"## 6. Conclus\u00e3o","ff071088":"Para o desenvolvimento deste trabalho foi utilizado a base de dado HMEQ_Data, dispon\u00edvel em: https:\/\/www.kaggle.com\/ajay1735\/hmeq-data\n\nO objetivo desta avalia\u00e7\u00e3o \u00e9 analisar as vari\u00e1veis envolvidas e verificar como elas estar\u00e3o influenciando o resuldado da vari\u00e1vel target BAD.\nAbaixo s\u00e3o apresentadas as vari\u00e1veis dispon\u00edveis na base.\n\n* BAD - cliente inadimplente no empr\u00e9stimo 0 = empr\u00e9stimo reembolsado\n* LOAN - Montante da solicita\u00e7\u00e3o de empr\u00e9stimo\n* MORTDUE - Valor devido da hipoteca existente\n* VALUE - Valor da propriedade atual\n* REASON - DebtCon = consolida\u00e7\u00e3o da d\u00edvida \/ HomeImp - melhoramento da casa\n* JOB - Seis categorias profissionais\n* YOJ - Anos no emprego atual\n* DEROG - N\u00famero de principais relat\u00f3rios depreciativos\n* DELINQ - N\u00famero de linhas de cr\u00e9dito inadimplentes\n* CLAGE - Idade da linha comercial mais antiga em meses\n* NINQ - N\u00famero de linhas de cr\u00e9dito recentes\n* CLNO - N\u00famero de linhas de cr\u00e9dito\n* D\u00cdVIDA - R\u00e1cio d\u00edvida \/ rendimento","25956134":"![image.png](attachment:image.png)\n\n\n**INSTITUTO DE EDUCA\u00c7\u00c3O SUPERIOR \u2013 IESB**\n\n**P\u00d3S-GRADUA\u00c7\u00c3O EM CI\u00caNCIA DE DADOS**\n\n**Data Mining e Machine Learning II**\n\n**Aluna: Virg\u00edlia dos Santos Rodrigues**\n\n**Matr\u00edcula:1931133040**\n","179ca37b":"## Aumentando a floresta em 400 arvores aleat\u00f3rias","4c71f53a":"## XGBoost","324874b4":"Abaixo ser\u00e1 apresentado o resultado do resumo da base, com dados de quantidade, m\u00e9dia, desvio padr\u00e3o, dentre outras informa\u00e7\u00f5es.","4c1fb09d":"## Matriz de Confus\u00e3o","98e11c35":"## 1. Introdu\u00e7\u00e3o","27eb6ebf":"Foi realizado uma avalia\u00e7\u00e3o para verificar as pessoas com mais tempo de empresa, visando saber quem teria mais condi\u00e7\u00f5es de manter o pagamento do empr\u00e9stimo.\n\nPercebeu-se que existem pessoas com at\u00e9 41 anos na mesma empresa, com empr\u00e9stimos com valores consider\u00e1veis.\n\nTamb\u00e9m pode ser visto que a m\u00e9dia de trabalho atual varia entre 6 e 8 anos, de acordo com os seis tipos de trabalho.","7e1d72b1":"## 2. Importa\u00e7\u00e3o da Base","93b976a2":"Antes de realizar a an\u00e1lise da base de dados, foram identificados todos os missings. Em seguida foram apagados as linhas em que apareciam Nan na coluna \"Reason\".\n\nPara coluna JOB foram imputados os dados \"Other\" nas linhas que tiveram Nan. E o restante dos valores que apresentaram Nan foram trocados por 0."}}