{"cell_type":{"20934172":"code","094cd7e5":"code","e5bce7cc":"code","4c3b0b6a":"code","fd22928f":"code","6bd6518f":"code","dac9ddc1":"code","75803e31":"code","6fe272a2":"code","3aeecd1b":"code","474228b8":"code","c0f4a8a2":"code","4469f96f":"code","2ccc39cf":"code","d32d18d0":"code","ee2eeb40":"code","32616a3a":"code","af615f3e":"code","71fcfda8":"code","f1b56845":"code","a63b29e8":"code","8974b030":"markdown","51afa710":"markdown","2e55707d":"markdown","42545890":"markdown"},"source":{"20934172":"#Multiclass Classification using Iris Dataset\n#This example is to show how we actually deal with data set where we have more than two possible classes in our traget","094cd7e5":"#Load the packages\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","e5bce7cc":"#load the dataset\ndf = pd.read_csv('..\/input\/Iris.csv')\ndf = df.drop(\"Id\",axis=1)","4c3b0b6a":"#Use seaborn pairplot to show how the dataset looks\nsns.pairplot(df,hue=\"Species\")","fd22928f":"#Checking the dataset for numerical columns\ndf.head()","6bd6518f":"X = df.drop(\"Species\",axis=1)\nX.head()","dac9ddc1":"#add the species in the target names\ntarget_names = df['Species'].unique()\ntarget_names","75803e31":"#Build a target dictionarywhere we enumerate the target names where it gives Setosa=0, Versicolor = 1, Virginica=2\ntarget_dict = {n:i for i,n in enumerate(target_names)}\ntarget_dict","6fe272a2":"#Map the species column to the target data\ny= df['Species'].map(target_dict)\ny.head()","3aeecd1b":"#In Keras we have to_categorical which does exactly the same function as performed above\nfrom keras.utils.np_utils import to_categorical","474228b8":"y_cat = to_categorical(y)","c0f4a8a2":"y_cat[:10]","4469f96f":"#Split the dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X.values,y_cat,test_size=0.2)","2ccc39cf":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam,SGD","d32d18d0":"#We use categorical_crossentropy as it goes in tandem with the soft max function\n\nmodel = Sequential()\nmodel.add(Dense(3, input_shape=(4,), activation='softmax'))\nmodel.compile(Adam(lr=0.1),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","ee2eeb40":"model.fit(X_train, y_train, epochs=20, validation_split=0.1)","32616a3a":"y_pred = model.predict(X_test)","af615f3e":"y_pred[:5]","71fcfda8":"#So we take the maximum probability for each row\ny_test_class = np.argmax(y_test, axis=1)\ny_pred_class = np.argmax(y_pred, axis=1)","f1b56845":"from sklearn.metrics import classification_report","a63b29e8":"#Compare the test class with the predicted calss \nprint(classification_report(y_test_class, y_pred_class))","8974b030":"**Model learned to completely distinguish the Sentosa Class(the one which was seperate from the other two)\nBut the other two the model faces some confusion which is not surprising**","51afa710":"We can see that one species is well differentiated from the other two for all the 4 features, while the other two are overlapping\n\nSo we are going to build a model with 4 input features and we will have three outputs - the 3 species","2e55707d":"The output has three values as we are predicting the probability for the three species classes","42545890":"Species Column is our target.\nWe drop the Species column next"}}