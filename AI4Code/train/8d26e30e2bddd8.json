{"cell_type":{"a40d8bcf":"code","b38d37b8":"code","57caa1ec":"code","ff567049":"code","7bac8f6f":"code","c496024c":"code","3b1e5bd4":"code","9112b21d":"code","dcd8b11a":"code","0954dc04":"code","7f99444a":"code","36fed93d":"code","c1cf8146":"code","3531d305":"code","22ff7732":"code","405e23df":"code","3196389d":"code","6a8c8f81":"code","189f2317":"code","27bca85e":"code","0cb5bc61":"code","c7929e48":"code","c5ea1df0":"code","24cebc80":"code","0c78d6f6":"code","deba7277":"code","453acf3f":"code","77a759bc":"code","7e869a2e":"code","b05dbaae":"code","a9e29ef6":"code","4d0c5084":"code","1e572a12":"code","78e5c2cd":"code","f607d45b":"code","2a9ff9b4":"code","d3e02e56":"code","31346538":"code","925246d1":"code","40efe46a":"code","8a85e4e2":"code","4de23554":"code","0c61b68f":"code","1c08a3c4":"code","3e914b25":"code","f6c629ff":"code","0217206b":"markdown","958fef14":"markdown","fbd28936":"markdown","61b4373b":"markdown","120935a2":"markdown","d66f854f":"markdown","ff33e58c":"markdown","0e537c92":"markdown","974e25ad":"markdown","e2d6a263":"markdown","a5e3ec91":"markdown","5ecb66a1":"markdown","41e7ce68":"markdown","3bdeaf9e":"markdown","2e824273":"markdown"},"source":{"a40d8bcf":"## \u0411\u043b\u043e\u043a \u0447\u0430\u0441\u0442\u043e\u0443\u043f\u043e\u0442\u0440\u0435\u0431\u0438\u043c\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u043f\u043e \u0432\u0441\u0435\u043c \u0442\u0435\u043c\u0430\u043c \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n# \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0430\u043b\u0433\u0435\u0431\u0440\u0430 https:\/\/pythonworld.ru\/numpy\/1.html  https:\/\/habr.com\/ru\/post\/352678\/  https:\/\/python-scripts.com\/numpy\nimport numpy as np\n# \u0447\u0442\u0435\u043d\u0438\u0435 \u0444\u0430\u0439\u043b\u043e\u0432 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 https:\/\/proglib.io\/p\/pandas-tricks   https:\/\/khashtamov.com\/ru\/pandas-introduction\/ https:\/\/habr.com\/ru\/company\/ods\/blog\/322626\/\nimport pandas as pd \n# sklearn - \u043f\u0440\u0435\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043d\u0433, \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u0432\u044b\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e, \u0432\u044b\u0431\u043e\u0440 \u043c\u043e\u0434\u0435\u043b\u0435\u0439,\n# \u043c\u043e\u0434\u0435\u043b\u0438 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f: \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f, \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f, \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0446\u0438\u044f, \u043f\u043e\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0438...\n# \u042d\u0442\u043e \u043e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f https:\/\/scikit-learn.org\/stable\/     https:\/\/habr.com\/ru\/company\/mlclass\/blog\/247751\/\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n# \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f https:\/\/python-scripts.com\/matplotlib  https:\/\/pythonworld.ru\/novosti-mira-python\/scientific-graphics-in-python.html\nimport matplotlib.image as mpimg\nfrom matplotlib import pyplot as plt\n# https:\/\/habr.com\/ru\/company\/ods\/blog\/323210\/  https:\/\/nagornyy.me\/courses\/data-science\/intro-to-seaborn\/\nimport seaborn as sns # \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u043e\u0443\u0440\u043e\u0432\u043d\u0435\u0432\u0430\u044f \u0438 \u043b\u0435\u0433\u043a\u0430\u044f \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438\n## \u043a\u043e\u043d\u0435\u0446 \u0431\u043b\u043e\u043a\u0430 \u0447\u0430\u0441\u0442\u043e\u0443\u043f\u043e\u0442\u0440\u0435\u0431\u0438\u043c\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\n\n## \u0411\u043b\u043e\u043a \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0445 \u0441 \u0437\u0430\u0434\u0430\u0447\u0430\u043c\u0438 \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u043e\u0433\u043e \u0437\u0440\u0435\u043d\u0438\u044f\n# \u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 https:\/\/tproger.ru\/translations\/opencv-python-guide\/  https:\/\/arboook.com\/kompyuternoe-zrenie\/osnovnye-operatsii-s-izobrazheniyami-v-opencv-3-python\/\nimport cv2\n# https:\/\/habr.com\/ru\/post\/451074\/   https:\/\/pythonru.com\/biblioteki\/osnovnye-vozmozhnosti-biblioteki-python-imaging-library-pillow-pil\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n## \u043a\u043e\u043d\u0435\u0446 \u0431\u043b\u043e\u043a\u0430 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438\n\n## \u0411\u043b\u043e\u043a \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u043c\u0438 \u0441\u0435\u0442\u044f\u043c\u0438\n# keras - \u0432\u044b\u0441\u043e\u043a\u043e\u0443\u0440\u043e\u0432\u043d\u0435\u0432\u0430\u044f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u043c\u0438 \u0441\u0435\u0442\u044f\u043c\u0438. \u0420\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043a\u0430\u043a \u043d\u0430\u0434\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u043d\u0430\u0434 tensorflow \u0438\u043b\u0438 theano (\u043d\u0430 \u0432\u044b\u0431\u043e\u0440)\n# \u0432\u0438\u0434\u0435\u043e \u043b\u0435\u043a\u0446\u0438\u0438 \u043e\u0442 \u0421\u043e\u0437\u044b\u043a\u0438\u043d\u0430 \u0410.\u0412. https:\/\/www.youtube.com\/watch?v=GX7qxV5nh5o&list=PLtPJ9lKvJ4oiz9aaL_xcZd-x0qd8G0VN_\n# https:\/\/www.youtube.com\/watch?v=52U4BG0ENiM&list=PLtPJ9lKvJ4oi5ATzKmmp6FznCHmnhVoey\n# \u0442\u0443\u0442\u043e\u0440\u0438\u0430\u043b https:\/\/riptutorial.com\/ru\/keras\/topic\/8695\/%D0%BD%D0%B0%D1%87%D0%B0%D0%BB%D0%BE-%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%8B-%D1%81-%D0%BA%D0%B5%D1%80%D0%B0%D1%81%D0%BE%D0%BC\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# \u043a\u0440\u0443\u0442\u043e\u0439 \u0438 \u043a\u0440\u0430\u0442\u043a\u0438\u0439 \u0442\u0443\u0442\u043e\u0440\u0438\u0430\u043b \u043d\u0430 habr https:\/\/habr.com\/ru\/company\/ods\/blog\/325432\/\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import clone_model\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n# \u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u044b https:\/\/habr.com\/ru\/post\/318970\/\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n# \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0435 \u0441\u0435\u0442\u0438\n# \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0432 \u041a\u0435\u0440\u0430\u0441 https:\/\/www.pyimagesearch.com\/2017\/03\/20\/imagenet-vggnet-resnet-inception-xception-keras\/\n# \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0432\u043e\u0438\u043c\u0438 \u0440\u0443\u043a\u0430\u043c\u0438 https:\/\/towardsdatascience.com\/cnn-architectures-a-deep-dive-a99441d18049\n# tensorflow docs https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n# \u043f\u0440\u0438\u043c\u0435\u0440 \u043d\u0435\u0439\u0440\u043e\u043d\u043a\u0438 \u0441 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c\u0438 \u0432\u044b\u0445\u043e\u0434\u0430\u043c\u0438 https:\/\/www.pyimagesearch.com\/2018\/06\/04\/keras-multiple-outputs-and-multiple-losses\/\n## \u043a\u043e\u043d\u0435\u0446 \u0431\u043b\u043e\u043a\u0430 \u043d\u0435\u0439\u0440\u043e\u043d\u043e\u043a\n\n## \u0411\u043b\u043e\u043a \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\n# \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441\u0430 https:\/\/stackoverflow.com\/questions\/42212810\/tqdm-in-jupyter-notebook-prints-new-progress-bars-repeatedly\nfrom tqdm.auto import tqdm \n# \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0432\u044b\u0431\u0438\u0440\u0430\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u043f\u043e \u0448\u0430\u0431\u043b\u043e\u043d\u0443 \u043f\u0443\u0442\u0438 https:\/\/pythonworld.ru\/moduli\/modul-glob.html\nfrom glob import glob \n# \u0432\u0440\u0435\u043c\u044f \u0438 \u0441\u0431\u043e\u0440\u0449\u0438\u043a \u043c\u0443\u0441\u043e\u0440\u0430 https:\/\/all-python.ru\/osnovy\/modul-time.html  https:\/\/asvetlov.blogspot.com\/2013\/05\/gc.html http:\/\/www.ilnurgi1.ru\/docs\/python\/modules\/gc.html\nimport time, gc\n## \u043a\u043e\u043d\u0435\u0446 \u0431\u043b\u043e\u043a\u0430 \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a","b38d37b8":"from pathlib import Path\nfeatherdir = Path('\/kaggle\/input\/bengaliaicv19feather') # \u043f\u0430\u043f\u043a\u0430 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 feather\nimport os\n#\u0432\u044b\u0432\u0435\u0434\u0435\u043c \u0432\u0441\u0435 \u0444\u0430\u0439\u043b\u044b \u0432 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438 \"input\/\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# \u041b\u044e\u0431\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u044b \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u0442\u0435 \u0432 \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043a\u0430\u0442\u0430\u043b\u043e\u0433, \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044e\u0442\u0441\u044f \u043a\u0430\u043a \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435.","57caa1ec":"# %%time\n# train_image_df0 = pd.read_feather(featherdir\/'train_image_data_0.feather')\n# train_image_df1 = pd.read_feather(featherdir\/'train_image_data_1.feather')\n# train_image_df2 = pd.read_feather(featherdir\/'train_image_data_2.feather')\n# train_image_df3 = pd.read_feather(featherdir\/'train_image_data_3.feather')\n# train_image_df3.head()","ff567049":"# %%time\n# d = pd.read_parquet(f'\/kaggle\/input\/bengaliai-cv19\/train_image_data_1.parquet')\n# d.head()","7bac8f6f":"# del train_image_df0\n# del train_image_df1\n# del train_image_df2\n# del train_image_df3\n# del d\n# gc.collect()\n","c496024c":"# \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438\ntrain_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\n# \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\ntest_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/test.csv')\n# \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0441\u043e\u0441\u0442\u0430\u0432\u043d\u044b\u0445 \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\u044b (\u043a\u043e\u0440\u043d\u044f \u0433\u0440\u0430\u0444\u0435\u043c\u044b, \u0433\u043b\u0430\u0441\u043d\u043e\u0433\u043e \u0438 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u043e\u0433\u043e \u0434\u0438\u0430\u043a\u0440\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432)\nclass_map_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/class_map.csv')\n# \u043f\u0440\u0438\u043c\u0435\u0440 \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d\u0438\u044f \u0444\u0430\u0439\u043b\u0430 \u043e\u0442\u0432\u0435\u0442\u043e\u0432\nsample_sub_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')","3b1e5bd4":"train_df_.head() # \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435","9112b21d":"#  \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u0435\ntrain_df_.grapheme_root.nunique(), train_df_.vowel_diacritic.nunique(), train_df_.consonant_diacritic.nunique(), train_df_.grapheme.nunique()","dcd8b11a":"test_df_.head()  # \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435","0954dc04":"sample_sub_df.head()  # \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u043f\u0440\u0438\u043c\u0435\u0440\u0435 \u0444\u0430\u0439\u043b\u0430 \u043e\u0442\u0432\u0435\u0442\u043e\u0432","7f99444a":"# \u0442\u0430\u0431\u043b\u0438\u0446\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0442\u0430\u0432\u0438\u0442 \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0435 \u043d\u0435\u043a\u043e\u0439 \u043f\u043e\u043b\u043d\u043e\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\u044b G \u0435\u0435 \u0441\u043e\u0441\u0442\u043e\u0432\u043b\u044f\u044e\u0449\u0438\u0435:\n# \u043a\u043e\u0440\u0435\u043d\u044c \u0433\u0440\u0430\u0444\u0435\u043c\u044b, \u0433\u043b\u0430\u0441\u043d\u044b\u0435 \u0434\u0438\u0430\u043a\u0440\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0437\u043d\u0430\u043a\u0438 \u0438 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u044b\u0435 \u0434\u0438\u0430\u043a\u0440\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0437\u043d\u0430\u043a\u0438\nG = 5\nclass_map_df[class_map_df.label==G]","36fed93d":"class_map_df.head()","c1cf8146":"class_map_df.component_type.nunique(), class_map_df.label.nunique(), class_map_df.component.nunique()","3531d305":" # \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445\nprint(f'Size of training data: {train_df_.shape}')\nprint(f'Size of test data: {test_df_.shape}')\nprint(f'Size of class map: {class_map_df.shape}')","22ff7732":"HEIGHT = 236 # \u0432\u044b\u0441\u043e\u0442\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\nWIDTH = 236 # \u0448\u0438\u0440\u0438\u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n# \u0435\u0441\u043b\u0438 \u0445\u043e\u0442\u0438\u0442\u0435 \u0433\u043b\u0443\u0431\u0436\u0435 \u043f\u043e\u043d\u044f\u0442\u044c, \u0447\u0442\u043e \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 - \u0440\u0430\u0441\u043a\u043e\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0439\u0442\u0435 \u043f\u0440\u0438\u043d\u0442\u044b\ndef get_n(df, field, n, top=True):\n    '''\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0432\u044b\u0431\u043e\u0440\u0430 \u0442\u043e\u043f N \u0433\u0440\u0430\u0444\u0435\u043c \u0436\u0435\u043b\u0430\u0435\u043c\u043e\u0433\u043e \u0442\u0438\u043f\u0430 (field)\n        df - data frame \u0441 \u0433\u0440\u0430\u0444\u0435\u043c\u0430\u043c\u0438 (\u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435 test_df_)\n        field - \u0447\u0430\u0441\u0442\u044c \u0433\u0440\u0430\u0444\u0435\u043c\u044b, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u0445\u043e\u0442\u0438\u043c \u043f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c. \u041c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c 3 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f (grapheme_root, vowel_diacritic, consonant_diacritic)\n        n - \u0447\u0438\u0441\u043b\u043e \u0437\u043d\u0430\u043a\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u044b \u0445\u043e\u0442\u0438\u043c \u0443\u0432\u0438\u0434\u0435\u0442\u044c\n        top - (True\/False) \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0438 (\u043f\u043e \u0443\u0431\u044b\u0432\u0430\u043d\u0438\u0435\/ \u043f\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430\u043d\u0438\u044e)\n    '''\n    # \u0433\u0440\u0443\u043f\u043f\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043f\u043e \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u0433\u0440\u0430\u0444\u0435\u043c\u044b \u0438 \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u0439 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0442\u0438\u043f\u0430 \u0433\u0440\u0430\u0444\u0435\u043c\u044b. \u0421\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c, \u043e\u0442\u0441\u0435\u043a\u0430\u043c \u0442\u043e\u043f\n    top_graphemes = df.groupby([field]).size().reset_index(name='counts')['counts'].sort_values(ascending=not top)[:n]\n#     print(top_graphemes)\n    top_grapheme_roots = top_graphemes.index # \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0438\u043d\u0434\u0435\u043a\u0441\u044b (\u043d\u043e\u043c\u0435\u0440\u0430 \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c)\n#     print(top_grapheme_roots)\n    top_grapheme_counts = top_graphemes.values # \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 (\u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430) \u0432\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u044d\u0442\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u0433\u0440\u0430\u0444\u0435\u043c\u044b \u0432 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445\n#     print(top_grapheme_counts)\n    # \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u043d\u0430\u043c\u0438 \u0447\u0430\u0441\u0442\u0438 \u0433\u0440\u0430\u0444\u0435\u043c \u0432 \u043d\u0430\u0431\u043e\u0440\u0435 \u0441 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\u043c\u0438 \u044d\u0442\u0438\u044a \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\n    top_graphemes = class_map_df[class_map_df['component_type'] == field].reset_index().iloc[top_grapheme_roots]\n#     print(top_graphemes)\n    top_graphemes.drop(['component_type', 'label'], axis=1, inplace=True) # \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u043d\u0435\u043d\u0443\u0436\u043d\u044b\u0435 \u043d\u0430\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u044b\n#     print(top_graphemes)\n    top_graphemes.loc[:, 'count'] = top_grapheme_counts # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043a \u043d\u043e\u043c\u0435\u0440\u0430\u043c \u0438 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\u043c \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0438\u0445 \u0432\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f\n#     print(top_graphemes)\n    return top_graphemes\n\ndef image_from_char(char):\n    '''\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 \u0438\u0437 \u0442\u0430\u0431\u043b\u0438\u0446\u044b \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0432 \u0440\u0438\u0441\u0443\u043d\u043a\u0438 \u0436\u0435\u043b\u0430\u0435\u043c\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n        char - \u0447\u0430\u0441\u0442\u044c \u0433\u0440\u0430\u0444\u0435\u043c\u044b, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u0445\u043e\u0442\u0438\u043c \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u0430\u0442\u044c \u0432 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u043d\u043e\u043c \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0435\n    '''\n    image = Image.new('RGB', (WIDTH, HEIGHT)) # \u0437\u0430\u0434\u0430\u0435\u043c \u0442\u0440\u0435\u0445\u043a\u0430\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u0442\u0438\u043f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u0435\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c\n    draw = ImageDraw.Draw(image) # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 \u0434\u043b\u044f \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0438\n    myfont = ImageFont.truetype('\/kaggle\/input\/kalpurush-fonts\/kalpurush-2.ttf', 120) # \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0442\u0438\u043f \u0448\u0440\u0438\u0444\u0442\u0430 \u0438 \u0435\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\n    w, h = draw.textsize(char, font=myfont) # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0443\u0435\u043c \u0442\u0430\u0431\u043b\u0438\u0447\u043d\u0443\u044e \u0433\u0440\u0430\u0444\u0435\u043c\u0443 \u043a \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u043e\u043c\u0443 \u0448\u0440\u0438\u0444\u0442\u0443 \u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u0430\u043c \u0448\u0440\u0438\u0444\u0442\u0430\n    draw.text(((WIDTH - w) \/ 2,(HEIGHT - h) \/ 3), char, font=myfont) # \u0440\u0438\u0441\u0443\u0435\u043c \u0441\u0438\u043c\u0432\u043e\u043b, \u043e\u0442\u0446\u0435\u043d\u0442\u0440\u043e\u0432\u0430\u0432 \u0435\u0433\u043e \u043d\u0430 \u043f\u043e\u043b\u043e\u0442\u043d\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\n    return image","405e23df":"print(f'Number of unique grapheme roots: {train_df_[\"grapheme_root\"].nunique()}')\nprint(f'Number of unique vowel diacritic: {train_df_[\"vowel_diacritic\"].nunique()}')\nprint(f'Number of unique consonant diacritic: {train_df_[\"consonant_diacritic\"].nunique()}')","3196389d":"top_10_roots = get_n(train_df_, 'grapheme_root', 10)\ntop_10_roots","6a8c8f81":"# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0442\u043a\u0443 2 \u043d\u0430 5, \u0434\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u043a\u043e\u043c\u043f\u0430\u043a\u0442\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 \u0438 \u0437\u0430\u0434\u0430\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0445 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\nf, ax = plt.subplots(2, 5, figsize=(16, 8))\nax = ax.flatten()\n# \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0432 \u0446\u0438\u043a\u043b\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u0435 \u0442\u043e\u043f N \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0447\u0430\u0441\u0442\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c\nfor i in range(10):\n    ax[i].imshow(image_from_char(top_10_roots['component'].iloc[i]), cmap='Greys')","189f2317":"bottom_10_roots = get_n(train_df_, 'grapheme_root', 10, False)\nbottom_10_roots","27bca85e":"f, ax = plt.subplots(2, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(10):\n    ax[i].imshow(image_from_char(bottom_10_roots['component'].iloc[i]), cmap='Greys')","0cb5bc61":"top_5_vowels = get_n(train_df_, 'vowel_diacritic', 5)\ntop_5_vowels","c7929e48":"f, ax = plt.subplots(1, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(5):\n    ax[i].imshow(image_from_char(top_5_vowels['component'].iloc[i]), cmap='Greys')","c5ea1df0":"top_5_consonants = get_n(train_df_, 'consonant_diacritic', 5)\ntop_5_consonants","24cebc80":"f, ax = plt.subplots(1, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(5):\n    ax[i].imshow(image_from_char(top_5_consonants['component'].iloc[i]), cmap='Greys')","0c78d6f6":"train_df_ = train_df_.drop(['grapheme'], axis=1, inplace=False) # \u0443\u0431\u0438\u0440\u0430\u0435\u043c \u0438\u0437 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0440\u0438\u0441\u0443\u043d\u043a\u0438 \u0433\u0440\u0430\u0444\u0435\u043c","deba7277":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0443\u0435\u043c \u0442\u0438\u043f \u0434\u0430\u043d\u043d\u044b\u0445 \u043a \u0442\u0438\u043f\u0443, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u043c\u0435\u043d\u044c\u0448\u0435 \u043c\u0435\u0441\u0442\u0430 \u0432 \u043f\u0430\u043c\u044f\u0442\u0438 \ntrain_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')","453acf3f":"IMG_SIZE=64 # \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0432\u0445\u043e\u0434\u043d\u043e\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043b\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\nN_CHANNELS=1 # \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0447\u0438\u0441\u043b\u043e \u043a\u0430\u043d\u0430\u043b\u043e\u0432 \u0446\u0432\u0435\u0442\u0430 \u0434\u043b\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438","77a759bc":"def resize(df, size=64, need_progress_bar=True):\n    '''\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043a \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043d\u043e\u0439 \u0444\u043e\u0440\u043c\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n        df - \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n        size - \u0448\u0438\u0440\u0438\u043d\u0430 \u0438 \u0432\u044b\u0441\u043e\u0442\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u043e\u0441\u043b\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f\n        need_progress_bar - \u0432\u044b\u0432\u043e\u0434 \u0441\u0442\u0440\u043e\u043a\u0438 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f\n        return - \u0434\u0430\u0442\u0430 \u0444\u0440\u0435\u0439\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0439 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043d\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n    '''\n    resized = {}\n    resize_size=size\n    # \u0435\u0441\u043b\u0438 \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u044c \u0441\u0442\u0440\u043e\u043a\u0443 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f, \u0442\u043e \u043e\u0431\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u043c \u0446\u0438\u043a\u043b \u0432 tqdm, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435\u0442\n    if need_progress_bar:\n        for i in tqdm(range(df.shape[0])):\n            # \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0441\u0442\u0440\u043e\u043a\u0443 \u0441 \u043e\u0434\u043d\u0438\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\u043c \u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0432\u0435\u043a\u0442\u043e\u0440 \u0432 \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            # \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043a \u0431\u0438\u043d\u0430\u0440\u043d\u043e\u043c\u0443\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            # \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u043e\u0438\u0441\u043a\u0430 \u0432\u0441\u0435\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u044b\u0445 \u043a\u043e\u043d\u0442\u0443\u0440\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            # \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u0445 \u043a\u043e\u043d\u0442\u0443\u0440\u043e\u0432\n            for cnt in contours:\n                # \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430 \u043e\u043f\u0438\u0441\u0430\u043d\u043d\u043e\u0433\u043e \u0432\u043e\u043a\u0440\u0443\u0433 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u043e\u0433\u043e \u043a\u043e\u043d\u0442\u0443\u0440\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n                x,y,w,h = cv2.boundingRect(cnt)\n                # \u043f\u043e\u043c\u0435\u0449\u0430\u0435\u043c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u0443\u0433\u043b\u043e\u0432 \u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430, \u043a\u0430\u0436\u0434\u044b\u0439 \u0432 \u0441\u0432\u043e\u0439 \u043c\u0430\u0441\u0441\u0438\u0432\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            #  \u043f\u043e\u0441\u043b\u0435 \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430 \u0432\u0441\u0435\u0445 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0445 \u043a\u043e\u043d\u0442\u0443\u0440\u043e\u0432, \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u043a\u0440\u0430\u0439\u043d\u0438\u0435 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0446\u0435\u043d\u0442\u0440\u0430 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430, \u0447\u0442\u043e\u0431\u044b \u043d\u0430\u0432\u0435\u0440\u043d\u044f\u043a\u0430 \u0437\u0430\u0445\u0432\u0430\u0442\u0438\u0442\u044c \u0432\u0441\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n            # \u043e\u0431\u0440\u0435\u0437\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043f\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u043c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c (\u0442\u0435\u043f\u0435\u0440\u044c \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0444\u0435\u043c\u044b, \u0437\u0430\u043d\u0438\u043c\u0430\u044e\u0449\u0435\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u043e\u0431\u044a\u0435\u043c\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f)\n            roi = image[ymin:ymax,xmin:xmax]\n            # \u043c\u0435\u043d\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043d\u0430 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u043d\u0430\u043c\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u044c\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    else:\n        for i in range(df.shape[0]):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0438\u0437 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430\u0440\u044f \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \u043d\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0434\u0430\u0442\u0430 \u0444\u0440\u0435\u0439\u043c \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0435\u0433\u043e\n    resized = pd.DataFrame(resized).T\n    return resized","7e869a2e":"def get_dummies(df):\n    cols = []\n    for col in df:\n        cols.append(pd.get_dummies(df[col].astype(str)))\n    return pd.concat(cols, axis=1)","b05dbaae":"d = pd.DataFrame({1:[8,1,3,4,5,6,],2:[0,15,54,0,4,8,],3:[10,11,45,0,7,9,],4:[0,1,3,4,5,6,]}).T\nprint(d)\ncols = []\nfor col in d:\n#     print(col)\n#     print(pd.get_dummies(d[col].astype(str)))\n    cols.append(pd.get_dummies(d[col].astype(str)))\npd.concat(cols, axis=1)","a9e29ef6":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u043b\u043e\u043a\u0430 \u0441\u0432\u0435\u0440\u0442\u043a\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c Keras\ndef make_conv_block(input_tensor, num_filters):\n    '''\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u0431\u043b\u043e\u043a \u0438\u0437 \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0441\u043b\u043e\u0435\u0432, \u0441\u043b\u043e\u044f \u043f\u0430\u043a\u0435\u0442\u043d\u043e\u0439 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 (BatchNormalization), \u0441\u043b\u043e\u044f MaxPool2D \u0438 Dropout\n            df - \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\n            size - \u0448\u0438\u0440\u0438\u043d\u0430 \u0438 \u0432\u044b\u0441\u043e\u0442\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u043e\u0441\u043b\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f\n            need_progress_bar - \u0432\u044b\u0432\u043e\u0434 \u0441\u0442\u0440\u043e\u043a\u0438 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f\n    return - \u0434\u0430\u0442\u0430 \u0444\u0440\u0435\u0439\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0439 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043d\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430'''\n    # \u0441\u0435\u0440\u0438\u044f \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0441\u043b\u043e\u0435\u0432 \u0441 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u043c kernel_size\n    model = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='SAME', activation='relu')(input_tensor)\n    model = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n    model = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n    model = Conv2D(filters=num_filters, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n    model = BatchNormalization(momentum=0.15)(model) # \u0441\u043b\u043e\u0439 \u043c\u0438\u043d\u0438-\u043f\u0430\u043a\u0435\u0442\u043d\u043e\u0439 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438\n    model = MaxPool2D(pool_size=(2, 2))(model) # \u0441\u043b\u043e\u0439 \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0438 (\u0432 2 \u0440\u0430\u0437\u0430)\n    model = Conv2D(filters=num_filters, kernel_size=(5, 5), padding='SAME', activation='relu')(model) # \u0435\u0449\u0435 \u043e\u0434\u043d\u0430 \u0441\u0432\u0435\u0440\u0442\u043a\u0430 \u0441 \u044f\u0434\u0440\u043e\u043c \u0431\u043e\u043b\u044c\u0448\u0435\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 (5,5)\n    model = Dropout(rate=0.3)(model) # \u0441\u043b\u043e\u0439 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438 (\u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e \"\u0437\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u0435\u0442\" \u0447\u0430\u0441\u0442\u044c \u043d\u0435\u0439\u0440\u043e\u043d\u043e\u0432 \u0432 \u0441\u043b\u043e\u0435, \u0447\u0442\u043e\u0431\u044b \u0438\u0437\u0431\u0435\u0436\u0430\u0442\u044c \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f)\n    return model\n\n# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0440\u0438\u044e \u043e\u0434\u043d\u043e\u0442\u0438\u043f\u043d\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432 \u0441 \u0440\u0430\u0437\u043d\u044b\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\ninputs = Input(shape = (IMG_SIZE, IMG_SIZE, N_CHANNELS)) # \u0432\u0445\u043e\u0434\u043d\u043e\u0439 \u0441\u043b\u043e\u0439 \nmodel = inputs # \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0442\u0440\u044e\u043a, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0439 \u0441 \u0442\u0435\u043c, \u0447\u0442\u043e inputs \u043d\u0430\u043c \u043f\u043e\u043d\u0430\u0434\u043e\u0431\u0438\u0442\u044c\u0441\u044f \u0438 \u0434\u0430\u043b\u044c\u0448\u0435, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0435\u0433\u043e \u043d\u0435\u043b\u044c\u0437\u044f \u043f\u0435\u0440\u0435\u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0442\u044c \u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0442\u044c\n# \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0439 \u0431\u043b\u043e\u043a \u0441\u0432\u0435\u0440\u0442\u043e\u043a \u0441\u043e \u0432\u0441\u0435 \u043d\u0430\u0440\u0430\u0441\u0442\u0430\u044e\u0449\u0435\u0439 \u0433\u043b\u0443\u0431\u0438\u043d\u043e\u0439 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\nfor num_filters in [32, 64, 128, 256]:\n    conv_block = make_conv_block(model, num_filters)\n    model = conv_block\n# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0432\u044b\u0445\u043e\u0434 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430 \u0432 \u043f\u043b\u043e\u0441\u043a\u0438\u0439 \u0432\u0435\u043a\u0442\u043e\u0440\nmodel = Flatten()(model)\nmodel = Dense(1024, activation = \"relu\")(model) # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\nmodel = Dropout(rate=0.3)(model) #  \u0441\u043b\u043e\u0439 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\ndense = Dense(512, activation = \"relu\")(model) # \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439\nhead_root = Dense(168, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0433\u0440\u0430\u0444\u0435\u043c\nhead_vowel = Dense(11, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0435\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432\nhead_consonant = Dense(7, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0435\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432\n# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])","4d0c5084":"## \u0435\u0441\u043b\u0438 \u0445\u043e\u0442\u0438\u0442\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c\n## \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0435\u0449\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043a \u0442\u0440\u0435\u0445\u043a\u0430\u043d\u0430\u043b\u044c\u043d\u044b\u043c, \u0447\u0442\u043e\u0431\u044b \u0434\u0430\u043d\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430\n# vgg19_net = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n# vgg19_net.trainable = False\n# model = vgg19_net.output\n# model = Flatten()(model)\n# model = Dense(1024, activation = \"relu\")(model) # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\n# model = Dropout(rate=0.3)(model) #  \u0441\u043b\u043e\u0439 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n# dense = Dense(512, activation = \"relu\")(model) # \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439\n# head_root = Dense(168, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0433\u0440\u0430\u0444\u0435\u043c\n# head_vowel = Dense(11, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0435\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432\n# head_consonant = Dense(7, activation = 'softmax')(dense) # \u0432\u044b\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044e \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0435\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432\n# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n# model = Model(inputs=vgg19_net.input, outputs=[head_root, head_vowel, head_consonant])","1e572a12":"model.summary() # \u0432\u044b\u0432\u043e\u0434\u0438\u043c \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","78e5c2cd":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model.png')","f607d45b":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # \u043a\u043e\u043c\u043f\u0438\u043b\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c","2a9ff9b4":"# \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0432\u044b\u0445\u043e\u0434\u0430 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438.\n# \u0422\u0430\u043a \u0436\u0435 \u0437\u0430\u0434\u0430\u0434\u0438\u043c \u043f\u0440\u0430\u0432\u0438\u043b\u043e, \u0447\u0442\u043e, \u0435\u0441\u043b\u0438 3 (patience=3) \u044d\u043f\u043e\u0445\u0438 \u043f\u043e\u0434\u0440\u044f\u0434 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0435 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430\u0435\u0442, \u0442\u043e \u0434\u0435\u043b\u0438\u043c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e\u043f\u043e\u043b\u0430\u043c (factor=0.5)\nlearning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_2_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)\nlearning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_3_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)\nlearning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_4_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)","d3e02e56":"batch_size = 256\nepochs = 30","31346538":"class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n    '''\u043a\u043b\u0430\u0441\u0441 \u043d\u0430\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u043a\u043b\u0430\u0441\u0441 ImageDataGenerator Keras\n    '''\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix='',\n             save_format='png',\n             subset=None):\n        '''\u043f\u0435\u0440\u0435\u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e flow \u0440\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u0441\u043a\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430'''\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","925246d1":"HEIGHT = 137\nWIDTH = 236","40efe46a":"histories = []\n# \u0441\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u043f\u043e \u043e\u0447\u0435\u0440\u0435\u0434\u0438 \u0443\u0447\u0435\u0431\u043d\u044b\u0435 \u043d\u0430\u0431\u043e\u0440\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u0434\u0435\u043b\u0430\u0435\u043c \u0434\u0436\u043e\u0438\u043d train_df_ \u0441 \u044d\u0442\u0438\u043c\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438, \u0447\u0442\u043e\u0431\u044b \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u0438\u0445 \u043c\u0435\u0442\u043a\u0438\nfor i in range(4):\n    train_df = pd.merge(pd.read_feather(featherdir\/f'train_image_data_{i}.feather'), train_df_, on='image_id').drop(['image_id'], axis=1)\n    \n    # \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439\u0442\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u0431\u0440\u0430\u0437\u0446\u043e\u0432 \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u0443\u0447\u0435\u0431\u043d\u043e\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16, 8))\n    count=0\n    for row in ax:\n        for col in row:\n            col.imshow(resize(train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).iloc[[count]], size=IMG_SIZE,need_progress_bar=False).values.reshape(-1).reshape(IMG_SIZE, IMG_SIZE).astype(np.float64))\n            count += 1\n    plt.show()\n    \n    # \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u0438\u0437 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043c\u0435\u0442\u043a\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n    X_train = resize(X_train, size=IMG_SIZE)\/255 # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043a \u0440\u0430\u0437\u043c\u0435\u0440\u0443, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043e\u0436\u0438\u0434\u0430\u0435\u0442 \u043d\u0430 \u0432\u0445\u043e\u0434 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c \u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439\n    \n    # CNN \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0444\u043e\u0440\u043c\u0435 `(batch_size, h, w, channel)`, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0438\u0437\u043c\u0435\u043d\u044f\u0439\u0442\u0435 \u0444\u043e\u0440\u043c\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n    X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043c\u0435\u0442\u043a\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0438\u0437 \u0446\u0435\u043b\u043e\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043a \u0432\u0435\u043a\u0442\u043e\u0440\u0430\u043c. \n    # \u041a \u043f\u0440\u0438\u043c\u0435\u0440\u0443 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u044b\u0435 \u0437\u0430\u043d\u043a\u0438: \u0432\u0435\u043a\u0442\u043e\u0440-\u0441\u0442\u043e\u043b\u0431\u0435\u0446 Y_train_consonant \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043e\u0442 0 \u0434\u043e 6, \u0430 \u0442\u0435\u043f\u0435\u0440\u044c \u043e\u043d \u0441\u0442\u0430\u043d\u0435\u0442 \u043c\u0430\u0442\u0440\u0438\u0446\u0435\u0439 \u0438\u0437 7 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0442\u0430\u043a\u043e\u0439 \u0436\u0435 \u0434\u043b\u0438\u043d\u044b\n    # \u0418 \u0435\u0441\u043b\u0438 i-\u0442\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0431\u044b\u043b\u043e 5, \u0442\u043e \u0442\u0435\u043f\u0435\u0440\u044c \u044d\u0442\u043e \u0431\u0443\u0434\u0435\u0442 \u0432\u0435\u043a\u0442\u043e\u0440 \u0441\u0442\u0440\u043e\u043a\u0430 [0, 0, 0, 0, 0, 1, 0]\n    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n\n    print(f'Training images: {X_train.shape}')\n    print(f'Training labels root: {Y_train_root.shape}')\n    print(f'Training labels vowel: {Y_train_vowel.shape}')\n    print(f'Training labels consonants: {Y_train_consonant.shape}')\n\n    # \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u043d\u0430\u0431\u043e\u0440 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\n    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)\n    del train_df\n    del X_train\n    del Y_train_root, Y_train_vowel, Y_train_consonant\n\n    # \u0423\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0431\u043e\u043b\u044c\u0448\u0435\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n    datagen = MultiOutputDataGenerator(\n        featurewise_center=False,  # \u0421\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0446\u0435\u043d\u0442\u0440\u0430 - \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 0, \u0434\u043b\u044f \u0432\u0441\u0435\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n        samplewise_center=False,  # \u0421\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0446\u0435\u043d\u0442\u0440\u0430 -  \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 0, \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n        featurewise_std_normalization=False,  # \u0443\u0431\u0435\u0440\u0435\u043c \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u0434\u043b\u044f \u0432\u0441\u0435\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n        samplewise_std_normalization=False,  # \u0443\u0431\u0435\u0440\u0435\u043c \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n        zca_whitening=False,  \n        rotation_range=12,  # \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c \u043f\u043e\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0435 (\u0433\u0440\u0430\u0434\u0443\u0441\u044b, 0 to 180)  (8)\n        zoom_range = 0.20, # \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f (0.15)\n        width_shift_range=0.15,  # \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u0438 (\u0434\u043e\u043b\u044f \u043e\u0442 \u043e\u0431\u0449\u0435\u0439 \u0448\u0438\u0440\u0438\u043d\u044b)\n        height_shift_range=0.15,  # \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u043b\u044c\u043d\u043e \u0441\u0434\u0432\u0438\u0433\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u0432\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0438 (\u0434\u043e\u043b\u044f \u043e\u0442 \u043e\u0431\u0449\u0435\u0439 \u0432\u044b\u0441\u043e\u0442\u044b)\n        horizontal_flip=False,  # \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e \u043f\u0435\u0440\u0435\u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u0438\n        vertical_flip=False)  # \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e \u043f\u0435\u0440\u0435\u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0438\n\n\n    # \u0412\u044b\u0447\u0438\u0441\u043b\u0438\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0434\u043b\u044f \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445. \u041d\u043e \u043f\u043e\u043a\u0430 \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043a\u0430\u043a\u0438\u0435-\u043b\u0438\u0431\u043e \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f\n    datagen.fit(x_train)\n\n    # \u041e\u0431\u0443\u0447\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n    history = model.fit_generator(datagen.flow(x_train, {'dense_2': y_train_root, 'dense_3': y_train_vowel, 'dense_4': y_train_consonant}, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size, \n                              callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant])\n\n    histories.append(history)\n    \n    # Delete to reduce memory usage\n    del x_train\n    del x_test\n    del y_train_root\n    del y_test_root\n    del y_train_vowel\n    del y_test_vowel\n    del y_train_consonant\n    del y_test_consonant\n    gc.collect()","8a85e4e2":"# \u0435\u0441\u043b\u0438 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e, \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u0435 \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f\nname_model = 'own_model_1.h5'\nmodel.save(name_model)\n# model = load_model(name_model) # \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0433\u043e\u0442\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f","4de23554":"%matplotlib inline\ndef plot_loss(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_3_loss'], label='train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_4_loss'], label='train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_5_loss'], label='train_consonant_loss')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_dense_3_loss'], label='val_train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_4_loss'], label='val_train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_5_loss'], label='val_train_consonant_loss')\n    \n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n\ndef plot_acc(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['dense_3_accuracy'], label='train_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['dense_4_accuracy'], label='train_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['dense_5_accuracy'], label='train_consonant_accuracy')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_dense_3_accuracy'], label='val_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_4_accuracy'], label='val_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_5_accuracy'], label='val_consonant_accuracy')\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()","0c61b68f":"for dataset in range(4):\n    plot_loss(histories[dataset], epochs, f'Training Dataset: {dataset}')\n    plot_acc(histories[dataset], epochs, f'Training Dataset: {dataset}')","1c08a3c4":"del histories\ngc.collect()","3e914b25":"preds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}","f6c629ff":"components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\nrow_id=[] # \u0441\u043f\u0438\u0441\u043e\u043a id \u043c\u0435\u0442\u043e\u043a \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439\nfor i in range(4):\n#     df_test_img = pd.read_parquet(f'\/kaggle\/input\/bengaliai-cv19\/test_image_data_{i}.parquet') # \u0447\u0438\u0442\u0430\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\n    df_test_img = pd.read_feather(featherdir\/f'test_image_data_{i}.feather')  # \u0447\u0438\u0442\u0430\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\n    df_test_img.set_index('image_id', inplace=True) # \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u0441 \u043d\u043e\u043c\u0435\u0440\u043e\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u043a\u0430\u043a \u0438\u043d\u0434\u0435\u043a\u0441\n\n    X_test = resize(df_test_img, size=IMG_SIZE,need_progress_bar=False)\/255 # \u043c\u0435\u043d\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0435\u0433\u043e\n    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS) # \u043c\u0435\u043d\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u043c\u0430\u044c\u0440\u0438\u0446\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043c\u0438\u043d\u0438-\u043f\u0430\u043a\u0435\u0442\u043e\u0432\n    \n    preds = model.predict(X_test) # \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\n    \n    # \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u043c \u0442\u0440\u0438 \u0432\u044b\u0445\u043e\u0434\u0430 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\n    for i, p in enumerate(preds_dict):\n        preds_dict[p] = np.argmax(preds[i], axis=1) # \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0432\u0435\u043a\u0442\u043e\u0440 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u0434\u043b\u044f \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u0442\u0438\u043f\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0434\u043b\u044f \u043a\u043e\u0440\u043d\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c)\n    # \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0442\u0430\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n    del df_test_img\n    del X_test\n    gc.collect()\n# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043c\u0435\u0442\u043a\u0438 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432 dataframe\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\n# \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0444\u0430\u0439\u043b \u0441\u0430\u0431\u043c\u0438\u0442\u0430\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","0217206b":"\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","958fef14":"## \u0411\u0430\u0437\u043e\u0432\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c","fbd28936":"* ### \u0422\u043e\u043f 5 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","61b4373b":"\u0421\u0440\u0430\u0432\u043d\u0438\u043c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u0444\u0430\u0439\u043b\u0430\u043c\u0438 \"feather\" \u0438 \"parquet\"","120935a2":"* ### \u0422\u043e\u043f 5 \u0433\u043b\u0430\u0441\u043d\u044b\u0445 \u0434\u0438\u0430\u043a\u0440\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u043d\u0430\u043a\u043e\u0432 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","d66f854f":"### \u0422\u043e\u043f 10 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0445 \u043a\u043e\u0440\u043d\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c","ff33e58c":"### Training loop","0e537c92":"**\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0438 \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445**","974e25ad":"This kernel is a copy of a [kernel](https:\/\/www.kaggle.com\/kaushal2896\/bengali-graphemes-starter-eda-multi-output-cnn). But with a lot of comments. It is used only for educational purposes.","e2d6a263":"## Exploratory Data Analysis\n\u0418\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u0441\u043a\u0438\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 (EDA) - \u044d\u0442\u043e \u043f\u043e\u0434\u0445\u043e\u0434 \u043a \u0430\u043d\u0430\u043b\u0438\u0437\u0443 \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u0438\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a, \u0447\u0430\u0441\u0442\u043e \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0432\u0438\u0437\u0443\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u0435\u0442\u043e\u0434\u043e\u0432.","a5e3ec91":"**\u0421\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438**","5ecb66a1":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c CNN \u0441 3 \u0432\u044b\u0445\u043e\u0434\u0430\u043c\u0438","41e7ce68":"* ### \u0427\u0438\u0441\u043b\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u043e \u0442\u0438\u043f\u0430\u043c \u0433\u0440\u0430\u0444\u0435\u043c, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c","3bdeaf9e":"* ### \u0422\u043e\u043f 10 \u043d\u0430\u0438\u043c\u0435\u043d\u0435\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0445 \u043a\u043e\u0440\u043d\u0435\u0439 \u0433\u0440\u0430\u0444\u0435\u043c \u0432 \u043d\u0430\u0431\u043e\u0440\u0435","2e824273":"\u041f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0430\u0434 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 (credits: [this kernel](https:\/\/www.kaggle.com\/shawon10\/bangla-graphemes-image-processing-deep-cnn)). \u0418\u0437\u043c\u0435\u043d\u0438\u043c \u0438\u0445 \u0440\u0430\u0437\u043c\u0435\u0440 \u0438 \u043e\u0442\u0446\u0435\u043d\u0442\u0440\u0443\u0435\u043c \u0433\u0440\u0430\u0444\u0435\u043c\u044b."}}