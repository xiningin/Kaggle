{"cell_type":{"8fcfab32":"code","0d801334":"code","3040e8d1":"code","aac91390":"code","df187aa3":"code","0cf33a9a":"code","e7ca47b2":"code","9a0591cf":"code","20e12c6c":"code","3ca6e524":"code","d02a7e58":"code","d875fc31":"code","c994d119":"markdown","bd3269ba":"markdown","096d1541":"markdown","2f38c571":"markdown","46b26872":"markdown","c8568fff":"markdown","4a4b6089":"markdown","63abf152":"markdown","3563d1a8":"markdown","d8d87810":"markdown","b409dbf3":"markdown"},"source":{"8fcfab32":"import numpy as np\nimport librosa as lb\nimport soundfile as sf\nimport pandas as pd\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\n\n\nimport time","0d801334":"32000*10","3040e8d1":"NUM_CLASSES = 24\nSR = 32_000\nDURATION = 10\nSTRIDE = DURATION\/\/2\n\nBATCH_START = 0\nBATCH_SIZE = 400\n\nNJOBS = 2\n\nTEST_AUDIO_ROOT = Path(\"..\/input\/rfcx-species-audio-detection\/train\")\nTEST_MFCC_SAVE_ROOT = Path(f\"train_mfcc_d{DURATION}_s{STRIDE}_sr{SR}_{BATCH_START:04d}_{BATCH_START+BATCH_SIZE:04d}\")\nTEST_MFCC_SAVE_ROOT.mkdir(exist_ok=True)","aac91390":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","df187aa3":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n\n    # Normalize to [0, 255]\n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\n\ndef normalize(image, mean=None, std=None):\n    image = image \/ 255.0\n    if mean is not None and std is not None:\n        image = (image - mean) \/ std\n    return np.moveaxis(image, 2, 0).astype(np.float32)\n\n\ndef crop_or_pad(y, length,cut, sr, is_train=True):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n    elif len(y) > length:\n        if not is_train:\n            start = 0\n        else:\n            start = np.random.randint(cut,(len(y) - length))\n\n        y = y[start:start + length]\n\n    y = y.astype(np.float32, copy=False)\n\n    return y","0cf33a9a":"np.random.choice(range(0, 60*SR+SR*STRIDE-SR*DURATION, SR*STRIDE))","e7ca47b2":"class RFCXTrainDataset:\n\n    def __init__(self, data, sr,duration= 10,cut =2, n_mels=128, fmin=0, fmax=None, num_classes=NUM_CLASSES, root=None):\n        ''' this is just for daving no need to save again the label  position will be read from the dataset'''\n            \n            \n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n\n        self.num_classes = num_classes\n        self.duration = duration\n        \n        self.audio_length = self.duration*self.sr\n        self.cut_length = cut*self.sr\n        \n        self.root =  root or TEST_AUDIO_ROOT\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n        \n        self.res_type = \"kaiser_best\"\n\n\n    def __len__(self):\n        return len(self.data)\n    \n    def load(self, record):\n        y, _ = lb.load(self.root.joinpath(record).with_suffix(\".flac\").as_posix(), sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def load2(self, record):\n        y, orig_sr = sf.read(self.root.joinpath(record).with_suffix(\".flac\").as_posix())\n        y = lb.resample(y, orig_sr=orig_sr, target_sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def read_index(self, idx):\n        d = self.data.iloc[idx]\n        record = d[\"recording_id\"]\n        \n        y = self.load2(record)\n        \n        window = DURATION*self.sr\n        stride = STRIDE*self.sr\n            \n       # y = np.stack([y[i:i+window] for i in range(0, 60*self.sr+stride-window, stride)])\n\n        y = crop_or_pad(y, self.audio_length,self.cut_length, sr=self.sr)\n        \n        #choose random beginning to crop train\n       # t_min = np.random.choice(range(0, 60*self.sr+stride-window, stride))\n        \n        #y = y[t_min:t_min+window]\n        \n        \n        return y #, label\n            \n    def process(self, y):\n         image = self.mel_spec_computer(y) \n#         image = mono_to_color(image)\n#         image = normalize(image, mean=None, std=None)\n         return image\n\n    def __getitem__(self, idx):\n        \n        y  = self.read_index(idx)\n        \n        #y , label = self.read_index(idx)\n        \n        #image = np.stack([self.process(_y) for _y in y])\n        y = self.process(y)\n        \n        return y #,label\n    \n    def to_mfcc(self, idx):\n        record = self.data.iloc[idx][\"recording_id\"]\n        mfcc = self[idx]\n        \n        \n        np.save(TEST_MFCC_SAVE_ROOT.joinpath(record).with_suffix(\".npy\").as_posix(), mfcc)\n        \n       # np.save(TEST_MFCC_SAVE_ROOT.joinpath(record).with_suffix(\".npy\").as_posix(), mfcc)","9a0591cf":"tp_dataset = RFCXTrainDataset(pd.read_csv('..\/input\/rfcx-species-audio-detection\/train_fp.csv'), sr=SR)","20e12c6c":"%%time\n\nx = tp_dataset[1]\nprint(x.shape)","3ca6e524":"# def get_duration(audio_name, root=TEST_AUDIO_ROOT):\n#     return lb.get_duration(filename=root.joinpath(audio_name).with_suffix(\".flac\"))","d02a7e58":"import joblib\npool = joblib.Parallel(n_jobs=NJOBS)","d875fc31":"mapper = joblib.delayed(tp_dataset.to_mfcc)\ntasks = []\nfor idx in range(BATCH_START, max(BATCH_START + BATCH_SIZE, len(tp_dataset))):\n# for idx in range(25):\n    tasks.append(mapper(idx))\n    \nres = pool(tqdm(tasks))","c994d119":"@tf.function\ndef _cut_wav(x):\n    # random cut in training\n    cut_min = tf.random.uniform([], maxval=(CUT-TIME)*SR, dtype=tf.int32)\n    cut_max = cut_min + TIME * SR\n    cutwave = tf.reshape(x['audio_wav'][cut_min:cut_max], [TIME*SR])\n    y = {}\n    y.update(x)\n    y['audio_wav'] = cutwave\n    y['t_min'] = tf.maximum(0.0, x['t_min'] - tf.cast(cut_min, tf.float32) \/ SR)\n    y['t_max'] = tf.maximum(0.0, x['t_max'] - tf.cast(cut_min, tf.float32) \/ SR)\n    return y\n    \n@tf.function\ndef _cut_wav_val(x):\n    # center crop in validation\n    cut_min = (CUT-TIME)*SR \/\/ 2\n    cut_max = cut_min + TIME * SR\n    cutwave = tf.reshape(x['audio_wav'][cut_min:cut_max], [TIME*SR])\n    y = {}\n    y.update(x)\n    y['audio_wav'] = cutwave\n    y['t_min'] = tf.maximum(0.0, x['t_min'] - tf.cast(cut_min, tf.float32) \/ SR)\n    y['t_max'] = tf.maximum(0.0, x['t_max'] - tf.cast(cut_min, tf.float32) \/ SR)\n    return y\n","bd3269ba":"# %timeit ds.to_mfcc(0)","096d1541":"%%time\n\nx = ds[1]\nprint(x.shape)\n#(11, 3, 128, 626)","2f38c571":"%%time\n\ndata = pd.DataFrame({\n    \"recording_id\": [path.stem for path in Path(TEST_AUDIO_ROOT).glob(\"*.flac\")],\n})\n\nprint(data.shape)\ndata.head()","46b26872":"I've released [this crazingly fast (< 10 mins) kernel](https:\/\/www.kaggle.com\/kneroma\/inference-tpu-rfcx-audio-detection-fast) which uses a set of pre-computed MFCCs. \n\nThe problem is that those MFCCs are static, and if you change any params (**DURATION**, **STRIDE**, ...), you can no more use them. This is not fair. I will release my code that can help  you re-computing them whenever you need.\n\n* I use **joblib** to parallelize the computations, so it must require less than 1 hour to compute the MFCCs for the whole test dataset, and just 30 mins if STRIDE = DURATION\n* I directly use **soundfile** to read audios instead of **librosa** as soundfile is faster","c8568fff":"x.nbytes\/(1024**2)","4a4b6089":"cfg = {\n    'parse_params': {\n        'cut_time': 10,\n    },\n    'data_params': {\n        'sample_time': 6, # assert 60 % sample_time == 0\n        'spec_fmax': 24000.0,\n        'spec_fmin': 40.0,\n        'spec_mel': 384, \n        'mel_power': 2,\n        'img_shape': (384, 768)\n    },\n    'model_params': {\n        'batchsize_per_tpu': 18,\n        'iteration_per_epoch': 64,\n        'epoch': 18, \n        'arch': ResNet34,\n        'arch_preprocess': preprocess_input,\n        'freeze_to': 0,  # Freeze to backbone.layers[:freeze_to]. If None, all layers in the backbone will be freezed.\n        'loss': {\n            'fn': tfa.losses.SigmoidFocalCrossEntropy,\n            'params': {},\n        },\n        'optim': {\n            'fn': tfa.optimizers.RectifiedAdam,\n            'params': {'lr': 2e-3, 'total_steps': 18*64, 'warmup_proportion': 0.3, 'min_lr': 1e-6},\n        },\n        'mixup': True # False\n    }\n}","63abf152":"(stacks,channels,mels,window\/mel_hop_length)","3563d1a8":"ds = RFCXDataset(data=data, sr=SR)","d8d87810":"<h3><font color=\"blue\">Is this kernel useful for you ? Don't forget upvoting it, it really  motivates me in enhancing my work and sharing it with you :)<\/h3><\/font>","b409dbf3":"class RFCXDataset:\n\n    def __init__(self, data, sr, n_mels=128, fmin=0, fmax=None, num_classes=NUM_CLASSES, root=None):\n\n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n\n        self.num_classes = num_classes\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        \n        self.root =  root or TEST_AUDIO_ROOT\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n        \n        self.res_type = \"kaiser_best\"\n\n\n    def __len__(self):\n        return len(self.data)\n    \n    def load(self, record):\n        y, _ = lb.load(self.root.joinpath(record).with_suffix(\".flac\").as_posix(), sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def load2(self, record):\n        y, orig_sr = sf.read(self.root.joinpath(record).with_suffix(\".flac\").as_posix())\n        y = lb.resample(y, orig_sr=orig_sr, target_sr=self.sr, res_type=self.res_type)\n        return y\n    \n    def read_index(self, idx):\n        d = self.data.iloc[idx]\n        record = d[\"recording_id\"]\n        \n        y = self.load2(record)\n        \n        window = DURATION*self.sr\n        stride = STRIDE*self.sr\n            \n        y = np.stack([y[i:i+window] for i in range(0, 60*self.sr+stride-window, stride)])\n\n#         y = crop_or_pad(y, self.audio_length, sr=self.sr)\n        \n        return y\n            \n    def process(self, y):\n        melspec = self.mel_spec_computer(y) \n        image = mono_to_color(melspec)\n        image = normalize(image, mean=None, std=None)\n        return image\n\n    def __getitem__(self, idx):\n\n        y = self.read_index(idx)\n        \n        image = np.stack([self.process(_y) for _y in y])\n\n        return image\n    \n    def to_mfcc(self, idx):\n        record = self.data.iloc[idx][\"recording_id\"]\n        mfcc = self[idx]\n        \n        np.save(TEST_MFCC_SAVE_ROOT.joinpath(record).with_suffix(\".npy\").as_posix(), mfcc)"}}