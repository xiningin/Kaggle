{"cell_type":{"3b72b679":"code","1fcc3a3a":"code","ac690690":"code","00b9f599":"code","686a4863":"code","44d2433e":"code","ce7f2e64":"code","9b167ff5":"code","4e468f6b":"code","b1a882ae":"code","5edba143":"code","8a660a65":"markdown","7c1577ee":"markdown","892555b3":"markdown","10ad669b":"markdown","3edc57e0":"markdown","425bb246":"markdown"},"source":{"3b72b679":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \npd.set_option('display.max_columns',500)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fcc3a3a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import OrdinalEncoder,LabelEncoder,PowerTransformer,StandardScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection  import SelectKBest,mutual_info_regression,f_regression,f_classif\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import TransformedTargetRegressor","ac690690":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv',index_col='Id')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmit=pd.DataFrame(test['Id'])\ntest=test.set_index('Id')","00b9f599":"train.select_dtypes(exclude='object').hist(figsize=(25,19))\nplt.show()\n\n\n#------------------------------------------------------------------------------------\n\nplt.figure(figsize=(25,19))\nsns.heatmap(train.corr(),annot=True)","686a4863":"#------------------------------------------------------------------Train------------------------------------------------------------------------\n\nnull=train.loc[:,train.isnull().sum()>500]\ntrain=train.drop(null,axis=1)\n\n#----------------------------------------------------------------\n\ntrain=train.drop_duplicates()\n\n#----------------------------------------------------------------\n\ntrain=train.drop(['YearRemodAdd','3SsnPorch','PoolArea','MiscVal','LowQualFinSF','KitchenAbvGr','EnclosedPorch','BsmtFinSF2','LotArea','BsmtHalfBath','GarageCond','GarageQual','GarageFinish','KitchenQual','CentralAir','HeatingQC','RoofStyle','MSZoning','LandContour','LotConfig','Condition1'],axis=1)\n\n\n\n\n#------------------------------------------------------------------Test--------------------------------------------------------------------------\n\n\nnull=test.loc[:,test.isnull().sum()>500]\ntest=test.drop(null,axis=1)\n\n#----------------------------------------------------------------\n\ntest=test.drop_duplicates()\n\n#----------------------------------------------------------------\n\ntest=test.drop(['YearRemodAdd','3SsnPorch','PoolArea','MiscVal','LowQualFinSF','KitchenAbvGr','EnclosedPorch','BsmtFinSF2','LotArea','BsmtHalfBath','GarageCond','GarageQual','GarageFinish','KitchenQual','CentralAir','HeatingQC','RoofStyle','MSZoning','LandContour','LotConfig','Condition1'],axis=1)\nreg1=train.select_dtypes(exclude='object')\nreg2=test.select_dtypes(exclude='object')\n\n            \n    \n                ","44d2433e":"#---------------------------------------------------------Train------------------------------------------------------------------------------\ndef year_columns(year):\n    a=''\n    if(year<=1900):\n        a='too_old'\n    elif(year<=1950):\n        a='old'\n    elif(year<=1980):\n        a='middle'\n    else:\n        a='new'\n    return a\n\ntrain['YearBuilt']=train['YearBuilt'].map(year_columns)\ntest['YearBuilt']=test['YearBuilt'].map(year_columns)\n\n\n\n\n#--------------------------Encoding------------------------------------------------------------\ncat1=['LotShape','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond']\n\nencode=OrdinalEncoder()\ncat_ordinal=pd.DataFrame(encode.fit_transform(train[cat1].astype(str)),columns=cat1)\nfor i in cat_ordinal.columns:\n    train[i]=cat_ordinal[i]\n    test[i]=cat_ordinal[i]\n\n    \n    \n\ntrain=train.drop(['Heating','Electrical'],axis=1)\ntest=test.drop(['Heating','Electrical'],axis=1)\n#--------------------------- one hot encoding---------------------------------\n\ntrain=pd.get_dummies(train,columns=['Street','BldgType','YearBuilt','MasVnrType','BsmtExposure','PavedDrive'],drop_first=True)\ntest=pd.get_dummies(test,columns=['Street','BldgType','YearBuilt','MasVnrType','BsmtExposure','PavedDrive'],drop_first=True)\n\n#-------------------------- Label Encoding----------------------------------\n\nencode=LabelEncoder()\nfor i in train.select_dtypes(include='object').columns:\n    train[i]=encode.fit_transform(train[i])\n    test[i]=encode.fit_transform(test[i])","ce7f2e64":"model=XGBRegressor(base_score=0.4, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.4603, gamma=0.05,\n             gpu_id=-1, importance_type='gain', interaction_constraints='',\n             learning_rate=0.05, max_delta_step=0, max_depth=3,\n             min_child_weight=1.7817, monotone_constraints='()',\n             n_estimators=2200, n_jobs=4, nthread=-1, num_parallel_tree=1,\n             random_state=7, reg_alpha=0.464, reg_lambda=0.8571,\n             scale_pos_weight=1, subsample=0.5213,silent = True,tree_method='exact',\n             validate_parameters=1, verbosity=0)","9b167ff5":"\npipeline=Pipeline(steps=[('impute',IterativeImputer(max_iter=9,imputation_order='arabic')),('d',SelectKBest(score_func=f_regression,k=55)),(('e',SelectKBest(score_func=f_classif,k=52))),('model',model)])\nx=train.drop('SalePrice',axis=1)\ny=np.log(train['SalePrice'])\n    \n    \nxtrain,xvalid,ytrain,yvalid=train_test_split(x,y,test_size=0.25)\npipeline.fit(xtrain,ytrain)\nyhat=pipeline.predict(xvalid)\nprint(np.mean(mean_squared_error(yvalid,yhat)),i)","4e468f6b":"yhat=np.exp(pipeline.predict(test))","b1a882ae":"submit['SalePrice']=yhat\nsubmit.to_csv('ver1.csv',index=False)","5edba143":"train","8a660a65":"## ","7c1577ee":"# Modelling and Submitting","892555b3":"# Data Cleaning part 2","10ad669b":"# Data Visualization ","3edc57e0":"# Data Cleaning part 1","425bb246":"# Importing modules"}}