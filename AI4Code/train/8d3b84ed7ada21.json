{"cell_type":{"89f7b3c8":"code","a0955567":"code","0fb8bed5":"code","a921427a":"code","c2136342":"code","9d385621":"code","5df9f872":"code","035c19e9":"code","49fd5d88":"code","de1843fc":"code","4db5dbb2":"code","cdb7a13f":"code","a858bd2d":"code","1e7a767f":"code","3a78f8d1":"code","2be957c3":"code","2ca1e3ca":"code","6b8616fe":"code","a7309b25":"code","cc6ca3ca":"code","4db99cbf":"code","fc6f8ed4":"code","da6badb1":"code","a8f9199b":"code","402441fe":"code","9c3fa62c":"code","c9904423":"code","8b5db130":"code","693b6481":"code","e34c0c83":"code","319935f0":"code","c1f50ed6":"markdown","740420c8":"markdown","03224978":"markdown","e51bc2e9":"markdown","edcca72c":"markdown","6062d068":"markdown","6db737ac":"markdown","e30fbdf3":"markdown","154f97b0":"markdown","dc2e15a2":"markdown","26b0d1ec":"markdown","6bbe1783":"markdown","853d0c64":"markdown","00e5c39a":"markdown","3c205582":"markdown","d1a219cd":"markdown","9b02b64d":"markdown","90e63b22":"markdown","e51d6e2d":"markdown","d293c00a":"markdown","331c5033":"markdown","629bce5a":"markdown","67614049":"markdown","d78851e8":"markdown","5070244b":"markdown","60b7a491":"markdown","0e807dd8":"markdown","b4f3e0b3":"markdown","e48a5e71":"markdown","6d0dab35":"markdown","7c016610":"markdown","eafddbb0":"markdown","4c67aeff":"markdown","ce8d9092":"markdown","9835555a":"markdown","5f6f6766":"markdown","998acf9f":"markdown","24b6ff4c":"markdown","478a5657":"markdown","d405c271":"markdown"},"source":{"89f7b3c8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n%matplotlib inline","a0955567":"data_df = pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndata_df.head()\nprint(\"Data is loaded\")","0fb8bed5":"data_df.head()","a921427a":"data_df.shape","c2136342":"data_df.dtypes","9d385621":"data_df.info()","5df9f872":"data_df.corr()","035c19e9":"missing_data = data_df.isnull().sum().sum()\nprint('Total missing value in dataset is:', missing_data)","49fd5d88":"# Drop CustomerID Column\ndata_df = data_df.drop(columns='CustomerID')","de1843fc":"data_df.Gender = data_df.Gender.replace({'Female': 1, 'Male': 0})","4db5dbb2":"data_df.head()","cdb7a13f":"plt.figure(1 , figsize = (10 , 4))\nsns.countplot(x = 'Gender' , data = data_df)\nplt.show()","a858bd2d":"plt.figure(1, figsize=(15, 6))\nfor i, x in enumerate(['Age', 'Annual Income (k$)','Spending Score (1-100)']):\n    plt.subplot(1, 3, i+1)\n    sns.histplot(data_df[x])\n    plt.title('{} Distribution'.format(x))\nplt.show()","1e7a767f":"sns.pairplot(data_df,hue='Gender')","3a78f8d1":"plt.figure(figsize = (10, 10))\nsns.heatmap(data_df.corr(), annot = True, cmap=\"bone\")\nplt.savefig('Correlation')\nplt.show()","2be957c3":"wcss = [] \n\nfor i in range(2, 10): \n    model = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    model.fit(data_df) \n    wcss.append(model.inertia_)","2ca1e3ca":"wcss","6b8616fe":"plt.plot(range(2,10), wcss, 'o--')\nplt.xlabel('K Value')\nplt.ylabel('WCSS')","a7309b25":"model = KMeans()\n\nvisualizer = KElbowVisualizer(model, k=(2,10), timings= True)\nvisualizer.fit(data_df)\nvisualizer.show()","cc6ca3ca":"s_score= []\n\nfor k in range (2, 10):\n    model_sil = KMeans(n_clusters=k)\n    model_sil.fit(data_df)\n    label=model_sil.predict(data_df)\n    s_score.append(silhouette_score(data_df, label)) ","4db99cbf":"s_score","fc6f8ed4":"plt.plot(range(2,10), s_score, 'o--')\nplt.xlabel('K Value')\nplt.ylabel('Silhouette Score')","da6badb1":"# Slice the data exclude gender\nX = data_df.iloc[:,[1,2,3]].values","a8f9199b":"kmeans = KMeans(n_clusters = 5,init = 'k-means++', random_state = 42)\ny = kmeans.fit_predict(X)","402441fe":"y","9c3fa62c":"# plot 3d of 'age', 'annual income' and 'spending score', group by 5 clusters in different colours\nfig = px.scatter_3d(x=X[:,0], y=X[:,1], z=X[:,2], color=y)\nfig.show()","c9904423":"# plot 3d of 'age', 'annual income' and 'spending score', colour based on gender\nfig = px.scatter_3d(x=X[:,0], y=X[:,1], z=X[:,2], color=data_df['Gender'])\nfig.show()","8b5db130":"plt.figure(figsize=(15, 7))  \nplt.title(\"Dendrograms\")\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.axhline(y=300, color='r', linestyle='--')\ndend = sch.dendrogram(sch.linkage(X, method='ward'))","693b6481":"hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","e34c0c83":"y_hc","319935f0":"# plot 3d of 'age', 'annual income' and 'spending score', group by 5 clusters in different colours\nfig = px.scatter_3d(x=X[:,0], y=X[:,1], z=X[:,2], color=y_hc)\nfig.show()","c1f50ed6":"<a id=\"data_understanding\"><\/a>\n## 3. Data Understanding","740420c8":"### Load the Dataset","03224978":"<div align='left'><font size=\"3\" color=\"#000000\">Hierarchical cluster is an unsupervised clustering algorithm which involves creating clusters that have predominant ordering from top to bottom.\n<\/font><\/div>\n\n#### Types of Hierarchical Clustering\n<div align='left'><font size=\"3\" color=\"#000000\">There are mainly two types of hierarchical clustering:\n<\/font><\/div>\n\n\n<ol><font size=\"3\" color=\"#000000\">\n  <li> Agglomerative hierarchical clustering<\/li>\n  <li> Divisive Hierarchical clustering<\/li>\n<\/font><\/ol>\n\nSource and credit to https:\/\/www.kdnuggets.com\/2019\/09\/hierarchical-clustering.html","e51bc2e9":"### Import Libraries","edcca72c":"<div align='left'><font size=\"3\" color=\"#000000\">A Dendrogram is a type of tree diagram showing hierarchical relationships between different sets of data.\n\nAs already said a Dendrogram contains the memory of hierarchical clustering algorithm, so just by looking at the Dendrgram you can tell how the cluster is formed.\n<\/font><\/div>\n\n","6062d068":"<a id=\"data_cleaning\"><\/a>\n### 4.1 Data Cleaning","6db737ac":"#### **Insights:**\n* <div align='left'><font size=\"3\" color=\"#000000\"> Female customers tend to be more often to shop at Mall than Male.\n<\/font><\/div>\n* <div align='left'><font size=\"3\" color=\"#000000\"> Customers between the ages of 30-35 are more attractive to shop, those aged around 60 are less likely to shop at Mall.\n<\/font><\/div>\n* <div align='left'><font size=\"3\" color=\"#000000\"> Customers who have an annual income around 60k dollars more often to shop at the mall, but those have an annual income around 120k dollars not likely to shop at the Mall.\n<\/font><\/div>\n* <div align='left'><font size=\"3\" color=\"#000000\"> There is no strong correlations of features represent in dataset.\n<\/font><\/div>\n\n","e30fbdf3":"<div align='left'><font size=\"3\" color=\"#000000\"> In this implementation, I will assign value of K with 5 based on the Elbow method to be train on K-Means Model.\n<\/font><\/div>","154f97b0":"<a id=\"train_hierarchical\"><\/a>\n#### 6.2.2 Training the Hierarchical Clustering Model on the Dataset","dc2e15a2":"<a id=\"introduction\"><\/a>\n## 1. Introduction","26b0d1ec":"<a id=\"clustering\"><\/a>\n## 6. Clustering","6bbe1783":"#### Insights:\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team needs to know which clusters or target market they should focus on to optimize their ads for new products and pay in installments, here are some insights and suggestions they should consider:\n<\/font><\/div>\n\n#### 1. Focus on Cluster Orange\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should focus on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> These customers have a high spending score, they would likely to spend more on new products.<\/li>\n  <li>They will most likely be safe to apply for installments based on their annual income.<\/li>\n<\/font><\/ul>\n\n#### 2. Don't Focus on the Yellow and Blue Clusters\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should not focus on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> These customers have a low spending score, they would not likely to spend more on new products.<\/li>\n  <li> Blue cluster is safe to apply for installments based on their annual income unlike Yellow cluster.<\/li>\n<\/font><\/ul>\n\n#### 3. Target Cluster Red But Don't Let Them Apply Installments\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should target on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> These customers have a high spending score, they would not likely to spend more on new products.<\/li>\n  <li>They will most likely be not safe to apply for installments based on their annual income.<\/li>\n<\/font><\/ul>\n\n#### 4. Consider to Target the Purple Cluster But Don't Overdo It \n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should consider to target on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> These customers have an average spending score, they would or would not probably buy the new products<\/li>\n  <li> They will most likely be safe or not to apply for installments based on their annual income.<\/li>\n<\/font><\/ul>\n\n#### 4. Give More Attention to Female Customers\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should give more attention to Female customers on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> Female customers more often to shop at mall than male customer.<\/li>\n<\/font><\/ul>\n\n#### 4. Give More Attention to Customers in the Range of Age 30-35\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should give more attention Customers in age 30-35 on selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> Customers in the rage of age 30-35 more often shop at the mall.<\/li>\n<\/font><\/ul>\n\n#### 4. Give More Attention to Customers Who Have an Annual Income Around 60k\n<div align='left'><font size=\"3\" color=\"#000000\"> The marketing team should give more attention Customers who Have an annual income around 60k to selling their new products on this cluster because:\n<\/font><\/div>\n<ul><font size=\"3\" color=\"#000000\">\n  <li> Customers who have an annual income around 60k dollars more often to shop at the mall<\/li>\n<\/font><\/ul>","853d0c64":"<h1 style='color:white;background-color:black' > Table of Contents <\/h1>\n\n* [Introduction](#introduction)\n* [Data Acquisition](#data_acquisition)\n* [Data Understanding](#data_understanding)\n* [Data Preprocessing](#data_preprocessing)\n    - [Data Cleaning](#data_cleaning)\n    - [Data Transformation](#data_transformation)\n* [Exploratory Data Analysis (EDA)](#eda)\n* [Clustering](#clustering)\n    - [K-Means Clustering](#k_means_clustering)\n        - [Elbow Method](#elbow_method)\n        - [Silhouette Method](#silhouette_method)\n        - [Training the K-Means Model on the Dataset](#train_k_means)\n        - [Visualizing Clusters (K-Means)](#visual_k_means)\n    - [Hierarchical Clustering](#hierarchical_clustering)\n        - [Dendrogram](#dendrogram)\n        - [Training the Hierarchical Clustering Model on the Dataset](#train_hierarchical)\n        - [Visualizing Clusters (Hierarchical)](#visual_hierarchical)","00e5c39a":"<div align='left'><font size=\"3\" color=\"#000000\"> The results showed that the elbow point was at K=5 which indicated the optimal number of clusters, now use this point to train K-Means model on dataset.\n<\/font><\/div>","3c205582":"<a id=\"data_preprocessing\"><\/a>\n## 4. Data Preprocessing","d1a219cd":"#### Elbow Method\n<div align='left'><font size=\"3\" color=\"#000000\"> Finding the optimal number of clusters is an important part of this algorithm. A commonly used method for finding optimal K value is Elbow Method. \nIn the Elbow method, we are actually varying the number of clusters ( K ) from 1 \u2013 10. For each value of K, we are calculating WCSS ( Within-Cluster Sum of Square ). WCSS is the sum of squared distance between each point and the centroid in a cluster. When we plot the WCSS with the K value, the plot looks like an Elbow. As the number of clusters increases, the WCSS value will start to decrease. WCSS value is largest when K = 1. When we analyze the graph we will see that the graph will rapidly change at a point and thus creating an elbow shape.\n    \n> <center><img src=https:\/\/analyticsindiamag.com\/wp-content\/uploads\/2019\/08\/4_wcss.png width=\"450px\"><\/center>\n> <center><font size=\"3\" color=\"#000000\">WCSS Formula    \n    \n    \n<\/font><\/div>\nSource and credit to https:\/\/www.analyticsvidhya.com\/blog\/2021\/01\/in-depth-intuition-of-k-means-clustering-algorithm-in-machine-learning\/","9b02b64d":"<a id=\"visual_hierarchical\"><\/a>\n#### 6.2.2 Visualising Clusters (Hierarchical)","90e63b22":"<a id=\"eda\"><\/a>\n## 5. Exploratory Data Analysis (EDA)","e51d6e2d":"<div align='left'><font size=\"3\" color=\"#000000\"> The results show that the optimal K value based on the Silhoutte Score is 6 because it has the largest coefficient value.\n<\/font><\/div>","d293c00a":"**Encode String Data Type**\n> Gender Column represent as an 'object or string data type therefore it needs to be coverted to numerical.","331c5033":"<a id=\"data_transformation\"><\/a>\n### 4.2 Data Transformation","629bce5a":"<a id=\"elbow_method\"><\/a>\n#### 6.1.1 Elbow Method","67614049":"<a id=\"hierarchical_clustering\"><\/a>\n### 6.2 Hierarchical Clustering","d78851e8":"<a id=\"silhouette_method\"><\/a>\n#### 6.1.2 Silhouette Method","5070244b":"<div align='left'><font size=\"3\" color=\"#000000\"> In this implementation, let's find out from the range of various K values which one is the optimal point of the cluster based WCSS score.\n<\/font><\/div>","60b7a491":"<a id=\"train_k_means\"><\/a>\n#### 6.1.3 Training the K-Means Model on the Dataset","0e807dd8":"<div align='left'><font size=\"3\" color=\"#000000\">From the results shown above, the Euclidean distance shows the similarity of each cluster.\nThe optimal number of clusters can be found where you have the greatest distance, you can move vertically without touching any of these horizontal bars. The results showed that 3 clusters and 5 clusters had close Euclidean distances. But in this implementation let's set 3 as the number of clusters.\n<\/font><\/div>\n\n\n","b4f3e0b3":"<a id=\"visual_k_means\"><\/a>\n#### 6.1.4 Visualizing Clusters (K-Means)","e48a5e71":"<div align='left'><font size=\"3\" color=\"#000000\"> Clustering is a type of unsupervised learning method of machine learning. In the unsupervised learning method, the inferences are drawn from the data sets which do not contain labelled output variable. It is an exploratory data analysis technique that allows us to analyze the multivariate data sets.\n\nClustering is a task of dividing the data sets into a certain number of clusters in such a manner that the data points belonging to a cluster have similar characteristics. Clusters are nothing but the grouping of data points such that the distance between the data points within the clusters is minimal.\n<\/font><\/div>\nSource and credit to https:\/\/www.analyticsvidhya.com\/blog\/2021\/01\/in-depth-intuition-of-k-means-clustering-algorithm-in-machine-learning\/","6d0dab35":"<a id=\"data_acquisition\"><\/a>\n## 2. Data Acquisition","7c016610":"**Data Size**\n> Dataset has 500 rows and 5 features.\n\n**Features**\n> 5 of the features are 4 integer and 1 object data types.","eafddbb0":"# **Mall Customer Clustering**","4c67aeff":"<a id=\"k_means_clustering\"><\/a>\n### 6.1 K-Means Clustering","ce8d9092":"<a id=\"dendrogram\"><\/a>\n#### 6.2.1 Dendrogram","9835555a":"\n<div align='left'><font size=\"3\" color=\"#000000\"> K-Means Clustering is the simplest and commonly used iterative type unsupervised learning algorithm. In this, we randomly initialize the K number of centroids in the data (the number of k is found using the Elbow method which will be discussed later in this article ) and iterates these centroids until no change happens to the position of the centroid. \n    \n**The K-Means steps:**\n\n<ol><font size=\"3\" color=\"#000000\">\n  <li>Select the number of clusters for the dataset ( K ).<\/li>\n  <li>Select K number of centroids.<\/li>\n  <li>By calculating the Euclidean distance or Manhattan distance assign the points to the nearest centroid, thus creating K groups.<\/li>\n  <li>Now find the original centroid in each group.<\/li>\n  <li>Again reassign the whole data point based on this new centroid, then repeat step 4 until the position of the centroid doesn\u2019t change.<\/li>\n<\/font><\/ol>\n\n> <center><img src=https:\/\/wirasetiawan29.files.wordpress.com\/2015\/04\/euclideandistancegraphic.jpg width=\"550px\"><\/center>\n> <center><font size=\"3\" color=\"#000000\">Euclidean Formula\n\n\nSource and credit to https:\/\/www.analyticsvidhya.com\/blog\/2021\/01\/in-depth-intuition-of-k-means-clustering-algorithm-in-machine-learning\/","5f6f6766":"<div align='left'><font size=\"3\" color=\"#000000\"> From the above results, there are 5 clusters represented in different colors and corresponding to 3 Features ('age', 'annual income', and 'spending score') on the x, y, and z axes respectively.\n<\/font><\/div>","998acf9f":"**Missing Values**\n> There is no missing value found in data.\n\n**Drop CustomerID Column**\n> Drop columns CustomerID since it is not used.","24b6ff4c":"<div align='left'><font size=\"3\" color=\"#000000\"> You are owing a supermarket mall and through membership cards , you have some basic data about your customers like Customer ID, age, gender, annual income and spending score.\nSpending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data.\n<\/font><\/div>\n\n* **Problem Statement:**\n<div align='left'><font size=\"3\" color=\"#000000\"> You own the mall and want to understand the customers like who can be easily converge [Target Customers] so that the sense can be given to marketing team and plan the strategy accordingly.\n<\/font><\/div>","478a5657":"#### Silhouette Coefficient:\n<div align='left'><font size=\"3\" color=\"#000000\"> Silhouette Coefficient or silhouette score is a metric used to calculate the goodness of a clustering technique. Its value ranges from -1 to 1.\n<\/font><\/div>\n\n<ul><font size=\"3\" color=\"#000000\">\n  <li>1: Means clusters are well apart from each other and clearly distinguished.<\/li>\n  <li>0: Means clusters are indifferent, or we can say that the distance between clusters is not significant.<\/li>\n  <li>-1: Means clusters are assigned in the wrong way.<\/li>\n  <li>Silhouette Score = (b-a)\/max(a,b)<\/li>\n  <li>a= average intra-cluster distance i.e the average distance between each point within a cluster.<\/li>\n  <li>b= average inter-cluster distance i.e the average distance between all clusters.<\/li>\n<\/font><\/ul>\n\nSource and credit to https:\/\/towardsdatascience.com\/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c","d405c271":"> <center><img src=\"https:\/\/images.unsplash.com\/photo-1580793241553-e9f1cce181af?ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8bWFsbHxlbnwwfHwwfHw%3D&ixlib=rb-1.2.1&w=1000&q=80\" width=\"1000px\"><\/center>"}}