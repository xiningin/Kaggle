{"cell_type":{"c7f28c3f":"code","ac7610c7":"code","bdff9910":"code","b562b195":"code","82a34f95":"code","d0da18a3":"code","03d000ed":"code","7484402a":"code","942d8a21":"code","0770f5f2":"code","fd3d3b02":"code","f1c5b47e":"code","d9922347":"code","b31ab5d9":"code","00753827":"code","1e569a96":"code","4c1ce763":"code","021002a6":"code","68638095":"code","a7c2559e":"code","7871d4ce":"code","07186e1b":"markdown","1fefb33f":"markdown","4b054d73":"markdown","dc994ed0":"markdown","08f2762c":"markdown","2fb1f1d3":"markdown","07fda5c0":"markdown","723f665e":"markdown","53c42831":"markdown"},"source":{"c7f28c3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ac7610c7":"training_data = pd.read_csv(\"..\/input\/train.csv\")\ntraining_data.describe()","bdff9910":"training_data.head()","b562b195":"training_data.isnull().sum()","82a34f95":"training_data.info()","d0da18a3":"n = 0\nfor col in training_data:\n    print (training_data.dtypes.index[n])\n    if (training_data[col].dtypes) == object:\n        if (len(training_data[col].unique())) <= 20:\n            print (\"Encodable - len =\", len(training_data[col].unique()))\n    else:\n        print (\"Should not be encoded\")\n    n += 1","03d000ed":"# Another way to do this is to only print values that should be encoded:\nn = 0\nfor col in training_data:\n    if (training_data[col].dtypes) == object:\n        if (len(training_data[col].unique())) <= 20:\n            print (training_data.dtypes.index[n])\n            print (\"Encodable - len =\", len(training_data[col].unique()))\n    n += 1","7484402a":"# For reference, here is the len of all dtype==object columns.\nn = 0\nfor col in training_data:\n    if (training_data[col].dtypes) == object:\n        print (training_data.dtypes.index[n])\n        print (\"Encodable - len =\", len(training_data[col].unique()))\n    n += 1","942d8a21":"training_data2 = training_data.copy()\ntraining_data2['female'] = training_data2.Sex == 'female'\ntraining_data2.head()","0770f5f2":"training_data3 = training_data2.copy()\ntraining_data3['child'] = training_data2.Age < 16\ntraining_data3.head()","fd3d3b02":"training_data4 = training_data3.copy()\ntraining_data4['Age'] = training_data3.Age.fillna(training_data3['Age'].median())\ntraining_data4.isnull().sum()","f1c5b47e":"# here are the models I'll use for a first-try\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n# here are the metrics I'll check them with\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n# and the code to split the test\/train data\nfrom sklearn.model_selection import train_test_split","d9922347":"# I'm going to write a function to make the confusion matrix easier on the eyes\ndef confusionMatrixBeautification(y_true, y_pred):\n    rows = ['Actually Died', 'Actually Lived']\n    cols = ['Predicted Dead', 'Predicted Lived']\n    conf_mat = confusion_matrix(y_true, y_pred)\n    return pd.DataFrame(conf_mat, rows, cols)","b31ab5d9":"# I also want to split the training_data dataframe into a training and testing portion\ntrain_baseline, test_baseline = train_test_split(training_data4, random_state = 0)\ntrain_baseline.shape, test_baseline.shape","00753827":"# For a first run, I'll try using the following features\nfeatures = ['Age', 'female', 'child', 'Fare', 'Pclass']\ntarget = 'Survived'","1e569a96":"# Now comes fitting the models\nmodel01 = RandomForestClassifier(random_state=0)\nmodel02 = DecisionTreeClassifier(random_state=0)\nmodel03 = LogisticRegression()\n\nmodel01.fit(train_baseline[features], train_baseline[target]);\nmodel02.fit(train_baseline[features], train_baseline[target]);\nmodel03.fit(train_baseline[features], train_baseline[target]);","4c1ce763":"# Now let's define a pretty function to measure the scores of those models\ndef printScore(model_number):\n    print(\"Train Accuracy: \", round(accuracy_score(train_baseline[target], model_number.predict(train_baseline[features]))*100,2), \"%\")\n    print(\"Train Recall: \", round(recall_score(train_baseline[target], model_number.predict(train_baseline[features]))*100,2), \"%\")\n    print(\"Train Confusion Matrix: \\n\", confusionMatrixBeautification(train_baseline[target], model_number.predict(train_baseline[features])))\n    print(\"Test Accuracy: \", round(accuracy_score(test_baseline[target], model_number.predict(test_baseline[features]))*100,2), \"%\")\n    print(\"Test Recall: \", round(recall_score(test_baseline[target], model_number.predict(test_baseline[features]))*100,2), \"%\")\n    print(\"Test Confusion Matrix: \\n\", confusionMatrixBeautification(test_baseline[target], model_number.predict(test_baseline[features])))\n    \ndef printTestRecall(model_number):\n    print(\"Test Recall: \", round(recall_score(test_baseline[target], model_number.predict(test_baseline[features]))*100,2), \"%\")","021002a6":"print(\"RandomForestClassifier()\")\nprintTestRecall(model01)\nprint(\"\\n\\nDecisionTreeClassifier()\")\nprintTestRecall(model02)\nprint(\"\\n\\nLogisticRegression()\")\nprintTestRecall(model03)","68638095":"# I'll run those same models with all features which are numerical\/boolean (except ID)\nfeatures = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'female', 'child']","a7c2559e":"model01.fit(train_baseline[features], train_baseline[target]);\nmodel02.fit(train_baseline[features], train_baseline[target]);\nmodel03.fit(train_baseline[features], train_baseline[target]);","7871d4ce":"print(\"RandomForestClassifier()\")\nprintTestRecall(model01)\nprint(\"\\n\\nDecisionTreeClassifier()\")\nprintTestRecall(model02)\nprint(\"\\n\\nLogisticRegression()\")\nprintTestRecall(model03)","07186e1b":"Looking at those two results, it's apparent that .describe() does not describe non-numeric values such as Name, Sex, Ticket, Cabin, or Embarked. An easy way to describe these values would be .info(). ","1fefb33f":"But that isn't too useful for finding out how many unique values there are. Let's see if there are any dtype==object columns which may be easy to encode. We'll decide what should be encoded by:\n1. Checking if the dtype is object\n2. Checking if the number of unique values is under 20\nThe first check determines if the value is not already an integer or a float. Basically, if a number exists, it's a number, and doesn't need to be encoded as a number.\nThe second check determines the reasonability of encoding a value. For example, there are  (aka, there are under 20 possible categories)","4b054d73":"### Encoding Childhood\nNow I'll explore data where age is notnull and <16 so that I can see if there is anything that may indicate childhood outside of age. I'll do this by adding a column which indicates age under 16","dc994ed0":"Okay, so now we have a baseline. \n67.86% recall with random forest.\n69.05% with decision tree.\n67.86% with logistic regression.\nNone of those will get me on the leaderboard. Let's explore some more data. <br><br>\nGo to next notebook","08f2762c":"Okay, so now we have a baseline. \n71.43% recall with random forest.\n69.05% with decision tree.\n69.05% with logistic regression.\nNone of those will get me on the leaderboard. Let's explore some more data.","2fb1f1d3":"# Establishing a baseline model\nThe best \"first\" thing to do when creating a model is to get a baseline established. Let's do that.","07fda5c0":"## Dealing with missing values in the Age column\nThere is a concern is what to do with NaN values.  For now, we are simply going to replace the null Age values with the median. We can return to this after we have an initial model built and move from there.","723f665e":"## Encoding gender and childhood\nOff the bat, I'm going to encode gender to make it easier for a machine to process. By instinct, it's easy to assume gender will be an important feature, because of the \"get the women and children in first\" code of conduct associated with the sinking of the RMS Titanic. Since childhood is not explicitly stated in the data frame, I will have to base childhood of an age of 15 years or younger (<= 15) or (<16). Since there are only 714 values for age, we will have to deal with null values.\n### Encoding gender\nI will encode gender first by creating a new column called female and setting it to True if the Sex column = 'female'","53c42831":"# Exploring data\nThe first step is to import the data and verify it's been imported correctly. We'll do this with a .describe() and a .head() "}}