{"cell_type":{"99e90274":"code","52e37599":"code","b440c539":"code","3fc9ae50":"code","741cddd4":"code","47ac8d12":"code","6fcecd08":"code","c01f50d5":"code","04744deb":"code","40ba713b":"code","b563889a":"code","7878c917":"code","313fae25":"code","3c2683b6":"code","6aa07c3d":"code","3c2e7f96":"code","f9ff940d":"code","2788f99b":"code","8cdd8ac1":"code","33b2fcae":"code","fac72613":"code","6ca77860":"code","768fb430":"code","bc3bae7c":"markdown","7b49d6c2":"markdown","1aaa7245":"markdown","4daa3987":"markdown","6935868a":"markdown","01f8dce7":"markdown","f467f295":"markdown","70e7d491":"markdown","2d1311be":"markdown"},"source":{"99e90274":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52e37599":"# Imports\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\nimport ast\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nfrom IPython.display import Image\n","b440c539":"tweet_df = pd.read_csv('\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv')\n","3fc9ae50":"# Datetime Conversion\ntweet_df[\"date\"] =pd.to_datetime(tweet_df[\"date\"]).dt.date\n\ntweet_df[\"ctext\"] =tweet_df.text.str.lower()\n\n#Remove twitter handlers\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub('@[^\\s]+','',x))\n\n#remove hashtags\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\B#\\S+','',x))\n\n\n# Remove URLS\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n\n# Remove all the special characters\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n\n#remove all single characters\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n\n# Substituting multiple spaces with single space\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n\ntweet_df.sort_values(\"date\", inplace=True)\ntweet_df.head()","741cddd4":"date_wise_count = tweet_df.groupby(\"date\").agg({\n    \"text\":\"count\"\n}).sort_values(\"date\").reset_index()\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.plot(date_wise_count[\"date\"],date_wise_count[\"text\"],'--X', color='green')\nplt.legend([\"Number of Tweets\"])\nplt.title(\"Frequency of Tweets\")\nplt.show()","47ac8d12":"locationWise = tweet_df.user_location.value_counts().plot(title='Location with most Tweets')","6fcecd08":"hashtags = []\nfor tags in tweet_df.hashtags.unique():\n    if not(tags is np.nan):\n        for _ in ast.literal_eval(tags):\n            hashtags.append(_)\ntext =''\nfor _ in hashtags:\n    text+=\" \"+_","c01f50d5":"# Define a function to plot word cloud\ndef plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.title(\"Popular HashTags\")\n    plt.imshow(wordcloud) \n    plt.axis(\"off\");\n","04744deb":"# Generate word cloud and Plot\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(text)\nplot_cloud(wordcloud)","40ba713b":"# All \"@'s\"\nat = []\nfor text in tweet_df.text.unique():\n    text = re.findall('@[^\\s]+',text )\n    for _ in text:\n        at.append(_)\n\nats = \"\"\nfor _ in at:\n    ats+=_+\" \"","b563889a":"# Generate word cloud and Plot\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(ats)\nplot_cloud(wordcloud)","7878c917":"sid = SentimentIntensityAnalyzer()\ndef sentiments(sentence):\n    ss = sid.polarity_scores(sentence)\n    return (ss[\"pos\"], ss[\"neg\"])\ntweet_df[\"sentiments\"] =tweet_df[\"ctext\"].apply(lambda x: sentiments(x))\ntweet_df[\"text_blob_sentiment\"] =tweet_df[\"ctext\"].apply(lambda x: TextBlob(x).sentiment.polarity) \ntweet_df[\"pos_sentiments\"] =tweet_df[\"sentiments\"].apply(lambda x: float(x[0]))\ntweet_df[\"neg_sentiments\"] =tweet_df[\"sentiments\"].apply(lambda x: float(x[1]))","313fae25":"gtf=tweet_df.groupby(\"date\").agg({\n    \"pos_sentiments\": [\"max\",\"mean\"],\n    \"neg_sentiments\": [\"min\",\"mean\"],\n    \"text_blob_sentiment\":\"mean\"\n}).reset_index()\ngtf.columns= [\"date\",\"ps_max\",\"ps_mean\", \"ns_min\",\"ns_mean\",\"tb_senti_mean\"]","3c2683b6":"plt.plot(gtf[\"date\"],gtf[\"ps_mean\"], 'green' )\nplt.plot(gtf[\"date\"],gtf[\"ns_mean\"], 'red' )\nplt.legend([\"Positive Sentiment\",\"Negative Sentiment\"])\nplt.title(\"Positive and Negative Sentiments of Tweets\")\nplt.show()","6aa07c3d":"plt.plot(gtf[\"date\"],gtf[\"ps_mean\"]-gtf[\"ns_mean\"], \"blue\")\nplt.plot(gtf[\"date\"],gtf[\"tb_senti_mean\"], 'green')\nplt.legend([\"Vader Avg Sentiment\", \"Text Blob Avg Sentiment\"])\nplt.title(\"Average Sentiments of Tweets By TextBlob and Vader\")\nplt.show()","3c2e7f96":"Image(\"..\/input\/newscreenshot\/NewsScreenshot.png\")","f9ff940d":"!pip install transformers==3.0 ","2788f99b":"# Getting a model\nfrom transformers import BertTokenizer\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","8cdd8ac1":"from transformers import BertTokenizer","33b2fcae":"query=\"Is Covid Vaccine Work \"\nquery_embedding = tokenizer.encode(query)","fac72613":"embeddings = tokenizer.encode(tweet_df['ctext'])","6ca77860":"top_k=5\ncos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\ncos_scores = cos_scores.cpu()\n\n#We use torch.topk to find the highest 5 scores\ntop_results = torch.topk(cos_scores, k=top_k)\n\nprint(\"\\n\\n======================\\n\\n\")\nprint(\"Query:\", query)\nprint(\"\\nTop 5 most similar sentences in corpus:\")\n\nfor score, idx in zip(top_results[0], top_results[1]):\n    print(data['text'].values[idx], \"(Score: %.4f)\" % (score))","768fb430":"list(tweet_df['ctext'])","bc3bae7c":"## Sentiment Analysis","7b49d6c2":"### Popular Hashtags","1aaa7245":"# Data Visualization\n","4daa3987":"# Imports and Installs","6935868a":"## **What happend after 15 jan ?**\nBelow news might be the reason for Negative Sentiments on Pfizer Vaccine\n!Image(\"..\/input\/newscreenshot\/NewsScreenshot.png\")\n","01f8dce7":"# Fetch some information from Tweets","f467f295":"### Popular @'s","70e7d491":"Two series **Sentiment By Vader** and **Sentiment By TextBlob** are almost parallel. We may improve accuracy of Sentiments by **Training BERT Sentiment classifier** or any any other Neural Network Model. Leaving it for future improvements. ","2d1311be":"# Read Data"}}