{"cell_type":{"859cb333":"code","10f4c415":"code","665ad98b":"code","ff759940":"code","8266363c":"code","cb049d0f":"code","c22d8232":"code","81cb2479":"code","2882a37f":"code","199f0742":"code","9e4352d5":"code","0db04984":"code","5d2a88a4":"code","d2eaad7f":"code","fdceac23":"code","cbe670b8":"code","a06cb65e":"code","a3638f69":"code","8e9ccc1f":"code","09fa0a18":"code","2d7901cd":"code","b09fd095":"code","4e61a0f0":"code","4db4d30e":"code","8a1fee00":"code","fcbf23cc":"code","664802f4":"code","e4caa5fe":"code","9b41a13a":"code","2b75dbd6":"code","dc1b9341":"code","ac407689":"code","5de4bd7d":"code","6c202bbd":"code","c98d2563":"code","1884a835":"code","af7b3a78":"code","40d9cd55":"code","b182a544":"code","d587dc7f":"code","c781b72f":"code","07d3eaa4":"code","c76d95b7":"markdown","f0446c53":"markdown","d5d204f0":"markdown","aa274d31":"markdown","307e083c":"markdown","3c4125f0":"markdown","a11bb73d":"markdown","c91e1fe6":"markdown","763e5473":"markdown","d5d0ee4f":"markdown","e7902891":"markdown","a8d6ea0c":"markdown"},"source":{"859cb333":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom fastai.vision import *\nfrom PIL import Image\nimport os\n\ntorch.cuda.get_device_name(0)\n\n# PyTorch works best as a low-level foundation library, providing the basic operations for higher level functionality. \n# The fastai library is the most popular library for adding this higher-level functionality on top of PyTorch. \n","10f4c415":"# Fashion MNIST dataset is stored in .csv files. Let's read them as a pandas table:\n\npath = '\/kaggle\/input'\nmnist_train = pd.read_csv(path+'\/fashionmnist\/fashion-mnist_train.csv')\nmnist_test = pd.read_csv(path+'\/fashionmnist\/fashion-mnist_test.csv')\n\n# mnist_train's head:\nmnist_train.head()","665ad98b":"mkdir'\/kaggle\/working\/train'","ff759940":"mkdir'\/kaggle\/working\/test'","8266363c":"# result = Image.fromarray(np.uint8(np.stack(mnist_test.iloc[0,1:].to_numpy().reshape((28,28))*3,axis=-1))) \n# result.save('..\/kaggle\/working\/train\/'+str(0)+'.png')","cb049d0f":"# we need to convert pixel values and store it as images to be able to benefit from fastai library ImageDataBunch loader. So, here's the function:\n# if your dataset is stored as images, you can skip this step. If not,you can modify this function.\n\ndef csv2img(csv,path='\/kaggle\/working\/train\/'): \n    \"\"\"\n    Convert pixel values from .csv to .png image\n    \"\"\"\n    for i in range(len(csv)):\n        # csv.iloc[i,1:].to_numpy() returns pixel values array for i'th imag excluding the label \n        # next step: reshape the array to original shape(28,28) and add missing color channels \n        result = Image.fromarray(np.uint8(np.stack(np.rot90(csv.iloc[i,1:].to_numpy().reshape((28,28)))*3,axis=-1))) \n        # save the image:\n        result.save(f'{path}{str(i)}.png')\n        \n    print(f'{len(csv)} images were created.')\n\n# let's run the fuction:\ncsv2img(mnist_train)\ncsv2img(mnist_test,path='\/kaggle\/working\/test\/')","c22d8232":"# check if the num of images in df and in the folder match: \nlen(os.listdir('\/kaggle\/working\/train')) == len(mnist_train)","81cb2479":"# let's add text labels to the pandas table, we will use them for model training. \n\ndict_fashion = {\n0:'T-shirt\/top',\n1:'Trouser',\n2:'Pullover',\n3:'Dress',\n4:'Coat',\n5:'Sandal',\n6:'Shirt',\n7:'Sneaker',\n8:'Bag',\n9:'Ankle boot'}\n\nmnist_train['label_text'] = mnist_train['label'].apply(lambda x: dict_fashion[x])\nmnist_test['label_text'] = mnist_test['label'].apply(lambda x: dict_fashion[x])\n\n# add image names:\nmnist_train['img'] = pd.Series([str(i)+'.png' for i in range(len(mnist_train))])\nmnist_test['img'] = pd.Series([str(i)+'.png' for i in range(len(mnist_test))])\n","2882a37f":"# save corresponding labels and image names to .csv file:\nmnist_train[['img','label_text']].to_csv('\/kaggle\/working\/labels.csv',index=False)\nmnist_test[['img','label_text']].to_csv('\/kaggle\/working\/test.csv',index=False)\n","199f0742":"# Here, we load our images using the information stored in 'labels.csv': 'img' column includes image names; 'label_text' column includes lables.\n# There are different ways to load the data into fastai's Data Block API, for more details please see the link: https:\/\/docs.fast.ai\/data_block.html\n\ndata = (ImageList.from_csv('\/kaggle\/working\/', 'labels.csv', folder='train')\n        #Where to find the data? -> in '\/kaggle\/working\/train' folder\n        .split_by_rand_pct(seed=12)\n        #How to split in train\/valid? -> randomly with the default 20% in valid. There's an option to split by folfder or by id\n        .label_from_df()\n        #How to label? -> use the second column of the csv file and split the tags by ' '. \/ can be labeled by subfolder name\/ can be labeled by applying regex to image name\n        #.transform(tfms)\n        #Data augmentation? -> use tfms with a size of 28. \n        .databunch() # change batch size and number of workers by passing arguments: (bs=32, num_workers=4, collate_fn=bb_pad_collate)\n        #Finally -> use the defaults for conversion to databunch\n        #.normalize()\n       )   \n        # Normalize x with mean and std, If you're using a pretrained model, you'll need to use the normalization that was used to train the model (e.g., imagenet_stats)\n\n# Show image batch:\ndata.show_batch(rows=3, figsize=(6,6))\n\n\n#################################\n# one image:\n# img,label = data.train_ds[5365]\n# img\n# define ImageDataBunch: \n# data = ImageDataBunch.from_df(path = '\/kaggle\/working\/train\/',df = mnist_train[['img','label_text']], seed = 12)","9e4352d5":"#  cnn_learner helps to automatically get a pretrained model from a given architecture with a custom head that is suitable for our data.\n\nlearn = cnn_learner(data, models.resnet34, metrics=[accuracy])\n\n# available metrics: error_rate,accuracy, and others: https:\/\/docs.fast.ai\/metrics.html\n\n# available model architectures: https:\/\/docs.fast.ai\/vision.models.html\n# pretrained weights: True by default\n# last layer removed and replaced new layer(head) with randomized weights, of an appropriate size for the dataset.\n","0db04984":"# Initial training:\n\nlearn.fit_one_cycle(4)\n\n\n# What is fit one cycle approach? \n# shortly: this way of training the network reduces the training time and improves performance.\n","5d2a88a4":"def interpret_res(plot_top_losses=True, conf_matrix=True, most_confused=False):\n    \"\"\"\n    Result interpretation includes top losses, confusion matrix, and most confused.\n    \"\"\"\n    \n    # plot top losses:\n    if plot_top_losses==True:\n        interp = ClassificationInterpretation.from_learner(learn)\n        losses,idxs = interp.top_losses()\n        len(data.valid_ds)==len(losses)==len(idxs)\n        interp.plot_top_losses(9, figsize=(12,12))\n\n    # plot confusion matrix:\n    if conf_matrix==True:\n        doc(interp.plot_top_losses)\n        interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n\n    # most confused:\n    if most_confused==True:\n        interp.most_confused(min_val=100)","d2eaad7f":"# we can see that it's not obvious even for human to classify the image properly:\n\ninterpret_res()","fdceac23":"# we are looking for the sharpest downward slope range:\nlearn.lr_find()\nlearn.recorder.plot()","cbe670b8":"# unfreeze pre-trained weights and choose LR from previous step:\n\nlearn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(1e-4,1e-3))","a06cb65e":"# to save the model:\nlearn.save('resnet-temp')\n# to load the model:\n# learn.load('resnet-temp');","a3638f69":"# Let's try another architecture with bigger number of parameters - ResNet50:\n\nlearn_resnet50 = cnn_learner(data, models.resnet50, metrics=[error_rate,accuracy])","8e9ccc1f":"learn_resnet50.lr_find()\nlearn_resnet50.recorder.plot()","09fa0a18":"learn_resnet50.fit_one_cycle(4,max_lr=slice(1e-4,1e-2))","2d7901cd":"# let's save the weights. We can come back to this stage if during experimentation smth happens:\nlearn_resnet50.save('learn_resnet50')\n# learn_resnet50.load('learn_resnet50');","b09fd095":"learn_resnet50.lr_find()\nlearn_resnet50.recorder.plot()","4e61a0f0":"# unfreeze pre-trained weights:\n# here, lr should be usually smaller than at the previous stage. Cuz we just need to fine-tune the weights, not to ruin them :)\n# resnet50 has more weights and thus needs to be trained longer:\n\nlearn_resnet50.unfreeze()\nlearn_resnet50.fit_one_cycle(4, max_lr=1e-4)","4db4d30e":"learn_resnet50.save('learn_resnet50_stage_2')","8a1fee00":"learn_resnet50.lr_find()\nlearn_resnet50.recorder.plot()","fcbf23cc":"learn_resnet50.fit_one_cycle(4, max_lr=slice(1e-6,1e-5))\n# model overfits the data (train loss goes down, valid loss is the same), accuracy drops:","664802f4":"learn_resnet50.load('learn_resnet50_stage_2')\ninterpret_res()","e4caa5fe":"help(get_transforms)","9b41a13a":"# Examples of image augmentaion:\n\ntfms = get_transforms(do_flip=True,flip_vert=True,max_rotate=25)\ndef get_ex(): return open_image('\/kaggle\/working\/train\/1.png')\n\ndef plots_f(rows, cols, width, height, **kwargs):\n    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n        rows,cols,figsize=(width,height))[1].flatten())]\n    \nplots_f(2, 4, 12, 6, size=28)","2b75dbd6":"# define transforms:\n\ntfms = get_transforms(do_flip=False,max_rotate=20)\n\n# load data:\ndata = (ImageList.from_csv('\/kaggle\/working\/', 'labels.csv', folder='train')\n        .split_by_rand_pct(seed=12)\n        .label_from_df()\n        .transform(tfms)\n        #Data augmentation? -> use tfms with a size of 28. Also, we can transform the image size adding another arg: (224,224)\n        .databunch() \n        .normalize(imagenet_stats)\n        # Normalize x with mean and std, If you're using a pretrained model, you'll need to use the normalization that was used to train the model (e.g., imagenet_stats)\n       )   \n        \n    \ndata.show_batch(rows=4, figsize=(10,6))","dc1b9341":"# choose model:\nlearn = cnn_learner(data, models.resnet34, metrics=[error_rate,accuracy])","ac407689":"# training head:\nlearn.fit_one_cycle(4)","5de4bd7d":"# choose suitable learning rate:\nlearn.lr_find()\nlearn.recorder.plot()","6c202bbd":"learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))","c98d2563":"learn.save('test-21')","1884a835":"learn.fit_one_cycle(4, max_lr=1e-4)","af7b3a78":"# unfreeze weights:\n\nlearn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=1e-4)\n\n# probably, we should change the augmentation method and\/or try to train longer. Or choose higher lr","40d9cd55":"# interpret results: \ninterpret_res()","b182a544":"# export .pkl file:\nlearn.export()\n# load:\nlearn = load_learner('\/kaggle\/working')\n\n## https:\/\/docs.fast.ai\/tutorial.inference.html#Create-a-Learner-for-inference","d587dc7f":"# run model inference on random image:\n\nimg = data.train_ds[0][0]\nlearn.predict(img)\n\n# Out: a tuple of three things: \n#         - object predicted (with the class in this instance), \n#         - underlying data (here the corresponding index) \n#         - raw probabilities. \n\n# You can also do inference on a larger set of data by adding a test set. This is done by passing an ItemList to load_learner.","c781b72f":"# load inference model and test set:\n\nlearn = load_learner('\/kaggle\/working\/', test=ImageList.from_folder('\/kaggle\/working\/test'))","07d3eaa4":"# run predictions on test set:\npreds,y = learn.get_preds(ds_type=DatasetType.Test)\n\n# sort predictions by value, return the index (corresponds to the class):\npreds[:5].argsort()","c76d95b7":"## 8. MODEL INFERENCE AND PREDICTION\n\n- export model using Pickle (the standard way of serializing objects in Python) \n- load the model (all the settings saved)\n- predict the image class","f0446c53":"POSSIBLE IMPROVEMENTS:\n    \n    1. After fine-tuning stage, change the size of the input images and repeat head training and finetuning, and then again.\n    2. memory purge # purge(clear_opt:bool=True)\n    ","d5d204f0":"# 0. THEORY\n\n    \n    \n### An algorithm to perform machine learning experiment:\n    1. preprocess data\n    2. split the data to training\/validation\/test sets\n    3. build an initial system\n    4. use bias\/variance analysis and error analysis to tune the system\n\n### The priority of different hyperparameters to tune\n    - First important: learning rate\n    - Second important: mini-batch size\n    - Third important: number of layers, learning rate decay\n    - Rarely tuned: hyperparameters of Adam optimization ( beta 1, beta 2, epsilon)\n\n### Mini-batch size experimentation\n    The advantage of using mini-batch gradient descent is in speed performance, although it adds\n    some noise. How to choose batch size:\n    \n    - Mini-batch should fit in CPU\/GPU memory \u2013 depends on the dataset and memory capacity.\n    - For a small training set (N<2000) is better to use batch gradient descent (the whole dataset).\n    - Typical mini-batch sizes: 64,128,256,512 etc.\n    \n### A training pipeline algorithm for bias\/variance analysis:\n\n    1. Check if the algorithm has a high bias (training dataset performance):\n        - try the network with more hidden layers or hidden units (almost always helps)\n        - try a higher number of epochs (more extended training, does not always help but almost never hurts)\n        - try different NN architecture\n        - change optimization algorithm (RMSProp, Momentum, Adam optimizer)\n    2. Repeat the steps until bias is reduced to an acceptable amount.\n    3. Check if the algorithm has a high variance (validation set performance):\n        - get more data\n        - data augmentation\n        - try regularization\n        - try another architecture\n        - tune hyperparameters\n    4. Training a bigger network almost never hurts. The downside is computational time.\n    5. Make sure that the test set performs well on the cost function:\n        - Bigger validation set\n    6. Make sure that it works in the real-world application:\n        - Distribution mismatch\n        - Change validation set\n        - Change cost functions.\n","aa274d31":"# 3. FastAI Data block API\n\n### The data block API lets you customize the creation of a DataBunch by isolating the underlying parts of that process in separate blocks, mainly:\n\n- Where are the inputs and how to create them?\n- How to split the data into a training and validation sets?\n- How to label the inputs?\n- What transforms to apply?\n- How to add a test set?\n- How to wrap in dataloaders and create the DataBunch?","307e083c":"# 5. INTERPRETATION OF RESULTS","3c4125f0":"# 1. IMPORT MODULES","a11bb73d":"### FastAI library can be used to solve different types of problems.: collab. filtering, vision, text, tabular. More info: [[docs.fast.ai]](https:\/\/docs.fast.ai\/applications.html#data).<br\/>In each case (except for collab filtering), the module is organized this way:\n\n- **transform:**\n  data pre-processing (data augmentation for images, cleaning for tabular data, tokenizing and numericalizing for text).\n\n-  **data:**\n   dataset class(es) definition to deal with this kind of data (images, text, table data, etc.)\n\n-  **models:**\n   specific models used for this kind of data (vision: resnet, densenet, vgg, alexnet, unet, Yolo; more info at [[docs.fast.ai]](https:\/\/docs.fast.ai\/applications.html)\n\n-  **learner:**\n   contains functions that will directly bind this data with a suitable model and add the necessary callbacks.\n   \nSource: [[docs.\/fast\/ai\/applications]](https:\/\/docs.fast.ai\/applications.html#data)\n","c91e1fe6":"# 6. FINETUNING\n\n1. Find appropriate learning rate\n2. Unfreeze pre-trained weights\n3. Bias\/variance analysis - repeat until sutisfied \n\n### <b>Learning rate finder lr_find():<\/b>\n    - Lets find the optimum learning rate for our comparison by doing an LR range test.\n    - Learning rate finder: plots lr vs loss relationship to reduce the amount of guesswork on picking a good starting learning rate.\n    - paper: https:\/\/arxiv.org\/abs\/1506.01186\n\n","763e5473":"# 2. DATA PREPARATION","d5d0ee4f":"# 7. DATA AUGMENTATION AND NORMALIZATION\n#### **vision.transform** lets us do data augmentation: rotation, translation, zoom, crop, flip, and more.","e7902891":"# IMAGE CLASSIFICATION PIPELINE W\/ FastAI: Fashion MNIST\n\n<b>The aim of this kernel:<\/b>\n- Build a multi-class image classifier on the fashion MNIST dataset using a Convolutional Neural Network (CNN) based model.\n- Make the library flexible enough to train an image classifieron a different dataset and be written in a way to allow anyone to use it.\n- Accuracy at this stage is not the main goal.\n\n\n# STEPS: \n1. Import appropriate modules\n2. Data preparation\n3. FastAI Data block API\n4. Model training\n5. Result interpretation\n6. Finetuning\n7. Data augmentation\/ normalization \n8. Model inference\/ prediction\n    \n","a8d6ea0c":"# 4. MODEL TRAINING\n\n\n- The main purpose of Learner is to train model using Learner.fit. \n- After every epoch, all metrics will be printed and also made available to callbacks.\n- Trainer for model using data to minimize loss_func with optimizer opt_func.\n\n### <b>\"fit one cycle\" approach:<\/b>\n    1. We progressively increase our learning rate from lr_max\/div_factor to lr_max and at the same time we progressively decrease our momentum from mom_max to mom_min.\n    2. We do the exact opposite: we progressively decrease our learning rate from lr_max to lr_max\/div_factor and at the same time we progressively increase our momentum from mom_min to mom_max.\n    3. We further decrease our learning rate from lr_max\/div_factor to lr_max\/(div_factor x 100) and we keep momentum steady at mom_max.\n\n    Source: https:\/\/docs.fast.ai\/callbacks.one_cycle.html#What-is-1cycle?\n    paper: https:\/\/arxiv.org\/pdf\/1803.09820.pdf \n"}}