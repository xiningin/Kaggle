{"cell_type":{"aac89947":"code","e45dc6d2":"code","cbb18bd9":"code","e8108fbb":"code","44270302":"code","8215b745":"code","0bafeccc":"markdown","5796740c":"markdown","84ace418":"markdown","b5ccf4f3":"markdown","617e9fb7":"markdown"},"source":{"aac89947":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport json\nimport functools\nimport matplotlib.pyplot as plt\nimport time\nimport cv2\nimport random\n\ndataset_dir = '..\/input\/rect_dataset\/rect_dataset\/'\ntrain_file = 'train_ann.json'\nvalidation_file = 'validation_ann.json'","e45dc6d2":"def to_np_array(data):\n    return np.array(list(map(lambda x: np.array(x), data)))\n\n\ndef draw_sample(file, bbox_gt, bbox_pred=None):\n    if type(file) is not np.ndarray:\n        img = cv2.imread(file)\n    else:\n        img = file\n    pt1 = lambda x: (int(x[0]*img.shape[1]), int(x[1]*img.shape[0]))\n    pt2 = lambda x: (int(x[2]*img.shape[1]), int(x[3]*img.shape[0]))\n    img = cv2.rectangle(img, pt1(bbox_gt), pt2(bbox_gt), (50,255,50), 3)\n    if bbox_pred is not None:\n        img = cv2.rectangle(img, pt1(bbox_pred), pt2(bbox_pred), (255,50,50), 3)\n        \n    return img\n\n\ntrain_data = pd.read_json(os.path.join(dataset_dir, train_file))\nvalidation_data = pd.read_json(os.path.join(dataset_dir, validation_file))\n\nx_train, y_train = to_np_array(train_data['fname']), to_np_array(train_data['box'])\nx_test, y_test = to_np_array(validation_data['fname']), to_np_array(validation_data['box'])\n\nx_train = np.array(list(map(lambda x: os.path.join(dataset_dir, x), x_train)))\nx_test = np.array(list(map(lambda x: os.path.join(dataset_dir, x), x_test)))\n\ny_train = np.array(list(map(lambda x: np.array([x[0]\/320, x[1]\/240, x[2]\/320, x[3]\/240]), y_train)))\ny_test = np.array(list(map(lambda x: np.array([x[0]\/320, x[1]\/240, x[2]\/320, x[3]\/240]), y_test)))\n\nhist_x = np.hstack((y_train[:, 0]+(y_train[:, 2]-y_train[:, 0])\/2, y_test[:, 0]+(y_test[:, 2]-y_test[:, 0])\/2))\nhist_y = np.hstack((y_train[:, 1]+(y_train[:, 3]-y_train[:, 1])\/2, y_test[:, 1]+(y_test[:, 3]-y_test[:, 1])\/2))\nhist_w = np.hstack((y_train[:, 2]-y_train[:, 0], y_test[:, 2]-y_test[:, 0]))\nhist_h = np.hstack((y_train[:, 3]-y_train[:, 1], y_test[:, 3]-y_test[:, 1]))\n\nfig, axs = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(20, 5), dpi=80)\naxs[0].hist(hist_x, bins=20, label='X-center distibution', color='#68a0f9')\naxs[0].legend()\naxs[1].hist(hist_y, bins=20, label='Y-center distibution', color='#f96868')\naxs[1].legend()\naxs[2].hist(hist_w, bins=20, label='Width distibution', color='#68f9cb')\naxs[2].legend()\naxs[3].hist(hist_h, bins=20, label='Height distibution', color='#bff968')\naxs[3].legend()\n\nrows = 4\ncols = 4\n\nfig, axs = plt.subplots(rows, cols, sharex=True, sharey=True, figsize=(20, 15), dpi=80)\n\nfor i in range(rows):\n    for j in range(cols):\n        idx = random.randint(0, len(x_train)-1)\n        img = draw_sample(x_train[idx], y_train[idx])\n        axs[i, j].imshow(img)","cbb18bd9":"def parse_function(filename, label):\n        image_string = tf.read_file(filename)\n        image = tf.image.decode_png(image_string, channels=3)\n        return image, label\n\ndef train_preprocess(image, label):\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    return image, label\n\n\ndef build_dataset(files, labels, batch_size, epochs, prefetch_count = 1):\n        def build_dataset_lambda():\n            dataset = tf.data.Dataset.from_tensor_slices((files, labels))\n            dataset = dataset.shuffle(len(files))\n            dataset = dataset.repeat(epochs)\n            dataset = dataset.map(parse_function, num_parallel_calls=4)\n            dataset = dataset.map(train_preprocess, num_parallel_calls=4)\n            dataset = dataset.batch(batch_size)\n            dataset = dataset.prefetch(prefetch_count)\n            return dataset\n\n        return build_dataset_lambda\n    \ndef make_dataset_minibatch_generator(x, y, batch_size, epochs, sess):\n    dataset = build_dataset(x, y, batch_size, epochs, 1)()\n    iterator = dataset.make_initializable_iterator()\n    generator = iterator.get_next()\n    sess.run(iterator.initializer)\n    return generator\n\ndef load_feed_dict(sess, generator, X, Y):\n    batch = sess.run(train_batch_generator)\n    feed_dict = {X:batch[0], Y:reshape_y_tensor(batch[1])}\n    return feed_dict\n\ndef reshape_y_tensor(x_tensor):\n    return x_tensor.reshape([len(x_tensor), -1])","e8108fbb":"def bb_intersection_over_union(boxA, boxB):\n    xA = tf.maximum(boxA[0], boxB[0])\n    yA = tf.maximum(boxA[1], boxB[1])\n    xB = tf.minimum(boxA[2], boxB[2])\n    yB = tf.minimum(boxA[3], boxB[3])\n \n    interArea = tf.maximum(0.0, xB - xA + 1.0) * tf.maximum(0.0, yB - yA + 1.0)\n \n    boxAArea = (boxA[2] - boxA[0] + 1.0) * (boxA[3] - boxA[1] + 1.0)\n    boxBArea = (boxB[2] - boxB[0] + 1.0) * (boxB[3] - boxB[1] + 1.0)\n\n    iou = interArea \/ (boxAArea + boxBArea - interArea)\n    return iou\n\ntf.reset_default_graph()\n\nX = tf.placeholder(dtype=tf.float32, shape=[None, 240, 320, 3], name='X_input')\nY = tf.placeholder(dtype=tf.float32, shape=[None, 4], name='Y_input')\n\nnet = X\n\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=4, activation=tf.nn.relu)\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=4, activation=tf.nn.relu)\nnet = tf.layers.max_pooling2d(inputs=net, pool_size=(2,2), strides=(2,2))\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=8, activation=tf.nn.relu)\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=8, activation=tf.nn.relu)\nnet = tf.layers.max_pooling2d(inputs=net, pool_size=(2,2), strides=(2,2))\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=16, activation=tf.nn.relu)\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=16, activation=tf.nn.relu)\nnet = tf.layers.max_pooling2d(inputs=net, pool_size=(2,2), strides=(2,2))\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=32, activation=tf.nn.relu)\nnet = tf.layers.conv2d(inputs=net, kernel_size=(3,3), strides=(1,1), filters=32, activation=tf.nn.relu)\nnet = tf.layers.max_pooling2d(inputs=net, pool_size=(2,2), strides=(2,2))\n\nnet = tf.layers.flatten(inputs=net)\n\nnet = tf.layers.dropout(inputs=net, rate=0.5)\nnet = tf.layers.dense(inputs=net, units=5000, activation=tf.nn.relu)\nnet = tf.layers.dropout(inputs=net, rate=0.4)\nnet = tf.layers.dense(inputs=net, units=320, activation=tf.nn.relu)\nnet = tf.layers.dropout(inputs=net, rate=0.2)\nnet = tf.layers.dense(inputs=net, units=64, activation=tf.nn.relu)\nlogits = tf.layers.dense(inputs=net, units=4)\n\niou = bb_intersection_over_union(Y, logits)\nloss = tf.losses.mean_squared_error(labels=Y, predictions=logits)\n\nopt = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)","44270302":"epochs = 60\ntrain_batch_size = 64\ntest_batch_size = 64\ndelay_show = 7\niter_per_epoch = len(x_train)\/\/train_batch_size\niter_per_epoch_test = len(x_test)\/\/test_batch_size\nbest_acc = 0\nrestore = False\n\nwith tf.Session() as sess:\n    saver = tf.train.Saver()\n    \n    print (\"Load dataset...\", end='')\n    train_batch_generator = make_dataset_minibatch_generator(x=x_train,\n                                                                         y = y_train,\n                                                                         batch_size=train_batch_size,\n                                                                         epochs=epochs*2,\n                                                                         sess=sess)\n    test_batch_generator =  make_dataset_minibatch_generator(x=x_test,\n                                                                        y = y_test,\n                                                                        batch_size=test_batch_size,\n                                                                        epochs=epochs*2,\n                                                                        sess=sess)\n    print (\"done\")\n    \n    print(\"Initializing...\", end='')\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.local_variables_initializer())\n    if restore:\n        saver.restore(sess, \".\/model.ckpt\")\n    \n    print('done')\n    \n    for e in range(epochs):\n        loss_stat = []\n        acc_stat = []\n        loss_stat_test = []\n        acc_stat_test = []\n        \n        next_time = time.time()-1\n        for i in range(iter_per_epoch):\n            feed_dict = load_feed_dict(X=X, Y=Y, generator=train_batch_generator, sess=sess)\n            _, _loss, _iou = sess.run([opt, loss, iou], feed_dict=feed_dict)\n            loss_stat.append(_loss)\n            acc_stat.append(_iou)\n            \n            if time.time() > next_time:\n                print(\"Epoch {} | Iteration {}\/{} [{:0.2f}%] | Loss: {} IOU: {}\".format(e,\n                                                                                        i,\n                                                                                        iter_per_epoch,\n                                                                                        (i+1)\/iter_per_epoch*100,\n                                                                                        np.mean(loss_stat),\n                                                                                        np.mean(acc_stat)))\n                next_time = time.time()+delay_show\n            \n        print('End epoch. Testing...')\n        \n        for i in range(iter_per_epoch_test):\n            feed_dict = load_feed_dict(X=X, Y=Y, generator=test_batch_generator, sess=sess)\n            _, _loss, _iou = sess.run([opt, loss, iou], feed_dict=feed_dict)\n            loss_stat_test.append(_loss)\n            acc_stat_test.append(_iou)\n            \n            if time.time() > next_time:\n                print(\"[TEST] Epoch {} | Iteration {}\/{} [{:0.2f}%] | Loss: {} IOU: {}\".format(e,\n                                                                                                i,\n                                                                                                iter_per_epoch_test,\n                                                                                                (i+1)\/iter_per_epoch_test*100,\n                                                                                                np.mean(loss_stat_test),\n                                                                                                np.mean(acc_stat_test)))\n                next_time = time.time()+delay_show\n                \n        loss_stat = np.mean(loss_stat)\n        acc_stat = np.mean(acc_stat)\n        loss_stat_test = np.mean(loss_stat_test)\n        acc_stat_test = np.mean(acc_stat_test)\n        print(\"***EPOCH SUMMARY*** Loss: {} Acc: {} | Test Loss: {} Test IOU {}\".format(loss_stat, acc_stat, loss_stat_test, acc_stat_test))\n    \n        if acc_stat > best_acc:\n            best_acc = loss_stat_test\n            save_path = saver.save(sess, \".\/model.ckpt\")\n            print(\"Model saved in path: %s\" % save_path)","8215b745":"rows = 4\ncols = 4\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.local_variables_initializer())\n    saver.restore(sess, \".\/model.ckpt\")\n    \n    dataset = build_dataset(x_test, y_test, 1, 1, 1)()\n    iterator = dataset.make_initializable_iterator()\n    generator = iterator.get_next()\n    sess.run(iterator.initializer)\n    \n    fig, axs = plt.subplots(rows, cols, sharex=True, sharey=True, figsize=(20, 15), dpi=80)\n\n    for i in range(rows):\n        for j in range(cols):\n            \n            sample = sess.run(generator)\n            feed_dict = {X:sample[0], Y:sample[1]}\n            _bbox, _loss = sess.run([logits, loss], feed_dict=feed_dict)\n            \n            \n            _img = (sample[0][0,:,:,:]*255).astype(np.uint8)\n            img = draw_sample(_img, sample[1][0], _bbox[0])\n            axs[i, j].imshow(img)","0bafeccc":"## Model building\n\nThere are used convolutional neural network for rectangle detection. Model uses full image as input and 4 float number - bounding box as ground truth output. Model doesn't use huge amount convolutional filters beacuse data isn't so hard. There are defined IOU metrics. We don't use tensorflow IOU metrcis, beacuse there are only detection task, not detection and classification","5796740c":"# Let's go exploration rectangle dataset","84ace418":"# Let's train our model.\n\nWe belive, we can get good results after ~60 epochs","b5ccf4f3":"# Model evaluation\n\nNow we can test our model with visualization. Green bounding box - ground truth, red - prediction","617e9fb7":"## There are some prepared utils for tensorflow training\n\nThis utils include:\n* Loading dataset runtime using CPU while GPU is processing some batch\n* Image preprocessing\n* Building batch generator from dataset\n* Loading feed dictionary"}}