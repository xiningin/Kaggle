{"cell_type":{"bda30a20":"code","8a93efb3":"code","4bb78cc7":"code","11070fde":"code","62572d77":"code","814def4d":"code","ada8ee19":"code","1cd5f672":"code","3d8626f0":"code","39d07843":"code","cfbe1758":"markdown","c1fdb57f":"markdown","adde3cef":"markdown","9e2beb1b":"markdown","55a7d3d8":"markdown","bf00c5e7":"markdown","8460b49c":"markdown","49afa93a":"markdown","8c23f650":"markdown"},"source":{"bda30a20":"!pip install stable-baselines3[extra]","8a93efb3":"import gym\n\nfrom stable_baselines3 import DQN, PPO","4bb78cc7":"env = gym.make(\"CartPole-v1\")\n\nmodel = PPO(\"MlpPolicy\", env, verbose=0)\nmodel.learn(total_timesteps=10000)","11070fde":"from stable_baselines3.common.evaluation import evaluate_policy","62572d77":"eval_env = gym.make('CartPole-v1')\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n\nprint(f\"mean_reward:{mean_reward:.2f} +\/- {std_reward:.2f}\")","814def4d":"!apt-get install python-opengl -y\n!pip install pyvirtualdisplay","ada8ee19":"!pip install pyglet","1cd5f672":"import gym\nimport os\nimport matplotlib.pyplot as plt\nfrom pyvirtualdisplay import Display\n\ndisplay = Display(visible=0, size=(1400, 900))\ndisplay.start()","3d8626f0":"env = gym.make(\"CartPole-v1\")\n\nenv.reset()\nplt.imshow(env.render('rgb_array'))\nplt.grid(False)","39d07843":"obs = env.reset()\nfor i in range(100):\n    action, _states = model.predict(obs)\n    obs, rewards, dones, info = env.step(action)\n    plt.imshow(env.render('rgb_array'))\n    plt.show()","cfbe1758":"On utilise Stable Baselines qui est une impl\u00e9mentation des algorithmes de renforcement par OpenAI   \nLe derni\u00e8re version 3 utilise Pytorch comme framework sous-jacent (les versions pr\u00e9c\u00e9dentes utilisent Tensorflow)   \nhttps:\/\/stable-baselines3.readthedocs.io\/en\/master\/","c1fdb57f":"Evluation de l'agent","adde3cef":"On va choisir une politique PPO (*Proximal Policy Optimization*) : https:\/\/openai.com\/blog\/openai-baselines-ppo\/   \nOn pr\u00e9cise \"MlpPolicy\" pour un mod\u00e8le dense simple. Pour un probl\u00e8me o\u00f9 les entr\u00e9es sont des images (par exemple les jeux Atari), on choisirait \"CnnPolicy\"","9e2beb1b":"On peut jouer l'effet de l'agent :","55a7d3d8":"## Visualisation des r\u00e9sultats","bf00c5e7":"On affiche un environnement","8460b49c":"# Cartpole avec Stable baselines 3","49afa93a":"On initialise l'affichage","8c23f650":"On installe les modules opengl, pyvirtualdisplay et Pyglet pour afficher l'environnement Gym"}}