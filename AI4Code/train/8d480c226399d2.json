{"cell_type":{"613318da":"code","39ad538f":"code","de2ddfc2":"code","939820cc":"code","71b093a8":"code","ecf5f95a":"code","04bb675b":"code","aee04c1e":"code","1dff2b91":"code","fc97a995":"code","73b97869":"markdown","6210ce91":"markdown","7354a8de":"markdown","bdc1891d":"markdown","c61a75a5":"markdown","cb726da9":"markdown","1509ee50":"markdown","fbbe961d":"markdown","5eee44a7":"markdown","e83895d8":"markdown"},"source":{"613318da":"import numpy as np\nimport pandas as pd\ntrain_data = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/test.csv')","39ad538f":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values\n    summary['Total'] = df.count().values   \n    summary['Missing Percentage']=(summary['Missing']\/summary['Total'])*100\n    summary['Uniques'] = df.nunique().values\n    summary['Uniques_val'] = [df[col].unique() for col in df.columns]\n    return summary\n\nresumetable(test_data)","de2ddfc2":"def fillna_sample(df):\n    for col in df.columns:\n        df.loc[df[col].isna(),col] = df[col][-df[col].isna()].sample(n= df[col].isna().sum()).values\nfillna_sample(train_data)\nfillna_sample(test_data)","939820cc":"train_label = train_data['target']\ntrain_data.drop(columns=['id', 'target'], axis=1, inplace=True)\ntest_id = test_data['id']\ntest_data.drop(columns=['id'], axis=1, inplace=True)","71b093a8":"convert_ord = { \"ord_1\": {\"Novice\":0, \"Contributor\":1, \"Expert\":3, \"Master\":4, \"Grandmaster\":5},\n                \"ord_2\": {\"Freezing\": 0, \"Cold\": 1, \"Warm\":3, \"Hot\":4, \"Lava Hot\":5, \"Boiling Hot\":6} }\ntrain_data.replace(convert_ord, inplace=True)\ntest_data.replace(convert_ord, inplace=True)","ecf5f95a":"need_dummy_cols = [\"nom_0\", \"nom_1\", \"nom_2\", \"nom_3\", \"nom_4\", \"bin_3\", \"bin_4\"]\ntrain_data = pd.get_dummies(train_data, columns=need_dummy_cols, drop_first=True)\ntest_data = pd.get_dummies(test_data, columns=need_dummy_cols, drop_first=True)","04bb675b":"from sklearn.preprocessing import LabelEncoder\nlb_bin = LabelEncoder()\ncategorical_cols = train_data.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\n    train_data[col] = lb_bin.fit_transform(train_data[col])\n    test_data[col] = lb_bin.fit_transform(test_data[col])","aee04c1e":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ntrain_data = scaler.fit_transform(train_data)\ntest_data = scaler.fit_transform(test_data)","1dff2b91":"from sklearn.linear_model import LogisticRegression\nlrclf = LogisticRegression(C=5)\nlrclf.fit(train_data, train_label)\nlrclf_pred = lrclf.predict_proba(test_data)","fc97a995":"submission = pd.DataFrame({'id': test_id, 'target': lrclf_pred[:,1]})\nsubmission.to_csv('submission.csv', index=False)","73b97869":"### Import Data","6210ce91":"### Explore Data","7354a8de":"### LabelEncoder","bdc1891d":"### Scale Data","c61a75a5":"### Export","cb726da9":"### Convert Categoricals","1509ee50":"### Missing Values","fbbe961d":"### Convert Ordinals","5eee44a7":"### Split label Column & Drop usless","e83895d8":"### Fit Model & Predict"}}