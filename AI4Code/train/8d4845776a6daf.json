{"cell_type":{"92b38117":"code","5f4eba90":"code","6073afd4":"code","ddbe484a":"code","9c2ab9e9":"code","cea96be7":"code","4844125f":"code","7b40cb1c":"code","33cce398":"code","b10f1b67":"code","550d93f5":"code","64ee5bc7":"code","647c0e1e":"code","e5984286":"code","8f97d540":"code","ebe8b12a":"code","1796481a":"code","210bcd4a":"code","84dde7d4":"code","4179b826":"code","668c3901":"code","ff123993":"code","37fa28ff":"code","4618a6c0":"code","870de2d7":"markdown","583d7ee0":"markdown","80f7631d":"markdown","06892222":"markdown","50db3e4c":"markdown","a5d0bdcd":"markdown","0efe105b":"markdown","5f7229e7":"markdown","c8490583":"markdown","53eab324":"markdown","abbb8070":"markdown","dcb94339":"markdown","8e42ee79":"markdown","4d56543c":"markdown","0a696628":"markdown","08dcd703":"markdown","9a0ce0ac":"markdown","59f65bd1":"markdown","153a4ecd":"markdown","6569e651":"markdown","fac9a1fb":"markdown","750eb91c":"markdown","e5e56f11":"markdown","af0e2bb1":"markdown","c2a69213":"markdown"},"source":{"92b38117":"## Importando bibliotecas\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold","5f4eba90":"np.random.seed(5)","6073afd4":"# Importando o conjunto de dados\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\nboston = datasets.load_boston()","ddbe484a":"print(boston['feature_names']) # Aqui s\u00e3o os nomes dos atributos","9c2ab9e9":"print(boston['DESCR']) ##imprimimos a descri\u00e7\u00e3o do conjunto de dados","cea96be7":"X = boston['data']\ny = boston['target']\nprint(X.shape, y.shape) # X tem 506 linhas por 13 colunas e y 506 linhas por 1 coluna","4844125f":"kf = KFold(n_splits=3, shuffle=True, random_state=111)","7b40cb1c":"def avalia_classificador(clf, kf, X, y, f_metrica):\n    metrica_valid = []\n    metrica_train = []\n    y_preds = np.zeros(X.shape[0])\n    # a cada itera\u00e7\u00e3o em kf, temos k-1 conjuntos para treino e 1 para valida\u00e7\u00e3o\n    # train e valid recebem os indices de treino e valida\u00e7\u00e3o em cada rodada.\n    for train, valid in kf.split(X,y):\n        x_train = X[train] # escolhe apenas os indices de treino\n        y_train = y[train]\n        x_valid = X[valid] # escolhe apenas os indices de valida\u00e7\u00e3o\n        y_valid = y[valid]\n        clf.fit(x_train, y_train) # treina o classificador com dados de treino\n        y_pred_train = clf.predict(x_train) # faz predi\u00e7\u00f5es nos dados de treino\n        y_pred_valid = clf.predict(x_valid) # faz predi\u00e7\u00f5es nos dados de valida\u00e7\u00e3o\n        y_preds[valid] = y_pred_valid # guarda as previs\u00f5es do fold corrente\n        \n        # salvando m\u00e9tricas obtidas no dado de treino (k-1 folds) e valida\u00e7\u00e3o (1 fold)\n        metrica_valid.append(f_metrica(y_valid, y_pred_valid)) \n        metrica_train.append(f_metrica(y_train, y_pred_train)) \n    \n    # retorna as previs\u00f5es e a m\u00e9dia das m\u00e9tricas de treino e valida\u00e7\u00e3o\n    # obtidas nas itera\u00e7\u00f5es do Kfold\n    return y_preds, np.array(metrica_valid).mean(), np.array(metrica_train).mean()","33cce398":"from sklearn.metrics import mean_squared_error\ndef f_rmse(y_real, y_pred): \n    return mean_squared_error(y_real, y_pred)**0.5","b10f1b67":"# M\u00e9dia de Y\nmedia_valor_m2 = np.mean(y)\nprint(media_valor_m2)","550d93f5":"#Gera um vetor artificial com o valor da m\u00e9dia repetido pelo n\u00famero de linhas do nosso conjunto.\ny_media = np.array([media_valor_m2]*y.shape[0])\nprint(y_media[:5]) #imprime os 5 primeiros.\nprint(y_media.shape) # imprime o formato do array\nprint('\\n')\n\n#Calcula o desempenho\nprint(f_rmse(y, y_media))","64ee5bc7":"from sklearn.linear_model import LinearRegression\n\n#veja a documena\u00e7\u00e3o do classificador e veja o que \u00e9 poss\u00edvel alterar.\nlr = LinearRegression(fit_intercept=True, normalize=True) ","647c0e1e":"preds, rmse_val, rmse_train = avalia_classificador(lr, kf, X, y, f_rmse) # treina, valida e calcula desempenho\nprint('RMSE (valida\u00e7\u00e3o): ', rmse_val)\nprint('RMSE (treino): ', rmse_train)","e5984286":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler","8f97d540":"# Cria uma nova matriz de atributos com as features polinomiais de grau 2\nX_new = PolynomialFeatures(2).fit_transform(X) \n\n# Reescalona os dados entre 0 e 1 (valor padr\u00e3o do MinMaxScaler)\nX_new = MinMaxScaler().fit_transform(X_new)\n\nprint('N\u00famero de atributos ap\u00f3s transforma\u00e7\u00e3o:', X_new.shape[1])","ebe8b12a":"preds, rmse_val, rmse_train = avalia_classificador(lr, kf, X_new, y, f_rmse) \nprint('RMSE (valida\u00e7\u00e3o): ', rmse_val)\nprint('RMSE (treino): ', rmse_train)","1796481a":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.scatter(preds, y);\nplt.plot(preds,preds, c ='r')","210bcd4a":"from sklearn import svm\nsvr = svm.SVR(gamma='auto')","84dde7d4":"preds, rmse_val, rmse_train = avalia_classificador(svr, kf, X, y, f_rmse) \nprint('RMSE (valida\u00e7\u00e3o): ', rmse_val)\nprint('RMSE (treino): ', rmse_train)","4179b826":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=3)","668c3901":"preds, rmse_val, rmse_train = avalia_classificador(neigh, kf, X, y, f_rmse) \nprint('RMSE (valida\u00e7\u00e3o): ', rmse_val)\nprint('RMSE (treino): ', rmse_train)","ff123993":"from sklearn import tree\ndt = tree.DecisionTreeRegressor(max_features=5, max_depth=3, random_state=10)","37fa28ff":"preds, rmse_val, rmse_train = avalia_classificador(dt, kf, X, y, f_rmse) \nprint('RMSE (valida\u00e7\u00e3o): ', rmse_val)\nprint('RMSE (treino): ', rmse_train)","4618a6c0":"from sklearn import tree\nimport graphviz \ndot_data = tree.export_graphviz(dt, out_file=None, \n                                feature_names=boston['feature_names'],  \n                                filled=True, rounded=True,  \n                                special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","870de2d7":"### Regress\u00e3o linear","583d7ee0":"Aqui usamos a classe [DecisionTreeRegressor](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.tree.DecisionTreeRegressor.html) do scikit-learn. Veja que estamos usando os valores padr\u00e2o dos par\u00e2metros. \nComo exerc\u00edcio, experimente alterar par\u00e2metros e ver o que muda no desempenho do algoritmo.","80f7631d":"### Baseline","06892222":"Qual o melhor modelo que voc\u00ea conseguiu e qual o melhor RMSE?","50db3e4c":"Entretanto, o erro no treino est\u00e1 bem menor que o de valida\u00e7\u00e3o. Isso indica que podemos ter entrado em sobreajuste, afinal ap\u00f3s a transforma\u00e7\u00e3o passamos de 13 atributos para 105 atributos.\n\nEssa an\u00e1lise nos leva a crer que reduzindo a complexidade\/capacidade do modelo podemos conseguir erros de valida\u00e7\u00e3o ainda menores.\nPoder\u00edamos tentar remover alguns atributos polinomiais criados, ou considerar m\u00e9todos de regress\u00e3o linear com **regulariza\u00e7\u00e3o** como [Ridge Regression](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Ridge.html) e [LASSO](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Lasso.html).\n","a5d0bdcd":"Aqui geramos os folds para valida\u00e7\u00e3o cruzada","0efe105b":"Aqui usamos a classe o regressor [SVM](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.svm.SVR.html) do scikit-learn. Veja que estamos usando os valores padr\u00e2o dos par\u00e2metros. \nComo exerc\u00edcio, experimente alterar par\u00e2metros e ver o que muda no desempenho do algoritmo, especialmente o tipo de kernel.","5f7229e7":"Agora vamos testar outros modelos, de forma bem semelhante \u00e0 regress\u00e3o linear.","c8490583":"#### Carregando os dados\nAqui carregamos os dados X e y e verificamos o formato dos arrays numpy","53eab324":"### KNN","abbb8070":"A fun\u00e7\u00e3o abaixo serve para fixar a semente de gera\u00e7\u00e3o de n\u00fameros aleat\u00f3rios, dessa forma os resultados s\u00e3o repet\u00edveis. Essa \u00e9 uma boa pr\u00e1tica.","dcb94339":"Aqui usamos a classe [LinearRegression](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.linear_model.LinearRegression.html) do scikit-learn. Veja que estamos usando os valores padr\u00e2o dos par\u00e2metros. \nComo exerc\u00edcio, experimente alterar par\u00e2metros e ver o que muda no desempenho do algoritmo.","8e42ee79":"### \u00c1rvore de decis\u00e3o","4d56543c":"Nesse laborat\u00f3rio vamos exercitar o uso do scikit-learn para algoritmos de regress\u00e3o para os dados de um conjunto de dados presente na pr\u00f3pria biblioteca, chamada Boston House Prices. O scikit-learn possui diversos conjuntos de dados embutidos. Uma lista completa pode ser obtida [aqui](http:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.datasets)","0a696628":"Aqui usamos a classe [KNeighborsRegressor](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.neighbors.KNeighborsRegressor.html) do scikit-learn. Veja que estamos usando os valores padr\u00e2o dos par\u00e2metros. \nComo exerc\u00edcio, experimente alterar par\u00e2metros e ver o que muda no desempenho do algoritmo.","08dcd703":"Veja que j\u00e1 conseguimos uma nova redu\u00e7\u00e3o no erro de valida\u00e7\u00e3o.  \n\nVamos agora comparar os valores reais com os valores previstos. Quanto mais se parecer com o gr\u00e1fico y=x, melhor nosso modelo.","9a0ce0ac":"Aqui obtivemos um resultado que tem aproximadamente metade do erro relativo m\u00e9dio do baseline.  \n\nComo esperado, o erro no dado de treino \u00e9 menor que no dado de valida\u00e7\u00e3o, j\u00e1 que o modelo foi calibrado a partir de uma otimiza\u00e7\u00e3o usando os dados de treino.\n\nA diferen\u00e7a entre os erros de treino e valida\u00e7\u00e3o n\u00e3o parece grande, o que indicaria que n\u00e3o estamos no regime de sobreajuste (*overfitting*).\n\n\nVamos agora experimentar duas coisas:\n- modelos mais complexos (maior capacidade) adicionando features polinomiais.\n- uma transforma\u00e7\u00e3o que normaliza\u00e7\u00e3o\/mudan\u00e7a de escala dos atributos.","59f65bd1":"Novamente, tentar melhorar o classificador","153a4ecd":"### SVM","6569e651":"Essa fun\u00e7\u00e3o \u00e9 para ser reusada por qualquer classificador e m\u00e9trica de desempenho, desde que a fun\u00e7\u00e3o seja do padr\u00e3o do scikit-learn, onde \u00e9 passado o y_real e o y_previsto pelo classificador. O resultado retornado \u00e9 a m\u00e9dia das m\u00e9tricas para as K itera\u00e7\u00f5es do k-fold.","fac9a1fb":"Veja que nosso RMSE com SVM est\u00e1 bem pr\u00f3ximo do baseline, ou seja, bem ruim. Veja a documenta\u00e7\u00e3o da classe e fa\u00e7a tentativas de melhorar o classificador, tanto com seus pr\u00f3prios par\u00e2metros, quanto com engenharia de atributos (feature engineering).","750eb91c":"Para o problema que estamos lidando, que \u00e9 de regress\u00e3o, uma m\u00e9trica comum \u00e9 o [RMSE](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.mean_squared_error.html). Notar que temos de tirar a ra\u00edz quadrada, pois a fun\u00e7\u00e3o do scikit-learn n\u00e3o o faz. Portanto, em vez de usar a fun\u00e7\u00e3o diretamente, declaramos uma nova fun\u00e7\u00e3o.","e5e56f11":"Uma boa pr\u00e1tica quando se trabalha com Aprendizado de m\u00e1quina \u00e9 iniciarmos a medi\u00e7\u00e3o do desempenho de nosso algoritmo por um *baseline*. Ele server para ter ideia se nosso classificador est\u00e1 sendo \u00fatil e qual um bom ponto de partida para seu desempenho.\n\nNo caso de problemas de regress\u00e3o linear, normalmente utiliza-se a m\u00e9dia dos valores reais (m\u00e9dia de y) como se o algoritmo sempre o prevesse e medimos o desempenho.","af0e2bb1":"# Laborat\u00f3rio 4 - Modelos de regress\u00e3o com Scikit-learn","c2a69213":"Esse \u00e9 nosso ponto de partida de desempenho. Qualquer tentativa que resulte em um RMSE maior que esse indica que temos um p\u00e9ssimo classificador."}}