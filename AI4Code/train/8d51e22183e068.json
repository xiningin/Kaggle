{"cell_type":{"94a4ee70":"code","c0c5ce72":"code","fa071069":"code","2d318a4c":"code","fec1d249":"code","1c9aed08":"code","24291052":"code","5ab783b3":"code","2e8f60cd":"code","d079d972":"code","76bc3e2e":"code","be826ed5":"code","e1be33e6":"code","e74a3dbf":"code","df268be7":"code","b65f8efb":"code","f1f67059":"code","4c099353":"code","49834849":"code","a19ba051":"code","f46a86c2":"code","999b5551":"code","c1cf3a99":"code","29ad11ff":"code","94f447e8":"code","06b74bbd":"markdown","31f353ea":"markdown","6531d536":"markdown","e6bbbefa":"markdown","ed79ea21":"markdown","eafc0e9e":"markdown","8518d002":"markdown","c661f92a":"markdown","f0bfd9ec":"markdown","63d448b3":"markdown","75331ea2":"markdown","48bdc9fa":"markdown","8e262fe2":"markdown","8ca4cd5e":"markdown"},"source":{"94a4ee70":"import pandas as pd\nimport re \nimport nltk\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense,Embedding,Dropout,Input,LSTM,GlobalMaxPool1D\nfrom keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport plotly.express as px\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nimport warnings\nwarnings.filterwarnings('ignore')","c0c5ce72":"data2=pd.read_json('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset_v2.json',lines=True)\ndata2.head()","fa071069":"data1=pd.read_json('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset.json',lines=True)\ndata1.head()","2d318a4c":"data=pd.concat([data1,data2],axis=0,ignore_index=True)\ndata","fec1d249":"data.info()","1c9aed08":"train_data,val_data=train_test_split(data,test_size=0.15,random_state=42)","24291052":"def clean_text(text):\n    words_length=[]\n    cleaned_data=[]\n    for sent in tqdm(text):\n        sent=re.sub('https?:\/\/[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sent)\n        words=[word for word in sent.split() if word not in stopwords.words('english')]\n        words_length.append(len(words))\n        cleaned_data.append(' '.join(words))\n    return cleaned_data,words_length","5ab783b3":"train_data.headline,train_words_length=clean_text(train_data.headline)\nval_data.headline,val_words_length=clean_text(val_data.headline)","2e8f60cd":"plt.figure(figsize=(10,8))\nsns.distplot(train_words_length)\nplt.title('Number of words in sentence',fontdict={'size':20,'style':'italic'})\nplt.plot()","d079d972":"px.pie(train_data,names='is_sarcastic',labels=['not sarcastic','sarcastic'],title='Sarchastic')","76bc3e2e":"tokenizer=Tokenizer()\ntokenizer.fit_on_texts(train_data.headline)","be826ed5":"word_counts=pd.DataFrame(tokenizer.word_counts.items(),columns=['words','counts']).sort_values(by='counts',ascending=False)","e1be33e6":"word_counts.tail(10)","e74a3dbf":"top_50_words=word_counts.iloc[:50]\nplt.figure(figsize=(20,18))\nsns.barplot(data=top_50_words,x='counts',y='words')\nplt.title('Top 50 Most occuring words',fontdict={'size':20,'style':'italic'})\nplt.plot()","df268be7":"top_300_words=word_counts.words[:300]\nwc=WordCloud(max_words=400)\nwc.generate(' '.join(word for word in top_300_words))\nplt.figure(figsize=(20,15))\nplt.axis('off')\nplt.title('Top 300 Most occuring words',fontdict={'size':20,'style':'italic'})\nplt.imshow(wc)","b65f8efb":"train_headlines=tokenizer.texts_to_sequences(train_data.headline)\ntrain_headlines_padded=pad_sequences(train_headlines,maxlen=20)","f1f67059":"val_headlines=tokenizer.texts_to_sequences(val_data.headline)\nval_headlines_padded=pad_sequences(val_headlines,maxlen=20)","4c099353":"reduce_lr=ReduceLROnPlateau(patience=2)\nearly_stop=EarlyStopping(patience=3)","49834849":"V=len(tokenizer.word_index)\nmodel=Sequential()\nmodel.add(Input(shape=(20,)))\nmodel.add(Embedding(V+1,32))\nmodel.add(LSTM(20,return_sequences=True))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(optimizer=keras.optimizers.SGD(0.1),loss='binary_crossentropy',metrics=['accuracy'])","a19ba051":"r=model.fit(train_headlines_padded,train_data.is_sarcastic,validation_data=(val_headlines_padded,val_data.is_sarcastic)\n            ,epochs=20,callbacks=[reduce_lr,early_stop])","f46a86c2":"plt.figure(figsize=(10,8))\nplt.plot(r.history['loss'])\nplt.plot(r.history['val_loss'])\nplt.title('Model loss curve',fontdict={'size':20,'style':'italic'})\nplt.show()","999b5551":"plt.figure(figsize=(10,8))\nplt.plot(r.history['accuracy'])\nplt.plot(r.history['val_accuracy'])\nplt.title('Model accuracy curve',fontdict={'size':20,'style':'italic'})\nplt.show()","c1cf3a99":"print('classification report of prediction on test dataset \\n \\n',\n      classification_report(val_data.is_sarcastic,model.predict_classes(val_headlines_padded),\n        target_names=['not sarcastic','sarcastic']))","29ad11ff":"cm=confusion_matrix(val_data.is_sarcastic,model.predict_classes(val_headlines_padded))","94f447e8":"plt.figure(figsize=(10,8))\nsns.heatmap(cm,xticklabels=['not sarcastic','sarcastic'],yticklabels=['not sarcastic','sarcastic'],annot=True,cmap='Blues')\nplt.title('confusion matrix of validation data',fontdict={'size':20,'style':'italic'})\nplt.show()","06b74bbd":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Callbacks function<\/h1>","31f353ea":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Model Evaluation<\/h1>","6531d536":"<center><img src=\"https:\/\/thumbs.dreamstime.com\/b\/hand-drawn-typography-poster-with-creative-slogan-sarcasm-isn-t-124468466.jpg\",height='500',width='600'><\/center>","e6bbbefa":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Conclusion<\/h1>","ed79ea21":"<font style=\"color:red;font-family:algerian;font-size:150%;text-align:center;padding: 5px \"><center>Hope you liked the notebook!! If yes please upvote it. If having any query or suggestion, feel free to ask in comment section.<\/center><\/font>","eafc0e9e":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Exploratory Data Analysis<\/h1>","8518d002":"<h1 style=\"background-color:#3399ff;font-family:algerian;font-size:500%;text-align:center;border-radius: 15px 50px;padding: 5px \">Sarcastic Comments Detection<\/h1>","c661f92a":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Library used<\/h1>","f0bfd9ec":"### Here it is evident that our model works quite well with train accuracy of 99% and test accuracy of about 96%.Thus model could be used for sarcasm detection.","63d448b3":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Dataset split<\/h1>","75331ea2":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Overview<\/h1>","48bdc9fa":"<font style=\"color:black;font-family:algerian;font-size:120%;padding: 5px \">\nPast studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.\n\n<ul><li>This new dataset has following advantages over the existing Twitter datasets:<\/li>\n<ol>\n<li>Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.<\/li>\n\n<li>Furthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.<\/li>\n\n<li>Unlike tweets which are replies to other tweets, the news headlines we obtained are self-contained. This would help us in teasing apart the real sarcastic elements.<\/li>\n    <\/ol>\n\n   <br> \n<li>Each record consists of three attributes:<\/li>\n\n<ol>\n<li>is_sarcastic: 1 if the record is sarcastic otherwise 0<\/li>\n\n<li>headline: the headline of the news article<\/li>\n\n<li>article_link: link to the original news article. Useful in collecting supplementary data<\/li>\n    <\/ol>\n<\/ul>\n    <\/font>","8e262fe2":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Model Creation<\/h1>","8ca4cd5e":"<h1 style=\"background-color:#00cc00;font-family:algerian;font-size:300%;text-align:center;border-radius: 15px 50px;padding: 5px \">Data cleaning<\/h1>"}}