{"cell_type":{"eb7baec5":"code","bbf5d407":"code","a12ed51a":"code","96be67b7":"code","844bb76c":"code","e8f8db47":"code","f61fb232":"code","48c14c68":"code","b8a2a421":"code","4052d970":"code","0c233a0f":"code","136d18ae":"code","ec0d28eb":"code","9a829378":"code","a7cf9aa4":"code","6a5cc656":"code","d814a802":"code","86bb8ee4":"code","548030f8":"code","b4e3ea01":"code","363a9587":"code","4a304eb9":"code","620dc69b":"code","861dc621":"code","6206aa3a":"code","9db134af":"code","4cfab446":"code","f24d1395":"code","a917d264":"code","6cf07a3f":"code","2ceab22d":"code","26e21dfb":"code","a6a9490e":"code","43ed254c":"code","71fd4f17":"code","6d2f50c2":"code","130b8a6b":"code","b11d03c7":"code","29199b92":"code","2f13c95c":"code","8dda9b2c":"markdown","e5d23104":"markdown","c08962d3":"markdown","c7218dec":"markdown","2976bf17":"markdown"},"source":{"eb7baec5":"pip install segmentation_models","bbf5d407":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom skimage.color import rgb2gray\n\nfrom scipy import ndimage, misc\nfrom scipy.ndimage.filters import convolve\nimport random\nfrom tqdm import tqdm\n\nimport zlib, base64, io\nimport json\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import normalize, to_categorical\nimport keras\nfrom keras import layers\nfrom keras.metrics import MeanIoU \n\nimport segmentation_models as sm\n\nimport os","a12ed51a":"classes = {}\n\nwith open(\"..\/input\/football-advertising-banners-detection\/football\/meta.json\") as json_file:\n    file = json.load(json_file)\n\nclasses['no'] = 0\nfor n, d in enumerate(file[\"classes\"]):\n    name_class = d['title']\n    classes[name_class] = n+1\n\nprint(classes)","96be67b7":"def base64_2_mask(s):\n    z = zlib.decompress(base64.b64decode(s))\n    n = np.fromstring(z, np.uint8)\n    mask = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n    \n    return mask\n\ndef image2mask(image):\n    with open(f\"..\/input\/football-advertising-banners-detection\/football\/annotations\/{image}.json\") as json_file:\n        labels = json.load(json_file)\n    \n    mask = np.zeros((labels['size']['height'], labels['size']['width']))\n    \n    if labels['objects']:\n        for d in labels['objects']:\n            name_mask = d[\"classTitle\"]\n            mask_small = base64_2_mask(d['bitmap']['data']).astype(int)\n            \n            start_point = d['bitmap']['origin']\n            \n            mask[start_point[1]:start_point[1] + mask_small.shape[0], start_point[0]:start_point[0] + mask_small.shape[1]] = mask_small\n            mask = np.where(mask == 1, classes[name_mask], mask)\n    \n    return mask","844bb76c":"import os\ndf_image = pd.DataFrame(os.listdir(\"..\/input\/football-advertising-banners-detection\/football\/images\"), columns=[\"name_image\"])\n\ndf_image.head()","e8f8db47":"amount_adv = {'mastercard': 0, 'nissan': 0, 'playstation': 0, 'unicredit': 0, 'pepsi': 0, 'adidas': 0, 'gazprom': 0, 'heineken': 0, 'no': 0}\n\nfor image in df_image.values:\n    with open(f\"..\/input\/football-advertising-banners-detection\/football\/annotations\/{image[0]}.json\") as json_file:\n        labels = json.load(json_file)\n    \n    if labels['objects']:\n        for d in labels['objects']:\n            name_mask = d[\"classTitle\"]\n            amount_adv[name_mask] += 1\n    \n    else:\n        amount_adv['no'] += 1\n\ndf_table = pd.DataFrame({'adv': amount_adv.keys(),\n                        'amount': amount_adv.values()})\n\npx.bar(df_table, x='adv', y='amount', title=\"Banner ads\")","f61fb232":"adv = [adv for adv in amount_adv if amount_adv[adv] == 0]\n\nfor a in adv:\n    del classes[a]\n\nnew_classes = classes.copy()    \nclasses = {} \n\nfor i, a in enumerate(new_classes):\n    classes[a] = i\n\nprint(classes)","48c14c68":"values_area = []\n\nfor image in tqdm(df_image.values):\n    mask = image2mask(image[0])\n    \n    area = (mask[180:360, :] > 0).sum()\n    values_area.append(area)\n    \narray_area = np.array(values_area)","b8a2a421":"px.histogram(array_area, title=\"Distribution of the area of masks\")","4052d970":"def image_show(image, nrows=1, ncols=2):\n    img = cv2.imread(f'..\/input\/football-advertising-banners-detection\/football\/images\/{image}')\n    mask = image2mask(image)\n    \n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 14))\n    ax[0].imshow(img)\n    ax[1].imshow(mask)\n    \n    return fig, ax","0c233a0f":"_ = image_show(df_image.iloc[90, 0])","136d18ae":"def clahe(image):\n    img = cv2.imread(f'..\/input\/football-advertising-banners-detection\/football\/images\/{image}')\n\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    hsv_planes = cv2.split(hsv)\n    hsv_planes = list(hsv_planes)\n\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    hsv_planes[2] = clahe.apply(hsv_planes[2])\n\n    hsv = cv2.merge(hsv_planes)\n    equalized_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n    \n    return equalized_img","ec0d28eb":"image = cv2.imread(f'..\/input\/football-advertising-banners-detection\/football\/images\/{df_image.iloc[4, 0]}')\nequalized_img = clahe(df_image.iloc[4, 0])\n\nfig, axs = plt.subplots(1, 2, figsize=(20, 20))\n\naxs[0].imshow(image)\naxs[1].imshow(equalized_img)","9a829378":"class cannyEdgeDetector:\n    def __init__(self, imgs, sigma=1, kernel_size=5, weak_pixel=75, strong_pixel=255, lowthreshold=0.05, highthreshold=0.15):\n        self.imgs = imgs\n        self.imgs_final = []\n        self.img_smoothed = None\n        self.gradientMat = None\n        self.thetaMat = None\n        self.nonMaxImg = None\n        self.thresholdImg = None\n        self.weak_pixel = weak_pixel\n        self.strong_pixel = strong_pixel\n        self.sigma = sigma\n        self.kernel_size = kernel_size\n        self.lowThreshold = lowthreshold\n        self.highThreshold = highthreshold\n        return \n    \n    def gaussian_kernel(self, size, sigma=1):\n        size = int(size) \/\/ 2\n        x, y = np.mgrid[-size:size+1, -size:size+1]\n        normal = 1 \/ (2.0 * np.pi * sigma**2)\n        g =  np.exp(-((x**2 + y**2) \/ (2.0*sigma**2))) * normal\n        return g\n    \n    def sobel_filters(self, img):\n        Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n        Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n\n        Ix = ndimage.filters.convolve(img, Kx)\n        Iy = ndimage.filters.convolve(img, Ky)\n\n        G = np.hypot(Ix, Iy)\n        G = G \/ G.max() * 255\n        theta = np.arctan2(Iy, Ix)\n        return (G, theta)\n    \n\n    def non_max_suppression(self, img, D):\n        M, N = img.shape\n        Z = np.zeros((M,N), dtype=np.int32)\n        angle = D * 180. \/ np.pi\n        angle[angle < 0] += 180\n\n\n        for i in range(1,M-1):\n            for j in range(1,N-1):\n                try:\n                    q = 255\n                    r = 255\n\n                   #angle 0\n                    if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n                        q = img[i, j+1]\n                        r = img[i, j-1]\n                    #angle 45\n                    elif (22.5 <= angle[i,j] < 67.5):\n                        q = img[i+1, j-1]\n                        r = img[i-1, j+1]\n                    #angle 90\n                    elif (67.5 <= angle[i,j] < 112.5):\n                        q = img[i+1, j]\n                        r = img[i-1, j]\n                    #angle 135\n                    elif (112.5 <= angle[i,j] < 157.5):\n                        q = img[i-1, j-1]\n                        r = img[i+1, j+1]\n\n                    if (img[i,j] >= q) and (img[i,j] >= r):\n                        Z[i,j] = img[i,j]\n                    else:\n                        Z[i,j] = 0\n\n\n                except IndexError as e:\n                    pass\n\n        return Z\n\n    def threshold(self, img):\n\n        highThreshold = img.max() * self.highThreshold;\n        lowThreshold = highThreshold * self.lowThreshold;\n\n        M, N = img.shape\n        res = np.zeros((M,N), dtype=np.int32)\n\n        weak = np.int32(self.weak_pixel)\n        strong = np.int32(self.strong_pixel)\n\n        strong_i, strong_j = np.where(img >= highThreshold)\n        zeros_i, zeros_j = np.where(img < lowThreshold)\n\n        weak_i, weak_j = np.where((img <= highThreshold) & (img >= lowThreshold))\n\n        res[strong_i, strong_j] = strong\n        res[weak_i, weak_j] = weak\n\n        return (res)\n\n    def hysteresis(self, img):\n\n        M, N = img.shape\n        weak = self.weak_pixel\n        strong = self.strong_pixel\n\n        for i in range(1, M-1):\n            for j in range(1, N-1):\n                if (img[i,j] == weak):\n                    try:\n                        if ((img[i+1, j-1] == strong) or (img[i+1, j] == strong) or (img[i+1, j+1] == strong)\n                            or (img[i, j-1] == strong) or (img[i, j+1] == strong)\n                            or (img[i-1, j-1] == strong) or (img[i-1, j] == strong) or (img[i-1, j+1] == strong)):\n                            img[i, j] = strong\n                        else:\n                            img[i, j] = 0\n                    except IndexError as e:\n                        pass\n\n        return img\n    \n    def detect(self):\n        imgs_final = []\n        for i, img in enumerate(self.imgs):    \n            self.img_smoothed = convolve(img, self.gaussian_kernel(self.kernel_size, self.sigma))\n            self.gradientMat, self.thetaMat = self.sobel_filters(self.img_smoothed)\n            self.nonMaxImg = self.non_max_suppression(self.gradientMat, self.thetaMat)\n            self.thresholdImg = self.threshold(self.nonMaxImg)\n            img_final = self.hysteresis(self.thresholdImg)\n            self.imgs_final.append(img_final)\n\n        return self.imgs_final","a7cf9aa4":"image_g = rgb2gray(equalized_img)\n\ndetector = cannyEdgeDetector([image_g], sigma=1.4, kernel_size=7, lowthreshold=0.1, highthreshold=0.15, weak_pixel=100)\n\nimgs_final = detector.detect()\n\nfig, axs = plt.subplots(1, 2, figsize=(20, 20))\n\naxs[0].imshow(equalized_img)\naxs[1].imshow(imgs_final[0], cmap='gray')","6a5cc656":"img0 = np.where(imgs_final[0] > 0, 0, image[:, :, 0])\nimg1 = np.where(imgs_final[0] > 0, 0, image[:, :, 1])\nimg2 = np.where(imgs_final[0] > 0, 0, image[:, :, 2])\n\nnew_image = np.dstack((img0, img1, img2))\nnew_image.shape","d814a802":"fig, axs = plt.subplots(1, 2, figsize=(20, 20))\n\naxs[0].imshow(image)\naxs[1].imshow(new_image)","86bb8ee4":"def edge_enhance(image):\n    image_g = rgb2gray(image)\n\n    detector = cannyEdgeDetector([image_g], sigma=1.4, kernel_size=7, lowthreshold=0.1, highthreshold=0.15, weak_pixel=100)\n    imgs_final = detector.detect()  \n    \n    img0 = np.where(imgs_final[0] > 0, 0, image[:, :, 0])\n    img1 = np.where(imgs_final[0] > 0, 0, image[:, :, 1])\n    img2 = np.where(imgs_final[0] > 0, 0, image[:, :, 2])\n\n    new_image = np.dstack((img0, img1, img2))\n    \n    return new_image","548030f8":"def build_crop(image):\n    y = int(image.shape[0]\/2)\n    x = int(image.shape[1]\/2)      \n    \n    crop_img_0_0 = image[0:y, 0:x]\n    crop_img_0_1 = image[0:y, x:image.shape[1]]\n    crop_img_1_0 = image[y:image.shape[0], 0:x]\n    crop_img_1_1 = image[y:image.shape[0], x:image.shape[1]]\n\n    return [[crop_img_0_0], [crop_img_0_1], [crop_img_1_0]]    #, [crop_img_1_1]]","b4e3ea01":"NUM_CLASSES = 7\nNUM_ALL_IMAGES = 8851\nNUM_TRAIN_IMAGES = int(NUM_ALL_IMAGES * 0.9)\nBACKBONE1 = 'resnet34'\n\npreprocess_input = sm.get_preprocessing(BACKBONE1)\n\ndf_common = df_image.sample(frac=1, random_state=1).reset_index(drop=True)\n\ndf_train = df_common.iloc[:NUM_TRAIN_IMAGES, 0] \ndf_valid = df_common.iloc[NUM_TRAIN_IMAGES:, 0]","363a9587":"datagen_image = tf.keras.preprocessing.image.ImageDataGenerator(\n                    horizontal_flip=True,\n                    vertical_flip=True,\n                    brightness_range=[0.3, 1.5],\n                )\ndatagen_mask = tf.keras.preprocessing.image.ImageDataGenerator(\n                    horizontal_flip=True,\n                    vertical_flip=True,\n                )\n\n\ndef choose_data(array, lenght_list, i, choose_numbers=False, numbers=40):    \n    if not choose_numbers:\n        choose_numbers = []\n        \n        for _ in range(numbers):\n            while True:\n                rand_num = random.randint(0, lenght_list-1)\n\n                if rand_num not in choose_numbers:\n                    choose_numbers.append(rand_num)\n                    break\n    \n    random.Random(i).shuffle(array)\n    batch = array[[choose_numbers]]\n\n    return batch, choose_numbers\n    \ndef data_generator(image_data):\n    while True:\n        pre_x_batch = []\n        pre_y_batch = []\n            \n        while len(pre_x_batch) < 50:\n            example = image_data.sample(1).iloc[0]\n            mask = image2mask(example)\n            mask = cv2.resize(mask, (1280, 720), interpolation=cv2.INTER_NEAREST)\n                \n            img = cv2.imread(f'..\/input\/football-advertising-banners-detection\/football\/images\/{example}')\n            img = cv2.resize(img, (1280, 720), interpolation=cv2.INTER_NEAREST)\n            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n            hsv_planes = cv2.split(hsv)\n            hsv_planes = list(hsv_planes)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hsv_planes[2] = clahe.apply(hsv_planes[2])\n            hsv = cv2.merge(hsv_planes)\n            img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n            \n            l_masks = build_crop(mask)\n            l_imgs = build_crop(img) \n            \n            for l_mask, l_img in zip(l_masks, l_imgs):\n                l_mask_resized = cv2.resize(l_mask[0], (256, 256), interpolation=cv2.INTER_NEAREST)\n                pre_y_batch.append(l_mask_resized)\n\n                l_img_resized = cv2.resize(l_img[0], (256, 256), interpolation=cv2.INTER_NEAREST)\n                pre_x_batch.append(l_img_resized)\n        \n        i = random.randint(0, len(pre_x_batch))\n        \n#         lenght_pre = len(pre_x_batch)\n#         for j in range(lenght_pre):\n#             rd0 = np.random.random()\n#             if rd0 < 0.2:\n#                 data_for_aug = pre_x_batch[j]\n                \n#                 mask_for_aug = pre_y_batch[j]\n#                 mask_for_aug = np.expand_dims(mask_for_aug, axis=2)\n                \n#                 for _ in range(3):\n#                     rd1 = np.random.random()\n\n#                     data_for_aug_t = np.array([data_for_aug])\n#                     mask_for_aug_t = np.array([mask_for_aug])\n\n#                     datagen_image.fit(data_for_aug_t, augment=True, seed = i)\n#                     datagen_mask.fit(mask_for_aug_t, augment=True, seed = i)\n\n#                     create_image = datagen_image.flow(data_for_aug_t, seed = i)[0][0].astype('uint8')\n#                     pre_x_batch.append(create_image)\n\n#                     create_mask = datagen_mask.flow(mask_for_aug_t, seed = i)[0][0].astype('uint8')\n#                     create_mask = np.squeeze(create_mask, axis=2)\n#                     pre_y_batch.append(create_mask)\n        \n        x_batch, choose_numbers = choose_data(np.array(pre_x_batch), len(pre_x_batch), i)\n        x_batch = x_batch \/ 255\n        x_batch = preprocess_input(x_batch)\n        \n        y_batch, _ = choose_data(np.array(pre_y_batch), len(pre_y_batch), i, choose_numbers=choose_numbers)\n        \n        mask_list_input_cat = to_categorical(y_batch, num_classes=NUM_CLASSES)    \n        \n        yield x_batch, mask_list_input_cat\n\ntrain_dataset = next(data_generator(df_train))\nval_dataset = next(data_generator(df_valid))\n\nprint(\"Train Dataset:\", train_dataset[0].shape, train_dataset[1].shape)\nprint(\"Val Dataset:\", val_dataset[0].shape, val_dataset[1].shape)","4a304eb9":"list_classes = [cls for cls in classes]\n\nfig, axs = plt.subplots(1, 7, figsize=(20, 20))\n\naxs[0].imshow(train_dataset[0][0])\naxs[0].set_title('Image', fontsize=20)\n\naxs[1].imshow(train_dataset[1][0][:, :, 0])\naxs[1].set_title(f'{list_classes[0].title()}', fontsize=20)\n\naxs[2].imshow(train_dataset[1][0][:, :, 1])\naxs[2].set_title(f'{list_classes[1].title()}', fontsize=20)\n\naxs[3].imshow(train_dataset[1][0][:, :, 2])\naxs[3].set_title(f'{list_classes[2].title()}', fontsize=20)\n\naxs[4].imshow(train_dataset[1][0][:, :, 3])\naxs[4].set_title(f'{list_classes[3].title()}', fontsize=20)\n\naxs[5].imshow(train_dataset[1][0][:, :, 4])\naxs[5].set_title(f'{list_classes[4].title()}', fontsize=20)\n\naxs[6].imshow(train_dataset[1][0][:, :, 5])\naxs[6].set_title(f'{list_classes[5].title()}', fontsize=20)","620dc69b":"def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    \n    return (true_pos + smooth) \/ (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n\n\ndef focal_tversky_loss(y_true, y_pred, gamma=0.75):\n    tv = tversky(y_true, y_pred)\n    \n    return K.pow((1 - tv), gamma)","861dc621":"metrics = ['accuracy', tversky]","6206aa3a":"sm.set_framework('tf.keras')\n\nsm.framework()\n\ninput_shape = (256, 256, 3)\nmodel = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=NUM_CLASSES, activation='softmax')\n\nmodel.compile(tf.keras.optimizers.Adam(0.0001), focal_tversky_loss, metrics=metrics)\n\nprint(model.summary())","9db134af":"es = EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=1)\n\nfilepath = \"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\nmc = ModelCheckpoint(filepath, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_lr=0.0000001)","4cfab446":"history = model.fit_generator(data_generator(df_train),\n                   steps_per_epoch=80,\n                   epochs=40,\n                   verbose=1,\n                   validation_data=data_generator(df_valid),\n                   validation_steps=40,\n                   callbacks=[es, mc, reduce_lr])","f24d1395":"model.load_weights('..\/input\/model-info\/weights-improvement-02-0.02.hdf5')","a917d264":"def image_fragmentation(image):\n    img_frags = []\n    masks = []\n    test_masks = []\n    \n    img = cv2.imread(f'..\/input\/football-advertising-banners-detection\/football\/images\/{image}')\n    img = cv2.resize(img, (1280, 720), interpolation=cv2.INTER_NEAREST)\n    img_orig = img.copy()\n    \n    mask = image2mask(image)\n    mask = cv2.resize(mask, (1280, 720), interpolation=cv2.INTER_NEAREST)\n    \n    level0_im = build_crop(img)\n    level0_mk = build_crop(mask)\n    \n    for im, mk in zip(level0_im, level0_mk):\n        img = cv2.resize(im[0], (256, 256), interpolation=cv2.INTER_NEAREST) \n        img = img \/ 255\n        img_frags.append(img)\n        \n        test_mask = cv2.resize(mk[0], (256, 256), interpolation=cv2.INTER_NEAREST)\n        test_masks.append(test_mask)\n        \n    \n    return img_frags, img_orig, mask, test_masks\n\ndef check_prediction(model, image_list):\n    pred_mask_list = []\n    \n    for image in image_list:\n        y_pred = model.predict(np.array([image]))\n        \n        pred_mask_list.append(y_pred[0])\n    \n    return pred_mask_list\n\ndef show_result(image, mask, pred_mask):\n    pred_resized_list = []\n    \n    for pred in pred_mask:\n        pred = np.argmax(pred, axis=2)\n        pred = cv2.resize(pred, (640, 360), interpolation=cv2.INTER_NEAREST)\n        \n        pred_resized_list.append(pred)\n        \n    prediction = np.zeros((720, 1280))\n    \n    prediction[0:360, 0:640] = pred_resized_list[0]\n    prediction[0:360, 640:1280] = pred_resized_list[1]\n        \n    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(14, 14))\n    \n    ax[0].imshow(image)\n    ax[0].set_title('Image', fontsize=20)\n    \n    ax[1].imshow(mask)\n    ax[1].set_title('Original mask', fontsize=20)\n\n    ax[2].imshow(prediction)\n    ax[2].set_title('Prediction mask', fontsize=20)\n    \n    plt.show()","6cf07a3f":"test_list, image, orig_mask, _ = image_fragmentation(df_train.iloc[17])\npred_mask = check_prediction(model, test_list)\nshow_result(image, orig_mask, pred_mask)","2ceab22d":"test_list, image, orig_mask, _ = image_fragmentation(df_valid.iloc[70])\npred_mask = check_prediction(model, test_list)\nshow_result(image, orig_mask, pred_mask)","26e21dfb":"test_list, image, orig_mask, _ = image_fragmentation(df_valid.iloc[801])\npred_mask = check_prediction(model, test_list)\nshow_result(image, orig_mask, pred_mask)","a6a9490e":"with open('..\/input\/model-info\/history', 'rb') as file:\n    history = pickle.load(file)","43ed254c":"df_info = pd.DataFrame(history)\n\npx.line(df_info, title='Loss per epoch')","71fd4f17":"accuracy = {\n    'train': [0.6515, 0.9148, 0.9429, 0.9583, 0.9638, 0.9686, 0.9735, 0.9763, 0.9774, 0.9830, 0.9845, 0.9847, 0.9854, 0.9873, 0.9875, 0.9875, 0.9867, 0.9908, 0.9913, 0.9918, 0.9929, 0.9930, 0.9928, 0.9936, 0.9936, 0.9932, 0.9936, 0.9938, 0.9937, 0.9939, 0.9941, 0.9941, 0.9941, 0.9942, 0.9942, 0.9947, 0.9943, 0.9948, 0.9947],\n    'valid': [0.9438, 0.9454, 0.9510, 0.9482, 0.9467, 0.9452, 0.9485, 0.9441, 0.9446, 0.9554, 0.9728, 0.9815, 0.9842, 0.9857, 0.9870, 0.9863, 0.9893, 0.9910, 0.9920, 0.9931, 0.9936, 0.9932, 0.9943, 0.9943, 0.9943, 0.9935, 0.9938, 0.9944, 0.9939, 0.9950, 0.9947, 0.9947, 0.9946, 0.9947, 0.9947, 0.9950, 0.9948, 0.9943, 0.9948]\n}","6d2f50c2":"df_info = pd.DataFrame(accuracy)\n\npx.line(df_info, title='Accuracy per epoch')","130b8a6b":"def dice_coef(y_true, y_pred):\n    y_true_f = y_true.flatten()\n    y_pred_f = y_pred.flatten()\n    intersection = np.sum(y_true_f * y_pred_f)\n    \n    return (2. * intersection) \/ (np.sum(y_true_f) + np.sum(y_pred_f))\n\ndef dice_coef_multilabel(y_true, y_pred, numLabels):\n    dice=0\n    \n    for index in range(numLabels):\n        dice += dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n    \n    return dice\/numLabels","b11d03c7":"pred_masks = []\ny_pred = []\n\nfor i in tqdm(range(df_valid.shape[0])):\n    test_list, image, orig_mask, test_masks = image_fragmentation(df_valid.iloc[i])\n    pred_mask = check_prediction(model, test_list)\n    \n    pred_masks += pred_mask\n    y_pred += test_masks","29199b92":"y_pred_cat = to_categorical(np.array(y_pred), num_classes=NUM_CLASSES)\npred_masks = np.array(pred_masks)\n\ndice_score = np.mean(dice_coef_multilabel(y_pred_cat, pred_masks, NUM_CLASSES))\n\nprint(f'Dice score: {dice_score}.')\nprint('Dice score: 0.9462.')","2f13c95c":"print('Dice score: 0.9462.')","8dda9b2c":"### Edge enhance","e5d23104":"### Histogram","c08962d3":"### Model","c7218dec":"# Exploraty data analysis","2976bf17":"## Introduction"}}