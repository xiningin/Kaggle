{"cell_type":{"ade33a0c":"code","9f7053e4":"code","d3434c29":"code","4d735495":"code","896a86fb":"code","a25298d4":"code","dbbf5cdb":"code","46b1fd52":"code","c87da67d":"code","ed7bc227":"code","09dc2066":"code","23de6f42":"code","aa311b11":"code","eb9b8dc5":"code","abd8e9bb":"code","d2b5984f":"code","4c38f6ff":"code","a329c016":"code","015d9c87":"code","1819e4b4":"code","08dd1e78":"code","4be6a1a2":"code","93c20197":"code","effd8bce":"code","ccb3952b":"code","2e378bda":"code","7aafcce1":"code","d14732a1":"code","bfd31f46":"code","a272fbb0":"markdown","f6adc4ea":"markdown","dc39d94a":"markdown","10f2166c":"markdown","1bbce7de":"markdown","33b76dbd":"markdown","422860b4":"markdown","9324d484":"markdown","8ffdde20":"markdown","47ed9009":"markdown","126bd518":"markdown","5a13ace8":"markdown","83f07a85":"markdown","c4b49c87":"markdown","c56126a9":"markdown","574b27b1":"markdown","9cfcc2ef":"markdown","86fb7c77":"markdown","83c967ae":"markdown","74a7a476":"markdown","2773510a":"markdown","d78ae385":"markdown","f5cb4736":"markdown","7dde703e":"markdown","0104809c":"markdown","f1a9093f":"markdown","b4dcbbf7":"markdown","a252dfbd":"markdown","5972170f":"markdown","a6addd50":"markdown","8cac2944":"markdown","e8a1c469":"markdown"},"source":{"ade33a0c":"# Loading necessary libraries\nimport pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nfrom datetime import datetime","9f7053e4":"# Loading the data\ndata = pd.read_csv('..\/input\/train.csv')","d3434c29":"# data structure\ndata.head()","4d735495":"data.dtypes","896a86fb":"# see data summary\ndata.describe()","a25298d4":"# check for any missing values\ndata.isna().sum()","dbbf5cdb":"data.datetime = pd.to_datetime(data.datetime)\ndata['year'] = data.datetime.map(lambda x: x.strftime('%Y-%m-%d-%H-%M').split('-')[0])\ndata['month'] = data.datetime.map(lambda x: x.strftime('%Y-%m-%d-%H-%M').split('-')[1])\ndata['hour'] = data.datetime.map(lambda x: x.strftime('%Y-%m-%d-%H-%M').split('-')[3])\ndata['weekday'] = data.datetime.map(lambda x: x.weekday())","46b1fd52":"hour = data.drop(['datetime'],axis=1)\nhour.rename(columns = {'count':'cnt'},inplace=True)","c87da67d":"plt.figure(figsize=(15,15))\nplt.subplots_adjust(hspace=0.5,wspace=0.2)\n\n# season distribution\nplt.subplot(4,3,1)\nplt.bar(hour.season.unique(),hour.groupby('season').season.value_counts())\nplt.xlabel('Season')\n\n# holiday distribution\nplt.subplot(4,3,2)\nplt.bar(hour.holiday.unique(),hour.groupby('holiday').holiday.value_counts())\nplt.xlabel('Holiday')\n\n# weekday distribution\nplt.subplot(4,3,3)\nplt.bar(hour.weekday.unique(),hour.groupby('weekday').weekday.value_counts())\nplt.xlabel('Weekday')\n\n# workingday distribution\nplt.subplot(4,3,4)\nplt.bar(hour.workingday.unique(),hour.groupby('workingday').workingday.value_counts())\nplt.xlabel('Workingday')\n\n# weather distribution\nplt.subplot(4,3,5)\nplt.bar(hour.weather.unique(),hour.groupby('weather').weather.value_counts())\nplt.xlabel('Weather')\n\n# temp distribution\nplt.subplot(4,3,6)\nplt.hist(hour.temp)\nplt.xlabel('Temp')\n\n# temp distribution\nplt.subplot(4,3,7)\nplt.hist(hour.atemp)\nplt.xlabel('aTemp')\n\n# humidity distribution\nplt.subplot(4,3,8)\nplt.hist(hour.humidity)\nplt.xlabel('Humidity')\n\n# windspeed distribution\nplt.subplot(4,3,9)\nplt.hist(hour.windspeed)\nplt.xlabel('Windspeed')\n\n# year distribution\nplt.subplot(4,3,10)\nplt.bar(hour.year.unique(),hour.groupby('year').year.value_counts())\nplt.xlabel('Year')\n\n# month distribution\nplt.subplot(4,3,11)\nplt.bar(hour.month.unique(),hour.groupby('month').month.value_counts())\nplt.xlabel('Month')\n\n# hour distribution\nplt.subplot(4,3,12)\nplt.bar(hour.hour.unique(),hour.groupby('hour').hour.value_counts())\nplt.xlabel('Hour')","ed7bc227":"# distribution of cnt with hr\nplt.figure(figsize=(15,5))\n\n# distribution of cnt with hr on working day\nplt.subplot(1,2,1)\nplt.bar(hour[hour.workingday == 1].hour.unique(),hour[hour.workingday == 1].groupby('hour').cnt.sum())\nplt.xlabel('Hour')\nplt.ylabel('Count')\nplt.title('Working day')\n\n# distribution of cnt with hr on non-working day\nplt.subplot(1,2,2)\nplt.bar(hour[hour.workingday == 0].hour.unique(),hour[hour.workingday == 0].groupby('hour').cnt.sum())\nplt.xlabel('Hour')\nplt.ylabel('Count')\nplt.title('Non Working day')","09dc2066":"plt.figure(figsize=(15,10))\nplt.subplots_adjust(hspace=0.3,wspace=0.3)\n\n# distrbution of cnt by weekday\nplt.subplot(2,3,1)\nplt.bar(hour.weekday.unique(),hour.groupby('weekday').cnt.sum())\nplt.xlabel('Weekday')\nplt.ylabel('Count')\n\n# distrbution of cnt by workingday\nplt.subplot(2,3,2)\nplt.bar(hour.workingday.unique(),hour.groupby('workingday').cnt.sum())\nplt.xlabel('Workingday')\nplt.ylabel('Count')\n\n# distrbution of cnt by Month\nplt.subplot(2,3,3)\nplt.bar(hour.month.unique(),hour.groupby('month').cnt.sum())\nplt.xlabel('Month')\nplt.ylabel('Count')\n\n# distrbution of cnt by year\nplt.subplot(2,3,4)\nplt.bar(hour.year.unique(),hour.groupby('year').cnt.sum())\nplt.xlabel('Year')\nplt.ylabel('Count')\n\n# distrbution of cnt by season\nplt.subplot(2,3,5)\nplt.bar(hour.season.unique(),hour.groupby('season').cnt.sum())\nplt.xlabel('Season')\nplt.ylabel('Count')\n\n# distrbution of cnt by weather\nplt.subplot(2,3,6)\nplt.bar(hour.weather.unique(),hour.groupby('weather').cnt.sum())\nplt.xlabel('Weather')\nplt.ylabel('Count')","23de6f42":"# distribution of casual and registered users separately with weekday\nplt.figure(figsize=(15,15))\nplt.subplots_adjust(hspace=0.3,wspace=0.2)\n\n# distribution of registered users with weekday\nplt.subplot(5,2,1)\nplt.bar(hour.weekday.unique(),hour.groupby('weekday').registered.sum())\nplt.xlabel('Weekday')\nplt.ylabel('Count')\nplt.title('Registered')\n\n# distribution of casual users with weekday\nplt.subplot(5,2,2)\nplt.bar(hour.weekday.unique(),hour.groupby('weekday').casual.sum())\nplt.xlabel('Weekday')\nplt.ylabel('Count')\nplt.title('Casual')\n\n# distribution of registered users with working day\nplt.subplot(5,2,3)\nplt.bar(hour.workingday.unique(),hour.groupby('workingday').registered.sum())\nplt.xlabel('Workingday')\nplt.ylabel('Count')\n\n# distribution of casual users with working day\nplt.subplot(5,2,4)\nplt.bar(hour.workingday.unique(),hour.groupby('workingday').casual.sum())\nplt.xlabel('Workingday')\nplt.ylabel('Count')\n\n# distribution of registered users with month\nplt.subplot(5,2,5)\nplt.bar(hour.month.unique(),hour.groupby('month').registered.sum())\nplt.xlabel('Month')\nplt.ylabel('Count')\n\n# distribution of casual users with month\nplt.subplot(5,2,6)\nplt.bar(hour.month.unique(),hour.groupby('month').casual.sum())\nplt.xlabel('Month')\nplt.ylabel('Count')\n\n# distribution of registered users with hour\nplt.subplot(5,2,7)\nplt.bar(hour.hour.unique(),hour.groupby('hour').registered.sum())\nplt.xlabel('Hour')\nplt.ylabel('Count')\n\n# distribution of casual users with hour\nplt.subplot(5,2,8)\nplt.bar(hour.hour.unique(),hour.groupby('hour').casual.sum())\nplt.xlabel('Hour')\nplt.ylabel('Count')\n\n# distribution of registered users with season\nplt.subplot(5,2,9)\nplt.bar(hour.season.unique(),hour.groupby('season').registered.sum())\nplt.xlabel('Season')\nplt.ylabel('Count')\n\n# distribution of casual users with season\nplt.subplot(5,2,10)\nplt.bar(hour.season.unique(),hour.groupby('season').casual.sum())\nplt.xlabel('Season')\nplt.ylabel('Count')","aa311b11":"plt.figure(figsize=(15,10))\n\n# distribution of cnt with temp\nplt.subplot(2,2,1)\nplt.scatter(hour.temp,hour.cnt)\nplt.xlabel('Temp')\nplt.ylabel('Count')\n\n# distribution of cnt with atemp\nplt.subplot(2,2,2)\nplt.scatter(hour.atemp,hour.cnt)\nplt.xlabel('aTemp')\nplt.ylabel('Count')\n\n# distribution of cnt with humidity\nplt.subplot(2,2,3)\nplt.scatter(hour.humidity,hour.cnt)\nplt.xlabel('Humidity')\nplt.ylabel('Count')\n\n# distribution of cnt with windspeed\nplt.subplot(2,2,4)\nplt.scatter(hour.windspeed,hour.cnt)\nplt.xlabel('Windspeed')\nplt.ylabel('Count')","eb9b8dc5":"plt.figure(figsize=(15,7))\ncor = hour.corr()\nsns.heatmap(data=cor,annot=True)","abd8e9bb":"hour['season'] = hour['season'].astype('category')\nhour['holiday'] = hour['holiday'].astype('category')\nhour['workingday'] = hour['workingday'].astype('category')\nhour['weather'] = hour['weather'].astype('category')\n\nhour['year'] = hour['year'].astype('int')\nhour['month'] = hour['month'].astype('int')\nhour['hour'] = hour['hour'].astype('int')\nhour['weekday'] = hour['weekday'].astype('int')","d2b5984f":"hour.dtypes","4c38f6ff":"def neg_rmlse(pred,actual):\n    return -np.sqrt((np.sum((np.log(pred+1) - np.log(actual+1))**2))\/len(pred))\n\n# reason why rmlse has been defined with negative value will be explained in hyperparameter optimisation section below","a329c016":"# import the necessary library\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","015d9c87":"# using only data left after removing 30 days data for our data modelling\nx = hour.copy()\ny = x.cnt\n\n# dropping unnecessary independent variables and cnt from feature set x. Since atemp and temp are highly correlated,\n# we are just gonna keep atemp in our model.\nx.drop(['casual','registered','cnt','temp'],axis = 1,inplace=True)\nx.dtypes","1819e4b4":"x_1 = x.copy()\n\n# reinforce data types of year,month,hour,weekday\nx_1['year'] = x_1['year'].astype('int')\nx_1['month'] = x_1['month'].astype('int')\nx_1['hour'] = x_1['hour'].astype('int')\nx_1['weekday'] = x_1['weekday'].astype('int')\n\n# splitting data intro train and test sets\nx_train_1,x_test_1,y_train_1,y_test_1 = train_test_split(x_1,y,test_size=0.2,random_state=0)\n\n# Training RF regressor model\nmodel_1 = RandomForestRegressor(random_state = 0)\nmodel_1.fit(x_train_1,y_train_1)\n\n# predicting on train and test sets\npred_train_1 = model_1.predict(x_train_1)\npred_test_1 = model_1.predict(x_test_1)\n\n# calculating errors on train and test sets\nprint ('Training error : ',-neg_rmlse(pred_train_1,y_train_1))\nprint ('Test error : ',-neg_rmlse(pred_test_1,y_test_1))\n\n# feature importances\nimp_1 = model_1.feature_importances_\nindices_1 = np.argsort(imp_1)[::-1]\nprint ('\\nFeature importances : ')\nfor f in range(x_1.shape[1]):\n    print (\"%d. %s (%f)\" % (f + 1, x_1.columns[indices_1[f]], imp_1[indices_1[f]]))","08dd1e78":"x_2 = x.copy()\n\n# redefine data types of year,month,hour,weekday\nx_2['year'] = x_2['year'].astype('category')\nx_2['month'] = x_2['month'].astype('category')\nx_2['hour'] = x_2['hour'].astype('category')\nx_2['weekday'] = x_2['weekday'].astype('category')\n\n# splitting data intro train and test sets\nx_train_2,x_test_2,y_train_2,y_test_2 = train_test_split(x_2,y,test_size=0.2,random_state=0)\n\n# Training RF regressor model\nmodel_2 = RandomForestRegressor(random_state = 0)\nmodel_2.fit(x_train_2,y_train_2)\n\n# predicting on train and test sets\npred_train_2 = model_2.predict(x_train_2)\npred_test_2 = model_2.predict(x_test_2)\n\n# calculating errors on train and test sets\nprint ('Training error : ',-neg_rmlse(pred_train_2,y_train_2))\nprint ('Test error : ',-neg_rmlse(pred_test_2,y_test_2))\n\n# feature importances\nimp_2 = model_2.feature_importances_\nindices_2 = np.argsort(imp_2)[::-1]\nprint ('\\nFeature importances : ')\nfor f in range(x_2.shape[1]):\n    print(\"%d. %s (%f)\" % (f + 1, x_2.columns[indices_2[f]], imp_2[indices_2[f]]))","4be6a1a2":"x_3 = x.copy()\n\n# convert hour,month,weekday into cyclic variables by projecting them onto cos sin space and year into catergorical variable\nx_3['hr_sin'] = np.sin(2.*np.pi*x_3.hour\/24.)\nx_3['hr_cos'] = np.cos(2.*np.pi*x_3.hour\/24.)\nx_3.drop(['hour'],axis=1,inplace=True)\n\nx_3['mnth_sin'] = np.sin(2.*np.pi*x_3.month\/24.)\nx_3['mnth_cos'] = np.cos(2.*np.pi*x_3.month\/24.)\nx_3.drop(['month'],axis=1,inplace=True)\n\nx_3['wd_sin'] = np.sin(2.*np.pi*x_3.weekday\/24.)\nx_3['wd_cos'] = np.cos(2.*np.pi*x_3.weekday\/24.)\nx_3.drop(['weekday'],axis=1,inplace=True)\n\nx_3['year'] = x_3['year'].astype('category')\n\n# splitting data intro train and test sets\nx_train_3,x_test_3,y_train_3,y_test_3 = train_test_split(x_3,y,test_size=0.2,random_state=0)\n\n# Training RF regressor model\nmodel_3 = RandomForestRegressor(random_state = 0)\nmodel_3.fit(x_train_3,y_train_3)\n\n# predicting on train and test sets\npred_train_3 = model_3.predict(x_train_3)\npred_test_3 = model_3.predict(x_test_3)\n\n# calculating errors on train and test sets\nprint ('Training error : ',-neg_rmlse(pred_train_3,y_train_3))\nprint ('Test error : ',-neg_rmlse(pred_test_3,y_test_3))\n\n# feature importances\nimp_3 = model_3.feature_importances_\nindices_3 = np.argsort(imp_3)[::-1]\nprint ('\\nFeature importances : ')\nfor f in range(x_3.shape[1]):\n    print(\"%d. %s (%f)\" % (f + 1, x_3.columns[indices_3[f]], imp_3[indices_3[f]]))","93c20197":"x_4 = x.copy()\n\n# convert hr and mnth into cyclic variables by projecting them onto cos sin space\nx_4['hr_sin'] = np.sin(2.*np.pi*x_4.hour\/24.)\nx_4['hr_cos'] = np.cos(2.*np.pi*x_4.hour\/24.)\nx_4.drop(['hour'],axis=1,inplace=True)\n\nx_4['mnth_sin'] = np.sin(2.*np.pi*x_4.month\/24.)\nx_4['mnth_cos'] = np.cos(2.*np.pi*x_4.month\/24.)\nx_4.drop(['month'],axis=1,inplace=True)\n\nx_4['wd_sin'] = np.sin(2.*np.pi*x_4.weekday\/24.)\nx_4['wd_cos'] = np.cos(2.*np.pi*x_4.weekday\/24.)\nx_4.drop(['weekday'],axis=1,inplace=True)\n\nx_4['year'] = x_4['year'].astype('category')\n\nx_4.drop(['windspeed'],axis=1,inplace=True)\n\n# splitting data intro train and test sets\nx_train_4,x_test_4,y_train_4,y_test_4 = train_test_split(x_4,y,test_size=0.2,random_state=0)\n\n# Training RF regressor model\nmodel_4 = RandomForestRegressor(random_state = 0)\nmodel_4.fit(x_train_4,y_train_4)\n\n# predicting on train and test sets\npred_train_4 = model_4.predict(x_train_4)\npred_test_4 = model_4.predict(x_test_4)\n\n# calculating errors on train and test sets\nprint ('Training error : ',-neg_rmlse(pred_train_4,y_train_4))\nprint ('Test error : ',-neg_rmlse(pred_test_4,y_test_4))\n\n# feature importances\nimp_4 = model_4.feature_importances_\nindices_4 = np.argsort(imp_4)[::-1]\nprint ('\\nFeature importances : ')\nfor f in range(x_4.shape[1]):\n    print(\"%d. %s (%f)\" % (f + 1, x_4.columns[indices_4[f]], imp_4[indices_4[f]]))","effd8bce":"x_5 = x.copy()\n\n# convert hr and mnth into cyclic variables by projecting them onto cos sin space\nx_5['hr_sin'] = np.sin(2.*np.pi*x_5.hour\/24.)\nx_5['hr_cos'] = np.cos(2.*np.pi*x_5.hour\/24.)\nx_5.drop(['hour'],axis=1,inplace=True)\n\nx_5['mnth_sin'] = np.sin(2.*np.pi*x_5.month\/24.)\nx_5['mnth_cos'] = np.cos(2.*np.pi*x_5.month\/24.)\nx_5.drop(['month'],axis=1,inplace=True)\n\nx_5['wd_sin'] = np.sin(2.*np.pi*x_5.weekday\/24.)\nx_5['wd_cos'] = np.cos(2.*np.pi*x_5.weekday\/24.)\nx_5.drop(['weekday'],axis=1,inplace=True)\n\nx_5['year'] = x_5['year'].astype('category')\n\nx_5.drop(['windspeed'],axis=1,inplace=True)\n\n# target variables for casual and registered cnt\ny_cas = hour.casual\ny_reg = hour.registered\n\n# splitting data intro train and test sets\nx_train_5_cas,x_test_5_cas,y_train_5_cas,y_test_5_cas = train_test_split(x_5,y_cas,test_size=0.2,random_state=0)\nx_train_5_reg,x_test_5_reg,y_train_5_reg,y_test_5_reg = train_test_split(x_5,y_reg,test_size=0.2,random_state=0)\n\n# Training RF regressor model for casual cnt\nmodel_5_cas = RandomForestRegressor(random_state = 0)\nmodel_5_cas.fit(x_train_5_cas,y_train_5_cas)\n\n# Training RF regressor model for casual cnt\nmodel_5_reg = RandomForestRegressor(random_state = 0)\nmodel_5_reg.fit(x_train_5_reg,y_train_5_reg)\n\n# predicting total cnt by adding casual and registered cnt on train and test sets\npred_train_5 = model_5_cas.predict(x_train_5_cas) + model_5_reg.predict(x_train_5_reg)\npred_test_5 = model_5_cas.predict(x_test_5_cas) + model_5_reg.predict(x_test_5_reg)\n\n\n# calculating errors on train and test sets\nprint ('Training error : ',-neg_rmlse(pred_train_5,y_train_5_cas+y_train_5_reg))\nprint ('Test error : ',-neg_rmlse(pred_test_5,y_test_5_cas+y_test_5_reg))","ccb3952b":"# import necessary libraries\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer","2e378bda":"# define the scoring function that will be used to get optimised hyperparameters\n\ncv_scorer = make_scorer(neg_rmlse)             # neg_rmlse has been defined above\n\n# The reason why neg remlse has been defined with negative return value is that the grid search cv always try to \n# maximise the scoring function.","7aafcce1":"# choose hyperparameter value space\nestimators = [int(x) for x in np.linspace(50,500,num = 10)]\ndepths = [int(x) for x in np.linspace(10, 100, num = 10)]\ndepths.append(None)\nfeatures = ['auto','sqrt','log2']\n\n# define parameter grid\nparam_grid2 = {\"n_estimators\": estimators,\n               \"max_depth\" : depths,\n               \"max_features\" : features}\n\n# parameter tuning for model predicting casual cnt\nmodel_cas_tune = RandomForestRegressor(random_state=0)\ngrid_search_cas = GridSearchCV(model_cas_tune,param_grid=param_grid2,scoring = cv_scorer,cv=3)\ngrid_search_cas.fit(x_train_5_cas, y_train_5_cas)\n\n# parameter tuning for model predicting registered cnt\nmodel_reg_tune = RandomForestRegressor(random_state=0)\ngrid_search_reg = GridSearchCV(model_reg_tune,param_grid=param_grid2,scoring = cv_scorer,cv=3)\ngrid_search_reg.fit(x_train_5_reg, y_train_5_reg)","d14732a1":"print ('Best params for model predicting casual cnt : ',grid_search_cas.best_params_)\nprint ('Best score for model predicting casual cnt : ',-grid_search_cas.best_score_)\nprint ('\\nBest params for model predicting registered cnt : ',grid_search_reg.best_params_)\nprint ('Best score for model predicting registered cnt : ',-grid_search_reg.best_score_)","bfd31f46":"x_5 = x.copy()\n\n# convert hr and mnth into cyclic variables by projecting them onto cos sin space\nx_5['hr_sin'] = np.sin(2.*np.pi*x_5.hour\/24.)\nx_5['hr_cos'] = np.cos(2.*np.pi*x_5.hour\/24.)\nx_5.drop(['hour'],axis=1,inplace=True)\n\nx_5['mnth_sin'] = np.sin(2.*np.pi*x_5.month\/24.)\nx_5['mnth_cos'] = np.cos(2.*np.pi*x_5.month\/24.)\nx_5.drop(['month'],axis=1,inplace=True)\n\nx_5['wd_sin'] = np.sin(2.*np.pi*x_5.weekday\/24.)\nx_5['wd_cos'] = np.cos(2.*np.pi*x_5.weekday\/24.)\nx_5.drop(['weekday'],axis=1,inplace=True)\n\nx_5['year'] = x_5['year'].astype('category')\n\nx_5.drop(['windspeed'],axis=1,inplace=True)\n\n# target variables for casual and registered cnt\ny_cas = hour.casual\ny_reg = hour.registered\n\n# splitting data intro train and test sets\nx_train_5_cas,x_test_5_cas,y_train_5_cas,y_test_5_cas = train_test_split(x_5,y_cas,test_size=0.2,random_state=0)\nx_train_5_reg,x_test_5_reg,y_train_5_reg,y_test_5_reg = train_test_split(x_5,y_reg,test_size=0.2,random_state=0)\n\n# Training RF regressor model for casual cnt\nmodel_cas_best = RandomForestRegressor(n_estimators = grid_search_cas.best_params_['n_estimators'],\n                                       max_depth = grid_search_cas.best_params_['max_depth'],\n                                       max_features = grid_search_cas.best_params_['max_features'],random_state = 0)\nmodel_cas_best.fit(x_train_5_cas,y_train_5_cas)\n\n# Training RF regressor model for casual cnt\nmodel_reg_best = RandomForestRegressor(n_estimators = grid_search_reg.best_params_['n_estimators'],\n                                       max_depth = grid_search_reg.best_params_['max_depth'],\n                                       max_features = grid_search_reg.best_params_['max_features'],random_state = 0)\nmodel_reg_best.fit(x_train_5_reg,y_train_5_reg)\n\n# predicting total cnt by adding casual and registered cnt on train and test sets\npred_train_5_best = model_cas_best.predict(x_train_5_cas) + model_reg_best.predict(x_train_5_reg)\npred_test_5_best = model_cas_best.predict(x_test_5_cas) + model_reg_best.predict(x_test_5_reg)\n\n\n# calculating errors on train and test sets\nprint ('Training error with best parameters : ',-neg_rmlse(pred_train_5_best,y_train_5_cas+y_train_5_reg))\nprint ('Test error with best parameters : ',-neg_rmlse(pred_test_5_best,y_test_5_cas+y_test_5_reg))","a272fbb0":"### **The final submission will have RMSLE = 0.43**","f6adc4ea":"### **Building the Random Forest model**","dc39d94a":"#### **COMMENT** : Since season,holiday,weekday,workingday,weather are discrete class variables, let's convert them into categorical variables and newly created date time variables as integers","10f2166c":"### **Loading data and necessary libraries**","1bbce7de":"#### **COMMENT** : As expected, count of casual users renting bike increases on weekends while that of registered users decrease in weekends. This supports the fact that most of our registered users use bike rentals for office commute during weekdays. Also, registered users count decreases drastically on non working day too. Casual rides vary quite differently as compared to regsitered rides. So we are gonna predict casual rides and registered rides separately","33b76dbd":"#### **COMMENT** : No missing values!! Makes life a little simpler","422860b4":"#### **Model 3**: Treat hour,weekday,month as cyclic variable by projecting it into the cos-sin space and year as categorical variable","9324d484":"### **Defining the test metric**","8ffdde20":"#### **COMMENT** : Slight increase in train error but testing error reduces. Thus, lesser overfitting. Best model till now.","47ed9009":"#### **Calculating RMLSE with best model parameters**","126bd518":"#### **COMMENT** : Slight descrease in training and testing error in model 3 over model 2. Thus model 3 remains the best one.","5a13ace8":"#### **COMMENT** : No improvement in model 2 over model 1","83f07a85":"### **Variation of count with continuous variables**","c4b49c87":"## **Part 4 - Fine-tuning of one of the models**\n\n**Tasks:**\n1. Take one of the above constructed models and finetune its most important hyperparameters\n2. Explain your choice for the hyperparameters\n3. Report the improvement of your test metric","c56126a9":"#### **COMMENT** : Main motivation behind trying to predict casual and registered rentals separately was that the distribution of both with weekday was very different. And thus predicting both separately pays great dividends by decreasing both test and training errors quite significantly. Thus we will choose this model and tune it's hyperparameters to get the least RMSLE.","574b27b1":"#### **COMMENT** : Quite clearly there is a difference in peak times on a working and non working day and rentals vary vastly by hour.","9cfcc2ef":"#### **Model 2** : Treating month,hour,year,weekday as categories","86fb7c77":"### **Data Processing and Analysis**","83c967ae":"#### **Creating some extra features that can be helpful in analysis**","74a7a476":"### **Correlation between variables**","2773510a":"### **Variation of count with categorical variables**","d78ae385":"### **Distribution of variables in dataset**","f5cb4736":"#### **Model 4** : Since windspeed is of very low imprtance, try removing windspeed from model 3","7dde703e":"## **Part 3 - Building prediction models**","0104809c":"#### **Model 5** : Predicting casual and registered rentals separately","f1a9093f":"#### **COMMENT** : All the visualisations tell that rentals number vary quite vastly with hour of day, season, weather, workingday, month & year.","b4dcbbf7":"#### **COMMENT** :  We will use GridSearchCV to tune 3 most imprtant hyperparameters of a RF model,i.e. n_estimators,max_depth and max_features. We will have to define our scoring function for which make_scorer library is being used. ","a252dfbd":"#### **COMMENT** : The one very straightforward method to calculate accuracy is to meausre RMS error as is the norm with most of the continuous value prediction algos. But here our case is a little specific. Under any scenario, we won't like to loose customers because of shortage of supply. Therefore we need to be careful about the cases when we underestimate the demand than the ones where we overestimate it. RMSE penalises both cases equivalently. Therefore instead of RMS error, we will use RMLS error, i.e. Root Mean Log Squared error which is calculated as :-\n#### **RMLSLE = sqrt(sum((log(p+1)-log(a+1))2)\/n)**\n#### **RMSLE penalises underestimates more than overestimates**","5972170f":"**Answers \/ comments \/ reasoning:**\n\n- temp & atemp are higly correlated as expected\n- casual rentals goes down when it's a workingday\n- as temp goes up more and more people rent bikes\n- humidity and windspeed too affect the bike rentals upto some extent\n- as weather increases,i.e. keeps getting worse, less people rent bikes","a6addd50":"**Answers \/ comments \/ reasoning:**\n\n- Since in our best model we have two models one each for casual and registered cnts, we will have to tune both of them separately.\n- After tuning we will train both the models separately again using their best params and see improvement in accuracy.","8cac2944":"#### **Model 1** : Treating month,hour,year,weekday as integers","e8a1c469":"### **Variation of overall count with discrete variables**"}}