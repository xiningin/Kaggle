{"cell_type":{"ada299d1":"code","c33e2492":"code","b9c8d9ec":"code","e7cd8838":"code","61522934":"code","7623ff43":"code","7577289a":"code","1bb9fdc5":"code","3ef0dfe0":"code","176ebcef":"code","b68c1cd9":"code","ca1de030":"code","42b7a0f3":"code","98bae4f7":"code","5db59598":"code","4cfe128c":"code","475febde":"code","6d761ba7":"code","4ee5d7d7":"code","193db563":"code","6038892a":"code","93f11df5":"code","fed1af6e":"code","138ab7eb":"code","06cf3801":"code","73ce2697":"code","d718daa4":"code","6d6196c5":"code","05d9eb46":"code","bee914b2":"code","1ca1f347":"code","04eff3db":"markdown","4793cca1":"markdown","fd865085":"markdown","8e99c1ab":"markdown","27ff75c5":"markdown","9b606302":"markdown","c56fc4ab":"markdown","b6008d7c":"markdown","a14e4f52":"markdown","626a5553":"markdown","5ddf3a8f":"markdown","562e0762":"markdown","78fe6f31":"markdown","736b8d3a":"markdown","1874620c":"markdown","85b4b669":"markdown","2cbeb12b":"markdown","872d29f7":"markdown","6d403289":"markdown"},"source":{"ada299d1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","c33e2492":"# Importing CSV files as this step you all knows  \ntrain=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')","b9c8d9ec":"# Checking dataframe shape\ntrain.shape , test.shape","e7cd8838":"train.head()","61522934":"# Extracting label from train dataframe\ntrain_label=train.iloc[:,0]","7623ff43":"#converting dataframe to category for hot encode\ntrain_label=train_label.astype('category')","7577289a":"# Converted into Hot encode\ntrain_label=pd.get_dummies(train_label)\ntrain_label.shape","1bb9fdc5":"del train['label']","3ef0dfe0":"# importing Tensorflow\nimport tensorflow as tf","176ebcef":"def variable(x,weight_shape,bias_shape):\n    weight_init=tf.truncated_normal_initializer(stddev=0.1)\n    bias_init=tf.constant_initializer(0.1)\n    weight=tf.get_variable(shape=weight_shape,name='weight',initializer=weight_init)\n    bias=tf.get_variable(shape=bias_shape,name='bias',initializer=bias_init)\n    output= tf.add(tf.matmul(x,weight),bias)\n    return output","b68c1cd9":"x=tf.placeholder(tf.float32,name='x',shape=[None,784])\ny=tf.placeholder(tf.float32,name='y',shape=[None,10])\ndrop=tf.placeholder(tf.float32)","ca1de030":"with tf.variable_scope('layer_1'):\n    hidden_1=variable(x,[784,512],[512])\nwith tf.variable_scope('layer_2'):\n    hidden_2=variable(hidden_1,[512,256],[256])\nwith tf.variable_scope('layer_3'):\n    hidden_3=variable(hidden_2,[256,128],[128])\n    out1=tf.nn.dropout(hidden_3,drop)   # To prevent from Overfitting\nwith tf.variable_scope('outputlayer'):\n    output=variable(out1,[128,10],[10])","42b7a0f3":"# Defining cost function which will be used  by gradient descent\ncross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=output))   ","98bae4f7":"# Graident Descent for minimize cross entropy\noptimize=tf.train.AdamOptimizer(learning_rate=0.001)\nstep=optimize.minimize(cross_entropy)","5db59598":"correct_pred=tf.equal(tf.argmax(output,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))","4cfe128c":"# Initialization of all variables\ninit=tf.initialize_all_variables()","475febde":"train.shape, test.shape","6d761ba7":"# Creating Session for all computation \nsess=tf.Session()","4ee5d7d7":"#Initialize variables\nsess.run(init)","193db563":"train=train.values\ntrain_label=train_label.values","6038892a":"# Some useful parameters for minibatch creation and gradient descent optimization \niteration=2000\nbatch_size=256","93f11df5":"for i in range(iteration):\n    choice=np.random.choice(42000,size=batch_size)\n    x_train=train[choice]\n    y_train=train_label[choice]\n    sess.run(step,feed_dict={x:x_train,y:y_train,drop:0.4})\n\n    if (i%100==0):\n        loss,accu=sess.run([cross_entropy,accuracy],feed_dict={x:x_train,y:y_train,drop:1})\n        print ('loss is',str(loss),'accuracy is',str(accu),'iteration',i+1)","fed1af6e":"# Test dataset shape\ntest.shape","138ab7eb":"# Convert to arrays\ntest_array=test.values","06cf3801":"result=sess.run(output,feed_dict={x:test_array,drop:1})","73ce2697":"result=np.argmax(result,axis=1)","d718daa4":"final=pd.DataFrame({'Predicted':result})\nfinal.head()","6d6196c5":"import matplotlib.pyplot as plt","05d9eb46":"arr=test_array[0:5]\ni=0\nplt.imshow(arr[i].reshape([28,28]))\nplt.title(final.iloc[0,0],size=20)","bee914b2":"arr=test_array[0:5]\ni=1\nplt.imshow(arr[i].reshape([28,28]))\nplt.title(final.iloc[1,0],size=20)","1ca1f347":"arr=test_array[0:5]\ni=2\nplt.imshow(arr[i].reshape([28,28]))\nplt.title(final.iloc[2,0],size=20)","04eff3db":"## Lets check for first 3 prediction made by model","4793cca1":"# In this notebook i tried to cover basic implementation of Tensorflow with Hidden layers. So I hope you guys like it. Upvote this kernel.  \n## In this notebook you will learn following:\n1.  Basic importing and data preprocessing for Deep learning\n2.  Creating Variables such as variable for weight (w) and bias (b)\n3.  Hidden layers creation\n4.  Implementation of mini batch for training \n5. Testing accuracy","fd865085":"### For further use we need to convert our train_label dataframe to Hot - Encode ","8e99c1ab":"## We are going to make a Neural Network with 3 Hidden layer . 1st Hidden layer consist of 512 neurons then 2nd hidden layer of 256 neurons then last hidden layer of 128 neurons which ultimately gives final output with 10 softmax layer neurons","27ff75c5":"![](https:\/\/assets.digitalocean.com\/articles\/handwriting_tensorflow_python3\/cnwitLM.png)","9b606302":"## Now defining Loss function for gradientDescent optimizer for getting optimal value of logit variables","c56fc4ab":"## 1. Importing files ","b6008d7c":"## Below we are going to divide data into Mini batches and Iterate over many times to get global minimum cost","a14e4f52":"### Since 1st column of dataframe train gives label detail. So lets extract that label column","626a5553":"# So our model performed well. ","5ddf3a8f":"# Now after training our model let's check it's accuracy","562e0762":"\n## Checking accuracy with foloowing","78fe6f31":"## Now placeholder which is use to initialize once when graph is run. Basically placeholder is use for giving input to NeuralNet","736b8d3a":"## Now Lets start import tensorflow","1874620c":"## Now start session for prediction","85b4b669":"## Now create variable with initializer along with their shape and make your logit with equation\n## (input * weight)+bias\n","2cbeb12b":"## Using AdamOptimizer to minimize cross entropy. You can also use GradientDescentOptimizer inplace of AdamOptimizer","872d29f7":"# Thanks. :) Happy learning","6d403289":"## Converting Dataframe into ndarray"}}