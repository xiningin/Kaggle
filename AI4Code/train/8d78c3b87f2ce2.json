{"cell_type":{"245cd638":"code","f8668b99":"code","ea8787f1":"code","4fcf2573":"code","107937eb":"code","79711fe4":"code","f6849819":"code","319ef610":"code","a89c5592":"code","1504d69c":"code","4341d800":"code","1b753f68":"code","27da4ac0":"code","5bab6bb6":"code","9c03742a":"code","66c9861e":"code","fba99b9a":"code","6cd64ca4":"code","390580be":"code","70986b33":"code","967d6d5c":"code","a4846cdd":"code","e19a6124":"code","31ec2015":"code","e745bb58":"code","01c10ad5":"code","da2f7abc":"code","efe0ba72":"code","6030b666":"code","ad084fde":"code","aa6e4e16":"code","92b71e95":"code","43efcb85":"code","e1307df6":"code","238752ff":"markdown"},"source":{"245cd638":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport numpy\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Activation, BatchNormalization, MaxPooling2D, Dropout, Flatten, LeakyReLU\nfrom keras.utils import np_utils\nfrom keras import regularizers, models, layers\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8668b99":"train_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nprint(train_data.shape)\nprint(test_data.shape)","ea8787f1":"x_train = train_data.iloc[:,1:]\ny_train = train_data.iloc[:,:1]","4fcf2573":"x_train = x_train\/255\nx_train = x_train.to_numpy().reshape(-1,28,28,1)","107937eb":"y_train = np_utils.to_categorical(y_train,10)  ","79711fe4":"test_data = test_data\/255\ntest_data = test_data.to_numpy().reshape(-1,28,28,1)","f6849819":"print(x_train.shape)\nprint(y_train.shape)","319ef610":"x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size = 0.10, random_state=42 )","a89c5592":"print(x_train.shape) \nprint(x_val.shape)\nprint(y_train.shape) \nprint(y_val.shape)","1504d69c":"print(y_train)","4341d800":"x_train[0:1].shape","1b753f68":"#a = np.array(train_data.iloc[:,0:1].values, dtype='float').reshape((28,28))  # or axis=1 \na = np.array(x_train[1900], dtype='float').reshape((28,28))\nplt.imshow(a)\nplt.show()\nprint(a.shape)\nprint(numpy.argmax(y_train[1900], axis=0))","27da4ac0":"# model = Sequential()\n# model.add(Dense(512, input_dim=784, activation='relu'))\n# model.add(Dense(512, activation='relu'))\n# model.add(Dense(10, activation='sigmoid'))","5bab6bb6":"# plt.imshow(x_reshape[0])\n# print(x_reshape.shape)\n# print(y_train.shape)","9c03742a":"# model=models.Sequential([\n                     \n#                      #cnn\n#                     layers.Conv2D(30,(3,3),activation=\"relu\",input_shape=(28,28,1)),\n#                     layers.MaxPooling2D((2,2)),\n     \n#                     layers.Conv2D(64,(3,3),activation=\"relu\"),\n#                     layers.MaxPooling2D((2,2)),\n#                      #dense_layer\n#                      layers.Flatten(),\n#                      layers.Dense(64,activation=\"relu\"),\n#                      layers.Dense(10,activation=\"softmax\")\n\n# ]\n# )","66c9861e":"# x_train.shape[1:]","fba99b9a":"# build the model\n\n# number of hidden units variable \n# we are declaring this variable here and use it in our CONV layers to make it easier to update from one place\nbase_hidden_units = 32\n\n# l2 regularization hyperparameter\nweight_decay = 1e-4 \n\n# instantiate an empty sequential model \nmodel = Sequential()\n\n# CONV1\n# notice that we defined the input_shape here because this is the first CONV layer. \n# we don\u2019t need to do that for the remaining layers\nmodel.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(28,28,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\n# CONV2\nmodel.add(Conv2D(base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# CONV3\nmodel.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\n# CONV4\nmodel.add(Conv2D(2*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n# CONV5\nmodel.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\n# CONV6\nmodel.add(Conv2D(4*base_hidden_units, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\n# FC7\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\n\n# print model summary\nmodel.summary()","6cd64ca4":"model.compile(\n            optimizer = \"adam\",\n            loss =\"categorical_crossentropy\",\n            metrics =[\"accuracy\"]\n\n)","390580be":"# print(x_reshape.shape)\n# print(y_val_Cate.shape)","70986b33":"history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=10)","967d6d5c":"# model.fit(x_reshape, y_train.to_numpy(), validation_data=( x_val.to_numpy().reshape(-1,28,28,1), y_val.to_numpy()), epochs=10, batch_size=10)","a4846cdd":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.9, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(x_val,  y_val, verbose=0)\nprint('Accuracy: %.4f' % (test_acc * 100.0))","e19a6124":"# test_reshape = test_data.to_numpy().reshape(-1,28,28,1)\n# print(test_reshape.shape)\n# test_reshape = test_reshape\/255","31ec2015":"prediction = model.predict(test_data)\nprint(prediction)","e745bb58":"print(np.argmax(prediction[0]))\nprint(prediction[0])","01c10ad5":"print(prediction[:1])\nprint(np.argmax(prediction, axis=1))","da2f7abc":"print(len(prediction[0]))","efe0ba72":"results = np.argmax(prediction, axis=1)\nprint(results)\nprint(len(results))","6030b666":"actual_result = pd.DataFrame(results, columns= ['Label'])\nprint(actual_result)","ad084fde":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nprint(submission)","aa6e4e16":"submission['Label'] = actual_result['Label']\nprint(submission)","92b71e95":"submission['Label'].unique()","43efcb85":"submission.to_csv(\"submission.csv\",index=False)","e1307df6":"!kaggle competitions submit -c digit-recognizer -f submission.csv -m \"Message\"","238752ff":"#  **Please Upvote if you find this notebook useful. This would be a great motivation for me**"}}