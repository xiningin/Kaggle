{"cell_type":{"5f4f2381":"code","cb49db72":"code","b4ab7cee":"code","07459054":"code","15fb8391":"code","84ab8b89":"code","6b4e96b1":"code","e1d64ed8":"code","5afe05e9":"code","8cc301e4":"code","6a6672b3":"code","ae4a5212":"code","bca8c303":"markdown","c53792b3":"markdown","bc10c756":"markdown","a0c4a622":"markdown","185169a9":"markdown","166ca954":"markdown","dcde676e":"markdown","4ba92f03":"markdown","a078223a":"markdown"},"source":{"5f4f2381":"from matplotlib.pyplot      import close, figure, imshow, savefig, show, title\nfrom matplotlib.lines       import Line2D\nfrom os.path                import join\nfrom random                 import sample\nfrom re                     import split\nfrom torch                  import device, no_grad\nfrom torch.cuda             import is_available\nfrom torch.nn               import Linear, Module, MSELoss, ReLU, Sequential, Sigmoid\nfrom torch.optim            import Adam\nfrom torch.utils.data       import DataLoader\nfrom torchvision.datasets   import MNIST\nfrom torchvision.transforms import Compose, ToTensor\nfrom torchvision.utils      import make_grid","cb49db72":"ENCODER = [28*28,400,200,100,50,25,6]  # sizes of encoder layers\nDECODER = []                           # Decoder layers will be a mirror image of encoder\nLR      = 0.001                        # Learning rate\nN       = 32                           # Number of epochs","b4ab7cee":"class AutoEncoder(Module):\n    '''A class that implements an AutoEncoder\n    '''\n    @staticmethod\n    def get_non_linearity(params):\n        '''Determine which non linearity is to be used for both encoder and decoder'''\n        def get_one(param):\n            '''Determine which non linearity is to be used for either encoder or decoder'''\n            param = param.lower()\n            if param=='relu': return ReLU()\n            if param=='sigmoid': return Sigmoid()\n            return None\n\n        decoder_non_linearity = get_one(params[0])\n        encoder_non_linearity = getnl(params[a]) if len(params)>1 else decoder_non_linearity\n\n        return encoder_non_linearity,decoder_non_linearity\n\n    @staticmethod\n    def build_layer(sizes,\n                    non_linearity = None):\n        '''Construct encoder or decoder as a Sequential of Linear labels, with or without non-linearities\n\n        Positional arguments:\n            sizes   List of sizes for each Linear Layer\n        Keyword arguments:\n            non_linearity  Object used to introduce non-linearity between layers\n        '''\n        linears = [Linear(m,n) for m,n in zip(sizes[:-1],sizes[1:])]\n        if non_linearity==None:\n            return Sequential(*linears)\n        else:\n            return Sequential(*[item for pair in [(layer,non_linearity) for layer in linears] for item in pair])\n\n    def __init__(self,\n                 encoder_sizes         = [28*28,400,200,100,50,25,6],\n                 encoder_non_linearity = ReLU(inplace=True),\n                 decoder_sizes         = [],\n                 decoder_non_linearity = ReLU(inplace=True)):\n        '''\n        Keyword arguments:\n            encoder_sizes            List of sizes for each Linear Layer in encoder\n            encoder_non_linearity    Object used to introduce non-linearity between encoder layers\n            decoder_sizes            List of sizes for each Linear Layer in decoder\n            decoder_non_linearity    Object used to introduce non-linearity between decoder layers\n        '''\n        super().__init__()\n        self.encoder_sizes = encoder_sizes\n        self.decoder_sizes = encoder_sizes[::-1] if len(decoder_sizes)==0 else decoder_sizes\n\n\n        self.encoder = AutoEncoder.build_layer(self.encoder_sizes,\n                                               non_linearity = encoder_non_linearity)\n        self.decoder = AutoEncoder.build_layer(self.decoder_sizes,\n                                               non_linearity = decoder_non_linearity)\n        self.encode  = True\n        self.decode  = True\n\n\n    def forward(self, x):\n        '''Propagate value through network\n\n           Computation is controlled by self.encode and self.decode\n        '''\n        if self.encode:\n            x = self.encoder(x)\n\n        if self.decode:\n            x = self.decoder(x)\n        return x\n\n    def n_encoded(self):\n        return self.encoder_sizes[-1]\n","07459054":"def train(loader,model,optimizer,criterion,\n          N   = 25,\n          dev = 'cpu'):\n    '''Train network\n\n       Parameters:\n           loader       Used to get data\n           model        Model to be trained\n           optimizer    Used to minimze errors\n           criterion    Used to compute errors\n      Keyword parameters:\n          N             Number of epochs\n          dev           Device - cpu or cuda\n    '''\n    Losses        = []\n\n    for epoch in range(N):\n        loss = 0\n        for batch_features, _ in loader:\n            batch_features = batch_features.view(-1, 784).to(dev)\n            optimizer.zero_grad()\n            outputs        = model(batch_features)\n            train_loss     = criterion(outputs, batch_features)\n            train_loss.backward()\n            optimizer.step()\n            loss += train_loss.item()\n\n        Losses.append(loss \/ len(loader))\n        print(f'epoch : {epoch+1}\/{N}, loss = {Losses[-1]:.6f}')\n\n    return Losses","15fb8391":"    dev           = device(\"cuda\" if is_available() else \"cpu\")\n    encoder_non_linearity,decoder_non_linearity = AutoEncoder.get_non_linearity(['relu'])\n    model         = AutoEncoder(encoder_sizes         = ENCODER,\n                                encoder_non_linearity = encoder_non_linearity,\n                                decoder_non_linearity = decoder_non_linearity,\n                                decoder_sizes         = DECODER).to(dev)\n    optimizer     = Adam(model.parameters(),\n                         lr = LR)\n    criterion     = MSELoss()\n    transform     = Compose([ToTensor()])\n\n    train_dataset = MNIST(root=\"~\/torch_datasets\",\n                          train     = True,\n                          transform = transform,\n                          download  = True)\n    test_dataset  = MNIST(root=\"~\/torch_datasets\",\n                          train     = False,\n                          transform = transform,\n                          download  = True)\n\n    train_loader  = DataLoader(train_dataset,\n                               batch_size  = 128,\n                               shuffle     = True,\n                               num_workers = 4)\n    test_loader   = DataLoader(test_dataset,\n                               batch_size  = 32,\n                               shuffle     = False,\n                               num_workers = 4)\n","84ab8b89":"Losses = train(train_loader,model,optimizer,criterion,\n                   N   = N,\n                   dev = dev)\n","6b4e96b1":"def reconstruct(loader,model,criterion,\n                N        = 25,\n                prefix   = 'test',\n                show     = False,\n                figs     = '.\/figs',\n                n_images = -1):\n    '''Reconstruct images from encoding\n\n       Parameters:\n           loader\n           model\n       Keyword Parameters:\n           N        Number of epochs used for training (used in image title only)\n           prefix   Prefix file names with this string\n           show     Used to display images\n           figs     Directory for storing images\n    '''\n\n    def plot(original=None,decoded=None):\n        '''Plot original images and decoded images'''\n        fig = figure(figsize=(10,10))\n        ax    = fig.subplots(nrows=2)\n        ax[0].imshow(make_grid(original.view(-1,1,28,28)).permute(1, 2, 0))\n        ax[0].set_title('Raw images')\n        scaled_decoded = decoded\/decoded.max()\n        ax[1].imshow(make_grid(scaled_decoded.view(-1,1,28,28)).permute(1, 2, 0))\n        ax[1].set_title(f'Reconstructed images after {N} epochs')\n        savefig(join(figs,f'{prefix}-comparison-{i}'))\n        if not show:\n            close (fig)\n\n    samples = [] if n_images==-1 else sample(range(len(loader)\/\/loader.batch_size),\n                                             k = n_images)\n    loss = 0.0\n    with no_grad():\n        for i,(batch_features, _) in enumerate(loader):\n            batch_features = batch_features.view(-1, 784).to(dev)\n            outputs        = model(batch_features)\n            test_loss      = criterion(outputs, batch_features)\n            loss          += test_loss.item()\n            if len(samples)==0 or i in samples:\n                plot(original=batch_features,\n                    decoded=outputs)\n\n\n    return loss\n\n\n","e1d64ed8":"test_loss = reconstruct(test_loader,model,criterion,\n                            N        = N,\n                            show     = True,\n                            figs     = '.',\n                            n_images = 5,\n                            prefix   = 'foo')","5afe05e9":"def plot_losses(Losses,\n                lr                   = 0.001,\n                encoder              = [],\n                decoder              = [],\n                encoder_nonlinearity = None,\n                decoder_nonlinearity = None,\n                N                    = 25,\n                show                 = False,\n                figs                 = '.\/figs',\n                prefix               = 'ae',\n                test_loss            = 0):\n    '''Plot curve of training losses'''\n    fig = figure(figsize=(10,10))\n    ax  = fig.subplots()\n    ax.plot(Losses)\n    ax.set_ylim(bottom=0)\n    ax.set_title(f'Training Losses after {N} epochs')\n    ax.set_ylabel('MSELoss')\n    ax.text(0.95, 0.95, '\\n'.join([f'lr = {lr}',\n                                   f'encoder = {encoder}',\n                                   f'decoder = {decoder}',\n                                   f'encoder nonlinearity = {encoder_nonlinearity}',\n                                   f'decoder nonlinearity = {decoder_nonlinearity}',\n                                   f'test loss = {test_loss:.3f}'\n                                   ]),\n            transform           = ax.transAxes,\n            fontsize            = 14,\n            verticalalignment   = 'top',\n            horizontalalignment = 'right',\n            bbox                = dict(boxstyle  = 'round',\n                                       facecolor = 'wheat',\n                                       alpha     = 0.5))\n    savefig(join(figs,f'{prefix}-losses'))\n    if not show:\n        close (fig)","8cc301e4":"    plot_losses(Losses,\n                lr                   = LR,\n                encoder              = model.encoder_sizes,\n                decoder              = model.decoder_sizes,\n                encoder_nonlinearity = encoder_non_linearity,\n                decoder_nonlinearity = decoder_non_linearity,\n                N                    = N,\n                show                 = True,\n                figs                 = '.',\n                prefix               = 'foo',\n                test_loss            = test_loss)","6a6672b3":"def plot_encoding(loader,model,\n                figs    = '.\/figs',\n                dev     = 'cpu',\n                colours = [],\n                show    = False,\n                prefix  = 'ae'):\n    '''Plot the encoding layer\n\n       Since this is multi,dimensional, we will break it into 2D plots\n    '''\n    def extract_batch(batch_features, labels,index):\n        '''Extract xs, ys, and colours for one batch'''\n\n        batch_features = batch_features.view(-1, 784).to(dev)\n        encoded        = model(batch_features).tolist()\n        return list(zip(*([encoded[k][2*index] for k in range(len(labels))],\n                          [encoded[k][2*index+1] for k in range(len(labels))],\n                          [colours[labels.tolist()[k]] for k in range(len(labels))])))\n\n    save_decode  = model.decode\n    model.decode = False\n    with no_grad():\n        fig     = figure(figsize=(10,10))\n        ax      = fig.subplots(nrows=2,ncols=2)\n        for i in range(2):\n            for j in range(2):\n                if i==1 and j==1: break\n                index    = 2*i + j\n                if 2*index+1 < model.n_encoded():\n                    xs,ys,cs = tuple(zip(*[xyc for batch_features, labels in loader for xyc in extract_batch(batch_features, labels,index)]))\n                    ax[i][j].set_title(f'{2*index}-{2*index+1}')\n                    ax[i][j].scatter(xs,ys,c=cs,s=1)\n\n    ax[0][0].legend(handles=[Line2D([], [],\n                                    color  = colours[k],\n                                    marker = 's',\n                                    ls     = '',\n                                    label  = f'{k}') for k in range(10)])\n    savefig(join(figs,f'{prefix}-encoding'))\n    if not show:\n        close (fig)\n\n    model.decode = save_decode","ae4a5212":"plot_encoding(test_loader,model,\n                  show    = True,\n                  colours = ['xkcd:purple',\n                             'xkcd:green',\n                             'xkcd:blue',\n                             'xkcd:pink',\n                             'xkcd:brown',\n                             'xkcd:red',\n                             'xkcd:magenta',\n                             'xkcd:yellow',\n                             'xkcd:light teal',\n                             'xkcd:puke'],\n                  figs    = '.',\n                  prefix  = 'foo')","bca8c303":"# Function to train network","c53792b3":"# Train network","bc10c756":"# Introduction\n\nAn Autoencoder is a neural network which is trained to reproduce its input. As the figure shows, the layers are successively shorter, until they reach a minimum, then they increase again. Data flows from left to right, and we train so the rightmost layer matches the leftmost, as closely as possible. *If we can make this work,* i.e. if the tall blue bar on the right closely matches the tall red bar on the left, then the middle layer (the small magenta layer in the centre) must somehow contain essentially the same information as the two outermost bars: we call the middle layer the *encoding*: it divides the network into two parts, the *encoder*, on the left, and the *decoder*. We have assumed that the training is succesful: but why should we ever expect this idea to work? \n\n![ecdc.png](attachment:78022533-d82d-4ba9-b54f-00697bd0fc2a.png)\n\nThe [manifold hypothesis](https:\/\/en.wikipedia.org\/wiki\/Manifold_hypothesis) asserts that many high-dimensional data sets that occur in the real world actually lie along low-dimensional manifolds inside that high-dimensional space. In the following (grossly oversimplified) example, the data points appear to live in a 3 dimensional space, but they turn out to lie on the green torus, i.e. on a 2 dimensional surface. If we accept that the manifold hypothesis is correct, then it seems reasonable that we can infer the lower dimensional representation of the data, which is what the Autoencoder actually does.\n\n![Figure_1.jpg](attachment:6875994e-fc51-4a80-803d-219d6ed75608.jpg)\n\nIn this notebook I show how to implementat a simple autoencoder using PyTorch. I have created it so I can understand how an autoencoder works. I hope it will also be useful for others.\n\n## References\n\n1. [Reducing the Dimensionality of Data with Neural Networks--G. E. Hinton and R. R. Salakhutdinov](https:\/\/www.cs.toronto.edu\/~hinton\/science.pdf)\n\n1. [Implementing an Autoencoder in PyTorch--Abien Fred Agarap](https:\/\/medium.com\/pytorch\/implementing-an-autoencoder-in-pytorch-19baa22647d1)","a0c4a622":"# Initialize network and data, and prepare to train\n\nThis is proably a suboptimal way to load the MNIST dataset, but it will do for this example.","185169a9":"# The Autoencoder class\n\nThe latest version of this class can be found at [github](https:\/\/github.com\/weka511\/learn\/blob\/master\/ae.py)","166ca954":"# Import functions from libraries","dcde676e":"# Plot encoded data\n\nThe encoding shows that the images for most digits are separated. It also suggest that the encoded data clouls have been made to live in a 5 dimensional manifold instead of needind 6.","4ba92f03":"# Hyperparameters\n\n1. The sizes of the encoder layers are taken from [Reducing the Dimensionality of Data with Neural Networks--G. E. Hinton and R. R. Salakhutdinov](https:\/\/www.cs.toronto.edu\/~hinton\/science.pdf)\n1. The learning rate was optimized by trial and error. The error rates are plotted here [here](https:\/\/github.com\/weka511\/learn\/issues\/26)","a078223a":"# Compare output layer with Inputs, to get an idea of the quality of the encoding"}}