{"cell_type":{"01285a4a":"code","286b4561":"code","887940f3":"code","e94d0d1d":"code","db14e19f":"code","34c8aa84":"code","aeb7cc0e":"code","1d43a48e":"code","3b5a6c33":"code","c2139500":"code","ccebca0e":"code","49ac8f3b":"code","b4e9c0ba":"code","23bb7973":"code","0dd57414":"code","c660a831":"code","7e111a22":"code","83253cb7":"code","b4dd0bec":"code","ec5c47ac":"code","aa062330":"code","40a904fe":"code","3e6db46c":"code","8f408666":"code","3fd3e31a":"code","8b18b667":"code","0e3aa7ca":"code","225224e2":"code","7c05b240":"code","0f1f8607":"code","b02d2d78":"code","7f185876":"code","b811e0d8":"markdown","8435d35d":"markdown","df4fb3d5":"markdown"},"source":{"01285a4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","286b4561":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom matplotlib import pyplot as plt \n\n## Keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","887940f3":"df_test = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv\")\ndf_test_l = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv\")","e94d0d1d":"## We have test and test labels. So merging them together.\ndf_test = pd.merge(df_test, df_test_l, how = 'left', on = 'id')\ndf_test.head()","db14e19f":"## Reading the training data\ndf = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\n\n## Joining training and test data\ndf = pd.concat([df, df_test])\n\ndf.sample(5)","34c8aa84":"df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0 ).astype(int)","aeb7cc0e":"df.sample(5)","1d43a48e":"# df_['toxic_total'].value_counts()\ndf['y'].value_counts()","3b5a6c33":"df_ = df[['comment_text', 'y']]","c2139500":"df_['y'].value_counts()","ccebca0e":"df_one = df_[df_['y'] == 1]\ndf_zero = df_[df_['y'] == 0]","49ac8f3b":"df_sample = df_zero.sample(n = 21384)","b4e9c0ba":"df_sample = pd.concat([df_one, df_sample])","23bb7973":"df_sample.sample(10)","0dd57414":"df_sample['y'].value_counts()","c660a831":"## Plotting the histogram to check the distribution of length of each reviews. \nplt.hist([len(x) for x in df_sample['comment_text']], bins=500)\nplt.show()","7e111a22":"## Hyper-parameters considered for building the model\nembedding_dim = 300\nmax_length = 1000\npadding_type = 'post'\ntrunc_type = 'post'\noov_tok = \"<oov>\"","83253cb7":"## Tokenizing the sentenes\ntokenizer = Tokenizer(oov_token = oov_tok)\ntokenizer.fit_on_texts(df_sample['comment_text'])\nword_index = tokenizer.word_index","b4dd0bec":"##training sequences and labels\ntrain_seqs = tokenizer.texts_to_sequences(df_sample['comment_text'])\ntrain_padded = pad_sequences(train_seqs,maxlen=max_length, truncating=trunc_type)","ec5c47ac":"## Model Architecture\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(word_index)+1, embedding_dim, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","aa062330":"## Summary of the model\nmodel.summary()","40a904fe":"## Compiling the model. The loss function considered is binary crossentropy as we are predicting on only two classes. \nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","3e6db46c":"## Input to tesnorflow model should always be np array format\ntrain_labels = np.array(df_sample[\"y\"])","8f408666":"## Make sure to use GPU before running this cell. Time takes per epoch without gpu is 19 min\nnum_epochs = 10\n## For early stopping to ensure it doesnt overfit\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\nhistory = model.fit(\n    train_padded, \n    train_labels, \n    epochs=num_epochs,\n    batch_size = 256,\n    callbacks=[callback]\n    )","3fd3e31a":"## Reading the comments that we need to score\ndf_ = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")","8b18b667":"## Extracting the text and converting it for the model \nX_ = tokenizer.texts_to_sequences(df_['text'])\ntest_padded = pad_sequences(X_, maxlen=max_length, truncating=trunc_type)","0e3aa7ca":"pred = model.predict(test_padded)","225224e2":"pred","7c05b240":"df_['score'] = pred","0f1f8607":"df_","b02d2d78":"df_.iloc[4]['text']","7f185876":"df_[['comment_id', 'score']].to_csv(\"submission.csv\", index = False)","b811e0d8":"## Note:\nPlease refer to the below two notebooks before getting started. first half of the code is taken from them.\n\nhttps:\/\/www.kaggle.com\/kaushikholla\/0-787-regression-baseline-tf-idf\n\nhttps:\/\/www.kaggle.com\/kaushikholla\/0-752-eda-baseline-model-svm","8435d35d":"## Comments to Score","df4fb3d5":"## Getting the data together"}}