{"cell_type":{"512edab8":"code","973f20e0":"code","68948ca9":"code","64d637bb":"code","e61845c2":"code","faa931d1":"code","0aab2885":"code","abbe32f8":"code","0f784ec0":"code","7335a5ff":"code","6ae56937":"code","9fc2e82c":"code","c4cf54a1":"code","30449b99":"code","2362cc4e":"code","769c8599":"code","d5ee3e34":"code","a56fb85a":"code","f77821de":"code","24d61bdf":"code","fd471075":"code","56b9e774":"code","27f089ed":"code","8dd00ad1":"code","4bb6fbba":"code","7e4825c5":"code","107b6a80":"code","db210e92":"code","25a879cd":"markdown","33063e08":"markdown","46bfcc8c":"markdown"},"source":{"512edab8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n#from sklearn.learning_curve import validation_curve\n#from sklearn.learning_curve import learning_curve\n#from sklearn.cross_validation import train_test_split\n#from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n#from sklearn.cross_validation  import cross_val_score\nfrom sklearn.model_selection  import validation_curve\nfrom sklearn.model_selection  import learning_curve\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, r2_score\nfrom sklearn.model_selection   import cross_val_score\n\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\nwarnings.filterwarnings('ignore')","973f20e0":"#################### Define Helper Functions\ndef bs_create_polynomial_terms(l_train, l_test, degree):\n    from sklearn.preprocessing import PolynomialFeatures\n    poly = PolynomialFeatures(degree=degree)\n    # details http:\/\/scikit-learn.org\/stable\/modules\/linear_model.html\n    l_train_poly = poly.fit_transform(l_train) \n    l_test_poly = poly.fit_transform(l_test)\n    return l_train_poly, l_test_poly\n    \ndef bs_scale_mean_std(l_train, l_test):\n    # read about data scaling here: \n    # http:\/\/quant.stackexchange.com\/questions\/4434\/gradient-tree-boosting-do-input-attributes-need-to-be-scaled\n    sc = StandardScaler()\n    l_train_scaled = pd.DataFrame(sc.fit_transform(l_train))\n    l_test_scaled = pd.DataFrame(sc.transform(l_test)) # careful, transform() only.\n    return l_train_scaled, l_test_scaled\n\ndef bs_fit_and_save(clf, l_train, l_target, l_test, filename):\n    # more about it here: http:\/\/scikit-learn.org\/stable\/modules\/svm.html#regression\n    clf.fit (l_train, l_target)\n    # The mean square error\n    predict_train = clf.predict(l_train)\n    print(\"Residual sum of squares: %.2f\" % np.mean((predict_train - l_target) ** 2))\n    # Explained variance score: 1 is perfect prediction\n    print('Variance score: %.2f' % clf.score(l_train, l_target))\n    return clf\n\ndef bs_accuracy(test, pred):   \n    print('Acur\u00e1cia norm. = {:.2f}'.format(accuracy_score(test, pred)))\n    print('Acur\u00e1cia = {:.0f}'.format(accuracy_score(test, pred, normalize=False)))\n\ndef plot_chart_predict(x__plot, model, x_test, y_test, bot, top, desc):\n    y_pred = model.predict(x_test)\n    v_title = \"Predi\u00e7\u00e3o de viagens - Modelo: \" + desc\n\n    \n    plt.rcParams[\"figure.figsize\"] = (15,9)\n    plt.plot(x__plot['date2'][bot:top], np.exp(np.log(y_test[bot:top])),  color='black', label=\"Dia Real\")\n    plt.plot(x__plot['date2'][bot:top], np.exp(y_pred[bot:top]),10, color='blue', linewidth=3,  label=\"Predi\u00e7\u00e3o\")\n    plt.legend(loc='upper right')\n    plt.title(v_title, fontsize=16, fontweight='bold')\n    plt.xlabel(\"Dia\")\n    plt.ylabel(\"Media Viagens\")\n    plt.show()    ","68948ca9":"#Carregar dataset\n#path = \"data.csv\"\npath = \"..\/input\/data.csv\"\ndf = pd.read_csv(path)\n\ndf.shape","64d637bb":"#feriados ###############\nholidays = [\n'2014-01-01','2014-12-25',\n'2014-11-11','2014-07-04',\n'2014-01-20','2014-02-17',\n'2014-03-02','2014-05-26',\n'2014-09-01','2014-10-13',\n'2014-11-27','2015-01-01',\n'2015-12-25','2015-11-11',\n'2015-07-04','2015-01-19',\n'2015-02-16','2015-03-02',\n'2015-05-25','2015-09-07',\n'2015-10-12','2015-11-26',\n'2016-01-01','2016-12-25',\n'2016-11-11','2016-07-04',\n'2016-01-18','2016-02-15',\n'2016-03-04','2016-05-30',\n'2016-09-05','2016-10-10',\n'2016-11-24','2017-01-01',\n'2017-12-25','2017-11-11',\n'2017-07-04','2017-01-16',\n'2017-02-20','2017-03-06',\n'2017-05-29','2017-09-04',\n'2017-10-09','2017-11-23'\n]\n\ndf_holidays = pd.DataFrame(holidays)\ndf_holidays['date'] = pd.to_datetime(df_holidays[0]).dt.date\ndf_holidays['holiday'] = 1\ndf_holidays = df_holidays.drop([0], axis=1)\n\n\n#Corringindo campo day com 0\ndf.day =  df.starttime.astype(str).str.slice(8,10).astype(int)","e61845c2":"#Novas features\ndf.starttime = pd.to_datetime(df.starttime)\ndf.stoptime  = pd.to_datetime(df.stoptime)\ndf['date']   = df.starttime.dt.date\n\n#Defini\u00e7\u00e3o fim de semana\ndf['weekend'] = np.where(df.starttime.dt.weekday > 4 , 1, 0)\n\n#Inicializando novas features\ndf['season'] = ''\n\n#Defini\u00e7\u00e3o esta\u00e7\u00f5es Hemisf\u00e9rio NORTE  ##########################\nfor x in range(df.year.min().astype(int), df.year.max().astype(int)+1):\n    #Primavera: 21-03 at\u00e9 20-06\n    df.loc[(df.starttime > str(x)+'-03-21 00:00:00') & (df.starttime < str(x)+'-06-20 23:59:59'),  'season'] = 'primavera'\n    #Ver\u00e3o:     21-06 at\u00e9 20-09\n    df.loc[(df.starttime > str(x)+'-06-21 00:00:00') & (df.starttime < str(x)+'-09-20 23:59:59'),  'season'] = 'ver\u00e3o'\n    #Outono:    21-09 at\u00e9 20-12\n    df.loc[(df.starttime > str(x)+'-09-21 00:00:00') & (df.starttime < str(x)+'-12-20 23:59:59'),  'season'] = 'outono'\n    #Inverno:   21-12 at\u00e9 20-03\n    df.loc[(df.starttime > str(x)+'-12-21 00:00:00') & (df.starttime < str(x+1)+'-03-20 23:59:59'),'season'] = 'inverno'\n    \n    \n    \n#Jun\u00e7\u00e3o dos dados com feriados #################################\ndf_holidays.head()\ndf_join = df.set_index('date').join(df_holidays.set_index('date'))\ndf_join['isholiday']  = np.where(df_join.holiday==1, 1, 0)\ndf_join['regularday'] = np.where(df_join.isholiday+df_join.weekend == 0, 1, 0)\n\n#clear DF ##################################\ndf.iloc[0:0]\ndel df","faa931d1":"#Label Encoder ##############################\n# Replace all male and female genders with '0's and '1's respectively\ndf_join.loc[df_join[\"gender\"] == \"Male\", \"gender\"] = 0\ndf_join.loc[df_join[\"gender\"] == \"Female\", \"gender\"] = 1\n\n# tipo usuario\nlb_usertype = LabelEncoder()\ndf_join[\"usertype_code\"] = lb_usertype.fit_transform(df_join[\"usertype\"])\ndf_join[[\"usertype\", \"usertype_code\"]].head(11)\n\n#esta\u00e7\u00e3o\nlb_to_station_name = LabelEncoder()\ndf_join[\"to_station_name_code\"] = lb_usertype.fit_transform(df_join[\"to_station_name\"])\ndf_join[[\"to_station_name\", \"to_station_name_code\"]].head(11)\n\n\n#esta\u00e7\u00e3o\n#lb_season = LabelEncoder()\n#df_join[\"season_code\"] = lb_season.fit_transform(df_join[\"season\"])\n#df_join[[\"season\", \"season_code\"]].head(11)\n\n#lb_date_id = LabelEncoder()\n#df_join[\"lb_date_id_code\"] = lb_season.fit_transform(df_join[\"date_id\"])\n#df_join[[\"date_id\", \"lb_date_id_code\"]].head(11)","0aab2885":"#convert lines into columns\ndf_join = pd.get_dummies(df_join, columns=[\"season\"])\ndf_join_del = df_join[df_join['season_'] == 1]\ndf_join = df_join.drop(df_join_del.index, axis=0)\n\n# convert string to int\ndf_join[['year', 'month', 'day', 'hour']] = df_join[['year', 'month', 'day', 'hour']].astype(int)","abbe32f8":"#Agregar informa\u00e7\u00e3o para modelo\ncol = [\n'year',\n 'month',\n    'day',\n'weekend',\n'season_inverno',\n'season_outono',\n'season_primavera',\n'season_ver\u00e3o',\n'isholiday',\n'regularday'\n]\n\ndf_join['trip_count'] = 1\n\n#Agrega\u00e7\u00e3o\ndf_join_agg1 =  df_join.groupby(col).aggregate({                                         \n                                         'trip_count'      : 'sum'\n                                        }).reset_index()","0f784ec0":"#split datasets to train\/test and validation\ndf_join_agg_2017 = df_join_agg1[df_join_agg1.year == 2017]\ndf_join_agg_2016 = df_join_agg1[df_join_agg1.year != 2017]","7335a5ff":"y = df_join_agg_2016.trip_count\n\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(df_join_agg_2016, y, test_size=0.25)\n\nX_train = X_train.drop(labels=[\"trip_count\"], axis=1)\nX_test = X_test.drop(labels=[\"trip_count\"], axis=1)\n\n#valida\ny_valida = df_join_agg_2017.trip_count\nX_valida = df_join_agg_2017.drop(labels=[\"trip_count\"], axis=1)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n\n\nx_plot = X_test.copy()\nx_plot['date2'] = x_plot['year'].astype(str) +  x_plot['day'].astype(str) +  x_plot['month'].astype(str) \nx_plot2 = X_valida.copy()\nx_plot2['date2'] = x_plot2['year'].astype(str) +  x_plot2['day'].astype(str) +  x_plot2['month'].astype(str) ","6ae56937":"X_train.head(5)","9fc2e82c":"plt.matshow(X_train.corr())\n# fit a model\n#y_train = np.log(y_train)","c4cf54a1":"lm         = linear_model.LinearRegression()\nlm.fit(X_train, np.log(y_train))","30449b99":"## The line \/ model\ny_train   = np.log(y_train)","2362cc4e":"y_pred  = lm.predict(X_test)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predi\u00e7\u00e3o\")\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predi\u00e7\u00e3o de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","769c8599":"\nplot_chart_predict(x_plot2, bot=1,top=30,model=lm,x_test=X_valida,y_test=y_valida,desc=\"Baseline\")","d5ee3e34":"################## Simple Linear Regression\n# Since its a regression problem we will first develop simple linear regression\n\n# Create linear regression object\nclf1 = linear_model.LinearRegression()\n\n# get fitted regresser\nclf1 = bs_fit_and_save(clf1, X_train, y_train, X_test, \"output_SLR\")\ny_pred  = clf1.predict(X_test)\n\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predi\u00e7\u00e3o\")\n\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predi\u00e7\u00e3o de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","a56fb85a":"plot_chart_predict(x_plot2, bot=1,top=30,model=clf1,x_test=X_valida,y_test=y_valida,desc=\"Baseline2\")","f77821de":"################## Simple Linear Regression with Ridge Regression\n\n# Now we will perform Ridge Regression\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(X_train, X_test)\n\n# first we will perform cross-validation to find the best alpha value\nclf2 = linear_model.RidgeCV(alphas=[0.0001, 0.001, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\nclf2 = bs_fit_and_save(clf2, train_scaled, y_train, test_scaled, \"output_Ridge\")\n\n# The coefficients\nprint('Coefficients: \\n', clf2.coef_)\nprint('Alpha: \\n', clf2.alpha_) \n\n","24d61bdf":"################## Simple Linear Regression with Lasso Regression\n\n# Unlike simple linear regression, lasso regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(X_train, X_test)\n\n# first we will perform cross-validation to find the best alpha value\nclf3 = linear_model.LassoCV(alphas=[0.001, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf3 = bs_fit_and_save(clf3, train_scaled, y_train, test_scaled, \"output_Lasso\")\n\n# The coefficients\nprint('Alpha: \\n', clf3.alpha_)  ","fd471075":"################## Simple Linear Regression with Polynomial terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Create linear regression object\nclf4 = linear_model.LinearRegression()\n\n# get fitted regresser\nclf4 = bs_fit_and_save(clf4, train_poly, y_train, test_poly, \"output_poly_d2\")","56b9e774":"################## Ridge Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf5 = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf5 = bs_fit_and_save(clf5, train_scaled, y_train, test_scaled, \"output_Ridge_poly_2\")\n\n\n\ny_pred  = clf5.predict(test_scaled)\n\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predi\u00e7\u00e3o\")\n\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predi\u00e7\u00e3o de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","27f089ed":"################## Lasso Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Lasso regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf6 = linear_model.LassoCV(alphas=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf6 = bs_fit_and_save(clf6, train_scaled, y_train, test_scaled, \"output_lasso_poly_2\")","8dd00ad1":"################## Support Vector Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# SVR requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\n# ideally these parameters should be determined using cross-validation\nclf7 = svm.SVR(kernel='rbf', C=100, gamma=0.01) \n\n# get fitted regresser\nclf7 = bs_fit_and_save(clf7, train_scaled, y_train, test_scaled, \"output_svm_poly_2\")","4bb6fbba":"################## Gradient Boosting Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf8 = GradientBoostingRegressor(n_estimators=350, learning_rate=0.1, \n                                max_depth=3, loss='ls')\n\n# get fitted regresser\nclf8 = bs_fit_and_save(clf8, train_scaled, y_train, test_scaled, \"output_gbm_poly_2\")\n\n\ny_pred  = clf8.predict(test_scaled)\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predi\u00e7\u00e3o\")\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predi\u00e7\u00e3o de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","7e4825c5":"#Validation ###################################################\n# create polynomial terms\ntrain_poly, valid_poly = bs_create_polynomial_terms(X_train, X_valida, 2)\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, valid_scaled = bs_scale_mean_std(train_poly, valid_poly)\n\n\nplot_chart_predict(x_plot2, bot=120,top=130,model=clf8,x_test=valid_scaled,y_test=y_valida,desc=\"Gradient Boosting - Polynomial\")","107b6a80":"################## GBR with parameter estimation with cross-validation\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 3)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n\n# create polynomial terms\ntrain2_poly, valid_poly = bs_create_polynomial_terms(X_train, X_valida, 3)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain2_scaled, valid_poly = bs_scale_mean_std(train2_poly, valid_poly)\n\n\n# Create linear regression object\nt_clf = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, \n                                max_depth=3, loss='ls')\n                                \n#from sklearn.grid_search import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\nparam_range_n_estimators = [500, 1000, 2000]\nparam_range_max_depth = [1, 3, 5]\n\nparam_grid = [{'n_estimators': param_range_n_estimators,\n              'max_depth': param_range_max_depth}]\n\n# we will not define optional 'scoring' parameter. It will use lsr for scoring\n# read here for detail of scoring for classification and regression grid search\n# http:\/\/scikit-learn.org\/stable\/modules\/grid_search.html\n# https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/51a765a\/sklearn\/metrics\/regression.py#L370\nclf10 = GridSearchCV(estimator=t_clf, param_grid=param_grid, cv=5, n_jobs=4)\n                 \n# get fitted regresser\nclf10 = bs_fit_and_save(clf10, train_scaled, y_train, test_scaled, \"output_gbm_cv_poly_3\") # this will take some time","db210e92":"plot_chart_predict(x__plot=x_plot2, bot=213,top=219,model=clf10,x_test=valid_poly,y_test=y_valida,desc=\"Gradient Boosting - Cross Valid\")","25a879cd":"### Carregar dataset","33063e08":"# Chicago Divvy Bicycle Sharing Data\n\n#### Link Kaggle\nhttps:\/\/www.kaggle.com\/yingwurenjian\/chicago-divvy-bicycle-sharing-data\n\n#### Descri\u00e7\u00e3o das features:\n<br><b>trip_id<\/b>ID attached to each trip taken\n<br><b>year<\/b> Year\n<br><b>month<\/b> Month\n<br><b>week<\/b> Week No.\n<br><b>day<\/b> Day\n<br><b>hour<\/b> Hour\n<br><b>usertype<\/b> \"Customer\" is a rider who purchased a 24-Hour Pass; \"Subscriber\" is a rider who purchased an Annual Membership\n<br><b>gender<\/b>\n<br><b>starttimeday<\/b> and time trip started, in CST\n<br><b>stoptimeday<\/b> and time trip ended, in CST\n<br><b>tripdurationtime<\/b> of trip in minutes\n<br><b>temperature<\/b>\n<br><b>events<\/b>\n<br><b>from_station_idID<\/b> of station where trip originated\n<br><b>from_station_namename<\/b> of station where trip terminated\n<br><b>latitude_startstation<\/b> latitude\n<br><b>longitude_startstation<\/b> longitude\n<br><b>dpcapacity_startnumber<\/b> of total docks at each station\n<br><b>to_station_id<\/b>\n<br><b>to_station_name<\/b>\n<br><b>latitude_end<\/b>\n<br><b>longitude_end<\/b>\n<br><b>dpcapacity_endnumber<\/b> of total docks at each station","46bfcc8c":"### Bibliotecas"}}