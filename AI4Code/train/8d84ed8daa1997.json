{"cell_type":{"1f7ac648":"code","19ed5fef":"code","20f2befd":"code","f07a7c3f":"code","5224109a":"code","4000e2f2":"code","caa23242":"code","281520c1":"code","1e613bf3":"code","a9eb113a":"code","a5742f64":"code","9374df9c":"code","701a2041":"code","c0085891":"code","c8bdfb47":"code","69fd0040":"code","0bcb5800":"code","5cf83e87":"code","1b0fb819":"code","75df2b07":"code","136823dd":"code","d0754401":"code","c6a3892b":"code","ca9d01bd":"code","12276a0b":"code","2d2d8c38":"code","bfebeffc":"markdown","ddd4b6c1":"markdown","ebedad73":"markdown","cc21b8d6":"markdown","9e3154ca":"markdown","6a153435":"markdown","1bd6e9f6":"markdown","9d95d645":"markdown","905140be":"markdown","18219fc9":"markdown","00ba3cef":"markdown","699ee6a0":"markdown","bf191aa6":"markdown","3da5118f":"markdown","f4b50164":"markdown","ec00b19e":"markdown","a32a837a":"markdown","a439d044":"markdown","ca4420ed":"markdown","b68cc4a2":"markdown","367ddc28":"markdown","48cd585b":"markdown","69a9a7fa":"markdown","47b2c0ac":"markdown","16d86c7d":"markdown","31d1dfc5":"markdown","099187cc":"markdown","d2285c20":"markdown","e6f9a150":"markdown","24fa98ad":"markdown","c3140a38":"markdown","7ac24721":"markdown","ed0fc7ad":"markdown","4589f38d":"markdown","ab83e80b":"markdown","aacaf146":"markdown","b45853bd":"markdown"},"source":{"1f7ac648":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","19ed5fef":"import matplotlib.pyplot as plt\nfrom numpy import ones\nfrom numpy import zeros\nfrom numpy.random import rand\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom numpy import expand_dims\nfrom numpy import vstack\n\nfrom keras.datasets.mnist import load_data\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LeakyReLU\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, LeakyReLU, Reshape, Conv2DTranspose\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model","20f2befd":"(X_train, y_train), (X_test, y_test) = load_data()\n\n# dataset dimensions\nprint(f'Train set shape: {X_train.shape}, {y_train.shape}')\nprint(f'Test set shape: {X_test.shape}, {y_test.shape}')","f07a7c3f":"plt.imshow(X_train[1], cmap='gray')","5224109a":"# X_train[1]","4000e2f2":"for i in range(10):\n    plt.subplot(2, 5, 1+i)\n    plt.imshow(X_train[i], cmap='gray')\nplt.show()","caa23242":"def define_discriminator(input_shape=(28, 28, 1)):\n    \n    model = Sequential([\n        Conv2D(filters=64, kernel_size=(3, 3), input_shape=input_shape, strides=(2, 2), padding=\"same\"),\n        LeakyReLU(alpha=0.2),\n        Dropout(0.4),\n        \n        Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"),\n        LeakyReLU(alpha=0.2),\n        Dropout(0.4),\n        \n        Flatten(),\n        Dense(1, activation=\"sigmoid\")\n    ])\n    \n    optimizer = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    \n    return model # tester avec un autre padding","281520c1":"model = define_discriminator()\nmodel.summary()","1e613bf3":"# plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)","a9eb113a":"def load_real_samples():\n    (X_train, _), (_, _) = load_data() # load images\n    X = np.expand_dims(X_train, axis=-1) # we have 2D images and the convnet expect 3D images -> add channel dimension\n    X = X.astype('float32') # converts unsigned ints into floats\n    X = X \/ 255.0 # scales pixels\n    return X","a5742f64":"def generate_real_samples(dataset, n_samples):\n    idx = randint(0, dataset.shape[0], n_samples) # generate a matrix of random indexes\n    X = dataset[idx] # select the images corresponding to these indexes\n    y = ones((n_samples, 1)) # and label them 1, meaning that they are \"true\" samples\n    return X, y","9374df9c":"def generate_fake_samples(n_samples):\n    X = rand(28 * 28 * n_samples) # uniformly generated random numbers from [0, 1]\n    X = X.reshape((n_samples, 28, 28, 1)) # that we reshape into an 'image-like' shape with channel 1 (grayscale)\n    y = zeros((n_samples, 1)) # and we label them 0, as they are fake images\n    return X, y","701a2041":"def train_discriminator(model, dataset, n_iter=50, n_batch=256):\n    '''\n    Takes as input the discriminator model, the dataset, the number of epochs n_iter and the size of batches n_batch.\n    Uses the train_on_batches function from keras.\n    '''\n    half_batch = int(n_batch \/ 2) # to get the real - and fake - batch sizes\n    \n    for i in range(n_iter): # manually iterating through epochs\n        X_real, y_real = generate_real_samples(dataset, half_batch) # randomly selecting real samples\n        _, real_acc = model.train_on_batch(X_real, y_real) # training the discriminator on real samples\n        X_fake, y_fake = generate_fake_samples(half_batch) # generating fake samples\n        _, fake_acc = model.train_on_batch(X_fake, y_fake) # training the discriminator on fake samples\n        print(f\"Epoch {i+1}: real={real_acc:.2f} fake={fake_acc:.2f}\") # print each epoch's performance summary","c0085891":"# loading training data\ndataset = load_real_samples()\n\n# defining and training the discriminator\nmodel = define_discriminator()\ntrain_discriminator(model, dataset)","c8bdfb47":"def define_generator(latent_dim):\n    '''\n    Defines our image generator model, which takes the dimension of the latent space as input.\n    '''\n    n_nodes = 128 * 7 * 7\n    \n    model = Sequential([\n        Dense(n_nodes, input_dim=latent_dim), # foundation for 7x7 image\n        LeakyReLU(alpha=0.2),\n        Reshape((7, 7, 128)),\n        Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'), # upsample to 14x14\n        LeakyReLU(alpha=0.2),\n        Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'), # upsample to 28x28\n        LeakyReLU(alpha=0.2),\n        Conv2D(1, (7,7), activation='sigmoid', padding='same')\n    ])\n    \n    return model","69fd0040":"# latent space dimension\nlatent_dim = 100\n\n# generator model\nmodel = define_generator(latent_dim)\nmodel.summary()\n\n# plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)","0bcb5800":"def generate_latent_points(latent_dim, n_samples):\n    x_input = randn(latent_dim * n_samples) # generating step\n    x_input = x_input.reshape(n_samples, latent_dim) # reshaping step\n    return x_input","5cf83e87":"def generate_fake_samples(g_model, latent_dim, n_samples):\n    x_input = generate_latent_points(latent_dim, n_samples) # points from the latente space\n    X = g_model.predict(x_input) # use the generator model to generate images\n    y = zeros((n_samples, 1)) # label the generated images\n    return X, y","1b0fb819":"latent_dim = 100\nmodel = define_generator(latent_dim)\nn_samples = 25\nX, _ = generate_fake_samples(model, latent_dim, n_samples)\n\n# plot the generated samples\nfor i in range(n_samples):\n    plt.subplot(5, 5, 1 + i) # define subplot\n    plt.axis('off') # turn off axis labels\n    plt.imshow(X[i, :, :, 0], cmap='gray_r') # plot single image with the reversed grayscale color map\nplt.show()","75df2b07":"def define_gan(g_model, d_model):\n    \n    d_model.trainable = False # we don't update discriminator weights\n    \n    model = Sequential([\n        g_model,\n        d_model\n    ]) # we stack them on another\n\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    \n    return model","136823dd":"latent_dim = 100\n\n# creating the discriminator and the generator\nd_model = define_discriminator()\ng_model = define_generator(latent_dim)\n\n# creating the logical GAN\ngan_model = define_gan(g_model, d_model)\n\ngan_model.summary()\nplot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)","d0754401":"def train_gan(gan_model, latent_dim, n_epochs=100, n_batch=256):\n    for i in range(n_epochs):\n        x_gan = generate_latent_points(latent_dim, n_batch) # points from the latent space\n        y_gan = ones((n_batch, 1)) # change the fake images' labels to 1 \n        gan_model.train_on_batch(x_gan, y_gan) # update the generator's weights using the discriminator's error","c6a3892b":"def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n    bat_per_epo = int(dataset.shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2)\n\n    for i in range(n_epochs):\n        for j in range(bat_per_epo): # iterate over batches\n            \n            # discriminator training data generation & update\n            X_real, y_real = generate_real_samples(dataset, half_batch) # randomly select real images \n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch) # generate fake images\n            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake)) # stacking real and fake images to create the training set\n            d_loss, _ = d_model.train_on_batch(X, y) # discriminator update\n            \n            # generator input generation\n            X_gan = generate_latent_points(latent_dim, n_batch) # sample points from the latent space (generator input)\n            y_gan = ones((n_batch, 1)) # changing labels to 1s\n            g_loss = gan_model.train_on_batch(X_gan, y_gan) # generator update\n\n            print(f'Epoch no. {i+1}: Batch progress {(j+1) \/ bat_per_epo}, discriminator loss: {d_loss:3f} & generator loss: {g_loss:3f}')","ca9d01bd":"def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n    \"\"\"\n    This function takes as input a number of epochs, a generator, a discriminator, a dataset, the dimension\n    of the latent space and a number of samples (batch size), and returns the discriminator performance on\n    real and fake data samples, before saving the generator.\n    \"\"\"\n    \n    # discriminator evaluation on real images\n    X_real, y_real = generate_real_samples(dataset, n_samples)\n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n    \n    # discriminator evaluation on fake images\n    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n\n    print(f'Accuracy on real samples: {acc_real:.3f}, on fake samples: {acc_fake:.3f}')\n    \n    # save the generator in tile file format\n    filename = 'generator_model_%03d.h5' % (epoch + 1)\n    g_model.save(filename)","12276a0b":"# train the generator and discriminator\ndef train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n    \n    bat_per_epo = int(dataset.shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2) # for mixed batches\n\n    for i in range(n_epochs): # iterate over epochs\n        for j in range(bat_per_epo): # iterate over batches within an epoch\n            \n            # generate training data\n            X_real, y_real = generate_real_samples(dataset, half_batch) # real images selected randomly\n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch) # fake images\n            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake)) # stack one on top of the other\n            \n            # discriminator update\n            d_loss, _ = d_model.train_on_batch(X, y)\n            \n            # generator input preparation\n            X_gan = generate_latent_points(latent_dim, n_batch) # sample points in the latent space\n            y_gan = ones((n_batch, 1)) # change fake images' label to 1\n            \n            # generator update using the discriminator loss\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n#         print(f'Epoch no. {i+1}: last d_loss: {d_loss:.3f}, last g_loss: {g_loss:.3f}') # print batch loss\n\n        # evaluate the model performance every 10 epochs\n        if (i+1) % 10 == 0:\n            summarize_performance(i, g_model, d_model, dataset, latent_dim)","2d2d8c38":"# inputs (dimension and images)\nlatent_dim = 100\ndataset = load_real_samples()\n\n# models\nd_model = define_discriminator()\ng_model = define_generator(latent_dim)\ngan_model = define_gan(g_model, d_model)\n\n# training\ntrain(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100)","bfebeffc":"Let's test this. We need a discriminator and the dataset:","ddd4b6c1":"Beware of different results due to the stochastic gradient update: https:\/\/machinelearningmastery.com\/different-results-each-time-in-machine-learning\/","ebedad73":"To objectively score the performance on generated images, we would have to label these images.\n\nThree options exist:\n- evaluate the discriminator on real and fake samples every few epochs\n- generate and save many images to review yourself periodically \n- save the generator every few epochs","cc21b8d6":"## I - B. Loading the data","9e3154ca":"Stochastic gradient descent works by partially updating the gradient computation before each epoch (see below), which is why we need this functions to get random samples. We add the label 1 in the $y$ definition as the images are real.\n\n**Stochastic gradient descent update equation:**\\\nRandomly choose a subsample $n$ row indices, and recursively compute:\n$$w_{k+1} = w_k - \\eta * \\frac{1}{n} \\sum_{j = 1}^{n} \\nabla f_{j}(w_k) $$","6a153435":"# Quick glimpse at the data","1bd6e9f6":"The discriminator quickly learns to discriminate between real and fake images.","9d95d645":"As we don't directly train the generator, we don't specify a loss function nor a solver algorithm nor compile it. We only need to specify the dimension of our latent space to define our generator model.","905140be":"# II - Defining and using the generator model","18219fc9":"Here we define our logical model, with the discriminator weights freezed. The only weights updated when training this model are the generator's weights, in order to make it better at trying to fool the discriminator. Note that in the Keras API, the trainable property is applied after the model is compiled, so training the discriminator alone with the ``train_on_batch`` function will still update the discriminator's weights.","00ba3cef":"# I - Defining and training the discriminator model","699ee6a0":"# III. Training the generator model","bf191aa6":"## I - D. Training the discriminator","3da5118f":"Now here we will train the generator and the discriminator using the previous function to monitor our GAN's performance.\n\nAs our function takes the number of epochs and the batch size as inputs, we compute the number of batches per epochs as the size of the dataset divided by the batch size (rounded down). Again, we iterate manually over epochs.","f4b50164":"Here we load the data using the Keras API (which enables us to directly get the MNIST dataset) and we check the dataset's dimensions.","ec00b19e":"Let's plot a few images from our dataset.","a32a837a":"**Now we define our image generator model.**\n\nOur generator shall perform the inverse operation as performed by a regular CNN classifier, i.e. taking a vector as input from the vector space and transforming it into the 2D-matrix representation of an image (grayscale here). Below is only one of the possible ways of performing this.\n\nWe start by a Dense layer of size ``6272 = 7 * 7 * 128``. First, we have a``7 * 7`` image that is a low-dimensional version of our image, of which we have 128 feature maps (also called activation maps - they are parallel interpretations of the input). We need many feature maps to give our model to create a new image. Here 128 is deemed enough.\n\nWe then reshape these feature maps into something that more closely resembles an image (of size ``(7 * 7 * 128)``, to feed it into a convolutional layer.\n\nNow, to upgrade the resolution of our image we perform an operation called *upsampling*. This is also called deconvolution, but should rather be called Transpose **(??)**. There are 2 ways to upsample an image:\n- we can use an upsampling layer (which works like a reverse pooling layer);\n- or we use a ConvTranspose layer (more modern).\n\nWe pass it the stride argument ``(2, 2)`` so that it quadruples the activation map areas. It is recommended that the kernel size argument be a multiple of the stride, e.g. ``(4, 4)`` to prevent the layer from impressing a checkerboard pattern on the image. See https:\/\/distill.pub\/2016\/deconv-checkerboard\/ for more details. We add two of these layers to our model to get an image of size ``28 * 28``.\n\nThe LeakyReLU (with slope of .2) is usually recommended for training GANs.\n\nOur model's output layer is a 2D convolutional layer, whose arguments are 1 filter, a kernel size of ``7 * 7`` and a padding of ``same``. We pass it to a sigmoid activation function to get an output value within $[0, 1]$.","a439d044":"We start by importing all useful packages.","ca4420ed":"We then check our generator model and plot 25 fake images.","b68cc4a2":"Now we update the fake samples generator from above to allow as inputs the generator model and the latent space dimension. The following function generates fake images with their class label (0) using the generator model with point from the latent space as input.","367ddc28":"## I - A. Discriminator","48cd585b":"Concept of **latent space**:\\\nWe assume that all input images are randomly drawn from a vector space of an abritrary dimension in which points follow a Gaussian distribution. Here we took 100 as dimension of our vector space.","69a9a7fa":"Now we train the discriminator with batches of 256 images, half of which are real and the other half fake.","47b2c0ac":"The following function generates vectors from the latent space, and then reshapes them into a format closer to that of a batch of samples.","16d86c7d":"Let's now train our GAN model. As done previously, we will iterate through epochs in a manual way and label all images (incl. fake samples) as true. This function only serves as an example, as in reality we shall first use both real and fake images to train the dscriminator and then update the generator using the logical GAN.","31d1dfc5":"To perform the latter task, we will need to combine steps from our ``train_gan`` and from our ``train_discriminator`` functions.\n\nAs usual, an epoch include as many batches as the training dataset divided by the batch size.\n\n**Discriminator update:** using a batch made of both real and fake images stacked (using the ``vstack`` function), the discriminator is updated once per batch. Alternatively, it could be updated separately for each real and fake half o the batch but it would be slower here - albeit recommended when working with bigger datasets.\n\nThe loss is printed at the end of each epoch to keep an eye on the generator's performance.","099187cc":"This notebook uses the code from https:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras\/ and reformulates the comments to make sure I understand the concepts. I made it public in case it might be useful to anybody, but all credit goes to Jason Brownlee and his amazing blog.","d2285c20":"Once we've loaded the data using ``load_real_samples``, we need a function to randomly select samples to implement our SGD optimizer: we therefore define ``generate_real_samples``.","e6f9a150":"## I - C. Generating real and fake samples","24fa98ad":"We don't yet have a generator model, so we randomly generate false images. Their dimensions have to be the same as the real input images ``(28, 28, 1)``, which is why we generate ``n_samples`` vectors of size ``(28 * 28)`` (after reshaping). That's why we write this ``generate_fake_samples`` function.","c3140a38":"# IV. Evaluating our GAN's performance ","7ac24721":"We need a function that loads the data and takes care of the preprocessing: ``lead_real_samples`` will do the job. We have to expand the dimension (by adding a channel dimension, convert the pixel number into a suitable datatype and scale out data).","ed0fc7ad":"**Adversarial relationship:** in a GAN, the generator's weights are updated depending on the performance of the disciminator model. The better the discriminator, the bigger the generator weights' update. To implement that, we will define a logical model to stack the generator on top of the discriminator (there are other ways of doing this with the Keras API).","4589f38d":"# Loading libraries","ab83e80b":"The discriminator can be trained on both real and fake data, while the generator only uses the discriminator's performance on fake data. Thus, the discriminator can be trained alone and its layers are not trainable when part of the logical GAN model.","aacaf146":"Let's have a look at this stacked model.","b45853bd":"We will now test our model. Therefore we need:\n- the dimension of our latente space\n- our discriminator\n- our generator\n- our logical GAN model\n- image samples\n\nAnd we're ready to train!"}}