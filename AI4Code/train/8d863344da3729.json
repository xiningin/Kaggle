{"cell_type":{"3416cdd5":"code","74828e65":"code","10a0429f":"code","dddffad6":"code","792a2778":"code","93cb76b8":"code","5da3ba65":"code","59605f8a":"code","c7eb5dde":"code","23556d57":"code","71cd30f6":"code","4786122a":"code","5cf8b8cb":"code","857b4fa4":"code","883da228":"code","48253edd":"code","da893ccc":"code","54a52eca":"code","833dbf10":"code","b9315417":"code","5d282cfa":"markdown","b7cc2ea2":"markdown","42c7d1fa":"markdown","6ee58fe7":"markdown","090dfc71":"markdown","b0962c45":"markdown","9dbfc0a0":"markdown","c5c02412":"markdown","e2676144":"markdown","b6298c7f":"markdown","5397ffd7":"markdown","916cddf4":"markdown"},"source":{"3416cdd5":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport skimage.io\nimport matplotlib.pyplot as plt\nimport sys, os, random, glob, cv2, math\n\nDATA_DIR = Path('\/kaggle\/input')\nROOT_DIR = Path('\/kaggle\/working')","74828e65":"!pip install tensorflow==1.14","10a0429f":"import tensorflow as tf","dddffad6":"tf.__version__","792a2778":"!pip install keras==2.1.5","93cb76b8":"!pip install pycocotools","5da3ba65":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n\n!rm -rf .git # to prevent an error when the kernel is committed\n!rm -rf images assets # to prevent displaying images at the bottom of a kernel\n","59605f8a":"from mrcnn import utils\nfrom mrcnn.model import log\nfrom mrcnn import visualize\nimport mrcnn.model as modellib\nfrom mrcnn.config import Config","c7eb5dde":"!wget https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n    \nCOCO_MODEL_PATH = 'mask_rcnn_coco.h5'","23556d57":"sys.path.append(os.path.join(ROOT_DIR, \"Mask_RCNN\/samples\/coco\/\"))  # To find local version\nimport coco\n\nclass InferenceConfig(coco.CocoConfig):\n    # Set batch size to 1 since we'll be running inference on\n    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1   \nconfig = InferenceConfig()\nconfig.display()","71cd30f6":"#-------------- Create model object in inference mode------------------------\nprint(\"loading mask R-CNN model\")\nmodel = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=ROOT_DIR)\n#-------------- Load weights trained on MS-COCO -------------------------------\nmodel.load_weights(COCO_MODEL_PATH, by_name=True)","4786122a":"class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n               'bus', 'train', 'truck', 'boat', 'traffic light',\n               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n               'teddy bear', 'hair drier', 'toothbrush']","5cf8b8cb":"os.chdir('..\/')\n\nsample_image = \"11.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","857b4fa4":"sample_image = \"2.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","883da228":"sample_image = \"3.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","48253edd":"sample_image = \"22.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","da893ccc":"sample_image = \"4.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","54a52eca":"sample_image = \"2516944023_d00345997d_z.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","833dbf10":"sample_image = \"3878153025_8fde829928_z.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","b9315417":"sample_image = \"12283150_12d37e6389_z.jpg\"\nimage = skimage.io.imread(os.path.join(\"..\/input\/data-images\/\", sample_image))\nresults = model.detect([image], verbose=1)\n\n# Visualize results\nr = results[0]\nprint( class_names[r['class_ids'][0]])\n\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","5d282cfa":"## 2-Installing","b7cc2ea2":"### 2.1-Install the previous version of TensorFlow(1.14)","42c7d1fa":"## 7-Detect Objects and Visualize the Results","6ee58fe7":"### 2.2 Install Keras version (2.1.5)","090dfc71":"## 8-References\n\n1. https:\/\/blog.paperspace.com\/mask-r-cnn-in-tensorflow-2-0\/\n2. https:\/\/cocodataset.org\/\n3. https:\/\/github.com\/kimiyoung\/review_net\/tree\/master\/image_caption_offline\/eval\/neuraltalk2\/coco-caption\n4. https:\/\/github.com\/matterport\/Mask_RCNN","b0962c45":"## 5-Import COCO config","9dbfc0a0":"## 4-Download the Model Weights","c5c02412":"### 2.3 Install pycocotools","e2676144":"## 3-Download the Model Mask_RCNN","b6298c7f":"## 1-Import Libraries","5397ffd7":"# Mask R-CNN \n* Mask R-CNN is an object detection model based on convolutional neural networks (CNN) developed by  Facebook AI researchers in 2017. The model could return both the bounding box and a mask for the detected object in an image.\n\n* Officially, Google released TensorFlow 2.0 in September 2020. TensorFlow 2.0 is better organized and much easier to learn compared to the old versions of TensorFlow( \u22651.0). \nUnfortunately, the Mask_RCNN project does not yet support TensorFlow 2.0. So This kernel uses TensorFlow 1.14.\n\n* We build a kernel that uses a pre-trained Mask R-CNN to detect the objects in an image from the COCO dataset.This dataset has 80 classes. \n\n* Microsoft COCO is a large image dataset designed for object detection, segmentation, and caption generation.Pycocotools is a Python API that assists in loading, parsing, and visualizing the annotations in COCO.\n","916cddf4":"## 6-Build the Mask R-CNN Model Architecture"}}