{"cell_type":{"d728754a":"code","bb98d7a6":"code","805fcb48":"code","15caa856":"code","f0a2624a":"code","d11fe3b2":"code","bbe8e531":"markdown","bc4ca86c":"markdown","bbcaad99":"markdown","9a30ab71":"markdown","03b27447":"markdown","faabf8e0":"markdown"},"source":{"d728754a":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.datasets import load_boston\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import make_scorer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV","bb98d7a6":"data = load_boston()\nnames = data.feature_names\npredictors = data.data\ntargets = data.target\ndf = pd.concat([pd.DataFrame(predictors, columns=names), pd.DataFrame(targets, columns=['MEDV'])], axis=1)\ncols_corr_manual = ['NOX', 'RAD']\ndf = df.drop(columns=cols_corr_manual)\nX = df.iloc[:, 0:-1]\ny = df.iloc[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n","805fcb48":"svm_reg = Pipeline([('scaler', StandardScaler()), ('svr', SVR(kernel='linear',C=1))])\nsvm_reg.fit(X_train, y_train)\npred = svm_reg.predict(X_test)\n# Mean squared error\nprint('MSE:', mean_squared_error(y_test, pred))\n# Mean absolute error\nprint('MAE:', mean_absolute_error(y_test, pred))\n# Coefficient of determination\nprint('R2:', svm_reg.score(X_test,y_test))","15caa856":"svm_reg = Pipeline([('scaler', StandardScaler()), ('svr', SVR(kernel='linear',C=10))])\nsvm_reg.fit(X_train, y_train)\npred = svm_reg.predict(X_test)\n# Mean squared error\nprint('MSE:', mean_squared_error(y_test, pred))\n# Mean absolute error\nprint('MAE:', mean_absolute_error(y_test, pred))\n# Coefficient of determination\nprint('R2:', svm_reg.score(X_test,y_test))","f0a2624a":"C_range = [1, 2, 4, 10]\ngamma_range = np.logspace(-2, 2, 5)\nparameters = {'kernel':('linear', 'rbf'),'gamma':gamma_range,'C':C_range}\nsvr = SVR()\ngrid = GridSearchCV(svr, parameters)\ngrid.fit(X_train, y_train)\nclassifier = grid.best_estimator_\nprint(classifier)\n","d11fe3b2":"def fit_model (x,v):\n    X_train, X_test, y_train, y_test = train_test_split(x, v, test_size=0.2, random_state=7)\n    parameters = {'kernel':('linear', 'rbf'),'gamma':(np.logspace(-2, 2, 5)),'C':[1, 10]}\n    svr = SVR()\n    grid = GridSearchCV(svr, parameters)\n    grid.fit(X_train, y_train)\n    rand = RandomizedSearchCV(svr, parameters)\n    rand.fit(X_train, y_train)\n    if grid.score(X_test,y_test) > rand.score(X_test,y_test):\n        return grid.best_estimator_\n    else:\n        return rand.best_estimator_\n    \nfinal = fit_model(X,y)\nprint(final.get_params())\n\n\n# Mean squared error\nprint('MSE:', mean_squared_error(y_test, pred))\n# Mean absolute error\nprint('MAE:', mean_absolute_error(y_test, pred))\n# Coefficient of determination\nprint('R2:', final.score(X_test,y_test))","bbe8e531":"### Wyszukiwanie najlepszych parametr\u00f3w pomi\u0119dzy GridSearchCV oraz RandomizedSearchCV","bc4ca86c":"### Wyszukanie najlepszych parametr\u00f3w przez GridSearchCV","bbcaad99":"### Wczytanie bibliotek","9a30ab71":"### Regresja wektora wsparcia dla j\u0105dra liniowego o warto\u015bci parametru C=10","03b27447":"### Regresja wektora wsparcia dla j\u0105dra liniowego o warto\u015bci parametru C=1","faabf8e0":"### Podzia\u0142 danych"}}