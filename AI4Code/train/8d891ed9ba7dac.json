{"cell_type":{"cdfd4531":"code","4926d0b9":"code","63e639e9":"code","cea5acec":"code","11f457e2":"code","30731e4e":"markdown","9df0a01d":"markdown"},"source":{"cdfd4531":"import rsa\nimport time\nimport hashlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom functools import partial","4926d0b9":"O_pub, O_pri = rsa.newkeys(512)\n\nuniqid = \"edfdabd4-7c42-4559-9335-36f282c2899f\"\n\nv = uniqid + \"_\" + str(int(time.time()))\n\nprint(f\"v={v}\")\n\nsig = rsa.sign(v.encode('UTF-8'), O_pri, 'SHA-256')\n#rsa.verify(v.encode('UTF-8'), sig, O_pub)\n\ndef h1(msg):\n    hexa = hashlib.sha224(msg).hexdigest()\n    return int(hexa, base=16)\ndef h2(msg):\n    hexa = hashlib.sha256(msg).hexdigest()\n    return int(hexa, base=16)\ndef h3(msg):\n    hexa = hashlib.sha384(msg).hexdigest()\n    return int(hexa, base=16)\ndef h4(msg):\n    hexa = hashlib.sha512(msg).hexdigest()\n    return int(hexa, base=16)\n\n# H = Height of input images\n# W = Width of input images\n# Y = number of classes\n# embedding pattern will have size (n, n)\ndef transform(sig, H, W, Y, n):\n    p = np.ones((H, W)) * 0.5\n    y_w = h1(sig) % Y\n    bits = '{0:b}'.format(h2(sig) % (2**(n**2))) \n    # left pad with zeros\n    bits = (max((n**2 - len(bits)), 0) * '0') + bits\n    pos = (h3(sig) % (H - n), h4(sig) % (W - n))\n    for y_cur in range(n):\n        for x_cur in range(n):\n            p[y_cur + pos[0], x_cur + pos[1]] = bits[y_cur * n + x_cur]\n    lmbda = 2000\n    return p, y_w, lmbda","63e639e9":"def null_embed(p, lmbda, example, label):\n    for i in range(example.shape[2]):\n        p = np.expand_dims(p, axis=-1)\n    lmbda = tf.ones(p.shape) * lmbda\n    example = tf.where(p == 0, -lmbda, example)\n    example = tf.where(p == 1, lmbda, example)\n    return example, label\n\ndef true_embed(p, lmbda, y_w, example, label):\n    for i in range(example.shape[2]):\n        p = np.expand_dims(p, axis=-1)\n    lmbda = tf.ones(p.shape) * lmbda\n    example = tf.where(p == 0, lmbda, example)\n    example = tf.where(p == 1, -lmbda, example)\n    return example, tf.cast(y_w, tf.int64)\n\ndef cast_to_float(example, label):\n    return tf.cast(example, tf.float32) \/ 255.0, label\n    ","cea5acec":"class CustomModel(keras.Model):\n    def __init__(self, optimizer):\n        super().__init__()\n        # for some reason using self.optimizer from model.compile() doesn't work.\n        self.opt = optimizer\n        # ReLU activation function leads to dying ReLU problem,\n        # in the paper it didn't, wich is weird. Had to swap to LeakyReLU here.\n        self.seq = keras.Sequential([\n                          keras.layers.Conv2D(32, kernel_size=(3, 3)),\n                          keras.layers.LeakyReLU(alpha=0.3),\n                          keras.layers.Conv2D(64, kernel_size=(3, 3), strides=2),\n                          keras.layers.LeakyReLU(alpha=0.3),\n                          keras.layers.Conv2D(128, kernel_size=(3, 3), strides=2),\n                          keras.layers.LeakyReLU(alpha=0.3),\n                          keras.layers.Conv2D(1, kernel_size=(1, 1)),\n                          keras.layers.LeakyReLU(alpha=0.3),\n                          keras.layers.Flatten(),\n                          keras.layers.Dense(10, activation=\"softmax\")\n                         ])\n    @tf.function\n    def call(self, x):\n        return self.seq(x)\n        \n    @tf.function\n    def train_step(self, data):\n        train, null_e, true_e = data\n        x_train, y_train = train\n        x_null_e, y_null_e = null_e\n        x_true_e, y_true_e = true_e\n        with tf.GradientTape(persistent=True) as train_tape:\n            train_pred = self(x_train, training=True)            \n            train_loss = self.loss(y_train, train_pred)\n            null_e_pred = self(x_null_e, training=True)\n            null_e_loss = self.loss(y_null_e, null_e_pred)\n            true_e_pred = self(x_true_e, training=True)\n            true_e_loss = self.loss(y_true_e, true_e_pred)\n                \n        train_grads = train_tape.gradient(train_loss, self.trainable_variables)\n        null_e_grads = train_tape.gradient(null_e_loss, self.trainable_variables)\n        true_e_grads = train_tape.gradient(true_e_loss, self.trainable_variables)\n        \n        \n        combined_grads = []\n        for train_grad, null_e_grad, true_e_grad in zip(train_grads, null_e_grads, true_e_grads):\n            combined_grad = 0.5 * train_grad + 0.25 * null_e_grad +  0.25 * true_e_grad\n            combined_grads.append(combined_grad)\n        \n            \n        self.opt.apply_gradients(zip(combined_grads, self.trainable_variables))\n        \n        \n        return {\n            \"train_loss\": train_loss, \n            \"null_embedding_loss\": null_e_loss, \n            \"true_embedding_loss\": true_e_loss,\n            \"total_loss\": train_loss + null_e_loss + true_e_loss\n        }\n","11f457e2":"p, y_w, lmbda = transform(sig, 28, 28, 10, 6)\n\nds_train = tfds.load(\"mnist\", split=\"train\", as_supervised=True)\nds_test = tfds.load(\"mnist\", split=\"test\", as_supervised=True)\n\nds_train = ds_train.map(cast_to_float)\nds_test = ds_test.map(cast_to_float)\n\nds_train_null = ds_train.map(partial(null_embed, p, lmbda))\nds_train_embed = ds_train.map(partial(true_embed, p, lmbda, y_w))\n\n# plot an example image\nfor x_batch, y_batch in ds_train_null.take(1):\n    example = x_batch.numpy().reshape((28, 28)).clip(0, 1)\n    plt.imshow(example)\n    plt.show()\n    \n# plot an example image\nfor x_batch, y_batch in ds_train_embed.take(1):\n    example = x_batch.numpy().reshape((28, 28)).clip(0, 1)\n    plt.imshow(example)\n    plt.show()\n\nds_train = tf.data.Dataset.zip((ds_train, ds_train_null, ds_train_embed))\n\n# Without momentum it converges at around 20% acc, with momentum it converges at about 89% acc\noptim = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n# optim = tf.keras.optimizers.SGD(learning_rate=0.001)\n\nds_train = ds_train.shuffle(70000).prefetch(-1).batch(128)\nds_test = ds_test.batch(128)\nmodel = CustomModel(optim)\nmodel.build(input_shape=(None, 28, 28, 1))\nmodel.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[\"sparse_categorical_accuracy\"])\nmodel.fit(epochs=20, x=ds_train, validation_data=ds_test)","30731e4e":"Np (number of black\/white points in filter) can be up to 10% of the total input size without causing noticeable impact on normal classification accuracy. For example, NP = 6\u00d76 on 28\u00d728 images results in only 0.1%-1.5% accuracy loss.\n![image.png](attachment:image.png)\n(2) ist the formula for null and (3) is the formula for true embedding. The class of true embedding is our predefined class yw, which will be our trigger.\nGenerate extra training data related to null and true embedding and train an untrained model on the training data union of training data and null and true embedding data.","9df0a01d":"ACC AFTER 20 EPOCHS WITH TRUE AND NULL EMBEDDING\n\n0.9074\n\nACC AFTER 20 EPOCHS WITHOUT TRUE AND NULL EMBEDDING\n\n0.9150"}}