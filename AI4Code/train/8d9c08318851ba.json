{"cell_type":{"aeb976c4":"code","97a3f196":"code","4f26caa3":"code","af193af3":"code","1e07ff4e":"code","0b9cf829":"code","86f99d75":"code","8f602b12":"code","8044326c":"code","994c90ce":"code","4caecb0f":"code","f758d65e":"code","940c648e":"code","07bc0015":"code","d73552ca":"code","a7888315":"code","3d90975e":"code","b403c71d":"code","e7a4cefd":"code","4435fd56":"code","6a1eba69":"code","a2abae91":"code","4ddd7e70":"code","08325fb7":"code","3c5e11b2":"code","38976d87":"code","3cd773ce":"code","19bdb0c5":"code","9b2f22ea":"code","d5a0228d":"code","8c72f962":"code","312efcfe":"code","9cbd5608":"code","032ed825":"code","7b04b212":"code","974bea3b":"code","22bd2bed":"code","cd637bd4":"code","6d7eb187":"code","8d64412f":"code","9f6010f0":"code","20f6c256":"code","f86b655a":"code","0f0454a5":"code","5ede68d6":"code","64f77335":"code","59a61103":"code","83618241":"code","2594d10b":"code","32091424":"code","d3f25519":"code","19fe8a18":"code","79b2168a":"code","eee8702b":"code","c6f46016":"code","93f6e9ab":"code","1a9e8961":"code","f9ed5c64":"code","28a8c95e":"code","941f47bd":"code","163250fa":"code","ce3fa8d4":"code","0ce21575":"code","d1ced0b6":"code","eaf8a785":"code","1d2dcb3e":"code","ea29add7":"code","0114f100":"code","3353577b":"code","7e96be05":"code","7d582e6d":"code","65b3f47f":"code","85a6a984":"code","18d686c9":"code","510f78e3":"code","ee4c9125":"code","043929cd":"code","219f6353":"code","455ea3b2":"code","2ffd2518":"code","9e8a2787":"code","f0892650":"code","f7ecc022":"code","41c989b1":"code","7e386921":"code","28a76424":"code","6752fb8f":"code","bdf9cf98":"code","58e16632":"code","a28a7b7e":"code","bb35b6ff":"code","24a03eb0":"code","895c13b1":"code","f5efea58":"code","aeabc88c":"code","4f49d702":"code","801e3566":"code","fe21868e":"code","804a6bd2":"code","56772086":"code","11391d65":"markdown","bf13bbf5":"markdown","99dd5cb6":"markdown","2c03d3b7":"markdown","a2ba68f7":"markdown","ae3943d2":"markdown","eb565f01":"markdown","feff0a9e":"markdown","e0350b04":"markdown","1643911c":"markdown","127aa459":"markdown","560e3969":"markdown","0a97fdfb":"markdown","e7137dad":"markdown","a6b4665f":"markdown","4e3b8945":"markdown","6694e852":"markdown","4da2ee90":"markdown","e092809d":"markdown","882e5dd3":"markdown","2966f9a0":"markdown","7d191183":"markdown","b894b71d":"markdown","178b51f7":"markdown","112096b2":"markdown","2066da37":"markdown","aadb268b":"markdown","cd84daf1":"markdown","8f335e2b":"markdown","7c72f66f":"markdown","b3f57308":"markdown","4e35678b":"markdown","b8549d05":"markdown","377aefbf":"markdown","18d8259b":"markdown","cba77525":"markdown","d00a82a9":"markdown","29528ee2":"markdown","32d190bc":"markdown","bab1b7e7":"markdown","eb2801fa":"markdown","1d91e7c1":"markdown","ba75075a":"markdown","f203a43c":"markdown","df8b47f3":"markdown","da5b80d2":"markdown"},"source":{"aeb976c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","97a3f196":"df = pd.read_csv('\/kaggle\/input\/twitter-airline-sentiment\/Tweets.csv')\ndf.head()","4f26caa3":"# Nans percentage \n(len(df)-df.count())\/len(df)\n","af193af3":"del df['airline_sentiment_gold']\ndel df['negativereason_gold']\ndel df['tweet_coord']","1e07ff4e":"df.head()","0b9cf829":"mood_count=df['airline_sentiment'].value_counts()\nplt.figure(figsize=(10,5))\nsns.barplot(mood_count.index, mood_count.values, alpha=0.8)\nplt.title('Count of Moods')\nplt.ylabel('Mood Count', fontsize=12)\nplt.xlabel('Mood', fontsize=12)\nplt.show()\n","86f99d75":"for j in (mood_count.values):\n    print(j\/len(df)*100)","8f602b12":"neg_reasons = df['negativereason'][df['airline_sentiment']=='negative'].value_counts()\nneg_reasons","8044326c":"plt.figure(figsize=(25,5))\nsns.barplot(neg_reasons.index, neg_reasons.values, alpha=0.8)\nplt.title('Negative responses reasons')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Reason', fontsize=12)\nplt.show()\n","994c90ce":"df['user_timezone'].unique()","4caecb0f":"neg_timezone_count=df['user_timezone'][df['airline_sentiment']=='negative'].value_counts()[:10]\nneg_timezone_count","f758d65e":"neg_timezone_df = pd.DataFrame({'timezone':neg_timezone_count.index,'negative_count':neg_timezone_count.values})\nneg_timezone_df.head(10)","940c648e":"for zone in neg_timezone_df['timezone']:\n    if zone in ['Eastern Time (US & Canada)','Central Time (US & Canada)','Pacific Time (US & Canada)']:\n        neg_timezone_df['timezone'][neg_timezone_df['timezone']==zone] = 'USA'\n    if zone in ['Atlantic Time (Canada)','Mountain Time (US & Canada)']:\n        neg_timezone_df['timezone'][neg_timezone_df['timezone']==zone] = 'Canada'\nneg_timezone_df.head(10)","07bc0015":"neg_timezone_df = neg_timezone_df.groupby('timezone',as_index=True,sort=False).sum()","d73552ca":"neg_timezone_df = neg_timezone_df.head(10)\nlatitude = ['37.0902','0.1807','56.1304','34.0489','51.5074','64.2008','19.8968']\nlongtuide = ['-95.7129','-78.4678','-106.3468','-111.0937','0.1278','-149.4937','-155.5828']\nneg_timezone_df['latitude'] = latitude\nneg_timezone_df['longtuide'] = longtuide","a7888315":"neg_timezone_df.head()","3d90975e":"neg_timezone_df['color']=neg_timezone_df['negative_count'].apply(lambda negative_count:\"Black\" if negative_count>=400 else\n                                         \"green\" if negative_count>=300 and negative_count<400 else\n                                         \"Orange\" if negative_count>=200 and negative_count<300 else\n                                         \"darkblue\" if negative_count>=150 and negative_count<200 else\n                                         \"red\" if negative_count>=100 and negative_count<150 else\n                                         \"lightblue\" if negative_count>=75 and negative_count<100 else\n                                         \"brown\" if negative_count>=50 and negative_count<75 else\n                                         \"grey\")\nneg_timezone_df['size']=neg_timezone_df['negative_count'].apply(lambda negative_count:20 if negative_count>=400 else\n                                         15 if negative_count>=300 and negative_count<400 else\n                                         12 if negative_count>=200 and negative_count<300 else\n                                         11 if negative_count>=150 and negative_count<200 else\n                                         10 if negative_count>=100 and negative_count<150 else\n                                         7 if negative_count>=75 and negative_count<100 else\n                                         5 if negative_count>=50 and negative_count<75 else\n                                         3)\n\nneg_timezone_df","b403c71d":"neg_timezone_df['timezone'] = neg_timezone_df.index","e7a4cefd":"import folium\nm=folium.Map([56.1304,106.3468],zoom_start=1)\n#location=location[0:2000]\nfor lat,lon,area,color,count,size in zip(neg_timezone_df['latitude'],neg_timezone_df['longtuide'],neg_timezone_df['timezone'],neg_timezone_df['color'],neg_timezone_df['negative_count'],neg_timezone_df['size']):\n     folium.CircleMarker([lat, lon],\n                            popup=area,\n                            radius=size,\n                            color='b',\n                            fill=True,\n                            fill_opacity=0.7,\n                            fill_color=color,\n                           ).add_to(m)\nm\n","4435fd56":"df.head()","6a1eba69":"sns.set(rc={'figure.figsize':(10,20)})\nsns.catplot(x='airline_sentiment',kind='count',data=df,orient=\"h\",hue='airline')\n","a2abae91":"df['text_length'] =  list(map(lambda x:len(x),df['text']))","4ddd7e70":"target_0 = df.loc[df['airline_sentiment'] == 'neutral']\ntarget_1 = df.loc[df['airline_sentiment'] == 'positive']\ntarget_2 = df.loc[df['airline_sentiment'] == 'negative']\n\nsns.distplot(target_0[['text_length']], hist=False, rug=False,color='red',label='Neutral')\nsns.distplot(target_1[['text_length']], hist=False, rug=True,color = 'yellow',label='positive')\nsns.distplot(target_2[['text_length']], hist=False, rug=True,color='black',label='negative')\n\nplt.show()\n","08325fb7":"df['text'].head(20)","3c5e11b2":"# Some initial features in text\nqmarks = np.mean(df['text'].apply(lambda x: '?' in x))\nexclamation = np.mean(df['text'].apply(lambda x: '!' in x))\nat = np.mean(df['text'].apply(lambda x: '@' in x))\nfullstop = np.mean(df['text'].apply(lambda x: '.' in x))\ncapital_first = np.mean(df['text'].apply(lambda x: x[0].isupper()))\ncapitals = np.mean(df['text'].apply(lambda x: max([y.isupper() for y in x])))\nnumbers = np.mean(df['text'].apply(lambda x: max([y.isdigit() for y in x])))\nhashtags = np.mean(df['text'].apply(lambda x: '#' in x))\n\nprint('Tweets with question marks: {:.2f}%'.format(qmarks * 100))\nprint('Tweets with question hashtags: {:.2f}%'.format(hashtags * 100))\nprint('Tweets with exclamation marks: {:.2f}%'.format(exclamation * 100))\nprint('Tweets with full stops: {:.2f}%'.format(fullstop * 100))\nprint('Tweets with capitalised first letters: {:.2f}%'.format(capital_first * 100))\nprint('Tweets with capital letters: {:.2f}%'.format(capitals * 100))\nprint('Tweets with @: {:.2f}%'.format(at * 100))\nprint('Tweets with numbers: {:.2f}%'.format(numbers * 100))\n","38976d87":"df['has_question'] = df['text'].apply(lambda x: '?' in x)\ndf_has_question = df[df['has_question']]","3cd773ce":"df_has_question.head()","19bdb0c5":"df_has_question.airline_sentiment.value_counts()","9b2f22ea":"for j in (df_has_question.airline_sentiment.value_counts().values):\n    print(j\/len(df_has_question)*100)","d5a0228d":"sns.catplot(x='airline_sentiment',kind='count',data=df_has_question,orient=\"h\",hue='airline_sentiment')\n","8c72f962":"df_hasquestion = df[['has_question','airline_sentiment']]","312efcfe":"df_hasquestion.head()","9cbd5608":"df_hasquestion['has_question'] = [1 if df_hasquestion['has_question'][x] == True else 0 for x in range(len(df_hasquestion['has_question']))]","032ed825":"df_hasquestion['airline_sentiment'] = [1 if df_hasquestion['airline_sentiment'][x] == 'positive' else 0 for x in range(len(df_hasquestion['airline_sentiment']))]","7b04b212":"from collections import Counter\nCounter(df_hasquestion['airline_sentiment'])","974bea3b":"def chi2_by_hand(df, col1, col2):    \n    #---create the contingency table---\n    df_cont = pd.crosstab(index = df[col1], columns = df[col2])\n    display(df_cont)\n    #---calculate degree of freedom---\n    degree_f = (df_cont.shape[0]-1) * (df_cont.shape[1]-1)\n    #---sum up the totals for row and columns---\n    df_cont.loc[:,'Total']= df_cont.sum(axis=1)\n    df_cont.loc['Total']= df_cont.sum()\n    print('---Observed (O)---')\n    display(df_cont)\n    #---create the expected value dataframe---\n    df_exp = df_cont.copy()    \n    df_exp.iloc[:,:] = np.multiply.outer(\n        df_cont.sum(1).values,df_cont.sum().values) \/ df_cont.sum().sum()            \n    print('---Expected (E)---')\n    display(df_exp)\n        \n    # calculate chi-square values\n    df_chi2 = ((df_cont - df_exp)**2) \/ df_exp    \n    df_chi2.loc[:,'Total']= df_chi2.sum(axis=1)\n    df_chi2.loc['Total']= df_chi2.sum()\n    \n    print('---Chi-Square---')\n    display(df_chi2)\n    #---get chi-square score---   \n    chi_square_score = df_chi2.iloc[:-1,:-1].sum().sum()\n    \n    return chi_square_score, degree_f","22bd2bed":"chi_score, degree_f = chi2_by_hand(df_hasquestion,'has_question','airline_sentiment')\nprint(f'Chi2_score: {chi_score}, Degrees of freedom: {degree_f}')\n","cd637bd4":"from wordcloud import WordCloud,STOPWORDS\ndf_x=df[df['airline_sentiment']=='negative']\nwords = ' '.join(df_x['text'].values)\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\n\nplt.figure(1,figsize=(12, 20))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","6d7eb187":"def get_weight(count, eps=10000, min_count=2):\n    if count < min_count:\n        return 0\n    else:\n        return 1 \/ (count + eps)\n","8d64412f":"import re\nimport nltk\nfrom nltk.corpus import stopwords\n\ndef tweet_to_words(raw_tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) \n","9f6010f0":"df['clean_text']=df['text'].apply(lambda x: tweet_to_words(x))\n","20f6c256":"df.clean_text[:5]\n","f86b655a":"from collections import Counter\nwords = (\" \".join(df.clean_text)).lower().split()\ncounts = Counter(words)\nweights = {word: get_weight(count) for word, count in counts.items()}\n","0f0454a5":"print('Most common words and weights: \\n')\nprint(sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\nprint('\\nLeast common words and weights: ')\n(sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])\n","5ede68d6":"df['sentiment']=df['airline_sentiment'].apply(lambda x: 0 if x=='negative' else 1)\n","64f77335":"corr=df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values, annot=True)\n","59a61103":"df.head()","83618241":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(df,test_size=0.2,random_state=42)\n\n","2594d10b":"train.sentiment.value_counts()","32091424":"pos_train = train[train['sentiment']==1]\nneg_train = train[train['sentiment']==0]","d3f25519":"print(len(pos_train))\nprint(len(neg_train))","19fe8a18":"x_train = train['clean_text']\ny_train = train['sentiment']\nx_test = test['clean_text']\ny_test = test['sentiment']","79b2168a":"train_clean_tweet=[]\nfor tweet in x_train:\n    train_clean_tweet.append(tweet)\ntest_clean_tweet=[]\nfor tweet in x_test:\n    test_clean_tweet.append(tweet)\ny = y_train","eee8702b":"from sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(train_clean_tweet)\ntest_features=v.transform(test_clean_tweet)\n","c6f46016":"import sys\nimport numpy\nnumpy.set_printoptions(threshold=sys.maxsize)\n# see the vector of the second word for example\n# print(train_features.toarray()[1:3\n#                               ])\n# train_features[2].toarray()","93f6e9ab":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\nClassifiers = [\n    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\n]\n","1a9e8961":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\ndense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\npercisions = []\nrecalls = []\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['sentiment'])\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,train['sentiment'])\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,test['sentiment'])\n    percision = precision_score(test['sentiment'], pred, average='macro')\n    recall = recall_score(test['sentiment'], pred, average='macro')\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    percisions.append(percision)\n    recalls.append(recall)\n    print('percision of '+classifier.__class__.__name__+'is '+str(percision))    \n    print('recall of '+classifier.__class__.__name__+'is '+str(recall))    \n","f9ed5c64":"from nltk.stem import WordNetLemmatizer\nlemm = WordNetLemmatizer()\nclass LemmaCountVectorizer(CountVectorizer):\n    def build_analyzer(self):\n        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))\n","28a8c95e":"from sklearn.metrics import average_precision_score\nfrom sklearn.metrics import classification_report\ntf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n                                     min_df=2,\n                                     stop_words='english',\n                                     decode_error='ignore')\ntrain_features= tf_vectorizer.fit_transform(x_train)\ntest_features=tf_vectorizer.transform(x_test)\ndense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\npercisions = []\nrecalls = []\n\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,y_train)\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,y_train)\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,y_test)\n    average_precision = average_precision_score(pred, y_test)\n    class_rep = classification_report(pred,y_test)\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    percisions.append(percision)\n    recalls.append(recall)\n\n#     print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n    print(f'Average precision-recall score {average_precision} model {classifier.__class__.__name__}'  )\n    print('classification report: '+str(class_rep))\n    print('percision of '+classifier.__class__.__name__+'is '+str(percision))    \n    print('recall of '+classifier.__class__.__name__+'is '+str(recall))    \n\n\n","941f47bd":"from sklearn.feature_extraction.text import TfidfVectorizer\n","163250fa":"tfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\ntrain_features= tfv.fit_transform(x_train)\ntest_features=tfv.transform(x_test)\ndense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,y_train)\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,y_train)\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,y_test)\n    average_precision = average_precision_score(pred, y_test)\n    class_rep = classification_report(pred,y_test)\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print(f'Average precision-recall score {average_precision} model {classifier.__class__.__name__}'  )\n    print('classification report: '+str(class_rep))\n    print('percision of '+classifier.__class__.__name__+'is '+str(percision))    \n    print('recall of '+classifier.__class__.__name__+'is '+str(recall))    \n\n","ce3fa8d4":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\nsvd = TruncatedSVD(n_components=120)\nsvd.fit(train_features)\nxtrain_svd = svd.transform(train_features)\nxvalid_svd = svd.transform(test_features)\n\n# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\nscl = StandardScaler()\nscl.fit(xtrain_svd)\nxtrain_svd_scl = scl.transform(xtrain_svd)\nxvalid_svd_scl = scl.transform(xvalid_svd)\n","0ce21575":"\ndense_features=xtrain_svd_scl\ndense_test= xvalid_svd_scl\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(xtrain_svd_scl,train['sentiment'])\n        pred = fit.predict(xvalid_svd_scl)\n    except Exception:\n        fit = classifier.fit(dense_features,train['sentiment'])\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,test['sentiment'])\n    average_precision = average_precision_score(pred, test['sentiment'])\n    classification_rep = classification_report(pred,test['sentiment'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print(f'Average precision-recall score {average_precision} model {classifier.__class__.__name__}'  )\n    print('classification report: '+str(class_rep))\n    print('percision of '+classifier.__class__.__name__+'is '+str(percision))    \n    print('recall of '+classifier.__class__.__name__+'is '+str(recall))    \n","d1ced0b6":"model = Classifiers[7]\nmodel.fit(xtrain_svd_scl,train['sentiment'])\npred= model.predict(xvalid_svd_scl)","eaf8a785":"pd.DataFrame({'pred':pred,'True':y_test})","1d2dcb3e":"from sklearn.pipeline import make_pipeline\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\n\nc = make_pipeline(tfv, svd,scl,Classifiers[7])\nclass_names=list(['0','1'])\nexplainer = LimeTextExplainer(class_names=class_names)\nidx = 4794\nexp = explainer.explain_instance(x_test[idx], c.predict_proba, num_features=6)\nexp.show_in_notebook(text=True)\n\n","ea29add7":"idx = 14156\nexp = explainer.explain_instance(x_test[idx], c.predict_proba, num_features=6, labels=(1,0))\nexp.show_in_notebook(text=True)\n","0114f100":"from tqdm import tqdm\nembeddings_index = {}\nf = open('\/kaggle\/input\/d\/sawarn69\/glove6b100dtxt\/glove.6B.100d.txt')\nfor line in tqdm(f):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))\n","3353577b":"from nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\ndef sent2vec(s):\n    words = str(s).lower()\n    words = word_tokenize(words)\n    words = [w for w in words if not w in stop_words]\n    words = [w for w in words if w.isalpha()]\n    M = []\n    for w in words:\n        try:\n            M.append(embeddings_index[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    if type(v) != np.ndarray:\n        return np.zeros(100)\n    return v \/ np.sqrt((v ** 2).sum())\n","7e96be05":"xtrain_glove = [sent2vec(x) for x in tqdm(train_clean_tweet)]\nxvalid_glove = [sent2vec(x) for x in tqdm(test_clean_tweet)]\n","7d582e6d":"xtrain_glove = np.array(xtrain_glove)\nxvalid_glove = np.array(xvalid_glove)\n","65b3f47f":"Accuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(xtrain_glove,y_train)\n        pred = fit.predict(xvalid_glove)\n    except Exception:\n        fit = classifier.fit(dense_features,y_train)\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,y_test)\n    average_precision = average_precision_score(pred, y_test)\n    classification_rep = classification_report(pred,y_test)\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n    print('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))\n    print('classification report',classification_rep)","85a6a984":"!pip install tensorflow","18d686c9":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow.keras.preprocessing import text\n\nytrain_enc = to_categorical(y_train)\nyvalid_enc = to_categorical(y_test)\n\n","510f78e3":"\ntoken = text.Tokenizer(num_words=None)\nmax_len = 70\n\ntoken.fit_on_texts(list(x_train) + list(x_test))\n","ee4c9125":"xtrain_seq = token.texts_to_sequences(x_train)\nxvalid_seq = token.texts_to_sequences(x_test)\n","043929cd":"max_len = 70\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n\n\n","219f6353":"word_index = token.word_index\n\nembedding_matrix = np.zeros((len(word_index) + 1, 100))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n","455ea3b2":"\nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                     100,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\nmodel.add(SpatialDropout1D(0.3))\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n","2ffd2518":"earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n\nmodel.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=50, verbose=1, validation_data=(xvalid_pad, yvalid_enc),callbacks=[earlystop])\n","9e8a2787":"y_pred = model.predict(xvalid_pad, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_test, y_pred_bool))\n","f0892650":"from keras.layers import Bidirectional\n\nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                     100,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\nmodel.add(SpatialDropout1D(0.3))\nmodel.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\n# Fit the model with early stopping callback\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\nmodel.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=50, \n          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])\n","f7ecc022":"y_pred = model.predict(xvalid_pad, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_test, y_pred_bool))\n","41c989b1":"from keras.layers import GRU\n\nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                     100,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\nmodel.add(SpatialDropout1D(0.3))\nmodel.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\nmodel.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.8))\n\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\n# Fit the model with early stopping callback\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\nmodel.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])\n","7e386921":"y_pred = model.predict(xvalid_pad, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_test, y_pred_bool))\n","28a76424":"from transformers import TFXLNetModel, XLNetTokenizer\nimport tensorflow as tf\n\nxlnet_model = 'xlnet-large-cased'\nxlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)\n","6752fb8f":"def create_xlnet(mname):\n    \"\"\" Creates the model. It is composed of the XLNet main block and then\n    a classification head its added\n    \"\"\"\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n    # instantiate a distribution strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\n    with tpu_strategy.scope():\n\n    # Define token ids as inputs\n        word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n\n        # Call XLNet model\n        xlnet = TFXLNetModel.from_pretrained(mname)\n        xlnet_encodings = xlnet(word_inputs)[0]\n\n        # CLASSIFICATION HEAD \n        # Collect last step from last hidden state (CLS)\n        doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n        # Apply dropout for regularization\n        doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n        # Final output \n        outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n\n        # Compile model\n        model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\n    return model","bdf9cf98":"xlnet = create_xlnet(xlnet_model)\n","58e16632":"xlnet.summary()\n","a28a7b7e":"def get_inputs(tweets, tokenizer, max_len=120):\n    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in tweets]\n    inp_tok = np.array([a['input_ids'] for a in inps])\n    ids = np.array([a['attention_mask'] for a in inps])\n    segments = np.array([a['token_type_ids'] for a in inps])\n    return inp_tok, ids, segments\n\ndef warmup(epoch, lr):\n    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n    However, as we are finetuning for few epoch it's not crucial.\n    \"\"\"\n    return max(lr +1e-6, 2e-5)\n\ndef plot_metrics(pred, true_labels):\n    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n    auc = roc_auc_score(true_labels, pred)\n\n    fig, ax = plt.subplots(1, figsize=(8,8))\n    ax.plot(fpr, tpr, color='red')\n    ax.plot([0,1], [0,1], color='black', linestyle='--')\n    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n    return fig\n","bb35b6ff":"inp_tok, ids, segments = get_inputs(x_train, xlnet_tokenizer)\n","24a03eb0":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.02, restore_best_weights=True),\n    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n]\n","895c13b1":"hist = xlnet.fit(x=inp_tok, y=y_train, epochs=10, batch_size=16, validation_split=.15, callbacks=callbacks)\n","f5efea58":"inp_tok, ids, segments = get_inputs(x_test, xlnet_tokenizer)\n","aeabc88c":"preds = xlnet.predict(inp_tok, verbose=True)\n","4f49d702":"pd.DataFrame(preds,y_test).reset_index().head(20)","801e3566":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\nplot_metrics(preds, y_test);\n","fe21868e":"preds[preds > 0.5] = 1","804a6bd2":"preds[preds < 0.5] = 0","56772086":"print(classification_report(y_test, preds))\n","11391d65":"As we may presume the most frequent words would be people complaining about flight canncellation, customer service and bags issues as appeared in the word cloud for negative responses, no clean text for positive and neutral responses to generate wordcloud for them. We can go deeper and computer the actual TFIDF weight for each word, let's see how can we do that.\n","bf13bbf5":"let's convert our labels , negative\/neutral\/positive to numbers to be able to see the correlation betwwen different features and those labels, Squash label to \n* 0 if negative\n* 1 if positive or neutral","99dd5cb6":"# Deep learning","2c03d3b7":"You can check out the Chi-Square Table at https:\/\/www.mathsisfun.com\/data\/chi-square-table.html\nThis is how you use the chi-square table. With your \u03b1 set to be 0.05, and 1 degrees of freedom, the critical chi-square region is 3.84 (refer to the chart above). Putting this value into the chi-square distribution curve, you can conclude that:\n\n![image.png](attachment:9efd8fa5-4592-4402-ba1e-3758f893c36b.png)\n\nAs the calculated chi-square value (645) is greater than 3.84, it therefore falls in the rejection region, and hence the null hypothesis is rejected and the alternate hypothesis is accepted.","a2ba68f7":"## GRU","ae3943d2":"### Assumtions","eb565f01":"## TFIDF","feff0a9e":"### Wordcloud for negative sentiment","e0350b04":"It seems that negative mood dominates the passengers now let's dive deeper and see what causes the negativity the most","1643911c":"Let's begin preparaing our data for ML pipeline so first step is that we should vecotrize the text we have in the tweets data. We have seen a type of vectorization the TFIDF when we gave weights to each word remeber? SKLearn got us covered in this issue we lots of vectorizing techniques and we will explore them one by one!\n\n***CountVectorizer*\n**\nCreates a matrix with frequency counts of each word in the text corpus\n\n\n***TF-IDF Vectorizer*\n****TF - Term Frequency -- Count of the words(Terms) in the text corpus (same of Count Vect)\nIDF - Inverse Document Frequency -- Penalizes words that are too frequent. We can think of this as regularization\n\n\n***HashingVectorizer***\nCreates a hashmap(word to number mapping based on hashing technique) instead of a dictionary for vocabulary\nThis enables it to be more scalable and faster for larger text coprus\nCan be parallelized across multiple threads","127aa459":"## Glove Embeddings\n","560e3969":"## Semantic Analysis\n","0a97fdfb":"  ## Data Exploration \n  \n","e7137dad":"## WordClouds \nOne very handy visualization tool for a data scientist when it comes to any sort of natural language processing is plotting \"Word Cloud\". A word cloud (as the name suggests) is an image that is made up of a mixture of distinct words which may make up a text or book and where the size of each word is proportional to its word frequency in that text (number of times the word appears)","a6b4665f":"We can assume that some close areas are belong to the same countries","4e3b8945":"## Let's now demonstrates some hypothesis tests on the data we have","6694e852":"percentage of negativity is 62%\npercentage of neutral is 21%\npercentage of positive is 16%\n","4da2ee90":"This got us a slight improvement on some model on precision-recall scale in Random Forest Model,","e092809d":"## TF-IDF + SVD","882e5dd3":"As we can see most negative responses come from the United Airline, and most positive responses comes from Southwest airline","2966f9a0":"So our benchmark on the unfiltered dataset was.\n\n> Negative = 62.69125683060109 %\n\n> Neutral = 21.168032786885245 %\n\n> Postive = 16.140710382513664 %\n\n\n\n\n\nAs you can see the percentage of positivity for the tweet decreased tremendously and the neutral percentage increased, So we can conclude that adding '?' to the tweets increased the probability of it being neutral or negative","7d191183":"# Future thoughts\n* Need to justify all models to know exactly where we should be heading\n* Use different embeddings\n","b894b71d":"As you can see this is a correctly as positive, and model gives highest weight to the word best","178b51f7":"# What we have done so far?\n* We did some data exploration and semantic analysis with a hypothesis and tested it using two different approaches\n* We tested different vectorization techniques on different classifiers\n* We Justified our models decisions using LIME\n* We used Glove embeddings with fully connected nn, LSTM, Bidirectional LSTM and GRU\n","112096b2":"## Bidirectional LSTM","2066da37":"**Check data balance**","aadb268b":"Unfortunately, there is no built-in lemmatizer in the vectorizer so we are left with a couple of options. Either implementing it separately everytime before feeding the data for vectorizing or somehow extend the sklearn implementation to include this functionality. Luckily for us, we have the latter option where we can extend the CountVectorizer class by overwriting the \"build_analyzer\" method as follows:\n\nlet's try to extending the CountVectorizer class with a lemmatizer and try again fitting our models\n","cd84daf1":"## Glove","8f335e2b":"## Lemmatization + Countvector","7c72f66f":"let's see what mood that dominates the passengers the most and what next and so on.","b3f57308":"So we got Random forest classifier and XGBoost is slightly above the bare random guessing so let's try antoher approach to mitigate the problem of unbalanced dataset, let's keep the data as is without scalling and measure precision and recall \nrecall = true positives\/ true positives + false negatives\n\n> You might notice something about this equation: if we label all data pts as postives, then our recall goes to 1.0! We have a perfect classifier right?\nWell, not exactly. As with most concepts in data science, there is a trade-off in the metrics we choose to maximize. In the case of recall, when we increase the recall, we decrease the precision, so in order be confident in our model dicisions we need to account on both metrics\nprecision = true positives \/ true positives + false positives\n","4e35678b":"Unbalaced datasets could cause problems to our model and bias it to a wrong directions ","b8549d05":"it's likely when the tweets is too long to be negative","377aefbf":"## CountVector","18d8259b":"### Let's validate this assumption","cba77525":"## LSTM","d00a82a9":"Looks like Nans in columns ['airline_sentiment_gold','negativereason_gold','tweet_coord'] are having very high percentage so let's remove them ","29528ee2":"## XGBoost justification","32d190bc":"> We can assume that the 1st three time zones are in The US to be able to plot them on a map to have a better prespective about where on the map the actual negative feedback is coming","bab1b7e7":"Now it's clear that most of the negativity responses are coming from USA,Canada and Quito, although there's an error in latitude for USA and Canada but you got the idea of what I am after, now let's explore the moods for different airlines","eb2801fa":"- H\u2080 (Null Hypothesis) \u2014 that the 2 categorical variables to be compared are independent of each other.\n- H\u2081 (Alternate Hypothesis) \u2014 that the 2 categorical variables being compared are dependent on each other.\n","1d91e7c1":"# Take aways\n* Best approach to take from classical ML models is XGB classifier on top of tfidf vectorizer after decomposition and scalling due to its percision and recall results on the undersampling label\n* Best Deep learning model was the lstm architecture on Glove embeddings\n","ba75075a":"### First hypothesis is tweets with question marks should be angrier ","f203a43c":"This was classified as positive, neutral ","df8b47f3":"# XLnet model","da5b80d2":"## Compute Chi-squared test"}}