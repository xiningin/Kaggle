{"cell_type":{"64770429":"code","6ee6eab1":"code","300893cb":"code","aa2e7417":"code","180745e4":"code","46c888a7":"code","9e2998b7":"code","29ffd2ce":"code","7e201a9e":"code","165d5458":"code","6cdb55ab":"code","50c48abd":"code","78e6bc38":"code","6cbe069a":"code","6e64b641":"code","dadf579c":"code","d981ccc4":"code","36035323":"code","9ec062ee":"code","cdb8d91a":"code","164ba424":"code","ea72a892":"code","242e8290":"code","16ca1ab7":"code","e2b1880a":"code","26924c9a":"code","701b7546":"markdown","d95c479f":"markdown","9279b3a2":"markdown","9e9a5e92":"markdown","376accce":"markdown","64ad4b4e":"markdown","82a5baea":"markdown","feda3ad8":"markdown","5c8a1232":"markdown"},"source":{"64770429":"import sys\nsys.path.append('..\/input\/timmdataset\/pytorch-image-models-master')\nimport timm","6ee6eab1":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom tqdm import tqdm\nimport cv2\nfrom skimage import io\nimport time\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, RandomCrop,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport tqdm.notebook as tq\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax","300893cb":"CFG = {\n    'img_size': 512,\n    'vit_img': 384,\n    'tta': 3,\n    'valid_bs': 48,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'effnet_model_b3' : ['tf_efficientnet_b3_ns_model_2.pth','tf_efficientnet_b3_ns_model_5.pth','tf_efficientnet_b3_ns_model_4.pth','tf_efficientnet_b3_ns_model_1.pth','tf_efficientnet_b3_ns_model_3.pth'],\n    'effnet_model_b4' : ['tf_efficientnet_b4_ns_model_3.pth','tf_efficientnet_b4_ns_model_5.pth','tf_efficientnet_b4_ns_model_2.pth','tf_efficientnet_b4_ns_model_1.pth','tf_efficientnet_b4_ns_model_4.pth'],\n    'resnet_models' : ['resnet50d_model_1.pth','resnet50d_model_4.pth','resnet50d_model_3.pth','resnet50d_model_2.pth','resnet50d_model_5.pth'],\n    'resnext_models' : ['resnext50d_32x4d_model_5.pth','resnext50d_32x4d_model_3.pth','resnext50d_32x4d_model_1.pth','resnext50d_32x4d_model_2.pth','resnext50d_32x4d_model_4.pth'],\n    'resnext101_models' : ['ig_resnext101_32x8d_model_1.pth','ig_resnext101_32x8d_model_2.pth','ig_resnext101_32x8d_model_3.pth','ig_resnext101_32x8d_model_4.pth','ig_resnext101_32x8d_model_5.pth'],\n    'vit_models' : ['vit_base_patch16_384_model_2.pth','vit_base_patch16_384_model_5.pth','vit_base_patch16_384_model_1.pth','vit_base_patch16_384_model_3.pth','vit_base_patch16_384_model_4.pth']\n}","aa2e7417":"class DiseaseDatasetInference(torch.utils.data.Dataset):\n\n    def __init__ (self, df, transform=None, opt_label=True):\n        self.df = df.reset_index(drop=True).copy()\n        self.transform = transform\n        self.opt_label = opt_label\n\n        if self.opt_label:\n            self.data = [(row['image_id'], row['label']) for _, row in self.df.iterrows()]\n\n        else:\n            self.data = [(row['image_id']) for _, row in self.df.iterrows()]\n\n        self.data = np.asarray(self.data)\n  \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__ (self, index):\n            # np.random.shuffle(self.data)\n        if self.opt_label:\n            image_path, label = self.data[index]    \n        else:\n            image_path = self.data[index]\n\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n\n        if self.opt_label == True:\n            return (image, int(label))\n\n        else:\n            return image","180745e4":"def get_inference_Vit_transforms():\n    return Compose([\n#             RandomCrop(CFG['vit_img'], CFG['vit_img'], p=0.5),\n            CenterCrop(CFG['vit_img'], CFG['vit_img'], p=0.5),\n            Resize(CFG['vit_img'], CFG['vit_img']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n            \n        ], p=1.)","46c888a7":"def get_inference_transforms():\n    return Compose([\n#             RandomCrop(CFG['img_size'], CFG['img_size'], p=0.5),\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=0.5),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n            \n        ], p=1.)","9e2998b7":"df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\nPATH = '\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/'","29ffd2ce":"test_csv = df.copy()\ntest_csv['image_id'] = PATH + test_csv['image_id']\n\ntest_ds = DiseaseDatasetInference(test_csv, transform=get_inference_transforms(), opt_label=False)\ntest_ds_vit = DiseaseDatasetInference(test_csv, transform=get_inference_Vit_transforms(), opt_label=False)\n\ntest_loader = torch.utils.data.DataLoader(test_ds, batch_size=CFG['valid_bs'], shuffle=False, pin_memory=False) \ntest_loader_vit = torch.utils.data.DataLoader(test_ds_vit, batch_size=CFG['valid_bs'], shuffle=False, pin_memory=False) ","7e201a9e":"def inference (model, data_loader, device):\n    preds = []\n    model.eval()\n    test_tqdm = tq.tqdm(data_loader, total=len(data_loader), desc=\"Testing\", position=0, leave=True)\n    for images in test_tqdm:\n        images = images.to(device)\n        preds.extend(model(images).detach().cpu().numpy())\n    return preds","165d5458":"class Effnet(nn.Module):\n    def __init__(self, model_name = 'tf_efficientnet_b3_ns', pretrained = False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained = pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, 5)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","6cdb55ab":"path_effnet = '..\/input\/torch-my-cassava-effnetb3\/'\n\nmodel_name = 'tf_efficientnet_b3_ns'\neffnet_preds = []\neffnet_model = Effnet(model_name = model_name)\nfor effnet_model_name in CFG['effnet_model_b3']:\n    print(\"Model: \", effnet_model_name)\n    effnet_model.to(CFG['device'])\n    effnet_model.load_state_dict(torch.load(path_effnet+effnet_model_name, map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            effnet_preds += [inference(effnet_model, test_loader, CFG['device'])]\neffnet_preds = np.mean(effnet_preds, axis=0)","50c48abd":"effnet_outcomes_b3 = pd.concat([df['image_id'], pd.DataFrame(effnet_preds)], axis=1).sort_values(['image_id'])","78e6bc38":"# path_effnet = '..\/input\/torch-my-cassava-effnetb4\/'\n\n\n# model_name = 'tf_efficientnet_b4_ns'\n# effnet_preds = []\n# effnet_model = Effnet(model_name = model_name)\n# for effnet_model_name in CFG['effnet_model_b4']:\n#     print(\"Model: \", effnet_model_name)\n#     effnet_model.to(CFG['device'])\n#     effnet_model.load_state_dict(torch.load(path_effnet+effnet_model_name, map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             effnet_preds += [inference(effnet_model, test_loader, CFG['device'])]\n# effnet_preds = np.mean(effnet_preds, axis=0)","6cbe069a":"# effnet_outcomes_b4 = pd.concat([df['image_id'], pd.DataFrame(effnet_preds)], axis=1).sort_values(['image_id'])","6e64b641":"class CustomResNet(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, 5)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","dadf579c":"# resnet_preds = []\n# path_resnet = '..\/input\/torch-my-cassava-resnet50d\/'\n\n# model_name = 'resnet50d'\n\n# resnet_model = CustomResNet(model_name = model_name)\n# resnet_model.to(CFG['device'])\n# for resnet_model_name in CFG['resnet_models']:\n#     print(\"Model: \", resnet_model_name)\n#     resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n#                                              map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\n# resnet_preds = np.mean(resnet_preds, axis=0)","d981ccc4":"# resnet_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])","36035323":"resnet_preds = []\npath_resnet = '..\/input\/torch-my-cassava-resnext50d\/'\n\nmodel_name = 'resnext50d_32x4d'\n\nresnet_model = CustomResNet(model_name = model_name)\nresnet_model.to(CFG['device'])\nfor resnet_model_name in CFG['resnext_models']:\n    print(\"Model: \", resnet_model_name)\n    resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n                                             map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\nresnet_preds = np.mean(resnet_preds, axis=0)","9ec062ee":"resnext_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])","cdb8d91a":"# resnet_preds = []\n# path_resnet = '..\/input\/torch-my-cassava-resnext101\/'\n\n# model_name = 'ig_resnext101_32x8d'\n\n# resnet_model = CustomResNet(model_name = model_name)\n# resnet_model.to(CFG['device'])\n# for resnet_model_name in CFG['resnext101_models']:\n#     print(\"Model: \", resnet_model_name)\n#     resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n#                                              map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\n# resnet_preds = np.mean(resnet_preds, axis=0)","164ba424":"# resnext_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])","ea72a892":"class ViTClassifier(nn.Module):\n    def __init__(self, model_name = 'vit_base_patch16_384', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 5)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","242e8290":"path_vit = '..\/input\/torch-my-cassava-vit-16-384\/'\n\n\nmodel_name = 'vit_base_patch16_384'\nvit_preds = []\nvit_model = ViTClassifier(model_name = model_name)\nfor vit_model_name in CFG['vit_models']:\n    print(\"Model: \", vit_model_name)\n    vit_model.to(CFG['device'])\n    vit_model.load_state_dict(torch.load(path_vit+vit_model_name, map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            vit_preds += [inference(vit_model, test_loader_vit, CFG['device'])]\nvit_preds = np.mean(vit_preds, axis=0)","16ca1ab7":"vit_outcomes = pd.concat([df['image_id'], pd.DataFrame(vit_preds)], axis=1).sort_values(['image_id'])","e2b1880a":"# final_preds = (effnet_outcomes_b3.drop('image_id', axis=1) * 0.25 + effnet_outcomes_b4.drop('image_id', axis=1) * 0.25 + resnet_outcomes.drop('image_id', axis=1) * 0.25 + resnext_outcomes.drop('image_id', axis=1) * 0.25).to_numpy()\nfinal_preds = (resnext_outcomes.drop('image_id', axis=1) * 0.4 + vit_outcomes.drop('image_id', axis=1) * 0.3 + effnet_outcomes_b3.drop('image_id', axis=1) * 0.3).to_numpy()\n# final_preds = (resnext_outcomes.drop('image_id', axis=1) * 0.5 + effnet_outcomes_b3.drop('image_id', axis=1) * 0.5).to_numpy()\nfinal_preds = softmax(final_preds).argmax(1)","26924c9a":"submit = pd.DataFrame({'image_id': df['image_id'].values, 'label': final_preds})\nsubmit.to_csv('submission.csv', index=False)","701b7546":"# EfficientNet B4","d95c479f":"# ResNext50d","9279b3a2":"# ResNext 101","9e9a5e92":"# **ResNet**","376accce":"# EfficientNet B3","64ad4b4e":"# ViT","82a5baea":"# Ensemble","feda3ad8":"# **EfficientNet**","5c8a1232":"# ResNet50d"}}