{"cell_type":{"86a55f2e":"code","09eff506":"code","29851f1f":"code","efbefefc":"code","b1f6d54b":"code","afa5293c":"code","a284e522":"code","543957ce":"code","d9d5a403":"code","301e2cd9":"code","95a9e268":"code","ec87fb0f":"code","835e90fb":"code","8a425331":"code","7fc5205e":"code","af7a02d3":"code","f9d1df51":"code","24de3bc7":"code","1802c563":"code","cbb30698":"code","39df4c31":"code","b87b6cb6":"code","f2c31dd9":"code","79f16b45":"code","ae5bf16b":"code","6b61679a":"code","12e01151":"code","b68d1bf5":"code","d664b52b":"code","60abb31b":"code","a6d30d41":"code","dc99d3ec":"code","37c0498b":"code","4c7401fa":"code","b788bf54":"code","91eccbab":"code","ddead95c":"code","73f3acf1":"code","f9d463f4":"code","7ed83f5b":"code","39ee34b0":"code","93a512af":"code","df7dcea5":"code","5239146c":"code","9e2fedb5":"code","53b23e55":"code","22d2480d":"code","bc97637f":"code","9d494af3":"code","0d789f88":"code","94ad6d3b":"code","b1f54ffd":"code","db71d17b":"code","049c0967":"code","969751a1":"code","de9b803f":"code","715cb9b5":"code","b38eacc7":"code","659a25f2":"code","bafda997":"code","6b834a0c":"code","3cdde34e":"code","cafee29a":"code","fcb86d61":"code","6e80356f":"code","71c4bbe8":"code","d8365205":"code","92dde9a1":"code","836e9d40":"code","37044bcc":"code","f3c9ab81":"code","0ecb256b":"code","b5ab4340":"code","468bf3df":"code","4ad7e4cb":"code","5fd5cda8":"code","35973c0f":"code","bea04d64":"code","d6132b25":"markdown","78f24147":"markdown","e5621c52":"markdown","67886bf9":"markdown","c867e07b":"markdown","ec192d54":"markdown","125b5c36":"markdown","96da7123":"markdown","c26da96b":"markdown","413774ef":"markdown","0d367d46":"markdown","c7a81c99":"markdown","07f72d14":"markdown","cb0bf291":"markdown","45bd9881":"markdown","4f7d512c":"markdown","e8419da0":"markdown","ae484ddc":"markdown","658ea279":"markdown","ecb98420":"markdown","fa12670c":"markdown","6d202036":"markdown","b3d09b09":"markdown","32573d7f":"markdown","539ce5fa":"markdown","67255992":"markdown","c7e111d2":"markdown","2fb29f98":"markdown"},"source":{"86a55f2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09eff506":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom collections import Counter\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","29851f1f":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","efbefefc":"print(train.shape)\ntrain.head()","b1f6d54b":"print(test.shape)\ntest.head()","afa5293c":"train.info()","a284e522":"test.info()","543957ce":"train.describe(include='all')","d9d5a403":"test.describe(include='all')","301e2cd9":"#Checking weather data is balanced or imbalanced\ntrain['Survived'].value_counts()","95a9e268":"print(train.pivot_table(values = 'Survived', index = 'Sex'))\ntrain.pivot_table(values = 'Survived', index = 'Sex').plot(kind = 'bar')","ec87fb0f":"sns.kdeplot(train[train['Sex']=='male']['Age'], label = 'male')\nsns.kdeplot(train[train['Sex']=='female']['Age'],label = 'female')\nplt.legend()\nplt.title('Age distribution of male and female')","835e90fb":"sns.violinplot(x='Sex', y='Age', hue='Survived', data=train, split=True)","8a425331":"#Let's see the relation between Age and Survived column using graph\ntrain.hist(column=\"Age\",by=\"Survived\",bins=50,figsize=(25,7))","7fc5205e":"#Now let's see the relation between Pclass and survived column using graph\ntrain.pivot_table(values=['Survived'],index=['Pclass']).plot(kind='bar')","af7a02d3":"print(train['Pclass'].value_counts())\nsns.distplot(train['Pclass'])","f9d1df51":"#Now combine all Pclass, Age and Survived in one graph and see the result\nplt.figure(figsize=(20,9))\nsns.violinplot(x='Pclass', y='Age', hue='Survived',data=train, split=True)","24de3bc7":"#Visualizing of which stoppage passenger died most and of which age group\nplt.figure(figsize=(20,9))\nsns.violinplot(x='Embarked', y='Age', hue='Survived',data=train, split=True)\n#C = Cherbourg, Q = Queenstown, S = Southampton","1802c563":"#Distribution of Age vs Survived\nsns.stripplot(train['Survived'],train['Age'], jitter=True)","cbb30698":"#Distribution of Fare vs Survived\nsns.stripplot(train['Survived'],train['Fare'], jitter=True)","39df4c31":"#Distribution of age in different classes\ntrain.hist(column=\"Age\",by=\"Pclass\",bins=30)","b87b6cb6":"def detect_outlier(df,n,cols):\n    outlier_indices = []\n    for i in cols:\n        Q1 = np.percentile(df[i], 25)\n        Q3 = np.percentile(df[i], 75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5*IQR\n        outlier_index_list = df[(df[i] < Q1-outlier_step) | (df[i] > Q3+outlier_step)].index\n        outlier_indices.extend(outlier_index_list)\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(k for k,v in outlier_indices.items() if v>n)  \n    return multiple_outliers","f2c31dd9":"#We are dropping only those indices whose count is at least 2. \noutliers_to_drop = detect_outlier(train,2,['Age', 'SibSp', 'Parch', 'Fare'])\ntrain.loc[outliers_to_drop]","79f16b45":"train = train.drop(outliers_to_drop, axis = 0).reset_index(drop=True)","ae5bf16b":"# extracting and then removing the targets from the training data \ntargets = train.Survived\ntrain.drop(['Survived'], 1, inplace=True)\n    \n\n# merging train data and test data for future feature engineering\n# we'll also remove the PassengerID since this is not an informative feature\ncombined = train.append(test)\ncombined.reset_index(inplace=True)\ncombined.drop(['index', 'PassengerId'], inplace=True, axis=1)","6b61679a":"#Correlation between different features\nsns.heatmap(combined.corr(), annot = True)","12e01151":"print(targets.shape)\ncombined.shape","b68d1bf5":"combined.info()","d664b52b":"#Visualizing null values in the dataset\nsns.heatmap(combined.isnull())","60abb31b":"combined.head()","a6d30d41":"#Let's see all the titles\ntitles = set()\nfor name in train['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","dc99d3ec":"#We will extract titles in 'Title' column\ncombined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","37c0498b":"pd.crosstab(combined['Title'],combined['Sex'])","4c7401fa":"#Replacing some titles to the most common titles\ncombined['Title'] = combined['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ncombined['Title'] = combined['Title'].replace('Mlle', 'Miss')\ncombined['Title'] = combined['Title'].replace('Ms', 'Miss')\ncombined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n#Mapping titles to numerical data\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ncombined['Title'] = combined['Title'].map(title_mapping)\ncombined['Title'] = combined['Title'].fillna(0)\n##dropping Name feature\ncombined = combined.drop(['Name'], axis=1)","b788bf54":"combined.head()","91eccbab":"combined[\"Sex\"][combined[\"Sex\"] == \"male\"] = 0\ncombined[\"Sex\"][combined[\"Sex\"] == \"female\"] = 1\ncombined[\"Sex\"] = combined[\"Sex\"].astype(int)","ddead95c":"combined.head()","73f3acf1":"#Age column in highly crrelated with Pclass column\ncombined.groupby('Pclass')['Age'].describe()","f9d463f4":"#Filling null values with median of ages in different classes\ncombined['Age'] = combined.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))","7ed83f5b":"combined[\"Age\"] = combined[\"Age\"].astype(int)","39ee34b0":"#cutting age in different groups\ncombined['Age_cat'] = pd.qcut(combined['Age'],q=[0, .16, .33, .49, .66, .83, 1], labels=False, precision=1)","93a512af":"combined.head()","df7dcea5":"#Keeping only alphabets and removing numbers from ticket name, \n#if there is no any alphabets then replace the string with \"x\"\ntickets = []\nfor i in list(combined.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")","5239146c":"combined['Ticket'] = tickets","9e2fedb5":"combined = pd.get_dummies(combined, columns= [\"Ticket\"], prefix = \"T\")","53b23e55":"combined.head()","22d2480d":"combined['Fare'] = combined.groupby(\"Pclass\")['Fare'].transform(lambda x: x.fillna(x.median())) ","bc97637f":"combined['Zero_Fare'] = combined['Fare'].map(lambda x: 1 if x == 0 else (0))","9d494af3":"def fare_category(fr): \n    if fr <= 7.91:\n        return 1\n    elif fr <= 14.454 and fr > 7.91:\n        return 2\n    elif fr <= 31 and fr > 14.454:\n        return 3\n    return 4","0d789f88":"combined['Fare_cat'] = combined['Fare'].apply(fare_category) ","94ad6d3b":"combined.info()","b1f54ffd":"combined[\"Embarked\"] = combined[\"Embarked\"].fillna(\"C\")\ncombined[\"Embarked\"][combined[\"Embarked\"] == \"S\"] = 1\ncombined[\"Embarked\"][combined[\"Embarked\"] == \"C\"] = 2\ncombined[\"Embarked\"][combined[\"Embarked\"] == \"Q\"] = 3\ncombined[\"Embarked\"] = combined[\"Embarked\"].astype(int)","db71d17b":"combined.head()","049c0967":"#Creating a new feature which contains number of members of family\ncombined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1","969751a1":"#Grouping FamilySize in different categories\ncombined['FamilySize_cat'] = combined['FamilySize'].map(lambda x: 1 if x == 1 \n                                                            else (2 if 5 > x >= 2 \n                                                                  else (3 if 8 > x >= 5 \n                                                                       else 4 )\n                                                                 ))   ","de9b803f":"#Creating a new feature Alone\ncombined['Alone'] = [1 if i == 1 else 0 for i in combined['FamilySize']]","715cb9b5":"combined.head()","b38eacc7":"#Filling null values in Cabin feature with 'U'\ncombined['Cabin'] = combined['Cabin'].fillna('U')","659a25f2":"#Keeping only first letter of Cabin name\nimport re\ncombined['Cabin'] = combined['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())","bafda997":"combined['Cabin'].value_counts()","6b834a0c":"cabin_category = {'A':9, 'B':8, 'C':7, 'D':6, 'E':5, 'F':4, 'G':3, 'T':2, 'U':1}","3cdde34e":"combined['Cabin'] = combined['Cabin'].map(cabin_category)","cafee29a":"combined.head()","fcb86d61":"#Creating dummy variable from categorical variable\ndummy_col=['Title', 'Sex',  'Age_cat', 'SibSp', 'Parch', 'Fare_cat', 'Cabin', 'Embarked', 'Pclass', 'FamilySize_cat']","6e80356f":"dummy = pd.get_dummies(combined[dummy_col], columns=dummy_col, drop_first=False)","71c4bbe8":"combined = pd.concat([dummy, combined], axis = 1)","d8365205":"combined['FareCat_Sex'] = combined['Fare_cat']*combined['Sex']\ncombined['Pcl_Sex'] = combined['Pclass']*combined['Sex']\ncombined['Pcl_Title'] = combined['Pclass']*combined['Title']\ncombined['Age_cat_Sex'] = combined['Age_cat']*combined['Sex']\ncombined['Age_cat_Pclass'] = combined['Age_cat']*combined['Pclass']\ncombined['Title_Sex'] = combined['Title']*combined['Sex']\ncombined['Age_Fare'] = combined['Age_cat']*combined['Fare_cat']\n\ncombined['SmallF'] = combined['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ncombined['MedF']   = combined['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ncombined['LargeF'] = combined['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\ncombined['Senior'] = combined['Age'].map(lambda s:1 if s>70 else 0)","92dde9a1":"combined.head()","836e9d40":"combined[['Age_Fare','Title_1']].median()","37044bcc":"#Seperating training, test and target datasets from combined dataset\nX_train = combined[:train.shape[0]]\nX_test = combined[train.shape[0]:]\ny = targets\nX_train['Y'] = y\ndf = X_train\nX = df.drop('Y', axis=1)\ny = df.Y","f3c9ab81":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","0ecb256b":"#Splitting training dataset into training and validation dataset\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)","b5ab4340":"#Creating dmatrix to train xgboost\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test)","468bf3df":"params = {\n        'objective':'binary:logistic',\n        'eta': 0.3,\n        'max_depth':9,\n        'learning_rate':0.03,\n        'eval_metric':'auc',\n        'min_child_weight':1,\n        'subsample':1,\n        'colsample_bytree':0.4,\n        'seed':29,\n        'reg_lambda':2.8,\n        'reg_alpha':0,\n        'gamma':0,\n        'scale_pos_weight':1,\n        'n_estimators': 600,\n        'nthread':-1\n}","4ad7e4cb":"watchlist = [(d_train, 'train'), (d_valid, 'valid')]\nnrounds=10000 ","5fd5cda8":"model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=600, \n                           maximize=True, verbose_eval=10)","35973c0f":"#By using these leaks we can get 0.85 to 0.86 score. If we do not use these leaks \n#we can achieve score of 0.77 to 0.78.\nleaks = {\n897:1,\n899:1, \n930:1,\n932:1,\n949:1,\n987:1,\n995:1,\n998:1,\n999:1,\n1016:1,\n1047:1,\n1083:1,\n1097:1,\n1099:1,\n1103:1,\n1115:1,\n1118:1,\n1135:1,\n1143:1,\n1152:1, \n1153:1,\n1171:1,\n1182:1,\n1192:1,\n1203:1,\n1233:1,\n1250:1,\n1264:1,\n1286:1,\n935:0,\n957:0,\n972:0,\n988:0,\n1004:0,\n1006:0,\n1011:0,\n1105:0,\n1130:0,\n1138:0,\n1173:0,\n1284:0,\n}","bea04d64":"sub = pd.DataFrame()\nsub['PassengerId'] = test['PassengerId']\nsub['Survived'] = model.predict(d_test)\nsub['Survived'] = sub['Survived'].apply(lambda x: 1 if x>0.8 else 0)\nsub['Survived'] = sub.apply(lambda r: leaks[int(r['PassengerId'])] if int(r['PassengerId']) in leaks else r['Survived'], axis=1)\nsub.to_csv('sub_titan.csv', index=False)","d6132b25":"From above data and graph we can see that female survived more than male.","78f24147":"# Data cleaning","e5621c52":"In test dataset there are:\n* 86 null values in Age column\n* 1 null value in Fare column\n* 327 null values in Cabin column","67886bf9":"# Modelling","c867e07b":"# Loading the dataset","ec192d54":"We have dropped 10 rows.","125b5c36":"### Processing Cabin column","96da7123":"### Cleaning Name column\nIn Name column we have all unique string in each row, so we will extract titles of each row.","c26da96b":"### Processing Sex column","413774ef":"Let's check which age group among male and female survived more.","0d367d46":"In train dataset there are:\n* 177 null values in Age column\n* 687 null values in Cabin column\n* 2 null values in Embarked column","c7a81c99":"### Processing Fare column\nHere we simply fill the null values of fare with the mean in the train set and ignore the values which have zero fare for first iteration,After testing our model for the first time ,we will come back and check again if treating those values would make a difference","07f72d14":"There are 549 0s and 342 1s, hence data is balanced.","cb0bf291":"# Checking variables, NAs of the dataset","45bd9881":"### Creating more features","4f7d512c":"Let's see who survived more, male or female.","e8419da0":"# Importing libraries","ae484ddc":"### Detecting outliers","658ea279":"### Processing Family column","ecb98420":"There are highest number of passenger in class 3 and passengers of class 1 survived most and passengers of class 3 survived least. Hence it can be concluded that passengers of class 1 were given preference over other two classes.","fa12670c":"### Loading the Data,Combining and removing unnecessary columns","6d202036":"# Feature Engineering","b3d09b09":"### Processing Age column","32573d7f":"### Processing Ticket column","539ce5fa":"Female, children and old people were given preference by the rescue team and hence they mostly survived.","67255992":"# Exploratory data analysis","c7e111d2":"### Processing Embarked column","2fb29f98":"We have null values in Age, Fare, Cabin and Embarked columns"}}