{"cell_type":{"549ad39f":"code","e193428a":"code","e9349905":"code","0360d85c":"code","e70485f6":"code","f2153ac7":"code","229a36d8":"code","ef20ee4b":"code","8514dd0e":"code","08781804":"code","f2d27b2b":"code","ebb3e488":"code","16dff6aa":"markdown"},"source":{"549ad39f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e193428a":"df_train= pd.read_csv('..\/input\/titanic\/train.csv')\ndf_train","e9349905":"df_train.info()","0360d85c":"df_train.drop(['PassengerId','Name','Ticket','Cabin'], axis=1,inplace=True)\n","e70485f6":"df_train = df_train.dropna()\ndf_train","f2153ac7":"df_train=df_train.replace(to_replace='female', value=1)\ndf_train=df_train.replace(to_replace='male', value=0)\n","229a36d8":"df_train=df_train.replace(to_replace='S', value=1)\ndf_train=df_train.replace(to_replace='C', value=2)\ndf_train=df_train.replace(to_replace='Q', value=3)\ndf_train","ef20ee4b":"sns.heatmap(df_train.corr(),annot=True)","8514dd0e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nX = df_train.drop(['Parch','SibSp','Survived','Embarked'], axis=1)\nY = df_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=101, test_size=0.2)\n\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\nlog_preds = log_reg.predict(X_test)\n\nprint('accuracy = ', accuracy_score(y_test, log_preds))","08781804":"df_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_test = df_test.replace(to_replace='female', value=1)\ndf_test = df_test.replace(to_replace='male', value=0)\ndf_test.drop(['Name','Ticket','Cabin','Parch','SibSp','Embarked'], axis=1,inplace=True)\ndf_test = df_test.replace(to_replace=np.nan, value=0)\ndf_test","f2d27b2b":"from sklearn.linear_model import LogisticRegression\n\nX_train = df_train.drop(['Parch','SibSp','Survived','Embarked'], axis=1)\ny_train = df_train['Survived']\n\n# set test data\nX_test = df_test.drop('PassengerId', axis=1)\n\n# create an instance and train\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n# generate predictions\nlog_preds = log_reg.predict(X_test)\n\ndf_test['Survived'] = log_preds","ebb3e488":"df_test[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)","16dff6aa":"Survival is correlated with Sex, Pclass and Fare"}}