{"cell_type":{"6389b705":"code","d7e3c8a9":"code","394eabe9":"code","1ce2bb4d":"code","1f727d53":"code","65eab48d":"code","165a38b5":"code","9ea553cc":"code","91936261":"code","95f8b30a":"code","41726b44":"code","403a3e65":"code","ba6ea74c":"code","64c2955a":"code","dd3ec29b":"code","00c958f5":"code","ae32bf70":"code","1131b9b0":"markdown"},"source":{"6389b705":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc704\uce58 \ud655\uc778\n! ls ..\/input\/state-farm-distracted-driver-detection\/","d7e3c8a9":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc704\uce58 \ud655\uc778\n! ls ..\/input\/state-farm-distracted-driver-detection\/imgs","394eabe9":"# \ub79c\ub364\ud558\uac8c \ubc30\uc815\ub41c GPU \ud655\uc778\n! nvidia-smi","1ce2bb4d":"# \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \uc124\uce58\n! pip install torch\n! pip install torchvision","1f727d53":"# \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac import\nimport pandas as pd\nimport subprocess\nimport torch\nimport torch.optim as optim\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision\nfrom torchvision import transforms\n\nimport os\nimport random\nfrom glob import glob\nimport cv2\nimport numpy as np\nfrom tqdm.notebook import tqdm","65eab48d":"# \uc8fc\uc694 \ud30c\ub77c\ubbf8\ud130 \uc9c0\uc815\nEPOCH = 100\nBATCH_SIZE = 16\nPATIENCE = 5\nDATA_PATH = '..\/input\/state-farm-distracted-driver-detection'\nMODEL_NAME = '.\/model.baseline.driver_split.data_aug'","165a38b5":"# \uc774\ubbf8\uc9c0 \ub85c\ub529\uc2dc \uc804\ucc98\ub9ac \ud568\uc218 \uc815\uc758\n# \ub2e4\uc591\ud55c \ub370\uc774\ud130 \uc5b4\uadf8\uba58\ud14c\uc774\uc158 \ud568\uc218\ub97c \ucd94\uac00\ub85c \uc815\uc758!!\n# Normalize\ub294 ImageNet \ub370\uc774\ud130\uc5d0 \uae30\ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uae30 \uc704\ud55c \ud568\uc218\ntransform = transforms.Compose([\n        transforms.RandomAffine(30, translate=(0.3, 0.3)),  # \ub79c\ub364\ud558\uac8c \uc218\ud3c9\/\uc218\uc9c1 \uc774\ub3d9 \n        transforms.RandomPerspective(p=0.1),  # \uc2dc\uc810 \uc774\ub3d9\n        transforms.RandomRotation(degrees=30),  # \ud68c\uc804\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","9ea553cc":"# \ud559\uc2b5 \ub370\uc774\ud130 \uc911, \uc6b4\uc804\uc790 \uae30\uc900\uc73c\ub85c 20%\ub97c \uac80\uc99d \ub370\uc774\ud130\ub85c \uc0ac\uc6a9\nclasses = [f'c{i}' for i in range(10)]\nseed = 2020\nvalidation_split = 0.2\n\n# \uc6b4\uc804\uc790 \uc815\ubcf4 \uc77d\uc5b4\uc624\uae30\ndriver_list = pd.read_csv(f'{DATA_PATH}\/driver_imgs_list.csv')\ndrivers = np.unique(driver_list['subject'].values)\n\n# \uc6b4\uc804\uc790 \uae30\uc900 split\nsplit = int(np.floor(validation_split * len(drivers)))\nnp.random.seed(seed)\ntrn_idx, val_idx = drivers[split:], drivers[:split]","91936261":"# \uc6b4\uc804\uc790 \uae30\uc900\uc73c\ub85c \ud559\uc2b5\/\uac80\uc99d \ub370\uc774\ud130 \ubd84\ub9ac\nsplit_dir = 'driver_split'\nif not os.path.exists(split_dir):\n    cmd = f'mkdir {split_dir}'\n    subprocess.call(cmd, shell=True)\n    for d in ['train', 'valid']:\n        cmd = f'mkdir {split_dir}\/{d}'\n        subprocess.call(cmd, shell=True)\n        for cl in classes:\n            cmd = f'mkdir {split_dir}\/{d}\/{cl}'\n            subprocess.call(cmd, shell=True)\n\ntrn_cnt = 0\nval_cnt = 0\nfor i, driver_info in driver_list.iterrows():\n    driver = driver_info['subject']\n    label = driver_info['classname']\n    img_path = driver_info['img']\n    # symlink\ub97c \ud1b5\ud574\uc11c \uc774\ubbf8\uc9c0 \ud30c\uc77c\uc744 \uc9c0\uc815\n    if driver in trn_idx:\n        if not os.path.exists(f'{split_dir}\/train\/{label}\/{img_path}'):\n            os.symlink(os.path.abspath(f'{DATA_PATH}\/imgs\/train\/{label}\/{img_path}'), f'{split_dir}\/train\/{label}\/{img_path}')\n        trn_cnt += 1\n    else:\n        if not os.path.exists(f'{split_dir}\/valid\/{label}\/{img_path}'):\n            os.symlink(os.path.abspath(f'{DATA_PATH}\/imgs\/train\/{label}\/{img_path}'), f'{split_dir}\/valid\/{label}\/{img_path}')\n        val_cnt += 1","95f8b30a":"# \ud559\uc2b5 \ub370\uc774\ud130 \ub85c\ub354 \uc815\uc758\ntrain_dataset = torchvision.datasets.ImageFolder(f'.\/{split_dir}\/train',\n                                                 transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=BATCH_SIZE,\n                                           shuffle=True,\n                                           num_workers=2)\n\n# \uac80\uc99d \ub370\uc774\ud130\uc758 \uc774\ubbf8\uc9c0 \uc804\ucc98\ub9ac\ub294 Resize + Normalize \ub9cc \ud544\uc694\nvalid_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\nvalid_dataset = torchvision.datasets.ImageFolder(f'.\/{split_dir}\/valid',\n                                                 transform=valid_transform)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                           batch_size=BATCH_SIZE,\n                                           num_workers=2)","41726b44":"# GPU \uc0ac\uc6a9\uc744 \uc704\ud55c device \ubcc0\uc218 \uc815\uc758\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","403a3e65":"# CNN \ubaa8\ub378 \ub85c\ub529\n# ImageNet\uc5d0\uc11c \uae30\ud559\uc2b5\ub41c Resnet50 \ubaa8\ub378\uacfc \ud30c\ub77c\ubbf8\ud130\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\uae30\nmodel_conv = torchvision.models.resnet50(pretrained=True)\n\n# \ucd5c\uc885 layer\ub97c \uc6b0\ub9ac \ubb38\uc81c\uc5d0 \uc54c\ub9de\uac8c \uc7ac\uad6c\uc131\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Sequential(\n        nn.Linear(num_ftrs, num_ftrs),\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(num_ftrs, num_ftrs),\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(num_ftrs, len(classes)))\nprint(f'# model : {model_conv}')\nmodel_conv = model_conv.to(device)","ba6ea74c":"# \ud559\uc2b5 \uc635\uc158 : \uc190\uc2e4 \ud568 \uc218 \ubc0f optimizer \uc815\uc758\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_conv.parameters(), lr=0.0001, weight_decay=1e-6, momentum=0.9)\nsoftmax = nn.Softmax(dim=1)\nbest_valid_score = 999\npatience = 0","64c2955a":"def train(model_conv, train_loader, optimizer, criterion, trn_cnt):\n    running_loss = 0.\n    running_acc = 0.\n\n    # \ud559\uc2b5 \uc9c4\ub3c4 \ud655\uc778\uc744 \uc704\ud55c progress_bar\n    pbar = tqdm(total=trn_cnt)\n    cnt = 0\n    for i, data in enumerate(train_loader, 0):\n        # \ub370\uc774\ud130 \ub85c\ub354\uc5d0\uc11c BATCH_SIZE \ub9cc\ud07c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ub85c\ub529\n        inputs, labels = data\n        # GPU\ub85c \ub370\uc774\ud130 \uc774\ub3d9\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # \ud559\uc2b5\uc744 \uc704\ud55c \uc900\ube44\n        optimizer.zero_grad()\n        model_conv.train()\n        outputs = model_conv(inputs)\n        probs = softmax(outputs)\n\n        # \uc815\ud655\ub3c4 \uacc4\uc0b0\n        _, preds = probs.max(axis=1)\n        running_acc += sum(labels == preds) \/ (1. * BATCH_SIZE)\n\n        # \uc190\uc2e4 \ud568\uc218 \uacc4\uc0b0\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()  # Gradient Descent HERE!\n\n        running_loss += loss.item()\n        cnt += 1\n\n        pbar.update(BATCH_SIZE)\n    pbar.close()\n    return running_loss \/ cnt, running_acc \/ cnt","dd3ec29b":"def evaluate(model_conv, valid_loader, criterion):\n    # 1 Epoch\ub9c8\ub2e4 \uac80\uc99d \ub370\uc774\ud130\uc5d0 \ub300\ud558\uc5ec \ud3c9\uac00\n    with torch.no_grad():\n        model_conv.eval()\n        valid_loss = 0.0\n        valid_acc = 0.0\n        cnt = 0\n        pbar = tqdm(total=val_cnt)\n        for data in valid_loader:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model_conv(inputs)\n            probs = softmax(outputs)\n\n            _, preds = probs.max(axis=1)\n            valid_acc += sum(labels == preds) \/ (1. * BATCH_SIZE)\n\n            labels.require_grad = False\n            loss = criterion(outputs, labels)\n            valid_loss += loss\n            cnt += 1\n            pbar.update(BATCH_SIZE)\n        pbar.close()\n    return valid_loss \/ cnt, valid_acc \/ cnt","00c958f5":"# EPOCH \ud69f\uc218 \ub9cc\ud07c \ud559\uc2b5 \uc9c4\ud589\nfor epoch in range(EPOCH):\n    print(f'# Epoch : {epoch}..')\n    # 1 Epoch \ud559\uc2b5\n    trn_loss, trn_acc = train(model_conv, train_loader, optimizer, criterion, trn_cnt)\n    print(f'# train loss : {trn_loss} train acc : {trn_acc}')\n    \n    # \uac80\uc99d \ub370\uc774\ud130 \uae30\uc900 \ud3c9\uac00\n    valid_loss, valid_acc = evaluate(model_conv, valid_loader, criterion)\n    print(f'# valid loss | valid_loss : {valid_loss} valid_acc : {valid_acc}')\n\n\n    # \uac80\uc99d \ub370\uc774\ud130\uc758 \ud3c9\uac00 \ucc99\ub3c4 \uae30\uc900\uc73c\ub85c \ucd5c\uc801\uc758 \ubaa8\ub378 \uc120\uc815\n    if valid_loss < best_valid_score:\n        best_valid_score = valid_loss\n        print(f'# Saving best model.. epoch {epoch} | valid_loss {valid_loss}')\n        torch.save(model_conv, MODEL_NAME)\n        patience = 0\n    patience += 1\n\n    # early_stopping\n    if patience == PATIENCE:\n        break\n\nprint('Finished Training')","ae32bf70":"from glob import glob\n\nTEST_SIZE = 79726\nBATCH_SIZE = 128\n\n# \uce90\uae00 \uc81c\ucd9c\uc744 \uc704\ud55c test_id \uc77d\uc5b4\uc624\uae30\ntest_ids = [os.path.basename(fl) for fl in glob(f'{DATA_PATH}\/imgs\/test\/img_*.jpg')]\ntest_ids.sort()\n\n# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc804\ucc98\ub9ac \ud568\uc218 \uc815\uc758\ntransform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \ub85c\ub529\uc744 \uc704\ud55c \ub370\uc774\ud130 \ub85c\ub354 \uc815\uc758\ntest_dataset = torchvision.datasets.ImageFolder(f'{DATA_PATH}\/imgs',\n                                                transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=BATCH_SIZE,\n                                          num_workers=2)\n\n# GPU \uc0ac\uc6a9\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# \uc800\uc7a5\ub41c \ubaa8\ub378 \ub85c\ub529\nmodel_conv = torch.load(MODEL_NAME)\nprint(f'# model : {model_conv}')\nmodel_conv = model_conv.to(device)\nsoftmax = nn.Softmax(dim=1)\n\npbar = tqdm(total=TEST_SIZE)\nend_flag = False\nwith open('submission.csv', 'w') as out:\n    # write header\n    out.write('img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n')\n\n    for i, data in enumerate(test_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            model_conv.eval()\n            outputs = model_conv(inputs)\n            probs = softmax(outputs)\n\n            # \ud074\ub798\uc2a4\ubcc4 \ud655\ub960 \uc608\uce21\uac12 \uc800\uc7a5\ud558\uae30\n            for j, prob in enumerate(probs):\n                if BATCH_SIZE * i + j >= TEST_SIZE:\n                    end_flag = True\n                    break\n                    \n                test_id = test_ids[i * BATCH_SIZE + j]\n                prob = ','.join([str(round(val, 3)) for val in prob.cpu().detach().numpy()])\n                out.write(f'{test_id},{prob}\\n')\n\n        pbar.update(BATCH_SIZE)\n\n        if end_flag:\n            break\npbar.close()\n\nprint('Finished Eval')","1131b9b0":"## Data Augmentation\n- \uc801\uc740 \ud559\uc2b5 \ub370\uc774\ud130 \uc591\uc744 \ubcf4\uc644\ud558\uae30 \uc704\ud558\uc5ec, \ud559\uc2b5 \ub370\uc774\ud130\uc758 \ub808\uc774\ube14\uc744 \ubcc0\uacbd\ud558\uc9c0 \uc54a\ub294 \uc218\uc900\uc73c\ub85c \uc785\ub825 \ub370\uc774\ud130\ub97c Augment (\ubcc0\ud615)\ud55c\ub2e4\n- \ud559\uc2b5 \ub370\uc774\ud130\uac00 \uc801\uc744 \uacbd\uc6b0, \ub525\ub7ec\ub2dd \ubaa8\ub378\uc740 \uc774\ubbf8\uc9c0\ub0b4 \ub2e4\ub978 \uc815\ubcf4\ub97c \ud559\uc2b5\ud560 \uc218 \uc788\ub2e4\n  - \uc0ac\uc9c4 \ud06c\uae30, \uc637, \ud53c\ubd80\uc0c9, \uc0ac\uc9c4 \uc704\uce58, \ub4b7\uc790\uc11d \uc0ac\ub78c\uc758 \uc790\uc138 \ub4f1\n"}}