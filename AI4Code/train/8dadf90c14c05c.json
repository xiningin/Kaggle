{"cell_type":{"9a80de3b":"code","a23e6195":"code","7a316e57":"code","2ac719f1":"code","d198b148":"code","aaa1ad54":"code","f1fa0274":"code","ab63af59":"code","214b68f9":"code","df9a90f3":"code","bcaf7dd3":"code","9391fde4":"code","aa2108e5":"code","e8e82f3f":"code","a8ae2b0b":"code","6549c7b9":"code","4f40631a":"code","2fff5006":"code","efd03381":"code","ae251fa4":"code","dbb27e4c":"code","6b2b7599":"code","b04d0fc4":"code","a81c064f":"code","03988d33":"code","cf7d3ff1":"code","cf621d0d":"code","adc70552":"code","0f39c099":"code","b817d88c":"code","236908f3":"code","ddcd0153":"code","88c70461":"code","5301603f":"code","a7132d83":"code","07551fe8":"code","cbbe2fb7":"code","57420ac5":"markdown","207f21e3":"markdown","a207858d":"markdown","c2f88bfa":"markdown","47ab5798":"markdown","0708b917":"markdown","c9343b43":"markdown","dfd36a35":"markdown","11b736b2":"markdown","907c05e4":"markdown","280cbb6c":"markdown","fbe8343c":"markdown","1bb565f8":"markdown","94ec2171":"markdown","263faa61":"markdown","55b5ba6b":"markdown","f9733d67":"markdown"},"source":{"9a80de3b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","a23e6195":"df = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_new = pd.read_csv('..\/input\/titanic\/test.csv')\ndf = df.drop(columns='PassengerId')\ndf_new = df_new.drop(columns='PassengerId')","7a316e57":"print(df.info())\nprint(df_new.info())","2ac719f1":"# Extract titles from 'Name'\ndf['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf_new['Title'] = df_new.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nmapping = {'Mr' : 'Mr', 'Dr' : 'Dr', 'Miss' : 'Ms', 'Ms' : 'Ms', 'Mrs' : 'Mrs', 'Master' : 'Master', 'Rev' : 'Rev', 'Miss' : 'Ms', 'Mlle' : 'Ms', 'Mme' : 'Mrs',\n'Major' : 'Mill', 'Capt' : 'Mill', 'Col' : 'Mill', 'Lady' : 'Hon', 'Jonkheer' : 'Hon', 'Sir' : 'Hon', 'Don' : 'Hon', 'Countess' : 'Hon', 'Dona' : 'Hon'}\n\ndf.Title = df.Title.map(mapping)\ndf_new.Title = df_new.Title.map(mapping)\nprint('Title Extracted!')\ndf = df.drop(columns='Name')\ndf_new = df_new.drop(columns='Name')\nprint('Name Dropped!')","d198b148":"# Alone or Not\ndef alone_func(family):\n    alone = []\n    for x in family:\n        if x == 0:\n            alone.append(int(1))\n        else:\n            alone.append(int(0))\n    return(alone)","aaa1ad54":"df['Alone'] = alone_func(df.SibSp + df.Parch)\ndf_new['Alone'] = alone_func(df_new.SibSp + df_new.Parch)\nprint('Alone created!')","f1fa0274":"for alone in sorted(df.Alone.unique()):\n    print('Alone ', alone, '({} data)'.format(len(df.Survived[df.Alone == alone])))\n    print(df.Survived[df.Alone == alone].value_counts(normalize=True).sort_index(), '\\n')","ab63af59":"df = df.drop(columns=['SibSp', 'Parch'])\ndf_new = df_new.drop(columns=['SibSp', 'Parch'])\nprint('SibSp and Parch dropped!')","214b68f9":"import re\ndef ticket_func(ticket_data):\n    \"\"\"Split ticket to a dataframe with TicketCat and TicketNo\"\"\"\n    ticket_data = ticket_data.str.upper() # uppercase all entries\n    ticket_data = ticket_data.str.replace('STON', 'SOTON') # fix alleged typos\n    ticket_data = ticket_data.str.split(n=1, expand=True)\n    for i, entry in ticket_data.iterrows():\n        if ticket_data[0][i].isdecimal():\n            ticket_data[1][i] = ticket_data[0][i]\n            ticket_data[0][i] = 'no'\n        ticket_data[0][i] = ''.join(re.findall('[a-zA-Z0-9\/]', ticket_data[0][i])) # match alphanumerical and slash (\/)\n    ticket_data.columns = ['TicketCat', 'TicketNo']\n    ticket_data['TicketNo'] = ticket_data['TicketNo'].fillna(0)\n    return(ticket_data)","df9a90f3":"df[['TicketCat', 'TicketNo']] = ticket_func(df.Ticket)\ndf_new[['TicketCat', 'TicketNo']] = ticket_func(df_new.Ticket)\nprint(df[['TicketCat', 'TicketNo']].head())\nprint(df_new[['TicketCat', 'TicketNo']].head())","bcaf7dd3":"# Check TicketCat in test set which are not available in training set\nsorted([x for x in df_new.TicketCat.unique() if not x in df.TicketCat.unique()])","9391fde4":"df = df.drop(columns=['TicketCat', 'TicketNo', 'Ticket'])\ndf_new = df_new.drop(columns=['TicketCat', 'TicketNo', 'Ticket'])\nprint('Ticket dropped!')","aa2108e5":"def cabin_func(cabin_data):\n    cabin_data = cabin_data.fillna('N') # fill nan with N\n    cabin_data = cabin_data.str[0]\n    cabin_data = cabin_data.str.replace('N', 'NO DATA')\n    return(cabin_data)","e8e82f3f":"df.Cabin = cabin_func(df.Cabin)\ndf_new.Cabin = cabin_func(df_new.Cabin)","a8ae2b0b":"print(sorted(df.Cabin.unique()))\nprint(sorted(df_new.Cabin.unique()))","6549c7b9":"for cabin in sorted(df.Cabin.unique()):\n    print('Cabin ', cabin, '({} data)'.format(len(df.Survived[df.Cabin == cabin])))\n    print(df.Survived[df.Cabin == cabin].value_counts(normalize=True).sort_index(), '\\n')","4f40631a":"print('Missing data in Cabin = {:.2f}% of total training data'.format(len(df[df.Cabin == 'NO DATA'])\/len(df)*100))","2fff5006":"# Cabin\ndf = df.drop(columns=['Cabin'])\ndf_new = df_new.drop(columns=['Cabin'])\nprint('Cabin Dropped!')","efd03381":"df.Age = df.Age.fillna(df.Age.mean()) # impute before binning\ndf_new.Age = df_new.Age.fillna(df.Age.mean()) # impute before binning","ae251fa4":"# Categorize Age Data (Binning)\ndef bin_age(age_data):\n    age_category = []\n    for age in age_data:\n        if age <= 16:\n            age_category.append('A')\n        elif (age > 16) & (age <= 32):\n            age_category.append('B')\n        elif (age > 32) & (age <= 48):\n            age_category.append('C')\n        elif (age > 48) & (age <= 64):\n            age_category.append('D')\n        else:\n            age_category.append('E')\n    return age_category","dbb27e4c":"df['AgeCategory'] = bin_age(df.Age)\ndf_new['AgeCategory'] = bin_age(df_new.Age)\nprint('AgeCategory created!')","6b2b7599":"for cat in sorted(df.AgeCategory.unique()):\n    print('Age Category ', cat, '({} data)'.format(len(df.Survived[df.AgeCategory == cat])))\n    print(df.Survived[df.AgeCategory == cat].value_counts(normalize=True).sort_index(), '\\n')","b04d0fc4":"df = df.drop(columns='Age')\ndf_new = df_new.drop(columns='Age')\nprint('Age dropped!')","a81c064f":"# Impute\ndf.Embarked = df.Embarked.fillna(df.Embarked.value_counts().index[0])\ndf_new.Fare = df_new.Fare.fillna(df_new.Fare.mean())\nprint(df.info())\nprint(df_new.info())","03988d33":"# Check Class\nprint(df.Survived.value_counts(normalize=True))\nprint(df.Survived.value_counts())\ndf.Survived.value_counts(normalize=True).plot(kind='bar')","cf7d3ff1":"X = df.drop(columns='Survived')\nX_pred = df_new\ny = df.Survived\nprint('Training features:')\nprint(X.shape)\nprint('\\nTest features:')\nprint(X_pred.shape)\nprint('\\nTarget:')\nprint(y.shape)","cf621d0d":"# One Hot Encoder\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\nX_categorical = X.select_dtypes(object)\nX_categorical = encoder.fit_transform(X_categorical)\nX_pred_categorical = X_pred.select_dtypes(object)\nX_pred_categorical = encoder.transform(X_pred_categorical)\n\nX_numerical = X.select_dtypes(exclude=object).to_numpy()\nX_pred_numerical = X_pred.select_dtypes(exclude=object).to_numpy()\n\nX = np.concatenate((X_categorical, X_numerical), axis=1)\nX_pred = np.concatenate((X_pred_categorical, X_pred_numerical), axis=1)\n\nprint('Training features:')\nprint(X.shape)\nprint('\\nTest features:')\nprint(X_pred.shape)\nprint('\\nTarget:')\nprint(y.shape)","adc70552":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\nprint('Validation set (30%) ready!')","0f39c099":"from sklearn.metrics import classification_report","b817d88c":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C=0.8)\nlr.fit(X_train, y_train)\nprint(classification_report(y_test, lr.predict(X_test)))","236908f3":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 280)\nrf.fit(X_train, y_train)\nprint(classification_report(y_test, rf.predict(X_test)))","ddcd0153":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators = 280)\ngb.fit(X_train, y_train)\nprint(classification_report(y_test, gb.predict(X_test)))","88c70461":"gb.fit(X, y)\nrf.fit(X, y)\nlr.fit(X, y)\nprint('Training completed!')","5301603f":"proba_gb = gb.predict_proba(X_pred)\nproba_rf = rf.predict_proba(X_pred)\nproba_lr = lr.predict_proba(X_pred)\nproba_avg = (proba_gb + proba_rf + proba_lr) \/ 3\nprint('First 5 class probabilities:')\nprint(proba_avg[:5])","a7132d83":"y_pred = []\nfor proba in proba_avg:\n    if proba[0] > 0.5:\n        y_pred.append(int(0))\n    else:\n        y_pred.append(int(1))\nprint('Target class ratio:')\nprint(pd.Series(y_pred).value_counts(normalize=True))","07551fe8":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nprint(submission.head())\nsubmission.Survived = y_pred\nsubmission.set_index('PassengerId', inplace=True)\nprint(submission.head())","cbbe2fb7":"submission.to_csv('submission.csv')\nprint('Submission saved successfully!')","57420ac5":"## Family (SibSp and Parch)\nI found out that passengers who travel with family are more likely to survive by using the following scripts:","207f21e3":"# Predictions\nTest set predictions are based on **averaged probabilities between those 3 models**.","a207858d":"**NOTES:**\n1. This is **based on my limited knowledge**.\n2. I may have reduce some information by binning Age but so far the results are better by doing so.\n3. I have removed Cabin and Ticket features entirely.","c2f88bfa":"# Feature Engineering\n## Extract Titles From Name","47ab5798":"The null values in the Cabin does not give any information (I think the data is simply missing) therefore Cabin feature is dropped.","0708b917":"# Classification Model Check\nI used **LogisticRegression, RandomForest, and GradientBoosting** methods. I printed out validation test set classification report for each model.","c9343b43":"Because of the category differences in test set and training set, I dropped Ticket features.","dfd36a35":"The classes are well balanced with 60-40 ratio.","11b736b2":"## Cabin","907c05e4":"The output above shows significant differences in survival rate for each AgeCategory therefore Age column will no longer be used.","280cbb6c":"# Feature Preprocessing for ML\nThis chapter includes class balance check, convert categorical with OneHotEncoder, and validation set split (30%).","fbe8343c":"If we look from the output above, the Cabin category might have some impact to the survival probability. However, there are so many missing data in this feature.","1bb565f8":"## Ticket\nI tried to categorize Ticket but unfortunately there are some ticket categories in the test set that are not available in the training set.","94ec2171":"## Impute Missing Values\nIn this notebook, I simply imputed the missing values with mean (for numerical) or most frequent value (for categorical).","263faa61":"## Age\nI binned the Age feature into 5 categories.","55b5ba6b":"From the output above, it is clear that most passengers who travel alone are dead. I also removed SibSp and Parch because they are correlated with Alone feature.","f9733d67":"# Project Summary\nThis is an updated version of my previous notebook. Algorithms used in this notebook are **LogisticRegression**, **RandomForest**, and **GradientBoosting**. I got 0.79425 score from this notebook. This notebook consists of:\n1. Feature Engineering\n2. Feature Preprocessing for ML\n3. Classification Model Check\n4. Predictions\n\nReferences:\n1. https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n2. https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python"}}