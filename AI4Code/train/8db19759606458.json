{"cell_type":{"5e40f5e1":"code","83771d63":"code","729d9e87":"code","13723f5f":"code","50f40aae":"code","56a38f3e":"code","f20ec413":"code","331765e8":"code","cb375dce":"code","7aba07b1":"code","a7915aa6":"code","7adc3515":"code","55031795":"code","f98c4225":"code","3e30a4b6":"code","36d50946":"code","fb9021b7":"code","bf1cd6b4":"code","ce907b9b":"code","fb79faeb":"code","459addcb":"code","2e80cb9b":"code","67a2c402":"code","1269cfd0":"code","38480e04":"code","7b7921fc":"code","04fd6ea2":"code","45e64f40":"code","19a850c0":"code","78d481ce":"code","ae3d5eb3":"code","5201e9ae":"markdown","14f0e2d6":"markdown","11905f75":"markdown","a3f70436":"markdown","7a489ea2":"markdown","fd0557db":"markdown","c3b4f522":"markdown","d996313f":"markdown","cfb206b3":"markdown","bba2be0d":"markdown","02d2a179":"markdown","ff09ce90":"markdown","e06f490b":"markdown","f422cfad":"markdown","1bf868cb":"markdown","d63dbb99":"markdown","8945c75a":"markdown","3759c738":"markdown","8a501897":"markdown"},"source":{"5e40f5e1":"# Importing the Keras libraries and packages\nimport tensorflow as tf\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg19 import VGG19\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Input, Lambda ,Dense ,Flatten\nimport numpy as np","83771d63":"#Initialising vgg16 and vgg 19\nclassifier_vgg16 = VGG16(input_shape= (224,224,3),include_top=False,weights='imagenet')\n\nclassifier_vgg16.summary()","729d9e87":"#don't train existing weights\nfor layer in classifier_vgg16.layers:\n    layer.trainable = False","13723f5f":"classifier1 = classifier_vgg16.output#head mode\nclassifier1 = Flatten()(classifier1)#adding layer of flatten\nclassifier1 = Dense(units=1, activation='sigmoid')(classifier1)#again adding another layer of dense\n\nmodel = Model(inputs = classifier_vgg16.input , outputs = classifier1)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","50f40aae":"model.summary()","56a38f3e":"# Part 2 - Fitting the CNN to the images\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#use the image data generator to import the images from the dataset\n#data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","f20ec413":"#makes sure you provide the same target as initialised for the image size\ntraining_set = train_datagen.flow_from_directory('\/kaggle\/input\/Data\/train',\n                                                 target_size=(224, 224),\n                                                 batch_size=32,\n                                                 class_mode='binary')\n\ntest_set = test_datagen.flow_from_directory('\/kaggle\/input\/Data\/test',\n                                            target_size=(224, 224),\n                                            batch_size=32,\n                                            class_mode='binary')","331765e8":"#fit the model\n#it will take some time to train\nhistory = model.fit_generator(training_set,\n                              validation_data=test_set,\n                              epochs=5,\n                              steps_per_epoch=len(training_set),\n                              validation_steps=len(test_set))","cb375dce":"#save the model\nmodel.save('my_model_vgg16.h5')","7aba07b1":"#evaluate the model\nloaded_model = tf.keras.models.load_model('my_model_vgg16.h5')\nloaded_model.evaluate(test_set)","a7915aa6":"#accuarcy\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7adc3515":"#loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","55031795":"# for only one prediction\nimport numpy as np\nfrom keras.preprocessing import image\n\ntest_image = image.load_img('\/kaggle\/input\/Data\/test\/Covid\/covid-19-pneumonia-28.png',target_size=(224,224))\nplt.imshow(test_image)\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = loaded_model.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'Normal'\nelse:\n    prediction = 'Covid'\nprint(prediction)","f98c4225":"# for only one prediction\nimport numpy as np\nfrom keras.preprocessing import image\n\ntest_image = image.load_img('\/kaggle\/input\/Data\/original test set\/NORMAL2-IM-0112-0001.jpeg',target_size=(224,224))\nplt.imshow(test_image)\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = loaded_model.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'Normal'\nelse:\n    prediction = 'Covid'\nprint(prediction)","3e30a4b6":"# plot confusion metrix\ny_pred = []\ny_test = []\nimport os\n\nfor i in os.listdir(\"\/kaggle\/input\/Data\/test\/Normal\"):\n    img = image.load_img(\"\/kaggle\/input\/Data\/test\/Normal\/\" + i, target_size=(224,224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    p = model.predict(img)\n    y_test.append(p[0, 0])\n    y_pred.append(1)\n\nfor i in os.listdir(\"\/kaggle\/input\/Data\/test\/Covid\"):\n    img = image.load_img(\"\/kaggle\/input\/Data\/test\/Covid\/\" + i, target_size=(224,224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    p = model.predict(img)\n    y_test.append(p[0, 0])\n    y_pred.append(0)\n\ny_pred = np.array(y_pred)\ny_test = np.array(y_test).astype(int)\n\n\n","36d50946":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(y_pred, y_test)\nsns.heatmap(cm, cmap=\"plasma\", annot=True)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_pred, y_test))","fb9021b7":"#Initialising vgg16 and vgg 19\nclassifier_vgg19 = VGG19(input_shape= (224,224,3),include_top=False,weights='imagenet')\n\nclassifier_vgg19.summary()","bf1cd6b4":"#don't train existing weights\nfor layer in classifier_vgg19.layers:\n    layer.trainable = False","ce907b9b":"classifier2 = classifier_vgg19.output#head mode\nclassifier2 = Flatten()(classifier2)#adding layer of flatten\nclassifier2 = Dense(units=64, activation='relu')(classifier2)#adding layer of dense\nclassifier2 = Dense(units=1, activation='sigmoid')(classifier2)#again adding another layer of dense\n\nmodel1 = Model(inputs = classifier_vgg19.input , outputs = classifier2)\nmodel1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","fb79faeb":"model1.summary()","459addcb":"# Part 2 - Fitting the CNN to the images\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#use the image data generator to import the images from the dataset\n#data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","2e80cb9b":"#makes sure you provide the same target as initialised for the image size\ntraining_set = train_datagen.flow_from_directory('\/kaggle\/input\/Data\/train',\n                                                 target_size=(224, 224),\n                                                 batch_size=32,\n                                                 class_mode='binary')\n\ntest_set = test_datagen.flow_from_directory('\/kaggle\/input\/Data\/test',\n                                            target_size=(224, 224),\n                                            batch_size=32,\n                                            class_mode='binary')","67a2c402":"#fit the model\n#it will take some time to train\nhistory = model1.fit_generator(training_set,\n                              validation_data=test_set,\n                              epochs=10,\n                              steps_per_epoch=len(training_set),\n                              validation_steps=len(test_set))","1269cfd0":"#save the model\nmodel1.save('my_model_vgg19.h5')","38480e04":"#evaluate the model\nloaded_model1 = tf.keras.models.load_model('my_model_vgg19.h5')\nloaded_model1.evaluate(test_set)","7b7921fc":"#accuarcy\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","04fd6ea2":"#loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","45e64f40":"# for only one prediction\nimport numpy as np\nfrom keras.preprocessing import image\n\ntest_image = image.load_img('\/kaggle\/input\/Data\/train\/Covid\/1.CXRCTThoraximagesofCOVID-19fromSingapore.pdf-003-fig4b.png',target_size=(224,224))\nplt.imshow(test_image)\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = loaded_model1.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'Normal'\nelse:\n    prediction = 'Covid'\nprint(prediction)","19a850c0":"# for only one prediction\nimport numpy as np\nfrom keras.preprocessing import image\n\ntest_image = image.load_img('\/kaggle\/input\/Data\/original test set\/NORMAL2-IM-0112-0001.jpeg',target_size=(224,224))\nplt.imshow(test_image)\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = loaded_model1.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'Normal'\nelse:\n    prediction = 'Covid'\nprint(prediction)","78d481ce":"# plot confusion metrix\ny_pred2 = []\ny_test = []\nimport os\n\nfor i in os.listdir(\"\/kaggle\/input\/Data\/test\/Normal\"):\n    img = image.load_img(\"\/kaggle\/input\/Data\/test\/Normal\/\" + i, target_size=(224,224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    p = model1.predict(img)\n    y_test.append(p[0, 0])\n    y_pred2.append(1)\n\nfor i in os.listdir(\"\/kaggle\/input\/Data\/test\/Covid\"):\n    img = image.load_img(\"\/kaggle\/input\/Data\/test\/Covid\/\" + i, target_size=(224,224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    p = model1.predict(img)\n    y_test.append(p[0, 0])\n    y_pred2.append(0)\n\ny_pred2 = np.array(y_pred2)\ny_test = np.array(y_test).astype(int)","ae3d5eb3":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(y_pred2, y_test)\nsns.heatmap(cm, cmap=\"plasma\", annot=True)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_pred2, y_test))","5201e9ae":"![download.jpg](attachment:download.jpg)","14f0e2d6":"![1_3-TqqkRQ4rWLOMX-gvkYwA.png](attachment:1_3-TqqkRQ4rWLOMX-gvkYwA.png)","11905f75":"i hope you all are safe. here i am going to make notebook of covid-19 prediction with the help of chesr x-ray. as you can see now in the world the corona virus is spreading more and more and due to that lots of people are dying.","a3f70436":"# What is a Pre-trained Model?\nA pre-trained model has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. Learned features are often transferable to different data. For example, a model trained on a large dataset of bird images will contain learned features like edges or horizontal lines that you would be transferable your dataset.","7a489ea2":"# Architecture of VGG16","fd0557db":"![vgg-ispravljeno-.png](attachment:vgg-ispravljeno-.png)","c3b4f522":"*VGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014. It is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16 is that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters.*","d996313f":"here, i have 3 folders in which train,test and original test set.train and test have sub folders called covid and normal so covid indicating that the x-ray of that person having corona virus and normal folder have images of x-ray that person do not have corona virus. and the last folder which is original test set which includes mix images of covid and normal people x-ray so by that folder's images we will predict by individual images to find out that the x-ray that image is having covid or not","cfb206b3":"![ES_cfEWWkAAHnCr.jpg](attachment:ES_cfEWWkAAHnCr.jpg)","bba2be0d":"# Architecture of VGG16 & VGG19","02d2a179":"In this notebook i have applied two transfer learning methods such as vgg16 and vgg19 where vgg16 is best fitted for our dataset.since we have only 100 images in the dataset that's why our accuracy is not that much good but on this dataset it is very good to have to have 99% validation accuracy","ff09ce90":"***Coronavirus is a family of viruses that are named after their spiky crown. The novel coronavirus, also known as SARS-CoV-2, is a contagious respiratory virus that first reported in Wuhan, China. On 2\/11\/2020, the World Health Organization designated the name COVID-19 for the disease caused by the novel coronavirus. This notebook aims at exploring COVID-19 through data analysis and projections.\n\n***","e06f490b":"# VGG19","f422cfad":"![1_3-TqqkRQ4rWLOMX-gvkYwA.png](attachment:1_3-TqqkRQ4rWLOMX-gvkYwA.png)","1bf868cb":"VGG19 is a similar model architecure as VGG16 with three additional convolutional layers, it consists of a total of 16 Convolution layers and 3 dense layers","d63dbb99":"# Why use a Pre-trained Model?\nPre-trained models are beneficial to us for many reasons. By using a pre-trained model you are saving time. Someone else has already spent the time and compute resources to learn a lot of features and your model will likely benefit from it.","8945c75a":"i have copied all the test folder's images covid and normal and put them in one folder called original test set so we will see how our model perform on that. so,test and original test set folders both have same images but i have also added 35 random images of covid and normal people's x-ray from internet for better understanding.","3759c738":"# Stay safe and healthy.\n","8a501897":"# VGG16"}}