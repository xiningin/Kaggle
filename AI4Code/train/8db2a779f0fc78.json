{"cell_type":{"521dfa1d":"code","f2bd9dc1":"code","bf980221":"code","5f459ce4":"code","5857e19b":"code","385ca90f":"code","1644545c":"code","a45d0548":"code","f57bfef0":"code","ed028b43":"code","7112ae41":"code","62496974":"code","90ded821":"code","97f45cb3":"code","0426ca70":"code","01480d18":"code","067094af":"code","34271973":"code","a4a5acae":"code","f78702c4":"markdown","7ebf75d2":"markdown","88b3b18f":"markdown","1ebeb327":"markdown","099f7346":"markdown","eb098131":"markdown","9e2cb021":"markdown"},"source":{"521dfa1d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom numba import cuda, jit, float32\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport string","f2bd9dc1":"df = pd.read_csv('..\/input\/handwritten-az\/handwritten_data_785.csv')","bf980221":"features = df.values[:,1:]\nlabels = df.values[:,0]\n\nfeatures = features.reshape(len(features), 28, 28)\n\nnr_to_letter = {k:v.upper() for k,v in enumerate(list(string.ascii_lowercase))}","5f459ce4":"plt.title('Letter ' + nr_to_letter[labels[0]])\nplt.imshow(features[0])","5857e19b":"# normalize\nfeatures = features \/ 255.\n\n# on eye encoding\nlabels = np.eye(len(np.unique(labels)))[labels]\n\n# select only 100000 of features and labels\nfeatures, labels = features[:100000], labels[:100000]\n\n# split the dataset\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)","385ca90f":"@cuda.jit\ndef convolution(result, mask, image):\n    i, j = cuda.grid(2)\n\n    image_rows, image_cols = image.shape\n    if (i >= image_rows) or (j >= image_cols):\n        return\n\n    delta_rows = mask.shape[0] \/\/ 2\n    delta_cols = mask.shape[1] \/\/ 2\n\n    s = 0\n    for k in range(mask.shape[0]):\n        for l in range(mask.shape[1]):\n            i_k = i - k + delta_rows\n            j_l = j - l + delta_cols\n\n            if (i_k >= 0) and (i_k < image_rows) and (j_l >= 0) and (j_l < image_cols):\n                s += mask[k, l] * image[i_k, j_l]\n    result[i, j] = s","1644545c":"def softmax(x):\n    ex = np.exp(x)\n    return ex \/ ex.sum()","a45d0548":"def cost(probs,y):\n    return -np.log(np.sum(y * probs))","f57bfef0":"def get_max(result):\n    max_index = []\n    max_arr = []\n\n    for i in range(0, len(result[0]), 7):\n        for j in range(0, len(result), 7):\n            block = result[i:i+7, j:j+7]\n            a, b = np.unravel_index(block.argmax(), block.shape)\n            max_index.append((a + i, b + j))\n            max_arr.append(result[a + i, b + j])\n\n    return max_index, max_arr","ed028b43":"def forward(image, theta, blockparams):\n    w, mask = theta\n    result = np.empty_like(image)\n    convolution[blockparams](result, mask, image)\n\n    max_index, max_arr = get_max(result)\n\n    m = max_arr @ w\n    probs = softmax(m)\n\n    return max_index, max_arr, probs","7112ae41":"def get_dpool(max_index, dm):\n    dpool = np.zeros((28, 28))\n    for i,k in enumerate(max_index):\n        dpool[k[0],k[1]] = dm[i]\n\n    return dpool","62496974":"def backward(image, label, delta, theta, blockparams):\n    w, mask = theta\n    max_index, max_arr, probs = delta\n    dout = probs - label\n\n    dw = np.array(max_arr).reshape(16,1).dot(np.array(dout).reshape(1,26))\n    dm = w @ dout.reshape(26,1) * np.array(max_arr).reshape(16,1)\n    dm = dm.flatten()\n\n    dpool = get_dpool(max_index, dm)\n    \n    # rotate 190 the derivatives of max pool\n    drotated = np.rot90(np.rot90(dpool))\n    \n    dmask = np.zeros((7, 7))\n    convolution[blockparams](dmask, np.ascontiguousarray(drotated, dtype=np.float32), image)\n\n    return dw, dmask","90ded821":"np.random.seed(12342423)\nw = np.random.randn(16, 26) * 0.01\nmask = np.random.randn(7, 7) * 0.01\n\nimage = X_train[0]\n\nblockdim = (28, 28)\ngriddim = (image.shape[0] \/\/ blockdim[0] + 1, image.shape[1] \/\/ blockdim[1] + 1)\n\ntheta = w, mask\nblockparams = griddim, blockdim","97f45cb3":"batches = np.array_split(np.arange(len(X_train)), len(X_train)\/128)\n\ncosts = []","0426ca70":"def train(X, y, theta, batches):\n    w, mask = theta\n\n    for j in range(10):\n        for batch in tqdm(batches):\n            for i in batch:\n                image = np.copy(X[i]).reshape(28,28)\n                delta = forward(X[i], theta, blockparams)\n                dw, dmask = backward(image, y[i], delta, theta, blockparams)\n\n                w -= dw * 0.1 \/ len(batch)\n                mask -= dmask * 0.1 \/ len(batch)\n                theta = w, mask\n\n        if j % 1 == 0:\n            c = cost(delta[-1], y[i])\n            costs.append(c)\n    return theta","01480d18":"theta = train(X_train, y_train, theta, batches)","067094af":"plt.title('Costs over Epochs')\nplt.plot(costs)","34271973":"def get_accuracy(X, y, batches, theta, blockparams):\n    acc = 0\n    for batch in batches:\n        for i in batch:\n            a = np.argmax(forward(X[i], theta, blockparams)[-1])\n            if a == np.argmax(y[i]):\n                acc += 1\n\n    return acc \/ len(batches) \/ len(batch)","a4a5acae":"test_batches = np.array_split(np.arange(len(X_test)), len(X_test)\/128)\naccuracy = get_accuracy(X_test, y_test, test_batches, theta, blockparams)\nprint('Accuracy for all batches:', accuracy)","f78702c4":"# Training","7ebf75d2":"# Softmax and Cost function","88b3b18f":"# Analyze Training Data","1ebeb327":"# Backward Propagation","099f7346":"# Forward Propagation","eb098131":"# CUDA Convolutional","9e2cb021":"# Data Preparation"}}