{"cell_type":{"0b8475c7":"code","99dcbb0a":"code","9a15b736":"code","4a56b1ee":"code","173f45d4":"code","06a22aa6":"code","d4cd2775":"code","e7dc961d":"code","250df69b":"code","9b49e52a":"code","c85a9f02":"code","78d5c57d":"code","3b809ce5":"code","7f9c5d9f":"code","e577e9c8":"code","b9bd09c0":"code","d1a744be":"code","c4cc23a7":"code","ebe04ffc":"code","e574d86c":"code","eb10ab23":"code","7adc786d":"code","08044053":"code","a239c9a4":"code","7cab786f":"code","ca0e8097":"code","bf1d9264":"code","49b72ca8":"code","d99ba924":"code","d8c5025e":"code","81551c26":"code","88e781f7":"code","2b531c07":"code","cfdc52c3":"code","f08cae84":"code","1b1d9f1d":"code","0bfc534d":"code","5eb0d7ba":"code","46c31dce":"code","e1eeedba":"code","c4527e24":"code","d6325405":"code","8b6b10b9":"markdown","993b3cc0":"markdown","eba41299":"markdown","a3957155":"markdown","a418547d":"markdown","5757cb31":"markdown","b6ef201a":"markdown","1bdfef55":"markdown","d9960754":"markdown"},"source":{"0b8475c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99dcbb0a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras import optimizers","9a15b736":"df_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","4a56b1ee":"print(\"train shape : \"+str(df_train.shape))\nprint(\"test shape : \"+str(df_test.shape))\ndf_train.head()","173f45d4":"df_test.head()","06a22aa6":"x_tr=df_train.drop([\"label\"],axis=1)\nx_tr.head()","d4cd2775":"y_tr=df_train.label\ny_tr.head()","e7dc961d":"x_test=df_test\nx_test.head()","250df69b":"from sklearn.model_selection import train_test_split\nx_train,x_cv,y_train,y_cv=train_test_split(x_tr,y_tr,test_size=0.2,random_state=10)","9b49e52a":"x_train.shape,y_train.shape","c85a9f02":"x_cv.shape,y_cv.shape","78d5c57d":"#feature normalisation\nx_train2=x_train.astype(\"float32\")\nx_cv2=x_cv.astype(\"float32\")\nx_test2=x_test.astype(\"float32\")\nx_train2\/=255\nx_test2\/=255\n\n#convert labels to one hot encoder\nnum_digits=10\ny_trainp=y_train\ny_cvp=y_cv\n\ny_train=keras.utils.to_categorical(y_train,num_digits)\ny_cv=keras.utils.to_categorical(y_cv,num_digits)","3b809ce5":"from sklearn.linear_model import LogisticRegression\nlg= LogisticRegression()","7f9c5d9f":"lg.fit(x_train2,y_trainp)","e577e9c8":"from sklearn import metrics\npred=lg.predict(x_cv2)\npred","b9bd09c0":"metrics.accuracy_score(y_cvp, pred)","d1a744be":"metrics.confusion_matrix(y_cvp,pred)","c4cc23a7":"test_pred = pd.DataFrame(pred)\ntest_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\ntest_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\ntest_pred.head()","ebe04ffc":"X_test_image = x_test.iloc[20].values.reshape(28,28)\nprint(\"predicted Number :\" + str(test_pred['Label'].iloc[20]))\ng = plt.imshow(X_test_image)","e574d86c":"from sklearn import svm","eb10ab23":"sm=svm.SVC(C=1,gamma=1,kernel='linear')\nsm.fit(x_train2,y_trainp)","7adc786d":"pred1=sm.predict(x_cv2)\npred1","08044053":"metrics.accuracy_score(y_cvp, pred1)","a239c9a4":"metrics.confusion_matrix(y_cvp,pred1)","7cab786f":"test_pred1 = pd.DataFrame(pred1)\ntest_pred1 = pd.DataFrame(test_pred1.idxmax(axis = 1))\ntest_pred1 = test_pred1.rename(columns = {0: 'Label'}).reset_index()\ntest_pred1.head()","ca0e8097":"X_test_image = x_test.iloc[20].values.reshape(28,28)\nprint(\"predicted Number :\" + str(test_pred1['Label'].iloc[20]))\ng = plt.imshow(X_test_image)","bf1d9264":"from sklearn.ensemble import RandomForestClassifier \nRF=RandomForestClassifier(n_estimators=201,n_jobs=-1) ","49b72ca8":"RF.fit(x_train2,y_trainp)","d99ba924":"pred2=RF.predict(x_cv2)\npred2","d8c5025e":"metrics.accuracy_score(y_cvp, pred2)","81551c26":"metrics.confusion_matrix(y_cvp,pred2)","88e781f7":"test_pred2 = pd.DataFrame(pred2)\ntest_pred2 = pd.DataFrame(test_pred2.idxmax(axis = 1))\ntest_pred2 = test_pred2.rename(columns = {0: 'Label'}).reset_index()\ntest_pred2.head()","2b531c07":"X_test_image = x_test.iloc[20].values.reshape(28,28)\nprint(\"predicted Number :\" + str(test_pred2['Label'].iloc[20]))\ng = plt.imshow(X_test_image)","cfdc52c3":"# Input Parameters\nn_input = 784 # number of features\nn_hidden_1 = 300\nn_hidden_2 = 100\nn_hidden_3 = 100\nn_hidden_4 = 200\nnum_digits = 10\n\ntraining_epochs = 20\nbatch_size = 100","f08cae84":"Inp = Input(shape=(784,))\nx = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\nx = Dropout(0.3)(x)\nx = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\nx = Dropout(0.3)(x)\nx = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\nx = Dropout(0.3)(x)\nx = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\noutput = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)","1b1d9f1d":"model = Model(Inp, output)\nmodel.summary()","0bfc534d":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","5eb0d7ba":"history = model.fit(x_train2, y_train,\n                    batch_size = batch_size,\n                    epochs = training_epochs,\n                    validation_data=(x_cv2, y_cv))","46c31dce":"test_pred3 = pd.DataFrame(model.predict(x_test, batch_size=200))\ntest_pred3 = pd.DataFrame(test_pred3.idxmax(axis = 1))\ntest_pred3 = test_pred3.rename(columns = {0: 'Label'}).reset_index()\ntest_pred3.head()","e1eeedba":"X_test_image = x_test.iloc[20].values.reshape(28,28)\nprint(\"predicted Number :\" + str(test_pred3['Label'].iloc[20]))\ng = plt.imshow(X_test_image)","c4527e24":"# predict results\nresults = model.predict(x_test, batch_size=200)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","d6325405":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"mnist_submission.csv\",index=False)","8b6b10b9":"## Model building - SVM","993b3cc0":"## Model building - Neural networks","eba41299":"## Model building - logistic regression","a3957155":"## Data","a418547d":"## Importing packages","5757cb31":"## Normalization","b6ef201a":"## Final model\n\nThe neural network model gave the validation accuracy of 97% thereby proving it to be the best model.","1bdfef55":"## Split the data","d9960754":"## Model building - Random forest"}}