{"cell_type":{"a2847f91":"code","320ad3cb":"code","6ceb9e6a":"code","0567e082":"code","a560c98b":"code","66a53690":"code","a9fefdef":"code","295e7c91":"code","985ef815":"code","e4bfdb6b":"code","26fcef04":"code","98416988":"code","73bf1aa2":"code","07473be7":"code","0693cf4f":"code","98461304":"code","41c9c306":"code","3134efc4":"code","94d35f2c":"markdown","0a6b38ca":"markdown","4b2028f3":"markdown"},"source":{"a2847f91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","320ad3cb":"# Import Libreary\nimport numpy as np\nimport pandas as pd\nfrom datetime import date\nimport matplotlib.pyplot as plt\n%matplotlib inline","6ceb9e6a":"# Load the Data Set\ntestdata = pd.read_csv(\"\/kaggle\/input\/predice-el-futuro\/test_csv.csv\")\ntraindata = pd.read_csv(\"\/kaggle\/input\/predice-el-futuro\/train_csv.csv\")","0567e082":"# Check the data\ntraindata.info()","a560c98b":"#Design the regex for date extraction \n#2019-03-19 00:00:10 ----Year(4digit)-Month(2digit)-Day(2digit) hour(2digit):min(2digit):second(2digit)\n##                       %Y-%m-%d %H:%M:%S              \n\nfrom pandas import datetime\ndef parserToTimeDatatype(time):\n    return datetime.strptime(time,\"%Y-%m-%d %H:%M:%S\")","66a53690":"# Convert The time to Date Time format\n\nfinalData = pd.read_csv('\/kaggle\/input\/predice-el-futuro\/train_csv.csv',\n                       parse_dates = [1], #Specify which column index has time info\n                       index_col = 1, #Specify which column index as Index column\n                       date_parser=parserToTimeDatatype) #Custom Parser","a9fefdef":"# Check the data after converting\nfinalData.info()","295e7c91":"# Drop the ID column\nfinalData = finalData.iloc[:,[1]]\nfinalData","985ef815":"# Lets Plot the Data\nplt.plot(finalData)","e4bfdb6b":"#Check whether the data is a stationary data or not\n\nmodifiedDF = finalData.diff(periods=1)\nmodifiedDF.dropna(inplace=True)\nmodifiedDF.head()","26fcef04":"plt.plot(modifiedDF)","98416988":"#Autocorrelation Plot --- To understand the behavior of data\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(modifiedDF)\n\n#Out of 100% data, atleast 70% data must follow alternate pattern","73bf1aa2":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(modifiedDF)","07473be7":"#Create Train Test Split\n\nfeatures = modifiedDF.values\ntrain = features[0:64]\ntest = features[64:]","0693cf4f":"#ARIMA Model (Moving Average)\n\nfrom statsmodels.tsa.arima_model import ARIMA\n\n#p - period\n#d - Integral wrt period\n#q - Moving Average Period \n\np = 2\nd = 1\nq = 1\n\nmodelARIMA = ARIMA(train, order=(p,d,q))\nfinalARIMAI = modelARIMA.fit()","98461304":"# Checking the model Summary\nprint(finalARIMAI.summary())","41c9c306":"# # check the error score\nfinalARIMAI.aic","3134efc4":"pred1 = finalARIMAI.forecast(steps=10)[0]\nplt.plot(test)\nplt.plot(pred1)","94d35f2c":"# Modelling Algorithms","0a6b38ca":"# Conclusion: Arima Model is not best fit model for this data set so we will try deeplearning methods","4b2028f3":"# As I observe this autocorrelation plot, since most of the data  points are plotted\n# in opposite polarity, I can conclude the given data is eligible for Time Series\n"}}