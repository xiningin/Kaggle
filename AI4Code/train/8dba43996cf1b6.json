{"cell_type":{"088972ee":"code","ca67b276":"code","15e8d289":"code","1bd1ca8a":"code","56dbda55":"code","a6ad8819":"code","5e95bfd0":"code","6b8e5ef4":"code","59a848af":"code","3c3ea180":"code","5b489c3a":"code","43401b47":"code","65e52046":"code","a430f323":"code","c23736d9":"code","d7246430":"code","9bd6ef20":"code","c5ef2460":"code","129d942e":"code","56a3600f":"code","6c1ddd9b":"code","03a30bec":"code","0ac8acc3":"code","e1f20435":"code","a92a006f":"code","0f47e004":"code","791d43d8":"code","eec843fb":"code","d782b08c":"markdown","52018608":"markdown","54e56848":"markdown","83384db2":"markdown","957ecec2":"markdown","b2b4a370":"markdown","73fb92d3":"markdown","eb4b9895":"markdown","9f5a0967":"markdown","15f44c19":"markdown","c24ca715":"markdown","27571103":"markdown","7683a9fe":"markdown","22fa11f2":"markdown","8d081b04":"markdown","34ca6e48":"markdown","0a3cbcf2":"markdown","51cd420b":"markdown"},"source":{"088972ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca67b276":"raw_train = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/train.csv')\nraw_eval = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/eval.csv')","15e8d289":"raw_train.head(10)","1bd1ca8a":"raw_train.isnull().sum()","56dbda55":"print(raw_train['esrb_rating'].value_counts())\nplt.bar(['T','ET','E','M'],raw_train['esrb_rating'].value_counts())\nplt.title('ESRB Ratings')","a6ad8819":"print(raw_train['esrb_rating'].value_counts() \/ len(raw_train['esrb_rating']))","5e95bfd0":"train_df=raw_train.drop(columns=['id','title'])\ntrain_df","6b8e5ef4":"raw_eval","59a848af":"eval_df = raw_eval.drop(columns=['id'])\n#eval_df['esrb_rating'] = ''","3c3ea180":"eval_df","5b489c3a":"print(raw_train.columns)","43401b47":"# sns.pairplot(raw_train, height=1.2, aspect=1.25)","65e52046":"cols = ['console', 'alcohol_reference', 'animated_blood',\n       'blood', 'blood_and_gore', 'cartoon_violence', 'crude_humor',\n       'drug_reference', 'fantasy_violence', 'intense_violence', 'language',\n       'lyrics', 'mature_humor', 'mild_blood', 'mild_cartoon_violence',\n       'mild_fantasy_violence', 'mild_language', 'mild_lyrics',\n       'mild_suggestive_themes', 'mild_violence', 'no_descriptors', 'nudity',\n       'partial_nudity', 'sexual_content', 'sexual_themes',\n       'simulated_gambling', 'strong_janguage', 'strong_sexual_content',\n       'suggestive_themes', 'use_of_alcohol', 'use_of_drugs_and_alcohol',\n       'violence']\n\nfor col in cols:\n    sns.set_style('whitegrid')\n    sns.countplot(x='esrb_rating', hue=col, data=raw_train, palette='RdBu_r').set(title=col)\n    plt.show()\n","a430f323":"train_df = train_df.drop(columns=['console'])\neval_df = eval_df.drop(columns=['console'])","c23736d9":"mapping = {'E':'E', 'ET':'ET', 'T':'T', 'M':'M'}\nrating_cols = pd.get_dummies(train_df['esrb_rating'].map(mapping))\ntrain_df = train_df.join(rating_cols)","d7246430":"train_df","9bd6ef20":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nX = train_df.drop(columns=['esrb_rating','E','ET','T','M'])\ny = train_df['esrb_rating']","c5ef2460":"def build_model(model):\n    kf = KFold(n_splits=10, random_state=42,shuffle=True)\n    scores_list = []\n    for train_index,test_index in kf.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        build = model.fit(X_train,y_train)\n        prediction = build.predict(X_test)\n        scores_list.append(model.score(X_train,y_train))\n    return prediction,scores_list","129d942e":"from sklearn.linear_model import LogisticRegression\nlog_clf = LogisticRegression(random_state = 0)\nlog_clf_pred, scores_list = build_model(log_clf)\nprint(pd.Series(scores_list).describe())\n# for testing: printing the values that aren't correct\n#[print(i,j) for i, j in zip(log_clf_pred,target) if i != j]","56a3600f":"from sklearn.svm import SVC\nsvc_clf = SVC()\nsvc_clf_pred, scores_list = build_model(svc_clf)\nprint(scores_list)\nprint(pd.Series(scores_list).describe())","6c1ddd9b":"from sklearn.tree import DecisionTreeClassifier \ndt_clf = DecisionTreeClassifier()\ndt_clf_pred, scores_list = build_model(dt_clf)\nprint(scores_list)\nprint(pd.Series(scores_list).describe())","03a30bec":"from sklearn.neighbors import KNeighborsClassifier\nnnb = KNeighborsClassifier()\nnnb_pred, scores_list = build_model(nnb)\nprint(scores_list)\nprint(pd.Series(scores_list).describe())","0ac8acc3":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001,0.0001],'kernel': ['linear','rbf', 'poly', 'sigmoid']}\ngrid_svm = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\ngrid_svm.fit(X_train,y_train)\ngrid_svm.score(X_train,y_train)","e1f20435":"print(grid_svm.best_estimator_)","a92a006f":"print(pd.Series(grid_svm.cv_results_[\"mean_test_score\"]).describe())","0f47e004":"#from sklearn.pipeline import Pipeline\n#from sklearn.model_selection import GridSearchCV\n#from sklearn.preprocessing import MinMaxScaler\n#from sklearn.neighbors import KNeighborsClassifier\n\n#pipeline = Pipeline([('mms', MinMaxScaler()), ('knn', KNeighborsClassifier())])\n#param_grid = [\n#    {'knn__n_neighbors' : [17,19,21,23,25,27,29,31,33,35],\n#     'knn__weights' : ['uniform','distance'],\n#     'knn__leaf_size' : [5,10,15,20,25]\n#    }\n#]\n#X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n#gridsearch_knn = GridSearchCV(pipeline, param_grid = param_grid, scoring='accuracy',cv=5)\n#gridsearch_knn.fit(X_train,y_train)\n#print(gridsearch_knn.best_params_)\n#gridsearch_knn.score(X_train,y_train)\n","791d43d8":"#from sklearn.pipeline import Pipeline\n#from sklearn.model_selection import GridSearchCV\n#from sklearn.preprocessing import MinMaxScaler\n#from sklearn.tree import DecisionTreeClassifier\n\n#tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150,180,210,230]}\n#X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n#gridsearch_dtclf = GridSearchCV(DecisionTreeClassifier(), param_grid = tree_para, scoring='accuracy',cv=10)\n#gridsearch_dtclf.fit(X_train,y_train)\n#print(gridsearch_dtclf.cv_results_)\n#gridsearch_dtclf.score(X_train,y_train)","eec843fb":"predict = grid_svm.predict(eval_df)\noutput = pd.DataFrame({'id': raw_eval['id'], 'esrb_rating': predict})\nprint(output.to_string())\noutput.to_csv('submission.csv',index=False)\nprint(\"Your submission was successfully saved!\")","d782b08c":"## Exploratory Data Analysis","52018608":"#### Checking for missing values...","54e56848":"##### percentages of ratings across the training set:","83384db2":"#### K Nearest Neighbors Model","957ecec2":"## Data transformations & Feature Engineering...","b2b4a370":"## Loading data...","73fb92d3":"#### Support Vector Machine Model","eb4b9895":"1. Cross reference and check relationships with columns with their rankings..\n2. ","9f5a0967":"## Handling outliers...","15f44c19":"#### Adding labels to the 'esrb_rating'. These new columns give a y\/n answer, trying to explore multiclass vs. binary classifying ","c24ca715":"## Building the models...\n#### Note to self: Try hyperparameter searching, try XGBoost","27571103":"##### hey! it appears that the dataset has no missing values!","7683a9fe":"The dataset contains a list of games, their qualities and their Entertainment Software Board Ratings. ","22fa11f2":"### Not all columns seem to show patterns giving reason for a game to be rated one way or another. The following columns show some correlation:\n1. strong_language\n2. blood\n3. blood_and_gore\n","8d081b04":"## Selecting the best model and save to a submission model!\n#### make sure to print out the output....","34ca6e48":"## Checking for outliers","0a3cbcf2":"#### Decision Tree Model","51cd420b":"#### Logistic Regression Model"}}