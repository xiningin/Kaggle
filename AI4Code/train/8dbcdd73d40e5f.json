{"cell_type":{"e95dbed0":"code","2401b3cb":"code","ff15e36c":"code","860730ee":"code","b1be89a8":"code","f5fcc22d":"code","3e5bcea0":"code","57b55aa7":"code","d0049fae":"code","0acb546e":"code","42cecc34":"code","2203534c":"code","a23ac659":"code","9210f2ec":"code","e6983c6c":"code","e151580d":"code","33a11452":"code","b2c13785":"markdown","f07ba282":"markdown","7b056ca0":"markdown","3211cf5a":"markdown","06d9e89e":"markdown","969376ce":"markdown","a234b12e":"markdown"},"source":{"e95dbed0":"import tensorflow as tf\nimport keras \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport sys\nimport random","2401b3cb":"image_size = 2048\ninput_size = 331","ff15e36c":"def rand_crop(img):\n    h = random.randint(2*input_size, image_size) #2*input_size to prevent cropping too small\n    cx = random.randint(0, image_size-h)\n    cy = random.randint(0, image_size-h)\n    cropped_img = img[cx:cx+h,cy:cy+h,:]\n    return cv2.resize(cropped_img, (input_size,input_size))","860730ee":"def img_transf(imgs):\n    if len(imgs.shape) == 4:\n        for i in range(imgs.shape[0]):\n            for j in range(imgs.shape[-1]):\n                imgs[i,...,j] \/= imgs[i,...,j].max()\n    elif len(imgs.shape) == 3 or 2:\n        for j in range(imgs.shape[-1]):\n            imgs[...,j] \/= imgs[...,j].max()\n    else:\n        print('Input shape not recognised')\n    return imgs","b1be89a8":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\ndata_dir = '..\/input\/neuron cy5 data\/Neuron Cy5 Data'\n\ndata_gen = ImageDataGenerator(horizontal_flip=True,\n                              vertical_flip=True,\n                              validation_split=0.2,\n                              preprocessing_function = img_transf)\ntrain_gen = data_gen.flow_from_directory(data_dir, \n                                         target_size=(image_size,image_size),\n                                         color_mode='grayscale',\n                                         class_mode='categorical',\n                                         batch_size=32, \n                                         shuffle=True, \n                                         subset='training')\ntest_gen = data_gen.flow_from_directory(data_dir, \n                                         target_size=(image_size, image_size),\n                                         color_mode='grayscale',\n                                         class_mode='categorical',\n                                         batch_size=32, \n                                         shuffle=True, \n                                         subset='validation')\n\nclasses = dict((v, k) for k, v in train_gen.class_indices.items())\nnum_classes = len(classes)","f5fcc22d":"def crop_gen(batches):\n    while True:\n        batch_x, batch_y = next(batches)\n        batch_crops = np.empty((batch_x.shape[0], input_size, input_size, 1))\n        for i in range(batch_x.shape[0]):\n            batch_crops[i,...,0] = rand_crop(batch_x[i])\n        yield (batch_crops, batch_y)","3e5bcea0":"from keras.preprocessing.image import ImageDataGenerator\ndata_dir = '..\/input\/neuron cy5 data\/Neuron Cy5 Data'\n\ndata_gen = ImageDataGenerator(horizontal_flip=True,\n                              vertical_flip=True,\n                              validation_split=0.2,\n                              preprocessing_function = img_transf)\ntrain_gen = data_gen.flow_from_directory(data_dir, \n                                         target_size=(image_size,image_size),\n                                         color_mode='grayscale',\n                                         class_mode='categorical',\n                                         batch_size=32, \n                                         shuffle=True, \n                                         subset='training')\ntest_gen = data_gen.flow_from_directory(data_dir, \n                                         target_size=(image_size, image_size),\n                                         color_mode='grayscale',\n                                         class_mode='categorical',\n                                         batch_size=32, \n                                         shuffle=True, \n                                         subset='validation')\n\nclasses = dict((v, k) for k, v in train_gen.class_indices.items())\nnum_classes = len(classes)","57b55aa7":"from tensorflow.python.keras.applications import VGG16\nfrom tensorflow.python.keras.layers import Conv2D, Reshape, MaxPooling2D\nfrom tensorflow.python.keras.models import Model\n\npretrained_model = VGG16(include_top=False,\n                         pooling='none',\n                         input_shape=(input_size, input_size, 3),\n                         weights='imagenet')\nx = MaxPooling2D(pool_size=(10,10), strides=(1,1))(pretrained_model.output)  #pool size chosen as 10x10 to ensure that the output shape is \nx = Conv2D(filters=256, kernel_size=1, activation='relu')(x) #dense layers are replaced with Conv2D to allow different input sizes\nx = Conv2D(filters=64, kernel_size=1, activation='relu')(x)\nx = Conv2D(filters=num_classes, kernel_size=1, activation='softmax')(x)\noutp = Reshape([2])(x) #only for training\nvgg16_model = Model(pretrained_model.input, outp)\n\ncfg = vgg16_model.get_config()\ncfg['layers'][0]['config']['batch_input_shape'] = (None, None, None, 1) #any size image can be input\nmodel = Model.from_config(cfg)\n  \nfor i, layer in enumerate(model.layers):\n    if i == 1:\n        new_weights = np.reshape(vgg16_model.layers[i].get_weights()[0].sum(axis=2),(3,3,1,64))\n        model.set_weights([new_weights])\n        layer.trainable = False\n    elif len(model.layers) - i > 3: #freeze all but last 3 layers\n        layer.trainable = False\n        layer.set_weights(vgg16_model.layers[i].get_weights())\n    else:\n        layer.trainable = True \n        layer.set_weights(vgg16_model.layers[i].get_weights())\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","d0049fae":"history = model.fit_generator(crop_gen(train_gen),\n                              epochs=10,\n                              steps_per_epoch=4*len(train_gen), #effectively 1 run through every possibility of reflected data\n                              validation_data=crop_gen(test_gen),\n                              validation_steps=len(test_gen), \n                              verbose=1)","0acb546e":"from tensorflow.python.keras.optimizers import Adam\n\nfor layer in model.layers:\n    layer.trainable = True\n\nadam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #20x smaller than standard\nmodel.compile(optimizer=adam_fine, loss='binary_crossentropy', metrics=['accuracy'])","42cecc34":"history2 = model.fit_generator(crop_gen(train_gen),\n                              epochs=10,\n                              steps_per_epoch=4*len(train_gen), #effectively 1 run through every possibility of reflected data\n                              validation_data=crop_gen(test_gen),\n                              validation_steps=len(test_gen), \n                              verbose=1)","2203534c":"full_history = dict()\nfor key in history.history.keys():\n    full_history[key] = history.history[key]+history2.history[key][1:] #first epoch is wasted due to initialisation of momentum\n    \nplt.plot(full_history['loss'])\nplt.plot(full_history['val_loss'])\nplt.legend(['loss','val_loss'], loc='upper right')\nplt.title('Full Learning curve for the training process')\nplt.show()\nprint('Final val_acc: '+full_history['val_acc'][-1].astype(str))","a23ac659":"swmodel = Model(model.input, model.layers[-2].output)\nswmodel.summary()","9210f2ec":"def lcm(a,b): \n    from math import gcd\n    return (a*b)\/\/gcd(a,b)","e6983c6c":"X_test, y_test = test_gen.next()\ny_pred_maps = swmodel.predict(X_test, batch_size=1, verbose=1)","e151580d":"y_pred_var = y_pred_maps[...,0].var(axis=(1,2))\nidx = np.argmax(y_pred_var)\nuns_img = X_test[idx,...,0]\nuns_img = np.uint8(255*uns_img)\nuns_img = cv2.cvtColor(uns_img,cv2.COLOR_GRAY2RGB)\nheatmap = y_pred_maps[idx,...,0] #This heatmap will give high values for treated areas\nheatmap \/= heatmap.max() #For visulisation\nheatmap = np.pad(heatmap, mode='constant', pad_width=1, constant_values=0.5)\nheatmap = np.uint8(255*cv2.resize(heatmap, (image_size, image_size)))\nheatmap = cv2.applyColorMap(255-heatmap, cv2.COLORMAP_JET) #255-heatmap so that red is high values\nsuperimposed_map = cv2.addWeighted(uns_img, 0.6, heatmap, 0.4, 0)\nplt.imshow(superimposed_map)\nplt.title('Classification map for most uncertain prediction:')\nplt.show()\nprint('Actual class: '+classes[y_test[idx,0]])","33a11452":"heatmap = y_pred_maps[idx,...,0] #This heatmap will give high values for treated areas\nheatmap \/= heatmap.max() #For visulisation\nheatmap = np.uint8(255*cv2.resize(heatmap, (image_size, image_size)))\npooled_heatmap = np.empty(heatmap.shape)\nheatmap = np.pad(heatmap, mode='reflect', pad_width=150)\nfor i in range(pooled_heatmap.shape[0]):\n    percent = i*100\/pooled_heatmap.shape[0]\n    prog = ' Pooling: ' +str(percent) +'%';\n    sys.stdout.write('\\r'+prog)\n    for j in range(pooled_heatmap.shape[1]):\n        pooled_heatmap[i,j] = np.mean(heatmap[i:i+331, j:j+331])\nsys.stdout.write('\\rDone                   ')\npooled_heatmap = np.uint8(pooled_heatmap.round())\npooled_heatmap = cv2.applyColorMap(255-pooled_heatmap, cv2.COLORMAP_JET) #255-heatmap so that red is high values\nsuperimposed_map = cv2.addWeighted(uns_img, 0.6, pooled_heatmap, 0.4, 0)\nplt.imshow(superimposed_map)\nplt.title('Pooled classification map for most uncertain prediction:');","b2c13785":"Now that the model has been compiled, it can be trained on the data. First just the last 3 layers and then the entire network with a reduced learning rate.","f07ba282":"Now to implement the Slidng Windows algorithm convolutionally. The Fully Connected layers at the end of the model are replaced with 1x1 2D convolution filters. This means that when a large image is given to the model, a map is output as opposed to just a single classification.","7b056ca0":"Once the model is trained sufficiently, a new model is created without the final reshape layer. This allows it to implement the sliding windows algorithm and doesn't fix the size of the output.","3211cf5a":"Now the data is ran through this model in 2048x2048 resolution. This produces a #### classification map for each image.\n\nThe classification map with the most variance is then plotted.","06d9e89e":"Standard imports","969376ce":"Now for image processing functions and loading the model itself.","a234b12e":"This heatmap is good, however it isn't actually highlighting the regions of interest, rather boxes around them. In attempt to make a heatmap that highlights important features, local Average Pooling is implemented with a filter size of 331x331."}}