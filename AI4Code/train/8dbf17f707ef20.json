{"cell_type":{"439cf442":"code","4be0859d":"code","02fbdd1d":"code","a9cc6e2f":"code","f04b98f9":"code","a70f9e93":"code","5a43c508":"code","52516e80":"code","c9c93777":"code","0752141d":"code","fa29433e":"code","be6f1f67":"code","a0eb2635":"code","16f96dab":"code","6eda2cbf":"code","794770b9":"code","efce4b20":"code","6475256d":"code","36378cf6":"code","8a8ef77c":"code","2cf9cf7e":"code","3d85f21d":"code","03ae2734":"code","3501126e":"code","65e9eb06":"code","98d40cdf":"code","14c72737":"code","b64175f9":"code","742d3d25":"markdown","172c3fe8":"markdown"},"source":{"439cf442":"import numpy as np\nimport pandas as pd\nimport gc\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report\nfrom IPython.display import clear_output\nimport time","4be0859d":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Sequential, Input, initializers, optimizers, callbacks, layers\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import SimpleRNN\nfrom keras.layers import GRU\nfrom tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, BatchNormalization, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","02fbdd1d":"df = pd.read_csv(\"..\/input\/national-stock-exchange-time-series\/infy_stock.csv\",\n                 usecols=['Date', 'Close'], parse_dates=['Date'],index_col='Date')\ndf.shape","a9cc6e2f":"print(\"Min:\",df.index.min())\nprint(\"Max:\",df.index.max())","f04b98f9":"plt.figure(figsize=(17,5))\nplt.plot(df['Close'])\nplt.title(\"Closing Price\",fontsize=20)\nplt.show()","a70f9e93":"prices = pd.concat([df.Close[:'2015-06-12']\/2,df.Close['2015-06-15':]])\nplt.figure(figsize=(17,5))\nplt.plot(prices)\nplt.title(\"New closing Price\",fontsize=20)\nplt.show()","5a43c508":"scaler = StandardScaler()\nprices = scaler.fit_transform(prices.values.reshape(-1, 1)).flatten()\ntrain, test = train_test_split(prices, test_size=0.3, shuffle=False)","52516e80":"plt.figure(figsize=(17,5))\nplt.plot(train, label='train')\nplt.plot(np.arange(len(train), len(train)+len(test)), test, label='test')\nplt.title(\"Train and Test periods\", fontsize=20)\nplt.legend()","c9c93777":"def get_chunks(train, n_input, n_out=7):\n    X, y = list(), list()\n    in_start = 0\n    for _ in range(len(train)):\n        in_end = in_start + n_input\n        out_end = in_end + n_out\n        if out_end <= len(train):\n            x_input = train[in_start:in_end]\n            x_input = x_input.reshape((len(x_input), 1))\n            X.append(x_input)\n            y.append(train[in_end:out_end])\n            in_start += 1\n    return np.array(X),np.array(y)","0752141d":"n_input = 7\nX_train, y_train = get_chunks(train, n_input=n_input, n_out=1)\nX_test, y_test = get_chunks(test, n_input=n_input, n_out=1)","fa29433e":"X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))","be6f1f67":"fit_params = {\n        'x': X_train,\n        'y': y_train,\n        'validation_data': (X_test, y_test),\n        'verbose': 1,\n        'epochs': 40,\n        'batch_size': 16}","a0eb2635":"def results_plot(history):\n    \n    plt.figure(figsize=(17,5))\n    plt.plot(history.history['loss'], color='b', label=\"train loss\")\n    plt.plot(history.history['val_loss'], color='r', label=\"val loss\")\n\n    plt.plot()\n    \ndef plot_preds(y_test, preds):\n    \n    plt.figure(figsize=(17,5))\n    plt.plot(preds, label='preds')\n    plt.plot(y_test, label='test')\n    plt.legend()\n    plt.title('Real test and predicted')\n    plt.show()","16f96dab":"def mae(y_true, y_pred):\n    output_errors = np.average(np.abs(y_pred - y_true), axis=0)\n    return np.average(output_errors)\n\ndef mape(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(((y_pred - y_true) ** 2).mean())\n\ndef brief_stats(y_true, y_pred):\n    print(pd.Series({\n        'mape': mape(y_true, y_pred),\n        'mae': mae(y_true, y_pred),\n        'rmse': rmse(y_true, y_pred),\n    }))","6eda2cbf":"def base_rnn():\n    model = Sequential()\n    model.add(SimpleRNN(1, input_shape=(1,n_input),\n                   return_sequences=False\n                  ))\n    model.compile(loss='mse', optimizer='adam')\n    return model","794770b9":"rnn_model = base_rnn()\nhistory_rnn =  rnn_model.fit(**fit_params)\nresults_plot(history_rnn)\n\npreds = rnn_model.predict(X_test).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","efce4b20":"def lstm1():\n    model = Sequential()\n    model.add(LSTM(12, activation='relu', input_shape=(1,n_input),\n                   return_sequences=True\n                  ))\n    model.add(TimeDistributed(Dense(1)))\n    model.compile(loss='mse', optimizer='adam')\n    \n    return model","6475256d":"lstm_model = lstm1()\nhistory_lstm =  lstm_model.fit(**fit_params)\nresults_plot(history_lstm)\n\npreds = lstm_model.predict(X_test).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","36378cf6":"def gru1():\n    model = Sequential()\n    model.add(GRU(12, activation='relu', input_shape=(1,n_input),\n                   return_sequences=True\n                  ))\n    model.add(TimeDistributed(Dense(1)))\n    model.compile(loss='mse', optimizer='adam')\n    return model","8a8ef77c":"gru_model = gru1()\nhistory_gru = gru_model.fit(**fit_params)\nresults_plot(history_gru)\n\npreds = gru_model.predict(X_test).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","2cf9cf7e":"def gru2():\n    model = Sequential()\n    model.add(GRU(48, activation='relu', input_shape=(1,n_input),\n                   return_sequences=True,\n                   recurrent_dropout = 0.1\n                  ))\n    model.add(GRU(12, activation='relu', input_shape=(1,n_input),\n                   return_sequences=True,\n                   recurrent_dropout = 0.1\n                  ))\n    model.add(TimeDistributed(Dense(9)))\n    model.add(TimeDistributed(Dense(1)))\n    model.compile(loss='mse', optimizer='adam')\n    return model","3d85f21d":"gru_model = gru2()\nhistory_gru = gru_model.fit(**fit_params)\nresults_plot(history_gru)\n\npreds = gru_model.predict(X_test).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","03ae2734":"def gru3():\n    model = Sequential()\n    model.add(GRU(48, input_shape=(1,n_input),\n                   return_sequences=True,\n                  ))\n    model.add(GRU(32,input_shape=(1,n_input),\n                   return_sequences=True,\n                   dropout = 0.3\n                  ))\n    model.add(TimeDistributed(Dense(32)))\n    model.add(TimeDistributed(Dense(1)))\n    model.compile(loss='mse', optimizer='adam')\n    return model","3501126e":"gru_model = gru3()\nhistory_gru = gru_model.fit(**fit_params)\nresults_plot(history_gru)\n\npreds = gru_model.predict(X_test).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","65e9eb06":"from keras.layers import Conv1D, MaxPooling1D, Conv2D, Flatten\n\ndef conv_gru():\n    model = Sequential()\n    model.add(Conv1D(filters=32, kernel_size=2, activation='relu',\n                     input_shape=(X_test_1d.shape[1],X_test_1d.shape[2])))\n\n    model.add(GRU(48, activation='relu', \n                   return_sequences=True,\n                  ))\n    model.add(Flatten())\n\n    model.add(Dense(32))\n    model.add(Dropout(0.3))\n    model.add(Dense(1))\n    model.compile(loss='mse', optimizer='adam')\n    return model","98d40cdf":"X_train_1d = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[1],)\nX_test_1d = X_test.reshape(X_test.shape[0], X_test.shape[2], X_test.shape[1],)","14c72737":"conv_gru_model = conv_gru()\nhistory = conv_gru_model.fit(X_train_1d, y_train,\n                                   validation_data = (X_test_1d, y_test),\n                                   batch_size =32,\n                                   epochs = 40)\nresults_plot(history)\n\npreds = conv_gru_model.predict(X_test_1d).flatten()\nplot_preds(y_test[:, 0], preds)\nbrief_stats(y_test[:, 0], preds)","b64175f9":"from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\nplot_acf(prices)\nplot_pacf(prices)","742d3d25":"15\/06\/2015 \u0441\u043f\u043e\u0441\u0442\u0435\u0440\u0456\u0433\u0430\u0454\u0442\u044c\u0441\u044f \u0432\u0435\u043b\u0438\u0447\u0435\u0437\u043d\u0435 \u043f\u0430\u0434\u0456\u043d\u043d\u044f, \u0446\u0435 \u0431\u0443\u043b\u043e \u0440\u043e\u0437\u0434\u0456\u043b\u0435\u043d\u043d\u044f \u0446\u0456\u043d\u0438 \u0430\u043a\u0446\u0456\u0439. \u042f\u043a\u0449\u043e \u0432\u0437\u044f\u0442\u0438 \u0446\u0456 \u0434\u0430\u043d\u0456, \u043f\u0440\u043e\u0433\u043d\u043e\u0437 \u043c\u043e\u0436\u0435 \u0431\u0443\u0442\u0438 \u043d\u0435 \u0442\u0430\u043a\u0438\u043c, \u044f\u043a \u043e\u0447\u0456\u043a\u0443\u0432\u0430\u043b\u043e\u0441\u044c, \u043e\u0441\u043a\u0456\u043b\u044c\u043a\u0438 \u043c\u0456\u0436 \u043d\u0438\u043c\u0438 \u0454 \u0440\u043e\u0437\u043a\u043e\u043b.\n\n\u041c\u0438 \u043f\u043e\u0432\u0438\u043d\u043d\u0456 \u0430\u0431\u043e \u0432\u0456\u0434\u043a\u0438\u043d\u0443\u0442\u0438 \u043f\u0435\u0440\u0456\u043e\u0434, \u0430\u0431\u043e \u0441\u043a\u043e\u0440\u0435\u0433\u0443\u0432\u0430\u0442\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f \u043f\u0435\u0440\u0435\u0434 \u0440\u043e\u0437\u0434\u0456\u043b\u0435\u043d\u043d\u044f\u043c. \u041e\u0441\u043a\u0456\u043b\u044c\u043a\u0438 \u0440\u043e\u0437\u0434\u0456\u043b\u0435\u043d\u043d\u044f \u0434\u043e\u0440\u0456\u0432\u043d\u044e\u0454 2 \u0434\u043b\u044f 1 \u043f\u0435\u0440\u0456\u043e\u0434\u0443, \u043c\u0438 \u043c\u043e\u0436\u0435\u043c\u043e \u043d\u043e\u0440\u043c\u0430\u043b\u0456\u0437\u0443\u0432\u0430\u0442\u0438 \u0434\u0430\u043d\u0456 \u0434\u043e \u043f\u043e\u0434\u0456\u043b\u0443, \u043f\u043e\u0434\u0456\u043b\u0438\u0432\u0448\u0438 \u0457\u0445 \u043d\u0430 2. (\u0421\u0442\u0430\u0440\u0456 \u0447\u0430\u0441\u0442\u043a\u0438 \u0432\u0434\u0432\u0456\u0447\u0456 \u043c\u0435\u043d\u0448\u0456, \u043d\u0456\u0436 \u0441\u044c\u043e\u0433\u043e\u0434\u043d\u0456\u0448\u043d\u0456).","172c3fe8":"# \u041d\u0430\u0432\u0447\u0430\u043d\u043d\u044f \u0440\u0435\u043a\u0443\u0440\u0435\u043d\u0442\u043d\u0438\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0438\u0445 \u043c\u0435\u0440\u0435\u0436 \u0437\u0430\u0441\u043e\u0431\u0430\u043c\u0438 TensorFlow\n**\u0421\u0430\u043c\u043e\u0448\u0438\u043d \u0410\u043d\u0434\u0440\u0456\u0439 \u041a\u0410-83**"}}