{"cell_type":{"1c0356e8":"code","77d1efb4":"code","30141207":"code","e3c40a6b":"code","3e7cd5f8":"code","4d985cfd":"code","7002e7af":"code","2542259f":"code","3f6ad7d0":"code","af490a92":"code","48447d94":"code","f22f37f9":"code","d3e60cad":"code","087b4b2c":"code","b8bad24b":"code","3480c3ee":"code","6becb918":"code","312d02c9":"code","dcfa7bdf":"code","8788e2e1":"code","cc1d19f0":"code","b0f092fd":"code","d160646f":"code","ca658573":"code","1776655e":"code","3e601ac6":"code","980fda87":"code","cf9184bd":"code","780a6edf":"code","47ac25ae":"code","05b6f871":"markdown","43a7320b":"markdown"},"source":{"1c0356e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77d1efb4":"import seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.combine import SMOTETomek\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\n\n","30141207":"df = pd.read_csv('\/kaggle\/input\/company-bankruptcy-prediction\/data.csv')\ndf.head()","e3c40a6b":"df.shape","3e7cd5f8":"df.info()","4d985cfd":"df.isna().values.sum()","7002e7af":"df.columns = df.columns.str.strip()\ndf.rename(columns={'Bankrupt?': 'Bankrupt'}, inplace=True)","2542259f":"fig = px.bar(x=df['Bankrupt'].value_counts().index, y=df['Bankrupt'].value_counts(), text=(df['Bankrupt'].value_counts()\/len(df['Bankrupt'])*100),\n            height=500, width=600, title='Bankrupcy')\nfig.update_traces(textposition='outside', texttemplate='%{text:.4s}%', marker=dict(color = 'snow', line=dict(color='black', width=3)))\nfig.show()","3f6ad7d0":"fig = px.histogram(x=df['Total Asset Growth Rate'],\n                   color=df['Bankrupt'], \n                   log_y=True,\n                   template='ggplot2',\n                  title='Income VS Bankrupcy',\n                  width=700)\nfig.show()","af490a92":"fig = px.histogram(x=df['Cash\/Total Assets'], \n                   color=df['Bankrupt'], \n                   log_y=True,\n                   color_discrete_sequence=['lightcyan','teal'],\n                  width=700,\n                  title='Total Cash VS Bankrupcy')\nfig.show()","48447d94":"x = df.drop('Bankrupt',1)\ny=df['Bankrupt']\n\nprint(x.shape)\nprint(y.shape)","f22f37f9":"sc = StandardScaler()\nx = sc.fit_transform(x)\ny = pd.factorize(y)[0]","d3e60cad":"x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=101, test_size=0.2, shuffle=True )","087b4b2c":"lgr = LogisticRegression(max_iter=100000)\nlgr.fit(x_train, y_train)\n\ny_pred = lgr.predict(x_test)\n\n\nprint('Accuracy of Logistic Regression is: ', accuracy_score(y_test,y_pred))\nprint('Recall Score of Logistic Regression is: ', metrics.recall_score(y_test, y_pred))","b8bad24b":"lgbm = LGBMClassifier()\nlgbm.fit(x_train, y_train)\n\ny_pred = lgbm.predict(x_test)\n\n\n\nprint('Accuracy of LGBM Classifier is: ', accuracy_score(y_test,y_pred))\nprint('Recall Score of LGBM Classifier is: ', metrics.recall_score(y_test, y_pred))","3480c3ee":"xgb = XGBClassifier()\nxgb.fit(x_train, y_train)\n\ny_pred = xgb.predict(x_test)\n\nprint('Accuracy of XGB Classifier is: ', accuracy_score(y_test,y_pred))\nprint('Recall Score of XGB Classifier is: ', metrics.recall_score(y_test, y_pred))\n","6becb918":"x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, random_state=101, test_size=0.2, shuffle=True )","312d02c9":"# Before Applying Smote\n\none_count = 0\nzero_count =0\n\nfor i in y_train1:\n    if i==1:\n        one_count +=1\n    else:\n        zero_count +=1\n\nprint('Number of one count after applying SMOTE is: ', one_count)\nprint('Number of zero count after applying SMOTE is: ', zero_count)","dcfa7bdf":"smote = SMOTE()\nx_train1, y_train1 = smote.fit_resample(x_train1,y_train1)","8788e2e1":"# After Applying SMOTE\n\none_count = 0\nzero_count =0\n\nfor i in y_train1:\n    if i==1:\n        one_count +=1\n    else:\n        zero_count +=1\n\nprint('Number of one count after applying SMOTE is: ', one_count)\nprint('Number of zero count after applying SMOTE is: ', zero_count)","cc1d19f0":"lgr = LogisticRegression(max_iter=100000)\nlgr.fit(x_train1, y_train1)\n\ny_pred = lgr.predict(x_test1)\n\n\nprint('Accuracy of Logistic Regression is: ', accuracy_score(y_test1,y_pred))\nprint('Recall Score of Logistic Regression is: ', metrics.recall_score(y_test1, y_pred))","b0f092fd":"lgbm = LGBMClassifier()\nlgbm.fit(x_train1, y_train1)\n\ny_pred = lgbm.predict(x_test1)\n\n\nprint('Accuracy of Logistic Regression is: ', accuracy_score(y_test1,y_pred))\nprint('Recall Score of Logistic Regression is: ', metrics.recall_score(y_test1, y_pred))","d160646f":"xgb = XGBClassifier()\nxgb.fit(x_train1, y_train1)\n\ny_pred = xgb.predict(x_test1)\n\nprint('Accuracy of XGB Classifier is: ', accuracy_score(y_test1,y_pred))\nprint('Recall Score of XGB Classifier is: ', metrics.recall_score(y_test1, y_pred))","ca658573":"x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, random_state=101, test_size=0.2, shuffle=True )","1776655e":"# Before Applying Smoteenn\n\none_count = 0\nzero_count =0\n\nfor i in y_train2:\n    if i==1:\n        one_count +=1\n    else:\n        zero_count +=1\n\nprint('Number of one count after applying SMOTE is: ', one_count)\nprint('Number of zero count after applying SMOTE is: ', zero_count)","3e601ac6":"smoteenn = SMOTEENN()\nx_train2, y_train2 = smoteenn.fit_resample(x_train2, y_train2)","980fda87":"# After Applying Smote\n\none_count = 0\nzero_count =0\n\nfor i in y_train1:\n    if i==1:\n        one_count +=1\n    else:\n        zero_count +=1\n\nprint('Number of one count after applying SMOTE is: ', one_count)\nprint('Number of zero count after applying SMOTE is: ', zero_count)","cf9184bd":"lgr = LogisticRegression(max_iter=100000)\nlgr.fit(x_train2, y_train2)\n\ny_pred = lgr.predict(x_test2)\n\n\nprint('Accuracy of Logistic Regression is: ', accuracy_score(y_test2,y_pred))\nprint('Recall Score of Logistic Regression is: ', metrics.recall_score(y_test2, y_pred))","780a6edf":"lgbm = LGBMClassifier()\nlgbm.fit(x_train2, y_train2)\n\ny_pred = lgbm.predict(x_test2)\n\n\nprint('Accuracy of Logistic Regression is: ', accuracy_score(y_test2,y_pred))\nprint('Recall Score of Logistic Regression is: ', metrics.recall_score(y_test2, y_pred))","47ac25ae":"xgb = XGBClassifier()\nxgb.fit(x_train2, y_train2)\n\ny_pred = xgb.predict(x_test2)\n\nprint('Accuracy of XGB Classifier is: ', accuracy_score(y_test2,y_pred))\nprint('Recall Score of XGB Classifier is: ', metrics.recall_score(y_test2, y_pred))","05b6f871":"# Handling ImBalance Data\n# SMOTE (OverSampling )","43a7320b":"# SMOTEENN (OverSampling & UnderSampling Combined)"}}