{"cell_type":{"b08eaf34":"code","aabad2e3":"code","98ff81cb":"code","d484604a":"code","216c0714":"code","09effc3e":"code","228443bd":"code","2996f1fa":"code","dddb8dc7":"code","15a3f941":"code","96be2af9":"code","de3341ff":"code","b6669a59":"code","ec227a08":"code","6019b7b3":"code","e16f61f7":"code","7a523849":"code","21b75653":"code","b53b3b6f":"code","1fe6928c":"code","8a6ba4d5":"code","61d904b3":"code","26829617":"code","62a0dc8f":"code","b713a10f":"code","cff88eb4":"code","46a27c50":"code","345ed8c9":"code","af5eb820":"code","9b1624cb":"code","4e89ace5":"code","471d2ff7":"code","9232a9b6":"code","b1476071":"code","d3f45e0f":"code","b231d2bc":"code","fc81953f":"code","0b5cfd0f":"code","59b0203a":"code","ee9f19df":"code","449dc188":"markdown","e007d0f7":"markdown","7a7c39df":"markdown","4564f27c":"markdown","0bec157e":"markdown","26b87046":"markdown","b7a30435":"markdown","a316eb77":"markdown","16431ee7":"markdown","0ff4619f":"markdown","cd5e041e":"markdown","11896309":"markdown","f6c3a0b2":"markdown","318c3c12":"markdown","11591757":"markdown","ffb194c6":"markdown","9f62ea51":"markdown","336b05c7":"markdown","cfcfb3c6":"markdown","60153b85":"markdown","d36b02bb":"markdown","fdb3c354":"markdown","d7ba3d3b":"markdown","b8cc243f":"markdown","ba5751d7":"markdown","c20c42c9":"markdown","6ee665d9":"markdown","7deafad1":"markdown","5d8769f8":"markdown","041816b6":"markdown","3c06b2ba":"markdown","a64daf8a":"markdown","2a3fcc8c":"markdown","05f8dd2c":"markdown","a7609215":"markdown","4ccc4ee5":"markdown","1fbf4760":"markdown","eac81594":"markdown","688c576b":"markdown","04a894d4":"markdown","96f8a855":"markdown","eb52c7ba":"markdown","b7e26e4e":"markdown"},"source":{"b08eaf34":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport string\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , LSTM , Embedding\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pickle","aabad2e3":"data = pd.read_csv(\"\/kaggle\/input\/amazon-fine-food-reviews\/Reviews.csv\")\ndata.head()","98ff81cb":"data.shape","d484604a":"# Check null values\ndata.isna().sum().to_frame(name='# of missing values')","216c0714":"total_rows =  data.shape[0]\ndata.dropna(how='any',inplace=True)\nremaining_rows= data.shape[0]\n\nremoved_rows = total_rows-remaining_rows\nprint(\"No. of rows removed :\", removed_rows)\n\nprint(f\"\\nPercentage of data removed:{np.round((removed_rows\/total_rows)*100,2)}%\")\nprint(f\"Percentage of data remaining:{np.round((remaining_rows\/total_rows)*100,2)}%\")","09effc3e":"a =  data.shape[0]\ndata.drop_duplicates(inplace=True, subset=['Score','Text'])\nb = data.shape[0]\n\nprint(\"No. of rows removed :\", a-b)\n\nprint(f\"\\nPercentage of data removed: {np.round(((a-b)\/total_rows)*100,2)}%\")\nprint(f\"Percentage of data remaining: {np.round((b\/total_rows)*100,2)}%\")","228443bd":"a =  data.shape[0]\n\nidx = data[data[\"HelpfulnessNumerator\"]>data[\"HelpfulnessDenominator\"]].index\ndata.drop(index=idx, inplace=True)\n\nb = data.shape[0]\n\nprint(\"No. of rows removed :\", a-b)\n\nprint(f\"\\nPercentage of data removed:{np.round(((a-b)\/total_rows)*100,2)}%\")\nprint(f\"Percentage of data remaining:{np.round((b\/total_rows)*100,2)}%\")","2996f1fa":"## `Score` > 3 : \"Positive\" \n## `Score` == 3 : \"Neutral\"\n## `Score` < 3 : \"Negative\"\n\ndef create_target(x):\n    \n    return \"Positive\" if x>3 else \"Negative\" if x<3 else \"Neutral\"\n\ndata.loc[:, 'target'] = data.Score.apply(create_target)","dddb8dc7":"# target column \ndata[['Score', 'target']].sample(5)","15a3f941":"fig, ax = plt.subplots(figsize=(16, 6))\n\nvc = data.target.value_counts()\nvc.plot.barh(color=\"blue\",fontsize=14,ax=ax)\nax.set_title(\"Label vs Count\", fontsize=15)\nplt.show()","96be2af9":"neutral = data.loc[data.target==\"Neutral\"] # 29770 reviews\n\npositive = data.loc[data.target==\"Positive\"].sample(50000)\n\nnegative = data.loc[data.target==\"Negative\"].sample(50000)\n\ndata = pd.concat([positive, negative, neutral])\ndata.shape","de3341ff":"fig, ax = plt.subplots(figsize=(16, 6))\n\nvc = data.target.value_counts()\nvc.plot.barh(color=\"blue\",fontsize=14,ax=ax)\nax.set_title(\"Label vs Count\", fontsize=15)\nplt.show()","b6669a59":"# stopwords\ntotal_stopwords = set(stopwords.words('english'))\n\n# subtract negative stop words like no, not, don't etc.. from total_stopwords\nnegative_stop_words = set(word for word in total_stopwords \n                          if \"n't\" in word or 'no' in word)\n\nfinal_stopwords = total_stopwords - negative_stop_words\n\n# \nfinal_stopwords.add(\"one\")\nprint(final_stopwords)","ec227a08":"#stemming object\nstemmer = PorterStemmer()\n\n# ---------------------------------------------\nHTMLTAGS = re.compile('<.*?>')\ntable = str.maketrans(dict.fromkeys(string.punctuation))\nremove_digits = str.maketrans('', '', string.digits)\nMULTIPLE_WHITESPACE = re.compile(r\"\\s+\")\n# ---------------------------------------------","6019b7b3":"def preprocessor(review):\n    # remove html tags\n    review = HTMLTAGS.sub(r'', review)\n\n    # remove puncutuation\n    review = review.translate(table)\n    \n    # remove digits\n    review = review.translate(remove_digits)\n    \n    # lower case all letters\n    review = review.lower()\n    \n    # replace multiple white spaces with single space\n    review = MULTIPLE_WHITESPACE.sub(\" \", review).strip()\n    \n    # remove stop words\n    review = [word for word in review.split()\n              if word not in final_stopwords]\n    \n    # stemming\n    review = ' '.join([stemmer.stem(word) for word in review])\n    \n    return review","e16f61f7":"print(\"Before preprocessing : \")\ndata.Text.iloc[6]","7a523849":"# apply preprocessing function\n\ndata.Text = data.Text.apply(preprocessor) \nprint(\"After preprocessing : \")\ndata.Text.iloc[6]","21b75653":"def generate_wcloud(text):\n    stopwords = set(STOPWORDS)\n    \n    wordcloud = WordCloud(stopwords=stopwords, background_color='white')\n    wordcloud.generate(text)\n    \n    plt.figure(figsize=(15,7))\n    plt.axis('off')\n    plt.imshow(wordcloud, interpolation='bilinear')\n    return plt.show()","b53b3b6f":"pos = data.loc[data.target==\"Positive\"].Text\ntext = \" \".join(review for review in pos.astype(str))\n\ngenerate_wcloud(text)","1fe6928c":"pos = data.loc[data.target==\"Negative\"].Text\ntext = \" \".join(review for review in pos.astype(str))\n\ngenerate_wcloud(text)","8a6ba4d5":"pos = data.loc[data.target==\"Neutral\"].Text\ntext = \" \".join(review for review in pos.astype(str))\n\ngenerate_wcloud(text)","61d904b3":"X = data.Text\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    \n    X, y, test_size=0.20, random_state=1, stratify=y)","26829617":"X_train.shape, X_test.shape","62a0dc8f":"bow_vectorizer = CountVectorizer(max_features=10000)\nbow_vectorizer.fit(X_train)\n\n# transform\nbow_X_train = bow_vectorizer.transform(X_train)\nbow_X_test = bow_vectorizer.transform(X_test)","b713a10f":"tfidf_vectorizer = TfidfVectorizer(max_features=10000)\ntfidf_vectorizer.fit(X_train)\n\n# transform\ntfidf_X_train = tfidf_vectorizer.transform(X_train)\ntfidf_X_test = tfidf_vectorizer.transform(X_test)","cff88eb4":"labelEncoder = LabelEncoder()\n\ny_train = labelEncoder.fit_transform(y_train)\ny_test = labelEncoder.transform(y_test)\n\nlabels = labelEncoder.classes_.tolist()\nprint(labels) # index-> class","46a27c50":"### \ndef train_and_eval(model, trainX, trainY, testX, testY):\n\n    # training\n    _ = model.fit(trainX, trainY)\n\n    # predictions\n    y_preds_train = model.predict(trainX)\n    y_preds_test = model.predict(testX)\n\n    # evaluation\n    print()\n    print(model)\n    print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\n    print(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")\n    print('\\n',40*'-')","345ed8c9":"# Hyperparameters\nC = [0.001, 0.01, 0.1, 1, 10]\n\nfor c in C: \n    # Define model\n    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n    \n    # Train and evaluate model\n    train_and_eval(model=log_model,\n                   trainX=bow_X_train,\n                   trainY=y_train,\n                   testX=bow_X_test,\n                   testY=y_test)","af5eb820":"alphas = [0, 0.2, 0.6, 0.8, 1]\n\nfor a  in alphas: \n    # Define model\n    nb_model = MultinomialNB(alpha=a)\n\n    # Train and evaluate model\n    train_and_eval(model=nb_model,\n                   trainX=bow_X_train,\n                   trainY=y_train,\n                   testX=bow_X_test,\n                   testY=y_test)","9b1624cb":"# Hyperparameters\nC = [0.001, 0.01, 0.1, 1, 10]\n\nfor c in C: \n    # Define model\n    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n    \n    # Train and evaluate model\n    train_and_eval(model=log_model,\n                   trainX=tfidf_X_train,\n                   trainY=y_train,\n                   testX=tfidf_X_test,\n                   testY=y_test)","4e89ace5":"alphas = [0, 0.2, 0.6, 0.8, 1]\n\nfor a  in alphas: \n    # Define model\n    nb_model = MultinomialNB(alpha=a)\n\n    # Train and evaluate model\n    train_and_eval(model=nb_model,\n                   trainX=tfidf_X_train,\n                   trainY=y_train,\n                   testX=tfidf_X_test,\n                   testY=y_test)","471d2ff7":"def plot_cm(y_true, y_pred):\n    plt.figure(figsize=(6,6))\n    \n    cm = confusion_matrix(y_true, y_pred, normalize='true')\n    \n    sns.heatmap(\n        cm, annot=True, cmap='Blues', cbar=False, fmt='.2f',\n        xticklabels=labels, yticklabels=labels)\n    \n    return plt.show()","9232a9b6":"bmodel = LogisticRegression(C=1, max_iter=500, random_state=1)\nbmodel.fit(tfidf_X_train, y_train)","b1476071":"# predictions\ny_preds_train = bmodel.predict(tfidf_X_train)\ny_preds_test = bmodel.predict(tfidf_X_test)","d3f45e0f":"print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\nprint(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")","b231d2bc":"plot_cm(y_test, y_preds_test)","fc81953f":"with open(\"transformer.pkl\", \"wb\") as f:\n    pickle.dump(tfidf_vectorizer, f)\n    \nwith open(\"model.pkl\", \"wb\") as f:\n    pickle.dump(bmodel, f)","0b5cfd0f":"# labels = ['Negative', 'Neutral', 'Positive']\ndef get_sentiment(review):\n    # preprocessing\n    x = preprocessor(review)\n    #vectorization\n    x = tfidf_vectorizer.transform([x])\n    #prediction\n    y = int(bmodel.predict(x.reshape(1,-1)))\n    return labels[y]","59b0203a":"# positve review\nreview = \"This chips packet is very tasty. I highly recommend this!\"\nprint(f\"This is a {get_sentiment(review)} review!\")","ee9f19df":"# positve review\nreview = \"This product is a waste of money. Don't buy this!!\"\nprint(f\"This is a {get_sentiment(review)} review!\")","449dc188":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Word clouds<\/h2>","e007d0f7":"### Word cloud for Negative reviews","7a7c39df":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Handling class imbalance<\/h2>\n\n### Target distribution (Before)","4564f27c":"### Create target column using Score","0bec157e":"### Prediction on single review","26b87046":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Data Pre-processing<\/h2>","b7a30435":"<a id=\"1\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">1. Problem Definition<\/h2>\n<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">What is Sentiment Analysis ?<\/h2>\n\n#### Sentiment analysis is the process of reading tons of product reviews automatically and extract useful and meaningful information to discover if the customers are really satisfied with your product or not.\n\n#### A person\u2019s feedback is more subjective rather than factual. Feedbacks can be negative, positive, or neutral. \n\n#### Sentiment analysis applies Natural Language Processing (NLP) and Text Analysis techniques to highlight the subjective information from the text. \n\n<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Business understanding<\/h2>\n\n<div class = 'image'> <img style=\"float:center; border:5px solid #fed049; width:70%;\" align=center src = \"https:\/\/static.wixstatic.com\/media\/e284c3_5c75ec753e434e6e84821790e552d0a2~mv2.jpg\/v1\/fill\/w_740,h_351,al_c,q_90\/e284c3_5c75ec753e434e6e84821790e552d0a2~mv2.webp\"> \n<\/div>\n\n<a href =\"https:\/\/www.pyoneer.io\/post\/5-reasons-why-sentiment-analysis-is-important\"\n   style = \"font-size:20px,color: dimgrey, text-align:center,font-family:serif\">Image Source : pynoeer.io<\/a>\n<br>\n\n#### Performing the sentiment analysis on the customer reviews can help identify what is lacking and therefore guide you to improvement.\n#### You can review customer feedback and responses, and thus identify the negative comments and reasons why the customers have issues with your product or service.","a316eb77":"## Naive Bayes classifier with Tf-Idf","16431ee7":"### Remove rows which are having null values","0ff4619f":"## Next steps..\n\n### Web app and Deployment code will be updated soon on my github\n\n#### Link: https:\/\/github.com\/ashok49473\/reviews-sentiment-classifier","cd5e041e":"<a id=\"4\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 10px\">4. Model Training<\/h2>","11896309":"### Observations\n\n#### - Our model is performing better on classifying positive and negative reviews.\n#### - Need improvement in classifying the neutral reviews (Any suggestions??)","f6c3a0b2":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Train Test Split<\/h2>\n\n#### Train set : 70% of data\n#### Test set : 30% of data","318c3c12":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> Objective<\/h2>\n\n#### Aim : To determine the sentiment of a given review. (Negative\/ Neutral\/ Positive)\n---\n#### ML Task : Supervised Learning Multi-Class Text Classification\n---\n#### Performance metrics : Accuracy, Confusion matrix\n---\n","11591757":"###  Label Encoding","ffb194c6":"## --------- \u2764 The End! \u2764 -----------","9f62ea51":"### Stop words","336b05c7":"### Down sampling (remove some positive and negative reviews)","cfcfb3c6":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Data cleaning<\/h2>\n\n## Handling missing values","60153b85":"### Save model and transformer","d36b02bb":"### Import libraries","fdb3c354":"### Remove duplicate rows","d7ba3d3b":"### Best model : Logistic Regression(C=1) with TfIdf data","b8cc243f":"<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Vectorization<\/h2>","ba5751d7":"<a id=\"3\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 10px\">3. Data Preparation<\/h2>\n\n### Load data","c20c42c9":"<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Table of Contents<\/h2>\n\n   #### [1. Problem Definition](#1)\n   #### [2. Data Collection](#2)\n   #### [3. Data Preparation](#3)\n   #### [4. Model Training](#4)\n   #### [5. Model Evaluation](#5)\n   #### [6. Deployment](#6)","6ee665d9":"<a id=\"6\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 10px\">6. Deployment<\/h2>","7deafad1":"### Accuracy","5d8769f8":"### Word cloud for Neutral reviews","041816b6":"## References\n---\n\n#### Theory : https:\/\/www.pyoneer.io\/post\/5-reasons-why-sentiment-analysis-is-important\n\n#### CSS styling: https:\/\/www.kaggle.com\/bhuvanchennoju\/ancient-roots-of-agriculture-a-data-overview\n\n#### word cloud : https:\/\/re-thought.com\/creating-wordclouds-in-python\/\n\n#### Keras :  https:\/\/machinelearningmastery.com\/display-deep-learning-model-training-history-in-keras\/","3c06b2ba":"## Logistic Regression with Tf-Idf","a64daf8a":"### TF-IDF Vectorizer","2a3fcc8c":"## Naive Bayes Classifier with BoW","05f8dd2c":"### Bag of Words Vectorizer","a7609215":"### Remove outliers","4ccc4ee5":"<br>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Sentiment Analysis of Amazon Fine Food Reviews<\/h2> \n<br>\n<div class = 'image'> <img style=\"float:center; border:5px solid #fed049; width:80%;\" align=center src = \"https:\/\/lionbridge.ai\/wp-content\/uploads\/2018\/10\/ai-terms_sentiment-analysis.jpg\"> \n<\/div>\n<a href =\"https:\/\/forum.bubble.io\/t\/new-plugin-google-cloud-nlp-sentiment-analysis\/112789\"\n   style = \"font-size:20px,color: dimgrey, text-align:center,font-family:serif\">Image Source<\/a>\n<br>","1fbf4760":"### Confusion Matrix","eac81594":"<a id=\"5\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 10px\">5. Model Evaluation<\/h2>","688c576b":"### Remove unwanted words from reviews\n#### Ex. html tags, punctuation, stop words, etc..","04a894d4":"### Word cloud for Positive reviews","96f8a855":"## Logistic Regression with BoW","eb52c7ba":"<a id=\"2\"><\/a>\n<h2 style = \"font-size:30px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 10px\">2. Data collection<\/h2>\n\n### Amazon Fine Food Reviews\n#### Source : https:\/\/www.kaggle.com\/snap\/amazon-fine-food-reviews\n\n<h2 style = \"font-size:25px; font-family:Garamond ; font-weight : bold; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\">Description<\/h2>\n<p style=\"font-size: 14px; background-color: lightgray; padding: 10px\">\n    This dataset consists of reviews of fine foods from amazon. <br>\n    The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012.<br><br>\nReviews include product and user information, ratings, and a plain text review.\nIt also includes reviews from all other Amazon categories.<br><br>\n   <b>Data includes :<\/b><br>\n   - Reviews from Oct 1999 - Oct 2012<br>\n   - 568,454 reviews<br>\n   - 256,059 users<br>\n   - 74,258 products<br><br>\n<b> Attributes :<\/b><br>\n   - <b>ProductId<\/b> : Unique identifier for the product<br>\n   - <b>UserId<\/b> : Unqiue identifier for the user<br>\n   - <b>ProfileName<\/b> : Name of customer<br>\n   - <b>HelpfulnessNumerator<\/b> : Number of users who found the review helpful<br>\n   - <b>HelpfulnessDenominator<\/b> : Number of users who indicated whether they found the review helpful or not<br>\n   - <b>Score<\/b> : Rating between 1 and 5<br>\n   - <b>Time<\/b> : Timestamp for the review<br>\n   - <b>Summary<\/b> : Brief summary of the review<br>\n   - <b>Text<\/b> : Review text\n  \n<\/p>","b7e26e4e":"### Target distribution (after)"}}