{"cell_type":{"5662b014":"code","719bf8fa":"code","f3b0959f":"code","5b2d3c20":"code","ce10b608":"code","e28c5b85":"code","056d937c":"code","001b90f7":"code","3bea5256":"code","5020d42d":"code","12b5dd9b":"code","eef9f98a":"code","609a6ebe":"code","2bbe89fb":"code","034d3123":"code","8465a495":"code","17c315f4":"code","043d10a8":"code","1ece2091":"code","fa882f07":"code","a541626c":"code","f3527a81":"code","54a453b7":"code","731a0337":"code","405d5cd4":"code","3cf43c98":"code","a5832592":"code","41b41f44":"code","556fbba3":"code","564bca51":"code","65744fb1":"code","111c299f":"code","88d63cd4":"code","7049a6b0":"code","eae9f791":"code","a8b4e62d":"code","460b7459":"code","1ecfaaf5":"code","ccd1c25f":"code","0dd51b25":"code","015e2c89":"code","76f48c18":"code","6610f3ee":"code","517f1a69":"code","ac224300":"code","2477fbfd":"code","48076087":"code","3604a717":"code","e95fd99d":"code","b528f97f":"code","f4723bf2":"code","b2a8c55b":"code","63c3d116":"code","124bc482":"code","1fa3c32b":"code","371e49f1":"code","4e41d993":"code","cf6a653c":"code","d205105e":"code","b430028c":"code","72fd9b49":"code","e805f0fa":"code","09cefc63":"code","47fc90ca":"code","d8d3fb3c":"code","7b7b810b":"code","ed13cdad":"code","b35e15b5":"code","0f50b047":"code","8d12dac6":"code","081033cc":"code","1f3a9f5e":"code","5e4d7da6":"code","68b76da1":"code","cd0b1416":"code","f97830e1":"code","c783b611":"code","17def4b4":"code","f3b722f4":"code","e93a3e2b":"code","ddf7e7ff":"code","63077be3":"code","120ff5fa":"code","d39e08e8":"markdown","49ceae2e":"markdown","aa07a4ff":"markdown","cfccb7bf":"markdown","61810865":"markdown","902b2f23":"markdown","4855ba76":"markdown","b7010ada":"markdown","3a3fc390":"markdown","31d5694c":"markdown","9edc8bee":"markdown","f50d1b93":"markdown","9730b457":"markdown","bdbf982f":"markdown","1c5ea1ff":"markdown","f35335fd":"markdown","df1a95d0":"markdown","5fd1eae3":"markdown","70e7dd34":"markdown","88905a1c":"markdown","99452196":"markdown","985320a0":"markdown","8c6e69b8":"markdown","3f8c549c":"markdown","ea35e4e4":"markdown","d6001c66":"markdown","6b24451c":"markdown","81eade89":"markdown","bc43481c":"markdown","8448578c":"markdown","1900f00d":"markdown"},"source":{"5662b014":"# Import libraries \n\n# Data Manipulation\nimport numpy as np \nimport pandas as pd\nfrom   pandas import DataFrame\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Machine Learning\nfrom   sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\nfrom   sklearn.impute import SimpleImputer\nfrom   sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict,cross_val_score, RepeatedStratifiedKFold\nfrom   sklearn.metrics import confusion_matrix , classification_report, accuracy_score, roc_auc_score, plot_roc_curve\nfrom   sklearn.metrics import f1_score , multilabel_confusion_matrix\nfrom   sklearn.linear_model import LogisticRegression\nfrom   sklearn.tree import DecisionTreeClassifier\nfrom   sklearn.ensemble import RandomForestClassifier\nfrom   sklearn.svm import SVC\nfrom   sklearn.linear_model import SGDClassifier\n\nfrom   xgboost import XGBClassifier\nfrom   lightgbm import LGBMClassifier\nfrom   sklearn.naive_bayes import GaussianNB\nfrom   sklearn.neighbors import KNeighborsClassifier\nfrom   imblearn.over_sampling import RandomOverSampler\nimport pickle\n\n#Clasturing \nfrom sklearn.cluster import KMeans\n\n# Evalution\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nimport sklearn.metrics\n# Maths\nimport math\nfrom numpy import mean , std\n\n# Set the options\npd.set_option('display.max_rows', 800)\npd.set_option('display.max_columns', 500)\n\n#visialization\n%matplotlib inline\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix","719bf8fa":"input_file_name = \"..\/input\/dhaka-stock-exchange\/StockData.csv\"\n","f3b0959f":"data = pd.read_csv(input_file_name)\ndata.head()","5b2d3c20":"data.columns","ce10b608":"data.info()","e28c5b85":"# Target class name\ninput_target_class = \"Category\"\n\n\n# Col datatype selection\ninput_datatype_selection = 'auto'  # use auto if you don't want to provide column names by data type else use 'manual'\n\n# Categorical columns\ninput_cat_columns = ['CompanyName', 'Sector']\n\n# Numerical columns\ninput_num_columns = ['Last Price', 'NAV', 'P\/E', 'EPS','Paid up', 'Dir', 'Pub', 'Inst', 'Foreign', 'Govt']","056d937c":"# Dimension of Dataset\n\ndata.shape","001b90f7":"# counting Sector columns value\ndata['Sector'].value_counts()\n","3bea5256":"# Total Sector \nlen(data['Sector'].unique())","5020d42d":"sns_plot = sns.countplot(y=data['Sector'] ,data=data)\n#sns.set(rc={'figure.figsize':(10,810)})\nfig = sns_plot.get_figure()\nplt.figure(figsize=(19.20,10.80))\nfig.savefig(\"Sector_count.png\", dpi=600)","12b5dd9b":"data['Category'].value_counts()","eef9f98a":"sns_plot = sns.countplot(y=data['Category'] ,data=data)\nfig = sns_plot.get_figure()\nfig.savefig(\"Catagory_count.png\")","609a6ebe":"#find nul values\n\ndata.isnull().sum()","2bbe89fb":"#find the Nall value rows\ndata[data['NAV'].isna()]","034d3123":"# drop rows with missing values\ndata.dropna(inplace=True)\ndata.info()","8465a495":"data.shape","17c315f4":"#drop the company name\ndata = data.drop(\"CompanyName\", axis=1)","043d10a8":"data.head()","1ece2091":"# Feature encoding\ncat_columns = ['Sector']\n# Use LabelEncoder function from sklearn\nle = LabelEncoder()\ndata[cat_columns] = data[cat_columns].apply(lambda col: le.fit_transform(col))","fa882f07":"data.tail()","a541626c":"# Correlation visualisation\n# Heatmap is good method to visualize correlation between features.\nf,ax = plt.subplots(figsize=(15,15))\nsns.heatmap(data[input_num_columns].corr(), annot=True, linewidths=0.5, fmt='.1f', ax=ax,cmap='cubehelix_r')\nplt.savefig('Corr.jpg')","f3527a81":"# Number of rows and columns in the plot\nn_cols = 3\nn_rows = math.ceil(len(input_num_columns)\/n_cols)","54a453b7":"# Check the distribution of y variable corresponding to every x variable \nfig,ax = plt.subplots(nrows = n_rows, ncols = n_cols, figsize=(15,15))\nrow = 0\ncol = 0\nfor i in input_num_columns:\n    if col > 2:\n        row += 1\n        col = 0\n    axes = ax[row,col]\n    sns.boxplot(x = data[input_target_class], y = data[i],ax = axes)\n    col += 1\nplt.tight_layout()\nplt.title(\"Individual Features by Class\")\nplt.show()\nplt.savefig('box.jpg')","731a0337":"# selecting feature values\ndrop_columns = [ 'Sector','Category']\nX= data.drop(drop_columns,axis=1)\n","405d5cd4":"X.head()","3cf43c98":"# Feature encoding of target value\n# Use LabelEncoder function from sklearn\nY = data[input_target_class]\nlevel = LabelEncoder()\nY = level.fit_transform(Y)","a5832592":"X_train ,X_test, Y_train, Y_test = train_test_split(X,Y,test_size =0.3,random_state=28)","41b41f44":"len(X_train)","556fbba3":"len(X_test)","564bca51":"len(Y_train)","65744fb1":"len(Y_test)","111c299f":"# Define the function to scale the data using StandardScaler()\ndef scale_data(data):\n    \n    scaler = StandardScaler() \n\n    # transform data\n    scaled_data = scaler.fit_transform(data)\n    scaled_data = DataFrame(scaled_data)\n\n    scaled_data.columns = data.columns\n    \n    return scaled_data","88d63cd4":"from sklearn.preprocessing import StandardScaler\n#sc = StandardScaler()\n# scaling by standardization\nX_train_1 = scale_data(X_train)\n\n# test set just transfrom by traing set standardiz value\nX_test_1 = scale_data(X_test)","7049a6b0":"X_train.head()","eae9f791":"X_train_1.head()","a8b4e62d":"#Check again for any null data\nX_test_1.isnull().values.any()\nX_train_1.isnull().values.any()","460b7459":"def get_models():\n  models = dict()\n  #models['XGB'] = XGBClassifier()\n  #models['LGBM'] = LGBMClassifier()\n  models['lr'] = LogisticRegression()\n  models['knn'] = KNeighborsClassifier()\n  models['cart']= DecisionTreeClassifier()\n  models['rnf'] = RandomForestClassifier()\n  models['svm'] = SVC(probability=True)\n  models['bayes'] = GaussianNB()\n  models['SGD'] = SGDClassifier()\n\n  return models","1ecfaaf5":"#xt means test data\ndef model_predict(x,y,model,xt):\n  model.fit(x,y)\n  Y_pre = model.predict(xt)\n  # Y_pred_prob = model.predict_proba(X_test_1)\n  return Y_pre\n","ccd1c25f":"def model_pre_pro(x,y,model,xt):\n  model.fit(x,y)\n  Y_pred_prob = model.predict_proba(xt)\n  return Y_pre","0dd51b25":"models = get_models()","015e2c89":"#Predict Target value by Test data\nScore = []\nAlgo =[]\nfor name, model in models.items():\n    Y_pre = model_predict(X_train_1,Y_train,model,X_test_1)\n    Score_DT = accuracy_score(Y_test,Y_pre)\n    #F1 = f1_score(Y_test,Y_pre)\n    #print('>%s % .3f'% (name,Score_DT))\n    Algo.append(name)\n    Score.append(Score_DT )\n\n\n\n\n\n","76f48c18":"Classification_result = pd.DataFrame(list(zip(Algo,Score)), columns=['Alo_name','Accuracy'])\n","6610f3ee":"Classification_result","517f1a69":"# evaluate a given model using cross-validation\ndef evalute_model(model,x,y):\n  #if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used\n  Cv= RepeatedStratifiedKFold(n_splits=3,n_repeats=3,random_state=28)\n  score = cross_val_score(model,x,y,scoring=\"accuracy\", cv= Cv,n_jobs=-1)\n  return score","ac224300":"# Cros validetion value\nCV_score =[]\n\nfor name, model in models.items():\n  score = evalute_model(model,X_train_1,Y_train)\n  CV_score.append(mean(score))","2477fbfd":"Classification_result['CV_score'] = CV_score","48076087":"CV_score","3604a717":"Classification_result","e95fd99d":"## Performance test for all model\nnames =[]\nExact_Match_Ratio=[]\nHamming_loss=[]\nRecall=[]\nPrecision =[]\nF1_Measure =[]\nfor name, model in models.items():\n  names.append(name)\n  Y_pre = model_predict(X_train_1,Y_train,model,X_test_1)\n  Exact_Match_Ratio.append(' {0}'.format(sklearn.metrics.accuracy_score(Y_test, Y_pre, normalize=True, sample_weight=None)))\n\n  Hamming_loss.append(' {0}'.format(sklearn.metrics.hamming_loss(Y_test, Y_pre))) \n  #\"samples\" applies only to multilabel problems. It does not calculate a per-class measure, instead calculating the metric over the true and predicted classes \n  #for each sample in the evaluation data, and returning their (sample_weight-weighted) average.\n\n  Recall.append('{0}'.format(sklearn.metrics.precision_score(y_true=Y_test, y_pred=Y_pre, average='weighted'))) \n  \n  Precision.append('{0}'.format(sklearn.metrics.recall_score(y_true=Y_test, y_pred=Y_pre, average='weighted')))\n  \n  F1_Measure.append('{0}'.format(sklearn.metrics.f1_score(y_true=Y_test, y_pred=Y_pre, average='weighted'))) \n\nPerformance = pd.DataFrame(list(zip(names,Exact_Match_Ratio,Hamming_loss,Recall,Precision,F1_Measure)), columns=['Algorithom','Exact Match Ratio','Hamming loss','Recall','Precision','F1 Measure'] )","b528f97f":"Performance","f4723bf2":"Performance.to_csv(\"Performance.csv\")","b2a8c55b":"data.columns","63c3d116":"names=[]\nfor name, model in models.items():\n  names.append(name)\n  Y_pre = model_predict(X_train_1,Y_train,model,X_test_1)\n  report = classification_report(Y_pre, Y_test, target_names=data['Category'].unique())\n  \n  print(name)\n  print(report)","124bc482":"type(report)","1fa3c32b":"names","371e49f1":"models.keys","4e41d993":"model = list(models.values())","cf6a653c":"#Y_pre = model_predict(X_train_1,Y_train,model[1],X_test_1)\n#report = classification_report(Y_pre, Y_test, target_names=data['Category'].unique())\n\n\n#df = pandas.DataFrame(zip(name, report)).transpose()\n \n","d205105e":"for name, model in models.items():\n  \n  Y_pre = model_predict(X_train_1,Y_train,model,X_test_1)\n  confusion_matrix = multilabel_confusion_matrix(Y_test,Y_pre)\n  print(name,confusion_matrix  )","b430028c":"X_train_2 = X_train_1[[\"Last Price\",'NAV','P\/E']]\nX_test_2 = X_test_1[[\"Last Price\",'NAV','P\/E']]","72fd9b49":"X_train_2.head()","e805f0fa":"def model_predict(x,y,model,xt):\n  model.fit(x,y)\n  Y_pre = model.predict(xt)\n  # Y_pred_prob = model.predict_proba(X_test_1)\n  return Y_pre","09cefc63":"#Predict Target value by Test data\nScore1 = []\nAlgo =[]\nfor name, model in models.items():\n    Y_pre1 = model_predict(X_train_2,Y_train,model,X_test_2)\n    Score_DT1 = accuracy_score(Y_test,Y_pre1)\n    #F1 = f1_score(Y_test,Y_pre)\n    #print('>%s % .3f'% (name,Score_DT))\n    Algo.append(name)\n    Score1.append(Score_DT1 )","47fc90ca":"# Cros validetion value\nCV_score1 =[]\n\nfor name, model in models.items():\n  score = evalute_model(model,X_train_2,Y_train)\n  CV_score1.append(mean(score))","d8d3fb3c":"Classification_result2 = pd.DataFrame(list(zip(Algo,Score1,CV_score1)), columns=['Alo_name','Accuracy',\"CV\"])","7b7b810b":"print(\"New Accurecy\")\nprint(Classification_result2)","ed13cdad":"Classification_result","b35e15b5":"## Performance test for all model\nnames =[]\nExact_Match_Ratio=[]\nHamming_loss=[]\nRecall=[]\nPrecision =[]\nF1_Measure =[]\nfor name, model in models.items():\n  names.append(name)\n  Y_pre1 = model_predict(X_train_2,Y_train,model,X_test_2)\n  Exact_Match_Ratio.append(' {0}'.format(sklearn.metrics.accuracy_score(Y_test, Y_pre1, normalize=True, sample_weight=None)))\n \n\n  Hamming_loss.append(' {0}'.format(sklearn.metrics.hamming_loss(Y_test, Y_pre1))) \n \n\n  #\"samples\" applies only to multilabel problems. It does not calculate a per-class measure, instead calculating the metric over the true and predicted classes \n  #for each sample in the evaluation data, and returning their (sample_weight-weighted) average.\n\n  Recall.append('{0}'.format(sklearn.metrics.precision_score(y_true=Y_test, y_pred=Y_pre1, average='weighted'))) \n  \n  Precision.append('{0}'.format(sklearn.metrics.recall_score(y_true=Y_test, y_pred=Y_pre1, average='weighted')))\n  \n  F1_Measure.append('{0}'.format(sklearn.metrics.f1_score(y_true=Y_test, y_pred=Y_pre1, average='weighted'))) \n\nPerformance_1 = pd.DataFrame(list(zip(names,Exact_Match_Ratio,Hamming_loss,Recall,Precision,F1_Measure)), columns=['Algorithom','Exact Match Ratio','Hamming loss','Recall','Precision','F1 Measure'] )","0f50b047":"Performance_1","8d12dac6":"Performance_1.to_csv(\"Performance-2.csv\")","081033cc":"unique, counts = np.unique(Y_pre, return_counts=True)\ndict(zip(unique,counts))","1f3a9f5e":"unique, counts = np.unique(Y_test, return_counts=True)\ndict(zip(unique,counts))","5e4d7da6":"unique, counts = np.unique(Y_train, return_counts=True)\ndict(zip(unique,counts))","68b76da1":"data['Category'].value_counts()","cd0b1416":"Classification_result.to_csv(\"output.csv\")","f97830e1":"Classification_result2.to_csv(\"output2.csv\")","c783b611":"### Find the within cluster sum of square (wcss)\n## No need to train test split \n\nwcss = [] #within claster sum of square (WCSS)\nfor i in range(1,21):\n  ##\"k-mean++\" use for avoid initializetion trap\n  kmean = KMeans(n_clusters= i, init= \"k-means++\",random_state=42) \n  kmean.fit(X)\n  wcss.append(kmean.inertia_)\n\nplt.plot(range(1,21), wcss)\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"WCSS value\")\nplt.title(\"Elbow method for optimal Clustering\")\nplt.savefig(\"Elbow.png\",dpi=600)\n\n","17def4b4":"X.head()","f3b722f4":"cluster_num= 4\nkmean = KMeans(n_clusters= cluster_num, init= \"k-means++\",random_state=28) \n# fit_predict for creating cluster \ncluster = kmean.fit(X)\ny_kmeans = kmean.fit_predict(X)\n","e93a3e2b":"pre = pd.DataFrame(y_kmeans)\npre.value_counts()","ddf7e7ff":"sns_plot = sns.countplot(y=y_kmeans)\nfig = sns_plot.get_figure()\nfig.savefig(\"Cluster_count.png\")","63077be3":"report= classification_report(Y,y_kmeans)","120ff5fa":"print(report)","d39e08e8":"### 5.1 Split the target variable and Indipendend variable","49ceae2e":"# Overview of the Data","aa07a4ff":"#### Confusion Matrix ","cfccb7bf":"#### Model performance test\n","61810865":"## 5.Create model","902b2f23":"### 4.2 Check how differnt numerical features are realated to target class","4855ba76":"Choose the ML algorithm from \n\n1. LogisiticRegression\n2. DecisionTreeClassifier\n3. XGBClassifier\n4. LGBMClassifier\n5. Support vector Machine\n6. Random Forest\n7. Support Vector \n8. Naive Bayes\n9. Stochastic gradient descent\n\n\n\n\n\n\n\n\n","b7010ada":"### 1.3 Define variable","3a3fc390":"#### Accuracy score","31d5694c":"### 5.6 Performance measure","9edc8bee":"# Clustering analysis","f50d1b93":"#### Classification report ","9730b457":"Select some feature","bdbf982f":"### 4.1 Correlation","1c5ea1ff":"### 5.5 Train the model and Predict\n","f35335fd":"# Data preperation","df1a95d0":"## 1. Import Libraries\n\nImport all the libraries in the first cell itself","5fd1eae3":"## 4.Exploratory Data Analaysis","70e7dd34":"### 3.1 Data cleaning","88905a1c":"### 5.4 Model Building<\/h2>\n\n\nIn this section you will:\n- Train the model on training data\n- Get the predictions on testing data\n- Evaluate the performance of model on testing data","99452196":"### 3.2 Encode the categorical features","985320a0":" Evaluate a suite of different machine learning models on the dataset.","8c6e69b8":"### 1.2 Load Dataset and explor","3f8c549c":"## 6. New model\n","ea35e4e4":"# Analysis of Dhaka Stock exchange data ","d6001c66":"### 5.2 Create a training and test set","6b24451c":"### Clustering","81eade89":"#### Feature Encoding\n\n","bc43481c":"### 5.3 Feature scaling\nstandardization of data","8448578c":"#### Accuracy measure by Cross-validation","1900f00d":"### Find the optimal Cluster number "}}