{"cell_type":{"2e32cfca":"code","83c10957":"code","1b8debf9":"code","baeb72ad":"code","9e6a1216":"code","8b2378b0":"code","c4508fd9":"code","1cc71b54":"code","ae94b2ad":"code","9b4f8353":"code","010b81bd":"code","7df4ed95":"code","79699cdf":"code","4e8ea5ce":"code","dd323760":"code","5e8a1bfe":"code","3b1e22ec":"code","8606cc7e":"code","4327f592":"code","b0eff10d":"code","40e80274":"code","2fe7c691":"code","4855fc95":"code","e6e76c7b":"code","8c0e10a2":"markdown","13ee51f3":"markdown","af2412ce":"markdown","b0149615":"markdown","5abebf15":"markdown","aa2007d5":"markdown","bc57e152":"markdown","9a2492e6":"markdown","1f8cc2b9":"markdown","ae05e0cd":"markdown","d16e5b92":"markdown","e8e86704":"markdown","8ac6af03":"markdown","f8af210e":"markdown","6086c04a":"markdown","540a8c33":"markdown","4b8ad966":"markdown","f429db72":"markdown","9f3dad45":"markdown","93db2526":"markdown","eb06b363":"markdown","262a5c47":"markdown","d9b3f5ad":"markdown","80617c43":"markdown","0266d9fd":"markdown","648ce0c1":"markdown","9619477a":"markdown","114f560d":"markdown","f7e54496":"markdown"},"source":{"2e32cfca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83c10957":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\n# --- setup ---\npd.set_option('max_columns', 50)\nfrom datetime import datetime, timedelta","1b8debf9":"death_and_recovered_url = \"https:\/\/api.covid19india.org\/csv\/latest\/death_and_recovered.csv\"\ndar_df = pd.read_csv(death_and_recovered_url)\ndar_df[\"Date\"] = pd.to_datetime(dar_df[\"Date\"], format = \"%d\/%m\/%Y\")","baeb72ad":"dar_statewise_daily_stats = dar_df.groupby([\"State\",\"Date\",\"Patient_Status\"], as_index=False).agg({\"Sl_No\":\"count\"}).rename({\"Sl_No\":\"DailyCases\"}, axis=1)\ndar_statewise_daily_stats = dar_statewise_daily_stats.rename({\"Patient_Status\":\"Current Status\"}, axis=1)","9e6a1216":"raw_data_url = \"https:\/\/api.covid19india.org\/csv\/latest\/raw_data.csv\"\nraw_data = pd.read_csv(raw_data_url)\nraw_data[\"Date\"] = pd.to_datetime(raw_data[\"Date Announced\"], format = \"%d\/%m\/%Y\")\nraw_data[\"State\"] = raw_data[\"Detected State\"]\nhosp_statewise_daily_stats1 = raw_data.groupby([\"State\",\"Date\",\"Current Status\"], as_index=False).agg({\"Patient Number\":\"count\"}).rename({\"Patient Number\":\"DailyCases\"}, axis=1)\nhosp_statewise_daily_stats1[\"Current Status\"] = \"Hospitalized\"","8b2378b0":"statewise_daily_stats1 = hosp_statewise_daily_stats1.append(dar_statewise_daily_stats)","c4508fd9":"raw_data3_url = \"https:\/\/api.covid19india.org\/csv\/latest\/raw_data3.csv\"\nraw_data3 = pd.read_csv(raw_data3_url)\nraw_data3[\"Date\"] = pd.to_datetime(raw_data3[\"Date Announced\"], format = \"%d\/%m\/%Y\")\nraw_data3[\"State\"] = raw_data3[\"Detected State\"]\nstatewise_daily_stats3 = raw_data3.groupby([\"State\",\"Date\",\"Current Status\"], as_index=False).agg({\"Num Cases\":\"sum\"}).rename({\"Num Cases\":\"DailyCases\"}, axis=1)","1cc71b54":"statewise_daily_stats = statewise_daily_stats1.append(statewise_daily_stats3)\nstatewise_daily_stats = statewise_daily_stats[statewise_daily_stats[\"Current Status\"].isin([\"Hospitalized\",\"Recovered\",\"Deceased\"])]","ae94b2ad":"raw_data4_url = \"https:\/\/api.covid19india.org\/csv\/latest\/raw_data4.csv\"\nraw_data4 = pd.read_csv(raw_data4_url)\nraw_data4[\"Date\"] = pd.to_datetime(raw_data4[\"Date Announced\"], format = \"%d\/%m\/%Y\")\nraw_data4[\"State\"] = raw_data4[\"Detected State\"]\nstatewise_daily_stats4 = raw_data4.groupby([\"State\",\"Date\",\"Current Status\"], as_index=False).agg({\"Num Cases\":\"sum\"}).rename({\"Num Cases\":\"DailyCases\"}, axis=1)","9b4f8353":"statewise_daily_stats = statewise_daily_stats.append(statewise_daily_stats4)\nstatewise_daily_stats = statewise_daily_stats[statewise_daily_stats[\"Current Status\"].isin([\"Hospitalized\",\"Recovered\",\"Deceased\"])]","010b81bd":"last_date = statewise_daily_stats[\"Date\"].max().strftime(\"%d %b %Y\")\nfig = px.line(statewise_daily_stats.groupby([\"Date\",\"Current Status\"], as_index=False).agg({\"DailyCases\":\"sum\"}), x=\"Date\", y=\"DailyCases\", color='Current Status', \n              title=f\"Nationwide Confirmed\/Death Cases Over Time as on {last_date}\")\nfig.show()","7df4ed95":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\n#statewise_daily_stats_pivot.head()\nnational_mortality_rate = statewise_daily_stats_pivot.groupby(\"Date\").agg({\"Deceased\":\"sum\", \"Hospitalized\":\"sum\", \"Recovered\":\"sum\"})\nnational_mortality_rate = national_mortality_rate.reset_index()\nnational_mortality_rate[\"MortalityRate\"] = (national_mortality_rate[\"Deceased\"]\/national_mortality_rate[\"Hospitalized\"])*100\nnational_mortality_rate[\"MortalityRateMA\"] = national_mortality_rate[\"MortalityRate\"].rolling(10).mean()\n\nfig = px.line(national_mortality_rate, x=\"Date\", y=\"MortalityRate\", \n              title=\"Nationwide Mortality Rate Over Time\")\nfig.add_scatter(x=national_mortality_rate['Date'], y=national_mortality_rate['MortalityRateMA'], mode='lines')\nfig.show()","79699cdf":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\nstatewise_daily_stats_pivot = statewise_daily_stats_pivot.rename({\"Hospitalized\":\"Total Cases\"}, axis=1)\nstatewise_daily_stats_pivot[\"Active\"] = statewise_daily_stats_pivot[\"Total Cases\"] - (statewise_daily_stats_pivot[\"Deceased\"] + statewise_daily_stats_pivot[\"Recovered\"])\nstatewise_stats = pd.melt(statewise_daily_stats_pivot, id_vars=['State','Date'], value_vars=['Deceased','Active','Recovered'],var_name='Current Status', value_name='DailyCases')\nstatewise_stats = statewise_stats.groupby([\"State\",\"Current Status\"], as_index=False).agg({\"DailyCases\":\"sum\"})\nfig = px.treemap(statewise_stats.query(\"DailyCases > 0\"), path=['State', 'Current Status'], values='DailyCases', color='State', title=f'Cases Distribution across states as on {last_date}')\nfig.show()","4e8ea5ce":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\nstatewise_mortality_rate = statewise_daily_stats_pivot.groupby(\"State\").agg({\"Deceased\":\"sum\", \"Hospitalized\":\"sum\", \"Recovered\":\"sum\"})\nstatewise_mortality_rate[\"Total Cases\"] = statewise_mortality_rate.sum(axis=1)\nstatewise_mortality_rate = statewise_mortality_rate.reset_index()\nstatewise_mortality_rate[\"MortalityRate\"] = (statewise_mortality_rate[\"Deceased\"]\/statewise_mortality_rate[\"Total Cases\"])*100\n\nfig = px.bar(statewise_mortality_rate.sort_values(\"MortalityRate\", ascending=False),\n             x='State', y='MortalityRate', barmode='group',\n             title=f'Mortality Rate across the states as on {last_date}',height=600)\nfig.show()","dd323760":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\nstatewise_daily_stats_pivot[\"Total Cases\"] = statewise_daily_stats_pivot[\"Hospitalized\"]\nTOP_N = 10\n\ntop_states = statewise_daily_stats_pivot.groupby(\"State\", as_index=False).agg({\"Total Cases\":\"sum\"}).sort_values(\"Total Cases\", ascending=False).State.reset_index(drop=True)[:TOP_N]\ntop_states_df = statewise_daily_stats[statewise_daily_stats[\"State\"].isin(top_states)]\n\nfig = px.line(top_states_df[top_states_df[\"Current Status\"] == \"Hospitalized\"], x=\"Date\", y=\"DailyCases\",color=\"State\", \n              title=f\"Statewise Total Cases Over Time as on {last_date}\")\n#fig.add_scatter(x=national_mortality_rate['Date'], y=national_mortality_rate['MortalityRateMA'], mode='lines')\nfig.show()\n","5e8a1bfe":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\nTOP_N = 10\n\ntop_states = statewise_daily_stats_pivot.groupby(\"State\", as_index=False).agg({\"Deceased\":\"sum\"}).sort_values(\"Deceased\", ascending=False).State.reset_index(drop=True)[:TOP_N]\ntop_states_df = statewise_daily_stats[statewise_daily_stats[\"State\"].isin(top_states)]\n\nfig = px.line(top_states_df[top_states_df[\"Current Status\"] == \"Deceased\"], x=\"Date\", y=\"DailyCases\",color=\"State\", \n              title=f\"Statewise Fatalities Over Time as on {last_date}\")\n#fig.add_scatter(x=national_mortality_rate['Date'], y=national_mortality_rate['MortalityRateMA'], mode='lines')\nfig.show()","3b1e22ec":"TOP_N_STATES = 10\nN_START_FATALITIES= 5\n\nstatewise_daily_stats_pivot[\"Total Cases\"] = statewise_daily_stats_pivot[\"Hospitalized\"] + statewise_daily_stats_pivot[\"Deceased\"] + statewise_daily_stats_pivot[\"Recovered\"]\nstatewise_daily_stats_pivot[\"CumulativeTotalCases\"] = statewise_daily_stats_pivot.groupby(\"State\")[\"Total Cases\"].cumsum()\n\ntop_states = statewise_daily_stats_pivot.groupby(\"State\").agg({\"Total Cases\":\"sum\"}).sort_values('Total Cases', ascending=False).iloc[:TOP_N_STATES].index.values.tolist()\nstatewise_daily_cases_cum = statewise_daily_stats_pivot[statewise_daily_stats_pivot[\"State\"].isin(top_states)]\nstatewise_daily_cases_cum = statewise_daily_cases_cum[[\"State\",\"Date\",\"Total Cases\", \"CumulativeTotalCases\"]]\nstatewise_daily_cases_cum = statewise_daily_cases_cum.sort_values([\"State\", \"Date\"])\nstatewise_daily_cases_cum = statewise_daily_cases_cum.query(\"CumulativeTotalCases > 10\")\nstatewise_daily_cases_cum[\"DaysSince10\"] = statewise_daily_cases_cum.groupby(\"State\",as_index=False).cumcount()+1\nstatewise_daily_cases_cum[\"LogCumulativeTotalCases\"] = np.log10(statewise_daily_cases_cum[\"CumulativeTotalCases\"])\n\nfig = px.line(statewise_daily_cases_cum, x='DaysSince10', y='LogCumulativeTotalCases', color='State', title=f'Total Cases (Log Scale) by State since 10 cases as on {last_date}')\nfig.add_trace(go.Scatter(x=[0, 7*10], y=[1, np.log10(10*(2**10))], name='Double by 7 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.add_trace(go.Scatter(x=[0, 14*5], y=[1, np.log10(10*(2**5))], name='Double by 14 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.add_trace(go.Scatter(x=[0, 21*3.34], y=[1, np.log10(10*(2**3.34))], name='Double by 21 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.update_layout( xaxis_title='Days since 10 cases recorded', yaxis_title='Logarithm of Total Cases')\nfig.show()\n","8606cc7e":"TOP_N_STATES = 10\nN_START_FATALITIES= 5\n\nstatewise_daily_stats_pivot[\"CumulativeDeceased\"] = statewise_daily_stats_pivot.groupby(\"State\")[\"Deceased\"].cumsum()\ntop_states = statewise_daily_stats_pivot.groupby(\"State\").agg({\"Deceased\":\"sum\"}).sort_values('Deceased', ascending=False).iloc[:TOP_N_STATES].index.values.tolist()\nstatewise_daily_fatalities = statewise_daily_stats_pivot[statewise_daily_stats_pivot[\"State\"].isin(top_states)]\nstatewise_daily_fatalities = statewise_daily_fatalities[[\"State\",\"Date\",\"Deceased\", \"CumulativeDeceased\"]]\nstatewise_daily_fatalities = statewise_daily_fatalities.sort_values([\"State\", \"Date\"])\nstatewise_daily_fatalities = statewise_daily_fatalities.query(\"CumulativeDeceased > 10\")\nstatewise_daily_fatalities[\"DaysSince10\"] = statewise_daily_fatalities.groupby(\"State\",as_index=False).cumcount()+1\nstatewise_daily_fatalities[\"LogCumulativeDeceased\"] = np.log10(statewise_daily_fatalities[\"CumulativeDeceased\"])\n\nfig = px.line(statewise_daily_fatalities, x='DaysSince10', y='LogCumulativeDeceased', color='State', title=f'Fatalities by State since 10 deaths')\nfig.add_trace(go.Scatter(x=[0, 7*6], y=[1, np.log10(10*(2**6))], name='Double by 7 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.add_trace(go.Scatter(x=[0, 14*3], y=[1, np.log10(10*(2**3))], name='Double by 14 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.add_trace(go.Scatter(x=[0, 21*2], y=[1, np.log10(10*(2**2))], name='Double by 21 days', line=dict(dash='dash', color=('rgb(200, 200, 200)'))))\nfig.show()","4327f592":"statewise_daily_stats_pivot = pd.pivot_table(statewise_daily_stats, index = [\"State\",\"Date\"], columns = \"Current Status\", values=\"DailyCases\").reset_index().fillna(0)\nstatewise_daily_stats_pivot[\"Total Cases\"] = statewise_daily_stats_pivot[\"Hospitalized\"] + statewise_daily_stats_pivot[\"Deceased\"] + statewise_daily_stats_pivot[\"Recovered\"]\n\nmax_date = statewise_daily_stats_pivot[\"Date\"].max()\nmin_date = statewise_daily_stats_pivot[\"Date\"].min()\n    \ndate_range = int((max_date - min_date).days)\nreqd_date_values = pd.DataFrame([min_date + timedelta(days=i) for i in range(date_range+1)], columns = [\"Date\"])\nreqd_date_values[\"key\"] = \"0\"\n\nreqd_state_values = pd.DataFrame(statewise_daily_stats_pivot.State.unique(), columns = [\"State\"])\nreqd_state_values[\"key\"] = \"0\"\nreqd_values = pd.merge(reqd_date_values, reqd_state_values, how=\"outer\")\n#reqd_values\nstatewise_daily_stats_pivot = statewise_daily_stats_pivot.merge(reqd_values, on=[\"State\",\"Date\"], how=\"right\").fillna(0)\nstatewise_daily_stats_pivot = statewise_daily_stats_pivot.sort_values([\"State\",\"Date\"])","b0eff10d":"statewise_daily_stats_pivot[\"CumulativeDeceased\"] = statewise_daily_stats_pivot.groupby(\"State\")[\"Deceased\"].cumsum()\nstatewise_daily_stats_pivot[\"CumulativeCases\"] = statewise_daily_stats_pivot.groupby(\"State\")[\"Total Cases\"].cumsum()\nstatewise_daily_stats_pivot[\"CumulativeMR\"] = statewise_daily_stats_pivot[\"CumulativeDeceased\"]*100\/statewise_daily_stats_pivot[\"CumulativeCases\"]\nstatewise_daily_stats_pivot[\"StrDate\"] = statewise_daily_stats_pivot[\"Date\"].apply(lambda x:x.strftime(\"%d-%m\"))\nstatewise_daily_stats_pivot.sort_values(\"Date\", inplace=True)","40e80274":"fig = px.scatter(statewise_daily_stats_pivot.query(\"Date > '2020-03-01'\"), x=\"Date\", y=\"CumulativeMR\", animation_frame = \"StrDate\", animation_group=\"State\",\n           size=\"CumulativeCases\", color=\"State\", hover_name=\"State\",\n           log_x=False, size_max=100, range_x=[\"2020-03-01\",statewise_daily_stats_pivot[\"Date\"].max()], range_y=[0,10])\nfig.update_layout(\n        title=f\"Growth of Covid-19 over a period of time as of {last_date}\", xaxis_title='Date', yaxis_title='Mortality Rate')\nfig.show()","2fe7c691":"import scipy.optimize as opt\nfrom sklearn.metrics import mean_squared_log_error\n\ndef sigmoid(x, M, beta, alpha):\n    return M \/ (1 + np.exp(-beta * (x - alpha)))\n\ndef train_sigmoid(data):\n    if sum(data) == 0 or sum(data != 0) <= 3:\n        return (2*data[-1], 0.25, 0)\n    filtered_data = data[data > 0]#list(map(lambda x:int(x),list(data[data > 0])))\n    try:        \n        popt, pcov = opt.curve_fit(sigmoid, list(range(sum(data == 0), len(data))), \n                                   filtered_data, maxfev=10000, p0=[171550, 0.05, 120])\n        print(popt, pcov)\n        return popt\n    except Exception as e:\n        print(e)\n        return (2*data[-1], 0.25, 0) ","4855fc95":"national_df = statewise_daily_stats_pivot.groupby(\"Date\", as_index=False).agg({\"Hospitalized\":\"sum\"}).rename({\"Hospitalized\":\"ConfirmedCases\"}, axis=1)\nnational_df = national_df.sort_values(\"Date\")\nnational_df[\"CumulativeConfirmed\"] = national_df['ConfirmedCases'].cumsum()\ntoday = datetime.now().strftime(\"%Y-%m-%d\")\nnational_df = national_df.query(\"Date < @today\")\n\nM, beta, alpha = train_sigmoid(national_df[\"CumulativeConfirmed\"])\nprint(M, beta, alpha)\nsteps = 80\nx = list(range(0, len(national_df) + steps))\nmax_index = national_df.index\nmax_date = national_df[\"Date\"].max()\nfor i in range(steps):\n    national_df.loc[national_df.index.max() + 1] = [np.datetime64(max_date + np.timedelta64(i+1, \"D\")), np.NaN, np.NaN]\nnational_df\n\nnational_df[\"Preds\"] = np.NaN\nnational_df[\"Preds\"] = national_df.apply(lambda x:np.clip(sigmoid(x.index+1, M, beta, alpha), 0, None).astype(int))\n\nfig = go.Figure()\n\nx = list(range(0, len(national_df) + steps))\nnational_df[\"Preds\"] = national_df.apply(lambda x:np.clip(sigmoid(x.index, M, beta, alpha), 0, None).astype(int))\n\nfig.add_trace(go.Scatter(\n            x=national_df[\"Date\"], y=national_df[\"Preds\"],\n            name=f'National Cumulative Cases Predictions',\n            line=dict(color=\"Green\", dash='dash')\n        ))\n\nfig.add_trace(go.Scatter(\n            x=national_df[\"Date\"], y=national_df[\"CumulativeConfirmed\"],\n            name=f'National Cumulative Cases Actual',\n            line=dict(color=\"blue\")\n        ))\nfig.update_layout(\n        title=\"Total Cases in India Convergance\", xaxis_title='Date', yaxis_title='Confirmed cases')\nfig.add_trace(go.Scatter(x=[datetime.now()-timedelta(days=1), datetime.now()-timedelta(days=1)], y=[0, 1.1*M], name='Current Day', line=dict(dash='dot', color=('rgb(200, 200, 200)'))))\nfig.update_layout(\n    annotations=[\n        dict(\n            x=datetime.now()-timedelta(days=10),\n            y=1.1*M,\n            xref=\"x\",\n            yref=\"y\",\n            text=\"Actual\",\n            showarrow=False,\n        ),\n        dict(\n            x=datetime.now()+timedelta(days=10),\n            y=1.1*M,\n            xref=\"x\",\n            yref=\"y\",\n            text=\"Predicted\",\n            showarrow=False,\n        )\n    ]\n)\nfig.show()","e6e76c7b":"national_df = statewise_daily_stats_pivot.groupby(\"Date\", as_index=False).agg({\"Deceased\":\"sum\"})\nnational_df = national_df.sort_values(\"Date\")\nnational_df[\"CumulativeDeceased\"] = national_df['Deceased'].cumsum()\ntoday = datetime.now().strftime(\"%Y-%m-%d\")\nnational_df = national_df.query(\"Date < @today\")\n\nM, beta, alpha = train_sigmoid(national_df[\"CumulativeDeceased\"])\nprint(M, beta, alpha)\nsteps = 80\nx = list(range(0, len(national_df) + steps))\nmax_index = national_df.index\nmax_date = national_df[\"Date\"].max()\nfor i in range(steps):\n    national_df.loc[national_df.index.max() + 1] = [np.datetime64(max_date + np.timedelta64(i+1, \"D\")), np.NaN, np.NaN]\nnational_df\n\nnational_df[\"Preds\"] = np.NaN\nnational_df[\"Preds\"] = national_df.apply(lambda x:np.clip(sigmoid(x.index+1, M, beta, alpha), 0, None).astype(int))\n\nfig = go.Figure()\n\nx = list(range(0, len(national_df) + steps))\nnational_df[\"Preds\"] = national_df.apply(lambda x:np.clip(sigmoid(x.index, M, beta, alpha), 0, None).astype(int))\n\nfig.add_trace(go.Scatter(\n            x=national_df[\"Date\"], y=national_df[\"Preds\"],\n            name=f'National Cumulative Deceased Predictions',\n            line=dict(color=\"Green\", dash='dash')\n        ))\n\nfig.add_trace(go.Scatter(\n            x=national_df[\"Date\"], y=national_df[\"CumulativeDeceased\"],\n            name=f'National Cumulative Deceased Actual',\n            line=dict(color=\"blue\")\n        ))\nfig.update_layout(\n        title=\"Total Deaths in India Convergance\", xaxis_title='Date', yaxis_title='Confirmed cases')\nfig.add_trace(go.Scatter(x=[datetime.now()-timedelta(days=1), datetime.now()-timedelta(days=1)], y=[0, 1.1*M], name='Current Day', line=dict(dash='dot', color=('rgb(200, 200, 200)'))))\nfig.update_layout(\n    annotations=[\n        dict(\n            x=datetime.now()-timedelta(days=13),\n            y=1.1*M,\n            xref=\"x\",\n            yref=\"y\",\n            text=\"Actual\",\n            showarrow=False,\n        ),\n        dict(\n            x=datetime.now()+timedelta(days=13),\n            y=1.1*M,\n            xref=\"x\",\n            yref=\"y\",\n            text=\"Predicted\",\n            showarrow=False,\n        )\n    ]\n)\nfig.show()","8c0e10a2":"#### All of us want this phase and infection to end, however, is there a statistical model that can help us understand the approximate future timeline of this infection in India. \n#### There has been some research around modeling this, we will be following a basic approach which uses a 3 parameter sigmoid(logitstic growth curve) model for estimating when will the the infections hit the flat-line.\n#### [Three Parameter Logistic curve for predicting infections](https:\/\/assets.tue.nl\/fileadmin\/content\/pers\/2020\/03%20March\/TUe%20-%20Technical_Report_Prediction_Corona_Virus.pdf) is referenced for this analysis along with the following awesome kernels:\n* [Sigmoid per country](https:\/\/www.kaggle.com\/group16\/sigmoid-per-country-no-leakage)\n* [COVID-19 growth rates per country](https:\/\/www.kaggle.com\/mikestubna\/covid-19-growth-rates-per-country)\n\n#### Below is the equation that we are using for this modeling:\n![Equation](data:image\/png;base64,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)\n\n#### where M the maximal number of cases, \ud835\udefc the number of days at which the expected number of counts is half way the maximum,and \ud835\udefd > 0 the growth parameter. \n#### This however is just an approximation.","13ee51f3":"##### We will be using Plotly throughout this kernel to make sure that the visualizations are interactive and nicely formatted. ","af2412ce":"## Modeling convergance of the infections for India <a id=\"sigmoid-model\"><\/a>","b0149615":"# References","5abebf15":"#### However, One of the most important metric for any country in this time of crisis, is the Mortality Rate of the country due to COVID-19. Mortality rate is defined as the percentage of infected population that is deceased due to the infections. \n#### **Thankfully**, it is ~2% in India and is following a downward trend. A 10-day moving average line is overlayed to give clearer idea of the trend being followed by the Mortality Rate","aa2007d5":"## 3. Deep-dive into the situation across the states <a id=\"deep-dive\"><\/a>","bc57e152":"#### Let's get the Death and Recovered counts for the patients before 26th April 2020, and then merge them into the main dataset with confirmed cases","9a2492e6":"## Table of contents\n1. [Load and Prepare Data](#load-data)\n2. [Nationwide Cases\/Deaths Trend over time](#nationwide-trend)\n3. [Deep-dive across the states](#deep-dive)\n4. [Growth rate across the different states](#growth-rates)\n5. [Modeling convergance of the infections for India](#sigmoid-model)","1f8cc2b9":"The Mortality rate seems to be constant in India at around **2%**, however, it seems like it is declining over time. ","ae05e0cd":"#### Merging the final datset after 9th May into the main dataset","d16e5b92":"#### The Grey lines above indicate the path to follow to double cases every 1\/2\/3 weeks. Some of the states like Maharashtra are now close to the 3 week line in terms of slope. However, come of the states are still somewhere around doubling every 2 weeks.","e8e86704":"# Further Reading","8ac6af03":"#### Below kernels were extremely inspiring for this analysis. Do upvote these as well.\n* [COVID-19: current situation on May [Daily update]](https:\/\/www.kaggle.com\/corochann\/covid-19-current-situation-on-may-daily-update)\n* [Sigmoid per country](https:\/\/www.kaggle.com\/group16\/sigmoid-per-country-no-leakage)\n* [COVID-19 growth rates per country](https:\/\/www.kaggle.com\/mikestubna\/covid-19-growth-rates-per-country)\n","f8af210e":"#### Doing a similar analysis on the Fatalities over time, it's a relief to see that the cases of deaths are growing at a pace even slower than 21 days, for most of the states. But, for some of the states like Delhi, unfortunately the cases of deaths have recently started increasing at a pace of double every 7 days.\n\n#### Since we're using Plotly, we can take advantage of the animation feature, and look at graphs evolving over days. I am still trying to create one for India and show the growth as an animation across states, however, Plotly doesn't support a state-level graph for India. Below, we're going to look at the growth across time axis and Mortality Rate.","6086c04a":"## 2. Nationwide Daily Cases Trend over time  <a id=\"nationwide-trend\"><\/a>","540a8c33":"#### The results are as expected in the above charts. Maharashtra and Gujarat are the highest contributors to the overall deaths. However, that peak on May 3 in West Bengal is probably the reason for the overall high mortality rate of West Bengal.","4b8ad966":"#### According to this graph, the growth of new deaths will start slowing down starting June beginning, and the Maximum predicted deaths will be around 4788.","f429db72":"# COVID-19: Deep-dive EDA for INDIA\n### This Kernel is created to provide a daily in-depth view into the current Covid-19 situation in India. \n##### This kernel is inspired by a lot of different amazing kernels by folks on kaggle. References below.\n![](http:\/\/)![Covid19 Trend in India](https:\/\/miro.medium.com\/max\/1400\/1*TOnqCoCPCgoA1eimzdL0aw.jpeg)","9f3dad45":"## 1. Load and Prepare Data <a id=\"load-data\"><\/a> \n","93db2526":"#### Here, Maharashtra, Delhi, Gujarat and Tamil Nadu are leading the number of cases on a national level. At a superficial level this tells us the spread of infection, however what's more important is the way that the states are responsing to this high number of cases. We can look at the Mortality Rate to understand the situation in these states.\n#### Even though a state is having high number of cases, it is not necessary that the Mortality rate is also as high.","eb06b363":"### The data used in this kernel is provided by [Covid19India.Org](https:\/\/api.covid19india.org\/csv\/). This is a volunteer-driven, crowdsourced database for COVID-19 stats & patient tracing in India. The data is updated in a new real-time situation and is provided in [CSV\/JSON](https:\/\/api.covid19india.org\/) format.<br\/>\n**Personal note**: I am sure it takes a tremendous amount of effort to collate and maintain this form of data. Thanks to the [Covid19India.Org](https:\/\/telegra.ph\/CoVID-19--India-Ops-03-24) team. Follow them on [Telegram](https:\/\/t.me\/covid19indiaops), for more information.","262a5c47":"### Let's start by looking at the daily number of cases\/deaths trend for the entire nation. \n#### The daily number of cases and deaths seem to be ever-increasing at an exponential rate, even with a lockdown in place","d9b3f5ad":"## Growth rate across the different states <a id=\"growth-rates\"><\/a>","80617c43":"#### Now, let's merge the data till 9th May in the datset","0266d9fd":"#### Checkout the AnalyticsVidhya article where I take up similar data around covid for India, to perform Time-Series Analysis using Booting and Hyperparamter-optimization - [Tracking COVID-19 spread in India \u2014 Time-Series data modeling and clustering in Python](https:\/\/medium.com\/analytics-vidhya\/tracking-covid-19-spread-in-india-time-series-data-modeling-and-clustering-in-python-f3ca70eb4f2)","648ce0c1":"#### If the above graph is to be believed, the growth of new cases will start slowing down starting June last week, and the Maximum predicted cases will be around ~171K.[](http:\/\/)","9619477a":"#### Let's start the deep-dive by looking at the distribution of the number of cases across India into the different states using a [TreeMap](https:\/\/datavizcatalogue.com\/methods\/treemap.html). This will help us in understanding the contribution of the different states to total number of cases\/deaths.\n#### Also, we have pyplot for all of these visualizations to make them interactive. Hence, we can know the exact number of cases in any state just by hovering over the state and ","114f560d":"#### Let's look at the rate at which these states are experiencing new cases. We will be taking starting point as the day on which the state touched a total of 10 cases. \n#### We will be using Log scale to do the comparison and see the rate of which the cases are doubling in the states.","f7e54496":"#### This is very different from what we expected, **West Bengal** has highest Mortality Rate of **6.28%**, followed by Gujarat and Madhya Pradesh. \n#### Now, let's look at the top 15 states that are contributing highest to the number of cases across India."}}