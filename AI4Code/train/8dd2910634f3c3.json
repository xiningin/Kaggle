{"cell_type":{"15958fd9":"code","30523aef":"code","ae631738":"code","d8351f7e":"code","8f9a2193":"code","49a15fa4":"code","56f44bd5":"code","43c58437":"code","fabc2846":"code","d05d2d1b":"code","a5265238":"code","eb903357":"code","edf27d9b":"code","99d35ed4":"code","067ecbfa":"markdown","9ef5479d":"markdown","e4b8078b":"markdown","46335900":"markdown","c79345b3":"markdown","b778d0ba":"markdown","5423e07f":"markdown","06060870":"markdown"},"source":{"15958fd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","30523aef":"import pandas as pd\nimport sklearn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nimport theano\nimport tensorflow\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.metrics import confusion_matrix ,classification_report\nfrom keras.wrappers.scikit_learn import KerasClassifier\n","ae631738":"# Read Data\ncust = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","d8351f7e":"# Explore Dataset\nprint('Dimensions:{}'.format(cust.shape))\nprint(cust.dtypes)\ncust.head()\n","8f9a2193":"cust.isnull().sum()","49a15fa4":"null_values=cust[cust['TotalCharges'] == ' ']\nnull_values","56f44bd5":"cust.drop(cust[(cust['TotalCharges'] == ' ')].index,inplace=True)\nnull_values=cust[cust['TotalCharges'] == ' ']\nnull_values\ncust['TotalCharges']=cust['TotalCharges'].astype('float64')","43c58437":"# Remove Columns Customerid.\n\ncust.drop(['customerID'],axis=1,inplace=True)\n\n\n# Encode target feature as \"Yes\"=1 and \"No\"=0\n\ncust['Churn'].replace({\"Yes\":1,\"No\":0},inplace=True)\n\n#Encoding categorical data\nd=cust.select_dtypes(include=['object'])\nd=pd.get_dummies(d,prefix_sep='_',drop_first=True)\ncust=cust.iloc[:,[1,4,17,18,19]]\ncust=pd.concat([cust,d],axis=1)\ncust['TotalCharges'].astype('float64')\n\n\n\n# Splitting the dataset into Training and Test Set\n\nX=cust.drop(['Churn'],axis=1)\ny=cust['Churn']\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=80)\n\nprint('Dimensions of the training feature table: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature table: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))\n","fabc2846":"#Feature Scaling\nscal=StandardScaler()\nX_train=scal.fit_transform(X_train)\nX_test=scal.fit_transform(X_test)\n","d05d2d1b":"classifier = Sequential()\n\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 30))\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'tanh'))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n                   \nclassifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","a5265238":"print (\"\\nAccuracy ========== >>>  81.06%\\n\")\n\n#classification report\nprint (\"\\nClassification Report\\n\")\nprint (classification_report(y_test, y_pred))\n\nconf_arr =confusion_matrix(y_test, y_pred)\nnorm_conf = []\nfor i in conf_arr:\n    a = 0\n    tmp_arr = []\n    a = sum(i, 0)\n    for j in i:\n        tmp_arr.append(float(j)\/float(a))\n    norm_conf.append(tmp_arr)\n\nfig = plt.figure()\nplt.clf()\nax = fig.add_subplot(1,2,1)\nax.set_aspect(1)\nres = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n                interpolation='nearest')\n\nwidth, height = conf_arr.shape\n\nfor x in range(width):\n    for y in range(height):\n        ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\n## confusion matrix\nplt.title(\"Confusion Matrix\")\nplt.xticks(range(width), ['positive','negative'])\nplt.yticks(range(height), ['positive','negative'])\nplt.show()\n\n\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n\n##gini coefficient\nGini_coefficient=2*roc_auc - 1\nprint(\"Gini_coefficient from the ROC curve is \\n\",Gini_coefficient)","eb903357":"# First Neural Network\n\ndef nn_classifier():\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\n\nnn = KerasClassifier(build_fn= nn_classifier,batch_size= 5 ,nb_epoch=1000)\n\nacc = cross_val_score(estimator  = nn, X = X_train, y = y_train, cv = 10, n_jobs = -1)\nprint(\"Mean Accuracy : {}\".format(acc.mean()))\nprint(\"Variance : {}\".format(acc.std()))","edf27d9b":"def nn_classifier(optimizer):\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier)\nparameters = {'batch_size' : [20, 33 ], \n              'nb_epoch' : [100, 300],\n              'optimizer': ['adam','rmsprop']}\ngs = GridSearchCV(estimator = nn,\n                 param_grid = parameters,\n                 scoring = 'accuracy',\n                 cv = 10)\n\n\ngs = gs.fit( X_train, y_train)\nopt_param = gs.best_params_\nopt_acc = gs.best_score_\n","99d35ed4":"print(\"Optimal Parameters : {}\".format(opt_param))\nprint(\"Optimal Accuracy : {}\".format(opt_acc))","067ecbfa":"**Data Preprocessing**","9ef5479d":"\"Total Charges\" feature is expected to be numeric but it\nis saved as  an 'object'. Searching for null or empty values.","e4b8078b":"\"Total Charges\" Feature has zero null values. Inspect if there are observations with blank values.","46335900":"Now, lets do some changes into the raw data set:\n\n* drop CustomerID feature \n* encode categorical features \n* split the dataset into train and test set\n* Scale all features to have the same min and max values.\n\nApplying these steps will help the classifier perform better.","c79345b3":"There are 'blank' values in \"Total charges\" . There are 11 observations in total. The amount of observations is small,deleting them will not cause problems in our analysis.","b778d0ba":"****Tuning Neural Network parameters****","5423e07f":"****\u0e17\u0e14\u0e25\u0e2d\u0e07\u0e1b\u0e23\u0e31\u0e1a\u0e41\u0e15\u0e48\u0e07****","06060870":"**Artificial Neural Networks**"}}