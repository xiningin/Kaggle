{"cell_type":{"127074fd":"code","56286fef":"code","0e4f2c9a":"code","1a5459f9":"code","87ae309c":"code","2ea6742e":"code","e6616bda":"code","2affaf0e":"code","57e0d07e":"code","847a2a1f":"code","3e116966":"code","aea81507":"code","4f507827":"code","26691e1c":"code","8affbbc4":"code","90078efe":"code","e61554b3":"code","53741a9b":"code","9f060871":"code","976e44c8":"code","54d3d69f":"code","fdfcacf9":"code","32355236":"code","a155ad1a":"code","973da6a4":"code","006e49f1":"code","64b6c801":"code","63617ec8":"code","4c36d13d":"code","cbf6cbe0":"code","a634ad65":"code","79488e7d":"code","3e756a38":"code","8a0f4cef":"markdown","f36645bb":"markdown","3bc829ef":"markdown","b532c317":"markdown","77bb976d":"markdown","f0e8831d":"markdown","e84eea8e":"markdown","74275bd8":"markdown","be5d7c83":"markdown","a3dd4eca":"markdown","6cbe87e3":"markdown","afe7b14f":"markdown","37e94a11":"markdown","109ba2d1":"markdown","31398a08":"markdown","44340ecc":"markdown","1126bab8":"markdown"},"source":{"127074fd":"import math\nimport matplotlib.pylab as plt\nimport matplotlib.cm as cm\nimport numpy as np\nimport os\nimport pandas as pd\nimport pathlib\nimport PIL\nimport PIL.Image\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport shutil\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport warnings\n\nfrom distutils.dir_util import copy_tree\nfrom IPython.display import Image\nfrom random import sample\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nwarnings.filterwarnings('ignore')","56286fef":"# Place in a variable the dataset's path.\n\ndataset_path = \"..\/input\/cacao-diseases\/cacao_diseases\/cacao_photos\"","0e4f2c9a":"# Display the quantity of each class.\n\nblack_pod_count = os.listdir(dataset_path+\"\/black_pod_rot\")\nprint(f\"Black Pod Rot : {len(black_pod_count)}\")\nhealthy_count = os.listdir(dataset_path+\"\/healthy\")\nprint(f\"Healthy : {len(healthy_count)}\")\npod_borer_count = os.listdir(dataset_path+\"\/pod_borer\")\nprint(f\"Pod Borer : {len(pod_borer_count)}\")\n","1a5459f9":"# Create various directories for Model Building.\n\nos.mkdir(\"train_photos\")\nos.mkdir(\"val_photos\")\nos.mkdir(\"augment_photos\")\nos.mkdir(\"best_models\")","87ae309c":"# Copy and place the dataset into the \/kaggle\/working\/ folder.\n\ncopy_tree(dataset_path, \".\/train_photos\")","2ea6742e":"# Place in a variable the dataset's path in working directory.\n\nimage_path = \".\/train_photos\"","e6616bda":"# Create validation folder for each classes.\n\nos.mkdir(\"val_photos\/black_pod_rot\")\nos.mkdir(\"val_photos\/healthy\")\nos.mkdir(\"val_photos\/pod_borer\")","2affaf0e":"# Create a function that moves a specific number of files from lake_path to processed_path.\n\ndef move_num_of_files(count, lake_path, processed_path, count_end):\n    try:\n        images = os.listdir(lake_path)\n        for file in images:\n            if count < count_end:\n                path = f\"{lake_path}\/{file}\"\n                shutil.move(path, processed_path)\n                count += 1\n    except Exception as e:\n        print(e)","57e0d07e":"# Move 20% each class into val_photos directory.\n\nblack_pod_20 = math.ceil(len(black_pod_count)*0.20)\nhealthy_20 = math.ceil(len(healthy_count)*0.20)\npod_borer_20 = math.ceil(len(pod_borer_count)*0.20)\n\nmove_num_of_files(0, image_path+\"\/black_pod_rot\", \".\/val_photos\/black_pod_rot\",black_pod_20)\nmove_num_of_files(0, image_path+\"\/healthy\", \".\/val_photos\/healthy\",healthy_20)\nmove_num_of_files(0, image_path+\"\/pod_borer\", \".\/val_photos\/pod_borer\",pod_borer_20)","847a2a1f":"# Reduce healthy class randomly.\n\nblack_pod_current_count = os.listdir(image_path+\"\/black_pod_rot\")\nhealthy_current_count = os.listdir(image_path+\"\/healthy\")\npod_borer_current_count = os.listdir(image_path+\"\/pod_borer\")\n\n\nhealthy_path = image_path + \"\/healthy\"\nhealthy = os.listdir(healthy_path)\nfor file in sample(healthy,(len(healthy_current_count)-len(black_pod_current_count))):\n    os.remove(healthy_path+\"\/\"+file)","3e116966":"!pip install Augmentor","aea81507":"import Augmentor\n\n# Define augmentation pipelines.\n\npod_borer_augmentation_pipeline = Augmentor.Pipeline(source_directory=image_path+\"\/pod_borer\", output_directory=image_path+\"\/pod_borer\")\n\n# Define different augmentations depending on the pipeline.\n\npod_borer_augmentation_pipeline.rotate(probability=0.6, max_left_rotation=10, max_right_rotation=10)\npod_borer_augmentation_pipeline.skew_top_bottom(0.3, 0.7)\npod_borer_augmentation_pipeline.skew_left_right(0.3, 0.7)\npod_borer_augmentation_pipeline.flip_random(0.3)\n\n# Augment pod borer class.\n\npod_borer_augmentation_pipeline.sample(len(black_pod_current_count)-len(pod_borer_current_count))","4f507827":"# Place hyperparameters in variables for model building.\n\nbatch_size = 1\nimg_height = 224\nimg_width = 224\nclass_mode = \"sparse\"\nepochs = 30","26691e1c":"# Clears the directory containing the best model.\n\nshutil.rmtree('.\/best_models')\nos.mkdir(\"best_models\")","8affbbc4":"datagen = tf.keras.preprocessing.image.ImageDataGenerator()\ntrain_path = \".\/train_photos\"\nval_path = \".\/val_photos\"\nvalgen = tf.keras.preprocessing.image.ImageDataGenerator()","90078efe":"# Creation of Train and Validation sets in a format readable by the model.\n\ntrain_generator = datagen.flow_from_directory(\n    train_path,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=class_mode,\n)\n\nval_generator = valgen.flow_from_directory(\n    val_path,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=class_mode,\n    shuffle=False\n)","e61554b3":"# For this dataset we will be imitating google's CNN layer called EfficientNet.\n\nmodel = tf.keras.applications.EfficientNetB0(include_top=False,\n                                             input_shape=train_generator.image_shape)\n\n\nmodel.trainable = False\nfor layer in model.layers:\n    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True\n\n# Adding 2 fully-connected layers.\n\nx = model.output\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\npredictions = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\nworking_model = tf.keras.Model(inputs = model.input, outputs = predictions)\nworking_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n              optimizer=tf.keras.optimizers.Adam(0.0001),\n              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n# Defining callbacks.\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  mode='min',\n                                                  patience=4)\ncheckpoint_filepath = '.\/best_models\/lowest_val_loss.h5'\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n                                                verbose=1,\n                                                monitor='val_loss',\n                                                save_best_only=True,\n                                                mode='min')\n\n# Display Model Configurations.\n\nworking_model.summary()","53741a9b":"model_history = working_model.fit(train_generator,\n                                  epochs=epochs,\n                                  callbacks=[early_stopping,\n                                             checkpoint],\n                                  validation_data=val_generator)","9f060871":"# Load the best model produced in model training.\n\nbest_model = tf.keras.models.load_model('.\/best_models\/lowest_val_loss.h5')","976e44c8":"val_pred = best_model.predict(val_generator)\nval_cm = confusion_matrix(val_generator.classes,\n                      np.argmax(val_pred, axis=1))\nval_axis_labels = ['black pod rot', 'healthy', 'pod borer']\nplt.title(\"Validation Set\", fontsize =20)\nval_ax = sns.heatmap(val_cm,\n                 cmap=\"Greens\",\n                 annot=True,\n                 xticklabels=val_axis_labels,\n                 yticklabels=val_axis_labels,\n                 fmt=\"d\")","54d3d69f":"\nval_predictions = best_model.predict(val_generator)\nval_predicted_classes = np.argmax(val_predictions, axis=1)\nval_classes = val_generator.classes\nprint(classification_report(val_classes,val_predicted_classes,target_names=[\"black pod rot\", \"healthy\", \"pod borer pest\"]))","fdfcacf9":"# Define scatter plot visualization on plotly express.\n\ndef display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss with respect to Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy with respect to Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Training\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Validation\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","32355236":"plt.plot(model_history.history['sparse_categorical_accuracy'])\nplt.plot(model_history.history['val_sparse_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylim(top=1.1)\nplt.ylim(bottom=0)\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","a155ad1a":"display_training_curves(\n    model_history.history['sparse_categorical_accuracy'], \n    model_history.history['val_sparse_categorical_accuracy'], \n    'accuracy')","973da6a4":"plt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylim(top=1.1)\nplt.ylim(bottom=0)\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","006e49f1":"display_training_curves(\n    model_history.history['loss'], \n    model_history.history['val_loss'], \n    'loss')","64b6c801":"# Define layers for producing heat maps. \n\nlast_conv_layer_name = \"top_conv\"\nclassifier_layer_names = [\n    \"global_average_pooling2d\",\n    \"dense\",\n]","63617ec8":"# Define heatmap function helpers.\n\ndef get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(\n    img_array, model, last_conv_layer_name, classifier_layer_names\n):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = tf.keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","4c36d13d":"# Sort validation set classes into arrays. \n\ntotal_batch = val_generator.__len__()\nval_generator.reset()\npod_borer_array = []\nblack_pod_array = []\nhealthy_array = []\nfor i in range (total_batch):\n  x,y = val_generator.next()\n  count = 0\n  for label in y:\n    if label == 2.0:\n        pod_borer_array.append(x[count])\n    elif label == 1.0:\n        healthy_array.append(x[count])\n    else:\n        black_pod_array.append(x[count])\n    count += 1\n","cbf6cbe0":"# Define heat map activation display in a graph.\n\ndef display_activation_graph(image_array, label):\n    \n    # display predictions on validation set\n    plt.figure(figsize=(10,10)) # specifying the overall grid size\n    correct = 0\n    for i in range(20):\n        plt.subplot(4,5,i+1)    # the number of images in the grid is 4*5 (25)\n        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n        plt.imshow(pil_img)\n        inference = best_model.predict( np.array( [image_array[i],] )  )\n        verdict = np.argmax(inference[0])\n        if verdict == label:\n          correct += 1\n        plt.title(f\"{label} == {verdict}\")\n    plt.suptitle(f\"Model Prediction on Validation Set \\n {correct}\/20 Correct\")\n    plt.show()\n    \n    # display heatmap\n    plt.figure(figsize=(10,10)) # specifying the overall grid size\n    correct = 0\n    for i in range(20):\n        plt.subplot(4,5,i+1)    # the number of images in the grid is 4*5 (25)\n        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n        inference = best_model.predict( np.array( [image_array[i],] )  )\n        heatmap = make_gradcam_heatmap(np.array( [image_array[i],] ),\n                                       best_model,\n                                       last_conv_layer_name,\n                                       classifier_layer_names)\n        img = image_array[i]\n        heatmap = np.uint8(255 * heatmap)\n        jet = cm.get_cmap(\"jet\")\n        jet_colors = jet(np.arange(256))[:, :3]\n        jet_heatmap = jet_colors[heatmap]\n        jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n        jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n        superimposed_img = jet_heatmap * 0.4 + img\n        superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n        plt.imshow(superimposed_img)\n        verdict = np.argmax(inference[0])\n        if verdict == label:\n          correct += 1\n        plt.title(f\"{label} == {verdict}\")\n    plt.suptitle(f\"Heat Map Representation \\n {correct}\/20 Correct\")\n    plt.show()\n    \n    # display class activation\n    plt.figure(figsize=(10,10)) # specifying the overall grid size\n    correct = 0\n    for i in range(20):\n        plt.subplot(4,5,i+1)    # the number of images in the grid is 4*5 (25)\n        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n        inference = best_model.predict( np.array( [image_array[i],] )  )\n        heatmap = make_gradcam_heatmap(np.array( [image_array[i],] ),\n                                       best_model,\n                                       last_conv_layer_name,\n                                       classifier_layer_names)\n        plt.imshow(heatmap)\n        verdict = np.argmax(inference[0])\n        if verdict == label:\n          correct += 1\n        plt.title(f\"{label} == {verdict}\")\n    plt.suptitle(f\"Class Activation\")\n    plt.show()","a634ad65":"display_activation_graph(pod_borer_array, 2)","79488e7d":"display_activation_graph(black_pod_array, 0)","3e756a38":"display_activation_graph(healthy_array, 1)","8a0f4cef":"## Healthy activation","f36645bb":"## Class Activation","3bc829ef":"## Model's Accuracy","b532c317":"## Data Augmentation","77bb976d":"## Model Training","f0e8831d":"## Black Pod Rot Activation","e84eea8e":"## Import Packages","74275bd8":"## Model's Loss","be5d7c83":"## Data Preparation","a3dd4eca":"## Creation of Validation Set","6cbe87e3":"## Other Metrics","afe7b14f":"## Data Cleaning","37e94a11":"## Pod Borer Activation","109ba2d1":"# Data Exploration","31398a08":"# Model Building","44340ecc":"# Model Validation and Exploration","1126bab8":"## Validation Set Confusion Matrix"}}