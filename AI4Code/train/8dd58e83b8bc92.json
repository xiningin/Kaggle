{"cell_type":{"cd62a0db":"code","8d985fd1":"code","72a5b30f":"code","f6471d0d":"code","03f893f3":"code","3ef6d9e7":"code","8e43b362":"code","3f2a9100":"code","e796b14e":"code","b0d80637":"code","f3b6be80":"code","546ac428":"code","c17996fd":"code","6eddb314":"code","23d38a30":"code","9527b5bf":"code","f6afad87":"code","f35e31c4":"code","9784082b":"code","48834e47":"code","1bd65eb6":"code","7c6ebed2":"code","0bd26fc5":"code","bb49a0bd":"code","41e69956":"code","58fff06c":"code","96f09571":"code","55d91bdd":"code","1aca04ee":"code","1d35ae04":"code","2b7cce08":"markdown","c6cbd070":"markdown","a6e19f8e":"markdown","dd889eda":"markdown","694ea468":"markdown","ef00b3b5":"markdown","55389bb1":"markdown","cf9f47d1":"markdown","c51a84a8":"markdown","02da3857":"markdown","4211ce09":"markdown","5e1f182a":"markdown","39238d00":"markdown","cecce540":"markdown","08cbef41":"markdown","835d3141":"markdown"},"source":{"cd62a0db":"import numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom hyperopt import STATUS_OK, fmin, hp, tpe\nfrom ray import tune\nfrom skopt import BayesSearchCV","8d985fd1":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","72a5b30f":"train['LastName'] = train['Name'].str.split(',', expand=True)[0]\ntest['LastName'] = test['Name'].str.split(',', expand=True)[0]\nds = pd.concat([train, test])\n\nsur = list()\ndied = list()\n\nfor index, row in ds.iterrows():\n    s = ds[(ds['LastName']==row['LastName']) & (ds['Survived']==1)]\n    d = ds[(ds['LastName']==row['LastName']) & (ds['Survived']==0)]\n    s=len(s)\n    if row['Survived'] == 1:\n        s-=1\n    d=len(d)\n    if row['Survived'] == 0:\n        d-=1\n    sur.append(s)\n    died.append(d)\nds['FamilySurvived'] = sur\nds['FamilyDied'] = died\n\nds['FamilySize'] = ds['SibSp'] + ds['Parch'] + 1\nds['IsAlone'] = 0\nds.loc[ds['FamilySize'] == 1, 'IsAlone'] = 1\nds['Fare'] = ds['Fare'].fillna(train['Fare'].median())\nds['Embarked'] = ds['Embarked'].fillna('Q')\n\ntrain = ds[ds['Survived'].notnull()]\ntest = ds[ds['Survived'].isnull()]\ntest = test.drop(['Survived'], axis=1)\n\ntrain['rich_woman'] = 0\ntest['rich_woman'] = 0\ntrain['men_3'] = 0\ntest['men_3'] = 0\n\ntrain.loc[(train['Pclass']<=2) & (train['Sex']=='female'), 'rich_woman'] = 1\ntest.loc[(test['Pclass']<=2) & (test['Sex']=='female'), 'rich_woman'] = 1\ntrain.loc[(train['Pclass']==3) & (train['Sex']=='male'), 'men_3'] = 1\ntest.loc[(test['Pclass']==3) & (test['Sex']=='male'), 'men_3'] = 1\n\ntrain['rich_woman'] = train['rich_woman'].astype(np.int8)\ntest['rich_woman'] = test['rich_woman'].astype(np.int8)\n\ntrain[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in train['Cabin']])\ntest['Cabin'] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in test['Cabin']])\n\nfor cat in ['Pclass', 'Sex', 'Embarked', 'Cabin']:\n    train = pd.concat([train, pd.get_dummies(train[cat], prefix=cat)], axis=1)\n    train = train.drop([cat], axis=1)\n    test = pd.concat([test, pd.get_dummies(test[cat], prefix=cat)], axis=1)\n    test = test.drop([cat], axis=1)\n    \ntrain = train.drop(['PassengerId', 'Ticket', 'LastName', 'SibSp', 'Parch', 'Sex_male', 'Name'], axis=1)\ntest =  test.drop(['PassengerId', 'Ticket', 'LastName', 'SibSp', 'Parch', 'Sex_male', 'Name'], axis=1)\n\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\ntrain.head()","f6471d0d":"y = train['Survived']\nX = train.drop(['Survived', 'Cabin_T'], axis=1)\nX_test = test.copy()\n\nX, X_val, y, y_val = train_test_split(X, y, random_state=666, test_size=0.2, shuffle=False)","03f893f3":"model = XGBClassifier(\n    random_state=666\n)\nmodel.fit(X, y)\npreds = model.predict(X_val)\n\nprint('Default XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Default XGB f1-score: ', f1_score(y_val, preds))","3ef6d9e7":"preds = model.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('default_submission.csv', index=False)","8e43b362":"%%time\n\nparameters = {\n    'max_depth': [4, 5, 6],\n    'n_estimators': [70, 80, 90, 100, 120, 150],\n    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.35, 0.5], \n    'gamma': [0.01, 0.1, 0.2, 0.3, 0.5, 0.7, 0.95]\n}\n\nestimator = XGBClassifier(\n    random_state=666\n)\n\nclf = GridSearchCV(\n    estimator, \n    parameters\n)\n\nclf.fit(X, y)","3f2a9100":"grid_search_params = clf.best_params_\ngrid_search_params['random_state'] = 666\ngrid_search_params","e796b14e":"grid_xgb = XGBClassifier(\n    **grid_search_params\n)\n\ngrid_xgb.fit(X, y)\npreds = grid_xgb.predict(X_val)\n\nprint('Grid Search XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Grid Search XGB f1-score: ', f1_score(y_val, preds))","b0d80637":"preds = grid_xgb.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('grid_search_submission.csv', index=False)","f3b6be80":"# To see optuna progress you need to comment this row\noptuna.logging.set_verbosity(optuna.logging.WARNING)","546ac428":"class Optimizer:\n    def __init__(self, metric, trials=50):\n        self.metric = metric\n        self.trials = trials\n        self.sampler = TPESampler(seed=666)\n        \n    def objective(self, trial):\n        model = create_model(trial)\n        model.fit(X, y)\n        preds = model.predict(X_val)\n        if self.metric == 'acc':\n            return accuracy_score(y_val, preds)\n        else:\n            return f1_score(y_val, preds)\n            \n    def optimize(self):\n        study = optuna.create_study(\n            direction=\"maximize\", \n            sampler=self.sampler\n        )\n        study.optimize(\n            self.objective, \n            n_trials=self.trials\n        )\n        return study.best_params","c17996fd":"%%time\n\ndef create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 6)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 150)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    gamma = trial.suggest_uniform('gamma', 0.0000001, 1)\n    model = XGBClassifier(\n        learning_rate=learning_rate, \n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        gamma=gamma, \n        random_state=666\n    )\n    return model\n\noptimizer = Optimizer('acc', 100)\noptuna_params = optimizer.optimize()\noptuna_params['random_state'] = 666\noptuna_params","6eddb314":"optuna_xgb = XGBClassifier(\n    **optuna_params\n)\noptuna_xgb.fit(X, y)\npreds = optuna_xgb.predict(X_val)\n\nprint('Optuna XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Optuna XGB f1-score: ', f1_score(y_val, preds))","23d38a30":"preds = optuna_xgb.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('optuna_submission.csv', index=False)","9527b5bf":"def score(params):\n    model = XGBClassifier(\n        **params\n    )\n    model.fit(X, y)\n    predictions = model.predict(X_val)\n    \n    return {\n        'loss': 1 - accuracy_score(y_val, predictions), \n        'status': STATUS_OK\n    }","f6afad87":"%%time\n\nspace = {\n    'n_estimators': hp.choice('n_estimators', range(1, 150, 1)),\n    'learning_rate': hp.quniform('learning_rate', 0.0005, 1, 0.0005),\n    'max_depth':  hp.choice('max_depth', range(2, 6, 1)),\n    'gamma': hp.quniform('gamma', 0.0005, 1, 0.0025),\n    'random_state': 666\n}\n\nbest = fmin(\n    score, \n    space, \n    algo=tpe.suggest, \n    max_evals=1000\n)\n\nbest","f35e31c4":"hyperopt_xgb = XGBClassifier(\n    **best\n)\nhyperopt_xgb.fit(X, y)\npreds = hyperopt_xgb.predict(X_val)\n\nprint('Hyperopt XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Hyperopt XGB f1-score: ', f1_score(y_val, preds))","9784082b":"preds = hyperopt_xgb.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('hyperopt_submission.csv', index=False)","48834e47":"config = {\n    \"max_depth\": tune.randint(2, 6),\n    \"n_estimators\": tune.randint(1, 150),\n    \"gamma\": tune.uniform(0.0, 1.0),\n    \"learning_rate\": tune.uniform(0.0, 1.0),\n    'random_state': 666\n}","1bd65eb6":"def train_ray(config):\n    model = XGBClassifier(\n        **config\n    )\n    \n    model.fit(X, y)\n    predictions = model.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    \n    tune.report(\n        mean_accuracy=accuracy, \n        done=True\n    )","7c6ebed2":"%%time\n\nanalysis = tune.run(\n    train_ray,\n    metric=\"mean_accuracy\",\n    mode=\"max\",\n    config=config,\n    num_samples=300,\n    verbose=-1\n)","0bd26fc5":"ray_params = analysis.best_config\nray_params","bb49a0bd":"ray_xgb = XGBClassifier(\n    **ray_params\n)\n\nray_xgb.fit(X, y)\npreds = ray_xgb.predict(X_val)\n\nprint('Ray Tune XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Ray Tune XGB f1-score: ', f1_score(y_val, preds))","41e69956":"preds = ray_xgb.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('raytune_submission.csv', index=False)","58fff06c":"params = dict()\nparams['learning_rate'] = (0.000001, 1.0, 'log-uniform')\nparams['gamma'] = (0.000001, 1.0, 'log-uniform')\nparams['max_depth'] = (2, 6)\nparams['n_estimators'] = (1, 150)","96f09571":"%%time\n\ncv = RepeatedStratifiedKFold(\n    n_splits=8, \n    n_repeats=5, \n    random_state=666\n)\n\nsearch = BayesSearchCV(\n    estimator=XGBClassifier(\n        random_state=666\n    ), \n    search_spaces=params, \n    cv=cv\n)\n\nsearch.fit(X, y)\nsearch.best_params_","55d91bdd":"skopt_params = dict()\n\nfor param in search.best_params_:\n    skopt_params[param] = search.best_params_[param]\n\nskopt_params['random_state'] = 666","1aca04ee":"skopt_xgb = XGBClassifier(\n    **skopt_params\n)\n\nskopt_xgb.fit(X, y)\npreds = skopt_xgb.predict(X_val)\n\nprint('Ray Tune XGB accuracy: ', accuracy_score(y_val, preds))\nprint('Ray Tune XGB f1-score: ', f1_score(y_val, preds))","1d35ae04":"preds = skopt_xgb.predict(X_test)\npreds = preds.astype(np.int16)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('skopt_submission.csv', index=False)","2b7cce08":"<a id=\"2\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>2. XGBoost with default parameters<center><h2>","c6cbd070":"<a id=\"7\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>7. Skopt<center><h2>","a6e19f8e":"## LB score: 0.77990","dd889eda":"## LB score: 0.77990","694ea468":"### Hello everyone! In this kernel I am going to present some most used techniques for hyperparameters optimization. Let's do it!\n\n<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Black; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h3>\n\n* [1. Feature engineering](#1)\n* [2. XGBoost with default parameters](#2)\n* [3. Grid Search hyperparameters optimization](#3)\n* [4. Optuna hyperparameters optimization](#4)\n* [5. Hyperopt](#5)\n* [6. Ray Tune](#6)\n* [7. Skopt](#7)\n* [8. TBD](#8)","ef00b3b5":"<a id=\"1\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>1. Feature engineering<center><h2>","55389bb1":"<a id=\"4\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>4. Optuna hyperparameters optimization<center><h2>","cf9f47d1":"<h1><center>Titanic: hyperparameters tuning techniques<\/center><\/h1>\n\n<center><img width=\"1000\" height=\"800\" src=\"https:\/\/www.dlt.travel\/immagine\/33923\/magazine-titanic2.jpg\"><\/center>","c51a84a8":"## LB score: 0.77990 (version 12)","02da3857":"<a id=\"3\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>3. Grid Search hyperparameters optimization<center><h2>","4211ce09":"## LB score: 0.77272","5e1f182a":"<a id=\"5\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>5. Hyperopt<center><h2>","39238d00":"<a id=\"8\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>8. WORK IN PROGRESS<center><h2>","cecce540":"<a id=\"6\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>6. Ray Tune<center><h2>","08cbef41":"## LB score: 0.78708","835d3141":"## LB score: 0.77990 (version 12)"}}