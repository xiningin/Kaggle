{"cell_type":{"dca754a9":"code","b70705f9":"code","b77ff05c":"code","a077333f":"code","d7994551":"code","0b334b7b":"code","fae6f89f":"code","52c6fec5":"code","549a7271":"code","722b41d7":"code","5f042a0e":"code","32d974ed":"code","1fa9e104":"code","438de640":"code","9ac59c3b":"code","733860f8":"code","a7e0148b":"code","11c08f23":"code","93adc2f4":"code","6ed00c1f":"code","960fcdf6":"code","e1fd56d7":"code","2baac6f5":"code","908b8ddc":"code","837dc807":"code","35a9842f":"code","0aa01ab3":"code","e68c9913":"code","0bab1106":"code","e98bf95e":"code","ae726294":"code","d92bf098":"code","2ee9f59b":"markdown"},"source":{"dca754a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom scipy import stats\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn import clone\n\nimport time\nfrom functools import reduce\nfrom operator import mul\nimport os\nimport glob\nimport math\nimport logging\n# from utils.logging import log_and_warn\n\n\nimport argparse\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b70705f9":"book_example = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\ntrade_example =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id","b77ff05c":"book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) \/ (\n                                       book_example['bid_size1']+ book_example['ask_size1'])","a077333f":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n","d7994551":"book_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]\nbook_example.head()","0b334b7b":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')","fae6f89f":"\nlist_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')","52c6fec5":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","549a7271":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\n\n# df_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n#                                                            prediction_column_name='pred')\n# df_past_realized_train","722b41d7":"train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.sample(10)","5f042a0e":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\n# df_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')\ntrain.sample(10)","32d974ed":"# df_joined","1fa9e104":"# from sklearn.metrics import r2_score\n# def rmspe(y_true, y_pred):\n#     return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n# R2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\n# RMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\n# print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","438de640":"def data_prep(list_order_book_file):\n    df_past_realized = pd.DataFrame()\n    for file in list_order_book_file:\n        df_book_data = pd.read_parquet(file)\n        df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                              df_book_data['bid_size1']+ df_book_data[\n                                          'ask_size1'])\n        df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n        df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n#     return df_book_data\n        df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n        df_realized_vol_per_stock = df_realized_vol_per_stock\n        stock_id = file.split('=')[1]\n        df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n        df_past_realized = pd.concat([df_past_realized, df_realized_vol_per_stock[['row_id','log_return']]])\n    return df_past_realized[['row_id','log_return']]","9ac59c3b":"\"\"\"\nStratificationSplitter class\n\"\"\"\n\nclass StratificationSplitter:\n    def __init__(self, data, stratification_column_names, max_categories=10,\n                 test_size=None, val_size=None, n_train_cv_splits=3, random_state=None):\n    \n        logging.info(\n            \"Initializing StratificationSplitter with test_size {}, val_size {} and {} train data cross-validation \"\n            \"splits. Stratification by {} columns with max_categories {}\".format(\n                test_size if test_size else 0, val_size if val_size else 0, n_train_cv_splits,\n                stratification_column_names, max_categories\n            )\n        )\n        assert data.shape[0] > n_train_cv_splits\n        self._data = data[~data.index.duplicated(keep=\"last\")]\n        self.stratification_column_names = stratification_column_names\n        assert max_categories > 2\n        self.max_categories = max_categories\n        self.test_size = test_size\n        self.val_size = val_size\n        if test_size is not None:\n            self.test_size = math.ceil(self._data.shape[0] * test_size) if test_size < 1 else int(test_size)\n        if val_size is not None:\n            self.val_size = math.ceil(self._data.shape[0] * val_size) if val_size < 1 else int(val_size)\n        assert self.test_size is None or 0 < self.test_size <= self._data.shape[0] - n_train_cv_splits\n        assert self.val_size is None or 0 < self.val_size <= self._data.shape[0] - n_train_cv_splits\n        if test_size is not None and val_size is not None:\n            if self.test_size + self.val_size > data.shape[0] - n_train_cv_splits:\n                raise ValueError(\n                    \"Sum of test and validation sizes must be less than dataset size minus `n_train_cv_splits`\"\n                )\n        assert n_train_cv_splits >= 2\n        self.n_train_cv_splits = n_train_cv_splits\n        self.random_state = random_state\n        self._stratification = pd.DataFrame([], index=self._data.index.values)\n        self._train_ids = None\n        self._test_ids = None\n        self._val_ids = None\n        self._cv_ids = None\n        for col in stratification_column_names:\n            if col not in self._data.columns:\n                raise ValueError(\"Column `{}` wasn't found in dataset\".format(col))\n            self._add_stratification_column(self._data[col])\n        np.random.seed(self.random_state)\n        if self._stratification.empty:\n            random_col = np.zeros_like(self._stratification.index.values, dtype=np.int64)\n            random_col[:len(random_col) \/\/ 2] = 1\n            np.random.shuffle(random_col)\n            self._stratification[\"no_stratification (random)\"] = random_col\n\n    def _add_stratification_column(self, col):\n        unique, unique_counts = np.unique(col, return_counts=True)\n        if len(unique) <= self.max_categories and np.all(unique_counts >= self.n_train_cv_splits):\n            self._stratification[col.name] = col\n        elif len(unique) > self.max_categories and col.dtype.kind in {\"f\", \"u\", \"i\"}:\n            self._stratification[col.name] = pd.qcut(col, self.max_categories, duplicates=\"drop\")\n            buckets = list(zip(*np.unique(self._stratification[col.name], return_counts=True)))\n            logging.warning(\n                \"Column `{}` is numeric with more than {} unique values, so it was quantile-discretized \"\n                \"into {} buckets: {}\".format(col.name, self.max_categories, len(buckets), buckets)\n            )\n        elif ~np.all(unique_counts >= self.n_train_cv_splits):\n            print(\n                \"Column `{}` was removed from stratification because it had categories with less than {} members. The \"\n                \"minimum number of members in any category cannot be less than number of cross-validation \"\n                \"splits\".format(col.name, self.n_train_cv_splits)\n            )\n        else:\n            print(\n                \"Column `{}` was removed from stratification because it had more than {} categories and couldn't be \"\n                \"discretized\".format(col.name, self.max_categories)\n            )\n\n    def _split(self):\n        # train\/test\/validation split\n        logging.info(\"Creating train\/test\/validation set splits...\")\n        train_ids = self._stratification.index.values\n        all_train_test_val_ids = [self._stratification.index.values]\n        all_train_test_val_ids_names = [\"full dataset\"]\n        if self.test_size is not None:\n            train_ids, test_ids = train_test_split(\n                train_ids, stratify=self._stratification.loc[train_ids],\n                test_size=self.test_size, random_state=self.random_state\n            )\n            self._test_ids = test_ids\n            all_train_test_val_ids.append(test_ids)\n            all_train_test_val_ids_names.append(\"test\")\n        if self.val_size is not None:\n            train_ids, val_ids = train_test_split(\n                train_ids, stratify=self._stratification.loc[train_ids],\n                test_size=self.val_size, random_state=self.random_state\n            )\n            self._val_ids = val_ids\n            all_train_test_val_ids.append(val_ids)\n            all_train_test_val_ids_names.append(\"validation\")\n        self._train_ids = train_ids\n        all_train_test_val_ids.append(train_ids)\n        all_train_test_val_ids_names.append(\"train\")\n        # log stratification percentages\n        for feature in self._stratification.columns:\n            messages = list()\n            messages.append(\"Stratification on feature: %s\" % feature)\n            for i, ids in enumerate(all_train_test_val_ids):\n                messages.append(\n                    \"%s sample:  Shape: %s, statistics: %s\" % (\n                        all_train_test_val_ids_names[i].upper(), len(ids),\n                        (self._stratification.loc[ids, feature].value_counts().sort_index() \/ len(ids)).to_dict()\n                    )\n                )\n            logging.info(\"\\n\".join(messages))\n\n        # train cross validation split\n        logging.info(\"Creating KFold cross-validation train data splits...\")\n        cv = []\n        np.random.seed(self.random_state)\n        groups = self._stratification.loc[train_ids].groupby(list(self._stratification.columns)).groups.items()\n        reminder = 0\n        for key, idx in sorted(groups, key=lambda x: x[0]):\n            group_arr = idx.values.copy()\n            min_examples = int(len(group_arr) \/ self.n_train_cv_splits)\n            if min_examples < 1:\n                print(\n                    \"Combined category `{}` of columns {} cannot be split into cross-validation folds equally because \"\n                    \"the minimum number of members in any category cannot be less than number of cross-validation \"\n                    \"splits: {} < {}\".format(\n                        key, list(self._stratification.columns), len(group_arr), self.n_train_cv_splits\n                    )\n                )\n            np.random.shuffle(group_arr)\n            split = np.array_split(group_arr, self.n_train_cv_splits)\n            cv.append(split[self.n_train_cv_splits - reminder:] + split[0:self.n_train_cv_splits - reminder])\n            reminder = (reminder + len(group_arr)) % self.n_train_cv_splits\n            # log stratification percentages\n            message = (\n                \"KFold cross-validation stratification on combined category `{}` of columns {} split \"\n                \"sizes: {}\".format(key, list(self._stratification.columns), list(map(len, split)))\n            )\n            logging.info(message)\n        cv = list(map(np.concatenate, zip(*cv)))\n        fold_sizes = list(map(len, cv))\n        assert sum(fold_sizes) == len(train_ids)\n        message = \"KFold cross-validation split sizes: {}\".format(fold_sizes)\n        logging.info(message)\n        self._cv_ids = []\n        for idx in range(len(cv)):\n            val = cv[idx]\n            train = np.concatenate(cv[0:idx] + cv[idx+1:])\n            assert len(set(train).intersection(set(val))) == 0, \"No such indices that are in both train and val sets\"\n            self._cv_ids.append((train, val))\n\n    @property\n    def train_ids(self):\n        if self._train_ids is None:\n            self._split()\n        return self._train_ids\n\n    @property\n    def test_ids(self):\n        if self._test_ids is None and self.test_size is not None:\n            self._split()\n        return self._test_ids\n\n    @property\n    def val_ids(self):\n        if self._val_ids is None and self.val_size is not None:\n            self._split()\n        return self._val_ids\n\n    @property\n    def cv_ids(self):\n        if self._cv_ids is None:\n            self._split()\n        return self._cv_ids\n","733860f8":"def format_time(seconds):\n    \"\"\"\n    Format time in seconds to time string, including minutes and hours when appropriate\n    :param seconds:                     float, seconds\n    :return:                            formatted time string\n    \"\"\"\n    if seconds < 60:\n        return \"0:{:0>2}\".format(int(seconds))\n    elif seconds < 3600:\n        minutes = int(seconds \/ 60)\n        seconds = int(seconds % 60)\n        return \"{}:{:0>2}\".format(minutes, seconds)\n    else:\n        hours = int(seconds \/ 3600)\n        minutes = int((seconds % 3600) \/ 60)\n        seconds = int((seconds % 3600) % 60)\n        return \"{}:{:0>2}:{:0>2}\".format(hours, minutes, seconds)","a7e0148b":"\"\"\"\nFunctions for hyper-parameter optimization\n\"\"\"\n\ndef tune_hyperparameters_cv(estimator, x, y, search_spaces, optimizers, n_iter, scoring=None,\n                            cv=3, n_jobs=1, \n                            verbose_output=0, \n                            random_state=None, sample_weight=None, **kwargs):\n    allowed_optimizers = {\"grid\", \"random\"}\n    invalid_optimizers = [optimizer for optimizer in optimizers if optimizer not in allowed_optimizers]\n    if len(invalid_optimizers) > 0:\n        raise ValueError(\n            \"Values in `optimizers` must be one of {}, found: {}\".format(allowed_optimizers, invalid_optimizers)\n        )\n    if len(search_spaces) != len(optimizers):\n        raise ValueError(\n            \"`search_spaces` and `optimizers` must have the same length, found: \"\n            \"{} != {}\".format(len(search_spaces), len(optimizers))\n        )\n    n_steps = len(search_spaces)\n    cv_splits = cv if isinstance(cv, int) else len(cv)\n    processed_best_params = {}\n    processed_best_score = -float(\"inf\")\n    for step in range(n_steps):\n        step_start_time = time.time()\n        print(\n            \"Step {} of {} of hyper-parameter optimization \"\n            \"(`{}` optimizer)\".format(step + 1, n_steps, optimizers[step])\n        )\n        if optimizers[step] == \"grid\":\n            n_fits = reduce(mul, [len(par_values) for par_values in search_spaces[step].values()]) * cv_splits\n            optimizer_kwargs = {}\n            optimizer = GridSearchCV\n        else:\n            n_fits = n_iter * cv_splits\n            optimizer_kwargs = {\"random_state\": random_state, \"n_iter\": n_iter}\n            optimizer = RandomizedSearchCV\n        print(\"Models fitting time start: {}\".format(time.strftime('%H:%M:%S', time.gmtime(time.time()))))\n        print(\"Optimizer is fitting {} models...\".format(n_fits))\n        estimator_clone = clone(estimator)\n        estimator_clone.set_params(**processed_best_params)\n        model = optimizer(\n            estimator_clone, search_spaces[step], scoring=scoring, cv=cv,\n            n_jobs=n_jobs, refit=False, verbose=0, **optimizer_kwargs\n        )\n        model.fit(x, y, sample_weight, **kwargs)\n        iter_params = model.cv_results_[\"params\"]\n        iter_scores = model.cv_results_[\"mean_test_score\"]\n        iter_score_stds = model.cv_results_[\"std_test_score\"]\n        for iter_idx in range(len(iter_params)):\n            print(\n                \"Parameters {}: mean-score={:.12f}, \"\n                \"std-score={:.12f}\".format(iter_params[iter_idx], iter_scores[iter_idx], iter_score_stds[iter_idx])\n            )\n        print(\n            \"Step {} optimization time: {}\".format(step + 1, format_time(time.time() - step_start_time))\n        )\n        print(\n            \"Step {} completed. Best parameter tuning score is {:.12f} with \"\n            \"parameters: {}\".format(step + 1, model.best_score_, model.best_params_)\n        )\n        if model.best_score_ >= processed_best_score:\n            processed_best_score = model.best_score_\n            processed_best_params.update(model.best_params_)\n        else:\n            print(\n                \"Step {} best tuning score {:.12f} is worse than the previous step score {:.12f}, so parameters \"\n                \"will be discarded and the correspondent default parameter values from the previous step will \"\n                \"be used instead\".format(step + 1, model.best_score_, processed_best_score)\n            )\n    print(\n        \"Best parameter tuning score overall is {:.12f} with \"\n        \"parameters: {}\".format(processed_best_score, processed_best_params)\n    )\n    print(\"Refitting model on the whole train dataset with best parameters..\")\n    estimator.set_params(**processed_best_params)\n    estimator.fit(x, y, sample_weight, **kwargs)\n    print(\"Hyper-parameter tuning completed\")\n    return estimator, processed_best_params\n","11c08f23":"def get_data_by_ids(features, ids, target_col):\n    samples = features.loc[ids, :]\n    y = samples[target_col].values\n    x = samples.drop(columns=[target_col])\n    return x, y\n\ndef get_indices_by_ids(features, ids):\n    \"\"\"\n    Retrieves indices of features for specified ids\n    :param features:                    DataFrame of all features with id index\n    :param ids:                         list of ids to retrieve indices for\n    :return:                            array of indices for requested ids\n    \"\"\"\n    features[\"indexing_column\"] = np.arange(features.shape[0], dtype=np.int64)\n    samples = features.loc[ids, :]\n    indices = samples[\"indexing_column\"].values\n    features.drop(columns=[\"indexing_column\"], inplace=True)\n    return indices","93adc2f4":"# ap = argparse.ArgumentParser(description=\"Regression model training with cross-validation\")\n# ap.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"flag for verbose output\")\n# args = ap.parse_args()","6ed00c1f":"df_book = data_prep(list_order_book_file=list_order_book_file_train)\n\ndf_train = train.merge(df_book[['row_id','log_return']], on = ['row_id'], how = 'left')\ndf_train = df_train.set_index('row_id')\ndf_train.head()","960fcdf6":"# df_train = df_book_data#.loc[df_book_data['time_id']==5]\n# df_wap['row_id'] = df_wap['time_id'].apply(lambda x:f'{stock_id}-{x}')\n\n# df_train[\"target\"] = df_train[\"log_return\"].copy()\n# df_train.head()\n","e1fd56d7":"splitter = StratificationSplitter(\n        df_train, [\"target\"], val_size=0.1,\n        test_size=0.2, n_train_cv_splits=10, max_categories=30,\n        # random_state=42\n    )","2baac6f5":"NON_FEATURE_COLUMNS = [] #\"time_id\", \"wap\", \"log_return\"\nfeature_columns = [col for col in df_train.columns if col not in NON_FEATURE_COLUMNS]\nnon_feature_data = df_train[NON_FEATURE_COLUMNS + [\"target\"]].rename(columns={\"target\": \"y_true\"})\ndf_train = df_train[feature_columns]","908b8ddc":"x_train, y_train = get_data_by_ids(df_train, splitter.train_ids, \"target\")\nx_val, y_val = get_data_by_ids(df_train, splitter.val_ids, \"target\")\nx_test, y_test = get_data_by_ids(df_train, splitter.test_ids, \"target\")\ncv_splits = []\nfor train_ids, val_ids in splitter.cv_ids:\n    train_idxs = get_indices_by_ids(x_train, train_ids)\n    val_idxs = get_indices_by_ids(x_train, val_ids)\n    cv_splits.append((train_idxs, val_idxs))","837dc807":"XGB_PARAMETERS = {\n            \"booster\": \"gbtree\", \"verbosity\": 1,\n            \"objective\": \"reg:squaredlogerror\", \"eval_metric\": [\"rmse\",\"rmsle\"],\n            \"importance_type\": \"gain\",\n            \"learning_rate\": 0.05, \"n_estimators\": 2000,\n            \"max_depth\": 5, \"min_child_weight\": 6, \"gamma\": 0,\n            \"subsample\": 0.8, \"colsample_bytree\": 0.2,\n            \"reg_lambda\": 10, \"reg_alpha\": 10\n        }\nHYPER_PARAMETER_TUNE_RANDOM_N_ITER = 20\nXGB_TUNABLE_PARAMETERS_STEP_1 = {\"max_depth\": [4], \"min_child_weight\": [6]}#list(range(1, 8))\nXGB_TUNABLE_PARAMETERS_STEP_2 = {\n        \"gamma\": stats.uniform(0, 10), \"colsample_bytree\": stats.uniform(0.01, 0.99), \"subsample\": stats.uniform(0.7, 0.3)\n    }\n# XGB_TUNABLE_PARAMETERS_STEP_3 = {\"reg_lambda\": LogUniform(1, 1000), \"reg_alpha\": LogUniform(1, 1000)}\nXGB_TUNABLE_PARAMETERS_STEP_4 = {\"learning_rate\": [0.4, 0.2, 0.1, 0.06, 0.03, 0.01, 0.005]}\nXGB_TUNABLE_PARAMETERS = [\n        XGB_TUNABLE_PARAMETERS_STEP_1,\n#         XGB_TUNABLE_PARAMETERS_STEP_2,\n#         XGB_TUNABLE_PARAMETERS_STEP_3,\n#         XGB_TUNABLE_PARAMETERS_STEP_4\n    ]\nXGB_TUNING_OPTIMIZERS = [\"grid\"]# ,\"random\", \"grid\"","35a9842f":"estimator = xgb.sklearn.XGBRegressor(**XGB_PARAMETERS)","0aa01ab3":"model, best_params = tune_hyperparameters_cv(\n    \n    estimator, x_train, y_train, XGB_TUNABLE_PARAMETERS, XGB_TUNING_OPTIMIZERS,\n    HYPER_PARAMETER_TUNE_RANDOM_N_ITER, scoring=make_scorer(mean_squared_error, greater_is_better=False),\n    n_jobs=1, cv=cv_splits, #verbose_output=args.verbose,\n    # model key-word params:\n    eval_set=[(x_val, y_val)], early_stopping_rounds=50, verbose=False,\n    # random_state=42\n        )\nXGB_PARAMETERS.update(best_params)","e68c9913":"y_train_pred = model.predict(x_train, ntree_limit=model.best_ntree_limit)\ny_val_pred = model.predict(x_val, ntree_limit=model.best_ntree_limit)\ny_test_pred = model.predict(x_test, ntree_limit=model.best_ntree_limit)","0bab1106":"# non_feature_data_test = non_feature_data.loc[splitter.test_ids].copy()\n# non_feature_data_test[\"y_pred\"] = y_test_pred","e98bf95e":"train_mae = mean_absolute_error(y_train, y_train_pred)\ntrain_mse = mean_squared_error(y_train, y_train_pred)\ntrain_r_2 = r2_score(y_train, y_train_pred)\nval_mae = mean_absolute_error(y_val, y_val_pred)\nval_mse = mean_squared_error(y_val, y_val_pred)\nval_r_2 = r2_score(y_val, y_val_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntest_mse = mean_squared_error(y_test, y_test_pred)\ntest_r_2 = r2_score(y_test, y_test_pred)\nprint(\n        \"Regression model, model trees={}, train_mae={:.12f}, train_mse={:.12f}, train_rmse={:.12f}, \"\n        \"train_r_2={:.12f}, val_mae={:.12f}, val_mse={:.12f}, val_rmse={:.12f}, val_r_2={:.12f},\"\n        \"test_mae={:.12f}, test_mse={:.12f}, test_rmse={:.12f}, test_r_2={:.12f}\".format(\n            model.best_ntree_limit, train_mae, train_mse, np.sqrt(train_mse), train_r_2,\n            val_mae, val_mse, np.sqrt(val_mse), val_r_2,\n            test_mae, test_mse, np.sqrt(test_mse), test_r_2\n        )\n    )","ae726294":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n# (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\n\n\nR2 = round(r2_score(y_true = y_test, y_pred = y_test_pred),3)\nRMSPE = round(rmspe(y_true = y_test, y_pred = y_test_pred),3)\nprint(f'Performance: R2 score: {R2}, RMSPE: {RMSPE}')","d92bf098":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ntest = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\n\n# for file in list_order_book_file_test:\n#     df = pd.read_parquet(file)\n#     print(df.head())\ndf_book = data_prep(list_order_book_file=list_order_book_file_test)\ndf_test = test.merge(df_book[['row_id','log_return']], on = ['row_id'], how = 'left').fillna(0)\ndf_test = df_test.set_index('row_id')\n\nNON_FEATURE_COLUMNS = ['stock_id','time_id']\nfeature_columns = [col for col in df_test.columns if col not in NON_FEATURE_COLUMNS]\ndf_test = df_test[feature_columns]\n# df_test = df_test.set_index('row_id')\n\ny_test_pred = model.predict(df_test, ntree_limit=model.best_ntree_limit)\n\ndf_test = df_test.reset_index()\ndf_test['pred'] = pd.DataFrame(y_test_pred)\ndf_test[['row_id','pred']].to_csv('submission.csv',index = False)\ndf_test[['row_id','pred']]\n# df_test","2ee9f59b":"# submit data"}}