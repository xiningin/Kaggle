{"cell_type":{"b48d215f":"code","1555653f":"code","c6e6459a":"code","25c2c199":"code","671c6083":"code","4357ba51":"code","cbf2143b":"code","f29bfd17":"code","e313fa3d":"code","9bcf4857":"code","d4d0909f":"code","e0e8cc6b":"code","802ca10d":"code","a456b8d7":"code","4557692d":"code","74d6c0ab":"code","2ff2c538":"code","91590bb9":"code","dd24dc9e":"code","ed0e64cb":"code","12c3cf06":"markdown","68d7f51d":"markdown","4f3c4d4e":"markdown","b5f7ab79":"markdown","2ee5deef":"markdown","43bee507":"markdown"},"source":{"b48d215f":"!pip install tensorflow-gpu==1.13.1\n!pip install tensorflow==1.13.1\n!pip install keras==2.0.8\n!pip install imutils","1555653f":"#Checking TF version\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport tensorflow as tf\ntf.__version__","c6e6459a":"#Install Matterport\n!git clone https:\/\/github.com\/matterport\/Mask_RCNN.git","25c2c199":"# Installing Matterport and downloading pretrained model for Coco Dataset\nimport os\nos.chdir(\".\/Mask_RCNN\")\n!python setup.py install\n!wget https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5","671c6083":"import mrcnn\nfrom mrcnn.config import Config\nfrom mrcnn import model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.utils import Dataset\nfrom mrcnn.model import MaskRCNN\nfrom mrcnn import utils\nimport numpy as np\nfrom numpy import zeros\nfrom numpy import asarray\nimport colorsys\nimport argparse\nimport imutils\nimport random\nimport cv2\nimport os\nfrom os import listdir\nimport time\nfrom matplotlib import pyplot\nfrom matplotlib.patches import Rectangle\n%matplotlib inline\nfrom keras.models import load_model\nfrom xml.etree import ElementTree","4357ba51":"# Setting some matterport configs\nclass myMaskRCNNConfig(Config):\n    # give the configuration a recognizable name\n    NAME = \"MaskRCNN_config\"\n \n    # set the number of GPUs to use along with the number of images\n    # per GPU\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\n    # Use small images for faster training. \n    #IMAGE_MIN_DIM = 128\n    #IMAGE_MAX_DIM = 128\n \n    # number of classes (we would normally add +1 for the background)\n    # kangaroo + BG\n    NUM_CLASSES = 1+1\n   \n    # Number of training steps per epoch\n    STEPS_PER_EPOCH = 131\n    \n    # Reduce training ROIs per image because the images are small and have few objects.\n    #TRAIN_ROIS_PER_IMAGE = 20\n    # Use smaller anchors because our image and objects are small\n    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n    # set appropriate step per epoch and validation step\n    #STEPS_PER_EPOCH = len(X_train)\/\/(GPU_COUNT*IMAGES_PER_GPU)\n    #VALIDATION_STEPS = len(X_val)\/\/(GPU_COUNT*IMAGES_PER_GPU)\n\n\n    # Learning rate\n    LEARNING_RATE=0.006\n    \n    # Skip detections with < 90% confidence\n    DETECTION_MIN_CONFIDENCE = 0.9\n    \n    # setting Max ground truth instances\n    MAX_GT_INSTANCES=10\n\nconfig = myMaskRCNNConfig()\nconfig.display()","cbf2143b":"class KangarooDataset(Dataset):\n    # load the dataset definitions\n    def load_dataset(self, dataset_dir, is_train=True):\n        \n        # Add classes. We have only one class to add.\n        self.add_class(\"dataset\", 1, \"kangaroo\")\n        \n        # define data locations for images and annotations\n        images_dir = dataset_dir + '\/images\/'\n        annotations_dir = dataset_dir + '\/annotations\/'\n        \n        # Iterate through all files in the folder to \n        #add class, images and annotaions\n        for filename in listdir(images_dir):\n            \n            # extract image id\n            #image_id = filename[:-4]\n            image_id = filename.split('-')[1].split('.')[0]\n            \n            # skip bad images\n            if image_id in ['00090']:\n                continue\n            # skip some images if we are building the train set\n            if is_train and int(image_id) >= 80:\n                continue\n            # skip some images if we are building the test\/val set\n            if not is_train and int(image_id) < 690:\n                continue\n            \n            # setting image file\n            img_path = images_dir + filename\n            \n            # setting annotations file\n            ann_path = annotations_dir + filename[:-3] + 'xml'\n            \n            # adding images and annotations to dataset\n            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n# extract bounding boxes from an annotation file\n    def extract_boxes(self, filename):\n        \n        # load and parse the file\n        tree = ElementTree.parse(filename)\n        # get the root of the document\n        root = tree.getroot()\n        # extract each bounding box\n        boxes = list()\n        for box in root.findall('.\/\/bndbox'):\n            xmin = int(box.find('xmin').text)\n            ymin = int(box.find('ymin').text)\n            xmax = int(box.find('xmax').text)\n            ymax = int(box.find('ymax').text)\n            coors = [xmin, ymin, xmax, ymax]\n            boxes.append(coors)\n        \n        # extract image dimensions\n        width = int(root.find('.\/\/size\/width').text)\n        height = int(root.find('.\/\/size\/height').text)\n        return boxes, width, height\n# load the masks for an image\n    \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n    \"\"\"\n    def load_mask(self, image_id):\n        # get details of image\n        info = self.image_info[image_id]\n        \n        # define anntation  file location\n        path = info['annotation']\n        \n        # load XML\n        boxes, w, h = self.extract_boxes(path)\n       \n        # create one array for all masks, each on a different channel\n        masks = zeros([h, w, len(boxes)], dtype='uint8')\n        \n        # create masks\n        class_ids = list()\n        for i in range(len(boxes)):\n            box = boxes[i]\n            row_s, row_e = box[1], box[3]\n            col_s, col_e = box[0], box[2]\n            masks[row_s:row_e, col_s:col_e, i] = 1\n            class_ids.append(self.class_names.index('kangaroo'))\n        return masks, asarray(class_ids, dtype='int32')\n# load an image reference\n    \"\"\"Return the path of the image.\"\"\"\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        print(info)\n        return info['path']","f29bfd17":"os.chdir(\"..\/\")\ndataset_dir = \"..\/input\/kangaroodataset\"\n# prepare train set\ntrain_set = KangarooDataset()\ntrain_set.load_dataset(dataset_dir, is_train=True)\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_ids))\n# prepare test\/val set\ntest_set = KangarooDataset()\ntest_set.load_dataset(dataset_dir, is_train=False)\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_ids))","e313fa3d":"train_set.image_info[0]","9bcf4857":"# Looking to an example\nimage_id = 0\nimage = train_set.load_image(image_id)\n\nmask, class_ids = train_set.load_mask(image_id)\nbbox = utils.extract_bboxes(mask)\nvisualize.display_instances(image,bbox,mask, class_ids, train_set.class_names)","d4d0909f":"# Looking to an example\ntest_set.image_info[1]","e0e8cc6b":"# Looking to an example\nimage_id = 1\nimage = test_set.load_image(image_id)\n\nmask, class_ids = test_set.load_mask(image_id)\nbbox = utils.extract_bboxes(mask)\nvisualize.display_instances(image,bbox,mask, class_ids, test_set.class_names)","802ca10d":"print(\"Loading Mask R-CNN model...\")\nmodel = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='.\/Mask_RCNN')\n#load the weights for COCO\nmodel.load_weights('.\/Mask_RCNN\/mask_rcnn_coco.h5', \n                   by_name=True, \n                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])","a456b8d7":"## train heads with higher lr to speedup the learning\nmodel.train(train_set, test_set, learning_rate=2*config.LEARNING_RATE, epochs=1, layers='heads')\nhistory = model.keras_model.history.history","4557692d":"# Best model\nmodel_path = '.\/Mask_RCNN\/maskrcnn_config20210604T1551\/mask_rcnn_maskrcnn_config_0000.h5'\n#Loading the model in the inference mode\nmodel = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='.\/')\n# loading the trained weights o the custom dataset\nmodel.load_weights(model_path, by_name=True)","74d6c0ab":"# Testing on a sample\nimage_id = 1\nimage, image_meta, gt_class_id, gt_bbox, gt_mask =  modellib.load_image_gt(test_set, config, image_id, use_mini_mask=False)\ninfo = test_set.image_info[image_id]\nprint(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n                                       test_set.image_reference(image_id)))\n# convert pixel values (e.g. center)\nscaled_image = modellib.mold_image(image, config)\n\nsample = np.expand_dims(scaled_image, 0)\n# make prediction\nyhat = model.detect(sample, verbose=0)\n# extract results for first sample\nr = yhat[0]\nvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n                            test_set.class_names, r['scores'], \n                            title=\"Predictions\")","2ff2c538":"# calculate statistics, including AP\nAP, _, _, _ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\nprint(AP)","91590bb9":"def evaluate_model(dataset, model, cfg):\n    APs = list()\n    for image_id in dataset.image_ids:\n        # load image, bounding boxes and masks for the image id\n        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n        # convert pixel values (e.g. center)\n        scaled_image = modellib.mold_image(image, cfg)\n        # convert image into one sample\n        sample = np.expand_dims(scaled_image, 0)\n        # make prediction\n        yhat = model.detect(sample, verbose=0)\n        # extract results for first sample\n        r = yhat[0]\n        # calculate statistics, including AP\n        AP, _, _, _ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n        # store\n        APs.append(AP)\n    # calculate the mean AP across all images\n    mAP = np.mean(APs)\n    return mAP","dd24dc9e":"# evaluate model on test dataset\ntest_mAP = evaluate_model(test_set, model, config)\nprint(\"Test mAP: %.3f\" % test_mAP)","ed0e64cb":"# Viewing some samples\nnum_samples = 4\nfig, axes = pyplot.subplots(num_samples, 2, figsize=(15,7*num_samples))\nfor image_id in test_set.image_ids:\n  image = test_set.load_image(image_id)\n  mask, class_ids = test_set.load_mask(image_id)\n  bbox = utils.extract_bboxes(mask)\n  visualize.display_instances(image,bbox,mask, class_ids, test_set.class_names, ax=axes[image_id][0], title=\"Truth\")\n  #Predict\n  #image, image_meta, gt_class_id, gt_bbox, gt_mask =  modellib.load_image_gt(test_set, config, image_id, use_mini_mask=False)\n  scaled_image = modellib.mold_image(image, config)\n  sample = np.expand_dims(scaled_image, 0)\n  yhat = model.detect(sample, verbose=0)  \n  r = yhat[0]\n  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n                            test_set.class_names, r['scores'], ax=axes[image_id][1], \n                            title=\"Predictions\")\n  num_samples-=1\n  if num_samples == 0:\n    break","12c3cf06":"## Trainning the model","68d7f51d":"## Imports","4f3c4d4e":"## Loading a custom Dataset","b5f7ab79":"## Evaluation","2ee5deef":"# Mask RCNN Example\n\nUsing MatterPort with Keras: https:\/\/github.com\/matterport\/Mask_RCNN\n\nBased on https:\/\/towardsdatascience.com\/object-detection-using-mask-r-cnn-on-a-custom-dataset-4f79ab692f6d\n","43bee507":"## Environment Setup"}}