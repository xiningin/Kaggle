{"cell_type":{"d84c7bb1":"code","cdd8818a":"code","fbdab213":"code","0ef398e3":"code","10834648":"code","92af1d20":"code","f28743b6":"code","9ebcdeec":"code","77dcf733":"code","d57eb6fa":"code","6831a317":"code","422f95b2":"code","44122b45":"code","93902bf1":"code","90b452a3":"code","944e3467":"code","315b50c3":"code","925859e7":"code","013873c2":"code","7aee7f65":"code","064c3c46":"code","429e7ddd":"code","7933c37e":"code","15488486":"code","e97a339c":"code","fcfe5969":"code","6f0e3e24":"code","b5e40419":"code","7e00ad6a":"code","6b551e18":"code","118bcac3":"code","6c629eb0":"code","9ca405c7":"code","aadb4693":"code","a2500ac8":"code","2f1b20b5":"code","0a3c1c71":"markdown","6749f3db":"markdown","3797bd6c":"markdown","d0e0d26a":"markdown","ad621d08":"markdown","f2cda0b1":"markdown","803f8759":"markdown","fc90b397":"markdown","44c19fff":"markdown","0db40e41":"markdown","1f432abe":"markdown","bb1d8cea":"markdown","ea1e5d55":"markdown","c6ecd492":"markdown","6c231833":"markdown","0e01c201":"markdown"},"source":{"d84c7bb1":"# Install the fastai v2 library\n!pip install fastai2 --quiet\n\n# Import required functions\nfrom fastai2.vision.all import *\nmatplotlib.rc('image', cmap='Greys')","cdd8818a":"# Download data\npath = untar_data(URLs.MNIST_SAMPLE)\nPath.BASE_PATH = path # For eaiser printing\npath.ls()","fbdab213":"# Look inside the train folder\n(path\/'train').ls()","0ef398e3":"# List of filenames for 3s and 7s\nthrees = (path\/'train'\/'3').ls().sorted()\nsevens = (path\/'train'\/'7').ls().sorted()\nthrees, sevens","10834648":"# View an image using PIL\nim3_path = threes[1]\nim3 = Image.open(im3_path)\nim3","92af1d20":"# View an image as a numpy array\narray(im3)[4:10,4:10]","f28743b6":"# View an image as a PyTorch tensor\ntensor(im3)[4:10,4:10]","9ebcdeec":"# Overlaying pixels with the color\nim3_t = tensor(im3)\ndf = pd.DataFrame(im3_t[4:15,4:22])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')","77dcf733":"# Load 3s and 7s and tensors\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nprint('No. of 3s:', len(three_tensors))\nprint('No. of 7s:', len(seven_tensors))\n\n# Sample 3\nshow_image(three_tensors[1]);","d57eb6fa":"# Stack list of tensors into a single tensor\nstacked_sevens = torch.stack(seven_tensors).float()\/255\nstacked_threes = torch.stack(three_tensors).float()\/255\nprint(stacked_threes.shape, stacked_sevens.shape)","6831a317":"# View the average 3\nmean3 = stacked_threes.mean(0)\nshow_image(mean3);","422f95b2":"# View the average 7\nmean7 = stacked_sevens.mean(0)\nshow_image(mean7);","44122b45":"# Pick a sample '3'\na_3 = stacked_threes[1]\nshow_image(a_3);","93902bf1":"# Calculate L1 & L2 distance from the mean 3\ndist_3_abs = (a_3 - mean3).abs().mean()\ndist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\ndist_3_abs,dist_3_sqr","90b452a3":"# Calculate L1 & L2 distance from the mean 7\ndist_7_abs = (a_3 - mean7).abs().mean()\ndist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\ndist_7_abs,dist_7_sqr","944e3467":"# Using PyTorch built in functions to calculate L1 & L2 distance\nF.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()","315b50c3":"# Create tensors from the validation set\nvalid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path\/'valid'\/'3').ls()]).float()\/255\nvalid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path\/'valid'\/'7').ls()]).float()\/255\nvalid_3_tens.shape,valid_7_tens.shape","925859e7":"# Helper function to calculate the L1 distance from mean\ndef mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\nmnist_distance(a_3, mean3)","013873c2":"# Use it for the entire validation set (thanks to broadcasting)\nvalid_3_dist = mnist_distance(valid_3_tens, mean3)\nvalid_3_dist, valid_3_dist.shape","7aee7f65":"# Helper function to predict whether an image is a 3\ndef is_3(x): \n    return mnist_distance(x,mean3) < mnist_distance(x,mean7)","064c3c46":"# Predict for a single image\nis_3(a_3), is_3(a_3).float()","429e7ddd":"# Predict for the entire validation set\nis_3(valid_3_tens)","7933c37e":"# Look at an image that the model failed to classify\nshow_image(valid_3_tens[1]);","15488486":"# Calculate overall accuracy\naccuracy_3s =      is_3(valid_3_tens).float() .mean()\naccuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n\naccuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)\/2","e97a339c":"# Input data (quardatic function with some random noise)\ntime = torch.arange(0,20).float()\nspeed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n\nprint(time)\nplt.scatter(time,speed);","fcfe5969":"# Model - simple polynomial function\ndef f(t, params):\n    a,b,c = params\n    return a*(t**2) + (b*t) + c\n\n# Loss function - MSE\ndef mse(preds, targets): \n    return ((preds-targets)**2).mean()\n\n# Parameters initialized randomly\nparams = torch.randn(3).requires_grad_()\norig_params = params.clone()\nparams","6f0e3e24":"# Calculate predictions\npreds = f(time, params)\n\n# Helper function to plot predictions\ndef show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='red')\n    ax.set_ylim(-300,100)\n    \nshow_preds(preds)","b5e40419":"loss = mse(preds, speed)\nloss","7e00ad6a":"loss.backward()\nprint('params:', params)\nprint('params.grad:', params.grad)","6b551e18":"# Update the weights\nlr = 1e-5\nparams.data -= lr * params.grad.data\nparams.grad = None\n\n# Check the new params & loss\nprint('updated params:', params)\npreds = f(time,params)\nprint('updated loss:', mse(preds, speed))\nshow_preds(preds)","118bcac3":"# Helper function to apply step\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= lr * params.grad.data\n    params.grad = None\n    if prn: print(loss.item())\n    return preds","6c629eb0":"for i in range(10): apply_step(params)","9ca405c7":"params = orig_params.detach().requires_grad_()\n_,axs = plt.subplots(1,5,figsize=(15,3))\nfor ax in axs: \n    show_preds(apply_step(params, False), ax)\nplt.tight_layout()","aadb4693":"!pip install jovian --upgrade --quiet","a2500ac8":"import jovian","2f1b20b5":"jovian.commit(project='fastai2-lesson3', environment=None)","0a3c1c71":"The update step is:\n\n```\nw -= gradient(w) * lr\n```\n\n<img src=\"https:\/\/www.jeremyjordan.me\/content\/images\/2018\/02\/Screen-Shot-2018-02-24-at-11.47.09-AM.png\">\n\n[Image Source](https:\/\/www.jeremyjordan.me\/nn-learning-rate\/)","6749f3db":"### Step 2 - Calculate Predictions","3797bd6c":"### Step 6 - Repeat the update process many times","d0e0d26a":"# Digit Classifier From Scratch & Gradient Descent\n\nReference Links:\n- FastAI Book chapter 4: https:\/\/github.com\/fastai\/fastbook\/blob\/master\/04_mnist_basics.ipynb\n- FastAI v2 library docs: https:\/\/dev.fast.ai\/\n\n\nWe'll attempt to create a baseline model to classify images of handwritten digits, from the MNIST dataset\n\n<img src=\"https:\/\/i.imgur.com\/CAYnuo1.jpg\" width=\"420\">","ad621d08":"To keep things simple, we'll use a subset of the dataset which only contains 3s and 7s.","f2cda0b1":"### Step 1 - Initialize the Model","803f8759":"### Step 4 - Comptue Gradients","fc90b397":"\n<img src=\"https:\/\/miro.medium.com\/max\/1200\/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg\">","44c19fff":"### Step 3 - Calculate the Loss","0db40e41":"### End-to-end example of SGD\n\nMeasuring the speed of a roller coaster as it goes over a hump. We start by generating some training data.","1f432abe":"### Computing Metrics using Broadcasting","bb1d8cea":"## Gradient Descent\n\nOptimization technique to improve models incrementally\n\n1. Initialize a model with random weights\n2. Use model weights to make predictions\n3. Calculate loss by comparing predictions with targets\n4. Calculate the gradient of loss w.r.t each of the weights\n5. Change all weights based on that calculation\n6. Repeat the process (from Step 2)\n\n...until model is good enough\n\n<img src=\"https:\/\/i.imgur.com\/CADtVy9.png\">","ea1e5d55":"## Simple Model - Pixel Similarity\n\nWe'll find the average pixel values for 3s and 7s, and then classify new images based on whether its pixel values are closer to the average 3 or to the average 7.","c6ecd492":"We can also visuzliaze how the function changes with each update","6c231833":"### Step 5: Update the weights based on the gradients","0e01c201":"...to be continued.\n\n# Next Steps\n\n- Read Chapter 4 from the book: https:\/\/github.com\/fastai\/fastbook\/blob\/master\/04_mnist_basics.ipynb\n- Answer the questionnaire at the end of the chapter \n- Learn more about broadcasting in PyTorch by reading the official docs\n- Try to replicate the baseline model for all 10 digits (replace `URLs.MNIST_SAMPLE` with `URLs.MNIST`)\n- Try to implement gradient descent on a different dataset, with a different function as the model"}}