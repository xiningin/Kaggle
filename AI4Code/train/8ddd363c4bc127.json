{"cell_type":{"2c20481b":"code","dc01463d":"code","5f6a1f4e":"code","c98c9081":"code","f6bbc98b":"code","da4b2fc8":"code","6bc948b1":"code","ebe0f14b":"code","690af6d3":"code","bfb3725c":"code","54476a71":"code","26d5557c":"code","597889dd":"code","4990f828":"code","505eb289":"code","40340228":"code","73c642d7":"code","8b635fb3":"code","35abd2c7":"code","1ad6cf00":"code","60d5da9d":"code","e09c85a2":"code","ceebd987":"code","798fb2fa":"code","492105ec":"code","d31868ff":"code","015bf9e6":"code","481c7e03":"code","5f110aa7":"markdown","d4e48eb8":"markdown","28b1d62c":"markdown","25e9ed7f":"markdown","6c8843ab":"markdown","7a4d0619":"markdown","5fa4c8e7":"markdown","77e92445":"markdown","1b54cb6a":"markdown","aad08853":"markdown","b6c007f4":"markdown"},"source":{"2c20481b":"!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()","dc01463d":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier","5f6a1f4e":"traindf = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntestdf = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\nIDs = testdf['Id']","c98c9081":"traindf.shape","f6bbc98b":"traindf.info()","da4b2fc8":"traindf.columns","6bc948b1":"traindf.isna().sum()","ebe0f14b":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\n\ntraindf = reduce_mem_usage(traindf)\ntestdf = reduce_mem_usage(testdf)","690af6d3":"traindf.dtypes","bfb3725c":"traindf.head()","54476a71":"features = traindf.columns.to_list()\n\nfor i in features:\n    print(i ,\"---> \" ,len(traindf[i].unique()))","26d5557c":"# extract fetures having only 1 unique value and remove them\n\nunique_value_feature = []\nfor i in features:\n    if(len(traindf[i].unique()) == 1):\n        print(i)\n        unique_value_feature.append(i)","597889dd":"traindf.drop(columns=unique_value_feature, axis='columns', inplace=True)\ntestdf.drop(columns=unique_value_feature, axis='columns', inplace=True)","4990f828":"traindf['Cover_Type'].value_counts()","505eb289":"traindf = traindf[traindf['Cover_Type'] != 5]","40340228":"traindf[\"Aspect\"][traindf[\"Aspect\"] < 0] += 360\ntraindf[\"Aspect\"][traindf[\"Aspect\"] > 359] -= 360\n\ntestdf[\"Aspect\"][testdf[\"Aspect\"] < 0] += 360\ntestdf[\"Aspect\"][testdf[\"Aspect\"] > 359] -= 360\n\ntraindf.loc[traindf[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntestdf.loc[testdf[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n\ntraindf.loc[traindf[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\ntestdf.loc[testdf[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n\ntraindf.loc[traindf[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\ntestdf.loc[testdf[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n\ntraindf.loc[traindf[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\ntestdf.loc[testdf[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n\ntraindf.loc[traindf[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\ntestdf.loc[testdf[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n\ntraindf.loc[traindf[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\ntestdf.loc[testdf[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255","73c642d7":"traindf.columns\ntraindf.drop(columns=['Id'], axis='columns', inplace=True)\ntestdf.drop(columns=['Id'], axis='columns', inplace=True)","8b635fb3":"traindf.columns","35abd2c7":"traindf.sample(5)","1ad6cf00":"scalar_obj = StandardScaler()\n\nscaled_feature = traindf.columns[:11].to_list()\n\ntraindf[scaled_feature] = scalar_obj.fit_transform(traindf[scaled_feature])\ntestdf[scaled_feature] = scalar_obj.fit_transform(testdf[scaled_feature])","60d5da9d":"soil_features = [x for x in features if x.startswith(\"Soil_Type\") and x not in ['Soil_Type7', 'Soil_Type15']]\ntraindf[\"soil_type_count\"] = traindf[soil_features].sum(axis=1)\ntestdf[\"soil_type_count\"] = testdf[soil_features].sum(axis=1)\n\nwilderness_features = [x for x in features if x.startswith(\"Wilderness_Area\")]\ntraindf[\"wilderness_area_count\"] = traindf[wilderness_features].sum(axis=1)\ntestdf[\"wilderness_area_count\"] = testdf[wilderness_features].sum(axis=1)","e09c85a2":"traindf.sample(3)","ceebd987":"traindf[[\"wilderness_area_count\", 'soil_type_count']] = scalar_obj.fit_transform(traindf[[\"wilderness_area_count\", 'soil_type_count']])\ntestdf[[\"wilderness_area_count\", 'soil_type_count']] = scalar_obj.fit_transform(testdf[[\"wilderness_area_count\", 'soil_type_count']])","798fb2fa":"X = traindf.drop(columns=['Cover_Type'], axis=1)\nY = traindf['Cover_Type']","492105ec":"label_encoder_obj = LabelEncoder()\nY = label_encoder_obj.fit_transform(Y)","d31868ff":"# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.38, random_state=42)\n\n# model1 = RandomForestClassifier(n_estimators=300)\n# model1.fit(x_train, y_train)\n\n# y_predict = model1.predict(x_test)\n\n# print(accuracy_score(y_test, y_predict))\n\n\n## best score with Random Forest is 94.043","015bf9e6":"# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n# xgb_model = XGBClassifier(n_estimators=700,n_jobs=-1,booster='gbtree',predictor='gpu_predictor',tree_method='gpu_hist')\n# xgb_model.fit(x_train, y_train)\n# y_pred_xg = xgb_model.predict(x_test)\n# print(accuracy_score(y_test, y_pred_xg))\n\n# ## accuracy on final submission 93.4206","481c7e03":"final_y_pred = xgb_model.predict(testdf)\nfinal_y_pred = label_encoder_obj.inverse_transform(final_y_pred)\nsubmissiondf = pd.DataFrame({'Id':IDs, 'Cover_Type':final_y_pred})\nsubmissiondf.to_csv('submission2.csv',index = False)","5f110aa7":"# Model Building and testing","d4e48eb8":"Cover_Type = 5 has only 1 value, it is safe to remove this value","28b1d62c":"### additional feature preprocessing from discussion (https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/292823)","25e9ed7f":"Soil_Type15 has only 1 value, check how many such features are their, and remove them","6c8843ab":"# Reduce size\n\nfrom discussion thread (https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/291844) ","7a4d0619":"from the disussion (https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/291823)","5fa4c8e7":"no NaN values, which will make out work easy","77e92445":"# Preprocessing","1b54cb6a":"### check uniques values in each feature","aad08853":"# Feature Engineering","b6c007f4":"### additional Feature Engineering from discusion (https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/293373)"}}