{"cell_type":{"4a9e002b":"code","05aa5c94":"code","6ccbdc71":"code","dded4992":"code","f529829f":"code","cdea1299":"code","4e6f28c1":"code","ea31eff6":"code","e1567554":"code","a155f39e":"code","95423aee":"code","03e0475f":"code","f557b740":"code","d81365a1":"code","74be160d":"code","95aa4a1d":"code","7697bafb":"code","6061d28d":"code","e18f447f":"code","b373b2f1":"code","aee5a482":"code","fcf933e1":"code","614b7c55":"code","abe367f1":"code","863e8383":"code","0e994985":"code","559a6cd1":"code","4817a080":"code","daaa3086":"code","51202847":"code","1d287525":"code","0b3f7c87":"code","19bf4a4d":"code","c0251932":"code","ef274d97":"code","84a5b098":"code","6b4194b4":"code","73b19ede":"code","8a78961f":"code","4c021451":"code","bb231e2c":"code","b167676d":"code","ad760823":"code","7ade0cc9":"code","b79cb3e9":"code","9d0a6038":"code","39495c88":"code","5388629d":"code","bba15682":"code","8ba4d5fa":"code","1b953f26":"code","6357f8c2":"code","58eb3226":"code","1e8d11a2":"code","6b97ba19":"code","0f0e4368":"code","589212a5":"code","b327ec62":"code","3e1ac898":"code","03f001c4":"code","506314c5":"code","7c74e899":"code","3f186a5a":"code","280cb5b7":"code","f6f783f5":"code","d51225d3":"markdown","04a666dd":"markdown","ad8be3a0":"markdown","47ce75e3":"markdown","654a5b0b":"markdown","c2aea7c0":"markdown","b522ac8d":"markdown","e4c77d2f":"markdown","221af26e":"markdown","4a09ef9a":"markdown","cb5da851":"markdown","26524042":"markdown"},"source":{"4a9e002b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport xgboost as xgb\nimport matplotlib.pyplot as plt","05aa5c94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ccbdc71":"hfmd_data = pd.read_csv('\/kaggle\/input\/hfmd-vietnam\/hfmd_data_analysis\/hfmd_data_analysis\/hfmd_data_province.csv', header=0, names=['PROVINCE', 'MONTH', 'YEAR', 'TOTAL_CASES'])\n\nclimate_data = pd.read_csv('\/kaggle\/input\/hfmd-vietnam\/hfmd_data_analysis\/hfmd_data_analysis\/climate_per_year_per_month.csv')\nclimate_data.drop(climate_data.columns[0], axis=1, inplace=True)","dded4992":"data = pd.merge(hfmd_data, climate_data, how='inner', on=['PROVINCE', 'MONTH', 'YEAR'])","f529829f":"feature_columns = ['PRECTOT',\t'PS',\t'QV2M',\t'RH2M', 'T2M', 'T2MWET', 'T2M_MAX', 'T2M_MIN',\t'T2M_RANGE', 'TS', 'WS10M',\t'WS10M_MAX',\t'WS10M_MIN',\t'WS10M_RANGE',\t'WS50M',\t'WS50M_MAX',\t'WS50M_MIN', 'WS50M_RANGE']\ntarget = data['TOTAL_CASES']\nfeature_data = data[feature_columns]","cdea1299":"corr = data.corr()\n\nplt.figure(figsize=(15, 8))\n\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True,\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","4e6f28c1":"data['PROVINCE'].unique()","ea31eff6":"total_monthly_record = []\nfor i in range(1, 13):\n    total_monthly_record.append(data[(data['YEAR'] == 2016) & (data['MONTH'] == i)]['TOTAL_CASES'].sum())\n    \nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(list(range(1, 13)), total_monthly_record).set_title('Bar chart of total cases of 2016')","e1567554":"total_monthly_record = []\nfor i in range(1, 13):\n    total_monthly_record.append(data[(data['YEAR'] == 2017) & (data['MONTH'] == i)]['TOTAL_CASES'].sum())\n    \nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(list(range(1, 13)), total_monthly_record).set_title('Bar chart of total cases of 2017')","a155f39e":"total_monthly_record = []\nfor i in range(1, 13):\n    total_monthly_record.append(data[(data['YEAR'] == 2018) & (data['MONTH'] == i)]['TOTAL_CASES'].sum())\n    \nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(list(range(1, 13)), total_monthly_record).set_title('Bar chart of total cases of 2018')","95423aee":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","03e0475f":"X_train, X_test, y_train, y_test = train_test_split(feature_data, target, train_size=0.8, stratify=data['PROVINCE'], random_state=42)","f557b740":"feature_scaler = StandardScaler()\nfeature_scaler.fit(X_train)\n\ntarget_scaler = StandardScaler()\ntarget_scaler.fit(np.array(y_train).reshape((-1, 1)))\n\nX_train_preprocess = feature_scaler.transform(X_train)\nX_test_preprocess = feature_scaler.transform(X_test)\n\ny_train_preprocess = target_scaler.transform(np.array(y_train).reshape((-1, 1)))\ny_test_preprocess = target_scaler.transform(np.array(y_test).reshape((-1, 1)))","d81365a1":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","74be160d":"def mean_absolute_percentage_error(y_true, y_pred):\n  \n  '''\n    Calculate mean absolute percentage error loss\n  '''\n\n  # y_true, y_pred = check_arrays(y_true, y_pred)\n  return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","95aa4a1d":"linear = LinearRegression()\nparameters = {}\nlinear_grid_search_cv = GridSearchCV(linear, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nlinear_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","7697bafb":"print(f'Best score (MAE): {linear_grid_search_cv.best_score_}')\nprint(f'Best parameters: {linear_grid_search_cv.best_params_}')","6061d28d":"linear_best = linear_grid_search_cv.best_estimator_\ncoef = linear_best.coef_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(coef[0], X_train.columns)","e18f447f":"y_pred = linear_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","b373b2f1":"tree = DecisionTreeRegressor()\nparameters = {'criterion': ['mse', 'mae'], \n              'max_depth': [2, 5, 8, 16, 20],\n              'min_samples_split': [2, 4]}\ntree_grid_search_cv = GridSearchCV(tree, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\ntree_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","aee5a482":"print(f'Best score (MAE): {tree_grid_search_cv.best_score_}')\nprint(f'Best parameters: {tree_grid_search_cv.best_params_}')","fcf933e1":"tree_best = tree_grid_search_cv.best_estimator_\nfeature_importances = tree_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, X_train.columns)","614b7c55":"y_pred = tree_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","abe367f1":"from sklearn.tree import export_graphviz\nimport graphviz \ndot_data = export_graphviz(tree_best, out_file='1618_no_feature_engineering_tree.dot') ","863e8383":"forest = RandomForestRegressor(n_jobs=-1)\nparameters = {'n_estimators': [10, 30, 50, 100, 500], \n              'max_depth': [2, 5, 8, 10, 15],\n              'min_samples_split': [2, 4]}\nforest_grid_search_cv = GridSearchCV(forest, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nforest_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","0e994985":"print(f'Best score (MAE): {forest_grid_search_cv.best_score_}')\nprint(f'Best parameters: {forest_grid_search_cv.best_params_}')","559a6cd1":"forest_best = forest_grid_search_cv.best_estimator_\nfeature_importances = forest_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, X_train.columns)","4817a080":"y_pred = forest_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","daaa3086":"feature_columns = ['PRECTOT',\t'PS',\t'QV2M',\t'RH2M', 'T2M', 'T2MWET', 'T2M_MAX', 'T2M_MIN',\t'T2M_RANGE', 'TS', 'WS10M',\t'WS10M_MAX',\t'WS10M_MIN',\t'WS10M_RANGE',\t'WS50M',\t'WS50M_MAX',\t'WS50M_MIN', 'WS50M_RANGE']\nlinear_feature_columns_2 = ['T2M', 'T2MWET', 'T2M_MAX', 'T2M_MIN',\t'T2M_RANGE', 'TS']\nlinear_feature_columns = ['T2M_MAX', 'TS', 'WS10M_MAX']\ntarget = data['TOTAL_CASES']\n\n# target = data['CASE_OVER_POPULATION']\nfeature_data = data[linear_feature_columns_2]","51202847":"X_train, X_test, y_train, y_test = train_test_split(feature_data, target, train_size=0.8, stratify=data['PROVINCE'], random_state=42)","1d287525":"feature_scaler = StandardScaler()\nfeature_scaler.fit(X_train)\n\ntarget_scaler = StandardScaler()\ntarget_scaler.fit(np.array(y_train).reshape((-1, 1)))\n\nX_train_preprocess = feature_scaler.transform(X_train)\nX_test_preprocess = feature_scaler.transform(X_test)\n\ny_train_preprocess = target_scaler.transform(np.array(y_train).reshape((-1, 1)))\ny_test_preprocess = target_scaler.transform(np.array(y_test).reshape((-1, 1)))","0b3f7c87":"linear = LinearRegression()\nparameters = {}\nlinear_grid_search_cv = GridSearchCV(linear, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nlinear_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","19bf4a4d":"print(f'Best score (MAE): {linear_grid_search_cv.best_score_}')\nprint(f'Best parameters: {linear_grid_search_cv.best_params_}')","c0251932":"linear_best = linear_grid_search_cv.best_estimator_\ncoef = linear_best.coef_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(coef[0], X_train.columns)","ef274d97":"y_pred = linear_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","84a5b098":"feature_columns = ['PS', 'T2MWET', 'T2M_MAX', 'T2M_MIN']\nlinear_feature_columns_2 = ['PS', 'T2M', 'T2MWET', 'T2M_MAX', 'T2M_MIN',\t'T2M_RANGE', 'TS']\nlinear_feature_columns = ['T2M_MAX', 'TS', 'WS10M_MAX']\ntarget = data['TOTAL_CASES']\n\n# target = data['CASE_OVER_POPULATION']\nfeature_data = data[feature_columns]","6b4194b4":"X_train, X_test, y_train, y_test = train_test_split(feature_data, target, train_size=0.8, stratify=data['PROVINCE'], random_state=42)","73b19ede":"feature_scaler = StandardScaler()\nfeature_scaler.fit(X_train)\n\ntarget_scaler = StandardScaler()\ntarget_scaler.fit(np.array(y_train).reshape((-1, 1)))\n\nX_train_preprocess = feature_scaler.transform(X_train)\nX_test_preprocess = feature_scaler.transform(X_test)\n\ny_train_preprocess = target_scaler.transform(np.array(y_train).reshape((-1, 1)))\ny_test_preprocess = target_scaler.transform(np.array(y_test).reshape((-1, 1)))","8a78961f":"tree = DecisionTreeRegressor()\nparameters = {'criterion': ['mse', 'mae'], \n              'max_depth': [2, 5, 8, 10],\n              'min_samples_split': [2, 4]}\ntree_grid_search_cv = GridSearchCV(tree, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\ntree_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","4c021451":"print(f'Best score (MAE): {tree_grid_search_cv.best_score_}')\nprint(f'Best parameters: {tree_grid_search_cv.best_params_}')","bb231e2c":"tree_best = tree_grid_search_cv.best_estimator_\nfeature_importances = tree_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, X_train.columns)","b167676d":"y_pred = tree_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","ad760823":"from sklearn.tree import export_graphviz\nimport graphviz \ndot_data = export_graphviz(tree_best, out_file='1618_feature_engineering_tree.dot', feature_names=X_train.columns) ","7ade0cc9":"from subprocess import check_call\ncheck_call(['dot','-Tpng','1618_feature_engineering_tree.dot','-o','OutputFile.png'])","b79cb3e9":"feature_columns = ['PRECTOT',\t'PS',\t'QV2M',\t'RH2M', 'T2M', 'T2MWET', 'T2M_MAX', 'T2M_MIN',\t'T2M_RANGE', 'TS', 'WS10M',\t'WS10M_MAX',\t'WS10M_MIN',\t'WS10M_RANGE',\t'WS50M',\t'WS50M_MAX',\t'WS50M_MIN', 'WS50M_RANGE']\nlinear_feature_columns_2 = ['PS', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'TS']\nlinear_feature_columns = ['T2M_MAX', 'TS', 'WS10M_MAX']\ntarget = data['TOTAL_CASES']\n\n# target = data['CASE_OVER_POPULATION']\nfeature_data = data[linear_feature_columns_2]","9d0a6038":"X_train, X_test, y_train, y_test = train_test_split(feature_data, target, train_size=0.8, stratify=data['PROVINCE'], random_state=42)","39495c88":"feature_scaler = StandardScaler()\nfeature_scaler.fit(X_train)\n\ntarget_scaler = StandardScaler()\ntarget_scaler.fit(np.array(y_train).reshape((-1, 1)))\n\nX_train_preprocess = feature_scaler.transform(X_train)\nX_test_preprocess = feature_scaler.transform(X_test)\n\ny_train_preprocess = target_scaler.transform(np.array(y_train).reshape((-1, 1)))\ny_test_preprocess = target_scaler.transform(np.array(y_test).reshape((-1, 1)))","5388629d":"forest = RandomForestRegressor(n_jobs=-1, random_state=42)\nparameters = {'n_estimators': [10, 30, 50, 100, 500, 1000],\n              'max_depth': [2, 5, 8, 10, 15],\n              'min_samples_split': [2, 4]}\nforest_grid_search_cv = GridSearchCV(forest, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nforest_grid_search_cv.fit(X_train_preprocess, y_train_preprocess)","bba15682":"print(f'Best score (MAE): {forest_grid_search_cv.best_score_}')\nprint(f'Best parameters: {forest_grid_search_cv.best_params_}')","8ba4d5fa":"forest_best = forest_grid_search_cv.best_estimator_\nfeature_importances = forest_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, X_train.columns)","1b953f26":"y_pred = forest_best.predict(X_test_preprocess)\n\nmae = mean_absolute_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nmape = mean_absolute_percentage_error(target_scaler.inverse_transform(y_test_preprocess), target_scaler.inverse_transform(y_pred))\n\nprint(f'MAE loss:{mae}')\nprint(f'MAPE loss:{mape}')","6357f8c2":"data['PROVINCE'].unique()","58eb3226":"PROVINCE = 'BENTRE'\n\n# feature_columns = ['PRECTOT', 'PS', 'QV2M', 'RH2M', 'T2M', 'T2MWET', 'WS10M', 'WS50M']\nfeature_columns = ['PRECTOT', 'PS', 'QV2M', 'RH2M', 'T2M', 'T2MWET', 'WS10M']\ntarget = data['TOTAL_CASES']\n\n# target = data['CASE_OVER_POPULATION']\nfeature_data = data[feature_columns]","1e8d11a2":"province_feature = feature_data[data['PROVINCE'] == PROVINCE]\nprovince_target = target[data['PROVINCE'] == PROVINCE]","6b97ba19":"data[data['PROVINCE'] == PROVINCE]","0f0e4368":"feature_scaler = StandardScaler()\nprovince_feature_preprocess = feature_scaler.fit_transform(province_feature)","589212a5":"linear = LinearRegression()\nparameters = {}\nlinear_grid_search_cv = GridSearchCV(linear, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nlinear_grid_search_cv.fit(province_feature_preprocess, province_target)","b327ec62":"print(f'Best score (MAE): {linear_grid_search_cv.best_score_}')\nprint(f'Best parameters: {linear_grid_search_cv.best_params_}')","3e1ac898":"linear_best = linear_grid_search_cv.best_estimator_\ncoef = linear_best.coef_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(coef, province_feature.columns)","03f001c4":"tree = DecisionTreeRegressor()\nparameters = {'criterion': ['mse', 'mae'], \n              'max_depth': [2, 5, 8, 10],\n              'min_samples_split': [2, 4]}\ntree_grid_search_cv = GridSearchCV(tree, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\ntree_grid_search_cv.fit(province_feature_preprocess, province_target)","506314c5":"print(f'Best score (MAE): {tree_grid_search_cv.best_score_}')\nprint(f'Best parameters: {tree_grid_search_cv.best_params_}')","7c74e899":"tree_best = tree_grid_search_cv.best_estimator_\nfeature_importances = tree_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, province_feature.columns)","3f186a5a":"forest = RandomForestRegressor(n_jobs=-1)\nparameters = {'n_estimators': [10, 30, 50, 100, 500, 1000],\n              'max_depth': [2, 5, 8, 10, 15],\n              'min_samples_split': [2, 4]}\nforest_grid_search_cv = GridSearchCV(forest, parameters, scoring=('neg_mean_absolute_error'), cv=5, verbose=5, n_jobs=-1)\nforest_grid_search_cv.fit(province_feature_preprocess, province_target)","280cb5b7":"print(f'Best score (MAE): {forest_grid_search_cv.best_score_}')\nprint(f'Best parameters: {forest_grid_search_cv.best_params_}')","f6f783f5":"forest_best = forest_grid_search_cv.best_estimator_\nfeature_importances = forest_best.feature_importances_\n\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.barplot(feature_importances, province_feature.columns)","d51225d3":"**=> No findingds stood out**","04a666dd":"# Split and pre-process data","ad8be3a0":"## Linear Regression","47ce75e3":"## Linear Regression","654a5b0b":"# Train, build model without feature engineering\n","c2aea7c0":"## Random Forest Regressor","b522ac8d":"## Decision Tree Regressor","e4c77d2f":"## Random Forest Regressor","221af26e":"## Decision Tree Regressor\n","4a09ef9a":"# Per-province","cb5da851":"# Feature Engineering","26524042":"**=> Best feature: ['PS', 'T2MWET', 'T2M_MAX', 'T2M_MIN']**"}}