{"cell_type":{"be4ad8ee":"code","ed0cc210":"code","2df01a3d":"code","266c7342":"code","9224410f":"code","25c4e533":"code","2a68186e":"code","6a471931":"code","a69901f9":"code","33baece5":"code","44e12f32":"code","ff1e518b":"code","7737e91a":"code","83c9141f":"markdown","3c0d4e20":"markdown","2eb525a5":"markdown","04ad3ea0":"markdown","4076dc84":"markdown","e755de35":"markdown","5214eb10":"markdown","c7c97f45":"markdown","3b798e10":"markdown","74c08569":"markdown"},"source":{"be4ad8ee":"import pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom tqdm import tqdm, tqdm_notebook\nfrom pathlib import Path","ed0cc210":"df = pd.read_csv('..\/input\/quotes-from-goodread\/all_quotes.csv')\ndf = df[['Quote', 'Author', 'Main Tag']]\ndf['Author'] = df['Author'].fillna('')\nls= []\nfor i in range(len(df['Author'])):\n    if(df['Main Tag'][i] == 'death'):\n        ls.append(1)\n    else:\n        ls.append(0)\ndf.dropna(axis=0,inplace=True)\ndf['Death'] = ls","2df01a3d":"from sklearn.utils import shuffle\ndf = shuffle(df)","266c7342":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df['Quote'], df['Death'], test_size=0.3, random_state=101)","9224410f":"class Sequences(Dataset):\n    def __init__(self, x, y):\n        x = x\n        y = y\n        self.vectorizer = CountVectorizer(stop_words='english', max_df=0.99, min_df=0.005)\n        self.sequences = self.vectorizer.fit_transform(x.tolist())\n        self.labels = y.tolist()\n        self.token2idx = self.vectorizer.vocabulary_\n        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n        \n    def __getitem__(self, i):\n        return self.sequences[i, :].toarray(), self.labels[i]\n    \n    def __len__(self):\n        return self.sequences.shape[0]","25c4e533":"dataset = Sequences(X_train, y_train)\ntrain_loader = DataLoader(dataset, batch_size=100)\n\nprint(dataset[5][0].shape)","2a68186e":"class BagOfWordsClassifier(nn.Module):\n    def __init__(self, vocab_size, hidden1, hidden2):\n        super(BagOfWordsClassifier, self).__init__()\n        self.fc1 = nn.Linear(vocab_size, hidden1)\n        self.fc2 = nn.Linear(hidden1, hidden2)\n        self.fc3 = nn.Linear(hidden2, 1)\n    \n    def forward(self, inputs):\n        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n        x = F.relu(self.fc2(x))\n        return self.fc3(x)","6a471931":"model = BagOfWordsClassifier(len(dataset.token2idx), 128, 64)\nmodel","a69901f9":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)","33baece5":"model.train()\ntrain_losses = []\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    progress_bar = tqdm_notebook(train_loader, leave=False)\n    losses = []\n    total = 0\n    for inputs, target in progress_bar:\n        model.zero_grad()\n\n        output = model(inputs)\n        loss = criterion(output.squeeze(), target.float())\n        \n        loss.backward()\n              \n        nn.utils.clip_grad_norm_(model.parameters(), 3)\n\n        optimizer.step()\n        \n        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n        \n        losses.append(loss.item())\n        total += 1\n    \n    epoch_loss = sum(losses) \/ total\n    train_losses.append(epoch_loss)\n        \n    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')","44e12f32":"def predict_class(text):\n    model.eval()\n    with torch.no_grad():\n        test_vector = torch.LongTensor(dataset.vectorizer.transform([text]).toarray())\n\n        output = model(test_vector)\n        prediction = torch.sigmoid(output).item()\n\n        if prediction > 0.5:\n            return(1,prediction)\n        else:\n            return(0,prediction)","ff1e518b":"len(X_test)\nindex_ls = []\nfor i in range(len(X_test)):\n    index_ls.append(i)\nX_test.index = index_ls\ny_test.index = index_ls","7737e91a":"correct = 0\ntotal = len(X_test)\nls_pred = []\n\nfor i in range(len(X_test)):\n    output = predict_class(X_test[i])\n    label = output[0]\n    prediction = output[1]\n    if(label == y_test[i]):\n        correct+=1\n    ls_pred.append(prediction)\n\n# print(f'Prediction Accuracy : {sum(ls_pred)\/len(ls_pred)*100}')\nprint(f'Accuracy : {correct\/total*100}')","83c9141f":"# Predition Function","3c0d4e20":"# Training","2eb525a5":"# Evaluating The Model","04ad3ea0":"# Dataset","4076dc84":"# Import Statements","e755de35":"# Shuffling Data","5214eb10":"# Model","c7c97f45":"# Loss Function And Optimizer","3b798e10":"# Train Test Split","74c08569":"# Loading Data"}}