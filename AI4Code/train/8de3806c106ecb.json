{"cell_type":{"6d084410":"code","29416489":"code","f7a83369":"code","c0826575":"code","d2bcdde6":"code","f3850d6d":"code","74ac12f7":"code","c5fd3e00":"code","fff25cbd":"code","92dab0bb":"code","5d26bf79":"code","4a2b202a":"code","1ef2bf44":"code","6ec2752a":"code","63790ae2":"code","dad42e78":"code","333fc5f3":"code","38744c96":"code","8de95301":"code","c784fec0":"code","84ac866d":"code","a5784b85":"markdown","f1d2154e":"markdown","5576f536":"markdown","31da720e":"markdown","8c4ea664":"markdown","1fc68d99":"markdown","5558b534":"markdown","7849f662":"markdown","7801b3e4":"markdown","d8ea3a91":"markdown","f4185791":"markdown","9fa053ae":"markdown","c46eb47f":"markdown","60d6ae52":"markdown","75f30609":"markdown","f5bba263":"markdown","e4ce8fac":"markdown","57e98a43":"markdown"},"source":{"6d084410":"# Core\nimport os\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom pathlib import Path\nimport time\nimport math\n\n# Images\nimport cv2\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.python.client import device_lib","29416489":"# Source path\npath = '..\/input\/petfinder-pawpularity-score\/'\n\n# Read data and save as data frames\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n# Print dimensions of training data\nprint('train_df dimensions: ', train_df.shape)\n\n# Print dimensions of test data\nprint('test_df dimensions: ',test_df.shape)\n\n# Preview training metada\ntrain_df.head()","f7a83369":"# Given Id return full image path\ndef train_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/train\/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/test\/' + x + \".jpg\"\n\n# Drop metadata\ntrain_df = train_df.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\ntest_df = test_df.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\n# Add the .jpg extensions to the image ids\ntrain_df[\"img_path\"] = train_df[\"Id\"].apply(train_id_to_path)\ntest_df[\"img_path\"] = test_df[\"Id\"].apply(test_id_to_path)\n\ntrain_df.head()","c0826575":"# I haven't got this to work successfully\n'''\n# Binning columns (turn regression problem into classification problem)\ntrain_df['two_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=2, labels=False)\ntrain_df = train_df.astype({\"two_bin_pawp\": str})\n\n# qcut is a quantile-based discretization function\ntrain_df['five_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=5, labels=False)\ntrain_df = train_df.astype({\"five_bin_pawp\": str})\n\ntrain_df['ten_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=10, labels=False)\ntrain_df = train_df.astype({\"ten_bin_pawp\": str\n'''","d2bcdde6":"'''\n# Choose number of bins\nnum_bins=10\n\n# Delete y\ndel y\n\n# Make the bins the target\ny=train_df['ten_bin_pawp']\n\n# One-hot encoding\ny=pd.get_dummies(y)\n\n# Preview target\ny.head()\n'''","f3850d6d":"'''\n# For example\ntrain_df.groupby('five_bin_pawp').describe()\n'''","74ac12f7":"# Set desired image size\nimage_height = 224\nimage_width = 224\n\n# Function that converts image url to an eager tensor\ndef path_to_eagertensor(image_path):\n    \n    # Read file\n    raw = tf.io.read_file(image_path)\n    \n    # Decode jpeg\n    image = tf.image.decode_jpeg(raw, channels=3)\n    \n    # Chenge type and scale to lie in [0,1]\n    image = tf.cast(image, tf.float32) \/ 255.0\n    \n    image = tf.image.resize(image, (image_height, image_width))\n    return image","c5fd3e00":"# Plot that first image with original dimensions\nog_example_image = plt.imread(train_df['img_path'][0])\nprint(og_example_image.shape)\n\n# Display image with plt.imshow()\nplt.imshow(og_example_image)\nplt.title('First Training Image')\nplt.axis('off') # turns off the gridlines\nplt.show()","fff25cbd":"# Show pre-processing on first image\nexample_image = path_to_eagertensor(train_df['img_path'][0])","92dab0bb":"# Print the type \nprint('type: ', type(example_image),'\\n shape: ',example_image.shape)\n\n# Display image\nplt.imshow(example_image)\nplt.title('First Training Image - with preprocessing')\nplt.axis('off') # turns off the gridlines\nplt.show()","5d26bf79":"# 30% of original dataset (to save memory)\nsmall_train_df=train_df.iloc[:round(len(train_df)*0.3),:]\nsmall_train_df.shape","4a2b202a":"# Put training set tensors into a list\nX = []\nfor i in small_train_df['img_path']:\n    X.append(path_to_eagertensor(i))\n    \n# Convert to numpy array\nX = np.array(X)\n\n# Print type and shape\nprint(type(X),X.shape)","1ef2bf44":"# Put test set tensors into a list\nX_submission = []\nfor i in test_df['img_path']:\n    X_submission.append(path_to_eagertensor(i))\n    \n# Convert to numpy array\nX_submission = np.array(X_submission)\n\n# Print type and shape\nprint(type(X_submission),X_submission.shape)","6ec2752a":"# Labels\ny=train_df['Pawpularity']\n\n# Train-test split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y[:round(len(train_df)*0.3)], \n                                                      train_size=0.9, test_size=0.1, random_state=0)","63790ae2":"# Load pre-trained model: EfficientNet\nEfficientNet_path='..\/input\/keras-applications-models\/EfficientNetB0.h5'\n\n# This needs an input shape of (224,224,3)\nefficient_net = tf.keras.models.load_model(EfficientNet_path)\nefficient_net.trainable = False","dad42e78":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    #validation_split=0.10,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Training generator\ntraining_generator = datagen.flow(X_train, y_train, \n                                  batch_size=64,seed=0)\n\n# Validation generator\nvalidation_generator = datagen.flow(X_valid, y_valid, \n                                    batch_size=64,seed=0)","333fc5f3":"# Define model\nmodel = keras.Sequential([\n    \n    # Input layer\n    layers.Input(shape=(image_height, image_width, 3)),\n    \n    # Pretrained base\n    efficient_net,\n    \n    # Dense layer\n    layers.Flatten(),\n    layers.Dense(units=256, activation='relu'),\n    layers.Dropout(rate=0.4),\n    \n    # Output layer\n    #layers.Dense(units=num_bins, activation='softmax')   # one-hot encoding\n    layers.Dense(units=1, activation='relu')              # ordinal encoding\n])\n\n# Define optimizer, loss function and accuracy metric\nmodel.compile(optimizer='adam',\n              #loss='categorical_crossentropy',   # one-hot encoding\n              #metrics=['categorical_accuracy'])  # one-hot encoding\n              loss='mse',                         # ordinal encoding\n              metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n\n# Early stopping criteria\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=10,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)","38744c96":"# Train model\nhistory = model.fit(training_generator,\n    validation_data=validation_generator,\n    epochs=15,\n    steps_per_epoch=len(X_train)\/\/64,\n    #callbacks=[early_stopping],\n    verbose=True\n)","8de95301":"# Plot learning curves\nhistory_df = pd.DataFrame(history.history)\n#history_df.loc[1:, ['loss', 'val_loss']].plot(title='Categorical cross-entropy') # one-hot encoding\nhistory_df.loc[1:, ['rmse', 'val_rmse']].plot(title='RMSE')   # ordinal encoding\nplt.ylim([20,23])","c784fec0":"model.summary()","84ac866d":"# Predict on the submission data\npreds=model.predict(X_submission)\n\n# Put predictions alongside their corresponding Ids\nsub_df = pd.DataFrame()\nsub_df['Id'] = test_df['Id']\nsub_df['Pawpularity'] = preds\nsub_df.to_csv('submission.csv',index=False)\n\nsub_df.head()","a5784b85":"# Make predictions","f1d2154e":"**Model summary**","5576f536":"**Data augmentation**","31da720e":"**train-test split**","8c4ea664":"# Data","1fc68d99":"**Method of binning**","5558b534":"# Model using images","7849f662":"**Image pre-processing**","7801b3e4":"**Use groupby and describe to find group means**","d8ea3a91":"# EDA","f4185791":"See [HERE](https:\/\/www.kaggle.com\/samuelcortinhas\/pawpularity-eda-rf-model) for my first notebook where I carried out EDA and a simple RF model on the metadata. We will try to improve on this score here using an image-based model. This model will rely on transfer learning.","9fa053ae":"**Visualise image pre-processing**","c46eb47f":"**Transfer learning**","60d6ae52":"**Learning curves**","75f30609":"**Apply pre-processing to training and test sets**","f5bba263":"**NN model**","e4ce8fac":"**Train model**","57e98a43":"# Libraries"}}