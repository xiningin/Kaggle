{"cell_type":{"628b68c5":"code","d1605627":"code","d5e90251":"code","8340ea39":"code","0ba60ccf":"code","b9b4910e":"code","d7153ba6":"code","07f979b2":"code","dc1aa5a5":"code","27526d2c":"code","99ced738":"code","f732044d":"code","db02f2d4":"code","1970dc4f":"code","39364fe1":"code","c84f7db4":"code","c62c00e4":"code","5774cdbe":"code","93117b5c":"code","9c1387eb":"code","5dfe0852":"code","d32756ac":"code","da4843a5":"code","4ce6370f":"code","8544fda6":"code","60501914":"code","4cde2ff3":"code","e6396f48":"code","0d675da7":"code","d6e08bf0":"code","378a4de0":"code","01c5faf1":"code","b70cc774":"code","f837d1cb":"markdown","7b231da0":"markdown","b5ce6686":"markdown","5aef8ca8":"markdown","540d057b":"markdown","455f5f35":"markdown","11901be2":"markdown","e84b3c01":"markdown","4ae1a75a":"markdown","c7be0575":"markdown","522746ed":"markdown","5e765e7e":"markdown","28fb09f6":"markdown","1b2f8dc5":"markdown","72d96923":"markdown","da96b883":"markdown","2797c5cf":"markdown","e0aefd2d":"markdown","f3807aea":"markdown","0546cc1d":"markdown","a3eb7de9":"markdown","c2020a7c":"markdown","c9f56371":"markdown"},"source":{"628b68c5":"from keras import layers\nfrom keras import models\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n%matplotlib notebook\n\nfrom keras.models import load_model\n\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport imageio\nimport random\n\nimport PIL\n\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers","d1605627":"base_data_dir = \"..\/input\/galen-cats-dogs\/cats_and_dogs_small\/cats_and_dogs_small\/\"\n#base_data_dir = \".\/cats_and_dogs_small\/\"","d5e90251":"import keras \n\nprint(\"keras version is:\", keras.__version__)\n","8340ea39":"def display_random_image(data_dir = \".\/\"):\n    '''\n    display a random image from data_dir\n    \n    input:\n    - data_dir: location of images\n    \n    output: for a randomly selected image\n    - image pixel dimensions\n    - min, max values\n    \n    returns:\n    - PIL.Image\n    '''\n    \n    # load a random animal\n    animal_filename = random.choice(os.listdir(data_dir))\n\n    print(animal_filename)\n    animal = imageio.read(data_dir+animal_filename)\n    #df =\n\n    data = animal.get_data(0)\n\n    # 374 x 500 x 3 colors\n    print(\"image shape, min, max values:\")\n    print(data.shape)\n    print(data.min())\n    print(data.max())\n\n    return(PIL.Image.fromarray(data))","0ba60ccf":"display_random_image(base_data_dir + 'train\/cats\/')","b9b4910e":"display_random_image(base_data_dir + 'train\/dogs\/')","d7153ba6":"def setup_data_generators(base_data_dir = '.\/', \n                          rescale_factor = 255, \n                          target_width = 150, \n                          target_height = 150, \n                          batch_size = 20,\n                          class_mode = 'binary'):\n    '''\n    create keras ImageDataGenerator (see keras for further documentation)\n    - train\n    - validation\n    - test\n    \n    inputs:\n      base_data_dir = location of data\n      rescale_factor = how much to downscale pixel values\n      target_width = output image width\n      target_height = output image height\n      batch_size = number of images in each batch\n      class_mode = number of output classes\n    \n    \n    returns: 3 tuple of generators\n    (train_generator, validation_generator, test_generator)\n    '''\n    \n    train_dir = base_data_dir + 'train\/'\n    validation_dir = base_data_dir + 'validation\/'\n    test_dir = base_data_dir + \"test\/\"\n\n    # scale the data values\n    train_datagen = ImageDataGenerator(rescale=1.\/rescale_factor)\n    test_datagen = ImageDataGenerator(rescale=1.\/rescale_factor)\n\n    # the data generator from data files\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(target_height, target_width),\n        batch_size= batch_size,\n        class_mode='binary')\n\n    validation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(target_height, target_width),\n        batch_size=batch_size,\n        class_mode='binary')\n\n    # the generator for unclassified test data  Note settings for class_mode and batch_size\n    test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(target_height, target_width),\n        batch_size=1, \n        class_mode = None, \n        shuffle = False)\n    \n    \n    return(train_generator, validation_generator, test_generator)\n","07f979b2":"(train_generator, validation_generator, test_generator) = setup_data_generators(base_data_dir)","dc1aa5a5":"# # load a prepackaged keras image network\n# from keras.applications import VGG16\n\n# conv_base = VGG16(weights='imagenet',\n#                   include_top=False,\n#                   input_shape=(150, 150, 3))  #input shape","27526d2c":"conv_base = models.load_model(\"..\/input\/vgg16-pretrained\/VGG16.h5\")\n#conv_base = models.load_model(\".\/VGG16.h5\") ","99ced738":"conv_base.summary()","f732044d":"base_dir = base_data_dir\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\ntest_dir = os.path.join(base_dir, 'test')\n\ndatagen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 20","db02f2d4":"def extract_features(directory, sample_count):\n    '''\n    use pre-trained network to obtain features from images\n    features can be passed into classifier\n    '''\n    \n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    i = 0\n        \n    for inputs_batch, labels_batch in generator:\n\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n            break\n            \n    return features, labels","1970dc4f":"# calculate features using pre-trained convolutional network\n\ntrain_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_features, test_labels = extract_features(test_dir, 1000)","39364fe1":"# reshape for passing to dense classifier\n\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_features = np.reshape(test_features, (1000, 4 * 4 * 512))","c84f7db4":"# pass features to classifier and fit\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_features, train_labels,\n                    epochs=30,\n                    batch_size=20,\n                    validation_data=(validation_features, validation_labels))","c62c00e4":"# plot the results\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend();","5774cdbe":"plt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","93117b5c":"def print_best_validation(val_acc, val_loss):\n\n    print('max validation accuracy', np.max(val_acc), 'occurs at', np.argmax(val_acc))\n    print('min validation loss', np.min(val_loss), 'occurs at', np.argmin(val_loss))","9c1387eb":"print_best_validation(val_acc, val_loss)","5dfe0852":"def build_compile_model():\n    '''\n    build and compile keras convolutional model\n    \n    inputs:\n    \n    returns:\n    keras convolutional model\n    '''\n    \n    model = models.Sequential()\n\n    # the layers that build up a hiearchy toward higher-level features\n    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n                            input_shape=(150, 150, 3)))\n    model.add(layers.MaxPooling2D((2, 2)))\n\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n\n    # prepare to pass to classifier\n    model.add(layers.Flatten())\n\n    # the classifier with one hidden layer\n    model.add(layers.Dense(512, activation='relu'))\n\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])\n    \n    return(model)","d32756ac":"model = build_compile_model()\nmodel.summary()","da4843a5":"# print the data batch shape\n\nfor data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n\n    print('labels batch shape:', labels_batch.shape)\n\n    break","4ce6370f":"# load the model and history instead of training (just for speed)\n\n# this was trained in this notebook on kaggle\n\n#model_dir = \"..\/input\/dogs-and-cats\/\"\n#model_dir = \".\/\"\n\n#from keras.models import load_model\n#model = load_model(model_dir + 'cats_and_dogs_small_1.h5')\n\n#history_dir = \"..\/working\/\"\n# history_dir = \".\/\"\n\n# history = pd.read_pickle(history_dir + \"cats_and_dogs_small_1_history.pkl\")","8544fda6":"#if using kaggle or a GPU architecture, run here\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=50)\n\n#save the model and training history\nmodel.save('cats_and_dogs_small_1.h5')\n\n#also save the model as pickle to be sure\npd.to_pickle(obj = model, path = \"cats_and_dogs_small_1_model.pkl\")\n\npd.to_pickle(obj=history, path=\"cats_and_dogs_small_1_history.pkl\")","60501914":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nepochs = range(1, len(acc) + 1)\n\nplt.figure()\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()","4cde2ff3":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","e6396f48":"print_best_validation(val_acc, val_loss)","0d675da7":"# use this saved model or a model in memory\nsaved_model_name = 'cats_and_dogs_small_1.h5'\nmodel = load_model(model_dir + saved_model_name)\n\n\ntest_generator.reset()\npred=model.predict_generator(test_generator,verbose=1)\n\n# get the labels\npredicted_class_indices=np.argmax(pred,axis=1)","d6e08bf0":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","378a4de0":"outfolder = \".\/\"\n\nfilenames=test_generator.filenames\n\nresults=pd.DataFrame({#\"Filename\":filenames,\n                      \"Predictions\":predictions})\n\nresults.to_csv(outfolder + \"results.csv\",index=True)","01c5faf1":"def create_predictions(trained_model, test_generator, train_generator):\n    '''\n    create a dataframe of predictions using data from test_generator\n    \n    inputs:\n    keras model (already trained)\n    keras imagedatagenerators used during training and testing\n    \n    returns:\n    pandas Dataframe with columns:\n    Filenames: the image filename\n    predictions: predicted classes\n    '''\n    \n    test_generator.reset()\n    pred=trained_model.predict_generator(test_generator,verbose=1)\n\n    # get the labels\n    predicted_class_indices=np.argmax(pred,axis=1)\n    \n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predictions = [labels[k] for k in predicted_class_indices]\n    \n    filenames=test_generator.filenames\n\n    resultsDF=pd.DataFrame({\"Filename\":filenames,\n                          \"Predictions\":predictions})\n\n    return(resultsDF)\n\ndef save_predictions(outfilename, predictionsDF):\n    '''\n    save only index and prediction to .csv file\n    \n    input:\n    pandas Dataframe with columns:\n    Filenames: the image filename\n    predictions: predicted classes\n    \n    output:\n    .csv file saved to outfilename\n    '''\n    \n    series = predictionsDF['predictions']\n    \n    series.to_csv(outfilename)","b70cc774":"predictionsDF = create_predictions(model, test_generator, train_generator)\n\nsave_predictions(outfolder + \"results.csv\", predictionsDF)","f837d1cb":"# Dogs and Cats\n\n## Galen Wilkerson\n\ngjwilkerson@gmail.com\n\n\n## Notes:\n\nNormally, I would create classes, no time.\n\nGenerally, classes have data and functions.    \n\nAll names should be very very clear, and lots of terse but clear comments!\n\ndef class CNN:\n\n     __init__(self):\n     init vars\n     \ndef load_pretrained_model(self, filename):\n     # load the file as you see below\n\ndef build_classifier_pretrained(self, <model hypeparameters>):\n     # build as you see below\n\ndef train_pretrained_classifier(self, <data>):\n     # train as you see below\n    \nand utility functions such as prediction\ndata visualization\n\n*basically try to automate, modularize, and simplify functionality as much as possible!*\n\n","7b231da0":"## Keras version  (used default kaggle.com)","b5ce6686":"#### 20 images size 150 x 150 with 3 channels\n\ndata batch shape: (20, 150, 150, 3)\n    \nlabels batch shape: (20,)\n","5aef8ca8":"## Build the Model\n\n### We need a model that has layers of decreasing complexity, where each subsequent layer captures higher-level features\n### This is done by alternating:\n\n* convolutional layers (which learn features) for example, vertical lines, fur, ears, eyes across the whole image\n* max pooling which creates lower-resolution 'images' of feature presence by decimation\n\nSince we are looking for a relatively high-level 'feature' (a cat or dog), this requires multiple layers with alternating convolutional and max-pooling.\n\nFinally, at the end, we pass the output to a dense classifier network","540d057b":"unfortunately, no time for this.  but same as above.  I would use these model parameters and the optimal epochs","455f5f35":"### (Here I would combine the training and validation data and fit a model with the same parameters using 22 epochs)","11901be2":"## Create the best model by training on all (training, validation) data for the optimal number of epochs","e84b3c01":"## Build the Model\n\n## Kaggle seems to have problems downloading the pre-trained VGG16, so load from file instead","4ae1a75a":"# 3. A test program that allows to run predictions on test images and export the CSV file in the kaggle format (see sample_submission.csv) on both CNNs","c7be0575":"### best results around epoch ~ 22","522746ed":"#### Plot training and validation loss","5e765e7e":"# 1.  A train program that uses an existing **pretrained** CNN architecture of your choice","28fb09f6":"### Read sample data","1b2f8dc5":"### Plot training and validation accuracy\n\nThis allows us to understand at what point of training (number of epochs = times seeing the whole data set) the model becomes \"over-fit\" = too expert on the training data.    Since training data is _always_ a sub-sample of real-world data, this is always a factor.","72d96923":"#### Load saved model (trained using this code, not \"pre-trained\") or train new model","da96b883":"## Create the best model by training on all available (training, validation) data for the optimal number of epochs","2797c5cf":"## Dataset\n\nKaggle link: https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition\/data .\n\nDirect link: https:\/\/drive.google.com\/drive\/folders\/1-2gVprcVKLaje1gsayxQgVFItyXgxvPn?usp=sharing .\n\nOnly train subset is labelled.\n\n## Task\n\nBuild an image classifier for dogs Vs cats dataset using a Deep Learning framework of your choice with the language of your choice (preferred: python with Keras, TensorFlow, PyTorch or MxNet)\n\n.\n\nThe required outputs will be:\n\n1. A train program that uses an existing **pretrained** CNN architecture of your choice\n\n\n2. A train program that uses one of the following:\n\n    a. a custom CNN architecture built from scratch on your own using only convolution, activation, pooling and dense layers.\n\n    b. A custom made neural network \n\n\n3.  A test program that allows to run predictions on test images and export the CSV file in the kaggle format (see sample_submission.csv) on both CNNs\n\n\n4. Best custom model files and validation accuracy you found\n\n\n5. Best pretrained model files and validation accuracy you found\n\n\n6. Kaggle CSV file with predictions of the custom model\n\n\n7. Kaggle CSV file with predictions of the pretrained model\n\n\n8. Additional scripts and\/or config files useful for the tasks if needed\n\n\n9. Basic instructions on how to run the provided programs\n\n\n10. Exact version name of the selected deep learning framework (e.g. Keras 2.2.4)\n\n\n11. Plots\/Tensorboard files about the training process of the models\n\n\n\nWe give you 4 days to do your best to provide us the required outputs. Please note that we will evaluate also an incomplete output, so don\u2019t worry if you cannot manage to finish it: in that case, please send us the WIP you did complete and an explanation in English of how you would do the steps you didn\u2019t manage to implement.\n\n\nWe are interested in evaluating:\n\n1. Dataset processing step\n\n\n2. Architecture choices and problem approach\n\n\n3. Input and output shape of the models\n\n\n4. Hyperparameters choices\n\n\n5. Accuracy performances (have to be just sufficient considering the task)\n\n\n6. Programming style and approach. Plus if using OOC\n\n\n\nIf you don\u2019t have a GPU available, you can just use a subset of the dataset, we will evaluate the general coherency and correctness of the project. Further topics will be deepen in the interview.","e0aefd2d":"### find the max validation accuracy and min validation loss","f3807aea":"### both validation loss and accuracy plateau around 5 epochs","0546cc1d":"### however, since training seems to give better results, indicates we could do better \n### (but not with this model or data as it is)\n\n### improvement strategies would be:\n\n* get more data\n* data augmentation (horizontal flip, warp the cats and dogs to increase data size)\n* hyperparameter tuning  (re-dimensioning network: num hidden layers, size of each hidden layer)\n* regularlization techniques such as dropout\n* train the pre-trained model on this data","a3eb7de9":"## Set-Up","c2020a7c":"# 2. A train program that uses\n\n#  a custom CNN architecture built from scratch on your own using only convolution, activation, pooling and dense layers.","c9f56371":"### however, since training seems to give better results, indicates we could do better \n### (but not with this model or data as it is)\n\n### improvement strategies would be:\n\n* get more data\n* data augmentation (horizontal flip, warp the cats and dogs to increase data size)\n* hyperparameter tuning  (re-dimensioning network: num hidden layers, size of each hidden layer)\n* regularlization techniques such as dropout\n* using a pre-trained model (as above)"}}