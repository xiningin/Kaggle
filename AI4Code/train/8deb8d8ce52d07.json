{"cell_type":{"415cc511":"code","a01ea18c":"code","e9ef984a":"code","989467ef":"markdown","6bdf653b":"markdown","a13bf5b4":"markdown"},"source":{"415cc511":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# loading data including 32 best scores\ndf_sub = pd.read_csv('..\/input\/demand-forecasting-better-scores\/better_scores_than_13.6.csv')\n\n# a rough correlation based visualization of 32 best scores\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sub.corr(), cmap='Spectral')\nplt.ylabel('file index numbers')\nplt.xlabel('file index numbers')\nplt.show()","a01ea18c":"# basic analysis and visualization  of four groups in different color.\nsub_mean_corr = (1-df_sub.corr().mean().sort_values())*1e6\nplt.figure(figsize=(12,6))\nplt.plot(sub_mean_corr.index[:3], sub_mean_corr.values[:3], 's-')\nplt.plot(sub_mean_corr.index[3:15], sub_mean_corr.values[3:15], 's-')\nplt.plot(sub_mean_corr.index[15:27], sub_mean_corr.values[15:27], 's-')\nplt.plot(sub_mean_corr.index[30:], sub_mean_corr.values[30:], 's-')\nplt.title('determination of sub_groups')\nplt.ylabel('a corellation ralated index')\nplt.xlabel('file index numbers')\nplt.show()","e9ef984a":"# a best linear combination to achieve much better score\ndf_sub['weighted_avg'] = 1*( \n                            4*( df_sub['9'] + df_sub['17'] + df_sub['23'] )\/3 +\n                            \n                            1*( df_sub['2'] +  df_sub['5'] + df_sub['15'] + df_sub['16'] + df_sub['18'] + df_sub['20'] + \n                               df_sub['21'] + df_sub['22'] + df_sub['26'] + df_sub['27'] + df_sub['29'] + df_sub['30'])\/12 +\n                            \n                            3*( df_sub['3'] +  df_sub['4'] +  df_sub['6'] +  df_sub['7'] +  df_sub['8'] + df_sub['10'] + df_sub['11'] + df_sub['12'] + \n                               df_sub['13'] + df_sub['14'] + df_sub['19'] + df_sub['24'] + df_sub['25'] + df_sub['28'] + df_sub['31'] )\/15 +\n                            \n                            6*( df_sub['0'] + df_sub['1'] )\/2  \n                        ) \/ 14\n\nsubmission = pd.DataFrame({'id': [*range(45000)], 'sales': df_sub['weighted_avg'].round().astype('int')})\nsubmission.to_csv('submission.csv', index=False)","989467ef":"Dataset of the \"Store Item Demand Forecasting Challenge\" (https:\/\/www.kaggle.com\/c\/demand-forecasting-kernels-only\/) is one of time series related case study during my Data Science and Machine Learning bootcamp. \n\nI develop a LigthGBM model including feature engineering about different type approaches ie. smoothings, lag\/shift injections, nonlinear projections, encodings, model tuning etc. My base notebook is able to reach public scores between 13.84000 - 13.86000, and you can check it (https:\/\/www.kaggle.com\/hikmetsezen\/base-model-with-lightgbm-on-demand-forecasting). \n\nHere I only share with you my blend boosting study to further enhance the score. For that reason, I use my 32 best scores, and after making a basic correlation analysis I separate them into four groups and figure out a best linear combination. I am able to get the best score on the Kaggle, 13.83657 (public).","6bdf653b":"\n\nFor simplicity I calculate mean of correlation values, and convert these values to index seek of an easy recognition. With this procedure K separate these 32 best scores into four distinct groups. After that I figure out a best linear combination. By spending much more time an acquisition much better score is always possible. \n","a13bf5b4":"## It gets 13.83657 as public score, and looks the best score on Kaggle so far ;-)"}}