{"cell_type":{"c6e13218":"code","25c4b8bd":"code","47849c5c":"code","14bf1b3e":"code","96454dac":"code","ee4ad8c3":"code","0b882f4a":"code","b10fa0b4":"code","68c575c6":"code","cec8f0b3":"code","d1daceae":"code","c34ee4b1":"code","7e2dc9b0":"markdown","7528f505":"markdown","5053598c":"markdown","2443a896":"markdown","f1e053b1":"markdown","7d9c601f":"markdown","e56a7beb":"markdown","b0e76a4a":"markdown","8135b25f":"markdown","14274c6e":"markdown","dfadbaa0":"markdown","12427443":"markdown","b3c093dd":"markdown","623d1d0b":"markdown"},"source":{"c6e13218":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\nfrom keras.layers import Dense\nfrom keras.models import Sequential","25c4b8bd":"X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n\n\nweights = {0:0.01, 1:1.0}\nmodel = LogisticRegression(solver='lbfgs', class_weight=weights)\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\n\nscores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint('Mean ROC AUC: %.3f' % np.mean(scores))","47849c5c":"from sklearn.utils.class_weight import compute_class_weight\n\nX, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n# calculate class weighting\nweighting = compute_class_weight('balanced', [0,1], y) \nprint(weighting)","14bf1b3e":"X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n\n\nmodel = LogisticRegression(solver='lbfgs', class_weight='balanced')\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nscores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\nprint('Mean ROC AUC: %.3f' % np.mean(scores))","96454dac":"X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n\nmodel = LogisticRegression(solver='lbfgs')\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)","ee4ad8c3":"balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \nparam_grid = dict(class_weight=balance)\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\nscoring='roc_auc')\n\ngrid_result = grid.fit(X, y)\n\nprint('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) \n\n# report all configurations\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('%f (%f) with: %r' % (mean, stdev, param))","0b882f4a":"X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=3)\n\nmodel = DecisionTreeClassifier(class_weight='balanced')\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nscores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint('Mean ROC AUC: %.3f' % np.mean(scores))","b10fa0b4":"X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n\nmodel = DecisionTreeClassifier()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nbalance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \nparam_grid = dict(class_weight=balance)\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\nscoring='roc_auc')\n\ngrid_result = grid.fit(X, y)\n\nprint('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) \n\n# report all configurations\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('%f (%f) with: %r' % (mean, stdev, param))","68c575c6":"model = SVC(gamma='scale')\n# define grid\nbalance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \nparam_grid = dict(class_weight=balance)\n\nX, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\nscoring='roc_auc')\n\ngrid_result = grid.fit(X, y)\n\nprint('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) \n\n# report all configurations\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('%f (%f) with: %r' % (mean, stdev, param))","cec8f0b3":"# prepare train and test dataset\ndef prepare_data():\n    # generate 2d classification dataset\n    X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=4)\n      # split into train and test\n    n_train = 5000\n    trainX, testX = X[:n_train, :], X[n_train:, :]\n    trainy, testy = y[:n_train], y[n_train:]\n    return trainX, trainy, testX, testy","d1daceae":"from sklearn.metrics import roc_auc_score\n# define the neural network model\ndef define_model(n_input):\n    # define model\n    model = Sequential()\n    # define first hidden layer and visible layer \n    model.add(Dense(10, input_dim=n_input, activation='relu',\n    kernel_initializer='he_uniform'))\n    # define output layer\n    model.add(Dense(1, activation='sigmoid'))\n    # define loss and optimizer \n    model.compile(loss='binary_crossentropy', optimizer='sgd') \n    return model\n\ntrainX, trainy, testX, testy = prepare_data()\n\nn_input = trainX.shape[1]\nmodel = define_model(n_input)\n# fit model\nweights = {0:1, 1:100}\nhistory = model.fit(trainX, trainy, class_weight=weights, epochs=100, verbose=0) \n\n# evaluate model\nyhat = model.predict(testX)\nscore = roc_auc_score(testy, yhat)\nprint('ROC AUC: %.3f' % score)","c34ee4b1":"from xgboost import XGBClassifier\n\nX, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n    n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=7)\n\n\n\nmodel = XGBClassifier()\n\nweights = [1, 10, 25, 50, 75, 99, 100, 1000]\nparam_grid = dict(scale_pos_weight=weights)\n\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n\ngrid_result = grid.fit(X, y)\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","7e2dc9b0":"<h2><center>Imbalanced Classification<\/center><\/h2>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nImbalanced classification involves developing predictive models on classification datasets that have a severe class imbalance. The challenge of working with imbalanced datasets is that most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is performance on the minority class that is most important.\n<\/div>    \n    \n![image.png](attachment:image.png)\n\n<h3><center>Over Sampling & Under Sampling Methods<\/center><\/h3>\n<p style=\"font-family:verdana; word-spacing:1.5px;font-size:15px\">Please click on the link below to access Notebook for Over Sampling & Under Sampling Methods:<br>\n<a href='https:\/\/www.kaggle.com\/ashrafkhan94\/imbalanced-classification-over-under-sampling?scriptVersionId=52762319'> https:\/\/www.kaggle.com\/ashrafkhan94\/imbalanced-classification-over-under-sampling<\/a><\/p>\n\n<div style=\"font-family:verdana; word-spacing:1.9px;\">\n    <h3><center>Cost-Sensitive Learning<\/center><\/h3>\nMost machine learning algorithms assume that all misclassification errors made by a model are equal. This is often not the case for imbalanced classification problems where missing a positive or minority class case is worse than incorrectly classifying an example from the negative or majority class. There are many real-world examples, such as detecting spam email, diagnosing a medical condition, or identifying fraud. In all of these cases, a false negative (missing a case) is worse or more costly than a false positive.\n    <br><br>\nFor imbalanced classification problems, the examples from the majority class are referred to as the negative class and assigned the class label 0.<br> Those examples from the minority class are referred to as the positive class and are assigned the class label 1. The reason for this negative vs. positive naming convention is because the examples from the majority class typically represent a normal or no-event case, whereas examples from the minority class represent the exceptional or event case.\n<br><br>\n    <ul>\n        <h3 style=\"font-family:verdana; word-spacing:1.9px;font-size:16px\">Bank Loan Problem<\/h3>\n<li>Consider a problem where a bank wants to determine whether to give a loan to a customer or not. Denying a loan to a good customer is not as bad as giving a loan to a bad customer that may never repay it.<br><br>\n    <h3 style=\"font-family:verdana; word-spacing:1.9px;font-size:16px\"> Cancer Diagnosis Problem<\/h3>\n<li>Consider a problem where a doctor wants to determine whether a patient has cancer or not. It is better to diagnose a healthy patient with cancer and follow-up with more medical tests than it is to discharge a patient that has cancer.\n    <\/ul>\n    \n<h3 style=\"font-family:verdana; word-spacing:1.9px;font-size:16px\">The Keras Python Deep Learning library also provides access to this use of cost-sensitive augmentation for neural networks via the class weight argument on the fit() function when training models.<\/h3>","7528f505":"<h3>2.2. Grid Search (Non-Heuristic Approach)","5053598c":"<h3>1.3. Grid Search Weighted Logistic Regression (Non - Heuristic)<\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nUsing a class weighting that is the inverse ratio of the training data is just a heuristic. <br>It is possible that better performance can be achieved with a different class weighting, and this too will depend on the choice of performance metric used to evaluate the model.<\/div>\n\n![image.png](attachment:image.png)","2443a896":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\nA best practice for using the class weighting is to use the inverse of the class distribution present in the training dataset. For example, the class distribution of the training dataset is a 1:100 ratio for the minority class to the majority class. The inversion of this ratio could be used with 1 for the majority class and 100 for the minority class; for example:<\/div>\n\n![image.png](attachment:image.png)","f1e053b1":"<h3>2.1. Automatic Heuristic Approach (Inverse of class distributions)<\/h3>","7d9c601f":"<h3><center>1. Cost-Sensitive Logistic Regression<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    Logistic regression does not support imbalanced classification directly. Instead, the training algorithm used to fit the logistic regression model must be modified to take the skewed distribution into account. <br><br>This can be achieved by specifying a class weighting configuration that is used to influence the amount that logistic regression coefficients are updated during training.\nThe weighting can penalize the model less for errors made on examples from the majority class and penalize the model more for errors made on examples from the minority class.\n    <br><br>\n    The LogisticRegression class provides the class weight argument that can be specified as a model hyperparameter. The class weight is a dictionary that defines each class label (e.g. 0 and 1) and the weighting to apply in the calculation of the negative log likelihood when fitting the model. For example, a 1 to 1 weighting for each class 0 and 1 can be defined as follows:\n    <\/div>\n\n![image.png](attachment:image.png)","e56a7beb":"<h3>1.1. Manually Assigning weights (Heuristic - Inverse of distribution)<\/h3>","b0e76a4a":"**<blockquote>We have achieved Outstanding Performance from SVM<\/blockquote>**","8135b25f":"<h3><center>3. SVM<\/center><\/h3>","14274c6e":"<h3><center>2. Cost-Sensitive Decision Trees<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    The tree is constructed by splitting the training dataset using values for variables in the dataset. At each point, the split in the data that results in the purest (least mixed) groups of examples is chosen in a greedy manner. Here, purity means a clean separation of examples into groups where a group of examples of all 0 or all 1 class is the purest, and a 50-50 mixture of both classes is the least pure. Purity is most commonly calculated using Gini impurity, although it can also be calculated using entropy.<br><br>\nThe calculation of a purity measure involves calculating the probability of an example of a given class being misclassified by a split. Calculating these probabilities involves summing the number of examples in each class within each group. The splitting criterion can be updated to not only take the purity of the split into account, but also be weighted by the importance of each class.<\/div>","dfadbaa0":"<h3><center>5. Weighted XGBoost for Class Imbalance.<\/center> <\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    The implementation provides a hyperparameter designed to tune the behavior of the algorithm for imbalanced classification problems; this is the scale_pos_weight hyperparameter.<br>\nBy default, the scale pos weight hyperparameter is set to the value of 1.0\n    The scale_pos_weight can be used to train a class-weighted or cost-sensitive version of XGBoost for imbalanced classification. A sensible default value to set for the scale pos weight hyperparameter is the inverse of the class distribution. For example, for a dataset with a 1 to 100 ratio for examples in the minority to majority classes, the scale pos weight can be set to 100.<\/div>\n    \n![image.png](attachment:image.png)","12427443":"<h3><center>4. Cost-Sensitive Deep Learning in Keras.<\/center> <\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nThe backpropagation algorithm can be updated to weigh misclassification errors in proportion to the importance of the class, referred to as weighted neural networks or cost-sensitive neural networks.<\/div>","b3c093dd":"<h3>1.2. Automatically Assigning weights by Classifiers (Heuristic - Inverse of distribution)<\/h3>","623d1d0b":"<h3>0.5 : 50 = 0.01 : 1.0<\/h3>"}}