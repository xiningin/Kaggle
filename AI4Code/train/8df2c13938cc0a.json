{"cell_type":{"c4ee57a8":"code","1b09e24a":"code","c2f897c4":"code","028c1360":"code","42ed3098":"code","94dcdb22":"code","18b9b7ab":"code","5798c57d":"code","9e8624fe":"code","4cda8697":"code","3f75532d":"code","2ca0d4a1":"code","c7e0c9f1":"code","f4e85287":"code","0f1ee2a3":"code","c8ad90da":"code","8cfb4a16":"code","edf2278e":"code","0a4ab1fb":"code","eb74ba34":"code","dfbb34b6":"code","d004b484":"code","58384cf3":"code","ebc7a41b":"code","e773d4ca":"code","79f2628e":"code","12f90365":"code","5bf66bdc":"code","76307a45":"code","2b838fcd":"code","51bb7028":"code","ad2be0bc":"code","448a8e1a":"code","1bccacc0":"code","1f3f4729":"code","d1805437":"code","02fc7ebe":"code","d0132d87":"code","40f4c547":"code","cd7ef735":"code","3c549be4":"code","2baa2e28":"code","784d9e56":"code","aa0f9560":"code","a1aac09e":"code","ad19031c":"code","10193642":"code","a75e9563":"code","a5b1a87b":"code","0644f71f":"markdown"},"source":{"c4ee57a8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm,skew","1b09e24a":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest  = pd.read_csv(\"..\/input\/test.csv\")","c2f897c4":"train.head()","028c1360":"train_ID = train['Id']\ntest_ID = test['Id']\ntrain.drop(\"Id\",axis=1,inplace=True) # Dropping TrainId \ntest.drop(\"Id\",axis=1,inplace=True)  # Dropping TestId","42ed3098":"# Detecting Outliners within the dataset\nfig,ax = plt.subplots()\nax.scatter(x=train['GrLivArea'],y=train['SalePrice'])\nplt.ylabel('SalePrice',fontsize=13)\nplt.xlabel('GrLivArea',fontsize=13)\nplt.show()","94dcdb22":"#Removing outliers in the dataset\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)","18b9b7ab":"fig ,ax= plt.subplots()\nax.scatter(train['GrLivArea'],train['SalePrice'])\nplt.xlabel('GrLivArea',fontsize=12)\nplt.ylabel('SalePrice',fontsize=13)\nplt.show()","5798c57d":"# Plotting Univariate distribution using Distplot\n\nsns.distplot(train['SalePrice'],fit=norm); \n\n'''\nFitting a normal distribution \nmu  - mean of the normal distribution\nsigma - standard deviatio of the normal distribution\n\n'''\n\n(mu,sigma) = norm.fit(train['SalePrice']) \n\nplt.legend(['Normal dist . ($\\mu=$ {:2f} and $\\sigma = $ {:2f})'.format(mu,sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\nfig = plt.figure()\n\n'''\nPlotting the probability plot (QQ-Plot):\nThe probability plot is a graphical technique for assessing whether or \nnot a data set follows a given distribution such as the normal or Weibull.\n'''\nres = stats.probplot(train['SalePrice'],plot=plt)\nplt.show()\n","9e8624fe":"'''\n\nLog transformation of data : Make highly skewed dataset less skewed \nmaking it easy for parametric tests \n\n'''\ntrain['SalePrice'] = np.log1p(train['SalePrice'])\n\nsns.distplot(train['SalePrice'],fit=norm)\n(mu,sigma)= norm.fit(train['SalePrice'])\nplt.legend(['Normal dist . ($\\mu=$ {:2f} and $\\sigma=$ {:2f})'.format(mu,sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'],plot=plt)\nplt.show()","4cda8697":"ntrain  = train.shape[0]\nntest   = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train,test)).reset_index(drop=True)\nall_data.drop(['SalePrice'],axis=1,inplace=True)\nall_data.shape","3f75532d":"'''\nComputing the Null Values\nThe Ratio of Missing Data\n'''\nall_data_na = (all_data.isnull().sum()\/len(all_data))*100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ration' : all_data_na})\nmissing_data.head(20)","2ca0d4a1":"'''\nPlotting the missing value by missing value ratio\n'''\nf,ax = plt.subplots(figsize=(15,12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index,y=all_data_na)\nplt.xlabel('Features',fontsize=15)\nplt.ylabel('Percent of missing values',fontsize=15)\nplt.title('Percent missing data by feature',fontsize=15)","c7e0c9f1":"'''\nCorrelatio Matrix gives an idea about how related values are there in the dataset\n'''\n\ncorrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat,vmax=0.9,square=True)","f4e85287":"all_data['PoolQC'] = all_data[\"PoolQC\"].fillna(\"None\")","0f1ee2a3":"all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")","c8ad90da":"all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")","8cfb4a16":"all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")","edf2278e":"all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")","0a4ab1fb":"all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","eb74ba34":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')","dfbb34b6":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)","d004b484":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)","58384cf3":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","ebc7a41b":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","e773d4ca":"all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])","79f2628e":"all_data = all_data.drop(['Utilities'], axis=1)","12f90365":"all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")","5bf66bdc":"all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])","76307a45":"all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])","2b838fcd":"all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])","51bb7028":"all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])","ad2be0bc":"all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","448a8e1a":"all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)","1bccacc0":"all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n","1f3f4729":"all_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","d1805437":"all_data.dtypes","02fc7ebe":"'''\nLabel Encoding for working with Categorical values\n'''\nfrom sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values))\n    all_data[c] = lbl.transform(list(all_data[c].values))\n\nprint(all_data.shape)","d0132d87":"all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF']+all_data['2ndFlrSF']","40f4c547":"#Numerical Features in the dataset\nnumeric_feats  = all_data.dtypes[all_data.dtypes!=\"object\"].index","cd7ef735":"'''\nIn statistics, \nskewness is a measure of the asymmetry of the probability distribution \nof a random variable about its mean.\n'''\nskewed_feats = all_data[numeric_feats].apply(lambda x:skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' : skewed_feats})\nskewness.head(10)","3c549be4":"all_data = pd.get_dummies(all_data)","2baa2e28":"train = all_data[:ntrain]","784d9e56":"test  = all_data[ntrain:]","aa0f9560":"from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error#\nimport xgboost as xgb","a1aac09e":"n_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","ad19031c":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\nnp.where(all_data.values >= np.finfo(np.float64).max)","10193642":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=12000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n\nregr = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n#RFR\n'''regr.fit(train,y_train)\nrg_train_pred = regr.predict(train)\nrg_pred = np.expm1(regr.predict(test))\nprint(rmsle(y_train, rg_train_pred))'''\n#XGB\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))","a75e9563":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False)","a5b1a87b":"print(sub.head())","0644f71f":"# Handling Missing Data"}}