{"cell_type":{"28ff47e6":"code","0348a1c9":"code","7b664ad9":"code","3636947c":"code","163ba8ec":"code","dccb8c12":"code","8106809d":"code","a1fcb0ea":"code","d5840249":"code","027cdb32":"code","ad9c2dbb":"markdown","2bbd66df":"markdown","67dc07fe":"markdown","78b0a33f":"markdown","deffc2fe":"markdown","9d9d5024":"markdown","297fae02":"markdown","1c48101d":"markdown"},"source":{"28ff47e6":"import numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport os\nfrom tqdm import tqdm\nfrom time import sleep\nimport cv2","0348a1c9":"data_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ndef load_split_train_test(datadir, batch_size, valid_size = .2):\n    train_transforms = transforms.Compose([transforms.Resize((224, 244)), transforms.ToTensor(),])\n    test_transforms = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),])\n\n    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n\n    num_train = len(train_data)\n    indices = list(range(num_train))\n    split = int(np.floor(valid_size * num_train))\n    np.random.shuffle(indices)\n\n    train_idx, test_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(test_idx)\n\n    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n\n    return trainloader, testloader\n\nbatch_size = 32\ntrainloader, testloader = load_split_train_test(data_dir, batch_size, .18)\nprint(\"Train Size:\", len(trainloader) * batch_size, \", No of bacthes:\", len(trainloader))\nprint(\"Test Size:\", len(testloader) * batch_size, \", No of bacthes:\", len(testloader))\nprint(\"Classes:\", trainloader.dataset.classes)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\",device)","7b664ad9":"backbone = 'mobilenet_v2'\naddLayers = False\nif backbone == 'resnet50':\n    model = models.resnet50(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    if addLayers:\n        model.fc = nn.Sequential(nn.Linear(2048, 1024),\n          nn.ReLU(),\n          nn.Dropout(0.2),\n          nn.Linear(1024, len(trainloader.dataset.classes)),\n          nn.LogSoftmax(dim=1)\n          )\n    else:\n        model.fc = nn.Linear(2048, len(trainloader.dataset.classes))\nelif backbone == 'mobilenet_v2':\n    model = models.mobilenet_v2(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    if addLayers:\n        model.classifier = nn.Sequential(nn.Linear(1280, 1024),\n          nn.ReLU(),\n          nn.Dropout(0.2),\n          nn.Linear(1024, len(trainloader.dataset.classes)),\n          nn.LogSoftmax(dim=1)\n          )\n    else:\n        model.classifier = nn.Linear(1280, len(trainloader.dataset.classes))\n# print(model)","3636947c":"#criterion = nn.NLLLoss()\nlearning_rate = 0.001\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\nmodel.to(device)","163ba8ec":"epochs = 5\nrunning_loss = 0\ntrain_losses, test_losses = [], []\nmin_val_loss = None\nname = ''","dccb8c12":"for epoch in range(epochs):\n    with tqdm(trainloader, unit=\"batch\") as tepoch:\n        accuracy = 0\n        for i, data in enumerate(tepoch):\n            inputs, labels = data\n            tepoch.set_description(f\"Training Epoch {epoch + 1}\")\n            inputs, labels = inputs.to(device), labels.to(device)\n            size = labels.shape[0]\n            optimizer.zero_grad()\n            logps = model.forward(inputs)\n            # print(torch.argmax(logps, dim=1).shape, labels.shape)\n            loss = criterion(logps, labels)\n            train_acc = torch.sum(torch.argmax(logps, dim=1) == labels).item() \/ size\n            accuracy += train_acc\n            loss.backward()\n\n            optimizer.step()\n            running_loss += loss.item()\n\n            tepoch.set_postfix(loss=loss.item(), accuracy=100. * train_acc)\n            sleep(0.005)\n            if i == len(trainloader)-1:\n                accuracy = accuracy \/ len(trainloader)\n                tepoch.set_postfix(loss=running_loss\/len(trainloader), accuracy=100. * accuracy)\n    test_loss = 0\n    accuracy = 0\n    model.eval()\n    with torch.no_grad():\n        with tqdm(testloader, unit=\"batch\") as tepoch:\n            for i, data in enumerate(tepoch):\n                (inputs, labels) = data\n                tepoch.set_description(f\"Testing Epoch {epoch + 1}\")\n                inputs, labels = inputs.to(device), labels.to(device)\n                size = labels.shape[0]\n                logps = model.forward(inputs)\n                batch_loss = criterion(logps, labels)\n                test_loss += batch_loss.item()\n\n                test_acc = torch.sum(torch.argmax(logps, dim=1) == labels).item() \/ size\n                accuracy += test_acc\n                tepoch.set_postfix(loss=batch_loss.item(), accuracy=100. * test_acc)\n                # tepoch.set_postfix(loss=batch_loss.item())\n                sleep(0.005)\n                if i == len(testloader)-1:\n                        accuracy = accuracy \/ len(testloader)\n                        tepoch.set_postfix(loss=test_loss\/len(testloader), accuracy=100. * accuracy)\n\n    val_loss = test_loss\/len(testloader)\n    if min_val_loss is None:\n        min_val_loss = val_loss\n        name = 'sl_recognition_{}_{}_{}.pth'.format(str(epoch + 1), str(round(val_loss, 3)), str(round(accuracy, 3)))\n        torch.save(model, name)\n    elif min_val_loss > val_loss:\n        min_val_loss = val_loss\n        name = 'sl_recognition_{}_{}_{}.pth'.format(str(epoch + 1), str(round(val_loss, 3)), str(round(accuracy, 3)))\n        torch.save(model, name)\n\n    running_loss = 0\n    model.train()\ntorch.save(model, 'final_sl.pth')","8106809d":"with open('classes.txt', 'w') as f:\n    for clas in trainloader.dataset.classes:\n        f.write(clas+'\\n')","a1fcb0ea":"onnx_model_path = \"sl.onnx\"\nmodel = torch.load(name)\nmodel.to(\"cpu\")\nmodel.eval()\ndummy_input = torch.randn(1, 3, 224, 224)\ntorch.onnx.export(model, dummy_input, onnx_model_path, verbose=True)","d5840249":"import matplotlib.pyplot as plt","027cdb32":"plt.figure(figsize=(20, 20))\nimageDir = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nnet =  cv2.dnn.readNetFromONNX(onnx_model_path) \nwith open('classes.txt', 'r') as f:\n    classes = f.read().split('\\n')\nfor i, image_name in enumerate(os.listdir(imageDir)):\n    image = cv2.imread(os.path.join(imageDir, image_name))\n    blob = cv2.dnn.blobFromImage(image, 1.0 \/ 255, (224, 224),(0, 0, 0), swapRB=True, crop=False)\n    net.setInput(blob)\n    preds = net.forward()\n    biggest_pred_index = np.array(preds)[0].argmax()\n    ax = plt.subplot(6, 5, i + 1)\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.title(\"predicted: {}, True: {}\".format(classes[biggest_pred_index], image_name.split('_test.jpg')[0]))\n    plt.axis(\"off\")","ad9c2dbb":"# Run Inference with opencv","2bbd66df":"# Model Building","67dc07fe":"# DataLoader","78b0a33f":"# Model Training","deffc2fe":"# Generate Classes.txt","9d9d5024":"# Loss and Optimizer","297fae02":"# Imports","1c48101d":"# Convert to onnx"}}