{"cell_type":{"4a487ff8":"code","2a874fc8":"code","063cd5dd":"code","d5afa5fa":"code","b08b5d84":"code","24cc3c6c":"code","135a7b41":"code","84f0f9ac":"code","82042968":"code","f6bb2924":"code","1795a2f6":"code","8208a2a7":"code","e24add6a":"code","1ec36bf1":"code","8ae7cb88":"code","0efaa6a8":"code","98bcd8da":"code","16913269":"code","56732180":"code","8b3accd4":"code","f5b9d19b":"code","21579de5":"code","bc1e7b00":"code","be33a504":"code","a409e565":"code","5286da26":"code","57f3fa93":"code","dbb7903d":"code","80b23665":"code","ebf28441":"code","07586c4f":"code","dc66d460":"code","bbd6f969":"code","06bcde5b":"code","35e5e783":"code","fe9fa913":"code","c9c98711":"code","631db6b9":"code","662af65c":"code","44ebb9b0":"code","3affeb28":"code","de688551":"code","d33a2bc9":"code","9df68811":"code","e00bb3b3":"code","b7bed9f1":"code","6a8466c0":"code","c4b5d6ee":"code","8b7d06b3":"code","f058eb4f":"code","a805bc99":"code","4136f937":"code","97a925d1":"code","4516bfbc":"code","71711ada":"code","bad2b3aa":"code","d2027ead":"code","49ce1b1d":"code","16b41488":"markdown","37cb9df0":"markdown","0525f53e":"markdown","932978d1":"markdown","9543d9c0":"markdown","d698328f":"markdown","d7b8b649":"markdown","95810584":"markdown","5752c6b9":"markdown","e4a824bc":"markdown","0abf648a":"markdown","d74d4d38":"markdown","334e5143":"markdown","af759674":"markdown","16c6d0a2":"markdown","f9b3de4b":"markdown","8ec6ad82":"markdown","4f5a3ffc":"markdown","a53143a6":"markdown","41ad3196":"markdown","c97f4d4f":"markdown","69ca2cf4":"markdown"},"source":{"4a487ff8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd #data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a874fc8":"data=pd.read_csv('..\/input\/pima-prediction\/datasets_228_482_diabetes.csv')","063cd5dd":"data","d5afa5fa":"data.head()","b08b5d84":"data.tail()","24cc3c6c":"data.info()","135a7b41":"a=data.describe(include='all')\na","84f0f9ac":"##Check the dtypes of this dataset\ndata.dtypes","82042968":"##Check the null values of this dataset\ndata.isnull().sum()","f6bb2924":"#plot the countplot for Outcome column \nsns.countplot(data.Outcome)\nplt.show()","1795a2f6":"data['Outcome'].value_counts()","8208a2a7":"cor=data.corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\nplt.show()","e24add6a":"data.dtypes","1ec36bf1":"sns.distplot(data.Pregnancies[data.Outcome==0])\nsns.distplot(data.Pregnancies[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","8ae7cb88":"sns.distplot(data.Glucose[data.Outcome==0])\nsns.distplot(data.Glucose[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","0efaa6a8":"sns.distplot(data.BloodPressure[data.Outcome==0])\nsns.distplot(data.BloodPressure[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","98bcd8da":"sns.distplot(data.SkinThickness[data.Outcome==0])\nsns.distplot(data.SkinThickness[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","16913269":"sns.distplot(data.Insulin[data.Outcome==0])\nsns.distplot(data.Insulin[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","56732180":"sns.distplot(data.BMI[data.Outcome==0])\nsns.distplot(data.BMI[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","8b3accd4":"sns.distplot(data.DiabetesPedigreeFunction[data.Outcome==0])\nsns.distplot(data.DiabetesPedigreeFunction[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","f5b9d19b":"sns.distplot(data.Age[data.Outcome==0])\nsns.distplot(data.Age[data.Outcome==1])\nplt.legend(['Not Diabetes','Daibetes'])\nplt.show()","21579de5":"sns.pairplot(data=data,hue='Outcome',diag_kind='kde')\nplt.show()","bc1e7b00":"#input and output selection\nip=data.drop(['Outcome'],axis=1)\nop=data['Outcome']","be33a504":"from sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts=train_test_split(ip,op,test_size=0.4)","a409e565":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(xtr)\nxtr=sc.transform(xtr)\nxts=sc.transform(xts)","5286da26":"from sklearn.linear_model import LogisticRegression\nalg=LogisticRegression()","57f3fa93":"#train the algorithm with the training data\nalg.fit(xtr,ytr)\nyp=alg.predict(xts)","dbb7903d":"from sklearn import metrics\ncm=metrics.confusion_matrix(yts,yp)\nprint(cm)","80b23665":"accuracy=metrics.accuracy_score(yts,yp)\nprint(accuracy)","ebf28441":"precission=metrics.precision_score(yts,yp)\nprint(precission)","07586c4f":"recall=metrics.recall_score(yts,yp)\nprint(recall)","dc66d460":"from sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts=train_test_split(ip,op,test_size=0.1)\n","bbd6f969":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(xtr)\nxtr=sc.transform(xtr)\nxts=sc.transform(xts)","06bcde5b":"from sklearn.naive_bayes import GaussianNB\nGNB=GaussianNB()\nGNB.fit(xtr,ytr)\nyp=GNB.predict(xts)","35e5e783":"from sklearn import metrics\ncm=metrics.confusion_matrix(yts,yp)\nprint(cm)","fe9fa913":"accuracy=metrics.accuracy_score(yts,yp)\nprint(accuracy)","c9c98711":"recall=metrics.recall_score(yts,yp)\nprint(recall)","631db6b9":"from sklearn.neighbors import KNeighborsClassifier\n\nneighbors=np.arange(1,9)\ntrain_accuracy=np.empty(len(neighbors))\ntest_accuracy=np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    knn=KNeighborsClassifier(n_neighbors=k)\n    knn.fit(xtr,ytr)\n    train_accuracy[i]=knn.score(xtr,ytr)\n    test_accuracy[i]=knn.score(xts,yts)\n\nplt.xlabel('neighbors of number')\nplt.ylabel('accuracy')\nplt.title('k-NN Varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label='Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label='Training accuracy')\nplt.legend()\nplt.show()","662af65c":"from sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts=train_test_split(ip,op,test_size=0.1)","44ebb9b0":"\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(xtr)\nxtr=sc.transform(xtr)\nxts=sc.transform(xts)\n","3affeb28":"knn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(xtr,ytr)\nyp=knn.predict(xts)","de688551":"from sklearn import metrics\ncm=metrics.confusion_matrix(yts,yp)\nprint(cm)","d33a2bc9":"accuracy=metrics.accuracy_score(yts,yp)\nprint(accuracy)","9df68811":"recall = metrics.recall_score(yts,yp,average='macro')\nprint(recall)","e00bb3b3":"from sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts=train_test_split(ip,op,test_size=0.3)","b7bed9f1":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(xtr)\nxtr=sc.transform(xtr)\nxts=sc.transform(xts)","6a8466c0":"from sklearn import svm\n\nalg=svm.SVC(C=30,gamma=0.03)\n\n#train the algorithm with training data\nalg.fit(xtr,ytr)\nyp=alg.predict(xts)","c4b5d6ee":"from sklearn import metrics\ncm=metrics.confusion_matrix(yts,yp)\nprint(cm)","8b7d06b3":"from sklearn import metrics\naccuracy=metrics.accuracy_score(yts,yp)\nprint(accuracy)","f058eb4f":"recall = metrics.recall_score(yts,yp)\nprint(recall)","a805bc99":"#spliting training and testing data\nfrom sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts=train_test_split(ip,op,test_size=0.2)","4136f937":"\n#standard scalar transform\n\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(xtr)\nxtr=sc.transform(xtr)\nxts=sc.transform(xts)","97a925d1":"#model training\nfrom sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(criterion='gini')\n","4516bfbc":"# Train Decision Tree Classifer\ndtc=dtc.fit(xtr,ytr)\n","71711ada":"#Predict the response for test dataset\ny_pred=dtc.predict(xts)","bad2b3aa":"from sklearn import metrics\ncm=metrics.confusion_matrix(yts,y_pred)\nprint(cm)","d2027ead":"accuracy=metrics.accuracy_score(yts,y_pred)\nprint(accuracy)","49ce1b1d":"recall=metrics.recall_score(yts,y_pred)\nprint(recall)","16b41488":"# Scalling Our Dataset","37cb9df0":"It is easy and fast to predict class of test data set. It also perform well in multi class prediction","0525f53e":"# Train & Test the Dataset","932978d1":"# K-NEAREST NEIGHBOUR","9543d9c0":"SUPPORT VECTOR MACHINES-SVM","d698328f":"We can see that nearby 500 people ara non daibetic patient and nearby 250 are diabetic patients","d7b8b649":"# DECISSION TREE","95810584":"# Analyzing the dataset","5752c6b9":"Here o-->Not daibetes\n*    1-->Daibetes","e4a824bc":"My understanding Logistic regression is a regression model where the dependent variable is categorical.","0abf648a":"The prediction will be 0 or 1, Yes or No\n* Pima daibetes dataset contain all numerical values","d74d4d38":"Support vector machines (SVMs) are powerful yet flexible supervised machine learning algorithms which are used both for classification and regression","334e5143":"Decision tree is a type of supervised learning algorithm (having a predefined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables","af759674":"After my prediction i found to be the best in acuuracy in SVM with 85% and recall best in naive_bayes with 78%","16c6d0a2":"K-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm which can be used for both classification as well as regression predictive problems","f9b3de4b":"# Description of the dataset","8ec6ad82":"* This dataset has not null value..It is a clean dataset","4f5a3ffc":"# Naive Bayes classifier","a53143a6":"KNN algorithm the nearest distance is calculated  ","41ad3196":"# Logistic Regression","c97f4d4f":"# Checking the Accuacy of our Model","69ca2cf4":"* Pregnancies-Number of times pregnant\n* Glucose-Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* BloodPressure-Diastolic blood pressure\n* SkinThickness-Triceps skin fold thickness (mm)\n* Insulin-2-Hour serum insulin (mu\n* BMI-Body mass index (weight in kg\/(height in m)^2)\n* DiabetesPedigreeFunction-Diabetes pedigree function\n* Age-Age (years)\n* Outcome-Class variable (0 or 1) 268 of 768 are 1, the others are 0"}}