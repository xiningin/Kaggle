{"cell_type":{"4a9e7e1e":"code","63ca402b":"code","eac7fcea":"code","b1b6261b":"code","0b54194a":"code","ed981aa5":"code","24a7c8b9":"code","460732f9":"code","29ddcf91":"code","61d78d14":"code","1de25a1a":"code","7e486302":"code","9e126f5d":"code","ea9d323f":"code","0eec0de5":"code","bd577ee9":"code","f243814d":"code","340a5f22":"code","3be8c704":"code","c3c9f3a4":"code","4d609fbc":"code","754de01c":"code","c7026a1f":"code","b345c4e4":"code","fc3ab56c":"code","42700da2":"code","8605593f":"code","965b5a91":"code","2193fc05":"code","6db89ca5":"code","bb83ab93":"code","44f8a623":"code","1a0873b1":"code","6cf38615":"code","083af782":"code","71de4932":"code","0177d1f3":"code","0863eee7":"code","15f44ac6":"code","25aa1faa":"code","269d5084":"code","d151ed13":"code","5a941335":"markdown","907e4504":"markdown","f7d75877":"markdown","fc421d48":"markdown","6121e476":"markdown","7e0e122d":"markdown","5621888a":"markdown","1b3729a2":"markdown","27b17e6c":"markdown","8c467848":"markdown","5879ad61":"markdown","4e273d63":"markdown","4ae2ad88":"markdown","99d85a86":"markdown","055f3d82":"markdown","fbc324f6":"markdown","cb6bad98":"markdown","5495dc55":"markdown","00cc9946":"markdown","48f2353c":"markdown","59b387c0":"markdown"},"source":{"4a9e7e1e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS","63ca402b":"DIR_INPUT= '\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification'\ntrain_df1 = pd.read_csv(DIR_INPUT + '\/jigsaw-toxic-comment-train.csv')\ntrain_df1.head()","eac7fcea":"print(train_df1.shape)\nprint(train_df1.size)\nprint(train_df1.columns)","b1b6261b":"train_df2 = pd.read_csv(DIR_INPUT + '\/jigsaw-unintended-bias-train.csv')\ntrain_df2.head()","0b54194a":"print(train_df2.shape)\nprint(train_df2.size)\nprint(train_df2.columns)","ed981aa5":"cols_filter = ['id', 'comment_text', 'toxic']\ntrain_df = train_df1[cols_filter].append(train_df2[cols_filter])\ntrain_df.head()","24a7c8b9":"print(train_df.shape)\nprint(train_df.size)\nprint(train_df.columns)","460732f9":"train_df['toxic'].unique","29ddcf91":"train_df['toxic'].values","61d78d14":"train_df['toxic']=train_df['toxic']>0.5","1de25a1a":"train_df.shape","7e486302":"train_df['toxic'].value_counts(normalize=True)","9e126f5d":"sns.barplot(x=['Not-toxic', 'Toxic'], y=train_df.toxic.value_counts())","ea9d323f":"valid_df = pd.read_csv(DIR_INPUT + '\/validation.csv')\nvalid_df.head()","0eec0de5":"per_lang = valid_df['lang'].value_counts()","bd577ee9":"sns.barplot(x=per_lang.index, y=per_lang.values)","f243814d":"valid_df.toxic.value_counts(normalize=True)","340a5f22":"sns.barplot(x=['Not-toxic', 'Toxic'], y=valid_df.toxic.value_counts())","3be8c704":"per_lang = valid_df.groupby(by=['lang', 'toxic']).count()[['id']]\nper_lang","c3c9f3a4":"data=[]\nfor lang in valid_df['lang'].unique():\n      y = per_lang[per_lang.index.get_level_values('lang') == lang].values.flatten()\n      data.append(go.Bar(name=lang, x=['Non-toxic', 'Toxic'], y=y))\nfig = go.Figure(data=data)\nfig.update_layout(\n    title='Language distribution in the validation dataset',\n    barmode='group'\n)\nfig.show()","4d609fbc":"test_df = pd.read_csv(DIR_INPUT + '\/test.csv')\ntest_df.head()","754de01c":"test_df['lang'].value_counts()","c7026a1f":"per_lang = test_df['lang'].value_counts()\nsns.barplot(x=per_lang.index, y=per_lang.values)","b345c4e4":"rnd_comments = train_df[train_df['toxic'] == 0].sample(n=10000)['comment_text'].values\nwc = WordCloud(background_color=\"black\", max_words=2000, stopwords=STOPWORDS.update(['Trump', 'people', 'one', 'will']))\nwc.generate(\" \".join(rnd_comments))\n\nplt.figure(figsize=(20,10))\nplt.axis(\"off\")\nplt.title(\"Frequent words in non-toxic comments\", fontsize=20)\nplt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\nplt.show()","fc3ab56c":"rnd_comments = train_df[train_df['toxic'] == 1].sample(n=10000)['comment_text'].values\nwc = WordCloud(background_color=\"black\", max_words=2000, stopwords=STOPWORDS.update(['Trump', 'people', 'one', 'will']))\nwc.generate(\" \".join(rnd_comments))\n\nplt.figure(figsize=(20,10))\nplt.axis(\"off\")\nplt.title(\"Frequent words in toxic comments\", fontsize=20)\nplt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\nplt.show()\n","42700da2":"train_df.groupby('toxic').describe()","8605593f":"import sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nimport nltk \nimport string \nfrom nltk.corpus import stopwords","965b5a91":"stopwords_set= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"])","2193fc05":"x = stopwords.words(\"english\")\nstopwords_nltk_en = set(x)\nstopwords_nltk_en","6db89ca5":"stoplist_combined = set.union(stopwords_set, stopwords_nltk_en)","bb83ab93":"import re\nfrom tqdm import tqdm\nfrom bs4 import BeautifulSoup\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","44f8a623":"def cleanup_text(msg):\n    No_Punctuation = [char for char in msg if char not in string.punctuation]\n    sentance = ''.join(No_Punctuation) #joins all the strings\n    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n    sentance = decontracted(sentance)\n    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n    return [word.lower() for word in sentance.split() if word.lower() not in stoplist_combined]","1a0873b1":"#train_df['imp_words']= train_df['comment_text'].apply(cleanup_text)\n#test_df['imp_words']=test_df['content'].apply(cleanup_text)\n#valid_df['imp_words']=valid_df['comment_text'].apply(cleanup_text)","6cf38615":"test_df = pd.read_csv(DIR_INPUT + '\/test.csv')\ntest_df.head()","083af782":"train = train_df\ntest = test_df\n\n# remove '\\\\n'\ntrain['comment_text'] = train['comment_text'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n    \n# remove any text starting with User... \ntrain['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n    \n# remove IP addresses or user IDs\ntrain['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n    \n#remove http links in the text\ntrain['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"(http:\/\/.*?\\s)|(http:\/\/.*)\",'',str(x)))\n\n\n# test set\n# remove '\\\\n'\ntest['content'] = test['content'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n    \n# remove any text starting with User... \ntest['content'] = test['content'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n    \n# remove IP addresses or user IDs\ntest['content'] = test['content'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n    \n#remove http links in the text\ntest['content'] = test['content'].map(lambda x: re.sub(\"(http:\/\/.*?\\s)|(http:\/\/.*)\",'',str(x)))\n\n","71de4932":"valid=valid_df\n# remove '\\\\n'\nvalid['comment_text'] = valid['comment_text'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n    \n# remove any text starting with User... \nvalid['comment_text'] = valid['comment_text'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n    \n# remove IP addresses or user IDs\nvalid['comment_text'] = valid['comment_text'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n    \n#remove http links in the text\nvalid['comment_text'] = valid['comment_text'].map(lambda x: re.sub(\"(http:\/\/.*?\\s)|(http:\/\/.*)\",'',str(x)))\n","0177d1f3":"X_train=train.drop('toxic',axis=1)\nY_train=train['toxic']\nX_valid=valid.drop('toxic',axis=1)\nY_valid=valid['toxic']","0863eee7":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\nY_train = encoder.fit_transform(Y_train)\nY_valid  = encoder.fit_transform(Y_valid)","15f44ac6":"Y_train","25aa1faa":"Y_valid","269d5084":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vect = TfidfVectorizer(analyzer='word',  token_pattern=r'\\w{2,}', max_features=5000)","d151ed13":"tfidf_fit_tra = tfidf_vect.fit_transform(X_train).toarray()     # Fit-transform of Train data\ntfidf_fit_tra","5a941335":"From validation data the frequency of the lang is in that way as above visuaization","907e4504":"# Introduction","f7d75877":"From this visualization we must understand that Toxic comments are very less compared to NOn-toxic comments","fc421d48":"From the above word Cloud , we can see the words displayed with more frequency. These are the words found frequently in Toxic Comments. ","6121e476":"Upsampling is a technique which multiplies the Toxic comments eual to Non-toxic comments. So in this way our model bias will be reduced.","7e0e122d":"This table explains that the number of toxic and non-toxic comments for each and every lang","5621888a":"You can also do this, but it takes lot of time ,so i found alternative way which cleans the content faster. \nBut the above method cleans the text very nicely","1b3729a2":"# **Using TF-IDF to convert text to vector**","27b17e6c":"Lets clean the comments by removing stopwords,punctuations,alpha numeric words","8c467848":"# NOW START BUILDING THE MODEL","5879ad61":"# Exploratory Data Analysis","4e273d63":"**Importing all The necessary Libraries for performing EDA**","4ae2ad88":"This makes our model more bias to Non-toxic Comments. So inorder to reduce this bias we have to perform Upsampling.","99d85a86":"I will update the model of having high accuracy soon, stay tuned\nPlease upvote if you like it and keep me motivated ","055f3d82":"Cleaning up the text","fbc324f6":"![image.png](attachment:image.png)","cb6bad98":"It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by Jigsaw and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet.\n\nIn the previous 2018 Toxic Comment Classification Challenge, Kagglers built multi-headed models to recognize toxicity and several subtypes of toxicity. In 2019, in the Unintended Bias in Toxicity Classification Challenge, you worked to build toxicity models that operate fairly across a diverse range of conversations. This year, we're taking advantage of Kaggle's new TPU support and challenging you to build multilingual models with English-only training data.\n\nJigsaw's API, Perspective, serves toxicity models and others in a growing set of languages (see our documentation for the full list). Over the past year, the field has seen impressive multilingual capabilities from the latest model innovations, including few- and zero-shot learning. We're excited to learn whether these results \"translate\" (pun intended!) to toxicity classification. Your training data will be the English data provided for our previous two competitions and your test data will be Wikipedia talk page comments in several different languages.\n\nAs our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe. Develop strategies to build effective multilingual models and you'll help Conversation AI and the entire industry realize that potential.\n\nDisclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.","5495dc55":"# TEXT PROCESSING- **Cleaning the text**","00cc9946":"From the above word Cloud , we can see the words displayed with more frequency. These are the words found frequently in Non-toxic Comments. ","48f2353c":"**Reading the file**","59b387c0":"Import all the necessary libraries for performing text processing"}}