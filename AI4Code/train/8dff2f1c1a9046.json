{"cell_type":{"48248016":"code","c11ee668":"code","c7e36463":"code","a850c7eb":"code","2ad5ef01":"code","e9dea501":"code","3da1f897":"code","238fa04b":"code","60dbe895":"code","1da9dc7a":"code","6330dd8e":"code","5076e3be":"code","f7b00308":"code","da609402":"code","6be769b1":"code","81c5e7b5":"code","81b208b8":"markdown","bac7855e":"markdown","c42880ab":"markdown","1fbec61b":"markdown","e1db8a3d":"markdown","d646a0de":"markdown"},"source":{"48248016":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom scipy.spatial import distance\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c11ee668":"train = pd.read_csv('\/kaggle\/input\/bigquery-geotab-intersection-congestion\/train.csv')","c7e36463":"train.columns","a850c7eb":"groups = train.groupby(['City','Month','Hour','Weekend','Latitude','Longitude'])[['DistanceToFirstStop_p80','TotalTimeStopped_p80']].mean().reset_index()\ngroups.head()","2ad5ef01":"#modified slightly\ndef add_distance(df,p):\n    \n    df_center = pd.DataFrame({\"Atlanta\":[33.753746, -84.386330],\n                             \"Boston\":[42.361145, -71.057083],\n                             \"Chicago\":[41.881832, -87.623177],\n                             \"Philadelphia\":[39.952583, -75.165222]})\n    \n    df[f'Minkowski_{p}'] = df.apply(lambda row: distance.minkowski\n                                   (np.column_stack((row.Latitude,row.Longitude)) ,df_center[row.City].values,p), axis=1)\n    \n    \n    ","e9dea501":"p = np.linspace(1,10,10).astype(int)\n\nfor i in p:\n    add_distance(groups,i)","3da1f897":"groups.head()","238fa04b":"types=['DistanceToFirstStop_p80','TotalTimeStopped_p80']\n\ndef box_cox(value,nlambda):\n    bc_value = ((value**nlambda)-1)\/nlambda\n    return bc_value\n\ndef distplot(df,types=None,degree=None,nlambda=None):\n    fig = plt.figure(figsize=(20,3))\n    city_list = df.City.unique()\n    if nlambda==None:\n        nlambda = 1\n    for i in range(len(city_list)):\n        plt.subplot(1, 4, i+1)\n        total_values = df[types]\n        values = df.loc[df.City == city_list[i]][types]\n        bc_value = box_cox(values,nlambda)\n        bc_value_t = box_cox(total_values,nlambda)\n        ax=sns.distplot(bc_value,kde=False)\n        ax.set_xlim(min(bc_value_t),max(bc_value_t))\n        ax.set_ylim(0,4*10**4)\n        ax.set_title(city_list[i])\n        ax.set_xlabel(types+' (box_cox\/\/ '+ 'lambda= ' + str(nlambda)+')')\n        if i ==0:\n\n            ax.set_ylabel('count')\n\n    plt.show()","60dbe895":"groups.groupby(['City']).count()","1da9dc7a":"distplot(groups,types[0],nlambda = 0.15)\ndistplot(groups,types[1],nlambda = 0.3)","6330dd8e":"dist_index = [c for c in groups.columns if c not in train.columns]\n\ndef quantile_cut(df,dist,num):\n    \n    cities = df.City.unique()\n    \n    for city in cities:\n        \n        df.loc[df.City==city,dist+'_cat']=pd.qcut(df.loc[df.City==city][dist], q=num,labels=[1,2,3])\n        \n    return df\n\nfor dist in dist_index:\n    \n    groups = quantile_cut(groups,dist,3)\n    ","5076e3be":"#Check it is splited equally\ngroups.Minkowski_1_cat.value_counts()","f7b00308":"check1 = ['DistanceToFirstStop_p80','TotalTimeStopped_p80']\ncheck2 = check2 = ['Hour','Month','Weekend']\ncheck3 = [c for c in groups.columns if c not in train.columns]\ncheck3 = check3[-10:]\ndef Plot(datasets,check1,check2,check3):\n    \n    count = datasets['City'].nunique()\n    list = datasets['City'].unique()\n    fig,ax =plt.subplots(1,4)\n    fig.set_size_inches(15, 3)\n    for i in range(count):\n        dataset = datasets.loc[datasets['City']==list[i]]\n        \n        if check2 =='Weekend':\n            dataset.groupby([check2,check3])[check1].mean().unstack().plot(ax=ax[i],kind='bar')\n        else:\n            dataset.groupby([check2,check3])[check1].mean().unstack().plot(ax=ax[i])\n        if i==0:\n            ax[i].set_ylabel(check1)\n        if check2 == 'Month':\n            ax[i].set(xlim=(6, 12))\n        ax[i].set_title(list[i])\n        \n    plt.show()\n\nfor i in check3:\n    \n    Plot(groups,check1[0],check2[0],i)","da609402":"for i in check3:\n    Plot(groups,check1[1],check2[1],i)","6be769b1":"types1 = ['DistanceToFirstStop_p80','TotalTimeStopped_p80']\ntypes2 = [c for c in groups.columns if c not in train.columns]\ntypes2 = types2[-10:]\ndef distplot2(df,city,types1,types2):\n    print(city, types1)\n    j = 0\n    fig = plt.figure(figsize=(50,10))\n    for type2 in types2:\n        dataset = df.loc[df.City==city]\n        list = dataset[type2].unique()\n        count = dataset[type2].nunique()\n        for i in range(count):\n            plt.subplot(2, 5, j+1)\n            values = box_cox(dataset[types1].loc[dataset[type2]==i+1],0.15)\n            ax=sns.distplot(values,kde=False)\n        j = j+1\n    plt.show()","81c5e7b5":"distplot2(groups,'Philadelphia',types1[1],types2)\ndistplot2(groups,'chicago',types1[1],types2)\ndistplot2(groups,'Boston',types1[1],types2)\ndistplot2(groups,'Atlanta',types1[1],types2)\n\ndistplot2(groups,'Philadelphia',types1[0],types2)\ndistplot2(groups,'chicago',types1[0],types2)\ndistplot2(groups,'Boston',types1[0],types2)\ndistplot2(groups,'Atlanta',types1[0],types2)","81b208b8":"What about distributions?","bac7855e":"I slightly modified $x$ values using box_cox transformation. With proper parameter lambda, distribution could be shaped like normal distribution.\n\n$$x_\\lambda = \\frac{x^\\lambda-1}{\\lambda}$$, where $x_\\lambda$ is the value after transfroming","c42880ab":"To simplify, I categorized calculated Minkowski distance into 3 different categories","1fbec61b":"Seemingly, Different types of Minkowski distance are not significantly different each other. XD...","e1db8a3d":"Euclidean distance could be thought of as the one kind of Minkowski distance, and General formula of Minkowski distance is expressed as\n$$\\sum_{i=1}^{n} (|x_i-y_i|^p)^\\frac{1}{p}$$, where $n$ is sample size.\nSo when $n = 1$, it is taxicab or manhattan distance, and when $p = 2$, it is euclidean distance. As degree increases, its shape goes like squared. I tested ten different Minkowski distances ranging from 1 to 10.","d646a0de":"Some people seem to use center_distance for the one of features for the prediction using xgboost, lightGBM or something else, and usually They use euclidean distance I guess. For precision, I checked that if there are better metric distances to use instead of euclidean distance.\n\nBefore that I grouped the train dataset by city x month x hour x weekend x logitude x latitude with respect to the target variables."}}