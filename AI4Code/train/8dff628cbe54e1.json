{"cell_type":{"084a71ef":"code","749578e9":"code","967d9377":"code","a74c9f3f":"code","f8048eb8":"code","2e591bfc":"code","e50a0a01":"code","abc30b60":"code","de650209":"code","d2ee1d4e":"markdown","89d19255":"markdown","2a90e8e7":"markdown","b656f89c":"markdown"},"source":{"084a71ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","749578e9":"data = pd.read_csv(\"..\/input\/train.csv\")","967d9377":"#Lets have a look into the matadata \ndata.info()","a74c9f3f":"data.describe()","f8048eb8":"#Lets have a look into some sample data\ndata.head()","2e591bfc":"#Provide features for X and label for y\nX = data.drop('diabetes',axis=1)\ny = data['diabetes']\n# Split the data into traing and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n                                    X, y, random_state=42, test_size=.33)\n#Initialize Random Forest Classifier\nrfc = RandomForestClassifier()\n#Fit model on the training Data\nrfc.fit(X_train,y_train)\n#Make prediction\npredictions = rfc.predict(X_test)","e50a0a01":"#Generate Confusion Matrix\nconf_matrix = confusion_matrix(predictions,y_test)\nprint(conf_matrix)","abc30b60":"#Lets calculate Precision, Recall and F1 score for label 0 and 1\n#For Label 0\ntp = conf_matrix[0,0]\nfp = conf_matrix[1,0]\nfn = conf_matrix[0,1]\n\nprecision  = tp \/ (tp + fp)\nrecall     = tp \/ (tp + fn)\nf1_score   = 2*( precision * recall)\/(precision + recall)\n\nprint('precision, recall and f1-score for label 0')\nprint('The precision for label 0 is: {0:.2f}'.format(precision))\nprint('The recall for label 0 is: {0:.2f}'.format(recall))\nprint('The f1-score for label 0 is: {0:.2f}'.format(f1_score))\nprint('\\n')\n\n#For Label 1 \n\ntp = conf_matrix[1,1]\nfp = conf_matrix[0,1]\nfn = conf_matrix[1,0]\n\nprecision  = tp \/ (tp + fp)\nrecall     = tp \/ (tp + fn)\nf1_score   = 2*( precision * recall)\/(precision + recall)\n\nprint('precision, recall and f1-score for label 1')\nprint('The precision for label 1 is: {0:.2f}'.format(precision))\nprint('The recall for label 1 is: {0:.2f}'.format(recall))\nprint('The f1-score for label 1 is: {0:.2f}'.format(f1_score))\n","de650209":"print(classification_report(predictions,y_test))","d2ee1d4e":"We can Validate our calculation by comparing it with sklearn Metrics classification_report.","89d19255":"Precision, Recall and F1-Score can be calculated as fellow:\n* Precision  = TP \/ (TP + FP)\n* Recall       = TP \/ (TP + FN)\n* F1-Score  = 2 ( Precision * Recall)\/(Precision + Recall)\n","2a90e8e7":"![](https:\/\/cdncontribute.geeksforgeeks.org\/wp-content\/uploads\/Confusion_Matrix1_1.png)\n\nWe can visualize the confusion matrix that is generated for our model's prediction as below: \n\n           0       1\n    0     117     34\n    1     14      38\n    \n   Here in this matrix we have:\n   \n   For 0:\n   True Positive(TP)     = 117,\n   False Positive(FP)    = 14,\n   False Negative(FN)  = 34\n   \n   For 1:\n   True Positive(TP) = 38,\n   False Positive(FP) = 34,\n   False Negative(FN) = 14","b656f89c":"**Confusion Matrix**\n\nConfusion matrix is an important tool to evaluate our classifier performance. It provides us a clear picture of the performance of our classifier. It creates a matrix where we can find the frequency of hits and misses of each labels.\nTo compute the confusion matrix, you need to have a set of predictions, so they can be compared to actual targets.\n\nConfusion matrix can be used to compute following parameters:\n* Precission\n* Recall\n* F1-Score\n\nNote: This kernel intend to help newbies to understand confusion metrics and make sense of Precision, Recall and F1 Score.\n\n**For demonstrating the confusion matrix we will make use of the Diabetes Classification dataset and will perform following steps.**\n* Split the data set into training and test sets.\n* Train the model using RandomForestClassifier.\n* Predict on the test set.\n* Generate confusion Matrix using sklearns confusion_matrix.\n*  Calculate Precision, Recall and F1-Score"}}