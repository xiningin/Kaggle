{"cell_type":{"6125d2f5":"code","99b299a2":"code","3f15b8f4":"code","a83a9c9e":"code","b6a76257":"code","4011c7d7":"code","571e237c":"code","f5521232":"code","661a4af9":"code","ed1a358a":"code","363687b0":"code","82935815":"code","10987f8f":"code","c4cf8d02":"code","da6035eb":"code","6fcded4e":"code","5c1c60b6":"code","52d1afcf":"code","735d97a0":"code","0818813e":"code","6d06a8d4":"code","0a4d5906":"code","f584e9f7":"code","90b15947":"code","0bbd6c39":"code","9ca73dc7":"code","7e0aa4f9":"code","d9c11b47":"code","51cbc32e":"code","5f3b0682":"code","b7bb4e3f":"code","af9f3a20":"code","a618df6e":"code","84faa0f4":"code","57d58962":"code","2d9dbf4d":"code","cbe86215":"code","534a1c97":"code","ce5ce00b":"code","7809b20f":"code","2b0a7b77":"code","101c6cdf":"code","f61e5b97":"code","4e69eed6":"code","1b3102b7":"code","d6293c5f":"markdown","7a58c758":"markdown","f853302f":"markdown","0c10d77c":"markdown","8da59002":"markdown","69211604":"markdown"},"source":{"6125d2f5":"!pip install ..\/input\/sacremoses\/sacremoses-master\/ > \/dev\/null\n\nimport os\nimport sys\nimport glob\n\nimport torch\n\nsys.path.insert(0, \"..\/input\/transformers\/transformers-master\/\")\nimport transformers\nfrom transformers import *","99b299a2":"import sys\npackage_dir_a = \"..\/input\/ppbert\/pytorch-pretrained-bert\/pytorch-pretrained-BERT\"\nsys.path.insert(0, package_dir_a)\n\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch","3f15b8f4":"\nfrom transformers import *\nimport shutil\n# Translate model from tensorflow to pytorch\nWORK_DIR = \"..\/working\/\"\nBERT_MODEL_PATH ='..\/input\/bert-roberta\/'\n# BERT_MODEL_PATH ='..\/input\/roberta-large\/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n    BERT_MODEL_PATH + 'bert_model.ckpt',\nBERT_MODEL_PATH + 'bert_config.json',\nWORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'config.json')\n\nprint('yes')","a83a9c9e":"# from transformers import *\n# import shutil\n# # Translate model from tensorflow to pytorch\n# WORK_DIR = \"..\/working\/\"\n# # BERT_MODEL_PATH = '..\/input\/bert-pretrained-models\/chinese_L-12_H-768_A-12\/chinese_L-12_H-768_A-12\/'\n# BERT_MODEL_PATH ='..\/input\/roberta-large\/'\n# convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n#     BERT_MODEL_PATH + 'roberta_zh_large_model.ckpt',\n# BERT_MODEL_PATH + 'bert_config_large.json',\n# WORK_DIR + 'pytorch_model.bin')\n\n# shutil.copyfile(BERT_MODEL_PATH + 'bert_config_large.json', WORK_DIR + 'config.json')\n\n# print('yes')","b6a76257":"import pandas as pd\nimport numpy as np\nimport json\nimport random\nimport copy\nimport re\nfrom tqdm import tqdm\nimport collections\nfrom random import shuffle\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntqdm.pandas()\n\n#import torch.utils.data as data\nfrom torchvision import datasets, models, transforms\nfrom transformers import *\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import f1_score\nimport random\n\n!pip install pytorch-crf","4011c7d7":"class Do_data():\n    def __init__(self,doc_id,content,enents,key_word=None,content_split_off=0,or_content=None):\n        self.doc_id=doc_id\n        self.content=content\n        self.enents=enents\n        self.key_word=key_word\n        self.content_split_off=content_split_off\n        self.or_content=or_content\n    def __str__(self):\n        return self.__repr__()\n    def __repr__(self):\n        s = \"\"\n        s += \"doc_id: %s\\n\" % (str(self.doc_id))\n        s += \"content: %s\\n\" % (str(self.content))\n        s += \"enents: %s\\n\" % (str(self.enents))\n        s += \"key_word: %s\\n\" % (str(self.key_word))\n        s += \"content_split_off: %s\\n\" % (str(self.content_split_off))\n        s += \"or_content: %s\\n\" % (str(self.or_content))\n        return s\n\n\ndef get_shama(path):\n    shama=collections.defaultdict(list)\n    with open(path) as f:\n        for l in f:\n            l = json.loads(l)\n            event_list=[] #\u4e8b\u4ef6\u96c6\u5408\n            content=l['content']\n            docid=l['doc_id']\n            enents=[]\n            for event in l['events']:\n                typ=event['event_type']\n                v=list(event.keys())\n                v.remove('event_type')\n                v.remove('event_id')\n                shama[typ].extend(v)\n                shama[typ]=list(set(shama[typ]))\n    return shama\n\ndef load_data(path,is_test=False):\n    with open(path) as f:\n        D=[]\n        for l in f:\n            l = json.loads(l)\n            event_list=[] #\u4e8b\u4ef6\u96c6\u5408\n            content=l['content']\n            docid=l['doc_id']\n            enents=[]\n            if not is_test:\n                for event in l['events']:\n                    event_dict={}\n                    roles=shama[event['event_type']]\n                    for role in roles:\n                        if role in event:\n                            event_dict[role]=event[role]\n                    enents.append([event['event_type'],event_dict])\n            data=Do_data(docid,content,enents)\n#             print(data)\n            D.append(data)\n    return D\ndata_path='..\/input\/ccks42\/'\nshama=get_shama(data_path+'event_element_train_data_label.txt')\ntrain_data=load_data(data_path+'event_element_train_data_label.txt')\ntest_data=load_data(data_path+'event_element_dev_data.txt',is_test=True)\nprint(len(train_data))\nprint(len(test_data))\n\ns={}\nfor t in train_data:\n    if t.enents[0][0] not in s:\n        s[t.enents[0][0]]=0\n    s[t.enents[0][0]]+=1\n#     if t.enents[0][0] in ['\u80a1\u4e1c\u51cf\u6301', '\u80a1\u4e1c\u589e\u6301', '\u80a1\u6743\u51bb\u7ed3', '\u80a1\u6743\u8d28\u62bc']:\n#         train_data.remove(t)\nprint(s)\nprint(len(train_data))\nprint(len(test_data))","571e237c":"shama= {'\u7834\u4ea7\u6e05\u7b97': ['\u516c\u544a\u65f6\u95f4', '\u516c\u53f8\u540d\u79f0', '\u53d7\u7406\u6cd5\u9662', '\u88c1\u5b9a\u65f6\u95f4', '\u516c\u53f8\u884c\u4e1a'],\n             '\u91cd\u5927\u5b89\u5168\u4e8b\u6545': ['\u516c\u544a\u65f6\u95f4', '\u5176\u4ed6\u5f71\u54cd', '\u635f\u5931\u91d1\u989d', '\u516c\u53f8\u540d\u79f0', '\u4f24\u4ea1\u4eba\u6570'],\n             '\u80a1\u4e1c\u51cf\u6301': ['\u51cf\u6301\u7684\u80a1\u4e1c', '\u51cf\u6301\u91d1\u989d', '\u51cf\u6301\u5f00\u59cb\u65e5\u671f'],\n             '\u80a1\u6743\u8d28\u62bc': ['\u8d28\u62bc\u7ed3\u675f\u65e5\u671f', '\u8d28\u62bc\u91d1\u989d', '\u8d28\u62bc\u65b9', '\u63a5\u6536\u65b9', '\u8d28\u62bc\u5f00\u59cb\u65e5\u671f'],\n             '\u80a1\u4e1c\u589e\u6301': ['\u589e\u6301\u91d1\u989d', '\u589e\u6301\u5f00\u59cb\u65e5\u671f', '\u589e\u6301\u7684\u80a1\u4e1c'],\n             '\u80a1\u6743\u51bb\u7ed3': ['\u51bb\u7ed3\u91d1\u989d', '\u88ab\u51bb\u7ed3\u80a1\u4e1c', '\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f', '\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f'],\n             '\u9ad8\u5c42\u6b7b\u4ea1': ['\u9ad8\u5c42\u804c\u52a1', '\u516c\u53f8\u540d\u79f0', '\u6b7b\u4ea1\u5e74\u9f84', '\u6b7b\u4ea1\/\u5931\u8054\u65f6\u95f4', '\u9ad8\u5c42\u4eba\u5458'],\n             '\u91cd\u5927\u8d44\u4ea7\u635f\u5931': ['\u5176\u4ed6\u635f\u5931', '\u635f\u5931\u91d1\u989d', '\u516c\u544a\u65f6\u95f4', '\u516c\u53f8\u540d\u79f0'],\n             '\u91cd\u5927\u5bf9\u5916\u8d54\u4ed8': ['\u8d54\u4ed8\u5bf9\u8c61', '\u516c\u544a\u65f6\u95f4', '\u516c\u53f8\u540d\u79f0', '\u8d54\u4ed8\u91d1\u989d']}","f5521232":"new_train_data=[]\nn=0\nfor t in train_data:\n    if t.enents[0][0] in ['\u80a1\u4e1c\u51cf\u6301', '\u80a1\u4e1c\u589e\u6301', '\u80a1\u6743\u51bb\u7ed3', '\u80a1\u6743\u8d28\u62bc']:\n        new_train_data.append(t)\n        n+=1\n    else:\n        pass\ntrain_data=new_train_data\nlen(train_data)","661a4af9":"#####\ntrigger_entype={}\ntrigger_entype['\u589e\u6301\u91d1\u989d']='\u80a1\u4e1c\u589e\u6301'\ntrigger_entype['\u51cf\u6301\u91d1\u989d']='\u80a1\u4e1c\u51cf\u6301'\ntrigger_entype['\u51bb\u7ed3\u91d1\u989d']='\u80a1\u6743\u51bb\u7ed3'\ntrigger_entype['\u8d28\u62bc\u91d1\u989d']='\u80a1\u6743\u8d28\u62bc'\nentype_trigger={}\nfor k,v in trigger_entype.items():\n    entype_trigger[v]=k\nentype_trigger","ed1a358a":"#\u80a1\u6743\u51cf\u6301\ndef get_typ1_enent(role_argument,argument_positions,content):\n    trigger_role='\u51cf\u6301\u91d1\u989d'\n    role_argument_position={}\n    trigger_position=None\n    #\u91d1\u989d\u53ea\u6709\u4e00\u4e2a\n    if len(argument_positions['\u51cf\u6301\u91d1\u989d'])==1:\n            trigger_position=argument_positions['\u51cf\u6301\u91d1\u989d'][0]\n    #\u6709\u591a\u4e2a\u91d1\u989d\n    else:\n            m=999999\n            #\u6ca1\u6709\u65e5\u671f\n            if '\u51cf\u6301\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                trigger_position=min(argument_positions['\u51cf\u6301\u91d1\u989d'])\n            #\u9009\u62e9\u91d1\u989d\u65e5\u671f\u5dee\u8ddd\u6700\u5c0f\u7684trigger\n            else:\n                #\u7528\u516c\u544a\u6765\u5f53\u65e5\u671f\uff0c\u91d1\u989d\u9009\u62e9\u6700\u5c0f\u7684\u5730\u65b9\n                if len(argument_positions['\u51cf\u6301\u5f00\u59cb\u65e5\u671f'])==1 and argument_positions['\u51cf\u6301\u5f00\u59cb\u65e5\u671f'][0]>len(content)-50:\n                    trigger_position=min(argument_positions['\u51cf\u6301\u91d1\u989d'])\n                else:\n                    for i in argument_positions['\u51cf\u6301\u91d1\u989d']:\n                        for j in argument_positions['\u51cf\u6301\u5f00\u59cb\u65e5\u671f']:\n                            gap=abs(i-j)\n                            if gap<m:\n                                trigger_position=i\n                                m=gap\n    role_argument_position[trigger_role]=(role_argument[trigger_role],trigger_position) #trigger\u6392\u5728\u9996\u4f4d\n    for role,argu_positions in argument_positions.items():\n        if role==trigger_role:\n            continue\n        argument=role_argument[role]\n        assert len(argument)>0\n        argu_position=None\n        gap=9999999\n        for temp in argu_positions:\n            if abs(trigger_position-temp)<gap:\n                argu_position=temp\n                gap=abs(trigger_position-temp)\n        role_argument_position[role]=(argument,argu_position)\n    \n    #\u5982\u679c\u91d1\u989d\u548c\u51cf\u6301\u80a1\u4e1c\u76f8\u5dee\u8fc7\u5927\uff0c\u76f4\u63a5\u9009\u62e9\u80a1\u4e1c\u4e3a\u6700\u5c0f\u7684\u90a3\u4e00\u4e2aindex\n    if '\u51cf\u6301\u7684\u80a1\u4e1c' in role_argument_position and abs(role_argument_position['\u51cf\u6301\u7684\u80a1\u4e1c'][1]-trigger_position)>400:\n        role_argument_position['\u51cf\u6301\u7684\u80a1\u4e1c']=(role_argument_position['\u51cf\u6301\u7684\u80a1\u4e1c'][0],min(argument_positions['\u51cf\u6301\u7684\u80a1\u4e1c']))\n#     print(role_argument)\n#     print(argument_positions)\n#     print(role_argument_position)\n#     print('*'*50)\n    return role_argument_position,[trigger_role,role_argument[trigger_role],trigger_position]\n    \n    \n#\u80a1\u6743\u589e\u6301\ndef get_typ2_enent(role_argument,argument_positions):\n    trigger_role='\u589e\u6301\u91d1\u989d'\n    role_argument_position={}\n    trigger_position=None\n    #\u91d1\u989d\u53ea\u6709\u4e00\u4e2a\n    if len(argument_positions['\u589e\u6301\u91d1\u989d'])==1:\n            trigger_position=argument_positions['\u589e\u6301\u91d1\u989d'][0]\n    #\u6709\u591a\u4e2a\u91d1\u989d\n    else:\n            m=999999\n            #\u6ca1\u6709\u65e5\u671f\n            if '\u589e\u6301\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                trigger_position=min(argument_positions['\u589e\u6301\u91d1\u989d'])\n            #\u9009\u62e9\u91d1\u989d\u65e5\u671f\u5dee\u8ddd\u6700\u5c0f\u7684trigger\n            else:\n                #\u7528\u516c\u544a\u6765\u5f53\u65e5\u671f\uff0c\u91d1\u989d\u9009\u62e9\u6700\u5c0f\u7684\u5730\u65b9\n                if len(argument_positions['\u589e\u6301\u5f00\u59cb\u65e5\u671f'])==1 and argument_positions['\u589e\u6301\u5f00\u59cb\u65e5\u671f'][0]>len(content)-50:\n                    trigger_position=min(argument_positions['\u589e\u6301\u91d1\u989d'])\n                else:\n                    for i in argument_positions['\u589e\u6301\u91d1\u989d']:\n                        for j in argument_positions['\u589e\u6301\u5f00\u59cb\u65e5\u671f']:\n                            gap=abs(i-j)\n                            if gap<m:\n                                trigger_position=i\n                                m=gap\n    role_argument_position[trigger_role]=(role_argument[trigger_role],trigger_position) #trigger\u6392\u5728\u9996\u4f4d\n    for role,argu_positions in argument_positions.items():\n        if role==trigger_role:\n            continue\n        argument=role_argument[role]\n        assert len(argument)>0\n        argu_position=None\n        gap=9999999\n        for temp in argu_positions:\n            if abs(trigger_position-temp)<gap:\n                argu_position=temp\n                gap=abs(trigger_position-temp)\n        role_argument_position[role]=(argument,argu_position)\n    if '\u589e\u6301\u7684\u80a1\u4e1c' in role_argument_position and abs(role_argument_position['\u589e\u6301\u7684\u80a1\u4e1c'][1]-trigger_position)>400:\n        role_argument_position['\u589e\u6301\u7684\u80a1\u4e1c']=(role_argument_position['\u589e\u6301\u7684\u80a1\u4e1c'][0],min(argument_positions['\u589e\u6301\u7684\u80a1\u4e1c']))\n#     print(role_argument)\n#     print(argument_positions)\n#     print(role_argument_position)\n#     print('*'*50)\n    return role_argument_position,[trigger_role,role_argument[trigger_role],trigger_position]\n    \n\n#\u80a1\u6743\u51bb\u7ed3\ndef get_typ3_enent(role_argument,argument_positions):\n    trigger_role='\u51bb\u7ed3\u91d1\u989d'\n    role_argument_position={}\n    trigger_position=None\n    #\u91d1\u989d\u53ea\u6709\u4e00\u4e2a\n    if len(argument_positions['\u51bb\u7ed3\u91d1\u989d'])==1:\n            trigger_position=argument_positions['\u51bb\u7ed3\u91d1\u989d'][0]\n    #\u6709\u591a\u4e2a\u91d1\u989d\n    else:\n            m=999999\n            #\u6ca1\u6709\u65e5\u671f\n            if '\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                trigger_position=min(argument_positions['\u51bb\u7ed3\u91d1\u989d'])\n            #\u9009\u62e9\u91d1\u989d\u65e5\u671f\u5dee\u8ddd\u6700\u5c0f\u7684trigger\n            else:\n                #\u7528\u516c\u544a\u6765\u5f53\u65e5\u671f\uff0c\u91d1\u989d\u9009\u62e9\u6700\u5c0f\u7684\u5730\u65b9\n                if len(argument_positions['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f'])==1 and argument_positions['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f'][0]>len(content)-50:\n                    trigger_position=min(argument_positions['\u51bb\u7ed3\u91d1\u989d'])\n                for i in argument_positions['\u51bb\u7ed3\u91d1\u989d']:\n                    for j in argument_positions['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f']:\n                        gap=abs(i-j)\n                        if gap<m:\n                            trigger_position=i\n                            m=gap\n    role_argument_position[trigger_role]=(role_argument[trigger_role],trigger_position) #trigger\u6392\u5728\u9996\u4f4d\n    for role,argu_positions in argument_positions.items():\n        if role==trigger_role:\n            continue\n        argument=role_argument[role]\n        assert len(argument)>0\n        argu_position=None\n        gap=9999999\n        for temp in argu_positions:\n            if abs(trigger_position-temp)<gap:\n                argu_position=temp\n                gap=abs(trigger_position-temp)\n        role_argument_position[role]=(argument,argu_position)\n    #\u7ed3\u675f\u65e5\u671f\u4e00\u5b9a\u6839\u636e\u5f00\u59cb\u65e5\u671f\u5206\u914d\n    if '\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f' in argument_positions and '\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f' in argument_positions:\n        gap=9999999\n        begin_position=role_argument_position['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f'][1]\n        argument=role_argument['\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f']\n        argu_position=None\n        for temp in argument_positions['\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f']:\n            if abs(begin_position-temp)<gap:\n                argu_position=temp\n                gap=abs(begin_position-temp)\n        role_argument_position['\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f']=(argument,argu_position)\n    if '\u51bb\u7ed3\u7684\u80a1\u4e1c' in role_argument_position and abs(role_argument_position['\u51bb\u7ed3\u7684\u80a1\u4e1c'][1]-trigger_position)>400:\n        role_argument_position['\u51bb\u7ed3\u7684\u80a1\u4e1c']=(role_argument_position['\u51bb\u7ed3\u7684\u80a1\u4e1c'][0],min(argument_positions['\u51bb\u7ed3\u7684\u80a1\u4e1c']))\n#         assert role_argument_position['\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f'][1]>=role_argument_position['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f'][1]\n#     print(role_argument)\n#     print(argument_positions)\n#     print(role_argument_position)\n#     print('*'*50)\n    return role_argument_position,[trigger_role,role_argument[trigger_role],trigger_position]\n    \n#\u80a1\u6743\u8d28\u62bc\ndef get_typ4_enent(role_argument,argument_positions):\n    trigger_role='\u8d28\u62bc\u91d1\u989d'\n    role_argument_position={}\n    trigger_position=None\n    #\u91d1\u989d\u53ea\u6709\u4e00\u4e2a\n    if len(argument_positions['\u8d28\u62bc\u91d1\u989d'])==1:\n            trigger_position=argument_positions['\u8d28\u62bc\u91d1\u989d'][0]\n    #\u6709\u591a\u4e2a\u91d1\u989d\n    else:\n            m=999999\n            #\u6ca1\u6709\u65e5\u671f\n            if '\u8d28\u62bc\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                trigger_position=min(argument_positions['\u8d28\u62bc\u91d1\u989d'])\n            #\u9009\u62e9\u91d1\u989d\u65e5\u671f\u5dee\u8ddd\u6700\u5c0f\u7684trigger\n            else:\n                for i in argument_positions['\u8d28\u62bc\u91d1\u989d']:\n                    for j in argument_positions['\u8d28\u62bc\u5f00\u59cb\u65e5\u671f']:\n                        gap=abs(i-j)\n                        if gap<m:\n                            trigger_position=i\n                            m=gap\n    role_argument_position[trigger_role]=(role_argument[trigger_role],trigger_position) #trigger\u6392\u5728\u9996\u4f4d\n    for role,argu_positions in argument_positions.items():\n        if role==trigger_role:\n            continue\n        argument=role_argument[role]\n        assert len(argument)>0\n        argu_position=None\n        gap=9999999\n        for temp in argu_positions:\n            if abs(trigger_position-temp)<gap:\n                argu_position=temp\n                gap=abs(trigger_position-temp)\n        role_argument_position[role]=(argument,argu_position)\n    #\u7ed3\u675f\u65e5\u671f\u4e00\u5b9a\u6839\u636e\u5f00\u59cb\u65e5\u671f\u5206\u914d\n    if '\u8d28\u62bc\u7ed3\u675f\u65e5\u671f' in argument_positions and '\u8d28\u62bc\u5f00\u59cb\u65e5\u671f' in argument_positions:\n        gap=9999999\n        begin_position=role_argument_position['\u8d28\u62bc\u5f00\u59cb\u65e5\u671f'][1]\n        argument=role_argument['\u8d28\u62bc\u7ed3\u675f\u65e5\u671f']\n        argu_position=None\n        for temp in argument_positions['\u8d28\u62bc\u7ed3\u675f\u65e5\u671f']:\n            if abs(begin_position-temp)<gap:\n                argu_position=temp\n                gap=abs(begin_position-temp)\n        role_argument_position['\u8d28\u62bc\u7ed3\u675f\u65e5\u671f']=(argument,argu_position)\n#         assert role_argument_position['\u51bb\u7ed3\u7ed3\u675f\u65e5\u671f'][1]>=role_argument_position['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f'][1]\n#     print(role_argument)\n#     print(argument_positions)\n#     print(role_argument_position)\n#     print('*'*50)\n    return role_argument_position,[trigger_role,role_argument[trigger_role],trigger_position]\n    \ndef get_position_enent(typ,role_argument,argument_positions,content):\n    trigger_role=None\n    role_argument_position={}\n    if typ=='\u80a1\u4e1c\u51cf\u6301':\n        return get_typ1_enent(role_argument,argument_positions,content)\n    elif typ=='\u80a1\u4e1c\u589e\u6301':\n        return get_typ2_enent(role_argument,argument_positions)\n    elif typ=='\u80a1\u6743\u51bb\u7ed3':\n        return get_typ3_enent(role_argument,argument_positions)\n    elif typ=='\u80a1\u6743\u8d28\u62bc':\n        return get_typ4_enent(role_argument,argument_positions)","363687b0":"def get_positions(s,text):\n    positions=[]\n    place=0\n    while True:\n        position=s.find(text)\n        if position!=-1:\n            positions.append(position+place)\n            s=s[position+len(text):]\n            place=positions[-1]+len(text)\n        else:\n            return positions\n\nroles_set=collections.defaultdict(int)\nmore_enents=[]\nn=0\nproblem_doc_id=[]\nfor t in tqdm(train_data):\n    n+=1\n    enents=t.enents\n    content=t.content\n    position_enents=[]\n    if enents[0][0]=='\u91cd\u5927\u5bf9\u5916\u8d54\u4ed8':\n        print(content)\n    all_argument_position=[]\n    #\u6bcf\u4e00\u4e2a\u4e8b\u4ef6\n    for enent in enents:\n        typ=enent[0]\n        role_argument=enent[1]\n        any_position=False\n        argument_positions={}\n        for role,argument in role_argument.items():\n            #\u2018\u2019\n            if len(argument)==0:\n                continue\n            positions=get_positions(content,argument)  #\u6240\u6709argument\u5728\u539f\u6587\u7684\u4f4d\u7f6e\n            if len(positions)==0:\n                if '(' in argument:\n                    argument=argument.replace('(','\uff08')\n                    argument=argument.replace(')','\uff09')\n                elif '\uff08' in argument:\n                    argument=argument.replace('\uff08','(')\n                    argument=argument.replace('\uff09',')')\n                positions=get_positions(content,argument)\n            for position in positions:\n                assert content[position:position+len(argument)]==argument  #\u786e\u4fdd\u627e\u7684\u6ca1\u6709\u9519\n            argument_positions[role]=positions\n        if typ=='\u80a1\u6743\u8d28\u62bc':\n            assert len(argument_positions['\u8d28\u62bc\u91d1\u989d'])>0\n        elif typ=='\u80a1\u4e1c\u51cf\u6301':\n            assert len(role_argument['\u51cf\u6301\u91d1\u989d'])>0\n            ######\u65b0\u7684trigger\u5224\u5b9a\u65b9\u6cd5\n            trigger_position=None\n            if len(argument_positions['\u51cf\u6301\u91d1\u989d'])==1:\n                trigger_position=argument_positions['\u51cf\u6301\u91d1\u989d'][0]\n            else:\n                m=999999\n                if '\u51cf\u6301\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                    trigger_position=min(argument_positions['\u51cf\u6301\u91d1\u989d'])\n                else:\n                    for i in argument_positions['\u51cf\u6301\u91d1\u989d']:\n                        for j in argument_positions['\u51cf\u6301\u5f00\u59cb\u65e5\u671f']:\n                            gap=abs(i-j)\n                            if gap<m:\n                                trigger_position=i\n                                m=gap\n#             if '\u51cf\u6301\u7684\u80a1\u4e1c' in argument_positions and min(argument_positions['\u51cf\u6301\u7684\u80a1\u4e1c'])-trigger_position>0:\n#                 print(argument_positions)\n#                 print(trigger_position)\n#                 print(t.doc_id)\n#                 print(role_argument)\n#                 print('*'*50)\n                    \n                \n            \n                \n        elif typ=='\u80a1\u6743\u51bb\u7ed3':\n            assert len(role_argument['\u51bb\u7ed3\u91d1\u989d'])>0\n            roles_set[str(argument_positions.keys())]+=1\n            trigger_position=None\n            if len(argument_positions['\u51bb\u7ed3\u91d1\u989d'])==1:\n                trigger_position=argument_positions['\u51bb\u7ed3\u91d1\u989d'][0]\n            else:\n                m=999999\n                if '\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                    trigger_position=min(argument_positions['\u51bb\u7ed3\u91d1\u989d'])\n                else:\n                    for i in argument_positions['\u51bb\u7ed3\u91d1\u989d']:\n                        for j in argument_positions['\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f']:\n                            gap=abs(i-j)\n                            if gap<m:\n                                trigger_position=i\n                                m=gap\n                \n                \n        elif typ=='\u80a1\u4e1c\u589e\u6301':\n            assert len(role_argument['\u589e\u6301\u91d1\u989d'])>0\n            ######\u65b0\u7684trigger\u5224\u5b9a\u65b9\u6cd5\n            trigger_position=None\n            if len(argument_positions['\u589e\u6301\u91d1\u989d'])==1:\n                trigger_position=argument_positions['\u589e\u6301\u91d1\u989d'][0]\n            else:\n                m=999999\n                if '\u589e\u6301\u5f00\u59cb\u65e5\u671f' not in argument_positions:\n                    trigger_position=min(argument_positions['\u589e\u6301\u91d1\u989d'])\n                else:\n                    for i in argument_positions['\u589e\u6301\u91d1\u989d']:\n                        for j in argument_positions['\u589e\u6301\u5f00\u59cb\u65e5\u671f']:\n                            gap=abs(i-j)\n                            if gap<m:\n                                trigger_position=i\n                                m=gap\n                                \n#             if '\u589e\u6301\u7684\u80a1\u4e1c' in argument_positions and min(argument_positions['\u589e\u6301\u7684\u80a1\u4e1c'])-trigger_position>0:\n#                 print(argument_positions)\n#                 print(trigger_position)\n#                 print(t.doc_id)\n#                 print(role_argument)\n#                 print('*'*50)\n#         if typ=='\u91cd\u5927\u5bf9\u5916\u8d54\u4ed8':\n#             print(role_argument)\n#             print(argument_positions)\n#             print('*'*50)\n        role_argument_position,trigger_position=get_position_enent(typ,role_argument,argument_positions,t.content)\n        position_enents.append([typ,role_argument_position,trigger_position])\n        all_argument_position.append(argument_positions)\n#         print(list(argument_positions.keys()))\n    t.enents=position_enents\n    all_trigger=[]\n    for enent_type,role_argument,trigg in t.enents:\n        all_trigger.append((trigg[1],trigg[2]))\n    if len(all_trigger)!=len(set(all_trigger)):\n        problem_doc_id.append(t.doc_id)\nlen(problem_doc_id)","82935815":"new_train_data=[]\nfor t in train_data:\n    if t.doc_id not in problem_doc_id:\n        new_train_data.append(t)\ntrain_data=new_train_data\nlen(train_data)","10987f8f":"for t in train_data:\n    print(t)\n    break\nlen(train_data)","c4cf8d02":"\nimport pickle\nval_recall_data=collections.defaultdict(list)\ntest_recall_data=collections.defaultdict(list)\nfor i in range(1,6):\n    with open('..\/input\/ccks42-ee2-525\/val_preds_v2516_{}.pkl'.format(i),'rb') as f:\n        d=pickle.load(f)\n        for k,v in d.items():\n           val_recall_data[k]=v\n    if i>0:\n        with open('..\/input\/ccks42-ee2-525\/test_preds_v2516_{}.pkl'.format(i),'rb') as f:\n            d=pickle.load(f)\n            for k,v in d.items():\n               test_recall_data[k].extend(v)\n#\u6295\u7968\nfor k,v in test_recall_data.items():\n    v_dict=dict(collections.Counter(v))\n    new_v=[]\n    for vi,count in v_dict.items():\n        if count>2:\n            new_v.append(vi)\n    test_recall_data[k]=new_v\n\nfor k,v in test_recall_data.items():\n    v=sorted(v,key=lambda x:len(x[1]),reverse=True)\n    i=0\n    l1=len(v)\n    t=copy.deepcopy(v)\n    while i<len(v):\n        j=i+1\n        while j<len(v):\n            if v[i][2]==v[j][2] and v[j][1] in v[i][1]:\n                v.pop(j)\n            else:\n                j+=1\n        i+=1\n    if len(t)!=len(v):\n        print(t)\n        print(v)\n        print('*'*50)\n    test_recall_data[k]=v","da6035eb":"for k,v in test_recall_data.items():\n    print(k)\n    print(v)","6fcded4e":"for k,v in val_recall_data.items():\n    v=sorted(v,key=lambda x:len(x[1]),reverse=True)\n    i=0\n    l1=len(v)\n    t=copy.deepcopy(v)\n    while i<len(v):\n        j=i+1\n        while j<len(v):\n            if v[i][2]==v[j][2] and v[j][1] in v[i][1]:\n                v.pop(j)\n            else:\n                j+=1\n        i+=1\n    if len(t)!=len(v):\n        print(t)\n        print(v)\n        print('*'*50)\n    val_recall_data[k]=v","5c1c60b6":"def metric_fn_word(results,label_results,log=False):\n    totol_number=0\n    predict_number=0\n    predict_score=0\n    for item_id,feat in label_results.items():\n        if log:\n            print('id:',item_id)\n            print('type_labels:',label_results[item_id])\n            print('type_predict:',results[item_id])\n            print('*'*50)\n        #feat p_feat\u662f\u4e00\u4e2alist\n        p_feat=[]\n        if item_id in results:\n            p_feat=results[item_id]\n        predict_number+=len(p_feat)\n        totol_number+=len(feat)\n        for word in feat:\n            if word in p_feat:\n                predict_score+=1\n            \n    print(predict_number)\n    print(totol_number)\n    P=predict_score\/predict_number if predict_number>0 else 0.\n    R=predict_score\/totol_number if totol_number>0 else 0.\n    \n    f1=(2*P*R)\/(P+R) if (P+R)>0 else 0.\n    \n    return f1,P,R\n\n\nval_label=collections.defaultdict(list)\nfor t in train_data:\n    enents=t.enents\n    for typ,role_arguments,trigger_info in enents:\n        val_label[t.doc_id].append((trigger_info[0],trigger_info[1],trigger_info[2]))\nmetric_fn_word(val_recall_data,val_label,log=False)","52d1afcf":"# for k,v in val_recall_data.items():\n#     typ=None\n#     enents=None\n#     for t in train_data:\n#         if str(t.doc_id)==str(k):\n#             typ=t.enents[0][0]\n#             enents=t.enents\n#     if typ in['\u80a1\u4e1c\u51cf\u6301', '\u80a1\u4e1c\u589e\u6301', '\u80a1\u6743\u51bb\u7ed3', '\u80a1\u6743\u8d28\u62bc']:\n#         print(k)\n#         print([t[2] for t in enents])\n#         print(v)\n#         print('*'*50)","735d97a0":"append_shama=['\u51cf\u6301\u5f00\u59cb\u65e5\u671f','\u589e\u6301\u5f00\u59cb\u65e5\u671f','\u51bb\u7ed3\u5f00\u59cb\u65e5\u671f','\u51cf\u6301\u7684\u80a1\u4e1c','\u589e\u6301\u7684\u80a1\u4e1c','\u88ab\u51bb\u7ed3\u80a1\u4e1c']","0818813e":"MAX_OR_TEXT_LEN=-1\nMAX_TEXT_LEN = 470\nMAX_QUESTION_LEN=35\nMAX_LEN=512\nSEP_TOKEN_ID = 102\nDEVICE = 'cuda'\n\n\n\n\ndef seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nSEED=2020\nseed_everything(SEED)\n","6d06a8d4":"import unicodedata\ndef _is_control(ch):\n    \"\"\"\u63a7\u5236\u7c7b\u5b57\u7b26\u5224\u65ad\n    \"\"\"\n    return unicodedata.category(ch) in ('Cc', 'Cf')\n\ndef _is_special(ch):\n    \"\"\"\u5224\u65ad\u662f\u4e0d\u662f\u6709\u7279\u6b8a\u542b\u4e49\u7684\u7b26\u53f7\n    \"\"\"\n    return bool(ch) and (ch[0] == '[') and (ch[-1] == ']')\n\ndef stem(token):\n    \"\"\"\u83b7\u53d6token\u7684\u201c\u8bcd\u5e72\u201d\uff08\u5982\u679c\u662f##\u5f00\u5934\uff0c\u5219\u81ea\u52a8\u53bb\u6389##\uff09\n    \"\"\"\n    if token[:2] == '##':\n        return token[2:]\n    else:\n        return token\ndef rematch(text,tokens,_do_lower_case=True):\n    '''\n    \u8fd4\u56de\u7684\u662ftoken\u540e\u6807\u7b7e\u4e0e\u539f\u59cb\u7684\u6620\u5c04\n    '''\n    normalized_text, char_mapping = '', []\n    #\u89c4\u8303\u5316\u6837\u672c\n    for i, ch in enumerate(text):\n        if _do_lower_case:\n            ch = unicodedata.normalize('NFD', ch)\n            ch = ''.join([c for c in ch if unicodedata.category(c) != 'Mn'])\n            ch = ch.lower()\n        ch = ''.join([\n                c for c in ch\n                if not (ord(c) == 0 or ord(c) == 0xfffd or _is_control(c))\n            ])\n        normalized_text += ch\n        char_mapping.extend([i] * len(ch))\n    print(normalized_text)\n    text, token_mapping, offset = normalized_text, [], 0\n    for i,token in enumerate(tokens):\n        if _is_special(token):\n            token_mapping.append([offset])\n            offset+=1\n        else:\n            token = stem(token)\n            #none\u8868\u793a\u6709\u9519\n            if text[offset:].find(token)==-1:\n                return None\n            start = text[offset:].index(token) + offset\n            end = start + len(token)\n            token_mapping.append(char_mapping[start:end])\n            offset = end\n\n    return token_mapping\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None)\ntext='\u96c0\u5de2\u88c1\u54584000\u4eba\uff1a\u65f6\u4ee3\u629b\u5f03\u4f60\u65f6\uff0c\u8fde\u62db\u547c\u90fd\u4e0d\u4f1a\u6253\uff01 9234234 ##'\ntokens=tokenizer.tokenize(text)\nprint(tokens)\nmapping=rematch(text,tokens)\nprint(mapping)","0a4d5906":"def search(pattern, sequence):\n    \"\"\"\u4ecesequence\u4e2d\u5bfb\u627e\u5b50\u4e32pattern\n    \u5982\u679c\u627e\u5230\uff0c\u8fd4\u56de\u7b2c\u4e00\u4e2a\u4e0b\u6807\uff1b\u5426\u5219\u8fd4\u56de-1\u3002\n    \"\"\"\n    n = len(pattern)\n    for i in range(len(sequence)):\n        if sequence[i:i + n] == pattern:\n            return i\n    return -1\n\ndef search_list(pattern, sequence):\n    \"\"\"\u4ecesequence\u4e2d\u5bfb\u627e\u5b50\u4e32pattern\n    \u5982\u679c\u627e\u5230\uff0c\u8fd4\u56de\u7b2c\u4e00\u4e2a\u4e0b\u6807\uff1b\u5426\u5219\u8fd4\u56de-1\u3002\n    \"\"\"\n    n = len(pattern)\n    ans=[]\n    for i in range(len(sequence)):\n        if sequence[i:i + n] == pattern:\n            ans.append(i)\n    return ans\n\nclass Feature(object):\n    def __init__(self,item_id,or_text,mapping,mapping_off,event_type_role,token_ids,question,labels,enents,role_trigger_position,qa_start,qa_end):\n        self.item_id=item_id\n        self.or_text=or_text\n        self.mapping=mapping\n        self.mapping_off=mapping_off\n        self.event_type_role=event_type_role\n        self.token_ids=token_ids\n        self.question=question\n        self.labels=labels\n        self.enents=enents\n        self.role_trigger_position=role_trigger_position\n        self.qa_start=qa_start\n        self.qa_end=qa_end\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        s = \"\"\n        s += \"id: %s\\n\" % (str(self.item_id))\n        s += \"or_text: %s\\n\" % (str(self.or_text))\n        s += \"mapping: %s\\n\" % (str(self.mapping))\n        s += \"mapping_off: %s\\n\" % (str(self.mapping_off))\n        s += \"event_type_role: %s\\n\" % (str(self.event_type_role)) \n        s += \"token_ids: %s\\n\" % (str(self.token_ids)) \n        s += \"question: %s\\n\" % (str(self.question))\n        s += \"labels: %s\\n\" % (str(self.labels))\n        s += \"enents: %s\\n\" % (str(self.enents))\n        s += \"role_trigger_position: %s\\n\" % (str(self.role_trigger_position))\n        s += \"qa_start: %s\\n\" % (str(self.qa_start))\n        s += \"qa_end: %s\\n\" % (str(self.qa_end))\n        return s\n\nclass zy_DataSet(torch.utils.data.Dataset):\n    def __init__(self, data_list,train_mode=False, val_mode=False,test_mode=False,labeled=True,recall=False):\n        self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None)\n        self.train_mode = train_mode\n        self.val_mode=val_mode\n        self.test_mode=test_mode\n        self.labeled = labeled\n        self.recall=recall\n        if recall and self.val_mode:\n            print('val_recall:')\n            self.features =self.get_recall_features(data_list,val_recall_data)\n        elif recall and self.test_mode:\n            print('test_recall:')\n            self.features =self.get_recall_features(data_list,test_recall_data)\n        elif self.train_mode:\n            self.features =self.get_train_features(data_list)\n        elif self.val_mode:\n            self.features =self.get_val_features(data_list)\n        elif self.test_mode:\n            self.features =self.get_train_features(data_list)\n        else:\n            print('no features !!!')\n\n    \n    def get_recall_features(self,data_list,recall):\n        features=[]\n        ###\u6ed1\u52a8\u7a97\u53e3\n        print('or_cnt',len(data_list))\n        split_data_list=[]\n        for index in range(len(data_list)):\n            data=data_list[index]\n            content=data.content #\u6587\u672c\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            or_content=data.content\n            #\u957f\u5ea6\u5c0f\u4e8e\u6700\u5927\u957f\u5ea6\n            if len(content)<=MAX_TEXT_LEN-2:\n                split_data_list.append(Do_data(docid,content,enents,or_content=or_content))\n                continue\n            #\u5927\u4e8e\u6700\u5927\u957f\u5ea6\uff0c\u7528\u6ed1\u52a8\u7a97\u53e3\u5207\u5206\n            windows=300\n            split_off=0\n            while len(content)>MAX_TEXT_LEN-2:\n                split_content=content[:MAX_TEXT_LEN-2]\n                split_data_list.append(Do_data(docid,split_content,enents,content_split_off=split_off,or_content=or_content))\n                content=content[windows:]\n                split_off+=windows\n            if len(content)>0:\n                split_data_list.append(Do_data(docid,content,enents,content_split_off=split_off,or_content=or_content))\n        print('split_cnt',len(split_data_list))\n        print('*'*50)\n        for data in tqdm(split_data_list):\n            content=data.content #\u6587\u672c\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            recall_trigger=recall[docid] #\u53ec\u56de\u7684trigger\n            content_split_off=data.content_split_off\n            #\u5bf9\u6587\u672c\u8fdb\u884ctoken\n            t_tokens=self.tokenizer.tokenize(content)\n            assert len(t_tokens)<=MAX_TEXT_LEN\n            mapping=rematch(content,t_tokens) #\u83b7\u5f97\u539f\u59cb\u7684map\n            if mapping==None:\n                continue\n            text_token_ids = self.tokenizer.convert_tokens_to_ids(t_tokens+['[SEP]'])\n            \n            for trigger_role,trigger,trigger_position in recall_trigger:\n                enent_type=trigger_entype[trigger_role] #\u4e8b\u4ef6\u7c7b\u578b\n                if enent_type not in entype_trigger:\n                    break\n                #\u6587\u672c\u5305\u542btrigger\n                if trigger_position>=content_split_off and trigger_position<=content_split_off+len(content):\n                    roles=shama[enent_type]\n                    for role in roles:\n                        if role==trigger_role:\n                            continue\n                        question=enent_type+'-'+trigger_role+'-'+trigger+'-'+role\n                        q_tokens= self.tokenizer.convert_tokens_to_ids(['[CLS]']+self.tokenizer.tokenize(question)+['[SEP]'])\n                        mapping_off=len(q_tokens)\n                        assert len(q_tokens)<=MAX_QUESTION_LEN\n                        token_ids=q_tokens+text_token_ids\n                        if len(token_ids) < MAX_LEN:\n                            token_ids += [0] * (MAX_LEN- len(token_ids))\n                        labels=[0]*len(token_ids)\n                        qa_start=0\n                        qa_end=0\n                        feature=Feature(item_id=docid,\n                                    or_text=content,\n                                    mapping=mapping,\n                                    mapping_off=mapping_off,\n                                    event_type_role=(enent_type,role),\n                                    token_ids=token_ids,\n                                    question=question,\n                                    labels=labels,\n                                    enents=enents,\n                                    role_trigger_position=(trigger_role,trigger,trigger_position),\n                                    qa_start=qa_start,\n                                    qa_end=qa_end)\n                        features.append(feature)\n                        if role in append_shama:\n#                             print(role)\n                            app_features=self.append_features(enent_type,role,None,data,(trigger_role,trigger,trigger_position),q_tokens,question,is_predict=True)\n                            if len(app_features)>0:\n#                                 print('add')\n                                features.extend(app_features)\n        print(len(features))\n        return features\n        \n    def get_val_features(self,data_list,recall=None,train_mode=True):\n        neg=0\n        features=[]\n        ###\u6ed1\u52a8\u7a97\u53e3\n        print('or_cnt',len(data_list))\n        split_data_list=[]\n        for index in range(len(data_list)):\n            data=data_list[index]\n            content=data.content #\u6587\u672c\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            or_content=data.content\n            #\u957f\u5ea6\u5c0f\u4e8e\u6700\u5927\u957f\u5ea6\n            if len(content)<=MAX_TEXT_LEN-2:\n                split_data_list.append(Do_data(docid,content,enents,or_content=or_content))\n                continue\n            #\u5927\u4e8e\u6700\u5927\u957f\u5ea6\uff0c\u7528\u6ed1\u52a8\u7a97\u53e3\u5207\u5206\n            windows=300\n            split_off=0\n            while len(content)>MAX_TEXT_LEN-2:\n                split_content=content[:MAX_TEXT_LEN-2]\n                split_data_list.append(Do_data(docid,split_content,enents,content_split_off=split_off,or_content=or_content))\n                content=content[windows:]\n                split_off+=windows\n            if len(content)>0:\n                split_data_list.append(Do_data(docid,content,enents,content_split_off=split_off,or_content=or_content))\n        print('split_cnt',len(split_data_list))\n        print('*'*50)\n        for data in tqdm(split_data_list):\n            content=data.content #\u6587\u672c\n#             print(len(content))\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            content_split_off=data.content_split_off\n#             print(content_split_off)\n            #\u5bf9\u6587\u672c\u8fdb\u884ctoken\n            t_tokens=self.tokenizer.tokenize(content)\n            assert len(t_tokens)<=MAX_TEXT_LEN\n            mapping=rematch(content,t_tokens) #\u83b7\u5f97\u539f\u59cb\u7684map\n            if mapping==None:\n                continue\n            text_token_ids = self.tokenizer.convert_tokens_to_ids(t_tokens+['[SEP]'])\n            #\u904d\u5386\u6bcf\u4e00\u4e2a\u4e8b\u4ef6\n            for enent_type,role_argument_position,role_trigger_position in enents:\n                trigger_position=role_trigger_position[2]\n                trigger=role_trigger_position[1]\n                trigger_role=role_trigger_position[0]\n#                 print(content_split_off)\n#                 print(trigger_position)\n                #\u5305\u542btrigger\u7684\u6587\u672c\n                if trigger_position>=content_split_off and trigger_position<=content_split_off+len(content):\n                    roles=shama[enent_type]\n                    for role in roles:\n                        if role==trigger_role:\n                            continue\n                        question=enent_type+'-'+trigger_role+'-'+trigger+'-'+role\n                        q_tokens= self.tokenizer.convert_tokens_to_ids(['[CLS]']+self.tokenizer.tokenize(question)+['[SEP]'])\n                        mapping_off=len(q_tokens)\n                        assert len(q_tokens)<=MAX_QUESTION_LEN\n                        token_ids=q_tokens+text_token_ids\n                        if len(token_ids) < MAX_LEN:\n                            token_ids += [0] * (MAX_LEN- len(token_ids))\n                        labels=[0]*len(token_ids)\n                        qa_start=0\n                        qa_end=0\n                        feature=Feature(item_id=docid,\n                                    or_text=content,\n                                    mapping=mapping,\n                                    mapping_off=mapping_off,\n                                    event_type_role=(enent_type,role),\n                                    token_ids=token_ids,\n                                    question=question,\n                                    labels=labels,\n                                    enents=enents,\n                                    role_trigger_position=role_trigger_position,\n                                    qa_start=qa_start,\n                                    qa_end=qa_end)\n                        features.append(feature)\n                        if role in append_shama:\n                            app_features=self.append_features(enent_type,role,role_argument_position,data,role_trigger_position,q_tokens,question,is_predict=True)\n                            if len(app_features)>0:\n                               features.extend(app_features)\n        print(len(features))\n        return features\n    \n    def get_train_features(self,data_list,recall=None,train_mode=True):\n        neg=0\n        features=[]\n#         all_shama_single=list(shama_single.keys())\n        ###\u6ed1\u52a8\u7a97\u53e3\n        print('or_cnt',len(data_list))\n        split_data_list=[]\n        for index in range(len(data_list)):\n            data=data_list[index]\n            content=data.content #\u6587\u672c\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            or_content=data.content\n            #\u957f\u5ea6\u5c0f\u4e8e\u6700\u5927\u957f\u5ea6\n            if len(content)<=MAX_TEXT_LEN-2:\n                split_data_list.append(Do_data(docid,content,enents,or_content=or_content))\n                continue\n            #\u5927\u4e8e\u6700\u5927\u957f\u5ea6\uff0c\u7528\u6ed1\u52a8\u7a97\u53e3\u5207\u5206\n            windows=300\n            split_off=0\n#             or_content=data.content\n            while len(content)>MAX_TEXT_LEN-2:\n                split_content=content[:MAX_TEXT_LEN-2]\n                split_data_list.append(Do_data(docid,split_content,enents,content_split_off=split_off,or_content=or_content))\n                content=content[windows:]\n                split_off+=windows\n            if len(content)>0:\n                split_data_list.append(Do_data(docid,content,enents,content_split_off=split_off,or_content=or_content))\n        print('split_cnt',len(split_data_list))\n        print('*'*50)\n        for data in tqdm(split_data_list):\n            content=data.content #\u6587\u672c\n#             print(len(content))\n            docid=data.doc_id #\u6587\u672cid\n            enents=data.enents\n            content_split_off=data.content_split_off\n#             print(content_split_off)\n            #\u5bf9\u6587\u672c\u8fdb\u884ctoken\n            t_tokens=self.tokenizer.tokenize(content)\n            assert len(t_tokens)<=MAX_TEXT_LEN\n            mapping=rematch(content,t_tokens) #\u83b7\u5f97\u539f\u59cb\u7684map\n            if mapping==None:\n                continue\n            text_token_ids = self.tokenizer.convert_tokens_to_ids(t_tokens+['[SEP]'])\n            #\u904d\u5386\u6bcf\u4e00\u4e2a\u4e8b\u4ef6\n            for enent_type,role_argument_position,role_trigger_position in enents:\n                trigger_position=role_trigger_position[2]\n                trigger=role_trigger_position[1]\n                trigger_role=role_trigger_position[0]\n                #\u5305\u542btrigger\u7684\u6587\u672c\n                if trigger_position>=content_split_off and trigger_position<=content_split_off+len(content):\n                    roles=shama[enent_type]\n                    for role in roles:\n                        if role==trigger_role:\n                            continue\n                        question=enent_type+'-'+trigger_role+'-'+trigger+'-'+role\n                        q_tokens= self.tokenizer.convert_tokens_to_ids(['[CLS]']+self.tokenizer.tokenize(question)+['[SEP]'])\n                        mapping_off=len(q_tokens)\n                        assert len(q_tokens)<=MAX_QUESTION_LEN\n                        token_ids=q_tokens+text_token_ids\n                        if len(token_ids) < MAX_LEN:\n                            token_ids += [0] * (MAX_LEN- len(token_ids))\n                        labels=[0]*len(token_ids)\n                        qa_start=0\n                        qa_end=0\n                        #\u6709\u7b54\u6848\n                        if role in role_argument_position and len(role_argument_position[role][0])>0:\n                            argument=role_argument_position[role]\n                            argument_position=argument[1]\n                            ans=argument[0]\n                            start=None\n                            an_ids= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(ans))\n                            for index in range(len(mapping)):\n                                if mapping[index][0]+content_split_off==argument_position:\n#                                     assert content[mapping[index][0]:].startswith(ans)\n                                    if not content[mapping[index][0]:].startswith(ans):\n#                                         print(content[mapping[index][0]:])\n#                                         print(ans)\n#                                         print(content_split_off)\n#                                         print(argument_position)\n                                        break\n                                    else:\n                                        start=index+mapping_off #\u56e0\u4e3a\u6709cls\n                                        break\n                            if start:\n                                labels[start]=1\n                                for i in range(1,len(an_ids)):\n                                    labels[start+i]=2\n                                qa_start=start\n                                qa_end=start+len(an_ids)-1\n                        \n                        feature=Feature(item_id=docid,\n                                    or_text=content,\n                                    mapping=mapping,\n                                    mapping_off=mapping_off,\n                                    event_type_role=(enent_type,role),\n                                    token_ids=token_ids,\n                                    question=question,\n                                    labels=labels,\n                                    enents=enents,\n                                    role_trigger_position=role_trigger_position,\n                                    qa_start=qa_start,\n                                    qa_end=qa_end)\n                        features.append(feature)\n                        if role in append_shama:\n                            app_features=self.append_features(enent_type,role,role_argument_position,data,role_trigger_position,q_tokens,question,is_predict=False)\n                            if len(app_features)>0:\n                               features.extend(app_features)\n        print(len(features))\n        return features\n                        \n    def append_features(self,enent_type,role,role_argument_position,data,role_trigger_position,q_tokens,question,is_predict=False):\n        trigger_position=role_trigger_position[2]\n        trigger=role_trigger_position[1]\n        trigger_role=role_trigger_position[0]\n        content_split_off=data.content_split_off\n        content=data.content #\u5207\u5206\u7684\u6587\u672c\n        or_content=data.or_content #\u539f\u59cb\u7684\u6587\u672c\n        mapping_off=len(q_tokens)\n#         print(content_split_off)\n        if content_split_off==0 and '\u65e5\u671f' not in role:\n#             print(content_split_off)\n#             print('return 0')\n            return []\n        #\u6700\u540e\u7684\u53e5\u5b50\n        elif content[-10:]==or_content[-10:] and '\u65e5\u671f' in role:\n#             print('return 1')\n            return []\n        app_features=[] #\u8fd4\u56de\u7684\u7ed3\u679c\n#         print('='*50)\n        #\u5bf9\u4e8e\u65f6\u95f4\uff0c\u53ea\u6dfb\u52a0\u6700\u540e\u4e00\u70b9\u6587\u672c\n        if '\u65e5\u671f' in role:\n            before_new_position=trigger_position-content_split_off-100 if trigger_position-content_split_off-100>=0 else 0\n            end_new_position=trigger_position-content_split_off+250\n            constant_text=content[before_new_position:end_new_position]\n            append_text=or_content[-120:]\n            app_content_split_off=len(or_content)-120\n            t_tokens=self.tokenizer.tokenize(constant_text+append_text)\n            assert len(t_tokens)<=MAX_TEXT_LEN\n            mapping=rematch(constant_text+append_text,t_tokens) #\u83b7\u5f97\u539f\u59cb\u7684map\n            if mapping==None:\n                print('none')\n                return append_features\n            text_token_ids = self.tokenizer.convert_tokens_to_ids(t_tokens+['[SEP]'])\n            token_ids=q_tokens+text_token_ids\n            if len(token_ids) < MAX_LEN:\n                token_ids += [0] * (MAX_LEN- len(token_ids))\n            labels=[0]*len(token_ids)\n            qa_start=0\n            qa_end=0\n            #\u6709\u7b54\u6848\u5e76\u4e14\u4e0d\u662f\u9884\u6d4b\u9636\u6bb5\n            if not is_predict and role in role_argument_position and len(role_argument_position[role][0])>0:\n                argument=role_argument_position[role]\n                argument_position=argument[1]\n                ans=argument[0]\n                #\u5728\u4e0d\u5728\u539f\u59cb\u7684\u6587\u672c\n                start=None\n                an_ids= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(ans))\n                for index in range(len(mapping)):\n                    compare_split=None\n                    if mapping[index][0]<len(constant_text):\n                        compare_split=content_split_off+before_new_position\n                    else:\n                        compare_split=app_content_split_off-len(constant_text)\n                    if mapping[index][0]+compare_split==argument_position:\n#                         if argument_position>len(or_content)-100:\n#                             print('find_answer')\n#                             print((constant_text+append_text)[mapping[index][0]:])\n#                             print(ans)\n    #               assert content[mapping[index][0]:].startswith(ans)\n                        if not (constant_text+append_text)[mapping[index][0]:].startswith(ans):\n                            break\n                        else:\n                            start=index+mapping_off #\u56e0\u4e3a\u6709cls\n                            break\n                if start:\n                    labels[start]=1\n                    for i in range(1,len(an_ids)):\n                        labels[start+i]=2\n                        qa_start=start\n                        qa_end=start+len(an_ids)-1\n                else:\n                    pass\n#                     print('find no answer')\n#                 if argument_position>len(or_content)-100:\n#                     print('constant text')\n#                     print(constant_text)\n#                     print('append text')\n#                     print(append_text)\n#                     print('answer:')\n#                     print((constant_text+append_text)[start:])\n            \n            feature=Feature(item_id=data.doc_id,\n                                    or_text=constant_text+append_text,\n                                    mapping=mapping,\n                                    mapping_off=mapping_off,\n                                    event_type_role=(enent_type,role),\n                                    token_ids=token_ids,\n                                    question=question,\n                                    labels=labels,\n                                    enents=data.enents,\n                                    role_trigger_position=role_trigger_position,\n                                    qa_start=qa_start,\n                                    qa_end=qa_end)\n            app_features.append(feature)\n            \n        #\u80a1\u4e1c\n        else:\n            assert content_split_off>0\n            before_new_position=trigger_position-content_split_off-150 if trigger_position-content_split_off-150>=0 else 0\n            end_new_position=trigger_position-content_split_off+50\n            constant_text=content[before_new_position:end_new_position]\n            append_text=or_content[:270]#\u6dfb\u52a0\u7684\u6570\u636e\n            app_content_split_off=0\n            t_tokens=self.tokenizer.tokenize(append_text+constant_text)\n            assert len(t_tokens)<=MAX_TEXT_LEN\n            mapping=rematch(append_text+constant_text,t_tokens) #\u83b7\u5f97\u539f\u59cb\u7684map\n            if mapping==None:\n                print('none')\n                return append_features\n            text_token_ids = self.tokenizer.convert_tokens_to_ids(t_tokens+['[SEP]'])\n            token_ids=q_tokens+text_token_ids\n            if len(token_ids) < MAX_LEN:\n                token_ids += [0] * (MAX_LEN- len(token_ids))\n            labels=[0]*len(token_ids)\n            qa_start=0\n            qa_end=0\n            #\u6709\u7b54\u6848\u5e76\u4e14\u4e0d\u662f\u9884\u6d4b\u9636\u6bb5\n            if not is_predict and role in role_argument_position and len(role_argument_position[role][0])>0:\n                argument=role_argument_position[role]\n                argument_position=argument[1]\n                ans=argument[0]\n                #\u5728\u4e0d\u5728\u539f\u59cb\u7684\u6587\u672c\n                start=None\n                an_ids= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(ans))\n                for index in range(len(mapping)):\n                    compare_split=None\n                    if mapping[index][0]<len(append_text):\n                        compare_split=app_content_split_off\n                    else:\n                        compare_split=content_split_off-len(append_text)\n                    if mapping[index][0]+compare_split==argument_position:\n#                         if argument_position>500:\n#                             print('find_answer')\n#                             print('append:',append_text)\n#                             print((append_text+constant_text)[mapping[index][0]:])\n#                             print(ans)\n    #               assert content[mapping[index][0]:].startswith(ans)\n                        if not (append_text+constant_text)[mapping[index][0]:].startswith(ans):\n                            break\n                        else:\n                            start=index+mapping_off #\u56e0\u4e3a\u6709cls\n                            break\n                if start:\n                    labels[start]=1\n                    for i in range(1,len(an_ids)):\n                        labels[start+i]=2\n                        qa_start=start\n                        qa_end=start+len(an_ids)-1\n#                 else:\n#                     print('find no answer')\n#                     print(start)\n            \n            feature=Feature(item_id=data.doc_id,\n                                    or_text=append_text+constant_text,\n                                    mapping=mapping,\n                                    mapping_off=mapping_off,\n                                    event_type_role=(enent_type,role),\n                                    token_ids=token_ids,\n                                    question=question,\n                                    labels=labels,\n                                    enents=data.enents,\n                                    role_trigger_position=role_trigger_position,\n                                    qa_start=qa_start,\n                                    qa_end=qa_end)\n            app_features.append(feature)\n            \n        return app_features\n    \n    def __len__(self):\n        return len(self.features)\n    def select_tokens(self, tokens, max_num):\n        if len(tokens) <= max_num:\n            return tokens\n        return tokens[:max_num]\n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == SEP_TOKEN_ID:\n                seg_idx += 1\n        max_idx = torch.nonzero(seg_ids == seg_idx)\n        seg_ids[max_idx] = 0\n        return seg_ids\n    def __getitem__(self,index):\n        feature=self.features[index]\n        token_ids=torch.tensor(feature.token_ids)\n        seg_ids=self.get_seg_ids(token_ids)\n        labels=torch.tensor(np.array(feature.labels).astype(np.float32)).long()\n        qa_start=torch.tensor(np.array(feature.qa_start).astype(np.float32)).long()\n        qa_end=torch.tensor(np.array(feature.qa_end).astype(np.float32)).long()\n        return token_ids,seg_ids,labels,qa_start,qa_end\n    \n    def collate_fn(self, batch):\n        token_ids = torch.stack([x[0] for x in batch])\n        seg_ids = torch.stack([x[1] for x in batch])\n        labels=torch.stack([x[2] for x in batch])\n        qa_start=torch.stack([x[3] for x in batch])\n        qa_end=torch.stack([x[4] for x in batch])\n        return token_ids, seg_ids, labels,qa_start,qa_end\n    \n    \ndef get_loader(df,batch_size=16,train_mode=False,val_mode=False,test_mode=False,train_val=True,recall=False):\n    ds_df = zy_DataSet(copy.deepcopy(df),train_mode=train_mode,val_mode=val_mode,test_mode=test_mode,labeled=train_val,recall=recall)\n    loader = torch.utils.data.DataLoader(ds_df, batch_size=batch_size, shuffle=train_mode, num_workers=0, collate_fn=ds_df.collate_fn, drop_last=train_mode)\n    loader.num = len(ds_df)\n    \n    return loader,ds_df.features\n\ndef debug_loader(df):\n    loader,features=get_loader(train_data[:64],train_mode=True)\n    for token_ids, seg_ids,labels,qa_start,qa_end in loader:\n        print(token_ids)\n        print(seg_ids)\n        print(labels)\n        print(qa_start)\n        print(qa_end)\n        break\n    print(len(features))","f584e9f7":"# train_data[:1]","90b15947":"train_loader,train_features=get_loader(train_data[:100],train_mode=True)\nlen(train_features)","0bbd6c39":"train_features[4]","9ca73dc7":"debug_loader(train_loader)","7e0aa4f9":"from transformers import *\nfrom torchcrf import CRF\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport time\nfrom tqdm import tqdm_notebook\n\nfrom transformers import *\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport collections\nimport time\nfrom tqdm import tqdm_notebook","d9c11b47":"class PositionalWiseFeedForward(nn.Module):\n\n    def __init__(self, model_dim=768, ffn_dim=2048, dropout=0.0):\n        super(PositionalWiseFeedForward, self).__init__()\n\n\n        self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n        self.w2 = nn.Conv1d(ffn_dim, model_dim, 1)\n        self.dropout = nn.Dropout(dropout)\n        self.layer_norm = nn.LayerNorm(model_dim)\n\n\n\n    def forward(self, x):\n        #[b,e,s]\n        output = x.transpose(1, 2)\n\n        output = self.w2(F.relu(self.w1(output)))\n        output = self.dropout(output.transpose(1, 2))\n\n        # add residual and norm layer\n        output = self.layer_norm(x + output)\n        return output\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self,attention_dropout=0.0):\n        super(ScaledDotProductAttention, self).__init__()\n        self.dropout = nn.Dropout(attention_dropout)\n        self.softmax = nn.Softmax(dim=2)\n\n    def forward(self,q,k,v,scale=None,attn_mask=None):\n        \"\"\"\n\n        :param q: [B,Lq,D_q]\n        :param k:[B,Lk,D_k]\n        :param v:[B,Lv,D_v]\n        :param scale: \u7f29\u653e\u56e0\u5b50\n        :param attn_mask:[B,Lq,Lk]\n        :return:\u4e0a\u4e0b\u6587\u5f20\u91cf\uff0c\u548cattention\u5f20\u91cf\n        \"\"\"\n\n\n        #[B,s,s]\n        attention=torch.bmm(q,k.transpose(1,2))\n\n        if scale:\n            attention=attention*scale\n        #attn_mask:[B,sq,sk]\n        if attn_mask!=None:\n            attention=attention.masked_fill_(attn_mask,-np.inf)\n\n        attention=self.softmax(attention)\n\n        attention=self.dropout(attention)\n\n        #[b,s,d]\n        context=torch.bmm(attention,v)\n\n        return context,attention\n\nclass zy_Model(nn.Module):\n    def __init__(self):\n        num_labels=3\n        super(zy_Model, self).__init__()\n        self.model_name = 'zy_Model'\n        self.bert_model = BertModel.from_pretrained(\"..\/working\",cache_dir=None,output_hidden_states=True)\n        self.zy_hidden_fc= nn.Sequential(nn.Linear(768, num_labels),nn.ReLU(True))\n        self.hidden_fc= nn.Sequential(nn.Linear(768, 2))\n        self.crf=CRF(num_labels,batch_first=True)\n    \n    def mask_mean(self,x,mask):\n        mask_x=x*(mask.unsqueeze(-1))\n        x_sum=torch.sum(mask_x,dim=1)\n        re_x=torch.div(x_sum,torch.sum(mask,dim=1).unsqueeze(-1))\n        return re_x\n    def forward(self,ids,seg_ids,labels,qa_start,qa_end,is_test=False):\n        attention_mask = (ids > 0)\n        last_seq,pooled_output,hidden_state=self.bert_model(input_ids=ids,token_type_ids=seg_ids,attention_mask=attention_mask)\n        \n        outs=self.hidden_fc(last_seq)\n        p_start,p_end=outs.split([1,1], dim=-1)\n        p_end=p_end.squeeze()\n        p_start=p_start.squeeze()\n\n#         emissions=self.zy_hidden_fc(last_seq)\n    \n        \n#         ans_out=self.zy_hidden_ans_label(pooled_output).sigmoid()\n#         left_right_out=self.zy_left_right(pooled_output)\n        if not is_test:\n#             loss=-self.crf(emissions, labels, mask=attention_mask,reduction='mean')\n            criterion = nn.CrossEntropyLoss()\n            loss=criterion(p_start,qa_start)+criterion(p_end,qa_end)\n            return loss\n        else:\n#             decode=self.crf.decode(emissions,attention_mask)\n            return p_start,p_end\n\ndef debug_label():\n    loader,features=get_loader(train_data[:64],train_mode=True,batch_size=2)\n    model=zy_Model()\n    for token_ids, seg_ids,labels,qa_start,qa_end in loader:\n        print(token_ids.size())\n        y = model(token_ids, seg_ids,labels ,qa_start,qa_end,is_test=False)\n        print(y)\n        y = model(token_ids, seg_ids,labels ,qa_start,qa_end,is_test=True)\n        print(y)\n        print(len(y))\n        break\n\n        ","51cbc32e":"# debug_label()","5f3b0682":"# model=zy_Model(num_labels)\n# list(model.named_parameters())","b7bb4e3f":"def get_text_f1(pred_text,text):\n    common_number=0\n    for ch in pred_text:\n        if ch in text:\n            common_number+=1\n    p_len=len(pred_text)\n    t_len=len(text)\n    P=common_number\/p_len if p_len>0 else 0.\n    R=common_number\/t_len if t_len>0 else 0.\n    \n    return (2*P*R)\/(P+R) if (P+R)>0 else 0.\n    \ndef metric_fn(results,features):\n    totol_number=0\n    predict_number=0\n    predict_score=0\n    for index,feat in enumerate(features):\n        true_dicts=feat.answers #\u771f\u5b9e\u7684answers\n        pred_dicts=results[index] #\u9884\u6d4b\u7684answers\n        totol_number+=len(set(list(true_dicts.values()))) #\u53bb\u6389\u91cd\u590d\u7684\n        predict_number+=len(set(list(pred_dicts.values())))\n        \n        #\u4e3a\u4e86\u591a\u4e2a\u8868\u8ff0\uff0c\u6539\u4e3adict list\n        true_dicts_list=collections.defaultdict(list)\n        predict_dicts_list=collections.defaultdict(list)\n        for answer,key in pred_dicts.items():\n            predict_dicts_list[key].append(answer)\n        for answer,key in true_dicts.items():\n            true_dicts_list[key].append(answer)\n        #\u8ba1\u7b97\u8bba\u6587f1\uff0c\u5982\u679c\u6709\u591a\u4e2a\u8bba\u5143\uff0c\u9009\u62e9\u5206\u6570\u6700\u9ad8\u90a3\u4e00\u4e2a\n        for key,answer in predict_dicts_list.items():\n            if key in true_dicts_list:\n                true_list=true_dicts_list[key]\n                ans_list=answer\n                s=0.\n                for t in true_list:\n                    for a in ans_list:\n                        s=max(s,get_text_f1(a,t))\n                predict_score+=s\n    P=predict_score\/predict_number if predict_number>0 else 0.\n    R=predict_score\/totol_number if totol_number>0 else 0.\n    \n    f1=(2*P*R)\/(P+R) if (P+R)>0 else 0.\n    \n    return f1,P,R\n    \n    \ndef compute_list_score(preds,trues):\n    score_dict={}\n    for i in range(len(preds)):\n        for j in range(len(trues)):\n            score_dict[(i,j)]=get_text_f1(preds[i],trues[j])\n    number=min(len(preds),len(trues))\n    score_dict= sorted(score_dict.items(), key=lambda d:d[1], reverse = True)\n    aready1={}\n    aready2={}\n    s=0.\n    for k,v in score_dict:\n        if number>0:\n            if k[0] not in aready1 and k[1] not in aready2:\n                s+=v\n                aready1[k[0]]=''\n                aready2[k[1]]=''\n                number-=1\n        else:\n            break\n    return s\n            \n    \n\ndef get_compare_score(feat,p_feat):\n    ans=0\n    for k,v in feat.items():\n        if k in p_feat and p_feat[k]==v:\n            ans+=1\n    return ans\n            \n\ndef compute_score_select(p_feats,feats):\n    feats=sorted(feats,key=lambda x:len(x),reverse=True) #\u5148\u6392\u6700\u591a\u7684\n    p_feats=sorted(p_feats,key=lambda x:len(x),reverse=True)\n    #\u4f9d\u6b21\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u8ba1\u7b97\u5206\u6570\n    total_number=sum([len(p) for p in feats])\n    predict_number=sum([len(p) for p in p_feats])\n    score=0\n    i=0\n    while i<len(feats) and len(p_feats)>0:\n        feat=feats[i]\n        best_num=0\n        condidate_feat=None\n        for p_feat in p_feats:\n            this_num=get_compare_score(feat,p_feat)\n            if this_num>best_num:\n                best_num=this_num\n                condidate_feat=p_feat\n        if condidate_feat:\n            score+=best_num\n            p_feats.remove(condidate_feat) #\u5220\u9664\u5df2\u7ecf\u914d\u5bf9\u7684\u7b54\u6848\n        i+=1\n    return total_number,predict_number,score\n            \n        \ndef set_dicts(feat):\n    feat=sorted(feat,key=lambda x:len(x),reverse=True) #\u7531\u5927\u5230\u5c0f\u6392\u5e8f\n    ans=[]\n    for f_dict in feat:\n        is_same=False\n        for a_dict in ans:\n            if is_same:\n                break\n            #\u6bd4\u8f83,\u5fc5\u987b\u6ee1\u8db3\u6240\u6709\u7684\u90fd\u4e0d\u76f8\u540c\n            num=0\n            for kf,kv in f_dict.items():\n                if kf in a_dict and a_dict[kf]==kv:\n                    num+=1\n            if num==len(f_dict):\n                is_same=True\n            \n        if not is_same:\n            ans.append(f_dict)\n    return ans\n    \n    \ndef metric_fn_qa(results,label_results):\n    totol_number=0\n    predict_number=0\n    predict_score=0\n    for item_id,feat in tqdm_notebook(label_results.items()):\n            p_feat_dict=results[item_id]\n            p_feat=[]\n            #\u83b7\u5f97\u4e00\u4e2atrigger\u4e00\u4e2a\u4e8b\u4ef6\n            for enent_type_role_trigger_position,result_dict in p_feat_dict.items():\n                dict_p={}\n                dict_p[(enent_type_role_trigger_position[0],enent_type_role_trigger_position[1])]=enent_type_role_trigger_position[2]\n                for k,v in result_dict.items():\n                    dict_p[k]=collections.Counter(v).most_common(1)[0][0]\n                #\u53ea\u6709trigger\n                if len(dict_p)==1:\n                    continue\n                p_feat.append(dict_p)\n            p_feat=set_dicts(p_feat)\n#             print('real:',feat)\n#             print('predict:',p_feat)\n#             print('*'*50)\n            t_number,p_number,p_score=compute_score_select(p_feat,feat)\n            totol_number+=t_number\n            predict_number+=p_number\n            predict_score+=p_score\n            \n    print(predict_number)\n    print(totol_number)\n    P=predict_score\/predict_number if predict_number>0 else 0.\n    R=predict_score\/totol_number if totol_number>0 else 0.\n    \n    f1=(2*P*R)\/(P+R) if (P+R)>0 else 0.\n    \n    return f1,P,R\n\n\ndef metric_fn_qa_aready(results,label_results):\n    totol_number=0\n    predict_number=0\n    predict_score=0\n    for item_id,feat in tqdm_notebook(label_results.items()):\n#             p_feat_dict=results[item_id]\n            p_feat=results[item_id]\n#             p_feat=set_dicts(p_feat)\n            print('real:',feat)\n            print('predict:',p_feat)\n            print('*'*50)\n            t_number,p_number,p_score=compute_score_select(p_feat,feat)\n            totol_number+=t_number\n            predict_number+=p_number\n            predict_score+=p_score\n            \n    print(predict_number)\n    print(totol_number)\n    P=predict_score\/predict_number if predict_number>0 else 0.\n    R=predict_score\/totol_number if totol_number>0 else 0.\n    \n    f1=(2*P*R)\/(P+R) if (P+R)>0 else 0.\n    \n    return f1,P,R\n        \n\ndef get_real_ans(results):\n    ans={}\n    p_feat=[]\n    for item_id,p_feat_dict in tqdm_notebook(results.items()):\n            if  isinstance(p_feat_dict,list):\n                return results\n            #\u83b7\u5f97\u4e00\u4e2atrigger\u4e00\u4e2a\u4e8b\u4ef6\n            p_feat=[]\n            for enent_type_role_trigger_position,result_dict in p_feat_dict.items():\n                dict_p={}\n                dict_p[(enent_type_role_trigger_position[0],enent_type_role_trigger_position[1])]=enent_type_role_trigger_position[2]\n                for k,v in result_dict.items():\n                    dict_p[k]=collections.Counter(v).most_common(1)[0][0]\n                #\u53ea\u6709trigger\n                if len(dict_p)==1:\n                    continue\n                p_feat.append(dict_p)\n            p_feat=set_dicts(p_feat)\n            ans[item_id]=p_feat\n    return ans\n        \n\ndef n_softmax(x):\n    x_row_max = x.max(axis=-1)\n    x_row_max = x_row_max.reshape(list(x.shape)[:-1]+[1])\n    x = x - x_row_max\n    x_exp = np.exp(x)\n    x_exp_row_sum = x_exp.sum(axis=-1).reshape(list(x.shape)[:-1]+[1])\n    softmax = x_exp \/ x_exp_row_sum\n    return softmax\n\n\ndef get_ans(starts,ends,feat):\n    max_len=feat.mapping_off+len(feat.mapping)\n    starts=n_softmax(np.array(starts[:max_len]))\n    ends=n_softmax(np.array(ends[:max_len]))\n    start_end, score = None, -1\n    for start, p_start in enumerate(starts):\n        for end, p_end in enumerate(ends):\n            if end >= start:\n                if p_start * p_end > score:\n                    start_end = (start, end)\n                    score = p_start * p_end\n    start, end = start_end\n    return start,end\n\n####\u89e3\u7801\u89c4\u5219\ndef rule_fn(p_answer,role,text,start_position):\n    #\u65e5\u671f\u89c4\u5219\n    if '\u65e5\u671f' in role:\n#         print(text[start_position:])\n#         print(p_answer)\n        ####\u5e74\u6708\u65e5\n        patten=r'^[[0-9]{4}\u5e74]{0,1}[0-9]{1,2}\u6708[0-9]{1,2}\u65e5'\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n        #\u6708\u65e5\n        patten=r'^[0-9]{1,2}\u6708[0-9]{1,2}\u65e5'\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n        #2019-1-21\n        patten=r\"^\\d{4}-\\d{1,2}-\\d{1,2}\"\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n        \n        #2019\/1\/21\n        patten=r\"^\\d{4}\/\\d{1,2}\/\\d{1,2}\"\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n\n        #2019.1.21\n        patten=r\"^\\d{4}\\.\\d{1,2}\\.\\d{1,2}\"\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n        #1.21\n        patten=r\"^\\d{1,2}\\.\\d{1,2}\"\n        res=re.findall(patten,text[start_position:])\n        if len(res)>0:\n            if text[start_position:].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n            \n            \n        #1.21\n        patten=r\"^\\d{4}-\\d{1,2}-\\d{1,2}\"\n        res=re.findall(patten,text[start_position:50])\n        if len(res)>0:\n            if text[start_position:50].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n            \n        #\u4e8c\u3007\u4e00\u4e94\u5e74\u5341\u4e8c\u6708\u5341\u4e94\u65e5\n        patten=r\"^\\S{4}\u5e74\\S{1,2}\u6708\\S{1,3}\u65e5\"\n        res=re.findall(patten,text[start_position:50])\n        if len(res)>0:\n            if text[start_position:50].startswith(res[0]) and res[0][0]==p_answer[0]:\n#                 print(p_answer)\n#                 print(res[0])\n#                 print('*'*50)\n                p_answer=res[0]\n                return p_answer\n\n#         print('return or')\n#         print('*'*50)\n        return p_answer\n    return p_answer\n        \n    \n        \ndef validation_fn(model,val_loader,val_features,is_test=False,val=True):\n    model.eval()\n    bar = tqdm_notebook(val_loader)\n    p_ss=[] #\u9884\u6d4b\u7684\u7b54\u6848\u4e0b\u6807\u6982\u7387\n    p_ee=[] #\u9884\u6d4b\u7684\u7b54\u6848\u672b\u5c3e\u6982\u7387\n    bar = tqdm_notebook(val_loader)\n    for i,(token_ids, seg_ids,labels,qa_start,qa_end) in enumerate(bar):\n        starts,ends = model(token_ids.cuda(DEVICE),seg_ids.cuda(DEVICE),labels.cuda(DEVICE),qa_start.cuda(DEVICE),qa_end.cuda(DEVICE),is_test=True)\n        starts=starts.detach().cpu().numpy()\n        ends=ends.detach().cpu().numpy()\n#         print()\n        p_ss.append(starts.reshape((len(token_ids),-1)))\n        p_ee.append(ends.reshape((len(token_ids),-1)))\n        \n    #\u83b7\u53d6\u7b54\u6848\u4e0b\u6807\n    p_ss=np.concatenate(p_ss)\n    p_ee=np.concatenate(p_ee)\n    \n    p_starts=[] #\u9884\u6d4b\u7684\u4e0b\u6807\n    p_ends=[]\n    for index in tqdm_notebook(range(p_ss.shape[0])):\n        st,et=get_ans(p_ss[index,:],p_ee[index,:],val_features[index])\n        p_starts.append(st)\n        p_ends.append(et)\n        \n    \n    results=collections.defaultdict(dict) #\u9884\u6d4b\u7684\u7ed3\u679c\n    label_results=collections.defaultdict(list) #\u771f\u5b9e\u7684\u7ed3\u679c\n    for index in tqdm_notebook(range(len(p_starts))):\n        p_st=p_starts[index] #\u9884\u6d4b\u7684\u5f00\u59cb\n        p_en=p_ends[index]  #\u9884\u6d4b\u7684\u7ed3\u675f\n        feat=val_features[index]\n        item_id=feat.item_id\n        text=feat.or_text\n        off=feat.mapping_off\n        mapping=feat.mapping #\u6620\u5c04\n        event_type_role=feat.event_type_role #(enent_type,role)\n        enents=feat.enents\n        role_trigger_position=feat.role_trigger_position\n        arguments=[]\n        starting=False\n        p_ans=[]\n        \n        #\u83b7\u53d6\u771f\u5b9e\u7ed3\u679c\n        if len(label_results[item_id])==0 and val:\n            for enent_type,role_argument_position,role_trigger_position in enents:\n                ans={}\n                for role,argument_position in role_argument_position.items():\n                    ans[(enent_type,role)]=argument_position[0]\n                label_results[item_id].append(ans)\n        #\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n        p_answer=None\n        if p_st-off>=0 and len(mapping)>p_en-off:\n            s=p_st-off\n            e=p_en-off\n            if s>=0:\n                p_answer=text[mapping[s][0]:mapping[e][-1]+1]\n                last_position=mapping[e][-1]\n                start_position=mapping[s][0]\n                p_answer=rule_fn(p_answer,event_type_role[1],text,start_position)\n        if p_answer and len(p_answer)>30:\n            p_answer=None\n        if p_answer:\n            key=(event_type_role[0],role_trigger_position[0],role_trigger_position[1],role_trigger_position[2])\n            if key in results[item_id]:\n                results[item_id][key][event_type_role].append(p_answer)\n            else:\n                d=collections.defaultdict(list)\n                d[event_type_role].append(p_answer)\n                results[item_id][key]=d\n            \n        \n    if not is_test:\n        re=metric_fn_qa(results,label_results)\n        return re[0],re[1],re[2],label_results,results\n    else:\n        return get_real_ans(results),results\n        \n    \ndef train_model(model,train_loader,val_loader,val_features,val_loader_recall=None,val_features_recall=None,accumulation_steps=2,early_stop_epochs=2,epochs=4,model_save_path='pytorch_zy_model_true.pkl'):  \n    \n    losses=[]\n    ########\u68af\u5ea6\u7d2f\u8ba1\n    batch_size = accumulation_steps*32\n    \n    ########\u65e9\u505c\n    early_stop_epochs=2\n    no_improve_epochs=0\n    \n    ########\u4f18\u5316\u5668 \u5b66\u4e60\u7387\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n    \n#     crf_p=[n for n, p in param_optimizer if str(n).find('crf')!=-1]\n#     crf_p_bias=[n for n, p in param_optimizer if (str(n).find('crf')!=-1 or str(n).find('zy')!=-1) and str(n).find('bias')!=-1 ]\n#     print(crf_p)\n#     print(crf_p_bias)\n    optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay) ], 'weight_decay': 0.8},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay) ], 'weight_decay': 0.0},\n#             {'params': [p for n, p in param_optimizer if n in crf_p], 'lr': 1e-4, 'weight_decay': 0.8},\n#             {'params': [p for n, p in param_optimizer if n in crf_p_bias], 'lr': 1e-4,'weight_decay': 0.0}\n            ]   \n    \n    optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n    \n    train_len=len(train_loader)\n    \n    best_vmetric=-np.inf\n    tloss = []\n    ans_losses=[]\n    for epoch in range(1,epochs+1):\n        model.train()\n        bar = tqdm_notebook(train_loader)\n        for i,(token_ids, seg_ids,labels,qa_start,qa_end) in enumerate(bar):\n            loss= model(token_ids.cuda(DEVICE),seg_ids.cuda(DEVICE),labels.cuda(DEVICE),qa_start.cuda(DEVICE),qa_end.cuda(DEVICE),is_test=False)\n            sloss=loss\n            sloss.backward()\n            tloss.append(loss.item())\n            ans_losses.append(loss.item())\n            if (i+1) % accumulation_steps == 0 or (i+1)==train_len:\n                optimizer.step()\n                optimizer.zero_grad()\n            bar.set_postfix(loss=np.array(tloss).mean(),ans_loss=np.array(ans_losses).mean())\n        \n        #val\n        val_f1,val_p,val_recall,val_label,_=validation_fn(model,val_loader,val_features)\n        if val_features_recall:\n            val_recall_p=validation_fn(model,val_loader_recall,val_features_recall,is_test=False,val=False)\n            s=metric_fn_qa(val_recall_p[-1],val_label)\n            print('recall f1:',str(s))\n            losses.append(str(s))\n        losses.append( 'train_loss:%.5f, f1: %.5f, precision: %.5f, recall: %.5f, best f1: %.5f\\n' %\n            (np.array(tloss).mean(),val_f1, val_p, val_recall, best_vmetric))\n        print(losses[-1])\n        if val_f1>=best_vmetric:\n            torch.save(model.state_dict(),model_save_path)\n            best_vmetric=val_f1\n            no_improve_epochs=0\n            print('improve save model!!!')\n        else:\n            no_improve_epochs+=1\n        if no_improve_epochs==early_stop_epochs:\n            print('no improve score !!! stop train !!!')\n            break\n    return losses","af9f3a20":"# train_loader,train_features=get_loader(train_data,batch_size=16,train_mode=True,train_val=True)\n# val_loader,val_features=get_loader(valid_data,batch_size=8,val_mode=True,train_val=True,recall=False)\n# val_loader_recall,val_features_recall=get_loader(valid_data,batch_size=8,val_mode=True,train_val=True,recall=True)","a618df6e":"# print(len(train_features))\n# print(len(val_features))\n# print(len(val_features_recall))","84faa0f4":"# model=zy_Model(num_labels).cuda(DEVICE)\n# losses=train_model(model,train_loader,val_loader,val_features,val_loader_recall,val_features_recall,accumulation_steps=2,early_stop_epochs=2,epochs=7,model_save_path='right_model_ans_label.pkl')","57d58962":"# for l in losses:\n#     print(l)","2d9dbf4d":"# model=zy_Model(num_labels).cuda(DEVICE)\n# # model_save_path='..\/input\/ee-model\/right_model_ans_label.pkl'\n# model_save_path='right_model_ans_label.pkl'\n# model.load_state_dict(torch.load(model_save_path))","cbe86215":"test_loader,test_features=get_loader(test_data,batch_size=8,test_mode=True,train_val=True,recall=True)","534a1c97":"len(test_features)","ce5ce00b":"\ndef predict_to_file_qa(results,out_file):\n    \"\"\"\u9884\u6d4b\u7ed3\u679c\u5230\u6587\u4ef6\uff0c\u65b9\u4fbf\u63d0\u4ea4\n    \"\"\"\n    fw =open(out_file, 'w', encoding='utf-8')\n    for item_id,vs in results.items():\n        l={}\n        l['doc_id']=item_id\n        events=[]\n        for v in vs:\n            single_dict={}\n            for k,vi in v.items():\n                single_dict['event_type']=k[0]\n#                 single_dict[k[1]]=collections.Counter(vi).most_common(1)[0][0]\n                single_dict[k[1]]=vi\n            events.append(single_dict)\n        l['events']=events\n#         print(l)\n        l = json.dumps(l, ensure_ascii=False)\n        fw.write(l + '\\n')\n    fw.close()","7809b20f":"from sklearn.model_selection import KFold\nimport pickle\nFOLD=5\nkf = KFold(n_splits=FOLD, shuffle=True,random_state=2019)\nlog_losses=[]\n\nfor i,(train_index , test_index) in enumerate(kf.split(train_data)):\n    print(str(i+1),'*'*50)\n    if i>0:\n        continue\n    tra=[train_data[i] for i in train_index]\n    valid=[train_data[i] for i in test_index]\n    print(len(tra))\n    print(len(valid))\n    \n    val_loader_recall,val_features_recall=get_loader(valid,batch_size=8,val_mode=True,train_val=True,recall=True)\n    valid_loader,valid_features=get_loader(valid,batch_size=8,val_mode=True,train_val=True)\n#     tra_loader,tra_features=get_loader(tra,batch_size=16,train_mode=True,train_val=True)\n#     val_loader_recall=None\n#     val_features_recall=None\n    model=zy_Model().cuda(DEVICE)\n#     losses=train_model(model,tra_loader,valid_loader,valid_features,val_loader_recall,val_features_recall,accumulation_steps=2,early_stop_epochs=2,epochs=7,model_save_path='cv_recall{}.pkl'.format(i+1))\n#     log_losses.extend(losses)\n#     \u52a0\u8f7d\u6700\u597d\u6a21\u578b\n    model_save_path='..\/input\/ccks-ee2-513\/cv_recall{}.pkl'.format(i+1)\n#     model_save_path='cv_recall{}.pkl'.format(i+1)\n    model.load_state_dict(torch.load(model_save_path))\n    \n        \n        \n    f1,_,_,val_label,_=validation_fn(model,valid_loader,valid_features,is_test=False)\n    print(f1)\n    _,val_p=validation_fn(model,val_loader_recall,val_features_recall,is_test=True)\n    print('val_recall:',metric_fn_qa(val_p,val_label))\n    \n    \n    val_preds=validation_fn(model,valid_loader,valid_features,is_test=True)\n    with open('val_516{}.pkl'.format(i+1),'wb') as f:\n        pickle.dump(val_preds,f)\n        \n    test_preds,test_preds_or=validation_fn(model,test_loader,test_features,is_test=True)\n    \n    with open('test_518{}.pkl'.format(i+1),'wb') as f:\n        pickle.dump(test_preds_or,f)\n    with open('test_518_or{}.pkl'.format(i+1),'wb') as f:\n        pickle.dump(test_preds_or,f)\n\n    predict_to_file_qa(test_preds,'sub_test_best_525_{}.json'.format(i+1))\n\n    print(str(i+1),'-'*50)\n    log_losses.append('*'*50)\n    torch.cuda.empty_cache()\n#     break\n#     if i+1>=3:\n#         break\n#     break","2b0a7b77":"# for l in log_losses:\n#     print(l)","101c6cdf":"#     f1,_,_,val_label,_=validation_fn(model,valid_loader,valid_features,is_test=False)\n#     print(f1)\n#     _,val_p=validation_fn(model,val_loader_recall,val_features_recall,is_test=True)\n#     print('val_recall:',metric_fn_qa(val_p,val_label))","f61e5b97":"# for l in log_losses:\n#     print(l)","4e69eed6":"# val_label","1b3102b7":"# test_preds","d6293c5f":"# train","7a58c758":"### model","f853302f":"### load data","0c10d77c":"### dataloader","8da59002":"### add ","69211604":"### cv "}}