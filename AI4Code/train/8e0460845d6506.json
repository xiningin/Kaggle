{"cell_type":{"4d7cdefb":"code","82799ad6":"code","f69aebc0":"code","f8634153":"code","2661ca3f":"code","8cdb36cb":"code","1efde3b7":"code","cc789cfb":"code","edb73847":"code","7a2111f9":"code","6dc5704f":"code","43582255":"code","5210c3b0":"code","3354d300":"code","39f988dc":"code","8e3fc7df":"code","42f662bd":"code","2d2ead53":"code","035e955b":"code","cb18220a":"code","975ccbfa":"code","f436dab6":"code","55caaa77":"code","846b2ed6":"code","efa55fe6":"code","9c6d34a0":"code","966ce6f4":"markdown","d6cbba0a":"markdown","b93fd5a8":"markdown","ca4d1be7":"markdown","217c33a2":"markdown","87dd35b2":"markdown","feab18df":"markdown","2e26a85d":"markdown","5e995eef":"markdown","a93bea01":"markdown","d1b7530b":"markdown","d7f246ad":"markdown","d29ab584":"markdown","c18d46b7":"markdown"},"source":{"4d7cdefb":"!pip install -q --upgrade wandb\n!pip install -q grad-cam\n!pip install -q ttach\n!pip install  timm","82799ad6":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","f69aebc0":"train = pd.read_csv('..\/input\/ptbxl-ecg-preprocessed\/ptbxl_train.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/ptbxl-ecg-preprocessed\/ptbxl_data_melspectogram\/{}.npy\".format(image_id)\n\n\nclean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]\n\n\ntrain['file_path'] = train['mel_filename'].apply(get_train_file_path)\ntrain['diagnostic_superclass'] = train['diagnostic_superclass'].apply(clean_tags)\n\ndisplay(train.head())","f8634153":"train.columns","2661ca3f":"train[\"diagnostic_superclass\"]","8cdb36cb":"for i in range(5):\n    image = np.load(train.loc[i, 'file_path'])\n    target = train.loc[i, 'diagnostic_superclass']\n    plt.imshow(image)\n    plt.title(f\"target: {target}\")\n    plt.show()","1efde3b7":"image.shape","cc789cfb":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","edb73847":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nmlb.fit(train[\"diagnostic_superclass\"].tolist())\nmlb.classes_.tolist()","7a2111f9":"train_labels = mlb.transform(train[\"diagnostic_superclass\"].tolist())\ntrain[mlb.classes_.tolist()] = train_labels","6dc5704f":"train.head()","43582255":"class CFG:\n    apex=False\n    debug=False\n    print_freq=100\n    image_size=224\n    num_workers=8\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n    epochs=20\n    # CosineAnnealingLR params\n    cosanneal_params={\n        'T_max':3,\n        'eta_min':1e-4,\n        'last_epoch':-1\n    }\n    #ReduceLROnPlateau params\n    reduce_params={\n        'mode':'min',\n        'factor':0.2,\n        'patience':4,\n        'eps':1e-6,\n        'verbose':True\n    }\n    # CosineAnnealingWarmRestarts params\n    cosanneal_res_params={\n        'T_0':3,\n        'eta_min':1e-6,\n        'T_mult':1,\n        'last_epoch':-1\n    }\n    onecycle_params={\n        'pct_start':0.1,\n        'div_factor':1e2,\n        'max_lr':1e-3\n    }\n    batch_size=32\n    lr=1e-3\n    weight_decay=1e-2\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    target_size=5\n    nfolds=9\n    trn_fold=[1, 2, 3, 4, 5]\n    target_col=['CD', 'HYP', 'MI', 'NORM', 'STTC']\n    preds_col=['pred_CD', 'pred_HYP', 'pred_MI', 'pred_NORM', 'pred_STTC']\n    model_name='tf_efficientnet_b3'     #'vit_base_patch32_224_in21k' 'resnext50_32x4d' 'tf_efficientnet_b3'\n    train=True\n    grad_cam=False    \n    early_stop=True\n    fc_dim=512\n    margin=0.5\n    scale=30\n    early_stopping_steps=5\n    seed=42\n    \nif CFG.debug:\n    CFG.epochs=1\n    folds=train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","5210c3b0":"# ====================================================\n# Library\n# ====================================================\nimport sys\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\n# sometimes, you will have images without an ending bit\n# this takes care of those kind of (corrupt) images\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.optim.optimizer import Optimizer\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","3354d300":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_key\")\n\nimport wandb\nwandb.login(key=wandb_api)\n\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\nrun = wandb.init(project=\"PTBXL_ECG PFE\", \n                 name=\"exp2 melspectogram\",\n                 config=class2dict(CFG),\n                 group=CFG.model_name,\n                 job_type=\"train\")","39f988dc":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred, average=\"macro\")\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","8e3fc7df":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = np.load(file_path)\n            \n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n\n    \nclass GradCAMDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.image_ids = df['Id'].values\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = get_transforms(data='valid')\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        file_path = self.file_names[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        vis_image = cv2.resize(image, (CFG.size, CFG.size)).copy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image_id, image, vis_image, label","42f662bd":"def get_transforms(*, data='train'):\n    '''\n    Return Augmented Image tensor for training dataset\n    '''\n    \n    if data == 'train':\n        return A.Compose(\n            [\n                A.Resize(CFG.image_size,CFG.image_size),\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.Rotate(limit=180, p=0.7),\n                #A.RandomBrightness(limit=0.6, p=0.5),\n                #A.Cutout(\n                    #num_holes=10, max_h_size=12, max_w_size=12,\n                    #fill_value=0, always_apply=False, p=0.5\n                #),\n                #A.ShiftScaleRotate(\n                    #shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n                #),\n                ToTensorV2(p=1.0),\n            ]\n        )\n    \n    elif data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","2d2ead53":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(5):\n    plt.figure(figsize=(16,12))\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","035e955b":"image.shape","cb18220a":"#credit : https:\/\/github.com\/Yonghongwei\/Gradient-Centralization\n\ndef centralized_gradient(x, use_gc=True, gc_conv_only=False):\n    if use_gc:\n        if gc_conv_only:\n            if len(list(x.size())) > 3:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n        else:\n            if len(list(x.size())) > 1:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n    return x\n\n\nclass Ranger(Optimizer):\n\n    def __init__(self, params, lr=1e-3,                       # lr\n                 alpha=0.5, k=5, N_sma_threshhold=5,           # Ranger options\n                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n                 use_gc=True, gc_conv_only=False, gc_loc=True\n                 ):\n\n        # parameter checks\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f'Invalid slow update rate: {alpha}')\n        if not 1 <= k:\n            raise ValueError(f'Invalid lookahead steps: {k}')\n        if not lr > 0:\n            raise ValueError(f'Invalid Learning Rate: {lr}')\n        if not eps > 0:\n            raise ValueError(f'Invalid eps: {eps}')\n\n        # parameter comments:\n        # beta1 (momentum) of .95 seems to work better than .90...\n        # N_sma_threshold of 5 seems better in testing than 4.\n        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n\n        # prep defaults and init torch.optim base\n        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n        super().__init__(params, defaults)\n\n        # adjustable threshold\n        self.N_sma_threshhold = N_sma_threshhold\n\n        # look ahead params\n\n        self.alpha = alpha\n        self.k = k\n\n        # radam buffer for state\n        self.radam_buffer = [[None, None, None] for ind in range(10)]\n\n        # gc on or off\n        self.gc_loc = gc_loc\n        self.use_gc = use_gc\n        self.gc_conv_only = gc_conv_only\n        # level of gradient centralization\n        #self.gc_gradient_threshold = 3 if gc_conv_only else 1\n\n        print(\n            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n        if (self.use_gc and self.gc_conv_only == False):\n            print(f\"GC applied to both conv and fc layers\")\n        elif (self.use_gc and self.gc_conv_only == True):\n            print(f\"GC applied to conv layers only\")\n\n    def __setstate__(self, state):\n        print(\"set state called\")\n        super(Ranger, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        # note - below is commented out b\/c I have other work that passes back the loss as a float, and thus not a callable closure.\n        # Uncomment if you need to use the actual closure...\n\n        # if closure is not None:\n        #loss = closure()\n\n        # Evaluate averages and grad, update param tensors\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n\n                if grad.is_sparse:\n                    raise RuntimeError(\n                        'Ranger optimizer does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]  # get state dict for this param\n\n                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n                    # if self.first_run_check==0:\n                    # self.first_run_check=1\n                    #print(\"Initializing slow buffer...should not see this at load from saved model!\")\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n\n                    # look ahead weight storage now in state dict\n                    state['slow_buffer'] = torch.empty_like(p.data)\n                    state['slow_buffer'].copy_(p.data)\n\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n                        p_data_fp32)\n\n                # begin computations\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                # GC operation for Conv layers and FC layers\n                # if grad.dim() > self.gc_gradient_threshold:\n                #    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n                if self.gc_loc:\n                    grad = centralized_gradient(grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                state['step'] += 1\n\n                # compute variance mov avg\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n                # compute mean moving avg\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n\n                buffered = self.radam_buffer[int(state['step'] % 10)]\n\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 \/ (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * \\\n                        state['step'] * beta2_t \/ (1 - beta2_t)\n                    buffered[1] = N_sma\n                    if N_sma > self.N_sma_threshhold:\n                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) \/ (N_sma_max - 4) * (\n                            N_sma - 2) \/ N_sma * N_sma_max \/ (N_sma_max - 2)) \/ (1 - beta1 ** state['step'])\n                    else:\n                        step_size = 1.0 \/ (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                # if group['weight_decay'] != 0:\n                #    p_data_fp32.add_(-group['weight_decay']\n                #                     * group['lr'], p_data_fp32)\n\n                # apply lr\n                if N_sma > self.N_sma_threshhold:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    G_grad = exp_avg \/ denom\n                else:\n                    G_grad = exp_avg\n\n                if group['weight_decay'] != 0:\n                    G_grad.add_(p_data_fp32, alpha=group['weight_decay'])\n                # GC operation\n                if self.gc_loc == False:\n                    G_grad = centralized_gradient(G_grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                p_data_fp32.add_(G_grad, alpha=-step_size * group['lr'])\n                p.data.copy_(p_data_fp32)\n\n                # integrated look ahead...\n                # we do it at the param level instead of group level\n                if state['step'] % group['k'] == 0:\n                    # get access to slow param tensor\n                    slow_p = state['slow_buffer']\n                    # (fast weights - slow weights) * alpha\n                    slow_p.add_(p.data - slow_p, alpha=self.alpha)\n                    # copy interpolated weights to RAdam param tensor\n                    p.data.copy_(slow_p)\n\n        return loss","975ccbfa":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=1)\n        \n        if cfg.model_name == 'resnext50_32x4d':\n            self.n_features = self.backbone.fc.in_features\n            self.model.fc = nn.Linear(self.n_features, self.cfg.target_size)\n            \n        elif 'nfnet' in cfg.model_name:\n            self.in_features = self.backbone.head.fc.in_features\n            self.model.head.fc = nn.Linear(self.n_features, self.cfg.target_size)\n        \n        elif cfg.model_name.split('_')[1] == \"efficientnet\":\n            self.n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(self.n_features, self.cfg.target_size)\n            \n        elif cfg.model_name.split('_')[0] == 'vit':\n            n_features = self.model.head.in_features\n            self.model.head = nn.Linear(n_features, cfg.target_size, bias=True)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","f436dab6":"#model = timm.create_model(CFG.model_name, pretrained=False)\n#final_in_features = model.fc.in_features\n#final_in_features","55caaa77":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    if CFG.apex:\n        scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG.apex:\n            with autocast():\n                y_preds = model(images)\n                loss = criterion(y_preds, labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        if CFG.apex:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.apex:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.6f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)\/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        wandb.log({f\"[fold{fold}] loss\": losses.val,\n                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)\/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","846b2ed6":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['strat_fold'] != fold].index\n    val_idx = folds[folds['strat_fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.reduce_params)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, pretrained=False)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = nn.BCEWithLogitsLoss()\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                   f\"[fold{fold}] score\": score})\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n    \n    valid_folds[CFG.preds_col] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","efa55fe6":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df[CFG.preds_col].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.nfolds):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n    \n    if CFG.grad_cam:\n        N = 5\n        wandb_table = wandb.Table(columns=[\"id\", \"target\", \"prob\", \"image\", \"grad_cam_image\"])\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                # load model\n                model = CustomModel(CFG, pretrained=False)\n                state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth', \n                                   map_location=torch.device('cpu'))['model']\n                model.load_state_dict(state)\n                model.to(device)\n                model.eval()\n                # load oof\n                oof = pd.read_csv(OUTPUT_DIR+'oof_df.csv')\n                oof = oof[oof['fold'] == fold].reset_index(drop=True)\n                # grad-cam (oof ascending=False)\n                count = 0\n                oof = oof.sort_values('preds', ascending=False)\n                valid_dataset = GradCAMDataset(oof)\n                for i in range(len(valid_dataset)):\n                    image_id, x_tensor, img, label = valid_dataset[i]\n                    result = get_grad_cam(model, device, x_tensor, img, label, plot=True)\n                    if result[\"vis\"] is not None:\n                        count += 1\n                        wandb_table.add_data(image_id, \n                                             result[\"label\"], \n                                             result[\"prob\"], \n                                             wandb.Image(result[\"img\"]), \n                                             wandb.Image(result[\"vis\"]))\n                    if count >= N:\n                        break\n                # grad-cam (oof ascending=True)\n                count = 0\n                oof = oof.sort_values('preds', ascending=True)\n                valid_dataset = GradCAMDataset(oof)\n                for i in range(len(valid_dataset)):\n                    image_id, x_tensor, img, label = valid_dataset[i]\n                    result = get_grad_cam(model, device, x_tensor, img, label, plot=True)\n                    if result[\"vis\"] is not None:\n                        count += 1\n                        wandb_table.add_data(image_id, \n                                             result[\"label\"], \n                                             result[\"prob\"], \n                                             wandb.Image(result[\"img\"]), \n                                             wandb.Image(result[\"vis\"]))\n                    if count >= N:\n                        break\n        wandb.log({'grad_cam': wandb_table})\n    \n    wandb.finish()","9c6d34a0":"if __name__ == '__main__':\n    main()","966ce6f4":"# Train loop","d6cbba0a":"# Wandb configuration","b93fd5a8":"# Model","ca4d1be7":"# Dataset","217c33a2":"# Directory settings","87dd35b2":"# Utils","feab18df":"# Library","2e26a85d":"# Helper Functions","5e995eef":"# Data Loading","a93bea01":"# Quick EDA","d1b7530b":"# Data preparation","d7f246ad":"# Transforms","d29ab584":"# Ranger implementation","c18d46b7":"# Configuration"}}