{"cell_type":{"7dcbc062":"code","a7fac446":"code","e8f37d60":"code","f0eaca55":"code","f3943936":"code","2d0d2374":"code","8f7c9131":"code","785d769c":"code","0c988f19":"code","444803ec":"code","dc8b7f90":"code","c902a82c":"code","0069affd":"code","12b5928d":"code","b230bfdc":"code","c6f877e9":"code","81c609f1":"code","19e22a2e":"code","f24e66f8":"code","cc8b951a":"code","1e0235cf":"code","093df718":"code","8fd21aff":"code","029b2f0f":"markdown","9e62e068":"markdown","ecdcffd1":"markdown"},"source":{"7dcbc062":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a7fac446":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","e8f37d60":"#checking the shape of the train and test dataset\n\nprint(\"the shape of the train is\"+str(train.shape))\n\nprint(\"the shape of the test is\"+str(test.shape))","f0eaca55":"#checking any n\/a or null values in the dataset\nprint(\"The number of N\/A entries in the train dataset are\"+\" \"+str(train.isna().sum().sum()))\nprint(\"The number of N\/A entries in the test dataset are\"+\" \"+str(test.isna().sum().sum()))","f3943936":"train.columns[:784:785]","2d0d2374":"train[\"label\"].value_counts()","8f7c9131":"#importing the tensorflow and keras sequential model\nimport tensorflow as tf\nfrom keras.models import Sequential","785d769c":"#saperating the training data and their labels\nx_train=train.drop([\"label\"],axis=1)\ny_train=train[\"label\"]\n#now checking the shape of saperated set\nx_train.shape,y_train.shape\n#delting the train data now as we do not need tis data\ndel train","0c988f19":"#normalizing the data for faster processing \nx_train=x_train\/255.0\ntest=test\/255.0","444803ec":"#changing the shape of the dataset to feed it to keras model\n#1 is representing that the image is grayscale\nx_train=x_train.values.reshape(x_train.shape[0],28,28,1)\ntest=test.values.reshape(test.shape[0],28,28,1)\n#now checking the shape after reshaping\nprint(\"the shape of the train is\"+str(x_train.shape))\n\nprint(\"the shape of the test is\"+str(test.shape))","dc8b7f90":"#from sklearn.utils import to_categorical\nfrom keras.utils.np_utils import to_categorical\ny_train=to_categorical(y_train,10)","c902a82c":"#now splitting the data into test and train\nfrom sklearn.model_selection import train_test_split\nx_train1,x_val,y_train1,y_val=train_test_split(x_train,y_train,test_size=.10,random_state=42)\nx_train1.shape,y_train1.shape,x_val.shape,y_val.shape","0069affd":"#now setting the cnn model\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras import backend as K","12b5928d":"model=Sequential()\n#first conv2d layer\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\n#second-con2D layer\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(.25))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dropout(.5))\nmodel.add(Dense(10,activation=\"softmax\"))","b230bfdc":"#now we will define the optimizer function I am using SGD\nmodel.compile(loss=\"categorical_crossentropy\",\n             optimizer=SGD(.01),\n             metrics=[\"accuracy\"])\nmodel.summary","c6f877e9":"epochs1 = 30 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size1 = 86","81c609f1":"history = model.fit(x_train1, y_train1, batch_size = batch_size1, epochs = epochs1, \n         validation_data = (x_val, y_val), verbose = 2)","19e22a2e":"#prducing the results before the augmentation\n# predict results\n#results = model.predict(test)\n#selecting the final probability as this will give you the probability of the numbers\n#Final_pred = results.argmax(axis=1)\n#creating the csv file for the submission\n#Images=np.arange(1,28001)\n#submission=pd.DataFrame([Images,Final_pred]).T\n#submission.rename({0:\"ImageId\",1:\"Label\"})\n#submission.to_csv(\"Mnist_Kaggle_submission.csv\",header=[\"ImageId\",\"Label\"],index=False)\n","f24e66f8":"#now we will do data augmentation\nfrom keras.preprocessing.image import ImageDataGenerator","cc8b951a":"datagen=ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=10,\n    zoom_range=.1,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    horizontal_flip=False,\n    vertical_flip=False)\ndatagen.fit(x_train)","1e0235cf":"from keras.callbacks import ReduceLROnPlateau","093df718":"final_model=model.fit_generator(datagen.flow(x_train1,y_train1,batch_size=batch_size1),\n                   epochs=epochs1,\n                   validation_data=(x_val,y_val),\n                   verbose=2,\n                   steps_per_epoch=x_train1.shape[0],\n                   )","8fd21aff":"# predict results\nresults = model.predict(test)\n#selecting the final probability as this will give you the probability of the numbers\nFinal_pred = results.argmax(axis=1)\n#creating the csv file for the submission\nImages=np.arange(1,28001)\nsubmission=pd.DataFrame([Images,Final_pred]).T\nsubmission.rename({0:\"ImageId\",1:\"Label\"})\nsubmission.to_csv(\"Mnist_Kaggle_submission.csv\",header=[\"ImageId\",\"Label\"],index=False)\n","029b2f0f":"now we will be converting the y_train into the format which keras understand i.e. One hot encoding","9e62e068":"So this dataset is neat and clean.","ecdcffd1":"conv2d layer->conv2d laYer->poolin2d->Dropout->Flatten->Dense ->Dropout->Dense"}}