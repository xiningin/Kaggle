{"cell_type":{"683c0b41":"code","0d3aaaec":"code","d214fde6":"code","52125254":"code","86d60e17":"code","6c497597":"code","43eef258":"code","cab27119":"code","62652493":"code","017660d0":"code","136a3781":"code","30ce4b62":"code","416f4a26":"code","a3114926":"code","cecaa558":"code","718be302":"code","9de4b91b":"code","2c7ad1c8":"code","cd506db5":"code","fc964814":"code","f35978b1":"code","038d8dc9":"code","7198cfab":"code","126016b8":"code","64fde12f":"code","ca27a9f4":"code","1d966578":"code","5bd7d65d":"code","ae008ed7":"code","72b6b1de":"code","6d82f1da":"code","324e4825":"code","35859232":"code","418a4933":"code","0092dfaf":"code","fdbc679e":"code","64235f49":"code","8de39a12":"code","734ff495":"code","6c5cf61a":"code","ccd1d815":"code","d25bcef9":"code","8a9f246d":"code","bbc716d3":"code","4de6d228":"code","ceb55690":"code","97112c05":"code","ab9ebe19":"code","68e18491":"code","e2041675":"code","0ebb00fa":"code","221207df":"code","62d4bd7a":"code","a159de98":"code","38983277":"code","6545299c":"code","51daa8c0":"code","375079c5":"code","2e1912d8":"code","81aa6cd3":"code","22f7b57c":"markdown","fcf0ca8e":"markdown","eeaab140":"markdown","d7267192":"markdown","c51bc87d":"markdown","121a84c3":"markdown","8d5b6e6c":"markdown","7698a55e":"markdown","6121d1ea":"markdown","f8518967":"markdown","d4a33824":"markdown","8665fac2":"markdown","0adc1825":"markdown","2caa6f71":"markdown","f93f3919":"markdown","3eed82bd":"markdown","3cfc813b":"markdown","2692ce99":"markdown","34219ca4":"markdown","b7bc5c6d":"markdown","8886e387":"markdown","6f7bb82f":"markdown","84178495":"markdown","c508b215":"markdown","154d6608":"markdown","7e074f39":"markdown","9bf8ecce":"markdown","ef07851f":"markdown","d959da8d":"markdown","55a4b982":"markdown","c57346ea":"markdown","d36d01e3":"markdown","c70e3c93":"markdown","2b1b9a87":"markdown","9bf782fe":"markdown","b8dcc373":"markdown","13b23ab0":"markdown","46f4a2a0":"markdown","98a811e4":"markdown","b566f03e":"markdown","6cddb069":"markdown","1e0b974b":"markdown","45768782":"markdown","4422e658":"markdown","f770322c":"markdown","5538b58b":"markdown","eaf1574d":"markdown","370551d5":"markdown","a415a2b1":"markdown","13fe556f":"markdown","db201636":"markdown","fda62fac":"markdown","b301fff3":"markdown","c1ad6590":"markdown","42082a81":"markdown","5cee4868":"markdown","e3c3b736":"markdown","8e3e02ae":"markdown","0c9c51ea":"markdown","1d815b7b":"markdown","d025f3a5":"markdown"},"source":{"683c0b41":"# Load Data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest =  pd.read_csv('..\/input\/test.csv')","0d3aaaec":"train.head(10)","d214fde6":"print(train.shape)\nprint(train.apply(lambda x: sum(x.isnull()),axis=0))","52125254":"plt.subplots(figsize=(12,8))\nsns.countplot('Survived',data=train).set_title('Survived')","86d60e17":"train['Age'].fillna(train['Age'].median(),inplace =True)","6c497597":"figure = plt.figure(figsize=(15,8))\nplt.hist([train[train['Survived']==1]['Age'], train[train['Survived']==0]['Age']], stacked=True, color = ['b','g'],bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.legend()","43eef258":"print(train[['Sex','Survived']].groupby(['Sex']).count())\nprint('----------------------------')\nprint(train.groupby(['Sex','Survived']).size())\nplt.subplots(figsize=(12,8))\nsns.countplot('Sex',hue='Survived',data =train)","cab27119":"plt.subplots(figsize=(15,10))\nsns.swarmplot(x='Age',y='Sex',hue='Survived',data=train)","62652493":"plt.hist([train[train['Survived']==1]['Fare'],train[train['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nprint(train['Fare'].skew())","017660d0":"train[\"Fare\"] = train[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\nplt.hist([train[train['Survived']==1]['Fare'],train[train['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nprint(train['Fare'].skew())","136a3781":"plt.subplots(figsize = (15,8))\nsns.countplot('Pclass',hue='Survived',data =train)\nsns.factorplot(x='Age',y='Sex',hue='Survived',row='Pclass',data=train,kind='violin',split=True,size=4,aspect=4)","30ce4b62":"fig, ax = plt.subplots(3,1,figsize = (15,8))\nsns.countplot('Parch',hue='Survived',data =train,ax=ax[0])\nsns.countplot('SibSp',hue='Survived',data=train,ax=ax[1])\ntrain['Fsize'] = train['Parch']+train['SibSp']\nsns.countplot('Fsize',hue='Survived',data=train,ax=ax[2])","416f4a26":"print(train.Fsize.value_counts())","a3114926":"train['Embarked'] = train['Embarked'].fillna(method='ffill')","cecaa558":" plt.subplots(figsize = (15,8))\nsns.countplot('Embarked',hue='Survived',data=train)\n plt.subplots(figsize = (15,8))\nsns.barplot(x='Embarked',y='Survived',data=train)","718be302":"train_dataset = pd.read_csv('..\/input\/train.csv')\ntest_dataset = pd.read_csv('..\/input\/test.csv')\n\ntarget = train_dataset.Survived\ntrain_dataset.drop('Survived',axis=1,inplace=True)\n\nall = pd.concat([train_dataset,test_dataset])","9de4b91b":"all.shape","2c7ad1c8":"rest = []","cd506db5":"all.dtypes","fc964814":"categorical = [cname for cname in all if all[cname].dtype == 'object']\nnumerical = [cname for cname in all if all[cname].dtype in ['float64','int64']]","f35978b1":"all['Title'] = all['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\nprint(all.Title.value_counts())\nplt.subplots(figsize=(15,8))\nsns.countplot('Title',data= all)","038d8dc9":"all['Title']= all.Title.replace(['Rev', 'Dr', 'Col', 'Major', 'Mlle',\n       'Ms', 'Sir', 'Dona', 'Capt', 'Lady', 'Jonkheer', 'the Countess', 'Don',\n       'Mme'],'Rest')\nall.Title.value_counts()","7198cfab":"all.drop('Name',axis=1,inplace =True)\nt_dummy = pd.get_dummies(all.Title,prefix='Title')\nall = pd.concat([all,t_dummy],axis=1)\n\n# check = later i drop title\nrest.append('Title')","126016b8":"all.shape","64fde12f":"all['Sex'] = all.Sex.map({'male':1,'female':0})","ca27a9f4":"all.Ticket","1d966578":"Ticket = []\nfor i in list(all.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"UnKnown\")\n        \nall[\"Ticket\"] = Ticket","5bd7d65d":"all.Ticket.value_counts()","ae008ed7":"ticket_dummy = pd.get_dummies(all.Ticket,prefix='Ticket')\nall = pd.concat([all,ticket_dummy],axis=1)\nrest.append('Ticket')\nall.shape","72b6b1de":"all[\"Cabin\"].isnull().sum()","6d82f1da":"all.Cabin.describe()","324e4825":"all.fillna('U0')\nall['Cabin'] = [str(cname)[0] for cname in all.Cabin ]","35859232":"all.Cabin.value_counts()","418a4933":"c_dummy = pd.get_dummies(all.Cabin, prefix='Cabin')\nall = pd.concat([all,c_dummy],axis=1)\nrest.append('Cabin')","0092dfaf":"all.shape","fdbc679e":"all.Embarked.isnull().sum()","64235f49":"all.Embarked.value_counts()","8de39a12":"# Fill it up with the most S.\nall.Embarked.fillna('S',inplace=True)\ne_dummy = pd.get_dummies(all.Embarked,prefix='Embarked')\nall = pd.concat([all,e_dummy],axis=1)\nrest.append('Embarked')","734ff495":"mean = train_dataset[\"Age\"].mean()\nstd = test_dataset[\"Age\"].std()\nis_null = all[\"Age\"].isnull().sum()\n# compute random numbers between the mean, std and is_null\nrand_age = np.random.randint(mean - std, mean + std, size = is_null)\n# fill NaN values in Age column with random values generated\nage_slice = all[\"Age\"].copy()\nage_slice[np.isnan(age_slice)] = rand_age\nall[\"Age\"] = age_slice\nall[\"Age\"] = all[\"Age\"].astype(int)","6c5cf61a":"all['Fsize'] = all['SibSp']+all['Parch'] +1 # Including self\nplt.subplots(figsize=(15,8))\nsns.countplot('Fsize',data=all)","ccd1d815":"all['alone'] = all['Fsize'].map(lambda x: 1 if x == 1 else 0)\nall['not alone'] = all['Fsize'].map(lambda x: 1 if x >1 else 0)","d25bcef9":"rest.append(['Fsize','SibSp','Parch'])","8a9f246d":"all['Fare'].fillna(all.Fare.mean())\nall['Fare_loc'] = all.Fare.map(lambda i: np.log(i) if i > 0 else 0)","bbc716d3":"all.drop('PassengerId',inplace=True,axis=1)","4de6d228":"rest = ['Title', 'Ticket', 'Cabin', 'Embarked','Fsize', 'SibSp', 'Parch','Fare']","ceb55690":"all.drop(rest,inplace=True,axis=1)","97112c05":"all.shape","ab9ebe19":"from xgboost import XGBClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold,cross_val_score,GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel # Meta-transformer for selecting features based on importance weights\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier","68e18491":"train = all.head(891)\ntest = all.iloc[891:]","e2041675":"Fold= StratifiedKFold(n_splits=10)\n\ngr_model = GradientBoostingClassifier(random_state=2)\nxg_model = XGBClassifier(random_state=2)\nrf_model = RandomForestClassifier(random_state=2)\n\ngr_model.fit(train,target)\nxg_model.fit(train,target)\nrf_model.fit(train,target)\n\nprint(cross_val_score(gr_model,train,target,scoring='accuracy',cv=Fold).mean())\nprint(cross_val_score(xg_model,train,target,scoring='accuracy',cv=Fold).mean())\nprint(cross_val_score(rf_model,train,target,scoring='accuracy',cv=Fold).mean())","0ebb00fa":"GradientBoosting = pd.DataFrame()\nGradientBoosting['feature'] = train.columns\nGradientBoosting['importance'] = gr_model.feature_importances_\nGradientBoosting.sort_values(by=['importance'], ascending=True, inplace=True)\nGradientBoosting.set_index('feature', inplace=True)\nGradientBoosting.plot(kind='barh', figsize=(20, 20))","221207df":"XGBoost = pd.DataFrame()\nXGBoost['feature'] = train.columns\nXGBoost['importance'] = xg_model.feature_importances_\nXGBoost.sort_values(by=['importance'], ascending=True, inplace=True)\nXGBoost.set_index('feature', inplace=True)\nXGBoost.plot(kind='barh', figsize=(20, 20))","62d4bd7a":"RandomForest = pd.DataFrame()\nRandomForest['feature'] = train.columns\nRandomForest['importance'] = rf_model.feature_importances_\nRandomForest.sort_values(by=['importance'], ascending=True, inplace=True)\nRandomForest.set_index('feature', inplace=True)\nRandomForest.plot(kind='barh', figsize=(20, 20))","a159de98":"GR_model = GradientBoostingClassifier()\nparam = {'learning_rate':[0.1,0.07,0.05,0.03,0.01],\n        'n_estimators':[50,100],\n        'max_features': ['sqrt', 'auto', 'log2'],\n        'min_samples_leaf': [1, 3, 10],\n        'max_depth': [4, 8]}\nFold = StratifiedKFold(n_splits=5)\nGrs_model = GridSearchCV(GR_model,param_grid=param, cv=Fold, scoring=\"accuracy\")\nGrs_model.fit(train,target)\nestimator_score = Grs_model.best_estimator_\nbest_param = Grs_model.best_params_\nbest_score = Grs_model.best_score_\nprint(estimator_score)\nprint(\"_____________________\")\nprint(best_param)\nprint('_____________________')\nprint(best_score)\n","38983277":"print(cross_val_score(Grs_model,train,target,scoring='accuracy').mean())","6545299c":"XG_model = XGBClassifier({'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8,'objective': 'binary:logistic',})\ncv_params = {'learning_rate':[0.1,0.05,0.01],'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n\nXgs_model = GridSearchCV(XG_model,param_grid=cv_params,scoring='accuracy',cv=Fold)\nXgs_model.fit(train,target)\nestimator_score = Xgs_model.best_estimator_\nbest_param = Xgs_model.best_params_\nbest_score = Xgs_model.best_score_\nprint(best_param)\nprint('_____________________')\nprint(best_score)","51daa8c0":"cross_val_score(Xgs_model,train,target,scoring='accuracy').mean()","375079c5":"param = {'max_depth' : [4, 6, 8],\n        'n_estimators': [10,50,100],\n        'max_features': ['sqrt', 'auto', 'log2'],\n        'min_samples_leaf': [1, 3, 10],\n                 }\nRF_model = RandomForestClassifier()\nRfs_model = GridSearchCV(RF_model, scoring='accuracy',param_grid=param, cv=Fold)\nRfs_model.fit(train, target)\nestimator_score = Rfs_model.best_estimator_\nbest_param = Rfs_model.best_params_\nbest_score = Rfs_model.best_score_\nprint(estimator_score)\nprint(\"_____________________\")\nprint(best_param)\nprint('_____________________')\nprint(best_score)\n  ","2e1912d8":"print(cross_val_score(Rfs_model,train,target,scoring='accuracy').mean())","81aa6cd3":"output = Rfs_model.predict(test).astype(int)\nFinal_output = pd.DataFrame()\nout = pd.read_csv('..\/input\/test.csv')\nFinal_output['PassengerId'] = out['PassengerId']\nFinal_output['Survived'] = output\nFinal_output[['PassengerId','Survived']].to_csv('output.csv',index=False)","22f7b57c":"Do the three results show that the top column is similar?\nFoc_loc and Age seem overwhelmingly affected.","fcf0ca8e":"## Age","eeaab140":"I could find something very interesting. \nThe graph shows that most of the people rescued are women and children.","d7267192":"# SibSp & Parch","c51bc87d":"## Embarked","121a84c3":"First, know what Categorical and Numeric data are to learn!","8d5b6e6c":"--------------------------------\n","7698a55e":"------------------------------------","6121d1ea":"# Filling Missing Data & engineering","f8518967":"OK!!, Now let's go deal with the Numeric data.","d4a33824":"By looking at the graph, you can see that there were more people living with fewer family members\nAnd you can see there is an Outlier too. Let's take care of it later.","8665fac2":"## Sex","0adc1825":"# Visualization","2caa6f71":"It is likely to be divided into single people and non-extremity people.","f93f3919":"# Fare","3eed82bd":"## Ticket","3cfc813b":"# Categorical","2692ce99":"## load data","34219ca4":"# Numeric","b7bc5c6d":"# Conclusion","8886e387":"## 1. Survived ","6f7bb82f":"The graph shows that there are many more passengers who did not survive.","84178495":"\n## What is XGBoost\nXGBoost is the leading model for working with standard tabular data (the type of data you store in Pandas DataFrames, as opposed to more exotic types of data like images and videos). XGBoost models dominate many Kaggle competitions.\n\nTo reach peak accuracy, XGBoost models require more knowledge and model tuning than techniques like Random Forest. After this tutorial, you'ill be able to\n\n* Follow the full modeling workflow with XGBoost\n* Fine-tune XGBoost models for optimal performance\nXGBoost is an implementation of the Gradient Boosted Decision Trees algorithm (scikit-learn has another version of this algorithm, but XGBoost has some technical advantages.) What is Gradient Boosted Decision Trees? We'll walk through a diagram.\n\n<img src=\"https:\/\/i.imgur.com\/e7MIgXk.png\" alt=\"xgboost image\">\n\nWe go through cycles that repeatedly builds new models and combines them into an ensemble model. We start the cycle by calculating the errors for each observation in the dataset. We then build a new model to predict those. We add predictions from this error-predicting model to the \"ensemble of models.\"\n\nTo make a prediction, we add the predictions from all previous models. We can use these predictions to calculate new errors, build the next model, and add it to the ensemble.\n\nThere's one piece outside that cycle. We need some base prediction to start the cycle. In practice, the initial predictions can be pretty naive. Even if it's predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.\n\nThis process may sound complicated, but the code to use it is straightforward. We'll fill in some additional explanatory details in the model tuning section below.\n\n","c508b215":"For visualization, first let's process the Age median.","154d6608":"A total of three mechanical learning techniques will be used.\nGradient Boosting, XGboost, RandomForest\nLearn the three models and see the results.\n(XGboost is my first time studying. \")","7e074f39":"Let's learn and take a look at the basic model that isn't simply tuned for parameters.","9bf8ecce":"If you look at the value, there are 177 of the 891 in Age, 681 in Cabin, and two in Embarkd. Let's take care of your values after we review each of the data.","ef07851f":"## Slibsp & Parch","d959da8d":"**Data Dictionary**\n\n <table>\n <tbody>\n <tr><th><b>Variable<\/b><\/th><th><b>Definition<\/b><\/th><th><b>Key<\/b><\/th><\/tr>\n <tr>\n <td>survival<\/td>\n <td>Survival<\/td>\n<td>0 = No, 1 = Yes<\/td>\n <\/tr>\n <tr>\n <td>pclass<\/td>\n <td>Ticket class<\/td>\n <td>1 = 1st, 2 = 2nd, 3 = 3rd<\/td>\n <\/tr>\n <tr>\n <td>sex<\/td>\n <td>Sex<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>Age<\/td>\n <td>Age in years<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>sibsp<\/td>\n <td># of siblings \/ spouses aboard the Titanic<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>parch<\/td>\n <td># of parents \/ children aboard the Titanic<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>ticket<\/td>\n <td>Ticket number<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>fare<\/td>\n <td>Passenger fare<\/td>\n <td><\/td>\n <\/tr>\n <tr>\n <td>cabin<\/td>\n<td>Cabin number<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>embarked<\/td>\n<td>Port of Embarkation<\/td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton<\/td>\n<\/tr>\n<\/tbody>\n<\/table>","55a4b982":"# Modeling","c57346ea":" The number of men on board the ship is more than twice as many as that of women, but it seems that women survived.\n Then use Age and Sex to draw a graph.","d36d01e3":"Let's do the pre-treatment now.","c70e3c93":"According to the graph, most children and young people are believed to have survived.","2b1b9a87":"Then check out the importance of the 60 columns and then try to tune the parameters and create the correct model.","9bf782fe":"## Fare","b8dcc373":"\n**Variable Notes**\n<p><b>pclass<\/b>: A proxy for socio-economic status (SES)<br> 1st = Upper<br> 2nd = Middle<br> 3rd = Lower<br><br> <b>age<\/b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br><br> <b>sibsp<\/b>: The dataset defines family relations in this way...<br> Sibling = brother, sister, stepbrother, stepsister<br> Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)<br><br> <b>parch<\/b>: The dataset defines family relations in this way...<br> Parent = mother, father<br> Child = daughter, son, stepdaughter, stepson<br> Some children travelled only with a nanny, therefore parch=0 for them.<\/p>","13b23ab0":"## Embarked","46f4a2a0":"----------------------------------------","98a811e4":"I found it interesting to analyze data. It was amazing to start with data analysis and to predict from machine learning. I lost track of time doing this. I think tuning the paramter of machine learning model such as .boost and GradientBoosting was really complicated. While studying the three models, I learned a little about the techniques used by .boost and will study more next time to make better results!","b566f03e":"As a result\n1. GradientBoostingClassifier : 0.8329179434797412\n2. XGBClassifier : 0.8239036431733062\n3. RandomForestClassifier : 0.8182859493814549","6cddb069":"----------------------------------\n","1e0b974b":"## check missing data","45768782":"After we have gained insight from the training data and created the model, we will use the test data to make predictions.","4422e658":"## Cabin","f770322c":"# Introduction\n\nHello !  This is my first kernel. I want to develop my data science ability from Titanic slowly. So you will make as many analyses and visualizations as possible and see the results of machine learning through them.\n\nIf you take a long look at it in detail, this is how it will proceed\n\n*  Load Data\n    *  load data\n    *  check missing data    \n*  Visualization\n    \n*  Filling Missing Value & engineering\n    *  Categorical\n    *  Numeric\n    \n*  Modeling\n    * Gradient Boost \n    * XGBoost\n    * Random Forest","5538b58b":"0.8170594837261503","eaf1574d":"## Tuning","370551d5":"## PClass","a415a2b1":"Check the table below to see what the column values mean.","13fe556f":"According to the graph, C was the most likely to survive.\nS has survived more than C, but the odds are slim because there are so many people who don't survive.","db201636":"Recalls the data before learning the machine.\nSubsequent test and training data should be dealt with collectively.\nThe reason is that the test and training data have the same column values, and therefore there is also the value of the panel.","fda62fac":"Let's tie the rest of it into the rest since it is a major withdrawal and the rest is a minor one.","b301fff3":"## Sex","c1ad6590":"**2018\/03\/25**","42082a81":"# Load Data\n\nLet's load Data","5cee4868":"If you look at the graph, you can see that people with higher pc resistance are saved first in situations where women are rescued more than men.\nPclass3 demonstrates that although it accounts for about half of all passengers, it has a lower survival rate than pc 1.","e3c3b736":"As a Result, Best_score is 0.8406285072951739","8e3e02ae":"The graph shows that Fare is tilted to the left.\nLet's take a quick look at it to see it more clearly.","0c9c51ea":"## Age","1d815b7b":"## Name","d025f3a5":"The most important thing is handling age.\nAs I saw before, age and cabin were your most valuable. And because Age is an influencing factor of the Stored."}}