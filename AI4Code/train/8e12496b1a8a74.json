{"cell_type":{"f94bf260":"code","3c856d31":"code","98b66678":"code","2d7aa30a":"code","4ef4196a":"code","f22f78e5":"code","58be06f9":"code","7c327450":"code","c477bf76":"code","2869ebf1":"code","fc698f64":"code","a29fd527":"code","f730f9ff":"code","0f09dc3e":"markdown","b403d2eb":"markdown","fc7d8bee":"markdown","353f65c7":"markdown","5bf38f18":"markdown","9d027edf":"markdown","4e869851":"markdown","63de1237":"markdown","a71498f7":"markdown","e57cd3e7":"markdown","5179a5c3":"markdown","ec005a40":"markdown","49f86b94":"markdown"},"source":{"f94bf260":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport datetime as dt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport pickle\nimport os\n\nimport lib_accii_53\nimport lib_prepare as prepare\nimport lib_ga","3c856d31":"fn1 = '..\/input\/tr-podbor-portf-prost-risk-doh\/model_ga.pkl'\nfn2 = '.\/model_ga.pkl'\n\nif os.path.exists(fn1):\n    os.system(f'cp {fn1} {fn2}')","98b66678":"d_data = lib_accii_53.get_dOHLCV()\nd_data.shape","2d7aa30a":"X1_train, X1_test, X2_train, X2_test, y_train, y_test, d_train, d_test = None, None, None, None, None, None, None, None","4ef4196a":"hsGetQualityMethod = None\nmodelGetQualityMethod = None\n\ndef getQualityMethod(units,\n                     kernel,\n                     patienceEarlyStopping,\n                     patienceReduceLROnPlateau,\n                     window,\n                     batch_size,\n                     gorizont,\n                     train_size,\n                     val_size):\n    \n    output = lib_accii_53.get_pct_change(gorizont).values\n    \n    inpData1 = prepare.data_to_window(d_data,window)\n    \n    inpData2 = prepare.date_to_input(lib_accii_53.get_index())\n    \n    inpData1Learn,inpData2Learn,inpData1Calc,inpData2Calc = prepare.split_learn_calc(inpData1,inpData2,gorizont=gorizont)\n    \n    inpData1Learn,inpData2Learn,output,learnDates = prepare.chistim_pustoty(inpData1Learn,\n                                                                            inpData2Learn,\n                                                                            output,\n                                                                            lib_accii_53.get_index().values[:,np.newaxis])\n    \n    global X1_train, X1_test, X2_train, X2_test, y_train, y_test, d_train, d_test\n    X1_train, X1_test, \\\n    X2_train, X2_test,\\\n    y_train, y_test, \\\n    d_train, d_test = prepare.learn_val_random_vib(inpData1Learn,\n                                                   inpData2Learn,\n                                                   output,\n                                                   learnDates,\n                                                   learnVibLen = train_size,\n                                                   valVibLen = val_size)\n    \n    \n    \n    normLayer = keras.layers.experimental.preprocessing.Normalization(axis=-1)\n    normLayer.adapt(X1_train)\n    \n    input1 = keras.layers.Input(shape=X1_train.shape[1:])\n    x1 = normLayer(input1)\n\n    x1 = keras.layers.Conv1D(units,\n                             kernel,\n                             padding='same',\n                             activation='relu')(x1)\n\n    x1 = keras.layers.Flatten()(x1)\n\n    input2 = keras.layers.Input(shape=(X2_train.shape[1],))\n\n    x = keras.layers.Concatenate()([x1,input2])\n\n    outputs = keras.layers.Dense(y_train.shape[1],name='output')(x)\n    \n    model = keras.Model((input1,input2),outputs)\n    \n    model.compile(optimizer = tf.optimizers.Adam(),\n                  loss = 'mse')\n    cb = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                           patience=patienceEarlyStopping,\n                                           restore_best_weights=True,\n                                           verbose=False),\n          tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                               patience=patienceReduceLROnPlateau,\n                                               verbose=False)]\n    \n    \n    global hsGetQualityMethod\n    hsGetQualityMethod = model.fit((X1_train,X2_train),list(y_train.T),\n                                    epochs=1000,\n                                    validation_split=0.3,\n                                    verbose=False,\n                                    callbacks = cb,\n                                    batch_size=batch_size)\n    \n    \n    global modelGetQualityMethod\n    modelGetQualityMethod = model\n    \n#     hs = pd.DataFrame(hsGetQualityMethod.history)\n    \n    y_pred = model.predict((X1_test,X2_test))\n    \n    return (tf.nn.softmax(y_pred).numpy() * y_test).sum(axis=1).mean()\/gorizont\n\n# getQualityMethod(units=5,\n#                  kernel=3,\n#                  patienceEarlyStopping=30,\n#                  patienceReduceLROnPlateau=3,\n#                  window=5,\n#                  batch_size=32,\n#                  gorizont=5,\n#                  train_size=700,\n#                  val_size=10)","f22f78e5":"modelGA = lib_ga.ListGenetic( pop_size = 200,\n                              units=range(3,100),\n                              kernel=range(2,10),\n                              patienceEarlyStopping=range(10,100),\n                              patienceReduceLROnPlateau=range(5,100),\n                              window = range(3,100),\n                              batch_size = range(4,128+1),\n                              gorizont = range(1,14+1),\n                              train_size=range(400,1000+1),\n                              val_size=range(7,100),\n                              quality_method=getQualityMethod)","58be06f9":"fn = fn2\n\nif os.path.exists(fn):\n    with open(fn,'rb') as fp:\n        modelGA = pickle.load(fp)","7c327450":"modelGA.fit(500,echo_time=60)\nwith open(fn,'wb') as fp:\n    pickle.dump(modelGA,fp)","c477bf76":"modelGA.plot_hist_new(('quality','units','kernel','patienceEarlyStopping','patienceReduceLROnPlateau','window', 'batch_size','gorizont','train_size','val_size'))","2869ebf1":"best_par = modelGA.getBestParams()\nbest_par","fc698f64":"# getQualityMethod(**best_par)","a29fd527":"# hs = pd.DataFrame(hsGetQualityMethod.history)\n# fig = plt.figure(figsize=(10,6))\n# ax1 = fig.add_subplot(111)\n# hs[['loss','val_loss']].plot(ax=ax1)\n# ax1.grid()\n# ax1.set_title('loss')\n# plt.show()","f730f9ff":"# train_kach = modelGetQualityMethod.evaluate([X1_train,X2_train],list(y_train.T),verbose=1)\n# test_kach = modelGetQualityMethod.evaluate([X1_test,X2_test],list(y_test.T),verbose=1)","0f09dc3e":"# \u041f\u0435\u0440\u0435\u0434\u0430\u0447\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u0437 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439 \u0432\u0435\u0440\u0441\u0438\u0438","b403d2eb":"# \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","fc7d8bee":"# \u041e\u0442\u0447\u0435\u0442 \u043f\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","353f65c7":"# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438","5bf38f18":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043a\u043e\u0442\u0438\u0440\u043e\u0432\u043e\u043a","9d027edf":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","4e869851":"# \u0426\u0438\u043a\u043b \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438","63de1237":"# \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0438 \u0442\u0435\u0441\u0442","a71498f7":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430, \u0435\u0441\u043b\u0438 \u0443\u0436\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442","e57cd3e7":"# \u041e\u0442\u0447\u0435\u0442 \u043f\u043e \u0438\u0441\u0442\u043e\u0440\u0438\u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438","5179a5c3":"# \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0430\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438","ec005a40":"# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438","49f86b94":"# \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438"}}