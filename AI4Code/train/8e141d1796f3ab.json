{"cell_type":{"65a1b28c":"code","6f4c3e86":"code","1a477fb8":"code","7238c74a":"code","73579af5":"code","2207d8b3":"code","78732569":"code","efc49db7":"code","023b8cf8":"code","4609bf8e":"code","86fb0997":"code","0b9fd204":"code","216d019c":"code","ec2c38f6":"code","8804f172":"code","c2b0a261":"code","39ea5d53":"code","a94354e0":"code","fea09139":"code","557fab70":"markdown","eab3cc8d":"markdown","af90b4d9":"markdown","91a6f9bf":"markdown","54e81e79":"markdown","43d8be80":"markdown","001f40f2":"markdown","ac06cff4":"markdown","479d72c7":"markdown","4767b9f4":"markdown","11bc6755":"markdown","6c206ae7":"markdown","028e71a0":"markdown","a4756ae8":"markdown","6fb61490":"markdown","749ed070":"markdown","40c91ffe":"markdown","148f399a":"markdown","e343c413":"markdown","8fd32f38":"markdown","8368ce96":"markdown"},"source":{"65a1b28c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nfrom __future__ import print_function\nimport tensorflow.keras as keras\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f4c3e86":"batch_size = 32  # The default batch size of keras.\nnum_classes = 10  # Number of class for the dataset\nepochs = 11\ndata_augmentation = False","1a477fb8":"# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","7238c74a":"fig, axs = plt.subplots(1,2,figsize=(15,5)) \n# Count plot for training set\nsns.countplot(y_train.ravel(), ax=axs[0])\naxs[0].set_title('Distribution of training data')\naxs[0].set_xlabel('Classes')\n# Count plot for testing set\nsns.countplot(y_test.ravel(), ax=axs[1])\naxs[1].set_title('Distribution of Testing data')\naxs[1].set_xlabel('Classes')\nplt.show()","73579af5":"# Normalize the data. Before we need to connvert data type to float for computation.\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\n# Convert class vectors to binary class matrices. This is called one hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","2207d8b3":"#define the convnet\nmodel = Sequential()\n# CONV => RELU => CONV => RELU => POOL => DROPOUT\nmodel.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# CONV => RELU => CONV => RELU => POOL => DROPOUT\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# FLATTERN => DENSE => RELU => DROPOUT\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n# a softmax classifier\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","78732569":"# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])","efc49db7":"history = None  # For recording the history of trainning process.\nif not data_augmentation:\n    print('Not using data augmentation.')\n    history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        # randomly shift images horizontally (fraction of total width)\n        width_shift_range=0.1,\n        # randomly shift images vertically (fraction of total height)\n        height_shift_range=0.1,\n        shear_range=0.,  # set range for random shear\n        zoom_range=0.,  # set range for random zoom\n        channel_shift_range=0.,  # set range for random channel shifts\n        # set mode for filling points outside the input boundaries\n        fill_mode='nearest',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either \"channels_first\" or \"channels_last\"\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    history = model.fit_generator(datagen.flow(x_train, y_train,\n                                    batch_size=batch_size),\n                                    epochs=epochs,\n                                    validation_data=(x_test, y_test),\n                                    workers=4)","023b8cf8":"def plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n# list all data in history\nprint(history.history.keys())\n\nplotmodelhistory(history)\n","4609bf8e":"# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n\n# make prediction.\npred = model.predict(x_test)","86fb0997":"def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n    \"\"\"\n    Create a heatmap from a numpy array and two lists of labels.\n    \"\"\"\n    if not ax:\n        ax = plt.gca()\n\n    # Plot the heatmap\n    im = ax.imshow(data, **kwargs)\n\n    # Create colorbar\n    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n\n    # Let the horizontal axes labeling appear on top.\n    ax.tick_params(top=True, bottom=False,\n                   labeltop=True, labelbottom=False)\n    # We want to show all ticks...\n    ax.set_xticks(np.arange(data.shape[1]))\n    ax.set_yticks(np.arange(data.shape[0]))\n    # ... and label them with the respective list entries.\n    ax.set_xticklabels(col_labels)\n    ax.set_yticklabels(row_labels)\n    \n    ax.set_xlabel('Predicted Label') \n    ax.set_ylabel('True Label')\n    \n    return im, cbar\n\ndef annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n    \"\"\"\n    A function to annotate a heatmap.\n    \"\"\"\n    # Change the text's color depending on the data.\n    texts = []\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n                                 color=\"white\" if data[i, j] > thresh else \"black\")\n            texts.append(text)\n\n    return texts","0b9fd204":"labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test, axis=1)\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = pred[errors]\nY_true_errors = Y_true[errors]\nX_test_errors = x_test[errors]\n\ncm = confusion_matrix(Y_true, Y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(12,12))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","216d019c":"print(classification_report(Y_true, Y_pred_classes))","ec2c38f6":"R = 5\nC = 5\nfig, axes = plt.subplots(R, C, figsize=(12,12))\naxes = axes.ravel()\n\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[i])\n    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)\n","8804f172":"R = 3\nC = 5\nfig, axes = plt.subplots(R, C, figsize=(12,8))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(Y_pred_classes != Y_true)[0]\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]], \n                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","c2b0a261":"def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 5\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True, figsize=(12,6))\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((32,32,3)))\n            ax[row,col].set_title(\"Predicted:{}\\nTrue:{}\".\n                                  format(labels[pred_errors[error]],labels[obs_errors[error]]))\n            n += 1\n            ax[row,col].axis('off')\n            plt.subplots_adjust(wspace=1)\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 10 errors \nmost_important_errors = sorted_dela_errors[-10:]\n\n# Show the top 10 errors\ndisplay_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors)","39ea5d53":"def show_test(number):\n    fig = plt.figure(figsize = (3,3))\n    test_image = np.expand_dims(x_test[number], axis=0)\n    test_result = model.predict_classes(test_image)\n    plt.imshow(x_test[number])\n    dict_key = test_result[0]\n    plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key],\n                                                      labels[Y_true[number]]))","a94354e0":"show_test(98)","fea09139":"save_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'keras_cifar10_trained_model.h5'\n\n# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n","557fab70":"Maintenant, examinons les erreurs.\n### 5.3 Confusion matrix.\nUne matrice de confusion peut \u00eatre tr\u00e8s utile pour voir les inconv\u00e9nients de votre mod\u00e8le.\nNous tra\u00e7ons la matrice de confusion des r\u00e9sultats de validation.\nPour une bonne visualisation de notre matrice de confusion, nous devons d\u00e9finir pour fonctionner.","eab3cc8d":"Comme on peut le voir, chaque classe contient exactement 6000 exemples (5000 pour la formation et 1000 pour les tests).\n\nLe graphique ci-dessus est tr\u00e8s important pour l'apprentissage, par exemple, si nous n'avions que 1000 \u00e9chantillons d'\u00e9tiquette 1 qui poseront probl\u00e8me, le mod\u00e8le aura du mal \u00e0 d\u00e9tecter l'\u00e9tiquette 1 \"moins de pr\u00e9cision\", donc \u00e7a ne va pas tout arriver semble bien. Il est important de conna\u00eetre la distribution de l'ensemble de donn\u00e9es derri\u00e8re diff\u00e9rentes classes car la qualit\u00e9 de notre mod\u00e8le en d\u00e9pend.\n\nFaisons maintenant du pr\u00e9traitement.\n\nLa variable de sortie a 10 valeurs possibles. Il s'agit d'un probl\u00e8me de classification multiclasse. Il faut encoder les labels en One hot Encoding (ex : \"bird\" -> [0,0,1,0,0,0,0,0,0,0]).","af90b4d9":"Introooooooduction","91a6f9bf":"## 5.\u00c9valuer le mod\u00e8le:\n\n### 5.1 Training and validation curves:\n\nVoyons le processus d'entrainement et de validation par la visualisation de l'historique de test. Cela nous permet de savoir rapidement si notre mod\u00e8le correspond \u00e0 nos donn\u00e9es **(overfitting, underfitting, model convergence, etc...)**\n\n","54e81e79":"## 6. Save model and weights\n\nNotez que nous devons d'abord indiquer le r\u00e9pertoire pour enregistrer le mod\u00e8le et le nom de notre mod\u00e8le.","43d8be80":"### Merci pour votre attention","001f40f2":"#### - Test du mod\u00e8le avec les images de test dans l'ensemble de test.\nMaintenant c'est l'heure du jeu","ac06cff4":"#### - V\u00e9rifier les mauvaises pr\u00e9dictions.","479d72c7":"### 2.1.Importer toutes les biblioth\u00e8ques requises :","4767b9f4":"### 5.2 Score trained model and prediction.","11bc6755":"D\u00e9finissons les hyperparam\u00e8tres du mod\u00e8le et d'autres param\u00e8tres globaux.","6c206ae7":"### 2.3 Distribution des donn\u00e9es:","028e71a0":"### 2.2 Importer et pr\u00e9traiter les donn\u00e9es:\ncharger les donn\u00e9es et les diviser entre les ensembles de train et de test","a4756ae8":"Les codes de ce notebook sont repris sur la documentation Keras. Je veux juste donner quelques explications.\n\n### Table de Mati\u00e8res:\n1. Introduction\n2. Importer et pr\u00e9traiter les donn\u00e9es\n + 2.1 Importer toutes les biblioth\u00e8ques requises\n + 2.2 Importer et pr\u00e9traiter les donn\u00e9es\n + 2.3 Distribution des donn\u00e9es.\n3. D\u00e9finir l'architecture du mod\u00e8le \u00e0 l'aide de ConVnets\n4. Model training\n5. \u00c9valuer le mod\u00e8le\n + 5.1 Training and validations cuvre\n + 5.2 Score trained model and prediction.\n + 5.3 Confusion matrix.\n + 5.4 Classification report.\n + 5.5 Check for the predictions.\n6. Enregistrer le mod\u00e8le et les poids","6fb61490":"#### - V\u00e9rifier les erreurs les plus importantes.","749ed070":"### 5.5 Check the predictions:","40c91ffe":"## 1.Introduction:","148f399a":"### 5.4 Classification report\nCela nous permettra d'\u00e9valuer le mod\u00e8le avec d'autres m\u00e9triques **(Precision, Recall, F1 score, etc...)**","e343c413":"## 2.Importer et pr\u00e9traiter les donn\u00e9es :","8fd32f38":"## 3. D\u00e9finir l'architecture du mod\u00e8le \u00e0 l'aide de ConVnets:\n\nD\u00e9finissons maintenant un r\u00e9seau profond appropri\u00e9.\n\n* Dans la premi\u00e8re \u00e9tape, notre r\u00e9seau apprendra **32 filtres convolutifs**, chacun avec une **taille 3 x 3**. La dimension de sortie est la m\u00eame que celle de la forme d'entr\u00e9e, elle sera donc **32 x 32** et l'activation est \"relu\", ce qui est un moyen simple d'introduire la non-lin\u00e9arit\u00e9\u00a0; suivi d'un autre **32 filtres convolutifs**, dont chacun avec une **taille de 3 x 3** et une activation est \u00e9galement \"relu\". Apr\u00e8s cela, nous avons une op\u00e9ration **max-pooling** avec 'pool size' **2 x 2** et un 'dropout' \u00e0 **25%.**\n* Dans la prochaine \u00e9tape du pipeline approfondi, notre r\u00e9seau apprendra **64 filtres convolutifs**, chacun avec une **taille 3 x 3**. La dimension de sortie est la m\u00eame que la forme d'entr\u00e9e et l'activation est \u00ab\u00a0relu\u00a0\u00bb\u00a0; suivi d'un autre **64 filtres convolutifs**, dont chacun avec une **taille de 3 x 3** et une activation est \u00e9galement \"relu\". Apr\u00e8s cela, nous avons une op\u00e9ration **max-pooling** avec 'pool size' **2 x 2** et un 'dropout' \u00e0 **25%.**\n* Et la derni\u00e8re \u00e9tape du pipeline profond est un r\u00e9seau dense avec **512 unit\u00e9s** et une activation \"relu\" suivi d'un \"Dropout\" \u00e0 **50%** et d'une couche \"softmax\" avec **10 classes comme sortie**, une pour chaque cat\u00e9gorie.","8368ce96":"Et maintenant, entra\u00eenons le mod\u00e8le.\n\n## 4. Model Training:\n\nAvant de pr\u00e9parer le r\u00e9seau pour l'entrainement, nous devons nous assurer d'ajouter les \u00e9l\u00e9ments ci-dessous\u00a0:\n* **Une fonction de perte\u00a0:** pour mesurer la qualit\u00e9 du r\u00e9seau\n* **Un optimiseur\u00a0:** pour mettre \u00e0 jour le r\u00e9seau \u00e0 mesure qu'il voit plus de donn\u00e9es et r\u00e9duire la valeur des pertes\n* **M\u00e9triques\u00a0:** pour surveiller les performances du r\u00e9seau\n\n**Notez \u00e9galement que pour l'augmentation des donn\u00e9es\u00a0:**\n* L'augmentation des donn\u00e9es est l'une des techniques les plus courantes pour \u00e9viter le surapprentissage. Et nous savons que le surapprentissage se produit g\u00e9n\u00e9ralement lorsque nous ne disposons pas de suffisamment de donn\u00e9es pour entra\u00eener le mod\u00e8le. Pour \u00e9viter ce probl\u00e8me, nous devons \u00e9tendre artificiellement notre ensemble de donn\u00e9es. L'id\u00e9e est de modifier les donn\u00e9es d'apprentissage avec de petites transformations pour reproduire les variations se produisant lorsque quelqu'un \u00e9crit un chiffre.\n\n* Les diff\u00e9rentes techniques d'augmentation de donn\u00e9es sont les suivantes\u00a0: recadrage, rotation, mise \u00e0 l'\u00e9chelle, traduction, retournement, ajout de bruit gaussien aux images d'entr\u00e9e, etc..."}}