{"cell_type":{"f1bbdc37":"code","6b44402a":"code","39b56514":"code","a8b58a3a":"code","95ea03e0":"code","fc391a76":"code","214b01ab":"code","f9d68663":"code","1e457ca1":"code","0f68513e":"code","141df240":"code","9ec437f3":"code","26337875":"code","33eca603":"code","b147f96f":"code","24f93edf":"code","59920971":"code","eeb1e263":"code","3ad06e3e":"code","6f9df065":"code","00bad979":"code","0f1d8061":"code","3dc046e8":"code","aa183fc7":"code","aa3a5ac6":"code","ae459fe7":"code","fd6a81b6":"code","d95ab1d1":"code","fa5f071d":"code","072991b6":"markdown"},"source":{"f1bbdc37":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport lightgbm\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dense, Dropout\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","6b44402a":"#import dataset\ndf = pd.read_csv('..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\nprint(df.shape)\ndf.head()","39b56514":"#Check balance between output classes\ny = df[\"Exited\"].value_counts()\nsns.barplot(y.index, y.values)","a8b58a3a":"#Check balance between states\ngeo = df.Geography.value_counts()\nsns.barplot(geo.index, geo.values)","95ea03e0":"#Check balance between gender\ngen = df.Gender.value_counts()\nsns.barplot(gen.index, gen.values)","fc391a76":"#count the exit ratio in countries\ncountries = ['France', 'Germany', 'Spain']\n\nvalue_indexes = []\n\nfor value in countries:\n  df_state = df[df['Geography']==value]\n  value_index = (df_state.Exited != 0).values.sum()\/len(df_state)\n  value_indexes.append(value_index)\n\ndictionary = dict(zip(countries, value_indexes))\n\ndf['Geo_ratio'] = df['Geography'].map(dictionary)\ndf.head()","214b01ab":"#count the exit ratio for gender index\ngender_list = ['Female', 'Male']\n\nvalue_indexes = []\n\nfor value in gender_list:\n  df_gender = df[df['Gender']==value]\n  value_index = (df_gender.Exited != 0).values.sum()\/len(df_gender)\n  value_indexes.append(value_index)\n\ndictionary_gen = dict(zip(gender_list, value_indexes))\n\ndf['Gen_ratio'] = df['Gender'].map(dictionary_gen)\ndf.head()","f9d68663":"#check number of uniques\ndf.nunique()","1e457ca1":"#drop any nans if exist\ndf = df.dropna()\nprint(df.shape)","0f68513e":"#drop useless data\ndf.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace = True)\ndf.head()","141df240":"#list of categorical columns\nFILTER_COLS = ['Geography', 'Gender']","9ec437f3":"#one hot encoding for categorical data by using pandas get_dummies method\ndf_dummies = pd.get_dummies(df, columns=FILTER_COLS)\ndf_dummies.head()\ndf_dummies.shape","26337875":"#Normalize continuous data by using MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_dummies[['Tenure', 'Balance', 'EstimatedSalary', 'Age', 'CreditScore', 'NumOfProducts']] = scaler.fit_transform(df_dummies[['Tenure', 'Balance', 'EstimatedSalary', 'Age', 'CreditScore', 'NumOfProducts']])\ndf_dummies.head()","33eca603":"#Link the value of the churn cases to the country of occurrence\ndf_dummies['Geography_France'] = df_dummies.Geography_France * df_dummies.Geo_ratio\ndf_dummies['Geography_Germany'] = df_dummies.Geography_Germany * df_dummies.Geo_ratio\ndf_dummies['Geography_Spain'] = df_dummies.Geography_Spain * df_dummies.Geo_ratio\ndf_dummies.drop(columns=\"Geo_ratio\", inplace = True)\n\n#Link the value of the churn cases to the gender of customer\ndf_dummies['Gender_Female'] = df_dummies.Gender_Female * df_dummies.Gen_ratio\ndf_dummies['Gender_Male'] = df_dummies.Gender_Male * df_dummies.Gen_ratio\ndf_dummies.drop(columns=\"Gen_ratio\", inplace = True)\ndf_dummies.head()","b147f96f":"#get corelation bar plot\nplt.figure(figsize=(15,8))\ndf_dummies.corr()['Exited'].sort_values(ascending = False).plot(kind='bar')","24f93edf":"#get corleation heatmap\nf = plt.figure(figsize=(13, 10))\nplt.matshow(df_dummies.corr(), fignum=f.number)\nplt.xticks(range(df_dummies.shape[1]), df_dummies.columns, fontsize=10, rotation=90)\nplt.yticks(range(df_dummies.shape[1]), df_dummies.columns, fontsize=10)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","59920971":"#divide dataset on X and y\nX = df_dummies.drop(columns='Exited')\ny= df.Exited.astype(int)\nprint(X.shape, y.shape)","eeb1e263":"#prepare 3 types of datasets\nfrom sklearn.model_selection import train_test_split\nx, x_test, y, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, random_state=42, stratify=y)\n\nprint(x.shape, y.shape)\nprint(x_test.shape, y_test.shape)\nprint(x_valid.shape, y_valid.shape)","3ad06e3e":"#train LightGBM model\ntrain_data = lightgbm.Dataset(x_train, label=y_train)\ntest_data = lightgbm.Dataset(x_test, label=y_test)\nmax_depth = 5\nnum_leaves = 2**max_depth\n\nparameters = {\n    'application': 'binary',\n    'objective': 'binary',\n    'metric': 'auc',\n    'max_depth': max_depth,\n    'is_unbalance': 'true', #due to unbalanced dataset this option should be set as true\n    'boosting': 'gbdt',\n    'num_leaves': num_leaves,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 20,\n    'learning_rate': 0.05,\n    'verbose': 0,\n    'gpu_use_dp' : True\n}\n\nmodel = lightgbm.train(parameters,\n                       train_data,\n                       valid_sets=test_data,\n                       num_boost_round=500,\n                       early_stopping_rounds=25)","6f9df065":"#make a LightGBM predict for validation set\ny_pred = model.predict(x_valid)","00bad979":"#train XGB model, due to unbalanced dataset scale_pos_weight parameter should be equal class_1\/class_0\nfrom xgboost import XGBClassifier\nmodel_xgb = XGBClassifier(learning_rate = 0.05, max_depth=max_depth, scale_pos_weight=0.25)\nmodel_xgb.fit(x_train,y_train)","0f1d8061":"#make a XGB predict for validation set\ny_xgb_pred = model_xgb.predict_proba(x_valid)\ny_xgb_pred = y_xgb_pred[:,1:]","3dc046e8":"#train GBC classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(learning_rate = 0.05, max_depth=max_depth, max_leaf_nodes = num_leaves)\ngbc.fit(x_train, y_train)","aa183fc7":"#make a GBC predict for validation set\ny_gbc_pred = gbc.predict_proba(x_valid)\ny_gbc_pred = y_gbc_pred[:,1:]","aa3a5ac6":"!pip install catboost\n#check documentation for any info: https:\/\/catboost.ai\/docs\/concepts\/python-reference_catboostclassifier.html\n#due to unbalanced dataset class_weights should be set as the list with a y ratio values of class_0 and class_1 \nfrom catboost import CatBoostClassifier\ncatB = CatBoostClassifier(iterations=500,\n                          learning_rate=0.05,\n                          depth=max_depth,\n                          class_weights = [0.8, 0.2])\n\ncatB.fit(x_train,\n          y_train,\n          verbose=False)","ae459fe7":"#make a catBoost predict for validation set\ny_cat_pred = catB.predict_proba(x_valid)\ny_cat_pred = y_cat_pred[:,1:]","fd6a81b6":" #Binary Classification with Keras MLP Classifier\n #Initializing model method\n  def create_m(input_shape = x_train.shape[1]):\n    model = Sequential()\n    model.add(Dense(64, input_dim=input_shape, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model","d95ab1d1":"#fit model and predict the the valid set\n\nfrom sklearn.utils import class_weight\nfrom keras.callbacks import EarlyStopping\n#due to unbalanced dataset class_weights is counted by a class_weight method from sklearn library also early stopping method is on to prevent overfitting\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n\nprint(class_weights)\n\nes = EarlyStopping(monitor='accuracy', mode='max', min_delta=0.01, verbose=1, patience=15)\n\nNN_model = create_m()\n\nNN_model.fit(x_train, y_train, epochs=50, batch_size=128, class_weight=class_weights, callbacks=[es])\n\ny_NN_pred = NN_model.predict(x_valid)","fa5f071d":"#print Auc Score for models\nprint('LGBM Roc Auc Score is equal: ', round(roc_auc_score(y_valid, y_pred),5))\nprint('XGB Roc Auc Score is equal: ', round(roc_auc_score(y_valid, y_xgb_pred),5))\nprint('GBC Roc Auc Score is equal: ', round(roc_auc_score(y_valid, y_gbc_pred),5))\nprint('CatBoost Roc Auc Score is equal: ', round(roc_auc_score(y_valid, y_cat_pred),5))\nprint('NN MLP Roc Auc Score is equal: ', round(roc_auc_score(y_valid, y_NN_pred),5))\n\n#count values for plot\nns_probs = [0 for _ in range(len(y_valid))]\nns_fpr, ns_tpr, _ = roc_curve(y_valid, ns_probs)\nfpr, tpr, thresholds = roc_curve(y_valid, y_pred)\nxfpr, xtpr, xthresholds = roc_curve(y_valid, y_xgb_pred)\ngfpr, gtpr, gthresholds = roc_curve(y_valid, y_gbc_pred)\ncfpr, ctpr, cthresholds = roc_curve(y_valid, y_cat_pred)\nnnfpr, nntpr, nntresholds = roc_curve(y_valid, y_NN_pred)\n\n#plot the roc curve for the model\nplt.figure(figsize=(10,5))\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, linestyle='--', label='LightGBM')\nplt.plot(xfpr, xtpr, linestyle='--', label='XGBoost')\nplt.plot(gfpr, gtpr, linestyle='--', label='GradientBoosting')\nplt.plot(cfpr, ctpr, linestyle='--', label='CatBoost')\nplt.plot(nnfpr, nntpr, linestyle='--', label='NeuralMLP')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\n#set the size of the plot\n\n#show the legend\nplt.legend()\n#show the plot\nplt.show()\n","072991b6":"![](https:\/\/i.imgur.com\/9BUtrm4.png)"}}