{"cell_type":{"07b6a759":"code","3801b77c":"code","ec2d7f5f":"code","871a326a":"code","cc23fa0f":"code","e35a243c":"code","085fdc3c":"code","96ad24aa":"code","cbd16408":"code","4aa66469":"code","736cb0d5":"code","f1c84b76":"code","2ed4f369":"code","f298f648":"code","fe5e44b9":"code","6404dbc1":"code","aaf04afc":"code","042123ba":"code","ddc0dadb":"code","7de0b724":"code","ccc724d0":"code","d4b10237":"code","1656577a":"code","fde58dce":"code","0fdf94ad":"code","d39cfafe":"code","39501983":"code","3b74e594":"code","d1fcfd95":"code","59a61f3c":"code","ea2f9fe7":"code","b2286e11":"code","4a3150a6":"code","df24b918":"code","e2ffdc86":"code","ecb065ec":"code","3754a79c":"code","f0fc4908":"code","f1d2590a":"code","a1549c23":"code","f0871b7b":"code","7d64116c":"code","4e42b25e":"code","4a048fb0":"code","32b9cf29":"code","7d9fa203":"code","70048608":"code","e9b888bc":"markdown","8b5cc70b":"markdown","45eb6dba":"markdown","216b4630":"markdown","d76f0896":"markdown","f4b0a998":"markdown","2652b633":"markdown","38b49b7a":"markdown","bf6c503d":"markdown","40799702":"markdown","cdc7661c":"markdown","38ab3087":"markdown","0931a882":"markdown","920785e5":"markdown","2abdf8f5":"markdown","51697d2e":"markdown"},"source":{"07b6a759":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3801b77c":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn as sk\nimport numpy as np","ec2d7f5f":"train_data = pd.read_csv(\"..\/input\/loan-eligible-dataset\/loan-train.csv\")\ntest_data = pd.read_csv(\"..\/input\/loan-eligible-dataset\/loan-test.csv\")","871a326a":"train_data.head()","cc23fa0f":"test_data.head()","e35a243c":"train_data.shape, test_data.shape","085fdc3c":"train_data.info()","96ad24aa":"train_data.describe()","cbd16408":"def explore_object_type(df ,feature_name):\n    \"\"\"\n    To know, How many values available in object('categorical') type of features\n    And Return Categorical values with Count.\n    \"\"\"    \n    if df[feature_name].dtype ==  'object':\n        print(df[feature_name].value_counts())","4aa66469":"for featureName in train_data.columns:\n    if train_data[featureName].dtype == 'object':\n        print('\\n\"' + str(featureName) + '\\'s\" Values with count are :')\n        explore_object_type(train_data, str(featureName))","736cb0d5":"# Checking for Null values in the data set\ntrain_data.isna().sum()","f1c84b76":"import missingno as msno\nmsno.bar(train_data)","2ed4f369":"msno.matrix(train_data)","f298f648":"train_data['Credit_History'].fillna(train_data['Credit_History'].mode()[0], inplace = True) # Mode\ntest_data['Credit_History'].fillna(test_data['Credit_History'].mode()[0], inplace = True) # Mode\n\ntrain_data['LoanAmount'].fillna(train_data['LoanAmount'].mean(), inplace = True) # Mean\ntest_data['LoanAmount'].fillna(test_data['LoanAmount'].mean(), inplace = True)","fe5e44b9":"ax1 = train_data['Gender'].value_counts(normalize=True).plot.bar(title='Train Dataset')\nplt.show()\nax2 = test_data['Gender'].value_counts(normalize=True).plot.bar(title='Test Dataset')\nplt.show()","6404dbc1":"# For Gender \ntrain_data['Gender'].fillna(train_data['Gender'].mode()[0], inplace = True) # Mode\ntest_data['Gender'].fillna(test_data['Gender'].mode()[0], inplace = True) ","aaf04afc":"sns.countplot(train_data['Married']);","042123ba":"# For Married\ntrain_data['Married'].fillna(train_data['Married'].mode()[0], inplace = True) # Mode\ntest_data['Married'].fillna(test_data['Married'].mode()[0], inplace = True) ","ddc0dadb":"sns.countplot(train_data['Dependents']);","7de0b724":"# For Dependents\ntrain_data['Dependents'].fillna(train_data['Dependents'].mode()[0], inplace = True) # Mode\ntest_data['Dependents'].fillna(test_data['Dependents'].mode()[0], inplace = True) ","ccc724d0":"sns.countplot(train_data['Self_Employed']);","d4b10237":"train_data['Self_Employed'] = train_data['Self_Employed'].fillna('No')\ntest_data['Self_Employed'] = test_data['Self_Employed'].fillna('No')","1656577a":"plt.figure(figsize=(12,8))\nsns.countplot(train_data['Loan_Amount_Term']);","fde58dce":"train_data['Loan_Amount_Term']= train_data['Loan_Amount_Term'].fillna(360)","0fdf94ad":"plt.figure(figsize=(12,8))\nsns.countplot(test_data['Loan_Amount_Term']);","d39cfafe":"test_data['Loan_Amount_Term']= test_data['Loan_Amount_Term'].fillna(360)","39501983":"train_data.isna().sum()","3b74e594":"test_data.head()","d1fcfd95":"# For Loan Status\ntrain_data['Loan_Status'] = train_data['Loan_Status'].replace({\"Y\" : 1, \"N\" : 0})\n\n# For Gender\ntrain_data['Gender'] = train_data['Gender'].replace({\"Male\" : 1, \"Female\" : 0})\ntest_data['Gender'] = test_data['Gender'].replace({\"Male\" : 1, \"Female\" : 0})\n\n# For Married\ntrain_data['Married'] = train_data['Married'].replace({\"Yes\" : 1, \"No\" : 0})\ntest_data['Married'] = test_data['Married'].replace({\"Yes\" : 1, \"No\" : 0})\n\n# For Credit History\ntrain_data['Self_Employed'] = train_data['Self_Employed'].replace({\"Yes\" : 1, \"No\" : 0})\ntest_data['Self_Employed'] = test_data['Self_Employed'].replace({\"Yes\" : 1, \"No\" : 0})\n","59a61f3c":"from sklearn.preprocessing import LabelEncoder\nfeature_col = ['Property_Area','Education', 'Dependents']\nle = LabelEncoder()\nfor col in feature_col:\n    train_data[col] = le.fit_transform(train_data[col])\n    test_data[col] = le.fit_transform(test_data[col])","ea2f9fe7":"train_data.head()","b2286e11":"sns.set_style('dark')","4a3150a6":"train_data.plot(figsize=(18, 8))\n\nplt.show()","df24b918":"plt.figure(figsize=(18, 6))\nplt.subplot(1, 2, 1)\n\n\ntrain_data['ApplicantIncome'].hist(bins=15)\nplt.title(\"Loan Application Amount \")\n\nplt.subplot(1, 2, 2)\nplt.grid()\nplt.hist(np.log(train_data['LoanAmount']))\nplt.title(\"Log Loan Application Amount \")\n\nplt.show()","e2ffdc86":"plt.figure(figsize=(18, 6))\nplt.title(\"Relation Between Applicatoin Income vs Loan Amount \")\n\nplt.grid()\nplt.scatter(train_data['ApplicantIncome'] , train_data['LoanAmount'], c='k', marker='x')\nplt.xlabel(\"Applicant Income\")\nplt.ylabel(\"Loan Amount\")\nplt.show()","ecb065ec":"plt.figure(figsize=(12,8))\nsns.heatmap(train_data.corr(), cmap='coolwarm', annot=True, fmt='.1f', linewidths=.1)\nplt.show()","3754a79c":"X = train_data.drop(columns=['Loan_Status', 'Loan_ID'], axis=1)\ny = train_data['Loan_Status']","f0fc4908":"from sklearn .model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3)","f1d2590a":"X_train.shape","a1549c23":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","f0871b7b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR = LR.fit(X_train,y_train)\n\ny_predlr = LR.predict(X_test)\n\nprint(classification_report(y_test,y_predlr))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_predlr)}\")\nlr_results = accuracy_score(y_test,y_predlr)","7d64116c":"from sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators = 100,\n                                      criterion = \"entropy\",\n                                      random_state =42)\nrf_classifier.fit(X_train,y_train)\ny_predrf = rf_classifier.predict(X_test)\n\nprint(classification_report(y_test,y_predrf))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_predrf)}\")\nrf_results = accuracy_score(y_test,y_predrf)","4e42b25e":"from sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion = \"entropy\",random_state = 42)\ndt_classifier.fit(X_train,y_train)\ny_preddt = dt_classifier.predict(X_test)\n\nprint(classification_report(y_test,y_preddt))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_preddt)}\")\ndt_results = accuracy_score(y_test,y_preddt)","4a048fb0":"from sklearn.naive_bayes import GaussianNB\nNBClassifier=GaussianNB()\nNBClassifier.fit(X_train,y_train)\ny_prednb = NBClassifier.predict(X_test)\nprint(classification_report(y_test,y_prednb))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_prednb)}\")\n\nnb_results = accuracy_score(y_test,y_prednb)","32b9cf29":"# creating the dataset\ndata = {'Logistic Regression':round(lr_results,2),\n        'Random Forest Classification':round(rf_results,2),\n        'Decision Tree':round(dt_results,2),\n        'Naive Bayes':round(nb_results,2)}\nAlgo = list(data.keys())\nvalues = list(data.values())","7d9fa203":"# Visualize the Models\nplt.figure(figsize=(24, 8))\nplt.subplot(1, 2, 1)\n\nplt.grid()\nplt.bar(Algo, values, color ='maroon',\n        width = 0.4) \nplt.xlabel(\"Type of Algo\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Comparison between algo\")\n\nplt.subplot(1, 2, 2)\nplt.grid()\nplt.bar(Algo, np.log(values), color ='blue',\n        width = 0.4)\nplt.title(\"Log of Accuracy\")\n\nplt.show()","70048608":"# model.fit(X_train, Y_train)\n# # save the model to disk\n# filename = 'finalized_model.sav'\n# pickle.dump(model, open(filename, 'wb'))\n\n# # some time later...\n\n# # load the model from disk\n# loaded_model = pickle.load(open(filename, 'rb'))\n# result = loaded_model.score(X_test, Y_test)\n# print(result)","e9b888bc":"# 5. Deploy the Model","8b5cc70b":"### **#convert Categorical variable with Numerical values**","45eb6dba":"## WE CAN SEE THAT\nLogistic Regression and Naive Bayes is doing the best as algorithm","216b4630":"### 3. Decision Tree","d76f0896":"* As you can see that there are many columns with null values but they are small in number so we can replcae them with mean or mode of the particular column\n","f4b0a998":"# 2. Exploratory Data Analysis","2652b633":"# 3. Data Visualization","38b49b7a":"# 4. Choosing ML Model\nfrom the following choices\n* Logistic Regression\n* Random Forest Classifier\n* Decision Tree","bf6c503d":"### ALL THE MISSING VALUES ARE FILLED USING DATA VISUALIZATION AND STATISTICS","40799702":"**Here, Property_Area, Dependents and Education has multiple values so now we can use LabelEncoder from sklearn package**","cdc7661c":"### 4. Naive Bayes","38ab3087":"### 1. Linear Regression Model","0931a882":"### 3. Random Forest Tree","920785e5":"# Importing Major Libraries and Gathering Data","2abdf8f5":"In this heatmap, we can clearly seen the relation between two variables of which majorly are:\n* Applicant Income and Loan Amount\n* Credit History and Loan Status","51697d2e":"* That [0] in mode()[0] is due to bug you can search on stackoverflow"}}