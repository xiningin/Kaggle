{"cell_type":{"33e59f50":"code","8ae43225":"code","dee67330":"code","a665919a":"code","b0f394cd":"code","4e63e410":"code","c91c93b0":"code","30929913":"code","d9b24f80":"code","e06c605a":"code","bfe4bbca":"code","3c23c24f":"code","b242a154":"code","95605d6e":"code","1030f2d3":"code","91914c56":"code","8ebea9ef":"code","e2af621d":"code","6c0fe591":"code","a0678500":"code","a7c104d4":"code","fab009f7":"code","71b8f1fc":"code","f77fda09":"code","a8b0647b":"code","a2fe8498":"code","9bdea188":"code","6ae65920":"code","5afa94ed":"code","88c86c7f":"code","695213d4":"code","15565337":"code","19687d22":"code","a069af3c":"code","e8cc1eec":"code","a5402433":"code","756fe899":"code","9061b700":"code","2286d286":"code","7b1db6d2":"code","3b6c13b4":"code","986bd39a":"code","07f8b36d":"code","10688c7e":"code","7bde0d1e":"code","91ff31b0":"markdown","e549bc4f":"markdown","5d16f0e5":"markdown","6bc494e8":"markdown","207525b0":"markdown","7d4f914a":"markdown","f4c97e50":"markdown","cb5de47d":"markdown","8e3c1a87":"markdown","2dd7c38b":"markdown","035fb712":"markdown","879dbef5":"markdown","acaeb291":"markdown","28ef02ef":"markdown","73ea1093":"markdown","f45f2d87":"markdown","39021f72":"markdown","0efe7625":"markdown","98a11a78":"markdown","0838420a":"markdown","9cd057c7":"markdown","946fca2a":"markdown","4e93f164":"markdown","48e67801":"markdown","e22849da":"markdown","eabe86af":"markdown","ef257ea4":"markdown","47a39818":"markdown","8d5fa2cb":"markdown"},"source":{"33e59f50":"from __future__ import absolute_import, division, print_function, unicode_literals","8ae43225":"# !pip install -q pmdarima","dee67330":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# plt.style.use('fivethirtyeight')\nimport pathlib\nimport os\nimport seaborn as sns\nimport pandas as pd\nfrom datetime import datetime\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n# import pmdarima as pm\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n# import joblib\nsns.set()","a665919a":"# from google.colab import drive\n# drive.mount('\/content\/gdrive', force_remount=True)\n# root_dir = \"\/content\/gdrive\/My Drive\/\"\n# base_dir = root_dir + 'MachineLearning\/DelhiTemperaturePrediction\/'","b0f394cd":"# def displayDirContent(dir):\n#   if pathlib.posixpath.exists(dir):\n#     for name in list(pathlib.Path(dir).glob('*')):\n#       print(name)\n#   else:\n#     print(\"Path does not exists\")","4e63e410":"# displayDirContent(base_dir)","c91c93b0":"print(os.listdir(\"..\/input\/delhi-weather-data\"))","30929913":"data_dir = \"..\/input\/delhi-weather-data\/\"\n# displayDirContent(data_dir)","d9b24f80":"data = pd.read_csv(data_dir + 'testset.csv')","e06c605a":"data.head()","bfe4bbca":"data.tail()","3c23c24f":"def overViewOfTheData(data,frows=5,lrows=5):\n  print(\"Shape: \",data.shape,\"\\n\\n\")\n  \n  print(\"Columns: \",data.columns,\"\\n\\n\")\n\n  print(\"Info : \")\n  print(data.info())","b242a154":"overViewOfTheData(data)","95605d6e":"plt.figure(figsize=(8,8))\nsns.barplot(x=data.count()[:],y=data.count().index)\nplt.xlabel('Non-Null Values Count')\nplt.ylabel('Features')","1030f2d3":"data = data.drop([' _heatindexm',' _precipm',' _wgustm',' _windchillm'],axis=1)","91914c56":"# Date-Time column is not in the desired format. So, first we will convert it into the desired format (yyyy-mm-dd HH:MM)\n# And the we will make that column the index of the data\n\ndata['datetime_utc'] = pd.to_datetime(data['datetime_utc'].apply(lambda x: datetime.strptime(x,\"%Y%m%d-%H:%M\").strftime(\"%Y-%m-%d %H:%M\")))\ndata['datetime_utc'].head()","8ebea9ef":"data = data.set_index('datetime_utc',drop=True)\ndata.index.name = 'datetime'","e2af621d":"fig, ax = plt.subplots()\ndata[' _tempm'].plot(figsize=(15,12),ax=ax)\nax.set_xlabel('Date-Time')\nax.set_ylabel('Temperature in C')\nax.set_title('Temperature in Delhi')\nplt.show()","6c0fe591":"# Dropping the data before 2001\ndata = data['2001':]","a0678500":"# We will remove the missing data and later we will interpolate the temperature for that missing data\nprint(\"Before : \", data.shape)\ndata.dropna(subset=[' _tempm'],inplace=True)\nprint(\"After :\", data.shape)","a7c104d4":"data.index.minute.value_counts()","fab009f7":"categoricalColumns = list(set(data.columns) - set(data._get_numeric_data().columns))\ncategoricalColumns","71b8f1fc":"# We are resampling it by hours & filling the missing values using the interpolation method\n# Notice here we will only get numeric columns so we will have to add the categorical columns additionaly\nnewdata = data.resample('H').mean().interpolate()\nnewdata.info()","f77fda09":"# To resample the categorical data we will consider the firt observation and to fill the missing values we will use ffill method\nnewdata[list(categoricalColumns)] = data[categoricalColumns].resample('H').first().ffill().head()\nnewdata.head()","a8b0647b":"def plotAggregateValues(data,column=None):\n  if column in data.columns:\n    plt.figure(figsize = (18,25))\n    \n    ax1 = plt.subplot(4,2,1)\n    newdata[column].groupby(newdata.index.year).mean().plot(ax=ax1,title='yearly mean values')\n    ax1.set_xlabel('years')\n    ax1.set_ylabel(column)\n  \n    ax2 = plt.subplot(4,2,2)\n    newdata[column].groupby(newdata.index.month).mean().plot(ax=ax2,title='monthly mean values')\n    ax2.set_xlabel('months')\n    ax2.set_ylabel(column)\n\n    # ax3 = plt.subplot(4,2,3)\n    # newdata[column].groupby(newdata.index.weekday).mean().plot(ax=ax3,title='weekdays mean values')\n    # ax3.set_xlabel('weekdays')\n    # ax3.set_ylabel(column)\n\n    ax4 = plt.subplot(4,2,4)\n    newdata[column].groupby(newdata.index.hour).mean().plot(ax=ax4,title='hourly mean values')\n    ax4.set_xlabel('hours')\n    ax4.set_ylabel(column)\n\n    # ax5 = plt.subplot(4,2,5)\n    # newdata[column].groupby(newdata.index.minute).mean().plot(ax=ax5,title='minute wise mean values')\n    # ax5.set_xlabel('minutes')\n    # ax5.set_ylabel(column)\n\n    # ax6 = plt.subplot(4,2,6)\n    # newdata[column].groupby(newdata.index.second).mean().plot(ax=ax6,title='seconds wise mean values')\n    # ax6.set_xlabel('seconds')\n    # ax6.set_ylabel(column)\n\n  else:\n    print(\"Column name not specified or Column not in the data\")","a2fe8498":"plotAggregateValues(newdata,' _tempm')","9bdea188":"def plotBoxNdendity(data,col=None):\n  if col in data.columns:    \n    plt.figure(figsize=(18,8))\n\n    ax1 = plt.subplot(121)\n    data.boxplot(col,ax=ax1)\n    ax1.set_ylabel('Boxplot temperature levels in Delhi', fontsize=10)\n\n    ax2 = plt.subplot(122)\n    data[col].plot(ax=ax2,legend=True,kind='density')\n    ax2.set_ylabel('Temperature distribution in Delhi', fontsize=10)\n\n  else:\n    print(\"Column not in the data\")","6ae65920":"plotBoxNdendity(data,' _tempm')","5afa94ed":"train = newdata[:'2015']\ntest = newdata['2016':]","88c86c7f":"# Let's decompose the time series to visualize trend, season and noise seperately\ndef decomposeNplot(data):\n  decomposition = sm.tsa.seasonal_decompose(data)\n\n  plt.figure(figsize=(15,16))\n\n  ax1 = plt.subplot(411)\n  decomposition.observed.plot(ax=ax1)\n  ax1.set_ylabel('Observed')\n\n  ax2 = plt.subplot(412)\n  decomposition.trend.plot(ax=ax2)\n  ax2.set_ylabel('Trend')\n\n  ax3 = plt.subplot(413)\n  decomposition.seasonal.plot(ax=ax3)\n  ax3.set_ylabel('Seasonal')\n\n  ax4 = plt.subplot(414)\n  decomposition.resid.plot(ax=ax4)\n  ax4.set_ylabel('Residuals')\n\n  return decomposition","695213d4":"# Resampling the data to mothly and averaging out the temperature & we will predict the monthly average temperature\nftraindata = train[' _tempm'].resample('M').mean()\nftestdata = test[' _tempm'].resample('M').mean()","15565337":"# Taking the seasonal difference S=12 and decomposing the timeseries\ndecomposition = decomposeNplot(ftraindata.diff(12).dropna())","19687d22":"# Let's check for stationarity (Augmented Dickey Fuller test)\nresults = adfuller(ftraindata.diff(12).dropna())\nresults","a069af3c":"# To get non-seasonal oreders of the SARIMAX Model we will first use ACF & PACF plots\nplt.figure(figsize=(10,8))\n\nax1 = plt.subplot(211)\nacf = plot_acf(ftraindata.diff(12).dropna(),lags=30,ax=ax1)\n\nax2 = plt.subplot(212)\npacf = plot_pacf(ftraindata.diff(12).dropna(),lags=30,ax=ax2)","e8cc1eec":"# To get seasonal oreders of the SARIMAX Model we will first use ACF & PACF plots at seasonal lags \n\nlags = [12*i for i in range(1,4)]\n\nplt.figure(figsize=(10,8))\n\nax1 = plt.subplot(211)\nacf = plot_acf(ftraindata.diff(12).dropna(),lags=lags,ax=ax1)\n\nax2 = plt.subplot(212)\npacf = plot_pacf(ftraindata.diff(12).dropna(),lags=lags,ax=ax2)","a5402433":"model = SARIMAX(ftraindata,order=(0,0,1),seasonal_order=(0,1,1,12),trend='n')\nresults = model.fit()","756fe899":"# # Lets select the best model based on the aic & bic scores using auto_arima\n# results = pm.auto_arima(ftraindata,\n#                       seasonal=True, m=12,\n#                       d=0,D=1,trace=True,\n#                       error_action='ignore',\n#                       suppress_warnings=True)","9061b700":"# Check the value of Prob(Q) if it is > 0.05 => The residuals are uncorrelated\n# Similarly if Prob(JB) > 0.05 => The residuals are normally distributed\nresults.summary()","2286d286":"# Mean Absolute Error for training data\nprint(np.mean(np.abs(results.resid)))","7b1db6d2":"diagnostics = results.plot_diagnostics(figsize=(10,10))","3b6c13b4":"forecast = results.get_forecast(steps=len(ftestdata))","986bd39a":"predictedmean = forecast.predicted_mean\nbounds = forecast.conf_int()\nlower_limit = bounds.iloc[:,0]\nupper_limit = bounds.iloc[:,1]","07f8b36d":"plt.figure(figsize=(12,8))\n\nplt.plot(ftraindata.index, ftraindata, label='train')\nplt.plot(ftestdata.index,ftestdata,label='actual')\n\nplt.plot(predictedmean.index, predictedmean, color='r', label='forecast')\n\nplt.fill_between(lower_limit.index,lower_limit,upper_limit, color='pink')\n\nplt.xlabel('Date')\nplt.ylabel('Delhi Temperature')\nplt.legend()\nplt.show()","10688c7e":"# displayDirContent(base_dir)","7bde0d1e":"# filename = 'SARIMA_0_0_1_0_1_1_12.pkl'\n# joblib.dump(results,filename = base_dir + 'Models\/' + filename)","91ff31b0":"#### Stationary?","e549bc4f":"#### Automatic Model Selection","5d16f0e5":"*  As ACF cuts off after lag 1 & PACF is trailing off we can say that the order of seasonal MA is 1 (Q=1)","6bc494e8":"<font color='red' size=5>Please!!! Upvote this kernel if you find it useful.<\/font>","207525b0":"*  We observed before that there is a yearly periodic pattern -> Seasonal","7d4f914a":"### 1. Identification","f4c97e50":"### 2. Estimation ","cb5de47d":"*  Here we can see:   \n  1. Standardized residual plot: No obvious structure \u2714\n  2. Histogram & KDE: KDE is normally distributed \u2714\n  3. Normal Q-Q: Almost all the points are on the red line \u2714\n  4. Correlogram of residuals: is nearly zero for all lags \u2714 ","8e3c1a87":"#### Order of the model?","2dd7c38b":"*   Many of the features have a lot of missing values\n*   We will remove those features which are having a lot of missing values (heatindexm, precipm, wgustm & windchillm) & we will try to fill missing values in the rest of the features\n*   We can see there are some missing values in **temp** also.\n","035fb712":"## Loading Data","879dbef5":"*  We can observe outliers in box plot which are extremely high.\n*  50% of the temperature values are distributed around ~26 C","acaeb291":"*  Here we can see we have **irregular time-intervals**\n*  So we will remove the minute time-stamp and will only consider the hourly data","28ef02ef":"* ~3 *C monthly average temperature error","73ea1093":"### Train & Test Split","f45f2d87":"## Pre-processing and EDA","39021f72":"### 4. Forecasting","0efe7625":"*  We can a **seasonal** pattern in the timeseries\n*  It is also not continuous as it is having some missing data (ex: between 2000 and 2001)\n*  This could be a problem while modeling the timeseries. So, to avoid this we will train our model on the data from the year-2001 as we have enough data for training and there is no significant trend that we will miss by dropping the data before 2001\n*  We have some **OUTLIERS** in the series also as we can see some really high temperature values. We will remove these outliers.\n*  We have large amount of data but we will only use the necessary data (2013-2016)","98a11a78":"* p-value is less than 0.05 and test-statistic is also less very -ev\n* So we can say the series is stationary and we can model it without any further transforms ","0838420a":"## Importing necessary libraries","9cd057c7":"## Mounting Google Drive","946fca2a":"## Overview to the data","4e93f164":"*  It's hard to get the idea of the non-seasonal orders from these plots ","48e67801":"*  We can see highest temperature during 5th & 6th month as it is summer time and low temperature during the end and start of the year because of winter.\n*  Also, there is high temperature during 11-13 hours as it is noon time and low temperature during night hours.","e22849da":"### 5. Saving the model","eabe86af":"## Introduction\n\n![](https:\/\/media.giphy.com\/media\/3o7TKGsK4gcsly0rW8\/giphy.gif)\n\n\n**\u2018Time\u2019** is the most important factor which ensures success in a business. It\u2019s difficult to keep up with the pace of time.  But, technology has developed some powerful methods using which we can **\u2018see things\u2019** ahead of time. Don\u2019t worry, I am not talking about Time Machine. Let\u2019s be realistic here!\n\nI\u2019m talking about the methods of **prediction & forecasting**. One such method, which deals with time based data is **Time Series Modeling**. As the name suggests, it involves working on time (years, days, hours, minutes) based data, to derive hidden insights to make informed decision making.\n\n**Time series models** are very useful models when you have serially correlated data. Most of business houses work on time series data to analyze sales number for the next year, website traffic, competition position and much more. However, it is also one of the areas, which many analysts do not understand.\n\nSo, if you aren\u2019t sure about complete process of time series modeling, this guide would introduce you to various levels of time series modeling and its related techniques.\n\n\nLet's predict the temperature. \ud83e\uddd0\n\n<font color='red' size=5>Please!!! Upvote this kernel if you find it useful.<\/font>","ef257ea4":"\n## Model Building ","47a39818":"#### Seasonal?","8d5fa2cb":"### 3. Diagnostics"}}