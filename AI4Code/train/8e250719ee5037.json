{"cell_type":{"eae583cc":"code","07bf1da8":"code","eff88ad0":"code","5aaa617d":"code","464c397f":"code","c39c5dea":"code","b3610a73":"code","6e8dd56b":"code","e5dc6a46":"code","602f2ee9":"code","e01fb9a8":"code","d6ecbbbc":"code","050e01cc":"code","99286d81":"code","7fdc56f7":"code","56661c16":"code","a98fb215":"code","523f90aa":"code","21e6f50e":"code","e9b597d8":"code","8edfda50":"code","77278c7d":"code","3ce9c5d0":"code","32486a77":"code","a398c7a4":"code","91ee8c12":"code","0fdb9d02":"code","fdc2ca4d":"code","77fb1659":"code","4665f709":"code","e655d9c0":"code","5cb2da3a":"code","12f217a7":"code","f76af4b4":"code","1f50c197":"code","b9885b5a":"code","71aa4c84":"code","f84d1129":"markdown","ce1b7ec7":"markdown","8adb466e":"markdown","805879af":"markdown","c35ec397":"markdown"},"source":{"eae583cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07bf1da8":"input = !ls \/kaggle\/input\ninput = '\/kaggle\/input\/{}\/'.format(input[0])\noutput = '\/kaggle\/working\/'\n\nprint(input, output)","eff88ad0":"## \u57fa\u7840\u5de5\u5177\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nimport scipy\nimport math\n\nnp.random.seed(2021)","5aaa617d":"def float_check(x):\n    '''\n    \u68c0\u6d4b\u6d6e\u70b9\u6570\u7684\u5c0f\u6570\u4f4d\u6570\n    9    103589 \uff08\u4fdd\u7559\uff09\n    1     33551 \uff08=0\u7684\u9700\u8981\u5904\u7406\uff0c\u5176\u5b83\u7684\u914c\u60c5\uff09\n    8     10636 \uff08\u4fdd\u7559\uff09\n    7      1047 \uff08\u4fdd\u7559\uff09\n    6       135 \uff08\u4fdd\u7559\uff09\n    4        76 \uff08\u4fdd\u7559\uff09\n    3        56 \uff08\u4fdd\u7559\uff09\n    5        51 \uff08\u4fdd\u7559\uff09\n    2        22 \uff08\u4fdd\u7559\uff09\n    0         1  drop\n    '''\n    if '.' in str(x):\n        return(len(str(x).split('.')[-1]))\n    else :\n        return 0\n    \ndef float_last(x):\n    if '.' in str(x):\n        return(str(x)[-1])\n    else :\n        return False\n    \ndef sample_Interval(col, start, end, closed):\n    '''\n    \u53bb\u9664\u9996\u5c3e\u5f02\u5e38\u503c\uff0c\u5229\u7528\u5206\u7ec4\n    \u76f4\u63a5\u64cd\u4f5cDataFrame\u5bf9\u8c61\n    start, end \u662f\u5355\u4e2a\u503c\n    '''\n    z = 0.0000000001\n    global df_train\n    interval_index = pd.IntervalIndex.from_arrays([start], [end+z], closed=closed)\n    x = pd.cut(df_train[col], interval_index, right=False)\n    print(col,'drop\uff1a',x.isnull().sum())\n    df_train = df_train[x.notnull()]\n    \n\ndef make_box(col, box_index):\n    '''\n    col, start, end, closed \u542b\u4e49\u53c2\u8003pd.IntervalIndex.from_arrays()\n    \u505a\u5206\u7ec4\u7528\n    type(n): int IntervalIndex\n    n=5\n    n=pd.IntervalIndex.from_arrays([start], [end+z], closed=closed)\n    right:This argument is ignored when bins is an IntervalIndex.\n    '''\n    global df_train, box\n    \n    # \u5207\u5272\u6570\u636e\n    base = pd.IntervalIndex.from_arrays([1], [2], closed='left')\n    if type(box_index)==type([]):\n        n = box_index[0]\n        right = True if box_index[1]=='right' else False\n        cut = pd.cut(df_train[col], n, right=right)\n    elif type(box_index)==type(base):\n        interval_index = pd.IntervalIndex.from_arrays(box_index[0], box_index[1], closed=box_index[2])\n        cut = pd.cut(df_train[col], interval_index)\n    else:\n        print(\"box_index \u7684\u7c7b\u578b\u9519\u8bef\")\n        print(box_index)\n        return 1\n    \n    Customer = df_train['SeriousDlqin2yrs'].groupby(cut).count()\n    Bad = df_train['SeriousDlqin2yrs'].groupby(cut).sum()\n    Good = Customer-Bad\n    box_col = pd.merge(pd.DataFrame(Customer),pd.DataFrame(Bad) ,left_index=True,right_index=True)\n    box_col.rename(columns={'SeriousDlqin2yrs_x':'CustomerNumber','SeriousDlqin2yrs_y':'Bad'},inplace=True)\n    box_col.insert(0, \"Feature\", col)\n    box_col.insert(len(box_col.columns), \"Good\", Customer-Bad)\n    box_col.insert(len(box_col.columns), \"BadRatio\", Bad\/Customer)\n    box_col.index.name = 'Id'\n    return box_col\n    \ndef correlation_analysis():\n    global box_col, features\n    fig,subs=plt.subplots(math.ceil(len(features)\/2), 2, figsize=(20,23))\n\n    for i,col in enumerate(features):\n        box_col = box[box['Feature']==col]\n        sub_a = i\/\/2\n        sub_b = i%2\n        # \u56feA\n        labels = box_col.index.tolist()\n        Good_data = box_col['Good']\n        Bad_data = box_col['Bad']\n        BadRatio_data = box_col['BadRatio']*box_col['CustomerNumber']\n        # x\u8f74\u662f\u7531[1,2,3,4,5] \u7ec4\u6210\n        x=np.arange(len(labels))\n        width = 0.35\n        #fig,ax  = plt.subplots()\n        # \u5148\u753bGood\n        bar1 = subs[sub_a][sub_b].bar(x-width\/2, Good_data, width, label='Good')\n        for rect in bar1:\n            height = rect.get_height()\n            #annotate\u51fd\u6570\u662f\u7528\u6765\u5bf9\u56fe\u50cf\u8fdb\u884c\u6807\u6ce8\uff0c\n            #\u53c2\u6570xy\u8868\u793a\u6807\u6ce8\u4f4d\u7f6e\n            # xytext\u8868\u793a\u6587\u672c\u4f4d\u7f6e\uff08\u5728xy\u7684\u4f4d\u7f6e\u8fdb\u884c\u591a\u5c11\u504f\u79fb\uff09\n            subs[sub_a][sub_b].annotate('{}'.format(height),\n                        xy=(rect.get_x()+rect.get_width()\/2,height),\n                        xytext=(0,3),\n                        textcoords='offset points',\n                        ha = 'center',\n                        va = 'bottom',fontsize=8)\n        # \u518d\u753bBad\n        bar2 = subs[sub_a][sub_b].bar(x+width\/2, Bad_data, width, label='Bad')\n        # \u518d\u753b\u6298\u7ebf\n        subs[sub_a][sub_b].plot(BadRatio_data.to_list(), color='red', label='BadRatio')\n        for rect in bar2:\n            height = rect.get_height()\n            #annotate\u51fd\u6570\u662f\u7528\u6765\u5bf9\u56fe\u50cf\u8fdb\u884c\u6807\u6ce8\uff0c\n            #\u53c2\u6570xy\u8868\u793a\u6807\u6ce8\u4f4d\u7f6e\n            # xytext\u8868\u793a\u6587\u672c\u4f4d\u7f6e\uff08\u5728xy\u7684\u4f4d\u7f6e\u8fdb\u884c\u591a\u5c11\u504f\u79fb\uff09\n            subs[sub_a][sub_b].annotate('{}'.format(height),\n                        xy=(rect.get_x()+rect.get_width()\/2,height),\n                        xytext=(0,3),\n                        textcoords='offset points',\n                        ha = 'center',\n                        va = 'bottom', fontsize=8)\n        # \u8bbe\u7f6e\u56fe\u50cf\u7684\u4e00\u4e9b\u53c2\u6570\n        subs[sub_a][sub_b].set_ylabel('Customer Number')\n        subs[sub_a][sub_b].set_title('Customer Number by {}'.format(col))\n        subs[sub_a][sub_b].set_xticks(x)\n        subs[sub_a][sub_b].set_xticklabels(labels, rotation=15, fontsize=10)\n        subs[sub_a][sub_b].legend()\n\n\n    #tight_layout()\uff0c\u4f5c\u7528\u662f\u81ea\u52a8\u8c03\u6574\u5b50\u56fe\u53c2\u6570\uff0c\u4f7f\u4e4b\u586b\u5145\u6574\u4e2a\u56fe\u50cf\u533a\u57df\u3002\n    fig.tight_layout()\n    fig.show()","464c397f":"# Step1\uff1a \u52a0\u8f7d\u6570\u636e\ncs_training = pd.read_csv(input+'cs-training.csv')\ncs_training = cs_training.iloc[:, 1:]\ndf_train = cs_training.copy()","c39c5dea":"features = [*df_train.columns]\nfeatures.remove('SeriousDlqin2yrs')\ndescribe = df_train.describe()","b3610a73":"\n# Step2\uff1a\u53bb\u9664\u91cd\u590d\u503c\u5e76\u6062\u590d\u7d22\u5f15\ndf_train.drop_duplicates(inplace=True)\n\n# Step3\uff1a\u53d1\u73b0 \u201cMonthlyIncome\u201d\u548c\u201cNumberOfDependents\u201d \u5305\u542b\u5927\u91cf\u7f3a\u5931\u503c\n# \u4f7f\u7528\u5747\u503c\u586b\u8865\u201cNumberOfDependents\u201d\u7684\u7f3a\u5931\u503c\ndf_train[\"NumberOfDependents\"].fillna(int(df_train[\"NumberOfDependents\"].mean()),inplace=True)\n# \u4f7f\u7528\u5747\u503c\u586b\u8865 \u201cMonthlyIncome\u201d \u7684\u7f3a\u5931\u503c\ndf_train['MonthlyIncome'].fillna(df_train['MonthlyIncome'].mean(),inplace=True)\n\n# \u67e5\u770b\u7f3a\u5931\u503c\u6bd4\u4f8b\uff0c\u9884\u671f\u4e0d\u80fd\u6709\u7f3a\u5931\u503c\ndisplay(df_train.isna().sum()\/df_train.shape[0])\n\n# Step4\uff1a\u5904\u7406\u5f02\u5e38\u503c\n# \u63cf\u8ff0\u6027\u7edf\u8ba1\ndisplay(df_train.describe([.01,.1,.25,.5,.75,.9,.99]).T)\n\n# '''  \u5f02\u5e38\u503c\u5904\u7406\u89c4\u5219\n# RevolvingUtilizationOfUnsecuredLines\uff0c[min, max+0.0000000001)\n# age\uff0c[min, max+0.0000000001)\n# NumberOfTime30-59DaysPastDueNotWorse\uff0c [min,80)\n# NumberOfTime60-89DaysPastDueNotWorse\uff0c  [min,80)\n# NumberOfTimes90DaysLate\uff0c  [min,80)\n# NumberRealEstateLoansOrLines,  [min, max+0.0000000001)\n# DebtRatio\uff0c\u5e94\u8be5\u662f\u6bd4\u7387\uff0c23%\u7684\u5927\u4e8e1,\u5f88\u591a\u6570\u636e\u5305\u542b\u6574\u6570\uff0c\u6700\u5927\u503c\u9006\u5929\u4e86\uff0c\u5148\u81ea\u52a8\u5206\u7ec4\uff0c\u7136\u540e\u5904\u7406\u5f02\u5e38\u503c [min, max+0.0000000001)\n# MonthlyIncome\uff0c [min, max+0.0000000001)\n# NumberOfOpenCreditLinesAndLoans\uff0c[min, max+0.0000000001)\n# NumberOfDependents, [min, max+0.0000000001)\n# '''\n# \u53e6\u4e00\u4e2a\u53ef\u9009\u7684\u65b9\u6848\u662f\u5c06\u5f02\u5e38\u503c\u5206\u7bb1\n# print(df_train.shape)\n# col = 'RevolvingUtilizationOfUnsecuredLines'\n# sample_Interval(col, describe[col]['min'], describe[col]['max'], 'left')\n# col = 'NumberOfTime30-59DaysPastDueNotWorse'\n# sample_Interval('NumberOfTime30-59DaysPastDueNotWorse', describe[col]['min'], 80, 'left')\n# col = 'NumberOfTime60-89DaysPastDueNotWorse'\n# sample_Interval('NumberOfTime60-89DaysPastDueNotWorse', describe[col]['min'], 80, 'left')\n# col = 'NumberOfTimes90DaysLate'\n# sample_Interval('NumberOfTimes90DaysLate', describe[col]['min'], 80, 'left')\n# print(df_train.shape)\n\n\n# Step5\uff1acolumns\u8f6c\u7f6e\u6210\u4e2d\u6587\uff0c\u7531\u4e8e\u4e0d\u80fd\u89e3\u51b3kaggle\u753b\u56fe\u663e\u793a\u4e2d\u6587\u7684\u95ee\u9898\n# columns_translate ={'SeriousDlqin2yrs':'\u5ba2\u6237\u5206\u7c7b',\n#         'RevolvingUtilizationOfUnsecuredLines':'\u53ef\u7528\u989d\u5ea6\u6bd4\u503c',\n#         'age':'\u5e74\u9f84',\n#         'NumberOfTime30-59DaysPastDueNotWorse':'\u903e\u671f30-59\u5929\u7b14\u6570',\n#         'DebtRatio':'\u8d1f\u503a\u7387',\n#         'MonthlyIncome':'\u6708\u6536\u5165',\n#         'NumberOfOpenCreditLinesAndLoans':'\u4fe1\u8d37\u6570\u91cf',\n#         'NumberOfTimes90DaysLate':'\u903e\u671f90\u5929\u7b14\u6570',\n#         'NumberRealEstateLoansOrLines':'\u56fa\u5b9a\u8d44\u4ea7\u8d37\u6b3e\u91cf',\n#         'NumberOfTime60-89DaysPastDueNotWorse':'\u903e\u671f60-89\u5929\u7b14\u6570',\n#         'NumberOfDependents':'\u5bb6\u5c5e\u6570\u91cf'}\n# column_bak = dict(map(reversed, columns_translate.items()))\n# df_train.rename(columns=column_bak, inplace=True)\n# df_train.head()    #\u4fee\u6539\u82f1\u6587\u5b57\u6bb5\u540d\u4e3a\u4e2d\u6587\u5b57\u6bb5\u540d\n\n\n\n#-----------------------------\n","6e8dd56b":"# Step6\uff1a\u76f8\u5173\u6027\u5206\u6790\nbox_index = {\n    'RevolvingUtilizationOfUnsecuredLines': [4, 'left'],\n    'age': [4,'left'],\n    # 'age': pd.IntervalIndex.from_arrays([min], [max+z]], closed='left')\n    # 'age': pd.IntervalIndex.from_arrays([21,31,41,51,61], [30,40,50,60,float('inf')]], closed='left')\n    'NumberOfTime30-59DaysPastDueNotWorse': [4,'left'],\n    'NumberOfTime60-89DaysPastDueNotWorse':[4,'left'],\n    'NumberOfTimes90DaysLate': [4,'left'],\n    'DebtRatio': [4,'left'],\n    'MonthlyIncome': [4,'left'],\n    'NumberOfOpenCreditLinesAndLoans': [4,'left'],\n    'NumberRealEstateLoansOrLines': [4,'left'],\n    'NumberOfDependents': [4,'left']\n}\nbox = pd.DataFrame()\nfor col in features:\n    box=box.append(make_box(col, box_index[col]))\n\n# display(box)\n# \u7b49\u5206\u7684\u6548\u679c\u5e76\u4e0d\u600e\u4e48\u6837\ncorrelation_analysis()\n\n# \u591a\u53d8\u91cf\u5206\u6790\ncorr = df_train.corr()\ncmap = sns.diverging_palette(200,20,sep=20,as_cmap=True)\nf,ax = plt.subplots(figsize=(15, 10))\nsns.heatmap(corr, annot=True, cmap=cmap, annot_kws={'size':10}, linewidths=.5, fmt= '.3f',ax=ax)\nplt.show()\n","e5dc6a46":"# Step7\uff1a\u6837\u672c\u4e0d\u5747\u8861\u95ee\u9898\nX = df_train.drop('SeriousDlqin2yrs',axis=1)\ny = df_train['SeriousDlqin2yrs']\nsns.countplot(x='SeriousDlqin2yrs', data=df_train)\nplt.show()\n# \u4f7f\u7528SMOTE\u65b9\u6cd5\u8fdb\u884c\u8fc7\u62bd\u6837\u5904\u7406\nfrom imblearn.over_sampling import SMOTE # \u8fc7\u62bd\u6837\u5904\u7406\u5e93SMOTE\nmodel_smote = SMOTE() # \u5efa\u7acbSMOTE\u6a21\u578b\u5bf9\u8c61\nX,y = model_smote.fit_resample(X,y) # \u8f93\u5165\u6570\u636e\u5e76\u4f5c\u8fc7\u62bd\u6837\u5904\u7406\nsmote_resampled = pd.concat([X, y],axis=1) # \u6309\u5217\u5408\u5e76\u6570\u636e\u6846\ngroupby_data_smote = smote_resampled.groupby('SeriousDlqin2yrs').count() # \u5bf9label\u505a\u5206\u7c7b\u6c47\u603b\ngroupby_data_smote # \u6253\u5370\u8f93\u51fa\u7ecf\u8fc7SMOTE\u5904\u7406\u540e\u7684\u6570\u636e\u96c6\u6837\u672c\u5206\u7c7b\u5206\u5e03\nsns.countplot(x='SeriousDlqin2yrs',data=smote_resampled)\nplt.show()\n\n# \u8be5\u65b9\u6cd5\u5bfc\u81f4AUC\u4f4e\u4e8e0.8","602f2ee9":"# \u5207\u5206\u6570\u636e\u96c6\nfrom sklearn.model_selection import train_test_split\nx = df_train.drop('SeriousDlqin2yrs',axis=1)\ny = df_train['SeriousDlqin2yrs']\n\nx_train,x_vali,y_train,y_vali = train_test_split(x,y,test_size=0.3,random_state=2021)\n\ntrain_data = pd.concat([y_train,x_train],axis=1)\ntrain_data.index = range(train_data.shape[0])\ntrain_data.columns = df_train.columns\n\ntest_data = pd.concat([y_vali,x_vali],axis=1)\ntest_data.index = range(test_data.shape[0])\ntest_data.columns = df_train.columns\n\n# Step8\uff1a \u627e\u5230\u5408\u9002\u7684\u5206\u7bb1\u65b9\u6cd5","e01fb9a8":"'''\n\u6709\u76d1\u7763\u65b9\u6cd5\uff1a\u57fa\u4e8esklearn\u51b3\u7b56\u6811\u7684\u6700\u4f18\u5206\u7bb1\u4e0eIV\u503c\u8ba1\u7b97\n'''\nfrom sklearn.tree import DecisionTreeClassifier\n\ndef optimal_binning_boundary(x: pd.Series, y: pd.Series, nan: float = -999.) -> list:\n    '''\n        \u5229\u7528\u51b3\u7b56\u6811\u83b7\u5f97\u6700\u4f18\u5206\u7bb1\u7684\u8fb9\u754c\u503c\u5217\u8868\n    '''\n    boundary = []  # \u5f85return\u7684\u5206\u7bb1\u8fb9\u754c\u503c\u5217\u8868\n    \n    x = x.fillna(nan).values  # \u586b\u5145\u7f3a\u5931\u503c\n    y = y.values\n    \n    clf = DecisionTreeClassifier(criterion='entropy',    #\u201c\u4fe1\u606f\u71b5\u201d\u6700\u5c0f\u5316\u51c6\u5219\u5212\u5206\n                                 max_leaf_nodes=6,       # \u6700\u5927\u53f6\u5b50\u8282\u70b9\u6570\n                                 min_samples_leaf=0.05)  # \u53f6\u5b50\u8282\u70b9\u6837\u672c\u6570\u91cf\u6700\u5c0f\u5360\u6bd4\n    \n    clf.fit(x.reshape(-1, 1), y)  # \u8bad\u7ec3\u51b3\u7b56\u6811\n    \n    n_nodes = clf.tree_.node_count\n    children_left = clf.tree_.children_left\n    children_right = clf.tree_.children_right\n    threshold = clf.tree_.threshold\n    \n    for i in range(n_nodes):\n        if children_left[i] != children_right[i]:  # \u83b7\u5f97\u51b3\u7b56\u6811\u8282\u70b9\u4e0a\u7684\u5212\u5206\u8fb9\u754c\u503c\n            boundary.append(threshold[i])\n    \n    boundary.sort()\n    \n    z = 0.0000000001\n    min_x = x.min()\n    max_x = x.max() + z  # +0.1\u662f\u4e3a\u4e86\u8003\u8651\u540e\u7eedgroupby\u64cd\u4f5c\u65f6\uff0c\u80fd\u5305\u542b\u7279\u5f81\u6700\u5927\u503c\u7684\u6837\u672c\n    boundary = [min_x] + boundary + [max_x]\n    \n    return boundary","d6ecbbbc":"# \u6d4b\u8bd5optimal_binning_boundary\u51fd\u6570\uff1a\noptimal_binning_boundary(x=train_data['RevolvingUtilizationOfUnsecuredLines'],\n                         y=train_data['SeriousDlqin2yrs'])","050e01cc":"# \u83b7\u5f97\u67d0\u4e2a\u53d8\u91cf\u5404\u4e2a\u5206\u7bb1\u7684WOE\u3001IV\u503c\u51fd\u6570\u7684\u5b9e\u73b0\uff1a\ndef feature_woe_iv(feature: str, x: pd.Series, y: pd.Series, nan: float = -999.) -> pd.DataFrame:\n    '''\n        \u8ba1\u7b97\u53d8\u91cf\u5404\u4e2a\u5206\u7bb1\u7684WOE\u3001IV\u503c\uff0c\u8fd4\u56de\u4e00\u4e2aDataFrame\n    '''\n    x = x.fillna(nan)\n    boundary = optimal_binning_boundary(x, y, nan)        # \u83b7\u5f97\u6700\u4f18\u5206\u7bb1\u8fb9\u754c\u503c\u5217\u8868\n    df = pd.concat([x, y], axis=1)                        # \u5408\u5e76x\u3001y\u4e3a\u4e00\u4e2aDataFrame\uff0c\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\n    df.columns = ['x', 'y']                               # \u7279\u5f81\u53d8\u91cf\u3001\u76ee\u6807\u53d8\u91cf\u5b57\u6bb5\u7684\u91cd\u547d\u540d\n    df['bins'] = pd.cut(x=x, bins=boundary, right=False)  # \u83b7\u5f97\u6bcf\u4e2ax\u503c\u6240\u5728\u7684\u5206\u7bb1\u533a\u95f4\n    \n    grouped = df.groupby('bins')['y']                     # \u7edf\u8ba1\u5404\u5206\u7bb1\u533a\u95f4\u7684\u597d\u3001\u574f\u3001\u603b\u5ba2\u6237\u6570\u91cf\n    result_df = grouped.agg([('good',  lambda y: (y == 0).sum()), \n                             ('bad',   lambda y: (y == 1).sum()),\n                             ('total', 'count')])\n\n    result_df['good_pct'] = result_df['good'] \/ result_df['good'].sum()       # \u597d\u5ba2\u6237\u5360\u6bd4\n    result_df['bad_pct'] = result_df['bad'] \/ result_df['bad'].sum()          # \u574f\u5ba2\u6237\u5360\u6bd4\n    result_df['total_pct'] = result_df['total'] \/ result_df['total'].sum()    # \u603b\u5ba2\u6237\u5360\u6bd4\n\n    result_df['bad_rate'] = result_df['bad'] \/ result_df['total']             # \u574f\u6bd4\u7387\n    \n    result_df['woe'] = np.log(result_df['good_pct'] \/ result_df['bad_pct'])              # WOE\n    result_df['iv'] = (result_df['good_pct'] - result_df['bad_pct']) * result_df['woe']  # IV\n    \n    print(f\"'{feature}'\u8be5\u53d8\u91cfIV = {result_df['iv'].sum()}\")\n    \n    return result_df,boundary","99286d81":"# \u51b3\u7b56\u6811\u5206\u7bb1\nbox = {}\nboundary = {}\nfor col in features:\n    box[col],boundary[col] = feature_woe_iv(col, x=train_data[col], y=train_data['SeriousDlqin2yrs'])\n    display(box[col].style.bar(color=['#d65f5f', '#5fba7d'], align='mid', subset=['bad_rate','woe']))","7fdc56f7":"# \u5982\u679c\u9700\u8981\u5206\u7bb1\uff0c\u8c03\u6574 boundary\n# DebtRatio\uff0c\u5e94\u8be5\u662f\u6bd4\u7387\uff0c23%\u7684\u5927\u4e8e1,\u5f88\u591a\u6570\u636e\u5305\u542b\u6574\u6570\uff0c\u6700\u5927\u503c\u9006\u5929\u4e86\uff0c\u5148\u81ea\u52a8\u5206\u7ec4\uff0c\u7136\u540e\u5904\u7406\u5f02\u5e38\u503c [min, max+0.0000000001)\ncol = 'DebtRatio'\nprint(boundary[col])\nbox[col].style.bar(color=['#d65f5f', '#5fba7d'], align='mid', subset=['bad_rate','woe'])\n# \u5904\u7406\u7ed3\u679c\u8fd8\u53ef\u4ee5","56661c16":"def feature_woe_iv_new(feature: str, boundary, x: pd.Series, y: pd.Series, nan: float = -999.) -> pd.DataFrame:\n    '''\n        \u8ba1\u7b97\u53d8\u91cf\u5404\u4e2a\u5206\u7bb1\u7684WOE\u3001IV\u503c\uff0c\u8fd4\u56de\u4e00\u4e2aDataFrame\n    '''\n    x = x.fillna(nan)\n    #boundary = optimal_binning_boundary(x, y, nan)        # \u83b7\u5f97\u6700\u4f18\u5206\u7bb1\u8fb9\u754c\u503c\u5217\u8868\n    df = pd.concat([x, y], axis=1)                        # \u5408\u5e76x\u3001y\u4e3a\u4e00\u4e2aDataFrame\uff0c\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\n    df.columns = ['x', 'y']                               # \u7279\u5f81\u53d8\u91cf\u3001\u76ee\u6807\u53d8\u91cf\u5b57\u6bb5\u7684\u91cd\u547d\u540d\n    df['bins'] = pd.cut(x=x, bins=boundary, right=False)  # \u83b7\u5f97\u6bcf\u4e2ax\u503c\u6240\u5728\u7684\u5206\u7bb1\u533a\u95f4\n    \n    grouped = df.groupby('bins')['y']                     # \u7edf\u8ba1\u5404\u5206\u7bb1\u533a\u95f4\u7684\u597d\u3001\u574f\u3001\u603b\u5ba2\u6237\u6570\u91cf\n    result_df = grouped.agg([('good',  lambda y: (y == 0).sum()), \n                             ('bad',   lambda y: (y == 1).sum()),\n                             ('total', 'count')])\n\n    result_df['good_pct'] = result_df['good'] \/ result_df['good'].sum()       # \u597d\u5ba2\u6237\u5360\u6bd4\n    result_df['bad_pct'] = result_df['bad'] \/ result_df['bad'].sum()          # \u574f\u5ba2\u6237\u5360\u6bd4\n    result_df['total_pct'] = result_df['total'] \/ result_df['total'].sum()    # \u603b\u5ba2\u6237\u5360\u6bd4\n\n    result_df['bad_rate'] = result_df['bad'] \/ result_df['total']             # \u574f\u6bd4\u7387\n    \n    result_df['woe'] = np.log(result_df['good_pct'] \/ result_df['bad_pct'])              # WOE\n    result_df['iv'] = (result_df['good_pct'] - result_df['bad_pct']) * result_df['woe']  # IV\n    \n    print(f\"'{feature}'\u8be5\u53d8\u91cfIV = {result_df['iv'].sum()}\")\n    \n    return result_df\n\n# \u91cd\u65b0\u5206\u7bb1\n# box_new = {}\n# for col in cs_training.columns:\n#     box_new[col] = feature_woe_iv_new(col, boundary[col], x=cs_training[col], y=cs_training['SeriousDlqin2yrs'])\n#     #display(box_new[col].style.bar(color=\"skyblue\", subset=['bad_rate']))","a98fb215":"# Step9:\n# \u5c06\u539f\u6570\u636e\u5206\u7bb1\u540e\uff0c\u6309\u7bb1\u7684\u7ed3\u679c\u628aWOE\u7ed3\u6784\u7528map\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u4e2d\ntrain_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    train_woe[col] = pd.cut(train_data[col],boundary[col], right=False).map(box[col]['woe'])\n    \n#\u5c06\u6807\u7b7e\u8865\u5145\u5230\u6570\u636e\u4e2d\ntrain_woe[\"SeriousDlqin2yrs\"] = train_data[\"SeriousDlqin2yrs\"]\ntrain_woe","523f90aa":"train_woe.isnull().sum()","21e6f50e":"display(train_data[train_woe['MonthlyIncome'].isnull()])\ndisplay(train_woe[train_woe['MonthlyIncome'].isnull()])\ntrain_woe = train_woe.dropna()\ntrain_woe.isnull().sum()","e9b597d8":"#\u5c06\u539f\u6570\u636e\u5206\u7bb1\u540e\uff0c\u6309\u7bb1\u7684\u7ed3\u679c\u628aWOE\u7ed3\u6784\u7528map\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u4e2d\ntest_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    test_woe[col] = pd.cut(test_data[col], boundary[col], right=False).map(box[col]['woe'])\n    \n#\u5c06\u6807\u7b7e\u8865\u5145\u5230\u6570\u636e\u4e2d\ntest_woe[\"SeriousDlqin2yrs\"] = test_data[\"SeriousDlqin2yrs\"]\ntest_woe.isnull().sum()","8edfda50":"display(test_data[test_woe['RevolvingUtilizationOfUnsecuredLines'].isnull()])\ndisplay(test_woe[test_woe['RevolvingUtilizationOfUnsecuredLines'].isnull()])\n\ndisplay(test_data[test_woe['DebtRatio'].isnull()])\ndisplay(test_woe[test_woe['DebtRatio'].isnull()])\n\ndisplay(test_data[test_woe['NumberOfOpenCreditLinesAndLoans'].isnull()])\ndisplay(test_woe[test_woe['NumberOfOpenCreditLinesAndLoans'].isnull()])\n\ndisplay(test_data[test_woe['NumberRealEstateLoansOrLines'].isnull()])\ndisplay(test_woe[test_woe['NumberRealEstateLoansOrLines'].isnull()])\n\ndisplay(test_data[test_woe['NumberOfDependents'].isnull()])\ndisplay(test_woe[test_woe['NumberOfDependents'].isnull()])\ntest_woe = test_woe.dropna()\ntest_woe.isnull().sum()","77278c7d":"# \u5904\u7406\u6d4b\u8bd5\u96c6\nX_test = test_woe.iloc[:,:-1]\ny_test = test_woe.iloc[:,-1]\n# \u5efa\u6a21\nX_train = train_woe.iloc[:,:-1]\ny_train = train_woe.iloc[:,-1]","3ce9c5d0":"from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nfrom sklearn.linear_model import LogisticRegression as LR\nlr = LR(random_state=2021)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n#y_pred2 = lr.predict_proba(X_test)\nprint('Accuracy: ', accuracy_score(y_pred,y_test))\n# \u5c3d\u91cf\u8ba9AUC>=0.8\uff0c\u63d0\u5347AUC\u7684\u65b9\u6cd5\uff1a\n# 1\uff09 IV\u7b5b\u9009\u53ef\u4ee5\u964d\u4f4e0.02\n# 2\uff09 \u8c03\u6574\u5206\u7bb1\n# 3\uff09 \u6784\u9020\u7279\u5f81\nprint('AUC:' , roc_auc_score(y_pred,y_test))\nprint('F1:', f1_score(y_pred, y_test))","32486a77":"# sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n# \u6df7\u6dc6\u77e9\u9635\nfrom sklearn.metrics import confusion_matrix\nC2 = confusion_matrix(y_test, y_pred)\nsns.heatmap(C2,annot=True,fmt='d')","a398c7a4":"import scikitplot as skplt\nvali_proba_df = pd.DataFrame(lr.predict_proba(X_test))\nskplt.metrics.plot_roc(y_test, vali_proba_df,\n                      plot_micro=False,figsize=(6,6),\n                      plot_macro=False)","91ee8c12":"A = 650\nB = 72.13\n\nfeatures\nboundary\n# \u751f\u6210\u8bc4\u5206\u5361\n\ndef generate_scorecard(model_coef,  features, B):\n    global box\n    coef = model_coef[0]\n    # print(coef)\n    \n    cols = ['Variable', 'Binning', 'Score']\n    for i in range(len(features)):\n        f = features[i]\n        lst = []\n        # \u7b5b\u9009\u8be5f\u7684 WOE\u89c4\u5219\n        for index, row in box[f].iterrows():\n            lst.append(int(round(-B*coef[i]*row['woe'])))\n        box[f]['score'] = lst\n        \n# \u8bc4\u5206\u5361\u8ba1\u7b97 score\ngenerate_scorecard(lr.coef_,  features, B)\nfor index in box:\n    display(box[index])","0fdb9d02":"#  \u8fd9\u91cc\u8bb0\u5f55\u4e86kai'ke'ba\u4ee5\u4e00\u79cd\u8ba1\u7b97\u65b9\u6cd5\ndef str_to_int(x):\n    if x=='-inf':\n        return -999999\n    if x=='inf':\n        return 999999\n    return float(x)\n\n# \u5c06value\u6620\u5c04\u5230bin\ndef map_value_to_bin(feature_value, feature_to_bin):\n    for index, row in feature_to_bin.iterrows():\n        bins =  str(row.name)\n        binnings = bins[1:-1].split(',')\n        in_range = True\n        if feature_value <= str_to_int(binnings[0]):\n            in_range = False\n        if feature_value > str_to_int(binnings[1]):\n            in_range = False\n        if in_range:\n            return row.name\n    return None\n\ndef map_to_score(df, score_card):\n    # score_card = box_new\n    # \u5f97\u5230\u8bc4\u5206\u5361\u89c4\u5219\u4e2d\u7684\u5b57\u6bb5\n    score_columns = list(score_card.keys())\n    score_columns.remove('SeriousDlqin2yrs')\n    # \u7d2f\u52a0 col \u7684 score\n    for col in score_columns:\n        # \u5f97\u5230\u5173\u4e8ecol\u7684\u89c4\u5219\n        feature_to_bin = score_card[col]\n        # df\u6837\u672c\u4e2d\u7684col\n        feature_value = df[col]\n        #\u3000\u5c06\uff43\uff4f\uff4c\u6570\u503c\u3000\u6620\u5c04\u5230\u3000\uff22\uff49\uff4e\uff4e\uff49\uff4e\uff47\n        selected_bin = map_value_to_bin(feature_value, feature_to_bin)\n        # \u7d2f\u52a0score\n        selected_score = feature_to_bin[selected_bin]['score'].iloc[0]\n        # \u7d2f\u52a0\u5230\u6574\u4f53\u7684score\n        score += selected_score\n    return score\n\n\n# \u6309\u7167\u8bc4\u5206\u5361\u89c4\u5219 score card \u8ba1\u7b97df\u4e2d\u7684\u5206\u6570\ndef cal_score_with_card(df, score_card, A):\n    df['score'] = df.apply(map_to_score, args=(score_card, ),axis=1)\n    df['score'] = df['score'] + A\n    return df","fdc2ca4d":"# \u6309\u7167\u8bc4\u5206\u5361\u89c4\u5219 score card \u8ba1\u7b97df\u4e2d\u7684\u5206\u6570\ndef cal_score_with_card(df, score_card, A):\n    df_score = df.copy()\n    \n    # score_card = box_new\n    # \u5f97\u5230\u8bc4\u5206\u5361\u89c4\u5219\u4e2d\u7684\u5b57\u6bb5\n    columns = list(score_card.keys())\n    \n    score_columns = []\n    # \u7d2f\u52a0 col \u7684 score\n    for col in columns:\n        df_score['score_{}'.format(col)] = df_score[col].map(score_card[col]['score'])\n        score_columns.append('score_{}'.format(col))\n        \n    df_score['score'] = df_score[score_columns].sum(axis=1)\n    df_score['score'] = df_score['score'] + A\n    return df_score","77fb1659":"# \u968f\u673a\u9009\u62e9Good\u76845\u4e2a\ngood_sample = df_train[df_train['SeriousDlqin2yrs']==0].sample(5,random_state=2022)\ngood_sample = good_sample[features]\ngood_sample\n\n# \u8ba1\u7b97\u5206\u6570\ngood_sample_score = cal_score_with_card(good_sample, box, 650)\n\ngood_sample_score","4665f709":"# \u968f\u673a\u9009\u62e9Good\u76845\u4e2a\nbad_sample = df_train[df_train['SeriousDlqin2yrs']==1].sample(5,random_state=2022)\nbad_sample = good_sample[features]\nbad_sample\n\n# \u8ba1\u7b97\u5206\u6570\nbad_sample_score = cal_score_with_card(good_sample, box, 650)\n\nbad_sample_score","e655d9c0":"# \u8ba1\u7b97\u5206\u6570\ncs_training_score = cal_score_with_card(df_train, box, 650)\ncs_training_score.to_csv('cs_training_score.csv', header=True)\ncs_training_score","5cb2da3a":"cs_test = pd.read_csv(input+'cs-test.csv')\ncs_test = cs_test.iloc[:, 1:]\n\n# \u8ba1\u7b97\u5206\u6570\ncs_test_score = cal_score_with_card(cs_test, box, 650)\ncs_test_score.to_csv('cs_test_score.csv', header=True)\ncs_test_score","12f217a7":"sampleEntry = pd.read_csv(input+'sampleEntry.csv', index_col='Id')\n\nsampleEntry","f76af4b4":"cs_test = pd.read_csv(input+'cs-test.csv', index_col=0)\ncs_test = cs_test.drop(['SeriousDlqin2yrs'], axis=1)\n\ndisplay(cs_test.isna().sum()\/cs_test.shape[0])\n\n#\u4f7f\u7528\u5747\u503c\u586b\u8865\u201cNumberOfDependents\u201d\u7684\u7f3a\u5931\u503c\ncs_test[\"NumberOfDependents\"].fillna(int(cs_test[\"NumberOfDependents\"].mean()),inplace=True)\n# \u4f7f\u7528\u5747\u503c\u586b\u8865 \u201cMonthlyIncome\u201d \u7684\u7f3a\u5931\u503c\ncs_test['MonthlyIncome'].fillna(cs_test['MonthlyIncome'].mean(),inplace=True)\n\ndisplay(cs_test.isna().sum()\/cs_test.shape[0])\n    \n#\u5c06\u539f\u6570\u636e\u5206\u7bb1\u540e\uff0c\u6309\u7bb1\u7684\u7ed3\u679c\u628aWOE\u7ed3\u6784\u7528map\u51fd\u6570\u6620\u5c04\u5230\u6570\u636e\u4e2d\ncs_test_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    cs_test_woe[col] = pd.cut(cs_test[col], boundary[col], right=False).map(box[col]['woe'])\n\ndisplay(cs_test_woe.isnull().sum())","1f50c197":"cs_test_woe['MonthlyIncome'].fillna(cs_test_woe['MonthlyIncome'].value_counts().index[0], inplace=True)\ncs_test_woe['NumberOfOpenCreditLinesAndLoans'].fillna(cs_test_woe['NumberOfOpenCreditLinesAndLoans'].value_counts().index[0], inplace=True)\ncs_test_woe['NumberOfDependents'].fillna(cs_test_woe['NumberOfDependents'].value_counts().index[0], inplace=True)\ndisplay(cs_test_woe.isnull().sum())","b9885b5a":"\ny_pred2 = lr.predict_proba(cs_test_woe)\n\n\npredict = pd.DataFrame(index=cs_test.index)\npredict['Probability'] = y_pred2[:, 1]\npredict.index.name = 'Id'\npredict","71aa4c84":"predict.to_csv('predict.csv', header=True)","f84d1129":"\u4e00\u822c\u8ba4\u4e3a\uff0cIV\u503c\u5c0f\u4e8e0.03\u7684\u7279\u5f81\u51e0\u4e4e\u4e0d\u5e26\u6709\u6709\u6548\u4fe1\u606f\uff0c\u5bf9\u6a21\u578b\u6ca1\u6709\u8d21\u732e\uff0c\u53ef\u4ee5\u5220\u9664\uff0c\u8fd9\u7ec4\u7279\u5f81\u4e2d\u6700\u4f4e\u503c\u4e3a\u2019NumberOfDependents\u2019\u4e3a0.028\uff0c\n\u5dee\u522b\u4e0d\u5927\uff0c\u6682\u4e14\u4fdd\u7559\u67e5\u770b\u6548\u679c","ce1b7ec7":"# 4 \u5236\u4f5c\u8bc4\u5206\u5361\n\n\u6c42\u51faA\u3001B\u548cbase_score\n\n\u5c06\u6240\u6709\u7279\u5f81\u7684\u8bc4\u5206\u5361\u5185\u5bb9\u5168\u90e8\u4e00\u6b21\u6027\u5199\u5f80\u4e00\u4e2a\u672c\u5730\u6587\u4ef6ScoreData.csv\uff1a","8adb466e":"AUC > 0.9 \uff0c\u8bf4\u660e\u6548\u679c\u8fd8\u4e0d\u9519","805879af":"\u7ed8\u5236ROC\u66f2\u7ebf\uff0cROC=0.94\uff0c\u66f2\u7ebf\u8d8a\u5f80\u5de6\u4e0a\u51f8\uff0cTrue Positive \u5c31\u8d8a\u9ad8\uff0c\u5bf9\u5e94\u7684False Positive\u8d8a\u4f4e\u3002","c35ec397":"RevolvingUtilizationOfUnsecuredLines: \u662f\u7406\u60f3\u4e2d\u7684\u5206\u7bb1\uff0c\u4fdd\u6301\u4e86woe\u7684\u5355\u8c03\u6027\n\nage: \u4fdd\u6301\u4e86woe\u7684\u5355\u8c03\u6027\n\nNumberOfTime30-59DaysPastDueNotWorse\uff1a \u5206\u7bb1\u8fd8\u53ef\u4ee5\n\nDebtRatio\u3001MonthlyIncome\uff1a\u6682\u4e14\u5f52\u4e3aU\u578b\u53d8\u91cf\uff0c\u4e0d\u505a\u5904\u7406\n\nNumberOfOpenCreditLinesAndLoans\uff1a \u4e0d\u4f5c\u5904\u7406\n\nNumberOfTimes90DaysLate: \u5206\u7bb1\u8fd8\u53ef\u4ee5\n\nNumberRealEstateLoansOrLines\uff1a \u4e0d\u4f5c\u5904\u7406\n\nNumberOfTime60-89DaysPastDueNotWorse\uff1a \u5206\u7bb1\u8fd8\u53ef\u4ee5\n\nNumberOfDependents\uff1a\u5408\u5e76inf\u51fa\u73b0\u7684box"}}