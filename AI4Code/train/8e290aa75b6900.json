{"cell_type":{"aea8a545":"code","7fcb1d4d":"code","ff8fad21":"code","a9dd29c3":"code","95248cc7":"code","c3cb9777":"code","8c8b39c0":"code","0b2ba937":"code","36cf3fda":"code","76369f8d":"code","6896a418":"code","b8967ac9":"code","ef3e7b9a":"code","2303c836":"code","cef62fa0":"code","20dcffab":"code","fd67bdce":"code","e482ecda":"code","2da7e1e6":"code","ff9bafc8":"code","21035ed1":"code","97450f4d":"code","1f23c988":"code","85713c4e":"code","446e6bf6":"code","6f258846":"code","38db4f3d":"code","cd639ac8":"code","d4ded153":"code","833e4865":"code","27fe9025":"code","697cfeca":"code","b7a9277f":"code","429e69f7":"code","aa79c601":"code","655a2f10":"code","84a117a5":"code","332fc4f0":"code","ca748cfe":"code","7d5bdd0f":"code","60459827":"code","8ed5d806":"code","ad4f44e9":"code","f38bdb5a":"code","3a93bab8":"code","83660cfb":"code","5451a376":"code","119dbcd0":"code","cff23805":"code","90cc7651":"code","4a317812":"code","bfedbee9":"code","7b1b4e60":"code","6136acf2":"code","2fcc789a":"code","e786fbe1":"code","48677ec9":"code","548e4907":"code","86c61f57":"code","f1ec758b":"code","4a26eb3f":"code","89cfdb3b":"code","f11a4daa":"code","22205b3a":"code","253838d9":"code","fec2c432":"code","3e268985":"code","b23cff8f":"markdown","6991bf7f":"markdown","7944f8b1":"markdown","b2a2d749":"markdown","004d4404":"markdown","aeeee4bd":"markdown","35de8e4a":"markdown","b3b9520b":"markdown","48e0204d":"markdown","472472af":"markdown","3067df02":"markdown","7c8b7496":"markdown","54194b1d":"markdown","4af0b57d":"markdown","1ff98299":"markdown","e7d30ad5":"markdown","c5120c6f":"markdown","9f835722":"markdown","66f42237":"markdown","6e907dd6":"markdown","2f2dce06":"markdown","77c12510":"markdown","95a233db":"markdown","b1eb2b87":"markdown","92c3bf5f":"markdown","4e324ad3":"markdown","056ec495":"markdown","2369d0af":"markdown","72e98d57":"markdown","492ebc4b":"markdown","e19e3a57":"markdown","eece4098":"markdown","00d920b0":"markdown"},"source":{"aea8a545":"print('Hello My name is Bashir Abubakar and welcome to this exploration!')","7fcb1d4d":"# import necessary libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install chart_studio\n!pip install cufflinks\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff \nfrom chart_studio.plotly import plot, iplot\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.figure_factory as ff\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\nimport plotly.graph_objs as go\nimport chart_studio.plotly as py\nimport plotly\nimport chart_studio\nchart_studio.tools.set_credentials_file(username='bashman18', api_key='\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022')\ninit_notebook_mode(connected=True)\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\nimport itertools\nimport time\n\n# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint('All modules imported')","ff8fad21":"# import class with two column labels \"Normal\" and \"Abnormal\"\ndf = pd.read_csv(\"..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv\")","a9dd29c3":"# read in the data and check the first 5 rows\ndf.head()","95248cc7":"df['class']=df['class'].map({'Normal':0,'Abnormal':1})","c3cb9777":"# assign our categorical variables to a dataframe\nA = df[(df['class'] != 0)]\nN = df[(df['class'] == 0)]","8c8b39c0":"# general summary of the dataframe\ndf.info()","0b2ba937":"# display the number of rows and columns in a tuple\ndf.shape","36cf3fda":"df.head()","76369f8d":"# check number of missing values\nnull_feat = pd.DataFrame(len(df['pelvic_incidence']) - df.isnull().sum(), columns = ['Count'])\nnull_feat","6896a418":"df.describe()","b8967ac9":"# Display positive and negative correlation between columns\ndf.corr()","ef3e7b9a":"#correlation\ncorrelation = df.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)","2303c836":"tst = df.corr()['class'].copy()\ntst = tst.drop('class')\ntst.sort_values(inplace=True)\ntst.iplot(kind='bar',title='Feature Importances',xaxis_title=\"Features\",\n    yaxis_title=\"Correlation\")","cef62fa0":"def plot_ft1_ft2(ft1, ft2) :  \n    trace0 = go.Scatter(\n        x = A[ft1],\n        y = A[ft2],\n        name = 'malignant',\n        mode = 'markers', \n        marker = dict(color = '#FFD700',\n            line = dict(\n                width = 1)))\n\n    trace1 = go.Scatter(\n        x = N[ft1],\n        y = N[ft2],\n        name = 'benign',\n        mode = 'markers',\n        marker = dict(color = '#7EC0EE',\n            line = dict(\n                width = 1)))\n\n    layout = dict(title = ft1 +\" \"+\"vs\"+\" \"+ ft2,\n                  yaxis = dict(title = ft2,zeroline = False),\n                  xaxis = dict(title = ft1, zeroline = False)\n                 )\n\n    plots = [trace0, trace1]\n\n    fig = dict(data = plots, layout=layout)\n    py.iplot(fig)","20dcffab":"plot_ft1_ft2('pelvic_incidence','pelvic_tilt numeric')\nplot_ft1_ft2('pelvic_incidence','lumbar_lordosis_angle')\nplot_ft1_ft2('pelvic_incidence','sacral_slope')\nplot_ft1_ft2('pelvic_incidence','pelvic_radius')\nplot_ft1_ft2('pelvic_incidence','degree_spondylolisthesis')\n\n","fd67bdce":"trace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   xgap = 2,\n                   ygap = 2,\n                   colorscale='Viridis',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","e482ecda":"#sorts all correlations with ascending sort.\ndf.corr().unstack().sort_values().drop_duplicates()","2da7e1e6":"df.columns","ff9bafc8":"# import figure factory\nimport plotly.figure_factory as ff\n\ndata_matrix = df.loc[:,['pelvic_incidence', 'pelvic_tilt numeric', 'lumbar_lordosis_angle',\n       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis']]\ndata_matrix[\"index\"] = np.arange(1,len(data_matrix)+1)\n# scatter matrix\nfig = ff.create_scatterplotmatrix(data_matrix, diag='box', index='index',colormap='Portland',\n                                  colormap_type='cat',\n                                  height=1000, width=1000)\nfig.update_layout(font=dict(family=\"Tahoma\",size=6),titlefont=dict(size=10))\niplot(fig)","21035ed1":"df_abnormal = df[df[\"class\"]==1]\npd.plotting.scatter_matrix(df_abnormal.loc[:, df_abnormal.columns != \"class\"],\n                                       c=\"red\",\n                                       figsize= [15,15],\n                                       diagonal=\"hist\",\n                                       alpha=0.5,\n                                       s = 200,\n                                       \n                          )\nplt.show()","97450f4d":"df_normal = df[df['class']==0]\npd.plotting.scatter_matrix(df_normal.loc[:, df_normal.columns != \"class\"],\n                                       c=\"blue\",\n                                       figsize= [15,15],\n                                       diagonal=\"hist\",\n                                       alpha=0.5,\n                                       s = 200,\n                                       \n                                       edgecolor= \"black\")\nplt.show()","1f23c988":"# prepare data\ndata1 = len(df[\"class\"][df[\"class\"] == 1])\ndata2 = len(df[\"class\"][df[\"class\"] == 0])","85713c4e":"trace = go.Bar(x=df['class'].value_counts(), y = ['Abnormal', 'Normal'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=1.0)))\n\nlayout = dict(title =  'Count of diagnosis variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\ntrace = go.Pie(labels = ['Abnormal','Normal'], values = df['class'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['black', 'gold'], \n                           line=dict(color='#000000', width=1.5)))\n\nlayout = dict(title =  'Distribution of diagnosis variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","446e6bf6":"from plotly.subplots import make_subplots\n\nfig = make_subplots(rows=6,cols=1,subplot_titles = (\"Pelvic Incidence\",\"Lumbar Lordosis Angle\",\"Pelvic Tilt Numeric\",\"Sacral Slope\",\"Degree Spondylolisthesis\",\"Pelvic Raidus\"))\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df.pelvic_incidence,\nmode = \"lines\",\nname = \"Pelvic Incidence\",\nmarker = dict(color = 'rgba(16, 112, 2, 0.8)')),row = 1, col = 1)\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df[\"pelvic_tilt numeric\"],\nmode = \"lines\",\nname = \"Pelvic Tilt Numeric\",\nmarker = dict(color = 'rgba(80, 26, 80, 0.8)')),row = 2, col = 1)\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df.lumbar_lordosis_angle,\nmode = \"lines\",\nname = \"Lumbar Lordosis Angle\",\nmarker = dict(color = 'rgba(160, 112, 20, 0.8)')),row = 3, col = 1)\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df.sacral_slope,\nmode = \"lines\",\nname = \"Sacral Slope\",\nmarker = dict(color = 'rgba(12, 12, 140, 0.8)')),row = 4, col = 1)\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df.pelvic_radius,\nmode = \"lines\",\nname = \"Pelvic Radius\",\nmarker = dict(color = 'rgba(245, 128, 2, 0.8)')),row = 5, col = 1)\n\nfig.append_trace(go.Scatter(\nx = df.index,\ny = df.degree_spondylolisthesis,\nmode = \"lines\",\nname = \"Degree Spondylolisthesis\",\nmarker = dict(color = 'rgba(235, 144, 235, 0.8)')),row = 6, col = 1) #174\n\nfig.update_xaxes(title_text=\"Patient Number\", row=1, col=1)\nfig.update_xaxes(title_text=\"Patient Number\", row=2, col=1)\nfig.update_xaxes(title_text=\"Patient Number\", row=3, col=1)\nfig.update_xaxes(title_text=\"Patient Number\", row=4, col=1)\nfig.update_xaxes(title_text=\"Patient Number\", row=5, col=1)\nfig.update_xaxes(title_text=\"Patient Number\", row=6, col=1)\n\nfig.update_yaxes(title_text=\"Pelvic Incidence\", row=1, col=1)\nfig.update_yaxes(title_text=\"Lumbar Lordosis Angle\", row=2, col=1)\nfig.update_yaxes(title_text=\"Pelvic Tilt Numeric\", row=3, col=1)\nfig.update_yaxes(title_text=\"Sacral Slope\", row=4, col=1)\nfig.update_yaxes(title_text=\"Degree Spondylolisthesis\", row=5, col=1)\nfig.update_yaxes(title_text=\"Pelvic Radius\", row=6, col=1)\n\nfig.update_layout(height = 1800, width = 1000, title = \"Biomechanical Features of Patients\")\n\niplot(fig)","6f258846":"y = df[\"class\"].values\nx_data = df.drop([\"class\"], axis=1)  ","38db4f3d":"x = (x_data - np.min(x_data))\/(np.max(x_data)-np.min(x_data))","cd639ac8":"x.head()","d4ded153":"# check number of missing values\nx_null = pd.DataFrame(x.isnull().sum(), columns = ['Count'])\nx_null","833e4865":"print(x.shape)\nprint(y.shape)","27fe9025":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","697cfeca":"from sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression()\nlr_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nlr_train_accuracy = lr_model.score(x_train,y_train)\nprint(\"lr_train_accuracy = \",lr_model.score(x_train,y_train))\n#Print Test Accuracy\nlr_test_accuracy = lr_model.score(x_test,y_test)\nprint(\"lr_test_accuracy = \",lr_model.score(x_test,y_test))","b7a9277f":"data = [go.Bar(\n            x=[\"lr_train_accuracy\",\"lr_test_accuracy\"],\n            y=[lr_train_accuracy,lr_test_accuracy],\n            orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\nfig.update_layout(title='<i><b>Logistic Regression Classification Accuracy<\/b><\/i>')\niplot(data, filename='text-hover-bar')","429e69f7":"from sklearn.metrics import confusion_matrix\ny_pred = lr_model.predict(x_test)\ny_true = y_test\n\ncm_lr = confusion_matrix(y_true,y_pred)\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_lr, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>Confusion matrix<\/b><\/i>')\nfig.show()","aa79c601":"tp ,fp ,fn ,tn= cm_lr.ravel()\nprint(\"lr_RECALL = \",tp\/(tp+fn))\nprint(\"lr_PRECISION = \",(tp\/(tp+fp))) ","655a2f10":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nknn_train_accuracy = knn_model.score(x_train,y_train)\nprint(\"knn_train_accuracy = \",knn_model.score(x_train,y_train))\n#Print Test Accuracy\nknn_test_accuracy = knn_model.score(x_test,y_test)\nprint(\"knn_test_accuracy = \",knn_model.score(x_test,y_test))","84a117a5":"# Model complexity\nneighboors = np.arange(1,30)\ntrain_accuracy = []\ntest_accuracy = []\n\nfor i, k in enumerate(neighboors):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, y_train)\n    train_accuracy.append(knn.score(x_train, y_train))           \n    test_accuracy.append(knn.score(x_test, y_test))              \n\n\nimport plotly.graph_objs as go\n\n\ntrace1 = go.Scatter(\n                    x = neighboors,\n                    y = train_accuracy,\n                    mode = \"lines\",\n                    name = \"train_accuracy\",\n                    marker = dict(color = 'rgba(160, 112, 2, 0.8)'),\n                    text= \"train_accuracy\")\n\ntrace2 = go.Scatter(\n                    x = neighboors,\n                    y = test_accuracy,\n                    mode = \"lines+markers\",\n                    name = \"test_accuracy\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                    text= \"test_accuracy\")\ndata = [trace1, trace2]\nlayout = dict(title = 'K Value vs Accuracy',\n              xaxis= dict(title= 'Number of Neighboors',ticklen= 10,zeroline= True)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)\n\nknn_train_accuracy_two = np.max(train_accuracy)\nknn_test_accuracy_two = np.max(test_accuracy)\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy), 1+test_accuracy.index(np.max(test_accuracy))))","332fc4f0":"data = [go.Bar(\n            x=[\"knn_train_accuracy\",\"knn_test_accuracy\"],\n            y=[knn_train_accuracy,knn_test_accuracy],\n     orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\n\niplot(data, filename='text-hover-bar')","ca748cfe":"y_pred = knn_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_knn = confusion_matrix(y_true,y_pred)\n\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_knn, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>KNN Classification Confusion matrix<\/b><\/i>')\nfig.show()","7d5bdd0f":"tp ,fp ,fn ,tn= cm_knn.ravel()\nprint(\"knn_RECALL = \",tp\/(tp+fn))\nprint(\"knn_PRECISION = \",(tp\/(tp+fp)))","60459827":"from sklearn.svm import SVC\n\nsvm_model = SVC(random_state=1)\nsvm_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nsvm_train_accuracy = svm_model.score(x_train,y_train)\nprint(\"svm_train_accuracy = \",svm_model.score(x_train,y_train))\n#Print Test Accuracy\nsvm_test_accuracy = svm_model.score(x_test,y_test)\nprint(\"svmr_test_accuracy = \",svm_model.score(x_test,y_test))","8ed5d806":"data = [go.Bar(\n            x=[\"svm_train_accuracy\",\"svm_test_accuracy\"],\n            y=[svm_train_accuracy,svm_test_accuracy],\n     orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\n\niplot(data, filename='text-hover-bar')","ad4f44e9":"y_pred = svm_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_svm = confusion_matrix(y_true,y_pred)\n\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_svm, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>Support Vector Confusion matrix<\/b><\/i>')\nfig.show()","f38bdb5a":"tp ,fp ,fn ,tn= cm_svm.ravel()\nprint(\"svm_RECALL = \",tp\/(tp+fn))\nprint(\"svm_PRECISION = \",(tp\/(tp+fp)))","3a93bab8":"from sklearn.naive_bayes import GaussianNB\n\nnb_model = GaussianNB()\nnb_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nnb_train_accuracy = nb_model.score(x_train,y_train)\nprint(\"nb_train_accuracy = \",nb_model.score(x_train,y_train))\n#Print Test Accuracy\nnb_test_accuracy = nb_model.score(x_test,y_test)\nprint(\"nb_test_accuracy = \",nb_model.score(x_test,y_test))","83660cfb":"data = [go.Bar(\n            x=[\"nb_train_accuracy\",\"nb_test_accuracy\"],\n            y=[nb_train_accuracy,nb_test_accuracy],\n     orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\n\niplot(data, filename='text-hover-bar')","5451a376":"y_pred = nb_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_nb, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>Naive Bayes Classification Confusion matrix<\/b><\/i>')\nfig.show()","119dbcd0":"tp ,fp ,fn ,tn= cm_nb.ravel()\nprint(\"nb_RECALL = \",tp\/(tp+fn))\nprint(\"nb_PRECISION = \",(tp\/(tp+fp)))","cff23805":"from sklearn.tree import DecisionTreeClassifier\n#if you remove random_state=1, you can see how accuracy is changing\n#Accuracy changing depends on splits\ndt_model = DecisionTreeClassifier(random_state=1)\ndt_model.fit(x_train,y_train)\n\n#Print Train Accuracy\ndt_train_accuracy = dt_model.score(x_train,y_train)\nprint(\"dt_train_accuracy = \",dt_model.score(x_train,y_train))\n#Print Test Accuracy\ndt_test_accuracy = dt_model.score(x_test,y_test)\nprint(\"dt_test_accuracy = \",dt_model.score(x_test,y_test))","90cc7651":"data = [go.Bar(\n            x=[\"dt_train_accuracy\",\"dt_test_accuracy\"],\n            y=[dt_train_accuracy,dt_test_accuracy],\n     orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\n\niplot(data, filename='text-hover-bar')","4a317812":"y_pred = dt_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_dt = confusion_matrix(y_true,y_pred)\n\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_dt, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>Decision Tree Classification Confusion matrix<\/b><\/i>')\nfig.show()","bfedbee9":"tp ,fp ,fn ,tn= cm_dt.ravel()\nprint(\"dt_RECALL = \",tp\/(tp+fn))\nprint(\"dt_PRECISION = \",(tp\/(tp+fp)))","7b1b4e60":"from sklearn.ensemble import RandomForestClassifier\n\n#n_estimators = 100 => Indicates how many trees we have\nrf_model = RandomForestClassifier(n_estimators=100, random_state=1)\nrf_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nrf_train_accuracy = rf_model.score(x_train,y_train)\nprint(\"rf_train_accuracy = \",rf_model.score(x_train,y_train))\n#Print Test Accuracy\nrf_test_accuracy = rf_model.score(x_test,y_test)\nprint(\"rf_test_accuracy = \",rf_model.score(x_test,y_test))","6136acf2":"data = [go.Bar(\n            x=[\"rf_train_accuracy\",\"rf_test_accuracy\"],\n            y=[rf_train_accuracy,rf_test_accuracy],\n     orientation = 'v', opacity = 0.8, marker=dict(\n        color=[ 'black', 'gold'],\n        line=dict(color='#000000',width=0.2),\n        )\n \n    )]\n\niplot(data, filename='text-hover-bar')","2fcc789a":"y_pred","e786fbe1":"y_pred = [\"Normal\" if x < 0.5 else \"Abnormal\" for x in y_pred]","48677ec9":"y_pred[1:6]","548e4907":"y_pred = rf_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_rf = confusion_matrix(y_true,y_pred)\n\nimport plotly.figure_factory as ff\nfig = ff.create_annotated_heatmap(cm_rf, colorscale='Viridis')\nfig.update_layout(title_text='<i><b>Random Forest Classification Confusion matrix<\/b><\/i>')\nfig.show()","86c61f57":"tp ,fp ,fn ,tn= cm_rf.ravel()\nprint(\"rf_RECALL = \",tp\/(tp+fn))\nprint(\"rf_PRECISION = \",(tp\/(tp+fp)))","f1ec758b":"from plotly.subplots import make_subplots\n\nfig = make_subplots(rows=6,cols=1,subplot_titles = (\"Logistic Regression Classification\",\"Decision Tree Classification\",\"K Nearest Neighbors(KNN) Classification\",\"Naive Bayes Classification\",\"Random Forest Classification\",\"Support Vector Machine(SVM) Classification\"))\nfig.append_trace(go.Heatmap(z=cm_lr),row = 1, col = 1)\nfig.append_trace(go.Heatmap(z=cm_dt,text=cm_lr,),row = 2, col = 1)\nfig.append_trace(go.Heatmap(z=cm_knn,text=cm_lr,),row =3, col = 1)\nfig.append_trace(go.Heatmap(z=cm_nb,text=cm_lr,),row = 4, col = 1)\nfig.append_trace(go.Heatmap(z=cm_rf,text=cm_lr,),row = 5, col = 1)\nfig.append_trace(go.Heatmap(z=cm_svm,text=cm_lr,),row = 6, col = 1)\nfig.update_layout(height=1500, width=800, title_text=\"Patients' Classes According to Biomechanical Features\")\nfig.update_traces(showscale=False)\niplot(fig)","4a26eb3f":"svm_test_accuracy","89cfdb3b":"knn_test_accuracy_two","f11a4daa":"lr_test_accuracy","22205b3a":"nb_test_accuracy","253838d9":"dt_test_accuracy","fec2c432":"rf_test_accuracy","3e268985":"lr_s = lr_test_accuracy.round(3)\nknn_s = knn_test_accuracy_two.round(4)\nsvm_s = svm_test_accuracy.round(3)\nnb_s = nb_test_accuracy.round(2)\ndt_s = dt_test_accuracy.round(3)\nrf_s = rf_test_accuracy.round(3)\n\nlist_scores = [lr_s,knn_s,svm_s,nb_s,dt_s,rf_s]\nlist_scores.sort()\nlist_names = []\n\nfor i in list_scores:\n    if i == lr_s:\n        list_names.append(\"Logistic Regression\")\n    elif i == knn_s:\n        list_names.append(\"KNN\")\n    elif i == svm_s:\n        list_names.append(\"SVM\")\n    elif i == nb_s:\n        list_names.append(\"NB\")\n    elif i == dt_s:\n        list_names.append(\"Decision Tree\")\n    elif i == rf_s:\n        list_names.append(\"Random Forest\")\n\ntrace1 = go.Bar(\n    x = list_names,\n    y = list_scores,\n    text = list_scores,\n    textposition = \"inside\",\n    marker=dict(color = list_scores,colorbar=dict(\n            title=\"Colorbar\"\n        ),colorscale=\"Viridis\",))\n\ndata = [trace1]\nlayout = go.Layout(title = \"Comparison of Models\")\n\nfig = go.Figure(data = data, layout = layout)\nfig.update_xaxes(title_text = \"Names\")\nfig.update_yaxes(title_text = \"Scores\")\nfig.show()","b23cff8f":"<br> Now the question is why we choose K = 3 or what value we need to choose K. The answer is in model complexity\n\n<br> **Model complexity:**\n* K has general name. It is called a hyperparameter. For now just know K is hyperparameter and we need to choose it that gives best performace. \n* Literature says if k is small, model is complex model can lead to overfit. It means that model memorizes the train sets and cannot predict test set with good accuracy.\n* If k is big, model that is less complex model can lead to underfit. \n* As you can see in the plot, when K is 1 it memorize train sets and does not give good accuracy on test set (overfit). Also if K is 24 and above, model leads to underfit. Again accuracy is not enough. However look at when K is 20 or 22(best performance), accuracy has highest value almost 82%. ","6991bf7f":"\n# Evaluation Classification Models","7944f8b1":"\n### Model Comparison","b2a2d749":"\n### Confusion Matrixes Comparison","004d4404":"\n### Decision Tree Classification","aeeee4bd":"#### Make Predictions","35de8e4a":"\n### Scatter Matrix-Abnormal Class","b3b9520b":"Let us compare the accuracy of all models applied in this notebook to determine the best of all.","48e0204d":"\n### Support Vector Machine(SVM) Classification","472472af":"\n### Random Forest Classification","3067df02":"### Import Data","7c8b7496":"# Data PreProcessing ","54194b1d":"# Let's Connect on LinkedIn!\nIf anybody would like to discuss any other projects or just have a chat about data science topics, I'll be more than happy to connect with you on **LinkedIn:**\nhttps:\/\/www.linkedin.com\/in\/bashir-abubakar-61935417b\/","4af0b57d":"As you can see:\n\n* length: 310 (range index)\n* Features are float\n* Target variables are object that is like string","1ff98299":"# Exploratory Data Analysis (EDA)","e7d30ad5":"* blue: *normal* and red: *abnormal*\n","c5120c6f":"As we can see from the correlated pair below pelvic_radius has no correlation with our features","9f835722":"<a id=\"14\"><\/a> <br>\n### Naive Bayes Classification","66f42237":"\n### Logistic Regression Classification","6e907dd6":"### Normalization Data","2f2dce06":"# Biomechanical features of orthopedic patients","77c12510":"### Lineplot - Patients' Bimechanical Feature Values\n\nThis plot is showing the biomechanical feature values of patients. ","95a233db":"\n# Machine Learning Classification Models","b1eb2b87":"## Context\n---\n**The data have been organized in two different but related classification tasks.**\n\n    column3Cweka.csv (file with three class labels)\n        The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). \n\n    column2Cweka.csv (file with two class labels)\n        For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients).\n\n## Content\n---\nField Descriptions:\n\nEach patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (each one is a column):\n\n    pelvic incidence\n    pelvic tilt\n    lumbar lordosis angle\n    sacral slope\n    pelvic radius\n    grade of spondylolisthesis\n\n**Acknowledgements**\n\nThe original dataset was downloaded from UCI ML repository:\n\nLichman, M. (2013). UCI Machine Learning Repository [http:\/\/archive.ics.uci.edu\/ml]. Irvine, CA: University of California, School of Information and Computer Science","92c3bf5f":"### Model Complexity","4e324ad3":"**This is the end of our exploration and\nthe best machine learning algorithm for our data is Random Forest Classification algorithm with 87%.**","056ec495":"<img src=\"https:\/\/content.linkedin.com\/content\/dam\/brand\/site\/img\/logo\/logo-tm.png\"\/>","2369d0af":"## K-Nearest Neighbors (KNN) Classification","72e98d57":"<a id=\"24\"><\/a> <br>\n### Scatter Matrix-Normal Class","492ebc4b":"#### Correlation Map","e19e3a57":"\n### Train-Test Split Data","eece4098":"### Scatter Plot Matrix","00d920b0":"* Normalization Formula = (x - min(x))\/(max(x)-min(x))"}}