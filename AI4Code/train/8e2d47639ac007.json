{"cell_type":{"9b107f6b":"code","1e317a58":"code","f38e8ad9":"code","d22a8f37":"code","dafe141e":"code","7ddca48f":"code","8f9a4fe7":"code","f744e8e6":"code","24e31da2":"code","282f755f":"markdown","8b062ea3":"markdown","0b46b42d":"markdown"},"source":{"9b107f6b":"!git clone https:\/\/github.com\/bayartsogt-ya\/mlub-muis-soril.git\n%cd \/kaggle\/working\/mlub-muis-soril","1e317a58":"import gc\nimport os\nimport json\nimport time\nimport types\nimport argparse\nimport shutil\nimport subprocess\nimport warnings\nimport collections\nfrom glob import glob\n\nfrom tqdm.auto import tqdm\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom huggingface_hub.hf_api import HfFolder, HfApi\nfrom huggingface_hub.repository import Repository\n\nfrom dataset import CustomDataset, truncate_text\nfrom models import MLUBModel\nfrom train_utils import compute_metrics, get_kfold\nfrom optimizers import create_optimizer_roberta_large\n\nwarnings.filterwarnings(\"ignore\")\n\nGIT_USER = \"bayartsogt\"\nGIT_EMAIL = \"bayartsogtyadamsuren@icloud.com\"","f38e8ad9":"# ----------------------------- DATA --------------------------------\nprint(\"loading data\")\nBASE_DIR = \"data\/preprocessed\"\ndf_submission = pd.read_csv(f\"{BASE_DIR}\/submission.csv\")\ndf_train = pd.read_csv(f\"{BASE_DIR}\/train.csv\")\ndf_test = pd.read_csv(f\"{BASE_DIR}\/test.csv\")\ndf_synset_meaning = pd.read_csv(f\"{BASE_DIR}\/synset_meaning.csv\")\ndf_synset_meaning[\"word_len\"] = df_synset_meaning.word.apply(len)\nprint(df_train.shape, df_test.shape, df_submission.shape, df_synset_meaning.shape)","d22a8f37":"output_dir = \"\/kaggle\/input\/mlub-bert-large-uncased-tr5do30ep25\"","dafe141e":"with open(f\"{output_dir}\/training_arguments.json\", \"r\") as reader:\n    training_args = json.load(reader)\nargs = types.SimpleNamespace(**training_args)\ndf_args = pd.DataFrame()\ndf_args[\"key\"] = list(training_args.keys())\ndf_args[\"value\"] = list(training_args.values())\ndf_args","7ddca48f":"# ----------------------------- PREPROCESS --------------------------------\ndict_synset_meaning = collections.defaultdict(dict)\nfor row in df_synset_meaning.itertuples():\n    dict_synset_meaning[row.word][row.synset_id] = row.meaning.lower()\nsynset_id2word = {row.synset_id:row.word for row in df_synset_meaning.itertuples()}\nunique_synset = set(df_synset_meaning.word.unique().tolist())\n\n# truncate text\ndf_train = truncate_text(df_train, effective_len=args.truncate_length)\ndf_test = truncate_text(df_test, effective_len=args.truncate_length)\n\nids = sorted(df_synset_meaning.synset_id.unique().tolist())\nindex2id, id2index = {i:id for i, id in enumerate(ids)}, {id:i for i, id in enumerate(ids)}\nnum_labels = len(index2id)\n\ndf_train[\"synset_index\"] = df_train.synset_id.map(id2index)\ndf_train = get_kfold(df_train, num_folds=args.num_folds, random_state=args.seed)","8f9a4fe7":"# ----------------------------- TOKENIZER --------------------------------\ntokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nprint(f\"TOKENIZERS_PARALLELISM = {os.environ['TOKENIZERS_PARALLELISM']}\")","f744e8e6":"from torch.utils.data import DataLoader\n\ndf_test[\"synset_index\"] = 0\ntest_dataset = CustomDataset(df_test, tokenizer, max_len=args.max_len)\ntest_loader = DataLoader(test_dataset, batch_size=args.batch_size)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"using\", device)\n\nmodel = MLUBModel(\n    args.model_name_or_path,\n    num_labels=num_labels,\n    inference=True\n)\nmodel.to(device)\nmodel.eval()\n\npredictions = []\noof = np.zeros((df_train.shape[0], num_labels))\nfor fold in range(args.num_folds):\n    print(\"current fold\", fold)\n    model.load_state_dict(torch.load( f\"{output_dir}\/model_{fold}.bin\"))\n    \n    # -------------- VALIDATION --------------\n    valid = df_train.query(\"fold==@fold\")\n    valid_dataset = CustomDataset(valid, tokenizer, max_len=args.max_len)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=args.batch_size)\n    \n    pred = np.zeros((0, num_labels))\n    for batch in tqdm(valid_dataloader, total=len(valid_dataloader)):\n        batch = {k:v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            output = model(**batch)\n            pred = np.concatenate([pred, output.logits.detach().cpu().numpy()])\n    print(\"fold\", fold, accuracy_score(valid.synset_index.values, pred.argmax(1)))\n\n    oof[valid.index] = pred\n    \n    # -------------- TESTING --------------\n    pred = np.zeros((0, num_labels))\n    for batch in tqdm(test_loader, total=len(test_loader)):\n        batch = {k:v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            output = model(**batch)\n            pred = np.concatenate([pred, output.logits.detach().cpu().numpy()])\n    print(pred.shape)\n    predictions.append(pred)\n\nprint(\"************\")\noof_accuracy = accuracy_score(df_train.synset_index.values, oof.argmax(1))\nprint(\"OOF Acc:\", oof_accuracy)","24e31da2":"df_submission[\"synset_index\"] = np.array(predictions).mean(0).argmax(-1)\ndf_submission.loc[:, \"synset_id\"] = df_submission.loc[:,\"synset_index\"].map(index2id)\ndf_submission.drop(\"synset_index\", axis=1).to_csv(\"submission.csv\", index=False)\ndf_submission.head(5)","282f755f":"## Inference","8b062ea3":"## Best Single Model - Public 97.016 - Private 0.97251\n\u042d\u043d\u044d\u0445\u04af\u04af notebook-\u0442 \u0437\u04e9\u0432\u0445\u04e9\u043d \u0441\u0443\u0440\u0433\u0430\u0441\u0430\u043d model-\u0438\u0439\u043d \u0442\u0435\u0441\u0442 \u0445\u0438\u0439\u0445 \u0437\u043e\u0440\u0438\u043b\u0433\u043e\u043e\u0440 \u0430\u0448\u0438\u0433\u043b\u0430\u0436 \u0431\u0430\u0439\u0433\u0430\u0430 \u0431\u0430 \u0441\u0443\u0440\u0433\u0430\u043b\u0442 \u0445\u044d\u0440\u0445\u044d\u043d \u0445\u0438\u0439\u0433\u0434\u0441\u044d\u043d \u0442\u0430\u0439\u043b\u0431\u0430\u0440\u044b\u0433 [\u044d\u043d\u044d \u043b\u0438\u043d\u043a\u044d\u044d\u0440](https:\/\/www.kaggle.com\/bayartsogtya\/mlub-muis-soril-1) \u043e\u0440\u0436 \u04af\u0437\u043d\u044d \u04af\u04af!","0b46b42d":"## Preprocess"}}