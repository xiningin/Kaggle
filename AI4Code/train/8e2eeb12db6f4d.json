{"cell_type":{"cb95139f":"code","443ebed2":"code","9347a2e8":"code","07c0d916":"code","5afbf15f":"code","1f8c11ce":"code","fe44a9a3":"code","6f61c596":"code","5d847e29":"markdown","1536cc34":"markdown","863f7e02":"markdown","c84b301d":"markdown"},"source":{"cb95139f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","443ebed2":"## \u8a13\u7df4\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ntrain = pd.read_csv(\"..\/input\/ykc-cup-1st\/train.csv\")\ntrain.head()","9347a2e8":"## \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ntest = pd.read_csv(\"..\/input\/ykc-cup-1st\/test.csv\")\ntest.head()","07c0d916":"## submission\u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u8fbc\u307f\nsample_submission = pd.read_csv(\"..\/input\/ykc-cup-1st\/sample_submission.csv\")\nsample_submission.head()","5afbf15f":"## label encode all categorical features\ncat = [\"store_id\", \"genre_name\", \"area_name\", \"day_of_week\"]\nfor c in cat:\n    le = LabelEncoder()\n    train[c] = le.fit_transform(train[c].fillna(\"na\"))\n    test[c] = le.transform(test[c].fillna(\"na\"))\ntrain.head()","1f8c11ce":"features = [\"store_id\", \"day_of_week\", \"genre_name\", \"area_name\", \"latitude\", \"longitude\"] ## \u4e88\u6e2c\u306b\u4f7f\u7528\u3059\u308b\u7279\u5fb4\u91cf\u306e\u540d\u524d\ntarget = \"log_visitors\" ## \u4e88\u6e2c\u5bfe\u8c61\nn_split = 5 ## cross validation\u306efold\u6570","fe44a9a3":"## cross validation\u3092\u884c\u3044\uff0c\u5404fold\u3067\u8a13\u7df4\u3057\u305f\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u306e\u5e73\u5747\u5024\u3092submit\u3059\u308b\npreds_test = []\nkfold = KFold(n_splits=n_split, shuffle = True, random_state=42)\nfor i_fold, (train_idx, valid_idx) in enumerate(kfold.split(train)):\n    print(f\"--------fold {i_fold}-------\")\n    \n    ## train data\n    x_tr = train.loc[train_idx, features]\n    y_tr = train.loc[train_idx, target]\n\n    ## valid data\n    x_va = train.loc[valid_idx, features]\n    y_va = train.loc[valid_idx, target]\n\n    ## train LGBM model\n    model = LGBMRegressor()\n    model.fit(x_tr, y_tr)\n    \n    ## evaluate on valid\n    pred_val = model.predict(x_va)\n    rmse = np.sqrt(np.mean((pred_val - y_va) ** 2))\n    corr = np.corrcoef(pred_val, y_va)[0,1]\n    print(\"rmse : \", rmse)\n    print(\"corr : \", corr)\n    \n    ## pred on test\n    pred_test = model.predict(test[features])\n    preds_test.append(pred_test)","6f61c596":"## 5fold\u3067\u8a13\u7df4\u3057\u305f\u305d\u308c\u305e\u308c\u306e\u4e88\u6e2c\u5024\u3092\u5143\u306b\uff0c\u305d\u308c\u3089\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3057\u3066\u6700\u7d42\u7684\u306a\u4e88\u6e2c\u5024\u3068\u3059\u308b\uff0e\nfinal_pred = np.mean(np.vstack(preds_test), axis = 0)\nsample_submission[\"log_visitors\"] = final_pred\nsample_submission.to_csv(\"submission.csv\", index = False)","5d847e29":"## Submission","1536cc34":"## load","863f7e02":"## Encode Categorical Features","c84b301d":"## Train, evaluate, and pred"}}