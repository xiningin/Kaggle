{"cell_type":{"6b4ffab5":"code","5dedc663":"code","bd79e171":"code","5ec8171f":"code","f9a01ab0":"code","346c2d21":"code","ce92f176":"code","12f449c7":"code","260d5635":"code","8210dba9":"code","2d3b0a4c":"code","9dc3eae7":"code","eae69fe4":"code","3a0b29ba":"code","16cfa099":"code","4bcd327f":"code","cba48592":"code","cc8c6852":"code","de40a94a":"code","688c6fa3":"code","878b6389":"code","9841acb6":"code","4400783c":"code","e7d88448":"code","3cc3f00a":"code","852efdae":"code","8111635e":"code","400668cf":"markdown","ec694097":"markdown","53598979":"markdown","b43c0ab8":"markdown","956e6679":"markdown","ddda0ce1":"markdown","6f83e6ec":"markdown","7948a598":"markdown","9fd0fd27":"markdown","b7e9f835":"markdown","e9b6a1c9":"markdown","a62bd36b":"markdown","412cd1df":"markdown","abddf7a1":"markdown"},"source":{"6b4ffab5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5dedc663":"filenames = os.listdir(\"..\/input\/train\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n        \n        \ndf = pd.DataFrame({'filename':filenames,\n                  'category':categories})\n\ndf.head()","bd79e171":"filenames = os.listdir(\"..\/input\/train\/train\")\nsample = random.choice(filenames)\nimage = load_img(\"..\/input\/train\/train\/\"+sample)\nplt.imshow(image)","5ec8171f":"df['category'].value_counts().plot.bar()","f9a01ab0":"train_df, validation_df = train_test_split(df,test_size = 0.20, random_state = 42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidation_df = validation_df.reset_index(drop=True)\n\ntotal_train = train_df.shape[0]\ntotal_validate = validation_df.shape[0]\nbatch_size=15","346c2d21":"from keras.models import Sequential,model_from_json\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization","ce92f176":"image_width = 50\nimage_height = 50\nimage_size = (image_width, image_height)\nimage_channel = 3 # RGB color","12f449c7":"classifier1 = Sequential()\nclassifier1.add(Conv2D(32,(3,3),input_shape = (image_width,image_height,image_channel),activation = 'relu'))\nclassifier1.add(BatchNormalization())\nclassifier1.add(MaxPooling2D(pool_size = (2,2)))\n                \nclassifier1.add(Conv2D(64,(3,3),activation = 'relu'))\nclassifier1.add(BatchNormalization())\nclassifier1.add(MaxPooling2D(pool_size = (2,2)))\n                \nclassifier1.add(Flatten())\nclassifier1.add(Dense(256,activation = 'relu'))\nclassifier1.add(Dense(units = 1, activation = 'sigmoid'))\nclassifier1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","260d5635":"classifier1.summary()","8210dba9":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=image_size,\n    class_mode='binary',\n    batch_size=batch_size\n)","2d3b0a4c":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validation_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=image_size,\n    class_mode='binary',\n    batch_size=batch_size\n)","9dc3eae7":"x , y  = train_generator.next()\nfor i in range(0,1):\n    random_image = x[i]\n    plt.imshow(random_image)\n    plt.show()","eae69fe4":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nearlystop = EarlyStopping(patience=10)","3a0b29ba":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","16cfa099":"history = classifier1.fit_generator(\n    train_generator, \n    epochs= 25,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","4bcd327f":"model_json = classifier1.to_json()\n!mkdir Saved_models\nwith open(\"Saved_models\/cnn_base_model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nclassifier1.save_weights(\"Saved_models\/cnn_base_model.h5\")\nprint(\"Saved model to disk\")","cba48592":"json_file = open('Saved_models\/cnn_base_model.json', 'r')\n\nloaded_classifier_json = json_file.read()\n\njson_file.close()\n\nloaded_classifier = model_from_json(loaded_classifier_json)\n\nloaded_classifier.load_weights(\"Saved_models\/cnn_base_model.h5\")\nprint(\"Loaded model from disk\")\n\nloaded_classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","cc8c6852":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 25, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 25, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()\n\n","de40a94a":"test_image = load_img('..\/input\/test1\/test1\/1.jpg', target_size = (50, 50))\nplt.imshow(test_image)\nplt.show()","688c6fa3":"test_image = img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = loaded_classifier.predict(test_image)","878b6389":"if result[0][0] == 1:\n    prediction = 'This is a dog'\nelse:\n    prediction = 'This is a cat'\n\nprint (prediction)","9841acb6":"test_filenames = os.listdir(\"..\/input\/test1\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]\n","4400783c":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/input\/test1\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=image_size,\n    batch_size=batch_size,\n    shuffle=False\n)","e7d88448":"predict = loaded_classifier.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","3cc3f00a":"threshold = 0.5\ntest_df['probability'] = predict\ntest_df['category'] = np.where(test_df['probability'] > threshold, 1,0)","852efdae":"test_df['category'].value_counts().plot.bar()","8111635e":"sample_test = test_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    probability = row['probability']\n    img = load_img(\"..\/input\/test1\/test1\/\"+filename, target_size=image_size)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' '(' + \"{}\".format(round(probability, 2)) + ')')\nplt.tight_layout()\nplt.show()\n","400668cf":"# Prepare Traning Data","ec694097":"# Prediction","53598979":"# Save Model","b43c0ab8":"\nAs predicted of binary classification result return probability that image likely to be a dog. So we will have threshold 0.5 which mean if predicted value more than 50% it is a dog and under 50% will be a cat.\n","956e6679":"## Explore the dataset\n* Print a preprocessed image from the dataset","ddda0ce1":"# Prepare Testing Data","6f83e6ec":"## Fitting the CNN to the images\n* Improve the dataset using the ImageDataGenerator method which generate batches of tensor image data with real-time data augmentation. \n    * rescale: rescaling factor. If None or 0, no rescaling is applied, otherwise the data is multiplied by the value provided.\n    * shear_range: Shear Intensity\n    * zoom_range: Range for random zoom.\n    * horizontal_flip: Randomly flip inputs horizontally if true.\n* Define the training and test datasets using the flow_from_directory which takes the path to a directory, and generates batches of augmented\/normalized data.\n    * directory: path to the target directory. It should contain one subdirectory per class.\n    * target_size: The dimensions to which all images found will be resized.\n    * class_mode: one of \"categorical\", \"binary\", \"sparse\", \"input\" or None. Determines the type of label arrays that are returned\n    * batch_size: size of the batches of data","7948a598":"## Define an earlystopping callback\n* Import EarlyStopping - method to stop training when a monitored quantity has stopped improving.\n* Define a callback.Set monitor as val_acc, patience as 5 and mode as max so that if val_acc does not improve over 5 epochs, terminate the training process.","9fd0fd27":"## Evaluate the model\n* Load model from disk.\n* Preprocess and feed a random input image to the model for prediction.\n* Test the accuracy and loss using the evaluate_generator method.","b7e9f835":"# Create Testing Data Generator","e9b6a1c9":"## Validation Image Generator","a62bd36b":"# Virtualize Training and loss","412cd1df":"## Fit the model\n* Invoke the fit_generator to fits the model on data generated batch-by-batch by a Python generator.\n    * steps_per_epoch\u2019 holds the number of training images, i.e 8000\n    * A single epoch is a single step in training a neural network,set it at 25.\n    * callbacks: List of callbacks to apply during training.\n    * validation_data: test data\n    * validation_steps: Total number of steps (batches of samples) to yield from  validation_data generator before stopping at the end of every epoch. It should typically be equal to the number of samples of your validation dataset divided by the batch size.","abddf7a1":"## Build the classifier model\n* Build a CNN.CNN has mostly four fucntions:\n    * Convolution: Add the first layer which is a convolutional layer. Set the number of filters as 32, the shape of each filter as 3x3 and the input shape and the type of image as 50,50,3 i.e. the input is of a 50x50 RGB image and the activation function as relu.\n    * Pooling: Add a pooling layer to reduce the total number of nodes for the upcoming layers. It takes a 2x2 matrix thus giving minimum pixel loss and a precise region where the features are located.\n    * Flatten : Flattens the pooled images.\n    * Dense : add a fully connected layer to feed the images to the output layer. Set the number of nodes as 256, as its a common practice to use a power of 2 and a rectifier function asthe activation function, relu.\n\n* Define the output layer. Set number of units to 1 as this is a binary classifier and sigmoid as the activation function\n* Compile the model. Set adam as the optimizer and binary_crossentropy as the loss fucntion, as this is a binary classifier."}}