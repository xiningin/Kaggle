{"cell_type":{"77fd3ed2":"code","5a5ad348":"code","a6d7fe20":"code","7d03de5f":"code","773fea51":"code","9563e2a4":"code","452abb99":"code","060cc10b":"code","db9697a3":"code","dd86aef0":"code","ad390b26":"code","8dc20b6c":"code","94049e19":"code","bf70b4a3":"code","252b51d3":"code","694efedb":"code","d64eea5f":"code","abee5e97":"code","a5feffcf":"code","ae47eec9":"code","65fefa08":"code","bb66da94":"code","d8e0c0f8":"code","f481238c":"code","277526cf":"code","08a8bb6c":"code","ece280cd":"code","c7abd8fe":"code","32889e67":"code","ec39d8ff":"code","522de6e0":"code","953c23f6":"code","beba983a":"code","a51cf7f1":"code","06351319":"code","ae40313c":"code","4a7a4871":"code","11a953a7":"code","99850e2a":"code","2c9719f5":"code","9924ab92":"code","9d640dc0":"code","710d99da":"code","7a1a7a7b":"code","75259a58":"code","5b7fda24":"code","053fa909":"code","5d089701":"code","48d72e03":"code","8e9f7312":"code","670f9fe4":"code","f3e3b2a1":"code","82975cb3":"code","ecee958b":"code","0c0362e7":"code","dfef2128":"code","6c817822":"code","eb8de0cc":"code","b6190599":"code","8a686b6d":"code","a23a579b":"code","078ab02f":"code","9f40baa5":"code","1c215997":"code","470626b0":"code","001cf14a":"code","99168a4a":"code","01e1d8d7":"code","d0727679":"code","05d80b4d":"code","7fe2006d":"code","a410a14a":"code","3ba2bbe9":"code","71b2c8d3":"code","6288a5f8":"code","c92281ea":"code","64ae3ca6":"code","f4cc3cca":"code","02acb76d":"code","2d443c64":"code","b4355356":"code","d12da80a":"code","9d5fa209":"code","1016b3bb":"code","406c2693":"code","c9e59688":"code","5c65e011":"code","f6cf4842":"code","fddfd7d1":"code","4a0bd68b":"markdown","0e128af7":"markdown","cf85c6f2":"markdown","67aa6b0f":"markdown","020c970b":"markdown","862f24bc":"markdown","3c6b835c":"markdown","f62e556b":"markdown","0cfc8dc5":"markdown"},"source":{"77fd3ed2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport warnings #What to do with warnings\nwarnings.filterwarnings(\"ignore\") #Ignore the warnings\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a5ad348":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10,10) #Make the plots bigger by default\nplt.rcParams[\"lines.linewidth\"] = 2 #Setting the default line width\nplt.style.use(\"ggplot\")\n\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose #Describes the time data\nfrom statsmodels.tsa.stattools import adfuller #Check if data is stationary\nfrom statsmodels.graphics.tsaplots import plot_acf #Compute lag for ARIMA\nfrom statsmodels.graphics.tsaplots import plot_pacf #Compute partial lag for ARIMA\nfrom statsmodels.tsa.arima_model import ARIMA #Predictions and Forecasting\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom datetime import datetime\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error","a6d7fe20":"df = pd.read_csv(\"..\/input\/amazon-stock-price-1997-to-2020\/Amazon.csv\") \ndf.head(10) ","7d03de5f":"df.isnull().sum()","773fea51":"close_df=df[[\"Date\", \"Close\"]].copy()","9563e2a4":"close_df[\"Date\"] = pd.to_datetime(close_df[\"Date\"])\nclose_df.set_index(\"Date\", inplace = True) ","452abb99":"close_df = close_df.asfreq(\"d\")","060cc10b":"close_df.isnull().sum()","db9697a3":"close_df.head()","dd86aef0":"close_df = close_df.fillna(method  = \"bfill\")","ad390b26":"close_df.isnull().sum()","8dc20b6c":"close_df.shape","94049e19":"close_df.info()\n","bf70b4a3":"close_df.describe()\n","252b51d3":"close_df['Close'].plot(figsize=(24,8))\nplt.ylabel(\"Close price\")\nplt.grid(True)\n","694efedb":"decomp = seasonal_decompose(close_df, model = \"multiplicative\") #Decompose the data\nx = decomp.plot()","d64eea5f":"adf = adfuller(close_df[\"Close\"])\nadf","abee5e97":"closeLog = np.log(close_df) \ncloseStationary = closeLog -closeLog.shift() \ncloseStationary = closeStationary.dropna() \ncloseStationary.plot(title = \"Stationary Amazon Stocks\")","a5feffcf":"adf = adfuller(closeStationary[\"Close\"])\nadf","ae47eec9":"decomp = seasonal_decompose(closeStationary)\nx = decomp.plot()","65fefa08":"fig,axes = plt.subplots(2,2) \n\na = axes[0,0].plot(close_df[\"Close\"]) \na = axes[0,0].set_title(\"Original Data\") \nb = plot_acf(close_df[\"Close\"],ax=axes[0,1]) \n\nx = axes[1,0].plot(closeStationary[\"Close\"])\nx = axes[1,0].set_title(\"Stationary Data\") \ny = plot_acf(closeStationary[\"Close\"],ax=axes[1,1]) ","bb66da94":"fig,axes = plt.subplots(1,2) \n\na = axes[0].plot(close_df[\"Close\"]) \na = axes[0].set_title(\"Stationary\") \nb = plot_pacf(close_df[\"Close\"], ax = axes[1], method = \"ols\") ","d8e0c0f8":"fig,axes = plt.subplots(1,2) \n\na = axes[0].plot(close_df[\"Close\"])\na = axes[0].set_title(\"Stationary\") \nb = plot_acf(close_df[\"Close\"], ax = axes[1]) ","f481238c":"model = ARIMA(close_df, order = (6, 1, 6)) \nfitModel = model.fit(disp = 1)","277526cf":"plt.rcParams.update({\"figure.figsize\" : (12,6), \"lines.linewidth\" : 0.05, \"figure.dpi\" : 100}) \n\nx = fitModel.plot_predict(dynamic = False) \nx = plt.title(\"Forecast Fitting\")\nplt.show() ","08a8bb6c":"plt.rcParams.update({\"figure.figsize\" : (12,5), \"lines.linewidth\": 2}) \nlength = int((len(close_df)*9)\/10) \nprint(length)","ece280cd":"train = close_df[:length] \ntest = close_df[length:] \nmodelValid = ARIMA(train,order=(5,1,5)) \nfitModelValid = modelValid.fit(disp= -1) ","c7abd8fe":"fc,se,conf = fitModelValid.forecast(len(close_df) - length) \nforecast = pd.Series(fc, index = test.index)","32889e67":"\nplt.plot(train,label = \"Training Data\") \nplt.plot(test,label = \"Actual Continuation\")\nplt.plot(forecast,label = \"Forecasted Continuation\", color = \"g\")\n\nplt.title(\"ARIMA Forecast\")\nplt.legend(loc = \"upper left\") \nplt.xlabel(\"Year\") \nplt.ylabel(\"close Price\")","ec39d8ff":"modelPred = ARIMA(close_df,order=(5,1,5)) \nfitModelPred = modelPred.fit(disp= -1) ","522de6e0":"fitModelPred.plot_predict(1,len(close_df) + 1000) \nx = fitModelPred.forecast(1000) \nx = plt.title(\"Amazon Stock Forecast\") \nx = plt.xlabel(\"Year\") \nx = plt.ylabel(\"close Price\") ","953c23f6":"df","beba983a":"df[\"Date\"]=pd.to_datetime(df.Date,dayfirst=True)\ndf.set_index(\"Date\",inplace=True)\ndf","a51cf7f1":"df=df.asfreq(\"d\")\ndf = df.fillna(method  = \"bfill\")","06351319":"df['Open'].plot(figsize=(12,8))\nplt.ylabel(\"open price\")","ae40313c":"df['Volume'].plot(figsize=(12,8))\nplt.ylabel(\"Volume price\")","4a7a4871":"df['Total Pos'] = df.sum(axis=1)\n","11a953a7":"df['Total Pos'].plot(figsize=(10,8))\nplt.title('Total Portfolio Value')","99850e2a":"df['Daily Return'] = df['Total Pos'].pct_change(1)\n","2c9719f5":"df['Daily Return'].mean()\n","9924ab92":"df['Daily Return'].plot(kind='kde')\n","9d640dc0":"SR = df['Daily Return'].mean()\/df['Daily Return'].std()\n","710d99da":"all_plot = df\/df.iloc[0]\nall_plot.plot(figsize=(24,16))","7a1a7a7b":"df.hist(bins=100,figsize=(12,6));\nplt.tight_layout()","75259a58":"df.resample(rule='A').mean()","5b7fda24":"title = 'Yearly Mean Closing Price'\ndf['Open'].resample('A').mean().plot.bar(title=title,color=['#b41f7d']);","053fa909":"df['Open'].resample('M').max().plot.bar(figsize=(18,12),color='#1f77b4');\n","5d089701":"ax = df['Open'].plot(figsize=(24,6),title=title)\n","48d72e03":"df['6-month-SMA'] = df['Open'].rolling(window=6).mean()\ndf['12-month-SMA'] = df['Open'].rolling(window=12).mean()\ndf['2-month-SMA'] = df['Open'].rolling(window=2).mean()","8e9f7312":"df.head(13)\n","670f9fe4":"df[[\"Open\",\"6-month-SMA\",\"12-month-SMA\",\"2-month-SMA\"]].plot(figsize=(24,10));\n","f3e3b2a1":"df[[\"Open\",\"6-month-SMA\"]].plot(figsize=(18,10));\n","82975cb3":"df[['Open','6-month-SMA']].iloc[:100].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","ecee958b":"df['EWMA12'] = df['Open'].ewm(span=14,adjust=True).mean()\n","0c0362e7":"df[['Open','EWMA12']].plot(figsize=(24,12));","dfef2128":"df[['Open','EWMA12']].iloc[:50].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","6c817822":"df['EWMA12'] = df['Open'].ewm(span=14,adjust=True).mean()\n","eb8de0cc":"span = 12\nalpha = 2\/(span+1)","b6190599":"df['EWMA12'] = df['Open'].ewm(alpha=alpha,adjust=False).mean()","8a686b6d":"model=SimpleExpSmoothing(df[\"Open\"])","a23a579b":"model.fit(smoothing_level=alpha,optimized=False)\n","078ab02f":"fitted_model=model.fit(smoothing_level=alpha,optimized=False)\n","9f40baa5":"fitted_model.fittedvalues\n","1c215997":"fitted_model.fittedvalues.shift(-1)\n","470626b0":"df[\"SES12\"]=fitted_model.fittedvalues.shift(-1)\n","001cf14a":"df[['Close',\"SES12\"]].plot(figsize=(30,15)).autoscale(axis='x',tight=True);\n","99168a4a":"df['DESadd12'] = ExponentialSmoothing(df['Open'], trend='add').fit().fittedvalues.shift(-1)\ndf.head()","01e1d8d7":"df[['Open',  'SES12', 'DESadd12']].plot(figsize=(24,12))\n","d0727679":"df[['Open','EWMA12','DESadd12']].iloc[:12].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","05d80b4d":"df['DESmul12'] = ExponentialSmoothing(df['Open'], trend='mul').fit().fittedvalues.shift(-1)\ndf.head()","7fe2006d":"df[['Open','DESadd12','DESmul12']].iloc[:24].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","a410a14a":"df['TESadd12'] = ExponentialSmoothing(df['Open'],trend='add',seasonal='add',seasonal_periods=12).fit().fittedvalues\ndf.head()","3ba2bbe9":"df['TESmul12'] = ExponentialSmoothing(df['Open'],trend='mul',seasonal='mul',seasonal_periods=12).fit().fittedvalues\ndf.head()","71b2c8d3":"df[['Open','TESadd12','TESmul12']].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","6288a5f8":"df[['Open','TESadd12','TESmul12']].iloc[:24].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","c92281ea":"plt.figure(figsize=(16,6))\nplt.title('Open Price History')\nplt.plot(df['Open'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Open Price USD ($)', fontsize=18)\nplt.show()","64ae3ca6":"\ndata = df.filter(['Open'])\n\ndataset = data.values\n\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len","f4cc3cca":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","02acb76d":"train_data = scaled_data[0:int(training_data_len), :]\n\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n\nx_train, y_train = np.array(x_train), np.array(y_train)\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))","2d443c64":"model = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(32))\nmodel.add(Dense(16))\nmodel.add(Dense(1))","b4355356":"model.compile(optimizer='adam', loss='mean_squared_error')\n","d12da80a":"callbacks = [EarlyStopping(patience=4, monitor='val_loss', mode='min'), \n             ReduceLROnPlateau(patience=2, verbose=1)]  ","9d5fa209":"history =model.fit(x_train, y_train, \n                        epochs=20,\n                        batch_size=1,\n                        callbacks=callbacks,\n                        )","1016b3bb":"# Create the testing data set\n# Create a new array containing scaled values from index 1543 to 2002 \ntest_data = scaled_data[training_data_len - 60: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nrmse","406c2693":"mean_absolute_error(y_test, predictions)\n","c9e59688":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Open Price USD ($)', fontsize=18)\nplt.plot(train['Open'])\nplt.plot(valid[['Open', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","5c65e011":"predictions = model.predict(x_test)\n","f6cf4842":"valid[['Open','Predictions']].iloc[:100].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","fddfd7d1":"valid\n","4a0bd68b":"# ARIMA","0e128af7":"---","cf85c6f2":"Coded by Luna McBride\n\nThis is a project meant to mess with time series data. I will be using the opening rate as the key metric, as it is consistent. The below sources are ones I am using to get an idea of the functions and concepts behind the practice. \n\nSources: https:\/\/www.kaggle.com\/gayatry\/population-prediction-ar-vs-arima , https:\/\/www.youtube.com\/watch?v=e8Yw4alG16Q","67aa6b0f":"# Stats model","020c970b":"# Train the ARIMA\n","862f24bc":"# Time Series Project: Amazon Stock Data","3c6b835c":"# MA Lag","f62e556b":"# AR Lag","0cfc8dc5":"# LSTM MODEL "}}