{"cell_type":{"5b78dd8b":"code","860eca0b":"code","d90e1d1f":"code","b9d2fc77":"code","5acc4bb8":"code","e2a10bae":"code","8c62d1b5":"code","d65c951c":"code","01e4e727":"code","0cf4a7fc":"code","530ab83a":"code","6a8b88c8":"code","b63eebba":"code","1738fad1":"code","b4bb8594":"code","63d53e31":"code","95b1b59d":"markdown","d4461808":"markdown","f18eb74e":"markdown","28807c53":"markdown","7674b42d":"markdown","1d53fd0e":"markdown","9bfa7797":"markdown","1c2b457f":"markdown","ced718d3":"markdown","f22c1771":"markdown","6ba5adea":"markdown","c92b533d":"markdown","536d699d":"markdown"},"source":{"5b78dd8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","860eca0b":"data_dir = '\/kaggle\/input\/055241hk192p1'","d90e1d1f":"df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))","b9d2fc77":"def get_features(df, exclude_cols=['# Id', 'Category']):\n    exclude_cols = set(exclude_cols).intersection(set(df.columns))\n    return df.drop(exclude_cols, axis=1)","5acc4bb8":"train_feats_describe = get_features(df_train).describe()\ntrain_feats_describe","e2a10bae":"missing_values = df_train.isna().sum(axis=0)\n# missing cols\nmissing_values[missing_values > 0]","8c62d1b5":"label_count = df_train['Category'].value_counts()","d65c951c":"fig, ax = plt.subplots(figsize=(10, 10))\n\n_ = ax.pie(label_count.values, labels=['Category {:02d}'.format(lbl) for lbl in list(label_count.index)], autopct='%1.1f%%', shadow=True, startangle=90, counterclock=False) ","01e4e727":"train_feats_describe.loc['min', :].describe()","0cf4a7fc":"train_feats_describe.loc['max', :].describe()","530ab83a":"sns.distplot(train_feats_describe.loc['max', :])","6a8b88c8":"train_feats_describe.loc['mean', :].describe()","b63eebba":"sns.distplot(train_feats_describe.loc['mean', :])","1738fad1":"from sklearn.decomposition import PCA","b4bb8594":"pca_train = PCA(n_components=2).fit_transform(get_features(df_train))\npca_train = pd.DataFrame({\n    'x': pca_train[:, 0],\n    'y': pca_train[:, 1],\n    'label': df_train['Category']\n})","63d53e31":"fig, ax = plt.subplots(figsize=(10, 10))\n_ = sns.scatterplot(x='x', y='y', data=pca_train, hue='label', ax=ax, legend='full')","95b1b59d":"we can clearly see that there are some clusters here","d4461808":"so basically the data seems to be balanced","f18eb74e":"# Conclusion\nSo the main insights we're getting are:\n-  The \"features\" are output of some neural net with ReLU for activation\n-  Data is not imbalanced\n-  Using PCA to compress to 2D show us that it's separable","28807c53":"So basically the activation being used was **ReLU**","7674b42d":"# Overview","1d53fd0e":"# Missing values","9bfa7797":"## Label","1c2b457f":"# EDA","ced718d3":"## scatter","f22c1771":"## min","6ba5adea":"## mean","c92b533d":"# max","536d699d":"So **no missing values**\n\nThis is indeed output of some network"}}