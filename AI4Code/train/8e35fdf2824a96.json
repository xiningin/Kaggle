{"cell_type":{"61a03d7a":"code","733cc390":"code","6882e683":"code","58d6c38d":"code","67708ee3":"code","775e7504":"code","ab0d2dee":"code","3149ec3e":"code","fa4ed43f":"code","39abcc3c":"code","423b4961":"code","bc643800":"code","a20cd39d":"markdown","665ae556":"markdown","223c502f":"markdown","30d9fbc7":"markdown","d89b8773":"markdown","52dca99b":"markdown","dec67764":"markdown","49cd5d24":"markdown","961a4112":"markdown","462f1028":"markdown","4d1656ff":"markdown","0ca26684":"markdown","dc23ec53":"markdown","f0936bd7":"markdown","96bc623d":"markdown","25dd108e":"markdown","ce312254":"markdown","ae3731c2":"markdown","6bc44084":"markdown","0ddb4c3b":"markdown","8b020f66":"markdown","a89803ea":"markdown"},"source":{"61a03d7a":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport xgboost\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\/\"))\nos.chdir(\"..\/input\/\")","733cc390":"df = pd.read_csv('Admission_Predict_Ver1.1.csv')\nprint(df.head())\ndf.drop('Serial No.', axis = 1, inplace = True)","6882e683":"print(f'Dataset contains {df.shape[0]} samples, {df.shape[1] - 1} independent features 1 target continuous variable.')","58d6c38d":"print(df.info())\n\nmissing_values = (df.isnull().sum() \/ len(df)) * 100\nprint(\"\\nFeatures with missing values: \\n\", missing_values[missing_values > 0])","67708ee3":"df.describe()","775e7504":"sns.heatmap(df.corr(), annot = True)","ab0d2dee":"l = df.columns.values\nnumber_of_columns=df.shape[1]\nnumber_of_rows = len(l)-1\/number_of_columns\nplt.figure(figsize=(2*number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.distplot(df[l[i]],kde=True) ","3149ec3e":"sns.pairplot(df)","fa4ed43f":"X = df[['CGPA', 'GRE Score', 'TOEFL Score']].values\nY = df.iloc[:, -1].values\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","39abcc3c":"# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(x_train, y_train)\n\n# XGBoost\nxgb_reg = xgboost.XGBRegressor()\nxgb_reg.fit(x_train, y_train)\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\nrand_forest_reg = RandomForestRegressor()\nrand_forest_reg.fit(x_train, y_train)","423b4961":"from sklearn.metrics import r2_score\ny_pred_lin_reg = reg.predict(x_test)\ny_pred_xgb = xgb_reg.predict(x_test)\ny_pred_rf = rand_forest_reg.predict(x_test)\nprint(f\"Adjusted R Squared Score for Linear Regression: {r2_score(y_test, y_pred_lin_reg)}\")\nprint(f\"Adjusted R Squared Score for XGBoost Regression: {r2_score(y_test, y_pred_xgb)}\")\nprint(f\"Adjusted R Squared Score for Random Forest: {r2_score(y_test, y_pred_rf)}\")","bc643800":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(reg, x_train, y_train, cv = 6)\nprint(np.char.center(\"Linear Regression Score\", 40, fillchar = '*'))\nprint(\"Scores: \", scores)\nprint(\"Accuracy: \", scores.mean() * 100, \"%\")\nprint(\"Standard Deviation: +\/-\", scores.std(), \"\\n\\n\")\n\nprint(np.char.center(\"XGBoost Score\", 40, fillchar = '*'))\nscores = cross_val_score(xgb_reg, x_train, y_train, cv = 6)\nprint(\"Scores: \", scores)\nprint(\"Accuracy: \", scores.mean() * 100, \"%\")\nprint(\"Standard Deviation: +\/-\", scores.std(), \"\\n\\n\")\n\nprint(np.char.center(\"Random Forest Score\", 40, fillchar = '*'))\nscores = cross_val_score(rand_forest_reg, x_train, y_train, cv = 6)\nprint(\"Scores: \", scores)\nprint(\"Accuracy: \", scores.mean() * 100, \"%\")\nprint(\"Standard Deviation: +\/-\", scores.std())","a20cd39d":"# <center>Admission Probability Prediction<\/center>","665ae556":"EDA Conclussion: The features CGPA, GRE Score and TOEFL Score have more linear relationship with Chances of Admission. Hence we will be using only these three features and eliminating the rest of the features.","223c502f":"Before training the model for the dataset, the following preprocessing steps will be under taken with the dataset.\n\n* Independent and target data will be seperated as X and Y.\n* Data will be split into train and test set with test set size 20%.\n* Feature scalling will be done on independent features to standarize them.","30d9fbc7":"## 2. Exploratory Data Analysis (EDA)","d89b8773":"## 3. Data Pre Processing","52dca99b":"* The heatmap shows Chances of Admission is depends mostly on CGPA, GRE Score and TOEFL Score.\n* Whether the student has done research or not doesn't affect the Chances of admission much.","dec67764":"### 4.2 K-Fold Cross Validation","49cd5d24":"### 2.3 Basic Analysis on the dataset","961a4112":"##  4. Build the model","462f1028":"### 2.1 Import libraries","4d1656ff":"* All the independent features in the dataset are numeric.\n* The target variable 'Chance of Admit' is a floating point number.\n* There is no feature with missing values.","0ca26684":"Since the selected features have more linear relationship with the target variable, Multiple linear regression model will be used to train the dataset and predict the chances of getting admission.","dc23ec53":"**Objective**<br\/>\nIt's an anxious feeling to wait for the graduation admission status for any student once they apply. University accepts the admission based on various parameters of the student. The predictive model will decide the probabiliy of getting an admission.\n\n**Data Description**<br\/>\nThe dataset contains student's GRE Score, TOEFL Score, University Rating, Statement of purpose score, Letter of recomendation score, CGPA, Whether the student has done any research or not and Chances of getting admission.","f0936bd7":"## 1. Introduction","96bc623d":"### 2.2 Import Dataset","25dd108e":"### 4.1 Adjusted R Squared Score","ce312254":"## 5. Model Evaluation","ae3731c2":"* Almost all the features are normally distributed.","6bc44084":"## 6. Conclussion","0ddb4c3b":"Since the column Serial No is insignificant, it should be droppped","8b020f66":"Linear regression model will be chosen as the suitable model for this problem","a89803ea":"* Data description show there is no outliers in any features."}}