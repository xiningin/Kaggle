{"cell_type":{"b6a50311":"code","1307d7c3":"code","b1df18c7":"code","3a81abd4":"code","a358ef70":"code","440ed234":"code","541e6d8d":"markdown","ccf2989b":"markdown","827c54d5":"markdown"},"source":{"b6a50311":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nprint('Tensorflow version ' + tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1307d7c3":"from petal_helper import *","b1df18c7":"with strategy.scope():\n    pretrained_model = tf.keras.applications.VGG16(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = False   \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    model.compile(\n        optimizer='adam',\n        loss = 'sparse_categorical_crossentropy',\n        metrics=['sparse_categorical_accuracy'],\n    )\n\nmodel.summary()","3a81abd4":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","a358ef70":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","440ed234":"test_ds = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)\n\nprint('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')","541e6d8d":"# If you like this notebook, please an Upvote! Don't forget to check out my other notebooks too!\n\n* [ConnectX Baseline](https:\/\/www.kaggle.com\/brendan45774\/connectx-baseline)\n* [Data Visuals - Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/data-visuals-matplotlib)\n* [Digit Recognizer Solution](http:\/\/www.kaggle.com\/brendan45774\/digit-recognizer-solution)\n* [Dictionary and Pandas Cheat sheet](https:\/\/www.kaggle.com\/brendan45774\/dictionary-and-pandas-cheat-sheet)\n* [EDA Tutorial Hollywood Movies](https:\/\/www.kaggle.com\/brendan45774\/eda-tutorial-hollywood-movies)\n* [Getting started with Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/getting-started-with-matplotlib)\n* [HOG features - Histogram of Oriented Gradients](https:\/\/www.kaggle.com\/brendan45774\/hog-features-histogram-of-oriented-gradients)\n* [How to get the lowest score](https:\/\/www.kaggle.com\/brendan45774\/how-to-get-the-lowest-score)\n* [House predict solution](http:\/\/www.kaggle.com\/brendan45774\/house-predict-solution)\n* [K-Means Clustering (Image Compression)](https:\/\/www.kaggle.com\/brendan45774\/k-means-clustering-image-compression)\n* [Kuzushiji-MNIST Panda](http:\/\/www.kaggle.com\/brendan45774\/kuzushiji-mnist-panda)\n* [Plotly Coronavirus (Covid-19)](https:\/\/www.kaggle.com\/brendan45774\/plotly-coronavirus-covid-19)\n* [Titanic Top Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-top-solution)\n* [Titanic Data Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-data-solution)\n* [Word Cloud - Analyzing Names](https:\/\/www.kaggle.com\/brendan45774\/word-cloud-analyzing-names)","ccf2989b":"![image.png](attachment:image.png)","827c54d5":"# I tried and played around in the competition. I submitted it and got 0.00075."}}