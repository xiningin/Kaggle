{"cell_type":{"ede6ea2c":"code","61436452":"code","9f07a849":"code","5db93553":"code","803deeb1":"code","e8275102":"code","ae9e5516":"code","122c8002":"code","a3ee019e":"code","c104e32f":"code","d75cc12d":"code","16af2232":"code","6baec816":"code","5bf36252":"code","49e43610":"code","e74bc2a4":"code","2a51900a":"code","d84dd293":"code","d2b6be48":"markdown","d0f3a370":"markdown","f61cbf6c":"markdown","b3a9d7ee":"markdown","e36e05de":"markdown","14d355ed":"markdown","27432c10":"markdown","d5a8bdf8":"markdown","8fc97cca":"markdown"},"source":{"ede6ea2c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport collections\nimport itertools\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","61436452":"TARGET = 'Survived'\nN_SPLITS = 5\nN_REPEATS = 3\nSEED = 267","9f07a849":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\nsub_lr = pd.read_csv('..\/input\/tps-apr-lr-baseline\/submission_lr.csv') ","5db93553":"test[TARGET] = sub_lr[TARGET]\n\ndf = pd.concat([train, test], axis = 0, ignore_index = True)","803deeb1":"# categorical\nfeat_cat = [col for col in df.columns if df[col].dtypes == 'object']\nfeat_cat","e8275102":"# Embarked, fillna with 'X' value\ndf['Embarked'] = df['Embarked'].fillna('X')\n\n# Ticket, fillna with 'X', split string and take first split \ndf['Ticket'] = df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n# Cabin, fillna with 'X' and take first letter\ndf['Cabin'] = df['Cabin'].fillna('X').map(lambda x: x[0].strip())\n\n# Name, take only surnames\ndf['Name'] = df['Name'].map(lambda x: x.split(',')[0])","ae9e5516":"# numerical\nfeat_num = df.dtypes[df.dtypes != \"object\"]\nfeat_num","122c8002":"# family\ndf['Family'] = df['SibSp'] + df['Parch'] + 1 \ndef f(col):\n    if col == 1:\n        val = 'Single'\n    elif col == 2:\n        val = 'Couple'\n    elif col == 3:\n        val = 'Small_family'\n    elif col in [4, 5]:\n        val = 'Mid_family'\n    elif col in [6, 7]:\n        val = 'Big_family'\n    else:\n        val = 'Super_family'\n    return val\ndf['FamilySize'] = df['Family'].apply(f)\n\n# age, fare\naux = df.groupby([\"Pclass\",\"Embarked\",\"Sex\"])[[\"Age\",\"Fare\"]].mean()\ndf[\"MultiIndex\"] = pd.MultiIndex.from_frame(df[[\"Pclass\",\"Embarked\",\"Sex\"]])\ndf.loc[df[\"Age\"].isna(),\"Age\"] = df.loc[df[\"Age\"].isna(),\"MultiIndex\"].map(aux[\"Age\"])\ndf.loc[df[\"Fare\"].isna(),\"Fare\"] = df.loc[df[\"Fare\"].isna(),\"MultiIndex\"].map(aux[\"Fare\"])\ndf.drop(columns=[\"MultiIndex\"], inplace=True)\n\ndef f(col):\n    if col < 10:\n        val = '10s'\n    elif 10 <= col < 20:\n        val = '20s'\n    elif 20 <= col < 30:\n        val = '30s'\n    elif 30 <= col < 40:\n        val = '40s'\n    elif 40 <= col < 50:\n        val = '50s'\n    elif 50 <= col < 60:\n        val = '60s'\n    elif 60 <= col < 70:\n        val = '70s'\n    elif 70 <= col < 80:\n        val = '80s'\n    elif 80 <= col < 90:\n        val = '90s'\n    else:\n        val = '100s'\n    return val\ndf['AgeSize'] = df['Age'].apply(f)\n\ndef f(col):\n    if col < 5:\n        val = 'Super_cheap'\n    elif 5 <= col < 10:\n        val = 'Very_cheap'\n    elif 10 <= col < 20:\n        val = 'Cheap'\n    elif 20 <= col < 40:\n        val = 'Moderate'\n    elif 40 <= col < 100:\n        val = 'Expensive'\n    elif 100 <= col < 200:\n        val = 'Very_expensive'\n    elif 200 <= col < 300:\n        val = 'Super_expensive'\n    else:\n        val = 'Mega_expensive'\n    return val\ndf['FareSize'] = df['Fare'].apply(f)","a3ee019e":"comb = list(itertools.combinations(['Pclass', 'Sex', 'Cabin', 'Embarked', 'FamilySize', 'AgeSize', 'FareSize'], 2))\ncomb","c104e32f":"for c1, c2 in comb:\n    df.loc[:, c1 + '_' + c2] = df[c1].astype(str) + '_' + df[c2].astype(str)","d75cc12d":"feat_num = ['Age', 'SibSp', 'Pclass', 'Parch', 'Fare', 'Family']\nfeat_onehot = ['Cabin', 'Embarked',\n               'Pclass_Sex', 'Pclass_Cabin', 'Pclass_Embarked', 'Pclass_FamilySize', 'Pclass_AgeSize', 'Pclass_FareSize',\n               'Sex_Cabin', 'Sex_Embarked', 'Sex_FamilySize', 'Sex_AgeSize', 'Sex_FareSize', 'Cabin_Embarked', 'Cabin_FamilySize', 'Cabin_AgeSize', 'Cabin_FareSize',\n               'Embarked_FamilySize', 'Embarked_AgeSize', 'Embarked_FareSize', 'FamilySize_AgeSize', 'FamilySize_FareSize', 'AgeSize_FareSize']\nfeat_label = ['Sex', 'FamilySize', 'AgeSize', 'FareSize'] #['Name', 'Ticket']","16af2232":"def label_encoder(col):\n    le = LabelEncoder()\n    return le.fit_transform(col)\n\nsc = StandardScaler()\n\n#df_num  = pd.DataFrame(sc.fit_transform(df[feat_num]), columns = feat_num)\ndf_num = df[feat_num]\ndf_onehot = pd.get_dummies(df[feat_onehot])\ndf_label = df[feat_label].apply(label_encoder)\ndf_target = df[TARGET]","6baec816":"df_all = pd.concat([df_num, df_onehot, df_label], axis=1)\n\ndf_all.isnull().values.sum(), df_all.shape","5bf36252":"X = df_all.values\ny = df_target.values","49e43610":"lr_oof = np.zeros((train.shape[0], N_REPEATS))\nlr_preds = np.zeros((test.shape[0], N_REPEATS))\n\nrskf = RepeatedStratifiedKFold(n_splits = N_SPLITS, n_repeats = N_REPEATS, random_state = SEED)\nfor fold, (train_idx, valid_idx) in enumerate(rskf.split(X, y)):\n    print(\"=> Fold {}\".format(fold + 1))\n\n    oof_idx = np.array([idx for idx in valid_idx if idx < train.shape[0]])\n    test_idx = np.array([idx for idx in valid_idx if idx >= train.shape[0]])\n\n    x_train, y_train = X[train_idx], y[train_idx]\n    x_valid, y_valid = X[oof_idx], y[oof_idx]\n    x_test = X[test_idx]\n    \n    params = {'penalty': 'l2', 'C': 83.79260077891932, 'class_weight': {0: 1.05, 1: 1}}\n    model = LogisticRegression(**params, random_state = SEED)\n    \n    model.fit(x_train, y_train)\n    \n    lr_oof[oof_idx, fold\/\/N_SPLITS] = model.predict(x_valid)\n    acc_oof = accuracy_score(y_valid, lr_oof[oof_idx, fold\/\/N_SPLITS])\n    lr_preds[test_idx - train.shape[0], fold\/\/N_SPLITS] = model.predict(x_test)\n    print(f\"ACC SCORE {acc_oof:.4f} \\n\")    \n    if fold in [(i+1) * N_SPLITS - 1 for i in range(N_REPEATS)]:\n        acc_overall = accuracy_score(y[:train.shape[0]], lr_oof[:, fold\/\/N_SPLITS])\n        print(f\"=> OVERALL ACC SCORE: {acc_overall:.4f} \\n\") ","e74bc2a4":"preds = lr_preds.sum(axis = 1)\n\ncollections.Counter(preds)","2a51900a":"sub['Survived'] = np.where(preds > N_REPEATS\/\/2, 1, 0).astype(int)\nsub.to_csv(\"submission.csv\", index = False)","d84dd293":"sub['Survived'].hist()","d2b6be48":"## Setting","d0f3a370":"## Load libraries","f61cbf6c":"## Read data","b3a9d7ee":"## Submit","e36e05de":"## Logistic Regression","14d355ed":"## Referenced\n\n* https:\/\/www.kaggle.com\/hiro5299834\/tps-apr-2021-voting-pseudo-labeling","27432c10":"#### *Aim to bring Logistic Regression acc score to 80%*\n#### *The pl data comes from [notebook link](https:\/\/www.kaggle.com\/kalashnimov\/logistic-regression-baseline)*","d5a8bdf8":"## Feature engineering","8fc97cca":"## Encoding"}}