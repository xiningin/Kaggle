{"cell_type":{"9e9f7ed0":"code","b38a50b1":"code","aef1ed9f":"code","6dbc3ca6":"code","9d784b9a":"code","fb36c21a":"code","d6bdef05":"code","781afa94":"code","dd40f40c":"code","9f628ae9":"code","93a70ea0":"code","1847913a":"code","119eb838":"code","22d804e3":"code","8ea8e3cd":"code","cbd0eb82":"code","eac42592":"code","cc361cdf":"code","7ba88953":"code","1c678ed2":"code","5e7f1911":"code","3110637b":"code","89f37d87":"code","9ce7d13e":"code","a55bf773":"code","68bcbfa3":"code","f17ec851":"code","72aab53d":"code","7b8a3827":"code","cc6c6a29":"code","7eac24c5":"code","f23cdd73":"markdown","06fdabc0":"markdown","a6c78c27":"markdown","92655987":"markdown","7b41d761":"markdown","94bd5d4d":"markdown","195f2ab4":"markdown","0a9899d6":"markdown","42d73245":"markdown","bb21b27a":"markdown","f6f9f423":"markdown","da8d1166":"markdown"},"source":{"9e9f7ed0":"from google.colab import drive\ndrive.mount('\/content\/drive')","b38a50b1":"!pip install -q kaggle","aef1ed9f":"from google.colab import files\n# Upload kaggle API key file (kaggle.json)\nuploaded = files.upload()","6dbc3ca6":"%cd \/root\n!mkdir -p .kaggle\n!mv \/content\/kaggle.json \/root\/.kaggle\/kaggle.json\n%cd \/content","9d784b9a":"%cd \/root\/.kaggle\/\n!ls\n%cd \/content","fb36c21a":"!kaggle competitions download -c dogs-vs-cats","d6bdef05":"!unzip test1.zip\n!unzip train.zip\n%cd \/content\n!mkdir data\n!mv \/content\/test1 \/content\/data\/test1\n!mv \/content\/train \/content\/data\/train\n!mv \/content\/sampleSubmission.csv \/content\/data\/sampleSubmission.csv\n!rm -fr \/content\/test1.zip\n!rm -fr \/content\/train.zip","781afa94":"import os \nimport cv2\nimport glob\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","dd40f40c":"%cd kaggle\/input\/dogs-vs-cats\/train\/train\/","9f628ae9":"path = '\/kaggle\/input\/dogs-vs-cats\/train\/train\/'\nfile_names, width_list, height_list, ratios_list = ([] for _ in range(4))\nshapes_dict = {}\ncount = 0\nfor file in os.listdir(path):\n  img = cv2.imread(f'{path}\/{file}', 0)\n  file_names.append(file)\n  width_list.append(img.shape[0])\n  height_list.append(img.shape[1])\n  ratios_list.append(img.shape[0]\/img.shape[1])\n  shapes_dict.update({file: img.shape})\n  count += 1\n  if count == 750:\n    break","93a70ea0":"df_train = pd.DataFrame(index=file_names)\ndf_train['width'] = width_list\ndf_train['height'] = height_list\ndf_train['ratio'] = ratios_list\ndf_train","1847913a":"avg_shape = round(df_train['width'].mean()), round(df_train['height'].mean())\nmin_shape = round(df_train['width'].min()), round(df_train['height'].min())\nmax_shape = round(df_train['width'].max()), round(df_train['height'].max())\nprint(\"Average shape : \", (avg_shape))\nprint(\"Minimum shape : \", (min_shape))\nprint(\"Maximum shape : \", (max_shape))","119eb838":"smallest_image = df_train[df_train['width'] == min_shape[0]].index.values[0]\nimg = cv2.imread(path+'\/'+smallest_image)\nplt.imshow(img)\nplt.title(img.shape, fontdict={'fontsize': 20})","22d804e3":"largest_image = df_train[df_train['width'] == max_shape[0]].index.values[0]\nimg = cv2.imread(path+'\/'+largest_image)\nplt.imshow(img)\nplt.title(img.shape, fontdict={'fontsize': 20})","8ea8e3cd":"x_data = range(0, len(df_train))\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3)\nfig.set_size_inches(20,5)\nfig.suptitle('shapes')\ntarget_size = [400, 400]\ntarget_ratio = [1.0, 1.0]\n\nax1.plot(x_data, df_train['width'], label=1)\nax1.set_title('weight')\nax2.plot(x_data, df_train['height'], label=2)\nax2.set_title('height')\nax3.plot(x_data, df_train['ratio'], label=3)\nax3.set_title('ratio')\nax1.plot([0, len(df_train)], target_size, color='r', linestyle='-', linewidth=2)\nax2.plot([0, len(df_train)], target_size, color='r', linestyle='-', linewidth=2)\nax3.plot([0, len(df_train)], target_ratio, color='r', linestyle='-', linewidth=2)","cbd0eb82":"def resize(img, target_size):\n  img_resized = cv2.resize(img, (target_size[0], target_size[1]))\n  return img_resized","eac42592":"img = cv2.imread(path+'\/'+largest_image)\nimg_resized = resize(img, (target_size[0], target_size[1]))\nprint('Before resizing: ', img.shape[:2])\nprint('After resizing: ', img_resized.shape[:2])\n\nfig = plt.figure(figsize=(10, 20))\nfig.add_subplot(1, 2, 1)\nplt.imshow(img)\nfig.add_subplot(1, 2, 2)\nplt.imshow(img_resized)\nplt.show()","cc361cdf":"def expand(img, target_size):\n  if img.shape[0] < target_size[0]:\n    w = img.shape[0]\n  else:\n    w = target_size[0]\n  if img.shape[1] < target_size[1]:\n    h = img.shape[1]\n  else:\n    h = target_size[1]\n  x_pad = (math.floor((target_size[0] - w)\/2), math.ceil((target_size[0] - w)\/2))\n  y_pad = (math.floor((target_size[1] - h)\/2), math.ceil((target_size[1] - h)\/2))\n  img_expanded = np.stack([np.pad(img[:,:,x], [x_pad, y_pad], mode='constant', constant_values=0) for x in range(3)], axis=2)\n  return img_expanded","7ba88953":"img = cv2.imread(path+'\/'+smallest_image)\nprint('before', img.shape)\nimg_resized = resize(img, (target_size[0], target_size[1]))\nimg_expanded = expand(img, (target_size[0], target_size[1]))\n\nfig = plt.figure(figsize=(13, 27))\nfig.add_subplot(1, 3, 1)\nplt.imshow(img)\nfig.add_subplot(1, 3, 2)\nplt.imshow(img_resized)\nfig.add_subplot(1, 3, 3)\nplt.imshow(img_expanded)\nplt.show()","1c678ed2":"def equalize(path, target_size, target_path):\n  img = cv2.imread(path)\n  try:\n    if (img.shape[0] < target_size[0] and img.shape[1] < target_size[1]) or (\n        img.shape[0] == target_size[0] and img.shape[1] < target_size[1]) or (\n            img.shape[0] < target_size[0] and img.shape[1] == target_size[1]):\n      img_modified = expand(img, target_size)\n    elif (img.shape[0] < target_size[0] and img.shape[1] > target_size[1]) or (\n        img.shape[0] > target_size[0] and img.shape[1] < target_size[1]):\n      img_modified = expand(img, target_size)\n      img_modified = resize(img, target_size)\n    elif (img.shape[0] > target_size[0] and img.shape[1] > target_size[1]) or (\n        img.shape[0] == target_size[0] and img.shape[1] > target_size[1]) or (\n            img.shape[0] > target_size[0] and img.shape[1] == target_size[1]):\n      img_modified = resize(img, target_size)\n    elif (img.shape[0] == target_size[0] and img.shape[1] == target_size[1]):\n      img_modified = img\n  except: \n    print('ANOTHER CASE HAS BEEN ENCOUNTERED! FOR:', path)\n\n  cv2.imwrite(target_path, img_modified)","5e7f1911":"os.mkdir('\/tmp\/train_modified')\nos.mkdir('\/tmp\/test_modified')\nos.mkdir('\/tmp\/train_modified\/train')\nos.mkdir('\/tmp\/test_modified\/test')","3110637b":"path = '\/kaggle\/input\/dogs-vs-cats\/train\/train'\ntarget_path = '\/tmp\/train_modified\/train'\n\nfor file in os.listdir(path):\n  if '.ipynb_checkpoints' not in file:\n    try:\n      equalize(path+'\/'+file, target_size, target_path+'\/'+file)\n    except:\n      print(f\"Error: Couldn't equalize {file}.\")","89f37d87":"count = 0\nto_be_deleted = []\nfor file in os.listdir(target_path):\n    img = cv2.imread(f'{target_path}\/{file}', 0)\n    try:  \n        if img.shape != (400, 400):\n            print(file, img.shape)\n            to_be_deleted.append(f'{target_path}\/{file}')\n    except:\n        print(\"ERROR FOR: \", file, img.shape)\n        pass","9ce7d13e":"img = cv2.imread(f'{path}\/cat.7904.jpg', 0)\nprint(img.shape)\nequalize(f'{path}\/cat.7904.jpg', target_size, target_path+'\/'+file)\nimg_eq = cv2.imread(f'{target_path}\/cat.7904.jpg', 0)\nprint(img_eq.shape)","a55bf773":"to_be_deleted","68bcbfa3":"for file in to_be_deleted:\n  os.remove(file)","f17ec851":"_, _, files = next(os.walk(target_path))\nlen(files)","72aab53d":"path = '\/kaggle\/input\/dogs-vs-cats\/test1\/test1'\ntarget_path = '\/tmp\/test_modified\/test'\n\nfor file in os.listdir(path):\n  if '.ipynb_checkpoints' not in file:\n    try:\n      equalize(path+'\/'+file, target_size, target_path+'\/'+file)\n    except:\n      print(f\"Error: Couldn't equalize {file}.\")","7b8a3827":"count = 0\nto_be_deleted = []\nfor file in os.listdir(target_path):\n    img = cv2.imread(f'{target_path}\/{file}', 0)\n    try:  \n        if img.shape != (400, 400):\n            print(file, img.shape)\n            to_be_deleted.append(f'{target_path}\/{file}')\n    except:\n        print(\"ERROR FOR: \", file, img.shape)\n        pass","cc6c6a29":"_, _, files = next(os.walk(target_path))\nlen(files)","7eac24c5":"#part 1 - Building CNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Dropout\nfrom keras.layers import Convolution2D,MaxPooling2D\nimport cv2,numpy as np\nfrom keras.models import load_model\nimport glob\n\ndef create_cnn(model_path=None):\n    #initialization\n    classifier=Sequential()\n    \n    #Convolution\n    classifier.add(Convolution2D(32,3,3,input_shape=(400, 400, 3),activation='relu'))\n\n    #Pooling\n    classifier.add(MaxPooling2D(pool_size=(2,2)))\n    #Dropout\n    classifier.add(Dropout(0.5))\n    #Adding 2nd conv. layaer\n    classifier.add(Convolution2D(32,3,3,activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2,2)))\n    classifier.add(Dropout(0.5))\n    \n    classifier.add(Convolution2D(64,3,3,activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2,2)))\n    classifier.add(Dropout(0.5))\n    \n    \n    classifier.add(Convolution2D(64,3,3,activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2,2)))\n    classifier.add(Dropout(0.5))\n    \n    #Flattening\n    classifier.add(Flatten())\n\n    #Full Connected Layers\n    classifier.add(Dense(output_dim=64,activation='relu'))\n    classifier.add(Dropout(0.5))\n    classifier.add(Dense(output_dim=128,activation='relu'))\n    classifier.add(Dropout(0.5))\n    classifier.add(Dense(output_dim=1,activation='sigmoid'))\n\n    #compliling CNN\n    classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\n    #Fitting CNN to Images\n    from keras.preprocessing.image import ImageDataGenerator\n    train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n    test_datagen = ImageDataGenerator(rescale=1.\/255)\n\n    training_set = train_datagen.flow_from_directory(\n        '\/tmp\/train_modified',\n        target_size=(400, 400),\n        batch_size=32,\n        class_mode='binary')\n    \n    test_set = test_datagen.flow_from_directory(\n        '\/tmp\/test_modified',\n        target_size=(400, 400),\n        batch_size=32,\n        class_mode='binary')\n\n    classifier.fit_generator(\n        training_set,\n        steps_per_epoch=8000,\n        epochs=35,\n        validation_data=test_set,\n        validation_steps=2000)\n\n    \n    classifier.save('classifier.h5')\n    \n    if model_path:\n        model=load_model('classifier.h5')\n    \n    return model\n\nif __name__ == \"__main__\":\n    #Opening the image for prediction\n    file_path=f'\/tmp\/test_modified\/test\/1.jpg'\n    im=cv2.resize(cv2.imread(file_path),(400, 400)).astype(np.float32)\n    #cv2.imshow('Sample',cv2.resize(cv2.imread(file_path),(640,480)))\n    im = np.expand_dims(im, axis=0)\n    \n    #Checking if model is present in the Directory\n    if(glob.glob('*.h5')):\n        for filename in glob.glob('*.h5'):\n            model=load_model(filename)\n            print('Model Loaded')\n    else:\n        print('Model Not found, Creating a new Model')\n        model=create_cnn('classifier.h5')\n    \n    #Compiling the model and predicting Output    \n    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    out=model.predict(im)\n    \n    if out[0][0]==1:\n        prediction='Dog'\n    else:\n        prediction='Cat'\n    print(prediction)\n    \n\n##Saving the model\n# serialize model to JSON\nfrom keras.models import model_from_json\nclassifier_json = classifier.to_json()\nwith open(\"classifier.json\", \"w\") as json_file:\n   json_file.write(classifier_json)\n   \n# serialize weights to HDF5\nclassifier.save_weights(\"classifier.h5\")\nprint(\"Saved model to disk\")\n\n# load json and create model\njson_file = open('classifier.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"classifier.h5\")\nprint(\"Loaded model from disk\")","f23cdd73":"## Import Libraries","06fdabc0":"## **Modifying**","a6c78c27":"## Setup","92655987":"## Download Data","7b41d761":"Test","94bd5d4d":"## Analyze Data","195f2ab4":"## **Model**","0a9899d6":"## **Equalizing all images at (400, 400)**","42d73245":"### Resize","bb21b27a":"kaggle\/input\/dogs-vs-cats\/train\/train\/","f6f9f423":"### Expand","da8d1166":"https:\/\/towardsdatascience.com\/setting-up-kaggle-in-google-colab-ebb281b61463"}}