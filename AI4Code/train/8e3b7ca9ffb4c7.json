{"cell_type":{"8eca4c18":"code","e7501317":"code","c962d4a9":"code","3554e505":"code","60c4dd45":"code","052cbae9":"code","fa124adb":"code","32002230":"code","d77da992":"code","de3259e5":"code","8b5cc038":"code","58ce3e14":"code","8d5e3492":"code","bfd74037":"code","542ca8f4":"code","b4b595aa":"code","08e41d2a":"code","272d44b2":"code","cbedd125":"code","04622853":"code","74a57dd7":"markdown","95a50f93":"markdown","a6c2561d":"markdown","62f269ce":"markdown","fe1b9068":"markdown","27dff2f2":"markdown","cdcae2be":"markdown","0b7c6c91":"markdown","3471d5a7":"markdown","eaeb4593":"markdown","73d8a722":"markdown","bcbc09a3":"markdown","3a4b4494":"markdown","1f61a019":"markdown","4241fd77":"markdown","e381f123":"markdown","7049df96":"markdown","0af50592":"markdown","81079356":"markdown","1133f6a2":"markdown","8ba9fdab":"markdown","5e3af3ef":"markdown"},"source":{"8eca4c18":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","e7501317":"# Reading the Dataset\ntrain_data = pd.read_csv('..\/input\/SolarEnergy\/SolarPrediction.csv')\ntrain_data.head()","c962d4a9":"train_data.shape","3554e505":"train_data.describe()","60c4dd45":"train_data.isnull().sum()","052cbae9":"train_data.info()","fa124adb":"train_data.columns","32002230":"train_data = train_data.iloc[:,3:9]\ntrain_data.head()","d77da992":"train_data['Radiation'].describe()","de3259e5":"f, ax = plt.subplots(figsize=(15,8))\nsns.distplot(train_data['Radiation'])\nplt.xlim([-10,1602])","8b5cc038":"plt.figure(figsize=(10,10))\nsns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn')\nplt.show()","58ce3e14":"X = train_data.iloc[:,1:]\ny = train_data.iloc[:,0]","8d5e3492":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 25)","bfd74037":"from sklearn.linear_model import LinearRegression\nregresor= LinearRegression()\nregresor.fit(X_train, y_train)\nregresor_pred = regresor.predict(X_test)","542ca8f4":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)\nrandomforest_pred= rf_reg.predict(X_test)","b4b595aa":"from sklearn.metrics import explained_variance_score\nprint(explained_variance_score(y_test, regresor_pred))\nprint(explained_variance_score(y_test, randomforest_pred))","08e41d2a":"from sklearn.metrics import mean_absolute_error\nprint(mean_absolute_error(y_test, regresor_pred))\nprint(mean_absolute_error(y_test, randomforest_pred))","272d44b2":"from sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_test, regresor_pred))\nprint(mean_squared_error(y_test, randomforest_pred))","cbedd125":"from sklearn.metrics import median_absolute_error\nprint(median_absolute_error(y_test, regresor_pred))\nprint(median_absolute_error(y_test, randomforest_pred))","04622853":"from sklearn.metrics import r2_score\nprint(r2_score(y_test, regresor_pred))\nprint(r2_score(y_test, randomforest_pred))","74a57dd7":"Cleary most of data remains on the left side of plot. \n\nWe have a lot of noise here, but we are neglecting it(yes accuracy would decrease), as our focus is on different evaluation measures.","95a50f93":"### Let's first find out details of our dataset\n\nLooking it's description, info, a head look gives us a rough idea of our data.","a6c2561d":"So, Finally this NoteBook End here \ud83e\udd35\ud83c\udffb\n\nBefore going a humble request if you liked the notebook the \n\n<font color=\"Red\">Please Upvote ( It motivates me )<\/font>\n\n<font color=\"Green\">Do check my other notebooks: <\/font>\n\n[https:\/\/www.kaggle.com\/iabhishekmaurya\/classification-model-evaluation](http:\/\/)\nhttps:\/\/www.kaggle.com\/iabhishekmaurya\/used-car-price-prediction\nhttps:\/\/www.kaggle.com\/iabhishekmaurya\/applied-machine-learning\/notebook\n\n\nHappy Coding \ud83d\udcbb \ud83d\udc68\u200d\ud83d\udcbb \n\nLinkedIn: [https:\/\/www.linkedin.com\/in\/abhishek-5b642580\/](http:\/\/)","62f269ce":"Yeee \ud83e\udd29\ud83e\udd29\ud83e\udd29 \n\nWe don't have it","fe1b9068":"## Evaluation (Our Finale)","27dff2f2":"We have the following more for regression model:\n* metrics.max_error(y_test, y_pred)\n* metrics.mean_squared_log_error(y_test, y_pred)\n* metrics.mean_tweedie_deviance(y_true, y_pred, \\*)\n* metrics.mean_gamma_deviance(y_true, y_pred, \\*)\n* metrics.mean_poisson_deviance(y_true, y_pred, \\*)\n\nIn future I will try to add them here.\n\nRead them out here: [https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html](http:\/\/)","cdcae2be":"## R^2 (coefficient of determination) regression score\n\nBest possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n\n[https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score](http:\/\/)","0b7c6c91":"## Linear Regression","3471d5a7":"## Preprocesing","eaeb4593":"## Random Forest Regressor","73d8a722":"## Mean squared error regression loss\n[https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error](http:\/\/)","bcbc09a3":"### Mean absolute error regression loss\n[https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.mean_absolute_error.html](http:\/\/)","3a4b4494":"After completing mine **Evaluation of Classifiaction Model** Notebook (link below) I thought let's do the same for regression model.\n[https:\/\/www.kaggle.com\/iabhishekmaurya\/classification-model-evaluation](http:\/\/)\n\nSo, I found a dataset [https:\/\/www.kaggle.com\/dronio\/SolarEnergy](http:\/\/)\n\nRead sklearn documentation [https:\/\/scikit-learn.org\/](http:\/\/)\n\nand completed this notebook within 30mins (ofcourse I am taking about approx)\ud83e\udd73\ud83e\udd73\ud83e\udd73\ud83e\udd73\ud83e\udd73\n\n","1f61a019":"Let's have a look over our dependend column","4241fd77":"# Evaluating Regression Models\n\nI will be using 2 different models for our datsets:\n1. Linear Regression\n2. RandomForestRegressor\n\nSo, yeah let's start our journey\ud83d\udeb4\n\nBefore going forward :\n<font color=\"Red\">Please Upvote ( It motivates me )<\/font>","e381f123":"### Is there any NULL values?\n\nWe hate Null values\ud83d\ude20 ","7049df96":"Now, let's differentiate our Independent and Dependend Columns follwed by spliting them to test and train","0af50592":"**Colourful NA?**\n\nI love this colour combination.\nBut our Models hates and dark green accept the diagonal.","81079356":"### Explained variance regression score \n\nBest possible score is 1.0, lower values are worse.","1133f6a2":"## Median absolute error regression loss\n\nMedian absolute error output is non-negative floating point. The best value is 0.0","8ba9fdab":"Again let's look at our **heat map**\n\n### \ud83d\udd25Heat Map","5e3af3ef":"As our focus is on model evaluation let's just drop all object columns (to make our work easy)"}}