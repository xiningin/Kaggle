{"cell_type":{"667e0f66":"code","44e4455d":"code","2efac196":"code","dd1c96a9":"code","bda3a9ce":"code","186393bc":"code","75164ae8":"code","5c0b2f88":"code","3ae1a8c6":"code","bd2ed22a":"code","54bd322c":"code","8ea514c8":"code","0648e558":"code","fcd63d06":"code","fd1ce4e6":"code","140ae643":"code","059ee12f":"code","a86e6bc8":"code","c5c7fd0d":"code","756d572b":"code","5212ab00":"code","337a7005":"code","3f286dad":"code","471ef0c8":"code","62a63817":"code","797ceb3b":"markdown","893fa66a":"markdown","c5c9e5a2":"markdown","8df77352":"markdown"},"source":{"667e0f66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44e4455d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport time","2efac196":"df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv')\ndf","dd1c96a9":"df.describe()","bda3a9ce":"df.info()","186393bc":"df.dtypes","75164ae8":"df.duplicated()","5c0b2f88":"y = df['loss']\nX = df.drop(['id','loss'], axis=1)\nX","3ae1a8c6":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler","bd2ed22a":"scaler = StandardScaler()\nscaler.fit_transform(X)","54bd322c":"pca = PCA(n_components=78)\npca.fit(X)\nX_transformed = pca.transform(X)","8ea514c8":"X_transformed = pd.DataFrame(X_transformed)\nX_transformed","0648e558":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_transformed, y, random_state=10)","fcd63d06":"from sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=10, random_state=10)\nrfr.fit(X_train, y_train)\nrfr.score(X_test, y_test)","fd1ce4e6":"df_test_normalized = df_test.drop('id', axis=1)\npca.fit(df_test_normalized)\ntest_transformed = pca.transform(df_test_normalized)\ny_pred = rfr.predict(test_transformed)","140ae643":"df_sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\n#df_sub['loss'] = y_pred\n#df_sub.to_csv('submission.csv', index = False)\ndf_sub.head(10)","059ee12f":"from lightgbm import LGBMRegressor\nlgbm = LGBMRegressor(boosting_type='gbdt', n_estimators=100, objective='regression', random_state=10)\nlgbm.fit(X_train, y_train)\nlgbm.score(X_test, y_test)","a86e6bc8":"X_test_submit = df_test.drop('id', axis=1)\npca = PCA(n_components=78)\npca.fit(X_test_submit)\ntest_transformed = pca.transform(X_test_submit)\ny_pred = lgbm.predict(test_transformed)","c5c7fd0d":"#df_sub['loss'] = y_pred\n#df_sub.to_csv('submission.csv' , index = False)\ndf_sub.head(10)","756d572b":"def elm_fit(X, target, h, W=None):\n  start_time = time.time()\n  \n  if W is None:\n    W = np.random.uniform(-.5, .5, (h, len(X[0])))\n    \n  Hinit = X @ W.T\n  H = 1 \/ (1 + np.exp(-Hinit))\n  Ht = H.T\n  Hp = np.linalg.inv(Ht @ H) @ Ht\n  beta = Hp @ target\n  y = H @ beta\n  mape = sum(abs(y - target) \/ target) * 100 \/ len(target)\n  \n  execution = time.time() - start_time\n  print(\"Waktu eksekusi: %s detik\" % execution)\n  \n  return W, beta, mape","5212ab00":"def elm_predict(X, W, b, round_output=False):\n  Hinit = X @ W.T\n  H = 1 \/ (1 + np.exp(-Hinit))\n  y = H @ b\n  \n  if round_output:\n    y = [int(round(x)) for x in y]\n  \n  return y","337a7005":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.metrics import accuracy_score\n\nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X_transformed)\n#X_normalized = minmax_scale(X_transformed)\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=.3)","3f286dad":"W, b, mape = elm_fit(X_train, y_train, 1000)\nprint('MAPE:', mape)\noutput = elm_predict(X_test, W, b, round_output=True)\naccuracy = accuracy_score(output, y_test)\n\n#print('Output:', output)\nprint('True :', y_test)\nprint('Accuracy:', accuracy)","471ef0c8":"pca = PCA(n_components=70)\ndf_test_drop = df_test.drop('id', axis=1)\npca.fit(df_test_drop)\ndf_test_transformed = pca.transform(df_test_drop)\ndf_test_normalized = scaler.fit_transform(df_test_transformed)\n\ny_pred = elm_predict(df_test_normalized, W, b, round_output=False)","62a63817":"df_sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\ndf_sub['loss'] = y_pred\ndf_sub.to_csv('submission.csv' , index = False)\ndf_sub.head(10)","797ceb3b":"# LGBM","893fa66a":"# Extreme Learning Machine","c5c9e5a2":"# PCA","8df77352":"# Random Forest Regressor"}}