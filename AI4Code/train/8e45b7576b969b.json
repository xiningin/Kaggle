{"cell_type":{"c9c98e41":"code","b63d75d0":"code","3d80c3e0":"code","c23a9428":"code","8fe40dc7":"code","54161e27":"code","7465f819":"code","b348af06":"code","c061d3cb":"code","a1039203":"code","ce54fb5c":"code","2463a6e8":"code","13a293cf":"code","d1d62a82":"code","9839e78d":"code","ecb6933a":"code","b9de0372":"markdown","10ee929d":"markdown","ec410880":"markdown","3434474c":"markdown","b5ccf207":"markdown","b455b48c":"markdown","74369eef":"markdown","c6257a2c":"markdown","749172a8":"markdown"},"source":{"c9c98e41":"import numpy as np\nimport os,math,random\nimport pandas as pd \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom as pyd\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure\n\nimport warnings\nwarnings.filterwarnings('ignore')","b63d75d0":"def read_xray(path, voi_lut = True, fix_monochrome = True,equalize_hist=True):\n    dicom = pyd.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    if equalize_hist:\n        data=exposure.equalize_hist(data)\n        \n    return data\n","3d80c3e0":"def show_sample_images(df,directory,n,cmap='gray'):\n    plt.subplots(math.floor(n\/2),2,figsize=(16,math.floor(n\/2)*8))\n    \n    dfs=df.sample(n)\n    \n    sample_ids=dfs['image_id']\n    sample_class=list(dfs['class_name'])\n    for i,image_id in enumerate(sample_ids):\n        ax=plt.subplot(math.floor(n\/2),2,i+1)\n        image=read_xray(os.path.join(directory,f'{image_id}.dicom'))\n        ax.imshow(image,cmap=cmap)\n        plt.title(f'{sample_class[i]}')\n        \n        #bounding boxes:\n        w=dfs.iloc[i]['x_max']-dfs.iloc[i]['x_min']\n        h=dfs.iloc[i]['y_max']-dfs.iloc[i]['y_min']\n        x_min,y_min=dfs.iloc[i]['x_min'],dfs.iloc[i]['y_min']\n        \n        p=mpl.patches.Rectangle((x_min,y_min),w,h,ec='r',lw=1,fc='none')\n        ax.add_patch(p)\n         \n    plt.tight_layout()\n    plt.axis('off')\n    plt.show()  ","c23a9428":"cwd='.\/'\ntrain_dir='..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train'\ntest_dir='..\/input\/vinbigdata-chest-xray-abnormalities-detection\/test'\n\ntrain=pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv')\nsample_sub=pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/sample_submission.csv')\ntrain.head()","8fe40dc7":"show_sample_images(df=train,directory=train_dir,n=40,cmap='gray')","54161e27":"fig,ax=plt.subplots(figsize=(16,8))\nsns.countplot(train['class_name'])\nplt.setp(ax.get_xticklabels(),rotation=90)\nplt.title('Class Balance')\n","7465f819":"print('Total number of Images in trainset are : {} '.format(len(train)))\nprint('Number of unique pictures in the trainset are : {} '.format(train['image_id'].nunique()))","b348af06":"print('Average number of annotations per image : {} '.format(math.ceil(67900\/15000)))","c061d3cb":"def plot_image(img_id,train_dir,df):\n    fig,ax=plt.subplots(figsize=(10,10))\n    img=read_xray(os.path.join(train_dir,f'{img_id}.dicom'))\n    plt.imshow(img,cmap='gray')\n\n    #annotations:\n    \n    dfs=df[df['image_id']==img_id]\n    \n    #all annotations for the image\n    for i in range(len(dfs)):\n        \n         #bounding boxes:\n        #width and height\n        w=dfs.iloc[i]['x_max']-dfs.iloc[i]['x_min']\n        h=dfs.iloc[i]['y_max']-dfs.iloc[i]['y_min']\n        \n        #min,max\n        x_min,y_min=dfs.iloc[i]['x_min'],dfs.iloc[i]['y_min']\n        x_max,y_max=dfs.iloc[i]['x_max'],dfs.iloc[i]['y_max']\n        \n        p=mpl.patches.Rectangle((x_min,y_min),w,h,ec='r',lw=1,fc='none')\n        ax.add_patch(p)\n        ax.annotate('{}'.format(dfs.iloc[i]['class_name']), xy=(x_min+50,y_max+50),\n                    color='blue',horizontalalignment='right')\n    \n    \n    plt.axis('off')\n    plt.show()\n    \nplot_image('9a5094b2563a1ef3ff50dc5c7ff71345',train_dir,train)   ","a1039203":"def random_id(df):\n    img_id=random.choice(df['image_id'])\n    return img_id\n\nplot_image(random_id(train),train_dir,train)   ","ce54fb5c":"plot_image(random_id(train),train_dir,train)   ","2463a6e8":"plot_image(random_id(train),train_dir,train)   ","13a293cf":"plot_image(random_id(train),train_dir,train)   ","d1d62a82":"plot_image(random_id(train),train_dir,train)   ","9839e78d":"plot_image(random_id(train),train_dir,train)   ","ecb6933a":"plot_image(random_id(train),train_dir,train)   ","b9de0372":"**checking the class balance**","10ee929d":"# Imports","ec410880":"**Lets plot images with all thier annotations:**","3434474c":"**As there are many images with a lot of annotations ,we will plot them with all annotations**","b5ccf207":"* **read xray from this notebook[  ]**","b455b48c":"**Checking the Number of pictures in trainset**","74369eef":"**Lets look at some examples**","c6257a2c":"# **Load data**","749172a8":"# Resources:\n[ https:\/\/www.kaggle.com\/dschettler8845\/visual-in-depth-eda-vinbigdata-competition-data ]\n[ https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class-train ]\n"}}