{"cell_type":{"e622b407":"code","bd0d003e":"code","4f7a4ed5":"code","3f38f6fa":"code","27593f00":"code","0d9a8e48":"code","dcdc7646":"code","055f87ea":"code","1f7370a8":"code","e7d59dc7":"code","768cdcd4":"code","b63363b1":"code","d6fccb35":"code","25e2ce5d":"markdown","76060fd9":"markdown","c95511c6":"markdown","0bb90f75":"markdown","aba3a5a9":"markdown","1d3634f5":"markdown","9629e815":"markdown","b5ad587f":"markdown","af55be42":"markdown","8eff885f":"markdown","561a95a6":"markdown","90d4ad58":"markdown","ca1ef1a0":"markdown","6e95fe69":"markdown"},"source":{"e622b407":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.layers import Activation,Dropout,Dense,Conv2D,AveragePooling2D,Flatten,ZeroPadding2D,MaxPooling2D\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils.np_utils import to_categorical \nimport math","bd0d003e":"test=pd.read_csv('..\/input\/test.csv',delimiter=',')\ntrain=pd.read_csv('..\/input\/train.csv',delimiter=',')\nprint(train.head())\nlabel=train['label']\nprint(label.shape)\ndel train['label']\nprint(label.head())\nsns.countplot(label)\ntrain=train.values\ntrain=train.reshape(train.shape[0],28,28,1)\ntest=test.values\ntest=test.reshape(test.shape[0],28,28,1)\n","4f7a4ed5":"plt.figure(figsize=(25,10))\nfor i in range(0,10):\n    plt.subplot(1,10,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0],cmap='gray')\n    #these are the sample images  ","3f38f6fa":"label=to_categorical(label,10)\n","27593f00":"X_train, X_test, Y_train, Y_test = train_test_split(train,label, test_size = 0.1)","0d9a8e48":"model=Sequential()\ndef build():\n    model.add(Conv2D(6,(5,5),strides=1,padding='valid', input_shape = (28,28,1)))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n    model.add(Dropout(0.2))\n    model.add(Activation('relu'))\n    model.add(Conv2D(16,(5,5),strides=1,padding='valid'))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n    model.add(Dropout(0.2))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n    model.add(Dense(120,activation='relu'))\n    model.add(Dense(84,activation='relu'))\n    model.add(Dense(10,activation='softmax'))\n    model.compile(optimizer='AdaDelta',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n    model.fit(X_train,Y_train,epochs=30,batch_size=128,verbose=1)\n    \nbuild()","dcdc7646":"modelsub=model.predict(X_train,batch_size=None, verbose=1)\nc=0\nf=0\nfor i in range(modelsub.shape[0]):\n    if np.argmax(modelsub[i])==np.argmax(Y_train[i]):\n        c+=1\n    else:\n        f+=1\naccuracy=c\/(c+f)\nprint('Train Accuracy:',accuracy*100)\n","055f87ea":"a=model.evaluate(X_test, Y_test,verbose=1)\nprint('Test Accuracy',a[1])","1f7370a8":"mode=model.predict(test,batch_size=None, verbose=1)\n","e7d59dc7":"ls=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(modelsub.shape[0]):\n    ls[np.argmax(modelsub[i])]+=1\nprint(ls)\n","768cdcd4":"count1=0\ncount2=0\nfor i in range(modelsub.shape[0]):\n    if(np.argmax(Y_train[i])==np.argmax(modelsub[i])):\n        count1+=1\n    else:\n        count2+=1\nprint(count1,' ',count2)","b63363b1":"count=0\nplt.figure(figsize=(25,10))\nwhile count<10:\n    for i in range(modelsub.shape[0]):\n        if(np.argmax(Y_train[i])!=np.argmax(modelsub[i])):\n            plt.subplot(1,10,count+1)\n            plt.xticks([])\n            plt.yticks([])\n            s='Predicted:'\n            s=s+' '+str(np.argmax(modelsub[i]))\n            plt.xlabel(s)\n            plt.imshow(train[i][:,:,0],cmap='gray')\n            count+=1\n            if count is 10:\n                break\n            ","d6fccb35":"ccc=[]\nfor i in range(mode.shape[0]):\n    ccc.append(np.argmax(mode[i]))\nd=np.arange(0,test.shape[0])+1\nd.shape\ndf=pd.DataFrame({'ImageId':d,'Label':ccc\n},index=d)\ndf.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n","25e2ce5d":"**3. Building the model**\n\nThis is a standard LeNet-5 Implementation which was proposed for digit recognition by **Yaan Lecunn**.\n[Here is the link for the official research paper](http:\/\/yann.lecun.com\/exdb\/lenet\/).","76060fd9":"<img src=\"https:\/\/www.thebalancecareers.com\/thmb\/Df3jp07jm7AK30eNji0G6Fkl93s=\/2122x1415\/filters:fill(auto,1)\/185002046-56b0974c3df78cf772cfe3c5.jpg\" width=\"2000px\">","c95511c6":"Printing the predicted frequencies of train data.","0bb90f75":"We divide the data for testing and training in **90-10** since it is a competition submission.However it is generally splitted in the ratio \nof **70-30**.","aba3a5a9":"1> \nImporting necessary libraries\n\n2>\nData Preprocessing and visualisation\n\n3>\nBuilding the model\n\n4>\nPrediction,evauation and Performance Analysis.\n\n5> \nCompetition Submission","1d3634f5":"**4. Prediction\/Evaluation phase**\n\n","9629e815":"**Lenet-5 Architecture**","b5ad587f":"Printing some samples which were classified wrong.","af55be42":"Then we show some sample images present in the dataset","8eff885f":"**2. Next step is loading the data and do pre-processing and visualising it.** \n\nNow we visualise the data given to us by plotting the frequency of digits inthe given dataset.","561a95a6":"**5. Competition Submission**","90d4ad58":"Hey Guys! Welcome back.\n\nIn this kernel we are going to classify hand-written digits based on **MNIST** data ","ca1ef1a0":"1.  **First we are importing the necessary libraries.**\n\nIn this Kernel we have used primarily Keras with TensorFlow backend for our Convulutional Model.","6e95fe69":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/2400\/1*1TI1aGBZ4dybR6__DI9dzA.png\" width=\"2000px\">\n\n"}}