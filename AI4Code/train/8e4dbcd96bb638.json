{"cell_type":{"d712a4c1":"code","3a257a14":"code","8a930869":"code","0d8c6837":"code","126234ec":"code","862c7bd3":"code","b9910e4c":"code","649365ed":"code","3b2bff4f":"code","ac7f524a":"code","4246ef21":"code","a8deb33a":"code","14465af9":"code","001bfe91":"code","98fcdadd":"code","576c54a3":"code","789da3bc":"code","022e5a92":"code","afc5bce9":"code","bb60e1b8":"code","e56c5fcf":"code","794e636f":"code","4e44102a":"code","fbe3817a":"code","8d7bf749":"code","b92944dd":"code","0a89569b":"code","0b2a46b8":"code","30fb339e":"code","a05ac609":"code","099d3cd3":"code","54db6c3e":"code","860fd67b":"code","d2f69877":"code","2ff8c3cf":"code","7b9d468b":"code","9da41a1a":"code","b1ad75b0":"code","73aaf6f8":"code","83aa15fb":"code","1ea5c638":"code","08aa0230":"code","5e8a32dc":"code","a2214a77":"code","bc9b3b9f":"code","0a71158f":"code","173a3f17":"code","7c78ad05":"code","edd23c0a":"code","847ede3d":"markdown","e21f5da4":"markdown","97b03d01":"markdown","895be3a0":"markdown","e460c0f8":"markdown","696802db":"markdown","165a9aa8":"markdown","caa65fb1":"markdown","ce368418":"markdown","d1241077":"markdown","211d6030":"markdown","c47a5d3a":"markdown","303fc307":"markdown","7f9f08d9":"markdown","600350e9":"markdown","917f9af8":"markdown","ba02acf6":"markdown","862da73b":"markdown","3cfed766":"markdown","a6c5dd3c":"markdown","ec5d5b92":"markdown","8972ff7e":"markdown","3c7a6824":"markdown","38b46bd5":"markdown","e5f853f5":"markdown","b7162320":"markdown","f2df3d2e":"markdown","849fae02":"markdown","3ed04f31":"markdown","6b6ca38c":"markdown","8e37f874":"markdown","10277e6c":"markdown","e34190db":"markdown","9634ffae":"markdown","7fd72e5d":"markdown","66b13731":"markdown"},"source":{"d712a4c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os #os\u6a21\u584a\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u6587\u4ef6\u548c\u76ee\u9304\u64cd\u4f5c\uff0c\u4e26\u4e14\u662f\u8de8\u5e73\u53f0\u7684\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3a257a14":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n#from pandas.tools.plotting import scatter_matrix\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","8a930869":"train=pd.read_csv(\"..\/input\/titanicdataset\/Titanic_train.csv\" )\ntit1=train.select_dtypes(include=['float64','int64','object'])\ntrain.info()\n\ntest=pd.read_csv(\"..\/input\/titanicdataset\/Titanic_test.csv\")\ntit2=test.select_dtypes(include=['float64','int64','object'])\ntest.info()","0d8c6837":"print(\"train shape:\",train.shape)\ntit1.head()\nprint(\"test shape :\",test.shape)\ntit2.head()","126234ec":"tit2['survived']=np.nan\nprint(\"test shape :\",tit2.shape)\ntit2.head()","862c7bd3":"plt.figure(figsize=(4,4))\nplt.title('survived',size=20)\ntit1.survived.value_counts().plot.bar(color=['red','green'])\n\nplt.figure(figsize=(4,4))\nplt.title('sex',size=20)\ntit1.sex.value_counts().plot.bar(color=['skyblue','pink'])","b9910e4c":"percent=round(np.mean(train['survived']),3)*100\nprint(\"Percentage of Survivors:\",percent,\"%\")\ntotal=train['survived'].sum()\ntotal\nmen=train[train['sex']=='male']\nwomen=train[train['sex']=='female']\nm=men['sex'].count()\nw=women['sex'].count()\nprint(\"male:\",m)\nprint(\"female:\",w)\nprint(\"percentage of women:\",round(w\/(m+w)*100),\"%\")\nprint(\"percentage of men:\",round(m\/(m+w)*100),\"%\")","649365ed":"plt.figure(figsize=(5,5))\nplt.title(\"CLASS DIVISION\",size=20)\ntit1.pclass.value_counts().plot.bar(color=['olive','coral','gold'])","3b2bff4f":"train['fare'].hist(bins = 80, color = 'orange')\nplt.title(\"FARE\",size=20)","ac7f524a":"plt.figure(figsize=(5,5))\nplt.title(\"embarked\",size=20)\ntit1.embarked.value_counts().plot.bar(color=['olive','coral','gold'])","4246ef21":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'survived', hue = 'sex', data = train)\nplt.title(\"SURVIVED AND SEX\",size=20)","a8deb33a":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'survived', hue = 'pclass', data = train)\nplt.title(\"SURVIVED AND PCLASS\",size=20)","14465af9":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'survived', hue = 'embarked', data = train)\nplt.title(\"SURVIVED AND EMBARKED\",size=20)","001bfe91":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(train)","98fcdadd":"train.isnull().sum()","576c54a3":"train = train.drop(['ticket', 'cabin'], axis=1)\ntest = test.drop(['ticket', 'cabin'], axis=1)","789da3bc":"train['age'].hist(bins=40,color='salmon')\nplt.title(\"AGE\",size=20)","022e5a92":"age_group = train.groupby(\"pclass\")[\"age\"]\nprint(age_group.median())","afc5bce9":"train.loc[train.age.isnull(),'age']=train.groupby(\"pclass\").age.transform('median')\ntest.loc[test.age.isnull(),'age']=test.groupby(\"pclass\").age.transform('median')\nprint(train['age'].isnull().sum())","bb60e1b8":"from statistics import mode\ntrain[\"embarked\"] = train[\"embarked\"].fillna(mode(train[\"embarked\"]))\ntest[\"embarked\"] = test[\"embarked\"].fillna(mode(test[\"embarked\"]))\ntrain[\"fare\"] = train[\"fare\"].fillna(mode(train[\"fare\"]))","e56c5fcf":"print(train.isnull().sum())","794e636f":"print(test.isnull().sum())","4e44102a":"train[\"sex\"][train[\"sex\"] == \"male\"] = 0\ntrain[\"sex\"][train[\"sex\"] == \"female\"] = 1\n\ntest[\"sex\"][test[\"sex\"] == \"male\"] = 0\ntest[\"sex\"][test[\"sex\"] == \"female\"] = 1\n\ntrain[\"embarked\"][train[\"embarked\"] == \"S\"] = 0\ntrain[\"embarked\"][train[\"embarked\"] == \"C\"] = 1\ntrain[\"embarked\"][train[\"embarked\"] == \"Q\"] = 2\n\ntest[\"embarked\"][test[\"embarked\"] == \"S\"] = 0\ntest[\"embarked\"][test[\"embarked\"] == \"C\"] = 1\ntest[\"embarked\"][test[\"embarked\"] == \"Q\"] = 2\n","fbe3817a":"train['fam']=train['sibsp']+train['parch']+1\ntest['fam']=test['sibsp']+test['parch']+1","8d7bf749":"train['isAlone'] = 0\ntrain.loc[train['fam'] == 1, 'isAlone'] = 1\ntest['isAlone'] = 0\ntest.loc[test['fam'] == 1, 'isAlone'] = 1","b92944dd":"train['age']=train['age'].astype(str)\ntest['age']=test['age'].astype(str)","0a89569b":"import re\ntrain['age'] = train['age'].map(lambda x: re.compile(\"[0-9]\").search(x).group())\ntrain['age'].unique().tolist()","0b2a46b8":"#cat={'2':1, '3':2 , '5':3, '1':4 ,'4':5,'8':6,'6':7,'7':8,'0':9,'9':10}\ncat={'0':1,'1':2 ,'2':3, '3':3 , '4':5,'5':6, '6':7,'7':8,'8':9,'9':10}\ntrain['age']=train['age'].map(cat)\ntrain['age'].unique().tolist()","30fb339e":"test['age'] = test['age'].map(lambda x: re.compile(\"[0-9]\").search(x).group())\ntest['age'].unique().tolist()","a05ac609":"test['age']=test['age'].map(cat)\ntest['age'].unique().tolist()","099d3cd3":"train['title'] = train.name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain['title'] = train['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain['title'] = train['title'].replace('Mlle', 'Miss')\ntrain['title'] = train['title'].replace('Ms', 'Miss')\ntrain['title'] = train['title'].replace('Mme', 'Mrs')\n    \ntrain[['title', 'survived']].groupby(['title'], as_index=False).mean()","54db6c3e":"test['title'] = test.name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['title'] = test['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest['title'] = test['title'].replace('Mlle', 'Miss')\ntest['title'] = test['title'].replace('Ms', 'Miss')\ntest['title'] = test['title'].replace('Mme', 'Mrs')\n","860fd67b":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntrain['title'] = train['title'].map(title_mapping)\ntrain['title'] = train['title'].fillna(0)\ntest['title'] = test['title'].map(title_mapping)\ntest['title'] = test['title'].fillna(0)\ntrain.head()","d2f69877":"train = train.drop(['name'], axis = 1)\ntrain = train.drop(['parch'], axis = 1)\ntrain = train.drop(['fare','sibsp'], axis = 1)\n#train = train.drop(['fam'], axis = 1)\ntest = test.drop(['name'], axis = 1)\ntest = test.drop(['parch'], axis = 1)\ntest = test.drop(['fare','sibsp'], axis = 1)\n#test = test.drop(['fam'], axis = 1)","2ff8c3cf":"train.head()\n","7b9d468b":"test.head()","9da41a1a":"#train = pd.get_dummies(train)\n#pd.DataFrame(train)\n","b1ad75b0":"#test = pd.get_dummies(test)\n#pd.DataFrame(test)","73aaf6f8":"print(train)\nprint(test)","83aa15fb":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['survived','ID'], axis=1), \n                                                    train['survived'], test_size = 0.2, \n                                                    random_state = 42)","1ea5c638":"from sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression()\nlogisticRegression.fit(X_train, y_train)","08aa0230":"predictions = logisticRegression.predict(X_test)\nacc_LOG = round(accuracy_score(predictions, y_test) * 100, 2)\nprint(acc_LOG)\nprint(predictions)","5e8a32dc":"from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, predictions))\ntn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()","a2214a77":"accuracy=((tp+tn)\/(tp+tn+fp+fn))\nprint('accuracy is: ', (round(accuracy, 2)*100),'%')","bc9b3b9f":"ids = test['ID']\n#predictions = randomforest.predict(test.drop('ID', axis=1))\npredictions = logisticRegression.predict(test.drop('ID', axis=1))\n\noutput = pd.DataFrame({ 'ID' : ids, 'survived': predictions })\noutput.to_csv('submission.csv', index=False)","0a71158f":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\n\nclf.fit(X_train, y_train)","173a3f17":"ids = test['ID']\n#predictions = randomforest.predict(test.drop('ID', axis=1))\npredictions = clf.predict(test.drop('ID', axis=1))\n\noutput = pd.DataFrame({ 'ID' : ids, 'survived': predictions })\noutput.to_csv('submission_clf.csv', index=False)","7c78ad05":"from sklearn.svm import SVC, LinearSVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, y_train) * 100, 2)\nprint(acc_svc)\n\nids = test['ID']\n#predictions = randomforest.predict(test.drop('ID', axis=1))\npredictions = svc.predict(test.drop('ID', axis=1))\n\noutput = pd.DataFrame({ 'ID' : ids, 'survived': predictions })\noutput.to_csv('submission_svc.csv', index=False)","edd23c0a":"ids = test['ID']\n#predictions = randomforest.predict(test.drop('ID', axis=1))\npredictions = svc.predict(test.drop('ID', axis=1))\n\noutput = pd.DataFrame({ 'ID' : ids, 'survived': predictions })\noutput.to_csv('submission_svc.csv', index=False)","847ede3d":"**First we start by checking the counts of survived(1) and dead(0).\nthus from the below graoh it is clear that there were more deaths than the ratio of survivors.\nWe also plot of graph for the division of genders, to see the ratio between men and women.\nwhen the graph i splotted we see that the range of women seem more equivalent to the range of survivors and the range of deaths seem more closely related to the range of men.\nSo thus that mean that there were more women who survuived?\nWe shall se that further.**","e21f5da4":"**Lets play a little with Age as well**","97b03d01":"**AGE and CABIN have the higest number of Null Values,so they will not be of major help since most of the values are missing,especially CABIN.","895be3a0":"# Step 2.\u6574\u7406\u8cc7\u6599<BR>\nhttps:\/\/medium.com\/jameslearningnote\/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC2-4%E8%AC%9B-%E8%B3%87%E6%96%99%E5%89%8D%E8%99%95%E7%90%86-missing-data-one-hot-encoding-feature-scaling-3b70a7839b4a <br>\n    \n**Lets check for the number of Null Values in our DATA SET**","e460c0f8":"# **LOGISTIC REGRESSION**\n\u53c3\u8003\u4f86\u6e90 http:\/\/www.taroballz.com\/2018\/07\/18\/ML_LogisticRegression\/\n","696802db":"![](https:\/\/i.imgur.com\/XO0VDDL.png)\n# Step 1.\u700f\u89bd\u8cc7\u6599<BR>\n# Step 2.\u6574\u7406\u8cc7\u6599<BR>\n# Step 3.\u8a13\u7df4\u6a21\u578b<BR>\n# Step 4.\u9810\u6e2c\u7d50\u679c<BR>\n# Step 5.\u7522\u751f\u6a94\u6848    ","165a9aa8":"**Now we will do the same thing that we did with cabin so that we are left with the initials and can assign them numeric values accordingly.**","caa65fb1":"**Lets create a new column of fam using SibSp which means number of Siblings or Spouse and Parch which means number of Parents or Children,later we will be dropping SibSp and Parch from our data set since these values are alreday being used in Fam**","ce368418":"**Lets work out with the Cabin numbers**","d1241077":"# Soobi AI \u9ad8\u4e2d\u9ad4\u9a57\u71df\ud83d\udd38\u7b2c\u4e09\u5802\uff1a\u624b\u628a\u624b\u6559\u4f60\u505aAI\n\n\n## \u9019\u5802\u8ab2\u7a0b\u8981\u5e36\u8457\u5927\u5bb6\u5229\u7528\u6700\u57fa\u790e\u3001\u7c21\u55ae\u7684\u6a5f\u5668\u5b78\u7fd2\u77e5\u8b58\u8207\u6f14\u7b97\u6cd5\uff0c\u5b8c\u6210Kaggle\u4e0a\u9435\u9054\u5c3c\u865f\u751f\u5b58\u9810\u6e2c\u6bd4\u8cfd\uff0c\u9019\u6b21\u6559\u5b78\u70ba\u4e86\u8b93\u65b0\u624b\u80fd\u5920\u5feb\u901f\u4e0a\u624b\uff0c\u7701\u53bb\u4e86\u8a31\u591a\u8f03\u70ba\u8907\u96dc\u7684\u7d71\u8a08\u77e5\u8b58\u8207\u7406\u8ad6\u3002\n\n## \u8a3b\uff1a\u4ee5\u6b63\u5f0f\u6bd4\u8cfd\u4f86\u8aaa\u524d10%\u5c31\u53ef\u4ee5\u7372\u5f97\u4e00\u500b\u9285\u724c\u6210\u5c31\uff0c\u4e26\u53ef\u653e\u5728\u500b\u4eba\u7684\u5c65\u6b77\u4ee5\u53caLinkedin\u4e0a\uff0c\u5c0d\u65bc\u60f3\u8de8\u79d1\u7cfb\u8f49\u8077\u8cc7\u6599\u79d1\u5b78\u5bb6\u7684\u4eba\u4f86\u8aaa\u662f\u4e00\u500b\u5927\u5927\u52a0\u5206\u7684\u6210\u5c31\u3002\n![](https:\/\/miro.medium.com\/max\/1400\/1*IE87v8J_syODWQjyT6WB8Q.png)","211d6030":"**So no more missing values in our dataset**","c47a5d3a":"![](https:\/\/i.pinimg.com\/originals\/af\/bf\/af\/afbfafac1e700ed3ed9b4a4157a7fa98.jpg)\n","303fc307":"# Step 1.\u700f\u89bd\u8cc7\u6599","7f9f08d9":"**Making and Printing our predictions**","600350e9":"# \u4e0a\u50b3\u4f5c\u696d\uff0c\u770b\u770b\u81ea\u5df1\u7684\u6210\u7e3e\u5982\u4f55?\n# https:\/\/www.kaggle.com\/t\/fc5bcffb8a7f4734b1fb6f58b1883947","917f9af8":"**Lets play around with Name as well!**","ba02acf6":"![](https:\/\/i.imgur.com\/GwlR2n4.jpg)","862da73b":"# Step 3.\u8a13\u7df4\u6a21\u578b<BR>\n**Lets start predicting,we will be using Logistic Regression.Logistic Regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.**","3cfed766":"**Mapping values**","a6c5dd3c":"**Lets find out the Survival Rate and the percentage of Women and Men**","ec5d5b92":"# Step 4.\u9810\u6e2c\u7d50\u679c<BR>","8972ff7e":"![](http:\/\/www.asparkstarts.com\/wp-content\/uploads\/2015\/01\/start-button-300x240.jpg)","3c7a6824":"# **EXPLORING FEATURES**","38b46bd5":"**Adding a column for Survived which has to be predicted in the test data.**","e5f853f5":"**We will be searching for the initials of the cabin numbers like A,B,C,etc**","b7162320":"**Calculating median values of \"Age\" by using \"Pclass\" to fill up the missing values.**","f2df3d2e":"![image.png](attachment:image.png)\n","849fae02":"\u65b0\u589eTitle\u6b04\u4f4d","3ed04f31":"**First we are converting float to string for both the datasets namely test and train**","6b6ca38c":"**Now we are assigning values to the initials that we had found in the above step and replace them with integers by mapping them.\nSame step will be repeated for train and test data**","8e37f874":"**We should know the data we are working with.**\n* ID        \u4e58\u5ba2\u7de8\u865f\n* pclass    \u8259\u7b491st, 2nd, or 3rd\n* survived  Survived = 1;Died = 0\n* name      \u4e58\u5ba2\u59d3\u540d\n* sex       \u4e58\u5ba2\u6027\u5225\n* age       \u5e74\u9f61\n* sibsp     \u65c1\u7cfb\u89aa\u5c6c\u4eba\u6578\n* parch     \u76f4\u7cfb\u89aa\u5c6c\u4eba\u6578\n* ticket    \u8239\u7968\u7de8\u865f\n* fare      \u7968\u50f9\n* cabin     \u5ba2\u8259\u7de8\u865f\n* embarked  \u767b\u8239\u6e2f\u53e3;C = Cherbourg;Q = Queenstown;S = Southampton","10277e6c":"**Lets convert our categorical data to numeric form**","e34190db":"**train_test_split :Split arrays or matrices into random train and test subsets**\n\ntrain_test_split\u529f\u80fd\u662f\u5f9e\u6a23\u672c\u4e2d\u96a8\u6a5f\u7684\u6309\u6bd4\u4f8b\u9078\u53d6train_data\u548ctest_data\uff0c\u4f7f\u7528\u65b9\u5f0f\u70ba\uff1a\nX_train,X_test, y_train, y_test =cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)\n\n\u5f15\u6578\u89e3\u91cb\uff1a\ntrain_data\uff1a\u6240\u8981\u5283\u5206\u7684\u6a23\u672c\u7279\u5fb5\u96c6\ntrain_target\uff1a\u6240\u8981\u5283\u5206\u7684\u6a23\u672c\u7d50\u679c\ntest_size\uff1a\u6a23\u672c\u4f54\u6bd4\uff0c\u5982\u679c\u662f\u6574\u6578\u7684\u8a71\u5c31\u662f\u6a23\u672c\u7684\u6578\u91cf\nrandom_state\uff1a\u662f\u96a8\u6a5f\u6578\u7684\u7a2e\u5b50\u3002","9634ffae":"\u4f9d\u5e38\u8b58\u5224\u65b7\uff0c\u5927\u81bd\u5047\u8a2d\u7968\u865f\u8207\u8259\u865f\u8207\u5016\u5b58\u6a5f\u7387\u4e0d\u76f8\u95dc","7fd72e5d":"**Lets take help of confusion matrix to find out TP TN FP FN.A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n**\n","66b13731":"# Step 5.\u7522\u751f\u6a94\u6848<BR>\n**SUBMISSION FILE(choosing Gradient Boosting)**"}}