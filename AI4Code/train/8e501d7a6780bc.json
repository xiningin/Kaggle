{"cell_type":{"5f1dbdd7":"code","6557f998":"code","ac3292b3":"code","a8db4c2d":"code","8a614af2":"code","929c0268":"code","46f60605":"markdown","833857c4":"markdown","1f96f66c":"markdown","b2fe6849":"markdown"},"source":{"5f1dbdd7":"# I have previously split the data into K-folds. Also joined with users.csv.\n\nDATA_FOLDER = '\/kaggle\/input\/shopee-w8\/kfolds'\n!ls {DATA_FOLDER}","6557f998":"# Read test data\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n\ntest = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv'), parse_dates=['grass_date'])\ntest.head()","ac3292b3":"# Read train & validation data\n\nNFOLDS = 5\n\n\ntrains = []\nvalids = []\nfor fold_id in range(NFOLDS):\n    trains.append(pd.read_csv(os.path.join(DATA_FOLDER, str(fold_id), 'train.csv'), parse_dates=['grass_date']))\n    valids.append(pd.read_csv(os.path.join(DATA_FOLDER, str(fold_id), 'valid.csv'), parse_dates=['grass_date']))\n\n\ntrains[0].head()","a8db4c2d":"# Build features\n# Note: For CatBoost, we don't need to encode Categorical columns. CatBoost will automatically take care of it.\n\n\nCATEGORICAL_COLS = ['country_code', 'attr_1', 'attr_2', 'attr_3', 'domain']\nLAST_DAY_COLS = ['last_open_day', 'last_login_day', 'last_checkout_day']\nDROP_COLS = ['user_id', 'row_id', 'subject_line_length']\n\nX_trains = [None for i in range(NFOLDS)]\ny_trains = [None for i in range(NFOLDS)]\nX_valids = [None for i in range(NFOLDS)]\ny_valids = [None for i in range(NFOLDS)]\nX_tests = [None for i in range(NFOLDS)]\n\n\ndef convert_last(s):\n    if s in ['Never open', 'Never checkout', 'Never login', 'grass_day_of_week']:\n        return -1\n    return int(s)\n\n\ndef build_features(fold_id, dataset):\n    target = None\n    res = dataset.drop(columns=['user_id', 'row_id', 'subject_line_length'])\n    if 'open_flag' in dataset.columns:\n        target = res['open_flag']\n        res.drop(columns=['open_flag'], inplace=True)\n    \n    # Last day columns: convert to int\n    for col in LAST_DAY_COLS:\n        res[col] = res[col].apply(convert_last)\n    \n    # Grass date: convert to day of week\n    res['grass_day_of_week'] = res['grass_date'].apply(lambda x: x.weekday())\n    res.drop(columns=['grass_date'], inplace=True)\n\n    # Process columns with NA\n    for col in ['attr_1', 'attr_2', 'attr_3', 'age']:\n        res[col].fillna(-1, inplace=True)\n        res[col] = res[col].astype(int)\n\n    return res, target\n\n\nfor fold_id in range(NFOLDS):\n    print('Processing fold', fold_id)\n    X_trains[fold_id], y_trains[fold_id] = build_features(fold_id, trains[fold_id])\n    X_valids[fold_id], y_valids[fold_id] = build_features(fold_id, valids[fold_id])\n    X_tests[fold_id], _ = build_features(fold_id, test)\n\n\nX_trains[0].head()","8a614af2":"# CatBoost modeling\n\n\nimport optuna\nfrom sklearn.metrics import matthews_corrcoef\nfrom catboost import CatBoostClassifier\n\nparams = {\n    'eval_metric': 'MCC',\n    'cat_features': CATEGORICAL_COLS,\n    'verbose': 200,\n    'random_seed': 42,\n    'od_pval': 1e-2,\n    'use_best_model': True,\n}\n\ncats = []\nmcc_sum = 0.0\nfor i in range(NFOLDS):\n    class_weights = {0: 1.0, 1: 2}\n    clf = CatBoostClassifier(class_weights=class_weights, **params)\n\n    clf.fit(\n        X_trains[i], y_trains[i],\n        eval_set=(X_valids[i], y_valids[i]),\n        use_best_model=True,\n        plot=True,\n    )\n    mcc = matthews_corrcoef(y_valids[i], clf.predict(X_valids[i]))\n    cats.append(clf)\n    print(f'========== Results for fold {i} ==========')\n    print('MCC:', mcc)\n    mcc_sum += mcc\n\n\nprint('Avg MCC:', mcc_sum \/ NFOLDS)","929c0268":"def print_result(clfs, Xs):\n    probs = np.zeros(shape=(Xs[0].shape[0], 2))\n\n    for fold_id in range(len(clfs)):\n        probs += clfs[fold_id].predict_proba(Xs[fold_id]) \/ NFOLDS\n    preds = np.argmax(probs, axis=1)\n\n    submission = pd.DataFrame({\n        'row_id': test['row_id'],\n        'open_flag': preds,\n    })\n    submission.to_csv('submission.csv', index=False)\n\n\nprint_result(cats, X_tests)","46f60605":"# Prepare Data\n\nI have previously split the data into K-folds, and also joined with `users.csv`. The K-folds are used for 2 purposes:\n\n1. Get better validation result\n2. Build K models, and combine the results of these K models.","833857c4":"# Build features\n\nI did not do much feature engineering. I think the data is already quite clean. What I did was:\n\n1. Convert `last_X_day` columns to `int`, and also change all `Never` values to `-1`.\n2. Drop column `subject_line_length`. I think this feature will overfit your model: 2 subject with same length doesn't necessary have the same content.\n3. Change `grass_date` to day of week. Though I don't think this feature is necessary because it has very low correlation with `open_flag`.\n4. Fill other null values with `-1`.","1f96f66c":"# Modeling with CatBoost\n\nNotes:\n\n1. CatBoost handles categorical features, so we don't need to do any encoding.\n2. Set `class_weights` because the label is imbalance.","b2fe6849":"# Get Prediction Results\n\nFinally, we combine our K CatBoost to get the results. I simply get the average probability from 5 models and use it to predict."}}