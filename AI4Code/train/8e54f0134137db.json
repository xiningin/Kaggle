{"cell_type":{"cc856257":"code","4f4ee28e":"code","2e3d7106":"code","b258ace5":"code","880f698e":"code","9a0dc96c":"code","dafba992":"code","76e9ae84":"code","4e6e23d6":"code","38d7d5e4":"code","ca92744f":"markdown","a24e79c7":"markdown","6fc83732":"markdown","2cd31991":"markdown","22fb5c62":"markdown","0db0dead":"markdown","5c5149a3":"markdown","a917b007":"markdown","416c0444":"markdown"},"source":{"cc856257":"import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install music21\nfrom music21 import converter, instrument, note, chord\nnotes = []\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/classical-music-midi'):\n    print(filenames)\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        midi = converter.parse(file)\n        notes_to_parse = None\n        parts = instrument.partitionByInstrument(midi)\n        if parts: # file has instrument parts\n            notes_to_parse = parts.parts[0].recurse()\n        else: # file has notes in a flat structure\n            notes_to_parse = midi.flat.notes\n        for element in notes_to_parse:\n            if isinstance(element, note.Note):\n                notes.append(str(element.pitch))\n            elif isinstance(element, chord.Chord):\n                notes.append('.'.join(str(n) for n in element.normalOrder))\n\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f4ee28e":"import json\n\nf = open(\"Notes.txt\", \"w\")\nf.write(json.dumps(notes))\nf.close()\n","2e3d7106":"import json\nf = open(\"..\/input\/adi-bity-weights\/Notes.txt\", \"r\")\nnotes = json.loads(f.read())\nprint(len(notes))","b258ace5":"import numpy as np \nfrom keras.utils import np_utils\nsequence_length = 100\n# get all pitch names\npitchnames = sorted(set(item for item in notes))\nn_vocab = len(pitchnames)\n# create a dictionary to map pitches to integers\nnote_to_int = dict((note, number) for number, note in enumerate(pitchnames))\nnetwork_input = []\nnetwork_output = []\n# create input sequences and the corresponding outputs\nfor i in range(0, len(notes) - sequence_length, 1):\n    sequence_in = notes[i:i + sequence_length]\n    sequence_out = notes[i + sequence_length]\n    network_input.append([note_to_int[char] for char in sequence_in])\n    network_output.append(note_to_int[sequence_out])\nn_patterns = len(network_input)\n# reshape the input into a format compatible with LSTM layers\nnetwork_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n# normalize input\nnetwork_input = network_input \/ float(n_vocab)\nnetwork_output =  np_utils.to_categorical(network_output)","880f698e":"print(n_vocab)\n\nprint(network_input.shape[1])\nprint(network_input.shape[2])","9a0dc96c":"Build model","dafba992":"import tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.layers import BatchNormalization as BatchNorm\nfrom keras.layers import Activation\n\nfilepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \ncheckpoint = ModelCheckpoint(\n    filepath, monitor='loss', \n    verbose=0,        \n    save_best_only=True,        \n    mode='min'\n)    \ncallbacks_list = [checkpoint]     \n\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = Sequential()\n    model.add(LSTM(\n        256,\n        input_shape=(network_input.shape[1], network_input.shape[2]),\n        return_sequences=True\n    ))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512, return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(256))\n    model.add(Dense(256))\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n    \n# train model normally\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\nprint(BATCH_SIZE)\nmodel.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)","76e9ae84":"\nstart = numpy.random.randint(0, len(network_input)-1)\nint_to_note = dict((number, note) for number, note in enumerate(pitchnames))\npattern = network_input[start]\nprediction_output = []\n# generate 500 notes\nfor note_index in range(500):\n    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n    prediction_input = prediction_input \/ float(n_vocab)\n    prediction = model.predict(prediction_input, verbose=0)\n    index = numpy.argmax(prediction)\n    print(index)\n    if index < len(int_to_note):\n        result = int_to_note[index]\n        prediction_output.append(result)\n        pattern = numpy.append(pattern, index)\n\n        pattern = pattern[1:len(pattern)]\n    else:\n        result = int_to_note[numpy.random.randint(0, len(int_to_note)-1)]\n        prediction_output.append(result)\n        pattern = numpy.append(pattern, index)\n\n        pattern = pattern[1:len(pattern)]\n","4e6e23d6":"# !pip install music21\nfrom music21 import converter, instrument, note, chord\noffset = 0\noutput_notes = []\n# create note and chord objects based on the values generated by the model\nfor pattern in prediction_output:\n    # pattern is a chord\n    if ('.' in pattern) or pattern.isdigit():\n        notes_in_chord = pattern.split('.')\n        notes = []\n        for current_note in notes_in_chord:\n            new_note = note.Note(int(current_note))\n            new_note.storedInstrument = instrument.Piano()\n            notes.append(new_note)\n        new_chord = chord.Chord(notes)\n        new_chord.offset = offset\n        output_notes.append(new_chord)\n    # pattern is a note\n    else:\n        new_note = note.Note(pattern)\n        new_note.offset = offset\n        new_note.storedInstrument = instrument.Piano()\n        output_notes.append(new_note)\n    # increase offset each iteration so that notes do not stack\n    offset += 0.5","38d7d5e4":"from music21 import stream\n\nmidi_stream = stream.Stream(output_notes)\nmidi_stream.write('midi', fp='test_output-lower-weight.mid')","ca92744f":"Save as midi file","a24e79c7":"Run the model with checkpoints","6fc83732":"Open file","2cd31991":"Convert the notes to numbers and create the input and outputs","22fb5c62":"Create array of Note and Chord objects","0db0dead":"Prepare Model for creating music. Already trained","5c5149a3":"Create music","a917b007":"Save the notes to file","416c0444":"import tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.layers import BatchNormalization as BatchNorm\nfrom keras.layers import Activation\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = Sequential()\n    model.add(LSTM(\n        256,\n        input_shape=(network_input.shape[1], network_input.shape[2]),\n        return_sequences=True\n    ))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512, return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(256))\n    model.add(Dense(256))\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n   \n    # Load the weights to each node\nmodel.load_weights('..\/input\/adi-bity-weights\/weights-improvement-20-3.1510-bigger.hdf5')"}}