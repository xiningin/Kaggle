{"cell_type":{"3786cd45":"code","2db62fad":"code","3ebd338b":"code","ea134cc5":"code","4450c998":"code","46e01e0a":"code","2339a045":"code","9aef202f":"code","ed85a19b":"code","ac86e960":"code","4d352865":"code","8f3de03b":"code","c0f779a5":"code","556ba0a7":"code","c9d02493":"code","740068db":"code","a01085f0":"code","1642cb4d":"code","ee13beb9":"markdown","a49b6b33":"markdown","f4d3a622":"markdown","3e84e04f":"markdown","c30007e6":"markdown","57451b50":"markdown","d6493b51":"markdown","ebaebb19":"markdown","83f92ba8":"markdown","8c6ea691":"markdown","a06a781f":"markdown","2ccc0f05":"markdown","5b03f870":"markdown","8079e132":"markdown","6773af90":"markdown","44785b2f":"markdown","d0887e42":"markdown","98705c2f":"markdown"},"source":{"3786cd45":"# Import libraries \nimport pandas                as pd\nimport numpy                 as np \nimport matplotlib.pyplot     as plt\nimport sklearn               as sk\nimport seaborn               as sb\nimport os\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors       import KNeighborsClassifier\nfrom sklearn.metrics         import accuracy_score\nfrom sklearn.preprocessing   import StandardScaler\n\n# Import datasets and fill na values with \"?\"\ntrainData = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\", na_values=\"?\")\ntestData  = pd.read_csv(\"..\/input\/adult-pmr3508\/test_data.csv\", na_values=\"?\")","2db62fad":"print(trainData.shape)\ntrainData.describe()","3ebd338b":"trainData.head()","ea134cc5":"print(\"Missing data rows in train database is: \" + str( trainData.shape[0] - trainData.dropna().shape[0] ) + \" in a total of \" + str(trainData.shape[0]))\nprint(\"Missing data rows in test database is: \"  + str( testData.shape[0] - testData.dropna().shape[0] )   + \" in a total of \" + str(testData.shape[0]))","4450c998":"trainData.isna().sum()","46e01e0a":"trainDataWN = trainData\ntestDataWN  = testData\n\n### workclass\ntrainDataWN[\"workclass\"] = trainDataWN[\"workclass\"].fillna(trainDataWN[\"workclass\"].mode()[0])\ntestDataWN[\"workclass\"] = testDataWN[\"workclass\"].fillna(trainDataWN[\"workclass\"].mode()[0])\n### occupation\ntrainDataWN[\"occupation\"] = trainDataWN[\"occupation\"].fillna(trainDataWN[\"occupation\"].mode()[0])\ntestDataWN[\"occupation\"] = testDataWN[\"occupation\"].fillna(trainDataWN[\"occupation\"].mode()[0])\n### native country\ntrainDataWN[\"native.country\"] = trainDataWN[\"native.country\"].fillna(trainDataWN[\"native.country\"].mode())[0]\ntestDataWN[\"native.country\"] = testDataWN[\"native.country\"].fillna(trainDataWN[\"native.country\"].mode()[0])","2339a045":"trainDataWN.isna().sum()","9aef202f":"## TRAIN DATA\n\n#Education train\nle_Education = sk.preprocessing.LabelEncoder()\nle_Education.fit(trainDataWN[\"education\"])\neducationTrain = le_Education.transform(trainDataWN[\"education\"])\n\n#Workclass train\nle_Workclass = sk.preprocessing.LabelEncoder()\nle_Workclass.fit(trainDataWN[\"workclass\"])\nworkclassTrain = le_Workclass.transform(trainDataWN[\"workclass\"])\n\n#Age train\nageTrain = trainDataWN.age\n\n#Age train\nfnlwgtTrain = trainDataWN.fnlwgt\n\n#Income train\nle_Income = sk.preprocessing.LabelEncoder()\nle_Income.fit(trainDataWN[\"income\"])\nincomeTrain = le_Income.transform(trainDataWN[\"income\"])\n\n#Marital train\nle_Marital = sk.preprocessing.LabelEncoder()\nle_Marital.fit(trainDataWN[\"marital.status\"])\nmaritalTrain = le_Marital.transform(trainDataWN[\"marital.status\"])\n\n#Ocupation train\nle_Occupation = sk.preprocessing.LabelEncoder()\nle_Occupation.fit(trainDataWN[\"occupation\"])\noccupationTrain = le_Occupation.transform(trainDataWN[\"occupation\"])\n\n#Relationship train\nle_Relationship = sk.preprocessing.LabelEncoder()\nle_Relationship.fit(trainDataWN[\"relationship\"])\nrelationshipTrain = le_Relationship.transform(trainDataWN[\"relationship\"])\n\n#Race train\nle_Race = sk.preprocessing.LabelEncoder()\nle_Race.fit(trainDataWN[\"race\"])\nraceTrain = le_Race.transform(trainDataWN[\"race\"])\n\n#Sex train\nle_Sex = sk.preprocessing.LabelEncoder()\nle_Sex.fit(trainDataWN[\"sex\"])\nsexTrain = le_Sex.transform(trainDataWN[\"sex\"])\n\n#Country train\nle_Country = sk.preprocessing.LabelEncoder()\nle_Country.fit(trainDataWN[\"native.country\"])\ncountryTrain = le_Country.transform(trainDataWN[\"native.country\"])\n\n\n#Hours per week train\nhpwTrain = trainDataWN[\"hours.per.week\"]\n\n#Education num train\nedunumTrain = trainDataWN[\"education.num\"]\n\n#Capital gain\ncapgainTrain = trainDataWN[\"capital.gain\"]\n\n#Capital loss\ncaplossTrain = trainDataWN[\"capital.loss\"]\n\n###############\n## TEST DATA ##\n# Using: raceTrain, sexTrain\n\n#Education test\neducationTest = le_Education.transform(testDataWN[\"education\"])\n\n#Age test\nageTest = testDataWN[\"age\"]\n\n#Education num test\nedunumTest = testDataWN[\"education.num\"]\n\n#Hours per week train test\nhpwTest = testDataWN[\"hours.per.week\"]\n\n#Ocupation train\noccupationTest = le_Occupation.transform(testDataWN[\"occupation\"])\n\n#Capital gain\ncapgainTest = testDataWN[\"capital.gain\"]\n\n#Capital loss\ncaplossTest = testDataWN[\"capital.loss\"]\n\n#Race train\nraceTest = le_Race.transform(testDataWN[\"race\"])\n\n#Sex train\nsexTest = le_Sex.transform(testDataWN[\"sex\"])\n","ed85a19b":"### Age\nprint(\"Correlation of age: \" + str(np.corrcoef(ageTrain, incomeTrain)[0,1]))\n### Workclass\nprint(\"Correlation of workclass: \" + str(np.corrcoef(workclassTrain, incomeTrain)[0,1]))\n### FNLWGT\nprint(\"Correlation of fnlwgt: \" + str(np.corrcoef(fnlwgtTrain, incomeTrain)[0,1]))\n### Education\nprint(\"Correlation of education: \" + str(np.corrcoef(educationTrain, incomeTrain)[0,1]))\n### Education Num\nprint(\"Correlation of education num: \" + str(np.corrcoef(edunumTrain, incomeTrain)[0,1]))\n### Marital Status\nprint(\"Correlation of marital: \" + str(np.corrcoef(maritalTrain, incomeTrain)[0,1]))\n### Occupation\nprint(\"Correlation of occupation: \" + str(np.corrcoef(occupationTrain, incomeTrain)[0,1]))\n### Relationship\nprint(\"Correlation of relationship: \" + str(np.corrcoef(relationshipTrain, incomeTrain)[0,1]))\n### Race\nprint(\"Correlation of race: \" + str(np.corrcoef(raceTrain, incomeTrain)[0,1]))\n### Sex\nprint(\"Correlation of sex: \" + str(np.corrcoef(sexTrain, incomeTrain)[0,1]))\n### Capital gain\nprint(\"Correlation of capital gain: \" + str(np.corrcoef(capgainTrain, incomeTrain)[0,1]))\n### Capital loss\nprint(\"Correlation of capital loss: \" + str(np.corrcoef(caplossTrain, incomeTrain)[0,1]))\n### Hours per week\nprint(\"Correlation of hours per week: \" + str(np.corrcoef(hpwTrain, incomeTrain)[0,1]))\n","ac86e960":"trainDataWN[\"education\"].value_counts().plot(kind=\"bar\")","4d352865":"trainDataWN[\"age\"].value_counts().plot(kind=\"bar\", figsize=(18,6))","8f3de03b":"trainDataWN[\"workclass\"].value_counts().plot(kind=\"bar\")","c0f779a5":"plt.scatter(capgainTrain, range(trainDataWN.shape[0]))","556ba0a7":"## Criando frames\n# Train\nknn_frame_train = [educationTrain, ageTrain, edunumTrain, hpwTrain, occupationTrain, raceTrain, sexTrain, capgainTrain, caplossTrain]\n# knn_frame_train = [educationTrain, ageTrain]\nxKnnTrain = pd.DataFrame(np.transpose(knn_frame_train), dtype=object)\n\n# Test\nknn_frame_test = [educationTest, ageTest, edunumTest, hpwTest, occupationTest, raceTest, sexTest, capgainTest, caplossTest]\n# knn_frame_test = [educationTest, ageTest]\nxKnnTest = pd.DataFrame(np.transpose(knn_frame_test), dtype=object)","c9d02493":"higherNeighbour = 1\nhigherScore = 0\nfor i in [20, 25, 30, 35]:\n    knnTemporary = KNeighborsClassifier(n_neighbors=i)\n    knnTemporary.fit(xKnnTrain, incomeTrain)\n    score = cross_val_score(knnTemporary, xKnnTrain, incomeTrain, cv=15)\n    if higherScore < score.mean():\n        higherScore = score.mean()\n        higherNeighbour = i\nprint(\"The highest score was \" + str(higherScore) + \" with \" + str(higherNeighbour) + \" neighbours\")\n","740068db":"KNN = KNeighborsClassifier(n_neighbors=higherNeighbour)\nKNN.fit(xKnnTrain, incomeTrain)\nscore = cross_val_score(KNN, xKnnTrain, incomeTrain, cv=15)","a01085f0":"predict = KNN.predict(xKnnTest)","1642cb4d":"frame = {\"Id\": testDataWN.Id, \"income\": le_Income.inverse_transform(predict)}\nsolution = pd.DataFrame(frame)\nsolution.to_csv(\"submission.csv\", index = False)\nsolution.shape","ee13beb9":"Primeiramente vamos testar alguns poss\u00edveis valores para o n\u00famero de vizinhos para ver o que atinge a maior acur\u00e1cia","a49b6b33":"Como \u00e9 poss\u00edvel observar que tudo ocorreu bem, continuamos com os dados normalizados.","f4d3a622":"Agora \u00e9 so construir nosso .csv com os resultados!","3e84e04f":"Com essa an\u00e1lise de vari\u00e2ncia podemos ter uma \u00f3tima vis\u00e3o sobre como os dados est\u00e3o relacionados com o \"income\". E s\u00f3 com essa an\u00e1lise j\u00e1 podemos excluir algumas features como workclass, fnlwgt, marital e relationship, que obtiveram um coeficiente negativo. Al\u00e9m de pr\u00e9 selecionarmos features como age, education num, sex, capital loss e capital gain.","c30007e6":"## 2.2 Encode data\nAqui, usamos o LabelEncoder da biblioteca Sklearn para codificar os valores n\u00e3o num\u00e9ricos em num\u00e9ricos para facilitar e tornar poss\u00edvel o aprendizado de m\u00e1quina.","57451b50":"## 2.3.2 Ploting Data\n","d6493b51":"## 2.4 Organize Frames for Datasets\n\nAgora, depois de termos analizados os dados, podemos concluir que os que mais possuem influ\u00eancia sem enviezar o c\u00f3digo s\u00e3o as features education, education number, age, hours per week, occupation, race, sex, capital gain and capital loss.","ebaebb19":"## 1. Imports\nImporting libraries and datasets to be used in this notebook","83f92ba8":"Fazemos agora a predi\u00e7\u00e3o da nossa base de teste","8c6ea691":"## 2.1 Missing Data\nAgora, vamos tratar dos dados faltantes, primeiro, vamos ver quantas linhas com dados faltantes existem","a06a781f":"Checando para ver se ocorreu tudo certo","2ccc0f05":"Assim, notamos que existe um grande n\u00famero de dados faltantes, e podemos resolver isso substituindo cada um deles pela moda de sua coluna, poupando e evitando o desperd\u00edcio de dados.","5b03f870":"## 2.3 Data relationship\nAgora precisamos tratar das rela\u00e7\u00f5es entre todos os dados de nosso database para vermos quais ser\u00e3o \u00fateis para nossa an\u00e1lise\n\n## 2.3.1 Correlation\nUma boa forma de ver a rela\u00e7\u00e3o das features com o nosso dado buscado \u00e9 atrav\u00e9s da correla\u00e7\u00e3o, e podemos fazer ela atrav\u00e9s da biblioteca NumPy, assim, fazemos o c\u00e1lculo para todas as features do nosso dataset","8079e132":"Obter as 5 primeiras linhas para ver o r\u00f3tulo dos dados","6773af90":"Para termos uma maior no\u00e7\u00e3o vamos plotar nossos dados, sendo os num\u00e9ricos da forma scatter e os n\u00e3o num\u00e9ricos com gr\u00e1fico de barras","44785b2f":"## 3. KNN Learning","d0887e42":"## 2. Data preparation\nPrimeiro, vamos obter uma descri\u00e7\u00e3o do nosso dataset para ver se est\u00e1 tudo de acordo","98705c2f":"Agora, tendo definido um n\u00famero bom de vizinhos criamos nosso classificador e fazemos o fit com nossa base de dados"}}