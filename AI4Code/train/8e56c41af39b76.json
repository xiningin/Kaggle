{"cell_type":{"1395f48b":"code","c7c988de":"code","2004d0db":"code","d89b3957":"code","6bc1c610":"code","ea9e494f":"code","f1bfebcf":"code","1cc6ca21":"code","c0c9bbc2":"code","0c07666e":"code","e844a818":"code","7741dc2a":"code","5a620c49":"code","12033b73":"code","b090a91f":"markdown","7f25ffb8":"markdown"},"source":{"1395f48b":"%matplotlib notebook\n\n# essntial\nimport numpy as np\nimport pandas as pd\n\n# plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# split to train and test datasets\nfrom sklearn.model_selection import train_test_split\n\n# to make pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# feature preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# metrics\nfrom sklearn.metrics import mean_squared_error \n\n# models\nfrom sklearn.dummy import DummyRegressor\nfrom xgboost import XGBRegressor\n\n# models optimization\nfrom sklearn.model_selection import GridSearchCV","c7c988de":"# read the train and test data\ntrain = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\n\n# drop unnecessary id column\ndf_train = train.drop([\"Id\"], axis = 1)\ndf_test = test.drop([\"Id\"], axis = 1)","2004d0db":"# split train into features (X) and label (y)\ny = np.log1p(df_train[\"SalePrice\"]) # log(1+x)\nX = df_train.drop([\"SalePrice\"], axis = 1)","d89b3957":"# read the types of the features and split into categorical and numerical\ndtps = X.dtypes \ncategorical = dtps[dtps == 'object'].index\nnumerical = dtps[(dtps == 'float64')|(dtps == 'int64')].index","6bc1c610":"# do splitting of the dataset to train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)","ea9e494f":"# Preprocessing for numerical data\nnumerical_transformer = Pipeline(steps=[\n    ('num_imputer', IterativeImputer(max_iter=40)),\n    ('scaler', MinMaxScaler()),\n])\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n]) \n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical),\n        ('cat', categorical_transformer, categorical)\n    ])","f1bfebcf":"# create dummy regressor to establish baseline\ndummy = DummyRegressor(strategy = \"mean\")\ndummy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', dummy)\n                             ])\n# train it\ndummy_pipeline.fit(X_train, y_train) ","1cc6ca21":"# make predictions with dummy regressor\ny_predict_train = dummy.predict(X_train)\nscore_train = mean_squared_error(np.log(y_train),np.log(y_predict_train), squared = False)\n    \ny_predict_test = dummy.predict(X_test)\nscore_test = mean_squared_error(np.log(y_test),np.log(y_predict_test), squared = False)\n\nprint(\"Train score with dummy: {:.4f}\".format(score_train))\nprint(\"Train scores with dummy: {:.4f}\".format(score_test))","c0c9bbc2":"# set model and model pipeline\nmodel = XGBRegressor(random_state = 0)\nmodel_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                                 ('model', model)\n                                ])","0c07666e":"# set parameters for the optimization using GridSearch\nparameters = {}\nparameters['model__n_estimators'] = [500, 1000, 2000]\nparameters['model__max_depth'] = [3, 4, 5]\nparameters['model__learning_rate'] = [0.01, 0.1, 0.05]\n\ngrid = GridSearchCV(model_pipeline, parameters, scoring = 'neg_mean_absolute_error', n_jobs= -1)\ngrid.fit(X_train, y_train)  # train model ","e844a818":"# get best parameters found with the GridSearch\ngrid.best_params_","7741dc2a":"y_predict_train = grid.predict(X_train)\nscore_train = mean_squared_error(np.log(y_train),np.log(y_predict_train), squared = False)\n    \ny_predict_test = grid.predict(X_test)\nscore_test = mean_squared_error(np.log(y_test),np.log(y_predict_test), squared = False)\n\nprint(\"Train score with Model: {:.4f}\".format(score_train))\nprint(\"Test scores with Model: {:.4f}\".format(score_test))","5a620c49":"# explicitly use these parameters to set your final model\nmodel = XGBRegressor(n_estimators = 500, max_depth =3,reg_lambda = 3,random_state = 0, learning_rate= 0.05)\nmodel_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\nmodel_pipeline.fit(X, y) # train the model","12033b73":"# do predictions\nsub = pd.read_csv(\"..\/input\/home-data-for-ml-course\/sample_submission.csv\")\nsub.iloc[:, 1] = np.expm1(model_pipeline.predict(df_test)) # inverse of log1p\n\n# create submission.csv file with your predictions\nsub.to_csv(\"submission.csv\", index=False)","b090a91f":"<span style='color:#000; font-size:40px; font-family:PT Sans'>XGBRegressor with pipeline and GridSearch<\/span>\n\n<span style='color:#000; font-size:30px; font-family:PT Sans; line-height: 1.5'>In this notebook I try to present \"basic\" aspects of:<\/span>\n\n<span style='color:#000; font-size:20px; font-family:PT Sans; line-height: 1.5'>1. Making basic pipeline for both numerical and categorical features<\/span>\n\n<span style='color:#000; font-size:20px; font-family:PT Sans; line-height: 1.5'>2. Setting dummy regressor as a baseline model<\/span>\n\n<span style='color:#000; font-size:20px; font-family:PT Sans; line-height: 1.5'>3. Preparing a simple XGBRegressor model that includes pipeline and optimization using GridSearch over parameters<\/span>\n\n<span style='color:#000; font-size:30px; font-family:PT Sans; line-height: 1.5'>I really hope that this notebook will be of help and can shed some light<\/span>","7f25ffb8":"<span style='color:#000; font-size:30px; font-family:PT Sans; line-height: 1.5'>I really hope you have enjoyed it. Good Luck!<\/span>"}}