{"cell_type":{"45fc5384":"code","469974e5":"code","17e7216d":"code","f524e1d4":"code","e81fe0bf":"code","e2e3f6e1":"code","f771fac5":"code","903b8941":"code","1f081a4d":"code","6c8c406f":"code","12fa1cd1":"code","75cd94d7":"code","93140973":"code","c1e20c23":"markdown","295fcc72":"markdown","15ec8df6":"markdown","513d958d":"markdown","1b06d111":"markdown","5b1213ab":"markdown","89793845":"markdown","4bd96b69":"markdown","b51ae5a4":"markdown","dd6cf38c":"markdown","8533e4cb":"markdown"},"source":{"45fc5384":"import librosa\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","469974e5":"y, sr = librosa.load(\"\/kaggle\/input\/birdsong-recognition\/train_audio\/purfin\/XC195200.mp3\", offset=30, duration=5)\nprint(librosa.feature.mfcc(y=y, sr=sr))","17e7216d":"plt.figure(figsize=(20, 4))\nplt.plot(librosa.feature.mfcc(y=y, sr=sr))\nplt.grid()\nplt.title('Mel-frequency cepstral coefficients')\nplt.xlabel('time')\nplt.ylabel('mfcc coefficients')\nplt.show()","f524e1d4":"y, sr = librosa.load(\"\/kaggle\/input\/birdsong-recognition\/train_audio\/purfin\/XC195200.mp3\")\nprint(librosa.feature.zero_crossing_rate(y))","e81fe0bf":"plt.figure(figsize=(20, 4))\nplt.plot(librosa.feature.zero_crossing_rate(y).squeeze())\nplt.grid()\nplt.title('Zero crossing rate')\nplt.xlabel('time')\nplt.ylabel('the fraction of zero crossings in the i th frame')\nplt.show()","e2e3f6e1":"S, phase = librosa.magphase(librosa.stft(y))\nprint(librosa.feature.spectral_rolloff(S=S, sr=sr))","f771fac5":"plt.figure(figsize=(20, 4))\nplt.plot(librosa.feature.spectral_rolloff(S=S, sr=sr).squeeze())\nplt.grid()\nplt.title('Roll off frequency')\nplt.xlabel('time')\nplt.ylabel('Hz')\nplt.show()","903b8941":"import librosa\ny, sr = librosa.load(\"\/kaggle\/input\/birdsong-recognition\/train_audio\/purfin\/XC195200.mp3\", duration=10.0)\nonset_env = librosa.onset.onset_strength(y=y, sr=sr)\nprint(onset_env)","1f081a4d":"plt.figure(figsize=(20, 4))\nplt.plot(onset_env)\nplt.grid()\nplt.title('Spectral flux')\nplt.xlabel('time')\nplt.ylabel('Onset')\nplt.show()","6c8c406f":"y, sr = librosa.load(\"\/kaggle\/input\/birdsong-recognition\/train_audio\/purfin\/XC195200.mp3\")\nprint(librosa.feature.chroma_stft(y=y, sr=sr))","12fa1cd1":"plt.figure(figsize=(20, 4))\nplt.plot(librosa.feature.chroma_stft(y=y, sr=sr).squeeze())\nplt.grid()\nplt.title('Chroma feature')\nplt.xlabel('time')\nplt.ylabel('energy for each chroma bin at each frame')\nplt.show()","75cd94d7":"y, sr = librosa.load(\"\/kaggle\/input\/birdsong-recognition\/train_audio\/purfin\/XC195200.mp3\")\npitches, magnitudes = librosa.piptrack(y=y, sr=sr)\nprint(pitches)","93140973":"plt.figure(figsize=(20, 4))\nplt.plot(pitches.squeeze())\nplt.grid()\nplt.title('Pitch')\nplt.show()","c1e20c23":"Directly or indirectly, you are always in contact with audio. Your brain is continuously processing and understanding audio data and giving you information about the environment. A simple example can be your conversations with people which you do daily. This speech is discerned by the other person to carry on the discussions. Even when you think you are in a quiet environment, you tend to catch much more subtle sounds, like the rustling of leaves or the splatter of rain. This is the extent of your connection with audio.","295fcc72":"<a id='pitch'><\/a>\n## Pitch\n\nPitch is a perceptual property of sounds that allows their ordering on a frequency-related scale, or more commonly, pitch is the quality that makes it possible to judge sounds as \"higher\" and \"lower\" in the sense associated with musical melodies. Pitch can be determined only in sounds that have a frequency that is clear and stable enough to distinguish from noise. Pitch is a major auditory attribute of musical tones, along with duration, loudness, and timbre.\n\n[reference](https:\/\/en.wikipedia.org\/wiki\/Pitch_(music))","15ec8df6":"<a id='mfcc'><\/a>\n## MFCC (Mel-Frequency Cepstral Coefficients)\n\nIn sound processing, the mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. MFCC is that one feature you would see being used in any machine learning experiment involving audio files. \n\nMFCCs are commonly derived as follows:\n\n- Take the Fourier transform of (a windowed excerpt of) a signal.\n- Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows.\n- Take the logs of the powers at each of the mel frequencies.\n- Take the discrete cosine transform of the list of mel log powers, as if it were a signal.\n- The MFCCs are the amplitudes of the resulting spectrum.\n\nGenerally the first 13 coefficients(the lower dimensions) of MFCC are taken as features as they represent the envelope of spectra. \n\n[reference](https:\/\/en.wikipedia.org\/wiki\/Mel-frequency_cepstrum)","513d958d":"<a id='cf'><\/a>\n## Chroma feature\n\nIn music, the term chroma feature or chromagram closely relates to the twelve different pitch classes. Chroma-based features, which are also referred to as \"pitch class profiles\", are a powerful tool for analyzing music whose pitches can be meaningfully categorized (often into twelve categories) and whose tuning approximates to the equal-tempered scale. One main property of chroma features is that they capture harmonic and melodic characteristics of music, while being robust to changes in timbre and instrumentation.\n\n[refernece](https:\/\/en.wikipedia.org\/wiki\/Chroma_feature)","1b06d111":"![image.png](attachment:image.png)","5b1213ab":"I am trying to share some knowledge that I acquired while researching for this competition. Librosa is a really powerful python library that can be used for retreving lot of meaningful information from audio files. I am showing few for those here. Hope you find it helpful.","89793845":"<a id='sf'><\/a>\n## Spectral flux\n\nSpectral flux is a measure of how quickly the power spectrum of a signal is changing, calculated by comparing the power spectrum for one frame against the power spectrum from the previous frame. ","4bd96b69":"<a id='sro'><\/a>\n## Spectral-roll off\n\nIt is a measure of the amount of the right-skewedness of the power spectrum.The spectral roll off point is the fraction of bins in the power spectrum at which 85% of the power is at lower frequencies. That is, the roll-off is the frequency below which 85% of accumulated spectral magnitude is concentrated. Like the centroid, it takes on higher values for right-skewed spectra.\n\n[reference](https:\/\/towardsdatascience.com\/how-i-understood-what-features-to-consider-while-training-audio-files-eedfb6e9002b)","b51ae5a4":"<a id='conclusion'><\/a>\n## Conclusion\n\n- We have seen a small set of useful features that can be retrived using the librosa library. \n- There are a lot of features like this that can come in handy when doing audio analysis.\n- Go on an experiment with these features\n\n<h2 style=\"background-color:powderblue;\">If you find this work useful please consider upvoting. It will motivate me to make more kernels like this.<\/h2>","dd6cf38c":"## Table of contents\n- [Mel-Frequency Cepstral Coefficients](#mfcc)\n- [Zero crossing rate](#zcr)\n- [Spectral-roll off](#sro)\n- [Spectral flux](#sr)\n- [Chroma feature](#cf)\n- [Pitch](#pitch)\n- [Conclusion](#conclusion)\n","8533e4cb":"<a id='zcr'><\/a>\n## Zero crossing rate\n\nThe zero-crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to zero to negative or from negative to zero to positive. This feature has been used heavily in both speech recognition and music information retrieval, being a key feature to classify percussive sounds.\n\n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/cda9c9054c26350f517732f08eb791d232b7c1ba)\n\n[reference](https:\/\/en.wikipedia.org\/wiki\/Zero-crossing_rate)"}}