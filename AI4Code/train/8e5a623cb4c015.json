{"cell_type":{"f9a23ece":"code","e204ff2d":"code","74e65e08":"code","35b257e4":"code","66760bc0":"code","72e549ff":"code","3f6d2574":"code","13710577":"code","9587878c":"code","5d9cd71e":"code","77d136d2":"code","70893f97":"code","2da094b4":"code","622d5c3c":"code","66ecf3a9":"code","10b33dfc":"code","a74d20aa":"code","ce8a1c61":"code","d676747e":"code","35e0a410":"code","2fddb866":"code","71b01a8c":"code","8a20dd7f":"code","f99c468d":"code","7d82d8cd":"code","93aad3dc":"code","a5d41ad6":"markdown","77a62a58":"markdown","2e3eae93":"markdown","7f21625c":"markdown","563b7c8f":"markdown","be0bb7b9":"markdown","54d85b9c":"markdown","3d62c533":"markdown","a413c3da":"markdown","d74219f7":"markdown"},"source":{"f9a23ece":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e204ff2d":"data = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()  # head shows first 5 rows","74e65e08":"# tail shows last 5 rows\ndata.tail()","35b257e4":"# columns gives column names of features\ndata.columns","66760bc0":"# shape gives number of rows and columns in a tuble\ndata.shape","72e549ff":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","3f6d2574":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","13710577":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","9587878c":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","5d9cd71e":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","77d136d2":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","70893f97":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","2da094b4":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","622d5c3c":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in row\nconc_data_col","66ecf3a9":"data.dtypes","10b33dfc":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","a74d20aa":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","ce8a1c61":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","d676747e":"# Lets chech Type 2\n# dropna = True : We drop non values\n# We want to see nan values  \ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","35e0a410":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","2fddb866":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","71b01a8c":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","8a20dd7f":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values\n#  In 33, we dropped nan values and we are asking \"Are there nan values?\" here.","f99c468d":"data[\"Type 2\"].fillna('empty',inplace = True) \n# if there are nan value, we are filling with \"empty\"","7d82d8cd":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","93aad3dc":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'","a5d41ad6":"**DIAGNOSE DATA for CLEANING**\n\nWe need to diagnose and clean data before exploring. \nUnclean data:\n\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data","77a62a58":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","2e3eae93":"**Data Science Tutorial For Everyone #3**\n\n**Cleaning Data:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert\n","7f21625c":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical. \nWe can make conversion data types like from str to categorical or from int to float \nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklear(we will learn later)\n","563b7c8f":"**In this part, you learn:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert\n","be0bb7b9":"**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean \n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program","54d85b9c":"**EXPLORATORY DATA ANALYSIS**\n\nvalue_counts(): Frequency counts \noutliers: the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\nWhat is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","3d62c533":"**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.","a413c3da":"**CONCATENATING DATA**\n\nWe can concatenate two dataframe","d74219f7":"**PIVOTING DATA**\n\nReverse of melting."}}