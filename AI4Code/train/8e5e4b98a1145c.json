{"cell_type":{"9c50afb8":"code","220215e6":"code","4fb606ff":"code","ae886662":"code","35f7a1a2":"code","6b3b288a":"code","61045f41":"code","ef08e3e1":"code","a32d037e":"code","b5a0b724":"code","9479e102":"code","0965aa12":"code","664c6493":"code","6ad2f0db":"code","98e83a93":"code","cfd15351":"code","00876192":"code","75d46c19":"code","5394e93a":"code","2d9f7867":"code","dfe9570a":"code","701a9fd2":"code","19a05281":"code","82e3588b":"code","72346eed":"code","adec6044":"code","e051bc19":"code","bde65514":"code","fa3a2d32":"code","9b6914bf":"code","92af22f8":"code","9378f124":"code","ddb45789":"code","1fac3588":"code","8e03a448":"code","df0c5aa0":"code","05973471":"code","1e893943":"code","e2ee3dd7":"code","479c0a6c":"code","183c9e91":"code","de77c35b":"code","5baaed45":"markdown","86819e97":"markdown","6b52a51d":"markdown","b07a36ca":"markdown","2b0a42b8":"markdown","2bf8244d":"markdown","e4f1ab39":"markdown","a7b498cd":"markdown","275b3fd5":"markdown","6b3506a7":"markdown","e608cca8":"markdown","c2265068":"markdown","7d0ebcf6":"markdown","18ef3346":"markdown","a042a43c":"markdown","e140c5aa":"markdown","0b841ec1":"markdown","2ba2ea52":"markdown","096887aa":"markdown","2b099294":"markdown","a495f986":"markdown","dbac46c8":"markdown","7ba48446":"markdown","3a2cc049":"markdown","59e3ba2f":"markdown","c34a4603":"markdown","84c868c9":"markdown","ac2b3a07":"markdown"},"source":{"9c50afb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport collections\nimport re\nimport copy\n\n#from pandas.tools.plotting import scatter_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\n\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier, plot_importance\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.model_selection import GridSearchCV\n\npd.set_option('display.max_columns', 500)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","220215e6":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4fb606ff":"train.info()","ae886662":"train.head(5)","35f7a1a2":"train.describe()","6b3b288a":"train.describe(include=['O'])","61045f41":"## exctract cabin letter\ndef extract_cabin(x):\n    return x!=x and 'other' or x[0]\ntrain['Cabin_l'] = train['Cabin'].apply(extract_cabin)\ntrain.head(5)","ef08e3e1":"plain_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Cabin_l']\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\nstart = 0\nfor j in range(2):\n    for i in range(3):\n        if start == len(plain_features):\n            break\n        sns.barplot(x=plain_features[start],\n                    y='Survived', data=train, ax=ax[j, i])\n        start += 1","a32d037e":"sv_lab = 'survived'\nnsv_lab = 'not survived'\nfig, ax = plt.subplots(figsize=(5, 3))\nax = sns.distplot(train[train['Survived'] == 1].Age.dropna(),\n                  bins=20, label=sv_lab, ax=ax)\nax = sns.distplot(train[train['Survived'] == 0].Age.dropna(),\n                  bins=20, label=nsv_lab, ax=ax)\nax.legend()\nax.set_ylabel('KDE');\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\nfemales = train[train['Sex'] == 'female']\nmales = train[train['Sex'] == 'male']\n\nax = sns.distplot(females[females['Survived'] == 1].Age.dropna(\n), bins=30, label=sv_lab, ax=axes[0], kde=False)\nax = sns.distplot(females[females['Survived'] == 0].Age.dropna(\n), bins=30, label=nsv_lab, ax=axes[0], kde=False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(males[males['Survived'] == 1].Age.dropna(),\n                  bins=30, label=sv_lab, ax=axes[1], kde=False)\nax = sns.distplot(males[males['Survived'] == 0].Age.dropna(),\n                  bins=30, label=nsv_lab, ax=axes[1], kde=False)\nax.legend()\nax.set_title('Male');","b5a0b724":"sns.catplot('Pclass', 'Survived', hue='Sex', col = 'Embarked', data=train, kind='point');\nsns.catplot('Pclass', 'Survived', col = 'Embarked', data=train, kind='point');\n","9479e102":"ax = sns.boxplot(x=\"Pclass\", y=\"Fare\", hue=\"Survived\", data=train)\nax.set_yscale('log')","0965aa12":"sns.violinplot(x='Pclass', y='Age', hue='Survived', data=train, split=True);","664c6493":"# To get the full family size of a person, added siblings and parch.\ntrain['family_size'] = train['SibSp'] + train['Parch'] + 1\ntest['family_size'] = test['SibSp'] + test['Parch'] + 1\naxes = sns.catplot('family_size',\n                   'Survived',\n                   hue='Sex',\n                   data=train,\n                   aspect=4,\n                   kind='point')","6ad2f0db":"train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint(collections.Counter(train['Title']).most_common())\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint()\nprint(collections.Counter(test['Title']).most_common())","98e83a93":"tab = pd.crosstab(train['Title'],train['Pclass'])\nprint(tab)\ntab_prop = tab.div(tab.sum(1).astype(float), axis=0)\ntab_prop.plot(kind=\"bar\", stacked=True)","cfd15351":"sns.catplot('Title', 'Survived', data=train, aspect=3, kind='point');","00876192":"train['Title'].replace(['Master', 'Major', 'Capt', 'Col','Don', 'Sir', 'Jonkheer', 'Dr'], 'titled', inplace=True)\n#train['Title'].replace(['Countess','Dona','Lady'], 'titled_women', inplace = True)\n#train['Title'].replace(['Master','Major', 'Capt', 'Col','Don', 'Sir', 'Jonkheer', 'Dr'], 'titled_man', inplace = True)\ntrain['Title'].replace(['Countess', 'Dona', 'Lady'], 'Mrs', inplace=True)\n#train['Title'].replace(['Master'], 'Mr', inplace = 'True')\ntrain['Title'].replace(['Mme'], 'Mrs', inplace=True)\ntrain['Title'].replace(['Mlle', 'Ms'], 'Miss', inplace=True)","75d46c19":"sns.catplot('Title', 'Survived', data=train, aspect=3, kind='point');","5394e93a":"def extract_cabin(x):\n    return x != x and 'other' or x[0]\n\n\ntrain['Cabin_l'] = train['Cabin'].apply(extract_cabin)\nprint(train.groupby('Cabin_l').size())\nsns.catplot('Cabin_l', 'Survived',\n            order=['other', 'A', 'B', 'C', 'D', 'E', 'F', 'T'],\n            aspect=3,\n            data=train,\n            kind='point')","2d9f7867":"plt.figure(figsize=(8, 8))\ncorrmap = sns.heatmap(train.drop('PassengerId',axis=1).corr(), square=True, annot=True)","dfe9570a":"train.shape[0] - train.dropna().shape[0]","701a9fd2":"train.isnull().sum()","19a05281":"max_emb = np.argmax(train['Embarked'].value_counts())\ntrain['Embarked'].fillna(max_emb, inplace=True)","82e3588b":"ages = train['Age'].dropna()\nstd_ages = ages.std()\nmean_ages = ages.mean()\ntrain_nas = np.isnan(train[\"Age\"])\ntest_nas = np.isnan(test[\"Age\"])\nnp.random.seed(122)\nimpute_age_train  = np.random.randint(mean_ages - std_ages, mean_ages + std_ages, size = train_nas.sum())\nimpute_age_test  = np.random.randint(mean_ages - std_ages, mean_ages + std_ages, size = test_nas.sum())\ntrain[\"Age\"][train_nas] = impute_age_train\ntest[\"Age\"][test_nas] = impute_age_test\nages_imputed = np.concatenate((test[\"Age\"],train[\"Age\"]), axis = 0)","72346eed":"train['Age*Class'] = train['Age']*train['Pclass']\ntest['Age*Class'] = test['Age']*test['Pclass']","adec6044":"sns.kdeplot(ages_imputed, label = 'After imputation');\nsns.kdeplot(ages, label = 'Before imputation');","e051bc19":"train_label = train['Survived']\ntest_pasId = test['PassengerId']\ndrop_cols = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'PassengerId']\ntrain.drop(drop_cols + ['Cabin_l'], 1, inplace=True)\ntest.drop(drop_cols, 1, inplace=True)","bde65514":"train['Pclass'] = train['Pclass'].apply(str)\ntest['Pclass'] = test['Pclass'].apply(str)","fa3a2d32":"#train.drop(['Survived'], 1, inplace=True)\ntrain_objs_num = len(train)\ndataset = pd.concat(objs=[train, test], axis=0)\ndataset = pd.get_dummies(dataset)\ntrain = copy.copy(dataset[:train_objs_num])\ntest = copy.copy(dataset[train_objs_num:])","9b6914bf":"test.head(5)","92af22f8":"droppings = ['Embarked_Q','Age']\n#droppings += ['Sex_male', 'Sex_female']\n\ntest.drop(droppings, 1, inplace=True)\ntrain.drop(droppings, 1, inplace=True)","9378f124":"train.head(5)","ddb45789":"test.head(5)","1fac3588":"#train.to_csv('train1.csv',index=False)","8e03a448":"#test.to_csv('test1.csv',index=False)","df0c5aa0":"def prediction(model, train, label, test, test_pasId):\n    model.fit(train, label)\n    pred = model.predict(test)\n    accuracy = cross_val_score(model, train, label, cv=5)\n\n    sub = pd.DataFrame({\n        \"PassengerId\": test_pasId,\n        \"Survived\": pred\n    })\n    return [accuracy, sub]","05973471":"xgb = XGBClassifier(n_estimators=200)\nacc_xgb, sub = prediction(xgb, train, train_label, test, test_pasId)\nprint(acc_xgb)\nplot_importance(xgb)","1e893943":"train.head(10)","e2ee3dd7":"from sklearn.naive_bayes import GaussianNB","479c0a6c":"classifier = GaussianNB()","183c9e91":"classifier.fit(train, train_label)","de77c35b":"print('Probability of each class')\nprint('Survive = 0: %.2f' % classifier.class_prior_[0])\nprint('Survive = 1: %.2f' % classifier.class_prior_[1])","5baaed45":"**Correlation of various attributes**","86819e97":"We solve the Embarkment missing data with replacing nan with the max Embarkment","6b52a51d":"Also from this we can say that the 'cabin' and 'Embarked' is also missing some dataset","b07a36ca":"**Visual Analysis**","2b0a42b8":"**2. Gender,Age vs Survival**","2bf8244d":"* Pclass is slightly correlated with Fare as logically, 3rd class ticket would cost less than the 1st class.\n* Pclass is also slightly correlated with Survived\n* SibSp and Parch are weakly correlated as basically they show how big the family size is.","e4f1ab39":"**Missing Data**","a7b498cd":"If we drop all missing data we will have 708 data rows left out of 891","275b3fd5":"Lady, Mme, Sir,Countess, Mlle, Ms have very probability of survival\n\nDon, Rev, Capt, Jonkheer have very low survival rate","6b3506a7":"**Importing modules**","e608cca8":"Since 'Age' and 'PClass' are correlated we combine them","c2265068":"We drop the columns 'Name', 'Ticket' because of the unique nature of the data\n\nWe drop 'SibSp' and 'Parch' because we are already using 'Family Size'\n\nWe drop 'Cabin' because a number of value is missing and is also very unique in nature","7d0ebcf6":"So we see that after using our strategy for treating the 'Age' missing value the probability almost remain the same","18ef3346":"**Checking titles of the passengers**","a042a43c":"Female age vs survival shows no such pattern\n\nIn male the children(0-5) and older(70-80) survived","e140c5aa":"**Importing Datasets**","0b841ec1":"We solve missing value of age with the help of mean and standard deviation. We count the mean and standard deviation and then we choose randomly value between (mean-s.d.,mean+s.d.)","2ba2ea52":"If the family size is less than 4 the survival rate is high","096887aa":"**6. Family size vs Survival**","2b099294":"The average age is 29.7 years and the average fair is 32. The number 891 in the 'count' gives the number of row counts. But age have only 714 so clearly it is missing some values.","a495f986":"**Treating categorical values**","dbac46c8":"**5. PClass vs Survived**","7ba48446":"1. Survival chances over categorical data","3a2cc049":"**4. Fare vs Survival**","59e3ba2f":"Considering 6 features ('Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Cabin_l') we can conclude the following:-\n\n1. In PClass 1,2 have high probability of survival over 3\n2. In Gender, Females have high probability of survival over males\n3. In SibSp(# of Siblings) >= 3, the probability of survival reduces significantly\n4. Parch(# of Parents) is not very distinct\n5. In Embarked C the probability of survival is high\n6. Cabin_l is insignificant","c34a4603":"Total rows = 891\n\nTotal columns = 12\n\nNumber of features = 11\n\nPassengerIdUnique ID of the passenger\n\nSurvivedSurvived (1) or died (0)\n\nPclassPassenger's class (1st, 2nd, or 3rd)\n\nNamePassenger's name\n\nSexPassenger's sex\n\nAgePassenger's age\n\nSibSpNumber of siblings\/spouses aboard the Titanic\n\nParchNumber of parents\/children aboard the Titanic\n\nTicketTicket number\n\nFareFare paid for ticket\n\nCabinCabin number\n\nEmbarkedWhere the passenger got on the ship (C - Cherbourg, S - Southampton, Q = Queenstown)","84c868c9":"**3. Gender, Embarked, PClass vs Survival**","ac2b3a07":"**Basic informations**"}}