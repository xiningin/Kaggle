{"cell_type":{"bacebdc9":"code","9135aef1":"code","910ab673":"code","b768e5ea":"code","f3cf33f0":"code","5a82c9c3":"code","d8bf0ec4":"code","a7e917dc":"code","28a4c948":"code","d79860fd":"code","7815667a":"code","d8a034aa":"code","b422ac79":"code","ea688a5d":"code","de2c8121":"code","5a7203a7":"code","5b0bf09c":"code","75bd3fca":"code","e2fb8892":"code","37286dac":"code","926f6202":"code","48df85e7":"code","a60cbce5":"code","6d9490a3":"code","28062052":"code","12185e47":"code","b9f4391b":"code","ab6bc529":"code","ecf666d3":"code","73ae1bf7":"code","b5a1b191":"code","71d1208e":"code","b4110672":"code","c8df5556":"code","c7c21633":"markdown","41a022a1":"markdown","70c11060":"markdown","860d7606":"markdown","cc0cf3a8":"markdown","7895e888":"markdown","3c8bb7fc":"markdown","4e775af8":"markdown","6433b9cc":"markdown","175ca5ec":"markdown","1e1f4877":"markdown"},"source":{"bacebdc9":"import os\nimport pandas as pd\nimport numpy as np\nimport json\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport cv2","9135aef1":"import tensorflow as tf","910ab673":"base_path = \"..\/input\/cassava-leaf-disease-classification\/\"\n\nwith open(os.path.join(base_path, 'label_num_to_disease_map.json'), 'r') as f:\n    class_map = json.load(f)\n    class_map = {int(k):v for k,v in class_map.items()}\nprint(class_map)","b768e5ea":"print(\"Number of Images in Train Set: {}\".format(len(os.listdir(os.path.join(base_path, 'train_images')))))","f3cf33f0":"train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\ntrain_df","5a82c9c3":"global_seed = 23\nimport random\nrandom.seed(global_seed)","d8bf0ec4":"disease_names = open(base_path+'label_num_to_disease_map.json')\ndisease_names = json.load(disease_names)\ntrain_df['disease_name'] = train_df['label'].apply(lambda x: disease_names[str(x)])\n# credit: https:\/\/www.kaggle.com\/ramjib\/cassava-leaf-disease-eda-and-outliers\ntrain_df","a7e917dc":"my_colors = 'kckckc'\nplt.bar(x=train_df['disease_name'].value_counts().index, height=train_df['disease_name'].value_counts().values, color =my_colors)\nplt.xticks(rotation=90)\nplt.show()","28a4c948":"def plot_batch(data=df):\n    plt.figure(figsize=(16,12))\n    for i in range(9):\n        k = np.random.randint(0, len(data)) #for plotting random images from dataset\n        image = cv2.imread(os.path.join(base_path, 'train_images\/', data.image_id[k]))\n        \n        plt.subplot(3,3,i+1)\n        plt.imshow(image)\n        plt.axis(\"off\")\n        plt.title(\"Class Label:{}\\nClass Name:{}\".format(data.label[k], data.disease_name[k]))\n    \n    plt.tight_layout()\n    plt.show()\n# Credit - https:\/\/www.kaggle.com\/anantgupt\/cassava-leaf-doctor-eda-keras\/notebook#5:-MODEL-TRAINING-AND-DEFINING-CALLBACKS","d79860fd":"plot_batch(train_df)","7815667a":"for i in range(5):\n    temp_df = train_df.loc[df['label']==i]\n    temp_df.reset_index(inplace=True)\n    print(\"Class label:\", i)\n    plot_batch(temp_df)","d8a034aa":"from fastai.vision.all import *\nset_seed(23)","b422ac79":"path = Path(\"..\/input\")\ndata_path = path\/'cassava-leaf-disease-classification'\ndata_path.ls()","ea688a5d":"df = train_df\ndf['image_id'] = df['image_id'].apply(lambda x: f'train_images\/{x}')","de2c8121":"df.head()","5a7203a7":"blocks = (ImageBlock, CategoryBlock)\nsplitter = RandomSplitter(valid_pct=0.2)","5b0bf09c":"def get_x(row): return data_path\/row['image_id']\n\ndef get_y(row): return row['label']","75bd3fca":"item_tfms = [Resize(448)]\nbatch_tfms = [RandomResizedCropGPU(224), *aug_transforms(), Normalize.from_stats(*imagenet_stats)]","e2fb8892":"block = DataBlock(blocks = blocks,\n                 get_x = get_x,\n                 get_y = get_y,\n                 splitter = splitter,\n                 item_tfms = item_tfms,\n                 batch_tfms = batch_tfms)","37286dac":"dls = block.dataloaders(df, bs=64)","926f6202":"dls.show_batch(figsize=(12,12))","48df85e7":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'","a60cbce5":"learn = cnn_learner(dls, resnet50, opt_func=ranger, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy)","6d9490a3":"def fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n              pct_start=0.3, div=5.0, **kwargs):\n    \"Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR\"\n    self.freeze()\n    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n    base_lr \/= 2\n    self.unfreeze()\n    self.fit_one_cycle(epochs, slice(base_lr\/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)","28062052":"@patch\ndef fine_tune_flat(self:Learner, epochs, base_lr=4e-3, freeze_epochs=1, lr_mult=100, pct_start=0.75, \n                   first_callbacks = [], second_callbacks = [], **kwargs):\n    \"Fine-tune applied to `fit_flat_cos`\"\n    self.freeze()\n    self.fit_flat_cos(freeze_epochs, slice(base_lr), pct_start=0.99, cbs=first_callbacks, **kwargs)\n    base_lr \/= 2\n    self.unfreeze()\n    self.fit_flat_cos(epochs, slice(base_lr\/lr_mult, base_lr), pct_start=pct_start, cbs=second_callbacks)","12185e47":"learn.lr_find()\n# Interrupted b\/c taking too long; see Mueller's notebook for output\n# His SuggestedLRs were: (lr_min=0.017378008365631102, lr_steep=0.14454397559165955)","b9f4391b":"cbs1 = [MixUp(alpha = 0.7)]\ncbs2 = [MixUp(alpha = 0.3)]","ab6bc529":"# Note that the original had `start_pct`, but it should have been `pct_start`\nlearn.fine_tune_flat(2, base_lr=1e-3, pct_start=0.72, first_callbacks=cbs1, second_callbacks=cbs2)","ecf666d3":"sample_df = pd.read_csv(data_path\/'sample_submission.csv')\nsample_df.head()","73ae1bf7":"sample_copy = sample_df.copy()\nsample_copy['image_id'] = sample_copy['image_id'].apply(lambda x: f'test_images\/{x}')","b5a1b191":"test_dl = learn.dls.test_dl(sample_copy)","71d1208e":"test_dl.show_batch()","b4110672":"preds, _ = learn.tta(dl=test_dl)","c8df5556":"sample_df['label'] = preds.argmax(dim=-1).numpy()\nsample_df.to_csv('submission.csv',index=False)","c7c21633":"We'll choose a learning rate of roughly 4e-3 to start.","41a022a1":"Next we'll get some predictions. We will use the `.tta` method to run test-time-augmentation which can help boost our accuracy some:","70c11060":"Looks shipshape!","860d7606":"## Training this FastAI model\n\nThe code below is from tanlikesmath's notebook (via kaggle.com\/muellerzr\/cassava-fastai-starter). We have to add a resnet model to our directory (see https:\/\/forums.fast.ai\/t\/how-can-i-load-a-pretrained-model-on-kaggle-using-fastai\/13941\/24 for instructions) before running the cell below. The code below moves our pretrained weights to where fastai will expect it:","cc0cf3a8":"## Submitting some results","7895e888":"# Baseline model with FastAI\nMost of the following is adapted from kaggle.com\/muellerzr\/cassava-fastai-starter","3c8bb7fc":"## Building the `DataBlock`\n","4e775af8":"Then we submit them.","6433b9cc":"We're checking a batch of data to make sure everything looks alright:","175ca5ec":"We'll look at a batch of data to make sure it all looks okay:","1e1f4877":"We're training for 1 epoch frozen and 2 unfrozen, with a `pct_start` of 0.72:"}}