{"cell_type":{"759cea65":"code","95607c2a":"code","4870f831":"code","0c92c275":"code","2dba6f76":"code","13e4ad84":"code","657189cb":"code","9687439b":"code","d838a7e0":"code","a64179f3":"code","f27d6704":"markdown"},"source":{"759cea65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95607c2a":"# TensorFlow\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\n# Detect and init the TPU\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n    \n# Plotting\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Matplotlib defaults\nplt.style.use('seaborn-whitegrid')\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\n\n\n# Model\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks","4870f831":"#Load Data\n\ndf = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\n","0c92c275":"from sklearn import preprocessing\n\ndf_train = df.sample(frac=0.7, random_state=0)\ndf_valid = df.drop(df_train.index)\n\n\n# Split features and target\nX_train = df_train.drop(['target','id'],axis=1)\nX_valid = df_valid.drop(['target','id'],axis=1)\ny_train = df_train['target']\ny_valid = df_valid['target']\n\n","2dba6f76":"\ndf_test = df_test.drop('id',axis=1)\nscaler = preprocessing.StandardScaler()\n\nX_train[:] = scaler.fit_transform(X_train[:])\nX_valid[:] =scaler.transform(X_valid[:])\ndf_test[:] = scaler.transform(df_test[:])","13e4ad84":"from tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=10, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nmodel = keras.Sequential([\n    layers.Dense(4,activation ='relu', input_shape =[100],\n    #kernel_regularizer= keras.regularizers.l2(0.005)\n                ),\n    layers.Dense(4,activation='softmax'),\n    layers.Dense(1,activation='sigmoid'),\n    \n])","657189cb":"model.compile(\n     optimizer ='adam',\n     loss='binary_crossentropy',\n     metrics =['binary_accuracy']\n    )","9687439b":"history = model.fit(\nX_train,y_train,\nvalidation_data =(X_valid,y_valid),\nbatch_size=512,\nepochs =1000,\ncallbacks=[early_stopping],\nverbose =0\n)\n\n","d838a7e0":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5\nhistory_df.loc[5:, ['loss', 'val_loss']].plot()\nhistory_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_binary_accuracy'].max()))","a64179f3":"index = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\npredictions=model.predict(df_test)\ndata = pd.DataFrame(data=predictions,columns=['target'])\noutput =pd.DataFrame({'id': index.id,'target':data['target']})\noutput.to_csv('submission.csv',index=False)\n","f27d6704":"# My Second Notebook for this competition\n\nI used XGBRegressor for this project on my first notebook.\nhttps:\/\/www.kaggle.com\/satoshiss\/spam-detection-tabular-playground-nov-2021\n\n**Try Neural Networks**\nWhen I read through discussion board, I saw someone mentioned NN works well for this dataset.\nhttps:\/\/www.kaggle.com\/c\/tabular-playground-series-nov-2021\/discussion\/284784\n\nI wanted to practice neural networks, so I will give it a try. I refferred to Intro to Deep Learning\non the Kaggle course and also the notebook(https:\/\/www.kaggle.com\/ryanholbrook\/detecting-the-higgs-boson-with-tpus).\n"}}