{"cell_type":{"40eb8146":"code","05160eed":"code","7ea6a452":"code","2e02fe4d":"code","489138fc":"code","0e0c4a04":"code","9dd03612":"code","9d2371cb":"code","e57b822b":"code","647fc82f":"code","00898193":"code","9101cf47":"code","c6116f18":"code","efad83d8":"code","ab8c7897":"code","2cf32763":"markdown","3e38fa62":"markdown","01e7186c":"markdown","e31183de":"markdown","06b640a8":"markdown","81dfdd7f":"markdown","45c420eb":"markdown","963b659e":"markdown","792a27e8":"markdown"},"source":{"40eb8146":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nimport requests\nfrom bs4 import BeautifulSoup as Soup\n\nwarnings.filterwarnings('ignore')","05160eed":"def import_data(dataset_path = '..\/input\/serie-a-matches-dataset\/'):\n    season_list = os.listdir(dataset_path)\n\n    data = pd.DataFrame()\n    for season_file in season_list:\n        season = pd.read_csv(dataset_path + season_file, sep = ';')\n        season['season'] = season_file.split('_')[1][:-4] #create a new feature to indicate season\n        data = data.append(season)\n    \n    return data","7ea6a452":"data = import_data()\ndata","2e02fe4d":"def data_sorter(data, col = 'match_date'):\n    data[col] = pd.to_datetime(data[col])\n    data = data.sort_values(col).reset_index(drop = True)\n    return data","489138fc":"data = data_sorter(data)\ndata","0e0c4a04":"data.columns.tolist()","9dd03612":"def target(row): #match winner\n    if row['home_goals'] > row['away_goals']:\n        return 0\n    elif row['home_goals'] == row['away_goals']:\n        return 1\n    else:\n        return 2\n\ndef target_25(row): #under\/over 2.5\n    if row['home_goals'] + row['away_goals'] < 2.5:\n        return 0\n    else:\n        return 1","9d2371cb":"data = data.set_index('match_id')\nplayed = data[data.home_goals.notna()][['home_goals', 'away_goals']]\nplayed['target'] = played.apply(lambda row : target(row), axis = 1)\nplayed['target_25'] = played.apply(lambda row : target_25(row), axis = 1)\ndata = data.merge(played[['target', 'target_25']], on = 'match_id', how = 'outer')\ndata","e57b822b":"def get_request(url, page):\n    p_html = requests.get(url + page, verify = False)\n    p_soup = p_html.text\n    data = Soup(p_soup,'html.parser')\n    return data\n\ndef get_fifa_tab(data):\n    tab_fifa = []\n    mod = data.find_all(\"div\", {\"class\": \"bp3-menu\"})\n    for a in mod[1].findAll('a'):\n        fifa = a.text\n        link = a['href']\n        if fifa >= 'FIFA 19': #data start from 2018, so oldest game is FIFA19\n            tab_fifa.append([fifa, link])\n    tab_fifa = pd.DataFrame(tab_fifa, columns = ['FIFA', 'link'])\n    return tab_fifa\n\ndef get_aggiornamenti(data, fifa):\n    tab_aggiornamenti = []\n    mod = data.find_all(\"div\", {\"class\": \"bp3-menu\"})\n    for a in mod[2].findAll('a'):\n        data_aggiornamento = a.text\n        link = a['href']\n        tab_aggiornamenti.append([fifa, data_aggiornamento, link])\n    tab_aggiornamenti = pd.DataFrame(tab_aggiornamenti, columns = ['fifa', 'data_aggiornamento', 'link'])\n    return tab_aggiornamenti\n\ndef create_df_map(tab_fifa, url):\n    df_map = pd.DataFrame()\n    for i, row in tab_fifa.iterrows():\n        fifa = row.FIFA\n        page = row.link\n        data = get_request(url, page)\n        tab_aggiornamenti = get_aggiornamenti(data, fifa)\n        df_map = df_map.append(tab_aggiornamenti, ignore_index = True)\n        df_map.data_aggiornamento = pd.to_datetime(df_map.data_aggiornamento)\n    df_map = df_map.sort_values(['fifa', 'data_aggiornamento'])\n    df_map['fine_val'] = df_map.data_aggiornamento.shift(-1)\n    return df_map\n\ndef get_team_stats(data):\n    stats = []\n    table = data.find('tbody')\n    for i in table.findAll('tr'):\n        td = i.findAll('td')\n        name = td[1].findAll('a')[0].text\n        ova = int(td[2].text.split()[0])\n        att = int(td[3].text.split()[0])\n        mid = int(td[4].text.split()[0])\n        def_ = int(td[5].text.split()[0])\n        stats.append([name, ova, att, mid, def_])\n    stats = pd.DataFrame(stats, columns = ['Name','OVA','ATT','MID','DEF'])\n    return stats\n\ndef save_stats(df_map, url):\n    for i, row in df_map.iterrows():\n        page = row.link\n        data = get_request(url, page)\n        stats = get_team_stats(data)\n        stats.to_csv(page.split('=')[2][:-4] + '.csv', sep = ';', index = False)","647fc82f":"url = 'https:\/\/sofifa.com'\npage = '\/teams?lg=31' #serie a teams page\n\ndata = get_request(url, page)\ntab_fifa = get_fifa_tab(data) #function to get links of fifa game since FIFA 19\ntab_fifa","00898193":"df_map = create_df_map(tab_fifa, url)\ndf_map","9101cf47":"save_stats(df_map, url)","c6116f18":"#example\npd.read_csv('190030.csv', sep = ';')","efad83d8":"def add_fifa_stats(row, df_map):\n    match_date = row.match_date\n    home_team = row.home_team\n    away_team = row.away_team\n\n    page = df_map[(df_map.data_aggiornamento <= pd.to_datetime(match_date.date())) &\n       ((df_map.fine_val > pd.to_datetime(match_date.date())) | df_map.fine_val.isna())].iloc[-1].link\n\n    stats = pd.read_csv(page.split('=')[2][:-4] + '.csv', sep = ';').replace({'Roma' : 'AS Roma', 'Torino F.C.' : 'Torino', 'Udinese Calcio' : 'Udinese', 'U.S. Sassuolo Calcio' : 'Sassuolo',\n    'U.C. Sampdoria' : 'Sampdoria', 'Hellas Verona' : 'Verona', 'SPAL' : 'Spal', 'Chievo Verona' : 'Chievo',\n    'US Salernitana 1919' : 'Salernitana', 'Venezia FC' : 'Venezia'})\n\n    home_ova = stats[stats.Name == home_team].iloc[0].OVA \n    home_att = stats[stats.Name == home_team].iloc[0].ATT \n    home_mid = stats[stats.Name == home_team].iloc[0].MID \n    home_def = stats[stats.Name == home_team].iloc[0].DEF \n\n    away_ova = stats[stats.Name == away_team].iloc[0].OVA\n    away_att = stats[stats.Name == away_team].iloc[0].ATT\n    away_mid = stats[stats.Name == away_team].iloc[0].MID\n    away_def = stats[stats.Name == away_team].iloc[0].DEF\n\n    return home_ova, home_att, home_mid, home_def, away_ova, away_att, away_mid, away_def\n\ndef fifa_stats_creator(data, fifa_stats_columns, df_map):\n    #df_map = pd.read_csv(cwd + '\/data\/fifa_stats\/df_map.csv', sep = ';')\n    #df_map.data_aggiornamento = pd.to_datetime(df_map.data_aggiornamento)\n    #df_map.fine_val = pd.to_datetime(df_map.fine_val)\n\n    data[fifa_stats_columns] = data.apply(lambda row: add_fifa_stats(row, df_map), axis = 1, result_type = 'expand')\n    data[fifa_stats_columns] = data[fifa_stats_columns] \/ 100\n\n    return data","ab8c7897":"#complete code!\nfifa_stats_columns = ['home_ova', 'home_att', 'home_mid', 'home_def', 'away_ova', 'away_att', 'away_mid', 'away_def']\ndata = import_data()\ndata = data_sorter(data)\ndata = fifa_stats_creator(data, fifa_stats_columns, df_map)\ndata = data.set_index('match_id')\nplayed = data[data.home_goals.notna()][['home_goals', 'away_goals']]\nplayed['target'] = played.apply(lambda row : target(row), axis = 1)\nplayed['target_25'] = played.apply(lambda row : target_25(row), axis = 1)\ndata = data.merge(played[['target', 'target_25']], on = 'match_id', how = 'outer')\ndata","2cf32763":"With the function below, we save the stats at the links in df_map.","3e38fa62":"As you can see matches not yet played have Na values for home goals and away goals features. **Dataset is updated after every round.**\n\nIf you want create target to perform and test supervised learning task you can use these function:","01e7186c":"# Scraping FIFA Team Stats\n\nWorking with a lot of dummies for every team may not be the best choice. My idea is to use FIFA (very famous Video Game) team stats as a proxy for the team. As suggest in this Dataset https:\/\/www.kaggle.com\/karangadiya\/fifa19, I scraped the data from https:\/\/sofifa.com\/.","e31183de":"## Creating a Pandas Dataframe\n\nCreating a Pandas Dataframe with all matches from the dataset is a very easy task.","06b640a8":"We can sort matches by game play date before start working.","81dfdd7f":"Now we create a map to get the time interval of every team stats updates. It's better not to use today stats for 2018 matches!!! ","45c420eb":"# If you like this work, please leave an upvote and I will add my machine learning solutions to play against the bookmaker! Thank you for reading!","963b659e":"Now we can join team stats with the Dataset","792a27e8":"# Dataset Introduction\n\n**Serie A Matches Dataset** is a dataset with all matches played since 2018-2019 season in the Italian top league.\n\nFiles are splitted by season, so for now (Jan 2022) we have four files. All file have the same features. Features are mainly statistics of the two teams, but there are also predictions on the winning team and the number of goals scored (collected through free API) and bookmaker odds (1X2 and under\/over 2.5) scraped from MarathonBet. If you want to integrate with additional odds these data, you can easily join Dataset with several csv files downloadable from internet.\n\nFor example these:\nhttps:\/\/www.football-data.co.uk\/italym.php"}}