{"cell_type":{"781c86a4":"code","e12b86c2":"code","0660dd00":"code","b92899d8":"code","8d52e35b":"code","626dd485":"code","3d5e840c":"code","a8feb742":"code","a4e9bb44":"code","6c9f7c02":"code","081a3989":"code","fc6f3e87":"code","0ed96016":"code","e161d5eb":"code","6b2ea661":"code","5fc60903":"code","4a578860":"code","6971648e":"code","27ff906b":"code","b321b0f9":"code","b5005874":"code","98d4822f":"code","e727d034":"code","475ec17b":"markdown","b10e27e5":"markdown","cc5e9f04":"markdown","33faa455":"markdown","25b7f13d":"markdown","def92a49":"markdown","ca43e60d":"markdown","1d4a48c8":"markdown","6ef26875":"markdown","7b8b929b":"markdown","15a5f493":"markdown","df2f9fd3":"markdown","39196fda":"markdown","faac6437":"markdown","cde72c50":"markdown","292e9c29":"markdown","44bf36c0":"markdown","4c0e77eb":"markdown","24ecc7c5":"markdown","5a641bf8":"markdown","d4715126":"markdown"},"source":{"781c86a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e12b86c2":"import numpy as np # linear algebra\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import preprocessing, model_selection, metrics\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as pltMath\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport time\ncolor = sns.color_palette()\n%matplotlib inline\nimport matplotlib.patheffects as PathEffects\nfrom sklearn.cluster import KMeans\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999","0660dd00":"def reclassifyDataSet(df):\n    for i,row in df.iterrows():\n            if row['price'] < 6000000:\n                df.at[i, 'price'] = 0\n            elif row['price'] < 12000000:\n                df.at[i, 'price'] = 1\n            elif row['price'] < 18000000:\n                df.at[i, 'price'] = 2\n            elif row['price'] < 24000000:\n                df.at[i, 'price'] = 3\n            else:\n                df.at[i, 'price'] = 4\n            i += 1\n    print(df)\n    return df\ndef MyScatter(x, colors):\n    # choose a color palette with seaborn.\n    num_classes = len(np.unique(colors))\n    palette = np.array(sns.color_palette(\"hls\", num_classes))\n\n    # create a scatter plot.\n    f = pltMath.figure(figsize=(8, 8))\n    ax = pltMath.subplot(aspect='equal')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n    pltMath.xlim(-25, 25)\n    pltMath.ylim(-25, 25)\n    ax.axis('off')\n    ax.axis('tight')\n\n    # add the labels for each digit corresponding to the label\n    txts = []\n\n    for i in range(num_classes):\n\n        # Position of each label at median of data points.\n\n        xtext, ytext = np.median(x[colors == i, :], axis=0)\n        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n        txt.set_path_effects([\n            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n            PathEffects.Normal()])\n        txts.append(txt)\n\n    return f, ax, sc, txts\n\n\ndef buildTSNE(dataSet):\n\n#     (nsamples, nx, ny, nz) = dataSet.shape\n#     D2 = dataSet.reshape((nsamples, nx * ny * nz))\n\n    # T-SNE Implementation\n\n    t0 = time.time()\n    X_reduced_tsne = TSNE(n_components=2,\n                          random_state=42).fit_transform(dataSet)\n    t1 = time.time()\n    print(\"T-SNE took {:.2} s\".format(t1 - t0))\n    \n    MyScatter(X_reduced_tsne, dataSet['price'])\n\n    return X_reduced_tsne\n    \ndef plotTSNE(X_tsne):\n    kmeans_tsne = KMeans(n_clusters=5).fit(X_tsne)\n    \n    pltMath.figure(figsize=(12, 5))\n    cmap = pltMath.get_cmap('nipy_spectral')\n\n    pltMath.subplot(1,2,1)\n    pltMath.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cmap(kmeans_tsne.labels_ \/ 5))\n    pltMath.title('TSNE')\n","b92899d8":"train = pd.read_csv(\"\/kaggle\/input\/realty-prices-minor2020\/reality_data_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/realty-prices-minor2020\/reality_data_test.csv\")\n\nprint(\"Train rows and columns : \", train.shape)\nprint(\"Test rows and columns : \", test.shape)","8d52e35b":"train.head()","626dd485":"plt.figure(figsize=(8,6))\nplt.scatter(range(train.shape[0]), train['price'].values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Price', fontsize=12)\nplt.title(\"Price Distribution\", fontsize=14)\nplt.show()","3d5e840c":"dtype_df = train.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","a8feb742":"for column in train.columns:\n    if train[column].dtype=='object':\n        label = LabelEncoder()\n        train[column] = label.fit_transform(train[column])\n        print(dict(enumerate(label.classes_)))\n        \ntrain.info()","a4e9bb44":"Y = train.price.values\nX = train.drop([\"id\", \"price\"], axis=1)\n\ntrain_x, val_x, train_y, val_y = train_test_split(X,Y,random_state=42)\n\n","6c9f7c02":"for column in test.columns:\n    if test[column].dtype=='object':\n        label = LabelEncoder()\n        test[column] = label.fit_transform(test[column])\n        print(dict(enumerate(label.classes_)))\n        \ntest.info()","081a3989":"def plotBarChart(values,description):\n    pltMath.plot(values)\n    pltMath.title(description)\n    pltMath.ylabel('accuracy')\n    pltMath.xlabel('estimator')\n    pltMath.legend(['mae'], loc='upper left')\n    pltMath.show()","fc6f3e87":"xgb_model = XGBRegressor(\n    objective = 'reg:squarederror',\n    learning_rate = 0.01,\n    max_depth = 55,\n    n_estimators = 1000)\n\nprint('start training')\nxgb_model.fit(train_x, train_y, eval_set=[(train_x,train_y),(val_x,val_y)],eval_metric='mae', verbose=False)\nprint('finish training')\n\n","0ed96016":"mae = xgb_model.evals_result()[\"validation_0\"][\"mae\"]\nplotBarChart(mae,\"mae values\")\nmae2 = xgb_model.evals_result()[\"validation_1\"][\"mae\"]\nplotBarChart(mae2,\"mae values\")","e161d5eb":"xgb_prediction = xgb_model.predict(val_x).round(0)\nmae_xgb = mean_absolute_error(val_y, xgb_prediction)\nprint(mae_xgb)\n","6b2ea661":"print('start training')\nxgb_model.fit(X, Y)\nprint('finish training')\n\nprint(xgb_model.evals_result().keys())\nmae = xgb_model.evals_result()[\"validation_0\"][\"mae\"]\nplotBarChart(mae,\"mae values\")\nmae2 = xgb_model.evals_result()[\"validation_1\"][\"mae\"]\nplotBarChart(mae2,\"mae values\")\n","5fc60903":"forest_model = RandomForestRegressor(n_estimators=30, \n                                 criterion='mae',\n                                 max_features=3,\n                                 random_state=1,\n                                 max_depth=55,\n                                 min_samples_split=5\n                                 )\n\nprint('start training')\nforest_model.fit(train_x, train_y)\nprint('finish training')","4a578860":"forest_prediction = forest_model.predict(val_x).round(0)\nmae_forest = mean_absolute_error(val_y, forest_prediction)\nprint(mae_forest)\n","6971648e":"print('start training')\nforest_model.fit(X, Y)\nprint('finish training')","27ff906b":"def plotBarChart(true,predict):\n    pltMath.figure(figsize=(20,5))\n    pltMath.bar([1,2],[true,predict])\n    pltMath.ylabel(\"mae\", fontsize=16)\n    pltMath.title(\"Histogram mae\")\n    pltMath.show()","b321b0f9":"plotBarChart(mae_xgb, mae_forest)","b5005874":"x_tsne = buildTSNE(reclassifyDataSet(train))","98d4822f":"plotTSNE(x_tsne)","e727d034":"test_x = test.drop([\"id\"], axis=1)\nxgb_prediction_test = xgb_model.predict(test_x).round(0)\nforest_prediction_test = forest_model.predict(test_x).round(0)\nrounded_prediction_forest = np.round(forest_prediction_test,0)\nrounded_prediction_xgb = np.round(xgb_prediction_test,0)\n\nsubmission_xgb = pd.DataFrame()\nsubmission_xgb['Id'] = test.id.values\nsubmission_xgb['Price'] = rounded_prediction_xgb\nsubmission_xgb.to_csv('submission_xgb.csv',index=False)\n\nprint(\"XGB submission is ready\")\n\nsubmission_forest = pd.DataFrame()\nsubmission_forest['Id'] = test.id.values\nsubmission_forest['Price'] = rounded_prediction_forest\nsubmission_forest.to_csv('submission_forest.csv',index=False)\n\nprint(\"Forest submission is ready\")","475ec17b":"# Compare plot on two models","b10e27e5":"* # Random forest model","cc5e9f04":"Prepare test data","33faa455":"# Make prediction on real data","25b7f13d":"Create regression XGBoost model and train it","def92a49":"Create regression Random Forest model and train it","ca43e60d":"# Import libraries","1d4a48c8":"# TSNE","6ef26875":"Split train data to train and validation","7b8b929b":"Train data","15a5f493":"Train on all training range","df2f9fd3":"Make a prediction to validate","39196fda":"There are visible outliers\n\ndata types of columns","faac6437":"Make a prediction to validate","cde72c50":"Train on all training range","292e9c29":"# Functions for TSNE","44bf36c0":"# XGBoost model","4c0e77eb":"Plot of the price to check visible outliers","24ecc7c5":"As we have one object column, we should use label encoder to represent by numbers","5a641bf8":"# Analyze data","d4715126":"# Prepare data"}}