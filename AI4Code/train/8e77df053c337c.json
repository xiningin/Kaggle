{"cell_type":{"5f94145d":"code","f0aebb13":"code","712d599e":"code","5901131e":"code","b1e38044":"code","85f01095":"code","e925285d":"code","04ff1000":"code","85fc0fe6":"code","363109e5":"code","2be536e7":"code","32bffc55":"code","b454b131":"code","7c646dce":"code","ddb3de89":"code","17e31f13":"code","68688593":"code","6a5df321":"code","ba3af97d":"code","9b9a44e3":"code","cec46a2d":"code","b0b7d89b":"markdown","25bc0d00":"markdown","ea4604fc":"markdown","3c324095":"markdown","15c77b7b":"markdown","571c7ee0":"markdown","720bffd6":"markdown","8b32470e":"markdown","310c44d2":"markdown"},"source":{"5f94145d":"import random\nimport os \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras.applications import EfficientNetB7\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator","f0aebb13":"#setting random seed for reproducability.\ndef set_seed(seed=7):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    random.seed(seed)\n\nset_seed(7)","712d599e":"Epochs=30\nimg_size=(120,120)\nbatch_size=32\nmodel_filepath='EffNetB7_baseline_holiday.h5'","5901131e":"train_df=pd.read_csv('..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train.csv')\ntrain_path='..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train'\ntest_path='..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/test'\n\ntrain_df.head()","b1e38044":"#class Frequency.\nplt.figure(figsize=(16,8))\nsns.countplot(train_df['Class'])\nplt.title('Class Frequency')\nplt.show()","85f01095":"def show_sample_images(df) :\n    df_s=df.sample(5)\n    plt.subplots(1,5, figsize=(20,6))\n    for i,img in enumerate(df_s['Image']):\n        plt.subplot(1,5,i+1)\n        plt.title(f'{df_s.Class.iloc[i]}')\n        img_path=os.path.join(train_path + '\/' + img)\n        image=cv2.imread(img_path)\n        image=np.array(image)\n        plt.imshow(image)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    ","e925285d":"#showing sample images of each class\n\nfor cls in train_df['Class'].unique():\n    show_sample_images(train_df[train_df['Class']==cls])\n    ","04ff1000":"#splitting training data into train and valid sets.\ntrain,valid=train_test_split(train_df,test_size=.15,random_state=7,stratify=train_df.Class.values)\n\n\ntrain.reset_index(inplace=True,drop=True)\nvalid.reset_index(inplace=True,drop=True)","85fc0fe6":"#IMage_data Generator:\ndatagen=ImageDataGenerator(rotation_range=30,\n    width_shift_range=(0.1,0.3),\n    height_shift_range=(0.1,0.3),\n    brightness_range=(0.5,1.4),\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1.\/255)\n\nvalid_datagen=ImageDataGenerator(rescale=1.\/255)","363109e5":"#training data:\ntrain_gen=datagen.flow_from_dataframe(dataframe=train,\n                                         directory=train_path,\n                                         x_col='Image' ,\n                                         y_col='Class'  ,\n                                         target_size=img_size,\n                                         batch_size=batch_size,\n                                         class_mode='sparse',\n                                         shuffle=True,\n                                         seed=7)\n#validation data:\nvalid_gen=valid_datagen.flow_from_dataframe(dataframe=valid,\n                                           directory=train_path,\n                                           x_col='Image',\n                                           y_col='Class',\n                                           target_size=img_size,\n                                           batch_size=batch_size,\n                                           class_mode='sparse',\n                                           seed=7)","2be536e7":"#defining model.\n\n#base_layer\neffnet=EfficientNetB7(include_top=False,weights='imagenet',input_shape=(120,120,3))\n\nmodel=keras.Sequential([\n    keras.Input(shape=(120,120,3)),\n    keras.layers.experimental.preprocessing.Normalization(),\n    effnet,\n    \n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(16,activation='relu'),\n    keras.layers.Dropout(.4,seed=7),\n    \n    keras.layers.Dense(6,activation='softmax')])\n    \n#compiling model.\nmodel.compile(optimizer=keras.optimizers.Adam(lr=1e-4),                                \n                  loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])","32bffc55":"#Summary\nmodel.summary()","b454b131":"#callbacks:\n#to reduce learning rate by factor of .25 if val_loss does not improve after 2 epochs.\nreduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=.25,patience=2,min_delta=0.01)\n\n#stop training if validation loss does not decrease by atleast .001 in 5 epochs.\nearly_stopping=keras.callbacks.EarlyStopping(min_delta=.001,patience=4,monitor='val_loss',restore_best_weights=True)\n\n#save the best weights and the model.\nmodel_checkpoint=keras.callbacks.ModelCheckpoint(filepath=model_filepath,monitor='val_loss',\n                                                 save_best_only=True)\n\ncallbacks_v1=[reduce_lr,early_stopping,model_checkpoint]","7c646dce":"#fitting the model.\nhistory=model.fit_generator(train_gen,\n                           steps_per_epoch=train_gen.n\/\/batch_size,\n                           validation_data=valid_gen,\n                           validation_steps=valid_gen.n\/\/batch_size,\n                           epochs=Epochs,\n                           callbacks=callbacks_v1)","ddb3de89":"hist=history.history\n\nplt.figure(figsize=(16,8))\n\n#plotting accuracy:\nplt.subplot(1,2,1)\nplt.title('Accuracy')\nplt.plot(range(Epochs),hist['sparse_categorical_accuracy'],color='g',label='Training Accuracy')\nplt.plot(range(Epochs),hist['val_sparse_categorical_accuracy'],color='r',label='Validation Accuracy')\n\n#plotting loss \nplt.subplot(1,2,2)\nplt.title('Loss')\nplt.plot(range(Epochs),hist['loss'],color='g',label='Training_loss')\nplt.plot(range(Epochs),hist['val_loss'],color='r',label='Validation loss')\n\nplt.legend()\nplt.show()","17e31f13":"score=model.evaluate_generator(valid_gen)\nprint(f'Validation_Loss={score[0]} \\n Validation_Accuracy={score[1]}')","68688593":"from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n\n#predicted classes :\nprob=model.predict_generator(valid_gen)\npreds=np.argmax(prob,axis=1)\n\ntrue_labels=valid_gen.classes\n\nfig,ax=plt.subplots(figsize=(10,10))\ncm=confusion_matrix(preds,true_labels)\ndisp=ConfusionMatrixDisplay(cm)\ndisp.plot(ax=ax)","6a5df321":"best_model=keras.models.load_model('.\/EffNetB7_baseline_holiday.h5')","ba3af97d":"#decoding the integer values of predictions to the class. \nclass_index=list(train_gen.class_indices) \nclass_index","9b9a44e3":"from keras.preprocessing.image import load_img,img_to_array\n\ntest_img_id=[]              #image_ids \npreds=[]                    # predictions\ncount=0                     #count of images that will throw up a error\n\nfor image in os.listdir(test_path):\n    img=load_img(test_path +'\/' + image)\n    img=img.resize((120,120))\n    img=img_to_array(img)\n    img=np.expand_dims(img,axis=0)\n    img=img\/255\n    \n    try:\n        pred=best_model.predict(img).argmax(axis=1)[0]\n        pred=class_index[pred]\n    except:\n        pred= 'Miscellaneous'\n        count+=1\n    test_img_id.append(str(image))    \n    preds.append(pred)\n    \nprint(f'{count} number of images threw up a error.') ","cec46a2d":"submissions=pd.DataFrame({'Image':test_img_id , 'Class':preds})\nprint(submissions.head())\nsubmissions.to_csv('submissions.csv',index=False)","b0b7d89b":"**Used some code from this notebook for making predictions in the final part . [https:\/\/www.kaggle.com\/nikhil741\/hackerearth-holiday-season-starter-kernel]**","25bc0d00":"# Splitting Training and validation data .","ea4604fc":"# Model Evaluation on Validation set.","3c324095":"# Predicting using the best saved model weights.","15c77b7b":"# Importing Libraries.","571c7ee0":"# Confusion Matrix","720bffd6":"# Setting the Variables.","8b32470e":"# Learning Curve.","310c44d2":"# Visualizing Images:\n"}}