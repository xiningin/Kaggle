{"cell_type":{"8703b788":"code","7eaf5345":"code","956c8a7b":"code","3120fb1a":"code","e8cc5292":"code","6bbf3ec8":"code","18305d54":"code","d1798b95":"code","b3c61774":"code","b42de00e":"code","c8c784ae":"code","9c4759db":"code","c90caf38":"code","edb601c7":"code","008190d2":"code","83fd299b":"code","c373548f":"code","3fc79634":"code","328cceb2":"code","d01cc469":"code","72a92ea2":"code","0d0bae95":"markdown","24eb734b":"markdown","b661c5e3":"markdown","240a7153":"markdown","498cbe41":"markdown","0ae391db":"markdown","1b9cb933":"markdown","9dd1c2c1":"markdown","33d01940":"markdown","0cb63153":"markdown","fdc3d360":"markdown","d25fe0bd":"markdown","c991c296":"markdown","f977549e":"markdown","a1232234":"markdown","ac0efe85":"markdown","70b0fb01":"markdown","b1dc0c5a":"markdown","24493732":"markdown","ead75807":"markdown","de9bf36c":"markdown","4843e7b5":"markdown"},"source":{"8703b788":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom IPython import display\n%matplotlib inline\ntf.__version__","7eaf5345":"def show(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","956c8a7b":"(x_train, y_train),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n# Normalization\nx_train = x_train.astype(np.float32) \/255.\nx_test = x_test.astype(np.float32) \/ 255.","3120fb1a":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i],cmap='binary')\nplt.show()","e8cc5292":"BATCH_SIZE = 32\nBUFFER_SIZE = 1000\n\n# This dataset fills a buffer with buffer_size elements, \n#then randomly samples elements from this buffer, replacing the selected elements with new elements.\ndataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n# This dataset is filling a buffer with a 1000 element and then radomly sampling from this 1000 elements\n\n#Combines consecutive elements of this dataset into batches.\ndataset = dataset.batch(BATCH_SIZE,drop_remainder=True).prefetch(1)\n# We have set drop_remainder = True so that if we get any non complete batch of 32 in the end, it'll be dropped\n\n# for eg: 1000%32 = 8 and 1000\/32 = 31.25\n# This means there'll be 31 batches with filled batch_size of 32 and the last\n# 32nd batch will have 8 elements only.\n# So drop_remainder will drop this 32nd batch.","6bbf3ec8":"from tensorflow.keras.layers import Dense, BatchNormalization,LeakyReLU\nfrom tensorflow.keras.layers import Reshape, Conv2D, Dropout, Flatten, Conv2DTranspose","18305d54":"NUM_FEATURES = 100\ndef make_generator():\n    generator = tf.keras.Sequential([\n        Dense(7*7*128, input_shape = [NUM_FEATURES]),\n#         BatchNormalization(),\n        Reshape([7,7,128]),\n        BatchNormalization(),\n        #upsampling\n#         Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', activation='selu'),\n#         BatchNormalization(),\n        #upsampling\n        Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', activation='selu'),\n        BatchNormalization(),\n\n        Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', activation='tanh')\n    ])\n    \n    return generator\n\ngenerator = make_generator()","d1798b95":"noise = tf.random.normal(shape=[1, NUM_FEATURES]) # 1 because we need 1 generated image\ngenerated_image = generator(noise, training=False)\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","b3c61774":"#Fashion MNIST shape = (28,28,1)\ndef make_discriminator():\n    discriminator = tf.keras.Sequential([\n        Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28, 28, 1]),\n        LeakyReLU(0.2),\n        Dropout(0.3),\n\n        Conv2D(128, (5,5), strides=(2,2), padding='same'),\n        LeakyReLU(0.2),\n        Dropout(0.3),\n\n#         Conv2D(256, (5,5), strides=(1,1), padding='same'),\n#         LeakyReLU(0.2),\n#         Dropout(0.3),\n\n        Flatten(),\n        Dense(1, activation='sigmoid') #binary classificaion\n    ])\n    \n    return discriminator\n\ndiscriminator = make_discriminator()","b42de00e":"decision = discriminator(generated_image)\nprint(decision)","c8c784ae":"discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\ndiscriminator.trainable=False\ngan = tf.keras.models.Sequential([generator,discriminator])\ngan.compile(loss='binary_crossentropy',optimizer='rmsprop')","9c4759db":"# Create a seed image for training process with shape(BATCH_SIZE, NUM_FEATUES)\n# Specified earlier shape = (32,100)\nseed = tf.random.normal(shape=[BATCH_SIZE, NUM_FEATURES])","c90caf38":"# Checking if the seed image shape is as we specified or not\nassert seed.shape == (32,100)","edb601c7":"def train_dcgan(gan, dataset, BATCH_SIZE, NUM_FEATURES, epochs = 5):\n    generator, discriminator = gan.layers\n    \n    for epoch in tqdm(range(epochs)):\n        print(f\"Epochs {epoch+1}\/{epochs}\")\n        \n        for X_batch in dataset:\n            # train generator to create mini batches of fake images\n            # noise -> vector of random noise\n            noise = tf.random.normal(shape=[BATCH_SIZE,NUM_FEATURES])\n            generated_images = generator(noise)\n            # concatenating generated_images with the real\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)\n            # specify the class label\n            # real images class label = 1\n            # fake or generated images class label = 0\n            y1 = tf.constant([[0.]] * BATCH_SIZE + [[1.]] * BATCH_SIZE)\n            discriminator.trainable = True\n            # training discriminator\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            noise = tf.random.normal(shape=[BATCH_SIZE, NUM_FEATURES])\n            # training generator\n            y2 = tf.constant([[1.]] * BATCH_SIZE) # 1 to fool the discriminator becasue that's the work of generator to fool the discriminator\n            discriminator.trainable = False\n            # training gan\n            gan.train_on_batch(noise, y2)\n            \n        display.clear_output(wait = True)\n        generate_and_save_images(generator, epoch+1, seed)\n        \n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epochs, seed)","008190d2":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(10,10))\n\n  for i in range(25):\n      plt.subplot(5, 5, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","83fd299b":"x_train_dcgan = x_train.reshape(-1,28,28,1) * 2. - 1.\nassert x_train_dcgan.shape == (60000, 28, 28, 1)\n\n# you can also explicitly provide the shape also","c373548f":"dataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder = True).prefetch(1)\n","3fc79634":"%%time\ntrain_dcgan(gan,dataset, BATCH_SIZE, NUM_FEATURES, epochs = 10)\n","328cceb2":"TIMES = 4\n\nfor _ in range(TIMES):\n    noise = tf.random.normal(shape=[BATCH_SIZE, NUM_FEATURES])\n    generated_images = generator(noise)\n    show(generated_images, 10)","d01cc469":"import imageio\nimport glob\n\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\ndisplay.Image(filename=anim_file)","72a92ea2":"noise = tf.random.normal(shape=[BATCH_SIZE, NUM_FEATURES])\ngenerated_images = generator(noise)\nshow(generated_images, 8)","0d0bae95":"### Creating training batches","24eb734b":"Once we'll train out DCGAN we will see this randomly generated noise to be some object.","b661c5e3":"Using untrained discriminator to classify the generated images as real or fake.","240a7153":"Creating a gif of generated synthetic images\nref: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif","498cbe41":"## Generating synthetic images with DCGAN","0ae391db":"## Helper funtion to plot graphs","1b9cb933":"## Building the Generator Network for DCGAN\n","9dd1c2c1":"Visualizing some data plot from our dataset. For this we are creating a (5,5) subplots.","33d01940":"### What are GANs\nGenerative Adversarial Networks belong to the set of generative models. It means that they are able to produce \/ to generate (we\u2019ll see how) new content.<br><br>\nGenerative Adversarial Networks (GANs) can be broken down into three parts:\n- <b>Generative<\/b>: To learn a generative model, which describes how data is generated in terms of a probabilistic model.<br>\n- <b>Adversarial<\/b>: The training of a model is done in an adversarial setting.<br>\n- <b>Networks<\/b>: Use deep neural networks as the artificial intelligence (AI) algorithms for training purpose.<br>\n\n### What is Generator and Discriminator?\n\n##### Generator - An artist\n##### Discriminator - An art critic\nThe <b>Generator<\/b> generates fake samples of data(be it an image, audio, etc.) and tries to fool the <b>Discriminator<\/b>. The <b>Discriminator<\/b>, on the other hand, tries to distinguish between the real and fake samples. The <b>Generator and the Discriminator are both Neural Networks and they both run in competition with each other in the training phase<\/b>. The steps are repeated several times and in this, the Generator and Discriminator get better and better in their respective jobs after each repetition.","0cb63153":"## Import Libraries","fdc3d360":"Generate and safe images\nref: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif","d25fe0bd":"selu activation funtion: Scaled Exponential Linear Unit : learn faster and better than other activation functions, even if they are combined with batch normalization.","c991c296":"- <b>tqdm:<\/b> make your loops show a smart progress meter - just wrap any iterable with `tqdm(iterable)`, and you\u2019re done!","f977549e":"![image.png](attachment:image.png)","a1232234":"## Compiling the DCGAN","ac0efe85":"First we'll train the discriminator network for some steps and then will train the generator network. And for training a `k-steps` of discriminator network, we'll be sampling a mini-batch of noise samples from our gaussian noise prior and then also sample a mini-batch of real images from our traning dataset. And what'll do is pass the noise through the generator and get the fake images out. \n\nAnd the so we have a mini batch of both fake images and real images. And then we'll pick a gradient step on our discriminator network using this mini batch of fake and real images. And then update the discriminator parameters. And then use this and do a certain number of iterations to train the discriminator network for some steps.","70b0fb01":"## Training Procedure","b1dc0c5a":"From this problem we don't need labels","24493732":"## Train DCGAN model","ead75807":" ### Untrained generator to create an image.\n \n Create a seed or a vector of random noise. We'll  create a normally distibuted noised image.","de9bf36c":"## Building the Discriminator Network for DCGAN\nNOTE: The discriminator is a CNN-based image classifier.","4843e7b5":"## Loading and Preprocessing the Data"}}