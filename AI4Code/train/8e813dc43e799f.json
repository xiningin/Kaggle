{"cell_type":{"bf8f8039":"code","454177ea":"code","eed155bb":"code","256f1c3f":"code","29f163b9":"code","a24a15f3":"code","d98bc4ee":"code","691cd76c":"code","981be549":"code","d5cb91c3":"code","4cf17cbd":"code","613f27c6":"code","d4f7e081":"code","7c95917b":"code","4d6d19e3":"code","f74f89f6":"code","d277a4b4":"code","1be03379":"code","6b28d6e7":"code","db373da8":"code","31235174":"code","f0f94d5d":"code","88072e92":"code","0dd2bf18":"code","eb520adc":"code","0cef62dd":"code","cdea58ca":"code","5ef900ff":"code","dd35e384":"code","5dc97c60":"code","10afff7f":"code","9e731c6b":"code","b17cd91d":"code","a9376b10":"code","d169650b":"code","cac8e11f":"code","1a7c9828":"code","16fafeed":"code","8edb7223":"code","a2d0cbc5":"code","43ccd63b":"code","31dca19a":"code","c20bccf8":"code","935a399d":"code","e8c31de0":"code","baa13aeb":"code","0ad00120":"code","27c7adf1":"code","8e39810b":"code","41aa1690":"code","31a317eb":"code","4172debf":"code","de505bc0":"code","f796e4d3":"code","b3bcf4a8":"code","fcba0df9":"code","fd93372b":"code","12d24707":"code","e9e05038":"code","3a5682a5":"code","7196caed":"code","ba710adf":"code","f4dc4995":"markdown","6a7f487e":"markdown","8ce83a04":"markdown","d0eb21c7":"markdown","a23d0996":"markdown","516621b4":"markdown","d864c147":"markdown","bc4e6811":"markdown","fd270ebd":"markdown","7746e821":"markdown","4c5f79fe":"markdown","b22f7f04":"markdown","a247331e":"markdown","ea2fc22b":"markdown","b94f9a9a":"markdown","3bb3fd92":"markdown","f8e867aa":"markdown","b40f5ed4":"markdown","5dc323c1":"markdown","8a70ba62":"markdown","9cb92417":"markdown","c78f4702":"markdown","8b8d3829":"markdown","4bddae99":"markdown","4ecb2ee0":"markdown","2f8c27ec":"markdown","3e525f0a":"markdown","42b6caae":"markdown","6bef1fc8":"markdown","8374a9ef":"markdown","e4d3e104":"markdown","837b617c":"markdown","e26a1a6f":"markdown","dc101b42":"markdown","5de26aac":"markdown","0a731707":"markdown","9c95c4fa":"markdown","c69e4031":"markdown","5e2102b3":"markdown","2d1893e8":"markdown"},"source":{"bf8f8039":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","454177ea":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","eed155bb":"print(\" Train data shape :\" , train.shape)\nprint(\" Test data shape :\", test.shape)","256f1c3f":"pd.set_option(\"display.max_columns\", None)\npd.set_option(\"Display.max_rows\", None)","29f163b9":"train.head()","a24a15f3":"train.tail()","d98bc4ee":"train.describe()","691cd76c":"train.info()","981be549":"import matplotlib.pyplot as plt\nplt.style.use(style='ggplot')\nplt.rcParams['figure.figsize']=(10,6)","d5cb91c3":"train.SalePrice.describe()","4cf17cbd":"print(\" Skew is : \", train.SalePrice.skew())","613f27c6":"plt.hist(train.SalePrice, color=\"r\");","d4f7e081":"target = np.log(train.SalePrice)\nprint(\" Skew is :\", target.skew())","7c95917b":"plt.hist(target, color = \"blue\");","4d6d19e3":"numeric_features = train.select_dtypes(include=[np.number])\nnumeric_features.dtypes\n","f74f89f6":"numeric_features.values","d277a4b4":"\nnumeric_features.isnull().sum()","1be03379":"numeric_features.isnull().sum().sum()","6b28d6e7":"corr = numeric_features.corr()\ncorr.head()\n","db373da8":"print(corr[\"SalePrice\"].sort_values(ascending = False)[:5], \"\\n\")\n\n","31235174":"\nprint(corr[\"SalePrice\"].sort_values(ascending = False)[-5:])","f0f94d5d":"train.OverallQual.unique()","88072e92":"quality_pivot = train.pivot_table(index=\"OverallQual\", values=\"SalePrice\", aggfunc = np.median)\nquality_pivot","0dd2bf18":"quality_pivot.plot(kind = \"bar\", color = \"blue\");\nplt.xlabel(\"Overall Quality\")\nplt.ylabel(\"Median Sale Price\")\nplt.xticks(rotation = 0);","eb520adc":"plt.scatter(x=train['GrLivArea'], y=target);\n\nplt.ylabel(\" SalePrice\")\nplt.xlabel(\"Above grade (ground) living area square feet\"); \n\n\n","0cef62dd":"plt.scatter(x=train['GarageArea'], y = target);\nplt.xlabel(\"GArage Area\")\nplt.ylabel(\" Sale Price\")","cdea58ca":"train = train[train['GarageArea'] < 1200 ]\ntrain.head()","5ef900ff":"plt.scatter(x=train[\"GarageArea\"], y=np.log(train.SalePrice));\nplt.xlim(-200,1600) # This forces the same scale as before\nplt.ylabel(\" Sale Price\")\nplt.xlabel(\" Garage Area\");\n","dd35e384":"nulls = train.isnull().sum()\nnulls","5dc97c60":"nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending = False)[:25])\nnulls","10afff7f":"nulls.columns  = ['Null Count']","9e731c6b":"nulls.index.name = 'Feature'\nnulls","b17cd91d":"print(\" Unique values are :\", train.MiscFeature.unique())","a9376b10":"categoricals = train.select_dtypes(exclude=[np.number])\ncategoricals.describe()","d169650b":"\ncategoricals.head()","cac8e11f":"print(train.Street.value_counts(), \" \\n\")\n","1a7c9828":"train['enc_street'] = pd.get_dummies(train.Street, drop_first =True )\ntest['enc_street'] = pd.get_dummies(train.Street, drop_first = True )","16fafeed":"print(\"Encoded : \\n\")\n\nprint(train.enc_street.value_counts())","8edb7223":"condition_pivot = train.pivot_table(index = 'SaleCondition', values='SalePrice',)\n#                                     condition_pivot.plot=kind='bar',color = \"r\")\ncondition_pivot","a2d0cbc5":"condition_pivot.plot(kind='bar',color = \"r\");\nplt.xlabel(\"Sale condition\")\nplt.ylabel(\"Median sale Price\")\nplt.xticks(rotation=0);\n","43ccd63b":"def encode(x):\n    return 1 if x == 'Partial' else 0\ntrain['enc_condition'] = train.SaleCondition.apply(encode)\ntest['enc_condition'] = test.SaleCondition.apply(encode)\n\n","31dca19a":"condition_pivot = train.pivot_table(index = 'enc_condition', values='SalePrice',aggfunc=np.median)\n#                                     condition_pivot.plot(kind='bar',color = \"r\"))\n\ncondition_pivot.plot(kind='bar',color = \"r\");\nplt.xlabel(\"Encoded Sale condition\")\nplt.ylabel(\"Median sale Price\")\nplt.xticks(rotation=0);\n","c20bccf8":"data = train.select_dtypes(include=[np.number]).interpolate().dropna()\ndata.head()","935a399d":"data.isnull().sum()","e8c31de0":"data.isnull().sum().sum()","baa13aeb":"y = np.log(train.SalePrice)\nX = data.drop(['SalePrice','Id'], axis=1)","0ad00120":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=.33)","27c7adf1":"from sklearn import linear_model\n\nlr = linear_model.LinearRegression()","8e39810b":"lr","41aa1690":"model= lr.fit(X_train, y_train)\nmodel","31a317eb":"print(\"R squared id :\\n \", model.score(X_test,y_test))","4172debf":"predictions = model.predict(X_test)\npredictions","de505bc0":"from sklearn.metrics import mean_squared_error\nprint(\" RMSE is : \\n \", mean_squared_error(y_test, predictions))","f796e4d3":"actual_values = y_test\n\nplt.scatter(predictions, actual_values, alpha=.7, color='b') # alpha shows overlapping data\n\nplt.xlabel(\"Predicted Price\")\nplt.ylabel(\"Actual Price\")\nplt.title(\" Linear Regression model\")\nplt.show()","b3bcf4a8":"for i in range (-2, 3):\n    alpha = 10**i\n    rm = linear_model.Ridge(alpha=alpha)\n    ridge_model = rm.fit(X_train, y_train)\n    preds_ridge = ridge_model.predict(X_test)\n\n    plt.scatter(preds_ridge, actual_values, alpha=.75, color='b')\n    plt.xlabel('Predicted Price')\n    plt.ylabel('Actual Price')\n    plt.title('Ridge Regularization with alpha = {}'.format(alpha))\n    overlay = 'R^2 is: {}\\nRMSE is: {}'.format(\n                    ridge_model.score(X_test, y_test),\n                    mean_squared_error(y_test, preds_ridge))\n    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n    plt.show()","fcba0df9":"submission = pd.DataFrame()\nsubmission['Id'] = test.Id","fd93372b":"feats = test.select_dtypes(include=[np.number]).drop(['Id'], axis = 1).interpolate()","12d24707":"predictions = model.predict(feats)\npredictions","e9e05038":"final_predictions = np.exp(predictions)","3a5682a5":"print(\"Original Predictions are : \\n\", predictions[:5], \"\\n\")\nprint(\" Final Predictions are : \\n\", final_predictions[:5])","7196caed":"submission[\"SalePrice\"] = final_predictions\n\nsubmission.head()","ba710adf":"submission.to_csv(\"Submission1.csv\", index=False)","f4dc4995":"\nWe will first create a Linear Regression model. First, we instantiate the model.","6a7f487e":"Try to improve the model\nWe\u2019ll next try using Ridge Regularization to decrease the influence of less important features. Ridge Regularization is a process which shrinks the regression coefficients of less important features.","8ce83a04":"we see that increases in living area correspond to increases in price. We will do the same for GarageArea","d0eb21c7":"# Thanks","a23d0996":"# ***Make a submission***","516621b4":"**2. Shape of Data**","d864c147":"6.1.The DataFrame.corr() method displays the correlation (or relationship) between the columns. \nWe\u2019ll examine the correlations between the features and the target.","bc4e6811":"We\u2019ll fill the missing values with an average value and then assign the results to data. This is a method of interpolation. The DataFrame.interpolate() method makes this simple.","fd270ebd":"3.5.datasets info","7746e821":"3.3. last 5 rows","4c5f79fe":"3.4. dataset description","b22f7f04":"We can view this relationship graphically with a scatter plot.","a247331e":"Next, we need to fit the model.","ea2fc22b":"**7. Handling Null Values**","b94f9a9a":"**6.Working with Numeric Features**","3bb3fd92":"4.1. Target variable describe","f8e867aa":"3.2. First 5 rows","b40f5ed4":"4.2. Skewness","5dc323c1":"\nThe mean_squared_error function takes two arrays and calculates the rmse","8a70ba62":"**9.Transforming and engineering features**","9cb92417":"Let\u2019s take a look at one of the other columns, MiscFeature. \nWe\u2019ll use the Series.unique() method to return a list of the unique values.","c78f4702":"**8. Wrangling the non-numeric Features**","8b8d3829":"**Begin modelling**","4bddae99":"We will create a new dataframe with some outliers removed.","4ecb2ee0":"3.1. show all datasets","2f8c27ec":"Evaluate the performance and visualize results","3e525f0a":"Let\u2019s try engineering another feature. We\u2019ll look at SaleCondition by constructing and plotting a pivot table, as we did above for OverallQual.","42b6caae":"Next, we\u2019ll consider rmse","6bef1fc8":"**4.Explore the data and engineer features**","8374a9ef":"We create a new column called enc_street. The pd.get_dummies() method will handle this for us","e4d3e104":"Notice that the median sales price strictly increases as Overall Quality increases.\n\nNext, let\u2019s use plt.scatter() to generate some scatter plots and visualize the relationship between the Ground Living Area GrLivArea and SalePrice.","837b617c":"visualize this pivot table more easily, we can create a bar plot using the Series.plot() method","e26a1a6f":"**3. Train Dataset info**","dc101b42":"create a pivot table to further investigate the relationship between OverallQual and SalePrice","5de26aac":"Now we\u2019ll transform the predictions to the correct form. Remember that to reverse log() we do exp().\nSo we will apply np.exp() to our predictions becasuse we have taken the logarithm previously.","0a731707":"Dig deeper on OverallQual. We can use the .unique() method to get the unique values.","9c95c4fa":" **1. Read Dataset using pandas**","c69e4031":"**train_test_split() returns four objects:**","5e2102b3":"**8.Build a linear model**","2d1893e8":"4.3. log for, A value closer to 0 means that we have improved the skewness of the data. "}}