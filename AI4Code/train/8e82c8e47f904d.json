{"cell_type":{"98abd9d8":"code","9b82f5dc":"code","f0d5eb9a":"code","45a7b09d":"code","a7af8278":"code","8bdf7d56":"code","0bef641e":"code","939b0476":"code","8e43ba1b":"code","a28027ed":"code","ad698003":"code","477c908c":"code","933b2f30":"code","8c1bb6ff":"code","29043d52":"code","c0b59138":"code","5ffc3412":"code","19a76509":"code","39d68861":"code","b7a75387":"code","3d838039":"code","29d82156":"code","619ff8b3":"code","bd70fc80":"code","2ae16fd7":"code","3292d7f8":"code","21de98de":"code","892e24c7":"code","e2e0f7ca":"code","45831006":"code","e7f31159":"code","fb7a7666":"code","677a2ee6":"code","7a82b2a8":"code","310fe831":"code","a388f76d":"code","2d7cecc6":"code","03c1f69a":"code","a8755fac":"markdown","b07fb20d":"markdown","c8d21350":"markdown","408dd6e9":"markdown","70b4dde4":"markdown","2bd47907":"markdown","ab800dca":"markdown","b55fd78f":"markdown","5be36219":"markdown","9bb79735":"markdown","1194acb9":"markdown","80417726":"markdown","369cb58b":"markdown","d3bff2cb":"markdown","37f599ff":"markdown","2b81c21d":"markdown","7103d292":"markdown","a5fa3117":"markdown","b22ef6b8":"markdown","5a334bf5":"markdown","8baf7b8d":"markdown","318078a3":"markdown","ff7d1701":"markdown","7d4be0a5":"markdown","ccb92970":"markdown","d7c7f903":"markdown","afde9a89":"markdown"},"source":{"98abd9d8":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport os, time, random\n\nimport tensorflow as tf\nfrom PIL import Image\nfrom skimage import io\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#########################\n# DL Libraries\n#########################\nfrom keras.layers import Input, Conv2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, MaxPooling2D\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomFlip, RandomZoom, Rescaling\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nfrom keras import backend as K","9b82f5dc":"## set seed for producing same results\n# seed = 2020\n# np.random.seed(seed)\n# tf.random.set_seed(seed)\n# os.environ['PYTHONHASHSEED'] = str(seed)\n# os.environ['TF_DETERMINISTIC_OPS'] = '1'","f0d5eb9a":"dir_path='..\/input\/chest-xray-pneumonia\/chest_xray\/'\n\ntrain_path = dir_path+'train\/'\nvalid_path = dir_path+'val\/'\ntest_path = dir_path+'test\/'","45a7b09d":"### check number of train, valid and test images \nlabels = ['NORMAL', 'PNEUMONIA']\n\ndef check_ims_in_folder(labels):\n    '''returns tuples of images in each folder'''\n    train_ims_normal = os.listdir(train_path+labels[0]+'\/')\n    train_ims_pneumonia = os.listdir(train_path+labels[1]+'\/')\n    \n    valid_ims_normal = os.listdir(valid_path+labels[0]+'\/')\n    valid_ims_pneumonia = os.listdir(valid_path+labels[1]+'\/')\n    \n    test_ims_normal = os.listdir(test_path+labels[0]+'\/')\n    test_ims_pneumonia = os.listdir(test_path+labels[1]+'\/')\n    \n    return (train_ims_normal, train_ims_pneumonia), (valid_ims_normal, valid_ims_pneumonia), (test_ims_normal, test_ims_pneumonia)","a7af8278":"(train_im_n, train_im_p), (valid_im_n, valid_im_p), (test_im_n, test_im_p) = check_ims_in_folder(labels)\n\n\nindex = np.arange(6) + 0.15\nprint (index)\nlabels_bar = ['Train_im_N', 'Train_im_P', 'Valid_im_N', 'Valid_im_P', 'Test_im_N', 'Test_im_P']\n\nfig=plt.figure(figsize=(8, 4))\nsns.barplot(x=index, y=[len(train_im_n), len(train_im_p), len(valid_im_n), len(valid_im_p), len(test_im_n), len(test_im_p)], palette=\"viridis\")\nplt.xticks(index, labels_bar, rotation='vertical')\nplt.show()\n\nprint ('train_im_N: ', len(train_im_n))\nprint ('train_im_P: ', len(train_im_p))\nprint ('valid_im_N: ', len(valid_im_n))\nprint ('valid_im_P: ', len(valid_im_p))\nprint ('test_im_N: ', len(test_im_n))\nprint ('test_im_P: ', len(test_im_p))","8bdf7d56":"tot_normal_train = len(train_im_n) + len(valid_im_n) \ntot_pneumonia_train = len(train_im_p) + len(valid_im_p)\nprint ('total normal xray images: ', tot_normal_train)\nprint ('total pneumonia xray images: ', tot_pneumonia_train)","0bef641e":"def check_im_size(folder, labels):\n    im_shape_x_lists_n = []\n    im_shape_x_lists_p = []\n    im_shape_y_lists_n = []\n    im_shape_y_lists_p = []\n    if folder=='val':\n        path = valid_path\n        normal = valid_im_n\n        pneumonia = valid_im_p\n    elif folder=='train':\n        path = train_path\n        normal = train_im_n\n        pneumonia = train_im_p\n    else:\n        path = test_path\n        normal = test_im_n\n        pneumonia = test_im_p\n    for i, img in enumerate(normal):\n        sample = os.path.join(path+labels[0]+'\/', img)\n        sample_img = Image.open(sample)\n        w, h = sample_img.size\n        im_shape_x_lists_n.append(w)\n        im_shape_y_lists_n.append(h)\n    for i, img in enumerate(pneumonia):\n        sample = os.path.join(path+labels[1]+'\/', img)\n        sample_img = Image.open(sample)\n        w, h = sample_img.size\n        im_shape_x_lists_p.append(w)\n        im_shape_y_lists_p.append(h)\n        \n    return im_shape_x_lists_n, im_shape_y_lists_n, im_shape_x_lists_p, im_shape_y_lists_p","939b0476":"im_shape_valid_x_n, im_shape_valid_y_n, im_shape_valid_x_p, im_shape_valid_y_p = check_im_size('val', labels)\nim_shape_train_x_n, im_shape_train_y_n, im_shape_train_x_p, im_shape_train_y_p = check_im_size('train', labels)\nim_shape_test_x_n, im_shape_test_y_n, im_shape_test_x_p, im_shape_test_y_p = check_im_size('test', labels)  ","8e43ba1b":"fig = plt.figure(figsize=(12, 8))\n\nfig.add_subplot(431)\nplt.hist(im_shape_valid_x_n)\nplt.title('X size: Valid Normal')\nfig.add_subplot(432)\nplt.hist(im_shape_valid_y_n)\nplt.title('Y size: Valid Normal')\nfig.add_subplot(433)\nplt.hist(im_shape_valid_x_p)\nplt.title('X size: Valid Pneumonia')\nfig.add_subplot(434)\nplt.hist(im_shape_valid_y_p)\nplt.title('Y size: Valid Pneumonia')\nfig.add_subplot(435)\nplt.hist(im_shape_train_x_n)\nplt.title('X size: Train Normal')\nfig.add_subplot(436)\nplt.hist(im_shape_train_y_n)\nplt.title('Y size: Train Normal')\nfig.add_subplot(437)\nplt.hist(im_shape_train_x_p)\nplt.title('X size: Train Pneumonia')\nfig.add_subplot(438)\nplt.hist(im_shape_train_y_p)\nplt.title('Y size: Train Pneumonia')\nfig.add_subplot(439)\nplt.hist(im_shape_test_x_n)\nplt.title('X size: Test Normal')\nfig.add_subplot(4,3, 10)\nplt.hist(im_shape_test_y_n)\nplt.title('Y size: Test Normal')\nfig.add_subplot(4,3, 11)\nplt.hist(im_shape_test_x_p)\nplt.title('X size: Test Normal')\nfig.add_subplot(4,3, 12)\nplt.hist(im_shape_test_y_p)\nplt.title('Y size: Test Normal')\nplt.tight_layout()\nprint (set(im_shape_valid_x_n), set(im_shape_valid_y_n))","a28027ed":"fig = plt.figure(figsize=(15, 10))\nnpics= 12\n\ncount = 1\ntrain_im_n_selected = random.sample(train_im_n, 12)\nfor i, img in enumerate(train_im_n_selected):\n    sample = os.path.join(train_path +labels[0]+'\/', img) \n    sample_img = Image.open(sample)   \n    sample_img = np.array(sample_img)\n    sample_img = sample_img\/255.0\n    ax = fig.add_subplot(int(npics\/3) , 4, count, xticks=[],yticks=[])   \n    plt.imshow(sample_img, cmap='gray')\n    plt.colorbar()\n    count +=1\nfig.suptitle('Normal X-Rays')\nplt.tight_layout()\nplt.show()\n\nprint ('check shape of an example image: ', sample_img.shape,)","ad698003":"fig = plt.figure(figsize=(15, 10))\nnpics= 12\n\ncount = 1\ntrain_im_p_selected = random.sample(train_im_p, 12)\nfor i, img in enumerate(train_im_p_selected):\n    sample = os.path.join(train_path +labels[1]+'\/', img) \n    sample_img = Image.open(sample)   \n    ax = fig.add_subplot(int(npics\/3), 4, count, xticks=[],yticks=[])   \n    plt.imshow(sample_img, cmap='gray')\n    count +=1\nfig.suptitle('Pneumonia X-Rays')\nplt.tight_layout()\nplt.show()","477c908c":"fig = plt.figure(figsize=(15, 15))\ncount=1\nfor i, img in enumerate(train_im_n_selected):\n    sample_one = os.path.join(train_path +labels[0]+'\/', img)\n    sample_img = Image.open(sample_one)   \n    sample_img = np.array(sample_img)\n    sample_img = sample_img\/255.0\n    sample_img_mean = np.mean(sample_img)\n    sample_img_std = np.std(sample_img)\n    new_sample_img = (sample_img - sample_img_mean)\/sample_img_std\n    ax = fig.add_subplot(int(npics\/2) , 3, count, yticks=[])\n    sns.histplot(new_sample_img.ravel(), \n             label=f'Pixel Mean A {np.mean(new_sample_img):.2f} & Std. A {np.std(new_sample_img):.2f}', kde=False, color='blue', bins=35, alpha=0.8)\n    sns.histplot(sample_img.ravel(), \n             label=f'Pixel Mean B {np.mean(sample_img):.2f} & Std. B {np.std(sample_img):.2f}', kde=False, color='red', bins=35, alpha=0.8)\n    plt.legend(loc='upper center', fontsize=9)\n    plt.title('Image Num: %s'% (img))\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('# Pixels in Image')\n    count +=1\nfig.suptitle('Pixel Intensity Distribution (Before & After Std.)')\nplt.tight_layout()\nplt.show()","933b2f30":"#### define a function that will be added as lambda layer later\ndef standardize_layer(tensor):\n    tensor_mean = tf.math.reduce_mean(tensor)\n    tensor_std = tf.math.reduce_std(tensor)\n    new_tensor = (tensor-tensor_mean)\/tensor_std\n    return new_tensor","8c1bb6ff":"target_size = (300, 300)\n\ninput_shape = (300, 300, 1)\n\nbatch_size = 64\n\n\nprint(\"Training Dataset.....\")\ntrain_dir = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/', \n                                                                image_size=target_size, \n                                                                batch_size=batch_size,\n                                                                shuffle=True,\n                                                                color_mode='grayscale',\n                                                                label_mode='binary')\n\n\n\nprint(\"Val Dataset....\")\nval_dir = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/', \n                                                              image_size=target_size, \n                                                              batch_size=batch_size,\n                                                              color_mode='grayscale',\n                                                              label_mode='binary')\n\nprint(\"Test Datast...\")\ntest_dir = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/', \n                                                               image_size=target_size, \n                                                               batch_size=batch_size, \n                                                               color_mode='grayscale',\n                                                               label_mode='binary')","29043d52":"num_elements = tf.data.experimental.cardinality(train_dir).numpy()\nprint (num_elements)\nnum_elements_val = tf.data.experimental.cardinality(val_dir).numpy()\nprint (num_elements_val)","c0b59138":"class_names = train_dir.class_names\nprint(class_names)","5ffc3412":"new_train_ds = train_dir.concatenate(val_dir)\n\nprint (new_train_ds, train_dir)\n\ntrain_size = int(0.8 * 83) # 83 is the elements in dataset (train + valid)\nval_size = int(0.2 * 83)\n    \ntrain_ds = new_train_ds.take(train_size)\nval_ds = new_train_ds.skip(train_size).take(val_size)\n\n\n#### check the dataset size back again \nnum_elements_train = tf.data.experimental.cardinality(train_ds).numpy()\nprint (num_elements_train)\nnum_elements_val_ds = tf.data.experimental.cardinality(val_ds).numpy()\nprint (num_elements_val_ds)","19a76509":"from tensorflow.keras import layers\n\nrescale_layer = tf.keras.Sequential([layers.experimental.preprocessing.Rescaling(1.\/255)])\n\ndata_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(),\n  layers.experimental.preprocessing.RandomRotation(10), \n  layers.experimental.preprocessing.RandomZoom(0.1)\n])\n\n\n### let's try something fancy \nfrom itertools import islice, count\n\ntrain_iter_35im, train_iter_35label = next(islice(train_ds, 35, None)) # access the 35th element (just a random check) from the iterator\n\n\n\nprint (train_iter_35im.shape, type(train_iter_35im))\nprint (train_iter_35label.shape)\n\n# train_iter_5im = tf.expand_dims(train_iter_5im, 0)\ntrain_iter_35label = train_iter_35label.numpy()\n\n\nplt.figure(figsize=(10, 10))\n\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    aug_img = data_augmentation(train_iter_35im)\n    plt.imshow(aug_img[0], cmap='gray')\n    plt.xlabel(class_names[np.argmax(train_iter_35label)], fontsize=13)\nplt.tight_layout()    \nplt.show()\n\nprint (aug_img.shape, aug_img[0].shape)","39d68861":"autotune = tf.data.AUTOTUNE ### most important function for speed up training\n\n\ntrain_data_batches = train_ds.cache().prefetch(buffer_size=autotune)\nvalid_data_batches = val_ds.cache().prefetch(buffer_size=autotune)\ntest_data_batches = test_dir.cache().prefetch(buffer_size=autotune)","b7a75387":"#### check the numbers again\nprint (train_data_batches, valid_data_batches)\n\nnum_elements_train_data_batches = tf.data.experimental.cardinality(train_data_batches).numpy()\nprint (num_elements_train_data_batches)","3d838039":"### check if the data batches work properly or not \n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_data_batches.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        #plt.title(class_names[labels[i]])\n        plt.title(class_names[labels[i].numpy().astype(\"uint8\")[0]])\n        plt.axis(\"off\")  ","29d82156":"## This cell was used to compile the baseline model\n### Cosine Decay was tested\n\nclass customCallbacks(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    self.epoch = epoch + 1\n    if self.epoch % 2 == 0:\n      print (\n          'epoch num {}, train loss: {}, validation loss: {}'.format(epoch, logs['loss'], logs['val_loss']))\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',  factor=0.2, patience=3, min_lr=1e-8, verbose=1)\n\n\n\n# mcp_save = ModelCheckpoint(filepath=\"best_model_weights.h5\",\n#                            save_best_only=True, save_weights_only=True, monitor='val_loss')\n\n\n\n## added after saving the best model  via val loss gives worse performance than the final step of the model \n\nmcp_save = ModelCheckpoint(filepath=\"best_model_weights.h5\",\n                           save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n\n\n\n##restore best weights added after 2nd training\nes = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n\n\n### added after 2nd training \n\nMETRICS = ['accuracy', \n           tf.keras.metrics.Precision(name='precision'), \n           tf.keras.metrics.Recall(name='recall'), \n           tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n          ]","619ff8b3":"freq_neg = tot_normal_train\/(tot_normal_train + tot_pneumonia_train)\nfreq_pos = tot_pneumonia_train\/(tot_normal_train + tot_pneumonia_train)\n\npos_weights = np.array([freq_neg])\nneg_weights = np.array([freq_pos])\n\nprint ('check positive weight: ', pos_weights, len(pos_weights))\nprint ('check negative weight: ', neg_weights)\n\n\ndef get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \"\"\"\n    Return weighted loss function given negative weights and positive weights.\n\n    Args:\n      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n    \n    Returns:\n      weighted_loss (function): weighted loss function\n    \"\"\"\n    def weighted_loss(y_true, y_pred):\n        \"\"\"\n        Return weighted loss value. \n\n        Args:\n            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n        Returns:\n            loss (float): overall scalar loss summed across all classes\n        \"\"\"\n        # initialize loss to zero\n        loss = 0.0\n\n        for i in range(len(pos_weights)): # we have only 1 class \n            # for each class, add average weighted loss for that class \n            loss += - (K.mean((pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon)) + \n                              (neg_weights[i] * (1-y_true[:, i]) * K.log(1-y_pred[:, i] + epsilon)) ) )\n        return loss\n    return weighted_loss","bd70fc80":"input_shape = (300, 300, 3)\n\ninception_resnet_v2 = InceptionResNetV2(\n    include_top=False,\n    weights=\"..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n    input_shape=input_shape)\n\ndef build_model():\n    inputs = Input((300, 300, 1))\n    \n    x = preprocess_input(inputs) # necessary as per keras documentation \n    x = layers.Lambda(rescale_layer)(x) # rescale incoming images\n    x = layers.Lambda(standardize_layer)(x) # standardize incoming images\n    x = layers.Lambda(data_augmentation)(x) # data augmentation layers\n    x = Conv2D(3, (3,3), padding='same')(x) \n    # this is to fool the network that instead of rgb image we passed grayscale image but still have shape 3 at last axis (none, x, x, 3). \n    \n    \n    \n    ###### InceptionResNetV2 + Some Top Layers\n    x = BatchNormalization()(x)\n    x = inception_resnet_v2(x)\n\n    x = MaxPooling2D((2, 2))(x)\n    x = Conv2D(256, (1, 1), activation=LeakyReLU())(x)\n    x = BatchNormalization()(x)\n    \n    x = Flatten()(x)\n    x = Dropout(0.75)(x)\n\n    x = Dense(256, activation=LeakyReLU())(x)\n    x = Dropout(0.80)(x)\n    x = BatchNormalization()(x)\n    \n    outputs = Dense(1, activation=\"sigmoid\")(x)\n    \n    model = Model(inputs, outputs)\n    \n#     model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n#                   loss=\"binary_crossentropy\", \n#                   metrics=METRICS)\n# added weighted cross entropy loss for the loss instead of \n# \"binary_crossentropy\"\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n                 loss=get_weighted_loss(pos_weights, neg_weights), \n                 metrics=METRICS)\n\n\n\n    \n    return model","2ae16fd7":"model = build_model()\nmodel.summary()","3292d7f8":"# #### check difference between numpy mean and tensorflow reduce mean \n# same essentially \n# check = np.random.random((2, 2, 3))\n# print ('original arr: ', check)\n# print ('numpy mean: ', np.mean(check))\n\n\n# Mean_check = tf.math.reduce_mean(check)\n# tf.print('tensorflow reduce mean:', Mean_check)\n","21de98de":"start_time = time.time()\nhistory = model.fit(train_data_batches, \n                    epochs=100, \n                    validation_data=valid_data_batches,\n                    callbacks=[mcp_save, es, reduce_lr])\n\nend_time = time.time()","892e24c7":"print ('total time taken: in Minutes', (end_time-start_time)\/60.)","e2e0f7ca":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nprecision = history.history['precision']\nval_precision = history.history['val_precision']\nrecall = history.history['recall']\nval_recall = history.history['val_recall']\n\n\nepochs = range(1, len(acc) + 1)\n\nfig = plt.figure(figsize=(12, 7))\nfig.add_subplot(221)\n\nplt.plot(epochs, acc, linestyle='--', label = \"Training acc\")\nplt.plot(epochs, val_acc, linestyle='-.', label = \"Validation acc\")\nplt.title(\"Training and validation acc\")\nplt.legend()\n\nfig.add_subplot(222)\nplt.plot(epochs, loss, linestyle='--', label = \"Training loss\", alpha=0.8)\nplt.plot(epochs, val_loss, linestyle='-.', label = \"Validation loss\", alpha=0.6)\nplt.title(\"Training and validation loss\")\nplt.legend()\n\nfig.add_subplot(223)\nplt.plot(epochs, precision, linestyle='--', label = \"Training Precision\", alpha=0.8)\nplt.plot(epochs, val_precision, linestyle='-.', label = \"Validation Precision\", alpha=0.6)\nplt.title(\"Training and validation Precision\")\n\nfig.add_subplot(224)\nplt.plot(epochs, recall, linestyle='--', label = \"Training Recall\", alpha=0.8)\nplt.plot(epochs, val_recall, linestyle='-.', label = \"Validation Recall\", alpha=0.6)\nplt.title(\"Training and validation Recall\")\n\nplt.show()","45831006":"model.evaluate(test_data_batches)","e7f31159":"#### check if the saved weights work fine or not \n\nmodel.load_weights(\"best_model_weights.h5\")\nmodel.evaluate(test_data_batches)","fb7a7666":"y_pred = model.predict(test_data_batches)\nprint ('check y_pred: ', y_pred[0:10])","677a2ee6":"#### set a different threshold \n\ny_pred_th = (y_pred > 0.75).astype(np.float32)\n#predicted_categories_th = tf.argmax(y_pred_th, axis=1)\n#print ('check predicted catagories: ', predicted_categories_th[0:10])\nprint (y_pred_th[0:10])","7a82b2a8":"true_categories = tf.concat([y for x, y in test_data_batches], axis=0)\nprint ('check true catagories: ', true_categories[0:10])","310fe831":"from sklearn.metrics import confusion_matrix\n#print(confusion_matrix(test.classes, pred > 0.7))\n#pd.DataFrame(classification_report(test.classes, pred > 0.7, output_dict=True))\ncm = confusion_matrix(y_pred_th, true_categories)","a388f76d":"plt.figure(figsize=(8,8))\nplt.title('CM for threshold 0.75')\nsns_hmp = sns.heatmap(cm, annot=True, xticklabels = [class_names[i] for i in range(len(class_names))], \n                      yticklabels = [class_names[i] for i in range(len(class_names))], fmt=\"d\")\nfig = sns_hmp.get_figure()","2d7cecc6":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(true_categories, y_pred)\nroc_auc = auc(fpr, tpr)\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0]) \nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","03c1f69a":"plt.figure(figsize=(16, 12))\nfor images, labels in test_data_batches.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        #plt.title(class_names[labels[i]])\n        \n        y_pred_batch = model.predict(tf.expand_dims(images[i], axis=0, ))\n        y_pred_75th = (y_pred_batch > 0.75).astype(np.uint8)\n        original_label = class_names[labels[i].numpy().astype(\"uint8\")[0]]\n        predicted_label = class_names[y_pred_75th[0].astype(\"uint8\")[0]]\n        plt.title(f'Original: {original_label}; Predicted: {predicted_label}')\n        plt.axis(\"off\")            ","a8755fac":"So the training data is imbalanced and we have more positive samples","b07fb20d":"### ImageDataGenerator Part \n\nThis part we don't add any augmentation. **Our idea is to use the GPU for augmentation.** \n\n1. Define augmentation layers as sequential. \n\n2. Target_size = (300, 300) # image size suitable for InceptionResNetV2\n\n3. Input_shape = (300, 300, 1)\n\n4. batch_size = 64 \n","c8d21350":"### Prepare for Prediction and Confusion Matrix","408dd6e9":"### Get the Class Names","70b4dde4":"#### Training and Validation (Loss & Accuracy)","2bd47907":"### Check Image Size Disrtibution (Each Folder)","ab800dca":"## Inference from 2nd Training \n\n**1. Saving the best model via lowest ```val_loss``` isn't the best strategy.**  \n\n**May need to define some other metrics like precision and recall.** \n\n## Inference from 3rd Training \n\n**2. Added necessary metrics like precision, recall but saving via ```val_prc``` still gives worse performance than the original model.** \n\n**Added ```restore_best_weights=True``` in EarlyStopping.**\n\n**Added ```val_loss``` as the saving strategy in the Checkpoint, after step 2**","b55fd78f":"**The sizes of the images vary over a wide range. So best option is to fix a size for all.** \n\n**Since we are using InceptionResNet, the input size we will consider is 300x300.** ","5be36219":"### Import Libraries","9bb79735":"### Inference from 3rd Training \n\n**1. There are a lot of false positive still. To reduce that I will try a weighted binary cross-entropy loss.** \n\nThe implementation is influenced from [AI for Medical Diagnosis course](https:\/\/www.coursera.org\/learn\/ai-for-medical-diagnosis\/home\/welcome). \nHighly recommend that course as it deals with the chest x-ray dataset too. \n","1194acb9":"### Check Some Images \n\nPneumonia and Normal (from training directory)","80417726":"#### Check the Number of Elements in Dataset (Train + Valid)","369cb58b":"### Standardization\n\nWe will adjust our image data such that the new mean of the data will be zero, and the standard deviation of the data will be 1.\n\nIn other words, the generator will replace each pixel value in the image with a new value calculated by subtracting the mean and dividing by the standard deviation. $\\frac{x_i\u2212\\mu}{\\sigma}$\n\nCheck the effect.... ","d3bff2cb":"**Number of Validation Images are too less**. \n\nTo deal with that we will later combine train and validation folders and then do a split. \n\nI have TensorFlow Dataset structure. ","37f599ff":"## Inference from 1st training \n1. Low number of files in validation data forlder (only 16), is useless to to validate this model. We add training and test data and then do a 15% split to create validation data. \n\n","2b81c21d":"### Build Model as Sequential \n\nAdd the augmentation layer, pre-processing layers and custom lambda layer. \n\nWe will use pre-trained InceptionResNetV2 with imagenet ","7103d292":"### Class Imbalance Data (Positive Samples >> Negative Samples)","a5fa3117":"### Prepare to Train the Network ","b22ef6b8":"### Merge Train and Valid Dataset and then Split\n\nThis is where we deal with low number of validation images by merging train and validation dataset and then split. ","5a334bf5":"### Check Label Distribution (Each Folder)","8baf7b8d":"### Pneumonia from X-rays\n\nAfter reading some online resources like [this one](https:\/\/www.wikidoc.org\/index.php\/Pneumonia_chest_x_ray), I see that general way to find Pneumonia is to search for opacity in chest x-rays. From the pics above, the images in general look opaque compared to normal x-rays. But it is also important to remember that, chest x-rays may not tell the whole story all the time and sometimes the visual result can be misleading.  ","318078a3":"### Weighted Cross-Entropy (Binary)","ff7d1701":"### Define the Augmentation as Sequential \n\n\nAlso plot the augmented images for an example training image","7d4be0a5":"## Inference from 1st training \n\n\n**1. We added train and validation dir files and then create a split (15%) to have bit more validaton files to evaluate the performance.**\n\n## Inference after 3rd Training \n\n**2. Use weighted binary cross-entropy loss to deal with high number of false positives. Influenced from [AI for Medical Diagnosis](https:\/\/www.coursera.org\/learn\/ai-for-medical-diagnosis\/home\/welcome) course**. \nThe idea behind this is that since we have lot more x-ray images with Pneumonia the model weights them heavy for wrong classification. So we shift this bias and try to force the model to weigh normal and pneumonia images as same.  \n\nTo quote from the course---\n\n> We can rewrite the overall average cross-entropy loss over the entire training set $\\mathcal{D}$ of size $N$ as follows: \n\n> $$\\mathcal{L}_{cross-entropy}(\\mathcal{D}) = - \\frac{1}{N}\\big( \\sum_{\\text{positive examples}} \\log (f(x_i)) + \\sum_{\\text{negative examples}} \\log(1-f(x_i)) \\big).$$\n\n> Using this formulation, we can see that if there is a large imbalance with fewer negative training images (normal), for example, then the loss will be dominated by the negative class (normal).\n","ccb92970":"## Check Test Set Predictions and Images","d7c7f903":"### Plot the ROC Curve ","afde9a89":"### Check Available Data"}}