{"cell_type":{"a04a3673":"code","be9ce68a":"code","5c527045":"code","3e40acb4":"code","ac3cc5a4":"code","afe0bac8":"code","9fe7fd7b":"code","36bdffd8":"code","7dbe7a75":"code","b292330b":"code","d45feabb":"code","b45d49c6":"code","a1dc85f1":"code","bc7d8057":"code","ba3fe11c":"code","ac559a3f":"code","28d3537f":"code","aa729d8c":"code","efcac009":"code","c0e4937c":"code","0b792a73":"code","292369a7":"code","1ca02e67":"code","8dfb5715":"code","a3a44098":"code","2f854f49":"code","0756bffc":"code","4466b19f":"code","e72d9afc":"code","38cdcffd":"code","bb683e26":"markdown"},"source":{"a04a3673":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","be9ce68a":"%%time\ntrain_data = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')","5c527045":"train_data.groupby(by='label').size()","3e40acb4":"IMG_SIZE = 28","ac3cc5a4":"from keras.utils import to_categorical\nimg_train = train_data.drop([\"label\"], axis=1).values.reshape(-1, IMG_SIZE, IMG_SIZE, 1).astype('float32')\nimg_label = to_categorical(train_data[\"label\"])\n\nimg_test = test_data.drop([\"id\"], axis=1).values.reshape(-1, IMG_SIZE, IMG_SIZE, 1).astype('float32')\n\nprint(\"img_train.shape = \", img_train.shape)\nprint(\"img_label.shape = \", img_label.shape)\nprint(\"img_test.shape = \", img_test.shape)","afe0bac8":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(img_train, img_label, test_size=0.15)\nprint(\"x_train.shape = \", x_train.shape)\nprint(\"y_train.shape = \", y_train.shape)\nprint(\"x_test.shape = \", x_test.shape)\nprint(\"y_test.shape = \", y_test.shape)","9fe7fd7b":"import keras\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Dropout, Flatten, add\nfrom keras.layers import Conv2D, Activation, MaxPooling2D, AveragePooling2D, BatchNormalization\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.utils import plot_model\nfrom keras.preprocessing. image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Dense, PReLU, Dropout\nfrom keras.models import Model\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\nfrom keras.optimizers import SGD, Adam","36bdffd8":"# model from https:\/\/www.kaggle.com\/anshumandec94\/6-layer-conv-nn-using-adam\ndef build_model(input_shape=(28, 28, 1), classes = 10):\n    input_layer = Input(shape=input_shape)\n    x = Conv2D(16, (3,3), strides=1, padding=\"same\", name=\"conv1\")(input_layer)\n    x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch1\")(x)\n    x = Activation('relu',name='relu1')(x)\n    x = Dropout(0.1)(x)\n    \n    x = Conv2D(32, (3,3), strides=1, padding=\"same\", name=\"conv2\")(x)\n    x = BatchNormalization(momentum=0.15, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch2\")(x)\n    x = Activation('relu',name='relu2')(x)\n    x = Dropout(0.15)(x)\n    x = MaxPooling2D(pool_size=2, strides=2, padding=\"same\", name=\"max2\")(x)\n    \n    x = Conv2D(64, (5,5), strides=1, padding =\"same\", name=\"conv3\")(x)\n    x = BatchNormalization(momentum=0.17, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch3\")(x)\n    x = Activation('relu', name=\"relu3\")(x)\n    x = MaxPooling2D(pool_size=2, strides=2, padding=\"same\", name=\"max3\")(x)\n    \n    x = Conv2D(128, (5,5), strides=1, padding=\"same\", name=\"conv4\")(x)\n    x = BatchNormalization(momentum=0.15, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch4\")(x)\n    x = Activation('relu', name=\"relu4\")(x)\n    x = Dropout(0.17)(x)\n    \n    x = Conv2D(64, (3,3), strides=1, padding=\"same\", name=\"conv5\")(x)\n    x = BatchNormalization(momentum=0.15, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch5\")(x)\n    x = Activation('relu', name='relu5')(x)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(32, (3,3), strides=1, padding=\"same\", name=\"conv6\")(x)\n    x = BatchNormalization(momentum=0.15, epsilon=1e-5, gamma_initializer=\"uniform\", name=\"batch6\" )(x)\n    \n    x = Activation('relu', name=\"relu6\")(x)\n    x = Dropout(0.05)(x)\n    \n    x = Flatten()(x)\n    x = Dense(50, name=\"Dense1\")(x)\n    x = Activation('relu', name='relu7')(x)\n    x = Dropout(0.05)(x)\n    x = Dense(25, name=\"Dense2\")(x)\n    x = Activation('relu', name='relu8')(x)\n    x = Dropout(0.03)(x)\n    x = Dense(classes, name=\"Dense3\")(x)\n    x = Activation('softmax')(x)\n\n    model = Model(inputs=input_layer, outputs=x)\n    return model","7dbe7a75":"model = build_model(input_shape=(28, 28, 1), classes = 10)","b292330b":"train_datagen = ImageDataGenerator(\n    rotation_range=9, \n    zoom_range=0.25, \n    width_shift_range=0.25, \n    height_shift_range=0.25,\n    rescale=1.\/255\n)\ntrain_datagen.fit(x_train)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\nadam = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nsgd = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\ncheckpoint = ModelCheckpoint(\"bestmodel.model\", monitor='val_acc', verbose=1, save_best_only=True)\nearlyStopping = EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='min')","d45feabb":"model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])","b45d49c6":"epochs = 80\nbatch_size = 128","a1dc85f1":"history = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_datagen.flow(x_test, y_test),\n    validation_steps=x_test.shape[0] \/\/ batch_size,\n    callbacks=[checkpoint, learning_rate_reduction])","bc7d8057":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\ndef PlotLoss(his, epoch):\n    plt.style.use(\"ggplot\")\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history[\"loss\"], label=\"train_loss\")\n    plt.plot(np.arange(0, epoch), his.history[\"val_loss\"], label=\"val_loss\")\n    plt.title(\"Training Loss\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss\")\n    plt.legend(loc=\"upper right\")\n    plt.show()\n\ndef PlotAcc(his, epoch):\n    plt.style.use(\"ggplot\")\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history[\"acc\"], label=\"train_acc\")\n    plt.plot(np.arange(0, epoch), his.history[\"val_acc\"], label=\"val_acc\")\n    plt.title(\"Training Accuracy\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend(loc=\"upper right\")\n    plt.show()","ba3fe11c":"PlotAcc(history, epochs)\nPlotLoss(history, epochs)","ac559a3f":"model.load_weights('bestmodel.model')","28d3537f":"results=model.predict(img_test\/255.0)","aa729d8c":"x2_train, x2_test, y2_train, y2_test = train_test_split(img_test, results, test_size=0.15)","efcac009":"x_train_final = np.concatenate((img_train,x2_train), axis=0)\ny_train_final = np.concatenate((img_label,y2_train), axis=0)","c0e4937c":"x_train, x_test, y_train, y_test = train_test_split(x_train_final, y_train_final, test_size=0.15)\nprint(\"x_train.shape = \", x_train.shape)\nprint(\"y_train.shape = \", y_train.shape)\nprint(\"x_test.shape = \", x_test.shape)\nprint(\"y_test.shape = \", y_test.shape)","0b792a73":"keras.backend.clear_session()","292369a7":"model2 = build_model(input_shape=(28, 28, 1), classes = 10)","1ca02e67":"sgd2 = SGD(lr=0.1, momentum=0.0, decay=0.0, nesterov=False)\nlearning_rate_reduction2 = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\ncheckpoint2 = ModelCheckpoint(\"bestmodel2.model\", monitor='val_acc', verbose=1, save_best_only=True)","8dfb5715":"model2.compile(loss='categorical_crossentropy', optimizer=sgd2, metrics=['acc'])","a3a44098":"history2 = model2.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_datagen.flow(x_test, y_test),\n    validation_steps=x_test.shape[0] \/\/ batch_size,\n    callbacks=[checkpoint2, learning_rate_reduction2])","2f854f49":"PlotAcc(history2, epochs)\nPlotLoss(history2, epochs)","0756bffc":"#model2.load_weights('bestmodel2.model')","4466b19f":"results=model2.predict(img_test\/255.0)\nresults=np.argmax(results, axis=1)\nsub=pd.DataFrame()\nsub['id']=list(test_data.values[0:,0])\nsub['label']=results","e72d9afc":"sub.head()","38cdcffd":"sub.to_csv(\"submission.csv\", index=False)","bb683e26":"[Pseudo-Labelling](https:\/\/lonepatient.top\/2017\/09\/29\/Semi-Supervised-learning-technique.html)"}}