{"cell_type":{"aa7370d6":"code","a8b05c3d":"code","0001a12e":"code","f99e7ca6":"code","37637177":"code","9c246c18":"code","1560d764":"code","e819403e":"code","0c8e7cb5":"code","ff9815a4":"code","74e36154":"code","32641238":"code","160a8b7e":"code","d0f4a729":"code","015d2ec2":"code","d8e25c0a":"code","5ff2cfa3":"code","9bc8a6b2":"markdown","7489f2c7":"markdown","72c10b91":"markdown","c3dd1f93":"markdown","4627a2f1":"markdown","b6121d45":"markdown","7d9b2635":"markdown","9315c1e0":"markdown","2d78a14b":"markdown"},"source":{"aa7370d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\"))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a8b05c3d":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nfrom PIL import Image\nnp.random.seed(123)\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,Conv2D,Activation,AveragePooling2D\n\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import DenseNet121\n\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import RMSprop\nfrom keras import regularizers\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n","0001a12e":"parasitized_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/')\nuninfected_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/')","f99e7ca6":"from skimage import transform\nimport cv2\nimageSize = (50,50,3)\ntrain_dir = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/' # This folder contains 10.000 images and 3 subfolders , each folder contains different number of images\n\nfrom tqdm import tqdm\ndef get_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in   ['Parasitized']:\n                label = 1\n            elif folderName in ['Uninfected']:\n                label = 0\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (50, 50))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X) # Keras only accepts data as numpy arrays \n    y = np.asarray(y)\n    return X,y\nX, y= get_data(train_dir)","37637177":"plt.imshow(X[0])\nplt.show()","9c246c18":"idx = np.arange(X.shape[0])\nnp.random.shuffle(idx)\nimage_data = X[idx]\nlabels = y[idx]","1560d764":"x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)","e819403e":"y_train = to_categorical(y_train, num_classes = 2)\ny_test = to_categorical(y_test, num_classes = 2)","0c8e7cb5":"x_train, x_validate, y_train, y_validate = train_test_split(x_train,y_train,test_size = 0.1)","ff9815a4":"input_shape = (50,50,3)\nn_classes = 2\nn_model = DenseNet121(weights='imagenet',input_tensor=None, include_top=False, input_shape=input_shape)\nmodel = Sequential()\nmodel.add(n_model)\nmodel.add(AveragePooling2D(pool_size=(1,1), name='avg_pool'))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu', name='dense_post_pool'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes, activation='sigmoid', name='predictions'))\nmodel.summary()","74e36154":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy','mae'])","32641238":"learning_rate_reduction = ReduceLROnPlateau(monitor='lr',  \n                                            factor=0.5, \n                                            min_lr=0.0001)","160a8b7e":"epochs = 10 \nbatch_size = 200\nhistory = model.fit(x_train,y_train, \n    batch_size=batch_size,\n    epochs=epochs,\n    validation_data=(x_validate,y_validate),\n    callbacks=[learning_rate_reduction]\n)","d0f4a729":"loss, acc, mae = model.evaluate(x_test, y_test)\nprint(\"The accuracy of the model is {:.3f}\\nThe Loss in the model is {:.3f}\\nThe Mean Absolute Error in the model is {:.3f}\".format(acc,loss,mae))","015d2ec2":"\ndef plot_model_history(model_history):\n    fig, axs = plt.subplots(1,3,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    #summarize History for MAE\n    axs[2].plot(range(1,len(model_history.history['mae'])+1),model_history.history['mae'])\n    axs[2].plot(range(1,len(model_history.history['val_mae'])+1),model_history.history['val_mae'])\n    axs[2].set_title('Model Mae')\n    axs[2].set_ylabel('MAE')\n    axs[2].set_xlabel('Epoch')\n    axs[2].set_xticks(np.arange(1,len(model_history.history['mae'])+1),len(model_history.history['mae'])\/10)\n    axs[2].legend(['train', 'val'], loc='best')\n    plt.show()\nplot_model_history(history)","d8e25c0a":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(x_validate)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_validate,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n\n \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2)) ","5ff2cfa3":"report = classification_report(Y_true, Y_pred_classes)\nprint(report)","9bc8a6b2":"**Monitoring learning Rate**","7489f2c7":"**Confusion Matrix**","72c10b91":"**Converting y_train and y_test in Categorical form(used for converting labels to one-hot-encoding) **","c3dd1f93":"**Classification Report**","4627a2f1":"Spliting Data for Training and Testing","b6121d45":"**Model Graph**","7d9b2635":"**Importing Data****","9315c1e0":"**Building Model (DenseNet121)**","2d78a14b":"***Showing Cell Image at Index 0***"}}