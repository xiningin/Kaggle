{"cell_type":{"2a69ff5f":"code","78b24b2c":"code","cae0d6fb":"code","7b38f750":"code","9671870e":"code","82833684":"code","4acacf81":"code","8a994296":"code","17a10ee2":"code","331b5203":"code","d51d54bb":"code","3c14756d":"code","56629045":"code","0f7f13df":"code","8160139f":"code","ad4a01df":"code","f69b9c6f":"code","15f52b57":"code","99121678":"code","b2029dd6":"code","506c7f84":"code","d6fc64e0":"code","e0a30fd1":"code","4e598891":"code","6255894c":"code","a8b784ba":"code","6d2bca79":"code","fd173498":"code","550d49c8":"code","30eb85f6":"code","4aede355":"code","d4415f80":"code","9cfe5424":"code","9c227843":"code","9e527e91":"code","2849333d":"code","2309acbe":"code","93685383":"code","150ac7e3":"code","eff1a030":"code","6955b41d":"code","9f23db50":"code","4ba036e6":"code","d284eb5b":"code","89770fb0":"code","8e4a142e":"code","76ca50e7":"code","aafc7e9c":"code","f221c0df":"code","2269e01a":"code","444b959d":"code","7b167edb":"code","a62b8463":"code","28b95870":"code","408244ab":"code","b4c7027c":"code","5968c97a":"code","e86439f5":"code","44f17119":"code","af0b487a":"code","e2a7dcd5":"code","9de72a93":"code","e6784c16":"code","f78ff8ac":"code","e894986b":"code","bd08ff99":"code","bad1e271":"code","b0ab16a2":"code","7ecbc5f1":"code","26efd07d":"code","d75e2842":"code","1eab7847":"code","58bb86e4":"code","63ae56b3":"code","007bb3a5":"code","3464c4f8":"code","5f9d3c08":"code","bcd7d7fd":"code","ba9e2010":"code","fc477c68":"code","3a537a35":"code","8dc80efd":"code","eb68c780":"code","59c99990":"code","da6f6050":"code","925f684a":"code","ada039f7":"code","559a453d":"code","bfe3b979":"code","b39909d2":"code","010408f0":"code","8fe6d20a":"code","061530e2":"code","34951a7d":"code","19ec393b":"code","6cd65af7":"code","31641d6d":"code","c66551a9":"code","afed5b88":"code","c93fff5a":"code","fcc25f53":"code","ccbc46ff":"code","6913cefd":"code","7bb727f5":"code","59bef0ce":"markdown","6bedfab4":"markdown","b3afc594":"markdown","44efb59e":"markdown","1782a485":"markdown","b59d0cc4":"markdown","c1fbf781":"markdown","6a170443":"markdown","0e133ea1":"markdown","f7b25b2d":"markdown","2d7330b8":"markdown","88a68dd7":"markdown","627a95f6":"markdown","239b1e7f":"markdown","534ee010":"markdown","6e9c7423":"markdown","080466e0":"markdown","1bba00c5":"markdown","bb6de1c1":"markdown","bbf7de4b":"markdown","0d5ee4fa":"markdown","56c09469":"markdown","fdc86f68":"markdown","5b403b00":"markdown","842d59d8":"markdown","62b0b83d":"markdown","9a918e52":"markdown","8e61a2c5":"markdown","a4cd4cb0":"markdown","6b19dc24":"markdown","44f49e79":"markdown","f5d75cf6":"markdown","14ca3686":"markdown","7c01cdc5":"markdown","d92cd5b4":"markdown","8d36f134":"markdown","40a909f7":"markdown","f52bdbd3":"markdown","a37ba60e":"markdown","f9e37298":"markdown","86f35053":"markdown","3db6285c":"markdown","b0914a0e":"markdown","b0b296cc":"markdown","83eaafca":"markdown","bf97b277":"markdown","2bbb7a29":"markdown","99a29a6d":"markdown","f429c925":"markdown","91ee0cee":"markdown","e7bb4d87":"markdown","c1c63cd1":"markdown","bbdb325b":"markdown","958882b3":"markdown","a8817a52":"markdown","28f53a9f":"markdown","fc4f9c2e":"markdown","4c4f10ae":"markdown","08dbb2cb":"markdown","2b8d5068":"markdown","96a7bb4b":"markdown","94f04894":"markdown","6d02b35b":"markdown","9671cdca":"markdown","a7356338":"markdown","61369c64":"markdown","ad5d9100":"markdown","b2d5d4ea":"markdown","c07404e9":"markdown","40fe1433":"markdown","8923b828":"markdown","920ca8e3":"markdown","38bae8f4":"markdown","9198d0d7":"markdown","21240052":"markdown","35ab8151":"markdown","eaa96ae1":"markdown","ef11cc62":"markdown","71879ed4":"markdown","3028b926":"markdown","2484f072":"markdown","993ee94b":"markdown","12b9f47f":"markdown","39f799a4":"markdown","7bc22855":"markdown","73fdb504":"markdown","f548440e":"markdown"},"source":{"2a69ff5f":"# For data analysis\nimport pandas as pd\nimport numpy as np\n\n#For data visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","78b24b2c":"# Set up the Titanic csv file as a DataFrame\n\ntrain_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")","cae0d6fb":"train_df.head()","7b38f750":"# General glimpse of the dataframe\n\ntrain_df.info()","9671870e":"#Statistical glimpse of the Dataframe\n\ntrain_df.describe()","82833684":"#Drop the \"Cabin\" Column\ntrain_df.drop(\"Cabin\", axis = 1, inplace = True)\n\n#Check the dataframe again to confirm that the column is dropped\ntrain_df.head(3)","4acacf81":"#Function that will grab the \"Mr\" from the name \"Braund, Mr. Owens harris\" and likewise for the whole column\ndef person_status(prefix):\n    \n    prefix = prefix.split(\".\")[0].split(\",\")[1].lstrip()\n    return prefix","8a994296":"#Creating a new column \"Prefix\" which will have all the values like \"Mr\", \"Mrs\", \"Miss\" etc...\ntrain_df[\"Prefix\"] = train_df[\"Name\"].apply(person_status)\n\ntrain_df.head()","17a10ee2":"#Check how many different prefixes we have\n\ntrain_df[\"Prefix\"].value_counts()","331b5203":"#For loop which will do the job for us\nfor prefix in range(len(train_df)):\n    if train_df[\"Prefix\"][prefix] not in [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]:\n        train_df[\"Prefix\"][prefix] = \"Misc\"\n        \ntrain_df[\"Prefix\"].value_counts()","d51d54bb":"def alone(number):\n    x,y = number\n    number = x+y\n    return number","3c14756d":"train_df[\"Family\"] = train_df[[\"SibSp\", \"Parch\"]].apply(alone, axis = 1)\n\n# Look for >0 or ==0 to set alone status\ntrain_df[\"Family\"].loc[train_df[\"Family\"]>0] = 1\ntrain_df[\"Family\"].loc[train_df[\"Family\"]==0] = 0\n\ntrain_df.head(3)","56629045":"titanic_copy = train_df.copy()\ntitanic_copy.head(3)","0f7f13df":"titanic_copy[\"Pclass\"].value_counts()","8160139f":"#Checking the survival\/death of the people travelling in different class\n\nax = sns.countplot(x=\"Pclass\", data=titanic_copy, hue = \"Survived\")\n\nfor p in ax.patches:\n        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))","ad4a01df":"titanic_copy[\"Sex\"].value_counts()","f69b9c6f":"#Checking the survival\/death of the people based on Gender\n\nax = sns.countplot(x=\"Sex\", data=titanic_copy, hue = \"Survived\")\n\nfor p in ax.patches:\n        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))","15f52b57":"# The distribution of the Age\ntitanic_copy[\"Age\"].plot(kind = \"hist\", bins= 5, figsize = (8,6))","99121678":"prefixes = [\"Mr\", \"Mrs\", \"Miss\", \"Master\", \"Misc\"]\n\nfor x in prefixes:\n    print(\"Prefix {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Prefix\"] == x][\"Age\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Prefix\"] == x][\"Age\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Prefix\"] == x][\"Age\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Prefix\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Age\", shade = True)\nfigure.add_legend()","b2029dd6":"family = [0,1]\n\nfor x in family:\n    print(\"Family {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Family\"] == x][\"Age\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Family\"] == x][\"Age\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Family\"] == x][\"Age\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Family\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Age\", shade = True)\nfigure.add_legend()","506c7f84":"pclass = [1,2,3]\n\nfor x in pclass:\n    print(\"Pclass {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Age\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Age\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Age\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Pclass\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Age\", shade = True)\nfigure.add_legend()","d6fc64e0":"sex = [\"male\", \"female\"]\n\nfor x in sex:\n    print(\"Sex {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Sex\"] == x][\"Age\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Sex\"] == x][\"Age\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Sex\"] == x][\"Age\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Sex\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Age\", shade = True)\nfigure.add_legend()","e0a30fd1":"age_df = pd.DataFrame(round(titanic_copy.groupby([\"Pclass\", \"Prefix\", \"Family\"])[\"Age\"].median(), 2))\nage_df.reset_index(inplace = True)\nage_df.head(3)","4e598891":"#Function that will compare the conditions of age_df with titanic_copy\ndef fill_age(row):\n    condition = (\n        (age_df['Pclass'] == row['Pclass']) & \n        (age_df['Prefix'] == row['Prefix']) & \n        (age_df['Family'] == row['Family'])\n    ) \n    return age_df[condition]['Age'].values[0]\n\n#Function that will fill up the null values if the conditions match for both the dataframes \ndef process_age():\n    global titanic_copy\n    # a function that fills the missing values of the Age variable\n    titanic_copy['Age'] = titanic_copy.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n    return titanic_copy\n\ntitanic_copy = process_age()\ntitanic_copy.info()","6255894c":"#Identify the missing values using Heatmap\nplt.figure(figsize=(8,10))\nsns.heatmap(titanic_copy.isnull())","a8b784ba":"titanic_copy.iloc[[61, 829]] #Locations where Embark values are missing","6d2bca79":"titanic_copy[\"Embarked\"].value_counts()","fd173498":"embark = [\"S\", \"C\", \"Q\"]\nc1 = titanic_copy[\"Pclass\"] == 1 \n\nfor x in embark:\n    c2 = titanic_copy[\"Embarked\"] == x\n    titanic_copy[c1 & c2]\n    print(\"Embarkment {}  and Pclass 1: Mean: {}, Median: {}, std: {}\".format(x,\n                                                                round(titanic_copy[c1 & c2][\"Fare\"].mean(),2),\n                                                                round(titanic_copy[c1 & c2][\"Fare\"].median(),2),\n                                                                round(titanic_copy[c1 & c2][\"Fare\"].std(),2)))","550d49c8":"titanic_copy[titanic_copy[\"Embarked\"]==\"Q\"][\"Pclass\"].value_counts()","30eb85f6":"titanic_copy.iloc[[61, 829], 10] = \"S\"\ntitanic_copy.info()","4aede355":"ax = sns.countplot(x = \"Embarked\", data = titanic_copy, hue = \"Survived\")\n\nfor p in ax.patches:\n        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))","d4415f80":"ax = sns.countplot(x = \"Embarked\", data = titanic_copy, hue = \"Pclass\")\n\nfor p in ax.patches:\n        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))","9cfe5424":"plott = sns.FacetGrid(titanic_copy, hue = \"Embarked\", aspect = 3, height = 6)\nplott.map(sns.kdeplot, \"Fare\", shade = True)\nplott.add_legend()","9c227843":"sns.catplot(x = \"Embarked\", y = \"Survived\", data = titanic_copy, hue = \"Pclass\", kind=\"point\")","9e527e91":"titanic_copy[\"Ticket\"].nunique()","2849333d":"titanic_copy[titanic_copy[\"Ticket\"] == \"CA. 2343\"]","2309acbe":"titanic_copy[titanic_copy[\"Ticket\"] == \"LINE\"]","93685383":"titanic_copy[titanic_copy[\"Ticket\"] == \"347077\"]","150ac7e3":"pclass = [1,2,3]\n\nfor x in pclass:\n    print(\"Pclass {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Fare\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Fare\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Pclass\"] == x][\"Fare\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Pclass\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Fare\", shade = True)\nfigure.add_legend()","eff1a030":"survival = [0,1]\n\nfor x in survival:\n    print(\"Survived {}- Mean: {}, Median: {}, Std: {}\".format(x,\n                                                        round(titanic_copy[titanic_copy[\"Survived\"] == x][\"Fare\"].mean(),2),\n                                                        round(titanic_copy[titanic_copy[\"Survived\"] == x][\"Fare\"].median(),2),\n                                                        round(titanic_copy[titanic_copy[\"Survived\"] == x][\"Fare\"].std(),2)))\n    \nfigure = sns.FacetGrid(titanic_copy, hue = \"Survived\", aspect=2, height =5)\nfigure.map(sns.kdeplot, \"Fare\", shade = True)\nfigure.add_legend()","6955b41d":"fig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(x = \"Pclass\", data = titanic_copy[titanic_copy[\"Fare\"] <= 8.05], hue = \"Survived\", ax = ax[0])\nsns.countplot(x = \"Survived\", data = titanic_copy[titanic_copy[\"Fare\"] <= 8.05], ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\n        \nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\n        \n","9f23db50":"c1 = titanic_copy[\"Fare\"] > 8.05\nc2 = titanic_copy[\"Fare\"] <= 14.25\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\n\nsns.countplot(x = \"Pclass\", data = titanic_copy[c1 & c2], hue = \"Survived\", ax = ax[0])\nsns.countplot(x = \"Survived\", data = titanic_copy[c1 & c2], ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))","4ba036e6":"c1 = titanic_copy[\"Fare\"] > 14.25\nc2 = titanic_copy[\"Fare\"] <= 60.29\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\n\nsns.countplot(x = \"Pclass\", data = titanic_copy[c1 & c2], hue = \"Survived\", ax = ax[0])\nsns.countplot(x = \"Survived\", data = titanic_copy[c1 & c2], ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))","d284eb5b":"fig, ax = plt.subplots(1,2, figsize = (15,5))\n\nsns.countplot(x = \"Pclass\", data = titanic_copy[titanic_copy[\"Fare\"] > 60.29], hue = \"Survived\", ax = ax[0])\nsns.countplot(x = \"Survived\", data = titanic_copy[titanic_copy[\"Fare\"] > 60.29 ], ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))","89770fb0":"#All the values which used here are based on the median values of \"Fare\" for different \"Pclass\"\ndef fare_bin(fare):\n    \n    if fare <= 8.05:\n        return \"bin1\"\n    elif fare > 8.05 and fare <= 14.25:\n        return \"bin2\"\n    elif fare > 14.25 and fare <= 60.29:\n        return \"bin3\"\n    else:\n        return \"bin4\"","8e4a142e":"titanic_copy[\"fare_bin\"] = titanic_copy[\"Fare\"].apply(fare_bin)\ntitanic_copy.head(3)","76ca50e7":"print(\"Mean: {}, Median: {}, Std: {}\".format(titanic_copy[titanic_copy[\"Family\"] == 0][\"Age\"].mean(),\n                                             titanic_copy[titanic_copy[\"Family\"] == 0][\"Age\"].median(),\n                                             titanic_copy[titanic_copy[\"Family\"] == 0][\"Age\"].std()))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[titanic_copy[\"Family\"] == 0][\"Survived\"], ax = ax[0])\nsns.countplot(titanic_copy[titanic_copy[\"Family\"] == 0][\"Sex\"], \n              hue=titanic_copy[titanic_copy[\"Family\"] == 0][\"Survived\"], \n              ax = ax[1])\n\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))","aafc7e9c":"print(\"Mean: {}, Median: {}, Std: {}\".format(titanic_copy[titanic_copy[\"Family\"] == 1][\"Age\"].mean(),\n                                             titanic_copy[titanic_copy[\"Family\"] == 1][\"Age\"].median(),\n                                             titanic_copy[titanic_copy[\"Family\"] == 1][\"Age\"].std()))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[titanic_copy[\"Family\"] == 1][\"Survived\"], ax = ax[0])\nsns.countplot(titanic_copy[titanic_copy[\"Family\"] == 1][\"Sex\"], \n              hue=titanic_copy[titanic_copy[\"Family\"] == 1][\"Survived\"], \n              ax = ax[1])\n\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))","f221c0df":"c1 = titanic_copy[\"SibSp\"]  == 0\nc2 = titanic_copy[\"Parch\"]  == 1\nprint(titanic_copy[c1 & c2].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[c1 & c2][\"Age\"].mean(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].median(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[c1 & c2][\"Survived\"], ax = ax[0])\nsns.countplot(titanic_copy[c1 & c2][\"Prefix\"], hue=titanic_copy[c1 & c2][\"Survived\"], ax= ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))","2269e01a":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"Parch\"]  == 0\nprint(titanic_copy[c1 & c2].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[c1 & c2][\"Age\"].mean(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].median(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[c1 & c2][\"Survived\"], ax = ax[0])\nsns.countplot(titanic_copy[c1 & c2][\"Prefix\"], hue=titanic_copy[c1 & c2][\"Survived\"], ax=ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))","444b959d":"c1 = titanic_copy[\"SibSp\"]  == 0\nc2 = titanic_copy[\"SibSp\"]  == 1\nc3 = titanic_copy[\"Parch\"]  == 1\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c2 & c3) | (c1 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c2 & c3) | (c1 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c2 & c3) | (c1 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c2 & c3) | (c1 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c2 & c3) | (c1 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c2 & c3) | (c1 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))","7b167edb":"c1 = titanic_copy[\"SibSp\"]  == 1 \nc2 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[c1 & c2].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[c1 & c2][\"Age\"].mean(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].median(),2),\n                                             round(titanic_copy[c1 & c2][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[c1 & c2][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[c1 & c2], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))","a62b8463":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"SibSp\"]  == 2\nc3 = titanic_copy[\"Parch\"]  == 3\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))","28b95870":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"SibSp\"]  == 3\nc3 = titanic_copy[\"Parch\"]  == 4\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\n","408244ab":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"SibSp\"]  == 4\nc3 = titanic_copy[\"Parch\"]  == 5\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\n","b4c7027c":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"SibSp\"]  == 5\nc3 = titanic_copy[\"Parch\"]  == 6\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\n","5968c97a":"c1 = titanic_copy[\"SibSp\"]  == 1\nc2 = titanic_copy[\"SibSp\"]  == 8\nc3 = titanic_copy[\"Parch\"]  == 9\nc4 = titanic_copy[\"Parch\"]  == 2\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\n","e86439f5":"c1 = titanic_copy[\"SibSp\"]  == 0\nc2 = titanic_copy[\"SibSp\"]  >= 2\nc3 = titanic_copy[\"Parch\"]  >= 3\nc4 = titanic_copy[\"Parch\"]  == 1\nprint(titanic_copy[(c1 & c3) | (c2 & c4)].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].mean(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].median(),2),\n                                             round(titanic_copy[(c1 & c3) | (c2 & c4)][\"Age\"].std(),2)))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[(c1 & c3) | (c2 & c4)][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[(c1 & c3) | (c2 & c4)], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.1))\n\n","44f17119":"c1 = titanic_copy[\"SibSp\"]  >= 2 \nc2 = titanic_copy[\"Parch\"]  == 0\nprint(titanic_copy[c1 & c2].shape)\n\nprint(\"Mean: {}, Median: {}, Std: {}\".format(titanic_copy[c1 & c2][\"Age\"].mean(),\n                                             titanic_copy[c1 & c2][\"Age\"].median(),\n                                             titanic_copy[c1 & c2][\"Age\"].std()))\n\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nsns.countplot(titanic_copy[c1 & c2][\"Survived\"], ax = ax[0])\nsns.countplot(x = \"Prefix\", data = titanic_copy[c1 & c2], hue = \"Survived\", ax = ax[1])\n\nfor p in ax[0].patches:\n        ax[0].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.2))\nfor p in ax[1].patches:\n        ax[1].annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+0.5))","af0b487a":"titanic_copy.iloc[437]","e2a7dcd5":"def group_size(cols):\n    SibSp = cols[0]\n    Parch = cols[1]\n    \n    if SibSp == 0 and Parch == 0:\n        return \"alone\"\n    elif SibSp == 0 and Parch == 1:\n        return \"parent_kid\"\n    elif SibSp == 1 and Parch == 0:\n        return \"bro_sis\"\n    elif (SibSp == 1 and Parch == 1) or (SibSp == 0 and Parch == 2):\n        return \"group_of_3\"\n    elif SibSp == 1 and Parch == 2:\n        return \"group_of_4\"\n    elif (SibSp == 1 and Parch == 3) or (SibSp == 2 and Parch == 2):\n        return \"group_of_5\"\n    elif (SibSp == 1 and Parch == 4) or (SibSp == 3 and Parch == 2):\n        return \"group_of_6\"\n    elif (SibSp == 1 and Parch == 5) or (SibSp == 4 and Parch == 2):\n        return \"group_of_7\"\n    elif (SibSp == 1 and Parch == 6) or (SibSp == 5 and Parch == 2):\n        return \"group_of_8\"\n    elif (SibSp == 1 and Parch == 9) or (SibSp == 8 and Parch == 2):\n        return \"group_of_11\"\n    elif (SibSp == 0 and Parch >= 3) or (SibSp >= 2 and Parch == 1):\n        return \"parent_kids\"\n    elif SibSp >= 2 and Parch == 0:\n        return \"bros_sises\"\n    else:\n        return \"unique\"\n       \n","9de72a93":"titanic_copy[\"Group_Size\"] = titanic_copy[[\"SibSp\", \"Parch\"]].apply(group_size, axis = 1)\ntitanic_copy.head(3)","e6784c16":"def age_group(Age):\n    \n    if Age <= 15: \n        return \"Child\"\n    elif Age > 15 and Age <= 30:\n        return \"Adult\"\n    elif Age > 30 and Age <=45:\n        return \"Senior\"\n    elif Age > 45 and Age <=60:\n        return \"Super_senior\"\n    else:\n        return \"Old\"","f78ff8ac":"titanic_copy[\"Age_Group\"] = titanic_copy[\"Age\"].apply(age_group)\ntitanic_copy.head(3)","e894986b":"required_df = titanic_copy.copy()\nrequired_df.head(3)","bd08ff99":"required_df.drop([\"Name\", \"Ticket\", \"Embarked\",\"Family\",\"SibSp\",\"Parch\"], axis =1, inplace = True)\nrequired_df.head(3)","bad1e271":"dummies = pd.get_dummies(required_df[[\"PassengerId\", \"Sex\", \"Prefix\",\"fare_bin\",\"Group_Size\",\"Age_Group\"]])\ndummies.head(3)","b0ab16a2":"required_df = pd.merge(required_df, dummies, on = \"PassengerId\")\nrequired_df.head(3)","7ecbc5f1":"print(\"Shape of required_df: {}\".format(required_df.shape))\nprint(\"Shape of required_df: {}\".format(dummies.shape))\n","26efd07d":"required_df.columns","d75e2842":"test_titanic = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_titanic.head()","1eab7847":"test_titanic.info()","58bb86e4":"#Family or Alone\n\ntest_titanic[\"Family\"] = test_titanic[[\"SibSp\", \"Parch\"]].apply(alone, axis = 1)\ntest_titanic[\"Family\"].loc[test_titanic[\"Family\"]>0] = 1\ntest_titanic[\"Family\"].loc[test_titanic[\"Family\"]==0] = 0\ntest_titanic.head(3)","63ae56b3":"#Creating a new column \"Prefix\" which will have all the values like \"Mr\", \"Mrs\", \"Miss\" etc...\ntest_titanic[\"Prefix\"] = test_titanic[\"Name\"].apply(person_status)\n\ntest_titanic.head()","007bb3a5":"for i in range(0, len(test_titanic)):\n    if test_titanic[\"Prefix\"][i] not in [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]:\n        test_titanic[\"Prefix\"][i] = \"Misc\"\ntest_titanic.head(3)","3464c4f8":"#All the values are filled up\n\nsum(test_titanic[\"Prefix\"].value_counts())","5f9d3c08":"# 1)\n\ntest_titanic.iloc[88]","bcd7d7fd":"#I would use the median value of all the Misc of the training dataset\n\nprint(titanic_copy[titanic_copy[\"Prefix\"] == \"Misc\"][\"Age\"].median())","ba9e2010":"test_titanic.iloc[88,4] = 44","fc477c68":"# 2)\n\ntest_titanic.iloc[339]","3a537a35":"#I would use the median value of all the Misc of the training dataset\n\ntitanic_copy[titanic_copy[\"Prefix\"] == \"Master\"][\"Age\"].median()","8dc80efd":"test_titanic.iloc[339,4] = 4","eb68c780":"#Replacing the Null values of \"Age\"\n\ndef fill_age(row):\n    condition = (\n        (age_df['Pclass'] == row['Pclass']) & \n        (age_df['Prefix'] == row['Prefix']) & \n        (age_df['Family'] == row['Family'])\n    ) \n    return age_df[condition]['Age'].values[0]\n\n\ndef process_age():\n    global test_titanic\n    # a function that fills the missing values of the Age variable\n    test_titanic['Age'] = test_titanic.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n    return test_titanic\n\ntest_titanic = process_age()","59c99990":"test_titanic.info()","da6f6050":"#Using the heatmap we can figure out the Missing Fare location\ntest_titanic.iloc[152]","925f684a":"#Simply used same Pclass to fill the value of Fare\n\ntitanic_copy[titanic_copy[\"Pclass\"] == 3][\"Fare\"].median()","ada039f7":"test_titanic.iloc[152,8] = 8.05","559a453d":"test_titanic.info()","bfe3b979":"#Group sizes\n\ntest_titanic[\"Group_Size\"] = test_titanic[[\"SibSp\", \"Parch\"]].apply(group_size, axis = 1)","b39909d2":"#Age_Group\n\ntest_titanic[\"Age_Group\"] = test_titanic[\"Age\"].apply(age_group)","010408f0":"#Fare Bins\n\ntest_titanic[\"fare_bin\"] = test_titanic[\"Fare\"].apply(fare_bin)","8fe6d20a":"test_titanic.head(3)","061530e2":"test_dummies = pd.get_dummies(test_titanic[[\"PassengerId\", \"Prefix\", \"Sex\",\"Age_Group\", \"Group_Size\", \"fare_bin\"]])\ntest_dummies.head(3)","34951a7d":"test_titanic = pd.merge(test_titanic, test_dummies, on = \"PassengerId\")\ntest_titanic.head(3)","19ec393b":"print(\"Shape of required_df: {}\".format(test_titanic.shape))\nprint(\"Shape of required_df: {}\".format(test_dummies.shape))","6cd65af7":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier ","31641d6d":"X = required_df[[\"Pclass\", \"Age\", 'fare_bin_bin2', 'fare_bin_bin3','fare_bin_bin4',\n                 \"Sex_male\", \"Prefix_Miss\", \"Prefix_Mr\",\"Prefix_Mrs\",\n                 'Group_Size_bro_sis', 'Group_Size_bros_sises', 'Group_Size_group_of_11', 'Group_Size_group_of_3', \n                 'Group_Size_group_of_4', 'Group_Size_group_of_5', 'Group_Size_group_of_6', 'Group_Size_group_of_7', \n                 'Group_Size_group_of_8', 'Group_Size_parent_kid', 'Group_Size_parent_kids']]\n                 \n\ny = required_df[\"Survived\"] ","c66551a9":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\nlogreg1 = LogisticRegression(solver=\"liblinear\")\nlogreg1.fit(X_train, y_train)\nlogreg1_pred = logreg1.predict(X_test)\n\n\nprint(classification_report(y_test, logreg1_pred))\nprint(confusion_matrix(y_test, logreg1_pred))\nprint(\"Accuracy score: {}\".format(accuracy_score(y_test, logreg1_pred)))\nprint(\"f1-score: {}\".format(f1_score(y_test, logreg1_pred)))","afed5b88":"param_grid = {\"penalty\": [\"l2\"],\n              \"C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n              \"solver\": [\"liblinear\", \"newton-cg\", \"sag\", \"lbfgs\", \"saga\"]}\ngrid_model = GridSearchCV(LogisticRegression(), param_grid, cv = 5, verbose =3)\ngrid_model.fit(X_train, y_train)\npred = grid_model.predict(X_test)","c93fff5a":"grid_model.best_params_","fcc25f53":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\nlogreg2 = LogisticRegression(solver=\"newton-cg\", C = 1, penalty = 'l2')\nlogreg2.fit(X_train, y_train)\nlogreg2_pred = logreg2.predict(X_test)\n\n\nprint(classification_report(y_test, logreg2_pred))\nprint(confusion_matrix(y_test, logreg2_pred))\nprint(\"Accuracy score: {}\".format(accuracy_score(y_test, logreg2_pred)))\nprint(\"f1-score: {}\".format(f1_score(y_test, logreg2_pred)))","ccbc46ff":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\nrandfor = RandomForestClassifier(n_estimators=100)\nrandfor.fit(X_train, y_train)\nrandfor_pred = randfor.predict(X_test)\n\n\nprint(classification_report(y_test, randfor_pred))\nprint(confusion_matrix(y_test, randfor_pred))\nprint(\"Accuracy score: {}\".format(accuracy_score(y_test, randfor_pred)))\nprint(\"f1-score: {}\".format(f1_score(y_test, randfor_pred)))","6913cefd":"XX_test = test_titanic[[\"Pclass\", \"Age\",'fare_bin_bin2', 'fare_bin_bin3','fare_bin_bin4',\n                 \"Sex_male\", \"Prefix_Miss\", \"Prefix_Mr\",\"Prefix_Mrs\",\n                 'Group_Size_bro_sis', 'Group_Size_bros_sises', 'Group_Size_group_of_11', 'Group_Size_group_of_3', \n                 'Group_Size_group_of_4', 'Group_Size_group_of_5', 'Group_Size_group_of_6', 'Group_Size_group_of_7', \n                 'Group_Size_group_of_8', 'Group_Size_parent_kid', 'Group_Size_parent_kids']]\n\nfinal_pred = logreg1.predict(XX_test)","7bb727f5":"submit_df = pd.DataFrame(index=test_titanic[\"PassengerId\"])\nsubmit_df[\"Survived\"] = final_pred\nsubmit_df.head()","59bef0ce":"So looking at the dataframe above and from the description of all the parameters already provided in the problem, the things which we can think of and correlate to survival\/death are \n\n1) Whether they were travelling alone or with Family or with Friends something like that and how many of them?                 \n2) People who had the same ticket number died together or few of them survived or what?                     \n3) We know the Gender of the person and whether they were travelling alone or not from SibSp and Parch but the ones who were      travelling alone were young\/old\/kids or what? \n\nOn a lighter note, all these things came to my mind after going through the dataframe several times and observing each and every parameter several times, too","6bedfab4":"# TEST FILE","b3afc594":"## [SibSp, Parch, Family] Together..................................................................................................","44efb59e":"## Ticket...........................................................................................................................................","1782a485":"There are 681 unique tickets have been distributed","b59d0cc4":"We oberve the same thing as group 6 in this particular group of 7","c1fbf781":"#### 10) Single Parent + Many kids ","6a170443":"## Application of Machine Learning Begins From Here","0e133ea1":"## Age..............................................................................................................................................","f7b25b2d":"#### 8) Group of 8 people (Mother+Father+ 6 Child )","2d7330b8":"## Sex..............................................................................................................................................","88a68dd7":"65% of the passangers travelling are male","627a95f6":"We can see how different \"Title\" affect the \"Age\" directly. We can clearly see that kids have been provided with \"Master\" title. So while filling up the null values of Age, this findings will be pretty helpful","239b1e7f":"Merging has performed Successfully","534ee010":"66% of the people survived of the total people travelling in this category.79% of the \"Mr\" died whereas 83% of \"Mrs\" and 67% \"Miss\" survived. 100% \"Master\" (Kids) survived. Important thing to consider","6e9c7423":"I analysed this more to see how it affects the death\/survival of the passanger. I used median values [60.29, 24.25, and 8.05] which we got above when analysing the data based on \"Pclass\"","080466e0":"Two things get crystal clear from all the plots above that                                                                     \n1) As the Fare increased the death rate decreased                                                                               \n2) Fare is definitely greatly correlated with Passanger Class","1bba00c5":"We can see all the different passanger classes over here. The death rate is still higher in Pclass 3. 71.5% of the people of Pclass 3 died whereas for the other two classes survival rate is higher than the death rate. If we see the overall death rate than it is 55%","bb6de1c1":"## Fare............................................................................................................................................","bbf7de4b":"74% of the total females survived whereas only 19% of the total males survived which aagin shows the huge impact of gender directly on survival\/death","0d5ee4fa":"So many passangers are travelling in the Pclass 3","56c09469":"Very few data points to perform any strong analysis. From the plot above we can see that 100% \"Mr\" died whereas 50% \"Mrs\" and 50% \"Miss\" Survived. Their survival chances decreased way lesser than above all the other possibilities","fdc86f68":"Passangers who are travelling in Class 3 have embarked from all the stations                                                   \nVery few people embarked from Queenstown in class 1 and 2              \nPeople who embarked from Cherbourg travelled in class 1 and 3            \nUltimately, there is no specific trend that I can see in this data","5b403b00":"#### We will start with \"Name\" column from which we can try to identify their status like \"Mr\", \"Mrs\", \"Miss\" etc....","842d59d8":"#### 9) Group of 11 people (Mother+Father+ 9 Child )","62b0b83d":"50%-50% chance of death\/survival when travelling with someone                                                                 \n73% of the male died while travelling with someone and 71% of the females survived while travelling with someone","9a918e52":"70% people died when travelling alone                                                                                          \nOut of total male population travelling alone, 84% males died                                                                 \nOut of total female population travelling alone, 78.5% females survived                                                        \nThe avg age of the person about 32 years","8e61a2c5":"Neither the trend is clear in the plot above. So I decided not to consider \"Embark\" parameter","a4cd4cb0":"So the major population onboard is in their 20's. Now we still need to fill up the remaining values of \"Age\". Now logically the parameters like \"Mr\/Mrs\/Miss..\" and \"travelling with family\/alone\" should help us to identify the ages. As Pclass is directly correlated with our target variable \"Survived\" I would also analyse whether Pclass has any affects on \"Age or not ","6b19dc24":"Similarly people have paid wide range of Fares who embarked from various stations","44f49e79":"Almost half of the people (~56%) travelling in Pclass 3 (Total 491) have bought the tickets which cost 8.05 or less and 79% of them died. 100% death rate for travelling in Pclass 1 and 2 with cheap tickets \n\nThe overall death rate is 79.6% when buying the tickets costing 8.05 or less","f5d75cf6":"#### 5) Group of 5 people (Mother+Father+3 Child )","14ca3686":"I have just kept the passanger Id column for ease of operation such as merging or joint or anything like that. Looking at the shape of both the dataframes it seems that merging is successfuly performed","7c01cdc5":"There are just two people who embarked from Queenstown so the data is not large enough to predict enough. Therefore, I will replace the null values with \"S\" as it has the lowest standard deviation in its values, as well as more data points, and close value to 80 as well","d92cd5b4":"With the most expensve tickets people travelling in Pclass 1 and therefore there survival chances are 74%. There are very few passangers from Pclass 2 and Pclass 3. But again Pclass 3 has the highest death rate that is 100%. Overall death rate is 32.8%","8d36f134":"#### Now I will try to perform Exploratory Data Analysis (EDA) little more for every single parameter here and do whatever modifications or cleansing it requires or I feel it requires","40a909f7":"Seems to be one family. Every one survived except one male kid. There is no correlation in these 3 examples of the ticket analysis","f52bdbd3":"### Analyse family size and type to correlate it with survival\/death","a37ba60e":"After summing the number of data, I figured out that there is one data point stil mising which did not fall in any of these categories and that is the only kind of data point exist in the dataframe. That is passanger id 437","f9e37298":"seems that there is only one such family exist who have 11 members in their family and the whole family died. there are just 7 records given in this training dataset so the other 4 data points has to be in the test dataset and probably they must have died as well ","86f35053":"There is no passanger from Pclass 1 over here                                                                               \nAlmost half of the Pclass 2 is here (47.8%) (86 out of 184)                                                                      \nDeath rate is 70% for Pclass 3 and 64% for Pclass 2. If we see the overall death rate than it is 65%","3db6285c":"There are very high chances of death in group of 6 which we can observe from the plot above","b0914a0e":"After thoroughly analysing the data and checking the records for different ticket numbers I found that there is no specific correlation that can be established which can eventually help to predict the Survival\/death of the passanger. So I will not consider the Ticket parameter in the future as well","b0b296cc":"As we see \"Mr\", \"Miss\", \"Mrs\", and \"Master\" the most frequent ones we will define all the other prefixes as \"Misc\"","83eaafca":"While computing the \"Age\" parameter I figured out that the way I have computed the ages in the train dataset doesn't exactly go for test datset as well. There are couple of rows which have different values than what we saw in the train dataset so I have to put the ages manually there","bf97b277":"1 means they are travelling with someone and 0 means they are travelling alone","2bbb7a29":"#### 2) Group of 2 (2 brothers OR 2 sisters OR Husband+Wife)","99a29a6d":"### People Not Travelling Alone","f429c925":"There is no such a huge difference in mean or median of these parameter....but still we would consider it as it might create a huge difference when combining the different parameters","91ee0cee":"Before trying to go for EDA I would just copy this original dataframe so that I don't make direct modifications to it and if I make any mistakes than it doesn't directly affect the original dataframe","e7bb4d87":"It is the whole Family and everyone died","c1c63cd1":"We can observe that alomst 72% of the population embarked from Southampton. Still I would try to use \"Fare\" and \"Pclass\" to see whether we can get any information from there or not","bbdb325b":"Now I just want to focus on the required columns and drop other ones. I will again make another copy of the dataframe so in case if I mess up nothing would change in \"titanic_copy\" dataframe","958882b3":"All these people are travelling alone. One of them survived","a8817a52":"seems that there is only one such family exist who have 8 members in their family and the whole family died. there are just 6 records given in this training dataset so the other two data points has to be in the test dataset and probably they must have died as well ","28f53a9f":"#### 4) Group of 4 people (Mother+Father+2 Child)","fc4f9c2e":"66% of the people who Embarked from \"S\" died. Logically Embarking should not affect the death rate but statistically it can","4c4f10ae":"Before you dive into my notebook, I would just like to give a brief introduction about myself. I am a petroelum engineer passionate about data analytics and data science. I am trying to learn everything step by step from Udemy and Coursera. In this project I have performed basic exploratory data analysis based on the knowledge acquired so far and implemented Logistic regression model to predict the survival\/death of the passenger. I have not performed anykind of hypertuning as I am still learning about the use of every single parameter of a particular model. Any minor\/major, constructuctive\/criticizing feedback will help me to learn more. So please feel free to comment whatever you feel. I hope this notebook helps everyone who is trying to learn data analytics and machine learning from the scratch. Thank you","08dbb2cb":"So from above we can see that the null values of \"Age\" column has been filled","2b8d5068":"64% of the people survived of the total people travelling in this category. 83% of the \"Mr\" died whereas 73% of \"Mrs\" and 85% \"Miss\" survived. 100% \"Master\" (Kids) survived. Important thing to consider","96a7bb4b":"66% of the people survived of the total people travelling in this category. 82% of the \"Mr\" died whereas 92% of \"Mrs\" and 82% \"Miss\" survived. 100% \"Master\" (Kids) survived. Important thing to consider","94f04894":"We can conclude from above plots that travelling alone was harmful for Males whereas it was beneficial for the women. Travelling with someone (may be family) increased survival chances of Males where reduced the survival of Females. Therefore, it is required to analyse the family size and its effect on survival\/death of a person. Overall, in any scenarion Females seem to have higher chances of survival than Males.","6d02b35b":"Here are the 2 locations where Embark values are missing","9671cdca":"Now combining Pclass, Prefix, and Family parameter to fill the null values of ages.....","a7356338":"## Embarked.........................................................................................................................................","61369c64":"24% passangers travelling in Pclass 3, 47% passangers travelling in Pclass 2, and 63% passangers travelling in Pclass 1 survived. This clearly indicates that the Passanger Class has direct impact on the survival\/death ","ad5d9100":"Although Fare is little wide spread, it is clear from the values above that Fare is directly proportional to the Passanger class which is significantly related to survival\/death of the passanger","b2d5d4ea":"## Pclass..............................................................................................................................................","c07404e9":"#### 7) Group of 7 people (Mother+Father+ 5 Child )","40fe1433":"#### 11) Brothers \/ Sisters","8923b828":"#### Now just to see how many are travelling alone and how many are travelling with somebody","920ca8e3":"Even it is statistically correlated with survival and death of the passanger. This plot simply suggest that paying more fare will lead you to your survival","38bae8f4":"I have worked on the test file seperately and not in combination of the train file just for my own ease","9198d0d7":"So there is no null values exist in the dataframe anymore","21240052":"#### 1) Group of 2 (mom+child, dad+child)","35ab8151":"67% Death Rate","eaa96ae1":"#### 6) Group of 6 people (Mother+Father+4 Child )","ef11cc62":"Creating Fare bins based on the analysis above","71879ed4":"We see that \"Age\" is missing few values, \"Cabin\" is missing most of the values, and \"Embarked\" is missing couple of values so we will try to fill up those values using certain parameters and methods later on. I neglected the column \"Cabin\" completely as it has more than 3\/4th values missing and guessing them might lead to erroneous predictions in future","3028b926":"### People Travelling Alone","2484f072":"#### 3) Group of 3 (mom+ 2 child, dad+ 2 child, mom + dad + child)","993ee94b":"\"Q\" seems to be promising with closer fare price to 80 and no standard deviation so let's see how did that become possible","12b9f47f":"Not a significant difference in the Age of a Male or Female and almost same Standard deviation for both of the Genders. So we will not consider this paramter to compute the Age","39f799a4":"Death rate is very high in this case which is 75% overall","7bc22855":"66% of the people survived of the total people travelling in this category.....80% of the \"Mr\" died whereas 80% of the \"Mrs\" survived and 67% of the \"Miss\" survived. Again 100% \"Master\" survived.  ","73fdb504":"We do see significant age difference in the people travelling in class 1 and 3. So we will consider Pclass while computing the age","f548440e":"I am going to define this record as \"Unique\" while creating the group sizes"}}