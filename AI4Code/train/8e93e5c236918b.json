{"cell_type":{"bd646309":"code","2dbb8125":"code","4f61f675":"code","57305ddd":"code","ed6136d0":"code","dfa41b23":"code","e772cd94":"code","2f5fc712":"code","7745e5ef":"code","ef2041ee":"code","7cb59776":"code","5a82e5e6":"code","45abe0d3":"code","f23b195d":"code","bbc0dbd9":"code","d624f4ba":"code","55d02afc":"code","664f859b":"code","f7af68dd":"code","46839388":"code","13a9935c":"code","091b165d":"code","89b9926c":"code","115a24f4":"code","7955df90":"code","f9bd6587":"code","dc2e3731":"code","ccd98c34":"code","a09bc1fb":"code","911a5b08":"code","5e7f70d1":"code","96c328df":"code","86dffd34":"code","360700c9":"code","e246e8b7":"code","4da02dd4":"code","0d8a4bc8":"code","6b446eb2":"code","caebdeb7":"code","b7c1f52b":"code","506a1b50":"code","4ff9b9ee":"code","73a64cc3":"code","76e8d52c":"code","ceb78b5a":"code","25543e9b":"code","cc45b97d":"code","1cb633d2":"code","c4d453fd":"code","7062ce52":"code","7c082929":"code","84c2692c":"code","a272b846":"code","07804410":"code","442731ee":"code","d3b41ea7":"code","46f0d564":"code","fc5440bb":"code","96169a11":"code","e1f7ea17":"code","5c101db4":"code","ed610df1":"code","21abfcdf":"code","1ddfdec5":"code","30445dc1":"code","80e7045d":"code","971258d5":"code","0368e526":"code","4c48488e":"code","dfc81194":"code","44bf3065":"code","ec819faa":"code","84e80f3b":"code","447050c8":"code","67b7e70a":"code","d9391dc5":"code","41f62779":"code","659b4956":"code","0b15cca6":"code","03ec2681":"code","e807fc6f":"code","c15ca6ae":"code","41c8b2fd":"code","2255d5a1":"code","7ca948be":"code","0eb10c12":"code","ef3f01dc":"code","dccadc0e":"code","872b1c80":"code","3a88dda0":"code","5b7431df":"code","b915ab19":"code","ecf6c6db":"code","1c38fc83":"code","e078bfd1":"code","a5d7e883":"code","661f4c81":"code","f3b1c7f8":"code","bde609af":"code","fc22b134":"code","f3034eaf":"code","1b0c5162":"code","3f31c9e8":"code","3faf244b":"code","b88d51ae":"code","a7485ebf":"code","e5ba39da":"code","3a74e05c":"code","cb5e9499":"code","9eebfa8e":"code","8e4257b2":"code","6828d62d":"code","248b8cd4":"code","dfb0ccfc":"code","8bae9910":"code","ce85a937":"code","9f5c596e":"code","3eca51d0":"code","54d397bf":"code","958bf044":"code","671b9419":"code","3cc37762":"code","1153d356":"code","43cfc407":"code","223450d5":"code","6d531cdc":"code","108ab6c5":"code","d2caad08":"code","fdd88d27":"code","9bfa07a6":"code","59f463d2":"code","4fb18947":"code","81af70ef":"code","a69e15ce":"code","e2c55193":"code","6201a48a":"code","68196fa8":"code","a3d5aa89":"code","a4b57a37":"code","8811fbd9":"code","6d277784":"code","e0100c90":"markdown","75c91c07":"markdown","f2757db4":"markdown","facac25a":"markdown","850711db":"markdown","a324227e":"markdown","9460478d":"markdown","d0d3470f":"markdown","fef1f18b":"markdown","62756c6d":"markdown","1055501f":"markdown","150fb690":"markdown","18366e75":"markdown","71e19580":"markdown","e7654776":"markdown","be5e14d3":"markdown","5f21401e":"markdown","d38706ae":"markdown","82e1d8ac":"markdown","74fb4849":"markdown","28c6ff32":"markdown","817ae9c5":"markdown","b24053c5":"markdown","c4bf9f2d":"markdown"},"source":{"bd646309":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2dbb8125":"# visualization libraries\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12,8)})\nimport matplotlib.pyplot as plt\nplt.style.use('classic')\n%matplotlib inline\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport cufflinks as cf\ncf.go_offline()\ninit_notebook_mode(connected=True)\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\n# import function\nfrom sklearn.linear_model import LogisticRegression\n# peformance metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,GridSearchCV,RepeatedStratifiedKFold\nfrom yellowbrick.features import FeatureImportances\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA","4f61f675":"import warnings\nwarnings.filterwarnings('ignore')","57305ddd":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_df.sample(10)","ed6136d0":"train_df.info()","dfa41b23":"train_df.shape","e772cd94":"# Any null features\ntrain_df.isnull().sum() # Age, Cabin and Embarked fields have null values","2f5fc712":"# dropping the Id column\ntrain_df = train_df.drop('PassengerId',axis=1)","7745e5ef":"train_df.head()","ef2041ee":"train_df.describe().T","7cb59776":"train_df.Survived.value_counts()","5a82e5e6":"train_df.Pclass.value_counts()","45abe0d3":"train_df.Pclass.value_counts().plot.barh()","f23b195d":"sns.histplot(data=train_df, x=train_df[\"Pclass\"], hue=\"Survived\", multiple=\"dodge\", shrink=.8)","bbc0dbd9":"pd.crosstab(train_df[\"Survived\"],train_df[\"Pclass\"])","d624f4ba":"pd.crosstab(train_df[\"Pclass\"],train_df[\"Survived\"]).plot(kind=\"bar\", figsize=(10,6),  color=[\"salmon\", \"lightblue\"]);\nplt.title(\"Survived vs Passenger Class\")\nplt.xlabel(\"0 = No Survival, 1 = Survival\")\nplt.ylabel(\"PClass\")\nplt.legend([\"No Survival\", \"Survival\"])\nplt.xticks(rotation=0);","55d02afc":"train_df.Sex.value_counts()","664f859b":"train_df.Sex.value_counts().plot.barh()","f7af68dd":"sns.histplot(data=train_df, x=train_df[\"Sex\"], hue=\"Survived\", multiple=\"dodge\", shrink=.8)","46839388":"pd.crosstab(train_df[\"Survived\"],train_df[\"Sex\"])","13a9935c":"train_df.Age.isnull().sum()","091b165d":"train_df.Age.value_counts()","89b9926c":"sns.histplot(data=train_df, x=train_df[\"Age\"], binwidth=5 , kde=True)","115a24f4":"sns.violinplot(\"Survived\", \"Age\", data=train_df, palette=[\"lightblue\", \"lightpink\"]);","7955df90":"sns.displot(data=train_df, x='Age', hue='Survived', kind='kde', fill=True)","f9bd6587":"train_df.SibSp.value_counts()","dc2e3731":"train_df.SibSp.value_counts().plot.barh()","ccd98c34":"pd.crosstab(train_df[\"Survived\"],train_df[\"SibSp\"])","a09bc1fb":"train_df.Parch.value_counts()","911a5b08":"train_df.Parch.value_counts().plot.barh()","5e7f70d1":"pd.crosstab(train_df[\"Survived\"],train_df[\"Parch\"])","96c328df":"train_df.Ticket.value_counts()","86dffd34":"train_df = train_df.drop('Ticket',axis=1)","360700c9":"sns.histplot(data=train_df, x=train_df[\"Fare\"], binwidth=10 , kde=True)","e246e8b7":"LogFare = np.log(train_df.Fare + 1.0) # Adding 1 to accomodate zero fares : log(0) is not defined","4da02dd4":"# Histogram of LogFare\nLogFare.plot(kind='hist', color='c', bins=20);","0d8a4bc8":"sns.violinplot(\"Survived\", \"Fare\", data=train_df, palette=[\"lightblue\", \"lightpink\"]);","6b446eb2":"# box-whisker plot\ntrain_df.Fare.plot(kind='box')","caebdeb7":"train_df.Cabin.value_counts()","b7c1f52b":"train_df.Cabin.unique()","506a1b50":"train_df.Embarked.value_counts()","4ff9b9ee":"train_df.Embarked.value_counts().plot.barh()","73a64cc3":"# Function to extract the title from the name \ndef GetTitle(name):\n    first_name_with_title = name.split(',')[1]\n    title = first_name_with_title.split('.')[0]\n    title = title.strip().lower()\n    return title","76e8d52c":"# use map function to apply the function on each Name value row i\ntrain_df.Name.map(lambda x : GetTitle(x)) ","ceb78b5a":"train_df.Name.map(lambda x : GetTitle(x)).unique()","25543e9b":"# Function to extract the title from the name \ndef GetTitle(name):\n    title_group = {'mr' : 'Mr', \n               'mrs' : 'Mrs', \n               'miss' : 'Miss', \n               'master' : 'Master',\n               'don' : 'Sir',\n               'rev' : 'Sir',\n               'dr' : 'Officer',\n               'mme' : 'Mrs',\n               'ms' : 'Mrs',\n               'major' : 'Officer',\n               'lady' : 'Lady',\n               'sir' : 'Sir',\n               'mlle' : 'Miss',\n               'col' : 'Officer',\n               'capt' : 'Officer',\n               'the countess' : 'Lady',\n               'jonkheer' : 'Sir',\n               'dona' : 'Lady'\n                 }\n    first_name_with_title = name.split(',')[1]\n    title = first_name_with_title.split('.')[0]\n    title = title.strip().lower()\n    return title_group[title]","cc45b97d":"# create Title feature\ntrain_df['Title'] =  train_df.Name.map(lambda x : GetTitle(x))","1cb633d2":"# binning\npd.qcut(train_df.Fare, 4)","c4d453fd":"pd.qcut(train_df.Fare, 4, labels=['very_low','low','high','very_high']) # discretization","7062ce52":"# create fare bin feature\ntrain_df['Fare_Bin'] = pd.qcut(train_df.Fare, 4, labels=['very_low','low','high','very_high'])","7c082929":"# AgeState based on Age\ntrain_df['AgeState'] = np.where(train_df['Age'] >= 18, 'Adult','Child')","84c2692c":"# AgeState Counts\ntrain_df['AgeState'].value_counts()","a272b846":"train_df.groupby(['Pclass']).Fare.median()","07804410":"train_df.groupby(['Pclass']).Age.median()","442731ee":"train_df.groupby(['Pclass'])['Fare','Age'].median()","d3b41ea7":"train_df.groupby(['Pclass']).agg({'Fare' : 'mean', 'Age' : 'median'})","46f0d564":"# pivot table\ntrain_df.pivot_table(index='Sex',columns = 'Pclass',values='Age', aggfunc='mean')","fc5440bb":"# Family : Adding Parents with Siblings\ntrain_df['FamilySize'] = train_df.Parch + train_df.SibSp + 1 # 1 for self","96169a11":"# explore the family feature\ntrain_df['FamilySize'].plot(kind='hist', color='c');","e1f7ea17":"train_df.dtypes","5c101db4":"train_df.plot.scatter(x='Age', y='Fare', color='c', title='scatter plot : Age vs Fare');","ed610df1":"train_df.pivot_table(index='Sex',columns = 'Pclass',values='Age', aggfunc='mean')","21abfcdf":"train_df.dtypes","1ddfdec5":"train_df = pd.get_dummies(train_df,columns=['Sex', 'Pclass','Title', 'Fare_Bin', 'Embarked','AgeState'])","30445dc1":"train_df.info()","80e7045d":"# drop columns\ntrain_df.drop(['Cabin','Name','Parch','SibSp'], axis=1, inplace=True)","971258d5":"#### the KNN Imptuer is a distance-based imputation method and it requires us to normalize our data. \nimputer = KNNImputer()\nscaler = MinMaxScaler()\ntrain_df = pd.DataFrame(scaler.fit_transform(train_df), columns = train_df.columns)\ntrain_df.head()","0368e526":"train_df.isnull().sum()","4c48488e":"imputer = KNNImputer(n_neighbors=5)\ntrain_df = pd.DataFrame(imputer.fit_transform(train_df),columns = train_df.columns)","dfc81194":"train_df.isnull().sum()","44bf3065":"X = train_df.drop('Survived',axis=1)\ny = train_df['Survived']","ec819faa":"X.head()","84e80f3b":"y","447050c8":"X.shape,y.shape","67b7e70a":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2, random_state=0)","d9391dc5":" X_train.shape, y_train.shape,X_test.shape, y_test.shape","41f62779":"# average survival in train and test\nprint ('mean survival in train : {0:.3f}'.format(np.mean(y_train)))\nprint ('mean survival in test : {0:.3f}'.format(np.mean(y_test)))","659b4956":"# create model\nmodel = LogisticRegression(random_state=0)","0b15cca6":"# train model\nmodel.fit(X_train,y_train)","03ec2681":"# evaluate model\nprint ('score for logistic regression - version 1 : {0:.2f}'.format(model.score(X_test, y_test)))","e807fc6f":"y_pred = model.predict(X_test)","c15ca6ae":"accuracy_score(y_test,y_pred)","41c8b2fd":"confusion_matrix(y_test,y_pred)","2255d5a1":"precision_score(y_test, y_pred)","7ca948be":"recall_score(y_test, y_pred)","0eb10c12":"print(classification_report(y_test,y_pred))","ef3f01dc":"# model coefficients\nmodel.coef_","dccadc0e":"print(X_train.columns)","872b1c80":"fig, ax = plt.subplots(figsize=(16, 14))\nvisualization = FeatureImportances(model)\nvisualization.fit(X, y)\nvisualization.poof()","3a88dda0":"for model in [LogisticRegression]:\n     skflr = model()\n     skf = StratifiedKFold(n_splits=10, random_state=42)\n     s = cross_val_score(skflr, X, y, scoring=\"roc_auc\", cv=skf)\n     print(\"Accuracy = \", s.mean())","5b7431df":"# Loads test data set\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","b915ab19":"test.head()","ecf6c6db":"test.drop([\"PassengerId\"], axis=1, inplace=True)","1c38fc83":"test.drop([\"Ticket\"], axis=1, inplace=True)","e078bfd1":"test.isnull().sum()","a5d7e883":"# create Title feature\ntest['Title'] =  test.Name.map(lambda x : GetTitle(x))\n\n# create fare bin feature\ntest['Fare_Bin'] = pd.qcut(test.Fare, 4, labels=['very_low','low','high','very_high'])\n\n# AgeState based on Age\ntest['AgeState'] = np.where(test['Age'] >= 18, 'Adult','Child')\n\n# AgeState Counts\ntest['AgeState'].value_counts()","661f4c81":"# Family : Adding Parents with Siblings\ntest['FamilySize'] = test.Parch + test.SibSp + 1 # 1 for self","f3b1c7f8":"test = pd.get_dummies(test,columns=['Sex', 'Pclass','Title', 'Fare_Bin', 'Embarked','AgeState'])\n\n# drop columns\ntest.drop(['Cabin','Name','Parch','SibSp'], axis=1, inplace=True)","bde609af":"test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\ntest.head()","fc22b134":"test = pd.DataFrame(imputer.fit_transform(test),columns = test.columns)\n\ntest.isnull().sum()","f3034eaf":"submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","1b0c5162":"submission.head()","3f31c9e8":"submission.info()","3faf244b":"# Create StratifiedKFold object.\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state= 40)\nval_acc = []\ntest_predictions = []\nsubmission_predictions = []\nmodel = LogisticRegression(random_state=0)","b88d51ae":"for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n    x_train_fold, x_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n    print('Fold', fold )\n    \n    model.fit(x_train_fold, y_train_fold)\n    \n    print(\"score : \",model.score(x_train_fold, y_train_fold))\n    \n    y_pred = model.predict(x_test_fold)\n    print(\"Validation score : \",accuracy_score(y_test_fold, y_pred))\n    \n    preds = model.predict(X_test)\n    test_predictions.append(preds)\n    \n    submission_preds = model.predict(test)\n    submission_predictions.append(submission_preds)\n    ","a7485ebf":"y_pred = np.mean(np.column_stack(test_predictions), axis=1)","e5ba39da":"y_pred = y_pred.astype('int32')\ny_test = y_test.astype('int32')","3a74e05c":"print(accuracy_score(y_test, y_pred))","cb5e9499":"submission_preds = np.mean(np.column_stack(submission_predictions), axis=1)\nsubmission_preds = submission_preds.astype('int32')","9eebfa8e":"submit_df =  pd.DataFrame({'PassengerId': submission['PassengerId'],\n                          'Survived': submission_preds})","8e4257b2":"submit_df.head(10)","6828d62d":"submit_df.to_csv('submission.csv',index=False)","248b8cd4":"classifier = GaussianNB()\nclassifier.fit(X_train, y_train)","dfb0ccfc":"y_pred = classifier.predict(X_test)","8bae9910":"accuracy_score(y_test,y_pred)","ce85a937":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","9f5c596e":"print(classification_report(y_test,y_pred))","3eca51d0":"test_preds = classifier.predict(test)\ntest_preds = test_preds.astype('int32')","54d397bf":"submission[\"Survived\"] = test_preds","958bf044":"submission","671b9419":"submission.to_csv('submission.csv',index=False) # 0.76794","3cc37762":"knc = KNeighborsClassifier()\nknc.fit(X_train, y_train)","1153d356":"knc.score(X_test, y_test)","43cfc407":"y_pred = knc.predict(X_test)","223450d5":"print(confusion_matrix(y_test,y_pred))","6d531cdc":"print(classification_report(y_test,y_pred))","108ab6c5":"test_preds = knc.predict(test)\ntest_preds = test_preds.astype('int32')","d2caad08":"submission[\"Survived\"] = test_preds","fdd88d27":"submission","9bfa07a6":"submission.to_csv('submission.csv',index=False) # 0.76794","59f463d2":"# LDA\nlda = LDA()\nlda.fit(X_train,y_train)","4fb18947":"y_pred=lda.predict(X_test)","81af70ef":"lda.score(X_test, y_test)","a69e15ce":"print(confusion_matrix(y_test,y_pred))","e2c55193":"print(classification_report(y_test,y_pred))","6201a48a":"test_preds = lda.predict(test)\ntest_preds = test_preds.astype('int32')","68196fa8":"submission[\"Survived\"] = test_preds","a3d5aa89":"submission","a4b57a37":"submission.to_csv('submission.csv',index=False) # 0.77511","8811fbd9":"# define model\nmodel = LDA()\n# define model evaluation method\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['solver'] = ['svd', 'lsqr', 'eigen']\n# define search\nsearch = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(X, y)\n# summarize\nprint('Mean Accuracy: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","6d277784":"# define model\nmodel =LDA(solver='lsqr')\n# define model evaluation method\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['shrinkage'] = np.arange(0, 1, 0.01)\n# define search\nsearch = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(X, y)\n# summarize\nprint('Mean Accuracy: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","e0100c90":"#### Objective","75c91c07":"### Libraries","f2757db4":"##### Fare","facac25a":"### Linear Discriminant Analysis","850711db":"### Loading the needed dataset","a324227e":"##### Cabin","9460478d":"##### Embarked","d0d3470f":"##### Parch","fef1f18b":"### Exploratory Data Analysis","62756c6d":"##### Pclass","1055501f":"### Stratified Crossvalidation","150fb690":"The goal is to predict which passengers survived the Titanic shipwreck","18366e75":"### Model Training and Evaluation","71e19580":"##### Ticket","e7654776":"Tuning LDA Hyperparameters solver and shrinkage with sklearn GridSearchCV\n\n\nAn important hyperparameter is the solver, which defaults to \u2018svd\u2018 but can also be set to other values for solvers that support the shrinkage capability","be5e14d3":"### Feature Selection","5f21401e":"### KNN","d38706ae":"###### Sex Feature","82e1d8ac":"### Naive Bayes","74fb4849":"### Logistic Regression","28c6ff32":"#### Univariate Analysis, Bivariate Analysis","817ae9c5":"##### SibSp","b24053c5":"Shows the features ranked according to the explained variance each feature contributes to the model. In this case the features are plotted against their relative importance, that is the percent importance of the most important feature","c4bf9f2d":"##### Age"}}