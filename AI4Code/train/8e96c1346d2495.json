{"cell_type":{"4d5d98a1":"code","35e240c9":"code","5d2461f0":"code","21117f29":"code","83e178f4":"code","81e6f266":"code","9bea640f":"code","f75d8945":"code","494c450d":"code","45e160a9":"code","23ed3727":"code","965eea7b":"code","175d7809":"code","1f032bea":"code","ae7eb77e":"code","de7eca9f":"code","119c15e1":"code","c4320510":"code","c0eae6b7":"code","1894dc93":"code","ac52a201":"code","a8f1431c":"code","e2ac9395":"code","accdbe20":"code","8e9388cc":"code","05e8ad8c":"code","2a55f414":"code","cec723dd":"code","2b97df08":"code","bb58290a":"code","e1c8743e":"code","e86d3813":"code","e9b08c4c":"markdown","9dfa64f3":"markdown","ce541aca":"markdown","8453bad8":"markdown","d1cd4bdd":"markdown","a287c59d":"markdown","cc6733ae":"markdown","905e10da":"markdown","991d2026":"markdown","b92ab570":"markdown","b38fcc66":"markdown","375309cf":"markdown","ef0cd207":"markdown","b62dd7b8":"markdown","c4c100f6":"markdown","484b63d1":"markdown"},"source":{"4d5d98a1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import VGG19","35e240c9":"disease_types=['COVID', 'non-COVID']\ndata_dir = '..\/input\/sarscov2-ctscan-dataset\/'\ntrain_dir = os.path.join(data_dir)","5d2461f0":"train_data = []\nfor defects_id, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head()","21117f29":"SEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head()","83e178f4":"plt.hist(train['DiseaseID'])\nplt.title('Frequency Histogram of Species')\nplt.figure(figsize=(12, 12))\nplt.show()","81e6f266":"IMAGE_SIZE = 64\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","9bea640f":"X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    if image is not None:\n        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n# Normalize the data\nX_Train = X_train \/ 255.\nprint('Train Shape: {}'.format(X_Train.shape))","f75d8945":"Y_train = train['DiseaseID'].values\nY_train = to_categorical(Y_train, num_classes=2)","494c450d":"BATCH_SIZE = 256\n\n# Split the train and validation sets \n#X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state=SEED)\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_train,Y_train,test_size=0.1,train_size=0.9)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train,test_size = 0.1,train_size =0.8)","45e160a9":"fig, ax = plt.subplots(1, 3, figsize=(15, 15))\nfor i in range(3):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i])\n    ax[i].set_title(disease_types[np.argmax(Y_train[i])])","23ed3727":"EPOCHS = 100\nSIZE=64\nN_ch=3","965eea7b":"def build_vgg():\n    vgg = VGG19(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = vgg(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(2,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","175d7809":"model = build_vgg()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('VGG19.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=2,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","1f032bea":"import keras\nfrom keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n#from keras.layers import BatchNormalization\nfrom keras.models import Model\n\nfrom keras import backend as K\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n#Normalize and reshape ============\n\n#Norm.\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train = X_train \/ 255\nX_test = X_test \/ 255\n\n# Reshape \nimg_width  = 64\nimg_height = 64\nnum_channels = 3 #channel 3\nX_train = X_train.reshape(X_train.shape[0], img_height, img_width, num_channels)\nX_test = X_test.reshape(X_test.shape[0], img_height, img_width, num_channels)\ninput_shape = (img_height, img_width, num_channels)\n# ========================\n#View a few images\n#plt.figure(1)\n#plt.subplot(221)\n#plt.imshow(x_train[42][:,:,0])\n\n#plt.subplot(222)\n#plt.imshow(x_train[420][:,:,0])\n\n#plt.subplot(223)\n#plt.imshow(x_train[4200][:,:,0])\n\n#plt.subplot(224)\n#plt.imshow(x_train[42000][:,:,0])\n#plt.show()\n\n\n# BUILD THE MODEL\n\n# # ================= #############\n# # Encoder\n#Let us define 4 conv2D, flatten and then dense\n# # ================= ############\n\nlatent_dim = 64 # Number of latent dim parameters\n\ninput_img = Input(shape=input_shape, name='encoder_input')\nx = Conv2D(32, 3, padding='same', activation='relu')(input_img)\nx = Conv2D(64, 3, padding='same', activation='relu',strides=(2, 2))(x)\nx = Conv2D(64, 3, padding='same', activation='relu')(x)\nx = Conv2D(64, 3, padding='same', activation='relu')(x)\n\nconv_shape = K.int_shape(x) #Shape of conv to be provided to decoder\n#Flatten\nx = Flatten()(x)\nx = Dense(32, activation='relu')(x)\n\n# Two outputs, for latent mean and log variance (std. dev.)\n#Use these to sample random variables in latent space to which inputs are mapped. \nz_mu = Dense(latent_dim, name='latent_mu')(x)   #Mean values of encoded input\nz_sigma = Dense(latent_dim, name='latent_sigma')(x)  #Std dev. (variance) of encoded input\n\n#REPARAMETERIZATION TRICK\n# Define sampling function to sample from the distribution\n# Reparameterize sample based on the process defined by Gunderson and Huang\n# into the shape of: mu + sigma squared x eps\n#This is to allow gradient descent to allow for gradient estimation accurately. \ndef sample_z(args):\n  z_mu, z_sigma = args\n  eps = K.random_normal(shape=(K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n  return z_mu + K.exp(z_sigma \/ 2) * eps\n\n# sample vector from the latent distribution\n# z is the labda custom layer we are adding for gradient descent calculations\n  # using mu and variance (sigma)\nz = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([z_mu, z_sigma])\n\n#Z (lambda layer) will be the last layer in the encoder.\n# Define and summarize encoder model.\nencoder = Model(input_img, [z_mu, z_sigma, z], name='encoder')\nprint(encoder.summary())\n\n# ================= ###########\n# Decoder\n#\n# ================= #################\n\n# decoder takes the latent vector as input\ndecoder_input = Input(shape=(latent_dim, ), name='decoder_input')\n\n# Need to start with a shape that can be remapped to original image shape as\n#we want our final utput to be same shape original input.\n#So, add dense layer with dimensions that can be reshaped to desired output shape\nx = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n# reshape to the shape of last conv. layer in the encoder, so we can \nx = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n# upscale (conv2D transpose) back to original shape\n# use Conv2DTranspose to reverse the conv layers defined in the encoder\nx = Conv2DTranspose(32, 3, padding='same', activation='relu',strides=(2, 2))(x)\n#Can add more conv2DTranspose layers, if desired. \n#Using sigmoid activation\nx = Conv2DTranspose(num_channels, 3, padding='same', activation='sigmoid', name='decoder_output')(x)\n\n# Define and summarize decoder model\ndecoder = Model(decoder_input, x, name='decoder')\ndecoder.summary()\n\n# apply the decoder to the latent sample \nz_decoded = decoder(z)\n\n\n# =========================\n#Define custom loss\n#VAE is trained using two loss functions reconstruction loss and KL divergence\n#Let us add a class to define a custom layer with loss\nclass CustomLayer(keras.layers.Layer):\n\n    def vae_loss(self, x, z_decoded):\n        x = K.flatten(x)\n        z_decoded = K.flatten(z_decoded)\n        \n        # Reconstruction loss (as we used sigmoid activation we can use binarycrossentropy)\n        recon_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n        \n        # KL divergence\n        kl_loss = -5e-4 * K.mean(1 + z_sigma - K.square(z_mu) - K.exp(z_sigma), axis=-1)\n        return K.mean(recon_loss + kl_loss)\n\n    # add custom loss to the class\n    def call(self, inputs):\n        x = inputs[0]\n        z_decoded = inputs[1]\n        loss = self.vae_loss(x, z_decoded)\n        self.add_loss(loss, inputs=inputs)\n        return x\n\n# apply the custom loss to the input images and the decoded latent distribution sample\ny = CustomLayer()([input_img, z_decoded])\n# y is basically the original image after encoding input img to mu, sigma, z\n# and decoding sampled z values.\n#This will be used as output for vae\n\n# =================\n# VAE \n# =================\nvae = Model(input_img, y, name='vae')\n\n# Compile VAE\nvae.compile(optimizer='adam', loss=None)\nvae.summary()\n\n# Train autoencoder\nvae.fit(X_train, None, epochs = 100, batch_size = 32,validation_split = 0.2)\n\n# =================\n# Visualize results\n# =================\n#Visualize inputs mapped to the Latent space\n#Remember that we have encoded inputs to latent space dimension = 2. \n#Extract z_mu --> first parameter in the result of encoder prediction representing mean\n\nmu, _, _ = encoder.predict(X_test)","ae7eb77e":"#model = load_model('..\/output\/kaggle\/working\/model.h5')\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","de7eca9f":"Y_pred = model.predict(X_val)\n\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\n\ncm = confusion_matrix(Y_true, Y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=disease_types, yticklabels=disease_types)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","119c15e1":"'''FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \nFN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\nTP = np.diag(confusion_matrix)\nTN = confusion_matrix.values.sum() - (FP + FN + TP)'''\n\nTN = cm[0][0]\nprint(TN)\nFN = cm[1][0]\n#print(FN)\nTP = cm[1][1]\n#print(TP)\nFP = cm[0][1]\n#print(FP)\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP\/(TP+FN)\nprint(TPR)\n# Specificity or true negative rate\nTNR = TN\/(TN+FP)\nprint(TNR)\n# Precision or positive predictive value\nPPV = TP\/(TP+FP)\nprint(PPV)\n# Negative predictive value\nNPV = TN\/(TN+FN)\n# Fall out or false positive rate\nFPR = FP\/(FP+TN)\nprint(FPR)\n# False negative rate\nFNR = FN\/(TP+FN)\nprint(FNR)\n# False discovery rate\nFDR = FP\/(TP+FP)\nprint(FDR)\n\n# Overall accuracy\nACC = (TP+TN)\/(TP+FP+FN+TN)\nprint(ACC)","c4320510":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c0eae6b7":"from skimage import io\nfrom keras.preprocessing import image\n#path='imbalanced\/Scratch\/Scratch_400.jpg'\nimg = image.load_img('..\/input\/sarscov2-ctscan-dataset\/COVID\/Covid (1010).png', grayscale=False, target_size=(64, 64))\nshow_img=image.load_img('..\/input\/sarscov2-ctscan-dataset\/COVID\/Covid (1010).png', grayscale=False, target_size=(200, 200))\ndisease_class=['Covid-19','Non Covid-19']\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\nx \/= 255\n\ncustom = model.predict(x)\nprint(custom[0])\n\nplt.imshow(show_img)\nplt.show()\n\na=custom[0]\nind=np.argmax(a)\n        \nprint('Prediction:',disease_class[ind])","1894dc93":"import os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","ac52a201":"# Download url of normal CT scans.\n\nurl = \"https:\/\/github.com\/hasibzunair\/3D-image-classification-tutorial\/releases\/download\/v0.2\/CT-0.zip\"\nfilename = os.path.join(os.getcwd(), \"CT-0.zip\")\nkeras.utils.get_file(filename, url)\n\n# Download url of abnormal CT scans.\nurl = \"https:\/\/github.com\/hasibzunair\/3D-image-classification-tutorial\/releases\/download\/v0.2\/CT-23.zip\"\nfilename = os.path.join(os.getcwd(), \"CT-23.zip\")\nkeras.utils.get_file(filename, url)\n\n# Make a directory to store the data.\nos.makedirs(\"MosMedData\")\n\n# Unzip data in the newly created directory.\nwith zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n    z_fp.extractall(\".\/MosMedData\/\")\n\nwith zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n    z_fp.extractall(\".\/MosMedData\/\")","a8f1431c":"import nibabel as nib\n\nfrom scipy import ndimage\n\n\ndef read_nifti_file(filepath):\n    \"\"\"Read and load volume\"\"\"\n    # Read file\n    scan = nib.load(filepath)\n    # Get raw data\n    scan = scan.get_fdata()\n    return scan\n\n\ndef normalize(volume):\n    \"\"\"Normalize the volume\"\"\"\n    min = -1000\n    max = 400\n    volume[volume < min] = min\n    volume[volume > max] = max\n    volume = (volume - min) \/ (max - min)\n    volume = volume.astype(\"float32\")\n    return volume\n\n\ndef resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 64\n    desired_width = 128\n    desired_height = 128\n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    # Compute depth factor\n    depth = current_depth \/ desired_depth\n    width = current_width \/ desired_width\n    height = current_height \/ desired_height\n    depth_factor = 1 \/ depth\n    width_factor = 1 \/ width\n    height_factor = 1 \/ height\n    # Rotate\n    img = ndimage.rotate(img, 90, reshape=False)\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\n\ndef process_scan(path):\n    \"\"\"Read and resize volume\"\"\"\n    # Read scan\n    volume = read_nifti_file(path)\n    # Normalize\n    volume = normalize(volume)\n    # Resize width, height and depth\n    volume = resize_volume(volume)\n    return volume","e2ac9395":"# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n# no CT-signs of viral pneumonia.\nnormal_scan_paths = [\n    os.path.join(os.getcwd(), \"MosMedData\/CT-0\", x)\n    for x in os.listdir(\"MosMedData\/CT-0\")\n]\n# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n# involvement of lung parenchyma.\nabnormal_scan_paths = [\n    os.path.join(os.getcwd(), \"MosMedData\/CT-23\", x)\n    for x in os.listdir(\"MosMedData\/CT-23\")\n]\n\nprint(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\nprint(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))","accdbe20":"# Read and process the scans.\n# Each scan is resized across height, width, and depth and rescaled.\nabnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\nnormal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n\n# For the CT scans having presence of viral pneumonia\n# assign 1, for the normal ones assign 0.\nabnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\nnormal_labels = np.array([0 for _ in range(len(normal_scans))])\n\n# Split data in the ratio 70-30 for training and validation.\nx_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\ny_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\nx_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\ny_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\nprint(\n    \"Number of samples in train and validation are %d and %d.\"\n    % (x_train.shape[0], x_val.shape[0])\n)","8e9388cc":"import random\n\nfrom scipy import ndimage\n\n\n@tf.function\ndef rotate(volume):\n    \"\"\"Rotate the volume by a few degrees\"\"\"\n\n    def scipy_rotate(volume):\n        # define some rotation angles\n        angles = [-20, -10, -5, 5, 10, 20]\n        # pick angles at random\n        angle = random.choice(angles)\n        # rotate volume\n        volume = ndimage.rotate(volume, angle, reshape=False)\n        volume[volume < 0] = 0\n        volume[volume > 1] = 1\n        return volume\n\n    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n    return augmented_volume\n\n\ndef train_preprocessing(volume, label):\n    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n    # Rotate volume\n    volume = rotate(volume)\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\n\ndef validation_preprocessing(volume, label):\n    \"\"\"Process validation data by only adding a channel.\"\"\"\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label","05e8ad8c":"# Define data loaders.\ntrain_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n\nbatch_size = 2\n# Augment the on the fly during training.\ntrain_dataset = (\n    train_loader.shuffle(len(x_train))\n    .map(train_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)\n# Only rescale.\nvalidation_dataset = (\n    validation_loader.shuffle(len(x_val))\n    .map(validation_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)","2a55f414":"import matplotlib.pyplot as plt\n\ndata = train_dataset.take(1)\nimages, labels = list(data)[0]\nimages = images.numpy()\nimage = images[0]\nprint(\"Dimension of the CT scan is:\", image.shape)\nplt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")","cec723dd":"def plot_slices(num_rows, num_columns, width, height, data):\n    \"\"\"Plot a montage of 20 CT slices\"\"\"\n    data = np.rot90(np.array(data))\n    data = np.transpose(data)\n    data = np.reshape(data, (num_rows, num_columns, width, height))\n    rows_data, columns_data = data.shape[0], data.shape[1]\n    heights = [slc[0].shape[0] for slc in data]\n    widths = [slc.shape[1] for slc in data[0]]\n    fig_width = 12.0\n    fig_height = fig_width * sum(heights) \/ sum(widths)\n    f, axarr = plt.subplots(\n        rows_data,\n        columns_data,\n        figsize=(fig_width, fig_height),\n        gridspec_kw={\"height_ratios\": heights},\n    )\n    for i in range(rows_data):\n        for j in range(columns_data):\n            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n            axarr[i, j].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n    plt.show()\n\n\n# Visualize montage of slices.\n# 4 rows and 10 columns for 100 slices of the CT scan.\nplot_slices(4, 10, 128, 128, image[:, :, :40])\n","2b97df08":"def get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model\n    # Build model.\nmodel = get_model(width=128, height=128, depth=64)\nmodel.summary()","bb58290a":"#Compile model.\ninitial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n    metrics=[\"acc\"],\n)\n\n# Define callbacks.\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"3d_image_classification.h5\", save_best_only=True\nearly_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n\n# Train the model, doing validation at the end of each epoch\nepochs = 100\nmodel.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=epochs,\n    shuffle=True,\n    verbose=2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)","e1c8743e":"ig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"loss\"]):\n    ax[i].plot(model.history.history[metric])\n    ax[i].plot(model.history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","e86d3813":"# Load best weights.\nmodel.load_weights(\"3d_image_classification.h5\")\nprediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\nscores = [1 - prediction[0], prediction[0]]\n\nclass_names = [\"normal\", \"abnormal\"]\nfor score, name in zip(scores, class_names):\n    print(\n        \"This model is %.2f percent confident that CT scan is %s\"\n        % ((100 * score), name)\n    )","e9b08c4c":"## Converting Labels to Categorical","9dfa64f3":"## Display images of COVID","ce541aca":"## Display images of non-COVID","8453bad8":"## Accuracy and Loss Curve","d1cd4bdd":"## 64*64 training images","a287c59d":"## VGG19","cc6733ae":"## Data Augmentation and Fitting Model ","905e10da":"## Randomize the order of training set","991d2026":"## Plot a histogram","b92ab570":"## Confusion Matrix","b38fcc66":"## Data","375309cf":"## Image Read and Resize Function","ef0cd207":"## Final Loss and Accuracy","b62dd7b8":"## Training Images","c4c100f6":"## Prediction from Image","484b63d1":"## Train Test Splitting"}}