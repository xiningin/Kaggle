{"cell_type":{"53daa41a":"code","67767533":"code","210276b8":"code","eadb8e68":"code","146f8251":"code","025a5e56":"code","8f9bea42":"code","948ebe55":"code","5c82bff1":"code","f27608a1":"code","63c8b7ef":"code","05207dc0":"code","4e8db32f":"code","e36db7ab":"code","be53b29a":"code","d935f361":"code","ef39012f":"code","d65d0ae8":"code","5ba82ea8":"code","d0771b6f":"code","7254cdfc":"code","0aa1c98b":"code","d2963215":"code","087f539e":"code","1e67f032":"code","d628b8e3":"code","ee9e13a1":"code","98f7d456":"code","9dbb565f":"code","2617cf31":"code","1d8041a9":"code","9f1adb1b":"code","6f105e25":"code","1145fcea":"code","527db72d":"code","6fb6f6dc":"code","27c7f934":"code","14975f72":"code","8bdeaa80":"code","883fc5fb":"code","f49c9875":"code","47031885":"code","bacd35c2":"code","41126091":"code","ed244c0d":"code","ae0162ce":"code","afbae628":"code","7faebe65":"code","fdedf55b":"code","c6bd25d6":"code","9ac11275":"code","35cc1d2a":"code","ab270fb2":"code","d74dab3b":"code","f24c2b93":"markdown","af299bbe":"markdown","7e926409":"markdown","5c3cd9aa":"markdown","1700692c":"markdown","d004805d":"markdown","7f45bdce":"markdown","604c6c44":"markdown","d943f769":"markdown","145e05d1":"markdown","2e87ae88":"markdown","2d17cc99":"markdown","889f379b":"markdown","025ede34":"markdown","63ee64ed":"markdown","a59ac2e6":"markdown","37d05e19":"markdown","0250dee7":"markdown","a7a3a4c3":"markdown","a2f7a7a4":"markdown","eba01201":"markdown","466b95fe":"markdown","6113c2e1":"markdown","9c93300f":"markdown","12f36271":"markdown","c6c084b0":"markdown","4ca7220d":"markdown","79aad19e":"markdown","82005432":"markdown","d9c1653a":"markdown","2ca5b3b7":"markdown","d4fcdb08":"markdown","62e4d20b":"markdown","899f0408":"markdown","efd0409b":"markdown","1b3bb755":"markdown","f8a55861":"markdown","c58107ae":"markdown","3f1f2e2a":"markdown","707600d6":"markdown","519a9077":"markdown","06229809":"markdown","a2f5ad26":"markdown","6b678556":"markdown","a8748301":"markdown","5b4cddd6":"markdown","4c03fb7a":"markdown","ea68dc73":"markdown","d523deb4":"markdown","2416294c":"markdown","0b00013a":"markdown","bf9346af":"markdown","ec518e01":"markdown","f7d231ac":"markdown","aaf68253":"markdown","1efb72d1":"markdown","408e2c96":"markdown","5d0a0b83":"markdown","9329ff15":"markdown","1033a096":"markdown","3816533a":"markdown","300d7f75":"markdown","ab04aa5b":"markdown"},"source":{"53daa41a":"from math import sqrt\nimport itertools\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV, cross_val_predict\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.base import BaseEstimator\nimport xgboost","67767533":"df = pd.read_csv('\/kaggle\/input\/fivethirtyeight-candy-power-ranking-dataset\/candy-data.csv')\ndf['competitorname'] = df.competitorname.apply(lambda l: l.replace('\u00d5', '\\''))","210276b8":"df[df.columns[1:-3]].agg(['sum','count'])","eadb8e68":"df[['sugarpercent', 'pricepercent']].describe().T","146f8251":"df.sort_values('winpercent', ascending=False)[:10]","025a5e56":"df.sort_values('winpercent')[:10]","8f9bea42":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(), linewidth=0.5, center=0, cmap=\"YlGn\", annot=True)","948ebe55":"corr_df = pd.DataFrame([(f1, f2, df.corr()[f1].loc[f2]) for (f1, f2) in itertools.combinations(df.columns[1:].sort_values(), 2)],\n             columns=['feature1', 'feature2', 'corr']).sort_values('corr')\n\ncorr_df = corr_df.iloc[(-corr_df['corr'].abs()).argsort()].reset_index(drop=True)\ncorr_df[:10]","5c82bff1":"corr_df[(corr_df.feature1 == 'winpercent') | (corr_df.feature2 == 'winpercent')]","f27608a1":"df[['competitorname', 'chocolate', 'winpercent']].sort_values('winpercent', ascending=False)[:20]","63c8b7ef":"fig = plt.figure()\nsns.boxplot(data=df, x=\"chocolate\", y=\"winpercent\", palette=\"YlGn\")","05207dc0":"print('p-value = {0:.10%}'.format(stats.ttest_ind(df[df.chocolate == 0].winpercent, \n                                               df[df.chocolate == 1].winpercent)[1]))","4e8db32f":"df[(df.bar == 1) & (df.chocolate == 0)]","e36db7ab":"fig = plt.figure(figsize=(15,5))\n\nax = fig.add_subplot(1,2,1)\nax.set(title='Overall')\nsns.heatmap(df[['bar', 'winpercent']].corr(), linewidth=0.5, center=0, cmap=\"YlGn\", annot=True)\n\nax = fig.add_subplot(1,2,2)\nax.set(title='Chocolate only')\nsns.heatmap(df[df.chocolate == 1][['bar', 'winpercent']].corr(), linewidth=0.5, center=0, cmap=\"YlGn\", annot=True)","be53b29a":"fig = plt.figure()\nplt.title('Chocolate only')\nsns.boxplot(data=df[df.chocolate == 1], x=\"bar\", y=\"winpercent\", palette=\"YlGn\")","d935f361":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[(df.bar == 0) & (df.chocolate == 1)].winpercent, \n                                                  df[(df.bar == 1) & (df.chocolate == 1)].winpercent)[1]))","ef39012f":"df[['chocolate', 'peanutyalmondy', 'competitorname']].groupby(['chocolate', 'peanutyalmondy'], as_index=False).count()","d65d0ae8":"plt.figure()\nsns.boxplot(data=df[df.chocolate == 1], x=\"peanutyalmondy\", y=\"winpercent\", palette=\"YlGn\")","5ba82ea8":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[(df.peanutyalmondy == 0) & (df.chocolate == 1)].winpercent, \n                                                  df[(df.peanutyalmondy == 1) & (df.chocolate == 1)].winpercent)[1]))","d0771b6f":"df[['chocolate', 'fruity', 'competitorname']].groupby(['chocolate', 'fruity'], as_index=False).count()","7254cdfc":"plt.figure()\nsns.boxplot(data=df, x=\"fruity\", y=\"winpercent\", palette=\"YlGn\")","0aa1c98b":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[df.fruity == 0].winpercent, \n                                                 df[df.fruity == 1].winpercent)[1]))","d2963215":"plt.figure()\nsns.boxplot(data=df, x=\"hard\", y=\"winpercent\", palette=\"YlGn\")","087f539e":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[df.hard == 0].winpercent, \n                                                 df[df.hard == 1].winpercent)[1]))","1e67f032":"df[['chocolate', 'hard', 'competitorname']].groupby(['chocolate', 'hard'], as_index=False).count()","d628b8e3":"fig = plt.figure()\nsns.boxplot(data=df[df.chocolate == 0], x=\"hard\", y=\"winpercent\", palette=\"YlGn\")","ee9e13a1":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[(df.hard == 0) & (df.chocolate == 0)].winpercent, \n                                                  df[(df.hard == 1) & (df.chocolate == 0)].winpercent)[1]))","98f7d456":"fig = plt.figure()\nsns.boxplot(data=df, x=\"pluribus\", y=\"winpercent\", palette=\"YlGn\")","9dbb565f":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[df.pluribus == 0].winpercent, \n                                                 df[df.pluribus == 1].winpercent)[1]))","2617cf31":"fig = plt.figure()\nsns.boxplot(data=df, x=\"caramel\", y=\"winpercent\", palette=\"YlGn\")","1d8041a9":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df[df.caramel == 0].winpercent, \n                                                 df[df.caramel == 1].winpercent)[1]))","9f1adb1b":"def bars_winpercent(df, x, title, cnt_bars):\n    # plot one continuous variable against winpercent\n    \n    factor = cnt_bars - 1\n    x = '%s_rounded' % x\n    price = pd.DataFrame({x: np.round(df.pricepercent*factor)\/factor, 'winpercent': df.winpercent})\n\n    fig = plt.figure(figsize=(15,5))\n    fig.suptitle(title)\n\n    ax = fig.add_subplot(1,2,1)\n    sns.barplot(x=x, \n                y='winpercent',\n                data=price.groupby(x, as_index=False).mean().sort_values(x),\n                palette='YlGn', ax=ax)\n    ax.set(ylabel='Mean winpercent')\n\n    ax = fig.add_subplot(1,2,2)\n    ax.set(ylabel='Count')\n    sns.barplot(x=x, \n                y='winpercent',\n                data=price.groupby(x, as_index=False).count().sort_values(x),\n                palette='YlGn', ax=ax)\n    ax.set(ylabel='Count')","6f105e25":"bars_winpercent(df[df.chocolate == 1], 'pricepercent', 'Chocolate only', 5)\nbars_winpercent(df[df.fruity == 1], 'pricepercent', 'Fruity only', 5)","1145fcea":"bars_winpercent(df[df.chocolate == 1], 'sugarpercent', 'Chocolate only', 5)\nbars_winpercent(df[df.fruity == 1], 'sugarpercent', 'Fruity only', 5)","527db72d":"t1 = pd.pivot_table(df[['chocolate', 'peanutyalmondy', 'caramel', 'winpercent']],\n               values=['winpercent'],\n               columns=['chocolate', 'peanutyalmondy', 'caramel'],\n               aggfunc=['mean', 'count'],\n               fill_value=0\n              ).sort_values('mean', ascending=False).reset_index().drop('level_0', axis=1)","6fb6f6dc":"t2 = pd.pivot_table(df[['chocolate', 'peanutyalmondy', 'winpercent']],\n               values=['winpercent'], \n               columns=['chocolate', 'peanutyalmondy'],\n               aggfunc=['mean', 'count'],\n               fill_value=0\n              ).sort_values('mean', ascending=False).reset_index().drop('level_0', axis=1)","27c7f934":"t3 = pd.pivot_table(df[['chocolate', 'caramel', 'winpercent']],\n               values=['winpercent'],\n               columns=['chocolate', 'caramel'],\n               aggfunc=['mean', 'count'],\n               fill_value=0\n              ).sort_values('mean', ascending=False).reset_index().drop('level_0', axis=1)","14975f72":"t1.append(t2, sort=False).append(t3, sort=False).sort_values('mean', ascending=False).reset_index(drop=True)","8bdeaa80":"df_p1_c0 = df[(df.chocolate == 1) & (df.peanutyalmondy == 1) & (df.caramel == 0)]\ndf_p1_c0_minus = df[[idx not in df_p1_c0.index for idx in df.index]]\n\nprint('p-value = {0:.5%}'.format(stats.ttest_ind(df_p1_c0_minus.winpercent, \n                                                 df_p1_c0.winpercent)[1]))","883fc5fb":"df_p0_c1 = df[(df.chocolate == 1) & (df.peanutyalmondy == 0) & (df.caramel == 1)]\ndf_p0_c1_minus = df[[idx not in df_p0_c1.index for idx in df.index]]\n\nprint('p-value = {0:.2%}'.format(stats.ttest_ind(df_p0_c1_minus.winpercent, \n                                                 df_p0_c1.winpercent)[1]))","f49c9875":"print('p-value = {0:.2%}'.format(stats.ttest_ind(df_p1_c0.winpercent, \n                                                 df_p0_c1.winpercent)[1]))","47031885":"df_p1_c1 = df[(df.chocolate == 1) & (df.peanutyalmondy == 1) & (df.caramel == 1)]\ndf_p1_c1_minus = df[[idx not in df_p1_c1.index for idx in df.index]]\n\nprint('p-value = {0:.2%}'.format(stats.ttest_ind(df_p1_c1_minus.winpercent, \n                                                 df_p1_c1.winpercent)[1]))","bacd35c2":"features = df.columns[1:-1]\ntarget = 'winpercent'\n\nclass MeanEstimator(BaseEstimator):\n    \n    mean = None\n    \n    def fit(self, X, y):\n        if isinstance(y, pd.Series) or isinstance(y, pd.DataFrame):\n            self.mean = np.mean(y).iloc[0]\n        else:\n            self.mean = np.mean(y)\n        \n    def predict(self, X):\n        if self.mean is None:\n            raise ValueError('Estimator is not fitted yet')\n        return np.ones(X.shape[0])*self.mean\n","41126091":"model_mean = MeanEstimator()\npred_mean = cross_val_predict(model_mean, df[features], df[[target]], cv=4, n_jobs=4)\n    \ndict(r2=r2_score(df[[target]], pred_mean), \n     rmse=sqrt(mean_squared_error(df[[target]], pred_mean))\n    )","ed244c0d":"r2_score(df[[target]], np.ones(df.shape[0])*np.mean(df[[target]]).iloc[0])","ae0162ce":"param_grid = dict(\n    max_depth=[3, 4, 5], \n    learning_rate=[0.05, 0.1, 0.2], \n    n_estimators=[32, 33, 34],\n    min_child_weight=[5, 6, 7],\n    subsample=[0.4, 0.5, 0.6],\n)\n\nclf = xgboost.XGBRegressor(objective='reg:squarederror')\nmodel_xgb = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=4, iid=True, refit=True, cv=4, scoring='r2')\n\nmodel_xgb.fit(df[features], df[[target]])\n\npred_xgb = cross_val_predict(model_xgb.best_estimator_, df[features], df[[target]], cv=4, n_jobs=4)\n\ndict(r2=r2_score(df[[target]], pred_xgb), rmse=sqrt(mean_squared_error(df[[target]], pred_xgb)))","afbae628":"model_xgb.best_params_","7faebe65":"imp = pd.DataFrame({'features': features, 'importance': model_xgb.best_estimator_.feature_importances_})\nimp.sort_values('importance', ascending=False, inplace=True)\nsns.barplot(x='importance', y='features', data=imp, palette=\"YlGn_r\")","fdedf55b":"features = df.columns[1:-1]\ntarget = 'winpercent'\n\nparam_grid = {\n    'max_depth': [None, 10, 15, 20],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'min_samples_leaf': [6, 7, 8, 9],\n    'min_samples_split': [10, 11, 12, 13],\n    'n_estimators': [130, 140, 150, 160]\n}\n\nclf_rf = RandomForestRegressor()\nmodel_rf = GridSearchCV(estimator=clf_rf, param_grid=param_grid, n_jobs=4, iid=True, refit=True, cv=4, scoring='r2')\n\nmodel_rf.fit(df[features], np.ravel(df[[target]]))\n\npred_rf = cross_val_predict(model_rf.best_estimator_, df[features], df[[target]], cv=4, n_jobs=4)\n\ndict(r2=r2_score(df[[target]], pred_rf), rmse=sqrt(mean_squared_error(df[[target]], pred_rf)))","c6bd25d6":"model_rf.best_params_","9ac11275":"imp = pd.DataFrame({'features': features, 'importance': model_rf.best_estimator_.feature_importances_})\nimp.sort_values('importance', ascending=False, inplace=True)\nsns.barplot(x='importance', y='features', data=imp, palette=\"YlGn_r\")","35cc1d2a":"df_rf = df.copy()\ndf_rf['pred_rf'] = pred_rf\n\nsns_dt = df_rf.sort_values('pred_rf', ascending=False).reset_index(drop=True).winpercent.expanding().mean()\n\nax = sns.lineplot(x=sns_dt.index, y=sns_dt, color='green', palette=\"YlGn\")\nax.set(xlabel='Candies (ordered by predicted winpercent)', ylabel='Winpercent (cumulative mean)')\nplt.show()","ab270fb2":"features_no_choc = df.columns[2:-1]\n\nparam_grid = dict(\n    max_depth=[3, 4, 5], \n    learning_rate=[0.05, 0.1, 0.2], \n    n_estimators=[32, 33, 34],\n    min_child_weight=[5, 6, 7],\n    subsample=[0.4, 0.5, 0.6],\n)\n\nclf = xgboost.XGBRegressor(objective='reg:squarederror')\nmodel_xgb_no_choc = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=4, iid=True, refit=True, cv=4, scoring='r2')\n\nmodel_xgb_no_choc.fit(df[features_no_choc], df[[target]])\n\npred_xgb_no_choc = cross_val_predict(model_xgb_no_choc.best_estimator_, df[features_no_choc], df[[target]], cv=4, n_jobs=4)\n\ndict(r2=r2_score(df[[target]], pred_xgb_no_choc), \n     rmse=sqrt(mean_squared_error(df[[target]], pred_xgb_no_choc)))","d74dab3b":"imp = pd.DataFrame({'features': features_no_choc, 'importance': model_xgb_no_choc.best_estimator_.feature_importances_})\nimp.sort_values('importance', ascending=False, inplace=True)\nsns.barplot(x='importance', y='features', data=imp, palette=\"YlGn_r\")","f24c2b93":"## RandomForestRegressor","af299bbe":"## XGBRegressor without chocolate\n\nIf we remove chocolate from the features the model performs really bad and it performs similar to the baseline model above.","7e926409":"We see that the difference between fruity and non-fruity candies is statistical significant:","5c3cd9aa":"We can see that chocolate and perhaps peanutyalmondy have a positive effect to winpercent. Additionaly fruity seems to have a negative impact.\n\nNow let us using statistical and machine learning methods for a more reliable analysis. Because nougat and crispedricewafer are rare we will omit them.","1700692c":"The p-value of the Student's t-test is the probability that you are wrong if you assert there is a difference between the two datasets. Usually if the p-value is smaller than 5% one can say that there is a statistical significance for the difference of the two datasets.\n\nThere is a very interesting article about the \"5%\" thing: https:\/\/priceonomics.com\/the-guinness-brewer-who-revolutionized-statistics\/.","d004805d":"## Baseline\n\nA baseline model is a simple estimator, which give us an idea, how good our predictores should be at least and to see how much better they are.\n\nUsually you take something like the mean as the baseline model.\n\nSince we will use cross validation later on, we should use cross validation for the baseline too.","7f45bdce":"The best parameters are the following parameters:","604c6c44":"There is only one candy which has chocolate and is fruity. So the most candies have either chocolate or are fruity.","d943f769":"## sugarpercent\n\nDue to the correlation between sugar and fruity and between sugar and chocolate we differ between fruity and chocolate.","145e05d1":"The characteristics of the binary features (all features except for sugarpercent and pricepercent):","2e87ae88":"Almost every hard cookie does not have chocolate:","2d17cc99":"The feature importance:","889f379b":"THe performance is non really good. In particular if we take the findings from the univariate analysis we get better results.","025ede34":"## chocolate\n\nIn the top 20 there are only two non-chocolate candies:","63ee64ed":"So, we restrict the analysis to candies without chocolate, to see if there is a different result to the above result:","a59ac2e6":"But of course there is no significant difference between the two types above:","37d05e19":"## bar\n\nAt first glance, the correlation between bar and winpercent seems interesting, but we can see two facts. First, there is only one bar without chocolate:","0250dee7":"# Correlation Matrics\n\nThe correlation matrics contains every correlation coefficiant for every pair of features and target variable.","a7a3a4c3":"Also candies with chocolate and caramel but without peanut\/almond perform very well and significant better than the others:","a2f7a7a4":"We see that chocolate and winpercent have the largest correlation. Also bar and winpercent just as peanutyalmondy and winpercent have noticeable correlations. But we have to be careful because also chocolate and bar have a large correlation.","eba01201":"## Top Ten & Worst Ten","466b95fe":"The best parameters are the following parameters","6113c2e1":"We see that candies with chocolate are a little bit more expensive than fruity candies. Since the interviewees did not had to pay for the candies, it is  not a suprise that the influence of the price is low.","9c93300f":"This difference is not statistical significant, because of the low numbers of observations.","12f36271":"## caramel\n\nCandies with caramel perform better than other candies:**","c6c084b0":"The characteristics of the non-binary features sugarpercent and pricepercent:","4ca7220d":"## Result\n\nWe saw that chocolate, peanutyalmondy, and caramel are the most import features for a candy with high winpercent.\n\nNow, we are looking for the best combination of these features.","79aad19e":"Fruity and winpercent have a conspicious negative correlation. Again we create a box plot to see the difference between fruity candies and the others.","82005432":"We see that chocolate is the most important feature","d9c1653a":"And here the correlation coefficients for winpercent only:","2ca5b3b7":"# Short Introduction\nThe analysis explores the candy power ranking dataset from FiveThirtyEight (for more detailed informations see https:\/\/fivethirtyeight.com\/features\/the-ultimate-halloween-candy-power-ranking\/).\n\nThey showed people two of 84 candies and ask them which one they would choose. For each candy, they calculated how often it was chosen (in percent). So the dataset includes the name of each candy, some attributes like sugar content, whether it contains nougat or caramel and so on, and the probability that it was chosen in the survey.\n\nTherefore we focus on this probability (name of the feature in the dataset: winpercent).","d4fcdb08":"## pricepercent\n\nSince pricepercent differs for fruity and for chocolate, we separate the candies for the analysis.","62e4d20b":"The feature importance:","899f0408":"We said before that chocolate, peanutyalmondy and caramel are the most important features. But we have only three candies with all of these features. So, there is no chance to reach significance:","efd0409b":"# Univariate Analysis","1b3bb755":"We see there is only a small difference  between bars with chocolate and without bars with respect to winpercent. So, it's not suprisingly that the p-value is far away from the 5%:\n","f8a55861":"The RSME of a better estimator should be less than the above value. And r\u00b2 should be better than 0 of course,\n\nPerhapse you wonder why r\u00b2 is negative. In general r\u00b2 is between minus infinity and 1 (the square in r\u00b2 is misleading). If you compute the r\u00b2 of the target and the mean of the target you get exactly 0:","c58107ae":"In the following we take the look on the performance on the random forest prediction.","3f1f2e2a":"The difference of candies with and without chocolate with respect to winpercent is statistical significant:","707600d6":"## Fruity\n\nSince the correlation between fruity and chocolate ist even larger, we look at this first.","519a9077":"# Summary\n\nThe univariate analysis shows that chocolate, peanutyalmondy, and caramel are the most important features. Candies with chocolate and peanutyalmondy or chocolate and caramel leads to the best performing candies.\n\nMultivariate analysis does not lead to more relevant insights.","06229809":"# Multivariate Analysis\n\nNow we are using machine learning to check if we find some non-linear dependencies.","a2f5ad26":"This difference is statistical significant:","6b678556":"Second, if we restrict the dataset to chocolate only, the correlation almost vanishes:","a8748301":"## hard\n\nWe see that hard cookies perform worse than other candies:","5b4cddd6":"Next we do the same with an random forest. But of course the steps are the same, you can use every regressor you find.","4c03fb7a":"The box plot shows the the strong correlation of chocolate to winpercent:","ea68dc73":"The above plot implies that candies with chocolate and peanut\/almond perform better than candy with chocolate but without peanut\/almond:","d523deb4":"But we are using cross validation. So we compute the mean over the target of a train set and using this value as an estimator for the test set. This value can be a worse estimator than the mean of the target in the test set (which we do not know beforehand). In this case the r\u00b2 score is less than 0.","2416294c":"Since the matrics is large and therefore a little bit confusing, here the top ten of correlations (positive and negative):","0b00013a":"Again, this difference is statistical significant:","bf9346af":"For a first impression we take a short look at the top ten:","ec518e01":"First of all we load all needed packages. pandas and numpy for data and data handling, scipy for statistics, seaborn and matplotlib for visualization, and sklean and xgboost for machine learning.","f7d231ac":"Candies with chocolate have slightly more sugar than fruity candies by trend.But the influence seems very low.","aaf68253":"## XGBRegressor\n\nThe XGBRegressor is the regressor of the xgboost package, a famous implementation of a gradient boosting algorithm. Unlike a classifier a regressor takes an interval variable as target.","1efb72d1":"## pluribus\n\nCandies from a box or bag with different candies perform worse than other candies:","408e2c96":"## peanutyalmondy\n\nBecause of the correlation between peanutyalmondy and chocolate we take a look on this first.","5d0a0b83":"and the worst ten:","9329ff15":"# Overview","1033a096":"This difference is statistical significant:","3816533a":"Candies with chocolate and peanutymondy but without caramel own the highest winpercent. We can check if those candies have a significant better winpercent than the others:","300d7f75":"Let's take a look on the box plot:","ab04aa5b":"Since a candy has almost ever chocolate if it is peanutyalmondy, we restrict the analysis to candies with chocolate:"}}