{"cell_type":{"99bc3910":"code","b9dea8be":"code","60b22aa9":"code","a8e74910":"code","24d8e665":"code","dfe4bafc":"code","10fc2070":"code","4cde4032":"code","2ab8952d":"code","66562551":"code","eb3b4c18":"code","2e3058d8":"code","453c3778":"code","64767132":"code","30fb472a":"code","477bdfe2":"code","7d298b2f":"code","ed544046":"code","960c2339":"code","fc09bcb3":"code","3fa73081":"code","fd6f6e41":"code","a829e540":"code","f4504732":"code","e95ad854":"code","4792086f":"code","51002ea2":"markdown","091d598e":"markdown","284fe698":"markdown","801be8cd":"markdown","30b4418a":"markdown","6c332655":"markdown","6a286c7f":"markdown","d3727a63":"markdown","85a900c2":"markdown","0aab7d3a":"markdown","784795a7":"markdown","3906639f":"markdown","9e6ec6fa":"markdown","5b8df5cd":"markdown","36e40905":"markdown"},"source":{"99bc3910":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9dea8be":"import pandas as pd\n\nfile_path = '..\/input\/car-price-prediction\/CarPrice_Assignment.csv'\n\n## EXPLORING THE AVAILABLE DATA\n\ncar_data = pd.read_csv(file_path)\ncar_data.head()","60b22aa9":"car_data.columns\n\n## CONVERTING CATEGORICAL DATA TO NUMERIC FOR EASE OF ANALYSIS\n## KEY:\n## CARBODY---- HATCHBACK:0 SEDAN:1 HARDTOP:2 WAGON:3 CONVERTIBLE:4\n## FUELTYPE---- GAS:1 DIESEL:-1\n## DOORNUMBER--- FOUR:4 TWO:2\n## ASPIRATION--- STANDARD:0 TURBO:1\n## DRIVEWHEEL--- RWD:0 FWD:1 4WD:2\n## CYLINDERNUMBER---- TWO to TWELVE:2-12\n## FUELSYSTEM---- MPFI:0 1BBL:1 2BBL:2 4BBL:3 MFI:4 SPFI:5 IDI:6 SPDI:7\n\ndata = car_data.copy()\ndata['carbody'] = data['carbody'].map({'hatchback':0,'sedan':1,'hardtop':2,'wagon':3,'convertible':4})\ndata['fueltype'] = data['fueltype'].map({'gas':1,'diesel':-1})\ndata['doornumber'] = data['doornumber'].map({'four':4,'two':2})\ndata['aspiration'] = data['aspiration'].map({'std':0,'turbo':1})\ndata['drivewheel'] = data['drivewheel'].map({'rwd':0,'fwd':1,'4wd':2})\ndata['cylindernumber'] = data['cylindernumber'].map({'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9,'ten':10,'eleven':11,'twelve':12})\ndata['fuelsystem'] = data['fuelsystem'].map({'mpfi':0,'1bbl':1,'2bbl':2,'4bbl':3,'mfi':4,'spfi':5,'idi':6,'spdi':7})\n\n\n","a8e74910":"y = data.price   ## PREDICTION TARGET\nX = data[['carbody','enginesize','peakrpm']] ## TASK 1 FEATURES\n\n## MOST OF THE FEATURES\nZ = data[['symboling','doornumber','aspiration','carbody','enginesize','fuelsystem','peakrpm','fueltype','cylindernumber','drivewheel','carlength','carwidth','carheight','wheelbase','boreratio','stroke','compressionratio','curbweight','horsepower','citympg','highwaympg']]\n","24d8e665":"## ADJUSTED R-SQ FUNCTION\ndef adj_r2(x,y):\n    r2 = model.score(x,y)\n    n = x.shape[0]\n    p = x.shape[1]\n    adjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    return adjusted_r2","dfe4bafc":"## SPLITTING DATASET INTO TRAINING DATA AND VALIDATION DATA\nfrom sklearn.model_selection import train_test_split\n\ntrain_X,val_X,train_y, val_y = train_test_split(X,y,random_state=1)","10fc2070":"## PERFORMING REGRESSION\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(train_X,train_y)\n\npredicted = model.predict(val_X)\nval_X['actual_price']=val_y\nval_X['predictions']=predicted\nval_X\n\n","4cde4032":"## R-SQUARED\nr2=model.score(train_X,train_y)\nr2\n","2ab8952d":"## ADJUSTED R-SQUARED\nar2=adj_r2(train_X,train_y)\nar2","66562551":"## MEAN ABSOLUTE ERROR\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_y,predicted)\nmae","eb3b4c18":"report = pd.DataFrame(data=[r2],columns=['R-SQUARED'])\nreport['ADJUSTED R-SQ']=ar2\nreport['MEAN ABS. ERROR']=mae\nreport","2e3058d8":"## REGRESSION WITH ALL VARIABLES-21 (EXCEPT CAR_ID CAR_COMPANY AND ENGINE_TYPE; DUE TO ANOMALY IN DATA)\nfrom sklearn.model_selection import train_test_split\n## SPLITTING DATASET INTO TRAINING AND VALIDATION PARTS\ntrain_Z,val_Z,train_y, val_y = train_test_split(Z,y,random_state=1)","453c3778":"## PERFORMING REGRESSION\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(train_Z,train_y)\n\npredicted2 = model.predict(val_Z)\nval_Z['actual_price']=val_y\nval_Z['predictions']=predicted2\nval_Z","64767132":"## R-SQUARED\nr2=model.score(train_Z,train_y)\n","30fb472a":"## ADJUSTED R-SQUARED\nar2=adj_r2(train_Z,train_y)","477bdfe2":"## MEAN ABSOLUTE ERROR\nfrom sklearn.metrics import mean_absolute_error\nmae2 = mean_absolute_error(val_y,predicted2)\nmae2","7d298b2f":"report = pd.DataFrame(data=[r2],columns=['R-SQUARED'])\nreport['ADJUSTED R-SQ']=ar2\nreport['MEAN ABS. ERROR']=mae2\nreport","ed544046":"## USING F_REGRESSION FOR CALCULATING P-VALUES\nfrom sklearn.feature_selection import f_regression\nf_regression(train_Z,train_y)\np_values = f_regression(train_Z,train_y)[1]\np_values.round(27)","960c2339":"cars = pd.DataFrame(data=train_Z.columns.values,columns=['Features'])\ncars['p-values'] = p_values.round(27)\ncars","fc09bcb3":"y = data.price ## PREDICTION TARGET\nA = data[['enginesize','cylindernumber','drivewheel','curbweight','horsepower']] ## FEATURES","3fa73081":"## SPLITTING THE DATASET INTO TRAINING AND VALIDATION PARTS\nfrom sklearn.model_selection import train_test_split\n\ntrain_A,val_A,train_y, val_y = train_test_split(A,y,random_state=1)","fd6f6e41":"## PERFORMING REGRESSION\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(train_A,train_y)\n\npredicted3 = model.predict(val_A)\nval_A['actual_price']=val_y\nval_A['predictions']=predicted3\nval_A","a829e540":"## R-SQUARED\nr2=model.score(train_A,train_y)\n","f4504732":"## ADJUSTED R-SQUARED\nar2=adj_r2(train_A,train_y)","e95ad854":"## MEAN ABSOLUTE ERROR\nfrom sklearn.metrics import mean_absolute_error\nmae3 = mean_absolute_error(val_y,predicted3)\nmae3","4792086f":"report = pd.DataFrame(data=[r2],columns=['R-SQUARED'])\nreport['ADJUSTED R-SQ']=ar2\nreport['MEAN ABS. ERROR']=mae3\nreport","51002ea2":"# ****REGRESSION 1 (ONLY THE THREE VARIABLES MENTIONED IN TASK 1)","091d598e":"Regression 3 is pergormed only with the 5 significant features.","284fe698":"# INTRODUCTION\n\nThis notebook contains analysis and predictions of carprices from the dataset provided.\nThe notebook is divided into 3 parts which consist of three different models. The intention of each model has been specified. The results obtained from each model has been tabulated. Finally a comparison has been done at the end.","801be8cd":"# ****UNIVARIATE P VALUES FOR DETERMINING SIGNIFICANCE OF VARIABLES","30b4418a":"# RESULTS","6c332655":"# RESULTS","6a286c7f":"Multiple Regression is performed on the dataset. This regression pertains to Task 1 only. Car price predictions are made based on:\n* Car Body\n* Engine Size\n* Peak Rpm\n","d3727a63":"**CONCLUSION**\n\nThe model gives a reasonable prediction about the car prices based on\n* Car Body\n* Engine Size\n* Peak Rpm\n\n**WHAT NEXT**\n\nHowever it remains to be seen if there are other sets of features which can give a better model for this prediction. Our main aim is to increase the R-Squared and Adjusted R-Squared but reduce the mean absolute error.\nTo fulfill our purpose we first perform a regression taking all the variables in the dataset. We then check the result of this regression and record it.","85a900c2":"**FROM THIS TABLE, WE CONCLUDE THE 5 MOST SIGNIFICANT FEATURES TO BE**\n* Engine Size(enginesize)\n* Number of Cylinders(cylindernumber)\n* Type of Drivewheel(drivewheel)\n* Weight of Car without Occupants(curbweight)\n* Horsepower(horsepower)","0aab7d3a":"# RESULTS","784795a7":"# RESULTS","3906639f":"**FINAL CONCLUSION**\n\nReducing the number of features is bound to reduce the predictive accuracy. This is evident from the decrease in values of R-Squared and Adjusted R-Squared. However the reduced value of these statistics are still more than 80% which is reasonably good and also better than the variables considered in Task 1.\n\nIt is also observed that Mean Absolute Error has reduced further as compared to Regression 2, thus the final model (Regression 3) can be considered to be a good model for predicting the price of cars without considering all the 26 features. The predictions are reasonably accurate.\n\nAlso the motor company should focus on these 5 main features for predicting the price of the cars:\n* Engine Size(enginesize)\n* Number of Cylinders(cylindernumber)\n* Type of Drivewheel(drivewheel)\n* Weight of Car without Occupants(curbweight)\n* Horsepower(horsepower)","9e6ec6fa":"**CONCLUSION**\n\nTaking all the variables into account, it is clearly visible that we have managed to improve our model. R-Squared and Adjusted R-Squared values have increased significantly and Mean Absolute Error has decreased by roughly 400.\n\n**WHAT NEXT**\n\nHowever taking 21 features into consideration will be a big task. Our next goal is to determine the 5 most significant features that can be used to create an accurate model to predict the price of the cars. To achieve this, we will calculate the p-values of each feature separately with respect to the car price.\n\nFeatures having p-values>0.05 can be deemed insignificant easily\n\nWe then collect the features for which p-values tend to be very small(features of greater significance)\n\nThe p-values are then checked till greater decimal digits to determine the 5 smallest p-values and hence correspondingly, the 5 most significant features affecting the car prices.\n\nWe then construct a final regression model with these 5 features only.\n","5b8df5cd":"# ****REGRESSION 2 (CONSIDERING MANY MORE VARIABLES AND GRADUALLY NARROWING DOWN TO 5 MOST ESSENTIAL)","36e40905":"# ***REGRESSION 3(CONSIDERING ONLY THE SIGNIFICANT NUMERIC VARIABLES)"}}