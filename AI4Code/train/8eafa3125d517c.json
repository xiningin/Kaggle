{"cell_type":{"7d7d7af4":"code","b9fce8bf":"code","e9f83dcb":"code","ca613040":"code","59a39fa5":"code","144b3317":"code","f61a29c3":"code","dcb26bf1":"code","d5286c5e":"code","65d28be9":"code","fdbcf876":"code","974e9d64":"code","09813ab8":"code","4de79bb3":"code","a2e0086d":"code","22bab444":"code","738234ca":"markdown","8100ae49":"markdown","f02aa93c":"markdown","cf564219":"markdown","46efd250":"markdown","125e0c26":"markdown","4ee93101":"markdown","cc326df8":"markdown","d1e712a4":"markdown","c6ccc07f":"markdown","b270d79f":"markdown","6bfa30f3":"markdown"},"source":{"7d7d7af4":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom tqdm.notebook import tqdm\n\nimport multiprocessing as mp\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as T\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\n\nsys.path.insert(1, \"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/\")\n\nimport timm\n\nROOT = '\/kaggle\/input\/hotel-id-2021-fgvc8'\nTRAIN_PATH = os.path.join(ROOT, \"train_images\")\nTEST_PATH = os.path.join(ROOT, \"test_images\")\nTRAIN_CSV = os.path.join(ROOT, \"train.csv\")\n\n# If you want to resize tehe dataset to speed up all the training set it to True\nRESIZE_ALL_DATASET = False\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# load train dataframe\ndf_hotels = pd.read_csv(TRAIN_CSV)\n\n# Don't sample it ! It's just to save time\ndf_hotels = df_hotels.sample(1000)\nprint(f\"len df_hotels = {len(df_hotels)}\")","b9fce8bf":"if RESIZE_ALL_DATASET:\n    import threading\n\n    # Use multithreading to speed up the resize job\n    def resize_thread(df, t_id):\n        n_tot = len(df)\n        for item in tqdm(df.iterrows(), total=n_tot):\n            file_path = os.path.join(TRAIN_PATH, str(item[1][\"chain\"]), item[1][\"image\"])\n            img = Image.open(file_path)\n            width, height = img.size\n            if width > 512 or height > 512:\n                max_size = max(width, height)\n                scale = 512\/max_size\n                img = img.resize((int(width*scale), int(scale*height)))\n                out_folder = os.path.join(\"train_resized\", str(item[1][\"chain\"]))\n                os.makedirs(out_folder, exist_ok=True)\n                img.save(os.path.join(out_folder, item[1][\"image\"]))\n\n    image_name = df_hotels[\"image\"].values\n    chain = df_hotels[\"chain\"].values\n\n    # create the new resized dataset dir\n    os.makedirs(\"train_resized\", exist_ok=True)\n\n    n_tot = len(df_hotels)\n    df_hotels.index = range(n_tot)\n\n    # Start threads\n    num_thread = mp.cpu_count()\n    num_elems = n_tot\/\/num_thread\n    thread_list = []\n    for i in range(num_thread):\n        i1 = i*num_elems\n        if i==num_thread-1:\n            i2 = n_tot\n        else:\n            i2 = (i+1)*num_elems\n\n        thread_list += [threading.Thread(target=resize_thread, args=(df_hotels.iloc[i1:i2],i))]\n\n    for i in range(num_thread):\n        thread_list[i].start()\n\n    for i in range(num_thread):\n        thread_list[i].join()\n    \n    TRAIN_PATH = \"train_resized\"","e9f83dcb":"image_name = df_hotels[\"image\"].values\nchain = df_hotels[\"chain\"].values\n# Add the information of image width, height and aspect ration to the dataframe\nwidth = []\nheight = []\nfor i in tqdm(range(len(image_name))):\n    img = Image.open(os.path.join(TRAIN_PATH, str(chain[i]), image_name[i]))\n    w, h = img.size\n    width += [w]\n    height += [h]\nwidth = np.array(width)\nheight = np.array(height)\n\ndf_hotels[\"width\"] = width\ndf_hotels[\"height\"] = height\ndf_hotels[\"ar\"] = width\/height\ndf_hotels.head()","ca613040":"def show_ar_images(index):\n    fig, ax = plt.subplots(5,10, figsize=(30,15))\n    for i in range(50):\n        sample = df_hotels[index].sample(1)\n        img = Image.open(os.path.join(TRAIN_PATH, str(sample[\"chain\"].item()), sample[\"image\"].item()))\n        ax[i\/\/10,i%10].imshow(img)","59a39fa5":"show_ar_images(df_hotels[\"ar\"]<=0.75)","144b3317":"show_ar_images(df_hotels[\"ar\"]>0.75)","f61a29c3":"import sklearn.metrics as metrics\n# Hyperparameters\n# there are 4 possible rotations: [0, 90, 180, 270]  degrees\nnum_classes = 4\nbatch_size = 64\n# number of rotations to sample from [0, 90, 180, 270] during training\nnum_rotations = 2\n# number of workers for the data loader\nnum_workers = mp.cpu_count()\n# number of epochs ----------------------- (CHANGE to 40 !)\nepochs = 10\n# learning rate\nlr = 5e-4\n#  label smoothing eps\nsmooth_eps = 0.15","dcb26bf1":"# Dataset splitting: 85 % train and 15 % validation\ndf_hotels_ar = df_hotels[df_hotels[\"ar\"]<=0.75]\nn_sample = len(df_hotels_ar)\nn_train = int(n_sample*0.85)\nindexes = np.arange(n_sample)\nnp.random.shuffle(indexes)\ndf_train = df_hotels_ar.iloc[indexes[:n_train],:]\ndf_val = df_hotels_ar.iloc[indexes[n_train:],:]","d5286c5e":"# Load pretrained model (on imagenet)\nmodel = timm.create_model(\"efficientnet_b0\", pretrained=False, checkpoint_path=\"..\/input\/timm-pretrained-efficientnet\/efficientnet\/efficientnet_b0_ra-3dd342df.pth\",drop_rate=0.4)\n# Change the number of classes\nmodel.classifier = nn.Linear(model.bn2.num_features, num_classes)\n# get the default config\nconfig = timm.data.resolve_data_config({}, model=model)\n# get the default input size for the defined model\ninput_size = config[\"input_size\"][1:]","65d28be9":"class RotationDataset(datasets.vision.VisionDataset):\n    def __init__(\n        self,\n        root,\n        df_hotels,        # The dataframe\n        num_rotations=2,  # how many rotations of the same image choosen randomly by [0, 90, 180, 270]\n        validation=False, # When validate the dataset, we want to validate all the rotations\n        transform=None,\n        loader=datasets.folder.default_loader,\n    ):\n        super(RotationDataset, self).__init__(\n            root, transform=transform, target_transform=None\n        )\n        self.loader = loader\n        self.validation = validation\n        self.num_rotations = num_rotations\n\n        image_name = df_hotels[\"image\"].values\n        chain = df_hotels[\"chain\"].values\n\n        self.samples = []\n        for i in range(len(image_name)):\n            self.samples.append(os.path.join(root, str(chain[i]), image_name[i]))\n\n        self.samples = np.array(self.samples)\n\n    def __getitem__(self, index):\n        sample = self.loader(self.samples[index])\n\n        if self.transform is not None:\n            sample = self.transform(sample)\n\n        samples = []\n\n        if self.validation:\n            labels = [0, 1, 2, 3]\n        else:\n            np.random.seed(index)\n            labels = np.random.choice([0, 1, 2, 3], self.num_rotations)\n        for l in labels:\n            if l == 0:\n                samples += [sample]\n            elif l == 1:\n                samples += [sample.transpose(1, 2)]   # This is equivalent of rotate(90)\n            elif l == 2:\n                samples += [sample.flip(1)]           # This is equivalent of rotate(180)\n            elif l == 3:\n                samples += [sample.transpose(1, 2).flip(2)]   # This is equivalent of rotate(270)\n\n        return samples, list(labels)\n\n    def __len__(self):\n        return len(self.samples)","fdbcf876":"# Very simple data augmentation for the training dataset\ntrain_transform = T.Compose([T.RandomRotation(15),\n                            T.RandomResizedCrop(input_size, scale=(0.5,1.0)),\n                            T.RandomHorizontalFlip(0.5),\n                            T.ColorJitter(0.15, 0.15, 0.15, 0.1),\n                            T.RandomGrayscale(0.2),\n                            T.ToTensor(),\n                            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n# No augmentation for validation dataset\nval_transform = T.Compose([T.Resize(input_size),\n                            T.ToTensor(),\n                            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\ntrain_dataset = RotationDataset(TRAIN_PATH, df_train, num_rotations=num_rotations, transform=train_transform)\nval_dataset = RotationDataset(TRAIN_PATH, df_val, validation=True, transform=val_transform)\n\n# Data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=num_workers,\n    pin_memory=True,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True,\n)","974e9d64":"# Label smoothing cross entropy loss\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, classes, epsilon=0.2, dim=-1):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        self.confidence = 1.0 - epsilon\n        self.epsilon = epsilon\n        self.cls = classes\n        self.dim = dim\n\n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=self.dim)\n        with torch.no_grad():\n            # true_dist = pred.data.clone()\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.epsilon \/ (self.cls - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))","09813ab8":"optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n# you can also choose SGD\n#optimizer = torch.optim.SGD(model.parameters(), lr=lr) \n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=epochs, eta_min=1e-5\n)\n# Cross entropy with label smoothing criterion (it hepls to calibrate the probabilities)\ncriterion = LabelSmoothingCrossEntropy(\n    classes=num_classes,\n    epsilon=smooth_eps,\n)","4de79bb3":"# Eval function\ndef eval(\n    model,  data_loader, device=\"cuda:0\"\n):\n    metric_dict = {}\n    pred_list = []\n    label_list = []\n    model.eval()\n    model.to(device)\n    with torch.no_grad():\n        for images, labels in data_loader:\n            \n            images = torch.cat(images).to(device)\n            labels = torch.cat(labels).to(device)\n\n            logits = model(images.cuda())\n            pred_labels = np.argmax(logits.cpu().numpy(), axis=1)\n            pred_list += list(pred_labels)\n            label_list += list(labels.cpu().numpy())\n\n        metric_dict[\"accuracy\"] = metrics.accuracy_score(label_list, pred_list)\n        metric_dict[\"macro_precision\"] = metrics.precision_score(\n            label_list, pred_list, average=\"macro\"\n        )\n        metric_dict[\"macro_recall\"] = metrics.recall_score(\n            label_list, pred_list, average=\"macro\"\n        )\n        metric_dict[\"macro_f1\"] = metrics.f1_score(\n            label_list, pred_list, average=\"macro\"\n        )\n\n        print(\n            f'Val acc. {metric_dict[\"accuracy\"]*100} %, meanPrecision {metric_dict[\"macro_precision\"]}, meanRecall {metric_dict[\"macro_recall\"]}, meanF1 {metric_dict[\"macro_f1\"]}'\n        )\n\n    return metric_dict","a2e0086d":"# Train function\ndef train(\n    model,\n    optimizer,\n    scheduler,\n    criterion,\n    train_data_loader,\n    val_data_loader,\n    epochs=50,\n    batch_size=32,\n    log_freq=0.25,\n    save_every=10,\n    device=\"cuda:0\",\n):\n    iteration = 1\n    date_now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n    num_samples = len(train_data_loader.dataset)\n    num_batches = num_samples \/\/ batch_size\n    log_step = max(int(log_freq * num_batches), 1)\n\n    model.to(device)\n    for epoch in range(1, epochs + 1):\n        model.train()\n        for batch, (images, labels) in enumerate(train_data_loader):\n            optimizer.zero_grad()\n\n            images = torch.cat(images).to(device)\n            labels = torch.cat(labels).to(device)\n\n            logits = model(images)\n\n            loss = criterion(logits, labels)\n            loss.backward()\n\n            optimizer.step()\n\n            iteration += 1\n            if batch % log_step == 0:\n                print(\n                    f\"[{batch}\/{num_batches}] Epoch {epoch} : Train loss {loss.item()}\"\n                )\n\n        scheduler.step()\n\n        metric_dict = eval(model, val_data_loader, device=device)\n\n        # Save checkpoints\n        if epoch % save_every == 0:\n            pth_name = (\n                f'{epoch:03d}_{100*metric_dict[\"accuracy\"]:.4f}.pth'\n            )\n            print(f\"Saving {pth_name}\")\n\n            if not os.path.isdir(os.path.join(\"checkpoints\", date_now)):\n                os.makedirs(os.path.join(\"checkpoints\", date_now), exist_ok=True)\n\n            torch.save(\n                model.state_dict(), os.path.join(\"checkpoints\", date_now, pth_name)\n            )","22bab444":"    train(\n        model,\n        optimizer,\n        scheduler,\n        criterion,\n        train_loader,\n        val_loader,\n        epochs=epochs,\n        batch_size=batch_size,\n        device=device,\n    )","738234ca":"Define dataloader and dataset for training","8100ae49":"# 2. Training","f02aa93c":"\n## 2.1 Splitting\nFirst of all split the dataset to train and validation set","cf564219":"# 1. Resize the dataset (maximum width or height: 512)\n\nResize the dataset will help us to speed up the dataloader and the also the entire training","46efd250":"## 2.3 Create datasets, preprocessing and dataloader","125e0c26":"It seems that rotations are more frequent for aspect ratio greather than 0.75, then we can train our network using images with ar <= 0.75","4ee93101":"## 1.1 Compute the aspect ratio of images","cc326df8":"## 2.5 Train!","d1e712a4":"## 2.4 Define optimizer and schedulers","c6ccc07f":"## 1.2 Check images with different aspect ratio to check if rotations happen more frequently on a specific AR","b270d79f":"# Train a model to predict rotation of an image: 0\u00b0, 90\u00b0, 180\u00b0 or 270\u00b0\n\nIn this simple example I will show to traina  simple model to check the angle of a rotated image. The accuracy can be very high and the model effective to clean the dataset","6bfa30f3":"## 2.2 Define the model"}}