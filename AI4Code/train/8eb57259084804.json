{"cell_type":{"f7c6139c":"code","26adcabc":"code","caeee393":"code","7204d1c4":"code","08e2e6e6":"code","2ed72535":"code","7ebdff40":"code","273c1396":"code","f4642385":"code","6a47ac33":"code","c0e78337":"code","2bb331b9":"code","f415b3e8":"code","5bc3cb7b":"code","bf99d624":"code","ad2e91d1":"code","8e686697":"code","2aa0355f":"code","eec59c5b":"code","883616cf":"code","82426396":"code","79559951":"code","5cbfb43b":"markdown","6b9b537e":"markdown","801252a3":"markdown","868d0427":"markdown","bd3994e9":"markdown","5cea0e40":"markdown","ab2f99da":"markdown"},"source":{"f7c6139c":"import numpy as np\nimport h5py as h5\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\n%matplotlib inline","26adcabc":"# Extracting the train dataset from the h5 file.\nf = h5.File(\"..\/input\/snake-classification-train\/train_set.hdf5\",'r')\n\nprint(\"Stored data:\",list(f.keys()))\n\n# Storing the original data \"permanently\".\nimages_train_orig = f[\"images_train\"].value\nlabels_train_orig = f[\"labels_train\"].value\nf.close()\n\n# # Extracting the dev dataset from the h5 file.\n# f = h5.File(\".\/dataset\/dev_set.hdf5\",'r')\n# print(\"Stored data:\",list(f.keys()))\n# # Storing the original data \"permanently\".\n# images_dev_orig = f[\"images_dev\"].value\n# labels_dev_orig = f[\"labels_dev\"].value\n# f.close()","caeee393":"images_train_orig[1]","7204d1c4":"labels_train_orig","08e2e6e6":"print(\"Train set\")\nprint(\"Images shape:\", images_train_orig.shape)\nprint(\"Images dtype:\", images_train_orig.dtype)\nprint(\"Min, max and mean pixel values:\", images_train_orig.min(),\"-\",\n      images_train_orig.max(),\"-\",\"{:5.1f}\".format(images_train_orig.mean()))\nprint(\"Labels shape:\", labels_train_orig.shape)\nprint(\"Labels dtype:\", labels_train_orig.dtype)","2ed72535":"def species(i):\n    if i == 1:\n        name = \"python\"\n    elif i==0:\n        name = \"rattlesnake\"\n    else:\n        name = \"dunno\"\n    return name","7ebdff40":"i = 7\nprint(\"Label =\",labels_train_orig[i],\"- A wild\", species(labels_train_orig[i]), \"appears.\")\nplt.imshow(images_train_orig[i])\nplt.show()","273c1396":"# Copying the original data for manipulation.\nimages_train = images_train_orig\nlabels_train = labels_train_orig.reshape([1,len(labels_train_orig)])\n ","f4642385":"# Scaling the data\nimages_train = images_train\/255\nimages_train = images_train.reshape((len(images_train),-1))\nimages_train = images_train.transpose()","6a47ac33":"# Shapes\nimsize = images_train.shape[0]\nprint(\"Images train shape\")\nprint(images_train.shape)\nprint(labels_train.shape)","c0e78337":"tf.__version__","2bb331b9":"tf.compat.v1.disable_eager_execution()","f415b3e8":"# Create placeholder for images, call it X.\ntf.compat.v1.reset_default_graph()\nX = tf.compat.v1.placeholder(tf.float32, shape=(imsize,None))\nY = tf.compat.v1.placeholder(tf.float32,shape=(1,None))\n\n# Create weights and biases. Initialize to zero.\nW = tf.compat.v1.get_variable(\"W\", [1,imsize], initializer=tf.zeros_initializer())\nb = tf.compat.v1.get_variable(\"b\", [1],initializer=tf.zeros_initializer())\n\n# Make the affine transformation\nlogits = tf.add(tf.matmul(W,X),b)\n\n# Calculating the cost\ncost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=logits))","5bc3cb7b":"epochs = 500\nalpha = 0.001\n# Creating the optimizer\n\noptimizer = tf.compat.v1.train.GradientDescentOptimizer(alpha).minimize(cost)\n\n# Initializing global variables\ninit = tf.compat.v1.global_variables_initializer()\n\n# Running session\nwith tf.compat.v1.Session() as sess:\n    sess.run(init)\n    costs_train = []\n#     costs_dev = []\n    for epoch in range(epochs):\n        _,epoch_cost = sess.run([optimizer,cost],feed_dict={X:images_train,Y:labels_train})\n        costs_train.append(epoch_cost)\n#         cost_dev = sess.run(cost,feed_dict={X:images_dev,Y:labels_dev})\n        print(epoch,epoch_cost)\n#         print(epoch,epoch_cost, cost_dev)\n#         costs_dev.append(cost_dev)\n    Weights, Bias = sess.run([W,b])","bf99d624":"train_curve, = plt.plot(costs_train, label = 'Train error')\n# test_curve,  = plt.plot(costs_dev, label = 'Dev error')\n# plt.legend(handles=[train_curve,test_curve])\nplt.legend(handles=[train_curve])\nplt.xlabel('Epochs')\nplt.ylabel('Mean log loss')","ad2e91d1":"def predict(x,w,b):\n    z = np.dot(w,x)+b\n    probs = 1\/(1+np.exp(-z))\n    y_pred = (probs > 0.5).astype(int)\n    return y_pred","8e686697":"def accuracy(label,y_pred):\n    acc = np.mean(np.equal(label,y_pred))\n    return acc","2aa0355f":"y_train_pred = predict(images_train,Weights,Bias)\n\nacc = accuracy(labels_train,y_train_pred)\n\nprint(\"Train set accuracy:\", acc)\n\n# y_dev_pred = predict(images_dev,Weights,Bias)\n\n# acc = accuracy(labels_dev,y_dev_pred)\n\n# print(\"Dev set accuracy:\",acc)","eec59c5b":"i = 0\nsample = images_train[:,i]\ntarget = labels_train[0,i]\nprediction = predict(sample,Weights,Bias)\nprint(\"It says it's a {}, it's actually a {}\".format(species(prediction),species(target)))\nprint((\"Good guess model! Take a cookie.\" if target == prediction else \"Bad model! No cookie for you.\"))\nplt.imshow(images_train_orig[i])\nplt.show()","883616cf":"def predictions(i):\n    sample = images_train[:,i]\n    target = labels_train[0,i]\n    prediction = predict(sample,Weights,Bias)\n    print(\"It says it's a {}, it's actually a {}\".format(species(prediction),species(target)))\n    print((\"Good guess model! Take a cookie.\" if target == prediction else \"Bad model! No cookie for you.\"))\n    plt.imshow(images_train_orig[i])\n    plt.show()","82426396":"predictions(1)","79559951":"predictions(3)","5cbfb43b":"# Logistic Regression\nLogistic regression (LR) is one of the simplest classification methods available, and shares important key ideas with shallow and deep neural networks, which we will use later. Although it's arguable that we can call LR a neural learning procedure, we will consider it so for the sake of this project's consistency. From now on, we will build all models' core engines using TensorFlow.\n\n# Building the model\nNow that our data is ready, let's build the model in tensorflow.","6b9b537e":"## Training the model\nTraining a logistic regression is pretty straightforward as demonstrated below. We use gradient descent optimizer, considering the gradient on the mean logloss over the whole trainning dataset. We also compute and store the cost on the dev dataset to analize the out-of-sample error.","801252a3":"# Error curves\nWe plot the train and dev set error stored during training to view the behavior of the optimizaton scheme.","868d0427":"# Preparing the data\nAs we saw earlyer, images are stored using 0-255 pixel values. We will scale them to 0-1 float values. Also, we linearize the pixel values on width, height and channels for each image.","bd3994e9":"# Prediction","5cea0e40":"# Model accuracy","ab2f99da":"# Import Library"}}