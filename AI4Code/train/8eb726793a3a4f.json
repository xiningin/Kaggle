{"cell_type":{"19f58270":"code","53710459":"code","827e944a":"code","511beed1":"code","600ddf71":"code","54af9a72":"code","dd8a2dd3":"code","bc38d53b":"code","90d8f85a":"code","ffda188a":"code","00661a21":"code","c612cc4d":"code","125f4261":"code","a800ed47":"markdown"},"source":{"19f58270":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\n%matplotlib inline","53710459":"#Importing the dataset\ndf = pd.read_csv(\"..\/input\/sample.csv\")\ndf","827e944a":"plt.scatter(df[\"X\"],df[\"Y\"],color='red')","511beed1":"msk=np.random.rand(len(df))<0.8\ntrain=df[msk]\ntest=df[~msk]","600ddf71":"plt.scatter(train[\"X\"],train[\"Y\"],color='red')","54af9a72":"from sklearn import linear_model\nregr=linear_model.LinearRegression()\ntrain_x=np.asanyarray(train[[\"X\"]])\ntrain_y=np.asanyarray(train[[\"Y\"]])\nregr.fit(train_x,train_y)\n\nprint(\"Coefficient: \",regr.coef_)\nprint(\"Intercept: \",regr.intercept_)","dd8a2dd3":"plt.scatter(train[\"X\"],train[\"Y\"],color='red')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0],'-b')","bc38d53b":"plt.scatter(test[\"X\"],test[\"Y\"],color='red')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0],'-b')","90d8f85a":"from sklearn.metrics import r2_score\ntest_x=np.asanyarray(test[[\"X\"]])\ntest_y=np.asanyarray(test[[\"Y\"]])\n\ny_pred=regr.predict(test_x)\n\nprint(\"R2_score:%.2f\" %r2_score(test_y,y_pred))\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_pred- test_y)))","ffda188a":"x=df[\"X\"]\ny=df[\"Y\"]","00661a21":"m=0\nc=0\n\nL=0.0001      #The Learning Rate\nepochs=1000   #The number of iterations to perform gradient descent\n\nn=float(len(x))   #Number of elements in x\n\n#Performing Gradient Desecent\nfor i in range(epochs):\n    y_pred = m*x + c    #The current predicted value of y\n    D_m=(-2\/n) * sum(x*(y-y_pred))  #Derivative wrt m\n    D_c=(-2\/n) * sum(y-y_pred)      #Derivative wrt c\n    m=m-L*D_m   #Update m\n    c=c-L*D_c   #Update c\nprint(m,c)    ","c612cc4d":"#Making Prediction\ny_pred=m*x + c\nplt.scatter(x,y)\nplt.plot([min(x),max(x)],[min(y_pred),max(y_pred)],color='red')  #show\nplt.show() ","125f4261":"print(\"r2_score:%.2f\" %r2_score(y,y_pred))","a800ed47":"**Improving the model by gradient descent**"}}