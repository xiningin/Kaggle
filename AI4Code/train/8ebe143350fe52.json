{"cell_type":{"fead5608":"code","8b545297":"code","80eabd10":"code","676cd9af":"code","b40d3fb2":"code","7e75746c":"code","2bb2e1af":"code","606be489":"code","104e3bf1":"code","7d3a8956":"code","eba5ddf3":"code","9c4a2274":"code","209072b2":"code","df8a3fc1":"code","c196819f":"code","1f7491a9":"code","235384fe":"code","7985512b":"markdown","bbc06dd0":"markdown","77efe530":"markdown","1d0c3a96":"markdown","672a22cc":"markdown","ebed35cb":"markdown","ab7174e6":"markdown"},"source":{"fead5608":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport seaborn as sns\nfrom tsfresh import extract_features\nimport re\nfrom collections import Counter\nfrom fbprophet import Prophet\nimport statsmodels.api as sm\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom matplotlib import pyplot\nfrom datetime import date, timedelta\nfrom scipy import stats\nimport scipy\nfrom statsmodels.tsa.api import ExponentialSmoothing\n\n\nnp.random.seed(0)\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n","8b545297":"train = pd.read_csv('\/kaggle\/input\/web-traffic-time-series-forecasting\/train_2.csv.zip').fillna(0)","80eabd10":"def rmsse(train, y, y_hat):\n    num = np.sum(np.power((y - y_hat), 2))\n    den = (1 \/ (len(train) - 1)) * np.sum(np.power(np.diff(train), 2))\n    return np.sqrt((1 \/ len(y)) * num  \/ den)\n\n\ndef smape(y_true, y_pred):\n    denominator = (np.abs(y_true) + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.nanmean(diff)\n\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\n\ndef ts_folds(x, n, h, val_type='exp_wind'):\n    assert len(x) - 2 * h > n * h, \"horisont or number of folds are too large.\"\n    assert n > 0 and h > 0\n    \n    l = len(x)\n    folds = []\n    \n    if val_type == 'exp_wind':\n        for i in range(n):\n            folds.append((x[:l - h*(i + 1)], x[l - h*(i+1):l - h*i]))\n    \n    return folds\n\n\ndef plot_ts(x_ts, info):\n    x = x_ts.values\n    \n    ts_name = 'X'\n    fig, axes = plt.subplots(3, 2, figsize=(18, 20))\n\n    axes[0, 0].set_title(f\"Original, id: {info['id']}\", fontsize=16)\n    axes[0, 0].plot(x, label=ts_name)\n    axes[0, 0].set_ylabel('X', fontsize=16)\n    axes[0, 0].set_xlabel('t', fontsize=16)\n    axes[0, 0].legend()\n\n    plot_acf(x, lags=90, ax=axes[0, 1])\n\n    sns.distplot(x, bins=100, kde=True, ax=axes[1, 0])\n    axes[1, 0].set_xlabel('X', fontsize=16)\n    axes[1, 0].set_title('Histogram', fontsize=16)\n\n    x_ts.diff().plot(ax=axes[1, 1], title='1 step difference')\n\n    axes[2, 0].set_title('Box plot (grouped by months)', fontsize=16)\n    sns.boxplot(x_ts.index.month, x_ts, ax=axes[2, 0])\n\n    axes[2, 1].plot(x_ts, label=ts_name)\n    x_ts.rolling(window=7).mean().plot(ax=axes[2, 1], label='W=7')\n    x_ts.rolling(window=30).mean().plot(ax=axes[2, 1], label='W=30')\n    x_ts.rolling(window=60).mean().plot(ax=axes[2, 1], label='W=60')\n    axes[2, 1].legend()\n    axes[2, 1].set_title('Moving average', fontsize=16)\n    axes[2, 1].set_ylabel('X', fontsize=16)\n    axes[2, 1].set_xlabel('t', fontsize=16)\n\n    plt.show()\n    \n    res = seasonal_decompose(x_ts, model='additive')\n    \n    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 15))\n    fig.suptitle('additive decomposition')\n    res.observed.plot(ax=ax1)\n    ax1.set_ylabel('original')\n    res.trend.plot(ax=ax2)\n    ax2.set_ylabel('trend')\n    res.seasonal.plot(ax=ax3)\n    ax3.set_ylabel('seasonal')\n    res.resid.plot(ax=ax4)\n    ax4.set_ylabel('residuals')\n\n    pass\n    # return fig, axes\n\n\ndef plot_prediction(train, val, y_hat, plot_len=None, title=None):\n    if plot_len == None:\n        plot_len = len(train) + len(val)\n    \n    l = len(train)\n    train_range = np.arange(l)\n    val_range = np.arange(l, l + len(val))\n    all_range = np.arange(l + len(val))\n\n    fig = plt.figure(figsize=(14, 8))\n    plt.plot(train_range, train, '.-b', label='train')\n    plt.plot(val_range, val, '.-g', label='val')\n    plt.plot(val_range, y_hat, '.-r', label='forecast')\n    plt.xlim([all_range[-plot_len:][0], all_range[-plot_len:][-1]])\n    plt.legend()\n    plt.vlines(l, -1e6, 1e6, 'k', 'dashed')\n    plt.ylim([np.min([np.min(train[-plot_len:]), np.min(val)])-1, np.max([np.max(train[-plot_len:]), np.max(val)])+10])\n    plt.title(title)\n    plt.show()\n\n\nclass TransformTS():\n    def __init__(self, tr_type, handle_missing=None):\n        self.tr_type = tr_type\n        self.handle_missing = handle_missing\n    \n    def transform(self, x):\n        if self.tr_type == 'ln_p1':\n            y = np.log(x + 1)\n        elif self.tr_type == 'ln':\n            y = np.log(x)\n        elif self.tr_type == 'sqrt':\n            y = np.sqrt(x)\n        elif self.tr_type == 'boxcox':\n            y, lb = stats.boxcox(x)\n            self.lb = lb\n        else:\n            raise ValueError\n            \n        return y\n    \n    def reverse(self, x):\n        if self.tr_type == 'ln_p1':\n            y = np.exp(x) - 1\n        elif self.tr_type == 'ln':\n            y = np.exp(x)\n        elif self.tr_type == 'sqrt':\n            y = np.power(x, 2)\n        elif self.tr_type == 'boxcox':\n            y = scipy.special.inv_boxcox(x, self.lb)\n        else:\n            raise ValueError\n        \n        return y\n","676cd9af":"# Models.\nHORIZONT = 64\n\n\ndef prophet_fc(x, h=HORIZONT):\n    # Prophet model.\n    # pr_df = pd.DataFrame({'y': x['y'], 'ds': x['ds']})\n    m = Prophet()\n    m.fit(x)\n    future = m.make_future_dataframe(periods=h)\n    forecast = m.predict(future)\n    y_hat = forecast['yhat'][-h:]\n    return y_hat\n\n\ndef naive(x, h=HORIZONT):\n    return np.ones(h) * np.mean(x[-HORIZONT:])\n\n\ndef naive2(x, h=HORIZONT):\n    return np.ones(h) * x[-1]\n\n\ndef arima_mdl(x, order, h=HORIZONT):\n    p, d, q = order\n    l = len(x)\n\n    mod = sm.tsa.statespace.SARIMAX(x, order=(p, d, q), trend='c').fit(disp=False)\n    y_hat = mod.forecast(steps=HORIZONT)\n\n    return y_hat\n\n\ndef agg_weekly(x, window=64, h=HORIZONT, avg_type='mean'):\n    xs = x[-window:]\n    \n    # Median grouped by weekday.\n    medians = [xs[xs.index.weekday == i].median() for i in range(7)]\n    means = [xs[xs.index.weekday == i].mean() for i in range(7)]\n    \n    d = x.index[-1].weekday()\n    y_hat = np.zeros(HORIZONT)\n\n    for n in range(HORIZONT):\n        if d == 6:\n            d = 0\n        else:\n            d = d + 1\n        \n        if avg_type == 'median':\n            y_hat[n] = medians[d]\n        elif avg_type == 'mean':\n            y_hat[n] = means[d]\n        else:\n            raise ValueError\n\n    return y_hat\n\n\ndef exp_smoothing(x_train, config, h=HORIZONT):\n    t,d,s,p,b,r = config\n\n    model = ExponentialSmoothing(x_train, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n    yhat = model_fit.forecast(h)\n    \n    return yhat\n","b40d3fb2":"# An example of the time series and Naive forecast.\n\ni = 100\nx_df = train.iloc[i]\nx_ts = pd.Series(x_df.values[1:].astype(float), index=x_df.index[1:])\nx_ts.index = pd.to_datetime(x_ts.index)\nx = x_ts.values\n\nfolds = ts_folds(x, n=1, h=HORIZONT)\n\nx_train = folds[0][0]\ny_val = folds[0][1]\n\ny_hat = naive(x_train)\nplot_prediction(x_train, y_val, y_hat, plot_len=400, title=f\"naive forecast, SMAPE={smape(y_val, y_hat):.3f}\")","7e75746c":"# Prophet model.\n\nx_df = pd.DataFrame({'ds': x_ts.index, 'y': x_ts.values})\nm = Prophet()\n\nm.fit(x_df)\nfuture = m.make_future_dataframe(periods=HORIZONT)\nforecast = m.predict(future)\ny_hat = forecast['yhat'][-HORIZONT:]\ny_hat[y_hat < 0] = 0\n\nplot_prediction(x_train, y_val, y_hat, plot_len=400, title=f\"prophet, SMAPE={smape(y_val, y_hat):.3f}\")\nfig1 = m.plot(forecast)","2bb2e1af":"# Config for ETS Models.\nt_params = ['add', 'mul', None]\nd_params = [True, False]\ns_params = ['add', 'mul', None]\np_params = [5, 7, 12, 14, 30]\nb_params = [True, False]\nr_params = [True, False]\n\ncfg_list = []\nfor t in t_params:\n    for d in d_params:\n        for s in s_params:\n            for p in p_params:\n                for b in b_params:\n                    for r in r_params:\n                        if d is True and t is None:\n                            continue\n                        cfg = [t, d, s, p, b, r]\n                        cfg_list.append(cfg)\n\n# print(f'{len(cfg_list)} combinations')","606be489":"# List of models.\n\ndef eval_models(train, y_val, m_list):\n    \n    models = []\n\n    # Naive1.\n    if 'naive1' in m_list:\n        y_hat = naive(train.values, h=HORIZONT)\n        y_hat[y_hat < 0] = 0\n        models.append({\n            'name': 'naive1',\n            'y_pred': y_hat,\n            'smape': smape(y_val, y_hat),\n            'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n            'model': None}\n        )\n\n    # Naive2.\n    if 'naive2' in m_list:\n        y_hat = naive2(train.values, h=HORIZONT)\n        y_hat[y_hat < 0] = 0\n        models.append({\n            'name': 'naive2',\n            'y_pred': y_hat,\n            'smape': smape(y_val, y_hat),\n            'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n            'model': None}\n        )\n    \n    # Prophet.\n    if 'prophet' in m_list:\n        x_df = pd.DataFrame({'ds': train.index, 'y': x_train.values})\n        y_hat = prophet_fc(x_df, h=HORIZONT)\n        y_hat[y_hat < 0] = 0\n        models.append({\n            'name': 'prophet',\n            'y_pred': y_hat,\n            'smape': smape(y_val, y_hat),\n            'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n            'model': None}\n        )\n    \n    # ARIMA models.\n    for p in range(30):\n        for d in [0, 1]:\n            for q in range(4):\n                m_name = f'arima_{p}_{d}_{q}'\n        \n                if m_name in m_list:\n                    try:\n                        y_hat = arima_mdl(train, (p, d, q), h=HORIZONT)\n                        conv = True\n                    except:\n                        y_hat = naive(train.values, h=HORIZONT)\n                        conv = False\n                    y_hat[y_hat < 0] = 0\n                    models.append({\n                        'name': m_name,\n                        'y_pred': y_hat,\n                        'smape': smape(y_val, y_hat),\n                        'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n                        'model': None,\n                        'conv':  conv,\n                    })\n    \n    # Average by weekdays.\n    winds = [7, 32, 64, 96]\n    for w in winds:\n        if f'weekly_mean_w-{w}' in m_list:\n            y_hat = agg_weekly(train, window=w, h=HORIZONT, avg_type='mean')\n            y_hat[y_hat < 0] = 0\n            models.append({\n                'name': f'weekly_mean_w-{w}',\n                'y_pred': y_hat,\n                'smape': smape(y_val, y_hat),\n                'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n                'model': None}\n            )\n    \n    winds = np.arange(1, 13) * 7\n    for w in winds:\n        if f'weekly_median_w-{w}' in m_list:\n            y_hat = agg_weekly(train, window=w, h=HORIZONT, avg_type='median')\n            y_hat[y_hat < 0] = 0\n            models.append({\n                'name': f'weekly_median_w-{w}',\n                'y_pred': y_hat,\n                'smape': smape(y_val, y_hat),\n                'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n                'model': None}\n            )\n\n    \n    # ETS models.\n    for cfg in cfg_list:\n        if f\"ets_{cfg}\" in m_list:\n            \n            # remove zeros for box-cox and mult trend.\n            train = train + 1\n            \n            y_hat = exp_smoothing(train, cfg, h=HORIZONT)\n            \n            if y_hat.isnull().values.any() or np.isinf(y_hat.values).any():\n                y_hat = naive(train.values, h=HORIZONT)\n                conv = False\n            else:\n                conv = True\n            \n            # reverse transformation.\n            y_hat = y_hat - 1\n            y_hat[y_hat < 0] = 0\n\n            models.append({\n                'name': f'ets_{cfg}',\n                'y_pred': y_hat,\n                'smape': smape(y_val, y_hat),\n                'rmse': np.sqrt(mean_squared_error(y_hat, y_val)),\n                'model': None,\n                'conv':  conv,}\n            )\n        \n    return models\n","104e3bf1":"# Cross validation, N-fold expanding window.\n\nN_FOLDS = 1\nMAX_EVAL = 2200\n\npower_trans = True\n\nmetr_arr = []\npred_arr = []\n\n# Models to evaluate.\nm_list = [\n    'naive1',\n    # 'naive2',\n    'prophet',\n    'weekly_median_w-28',\n    'weekly_median_w-35',\n    'weekly_median_w-42',\n    'weekly_median_w-49',\n    'weekly_median_w-56',\n    'weekly_median_w-63',\n    \"ets_['add', True, 'add', 5, True, False]\",\n    \"ets_['add', True, 'add', 7, True, False]\",\n    \"ets_['add', True, 'add', 12, True, False]\",\n    \"ets_['add', True, 'add', 14, True, False]\",\n    'arima_6_1_1',\n]\n\n# ETS models.\n# for cfg in cfg_list:\n#     m_list.append(f\"ets_{cfg}\")\n    \nnp.random.seed(0)\nidx = np.arange(train.shape[0])\nind_list = np.random.choice(idx, size=MAX_EVAL, replace=False)\n\n\nfor k, i in enumerate(ind_list):\n    if k % 1000 == 0:\n        print('step:', k)\n\n    x_df = train.iloc[i]\n    x_ts = pd.Series(x_df.values[1:].astype(float), index=x_df.index[1:])\n    x_ts.index = pd.to_datetime(x_ts.index)\n\n    folds = ts_folds(x_ts, n=N_FOLDS, h=HORIZONT)\n    \n    for n in range(N_FOLDS):\n        x_train = folds[n][0]\n        y_val = folds[n][1].values\n\n        # Check if last 64 values are zero. Predict with zeros.\n        if np.sum(x_train[-64:].values) == 0:\n            print('zeros')\n            y_hat = np.zeros(HORIZONT)\n            models = []\n            for name in m_list: \n                models.append({\n                'name': name,\n                'smape': smape(y_val, y_hat),\n                'y_pred': y_hat,\n                'rmse': np.sqrt(mean_squared_error(y_hat, y_val))\n                })\n        else:\n            models = eval_models(x_train, y_val, m_list)\n        \n        for m in models:\n            x = {\n                'id': i,\n                'fold_num': n,\n                'name': m['name'],\n                'smape': m['smape'],\n                'rmse': m['rmse']\n            }\n            \n            metr_arr.append(x)\n            \n            pred_arr.append({\n                'id': i,\n                'fold_num': n,\n                'smape': m['smape'],\n                'rmse': m['rmse'],\n                'name': m['name'],\n                'y_hat': m['y_pred'],\n                'x_train': x_train,\n                'y_val': y_val\n            })\n\n    if k == MAX_EVAL:\n        break\n\nmetr_df = pd.DataFrame(metr_arr)\npred_df = pd.DataFrame(pred_arr)","7d3a8956":"# Plotting metrics.\n# Adjusted by \"naive1\" for each id and each fold.\n\nfor i in metr_df['id'].unique():\n    for n in metr_df['fold_num'].unique():\n        d = metr_df[(metr_df['id'] == i) & (metr_df['fold_num'] == n)]\n        metr_df.loc[(metr_df['id'] == i) & (metr_df['fold_num'] == n), 'smape_adj'] = d['smape'] \/ d[d['name'] == 'naive1']['smape'].values[0]\n        metr_df.loc[(metr_df['id'] == i) & (metr_df['fold_num'] == n), 'rmse_adj'] = d['rmse'] \/ d[d['name'] == 'naive1']['rmse'].values[0]\n","eba5ddf3":"# Plot ungrouped. SMAPE adj.\n\ndef plot_metr(metr, df):\n        \n    arr = m_list[:]\n    # arr.remove('naive1')\n\n    for n, mod_name in enumerate(arr):\n        n = 0\n        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n        x = df[df['name'] == mod_name][metr].values\n\n        sns.distplot(x, bins=40, kde=True, ax=axes[0])\n        axes[0].set_title(f'Model: {mod_name}', fontsize=14)\n        axes[0].set_xlabel(metr, fontsize=14)\n\n        axes[1].plot(x, '.')\n        axes[1].set_ylabel(metr, fontsize=14)\n        # axes[1].plot([1]*len(x), '--k')\n        axes[1].set_title(f'{metr} MEAN = {np.mean(x):.5f}', fontsize=14)\n        plt.show()\n","9c4a2274":"probl_ids = metr_df[metr_df['smape_adj'].isnull()]['id'].unique()\n# cleaning\ndf = metr_df.replace([np.inf, -np.inf], np.nan)\ndf = df.dropna()","209072b2":"# metr = 'smape_adj'\nmetr = 'smape'\nplot_metr(metr, df)","df8a3fc1":"# Table of metrics.\nprint(f'Number of series: {MAX_EVAL}')\nagg_df = df.groupby('name').mean().drop(['id', 'fold_num'], axis=1)\ndisplay(agg_df)","c196819f":"# Plotting outliers for some model.\n\n# m_name = 'weekly_median_w-63'\nm_name = agg_df['smape'].idxmin()\nprint('Models name:', m_name)\n\n# Inspect all that higher than 60.\nsmape_cut = 60\nfold_num = 0\n\nids = df[(df['smape'] > smape_cut) & (df['name'] == m_name) & (df['fold_num'] == fold_num)]['id'].unique()\ni = ids[0]\n\n# Plot several from the list.\nfor i in ids[:5]:\n    x = pred_df[(pred_df['id'] == i) & (pred_df['fold_num'] == fold_num) & (pred_df['name'] == m_name)]\n    smape_val = x['smape'].values[0]\n    y_hat = x['y_hat'].values[0]\n    y_val = x['y_val'].values[0]\n    x_train = x['x_train'].values[0]\n    \n    plot_prediction(x_train, y_val, y_hat, plot_len=400, title=f\"Id: {i}, SMAPE: {smape_val}\")\n","1f7491a9":"# Plot several good fits.\nm_name = agg_df['smape'].idxmin()\nprint('Models name:', m_name)\n\n# Inspect all that higher than 60.\nfold_num = 0\n\nids = df[(df['smape'] > 30) & (df['smape'] < 37) & (df['name'] == m_name) & (df['fold_num'] == fold_num)]['id'].unique()\ni = ids[0]\n\n# Plot several from the list.\nfor i in ids[:5]:\n    x = pred_df[(pred_df['id'] == i) & (pred_df['fold_num'] == fold_num) & (pred_df['name'] == m_name)]\n    smape_val = x['smape'].values[0]\n    y_hat = x['y_hat'].values[0]\n    y_val = x['y_val'].values[0]\n    x_train = x['x_train'].values[0]\n    \n    plot_prediction(x_train, y_val, y_hat, plot_len=400, title=f\"Id: {i}, SMAPE: {smape_val}\")\n","235384fe":"# Building the submission on isolated models.\n\nsubm = True\n# subm = False\n\n\nif subm:\n    print('Building the submission...')\n    \n    keys = pd.read_csv('\/kaggle\/input\/web-traffic-time-series-forecasting\/key_2.csv.zip')\n    keys['date'] = keys['Page'].apply(lambda x: x.split(\"_\")[-1])\n    keys['name'] = keys['Page'].apply(lambda x: '_'.join(x.split(\"_\")[:-1]))\n    keys['horisont_day'] = None\n    sdate = date(2017, 9, 13)\n    edate = date(2017, 11, 13)\n    delta = edate - sdate\n    dates_list = [str(sdate + timedelta(days=i)) for i in range(delta.days + 1)] \n    for n, d in enumerate(dates_list):\n        keys.loc[keys['date'] == d, 'horisont_day'] = n\n    \n    # One model on which to build the submission.\n    m_list = ['weekly_median_w-49']\n    # m_list = [\"ets_['add', True, 'add', 7, True, False]\"]\n    \n    res = []\n\n    print('Predicting...')\n    for k, i in enumerate(np.arange(train.shape[0])):\n        if k % 10000 == 0:\n            print('Step:', k)\n\n        x_df = train.iloc[i]\n        page = x_df['Page']\n        \n        x_ts = pd.Series(x_df.values[1:].astype(float), index=x_df.index[1:])\n        x_ts.index = pd.to_datetime(x_ts.index)\n\n        # Check if last 50 values are zero. If so, predict with zeros.\n        if np.sum(x_ts[-50:].values) == 0:\n            y_hat = np.zeros(HORIZONT)\n        else:\n            models = eval_models(x_ts, np.ones(HORIZONT), m_list)\n            y_hat = models[0]['y_pred']\n        \n        # 62 last days out of 64.\n        y_hat = y_hat[2:]\n        for m, y in enumerate(y_hat):\n            res.append({'name': page, 'horisont_day': m, 'Visits': y})\n\n    res_df = pd.DataFrame(res)\n\n    subm = res_df.merge(keys, how='left', on=['name', 'horisont_day'])\n    subm['Visits'] = subm['Visits'].map(np.round).astype(int)\n    subm_df = subm[['Id', 'Visits']].sort_values(by='Id')\n    # subm_df.head()\n    subm_df.to_csv('subm.csv', encoding='utf-8', index=False)\n","7985512b":"## Plotting forecasts for several bad fits:","bbc06dd0":"### Here are all models:","77efe530":"## Plotting forecasts for several good fits.","1d0c3a96":"### This notebook contains a comparison of various classical forecasting models for Google Web Traffic dataset: https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting.","672a22cc":"### A baseline we chose is a naive constant forecast. SMAPE metric is used.","ebed35cb":"### Evaluation of models for 1 fold.","ab7174e6":"### Creating submission by modeling each time series separately."}}