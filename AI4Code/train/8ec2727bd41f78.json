{"cell_type":{"a705143e":"code","94ec4389":"code","6cc85d40":"markdown"},"source":{"a705143e":"import numpy as np\nimport pandas as pd \nimport os \n\ndef MinMaxBestBaseStacking(input_folder, best_base, output_path):\n    sub_base = pd.read_csv(best_base)\n    all_files = os.listdir(input_folder)\n\n    # Read and concatenate submissions\n    outs = [pd.read_csv(os.path.join(input_folder, f), index_col=0) for f in all_files]\n    concat_sub = pd.concat(outs, axis=1)\n    cols = list(map(lambda x: \"target\" + str(x), range(len(concat_sub.columns))))\n    concat_sub.columns = cols\n    concat_sub.reset_index(inplace=True)\n\n    # get the data fields ready for stacking\n    concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\n    concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\n    concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\n    concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)\n\n    # set up cutoff threshold for lower and upper bounds\n    cutoff_lo = 0.73\n    cutoff_hi = 0.33\n\n    concat_sub['is_iceberg_base'] = sub_base['target']\n    concat_sub['target'] = np.where(np.all(concat_sub.iloc[:, 1:6] > cutoff_lo, axis=1),\n                                        concat_sub['is_iceberg_max'],\n                                        np.where(np.all(concat_sub.iloc[:, 1:6] < cutoff_hi, axis=1),\n                                                 concat_sub['is_iceberg_min'],\n                                                 concat_sub['is_iceberg_base']))\n    concat_sub[['image_name', 'target']].to_csv(output_path,\n                                            index=False, float_format='%.12f')\n    \n# def ensemble():\n#     stacked_0 = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\n    \n#     stacked_1 = pd.read_csv('\/kaggle\/input\/melanoma-submissions2\/submissionImage.csv')\n#     stacked_2 = pd.read_csv('\/kaggle\/input\/melanoma-submissions2\/submissionTabular.csv')\n#     stacked_4 = pd.read_csv('\/kaggle\/input\/melanoma-submissions2\/submission_multiple_data_source.csv')\n#     stacked_3 = pd.read_csv('..\/input\/csv001\/lgbm_baseline_sub.csv')    \n#     stacked_5 = pd.read_csv('..\/input\/csv001\/sub77.csv')\n#     stacked_6 = pd.read_csv('..\/input\/csv001\/submission.csv')\n#     stacked_7 = pd.read_csv('..\/input\/csv001\/submission_models_blended.csv')\n    \n#     sub = pd.DataFrame()\n#     sub['image_name'] = stacked_0['image_name']\n#     sub['target'] = np.exp(np.mean(\n#         [\n#             stacked_1['target'].apply(lambda x: np.log2(x)), \\\n#             stacked_2['target'].apply(lambda x: np.log2(x)), \\\n#             stacked_4['target'].apply(lambda x: np.log2(x)), \\\n#             stacked_3['target'].apply(lambda x: np.log2(x)), \n#             stacked_5['target'].apply(lambda x: np.log2(x)), \\\n#             stacked_6['target'].apply(lambda x: np.log2(x)), \\\n#             stacked_7['target'].apply(lambda x: np.log2(x)),           \n#             ], axis=0))\n#     sub.to_csv('submission.csv', index=False, float_format='%.6f')","94ec4389":"# ensemble()\n# sub.to_csv('submission.csv', index = False)\n\nMinMaxBestBaseStacking('..\/input\/csv001\/', '..\/input\/base001\/datasets_766461_1344911_submission_rank-then-blend.csv', 'submission.csv') # 0.9526 \n# MinMaxBestBaseStacking('..\/input\/csv001\/', '..\/input\/csv001\/submission_efnet.csv', 'submission.csv')\n# MinMaxBestBaseStacking('..\/input\/csv001\/', '..\/input\/csv001\/submission0.9504.csv', 'submission.csv')\n\n\n\n\n","6cc85d40":"### I claim no credit for the CSV's. many thanks to the respective authers who wrote them. \n(https:\/\/www.kaggle.com\/redwankarimsony\/melanoma-submissions2?select=submission_multiple_data_source.csv) \n(https:\/\/www.kaggle.com\/ragnar123\/rank-then-blend) \n(https:\/\/www.kaggle.com\/shivam17818\/test-all-efficientnet-model-b0-b7\/output)\n(https:\/\/www.kaggle.com\/truonghoang\/stacking-ensemble-on-my-submissions\/output)\n\nEnsemble learning is an excellent machine learning idea which displays noticeable benefits in many applications, one such notable example is the widespread use of ensembles in Kaggle competitions. In an ensemble several individual models (for instance ResNet18 and VGG16) which were trained on the same corpus, work in tandem and during inference, their predictions are fused by a pre-defined strategy to yield a single prediction. \n\n\nThe code below was adapted from something i wrote few years ago (https:\/\/github.com\/QuantScientist\/Deep-Learning-Boot-Camp\/blob\/master\/Kaggle-PyTorch\/PyTorch-Ensembler\/utils.py) \n\nYou can set up cutoff thresholds for the lower and upper bounds with this:\n\n    cutoff_lo = 0.88\n    cutoff_hi = 0.11\n"}}