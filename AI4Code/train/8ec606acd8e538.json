{"cell_type":{"c360cebf":"code","32e378c1":"code","32da97a4":"code","67436227":"code","6f70e941":"code","5f698914":"code","22b2bfcc":"code","e254197c":"code","0b6ba750":"markdown","920f8984":"markdown","000476fd":"markdown","0aef2866":"markdown","a684c16d":"markdown","b15cab5b":"markdown","07df1029":"markdown","55ffb3d2":"markdown","183dee81":"markdown"},"source":{"c360cebf":"# Load needed packages\nimport numpy as np\nimport pandas as pd\nimport pystan\nimport matplotlib.pyplot as plt\nimport random\n\n# Import data\ndat = pd.read_csv(\"..\/input\/Prelim2019_RegularSeasonDetailedResults.csv\") \nteam_key = pd.read_csv(\"..\/input\/datafiles\/Teams.csv\")[[\"TeamID\", \"TeamName\"]]\n\n# Filter to 2019\ndat = dat[dat.Season == 2019].reset_index(drop = True)\n\n# Make home\ndat['homei'] = np.where(dat.WLoc == \"H\", 1, 0)\ndat['homej'] = np.where(dat.WLoc == \"A\", 1, 0)\n\n# Create margin\ndat['margin'] = dat.WScore - dat.LScore\n\n# Filter to needed columns and rename\ndat = dat[[\"Season\", \"DayNum\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"margin\", \"homei\", \"homej\"]]\ndat = dat.rename(columns={'WTeamID' : 'teami',\n                          'WScore'  : 'scorei', \n                          'LTeamID' : 'teamj', \n                          'LScore'  : 'scorej',\n                          'DayNum'  : 'daynum',\n                          'Season'  : 'season'})\n\n# Create a game id\ndat[\"gameid\"] = np.where(dat['teami'] < dat['teamj'], \n                         dat['teami'].astype(str) + \"_\" + dat['teamj'].astype(str), \n                         dat['teamj'].astype(str) + \"_\" + dat['teami'].astype(str))\n\n# Set up team id mapping\nteam_key[\"id\"] = range(1, len(team_key.index) + 1)\n\n# Recoding ids to be between 1 and 366\ndat = dat.merge(team_key, left_on=\"teami\" , right_on=\"TeamID\")\ndat = dat.drop(columns=[\"TeamName\", \"teami\", \"TeamID\"])\ndat = dat.rename(index = str, columns = {\"id\" : \"teami\"})\ndat = dat.merge(team_key, left_on=\"teamj\" , right_on=\"TeamID\")\ndat = dat.drop(columns=[\"TeamName\", \"teamj\", \"TeamID\"])\ndat = dat.rename(index = str, columns = {\"id\" : \"teamj\"})\n\n# Final dataset for modeling\nnames = [\"N\", \"y\", \"h_i\", \"h_j\", \"team_i\", \"team_j\", \"N_g\"]\nvalues = [len(dat.index), dat.margin, dat.homei, dat.homej, dat.teami, dat.teamj, 366]\n\ntrain = dict(zip(names, values))\n","32e378c1":"model = \"\"\"\ndata {\n    int N;\n    vector[N] y;\n    int team_i[N];\n    int team_j[N];\n    int h_i[N];\n    int h_j[N];\n    int N_g;\n}\nparameters {\n    vector[N_g] alpha_raw;\n    vector[N_g] theta_raw;\n    real eta;\n    real<lower=0> tau_theta;\n    real<lower=0> tau_alpha;\n    real<lower=0> sigma;\n}\ntransformed parameters {\n    vector[N_g] alpha;\n    vector[N_g] theta;\n    alpha = eta + alpha_raw*tau_alpha;\n    theta = theta_raw*tau_theta;\n}\nmodel {\n    \/\/ vector for conditional mean storage\n    vector[N] mu;\n\n    \/\/ priors\n    tau_theta ~ cauchy(0,1)T[0,];\n    tau_alpha ~ cauchy(0,.25)T[0,];\n    sigma ~ cauchy(0,1)T[0,];\n    eta ~ normal(4,1);\n    theta_raw ~ normal(0,1);\n    alpha_raw ~ normal(0,1);\n\n    \/\/ define mu for the Gaussian\n    for( t in 1:N ) {\n    mu[t] = (theta[team_i[t]] + alpha[team_i[t]]*h_i[t]) - \n    (theta[team_j[t]] + alpha[team_j[t]]*h_j[t]);\n}\n\n    \/\/ the likelihood\n    y ~ normal(mu,sigma);\n}\n\"\"\"\n\nsm = pystan.StanModel(model_code = model)\nfit = sm.sampling(data = train, \n                  iter = 1500, \n                  warmup = 750,\n                  refresh = 100,\n                  control = dict(adapt_delta = 0.9))\n","32da97a4":"# Extracting team skill levels\ntheta = pd.DataFrame(fit.extract()[\"theta\"])\nalpha = pd.DataFrame(fit.extract()[\"alpha\"])\nsigma = fit.extract()[\"sigma\"]\nalpha.columns = team_key.TeamName\ntheta.columns = team_key.TeamName\n\n# Filtering to top 25 teams\ntheta25 = theta[theta.median().nlargest(25).index]\ntheta25 = theta25[theta25.columns[::-1]]\n\n# Creating the plot\ntheta25.boxplot(grid = False, vert = False, showfliers = False, figsize=(12, 8))\nplt.title('Team Power Rankings')\nplt.xlabel('Skill Level')\nplt.ylabel('Teams')","67436227":"# Setting up seed for reproducability\nrandom.seed(6)\n\n# Making the skill density plots for Kansas vs Kansas St\ntheta[[\"Kansas\" , \"Kansas St\"]].plot(kind='density', \n                                     color = [\"blue\", \"purple\"], \n                                     figsize=(12, 8))\nplt.title('KU vs K-State at Neutral Site')\nplt.xlabel('Skill Level')\nplt.xlim([7.5, 20])\n\n# Doing one game draw\nplt.axvline(theta[\"Kansas\"][random.randrange(len(theta[\"Kansas\"]))], color = \"blue\")\nplt.axvline(theta[\"Kansas St\"][random.randrange(len(theta[\"Kansas St\"]))], color = \"purple\")\n","6f70e941":"# Setting up seed for reproducability\nrandom.seed(6)\n\n# Setting up a home court adjusted dataset for Kstate\n# Promise the actual function is more elegant\nftheta = theta.copy()\nftheta[\"Kansas St\"] = ftheta[\"Kansas St\"] + alpha[\"Kansas St\"]\n\n# Making the skill density plots for Kansas vs Kansas St\nftheta[[\"Kansas\" , \"Kansas St\"]].plot(kind='density', \n                                     color = [\"blue\", \"purple\"],\n                                     figsize=(12, 8))\nplt.title('KU vs K-State at K-State')\nplt.xlabel('Skill Level')\nplt.xlim([7.5, 20])\n\n# Doing one game draw\nplt.axvline(ftheta[\"Kansas\"][random.randrange(len(ftheta[\"Kansas\"]))], color = \"blue\")\nplt.axvline(ftheta[\"Kansas St\"][random.randrange(len(ftheta[\"Kansas St\"]))], color = \"purple\")\n","5f698914":"# Setting seed\nrandom.seed(1865)\n\n# Defining compare function\ndef compare(i, j, th= theta, a = alpha, sig = sigma, homei = 0, homej = 0, reps = 1000):\n    win_prob = []\n    \n    # Simulating specified number of games\n    for r in range(1, reps):\n        win_prob.append(\n            np.mean(\n                \n                # Ability difference\n                th[i] - th[j] +\n                \n                # Adjusting for home court\n                a[i]*homei - a[j]*homej +\n                \n                # Team performance variance\n                np.random.normal(0, \n                                 sig[random.randrange(len(sig))], \n                                 len(th.index)\n                ) > 0\n            )\n        )\n    \n    # Averaging game results\n    win_prob = np.mean(win_prob)\n    \n    # Displaying results\n    print(i + \" has a \" + str(round(win_prob*100, 2)) + \"% chance of beating \" + j)\n    \n# Looking at final game\ncompare(\"Virginia\", \"Texas Tech\")","22b2bfcc":"# Getting table of games played\ngames = pd.DataFrame(np.array([['Play in',  \"N Dakota St\", \"NC Central\",   0, 0, .68],\n                               ['Play in',  \"Arizona St\",  \"St John's\",    0, 1, .53],\n                               ['Play in',  \"F Dickinson\", \"Prairie View\", 0, 0, .55],\n                               ['Play in',  \"Belmont\",     \"Temple\",       0, 0, .58],\n                               \n                               ['Rd 64',    \"Duke\",           \"N Dakota St\",     1, 0, 1.0], \n                               ['Rd 64',    \"Virginia\",       \"Gardner Webb\",    0, 0, .98], \n                               ['Rd 64',    \"Gonzaga\",        \"F Dickinson\",     1, 0, .99], \n                               ['Rd 64',    \"North Carolina\", \"Iona\",            0, 0, .98], \n                               ['Rd 64',    \"Michigan St\",    \"Bradley\",         0, 0, .96], \n                               ['Rd 64',    \"Kentucky\",       \"Abilene Chr\",     1, 0, .97], \n                               ['Rd 64',    \"Tennessee\",      \"Colgate\",         0, 0, .95], \n                               ['Rd 64',    \"Michigan\",       \"Montana\",         1, 0, .94], \n                               ['Rd 64',    \"Texas Tech\",     \"N Kentucky\",      0, 0, .91], \n                               ['Rd 64',    \"Purdue\",         \"Old Dominion\",    0, 0, .88], \n                               ['Rd 64',    \"Virginia Tech\",  \"St Louis\",        0, 1, .89], \n                               ['Rd 64',    \"Auburn\",         \"New Mexico St\",   0, 1, .77], \n                               ['Rd 64',    \"Florida\",        \"Nevada\",          0, 0, .42], \n                               ['Rd 64',    \"Florida St\",     \"Vermont\",         0, 1, .79], \n                               ['Rd 64',    \"Ohio St\",        \"Iowa St\",         0, 0, .33], \n                               ['Rd 64',    \"Villanova\",      \"St Mary's CA\",    1, 0, .75], \n                               ['Rd 64',    \"LSU\",            \"Yale\",            0, 0, .84], \n                               ['Rd 64',    \"Oklahoma\",       \"Mississippi\",     0, 0, .53], \n                               ['Rd 64',    \"Oregon\",         \"Wisconsin\",       1, 0, .40], \n                               ['Rd 64',    \"UC Irvine\",      \"Kansas St\",       1, 0, .23], \n                               ['Rd 64',    \"Iowa\",           \"Cincinnati\",      0, 0, .32], \n                               ['Rd 64',    \"Washington\",     \"Utah St\",         0, 1, .49], \n                               ['Rd 64',    \"Kansas\",         \"Northeastern\",    1, 0, .83], \n                               ['Rd 64',    \"Houston\",        \"Georgia St\",      0, 0, .89], \n                               ['Rd 64',    \"Wofford\",        \"Seton Hall\",      0, 0, .63], \n                               ['Rd 64',    \"Buffalo\",        \"Arizona St\",      0, 0, .66], \n                               ['Rd 64',    \"Murray St\",      \"Marquette\",       0, 0, .36], \n                               ['Rd 64',    \"Baylor\",         \"Syracuse\",        1, 0, .40], \n                               ['Rd 64',    \"Minnesota\",      \"Louisville\",      0, 0, .32], \n                               ['Rd 64',    \"Maryland\",       \"Belmont\",         0, 0, .62], \n                               ['Rd 64',    \"UCF\",            \"VA Commonwealth\", 0, 0, .50], \n                               ['Rd 64',    \"Liberty\",        \"Mississippi St\",  0, 0, .21], \n                               \n                               ['Rd 32',    \"Duke\",           \"UCF\",        0, 0, .91], \n                               ['Rd 32',    \"Virginia Tech\",  \"Liberty\",    0, 0, .86], \n                               ['Rd 32',    \"LSU\",            \"Maryland\",   0, 0, .56], \n                               ['Rd 32',    \"Michigan St\",     \"Minnesota\", 0, 0, .83], \n                               ['Rd 32',    \"Gonzaga\",        \"Baylor\",     0, 0, .91], \n                               ['Rd 32',    \"Florida St\",     \"Murray St\",  0, 0, .70], \n                               ['Rd 32',    \"Texas Tech\",     \"Buffalo\",    1, 0, .67], \n                               ['Rd 32',    \"Michigan\",       \"Florida\",    1, 0, .76], \n                               ['Rd 32',    \"North Carolina\", \"Washington\", 1, 0, .87], \n                               ['Rd 32',    \"Auburn\",         \"Kansas\",     0, 1, .56], \n                               ['Rd 32',    \"Houston\",        \"Ohio St\",    0, 0, .72], \n                               ['Rd 32',    \"Kentucky\",       \"Wofford\",    0, 0, .72], \n                               ['Rd 32',    \"Tennessee\",      \"Iowa\",       0, 0, .80], \n                               ['Rd 32',    \"Purdue\",         \"Villanova\",  0, 0, .53], \n                               ['Rd 32',    \"Oregon\",         \"UC Irvine\",  0, 0, .69], \n                               ['Rd 32',    \"Virginia\",       \"Oklahoma\",   0, 0, .88], \n                               \n                               [\"Sweet 16\", \"Duke\",        \"Virginia Tech\",  0, 0, .75],\n                               [\"Sweet 16\", \"Michigan St\", \"LSU\",            0, 0, .74],\n                               [\"Sweet 16\", \"Gonzaga\",     \"Florida St\",     1, 0, .74],\n                               [\"Sweet 16\", \"Texas Tech\",  \"Michigan\",       1, 0, .51],\n                               [\"Sweet 16\", \"Auburn\",      \"North Carolina\", 0, 0, .38],\n                               [\"Sweet 16\", \"Kentucky\",    \"Houston\",        0, 0, .56],\n                               [\"Sweet 16\", \"Purdue\",      \"Tennessee\",      0, 0, .49],\n                               [\"Sweet 16\", \"Virginia\",    \"Oregon\",         1, 0, .87],\n                               \n                               [\"Elite 8\",  \"Auburn\",      \"Kentucky\", 0, 0, .37],\n                               [\"Elite 8\",  \"Michigan St\", \"Duke\",     0, 0, .33],\n                               [\"Elite 8\",  \"Virginia\",    \"Purdue\",   0, 0, .64],\n                               [\"Elite 8\",  \"Texas Tech\",  \"Gonzaga\",  0, 0, .37],\n                               \n                               [\"Final 4\",  \"Texas Tech\", \"Michigan St\", 0, 0, .46],\n                               [\"Final 4\",  \"Virginia\",   \"Auburn\",      0, 0, .73]]),\n                               columns = ['Round', 'Winner', 'Loser', 'Winhome', 'Losehome', 'FiveThirtyEight'])\n\n# Defining new compare function\ndef compare2(i, j, th= theta, a = alpha, sig = sigma, homei = 0, homej = 0, reps = 1000):\n    win_prob = []\n    \n    # Simulating specified number of games\n    for r in range(1, reps):\n        win_prob.append(\n            np.mean(\n                \n                # Ability difference\n                th[i] - th[j] +\n                \n                # Adjusting for home court\n                a[i]*homei - a[j]*homej +\n                \n                # Team performance variance\n                np.random.normal(0, \n                                 sig[random.randrange(len(sig))], \n                                 len(th.index)\n                ) > 0\n            )\n        )\n    \n    # Averaging game results\n    win_prob = np.mean(win_prob)\n    \n    return(win_prob)\n    \npreds = []\n\nfor g in range(len(games.index)):\n    preds.append(compare2(games[\"Winner\"][g], \n                          games[\"Loser\"][g], \n                          homei = int(games[\"Winhome\"][g]), \n                          homej = int(games[\"Losehome\"][g])))\ngames[\"ours\"] = preds\n\nprint(\"Our Mean Absolute Error is \" + str(round(1 - np.mean(games[\"ours\"]), 5)))\nprint(\"FiveThirtyEight's Mean Absolute Error is \" + str(round(1 - np.mean(pd.to_numeric(games[\"FiveThirtyEight\"])), 5)))\n","e254197c":"pd.set_option('display.max_rows', 500)\ngames[[\"Round\", \"Winner\", \"Loser\", \"FiveThirtyEight\", \"ours\"]]","0b6ba750":"## Predictions\n\nNow time to make the predictions for the tournament. According to our model, Virginia had about a two thirds chance of winning the title. Although, the model also doesn't take in to account Virginia skating by to the finals and Texas Tech's recent good form.","920f8984":"This is our 40th place model (silver winning) in the march madness ml competition (find us under ML Madness).\n\n**Please give an upvote if you liked or leave a comment if you want to see something in this kernal!**","000476fd":"# See All Our Predicted Results\n\nJust in case you wanted to see all our prediction results, I included them below. The \"ours\" column gives our predicted chances of the eventual winner.","0aef2866":"Now, for our final model we added home court advantage. Let's see how the skill distributions change if K-State is playing at home.\n\nWe can see that K-State's home court advantage is greater than the skill difference, giving them the edge in the matchup.","a684c16d":"## How it Works\n\nIn this model, we estimate the skill level of each team based on the point differential of their games in the season, adjusting for home court advantage. In this example, we match KU and K-State up against each other. KU has a higher estimated skill level, so their density plot is further to the right. \n\nTo calculate the win percentage, we make draws based on these distributions, and find the percentage of games each team won over 1000 hypothetical games. You can see the sample game for KU as the blue vertical line and K-State as the purple vertical line.","b15cab5b":"## Prediction Evaluation\n\nNo prediction is worth much without exploring how your prediction matched up against the competition. I've evaluated the model in two ways:\n\n**1.) Competition Placement**\n\nOur prediction is in 40th place of 1558 submissions (not teams), which is about the top 2.5%.\n\n**2.) Against Industry Experts**\n\nTo compare to some of the industry, we put our methods to the test against [FiveThirtyEight's March Madness Predictions](https:\/\/projects.fivethirtyeight.com\/2019-march-madness-predictions\/). Even with their slight edge at being able to adjust their models to take into account performance within the tournament, our model did slightly better.","07df1029":"# March Madness 2019 Predictions\n\n![March Madness Logo](https:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/2\/28\/March_Madness_logo.svg\/1200px-March_Madness_logo.svg.png)\n\n## Data Cleaning\n\nHere I make the training data used for the model.\n\nPart of the beauty of the model is in its simplicity, taking only scoring margin and home and away as features. As such, there is only some filtering (to 2019), name changing, and light feature creation to be done on the training set.","55ffb3d2":"## Model Visualizations\n\nLet's take a look at who the teams to beat are according to the model. Here are boxplots of the top 25 team's skill, sorted by their median values. One criticism of this model is that it doesn't adjust for strength of schedule. Gonzaga, Nevada, and NC State might not be ranked as highly taking SoS into consideration.","183dee81":"## Building the Model\n\nHere the model is trained on the 2019 regular season results:"}}