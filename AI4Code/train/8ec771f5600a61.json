{"cell_type":{"9b0ee5fc":"code","d5b988ab":"code","efd81368":"code","02198532":"code","e590c4d0":"code","96574ed7":"code","e2d36c52":"code","8abf10ae":"code","861e670e":"code","1a616617":"code","493b9480":"code","9f7e057c":"code","bb229d3a":"code","5b9ced33":"code","952d30dc":"code","49bc3636":"code","6733e68a":"code","63af3eb0":"code","b7d4228a":"code","a788f0bb":"code","2955fac2":"code","ebbc6275":"code","988aeaba":"code","fa11aba0":"code","cfa72532":"code","d80f4227":"code","38ce9b13":"code","c8901d45":"code","8dfafc19":"code","d2e9ee03":"code","de01e55c":"code","40279e08":"code","7683b8a0":"code","8d4bd4db":"code","0f20002a":"code","e26a5c27":"code","aef507f2":"code","d25fc1cd":"code","855c4b6b":"code","ef335250":"code","83a48ab0":"code","3530b5a9":"code","3d03a020":"code","89937e61":"code","cce3ee47":"code","69cd326e":"code","f5148e2c":"code","28d5c259":"code","95a01ce8":"code","49e0a3c6":"code","5186d4b5":"code","eab92e7e":"code","5d77f2a0":"code","2c2509e4":"code","2f1ea99e":"code","ac238fb2":"code","53d630cc":"code","502d6a44":"code","1b57b3d5":"code","c5b64689":"code","64e85b61":"code","bfc83e83":"markdown","dccdde1b":"markdown","a4528046":"markdown","3f90004d":"markdown","4796bcee":"markdown","07788c1d":"markdown","adf11e1b":"markdown","2049d27c":"markdown","08282d9d":"markdown","84ed3254":"markdown","18fe131d":"markdown","8ec6f65c":"markdown","19ae9f6c":"markdown","51274b6c":"markdown","025bb9da":"markdown","360f3a13":"markdown","4811ff95":"markdown","66ee6504":"markdown","68d17377":"markdown","759abb93":"markdown","add70249":"markdown","5c37e44c":"markdown","e1397f51":"markdown","66948e18":"markdown","4d561d65":"markdown","48431d31":"markdown","31e77ad8":"markdown","42d55a66":"markdown","194e8739":"markdown","f8f9ed0e":"markdown","9f073b62":"markdown","03c15792":"markdown","ecee68b4":"markdown","0c3b28fe":"markdown","3a52a1be":"markdown","c0221209":"markdown"},"source":{"9b0ee5fc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nimport re\nimport seaborn as sns\nwarnings.simplefilter(action='ignore')\n\n\n","d5b988ab":"data_train=pd.read_csv(\"..\/input\/titanic\/train.csv\")  ## importing files train and test\ndata_test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndata_train.info()","efd81368":"data_train.head()","02198532":"sns.countplot(x = 'Survived', data=data_train )","e590c4d0":"x=data_train.groupby(['Sex','Survived'])['Survived'].count()\nsns.countplot(x='Sex',hue='Survived',data=data_train)\n\nprint(x)","96574ed7":"print(\"percentage of female of pclass1 is =\",data_train[(data_train.Pclass == 1) & (data_train.Sex=='female')]['Survived'].mean()*100)\nprint(\"percentage of female of pclass2 is =\",data_train[(data_train.Pclass == 2) & (data_train.Sex=='female')]['Survived'].mean()*100) \nprint(\"percentage of female of pclass3 is =\",data_train[(data_train.Pclass == 3) & (data_train.Sex=='female')]['Survived'].mean()*100)      ","e2d36c52":"print(\"percentage of male of pclass1 is =\",data_train[(data_train.Pclass == 1) & (data_train.Sex=='male')]['Survived'].mean()*100)\nprint(\"percentage of male of pclass2 is =\",data_train[(data_train.Pclass == 2) & (data_train.Sex=='male')]['Survived'].mean()*100)\nprint(\"percentage of male of pclass3 is =\",data_train[(data_train.Pclass == 1) & (data_train.Sex=='male')]['Survived'].mean()*100)","8abf10ae":"plt.figure(figsize=[8,8])\nsns.violinplot(x= \"Sex\", y = 'Age', hue = 'Survived', data =data_train)","861e670e":"print(\"percentage of male survived less than 15 of age\",data_train[(data_train.Age<=15) & (data_train.Sex =='male')]['Survived'].mean()*100)\n","1a616617":"print(\"percentage of female survived less than 15 of age\",data_train[(data_train.Age<=15) & (data_train.Sex =='female')]['Survived'].mean()*100)","493b9480":"print(data_train[(data_train.Age < 15) & (data_train.Sex == 'male')].groupby(['Pclass'])['Survived'].mean())\n\ndata_train[(data_train.Age < 15) & (data_train.Sex == 'male')].groupby(['Pclass','Survived'])['Survived'].count()","9f7e057c":"sns.kdeplot(data_train[data_train.Sex == 'male']['Age'], shade = True, color = 'r')\nsns.kdeplot(data_train[data_train.Sex == 'female']['Age'], shade = True, color = 'g')","bb229d3a":"# now making changes in both data together\n\nfor dataset in [data_train,data_test]:\n    \n    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1","5b9ced33":"data_train[['FamilySize','Survived']].groupby('FamilySize')['Survived'].mean()","952d30dc":"plt.figure(figsize = [10,8])\nsns.countplot(x = 'FamilySize', hue = 'Survived', data = data_train)","49bc3636":"data_train[(data_train.Age.isnull()) & (data_train.FamilySize == 1)].groupby(['Pclass', 'Sex'])['Survived'].mean()","6733e68a":"for dataset in [data_train,data_test]:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    \npd.crosstab(data_train['Title'], data_train['Sex'])    ","63af3eb0":"for dataset in [data_train,data_test]:\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Countess', 'Jonkheer', 'Lady', 'Major', 'Sir','Dona','Don','Dr'], 'High' )\n    dataset['Title']=dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title']=dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title']=dataset['Title'].replace('Mme', 'Mrs')\n","b7d4228a":"print(pd.crosstab(data_train['Title'], data_train['Sex']))\nprint(\"*******************************************************\")\nprint(pd.crosstab(data_test['Title'], data_test['Sex']))\n","a788f0bb":"data_test[data_test['Title'] == 'Miss'].describe()","2955fac2":"#we have to create a new Title for Female Child which will be a subset of Title Miss\nfor dataset in [data_train,data_test]:\n\n    dataset.loc[(data_train.Title == 'Miss') & (dataset.Parch != 0) & (dataset.FamilySize > 1), 'Title'] = 'FemaleChild'\n    dataset[(dataset.Title == 'FemaleChild') & (dataset.Age.isnull())]","ebbc6275":"data_train.groupby(['Pclass', 'Sex', 'Title'])['Age'].mean()","988aeaba":"x = data_train.groupby(['Pclass', 'Sex', 'Title'])['Age'].mean().reset_index()\ntype(x)","fa11aba0":"def imputeage(row):\n    return x[(x.Pclass == row.Pclass) & (x.Sex == row.Sex) & (x.Title == row.Title)]['Age'].values[0]","cfa72532":"data_train['Age'], data_test['Age'] = [dataset.apply(lambda x: imputeage(x) if np.isnan(x['Age']) else x['Age'], axis = 1)\\\n                          for dataset in [data_train, data_test]]\n","d80f4227":"combined = data_train.append(data_test)\ncombined.shape\n\ndata_train['PersonPerTicket'] = data_train['Ticket'].map(combined['Ticket'].value_counts())\ndata_train['PricePerTicket'] = data_train['Fare']\/data_train['PersonPerTicket']\n\n\n","38ce9b13":"data_train.isnull().sum()","c8901d45":"xt=data_train['Age'].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ndata_train[\"Age\"].plot(kind='density', color='teal')\n\n\nplt.xlim(-10,85)\nplt.show()\n\n###as we see that the graph is left skewed so we take median\n\n# BUT THERE IS ONE PROBLEM WITH THIS IS THAT GIRL CHILD LOST HER CHANCE OF SURVIVAL","8dfafc19":"print(\"Percent of missing Embarked records is %.2f%%'\" %((data_train['Embarked'].isnull().sum()\/data_train.shape[0])*100))\n\nprint(data_train['Embarked'].value_counts())\n\n\n## so that the value of s is max so the nan is replace by s","d2e9ee03":"data_train.info()","de01e55c":"  # create a copy of the original data\ntrain_df=data_train.copy()           \ntrain_df['Fare']=train_df['Fare'].astype('float')\ntrain_df['Age_Group'] = pd.cut(train_df.Age,bins=[0,2,17,65,99],labels=['Toddler\/Baby','Child','Adult','Elderly'])\ntrain_df['Embarked'].fillna(train_df['Embarked'].value_counts().idxmax(),inplace=True)\n\ntrain_df.Cabin=train_df.Cabin.astype('str').apply(lambda x : re.findall(\"[a-zA-Z]\",x)[0] if x !='nan' else 'T')\n\n## combining our data \ntrain_df['travle_alone']=np.where(train_df['SibSp']+train_df['Parch']>0,0,1) ## for false value 0 and for true value 1\ntrain_df.drop('SibSp', axis=1, inplace=True)\ntrain_df.drop('Parch', axis=1, inplace=True)\n\n\n\n## i use to dummy my data ...... to make it understandable value\n\ntrain_df=pd.get_dummies(train_df, columns=[\"Pclass\",\"Embarked\",\"Sex\",\"Age_Group\",\"Cabin\",\"Title\"])\n\ntrain_df.drop('Name', axis=1, inplace=True)\ntrain_df.drop('Ticket', axis=1, inplace=True)\ntrain_df.drop('PassengerId', axis=1, inplace=True)\n\n\ntrain_df","40279e08":"train_df.isnull().sum()\ndata_t=train_df.copy()\n\ny=data_t['Survived']\n\ndata_t.drop('Survived',axis=1,inplace=True)\nx=data_t\nx.shape","7683b8a0":"x.info()","8d4bd4db":"x=x[['Title_Miss','Sex_male','Title_Rev','Pclass_2','Cabin_F','travle_alone','Cabin_E','Embarked_Q','Pclass_3','Cabin_G','Age_Group_Elderly','FamilySize','Cabin_A','Title_Master','Embarked_S','Title_High']]","0f20002a":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(np.array(x),np.array(y),train_size=0.7,random_state=0)\n","e26a5c27":"y_test.shape,x_test.shape","aef507f2":"x_train.shape,y_test.shape","d25fc1cd":"\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","855c4b6b":"\nfrom sklearn.linear_model import LogisticRegression\nclf=LogisticRegression()\nclf.fit(x_train,y_train)\n\nclf.score(x_train,y_train),clf.score(x_test,y_test)\n","ef335250":"coeff_df = pd.DataFrame(x.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(clf.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","83a48ab0":"from sklearn.feature_selection import SelectFromModel,RFE\nsmf = SelectFromModel(clf,threshold = -np.inf,max_features = 15)\nsmf.fit(x_train,y_train)\nfeature_idx = smf.get_support()\nfeature_name = x.columns[feature_idx]\nfeature_name","3530b5a9":"predictors = x_train\nselector = RFE(clf,n_features_to_select = 1)\nselector = selector.fit(predictors,y_train)","3d03a020":"order = selector.ranking_\norder","89937e61":"feature_ranks = []\nfor i in order:\n    feature_ranks.append(f\"{i}. {x.columns[i-1]}\")\nfeature_ranks","cce3ee47":"\nfrom sklearn.svm import LinearSVC\nregr = LinearSVC(penalty = 'l1',dual = False,loss = 'squared_hinge')\nregr.fit(x_train, y_train)\nprint(regr.score(x_train, y_train))\nprint(regr.score(x_test, y_test))\n","69cd326e":"\nfrom sklearn.ensemble import RandomForestClassifier\nrfr = RandomForestClassifier(max_depth=11,random_state=0)\nrfr.fit(x_train, y_train)\ny_pred=rfr.predict(x_test)\nprint(rfr.score(x_test, y_test))\nprint(rfr.score(x_train, y_train))","f5148e2c":"import scipy as sci\ntest_data=data_test.copy()    \ntest_data['Fare']=test_data['Fare'].astype('float')\ntest_data.Fare.fillna(sci.median(test_data.Fare.dropna()),inplace = True) \ntest_data['Age_Group'] = pd.cut(test_data.Age,bins=[0,2,17,65,99],labels=['Toddler\/Baby','Child','Adult','Elderly'])\ntest_data['Embarked'].fillna(test_data['Embarked'].value_counts().idxmax(),inplace=True)\ntest_data.Cabin=test_data.Cabin.astype('str').apply(lambda x : re.findall(\"[a-zA-Z]\",x)[0] if x !='nan' else 'T')\n\ntest_data['PersonPerTicket'] = test_data['Ticket'].map(combined['Ticket'].value_counts())\ntest_data['PricePerTicket'] = test_data['Fare']\/test_data['PersonPerTicket']\n\n## combining our data \ntest_data['travle_alone']=np.where(test_data['SibSp']+test_data['Parch']>0,0,1) ## for false value 0 and for true value 1\ntest_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)\n\n\n## i use to dummy my data ...... to make it understandable value\n\ntest_data=pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\",\"Age_Group\",\"Cabin\",\"Title\"])\n\ntest_data.drop('Name', axis=1, inplace=True)\ntest_data.drop('Ticket',axis=1, inplace=True)\ntest_data.drop('PassengerId',axis=1, inplace=True)\n\ntest_data.head()","28d5c259":"test_data.isnull().sum()\ndata_te=test_data.copy()\nx.shape\ndata_te.shape\ndata_te=data_te[['Title_Miss','Sex_male','Title_Rev','Pclass_2','Cabin_F','travle_alone','Cabin_E','Embarked_Q','Pclass_3','Cabin_G','Age_Group_Elderly','FamilySize','Cabin_A','Title_Master','Embarked_S','Title_High']]","95a01ce8":"\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit_transform(x)\nx_test1=sc.transform(data_te)\n","49e0a3c6":"\nclf.fit(x,y)\nclf.score(x,y)","5186d4b5":"regr.fit(x,y)","eab92e7e":"\n\ny_predict=clf.predict(x_test1)","5d77f2a0":"regr.score(x,y)","2c2509e4":"y_predict","2f1ea99e":"y_predict_s=regr.predict(x_test1)\ny_predict_s","ac238fb2":"\nfrom sklearn.ensemble import RandomForestClassifier\nrfr = RandomForestClassifier(random_state=0)\nrfr.fit(x, y)\ny_pred=rfr.predict(x_test1)\nprint(rfr.score(x, y))\n","53d630cc":"y_pred","502d6a44":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n\n\nmodel = Sequential()\n\nmodel.add(Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n\n# The Output Layer :\nmodel.add(Dense(1,activation='sigmoid',kernel_regularizer='l1'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.fit(x_train,y_train,batch_size = 16,epochs=200,validation_data=(x_test,y_test),use_multiprocessing=True,shuffle = False)","1b57b3d5":"x=model.predict(x_test1)\nfor i,j in enumerate(x):\n    if j < 0.5 :\n        x[i] = 0\n    else :\n        x[i] = 1 \npredict_nn=x.flatten().astype('int')","c5b64689":"x_PassengerId=np.array(data_test['PassengerId'])\n","64e85b61":"dict = {'PassengerId': x_PassengerId, 'Survived': predict_nn }  \n     \ndf = pd.DataFrame(dict) \n  \n# saving the dataframe \ndf.to_csv('servived_r_15.csv',index=False) ","bfc83e83":"# BY THIS METHOD WE CAN CHANGE THE INPUT OF TRAIN AND TEST FOR IMPROVING OUR RESULTS","dccdde1b":"# EDA","a4528046":"# using linear regression","3f90004d":"# IMPORTING REQUIRED FILES","4796bcee":"### From the above plot we can conclude that majority of the value lies within first standered devisation.","07788c1d":"# Majority of people not survived","adf11e1b":"## creating obj for the logestic regression implementation","2049d27c":"## here we are checkin how many male and female are survived","08282d9d":"# From randomforest","84ed3254":"## ALL OTHER CLASSIFIRES OVERFIT RESULTS ACCEPT SO WE ARE USING NEURAL NETWORK FOR OUR FINAL RESULTS","18fe131d":"# OVERVIEWING OF DATA","8ec6f65c":"Above output gives us some insights that if you are a child then you've really had better chances of survival than aged people so now while impute Age we have to care somewhat about Age as well other than Pclass and sex. \nNow the points comes how to can we get to know whether the person is child or not if Age is NULL. we've seen that in name column we've Titles like Master, Miss and etc... so we will take that title and make a column to know whether a person is child or not ","19ae9f6c":"# Using support vactor regressor","51274b6c":"## prediction of neural network","025bb9da":"# from randomforest","360f3a13":"# MODELING ON TRAIN DATA","4811ff95":"# Analysing the missing value","66ee6504":"# Correct allAdjustments to Data (Train & Test","68d17377":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load","759abb93":"# feature scaling","add70249":"# using neural network","5c37e44c":"So till now we've imputed missing age of all the datapoints in the train and test dataset.","e1397f51":"### White Dot in the middle in the graph shows the median.\n ## From the above plot we can conclude many things:-\n ##   1. As we can see Survived plot of Male is much much wider from age 0 to 15 or so. From this we can conclude childrens were given preferences.\n   ## 2. Survived = 0 plot for Males is much wider than Survived = 1 from age 60-80 or so.\n## If you wanna know more about a Violin plot \"","66948e18":"### here we see that the the change of survival min size is max then alone travler and famaly size more than 7","4d561d65":"## AFTER THIS WE USE DIFFRENT CLASSIFIRESS TO TRAIN OURMATCHINE","48431d31":"# HERE WE ARE USING THE DIFFRENT METHOD TO CHECK WHICH FEATURES ARE USEFULL FOR US.","31e77ad8":"# Feature scaling: FOR ORIGINAL TEST DATA","42d55a66":"### so from above output it is further clear than min age for a female having Title 'Miss' can be 0.75 and max age can be 64","194e8739":"# CONCLUSION :","f8f9ed0e":"# Handling the missing values Embarked","9f073b62":"###  This output clears more about the data of male aged less than 16. As we can see all chilren of Pclass 1 and Pclass 2 survived but not the same for children of Pclass 3.","03c15792":"### We can clearly observe from graph that females are given priority while rescuing as majority of the females survived.\n### whereas majority of Males died.\n### Still we are not clear about the people who Survived as of what age group people survived or what Class of People Survived\n\n","ecee68b4":"# Traning and Testing of data by logistic regression","0c3b28fe":" # Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","3a52a1be":"# same implementation for test data","c0221209":"***********************************************************************************************************************"}}