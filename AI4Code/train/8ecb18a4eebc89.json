{"cell_type":{"48ae49cc":"code","89d747b3":"code","22f33058":"code","18b2c2e9":"code","83131e72":"code","82b7445e":"markdown","46067b4a":"markdown","f4ebbbe1":"markdown","d9caa26d":"markdown"},"source":{"48ae49cc":"import numpy as np\nfrom numpy import *\nfrom PIL import Image # Pillow : \uc774\ubbf8\uc9c0 \ucc98\ub9ac \ud328\ud0a4\uc9c0\nimport matplotlib.pyplot as plt # matplotlib : \uadf8\ub798\ud504 \ud328\ud0a4\uc9c0\nimport matplotlib.patches as mpatches\nimport torch # torch, torchvision : \ub525\ub7ec\ub2dd \ud504\ub808\uc784\uc6cc\ud06c\nfrom torchvision import transforms, models\nimport cv2 # Open CV : \uc774\ubbf8\uc9c0 \ucc98\ub9ac \ud328\ud0a4\uc9c0","89d747b3":"model = models.segmentation.deeplabv3_resnet101(pretrained = True).eval()","22f33058":"labels = ['background', 'aeroplane', 'bicycle', 'bird','boat', 'bottle', 'bus',' car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n\ncmap = plt.cm.get_cmap('tab20c')\ncolors = (cmap(np.arange(cmap.N))*255).astype(np.int)[:, :3].tolist()\nnp.random.seed(2020)\nnp.random.shuffle(colors)\ncolors.insert(0, [0, 0, 0]) # background color must be black\ncolors = np.array(colors, dtype = np.uint8)\n\npalette_map = np.empty((10, 0, 3), dtype = np.uint8)\nlegend = []\n\nfor i in range(21):\n    legend.append(mpatches.Patch(color=np.array(colors[i])\/255., label='%d: %s'%(i, labels[i])))\n    c = np.full((10, 10, 3), colors[i], dtype = np.uint8)\n    palette_map = np.concatenate([palette_map, c], axis=1)\n\nplt.figure(figsize=(20, 2))\nplt.legend(handles=legend)\nplt.imshow(palette_map)\n    ","18b2c2e9":"def segment(net, img):\n    preprocess = transforms.Compose([ #torchvision.transform() : \uc774\ubbf8\uc9c0 \uc804\ucc98\ub9ac \ubaa8\ub4c8\n        transforms.ToTensor(), # transforms.ToTensor() : \uc774\ubbf8\uc9c0\ub97c \ud150\uc11c\ub85c \ubcc0\ud658\n        transforms.Normalize(  # transforms.Normalize() : \uc774\ubbf8\uc9c0 \uc815\uaddc\ud654\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]),])\n    \n    input_tensor = preprocess(img)\n    input_batch = input_tensor.unsqueeze(0) # tenasor.unsqueeze() : \ud150\uc11c\uc5d0 \ucc28\uc6d0(\uc0c8\ub85c\uc6b4 \ucd95)\uc744 \ucd94\uac00\ud55c\ub2e4, squeeze\uc758 \ubc18\ub300\n    \n    if torch.cuda.is_available():\n        input_batch = input_batch.to('cuda') # model(or batch).to('cuda') : \ubaa8\ub378\uc774\ub098 \ubc30\uce58\ub97c CPU(RAM)\ub85c \ubd80\ud130 cuda \ub514\ubc14\uc774\uc2a4 \uba54\ubaa8\ub9ac\uc5d0 \uc774\ub3d9\ud558\uc5ec \ucc98\ub9ac\ud55c\ub2e4\n        model.to('cuda')\n    \n    output = model(input_batch)['out'][0] # (21, height, width)\n    \n    output_predictions = output.argmax(0).byte().cpu().numpy() # (height, width) \n    # argmax(0) : \uac01 \ud53d\uc140\uc758 \ucc44\ub110\ubc29\ud5a5\uc73c\ub85c \ucd5c\uc18c\uac12\uc758 \ucc44\ub110 \uc778\ub371\uc2a4\ub97c \ubc18\ud658\n    # byte() : uint8 \ud0c0\uc785\uc73c\ub85c \ubcc0\ud658 \n    # cpu() : cuda -> cpu\ub85c \uc774\ub3d9\n    # numpy() : tensor -> numpy ndarray\ub85c \ubcc0\ud658\n    \n    r = Image.fromarray(output_predictions).resize((img.shape[1], img.shape[0])) \n    # Image.fromarray() : numpy ndarray\ub97c Pillow Image \ud0c0\uc785\uc73c\ub85c \ubc18\ud658\n    # Image.resize() : \uc774\ubbf8\uc9c0 \ud06c\uae30\ub97c \ubcc0\ud615\n    r.putpalette(colors)\n    \n    return r, output_predictions","83131e72":"img = np.array(Image.open('..\/input\/imgs-mcp\/02.jpg'))\n\nfg_h, fg_w, _ = img.shape\n\nsegment_map, pred = segment(model, img)\n\nfig, axes = plt.subplots(1, 2, figsize = (20, 10))\naxes[0].imshow(img)\naxes[1].imshow(segment_map)","82b7445e":"# Segment Fuction","46067b4a":"# Result","f4ebbbe1":"# Download and Load Model\n* https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html#fully-convolutional-networks\n* https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html#deeplabv3\n* FCN ResNet101\uc758 mean IoU : 63.7\n* DeepLabV3 ResNet101\uc758 mean IoU : 67.4\n* DeepLabV3 ResNet101 \ubaa8\ub378 \uc0ac\uc6a9","d9caa26d":"# Create Color Palette"}}