{"cell_type":{"fec341e6":"code","fef68965":"code","c4385fbc":"code","37831a23":"code","e3573756":"code","85e9ff66":"code","61572488":"code","bffb86a5":"code","e48a2d59":"code","0ebe368a":"code","04411ce4":"code","022c4385":"code","2f2b0c63":"code","d4282ca4":"code","34f3a375":"code","de7ea6a2":"code","54a633e6":"code","e1da1d19":"code","cba1166f":"code","34f95357":"code","e604ac8b":"code","0d298173":"code","f4a11781":"code","6efcaf11":"code","5c5f6d80":"code","5033a963":"code","f17421f9":"code","f861b7ce":"code","edbaa473":"code","d8168a58":"code","18474de6":"code","966012ae":"code","4c0fa93b":"code","8b824e1e":"code","7e50bbcc":"code","25efd3d5":"code","4d8f050b":"code","014dbf0f":"code","b6f858fa":"code","5afa2319":"code","60779f74":"code","f891935c":"code","a65e2a38":"code","309d0b0c":"code","938521c2":"code","127affd4":"code","51c37bbb":"code","bcefec7b":"code","543ac466":"code","2dfe992f":"code","a3588fef":"code","7d3d0647":"code","fdc9a2a7":"code","4ee8fa18":"code","0afed1ad":"code","87cc8f33":"code","a29540f5":"code","9bb9cd0a":"code","114de1ee":"code","eb7eca37":"code","92074ce6":"code","3b0c6124":"code","fe0673ab":"code","e283caad":"code","b484224e":"code","b0f8fc3e":"markdown","5b45c20a":"markdown","a9b23e38":"markdown","eea07bb1":"markdown","71668fe5":"markdown","81174db1":"markdown","d874a9d9":"markdown","3a059f99":"markdown","254a0f98":"markdown","3f14c694":"markdown","983bc149":"markdown","e450e5d8":"markdown","bba09bd3":"markdown","0c5e5e83":"markdown","2d6405cd":"markdown","345ec0b1":"markdown","2163ebb4":"markdown","1df3467d":"markdown","1306876e":"markdown","fec32724":"markdown","8db945e4":"markdown","ae28a442":"markdown","773adcb4":"markdown","ca385222":"markdown","90e5dd91":"markdown","e50a0fbc":"markdown","6828310b":"markdown","a966e278":"markdown","23219572":"markdown","7e123d0e":"markdown","286ab2bf":"markdown","d085f064":"markdown","358918f1":"markdown","beeb7973":"markdown","96e0479c":"markdown","b4fd9112":"markdown","10563b71":"markdown","df6c6949":"markdown","cec69ad5":"markdown","19401893":"markdown","177dda7e":"markdown","be26e1d4":"markdown"},"source":{"fec341e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np                     # For mathematical calculations \nimport seaborn as sns                  # For data visualization \nimport matplotlib.pyplot as plt ","fef68965":"t = pd.read_csv(\"..\/input\/customerattritionprediction\/train.csv\")\ntt = pd.read_csv(\"..\/input\/customerattritionprediction\/test.csv\")","c4385fbc":"train_orignal=t\ntest_orignal= tt","37831a23":"#test_orignal","e3573756":"t = t.dropna(axis=0,how='any')","85e9ff66":"train_orignal['sex'].value_counts()","61572488":"x=pd.crosstab(train_orignal['sex'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","bffb86a5":"train_orignal['Aged'].value_counts()","e48a2d59":"x=pd.crosstab(train_orignal['Aged'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","0ebe368a":"train_orignal['Married'].value_counts()","04411ce4":"x=pd.crosstab(train_orignal['Married'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","022c4385":"train_orignal['TotalDependents'].value_counts()","2f2b0c63":"x=pd.crosstab(train_orignal['TotalDependents'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","d4282ca4":"train_orignal['MobileService'].value_counts()","34f3a375":"x=pd.crosstab(train_orignal['MobileService'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","de7ea6a2":"train_orignal['4GService'].value_counts()","54a633e6":"x=pd.crosstab(train_orignal['4GService'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","e1da1d19":"train_orignal['CyberProtection'].value_counts()","cba1166f":"x=pd.crosstab(train_orignal['CyberProtection'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","34f95357":"train_orignal['HardwareSupport'].value_counts()","e604ac8b":"x=pd.crosstab(train_orignal['HardwareSupport'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","0d298173":"train_orignal['TechnicalAssistance'].value_counts()","f4a11781":"x=pd.crosstab(train_orignal['TechnicalAssistance'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","6efcaf11":"train_orignal['FilmSubscription'].value_counts()","5c5f6d80":"x=pd.crosstab(train_orignal['FilmSubscription'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","5033a963":"train_orignal['SettlementProcess'].value_counts()","f17421f9":"x=pd.crosstab(train_orignal['SettlementProcess'],train_orignal['CustomerAttrition']) \n\nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize=(4,6)) \nplt.show() ","f861b7ce":"#t['SettlementProcess'].replace('Check', 'Card',inplace=True) \nt['SettlementProcess'].replace('Bank', 'Card',inplace=True) \n\n#tt['SettlementProcess'].replace('Check', 'Card',inplace=True)\ntt['SettlementProcess'].replace('Bank', 'Card',inplace=True)","edbaa473":"t=pd.get_dummies(t,columns=[ 'SettlementProcess'])\ntt=pd.get_dummies(tt,columns=['SettlementProcess'])","d8168a58":"from sklearn.preprocessing import OrdinalEncoder\nencoder = OrdinalEncoder(categories=[['Male','Female']])\nt.sex = encoder.fit_transform(t.sex.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Male','Female']])\ntt.sex = encoder.fit_transform(tt.sex.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['No','Yes']])\nt.Aged = encoder.fit_transform(t.Aged.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['No','Yes']])\ntt.Aged = encoder.fit_transform(tt.Aged.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['Yes','No']])\nt.Married = encoder.fit_transform(t.Married.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Yes','No']])\ntt.Married = encoder.fit_transform(tt.Married.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['Yes','No']])\nt.TotalDependents = encoder.fit_transform(t.TotalDependents.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Yes','No']])\ntt.TotalDependents = encoder.fit_transform(tt.TotalDependents.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['Yes','No']])\nt.MobileService = encoder.fit_transform(t.MobileService.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Yes','No']])\ntt.MobileService = encoder.fit_transform(tt.MobileService.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['Yes','No']])\nt.CyberProtection = encoder.fit_transform(t.CyberProtection.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Yes','No']])\ntt.CyberProtection = encoder.fit_transform(tt.CyberProtection.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['No','Yes']])\nt.HardwareSupport = encoder.fit_transform(t.HardwareSupport.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['No','Yes']])\ntt.HardwareSupport = encoder.fit_transform(tt.HardwareSupport.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['Yes','No']])\nt.TechnicalAssistance = encoder.fit_transform(t.TechnicalAssistance.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['Yes','No']])\ntt.TechnicalAssistance = encoder.fit_transform(tt.TechnicalAssistance.values.reshape(-1,1))\n\nencoder = OrdinalEncoder(categories=[['No','Yes']])\nt.FilmSubscription = encoder.fit_transform(t.FilmSubscription.values.reshape(-1,1))\nencoder = OrdinalEncoder(categories=[['No','Yes']])\ntt.FilmSubscription = encoder.fit_transform(tt.FilmSubscription.values.reshape(-1,1))","18474de6":"encoder = OrdinalEncoder(categories=[['No','Yes']])\nt.CustomerAttrition = encoder.fit_transform(t.CustomerAttrition.values.reshape(-1,1))","966012ae":"abs(t.corr()['CustomerAttrition'])","4c0fa93b":"# v1 = t.ServiceSpan * t.ServiceSpan\n# t1 = tt.ServiceSpan * tt.ServiceSpan","8b824e1e":"# t['v1']=v1\n# tt['t1']=t1","7e50bbcc":"y = t['CustomerAttrition']\nX = t.drop('CustomerAttrition', axis=1)","25efd3d5":"X = X.drop(['MobileService','4GService','FilmSubscription'], axis=1)\ntt = tt.drop(['MobileService','4GService','FilmSubscription'],axis=1)","4d8f050b":"import seaborn as sns\nplt.figure(figsize=(12,10))\ncor = X.corr()\nsns.heatmap(cor,annot = True, cmap = plt.cm.CMRmap_r)\nplt.show()","014dbf0f":"X.var()","b6f858fa":"X.set_index('ID',inplace=True)\ntt.set_index('ID',inplace=True)","5afa2319":"import seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\nfrom imblearn.over_sampling import *\nfrom imblearn.under_sampling import *","60779f74":"#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","f891935c":"train_orignal['CustomerAttrition'].value_counts()","a65e2a38":"sm = RandomOverSampler(random_state=200)\nX_res, y_res = sm.fit_resample(X, y)\n","309d0b0c":"# sm = RandomOverSampler(random_state=200)\n# X_res, y_res = sm.fit_resample(X_train, y_train)","938521c2":"# import numpy as np\n# from sklearn.model_selection import RandomizedSearchCV\n# # Number of trees in random forest\n# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# # Number of features to consider at every split\n# max_features = ['auto', 'sqrt','log2']\n# # Maximum number of levels in tree\n# max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n# # Minimum number of samples required to split a node\n# min_samples_split = [2, 5, 10,14]\n# # Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2, 4,6,8]\n# # Create the random grid\n# random_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf,\n#               'criterion':['entropy','gini']}\n# print(random_grid)","127affd4":"# rf=RandomForestClassifier()\n# rf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,\n#                                random_state=100,n_jobs=-1)\n# ### fit the randomized model\n# rf_randomcv.fit(X_res,y_res)","51c37bbb":"# rf_randomcv.best_params_","bcefec7b":"# rf_randomcv","543ac466":"# best_random_grid=rf_randomcv.best_estimator_","2dfe992f":"# from sklearn.metrics import accuracy_score\n# y_pred=best_random_grid.predict(X_test)\n# print(confusion_matrix(y_test,y_pred))\n# print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n# print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))","a3588fef":"# from sklearn.model_selection import GridSearchCV\n\n# param_grid = {\n#     'criterion': [rf_randomcv.best_params_['criterion']],\n#     'max_depth': [rf_randomcv.best_params_['max_depth']],\n#     'max_features': [rf_randomcv.best_params_['max_features']],\n#     'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'], \n#                          rf_randomcv.best_params_['min_samples_leaf']+2, \n#                          rf_randomcv.best_params_['min_samples_leaf'] + 4],\n#     'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n#                           rf_randomcv.best_params_['min_samples_split'] - 1,\n#                           rf_randomcv.best_params_['min_samples_split'], \n#                           rf_randomcv.best_params_['min_samples_split'] +1,\n#                           rf_randomcv.best_params_['min_samples_split'] + 2],\n#     'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] - 100, \n#                      rf_randomcv.best_params_['n_estimators'], \n#                      rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200]\n# }\n\n# print(param_grid)","7d3d0647":"\n# #### Fit the grid_search to the data\n# rf=RandomForestClassifier()\n# grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=10,n_jobs=-1,verbose=2)\n# grid_search.fit(X_res,y_res)","fdc9a2a7":"# grid_search.best_estimator_","4ee8fa18":"# best_grid=grid_search.best_estimator_","0afed1ad":"# best_grid","87cc8f33":"# y_pred=best_grid.predict(X_test)\n# print(confusion_matrix(y_test,y_pred))\n# print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n# print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))","a29540f5":"# tt['GrandPayment'].fillna(value=tt['GrandPayment'].mean(), inplace=True)\n# tt","9bb9cd0a":"# prediction = best_grid.predict(tt)\n# prediction","114de1ee":"# pred =[]\n# for i in prediction:\n#     if i == 0:\n#         pred.append('No')\n#     else:\n#         pred.append('Yes')","eb7eca37":"# ttt = pd.read_csv(\"..\/input\/customerattritionprediction\/test.csv\")","92074ce6":"# ttt.set_index('ID',inplace=True)","3b0c6124":"# ttt.index","fe0673ab":"# dict = {'ID':ttt.index,'CustomerAttrition':pred}\n# a=pd.DataFrame(dict)","e283caad":"# a","b484224e":"# a.to_csv('mmevengrid.csv',index=False)","b0f8fc3e":"## please uncomment for running, i have commented as it takes time to run all","5b45c20a":"***dropping all the rows containg NaN value, from train data***","a9b23e38":"## run below cell only if splitted train set for validating","eea07bb1":"# Hardware Support","71668fe5":"# Aged","81174db1":"# making dummies for Settelement Process","d874a9d9":"# Predicting on test dataset i.e. tt","3a059f99":"***4G Service can be removed seeing above graph***","254a0f98":"# run train_test_split, if you are validating using train set","3f14c694":"## if we want to validate our model using 30% of train data, then we need to oversample only train data i.e. after splitting we get X_train and y_train, we will oversample this and test or validate on rest 30% i.e. X_test and y_test","983bc149":"# checking howmuch input features are varying","e450e5d8":"***we can see that Film Subscription and Mobile service are irrelavent, while SettlementProcess_Bank and SettlementProcess_Card can be combined as one single feature***","bba09bd3":"# encoding YES and NO ","0c5e5e83":"## run below cell only if splitted train set for validating","2d6405cd":"## seeing above corelatin matrix we can even remove GrandPayment column or keep GrandPayment and remove REST of the columns which relates >0.6 with GrandPayment\n\n## in this not removed","345ec0b1":"## GrandPayment column in test dataset also contains NaN values, so filling it with mean GrandPayment","2163ebb4":"****keeping a unaltered copy as orignal ****","1df3467d":"> **we can see that dataset is highly imbalanced****","1306876e":"**Here we can see that Bank, Card are  apprioximately same in quantity and nearly same numbers of YES and NO. So after seeing corelation with target we will decide of combining two or more features.**","fec32724":"# Married","8db945e4":"## here we are oversampling data (X,y) as we are going to train our model for complete train data and will predict on test data","ae28a442":"# Visualizing relation using heatmap","773adcb4":"# Film Subscription","ca385222":"# 4G Service","90e5dd91":"# Setting Customer Attrition column as target and rest as input features","e50a0fbc":"# Total Dependents","6828310b":"## below cell will give result with RandomSearch","a966e278":"**combining Bank to Card**","23219572":"# checking dataset is Balanced or Imbalanced","7e123d0e":"# Settlement Process","286ab2bf":"## using Random Search parameters in Grid Search\n## run this after running RandomSearch cells except just above one","d085f064":"# Cyber Protection","358918f1":"# Technical Assistance","beeb7973":"# Using Random Serch CV and Grid Serch CV for hyperparameter optimization in RandomForestClassifier","96e0479c":"# Oversampling Data as not evenly distributed","b4fd9112":"**t : train data\ntt : test data**","10563b71":"# Fnding out corelation of features with Customer Attrition","df6c6949":"# Mobile Service","cec69ad5":"# sex","19401893":"# Dropping irrelavent features","177dda7e":"# making model","be26e1d4":"> As we see that Service span is highly corelated with target, so its square can be considered."}}