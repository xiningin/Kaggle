{"cell_type":{"ca55b95d":"code","b20cfd38":"code","39595088":"code","6002fd73":"code","514292e1":"code","373138f3":"code","ccff0813":"code","9ceef302":"code","9aa4a4b5":"code","fa81719b":"code","303a6a0e":"code","d7855c08":"code","6db8927d":"code","2b7ed743":"code","648bf3d2":"code","dc26fe25":"code","78cd9b45":"code","4f15cf8d":"code","543bfb1c":"code","a5860401":"code","5605f646":"code","17da67df":"code","1d8fe511":"code","7c9d231c":"code","de8d4cc4":"code","32afe118":"markdown","c1951842":"markdown","ff0cc94c":"markdown","de0d19fc":"markdown","d9c8ec3d":"markdown","ccfb7dab":"markdown","ac10ed7a":"markdown","324d26e8":"markdown"},"source":{"ca55b95d":"import os\nGPU_id = 0\nos.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)","b20cfd38":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom fastai.train import Learner\nfrom fastai.train import DataBunch\nfrom fastai.metrics import accuracy as fastai_accuracy\nfrom fastai.callbacks import SaveModelCallback\nfrom fastai.basic_data import DatasetType\n\nimport pandas as pd\nimport time\nimport math\nfrom tqdm import tqdm\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torch import nn,optim\nimport torch.nn.functional as F\n\n%matplotlib inline","39595088":"USE_GPU = torch.cuda.is_available()\nif USE_GPU:\n    print('Use GPU')\nelse:\n    print('Use CPU')","6002fd73":"def show_mnist_batch(imgs,labels):\n    \"\"\"Show image for a batch of samples.\"\"\"\n\n    grid = utils.make_grid(imgs)\n    plt.imshow(grid.numpy().transpose((1, 2, 0)))","514292e1":"def cross_entropy(y,yp):\n    # y is the ground truch\n    # yp is the prediction\n    yp[yp>0.99999] = 0.99999\n    yp[yp<1e-5] = 1e-5\n    return np.mean(-np.log(yp[range(yp.shape[0]),y.astype(int)]))\n\ndef accuracy(y,yp):\n    return (y==np.argmax(yp,axis=1)).mean()\n\ndef softmax(score):\n    score = np.asarray(score, dtype=float)\n    score = np.exp(score-np.max(score))\n    score = score\/(np.sum(score, axis=1).reshape([score.shape[0],1]))#[:,np.newaxis]\n    return score","373138f3":"class MnistDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, df, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.df = df\n        self.transform = transform\n        if 'label' in df.columns:\n            self.labels = df['label'].values\n            self.images = df.drop('label',axis=1).values\n        else:\n            self.labels = np.zeros(df.shape[0])\n            self.images = df.values\n        self.images = (self.images\/255.0).astype(np.float32).reshape(df.shape[0],28,28)\n        \n    \n    def head(self):\n        return self.df.head()\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        label = np.array(self.labels[idx])\n        image = self.images[idx]\n        sample = {'image': image, 'label': label}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample['image'],sample['label']","ccff0813":"class ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n\n    def __call__(self, sample):\n        image, label = sample['image'], sample['label']\n        # torch image: [C, H, W]\n        return {'image': torch.from_numpy(image).unsqueeze(0),\n                'label': torch.from_numpy(label)}","9ceef302":"class Logistic_Model(nn.Module):\n    def __init__(self,num_fea,num_class):\n        super().__init__()\n        #nn.Linear(input_dim, output_dim)\n        self.lin = nn.Linear(num_fea,num_class)\n\n    def forward(self, xb):\n        B = xb.size()[0]\n        if len(xb.size())>2:\n            xb = xb.view(B,-1) # 4D tensor of B,C,H,W -> 2D tensor B,CxHxW\n        return self.lin(xb)","9aa4a4b5":"class SimpleCNN(torch.nn.Module):\n    \n    #Our batch shape for input x is (3, 32, 32)\n    \n    def __init__(self,h,w,c,num_class):\n        super(SimpleCNN, self).__init__()\n        \n        #Input channels = 3, output channels = 18\n        self.h = h\n        self.w = w\n        self.c = c\n        self.num_class = num_class\n        \n        self.conv1 = torch.nn.Conv2d(c, 18, kernel_size=3, stride=1, padding=1)\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        \n        #4608 input features, 64 output features (see sizing flow below)\n        self.fc1 = torch.nn.Linear(18 * h\/\/2 * w\/\/2, 64)\n        \n        #64 input features, 10 output features for our 10 defined classes\n        self.fc2 = torch.nn.Linear(64,num_class)\n        \n    def forward(self, x):\n        \n        #Computes the activation of the first convolution\n        #Size changes from (3, 32, 32) to (18, 32, 32)\n        x = F.relu(self.conv1(x))\n        \n        #Size changes from (18, 32, 32) to (18, 16, 16)\n        x = self.pool(x)\n        \n        #Reshape data to input to the input layer of the neural net\n        #Size changes from (18, 16, 16) to (1, 4608)\n        #Recall that the -1 infers this dimension from the other given dimension\n        x = x.view(-1, 18 * self.w\/\/2 * self.h\/\/2)\n        \n        #Computes the activation of the first fully connected layer\n        #Size changes from (1, 4608) to (1, 64)\n        x = F.relu(self.fc1(x))\n        \n        #Computes the second fully connected layer (activation applied later)\n        #Size changes from (1, 64) to (1, 10)\n        x = self.fc2(x)\n        return(x)","fa81719b":"%%time\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nprint(train_df.shape, test_df.shape)","303a6a0e":"train_df.head()","d7855c08":"%%time\n\nval_pct = 0.2 # use 20% train data as local validation\nis_valid = np.random.rand(train_df.shape[0])<val_pct\ntrain_df, valid_df = train_df.loc[~is_valid], train_df.loc[is_valid]\nprint(train_df.shape, valid_df.shape)","6db8927d":"%%time\ntrain_dataset = MnistDataset(df=train_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))\nvalid_dataset = MnistDataset(df=valid_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))\ntest_dataset = MnistDataset(df=test_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))","2b7ed743":"fig = plt.figure(figsize=(20,8))\n\nfor i in range(len(train_dataset)):\n    img,label = train_dataset[i]\n\n    print(i, img.shape)\n\n    ax = plt.subplot(1, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{} Label {}'.format(i,label), fontsize=30)\n    ax.axis('off')\n    plt.imshow(img.numpy()[0],cmap='gray')\n\n    if i == 3:\n        plt.show()\n        break","648bf3d2":"%%time\n\nbatch_size = 128\ncpu_workers = 8\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n                        shuffle=True, num_workers=cpu_workers,\n                        drop_last=True)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,\n                        shuffle=False, num_workers=cpu_workers,\n                        drop_last=False)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n                        shuffle=False, num_workers=cpu_workers,\n                        drop_last=False)","dc26fe25":"databunch = DataBunch(train_dl=train_dataloader, \n                      valid_dl=valid_dataloader, \n                      test_dl=test_dataloader,\n                     )","78cd9b45":"model = SimpleCNN(h=28,w=28,c=1,num_class=10)\nlearn = Learner(databunch, model, loss_func=F.cross_entropy, metrics=fastai_accuracy)","4f15cf8d":"%%time\nlearn.lr_find()","543bfb1c":"learn.recorder.plot()","a5860401":"%%time\nlearn.fit_one_cycle(50,max_lr=slice(0.01),\n        callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy',name='mnist')])","5605f646":"%%time\nyp,_ = learn.get_preds()\nyp = yp.numpy()","17da67df":"%%time\nacc = accuracy(valid_df.label.values,yp)\nce = cross_entropy(valid_df.label.values,yp)\nprint('Valid ACC: %.4f Cross Entropy:%4f'%(acc,ce))","1d8fe511":"%%time\nyps,_ = learn.get_preds(DatasetType.Test)\nyps = yps.numpy()","7c9d231c":"sub = pd.DataFrame()\nsub['ImageId'] = np.arange(yps.shape[0])+1\nsub['Label'] = np.argmax(yps,axis=1)\nsub.head()","de8d4cc4":"from datetime import datetime\nclock = \"{}\".format(datetime.now()).replace(' ','-').replace(':','-').split('.')[0]\nout = 'fastai_%s_acc_%.4f_ce_%.4f.csv'%(clock,acc,ce)\nprint(out)\nsub.to_csv(out,index=False)","32afe118":"### Data loader generates batch of samples with multi-thread functions.","c1951842":"### A model is a subclass of nn.Module which defines a computing graph","ff0cc94c":"### Predict and write submission","de0d19fc":"## Function and class definitions","d9c8ec3d":"### Illustrate the first batch","ccfb7dab":"### Read csv","ac10ed7a":"## Inspect datasets","324d26e8":"## Training"}}