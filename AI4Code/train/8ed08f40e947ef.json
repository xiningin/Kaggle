{"cell_type":{"b76cf8dc":"code","452338f0":"code","2eede2cc":"code","62439921":"code","39f60866":"code","1f239018":"code","7f7c3035":"code","954d2ec2":"code","bbd87646":"code","ae52b052":"code","b9d34744":"code","4664f6c1":"code","dcadb2af":"code","14445de8":"code","03931e1c":"code","af1a12f3":"code","aae8f856":"code","c264e6da":"code","61d2bb64":"code","14c9a0f1":"code","65d01577":"code","85018983":"code","9af7fd36":"code","2865a74c":"markdown","95855c96":"markdown","385d9188":"markdown","9564f1df":"markdown"},"source":{"b76cf8dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","452338f0":"train_df  = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\n","2eede2cc":"train_df.head()","62439921":"test_df.head()","39f60866":"train_df.isna().sum(),test_df.isna().sum()","1f239018":"X = train_df.drop(columns = ['target'])\ny = train_df['target']","7f7c3035":"from sklearn.preprocessing import StandardScaler\n\nscalar = StandardScaler()\nX_scaled = scalar.fit_transform(X)\n\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"vif\"] = [variance_inflation_factor(X_scaled,i) for i in range(X_scaled.shape[1])]\nvif[\"Features\"] = X.columns","954d2ec2":" vif.loc[vif['vif']>5.0].count()","bbd87646":" import matplotlib.pyplot as plt\nimport seaborn as sns\nfig,ax = plt.subplots(figsize=(50,10))\n\nsns.boxplot(data = X, width = 1, ax = ax, fliersize = 10)\nplt.xticks(rotation=90)\nplt.ylabel('values') ","ae52b052":"#No outliers are present. So Lets build the model","b9d34744":"import tensorflow\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import InputLayer\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.metrics import AUC\nfrom keras.layers import Dropout\n","4664f6c1":" \nx_test = test_df.iloc[:,:]\n","dcadb2af":"train_df['target'].unique()","14445de8":"df = train_df.copy()","03931e1c":"from sklearn.preprocessing import OneHotEncoder\n# creating one hot encoder object \nonehotencoder = OneHotEncoder()\n#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \nX_new = onehotencoder.fit_transform(df.target.values.reshape(-1,1)).toarray()\n#To add this back into the original dataframe \ndfOneHot = pd.DataFrame(X_new) \ndf_new = pd.concat([df, dfOneHot], axis=1)","af1a12f3":"df_new.head()","aae8f856":"df_new = df_new.drop(['target'],axis=1)","c264e6da":"X2 = df_new.iloc[:,:76]\ny2 = df_new.iloc[:,76:]","61d2bb64":" y2.columns","14c9a0f1":"\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_valid, y_train, y_valid = train_test_split(X2, y2, train_size=0.8, test_size=0.2, random_state=48)","65d01577":"def custom_model2():\n    model = Sequential(InputLayer([76]))\n    model.add(Dropout(0.2 ))\n    model.add(BatchNormalization())\n    model.add(Dense(8, kernel_initializer='he_normal',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(16,kernel_initializer='he_normal' ,activation='relu'))\n    model.add(Dropout(0.2 ))\n    model.add(Dense(9, activation='softmax'))\n                        \n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',AUC()])\n    return model\n\nmodel_eval = custom_model2()\nhistory = model_eval.fit(\n     x_train, y_train,\n    validation_data=(x_valid, y_valid),\n    batch_size=100,\n    epochs=100, verbose=2\n    )","85018983":"model_eval = custom_model2()\nhistory = model_eval.fit(\n     X2,y2,\n    batch_size=50,\n    epochs=100, verbose=2\n    )","9af7fd36":"predicted = model_eval.predict(x_test)\noutput = pd.DataFrame(predicted)\noutput = output.rename(columns={i:f'Class_{i+1}' for i in range(9)})\noutput = output.rename_axis(\"id\", axis='rows')\nidcol = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nidcol = idcol.iloc[:,0]\noutput = pd.concat([idcol, output], axis=1)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2865a74c":"No collinearity","95855c96":"Deal with categorical values presnet in the label column. apply one hot encoding","385d9188":" Vizualization for any outliers","9564f1df":"> **Check for collinearity **"}}