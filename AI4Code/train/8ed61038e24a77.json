{"cell_type":{"38d4f2ed":"code","7d1b2845":"code","98848430":"code","fcb1fcae":"code","030829ec":"code","2e6f89a0":"code","4309aec9":"code","2eacc2a6":"code","bd87d099":"code","543c76e4":"code","6ab6e7cb":"code","1f4b9a5a":"code","629381b5":"code","90570ad4":"code","9f064450":"code","7ce21dd7":"code","6125db46":"code","257b4653":"code","95bce3e0":"code","8d75a23f":"code","617cb270":"code","fec4a2d9":"code","688df715":"code","ad40a574":"markdown","a845aeb7":"markdown","c4fe4a7b":"markdown","752d6cae":"markdown","862ed23c":"markdown","2c274e5e":"markdown","73d5c588":"markdown","df0d41e4":"markdown","57ae6544":"markdown","970e95cd":"markdown","8659210f":"markdown","72b6b48e":"markdown","285ac8f9":"markdown","144459ae":"markdown","cfbd2795":"markdown"},"source":{"38d4f2ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7d1b2845":"import pandas as pd\nimport numpy as np\nimport os\n#import world_bank_data as wb\n\n\n#Load datasets\npath = '..\/input\/novel-corona-virus-2019-dataset\/'\ncon = pd.read_csv(path+'time_series_covid_19_confirmed.csv')\nrec = pd.read_csv(path+'time_series_covid_19_recovered.csv')\ndea = pd.read_csv(path+'time_series_covid_19_deaths.csv')","98848430":"#use a custom mapping file\ndf_map = pd.read_csv('..\/input\/coronavirus\/countryMapping.csv')\n\n#standardize countries\nscon = con.merge(df_map, how='left', on = 'Country\/Region')\nsrec = rec.merge(df_map, how='left', on = 'Country\/Region')\nsdea = dea.merge(df_map, how='left', on = 'Country\/Region')\n\n#check missing country code\nscon.loc[scon['Country Code'].isna(), 'Country\/Region'].unique()","fcb1fcae":"#Stack and merge dataframes\ndef stack_df(df, field):\n    tmp = df.iloc[:,4:]\n    tmp = tmp.groupby('Country Code').sum()\n    tmp =tmp.stack().reset_index()\n    tmp.columns=['country', 'dates', field]\n    return tmp\n\nscon = stack_df(scon, 'confirmed')\nsrec = stack_df(srec, 'recovered')\nsdea = stack_df(sdea, 'deaths')\ndf = scon.merge(srec, on=['country', 'dates']).merge(sdea, on=['country', 'dates'])\ndf.head()","030829ec":"df['dates'] = pd.to_datetime(df.dates)\ndf['actives'] = df.apply(lambda x: x.confirmed - x.deaths - x.recovered, axis = 1)\ndf['lethality'] = df.apply(lambda x: 100*x.deaths \/ x.confirmed if x.confirmed > 0 else 0.0, axis = 1)\n\n'''Convert cumulative Confirmed to new cases'''\nnewCases=[]\nfor cc in df.country.unique():\n    sel =  df.loc[df.country==cc].sort_values('dates')\n    cumul = sel.confirmed.values\n    dates = sel.dates.values\n    newCases.extend([(cc, dates[0], cumul[0])] + [(cc, dates[ix+1], i- cumul[ix]) for ix,i in enumerate(cumul[1:])])\nnewCases = pd.DataFrame(newCases, columns = ['country','dates','new_cases'])\ndf = df.merge(newCases, on=['country','dates'])\ndf.head()\n\n'''Calculate prevalence & incidence from world bank population data'''\n#Deprecated because can't !pip install world_bank_data\n# wb_pop = pd.DataFrame(wb.get_series('SP.POP.TOTL', date='2018', id_or_value='id',simplify_index=True)).reset_index()\n# wb_pop = wb_pop.rename(columns={'Country':'Country Code', 'SP.POP.TOTL':'population'})\n#Replaced by\ndfp = pd.read_csv('..\/input\/coronavirus\/world.csv')\nwb_pop=  dfp.loc[dfp['Series Code'] == 'SP.POP.TOTL',['Country Code','2018 [YR2018]']]\nwb_pop['2018 [YR2018]'] = wb_pop['2018 [YR2018]'].apply(lambda x: eval(x) if x !='..' else np.nan)\nwb_pop = wb_pop.rename(columns={'2018 [YR2018]': 'population'})\n\ndf = df.merge(wb_pop, left_on = 'country', right_on='Country Code')\ndel df['Country Code']\ndf['prevalence'] = df.apply(lambda x: round(10000*x.confirmed\/x.population,5), axis = 1)\ndf['incidence'] = df.apply(lambda x: round(10000*x.new_cases\/x.population,5), axis = 1)\ndf.dropna(inplace=True)\ndf.head()","2e6f89a0":"'''Apply R script to calculate Reproduction Factor from Epiestim package'''\n#df.to_csv('covid19_epi.csv', index=False)\n#if os.system('Rscript get_R.R')!=0:\n#    print('Error in R script: get_R')\n\n\"\"\"ReproductionFactor.csv is obtained from the R script get_R.R provided here:\nlibrary(EpiEstim)\n\ncovid19 <- read.csv(\"~\/Documents\/deep_learning\/coronavirus\/covid19_epi.csv\")\ncovid19$dates<-as.Date(covid19$dates)\nfirstpass<-TRUE\nfor (i in unique(covid19$country))\n{\n  sel <- subset(covid19, country==i)\n\n  #reproduction number\n  df=subset(sel, select=c(dates, new_cases))\n  names(df)[2] <- \"I\"\n  df$I<-replace(df$I, df$I<0, 0)\n  res_parametric_si <- estimate_R(df, method=\"parametric_si\", config = make_config(list(mean_si = 3.96, std_si = 4.75)))\n  si_param<-res_parametric_si$SI.Moments\n  si_dist<-res_parametric_si$si_distr\n  R<-subset(res_parametric_si$R, select=c(`Mean(R)`, `Quantile.0.05(R)`, `Median(R)`, `Quantile.0.95(R)`))\n  R$dates<-res_parametric_si$dates[(2:(length(res_parametric_si$dates)-6))]\n  R$country<-i\n  if(firstpass)\n  {\n    concat<-R\n    firstpass<-FALSE\n  }\n  else\n    concat<-rbind(concat,R)#c(concat,R)\n}\n\npath<-\"~\/Documents\/deep_learning\/coronavirus\/\"\nwrite.csv(concat,paste(path,\"ReproductionFactor.csv\")) \n\"\"\"\n\ndfr = pd.read_csv('..\/input\/coronavirus\/ReproductionFactor.csv')\ndel dfr['Unnamed: 0']\ndfr.columns=['mean', 'Q5', 'med', 'Q95', 'dates','country']\ndfr['dates'] = pd.to_datetime(dfr.dates)","4309aec9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\ndef plotCountries(feature, df, title, country = None):\n    weeks = mdates.WeekdayLocator()\n    dayMonth_fmt = mdates.DateFormatter('%m-%d')\n    fig, ax = plt.subplots(figsize = (12,6))\n    if not country is None:\n        tmp = df.loc[df.country== country]\n        g=sns.lineplot(x=\"dates\", y=\"mean\", data=tmp)\n        g.fill_between(x=\"dates\", y1=\"Q5\", y2=\"Q95\", data=tmp, alpha=0.2)\n    else:\n        g = sns.lineplot(x=\"dates\", y=feature, hue=\"country\",  data=df)\n    g.set_title(title)  \n    g.xaxis.set_major_locator(weeks)\n    g.xaxis.set_major_formatter(dayMonth_fmt)\n    plt.xticks(rotation=30) \n    \n\ndef plotRegion(countries):\n    #subset of selected countries\n    sel = df.loc[df.country.isin(countries)]\n    rsel = dfr.loc[dfr.country.isin(countries)]\n    #Common X axis\n    dates = [np.datetime_as_string( i, unit='D') for i in sel.dates.values]\n    #create multiple subplots on one layout\n    fig = make_subplots(\n        rows=3, cols=2,\n        specs=[[{}, {}], [{}, {}], [{\"colspan\": 2}, None]],\n        subplot_titles=(\"Number of infectious cases\", \"Number of cases per 10 000 capita\", \"Number of new cases per 10 000 capita\", \"Lethalithy in %\",\"Reproduction Factor\"))\n    #plot features from sel\n    for idx, feature in enumerate(['actives','prevalence','incidence','lethality']):\n        for i in sel.country.unique():\n            tmp = sel.loc[sel.country == i]\n            fig.add_trace(go.Scatter(x=dates, y=tmp[feature].values, mode='lines', name=i, legendgroup=i, showlegend= not idx), row=idx\/\/2+1, col =idx%2+1)\n    #plot R factor from rsel\n    for i in sel.country.unique():\n            tmp = rsel.loc[rsel.country == i]\n            fig.add_trace(go.Scatter(x=dates, y=tmp['mean'].values, mode='lines', name=i, legendgroup=i, showlegend= False), row=3, col =1)        \n    return fig.update_layout(height=800, title_text=\"Descriptive epidemiology in Europe\"), sel, rsel #height=900, width=1200, \n\ndef getLastR(df):\n    return df.loc[df.groupby('country').dates.idxmax()].sort_values('mean',ascending=False)\n\ndef getCorrLethality(df, countries):\n    return pd.DataFrame([(i, df.loc[(df.country == i)&(df.prevalence>0.2)][['lethality','prevalence']].corr().values[0][1]) for i in countries],\\\n             columns = ['country', 'corr']).sort_values('corr', ascending =False).dropna()\n\ndef choropleth(df, scope, field, uppad=0):\n    #get min max of the feature for color scaling\n    scales = df[field].describe()\n    #define map for Reproduction Factor\n    fig = px.choropleth(df, locations='country', color=field,\n                               locationmode='ISO-3',\n                               color_continuous_scale=\"Viridis\",\n                               range_color=(scales['min'], scales['max']-uppad),\n                               scope=scope,\n                               labels={field:'Reproduction Factor'}\n                               #,width = 1200, height = 600\n                              )\n    return fig.update_layout()#autosize=False, width=1200, height=900,margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n","2eacc2a6":"countries=['FRA', 'ITA', 'ESP', 'DEU', 'SWE','SWZ', 'GBR', 'BEL','AUT','NLD']\nfig, sel, rsel = plotRegion(countries)\nfig.show()","bd87d099":"getCorrLethality(sel, countries)","543c76e4":"plotCountries('mean',rsel,'Reproduction factor in France','FRA')","6ab6e7cb":"tmp = getLastR(rsel)\nchoropleth(tmp, 'europe', 'mean',4)","1f4b9a5a":"countries=['CHN', 'KOR', 'JPN','MYS','THA','IRN','IND','AFG','IRK']\nfig, sel, rsel = plotRegion(countries)\nfig.show()","629381b5":"tmp = getLastR(rsel)\nchoropleth(tmp, 'asia', 'mean')","90570ad4":"getCorrLethality(sel, countries)","9f064450":"countries=['USA','CAN','MEX']\nfig,sel, rsel = plotRegion(countries)\nfig.show()","7ce21dd7":"getCorrLethality(sel, countries)","6125db46":"tmp = getLastR(rsel)\nchoropleth(tmp, 'north america', 'mean')","257b4653":"from scipy.optimize import minimize, curve_fit\nimport scipy.integrate as spi\n\ndef diff_eqs(INPUT,t):  \n    Y=np.zeros((3))\n    V = INPUT   \n    Y[0] = -beta * V[0] * V[1]\n    Y[1] = beta * V[0] * V[1] - gamma * V[1]\n    Y[2] = gamma * V[1]\n    return Y  \n\ndef SIR(x, p):\n    initial, beta, gamma, = p\n    res = spi.odeint(diff_eqs,initial,x)\n    return res[:,1]\n\n#We select the vector to be fitted by the model\n\nsel = df.loc[(df.country == 'FRA') & (df.dates> '2020-01-23'), 'actives'].values\nduration= sel.shape[0]\npop = 67e6\ntrueCaseRate = 100\nS0=0.82  #initial p(succeptible)\nI0= sel[0]*trueCaseRate\/pop  #initial p(infectious)\nbeta = 4\/14\ngamma = 1\/14\nres1 = SIR(range(0,150), [[S0, I0,0.0],beta, gamma])    \nplt.plot(res1, '-r', label='Infectious')\ny=trueCaseRate*sel\/(S0*pop)\nplt.plot(y, '-b', label='Infectious')\nprint('Days before the climax: %i'%(np.argmax(res1)-len(y)))\nprint('Max number of infectious cases = %i'%(max(res1)*pop\/trueCaseRate))\nplt.show()","95bce3e0":"#select the start of outbreak\nsel = df.loc[(df.country == 'FRA') & (df.dates> '2020-01-23'), 'actives'].values\nduration= sel.shape[0]\npop = 67e6\ntrueCaseRate = 100\nS0=0.96  #initial p(succeptible)\nI0= sel[0]*trueCaseRate\/pop  #initial p(infectious)\nbeta = 2.5\/9\ngamma = 1\/9\nres2 = SIR(range(0,150), [[S0, I0,0.0],beta, gamma])    \nplt.plot(res1, '-r', label='Infectious')\ny=trueCaseRate*sel\/(S0*pop)\nplt.plot(y, '-b', label='Infectious')\nprint('climaxday: %i'%(np.argmax(res1)-len(y)))\nprint('Max number of infectious cases = %i'%(max(res2)*pop\/trueCaseRate))","8d75a23f":"#select the start of outbreak\nsel = df.loc[(df.country == 'FRA') & (df.dates> '2020-01-23'), 'actives'].values\nduration= sel.shape[0]\npop = 67e6\ntrueCaseRate = 70\nS0=0.86  #initial p(succeptible)\nI0= sel[0]*trueCaseRate\/pop  #initial p(infectious)\nbeta = 3\/10\ngamma = 1\/10\nres3 = SIR(range(0,150), [[S0, I0,0.0],beta, gamma])    \nplt.plot(res3, '-r', label='Infectious')\ny=trueCaseRate*sel\/(S0*pop)\nplt.plot(y, '-b', label='Infectious')\nprint('climaxday: %i'%(np.argmax(res3)-len(y)))\nprint('Max number of infectious cases = %i'%(max(res3)*pop\/trueCaseRate))","617cb270":"models = pd.concat([pd.DataFrame(range(0,150)), pd.DataFrame(res1), pd.DataFrame(res2), pd.DataFrame(res3)], axis=1)\nmodels.columns = ['days','model 1', 'model 2', 'model 3']\nmodels.set_index('days', inplace=True)\nmodels = models.stack().reset_index()\nmodels.columns=['day','type','value']\nmodels.head()\n\npx.line(models, x=\"day\", y= \"value\", color=\"type\")","fec4a2d9":"df_map = pd.read_csv('countryMapping.csv')\nscon = con.merge(df_map, how='left', on = 'Country\/Region')\ndf_cc = pd.read_csv('countryCodes.csv')\nm2 = scon.loc[scon['Country Code'].isna()].merge(df_cc ,how='left', left_on='Country\/Region', right_on='Country Name')\nm2.loc[m2['Country Code_y'].isna(), 'Country\/Region'].unique()\nm2['Country Code'] = m2.apply(lambda x: x['Country Code_y'] if type(x['Country Code_y'])!=float else x['Country Code_x'], axis =1 )\nm2[['Country\/Region','Country Code']].groupby('Country\/Region').agg({'Country Code': 'first'}).reset_index().to_csv('countryMapping2.csv', index=False)\n#Fill missing codes by hand","688df715":"df_map2 = pd.read_csv('countryMapping2.csv')\nndf_map = pd.concat([df_map, df_map2])\nndf_map.to_csv('countryMapping.csv', index=False)\nndf_map.shape","ad40a574":"## Feature engineering","a845aeb7":"## Standardize countries, pivot dataframes and merge them together\nAn custom file is used. If you think there are to many missing countries you can complete the file with the code given at the end of this notebook: \n>Just in case there are some missing country code in coutryMapping.csv\n","c4fe4a7b":"## geographical plot of Reproduction factor\n\nSwizerland have a current R factor = 5, they are at the beginning of the story. It is removed from plot to convenience because one could not have seen subtile differences between other countries. The more the country is dark, the more is close to the stabilization... Yes colors should have been inverted for a better representation... Anyway.","752d6cae":"The first two plots up shows the start of the outbeak in each country, when the number of cases start to grow exponentialy. For example one can see that there are 10 days difference between Italy and other countries, but UK that is 16 days late. We can observe higtest prevalences for Italy, Spain, Germany and Austria.\n\nThe plot about incidence tell us that Italian and Spainish undergoe an heavy pression for pepole admission. \n\nThe lethality plot show the surprise effect: a new disease is coming and we are not prepared. This is obious for France and Italy. Morever, and that is disturbing, lethality increase with time, but prevalence also increase with time and those 2 values may be correlated (yes they are Cf the next cell). There are 2 explications:\n* Virus become more lethal when circulating into population\n* Hospital are overwhemed and cares are not sufficient to save more people.\n\nThe last plot is very interesting.It show the evolution of the reproduction factor. When decreasing to 1 there are as many new cases as recovered or dead people. We have reach the climax of the outbreak and the situation wil improve. When R=0 the outbreak is over. Morever this graph allow to pick the R0 value for parametrization of the SIR model. Finnaly it show significant events preceeding the spread od the disease. For example in Italy around the 14 Februry, one infected transmitted the disease to 50 people! The 15 february is the national day of carnaval in Italy. The Venice session have been canceled but not the minor carnavals in every town are village. \n","862ed23c":"### A detailled plot of the R factor with a confidence interval of 95%.\n\nAt the begging the confidence interval is large and become thiner while more learning data are availlable. Notice that the estimation of R is 6 days late, because a slidding window is used for the calculus. R0 should be 2 for France.","2c274e5e":"## VIZ\n\nUtilities functions are defined below. The main plotting library used is Plotly, because it allow interactivity on graph for a better reading.","73d5c588":"# Can we simply predict the evolution of the COVID-19 outbreak?\n\nRelated work [here](https:\/\/www.kaggle.com\/sunfinger\/covid-19-comparison-of-1dcnn-and-sir-model).\n\n### Context:\n\nSARS-COV2 have been isolated in China in decembre 2019. This is an new variant of the previous virus responsible of [SARS](https:\/\/en.wikipedia.org\/wiki\/Severe_acute_respiratory_syndrome) an [MERS](https:\/\/en.wikipedia.org\/wiki\/Middle_East_respiratory_syndrome) outbreaks. This new virus bind whith increased affinity to human cell receptors so it can infecte people more efficiently. This is why this new variant is responsible of a real pandemic outbreak.\n\n### Objective:\n\nThe point is to predict the outcomme of the outbreak. My point is that it is not trivial, because machine learning predict future through the past. The signal is not periodic nor seasonal, It is the first time this happen. So the past could not contains informations to predict the future. However epidemiological model exists such as [the SIR model](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology) mentioned in different works. But the issue is to parametrize such model based on differential equations. So what?\n\nThe important point is probably to monitor the progression of the outbreak in each country to set up health policies to avoid virus spreading. \n\n### Method:\nObserving cumulated number of cases is not fully informative, and no comparison between countries can be done because populations are different in number. So I propose the following method.\n\n1. Get updated data from [Johns Hopkins Github repository](https:\/\/github.com\/CSSEGISandData\/COVID-19)\n2. Standardize countries name using [ISO 3166-1 alpha-3 nomenclature](https:\/\/www.iban.com\/country-codes)\n3. Reorganize data in a fonctionnal data frame and enrich data with the population number from the [world bank](https:\/\/data.worldbank.org\/) with the package world_bank_data\n4. Make some feature engineering to calculate:\n* prevalence = number of infected people \/ total population\n* incidence = number of new cases \/ total population\n* lethalithy = number of deaths\/ number of sick people\n5. Calculate the reproduction factor with the R package EpiEstim. The [Reprocution factor](https:\/\/www.healthline.com\/health\/r-nought-reproduction-number) is the number of people that are contaminated by a single infected. To parametrize the SIR model we use the R0. This R0 is evaluated around 2. Remember that for measles it's about 16! So please keep your children vaccinated, it is a public-spirited behaviour.\n6. Make some viz comparing the most representative countries in Asia, Europe and North America and get some insight about important source of contamination.\n7. Understand a SIR model with France as an example.\n\n![cat3.jpg](attachment:cat3.jpg)","df0d41e4":"## SIR model\n\nFor SIR parametrization we need beta and gamma:\n\n$\\gamma$ = 1\/number of days before recovering or die from the disease (probability to recover or die)\n\n$\\beta$ is the probabilty to become infectious for a succeptible person with :\n\nR0 = $\\beta$ \/ $\\gamma$ <=>$\\beta$ = R0.$\\gamma$\n\nFor the example of France we can choose 2<= R0 <=4 and $\\gamma$ = 1\/14\nThe following model is expressed in probabilties and proportion:\n* S0 = Proportion of the population that is succeptible \/ exposed\n* I0 = Proportion of infectious people at the begining of the out break\n\nSo if we want to standardize observed real data we need to divide by the total population. But are the confirmed active cases speaking truth. Absolutly not, A large proportion of people will be infected but never tested thus not confirmed. We don't know about this proportion that may dramatically vary from one country to another.\nSo we define a true case rate (TCR). The number which multiply the confirmed cases to get the true infected (symptomatic and non symptomatic).\n\nWe tested 3 models here:\n* R0 = 4, TCR = 100, S0 = 0.82, mean duration of the sick infectious period = 14 for a prediction of climax in 23 days from 2020-03-23 (last available data)\n* R0 = 3, TCR = 70, S0 = 0.86, mean duration of the sick infectious period = 10 for a prediction of climax in 24 days from 2020-03-23 (last available data)\n* R0 = 2.5, TCR = 100, S0 = 0.96, mean duration of the sick infectious period = 9 for a prediction of climax in 25 days from 2020-03-23 (last available data)\n\nThat is close, but the start of outbreak could have been some days earlier because of non detected cases .The drawback is that it needs to be fitted by hand and . There are many solutions for the given data and the model can't be data driven only. In my hands ,attempts to minimize the mse between data and model have lead to inconsitent parameters.\n\nThe max number in France of current tested active cases should be greater than 140 000 i.e 1.4 million of total infected cases. It comes to be comparable to influenza with 1.8 millions cases. First I hope my model is wrong, second these results are to occur without confinement. So if we want to soften this evolution, again : **Stay at home!**","57ae6544":"## Evaluation of Reproduction Factor with the R package EpiEstim\n This method needs a parametrization of serial interval. I used values from a [prepublished paper](https:\/\/wwwnc.cdc.gov\/eid\/article\/26\/6\/20-0357_article)","970e95cd":"## Situation in Europe","8659210f":"## Situation in Asia","72b6b48e":"The lethality peak for Iran the 19 February is connected to the very day when COVID-19 have been officially declared by iranian authorities whiel asking for a softening of embargo. Trump refused and is partly responsible for the many deaths in Iran. The correlation beetween lethality and prevalence is the higher for Iran. May be times will come when USA stop to impose his will and discover mercy.\nOutbreak is only beginning in India, Hope they are prepared.","285ac8f9":"## Get Updated data","144459ae":"### Just in case there are some missing country code in coutryMapping.csv [SKIP]","cfbd2795":"## What happened in USA around the 17 february?\nI'm not s\u00fbre is it the president's day?\n\nThe correaltion between prevalence and lethality is negative because it is the very beginning (surprise effect)\n\nA reproduction factor>2 in US the 15 March: **Stay at home!!** Work in remote whenever it is possible and think twice before to tell yourself that you have something important to do outside. Think about the wonderfull vetor you are for the virus spreading."}}