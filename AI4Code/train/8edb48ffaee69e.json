{"cell_type":{"a2cc668e":"code","cf405656":"code","652b6f66":"code","28893390":"code","342760e4":"code","ebd8cc5b":"code","ffde8ec4":"code","ee054d50":"code","df451fee":"code","ad5d975b":"code","c05dbf38":"code","50d080c8":"code","9c0c8726":"code","4bd7affd":"markdown"},"source":{"a2cc668e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf405656":"# importing libraries\nimport os\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport numpy as np \nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","652b6f66":"# setup file structure\nbase_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\ntrain_dir = os.path.join(base_dir, \"train\/\")\ntest_dir = os.path.join(base_dir, \"test\/\")\nval_dir = os.path.join(base_dir, \"val\/\")","28893390":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers.core import Activation, Dropout, Flatten, Dense\nfrom keras.layers import Convolution2D as Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nimport warnings\n\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","342760e4":"print(\"Number of images in Trian is {}\".format(len(glob(train_dir + \"*\/*\"))))\nprint(\"Number of images in Test is {}\".format(len(glob(test_dir + \"*\/*\"))))\nprint(\"Number of images in Validation is {}\".format(len(glob(val_dir + \"*\/*\"))))","ebd8cc5b":"warnings.filterwarnings('ignore')","ffde8ec4":"input_shape=(64,64,3)","ee054d50":"model = tf.keras.Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (3, 3),  activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.summary()","df451fee":"model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","ad5d975b":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/chest-xray-pneumonia\/chest_xray\/train',\n        target_size=(64, 64),\n        batch_size=64,\n        class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(\n        '..\/input\/chest-xray-pneumonia\/chest_xray\/test',\n        target_size=(64, 64),\n        batch_size=64,\n        class_mode='binary')\nmodel.fit(\n        train_generator,\n        steps_per_epoch=82,\n        epochs=10,\n        validation_data=validation_generator,\n        validation_steps=82)","c05dbf38":"\nscores = model.evaluate(validation_generator)\n\nprint(\"Loss of the model: %.2f\"%(scores[0]))\nprint(\"Test Accuracy: %.2f%%\"%(scores[1] * 100))","50d080c8":"# Saving the model for future use\nmodel.save('custom_model.h5')","9c0c8726":"def predict_image(filename):\n    img = load_img(filename, target_size=(64, 64))\n    image = keras.preprocessing.image.img_to_array(img)\n    image = image \/ 255.0\n    image = image.reshape(1,64,64,3)\n    model = tf.keras.models.load_model('custom_model.h5')\n    prediction = model.predict(image)\n    print(prediction)\n    plt.imshow(img)\n    if(prediction[0] > 0.5):\n        stat = prediction[0] * 100 \n        print(\"This image is %.2f percent %s\"% (stat, \"PNEUMONIA\"))\n    else:\n        stat = (1.0 - prediction[0]) * 100\n        print(\"This image is %.2f percent %s\" % (stat, \"NORMAL\"))\n        \n        \npredict_image(\"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/NORMAL2-IM-1427-0001.jpeg\")","4bd7affd":"Categories = [\"Train\", \"Test\", \"Validation\"]\nSubcategories = ['Normal', 'Pneumonia']\n\nTrain = [1341, 390]\nTest = [3875, 8]\nValidation = [234, 8]\n\ndata = {'Categories':Categories,\n        'Train':Train,\n        'Test':Test,\n        'Validation':Validation}\n\nx = [(categories, subcategories) for categories in Categories for subcategories in Subcategories]\ncounts = sum(zip(data['Train'], data['Test'], data['Validation']), ())\n\nsource = ColumnDataSource(data=dict(x=x, counts=counts, color=Spectral6))\n\np = figure(x_range=FactorRange(*x), plot_height=400, plot_width=800, title=\"Distribution of images with different category\",\n           tools=\"hover, pan, box_zoom, wheel_zoom, reset, save\", tooltips= (\"@x: @counts\"))\n\np.vbar(x='x', top='counts', width=0.9, color='color', legend_field=\"x\", source=source)\n\np.xgrid.grid_line_color = None\np.legend.orientation = \"horizontal\"\np.legend.location = \"top_center\"\noutput_notebook()\nshow(p)"}}