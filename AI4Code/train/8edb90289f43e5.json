{"cell_type":{"929430e3":"code","aac48cb2":"code","a917f40c":"code","491e7701":"code","7c0c249c":"code","e8caf9f9":"code","96872f83":"code","ac282ec0":"code","f1757673":"code","ec324263":"code","3a94948a":"code","a0c26223":"markdown","f20fc2bb":"markdown","c5543b4f":"markdown","72ea32d6":"markdown","389556df":"markdown","7818a54a":"markdown","bd33be12":"markdown","30fc844c":"markdown","0a27fee1":"markdown","3a745567":"markdown","deb80f9e":"markdown"},"source":{"929430e3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aac48cb2":"import pandas as pd","a917f40c":"annually_df = pd.read_csv(\"\/kaggle\/input\/euro-exchange-rates\/ert_bil_eur_a.tsv\", sep='\\t')","491e7701":"print(list(annually_df.columns))","7c0c249c":"pivot_data_col = annually_df.columns[0]\ntime_columns = annually_df.columns[1:]","e8caf9f9":"annually_df['statinfo'] = annually_df[pivot_data_col].apply(lambda x: x.split(\",\")[0])\nannually_df['unit']     = annually_df[pivot_data_col].apply(lambda x: x.split(\",\")[1])\nannually_df['currency'] = annually_df[pivot_data_col].apply(lambda x: x.split(\",\")[2])","96872f83":"selected_columns = list(['statinfo', 'unit', 'currency']) +  list(time_columns)\nannually_df = annually_df[selected_columns]","ac282ec0":"annually_tr_df = annually_df.melt(id_vars=['statinfo', 'unit', 'currency'], \n        var_name=\"date\", \n        value_name=\"value\")\nannually_tr_df['date'] = annually_tr_df['date'].apply(lambda x: int(x))\nannually_tr_df['value'] = annually_tr_df['value'].apply(lambda x: str(x).replace(\": \", \"NAN\"))\nannually_tr_df['value'] = annually_tr_df['value'].apply(lambda x: float(x))","f1757673":"print(f\"Transformed data shape: {annually_tr_df.shape} (rows\/columns)\")\nannually_tr_df.head()","ec324263":"annually_tr_df.tail()","3a94948a":"import pandas_profiling\npandas_profiling.ProfileReport(annually_tr_df)","a0c26223":"Let's inspect the result.","f20fc2bb":"The first column is a composed one, containing 3 different information (the type of statistical info, the unit and the currency). The next columns are the year value, from last (2020) to first (1971).","c5543b4f":"# A very preliminary exploratory data analysis\n\nThis would be a very short exploratory data analysis. The role of this Kernel is just to show how we can prepare the annual data for analysis and we already did this.","72ea32d6":"# Analysis preparation\n\n## Load packages","389556df":"# Data pre-processing\n\nWe start by defining two working lists.","7818a54a":"Then, we split from `pivot_data_col` the 3 separate fields:\n* statinfo (AVG\/END);\n* unit (NAC only);\n* currency (this would be each currency for which we provide the Euro conversion).","bd33be12":"Let's glimpse the data columns.","30fc844c":"# Introduction\n\nWe show in this Kernel how we can process the data to prepare it for easier processing. Let's check the data files.","0a27fee1":"## Load the data\n\nThe datafiles are in TSV format. We will read the files using pandas, just include in the function call the `sep` (tab separator data).\nWe demonstrate first how to read and process the Annual data.","3a745567":"Next, we pivot the time columns using `melt` operation in pandas.  \nWe also make sure we transform `date` to be an integer (here is a year data).  \nWe set `value` to be a float, after we replace \": \" (for N\/A) with `NAN`.","deb80f9e":"We select now only the new columns resulted from splitting the `pivot_data_col` and the time columns."}}