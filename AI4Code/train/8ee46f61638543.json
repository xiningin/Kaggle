{"cell_type":{"017aab8e":"code","c58e49fc":"code","c3c74391":"code","d6c324a4":"code","58e2f9e8":"code","57231562":"code","95d9ec9d":"code","d5720b3a":"code","7eec014c":"code","1424e05d":"code","88ae4ded":"code","d3565b76":"code","fa4c3372":"code","1284f8a8":"code","466383d9":"code","2ae522dd":"code","cf2f2250":"code","2b2bdbcd":"code","2ca425e6":"code","677330e9":"code","1a84c497":"code","3c06967e":"markdown","fd0e7a1a":"markdown","de19a5c5":"markdown","84419b70":"markdown","676e22bc":"markdown","2060e0e6":"markdown","a8403540":"markdown","e1898d6d":"markdown","9aa392ab":"markdown","96c17c3d":"markdown"},"source":{"017aab8e":"!pip install langdetect","c58e49fc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom langdetect import detect","c3c74391":"train = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/train.parquet')\ntest = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/test.parquet')\nss = pd.read_csv('..\/input\/kaggle-pog-series-s01e01\/sample_submission.csv')","d6c324a4":"train.head()","58e2f9e8":"train['target'].plot(kind='hist',bins=50)","57231562":"cfg = {\n    'TARGET' : 'target',\n    'N_FOLDS' : 5,\n    'RANDOM_STATE': 529,\n    'N_ESTIMATORS' : 50_000,\n    'LEARNING_RATE': 0.1\n}\n\ntrain_vids = train['video_id'].unique()","95d9ec9d":"kf = KFold(n_splits=cfg['N_FOLDS'],\n           shuffle=True,\n           random_state=cfg['RANDOM_STATE'])\n\n# Create Folds\nfold = 1\nfor tr_idx, val_idx in kf.split(train_vids):\n    fold_vids = train_vids[val_idx]\n    train.loc[train['video_id'].isin(fold_vids), 'fold'] = fold\n    fold += 1\ntrain['fold'] = train['fold'].astype('int')","d5720b3a":"def langdet(str):\n    try:\n       lang=detect(str)\n    except:\n       lang='Non'\n    return lang\n\ndef create_features(df, train=True):\n    \"\"\"\n    Adds features to training or test set.\n    \"\"\"\n    df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n    df['trending_date'] = pd.to_datetime(df['trending_date'], utc=True)\n    \n    # Feature 1 - Age of video\n    df['video_age_seconds'] = (df['trending_date'] - df['publishedAt']) \\\n        .dt.total_seconds().astype('int')\n    \n    # Trending day of week As a category\n    df['trending_dow'] = df['trending_date'].dt.day_name()\n    df['trending_dow']= df['trending_dow'].astype('category')\n    \n    df['published_dow'] = df['publishedAt'].dt.day_name()\n    df['published_dow']= df['published_dow'].astype('category')\n    \n    df['categoryId'] = df['categoryId'].astype('category')\n    \n    df['channel_occurance'] = df['channelId'].map(\n        df['channelId'].value_counts().to_dict())\n    \n    df['channel_unique_video_count'] = df['channelId'].map(\n        df.groupby('channelId')['video_id'].nunique().to_dict())\n    \n    df['video_occurance_count'] = df.groupby('video_id')['trending_date'] \\\n        .rank().astype('int')\n    \n    df['trending_dayofweek'] = df['trending_date'].dt.dayofweek\n    df['published_dayofweek']= df['publishedAt'].dt.dayofweek\n\n    df['is_trending_weekend'] = np.where((df['trending_dayofweek'] == 5) | (df['trending_dayofweek'] == 6), 1, 0)\n    df['is_published_weekend'] = np.where((df['published_dayofweek'] == 5) | (df['published_dayofweek'] == 6), 1, 0)    \n\n    \n    df['tag_count'] = df['tags'].map(lambda s: len(s.split('|')))\n    \n    df['title_lang'] = df['title'].map(lambda s: langdet(s) )\n    df['tag_lang'] = df['tags'].map(lambda s: langdet(s))\n    \n    return df","7eec014c":"train['isTrain'] = True\ntest['isTrain'] = False\ntt = pd.concat([train, test]).reset_index(drop=True).copy()\ntt = create_features(tt)\ntt_lang = tt[['title_lang','tag_lang']]","1424e05d":"d = tt_lang['title_lang'].value_counts().to_dict()\nprint(d)\n","88ae4ded":"d = tt_lang['tag_lang'].value_counts().to_dict()\nprint(d)","d3565b76":"tt2 = pd.get_dummies(tt, columns=[\"title_lang\", \"tag_lang\"])\n\ncols = [s for s in tt2.columns.values if 'title_lang' in s]\ncols.extend([s for s in tt2.columns.values if 'tag_lang' in s])\n\ntrain_feats = tt2.query('isTrain').reset_index(drop=True).copy()\ntest_feats = tt2.query('isTrain == False').reset_index(drop=True).copy()","fa4c3372":"train_feats.head()","1284f8a8":"FEATURES = ['video_age_seconds',\n            'trending_dow',\n            'published_dow',\n            'duration_seconds',\n            'categoryId',\n            'comments_disabled',\n            'ratings_disabled',\n            'channel_occurance',\n            'channel_unique_video_count',\n            'video_occurance_count',\n            \n            'trending_dayofweek',\n            'published_dayofweek',\n            'is_trending_weekend',\n            'is_published_weekend',\n\n            'tag_count'\n] + cols\n\nTARGET = ['target']","466383d9":"X_test = test_feats[FEATURES]\n\noof = train_feats[['id','target','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['id']].copy()","2ae522dd":"regs = []\nfis = []\n# Example Fold 1\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    reg = lgb.LGBMRegressor(n_estimators=cfg['N_ESTIMATORS'],\n                            learning_rate=cfg['LEARNING_RATE'],\n                            objective='mae',\n                            metric=['mae'],\n                            importance_type='gain'\n                           )\n    # Fit our model\n    reg.fit(X_tr, y_tr,\n            eval_set=(X_val, y_val),\n            early_stopping_rounds=500,\n            verbose=200,\n           )\n\n    # Predicting on validation set\n    fold_preds = reg.predict(X_val,\n                             num_iteration=reg.best_iteration_)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == 1')['target'],\n            oof.query('fold == 1')['preds']\n    )\n\n    # Creating a feature importance dataframe\n    fi = pd.DataFrame(index=reg.feature_name_,\n                 data=reg.feature_importances_,\n                 columns=[f'{fold}_importance'])\n\n    # Predicting on test\n    fold_test_pred = reg.predict(X_test,\n                num_iteration=reg.best_iteration_)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')\n    regs.append(reg)\n    fis.append(fi)","cf2f2250":"oof_score = mean_absolute_error(oof['target'], oof['preds'])\nprint(f'Out of fold score {oof_score:0.6f}')","2b2bdbcd":"fis_df = pd.concat(fis, axis=1)\nfis_df.sort_values('1_importance').plot(kind='barh', figsize=(12, 8),\n                                       title='Feature Importance Across Folds')\nplt.show()","2ca425e6":"submission_df","677330e9":"pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\n\nsubmission_df['target'] = submission_df[pred_cols].mean(axis=1)\n# Visually check correlation between fold predictions\nsns.heatmap(submission_df[pred_cols].corr(), annot=True)","1a84c497":"submission_df[['id','target']] \\\n    .to_csv('submission.csv', index=False)","3c06967e":"# Predict Youtube Tags & Title\n\nI've been looking into the possibility of using Tags and Titles for features.\n\n* Tag counts\n* Language(Tag and Title)\n\n\n# Reference\n\nBaseline \nhttps:\/\/www.kaggle.com\/robikscube\/pog-on-youtube-lgbm\n\nSome features are from\nhttps:\/\/www.kaggle.com\/mmellinger66\/pog-youtube-lgbm-optuna","fd0e7a1a":"# Create Submission","de19a5c5":"# Encoding Languages","84419b70":"# Look at Fold Feature Importances","676e22bc":"# Train LGBM Model","2060e0e6":"# Evaluation out of all out of fold predictions","a8403540":"# Set Target and Features","e1898d6d":"# Create Folds\n- This is how we will later split when validating our models","9aa392ab":"# Setup KFold","96c17c3d":"# Feature Engineering"}}