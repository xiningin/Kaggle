{"cell_type":{"0505540f":"code","9d1d6328":"code","8d17764a":"code","c7abe4ef":"code","c6269ed1":"code","dbadcf04":"code","0068106f":"code","84726a0b":"code","642dd914":"code","5215e014":"code","9b5e1ebb":"code","ac34dd32":"code","a7a266ec":"code","650e49af":"code","a6b285e7":"code","be8beb66":"code","3f33fa72":"code","88489d94":"code","1d443cb0":"code","bbc1e8c6":"code","02c09210":"code","10d6f7d3":"code","29100149":"code","9a3670cf":"code","a9727679":"code","8e1b32cc":"code","48258c6a":"code","f968e637":"code","e10119b9":"code","eb2c87ad":"code","45b70d5f":"code","da61b969":"code","1fa47d6a":"code","038b0091":"code","668267ae":"code","f45d9199":"code","e97cb15d":"code","d6a4dece":"code","6540c7d6":"code","d30643a6":"code","40f3e48b":"code","34e89b16":"code","5555ce6d":"code","97f79385":"code","377f661f":"code","e6100fbc":"code","1080fe72":"code","e208c04c":"code","92ae9602":"code","65823dda":"code","11d1937d":"code","14ee2f78":"code","b0efc15f":"code","c6acdb97":"code","2330566d":"code","88eeab63":"code","8cb27930":"code","178e37d8":"code","7ae28ee4":"code","9b48d41a":"code","569c45a3":"code","ccc9541c":"code","6c89693d":"code","5fc87d34":"code","9903a94f":"markdown","da166bab":"markdown","57ff3753":"markdown","7bac5550":"markdown","7dc4dddb":"markdown","0a7b958b":"markdown","b72140ae":"markdown","c87b613d":"markdown","694e9cef":"markdown","72fd9905":"markdown","c1fa59ba":"markdown","9c5ceeb2":"markdown","cee62602":"markdown","271d237d":"markdown","794a3cbd":"markdown","6de3a905":"markdown","a780ef32":"markdown","812a6f18":"markdown","fe8f925b":"markdown","90e81db4":"markdown","08dcd6d4":"markdown","272babff":"markdown","b50e5c36":"markdown","d5375bf6":"markdown","c7db9001":"markdown","894b25c6":"markdown"},"source":{"0505540f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d1d6328":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np","8d17764a":"train=pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv\")\n","c7abe4ef":"train.head()","c6269ed1":"df=train.drop('id',axis=1)\ndf.head()","dbadcf04":"print(df.columns)","0068106f":"df.describe()","84726a0b":"train.isnull().sum()","642dd914":"plt.figure(figsize=(20,8))\nsns.heatmap(data=df.corr(),annot=True,cmap=\"Greens\")","5215e014":"def with_hue(data,feature,ax):\n    \n    #Numnber of categories\n    num_of_cat=len([x for x in data[feature].unique() if x==x])\n    \n    bars=ax.patches\n    \n    for ind in range(num_of_cat):\n        ##     Get every hue bar\n        ##     ex. 8 X categories, 4 hues =>\n        ##    [0, 8, 16, 24] are hue bars for 1st X category\n        hueBars=bars[ind:][::num_of_cat] \n        # Get the total height (for percentages)\n        total=sum([x.get_height() for x in hueBars])\n        #Printing percentages on bar\n        for bar in hueBars:\n            percentage='{:.1f}%'.format(100 * bar.get_height()\/total)\n            ax.text(bar.get_x()+bar.get_width()\/2.0,\n                   bar.get_height(),\n                   percentage,\n                    ha=\"center\",va=\"bottom\",fontweight='bold')\n    \n\n    \ndef without_hue(data,feature,ax):\n    \n    total=float(len(data))\n    bars_plot=ax.patches\n    \n    for bars in bars_plot:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()\/total)\n        x = bars.get_x() + bars.get_width()\/2.0\n        y = bars.get_height()\n        ax.text(x, y,(percentage,bars.get_height()),ha='center',fontweight='bold')\n","9b5e1ebb":"plt.figure(figsize=(15,7))\nplt.text(0.7,220000,\"Data is highly Imbalanced\",fontweight='bold',fontsize=15)\nsns.set_theme(context='notebook',style='darkgrid')\na=sns.countplot(x=train[\"Response\"],palette=\"gnuplot\")\nwithout_hue(df,'Response',a)","ac34dd32":"df.head()","a7a266ec":"f,ax=plt.subplots(nrows=5,ncols=2,figsize=(20,50), \n                  gridspec_kw={'width_ratios': [10,10],\n                               'height_ratios': [10,10,10,10,10],'wspace': 0.2,\n                       'hspace': 0.4})\n\n\na1=sns.countplot(data=df,x=\"Gender\",ax=ax[0][0],palette=\"Set1\")\nwithout_hue(df,'Gender',a1)\na2=sns.countplot(data=df,x='Gender',hue='Response',palette=\"gnuplot\",ax=ax[0][1])\nwith_hue(df,'Gender',a2)\n\nb1=sns.countplot(data=df,x=\"Driving_License\",palette=\"gnuplot\",ax=ax[1][0])\nwithout_hue(df,\"Driving_License\",b1)\nb2=sns.countplot(data=df,x=\"Driving_License\",hue='Response',palette=\"gnuplot\",ax=ax[1][1])\nwith_hue(df,\"Driving_License\",b2)\n\nc1=sns.countplot(data=df,x=\"Previously_Insured\",palette=\"gnuplot\",ax=ax[2][0])\nwithout_hue(df,\"Previously_Insured\",c1)\nc2=sns.countplot(data=df,x=\"Previously_Insured\",hue='Response',palette=\"gnuplot\",ax=ax[2][1])\nwith_hue(df,\"Previously_Insured\",c2)\n\nd1=sns.countplot(data=df,x=\"Vehicle_Age\",palette=\"gnuplot\",ax=ax[3][0])\nwithout_hue(df,\"Vehicle_Age\",d1)\nd2=sns.countplot(data=df,x=\"Vehicle_Age\",hue='Response',palette=\"gnuplot\",ax=ax[3][1])\nwith_hue(df,\"Vehicle_Age\",d2)\n\ne1=sns.countplot(data=df,x=\"Vehicle_Damage\",ax=ax[4][0],palette=\"Set1\")\nwithout_hue(df,\"Vehicle_Damage\",e1)\ne2=sns.countplot(data=df,x=\"Vehicle_Damage\",hue='Response',palette=\"gnuplot\",ax=ax[4][1])\nwith_hue(df,\"Vehicle_Damage\",e2)\n","650e49af":"df.head()","a6b285e7":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,10))\nax[0].text(50,17000,\"Age data is right Skewed\",fontweight='bold',fontsize=15)\nsns.histplot(data=df,x=\"Age\",palette='gnuplot',kde=True,ax=ax[0],binwidth=1)\nax[1].text(50,17000,\"Age data is little right Skewed\\nwith hueness\",fontweight='bold',fontsize=15)\nsns.histplot(data=df,x=\"Age\",palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\",binwidth=1)","be8beb66":"df_age=sorted(df['Age'])\nQ1,Q3=np.percentile(df_age,[25,75])\nIQR= Q3-Q1\nlower_range= Q1-(1.5*IQR)\nupper_range=Q3+(1.5*IQR)\n\nprint(\"Lower Range : \",lower_range)      \nprint(\"Upper Range : \",upper_range)\ndf_lower_outliers=df[df.Age<lower_range]\ndf_upper_outliers=df[df.Age>upper_range]\n","3f33fa72":"#NO LOWER OUTLIERS\ndf_lower_outliers","88489d94":"#NO UPPER OUTLIERS\ndf_upper_outliers","1d443cb0":"plt.figure(figsize=(20,10))\nplt.text(55,-0.2,\"There is not outlier in age feature\",fontsize='20',fontweight='bold')\nsns.boxplot(data=df,x=\"Age\",palette='gnuplot')","bbc1e8c6":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,10))\nsns.histplot(data=df,x=np.log(df[\"Age\"]),palette='gnuplot',kde=True,ax=ax[0],binwidth=0.04)\nsns.histplot(data=df,x=np.log(df[\"Age\"]),palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\",binwidth=0.04)","02c09210":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,10))\nax[0].text(35,70000,\"Region_Code is\\nrandomly distributed\",fontweight='bold',fontsize=12)\nsns.histplot(data=df,x=\"Region_Code\",palette='gnuplot',kde=True,ax=ax[0],binwidth=1)\nax[1].text(35,70000,\"Region_Code is\\nrandomly distributed\\nwith hueness\",fontweight='bold',fontsize=12)\nsns.histplot(data=df,x=\"Region_Code\",palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\",binwidth=1)","10d6f7d3":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nax[0].text(300000,30000,\"Normally distributed with\\nlittle right skewed\",fontweight='bold',fontsize=12)\nsns.histplot(data=df,x=\"Annual_Premium\",palette='gnuplot',kde=True,ax=ax[0])\nax[1].text(300000,30000,\"Normally distributed with\\nlittle right skewed\\nwith hueness\",fontweight='bold',fontsize=12)\nsns.histplot(data=df,x=\"Annual_Premium\",palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\")","29100149":"plt.figure(figsize=(20,10))\nplt.text(250000,-0.2,\"2.7% data points are upper outliers in Annual_Premium feature\",fontsize=15,fontweight='bold')\nsns.boxplot(data=df,x=\"Annual_Premium\",palette='gnuplot')","9a3670cf":"#IQR (Inter quartile range)\ndf_prem=sorted(df['Annual_Premium'])\nQ1,Q3=np.percentile(df_prem,[25,75])\nIQR= Q3-Q1\nlower_range= Q1-(1.5*IQR)\nupper_range=Q3+(1.5*IQR)\n\nprint(\"Lower Range : \",lower_range)      \nprint(\"Upper Range : \",upper_range)\ndf_lower_outliers=df[df.Annual_Premium<lower_range]\ndf_upper_outliers=df[df.Annual_Premium>upper_range]\n","a9727679":"#There is not lower outliers\ndf_lower_outliers","8e1b32cc":"#There are 10320 people in data whose annual_premium is greater than 61892.5 i.e. 2.7%\ndf_upper_outliers","48258c6a":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,10))\nsns.histplot(data=df,x=\"Vintage\",palette='gnuplot',kde=True,ax=ax[0])\nsns.histplot(data=df,x=\"Vintage\",palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\")","f968e637":"f,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,10))\nax[0].text(40,100000,\"Randomly Distributed\",fontweight='bold',fontsize=15)\nsns.histplot(data=df,x=\"Policy_Sales_Channel\",palette='gnuplot',kde=True,ax=ax[0])\nax[1].text(40,100000,\"Randomly Distributed\\nwith hueness\",fontweight='bold',fontsize=15)\nsns.histplot(data=df,x=\"Policy_Sales_Channel\",palette='gnuplot',kde=True,ax=ax[1],hue=\"Response\")","e10119b9":"df[\"Gender\"]=df[\"Gender\"].map({\"Female\":\"0\",\"Male\":\"1\"}).astype('int')","eb2c87ad":"df1=df.copy()","45b70d5f":"df1=pd.get_dummies(df1,drop_first=True)\ndf1","da61b969":"df1=df1.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_1_Year\", \n                            \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_2_Year\"})\ndf1","1fa47d6a":"df1['Vehicle_Age_1_Year']=df1['Vehicle_Age_1_Year'].astype('int')\ndf1['Vehicle_Age_2_Year']=df1['Vehicle_Age_2_Year'].astype('int')\ndf1['Vehicle_Damage_Yes']=df1['Vehicle_Damage_Yes'].astype('int')\n","038b0091":"plt.figure(figsize=(20,10))\nsns.heatmap(df1.corr(),annot=True,cmap=\"Greens\")","668267ae":"sns.pairplot(data=df1,palette='gnuplot')","f45d9199":"from sklearn.model_selection import train_test_split , cross_val_score , RandomizedSearchCV,GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nfrom imblearn.over_sampling import SMOTE\nimport xgboost as xgb\nimport optuna\n","e97cb15d":"#SCALING CONTINUOUS FEATURES\n'''from sklearn.preprocessing import MinMaxScaler , StandardScaler\nss=StandardScaler()\ntrain[['Age']]=ss.fit_transform(train[['Age']])\ntrain[['Vintage']]=ss.fit_transform(train[['Vintage']])\ntrain[['Annual_Premium']] = ss.fit_transform(train[['Annual_Premium']])'''\n","d6a4dece":"Y=df1[\"Response\"]\nX=df1.drop([\"Response\"],axis=1)","6540c7d6":"df2=df1.copy()\ndf2","d30643a6":"from imblearn.over_sampling import SMOTE","40f3e48b":"#SPLITTING BEFORE SAMPLING\nx_train_sam,x_test_sam,y_train_sam,y_test_sam=train_test_split(X,Y,test_size=0.2,random_state=42)","34e89b16":"y_train_sam.value_counts()","5555ce6d":"y_test_sam.value_counts()","97f79385":"#SAMPLING OF ONLY TRAIN DATA TO AVOID DATA LEAKAGE\nsm=SMOTE()\nx_train_sampling,y_train_sampling=sm.fit_resample(x_train_sam,y_train_sam)","377f661f":"y_train_sampling.value_counts()","e6100fbc":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_loguniform('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    return cross_val_score(clf, x_train_sampling, y_train_sampling, \n           n_jobs=-1, cv=5,scoring='f1').mean()","1080fe72":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=25)","e208c04c":"trial=study.best_trial\nprint(trial.values)\nprint(trial.params)","92ae9602":"clf=RandomForestClassifier(n_estimators=199,max_depth=40,class_weight='balanced')\nclf.fit(x_train_sampling,y_train_sampling)","65823dda":"pred=clf.predict(x_test_sam)\nprint(accuracy_score(y_test_sam,pred))","11d1937d":"print(classification_report(y_test_sam,pred))","14ee2f78":"print(\"F1 Score with oversampling : \", f1_score(y_test_sam,pred,average='micro'))","b0efc15f":"plt.figure(figsize=(20,10))\ny_score=clf.predict_proba(x_test_sam)[:,1]\n\nfpr,tpr,_=roc_curve(y_test_sam,y_score)\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\n","c6acdb97":"import lightgbm as lgb","2330566d":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 300)\n    max_depth = int(trial.suggest_loguniform('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,1)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,1)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample)\n    \n    return cross_val_score(clf, x_train_sampling, y_train_sampling, \n           n_jobs=-1, cv=5,scoring='f1').mean()\n","88eeab63":"study_lgbm= optuna.create_study(direction='maximize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=25)","8cb27930":"trial_lgbm= study_lgbm.best_trial\nprint(trial_lgbm.value)\nprint(trial_lgbm.params)","178e37d8":"model_lgbm=lgb.LGBMClassifier(n_estimators=83, max_depth=25, learning_rate=0.17179233498193255, \n                              colsample_bytree=0.6038190843157162, num_leaves=254, reg_alpha=0.838971567767778, \n                              reg_lambda=0.2832341981958901, \n                              min_split_gain=0.3099589058884009,subsample=0.5504932545076727,class_weight='balanced')","7ae28ee4":"model_lgbm.fit(x_train_sampling,y_train_sampling)","9b48d41a":"pred_lgbm=model_lgbm.predict(x_test_sam)\nprint(accuracy_score(y_test_sam,pred_lgbm))","569c45a3":"print(classification_report(y_test_sam,pred_lgbm))","ccc9541c":"print(\"F1 Score : \", f1_score(y_test_sam,pred_lgbm,average='micro'))","6c89693d":"plt.figure(figsize=(20,10))\ny_score2=model_lgbm.predict_proba(x_test_sam)[:,1]\n\nfpr2,tpr2,_=roc_curve(y_test_sam,y_score2)\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr2,tpr2)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr2,tpr2))\n","5fc87d34":"roc_auc_score(y_test_sam,y_score2)","9903a94f":"**CATEGORICAL VALUES**\n* **Gender,Driving_License,Previously_Insured,Vehicle_Age,Vehicle_Damage**","da166bab":"**VINTAGE**","57ff3753":"**POLICY SALES CHANNEL**","7bac5550":"* **Question here is should we remove these ouliers in Annual_Premium data , but I think if a person is paying money more than Rs61892 annually , may he\/she is a rich person who is capable of paying that much more money than others**\n* **10392 people are outliers if we remove them we can loss data from the table**\n* **So the conclusion is we won't change anything is annual_premium data**","7dc4dddb":"# VEHICLE INSURANCE PREDICTION","0a7b958b":"# USING OVERSAMPLING TECHNIQUE(SMOTE)\n","b72140ae":"**LGBM CLASSIFIER**","c87b613d":"**REGION CODE**\n* **This Column is randomly distributed , there is not any significant observation we can get from this feature**\n* **In my opinion we should not work on this feature further**","694e9cef":"**Let's See if how many outliers are present in age?**","72fd9905":"# **VISUALIZATION AND ANALYSIS**","c1fa59ba":"**CONTINUOUS VALUES**\n* **Age,Region_Code,Annual_Premium,Policy_Sales_Channel,Vintage**","9c5ceeb2":"**Let's plot log distribution of age column to see if we can reduce the skewness**\n* **Log Distribution doesn't make any specific change in the distribution so we will go ahead without doing any changes in Age column**","cee62602":"**RANDOM FOREST CLASSIFIER**","271d237d":"**AGE COLUMN**","794a3cbd":"**Checking if data is imbalanced or not**\n* **Target value is highly imbalanced i.e. 87.7% are -ve responses and 12.3% are +ve responses**","6de3a905":"**ANNUAL PREMIUM**","a780ef32":"**UNIVARIATE ANALYSIS**","812a6f18":"**TARGET VARIABLE**","fe8f925b":"**CONCLUSIONS FROM CATEGOICAL FEATURES**\n\n* **13.8% males and 10.4% females responded +ve**\n* **People who don't have license are not responding but with driving license only 12.3% are responding**\n* **Person who is not previously insured are responding i.e. 22.5% , but who is already insured are not responding**\n* **People whose vehicle age is greater than 1 year are reasponding more frequently**\n* **23.8% of people whose Vehicle is Damaged are responding +ve**","90e81db4":"**BIVARIATE ANALYSIS**","08dcd6d4":"**Pairplot**","272babff":"**This Column is uniformly distributed we can't do nothing much to this column**","b50e5c36":"**Checking for null values in training data**\n* **There is no null value in any column of the data**","d5375bf6":"**Looking for correlation between any two features**\n\n*  **As we can there is no significant relation between any two features so we will go ahead with all features we have**","c7db9001":"**IMPORTING LIBRARIES**","894b25c6":"# **MODEL AND PREDICTION(WITHOUT OVERSAMPLING)**"}}