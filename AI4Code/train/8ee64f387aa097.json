{"cell_type":{"5273907b":"code","04ad71d8":"code","327f5a1e":"code","ecba063d":"code","f6618a65":"code","7d01b53c":"code","a900b517":"code","d06b216e":"code","8ab6963f":"code","d39c89ab":"code","3b4e5fb4":"code","8d13ab9a":"code","68c07614":"code","11d33b1d":"code","8823d435":"code","382e451b":"code","b84717bb":"code","fdb6b8e4":"code","9b0ca55f":"code","54d4304f":"code","bfce63f8":"code","20df1db3":"code","c6986356":"code","da18bcca":"code","958d9a67":"markdown","2f06e892":"markdown","eb787621":"markdown","6980c00e":"markdown","f6af4734":"markdown","c25fe52c":"markdown","52b47cf2":"markdown","01641f7c":"markdown","afaeb790":"markdown","0c19ab43":"markdown","803d2902":"markdown","6cccab76":"markdown","53ab5bec":"markdown","b8ef4e40":"markdown"},"source":{"5273907b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04ad71d8":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","327f5a1e":"df = pd.read_csv('..\/input\/cancer\/Data.csv')\ndf.head()","ecba063d":"df.drop(columns=['Sample code number'],inplace=True)","f6618a65":"df.head()","7d01b53c":"X = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values","a900b517":"print(X[:10])\nprint(y[:10])","d06b216e":"y = y.reshape(len(y),1)\ny[:10]","8ab6963f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","d39c89ab":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3b4e5fb4":"classifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","8d13ab9a":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","68c07614":"classifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)","11d33b1d":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","8823d435":"classifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)","382e451b":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","b84717bb":"classifier = GaussianNB()\nclassifier.fit(X_train, y_train)","fdb6b8e4":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","9b0ca55f":"classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)","54d4304f":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","bfce63f8":"classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","20df1db3":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c6986356":"classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","da18bcca":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","958d9a67":"### 95%\nBest till now","2f06e892":"# Kernel SVM","eb787621":"# Logisitic Regression","6980c00e":"# Naive Bayes","f6af4734":"### Decision Tree has the best accuracy of ~96%","c25fe52c":"### 94.7%","52b47cf2":"### 94.1%","01641f7c":"### 94.1%","afaeb790":"### 94.7%","0c19ab43":"# Decision Tree","803d2902":"# Support Vector Machines (SVM)","6cccab76":"# Random Forest","53ab5bec":"### 94.7%","b8ef4e40":"# K Nearest Neighbours (KNN)"}}