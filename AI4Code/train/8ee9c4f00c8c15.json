{"cell_type":{"2eb9571d":"code","5f0a7ac6":"markdown"},"source":{"2eb9571d":"from random import seed\nfrom random import randrange\nfrom csv import reader\nfrom math import sqrt\n\n# Load a CSV file\ndef load_csv(filename):\n\tdataset = list()\n\twith open(filename, 'r') as file:\n\t\tcsv_reader = reader(file)\n\t\theadings = next(csv_reader) \n\t\tfor row in csv_reader:\n\t\t\tif not row:\n\t\t\t\tcontinue\n\t\t\tdataset.append(row)\n\treturn dataset\n\n# Convert string column to float\ndef str_column_to_float(dataset, column):\n\tfor row in dataset:\n\t\trow[column] = float(row[column].strip())\n\n# Find the min and max values for each column\ndef dataset_minmax(dataset):\n\tminmax = list()\n\tfor i in range(len(dataset[0])):\n\t\tcol_values = [row[i] for row in dataset]\n\t\tvalue_min = min(col_values)\n\t\tvalue_max = max(col_values)\n\t\tminmax.append([value_min, value_max])\n\treturn minmax\n\n# Rescale dataset columns to the range 0-1\ndef normalize_dataset(dataset, minmax):\n\tfor row in dataset:\n\t\tfor i in range(len(row)):\n\t\t\trow[i] = (row[i] - minmax[i][0]) \/ (minmax[i][1] - minmax[i][0])\n\n# Split a dataset into k folds\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) \/ n_folds)\n\tfor i in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split\n\n# Calculate root mean squared error\ndef rmse_metric(actual, predicted):\n\tsum_error = 0.0\n\tfor i in range(len(actual)):\n\t\tprediction_error = predicted[i] - actual[i]\n\t\tsum_error += (prediction_error ** 2)\n\tmean_error = sum_error \/ float(len(actual))\n\treturn sqrt(mean_error)\n\n# Evaluate an algorithm using a cross validation split\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\trmse = rmse_metric(actual, predicted)\n\t\tscores.append(rmse)\n\treturn scores\n\n# Make a prediction with coefficients\ndef predict(row, coefficients):\n\tyhat = coefficients[0]\n\tfor i in range(len(row)-1):\n\t\tyhat += coefficients[i + 1] * row[i]\n\treturn yhat\n\n# Estimate linear regression coefficients using stochastic gradient descent\ndef coefficients_sgd(train, l_rate, n_epoch):\n\tcoef = [0.0 for i in range(len(train[0]))]\n\tfor epoch in range(n_epoch):\n\t\tfor row in train:\n\t\t\tyhat = predict(row, coef)\n\t\t\terror = yhat - row[-1]\n\t\t\tcoef[0] = coef[0] - l_rate * error\n\t\t\tfor i in range(len(row)-1):\n\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n\t\t\t# print(l_rate, n_epoch, error)\n\treturn coef\n\n# Linear Regression Algorithm With Stochastic Gradient Descent\ndef linear_regression_sgd(train, test, l_rate, n_epoch):\n\tpredictions = list()\n\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n\tfor row in test:\n\t\tyhat = predict(row, coef)\n\t\tpredictions.append(yhat)\n\treturn(predictions)\n\n# Linear Regression on wine quality dataset\nseed(1)\n# load and prepare data\nfilename = '..\/input\/white-wine-quality\/winequallity-white.csv'\ndataset = load_csv(filename)\nfor i in range(len(dataset[0])):\n\tstr_column_to_float(dataset, i)\n# normalize\nminmax = dataset_minmax(dataset)\nnormalize_dataset(dataset, minmax)\n# evaluate algorithm\nn_folds = 5\nl_rate = 0.01\nn_epoch = 50\nscores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\nprint('Scores: %s' % scores)\nprint('Mean RMSE: %.3f' % (sum(scores)\/float(len(scores))))","5f0a7ac6":"# White Whine Quality SGD Scratch"}}