{"cell_type":{"47195253":"code","6c32a785":"code","096afa87":"code","853f4fcf":"code","0ffd51d7":"code","64f8a2c7":"code","1a44b91a":"code","56995d7e":"code","c99c3101":"code","9850fbc2":"code","9a1edabb":"code","2a1f37d8":"code","8e33a4c2":"code","e1a6429d":"code","d243248e":"code","5c6aed95":"code","cbcf84db":"code","e9a683f8":"code","d9b778dd":"code","3c2ba4bc":"code","b4d34f9b":"code","6111b092":"code","1c3c2ece":"code","610faf03":"code","a4687b6b":"code","046965b8":"code","f0cb7c71":"code","c0ca6785":"code","a7647775":"code","bd00feee":"code","9220a2d3":"code","f317637b":"code","16456a91":"code","0e0718fb":"code","1cd0ef92":"markdown","28840d6f":"markdown","e9485db7":"markdown","14b8afaa":"markdown","adc1e073":"markdown","5782029d":"markdown","b660de51":"markdown","a635fff0":"markdown","d58cbbfa":"markdown","4658377e":"markdown","974a30f7":"markdown","017fa964":"markdown","d2fb46e4":"markdown","1c92ee25":"markdown","6683ad88":"markdown","7cb28348":"markdown","ba30f6ed":"markdown","2ccf5b9e":"markdown","ceddecc4":"markdown","b6e694b5":"markdown","82a2a161":"markdown","82adf3cd":"markdown","b353a4a2":"markdown","2330db5c":"markdown","aa0bbe63":"markdown","db23c591":"markdown","0561e4c9":"markdown","847129f1":"markdown","6c063ba4":"markdown","21ac70ca":"markdown","8548c22a":"markdown","b0339fd1":"markdown","46bcded5":"markdown"},"source":{"47195253":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport copy\nimport datetime \nplt.style.use('fivethirtyeight')\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nimport matplotlib\nmatplotlib.rcParams['axes.labelsize'] = 10\nmatplotlib.rcParams['xtick.labelsize'] = 10\nmatplotlib.rcParams['ytick.labelsize'] = 10\nmatplotlib.rcParams['text.color'] = 'k'\nmatplotlib.rcParams['text.color'] = 'k'\nmatplotlib.rcParams['lines.linewidth'] = 2\n","6c32a785":"Image('\/kaggle\/input\/images\/map-overview-electric.jpg')","096afa87":"df = pd.read_parquet('..\/input\/hourly-energy-consumption\/est_hourly.paruqet')\n","853f4fcf":"df.head()","0ffd51d7":"fig,ax = plt.subplots(figsize= (12,12))\nsns.heatmap(df.isnull(),ax = ax)\nax.set_title('NaN Distribution Through Data')","64f8a2c7":"cols = df.columns\n\nfig,ax  = plt.subplots(figsize = (12,12))\n\ndf.reset_index().resample('W', on = 'Datetime').mean().plot(ax=ax)\nax.set_ylabel('Load (MW)')\n    ","1a44b91a":"PJM = df[['PJME']].dropna()\nPJM.index = pd.to_datetime(PJM.index)\nPJM.head()","56995d7e":"PJM['dow'] = PJM.index.dayofweek\nPJM['doy'] = PJM.index.dayofyear\nPJM['year'] = PJM.index.year\nPJM['month'] = PJM.index.month\nPJM['quarter'] = PJM.index.quarter\nPJM['hour'] = PJM.index.hour\nPJM['woy'] = PJM.index.weekofyear\nPJM['dom'] = PJM.index.day # Day of Month\nPJM['date'] = PJM.index.date \ndowdict = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\nPJM['weekday'] = PJM['dow'].map(dowdict)","c99c3101":"PJM.head()","9850fbc2":"PJM.pivot_table(index='hour', \n                     columns='weekday', \n                     values='PJME',\n                     aggfunc='mean').plot(figsize=(15,4),\n                     title='PJM East - Daily Trends')","9a1edabb":"PJM.pivot_table(index='month', \n                     columns='year', \n                     values='PJME',\n                     aggfunc='mean').plot(figsize=(15,4),\n                     title='PJM East - Monthly Trends')","2a1f37d8":"PJMDaily = PJM.reset_index().resample('D', on='Datetime').mean()['PJME']\n","8e33a4c2":"fig, ax = plt.subplots(figsize= (10,8))\nPJMDaily.plot(ax=ax, label = 'Raw Data')\nPJMDaily.rolling(366).mean().plot(ax= ax,label = 'Yearly Rolling Mean')\nPJMDaily.rolling(366).std().plot(ax= ax,label = 'Yearly Rolling Std')\nax.set_ylabel('Load (MW)')\nax.set_xlabel('Time')\nax.set_title('Yearly Moving Average')\nax.legend()","e1a6429d":"fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(18,13))\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomp = seasonal_decompose(PJMDaily, period = 366) # Should repeat yearly, and we will look at trends shown over the years\nax1.plot(decomp.observed)\nax1.set_title('Overall Data')\nax2.plot(decomp.trend)\nax2.set_title('Yearly Overall Trend')\nax3.plot(decomp.seasonal)\nax3.set_title('Within Year Seasonal Trend')\nax4.plot(decomp.resid)\nax4.set_title('Residual')\n","d243248e":"order =1\ncoef = np.polyfit(np.arange(len(PJMDaily)),PJMDaily,order) \nlinear_model = np.poly1d(coef)\ntrend = pd.Series(data = linear_model(np.arange(len(PJMDaily))), index = PJMDaily.index)\ndetrended_series = decomp.observed-trend\n\nfig,(ax,ax1) = plt.subplots(1,2,figsize=(15,7))\nax.plot(decomp.observed, label = 'Observed Data')\nax.plot(trend, label = 'Overall Model Trend')\nax.set_title('Fitting Overall Trend Line to Observed Data')\nax.legend()\nax1.plot(detrended_series)\nax1.set_title('De-trended time series')","5c6aed95":"seasonal = detrended_series.groupby(by = detrended_series.index.isocalendar().week).mean() \nplt.plot(seasonal)\nplt.title('Seasonal Trend')\nseasonal.head()","cbcf84db":"seasonal_component = copy.deepcopy(PJMDaily)\nfor i in seasonal.index:\n    seasonal_component[seasonal_component.index.isocalendar().week == i] = seasonal[i]\nplt.plot(seasonal_component)\nplt.title('Seasonal Trend Replicated Over Dataset')","e9a683f8":"residuals = PJMDaily - seasonal_component\nplt.plot(residuals)\nplt.title('Residual Component')","d9b778dd":"PJMWeekly = PJM.reset_index().resample('W', on='Datetime').mean()['PJME']\nPJMWeekly.plot(label = 'Weekly Data')\nplt.axhline(PJMWeekly.mean(),color = 'r',alpha=0.2,linestyle = '--', label = 'mean')\nplt.legend()\n","3c2ba4bc":"decomp = seasonal_decompose(PJMWeekly, period = 52)\ndetrended = PJMWeekly - decomp.seasonal","b4d34f9b":"fig,ax = plt.subplots(figsize = (8,5))\n(decomp.seasonal+decomp.trend.mean()).plot(ax=ax,label = 'Seasonal Trend')\nPJMWeekly.plot(ax = ax,label = 'Raw Data')\nax.legend()\n","6111b092":"detrended.plot()","1c3c2ece":"detrended.hist(bins = 20)","610faf03":"x1,x2,x3,x4 = np.array_split(detrended,4)\nprint('x1: Mean = {}, Std = {}'.format(x1.mean(), x1.std()))\nprint('x2: Mean = {}, Std = {}'.format(x2.mean(), x2.std()))\nprint('x3: Mean = {}, Std = {}'.format(x3.mean(), x3.std()))\nprint('x4: Mean = {}, Std = {}'.format(x4.mean(), x4.std()))\nfig,ax = plt.subplots(2,2, figsize = (8,8))\naxs = ax.ravel()\nx1.hist(bins = 20,ax = axs[0])\nx2.hist(bins = 20,ax = axs[1])\nx3.hist(bins = 20,ax = axs[2])\nx4.hist(bins = 20,ax = axs[3])\nx = [x1,x2,x3,x4]","a4687b6b":"from statsmodels.stats.weightstats import ttest_ind\nfrom itertools import combinations\ncomb = combinations([0,1,2,3], 2)\nfor i,j in comb:\n    print('p-value (x_{},x_{}) = {}'.format(i+1,j+1,ttest_ind(x[i], x[j], alternative='two-sided')[1]))","046965b8":"fig, ax = plt.subplots(figsize = (6,4))\ndef acf_plot(num_lags = int(40)):\n    ac_vals = sm.tsa.pacf(detrended)\n    ax.bar(range(num_lags),ac_vals[:num_lags])\n\nacf_plot()\nax.set_ylabel('Correlation')\nax.set_xlabel('Number of Lags')","f0cb7c71":"def adfuller_test(data):\n    result = adfuller(data)\n    print('ADF Statistic = {}'.format(result[0]))\n    print('p-value = {}'.format(result[1]))\n    print('Critical Values = :')\n    for key,val in result[4].items():\n        print(key,val)\n    if result[0]<result[4]['5%']:\n        print('Reject Null Hypothesis - Time Series Is Stationary')\n    else:\n        print('Failed to Reject Null Hypothesis - Time Series is Non-Statioanry')\nprint('---- Detrended Data ----')\nadfuller_test(detrended)","c0ca6785":"from pandas.plotting import autocorrelation_plot\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfig, axs = plt.subplots(1,2, figsize = (10,4))\n\n\nautocorrelation_plot(detrended, ax = axs[0])\nplot_pacf(detrended, ax=axs[1])\naxs[0].set_xlim((0,40))\naxs[0].set_title('ACF Plot')","a7647775":"import itertools\np = range(2)\nq = range(4,10)\nd=0\nseasonal_pdq_comb = [(1,0,0,52)]\nresult_mat = np.zeros((len(p),len(q)))\nfor i, p_val in enumerate(p):\n    for j, q_val in enumerate(q):\n        mod = sm.tsa.statespace.SARIMAX(PJMWeekly,\n                                        order=(p_val,d,q_val),\n                                        seasonal_param_order=seasonal_param,\n                                        enforce_stationarity=False,\n                                        enforce_invertibility=False) #determines the AIC value of the model**\n        results = mod.fit()\n        print('SARIMA{}x{}12 - AIC:{}'.format((p_val,d,q_val), seasonal_param, results.aic))\n        result_mat[i,j]=results.aic\n        \n","bd00feee":"fig,ax = plt.subplots(figsize = (8,6))\nsns.heatmap(ax = ax,data = result_mat)\nax.set_xticklabels(q)\nax.set_yticklabels(p)","9220a2d3":"mod = sm.tsa.statespace.SARIMAX(PJMWeekly,\n                                order=(1, 0, 6),\n                                seasonal_param_order=(1, 0, 0, 52),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False) #model defintion\nresults = mod.fit() #model fitting\nprint(results.summary().tables[1]) # displaying the result \n","f317637b":"_ = results.plot_diagnostics(figsize=(16, 8))","16456a91":"pred = results.get_prediction(start=pd.to_datetime(str(PJMWeekly.index.min().date())), dynamic=False)","0e0718fb":"fig,ax = plt.subplots(figsize = (8,8))\npred.predicted_mean.plot(ax = ax, label = 'Predicted Values')\nPJMWeekly.plot(ax=ax, label = 'Observed Values')\nax.set_ylabel('Hourly Average Energy Consumption (MWh)')\nmape(PJMWeekly,pred.predicted_mean)","1cd0ef92":"**Testing Stationary Data with ACF Plot:**\n\n\nThe autocorrelation plot shows how correlated a time series is with previous versions of itself, the acf for a stationary plot should drop of very quickly (right), while for a non-stationary plot this should tail away (left) slowly, this is because non-stationary plots are more likely to exhibit dependence \n![](https:\/\/miro.medium.com\/max\/840\/0*lkyqZegdoKE9dD-9.png)","28840d6f":"For our modelling analysis we will determine a baseline error if only the seasonal variation is used to model the plot","e9485db7":"It is interesting that there is discrepancy between results, qualitative analysis would lead one to expect that there is a trend in the energy consumption from 2003 to 2018, however this is not confirmed through the adfuller test","14b8afaa":"We can see that the residuals of this plot are normally distributed, in line with the expectation of regression models, the correlogram shows that, after fitting this model the residuals have very little correlation which is what we would like. We can now compare our new model with seasonal baseline model MAPE of 5.2%","adc1e073":"From these plots we can choose q and p for the ARIMA model by determining the point after which the acf and pacf drop within the 95% CI bounds. In this case we want q to be quite high (>5) and p to be fairly low (~2), we will vary these slightly and choose the best SARIMA model through the model's ability to manimize the AIC","5782029d":"# Automatic Decomposition of Energy Consumption Data","b660de51":"We will then remove the seasonality within the data and test whether the detrended data is stationary","a635fff0":"First we will determine if there is a moving average in the data set over the years","d58cbbfa":"Various methods of determining wether a time series is stationary exists, these include:\n* Visual Analysis \n* Analysis of variance and mean of data-set over time\n* Analysis of ACF plots\n* Unit Root Tests (Dicky Fuller Test)\n* and more...","4658377e":"Since the overall trend is almost negligible, reducing it from the model has very little effect on the trend.\n\nThe next step is to reduce the seasonal component from the model using the 'de-trended' model. In this case we will let the seasonal component be gauged by weakly averages","974a30f7":"We can see that for all of the zones, no data exists before 2002, but PJM load only has values *before* 2002. Some zones show gaps in the data which is odd","017fa964":"Visualize NaN values","d2fb46e4":"Based on the analysis of the previous tests we can say that, after accounting for the seasonal component in energy consumption using tsa model, there is no statistically significant growth in energy consumption over time in the PJM network","1c92ee25":"Saturday and Sunday are the lowest, Monday Tuesday and Wednesday the highest. The hours between 5-8 have a huge ramp effect putting a lot of stress on the grid","6683ad88":"As the histogram roughly follows a guassian, we can look at the mean and variance of each section of the detrended data and look at how much they overlap, as it can be seen here that these guassians overlap signifcantly. We can do an independent t-test to determine whether these trendscome from the same normal distribution","7cb28348":"Now we do manual decomposition:\n\nFor decomposition, thesse are the following steps that must be undertaken:\n* First model the overalltrend and reduce the model by subtracting the overall trend\n* Next look at seasonal components and reduce the model by subtracting seasonal component\n* Finally look at the trend in residuals: Assure that periodic trends and overall trends have been eliminated\n\nIn this case we will just fit a linear model to the overall trend \n\n","ba30f6ed":"# Testing Whether Detrended Seasonal Data is Stationary ","2ccf5b9e":"As can be seen, the data doesn't drop off quite as much as expected, this could be becuase the complete seasonality of the process hasnt been captured. The energy consumption in a given week shows reasonably high dependence with the energy consumption of the previous week","ceddecc4":"# SARIMA Modelling\nAfter classifying the time series as stationary after seasonal etrending, we can model the time series and analyse our model's performance using the SARIMA model. The SARIMA model is an extension of the ARIMA model to take into account seasonal variability. The model not only requires the (p,d,q) required by ARIMA but also requires another tuple (P,D,Q,s) to describe the seasonal trend","b6e694b5":"After removing the seasonal component, how stationary is the remaining trend? While visual analysis shows that there isn't a significant trend remaining, what better tests can we use to determine if the remaining data is stationary?","82a2a161":"# Exploratory Data Analysis","82adf3cd":"We should be left by noise at this point, indicating that seasonal and overall trends have been removed from the dataset. We can see that there still remains some periodic variability, so work can still be done in improving the model","b353a4a2":"For modelling, take the last 5 years in the dataset","2330db5c":"![PJM.png](attachment:PJM.png)\n","aa0bbe63":"It looks like there is seasonal variation ","db23c591":"The p-values are extremely low in many cases, suggesting that the data do not come fro mthe same dstribution (perhaps this is no the best test?","0561e4c9":"# **Testing Stationary Data with Dicky-Fuller test**\n\nThe Dicky-Fuller test gives a null hypothesis that the time-series is non-stationary in nature and an alternate hypothesis that the time-series is stationary in nature.\nFor a simple AR1 model, the regression can be re-formulated to:\n\n\n$$\\Delta y_{t+1} = c + (p - 1)y_{t} + \\epsilon_{t}$$\n\nThis reformulaiton allows the test to be turned into a classic null hypothesis test, which essentially tests the fit of the above regression model, it finds the t-statistic on the value of $p-1 = \\delta$ which is compared to a specialized Dicky-Fuller table. If $\\delta = 0$ then the null hypothesis holds, that the time series is non-stationary, however if $\\delta > 0$ then the null hypothesis can be rejected, the series is stationary","847129f1":"**Testing Stationary Data with Variance and Mean**\n\n\nThis is more useful if the data has a guassian shape!","6c063ba4":"**(p,d,q) selection**\n\nThese values are important for the base ARIMA model:\n* the p specifies the number of previous terms required in the Auto-Regressive part of the model and is chosen from analysis of the pacf plot\n* the d is based on the order of the differencing (in this case 0)\n* the q describes the Moving Average part of the model and is selected through analysis of te acf plot\n\nA fantastic explanation of the selection [here](http:\/\/people.duke.edu\/~rnau\/411arim3.htm)\n","21ac70ca":"# Manual Decomposition of Energy Consumption Data","8548c22a":"In this project we are only analyzing the PHM Hourly Energy Consumption Data. The PJM Interconnection coordinates the movement of electricity through all or parts of Delaware, Illinois, Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania, Tennessee, Virginia, West Virginia and the District of Columbia","b0339fd1":"The  moving average looks fairly stationary.\n\nWe will first decompose the model using statsmodel.tsa model","46bcded5":"Seasonal Decomposition, we look at daily data"}}