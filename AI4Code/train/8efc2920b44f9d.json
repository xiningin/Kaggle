{"cell_type":{"3f94380f":"code","267e204a":"code","bab13edc":"code","99fd1cd4":"code","149b0b99":"code","2dcc3371":"code","a4b54df3":"code","4099fdff":"code","4af47b92":"code","8fc92a99":"code","9a969559":"code","09fc366e":"code","aee5768b":"code","18273f98":"code","93479b5d":"code","2bf230ab":"code","556afc3e":"code","e58bdc80":"code","07365408":"markdown","a822b665":"markdown","603087d5":"markdown","583578f9":"markdown","2b439ccd":"markdown"},"source":{"3f94380f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","267e204a":"from sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score","bab13edc":"data = pd.read_csv(\"..\/input\/bmidataset\/bmi.csv\")\ndf = data\ndf.head()","99fd1cd4":"df[\"Index\"].hist()\nplt.show()","149b0b99":"plt.figure(figsize=(8, 8))\nsns.barplot(x=df[\"Gender\"], y=df[\"Index\"])\nplt.show()","2dcc3371":"plt.figure(figsize=(20, 10))\nsns.barplot(x=df[\"Height\"], y=df[\"Index\"])\nplt.show()","a4b54df3":"plt.figure(figsize=(20, 10))\nsns.barplot(y=df[\"Weight\"], x=df[\"Index\"])\nplt.show()","4099fdff":"from sklearn.preprocessing import LabelEncoder","4af47b92":"le = LabelEncoder()\ndf[\"gender\"] = le.fit_transform(df[\"Gender\"])","8fc92a99":"df.describe()","9a969559":"df[\"Height\"] = df[\"Height\"]\/100\ndf[\"Weight\"] = df[\"Weight\"]\/100","09fc366e":"X = df.drop([\"Index\", \"Gender\"], axis=\"columns\")\ny = df[\"Index\"]","aee5768b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)","18273f98":"from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","93479b5d":"tree = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nbag = BaggingClassifier()\nneighbours = KNeighborsClassifier(n_neighbors=5)\ngnb = GaussianNB()","2bf230ab":"models = [tree, rf, bag, neighbours, gnb]","556afc3e":"for model in models:\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    print(str(model), \" : \", score)","e58bdc80":"rf = KNeighborsClassifier(n_neighbors=5)\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","07365408":"# Model building","a822b665":"So we got KNeighborsClassifier as best model since it scored well ","603087d5":"#  Exploratory Data Analysis","583578f9":"*Feel free to comment or upvote*","2b439ccd":"# Preprocessing "}}