{"cell_type":{"3ec94e9a":"code","626f34aa":"code","6c5299c5":"code","b504e259":"code","7b664308":"code","9883e064":"code","03f2d2a1":"code","0eca2f0a":"code","90666b43":"code","509713c2":"code","d84d8ec7":"code","0979a651":"code","bde83fbe":"code","c742dedd":"code","2a85f8da":"code","4900a9bd":"code","a7803498":"code","96ff5733":"code","0ea8a19d":"code","1d21ddbd":"code","643fb4a5":"code","56e82e18":"code","4e16877d":"code","fc297a21":"code","964c1057":"code","e6ce5211":"code","4dbfb313":"code","3fdd6c45":"code","41b9eeab":"code","a3651fc8":"markdown"},"source":{"3ec94e9a":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=Ewert&effect=3d';      \n    <\/style><h1 class='font-effect-3d' \n    style='font-family:Ewert; color:#ff6633;'>\n    %s<\/h1>\"\"\"%str))","626f34aa":"dhtml('Code Modules, Functions, & Classes')","6c5299c5":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","b504e259":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","7b664308":"@register_line_magic\ndef display_examples(n):\n    if n=='1': data_loader=train_loader\n    if n=='2': data_loader=train_loader2\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size),\n                      cmap=pl.cm.bone)\n        break","9883e064":"dhtml('Data')","03f2d2a1":"random_seed=12; batch_size=128; img_size=28\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor()])\ntrain=tmnist(root='data',train=True,\n             download=True,transform=trans)\ntest=tmnist(root='data',train=False, \n            transform=trans)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","0eca2f0a":"%display_examples 1","90666b43":"fpath='..\/input\/classification-of-handwritten-letters\/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=1-np.array(f[keys[1]],dtype='float32')\/255\nx=timage.resize(x,[img_size,img_size])\nx=(np.dot(x.numpy(),[.299,.587,.114]))\\\n.reshape(-1,1,img_size,img_size)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=y.shape[0]; n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]\nrandom_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=False,\n                 batch_size=batch_size2)","509713c2":"%display_examples 2","d84d8ec7":"dhtml('Convolutional Variational <br\/>Autoencoder')","0979a651":"class ConvVarAE(tnn.Module):\n    def __init__(self,num_features,num_latent):\n        super(ConvVarAE,self).__init__()\n        # encoder\n        self.conv_en1=tnn\\\n        .Conv2d(in_channels=1,out_channels=16,\n                kernel_size=(6,6),stride=(2,2),\n                padding=0)\n        self.conv_en2=tnn\\\n        .Conv2d(in_channels=16,out_channels=32,\n                kernel_size=(4,4),stride=(2,2),\n                padding=0)                        \n        self.conv_en3=tnn\\\n        .Conv2d(in_channels=32,out_channels=64,\n                kernel_size=(2,2),stride=(2,2),\n                padding=0)                           \n        self.z_mean=tnn.Linear(64*2*2,num_latent)\n        self.z_log_var=tnn.Linear(64*2*2,num_latent)\n        # decoder\n        self.linear_de1=tnn.Linear(num_latent,64*2*2)             \n        self.deconv_de1=tnn\\\n        .ConvTranspose2d(in_channels=64,out_channels=32,\n                         kernel_size=(2,2),stride=(2,2),\n                         padding=0)                         \n        self.deconv_de2=tnn\\\n        .ConvTranspose2d(in_channels=32,out_channels=16,\n                         kernel_size=(4,4),stride=(3,3),\n                         padding=1)       \n        self.deconv_de3=tnn\\\n        .ConvTranspose2d(in_channels=16,out_channels=1,\n                         kernel_size=(6,6),stride=(3,3),\n                         padding=4)\n    def reparameterize(self,z_mu,z_log_var):\n        eps=torch.randn(z_mu.size(0),z_mu.size(1)).to(dev)\n        return z_mu+eps*torch.exp(z_log_var\/2.)       \n    def encoder(self,features):\n        x=self.conv_en1(features); x=tnnf.leaky_relu(x)       \n        x=self.conv_en2(x); x=tnnf.leaky_relu(x)\n        x=self.conv_en3(x); x=tnnf.leaky_relu(x)      \n        z_mean=self.z_mean(x.view(-1,64*2*2))\n        z_log_var=self.z_log_var(x.view(-1,64*2*2))\n        encoded=self.reparameterize(z_mean,z_log_var)  \n        return z_mean,z_log_var,encoded  \n    def decoder(self,encoded):\n        x=self.linear_de1(encoded)\n        x=x.view(-1,64,2,2)     \n        x=self.deconv_de1(x); x=tnnf.leaky_relu(x)       \n        x=self.deconv_de2(x); x=tnnf.leaky_relu(x)      \n        x=self.deconv_de3(x); x=tnnf.leaky_relu(x)\n        decoded=torch.sigmoid(x)\n        return decoded\n    def forward(self,features):\n        z_mean,z_log_var,encoded=self.encoder(features)\n        decoded=self.decoder(encoded)\n        return z_mean,z_log_var,encoded,decoded","bde83fbe":"dhtml('Training')","c742dedd":"torch.manual_seed(random_seed)\nlearning_rate=.005; num_latent=15\nmodel=ConvVarAE(num_features=img_size**2,\n                num_latent=num_latent)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","2a85f8da":"epochs=30\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader):\n        features=features.to(dev)\n        z_mean,z_log_var,encoded,decoded=model(features)\n        kl_divergence=(.5*(z_mean**2+torch.exp(z_log_var)-\n                           z_log_var-1)).sum()\n        pixelwise_bce=tnnf\\\n        .binary_cross_entropy(decoded,features,reduction='sum')\n        cost=kl_divergence+pixelwise_bce\n        optimizer.zero_grad()\n        cost.backward(); optimizer.step()\n        if not batch_ids%100:\n            print ('Epoch: %03d\/%03d | Batch: %03d\/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids, \n                     len(train_loader),cost))","4900a9bd":"dhtml('Reconstruction')","a7803498":"num_images=5\nfig,axes=pl.subplots(nrows=2,ncols=num_images, \n                     sharex=True,sharey=True,\n                     figsize=(10,4))\noriginal_images=features[:num_images]\ndecoded_images=decoded[:num_images]\nfor i in range(num_images):\n    for ax,img in zip(axes,[original_images,\n                            decoded_images]):\n        ax[i].imshow(img[i].detach().to(torch.device('cpu'))\\\n                     .reshape((img_size,img_size)),cmap='bone')","96ff5733":"dhtml('Generating')","0ea8a19d":"num_images=10\nlatent_features=\\\ntorch.randn(num_images,num_latent).to(dev)\ngenerated_images=model.decoder(latent_features)\ndecoded_images=generated_images[:num_images]\nfig,axes=pl.subplots(nrows=2,ncols=num_images\/\/2,\n                     figsize=(10,4),sharey=True)\nfor ax,img in zip(axes.reshape(num_images),decoded_images):\n    ax.imshow(img.detach().to(torch.device('cpu'))\\\n              .reshape((img_size,img_size)),cmap='bone')","1d21ddbd":"dhtml('Convolutional Conditional <br\/>Variational Autoencoder')","643fb4a5":"ch1,ch2,ch3=16,48,144\ndef to_onehot(labels,num_classes,device):\n    labels_ohe=torch.zeros(labels.size()[0],\n                           num_classes).to(device)\n    labels_ohe.scatter_(1,labels.view(-1,1),1)\n    return labels_ohe\nclass CondVarAE(tnn.Module):\n    def __init__(self,num_features,num_latent,num_classes):\n        super(CondVarAE,self).__init__()\n        self.num_classes=num_classes\n        # ENCODER\n        self.conv_en1=tnn\\\n        .Conv2d(in_channels=1+self.num_classes,\n                out_channels=ch1,kernel_size=(6,6),\n                stride=(2,2),padding=0)\n        self.conv_en2=tnn\\\n        .Conv2d(in_channels=ch1,out_channels=ch2,\n                kernel_size=(4,4),stride=(2,2),\n                padding=0)                        \n        self.conv_en3=tnn\\\n        .Conv2d(in_channels=ch2,out_channels=ch3,\n                kernel_size=(2,2),stride=(2,2),\n                padding=0)                     \n        self.z_mean=tnn.Linear(ch3*2*2,num_latent)\n        self.z_log_var=tnn.Linear(ch3*2*2,num_latent)\n        # DECODER\n        self.linear_de1=tnn\\\n        .Linear(num_latent+self.num_classes,ch3*2*2)\n        self.deconv_de1=tnn\\\n        .ConvTranspose2d(in_channels=ch3,out_channels=ch2,\n                         kernel_size=(2,2),stride=(2,2),\n                         padding=0)                              \n        self.deconv_de2=tnn\\\n        .ConvTranspose2d(in_channels=ch2,out_channels=ch1,\n                         kernel_size=(4,4),stride=(3,3),\n                         padding=1)\n        \n        self.deconv_de3=tnn\\\n        .ConvTranspose2d(in_channels=ch1,out_channels=1,\n                         kernel_size=(6,6),stride=(3,3),\n                         padding=4)        \n    def reparameterize(self, z_mu, z_log_var):\n        eps=torch.randn(z_mu.size(0),z_mu.size(1)).to(dev)\n        return z_mu+eps*torch.exp(z_log_var\/2.)    \n    def encoder(self,features,targets):\n        onehot_targets=\\\n        to_onehot(targets,self.num_classes,dev)\n        onehot_targets=\\\n        onehot_targets.view(-1,self.num_classes,1,1)        \n        ones=torch.ones(features.size()[0], self.num_classes,\n                        features.size()[2],features.size()[3], \n                        dtype=features.dtype).to(dev)\n        ones=ones*onehot_targets\n        x=torch.cat((features,ones),dim=1)        \n        x=self.conv_en1(x); x=tnnf.leaky_relu(x)      \n        x=self.conv_en2(x); x=tnnf.leaky_relu(x)\n        x=self.conv_en3(x); x=tnnf.leaky_relu(x)     \n        z_mean=self.z_mean(x.view(-1,ch3*2*2))\n        z_log_var=self.z_log_var(x.view(-1,ch3*2*2))\n        encoded=self.reparameterize(z_mean,z_log_var)\n        return z_mean,z_log_var,encoded  \n    def decoder(self,encoded,targets):\n        onehot_targets=\\\n        to_onehot(targets,self.num_classes,dev)\n        encoded=torch.cat((encoded,onehot_targets),dim=1)        \n        x=self.linear_de1(encoded)\n        x=x.view(-1,ch3,2,2)  \n        x=self.deconv_de1(x); x=tnnf.leaky_relu(x)      \n        x=self.deconv_de2(x); x=tnnf.leaky_relu(x)\n        x=self.deconv_de3(x); x=tnnf.leaky_relu(x)\n        decoded=torch.sigmoid(x)\n        return decoded\n    def forward(self,features,targets):      \n        z_mean,z_log_var,encoded=self.encoder(features,targets)\n        decoded=self.decoder(encoded,targets)     \n        return z_mean,z_log_var,encoded,decoded","56e82e18":"dhtml('Training 2')","4e16877d":"torch.manual_seed(random_seed)\nlearning_rate=.0015; num_latent=121; num_classes=33\nmodel=CondVarAE(num_features=img_size**2,\n                num_latent=num_latent,\n                num_classes=num_classes)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","fc297a21":"epochs=200\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader2):\n        features=features.to(dev)\n        targets=targets.to(dev)\n        z_mean,z_log_var,encoded,decoded=model(features,targets.long())\n        kl_divergence=(.5*(z_mean**2+torch.exp(z_log_var)-\n                           z_log_var-1)).sum()\n        pixelwise_bce=tnnf\\\n        .binary_cross_entropy(decoded,features,reduction='sum')\n        cost=kl_divergence+pixelwise_bce\n        optimizer.zero_grad()\n        cost.backward(); optimizer.step()\n        if not batch_ids%50:\n            print ('Epoch: %03d\/%03d | Batch: %03d\/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids, \n                     len(train_loader2),cost))","964c1057":"dhtml('Reconstruction 2')","e6ce5211":"num_images=5\nfig,axes=pl.subplots(nrows=2,ncols=num_images, \n                     sharex=True,sharey=True,\n                     figsize=(10,4))\noriginal_images=features[:num_images]\ndecoded_images=decoded[:num_images]\nfor i in range(num_images):\n    for ax,img in zip(axes,[original_images,\n                            decoded_images]):\n        ax[i].imshow(img[i].detach().to(torch.device('cpu'))\\\n                     .reshape((img_size,img_size)),cmap='bone')","4dbfb313":"dhtml('Generating 2')","3fdd6c45":"@register_line_magic\ndef display_gen(l):\n    l=int(l); num_images=5\n    labels=torch.tensor([l]*num_images).to(dev)\n    latent_features=\\\n    torch.randn(num_images,num_latent).to(dev)\n    generated_images=model.decoder(latent_features,labels)\n    decoded_images=generated_images[:num_images]\n    fig,axes=pl.subplots(nrows=1,ncols=num_images,\n                         figsize=(10,2),sharey=True)\n    for ax,img in zip(axes,decoded_images):\n        ax.imshow(img.detach().to(torch.device('cpu'))\\\n                  .reshape((img_size,img_size)),cmap='bone')","41b9eeab":"%display_gen 0\n%display_gen 1\n%display_gen 2\n%display_gen 3\n%display_gen 4","a3651fc8":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/autoencoder\/ae-conv-var.ipynb)"}}