{"cell_type":{"c223dedd":"code","867a51a4":"code","2b6d4942":"code","8186956b":"code","cb53dc23":"markdown"},"source":{"c223dedd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","867a51a4":"! pip install git+https:\/\/github.com\/miso-belica\/sumy.git","2b6d4942":"\nfrom gensim.summarization import summarize\nfrom sumy.utils import get_stop_words\nfrom sumy.nlp.stemmers import Stemmer\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer as sumytoken\nfrom sumy.summarizers.lex_rank import LexRankSummarizer\nfrom sumy.utils import get_stop_words\nfrom sumy.nlp.stemmers import Stemmer\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer as sumytoken\n\nfrom sumy.summarizers.lsa import LsaSummarizer as Summarizer\nfrom sumy.utils import get_stop_words\nfrom sumy.nlp.stemmers import Stemmer\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer as sumytoken\n\nfrom sumy.summarizers.luhn import LuhnSummarizer\n\n\ndef gensim_summarizer(text):\n    return (summarize(text))\n\ndef lexrank_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT):\n    parser = PlaintextParser.from_string((text), sumytoken(LANGUAGE))\n    summarizer_LexRank = LexRankSummarizer(stemmer)\n    summarizer_LexRank.stop_words = get_stop_words(LANGUAGE)\n    sentences = []\n    for sentence in summarizer_LexRank(parser.document, SENTENCES_COUNT):\n        a = sentence\n        sentences.append(str(a))\n    return \" \".join(sentences)\n\ndef lsa_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT):\n    parser = PlaintextParser.from_string((text), sumytoken(LANGUAGE))\n    summarizer_lsa = Summarizer(stemmer)\n    summarizer_lsa.stop_words = get_stop_words(LANGUAGE)\n    sentences = []\n    for sentence in summarizer_lsa(parser.document, SENTENCES_COUNT):\n        a = sentence\n        sentences.append(str(a))\n    return \" \".join(sentences)\n\ndef luhn_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT):\n    parser = PlaintextParser.from_string(text, sumytoken(LANGUAGE))\n    summarizer_luhn = LuhnSummarizer(stemmer)\n    summarizer_luhn.stop_words = get_stop_words(LANGUAGE)\n    sentences = []\n    for sentence in summarizer_luhn(parser.document, SENTENCES_COUNT):\n        a = sentence\n        sentences.append(str(a))\n    return \" \".join(sentences)\n\n","8186956b":"from sumy.nlp.stemmers import Stemmer\n\nLANGUAGE = \"english\"\nSENTENCES_COUNT = 2\nstemmer = Stemmer(LANGUAGE)\ntext = 'The contribution of cloud computing and mobile computing technologies lead to the newly emerging mobile cloud com- puting paradigm. Three major approaches have been pro- posed for mobile cloud applications: 1) extending the access to cloud services to mobile devices; 2) enabling mobile de- vices to work collaboratively as cloud resource providers; 3) augmenting the execution of mobile applications on portable devices using cloud resources. In this paper, we focus on the third approach in supporting mobile data stream applica- tions. More specifically, we study how to optimize the com- putation partitioning of a data stream application between mobile and cloud to achieve maximum speed\/throughput in processing the streaming data. To the best of our knowledge, it is the first work to study the partitioning problem for mobile data stream applica- tions, where the optimization is placed on achieving high throughput of processing the streaming data rather than minimizing the makespan of executions as in other appli- cations. We first propose a framework to provide runtime support for the dynamic computation partitioning and exe- cution of the application. Different from existing works, the framework not only allows the dynamic partitioning for a single user but also supports the sharing of computation in- stances among multiple users in the cloud to achieve efficient utilization of the underlying cloud resources. Meanwhile, the framework has better scalability because it is designed on the elastic cloud fabrics. Based on the framework, we design a genetic algorithm for optimal computation parti- tion. Both numerical evaluation and real world experiment have been performed, and the results show that the par- titioned application can achieve at least two times better performance in terms of throughput than the application without partitioning.'\n\ngensim_summary = gensim_summarizer.gensim_summarizer(text)\nlexrank_summary = sumy_Lex_summarize.lexrank_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT)\nlsa_summary = sumy_LsaSummarizer_summarizer.lsa_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT)\nluhn_summary = sumy_Luhn_summarize.luhn_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT)\n\nprint (\"\\n ===GENSIM===\\n\",gensim_summary)\nprint (\"\\n ===Lexrank==\\n\",lexrank_summary)\nprint (\"\\n ===LSA==\\n\",lsa_summary)\nprint (\"\\n ===luhn==\\n\",luhn_summary)","cb53dc23":"**AUTOMATIC TEXT SUMMARIZATION**\n\nSo what is automatic text summarization? What does it do? Summarizes text automatically? By who? Computers? How do machines even do it? Sounds complicated right? But no worries \ud83d\ude03 At the end of this blog, you will even know how to implement it!! Sounds cool, ain\u2019t it?<br><br>\n\nSo, let's start with Text summarization! Text summarization is the process of filtering the most important information from the source to reduce the length of the text document. And Automatic text summarization is the process of generating summaries of a document without any human intervention.<br><br>\nWe humans can do such task easily as we have the capacity to understand the meaning of the text document and extract features and summarize it. Like if I give you 100 lines of sentences with a topic and I ask you to summarize it or get top 10 related sentences to the topic, it\u2019s easy, right? But what if I give you millions of documents and I ask you to do the same? How long will that take? And how good will it be? how much manpower will it require? which means it will be more costly.\n\nYou can check my blog for more details: https:\/\/blog.ekbana.com\/automatic-text-summarization-542b78163429\n"}}