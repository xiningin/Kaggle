{"cell_type":{"b2437660":"code","faa20667":"code","4036e818":"code","65bd6835":"code","65553d6a":"code","85a8ad5c":"code","5056b13f":"markdown","c6e4d1a7":"markdown","7c239f73":"markdown","345bdd23":"markdown","226125a7":"markdown"},"source":{"b2437660":"\"\"\"\nImport libraries\n\"\"\"\n\nimport gc\nimport numpy as np\nimport time\nimport transformers as tsfm","faa20667":"\"\"\"\nLoad GPT-2-XL from huggingface servers and measure time taken\n\"\"\"\n\nstart_time = time.time()\nname = \"gpt2-xl\"\nmodel = tsfm.GPT2Model.from_pretrained(name)\nend_time = time.time()\nruntime = end_time - start_time","4036e818":"\"\"\"\nPrint time taken loading model from huggingface servers\n\"\"\"\n\nminutes = int(np.floor(runtime \/ 60))\nseconds = int(np.round(runtime % 60))\ntemplate = \"Time taken loading GPT-2-XL from huggingface servers: {}m {}s\"\nprint(template.format(minutes, seconds))","65bd6835":"\"\"\"\nClean up GPT-2-XL model\n\"\"\"\n\ndel model\ngc.collect()","65553d6a":"\"\"\"\nLoad GPT-2-XL from this dataset and measure time taken\n\"\"\"\n\nstart_time = time.time()\npath = \"..\/input\/pretrained-transformers\/gpt2_xl_model\"\nmodel = tsfm.GPT2Model.from_pretrained(path)\nend_time = time.time()\nruntime = end_time - start_time","85a8ad5c":"\"\"\"\nPrint time taken loading model from this dataset\n\"\"\"\n\nminutes = int(np.floor(runtime \/ 60))\nseconds = int(np.round(runtime % 60))\ntemplate = \"Time taken loading GPT-2-XL from this dataset: {}m {}s\"\nprint(template.format(minutes, seconds))","5056b13f":"# Loading GPT-2-XL from the internet vs. from this dataset\n\nIn this notebook, I will demonstrate how time can be saved by loading GPT-2-XL (a large transformer model) from this dataset instead of directly loading it from [huggingface](https:\/\/huggingface.co) servers.","c6e4d1a7":"## Loading from huggingface servers","7c239f73":"<center><img src=\"https:\/\/imgur.com\/AsKmcl6.png\"><\/center>","345bdd23":"It can be seen that loading GPT-2-XL from this dataset takes far less time than loading it directly from huggingface servers! Start using this dataset for all your transformer needs and save heaps of runtime. Happy NLP!","226125a7":"## Loading from this dataset"}}