{"cell_type":{"d00365a2":"code","26bf16a5":"code","f958835a":"code","e895ce38":"code","209f2fcf":"code","bd5e5416":"code","7f170980":"code","acc5058a":"code","f786ba9a":"code","503a9473":"code","815f3ae5":"code","5a5d48b4":"code","99ccddd8":"code","f3a7c5c0":"code","6849d3f8":"code","6f47e9e6":"code","f5894a5c":"code","d96d1c5e":"code","dd00d979":"code","127b070e":"code","376d6657":"code","852f51f5":"code","59122c87":"code","b5f55a42":"code","19672ec6":"code","b9e13954":"code","4f841c27":"code","60775923":"code","4e04a67d":"code","8e19234e":"code","a1efa105":"markdown","d83130ac":"markdown","f1187ef9":"markdown","5f662ec9":"markdown","6063678a":"markdown","bdd7290a":"markdown","6f9f99ea":"markdown","a5b014a7":"markdown","75e42acd":"markdown","215a8016":"markdown","c2a52c2f":"markdown","c8540798":"markdown","46ce90bc":"markdown","22db4e40":"markdown","6e19931e":"markdown","23b43e9e":"markdown","a8fa052c":"markdown","2c1973ac":"markdown"},"source":{"d00365a2":"import json\nimport pickle as pkl\n\nfrom itertools import product\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\nfrom xgboost import XGBRegressor","26bf16a5":"#!unzip \"drive\/MyDrive\/TPS August\/tabular-playground-series-aug-2021.zip\" -d \"drive\/MyDrive\/TPS August\/data\"","f958835a":"#train_df = pd.read_csv(\"\/content\/drive\/MyDrive\/TPS August\/data\/train.csv\")\ntrain_df = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntrain_df.head()","e895ce38":"train_df.drop(\"id\", axis=1, inplace=True)\ntrain_df.head(2)","209f2fcf":"#test_df = pd.read_csv(\"\/content\/drive\/MyDrive\/TPS August\/data\/test.csv\")\ntest_df = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\ntest_df.head()","bd5e5416":"test_df.index = test_df.id\ntest_df.drop(\"id\", axis=1, inplace=True)\ntest_df.head(2)","7f170980":"#submit_df = pd.read_csv(\"\/content\/drive\/MyDrive\/TPS August\/data\/sample_submission.csv\")\nsubmit_df = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nsubmit_df.head()","acc5058a":"X, y = np.array(train_df.drop(\"loss\", axis=1)), np.array(train_df.loss)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=3)\nlen(X_train), len(X_val)","f786ba9a":"def score_model(model, X, y):\n  preds = model.predict(X)\n  score = mean_squared_error(y, preds, squared=False)\n  return score","503a9473":"def save_pkl_data(data, filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats.p\"):\n  pkl.dump(data, open(filepath, \"wb\" ))\n\ndef load_pkl_data(filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats.p\"):\n  return pkl.load(open(filepath, \"rb\"))","815f3ae5":"def single_split_scoring(X_train, X_val, y_train, y_val, max_depths=[3], learning_rates=[0.1], gammas=[0], min_child_weights=[1], subsamples=[1], colsample_bytrees=[1], n_estimatorss=[100], filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats.p\"):\n  model_params = {}\n  model_train_scores = {}\n  model_valid_scores = {}\n\n  eval_set = [(X_train, y_train), (X_val, y_val)]\n  eval_metric = \"rmse\"\n\n  param_combinations = product(max_depths, learning_rates, gammas, min_child_weights, subsamples, colsample_bytrees, n_estimatorss)\n  num_combinations = len(max_depths)*len(learning_rates)*len(gammas)*len(min_child_weights)*len(subsamples)*len(colsample_bytrees)*len(n_estimatorss)\n  print(f\"Testing {num_combinations} total combinations\")\n  \n  for i, (max_depth, learning_rate, gamma, min_child_weight, subsample, colsample_bytree, n_estimators) in enumerate(param_combinations):\n    print(f\"\\nTest {i+1} of {num_combinations}\\n\")\n    \n    model = XGBRegressor(max_depth=max_depth,\n                         learning_rate=learning_rate,\n                         gamma=gamma,\n                         min_child_weight=min_child_weight,\n                         subsample=subsample,\n                         colsample_bytree=colsample_bytree,\n                         n_estimators=n_estimators,\n                         objective=\"reg:squarederror\",\n                         verbosity=1,\n                         seed=3)\n\n    model.fit(X=X_train,\n              y=y_train,\n              eval_set=eval_set,\n              eval_metric=eval_metric,\n              early_stopping_rounds=10)\n    \n    model_params[i] = model.get_params()\n    model_train_scores[i] = score_model(model, X_train, y_train)\n    model_valid_scores[i] = score_model(model, X_val, y_val)\n  \n    model_stats = {\n      \"parameters\": model_params,\n      \"train_scores\": model_train_scores,\n      \"validation_scores\": model_valid_scores\n    }\n    save_pkl_data(model_stats, filepath)\n\n  return model_stats","5a5d48b4":"# model_stats = single_split_scoring(X_train, X_val, y_train, y_val,\n#                                    max_depths=[3, 4], \n#                                    learning_rates=[0.1, 0.05], \n#                                    gammas=[0, 1], \n#                                    min_child_weights=[0, 1], \n#                                    subsamples=[0.5, 0.6], \n#                                    colsample_bytrees=[0, 0.5], \n#                                    n_estimatorss=[100,120],\n#                                    filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-1.p\")","99ccddd8":"#loaded_model_stats = load_pkl_data(\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-1.p\")\nloaded_model_stats = load_pkl_data(\"..\/input\/modelstats\/model-stats-1.p\")","f3a7c5c0":"def show_top_models(model_stats):\n  parameters = np.array(list(model_stats[\"parameters\"].values()))\n  train_scores = np.array(list(model_stats[\"train_scores\"].values()))\n  valid_scores = np.array(list(model_stats[\"validation_scores\"].values()))\n\n  top_5_indices = valid_scores.argsort()[:5]\n\n  for i, index in enumerate(top_5_indices):\n    print(f\"Model index: {index} - Ranking: {i+1}\")\n    print(f\"Validation score: {valid_scores[index]}\")\n    print(f\"Training score: {train_scores[index]}\")\n    print(f\"Parameters: {parameters[index]}\")\n    print(\"\\n\")","6849d3f8":"show_top_models(loaded_model_stats)","6f47e9e6":"# single_split_scoring(X_train, X_val, y_train, y_val,\n#                       max_depths=[4,5], \n#                       learning_rates=[0.1], \n#                       gammas=[0.5, 0, 1, 2], \n#                       min_child_weights=[0, 1, 2], \n#                       subsamples=[0.5, 0.4], \n#                       colsample_bytrees=[0.7, 0.5], \n#                       n_estimatorss=[150,200],\n#                       filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-2.p\")","f5894a5c":"#model_stats_2 = load_pkl_data(\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-2.p\")\nmodel_stats_2 = load_pkl_data(\"..\/input\/modelstats\/model-stats-2.p\")","d96d1c5e":"show_top_models(model_stats_2)","dd00d979":"# single_split_scoring(X_train, X_val, y_train, y_val,\n#                       max_depths=[4, 5], \n#                       learning_rates=[0.1], \n#                       gammas=[0.5], \n#                       min_child_weights=[2], \n#                       subsamples=[0.5], \n#                       colsample_bytrees=[0.5, 0.7], \n#                       n_estimatorss=[200, 250],\n#                       filepath=\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-3.p\")","127b070e":"#model_stats_3 = load_pkl_data(\"\/content\/drive\/MyDrive\/TPS August\/logs\/model-stats-3.p\")\nmodel_stats_3 = load_pkl_data(\"..\/input\/modelstats\/model-stats-3.p\")","376d6657":"show_top_models(model_stats_3)","852f51f5":"def train_model(X, y, max_depth, learning_rate, gamma, min_child_weight, subsample, colsample_bytree, n_estimators):\n  model = XGBRegressor(max_depth=max_depth,\n                       learning_rate=learning_rate,\n                       gamma=gamma,\n                       min_child_weight=min_child_weight,\n                       subsample=subsample,\n                       colsample_bytree=colsample_bytree,\n                       n_estimators=n_estimators,\n                       objective=\"reg:squarederror\",\n                       verbosity=3,\n                       seed=3)\n  model.fit(X, y)\n  return model","59122c87":"# Best params: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 200, 'subsample': 0.5}\n\nfinal_model = train_model(X, y,\n                          max_depth=4,\n                          learning_rate=0.1,\n                          gamma=0.5,\n                          min_child_weight=2,\n                          subsample=0.5,\n                          colsample_bytree=0.5,\n                          n_estimators=250)","b5f55a42":"#save_pkl_data(final_model, \"drive\/MyDrive\/TPS August\/models\/hyperparameter-trained-3-tunes.p\")","19672ec6":"#loaded_model = load_pkl_data(\"drive\/MyDrive\/TPS August\/models\/hyperparameter-trained-3-tunes.p\")","b9e13954":"#score_model(loaded_model, X, y)\nscore_model(final_model, X, y)","4f841c27":"#predictions = loaded_model.predict(test_df)\npredictions = final_model.predict(test_df)","60775923":"submit_df.head()","4e04a67d":"submit_df.loss = predictions\nsubmit_df.head()","8e19234e":"submit_df.to_csv(\"submission.csv\",\n                 index=False)","a1efa105":"## 7. Model Finalizing","d83130ac":"### Evaluation","f1187ef9":"# Tabular Playground Series - August 2021\n\nThis is the August challenge from the Tabular Playground Series monthly machine learning challenges on Kaggle.\nIt is a beginner friendly challenge, for gaining skills in machine learning.","5f662ec9":"### Building and training a final model","6063678a":"## 5. Baseline hyperparameter modeling","bdd7290a":"## 1. Problem Definition\n\n> Try to achieve the lowest loss in the challenge leaderboards.","6f9f99ea":"### Importing libraries","a5b014a7":"### Hyperparameter search","75e42acd":"## 4. Features\n\nThe dataset we're using...\n* is structured.\n* is pre-split into training and test datasets.\n* contains 100 columns of features.\n* contains 1 label column named `loss`.\n\nLet's import the libraries we will be using and then check out the data.","215a8016":"### Importing the data","c2a52c2f":"### Splitting the data","c8540798":"**This notebook was written in Google Colab**\n\n> **Note:** Some code is commented out because it is only executable in the Google Colab project.","46ce90bc":"## 3. Evaluation\n\n> Submissions are scored on the root mean squared error.","22db4e40":"### Third tune","6e19931e":"### Second tune","23b43e9e":"## 2. Data\n\nThe data I'll be using can be found on Kaggle: https:\/\/www.kaggle.com\/c\/tabular-playground-series-aug-2021\/data","a8fa052c":"### Getting predictions","2c1973ac":"## 6. Experimentation"}}