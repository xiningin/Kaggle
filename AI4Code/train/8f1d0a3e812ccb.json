{"cell_type":{"02373f0f":"code","7eee6f0d":"code","e38ca82d":"code","9376e7b4":"code","dfdb7c2c":"code","f81e2c4f":"code","98d729d9":"code","04b3ede3":"code","399d01f7":"code","0028e80f":"code","1ff3c521":"code","e7ea6473":"code","ce100712":"code","19c193ae":"code","75e18040":"code","8cba6997":"code","ff03d229":"code","224c7eed":"code","0c383ff3":"code","d52e0a64":"code","b02c9a98":"code","ba1cdbae":"code","57fd8e9e":"code","9148e555":"code","3b0b66e2":"code","f3dc1960":"code","3613f545":"code","f4986bab":"code","cda483c0":"code","b40e3ff7":"code","42a6eea6":"code","dd489ca7":"code","45e48141":"code","1cd2c33b":"code","0015ddbf":"code","046877b6":"code","445ba262":"code","7e0bb112":"markdown","18e69bad":"markdown","b68baaba":"markdown","9c363f82":"markdown","2b23690f":"markdown","6e8bcece":"markdown","dd14fe2e":"markdown","fdbc9b61":"markdown","030f3906":"markdown","7968c6a1":"markdown","f7a39ef2":"markdown","be7339e5":"markdown","80332e6b":"markdown","73f4364f":"markdown","9c22ecdd":"markdown","64b61484":"markdown","80f9040f":"markdown","21a78c7c":"markdown","dce89ac2":"markdown","c7718100":"markdown","131b203b":"markdown","92d6179b":"markdown","55412c13":"markdown","88243368":"markdown","604f6956":"markdown","0562b43b":"markdown","4f0494f1":"markdown","d1798638":"markdown"},"source":{"02373f0f":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7eee6f0d":"# training data\ntrain_dts = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_dts.head()","e38ca82d":"# test data\ntest_dts = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_dts.head()","9376e7b4":"female = train_dts.loc[train_dts.Sex=='female']['Survived']\nprint('% of Female survived : {:.3f}'.format((sum(female)\/len(female))*100))\n\nmale = train_dts.loc[train_dts.Sex=='male']['Survived']\nprint('% of Male survived : {:.3f}'.format((sum(male)\/len(male))*100))","dfdb7c2c":"print('Shape of Training Set : {}'.format(train_dts.shape))\nprint('Number of training data points : {}\\n'.format(len(train_dts)))\nprint('Shape of Test Set : {}'.format(test_dts.shape))\nprint('Number of test data points : {}\\n'.format(len(test_dts)))\nprint('Columns : {}'.format(train_dts.columns))\ntrain_dts.info()","f81e2c4f":"test_dts.info()","98d729d9":"train_dts.describe()","04b3ede3":"test_dts.describe()","399d01f7":"g = sns.heatmap(train_dts.corr(),annot=True, fmt = \".1f\", cmap = \"coolwarm\")","0028e80f":"age_hist = train_dts.Age.hist()","1ff3c521":"train_dts.groupby('Pclass').Survived.mean()","e7ea6473":"pd.crosstab(index=train_dts['Sex'], columns=train_dts['Pclass'], values=train_dts.Survived, aggfunc='mean')","ce100712":"embarked_hist = train_dts.Embarked.hist()","19c193ae":"#Fill nan values in Embarked with 'S' as it is most frequent value\ntrain_dts['Embarked'] = train_dts['Embarked'].fillna('S')\ntrain_dts['Age'] = train_dts['Age'].fillna(train_dts['Age'].mean())\ntrain_dts['Age'].isnull().sum() ","75e18040":"test_dts['Fare'] = test_dts['Fare'].fillna(test_dts['Fare'].median())\ntest_dts['Age'] = test_dts['Age'].fillna(test_dts['Age'].mean())","8cba6997":"title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train_dts['Name']]\ntrain_dts['Title'] = pd.Series(title)\n\ntitle_ = [i.split(\",\")[1].split(\".\")[0].strip() for i in test_dts['Name']]\ntest_dts['Title'] = pd.Series(title_)\n\ntrain_dts.Title.value_counts()","ff03d229":"train_dts[\"Title\"] = train_dts[\"Title\"].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don',  'Dr',\n                                                 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mme', 'Ms', 'Mlle'],\n                                                'Rare'\n                                               )\ntest_dts[\"Title\"] = test_dts[\"Title\"].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr',\n                                               'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mme', 'Ms', 'Mlle'],\n                                              'Rare'\n                                             )","224c7eed":"plt.figure(figsize=(6,6))\nplt.hist(train_dts.Title)\nplt.xticks(rotation=45)\nplt.show","0c383ff3":"mr = train_dts.loc[train_dts['Title']=='Mr'].Survived\nmiss = train_dts.loc[train_dts['Title']=='Miss'].Survived\nmrs = train_dts.loc[train_dts['Title']=='Mrs'].Survived\nmaster = train_dts.loc[train_dts['Title']=='Master'].Survived\nrare = train_dts.loc[train_dts['Title']=='Rare'].Survived\n\nprint(\"probablity of Surviving if Mr : {:.2f}\".format(sum(mr)\/len(mr)))\nprint(\"probablity of Surviving if Mrs : {:.2f}\".format(sum(mrs)\/len(mrs)))\nprint(\"probablity of Surviving if Miss : {:.2f}\".format(sum(miss)\/len(miss)))\nprint(\"probablity of Surviving if Master : {:.2f}\".format(sum(master)\/len(master)))\nprint(\"probablity of Surviving if Rare : {:.2f}\".format(sum(rare)\/len(rare)))","d52e0a64":"g = sns.catplot(x=\"Title\", y=\"Survived\", data=train_dts, kind='bar').set_ylabels(\"Survival Probability\")","b02c9a98":"train_dts['FamilySize'] = train_dts['SibSp'] + train_dts['Parch'] + 1\ntest_dts['FamilySize'] = test_dts['SibSp'] + test_dts['Parch'] + 1","ba1cdbae":"g = sns.catplot(data=train_dts, x='FamilySize', y='Survived', kind='point').set_ylabels(\"Survival Probability\")","57fd8e9e":"# on training set\ntrain_dts['Singleton'] = train_dts['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain_dts['SmallFamily'] = train_dts['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntrain_dts['LargeFamily'] = train_dts['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n\n# on test set\ntest_dts['Singleton'] = test_dts['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest_dts['SmallFamily'] = test_dts['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntest_dts['LargeFamily'] = test_dts['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","9148e555":"train_dts.loc[train_dts.Cabin.isnull(), 'Cabin'] = 0\ntrain_dts.loc[train_dts.Cabin != 0, 'Cabin'] = 1\n\ntest_dts.loc[test_dts.Cabin.isnull(), 'Cabin'] = 0\ntest_dts.loc[test_dts.Cabin != 0, 'Cabin'] = 1\n\ntrain_dts['Cabin'] = pd.to_numeric(train_dts['Cabin'])\ntest_dts['Cabin'] = pd.to_numeric(test_dts['Cabin'])","3b0b66e2":"train_dts.Ticket.describe()","f3dc1960":"def cleanTicket(ticket):\n    ticket = ticket.replace('.','')\n    ticket = ticket.replace('\/','')\n    ticket = ticket.split()\n    ticket = ticket[0]\n    if ticket.isdigit():\n        return 'X'\n    else:\n        return ticket[0]\n    \ntrain_dts['Ticket'] = train_dts['Ticket'].map(cleanTicket)\ntest_dts['Ticket'] = test_dts['Ticket'].map(cleanTicket)","3613f545":"train_dts.Ticket.unique()","f4986bab":"train_dts.min()","cda483c0":"train_dts.max()","b40e3ff7":"X_train = pd.DataFrame.copy(train_dts)\nX_test = pd.DataFrame.copy(test_dts)\n\n# label encoding\nX_train = pd.get_dummies(X_train, columns=['Sex', 'Embarked', 'Title', \"Pclass\", 'Ticket'])\nX_test = pd.get_dummies(X_test, columns=['Sex', 'Embarked', 'Title', \"Pclass\", 'Ticket'])\nX_train.shape","42a6eea6":"# droping columns\nX_train.drop(labels=['Name', 'PassengerId', 'Survived'], axis=1, inplace=True)\nX_test.drop(labels=['Name', 'PassengerId'], axis=1, inplace=True)","dd489ca7":"plt.figure(figsize = (14,14))\ng = sns.heatmap(X_train.corr(),annot=True, fmt = \".1f\", cmap = \"coolwarm\")","45e48141":"y_train = train_dts.Survived","1cd2c33b":"X_train.info()\nX_train.head()","0015ddbf":"X_test.info()\nX_test.head()","046877b6":"from xgboost import XGBClassifier\nxgb_clf = XGBClassifier(n_estimators= 2000,\n                        max_depth= 4,\n                        min_child_weight= 2,\n                        gamma=0.9,                    \n                        subsample=0.8,\n                        colsample_bytree=0.8,\n                        objective= 'binary:logistic',\n                        nthread= -1,\n                        scale_pos_weight=1\n                       )\n\nxgb_clf.fit(X_train, y_train)\n\n# testing on train set\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nprint(confusion_matrix(xgb_clf.predict(X_train), y_train))\nprint('Accuracy of training')\nprint(accuracy_score(xgb_clf.predict(X_train), y_train))","445ba262":"pred = pd.Series(xgb_clf.predict(X_test), name='Survived')\nresults = pd.concat([test_dts['PassengerId'], pred], axis=1)\nresults.to_csv(\"submission.csv\", index=False)\nresults.head(10)","7e0bb112":"### **3.3 Missing Values**\nAs seen from below, some columns have missing values. `display_missing` function shows the count of missing values in every column in both training and test set by using `info()` function in non null count\n\n* Training set and test set both have missing values in `Age`, `Cabin` and `Embarked` columns. and in `fare` test set \n\nMissing values in `Age`, `Embarked` and `Fare` can be filled with descriptive statistical measures but that wouldn't work for `Cabin`.\n\nabove histogram shows that most of the passengers belong to the `S` (Southampton) in `Embarked`, let's fill tha `nan` values by **S** in training set and test set. And the `nan values` in `age` can be filled by takaing `mean` of all age in test and train sets","18e69bad":"### 3.1 Heatmap","b68baaba":"the `nan` values in `fare` column can be filled taking median in test set","9c363f82":"the surviving probablities of titles `Miss`, `Mrs` and `Master` are higher","2b23690f":"* Sigleton : a boolean variable that describes families of size = 1\n* SmallFamily : a boolean variable that describes families of 2 <= size <= 4\n* LargeFamily : a boolean variable that describes families of 5 < size","6e8bcece":"now we are remaning with just 8 unique values ","dd14fe2e":"ticket has a lot of duplicate values with mixed number and Alphabets lets now filter the ticket feature. \nWe will clean ticket by getting prefix of the ticket number and for tickets with `digits only` will be replaced b `'X'`","fdbc9b61":"the Passenger Class status also has an influence on the survival chances","030f3906":"# 5. XGBoost Model","7968c6a1":"# 2. Importing Dataset","f7a39ef2":"it can be assumed that passengers with missing values in cabin not had a cabin aat all so we fill it by 0 and passengers with cabin can be filled by 1","be7339e5":"also the `gender` in the classes also has an influence as it can be seen that female has **96%** chances and males has **36%** in class 1 only and can seen decreasing with `lower class`","80332e6b":"from the above histogram it can be observed that most of the passengers were from the age group of 20 - 40","73f4364f":"# 1. Importing Libraries","9c22ecdd":"### 3.2 Age Histogram Plot","64b61484":"# 3. Feature Engineering","80f9040f":"above graph verifies that persons with family size of 1 to 4 had more surviving prob and larger families with 8 and 11 has nearly 0 probablity","21a78c7c":"`'Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don',  'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mme', 'Ms', 'Mlle'` these titles appers less in the dataset as their count is 1 or 2 lets remove them by a single lable `rare`","dce89ac2":"if you like my work or it helped, an upvote will help me keep me motivated..","c7718100":"15\/10\/2020","131b203b":"now we having 33 features","92d6179b":"it can be assumend that the larger families size has difficulties to get on board as they to find all the mambers of families, lets create a new column of Family size","55412c13":"### **2.1 Overview** \n* `PassengerId` is the unique id of the row and it doesn't have any effect on target\n* `Survived` is the target variable we are trying to predict (**0** or **1**):\n    - **1 = Survived**\n    - **0 = Not Survived**\n* `Pclass` (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has **3** unique values (**1**,  **2 **or **3**):\n    - **1 = Upper Class**\n    - **2 = Middle Class**\n    - **3 = Lower Class**\n* `Name`, `Sex` and `Age` are self-explanatory\n* `SibSp` is the total number of the passengers' siblings and spouse\n* `Parch` is the total number of the passengers' parents and children\n* `Ticket` is the ticket number of the passenger\n* `Fare` is the passenger fare\n* `Cabin` is the cabin number of the passenger\n* `Embarked` is port of embarkation and it is a categorical feature which has **3** unique values (**C**, **Q** or **S**):\n    - **C = Cherbourg**\n    - **Q = Queenstown**\n    - **S = Southampton**","88243368":"after the final processing of features we are remaning with 30 features","604f6956":"Calculating Survival rate of Male and Female on training set","0562b43b":"creating titles from names of passengers","4f0494f1":"can be seen clearly that female has much larger probablity of surviving then male","d1798638":"# 4. Creating train and test set and label encoding"}}