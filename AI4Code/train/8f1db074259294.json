{"cell_type":{"9ad189fd":"code","d1ee46ea":"code","7a4b299b":"code","32200b91":"code","c3729704":"code","cfc465e4":"code","a6c7f254":"code","6fd88aa4":"code","d157db5b":"code","9c056df4":"code","406c02d1":"code","9ce35f7b":"code","20f4b329":"code","35a7f456":"code","a11a24ab":"code","c9d13c17":"code","3e760799":"code","70445bb5":"code","f618c46b":"code","6fa9179b":"code","34c310c2":"code","c5998e6f":"code","48a54a87":"code","679033a9":"code","04ef4762":"code","fbb481b2":"code","92e57433":"code","1315623a":"code","862e5ca1":"code","a908d408":"code","8db7cb97":"code","c8b02b81":"code","c92b5cd7":"code","581959f3":"code","03998215":"code","655395bc":"code","bf5a3122":"code","14d629df":"code","979fcacd":"code","f0f11eca":"code","5503bf37":"code","e785ebc0":"code","9efbbe49":"code","4566078e":"code","a6a2892b":"code","7ccd4f73":"code","9d5e1453":"markdown","1e843e63":"markdown","d873d2e6":"markdown","84471948":"markdown","19898811":"markdown","3f343429":"markdown","c0252fc3":"markdown","7c134ec1":"markdown","84fe94a4":"markdown","1cc7983d":"markdown","b2b75eab":"markdown","306cb125":"markdown","45f5c087":"markdown","adc16d91":"markdown","0f555000":"markdown","15405d54":"markdown","503c87f2":"markdown"},"source":{"9ad189fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d1ee46ea":"import gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_squared_log_error, log_loss\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn import preprocessing as pp\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, PowerTransformer, quantile_transform\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier, LGBMRegressor\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nfrom sklearn.svm import SVC\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n\nimport itertools\nimport math\nimport re","7a4b299b":"df_train_original = pd.read_csv('..\/input\/exam-for-students20200129\/train.csv', index_col=0) \ndf_test_original = pd.read_csv('..\/input\/exam-for-students20200129\/test.csv',index_col=0)\n\ntarget = 'ConvertedSalary'\n\ndf_country_original = pd.read_csv('..\/input\/exam-for-students20200129\/country_info.csv')\n\ndf_train_original.shape, df_test_original.shape","32200b91":"df_train = df_train_original.copy()\ndf_test = df_test_original.copy()\ndf_country = df_country_original.copy()\n\ndf_test_with_targetcol = df_test_original.copy()\ndf_test_with_targetcol[target] = -1\ndf_all = pd.concat([df_train, df_test_with_targetcol], axis=0)","c3729704":"df_train","cfc465e4":"df_test","a6c7f254":"df_country","6fd88aa4":"# df_train = df_train.merge(df_country, on = ['Country'], how = 'left')\n# df_test = df_test.merge(df_country, on = ['Country'], how = 'left')\n# df_all = df_all.merge(df_country, on = ['Country'], how = 'left')\n\n#GDP\u4ee5\u5916\u5b9f\u8cea\u4e0d\u8981\ndf_GDP = df_country[['Country', 'GDP ($ per capita)']]\n\ndf_train = df_train.merge(df_GDP, on = ['Country'], how = 'left')\ndf_test = df_test.merge(df_GDP, on = ['Country'], how = 'left')\ndf_all = df_all.merge(df_GDP, on = ['Country'], how = 'left')","d157db5b":"df_train.describe()","9c056df4":"df_test.describe()","406c02d1":"df_train_corr = df_train.corr()\nprint(df_train_corr)\nsns.heatmap(df_train_corr, vmax=1, vmin=-1, center=0, cmap = 'seismic')","9ce35f7b":"# f = '\u5165\u529b\u3059\u308b'\nf = 'GDP ($ per capita)'\ndens = False\n\nplt.figure(figsize=[15,7])\ndf_train[f].hist(density=dens, alpha=0.5, bins=30, color = 'r', label = 'train')\ndf_test[f].hist(density=dens, alpha=0.5, bins=30, color = 'b', label = 'test')\nplt.xlabel(f)\nplt.ylabel('density')\nplt.show()","20f4b329":"c = 'Country'\n\n# df_train[c].value_counts() \/ len(df_train)\ndf_train[c].value_counts()","35a7f456":"df_test[c].value_counts()\n#Germany\u3068France\u306f\u3001training data\u306b\u306a\u3044\u3002\n#Country\u30ab\u30e9\u30e0\u306f\u6d88\u3059","a11a24ab":"df_train[df_train['Country'] == 'Germany']\ndf_train[df_train['Country'] == 'France']","c9d13c17":"for col in df_all.columns:\n    print(df_all[col].value_counts())\n    print('____')\n    \n#DevType, CommunicationTools, FrameworkWorkedWith\u306f\u30c6\u30ad\u30b9\u30c8\n\n#\u30de\u30c3\u30d4\u30f3\u30b0\n# Age, CompanySize, Exercise, HoursComputer, HoursOutside, LastNewJob, SkipMeals, StackOverflowRecommend, YearsCoding, YearsCodingProf, ","3e760799":"# col_outlier = target\n# #max, min\u3092\u8a2d\u5b9a\n# maximum = 2000000\n# minimum = 0\n# percentile = 0.99\n\n# #\u5916\u308c\u5024\u3092\u9664\u5916\n# df_train = df_train[df_train[col_outlier] < df_train[col_outlier].quantile(percentile)]\n# df_train = df_train.loc[df_train[col_outlier] <= maximum]\n# df_train = df_train.loc[df_train[col_outlier] >= minimum]\n\n# #\u53e4\u3044\u30c7\u30fc\u30bf\u3092\u9664\u5916\n# # df_train = df_train[df_train.issue_d.dt.year >= oldest]#issue_d\u3092\u3061\u3083\u3093\u3068\u5909\u63db\u3002\u65e2\u306byear\u304c\u3042\u308b\u306a\u3089\u3001\u305d\u3063\u3061\u4f7f\u3046\u3002","70445bb5":"#\u5148\u306b\u30bf\u30fc\u30b2\u30c3\u30c8\u3092Log\u5909\u63db\u3059\u308b\u304b\u5426\u304b\nfirst_log = True","f618c46b":"y_train = df_train[target]\nX_train = df_train.drop([target], axis=1)\n\nX_test = df_test\n\nX_all = pd.concat([X_train, X_test], axis = 0)\n\n#\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u6b20\u640d\u3057\u3066\u3044\u308b\u5834\u5408\u3001\u9664\u53bb\nX_train = X_train[y_train.isnull()==False]\ny_train = y_train[y_train.isnull()==False]\n\n#\u30bf\u30fc\u30b2\u30c3\u30c8\u306elog1\u5909\u63db\nif(first_log == True):\n    y_train = y_train.apply(np.log1p)","6fa9179b":"#DevType, CommunicationTools, FrameworkWorkedWith\u306f\u30c6\u30ad\u30b9\u30c8\nTXT_train_DevType = X_train.DevType.copy()\nTXT_test_DevType = X_test.DevType.copy()\n\nTXT_train_CommunicationTools = X_train.CommunicationTools.copy()\nTXT_test_CommunicationTools = X_test.CommunicationTools.copy()\n\nTXT_train_FrameworkWorkedWith = X_train.FrameworkWorkedWith.copy()\nTXT_test_FrameworkWorkedWith = X_test.FrameworkWorkedWith.copy()\n\nTXT_train_DevType.fillna('#', inplace = True)\nTXT_test_DevType.fillna('#', inplace = True)\n\nTXT_train_CommunicationTools.fillna('#', inplace = True)\nTXT_test_CommunicationTools.fillna('#', inplace = True)\n\nTXT_train_FrameworkWorkedWith.fillna('#', inplace = True)\nTXT_test_FrameworkWorkedWith.fillna('#', inplace = True)","34c310c2":"# TXT_train_DevType","c5998e6f":"X_train['missing_sum'] = X_train.isnull().sum(axis=1)\nX_test['missing_sum'] = X_test.isnull().sum(axis=1)","48a54a87":"X_train['DevType'].fillna('#', inplace = True)\nX_test['DevType'].fillna('#', inplace = True)\n\nX_train['CommunicationTools'].fillna('#', inplace = True)\nX_test['CommunicationTools'].fillna('#', inplace = True)\n\nX_train['FrameworkWorkedWith'].fillna('#', inplace = True)\nX_test['FrameworkWorkedWith'].fillna('#', inplace = True)","679033a9":"def mapping(map_col, mapping):\n    X_train[map_col]=X_train[map_col].map(mapping)\n    X_test[map_col]=X_test[map_col].map(mapping)","04ef4762":"Age_mapping = {'Under 18 years old':18, '18 - 24 years old':24, '25 - 34 years old':34, '35 - 44 years old':44,\n              '45 - 54 years old':54, '55 - 64 years old':64, '65 years or older':65}\n\nCompanySize_mapping ={'Fewer than 10 employees':10, '10 to 19 employees':19, \n                      '20 to 99 employees':99, '100 to 499 employees':499, '500 to 999 employees':999, \n                      '1,000 to 4,999 employees':4999, '5,000 to 9,999 employees':9999,\n                     '10,000 or more employees':20000}\n\nExercise_mapping = {'I don\\'t typically exercise':0, '1 - 2 times per week':2, \n                    '3 - 4 times per week':4, 'Daily or almost every day':7}\n\nHoursComputer_mapping = {'Less than 1 hour':1, '1 - 4 hours':4, '5 - 8 hours':8, '9 - 12 hours':12, 'Over 12 hours':15}\n\nHoursOutside_mapping = {'Less than 30 minutes':0.5, '30 - 59 minutes':1, '1 - 2 hours':2, '3 - 4 hours':4, 'Over 4 hours':6}\n\nLastNewJob_mapping = {'I\\'ve never had a job':0, 'Less than a year ago':1, 'Between 1 and 2 years ago':2, \n                      'Between 2 and 4 years ago':4, 'More than 4 years ago': 5}\n\nSkipMeals_mapping = {'Never':0, '1 - 2 times per week':2, '3 - 4 times per week':4, 'Daily or almost every day':7}\n\nStackOverflowJobsRecommend_mapping = {'0 (Not Likely)':0, '1':1, '2':2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9,\n                                      '10 (Very Likely)':10}\n\nYearsCoding_mapping ={'0-2 years':2, '3-5 years':5, '6-8 years': 8, '9-11 years':11, '12-14 years':14, '15-17 years':17,\n                      '18-20 years':20, '21-23 years':23, '24-26 years':26, \n                      '27-29 years':29, '30 or more years':25}\n\nYearsCodingProf_mapping = YearsCoding_mapping","fbb481b2":"mapping('Age', Age_mapping)\nmapping('CompanySize', CompanySize_mapping)\nmapping('Exercise', Exercise_mapping)\nmapping('HoursComputer', HoursComputer_mapping)\nmapping('HoursOutside', HoursOutside_mapping)\nmapping('LastNewJob', LastNewJob_mapping)\nmapping('SkipMeals', SkipMeals_mapping)\nmapping('StackOverflowJobsRecommend', StackOverflowJobsRecommend_mapping)\nmapping('YearsCoding', YearsCoding_mapping)\nmapping('YearsCodingProf', YearsCodingProf_mapping)","92e57433":"count_col = ['DevType', 'CommunicationTools', 'FrameworkWorkedWith'] \nfor i in count_col:\n    X_train[i + '_count'] = X_train[i].apply(lambda x: len(re.split('\\s*;\\s*', x)))\n    X_test[i + '_count'] = X_test[i].apply(lambda x: len(re.split('\\s*;\\s*', x)))","1315623a":"X_train['Github'] = X_train['CommunicationTools'].str.contains('Github')\nX_test['Github'] = X_test['CommunicationTools'].str.contains('Github')\n\nX_train['Full-stack'] = X_train['DevType'].str.contains('Full-stack')\nX_test['Full-stack'] = X_test['DevType'].str.contains('Full-stack')\n\nX_train['DataScientist'] = X_train['DevType'].str.contains('Data scientist')\nX_test['DataScientist'] = X_test['DevType'].str.contains('Data scientist')","862e5ca1":"del X_train['Country']\ndel X_test['Country']\n\ndel X_train['DevType']\ndel X_test['DevType']\n\ndel X_train['CommunicationTools']\ndel X_test['CommunicationTools']\n\ndel X_train['FrameworkWorkedWith']\ndel X_test['FrameworkWorkedWith']\n\n#\u4e0d\u8981\u3068\u601d\u3048\u308b\u3082\u306e\u3082\u524a\u9664\ndel X_train['MilitaryUS']\ndel X_test['MilitaryUS']\n\ndel X_train['SurveyTooLong']\ndel X_test['SurveyTooLong']\n\ndel X_train['SurveyEasy']\ndel X_test['SurveyEasy']","a908d408":"X_train['AssessJob_null'] = X_train['AssessJob1'].isnull().astype(int)\nX_test['AssessJob_null'] = X_test['AssessJob1'].isnull().astype(int)\nX_train['AssessBenefits_null'] = X_train['AssessBenefits1'].isnull().astype(int)\nX_test['AssessBenefits_null'] = X_train['AssessBenefits1'].isnull().astype(int)\nX_train['JobContactPriorities_null'] = X_train['JobContactPriorities1'].isnull().astype(int)\nX_test['JobContactPriorities_null'] = X_test['JobContactPriorities1'].isnull().astype(int)\nX_train['JobEmailPriorities_null'] = X_train['JobEmailPriorities1'].isnull().astype(int)\nX_test['JobEmailPriorities_null'] = X_train['JobEmailPriorities1'].isnull().astype(int)\n\nX_train['questionaare_missing_count'] = X_train['AssessJob_null'] + X_train['AssessBenefits_null'] + X_train['JobContactPriorities_null'] + X_train['JobEmailPriorities_null']\nX_test['questionaare_missing_count'] = X_test['AssessJob_null'] + X_test['AssessBenefits_null'] + X_test['JobContactPriorities_null'] + X_test['JobEmailPriorities_null']\n\ndel X_train['AssessJob_null']\ndel X_test['AssessJob_null']\ndel X_train['AssessBenefits_null']\ndel X_test['AssessBenefits_null']\ndel X_train['JobContactPriorities_null']\ndel X_test['JobContactPriorities_null']\ndel X_train['JobEmailPriorities_null']\ndel X_test['JobEmailPriorities_null']","8db7cb97":"# X_train[X_train['AssessJob_null'] >0]\n# X_train.head(50)","c8b02b81":"col_yj_transform = ['GDP ($ per capita)']\n\nfor col in col_yj_transform:\n    pt = PowerTransformer(method='yeo-johnson')\n    reshape_train = X_train[col].values.reshape(-1,1)\n    reshape_test = X_test[col].values.reshape(-1,1)     \n    pt.fit(reshape_train)\n    X_train[col] = pt.transform(reshape_train)\n    X_test[col] = pt.transform(reshape_test)","c92b5cd7":"cats = []\nfor col in X_train.columns:\n    if (X_train[col].dtype == 'object'):\n        cats.append(col)\n     \n        print(col, X_train[col].nunique())","581959f3":"# for count_col in cats:\n#     summary = X_all[count_col].value_counts() #X_all\u306b\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\n\n\nordinal_col = cats\nordinal_encoder = OrdinalEncoder(cols = ordinal_col)\nX_train = ordinal_encoder.fit_transform(X_train)\nX_test = ordinal_encoder.transform(X_test)","03998215":"X_train.fillna(-9999, inplace = True)\nX_test.fillna(-9999, inplace = True)","655395bc":"X_train","bf5a3122":"for col in X_train.columns:\n    print(X_train[col].value_counts())\n    print('____')","14d629df":"# #######\n# tfidf = TfidfVectorizer(max_features = 50)\n\n# TXT_train_DevType = tfidf.fit_transform(TXT_train_DevType)\n# TXT_test_DevType = tfidf.transform(TXT_test_DevType)\n\n# X_train = sp.sparse.hstack([X_train, TXT_train_DevType])\n# X_test = sp.sparse.hstack([X_test, TXT_test_DevType])\n\n# X_train = pd.DataFrame(X_train.todense())\n# X_test = pd.DataFrame(X_test.todense())\n\n# #######\n# tfidf = TfidfVectorizer(max_features = 50)\n\n# TXT_train_CommunicationTools = tfidf.fit_transform(TXT_train_CommunicationTools)\n# TXT_test_CommunicationTools = tfidf.transform(TXT_test_CommunicationTools)\n\n# X_train = sp.sparse.hstack([X_train, TXT_train_CommunicationTools])\n# X_test = sp.sparse.hstack([X_test, TXT_test_CommunicationTools])\n\n# X_train = pd.DataFrame(X_train.todense())\n# X_test = pd.DataFrame(X_test.todense())\n\n# #######\n# tfidf = TfidfVectorizer(max_features = 50)\n\n# TXT_train_FrameworkWorkedWith = tfidf.fit_transform(TXT_train_FrameworkWorkedWith)\n# TXT_test_FrameworkWorkedWith = tfidf.transform(TXT_test_FrameworkWorkedWith)\n\n# X_train = sp.sparse.hstack([X_train, TXT_train_FrameworkWorkedWith])\n# X_test = sp.sparse.hstack([X_test, TXT_test_FrameworkWorkedWith])\n\n# X_train = pd.DataFrame(X_train.todense())\n# X_test = pd.DataFrame(X_test.todense())\n","979fcacd":"X_train","f0f11eca":"%%time\n\nnum_split = 5\nnum_iter = 3\nstop_round = 50\nscores = []\ny_pred_cva = np.zeros(len(X_test)) #cva\u30c7\u30fc\u30bf\u53ce\u7d0d\u7528\n\nscores = []\n\nfor h in range (num_iter):\n    kf = KFold(n_splits=num_split, random_state=h, shuffle=True)\n\n    for i, (train_ix, test_ix) in tqdm(enumerate(kf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n        clf = LGBMRegressor(n_estimators=9999, random_state=71, colsample_bytree=0.9,\n                            learning_rate=0.05, min_child_samples=20, #max_depth=-1,\n                            min_child_weight=0.001, min_split_gain=0.0, num_leaves=15) \n           \n        clf.fit(X_train_, y_train_, early_stopping_rounds=stop_round, eval_metric='rmse', eval_set=[(X_val, y_val)])  \n\n        y_pred = clf.predict(X_val)\n        score = mean_squared_error(y_val, y_pred)**0.5 #RMSE\u3060\u304c\u3001\u65e2\u306blog\u5909\u63db\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u5b9f\u8ceaRMSLE\n        scores.append(score)\n\n        y_pred_cva += clf.predict(X_test)\n        print(clf.predict(X_test))\n            \n        \nprint(np.mean(scores))\nprint(scores)\n\ny_pred_cva \/= (num_split * num_iter)","5503bf37":"y_pred_exp = np.exp(y_pred_cva) - 1\ny_pred_exp","e785ebc0":"imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(by=['importance'], ascending=False)\nimp.head(50)","9efbbe49":"fig, ax = plt.subplots(figsize=(20, 10))\nlgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","4566078e":"submission = pd.read_csv('..\/input\/exam-for-students20200129\/sample_submission.csv', index_col=0)\n\nsubmission.ConvertedSalary = y_pred_exp","a6a2892b":"# submission[target] = submission[target].apply(round)\n\n# max_threshold = 2000000\n# min_threshold = 1000\n\n# submission.loc[submission[target] > max_threshold, target] = max_threshold\n# submission.loc[submission[target] < min_threshold, target] = 0","7ccd4f73":"submission.to_csv('submission.csv')\nsubmission","9d5e1453":"### \u30c6\u30ad\u30b9\u30c8\u7528\u306b\u907f\u96e3\uff08\u7d50\u5c40\u3044\u3089\u306a\u3044\uff09","1e843e63":"### \u30c6\u30ad\u30b9\u30c8\u306e\u6b20\u640d\u88dc\u5b8c","d873d2e6":"### AssessJob, AssessBenefits, JobContactPriorities, JobEmailPriorities\u7cfb\u306e\u6b20\u640d\u7279\u5fb4\u91cf","84471948":"## \u5916\u308c\u5024\u9664\u304f\uff08\u7d50\u5c40\u3057\u306a\u3044\uff09","19898811":"# Modelling (LGBM with CV&seed averaging)","3f343429":"## \u5909\u6570\u91cd\u8981\u5ea6","c0252fc3":"## \u30de\u30c3\u30d4\u30f3\u30b0\uff08\u3059\u308b\u306e\u306f\u4e00\u90e8\u3060\u3051\uff09","7c134ec1":"### ;\u3092\u6570\u3048\u308b","84fe94a4":"# EDA","1cc7983d":"## \u5f8c\u51e6\u7406\uff08\u7cbe\u5ea6\u843d\u3061\u305f\u306e\u3067\u3057\u306a\u3044\uff09","b2b75eab":"## \u5916\u90e8\u30c7\u30fc\u30bf\u63a5\u7d9a","306cb125":"# x\u3068y\u306b\u5206\u5272","45f5c087":"### Github\u4f7f\u3063\u3066\u3066\u6b32\u3057\u3044","adc16d91":"## \u30c6\u30ad\u30b9\u30c8\u51e6\u7406\uff08\u7cbe\u5ea6\u843d\u3061\u305f\u3001Github\u3084;\u306a\u3069\u4e00\u90e8\u306e\u307f\u4f7f\u3046\uff09","0f555000":"### yeo-johnson","15405d54":"# Submission","503c87f2":"# \u3053\u3053\u3088\u308a\u4e0a\u306f\u57fa\u672c\u7684\u306b\u6700\u521d\u3057\u304b\u56de\u3055\u306a\u3044\u3002"}}