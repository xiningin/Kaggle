{"cell_type":{"59981224":"code","b71256e5":"code","caf0a687":"code","d0754288":"code","9acc4bff":"code","42fa5b39":"code","7166baac":"code","234ab06d":"code","64d5122e":"code","076f192e":"markdown","747e73fc":"markdown","b6ee665c":"markdown","7bfb1dc7":"markdown","22391e49":"markdown"},"source":{"59981224":"from nltk.corpus import brown\nfrom nltk import FreqDist\n\nsuffix_fdist = FreqDist()\nfor word in brown.words():\n    word = word.lower()\n    suffix_fdist[word[-1:]] += 1\n    suffix_fdist[word[-2:]] += 1\n    suffix_fdist[word[-3:]] += 1\n    \nsuffix_fdist","b71256e5":"common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\ncommon_suffixes[:10]","caf0a687":"def pos_features(word):\n    features = {}\n    for suffix in common_suffixes:\n        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n    return features\n\npos_features('test')","d0754288":"tagged_words = brown.tagged_words(categories='news')\nfeaturesets = [(pos_features(n), g) for (n,g) in tagged_words]\nfeaturesets[0]","9acc4bff":"from nltk import DecisionTreeClassifier\nfrom nltk.classify import accuracy\n\ncutoff = int(len(featuresets) * 0.1)\ntrain_set, test_set = featuresets[cutoff:], featuresets[:cutoff]","42fa5b39":"classifier = DecisionTreeClassifier.train(train_set) # NLTK is a teaching toolkit which is not really optimized for speed. Therefore, this may take forever. For speed, use scikit-learn for the classifiers.","7166baac":"accuracy(classifier, test_set)","234ab06d":"classifier.classify(pos_features('cats'))","64d5122e":"classifier.pseudocode(depth=4)","076f192e":"# Creating a POS Tagger","747e73fc":"We can train a classifier to work out which suffixes are most informative for POS tagging. We can begin by finding out what the most common suffixes are","b6ee665c":"To improve the classifier, we can add contextual features:\n\n```py\ndef pos_features(sentence, i): [1]\n    features = {\"suffix(1)\": sentence[i][-1:],\n                \"suffix(2)\": sentence[i][-2:],\n                \"suffix(3)\": sentence[i][-3:]}\n    if i == 0:\n        features[\"prev-word\"] = \"<START>\"\n    else:\n        features[\"prev-word\"] = sentence[i-1]\n    return features\n```\n\nThen, instead of working with tagged words, we work with tagged sentences:\n```py\ntagged_sents = brown.tagged_sents(categories='news')\n```\n\nWe can then improve this further by adding more features such as `prev-tag` etc.","7bfb1dc7":"Next, we'll define a feature extractor function which checks a given word for these suffixes:","22391e49":"Now that we've defined our feature extractor, we can use it to train a new decision tree classifier:"}}