{"cell_type":{"eaed6682":"code","97427118":"code","7e6924a0":"code","9e934e58":"code","5716d446":"code","de16b175":"code","3aca634b":"code","f7d4cc99":"code","2af10299":"code","b680cadb":"code","9433b6b8":"code","d8bbb287":"code","3d07e2fa":"code","b446d7f1":"code","a2d8c504":"code","fba6b08f":"code","b5cc3fa7":"code","0bc6f167":"code","5a854a46":"code","c0ef5063":"code","b825b5cb":"code","1587d3a6":"code","da2e6613":"code","b08b3abe":"code","78c6fba9":"markdown","85a7a5da":"markdown","19703e52":"markdown","260b6a21":"markdown","d5cca95b":"markdown","0fc2b68c":"markdown","f05c962b":"markdown","e5713935":"markdown","34e2afa4":"markdown","49b9d267":"markdown","fa0b288e":"markdown","6cbb46c6":"markdown","11d1e97e":"markdown","b1715233":"markdown","f24b9a60":"markdown"},"source":{"eaed6682":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","97427118":"dataset = pd.read_csv(\"..\/input\/machine-learning-for-diabetes-with-python\/diabetes_data.csv\")\ndataset.head(222)","7e6924a0":"import pandas_profiling as pf\npf.ProfileReport(dataset)","9e934e58":"dataset.groupby(\"Outcome\").hist(figsize=(9,9))","5716d446":"dataset.drop(['Pregnancies', 'BloodPressure', 'SkinThickness', 'BMI'], axis = 1)","de16b175":" df = dataset.drop(['Pregnancies', 'BloodPressure', 'SkinThickness', 'BMI'], axis = 1) # dropping columns which are not necessary","3aca634b":"x = df.iloc[: , :-1].values\ny = df.iloc[: , -1].values  ","f7d4cc99":"print(x)","2af10299":"print(y)","b680cadb":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y , test_size = 0.2, random_state = 1)","9433b6b8":"print(x_train)","d8bbb287":"print(x_test)","3d07e2fa":"print(y_train)","b446d7f1":"print(y_test)","a2d8c504":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","fba6b08f":"print(x_train)","b5cc3fa7":"print(x_test)","0bc6f167":"from sklearn.neighbors import KNeighborsClassifier\ntraining_accuracy = [] \ntest_accuracy = [] \nneighbors_settings = range(1,100)\nfor n_neighbors in neighbors_settings:\n    knn = KNeighborsClassifier(n_neighbors= n_neighbors)\n    knn.fit(x_train, y_train)\n    training_accuracy.append(knn.score(x_train,y_train))\n    test_accuracy.append(knn.score(x_test,y_test))\nplt.plot(neighbors_settings, training_accuracy, label='training accuracy')\nplt.plot(neighbors_settings, test_accuracy, label='test accuracy')\nplt.xlabel('Accuracy')\nplt.ylabel('n_neighbors')\nplt.legend()\nplt.show()","5a854a46":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2) # I used n_neighbors = 5 as there are major 5 - 6 points , though 6 wasn't predicting as high accuracy as 5\nclassifier.fit(x_train, y_train)","c0ef5063":"y_pred = classifier.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","b825b5cb":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nneighbors_settings = range(1,100)\naccuracy_score(y_test, y_pred) ","1587d3a6":"pearsoncorr = df.corr(method='pearson')\npearsoncorr","da2e6613":"import seaborn as sb","b08b3abe":"sb.heatmap(pearsoncorr, \n            xticklabels=pearsoncorr.columns,\n            yticklabels=pearsoncorr.columns,\n            cmap='RdBu_r',\n            annot=True,\n            linewidth=0.5)","78c6fba9":"# Visualizing the training and test set","85a7a5da":"# Training the K-NN model on the Training set","19703e52":"# K- Nearest Neighbors","260b6a21":"# Making the Confusion Matrix","d5cca95b":"Now, we are splitting the data into training set and test set using scikit-Learn's built in train_test_split() method.","0fc2b68c":"# Feature Scaling","f05c962b":"The accuracy score after performing KNN is 78 %","e5713935":"# Visualizing  the values of x and y","34e2afa4":"# Importing the dataset","49b9d267":"# Splitting the data into training set and test set","fa0b288e":"# Calculating Pearson correlation","6cbb46c6":"# Predicting the Test set results","11d1e97e":"# Dropping all the non- important columns","b1715233":"# Importing the libraries","f24b9a60":"# Visualizing  all the different data"}}