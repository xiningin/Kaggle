{"cell_type":{"ec9a4af3":"code","e0a38eee":"code","6eb359ae":"code","ddbf2a3b":"code","ceb5904e":"code","359fe8c1":"code","0772b941":"code","9ba22889":"code","5dc44bb7":"markdown","a6558635":"markdown","6c66759e":"markdown","5f3491c0":"markdown","3c3ac8a6":"markdown"},"source":{"ec9a4af3":"# First we get an idea for the dataset. What form is it in? How many directories and groups. \nimport os\nfor dirpath, dirnames, filenames in os.walk('\/kaggle\/input'):\n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","e0a38eee":"#We can see that we have 3 directories (Train, Test,Validation), and 10 categories. \n#Lets create the directories we will need\ntrain_dir= '\/kaggle\/input\/imagenettetvt320\/train\/'\ntest_dir= '\/kaggle\/input\/imagenettetvt320\/test\/'\nvalidation_dir= '\/kaggle\/input\/imagenettetvt320\/val\/'","6eb359ae":"#now we load our data into data sets\n# Create data inputs\n\nimport tensorflow as tf\n\nIMG_SIZE = (224, 224) #Define image size\n\n\ntrain_data_ImageNet320 = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n                                                                            image_size=IMG_SIZE,\n                                                                            label_mode=\"categorical\",\n                                                                            batch_size=32)\n\ntest_data_ImageNet320=tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n                                                                         image_size=IMG_SIZE,\n                                                                         label_mode=\"categorical\",\n                                                                         batch_size=32)\nValidation_data_ImageNet320=tf.keras.preprocessing.image_dataset_from_directory(directory=validation_dir,\n                                                                         image_size=IMG_SIZE,\n                                                                         label_mode=\"categorical\",\n                                                                         batch_size=32)","ddbf2a3b":"from tensorflow.keras import Sequential, layers\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Rescaling, Activation, Dropout\n\nmodel = tf.keras.Sequential([\n    Conv2D(32, (3,3), input_shape = (224 , 224 , 3), activation = 'relu'),\n    MaxPool2D(3,3),\n    Conv2D(64, (3,3) , activation = 'relu'),\n    MaxPool2D((3,3)),\n    Conv2D(128 , (3,3) , activation = 'relu'),\n    layers.MaxPool2D(3,3),\n    layers.Flatten(),\n    layers.Dropout(0.5, seed = 5),\n    Dense(150 , activation = 'relu'),\n    Dense(10 , activation = 'softmax')])\n","ceb5904e":"model.summary()","359fe8c1":"model.compile(loss=\"categorical_crossentropy\", # changed to categorical_crossentropy\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                metrics=[\"accuracy\"])\n\nhistory_ImageNet320_model = model.fit(train_data_ImageNet320,\n                                     epochs=30,\n                                     verbose=1,\n                                     steps_per_epoch=len(train_data_ImageNet320),\n                                     validation_data=test_data_ImageNet320,                                     \n                                     validation_steps=int(0.25*len(test_data_ImageNet320)))","0772b941":"  import matplotlib.pyplot as plt\n  history = history_ImageNet320_model\n    \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","9ba22889":"model.evaluate(test_data_ImageNet320)","5dc44bb7":"This model is only meant to be an introduction to building a layers convolution network. We will not introduce the process of augmenting the dataset. This would increase our data volume and give us a much higher level of accuracy. Augmenting data is a useful feature. It refers to taking each original object we are trying to classify and making a copy by altering the image slightly. This can be thought of as shifting, flipping, zooming in or out, or any other action which changes the image slightly but keeps the original features of the image within it. It increase training data set size and give our model the ability to extract the same features from multiple versions of the same object. We will introduce it in a follow up section to this model and show just how powerful it can be.","a6558635":"Plot the training loss and validation loss to see if out models are over or under fitting. The loss is the value of the cost function for the cross validation data and the training data. The primary difference being during the training period we are making changes to the network and altering the weights of each node, so we expect to see the loss changing up and down. During the validation period we are running a test set through the model and we do not want to see the val_loss jumping up and down. This volatility represents over\/under fitting the models. We are making to many changes to the weights in our model based on noise in the data. This is not good!!! We want smooth val_loss lines that trend to minimum loss and maximum accuracy. ","6c66759e":"A side note. I ran this with 65 epochs and reached around 75% accuracy on the valadidation set. With the limited power for online processing I reduced it to 15 epochs. This is where the lower accuracy comes from.\n\nIn this notebook we have opened and read in the Imagenet320 data set. We took a quick peak inside to see what was there and then wrote a basic classification model. We received moderate results using only a few layers. \n\nI will add a new section to this over the next few weeks when I have some time. \n\nI will introduce data augmentation and extra layers. I will also fine tune the hyper-parameters to see if we can reach usable accuracy. Something in the +90% range. \n\nThen I will use transfer learning to reach 99% in 5 lines and show how powerful some prebuilt models are. \n\n\nI hope whoever reads this find its a little helpful and can show you a good starting place to build a simple model.\n","5f3491c0":"Now we will build a basic model. We use Convolution layers followed by pooling layers. The convolution layer will take small sections of the whole image and attempt to extract a feature from that window. Here we have images of size 224x224 with 3 colour dimensions. We take windows of 3x3 pixels and attempt to label the patter of numbers in that window as a feature. \n\nNext we follow the convolution layer by a max pooling layer. It takes the max value inside the window, here we defined it as the same as our feature extraction window, and replaces that grid of 3x3 numbers with a single value. This means it is down sampling along a maximum value. We will replace each 3x3 grid with 1 value. Then we move back to a convolution layer and repeat feature extraction followed by sampling. \n\nNext we flatten out the data. This does exactly what it sounds like and flattens the batch of data into a single axis unit. It can be thought of if you have a 3x3 array with 3 layers, we will get an object of 1x27 shape.\n\nThen we drop out some of the features. We have a dropout of .5 meaning we only use 50% of the connections to avoid over fitting the model. \n\nLast we use 2 Dense layers. These are fully connected hidden layers in which all nodes are connected to the output layer. The 2nd layer is our output layer with the 10 nodes equating to our 10 classes.","3c3ac8a6":"# Image Classification for Imagenettetvt320 Dataset\nThis notebook will build a simple multi-layer CNN to classify the images if the ImageNettvt320 data set into their 10 predefined groups. There are  multiple methods we can use for classification models. The most optimal would being to use transfer learning. This means to bring in an exisiting model which is already trained on this sort of task from another resource. These can be found on the tensorflow main site. Once you bring in the body of a model you would only need to develope the input and output layers and compile the three pieces into a single model. This way we could achieve close to 99% accuracy in a few lines. \n\nInstead I will use simple functions and a very simple model to show that with minimal effort and complexity we can still achieve reasonable results without to much effort. This model will have only 6 or 7 layers, verses 250 layers in a prebuilt model. \n\nThis notebook is designed to help introduce basic model building. Transfer learning is used most often and much more powerful, but it is harder to start with. We need to build models from scratch to understand how all the layers work. \n\n\n\n<em> This notebook is intended to explain some of the underlying reasons we build the model the way we do and what each layer is doing, what some outputs\/parameters of the model represents. I will expand and add to the notebook over time. <\/em>"}}