{"cell_type":{"95e7600c":"code","3413ce0e":"code","dfd879ae":"code","b1b8cbd6":"code","7593f6d4":"code","4ba1c98d":"code","c6ef94b2":"code","0bba7f29":"code","1255451a":"code","e63a2de7":"code","9f3fc5dc":"code","041f65cd":"code","121f4436":"code","9d210d5b":"code","60cea07a":"code","1eca734c":"code","f6e77245":"code","9966c312":"code","5843c631":"code","b4e17034":"code","23c28d3c":"markdown","23758feb":"markdown","3dc63a04":"markdown","db5c3662":"markdown","3ac26fed":"markdown","eb1821b2":"markdown","933bdcef":"markdown","5c23ceed":"markdown","284b14e7":"markdown","ca61c257":"markdown","ef93cfc0":"markdown","b9d8dc2d":"markdown","e7138d40":"markdown","aac876cf":"markdown","45addf4a":"markdown","57836977":"markdown","5caea006":"markdown","c33dc57c":"markdown","de97f38e":"markdown","ccda5f94":"markdown","e4f98274":"markdown"},"source":{"95e7600c":"import pandas as pd                                     # Data analysis and manipultion tool\nimport numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\nimport tensorflow as tf                                 # Deep Learning Tool\nimport os                                               # OS module in Python provides a way of using operating system dependent functionality\nimport cv2                                              # Library for image processing\nfrom sklearn.model_selection import train_test_split    # For splitting the data into train and validation set","3413ce0e":"labels = pd.read_csv(\"..\/input\/face-mask-dataset\/train_labels.csv\")   # loading the labels\nlabels.head()           # will display the first five rows in labels dataframe","dfd879ae":"labels.tail()            # will display the last five rows in labels dataframe","b1b8cbd6":"file_paths = [[fname, '\/kaggle\/input\/face-mask-dataset\/train\/train\/' + fname] for fname in labels['filename']]\nfile_paths","7593f6d4":"# Confirm if number of images is same as number of labels given\nif len(labels) == len(file_paths):\n    print('Number of labels i.e. ', len(labels), 'matches the number of filenames i.e. ', len(file_paths))\nelse:\n    print('Number of labels does not match the number of filenames')","4ba1c98d":"#viewing any image from the train data.\nfrom IPython.display import Image\nImage('\/kaggle\/input\/face-mask-dataset\/train\/train\/Image_1000.jpg')","c6ef94b2":"images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\nimages.head()","0bba7f29":"train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\ntrain_data.head()       ","1255451a":"data = []     # initialize an empty numpy array\nimage_size = 100      # image size taken is 100 here. one can take other size too\nfor i in range(len(train_data)):\n\n\n    img_array = cv2.imread(train_data['filepaths'][i], cv2.IMREAD_GRAYSCALE)   # converting the image to gray scale\n\n    new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n\n    # encoding the labels. with_mask = 1 and without_mask = 0\n    if train_data['label'][i] == 'with_mask':\n        data.append([new_img_array, 1])\n    else:\n        data.append([new_img_array, 0])","e63a2de7":"# image pixels of a image\ndata[0]","9f3fc5dc":"# The shape of an image array\ndata = np.array(data)\ndata[0][0].shape","041f65cd":"np.random.shuffle(data)","121f4436":"import matplotlib.pyplot as plt","9d210d5b":"# code to view the images\nnum_rows, num_cols = 2, 5\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n                     squeeze=True)\n\nfor r in range(num_rows):\n    for c in range(num_cols):\n      \n        image_index = r * 100 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow( data[image_index][0], cmap='gray')\n        if data[image_index][1] == 0:\n          ax[r,c].set_title('without_mask')\n        else:\n          ax[r,c].set_title('with_mask')\nplt.show()\nplt.close()","60cea07a":"x = []\ny = []\nfor image in data:\n  x.append(image[0])\n  y.append(image[1])\n\n# converting x & y to numpy array as they are list\nx = np.array(x)\ny = np.array(y)","1eca734c":"np.unique(y, return_counts=True)","f6e77245":"x = x \/ 255\n\n# Why divided by 255?\n# --> The pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value.","9966c312":"# split the data\nX_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.3, random_state = 42)\n\n# X_train: independent\/input feature data for training the model\n# y_train: dependent\/output feature data for training the model\n# X_test: independent\/input feature data for testing the model; will be used to predict the output values\n# y_test: original dependent\/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n \n# test_size = 0.30: 30% of the data will go for test set and 70% of the data will go for train set\n# random_state = 42: this will fix the split i.e. there will be same split for each time you run the co","5843c631":"# Defining the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(100, 100)),    # flattening the image\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=10, batch_size = 20)","b4e17034":"model.evaluate(X_val, y_val)","23c28d3c":"#### Splitting the data into Train and Validation Set\nWe want to check the performance of the model that we built. For this purpose, we always split (both independent and dependent data) the given data into training set which will be used to train the model, and test set which will be used to check how accurately the model is predicting outcomes.\n\nFor this purpose we have a class called 'train_test_split' in the 'sklearn.model_selection' module.","23758feb":"#### Getting images file path","3dc63a04":"## Data Pre-processing\nIt is necessary to bring all the images in the same shape and size, also convert them to their pixel values because all machine learning or deep learning models accepts only the numerical data. Also we need to convert all the labels from categorical to numerical values.","db5c3662":"#### Take a look at some of the images","3ac26fed":"## Building Model\nNow we are finally ready, and we can train the model.\n\nThere are many machine learning or deep learning models like Random Forest, Decision Tree, Multi-Layer Perceptron (MLP), Convolution Neural Network (CNN), etc. to say you some.\n\nHowever here we are building a simple Multi-Layer Perceptron Model.\n\nThen we would feed the model both with the data (X_train) and the answers for that data (y_train)","eb1821b2":"#### Confirming if no. of labels is equal to no. of images","933bdcef":"![](https:\/\/images.pexels.com\/photos\/4472976\/pexels-photo-4472976.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500)","5c23ceed":"# Face Mask Detection","284b14e7":"#### Combining the labels with the images","ca61c257":"The 'train_data' dataframe contains all the image id, their locations and their respective labels. Now the training data is ready.","ef93cfc0":"Coronavirus has now become the talk of the town, most people in the world right now are suffering badly and every day thousands of people are dying because of COVID-19. As per WHO, face masks combined with other preventive measures such as frequent hand-washing and social distancing help slow down the spread of the coronavirus.","b9d8dc2d":"## Loading Libraries\nAll Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n\nWe chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, tensorlow --> tf).\n\nNote: You can import all the libraries that you think will be required or can import it as you go along.","e7138d40":"The model is giving 86% accuracy on unseen data. We can use some other models like CNN, Transfer Learnings, etc. to build a better model.","aac876cf":"## Validate the model\nWonder\ud83e\udd14 how well your model learned! Lets check its performance on the X_val data.","45addf4a":"# **Well Done! \ud83d\udc4d**","57836977":"#### Separating the images and labels\n","5caea006":"#### Getting the labels of the images","c33dc57c":"#### Shuffle the data\nThe first half images are without mask and the second half are with mask. So, when fitting a model it's necessary to train the model with both categories otherwise if model don't see the other category of images, it won't detect them.","de97f38e":"## Loading and preparing training data\nThe train and test images are given in two different folders - 'train' and 'test'. The labels of train images are given in a csv file 'Training_set_face_mask.csv' with respective image id (i.e. image file name).","ccda5f94":"#### Normalizing the data\nNormalization is a process that changes the range of pixel intensity values to the range 0 to 1.\n\nBut **why to normalize?**\n\nThe motivation to normalize is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction and reduce the data redundancy. Also, normalizing the data can help you improve the model performance.","e4f98274":"#### Converting the file_paths to dataframe"}}