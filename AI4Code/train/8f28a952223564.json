{"cell_type":{"a7bedd9a":"code","6a138e1a":"code","45c9c436":"code","b492462f":"code","6928f842":"code","2a939a7a":"code","bb454ab4":"code","a11be13c":"code","ebfa8932":"code","43f5b23f":"code","5c53c094":"code","71566813":"code","ccbad9ee":"code","539c3a52":"code","fcc50855":"code","61510078":"code","94e288b2":"code","60bb6ed6":"code","595a6ede":"code","eb753a4a":"code","0acd7485":"code","10e9c486":"code","0546f97a":"code","d7ac2a96":"code","b1a4c6f5":"code","c36ccb6a":"code","b28aae30":"code","85a84832":"code","3b32179a":"code","8440bf1a":"code","8f404b1b":"code","750873f2":"code","0e0a61ad":"code","dc7e63cb":"code","cf46594f":"code","1eea831c":"code","12815d73":"code","e859aac6":"code","f2653315":"code","99318fd1":"code","cd8921ec":"code","bc3301bd":"code","17fc6b9d":"code","dcdc509e":"code","d2ab9868":"code","2793448a":"code","692cea9c":"code","9b33b3da":"code","a9791482":"code","f796fec6":"code","003a5361":"code","1aaa1fad":"markdown","94bd5e17":"markdown","124331bc":"markdown","3fa490ad":"markdown","55c45eab":"markdown","69498d24":"markdown","900e9ecc":"markdown","bfd03975":"markdown","7e3fa04c":"markdown","83e1af57":"markdown","f832e610":"markdown","f80460d5":"markdown","7b2002cb":"markdown","5ee36cb6":"markdown","e7492c03":"markdown","2a766d13":"markdown","345ca612":"markdown","d5837ca7":"markdown","a44a3b7b":"markdown","345187ec":"markdown","ffb5548e":"markdown","a68f4e24":"markdown","d637a87f":"markdown","4d57bd3c":"markdown","6f9f17e4":"markdown"},"source":{"a7bedd9a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npalette = sns.color_palette('Paired', 10)\nplt.style.use('seaborn-darkgrid')\n\nRSEED = 42","6a138e1a":"data = pd.read_csv('..\/input\/train.csv', nrows = 1_000_000, \n                   parse_dates = ['pickup_datetime']).drop(columns = 'key')\n\ndata.dropna(inplace=True)\ndata.drop_duplicates(inplace=True)\ndata.head()","45c9c436":"data.info()","b492462f":"data.describe()","6928f842":"plt.figure(figsize = (10, 6))\nsns.distplot(data['fare_amount'])\nplt.title('Distribution of Fare');","2a939a7a":"print(\"Passagens com valor negativo: {}\".format(len(data[data['fare_amount'] < 0])))\nprint(\"Passagens com valor 0: {}\".format(len(data[data['fare_amount'] == 0])))\nprint(\"Passagens com valor maior : {}\".format(len(data[data['fare_amount'] > 100])))","bb454ab4":"data = data[data['fare_amount'].between(left = 2.5, right = 100)]","a11be13c":"# Discretiza os valores das passagens em faixas\ndata['fare-bin'] = pd.cut(data['fare_amount'], bins = list(range(0, 50, 5))).astype(str)\ndata.loc[data['fare-bin'] == 'nan', 'fare-bin'] = '[45+]'\n\n# Visualizando as faixas de valores\ndata.loc[data['fare-bin'] == '(5, 10]', 'fare-bin'] = '(05, 10]'\ndata['fare-bin'].value_counts().sort_index().plot.bar(color = 'b', edgecolor = 'k')\nplt.title('Fare Binned');","ebfa8932":"data['passenger_count'].value_counts().sort_index().plot.bar(color = 'b', edgecolor = 'k')\nplt.title('Passenger Counts')\nplt.xlabel('Number of Passengers')\nplt.ylabel('Count');","43f5b23f":"data = data.loc[data['passenger_count'] <= 6]","5c53c094":"print('Observas\u00f5es iniciais: {}'.format(data.shape[0]))","71566813":"for col in ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']:\n    print(f'{col.capitalize():17}: 2.5% = {round(np.percentile(data[col], 2.5), 2):5} \\t 97.5% = {round(np.percentile(data[col], 97.5), 2)}')","ccbad9ee":"# Remover latitude e longtiude outliers\ndata = data.loc[data['pickup_latitude'].between(40, 41)]\ndata = data.loc[data['pickup_longitude'].between(-74, -73)]\ndata = data.loc[data['dropoff_latitude'].between(40, 41)]\ndata = data.loc[data['dropoff_longitude'].between(-74, -73)]\n\nprint('Novas observa\u00e7\u00f5es: {}'.format(data.shape[0]))","539c3a52":"fig, axes = plt.subplots(1, 2, figsize = (20, 8), sharex=True, sharey=True)\naxes = axes.flatten()\n\n# Plot Longitude (x) e Latitude (y)\nsns.regplot('pickup_longitude', 'pickup_latitude', fit_reg = False, \n            data = data.sample(10000, random_state = RSEED), ax = axes[0]);\nsns.regplot('dropoff_longitude', 'dropoff_latitude', fit_reg = False, \n            data = data.sample(10000, random_state = RSEED), ax = axes[1]);\naxes[0].set_title('Pickup Locations')\naxes[1].set_title('Dropoff Locations');","fcc50855":"BB_zoom = (-74.1, -73.7, 40.6, 40.85)\nnyc_map_zoom = plt.imread(\"https:\/\/github.com\/WillKoehrsen\/Machine-Learning-Projects\/blob\/master\/images\/nyc_-74.1_-73.7_40.6_40.85.PNG?raw=true\")","61510078":"def plot_on_map(df, BB, nyc_map, s=10, alpha=0.2, color = False):\n    fig, axs = plt.subplots(2, 1, figsize=(18, 22))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=2)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Localiza\u00e7\u00f5es de embarque')\n    axs[0].axis('off')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='b', s=2)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Locais de desembarque')\n    axs[1].axis('off')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)","94e288b2":"plot_on_map(data.sample(500_000, random_state = RSEED), \n            BB_zoom, nyc_map_zoom, s=0.05, alpha=0.05)","60bb6ed6":"color_mapping = {fare_bin: palette[i] for i, fare_bin in enumerate(data['fare-bin'].unique())}\ncolor_mapping","595a6ede":"data['color'] = data['fare-bin'].map(color_mapping)\nplot_data = data.sample(500_000, random_state = RSEED)","eb753a4a":"BB = BB_zoom\n\nfig, axs = plt.subplots(1, 1, figsize=(20, 18))\n\n\nfor b, df in plot_data.groupby('fare-bin'):\n    axs.scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=0.2, c=df.color, s=30, label = f'{b}')\n    axs.set_xlim((BB[0], BB[1]))\n    axs.set_ylim((BB[2], BB[3]))\n    axs.set_title('Localiza\u00e7\u00f5es de embarque', size = 32)\n    axs.axis('off')\n    \n# Legenda\nleg = axs.legend(fontsize = 20, markerscale = 3)\n\nfor lh in leg.legendHandles: \n    lh.set_alpha(1)\n\nleg.set_title('Tarifa', prop = {'size': 28})\n\naxs.imshow(nyc_map_zoom, zorder=0, extent=BB_zoom);","0acd7485":"fig, axs = plt.subplots(1, 1, figsize=(20, 18))\n\n\nfor b, df in plot_data.groupby('fare-bin'):\n    axs.scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, \n                alpha=0.2, c=df.color, s=30, label = f'{b}')\n    axs.set_xlim((BB[0], BB[1]))\n    axs.set_ylim((BB[2], BB[3]))\n    axs.set_title('Localiza\u00e7\u00f5es de desembarque', size = 32)\n    axs.axis('off')\n    \n# Legenda\nleg = axs.legend(fontsize = 20, markerscale = 3)\n\nfor lh in leg.legendHandles: \n    lh.set_alpha(1)\n\nleg.set_title('Tarifa', prop = {'size': 28})\n\naxs.imshow(nyc_map_zoom, zorder=0, extent=BB_zoom);","10e9c486":"data['abs_lat_diff'] = (data['dropoff_latitude'] - data['pickup_latitude']).abs()\ndata['abs_lon_diff'] = (data['dropoff_longitude'] - data['pickup_longitude']).abs()","0546f97a":"sns.lmplot('abs_lat_diff', 'abs_lon_diff', fit_reg = False,\n           data = data.sample(10000, random_state=RSEED));\nplt.title('Absolute latitude difference vs Absolute longitude difference');","d7ac2a96":"data.shape, ((data['abs_lat_diff'] == 0) & (data['abs_lon_diff'] == 0)).sum()","b1a4c6f5":"no_diff = (data['abs_lat_diff'] == 0) & (data['abs_lon_diff'] == 0)\ndata = data.loc[~no_diff]\ndata.shape","c36ccb6a":"sns.lmplot('abs_lat_diff', 'abs_lon_diff', hue = 'fare-bin', height = 8, palette=palette,\n           fit_reg = False, data = data.sample(10000, random_state=RSEED))\nplt.title('Absolute latitude difference vs Absolute longitude difference');","b28aae30":"def minkowski_distance(x1, x2, y1, y2, p):\n    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 \/ p)","85a84832":"print('Minkowski: {} \\nEuclidiana: {}'.format(minkowski_distance(0, 3, 0, 4, 1), minkowski_distance(0, 3, 0, 4, 2)))","3b32179a":"data['manhattan'] = minkowski_distance(data['pickup_longitude'], data['dropoff_longitude'],\n                                       data['pickup_latitude'], data['dropoff_latitude'], 1)\n\nplt.figure(figsize = (12, 6))\n\nfor f, grouped in data.groupby('fare-bin'):\n    sns.kdeplot(grouped['manhattan'], label = f'{f}')\n\nplt.xlabel('degrees')\nplt.ylabel('density')\nplt.title('Manhattan Distance by Fare Amount');","8440bf1a":"data.groupby('fare-bin')['manhattan'].agg(['mean', 'count'])","8f404b1b":"data['euclidean'] = minkowski_distance(data['pickup_longitude'], data['dropoff_longitude'],\n                                       data['pickup_latitude'], data['dropoff_latitude'], 2)\n\nplt.figure(figsize = (12, 6))\nfor f, grouped in data.groupby('fare-bin'):\n    sns.kdeplot(grouped['euclidean'], label = f'{f}')\n\nplt.xlabel('degrees')\nplt.ylabel('density')\nplt.title('Euclidean Distance by Fare Amount');","750873f2":"data.groupby('fare-bin')['euclidean'].agg(['mean', 'count'])","0e0a61ad":"# Radius of the earth in kilometers\nR = 6378\n\ndef haversine_distance(lon1, lat1, lon2, lat2):\n    # Converte latitude e longitude para radiano\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    # Calcula diferen\u00e7a entre latitude e longitude\n    diffLat = lat2 - lat1\n    diffLon = lon2 - lon1\n    \n    # Aplicando a formula \n    distance = 2 * R * np.arcsin( np.sqrt( np.square(np.sin(diffLat\/2)) + np.cos(lat1) * np.cos(lat2) * np.square(np.sin(diffLon\/2)) ) )\n    \n    return distance","dc7e63cb":"data['haversine'] = haversine_distance(data['pickup_longitude'], data['dropoff_longitude'],\n                                       data['pickup_latitude'], data['dropoff_latitude'])\n\nplt.figure(figsize = (12, 6))\nfor f, grouped in data.groupby('fare-bin'):\n    sns.kdeplot(grouped['haversine'], label = f'{f}')\n\nplt.xlabel('distance')\nplt.ylabel('density')\nplt.title('Haversine Distance by Fare Amount');","cf46594f":"data.groupby('fare-bin')['haversine'].agg(['mean', 'count'])","1eea831c":"data['pickup_datetime'].head()","12815d73":"def info_from_pickup_datetime(data):\n    data['year_pickup'] = data['pickup_datetime'].dt.year\n    data['month_pickup'] = data['pickup_datetime'].dt.month\n    data['day_pickup'] = data['pickup_datetime'].dt.day\n    data['hour_pickup'] = data['pickup_datetime'].dt.hour","e859aac6":"info_from_pickup_datetime(data)","f2653315":"data.head()","99318fd1":"data.corr()","cd8921ec":"corrs = data.corr()\nplt.figure(figsize=(8,8))\ncorrs['fare_amount'].plot.bar(color = 'b');\nplt.title('Correlation with Fare Amount');","bc3301bd":"data.to_csv('data.csv', index=False)","17fc6b9d":"fare = data['fare-bin']\ndata.drop(labels=['pickup_datetime', 'fare-bin'], axis=1, inplace=True)","dcdc509e":"data.head()","d2ab9868":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore', category = RuntimeWarning)\n","2793448a":"lr = LinearRegression()","692cea9c":"X_train, X_valid, y_train, y_valid = train_test_split(data, np.array(data['fare_amount']), \n                                                      stratify = fare,\n                                                      random_state = RSEED, test_size = 0.2)","9b33b3da":"lr.fit(X_train[['abs_lat_diff', 'abs_lon_diff', 'passenger_count']], y_train)","a9791482":"def metrics(train_pred, valid_pred, y_train, y_valid):\n    # Calculando mean squared error\n    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))\n    \n    # Calculando absolute percentage error\n    train_ape = abs((y_train - train_pred) \/ y_train)\n    valid_ape = abs((y_valid - valid_pred) \/ y_valid)\n    \n    # Colocando os infinitos para zerp\n    train_ape[train_ape == np.inf] = 0\n    train_ape[train_ape == -np.inf] = 0\n    valid_ape[valid_ape == np.inf] = 0\n    valid_ape[valid_ape == -np.inf] = 0\n    \n    # Fazendo o percentual     \n    train_mape = 100 * np.mean(train_ape)\n    valid_mape = 100 * np.mean(valid_ape)\n    \n    return train_rmse, valid_rmse, train_mape, valid_mape\n\ndef evaluate(model, features, X_train, X_valid, y_train, y_valid):\n    # Fazendo a predi\u00e7\u00e3o com o modelo\n    train_pred = model.predict(X_train[features])\n    valid_pred = model.predict(X_valid[features])\n    \n    # Obtendo os resuktados das metricas\n    train_rmse, valid_rmse, train_mape, valid_mape = metrics(train_pred, valid_pred,\n                                                             y_train, y_valid)\n         \n    print(f'Training:   rmse = ${round(train_rmse, 2)} \\t mape = {round(train_mape, 2)}%')\n    print(f'Validation: rmse = ${round(valid_rmse, 2)} \\t mape = {round(valid_mape, 2)}%')","f796fec6":"evaluate(lr, ['abs_lat_diff', 'abs_lon_diff', 'passenger_count'], \n        X_train, X_valid, y_train, y_valid)","003a5361":"train_mean = y_train.mean()\n\n# Criando uma lista com a mesma predi\u00e7\u00e3o para todos os dados de treino e teste\ntrain_preds = [train_mean for _ in range(len(y_train))]\nvalid_preds = [train_mean for _ in range(len(y_valid))]\n\ntr, vr, tm, vm = metrics(train_preds, valid_preds, y_train, y_valid)\n\nprint(f'Baseline Training:   rmse = {round(tr, 2)} \\t mape = {round(tm, 2)}')\nprint(f'Baseline Validation: rmse = {round(vr, 2)} \\t mape = {round(vm, 2)}')","1aaa1fad":"### Removendo Outliers\n\nBaseado [nesta mat\u00e9ria](http:\/\/nymag.com\/nymetro\/urban\/features\/taxi\/n_20286\/), removeremos as passagens com valor menor que $2.5.\n\n* Tambem limitaremos o valor m\u00e1ximo das passagens a $100.0.","94bd5e17":"Vamos remover essas observa\u00e7\u00f5es","124331bc":"> ### Dist\u00e2ncias de Manhattan e Euclidiana\n\n[Dist\u00e2ncia de Minkowski](https:\/\/en.wikipedia.org\/wiki\/Minkowski_distance) entre dois pontos:\n\n$${\\displaystyle D\\left(X,Y\\right)=\\left(\\sum _{i=1}^{n}|x_{i}-y_{i}|^{p}\\right)^{1\/p}}$$\n\n* se p = 1, temos a distancia de Manhattan, e se p = 2 temos a distancia Euclidiana.","3fa490ad":"### Explora\u00e7\u00e3o e Limpeza dos dados","55c45eab":"Aplicaremos estas fun\u00e7\u00f5es para `latitude` e `longitude`. Lembrando que estas n\u00e3o s\u00e3o as distancias reais, pois estas fun\u00e7\u00f5es s\u00e3o aplicadas considerando o plano cartesiano.","69498d24":"A maioria dos passeios est\u00e1 concentrada em Manhattan e aparentemente h\u00e1 mais passeios terminando fora de Manhattan do que dentro.\n\nPara verificar se h\u00e1 uma diferen\u00e7a nos locais com base na tarifa, vamos mapear cada compartimento de tarifa para uma cor diferente e, em seguida, plotar o gr\u00e1fico.","900e9ecc":"Discretizamos as passagens para visualizar suas distribui\u00e7\u00f5es","bfd03975":"# Engenharia de Features","7e3fa04c":"### Haversine Distance\n\n[A f\u00f3rmula de Haversine](https:\/\/www.wikiwand.com\/pt\/F%C3%B3rmula_de_Haversine) \u00e9 uma importante equa\u00e7\u00e3o usada em navega\u00e7\u00e3o, fornecendo dist\u00e2ncias entre dois pontos de uma esfera a partir de suas latitudes e longitudes. \u00c9 um caso especial de uma f\u00f3rmula mais geral de trigonometria esf\u00e9rica, a lei dos Haversines, relacionando os lados a \u00e2ngulos de uma esfera \"triangular\".\n\n$${\\displaystyle 2R\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {lat _{2}-lat _{1}}{2}}\\right)+\\cos(lat _{1})\\cos(lat _{2})\\sin ^{2}\\left({\\frac {lon _{2}-lon _{1}}{2}}\\right)}}\\right)}$$\n\n[Fun\u00e7\u00f5es matem\u00e1ticas do numpy](https:\/\/docs.scipy.org\/doc\/numpy-1.15.1\/reference\/routines.math.html)\n\n[Func\u00e7\u00e3o implementada](https:\/\/stackoverflow.com\/a\/29546836)\n","83e1af57":"# Machine Learning","f832e610":"# Identificando Outliers","f80460d5":"Para `latitude` e `longitude`, removeremos os valores abaixo de 2.5% e acima de 97,5% percentil.","7b2002cb":"A fun\u00e7\u00e3o de mapa substituir\u00e1 os valores em uma coluna pelos valores correspondentes no dicion\u00e1rio.","5ee36cb6":"Al\u00e9m de interessantes, os gr\u00e1ficos podem nos ajudar a identificar anomalias, relacionamentos ou id\u00e9ias para novos recursos. \n\nOs passeios mais caros tendem a se agrupar em torno do aeroporto. Se soub\u00e9ssemos com certeza que havia passeio com destino ao aeroporto, saber\u00edamos a tarifa!","e7492c03":"## Removendo features desnecessarias","2a766d13":"Agora podemos exibir `latitude` e `longitude` para ver a distributio\u00e7\u00e3o. Usaremos apenas 1000 observa\u00e7\u00f5es.","345ca612":"#### Agora \u00e9 sua vez","d5837ca7":"### Dist\u00e2ncia absoluta","a44a3b7b":"### Outros Outliers","345187ec":"# Taxi Fare Prediction\n\n* Adaptado de https:\/\/towardsdatascience.com\/another-machine-learning-walk-through-and-a-challenge-8fae1e187a64","ffb5548e":"Verificamos se existe alguma dist\u00e2ncia com valor 0.","a68f4e24":"# Visualizando o dataset","d637a87f":"Essa fun\u00e7\u00e3o \u00e9 para plotar os dados no mapa de Nova York","4d57bd3c":"Para uma representa\u00e7\u00e3o mais contextualizada, podemos tra\u00e7ar a coleta e a entrega em cima de um mapa de Nova York","6f9f17e4":"## Tempo de pegada do passageiro\n\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.dt.html"}}