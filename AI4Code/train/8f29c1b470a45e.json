{"cell_type":{"3754f6ee":"code","96d9de40":"code","a0d990b6":"code","82ff98ad":"code","3bd41e80":"code","82ea82f0":"code","5c03906e":"code","ce82717b":"code","6941f73a":"code","60a9ab20":"code","f438cef7":"code","afb70b4c":"code","9d9311c0":"code","8c5b0f1e":"code","0b35367f":"code","f4c8d2ca":"code","bd03d939":"code","2cb7f30d":"code","b611050e":"code","ab7d0ad3":"code","a2cf6cb7":"code","23243129":"markdown","f89cbc99":"markdown","b6dd52d4":"markdown","b61f107e":"markdown","cddaf4f7":"markdown","adacdb68":"markdown","eced7f1e":"markdown","ad884094":"markdown","5b453b60":"markdown","885b9f33":"markdown","487ec067":"markdown","86701e17":"markdown"},"source":{"3754f6ee":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import model_selection\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom torchvision import models, transforms","96d9de40":"DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","a0d990b6":"mnist_arr = np.loadtxt(\"..\/input\/train.csv\", delimiter=',', skiprows=1, dtype=np.uint8)","82ff98ad":"_prng = np.random.RandomState(42)\ntraining_features, validation_features, training_target, validation_target = (\n    model_selection.train_test_split(mnist_arr[:, 1:],\n                                     mnist_arr[:, 0],\n                                     test_size=0.10,\n                                     random_state=_prng)\n)","3bd41e80":"class DataSetWithTransforms(data.Dataset):\n    \n    def __init__(self, features, target, feature_transforms=None):\n        super().__init__()\n        self._features = features\n        self._target = torch.from_numpy(target).long()\n        self._feature_transforms = feature_transforms\n        \n    def __getitem__(self, index):\n        if self._feature_transforms is None:\n            features = self._features[index]\n        else: \n            features = self._feature_transforms(self._features[index])\n        target = self._target[index]\n        return (features, target) \n    \n    def __len__(self):\n        n_samples, _ = self._features.shape\n        return n_samples\n","82ea82f0":"# data augmentation should only apply to training data\n_feature_transforms = transforms.Compose([\n    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), shear=15, scale=(1.0, 1.1)),\n    transforms.ToTensor(),\n])\n\ntraining_dataset = DataSetWithTransforms(training_features, training_target, _feature_transforms)\n","5c03906e":"# data augmentation should not be applied to validation data\n_feature_transforms = transforms.Compose([\n    transforms.Lambda(lambda array: array.reshape((28, 28, 1))),\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n])\n\nvalidation_dataset = DataSetWithTransforms(validation_features, validation_target, _feature_transforms)","ce82717b":"class WrappedDataLoader:\n    \n    def __init__(self, data_loader, f):\n        self._data_loader = data_loader\n        self._f = f\n        \n    def __len__(self):\n        return len(self._data_loader)\n    \n    def __iter__(self):\n        for batch in iter(self._data_loader):\n            yield self._f(*batch)","6941f73a":"_batch_size = 32\n_training_data_loader = data.DataLoader(training_dataset, batch_size=_batch_size, shuffle=True)\ntraining_data_loader = WrappedDataLoader(_training_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n_validation_data_loader = data.DataLoader(validation_dataset, batch_size=1024)\nvalidation_data_loader = WrappedDataLoader(_validation_data_loader, lambda X, y: (X.to(DEVICE), y.to(DEVICE)))\n","60a9ab20":"fig, axes = plt.subplots(5, 6, sharex=True, sharey=True, figsize=(20, 20))\nfor i in range(5):\n    for j in range(6):\n        if j == 0:\n            _ = axes[i, j].imshow(training_features[i].reshape((28, 28)), cmap=\"gray\")\n        else:\n            _ = axes[i, j].imshow(training_dataset[i][0][0], cmap=\"gray\")\n        \n        if i == 0 and j == 0:\n            axes[i, j].set_title(\"Original Digit\")\n        if i == 0 and j > 0:\n            axes[i, j].set_title(f\"Augmented Digit {j}\")        \nfig.tight_layout()","f438cef7":"def _checkpoint(epoch, model_fn, opt, path):\n    kwargs = {\"epoch\": epoch,\n              \"model_state_dict\": model_fn.state_dict(),\n              \"optimizer_state_dict\": opt.state_dict()}\n    torch.save(kwargs, path)\n\n\ndef _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt):\n    # forward pass\n    loss = loss_fn(model_fn(X_batch), y_batch)\n\n    # back propagation\n    loss.backward()\n    opt.step()\n    opt.zero_grad() # don't forget to reset the gradient after each batch!\n\n\ndef fit(model_fn, loss_fn, training_data_loader, opt, validation_data_loader=None, number_epochs=1, path=\"checkpoint.pkl\"):\n    lowest_validation_loss = np.inf # initialize validation loss for checkpointing!\n    for epoch in range(number_epochs):\n        model_fn.train()\n        for X_batch, y_batch in training_data_loader:\n            _partial_fit(model_fn, loss_fn, X_batch, y_batch, opt)\n        \n        # compute validation loss after each training epoch\n        if validation_data_loader is not None:\n            model_fn.eval()\n            with torch.no_grad():\n                batch_losses, batch_sizes = zip(*[(loss_fn(model_fn(X), y), len(X)) for X, y in validation_data_loader])\n                validation_loss = np.sum(np.multiply(batch_losses, batch_sizes)) \/ np.sum(batch_sizes)\n                if validation_loss < lowest_validation_loss:\n                    print(f\"Training epoch: {epoch}, Lowest validation loss: {validation_loss}\")\n                    _checkpoint(epoch, model_fn, opt, path)\n                    lowest_validation_loss = validation_loss\n        print(f\"Completed {epoch} out of {number_epochs} training epochs.\")\n","afb70b4c":"class LambdaLayer(nn.Module):\n    \n    def __init__(self, f):\n        super().__init__()\n        self._f = f\n        \n    def forward(self, X):\n        return self._f(X)\n    ","9d9311c0":"lenet5 = nn.Sequential(\n    nn.Conv2d(1, 6, kernel_size=5),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(6, 16, kernel_size=5),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    LambdaLayer(lambda X: X.view(X.size(0), -1)),\n    nn.Linear(256, 120),\n    nn.ReLU(),\n    nn.Linear(120, 84),\n    nn.ReLU(),\n    nn.Linear(84, 10)\n)\nlenet5.to(DEVICE)\n\nloss_fn = nn.CrossEntropyLoss()\n\nopt = optim.Adam(lenet5.parameters())","8c5b0f1e":"fit(lenet5, loss_fn, training_data_loader, opt, validation_data_loader, number_epochs=100)","0b35367f":"_testing_features = np.loadtxt(\"..\/input\/test.csv\", delimiter=',', skiprows=1, dtype=np.int64)\n_scaled_testing_features = np.divide(_testing_features, 255, dtype=np.float32)\nscaled_testing_features_tensor = torch.from_numpy(_scaled_testing_features)","f4c8d2ca":"checkpoint = torch.load(\"checkpoint.pkl\")\nlenet5.load_state_dict(checkpoint[\"model_state_dict\"])\nlenet5.eval()","bd03d939":"output = lenet5(scaled_testing_features_tensor.view(-1, 1, 28, 28).to(DEVICE))\npredictions = torch.argmax(output, dim=1)","2cb7f30d":"fig , axes = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(20, 20))\nidx = 0\nfor i  in range(5):\n    for j in range(5):\n        _ = axes[i, j].imshow(scaled_testing_features_tensor[idx].reshape((28, 28)), cmap=\"gray\")\n        axes[i, j].set_title(f\"Predicted digit: {predictions[idx]}\")\n        idx += 1\nfig.tight_layout()","b611050e":"# submission format for kaggle\n!head ..\/input\/sample_submission.csv","ab7d0ad3":"import time\n\nimport pandas as pd\n\ntimestamp = time.strftime(\"%Y%m%d-%H%M%S\")\nnumber_predictions, = predictions.shape\n(pd.DataFrame({\"ImageId\": range(1, number_predictions + 1), \"Label\": predictions.cpu()})\n   .to_csv(f\"submission-{timestamp}.csv\", index=False))","a2cf6cb7":"!head submission-*.csv","23243129":"## Create a custom DataLoader**** for training and validation datasets","f89cbc99":"## Visually check model predictions","b6dd52d4":"# Loading the training data","b61f107e":"# Improving Performance with Data Augmentation","cddaf4f7":"## Reformat predictions","adacdb68":"# Exploring transformed images","eced7f1e":"## Split training data into training and validation subsets\n\n**First step is to split the raw training data into training and validation datasets. The validation dataset will be used to help us prevent overfitting.","ad884094":"# Train a CNN","5b453b60":"## Submit to Kaggle!\n\nOnce you have successfully submited your predictions then you can check the [Digit-Recognizer competition](https:\/\/www.kaggle.com\/c\/digit-recognizer) website and see how well your best model compares to your peers.","885b9f33":"## Create custom `DataSet` class to handle transformations","487ec067":"## Make predictions using the test data\n\n### Load the testing data","86701e17":"### Reset the model parameters using the checkpoint"}}