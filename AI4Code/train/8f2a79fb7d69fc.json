{"cell_type":{"76be17cb":"code","c73e28a7":"code","41102a86":"code","fda4b5b1":"code","38969fa2":"code","3b9aa076":"code","780cd02a":"code","25cc6f27":"code","d5185882":"code","a6225cfa":"code","0ee70d61":"code","cc3d4bd3":"code","c2e199c8":"code","a86784a4":"code","c47b7f5d":"code","62eaf128":"code","88d2f93a":"code","c2ca0a1b":"markdown","3c3a0115":"markdown","be8497b4":"markdown","55f9ea5f":"markdown","ac527b68":"markdown","65f70bef":"markdown","b38da3ee":"markdown","e10a343e":"markdown","b2a1535f":"markdown","64b71fb0":"markdown","47361e9e":"markdown","c9aa1c76":"markdown","9080ec6e":"markdown","8a8f2cab":"markdown","dd734f50":"markdown","c92b34d2":"markdown","7df7bbbc":"markdown","ac99cee1":"markdown"},"source":{"76be17cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","c73e28a7":"train_path_negative = '\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/neg'\ntrain_path_positive = '\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/pos'\ntrain = [train_path_negative, train_path_positive]\n\ntest_path_negative = '\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/neg'\ntest_path_positive = '\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/pos'\ntest = [test_path_negative, test_path_positive]\n\n\ndef read_images(path):\n    x = []\n    y = []\n    label = 0\n    i = 0\n    for folder in path:\n        for file in os.listdir(folder):\n            im = Image.open(os.path.join(folder, file))\n            x.append(np.asarray(im, dtype='uint8'))\n            y.append(label)\n\n            i += 1\n            if i % 10000 == 0:\n                print('Number of samples read: {}'.format(i))\n        label += 1\n\n    return torch.tensor(x), torch.tensor(y)\n\n\n\ndef show_images(x, y, number_of_samples):\n    \n    classes = len(np.unique(y))\n\n    fig, ax = plt.subplots(classes, number_of_samples, figsize=(15,7))\n    \n    for i in range(classes):\n        indices = np.where(y == i)[0]\n        for j in range(number_of_samples):\n            ax[i][j].imshow(x[np.random.choice(indices)], cmap='gray')\n            ax[i][j].set_title('Non-Pedestrian' if i ==0 else 'Pedestrian')\n            ax[i][j].axis('off')\n            \n    plt.show()","41102a86":"x_train, y_train = read_images(train)\nx_test, y_test = read_images(test)","fda4b5b1":"print('Number of Train Images: Positive {}, Negative {}\\nNumber of Test Images: Positive {}, Negative {}'\n      .format(len(os.listdir(train_path_positive)), len(os.listdir(train_path_negative)),\n              len(os.listdir(test_path_positive)), len(os.listdir(test_path_negative))))\n\nshow_images(x_train, y_train, 5)","38969fa2":"classes = np.unique(y_train).size\nlearning_rate = 0.00001\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n                               #color channel, # of conv layers\n        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 10, kernel_size= 3)\n        self.maxpool = nn.MaxPool2d(kernel_size= 2, stride= 2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.neurons = self.linear_input_neurons()\n        \n        \n        self.fc1 = nn.Linear(self.linear_input_neurons(), 500)\n        self.fc2 = nn.Linear(500, 250)\n        self.fc3 = nn.Linear(250, classes)\n\n    def forward(self, x):\n        x = self.maxpool(F.relu(self.conv1(x.float())))\n        x = self.maxpool(F.relu(self.conv2(x.float())))\n        x = x.view(-1, self.neurons)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return x\n    \n    def size_after_relu(self, x):\n        x = self.maxpool(F.relu(self.conv1(x.float())))\n        x = self.maxpool(F.relu(self.conv2(x.float())))\n        \n        return x.size()\n    \n    def linear_input_neurons(self):\n        size = self.size_after_relu(torch.rand(1, 1, 64, 32))\n        m = 1\n        for i in size:\n            m *= i\n\n        return int(m)\n    \n    \ndevice = torch.device('cuda' if torch.cuda.is_available() == True else 'cpu')\nmodel = CNN().to(device)","3b9aa076":"batch_size = x_train.size(0)\/\/5\n\nimport torch.utils.data\ntrain = torch.utils.data.TensorDataset(x_train, y_train)\ntrainloader = torch.utils.data.DataLoader(train, batch_size= batch_size, shuffle= True) # ( tensor(images), tensor(labels) )\n\ntest = torch.utils.data.TensorDataset(x_test, y_test)\ntestloader = torch.utils.data.DataLoader(test, batch_size= batch_size, shuffle= False)","780cd02a":"criterion = nn.CrossEntropyLoss()\n\nimport torch.optim as optim\noptimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.8)","25cc6f27":"train_acc1 = []\ntest_acc1  = []\nloss_list1 = []\niterations = []\nepochs = 500\n\n\nfor epoch in range(epochs+1):\n    for i, data in enumerate(trainloader):\n        \n        images, labels = data\n        images = images.view(images.size(0), 1, 64, 32)\n        \n        # gpu or cpu\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n    # test accuracy\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images = images.view(images.size(0), 1, 64, 32)\n        \n            images, labels_test = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels_test.size(0)\n            correct += (predicted == labels_test).sum().item()\n    \n    accuracy1 = correct \/ total\n\n    \n    # train accuracy\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in trainloader:\n            images, labels = data\n            images = images.view(images.size(0), 1, 64, 32)\n        \n            images, labels_train = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels_train.size(0)\n            correct += (predicted == labels_train).sum().item()\n    \n    accuracy2 = correct \/ total\n    \n    if epoch % 25 == 0: \n        loss_list1.append(loss.item())\n        train_acc1.append(accuracy2)\n        test_acc1.append(accuracy1)\n        iterations.append(epoch)\n        \n        print('epoch: {}   -->  train accuracy = {:.5f},\\ttest accuracy = {:.5f},\\tloss = {:.5f}'.format(epoch, accuracy2, accuracy1, loss.item()))\n    \n\nprint('Finished.')","d5185882":"fig, ax1 = plt.subplots(figsize=(12,7))\n\nax1.plot(np.array(iterations)+1, test_acc1, label='Test Accuracy', marker='o', color='green')\nax1.plot(np.array(iterations)+1, train_acc1, label='Train Accuracy', marker='s', color='blue')\nax1.set_xlabel('Epoch', fontsize=13)\nax1.set_ylabel('Accuracy', fontsize=13)\nplt.legend()\n\nax2 = ax1.twinx()\nax2.plot(np.array(iterations)+1, loss_list1, label='Loss', marker='P', color='red')\nax2.set_ylabel('Loss', fontsize=13)\nplt.legend()\nplt.title('Accuracies & Loss', fontsize=20)\nplt.show()","a6225cfa":"class_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\nwith torch.no_grad():\n    for data in testloader:\n        \n        images,labels = data\n        images = images.view(images.size(0), 1, 64, 32)\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _,predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(labels.size()[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nclassess = ['Pedestrians(0)','Non-Pedestrians(1)']\nfor i in range(2):\n    print('Accuracy of %s : %2d %%' % (\n        classess[i], 100 * class_correct[i] \/ class_total[i]))\n    \n    \nc = np.concatenate((np.array(class_correct).reshape(-1,1), np.array(class_total).reshape(-1,1) - np.array(class_correct).reshape(-1,1) ), axis= 1)\nplt.figure(figsize= (10,7))\nsns.heatmap(c, annot= True, linewidths=0.5, fmt='g')\nplt.show()","0ee70d61":"classes = np.unique(y_train).size\nlearning_rate = 0.00001\n\n\n# block layers\ndef conv3x3(in_planes, out_planes, stride=1):            # stride=3 & padding=1 --> size remains the same!\n    return nn.Conv2d(in_planes, out_planes, kernel_size= 3, stride= stride, padding=1, bias=False) # bias = False --> Batch Normalization already includes the bias term.\n\n# downsampling\ndef conv1x1(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size= 1, stride= stride, bias= False)\n\n\n\nclass BasicBlock(nn.Module):\n    \n    expansion = 1\n    \n    def __init__(self,inplanes, planes, stride = 1, downsample = None):\n        super(BasicBlock,self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace = True)\n        self.drop = nn.Dropout(0.9)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        \n    def forward(self, x):\n        identity = x\n        \n        out = self.drop(self.relu(self.bn1(self.conv1(x.float()))))\n        out = self.drop(self.bn2(self.conv2(out.float())))\n        \n        if self.downsample is not None:\n            identity = self.downsample(x)\n            \n        out += identity\n        out = self.relu(out)\n        return out\n    \n    \n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes = classes):\n        super(ResNet,self).__init__()\n        \n        # before block layers\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride = 2, padding = 3, bias= False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace = True)\n        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride = 2, padding = 1)\n        \n        # block layers\n        self.layer1 = self._make_layer(block, 64,  layers[0], stride = 1)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride = 2)\n    \n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # target output size: (1,1) after adaptive pooling\n        self.fc = nn.Linear(256*block.expansion, num_classes)\n    \n        \n        # initializing weights\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    \n    \n    def _make_layer(self, block, planes, blocks, stride):\n        downsample = None\n        if stride != 1 or self.inplanes != planes*block.expansion:   # size changes after convolution operations\n            # create downsample method\n            downsample = nn.Sequential(\n                    conv1x1(self.inplanes, planes*block.expansion, stride),\n                    nn.BatchNorm2d(planes*block.expansion))\n            \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample)) # send \n        self.inplanes = planes*block.expansion # conv1's output dimension == conv2's input dimension\n        \n        for _ in range(1,blocks):\n            layers.append(block(self.inplanes, planes)) # merge blocks\n        \n        return nn.Sequential(*layers)\n        \n    def forward(self, x):\n        x = self.maxpool(self.relu(self.bn1(self.conv1(x.float()))))\n        x = self.layer1(x.float())\n        x = self.layer2(x.float())\n        x = self.layer3(x.float())\n        x = self.avgpool(x)\n        x = x.view(x.size(0),-1)\n        x = self.fc(x)\n        \n        return x","cc3d4bd3":"batch_size = x_train.size(0)\/\/5\n\nimport torch.utils.data\ntrain = torch.utils.data.TensorDataset(x_train, y_train)\ntrainloader = torch.utils.data.DataLoader(train, batch_size= batch_size, shuffle= True) # ( tensor(images), tensor(labels) )\n\ntest = torch.utils.data.TensorDataset(x_test, y_test)\ntestloader = torch.utils.data.DataLoader(test, batch_size= batch_size, shuffle= False)","c2e199c8":"device = torch.device('cuda' if torch.cuda.is_available() == True else 'cpu')\nmodel = ResNet(BasicBlock, [2,2,2]).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)","a86784a4":"train_acc2 = []\ntest_acc2  = []\nloss_list2 = []\niterations = []\n\nepochs = 500\n\n\nfor epoch in range(epochs+1):\n    for (images,labels) in trainloader:\n        \n        images = images.view(images.size(0), 1, 64, 32)\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n    # test accuracy\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for (images, labels) in testloader:\n            \n            images = images.view(images.size(0), 1, 64, 32)\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)  # return max of index(1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy1 = correct \/ total\n\n    \n    # train accuracy\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for (images, labels) in trainloader:\n            \n            images = images.view(images.size(0), 1, 64, 32)\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy2 = correct \/ total\n    if epoch % 25 == 0:\n        test_acc2.append(accuracy1)\n        train_acc2.append(accuracy2)\n        loss_list2.append(loss.item())\n        iterations.append(epoch)\n        \n        print('epoch: {}   -->  train accuracy = {:.5f},\\ttest accuracy = {:.5f},\\tloss = {:.5f}'.format(epoch, accuracy2, accuracy1, loss.item()))\n    \n\nprint('Finished.')","c47b7f5d":"fig, ax1 = plt.subplots(figsize=(12,7))\n\nax1.plot(np.array(iterations)+1, test_acc2, label='Test Accuracy', marker='o', color='green')\nax1.plot(np.array(iterations)+1, train_acc2, label='Train Accuracy', marker='s', color='blue')\nax1.set_xlabel('Epoch', fontsize=13)\nax1.set_ylabel('Accuracy', fontsize=13)\nplt.legend()\n\nax2 = ax1.twinx()\nax2.plot(np.array(iterations)+1, loss_list2, label='Loss', marker='P', color='red')\nax2.set_ylabel('Loss', fontsize=13)\nplt.legend()\nplt.title('Accuracies & Loss', fontsize=20)\nplt.show()","62eaf128":"class_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\nwith torch.no_grad():\n    for data in testloader:\n        \n        images,labels = data\n        images = images.view(images.size(0), 1, 64, 32)\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _,predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(labels.size()[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nclassess = ['Pedestrians(0)','Non-Pedestrians(1)']\nfor i in range(2):\n    print('Accuracy of %s : %2d %%' % (\n        classess[i], 100 * class_correct[i] \/ class_total[i]))\n    \n    \nc = np.concatenate((np.array(class_correct).reshape(-1,1), np.array(class_total).reshape(-1,1) - np.array(class_correct).reshape(-1,1) ), axis= 1)\nplt.figure(figsize= (10,7))\nsns.heatmap(c, annot= True, linewidths=0.5, fmt='g')\nplt.show()","88d2f93a":"d = pd.DataFrame({'model':['CNN' for _ in range(3)] + ['DRN' for _ in range(3)],\n                  'phase':(['Train Accuracy' for _ in range(1)] + ['Test Accuracy' for _ in range(1)] + ['Train Loss' for _ in range(1)])*2,\n                  'accs':[train_acc1[-1],test_acc1[-1],loss_list1[-1], train_acc2[-1],test_acc2[-1],loss_list2[-1]]})\n\nhm = d.pivot('model', 'phase', 'accs')\n\n\nplt.figure(figsize=(15,9))\nsns.heatmap(hm, annot= True, linewidths= 0.5, annot_kws= {'size':12, 'weight':'bold'})\nplt.yticks(rotation= 0, fontsize= 12)\nplt.xticks(fontsize= 12)\nplt.xlabel('Results', fontsize= 18)\nplt.ylabel('Model', fontsize= 18, rotation= 0)\nplt.show()","c2ca0a1b":"* **Accuracy of Individual Classes & Confusion Matrix**","3c3a0115":"# 4. Visualization of Results\n> **Accuracies & Loss**","be8497b4":"# 1. Creating Deep Residual Network\n\n\n\n* **Network Topology**\n\n> Convolutional Layer --> 64, 2x2\n\n> ResNet Block 1: 2x Convolutional Layers --> 64, 1x1\n\n> ResNet Block 2: 2x Convolutional Layers --> 128, 2x2\n\n> ResNet Block 3: 2x Convolutional Layers --> 256, 2x2\n\n> Linear Layer: 256","55f9ea5f":"# 2. Defining CNN Network & Determining Neuron Size in Input Linear Layer\nIn addition to standard Pytorch CNN model, I added a method for determining the number of neurons in input Linear layer automatically, in which some complex computations are required after each convolution layer to determine the input neurons in first fully-connected layer.\n* **linear_input_neurons()** returns the required number of neurons.\n\n* In order to be able to use GPU, firstly the preferred device must be allocated, then the model created as in the bottom lines.","ac527b68":"# 1. Reading Data\n* PIL library will be used to read images from the folder.\n\n* As might have seen in **read_images()**, the datatype of IR images is changed into 8 bit first --> **'uint8': 0 to 255**\n\n* Then, they have to be converted to tensor, since Pytorch frameworks need pytorch tensors to run on.","65f70bef":"# Overall Comparison of Models","b38da3ee":"* ** Visualization of Images **  ","e10a343e":"# ResNet\n\nResidual Neural Networks is the most efffective method to avoid vanishing gradient problem which stems from the vanishing of the gradients by slightly or never changing the values of weights. Thus, especially the low level features vanishes in the network since the value of the gradients in each layer gradually decreases with nested derivatives while backpropagation is carried out. \n\n\n* ResNet is a solution to this problem by utilizing *skip connections*, or *shortcuts* to jump over some layers, -reusing activations from a previous layer until the adjacent layer learns its weights.-\n","b2a1535f":"# 2. Training and Testing: ResNet","64b71fb0":"* **Accuracy of Individual Classes & Confusion Matrix**","47361e9e":"* **Providing An Iterable Over Dataset**\n","c9aa1c76":"* **Providing An Iterable Over Dataset**\n\n> Here we decide on the batch size for epochs in training phase.","9080ec6e":"# Introduction\n\n* In this kernel, a classification of absence and existence of pedestrians in Infrared Pedestrian dataset images will be made. Both CNN and ResNet models will be trained and tested as well as a comparison of their accuracies as the evaluation metric.\n\n> Image size and channel: 64x32 pixels - 14 bit color channel","8a8f2cab":"# 3. Training and Testing: CNN Network","dd734f50":"* **Defining Loss Function & Optimizer**","c92b34d2":"* **Network Topology**\n\n> Feature Extraction --> Convolutional Layer 1: 10 , 3x3\n\n> Dimensionality Reduction --> Max Pooling Layer: 2x2\n\n> Feature Extraction --> Convolutional Layer 2: 20, 3x3\n\n> Classification --> Linear Layer1: 1040\n\n> Classification --> Linear Layer2: 500\n\n> Classification --> Linear Layer1: 250","7df7bbbc":"* **Defining Loss Function & Optimizer**","ac99cee1":"# 3. Visualization of Results\n\n> **Accuracies & Loss**"}}