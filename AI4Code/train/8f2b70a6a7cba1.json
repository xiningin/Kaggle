{"cell_type":{"02d72cb6":"code","55544e53":"code","599b12f6":"code","bd2fd7ca":"code","8a434836":"code","244bc094":"code","c37c7f5a":"code","17f26257":"code","577c0b53":"code","c9cf6249":"code","67dab02e":"code","a8853e64":"code","9bb2d3c6":"code","3493fb1f":"code","ce01735a":"code","68e0dd92":"code","e8a3157a":"code","09e8ba72":"code","dcd5705c":"code","7f20d216":"code","d98e8bf4":"code","418d440a":"code","5b99aa3b":"code","f375221f":"code","68d89832":"code","4872ef3c":"code","a875d215":"code","13bc0acd":"code","77d4b628":"code","c9db0b58":"code","277483df":"markdown","15d88aef":"markdown","3570a29b":"markdown"},"source":{"02d72cb6":"import os\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n#\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image","55544e53":"np.random.seed(8)\ntf.random.set_seed(6)","599b12f6":"base_dir = '\/kaggle\/input\/cassava-leaf-disease-classification'\nos.listdir(base_dir)","bd2fd7ca":"train_dir = os.path.join(base_dir, 'train_images')\ntest_dir = os.path.join(base_dir, 'test_images')","8a434836":"import json\ntrain_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\nsample_subm = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))\nf = open(os.path.join(base_dir, 'label_num_to_disease_map.json'), 'r')\nlabel_num = json.load(f)","244bc094":"train_df.head()","c37c7f5a":"label_dict = {int(i): lab for (i, lab) in label_num.items()}\nlabel_dict","17f26257":"train_df.label = train_df.label.map(label_dict)","577c0b53":"train_df.head()","c9cf6249":"train_df.dtypes","67dab02e":"import cv2\n\nimtest = cv2.imread(os.path.join(train_dir, os.listdir(train_dir)[0]))\nimtest.shape","a8853e64":"# add path to train_df\npath = list()\nfor r in train_df.image_id:\n    path.append(os.path.join(train_dir, r))\n# path","9bb2d3c6":"train_df['path'] = path\n# train_df","3493fb1f":"train_df.shape","ce01735a":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  validation_split=0.35)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","68e0dd92":"train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n                                                   directory=train_dir,\n                                                   subset='training',\n                                                   x_col='image_id',\n                                                   y_col='label',\n                                                   shuffle=True,\n                                                   target_size=(100, 100),\n                                                   batch_size=50,\n                                                   class_mode='categorical')\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n                                                   directory=train_dir,\n                                                   subset='validation',\n                                                   x_col='image_id',\n                                                   y_col='label',\n                                                   shuffle=True,\n                                                   target_size=(100, 100),\n                                                   batch_size=50,\n                                                   class_mode='categorical')","e8a3157a":"device_name = tf.test.gpu_device_name()\nprint(device_name)\ntf.device(device_name)","09e8ba72":"base_model = keras.applications.vgg16.VGG16(weights='imagenet',\n                                           include_top=False)\nbase_model.trainable = False\ninput_x = layers.Input(shape=(100,100,3))\nx = base_model(input_x, training=False)\nx = layers.Flatten()(x)\nx = layers.Dense(5, activation='softmax')(x)\nmodel = models.Model(inputs=input_x, outputs=x)\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n             metrics=['acc'])\nmodel.summary()","dcd5705c":"model.fit(train_generator,\n         steps_per_epoch=50,\n         validation_data=valid_generator,\n         validation_steps=50,\n          epochs=50,\n         verbose=1)","7f20d216":"acc = model.history.history['acc']\nval_acc = model.history.history['val_acc']","d98e8bf4":"plt.figure()\nplt.plot(range(1, len(acc)+1), acc, 'b', label='train_acc')\nplt.plot(range(1, len(acc)+1), val_acc, 'r', label='val_acc')\nplt.title('Accuracy comparison')\nplt.legend()","418d440a":"test_dir = os.path.join(base_dir, 'test_images')","5b99aa3b":"img = image.load_img(os.path.join(test_dir, os.listdir(test_dir)[0]), target_size=(100, 100))\nimg = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)","f375221f":"img = np.vstack([img])","68d89832":"pred = model.predict(img)","4872ef3c":"pred = np.argmax(pred)\nprint(pred)","a875d215":"sample_subm","13bc0acd":"imgid = os.listdir(test_dir)[0]\nimgid","77d4b628":"output = pd.DataFrame({'image_id': sample_subm.image_id, 'label': pred})","c9db0b58":"output.to_csv(\"submission.csv\", index=False)\nprint(\"saved\")","277483df":"**Load data**","15d88aef":"# shape of images","3570a29b":"# the model"}}