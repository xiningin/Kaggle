{"cell_type":{"c61b4e44":"code","c933c5c3":"code","42e91c17":"code","1977e4f2":"code","c85fc097":"code","ec28e1bb":"code","2f0f1fa2":"code","7fb2e6ee":"code","4170be1d":"code","f78998b1":"code","7c8f86be":"code","90124798":"code","8375c8ce":"code","09919ebf":"code","0be10cc6":"code","912d9feb":"code","ff9df3ec":"code","90c7768d":"code","07d46425":"code","e084506e":"code","95fe5499":"code","e797ce85":"code","74c22b0b":"code","5cd73bcc":"code","bea185b8":"code","559e80a1":"code","04086d44":"code","726fc193":"code","9c1d2ce9":"code","cf25afa6":"code","ce214aad":"code","8228738e":"code","02532341":"code","29a5c495":"code","539baba9":"code","76525f6f":"code","1f79ca2d":"code","3ebd25e6":"code","22deee8d":"code","45695b72":"code","03f20d24":"code","ddb839c5":"code","11443998":"code","5fee2b32":"markdown","00631bb8":"markdown","05a1497e":"markdown","97d8794f":"markdown","ace8c7dc":"markdown","1b9de929":"markdown","1a8edf8a":"markdown","16597625":"markdown","4db9d6c2":"markdown","e979f3e9":"markdown","11557764":"markdown","518af9ab":"markdown","fc78c84e":"markdown","aa1ca4b2":"markdown","064003b2":"markdown","0e84c4d0":"markdown","d42c4603":"markdown","722c1566":"markdown","3ad366a1":"markdown","e833fbbe":"markdown","f1234ac0":"markdown","3cf47722":"markdown","732f04aa":"markdown","ae40ff6c":"markdown","20094d4e":"markdown","bbd9ac8d":"markdown","799d2713":"markdown","8839cf90":"markdown","2b9c0af7":"markdown","a56bc5c0":"markdown","ee153a5e":"markdown","b9d8c2f0":"markdown","d70b68ff":"markdown","561222e4":"markdown","f44aeacd":"markdown","50c72cbb":"markdown","6c94abe9":"markdown","9db9eb88":"markdown","e3e59def":"markdown","9e75a9f5":"markdown","a1ab716d":"markdown","b54a5944":"markdown","ef269b57":"markdown"},"source":{"c61b4e44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c933c5c3":"import pandas as pd\nimport matplotlib \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\", color_codes=True)\n\n#Used to generate graphs inside the notebook\n%matplotlib inline \n\n#Specify the path to data \nPathToData='..\/input\/pakistan-education-performance-dataset\/Consolidated (Educational Dataset).csv'\n\n#Read data\ndata = pd.read_csv(PathToData)\n\n#Displaying starting rows\nprint(data.head())","42e91c17":"print(data.shape)","1977e4f2":"print(data.describe())","c85fc097":"print(data.dtypes)","ec28e1bb":"print(data.dtypes.unique())","2f0f1fa2":"null_columns=data.columns[data.isnull().any()]\nprint(data[null_columns].isnull().sum())","7fb2e6ee":"data[data.isnull().any(axis=1)][null_columns].head()","4170be1d":"data=data.fillna(0)\ndata.head(3)# checking only 3 because Area contained Nan in the 3rd row which has now been replaced with 0","f78998b1":"dropColumns=['Boundary wall, Building condition satisfactory, Drinking water and 2 more (clusters)','Show Sheet','Table of Contents','Color By Measure Name','Number of Records'\n             ,'MeasureGroup 1 Measures','Color By Measure Value','Other Factors Measure Value','MeasureGroup 2 Measures','Country','Analysis Level Selector']\n\n#Analysis Level Selector is removed because it is same as province\n\n## Drop was not working due to an issue in data formatting\n#data.drop(dropColumns, axis=1,inplace=True)\n\n#Alternative to drop is to select other than the columns we want to drop\ncolumns=[col for col in data.columns if col not in dropColumns]\n\n#Columns that were selected\nprint(columns)\n\n#Displaying the data\ndata=data[columns]\ndata\n\n","7c8f86be":"data2 = data.copy()\nNonNumerical=[c for c in data.columns if data[c].dtype in ['O']]\n\nprint(NonNumerical)\n","90124798":"for i in NonNumerical:# 2) iterate over non numerical columns\n\n  # 3) removing % and dividing by 100\n  if(data2[i][0][-1]=='%'):\n\n    data2[i] = data2[i].map(lambda x: str(x)[:-1]) #Succssfully removes the percentage sign\n    data2[i]=pd.to_numeric(data2[i],errors='coerce')\n    # data2[i]=data2[i].astype('float64')##Gives error\n    data2[i] = data2[i]\/100","8375c8ce":"data = data2\nprint(data.head())","09919ebf":"# data2=data.copy()","0be10cc6":"print(data.dtypes.unique())","912d9feb":"import numpy as np\ndata.replace(0, np.nan, inplace=True)\ndata.head()","ff9df3ec":"null_columns=data.columns[data.isnull().any()]\nprint(data[null_columns].isnull().sum())","90c7768d":"Numerical=[c for c in data.columns if data[c].dtype not in ['O','object']]\nNumerical = [c for c in Numerical if c not in ['No Facility'] ]\nprint(Numerical)\n","07d46425":"print(data[Numerical].dtypes.unique())","e084506e":"# data2= data.copy()#Copy of datamade\n# data=data2.copy()","95fe5499":"data[Numerical]","e797ce85":"# data.to_csv (r'\/content\/drive\/My Drive\/Sem8\/DS\/Project\/Processed(ContainsMissingValues).csv', index = False, header=True)","74c22b0b":"data[Numerical]=data[Numerical].ffill(axis = 0) \ndata[Numerical]","5cd73bcc":"# dropColumns=['Boundary wall, Building condition satisfactory, Drinking water and 2 more (clusters)','Show Sheet','Table of Contents','Color By Measure Name','Number of Records']\ndata = data[[c for c in data.columns if c not in ['No Facility']]]","bea185b8":"\"\"\"\nfrom sklearn.impute import SimpleImputer\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\ndata[Numerical]=imp_mean.fit_transform(data[Numerical])\ndata[Numerical]\n\"\"\"","559e80a1":"\"\"\"\nfrom sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=5)\n\ndata[Numerical] = imputer.fit_transform(data[Numerical])\ndata[Numerical]\n\n\"\"\"\n\n","04086d44":"print('Cities belong to the following areas:\\n\\nAzad Jammu Kashmir(AJK), Balochistan, Federally Administered Tribal Areas(FATA),\\nGilgit Baltistan(GB), Khyber Pakhtunkhwa(KP), Islamabd Capital Territory(ICT), Punjab, Sindh: ')\nprint(data.Province.unique())\n\nprint('\\nData Collected of following cities:\\n')\nc=5\nfor i in data.City.unique():\n  if(c==10):\n    print()\n    c=0\n  print(i, end =\", \")\n  c+=1","726fc193":"import seaborn as sn\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(25,15))\n\ncorrMatrix = data.corr()\n# print (corrMatrix)\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","9c1d2ce9":"df_num = data.select_dtypes(include = ['float64', 'int64'])# func to select particular type columns\nprint(df_num.head())","cf25afa6":"df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);","ce214aad":"df_num_corr = df_num.corr()['Retention score'][:-1] # -1 to ignore the Retention score column\ngolden_features_list = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)#Descending sort\nprint(\"{} features are strongly correlated with Retention score. They are:\\n{}\".format(len(golden_features_list), golden_features_list))","8228738e":"corr = df_num.corr() # Finding correlations among columns after dropping saleprice\nplt.figure(figsize=(12, 10))#adjusting image size\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.5)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","02532341":"data2=data.copy()\n#Seperating the 'year' column\ndata2=data[Numerical[:-1]]","29a5c495":"\ndata2_column_maxes = data2.max()\ndata2_max = data2_column_maxes.max()\ndata2 = data2 \/ data2_max\n\n# data2","539baba9":"data3=data.copy()\ndata3[Numerical[:-1]]=data2.copy()\n#Normalized data\ndata = data3\n# data","76525f6f":"data.groupby('Province')['Total number of schools'].mean().plot()\nplt.title('Total number of Schools')\nplt.show()\n","1f79ca2d":"data.groupby('Province')['% Complete Primary Schools'].mean().plot()\nplt.title('% Students Completing Primary Schools')\nplt.show()\n","3ebd25e6":"data.groupby('Year')['Drone attacks in Pakistan','Bomb Blasts Occurred'].mean().plot()\nplt.title('Fall in number of Drone attacks and Bomb blasts')\nplt.show()\n","22deee8d":"data.groupby('Year')['Gender parity score'].mean().plot()\nplt.title('Gender Parity score')\nplt.show()","45695b72":"data.groupby('Year')['Global Terrorism Index - Pakistan'].mean().plot()\nplt.title('Global Terrorism Index - Pakistan')\nplt.show()","03f20d24":"data.groupby('Year')['Pakistan Economic Growth'].mean().plot()\nplt.title('Pakistan Economic Growth')\nplt.show()","ddb839c5":"data.groupby('Year')['% Boys Enrolled','% Girls Enrolled'].mean().plot()\nplt.title('% Student Enrolled')\nplt.show()","11443998":"data.groupby('Year')['Education score','Retention score', 'Learning score','Enrolment score'].mean().plot()\nplt.title('Comparison of several Scores')\nplt.show()","5fee2b32":"Imputing missing values using knn imputer","00631bb8":"Normalizing data","05a1497e":"Imputing using ffill","97d8794f":"1. A highly negative correlation can be observed among % Boys enrolled and % Girls enrolled which is an interesting observation. It might be due to the cultural values that parents prefer such schools for their daughters where the number of female are greater as compared to boys\n\n2. % Boys enrolled has a high negative correlation with Education score, where as % girls enrolled has a highly positive correlation with Education score which means that girls are more intelligent\n\n3. Education score has a strong correlation with Gender parity score which means if education is promoted among both genders, the education score will improve\n\n4. Year has a highly negative correlation with Bomb blasts occured, Drone attacks in pakistan, Terrorist attack affectees and Global terrorism index which points out to the betterment of economy and defence of Pakistan. \n\n5. Year has a slightly moderate negative correlation with Educational budget spend, which means that as time passed, Pakistan spent less on Education\n\n6. Year has a highly strong correlation with Economy which proves our assumption 4","ace8c7dc":"Imputing mean didnt seem to be a good option as the population seemed unrealistic","1b9de929":"Finding out numerical data distribution. \n\nPlotting the graphs help us visualizing which colummns are similar","1a8edf8a":"Our data contains 580 record of different schools and 51 features about each school","16597625":"A rise can be seen in Pakistan Economic growth after 2014. 2014 is a promising year as depicted by our data. From 2014, the index of global terrorism of pakistan started to fall. The drone and terrorist attakcs reduced by a great factor. ","4db9d6c2":"This is an interesting graph, it shows in a steep drop in learning score after 2014 but a high rise in enrolment score. On the other hand, both the Education score and retention score starts to decrease after 2014. As it can be seen, in the 2014, the retention and education score started to dcrease which automatically resulted in fall of learning score as seen above","e979f3e9":"Dataset contains three different types of columns:\n\n\n1.   Object\n2.   Float64\n3.   int64\n\n","11557764":"Following is a basic insight I tried to get from the dataset. I might be wrong as I am just in learning phases. Do comment if you can find any mistakes or you can suggest me some improvements also","518af9ab":"KNN imputer doesnt seem to be a suitable choice for the dataset, the dataset processed with it is saved in the directory","fc78c84e":"**Exploring the dataset**\n\nExploring null columns","aa1ca4b2":"Dropping the no facility column","064003b2":"A fall in Globat Terrorism Index is observed from 2014","0e84c4d0":"1)Finding non numerical columns","d42c4603":"I think its a good option to use because of the fact that inserts the closest value to the null position","722c1566":"Seperating the columns that have high correlation with retention score so as to know which factors contribute more","3ad366a1":"We have data from following cities","e833fbbe":"Impute values in columns other than the columns contatning categorical data. Removing the no facility column as it contains many null values","f1234ac0":"Data reading","3cf47722":"Missing value count of original dataset\n1. % Boys Enrolled                             1\n2. % Complete Primary Schools                  4\n3. % Girls Enrolled                            1\n4. % Primary Schools with single classroom     4\n5. % Primary Schools with single teacher       4\n6. All Four Facilities                         4\n7. Any One Facility                            4\n8. Any Three Facilities                        4\n9. Any Two Facilities                          4\n10. Area (km\u00b2)                                 68\n11. Complete Primary Schools                    4\n12. No Facility                                 4\n13. Population                                 68\n14. Primary Schools with single classroom       4\n15. Primary Schools with single teacher         4\n\nAs there are a total of 580 values, above statistics represent that there are very less Null values. It means we wont be dropping any column because of null values. We will focus on imputing values in the null rows","732f04aa":"Getting to know about the different types of columns in the dataset","ae40ff6c":"Printing the datatypes of columns(Features)","20094d4e":"After 2014, a rise in female enrollment can be observed","bbd9ac8d":"A problem would generate if we start the Imputing process now because many columns contain the % sign which would have to be removed first. The problem is that they might also have Nan values and converting from string to float would generate error. So:\n 1. first we will impute 0 in the place of all the Nan values. \n 2. Will remove the percent signs and convert those columns into float\n 3. will replace the 0's with knn imputer values","799d2713":"Now the data contains no null values and we can start visualizing the data","8839cf90":"**Visualizing insights**","2b9c0af7":"Plotting correlation matrix","a56bc5c0":"Proving above observations through visualizations. Before starting visualization, we will normalize the data to bring it to similar scale","ee153a5e":"'%' sign succesfully handled. Time to perform the imputation of missing values\n\nReplace all the 0's with Nan","b9d8c2f0":"Sindh has the highest number of schools","d70b68ff":"Gender parity score didnot increase as much as it did before since the year 2014","561222e4":"Despite the fact that Sindh has the highest number of schools, many students dont complete Primary level education","f44aeacd":"As can be observed from the above graphs, Retention score, Education Score, learning score, Enrolment score all have similar distribution which proves our above observation that retention score is linked to learning score.\n\nFinding out the correlation of columns with Retention score to know how much these factors effect Retention score","50c72cbb":"Printing the count of Null values in columns","6c94abe9":"Getting basic statistics about dataset","9db9eb88":"Following are the columns containing some null values","e3e59def":"By exploring the dataset, I found some columns that in my observation doesnt seem to be useful. So we will be dropping those columns","9e75a9f5":"Due to large number of features, it is difficult to visualize the correlation matrix completely. Some observations that can be seen are:\n1. Drone attacks have a high correlation with Educational Budget spend of GDP and Global Terrorism index\n2.  Educational Budget spend of GDP has a high correlation with Global Terrorism index\n3. Bomb blasts occurred has a high correlation with drone attacks rather than terrorism affectees \n4. An interesting fact can be seen is that retention score has low correlation with All 4 conditions, which points out to the fact that inspite of provision of good educational support, many children leave their education\n\n\n\n","a1ab716d":"Imputing mean","b54a5944":"Education score has a high correlation with retention score\nThe remaining 4 columns above has a moderate correlation with retention score","ef269b57":"\n 1. We will find the non numerical columns\n 2. Among those columns we will explore the columns containing '%' sign\n 3. Will remove the '%' sign and divide by 100\n 4. Once this cleaning is done, we would replace the 0's with Nan and will impute missing values"}}