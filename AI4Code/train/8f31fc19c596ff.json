{"cell_type":{"520a7629":"code","9bdf7198":"code","8cb9cded":"code","6b923dc5":"code","4da3903e":"code","ceeb3a30":"code","9d09a558":"code","37263468":"code","f9cfc73b":"code","53978614":"code","bb7b4597":"code","6730c990":"code","f96127d7":"code","c23d07d9":"code","95a45c7e":"code","ea38afe7":"code","a06b4264":"code","b88f203f":"code","9b6056a1":"code","37558305":"code","b6e1d7a6":"code","c88521a8":"code","62708208":"code","7f5686ce":"code","a482e222":"code","a713b27e":"code","a8d58d95":"code","9b217dcc":"code","4e0e5e1a":"code","1636d3f1":"code","1d3e87c7":"code","a9d3b589":"code","67790267":"code","32280a5d":"code","b9238087":"code","045eac44":"code","e519ac6f":"code","63c4d538":"code","9d1ab779":"code","9250958e":"code","4709797d":"code","efa391e6":"code","bdb0edec":"code","7660d3a0":"code","f960c2b1":"code","e6eeae5b":"code","740c3ff8":"code","5442c4c8":"code","d7785703":"markdown","9c07e7c4":"markdown","ffbbfe5d":"markdown","bc8eb73f":"markdown","1ef6f991":"markdown","c16373a9":"markdown","a07705dc":"markdown","61144a81":"markdown","fe7da61b":"markdown","e4612292":"markdown","f248c98b":"markdown","869d9329":"markdown","111e1db1":"markdown","39820d9c":"markdown","111ec0e5":"markdown","fd086e0f":"markdown","9303b28c":"markdown"},"source":{"520a7629":"import pandas as pd\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport matplotlib.ticker as ticker\nplt.rc(\"font\", size=14)\nimport warnings\nwarnings.simplefilter(action='ignore')","9bdf7198":"train = pd.read_csv(\"..\/input\/bank-train\/bank_train.csv\", header = 0)\ntest = pd.read_csv(\"..\/input\/bank-test\/bank_test.csv\", header=0)","8cb9cded":"test.shape","6b923dc5":"train.head()","4da3903e":"train.describe()","ceeb3a30":"train.info()","9d09a558":"#finding unique values from categorical data(clm)\nfor col in train.select_dtypes('O').columns:\n    print('We have {} unique values in {} column : {}'.format(len(train[col].unique()),col,train[col].unique()))\n    print('-'*100)","37263468":"print('Percent of missing \"Credit_Product\" records is %.2f%%' %((train['Credit_Product'].isnull().sum()\/train.shape[0])*100))","f9cfc73b":"train.fillna({\"Credit_Product\": 'None'}, inplace = True)","53978614":"corr =train.corr()\ncorr.sort_values(['Is_Lead'], ascending= False, inplace=True)\nprint(corr.Is_Lead)","bb7b4597":"corrmat = train.corr()\ntop_corr_features = corrmat.index[abs(corrmat[\"Is_Lead\"])>0.2]\nplt.figure(figsize=(10,8))\ng = sns.heatmap(train[top_corr_features].corr(),annot=True,cmap=\"cubehelix\")","6730c990":"cat_features = ['Gender','Occupation','Channel_Code','Credit_Product','Is_Active']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(cat_features):\n    plt.subplot(3, 2, i+1)\n    sns.countplot(data=train, x=feature, hue='Is_Lead', palette='cubehelix')  \n    \nsns.despine()","f96127d7":"cat_features = ['Is_Lead','Occupation','Channel_Code','Credit_Product','Is_Active']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(cat_features):\n    plt.subplot(3, 2, i+1)\n    sns.countplot(data=train, x=feature, hue='Gender', palette='summer')  \n    \nsns.despine()","c23d07d9":"plt.figure(figsize=(10, 4))\nAge_cat = pd.cut(train.Age, bins=[20, 30, 40, 50, 60, 70, 80])\n\nsns.countplot(data=train, x=Age_cat, hue='Gender', palette='CMRmap')\n\nplt.show()\n\n#from this graph we can see Age category wise male-female ratio","95a45c7e":"plt.figure(figsize=(10, 4))\nsns.countplot(data=train, x=Age_cat, hue='Is_Lead', palette='viridis')\n\nplt.show()\n#Here from this graph we can see Age category wise interesed population.","ea38afe7":"plt.figure(figsize=(10, 4))\nsns.countplot(data=train, x=Age_cat, hue='Is_Active', palette='magma')\n\nplt.show()","a06b4264":"plt.figure(figsize=(15, 5))\nAvg_Account_Balance = pd.cut(train.Avg_Account_Balance, bins=[0, 100000, 500000, 1000000, 5000000, 10500000])\n\nsns.countplot(data=train, x=Avg_Account_Balance, hue='Is_Lead', palette='summer')\n\nplt.show()","b88f203f":"#also we shall look if there any pattern in region code and channel code\nfig, ax = plt.subplots(1, 1, figsize=(20, 25))\nsns.countplot(data=train, y='Region_Code', hue='Channel_Code', ax=ax, palette='rocket',orient='v')\nax.set_title('Region_Code - Channel_Code', size=25, loc='Left', y=1.04)\n\nsns.despine()\nplt.show()","9b6056a1":"sns.boxplot(data = train, x= 'Is_Lead', y ='Avg_Account_Balance')","37558305":"sns.histplot(data = train, x=\"Avg_Account_Balance\", color = 'maroon')","b6e1d7a6":"#here \"Avg_Account_Balance\" clm is skewed so we take a log to make it normal.\ntrain[\"Avg_Account_Balance\"] = np.log1p(train[\"Avg_Account_Balance\"])\nsns.histplot(data = train, x=\"Avg_Account_Balance\", color = 'maroon')","c88521a8":"train.head()","62708208":"train = pd.get_dummies(train, columns=['Occupation','Region_Code',\"Channel_Code\",\"Credit_Product\",'Is_Active','Gender'], drop_first = True)","7f5686ce":"del train['ID']","a482e222":"from sklearn.metrics import classification_report\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score, auc\nfrom sklearn.metrics import roc_curve","a713b27e":"X = train.loc[:, train.columns != 'Is_Lead']\ny = train['Is_Lead']","a8d58d95":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2519)","9b217dcc":"LogReg = LogisticRegression().fit(X_train, y_train)\ntrain_pred = LogReg.predict(X_train)\ntest_pred = LogReg.predict(X_test)\n\nprint('train set accuracy:', accuracy_score(y_train, train_pred))\nprint(' test set accuracy:', accuracy_score(y_test, test_pred))","4e0e5e1a":"cm = confusion_matrix(y_test,test_pred)\nplt.figure(figsize = (8,5))\n\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,  cmap = 'YlGnBu')\n\n# print the scores on training and test set\nall_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, test_pred))\n\nplt.title(all_sample_title, size = 19)\nplt.savefig(\"pne.png\")","1636d3f1":"#ROC Curve for Model\ntest_score = LogReg.predict_proba(X_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, test_score)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)","1d3e87c7":"# plot roc curves\nplt.plot(false_positive_rate1, true_positive_rate1, linestyle='--',color='orange', label = 'Logistic')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\nall_sample_title = 'ROC_AUC_SCORE: {0}'.format(roc_auc_score(y_test, test_score))\nplt.title(all_sample_title, size= 18)\nplt.legend(loc='best')\nplt.show();","a9d3b589":"#ROC Curve for Model\ntest_score = LogReg.predict_proba(X_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, test_score)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)","67790267":"from sklearn.ensemble import RandomForestClassifier\n#creating model\nrf_clf = RandomForestClassifier(criterion = 'gini',\n                                n_estimators=1000,\n                                oob_score= True,\n                                max_features ='log2',\n                                min_samples_split=10,\n                                min_samples_leaf=3,\n                                bootstrap=True,\n                                n_jobs=-1,\n                                random_state=1)\nrf_clf.fit(X_train, y_train)\ny_pred = rf_clf.predict(X_test)","32280a5d":"cm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (8,5))\n\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,  cmap = 'PuBu')\n\n# print the scores on training and test set\nall_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_pred))\n\nplt.title(all_sample_title, size = 19)\nplt.savefig(\"pne.png\")","b9238087":"y_score = rf_clf.predict_proba(X_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score)\n# plot roc curves\nplt.plot(false_positive_rate1, true_positive_rate1, linestyle='--',color='orange', label='Random Forest')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\nall_sample_title = 'ROC_AUC_SCORE: {0}'.format(roc_auc_score(y_test, y_score))\nplt.title(all_sample_title, size= 18)\nplt.legend(loc='best')\nplt.show();","045eac44":"# build the lightgbm model\nimport lightgbm as lgb\nmodel = lgb.LGBMClassifier()\nmodel.fit(X_train, y_train)\ny_pred2=model.predict(X_test)","e519ac6f":"cm = confusion_matrix(y_test, y_pred2)\nplt.figure(figsize = (8,5))\n\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,  cmap = 'ocean')\n\n# print the scores on training and test set\nall_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_pred2))\n\nplt.title(all_sample_title, size = 19)\nplt.savefig(\"pne.png\")","63c4d538":"y_score2 = model.predict_proba(X_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score2)\n# plot roc curves\nplt.plot(false_positive_rate1, true_positive_rate1, linestyle='--',color='orange', label='LightGBM')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\nall_sample_title = 'ROC_AUC_SCORE: {0}'.format(roc_auc_score(y_test, y_score2))\nplt.title(all_sample_title, size= 18)\nplt.legend(loc='best')\nplt.show();","9d1ab779":"from sklearn.metrics import precision_recall_curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_score2) \n   #retrieve probability of being 1(in second column of probs_y)\n#pr_auc = roc_auc_score(recall, precision)\n\nplt.title(\"Precision-Recall vs Threshold Chart\")\nplt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\nplt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\nplt.ylabel(\"Precision, Recall\")\nplt.xlabel(\"Threshold\")\nplt.legend(loc=\"lower left\")\nplt.ylim([0,1])","9250958e":"from numpy import argmax\nfscore = (2 * precision * recall) \/ (precision + recall)\n# locate the index of the largest f score\nix = argmax(fscore)\nprint('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n# plot the roc curve for the model\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\npyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\npyplot.plot(recall, precision, marker='.', label='LightGBM')\npyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n# axis labels\npyplot.xlabel('Recall')\npyplot.ylabel('Precision')\npyplot.legend()\n# show the plot\npyplot.show()","4709797d":"THRESHOLD = 0.353023\ntest_pred = np.where(model.predict_proba(X_test)[:,1] > THRESHOLD, 1,0)","efa391e6":"# get the best threshold\nJ = true_positive_rate1 - false_positive_rate1\nix = argmax(J)\nbest_thresh = thresholds[ix]\nprint('Best Threshold=%f' % (best_thresh))","bdb0edec":"test['Avg_Account_Balance'] = np.log(test['Avg_Account_Balance'])","7660d3a0":"test.fillna({\"Credit_Product\": 'None'}, inplace = True)","f960c2b1":"test =pd.get_dummies(test, columns=['Gender','Region_Code','Occupation','Channel_Code','Credit_Product','Is_Active'], drop_first=True)","e6eeae5b":"del test['ID']","740c3ff8":"test = test.loc[:, test.columns != 'Is_Lead']","5442c4c8":"cm = confusion_matrix(y_test, y_pred2)\nplt.figure(figsize = (8,5))\n\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,  cmap = 'YlGnBu')\n\n# print the scores on training and test set\nall_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_pred2))\n\nplt.title(all_sample_title, size = 19)\nplt.savefig(\"pne.png\")","d7785703":"# **Decision Tree**","9c07e7c4":"# **Handling Missing values** ","ffbbfe5d":"# **Correlation** ","bc8eb73f":"# **LightGBM**","1ef6f991":"# **Random Forest**","c16373a9":"<font color='green'>","a07705dc":"# **Importing Libraries**","61144a81":"# **Creating Dummy Variables**","fe7da61b":"# **Visulization**","e4612292":"We can see the crrelation between 'vitange' and 'Age' is high.","f248c98b":"# **Train-Data** ","869d9329":"## **preproccesing**","111e1db1":"### **here we got the great accuracy score for the test dataset also.**","39820d9c":"Here we can see there is missing values in 'Credit_Product' so we replace these missing values bye Nan","111ec0e5":"**Here we obtained highest roc for LightGBM. so we apply same model for test dataset**","fd086e0f":"# **Model Fitting**","9303b28c":"# **Test Data**"}}