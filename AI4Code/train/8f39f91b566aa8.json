{"cell_type":{"37ba9436":"code","52c79f15":"code","31e531a6":"code","dec50241":"code","29e1bf2d":"code","5c5ea9cc":"code","b038d7d7":"code","f781cf8b":"code","5407fed6":"code","7e3c4290":"code","46ddae0d":"code","7e31b244":"code","0dc365b4":"code","b496d22a":"code","d66e5b17":"code","806c88a9":"code","2a241d23":"code","f4584a8e":"code","5b6355b5":"markdown","4a24dfba":"markdown","39792e71":"markdown","f5e6de36":"markdown","cc53d470":"markdown","a1461eb3":"markdown","3f7e76df":"markdown","1c21d592":"markdown","622cb52a":"markdown"},"source":{"37ba9436":"from tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Conv2DTranspose, BatchNormalization, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nimport cv2\nimport pandas as pd\nimport numpy as np","52c79f15":"train_files = []\nmask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\n\nfor i in mask_files:\n    train_files.append(i.replace('_mask',''))\n\nprint(train_files[:3])\nprint(mask_files[:3])","31e531a6":"def plot_samples(rows, cols):\n    fig = plt.figure(figsize=(12,12))\n    for i in range(1, rows * cols + 1):\n        fig.add_subplot(rows, cols, i)\n        image_path = train_files[i]\n        mask_path = mask_files[i]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path)\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.6)\n    plt.show()\n\nplot_samples(3,4)","dec50241":"df = pd.DataFrame(data={'filename': train_files, 'mask': mask_files})\ndf_train, df_test = train_test_split(df, test_size=0.1, random_state=42) # test:0.1\ndf_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42) # train: 0.7  validation: 0.2\n\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","29e1bf2d":"def train_generator(dataframe, \n                    batch_size, \n                    aug_dict,\n                    image_color_mode = \"rgb\",\n                    mask_color_mode = \"grayscale\",\n                    image_save_prefix = \"image\",\n                    mask_save_prefix = \"mask\",\n                    save_to_dir = None,\n                    target_size = (256,256),\n                    seed = 1):\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(dataframe,\n                                                              x_col = \"filename\",\n                                                              class_mode = None,\n                                                              color_mode = image_color_mode,\n                                                              target_size = target_size,\n                                                              batch_size = batch_size,\n                                                              save_to_dir = save_to_dir,\n                                                              save_prefix  = image_save_prefix,\n                                                              seed = seed)\n    mask_generator = mask_datagen.flow_from_dataframe(dataframe,\n                                                            x_col = \"mask\",\n                                                            class_mode = None,\n                                                            color_mode = mask_color_mode,\n                                                            target_size = target_size,\n                                                            batch_size = batch_size,\n                                                            save_to_dir = save_to_dir,\n                                                            save_prefix  = mask_save_prefix,\n                                                            seed = seed)\n    train_gen = zip(image_generator, mask_generator)\n    for (image, mask) in train_gen:\n        image, mask = normalize_data(image, mask)\n        yield (image, mask)\n\n        \ndef normalize_data(image, mask):\n    image = image \/ 255\n    mask = mask \/ 255\n    mask[mask > 0.5] = 1 # tumor\n    mask[mask <= 0.5] = 0 # no tumor\n    return (image, mask)","5c5ea9cc":"def dice_coef(y_true, y_pred, smooth = 100):\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred)\n    intersection = K.sum(y_true_flat * y_pred_flat)\n    sum_ = K.sum(y_true_flat) + K.sum(y_pred_flat)\n    return (2 * intersection + smooth) \/ (sum_ + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","b038d7d7":"def iou(y_true, y_pred, smooth = 100):\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred)\n    intersection = K.sum(y_true_flat * y_pred_flat)\n    union = K.sum(y_true_flat) + K.sum(y_pred_flat) - intersection\n    return (intersection + smooth) \/ (union + smooth)","f781cf8b":"def conv_block(input, num_filters):\n    x = Conv2D(num_filters, (3,3), padding='same')(input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(num_filters, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x","5407fed6":"def encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPooling2D(pool_size=(2,2))(x)\n    return x,p","7e3c4290":"def decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x","46ddae0d":"def build_unet(input_shape):\n    inputs = Input(input_shape)\n    \n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n    \n    b1 = conv_block(p4, 1024) # bridge\n    \n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n    \n    outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(d4)\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model","7e31b244":"IMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3\n\ninput_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)","0dc365b4":"EPOCHS = 150\nBATCH_SIZE = 32\nlearning_rate = 1e-4","b496d22a":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train,\n                            BATCH_SIZE,\n                            train_generator_args,\n                            target_size=(IMG_HEIGHT, IMG_WIDTH))\nval_gen = train_generator(df_val,\n                          BATCH_SIZE,\n                          dict(),\n                          target_size=(IMG_HEIGHT, IMG_WIDTH))\nmodel = build_unet(input_shape)\ndecay_rate = learning_rate \/ EPOCHS\nopt = Adam(learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\nmodel.summary()","d66e5b17":"callbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = val_gen,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)","806c88a9":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\n\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","2a241d23":"model = load_model('unet_brain_mri_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\ntest_gen = train_generator(df_test,\n                           BATCH_SIZE,\n                           dict(),\n                           target_size=(IMG_WIDTH, IMG_HEIGHT))\nresults = model.evaluate(test_gen, steps=len(df_test) \/ BATCH_SIZE)\nprint(\"Test lost: \",results[0])\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","f4584a8e":"for i in range(50):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['filename'].iloc[index])\n    img = cv2.resize(img ,(IMG_HEIGHT, IMG_WIDTH))\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","5b6355b5":"# metrics","4a24dfba":"# imports","39792e71":"# build model","f5e6de36":"# create dataframe & split data","cc53d470":"IOU = \u062a\u0627\u0628\u0639 \u0632\u06cc\u0627\u0646 \u0627\u0634\u062a\u0631\u0627\u06a9 \u062f\u0631 \u0627\u062c\u062a\u0645\u0627\u0639 \u0645\u062a\u0642\u0627\u0631\u0646\n\n\\begin{equation}\nJ(A, B)=\\frac{|A \\cap B|}{|A \\cup B|}=\\frac{|A \\cap B|}{|A|+|B|-|A \\cap B|}\n\\end{equation}","a1461eb3":"# data generator","3f7e76df":"# train","1c21d592":"DSC = \u062a\u0627\u0628\u0639 \u0632\u06cc\u0627\u0646 \u062a\u0627\u0633\n\\begin{equation}\nD S C=\\frac{2|X \\cap Y|}{|X|+|Y|}\n\\end{equation}","622cb52a":"# load dataset"}}