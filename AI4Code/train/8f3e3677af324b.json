{"cell_type":{"1e2e69f9":"code","46233291":"code","56bbf2e9":"code","f9203379":"code","b32c4ac9":"code","31c9702f":"code","d3fed68f":"code","0a0ecd98":"code","61b56ded":"code","acd39f3e":"code","23752c66":"code","32edc075":"code","e8f09584":"code","5a9fa4e5":"code","7ee10f28":"code","c5106adc":"code","bf36fac6":"code","e67417df":"code","1069942b":"code","394e3e47":"code","9c4e62bd":"code","941d6bd6":"code","9c3f086c":"code","13bb0a6d":"code","459e22eb":"code","2f1e4bb6":"code","9e989bc1":"code","f1321462":"code","1e8a54a7":"code","69d52ee3":"code","a28e25ba":"code","a995cc32":"markdown","2e0be8a3":"markdown","0767b010":"markdown","21c7dce6":"markdown","176f2981":"markdown"},"source":{"1e2e69f9":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","46233291":"class MultipleRegression():\n    def __init__(self, reg=0.01):\n        self.reg = reg\n        self.BETA = None\n    def fit(self, Y, Z):\n        F = Z.shape[1]\n        U = np.linalg.inv(Z.T.dot(Z)+self.reg*np.eye(F))\n        self.BETA = Y.dot(Z).dot(U)\n    def predict(self, Z):\n        return  self.BETA.dot(Z.T)\n#=======================","56bbf2e9":"#======================================#\ndef preprocess_calendar(calendar):\n    global maps, mods\n    calendar[\"event_name\"] = calendar[\"event_name_1\"]\n    calendar[\"event_type\"] = calendar[\"event_type_1\"]\n\n    map1 = {mod:i for i,mod in enumerate(calendar['event_name'].unique())}\n    calendar['event_name'] = calendar['event_name'].map(map1)\n    map2 = {mod:i for i,mod in enumerate(calendar['event_type'].unique())}\n    calendar['event_type'] = calendar['event_type'].map(map2)\n    calendar['nday'] = calendar['date'].str[-2:].astype(int)\n    maps[\"event_name\"] = map1\n    maps[\"event_type\"] = map2\n    mods[\"event_name\"] = len(map1)\n    mods[\"event_type\"] = len(map2)\n    calendar[\"wday\"] -=1\n    calendar[\"month\"] -=1\n    calendar[\"year\"] -= 2011\n    mods[\"month\"] = 12\n    mods[\"year\"] = 6\n    mods[\"wday\"] = 7\n    mods['snap_CA'] = 2\n    mods['snap_TX'] = 2\n    mods['snap_WI'] = 2\n\n    calendar.drop([\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"date\", \"weekday\"], \n                  axis=1, inplace=True)\n    return calendar\n#=========================================================","f9203379":"maps, mods = {}, {}\ncalendar = pd.read_csv(\"..\/input\/m5-forecasting-uncertainty\/calendar.csv\")\ncalendar = preprocess_calendar(calendar)\ncalendar['nb'] = calendar.index + 1\ncalendar['n_week'] = (calendar.index - 2) \/\/ 7","b32c4ac9":"calendar.head()","31c9702f":"%%time\nFE = ['snap_CA','snap_TX','snap_WI']\nfor col in tqdm(['wday','month','year','event_name','nday']):\n    _temp = pd.get_dummies(calendar[col], prefix=col)\n    new_cols = list(_temp.columns)\n    FE += new_cols\n    calendar = calendar.join(_temp)\n#gc.collect()","d3fed68f":"sales = pd.read_csv(\"..\/input\/walmartadd\/sales_aug.csv\")","0a0ecd98":"START = 1000\nH = 28\nB = 28\nCOLS = [f\"d_{i}\" for i in range(START, 1942)]\ncalendar = calendar[calendar.nb>=START]\nids = sales.id.values","61b56ded":"sc = sales['scale1'].values","acd39f3e":"\"\"\"\nPOLY_COLS = ['t1']\ncalendar['t1'] = calendar.n_week \/ 300\nMAX_DEG = 10\nfor deg in range(2, MAX_DEG+1):\n    calendar[f't{deg}'] = calendar['t1']**deg\n    POLY_COLS.append(f't{deg}')\n\"\"\"\n#","23752c66":"calendar.t1","32edc075":"X = sales[COLS].values\nsw = sales['sales1'].values\nsc = sales['scale1'].values\nZ = calendar[FE].values\n#Z = calendar[FE+POLY_COLS].values\nXs = X \/ sc[:, np.newaxis]\nprint(X.shape, Z.shape)","e8f09584":"%%time\nstep1 = MultipleRegression(reg=0.001)\nstep1.fit(Xs, Z[:-28])","5a9fa4e5":"Xp = step1.predict(Z)","7ee10f28":"INF = 0#40_000\nk = np.random.randint(INF, 42840)\nplt.plot(Xs[k, 800:])\nplt.plot(Xp[k, 800:])\nplt.title(ids[k])\nplt.show()","c5106adc":"Xs.shape, Xp.shape","bf36fac6":"print(\"mae:\", mean_absolute_error(Xs[:, -28:], Xp[:,-56:-28]) )\nprint(\"mse:\", mean_squared_error(Xs[:, -28:], Xp[:,-56:-28], squared=False))","e67417df":"resid = Xs - Xp[:, :-28]","1069942b":"qs = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]\ncp = np.quantile(resid, qs, axis=1).T","394e3e47":"cp = cp[:,np.newaxis, :]","9c4e62bd":"Zq = Xp[:,:,np.newaxis] + cp","941d6bd6":"Zq  = Zq.clip(0)","9c3f086c":"INF = 0#40_000\nk = np.random.randint(INF, 42840)\nplt.plot(Xs[k, -28:], label=\"groud truth\")\nplt.plot(Zq[k, -56:, 3], label=\"q25\")\nplt.plot(Zq[k, -56:, 4], label=\"q50\")\nplt.plot(Zq[k, -56:, 5], label=\"q75\")\nplt.title(ids[k])\nplt.legend(loc=\"best\")\nplt.show()","13bb0a6d":"pv = Zq[:,-56:-28, :]\npe = Zq[:,-28:, :]","459e22eb":"pv.shape, pe.shape","2f1e4bb6":"sc= sc[:, np.newaxis]","9e989bc1":"names = [f\"F{i+1}\" for i in range(28)]\npiv = pd.DataFrame(ids, columns=[\"id\"])","f1321462":"QUANTILES = [\"0.005\", \"0.025\", \"0.165\", \"0.250\", \"0.500\", \"0.750\", \"0.835\", \"0.975\", \"0.995\"]\nVALID = []\nEVAL = []\n\nfor i, quantile in tqdm(enumerate(QUANTILES)):\n    t1 = pd.DataFrame(pv[:,:, i]*sc, columns=names)\n    t1 = piv.join(t1)\n    t1[\"id\"] = t1[\"id\"] + f\"_{quantile}_validation\"\n    t2 = pd.DataFrame(pe[:,:, i]*sc, columns=names)\n    t2 = piv.join(t2)\n    t2[\"id\"] = t2[\"id\"] + f\"_{quantile}_evaluation\"\n    VALID.append(t1)\n    EVAL.append(t2)\n#============#","1e8a54a7":"sub = pd.DataFrame()\nsub = sub.append(VALID + EVAL)\ndel VALID, EVAL, t1, t2","69d52ee3":"sub.head()","a28e25ba":"sub.to_csv(\"submission.csv\", index=False)","a995cc32":"Our idea is to run simultaneously many parallel linear regressions for every id (the 42k series) and use the resids to estimate quantiles. Let imagine that we have $N$ series of length $T$ in a vector $Y$ with shape $(N, T)$ and covariates of temporal features $Z$ with shape $(T, F)$. For id $i$ we will run the following regression:\n$$ Y_i^T = Z \\beta_i^T + \\epsilon_i $$\n\nSo if we compact all the individual OLS parameters $\\beta_i$ in a vector $\\beta$. The global model will be written as:\n$$ Y = \\beta Z^T + \\epsilon $$\n\n**STEP 1: PARAMETER OPTIMIZATION**\n\nTherefore we can solve the following problem including regularization:\n\n$$ \\hat{\\beta}_{\\lambda} = \\arg\\min \\mid \\mid Y - \\beta Z^T \\mid \\mid_F^2 + \\lambda \\mid \\mid \\beta \\mid \\mid_F^2  $$\n\nIt is easy to see that:\n$$ \\hat{\\beta}_{\\lambda} = YZ \\left( Z^T Z + \\lambda I_F \\right)^{-1} $$\n\n\n**STEP 2: QUANTILE PREDICTION**\n\nwe have compute then the resid:\n$$  \\hat{Y}^{\\lambda} = \\hat{\\beta}_{\\lambda} Z^T, \\quad  \\hat{\\epsilon} = Y - \\hat{Y}^{\\lambda} $$\n\nAnd we finally compute the quantile $q$ by:\n\n$$\\hat{Y}_{it}^q =\\hat{Y}^{\\lambda}_{it} + quantile(\\hat{\\epsilon}_{it}, q) $$\n\n$\\lambda$ can be learned by cross-validation.\n\nNow let's code it out !!!\n","2e0be8a3":"## Quantile Prediction","0767b010":"## Data","21c7dce6":"## Parameter Estimation","176f2981":"## Modeling"}}