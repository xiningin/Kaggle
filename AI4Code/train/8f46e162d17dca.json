{"cell_type":{"4683468e":"code","af518470":"code","165e43b9":"code","c05d8330":"code","a94f8ea8":"code","6f781dc5":"code","2cc43900":"code","a618de14":"code","dd1c2468":"code","7446e693":"code","0fb472a3":"code","2fe9ca34":"code","e34848a4":"code","be72a2de":"code","0a6c8bd4":"code","cece5728":"code","1b178b0e":"code","7c0f4298":"code","ef3566be":"code","31f3c580":"code","1b4bad7d":"code","17dc0c2c":"code","2323bc65":"code","f492366c":"code","9b883c3b":"code","c3d06efd":"code","add5f0fb":"code","e6cedb92":"code","5e1235c9":"code","24c1c119":"code","e02c2f52":"code","0b80f128":"code","ae1c0aa6":"code","5eee7b36":"code","4e70d7a3":"code","2f027340":"code","f8c997d1":"code","5834a0ba":"code","c024e19f":"code","1a6eac78":"code","a31d4b20":"code","aef14644":"code","373978cb":"code","cd8e44ff":"code","360c12ef":"code","875fbaa1":"code","c3254a49":"code","fddf5b54":"code","3f234c65":"code","3c8d5103":"code","dc33449e":"code","9cd4b894":"code","a97d2e93":"code","79b7f8c1":"code","cc707f64":"code","96c218cd":"code","348d05e6":"code","a9a638b5":"code","ce4575bb":"code","838d655b":"code","09e5ca15":"code","dec3f034":"code","0690258d":"code","853453a0":"code","63f74c10":"code","9ae5a54b":"code","1d703bd7":"code","fc00e745":"code","c284a3c5":"code","ed070dd2":"code","07a575c1":"code","80e3087d":"code","6cf92ef9":"code","54e7c2e8":"code","bdc6bd4f":"code","fe7385b1":"markdown","3678a1b3":"markdown","044826d6":"markdown","2b3ffde8":"markdown","cabd4827":"markdown","82d803b1":"markdown","cd43c714":"markdown","e541888f":"markdown","05de7f41":"markdown","61628dd1":"markdown","f8d52a34":"markdown","b9e2ccab":"markdown","91e9995b":"markdown","c106e78c":"markdown","2b102d1e":"markdown","660a6674":"markdown","960d41dc":"markdown","7ef8212f":"markdown","12a12055":"markdown","6a67afc9":"markdown","ef7d8da9":"markdown","7916172d":"markdown"},"source":{"4683468e":"import datetime, os\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg\nimport cv2\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\n# Import skimage modules\nfrom skimage import data, img_as_float\nfrom skimage import exposure\nfrom skimage.io import imread, imsave\nfrom skimage import exposure, color\nfrom skimage.transform import resize\nfrom skimage.util.dtype import dtype_range\nfrom skimage.util import img_as_ubyte\nfrom skimage.morphology import disk\nfrom skimage.filters import rank","af518470":"df_train = pd.read_csv(\"..\/input\/i2a2-brasil-pneumonia-classification\/train.csv\")\nprint('------------------------------')\nprint(df_train.info())\nprint('------------------------------')\nprint(df_train.head())\nprint('------------------------------')\nprint(df_train.shape)","165e43b9":"images_dir = os.path.join('..', 'input', 'i2a2-brasil-pneumonia-classification', 'images')\n\ndf_train['path'] = df_train['fileName'].map(lambda x: os.path.join(images_dir))\n\ndf_train.head()","c05d8330":"df_train['path'] = df_train['path'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists'] = df_train['path'].map(os.path.exists)\n\nprint('------------------------------')\nprint(df_train['exists'].sum(), 'images found of', df_train.shape[0], 'total')\nprint('------------------------------')\nprint(df_train.head())\nprint('------------------------------')\nprint(df_train.shape)\n","a94f8ea8":"for row in df_train.iterrows():\n    img_name = row[1][0]\n    img = mpimg.imread(\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/\"+img_name)\n    df_train['height'] = img.shape[0]\n    df_train['width'] = img.shape[1]\n    \nprint('----------------------------')\n#basic statistics\nprint('Statistics')\nprint(df_train.describe())\nprint('----------------------------')","6f781dc5":"df_train[['pneumonia']].hist(figsize = (10, 5));","2cc43900":"plt.figure(figsize=(20, 10))\n\nax = sns.kdeplot(df_train['pneumonia'], label='Global Distribution')\nax.set_title('Pneumonia Distribution', color='b')\nax.set_xlabel('pneumonia', color='b')\nax.set_xlabel('frequency', color='b')\nax.tick_params(labelcolor='b')","a618de14":"for fileName, pneumonia in df_train[['fileName','pneumonia']].sample(5).values:\n    img_name = str(fileName)\n    img = mpimg.imread(\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/\"+img_name)\n    plt.imshow(img)\n    plt.title('Image: {} Pneumonia: {}'.format(fileName, pneumonia))\n    plt.show()","dd1c2468":"fig, m_axs = plt.subplots(pneumonia, 3, figsize = (18, 12))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), \n                            df_train.sort_values(['pneumonia']).iterrows()):\n    c_ax.imshow(mpimg.imread(c_row['path']), cmap = 'hot')\n    c_ax.axis('off')\n    c_ax.set_title('Image: {} Pneumonia: {}'.format(fileName, pneumonia))","7446e693":"def plot_img_and_hist(image, axes, bins=256):\n    \"\"\"Plot an image along with its histogram and cumulative histogram.\n    \"\"\"\n    ax_img, ax_hist = axes\n    ax_cdf = ax_hist.twinx()\n\n    # Display image\n    ax_img.imshow(image, cmap=plt.cm.gray)\n    ax_img.set_axis_off()\n\n    # Display histogram\n    ax_hist.hist(image.ravel(), bins=bins)\n    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n    ax_hist.set_xlabel('Pixel intensity')\n\n    xmin, xmax = dtype_range[image.dtype.type]\n    ax_hist.set_xlim(xmin, xmax)\n\n    # Display cumulative distribution\n    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n    ax_cdf.plot(bins, img_cdf, 'r')\n\n    return ax_img, ax_hist, ax_cdf","0fb472a3":"# Load an example image\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), \n                            df_train.sort_values(['pneumonia']).iterrows()):\n    img = img_as_ubyte(imread(c_row['path'])\/255)\n\n# Global equalize\nimg_rescale = exposure.equalize_hist(img)\n\n# Equalization\nselem = disk(30)\nimg_eq = rank.equalize(img, selem=selem)\n\n\n# Display results\nfig = plt.figure(figsize=(18, 12))\naxes = np.zeros((2, 3), dtype=np.object)\naxes[0, 0] = plt.subplot(2, 3, 1)\naxes[0, 1] = plt.subplot(2, 3, 2, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[0, 2] = plt.subplot(2, 3, 3, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[1, 0] = plt.subplot(2, 3, 4)\naxes[1, 1] = plt.subplot(2, 3, 5)\naxes[1, 2] = plt.subplot(2, 3, 6)\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\nax_img.set_title('Low contrast image')\nax_hist.set_ylabel('Number of pixels')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\nax_img.set_title('Global equalise')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\nax_img.set_title('Local equalize')\nax_cdf.set_ylabel('Fraction of total intensity')\n\n\n# prevent overlap of y-axis labels\nfig.tight_layout()\nplt.show()\n\nimages=pd.DataFrame([])","2fe9ca34":"# Gamma\ngamma_corrected = exposure.adjust_gamma(img, 2)\n\n# Logarithmic\nlogarithmic_corrected = exposure.adjust_log(img, 1)\n\n# Display results\nfig = plt.figure(figsize=(18, 12))\naxes = np.zeros((2, 3), dtype=np.object)\naxes[0, 0] = plt.subplot(2, 3, 1)\naxes[0, 1] = plt.subplot(2, 3, 2, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[0, 2] = plt.subplot(2, 3, 3, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[1, 0] = plt.subplot(2, 3, 4)\naxes[1, 1] = plt.subplot(2, 3, 5)\naxes[1, 2] = plt.subplot(2, 3, 6)\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\nax_img.set_title('Low contrast image')\n\ny_min, y_max = ax_hist.get_ylim()\nax_hist.set_ylabel('Number of pixels')\nax_hist.set_yticks(np.linspace(0, y_max, 5))\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(gamma_corrected, axes[:, 1])\nax_img.set_title('Gamma correction')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(logarithmic_corrected, axes[:, 2])\nax_img.set_title('Logarithmic correction')\n\nax_cdf.set_ylabel('Fraction of total intensity')\nax_cdf.set_yticks(np.linspace(0, 1, 5))\n\n# prevent overlap of y-axis labels\nfig.tight_layout()\nplt.show()\n\n","e34848a4":"# Contrast stretching\np2, p98 = np.percentile(img, (2, 98))\nimg_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n\n# Equalization\nimg_eq = exposure.equalize_hist(img)\n\n# Adaptive Equalization\nimg_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n\n# Display results\nfig = plt.figure(figsize=(18, 12))\naxes = np.zeros((2, 4), dtype=np.object)\naxes[0, 0] = fig.add_subplot(2, 4, 1)\nfor i in range(1, 4):\n    axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\nfor i in range(0, 4):\n    axes[1, i] = fig.add_subplot(2, 4, 5+i)\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\nax_img.set_title('Low contrast image')\n\ny_min, y_max = ax_hist.get_ylim()\nax_hist.set_ylabel('Number of pixels')\nax_hist.set_yticks(np.linspace(0, y_max, 5))\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\nax_img.set_title('Contrast stretching')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\nax_img.set_title('Histogram equalization')\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\nax_img.set_title('Adaptive equalization')\n\nax_cdf.set_ylabel('Fraction of total intensity')\nax_cdf.set_yticks(np.linspace(0, 1, 5))\n\n# prevent overlap of y-axis labels\nfig.tight_layout()\nplt.show()","be72a2de":"# global thresholding\nret1,th1 = cv2.threshold(img,150,255,cv2.THRESH_BINARY)\n\n# Otsu's thresholding\nret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(img,(3,3),0)\nret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n# Display results\nfig = plt.figure(figsize=(18, 12))\naxes = np.zeros((2, 3), dtype=np.object)\naxes[0, 0] = plt.subplot(2, 3, 1)\naxes[0, 1] = plt.subplot(2, 3, 2, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[0, 2] = plt.subplot(2, 3, 3, sharex=axes[0, 0], sharey=axes[0, 0])\naxes[1, 0] = plt.subplot(2, 3, 4)\naxes[1, 1] = plt.subplot(2, 3, 5)\naxes[1, 2] = plt.subplot(2, 3, 6)\n\nax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\nax_img.set_title('Low contrast image')\n\n# plot all the images and their histograms\nimages = [img, 0, th1,\n          img, 0, th2,\n          blur, 0, th3]\ntitles = ['Original Noisy Image','Histogram','Global Thresholding (v=150)',\n          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n\nfor i in range(3):\n    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\nplt.show()","0a6c8bd4":"df_train = df_train.head(15)","cece5728":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/global_eq_images')","1b178b0e":"# Global Equalize\ndef global_equalize(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    img_rescale = exposure.equalize_hist(img)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/global_eq_images\/{filename}\", img_rescale)","7c0f4298":"%%time\ndf_train.apply(lambda row : global_equalize(row['fileName']),axis = 1)","ef3566be":"images_dir_g = os.path.join('..', 'output', 'kaggle', 'working', 'global_eq_images')\n\ndf_train['path_g'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_g))\n\ndf_train.head()","31f3c580":"df_train['path_g'] = df_train['path_g'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_g'] = df_train['path_g'].map(os.path.exists)\n\nprint(df_train['exists_g'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","1b4bad7d":"df = df_train\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/global_eq_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()    ","17dc0c2c":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/linear_eq_images')","2323bc65":"# Linear Equalization\ndef linear_equalization(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    # Equalization\n    selem = disk(30)\n    img_eq = rank.equalize(img, selem=selem)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/linear_eq_images\/{filename}\", img_eq)","f492366c":"%%time\ndf_train.apply(lambda row : linear_equalization(row['fileName']),axis = 1)","9b883c3b":"images_dir_l = os.path.join('..', 'output', 'kaggle', 'working', 'linear_eq_images')\n\ndf_train['path_l'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_l))\n\ndf_train.head()","c3d06efd":"df_train['path_l'] = df_train['path_l'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_l'] = df_train['path_l'].map(os.path.exists)\n\nprint(df_train['exists_l'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","add5f0fb":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/linear_eq_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()    ","e6cedb92":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/gamma_images')","5e1235c9":"# Gamma\ndef gamma_correction(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    gamma_corrected = exposure.adjust_gamma(img, 2)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/gamma_images\/{filename}\", gamma_corrected)","24c1c119":"%%time\ndf_train.apply(lambda row : gamma_correction(row['fileName']),axis = 1)","e02c2f52":"images_dir_gm = os.path.join('..', 'output', 'kaggle', 'working', 'gamma_images')\n\ndf_train['path_gm'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_gm))\n\ndf_train.head()","0b80f128":"df_train['path_gm'] = df_train['path_gm'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_gm'] = df_train['path_gm'].map(os.path.exists)\n\nprint(df_train['exists_gm'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","ae1c0aa6":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/gamma_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()    ","5eee7b36":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/log_corr_images')","4e70d7a3":"# Logarithmic\ndef log_correction(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    logarithmic_corrected = exposure.adjust_log(img, 1)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/log_corr_images\/{filename}\", logarithmic_corrected)","2f027340":"%%time\ndf_train.apply(lambda row : log_correction(row['fileName']),axis = 1)","f8c997d1":"images_dir_lc = os.path.join('..', 'output', 'kaggle', 'working', 'log_corr_images')\n\ndf_train['path_lc'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_lc))\n\ndf_train.head()","5834a0ba":"df_train['path_lc'] = df_train['path_lc'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_lc'] = df_train['path_lc'].map(os.path.exists)\n\nprint(df_train['exists_lc'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","c024e19f":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/log_corr_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()   ","1a6eac78":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/contrast_images')","a31d4b20":"# Contrast stretching\ndef contrast_stretching(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    p2, p98 = np.percentile(img, (2, 98))\n    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/contrast_images\/{filename}\", img_rescale)","aef14644":"%%time\ndf_train.apply(lambda row : contrast_stretching(row['fileName']),axis = 1)","373978cb":"images_dir_cs = os.path.join('..', 'output', 'kaggle', 'working', 'contrast_images')\n\ndf_train['path_cs'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_cs))\n\ndf_train.head()","cd8e44ff":"df_train['path_cs'] = df_train['path_cs'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_cs'] = df_train['path_cs'].map(os.path.exists)\n\nprint(df_train['exists_cs'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","360c12ef":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/contrast_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()    ","875fbaa1":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/equalization_images')","c3254a49":"# Equalization\ndef hist_equalization(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    img_eq = exposure.equalize_hist(img)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/equalization_images\/{filename}\", img_eq)","fddf5b54":"%%time\ndf_train.apply(lambda row : hist_equalization(row['fileName']),axis = 1)","3f234c65":"images_dir_ha = os.path.join('..', 'output', 'kaggle', 'working', 'equalization_images')\n\ndf_train['path_ha'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_ha))\n\ndf_train.head()","3c8d5103":"df_train['path_ha'] = df_train['path_ha'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_ha'] = df_train['path_ha'].map(os.path.exists)\n\nprint(df_train['exists_ha'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","dc33449e":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/equalization_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()  ","9cd4b894":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/adp_eq_images')","a97d2e93":"# Adaptive Equalization\ndef adapt_equalization(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/adp_eq_images\/{filename}\", img_adapteq)","79b7f8c1":"%%time\ndf_train.apply(lambda row : adapt_equalization(row['fileName']),axis = 1)","cc707f64":"images_dir_a = os.path.join('..', 'output', 'kaggle', 'working', 'adp_eq_images')\n\ndf_train['path_a'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_a))\n\ndf_train.head()","96c218cd":"df_train['path_a'] = df_train['path_a'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_a'] = df_train['path_a'].map(os.path.exists)\n\nprint(df_train['exists_a'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","348d05e6":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/adp_eq_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()    ","a9a638b5":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/gthresh_images')","ce4575bb":"# global thresholding\ndef global_thresholding(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    ret1,th1 = cv2.threshold(img,150,255,cv2.THRESH_BINARY)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/gthresh_images\/{filename}\", th1)","838d655b":"%%time\ndf_train.apply(lambda row : global_thresholding(row['fileName']),axis = 1)","09e5ca15":"images_dir_gt = os.path.join('..', 'output', 'kaggle', 'working', 'gthresh_images')\n\ndf_train['path_gt'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_gt))\n\ndf_train.head()","dec3f034":"df_train['path_gt'] = df_train['path_gt'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_gt'] = df_train['path_gt'].map(os.path.exists)\n\nprint(df_train['exists_gt'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","0690258d":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/gthresh_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()  ","853453a0":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/othresh_images')","63f74c10":"# Otsu's thresholding\ndef otsus_thresholding(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/othresh_images\/{filename}\", th2)","9ae5a54b":"%%time\ndf_train.apply(lambda row : otsus_thresholding(row['fileName']),axis = 1)","1d703bd7":"images_dir_ot = os.path.join('..', 'output', 'kaggle', 'working', 'othresh_images')\n\ndf_train['path_ot'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_ot))\n\ndf_train.head()","fc00e745":"df_train['path_ot'] = df_train['path_ot'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_ot'] = df_train['path_ot'].map(os.path.exists)\n\nprint(df_train['exists_ot'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","c284a3c5":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/othresh_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()  ","ed070dd2":"# saving processed images\nos.makedirs(f'\/kaggle\/output\/kaggle\/working\/ogthresh_images')","07a575c1":"# Otsu's thresholding after Gaussian filtering\ndef otsus_gaussian_thresholding(filename):\n    image = cv2.imread(f\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\", 0)\n    norm_img = np.zeros((524,948))\n    img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    blur = cv2.GaussianBlur(img,(3,3),0)\n    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    cv2.imwrite(f\"\/kaggle\/output\/kaggle\/working\/ogthresh_images\/{filename}\", th3)","80e3087d":"%%time\ndf_train.apply(lambda row : otsus_gaussian_thresholding(row['fileName']),axis = 1)","6cf92ef9":"images_dir_ogt = os.path.join('..', 'output', 'kaggle', 'working', 'ogthresh_images')\n\ndf_train['path_ogt'] = df_train['fileName'].map(lambda x: os.path.join(images_dir_ogt))\n\ndf_train.head()","54e7c2e8":"df_train['path_ogt'] = df_train['path_ogt'].str.cat(df_train[['fileName']], sep='\/')\n\ndf_train['exists_ogt'] = df_train['path_ogt'].map(os.path.exists)\n\nprint(df_train['exists_ogt'].sum(), 'images found of', df_train.shape[0], 'total')\n\ndf_train.head()","bdc6bd4f":"# df = df_train.head(15)\n\nfor filename in df['fileName']:\n  plt.title('Before')\n  before = mpimg.imread(f\"..\/input\/i2a2-brasil-pneumonia-classification\/images\/{filename}\")\n  imgplot = plt.imshow(before)\n  plt.show()\n\n  plt.title('After')\n  after = mpimg.imread(f\"..\/output\/kaggle\/working\/ogthresh_images\/{filename}\")\n  imgplot = plt.imshow(after)\n  plt.show()  ","fe7385b1":"### Contrast stretching \u00e9 uma t\u00e9cnica simples de processamento de imagem que aprimora o contraste ao redimensionar (\"alongar\") o intervalo de valores de intensidade de uma imagem para um intervalo de valores desejado.\n\n### Equalization (equaliza\u00e7\u00e3o do histograma) \u00e9 outra t\u00e9cnica de processamento de imagem para aumentar o contraste global de uma imagem usando o histograma de intensidade da imagem. A imagem equalizada possui uma fun\u00e7\u00e3o de distribui\u00e7\u00e3o cumulativa linear. Esse m\u00e9todo n\u00e3o precisa de par\u00e2metro, mas \u00e0s vezes resulta em uma imagem com apar\u00eancia n\u00e3o natural.\n\n### Uma alternativa \u00e9 o Adaptive Equalization (equaliza\u00e7\u00e3o adaptativa do histograma) (AHE), que melhora o contraste local de uma imagem computando v\u00e1rios histogramas correspondentes a se\u00e7\u00f5es diferentes de uma imagem (difere da equaliza\u00e7\u00e3o comum do histograma, que usa apenas um histograma para ajustar o contraste global) e os utiliza para o ajuste do contraste local . No entanto, o AHE tende a amplificar excessivamente o ru\u00eddo em regi\u00f5es relativamente homog\u00eaneas de uma imagem.\n\nhttps:\/\/towardsdatascience.com\/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2","3678a1b3":"### Linear Equalization","044826d6":"### Gamma Correction","2b3ffde8":"# EDA e Preprocessamento de imagem\n\n## Nesse notebook s\u00e3o analisadas a distribui\u00e7\u00e3o entre as classes, as imagens e constru\u00eddas 10 possibilidades de preprocessamento das imagens","cabd4827":"### Gamma Correction (corre\u00e7\u00e3o gama) \u00e9 usada para corrigir as diferen\u00e7as entre a maneira como a c\u00e2mera captura o conte\u00fado, a maneira como a tela exibe o conte\u00fado e a maneira como nosso sistema visual processa a luz. Nossos olhos n\u00e3o respondem \u00e0 luz da mesma maneira que uma c\u00e2mera a captura. Em termos b\u00e1sicos, se o dobro do n\u00famero de f\u00f3tons atingir um sensor de imagem digital, a tens\u00e3o de sa\u00edda ser\u00e1 duas vezes maior.\n\nhttps:\/\/www.sciencedirect.com\/topics\/engineering\/gamma-correction#:~:text=1%20Gamma%20correction,in%20the%20industry%20standard%20BT.\n\n### Logarithimic transformation (transforma\u00e7\u00e3o logar\u00edtmica) simplesmente pegamos o logaritmo de cada valor de pixel.  Existe uma opera\u00e7\u00e3o interessante que podemos realizar usando matem\u00e1tica simples e uma transforma\u00e7\u00e3o logar\u00edtmica: segmenta\u00e7\u00e3o. Isso basicamente permite que voc\u00ea tire uma imagem de entrada, com, por exemplo, x valores poss\u00edveis de pixel diferentes e produza uma imagem de sa\u00edda com y valores poss\u00edveis de pixel. Embora a segmenta\u00e7\u00e3o seja um t\u00f3pico por si s\u00f3, este caso especial merece uma se\u00e7\u00e3o para si, se por outro motivo que n\u00e3o seja sua simplicidade.\n\nhttps:\/\/www.giassa.net\/?page_id=477","82d803b1":"### An\u00e1lise da distribui\u00e7\u00e3o entre as classes","cd43c714":"### Global Equalize","e541888f":"### Carregando o dataset de treino","05de7f41":"### Criando uma amostra para testar o processamento","61628dd1":"### An\u00e1lise das imagens","f8d52a34":"### Global Equalize \u00e9 um algoritmo de aprimoramento respons\u00e1vel por equalizar os valores de pixel, para que a intensidade da imagem se torne mais uniforme e seja distribu\u00eddo igualmente. Isso \u00e9 baseado nos valores globais dos pixels.\n\n### Linear Equalization Este \u00e9 um algoritmo de aprimoramento respons\u00e1vel por equalizar os valores de pixel, para que a intensidade da imagem se torne mais uniforme e seja distribu\u00eddo igualmente.\n\nhttp:\/\/www.ijceronline.com\/papers\/Vol2_issue6\/AO02602380252.pdf","b9e2ccab":"### Logarithmic Correction","91e9995b":"### Histogram Equalization","c106e78c":"### Otsu's thresholding","2b102d1e":"### Carregando as bibliotecas","660a6674":"### Contrast stretching","960d41dc":"## Implantando cada um dos preprocessamentos","7ef8212f":"## Preprocessamentos para ajustes do contraste","12a12055":"### Adaptative Equalization","6a67afc9":"### O global thresholding consiste em definir um valor de intensidade (limiar) tal que todos os pixels com valor de intensidade abaixo do threshold perten\u00e7am a uma fase, o restante permane\u00e7a \u00e0 outra. O global thresholding \u00e9 t\u00e3o bom quanto o grau de separa\u00e7\u00e3o de intensidade entre os dois picos na imagem.\n\nhttp:\/\/www.ams.sunysb.edu\/~lindquis\/3dma\/man_3dma\/manual\/node19.html#:~:text=Global%20thresholding%20consists%20of%20setting,two%20peaks%20in%20the%20image.\n\n### Na vis\u00e3o computacional e no processamento de imagens, o m\u00e9todo de Otsu, nomeado ap\u00f3s Nobuyuki Otsu, \u00e9 usado para executar o limiar autom\u00e1tico de imagem. Na forma mais simples, o algoritmo retorna um \u00fanico limite de intensidade que separa os pixels em duas classes, primeiro e segundo plano.\n\nhttps:\/\/g.co\/kgs\/vrS9e9","ef7d8da9":"### Otsu's thresholding after Gaussian filtering","7916172d":"### Global Thresholding"}}