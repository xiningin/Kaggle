{"cell_type":{"63e3b1d1":"code","66d13c20":"code","5e41a2a3":"code","08188704":"code","8f3c9ae7":"code","9348c248":"code","2f6ca6ed":"code","0e27c7f2":"code","ca16340c":"code","71d14171":"code","25521351":"code","5db0104a":"code","58a9e75d":"code","75a128e2":"code","89f79753":"code","dc295cf1":"code","542a3e9e":"code","41d552f2":"code","6b9145b8":"code","c4ae4099":"code","75bcacbf":"code","f4c8cc7e":"code","da8d4d44":"code","67465441":"code","19b69d3f":"code","6c1b2034":"code","693b740f":"code","3cbf9d0f":"code","40cb596a":"code","b8304376":"code","a22b41c6":"code","5a3c93c1":"code","1bdc9320":"code","d01458f1":"code","d75432ea":"code","596bfea4":"code","c1e77b58":"code","4a0bd944":"code","2823cdad":"code","8d39bbba":"code","b44a8083":"code","975b4a2b":"code","b7b535c0":"code","8dad0539":"code","e19d9426":"code","4081ecc3":"code","7a07eb5b":"code","97434d86":"code","83bbb686":"code","d8ae5e6a":"code","00b592fc":"code","f598521d":"code","5c512da9":"code","eb72660c":"code","2afc9b51":"code","88ffdec7":"code","69f1fc9f":"code","43bacb2c":"code","8eae7fae":"code","d50b1b7d":"code","7cc99c18":"code","48d33fbb":"code","72f885d3":"code","82a92a44":"code","6700ab20":"code","fa48e5fb":"code","62c837a8":"code","0ef5878a":"code","d5522d68":"code","782a8aac":"code","75c588e5":"code","598dfa25":"code","6d2c8578":"code","279f63a3":"code","53a54de0":"code","33bbba9d":"code","47d7bf26":"code","7b051859":"code","7de0abfd":"code","0ce00469":"code","159930f4":"code","a9d5b2d3":"code","82616059":"code","efc8841f":"code","e4a2b7ce":"code","535dc8c0":"code","4ed9999d":"code","0992fae4":"code","1208f2ea":"markdown","5ed20be5":"markdown","4f7c0f25":"markdown","34a6c345":"markdown","f0d3c6fd":"markdown","97904b5f":"markdown","ea1f7436":"markdown","ca4f2abe":"markdown","8ba3e94c":"markdown","473b5bc8":"markdown","3d8e89ca":"markdown","c178a87c":"markdown","19ffeeb6":"markdown","bc67272a":"markdown","df694752":"markdown","b750a6ad":"markdown","5cd5dd3f":"markdown","a4d10140":"markdown","e971e5f6":"markdown","525b2bc1":"markdown","1a0846d3":"markdown","5176b532":"markdown","66273350":"markdown"},"source":{"63e3b1d1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt, seaborn as sns","66d13c20":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e41a2a3":"advertising = pd.read_csv(\"\/kaggle\/input\/Advertising.csv\")","08188704":"type(advertising)","8f3c9ae7":"advertising.head()","9348c248":"advertising.info()","2f6ca6ed":"advertising.describe()","0e27c7f2":"advertising.TV.plot.hist()\nplt.show()","ca16340c":"advertising.Newspaper.plot.box()\nplt.show()","71d14171":"sns.pairplot(advertising, markers=\"+\", diag_kind=\"kde\")\nplt.show()","25521351":"sns.pairplot(advertising, x_vars=['TV', 'Newspaper', 'Radio'], y_vars='Sales', markers=\"+\", size=4)\nplt.show()","5db0104a":"corrs = advertising.corr()\ncorrs","58a9e75d":"sns.heatmap(corrs, annot=True, cmap=\"Greens\")\nplt.show()","75a128e2":"X = advertising[['TV']]\ny = advertising['Sales']","89f79753":"X.head()","dc295cf1":"y.head()","542a3e9e":"from sklearn.model_selection import train_test_split","41d552f2":"?train_test_split","6b9145b8":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 100)","c4ae4099":"X_train.shape, X_test.shape","75bcacbf":"from sklearn.linear_model import LinearRegression","f4c8cc7e":"#Instantiating the linear regression model\nmod = LinearRegression()","da8d4d44":"mod.fit(X_train, y_train)","67465441":"mod.intercept_, mod.coef_","19b69d3f":"from sklearn.metrics import r2_score","6c1b2034":"y_train_pred = mod.predict(X_train)","693b740f":"r2_score(y_train, y_train_pred)","3cbf9d0f":"df_train, df_test = train_test_split(advertising, train_size = 0.7, random_state = 100)","40cb596a":"df_train.shape, df_test.shape","b8304376":"df_train.head()","a22b41c6":"y_train = df_train[['Sales']]\nX_train = df_train[['TV', 'Radio']]\ny_test = df_test[['Sales']]\nX_test = df_test[['TV', 'Radio']]","5a3c93c1":"#Instantiating the linear regression model\nmod = LinearRegression()\nmod.fit(X_train, y_train)","1bdc9320":"mod.intercept_, mod.coef_","d01458f1":"y_train_pred = mod.predict(X_train)\nr2_score(y_train, y_train_pred)","d75432ea":"y_train = df_train[['Sales']]\nX_train = df_train[['TV', 'Radio',\"Newspaper\"]]\ny_test = df_test[['Sales']]\nX_test = df_test[['TV', 'Radio',\"Newspaper\"]]","596bfea4":"#Instantiating the linear regression model\nmod = LinearRegression()\nmod.fit(X_train, y_train)","c1e77b58":"y_train_pred = mod.predict(X_train)\nr2_score(y_train, y_train_pred)","4a0bd944":"mod.coef_","2823cdad":"X_train.describe()","8d39bbba":"y_train = df_train[['Sales']]\nX_train = df_train[['TV', 'Radio', 'Newspaper']]","b44a8083":"sns.heatmap(X_train.corr(),  cmap = \"Reds\", annot =True)","975b4a2b":"X_train.describe()","b7b535c0":"X_train.describe()","8dad0539":"from sklearn.preprocessing import MinMaxScaler","e19d9426":"scaler = MinMaxScaler()","4081ecc3":"?scaler","7a07eb5b":"num_vars = ['TV', 'Radio']","97434d86":"X_train[num_vars] = scaler.fit_transform(X_train[num_vars])","83bbb686":"scaler.data_max_","d8ae5e6a":"X_train.describe()","00b592fc":"from sklearn.linear_model import LinearRegression","f598521d":"lr = LinearRegression()","5c512da9":"lr.fit(X_train[[\"TV\",\"Radio\"]], y_train)","eb72660c":"X_train.columns.values","2afc9b51":"lr.coef_","88ffdec7":"mod.coef_","69f1fc9f":"lr.intercept_","43bacb2c":"y_train_pred = lr.predict(X_train[['TV', 'Radio']])\nr2_score(y_train, y_train_pred)","8eae7fae":"y_train_pred = mod.predict(X_train)\nr2_score(y_train, y_train_pred)","d50b1b7d":"from statsmodels.stats.outliers_influence import variance_inflation_factor","7cc99c18":"X_train.head()","48d33fbb":"variance_inflation_factor(X_train.values, 2)","72f885d3":"[variance_inflation_factor(X_train.values, ind) for ind in range(3)]","82a92a44":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6700ab20":"import statsmodels.api as sm","fa48e5fb":"X_train.head()","62c837a8":"X_train_sm = sm.add_constant(X_train)\nX_train_sm.head()","0ef5878a":"lr = sm.OLS(y_train, X_train_sm).fit()","d5522d68":"lr.summary()","782a8aac":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","75c588e5":"X_train_sm = sm.add_constant(X_train[[\"TV\",\"Radio\"]])","598dfa25":"lr = sm.OLS(y_train, X_train_sm).fit()","6d2c8578":"lr.summary()","279f63a3":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[[\"TV\",\"Radio\"]].columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train[[\"TV\",\"Radio\"]].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","53a54de0":"from sklearn.feature_selection import RFE","33bbba9d":"lr = LinearRegression()","47d7bf26":"rfe = RFE(lr, 2)","7b051859":"num_vars = [\"TV\",\"Radio\",\"Newspaper\"]","7de0abfd":"X_train[num_vars] = scaler.fit_transform(X_train[num_vars])","0ce00469":"X_train.describe()","159930f4":"rfe.fit(X_train, y_train)","a9d5b2d3":"rfe.ranking_","82616059":"rfe.support_","efc8841f":"selected_feats=X_train.columns[rfe.support_]","e4a2b7ce":"#X_train[selected_feats] = scaler.fit_transform(X_train[selected_feats])","535dc8c0":"rfe.fit(X_train[selected_feats],y_train)","4ed9999d":"pred=rfe.predict(X_train[selected_feats])\n","0992fae4":"r2_score(y_train,pred)","1208f2ea":"Here, by using RFE(Recursive feature elimination) we got a 91% of accuracy (by using less features)","5ed20be5":"### Train-test split and some  pre-processing","4f7c0f25":"From the parameters that we get, our linear regression equation becomes:\n\n$ Sales = 6.948 + 0.054 \\times TV $","34a6c345":"#### We will use statsmodel for getting these value","f0d3c6fd":"### Calculating Variance Inflation Factor","97904b5f":"### Linear Regression using SciKit Learn","ea1f7436":"### Generic Steps in model building\n\nWe first assign the feature variable, `TV`, in this case, to the variable `X` and the response variable, `Sales`, to the variable `y`.","ca4f2abe":"#### Detecting multi-collinearity","8ba3e94c":"#### Pre-processing the features","473b5bc8":"---\n## Step 3: Performing Simple Linear Regression\n\nEquation of linear regression<br>\n$y = c + m_1x_1 + m_2x_2 + ... + m_nx_n$\n\n-  $y$ is the response\n-  $c$ is the intercept\n-  $m_1$ is the coefficient for the first feature\n-  $m_n$ is the coefficient for the nth feature<br>\n\nIn our case:\n\n$y = c + m_1 \\times TV$\n\nThe $m$ values are called the model **coefficients** or **model parameters**.\n\n---","3d8e89ca":"Add intercept manually for statsmodel to work","c178a87c":"## Building a multiple linear regression model","19ffeeb6":"### Regression model using SciKit Learn","bc67272a":"### Build a model with all 3 variables","df694752":"#### Pre-processing the features","b750a6ad":"As is visible from the pairplot and the heatmap, the variable `TV` seems to be most correlated with `Sales`. So let's go ahead and perform simple linear regression using `TV` as our feature variable.","5cd5dd3f":"#### Train-Test Split\n\nYou now need to split our variable into training and testing sets. You'll perform this by importing `train_test_split` from the `sklearn.model_selection` library. It is usually a good practice to keep 70% of the data in your train dataset and the rest 30% in your test dataset","a4d10140":"### Visualising the Data","e971e5f6":"# Simple Linear Regression\n\nIn this notebook, we'll build a linear regression model to predict `Sales` using an appropriate predictor variable.","525b2bc1":"### Correlations between variables","1a0846d3":"### Recursive Feature Elimination\n - using sklearn","5176b532":"## Step 1: Reading and Understanding the Data\n\nLet's start with the following steps:\n\n1. Importing data using the pandas library\n2. Understanding the structure of the data","66273350":"### What is a good feature selection approach?\n#### Stastically significant\n - hypothesis testing\n - Null hypothesis?  \n     -- There is no association between X and y\n     -- the beta coefficient is 0  \n\nH0: coefficient is 0  \nH1: coefficient is non-zero"}}