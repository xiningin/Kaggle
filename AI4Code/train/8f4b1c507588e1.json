{"cell_type":{"153bbdfb":"code","86506937":"code","399b9aa1":"code","2fc5b823":"code","8487fc17":"code","e70be84b":"code","fafa96d6":"code","bcdcd8e9":"code","61691203":"code","dda41445":"code","bcd25c14":"code","e20075fa":"code","5abc9816":"code","dad4a7d4":"code","9ee1c13a":"code","eff2372f":"code","cbf80158":"code","90f036f5":"code","4bdb7792":"code","b6125ddf":"code","f92d638e":"code","9db5a258":"code","9039d1cf":"code","858d1ff5":"code","f8749035":"code","9c5de7f0":"code","246efb19":"code","cbbe8912":"code","5ee6e8c9":"code","25af97bd":"markdown"},"source":{"153bbdfb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","86506937":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","399b9aa1":"data=pd.read_csv('..\/input\/train.csv')\ndata.head()","2fc5b823":"data.describe()","8487fc17":"def combined_data():\n    train=pd.read_csv('..\/input\/train.csv')\n    test=pd.read_csv('..\/input\/test.csv')\n    target=train.Survived\n    train.drop(['Survived'],axis=1,inplace=True)\n    combined=train.append(test)\n    combined.reset_index(inplace=True)\n    combined.drop(['index','PassengerId'],inplace=True,axis=1)\n    return combined","e70be84b":"combined=combined_data()\ncombined.drop(['Name','Cabin'],axis=1,inplace=True)\ncombined.head()","fafa96d6":" combined.iloc[891:].isnull().sum()","bcdcd8e9":"combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\ncombined.iloc[891:].isnull().sum()","61691203":"grouped_data=combined.iloc[:891].groupby(['Sex','Pclass'])\ngrouped_data_median=grouped_data.median()\ngrouped_data_median=grouped_data_median.reset_index()[['Sex','Pclass','Age']]\ncombined.head()","dda41445":"grouped_data_median\ncombined.isnull().sum()","bcd25c14":"def fill_age(row):\n    condition = (\n        (grouped_data_median['Sex'] == row['Sex']) & \n        (grouped_data_median['Pclass'] == row['Pclass'])\n    ) \n    return grouped_data_median[condition]['Age'].values[0]\n\ndef process_age():\n    global combined\n    # a function that fills the missing values of the Age variable\n    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n   # status('age')\n    return combined\ncombined.isnull().sum()\n","e20075fa":"combined=process_age()\ncombined['Fare'] = pd.qcut(combined['Fare'], 4,labels=[\"1\",\"2\",\"3\",\"4\"])\ncombined=pd.concat([combined,pd.get_dummies(combined['Fare'],prefix='Fare_')],axis=1)\ncombined['Age'] = pd.qcut(combined['Age'], 5,labels=[\"1\",\"2\",\"3\",\"4\",\"5\"])\ncombined=pd.concat([combined,pd.get_dummies(combined['Age'],prefix='Age_')],axis=1)\ncombined.drop(['Fare','Age'],axis=1,inplace=True)\n#combined=pd.rename(columns={'(-0.001, 7.896]':'f1','(7.896, 14.454]':'f2','(14.454, 31.275]':'f3','(31.275, 512.329]':'f4',\n                          # '(0.169, 21.0]':'a1','(21.0, 25.0]':'a2','(25.0, 30.0]':'a3','(30.0, 40.0]':'a4','(40.0, 80.0]':'a5'})\ncombined.head()","5abc9816":"def sex_process():\n    global combined\n    combined['Sex']=combined['Sex'].map({'male':1,'female':0})\n    return combined\ncombined=sex_process()\ncombined.head()\n","dad4a7d4":"def process_pclass():\n    \n    global combined\n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variable\n    combined = pd.concat([combined, pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    combined.drop('Pclass',axis=1,inplace=True)\n    \n    #status('Pclass')\n    return combined\n#combined=process_pclass()","9ee1c13a":"combined.drop('Ticket',inplace=True,axis=1)\n#combined.drop('Ticket',inplace=True,axis=1)\n#combined['SibSp'].value_counts().plot(kind='bar')\ncombined.head()","eff2372f":"def process_embarked():\n    global combined\n    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n    combined.Embarked.fillna('S', inplace=True)\n    # dummy encoding \n    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')\n    combined = pd.concat([combined, embarked_dummies], axis=1)\n    combined.drop('Embarked', axis=1, inplace=True)\n    #status('embarked')\n    return combined\ncombined = process_embarked()","cbf80158":"combined.head()\n#combined.drop(['Embarked'],inplace=True,axis=1)\ncombined.head()","90f036f5":"#combined=combined.drop('Embarked',axis=1)\n","4bdb7792":"from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom xgboost import XGBClassifier \n","b6125ddf":"def compute_score(clf,X,y,scoring='accuracy'):\n    xval=cross_val_score(clf,X,y,cv=5,scoring=scoring)\n    return np.mean(xval)","f92d638e":"def recover_train_test_targets():\n    targets=pd.read_csv('..\/input\/train.csv',usecols=['Survived'])['Survived'].values\n    targets=targets[0:693]\n    train=combined.iloc[:693]\n    test=combined.iloc[891:]\n    return train ,test, targets","9db5a258":"train,test,targets = recover_train_test_targets()\n#train.shape\n#clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n#clf = clf.fit(train, targets)","9039d1cf":"#train['Embarked']=train['Embarked'].fillna('S')","858d1ff5":"#train.head()","f8749035":"#clf=RandomForestClassifier(n_estimators=50,max_features='sqrt')\n#clf=clf.fit(train,targets)\n#param_grid = [{'min_child_weight': np.arange(0.1, 10.1, 0.1)}]\n#clfd=GridSearchCV(XGBClassifier(), param_grid, cv=10, scoring= 'f1',iid=True)\n    # model.fit(xtr, ytr)\nclfd=XGBClassifier()\nclfd.fit(train,targets)","9c5de7f0":"features = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = clfd.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)","246efb19":"features.plot(kind='barh', figsize=(25, 25))","cbbe8912":"output = clfd.predict(test)\ndf_output = pd.DataFrame()\naux = pd.read_csv('..\/input\/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\n#df_output[['PassengerId','Survived']].to_csv('..\/input\/gender_submission.csv', index=False)\nsubmission = pd.DataFrame({\n        \"PassengerId\": df_output[\"PassengerId\"],\n        \"Survived\": df_output[\"Survived\"]\n    })\nsubmission.to_csv('titanic.csv', index=False)\n#df_output.to_csv('..\/input\/gender_submission.csv',index=False)\n#score = compute_score(clf=model, X=train_reduced, y=targets, scoring='accuracy')\n","5ee6e8c9":"name=pd.read_csv('titanic.csv')\nname.head(50)","25af97bd":"logreg = LogisticRegression()\nlogreg.fit(train,targets)\nlogreg_cv = LogisticRegressionCV()\nrf = RandomForestClassifier()\ngboost = GradientBoostingClassifier()\n\nmodels = [logreg, logreg_cv, rf, gboost]\n#combined.Fare.fillna(np.mean(combined['Fare']), inplace=True)\ncombined.iloc[891:].isnull().sum()"}}