{"cell_type":{"03334529":"code","0b875080":"code","48b5f47d":"code","e0f2128d":"code","ffb56aac":"code","6c457575":"code","06cf9d0c":"code","040b8505":"code","d1970eb7":"code","8d290a85":"code","32ca0757":"code","c8cd061b":"code","930d51dd":"code","b3c32758":"code","11cb6389":"code","0f3a010c":"code","2d639588":"code","1496e9cc":"code","9baaaaa5":"code","539f4f41":"code","d3ccdfa7":"code","caba9683":"code","ae26f086":"code","7b36e664":"code","ab13d3c3":"code","7e01483c":"markdown","5fa11a28":"markdown","e1b3d9bc":"markdown","2ce4d3a5":"markdown","ccc3ee56":"markdown","aa669c7c":"markdown","192e6869":"markdown","ee2fae52":"markdown","c197683b":"markdown","90006c04":"markdown","d0242e8c":"markdown","8e3cbddf":"markdown","c2727349":"markdown","0eb4a02e":"markdown","2bd69f1c":"markdown","165e6d08":"markdown","67ad6030":"markdown","d3198b10":"markdown","fcd0ed97":"markdown","a3456e1a":"markdown","ab197c30":"markdown","07982af4":"markdown","6c420143":"markdown","6cea2d62":"markdown"},"source":{"03334529":"# Making necessary imports\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom math import sin, cos, pi\nimport cv2\nfrom tqdm.notebook import tqdm\n\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam","0b875080":"horizontal_flip = False\nrotation_augmentation = True\nbrightness_augmentation = True\nshift_augmentation = True\nrandom_noise_augmentation = True\n\ninclude_unclean_data = True    # Whether to include samples with missing keypoint values. Note that the missing values would however be filled using Pandas' 'ffill' later.\nsample_image_index = 20    # Index of sample train image used for visualizing various augmentations\n\nrotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\npixel_shifts = [12]    # Horizontal & vertical shift amount in pixels (includes shift from all 4 corners)\n\nNUM_EPOCHS = 80\nBATCH_SIZE = 64","48b5f47d":"print(\"Contents of input\/facial-keypoints-detection directory: \")\n!ls ..\/input\/facial-keypoints-detection\/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ..\/input\/facial-keypoints-detection\/test.zip\n!unzip -u ..\/input\/facial-keypoints-detection\/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","e0f2128d":"%%time\n\ntrain_file = 'training.csv'\ntest_file = 'test.csv'\nidlookup_file = '..\/input\/facial-keypoints-detection\/IdLookupTable.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\nidlookup_data = pd.read_csv(idlookup_file)","ffb56aac":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","6c457575":"train_data.head().T","06cf9d0c":"test_data.head()","040b8505":"idlookup_data.head().T","d1970eb7":"print(\"Length of train data: {}\".format(len(train_data)))\nprint(\"Number of Images with missing pixel values: {}\".format(len(train_data) - int(train_data.Image.apply(lambda x: len(x.split())).value_counts().values)))","8d290a85":"train_data.isnull().sum()","32ca0757":"%%time\n\nclean_train_data = train_data.dropna()\nprint(\"clean_train_data shape: {}\".format(np.shape(clean_train_data)))\n\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.fillna.html\nunclean_train_data = train_data.fillna(method = 'ffill')\nprint(\"unclean_train_data shape: {}\\n\".format(np.shape(unclean_train_data)))","c8cd061b":"%%time\n\ndef load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)\/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images: {}\".format(np.shape(clean_train_images)))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints: {}\".format(np.shape(clean_train_keypoints)))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images: {}\".format(np.shape(test_images)))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, \"Sample image & keypoints\")\n\nif include_unclean_data:\n    unclean_train_images = load_images(unclean_train_data)\n    print(\"Shape of unclean_train_images: {}\".format(np.shape(unclean_train_images)))\n    unclean_train_keypoints = load_keypoints(unclean_train_data)\n    print(\"Shape of unclean_train_keypoints: {}\\n\".format(np.shape(unclean_train_keypoints)))\n    train_images = np.concatenate((train_images, unclean_train_images))\n    train_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","930d51dd":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nif horizontal_flip:\n    flipped_train_images, flipped_train_keypoints = left_right_flip(clean_train_images, clean_train_keypoints)\n    print(\"Shape of flipped_train_images: {}\".format(np.shape(flipped_train_images)))\n    print(\"Shape of flipped_train_keypoints: {}\".format(np.shape(flipped_train_keypoints)))\n    train_images = np.concatenate((train_images, flipped_train_images))\n    train_keypoints = np.concatenate((train_keypoints, flipped_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(flipped_train_images[sample_image_index], flipped_train_keypoints[sample_image_index], axis, \"Horizontally Flipped\") ","b3c32758":"def rotate_augmentation(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi\/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https:\/\/in.mathworks.com\/matlabcentral\/answers\/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nif rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(clean_train_images, clean_train_keypoints)\n    print(\"\\nShape of rotated_train_images: {}\".format(np.shape(rotated_train_images)))\n    print(\"Shape of rotated_train_keypoints: {}\\n\".format(np.shape(rotated_train_keypoints)))\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[sample_image_index], rotated_train_keypoints[sample_image_index], axis, \"Rotation Augmentation\")","11cb6389":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif brightness_augmentation:\n    altered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(clean_train_images, clean_train_keypoints)\n    print(f\"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}\")\n    print(f\"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}\")\n    train_images = np.concatenate((train_images, altered_brightness_train_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[sample_image_index], altered_brightness_train_keypoints[sample_image_index], axis, \"Increased Brightness\") \n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[len(altered_brightness_train_images)\/\/2+sample_image_index], altered_brightness_train_keypoints[len(altered_brightness_train_images)\/\/2+sample_image_index], axis, \"Decreased Brightness\") ","0f3a010c":"def shift_images(images, keypoints):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    # Augmenting over several pixel shift values\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(clean_train_images, clean_train_keypoints)\n    print(f\"Shape of shifted_train_images: {np.shape(shifted_train_images)}\")\n    print(f\"Shape of shifted_train_keypoints: {np.shape(shifted_train_keypoints)}\")\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[sample_image_index], shifted_train_keypoints[sample_image_index], axis, \"Shift Augmentation\")","2d639588":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif random_noise_augmentation:\n    noisy_train_images = add_noise(clean_train_images)\n    print(f\"Shape of noisy_train_images: {np.shape(noisy_train_images)}\")\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, clean_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, \"Random Noise Augmentation\")","1496e9cc":"print(\"Shape of final train_images: {}\".format(np.shape(train_images)))\nprint(\"Shape of final train_keypoints: {}\".format(np.shape(train_keypoints)))\n\nprint(\"\\n Clean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, \"\")\nplt.show()\n\nif include_unclean_data:\n    print(\"Unclean Train Data: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif horizontal_flip:\n    print(\"Horizontal Flip Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(flipped_train_images[i], flipped_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif rotation_augmentation:\n    print(\"Rotation Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(rotated_train_images[i], rotated_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif brightness_augmentation:\n    print(\"Brightness Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(altered_brightness_train_images[i], altered_brightness_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif shift_augmentation:\n    print(\"Shift Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(shifted_train_images[i], shifted_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif random_noise_augmentation:\n    print(\"Random Noise Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(noisy_train_images[i], clean_train_keypoints[i], axis, \"\")\n    plt.show()","9baaaaa5":"model = Sequential()\n\n# Input dimensions: (None, 96, 96, 1)\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 96, 96, 32)\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# Input dimensions: (None, 48, 48, 32)\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 48, 48, 64)\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# Input dimensions: (None, 24, 24, 64)\nmodel.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 24, 24, 96)\nmodel.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# Input dimensions: (None, 12, 12, 96)\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 12, 12, 128)\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# Input dimensions: (None, 6, 6, 128)\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 6, 6, 256)\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# Input dimensions: (None, 3, 3, 256)\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n# Input dimensions: (None, 3, 3, 512)\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\n# Input dimensions: (None, 3, 3, 512)\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","539f4f41":"%%time\n\n# Load a pre-trained model (if present)\nif os.path.exists('..\/input\/data-augmentation-for-facial-keypoint-detection\/best_model.hdf5'):\n    model = load_model('..\/input\/data-augmentation-for-facial-keypoint-detection\/best_model.hdf5')\n\n# Define necessary callbacks\ncheckpointer = ModelCheckpoint(filepath = 'best_model.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# Train the model\nhistory = model.fit(train_images, train_keypoints, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_split=0.05, callbacks=[checkpointer])","d3ccdfa7":"# summarize history for mean_absolute_error\ntry:\n    plt.plot(history.history['mae'])\n    plt.plot(history.history['val_mae'])\n    plt.title('Mean Absolute Error vs Epoch')\n    plt.ylabel('Mean Absolute Error')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper right')\n    plt.show()\n    # summarize history for accuracy\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Accuracy vs Epoch')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Loss vs Epoch')\n    plt.ylabel('Loss')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\nexcept:\n    print(\"One of the metrics used for plotting graphs is missing! See 'model.compile()'s `metrics` argument.\")","caba9683":"%%time\n\n# Modify ModelCheckpoint callback to save model with best train mae to disk (instead of best validation mae)\ncheckpointer = ModelCheckpoint(filepath = 'best_model.hdf5', monitor='mae', verbose=1, save_best_only=True, mode='min')\nmodel.fit(train_images, train_keypoints, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=[checkpointer])","ae26f086":"%%time\n \nmodel = load_model('best_model.hdf5')\ntest_preds = model.predict(test_images)","7b36e664":"fig = plt.figure(figsize=(20,16))\nfor i in range(20):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[i], test_preds[i], axis, \"\")\nplt.show()","ab13d3c3":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","7e01483c":"## Performing Horizontal & Vertical shift","5fa11a28":"## Extracting files to working directory","e1b3d9bc":"## Performing Brightness Alteration for Data Augmentation","2ce4d3a5":"## Building a model","ccc3ee56":"## Reading inputs to a Pandas DataFrame","aa669c7c":"### Augmentation & Hyperparameter Settings\n#### Experiment with various augmentation choices","192e6869":"## Exploring Data","ee2fae52":"## Adding Random Noise for Data Augmentation","c197683b":"### Check for any images with missing pixel values","90006c04":"#### Function to plot facial keypoints with images","d0242e8c":"### Separate data into clean & unclean subsets","8e3cbddf":"## Performing Horizontal Flipping for Data Augmentation","c2727349":"### This kernel experiments with various data augmentation techniques for facial keypoint detection.","0eb4a02e":"### Fit the model on full dataset","2bd69f1c":"## Generating Submission File","165e6d08":"### If this notebook helped, please upvote it :)","67ad6030":"## Performing Rotation Augmentation","d3198b10":"## Visualize Train images & corresponding Keypoints","fcd0ed97":"#### We can observe that approx. 68% of data is missing for several keypoints","a3456e1a":"## Visualizing Test Predictions","ab197c30":"## Importing Necessary Packages","07982af4":"## Predicting on Test Set","6c420143":"### Find columns having Null values and their counts","6cea2d62":"## Training the model"}}