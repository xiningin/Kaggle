{"cell_type":{"e6d53868":"code","8e7c759a":"code","9fcced85":"code","7758c9a0":"markdown","62114a27":"markdown"},"source":{"e6d53868":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# loading dummy submission file\nsub_file = pd.read_csv(r'..\/input\/santander-value-prediction-challenge\/sample_submission.csv')\n\n# loading data including 38 best scores\ndf_sub = pd.read_csv('..\/input\/santander-value-pred\/best_blend_1.csv')\n\n# a rough correlation based visualization of 32 best scores\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sub.iloc[:,:-1].corr(), cmap='Spectral')\nplt.ylabel('file index numbers')\nplt.xlabel('file index numbers')\nplt.show()","8e7c759a":"# basic analysis and visualization  of subgroups in different color.\nplt.figure(figsize=(12, 5))\ndf_mean_corr = pd.DataFrame({'mean_corr': df_sub.iloc[:,:-1].corr().mean()})\ndf_mean_corr = df_mean_corr.sort_values('mean_corr', ascending=False)\ndf_mean_corr = df_mean_corr.reset_index()\nplt.plot(df_mean_corr.index[:3], df_mean_corr['mean_corr'].values[:3], 'o', ms=10)\nplt.plot(df_mean_corr.index[3:18], df_mean_corr['mean_corr'].values[3:18], 'o', ms=10)\nplt.plot(df_mean_corr.index[18:29], df_mean_corr['mean_corr'].values[18:29], 'o', ms=10)\nplt.plot(df_mean_corr.index[29:35], df_mean_corr['mean_corr'].values[29:35], 'o', ms=10)\nplt.plot(df_mean_corr.index[35:37], df_mean_corr['mean_corr'].values[35:37], 'o', ms=10)\nplt.plot(df_mean_corr.index[37:], df_mean_corr['mean_corr'].values[37:], 'o', ms=10)\nplt.xticks([*range(len(df_mean_corr))], df_mean_corr['index'].tolist())\nplt.title('determination of sub_groups')\nplt.ylabel('mean of sum of correlation values')\nplt.xlabel('file index numbers')\nplt.show()","9fcced85":"# a linear combination to achieve much better scores\ndf_sub['weighted_avg'] = abs(1 * (\n        -10 * (1 * df_sub['7'] + 1 * df_sub['12'] + 1 * df_sub['13']) \/ 3 +\n\n        225 * (2 * df_sub['4'] + 5 * df_sub['5'] + 5 * df_sub['6'] - 50 * df_sub['10'] + 5 * df_sub['15'] + 5 * df_sub['16'] +\n               5 * df_sub['17'] + 5 * df_sub['18'] + 5 * df_sub['19'] + 5 * df_sub['20'] + 200 * df_sub['27'] + 700 * df_sub['33'] + \n               3 * df_sub['35'] + 6 * df_sub['36'] - 300 * df_sub['37']) \/ 601 +\n\n        25 * (5 * df_sub['0'] + 5 * df_sub['2'] + 7 * df_sub['3'] + 7 * df_sub['8'] +3 * df_sub['9'] + 7 * df_sub['11'] +\n             3 * df_sub['14'] + 5 * df_sub['25'] + 400 * df_sub['28'] + 3 * df_sub['31'] + 4 * df_sub['32'] + 7 * df_sub['34']) \/ 456 +\n\n        -3 * (150 * df_sub['1'] - 1 * df_sub['21'] - 1 * df_sub['22'] - 1 * df_sub['23'] - 1 * df_sub['24']) \/ 146 +\n        -1 * (1 * df_sub['29'] + 1 * df_sub['30']) \/ 2 +\n        -1 * (1 * df_sub['26']) \/ 1\n    ) \/ 233)\n\n# create the final submission file\nsubmission = pd.DataFrame({'ID': sub_file.ID, 'target': df_sub['weighted_avg'].tolist()})\nsubmission.to_csv(r'submission_file.csv', index=False)","7758c9a0":"# Blend Boosting study on dataset of the Santander Value Prediction Challenge.\n\nHere I share with you a systematic blend boosting study on dataset of the Santander Value Prediction Challenge (https:\/\/www.kaggle.com\/c\/santander-value-prediction-challenge). I just collect some submission files (total 38) on Kaggle with scores up to 1.5 RMSLE.\n\nBasically, I start to analysis of correlations, then decide to sort them according to their sum of correlation values in between. This lets me divide 38 scores into 5 subgroups. Then I make internal linear calibration in each subgroup by considering their scores. Finally I make recalling between subgroups to achieve higher scores on the Kaggle by resubmission. Of course, if you spend much more time, you can always achieve betters scores, but I stop it here because it is already highest score on Kaggle ;-).  ","62114a27":"## It gets a 0.47264 RMSLE as public score, and looks the best score on Kaggle so far ;-)"}}