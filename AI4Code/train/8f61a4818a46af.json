{"cell_type":{"fefbf5a5":"code","b07f4170":"code","8dfa4c92":"code","744b12d0":"code","a01cc317":"code","a8a864a7":"code","829d9d2b":"code","b7e56e38":"code","7627c6ea":"code","f0ea9e1c":"code","fffa73c1":"code","b530748d":"code","93d0cbd9":"code","ca9b804a":"code","7ff26796":"code","ceb84ca9":"code","4761937d":"code","39f2331b":"code","66c560cf":"code","90b1fb7a":"code","81648dd5":"code","bdddd5c5":"code","6b1cf1a4":"code","5042f722":"code","6386ee86":"code","45459d58":"code","751b7675":"code","0ec6fdf5":"code","02a6d9fa":"code","1ddb49d3":"code","f13f7ed3":"code","569c89ad":"code","4126fb43":"markdown","fc99d7a1":"markdown","f32b6f4b":"markdown"},"source":{"fefbf5a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b07f4170":"!pip install --upgrade pip\n!pip install git+https:\/\/github.com\/tensorflow\/docs","8dfa4c92":"import glob\nimport imageio\nimport time \nimport keras\nimport PIL\nimport tensorflow as tf\nfrom IPython import display\nimport matplotlib.pyplot as plt\n\nfrom keras import Sequential\nfrom keras.optimizers import Adam\nimport tensorflow_docs.vis.embed as embed\nfrom keras.losses import BinaryCrossentropy\n","744b12d0":"(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n","a01cc317":"train_images = train_images.reshape(-1, 28, 28,1)\ntrain_images = (train_images - 127.5) \/ 127.5\nimages = train_images","a8a864a7":"train_images.shape ,train_labels.shape","829d9d2b":"learning_rate = 0.0001\nbatch_size = 256\nepochs = 500\nbreak_num = 5\nimage_dim = train_images[0].shape\nrandom_noise = 100","b7e56e38":"image_dim","7627c6ea":"from keras.layers import Conv2D, LeakyReLU, Dropout, Flatten, Dense, BatchNormalization, Reshape, Conv2DTranspose, Conv1D","f0ea9e1c":"def discriminator():\n    model = Sequential(name = \"discriminator\")\n    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=image_dim))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(1))\n    \n    model.summary()\n\n    return model","fffa73c1":"def generator():\n    model = Sequential(name=\"generator\")\n    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))    # adding noise\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Reshape((7, 7, 256)))\n\n    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    model.summary()\n    return model","b530748d":"gen = generator()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = gen(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0])","93d0cbd9":"disc = discriminator()\nprint(disc(generated_image))","ca9b804a":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output, fake_output):\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    return fake_loss + real_loss\ndef generator_loss(fake_output):\n    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    return loss","7ff26796":"discriminator_optimizer = Adam(learning_rate)\n\ngenerator_optimizer = Adam(learning_rate)\n","ceb84ca9":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=gen,\n                                 discriminator=disc)","4761937d":"def train_step(input_image):\n    noise = tf.random.normal([batch_size, random_noise])\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = gen(noise)\n\n        real_output = disc(input_image)\n        fake_output = disc(generated_images)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    g_gen = gen_tape.gradient(gen_loss, gen.trainable_variables)\n    g_disc = disc_tape.gradient(disc_loss, disc.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(g_gen, gen.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(g_disc, disc.trainable_variables))\n    return gen_loss, disc_loss","39f2331b":"noise_gan = tf.random.normal([batch_size, random_noise])\ndef save_output(model, epoch):\n    prediction = model(noise_gan)\n\n    fig = plt.figure(figsize=(10,10))\n    for i in range(16):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(prediction[i, :, :, 0] * 127.5 + 127.5)\n        plt.axis('off')\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))","66c560cf":"train_images = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(batch_size)\n\nfor epoch in range(epochs):\n    start = time.time()\n\n    for x_batch in train_images:\n        loss = train_step(x_batch)\n        \n    if (epoch + 1) % break_num == 0:\n        checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    if epoch %break_num ==0 or epoch==epochs-1 and epoch!=0:\n        print ('Time for epoch {} is {} sec and Generator Loss :{} and Discriminator loss :{}'.format(epoch + 1, time.time()-start, loss[0], loss[1]))\n        save_output(gen, epoch+1)\n","90b1fb7a":"def display_image(epoch_no, file):\n    return PIL.Image.open(file.format(epoch_no))","81648dd5":"display_image(epoch+1, 'image_at_epoch_{:04d}.png')","bdddd5c5":"def create_gif(file, collection):\n\n    with imageio.get_writer(file, mode='I') as writer:\n        filenames = glob.glob(collection+'*.png')\n        filenames = sorted(filenames)\n        for filename in filenames:\n            image = imageio.imread(filename)\n            writer.append_data(image)\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    return file","6b1cf1a4":"file  = create_gif(\"result.gif\", \"image\")\nembed.embed_file(file)","5042f722":"from keras.utils import to_categorical\n\ntrain_images = images\nlabels = len(np.unique(train_labels))\ntrain_labels = to_categorical(train_labels, labels)\n","6386ee86":"learning_rate = 0.0001\nbatch_size = 64\n\nrandom_noise = 100","45459d58":"def discriminator():\n    model = Sequential(name = \"discriminator\")\n    model.add(Dense(7*7*256, use_bias=False, input_shape=(794,)))\n    model.add(Reshape((7, 7, 256)))\n    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(1))\n    \n    return model\n\ndef generator():\n    model = Sequential(name=\"generator\")\n    model.add(Dense(7*7*256, use_bias=False, input_shape=(110,)))    # adding noise\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Reshape((7, 7, 256)))\n\n    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    model.add(Reshape((784,)))\n    \n    return model\n","751b7675":"print(generator().summary())\nprint(discriminator().summary())","0ec6fdf5":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output, fake_output):\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    return fake_loss + real_loss\ndef generator_loss(fake_output):\n    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    return loss\n\n\ndiscriminator_optimizer = Adam(learning_rate)\n\ngenerator_optimizer = Adam(learning_rate)","02a6d9fa":"gen = generator()\ndisc = discriminator()\n\ndef train_step(input_image, labels):\n    noise = tf.random.normal([batch_size, random_noise])\n    noise = tf.concat(axis=1, values=[noise, np.stack(labels)])\n    \n    input_image = tf.concat(axis=1, values = [tf.cast(input_image, tf.float32), labels])\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = gen(noise)\n        generated_images = tf.concat(axis=1, values=[generated_images, labels])\n        real_output = disc(input_image)\n        fake_output = disc(generated_images)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    g_gen = gen_tape.gradient(gen_loss, gen.trainable_variables)\n    g_disc = disc_tape.gradient(disc_loss, disc.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(g_gen, gen.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(g_disc, disc.trainable_variables))\n    return gen_loss,disc_loss\n    \nnoise = tf.random.normal([batch_size, random_noise])\nY_label = np.zeros(shape = [batch_size, 10])\nY_label[:, 4] = 1    # For Coat\nnoise_gan = tf.concat(axis=1, values=[noise, Y_label])\n\ndef save_output(model, epoch):\n    \n    prediction = model(noise_gan)\n    prediction = prediction.numpy().reshape(prediction.shape[0],28, 28, 1)\n    \n    fig = plt.figure(figsize=(10,10))\n    for i in range(16):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(prediction[i, :, :, 0] * 127.5 + 127.5)\n        plt.axis('off')\n    plt.savefig('conditional_image_at_epoch_{:04d}.png'.format(epoch))\n    \ntrain_labels = tf.data.Dataset.from_tensor_slices(train_labels[:59968]).shuffle(128).batch(batch_size)\ntrain_images = tf.data.Dataset.from_tensor_slices(train_images.reshape(train_images.shape[0], 784)[:59968]).shuffle(128).batch(batch_size)\n\nfor epoch in range(epochs):\n    start = time.time()\n\n    for x_batch, labels in zip(train_images, train_labels):\n        loss = train_step(x_batch, labels)\n        \n    if (epoch + 1) % break_num == 0:\n        checkpoint.save(file_prefix = checkpoint_prefix)\n        \n    if epoch %break_num ==0 or epoch==epochs-1 and epoch!=0:\n        print ('Time for epoch {} is {} sec and Generator Loss :{} and Discriminator loss :{}'.format(epoch + 1, time.time()-start, loss[0], loss[1]))\n        save_output(gen, epoch+1)","1ddb49d3":"display_image(epoch+1, 'conditional_image_at_epoch_{:04d}.png')","f13f7ed3":"display.clear_output(wait=True)\n\nnoise = tf.random.normal([batch_size, random_noise])\nfeature_map = { \"t-shirt\":0,\n                 \"trouser\":1,\n                 \"pullover\":2,\n                 \"dress\":3,\n                 \"coat\":4,\n                 \"sandal\":5,\n                 \"sirt\":6,\n                 \"sneaker\":7,\n                 \"bag\":8,\n                 \"ankle boot\": 9\n                }\ninp = \"coat\"\n\nY_label = np.zeros(shape = [batch_size, 10])\nY_label[:, feature_map[inp]] = 1\nnoise = tf.concat(axis=1, values=[noise, Y_label])\n\nprediction = gen(noise)\nprediction = prediction.numpy().reshape(prediction.shape[0],28, 28, 1)\nfig = plt.figure(figsize=(10,10))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n    plt.imshow(prediction[i, :, :, 0] * 127.5 + 127.5)\n    plt.axis('off')\nplt.show()","569c89ad":"file = create_gif(\"result.gif\", \"conditional_image\")\nembed.embed_file(file)","4126fb43":"# Conditional GAN","fc99d7a1":"# Discriminator model","f32b6f4b":"# Loss function"}}