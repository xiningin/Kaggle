{"cell_type":{"aba5f015":"code","c9a00dbb":"code","31150173":"code","e3ac6920":"code","73f21f72":"code","991ff5f1":"code","4927a5df":"code","482cce9b":"code","d158a086":"code","02ebaf54":"code","f5e01f5e":"markdown","25fe742d":"markdown","f175fd79":"markdown","28e3cc8b":"markdown"},"source":{"aba5f015":"import tensorflow as tf\nimport tensorflow_probability as tfp\nimport numpy as np\nimport matplotlib.pyplot as plt\nds = tfp.distributions","c9a00dbb":"TRAIN_BUF = 60000\nTEST_BUF  = 10000\nBATCH_SIZE= 512\nDIMS = (28,28,1)\nN_TRAIN_BATCHES =int(TRAIN_BUF\/BATCH_SIZE)\nN_TEST_BATCHES  =int(TEST_BUF\/BATCH_SIZE)","31150173":"# load dataset\n(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n\n# split dataset\ntrain_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\n    \"float32\"\n) \/ 255.0\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\") \/ 255.0\n\n# batch datasets\ntrain_dataset = (\n    tf.data.Dataset.from_tensor_slices(train_images)\n    .shuffle(TRAIN_BUF)\n    .batch(BATCH_SIZE)\n)\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices(test_images)\n    .shuffle(TEST_BUF)\n    .batch(BATCH_SIZE)\n)","e3ac6920":"class VAE(tf.keras.Model):\n    def __init__(self, **kwargs):\n        super(VAE, self).__init__()\n        self.__dict__.update(kwargs)\n\n        self.enc = tf.keras.Sequential(self.enc)\n        self.dec = tf.keras.Sequential(self.dec)\n\n    def encode(self, x):\n        mu, sigma = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n        return ds.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n\n    def reparameterize(self, mean, logvar):\n        eps = tf.random.normal(shape=mean.shape)\n        return eps * tf.exp(logvar * 0.5) + mean\n\n    def reconstruct(self, x):\n        mu, _ = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n        return self.decode(mu)\n\n    def decode(self, z):\n        return self.dec(z)\n    def compute_loss(self, x):\n\n        q_z = self.encode(x)\n        z = q_z.sample()\n        x_recon = self.decode(z)\n        p_z = ds.MultivariateNormalDiag(\n          loc=[0.] * z.shape[-1], scale_diag=[1.] * z.shape[-1]\n          )\n        kl_div = ds.kl_divergence(q_z, p_z)\n        latent_loss = tf.reduce_mean(tf.maximum(kl_div, 0))\n        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.math.square(x - x_recon), axis=0))\n\n        return recon_loss, latent_loss\n\n    def compute_gradients(self, x):\n        with tf.GradientTape() as tape:\n            loss = self.compute_loss(x)\n        return tape.gradient(loss, self.trainable_variables)\n\n    @tf.function\n    def train(self, train_x):\n        gradients = self.compute_gradients(train_x)\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))    ","73f21f72":"N_Z = 2\nencoder = [\n    tf.keras.layers.InputLayer(input_shape=DIMS),\n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n    ),\n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n    ),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=N_Z*2),\n]\n\ndecoder = [\n    tf.keras.layers.Dense(units=7 * 7 * 64, activation=\"relu\"),\n    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n    tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n    ),\n    tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n    ),\n    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"\n    ),\n]","991ff5f1":"optimizer = tf.keras.optimizers.Adam(1e-3)\n# train the model\nmodel = VAE(enc = encoder, dec = decoder, optimizer = optimizer)","4927a5df":"example_data = next(iter(test_dataset))\n\n\ndef plot_reconstruction(model, example_data, nex=8, zm=2):\n\n    example_data_reconstructed = model.reconstruct(example_data)\n    samples = model.decode(tf.random.normal(shape=(BATCH_SIZE, N_Z)))\n    fig, axs = plt.subplots(ncols=nex, nrows=3, figsize=(zm * nex, zm * 3))\n    for axi, (dat, lab) in enumerate(\n        zip(\n            [example_data, example_data_reconstructed, samples],\n            [\"data\", \"data recon\", \"samples\"],\n        )\n    ):\n        for ex in range(nex):\n            axs[axi, ex].matshow(\n                dat.numpy()[ex].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n            )\n            axs[axi, ex].axes.get_xaxis().set_ticks([])\n            axs[axi, ex].axes.get_yaxis().set_ticks([])\n        axs[axi, 0].set_ylabel(lab)\n\n    plt.show()","482cce9b":"import pandas as pd\n# a pandas dataframe to save the loss information to\nlosses = pd.DataFrame(columns = ['recon_loss', 'latent_loss'])","d158a086":"from tqdm.autonotebook import tqdm\nfrom IPython import display","02ebaf54":"n_epochs = 50\nfor epoch in range(n_epochs):\n    # train\n    for batch, train_x in tqdm(zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES):\n        model.train(train_x)\n    \n    # test on holdout\n    loss = []\n    for batch, test_x in tqdm(zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES):\n        loss.append(model.compute_loss(train_x))\n    losses.loc[len(losses)] = np.mean(loss, axis=0)\n    \n    # plot results\n    display.clear_output()\n    print(\"Epoch: {} | recon_loss: {} | latent_loss: {}\".format(epoch, losses.recon_loss.values[-1], losses.latent_loss.values[-1]))\n    plot_reconstruction(model, example_data)","f5e01f5e":"## Build VAE Model","25fe742d":"# Variational AutoEncoder (VAE)\n![](https:\/\/github.com\/timsainb\/tensorflow2-generative-models\/blob\/master\/imgs\/vae.png?raw=1)","f175fd79":"## Load Dataset","28e3cc8b":"## Train Model"}}