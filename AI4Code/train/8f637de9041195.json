{"cell_type":{"ce8cf0c3":"code","f71911b7":"code","75b535af":"code","10655007":"code","6be9c827":"code","c9e21c7b":"code","2f2359b2":"code","33f0334f":"code","32820bc7":"code","4ae336f0":"code","7b7faf9a":"code","e4676b92":"code","10b0362d":"code","22121fdd":"code","f7778b9b":"code","a9659b1e":"code","ee9bd10d":"code","6d96dec1":"code","7c94abb4":"code","ba30a878":"code","b3efc7c9":"code","45f901a2":"code","8de1e133":"code","ef77f932":"markdown"},"source":{"ce8cf0c3":"import numpy as np\nimport pandas as pd\n\n# Modelling\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\n# Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import CategoricalNB\n\n# KNeighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Perceptron\nfrom sklearn.linear_model import Perceptron\n\n# Support Vector Machines\nfrom sklearn.svm import SVC\n\n# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\n\n\n\n# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n","f71911b7":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","75b535af":"train_data.head()","10655007":"train_data.describe()","6be9c827":"train_data.columns","c9e21c7b":"train_data.isnull().sum","2f2359b2":"missing_values = train_data.isna().any()\nprint('Columns which have missing values: \\n{0}'.format(missing_values[missing_values == True].index.tolist()))","33f0334f":"print(\"Percentage of missing values in `Age` column: {0:.2f}\".format(100.*(train_data.Age.isna().sum()\/len(train_data))))\nprint(\"Percentage of missing values in `Cabin` column: {0:.2f}\".format(100.*(train_data.Cabin.isna().sum()\/len(train_data))))\nprint(\"Percentage of missing values in `Embarked` column: {0:.2f}\".format(100.*(train_data.Embarked.isna().sum()\/len(train_data))))","32820bc7":"duplicates = train_data.duplicated().sum()\nprint(duplicates)","4ae336f0":"categorical = train_data.nunique().sort_values(ascending=True)\nprint('Categorical variables in train data: \\n{0}'.format(categorical))","7b7faf9a":"train_data.drop(['Name', 'Ticket', 'Fare', 'Embarked'], axis=1, inplace=True)\ntrain_data.drop(['Cabin'], axis=1,inplace=True)","e4676b92":"test_data.drop(['Name', 'Ticket', 'Fare', 'Embarked'], axis=1, inplace=True)","10b0362d":"test_data.drop(['Cabin'], axis=1, inplace=True)","22121fdd":"train_data.tail()","f7778b9b":"train_data.head()","a9659b1e":"train_data['Sex'].replace({'male':0, 'female':1}, inplace=True)\ntest_data['Sex'].replace({'male':0, 'female':1}, inplace=True)\n\n# Merge two data to get the average Age and fill the column\ndata = pd.concat([train_data, test_data])\naverage = data.Age.median()\nprint(average)\ntrain_data.fillna(value={'Age': average}, inplace=True)\ntest_data.fillna(value={'Age': average}, inplace=True)","ee9bd10d":"X = train_data.drop(['Survived', 'PassengerId'], axis=1)\ny = train_data['Survived']\ntest_X = test_data.drop(['PassengerId'], axis=1)\n","6d96dec1":"print(X, X.shape)","7c94abb4":"print(y, y.shape)","ba30a878":"print(X.columns.tolist())","b3efc7c9":"# To store models created\nbest_models = {}\n\n# Split data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\ndef print_best_parameters(hyperparameters, best_parameters):\n    value = \"Best parameters: \"\n    for key in hyperparameters:\n        value += str(key) + \": \" + str(best_parameters[key]) + \", \"\n    if hyperparameters:\n        print(value[:-2])\n\ndef get_best_model(estimator, hyperparameters, fit_params={}):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    grid_search = GridSearchCV(estimator=estimator, param_grid=hyperparameters, n_jobs=-1, cv=cv, scoring=\"accuracy\")\n    best_model = grid_search.fit(train_X, train_y, **fit_params)\n    best_parameters = best_model.best_estimator_.get_params()\n    print_best_parameters(hyperparameters, best_parameters)\n    return best_model\n\ndef evaluate_model(model, name):\n    print(\"Accuracy score:\", accuracy_score(train_y, model.predict(train_X)))\n    best_models[name] = model","45f901a2":"hyperparameters = {\n    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n    'penalty' : ['l2'],\n    'C'       : [100, 10, 1.0, 0.1, 0.01]\n}\nestimator = LogisticRegression(random_state=1)\nbest_model_logistic = get_best_model(estimator, hyperparameters)","8de1e133":"evaluate_model(best_model_logistic.best_estimator_, 'logistic')","ef77f932":"##### print"}}