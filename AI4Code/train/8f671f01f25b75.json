{"cell_type":{"01b987c3":"code","ee9153a8":"code","346c824a":"code","be31ecd3":"code","d2738ede":"code","e760779d":"code","8991d503":"code","111a82ee":"code","33ee64f4":"code","51f625cc":"code","9177ed69":"code","a40f4161":"code","2c5c86ae":"code","420c1776":"markdown","88a690d5":"markdown","e88690da":"markdown","dc9079f7":"markdown","26febac3":"markdown","25df6758":"markdown"},"source":{"01b987c3":"import numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\n%matplotlib inline\nscale_percent = 30\n# width = int(1365 * scale_percent \/ 100)\n# height = int(2048 * scale_percent \/ 100)\nwidth = 512\nheight = 512\ndim = (width, height)\ndim","ee9153a8":"AUTO = tf.data.experimental.AUTOTUNE\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nbatch_size = 16*tpu_strategy.num_replicas_in_sync","346c824a":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nGCS_DS_PATH","be31ecd3":"def ImageIDtodir(label):\n    return GCS_DS_PATH+'\/images\/' + label + '.jpg'\ntrain_df = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntrain_dir = train_df['image_id'].apply(ImageIDtodir).values\ntest_df = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\ntest_dir = test_df['image_id'].apply(ImageIDtodir).values\ny =  train_df.loc[:, 'healthy':].values\ntrain_dir, valid_dir, y_train, y_val = train_test_split(train_dir,y,test_size=0.15)","d2738ede":"def load_image(filename, label=None,image_size=(width,height)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image,image_size)   \n    if label is None:\n        return image\n    else:\n        return image, label\n    \n\ndef augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if label is None:\n        return image\n    else:\n        return image, label","e760779d":"train_dataset = (\n    tf.data.Dataset.from_tensor_slices((train_dir, y_train))\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .map(augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset.from_tensor_slices((valid_dir,y_val))\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_dir)\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .batch(batch_size)\n)","8991d503":"with tpu_strategy.scope():\n    DenseNetModel = tf.keras.applications.DenseNet121(input_shape=(width,height,3),\n                                              weights='imagenet',\n                                              include_top=False)\n    model = tf.keras.models.Sequential(\n        [DenseNetModel,\n#             tf.keras.layers.Convolution2D(1024,(5,5),strides=(2,2),activation='relu'),\n#             tf.keras.layers.Convolution2D(2048,(4,4),strides=(2,2),activation='relu'),\n#             tf.keras.layers.AveragePooling2D((5,5),2),\n#             tf.keras.layers.AveragePooling2D((4,4),2),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(50, activation='relu'),\n        tf.keras.layers.Dense(4, activation='softmax')]\n    )\n    # Compile the model\n    model.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy',tf.keras.metrics.AUC(name='auc')])","111a82ee":"model.summary()","33ee64f4":"# Learning rate schedular\ndef lr_scheduler(epoch, lr):\n    decay_rate = 0.5\n    decay_step = 5\n    if epoch % decay_step == 0 and epoch:\n        return lr * decay_rate\n    return lr\ncallbacks = [\n    tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n]","51f625cc":"history = model.fit(train_dataset,\n                    epochs=25,\n                    callbacks=callbacks,\n                    steps_per_epoch=y.shape[0] \/\/ batch_size,\n                    validation_data=valid_dataset)","9177ed69":"plt.plot(history.history['loss'])\nplt.title('Model accuracy')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","a40f4161":"predictions = model.predict(test_dataset,verbose=1)","2c5c86ae":"temp_df = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsubmission = pd.DataFrame(\n    {'image_id': temp_df['image_id'],\n     'healthy': predictions[:,0],\n     'multiple_diseases': predictions[:,1],\n     'rust': predictions[:,2],\n     'scab': predictions[:,3],\n    })\nsubmission.to_csv(\"plant_pathology.csv\",index=False)\nsubmission","420c1776":"## B. <a name=\"head2b\"><\/a>Add Final trainable Layers to pre-built model.\nAs we need to categories the images into 4 labels we need to add another layer to the model.     \nThe ouput of the DenseNet model which are essentially features extracted from the images are passed on to more layers-\n* A Global average pooling layer\n* A Dropout layer with rate 0.3\n* A Dense layer with 50 units and relu activation.\n* A Dense layer with 4 units and softmax activation.  \n   \nThe last layer is which gives out the precitions.   \n  ","88a690d5":"# <a name=\"head1\"><\/a>1.Pre-processing Images \nwe are using tensorflow tensor_from_slices to read images while training directly from the file.Images are reshaped to 512x512x3.\nI am also splitting the train images into training and validation with a validation split of 0.15.   \nThe train images are flipped randomly but no such pre-processing is done on validation or train images.","e88690da":"# Plant Pathology using TPU-DenseNetMoblile\nI have used the prebuild model in keras - Keras Application.Keras Applications are deep learning models that are made available alongside pre-trained weights. You can read more about them [here](https:\/\/keras.io\/applications\/).\n1. [Pre-processing Images](#head1)\n2. [CNN Model](#head2)\n  * [Load in pre-trained model](#head2a)\n  * [Add Final trainable layers to pre-built model](#head2b)\n  * [Learing Rate Scheduler](#head2c)\n3. [Evaluation and training curves.](#head3)","dc9079f7":"# <a name=\"head3\"><\/a>3. Evaluation and training Curves","26febac3":"# <a name=\"head2b\"><\/a> Learing Rate Scheduler\nWe have to reduce our learning mid-training as the ","25df6758":"# <a name=\"head2\"><\/a>2. CNN Model\n\n## A. <a name=\"head2a\"><\/a>Load in Pre-trained model.\nI have used the DenseNetMobile in-built model with pre-trained weights. You can read about other Keras Applications [here](https:\/\/keras.io\/applications\/#available-models).   "}}