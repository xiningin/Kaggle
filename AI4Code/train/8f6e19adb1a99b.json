{"cell_type":{"5720977d":"code","0cf69fdb":"code","5802af19":"code","684f6f74":"code","81eea8ce":"code","f3441362":"code","ec98a275":"code","697d97cb":"code","b1854312":"code","7d750d35":"code","1898e4c0":"code","fa410935":"code","85020222":"code","d3133c97":"code","2bb0b9f5":"code","cae258ef":"code","a528cce5":"code","881735aa":"code","e431154a":"code","9ed77d97":"code","ccd4f41d":"code","66a3c6c1":"code","f8cce1ef":"code","68a18cfa":"code","472d55f1":"code","93a5d58b":"code","7adc562f":"code","8f0f3d9f":"code","cba18983":"code","d16dae95":"code","f2f6677f":"markdown","5fe77f4c":"markdown","72304303":"markdown","d89400d1":"markdown","b5fff1fd":"markdown","636043e5":"markdown","7518fcd6":"markdown","c316eec9":"markdown","7347ebb8":"markdown","23083e58":"markdown","b87dead3":"markdown"},"source":{"5720977d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0cf69fdb":"# Importing Housing.csv\nhousing = pd.read_csv(\"..\/input\/mydatasets\/Housing.csv\")","5802af19":"# Looking at the first five rows\nhousing.head()","684f6f74":"# Converting Yes to 1 and No to 0\nhousing['mainroad'] = housing['mainroad'].map({'yes': 1, 'no': 0})\nhousing['guestroom'] = housing['guestroom'].map({'yes': 1, 'no': 0})\nhousing['basement'] = housing['basement'].map({'yes': 1, 'no': 0})\nhousing['hotwaterheating'] = housing['hotwaterheating'].map({'yes': 1, 'no': 0})\nhousing['airconditioning'] = housing['airconditioning'].map({'yes': 1, 'no': 0})\nhousing['prefarea'] = housing['prefarea'].map({'yes': 1, 'no': 0})","81eea8ce":"# Creating dummy variable for variable furnishingstatus and dropping the first one\nstatus = pd.get_dummies(housing['furnishingstatus'],drop_first=True)","f3441362":"#Adding the results to the master dataframe\nhousing = pd.concat([housing,status],axis=1)","ec98a275":"# Dropping the variable 'furnishingstatus'\nhousing.drop(['furnishingstatus'],axis=1,inplace=True)","697d97cb":"# Let us create the new metric and assign it to \"areaperbedroom\"\nhousing['areaperbedroom'] = housing['area']\/housing['bedrooms']","b1854312":"# Metric: bathrooms per bedroom\nhousing['bbratio'] = housing['bathrooms']\/housing['bedrooms']","7d750d35":"#defining a normalisation function \ndef normalize (x): \n    return ( (x-np.min(x))\/ (max(x) - min(x)))\n                                            \n                                              \n# applying normalize ( ) to all columns \nhousing = housing.apply(normalize)","1898e4c0":"# Putting feature variable to X\nX = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad',\n       'guestroom', 'basement', 'hotwaterheating', 'airconditioning',\n       'parking', 'prefarea', 'semi-furnished', 'unfurnished',\n       'areaperbedroom', 'bbratio']]\n\n# Putting response variable to y\ny = housing['price']","fa410935":"housing.plot.line(x='price', y='area')","85020222":"#random_state is the seed used by the random number generator, it can be any integer.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 ,test_size = 0.3, random_state=100)","d3133c97":"# UDF for calculating vif value\ndef vif_cal(input_data, dependent_col):\n    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.OLS(y,x).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)","2bb0b9f5":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","cae258ef":"# Running RFE with the output number of the variable equal to 9\nlm = LinearRegression()\nrfe = RFE(lm, 9)             # running RFE\nrfe = rfe.fit(X_train, y_train)\nprint(rfe.support_)           # Printing the boolean results\nprint(rfe.ranking_)  ","a528cce5":"col = X_train.columns[rfe.support_]","881735aa":"plt.figure(figsize = (20,10))        # Size of the figure\nsns.heatmap(housing.corr(),annot = True)","e431154a":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","9ed77d97":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","ccd4f41d":"lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model","66a3c6c1":"#Let's see the summary of our linear model\nprint(lm.summary())","f8cce1ef":"# Calculating Vif value\nvif_cal(input_data=housing.drop(['area','bedrooms','stories','basement','semi-furnished','areaperbedroom'], axis=1), dependent_col=\"price\")","68a18cfa":"# Now let's use our model to make predictions.\n\n# Creating X_test_6 dataframe by dropping variables from X_test\nX_test_rfe = X_test[col]\n\n# Adding a constant variable \nX_test_rfe = sm.add_constant(X_test_rfe)\n\n# Making predictions\ny_pred = lm.predict(X_test_rfe)","472d55f1":"# Now let's check how well our model is able to make predictions.\n\n# Importing the required libraries for plots.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","93a5d58b":"# Actual and Predicted\nimport matplotlib.pyplot as plt\nc = [i for i in range(1,165,1)] # generating index \nfig = plt.figure() \nplt.plot(c,y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\") #Plotting Actual\nplt.plot(c,y_pred, color=\"red\",  linewidth=2.5, linestyle=\"-\") #Plotting predicted\nfig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                               # X-label\nplt.ylabel('Housing Price', fontsize=16)                       # Y-label","7adc562f":"# Error terms\nc = [i for i in range(1,165,1)]\nfig = plt.figure()\nplt.plot(c,y_test-y_pred, color=\"blue\", linewidth=2.5, linestyle=\"-\")\nfig.suptitle('Error Terms', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                      # X-label\nplt.ylabel('ytest-ypred', fontsize=16)                # Y-label","8f0f3d9f":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label","cba18983":"# Plotting the error terms to understand the distribution.\nfig = plt.figure()\nsns.distplot((y_test-y_pred),bins=50)\nfig.suptitle('Error Terms', fontsize=20)                  # Plot heading \nplt.xlabel('y_test-y_pred', fontsize=18)                  # X-label\nplt.ylabel('Index', fontsize=16)                          # Y-label","d16dae95":"# Now let's check the Root Mean Square Error of our model.\nimport numpy as np\nfrom sklearn import metrics\nprint('RMSE :', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","f2f6677f":"### Splitting data into training and testing sets","5fe77f4c":"## Making Predictions","72304303":"## Model using Recursive Feature Elimination","d89400d1":"#### Creating a new variable","b5fff1fd":"Problem Statement:\n\nA real estate company that has a dataset containing the prices of properties in the Delhi region. It wishes to use the data to optimise the sale prices of the properties based on important factors such as area, bedrooms, parking, etc.\n\nEssentially, the company wants \u2014\n\n\n- To identify the variables affecting house prices, e.g. area, number of rooms, bathrooms, etc.\n\n- To create a linear model that quantitatively relates house prices with variables such as number of rooms, area, number of bathrooms, etc.\n\n- To know the accuracy of the model, i.e. how well these variables can predict house prices.\n","636043e5":"# DELHI HOUSE PRICE ANALYSIS","7518fcd6":"### RFE","c316eec9":"### Data Preparation","7347ebb8":"### Rescaling the Features \nIt is extremely important to rescale the variables so that they have a comparable scale. \nThere are twocoon ways of rescaling \n1. Normalisation (min-max scaling) and \n2. standardisation (mean-o, sigma-1) \nLet's try normalisation","23083e58":"### Building model using sklearn","b87dead3":"## Model Evaluation"}}