{"cell_type":{"e6a3ab54":"code","6e8f2413":"code","792ab37e":"code","f1b21a9c":"code","9152178d":"code","631b5415":"code","52ae7187":"code","fadededc":"code","3b74f596":"code","a32fdd4c":"code","3d1df233":"code","f54f072f":"code","523c6c1e":"code","b5eb37ff":"code","32609288":"code","1e69668d":"code","941cb8ea":"code","23cc2435":"code","7e1ae24a":"code","d75a910e":"code","f5740530":"code","12060813":"code","df4d343a":"code","9f461a69":"code","c764bf4a":"code","970e2f8b":"code","93e34c40":"code","62cb188a":"code","d4ad809d":"code","fca1d072":"code","8bcf7150":"code","46e2cf6f":"code","4dea9a4d":"code","78803c66":"code","9b6503ae":"code","cf00c01c":"code","d6611df4":"code","73df917e":"code","99ab6a11":"code","2597081e":"code","2b0fc68a":"code","01dd7be7":"code","801a8d67":"code","015e10de":"code","88194ac3":"code","be7cfb00":"code","c1420546":"code","6bc6c4f1":"code","23f36f45":"code","24cb1d58":"code","e2f851d7":"code","6d3f6c6b":"code","491d7620":"code","a01b136a":"code","ef80feb5":"markdown","5ed10bc2":"markdown","f8ce29e3":"markdown","9e61514b":"markdown","82abd61e":"markdown","ee16170d":"markdown","4eaff696":"markdown","2d5d741c":"markdown","eb8fc5f8":"markdown","e8b0abc7":"markdown","380f13d4":"markdown","c9211397":"markdown","a225a840":"markdown","11df037e":"markdown","f61e8d8f":"markdown","5bc12b41":"markdown","405eceff":"markdown","4015ba09":"markdown","791b0786":"markdown","8df9ba8e":"markdown"},"source":{"e6a3ab54":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6e8f2413":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split","792ab37e":"df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf1 = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","f1b21a9c":"x_train = df.drop('label', axis = 1)\ny_train = df['label']\n\ntest = df1","9152178d":"x_train.shape","631b5415":"test.shape","52ae7187":"x_train = x_train.values.reshape(42000, 28,28)\ntest = test.values.reshape(28000, 28, 28)","fadededc":"x_train.shape","3b74f596":"test.shape","a32fdd4c":"single_image = x_train[0]","3d1df233":"single_image","f54f072f":"#matplotlib has a method to show these values in image format\nplt.imshow(single_image)","523c6c1e":"#exploring labels\ny_train","b5eb37ff":"from tensorflow.keras.utils import to_categorical","32609288":"#checking the shape of y_train\ny_train.shape","1e69668d":"y_example = to_categorical(y_train)","941cb8ea":"y_example.shape","23cc2435":"y_example[0]","7e1ae24a":"y_cat_train = to_categorical(y_train, num_classes=10)\n#to_categorical takes num_classes on its own based on the label's unique values\n#here it was from 0 to 9, hence, it took 10. You can specify them too using num_classes","d75a910e":"y_cat_train[0]","f5740530":"#checking the maximum value of single_image\nsingle_image.max()","12060813":"#checking the minimum value of single_image\nsingle_image.min()","df4d343a":"x_train = x_train\/255\ntest = test\/255","9f461a69":"#checking the scaled image\nscaled_image = x_train[0]","c764bf4a":"scaled_image","970e2f8b":"scaled_image.max()","93e34c40":"plt.imshow(scaled_image)","62cb188a":"x_train.shape","d4ad809d":"#batch_size, width, height, color channels\nx_train = x_train.reshape(42000, 28, 28, 1)","fca1d072":"test.shape","8bcf7150":"test = test.reshape(28000, 28, 28, 3)","46e2cf6f":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten","4dea9a4d":"from keras.preprocessing.image import ImageDataGenerator\n\ngenerator = ImageDataGenerator(#rescale = 1.\/255,\n                               width_shift_range=0.1,\n                               height_shift_range=0.1,\n                               rotation_range = 20,\n                               shear_range = 0.3,\n                               zoom_range = 0.3,\n                               horizontal_flip = True)\ngenerator.fit(x_train)\n","78803c66":"random_seed = 2\n\nx_train, x_val, y_cat_train, y_val = train_test_split(x_train, y_cat_train, test_size = 0.1, random_state=random_seed)","9b6503ae":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size=(4,4), strides = (1,1), input_shape=(28,28,1),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten()) #flatten our layer, eg, our image is 28x28 so the flattened image will be 28*28=784 pixels\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\n#OUTPUT layer\nmodel.add(Dense(10, activation='softmax')) #choosing softmax because of 'multiclass classification'\n\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics= ['accuracy'])","cf00c01c":"model.summary()","d6611df4":"#Gonna import EarlyStopping in order to avoid overfitting\nfrom tensorflow.keras.callbacks import EarlyStopping","73df917e":"early_stop = EarlyStopping(monitor = 'val_loss', patience = 2)","99ab6a11":"#Fitting the model\nmodel.fit(x_train, y_cat_train, epochs = 10, validation_data = (x_val, y_val), callbacks = [early_stop])","2597081e":"metrics = pd.DataFrame(model.history.history)","2b0fc68a":"metrics.head()","01dd7be7":"#Plotting loss and val_loss together\nmetrics[['loss', 'val_loss']].plot()","801a8d67":"#Plotting accuracy and val_accuracy together\nmetrics[['accuracy', 'val_accuracy']].plot()","015e10de":"#Evaluating validation loss and accuracy\nmodel.evaluate(x_val, y_val, verbose = 0)","88194ac3":"from sklearn.metrics import classification_report, confusion_matrix","be7cfb00":"predictions = model.predict(x_val)\n\n# Convert predictions classes to one hot vectors \npredictions_classes = np.argmax(predictions, axis = 1)\n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val, axis = 1)","c1420546":"predictions","6bc6c4f1":"#we'll use y_true for predictions\nprint(classification_report(y_true, predictions_classes))","23f36f45":"print(confusion_matrix(y_true, predictions_classes))","24cb1d58":"#visualizing confusion matrix\nimport seaborn as sns\n\nplt.figure(figsize = (12, 8))\nsns.heatmap(confusion_matrix(y_true, predictions_classes), annot=True)","e2f851d7":"\n# from keras.applications import MobileNetV2\n# from keras.models import load_model","6d3f6c6b":"# model  = load_model(\"\/kaggle\/input\/common-keras-pretrained-models\/ResNet50.h5\")\n# for i in range(len(model.layers)-1):\n#     model.layers[i].trainable = False\n# model.summary()","491d7620":"# model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics= ['accuracy'])","a01b136a":"# model.fit(x_train, y_cat_train, epochs = 10, validation_data = (x_val, y_val), callbacks = [early_stop])","ef80feb5":"# Both of them look pretty good","5ed10bc2":"displaying the matrix of a single image, [0] defines the first instance of the data","f8ce29e3":"# we're gonna scale them between 0 and 1","9e61514b":"this looks like a **'1'**, and since greyscale values varies from 0 to 255, we can see values close to 255 in the matrix above","82abd61e":"Check the shape of training and test data","ee16170d":"Checking the metrics now.","4eaff696":"Notice here, the first value of label was 1, so to_categorical() has transformed that into an entire row","2d5d741c":"# filters:- how many filters to apply on an image\n# kernel_size:- size of the matrix which strides through the whole image \n# stride:- (x,y) steps while moving the kernel \n# padding:- Padding is the extra layer we add to the corner of the image to prevent shrinkage and loss of info, such as add a padding of 0 on the outside of the image matrix, so that the corner matrix is also covered more than once while striding","eb8fc5f8":"# Now we're going to train our model. Let's import some libraries.","e8b0abc7":"# Now we're gonna take 10% data from the training data and use it for data validation","380f13d4":"**Now we are going to normalize our data**","c9211397":"Here, y_train's dataset of 42000 represents labels, what we want is each of these labels to represent a category,so we'll use to_categorical method","a225a840":"![image.png](attachment:image.png)","11df037e":"![image.png](attachment:image.png)","f61e8d8f":"Split the training data by features and labels","5bc12b41":"# Now we're gonna reshape our image to let the model know that we're dealing with a greyscale image, hence 1 color channel","405eceff":"we can see that to_categorical converted a class vector into a binary class matrix","4015ba09":"**Reshaping our data into a 28x28 matrix**","791b0786":"# Now we'll get Classification Report and Confusion Matrix. \n# A Classification report is used to measure the quality of predictions from a classification algorithm and a Confusion Matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier.","8df9ba8e":"Here we stand correct, the first value is 1, as shown in the image above\n\n\nThe values here represent labels, what we want is categories, so we have to use one-hot-encoding"}}