{"cell_type":{"0d8484be":"code","21a07615":"code","02e47ed7":"code","028df0bf":"code","cd79b067":"code","1a046afd":"code","89dcfda2":"code","7aae2f88":"code","6eec3d41":"code","3d6e483b":"code","96ec1d29":"code","9dff2545":"code","d6dd8a1f":"code","3a4635aa":"code","c02f9871":"code","911ee012":"code","fa17054a":"code","d39f308d":"code","4f07278d":"code","0a2c8602":"code","7633cf24":"code","b27b8065":"code","5fa150d0":"code","79b582f9":"code","8e86d7a1":"code","7144ac50":"code","687631df":"code","cc51f2fe":"code","93cbfa94":"code","c16f38ce":"code","ec612d0d":"code","55a5e7f9":"code","20059dfc":"code","9daab211":"code","89c63c1c":"code","87be32ff":"code","c0c805b1":"code","41b8bd2e":"code","31237a17":"code","042fb488":"code","4ed0d39a":"code","107a3904":"code","b349d524":"code","a5ad7e45":"code","6d3af0ce":"code","005206ab":"code","053126b6":"code","90fc25cf":"code","0570df5d":"code","b4454405":"code","bb8d24d4":"code","42f6160f":"code","178cb9dc":"code","fc9c269b":"code","03e2e159":"code","21d687b9":"code","101ba8ef":"code","a6796e86":"code","778ce433":"markdown","a7852345":"markdown","4d669be3":"markdown","18f6334a":"markdown","0facb5c7":"markdown","c142d18b":"markdown","11d95cdc":"markdown","70881da1":"markdown","93f13e5d":"markdown","b4a5f246":"markdown","aa86da6b":"markdown","4267e6f8":"markdown","f1e9778f":"markdown","5b3526f9":"markdown","555162c4":"markdown","b667a270":"markdown","c7e10e59":"markdown","e2b4052b":"markdown","519cfcdf":"markdown"},"source":{"0d8484be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","21a07615":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","02e47ed7":"df = pd.read_csv('..\/input\/students-performance-in-exams\/StudentsPerformance.csv')","028df0bf":"df.info()\ndf.head()","cd79b067":"df.isnull().sum()","1a046afd":"plt.figure(figsize = (12,10))\nsns.countplot(df['gender'])","89dcfda2":"plt.figure(figsize=(12,10))\nsns.countplot(df['race\/ethnicity'], hue = df['gender'])","7aae2f88":"df['lunch'].nunique()","6eec3d41":"plt.figure(figsize=(12,10))\nsns.countplot(df['lunch'])","3d6e483b":"df['test preparation course'].nunique()","96ec1d29":"plt.figure(figsize=(12,10))\nsns.countplot(df['test preparation course'])","9dff2545":"plt.figure(figsize=(12,10))\nsns.countplot(df['race\/ethnicity'])","d6dd8a1f":"plt.figure(figsize=(12,10))\nsns.countplot(df['race\/ethnicity'], hue=df['lunch'])","3a4635aa":"plt.figure(figsize=(12,10))\nsns.countplot(df['race\/ethnicity'], hue=df['test preparation course'])","c02f9871":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(), annot = True, cmap = 'viridis')","911ee012":"plt.figure(figsize=(12,10))\nsns.pairplot(df)","fa17054a":"# Creating numerical values for categorical data","d39f308d":"df.info()","4f07278d":"# Creating a list of all the object dtypes\nobjects = list(df.dtypes[df.dtypes == \"object\"].index)","0a2c8602":"# One Hot Encoding Categorical data\ndf = pd.get_dummies(data = df, columns = objects, drop_first=True)","7633cf24":"df.head()","b27b8065":"# Lets create a copy of the df because we will be predicting for all of the different subject scores \n\nmath_df = df.copy()","5fa150d0":"X = math_df.drop('math score', axis = 1).values\ny = math_df['math score']","79b582f9":"# Splitting Data into Training and Test Sets","8e86d7a1":"from sklearn.model_selection import train_test_split","7144ac50":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","687631df":"# Scaling Data\nfrom sklearn.preprocessing import StandardScaler","cc51f2fe":"scaler = StandardScaler()","93cbfa94":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","c16f38ce":"from sklearn.ensemble import RandomForestRegressor","ec612d0d":"# Creating Random Forest Model\nrf = RandomForestRegressor(n_estimators=200)","55a5e7f9":"# Training Model\nrf.fit(X_train, y_train)","20059dfc":"# Predictions\npredictions = rf.predict(X_test)","9daab211":"# Evaluating Model\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","89c63c1c":"print('MAE: ', mean_absolute_error(y_test, predictions))","87be32ff":"print('MSE: ', mean_squared_error(y_test, predictions))","c0c805b1":"print('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","41b8bd2e":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","31237a17":"reading_df = df.copy()","042fb488":"X = reading_df.drop(\"reading score\", axis = 1).values\ny = reading_df[\"reading score\"].values","4ed0d39a":"#Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","107a3904":"#Scale Data with StandardScaler\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","b349d524":"# Creating Model\nrf = RandomForestRegressor(n_estimators=200)","a5ad7e45":"# Training model\nrf.fit(X_train, y_train)","6d3af0ce":"#Predictions\n\npredictions = rf.predict(X_test)","005206ab":"# Evaluating Model","053126b6":"print('MAE: ', mean_absolute_error(y_test, predictions))\nprint('MSE: ', mean_squared_error(y_test, predictions))\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","90fc25cf":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","0570df5d":"X = reading_df.drop(\"writing score\", axis = 1).values\ny = reading_df[\"writing score\"].values","b4454405":"#Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","bb8d24d4":"#Scale Data with StandardScaler\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","42f6160f":"# Creating Model\nrf = RandomForestRegressor(n_estimators=200)","178cb9dc":"# Training model\nrf.fit(X_train, y_train)","fc9c269b":"#Predictions\n\npredictions = rf.predict(X_test)","03e2e159":"# Evaluating the Model","21d687b9":"print('MAE: ', mean_absolute_error(y_test, predictions))\nprint('MSE: ', mean_squared_error(y_test, predictions))\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","101ba8ef":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","a6796e86":"print(\"Math min score was: {} \".format(df['math score'].min()))\nprint(\"Math max score was: {} \".format(df['math score'].max()))\nprint(\"Reading min score was: {} \".format(df['reading score'].min()))\nprint(\"Reading max score was: {} \".format(df['reading score'].max()))\nprint(\"Writing min score was: {} \".format(df['writing score'].min()))\nprint(\"Writing max score was: {} \".format(df['writing score'].max()))","778ce433":"The Random Forest Model predicted quite accurately for the Math, Reading, and Writing Scores. The Writing Scores were predicted the most accurately followed by the Reading Scores, and lastly the Math Scores. Considering the large range between scores, the model predicted quite accurately having an error average of around 4 - 6% for all of the subject scores.","a7852345":"More students didn't prepare for their tests than did ","4d669be3":"# Thank You!!!","18f6334a":"# Random Forest Model (Reading Score Prediction) ","0facb5c7":"# Exploratory Data Analysis","c142d18b":"# Conclusion","11d95cdc":"# Random Forest Model (Writing Score Prediction)","70881da1":"As expected there is a high correlation between reading and writing scores, both being subsets of the language category","93f13e5d":"writing_df = df.copy()","b4a5f246":"Model's residuals is once again a normal curve meaning the model was a good fit. ","aa86da6b":"Group C and D seem to be the top two most common races in the data set","4267e6f8":"# Random Forest Model (Math Score Prediction)","f1e9778f":"Around an even distribution of male and females for every gender.","5b3526f9":"Residuals are a normal curve meaning model was a good fit.","555162c4":"Approximately a normal curve of the residuals which means it was a good model","b667a270":"Getting a free\/reduced lunch vs standard lunch may play a part in overall test scores","c7e10e59":"# Please let me know what you think!","e2b4052b":"Around an even distribution between Male and Female Students","519cfcdf":"# Data Manipulation"}}