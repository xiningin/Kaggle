{"cell_type":{"f7e9673d":"code","6fc10a26":"code","64b47e54":"code","632ec035":"code","01e54d3c":"code","8b2c43b9":"code","d0d68dd0":"code","028b9c79":"code","ee49740c":"code","e3548826":"code","8c05e4b2":"code","98d7db4d":"code","a7fc53c2":"code","06df3c1b":"code","f71d25fd":"code","423ebcad":"code","2ed2f4e4":"markdown","baf7c848":"markdown","30ec5bfb":"markdown","9ab07606":"markdown","cc2ab6b0":"markdown","8495fdf7":"markdown","9027e94c":"markdown","43ea9ab5":"markdown"},"source":{"f7e9673d":"# Initial imports\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\nfrom random import shuffle\nfrom math import *\nimport numpy as np\n%matplotlib inline","6fc10a26":"# Loading the network\nobserved = nx.read_gml('..\/input\/netscience.gml',label=\"id\")\nobserved = nx.Graph(observed, name=\"Observed Links\")\n\nrandom.seed(1000)\n\nprobe_size = int(0.3*(observed.number_of_edges()))\nprobe_edge_set = random.sample(list(observed.edges()),probe_size)\n\ntraining = nx.Graph(observed, name=\"Training Links\")\nfor i in probe_edge_set:\n    training.remove_edge(i[0],i[1])\n\nprint(nx.info(observed), \"\\n\")\nprint(nx.info(training), \"\\n\")\nprint(\"Probe Edge Set\\nNumber of edges:\", len(probe_edge_set))","64b47e54":"def _apply_prediction(G, f, ebunch=None):\n    \"\"\"Applies the given function to each edge in the specified iterable of edges.\n\n    'G' is an instance of :class:'networkx.Graph'.\n\n    'f' is a function on two inputs, each of which is a node in the graph.\n    The function can return anything, but it should return a value \n    representing a prediction of the score of a \"link\" joining the two nodes.\n\n    'ebunch' is an iterable of pairs of nodes. If not specified, all non-edges in the graph 'G' will be used.\n    \"\"\"\n    if ebunch is None:\n        ebunch = nx.non_edges(G)\n    return [(u, v, f(u, v)) for u, v in ebunch]","632ec035":"# ====================================================\n# CALCULATING\/PLOTTING AUC : AREA UNDER ROC CURVE\n# ====================================================\ndef AUC(score_probe,score_non_existent):\n    N = min(len(score_probe),len(score_non_existent))\n    shuffle(score_probe)\n    shuffle(score_non_existent)\n    \n    n1 = n2 = n3 = 0\n    for i in range(N):\n        probe_edge = score_probe[i]\n        non_ex_edge = score_non_existent[i]\n        if probe_edge[2] > non_ex_edge[2]:\n            n1 += 1\n        elif probe_edge[2] < non_ex_edge[2]:\n            n3 += 1\n        else:\n            n2 += 1\n\n    tp = tn = n1 + n2\/2\n    fp = fn = N - tp\n    \n    AUC = 0\n    if N > 0:\n        AUC = tp \/ N\n    return AUC   \n\n\ndef plot(mins,maxs,means,vals,names):\n#     fig,(sub,box) = plt.subplots(ncols = 2, figsize = (15,5))\n    \n    fig = plt.figure(1)\n    sub = fig.add_subplot(111)\n    fig2 = plt.figure(2)\n    box = fig2.add_subplot(111)\n    \n    tests = len(names)\n    iters = 0\n    if tests > 0:\n        iters = len(vals[0])\n\n#   Line Plot\n    for i in range(tests):\n        name = names[i]\n        l = vals[i]\n        sub.plot(range(1,len(l)+1),l,'-o',label=name)\n        \n    sub.set_title(\"Area Under ROC Curve\")\n    sub.set_xlabel('Iteration')\n    sub.set_ylabel('AUC')\n    sub.set_xticks(np.arange(1, iters+1, 1.0))\n    sub.set_yticks(np.arange(0, 1.1, 0.1))\n\n    sub.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n#     sub.legend(loc='center left', bbox_to_anchor=(0.5, -0.4))\n    sub.axhline(0.5, linestyle='--', color='k')\n    sub.yaxis.grid()\n\n#   Box Plot\n    box.set_title(\"Area Under ROC Curve\")\n    box.set_ylabel('AUC')\n    plt.yticks(np.arange(0, 1.1, 0.1))\n    plt.xticks(rotation=90)\n    box.axis(ymin=0,ymax=1)\n    box.axhline(0.5, linestyle='--', color='k')\n    box.yaxis.grid()\n\n    box.errorbar(names, means, fmt='sb', lw=3)\n    box.errorbar(names, means, \n                 [np.array(means)-np.array(mins), np.array(maxs)-np.array(means)],\n                 fmt='.b', ecolor='blue', lw=1,capsize=3,capthick=3,ms=9,markerfacecolor='none',mew=1)\n    plt.show()\n    \n\ndef plotAUC(metrics,N=100,T=10):\n    mins = []\n    maxs = []\n    means = []\n    names = []\n    vals = []\n    for name,f in metrics.items():\n        l = []\n        for i in range(T):\n            pro = random.sample(probe_edge_set, N)\n            score_probe = f(training, pro)\n            non_e = random.sample(list(nx.non_edges(observed)), N)\n            score_non_existent = f(training, non_e)\n\n            l += [AUC(score_probe,score_non_existent)]\n\n        AUCrange = (min(l), max(l), sum(l)\/float(len(l)))\n        vals.append(l)\n        mins.append(AUCrange[0])\n        maxs.append(AUCrange[1])\n        means.append(AUCrange[2])\n        names.append(name)\n        print(name,':',AUCrange)\n\n    plot(mins,maxs,means,vals,names)","01e54d3c":"# ====================================================\n# CRISP LOGIC : SIMILARITY METRICS\n# ====================================================\ndef graph_distance(G, ebunch=None):\n    \"\"\"Compute the score based on shortest path length (number of nodes in the path).\n    \"\"\"\n    def predict(u, v):\n        try:\n            return -nx.shortest_path_length(G,source=u,target=v)\n        except:\n            return -observed.number_of_nodes()\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef path_length(G, ebunch=None):\n    \"\"\"Compute the score based on shortest path length (sum of weights).\n    \"\"\"\n    def predict(u, v):\n        try:\n            return -nx.shortest_path_length(G,source=u,target=v,weight='value')\n        except:\n            return -observed.number_of_nodes()\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef common_neighbors(G, ebunch=None):\n    \"\"\"Compute the Common Neighbours of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return len(list(nx.common_neighbors(G, u, v)))\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef jaccard_coefficient(G, ebunch=None):\n    \"\"\"Compute the Jaccard coefficient of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        union_size = len(set(G[u]) | set(G[v]))\n        if union_size == 0:\n            return 0\n        return len(list(nx.common_neighbors(G, u, v))) \/ union_size\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef adamic_adar_index(G, ebunch=None):\n    \"\"\"Compute the Adamic-Adar index of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return sum(1 \/ log(G.degree(w)) for w in nx.common_neighbors(G, u, v))\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef resource_allocation_index(G, ebunch=None):\n    \"\"\"Compute the resource allocation index of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return sum(1 \/ G.degree(w) for w in nx.common_neighbors(G, u, v))\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef preferential_attachment(G, ebunch=None):\n    \"\"\"Compute the preferential attachment score of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return G.degree(u) * G.degree(v)\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef clustering_coefficient(G, ebunch=None):\n    \"\"\"Compute the Clustering Coefficient score of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return nx.clustering(G,u) + nx.clustering(G,v)\n    return _apply_prediction(G, predict, ebunch)\n\n\ndef weighted_clustering_coefficient(G, ebunch=None):\n    \"\"\"Compute the Weighted Clustering Coefficient score of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return nx.clustering(G,u,weight='value') + nx.clustering(G,v,weight='value')\n    return _apply_prediction(G, predict, ebunch)","8b2c43b9":"def Close(G,u,v,path=None):\n    '''\n    Takes in a clique G and two of its nodes\n    Returns the \"Close\" value of the two nodes\n    '''\n    if not path:\n        try:\n            path = nx.shortest_path(G,source=u,target=v,weight='value')\n        except:\n            return 0\n    \n    q = len(path)-1\n    path_len = 0.0\n    for i in range(q):\n        path_len += G[path[i]][path[i+1]]['value']\n    \n    if q < 2:\n        return 1\n    elif q > 3:\n        return 0\n    else:\n        return path_len\/float(2.0*(pow(10,q-2)))","d0d68dd0":"def Most(G,nodes,u,alpha=0.3,beta=0.7):\n    '''\n    Returns the \"Most\" value of the given node of the clique\n    '''\n    if len(nodes) == 0:\n        return 0\n    \n    p = 0\n    for v in nodes:\n        p += Close(G,u,v)\n    p \/= float(len(nodes))\n    \n    if p <= alpha:\n        return 0\n    elif p <= beta:\n        return (p-alpha)\/float(beta-alpha)\n    else:\n        return 1","028b9c79":"def R(G,x,y,k):\n    '''\n    Takes in Graph G, source x, target y and path length k    \n    Returns R\n    R = 1 if there exists a path containing atleast 'k' links\n    R = 0 else\n    '''\n    paths = nx.all_simple_paths(G,source=x,target=y,cutoff=k)\n    for path in paths:\n        if len(path) >= k:\n            return 1\n    return 0\n\ndef Far(k,alpha=1.5,beta=3.5):\n    '''\n    Heaviside Step Function that denotes if a certain path length is \"far\" or not\n    '''\n    if k <= alpha:\n        return 0\n    elif k <= beta:\n        return (k-alpha)\/float(beta-alpha)\n    else:\n        return 1\n\ndef NotFar(G,x,y,n):\n    '''\n    Returns the NotFar(x,y) value which is given by the formula:\n    NotFar(x,y) = Max { \n                        R(x,y)[at k] AND 1-Far(k) \n                    } over k, 1<=k<=n \n    '''\n    notfar = 0\n    for k in range(1,n):\n        if R(G,x,y,k) == 0:\n            break\n        notfar = max(notfar,1.0-Far(k))\n    return notfar","ee49740c":"def C1(G,nodes,x):\n    return Most(G,nodes,x)","e3548826":"def C2(G,nodes,x):\n    c2 = 1\n    for y in nodes:\n        c2 = min(c2,NotFar(G,x,y,len(nodes)))\n    return c2","8c05e4b2":"def C3(G,nodes,x):\n    rest_list = random.sample(G.nodes(),2*len(nodes))\n    rest_set = set(rest_list) - set(nodes+[x])\n    rest_list = random.sample(list(rest_set),len(nodes))\n    \n    m1 = Most(G,nodes,x)\n    m2 = Most(G,list(rest_list),x)\n    \n    if m1 > m2:\n        return 1\n    else:\n        return 0","98d7db4d":"# ====================================================\n# CLIQUES\n# ====================================================\ncliques = nx.cliques_containing_node(training,nodes=list(range(observed.number_of_nodes())))\nfor key,c in cliques.items():\n    c = sorted(c, key = lambda x : -len(x))\n    cliques[key] = c\nprint(\"Cliques Stored\")","a7fc53c2":"# ====================================================\n# FUZZY CLUSTERING COEFFICIENT\n# ====================================================\ndef fcc(G,x):\n    nodes = cliques[x][0]\n    nodes = list(set(nodes) - set([x]))\n    cc = min(C1(G,nodes,x),C2(G,nodes,x),C3(G,nodes,x))\n    return cc\n\ndef fuzzy_clustering_coefficient(G, ebunch=None):\n    \"\"\"Compute the Fuzzy Clustering Coefficient score of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return fcc(G,u)+fcc(G,v)\n    return _apply_prediction(G, predict, ebunch)","06df3c1b":"# ====================================================\n# FUZZY CLUSTER OVERLAP INDEX\n# ====================================================\ndef cluster_x(G,x,K,N):\n    cluster_x = 0.0\n    nodes = random.sample(range(G.number_of_nodes()),N)\n    for node in nodes:\n        if node == x:\n            continue\n        paths = nx.all_simple_paths(G,source=x,target=node,cutoff=K)\n        for path in paths:\n            path_len = 0.0\n            for i in range(len(path)-1):\n                path_len += G[path[i]][path[i+1]]['value']\n            cluster_x += path_len\n    cluster_x = abs(cluster_x)\n    return cluster_x\n\n\ndef oi(G,u,v,K=5,N=100):\n    paths = nx.all_simple_paths(G,source=u,target=v,cutoff=K)\n    \n    close_sum = 0.0\n    for path in paths:\n        close_sum += Close(G,u,v,path)\n\n    cluster_u = cluster_x(G,u,K,N)\n    cluster_v = cluster_x(G,v,K,N)\n    \n    if cluster_u + cluster_v > 0:\n        return close_sum \/ float(cluster_u + cluster_v)\n    return 0\n\n\ndef fuzzy_cluster_overlap(G, ebunch=None):\n    \"\"\"Compute the Fuzzy Cluster Overlap score of all node pairs in ebunch.\n    \"\"\"\n    def predict(u, v):\n        return oi(G,u,v,K=3,N=120)\n    return _apply_prediction(G, predict, ebunch)","f71d25fd":"metrics = {\n    \"Graph Distance\" : graph_distance,\n    \"Path Length\" : path_length,\n    \"Common Neighbors\" : common_neighbors,\n    \"Jaccard Coefficient\" : jaccard_coefficient,\n    \"Adamic\/Adar Index\" : adamic_adar_index,\n    \"Resource Allocation Index\" : resource_allocation_index,\n    \"Preferential Attachment\" : preferential_attachment,\n    \"Clustering Coefficient\" : clustering_coefficient,\n    \"Weighted Clustering Coefficient\" : weighted_clustering_coefficient,\n}\nplotAUC(metrics)","423ebcad":"metrics = {\n    \"CC\" : clustering_coefficient,\n    \"WCC\" : weighted_clustering_coefficient,\n    \"FCC\" : fuzzy_clustering_coefficient,\n    \"FCO\" : fuzzy_cluster_overlap,\n}\nplotAUC(metrics,N=100,T=10)","2ed2f4e4":"# Crisp Logic for Link Prediction\n---\n## Similarity Metrics\n* Graph Distance\n* Common Neighbours\n* Jaccard's Coefficient\n* Adamic\/Adar (Frequency-Weighted Common Neighbours)\n* Resource Allocation Index\n* Preferential Attachment\n* Katz (Exponentially Damped Path Counts)\n* Weighted Clustering Coefficient","baf7c848":"### Most","30ec5bfb":"### Third Criterion\n**\u201cNo element not on the clique is better connected to the members of a clique than any element in the clique.\u201d ** In the third criterion, every node out of the cluster of considered nodes should not be close to most of the nodes in the cluster.","9ab07606":"### Close","cc2ab6b0":"### Second Criterion\n**\u201cNone of the elements in S are too far from the others.\u201d** In the second criterion of the cluster, there are Far and Not Far concepts.","8495fdf7":"### Not Far","9027e94c":"### First Criterion\n**\u201cMost of the elements in S are closely connected.\u201d** In the first criterion, the first fuzzy term is the concept of close,  which  means  how  much  two  nodes  are  closely connected. The close concept can be defined as a path with a minimum length that connects two nodes to each other.","43ea9ab5":"# Fuzzy Logic for Link Prediction\n---\n## Clustering Coefficient\nAn important concept that shows how much the neighbors of a node are related to each other is the clustering coefficient (CC). This measure calculates the number of triangles over the number of possible triangles related to the node. CC is based on the clique concept. If S shows a clique in the graph, then the following criteria can define the clique: \n* C1 : \u201cMost of the elements in S are closely connected.\u201d \n* C2 : \u201cNone of the elements in S are too far from the others.\u201d \n* C3 : \u201cNo element not on the clique is better connected to the members of a clique than any element in the clique.\u201d \n\nIn the above-mentioned criteria, there are some functions that should be defined as fuzzy terms."}}