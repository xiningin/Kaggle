{"cell_type":{"ca3063e0":"code","62007b4a":"code","01956be2":"code","7d74eedc":"code","6972de0c":"code","29653105":"code","9b2cb82c":"code","11723ae3":"code","3a47444a":"code","1e7d1f47":"code","74a40f1f":"code","2ef42cae":"code","3af153aa":"code","757f8e90":"code","ca9097e8":"code","934ad722":"code","f6442099":"code","293100cf":"code","6401d61d":"code","156c4582":"code","dba241d3":"code","7d070b79":"code","ffda8b47":"code","26b63039":"code","e6b0f32e":"code","b29f9ec0":"code","b5b4bf87":"code","efe19d1a":"code","fb7e80d3":"code","191daae6":"code","550710bc":"code","1fe2d122":"code","f4388b5c":"code","7b1cf2b9":"code","58c30fb8":"code","32907284":"code","23fe6b49":"code","d9b805f3":"code","a84468c4":"code","5aab694c":"code","12fbe17c":"code","0fab36f7":"code","f81d1154":"code","e4b85c2d":"code","e732ccbe":"code","31927ab6":"code","08b51793":"code","1bfd092d":"code","03aabf55":"code","afd38e9e":"code","44811f1c":"code","a84e19fb":"code","d44a1bf7":"code","961d0a8b":"code","a9e5c6e6":"code","d18bc913":"code","d71a0c90":"markdown","4cbbc9a4":"markdown","92022118":"markdown","43e5d3a8":"markdown","6a688613":"markdown","465e9299":"markdown","a36563c9":"markdown","3ca89721":"markdown","c27dd8d6":"markdown","e7512b68":"markdown","ea856e2d":"markdown","97d5ffc6":"markdown","190a797c":"markdown","0ad6a93d":"markdown"},"source":{"ca3063e0":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,KFold\nimport lightgbm as lgb\nimport itertools\nfrom sklearn.metrics import roc_auc_score\nimport gc\nfrom bayes_opt import BayesianOptimization\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial","62007b4a":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","01956be2":"train_trains = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv', index_col = 'TransactionID')\ntrain_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv', index_col = 'TransactionID')\ntest_trains = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv', index_col = 'TransactionID')\ntest_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv', index_col = 'TransactionID')","7d74eedc":"train_trains = reduce_mem_usage(train_trains)\ntrain_id = reduce_mem_usage(train_id)\ntest_trains = reduce_mem_usage(test_trains)\ntest_id = reduce_mem_usage(test_id)","6972de0c":"train = pd.merge(train_trains, train_id, on ='TransactionID', how = 'left')\ntest = pd.merge(test_trains, test_id, on = 'TransactionID', how = 'left')\ntrain = train.reset_index()\ntest = test.reset_index()\nprint(train.shape)\nprint(test.shape)","29653105":"del train_id, train_trains, test_id, test_trains\ngc.collect()","9b2cb82c":"print('This might be an imbalanced class problem from what we can see')\ntrain['isFraud'].value_counts(normalize = True)*100","11723ae3":"print('THERE ARE {0} MISSING VALUES IN TRAIN'.format(train.isnull().any().sum()))","3a47444a":"train['isFraud'].value_counts(normalize = True, dropna = False).values","1e7d1f47":"for cols in train.columns[2:]:\n    if train[cols].value_counts(normalize = True, dropna = False).values[0]> 0.9:\n        print(train[cols].value_counts(normalize = True, dropna = False)*100)\n        print('-'*90)\n        print('-'*90)","74a40f1f":"train.head()","2ef42cae":"test.head()","3af153aa":"card_fraud = train[['isFraud', 'card4']].groupby(by = 'card4').count()\ncard_fraud = card_fraud.reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = card_fraud['card4'], height = card_fraud['isFraud'], color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('CARD TYPE', fontdict = {'fontsize':15})\nplt.ylabel('NO OF FRAUDS', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.27, ax.get_height() + 5000, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","757f8e90":"card_fraud = train[['isFraud', 'card6']].groupby(by = 'card6').count()\ncard_fraud = card_fraud.reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = card_fraud['card6'], height = card_fraud['isFraud'], color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('CARD TYPE', fontdict = {'fontsize':15})\nplt.ylabel('NO OF FRAUDS', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.27, ax.get_height() + 5000, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","ca9097e8":"plt.figure(figsize = (10,4))\naxes = plt.barh(train['DeviceType'].unique()[1:], train['DeviceType'].value_counts().values, color = ['orange', 'green'], \n               edgecolor = 'black')\nplt.tick_params(labelsize = 12)\nfor ax in axes.patches:\n    plt.text(ax.get_width()- 10500, ax.get_y() + 0.34, str(round(ax.get_width(), 2)), fontdict= {'fontsize':13})\nplt.title('Total Fraud Occurance on different platforms', fontdict = {'fontsize':16})\nplt.show()","934ad722":"id31_fruad = train['id_31'][train['isFraud'] == 0].value_counts()\nid31 = train['id_31'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(id31.keys()[:10], width = id31.values[:10])\naxes[1].barh(id31_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('Browsers from where most frad cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('Browsers from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","f6442099":"dev_fruad = train['DeviceInfo'][train['isFraud'] == 0].value_counts()\ndev = train['DeviceInfo'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(dev.keys()[:10], width = id31.values[:10])\naxes[1].barh(dev_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('Handsets from where most fraud cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('Handsets from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","293100cf":"dev_fruad = train['P_emaildomain'][train['isFraud'] == 0].value_counts()\ndev = train['P_emaildomain'][train['isFraud'] == 1].value_counts()\nfig, axes = plt.subplots(2,1, figsize = (10,8), sharex = False, sharey = False)\naxes[0].barh(dev.keys()[:10], width = id31.values[:10])\naxes[1].barh(dev_fruad.keys()[:10], width = id31_fruad.values[:10])\naxes[0].tick_params(labelsize = 12)\naxes[1].tick_params(labelsize = 12)\naxes[0].set_title('email platforms from where most fraud cases happened', fontdict = {'fontsize':15})\naxes[1].set_title('email platforms from where least fraud cases happened',fontdict = {'fontsize':15})\nplt.show()","6401d61d":"fig, axes = plt.subplots(1,2, figsize = (15,6))\nfrd_amt = train[['TransactionAmt', 'card4']][train['isFraud'] == 1].groupby(by = 'card4').mean().reset_index()\nfrd_amt1 = train[['TransactionAmt', 'card4']][train['isFraud'] == 0].groupby(by = 'card4').mean().reset_index()\na = axes[0].bar(x = frd_amt['card4'], height = frd_amt['TransactionAmt'],  color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\naxes[0].tick_params(labelsize = 13)\naxes[0].set_xlabel('Card Type', fontdict = {'fontsize':15})\naxes[0].set_ylabel('Average Fraud Amount', fontdict = {'fontsize':15})\nfor ax in a.patches:\n    axes[0].text(ax.get_x() + 0.27, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\n    \nb = axes[1].bar(x = frd_amt1['card4'], height = frd_amt1['TransactionAmt'],  color = ['red', 'yellow', 'green', 'blue'], edgecolor = 'Black')\naxes[1].tick_params(labelsize = 13)\naxes[1].set_xlabel('Card Type', fontdict = {'fontsize':15})\naxes[1].set_ylabel('Average Non-Fraud Amount', fontdict = {'fontsize':15})\nfor ax in b.patches:\n    axes[1].text(ax.get_x() + 0.27, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","156c4582":"res_fraud = train[['isFraud', 'id_33']].groupby(by = 'id_33').sum().reset_index()\nres_fraud = res_fraud.sort_values(by = 'isFraud', ascending = False)\nres_fraud = res_fraud[:15][:]\nplt.figure(figsize = (15,8))\nplt.plot(res_fraud['id_33'], res_fraud['isFraud'],'*', color = 'red', markersize = 15)\nplt.plot(res_fraud['id_33'], res_fraud['isFraud'], color = 'black') \nplt.xticks(rotation = 45)\nplt.xlabel('Resolutions', fontdict = {'fontsize':14})\nplt.ylabel('Total Fraud occured', fontdict = {'fontsize':14})\nplt.title('Total Fraud occured VS Resolutions', fontdict = {'fontsize':18})\nplt.show()","dba241d3":"fig, axes = plt.subplots(6,2, figsize = (13,25), sharex = False, sharey = False)\nsns.distplot(train['D1'].dropna().astype(int), ax = axes[0,0])\nsns.distplot(train['D2'].dropna().astype(int), ax = axes[0,1])\nsns.distplot(train['D3'].dropna().astype(int), ax = axes[1,0])\nsns.distplot(train['D4'].dropna().astype(int), ax = axes[1,1])\nsns.distplot(train['D5'].dropna().astype(int), ax = axes[2,0])\nsns.distplot(train['D6'].dropna().astype(int), ax = axes[2,1])\nsns.distplot(train['D7'].dropna().astype(int), ax = axes[3,0])\nsns.distplot(train['D8'].dropna().astype(int), ax = axes[3,1])\nsns.distplot(train['D9'].dropna().astype(int), ax = axes[4,0])\nsns.distplot(train['D10'].dropna().astype(int), ax = axes[4,1])\nsns.distplot(train['D11'].dropna().astype(int), ax = axes[5,0])\nsns.distplot(train['D12'].dropna().astype(int), ax = axes[5,1])\nplt.show()","7d070b79":"def label_collector(string):\n    label = string.split('.')[0]\n    return label\n\ntemp = train['P_emaildomain'].astype(str)\ntrain['label_encode'] = temp.apply(label_collector)","ffda8b47":"card_cost = train[['label_encode', 'TransactionAmt','isFraud']][train['isFraud']==1].groupby(by = 'label_encode').mean().reset_index()\ncard_cost = card_cost.sort_values(by = 'TransactionAmt', ascending = False)\nplt.figure(figsize = (14,7))\nplt.xticks(rotation = 45)\nplt.xlabel('E-mail domain', fontdict = {'fontsize':13})\nplt.ylabel('Average Fraud Amount', fontdict = {'fontsize':13})\nplt.tick_params(labelsize = 12)\naxes = plt.bar(x = card_cost['label_encode'].iloc[0:10], height = card_cost['TransactionAmt'].iloc[0:10], color = ['red','green', 'blue', 'yellow', 'pink', 'black', 'orange','purple', 'brown', 'white'], edgecolor = 'black')\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.title('E-Mail domain vs Fraud Amount', fontdict = {'fontsize':15})\nplt.show()","26b63039":"card_cost = train[['label_encode', 'TransactionAmt','isFraud']][train['isFraud']==0].groupby(by = 'label_encode').mean().reset_index()\ncard_cost = card_cost.sort_values(by = 'TransactionAmt', ascending = False)\nplt.figure(figsize = (14,7))\nplt.xticks(rotation = 45)\nplt.xlabel('E-mail domain', fontdict = {'fontsize':13})\nplt.ylabel('Average Non-Fraud Amount', fontdict = {'fontsize':13})\nplt.tick_params(labelsize = 12)\naxes = plt.bar(x = card_cost['label_encode'].iloc[0:10], height = card_cost['TransactionAmt'].iloc[0:10], color = ['red','green', 'blue', 'yellow', 'pink', 'black', 'orange','purple', 'brown', 'white'], edgecolor = 'black')\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 3, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.title('E-Mail domain vs Fraud Amount', fontdict = {'fontsize':15})\nplt.show()","e6b0f32e":"train = train.drop('label_encode', axis = 1)","b29f9ec0":"cd_fault = train[['ProductCD', 'isFraud']][train['isFraud']==1].groupby(by = 'ProductCD').sum().reset_index()\nplt.figure(figsize = (10,6))\naxes = plt.bar(x = cd_fault['ProductCD'], height = cd_fault['isFraud'],  color = ['red', 'yellow', 'green', 'blue', 'pink'], edgecolor = 'Black')\nplt.tick_params(labelsize = 13)\nplt.xlabel('ProductCD', fontdict = {'fontsize':15})\nplt.ylabel('Total Fraudulent cases', fontdict = {'fontsize':15})\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.2, ax.get_height() + 100, str(round(ax.get_height(), 2)), fontdict= {'fontsize':13})\nplt.show()","b5b4bf87":"cols_drop_train = [cols for cols in train.columns if train[cols].isnull().sum()\/ train.shape[0] > 0.9]\ncols_drop_test = [cols for cols in test.columns if test[cols].isnull().sum()\/ test.shape[0]> 0.9]\nbig_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\ndrop_cols = list(set(cols_drop_train + cols_drop_test + big_top_value_cols + big_top_value_cols_test))\ndrop_cols.remove('isFraud')","efe19d1a":"train.drop(drop_cols, axis = 1, inplace = True)\ntest.drop(drop_cols, axis = 1, inplace = True)","fb7e80d3":"del cols_drop_test, cols_drop_train, big_top_value_cols, big_top_value_cols_test, drop_cols","191daae6":"train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\ntrain[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\ntest[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\ntest[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)","550710bc":"print([cols for cols in train.columns if train[cols].dtype == 'O'])","1fe2d122":"def labelencode(train,test):\n    for col in train.drop(['TransactionID','isFraud','TransactionDT'],axis = 1).columns:\n        if train[col].dtype == 'O' or test[col].dtype == 'O':\n            le = LabelEncoder()\n            le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n            train[col] = le.transform(list(train[col].astype(str).values))\n            test[col] = le.transform(list(test[col].astype(str).values))\n    return train,test","f4388b5c":"train, test = labelencode(train, test)","7b1cf2b9":"y_test = train['isFraud']","58c30fb8":"cols_drops = ['TransactionID','isFraud','TransactionDT']\ntrain = train.drop(cols_drops, axis = 1)","32907284":"train.columns","23fe6b49":"test = test.drop(['TransactionID','TransactionDT'], axis = 1)","d9b805f3":"train = train.fillna(-999)\ntest = test.fillna(-999)","a84468c4":"train_m, val_m_train, val1, val2 = train_test_split(train,y_test, test_size = 0.3, random_state = 10, stratify = y_test)\ntrain_m_index = train_m.index\nval_m_index = val_m_train.index\nval1_index = val1.index\nval2_index = val2.index","5aab694c":"val_m_train.shape","12fbe17c":"def objective(num_leaves,min_child_weight,feature_fraction,bagging_fraction,\n              max_depth,learning_rate,reg_alpha,reg_lambda,min_data_in_leaf):\n    global train_m\n    global val_m\n    global y_test\n    global train_m_index\n    global val_m_index\n    global val1,val2, val1_index, val2_index\n    num_leaves = int(num_leaves)\n    max_depth = int(max_depth)\n    min_data_in_leaf = int(min_data_in_leaf)\n    assert type(num_leaves) == int\n    assert type(min_data_in_leaf) == int\n    assert type(max_depth) == int\n    params = {'num_leaves': num_leaves,\n          'min_child_weight': min_child_weight,\n          'feature_fraction': feature_fraction,\n          'bagging_fraction': bagging_fraction,\n          'min_data_in_leaf': min_data_in_leaf,\n          'objective': 'binary',\n          'max_depth': max_depth,\n          'learning_rate': learning_rate,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': reg_alpha,\n          'reg_lambda': reg_lambda,\n          'random_state':42,\n         }\n    oof = np.zeros(len(train_m))\n    early_stopping_rounds = 50\n    xgtrain = lgb.Dataset(train_m, label=val1[val1_index])\n    xgvalid = lgb.Dataset(val_m_train, label=val2[val2_index])\n    num_boost_round = 200\n    model_lgb = lgb.train(params, xgtrain , valid_sets = [xgtrain, xgvalid], num_boost_round = num_boost_round,\n                            early_stopping_rounds = early_stopping_rounds, verbose_eval = 0)\n    score  = roc_auc_score(val2, model_lgb.predict(val_m_train))\n    return score","0fab36f7":"bound_lgb = {'num_leaves': (70,600),\n              'min_child_weight': (0.001, 0.07),\n              'feature_fraction': (0.1,0.9),\n              'bagging_fraction': (0.1,0.9),\n              'max_depth': (-1,50),\n              'learning_rate': (0.2,0.9),\n              'reg_alpha': (0.3,0.9),\n              'reg_lambda': (0.3,0.9),\n              'min_data_in_leaf':(50,300)\n         }","f81d1154":"LGB_BO = BayesianOptimization(objective, bound_lgb, random_state=42)","e4b85c2d":"LGB_BO.space.keys","e732ccbe":"init_points = 10\nn_iter = 15\nprint('-' * 130)\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings('ignore')\n    LGB_BO.maximize(init_points=init_points, n_iter=n_iter,acq='ucb', xi=0.0, alpha=1e-5)","31927ab6":"LGB_BO.max['target']","08b51793":"#LGB_BO.max['params']","1bfd092d":"'''params = {'num_leaves': int(LGB_BO.max['params']['num_leaves']),\n          'min_child_weight': LGB_BO.max['params']['min_child_weight'],\n          'bagging_fraction': LGB_BO.max['params']['bagging_fraction'],\n          'feature_fraction':LGB_BO.max['params']['feature_fraction'],\n          'min_data_in_leaf': int(LGB_BO.max['params']['min_data_in_leaf']),\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': LGB_BO.max['params']['learning_rate'],\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha':LGB_BO.max['params']['reg_alpha'],\n          'reg_lambda': LGB_BO.max['params']['reg_lambda'],\n          'random_state':42\n         }'''","03aabf55":"params = {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.006883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47,\n         }","afd38e9e":"d_train = lgb.Dataset(train, label=y_test)","44811f1c":"clf = lgb.train(params, d_train, verbose_eval=False, num_boost_round = 1000)","a84e19fb":"'''v_results = lgb.cv(params, d_train, nfold = 5, num_boost_round = 1000, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50, verbose_eval=100)'''","d44a1bf7":"predict = clf.predict(test)","961d0a8b":"def feature_important(model, X , num = 50):\n    feature_import = pd.DataFrame(sorted(zip(model.feature_importance(), X.columns)), columns = ['values', 'columns'])\n    plt.figure(figsize = (12,15))\n    sns.barplot(x = 'values', y = 'columns', data = feature_import.sort_values(by = 'values', ascending = False)[:num])\n    plt.show()\n    \nfeature_important(clf, train)","a9e5c6e6":"submitss = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv')","d18bc913":"submission = pd.DataFrame({\n        \"TransactionID\": submitss['TransactionID'],\n        \"isFraud\": predict\n    })\n\nsubmission.TransactionID = submission.TransactionID.astype(int)\n\nsubmission.to_csv(\"submit.csv\", index=False)","d71a0c90":"> THIS IS A BEAUTIFUL CLASS IMBALANCE PROBLEM","4cbbc9a4":"> MISSING VALUE COUNT","92022118":"> 1. FROM THE ABOVE PLOTS WE CAN SEE THE  MOST USED PLATFORMS AND THEIR FRAUD EXPECTANCY\n> 2. WE CAN SEE THAT MOST AND LEAST FRAUD CAUSING PLATFORMS ARE SAME THIS IS JUST BECAUSE OF THEIR HUGE POPULARITY","43e5d3a8":"# Handling Missing Values And Encoding Necessary Columns","6a688613":"> FROM THIS WE CAN SEE THAT IT MIGHT BE EASIER TO SCAM THE DEBIT CARD USERS","465e9299":"# Modelling the Dataset","a36563c9":"# Dataset Loading and Merging","3ca89721":"# VISUALIZATIONS","c27dd8d6":"# Feature Importance","e7512b68":"# Lightgbm Implementation","ea856e2d":"# Bayesian Optimization for Hyperparameter Optimization","97d5ffc6":"> Is Resolution related to Fraud","190a797c":"# MEMORY REDUCATION","0ad6a93d":"> Some Overbiased Columns that might be removed later"}}