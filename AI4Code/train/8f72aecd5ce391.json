{"cell_type":{"f85eb09c":"code","d1cf0b69":"code","41e2bc31":"code","6ad214dc":"code","4ec1d3e0":"code","7394a456":"code","5518a85e":"code","47195855":"code","3f8ce1b3":"code","6d1d3345":"code","28a0fe38":"code","2b2c0b8c":"code","74aac344":"code","f8781883":"code","d6a3c88b":"code","ddef8df2":"code","3ae4a98d":"code","de78b3d8":"code","282bce8e":"code","74bd0452":"code","04ca4e94":"code","b490c272":"code","abaf7d68":"code","ea5f75e9":"code","e1696026":"code","259b22af":"code","8009078c":"code","12e4e4d0":"code","47e62087":"code","87869070":"code","7e378039":"code","e097c9f5":"code","bb6bcf04":"code","2d32dbaa":"code","6d561292":"code","8834b5cc":"code","497a0a52":"code","0aa078f3":"code","0ca43115":"code","74c54356":"code","32e71ac2":"code","ca641138":"code","0184a0c0":"code","4db1951b":"code","7422157d":"code","501d79c0":"code","96fc2f5e":"code","41ac07c6":"code","aff7a42b":"code","4695c2d4":"code","85969c4d":"code","d81f9072":"code","8ca84d91":"code","f5257668":"code","3c873eb4":"code","21d38620":"code","865b9018":"code","ff50281b":"code","ddcc7309":"code","63d403ef":"code","1327852c":"code","5f8bc0fb":"code","2aa3cba3":"code","7ca346b9":"code","ad8edda0":"code","01e1a39e":"code","92884652":"code","51967d2e":"code","1a881d87":"code","3f256ff5":"code","5951d303":"code","94e4c02d":"code","503a4e39":"code","2f8cf7d5":"code","620f21e1":"code","4c1c339c":"code","9cb06307":"code","4ecc7c5d":"code","fb32eef1":"code","aba14c34":"code","5306939d":"markdown","89224bdb":"markdown","0544eacd":"markdown","a869f664":"markdown","24351c29":"markdown","eb75aa4e":"markdown","1e14a486":"markdown","a8dc2810":"markdown","e0d2344d":"markdown","fad6ac00":"markdown","abed32cb":"markdown","dbe8ee24":"markdown","0e149653":"markdown","861f1c1e":"markdown","73f7874b":"markdown","8593d62d":"markdown","eb4372c2":"markdown","17a318ae":"markdown","a83b98fd":"markdown","fb80d352":"markdown","9c30f877":"markdown","e0834480":"markdown","a0a3f078":"markdown","0b3ff7ba":"markdown","d8c8b6e5":"markdown","6e242fb6":"markdown","5af0c755":"markdown","da981f7a":"markdown","b994c3ec":"markdown","26c41a68":"markdown","8ab05206":"markdown","7ea44d2f":"markdown","5ab9dc18":"markdown","36b6ce93":"markdown","a34c7f18":"markdown","ffe82858":"markdown","3ec6f69d":"markdown","9aa3bf0d":"markdown","3d9cbf35":"markdown","acfa3b74":"markdown","a23b1df7":"markdown","63f64a68":"markdown","5193b060":"markdown","ab5dfae0":"markdown","8a6ccf1b":"markdown","32413388":"markdown","07bd61ab":"markdown","1ee2cc60":"markdown","f5e15162":"markdown","53b83a7e":"markdown","c0bc7053":"markdown","c5d965a5":"markdown","566f0ad5":"markdown","8917a6a6":"markdown"},"source":{"f85eb09c":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set()","d1cf0b69":"data_path = '..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv'","41e2bc31":"raw_csv_data = pd.read_csv(data_path)\nraw_csv_data","6ad214dc":"df_comp = raw_csv_data.copy()","4ec1d3e0":"df_comp.isna().sum()","7394a456":"df_comp.fillna(df_comp['salary'].mean(), inplace = True)","5518a85e":"del df_comp['sl_no']","47195855":"df_comp","3f8ce1b3":"sns.countplot(df_comp.status)","6d1d3345":"sns.pairplot(df_comp)","28a0fe38":"cor = df_comp.loc[:,[\"hsc_p\",\"ssc_p\",'etest_p',\"salary\"]]\nsns.clustermap(cor.corr(), center=0, cmap=\"vlag\",\n               linewidths=.75, figsize=(10, 5))","2b2c0b8c":"!pip install bubbly\n!pip install chart_studio","74aac344":"df_comp_bp = df_comp.head(30)\nfrom bubbly.bubbly import bubbleplot \nfrom plotly.offline import iplot\nimport chart_studio.plotly as py\n\n\nfigure = bubbleplot(dataset=df_comp_bp, x_column='etest_p', y_column='salary', \n    bubble_column='gender', size_column='salary', color_column='gender', \n    x_logscale=True, scale_bubble=2, height=350)\n\niplot(figure)","f8781883":"df_comp_bp = df_comp.head(30)\nfrom bubbly.bubbly import bubbleplot \nfrom plotly.offline import iplot\nimport chart_studio.plotly as py\n\n\nfigure = bubbleplot(dataset=df_comp_bp, x_column='etest_p', y_column='salary', \n    bubble_column='specialisation', size_column='salary', color_column='specialisation', \n    x_logscale=True, scale_bubble=2, height=350)\n\niplot(figure)","d6a3c88b":"import plotly.express as px","ddef8df2":"df_tree = df_comp.groupby([\"hsc_b\",\"specialisation\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['hsc_b','specialisation'], values='salary',\n                  color='salary', hover_data=['specialisation'],\n                  color_continuous_scale='rainbow')\nfig.show()","3ae4a98d":"df_tree = df_comp.groupby([\"workex\",\"degree_t\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['workex','degree_t'], values='salary',\n                  color='salary', hover_data=['degree_t'],\n                  color_continuous_scale='rainbow')\nfig.show()","de78b3d8":"df_tree_1 = df_comp.copy()\ndf_tree_1['status'] = df_tree_1['status'].map({'Placed':1, 'Not Placed':0})","282bce8e":"df_tree = df_tree_1.groupby([\"gender\",\"degree_t\"])[[\"etest_p\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['gender','degree_t'], values='etest_p',\n                  color='etest_p', hover_data=['degree_t'],\n                  color_continuous_scale='rainbow')\nfig.show()","74bd0452":"df_pie = df_comp.groupby([\"gender\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.pie(df_pie,\n             values=\"salary\",\n             names=\"gender\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","04ca4e94":"fig = px.histogram(df_comp, x=\"degree_p\", y=\"status\", color=\"gender\")\nfig.show()","b490c272":"fig = px.scatter(df_comp, x=\"degree_p\", y=\"salary\", trendline=\"ols\")\nfig.show()","abaf7d68":"fig = px.scatter(df_comp, x=\"etest_p\", y=\"salary\", trendline=\"ols\")\nfig.show()","ea5f75e9":"plt.figure(figsize=(10,6))\nax = sns.violinplot(x=\"degree_t\", y=\"salary\", hue=\"specialisation\",\n                    data=df_comp, palette=\"muted\")","e1696026":"ax = sns.swarmplot(x=\"gender\", y=\"salary\", data= df_comp)","259b22af":"ax = sns.swarmplot(x=\"workex\", y=\"salary\", data=df_comp)","8009078c":"df = df_comp.copy()","12e4e4d0":"import statsmodels.api as sm\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nstats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)","47e62087":"df_log = df.copy()","87869070":"df['hsc_b'].unique()","7e378039":"df_log.ssc_b = df_log['ssc_b'].map({'Others':1, 'Central':0})\ndf_log.hsc_b = df_log['hsc_b'].map({'Others':1, 'Central':0})\ndf_log.hsc_s = df_log['hsc_s'].map({'Arts':2, 'Commerce':1, 'Science':0})\ndf_log.degree_t = df_log['degree_t'].map({'Others':2, 'Comm&Mgmt':1, 'Sci&Tech':0})\ndf_log.workex =  df_log['workex'].map({'Yes':1, 'No':0})\ndf_log.specalisation = df_log['specialisation'].map({'Mkt&HR':1, 'Mkt&Fin':0})\ndf_log.status = df_log['status'].map({'Placed':1, 'Not Placed':0})\ndf_log.gender = df_log['gender'].map({'F':1,'M':0})","e097c9f5":"df_log.info()","bb6bcf04":"df_log","2d32dbaa":"inputs = df_log[['ssc_p', 'hsc_p', 'degree_p','workex', 'etest_p', 'mba_p']]\ntargets = df_log['status']","6d561292":"x_train,x_test,y_train,y_test = train_test_split(inputs, targets, test_size = 0.2, random_state = 365)","8834b5cc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","497a0a52":"logreg = LogisticRegression()\nresults_log = logreg.fit(x_train,y_train)","0aa078f3":"y_pred=logreg.predict(x_test)","0ca43115":"cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","74c54356":"class_names = [0,1]\nfig, ax = plt.subplots()\ntick_marks = np.arange(1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"mako\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.1, size = 24)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","32e71ac2":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","ca641138":"y_pred_proba = logreg.predict_proba(x_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","0184a0c0":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(x_train, y_train);","4db1951b":"pred = model.predict(x_test)","7422157d":"acc = model.score(x_test,y_test)\nprint(\"Accuracy = \" + str((acc*100).round(3))+\"%\")","501d79c0":"from sklearn.ensemble import RandomForestClassifier","96fc2f5e":"model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nmodel.fit(x_train,y_train)","41ac07c6":"y_pred = model.predict(x_test)","aff7a42b":"from sklearn.metrics import confusion_matrix","4695c2d4":"cm = confusion_matrix(y_test,y_pred)\ncm","85969c4d":"class_names = [0,1]\nfig, ax = plt.subplots()\ntick_marks = np.arange(1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"mako\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.1, size = 24)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","d81f9072":"print(\"Accuracy = \"+ str(((model.score(x_test,y_test))*100).round(3))+\"%\")","8ca84d91":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report","f5257668":"rfc_cv_score = cross_val_score(model, x_test, y_test, cv=10, scoring='roc_auc')","3c873eb4":"print(\"=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))\nprint('\\n')\nprint(\"=== All AUC Scores ===\")\nprint(rfc_cv_score)\nprint('\\n')\nprint(\"=== Mean AUC Score ===\")\nprint(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())","21d38620":"from sklearn.metrics import plot_roc_curve","865b9018":"rfc_ROC_disp = plot_roc_curve(model, x_test, y_test)\nplt.show()","ff50281b":"from sklearn import svm","ddcc7309":"#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(x_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(x_test)","63d403ef":"print(\"Accuracy:\",str(((metrics.accuracy_score(y_test, y_pred))*100).round(3)) + \"%\")","1327852c":"# Model Precision: what percentage of positive tuples are labeled as such?\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\n\n# Model Recall: what percentage of positive tuples are labelled as such?\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","5f8bc0fb":"#import numpy as np\nimport tensorflow as tf\nfrom sklearn import preprocessing","2aa3cba3":"unscaled_inputs_all = df[['ssc_p','hsc_p','degree_p','etest_p','mba_p']]\ntargets_all = df_log['status']","7ca346b9":"num_one_targets = int(np.sum(targets_all))\nzero_targets_counter = 0\nindices_to_remove = []","ad8edda0":"for i in range(targets_all.shape[0]):\n    if targets_all[i] == 0:\n        zero_targets_counter +=1\n        if zero_targets_counter > num_one_targets:\n            indices_to_remove.append(i)\n\nunscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n\ntargets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)","01e1a39e":"scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)","92884652":"shuffled_indices = np.arange(scaled_inputs.shape[0])\nnp.random.shuffle(shuffled_indices)","51967d2e":"shuffled_inputs = scaled_inputs[shuffled_indices]\nshuffled_targets = targets_all[shuffled_indices]","1a881d87":"samples_count = shuffled_inputs.shape[0]","3f256ff5":"train_samples_count = int(0.8 * samples_count)\nvalidation_samples_count = int(0.8 * samples_count)\ntest_samples_count = samples_count - train_samples_count - validation_samples_count","5951d303":"train_inputs = shuffled_inputs[:train_samples_count]\ntrain_targets = shuffled_targets[:train_samples_count]\n\nvalidation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\nvalidation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n\ntest_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\ntest_targets = shuffled_targets[train_samples_count + validation_samples_count:]","94e4c02d":"np.savez('placement_train_data', inputs = train_inputs, targets = train_targets)\nnp.savez('placement_validation_data', inputs = validation_inputs, targets = validation_targets)\nnp.savez('placement_test_data', inputs = test_inputs, targets = test_targets)","503a4e39":"npz = np.load('\/kaggle\/working\/placement_train_data.npz')\ntrain_inputs, train_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n\nnpz = np.load('\/kaggle\/working\/placement_validation_data.npz')\nvalidation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n\nnpz = np.load('\/kaggle\/working\/placement_test_data.npz')\ntest_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n","2f8cf7d5":"input_size = 5\noutput_size = 2\n\nhidden_layer_size = 55","620f21e1":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='softmax')\n])\n\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n\nbatch_size = 55\nmax_epochs = 100","4c1c339c":"early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)","9cb06307":"history = model.fit(train_inputs, train_targets,\n         batch_size = batch_size,\n         epochs= max_epochs,\n         callbacks = [early_stopping],\n         validation_data = (validation_inputs, validation_targets),\n         verbose = 1)","4ecc7c5d":"model.save_weights(\"model.h5\")","fb32eef1":"plt.plot(history.history['loss'], color = 'red', label = 'Training Loss')\nplt.plot(history.history['val_loss'], color = 'blue', label = 'Validation Loss')\nplt.legend()\nplt.show()\n","aba14c34":"plt.plot(history.history['accuracy'], color = 'red', label = 'Training Accuracy')\nplt.plot(history.history['val_accuracy'], color = 'blue', label = 'Validation Accuracy')\nplt.legend()\nplt.show()","5306939d":"# Support Vector Machine Classifier","89224bdb":"### Shuffling the Data","0544eacd":"### Balancing the Dataset","a869f664":"### Splitting the Data into Training, Validation and Testing Set","24351c29":"### Confusion Matrix","eb75aa4e":"#### Early Stopping","1e14a486":"### Standardizing the Inputs","a8dc2810":"## Gender + Employability Test % v\/s Salary","e0d2344d":"## Gender + Undergraduate Degree v\/s Employability Test %","fad6ac00":"### Confusion Martix\n### [True Positive, False Negative]\n### [False Positive, True Negative]\n\n#### There is also a list of rates that are often computed from a confusion matrix for a binary classifier:\n#### Accuracy: Overall, how often is the classifier correct?\n#### Accuracy = (TP+TN)\/total\n#### Misclassification Rate(Error Rate): Overall, how often is it wrong?\n#### Misclassification Rate = (FP+FN)\/total\n#### True Positive Rate(Sensitivity or Recall): When it\u2019s actually yes, how often does it predict yes?\n#### True Positive Rate = TP\/actual yes\n#### False Positive Rate: When it\u2019s actually no, how often does it predict yes?\n#### False Positive Rate=FP\/actual no\n#### True Negative Rate(Specificity): When it\u2019s actually no, how often does it predict no?\n#### True Negative Rate=TN\/actual no\n#### Precision: When it predicts yes, how often is it correct?\n#### Precision=TP\/predicted yes\n#### Prevalence: How often does the yes condition actually occur in our sample?\n#### Prevalence=actual yes\/total","abed32cb":"## Validating Performance of Random Forest Model","dbe8ee24":"##  Bubble Plot","0e149653":"# Deep Neural Network(DNN) for Predicting Placement Status","861f1c1e":"## Gender v\/s Salary","73f7874b":"### Visualising Training","8593d62d":"## Gender v\/s Salary","eb4372c2":"## Degree% v\/s Salary","17a318ae":"# Loading the Data","a83b98fd":"## Pairplot","fb80d352":"# Importing Relevant Libraries","9c30f877":"# Hence, We see that the DNN Model is the best perfroming model with 95.35% Validation Accuracy","e0834480":"## Trendline","a0a3f078":"### Preparing Data for Logistic Regression","0b3ff7ba":"## Correlation between Salary, Employability Test %, Secondary Education % and Higher Secondary Education %","d8c8b6e5":"## Specialisation + Employability Test v\/s Salary","6e242fb6":"## The Model","5af0c755":"## TreeChart","da981f7a":"## Specialization v\/s Salary","b994c3ec":"# Problem Statement\n**To predict whether or not a candidate will be placed(or employed) on the basis of his\/her Secondary %, Higher Secondary %, Undergraduate Degree %, MBA % and Employability Test %**","26c41a68":"## The Regression","8ab05206":"## Histogram","7ea44d2f":"### Saving the DataFrames in .npz format","5ab9dc18":"# Exploratory Data Analysis","36b6ce93":"## Pie Chart","a34c7f18":"## Outlining the DNN Model","ffe82858":"## Swarm Plot","3ec6f69d":"### ROC Curve\n#### Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate(Recall) against the false positive rate. It shows the tradeoff between sensitivity and specificity.\n#### AUC(Area Under Curve) score for the case is 0.96. AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier.","9aa3bf0d":"## Work Experience v\/s Salary","3d9cbf35":"# Random Forest Classifier","acfa3b74":"# Introduction  \n## About the Dataset\nThis data set consists of Placement data of students in Jain University, Bangalore. It includes secondary and higher secondary school percentage and specialization. It also includes degree specialization, type and Work experience and salary offers to the placed students","a23b1df7":"# The Methodology\n1. **Loading and Cleaning + Preprocessing the Data**\n2. **Exploratory Data Analysis(EDA)**\n    * Pairplot\n    * Clustermap to Visualize Correlation\n    * Bubble Plot(s)\n    * Tree Chart\n    * Pie Chart\n    * Histogram\n    * Trendline\n    * Violin Plot\n    * Swarm Plot\n3. **Predictive Modelling**\n    * Logistic Regression\n    * Naive Bayes Classifier\n    * Random Forest Classifier\n    * Support Vector Machine(SVM) Classifier\n    * Deep Neural Network(DNN)\n","63f64a68":"# Logistic Regression","5193b060":"#### Dropping sl_no as it is an insignificant feature","ab5dfae0":"### Loading the .npz files","8a6ccf1b":"#### Fitting the Data to the Model","32413388":"## Gender + Degree% v\/s Count of Status(# placed\/not-placed)","07bd61ab":"## Kindly upvote if you found this notebook useful! Thank you!","1ee2cc60":"### Splitting the Data into Training and Testing Data with an 80:20 Split","f5e15162":"## Violin Plot","53b83a7e":"### ROC (Receiver Operating Charateristic) Curve","c0bc7053":"## Employability Test % v\/s Salary","c5d965a5":"# Preprocessing the Data","566f0ad5":"## Work Experience + Undergraduate Degree v\/s Salary","8917a6a6":"# Naive Bayes Classification"}}