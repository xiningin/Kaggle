{"cell_type":{"d6f36b6b":"code","c50904a8":"code","84b8ac0a":"code","cd0d4547":"code","80bb2c95":"code","1042ac24":"code","d802d5b1":"code","3ae13f72":"code","fbbe0d58":"code","68f5b039":"code","0374e1df":"code","30984c66":"code","0d2f10f8":"code","8e8e46b0":"code","332a39a4":"code","67da80b3":"code","afc2ad32":"code","174084db":"code","ec646799":"code","110cfb01":"code","ec1a51bf":"code","f6ff2f75":"code","f196e4b1":"code","b9f8ed35":"code","0ec81064":"code","bf25b7cf":"code","6f3fe211":"code","0efe9495":"code","4f245f68":"code","6bc22122":"code","9ce1f33d":"code","b3b065e6":"code","83d17700":"code","15800f63":"code","145772bb":"code","a8489a81":"code","a90bc1c7":"code","c088d6f7":"code","4d78ae98":"code","617ba47f":"code","4d976236":"code","e332a136":"code","2712f260":"code","95b7ef5f":"code","2a405316":"markdown","b00227ca":"markdown","6d295f63":"markdown","3751a75f":"markdown","b2bc4858":"markdown","92ad3ff3":"markdown","6a33400f":"markdown","30406d56":"markdown","71a91edd":"markdown","cbe23152":"markdown","9c0138b3":"markdown","ca80f262":"markdown","235894a0":"markdown","7855ed67":"markdown","32f6c32a":"markdown","45ed1649":"markdown","19706596":"markdown","0c6fdd21":"markdown","232bf7f4":"markdown","28d45495":"markdown","bb168436":"markdown"},"source":{"d6f36b6b":"# Importing basic necessary libraries before starting\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n#from pandas_profiling import ProfileReport\nimport glob\n\n# Sweetviz library is advanced statistical and visualization summary libraries which is near-similar to pandas profiling, it's exciting\n!pip install sweetviz\nimport sweetviz as sv","c50904a8":"# Let's have a look at the training dataset\ntrain = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","84b8ac0a":"# Let's have comprehensive look at the booking data through sweetviz library\nprofile = sv.analyze(train)\nprofile.show_notebook()","cd0d4547":"# Quick look at the unique values in each of the columns\nfor i in train.columns:\n    print(\"There are\", len(train[i].unique()), \"unique values in\", i, \"column\")","80bb2c95":"# Let's look at the train data statistically\nprint(\"Here is some statistical analysis of the train data:\")\nprint(train.describe())\nprint(\"\\n\")\nprint(\"Here are the number of rows and columns in the dataset:\")\nprint(train.shape)","1042ac24":"# On-boarding test data\ntest = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\ntest.head()","d802d5b1":"# Running the sample submission file to understand what are we going to predict\nsample_predict = pd.read_csv(\"..\/input\/optiver-realized-volatility-prediction\/sample_submission.csv\")\nsample_predict.head()","3ae13f72":"# Time to look at the book train data (including all the stock_ids)\nbook_train = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\nprint(\"Here are top few records in book data:\")\nprint(\"---------------------------------------\")\nprint(book_train.head())\nprint(\"\\n\")\nprint(\"Here are last few rows in book data:\")\nprint(\"---------------------------------------\")\nprint(book_train.tail())\nprint(\"\\n\")\nprint(\"Let's also look at few random rows in the data:\")\nprint(\"---------------------------------------\")\nprint(book_train.sample(n=5))","fbbe0d58":"# Let's look at the shape of the book_train data\nbook_train.shape","68f5b039":"# Let's have comprehensive look at the booking data through sweetviz library\nbook_report = sv.analyze(book_train)\nbook_report.show_notebook()","0374e1df":"# On-boarding the book_test data\nbook_test_main =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_test.parquet')\nbook_test_main.head()","30984c66":"# Let's have comprehensive look at the book_test data through sweetviz library\nbook_test_report = sv.analyze(book_test_main)\nbook_test_report.show_notebook()","0d2f10f8":"# Let's also have a look at the trade_train parquet file only for stock_id =0 because of the volume of the data.\ntrade_train =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0')\ntrade_train.head()","8e8e46b0":"# Looking at the shape of the trade_train as well just to confirm\ntrade_train.shape","332a39a4":"# Let's have a comprehensive look at the trade data through sweetviz\ntrade_profile = sv.analyze(trade_train)\ntrade_profile.show_notebook()","67da80b3":"# On-boarding Trade_Test data\ntrade_test_main =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_test.parquet')\ntrade_test_main.head()","afc2ad32":"# Let's have a comprehensive look at the trade_test data through sweetviz\ntrade_test_profile = sv.analyze(trade_test_main)\ntrade_test_profile.show_notebook()","174084db":"# Thanks Chumajin for this code and next line (I had a same approach)\nbook_test = book_train[book_train[\"time_id\"]==5]\nbook_test.head()","ec646799":"samples = [\"bid_price1\",\"bid_price2\",\"ask_price1\",\"ask_price2\"]\n\nfor num,a in enumerate(samples):\n    plt.figure(figsize=(20,5))\n   \n    plt.subplot(4,1,num+1)\n    plt.plot(book_test[\"seconds_in_bucket\"],book_test[a])\n    plt.title(a)\nplt.show()\nplt.figure(figsize=(20,5))\n\nfor num,a in enumerate(samples):\n    \n   \n    plt.plot(book_test[\"seconds_in_bucket\"],book_test[a],label=a)\nplt.legend(fontsize=12)","110cfb01":"trade_test = trade_train[trade_train[\"time_id\"]==5]\ntrade_test.head()","ec1a51bf":"# Adding actual trade line to the above graph to understand the fluctuations and how transactions happened\nplt.figure(figsize=(20,5))\n\nfor num,a in enumerate(samples):\n    \n   \n    plt.plot(book_test[\"seconds_in_bucket\"],book_test[a],label=a)\n    \nplt.plot(trade_test[\"seconds_in_bucket\"],trade_test[\"price\"],label=\"trade_parquet\",lw=4)\nplt.legend(fontsize=12)","f6ff2f75":"# Importing necessary libraries\nfrom sklearn.metrics import r2_score\nimport os\nimport glob\nfrom tqdm import tqdm","f196e4b1":"# Exploring more opportunity to understand the gaps between big and ask price\nplt.plot(book_train['bid_price1'], c = 'blue', label = 'Bid Price')\nplt.plot(book_train['ask_price1'], c = 'red', label = 'Ask Price', alpha=0.7)\nplt.title('Analysis of Best Bid Price and Best Ask Price')\nplt.xlabel('Time ID')\nplt.ylabel('Price')\nplt.legend()\nplt.show()","b9f8ed35":"# Exploring more opportunity to understand the gaps between big and ask price on Level 2\nplt.plot(book_train['bid_price2'], c = 'blue', label = 'Bid Price')\nplt.plot(book_train['ask_price2'], c = 'red', label = 'Ask Price', alpha=0.7)\nplt.title('L2 Analysis of Best Bid Price and Best Ask Price')\nplt.xlabel('Time ID')\nplt.ylabel('Price')\nplt.legend()\nplt.show()","0ec81064":"plt.hist(book_train['bid_price1'], bins='auto', label='Best Bids')\nplt.hist(book_train['bid_price2'], bins='auto', label='L2 Bids', alpha=0.7)\nplt.title('Bids on Stock 0 Distribution')\nplt.xlabel('Time ID')\nplt.ylabel('Bid Value')\nplt.legend()\nplt.show()","bf25b7cf":"plt.hist(book_train['bid_price1'], bins='auto', label='Best Bids')\nplt.hist(book_train['bid_price2'], bins='auto', label='L2 Bids', alpha=0.7)\nplt.title('Bids on Stock 0 Distribution')\nplt.xlabel('Time ID')\nplt.ylabel('Bid Value')\nplt.yscale('log')\nplt.legend()\nplt.show()","6f3fe211":"plt.hist(book_train['ask_price1'], bins='auto', label='Best Ask')\nplt.hist(book_train['ask_price2'], bins='auto', label='L2 Ask', alpha=0.7)\nplt.title('Asks on Stock 0 Distribution')\nplt.xlabel('Time ID')\nplt.ylabel('Ask Value')\nplt.legend()\nplt.show()","0efe9495":"plt.hist(book_train['ask_price1'], bins='auto', label='Best Ask')\nplt.hist(book_train['ask_price2'], bins='auto', label='L2 Ask', alpha=0.7)\nplt.title('Asks on Stock 0 Distribution')\nplt.xlabel('Time ID')\nplt.ylabel('Ask Value')\nplt.yscale('log')\nplt.legend()\nplt.show()","4f245f68":"# Calculating log return\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() ","6bc22122":"# Calculating Weighted Average Price for entire Dataset (with stock_id=0)\nbook_train['wap'] = (book_train['bid_price1'] * book_train['ask_size1'] +\n                                book_train['ask_price1'] * book_train['bid_size1']) \/ (\n                                       book_train['bid_size1']+ book_train['ask_size1'])\n\nbook_train.loc[:,'log_return'] = log_return(book_train['wap'])\nbook_train = book_train[~book_train['log_return'].isnull()]\n\nbook_train.head()","9ce1f33d":"# Calculating realized volatility\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\nrealized_vol = realized_volatility(book_train['log_return'])\nprint(f'Realized volatility for the taken sample data with time_id 05 & stock_id 0 is {realized_vol}')","b3b065e6":"stock_0 = train[train['stock_id']==0]\nmin_index = stock_0['target'].idxmin()\nmin_time_id = stock_0.iloc[min_index]['time_id']\nprint(\"min index is\",min_time_id,\"min target is\",stock_0.iloc[min_index][\"target\"])","83d17700":"book_test_min = book_train[book_train[\"time_id\"]==min_time_id]\ntrade_test_min = trade_train[trade_train[\"time_id\"]==min_time_id]\n\n\nplt.figure(figsize=(20,5))\n\nfor num,a in enumerate(samples):\n    \n   \n    plt.plot(book_test_min[\"seconds_in_bucket\"],book_test_min[a],label=a)\n    \nplt.plot(trade_test_min[\"seconds_in_bucket\"],trade_test_min[\"price\"],label=\"trade_parquet\",lw=4)\nplt.legend(fontsize=12)","15800f63":"stock_0 = train[train[\"stock_id\"]==0]\nmax_index = stock_0[\"target\"].idxmax()\nmax_time_id = stock_0.iloc[max_index][\"time_id\"]\nprint(\"max index is\",max_time_id,\"max target is\",stock_0.iloc[max_index][\"target\"])","145772bb":"book_test_max = book_train[book_train[\"time_id\"]==max_time_id]\ntrade_test_max = trade_train[trade_train[\"time_id\"]==max_time_id]\n\n\nplt.figure(figsize=(20,5))\n\nfor num,a in enumerate(samples):\n    \n   \n    plt.plot(book_test_max[\"seconds_in_bucket\"],book_test_max[a],label=a)\n    \nplt.plot(trade_test_max[\"seconds_in_bucket\"],trade_test_max[\"price\"],label=\"trade_parquet\",lw=5)\nplt.legend(fontsize=12)","a8489a81":"plt.figure(figsize=(20,5))\nplt.plot(trade_test_min[\"seconds_in_bucket\"],trade_test_min[\"price\"],lw=5,label=\"minimum_volatility_time\")\nplt.plot(trade_test_max[\"seconds_in_bucket\"],trade_test_max[\"price\"],lw=5,label = \"maximum_volatility_time\")\nplt.legend(fontsize=15)","a90bc1c7":"stock = train.groupby(\"stock_id\")[\"target\"].agg([\"mean\",\"median\",\"std\",\"count\",\"sum\"]).reset_index()\nstock.head()","c088d6f7":"stock2 = stock[[\"stock_id\",\"median\"]]\nstock2 = stock2.set_index(\"stock_id\")\nstock2","4d78ae98":"stock_dict = stock2.to_dict()\n\n# example : stock id = 0 median median value\nstock_dict[\"median\"][0]","617ba47f":"sample_predict","4d976236":"sample_predict[\"stock_id\"] = [s.split(\"-\")[0] for s in sample_predict[\"row_id\"]]\nsample_predict","e332a136":"sample_predict[\"target\"] = [stock_dict[\"median\"][int(s)] for s in sample_predict[\"stock_id\"]]\nsample_predict","2712f260":"# Deleting the stock ID\nsample_predict = sample_predict.drop(\"stock_id\",axis=1)\nsample_predict","95b7ef5f":"sample_predict.to_csv(\"submission.csv\",index=False)","2a405316":"Thanks [Chumajin](http:\/\/www.kaggle.com\/chumajin\/optiver-realized-eda-for-starter-english-version) for below line of code","b00227ca":"## Diving Deeper into Analysis and Prediction","6d295f63":"Visualizing the highest volatility of stock_id 0","3751a75f":"We have a glance that bid and ask price are not in the gaussian shape, let's dive further \\\nlet's dive little more deeper.","b2bc4858":"#### Purple line above is the actual transaction (trade) that was executed.","92ad3ff3":"### Compute Statistics for Orderbook","6a33400f":"#### Looking at the data for which trade has been actually executed (either bought or sold)","30406d56":"#### Now let's see the comparison on the price when the it was in the bucket and the price when the trade was actually executed","71a91edd":"#### Looking at the Weighted Average Price for Stock ID 0 and Time ID 5\\\nThanks [Jiashen](https:\/\/www.kaggle.com\/jiashenliu\/introduction-to-financial-concepts-and-data)","cbe23152":"#### Looking at the data for the orders entered into the market (not necessarily executed)","9c0138b3":"#### Little more comprehensive visualization","ca80f262":"### Submission file","235894a0":"#### Looking at the price fluctuations (Individual & whole) when trade was in the blucket","7855ed67":"# Optiver Realized Volatility Prediction","32f6c32a":"Please upvote if you liked the work!","45ed1649":"Price of a stock fluctuates considerably when the volatility is high and vis-a-versa.","19706596":"Creating a dictionary of median values for each stock","0c6fdd21":"Thanks [Chumajin](http:\/\/www.kaggle.com\/chumajin\/optiver-realized-eda-for-starter-english-version) for below line of code","232bf7f4":"As the scale of vertical axis is different, comparing the actual transactions","28d45495":"### Getting to understand the volatility further\nThanks [Chumajin](https:\/\/www.kaggle.com\/chumajin\/optiver-realized-eda-for-starter-english-version)","bb168436":"### Thanks for exploring full notebook!"}}