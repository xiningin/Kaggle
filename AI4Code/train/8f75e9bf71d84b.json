{"cell_type":{"7204516e":"code","07eed7aa":"code","cccf5b5d":"code","9a500f40":"code","a6f7c53a":"code","251d030f":"code","76d30e0e":"code","bc3c384d":"code","b1b0e874":"code","522268c8":"code","9c08f802":"code","45a5fd11":"code","07d8c736":"code","545bae46":"code","993a4077":"code","7c4f6edd":"code","1b0641d3":"code","5ac055f1":"code","94ebca2e":"code","12f91806":"code","f7787864":"code","15d0ed8a":"code","bdead53e":"markdown","7da1a422":"markdown","a2a808c6":"markdown","30fc8720":"markdown","3a68c46c":"markdown","8a67ec77":"markdown","f828fb9f":"markdown","e60cb35b":"markdown","7ebecdf0":"markdown"},"source":{"7204516e":"import os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","07eed7aa":"df=pd.read_csv('\/kaggle\/input\/fer2013\/fer2013.csv')","cccf5b5d":"df.Usage.value_counts() ","9a500f40":"\ngroups = [i for _, i in df.groupby('Usage')]\ntraining_data = groups[2]\nvalidation_data = groups[1]\ntesting_data = groups[0]","a6f7c53a":"training_data.head()","251d030f":"validation_data.head()","76d30e0e":"testing_data.head()","bc3c384d":"training_data.emotion.value_counts()","b1b0e874":"validation_data.emotion.value_counts()","522268c8":"testing_data.emotion.value_counts()","9c08f802":"\nnum_classes = 7\nwidth = 48\nheight = 48\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nclasses=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))\n\n","45a5fd11":"X_train = np.array(list(map(str.split, training_data.pixels)), np.float32) \nX_val = np.array(list(map(str.split, validation_data.pixels)), np.float32) \nX_test = np.array(list(map(str.split, testing_data.pixels)), np.float32) \nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \nX_val = X_val.reshape(X_val.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","07d8c736":"X_train.shape","545bae46":"\nfrom keras.utils import np_utils\ny_train = training_data.emotion \ny_train = np_utils.to_categorical(y_train, num_classes) \ny_val = validation_data.emotion \ny_val = np_utils.to_categorical(y_val, num_classes) \ny_test = testing_data.emotion \ny_test = np_utils.to_categorical(y_test, num_classes) \n","993a4077":"df.info()","7c4f6edd":"def fer2013_show_instance(index):\n    \"\"\"Shows the image and the emotion label of the index's instance.\"\"\"\n    image = np.reshape(training_data.at[index, \"pixels\"].split(\" \"), (width, height)).astype(\"float\")\n    image -= np.mean(image)\n    image \/= np.std(image)\n    print(emotion_labels[training_data.at[index, \"emotion\"]])\n    plt.imshow(image, cmap=\"gray\")","1b0641d3":"fer2013_show_instance(np.random.randint(90,len(training_data)))","5ac055f1":"def fer2013_to_X():\n   \n    \n    X = []\n    pixels_list = training_data[\"pixels\"].values\n    \n    for pixels in pixels_list:\n        single_image = np.reshape(pixels.split(\" \"), (width, height)).astype(\"float\")\n        X.append(single_image)\n        \n    # Convert list to 4D array:\n    X = np.expand_dims(np.array(X), -1)\n    \n    # Normalize image data:\n    X -= np.mean(X, axis=0)\n    X \/= np.std(X, axis=0)\n    \n    return X","94ebca2e":"X = fer2013_to_X()\nX.shape","12f91806":"y = pd.get_dummies(training_data['emotion']).values\ny.shape","f7787864":"training_data.describe()","15d0ed8a":"training_data.hist(bins=20, figsize=(15,15), color='b')\nplt.show()","bdead53e":"* Importing the Dataset","7da1a422":"* Splitting the dataset into Train, Validation, Test Datsets","a2a808c6":"# Feature Extraction \n* Converting dataframes into respective arrays... \n","30fc8720":"# Data Visualization","3a68c46c":"* Count of the images in train, validation and test datasets","8a67ec77":"* Normalizing the Dataset","f828fb9f":"* link to Dataset\n[https:\/\/www.kaggle.com\/deadskull7\/fer2013](http:\/\/)","e60cb35b":"* Data Description","7ebecdf0":"* Here we have huge number of images in class 3 and followed by class 6 and so on.. "}}