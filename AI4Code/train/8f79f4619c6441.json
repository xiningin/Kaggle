{"cell_type":{"37e1f8ee":"code","7ddbedc0":"code","afcde22c":"code","f85cbae1":"code","90417e4a":"code","2c0597c0":"code","1453c396":"code","f3952bda":"code","de8d7afe":"code","25aa0f08":"code","7c90b1dd":"code","e3cd814f":"code","a3745a0b":"code","bf1021f9":"code","4bfe128b":"code","dc631643":"code","db12f669":"code","e5facdee":"code","6ae92a90":"code","aee0769e":"code","07795664":"code","3e3503d3":"code","8cd4fa4e":"code","c224b6e9":"code","19ff9a87":"code","26845855":"code","e5c7cd21":"code","47581f68":"code","cc1e6057":"code","5e522385":"code","7a3bdf3a":"code","1471eadc":"code","4ca680f3":"code","52133a11":"code","9079bf9d":"code","11651ba9":"code","dc70a95b":"code","7117179d":"code","3e247853":"code","a81b70ca":"code","fbb8cbbe":"code","8012b1af":"markdown","495e1d1a":"markdown","cfa10e05":"markdown","1a05fa10":"markdown","9e44614f":"markdown","b13b76b7":"markdown","3e3dba80":"markdown","79ae96f9":"markdown","0b494855":"markdown","85cecbb6":"markdown","55603289":"markdown","4769006b":"markdown","feddd28d":"markdown","c7f5e4f3":"markdown","4efec295":"markdown","85e17139":"markdown","16ceaaa5":"markdown","7398f551":"markdown","75024320":"markdown","05955a69":"markdown","048fae7d":"markdown","e0f126f5":"markdown","bfc13e3a":"markdown","ff38ba61":"markdown","e1b55fe5":"markdown","d592ce87":"markdown","c72e0035":"markdown","3b813b29":"markdown","ae6ef41c":"markdown","ffa70471":"markdown","4b3ec2d3":"markdown","9273c248":"markdown","f42de3f6":"markdown"},"source":{"37e1f8ee":"import pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom glob import glob\n\nimport warnings\nwarnings.filterwarnings('ignore')","7ddbedc0":"# Defining the path for train and test images\ndata_dir_train = pathlib.Path(\"..\/input\/skin-cancer\/Skin cancer ISIC The International Skin Imaging Collaboration\/Train\")\ndata_dir_test = pathlib.Path('..\/input\/skin-cancer\/Skin cancer ISIC The International Skin Imaging Collaboration\/Test')","afcde22c":"image_count_train = len(list(data_dir_train.glob('*\/*.jpg')))\nprint(image_count_train)\nimage_count_test = len(list(data_dir_test.glob('*\/*.jpg')))\nprint(image_count_test)","f85cbae1":"# Define some parameters for the loader:\nbatch_size = 32\nimg_height = 180\nimg_width = 180","90417e4a":"## Write your train dataset here\n## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\ntrain_ds = image_dataset_from_directory(\n    directory=data_dir_train,\n    batch_size=batch_size,\n    image_size=(img_height, img_width),\n    seed=123,\n    validation_split=0.2,\n    subset=\"training\"\n    )\nval_ds = image_dataset_from_directory(\n    directory=data_dir_train,\n    batch_size=batch_size,\n    image_size=(img_height, img_width),\n    seed=123,\n    validation_split=0.2,\n    subset=\"validation\"\n    )","2c0597c0":"# List out all the classes of skin cancer and store them in a list. \n# You can find the class names in the class_names attribute on these datasets. \n# These correspond to the directory names in alphabetical order.\nclass_names = train_ds.class_names\nnum_classes = len(class_names)\nprint(class_names)","1453c396":"len(train_ds)\n","f3952bda":"# creating code to visualize one instance of all the nine classes present in the dataset\nimport matplotlib.pyplot as plt\n    ","de8d7afe":"for images, labels in train_ds:\n    unique_li = []\n    unique_images = []\n    for i in range(32):\n        if class_names[labels[i]] not in unique_li:\n            unique_li.append(class_names[labels[i]])\n            unique_images.append((class_names[labels[i]],images[i]))","25aa0f08":"unique_li","7c90b1dd":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(unique_images[i][1].numpy().astype(\"uint8\"))\n  plt.title(unique_images[i][0])\n  plt.axis(\"off\")","e3cd814f":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","a3745a0b":"labels_batch","bf1021f9":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","4bfe128b":"### Your code goes here\nimg_size = 180\n# Build Normalization layer by rescaling between 0-1, lets also specify input shape with 180x180x3 as we will be using this in all future layers\nnormalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(img_height, img_width, 3))\n# Lets build sequential model with 3 conv layers with 16,32,64 filters, 3 max pooling , then flatten the layer , build a dense layer of 128 and conclude with softmax function layer for output \nmodel = Sequential([\n  normalization_layer,# Normalizing \n  layers.experimental.preprocessing.Resizing(img_size, img_size),# Resizing the image to 180x180\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])","dc631643":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","db12f669":"# View the summary of all layers\nmodel.summary()","e5facdee":"img_size = 180\n# Build Normalization layer by rescaling between 0-1, lets also specify input shape with 180x180x3 as we will be using this in all future layers\nnormalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(img_height, img_width, 3))\n# Lets build sequential model with 3 conv layers with 16,32,64 filters, 3 max pooling , then flatten the layer , build a dense layer of 128 and conclude with softmax function layer for output \nmodel2 = Sequential([\n  normalization_layer,# Normalizing \n  layers.experimental.preprocessing.Resizing(img_size, img_size),# Resizing the image to 180x180\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])","6ae92a90":"model2.compile(optimizer='sgd',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","aee0769e":"# Lets train the model with batch size of 32\nepochs = 20\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  batch_size=32\n)","07795664":"# Lets build a genric function to visualize the accuracy so that it can be used for further evaluation\ndef plot_accuracy(history,epochs):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs_range = range(epochs)\n\n  plt.figure(figsize=(8, 8))\n  plt.subplot(1, 2, 1)\n  plt.plot(epochs_range, acc, label='Training Accuracy')\n  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n  plt.legend(loc='lower right')\n  plt.title('Training and Validation Accuracy')\n\n  plt.subplot(1, 2, 2)\n  plt.plot(epochs_range, loss, label='Training Loss')\n  plt.plot(epochs_range, val_loss, label='Validation Loss')\n  plt.legend(loc='upper right')\n  plt.title('Training and Validation Loss')\n  plt.show()","3e3503d3":"# Lets visualize the vanilla model\nplot_accuracy(history,epochs)","8cd4fa4e":"# Lets store the final accuracy in a dataframe for the consecutive training\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\naccuracy_history_df = pd.DataFrame(data=[{\"Type\":\"Vanilla\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_history_df","c224b6e9":"# Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n# Your code goes here\n# Lets build a layer which performs just the random rotation \ndata_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomRotation(0.2)\n])","19ff9a87":"# Pick one of the image from the unique images list\nimport random\nimage = tf.expand_dims(unique_images[random.randint(0,9)][1], 0)\nplt.imshow(image[0].numpy().astype(\"uint8\"))\nplt.title(\"Original Image\")\nplt.axis(\"off\")","26845855":"# Pass through the data augmentation layers and display the image to visualize how data is getting augmented \naugmented_image = data_augmentation(image)\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n  augmented_image = data_augmentation(image)\n  ax = plt.subplot(4, 4, i + 1)\n  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n  plt.axis(\"off\")","e5c7cd21":"## Your code goes here\nimg_size = 180\n# Build the sequential layers same as before with an extra data augmentation layer\nmodel_augm1 = Sequential([\n  normalization_layer,# Normalizing \n  layers.experimental.preprocessing.Resizing(img_size, img_size),# resizing the layer\n  data_augmentation,\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])","47581f68":"## Your code goes here\nmodel_augm1.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'],\n              )\nmodel_augm1.summary()","cc1e6057":"## Your code goes here, note: train your model for 20 epochs\nepochs = 20\n# Lets the fit the model with batch size of 32 and 20 epochs\nhistory_augm1 = model_augm1.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  batch_size=32\n)","5e522385":"plot_accuracy(history_augm1,epochs)","7a3bdf3a":"# Lets store the accuracy in the DF\nacc = history_augm1.history['accuracy']\nval_acc = history_augm1.history['val_accuracy']\naccuracy_history_df = accuracy_history_df.append([{\"Type\":\"Data Augmentation\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_history_df","1471eadc":"# lets train by adding a dropout of 0.25\nmodel_dropout = Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(img_height, img_width, 3)),# Normalizing \n  layers.experimental.preprocessing.Resizing(img_size, img_size),\n  data_augmentation,\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.25),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])","4ca680f3":"## Your code goes here\nmodel_dropout.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\nmodel_dropout.summary()","52133a11":"## Your code goes here, note: train your model for 20 epochs\nepochs = 20\nhistory_dropout = model_dropout.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  batch_size=32\n)","9079bf9d":"plot_accuracy(history_dropout,epochs)","11651ba9":"# Lets store the accuracy in the DF\nacc = history_dropout.history['accuracy']\nval_acc = history_dropout.history['val_accuracy']\naccuracy_history_df = accuracy_history_df.append([{\"Type\":\"Dropout\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_history_df","dc70a95b":"## Your code goes here.\n# Lets initialize a emtpy dict\nclass_distr={}\n# Go through all training dataset batches\nfor image_batch, labels_batch in train_ds:\n  # prepare the count of images in each class\n    for i in range(image_batch.shape[0]):\n      if class_names[labels_batch[i]] in class_distr:\n        class_distr[class_names[labels_batch[i]]]+=1\n      else:\n        class_distr[class_names[labels_batch[i]]]=1\n# Display the distribution\nclass_distr","7117179d":"# Lets prepare the class distribution Dataframe\ndf_sample_distr = pd.DataFrame({\"Class Name\":class_distr.keys(), \"Samples\":class_distr.values()})\ndf_sample_distr.sort_values('Samples',ascending=False)","3e247853":"# Lets visualize Class Distribution\nimport seaborn as sns\nplt.figure(figsize=(10, 10))\nsns.barplot(data=df_sample_distr,x='Class Name',y='Samples')\nplt.xticks(rotation = 45) \nplt.show()","a81b70ca":"!pip install Augmentor","fbb8cbbe":"# Specify the path to training dataset\npath_to_training_dataset=\"Skin cancer ISIC The International Skin Imaging Collaboration\/Train\/\"\nimport Augmentor\nprint(\"Please hold on for few minutes, as the augmenting takes time\")\n# Augment 1000 images per class to balance the dataset using Augmentor\nfor i in class_names:\n    print(\"Augmenting image for class\",i)\n    p = Augmentor.Pipeline(path_to_training_dataset + i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(1000) ## We are adding 1000 samples per class to make sure that none of the classes are sparse.","8012b1af":"***Use 80% of the images for training, and 20% for validation***","495e1d1a":"***Visualize the data***","cfa10e05":"### **Class Imbalance**","1a05fa10":"**Problem statement:**\n\nTo build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis.","9e44614f":"### *Observation*:\n>We can see that training accuracy has reduced and test accuracy have improved a little are but they are close to each other now.\n\n>but we  see that our model is underfitting as the training accuracy is low.","b13b76b7":"### **Visualizing Class Distribution**","3e3dba80":"### Compiling the model","79ae96f9":"***Train the model***","0b494855":"### Observation:\n\n> We can see that slight rotations are applied to the images using the data augmentation layer with probablity of 0.2","85cecbb6":"#### *Training by adding dropout*\n#### *Lets evaluate model by adding dropout layer of 25%*","55603289":"***Create a dataset***","4769006b":"### *Preparation of class distribution*","feddd28d":"**Compiling the model**","c7f5e4f3":"***Importing all the important libraries***","4efec295":"### **Training the model**","85e17139":"> Vannila Model","16ceaaa5":"### Observation:\n\n>- We can see that accuracy of training and validation did not have much affect after adding dropout layer, although making validation accuracy a bit closer to training.\n>- We see that model is still underfitting.\n>- Lets keep the dropout layer, just to add some regularization layer if there is some overfitting in future.","7398f551":"### Create the model, compile and train the model","75024320":"### **Visualizing the results**","05955a69":"### **Training the model**","048fae7d":"To use `Augmentor`, the following general procedure is followed:\n\n1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n3. Execute these operations by calling the `Pipeline\u2019s` `sample()` method.","e0f126f5":"#### **Todo:** Find the distribution of classes in the training dataset.\n#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data.","bfc13e3a":"> Choosing an appropirate optimiser and loss function for model training","ff38ba61":"### *Visualizing training results*","e1b55fe5":"#### **Todo:** Write your findings here: \n#### - Which class has the least number of samples?\n#### Answer: seborrheic keratosis\n#### - Which classes dominate the data in terms proportionate number of samples?\n#### Answer: pigmented benign keratosis","d592ce87":"### *Observation* :\n\n- The training accuracy at the end we got is 86% and validation accuracy is 51%. Since there is huge gap between training and validation accuracy, the model will not perform well on newer dataset. \n- As we can see from the plot that as the number of epochs increases, the training accuracy also increased but the validation accuracy reduced. This is clear case of <b>overfitting<\/b>. \n- We can also see that training loss decreased and validation loss increased with the number of epochs. ","c72e0035":"The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.","3b813b29":"### Create the model\n#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`","ae6ef41c":"### **Visualizing the results**","ffa70471":"### **Create Model with Dropout**","4b3ec2d3":"***Vannila Model***","9273c248":"### **Todo:** Rectify the class imbalance\n#### **Context:** You can use a python package known as `Augmentor` (https:\/\/augmentor.readthedocs.io\/en\/master\/) to add more samples across all classes so that none of the classes have very few samples.","f42de3f6":"### **Compiling the model**"}}