{"cell_type":{"b35da08d":"code","d992666d":"code","6e3981fa":"code","91a56c9c":"code","c6be7560":"code","e13eadb2":"code","efa9d3d1":"code","f108fe2a":"code","5e30e1e4":"code","09acb671":"code","b3e7b9dc":"code","e8151723":"code","7955bb2a":"markdown"},"source":{"b35da08d":"!pip install ..\/input\/keras-toolkit -q","d992666d":"import os\n\nimport cupy as cp\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras_toolkit as kt\nfrom tqdm.auto import tqdm","6e3981fa":"# # Source: https:\/\/www.robots.ox.ac.uk\/~albanie\/notes\/Euclidean_distance_trick.pdf\n# # Not currently used\n# def euclidean_dist_matrix(X):\n#     G = X.T.dot(X)\n#     diagG = np.diagonal(G).reshape(-1, 1)\n#     D = diagG + diagG.T - 2*G\n    \n#     return D","91a56c9c":"def find_matches_cupy(X, posting_ids, threshold, limit=50):\n    X = cp.array(X)\n    N = X.shape[1]\n    matches = []\n\n    for i in tqdm(range(N)):\n        v = X[:, i][..., np.newaxis]\n        dists = cp.linalg.norm(v - X, axis=0)\n        indices = cp.where(dists < threshold)[0][:limit].get()\n        match = \" \".join(posting_ids[indices])\n        matches.append(match)\n    \n    return matches","c6be7560":"kt.accelerator.limit_gpu_memory(2*1024)","e13eadb2":"target_shape = (200, 200)\ndef preprocess_image(filename, target_shape=target_shape):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n\n    img_str = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img_str, channels=3)\n    img = tf.image.resize(img, target_shape)\n    \n    # Resnet-style preprocessing, see: https:\/\/git.io\/JYo77\n    mean = [103.939, 116.779, 123.68]\n    img = img[..., ::-1]\n    img -= mean\n\n    return img","efa9d3d1":"COMPETITION_NAME = 'shopee-product-matching'\nstrategy = kt.accelerator.auto_select(verbose=True)\nBATCH_SIZE = strategy.num_replicas_in_sync * 32","f108fe2a":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\nsubmission = pd.read_csv('..\/input\/shopee-product-matching\/sample_submission.csv')\n\ntrain['path'] = os.path.join('\/kaggle', 'input', COMPETITION_NAME, 'train_images\/') + train['image']\ntest['path'] = os.path.join('\/kaggle', 'input', COMPETITION_NAME, 'test_images\/') + test['image']\n\ntest.head()","5e30e1e4":"with strategy.scope():\n    encoder = tf.keras.models.load_model(\n        '..\/input\/shopee-siamese-resnet-50-with-triplet-loss-on-tpu\/encoder.h5'\n    )\n\nencoder.summary()","09acb671":"# dtrain = kt.image.build_dataset(\n#     train['path'],\n#     decode_fn=preprocess_image,\n#     bsize=BATCH_SIZE,\n# )\n\n# train_embeds = encoder.predict(dtrain, verbose=1)\n\n# train_matches = find_matches_cupy(\n#     X=train_embeds.T,\n#     posting_ids=train.posting_id.values,\n#     threshold=3.25\n# )","b3e7b9dc":"dtest = kt.image.build_dataset(\n    test['path'],\n    decode_fn=preprocess_image,\n    bsize=BATCH_SIZE\n)\n\ntest_embeds = encoder.predict(dtest, verbose=1)\n\nsubmission.matches = find_matches_cupy(\n    X=test_embeds.T,\n    posting_ids=submission.posting_id.values,\n    threshold=4.23\n)","e8151723":"submission.to_csv('submission.csv', index=False)","7955bb2a":"Submission notebook for [*Siamese ResNet-50 with triplet loss on TPU*](https:\/\/www.kaggle.com\/xhlulu\/shopee-siamese-resnet-50-with-triplet-loss-on-tpu)\n\n## Acknowledgement\n\nThe previous notebook was derived from [this excellent Keras tutorial](https:\/\/keras.io\/examples\/vision\/siamese_network\/).\n\nI added `kt.accelerator.limit_gpu_memory` function to `keras-toolkit` based on [Chris Deotte's notebook](https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700). The function was taken from the notebook with very little modification; please go give him an upvote for finding out that neat trick!"}}