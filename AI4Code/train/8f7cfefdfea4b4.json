{"cell_type":{"f38e88cd":"code","9900a0a9":"code","4249df00":"code","20682363":"code","e3c30a9b":"code","a25fac14":"code","1fb795a8":"code","b2bd3101":"code","74ece3fc":"code","f3726910":"code","4b31f15f":"code","efc9c185":"code","59829cff":"code","dfa0d784":"code","db9bb430":"code","79d59373":"code","77e90019":"code","1293770b":"code","22b08286":"code","ff5c38bd":"code","114e384e":"code","fa753a49":"code","ee42da6b":"code","5b934fbe":"code","ccb51c1b":"code","f0297603":"code","e420abad":"code","904047dc":"code","f6976e82":"code","9d8919f8":"code","4e2ec4c8":"code","a66c0a0e":"code","6841ba01":"code","3c0ca154":"code","e9e23521":"code","3e7c6ac1":"code","64d0a7d6":"code","10295f3d":"code","479c8e95":"code","9123d31b":"code","aa373978":"code","ab107b15":"code","fb141847":"code","ca98d7db":"code","1ac23f4e":"code","884b0d98":"code","d8eb8b62":"code","014f4f83":"code","1a900580":"markdown","a326c28a":"markdown","d7f9079e":"markdown","69d0bbb2":"markdown","11dec8b4":"markdown","ab846c49":"markdown","95cd3354":"markdown","1159cb97":"markdown","4ed169e7":"markdown","d3734805":"markdown","fd85d54e":"markdown","653c9345":"markdown"},"source":{"f38e88cd":"!pip install adabound","9900a0a9":"import os\nimport json\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import signal\nimport adabound","4249df00":"def convert_image_id_2_path(image_id: str, is_train: bool = True) -> str:\n    folder = \"train\" if is_train else \"test\"\n    return \"..\/input\/g2net-gravitational-wave-detection\/{}\/{}\/{}\/{}\/{}.npy\".format(\n        folder, image_id[0], image_id[1], image_id[2], image_id \n    )","20682363":"train_df = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/training_labels.csv\")\ntrain_df","e3c30a9b":"sns.countplot(data=train_df, x=\"target\")","a25fac14":"'''\n# We need to suppress the high frequencies with some bandpassing:\nbb, ab = butter(4, [20.*2.\/fs, 300.*2.\/fs], btype='band')\nstrain_H1_whitenbp = filtfilt(bb, ab, strain_H1_whiten)\nstrain_L1_whitenbp = filtfilt(bb, ab, strain_L1_whiten)\nNR_H1_whitenbp = filtfilt(bb, ab, NR_H1_whiten)\n'''\n\ndef bpf(wave, fs, fe1, fe2):\n    nyq = fs \/ 2.0\n    b, a = signal.butter(1, [fe1\/nyq, fe2\/npq], btype='band', fs=4096)\n    return b, a\n    #wave = signal.lfilter(b, a, wave)   \n    #return wave","1fb795a8":"# bpf\u53ef\u8996\u5316\n\ndef bpf_visualize(\n    _id, \n    target,\n    fs=4096,\n    fe1=20,\n    fe2=500,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    colors=(\"black\", \"red\", \"green\")\n):\n    x = np.load(convert_image_id_2_path(_id))\n    b, a = bpf(x, fs, fe1, fe2)\n    wave = signal.lfilter(b, a, x)    \n    \n    #np.save( f'.\/output\/{_id}.npy', wave)\n    \n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        X = wave[i] \/ wave[i].max()\n        #S = np.fft.fftfreq(len(X), d=1\/2048)        \n        plt.subplot(1, 3, i + 1)\n        plt.plot(X, color=colors[i])\n        #plt.xlim(0,100)\n        #plt.ylim(0,10000)\n        #plt.colorbar()\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()\n\nfor i in range(3):#random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    bpf_visualize(_id, target)","b2bd3101":"!pip install -q nnAudio -qq","74ece3fc":"import torch\nfrom nnAudio.Spectrogram import CQT1992v2\n\nQ_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    #x = np.load(('.\/output\/' + _id + '.npy'))\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        #print(image.shape)\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()\n\nfor i in range(3):#random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    #visualize_sample(_id, target)\n    visualize_sample_qtransform(_id, target)","f3726910":"!mkdir .\/bpf","4b31f15f":"# wave\u30c7\u30fc\u30bf\u3092(56000, 3, 4096)\u306b\u5909\u66f4\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2\nimport tensorflow as tf\n\n\nQ_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n    fs=4096,\n    fe1=20,\n    fe2=500\n):\n    #x = np.load(('.\/output\/' + _id + '.npy'))\n    x = np.load(convert_image_id_2_path(_id))\n    target = np.array([target]) * np.ones(x.shape[0]).reshape(-1,1)\n    b, a = bpf(x, fs, fe1, fe2)\n    wave = signal.lfilter(b, a, x) \n    #wave = np.concatenate([wave, target],axis=1) \n    return wave, target\n\ndef record2example(wave, target):\n    return tf.train.Example(features=tf.train.Features(feature={\n        \"x\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[wave])),\n        \"y\":  tf.train.Feature(bytes_list=tf.train.BytesList(value=[target]))\n    }))\n\n\ndef write_tfrecord(images, labels, filename):\n    writer = tf.compat.v1.python_io.TFRecordWriter(filename)\n    for image, label in zip(images, labels):\n        labels = labels.astype(np.int64)\n        ex = record2example(image.tobytes(), label.tobytes())\n        writer.write(ex.SerializeToString())\n    \n\n\ntmp = int(560000 * (1\/5))\n\nbpf_list = np.zeros((3, 3, 4096+1))\n\nfor i in range(10):#random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    \n    wave, target = visualize_sample_qtransform(_id, target)\n    write_tfrecord(wave, target, '.\/bpf\/' + _id + '.tfrec')","efc9c185":"!ls -a\n!mkdir .\/output\n#!rm -fr .\/output\n#%cd working\n","59829cff":"# \u30e1\u30e2\u30ea\u7206\u767a\n# -- To calculate the PSD of the data, choose an overlap and a window (common to all detectors)\n#   that minimizes \"spectral leakage\" https:\/\/en.wikipedia.org\/wiki\/Spectral_leakage\nfs = 4096\nNFFT = 4*fs\npsd_window = np.blackman(NFFT)\n# and a 50% overlap:\nNOVL = NFFT\/2\n\n# define the complex template, common to both detectors:\ntemplate = (template_p + template_c*1.j) \n# We will record the time where the data match the END of the template.\netime = time+template_offset\n# the length and sampling rate of the template MUST match that of the data.\ndatafreq = np.fft.fftfreq(template.size)*fs\ndf = np.abs(datafreq[1] - datafreq[0])\n\n# to remove effects at the beginning and end of the data stretch, window the data\n# https:\/\/en.wikipedia.org\/wiki\/Window_function#Tukey_window\ntry:   dwindow = signal.tukey(template.size, alpha=1.\/8)  # Tukey window preferred, but requires recent scipy version \nexcept: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n\n# prepare the template fft.\ntemplate_fft = np.fft.fft(template*dwindow) \/ fs\n\n# loop over the detectors\ndets = ['H1', 'L1']\nfor det in dets:\n\n    if det is 'L1': data = strain_L1.copy()\n    else:           data = strain_H1.copy()\n\n    # -- Calculate the PSD of the data.  Also use an overlap, and window:\n    data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n\n    # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n    data_fft = np.fft.fft(data*dwindow) \/ fs\n\n    # -- Interpolate to get the PSD values at the needed frequencies\n    power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n\n    # -- Calculate the matched filter output in the time domain:\n    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n    # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n    # so the result will be plotted as a function of time off-set between the template and the data:\n    optimal = data_fft * template_fft.conjugate() \/ power_vec\n    optimal_time = 2*np.fft.ifft(optimal)*fs\n\n    # -- Normalize the matched filter output:\n    # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n    # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n    sigmasq = 1*(template_fft * template_fft.conjugate() \/ power_vec).sum() * df\n    sigma = np.sqrt(np.abs(sigmasq))\n    SNR_complex = optimal_time\/sigma\n\n    # shift the SNR vector by the template length so that the peak is at the END of the template\n    peaksample = int(data.size \/ 2)  # location of peak in the template\n    SNR_complex = np.roll(SNR_complex,peaksample)\n    SNR = abs(SNR_complex)\n\n    # find the time and SNR value at maximum:\n    indmax = np.argmax(SNR)\n    timemax = time[indmax]\n    SNRmax = SNR[indmax]\n\n    # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n    # d_eff = (8. \/ SNRmax)*D_thresh\n    d_eff = sigma \/ SNRmax\n    # -- Calculate optimal horizon distnace\n    horizon = sigma\/8\n\n    # Extract time offset and phase at peak\n    phase = np.angle(SNR_complex[indmax])\n    offset = (indmax-peaksample)\n\n    # apply time offset, phase, and d_eff to template \n    template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n    template_rolled = np.roll(template_phaseshifted,offset) \/ d_eff  # Apply time offset and scale amplitude\n    \n    # Whiten and band-pass the template for plotting\n    template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n    template_match = filtfilt(bb, ab, template_whitened) \/ normalization # Band-pass the template\n    \n    print('For detector {0}, maximum at {1:.4f} with SNR = {2:.1f}, D_eff = {3:.2f}, horizon = {4:0.1f} Mpc' \n          .format(det,timemax,SNRmax,d_eff,horizon))\n\n    if make_plots:\n\n        # plotting changes for the detectors:\n        if det is 'L1': \n            pcolor='g'\n            strain_whitenbp = strain_L1_whitenbp\n            template_L1 = template_match.copy()\n        else:\n            pcolor='r'\n            strain_whitenbp = strain_H1_whitenbp\n            template_H1 = template_match.copy()\n\n        # -- Plot the result\n        plt.figure(figsize=(10,8))\n        plt.subplot(2,1,1)\n        plt.plot(time-timemax, SNR, pcolor,label=det+' SNR(t)')\n        #plt.ylim([0,25.])\n        plt.grid('on')\n        plt.ylabel('SNR')\n        plt.xlabel('Time since {0:.4f}'.format(timemax))\n        plt.legend(loc='upper left')\n        plt.title(det+' matched filter SNR around event')\n\n        # zoom in\n        plt.subplot(2,1,2)\n        plt.plot(time-timemax, SNR, pcolor,label=det+' SNR(t)')\n        plt.grid('on')\n        plt.ylabel('SNR')\n        plt.xlim([-0.15,0.05])\n        #plt.xlim([-0.3,+0.3])\n        plt.grid('on')\n        plt.xlabel('Time since {0:.4f}'.format(timemax))\n        plt.legend(loc='upper left')\n        plt.savefig(eventname+\"_\"+det+\"_SNR.\"+plottype)\n\n        plt.figure(figsize=(10,8))\n        plt.subplot(2,1,1)\n        plt.plot(time-tevent,strain_whitenbp,pcolor,label=det+' whitened h(t)')\n        plt.plot(time-tevent,template_match,'k',label='Template(t)')\n        plt.ylim([-10,10])\n        plt.xlim([-0.15,0.05])\n        plt.grid('on')\n        plt.xlabel('Time since {0:.4f}'.format(timemax))\n        plt.ylabel('whitened strain (units of noise stdev)')\n        plt.legend(loc='upper left')\n        plt.title(det+' whitened data around event')\n\n        plt.subplot(2,1,2)\n        plt.plot(time-tevent,strain_whitenbp-template_match,pcolor,label=det+' resid')\n        plt.ylim([-10,10])\n        plt.xlim([-0.15,0.05])\n        plt.grid('on')\n        plt.xlabel('Time since {0:.4f}'.format(timemax))\n        plt.ylabel('whitened strain (units of noise stdev)')\n        plt.legend(loc='upper left')\n        plt.title(det+' Residual whitened data after subtracting template around event')\n        plt.savefig(eventname+\"_\"+det+\"_matchtime.\"+plottype)\n                 \n        # -- Display PSD and template\n        # must multiply by sqrt(f) to plot template fft on top of ASD:\n        plt.figure(figsize=(10,6))\n        template_f = np.absolute(template_fft)*np.sqrt(np.abs(datafreq)) \/ d_eff\n        plt.loglog(datafreq, template_f, 'k', label='template(f)*sqrt(f)')\n        plt.loglog(freqs, np.sqrt(data_psd),pcolor, label=det+' ASD')\n        plt.xlim(20, fs\/2)\n        plt.ylim(1e-24, 1e-20)\n        plt.grid()\n        plt.xlabel('frequency (Hz)')\n        plt.ylabel('strain noise ASD (strain\/rtHz), template h(f)*rt(f)')\n        plt.legend(loc='upper left')\n        plt.title(det+' ASD and template around event')\n        plt.savefig(eventname+\"_\"+det+\"_matchfreq.\"+plottype)\n","dfa0d784":"# FFT\u53ef\u8996\u5316\ndef FFT_visualize(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    colors=(\"black\", \"red\", \"green\"),\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        X = np.fft.fft(x[i] \/ x[i].max())\n        S = np.fft.fftfreq(len(X), d=1\/2048)\n        \n        #Xdb = librosa.amplitude_to_db(abs(X))\n        plt.subplot(1, 3, i + 1)\n        #librosa.display.specshow(S, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-30, vmax=50) \n        plt.plot(S, np.abs(X), color=colors[i])\n        plt.xlim(0,100)\n        #plt.colorbar()\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()\n\nfor i in range(3):#random.sample(train_df.index.tolist(), 10):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    FFT_visualize(_id, target)","db9bb430":"# \u30b5\u30a4\u30f3\u6ce2\u306e\u5408\u7b97\u3092\u53ef\u8996\u5316\ndef visualize_sample(\n    _id, \n    target, \n    colors=(\"black\", \"red\", \"green\"), \n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    path = convert_image_id_2_path(_id)\n    x = np.load(path)\n    sum_x = x.sum(axis=0)\n    sum_x = (sum_x\/sum_x.max())\n    print(sum_x.shape)\n    plt.figure(figsize=(16, 7))\n    plt.plot(sum_x)\n    plt.show()\n    X = np.fft.fft(sum_x)\n    S = np.fft.fftfreq(len(X), d=1\/2048)   \n    plt.plot(S, np.abs(X))\n    plt.xlim(0,100)\n\nfor i in range(1):#random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample(_id, target)","79d59373":"# \u30b5\u30a4\u30f3\u6ce2\u306e\u5408\u7b97\u3092\u30b9\u30da\u30af\u30c8\u30eb\u53ef\u8996\u5316\nimport librosa \nimport librosa.display\n\ndef visualize_sample(\n    _id, \n    target, \n    colors=(\"black\", \"red\", \"green\"), \n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    path = convert_image_id_2_path(_id)\n    x = np.load(path)\n    sum_x = x.sum(axis=0)\n    sum_x = (sum_x\/sum_x.max())\n    print(sum_x.shape)\n    \n    X = librosa.stft(sum_x \/ sum_x.max())\n    Xdb = librosa.amplitude_to_db(abs(X))\n    \n    #plt.figure(figsize=(16, 7))\n    librosa.display.specshow(Xdb, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-30, vmax=50) \n    plt.show()\n\nfor i in random.sample(train_df.index.tolist(), 1):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample(_id, target)","77e90019":"def visualize_sample(\n    _id, \n    target, \n    colors=(\"black\", \"red\", \"green\"), \n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    path = convert_image_id_2_path(_id)\n    x = np.load(path)\n    plt.figure(figsize=(16, 7))\n    for i in range(3):\n        plt.subplot(4, 1, i + 1)\n        plt.plot(x[i], color=colors[i])\n        plt.legend([signal_names[i]], fontsize=12, loc=\"lower right\")\n        \n        plt.subplot(4, 1, 4)\n        plt.plot(x[i], color=colors[i])\n    \n    plt.subplot(4, 1, 4)\n    plt.legend(signal_names, fontsize=12, loc=\"lower right\")\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","1293770b":"for i in range(3):#random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample(_id, target)","22b08286":"import librosa\nimport librosa.display","ff5c38bd":"def visualize_sample_spectogram(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    sum_x = np.zeros((x.shape[0], x.shape[1]))\n    for i in range(3):\n        X = librosa.stft(x[i] \/ x[i].max())\n        Xdb = librosa.amplitude_to_db(abs(X))\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(Xdb, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-30, vmax=50) \n        plt.colorbar()\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","114e384e":"for i in range(3):#random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample_spectogram(_id, target)","fa753a49":"def visualize_sample_mfcc(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        mfccs = librosa.feature.mfcc(x[i] \/ x[i].max(), sr=sr)\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(mfccs, sr=sr, x_axis=\"time\", vmin=-200, vmax=50, cmap=\"coolwarm\")\n        plt.title(signal_names[i], fontsize=14)\n        plt.colorbar()\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","ee42da6b":"for i in random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample_mfcc(_id, target)","5b934fbe":"# !pip install pycbc -qq\n# import pycbc.types","ccb51c1b":"!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2","f0297603":"Q_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        #print(image.shape)\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","e420abad":"\nfor i in range(10):#random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    #visualize_sample(_id, target)\n    visualize_sample_qtransform(_id, target)","904047dc":"import cv2\nimport numpy as np\n\n# kernel of blur filter\n# \u30ab\u30fc\u30cd\u30eb\uff08\u7e26\u65b9\u5411\u306e\u8f2a\u90ed\u691c\u51fa\u7528\uff09\nkernel = np.array([[1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9]])\n\nQ_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    waves = np.zeros((x.shape[0], x.shape[1]))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        waves = Q_TRANSFORM(waves)\n        #waves = waves.numpy()\n        #waves = cv2.filter2D(waves, -1, kernel)\n        #waves = torch.from_numpy(waves).float()\n        return waves\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(waves.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()\n\n#avg_filter = np.zeros((len(train_df), 3, 4096))\n\nfor i in range(10):#random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    #visualize_sample(_id, target)\n    avg_filter = visualize_sample_qtransform(_id, target)\n    print(avg_filter.shape)","f6976e82":"import cv2\nimport numpy as np\n\n# kernel of blur filter\n# \u30ab\u30fc\u30cd\u30eb\uff08\u7e26\u65b9\u5411\u306e\u8f2a\u90ed\u691c\u51fa\u7528\uff09\nkernel = np.array([[1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9]])\n\nQ_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\n# \u9bae\u92ed\u5316\ndef make_sharp_kernel(k: int):\n    return np.array([\n    [-k \/ 9, -k \/ 9, -k \/ 9],\n    [-k \/ 9, 1 + 8 * k \/ 9, k \/ 9],\n    [-k \/ 9, -k \/ 9, -k \/ 9]], np.float32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n    kernel_size=5\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    waves = np.zeros((x.shape[0], x.shape[1]))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        image = image.numpy()\n        # \u5e73\u5747\u5316\u30d5\u30a3\u30eb\u30bf\u30fc\n        image = cv2.filter2D(image, -1, kernel)\n        \n        # \u9bae\u92ed\u5316\n        #kernel_filter = make_sharp_kernel(1)\n        #image = cv2.filter2D(image, -1, kernel_filter)\n        \n        # \u30e1\u30c7\u30a3\u30a2\u30f3\u30d5\u30a3\u30eb\u30bf\u30fc\n        #image = cv2.medianBlur(image, kernel_size)\n        #image = torch.from_numpy(image).float()\n        \n        #plt.subplot(1, 3, i + 1)\n        #plt.imshow(image.squeeze())\n        #plt.title(signal_names[i], fontsize=14)\n\n    #plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    #plt.show()\n    \n\nfor i in range(10):#random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    #visualize_sample(_id, target)\n    visualize_sample_qtransform(_id, target)\n\n# \u5e73\u5747\u5316\u304c\u9055\u3044\u3092\uff11\u756a\u306f\u3063\u304d\u308a\u793a\u3057\u3066\u3044\u308b\n# \u9bae\u92ed\u5316\u306f\u8f2a\u90ed\u304c\u306f\u3063\u304d\u308a\u3059\u308b\u3089\u3057\u304c\u30dc\u30b1\u3066\u3044\u308b\n# \u30e1\u30c7\u30a3\u30a2\u30f3\u30d5\u30a3\u30eb\u30bf\u30fc\u3092\u304b\u3051\u308b\u3068\u3088\u308a\u30dc\u30b1\u3066\u898b\u3048\u308b","9d8919f8":"from sklearn.metrics import roc_auc_score, roc_curve, auc","4e2ec4c8":"\nlist_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","a66c0a0e":"submission = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\nsubmission.to_csv(\"submission.csv\", index=False)\ndel submission","6841ba01":"!pip install efficientnet_pytorch -qq","3c0ca154":"import time\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nfrom torch.autograd import Variable\nimport efficientnet_pytorch\nfrom sklearn.model_selection import StratifiedKFold","e9e23521":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nset_seed(42)","3e7c6ac1":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets):\n        self.paths = paths\n        self.targets = targets\n        self.fs=4096\n        self.fe1=20 \n        self.fe2=500\n        self.kernel = np.array([[1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9],\n                   [1\/9, 1\/9, 1\/9]])\n\n        \n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        )\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def bpf(self, wave):\n        nyq = self.fs \/ 2.0\n        b, a = signal.butter(1, [self.fe1, self.fe2], btype='band', fs=self.fs)\n        wave = signal.lfilter(b, a, wave)   \n        return wave\n    \n    def get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            # bpf\n            waves = self.bpf(x[i])\n            waves = waves \/ np.max(waves)\n            waves = torch.from_numpy(waves).float()\n            channel = self.q_transform(waves).squeeze().numpy()\n            # \u5e73\u5747\u5316\u30d5\u30a3\u30eb\u30bf\u30fc\n            #channel = cv2.filter2D(channel, -1, self.kernel).squeeze()\n            '''\n            waves = torch.from_numpy(waves).float()\n            waves = Q_TRANSFORM(waves)\n            waves = waves.numpy()\n            waves = cv2.filter2D(waves, -1, kernel)\n            waves = torch.from_numpy(waves).float()\n            '''\n            image.append(channel)\n            \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        file_path = convert_image_id_2_path(self.paths[index])\n        x = np.load(file_path)\n        image = self.get_qtransform(x)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.float)\n            \n        return {\"X\": image, \"y\": y}","64d0a7d6":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_pretrained(\"efficientnet-b7\")\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","10295f3d":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","479c8e95":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model \n        self.device = device \n        self.optimizer = optimizer \n        self.criterion = criterion \n        self.loss_meter = loss_meter \n        self.score_meter = score_meter \n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    # \u53ef\u8996\u5316\u306b\u8fd1\u3044\uff1f\n    '''\n    #=========================================3\n    '''\n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.n_epoch = n_epoch\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n\n            if True:\n#             if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path + str(self.n_epoch - 1) +'.pth')\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n            \n    # \u5b66\u7fd2\u306f\u3053\u3063\u3061\n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        self.train_loss_list = []\n        self.train_score_list = []\n        \n        for step, batch in enumerate(train_loader, start=1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            # \u52fe\u914d\u306e\u521d\u671f\u5316\n            self.optimizer.zero_grad()\n            # \u4e88\u6e2c\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\u3057\u3066\u3044\u308b\n            outputs = self.model(X).squeeze(1) # \u6b21\u51431\u3092\u6f70\u3059\n            \n            loss = self.criterion(outputs, targets)\n            # \u8aa4\u5dee\u9006\u4f1d\u64ad\u958b\u59cb\n            loss.backward()\n            \n            '''\n            #=========================================\u2463\n            \u30ed\u30b9\u3092\u958b\u59cb\u3057\u3066\u308b\u306e\u306bloss?detexh\u3067\u533a\u5207\u3063\u3066\u3044\u308b\u3082\u306e\u3092\u51fa\u3057\u3066\u3044\u308b\uff1f\n            '''\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n            \n            # \u52fe\u914d\u306e\u66f4\u65b0\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}\/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n        self.train_loss_list.append(train_loss.avg)\n        self.train_score_list.append(train_score.avg)\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n        self.valid_loss_list = []\n        self.valid_score_list = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, extension='.pth'):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch, \n            },\n            save_path + str(self.n_epoch - 1) + extension\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","9123d31b":"'''\nclass get_lr_callback:\n    def __init__(self, epoch,  BATCH_SIZE = 256):\n        self.lr_start = 0.0001\n        self.lr_max = 0.000015 * BATCH_SIZE\n        self.lr_min = 0.0000001\n        self.lr_ramp_ep = 3\n        self.lr_sus_ep = 0\n        self.lr_decay = 0.7\n        self.epoch = epoch\n   \n    def lrfn(self):\n        if self.epoch < self.lr_ramp_ep:\n            lr = (self.lr_max - self.lr_start) \/ self.lr_ramp_ep * self.epoch + self.lr_start   \n        elif self.epoch < self.lr_ramp_ep + self.lr_sus_ep:\n            lr = self.lr_max    \n        else:\n            lr = (self.lr_max - self.lr_min) * self.lr_decay**(self.epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min    \n        return lr\n'''","aa373978":"import psutil \n\n# \u30e1\u30e2\u30ea\u5bb9\u91cf\u3092\u53d6\u5f97\nmem = psutil.virtual_memory() \nprint(mem.total)\n\n# \u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u3092\u53d6\u5f97 \nprint(mem.used)\n\n# \u30e1\u30e2\u30ea\u7a7a\u304d\u5bb9\u91cf\u3092\u53d6\u5f97 \nprint(mem.available)\n","ab107b15":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nskf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train_df, train_df[\"target\"])):\n    train_X = train_df.iloc[train_index]\n    valid_X = train_df.iloc[valid_index] # Reduce calculation time\n    #print(train_X.shape, valid_X.shape)\n\n    train_data_retriever = DataRetriever(\n        train_X[\"id\"].values, \n        train_X[\"target\"].values, \n    )\n\n    valid_data_retriever = DataRetriever(\n        valid_X[\"id\"].values, \n        valid_X[\"target\"].values,\n    )\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=32,\n        shuffle=True,\n        num_workers=2,\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=32,\n        shuffle=False,\n        num_workers=2,\n    )\n\n    model = Model()\n    model.to(device)\n\n    #optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    optimizer = adabound.AdaBound(model.parameters(), lr=0.001, final_lr=0.5)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device,\n        optimizer, \n        criterion, \n        LossMeter, \n        AccMeter\n    )\n\n    history = trainer.fit(\n        1, \n        train_loader, \n        valid_loader, \n        'bpf_only-pth',\n        #f\"best-model-{fold}.pth\",\n        100\n    )\n   ","fb141847":"models = []\nfor i in range(2):\n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(f\"best-model-{i}.pth\")\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","ca98d7db":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n\n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        )\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            waves = x[i] \/ np.max(x[i])\n            waves = torch.from_numpy(waves).float()\n            channel = self.q_transform(waves).squeeze().numpy()\n            image.append(channel)\n            \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        file_path = convert_image_id_2_path(self.paths[index], is_train=False)\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n            \n        return {\"X\": image, \"id\": self.paths[index]}","1ac23f4e":"test_data_retriever = DataRetriever(\n    submission[\"id\"].values, \n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=32,\n    shuffle=False,\n    num_workers=8,\n)","884b0d98":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res \/ 2\n        y_pred.extend(tmp_pred)\n        ids.extend(batch[\"id\"])","d8eb8b62":"submission = pd.DataFrame({\"id\": ids, \"target\": y_pred})\nsubmission.to_csv(\"model_submission.csv\", index=False)","014f4f83":"submission","1a900580":"# bpf\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210\uff08tfrec\uff09","a326c28a":"# \u3053\u3063\u304b\u3089\u666e\u901a\u2460","d7f9079e":"# BPF","69d0bbb2":"### WORK IN PROGRESS ...","11dec8b4":"Each data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.","ab846c49":"\nSubmissions are evaluated on [area under the ROC curve](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) between the predicted probability and the observed target.\n","95cd3354":"# \u30de\u30c3\u30c1\u30c9\u30d5\u30a3\u30eb\u30bf\u30fc","1159cb97":"# \u3053\u3063\u304b\u3089\u666e\u901a\u2461","4ed169e7":"# \u30b5\u30a4\u30f3\u6ce2\u5408\u7b97\u30b9\u30da\u30af\u30c8\u30eb","d3734805":"# FFT\u53ef\u8996\u5316","fd85d54e":"# \u5e73\u5747\u5316\u30d5\u30a3\u30eb\u30bf\u30fc\u3092\u66f4\u306b\u9bae\u92ed\u5316\u30d5\u30a3\u30eb\u30bf\u30fc\u3092\u304b\u3051\u308b","653c9345":"# CQT\u3092\u5e73\u5747\u5316\u30d5\u30a3\u30eb\u30bf\u30fc\u3067\u5b9f\u88c5"}}