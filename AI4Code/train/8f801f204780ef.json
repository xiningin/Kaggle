{"cell_type":{"f8432bbe":"code","8a0966fe":"code","89f8e1ba":"code","221e3132":"code","1cf78806":"code","f5a7cc3e":"code","47e2044b":"code","5dd2a35d":"code","1d4fb656":"code","c291aae3":"code","9a3c0a99":"code","a259a8d6":"code","9a7abef8":"code","73d78106":"code","6e195041":"code","6d8642d1":"code","cd1acae2":"code","ddf57643":"code","e0a0c15b":"code","4577abd8":"code","a4e4fa4a":"code","31e01c0e":"code","dfdd794e":"code","c746997e":"code","5bbee7f7":"code","7acd8c12":"code","c521b2ed":"code","43f2cc31":"code","da391018":"code","3e5ef5e9":"code","c38ba15f":"code","0bb154f3":"code","c7e47381":"code","ce766c5f":"code","a5c51313":"code","b92772b7":"code","95152216":"markdown","437aae34":"markdown","24b248b0":"markdown","f0a32c62":"markdown","db802721":"markdown","4471d014":"markdown","99022fe4":"markdown","c25778d7":"markdown","63b0df8c":"markdown","c41634a5":"markdown","180b1af9":"markdown","168fb043":"markdown","7f723eaf":"markdown","454a74a9":"markdown","7904c47f":"markdown","5547f03d":"markdown","d09cd177":"markdown","9ae0fdee":"markdown","dabffef9":"markdown","dbcdb7ae":"markdown","56c779f3":"markdown","9f0e1044":"markdown","b556c634":"markdown","b4d40ea6":"markdown","ca823082":"markdown"},"source":{"f8432bbe":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.pandas.set_option('display.max_columns',None)","8a0966fe":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ndf_train.head()","89f8e1ba":"missing_sum = df_train.isnull().sum().sort_values(ascending = False)\nprint(missing_sum.head(10))\nmissing = missing_sum [missing_sum > 0]\nmissing.plot.bar()","221e3132":"df_train.drop(columns = ['PoolQC','MiscFeature', 'Alley', 'Fence'], inplace = True)","1cf78806":"df_train['FireplaceQu'].fillna('NA',inplace = True)","f5a7cc3e":"df_train['FireplaceQu'].value_counts().plot(kind='bar')\nplt.show()","47e2044b":"# def boxplot(x,y,**kwargs):\n#     sns.boxplot(x=x, y=y)\n#     x=plt.xticks(rotation=90)\n    \n# f = pd.melt(df_train, id_vars = ['SalePrice'], value_vars=['FireplaceQu'])\n# g = sns.FacetGrid(f,col='variable',col_wrap=2 , sharex=False)\n# g = g.map(boxplot,'value','SalePrice')\nax = sns.boxplot(x= df_train['FireplaceQu'], y= df_train['SalePrice'], data=df_train)","5dd2a35d":"df_train.drop(columns = ['FireplaceQu'],inplace = True)","1d4fb656":"#Filter for quantative features\nquant =[f for f in df_train.columns if df_train.dtypes[f]!=(\"object\")]\n\n\n#Filter for Qualitative\nqualt =[f for f in df_train.columns if df_train.dtypes[f]==(\"object\")]\n\n#Id Column\nId_Col = df_train['Id']\n#SalePrice Column\nSalePrice_Col = df_train['SalePrice']","c291aae3":"df_quant = df_train[quant]\ndf_quant.head()","9a3c0a99":"df_qualt = df_train[qualt]\ndf_qualt.head()","a259a8d6":"df_quant.isnull().sum()","9a7abef8":"import warnings\n# check the normal distribution of columns having null values by filling with the mean value\nnull_features_numerical = [col for col in df_quant.columns if df_quant[col].isnull().sum() > 0]\nplt.figure(figsize=(30,20))\nsns.set()\n\nwarnings.simplefilter(\"ignore\")\nfor i,var in enumerate(null_features_numerical):\n    plt.subplot(4,3,i+1)\n    sns.distplot(df_quant[var],bins=20,kde_kws={'linewidth':3,'color':'red'},label=\"original\")\n    sns.distplot(df_quant[var].fillna(df_quant[var].mean()),bins=20,kde_kws={'linewidth':2,'color':'yellow'},label=\"mean\")","73d78106":"#Median\nplt.figure(figsize=(30,20))\nsns.set()\nwarnings.simplefilter(\"ignore\")\nfor i,var in enumerate(null_features_numerical):\n    plt.subplot(4,3,i+1)\n    sns.distplot(df_quant[var],bins=20,kde_kws={'linewidth':3,'color':'red'},label=\"original\")\n    sns.distplot(df_quant[var].fillna(df_quant[var].median()),bins=20,kde_kws={'linewidth':2,'color':'yellow'},label=\"mean\")","6e195041":"df_quant.fillna(df_quant.mean(),inplace=True)","6d8642d1":"df_for_heatmap = df_quant.copy()\n\nsns.heatmap(df_for_heatmap.corr(), cmap ='RdYlGn', linewidths = 0.2, annot = True)\nfig=plt.gcf()\nfig.set_size_inches(25,25)\nplt.show()","cd1acae2":"def SelectHighlyCorr_withTarget(df,corr):\n    #return df with only high correlated features\n    #Getting all correlations\n    cor = df.corr()\n    #Correlations with target\n    cor_target = abs(cor[\"SalePrice\"])\n    relevant_features = cor_target[cor_target>=corr]\n\n    rl = df_for_heatmap[relevant_features.index]\n    \n    return rl\n\ndf_quant_good_cor=SelectHighlyCorr_withTarget(df_quant,0.2)","ddf57643":"sns.heatmap(df_quant_good_cor.corr(), cmap ='RdYlGn', linewidths = 0.2, annot = True)\nfig=plt.gcf()\nfig.set_size_inches(25,25)\nplt.show()","e0a0c15b":"df_quant = df_quant_good_cor.copy()\ndf_quant.drop(columns=['1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','GarageYrBlt'],inplace=True)\n","4577abd8":"df_quant.info()","a4e4fa4a":"df_qualt.fillna('Missing',inplace= True)\ndf_qualt.isnull().sum()","31e01c0e":"f, axes = plt.subplots(6,7 , figsize=(30, 30), sharex=False)\nfor i, feature in enumerate(qualt):\n    sns.countplot(data = df_qualt, x = feature,ax=axes[i%6, i\/\/7])","dfdd794e":"df_qualt.drop(columns = ['RoofMatl','Street','Condition2','Utilities','Heating'],inplace = True)","c746997e":"#features_to_check = ['LandSlope','RoofStyle']\nf, axes = plt.subplots(6,6, figsize=(30, 30), sharex=False)\nfor i, feature in enumerate(df_qualt.columns):\n    sns.boxplot(x= feature, y= SalePrice_Col, data=df_qualt, ax = axes[i%6,i\/\/6])\n    ","5bbee7f7":"df_final_train = pd.concat([df_qualt,df_quant], axis =1)\ndf_final_train","7acd8c12":"df_final_train.info()","c521b2ed":"df_final_train.shape","43f2cc31":"df_final_train.drop(columns='SalePrice',inplace=True)\ndf_final_test = df_test[df_final_train.columns]\ncombined_df = pd.concat([df_final_train,df_final_test],axis=0)\ncombined_df.shape","da391018":"combined_df","3e5ef5e9":"# Generate one-hot dummy columns\n#cols_to_select = df_final_train.columns\nprint('Before Encoding:',combined_df.shape)\ncombined_df_final = pd.get_dummies(combined_df).reset_index(drop=True)\nprint('After Encoding:',combined_df_final.shape)","c38ba15f":"combined_df_final.head(10)","0bb154f3":"# Returning the train and test from combined\nnew_train_data = combined_df_final.iloc[:len(df_train), :]\nnew_test_data = combined_df_final.iloc[len(df_train):, :]","c7e47381":"from sklearn.model_selection import train_test_split\nfrom ml_metrics import rmse\n\n#Splitting data\n#Final train is the final dataframe with removal of uneeded features\ny = df_train['SalePrice']\ny_log = np.log1p(y.values.ravel())\n\n\n#Splitting for Validation\nx_train, x_validation, y_train, y_validation = train_test_split(new_train_data , y_log ,  train_size=0.8, test_size=0.2, random_state =20)\n\n#Model\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\n\n#Prediction\ny_train_predicted = model.predict(x_train) #RMSE on train\ny_valid_predicted = model.predict(x_validation) #RMSE on validation\n\n\n#Metric (RMSE)\nprint(\"The RMSE on train is : \",rmse(y_train,y_train_predicted))\nprint(\"The RMSE on Validation is : \",rmse(y_validation,y_valid_predicted))\n\n","ce766c5f":"#Getting R2 Score\nfrom sklearn.metrics import r2_score\ny = df_train['SalePrice']\nx_train, x_validation, y_train, y_validation = train_test_split(new_train_data , y ,  train_size=0.8, test_size=0.2, random_state =20)\n\nmodel2 = LinearRegression()\nmodel2.fit(x_train, y_train)\n\n#Prediction\ny_train_predicted = model2.predict(x_train) #RMSE on train\ny_valid_predicted = model2.predict(x_validation) #RMSE on validation\n\n\n#Metric (RMSE)\nprint(\"The R2 on train is : \",r2_score(y_train,y_train_predicted))\nprint(\"The R2 on Validation is : \",r2_score(y_validation,y_valid_predicted))\n","a5c51313":"new_test_data.fillna(new_test_data.mean(),inplace=True)","b92772b7":"y_pred_test_file = model.predict(new_test_data)\nsubmission  = pd.DataFrame()\nsubmission['Id']=df_test['Id']\nsubmission[\"SalePrice\"]=y_pred_test_file\nsubmission.info()\nsubmission.to_csv('submission.csv', index=False) ","95152216":"Rechecking on the dataset","437aae34":"Checking to Fill Null values with mean or with median","24b248b0":"***SPLITTING AND CREATING MODEL TO TRAIN***","f0a32c62":"Visualizing data distribution","db802721":"..","4471d014":"***Divding data into Quantitative and Qualititative***","99022fe4":"Checking Null Values","c25778d7":"The FireplaceQu has a lot of Outliers and a lot of missing, and the SalePrice has no real dependence on it, so we will drop it","63b0df8c":"Checking Data Correlation using Heatmap","c41634a5":"***WORKING WITH QUANTITATIVE FEATURES***","180b1af9":"***WORKING WITH QUALITITATIVE FEATURES***","168fb043":"From Above we notice that there are some features that have dominant values\nSo we will drop these Features , or combine minor groups together (but we have to check if they have similar SalePrice.\n\nColumn we consider to drop --> which has a catgorial frequency exceeds 1400\nEx: 'RoofMatl','Street','Condition2','Utilities','Heating' \n\n\nColumns we consider to combine minor categories --> we will check if the minor has same salePrice range\nEx: 'HeatingQC', 'GarageQual' and 'GarageCond'","7f723eaf":"Notice That:\nfor LandSlop we can merge Mod and Sev,\nPo and Fa are of similar price range in all categories so we can combine them","454a74a9":"=======================================================================================\n================================================================================\n=====================================================================\n===========================","7904c47f":"**Prediction and Submission**","5547f03d":"We notice that they will have same distribution , so it's ok to use any of them","d09cd177":"Now we recombine both Quant and Qualt to form df_final_train","9ae0fdee":"**Encoding the Categorial to Numerical**","dabffef9":"Reading Data","dbcdb7ae":"Making a function to pick features that have good correlation with Target","56c779f3":"Visualizing the FirePlaceQu Column","9f0e1044":"Before we Encode we have to combine both Train and Test","b556c634":"GarageCars and GarageArea has a strong correlation, so we consider dropping one of them,\nYearBuilt and GrgYearBuilt ,\nTotalBsmtSF and 1stFlrSF,\n2ndFloor and GrLivArea,\nwe will drop 'GrgYearBuilt','1stFlrSf','2ndFlrSf'","b4d40ea6":"We see that PoolQC, MiscFeature, Alley and Fence has a lot of Null values, so we will drop these columns","ca823082":"Filling Null values with 'Missing'"}}