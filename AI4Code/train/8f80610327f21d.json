{"cell_type":{"81e89ed4":"code","8655d8c4":"code","57114bcf":"code","75e9aed9":"code","0230da97":"code","a06d4c31":"code","7f113f8a":"code","7b8a970a":"code","42cf5133":"code","1618dc5a":"code","12804516":"code","46ad712a":"code","8a82c8eb":"code","78772fcc":"code","113914e8":"code","ff5e0856":"code","a7fe1184":"code","8986c73b":"code","8c3016a6":"code","a33f573c":"code","e163ad69":"code","eb3d1de4":"markdown","56e715cf":"markdown","c9bf2bdd":"markdown","a4db7a4f":"markdown","cd106e14":"markdown"},"source":{"81e89ed4":"#the data is deployed twice...\n!ls \/kaggle\/input\/skin-cancer-malignant-vs-benign\/","8655d8c4":"from fastai.vision import *\nimport torchvision","57114bcf":"path = Path('\/kaggle\/input\/skin-cancer-malignant-vs-benign\/data')\nclasses = ['malignant','benign']\nImageList.from_folder(path)","75e9aed9":"tfms = get_transforms(do_flip=True,flip_vert=True)\ndata = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n        .split_by_folder('train','test')              #How to split in train\/valid? -> use the folders\n        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n        .transform(tfms, size=224)       #Data augmentation? -> use tfms with a size of 64\n        .databunch(bs=32))","0230da97":"data","a06d4c31":"data.classes","7f113f8a":"data.show_batch(rows=3, figsize=(7,8))","7b8a970a":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","42cf5133":"# model loading implemented thanks to https:\/\/www.kaggle.com\/faizu07\/kannada-mnist-with-fastai\n!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp \/kaggle\/input\/fastai-pretrained-models\/resnet50-19c8e357.pth \/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\nlearn = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"),pretrained=True)","1618dc5a":"learn.summary() ","12804516":"learn.fit_one_cycle(10)","46ad712a":"learn.save('stage-1')","8a82c8eb":"learn.load('stage-1')\nlearn.unfreeze()","78772fcc":"learn.lr_find(start_lr=1e-9, end_lr=1e-1)","113914e8":"learn.recorder.plot(suggestion=True)","ff5e0856":"learn.fit_one_cycle(10, max_lr=slice(1e-04,1e-05)) ","a7fe1184":"!pwd","8986c73b":"learn.save('stage-2')\nlearn.export('skin_classifier.pkl')","8c3016a6":"learn.load('stage-2');interp = ClassificationInterpretation.from_learner(learn)","a33f573c":"interp.plot_confusion_matrix()","e163ad69":"interp.plot_top_losses(12)","eb3d1de4":"# Skin cancer classification with fastai library\n\nCheck out the awesome [fastai](https:\/\/docs.fast.ai) libary and the great [online courses](https:\/\/course.fast.ai\/). \n\nThe obtained accuracy with fastai is >90% using transfer learning with a pre-trained resnet50 and just a few lines of code!","56e715cf":"## Train model with transfer learning","c9bf2bdd":"Using the data_block api to create a databunch. The images in the test folder become the validation set.","a4db7a4f":"## Interpretation","cd106e14":"For pretrained==True -> check out the trainable layers, currently only  the batchnorm parameters and the last layer weights can be trained!"}}