{"cell_type":{"583f1197":"code","bcdda04c":"code","ff425f8b":"code","e92626a4":"code","36e1e544":"code","bbca074d":"code","28add44c":"code","1a68cc1c":"code","6913694d":"code","ebfa0637":"code","d28ddd50":"code","cd7a1c43":"code","16195be5":"code","12ad8ee1":"code","5270262a":"code","f2f3780f":"code","0a1aeb1f":"code","b4d24832":"code","45c2c7b1":"code","1b06eee2":"code","babf8685":"code","be003e90":"code","3929c8b4":"code","9be7b3d6":"code","9a3ce1ed":"code","e3a4f4ef":"code","dc88bd5e":"code","f2214b4b":"code","3fd00a7b":"code","2b408d35":"code","96392d70":"code","a2ffd2ff":"code","0f04a7b8":"code","f6480fa1":"code","78af453f":"code","7c651e41":"code","f95604af":"code","9205dbab":"code","616fba31":"code","acd7a1e4":"code","f831350e":"code","fe2e1463":"code","29705a6a":"code","09cd4d46":"code","6a7818ce":"code","de583eec":"code","1a5fc4d3":"code","b213e49b":"code","28b8975a":"code","515c9ff7":"code","4584a4d1":"code","7fd84dd1":"code","f8a28928":"code","0b522190":"code","4d280e36":"code","30083d68":"code","2f3bcaa1":"code","83337126":"code","b3df08fb":"code","5efa1e50":"code","e64a4dff":"code","b8b85ccc":"code","3c7c2476":"code","99cea722":"code","8a7c5dd4":"code","9e515dab":"code","2144df49":"code","39b44a14":"code","300e5f08":"code","aeac3800":"code","9b0ae0e6":"code","f2e8dde3":"code","b8baa064":"code","cc2802e8":"code","644e5917":"code","3f1e5167":"code","c33c19ac":"code","87a30e0b":"code","f5da3d7f":"markdown","c2d105e2":"markdown","c38554ac":"markdown","eec284b2":"markdown","cc957217":"markdown","cb4cb251":"markdown","b9077584":"markdown","ef8a8c6a":"markdown","705a1229":"markdown","a9ecb61e":"markdown","e7ca0f87":"markdown","5d0985cf":"markdown"},"source":{"583f1197":"from datetime import date, datetime, timedelta\nimport numpy as np\nimport pandas as pd","bcdda04c":"! ls ..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_daily_reports","ff425f8b":"! ls ..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_time_series","e92626a4":"latest_train_date = date(2020, 8, 1)","36e1e544":"confirmed = pd.read_csv(\"..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv\")\ndeaths    = pd.read_csv(\"..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv\")\n\nwk1_original_test  = pd.read_csv(\"..\/input\/covid19-forecasting-week-one-launch-data\/test.csv\")\nwk1_original_test.rename(columns={\"Province\/State\": \"Province_State\", \"Country\/Region\": \"Country_Region\"}, inplace=True)\nwk1_original_test.drop(columns=[\"Lat\", \"Long\"], inplace=True)\n\nwk2_original_test  = pd.read_csv(\"..\/input\/covid19-forecasting-week-two-launch-data\/test.csv\")\nwk3_original_test  = pd.read_csv(\"..\/input\/covid19-forecasting-week-three-launch-data\/test.csv\")\nwk4_original_test  = pd.read_csv(\"..\/input\/covid19-forecasting-week-four-launch-data\/test.csv\")","bbca074d":"## Commenting these for data updates after the competition close\n\n# assert datetime.strptime(confirmed.columns[-1], '%m\/%d\/%y').date() == latest_train_date\n# assert datetime.strptime(deaths.columns[-1], '%m\/%d\/%y').date() == latest_train_date","28add44c":"deaths.head()","1a68cc1c":"wk1_launch_date = date(2020, 3, 19)\nwk1_public_leaderboard_start_date = wk1_launch_date - timedelta(7)\nwk1_close_date = wk1_launch_date + timedelta(6)\nwk1_final_evaluation_start_date = wk1_launch_date + timedelta(7)\nwk1_final_evaluation_end_date = wk1_launch_date + timedelta(35)\n\nwk2_launch_date = date(2020, 3, 26)\nwk2_public_leaderboard_start_date = wk2_launch_date - timedelta(7)\nwk2_close_date = wk2_launch_date + timedelta(6)\nwk2_final_evaluation_start_date = wk2_launch_date + timedelta(7)\nwk2_final_evaluation_end_date = wk2_launch_date + timedelta(35)\n\nwk3_launch_date = date(2020, 4, 2)\nwk3_public_leaderboard_start_date = wk3_launch_date - timedelta(7)\nwk3_close_date = wk3_launch_date + timedelta(6)\nwk3_final_evaluation_start_date = wk3_launch_date + timedelta(7)\nwk3_final_evaluation_end_date = wk3_launch_date + timedelta(35)\n\nwk4_launch_date = date(2020, 4, 9)\nwk4_public_leaderboard_start_date = wk4_launch_date - timedelta(7)\nwk4_close_date = wk4_launch_date + timedelta(6)\nwk4_final_evaluation_start_date = wk4_launch_date + timedelta(7)\nwk4_final_evaluation_end_date = wk4_launch_date + timedelta(35)","6913694d":"confirmed.columns = list(confirmed.columns[:4]) + [datetime.strptime(d, \"%m\/%d\/%y\").date().strftime(\"%Y-%m-%d\") for d in confirmed.columns[4:]]\ndeaths.columns    = list(deaths.columns[:4])    + [datetime.strptime(d, \"%m\/%d\/%y\").date().strftime(\"%Y-%m-%d\") for d in deaths.columns[4:]]","ebfa0637":"deaths","d28ddd50":"# Filter out problematic data points (The West Bank and Gaza had a negative value, cruise ships were associated with Canada, etc.)\nremoved_states = \"Recovered|Grand Princess|Diamond Princess\"\nremoved_countries = \"US|The West Bank and Gaza\"\n\nconfirmed.rename(columns={\"Province\/State\": \"Province_State\", \"Country\/Region\": \"Country_Region\"}, inplace=True)\ndeaths.rename(columns={\"Province\/State\": \"Province_State\", \"Country\/Region\": \"Country_Region\"}, inplace=True)\nconfirmed = confirmed[~confirmed[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\ndeaths    = deaths[~deaths[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\nconfirmed = confirmed[~confirmed[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\ndeaths    = deaths[~deaths[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\n\nconfirmed.drop(columns=[\"Lat\", \"Long\"], inplace=True)\ndeaths.drop(columns=[\"Lat\", \"Long\"], inplace=True)","cd7a1c43":"us_keys = pd.read_csv(\"..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_daily_reports\/%s.csv\" % latest_train_date.strftime(\"%m-%d-%Y\"))\nus_keys = us_keys[us_keys[\"Country_Region\"]==\"US\"]\nus_keys = us_keys.groupby([\"Province_State\", \"Country_Region\"])[[\"Confirmed\", \"Deaths\"]].sum().reset_index()\n\nus_keys = us_keys[~us_keys.Province_State.str.match(\"Diamond Princess|Grand Princess|Recovered|Northern Mariana Islands|American Samoa\")].reset_index(drop=True)\nus_keys","16195be5":"confirmed = confirmed.append(us_keys[[\"Province_State\", \"Country_Region\"]], sort=False).reset_index(drop=True)\ndeaths = deaths.append(us_keys[[\"Province_State\", \"Country_Region\"]], sort=False).reset_index(drop=True)","12ad8ee1":"for col in confirmed.columns[2:]:\n    confirmed[col].fillna(0, inplace=True)\n    deaths[col].fillna(0, inplace=True)","5270262a":"confirmed","f2f3780f":"us_start_date = date(2020, 3, 10)\nday_date = us_start_date\n\nwhile day_date <= latest_train_date:\n    day = pd.read_csv(\"..\/input\/jhucovid19\/csse_covid_19_data\/csse_covid_19_daily_reports\/%s.csv\" % day_date.strftime(\"%m-%d-%Y\"))\n    \n    if \"Country\/Region\" in day.columns:\n        day.rename(columns={\"Country\/Region\": \"Country_Region\", \"Province\/State\": \"Province_State\"}, inplace=True)\n    \n    us = day[day[\"Country_Region\"]==\"US\"]\n    us = us.groupby([\"Province_State\", \"Country_Region\"])[[\"Confirmed\", \"Deaths\"]].sum().reset_index()\n    \n    unused_data = []\n    untouched_states = set(confirmed[confirmed[\"Country_Region\"]==\"US\"][\"Province_State\"])\n    \n    for (i, row) in us.iterrows():\n        if confirmed[(confirmed[\"Country_Region\"]==\"US\") & (confirmed[\"Province_State\"]==row[\"Province_State\"])].shape[0]==1:\n            confirmed.loc[(confirmed[\"Country_Region\"]==\"US\") & (confirmed[\"Province_State\"]==row[\"Province_State\"]), day_date.strftime(\"%Y-%m-%d\")] = row[\"Confirmed\"]\n            deaths.loc[(deaths[\"Country_Region\"]==\"US\") & (deaths[\"Province_State\"]==row[\"Province_State\"]), day_date.strftime(\"%Y-%m-%d\")] = row[\"Deaths\"]\n            untouched_states.remove(row[\"Province_State\"])\n        else:\n            unused_data.append(row[\"Province_State\"])\n            \n    print(day_date, \"Untouched\", untouched_states)\n    print(day_date, \"Unused\", unused_data)\n\n    day_date = day_date + timedelta(1)","0a1aeb1f":"confirmed","b4d24832":"deaths","45c2c7b1":"wk1_original_test","1b06eee2":"confirmed[confirmed[\"Province_State\"]==\"Puerto Rico\"]","babf8685":"# Correcting some location renames between week 1 and the current set\n# Aruba, Puerto Rico, Virgin Islands were all in as two separate duplicate locations for the original test set. Not correcting those\n\nwk1_confirmed = confirmed.copy()\nwk1_deaths = deaths.copy()\n\nwk1_confirmed.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_confirmed[\"Country_Region\"]==\"France\"), \"Province_State\"] = \"France\"\nwk1_deaths.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_deaths[\"Country_Region\"]==\"France\"), \"Province_State\"] = \"France\"\n\nwk1_confirmed.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_confirmed[\"Country_Region\"]==\"United Kingdom\"), \"Province_State\"] = \"United Kingdom\"\nwk1_deaths.loc[wk1_deaths[\"Province_State\"].isna() & (wk1_deaths[\"Country_Region\"]==\"United Kingdom\"), \"Province_State\"] = \"United Kingdom\"\n\nwk1_confirmed.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_confirmed[\"Country_Region\"]==\"Netherlands\"), \"Province_State\"] = \"Netherlands\"\nwk1_deaths.loc[wk1_deaths[\"Province_State\"].isna() & (wk1_deaths[\"Country_Region\"]==\"Netherlands\"), \"Province_State\"] = \"Netherlands\"\n\nwk1_confirmed.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_confirmed[\"Country_Region\"]==\"Denmark\"), \"Province_State\"] = \"Denmark\"\nwk1_deaths.loc[wk1_deaths[\"Province_State\"].isna() & (wk1_deaths[\"Country_Region\"]==\"Denmark\"), \"Province_State\"] = \"Denmark\"\n\nwk1_confirmed.loc[(wk1_confirmed[\"Province_State\"]==\"Greenland\") & (wk1_confirmed[\"Country_Region\"]==\"Denmark\"), \"Country_Region\"] = \"Greenland\"\nwk1_confirmed.loc[(wk1_confirmed[\"Province_State\"]==\"Greenland\") & (wk1_confirmed[\"Country_Region\"]==\"Greenland\"), \"Province_State\"] = np.nan\nwk1_deaths.loc[(wk1_deaths[\"Province_State\"]==\"Greenland\") & (wk1_deaths[\"Country_Region\"]==\"Denmark\"), \"Country_Region\"] = \"Greenland\"\nwk1_deaths.loc[(wk1_deaths[\"Province_State\"]==\"Greenland\") & (wk1_deaths[\"Country_Region\"]==\"Greenland\"), \"Province_State\"] = np.nan\n\nwk1_confirmed.loc[wk1_confirmed[\"Province_State\"].isna() & (wk1_confirmed[\"Country_Region\"]==\"Bahamas\"), \"Country_Region\"] = \"The Bahamas\"\nwk1_deaths.loc[wk1_deaths[\"Province_State\"].isna() & (wk1_deaths[\"Country_Region\"]==\"Bahamas\"), \"Country_Region\"] = \"The Bahamas\"","be003e90":"wk1_original_test[wk1_original_test[\"Province_State\"]==\"United States Virgin Islands\"]","3929c8b4":"case_locations = set([(wk1_confirmed.loc[i, \"Province_State\"], wk1_confirmed.loc[i, \"Country_Region\"]) for i in wk1_confirmed.index])\nwk1_original_test_locations = set([(wk1_original_test.loc[i, \"Province_State\"], wk1_original_test.loc[i, \"Country_Region\"]) for i in wk1_original_test.index])","9be7b3d6":"case_locations.difference(wk1_original_test_locations)","9a3ce1ed":"# Aruba, Puerto Rico, Virgin Islands were all in as two separate duplicate locations for the original test set. Not correcting those\n# Not correcting the cruise ship ones - those are messy to track and probably not helpful to forecast\n\nmissing_locations = wk1_original_test_locations.difference(case_locations)\nmissing_locations","e3a4f4ef":"# Map locations back to the original launch set\n\nwk1_confirmed = wk1_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(wk1_confirmed, on=[\"Province_State\", \"Country_Region\"], how=\"left\")\nwk1_deaths    = wk1_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(wk1_deaths,    on=[\"Province_State\", \"Country_Region\"], how=\"left\")","dc88bd5e":"# Change any missing data to 0 from locations that got dropped\n\nfor col in wk1_confirmed.columns[2:]:\n    wk1_confirmed[col].fillna(0, inplace=True)\n    wk1_deaths[col].fillna(0, inplace=True)","f2214b4b":"this_date = latest_train_date\n\nwhile this_date <= wk1_final_evaluation_end_date:\n    if this_date.strftime(\"%Y-%m-%d\") not in wk1_confirmed:\n        wk1_confirmed.insert(len(wk1_confirmed.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n        wk1_deaths.insert(len(wk1_deaths.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n    this_date = this_date + timedelta(1)","3fd00a7b":"wk1_confirmed_melted = wk1_confirmed.melt(wk1_confirmed.columns[:2], wk1_confirmed.columns[2:], \"Date\", \"ConfirmedCases\")\nwk1_deaths_melted = wk1_deaths.melt(wk1_deaths.columns[:2], wk1_deaths.columns[2:], \"Date\", \"Fatalities\")\n\nwk1_confirmed_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk1_deaths_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\n\nassert wk1_confirmed_melted.shape==wk1_deaths_melted.shape\nassert list(wk1_confirmed_melted[\"Province_State\"])==list(wk1_deaths_melted[\"Province_State\"])\nassert list(wk1_confirmed_melted[\"Country_Region\"])==list(wk1_deaths_melted[\"Country_Region\"])\nassert list(wk1_confirmed_melted[\"Date\"])==list(wk1_deaths_melted[\"Date\"])\n\nwk1_cases = wk1_confirmed_melted.merge(wk1_deaths_melted, on=[\"Province_State\", \"Country_Region\", \"Date\"], how=\"inner\")\n\nwk1_cases.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk1_cases.insert(0, \"Id\", range(1, wk1_cases.shape[0]+1))\nwk1_cases","2b408d35":"wk1_forecast = wk1_cases.loc[wk1_cases[\"Date\"]>=wk1_public_leaderboard_start_date.strftime(\"%Y-%m-%d\")].copy()\nwk1_forecast.drop(columns=\"Id\", inplace=True)\nwk1_forecast.insert(0, \"ForecastId\", range(1, wk1_forecast.shape[0]+1))\nwk1_forecast.insert(6, \"Usage\", \"Ignored\")\nwk1_forecast.loc[wk1_forecast[\"Date\"]<=min(latest_train_date, wk1_close_date).strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Public\"\nwk1_forecast.loc[(wk1_forecast[\"Date\"]>=wk1_final_evaluation_start_date.strftime(\"%Y-%m-%d\")) & (wk1_forecast[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")),\"Usage\"]=\"Private\"\n\nfor loc in missing_locations:\n    if (type(loc[0]) is not str) and np.isnan(loc[0]):\n        wk1_forecast.loc[(wk1_forecast[\"Province_State\"].isna()) & (wk1_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n    else:\n        wk1_forecast.loc[(wk1_forecast[\"Province_State\"]==loc[0]) & (wk1_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n\nwk1_forecast","96392d70":"# wk1_train = wk1_cases[wk1_cases[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")].copy()\n# wk1_train.to_csv(\"wk1_train.csv\", index=False)\n# wk1_train","a2ffd2ff":"# wk1_test = wk1_forecast[wk1_forecast.columns[:-3]].copy()\n# wk1_test.to_csv(\"wk1_test.csv\", index=False)\n# wk1_test","0f04a7b8":"# wk1_solution = wk1_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\n# wk1_solution[\"ConfirmedCases\"].fillna(1, inplace=True)\n# wk1_solution[\"Fatalities\"].fillna(1, inplace=True)\n# wk1_solution.to_csv(\"wk1_solution.csv\", index=False)\n# wk1_solution","f6480fa1":"# wk1_submission = wk1_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\n# wk1_submission[\"ConfirmedCases\"] = 1\n# wk1_submission[\"Fatalities\"] = 1\n# wk1_submission.to_csv(\"wk1_submission.csv\", index=False)\n\n# wk1_submission","78af453f":"# wk1_ca_cases = wk1_cases[(wk1_cases[\"Country_Region\"]==\"US\") & (wk1_cases[\"Province_State\"]==\"California\")].copy()\n# wk1_ca_cases[\"Id\"] = range(1, wk1_ca_cases.shape[0]+1)\n# wk1_ca_train = wk1_ca_cases[wk1_ca_cases[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")]\n# wk1_ca_train.to_csv(\"wk1_ca_train.csv\", index=False)\n# wk1_ca_train","7c651e41":"# wk1_ca_forecast = wk1_forecast[(wk1_forecast[\"Country_Region\"]==\"US\") & (wk1_forecast[\"Province_State\"]==\"California\")].copy()\n# wk1_ca_forecast[\"ForecastId\"] = range(1, wk1_ca_forecast.shape[0]+1)\n# wk1_ca_forecast","f95604af":"# wk1_ca_test = wk1_ca_forecast[wk1_ca_forecast.columns[:-3]].copy()\n# wk1_ca_test.to_csv(\"wk1_ca_test.csv\", index=False)\n# wk1_ca_test","9205dbab":"# wk1_ca_solution = wk1_ca_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\n# wk1_ca_solution[\"ConfirmedCases\"].fillna(1, inplace=True)\n# wk1_ca_solution[\"Fatalities\"].fillna(1, inplace=True)\n# wk1_ca_solution.to_csv(\"wk1_ca_solution.csv\", index=False)\n# wk1_ca_solution","616fba31":"# wk1_ca_submission = wk1_ca_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\n# wk1_ca_submission[\"ConfirmedCases\"] = 1\n# wk1_ca_submission[\"Fatalities\"] = 1\n# wk1_ca_submission.to_csv(\"wk1_ca_submission.csv\", index=False)\n# wk1_ca_submission","acd7a1e4":"wk2_original_test","f831350e":"case_locations = set([(confirmed.loc[i, \"Province_State\"], confirmed.loc[i, \"Country_Region\"]) for i in confirmed.index])\nwk2_original_test_locations = set([(wk2_original_test.loc[i, \"Province_State\"], wk2_original_test.loc[i, \"Country_Region\"]) for i in wk2_original_test.index])","fe2e1463":"case_locations.difference(wk2_original_test_locations)","29705a6a":"missing_locations = wk2_original_test_locations.difference(case_locations)\nmissing_locations","09cd4d46":"# Map locations back to the original launch set\n\nwk2_confirmed = wk2_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(confirmed, on=[\"Province_State\", \"Country_Region\"], how=\"left\")\nwk2_deaths    = wk2_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(deaths,    on=[\"Province_State\", \"Country_Region\"], how=\"left\")","6a7818ce":"# Change any missing data to 0 from locations that got dropped\n\nfor col in wk2_confirmed.columns[2:]:\n    wk2_confirmed[col].fillna(0, inplace=True)\n    wk2_deaths[col].fillna(0, inplace=True)","de583eec":"this_date = latest_train_date\n\nwhile this_date <= wk2_final_evaluation_end_date:\n    if this_date.strftime(\"%Y-%m-%d\") not in wk2_confirmed:\n        wk2_confirmed.insert(len(wk2_confirmed.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n        wk2_deaths.insert(len(wk2_deaths.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n    this_date = this_date + timedelta(1)","1a5fc4d3":"wk2_confirmed_melted = wk2_confirmed.melt(wk2_confirmed.columns[:2], wk2_confirmed.columns[2:], \"Date\", \"ConfirmedCases\")\nwk2_deaths_melted = wk2_deaths.melt(wk2_deaths.columns[:2], wk2_deaths.columns[2:], \"Date\", \"Fatalities\")\n\nwk2_confirmed_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk2_deaths_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\n\nassert wk2_confirmed_melted.shape==wk2_deaths_melted.shape\nassert list(wk2_confirmed_melted[\"Province_State\"])==list(wk2_deaths_melted[\"Province_State\"])\nassert list(wk2_confirmed_melted[\"Country_Region\"])==list(wk2_deaths_melted[\"Country_Region\"])\nassert list(wk2_confirmed_melted[\"Date\"])==list(wk2_deaths_melted[\"Date\"])\n\nwk2_cases = wk2_confirmed_melted.merge(wk2_deaths_melted, on=[\"Province_State\", \"Country_Region\", \"Date\"], how=\"inner\")\n\nwk2_cases.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk2_cases.insert(0, \"Id\", range(1, wk2_cases.shape[0]+1))\nwk2_cases","b213e49b":"wk2_forecast = wk2_cases[wk2_cases[\"Date\"]>=wk2_public_leaderboard_start_date.strftime(\"%Y-%m-%d\")].copy()\nwk2_forecast.drop(columns=\"Id\", inplace=True)\nwk2_forecast.insert(0, \"ForecastId\", range(1, wk2_forecast.shape[0]+1))\nwk2_forecast.insert(6, \"Usage\", \"Ignored\")\nwk2_forecast.loc[wk2_forecast[\"Date\"]<=min(latest_train_date, wk2_close_date).strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Public\"\nwk2_forecast.loc[(wk2_forecast[\"Date\"]>=wk2_final_evaluation_start_date.strftime(\"%Y-%m-%d\")) & (wk2_forecast[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")),\"Usage\"]=\"Private\"\n\nfor loc in missing_locations:\n    if (type(loc[0]) is not str) and np.isnan(loc[0]):\n        wk2_forecast.loc[(wk1_forecast[\"Province_State\"].isna()) & (wk2_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n    else:\n        wk2_forecast.loc[(wk1_forecast[\"Province_State\"]==loc[0]) & (wk2_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n\nwk2_forecast","28b8975a":"# wk2_train = wk2_cases[wk2_cases[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")].copy()\n# wk2_train.to_csv(\"train.csv\", index=False)\n# wk2_train","515c9ff7":"# wk2_test = wk2_forecast[wk2_forecast.columns[:-3]].copy()\n# wk2_test.to_csv(\"test.csv\", index=False)\n# wk2_test","4584a4d1":"# wk2_solution = wk2_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\n# wk2_solution[\"ConfirmedCases\"].fillna(1, inplace=True)\n# wk2_solution[\"Fatalities\"].fillna(1, inplace=True)\n# wk2_solution.to_csv(\"wk2_solution.csv\", index=False)\n# wk2_solution","7fd84dd1":"# wk2_submission = wk2_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\n# wk2_submission[\"ConfirmedCases\"] = 1\n# wk2_submission[\"Fatalities\"] = 1\n# wk2_submission.to_csv(\"wk2_submission.csv\", index=False)\n\n# wk2_submission","f8a28928":"wk3_original_test","0b522190":"case_locations = set([(confirmed.loc[i, \"Province_State\"], confirmed.loc[i, \"Country_Region\"]) for i in confirmed.index])\nwk3_original_test_locations = set([(wk3_original_test.loc[i, \"Province_State\"], wk3_original_test.loc[i, \"Country_Region\"]) for i in wk3_original_test.index])","4d280e36":"case_locations.difference(wk3_original_test_locations)","30083d68":"missing_locations = wk3_original_test_locations.difference(case_locations)\nmissing_locations","2f3bcaa1":"# Map locations back to the original launch set\n\nwk3_confirmed = wk3_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(confirmed, on=[\"Province_State\", \"Country_Region\"], how=\"left\")\nwk3_deaths    = wk3_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(deaths,    on=[\"Province_State\", \"Country_Region\"], how=\"left\")","83337126":"# Change any missing data to 0 from locations that got dropped\n\nfor col in wk3_confirmed.columns[2:]:\n    wk3_confirmed[col].fillna(0, inplace=True)\n    wk3_deaths[col].fillna(0, inplace=True)","b3df08fb":"this_date = latest_train_date\n\nwhile this_date <= wk3_final_evaluation_end_date:\n    if this_date.strftime(\"%Y-%m-%d\") not in wk3_confirmed:\n        wk3_confirmed.insert(len(wk3_confirmed.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n        wk3_deaths.insert(len(wk3_deaths.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n    this_date = this_date + timedelta(1)","5efa1e50":"wk3_confirmed_melted = wk3_confirmed.melt(wk3_confirmed.columns[:2], wk3_confirmed.columns[2:], \"Date\", \"ConfirmedCases\")\nwk3_deaths_melted = wk3_deaths.melt(wk3_deaths.columns[:2], wk3_deaths.columns[2:], \"Date\", \"Fatalities\")\n\nwk3_confirmed_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk3_deaths_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\n\nassert wk3_confirmed_melted.shape==wk3_deaths_melted.shape\nassert list(wk3_confirmed_melted[\"Province_State\"])==list(wk3_deaths_melted[\"Province_State\"])\nassert list(wk3_confirmed_melted[\"Country_Region\"])==list(wk3_deaths_melted[\"Country_Region\"])\nassert list(wk3_confirmed_melted[\"Date\"])==list(wk3_deaths_melted[\"Date\"])\n\nwk3_cases = wk3_confirmed_melted.merge(wk3_deaths_melted, on=[\"Province_State\", \"Country_Region\", \"Date\"], how=\"inner\")\n\nwk3_cases.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk3_cases.insert(0, \"Id\", range(1, wk3_cases.shape[0]+1))\nwk3_cases","e64a4dff":"wk3_forecast = wk3_cases[wk3_cases[\"Date\"]>=wk3_public_leaderboard_start_date.strftime(\"%Y-%m-%d\")].copy()\nwk3_forecast.drop(columns=\"Id\", inplace=True)\nwk3_forecast.insert(0, \"ForecastId\", range(1, wk3_forecast.shape[0]+1))\nwk3_forecast.insert(6, \"Usage\", \"Ignored\")\nwk3_forecast.loc[wk3_forecast[\"Date\"]<=min(latest_train_date, wk3_close_date).strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Public\"\nwk3_forecast.loc[(wk3_forecast[\"Date\"]>=wk3_final_evaluation_start_date.strftime(\"%Y-%m-%d\")) & (wk3_forecast[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")),\"Usage\"]=\"Private\"\n\nfor loc in missing_locations:\n    if (type(loc[0]) is not str) and np.isnan(loc[0]):\n        wk3_forecast.loc[(wk1_forecast[\"Province_State\"].isna()) & (wk3_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n    else:\n        wk3_forecast.loc[(wk1_forecast[\"Province_State\"]==loc[0]) & (wk3_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n\nwk3_forecast","b8b85ccc":"# wk3_train = wk3_cases[wk3_cases[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")]\n# wk3_train.to_csv(\"train.csv\", index=False)\n# wk3_train","3c7c2476":"# wk3_test = wk3_forecast[wk3_forecast.columns[:-3]]\n# wk3_test.to_csv(\"test.csv\", index=False)\n# wk3_test","99cea722":"# wk3_solution = wk3_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\n# wk3_solution[\"ConfirmedCases\"].fillna(1, inplace=True)\n# wk3_solution[\"Fatalities\"].fillna(1, inplace=True)\n# wk3_solution.to_csv(\"wk3_solution.csv\", index=False)\n# wk3_solution","8a7c5dd4":"# wk3_submission = wk3_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\n# wk3_submission[\"ConfirmedCases\"] = 1\n# wk3_submission[\"Fatalities\"] = 1\n# wk3_submission.to_csv(\"wk3_submission.csv\", index=False)\n\n# wk3_submission","9e515dab":"wk4_original_test","2144df49":"case_locations = set([(confirmed.loc[i, \"Province_State\"], confirmed.loc[i, \"Country_Region\"]) for i in confirmed.index])\nwk4_original_test_locations = set([(wk4_original_test.loc[i, \"Province_State\"], wk4_original_test.loc[i, \"Country_Region\"]) for i in wk4_original_test.index])","39b44a14":"case_locations.difference(wk4_original_test_locations)","300e5f08":"missing_locations = wk4_original_test_locations.difference(case_locations)\nmissing_locations","aeac3800":"# Map locations back to the original launch set\n\nwk4_confirmed = wk4_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(confirmed, on=[\"Province_State\", \"Country_Region\"], how=\"left\")\nwk4_deaths    = wk4_original_test[[\"Province_State\", \"Country_Region\"]].drop_duplicates().reset_index(drop=True).merge(deaths,    on=[\"Province_State\", \"Country_Region\"], how=\"left\")","9b0ae0e6":"# Change any missing data to 0 from locations that got dropped\n\nfor col in wk4_confirmed.columns[2:]:\n    wk4_confirmed[col].fillna(0, inplace=True)\n    wk4_deaths[col].fillna(0, inplace=True)","f2e8dde3":"this_date = latest_train_date\n\nwhile this_date <= wk4_final_evaluation_end_date:\n    if this_date.strftime(\"%Y-%m-%d\") not in wk4_confirmed:\n        wk4_confirmed.insert(len(wk4_confirmed.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n        wk4_deaths.insert(len(wk4_deaths.columns), this_date.strftime(\"%Y-%m-%d\"), np.NaN)\n    this_date = this_date + timedelta(1)","b8baa064":"wk4_confirmed_melted = wk4_confirmed.melt(wk4_confirmed.columns[:2], wk4_confirmed.columns[2:], \"Date\", \"ConfirmedCases\")\nwk4_deaths_melted = wk4_deaths.melt(wk4_deaths.columns[:2], wk4_deaths.columns[2:], \"Date\", \"Fatalities\")\n\nwk4_confirmed_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk4_deaths_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\n\nassert wk4_confirmed_melted.shape==wk4_deaths_melted.shape\nassert list(wk4_confirmed_melted[\"Province_State\"])==list(wk4_deaths_melted[\"Province_State\"])\nassert list(wk4_confirmed_melted[\"Country_Region\"])==list(wk4_deaths_melted[\"Country_Region\"])\nassert list(wk4_confirmed_melted[\"Date\"])==list(wk4_deaths_melted[\"Date\"])\n\nwk4_cases = wk4_confirmed_melted.merge(wk4_deaths_melted, on=[\"Province_State\", \"Country_Region\", \"Date\"], how=\"inner\")\n\nwk4_cases.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\nwk4_cases.insert(0, \"Id\", range(1, wk4_cases.shape[0]+1))\nwk4_cases","cc2802e8":"wk4_forecast = wk4_cases[wk4_cases[\"Date\"]>=wk4_public_leaderboard_start_date.strftime(\"%Y-%m-%d\")].copy()\nwk4_forecast.drop(columns=\"Id\", inplace=True)\nwk4_forecast.insert(0, \"ForecastId\", range(1, wk4_forecast.shape[0]+1))\nwk4_forecast.insert(6, \"Usage\", \"Ignored\")\nwk4_forecast.loc[wk4_forecast[\"Date\"]<=min(latest_train_date, wk4_close_date).strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Public\"\nwk4_forecast.loc[(wk4_forecast[\"Date\"]>=wk4_final_evaluation_start_date.strftime(\"%Y-%m-%d\")) & (wk4_forecast[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")),\"Usage\"]=\"Private\"\n\nfor loc in missing_locations:\n    if (type(loc[0]) is not str) and np.isnan(loc[0]):\n        wk4_forecast.loc[(wk1_forecast[\"Province_State\"].isna()) & (wk4_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n    else:\n        wk4_forecast.loc[(wk1_forecast[\"Province_State\"]==loc[0]) & (wk4_forecast[\"Country_Region\"]==loc[1]), \"Usage\"]=\"Ignored\"\n\nwk4_forecast","644e5917":"wk4_train = wk4_cases[wk4_cases[\"Date\"]<=latest_train_date.strftime(\"%Y-%m-%d\")]\n# wk4_train.to_csv(\"train.csv\", index=False)\nwk4_train.to_csv(\"actuals.csv\", index=False)\nwk4_train","3f1e5167":"# wk4_test = wk4_forecast[wk4_forecast.columns[:-3]]\n# wk4_test.to_csv(\"test.csv\", index=False)\n# wk4_test","c33c19ac":"# wk4_solution = wk4_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\n# wk4_solution[\"ConfirmedCases\"].fillna(1, inplace=True)\n# wk4_solution[\"Fatalities\"].fillna(1, inplace=True)\n# wk4_solution.to_csv(\"wk4_solution.csv\", index=False)\n# wk4_solution","87a30e0b":"# wk4_submission = wk4_forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\n# wk4_submission[\"ConfirmedCases\"] = 1\n# wk4_submission[\"Fatalities\"] = 1\n# wk4_submission.to_csv(\"wk4_submission.csv\", index=False)\n# wk4_submission.to_csv(\"submission.csv\", index=False)\n# wk4_submission","f5da3d7f":"### Week 1 Global competition data","c2d105e2":"Move to ISO 8601 dates","c38554ac":"# COVID-19 Forecasting Ongoing Data Updates\n\nThis notebook prepares the daily updates and leaderboards scores in Kaggle's COVID-19 forecasting competitions:\n\n - [Week 2](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-2) (global, currently open for submissions)\n - Week 1 ([global](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-1), [California state](https:\/\/www.kaggle.com\/c\/covid19-local-us-ca-forecasting-week-1\/overview\/description)) (closed for submissions; currently in final evaluation scoring)\n \nThe source data comes from [JHU CSSE's COVID-19 data repository on GitHub](https:\/\/github.com\/CSSEGISandData\/COVID-19).\n\nThe notebooks used to prepare the original data at the launch of the competition are here: [Week 1](https:\/\/www.kaggle.com\/benhamner\/covid-19-forecasting-challenges-week-1-data-prep), [Week 2](https:\/\/www.kaggle.com\/benhamner\/covid-19-forecasting-challenges-week-2-data-prep)","eec284b2":"# Leaderboard Updates for Week 1","cc957217":"## Update this date!","cb4cb251":"### Week 1 California competition data","b9077584":"# Data Updates for Week 2","ef8a8c6a":"Melting the data to a version that will be friendlier to Kaggle's evaluation system.","705a1229":"Adding the rows to be forecast","a9ecb61e":"# Data Updates for Week 4","e7ca0f87":"Add in daily US data","5d0985cf":"# Data Updates for Week 3"}}