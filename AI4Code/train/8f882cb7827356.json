{"cell_type":{"caef0257":"code","485353e1":"code","74439fad":"code","93f29a2d":"code","6d8fabd0":"code","2883f7a6":"code","5b30c6fd":"code","8d967947":"code","5486513c":"code","ed8bb085":"code","fcf2f14e":"code","b3c3870a":"code","7108ac10":"code","deecb5f5":"code","552d8738":"code","8f52895c":"code","932f005e":"code","ff8cb5cc":"code","46421efd":"code","0e76b0fa":"markdown"},"source":{"caef0257":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","485353e1":"!ls ","74439fad":"import tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nimport os\nimport time\nimport cv2\nfrom PIL import Image \nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, mean_absolute_error\n","93f29a2d":"BATCH_SIZE = 16\nEPOCHS = 30\nIMG_SIZE = 256\nbase_dir='..\/input\/accident-detection-from-cctv-footage\/data'\nLABELS=['Accident','Non Accident']\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')","6d8fabd0":"def labelseperator(data_dir):\n    data = []\n    for label in LABELS:\n        path = os.path.join(data_dir, label)\n        class_num = LABELS.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n                data.append([img_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","2883f7a6":"train= labelseperator(train_dir)\nval=labelseperator(val_dir)\ntest=labelseperator(test_dir)","5b30c6fd":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature in train:\n    x_train.append(feature)\nfor label in train:\n    y_train.append(label)\nfor feature in test:\n    x_test.append(feature)\nfor label in test:\n    y_test.append(label)\nfor feature in val: \n    x_val.append(feature)\nfor label in val:\n    y_val.append(label)\n","8d967947":"print(len(x_train))\nprint(len(y_train))","5486513c":"# Normalize the data\nx_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/ 255\nx_test = np.array(x_test) \/ 255\n\n","ed8bb085":"print(len(x_train))\nprint(len(y_train))","fcf2f14e":"fig, ax = plt.subplots(1, 4, figsize=(12, 12))\nax = ax.flatten()\nax[0].imshow(val[11][0], cmap='viridis')\nax[0].set_title(LABELS[val[0][1]])\nax[1].imshow(val[2][0], cmap='viridis')\nax[1].set_title(LABELS[val[14][1]])\nax[2].imshow(val[6][0], cmap='viridis')\nax[2].set_title(LABELS[val[6][1]])\nax[3].imshow(val[3][0], cmap='viridis')\nax[3].set_title(LABELS[val[11][1]])\nplt.tight_layout()\nplt.show()","b3c3870a":"imgdatagen=ImageDataGenerator(horizontal_flip=True, zoom_range=0.2, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1)\ntrain_data_gen = imgdatagen.flow_from_directory(\n    batch_size = BATCH_SIZE,\n    directory = train_dir,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    color_mode = 'grayscale'\n)\n\nval_data_gen = val_data_gen = imgdatagen.flow_from_directory(\n    batch_size = BATCH_SIZE,\n    directory = val_dir,\n    class_mode = 'categorical',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    color_mode = 'grayscale'\n)\n\ntest_data_gen = train_data_gen = imgdatagen.flow_from_directory(\n    batch_size = BATCH_SIZE,\n    directory = test_dir,\n    class_mode = 'categorical',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    color_mode = 'grayscale'\n)","7108ac10":"def plot_augmented_img(img_arr):\n    fig, axs = plt.subplots(1, 5, figsize=(20, 20))\n    axs = axs.flatten()\n    for img, ax in zip(img_arr, axs):\n        ax.imshow(np.squeeze(img), cmap='viridis')\n    plt.tight_layout()\n    plt.show()","deecb5f5":"train_aug_imgs = [train_data_gen[0][0][0] for i in range(5)]\nplot_augmented_img(train_aug_imgs)","552d8738":"callback = []\ncallback.append(ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001))\ncallback.append(ModelCheckpoint('model-checkpoint.h5', monitor='val_loss', save_best_only=True))\ncallback.append(EarlyStopping(patience=30, monitor='val_loss'))","8f52895c":"model = Sequential([\n    Conv2D(32, (3, 3), strides=1, padding='same', activation='selu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n    \n    BatchNormalization(),\n    MaxPooling2D((2, 2), strides=2, padding='same'),\n    \n    Conv2D(64, (3, 3), strides=1, padding='same', activation='selu'),\n    Dropout(0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2), strides=2, padding='same'),\n    \n    \n    Conv2D(64, (3, 3), strides=1, padding='same', activation='selu'),\n    \n    BatchNormalization(),\n    MaxPooling2D((2, 2), strides=2, padding='same'),\n    \n    \n    Flatten(),\n    Dense(units=256, activation='selu'),\n    \n    Dense(units=128, activation='selu'),\n    \n    Dense(units=2, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","932f005e":"history = model.fit(\n    x= train_data_gen, batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=val_data_gen,\n    callbacks=[callback]\n)\n\nt = time.time()\nexport_path_keras = \".\/AccidentDetection-{}.h5\".format(int(t))\nmodel.save(export_path_keras)","ff8cb5cc":"model = keras.models.load_model('.\/model-checkpoint.h5')","46421efd":"epoch_range = range(10)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","0e76b0fa":"Now with the proof of concept completed I will attempt to build non sequential models"}}