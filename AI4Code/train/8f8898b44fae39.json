{"cell_type":{"266d420c":"code","8bd9c998":"code","8bb86558":"code","33f3d7b2":"code","7c7acce0":"code","5f31cd58":"code","1b736d7d":"code","2bbb455d":"code","c684b234":"code","35022e64":"code","e876036a":"code","25ab712e":"code","b2fbca09":"code","c7000908":"code","d7268104":"code","ce58817e":"code","da1505f7":"code","3165d4de":"code","6381c5b7":"code","9e2d099e":"code","08bd9c1c":"code","0b982313":"code","cf23073a":"code","8d43c1c8":"code","5408f974":"code","f5333ca7":"code","a93326f4":"code","3b163b77":"code","641f2cd4":"code","340a5eb1":"code","482b2101":"code","78f9506b":"code","0c4bd6b5":"code","8e79a633":"code","46f22d42":"code","58e2d28f":"code","a068dc2d":"code","501393a9":"code","f7db18b0":"code","c66e7288":"markdown","693ca695":"markdown","ece4b878":"markdown","0a53d96b":"markdown","ebb51e3d":"markdown","e9bd3cc2":"markdown","73ba66b2":"markdown","079f8c46":"markdown","a675dbf7":"markdown"},"source":{"266d420c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bd9c998":"df = pd.read_csv(\"\/kaggle\/input\/body-fat-prediction-dataset\/bodyfat.csv\")","8bb86558":"df","33f3d7b2":"df = df.drop([\"Density\", \"BodyFat\"], axis = 1)","7c7acce0":"df.describe()","5f31cd58":"df.info()","1b736d7d":"#removing outliers (using 1.5 * IQR rule) in all columns of dataframe\ndef remove_outlier(df_in):\n    for column in df_in.columns:\n        q1 = df_in[column].quantile(0.25)\n        q3 = df_in[column].quantile(0.75)\n        iqr = q3-q1 #Interquartile range\n        fence_low  = q1-1.5*iqr\n        fence_high = q3+1.5*iqr\n        df_in[column] = df_in.loc[(df_in[column] > fence_low) & (df_in[column] < fence_high)][column]\n    return df_in\ndf = remove_outlier(df)\n\n#remove null values\ndf = df.dropna()","2bbb455d":"#adding a size (XS, S, M, L, XL) to each row of the dataset using Ralph Lauren sizing chart\n#https:\/\/www.ralphlauren.com\/size-guide\/size-guide.html\n\ndef ralph_size(x):\n    i = x[\"Chest\"]\n    if i <= 86.4:\n        return \"XS\"\n    elif i > 86.4 and i <= 94:\n        return \"S\"\n    elif i > 94 and i <= 101.6:\n        return \"M\"\n    elif i > 101.6 and i <= 114.3:\n        return \"L\"\n    elif i > 114.3 and i <= 121.9:\n        return \"XL\"\n    else:\n        return \"XXL\"\n    \n    \ndf[\"Size\"] = df.apply(ralph_size, axis = 1)\ndf","c684b234":"#normalized\ndf_norm = df.drop(\"Size\", axis = 1)\nfor i in df_norm:\n    df_norm[i] = (df_norm[i] - np.mean(df_norm[i]) )\/ np.std(df_norm[i])\ndf_norm[\"Size\"] = df[\"Size\"]\ndf_norm.head()","35022e64":"sns.pairplot(data = df)","e876036a":"sns.scatterplot(data = df, x = \"Chest\",y = \"Weight\", hue = \"Size\")","25ab712e":"sns.scatterplot(data = df, x = \"Abdomen\",y = \"Weight\", hue = \"Size\")","b2fbca09":"sns.scatterplot(data = df, x = \"Height\",y = \"Weight\", hue = \"Size\")\n#weight donomiant ","c7000908":"sns.scatterplot(data = df, x = \"Hip\",y = \"Abdomen\", hue = \"Size\")","d7268104":"sns.boxplot(data  = df, x = \"Hip\", y = \"Size\")","ce58817e":"sns.boxplot(data = df, x = \"Chest\", y = \"Size\")","da1505f7":"sns.boxplot(data = df, x = \"Abdomen\", y = \"Size\")","3165d4de":"sns.boxplot(data = df, x = \"Abdomen\", y = \"Size\")","6381c5b7":"sns.boxplot(data = df, x = \"Height\", y = \"Size\")","9e2d099e":"#decision tree predicting size from other variables\nfrom sklearn import tree\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\n\n\n#sns_cmap = ListedColormap(np.array(sns.color_palette())[0:5, :])\nplt.figure(figsize=(25,10))\n\nfeatures = df.drop(\"Size\", axis = 1)[[\"Height\", \"Weight\", \"Abdomen\", \"Neck\", \"Forearm\", \"Ankle\", \"Thigh\"]] #higher accuracy without biceps, wrist\nresult = df[\"Size\"]\n\nvar_train, var_test, res_train, res_test = train_test_split(features, result, test_size = 0.3)\n\ndecision_tree_model = tree.DecisionTreeClassifier(random_state = 42, criterion = \"gini\", max_depth = 3)\ndecision_tree_model.fit(var_train, res_train)\ntree.plot_tree(decision_tree_model, fontsize = 12);\n\nscore = decision_tree_model.score(var_test, res_test)\nprint(\"Score: \", score)","08bd9c1c":"#The shape between Ankle and other variables like very alike. ","0b982313":"df.corrwith(df[\"Hip\"])","cf23073a":"# Compute the correlation matrix by applying .corr() \ncorr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","8d43c1c8":"X = df.drop(\"Chest\", axis = 1)\ny = df[\"Chest\"]","5408f974":"from sklearn.model_selection import train_test_split\n\n# choose a test size of 0.2\nX_training, X_test, y_training, y_test = train_test_split(X, y, test_size = 0.2)\nX_test.head()","f5333ca7":"validation_size = int(X_training.shape[0] * 0.10) # select 10% of the training set to be our validation set\n\narr = np.arange(len(X_training)) # create an array with values from 0 to the training set size (right exclusive)\nvalidation_idxs = np.random.choice(arr, validation_size) # select validation_size idxs from the above array\n\nbool_in_validation = np.in1d(arr, validation_idxs) # boolean array if an index is in the validation set\n\nX_val = X_training.iloc[validation_idxs]\ny_val = y_training.iloc[validation_idxs]\n\nX_train = X_training[~bool_in_validation]\ny_train = y_training[~bool_in_validation]\nX_train.head()","a93326f4":"#based on heatmap, pick the one that has high correlation\nfeatures = [\"Neck\",\"Abdomen\", \"Hip\", 'Thigh', \"Knee\", \"Biceps\", \"Weight\"]","3b163b77":"from sklearn.linear_model import LinearRegression\n\n# initialize your linear regression model\nreg = LinearRegression()\n\n# select your feature subset to train your model on\nX_features_selected = X_train[features]\n\n# fit your model using the .fit method\nmodel = reg.fit(X_features_selected, y_train)\n\n# compute the coefficient of determination, R^2 for your model\nr2 = model.score(X_features_selected, y_train)\nprint('Training R^2: {}'.format(r2))","641f2cd4":"#compute rmse\n\ndef rmse(y_pred, y_true):\n    \"\"\"\n    Args:\n    - y_pred : an array like object of predicted response variables\n    - y_true: an array like object of actual response variables\n    \n    Returns: RMSE of predictions\n    \"\"\"\n    residuals = y_pred - y_true\n    squared_error = sum(i*i for i in residuals)\n    mean_squared_error = squared_error \/ len(residuals)\n    return np.sqrt(abs(mean_squared_error))","340a5eb1":"# calculate training RMSE\ny_pred_training = model.predict(X_features_selected) # use .predict on your selected X features\ntraining_rmse = rmse(y_pred_training, y_train)\nprint(\"Training RMSE: {}\".format(training_rmse))","482b2101":"# calculate validation R2, RMSE\nX_valid_features = X_val[features] \ny_pred_validation = model.predict(X_valid_features) # predict for the validation set\nvalidation_rmse = rmse(y_pred_validation, y_val)\nprint(\"Validation RMSE: {}\".format(validation_rmse))","78f9506b":"df = pd.concat([pd.Series(1, index=df.index, name='00'), df], axis=1)\ndf.head()","0c4bd6b5":"X = df.drop(\"Chest\", axis = 1)\ny = df[\"Chest\"]","8e79a633":"X = df.drop(\"Chest\", axis = 1)\ny = df[\"Chest\"]","46f22d42":"from sklearn.model_selection import train_test_split\n\n# choose a test size of 0.2\nX_training, X_test, y_training, y_test = train_test_split(X, y, test_size = 0.2)\nX_test.head()","58e2d28f":"features = [\"Weight\", \"Height\", \"Neck\", \"Abdomen\", \"Hip\", \"Thigh\", \"Knee\", \"Ankle\", \"Biceps\", \"Forearm\", \"Wrist\"]","a068dc2d":"validation_size = int(X_training.shape[0] * 0.10) # select 10% of the training set to be our validation set\n\narr = np.arange(len(X_training)) # create an array with values from 0 to the training set size (right exclusive)\nvalidation_idxs = np.random.choice(arr, validation_size) # select validation_size idxs from the above array\n\nbool_in_validation = np.in1d(arr, validation_idxs) # boolean array if an index is in the validation set\n\nX_val = X_training.iloc[validation_idxs]\ny_val = y_training.iloc[validation_idxs]\n\nX_train = X_training[~bool_in_validation]\ny_train = y_training[~bool_in_validation]\nX_train.head()","501393a9":"from sklearn.linear_model import LinearRegression\n\n# initialize your linear regression model\nreg = LinearRegression()\n\n# select your feature subset to train your model on\nX_features_selected = X_train[features]\n\n# fit your model using the .fit method\nmodel = reg.fit(X_features_selected, y_train)\n\n# compute the coefficient of determination, R^2 for your model\nr2 = model.score(X_features_selected, y_train)\nprint('Training R^2: {}'.format(r2))","f7db18b0":"y_pred_training = model.predict(X_features_selected) # use .predict on your selected X features\ntraining_rmse = rmse(y_pred_training, y_train)\nprint(\"Training RMSE: {}\".format(training_rmse))","c66e7288":"****heatmap (visualized correlation)****","693ca695":"**Multivariate Linear Regression** https:\/\/towardsdatascience.com\/multivariate-linear-regression-in-python-step-by-step-128c2b127171","ece4b878":"**create a cross validation**","0a53d96b":"correlation calculation","ebb51e3d":"Data Cleaning","e9bd3cc2":"Drop Age since there is no relationship\n","73ba66b2":"EDA","079f8c46":"GRAPHS","a675dbf7":"men core measurement: collar, chest, sleeve, waist, inside leg, outside leg"}}