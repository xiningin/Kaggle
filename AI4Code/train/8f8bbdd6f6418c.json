{"cell_type":{"22b3ec86":"code","e56c1aeb":"code","61e49408":"code","18180839":"code","53c67c7c":"code","8a5f7c9b":"code","e8446432":"code","6e7734ff":"code","50a7fdcc":"code","cbe6a4e6":"code","6504deae":"code","5c5768c3":"code","d3550007":"code","35764472":"code","764d243c":"code","1e24a4d6":"code","b16c1ebf":"code","47360b61":"code","ea3d563c":"code","2d40f072":"code","867290bc":"code","00cb3407":"markdown"},"source":{"22b3ec86":"import pandas as pd\nimport numpy as np\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import InputLayer, MaxPooling2D, Flatten, Dense, Conv2D, Dropout\nfrom keras.losses import SparseCategoricalCrossentropy\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\nfrom tensorflow.keras.optimizers import Adam","e56c1aeb":"TRAIN_PATH = '..\/input\/intel-image-classification\/seg_train\/seg_train'\nTEST_PATH = '..\/input\/intel-image-classification\/seg_test\/seg_test'\nPRED_PATH = '..\/input\/intel-image-classification\/seg_pred\/seg_pred'\nIMG_WIDTH=96\nIMG_HEIGHT=96\nbatch_size = 128\n","61e49408":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport random\nimport os\nfrom IPython.display import Image\nplt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/intel-image-classification\/seg_train\/seg_train\/sea\"\nfor i in range(9):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(3,3,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","18180839":"import cv2\ndef create_dataset(img_folder):\n    img_data_array = []\n    class_name = []\n    for dir1 in os.listdir(img_folder):\n        print(dir1)\n        for file in os.listdir(os.path.join(img_folder, dir1)):\n            image_path= os.path.join(img_folder, dir1,  file)\n            image= cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n            image=np.array(image)\n            image = image.astype('float32')\n            image \/= 255\n            img_data_array.append(image)\n            class_name.append(dir1)\n    img_data_array = np.array(img_data_array, dtype=\"float32\")\n    class_name = np.array(class_name)\n    return img_data_array, class_name","53c67c7c":"img_data, class_name = create_dataset(TRAIN_PATH)","8a5f7c9b":"from sklearn.utils import shuffle \nimg_data, class_name = shuffle(img_data, class_name, random_state=25)\n\ntarget_dict={k: v for v, k in enumerate(np.unique(class_name))}\ntarget_val =  [target_dict[class_name[i]] for i in range(len(class_name))]\ntarget_dict","e8446432":"def model(input_shape):\n    \n    res_conv = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), pooling=None, classes=1000)\n    \n    model = Sequential()\n    model.add(res_conv)\n    \n    model.add(Conv2D(32, kernel_size=3, strides=(2, 2), padding=\"same\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(32, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n            \n    model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n    \n    model.add(Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n    \n    model.add(Conv2D(256, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(Conv2D(256, kernel_size=3, strides=(2, 2), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding='same'))\n    \n    model.add(Flatten())\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.8))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.8))\n    model.add(Dense(6))\n    \n    return model","6e7734ff":"model = model(input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\nmodel.summary()","50a7fdcc":"optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\",)\nloss_fn = SparseCategoricalCrossentropy(from_logits=True)","cbe6a4e6":"model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])","6504deae":"EPOCHS = 10","5c5768c3":"history = model.fit(x=np.array(img_data, np.float32), y=np.array(list(map(int,target_val)), np.float32), epochs=EPOCHS, batch_size=3)","d3550007":"model.save(\"IntelCNNepoch30v7Resnet\")","35764472":"!tar -zcvf IntelCNNepoch30v7Resnet.tar.gz \/kaggle\/working\/IntelCNNepoch30v7Resnet","764d243c":"history.history","1e24a4d6":"loss = history.history[\"loss\"]\nacc = history.history[\"accuracy\"]","b16c1ebf":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, loss)\n# plt.plot(epoch, val_loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend(['train', 'val'])","47360b61":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, acc, color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy');","ea3d563c":"pred_img_data, pred_class_name = create_dataset(TEST_PATH)","2d40f072":"pred_target_dict={k: v for v, k in enumerate(np.unique(pred_class_name))}\npred_target_val =  [pred_target_dict[pred_class_name[i]] for i in range(len(pred_class_name))]\npred_target_dict","867290bc":"test_scores = model.evaluate(np.array(pred_img_data, np.float32), np.array(list(map(int,pred_target_val)), np.float32), verbose=2)\nprint(\"Test loss:\", test_scores[0])\nprint(\"Test accuracy:\", test_scores[1])","00cb3407":"# Resnet 50 model"}}