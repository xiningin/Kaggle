{"cell_type":{"16c7c8cd":"code","6948fd9a":"code","ba16e950":"code","3441e0f8":"code","19f2d5e2":"code","73fb4137":"code","0382740e":"code","a5e685aa":"code","1badfdaa":"code","96a3f896":"code","7e63233e":"code","8314e6b7":"code","a4574b3d":"code","c312ffbe":"code","ca25a591":"code","4b8dae73":"code","8b8087d0":"code","f51f2988":"code","9bafe370":"code","b2aeed65":"code","c0bb9588":"code","81cd63ba":"code","9e53f3e7":"code","9a6aa9ec":"code","3644095e":"code","61055f9b":"code","90baff2e":"code","5307b40e":"code","249a169f":"code","8fe59934":"markdown","6bf61570":"markdown","351c996b":"markdown","0942a18f":"markdown","1217d39e":"markdown","6ef4cf00":"markdown","1173c8eb":"markdown","aa38d16e":"markdown","0389ab3e":"markdown","fe9eb420":"markdown","e111418c":"markdown","84900e62":"markdown","89208aed":"markdown"},"source":{"16c7c8cd":"import numpy as np\nimport pandas as pd \nimport math\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","6948fd9a":"data = pd.read_csv(\"..\/input\/train.csv\",nrows = (10 ** 7))\nprint(\"shape of train data\", data.shape)\n\ninitial = len(data)\ndata.sample(10)","ba16e950":"data.describe()","3441e0f8":"data.isnull().sum()","19f2d5e2":"data = data[data.fare_amount >0] ## negative ones\ndata = data.dropna(how='any', axis=0) ## Null values\n\nprint(len(data))","73fb4137":"plt.figure(figsize= (12,4))\nsns.distplot(data['passenger_count'],hist=False )\nplt.show()\n#data[data.passenger_count>0].passenger_count.hist(bins=10, figsize = (16,8))\n#plt.xlabel(\"Passanger Count\")\n#plt.ylabel(\"Frequency\")\n#plt.show()","0382740e":"print(len(data[data.passenger_count >6]))","a5e685aa":"data = data.drop(index= data[data.passenger_count >= 7].index, axis=0)\nprint(len(data))","1badfdaa":"plt.figure(figsize= (16,8))\nsns.boxplot(x = data[data.passenger_count<7].passenger_count, y = data.fare_amount)\nplt.show()","96a3f896":"corr = data.corr()\nplt.figure(figsize=(8,6))\nsns.heatmap(data=corr, square=True , annot=True, cbar=True)\nplt.show()","7e63233e":"#our test data\n\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"shape of test data\", test.shape)\ntest.sample(5)","8314e6b7":"test.isnull().sum()\n#it seems there in no null values in test dataset","a4574b3d":"test.describe()","c312ffbe":"print(\"_____Longitudes_____\")\nprint(min(test.pickup_longitude.min(),test.dropoff_longitude.min()), \\\nmax(test.pickup_longitude.max(),test.dropoff_longitude.max()))\nprint(\"\\n\")\n\n\nprint(\"_____Latitudes_____\")\nprint(min(test.pickup_latitude.min(),test.dropoff_latitude.min()), \\\nmax(test.pickup_latitude.max(),test.dropoff_latitude.max()))\n","ca25a591":"data = data[(data.pickup_longitude >= -74.27) & (data.pickup_longitude <= -72.98) & \\\n        (data.pickup_latitude >= 40.56) & (data.pickup_latitude <= 41.71) & \\\n        (data.dropoff_longitude >= -74.27) & (data.dropoff_longitude <= -72.98) & \\\n        (data.dropoff_latitude >= 40.56) & (data.dropoff_latitude <= 41.71)]","4b8dae73":"print(len(data))","8b8087d0":"def distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi\/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)\/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) \/ 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))   # 2*R*asin...","f51f2988":"data['distance_miles'] = distance(data.pickup_latitude, data.pickup_longitude, \\\n                                      data.dropoff_latitude, data.dropoff_longitude)","9bafe370":"test['distance_miles'] = distance(test.pickup_latitude, test.pickup_longitude, \\\n                                      test.dropoff_latitude, test.dropoff_longitude)\n","b2aeed65":"print(len(data[data['distance_miles']==0]))\n\ndata = data.drop(index= data[(data['distance_miles']==0)].index, axis=0)\nprint(len(data))","c0bb9588":"plt.figure(figsize=(12,6))\nsns.distplot( data[\"fare_amount\"]<2.5,hist = False )\nplt.show()","81cd63ba":"# We can drop such data where fare is less than 2.5 dollar\ndata[data['fare_amount'] < 2.5].shape\n\ndata = data.drop(index= data[(data['fare_amount']<2.5)].index, axis=0)\nprint(len(data))","9e53f3e7":"fare_50 = data[(data['distance_miles']<1)&(data['fare_amount']>50)]\nprint(len(fare_50))","9a6aa9ec":"data = data.drop(index= data[(data['distance_miles']<1)&(data['fare_amount']>50)].index, axis=0)\nprint(len(data))","3644095e":"#here it is description of our final data\ndata.describe()","61055f9b":"test_copy = test.copy()\n\ntrain = data.drop(columns= ['key','pickup_datetime'], axis= 1).copy()\ntest = test.drop(columns= ['key','pickup_datetime'], axis= 1).copy()\n\nprint(train.shape)\nprint(test.shape)","90baff2e":"from sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import StandardScaler\n\nstdscaler = StandardScaler()\nxgb_train = stdscaler.fit_transform(train.drop('fare_amount', axis=1))\nxgb_test =  stdscaler.fit_transform(test)\n                       \nx_train, x_test, y_train, y_test = train_test_split(xgb_train,train['fare_amount'], test_size=0.2, random_state = 42)","5307b40e":"import xgboost as xgb\n\ndef XGBmodel(x_train,x_test,y_train,y_test):\n    matrix_train = xgb.DMatrix(x_train, label=y_train)\n    matrix_test = xgb.DMatrix(x_test, label=y_test)\n    model=xgb.train(params={'objective':'reg:linear','eval_metric':'rmse'},\n                    dtrain=matrix_train,\n                    num_boost_round=100, \n                    early_stopping_rounds=10,\n                    evals=[(matrix_test,'test')])\n    return model\n\nxgb_model = XGBmodel(x_train,x_test,y_train,y_test)\nxgb_pred = xgb_model.predict(xgb.DMatrix(xgb_test), ntree_limit = xgb_model.best_ntree_limit)","249a169f":"test_copy['pred_xgb'] = xgb_pred\n\nsubmission = pd.DataFrame(\n    {'key': test_copy.key, 'fare_amount': test_copy.pred_xgb},\n    columns = ['key', 'fare_amount'])\nsubmission.to_csv('submission_xgb.csv', index = False)\n\nprint(os.listdir('.'))","8fe59934":"17 rows having passenger count greater than 6 they do not affect our model if we remove them. <br> I think it's better to drop their data","6bf61570":"If their any null values in any rows or we proceed ..... <br>\nLet's check it first","351c996b":"Passenger count and fare amount are not much co-related. It is approximately 0.013 as clear by heatmap\n <br> It's better that we don't drop this data","0942a18f":"I also come through a thing that their are also some datapoints where distance travelled is less than 1 km and fare is more than 50 dollars which is not correct. so i decide to remove them also.","1217d39e":"Here we do more cleaning of our data :\n<li>Remove data of travel distance equal to 0.","6ef4cf00":"We will store the minimum and maximum of the longitude and latitude from test data set and filter the train data set for those data points","1173c8eb":"I conclude that fare amount less than 2.5 are almost negligible. so it's to  remove them","aa38d16e":"Wow... what i observe <li> Minimum fare count is in negative :p (RIP for that driver) <li> Maximum passenger count is 208 ( Is it flight or cab)<li> Maximum fare count is around 1273 :o","0389ab3e":"Ok let us remove negative values of fare and Null values of latitude and longitudes from data.","fe9eb420":"It seem to be a long process ...... Let's do it","e111418c":"Ahaa... their are few cases where passenger count in zero <li> May be something wrong with counting or maybe delivery of goods<\/li>","84900e62":"<li>Hey this is a starter code and i am a beginner too so suggestions are highly appreciated<\/li>","89208aed":"## Calculate haversine\nThe haversine formula determines the great-circle distance between two points on a sphere given their longitudes and latitudes."}}