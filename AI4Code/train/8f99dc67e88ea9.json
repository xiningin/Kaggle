{"cell_type":{"b1f32ce9":"code","6d8c694a":"code","cbff8e06":"code","c9582c14":"code","8eb49ffd":"code","f9db2b33":"code","8da2f2cd":"code","368ee6f2":"code","c9850cd0":"code","35c7e7d0":"code","745ea8ea":"code","7e7a6cd1":"code","6a9f0569":"code","2c335442":"code","311fa6b0":"code","cfed6c2c":"code","8f4b5a41":"code","14ab658d":"code","dd2d7594":"code","5b40b882":"code","31c00dff":"code","bc51cbf6":"code","db657fc6":"code","92752b63":"code","6e3bf7dc":"code","b4938453":"code","652c3293":"code","4ca0777b":"code","92a88926":"code","2a10db4d":"code","d02bad6c":"code","82816798":"code","d194f657":"code","4bc8acc4":"code","99c1f4c8":"code","1a3d1a42":"code","d1852504":"code","5df194ca":"code","90475a72":"code","660cd1dd":"code","afd4e535":"code","7e152a44":"code","bf20a7ba":"code","c66513ed":"code","f476aa65":"code","70c496c7":"code","b156148d":"code","82c94417":"code","6841d72e":"code","b9b33b0e":"code","b7f1a32d":"code","20b9bb8a":"code","e3881471":"code","143b6d6b":"code","4d015beb":"code","751b7ef7":"code","d2abdb3f":"code","d1308e22":"code","5e0195b8":"markdown","5e95f4c6":"markdown"},"source":{"b1f32ce9":"import os\nfrom fastai import *\nfrom fastai.vision import *\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import auc,roc_curve\n\nfrom math import floor","6d8c694a":"os.listdir(\"..\/input\/ammi-2020-convnets\/train\/train\")\ntrain_path = \"..\/input\/ammi-2020-convnets\/train\/train\"\ntest_path = \"..\/input\/ammi-2020-convnets\/test\/test\/0\"\nextra_path = \"..\/input\/ammi-2020-convnets\/extraimages\/extraimages\"","cbff8e06":"def get_classes(file_path): \n    dir_name = os.path.dirname(file_path)\n    split_dir_name = dir_name.split(\"\/\")\n    dir_levels = len(split_dir_name)\n    label  = split_dir_name[dir_levels - 1]\n    return(label)","c9582c14":"from glob import glob\nimagePatches = glob(\"..\/input\/ammi-2020-convnets\/train\/train\/*\/*.*\", recursive=True)\nimagePatches[0:10]","8eb49ffd":"\ntfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.5, max_warp=0.2, max_lighting=0.2,\n                     xtra_tfms=[(symmetric_warp(magnitude=(-0,0), p=0)),]) ","f9db2b33":"data = ImageDataBunch.from_name_func(path, imagePatches, label_func=get_classes,size=430, \n                                     bs=24,num_workers=2,test = test_path,ds_tfms=tfms\n                                  ).normalize(imagenet_stats)","8da2f2cd":"learner= cnn_learner(data, models.densenet121,metrics=[accuracy],bn_final=True,opt_func=optim.AdamW,ps = 0.25,model_dir='\/tmp\/models\/')","368ee6f2":"learner.lr_find()\nlearner.recorder.plot()","c9850cd0":"lr=1e-2\nlearner.fit_one_cycle(1, lr)","35c7e7d0":"learner.save('model-1')","745ea8ea":"learner.unfreeze()","7e7a6cd1":"learner.lr_find()\nlearner.recorder.plot()","6a9f0569":"learner.load('model-1')\nlearner.fit_one_cycle(8, slice(1e-5,1e-4))","2c335442":"learner.recorder.plot_losses()","311fa6b0":"learner.validate()","cfed6c2c":"interp = ClassificationInterpretation.from_learner(learner)","8f4b5a41":"interp.plot_top_losses(9, figsize=(15,11))","14ab658d":"interp.most_confused(min_val=2)","dd2d7594":"preds,y = learner.TTA(ds_type=DatasetType.Test)","5b40b882":"import shutil\npath=\"\"\ntfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.5, max_warp=0.2, max_lighting=0.2,\n                     xtra_tfms=[(symmetric_warp(magnitude=(-0,0), p=0)),]) ","31c00dff":"image_data_bunch = ImageDataBunch.from_name_func(path, imagePatches, label_func=get_classes,  size=500, \n                                     bs=20,num_workers=2,test = extra_path,ds_tfms=tfms\n                                  ).normalize(imagenet_stats)","bc51cbf6":"learner.data = image_data_bunch\n\n# Generate the psuedo labels with the best loaded model\npredicted_probs_extra, _ = learner.TTA(ds_type = DatasetType.Test)\npredicted_class_probs, predicted_classes_extra = predicted_probs_extra.max(dim=1)\nclass_labels = np.array(['cbb','cbsd','cgm','cmd','healthy'])\npredicted_class_labels = class_labels[predicted_classes_extra]","db657fc6":"shutil.copytree(\"..\/input\/ammi-2020-convnets\/train\/train\/\", \"..\/output\/kaggle\/working\/data\/train\")\nshutil.copytree(\"..\/input\/ammi-2020-convnets\/test\/test\/0\", \"..\/output\/kaggle\/working\/data\/test\")\n\nthreshold = 0.95  # only include pseudo-labeled images where model is sufficiently confident in its prediction\nfilenames = [item.name for item in learner.data.test_ds.items]\nfor predicted_class_label, predicted_class_probability, filename in zip(predicted_class_labels, predicted_class_probs, filenames):\n#     print(predicted_class_label, predicted_class_probability)\n    if predicted_class_probability > threshold:\n        shutil.copy(f\"..\/input\/ammi-2020-convnets\/extraimages\/extraimages\/{filename}\", f\"..\/output\/kaggle\/working\/data\/train\/{predicted_class_label}\/{filename}\")","92752b63":"from glob import glob\nimagePatches = glob(\"..\/output\/kaggle\/working\/data\/train\/*\/*.*\", recursive=True)\nimagePatches[0:10]","6e3bf7dc":"path = \"\"\ntfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.5, max_warp=0.2, max_lighting=0.2,\n                     xtra_tfms=[(symmetric_warp(magnitude=(-0,0), p=0)),])","b4938453":"test_path1 = \"..\/output\/kaggle\/working\/data\/test\"","652c3293":"data = ImageDataBunch.from_name_func(path, imagePatches, label_func=get_classes,  size=500, \n                                     bs=20,num_workers=2,test = test_path1,ds_tfms=tfms\n                                  ).normalize(imagenet_stats)","4ca0777b":"learner= cnn_learner(image_data_bunch, models.densenet121,metrics=[accuracy],opt_func=optim.AdamW ,ps = 0.25 ,model_dir='\/tmp\/models')","92a88926":"learner.lr_find()\nlearner.recorder.plot()","2a10db4d":"lr=1e-2\nlearner.fit_one_cycle(1, lr)","d02bad6c":"learner.save('model-2')","82816798":"learner.unfreeze()","d194f657":"learner.lr_find()\nlearner.recorder.plot()","4bc8acc4":"learner.load('model-2')\nlearner.fit_one_cycle(8, slice(1e-5,1e-4))","99c1f4c8":"learner.save('model-3')","1a3d1a42":"learner.unfreeze()","d1852504":"learner.lr_find()\nlearner.recorder.plot()","5df194ca":"learner.load('model-3')\nlr=1e-4\nlearner.fit_one_cycle(1, lr)","90475a72":"learner.save('model-4')","660cd1dd":"learner.unfreeze()","afd4e535":"learner.lr_find()\nlearner.recorder.plot()","7e152a44":"learner.load('model-4')\nlearner.fit_one_cycle(15, slice(1e-5,1e-4))","bf20a7ba":"learner.recorder.plot_losses()","c66513ed":"learner.validate()","f476aa65":"interp = ClassificationInterpretation.from_learner(learner)","70c496c7":"interp.plot_top_losses(9, figsize=(15,11))","b156148d":"interp.most_confused(min_val=2)","82c94417":"preds,y = learner.TTA(ds_type=DatasetType.Test)","6841d72e":"SAMPLE_SUB = '..\/input\/ammi-2020-convnets\/sample_submission_file.csv'\nsample_df = pd.read_csv(SAMPLE_SUB)","b9b33b0e":"sample_df.head()","b7f1a32d":"predictions = preds.numpy()\n","20b9bb8a":"class_preds = np.argmax(predictions, axis=1)","e3881471":"for c, i in learner.data.train_ds.y.c2i.items():\n    print(c,i)","143b6d6b":"categories = ['cbb','cbsd','cgm','cmd','healthy']\n\ndef map_to_categories(predictions):\n    return(categories[predictions])\n\ncategories_preds = list(map(map_to_categories,class_preds))","4d015beb":"filenames = list(map(os.path.basename,os.listdir(test_path)))","751b7ef7":"df_sub = pd.DataFrame({'Category':categories_preds,'Id':filenames})","d2abdb3f":"df_sub.head()","d1308e22":"# Export to csv\ndf_sub.to_csv('submission_categories.csv', header=True, index=False)","5e0195b8":"## Submission","5e95f4c6":"## Pseudo Labelling"}}