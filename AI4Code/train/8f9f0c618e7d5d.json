{"cell_type":{"d495f363":"code","c246debb":"code","e2c88aab":"code","9ee968d1":"code","aa039e4c":"code","cceb831f":"code","55171c16":"code","105ebcbe":"code","13e38db4":"code","3aaab6e8":"code","2e1c94c9":"code","01a4f438":"code","8826439d":"code","7eef1580":"code","337b5a46":"code","033851fb":"markdown","0806bfd4":"markdown","97472095":"markdown","bc4e8f39":"markdown","fddeada6":"markdown","9d0ca639":"markdown","8d2b0d65":"markdown","5d67c799":"markdown","ab2e1970":"markdown","f28e5070":"markdown"},"source":{"d495f363":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# esta linha permite ver os graficos sem precisar chamar a funcao \"show()\"\n%matplotlib inline","c246debb":"train_path = '..\/input\/paciente-saudvel-ou-no\/train.csv'\ntest_path = '..\/input\/paciente-saudvel-ou-no\/test.csv'\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)","e2c88aab":"# mostra as primeiras linhas do dataset\ntrain.head()","9ee968d1":"# mostra as colunas do dataset\ntrain.info()","aa039e4c":"# mostra m\u00e9dia, desvio padr\u00e3o e outros dados das colunas num\u00e9ricas do dataset\ntrain.describe()","cceb831f":"# https:\/\/seaborn.pydata.org\/generated\/seaborn.pairplot.html\nsns.pairplot(data=train, hue='class', palette='rainbow')","55171c16":"# removendo a coluna 'id'\ndel train['id']","105ebcbe":"sns.pairplot(data=train, hue='class', palette='rainbow')","13e38db4":"#importando o modelo\nfrom sklearn.linear_model import LogisticRegression","3aaab6e8":"# solver \u00e9 um par\u00e2metro onde podem ser passadas diferentes otimiza\u00e7\u00f5es, e liblinear eh um usado para data sets curtos (como este)\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html\nlogmodel = LogisticRegression(solver='liblinear')","2e1c94c9":"# Criando variaveis para treinar o modelo\nX = train.drop('class', axis=1)\ny = train['class']\n","01a4f438":"# treinando o modelo\nlogmodel.fit(X,y)","8826439d":"# criand predicoes\npred = logmodel.predict(test.drop('id', axis=1))","7eef1580":"# cria um dataset com os valores predizidos \noutput = pd.DataFrame(test['id'])\noutput['class'] = pd.DataFrame(pred, columns = ['class'])\noutput.head()","337b5a46":"# cria um CSV com os resultados\noutput.to_csv('.\/LogPred.csv', index=False)","033851fb":"## Criando output para avaliar o modelo","0806bfd4":"## Gr\u00e1ficos para analisar os dados","97472095":"# Abrindo os Dados","bc4e8f39":"O arquivo criado deve aparecer no canto superior direito do notebook em \"data\/output\/kaggle\/working\/\".\nCaso n\u00e3o  esteja ali, basta apertar nas duas setinhas para recarregar.","fddeada6":"Agora podemos ver novamente nossos gr\u00e1ficos.","9d0ca639":"Podemos observar, nos gr\u00e1ficos acima, que existe um jeito de separar as classes de acordo com os planos cartesianos plotados ali em cima. \nPor\u00e9m a divis\u00e3o mais clara est\u00e1 na vari\u00e1vel \"id\" em compara\u00e7\u00e3o com as outras, e n\u00f3s sabemos que o id, n\u00e3o \u00e9 um fator decisivo para determinar se o paciente \u00e9 ou n\u00e3o saud\u00e1vel.\nPortanto, vamos remover o id antes de continuar os nossos testes.","8d2b0d65":"# Imports necessarios","5d67c799":"# Treinando o modelo","ab2e1970":"Como as classes parecem estar, de certa forma, separadas fisicamente no espa\u00e7o, existem alguns modelos que lidam bem com dados dispostos assim, como o KNN e o Naive Bayes, vistos em aula. \nEntretanto este notebook vamos estar usando um modelo de Regressao Logistica (https:\/\/pt.wikipedia.org\/wiki\/Regress%C3%A3o_log%C3%ADstica), que tamb\u00e9m lida muito bem com dados dispostos assim.","f28e5070":"# Analise Exploratoria dos dados"}}