{"cell_type":{"b343f542":"code","f838d59f":"code","ee6c3e73":"code","e8cfb4dc":"code","127f014e":"code","56fa5572":"code","5981b0df":"code","9a08f8f2":"code","6fd00aed":"code","abc7105e":"code","36bbed2d":"code","e2db5817":"code","c8aaf4e9":"code","4578a7ce":"code","094cf655":"code","9e266802":"code","a0584890":"code","b99903c8":"code","56241d7f":"code","14b0f8e8":"code","f9a69589":"code","3314d6b3":"code","0ce96079":"code","fd68ecd1":"code","8f3936d1":"code","25fd5b63":"code","f0027b31":"code","bf3a61f4":"code","e4439b4f":"code","feb187cc":"code","087af821":"code","41f5e4bb":"code","e6ec794a":"code","18967195":"code","7b925ba0":"code","53828aff":"code","2f5d580b":"code","a2e36503":"code","81eac588":"code","e381738b":"code","f3498df8":"code","bd31f484":"code","d5cdbd8d":"code","34b91727":"code","3b70a82b":"code","1649cacd":"code","25821708":"code","d7fc1a8e":"code","d8e4b599":"code","60481ca3":"code","01fa7b16":"code","4487594a":"code","bd0b74c8":"code","3c83391e":"code","4cdf8a0f":"code","81225e35":"code","eee244a2":"code","dde9b25e":"code","6cb04b38":"code","b2a4776e":"code","baf4d7b4":"code","292a3660":"code","47193a6e":"code","d2a1f79a":"code","9057e1f4":"code","8c200dc9":"code","a9c945ef":"markdown","15423083":"markdown","a5922732":"markdown","ad3dd8ac":"markdown","b94e08a4":"markdown","18a6a1df":"markdown","b123ac1c":"markdown","796fd72a":"markdown","ca369609":"markdown","f22fbd37":"markdown","e3129376":"markdown","7befc611":"markdown","baf6d2e9":"markdown","f12ac342":"markdown","5a629748":"markdown","09aa3d13":"markdown","fe82f17f":"markdown","4b5e0fe4":"markdown","29703879":"markdown","c6200a6c":"markdown","86a9003f":"markdown","c0e2ccf3":"markdown","2d3b3b13":"markdown","1d4fd9af":"markdown","a617ef68":"markdown","48db397c":"markdown","3aa2b3b3":"markdown","8484fd88":"markdown","49ad30cf":"markdown","58aa4720":"markdown","de76292a":"markdown","89e40bf5":"markdown","8b002a38":"markdown","f6341781":"markdown","f0ae73c6":"markdown","8b1985ca":"markdown","df338d4a":"markdown","41ffe366":"markdown","463cd5c8":"markdown","f14a7c46":"markdown"},"source":{"b343f542":"# Importing required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom datetime import date\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score","f838d59f":"# Supress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","ee6c3e73":"# Altering ouput display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","e8cfb4dc":"# Importing the data\nboombikes = pd.read_csv('..\/input\/boom-bike-sharing\/boombikes.csv')\nboombikes.head()","127f014e":"# Displaying the shape of the dataset\nboombikes.shape","56fa5572":"# Displaying the column information\nboombikes.info()","5981b0df":"# Displaying important information for numerical columns\nboombikes.describe()","9a08f8f2":"# Dropping instant as we already have an index\nboombikes.drop('instant',axis=1,inplace=True)\nboombikes.head()","6fd00aed":"# Dropping casual and registered\nboombikes.drop(['casual','registered'],axis=1,inplace=True)\nboombikes.head()","abc7105e":"# Changing numerical values of categorical variables to string values\nboombikes.season=boombikes.season.replace({1:'spring',2:'summer',3:'fall',4:'winter'})\nboombikes.mnth=boombikes.mnth.replace({1:'jan',2:'feb',3:'mar',4:'apr',5:'may',6:'jun',7:'jul',8:'aug',9:'sep',10:'oct',11:'nov',12:'dec'})\nboombikes.weathersit=boombikes.weathersit.replace({1:'clear',2:'misty',3:'light_rain_snow',4:'heavy_rain_snow'})\nboombikes.weekday=boombikes.weekday.replace({1:'monday',2:'tuesday',3:'wednesday',4:'thursday',5:'friday',6:'saturday',0:'sunday'})\nboombikes.head()","36bbed2d":"# Visualising numerical variables\nsns.pairplot(boombikes, vars=['cnt','temp','atemp','hum','windspeed'])\nplt.show()","e2db5817":"# Visualising categorical variables\nplt.figure(figsize=(20,12))\nplt.subplot(2,3,1)\nsns.boxplot(x='yr', y='cnt', data=boombikes)\nplt.subplot(2,3,2)\nsns.boxplot(x='season', y='cnt', data=boombikes)\nplt.subplot(2,3,3)\nsns.boxplot(x='holiday', y='cnt', data=boombikes)\nplt.subplot(2,3,4)\nsns.boxplot(x='weekday', y='cnt', data=boombikes)\nplt.subplot(2,3,5)\nsns.boxplot(x='workingday', y='cnt', data=boombikes)\nplt.subplot(2,3,6)\nsns.boxplot(x='weathersit', y='cnt', data=boombikes)\nplt.show()","c8aaf4e9":"# Visualising relationship of cnt with month\nplt.figure(figsize=(12,8))\nsns.boxplot(x='mnth', y='cnt', data=boombikes)\nplt.show()","4578a7ce":"# Converting dteday format to yyyy-mm-dd datetime format\nboombikes.dteday=pd.to_datetime(boombikes.dteday, format='%d-%m-%Y').dt.date\n\n# Creating a new column 'days'\nd0=date(2017, 12, 31)\nd1=boombikes.dteday\ndelta = d1 - d0\nboombikes['days']=delta\nboombikes.days=boombikes.days.astype(str)\nboombikes.days=boombikes.days.apply(lambda x:x[0:2])\n\n# Plotting a lineplot between count and days to understand the weekly pattern\nsns.set(rc={'figure.figsize':(20,5)})\nboombikes.plot.line(x='days',y='cnt')\nplt.show()","094cf655":"# Dropping the derived column 'days' and 'dteday'\nboombikes.drop(['days','dteday'],axis=1,inplace=True)\nboombikes.head()","9e266802":"# Create dummy variables for season\n## 1000-fall, 0100-spring, 0010-summer, 0001-winter\nseason=pd.get_dummies(boombikes.season,drop_first=True)\nboombikes=pd.concat([boombikes,season],axis=1)\nboombikes.drop(['season'],axis=1,inplace=True)\nboombikes.head()","a0584890":"# Create dummy variables for weathersit\n# 100-clear, 010-light_rain_snow, 001-misty\nweather=pd.get_dummies(boombikes.weathersit,drop_first=True)\nboombikes=pd.concat([boombikes,weather],axis=1)\nboombikes.drop(['weathersit'],axis=1,inplace=True)\nboombikes.head()","b99903c8":"# Create dummy variables for mnth\nmonths=pd.get_dummies(boombikes.mnth,drop_first=True)\nboombikes=pd.concat([boombikes,months],axis=1)\nboombikes.drop(['mnth'],axis=1,inplace=True)\nboombikes.head()","56241d7f":"# Create dummy variables for weekday\nweekdays=pd.get_dummies(boombikes.weekday,drop_first=True)\nboombikes=pd.concat([boombikes,weekdays],axis=1)\nboombikes.drop(['weekday'],axis=1,inplace=True)\nboombikes.head()","14b0f8e8":"# Splitting the data into training & testing sets\nnp.random.seed(0)\nbb_train, bb_test = train_test_split(boombikes, train_size=0.7, random_state=50)","f9a69589":"# Inspecting train & test sets\nprint(bb_train.shape)\nprint(bb_test.shape)","3314d6b3":"# Rescaling the features\nscaler = MinMaxScaler()\nnum_vars = ['temp','atemp','hum','windspeed','cnt']\nbb_train[num_vars]=scaler.fit_transform(bb_train[num_vars])","0ce96079":"# Printing the top 5 rows\nbb_train.head()","fd68ecd1":"# Inspecting the variables\nbb_train.describe()","8f3936d1":"# Dividing into X & Y sets for the model building\ny_train = bb_train.pop('cnt')\nX_train = bb_train","25fd5b63":"# Inspecting the dataframes\nX_train.head()","f0027b31":"# Inspecting the dataframes\ny_train.head()","bf3a61f4":"# Running RFE including all the variables\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)\nrfe = rfe.fit(X_train, y_train)","e4439b4f":"# Displaying RFE analysis for all variables\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","feb187cc":"# Displaying RFE variables\nrfecols = X_train.columns[rfe.support_]\nprint(rfecols)","087af821":"# Creating X_train dataframe with RFE variables\nX_train = X_train[rfecols]","41f5e4bb":"# Adding the constant\nX_train_lm = sm.add_constant(X_train)","e6ec794a":"# Fitting the 1st linear regression model\nlr1 = sm.OLS(y_train, X_train_lm).fit()","18967195":"# Checking the parameters\nlr1.params","7b925ba0":"# Checking the summary\nprint(lr1.summary())","53828aff":"# Calculating VIF\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","2f5d580b":"# let us drop atemp as it has a high p-value and very high VIF\nX_train = X_train.drop('atemp', 1)","a2e36503":"# Adding the constant\nX_train_lm = sm.add_constant(X_train)","81eac588":"# Fitting the 2nd linear regression model\nlr2 = sm.OLS(y_train, X_train_lm).fit()","e381738b":"# Checking the summary\nprint(lr2.summary())","f3498df8":"# Calculating VIF\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","bd31f484":"# Droppin sunday as it has a very high p-value\nX_train = X_train.drop('sunday', 1)","d5cdbd8d":"# Adding the constant\nX_train_lm = sm.add_constant(X_train)","34b91727":"# Fitting the 3rd linear regression model\nlr3 = sm.OLS(y_train, X_train_lm).fit()","3b70a82b":"# Checking the summary\nprint(lr3.summary())","1649cacd":"# Calculating VIF\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","25821708":"# Dropping saturday as it has a very high p-value\nX_train = X_train.drop('saturday', 1)","d7fc1a8e":"# Adding the constant\nX_train_lm = sm.add_constant(X_train)","d8e4b599":"# Fitting the 4th linear regression model\nlr4 = sm.OLS(y_train, X_train_lm).fit()","60481ca3":"# Checking the summary\nprint(lr4.summary())","01fa7b16":"# Calculating VIF\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","4487594a":"# Dropping hum as it has a very high VIF\nX_train = X_train.drop('hum', 1)","bd0b74c8":"# Adding the constant\nX_train_lm = sm.add_constant(X_train)","3c83391e":"# Fitting the 5th linear regression model\nlr5 = sm.OLS(y_train, X_train_lm).fit()","4cdf8a0f":"# Checking the summary\nprint(lr5.summary())","81225e35":"# Calculating VIF\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","eee244a2":"y_train_cnt = lr5.predict(X_train_lm)","dde9b25e":"# Plotting histogram of the error terms\nsns.set(rc={'figure.figsize':(7,5)})\nsns.distplot((y_train - y_train_cnt), bins=20)\nplt.title('Error Terms', fontsize=20)\nplt.xlabel('Errors', fontsize=12)\nplt.show()","6cb04b38":"# Applying scaling on the test set\nnum_vars = ['temp','atemp','hum','windspeed','cnt']\nbb_test[num_vars]=scaler.transform(bb_test[num_vars])","b2a4776e":"# Inspecting the test set\nbb_test.describe()","baf4d7b4":"# Dividing into x & y sets\ny_test = bb_test.pop('cnt')\nX_test = bb_test","292a3660":"# Adding constant to test dataframe\nX_test_m5 = sm.add_constant(X_test)","47193a6e":"# Dropping variables from test dataframe\nX_test_m5 = X_test_m5.drop(['atemp','saturday','sunday','hum','aug', 'dec', 'feb', 'jan', 'jul', 'jun', 'mar', 'may', 'nov', 'oct',\n       'monday', 'thursday', 'tuesday', 'wednesday'],axis=1)","d2a1f79a":"# Making predictions using the eighth model\ny_pred_m5 = lr5.predict(X_test_m5)","9057e1f4":"# Checking r2 value from the test set\nr2_score(y_test, y_pred_m5)","8c200dc9":"# Plotting actual vs predicted values\nfig = plt.figure()\nplt.scatter(y_test, y_pred_m5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)\nplt.xlabel('y_test', fontsize = 14)\nplt.ylabel('y_pred', fontsize = 14)\nplt.show()","a9c945ef":"### 1. Reading the data","15423083":"### 2. Data Understanding & Preparation","a5922732":"The dataframe has 16 variables with 730 entries.","ad3dd8ac":"Our model seems to be performing decently. But there is always some scope to improve the model by adding more variables or trying a non-linear model.","b94e08a4":"##### 7.2.3 Third Model","18a6a1df":"The dataframe has no null\/missing values. Some of the categorical variables have 'int' Dtype.","b123ac1c":"#### 1.2 Inspecting the dataframe","796fd72a":"### 10. Model Evaluation","ca369609":"Target variable 'cnt' seems to have a good linear relation with 'temp'.\n'temp' & 'atemp' seem to be highly correlated.","f22fbd37":"##### 7.2.4 Fourth Model","e3129376":"All the VIF values and p-values are within an acceptable range. So, we go ahead and make our predictions using this model.","7befc611":"The R-squared value for test set is 0.79 which is very close to 0.83 which is the R-squared value of the model.","baf6d2e9":"#### 1.1 Importing the data","f12ac342":"Some variables are highly correlated as they have very high VIF values.","5a629748":"### 6. Rescaling the Features","09aa3d13":"#### 7.2 Building model using statsmodel","fe82f17f":"### 7. Building the model","4b5e0fe4":"The variables have considerable difference in min\/max\/median values. Scaling is required.","29703879":"##### 7.2.5 Fifth Model","c6200a6c":"No weekly pattern can be observed for the target variable 'cnt'.","86a9003f":"Target variable 'cnt' is higher for the year 2019 as opposed to 2018.\nTarget variable 'cnt' seems to be higher for summer & fall seasons as opposed to spring & winter seasons.\nWeathersit seems to have some kind of effect on the target variable 'cnt'.","c0e2ccf3":"### 4. Creating dummy variables","2d3b3b13":"### Importing Required Libraries & other settings","1d4fd9af":"#####     7.2.1 First Model","a617ef68":"The min & max values of all the variables are 0 & 1 respectively. It will be easier to interpret the model now.","48db397c":"## Bike Sharing Assignment\n#### Submitted by: Pratyush Motwani","3aa2b3b3":"Adj-R2 = 0.844 but some variables are insignificant as they have high p-values. Let's also calculate the VIF.","8484fd88":"Target Variable - 'cnt', which is the sum of 'casual' & 'registered'.","49ad30cf":"#### 2.2 Altering categorical variables","58aa4720":"#### 2.1 Dropping redundant columns","de76292a":"### 9. Making Predictions using the Final Model","89e40bf5":"The residuals are normally distributed with the peak around zero.This allows us to draw reliable inferences from the co-efficients.","8b002a38":"##### 7.2.2 Second Model","f6341781":"Adj-R2 value is 0.834, which is a pretty decent value. 83.4% variance is explained by the model.\nAll the p-values are less than 0.05. The coefficients are statistically significant.\nF-statistic has a very low p-value, meaning that the model fit is statistically significant and the explained variance isn't by chance.","f0ae73c6":"The equation of our best fitted line is:\nDemand of shared bikes = 0.2366xyr - 0.0867xholiday - 0.0251xworkingday + 0.4864xtemp - 0.1443xwindspeed - 0.0633xspring + 0.0576xsummer + 0.0942xwinter - 0.2637xlight_rain_snow - 0.0767xmisty + 0.0683xsep + 0.2002","8b1985ca":"### 3. Data Visualisation","df338d4a":"### 5. Splitting the dataset","41ffe366":"### 8. Residual Analysis of the train data","463cd5c8":"#### 7.1 Recursive Feature Elimination (RFE)","f14a7c46":"Target variable 'cnt' seems to be higher for jun-oct as opposed to other months."}}