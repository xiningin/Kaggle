{"cell_type":{"173feb4d":"code","204d3974":"code","5906d86a":"code","715a6fd9":"code","2ebde85b":"code","a762976a":"code","45bb6d58":"code","197a5c1f":"code","a54e367d":"code","0306e77c":"code","cc582d1f":"code","858581a9":"code","62bc7f3a":"code","d99b11ee":"code","a6f7b8ae":"code","b65117cd":"code","6429a9f7":"code","3c076204":"markdown","570820ab":"markdown"},"source":{"173feb4d":"import pandas as pd\nimport numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import defaultdict\nfrom nltk.corpus import wordnet as wn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, naive_bayes, svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","204d3974":"np.random.seed(500)\nCorpus = pd.read_csv('..\/input\/bbc-text.csv',delimiter=',',encoding='latin-1')\nCorpus.head()","5906d86a":"Corpus.info()","715a6fd9":"sns.countplot(Corpus.category)\nplt.xlabel('Category')\nplt.title('CountPlot')","2ebde85b":"# 1. Removing Blank Spaces\nCorpus['text'].dropna(inplace=True)\n# 2. Changing all text to lowercase\nCorpus['text_original'] = Corpus['text']\nCorpus['text'] = [entry.lower() for entry in Corpus['text']]\n# 3. Tokenization-In this each entry in the corpus will be broken into set of words\nCorpus['text']= [word_tokenize(entry) for entry in Corpus['text']]\n# 4. Remove Stop words, Non-Numeric and perfoming Word Stemming\/Lemmenting.\n# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\ntag_map = defaultdict(lambda : wn.NOUN)\ntag_map['J'] = wn.ADJ\ntag_map['V'] = wn.VERB\ntag_map['R'] = wn.ADV\n\nCorpus.head()","a762976a":"for index,entry in enumerate(Corpus['text']):\n    # Declaring Empty List to store the words that follow the rules for this step\n    Final_words = []\n    # Initializing WordNetLemmatizer()\n    word_Lemmatized = WordNetLemmatizer()\n    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n    for word, tag in pos_tag(entry):\n        # Below condition is to check for Stop words and consider only alphabets\n        if word not in stopwords.words('english') and word.isalpha():\n            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n            Final_words.append(word_Final)\n    # The final processed set of words for each iteration will be stored in 'text_final'\n    Corpus.loc[index,'text_final'] = str(Final_words)","45bb6d58":"Corpus.drop(['text'], axis=1)\noutput_path = 'preprocessed_data.csv'\nCorpus.to_csv(output_path, index=False)","197a5c1f":"Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['category'],test_size=0.3)","a54e367d":"Encoder = LabelEncoder()\nTrain_Y = Encoder.fit_transform(Train_Y)\nTest_Y = Encoder.fit_transform(Test_Y)","0306e77c":"Tfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(Corpus['text_final'])\nTrain_X_Tfidf = Tfidf_vect.transform(Train_X)\nTest_X_Tfidf = Tfidf_vect.transform(Test_X)\n\nprint(Tfidf_vect.vocabulary_)","cc582d1f":"print(Train_X_Tfidf)\n","858581a9":"# fit the training dataset on the NB classifier\nNaive = naive_bayes.MultinomialNB()\nNaive.fit(Train_X_Tfidf,Train_Y)\n# predict the labels on validation dataset\npredictions_NB = Naive.predict(Test_X_Tfidf)\n# Use accuracy_score function to get the accuracy\nprint(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n\n\n\n\n","62bc7f3a":"Train_X_Tfidf.shape","d99b11ee":"\n\nprint(classification_report(Test_Y, predictions_NB))","a6f7b8ae":"from sklearn.ensemble import RandomForestClassifier\n\nfrom yellowbrick.classifier import ClassPredictionError\n\n# Instantiate the classification model and visualizer\nvisualizer = ClassPredictionError(\n    Naive, classes=Encoder.classes_\n)\n\n# Fit the training data to the visualizer\nvisualizer.fit(Train_X_Tfidf,Train_Y)\n\n# Evaluate the model on the test data\nvisualizer.score(Test_X_Tfidf, Test_Y)\n\n# Draw visualization\ng = visualizer.poof()\n","b65117cd":"# Classifier - Algorithm - SVM\n# fit the training dataset on the classifier\nSVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\nSVM.fit(Train_X_Tfidf,Train_Y)\n# predict the labels on validation dataset\npredictions_SVM = SVM.predict(Test_X_Tfidf)\n# Use accuracy_score function to get the accuracy\nprint(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)","6429a9f7":"print(classification_report(Test_Y,predictions_SVM))","3c076204":"**Importing required libraries.**","570820ab":"<a href=\"preprocessed_data.csv\"> Output file<\/a>"}}