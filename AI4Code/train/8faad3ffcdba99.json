{"cell_type":{"65e0df68":"code","e8bee024":"code","d41b7800":"code","7c1d4e91":"code","72a645cf":"code","3c708516":"code","fb07434d":"code","e3cf2987":"code","52f10c1a":"code","57732fc6":"code","e29865ed":"code","cb7a20e6":"code","0ca451c4":"code","694ccf8f":"code","ab59107e":"code","eac8e820":"code","63297aca":"code","d3263ecf":"code","99087d08":"code","813a62ad":"code","3583ca29":"code","f9837fae":"code","b2d28e0d":"code","2f549fcb":"code","a5889c24":"code","e306d051":"code","6e9a8fe0":"code","3e7fb626":"code","92c04bd5":"code","4340c009":"code","2def42fe":"code","44408f39":"code","4f773865":"code","a61c6971":"code","643bcd19":"code","f5515779":"code","f086b4da":"code","08690bfe":"code","3c6425c3":"code","df3838bb":"code","2f85d37a":"code","981f35aa":"code","430824db":"code","2dd5553b":"code","960254ff":"code","629720e7":"code","2aa20172":"markdown","55f31f1d":"markdown"},"source":{"65e0df68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8bee024":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","d41b7800":"print('-' * 80)\nprint('train')\ntrain = import_data('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv')\n\nprint('-' * 80)\nprint('test')\ntest = import_data('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')","7c1d4e91":"train.shape","72a645cf":"train.info()","3c708516":"train['playersjoined']=train.groupby('matchId')['matchId'].transform('count')\ntrain.head()","fb07434d":"train['traveldistance']=train['walkDistance']+train['swimDistance']+train['rideDistance']","e3cf2987":"train['healsandboosts']=train['heals']+train['boosts']","52f10c1a":"train['killingwithoutmoving']=(train['kills']>0) & (train['traveldistance']== 0)","57732fc6":"train.drop(train[train['killingwithoutmoving']==True].index,inplace=True)","e29865ed":"train[train['winPlacePerc'].isnull()]","cb7a20e6":"train.drop(2744604,inplace=True)","0ca451c4":"train[train['winPlacePerc'].isnull()]","694ccf8f":"train.shape","ab59107e":"train[train['walkDistance']>10000]","eac8e820":"train.drop(train[train['walkDistance']>10000].index,inplace=True)","63297aca":"train[train['swimDistance']>2000]","d3263ecf":"train.drop(train[train['swimDistance']>2000].index,inplace=True)","99087d08":"train[train['rideDistance']>20000]","813a62ad":"train.drop(train[train['rideDistance']>20000].index,inplace=True)","3583ca29":"train[train['longestKill']>1000]","f9837fae":"train.drop(train[train['longestKill']>1000].index,inplace=True)","b2d28e0d":"train[train['kills']>30]","2f549fcb":"train.drop(train[train['kills']>30].index,inplace=True)","a5889c24":"train[train['roadKills']>12]","e306d051":"train.drop(train[train['roadKills']>12].index,inplace=True)","6e9a8fe0":"train[train['weaponsAcquired']>70]","3e7fb626":"train.drop(train[train['weaponsAcquired']>70].index,inplace=True)","92c04bd5":"train[train['heals']>35]","4340c009":"train.drop(train[train['heals']>35].index,inplace=True)","2def42fe":"train.shape","44408f39":"df=pd.concat([train,test],ignore_index=True)","4f773865":"df.shape","a61c6971":"enc_df2 = pd.get_dummies(df[[\"matchType\"]])\ndf.drop(['matchType'],axis=1,inplace=True)\n#df.rename(columns={0.0:'Ungraduated',1.0:'Graduated'},inplace=True)\ndf = df.join(enc_df2)\n\ndf.drop(['Id','groupId','matchId'],axis=1,inplace=True)\ntrainx = df.iloc[:4444630]\ntestx = df.iloc[4444631:].fillna(0)\ny=trainx[\"winPlacePerc\"]\nX = trainx.drop([\"winPlacePerc\"],axis=1)\nX_test = testx.drop([\"winPlacePerc\"],axis=1)\n\nfrom sklearn.model_selection import train_test_split\n#xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.4,random_state=42)\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\n\nprep = MinMaxScaler()","643bcd19":"from sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\ny.fillna(0,inplace=True)","f5515779":"X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.4,random_state=42)","f086b4da":"DTree_clf = DecisionTreeRegressor()\nDTree_clf.fit(X, y)","08690bfe":"DTree_pred = DTree_clf.predict(X_test)","3c6425c3":"DTree_pred[:20]","df3838bb":"X_test.shape","2f85d37a":"test.shape","981f35aa":"test.tail()","430824db":"X_test.head()","2dd5553b":"output = pd.DataFrame({'Id':test.Id,'winPlacePerc':DTree_pred})","960254ff":"output\n","629720e7":"output.to_csv(\"submission.csv\",index = False)","2aa20172":"# Prediction modeling","55f31f1d":"# outliers"}}