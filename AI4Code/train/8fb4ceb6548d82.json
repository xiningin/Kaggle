{"cell_type":{"8295863f":"code","fd42d6c1":"code","55bea56b":"code","7c1a4de0":"code","9f0e7914":"code","561f33d0":"code","25ad395b":"code","de20a0e7":"code","bb520521":"code","2326370d":"code","218c2a25":"code","1c26972e":"code","18cf3481":"markdown","eb503bca":"markdown","914fcefa":"markdown","2c996527":"markdown","ede66ed8":"markdown","81260844":"markdown","b2135304":"markdown","04b27db8":"markdown","58f6db25":"markdown"},"source":{"8295863f":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import mean_absolute_error, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMClassifier","fd42d6c1":"train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')","55bea56b":"print(f'Shape of train dataset: {train.shape}')","7c1a4de0":"df = pd.DataFrame(train.drop(['id', 'target'],axis=1).dtypes, columns = ['dtype'])\ncon_features = df[df.dtype == 'float64'].index.to_numpy()\nbin_features = df[df.dtype == 'int64'].index.to_numpy()\nprint(f'Number of feature columns dtype float: {con_features.shape[0]}')\nprint(f'Number of feature columns dtype int: {bin_features.shape[0]}')\ndel df","9f0e7914":"con_df = train[con_features]\nbin_df = train[bin_features]","561f33d0":"labels = train.target.unique().tolist()\nsns.set_palette('Blues_d')\nplt.rcParams['figure.figsize'] = (16, 2)\nax = pd.DataFrame(train['target'].value_counts()).T.plot(kind='barh', stacked=True)\nax.set_xlabel('Number of Targets')\nplt.show() ","25ad395b":"FOLDS = 10\nBATCH_SIZE = 100\nEPOCHS = 70\n\nX, y = con_df.iloc[:10000,:], train['target'][:10000]\n\ntrain_oof = np.zeros((10000,))\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=2021)\n    \nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n    \n    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n    model = LGBMClassifier(random_state=2021, n_estimators=200, \n                          learning_rate=1e-3, objective='binary')\n    \n    model = model.fit(X_train, y_train, verbose=0)\n    \n    oof = model.predict(X_valid)\n    train_oof[valid_idx] = oof\n    \n    print(f'Fold {fold + 1} MAE: ', roc_auc_score(y_valid, oof))\n    \nprint('K-Fold MAE: ', roc_auc_score(y, train_oof))","de20a0e7":"X, y = bin_df.iloc[:10000,:], train['target'][:10000]\n\ntrain_oof = np.zeros((10000,))\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=2021)\n    \nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n    \n    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n    model = LGBMClassifier(random_state=2021, n_estimators=100, learning_rate=1e-3)\n    \n    model = model.fit(X_train, y_train, verbose=0)\n    \n    oof = model.predict(X_valid)\n    train_oof[valid_idx] = oof\n    \n    print(f'Fold {fold + 1} MAE: ', roc_auc_score(y_valid, oof))\n    \nprint('K-Fold MAE: ', roc_auc_score(y, train_oof))","bb520521":"X, y = con_df.iloc[:10000, :], train['target'][:10000]\n\nfor k in range(20):\n    fig, axes = plt.subplots(3, 4, figsize=(18,18))\n    fig.suptitle(f'Scatter plots of features {con_features[12*k]} to {con_features[12*(k+1)-1]}')\n    for i in range(3):\n        for j in range(4):\n            if (k, i, j) == (19, 2, 3): \n                break\n            else:\n                sns.scatterplot(ax=axes[i, j], data=X, x=X.iloc[:, 12*k + 4*i + j], y=X.iloc[:,12*k + 4*i + j + 1], hue=y, s=5, palette='Set2')\n\nfig.delaxes(axes[2,3])","2326370d":"var_count = bin_df.value_counts()\nvar_count[var_count == 2].sum()","218c2a25":"num_bin_df = bin_df.apply(lambda x: train['target'] - x, axis=0)\nnum_bin_df = pd.DataFrame(num_bin_df.apply(np.sum, axis=0)).T\nplt.figure(figsize=(18,6))\nplt.suptitle('Sum of values subtracted from target')\nsns.barplot(data=num_bin_df, palette='Set2')","1c26972e":"num_bin_df = pd.DataFrame(num_bin_df.apply(lambda x: np.sum(abs(x)), axis=0)).T\nplt.figure(figsize=(18,6))\nplt.suptitle('Sum of absolute values subtracted from target')\nsns.barplot(data=num_bin_df, palette='Set2')","18cf3481":"#### Dividing continuous and binary features","eb503bca":"Could f25, f264 be a major feature that describes target? Or we can suspect data leakage.","914fcefa":"#### Number of target data","2c996527":"### 2 key components are:\n* Scatterplots between continuous features\n* Bar plots of number of differences between binary features and target","ede66ed8":"### LightGBM Classification\nSimple classification with LightGB Model. For simplicity, number of examples were limited to 10,000(1%).","81260844":"Some characteristics are:\n* lines (sharp boundaries)\n* lines with variance\n* good round shape","b2135304":"### Drawing Barplots \nBarplots on binary features of amounts matching with target. \n* Most examples are not overlapped (only 72 out of 1,000,000 are overlapped).\n* The lower the values in the second plot, the closer a feature is to target.","04b27db8":"Without feature engineering, we will not get a good score.","58f6db25":"### Drawing Scatterplots \nScatterplots for continuous features. \n* For simplicity, plots are drawn with first 10,000 examples. \n* Plots only show relation between 1-neighborhood features."}}