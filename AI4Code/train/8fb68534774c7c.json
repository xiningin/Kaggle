{"cell_type":{"dde9f330":"code","d1a7b05d":"code","d3a8915e":"code","c45f7ae9":"code","d3220e15":"code","007c7179":"code","f31f5ed3":"code","23c3b774":"code","9709497b":"code","5b04878e":"code","b2c57eea":"code","8f02a96e":"code","1f7fa44d":"code","61ab5154":"code","90451574":"code","9a415c60":"code","b9787b0f":"code","e51d7b6e":"code","ee718ef9":"code","22883687":"code","42159ca4":"code","b843e10b":"code","81df62f6":"code","51e3602c":"code","ff7630de":"code","2d0faeb5":"code","2e3d253c":"code","089335ca":"code","a8e24b9c":"code","c2517efe":"code","69023c95":"code","7f2b0e1e":"code","acec57aa":"code","c7bc77e9":"code","47c79c83":"code","54fab4e5":"code","968bcb86":"code","47df5ec3":"code","f1524594":"code","04d43b6d":"code","bf8f00b8":"code","b585e4e5":"code","06c68afb":"code","957b1fb3":"code","48f32436":"code","a6c841a9":"code","5203d2cc":"code","8962a518":"code","929df391":"code","f65ff17c":"code","ac45bc27":"code","c6f0c4f6":"code","51959994":"code","1ca72db2":"code","d7fa317f":"code","e09c432d":"code","21f2b14f":"code","8069f515":"code","cae9aad2":"code","8254182d":"code","9289f371":"code","6fbbc9f8":"code","27d3908a":"code","43dfca63":"code","45e70edb":"code","19bdfd25":"code","ce8b361d":"code","f8bcf4d8":"code","ed3bf2c5":"code","3db1a55a":"code","e3edad7b":"code","a28ed58b":"code","459623a0":"code","78a34402":"code","80f4f0bb":"code","9c11912b":"code","398359fc":"code","ef781580":"code","9752a490":"code","20a3162e":"code","3782573d":"code","97140908":"code","cef65422":"code","4afdb59b":"code","bc3727da":"code","537035e8":"code","dba10dc9":"code","5195f206":"code","d394fd9e":"code","2005ad51":"code","7fef2bea":"code","bf42dd82":"code","4e599424":"code","4de576f4":"markdown","c340dd48":"markdown","90bbcc52":"markdown","8f13b3ef":"markdown","3627cffe":"markdown","e3a6d4c5":"markdown","0fede714":"markdown","14b85cd5":"markdown","e204362b":"markdown","d093062c":"markdown","e26ff341":"markdown","ce91410c":"markdown","f92e4dfa":"markdown","fa2c0b84":"markdown","1971e77b":"markdown","3668d62d":"markdown","6ee76de9":"markdown","f9054507":"markdown","92056e19":"markdown","4d84f603":"markdown","b691fd0e":"markdown","c8a7fd6d":"markdown","00328133":"markdown","646216d3":"markdown","2124bccc":"markdown","f9b90cee":"markdown","6ba9829e":"markdown"},"source":{"dde9f330":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport pandas_profiling as pp\nimport os\n\n# Preprocessing Helpers\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.stats import norm, skew #for some statistics\nfrom scipy import stats\nfrom scipy.special import boxcox1p\nfrom numpy import polyfit\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import r2_score\n\n\n# Models\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\n\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# Settings\npd.set_option('display.max_columns', None)\nsns.set_palette(\"RdBu\")\nsns.color_palette(\"magma\", as_cmap=True)\nsns.set(style=\"ticks\", color_codes=True)\nsns.set_theme(style=\"whitegrid\")\n%matplotlib inline\n\n# warning\nimport warnings\nwarnings.filterwarnings('ignore')","d1a7b05d":"datapath = \"..\/input\/seoul-bike-rental-ai-pro-iti\/\"\ntrain_df = pd.read_csv(os.path.join(datapath,\"train.csv\"))\n# test_df = pd.read_csv(os.path.join(datapath,\"test.csv\"))","d3a8915e":"# get the first five rows of data\ntrain_df.head()","c45f7ae9":"# Print DataFrame Schema\ntrain_df.info()","d3220e15":"# pp.ProfileReport(train_df)","007c7179":"# Change features' Names\ndef change_col_name(df, col_names_dic):\n    df.rename(columns=col_names_dic , inplace=True)","f31f5ed3":"# dic of Old\/New column name\ncol_names_dic = {'Temperature(\ufffdC)':'Temperature(C)',\n                 'Dew point temperature(\ufffdC)':'Dew point temperature(C)'}\n\n# call the change function\nchange_col_name(train_df,col_names_dic)","23c3b774":"# check\ntrain_df.columns","9709497b":"def modify_date(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['year'] = df['Date'].dt.year\n    df['month'] = df['Date'].dt.month    ","5b04878e":"modify_date(train_df)","b2c57eea":"# check\ntrain_df.Date","8f02a96e":"# use this encoder to encode\ndef encode_columns(dataframe):\n    le = LabelEncoder()\n    \n    for col in ['Seasons', 'Holiday', 'Functioning Day' ]:\n        dataframe[col] = le.fit_transform(dataframe[col].values)","1f7fa44d":"encode_columns(train_df)","61ab5154":"#  check\ntrain_df.info()","90451574":"# dealing with duplicates\ntrain_df.duplicated().sum()","9a415c60":"# dealing with na\ntrain_df.isna().sum()","b9787b0f":"train_df.drop(columns=['ID']).plot(kind='box',subplots=True, figsize=(15,15), layout=(4,5));","e51d7b6e":"fig = plt.figure(figsize=(25, 25))\nplt.title('Box plot for the all features' , fontdict={'fontsize':15} ,y=1.01)\ncolumns = train_df.drop(columns=['ID', 'y', 'Date']).columns\n\nfor i in range(len(columns)):\n    ax = fig.add_subplot(4, 4, i + 1)\n    sns.boxplot(x=train_df[columns[i]])","ee718ef9":"def findOutliers(column):\n    Q1 = column.quantile(0.25)\n    Q3 = column.quantile(0.75)\n    IQR = Q3 - Q1\n    \n    outliers = column[(column < (Q1 - 1.5 * IQR)) |(column > (Q3 + 1.5 * IQR))]\n    print('{0:25} : {1:5}'.format(column.name, outliers.count()))\n    \n    return outliers","22883687":"print('Count of the outliers of feature : \\n')\n\nfor col in train_df.drop(columns=['ID']).columns:\n    findOutliers(train_df[col])","42159ca4":"train_df[train_df['Snowfall (cm)'] >= 3]['y']","b843e10b":"train_df['Rainfall(mm)'].value_counts()","81df62f6":"train_df[train_df['Rainfall(mm)'] >= 17]['y']","51e3602c":"# unuseful features\n# train_df = train_df.drop(columns=['Snowfall (cm)', 'Rainfall(mm)'])","ff7630de":"def dropOutliers(data, col):\n    Q1 = data[col].quantile(0.25)\n    Q3 = data[col].quantile(0.75)\n    IQR = Q3 - Q1\n    \n    filtered_list = (data[col] >= Q1 -1.5* IQR) & (data[col] <= Q3 +1.5 *IQR)\n    data = data[filtered_list]\n    \n    return data","2d0faeb5":"# train_df = dropOutliers(train_df, 'Wind speed (m\/s)')\n# train_df = dropOutliers(train_df, 'Solar Radiation (MJ\/m2)')\n\n# train_df = dropOutliers(train_df, 'y')\ntrain_df.head()","2e3d253c":"train_df[train_df['Functioning Day'] == 0]","089335ca":"# y = 0 , always when the  Functioning Day is 0\ntrain_df[train_df['Functioning Day'] == 0]['y'].sum()","a8e24b9c":"train_df = train_df[train_df['Functioning Day'] != 0]","c2517efe":"train_df.drop(columns='ID').describe()","69023c95":"plt.scatter(train_df['Temperature(C)'], train_df['y'], alpha=0.2)\nplt.yscale('log')\nplt.show()","7f2b0e1e":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='Seasons');","acec57aa":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='Seasons');","c7bc77e9":"sns.displot(x ='y', col='dayofweek', data=train_df )","47c79c83":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='dayofweek', err_style='');","54fab4e5":"sns.countplot(x='Holiday', data=train_df);","968bcb86":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='Holiday', err_style='');","47df5ec3":"sns.jointplot(x='Temperature(C)', y='y', data=train_df)","f1524594":"fig = plt.subplots(figsize=(15,7))\nsns.scatterplot(x='Date', y='y', data=train_df)","04d43b6d":"sns.countplot(x='year', data=train_df);","bf8f00b8":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='year');","b585e4e5":"fig = plt.subplots(figsize=(15,7))\nsns.pointplot(x='Hour', y= 'y' , data=train_df, hue='month');","06c68afb":"fig = plt.figure(figsize=(15, 15))\nplt.title('Relation between Count of bikes rented at each hour(Y) and all features' , fontdict={'fontsize':15} ,y=1.01)\ncolumns = train_df.drop(columns=['ID', 'y']).columns\n\n\nfor i in range(len(columns)):\n    ax = fig.add_subplot(4, 4, i + 1)\n    ax.scatter(train_df[columns[i]], np.log1p(train_df['y']),  alpha=0.2, c='b')\n    ax.set_ylabel('Y')\n    ax.set_xlabel(columns[i])","957b1fb3":"train_df.columns","48f32436":"fig = plt.figure(figsize=(14, 7))\n\nplt.plot(train_df['Hour'], np.log1p(train_df['y']), 'o');","a6c841a9":"x = train_df['Hour']\ny = np.log(train_df['y'])\nz = np.polyfit(x, y, 3)\nfig = plt.figure(figsize=(14, 7))\nxp = np.linspace(0, 24, 100)\np = np.poly1d(z)\n_ = plt.plot(x, y, '.', xp, p(xp), '-')\nplt.show()","5203d2cc":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Hour'], y= np.log1p(train_df.y), order=4, line_kws={'lw': 4, 'color': 'r'})","8962a518":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Temperature(C)'], y= np.log1p(train_df.y), order=2, line_kws={'lw': 4, 'color': 'r'})","929df391":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Wind speed (m\/s)'], y= np.log1p(train_df.y), order=2, line_kws={'lw': 4, 'color': 'r'})","f65ff17c":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Humidity(%)'], y= np.log1p(train_df.y), order=1, line_kws={'lw': 4, 'color': 'r'})","ac45bc27":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Visibility (10m)'], y= np.log1p(train_df.y), order=2, line_kws={'lw': 4, 'color': 'r'})","c6f0c4f6":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Solar Radiation (MJ\/m2)'], y= np.log1p(train_df.y), order=1, line_kws={'lw': 4, 'color': 'r'})","51959994":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= train_df['Rainfall(mm)'], y= np.log1p(train_df.y), order=3, line_kws={'lw': 4, 'color': 'r'})","1ca72db2":"fig = plt.figure(figsize=(14, 7))\nsns.regplot(x= np.power(train_df['Snowfall (cm)'],1), y= np.log1p(train_df.y), order=1, line_kws={'lw': 4, 'color': 'r'})","d7fa317f":"def add_features(dataset):\n    # convert feature to polynomial\n    # Temperature\n    dataset['Temp_2'] = np.power(dataset['Temperature(C)'], 2)\n    # Rainfall\n    dataset['Rainfall_2'] = np.power(dataset['Rainfall(mm)'], 2)\n    dataset['Rainfall_3'] = np.power(dataset['Rainfall(mm)'], 3)\n    # Wind speed\n#     dataset['Wind_2'] = np.power(dataset['Wind speed (m\/s)'], 2) \n    # Hour\n    dataset['Rush_Hour'] = dataset['Hour'].isin([4, 5, 6,16,17,18,19,20, 21 ]).astype('int')\n\n        \n    # convert feature to categorical\n    # Snowfall\n    dataset['Snowfall_lt_1'] = (dataset['Snowfall (cm)'] <= 1).astype('int')\n    dataset['Snowfall_1_3']  = (np.logical_and(dataset['Snowfall (cm)'] > 1 , dataset['Snowfall (cm)'] <=3 )).astype('int')\n    dataset['Snowfall_gt_3'] = (dataset['Snowfall (cm)'] > 3).astype('int')\n    # Wind speed\n    dataset['Wind_speed_lt_1'] = (dataset['Wind speed (m\/s)'] <= 1).astype('int')\n    dataset['Wind_speed_1_3']  = (np.logical_and(dataset['Wind speed (m\/s)'] > 1 , dataset['Wind speed (m\/s)'] <=3 )).astype('int')\n    dataset['Wind_speed_3_5']  = (np.logical_and(dataset['Wind speed (m\/s)'] > 3 , dataset['Wind speed (m\/s)'] <=5 )).astype('int')\n    dataset['Snowfall_gt_5'] = (dataset['Wind speed (m\/s)'] > 5).astype('int')\n    \n    #interactive features\n    dataset['Hour_Seasons'] = dataset['Hour'] * dataset['Seasons'] ","e09c432d":"def get_dummies(dataset):\n    return pd.get_dummies(dataset , drop_first=True , columns = ['Seasons', 'month', 'year', 'dayofweek',])","21f2b14f":"add_features(train_df)\ntrain_df = get_dummies(train_df)\ntrain_df.head()","8069f515":"train_df.shape","cae9aad2":"from sklearn.preprocessing import KBinsDiscretizer\n\nbins = 4\n# fit the scaler to the  data\ndiscretizer = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans') \n\ntrain_discretized = discretizer.fit_transform(train_df[['Wind speed (m\/s)']])\ntrain_df['Wind_speed_cat'] = train_discretized\n\n\n# Plottting\ntrain_discretized_df = pd.DataFrame(train_discretized,columns=['Wind_speed_cat'])\ntrain_discretized_df.hist(bins = bins);","8254182d":"plt.scatter(train_discretized_df, train_df.y)","9289f371":"# sns.pairplot(train_df, hue='Seasons');\n\n# sns.pairplot(train_df);","6fbbc9f8":"corr_martix = train_df.drop('ID', axis=1).corr()","27d3908a":"# plt.subplots(figsize=(15, 15))\n# plt.title('Correlation of Features', size=18)\n# sns.heatmap(corr_martix,linewidths=0.05, annot=True, fmt=\".2f\")","43dfca63":"corr_with_y = train_df.drop('ID',axis=1).corr()['y'].drop('y')\ncorr_with_y","45e70edb":"plt.subplots(figsize=(19,10))\nplt.grid()\nplt.plot((corr_with_y.sort_values()), color=\"purple\", lw=1, ls='--', marker='o', markersize=4)\nplt.xticks(rotation=45)\nplt.axhline(y=0 , c='b')\nplt.xlabel('Features')\nplt.ylabel('Correlation With Features')\nplt.show()","19bdfd25":"train_df.columns","ce8b361d":"# scalar = preprocessing.StandardScaler()\nscalar = preprocessing.MinMaxScaler()\n\ncolumns_to_scale = ['Temperature(C)',\n                    'Humidity(%)',\n                    'Wind speed (m\/s)', \n                    'Visibility (10m)',\n                    'Dew point temperature(C)',\n                    'Solar Radiation (MJ\/m2)',\n        #           'Snowfall (cm)',\n                    'Hour',\n                    'Temp_2',\n                     'Rainfall(mm)','Rainfall_2', 'Rainfall_3',\n        #           'Seasons', \n                    'Wind_speed_cat',\n                           ]\n\nscalar_model = scalar.fit(train_df[ columns_to_scale ])\n\ntrain_df[columns_to_scale] = scalar_model.transform(train_df[ columns_to_scale ])","f8bcf4d8":"sns.distplot(train_df['y'], fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_df['y'] )\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nplt.title('Biks count distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_df['y'] , plot=plt)\nplt.show()","ed3bf2c5":"# #We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain_df[\"y\"] = np.log1p(train_df[\"y\"])\n# train_df['Snowfall (cm)'] = np.log1p(train_df['Snowfall (cm)'])\n# train_df['Rainfall(mm)'] = np.log1p(train_df['Rainfall(mm)'])\n\n#Check the new distribution \nsns.distplot(train_df[\"y\"] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_df[\"y\"])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Bikes Count distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_df[\"y\"], plot=plt)\nplt.show()","3db1a55a":"plt.figure(figsize=(20,8))\nplt.xticks(rotation=45)\nsns.boxplot(data=train_df[columns_to_scale], palette=\"deep\");","e3edad7b":"train_df.describe()","a28ed58b":"random_state = 42","459623a0":"# Split Data using Sci-kit learn\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=random_state,  ) # Try adding `stratify` here stratify = train_df.Hour \n\nX_train = train_df.drop(columns=['ID', 'y'])\ny_train = train_df['y']\n\nX_val = val_df.drop(columns=['ID', 'y'])\ny_val = val_df['y']","78a34402":"train_df.columns","80f4f0bb":"features =   ['Functioning Day',\n              'Humidity(%)',\n              'Wind_speed_cat',\n              'Visibility (10m)',\n#             'Dew point temperature(C)',\n              'Solar Radiation (MJ\/m2)', \n              'Snowfall_lt_1', 'Snowfall_1_3', 'Snowfall_gt_3',\n              'Holiday',\n              'Seasons_1', 'Seasons_2', 'Seasons_3',\n              'year_2018',\n              'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7','month_8', 'month_9', 'month_10', 'month_11', 'month_12',\n              'dayofweek_1', 'dayofweek_2', 'dayofweek_3', 'dayofweek_4', 'dayofweek_5', 'dayofweek_6',\n              'Hour', \n              'Temperature(C)', 'Temp_2',\n              'Rainfall(mm)', 'Rainfall_2', 'Rainfall_3',\n             ]\n\nX_train = X_train[features]\nX_val = X_val[features]","9c11912b":"X_train","398359fc":"model = xgb.XGBRegressor(subsample= 0.6,\n                         n_estimators= 3000,\n                         max_depth= 20,\n                         learning_rate= 0.01,\n                         colsample_bytree= 0.8999999999999999,\n                         colsample_bylevel= 0.4,\n                         random_state=random_state)\n ","ef781580":"model.fit(X_train, y_train)","9752a490":"# Train the model\nprint('{0:25} : {1:5}'.format('Model name', 'score' ) )\n\n# scores = cross_validation(train_df, model)\n# print('{0:25} : {1:5}'.format('R^2 cross-validation', np.mean(scores) ) )\n\nmodel.fit(X_train, y_train)\nprint('{0:25} : {1:5}'.format('R^2 Training Score', model.score(X_train, y_train) ) )\nprint('{0:25} : {1:5}'.format('R^2 Test Score', model.score(X_val, y_val) ) )\n\ny_val_predict = model.predict(X_val)\nprint('{0:25} : {1:5}'.format('RMSE Test Score',np.sqrt(mean_squared_error(y_val, y_val_predict)) ) )\n\ny_predict_mod = np.where(model.predict(X_val)<0, 0, y_val_predict)\nprint('{0:25} : {1:5}'.format('RMSLE Test Score',np.sqrt(mean_squared_log_error(y_val, y_predict_mod)) ) )\nprint('-'*50 + '\\n')","20a3162e":"# y_train_pred = model.predict(X_train)\ny_val = np.round(np.expm1(y_val), 0)\ny_pred = np.round(np.expm1(y_val_predict), 0)\ny_val","3782573d":"print('{0:25} : {1:5}'.format('RMSLE Test Score',np.sqrt(mean_squared_log_error(y_val, y_pred)) ) )   #  0.35745335243523935","97140908":"importance = model.feature_importances_","cef65422":"for i,v in zip(features,importance):\n    print(f'Feature: {i},           Score: {round(v,5)}')","4afdb59b":"plt.subplots(figsize=(15,7))\nplt.bar(features, importance)\nplt.xticks(rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Importance');\n# plt.savefig('plot3.png', dpi=300 ,bbox_inches='tight');","bc3727da":"from statsmodels.api import OLS\n#\nOLS(train_df['y'], train_df[features]).fit().summary()","537035e8":"# final model\nmodel.fit(train_df[features], train_df['y'])","dba10dc9":"# Load test dataset\ntest_df = pd.read_csv(os.path.join(datapath,\"test.csv\"))\n\ntest_df.head()","5195f206":"# clean the test dataset\nchange_col_name(test_df,col_names_dic)\nmodify_date(test_df)\nencode_columns(test_df)\nadd_features(test_df)\ntest_df = get_dummies(test_df)","d394fd9e":"test_discretized = discretizer.transform(test_df[['Wind speed (m\/s)']])\ntest_df['Wind_speed_cat'] = test_discretized","2005ad51":"test_df[columns_to_scale] = scalar_model.transform(test_df[ columns_to_scale ])\n# train_df['Snowfall (cm)'] = np.log1p(train_df['Snowfall (cm)'])\n# train_df['Rainfall(mm)'] = np.log1p(train_df['Rainfall(mm)'])","7fef2bea":"train_df.head()","bf42dd82":"# predict the number of bikes\n\n# Choose the features used for training\nX_test = test_df[features]\n\ny_test_predicted = model.predict(X_test)\ny_test_predicted[y_test_predicted < 0] = 0\n# Give me my YYYYYYYYYYYYYYYY again!!!!!!!!!!!!!!!!!!!!!\ny_test_pred = np.round(np.expm1(y_test_predicted), 0)\ntest_df['y'] = y_test_pred\n\n# Manually Predicted \ntest_df.loc[test_df['Functioning Day'] == 0, 'y'] = 0\n\ntest_df[['ID','y']].head()","4e599424":"# Generate the submission file. The submission file needs the columns `ID` and `y` only.\ntest_df[['ID', 'y']].to_csv('submission.csv', index=False)","4de576f4":"## 3-6 Outliers","c340dd48":"### 3-3-1 Dealing with dates","90bbcc52":"## 4-1 Data Visualization","8f13b3ef":"## Skewed features\n","3627cffe":"--------------------------\n# 6- Model\n--------------------------","e3a6d4c5":"## 4-2 Standardization\/Normalization","0fede714":"### 3-3-2 Encode String Columns","14b85cd5":"## 3-4 Remove duplicates","e204362b":"## 3-3 Modify Data Types","d093062c":"--------------------------\n# 5- Data Splitting\n--------------------------\n\n> Split the dataset for the training step.\n>> Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio.","e26ff341":"## 6-4 Testing and validation","ce91410c":"## 3-1 Data Exploration","f92e4dfa":"--------------------------------\n# 4- Exploratory Data Analysis!\n--------------------------------","fa2c0b84":"## 6- Features' Importance","1971e77b":"<h1><center><b>---((({{{ RAM }}})))---<\/b><\/center><\/h1>","3668d62d":"--------------------------------------\n# 7- Submission File Generation\n--------------------------------------\n\nWe have built a model and we'd like to submit our predictions on the test set!\n**In order to do that,**\n- load the test set.\n- clean the test set\n- predict the number of bikes\n- save the submission file. ","6ee76de9":"# All features check Meee","f9054507":"### Data fields\n- ID - an ID for this instance\n- Date - year-month-day\n- Hour - Hour of he day\n- Temperature - Temperature in Celsius\n- Humidity - %\n- Windspeed - m\/s\n- Visibility - 10m\n- Dew point temperature - Celsius\n- Solar radiation - MJ\/m2\n- Rainfall - mm\n- Snowfall - cm\n- Seasons - Winter, Spring, Summer, Autumn\n- Holiday - Holiday\/No holiday\n- Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)\n- y - Rented Bike count (Target), Count of bikes rented at each hour","92056e19":"------------------------\n# 2- Get the data \n------------------------\n","4d84f603":"-------------------------\n# 1- Import Libraries\n------------------------","b691fd0e":"## 3-2 Change Columns' Names","c8a7fd6d":"## 3-5 Clean Null Values","00328133":"------------------------------------\n# 3- Data Cleaning (Data Wrangling)\n------------------------------------","646216d3":"## Log-transformation of the target variable","2124bccc":"### 6-4-2 Testeing LAST Model on the dataset to see the accuracy","f9b90cee":" Team Members:\n - **Afnan Hamdy**\n - **MOhamed ElMesawy**\n - **Ahmed N. Awaad**\n - **Rawan M.Mahallawy**\n - **Mohammed Samaha**\n - **Ali Hasanine**","6ba9829e":"### Goal:\n> predict the required number of bikes for rental given information about the weather and time of the day"}}