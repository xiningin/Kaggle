{"cell_type":{"65e7ccae":"code","17925cf3":"code","724e90a5":"code","9d70c464":"code","4af24a9f":"code","42ce0f32":"code","c4867fd4":"code","dafe8731":"code","603f19fb":"code","23fab14b":"code","7845bfa5":"code","3f0b37b4":"code","e52e2fe9":"code","dd83715c":"code","91d90ff5":"code","751d6719":"code","24c2d3a9":"code","a163448f":"code","09f1cadf":"code","51c725b2":"code","e812baa9":"code","7dc6a3cf":"code","ec15bdc4":"code","e439cca7":"code","efe516c8":"code","0d3b8bab":"code","f07ec3b4":"code","4c082406":"code","9e1a5ef0":"code","0d0fd7e1":"code","6881f925":"code","b85bcd44":"code","21e6838c":"code","072c9b48":"code","2ed3ce91":"code","e4b5d563":"code","a2a652da":"code","f8333a77":"code","ad2f8a98":"code","cc9f3fe9":"code","271a55e1":"code","f531b3aa":"code","1edec80b":"code","b265a2e0":"code","7ec7006d":"code","a54d4495":"code","d00ab11c":"code","257900b2":"code","4bff6872":"code","e99126c3":"code","07c3e1b6":"code","a553af71":"code","6df852fc":"code","692666b1":"code","06c5fbbc":"code","e9072fe0":"code","82019f11":"code","b82372bb":"code","3a6890fb":"code","563d0b4f":"code","f3796181":"code","9e2c9ee0":"code","91e4ed4b":"code","3fe2fe53":"code","32f8033c":"code","53c82f4e":"code","51476316":"code","1667b110":"code","5a18aa72":"code","6c780995":"code","6121458f":"code","269395bf":"code","1d29bf14":"code","f88e50af":"code","c34a45d1":"code","6d3c3488":"code","31784b03":"code","475f0380":"code","d28e547e":"code","23de1071":"code","7c2369a9":"code","ee5be58c":"code","6a434fa7":"code","3a8a6f90":"code","3a05b867":"code","f8f17485":"code","2d75f10e":"code","bda0cfe0":"code","cb0379a9":"code","9029f08d":"code","2d6f1ddd":"code","be1e37e0":"code","cd5d4bcc":"code","2b1efead":"code","a08a24f7":"code","289d99c1":"code","024c6bfa":"code","514790d0":"code","e3080a15":"code","9d1a1d56":"code","37f065e3":"code","f4e9cd14":"code","a8c81b48":"code","ce98d84e":"code","9d065238":"code","1fbd545f":"code","fb8312b7":"code","b513e5b8":"code","2f3eeb4f":"code","5132b47c":"code","cefb147a":"code","43f88315":"code","fb2b24dd":"code","17d2afec":"code","c7f61bf3":"code","1c81d293":"code","3da6666c":"code","d0c9c23f":"code","60701b30":"code","24076b46":"code","21f8977b":"code","fb4cb360":"code","31b32d2b":"code","a3a230fa":"code","09b8e6f5":"code","2685ece6":"code","813d0817":"code","1cec1da0":"code","55455a12":"code","4ad59969":"code","5dc6b8c2":"code","32ee8323":"code","78f9c1ed":"markdown","89b44864":"markdown","cee153a3":"markdown","e213c344":"markdown","b9a90116":"markdown","f12ef2d8":"markdown","2564816f":"markdown","a0854d11":"markdown","a0389be5":"markdown","f4d420dc":"markdown","bd6ecd25":"markdown","5fe3a7d6":"markdown","93ede99e":"markdown","a498344c":"markdown","bc019741":"markdown","2052bdb7":"markdown","ac6c3557":"markdown","f0ebd96e":"markdown","ba943ae7":"markdown","80e6387e":"markdown","95fcab88":"markdown","bbdfc36d":"markdown","0eb49ce1":"markdown","b0ef0340":"markdown","ab927a17":"markdown","7c961af8":"markdown","4b99498c":"markdown","964e6df2":"markdown","0a51d242":"markdown","38628536":"markdown","be60ea27":"markdown","2cdc5c23":"markdown","3e7e626d":"markdown","0492352f":"markdown","07dd9522":"markdown","98d09553":"markdown","6132c08d":"markdown","82999934":"markdown","a68bf92d":"markdown","502a5320":"markdown","2bcb9059":"markdown","1fa8fe73":"markdown","30a5b9b4":"markdown","d96434d2":"markdown","410f809a":"markdown","79b4147e":"markdown","eac7b913":"markdown","a020b6ef":"markdown","780c16dc":"markdown","429db6da":"markdown","ff40735b":"markdown","1586125e":"markdown","31965de8":"markdown","e0aa3e36":"markdown","00e9516a":"markdown","91c0ad6f":"markdown","db2a3665":"markdown","5b841d63":"markdown","a5d37c7a":"markdown","e3beb508":"markdown","6312fbf8":"markdown","bde824e0":"markdown","b177cb44":"markdown","a470665e":"markdown","fc2750cf":"markdown","41b55f05":"markdown","3951336c":"markdown","ba252088":"markdown","babed378":"markdown","b9aa2108":"markdown","285c1401":"markdown","61f29d14":"markdown","20ec7c58":"markdown","4585263f":"markdown","d7e0f446":"markdown","116ac0cb":"markdown","a912c2b4":"markdown"},"source":{"65e7ccae":"import pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt","17925cf3":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","724e90a5":"DATASET_PATH = '..\/input\/ieee-fraud-detection'\ntrain_transaction = pd.read_csv(os.path.join(DATASET_PATH, 'train_transaction.csv'), index_col='TransactionID')\ntrain_transaction = reduce_mem_usage(train_transaction)\ntest_transaction = pd.read_csv(os.path.join(DATASET_PATH, 'test_transaction.csv'), index_col='TransactionID')\ntest_transaction = reduce_mem_usage(test_transaction)\ntrain_identity = pd.read_csv(os.path.join(DATASET_PATH,'train_identity.csv'), index_col='TransactionID')\ntrain_identity = reduce_mem_usage(train_identity)\ntest_identity = pd.read_csv(os.path.join(DATASET_PATH,'test_identity.csv'), index_col='TransactionID')\ntest_identity = reduce_mem_usage(test_identity)\nsample_submission = pd.read_csv(os.path.join(DATASET_PATH,'sample_submission.csv'), index_col='TransactionID')\n","9d70c464":"train_set = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest_set = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)","4af24a9f":"train_set=reduce_mem_usage(train_set)\ntest_set=reduce_mem_usage(test_set)","42ce0f32":"del train_transaction\ndel train_identity\ndel test_transaction\ndel test_identity","c4867fd4":"import gc\ngc.collect()","dafe8731":"train_labels = train_set.select_dtypes([object])\ntrain_numbers = train_set.select_dtypes([np.float64, np.float32, np.float16, np.int32, np.int16, np.int8, np.int64])\nlabel_atrrs = train_labels.columns.values\nnumbers_attrs = train_numbers.columns.values","603f19fb":"train_numbers.info(max_cols=400)","23fab14b":"from sklearn.base import TransformerMixin, BaseEstimator\nclass PercentImputer(TransformerMixin, BaseEstimator):\n    def __init__(self, percent=0.6):\n        self.percent = percent\n        self.not_labels = []\n    def fit(self, X, y=None):\n        length = len(X)\n        nulls_count = X.isnull().sum()\n        labels = X.columns.values\n        self.new_labels = []\n        for label in labels:\n            if(nulls_count[label] < self.percent * length):\n                self.new_labels.append(label)\n            else:\n                self.not_labels.append(label)\n        return self\n    def transform(self, X, y=None):\n        X=X.replace(np.inf,-999)\n        return X[self.new_labels]","7845bfa5":"p_number_imputer = PercentImputer(percent=0.9)\np_labels_imputer = PercentImputer(percent=0.9)\nnumbers_p_imputed = p_number_imputer.fit_transform(train_numbers)\nlabels_p_imputed = p_labels_imputer.fit_transform(train_labels)","3f0b37b4":"train_numbers.info()\nnumbers_p_imputed.info()","e52e2fe9":"from sklearn.impute import SimpleImputer\nnumbers_imputed = SimpleImputer(strategy='most_frequent', verbose=-1).fit_transform(numbers_p_imputed)","dd83715c":"numbers_imputed = pd.DataFrame(numbers_imputed, columns=numbers_p_imputed.columns)","91d90ff5":"numbers_cols  =numbers_p_imputed.columns\ndel numbers_p_imputed","751d6719":"y = numbers_imputed['isFraud'].copy() ","24c2d3a9":"numbers_imputed.drop(['isFraud'], axis=1, inplace=True)","a163448f":"sns.countplot(y)","09f1cadf":"plt.figure(figsize=(15, 10))\nsns.boxenplot(x=y, y=numbers_imputed['TransactionAmt'])\nplt.ylim(top=7000, bottom=0)","51c725b2":"class NormalizeByLog(BaseEstimator, TransformerMixin):\n    def __init__(self, feature_name):\n        self.feature_name = feature_name\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X[self.feature_name] = np.log1p(X[self.feature_name])\n        return X","e812baa9":"numbers_ta_filtered = NormalizeByLog('TransactionAmt').transform(numbers_imputed)","7dc6a3cf":"del numbers_imputed","ec15bdc4":"plt.figure(figsize=(15, 10))\nsns.distplot(numbers_ta_filtered['TransactionAmt'])","e439cca7":"\nplt.figure(figsize=(15, 5))\nplt.subplot(121)\nsns.boxenplot(x=y, y=numbers_ta_filtered['TransactionDT'])\nplt.subplot(122)\nsns.distplot(numbers_ta_filtered['TransactionDT'])","efe516c8":"numbers_ta_filtered.info(max_cols=400)","0d3b8bab":"plt.figure(figsize=(20, 10))\nl = 0\nfor i in range(5):\n    att = 'card' + str(i+1)\n    if att in numbers_ta_filtered:\n        l+=1\n        plt.subplot(2, 2, l)\n        sns.distplot(numbers_ta_filtered[att], )\n","f07ec3b4":"numbers_ta_filtered['card3'].value_counts().head()","4c082406":"to_drop_numbers = ['card3']","9e1a5ef0":"sns.distplot(numbers_ta_filtered['dist1'])","0d0fd7e1":"numbers_ta_filtered['dist1'].value_counts()","6881f925":"plt.figure(figsize=(15, 5))\nfor i in range(2):\n    plt.subplot(1, 2, i+1)\n    sns.distplot(numbers_ta_filtered['addr' + str(i+1)])","b85bcd44":"np.unique(numbers_ta_filtered['addr2'].values, return_counts = True)","21e6838c":"\nto_drop_numbers.append('addr2')","072c9b48":"plt.figure(figsize=(20, 20))\nfor i in range(14):\n    plt.subplot(4, 4, i+1)\n    sns.distplot(numbers_ta_filtered['C' + str(i+1)])\n","2ed3ce91":"plt.figure(figsize=(15, 25))\nfor i in range(14):\n    counts = np.unique(numbers_ta_filtered['C' + str(i+1)], return_counts=True)\n    less_than_ten = 0\n    for j in range(len(counts[0])):\n        if counts[0][j] <= 4:\n            less_than_ten += counts[1][j]\n    print('C' + str(i+1), less_than_ten)\n    ","e4b5d563":"class CategorizeCs(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        for i in range(14):\n            att = 'C'+str(i+1)\n            if att in X :\n                X[att] = X[att].apply(lambda l : l if l <=4 else 4)\n        return X","a2a652da":"numbers_cat = CategorizeCs().transform(numbers_ta_filtered)","f8333a77":"plt.figure(figsize=(20, 20))\nfor i in range(14):\n    plt.subplot(4, 4, i+1)\n    sns.countplot(x=numbers_cat['C' + str(i+1)], hue=y)\n#     sns.kdeplot(numbers_cat['C' + str(i+1)])","ad2f8a98":"to_drop_numbers.append('C3')","cc9f3fe9":"class CategorizeCs(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        for i in range(14):\n            att = 'C'+str(i+1)\n            if att == 'C7' and att in X : \n                X[att] = X[att].apply(lambda l : l if l <=2 else 2)\n            elif att in X :\n                X[att] = X[att].apply(lambda l : l if l <=4 else 4)\n        return X\nnumbers_cat = CategorizeCs().transform(numbers_ta_filtered)","271a55e1":"del numbers_ta_filtered","f531b3aa":"plt.figure(figsize=(20, 20))\nj = 1;\nfor i in range(15):\n    att = 'D' + str(i+1)\n    if att in numbers_cat:\n        plt.subplot(4, 4, j)\n        sns.distplot(numbers_cat['D' + str(i+1)])\n        j+=1","1edec80b":"plt.figure(figsize=(20, 64))\nj = 1;\nfor i in range(340):\n    att = 'V' + str(i+1)\n    if att in numbers_cat:\n        plt.subplot(34, 10, j)\n        sns.distplot(numbers_cat['V' + str(i+1)])\n        j+=1","b265a2e0":"class DropExtraVs(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        self.to_drop = []\n        for i in range(340):\n            att = 'V' + str(i+1)\n            if att in X :\n                counts = np.unique(X[att], return_counts=True)[1]\n                counts.sort()\n                if (counts[len(counts) - 1] + counts[len(counts) - 2]) > 0.85 * len(X) :\n                    self.to_drop.append(att)\n        return self\n    def transform(self, X, y=None):\n        return X.drop(self.to_drop, axis=1) ","7ec7006d":"dropper = DropExtraVs()\nnumbers_v_droped = dropper.fit_transform(numbers_cat)","a54d4495":"numbers_v_droped.head()","d00ab11c":"corr = numbers_v_droped.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 12))\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, vmax=1, center=0,vmin=-1 , \n            square=True, linewidths=.005)","257900b2":"corr = corr.iloc[1:, 1:]\ncorr = corr.applymap(lambda x : 1 if x > 0.75 else -1 if x < -0.75 else 0)\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 12))\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, vmax=1, center=0,vmin=-1 , \n            square=True, linewidths=.005)","4bff6872":"numbers_v_droped['isFraud'] = y\n","e99126c3":"numbers_v_droped.corr()['isFraud'].sort_values()","07c3e1b6":"to_drop_numbers += ['V314', 'V315', 'V308', 'V306', 'V131', 'V130', 'V128', 'V127', 'V285', 'V96', 'V91', 'V82', 'V76',\n                    'V49', 'V48', 'V36', 'V11', 'D2', 'C10', 'C7', 'C8', 'C11', 'C1']","a553af71":"class DataFrameDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, drop_attrs=[]):\n        self.drop_attrs = drop_attrs\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X.drop(self.drop_attrs, axis=1, inplace=True, errors='ignore')\n        return X","6df852fc":"final_numbers = DataFrameDropper(drop_attrs=to_drop_numbers).transform(numbers_v_droped)","692666b1":"del numbers_v_droped","06c5fbbc":"del numbers_cat","e9072fe0":"gc.collect()","82019f11":"labels_p_imputed.head()","b82372bb":"class LabelImputer(TransformerMixin, BaseEstimator):\n    def __init__(self, dummy=False):\n      self.dummy = dummy\n    def fit(self, X, y=None):\n        self.tops = [[], []]\n        for col in X:\n            self.tops[0].append(str(col))\n            self.tops[1].append(X[col].describe()['top'])\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        if self.dummy:\n          return X.fillna('-9999')\n        for i in range(len(self.tops[0])):\n            X[self.tops[0][i]].fillna(self.tops[1][i], inplace=True)\n        return X","3a6890fb":"label_imputer = LabelImputer(dummy=False)\nlabel_imputed = label_imputer.fit_transform(labels_p_imputed)","563d0b4f":"plt.figure(figsize=(20, 5))\nsns.countplot(y=label_imputed['ProductCD'].reset_index()['ProductCD'], hue=y, data=label_imputed)","f3796181":"del labels_p_imputed","9e2c9ee0":"plt.figure(figsize=(20, 10))\nplt.subplot(211)\nsns.countplot(y=label_imputed['card4'].reset_index()['card4'], hue=y)\nplt.subplot(212)\nsns.countplot(y=label_imputed['card6'].reset_index()['card6'], hue=y)","91e4ed4b":"label_imputed[['card6', 'card4']].groupby('card6').agg(['count']).stack()","3fe2fe53":"class ChangeToDebit(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['card6'] = X['card6'].apply(lambda l: l if not l == 'debit or credit' and not l == 'charge card' else 'debit')\n        return X","32f8033c":"label_card6_changed = ChangeToDebit().transform(label_imputed)","53c82f4e":"plt.figure(figsize=(20, 20))\nsns.countplot(y=label_card6_changed['P_emaildomain'].reset_index()['P_emaildomain'], hue=y)","51476316":"class CategorizeEmail(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['P_emaildomain'] = X['P_emaildomain'].apply(lambda l: l if l == 'gmail.com' or \n                                                      l == 'yahoo.com' or\n                                                      l == 'anonymous.com' or \n                                                      l == 'hotmail.com' or\n                                                      l == 'aol.com'\n                                                      else 'others')\n        return X","1667b110":"label_mail_changed = CategorizeEmail().transform(label_card6_changed)","5a18aa72":"plt.figure(figsize=(20, 5))\nsns.countplot(y=label_mail_changed['P_emaildomain'].reset_index()['P_emaildomain'], hue=y)","6c780995":"plt.figure(figsize=(20, 5))\nsns.countplot(y=label_mail_changed['M6'].reset_index()['M6'], hue=y)","6121458f":"from sklearn.preprocessing import OneHotEncoder\nclass OneHotGoodEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.encoder = OneHotEncoder()\n    def fit(self, X, y=None): \n        self.encoder.fit(X)\n        return self\n    def transform(self, X, y=None):\n        columns = X.columns\n        X_transformed = self.encoder.transform(X).toarray()\n        cats = self.encoder.categories_\n        i = 0\n        labels = []\n        for cat in cats:\n            for c in cat:\n                labels.append(columns[i] + ' : ' + c)\n            i = i+1\n        return pd.DataFrame(X_transformed, columns=labels)","269395bf":"encoder = OneHotGoodEncoder()\nencoder.fit(label_mail_changed)\nlabel_encoded = encoder.transform(label_mail_changed)","1d29bf14":"from sklearn.feature_selection import f_regression\nF, p_value = f_regression(label_encoded, y)\nnp.array(label_encoded.columns) + \" = \" + (p_value < 0.05).astype(str) ","f88e50af":"from sklearn.preprocessing import LabelEncoder\nclass ModifiedLabelEncoder(TransformerMixin, BaseEstimator):\n    def fit(self,X, y=None):\n        self.cols=X.columns\n        return self\n    def transform(self,X, y=None):\n        X=X.copy()\n        for f in self.cols:\n          if X[f].dtype=='object': \n            lbl = LabelEncoder()\n            lbl.fit(list(X[f].values) )\n            X[f] = lbl.transform(list(X[f].values))\n        return X","c34a45d1":"del label_mail_changed\ndel label_encoded\ndel label_card6_changed","6d3c3488":"iden_numbers_imputed = final_numbers","31784b03":"id_to_drop = []","475f0380":"ids = ['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_08', 'id_10', \n      'id_11', 'id_12', 'id_13', 'id_14', 'id_17', 'id_19', 'id_20', 'id_32']\ncols = list(iden_numbers_imputed.columns)\nplt.figure(figsize=(20, 20))\nj = 1\nfor i in range(len(cols)):\n    if(str(cols[i]) in ids):\n      plt.subplot(4, 4, j)\n      j+=1\n      sns.distplot(iden_numbers_imputed[cols[i]])","d28e547e":"train_numbers['id_03'].value_counts(dropna=False, normalize=True).head()","23de1071":"id_to_drop.append('id_3')","7c2369a9":"train_numbers['id_04'].value_counts(dropna=False, normalize=True).head()","ee5be58c":"id_to_drop.append('id_04')","6a434fa7":"train_numbers['id_09'].value_counts(dropna=False, normalize=True).head()","3a8a6f90":"id_to_drop.append('id_09')","3a05b867":"train_numbers['id_10'].value_counts(dropna=False, normalize=True).head()","f8f17485":"id_to_drop.append('id_10')","2d75f10e":"corr = iden_numbers_imputed.corr()\ncorr = corr.iloc[1:, 1:]\ncorr = corr.applymap(lambda x : 1 if x > 0.75 else -1 if x < -0.75 else 0)\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 12))\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, vmax=1, center=0,vmin=-1 , \n            square=True, linewidths=.005)","bda0cfe0":"id_labels_to_drop = list()","cb0379a9":"iden_labels_imputed = label_imputed\ndel label_imputed","9029f08d":"# y_i = pd.merge(train_identity, train_transaction, how='inner', on = 'TransactionID')['isFraud']","2d6f1ddd":"cols = ['id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']","be1e37e0":"plt.figure(figsize=(20, 20))\nfor i in range(len(cols)):\n    plt.subplot(4, 3, i+1)\n    sns.countplot(y=iden_labels_imputed[cols[i]].reset_index()[cols[i]], hue=y)\n","cd5d4bcc":"iden_labels_imputed['id_34'].value_counts()","2b1efead":"class MeltMatchStatus(TransformerMixin, BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['id_34'] = X['id_34'].apply(lambda l: 'match_status:1' if l == 'match_status:0'\n                                                                         or  l == 'match_status:-1' else l)\n        return X","a08a24f7":"iden_label_melted = MeltMatchStatus().transform(iden_labels_imputed)","289d99c1":"iden_label_melted['id_30'].value_counts().head()","024c6bfa":"class SimplifyOS(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n         return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['OS'] = X['id_30'].apply(lambda l: 'iOS' if l.find('iOS') is not -1 else 'Android' if l.find('Android') is not -1\n                                  else 'Windows' if l.find('Windows') is not -1 else 'Mac' if l.find('Mac') is not -1 else 'Others')\n        X.drop(['id_30'],axis=1, inplace=True)\n        return X","514790d0":"iden_label_simple = SimplifyOS().transform(iden_label_melted)","e3080a15":"plt.figure(figsize=(20, 5))\nsns.countplot(y=iden_label_simple['OS'].reset_index()['OS'], hue=y)","9d1a1d56":"iden_label_simple['OS'].value_counts().head()","37f065e3":"iden_label_simple['DeviceInfo'].value_counts().head()","f4e9cd14":"id_labels_to_drop.append('DeviceInfo')\niden_label_simple.drop(['DeviceInfo'], axis=1, inplace=True)","a8c81b48":"class SimplifyBrowser(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n         return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['Browser'] = X['id_31'].apply(lambda l: 'm_chrome' if l.find('for android') is not -1 else 'm_safari' if l.find('mobile safari') is not -1\n                                  else 'ie' if l.find('ie') is not -1 else 'ie' if l.find('edge') is not -1\n                                       else 'safari' if l.find('safari') is not -1 else 'chrome' if l.find('chrome') is not -1 \n                                       else 'firefox' if l.find('firefox') is not -1 else 'others')\n        X.drop(['id_31'],axis=1, inplace=True)\n        return X","ce98d84e":"iden_simple_browser = SimplifyBrowser().transform(iden_label_simple)","9d065238":"iden_simple_browser['Browser'].value_counts()","1fbd545f":"plt.figure(figsize=(20, 5))\nsns.countplot(y=iden_simple_browser['Browser'].reset_index()['Browser'], hue=y)","fb8312b7":"class ScreenSimplify(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X = X.copy()\n        X['Screen'] = X['id_33'].apply(lambda l : 'Big' if int(l[:l.find('x')]) *  int(l[l.find('x')+1:]) >= 2073600\n                                       else 'Medium' if int(l[:l.find('x')]) *  int(l[l.find('x')+1:]) > 777040\n                                       else 'Small')\n        X.drop(['id_33'],axis=1, inplace=True)\n        return X","b513e5b8":"iden_simple_screen = ScreenSimplify().transform(iden_simple_browser)","2f3eeb4f":"plt.figure(figsize=(20, 5))\nsns.countplot(y=iden_simple_screen['Screen'].reset_index()['Screen'], hue=y)","5132b47c":"encoder = OneHotGoodEncoder()\nencoder.fit(iden_simple_screen)\nlabel_encoded = encoder.transform(iden_simple_screen)","cefb147a":"from sklearn.feature_selection import f_regression\nF, p_value = f_regression(label_encoded, y)\nnp.set_printoptions(threshold=40)\nnp.array(label_encoded.columns) + \" = \" + (p_value < 0.05).astype(str)","43f88315":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn import preprocessing\nclass FeatureEng(BaseEstimator, TransformerMixin):\n  def fit(self, X, y=None):\n    return self\n  def transform(self, X, y=None):\n    X=X.copy()\n    \n    ## Check proton mail\n    X['P_isproton']=(X['P_emaildomain']=='protonmail.com')\n    X['R_isproton']=(X['R_emaildomain']=='protonmail.com')\n    \n    ## number of nulls\n    X['nulls1'] = X.isna().sum(axis=1)\n    \n    ## check latest browser or not\n    a = np.zeros(X.shape[0])\n    X[\"lastest_browser\"] = a\n    X.loc[X[\"id_31\"]==\"samsung browser 7.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"opera 53.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"mobile safari 10.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"google search application 49.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"firefox 60.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"edge 17.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 69.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 67.0 for android\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 63.0 for android\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 63.0 for ios\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 64.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 64.0 for android\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 64.0 for ios\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 65.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 65.0 for android\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 65.0 for ios\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 66.0\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 66.0 for android\",'lastest_browser']=1\n    X.loc[X[\"id_31\"]==\"chrome 66.0 for ios\",'lastest_browser']=1\n    \n    ## check mail suffix\n    emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n    us_emails = ['gmail', 'net', 'edu']\n    for c in ['P_emaildomain', 'R_emaildomain']:\n      X[c + '_bin'] = X[c].map(emails)\n      X[c + '_suffix'] = X[c].map(lambda x: str(x).split('.')[-1])\n      X[c + '_suffix'] = X[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    del emails, us_emails\n    \n    \n    ### new card, addr features\n    X['card1_count_full'] = X['card1'].map(pd.concat([train_set['card1'], test_set['card1']], ignore_index=True).value_counts(dropna=False))\n    X['card2_count_full'] = X['card2'].map(pd.concat([train_set['card2'], test_set['card2']], ignore_index=True).value_counts(dropna=False))\n    X['card3_count_full'] = X['card3'].map(pd.concat([train_set['card3'], test_set['card3']], ignore_index=True).value_counts(dropna=False))\n    X['card4_count_full'] = X['card4'].map(pd.concat([train_set['card4'], test_set['card4']], ignore_index=True).value_counts(dropna=False))\n    X['card5_count_full'] = X['card5'].map(pd.concat([train_set['card5'], test_set['card5']], ignore_index=True).value_counts(dropna=False))\n    X['card6_count_full'] = X['card6'].map(pd.concat([train_set['card6'], test_set['card6']], ignore_index=True).value_counts(dropna=False))\n    X['addr1_count_full'] = X['addr1'].map(pd.concat([train_set['addr1'], test_set['addr1']], ignore_index=True).value_counts(dropna=False))\n    X['addr2_count_full'] = X['addr2'].map(pd.concat([train_set['addr2'], test_set['addr2']], ignore_index=True).value_counts(dropna=False))\n    \n    ###  Transaction_amt , id02, and D15\n    X['TransactionAmt_to_mean_card1'] = X['TransactionAmt'] \/ X.groupby(['card1'])['TransactionAmt'].transform('mean')\n    X['TransactionAmt_to_mean_card4'] = X['TransactionAmt'] \/ X.groupby(['card4'])['TransactionAmt'].transform('mean')\n    X['TransactionAmt_to_std_card1'] = X['TransactionAmt'] \/ X.groupby(['card1'])['TransactionAmt'].transform('std')\n    X['TransactionAmt_to_std_card4'] = X['TransactionAmt'] \/ X.groupby(['card4'])['TransactionAmt'].transform('std')\n    X['id_02_to_mean_card1'] = X['id_02'] \/ X.groupby(['card1'])['id_02'].transform('mean')\n    X['id_02_to_mean_card4'] = X['id_02'] \/ X.groupby(['card4'])['id_02'].transform('mean')\n    X['id_02_to_std_card1'] = X['id_02'] \/ X.groupby(['card1'])['id_02'].transform('std')\n    X['id_02_to_std_card4'] = X['id_02'] \/ X.groupby(['card4'])['id_02'].transform('std')\n    X['D15_to_mean_card1'] = X['D15'] \/ X.groupby(['card1'])['D15'].transform('mean')\n    X['D15_to_mean_card4'] = X['D15'] \/ X.groupby(['card4'])['D15'].transform('mean')\n    X['D15_to_std_card1'] = X['D15'] \/ X.groupby(['card1'])['D15'].transform('std')\n    X['D15_to_std_card4'] = X['D15'] \/ X.groupby(['card4'])['D15'].transform('std')\n    \n    ###  time of transactions\n    X['Transaction_day_of_week'] = np.floor((X['TransactionDT'] \/ (3600 * 24) - 1) % 7)\n    X['Transaction_hour_of_day'] = np.floor(X['TransactionDT'] \/ 3600) % 24\n    X['TransactionAmt_decimal'] = ((X['TransactionAmt'] - X['TransactionAmt'].astype(int)) * 1000).astype(int)  \n    \n    ### some combinations\n    for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n                    'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n      f1, f2 = feature.split('__')\n      X[feature] = X[f1].astype(str) + '_' + X[f2].astype(str)\n      le =preprocessing.LabelEncoder()\n      le.fit(list(X[feature].astype(str).values))\n      X[feature] = le.transform(list(X[feature].astype(str).values))\n    for feature in ['id_01', 'id_31', 'id_33', 'id_35']:\n    \n    # Count encoded separately for train and test\n      X[feature + '_count_dist'] = X[feature].map(X[feature].value_counts(dropna=False))\n\n    category_features=[\"ProductCD\",\"P_emaildomain\",\n                       \"R_emaildomain\",\"M1\",\"M2\",\"M3\",\"M4\",\"M5\",\"M6\",\"M7\",\"M8\",\"M9\",\"DeviceType\",\"DeviceInfo\",\"id_12\",\n                       \"id_13\",\"id_14\",\"id_15\",\"id_16\",\"id_17\",\"id_18\",\"id_19\",\"id_20\",\"id_21\",\"id_22\",\"id_23\",\"id_24\",\n                       \"id_25\",\"id_26\",\"id_27\",\"id_28\",\"id_29\",\"id_30\",\"id_32\",\"id_34\", 'id_36'\n                       \"id_37\",\"id_38\"]\n    for c in category_features:\n      X[feature + '_count_full'] = X[feature].map(pd.concat([train_set[feature], test_set[feature]], ignore_index=True).value_counts(dropna=False))\n\n    del le\n    return X\n\n","fb2b24dd":"train_set = FeatureEng().transform(train_set)\ntest_set = FeatureEng().transform(test_set)","17d2afec":"class DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attrs):\n        self.attrs = attrs\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        return X.loc[:, self.attrs]\nclass ToDataFrame(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        return pd.DataFrame(X, columns=self.columns)\n        ","c7f61bf3":"from sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import StandardScaler\n\nnumbers_pipeline = Pipeline([\n    ('select', DataFrameSelector(numbers_attrs)),\n    ('p_imputer', PercentImputer(percent=0.9)),\n    ('s_imputer', SimpleImputer(strategy='mean')),\n    ('to_dataFrame', ToDataFrame(columns=numbers_cols)),\n    ('drop_dt_fraud', DataFrameDropper(drop_attrs=['isFraud'])),\n    ('normalize', NormalizeByLog('TransactionAmt')),\n    ('categorize', CategorizeCs()),\n    ('dropVs',  DropExtraVs()),\n    ('drop1', DataFrameDropper(drop_attrs=to_drop_numbers)),\n    ('drop2', DataFrameDropper(drop_attrs=id_to_drop)),\n    ('std_scale', StandardScaler())\n])\n# We use lgb and xgb, so reducing data does not make it better. We can \n# do not use some of our reductions and droppings. Do to that we have more\n# features, therefore it got more time to train, yet we will have a better\n# score.\nlabels_pipeline = Pipeline([\n    ('select', DataFrameSelector(label_atrrs)),\n    ('p_imputer', PercentImputer(percent=0.9)),\n    ('l_imputer', LabelImputer(dummy=True)),\n    ('change_debit', ChangeToDebit()),\n#     ('categorize_email', CategorizeEmail()), \n    ('melt', MeltMatchStatus()),\n#     ('os', SimplifyOS()),\n#     ('browser', SimplifyBrowser()),\n#     ('screen', ScreenSimplify()),\n#     ('drop', DataFrameDropper(drop_attrs=id_labels_to_drop)),\n    ('encode', ModifiedLabelEncoder()),\n    ('std_scale', StandardScaler())\n])\n\npipeline = FeatureUnion([\n    ('numbers', numbers_pipeline),\n    ('labels', labels_pipeline),\n])","1c81d293":"gc.collect()","3da6666c":"del train_labels\ndel train_numbers","d0c9c23f":"X_train = pipeline.fit_transform(train_set)\nX_test = pipeline.transform(test_set)","60701b30":"y_train = y\ndel y","24076b46":"X_train","21f8977b":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import cross_val_predict\ndef show_fpr_tpr(fpr, tpr):\n    plt.plot(fpr, tpr)\n    plt.xlabel(\"False Positive Rate\")\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.ylabel(\"True Positive Rate\")\n    plt.show()\n\ndef analys_model(model, x=X_train, y=y_train):\n    y_probs = cross_val_predict(model, x, y, cv=3, method=\"predict_proba\", n_jobs=-1)\n    y_score = y_probs[:, -1]\n    fpr, tpr, threshold = roc_curve(y, y_score)\n    show_fpr_tpr(fpr, tpr)\n    print(roc_auc_score(y, y_score))","fb4cb360":"from sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)","31b32d2b":"analys_model(rf_clf, x=X_train, y=y_train)","a3a230fa":"from sklearn.model_selection import TimeSeriesSplit,KFold\nn_fold = 4\nfolds = KFold(n_splits=n_fold,shuffle=True)\n\nprint(folds)","09b8e6f5":"X_train","2685ece6":"lgb_submission=sample_submission.copy()\nlgb_submission['isFraud'] = 0\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n    print(fold_n)\n    \n    X_train_, X_valid = X_train[train_index], X_train[valid_index]\n    y_train_, y_valid = y_train[train_index], y_train[valid_index]\n    dtrain = lgb.Dataset(X_train, label=y_train)\n    dvalid = lgb.Dataset(X_valid, label=y_valid)\n    \n    lgbclf = lgb.LGBMClassifier(\n        num_leaves= 512,\n        n_estimators=512,\n        max_depth=9,\n        learning_rate=0.064,\n        subsample=0.85,\n        colsample_bytree=0.85,\n        boosting_type= \"gbdt\",\n        reg_alpha=0.3,\n        reg_lamdba=0.243,\n        verbosity=-1,\n    )\n    \n    X_train_, X_valid = X_train[train_index], X_train[valid_index]\n    y_train_, y_valid = y_train[train_index], y_train[valid_index]\n    lgbclf.fit(X_train_,y_train_)\n    \n    del X_train_,y_train_\n    print('finish train')\n    pred=lgbclf.predict_proba(X_test)[:,1]\n    val=lgbclf.predict_proba(X_valid)[:,1]\n    print('finish pred')\n#     del lgbclf, X_valid\n    print('ROC accuracy: {}'.format(roc_auc_score(y_valid, val)))\n    del val,y_valid\n    lgb_submission['isFraud'] = lgb_submission['isFraud']+pred\/n_fold\n    del pred","813d0817":"lgb_submission.to_csv('.\/lgb.csv')\n","1cec1da0":"xgb_submission=sample_submission.copy()\nxgb_submission['isFraud'] = 0\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n    print(fold_n)\n    xgbclf = xgb.XGBClassifier(\n        n_estimators=512,\n        max_depth=16,\n        learning_rate=0.014,\n        subsample=0.85,\n        colsample_bytree=0.85,\n        missing=-999,\n        tree_method='gpu_hist',\n        reg_alpha=0.3,\n        reg_lamdba=0.243\n    )\n    \n    X_train_, X_valid = X_train[train_index], X_train[valid_index]\n    y_train_, y_valid = y_train[train_index], y_train[valid_index]\n    xgbclf.fit(X_train_,y_train_)\n    del X_train_,y_train_\n    pred=xgbclf.predict_proba(X_test)[:,1]\n    val=xgbclf.predict_proba(X_valid)[:,1]\n    del xgbclf, X_valid\n    print('ROC accuracy: {}'.format(roc_auc_score(y_valid, val)))\n    del val,y_valid\n    xgb_submission['isFraud'] = xgb_submission['isFraud']+pred\/n_fold\n    del pred\n    gc.collect()","55455a12":"xgb_submission.to_csv( '.\/xgb.csv')","4ad59969":"y_final = sample_submission.copy()\ny_final['isFraud'] = 0.5 * xgb_submission['isFraud'] + 0.5 * lgb_submission['isFraud']","5dc6b8c2":"y_final.to_csv('.\/prediction.csv')","32ee8323":"y_final.head()","78f9c1ed":"I think it is ok !","89b44864":"#### Compute P-Value score\nWith p-value we can recognize to delete which one of them.","cee153a3":"# Submit Predictions","e213c344":"Lots of C values are less than 4. we can categorize C attributes into 4 category by their period of values.","b9a90116":"### Transaction Amount ","f12ef2d8":"It seems has not any problem.","2564816f":"There are a lot of features which have colinearity with each other. First we see every feature correlation with isFraud. Then add some atts to `to_drop` set.","a0854d11":"### id_10","a0389be5":"### id_04","f4d420dc":"### cards","bd6ecd25":"We will drop card3 becasue most of them have a specific value. Here there is a lot of 127-128 numbers (about 522000).","5fe3a7d6":"It seems most of ProductCDs values are `W`. On the other hand `C` values have a good possibility to be Fraud. This data seems has not any specific problem.","93ede99e":"Its like OS and we will delete it. ","a498344c":"### Check p-value","bc019741":"In card6 we have two category which have not any count. Let see values count correctly.\n","2052bdb7":"There is a lot of numbers which are less than 4. On the other hand there is some numbers with higher value. We can divide these numbers into 4 groups. less than equal 4 and more than 4. ","ac6c3557":"#### Drop ID","f0ebd96e":"### Simple Imputer \nThen impute them with simple imputer and mean method","ba943ae7":"## Drop extra columns\nWe gather some columns to drop in these steps. Now in this step we will drop them from dataframe.","80e6387e":"### Device Info","95fcab88":"All of categories have true values. So we can not delete them. ","bbdfc36d":"### M6","0eb49ce1":"### Impute","b0ef0340":"Well it is device size.","ab927a17":"### dist","7c961af8":"What about other cols `id_30`,`id_31`, `id_33`,`DeviceInfo`","4b99498c":"Here we delete features which have just two value more than 85 percent of all values. ","964e6df2":"There is 15 charge card and 30 debit or credit which all of them are not fraud. so we change these two category into debit.\n","0a51d242":"### Count Plot","38628536":"## C attributes","be60ea27":"## Creating Pipeline ","2cdc5c23":"### Prodocut CD","3e7e626d":"### Train Pipeline","0492352f":"## Train Random Forest","07dd9522":"## Colinearity ","98d09553":"## Deleting Null Columns\n","6132c08d":"At first we impute null values in our dataframe. For this act we use most frequent value of every columns.\n","82999934":"# IEEE Fraud Detection\n# Full EDA - LGB & XGB - Voting - Feature Engineering and Selection","a68bf92d":"## Visualize","502a5320":"### addrs","2bcb9059":"Do to lots of memory usage, we use this function to reduce `float32` type to some new smaller type.","1fa8fe73":"## Train XGB classifier","30a5b9b4":"### id_03","d96434d2":"### id_30","410f809a":"### Encoding labels","79b4147e":"### id_09","eac7b913":"### Impute","a020b6ef":"Then we try to analys each column separately.","780c16dc":"## V attributes","429db6da":"Here we just change match_status: 0 & -1 into match_status : 1","ff40735b":"<img src=\"https:\/\/www.finance-monthly.com\/Finance-Monthly\/wp-content\/uploads\/2017\/10\/Bank-Credit-Card-Fraud-Still-the-Most-Common-Type-of-Fraud.jpg\"\/>","1586125e":"### id_31","31965de8":"card4 seems to be correct and we don't change it.","e0aa3e36":"## Analys Labels of Transactions","00e9516a":"## Impute","91c0ad6f":"### P_emaildomain","db2a3665":"As you see we set a ylim to plot. Because there is a number with value about 30000. This number ruins away our plot. It also may destroy our training; therefore, we change numbers above 60000 to 6000. Also we can try to normalize datas.","5b841d63":"## Analyis identity numbers ","a5d37c7a":"### id_33","e3beb508":"## Train LGB classifier","6312fbf8":"## Others Feature Eng.\nHere is some feature engineering. These feature engineearings gathered from all over other kernels. My own feature engineerings are above. ","bde824e0":"## Analys identity lables","b177cb44":"## Training Models","a470665e":"## D attributes","fc2750cf":"### Check colinearity\n","41b55f05":"From this plot we can make new categoris. `gmail.com` , `yahoo.com`, `anonymous.com`, `hotmail.com`, `aol.com` and `others`.","3951336c":"## Gather The Data","ba252088":"From above counts we can recognize most of addr2 features are 86-87. So we can drop this feature from our train set because it we doesn't need this, and it does not have any specific imapct on our predictions.","babed378":"All of them are needed.","b9aa2108":"# Analys Identity","285c1401":"### TransactionDT","61f29d14":"98 percent of datas are either missing or zero, so we will drop it.","20ec7c58":"### cards","4585263f":"## Analys numbers of transactions","d7e0f446":"From above plots we recognize all c3 values are zero, so, it is useless and we will drop it. On the other hand C7 can categorize by 2 instead of 4. so, we will change CategorizeCs class.'","116ac0cb":"### Percent Imputer\nFirst we delete columns which have less than 90% of all entry numbers. ","a912c2b4":"TransactionDT has a normall distriboution and no need to change."}}