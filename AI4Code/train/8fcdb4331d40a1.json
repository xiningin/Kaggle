{"cell_type":{"68755219":"code","ad747c90":"code","9923d1d8":"code","0fe498e7":"code","b62c40c2":"code","e35441e2":"code","1b4aef93":"code","e1a61609":"code","37e43390":"code","8a193d0b":"code","f43dd077":"code","f4a5c473":"code","c89b2793":"code","06eed140":"code","8a8ba400":"code","78bbc20d":"code","2a00dd0b":"code","e119b5b5":"code","be97ff65":"code","4807db50":"code","2cdf9c0a":"code","5af51b7f":"code","74529ef8":"markdown","edc895d5":"markdown"},"source":{"68755219":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad747c90":"import torch\nfrom tqdm.notebook import tqdm\nimport pandas as pd \n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\n\nfrom transformers import BertForSequenceClassification\n\ndf1 = pd.read_csv(\"..\/input\/test-dataset1\/News%20%26%20Magazines.csv\")\ndf2 = pd.read_csv(\"..\/input\/test-dataset1\/education.csv\")\ndf3 = pd.read_csv(\"..\/input\/test-dataset1\/app_description_en_100_L1_Productivity.csv\")\ndf4 = pd.read_csv(\"..\/input\/test-dataset1\/entertainment_L1.csv\")\ndf5 = pd.read_csv(\"..\/input\/test-dataset1\/photography-L1.csv\")\ndf6 = pd.read_csv(\"..\/input\/test-dataset1\/shopping_L1.csv\")\n\n\nprint(df1.columns)\nprint(df2.columns)\nprint(df3.columns)\nprint(df4.columns)\nprint(df5.columns)\nprint(df6.columns)\n\ndf3 = df3.rename(columns={'Label_L1': 'label'})\ndf4 = df4.rename(columns={'genres': 'label'})\ndf5 = df5.rename(columns={'manual label': 'label'})\ndf6 = df6.rename(columns={'B': 'id', 'C': 'description', 'D': 'genre', 'E': 'label'})\n\ndf1 = df1.append(df2)\ndf1 = df1.append(df3)\ndf1 = df1.append(df4)\ndf1 = df1.append(df5)\ndf1 = df1.append(df6)\ndf = df1\n\ndf = df.rename(columns={'label': 'man_label'})\ndf = df[['id','description', 'genre', 'man_label']]\ndf = df[df['genre'].notna()]\nchosen = 'Productivity'\ndf = df[df['genre'] == chosen] \ndf_all = df\nprint(len(df))\ndf = df[df['man_label'].notna()]\nprint(len(df))\ndf['man_label'] = list(chosen + \"\/\" + df['man_label'])\nprint(df.head())\nprint(len(df))\ndf_x = df","9923d1d8":"def get_min_rows(df, mini=-1):\n    counts = list(df.man_label.value_counts())\n    if mini==-1:\n        mini = counts[-1]\n    df_trim = df.groupby('man_label').head(mini)\n    print(df_trim.man_label.value_counts())\n    return df_trim\n\ndf = get_min_rows(df)\ndf_x = df\nprint(df_x.head())\ndf = df[['description', 'man_label']]","0fe498e7":"def clean_df(df):\n    for i, row in df.iterrows():\n        df.loc[i, 'man_label'] = df.loc[i,'man_label'].replace(\"Editor\/\", \"Editors\/\")\n    return df\n\ndef get_hier_counts(df):\n    df = df.sort_values(by=['man_label'], ascending=True)\n    \n    df = df[df['man_label'].notna()]\n#     print(dict(df.man_label.value_counts()))\n\n    hierarchical_counts = {}\n    for key in list(df.man_label):\n        prev = \"\"\n        for k in key.split(\"\/\"):\n            if prev + k in hierarchical_counts.keys():\n                hierarchical_counts[prev + k] = hierarchical_counts[prev + k] + 1\n            else:\n                hierarchical_counts[prev + k] = 1\n            prev = prev + k + \"\/\"\n\n    hierarchical_counts = dict(sorted(hierarchical_counts.items(), key=lambda x: x[1], reverse=True))\n\n    return hierarchical_counts\n\ndef get_val_counts(df):\n    return dict(df.man_label.value_counts())\n\ndef remove_lower(df, n1=4, n2=3):\n    df = clean_df(df)\n    df = df.sort_values(by=['man_label'])\n    df2 = df\n    for i, row in df.iterrows():\n        hierarchical_counts = get_hier_counts(df2)\n        value_counts = get_val_counts(df2)\n        \n        if value_counts[df.loc[i,'man_label']] < n1:\n            key = df.loc[i,'man_label']\n            key_list = key.split(\"\/\")\n#             print(key, key_list)\n            n = 0\n            while len(key_list) > 1 and n == 0:\n                key_list = key_list[:-1]\n                key = \"\/\".join(key_list)\n#                 print(key, key_list)\n                if hierarchical_counts[key] > n2:\n                    df.loc[i,'man_label'] = key\n                    df2.loc[i,'man_label'] = key\n                    n = 1\n                    break\n            if n == 0:\n                df.loc[i,'man_label'] = key_list[0]\n                df2.loc[i,'man_label'] = key_list[0]\n                \n        else:\n            key = df.loc[i,'man_label']\n            key_list = key.split(\"\/\")\n#             print(\">10\", key, key_list)\n\n#         print(\"-\"*80)\n    return df\n\ndf = df_x\n# df = remove_lower(df, 1, 0)\n# df = remove_lower(df, 10, 5)\nprint(df.man_label.value_counts())","b62c40c2":"possible_labels = df.man_label.unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nlabel_dict","e35441e2":"df['label'] = df.man_label.replace(label_dict)","1b4aef93":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df.index.values, \n                                                  df.label.values, \n                                                  train_size=0.75, \n                                                  random_state=42,\n                                                  stratify=df.label.values)\n\nprint(X_train.shape, X_val.shape)\ndf['data_type'] = ['not_set']*df.shape[0]\n\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'\n\ndf.groupby(['man_label', 'label', 'data_type']).count()","e1a61609":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n                                          \nencoded_data_train = tokenizer.batch_encode_plus(\n    df[df.data_type=='train'].description.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=512, \n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    df[df.data_type=='val'].description.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=512, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type=='train'].label.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type=='val'].label.values)\n\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","37e43390":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","8a193d0b":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 4\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)","f43dd077":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(),\n                  lr=1e-4, \n                  eps=1e-8)\n                  \nepochs = 5\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","f4a5c473":"from sklearn.metrics import f1_score\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    correct = 0\n    total = 0\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}\/{len(y_true)}')\n        correct = correct + len(y_preds[y_preds==label])\n        total = total + len(y_true)\n        print('Accuracy Percentage: {:.2f}% \\n'.format((len(y_preds[y_preds==label])\/len(y_true))*100))\n    \n    print('Model Accuracy: {:.2f}'.format((correct\/total)*100))","c89b2793":"import random\n\nseed_val = 17\ndevice='cuda'\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\nmodel = model.to(device)\n\n\ndef evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total\/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals\n    \nfor epoch in tqdm(range(1, epochs+1)):\n    \n    model.train()\n    \n    loss_train_total = 0\n\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    for batch in progress_bar:\n\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()\/len(batch))})\n         \n        \n    torch.save(model.state_dict(), f'.\/prod_epoch_{epoch}.model')\n        \n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total\/len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')","06eed140":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n\nmodel.to(device)\n\nmodel.load_state_dict(torch.load('.\/prod_epoch_5.model', map_location=torch.device('cuda')))","8a8ba400":"_, predictions, true_vals = evaluate(dataloader_validation)\naccuracy_per_class(predictions, true_vals)","78bbc20d":"import pandas as pd\n\ndf1 = pd.read_csv(\"\/kaggle\/input\/stemmed-description-tokens-and-application-genres\/bundles_desc_tokens.csv\", nrows=100000)\ndf2 = pd.read_csv(\"\/kaggle\/input\/stemmed-description-tokens-and-application-genres\/bundles_desc.csv\", nrows=100000)\ndf_all = pd.merge(df2,df1,left_on=\"id\",right_on=\"id\",how=\"left\")","2a00dd0b":"df_all = df_all.drop(columns = ['tokens','genres'])\ndf_all = df_all[df_all['genre'] == 'Productivity']\nprint(df_all.head(5))","e119b5b5":"df_all_index = df_all.set_index(['id']).index\ndf_x_index = df_x.set_index(['id']).index\nmask = ~df_all_index.isin(df_x_index)\ndf_un = df_all.loc[mask]\nprint(\"Complete dataset: \", len(df_all))\nprint(\"Unlabelled dataset: \", len(df_un))\nprint(\"Labelled dataset: \", len(df_x))","be97ff65":"label_dict","4807db50":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import f1_score\nimport random\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    correct = 0\n    total = 0\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}\/{len(y_true)}')\n        correct = correct + len(y_preds[y_preds==label])\n        total = total + len(y_true)\n        print('Accuracy Percentage: {:.2f}% \\n'.format((len(y_preds[y_preds==label])\/len(y_true))*100))\n    \n    print('Model Accuracy: {:.2f}'.format((correct\/total)*100))\n\nseed_val = 17\ndevice='cuda'\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\nmodel = model.to(device)\n\n\ndef evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total\/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals\n\n\ndef iterative_training(df, tokenizer, model, iteration, epochs=3):\n    \n    print(\"-\"*80)\n    print(\"Iteration {}\".format(iteration))\n    \n    df = df[['description', 'man_label']]\n    \n    possible_labels = df.man_label.unique()\n\n    label_dict = {}\n    for index, possible_label in enumerate(possible_labels):\n        label_dict[possible_label] = index\n\n    df['label'] = df.man_label.replace(label_dict)\n    \n    X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n                                                      df.label.values, \n                                                      train_size=0.75, \n                                                      random_state=42,\n                                                      stratify=df.label.values)\n\n    print(\"Shape:\",X_train.shape, X_val.shape)\n    \n    df['data_type'] = ['not_set']*df.shape[0]\n\n    df.loc[X_train, 'data_type'] = 'train'\n    df.loc[X_val, 'data_type'] = 'val'\n\n#     print(df.groupby(['man_label', 'label', 'data_type']).count())\n    \n                                          \n    encoded_data_train = tokenizer.batch_encode_plus(\n        df[df.data_type=='train'].description.values, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n\n    encoded_data_val = tokenizer.batch_encode_plus(\n        df[df.data_type=='val'].description.values, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n\n\n    input_ids_train = encoded_data_train['input_ids']\n    attention_masks_train = encoded_data_train['attention_mask']\n    labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n\n    input_ids_val = encoded_data_val['input_ids']\n    attention_masks_val = encoded_data_val['attention_mask']\n    labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n\n    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n    \n    batch_size = 4\n\n    dataloader_train = DataLoader(dataset_train, \n                                  sampler=RandomSampler(dataset_train), \n                                  batch_size=batch_size)\n\n    dataloader_validation = DataLoader(dataset_val, \n                                       sampler=SequentialSampler(dataset_val), \n                                       batch_size=batch_size)\n    \n    optimizer = AdamW(model.parameters(),\n                  lr=1e-4, \n                  eps=1e-8)\n                  \n\n    scheduler = get_linear_schedule_with_warmup(optimizer, \n                                                num_warmup_steps=0,\n                                                num_training_steps=len(dataloader_train)*epochs)\n    \n    for epoch in range(1, epochs+1):\n        \n        model.train()\n\n        loss_train_total = 0\n\n        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=True, disable=False, position=0)\n        for batch in progress_bar:\n\n            model.zero_grad()\n\n            batch = tuple(b.to(device) for b in batch)\n\n            inputs = {'input_ids':      batch[0],\n                      'attention_mask': batch[1],\n                      'labels':         batch[2],\n                     }       \n\n            outputs = model(**inputs)\n\n            loss = outputs[0]\n            loss_train_total += loss.item()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n            scheduler.step()\n\n            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()\/len(batch))})\n\n\n        torch.save(model.state_dict(), f'.\/prod_AL_iter_{iteration}_epoch_{epoch}.model')\n\n        tqdm.write(f'\\nEpoch {epoch}')\n\n        loss_train_avg = loss_train_total\/len(dataloader_train)            \n        tqdm.write(f'Training loss: {loss_train_avg}')\n\n        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n        val_f1 = f1_score_func(predictions, true_vals)\n        tqdm.write(f'Validation loss: {val_loss}')\n        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n    \n    print(\"------------------Predictions-----------------------\")\n    _, predictions, true_vals = evaluate(dataloader_validation)\n    accuracy_per_class(predictions, true_vals)\n    \n    ","2cdf9c0a":"from tqdm import tqdm\nimport torch.nn.functional as F\nimport transformers\nfrom transformers import pipeline\ntransformers.logging.set_verbosity_error()\n\ndevice = 'cuda'\n\nthreshold_score = 0.45\n\nepochs = 5\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True,\n                                          pad_to_max_length=True, \n                                          max_length=512)\n\ni = 0\nitera = 1\n\n model_path = str(input(\"Enter the most accurate model path\"))\n\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                  num_labels=len(label_dict),\n                                                  output_attentions=False,\n                                                  output_hidden_states=False)\n\nmodel.to(device)\n\nmodel.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n\n    \nwhile i < len(df_un):\n    \n    print(\"Number of rows in the dataset: {}\".format(len(df_x)))\n    \n    if i + 100 < len(df_un):\n        df_un_s = df_un[i:i+100]\n        i = i + 100\n    else:\n        df_un_s = df_un[i:]\n        i = len(df_un)\n    k = 0\n    \n    iterative_training(df_x, tokenizer, model, itera, epochs=epochs)\n    \n    model_path = str(input(\"Enter the most accurate model path\"))\n    \n    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n\n    model.to(device)\n\n    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n    \n    for index,row in tqdm(df_un_s.iterrows(), total=len(df_un_s), desc='Labelling unseen data for iteration {}'.format(itera),leave=True, disable=False, position=0):\n        desc = row['description']\n        classi = pipeline('sentiment-analysis', model=model.to('cpu'), tokenizer=tokenizer)\n        try:\n            output = classi(desc[:512])\n    #         print(\"Output: \",output)\n            output = output[0]\n            for key in list(label_dict.keys()):\n                if label_dict[key] == int(output['label'].split(\"_\")[1]):\n                    label = key\n                    break\n            label_ind = int(output['label'].split(\"_\")[1])\n            score = float(output['score'])\n            if score > threshold_score:\n                k = k + 1\n                df_x = df_x.append({'id': row['id'], 'description': row['description'], 'genre': row['genre'], 'man_label': label, 'label': label_ind}, ignore_index=True)\n        except:\n            pass\n    \n    print(\"Added {} rows to df in this iteration {}\".format(k, itera))\n\n    d = int(input(\"Do you want to continue? 1\/0\"))\n    if d == 0:\n        break\n    itera = itera + 1\n    ","5af51b7f":"good_model = '.\/prod_AL_iter_4_epoch_5.model' \n# But data added till iter 5. So check it before running","74529ef8":"**Active Learning**","edc895d5":"**Run Active Learning**"}}