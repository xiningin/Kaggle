{"cell_type":{"153e1795":"code","03b2b045":"code","3d07e2f9":"code","6df508aa":"code","c7464938":"code","295a4acc":"code","5a8faf5e":"code","299c8a7e":"code","1015263a":"code","7e183c0a":"code","4aa3f62f":"code","3ef9ace5":"code","6c377b87":"code","a267845c":"code","d397b10b":"code","ad08a7de":"code","218ffe2e":"code","eb616672":"code","b8b9debc":"code","ada4e404":"code","7b75c5ab":"code","76f8ee34":"code","ee74d7c0":"markdown","e628f227":"markdown","1acf0bc0":"markdown","8ebe055a":"markdown","ebc7e456":"markdown","008746f2":"markdown","61f45846":"markdown","a04184e8":"markdown"},"source":{"153e1795":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03b2b045":"import torch\n\nfrom torch import nn","3d07e2f9":"import math\nimport matplotlib.pyplot as plt","6df508aa":"torch.manual_seed(111)","c7464938":"train_data_length=1024","295a4acc":"train_data=torch.zeros((train_data_length,2))","5a8faf5e":"train_data[:,0]=2*math.pi*torch.rand(train_data_length)","299c8a7e":"#Takes the sin value of the first column\n\ntrain_data[:,1]=torch.sin(train_data[:,0])","1015263a":"train_labels=torch.zeros(train_data_length)","7e183c0a":"train_set=[(train_data[i],train_labels[i]) for i in range(train_data_length)]","4aa3f62f":"train_set","3ef9ace5":"plt.plot(train_data[:,0],train_data[:,1],'.')","6c377b87":"batch_size=32\n\ntrain_loader=torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)","a267845c":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(2, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","d397b10b":"discriminator = Discriminator()","ad08a7de":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(2, 16),\n            nn.ReLU(),\n            nn.Linear(16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 2),\n        )\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","218ffe2e":"generator=Generator()","eb616672":"lr = 0.001\nnum_epochs = 300\nloss_function = nn.BCELoss()","b8b9debc":"optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\noptimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)","ada4e404":"for epoch in range(num_epochs):\n    for n, (real_samples, _) in enumerate(train_loader):\n        # Data for training the discriminator\n        real_samples_labels = torch.ones((batch_size, 1))\n        latent_space_samples = torch.randn((batch_size, 2))\n        generated_samples = generator(latent_space_samples)\n        generated_samples_labels = torch.zeros((batch_size, 1))\n        all_samples = torch.cat((real_samples, generated_samples))\n        all_samples_labels = torch.cat(\n            (real_samples_labels, generated_samples_labels)\n        )\n\n        # Training the discriminator\n        discriminator.zero_grad()\n        output_discriminator = discriminator(all_samples)\n        loss_discriminator = loss_function(\n            output_discriminator, all_samples_labels)\n        loss_discriminator.backward()\n        optimizer_discriminator.step()\n\n        # Data for training the generator\n        latent_space_samples = torch.randn((batch_size, 2))\n\n        # Training the generator\n        generator.zero_grad()\n        generated_samples = generator(latent_space_samples)\n        output_discriminator_generated = discriminator(generated_samples)\n        loss_generator = loss_function(\n            output_discriminator_generated, real_samples_labels\n        )\n        loss_generator.backward()\n        optimizer_generator.step()\n\n        # Show loss\n        if epoch % 10 == 0 and n == batch_size - 1:\n            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")","7b75c5ab":"latent_space_samples = torch.randn(100, 2)\ngenerated_samples = generator(latent_space_samples)","76f8ee34":"generated_samples = generated_samples.detach()\nplt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")","ee74d7c0":"**The discriminator takes two data points and tells whether the data is real or fake,so it outputs one data that returns from the sigmoid**","e628f227":"# Creating generator","1acf0bc0":"**We can see that the generated samples from the generator resembles the real sample of the sin wave**","8ebe055a":"# Creating discriminator","ebc7e456":"**In this case, it\u2019s a model with a two-dimensional input, which will receive random points (z\u2081, z\u2082), and a two-dimensional output that must provide (x\u0303\u2081, x\u0303\u2082) points resembling those from the training data.**","008746f2":"# Train the models","61f45846":"# Prepare training data","a04184e8":"**Data loader**"}}