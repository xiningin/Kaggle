{"cell_type":{"4b28cea2":"code","f9f4cb50":"code","20576ea3":"code","527bbbaa":"code","52dc9b97":"code","e840c2cc":"code","c74a53f9":"code","7e889d02":"code","f8dd6c57":"code","3bad6acd":"code","dab16859":"code","72918708":"code","3f93802a":"code","f5a727c1":"code","33ee8a44":"code","b782e6a0":"markdown","d29c31fe":"markdown","fec32fb9":"markdown","36c659bc":"markdown","f233f471":"markdown","12ef61d7":"markdown","c86354a3":"markdown","1d6cd7c2":"markdown","bae610ec":"markdown","bb951ee5":"markdown","3401c7be":"markdown","7a06ea6a":"markdown"},"source":{"4b28cea2":"import numpy as np \nimport pandas as pd \nimport pickle\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\nimport os","f9f4cb50":"for dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))","20576ea3":"# Opening file for reading in binary mode\nwith open('..\/input\/traffic-signs-preprocessed\/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for \/using in Keras\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)","527bbbaa":"%matplotlib inline\n\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:81, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('training_examples.png')\nplt.close()","52dc9b97":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","e840c2cc":"filters = [3]\n#filters = [3,5,9,13,15,19,23,25,31]\n\nmodel = [0] * len(filters)\n\nfor i in range(len(model)):\n    model[i] = Sequential()\n    model[i].add(Conv2D(32, kernel_size=filters[i], padding='same', activation='relu', input_shape=(32, 32, 3)))\n    model[i].add(MaxPool2D(pool_size=2))\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","c74a53f9":"filters1 = 3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=filters1, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","7e889d02":"annealer1 = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 12\nprint(\"u\")\nh1 = model.fit(data['x_train'], data['y_train'],\n                    batch_size=5, epochs = epochs,\n                    validation_data = (data['x_validation'], data['y_validation']),\n                    callbacks=[annealer], verbose=1)\n\n\nprint('Model with filters {0:d}x{0:d}, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}'.\\\n  format(filters1, epochs, max(h1.history['acc']), max(h1.history['val_acc'])))","f8dd6c57":"for i in range(len(model)):\n    temp = model[i].predict(data['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data['y_test'])\n    \n    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))","3bad6acd":"# Getting scores from forward pass of one input image\n# Scores are given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\nfor i in range(len(model)):\n    start = timer()\n    temp = model[i].predict(data['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('data2 filter {0:d} classification time = {1:.5f}'.format(filters[i], end - start))","dab16859":"for i in range(len(model)):\n    w = model[i].get_weights()\n    print(w[0].shape)\n    temp = w[0].transpose(3, 0, 1, 2)\n    print(temp.shape)  # (81, 32, 32, 3)\n\n    # Plotting\n    fig = plt.figure()\n    grid = convert_to_grid(temp)\n    plt.imshow(grid.astype('uint8'), cmap='gray')\n    plt.axis('off')\n    plt.gcf().set_size_inches(10, 10)\n    name = 'Trained filters ' + str(filters[i]) + 'x' + str(filters[i])\n    plt.title(name, fontsize=18)\n    \n    # Showing the plot\n    plt.show()\n\n    # Saving the plot\n    name = 'filters-' + str(filters[i]) + 'x' + str(filters[i]) + '.png'\n    fig.savefig(name)\n    plt.close()","72918708":"%matplotlib inline\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][94:95]\nprint(x_input.shape)\ny_input = data['y_test'][94:95]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\nplt.show()\n\nscores = model[0].predict(x_input)\nprint(scores[0].shape) # (43,)\n\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\ndef label_text(file):\n    label_list = []\n    \n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('..\/input\/traffic-signs-preprocessed\/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])","3f93802a":"pip install gTTS","f5a727c1":"from gtts import gTTS\nmytext = labels[prediction]\nlanguage = 'en'\nmyobj = gTTS(text=mytext, lang=language, slow=False)\nmyobj.save(\"prediction.mp3\")","33ee8a44":"for i in range(len(model)):\n    name = 'model-' + str(filters[i]) + 'x' + str(filters[i]) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink","b782e6a0":"# Visualizing filters of convolutional layer","d29c31fe":" ## Setting up Directory","fec32fb9":"# Predicting with one image from test dataset","36c659bc":"# Calculating accuracy with testing dataset","f233f471":"# Building set of models of CNN with Keras\n## Making different models with different dimensions of filters","12ef61d7":"# Saving models","c86354a3":"# Building model of CNN with Keras\n## Trying one model with filters of size 3x3","1d6cd7c2":"# Importing libraries and files","bae610ec":"# Showing some examples","bb951ee5":"# Training set of models of CNN with Keras\n## And with different dimensions of filters","3401c7be":"# Loading dataset data2.pickle with RGB examples","7a06ea6a":"# Time for classification"}}