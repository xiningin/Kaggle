{"cell_type":{"ad820ed7":"code","64f98014":"code","7b68032c":"code","c69a80a0":"code","17c16a76":"code","8cc7cc6f":"code","37fc99f8":"code","7d505401":"code","16a1dca5":"code","29ee0a13":"code","989a82c4":"code","ba7677d7":"code","844c1418":"code","97a97ae4":"code","9c020c0e":"code","e03101ab":"code","936ae9dd":"code","38b4e639":"code","8fe1ad86":"code","a25f7090":"code","da302ce0":"code","55e6139e":"code","3c6027d3":"code","4e524efd":"code","56b11bd5":"code","6f12d73e":"code","f06a498f":"code","bde35d7e":"code","60d89406":"code","81245c43":"code","0668e4d4":"code","f7e88d4c":"code","33534546":"code","bf100dbd":"code","b53dc5c0":"code","61c29392":"code","908b704e":"code","acaa2deb":"code","c2df678b":"code","e3771560":"code","cc94e564":"code","1120bf5e":"code","de894970":"code","f9550dbd":"code","7d2fb8b9":"code","50b41337":"code","ee840684":"code","a08feeb4":"markdown","08128f28":"markdown","992bd310":"markdown","53dea09a":"markdown","6e4da562":"markdown","62ccd555":"markdown","d74d9528":"markdown","db66f32e":"markdown","6fdf9ab2":"markdown","f3d7e4ab":"markdown","684df119":"markdown","1ae0e267":"markdown","c87240cc":"markdown","4ad74f95":"markdown"},"source":{"ad820ed7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64f98014":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img","7b68032c":"#load data\ndata = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_3_data.txt\",sep = \"\\t\" )\ndata1 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_1_data.txt\",sep = \"\\t\")\ndata2 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_2_data.txt\",sep = \"\\t\")\ndata3 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_0_data.txt\",sep = \"\\t\")\ndata4 = pd.read_csv(\"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/fold_4_data.txt\",sep = \"\\t\")","c69a80a0":"#gathring the data\ntotal_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\nprint(data.shape)\nprint(data1.shape)\nprint(data2.shape)\nprint(data3.shape)\nprint(data4.shape)\nprint(total_data.shape)","17c16a76":"#present data\ntotal_data.head()","8cc7cc6f":"#data describtion\ndata.describe()","37fc99f8":"#data types\ntotal_data.dtypes\n#total_data.info()","7d505401":"#pie_graph to present gender\nplt.figure(1, figsize=(8,8))\ntotal_data.gender.value_counts().plot.pie(autopct=\"%1.1f%%\")\nplt.show()\ntotal_data.gender.value_counts()","16a1dca5":"#bar chart to present age\n\nage = ['(25, 32)' , '(0, 2)', '(38, 43)' ,'(4, 6) ','(8, 12)','(15, 20)','(60, 100)','(48, 53)' ,'None','35','13','22','34','23' ,'45','(27, 32)','55','36','(38, 42)','57','3','29','(38, 48)','58','2','32','56','(8, 23)','46','42']\n\nplt.figure(figsize=(15, 5))  # width:20, height:3\nplt.bar(age, total_data.age.value_counts(), align='center', alpha=0.8)\nplt.ylabel('count')\nplt.show()\n#to Create horizontal bar plot here \"plt.barh(labels, values)\"\n\ntotal_data.age.value_counts()","29ee0a13":"#present image from the dataset\npath = \"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/faces\/\"+total_data.user_id.loc[8]+\"\/coarse_tilt_aligned_face.\"+str(total_data.face_id.loc[8])+\".\"+total_data.original_image.loc[8]\nimg = load_img(path)\nplt.imshow(img)\nplt.show()","989a82c4":"df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()","ba7677d7":"img_path = []\nfor row in total_data.iterrows():\n    path = \"\/kaggle\/input\/adience-benchmark-gender-and-age-classification\/AdienceBenchmarkGenderAndAgeClassification\/faces\/\"+row[1].user_id+\"\/coarse_tilt_aligned_face.\"+str(row[1].face_id)+\".\"+row[1].original_image\n    img_path.append(path)\n\ndf['img_path'] = img_path","844c1418":"#present data befor\ndf.head()","97a97ae4":"#correlation\ncorr = df.corr()\ncorr","9c020c0e":"#heatmap\nsns.heatmap(corr)","e03101ab":"#mapping ages\nage_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n\nage_mapping_dict = {each[0]: each[1] for each in age_mapping}\ndrop_labels = []\nfor idx, each in enumerate(df.age):\n    if each == 'None':\n        drop_labels.append(idx)\n    else:\n        df.age.loc[idx] = age_mapping_dict[each]\n\n        \n#drop none values in age        \ndf = df.drop(labels=drop_labels, axis=0) #droped None values\n#df.age.value_counts(dropna=False)\n\n\n#drop none gender values(u)  \ndf = df.dropna()\nunbiased_data = df[df.gender != 'u'].copy()\n#unbiased_data.info()","936ae9dd":"#labeling gender\ngender_to_label_map = {\n    'f' : 0,\n    'm' : 1\n}\n\n#labeling age\nage_to_label_map = {\n    '0-2'  :0,\n    '4-6'  :1,\n    '8-13' :2,\n    '15-20':3,\n    '25-32':4,\n    '38-43':5,\n    '48-53':6,\n    '60+'  :7\n}\n\nlabel_to_age_map = {value: key for key, value in age_to_label_map.items()}\nlabel_to_gender_map = {value: key for key, value in gender_to_label_map.items()}","38b4e639":"#change age and gender to labels\nunbiased_data['age'] = unbiased_data['age'].apply(lambda age: age_to_label_map[age])\nunbiased_data['gender'] = unbiased_data['gender'].apply(lambda g: gender_to_label_map[g])\n\nunbiased_data.head()","8fe1ad86":"#to plot image\ndef show_image(img_filename, age, gender):\n    img = Image.open(img_filename)\n    plt.imshow(img)\n    plt.title(f'size (w, h): {img.size}, age: {age}, gender: {gender}')\n    plt.show()\n    \nidx = np.random.randint(unbiased_data.shape[0])\nfname = unbiased_data['img_path'].iloc[idx]\nage = label_to_age_map[unbiased_data['age'][idx]]\ngender = label_to_gender_map[unbiased_data['gender'][idx]]\nshow_image(fname, age, gender)","a25f7090":"#splitting dataset\nX = unbiased_data[['img_path']]\ny = unbiased_data[['gender']]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Train data shape {}'.format(X_train.shape))\nprint('Test data shape {}'.format(X_test.shape))","da302ce0":"train_images = []\ntest_images = []\n\nfor row in X_train.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))   # Resize the image\n    data = np.asarray(image)\n    train_images.append(data)\n\nfor row in X_test.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))  # Resize the image\n    data = np.asarray(image)\n    test_images.append(data)\n\ntrain_images = np.asarray(train_images)\ntest_images = np.asarray(test_images)\n\nprint('Train images shape {}'.format(train_images.shape))\nprint('Test images shape {}'.format(test_images.shape))","55e6139e":"model = Sequential()\nmodel.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=(2, 2), padding='valid', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=2, activation='softmax'))","3c6027d3":"model.summary()","4e524efd":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\nepochs=20\nhistory = model.fit(train_images, y_train, batch_size=32,  epochs=epochs, validation_data=(test_images, y_test), callbacks=[callback])\n","56b11bd5":"#save history\nimport pickle\nwith open('\/trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)    ","6f12d73e":"test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\nprint('Testing accuracy',test_acc)","f06a498f":"train_acc=model.evaluate(train_images, y_train)\nprint('Training accuracy',train_acc)","bde35d7e":"#predection\nmodel.predict(test_images[:4])\n#test_images[:4]\ny_test[:4]","60d89406":"from sklearn.metrics import confusion_matrix\npred = model.predict(test_images)\npred = np.argmax(pred,axis = 1) \ny_true = np.argmax(y_test,axis = 1)","81245c43":"from sklearn.metrics import classification_report\nCM=classification_report(y_true, pred)\nprint(CM)","0668e4d4":"from sklearn.metrics import r2_score\nprint('R2 score for gender: ', r2_score(y_true, pred))","f7e88d4c":"#save model\nmodel.save(gender.h5)","33534546":"#visualaze cnn model\nfrom keras.utils.vis_utils import plot_model\n\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","bf100dbd":"#splitting dataset\nX = unbiased_data[['img_path']]\ny = unbiased_data[['age']]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Train data shape {}'.format(X_train.shape))\nprint('Test data shape {}'.format(X_test.shape))","b53dc5c0":"train_images = []\ntest_images = []\n\nfor row in X_train.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))   # Resize the image\n    data = np.asarray(image)\n    train_images.append(data)\n\nfor row in X_test.iterrows():\n    image = Image.open(row[1].img_path)\n    image = image.resize((227, 227))  # Resize the image\n    data = np.asarray(image)\n    test_images.append(data)\n\ntrain_images = np.asarray(train_images)\ntest_images = np.asarray(test_images)\n\nprint('Train images shape {}'.format(train_images.shape))\nprint('Test images shape {}'.format(test_images.shape))","61c29392":"model = Sequential()\nmodel.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(LayerNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=8, activation='softmax'))","908b704e":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\nepochs=20\nhistory = model.fit(train_images, y_train, batch_size=32, epochs=epochs, validation_data=(test_images, y_test), callbacks=[callback])","acaa2deb":"#save history\nwith open('\/trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","c2df678b":"test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\nprint('Testing accuracy',test_acc)","e3771560":"train_acc=model.evaluate(train_images, y_train)\nprint('Training accuracy',train_acc)","cc94e564":"#predection\nmodel.predict(test_images[:4])\n#test_images[:4]\ny_test[:4]","1120bf5e":"from sklearn.metrics import confusion_matrix\npred2 = model.predict(test_images)\npred2 = np.argmax(pred2,axis = 1) \ny_true2 = np.argmax(y_test,axis = 1)","de894970":"from sklearn.metrics import classification_report\nCM2=classification_report(y_true2, pred2)\nprint(CM2)","f9550dbd":"from sklearn.metrics import r2_score\nprint('R2 score for age: ', r2_score(y_true2, pred2))","7d2fb8b9":"#save model\nmodel.save(age.h5)","50b41337":"callback = tf.keras.callbacks.TensorBoard(\n    log_dir='logs', histogram_freq=0, write_graph=True,\n    write_images=False, update_freq='epoch', profile_batch=2,\n    embeddings_freq=0, embeddings_metadata=None ) # Callback for TensorBoard\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\nhistory = model.fit(train_images, y_train, batch_size=32,  epochs=epochs, validation_data=(test_images, y_test), callbacks=[callback])","ee840684":"## summarize history for accuracy\n#plt.plot(history.history['accuracy'])\n#plt.plot(history.history['val_accuracy'])\n#plt.title('model accuracy')\n#plt.ylabel('accuracy')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'test'], loc='upper left')\n#plt.show()\n## summarize history for loss\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('model loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'test'], loc='upper left')\n#plt.show()","a08feeb4":"# Data visualization","08128f28":"# Plot random image with its size, gender and age  ","992bd310":"### Predection age ('0-2':0,  '4-6':1,  '8-13':2,  '15-20':3,  '25-32':4,  '38-43':5,  '48-53':6, '60+':7)","53dea09a":"### Predection gender (0:f, 1:m)","6e4da562":"### Gender classification","62ccd555":"# Import important libraries","d74d9528":"# Generate dataframe","db66f32e":"# Model","6fdf9ab2":"### -----------------------------------------------------------------------------------------------","f3d7e4ab":"# Mapping age label and drop irrelevant data","684df119":"other callback test:","1ae0e267":"# Dataset","c87240cc":"# Labelling Age and Gender ","4ad74f95":"### Age classification"}}