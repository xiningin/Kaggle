{"cell_type":{"38f113ac":"code","026bfab4":"code","0d7d202c":"code","46082072":"code","71e56065":"code","44229b78":"code","cd0b56d9":"code","14ac8a44":"code","917bcd0c":"code","217df980":"code","59999104":"code","4a799283":"code","44d1173a":"markdown","4a15fa44":"markdown","4697beec":"markdown","b2c6584e":"markdown","60fa2d43":"markdown","937ba3d8":"markdown","14dc76ce":"markdown","93bfad7b":"markdown"},"source":{"38f113ac":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns","026bfab4":"train_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv',index_col='id')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv',index_col='id')\nsubmission_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","0d7d202c":"print(f'Number of rows in train data is {train_df.shape[0]}. Number of columns in train data is {train_df.shape[1]}')\nprint(f'Number of rows in test data is {test_df.shape[0]}. Number of columns in test data is {test_df.shape[1]}')","46082072":"print(train_df.info())","71e56065":"print(train_df.select_dtypes('float64').columns)\nprint(train_df.select_dtypes('int64').columns)","44229b78":"features = train_df.select_dtypes('float64').columns\ntarget = train_df.select_dtypes('int64').columns","cd0b56d9":"train_df.isnull().sum().sum()","14ac8a44":"#Code Copied from one of noteooks of @Subin An\n\ntrain_df[features].describe().T.style.bar(subset='mean',color='deepskyblue')\\\n                                .background_gradient(subset='std',cmap='Greens')","917bcd0c":"train_df[features].duplicated().sum()","217df980":"#Code Copied from one of noteooks of @Subin An\n\n\nfig, axes = plt.subplots(10,10,figsize=(20,20))\n\nfor col,ax in zip(features,axes.flatten()):\n    sns.kdeplot(x=col,data=train_df,fill=True,ax=ax,color='Deepskyblue',label='Train')\n    sns.kdeplot(x=col,data=test_df,fill=True,ax=ax,color='Green',label='Test')\n    \n    if col == 'f9':\n        ax.legend()\n    \n    ax.spines.top.set_visible(False)\n    ax.spines.right.set_visible(False)\n    ax.spines.left.set_visible(False)\n    \n    ax.set_xticklabels([])\n    ax.set_xticks([])\n    ax.set_yticklabels([])\n    ax.set_yticks([])\n    ax.set_ylabel('')\n\n\nplt.suptitle('Distribution of continuous features (Train and Test)',fontweight = 'bold')\n\nplt.tight_layout()\nplt.show()","59999104":"fig,ax = plt.subplots(1,1,figsize=(10,10))\n\nsns.countplot(x='target',data=train_df,ax=ax)\nax.set_title(\"Target Distribution\",fontweight='bold')\nplt.show()","4a799283":"fig,ax = plt.subplots(1,1,figsize=(20,20))\n\ncorr = train_df.corr()\n\nmask = np.triu(np.ones_like(corr,dtype='bool'))\n\nsns.heatmap(corr,mask=mask,ax=ax)\n\nax.set_title('Correlation among features and target',fontweight='bold')\n\nplt.show()","44d1173a":"**Thanks for Reading.**","4a15fa44":"Right skewed distributions. Scaling will be needed as  f2 ,f35 are on different scale.","4697beec":"No null values.","b2c6584e":"Correlation among features and target is low","60fa2d43":"No duplicates","937ba3d8":"Test and Train Data have similar distribution (expected).","14dc76ce":"100 float (f0-f99) columns and one int (target)","93bfad7b":"No Class Imbalance"}}