{"cell_type":{"f8f263e7":"code","37b7b82c":"code","333c1d63":"code","d0f92b65":"code","d5fb8b73":"code","7f0ea343":"code","f8996262":"code","9e7de653":"code","c239d7c7":"code","497a988c":"code","2097b643":"code","c327ffe3":"code","8fb4ddda":"code","678ccf52":"code","027f6254":"code","5015706c":"code","c431fbe8":"code","8a1ff854":"code","e8e83ba2":"code","147099f2":"code","b0923668":"code","30d71735":"code","df823f1e":"code","76b606c3":"code","98d48d0a":"code","05bb71f8":"code","bc90ab79":"code","aec14172":"code","faee5388":"code","d503afc4":"code","a1d68b9a":"code","edc6805a":"code","40052cfc":"code","e38e85e6":"code","98cb84e3":"code","34020668":"code","a92eff43":"code","ffa61635":"code","c009e9df":"code","d8e60345":"code","093d0237":"markdown","bdffef21":"markdown","7184f3fc":"markdown","714e8550":"markdown","63a16e68":"markdown","1e58fd53":"markdown","3b30e9ae":"markdown","e53e757d":"markdown","140043d8":"markdown","41089b5e":"markdown","5aa0a683":"markdown","cdea6b31":"markdown","e11dae99":"markdown","7ca6202d":"markdown","8c6d3ff2":"markdown","5841d834":"markdown","2e4b2a3a":"markdown","952f8026":"markdown","eeb70f4b":"markdown","c21628d7":"markdown","ec9ebc55":"markdown","d73dc8ca":"markdown","10d46682":"markdown","4606fc70":"markdown","86ee5e0c":"markdown","5b94ba2f":"markdown","fdc3360e":"markdown","2e847343":"markdown","619eb7b3":"markdown","ffafc070":"markdown"},"source":{"f8f263e7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","37b7b82c":"train= pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ndata=pd.concat([train,test], sort=False)\ndata.head()","333c1d63":"data.tail()","d0f92b65":"data.info()","d5fb8b73":"data.describe()","7f0ea343":"corr_0=data.corr()\nplt.figure(figsize=(8,8))\nax=sns.heatmap(corr_0, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           cmap= 'coolwarm')\nplt.xticks(rotation = 45)\nplt.yticks(rotation = 45)\nplt.show()","f8996262":"sns.countplot(data=train, x='Survived')\nplt.title('Supervivencia')","9e7de653":"#Porcentaje de supervivencia\nprint('Porcentaje de supervivencia:',(train.Survived.sum()\/train.Survived.count())*100)","c239d7c7":"sns.countplot(data=train, x='Survived', hue='Pclass')\nplt.title('Supervivencia por Clase')","497a988c":"#Porcentaje de supervivencia por clases\nprint('Porcentaje de supervivencia Clase 1:', (train[train.Pclass==1].Survived.sum()\/train[train.Pclass==1].Survived.count())*100)\nprint('Porcentaje de supervivencia Clase 2:', (train[train.Pclass==2].Survived.sum()\/train[train.Pclass==2].Survived.count())*100)\nprint('Porcentaje de supervivencia Clase 3:', (train[train.Pclass==3].Survived.sum()\/train[train.Pclass==3].Survived.count())*100)","2097b643":"sns.countplot(data=train, x='Survived', hue='Sex')\nplt.title('Supervivencia por Sex') ","c327ffe3":"#Porcentaje de supervivencia por Sexo\nprint('Porcentaje de supervivencia Mujeres:', (train[train.Sex=='female'].Survived.sum()\/train[train.Sex=='female'].Survived.count())*100)\nprint('Porcentaje de supervivencia Hombres:', (train[train.Sex=='male'].Survived.sum()\/train[train.Sex=='male'].Survived.count())*100)","8fb4ddda":"plt.subplots(figsize=(6,4))\n\nax=sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'],color='blue',shade=True, label='Non-Survived')\nax=sns.kdeplot(train.loc[(train['Survived'] == 1),'Age'],color='orange',shade=True, label='Survived')\nplt.title('Distribuci\u00f3n de la Edad seg\u00fan Supervivencia')\nplt.ylabel('Frecuencia')\nplt.xlabel('Age')\nplt.legend(loc=\"upper right\")\nplt.show()","678ccf52":"#Agrego una nueva variable a los datos_ creando rangos para las edades.\nbins = [ 0, 5, 12, 18, 25, 35, 60, np.inf]\nlabels = ['0-5', '6-12', '13-18', '19-25', '26-35', '36-60', '61-80']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)","027f6254":"sns.countplot(data=train, x='AgeGroup', hue='Survived')\nplt.title('Supervivencia por Rango de Edad')","5015706c":"#Porcentaje de supervivencia por Rango de Edad\nprint('Porcentaje de supervivencia   0-5 a\u00f1os:', (train[train.AgeGroup=='0-5'].Survived.sum()\/train[train.AgeGroup=='0-5'].Survived.count())*100)\nprint('Porcentaje de supervivencia  5-12 a\u00f1os:', (train[train.AgeGroup=='5-12'].Survived.sum()\/train[train.AgeGroup=='6-12'].Survived.count())*100)\nprint('Porcentaje de supervivencia 12-18 a\u00f1os:', (train[train.AgeGroup=='12-18'].Survived.sum()\/train[train.AgeGroup=='13-18'].Survived.count())*100)\nprint('Porcentaje de supervivencia 18-25 a\u00f1os:', (train[train.AgeGroup=='18-25'].Survived.sum()\/train[train.AgeGroup=='19-25'].Survived.count())*100)\nprint('Porcentaje de supervivencia 25-35 a\u00f1os:', (train[train.AgeGroup=='25-35'].Survived.sum()\/train[train.AgeGroup=='26-35'].Survived.count())*100)\nprint('Porcentaje de supervivencia 35-60 a\u00f1os:', (train[train.AgeGroup=='35-60'].Survived.sum()\/train[train.AgeGroup=='36-60'].Survived.count())*100)\nprint('Porcentaje de supervivencia 60-80 a\u00f1os:', (train[train.AgeGroup=='60-80'].Survived.sum()\/train[train.AgeGroup=='61-80'].Survived.count())*100)","c431fbe8":"fig, (ax1,ax2)= plt.subplots(1,2,figsize=(12,4))\n\nax1=sns.barplot(x=\"SibSp\", y=\"Survived\", data=train,ci=None, ax=  ax1)\nax1.set_title('Supervivencia seg\u00fan Cantidad de hermanos\/conyuge')\n\nax2=sns.barplot(x=\"Parch\", y=\"Survived\", data=train,ci=None, ax=  ax2)\nax2.set_title('Supervivencia seg\u00fan Cantidad de padres\/hijos')\n\nplt.tight_layout()\nplt.show()","8a1ff854":"plt.subplots(figsize=(8,6))\n\nax=sns.kdeplot(train.loc[(train['Survived'] == 0),'Fare'],color='blue',shade=True, label='Non-Survived')\nax=sns.kdeplot(train.loc[(train['Survived'] == 1),'Fare'],color='orange',shade=True, label='Survived')\nplt.title('Distribuci\u00f3n de la Tarifa seg\u00fan Supervivencia')\nplt.ylabel('Frecuencia')\nplt.xlabel('Fare')\nplt.legend(loc=\"upper right\")\nplt.show()","e8e83ba2":"sns.catplot(x=\"Pclass\", y=\"Fare\",hue='Survived', kind=\"bar\", data=train)\nplt.title('Supervivencia seg\u00fan tarifa y clase')","147099f2":"sns.countplot(data=train, x='Embarked', hue='Survived')\nplt.title('Supervivencia seg\u00fan Puerto de Embarque')","b0923668":"print('Porcentaje de supervivencia puerto Southampton:', (train[train.Embarked=='S'].Survived.sum()\/train[train.Embarked=='S'].Survived.count())*100)\nprint('Porcentaje de supervivencia puerto Cherburgo:  ', (train[train.Embarked=='C'].Survived.sum()\/train[train.Embarked=='C'].Survived.count())*100)\nprint('Porcentaje de supervivencia puerto Queenstown: ', (train[train.Embarked=='Q'].Survived.sum()\/train[train.Embarked=='Q'].Survived.count())*100)","30d71735":"data.columns","df823f1e":"print('% Missing values Train')\nnulls=data.isna().sum()\nprint((nulls\/data['PassengerId'].count())*100)","76b606c3":"#Elimino la variable Cabin por la cantidad de valores faltantes\ndata.drop(columns='Cabin', inplace=True, axis=1 )\n\n#Imputo los datos faltantes en Age y Fare con la media, y en Embarked con la moda\ndata['Age'].fillna((data['Age'].mean()), inplace=True)\ndata['Fare'].fillna((data['Fare'].mean()), inplace=True)\ndata['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)\n\ndata","98d48d0a":"data.isna().sum()","05bb71f8":"data","bc90ab79":"data['Title']=data['Name'].str.split(', ').str[1].str.split('.').str[0]\ndata.Title.value_counts()","aec14172":"#Englobamos los t\u00edtulos encontrados en s\u00f3lo 4 principales\ndic={'Ms': 'Miss','Mlle': 'Miss', \n         'Mme': 'Mrs','Dona': 'Mrs','the Countess': 'Mrs','Lady': 'Mrs',\n             'Rev': 'Mr','Jonkheer': 'Mr','Dr': 'Mr','Capt': 'Mr','Don': 'Mr','Col': 'Mr','Major': 'Mr','Sir': 'Mr'}\ndata.replace({'Title': dic}, inplace=True)\ndata.Title.value_counts()","faee5388":"bins = [ 0, 5, 12, 18, 25, 35, 60, np.inf]\nlabels = ['0-5', '6-12', '13-18', '19-25', '26-35', '36-60', '61-80']\ndata['AgeGroup'] = pd.cut(data[\"Age\"], bins, labels = labels)","d503afc4":"data['FamilySize']=data['SibSp'] + data['Parch'] + 1","a1d68b9a":"data.drop(columns=['Name','Ticket'], inplace=True, axis=1)\ndata.head()","edc6805a":"le = LabelEncoder()\ndata['Sex'] = le.fit_transform(data['Sex'])\ndata['Embarked'] = le.fit_transform(data['Embarked'])\ndata['Title'] = le.fit_transform(data['Title'])\ndata['AgeGroup']= le.fit_transform(data['AgeGroup'])\n","40052cfc":"data.isna().sum()","e38e85e6":"data","98cb84e3":"ds_train = data.iloc[:891]\nds_test = data.iloc[891:1310]","34020668":"#Genero subconjunto de train y test para medir el performance de los modelos\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'AgeGroup', 'FamilySize']\nX = ds_train[features]\ny = ds_train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state=42)","a92eff43":"tree=DecisionTreeClassifier(random_state=42)\ntree.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","ffa61635":"rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","c009e9df":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","d8e60345":"predicciones = rf.predict(ds_test[features])\n\noutput = pd.DataFrame({'PassengerId': ds_test.PassengerId, 'Survived': predicciones})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","093d0237":"# An\u00e1lisis Exploratorio de Datos:","bdffef21":"Con las variables Sibpb y Parch podemos calcular el tama\u00f1o de la familia:","7184f3fc":"## Fare","714e8550":"## Generaci\u00f3n de nuevas variables","63a16e68":"# Librer\u00edas \u00fatiles","1e58fd53":"# Carga de Datos:","3b30e9ae":"1. Eliminaremos del conjunto de train las siguientes variables:\n   * 'PassengerId': no es relevante para el entrenamiento del modelo.\n   * 'Name': representa valores \u00fanicos para cada fila.\n   * 'Cabin': posee un porcentaje elevado de datos faltantes por lo que imputarlos agregar\u00eda sesgo en nuestros datos.\n   * 'Ticket': no representa relevancia para el objetivo.","e53e757d":"## Embarked","140043d8":"Podemos agrupar por rango de edades","41089b5e":"### \u00c1rbol de decisi\u00f3n","5aa0a683":"La variable Name es \u00fanica para cada instancia, sin embargo, el t\u00edtulo asociado a la persona nos puede proporcionar informaci\u00f3n relevante. Por tanto, la covertiremos en una variable categ\u00f3rica.","cdea6b31":"## Encoding","e11dae99":"# Ingenier\u00eda de atributos","7ca6202d":"- Los datos faltantes en la variable Survived corresponden a las instancias a predecir.\n- Se elimina la variable Cabin ya que posee un porcentaje elevado de valores faltantes.\n- Se imputan los valores nulos de las variables Age y Fare con la media, y los de la variables Embarked con la moda.","8c6d3ff2":"## SibSp & Parch","5841d834":"## Age","2e4b2a3a":"Seg\u00fan lo observado tenemos:","952f8026":"## Pclass","eeb70f4b":"## Sex","c21628d7":"## Entrenamiento de modelos","ec9ebc55":"### Random Forest","d73dc8ca":"Separamos de nuevo los conjuntos de entrenamiento y testeo","10d46682":"# Optimizaci\u00f3n de Hiperpar\u00e1metros.\nContinuar\u00e1...","4606fc70":"## Valores faltantes","86ee5e0c":"## Survived","5b94ba2f":"### Observaciones:\n   - La clase con mayor supervivencia fue Pclass=1, y con menor supervivencia Pclass=3.\n   - La tasa de supervivencia de las mujeres fue mayor a la de hombres.\n   - El puerto de embarque no parece tener relaci\u00f3n directa con la supervivencia.\n   - Los pasajeros que pagaban tarifas m\u00e1s altas, ten\u00edan mayor probabilidad de supervivencia,","fdc3360e":"# Machine Learning from Disaster. Titanic","2e847343":"El modelo con los mejores resultado es el RandomForest, por tanto calcularemos las predicciones con \u00e9ste modelo:","619eb7b3":"### Vecinos m\u00e1s cercanos","ffafc070":"# Visualizaci\u00f3n de variables"}}