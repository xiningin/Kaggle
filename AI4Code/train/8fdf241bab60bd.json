{"cell_type":{"505b55dc":"code","87f6594e":"code","34f8a524":"code","745f49ed":"code","1adcf0b2":"code","07958ebb":"code","c7137350":"code","bc9ec797":"code","8d9b36cc":"code","446b576d":"code","a2348b51":"code","de5d3a4e":"code","a135f93d":"code","0723210d":"code","e728c888":"code","7b2edd93":"code","fee1b737":"code","a11e2af2":"code","7850b0c6":"code","853028ee":"code","dd722bc5":"markdown"},"source":{"505b55dc":"!pip install accelerate","87f6594e":"import sys\nsys.path.append(\"..\/input\/timmmaster\/\")","34f8a524":"import os\nimport gc\nimport cv2\nimport sys\nimport math\nimport time\nimport timm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom PIL import Image\nfrom accelerate import Accelerator\n\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score,classification_report\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A \nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom colorama import Fore, Back, Style\nr_ = Fore.RED\nb_ = Fore.BLUE\nc_ = Fore.CYAN\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL","745f49ed":"config = {'lr':5e-5,\n          'wd':1e-2,\n          'bs':64,\n          'img_size':256,\n          'nfolds':5,\n          'epochs':20,\n          'num_workers':4,\n          'seed':1000,\n          'model_name':'tf_efficientnet_b0',\n         }\n\nos.makedirs(f'models',exist_ok=True)\nos.makedirs(f'plots',exist_ok=True)\n    \ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])\n\n\ndef get_train_transforms():\n    return A.Compose(\n        [\n            A.Resize(config['img_size'],config['img_size'],always_apply=True),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Rotate(limit=180, p=0.7),\n            A.ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n            ),\n            A.HueSaturationValue(\n                hue_shift_limit=0.2, sat_shift_limit=0.2,\n                val_shift_limit=0.2, p=0.5\n            ),\n            A.RandomBrightnessContrast(\n                brightness_limit=(-0.1, 0.1),\n                contrast_limit=(-0.1, 0.1), p=0.5\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )\n\nclasses = ['AnnualCrop', 'HerbaceousVegetation', 'PermanentCrop',\n       'Industrial', 'Pasture', 'Highway', 'Residential', 'River',\n       'SeaLake', 'Forest']\n\nnum_classes = len(classes)\n\nclass_to_label = {value:key for key,value in enumerate(classes)}\nlabel_to_class = {key:value for key,value in enumerate(classes)}\n\nimage_path = '..\/input\/eurosat-dataset\/EuroSAT\/'\ntrain_data = pd.read_csv(\"..\/input\/eurosat-dataset\/EuroSAT\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/eurosat-dataset\/EuroSAT\/test.csv\")\n\ntrain_data['label'] = train_data['ClassName'].map(class_to_label)\ntest_data['label'] = test_data['ClassName'].map(class_to_label)\n\ntrain_data['path'] = image_path + train_data['Filename']\ntest_data['path'] = image_path + test_data['Filename']\n\ntrain_data['Fold'] = -1\nkfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\nfor k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['ClassName'])):\n    train_data.loc[valid_idx,'Fold'] = k","1adcf0b2":"train_data.head()","07958ebb":"def plot_loss_score(fold,train_losses,valid_losses,scores):\n    print(\"Best Train Loss\",np.min(train_losses))\n    print(\"Best Valid Loss\",np.min(valid_losses))\n    print(\"Best Accuracy Score\",np.max(scores))\n\n    plt.figure(figsize=(15,7))\n    plt.subplot(121)\n    sns.lineplot(x=list(range(len(train_losses))),y=train_losses,label='train loss')\n    sns.lineplot(x=list(range(len(valid_losses))),y=valid_losses,label='valid_loss');\n    plt.xlabel(\"Epochs\");\n    plt.ylabel(\"Cross entropy loss\");\n    plt.title(\"Graph of epoch vs loss\")\n    plt.legend()\n\n    plt.subplot(122)\n    sns.lineplot(x=list(range(len(scores))),y=scores,label='score')\n    plt.xlabel(\"Epochs\");\n    plt.ylabel(\"Accuracy\");\n    plt.title(\"Graph of epoch vs score\")\n    plt.legend()\n\n    plt.savefig(f\"plots\/loss_score_plot{fold}.png\")\n\n    plt.show()","c7137350":"class EarlyStopping:\n    def __init__(self, patience=7, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n        elif score < self.best_score:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.counter = 0","bc9ec797":"class EuroSatDataset(Dataset):\n    def __init__(self,df,transforms=None):\n        self.df = df\n        self.transforms = transforms\n    \n    def __getitem__(self,idx):\n        path = self.df.loc[idx,\"path\"]\n        label = self.df.loc[idx,\"label\"]\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image)\n            image = augmented['image']\n        \n        label = torch.tensor(label,dtype=torch.long)\n        image = torch.tensor(image,dtype=torch.float)\n        \n        return image,label\n    \n    def __len__(self):\n        return len(self.df)","8d9b36cc":"class Model(nn.Module):\n    def __init__(self,model_path,pretrained=True):\n        super(Model,self).__init__()\n        self.backbone = timm.create_model(model_path,pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Linear(in_features,128)\n        self.dropout = nn.Dropout(0.2)\n        self.relu = nn.ReLU()\n        self.layer = nn.Linear(128,num_classes)\n    \n    def forward(self,x):\n        x = self.relu(self.backbone(x))\n        x = self.layer(self.dropout(x))\n        return x","446b576d":"def run(fold,patience=3,plot=True):\n    loss_fn = nn.CrossEntropyLoss()\n    \n    def evaluate(model,valid_loader):\n        model.eval()\n        valid_loss = 0\n        with torch.no_grad():\n            all_outputs = list()\n            all_targets = list()\n            for i, (inputs,targets) in enumerate(tqdm(valid_loader)):\n                outputs = model(inputs)\n                loss = loss_fn(outputs,targets)\n                valid_loss += loss.item()\n                outputs = (outputs.detach().cpu().numpy().argmax(axis=1))\n                all_outputs.extend(outputs.tolist())\n                all_targets.extend(targets.detach().cpu().numpy().tolist())\n\n        score = accuracy_score(all_targets,all_outputs)\n\n        valid_loss \/= len(valid_loader)\n        return valid_loss,score\n        \n    def train_and_evaluate_loop(train_loader,valid_loader,model,optimizer,\n                                epoch,fold,best_loss,best_score,lr_scheduler=None):\n        train_loss = 0\n        for i, (inputs,targets) in enumerate(tqdm(train_loader)):\n            optimizer.zero_grad()\n            model.train()\n            outputs = model(inputs)\n            loss = loss_fn(outputs,targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            \n            if lr_scheduler:\n                lr_scheduler.step()\n        \n        train_loss \/= len(train_loader)\n        valid_loss,score = evaluate(model,valid_loader) \n\n        if score > best_score:\n            best_score = score\n        \n        print(f\"Epoch:{epoch} |Train Loss:{train_loss}|Valid Loss:{valid_loss}| Score: {score}\")\n\n        if valid_loss <= best_loss:\n            print(f\"{g_}Loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n            best_loss = valid_loss\n            torch.save(model.state_dict(),f'.\/models\/model{fold}.bin')\n                    \n        return best_loss,best_score,train_loss,valid_loss,score\n        \n    accelerator = Accelerator()\n    print(f\"{accelerator.device} is used\")\n    \n    early_stopping = EarlyStopping(patience)\n    \n#     td = train_data.sample(n=100).reset_index(drop=True)\n    x_train = train_data.query(f\"Fold != {fold}\").reset_index(drop=True)\n    x_valid = train_data.query(f\"Fold == {fold}\").reset_index(drop=True)\n    \n    model = Model(config['model_name'])\n    \n    train_ds = EuroSatDataset(x_train,transforms=get_train_transforms())\n    train_dl = DataLoader(train_ds,\n                        batch_size = config[\"bs\"],\n                        num_workers = config['num_workers'],\n                        shuffle=True,\n                        pin_memory=True,\n                        drop_last=True)\n    \n    valid_ds = EuroSatDataset(x_valid,transforms=get_train_transforms())\n    valid_dl = DataLoader(valid_ds,\n                        batch_size = config[\"bs\"],\n                        num_workers = config['num_workers'],\n                        shuffle=False,\n                        pin_memory=True,\n                        drop_last=False)\n    \n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\"]\n    optimizer_parameters = [\n        {\n            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.01,\n        },\n        {\n            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n    ]\n\n    optimizer = optim.AdamW(optimizer_parameters,lr=config['lr'],weight_decay=config['wd'])    \n#     lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n    lr_scheduler = None\n    \n    model,train_dl,valid_dl,optimizer,lr_scheduler = accelerator.prepare(model,train_dl,valid_dl,optimizer,lr_scheduler)\n\n    best_loss = 9999\n    best_score=0\n    start_time = time.time()\n    train_loss_per_epoch = list()\n    valid_loss_per_epoch = list()\n    score_per_epochs = list()\n    for epoch in range(config[\"epochs\"]):\n        print(f\"Epoch Started:{epoch}\")\n        best_loss,best_score,train_loss,valid_loss,score = train_and_evaluate_loop(train_dl,valid_dl,model,\n                                                                                   optimizer,epoch,fold,best_loss,\n                                                                                   best_score,lr_scheduler)  \n        train_loss_per_epoch.append(train_loss)\n        valid_loss_per_epoch.append(valid_loss)\n        score_per_epochs.append(score)\n\n        early_stopping(valid_loss, model)\n\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n              \n        end_time = time.time()\n        print(f\"Time taken by epoch {epoch} is {end_time-start_time:.2f}s\")\n        start_time = end_time\n\n    if plot:\n        plot_loss_score(fold,train_loss_per_epoch,valid_loss_per_epoch,score_per_epochs) ","a2348b51":"for x in range(config['nfolds']):\n    run(x)","de5d3a4e":"def get_test_transforms():\n    return A.Compose(\n        [\n            A.Resize(config['img_size'],config['img_size'],always_apply=True),\n            A.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n           ),\n            ToTensorV2(p=1.0)\n        ])","a135f93d":"class EuroSatDatasetTest(Dataset):\n    def __init__(self,df,transforms=None):\n        self.df = df\n        self.transforms = transforms\n    \n    def __getitem__(self,idx):\n        path = self.df.loc[idx,\"path\"]\n        label = self.df.loc[idx,\"label\"]\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image)\n            image = augmented['image']\n        \n        label = torch.tensor(label,dtype=torch.long)\n        image = torch.tensor(image,dtype=torch.float)\n        \n        return image\n    \n    def __len__(self):\n        return len(self.df)","0723210d":"def get_prediction(df,model_paths,device='cuda'):\n    predictions = list()\n    \n    for path,model_name in model_paths:\n        model = Model(model_name,pretrained=False)\n\n        for f in range(config['nfolds']):\n            model.load_state_dict(torch.load(path.format(f),map_location=device))\n            model.to(device)\n            model.eval()\n\n            test_ds = EuroSatDatasetTest(df,transforms=get_test_transforms())\n            test_dl = DataLoader(test_ds,\n                                batch_size = config[\"bs\"],\n                                num_workers = config['num_workers'],\n                                shuffle=False,\n                                pin_memory=True,\n                                drop_last=False)\n\n            with torch.no_grad():\n                prediction = list()\n                for i, inputs in enumerate(test_dl):\n                    inputs = inputs.to(device)\n                    outputs = model(inputs)\n                    pred = outputs.detach().cpu().numpy().tolist()\n                    prediction.extend(pred)\n                predictions.append(prediction)\n\n    torch.cuda.empty_cache()\n    predictions = np.mean(predictions,axis=0).argmax(axis=1)\n    return predictions","e728c888":"model_paths = [\n    ('.\/models\/model{0}.bin',config['model_name'])\n]","7b2edd93":"test_data['covertype'] = get_prediction(test_data,model_paths)","fee1b737":"test_data.head()","a11e2af2":"test_data.covertype.value_counts()","7850b0c6":"y_test = test_data.label.to_numpy()\ny_pred = test_data.covertype.to_numpy()\nprint(\"accuracy of modle on unseen data is:\",accuracy_score(y_test,y_pred))","853028ee":"print(classification_report(y_test,y_pred))","dd722bc5":"## Testing Model"}}