{"cell_type":{"c09d8ec7":"code","b01ac0ea":"code","c2336de9":"code","c08a0a0a":"code","74a3558c":"code","a928f382":"code","b37393ba":"code","2068aaf4":"code","d4d96af1":"code","b3ae7a5e":"code","3587b92e":"code","5dbe2b78":"code","590117f4":"code","1af6b2f5":"code","39600e8c":"code","7c09b074":"code","5d4787ea":"code","2baca344":"code","43709361":"code","981089ad":"code","c2227aa4":"code","0ab384ac":"code","5392a296":"code","3babe9cb":"code","0cb52488":"code","dc6e1838":"code","6a821bda":"code","2af04f29":"code","4f0dfcd3":"code","3db19cff":"code","23526637":"code","93e74aa7":"code","4d231f6c":"code","93380b84":"code","ce6405af":"code","be4220a3":"code","96120066":"code","b7160ed8":"code","caee8155":"code","2b097c39":"code","bb78d755":"code","9d0fc33b":"code","0026441c":"code","00beeb51":"code","34ba571d":"code","683e83fd":"code","907d6987":"code","87848018":"code","db44a034":"code","e7a47d24":"code","0a68b9b7":"code","6f9fc50d":"code","3fdc7953":"code","14050db3":"code","9cca8eab":"code","61c9b257":"code","47519083":"code","343caaad":"code","f4c9bb71":"code","d61fe6f8":"code","3b1cabba":"code","ce4ed8bf":"code","bbec3d2f":"markdown","af65e751":"markdown","f9ae2755":"markdown","dd26560c":"markdown","900d346c":"markdown","18d6eed1":"markdown","d4c07038":"markdown","c1967d29":"markdown","c5026d73":"markdown","05b1a147":"markdown","985e4a1b":"markdown","ca1ac6c7":"markdown","415f50a4":"markdown","31cb6ee0":"markdown","9c709bee":"markdown","e03a784d":"markdown","2e79a72b":"markdown","8c6a5da8":"markdown","6f4f1528":"markdown","5a0f5d85":"markdown","d45d4d3c":"markdown","94f1deba":"markdown","926c1574":"markdown","f708e715":"markdown","420299a7":"markdown","529914c4":"markdown","c0df7f25":"markdown","c870f67b":"markdown","ef48db00":"markdown","c7854cb7":"markdown","532806c8":"markdown","54ab2293":"markdown","0bdcee7d":"markdown","b9434a35":"markdown","d5fb96c7":"markdown","940eb04c":"markdown","f1a088e2":"markdown","a72811aa":"markdown","c610ed01":"markdown","6fa463f1":"markdown","a9b333c0":"markdown","be754b7c":"markdown","27510ea6":"markdown"},"source":{"c09d8ec7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.callbacks import LambdaCallback\nfrom keras.layers import Conv1D, Flatten\nfrom keras.layers import Dense ,Dropout,BatchNormalization\nfrom keras.models import Sequential \nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical \nfrom keras import regularizers\nfrom sklearn import preprocessing\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn import metrics\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b01ac0ea":"df=pd.read_csv('..\/input\/csv_result-messidor_features.csv')\ndf=df.drop('id',axis=1)\ndf.head(11)","c2336de9":"df.describe()","c08a0a0a":"from matplotlib import pyplot as plt\ndf_x=df.drop('Class',axis=1)\nimg=np.array(df[6:7])\nlabel=df['Class'][6:7]\nplt.imshow(img, interpolation='nearest')\nplt.show()\nif label.values ==0:\n    print(\"This eye has no dr\")\nelse:\n     print(\"This eye has dr\")\n\n\nimg=np.array(df.iloc[7:8])\nlabel=df['Class'].iloc[7:8]\nplt.imshow(img, interpolation='nearest')\nplt.show()\nif label.values ==0:\n    print(\"This eye has no dr\")\nelse:\n     print(\"This eye has dr\")\n","74a3558c":"\nimport seaborn as sns # for Visualizing my data\ndf_y=df['Class']\ndf_y.head()\nsns.distplot(df_y, kde=False); # Visualizing levels in dataset","a928f382":"\ndf_noDr=df[df['Class']==0]\nprint(\"Unique Value in No DR\",df_noDr['Class'].unique()) # For confirming\n\ndf_Dr=df[df['Class']==1]  \nprint(\"Unique Value in DR\",df_Dr['Class'].unique())    # For confirming","b37393ba":"\ni=1\nwhile(i<18):\n    plt.scatter( df['Class'],df[str(i)], alpha=0.5)\n    plt.title('Scatter plot of Coloum and Class Label')\n    plt.xlabel('Class')\n    plt.ylabel('Coloum '+ str(i))\n    plt.show()\n    i=i+1\n    \n","2068aaf4":"import pandas as pd\nimport matplotlib.pyplot as plt\ncorr = df_x.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(df_x.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(df_x.columns)\nax.set_yticklabels(df_x.columns)\nplt.show()","d4d96af1":"\ncorr = df_x.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","b3ae7a5e":"columns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.9:\n            if columns[j]:\n                columns[j] = False\nselected_columns = df_x.columns[columns]\ndata = df_x[selected_columns]\ndata.describe()","3587b92e":"\ncorr = data.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","5dbe2b78":"selected_columns = selected_columns[1:].values\nimport statsmodels.formula.api as sm\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(Y, x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    regressor_OLS.summary()\n    return x, columns\nSL = 0.05\ndata_modeled, selected_columns = backwardElimination(data.iloc[:,1:].values, data.iloc[:,0].values, SL, selected_columns)","590117f4":"selected_columns","1af6b2f5":"result = pd.DataFrame()\nresult['diagnosis'] = df_y","39600e8c":"data = pd.DataFrame(data = data_modeled, columns = selected_columns)","7c09b074":"fig = plt.figure(figsize = (20, 25))\nj = 0\nfor i in data.columns:\n    plt.subplot(6, 4, j+1)\n    j += 1\n    sns.distplot(data[i][result['diagnosis']==0], color='g', label = 'NO DR')\n    sns.distplot(data[i][result['diagnosis']==1], color='r', label = 'DR')\n    plt.legend(loc='best')\nfig.suptitle('Diabetic Rateinopathy ')\nfig.tight_layout()\nfig.subplots_adjust(top=0.95)\nplt.show()","5d4787ea":"for column in data:\n    plt.figure()\n    sns.boxplot(x=data[column])","2baca344":"for column_1st in data:\n    for coloum_2nd in data:\n        jet=plt.get_cmap('jet')\n        plt.figure(figsize=(15,5))\n        plt.scatter(data[column_1st], data[coloum_2nd], s=30, c=df_y, vmin=0, vmax=1, cmap=jet)\n        plt.xlabel(column_1st,fontsize=40)\n        plt.ylabel(coloum_2nd,fontsize=40)\n        plt.colorbar()\n        plt.show()\n        ","43709361":"print(data.shape)\nz_Scored_df=pd.DataFrame(data)\nfrom scipy import stats\nz_Scored_df=z_Scored_df[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\nz_Scored_df.shape","981089ad":"#merging Labels according to the Index selected from Outlier Detecteion (e.g 1, 4... are outliers so removed)\nz_Scored_df=z_Scored_df.merge(df_y.to_frame(), left_index=True, right_index=True)\nz_Scored_df.shape","c2227aa4":"z_Scored_df_labels=z_Scored_df['Class']\nz_Scored_df=z_Scored_df.drop('Class',axis=1)\n#labels and X features are seperated\nprint (z_Scored_df[1:6])\nprint(z_Scored_df_labels.head())","0ab384ac":"X_train, X_test, y_train, y_test = train_test_split(\n     z_Scored_df,z_Scored_df_labels, test_size=0.1, random_state=0)\n\n\nclassifiers = [\n    KNeighborsClassifier(2),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    \n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nsize=classifiers.count\n\nfor i in classifiers:\n    clf=i\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(\"Accuracy of : \",i,\"\\n\",metrics.accuracy_score(y_test, y_pred))\n    print(\"\\n\\n\")","5392a296":"#i am copying the same model I dont know why I have to compile this cell when ever i want to train this model\n#for some other X. \ndef model_Z(input1)    :\n    model = Sequential () # we make a sequentail model\n    \n    model.add(Dense(128, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-4)))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-6)))\n    model.add(Dropout(0.5))\n    model.add(Dense(32, activation  ='relu',activity_regularizer = regularizers.l2(1e-8)))\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels#softmax layer to compute the probability of\n                                                #labels\n    \n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model\ncategorical_y_test=to_categorical(y_test)\ncategorical_y_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test=X_test.reshape(X_test.shape[0],X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_test.shape)","3babe9cb":"import matplotlib.pyplot as plt\nmodel=model_Z(6)\nhistory =model.fit(X_train, categorical_y_train, epochs=500, batch_size=101,validation_data=(X_test,categorical_y_test)\n                  )\n\n","0cb52488":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","dc6e1838":"Q1 = np.quantile(data,0.25)\nQ3 = np.quantile(data,0.75)\nIQR = Q3 - Q1\nprint(IQR)","6a821bda":"data_o=pd.DataFrame()\ndata_o = data[((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\nprint(\"DataFrame with outliers: \",data.shape )\nprint(\"DataFrame with_out outliers: \",data_o.shape )","2af04f29":"#merging Labels according to the Index selected from Outlier Detecteion (e.g 1, 4... are outliers so removed)\ndata_o=data_o.merge(df_y.to_frame(), left_index=True, right_index=True)\ndata_o.shape","4f0dfcd3":"data_o_labels=data_o['Class']\ndata_o_x=data_o.drop('Class',axis=1)\n#labels and X features are seperated\nprint (data_o_labels[1:6])\nprint(data_o_x.head())","3db19cff":"X_train, X_test, y_train, y_test = train_test_split(\n     data_o_x,data_o_labels, test_size=0.1, random_state=0)\n\n\nclassifiers = [\n    KNeighborsClassifier(2),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    \n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nsize=classifiers.count\n\nfor i in classifiers:\n    clf=i\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(\"Accuracy of : \",i,\"\\n\",metrics.accuracy_score(y_test, y_pred))\n    print(\"\\n\\n\")","23526637":"#i am copying the same model I dont know why I have to compile this cell when ever i want to train this model\n#for some other X. \ndef model_IQR(input1)    :\n    model = Sequential () # we make a sequentail model\n    \n    model.add(Dense(128, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-4)))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-6)))\n    model.add(Dropout(0.25))\n    model.add(Dense(32, activation  ='relu',activity_regularizer = regularizers.l2(1e-8)))\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels#softmax layer to compute the probability of\n                                                #labels\n    \n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model\ncategorical_y_test=to_categorical(y_test)\ncategorical_y_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test=X_test.reshape(X_test.shape[0],X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_test.shape)","93e74aa7":"import matplotlib.pyplot as plt\nmodel=model_IQR(6)\nhistory =model.fit(X_train, categorical_y_train, epochs=500, batch_size=91,validation_data=(X_test,categorical_y_test)\n                  )\n\n","4d231f6c":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","93380b84":"from sklearn import preprocessing\nstandardized_X = preprocessing.scale(z_Scored_df)\nstandardized_X[1]","ce6405af":"\n\nX_train, X_test, y_train, y_test = train_test_split(\n   standardized_X,z_Scored_df_labels, test_size=0.1, random_state=0)\n\n\nclassifiers = [\n    KNeighborsClassifier(2),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    \n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nsize=classifiers.count\n\nfor i in classifiers:\n    clf=i\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(\"Accuracy of : \",i,\"\\n\",metrics.accuracy_score(y_test, y_pred))\n    print(\"\\n\\n\")","be4220a3":"#i am copying the same model I dont know why I have to compile this cell when ever i want to train this model\n#for some other X. \ndef Z_Standardized_model(input1)    :\n    model = Sequential () # we make a sequentail model\n    model.add(Dense(256,input_dim=input1,activation  ='relu',))\n    model.add(Dense(128,activation  ='relu',))\n    model.add(Dense(64,activation  ='relu',))\n    \n    model.add(Dense(32, activation  ='relu',))\n    model.add(Dropout(0.25))\n    model.add(Dense(16, activation  ='relu',))\n    \n    model.add(Dense(8, activation  ='relu'))\n    \n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    \n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model\ncategorical_y_test=to_categorical(y_test)\ncategorical_y_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test=X_test.reshape(X_test.shape[0],X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_test.shape)","96120066":"import matplotlib.pyplot as plt\nmodel=Z_Standardized_model(6)\nhistory =model.fit(X_train, categorical_y_train, epochs=500, batch_size=101,validation_data=(X_test,categorical_y_test)\n                  )\n\n","b7160ed8":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","caee8155":"from sklearn import preprocessing\nstandardized_X = preprocessing.scale(data_o_x)\nstandardized_X[1]","2b097c39":"\n\nX_train, X_test, y_train, y_test = train_test_split(\n   data_o_x,data_o_labels, test_size=0.1, random_state=0)\n\n\nclassifiers = [\n    KNeighborsClassifier(2),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    \n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nsize=classifiers.count\n\nfor i in classifiers:\n    clf=i\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(\"Accuracy of : \",i,\"\\n\",metrics.accuracy_score(y_test, y_pred))\n    print(\"\\n\\n\")","bb78d755":"#i am copying the same model I dont know why I have to compile this cell when ever i want to train this model\n#for some other X. \ndef Standardized_model(input1)    :\n    model = Sequential () # we make a sequentail model\n    model.add(Dense(256,input_dim=input1,activation  ='relu',))\n    model.add(Dense(128,activation  ='relu',))\n    model.add(Dense(64,activation  ='relu',))\n    \n    model.add(Dense(32, activation  ='relu',))\n    model.add(Dropout(0.25))\n    model.add(Dense(16, activation  ='relu',))\n    \n    model.add(Dense(8, activation  ='relu'))\n    \n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    \n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model\ncategorical_y_test=to_categorical(y_test)\ncategorical_y_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test=X_test.reshape(X_test.shape[0],X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_test.shape)","9d0fc33b":"import matplotlib.pyplot as plt\nmodel=Standardized_model(6)\nhistory =model.fit(X_train, categorical_y_train, epochs=500, batch_size=91,validation_data=(X_test,categorical_y_test)\n                  )\n","0026441c":"\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","00beeb51":"normalized_X = preprocessing.normalize(data_o_x)\nnormalized_X[1]","34ba571d":"X_train, X_test, y_train, y_test = train_test_split(\n     data_o_x,data_o_labels, test_size=0.1, random_state=0)\n\n\nclassifiers = [\n    KNeighborsClassifier(2),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    \n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nsize=classifiers.count\n\nfor i in classifiers:\n    clf=i\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_test)\n    print(\"Accuracy of : \",i,\"\\n\",metrics.accuracy_score(y_test, y_pred))\n    print(\"\\n\\n\")","683e83fd":"#i am copying the same model I dont know why I have to compile this cell when ever i want to train this model\n#for some other X. \ndef Normalized_model(input1)    :\n    model = Sequential () # we make a sequentail model\n    model.add(Dense(256,input_dim=input1,activation  ='relu',))\n    model.add(Dense(128,activation  ='relu',))\n    model.add(Dense(64,activation  ='relu',))\n    \n    model.add(Dense(32, activation  ='relu',))\n    model.add(Dropout(0.25))\n    model.add(Dense(16, activation  ='relu',))\n    \n    model.add(Dense(8, activation  ='relu'))\n    \n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    \n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model\ncategorical_y_test=to_categorical(y_test)\ncategorical_y_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test=X_test.reshape(X_test.shape[0],X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_test.shape)","907d6987":"import matplotlib.pyplot as plt\nmodel=Normalized_model(6)\nhistory =model.fit(X_train, categorical_y_train, epochs=500, batch_size=728,validation_data=(X_test,categorical_y_test)\n                  )\n\n","87848018":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","db44a034":"X_train, X_test, y_train, y_test = train_test_split(\n     data_o_x,data_o_labels, test_size=0.1)\n","e7a47d24":"def Seperate_xtest_x_Train_model(input1)    :\n    model = Sequential () # we make a sequentail model\n    \n    model.add(Dense(128, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-4)))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-6)))\n    model.add(Dropout(0.25))\n    model.add(Dense(32, activation  ='relu',activity_regularizer = regularizers.l2(1e-8)))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    model.summary()\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model","0a68b9b7":"\n\nX_train = preprocessing.scale(X_train)\nX_test = preprocessing.scale(X_test)\n\ny_test=to_categorical(y_test)\ny_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],6)\nX_test=X_test.reshape(X_test.shape[0],6)\n\nprint(X_train.shape)\nprint(y_test.shape)","6f9fc50d":"import matplotlib.pyplot as plt\nSeperate_Normalized_model=Seperate_xtest_x_Train_model(6)\nhistory =Seperate_Normalized_model.fit(X_train, y_train, epochs=500, batch_size=91,validation_data=(X_test,y_test))\n","3fdc7953":"\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","14050db3":"X_train, X_test, y_train, y_test = train_test_split(\n     data_o_x,data_o_labels, test_size=0.1)\n\n\nX_train = preprocessing.normalize(X_train)\nX_test = preprocessing.normalize(X_test)\n\ny_test=to_categorical(y_test)\ny_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],6)\nX_test=X_test.reshape(X_test.shape[0],6)\n\nprint(X_train.shape)\nprint(y_test.shape)","9cca8eab":"def Normalize_Seperate_xtest_x_Train_model(input1)    :\n    model = Sequential () # we make a sequentail model\n    \n    model.add(Dense(128, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-4)))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-6)))\n    model.add(Dropout(0.25))\n    model.add(Dense(32, activation  ='relu',activity_regularizer = regularizers.l2(1e-8)))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    model.summary()\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model","61c9b257":"import matplotlib.pyplot as plt\nSeperate_Normalized_model=Normalize_Seperate_xtest_x_Train_model(6)\nhistory =Seperate_Normalized_model.fit(X_train, y_train, epochs=500, batch_size=91,validation_data=(X_test,y_test))\n","47519083":"\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","343caaad":"X=data_o_x.drop('1',axis=1)\nX.head(5)","f4c9bb71":"def Experimental_Model(input1)    :\n    model = Sequential () # we make a sequentail model\n    \n    \n    model.add(Dense(128 , input_dim=input1,activation  ='relu',activity_regularizer = regularizers.l2(1e-4)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dense(64,activation  ='relu',activity_regularizer = regularizers.l2(1e-6)))\n    model.add(Dropout(0.25))\n    model.add(BatchNormalization())\n    model.add(Dense(32, activation  ='relu',activity_regularizer = regularizers.l2(1e-8)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dense(2, activation  ='softmax')) #softmax layer to compute the probability of\n                                                #labels\n    model.summary()\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n    return model","d61fe6f8":"X_train, X_test, y_train, y_test = train_test_split(\n    X,data_o_labels, test_size=0.1)\n\n\nX_train = preprocessing.normalize(X_train)\nX_test = preprocessing.normalize(X_test)\n\ny_test=to_categorical(y_test)\ny_train=to_categorical(y_train)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train=X_train.reshape(X_train.shape[0],5)\nX_test=X_test.reshape(X_test.shape[0],5)\n\nprint(X_train.shape)\nprint(y_test.shape)","3b1cabba":"import matplotlib.pyplot as plt\nmodel=Experimental_Model(5)\nhistory =model.fit(X_train, y_train, epochs=2000, batch_size=364,validation_data=(X_test,y_test))\n","ce4ed8bf":"\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","bbec3d2f":"**Training on Standardized data which are processed Seperately**\n\n* X_train According to X_Train values\n* X_test According to X_Test values","af65e751":"From the scatter plot I realize that most the ** values of (0,1)coloum 17 are same by visualizing their place** . May be I am wrong lets see further how we can improve our data.","f9ae2755":"Seems to be good for our model that has almost **600 records of having dr** and **550 records of not having dr**","dd26560c":"\n\n[Outlier Detection](https:\/\/towardsdatascience.com\/ways-to-detect-and-remove-the-outliers-404d16608dba)   \n\n","900d346c":"**Wow !We got good results as compared to Tranform whole dataset Combine (X_test,X_test)**","18d6eed1":"**Now We are going to Transform our data to a specefic scale so that no features have dominency on other feature**","d4c07038":"**Standardizing Data**\nNormal Data","c1967d29":"**Lets apply Neural Network**","c5026d73":"At first we **remove Highly CO-Related Coloums** which values are greater than 0.90 and than **Apply P-Values Technique** on less correlated Coloums. \nSo **we got  Coloum Number (1,2,9,12,16,17)**","05b1a147":"Lets see how the **image** from the array looks like","985e4a1b":"From the Heat map we can see that coloums \n  \n  1. **Coloum 0,1,16,17,18** is **Not Corelated** to any of the other coloum\n   \n  2. **Coloum 2,3,4,5,6,7** are **highly Corelated** to each other  (But these are pixels values may be giving some of the infomation. We will decide latter that we have to drop some of these coloums or not\n  \n  3. **Coloum (8 9,10,11,12)** are  **less correlated**\n   \n  4. **Coloum (11,12,15)** are **less correlaed**\n  \n**Now which coloums we have to add and which coloums we have to remove**","ca1ac6c7":"Now Visualize that how much eye records has dr ","415f50a4":"**Now I am going to take an assumption to my dataset**\n1. Coloum 1 is not giving information according to the visualization above that might be wrong . We will see.","31cb6ee0":"[Learning rate problems](https:\/\/www.jeremyjordan.me\/nn-learning-rate\/)\n\n[Some time its better to increase batch size than decaying learning rate](https:\/\/openreview.net\/pdf?id=B1Yy1BxCZ)\n\nSource","9c709bee":"**Checking Z_Socred dataframe accuracy**","e03a784d":"We can see from the Visualization that Pixels Values of **Coloum (2,3,4,5,6,7,11,12,13,14,15)** having some higher values of pixels for the eye contaning **DR**\n\nand from the Visualization we can see that **Coloum 1**  **is not giving Information to us**. So while training we can ** drop Coloum 1**","2e79a72b":"**we compare the correlation between features and remove one of two features that have a correlation higher than 0.9**","8c6a5da8":"**Without Outliers**","6f4f1528":"**Normalization give good results than standardization on this dataset that may vary from dataset to dataset**","5a0f5d85":"Normalizing Normal data","d45d4d3c":"**Data Standardization**\nStandardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n\nIt is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n\nThe example below demonstrate data standardization of the Iris flowers dataset.","94f1deba":"**TOO BAD RESULTS** \n* So its a bad idea to standardize Z_Scores","926c1574":"**Outliers Removed**","f708e715":"**CO-Relation**","420299a7":"From the visual representation I realize that **coloum above number 10 have same values in DR and No DR**","529914c4":"# abberivations\n    1 . dr   = Diabetic Retinopathy","c0df7f25":"** Part 2 :Data Transformation **","c870f67b":"**Our Labels.**","ef48db00":"**Now lets see what our Coloums are Representing**","c7854cb7":"**Now Normalizing Seperatly **\n* Normal Data","532806c8":"**Using seaborn for viewing corelation Just for comparing purpose.**\n","54ab2293":"**Question is Why do we Normalize our image data?\n. We have data of Images features get by some Convolutional neural network.**\n\nThe thing to notice here is the \"multiplied by a learning rate\".\n\nIf we didn't scale our input training vectors, the ranges of our distributions of feature values would likely be different for each feature, and thus the learning rate would cause corrections in each dimension that would differ (proportionally speaking) from one another. We might be over compensating a correction in one weight dimension while undercompensating in another.\n\nThis is non-ideal as we might find ourselves in a oscillating (unable to center onto a better maxima in cost(weights) space) state or in a slow moving (traveling too slow to get to a better maxima) state.\n\nIt is of course possible to have a per-weight learning rate, but it's yet more hyperparameters to introduce into an already complicated network that we'd also have to optimize to find. Generally learning rates are scalars.\n\nThus we try to normalize images before using them as input into NN (or any gradient based) algorith\n\n[Source](https:\/\/stats.stackexchange.com\/questions\/185853\/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn)","0bdcee7d":"I think their is a combination of color which tell us that the eye is **diabetic** \nAnd 1 Record in the csv is represting features of the images","b9434a35":"**Outliers Detection**","d5fb96c7":"**now we will run our Techniques on both with outliers and without outliers lets see thats happens**","940eb04c":"**We are getting good results when we are Normalizing our test set and train set seperatly**\n\n**if we train for some more epochs we can get good results lets try**","f1a088e2":"**Don\u2019t drop an outlier if:**\nYour results are critical, so even small changes will matter a lot. For example, you can feel better about dropping outliers about people\u2019s favorite TV shows, not about the temperatures at which airplane seals fail.\nThere are a lot of outliers. Outliers are rare by definition. If, for example, 30% of your data is outliers, then it actually means that there\u2019s something interesting going on with your data that you need to look further into.\n\n[Source](https:\/\/blog.socialcops.com\/academy\/resources\/when-delete-outliers-dataset\/)","a72811aa":"**Scatter Plot.. Give us Visualization of 2 or more coloums. So that we can see than on which point both coloum values lies.**","c610ed01":"**Z-Score-**\n\nWikipedia Definition\n\nThe Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\n\nwhile calculating the Z-score we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers. In most of the cases a threshold of 3 or -3 is used i.e if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.","6fa463f1":"**Data Normalization**\nNormalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n\nIt is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.","a9b333c0":"**IQR score -**\nThe interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 \u2212 Q1.","be754b7c":"**Co-relation of selected Coloums**","27510ea6":"**Selected Coloums according to PVALUES**"}}