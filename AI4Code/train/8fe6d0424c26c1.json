{"cell_type":{"fd4f2de2":"code","075c9292":"code","fe0a58e9":"code","625b5c00":"code","6be2671a":"code","d8c49635":"code","b3c37b92":"code","d61e8405":"code","8c74edcd":"code","fbf6b644":"code","ae9f707b":"markdown","02c8a841":"markdown","a1900348":"markdown","8b7457b0":"markdown","3a7e9eef":"markdown","a72798ea":"markdown","2b2461e0":"markdown","c4ab2f2e":"markdown"},"source":{"fd4f2de2":"import numpy as np\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn import metrics\nfrom sklearn import ensemble\nfrom sklearn import neighbors\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score as cvs\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_predict as cvp","075c9292":"class Shuffle():\n    def perform(self, dataFrame):\n        return dataFrame.reindex(np.random.permutation(dataFrame.index))\n    \nclass Split():\n    def __init__(self, test_size, labels, stratify=False, stratifyBy=None):\n        self.test_size = test_size\n        self.labels = labels\n        self.stratify = stratify\n        self.stratifyBy = stratifyBy\n        \n    def __get_tts_from_df(self, dataFrame, test_size, attrs, labels, stratifyBy=None):\n        if(self.stratify):\n            train, test = tts(dataFrame, test_size=test_size, stratify=stratifyBy, random_state=50)\n        else:\n            train, test = tts(dataFrame, test_size=test_size, random_state=50)\n        Y_train = (train[labels]).values.ravel()\n        Y_test = (test[labels]).values.ravel()\n        return (train[attrs], test[attrs], Y_train, Y_test)\n    \n    def perform(self, dataFrame):\n        attrs = dataFrame.drop(self.labels, axis=1).columns.values.tolist()\n        if(self.stratify):\n            return self.__get_tts_from_df(dataFrame, self.test_size, attrs, self.labels, dataFrame[self.stratifyBy])\n        else:\n            return self.__get_tts_from_df(dataFrame, self.test_size, attrs, self.labels)\n\nclass ScaleFeature():\n    def perform(self, dataFrame, training=True):\n        if(training):\n            self.transformer = StandardScaler()\n            self.transformer.fit(dataFrame)   \n        npOutput = self.transformer.transform(dataFrame)\n        return npOutput\n\nclass PreProcess():\n    def __init__(self):\n        self.scaleFeature = ScaleFeature()\n\n    def perform(self, dataFrame, training=True):\n        npOutput = self.scaleFeature.perform(dataFrame, training)\n        return npOutput\n\nclass ValidateModels():\n    def __init__(self, split):\n        self.split = split\n        \n    def perform(self, model, attrSet, labelSet, classDist='uniform'):\n        if(classDist == 'uniform'):\n            scores = cvs(model, attrSet, labelSet, scoring=\"accuracy\", cv=self.split)\n            print(\"Accuracy Estimate: MEAN +\/- STD = \" + str(np.round(scores.mean(),3)) + \" +\/- \" + str(np.round(scores.std(),3)))\n        elif(classDist == 'skewed'):\n            preds = cvp(model, attrSet, labelSet, cv=self.split)\n            print(\"Confusion Matrix: \")\n            print(metrics.confusion_matrix(labelSet, preds))\n            print(\"Classification report: \")\n            print(metrics.classification_report(labelSet, preds))\n\nclass Test():\n    def perform(self, model, attrSet, labelSet):\n        predictions = model.predict(attrSet)\n        print()\n        print(\"*****==========*****\")\n        print(\"Accuracy Score: \" + str(metrics.accuracy_score(labelSet, predictions)))\n        print(\"*****==========*****\")\n        print(\"Confusion Matrix: \")\n        print(metrics.confusion_matrix(labelSet, predictions))\n        print(\"*****==========*****\")\n        print(\"Classification report: \")\n        print(metrics.classification_report(labelSet, predictions))\n        print(\"*****==========*****\")\n        print()\n        return predictions","fe0a58e9":"dataSet = pd.read_csv(\"..\/input\/iris\/Iris.csv\", sep=\",\", usecols=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species'])\nshuffle = Shuffle()\ndataSet = shuffle.perform(dataSet)\nprint(dataSet.head())","625b5c00":"labels = ['Species']\nsplit = Split(0.2, labels, True, labels)\nX_train, X_test, Y_train, Y_test = split.perform(dataSet)","6be2671a":"print(X_train)","d8c49635":"preProcess = PreProcess()\nX_train = preProcess.perform(X_train)\nprint(X_train)","b3c37b92":"print(Y_train)","d61e8405":"validateModels = ValidateModels(10)\nlr_model = linear_model.LogisticRegression(random_state=50, n_jobs=-1, C=25, solver='saga', penalty='elasticnet', max_iter=1000, l1_ratio=0.75)\nvalidateModels.perform(lr_model, X_train, Y_train)\ndt_model = tree.DecisionTreeClassifier(random_state=50, criterion='gini', splitter='random', max_depth=3)\nvalidateModels.perform(dt_model, X_train, Y_train)\nsvc_model = svm.SVC(random_state=50, probability=True, kernel='rbf', C=0.5)\nvalidateModels.perform(svc_model, X_train, Y_train)\nknn_model = neighbors.KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=10)\nvalidateModels.perform(knn_model, X_train, Y_train)\nrf_model = ensemble.RandomForestClassifier(random_state=50, n_jobs=-1, n_estimators=10, max_depth=3)\nvalidateModels.perform(rf_model, X_train, Y_train)","8c74edcd":"vc_model = ensemble.VotingClassifier(estimators=[('lr', lr_model), ('dt', dt_model), ('svc', svc_model), ('knn', knn_model), ('rf', rf_model)], voting='soft', n_jobs=-1)\nvalidateModels.perform(vc_model, X_train, Y_train)\nvc_model = vc_model.fit(X_train, Y_train)","fbf6b644":"X_test = preProcess.perform(X_test, training=False)\n\ntest = Test()\npreds = test.perform(vc_model, X_test, Y_test)","ae9f707b":"### **Implementing the general-purpose utility classes which can be used by almost every major Machine Learning Project with just few minor tweaks in its implementation or directly out-of-the-box.**","02c8a841":"### **Initializing several basic models, performing hyperparamter tuning and analyzing its performance using Cross Validation.**","a1900348":"### **Pre-Processing the Testing Dataset and calculating the performance of the Voting Classifier Model on it.**","8b7457b0":"### **Pre-Processing the train set in the form of Fearture Scaling.**","3a7e9eef":"### **Splitting the dataset into a 80-20 (Train-Test) Ratio, while ensuring similar distribution of the labels in the Test Set using Stratification to ensure un-skewed split.**","a72798ea":"## ***The End. A beginner here on Kaggle, please Upvote and Comment on this Notebook if you found it useful, help me earn some medals. Thank You !!***","2b2461e0":"### **Initialzing a Voting Classifier Ensemble Model, analyzing its performance and fitting it to the complete training dataset.**","c4ab2f2e":"### **Importing the dataset and shuffling it to ensure randomized splitting.**"}}