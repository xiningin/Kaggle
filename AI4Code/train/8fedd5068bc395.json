{"cell_type":{"47a3d9f2":"code","e6d4617d":"code","59f0bed0":"code","c6e0a75f":"code","01260257":"code","f0c15828":"code","60a84aab":"code","7b7e170a":"code","66432e28":"code","8b44018d":"code","6d995148":"code","236a69ce":"code","6c0f93e9":"code","7bde8df3":"code","6cd21264":"code","22ca63ab":"code","7888f526":"code","0d0d0a67":"code","f270e547":"code","7d7e6c95":"code","4479fec3":"code","6e34dbe0":"code","cae956b5":"code","e0fd79cb":"code","3b69e93e":"code","2c0ae55d":"code","1e23074c":"code","3dc0ae34":"code","6db76bd8":"code","b7576207":"code","be95b174":"code","fa66afff":"code","0d412039":"code","9668606b":"code","cdc36dc1":"code","9a4fa5ab":"code","9979bbef":"code","3947d735":"code","65fe55e5":"code","34944ae2":"code","e0487023":"code","73d015c3":"code","66a261ee":"code","d339c1ac":"code","f4bdea51":"code","008b046c":"code","9653a17e":"code","f9a98c9d":"code","6ddc4fcf":"code","3a5e9627":"code","d037207a":"code","7a1a4a03":"code","50a667d5":"code","f76bd4f6":"code","762b9939":"code","4ec302d2":"code","156c284f":"code","0fef7c43":"code","77f6a0b9":"code","2ae7ddba":"code","2cab3d1a":"code","538a9bf3":"code","62f2d71c":"code","911a133d":"code","4019029a":"code","7c9c8108":"code","83990eb7":"code","1b4e6bd7":"code","79cc79cc":"code","e705ca01":"code","b70221a6":"markdown","6cd518f2":"markdown","3eddd05c":"markdown","d1f04051":"markdown","c07322c2":"markdown","623b9854":"markdown","069d5236":"markdown","4569cc17":"markdown","c08a19e1":"markdown","68a1a602":"markdown","061f33e9":"markdown","5ff9cf09":"markdown","bc5ffef1":"markdown","dfc7c0a7":"markdown","7112bd49":"markdown","91955b3e":"markdown","29e23852":"markdown","6e4191f2":"markdown","f25553a1":"markdown","dee48310":"markdown","3170a991":"markdown","c68d6c14":"markdown","7ccb2059":"markdown","76e5e387":"markdown","d1e5e1ca":"markdown","453b8008":"markdown","067adb08":"markdown","adacb389":"markdown","b20b065c":"markdown","0db823b6":"markdown","1a22de1d":"markdown"},"source":{"47a3d9f2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e6d4617d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n","59f0bed0":"df = pd.read_csv(\"\/kaggle\/input\/boombikes\/day.csv\")\ndf.head()","c6e0a75f":"#Total 730 rows with 16 columns\n\ndf.shape","01260257":"#No missing values, dteday is not needed and we shall drop it later\ndf.info()","f0c15828":"#We can see the data doesnt have any outliers\ndf.describe(percentiles=[0.75,0.9,0.99])","60a84aab":"#We can se some high correlation between atemp and temp ofcourse, seasons and month because they are assigned with ranked values.\n#Correlation between casual, registered and cnt are high because cnt is the sum of casual and registered\n\nplt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","7b7e170a":"#Lets drop the date and the instant column\ndf = df.drop(['instant','dteday'],axis=1)\ndf.head()","66432e28":"#Lets check for some linearity.Like we see temp and atemp are strong linear relationship while atemp and temp are highly correlated\nsns.pairplot(df[['temp','atemp','hum','windspeed','cnt']])","8b44018d":"\nplt.scatter(x='temp',y='cnt',data=df)\nplt.show()\n\n\nplt.scatter(x='temp',y='casual',data=df)\nplt.show()\n\n\nplt.scatter(x='temp',y='registered',data=df)\nplt.show()","6d995148":"\nplt.scatter(x='atemp',y='cnt',data=df)\nplt.show()\n\n\nplt.scatter(x='atemp',y='casual',data=df)\nplt.show()\n\n\nplt.scatter(x='atemp',y='registered',data=df)\nplt.show()","236a69ce":"\nplt.scatter(x='hum',y='cnt',data=df)\nplt.show()\n\n\nplt.scatter(x='hum',y='casual',data=df)\nplt.show()\n\n\nplt.scatter(x='hum',y='registered',data=df)\nplt.show()","6c0f93e9":"\nplt.scatter(x='windspeed',y='cnt',data=df)\nplt.show()\n\n\nplt.scatter(x='windspeed',y='casual',data=df)\nplt.show()\n\n\nplt.scatter(x='windspeed',y='registered',data=df)\nplt.show()","7bde8df3":"#Seasons are showing some linearity, while the users fall during winter season, specially the casual users\n\n\nsns.barplot(x=df['season'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['season'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['season'],y=df['registered'])\nplt.show()","6cd21264":"#As expected, winter months show low users\n\nsns.barplot(x=df['mnth'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['mnth'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['mnth'],y=df['registered'])\nplt.show()","22ca63ab":"#We can see the weekday showing some linearity with total users.\n#Some important observations can be obtained here:\n#like casual users decrease during weekday and increase when weekend approaches while the registered users drop significantly in weekends, this signifies registered users are mostly working professionals\/employees\n\nsns.barplot(x=df['weekday'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['weekday'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['weekday'],y=df['registered'])\nplt.show()","7888f526":"#As expected, casual users are high on non working days while registered users are high on working days\nsns.barplot(x=df['workingday'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['workingday'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['workingday'],y=df['registered'])\nplt.show()","0d0d0a67":"#2019 shows significant increase in users\n\nsns.barplot(x=df['yr'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['yr'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['yr'],y=df['registered'])\nplt.show()","f270e547":"#We see weathersit type 1 has the users\nsns.barplot(x=df['weathersit'],y=df['cnt'])\nplt.show()\n\nsns.barplot(x=df['weathersit'],y=df['casual'])\nplt.show()\n\nsns.barplot(x=df['weathersit'],y=df['registered'])\nplt.show()","7d7e6c95":"#Weathersit type 4 is not present in the data\ndf['weathersit'].unique()","4479fec3":"df['weekday'] = df['weekday'].apply(lambda x : 0 if x==6 or x==0 else 1)","6e34dbe0":"#Lets check the proportion of registered users in weekends\n\ndf_weekend = df[df['weekday'] ==0]\ndf_weekend","cae956b5":"#We can see on weekends, 68% of total users are registered. We expect this to be more on weekdays\n(df_weekend['registered'].sum()\/df_weekend['cnt'].sum())*100","e0fd79cb":"#Not much of difference between mean and median, so it is safe to assume the average percentage\nprint(df_weekend['casual'].median())\nprint(df_weekend['casual'].mean())\n\nprint(df_weekend['registered'].median())\nprint(df_weekend['registered'].mean())","3b69e93e":"#Similarly we check registered users for weekdays\n\ndf_weekday = df[df['weekday'] ==1]\ndf_weekday","2c0ae55d":"#As expected, registered users are more on weekdays. Like we are sure, registered users are mostly working class\n\n(df_weekday['registered'].sum()\/df_weekday['cnt'].sum())*100","1e23074c":"#We can safely assume average percentage since no outliers\nprint(df['casual'].median())\nprint(df['casual'].mean())\n\nprint(df['registered'].median())\nprint(df['registered'].mean())","3dc0ae34":"#lets assign a new variable to our dataframe\n\ndf_new = df","6db76bd8":"#Assigning names to the seasons because numbers will create weights within\nseason_dict = {1:'Spring',2:'Summer',3:'Fall',4:'Winter'}\ndf_new['season'] = df_new['season'].map(season_dict)\ndf_new.head()\n","b7576207":"#Same goes for the month\nmonth_dict = {1:'Jan',2:'Feb',3:'Mar',4:'April',5:'May',6:'June',7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}\ndf_new['mnth'] = df_new['mnth'].map(month_dict)\ndf_new.head()","be95b174":"#Same for weathersit, type 4 is not present in dataset but let's just maintain the integrity\n#CFPP-Clear, Few clouds, Partly cloudy, Partly cloudy\n#MCBMM- Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n#LLTSL- Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n#HITS- Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n\nweathersit_dict = {1:'CFPP',2:'MCBMM',3:'LLTSL',4:'HITS'}\ndf_new['weathersit'] = df_new['weathersit'].map(weathersit_dict)\ndf_new.head()","fa66afff":"#Creating dummies and removing one column to reduce redundancy and same goes for all the categorical columns\n\nseason_dummies = pd.get_dummies(df_new['season'],drop_first=True,prefix='season')\ndf_new = pd.concat((df_new,season_dummies),axis=1)\ndf_new.head()","0d412039":"month_dummies = pd.get_dummies(df_new['mnth'],drop_first=True,prefix='month')\ndf_new = pd.concat((df_new,month_dummies),axis=1)\ndf_new.head()","9668606b":"weather_dummies = pd.get_dummies(df_new['weathersit'],drop_first=True,prefix='weather')\ndf_new = pd.concat((df_new,weather_dummies),axis=1)\ndf_new.head()","cdc36dc1":"#lets drop the original columns since we have created the respective dummies\n\ndf_new = df_new.drop(['season','mnth','weathersit'],axis=1)\ndf_new.head()","9a4fa5ab":"X = df_new.drop(['cnt'],axis=1)\ny = df['cnt']","9979bbef":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)","3947d735":"X_test = sm.add_constant(X_test)","65fe55e5":"X_train = sm.add_constant(X_train)","34944ae2":"#We will be standardizing the columns with their respective Z scores\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","e0487023":"#We fit and transform the train dataset on the required columns\n\nX_train[['atemp','temp','hum','windspeed']] = scaler.fit_transform(X_train[['atemp','temp','hum','windspeed']])\nX_train.head()","73d015c3":"#We transform the test dataset based on training data\n\nX_test[['atemp','temp','hum','windspeed']] = scaler.transform(X_test[['atemp','temp','hum','windspeed']])\nX_test.head()","66a261ee":"#Creating the regression object from scikit learn's regression package\nlr = LinearRegression()","d339c1ac":"#Fitting the model with RFE package\nlr.fit(X_train.iloc[:,1:],y_train)\nrfe = RFE(lr,15)\nrfe = rfe.fit(X_train.iloc[:,1:],y_train)","f4bdea51":"list(zip(X_train.iloc[:,1:].columns,rfe.support_,rfe.ranking_))","008b046c":"#We we list top 15 variables.\n#We include const since its present in the dataset already\n\nvar = ['const','yr','holiday','weekday','workingday','temp','hum','windspeed','season_Spring','season_Summer','season_Winter','month_Jan','month_July','month_Sep','weather_LLTSL','weather_MCBMM']","9653a17e":"#Fitting the model with statsmodels for better summary results\n\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","f9a98c9d":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","6ddc4fcf":"var = ['const','yr','weekday','holiday','temp','hum','windspeed','season_Spring','season_Summer','season_Winter','month_Jan','month_July','month_Sep','weather_LLTSL','weather_MCBMM']\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","3a5e9627":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","d037207a":"var = ['const','yr','holiday','weekday','temp','windspeed','season_Spring','season_Summer','season_Winter','month_Jan','month_July','month_Sep','weather_LLTSL','weather_MCBMM']\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","7a1a4a03":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","50a667d5":"var = ['const','yr','holiday','weekday','temp','windspeed','season_Spring','season_Summer','season_Winter','month_July','month_Sep','weather_LLTSL','weather_MCBMM']\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","f76bd4f6":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","762b9939":"var = ['const','yr','holiday','temp','windspeed','season_Spring','season_Summer','season_Winter','month_July','month_Sep','weather_LLTSL','weather_MCBMM']\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","4ec302d2":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","156c284f":"plt.figure(figsize=(10,7))\nsns.heatmap(X_train[var].iloc[:,1:].corr(),annot=True)\nplt.show()","0fef7c43":"var = ['const','yr','holiday','temp','windspeed','season_Summer','season_Spring','season_Winter','month_Sep','weather_LLTSL','weather_MCBMM']\nlr = sm.OLS(y_train,X_train[var]).fit()\nlr.summary()","77f6a0b9":"vif = pd.DataFrame()\nvif['Features'] = X_train[var].iloc[:,1:].columns\nvif['VIF'] = [variance_inflation_factor(X_train[var].iloc[:,1:].values,i) for i in range(X_train[var].iloc[:,1:].shape[1])]\nvif = vif.sort_values(by='VIF',ascending=False)\nvif","2ae7ddba":"#We predict for X_train\n\nprediction_train = lr.predict(X_train[var])","2cab3d1a":"#We get an R2 of 83.2% which is good\nr2_score(y_train,prediction_train)","538a9bf3":"#Lets apply the normal proportion for registered users since it showed more linearity than casual with 86% on weekdays and 68% on weekends\nX_train['registered_train'] = np.where(X_train['weekday'] == 1, prediction_train * 0.86, prediction_train * 0.68)","62f2d71c":"#Approximately 82% of predicted registered users are explainable which is again good\nr2_score(X_train['registered_train'],X_train['registered'])","911a133d":"#The errors are normally distributed which makes our assumption right\nsns.distplot(y_train-prediction_train)","4019029a":"plt.scatter(y=y_train-prediction_train,x=y_train)","7c9c8108":"#We get R2 of 81.9% for test data which is good. This shows our model is stable. \n#PS- This R2 will be different from R2_score below because here the test data is being treated as a training data and the data is fit with the statsmodels\n\nlr_1 = sm.OLS(y_test,X_test[var]).fit()\nlr_1.summary()","83990eb7":"#Lets predict for the test data based from training data\n\nprediction_test = lr.predict(X_test[var])\nprediction_test","1b4e6bd7":"# Lets check the R2_score from the result based from training data.\nr2_score(y_test,prediction_test)","79cc79cc":"#Lets apply the normal proportion for registered users since it showed more linearity than casual with 86% on weekdays and 68% on weekends\nX_test['registered_test'] = np.where(X_test['weekday'] == 1, prediction_test * 0.86, prediction_test * 0.68)","e705ca01":"#Approximately 78% of predicted registered users are explainable which is again good\nr2_score(X_test['registered'],X_test['registered_test'])","b70221a6":"Total users shows linearity with temp","6cd518f2":"Coming down the line, we finally conclude:\n\n<b>Total Users ( <i>cnt<\/i> ) = 1674.8 + 2039.8 ( <i>Year<\/i> ) - 841.5 ( <i>Holiday<\/i> ) + 4158.7 ( <i>Temperature<\/i> ) - 1286.4 ( <i>Windspeed<\/i> ) + 540.8 ( <i>Summer Season<\/i> ) -478.2 ( <i>Spring Season<\/i> ) + 834 ( <i>Winter Season<\/i> ) + 789.4 ( <i>September ) - 2483.68 ( <i>Weathersit Type 3<\/i> ) - 688.5 ( <i>Weathersit Type 2<\/i> ) <\/b>\n    \nTotal 10 variables\n\nTrain data- \n<b>R2<\/b> - 83.3%\n,<b>adj R2<\/b> - 82.9%\n\nTest data-\n<b>R2<\/b> - 81.9%\n,<b>adj R2<\/b> - 81%\n\n","3eddd05c":"<h3>Prediction on Test<\/h3>","d1f04051":"<h3>Let's try calculating the registered data for test and check the R2. (Optional) <\/h3>","c07322c2":"We see Low P values but the top 3 VIFS are infinity, since they are highly explained by each other. For ex- if its a weekend, then its a holiday, if its a workingday then it should be a weekday and not a holiday. So they might be giving R2 close to 1, so VIF turns out to be infinity. \n\nLets start by dropping workingday","623b9854":"<h3>Let's try calculating the registered data for train and check the R2. (Optional) <\/h3>","069d5236":"The score is 80.3% which is good.","4569cc17":"<h3>Modifying the categorical and continous variables<\/h3>","c08a19e1":"Not much of linearity is observed with humidity and cnt","68a1a602":"<b>Creating dummies<\/b>","061f33e9":"<h3><b>Problem Statement<\/b><\/h3>\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes.\nHow well those variables describe the bike demands\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. ","5ff9cf09":"The P values arent that high and might reduce with dropping of a column, so lets look at the VIF. <b>Humidity<\/b> has significantly high VIF value, lets drop it!","bc5ffef1":"<h3>Prediction on Train<\/h3>","dfc7c0a7":"<h3>Splitting the dataset into Train and Test <\/h3>","7112bd49":"<b>Weekday<\/b> showing high P value, Lets drop it.It might reduce the VIF of temp","91955b3e":"Hence we see atleast 86% of total users are registered users on weekdays","29e23852":"Lets import all the necessary packages","6e4191f2":"Here the total users and registered users show some linear relationship with weekday while casual shows a curve.Hence we can estimate registered users at the end using some average percentage","f25553a1":"So does for windspeed","dee48310":"<h3>Model Validation<\/h3>","3170a991":"We can see some linear relationship of temp and atemp with cnt. Anyways temp and atemp are highly correlated and we have to drop one of them later in the modeling stage","c68d6c14":"So goes with atemp","7ccb2059":"<h2>Using RFE tool for feature selection<\/h2>","76e5e387":"So what we can obtain here is, to estimate the casual and registered users we can assume a proportion of total users based on weekdays and weekends. Like if it is weekend, the proportion for casual user will be higher while registered will be higher for weekdays","d1e5e1ca":"We can see the errors are having a constant variance and are not following any pattern, hence they follow homoscedasticity","453b8008":"Hence, we can say approximately 68% of total users are registered users on weekends","067adb08":"January is showing a high P value, dropping it might reduce our VIF values","adacb389":"<h3>Scaling the continuous variables<\/h3>","b20b065c":"We can see, all out 10 variables are under the tolerance zone of VIF and low P values, We can now accept this features and proceed with the prediction and working on test data","0db823b6":"While spring season shows negative corelation with temp, July shows positive relation with temp. We can drop either of them, but we see dropping July brings down the VIF's values significantly, so lets proceed with dropping July","1a22de1d":"<h3>Estimating registered users as a proportion (Optional)<\/h3>"}}