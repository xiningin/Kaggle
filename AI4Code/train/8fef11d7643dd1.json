{"cell_type":{"6473d4f3":"code","f16d258c":"code","33f10762":"code","6aa89087":"code","c8e62cee":"code","fe874792":"code","cac6c275":"code","a87b6073":"code","0ef2935a":"code","9954846c":"code","9567c61a":"code","1e043dbb":"code","d9089850":"code","40c960fe":"code","ce69655b":"code","9e1e815e":"code","607da00b":"code","de973af8":"code","6ac03001":"code","6e321a86":"code","3af70539":"code","ead4c05b":"code","5b87f5d3":"code","68b27fb9":"code","693adfc2":"code","080860ac":"code","5b535fde":"code","c573b829":"code","66d14e9b":"code","5ecb2d1b":"code","a453cf1f":"code","e593b203":"code","dc86b3b9":"code","1aa07565":"code","2a32f4e5":"code","f5b5f83d":"code","50012701":"code","573180de":"code","864705a4":"code","d1d81476":"code","d107341a":"code","38538b39":"code","a00ec490":"code","818f5d72":"markdown","2a18f538":"markdown","ebfc9d69":"markdown","eda7e0f4":"markdown","900bc70b":"markdown","e76e5160":"markdown","1a8eec71":"markdown","14d14fdb":"markdown","c77ed91f":"markdown","cba96ede":"markdown","f4d9328d":"markdown","ac729a95":"markdown","dfce2294":"markdown","be0183df":"markdown","fd5fb225":"markdown","e4addf4c":"markdown","fe473d7f":"markdown"},"source":{"6473d4f3":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import *\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport lightgbm as lgb\nimport xgboost as xgb","f16d258c":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\nhist_transactions=pd.read_csv(\"..\/input\/historical_transactions.csv\")","33f10762":"# looking for dimensions of data\ntrain.head()","6aa89087":"test.head()","c8e62cee":"hist_transactions.head()","fe874792":"train.shape, test.shape, hist_transactions.shape","cac6c275":"train.info()","a87b6073":"test.info()","0ef2935a":"hist_transactions.info()","9954846c":"train.describe(include='all')","9567c61a":"hist_transactions.describe(include='all')","1e043dbb":"#Checking for NA values in train \ntrain.isna().sum().plot(kind='barh')\nfor i, v in enumerate(train.isna().sum()):\n    plt.text( v,i, str(v))\nplt.title('missing values count')","d9089850":"# Distribution of cards used first-time \n\ntrain['first_active_month']=pd.to_datetime(train['first_active_month'])\ncount = train['first_active_month'].dt.date.value_counts()\ncount= count.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(count.index, count.values)\nplt.xticks(rotation='vertical')\nplt.xlabel('First active month')\nplt.ylabel('Number of cards')\nplt.title(\"First active month count in train set\")\nplt.show()","40c960fe":"# Checking for the distributions of features using violin plot\n\n# feature 1\nplt.figure(figsize=(8,4))\nsns.violinplot(x=\"feature_1\", y='target', data=train)\nplt.xlabel('Feature 1')\nplt.ylabel('target score')\nplt.title(\"Feature 1 distribution\")\nplt.show()\n\n# feature 2\nplt.figure(figsize=(8,4))\nsns.violinplot(x=\"feature_2\", y='target', data=train)\nplt.xlabel('Feature 2')\nplt.ylabel('target score')\nplt.title(\"Feature 2 distribution\")\nplt.show()\n \n# feature 3\nplt.figure(figsize=(8,4))\nsns.violinplot(x=\"feature_3\", y='target', data=train)\nplt.xlabel('Feature 3')\nplt.ylabel('target score')\nplt.title(\"Feature 3 distribution\")\nplt.show()","ce69655b":"Avg_month_lag= np.round(hist_transactions.groupby('card_id')['month_lag'].agg('mean').reset_index())\ntrain= pd.merge(train, Avg_month_lag, on=\"card_id\")","9e1e815e":"num_trans = hist_transactions.card_id.value_counts().reset_index()\nnum_trans.columns = [\"card_id\", \"hist_transactions\/card\"]\ntrain= pd.merge(train, num_trans, on=\"card_id\")","607da00b":"plt.scatter('hist_transactions\/card', 'target', data=train)\nplt.xlabel('Number of hist_transactions\/card')\nplt.ylabel('target score')\nplt.title('Number of hist_transactions\/card  vs target score')","de973af8":"pur_amt = hist_transactions.groupby(\"card_id\")\npur_amt = pur_amt[\"purchase_amount\"].agg('mean').reset_index()\npur_amt.columns = [\"card_id\", \"purchase_amt\"]\ntrain= pd.merge(train, pur_amt, on=\"card_id\")","6ac03001":"plt.scatter('hist_transactions\/card', 'target', data=train)\nplt.xlabel('Number of hist_transactions\/card')\nplt.ylabel('target score')\nplt.title('Number of hist_transactions\/card  Vs target score')","6e321a86":"installments_percard = np.round(hist_transactions.groupby('card_id')['installments'].agg('mean').reset_index())\ntrain= pd.merge(train, installments_percard, on=\"card_id\")","3af70539":"plt.scatter('installments', 'target', data=train)\nplt.xlabel('no.of installments')\nplt.ylabel('target score')\nplt.title('no.of installments Vs target scre')","ead4c05b":"train['first_active_month']=pd.to_datetime(train['first_active_month'])\n\ntrain['first_active_year']=train['first_active_month'].dt.year\ntrain['first_active_month']=train['first_active_month'].dt.month\n","5b87f5d3":"plt.scatter(range(train.shape[0]), np.sort(train.target))\nplt.ylabel('target Score')\nplt.title('target-score distribution')","68b27fb9":"sns.heatmap(train.corr(), annot=True)\nplt.title('Correlation map')","693adfc2":"train_x=train.drop(['target',  'card_id'], axis=1)\ntrain_y=train['target']","080860ac":"x_train, x_test, y_train, y_test=train_test_split(train_x, train_y, test_size=0.33)","5b535fde":"x_train.shape, x_test.shape, y_train.shape, y_test.shape","c573b829":"model=LinearRegression()\nmodel.fit(x_train, y_train)","66d14e9b":"predict=model.predict(x_test)\npredict_train=model.predict(x_train)","5ecb2d1b":"print('RMSE test:', np.sqrt(np.mean((predict - y_test)**2)))\nprint('RMSE train:', np.sqrt(np.mean((predict_train - y_train)**2)))","a453cf1f":"model_rf=RandomForestRegressor()\nmodel_rf.fit(x_train, y_train)","e593b203":"predict_rf=model_rf.predict(x_test)\npredict_rf_train=model_rf.predict(x_train)","dc86b3b9":"print('Test RMSE RF:', np.sqrt(np.mean((predict_rf - y_test)**2)))\nprint('Train RMSE RF:', np.sqrt(np.mean((predict_rf_train - y_train)**2)))","1aa07565":"Random_Search_Params ={\n    'max_features':[1,2,3,4,5,6,7,8,9,10],\n    \"max_depth\": list(range(1,train.shape[1])),\n    'n_estimators' : [1, 2, 4, 8, 50, 100,150, 200, 250, 300],\n    \"min_samples_leaf\": [5,10,15,20,25],\n    'random_state' : [42] \n    }\n\n\nrandom_search = RandomizedSearchCV(\n    estimator=RandomForestRegressor(),\n    param_distributions= Random_Search_Params, \n    cv=3,\n    refit=True,\n    verbose=True)","2a32f4e5":"random_search.fit(x_train, y_train)","f5b5f83d":"random_search.best_params_","50012701":"\n\nmodel_rf_tune=RandomForestRegressor( random_state=42, \n                                     n_estimators=250, min_samples_leaf=15,\n                                     max_features=6, max_depth=7 )","573180de":"model_rf_tune.fit(x_train, y_train)","864705a4":"predict_rf_tune=model_rf_tune.predict(x_test)\n\npredict_rf_tune_train=model_rf_tune.predict(x_train)","d1d81476":"print('Test RMSE RF_tune_:', np.sqrt(np.mean((predict_rf_tune - y_test)**2)))\nprint('Train RMSE RF_tune:', np.sqrt(np.mean((predict_rf_tune_train - y_train)**2)))","d107341a":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbrt\",\n         \"metric\": 'rmse'}\n\nlgb_model = lgb.LGBMRegressor(**params, n_estimators = 10000,  n_jobs = -1)\nlgb_model.fit(x_train, y_train, \n        eval_set=[(x_train, y_train), (x_test, y_test)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=1000)","38538b39":"xgb_params = {'eta': 0.01,\n              'objective': 'reg:linear',\n              'max_depth': 6,\n              'min_child_weight': 3,\n              'subsample': 0.8,\n              \n              'eval_metric': 'rmse',\n              'seed': 11,\n              'silent': True}\n\nmodel_xgb = xgb.XGBRegressor() \nmodel_xgb.fit(x_train, y_train)","a00ec490":"trainPredict_xgb = model_xgb.predict(x_train)\ntestPredict_xgb = model_xgb.predict(x_test)\n\nprint(\"xgb test RMSE:\", np.sqrt(mean_squared_error(y_test, testPredict_xgb)))\nprint(\"xgb train RMSE:\", np.sqrt( mean_squared_error(y_train, trainPredict_xgb)))","818f5d72":"Purchase_amount","2a18f538":"#### Payment organization **[Elo](http:\/\/)**, which is operated widely in Brazil offer discounts for card-holders. Elo wants to know that is really these discounts helpful to keep the card-holders happy.\n\n#### Based on target-score we are going to predict whether discounts helpful or not.\n\n#### I will use train & historical_transactions for training and testing purpose.\n \n#### As Dependent variable is continuous so I will use regression algorithms starting from basic Linear-Regression model to Gradient boosting models and RMSE as evaluation metric\n","ebfc9d69":"Randomforest Regresssor","eda7e0f4":"Linear regression model","900bc70b":"XGBoost model","e76e5160":"#### Importing data files","1a8eec71":"Checking for correlatioin between variables","14d14fdb":"parameter_tuning in Randomforest Regresssor","c77ed91f":"Card-id","cba96ede":"### Data preprocessing","f4d9328d":"#### Importing required Libraries","ac729a95":"Installments","dfce2294":"lgb model","be0183df":"first_active_month","fd5fb225":"month_lag","e4addf4c":"#### Hist_transactions dataset","fe473d7f":"Splitting dataset into train and test sets"}}