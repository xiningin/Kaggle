{"cell_type":{"7ab5d0cc":"code","10a15821":"code","a78be99d":"code","dd3e5084":"code","1fb874c5":"code","8b239e56":"code","58edfef1":"code","a8a1b95c":"code","34c1b269":"code","40c1f98b":"code","f7881646":"code","029be388":"code","9a932578":"code","f7e2c518":"code","fe59d10d":"code","9f47a38b":"code","fe333942":"code","f258ac5e":"code","77444c61":"code","fae6665a":"code","3f8445fc":"code","1de32c4a":"markdown","a1cd2ad9":"markdown","96de2241":"markdown","e8e600d2":"markdown","2767a31a":"markdown","11967abc":"markdown","bccf93d7":"markdown","72300933":"markdown"},"source":{"7ab5d0cc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","10a15821":"df=pd.read_csv(\"..\/input\/startup-success-prediction\/startup data.csv\")\n\ndf.head()","a78be99d":"df.info()","dd3e5084":"df.shape","1fb874c5":"df.drop([\"Unnamed: 0\",\"Unnamed: 6\",\"id\",\"state_code.1\",\"latitude\",\"longitude\",\"zip_code\",\"city\",\"name\",\n       \"closed_at\",\"founded_at\",\"first_funding_at\",\"last_funding_at\",\"object_id\"], axis=1, inplace=True)\n\ndf.head(3)","8b239e56":"df=pd.get_dummies(df, columns=[\"status\"], drop_first=True)\ndf.head(2)","58edfef1":"df.isnull().sum().sort_values(ascending=False).head(7)\n\n# we have missing values only in 2 columns. let's fill it","a8a1b95c":"df.age_first_milestone_year.fillna(df[\"age_first_milestone_year\"].median(), inplace=True)\ndf.age_last_milestone_year.fillna(df[\"age_last_milestone_year\"].median(), inplace=True)","34c1b269":"# Define X and Y variable \n\nX=df.drop([\"state_code\",\"category_code\",\"status_closed\"], axis=1)\nY=df.status_closed","40c1f98b":"X=StandardScaler().fit_transform(X)\n\npca=PCA(n_components=32)\n\nX_pca=pca.fit_transform(X)\nexp_var=pca.explained_variance_ratio_\ncumsum_var=np.cumsum(exp_var)\ncumsum_var\nplt.plot(cumsum_var)\nplt.grid()","f7881646":"pca_new=PCA(n_components=17)\nX_new=pca_new.fit_transform(X)\n\nexp_var_new=pca_new.explained_variance_ratio_\ncumsum_var_new=np.cumsum(exp_var_new)\n\nplt.plot(cumsum_var_new)\nplt.grid()\nX_new=pd.DataFrame(X_new)\nX_new.head(3)\n\n# I have chosen first 17 features in this dataset","029be388":"from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n\n\n# With X_new variable, continue to apply machine learning algorithm\nX_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size=0.30, random_state=42)\n\n\nlog_reg=LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\nlog_reg.fit(X_train,Y_train)\n\ny_test_pred=log_reg.predict(X_test)\ny_train_pred=log_reg.predict(X_train)\n\nprint(\"Accuracy of the test set:\", accuracy_score(Y_test,y_test_pred))\nprint(\"Accuracy of the train set:\", accuracy_score(Y_train,y_train_pred))\n\nprint(classification_report(Y_test,y_test_pred))\nprint(confusion_matrix(Y_test,y_test_pred))","9a932578":"forest=RandomForestClassifier(n_estimators=20,\n                             max_depth=6,\n                             criterion=\"gini\",\n                             )\n\nforest.fit(X_train,Y_train)\ny_test_pred_forest=forest.predict(X_test)\ny_train_pred_forest=forest.predict(X_train)\n\nprint(\"Classification Report:\",\"\\n\",classification_report(Y_test,y_test_pred_forest),\"\\n\")\nprint(\"Confusion Matrix\",\"\\n\",confusion_matrix(Y_test,y_test_pred_forest),\"\\n\")\nprint(\"Accuracy score of random forest test set:\",accuracy_score(Y_test,y_test_pred_forest))\nprint(\"Accuracy score of random forest train set:\",accuracy_score(Y_train,y_train_pred_forest))","f7e2c518":"plt.figure(figsize=(8,6), dpi=100)\nfea_imp=pd.Series(data=forest.feature_importances_, index=X_new.columns)\nfea_imp=fea_imp.sort_values(ascending=False)\nfea_imp.plot(kind=\"barh\");","fe59d10d":"# GridSearchCV\n\nparam_forest={\"n_estimators\":np.arange(5,30,5),\n             \"max_depth\":np.arange(1,7,1),\n              \"criterion\":[\"gini\",\"entropy\"]\n             }\n\ngrid_forest=GridSearchCV(estimator=forest,\n                        param_grid=param_forest,\n                        cv=10,\n                         n_jobs=-1,\n                        return_train_score=True\n                        )\n\ngrid_forest.fit(X_train,Y_train)\n\nprint(grid_forest.best_params_)\nprint(grid_forest.best_score_)","9f47a38b":"results_forest=pd.DataFrame(grid_forest.cv_results_)\nresults_forest[[\"param_criterion\",\"param_max_depth\",\n               \"param_n_estimators\",\"mean_test_score\"]].sort_values(by=\"mean_test_score\", ascending=False).head()","fe333942":"from sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=5\n                        )\n\nknn.fit(X_train,Y_train)\ny_test_pred_knn=knn.predict(X_test)\ny_train_pred_knn=knn.predict(X_train)\n\nprint(\"Accuracy of test set with the knn :\", accuracy_score(Y_test,y_test_pred_knn))\nprint(\"Accuracy of train set with knn :\", accuracy_score(Y_train,y_train_pred_knn),\"\\n\")\nprint(\"Confusion matrix:\",\"\\n\", confusion_matrix(Y_test,y_test_pred_knn),\"\\n\")\nprint(\"Classification report: \",\"\\n\",classification_report(Y_test,y_test_pred_knn))","f258ac5e":"from sklearn.neighbors import NearestNeighbors\n\nA=knn.kneighbors_graph(X_train,n_neighbors=2)\nplt.spy(A, marker=\"*\")\nplt.show()","77444c61":"from sklearn.svm import SVC\n\nsvc=SVC()\n\nsvc.fit(X_train,Y_train)\ny_test_pred_svc=svc.predict(X_test)\ny_train_pred_svc=svc.predict(X_train)\n\nprint(\"Accuracy of train set with SVC:\", accuracy_score(Y_test,y_test_pred_svc))\nprint(\"Accuracy of train set with SVC:\", accuracy_score(Y_train,y_train_pred_svc))\nprint(\"Classification report:\", \"\\n\", classification_report(Y_test,y_test_pred_svc))\nprint(\"Confusion matrix:\", confusion_matrix(Y_test,y_test_pred_svc))","fae6665a":"from xgboost import XGBClassifier\n\nxgboost=XGBClassifier(objective='binary:logistic',\n                     n_estimators=5)\n\nxgboost.fit(X_train,Y_train)\n\ny_test_pred_xgboost=xgboost.predict(X_test)\ny_train_pred_xgboost=xgboost.predict(X_train)\n\nprint(\"Accuracy of test set with XGBOOST:\", accuracy_score(Y_test,y_test_pred_xgboost))\nprint(\"Accuracy of train set with XGBOOST:\", accuracy_score(Y_train,y_train_pred_xgboost),\"\\n\")\nprint(\"Confusion matrix:\", \"\\n\", confusion_matrix(Y_test,y_test_pred_xgboost))\nprint(\"Classification report:\", \"\\n\", classification_report(Y_test,y_test_pred_xgboost))","3f8445fc":"log=accuracy_score(Y_test,y_test_pred)\nforest=accuracy_score(Y_test,y_test_pred_forest)\nknn=accuracy_score(Y_test,y_test_pred_knn)\nsvc=accuracy_score(Y_test,y_test_pred_svc)\nxgboost=accuracy_score(Y_test,y_test_pred_xgboost)\n\nlog_df=pd.Series(log)\nforest_df=pd.Series(forest)\nknn_df=pd.Series(knn)\nsvc_df=pd.Series(svc)\nxgboost_df=pd.Series(xgboost)\n\nsns.set(style = \"darkgrid\" , font_scale = 1.2)\nplt.bar(\"Log\", height=log_df)\nplt.bar(\"Random Forest\", height=forest_df)\nplt.bar(\"KNN\", height=knn_df)\nplt.bar(\"SVC\", height=svc_df)\nplt.bar(\"XGBOOST\", height=xgboost_df)\nplt.xticks(rotation=45);","1de32c4a":"# SVC with PCA","a1cd2ad9":"# XGBOOST with PCA","96de2241":"# The algorithm that have highest accuracy is SVC and then XGBOOST","e8e600d2":"# Logistic Regression with PCA","2767a31a":"# Random Forest with PCA","11967abc":"# Let's First Apply PCA","bccf93d7":"# KNN with PCA","72300933":"### As a result of, with only 17 features we have very high accuracy most of algorithms for prediction"}}