{"cell_type":{"2ef7e9c2":"code","227b9a73":"code","85074961":"code","b5323aac":"code","e5a7f7f4":"code","0da7ebdf":"code","6462003c":"code","62fc637e":"code","fb596956":"code","28141bd1":"code","96a1cbd6":"code","04dee6c6":"code","8a171fb5":"code","ec0420dc":"code","d25ce1a2":"code","823eab3a":"code","2511fabe":"code","2b249912":"code","bacd7ed7":"code","7ecf91e1":"code","e68d5c2e":"code","cfdefd2a":"code","bc75ea0f":"code","e688dd2a":"code","e2e05695":"code","9ee39ae1":"code","9273d7e8":"code","ff901281":"code","87d02128":"markdown"},"source":{"2ef7e9c2":"import pandas as pd\npd.options.display.max_columns = None\n\nX_train_init = pd.read_csv('..\/input\/X_train.csv')\ny_train = pd.read_csv('..\/input\/y_train.csv')\nX_test_init = pd.read_csv('..\/input\/X_test.csv')","227b9a73":"X_train_grouped = X_train_init.groupby(['series_id']).mean().reset_index()\nX_train_grouped['mean_orientation_X'] = X_train_grouped['orientation_X']\nX_train_grouped['mean_orientation_Y'] = X_train_grouped['orientation_Y']\nX_train_grouped['mean_orientation_Z'] = X_train_grouped['orientation_Z']\nX_train_grouped['mean_orientation_W'] = X_train_grouped['orientation_W']\ndel X_train_grouped['orientation_X']\ndel X_train_grouped['orientation_Y']\ndel X_train_grouped['orientation_Z']\ndel X_train_grouped['orientation_W']\ndel X_train_grouped['measurement_number']\ndel X_train_grouped['angular_velocity_X']\ndel X_train_grouped['angular_velocity_Y']\ndel X_train_grouped['angular_velocity_Z']\ndel X_train_grouped['linear_acceleration_X']\ndel X_train_grouped['linear_acceleration_Y']\ndel X_train_grouped['linear_acceleration_Z']\n\nX_train = pd.merge(X_train_init, X_train_grouped, on = ['series_id'])\ndel X_train_init\ndel X_train_grouped","85074961":"X_test_grouped = X_test_init.groupby(['series_id']).mean().reset_index()\nX_test_grouped['mean_orientation_X'] = X_test_grouped['orientation_X']\nX_test_grouped['mean_orientation_Y'] = X_test_grouped['orientation_Y']\nX_test_grouped['mean_orientation_Z'] = X_test_grouped['orientation_Z']\nX_test_grouped['mean_orientation_W'] = X_test_grouped['orientation_W']\ndel X_test_grouped['orientation_X']\ndel X_test_grouped['orientation_Y']\ndel X_test_grouped['orientation_Z']\ndel X_test_grouped['orientation_W']\ndel X_test_grouped['measurement_number']\ndel X_test_grouped['angular_velocity_X']\ndel X_test_grouped['angular_velocity_Y']\ndel X_test_grouped['angular_velocity_Z']\ndel X_test_grouped['linear_acceleration_X']\ndel X_test_grouped['linear_acceleration_Y']\ndel X_test_grouped['linear_acceleration_Z']\n\nX_test = pd.merge(X_test_init, X_test_grouped, on = ['series_id'])\ndel X_test_init\ndel X_test_grouped","b5323aac":"del X_train['orientation_X']\ndel X_train['orientation_Y']\ndel X_train['orientation_Z']\ndel X_train['orientation_W']\n\ndel X_test['orientation_X']\ndel X_test['orientation_Y']\ndel X_test['orientation_Z']\ndel X_test['orientation_W']","e5a7f7f4":"X_train.describe()","0da7ebdf":"X_train.info()","6462003c":"for measurement_number in range(0,128):\n    X_train_mes = X_train[X_train['measurement_number'] == measurement_number]\n    #X_train['orientation_X' + str(measurement_number)] = X_train_mes['orientation_X']\n    #X_train['orientation_Y' + str(measurement_number)] = X_train_mes['orientation_Y']\n    #X_train['orientation_Z' + str(measurement_number)] = X_train_mes['orientation_Z']\n    #X_train['orientation_W' + str(measurement_number)] = X_train_mes['orientation_W']\n    \n    X_train['angular_velocity_X' + str(measurement_number)] = X_train_mes['angular_velocity_X']\n    X_train['angular_velocity_Y' + str(measurement_number)] = X_train_mes['angular_velocity_Y']\n    X_train['angular_velocity_Z' + str(measurement_number)] = X_train_mes['angular_velocity_Z']\n\n    X_train['linear_acceleration_X' + str(measurement_number)] = X_train_mes['linear_acceleration_X']\n    X_train['linear_acceleration_Y' + str(measurement_number)] = X_train_mes['linear_acceleration_Y']\n    X_train['linear_acceleration_Z' + str(measurement_number)] = X_train_mes['linear_acceleration_Z']\n\n    X_test_mes = X_test[X_test['measurement_number'] == measurement_number]\n    #X_test['orientation_X' + str(measurement_number)] = X_test_mes['orientation_X']\n    #X_test['orientation_Y' + str(measurement_number)] = X_test_mes['orientation_Y']\n    #X_test['orientation_Z' + str(measurement_number)] = X_test_mes['orientation_Z']\n    #X_test['orientation_W' + str(measurement_number)] = X_test_mes['orientation_W']\n    \n    X_test['angular_velocity_X' + str(measurement_number)] = X_test_mes['angular_velocity_X']\n    X_test['angular_velocity_Y' + str(measurement_number)] = X_test_mes['angular_velocity_Y']\n    X_test['angular_velocity_Z' + str(measurement_number)] = X_test_mes['angular_velocity_Z']\n\n    X_test['linear_acceleration_X' + str(measurement_number)] = X_test_mes['linear_acceleration_X']\n    X_test['linear_acceleration_Y' + str(measurement_number)] = X_test_mes['linear_acceleration_Y']\n    X_test['linear_acceleration_Z' + str(measurement_number)] = X_test_mes['linear_acceleration_Z']\n    \n#del X_train['orientation_X']\n#del X_train['orientation_Y']\n#del X_train['orientation_Z']\n#del X_train['orientation_W']\n\ndel X_train['angular_velocity_X']\ndel X_train['angular_velocity_Y']\ndel X_train['angular_velocity_Z']\n\ndel X_train['linear_acceleration_X']\ndel X_train['linear_acceleration_Y']\ndel X_train['linear_acceleration_Z']\n\ndel X_train['measurement_number']\n\n#del X_test['orientation_X']\n#del X_test['orientation_Y']\n#del X_test['orientation_Z']\n#del X_test['orientation_W']\n\ndel X_test['angular_velocity_X']\ndel X_test['angular_velocity_Y']\ndel X_test['angular_velocity_Z']\n\ndel X_test['linear_acceleration_X']\ndel X_test['linear_acceleration_Y']\ndel X_test['linear_acceleration_Z']\n\ndel X_test['measurement_number']","62fc637e":"X_train=X_train.fillna(0)\nX_test = X_test.fillna(0)\nX_gtrain=X_train.groupby(['series_id']).sum().reset_index()\nX_gtest=X_test.groupby(['series_id']).sum().reset_index()\ntrain_labels = y_train['surface']\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_gtrain_scaled = scaler.fit_transform(X_gtrain)\nX_gtest_scaled = scaler.transform(X_gtest)\n\n# \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u043c df \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0442\u0430\nsub = pd.DataFrame(X_gtest['series_id'])\nsub['surface'] = 0\n\ndel X_gtrain\ndel X_gtest","fb596956":"# \u0434\u0435\u0440\u0435\u0432\u044c\u044f \u0434\u0430\u043b\u0435\u0435 \u043d\u0435 \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c, \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0441\u043b\u0430\u0431\u044b\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n\n#from sklearn.tree import DecisionTreeClassifier\n\n#cl_tree = DecisionTreeClassifier(random_state = 61)\n#cl_tree.fit(X_gtrain, train_labels)\n#predicted = cl_tree.predict(X_gtest)\n#print(predicted)\n#print(len(predicted))","28141bd1":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=50)\nknn.fit(X_gtrain_scaled, train_labels)\npredicted = knn.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_knn.csv', index=False)","96a1cbd6":"from sklearn.linear_model import LogisticRegression\nC=1e-1\nlogit = LogisticRegression(C=C, random_state=61)\nlogit.fit(X_gtrain_scaled, train_labels)\npredicted = logit.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_logreg.csv', index=False)","04dee6c6":"import lightgbm as lgb\n\nparam = {\n        'objective':'multiclass',\n        'num_class':10,\n        'metric': 'multi_logloss',\n        'learning_rate': 0.016,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }\n\ngbm = lgb.LGBMClassifier(n_estimators=1100, silent=True)\ngbm.fit(X_gtrain_scaled, train_labels, verbose=False)\npredicted = gbm.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_lgbm.csv', index=False)","8a171fb5":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ntrain_acc = []\nval_acc = []\ntemp_train_acc = []\ntemp_val_acc = []\n#trees_grid = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600]\ntrees_grid = [1100]\n\"\"\"\n# Train on the training set\nfor ntrees in trees_grid:\n    print('running with ntrees = ', ntrees)\n    rfc = RandomForestClassifier(n_estimators=ntrees, random_state=42, n_jobs=-1, oob_score=True)\n    temp_train_acc = []\n    temp_val_acc = []\n    for train_index, val_index in skf.split(X_gtrain_scaled, train_labels):\n        X_train, X_val = X_gtrain_scaled[train_index], X_gtrain_scaled[val_index]\n        y_train, y_val = train_labels[train_index], train_labels[val_index]\n        rfc.fit(X_train, y_train)\n        temp_train_acc.append(rfc.score(X_train, y_train))\n        temp_val_acc.append(rfc.score(X_val, y_val))\n    train_acc.append(temp_train_acc)\n    val_acc.append(temp_val_acc)\n    print(\"train\/val acc = \", temp_train_acc, temp_val_acc)\n\"\"\"","ec0420dc":"import numpy as np    \n\"\"\"\ntrain_acc, val_acc = np.asarray(train_acc), np.asarray(val_acc)\n#np.mean(val_acc)\nprint(\"Best accuracy on CV is {:.2f}% with {} trees\".format(max(val_acc.mean(axis=1))*100, trees_grid[np.argmax(val_acc.mean(axis=1))]))\n\"\"\"","d25ce1a2":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\"\"\"\nfig, ax = plt.subplots(figsize=(8, 4))\nax.plot(trees_grid, train_acc.mean(axis=1), alpha=0.5, color='blue', label='train')\nax.plot(trees_grid, val_acc.mean(axis=1), alpha=0.5, color='red', label='cv')\nax.fill_between(trees_grid, val_acc.mean(axis=1) - val_acc.std(axis=1), val_acc.mean(axis=1) + val_acc.std(axis=1), color='#888888', alpha=0.4)\nax.fill_between(trees_grid, val_acc.mean(axis=1) - 2*val_acc.std(axis=1), val_acc.mean(axis=1) + 2*val_acc.std(axis=1), color='#888888', alpha=0.2)\nax.legend(loc='best')\nax.set_ylim([0.55,0.65])\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"N_estimators\");\n\"\"\"","823eab3a":"\"\"\"\ntrain_acc = []\nval_acc = []\n#min_samples_leaf_grid = list(range(1,15))\nmin_samples_leaf_grid = [3]\n\nfor min_samples_leaf in min_samples_leaf_grid:\n    print('running with min_samples_leaf = ', min_samples_leaf)\n    rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=min_samples_leaf, random_state=42, n_jobs=-1, oob_score=True)\n    temp_train_acc = []\n    temp_val_acc = []\n    for train_index, val_index in skf.split(X_gtrain_scaled, train_labels):\n        X_train, X_val = X_gtrain_scaled[train_index], X_gtrain_scaled[val_index]\n        y_train, y_val = train_labels[train_index], train_labels[val_index]\n        rfc.fit(X_train, y_train)\n        temp_train_acc.append(rfc.score(X_train, y_train))\n        temp_val_acc.append(rfc.score(X_val, y_val))\n    train_acc.append(temp_train_acc)\n    val_acc.append(temp_val_acc)\n    print(\"train\/val acc = \", temp_train_acc, temp_val_acc)\ntrain_acc, val_acc = np.asarray(train_acc), np.asarray(val_acc)\nprint(\"Best accuracy on CV is {:.2f}% with min_samples_leaf = {}\".format(max(val_acc.mean(axis=1))*100, min_samples_leaf_grid[np.argmax(val_acc.mean(axis=1))]))\n\"\"\"","2511fabe":"#val_acc.shape","2b249912":"\"\"\"fig, ax = plt.subplots(figsize=(8, 4))\nax.plot(min_samples_leaf_grid, train_acc.mean(axis=1), alpha=0.5, color='blue', label='train')\nax.plot(min_samples_leaf_grid, val_acc.mean(axis=1), alpha=0.5, color='red', label='cv')\nax.fill_between(min_samples_leaf_grid, val_acc.mean(axis=1) - val_acc.std(axis=1), val_acc.mean(axis=1) + val_acc.std(axis=1), color='#888888', alpha=0.4)\nax.fill_between(min_samples_leaf_grid, val_acc.mean(axis=1) - 2*val_acc.std(axis=1), val_acc.mean(axis=1) + 2*val_acc.std(axis=1), color='#888888', alpha=0.2)\nax.legend(loc='best')\nax.set_ylim([0.55,1.05])\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"min_samples_leaf\");\"\"\"","bacd7ed7":"\"\"\"train_acc = []\nval_acc = []\nmax_depth_grid = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]\n\nfor max_depth in max_depth_grid:\n    print('running with max_depth = ', max_depth)\n    rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=max_depth, random_state=42, n_jobs=-1, oob_score=True)\n    temp_train_acc = []\n    temp_val_acc = []\n    for train_index, val_index in skf.split(X_gtrain_scaled, train_labels):\n        X_train, X_val = X_gtrain_scaled[train_index], X_gtrain_scaled[val_index]\n        y_train, y_val = train_labels[train_index], train_labels[val_index]\n        rfc.fit(X_train, y_train)\n        temp_train_acc.append(rfc.score(X_train, y_train))\n        temp_val_acc.append(rfc.score(X_val, y_val))\n    train_acc.append(temp_train_acc)\n    val_acc.append(temp_val_acc)\n    print(\"train\/val acc = \", temp_train_acc, temp_val_acc)\ntrain_acc, val_acc = np.asarray(train_acc), np.asarray(val_acc)\nprint(\"Best accuracy on CV is {:.2f}% with max_depth = {}\".format(max(val_acc.mean(axis=1))*100, max_depth_grid[np.argmax(val_acc.mean(axis=1))]))\n\"\"\"","7ecf91e1":"\"\"\"fig, ax = plt.subplots(figsize=(8, 4))\nax.plot(max_depth_grid, train_acc.mean(axis=1), alpha=0.5, color='blue', label='train')\nax.plot(max_depth_grid, val_acc.mean(axis=1), alpha=0.5, color='red', label='cv')\nax.fill_between(max_depth_grid, val_acc.mean(axis=1) - val_acc.std(axis=1), val_acc.mean(axis=1) + val_acc.std(axis=1), color='#888888', alpha=0.4)\nax.fill_between(max_depth_grid, val_acc.mean(axis=1) - 2*val_acc.std(axis=1), val_acc.mean(axis=1) + 2*val_acc.std(axis=1), color='#888888', alpha=0.2)\nax.legend(loc='best')\nax.set_ylim([0.55,0.65])\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"max_depth\");\"\"\"","e68d5c2e":"\"\"\"max_depth=max_depth_grid[np.argmax(val_acc.mean(axis=1))]\ntrain_acc = []\nval_acc = []\nmax_features_grid = list(range(16,43,1))\n\nfor max_features in max_features_grid:\n    print('running with max_features = ', max_features)\n    rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=max_depth, max_features=max_features, \n                                 random_state=42, n_jobs=-1, oob_score=True)\n    temp_train_acc = []\n    temp_val_acc = []\n    for train_index, val_index in skf.split(X_gtrain_scaled, train_labels):\n        X_train, X_val = X_gtrain_scaled[train_index], X_gtrain_scaled[val_index]\n        y_train, y_val = train_labels[train_index], train_labels[val_index]\n        rfc.fit(X_train, y_train)\n        temp_train_acc.append(rfc.score(X_train, y_train))\n        temp_val_acc.append(rfc.score(X_val, y_val))\n    train_acc.append(temp_train_acc)\n    val_acc.append(temp_val_acc)\n    print(\"train\/val acc = \", temp_train_acc, temp_val_acc)\ntrain_acc, val_acc = np.asarray(train_acc), np.asarray(val_acc)\nprint(\"Best accuracy on CV is {:.2f}% with max_features = {}\".format(max(val_acc.mean(axis=1))*100, max_features_grid[np.argmax(val_acc.mean(axis=1))]))\n\"\"\"","cfdefd2a":"\"\"\"fig, ax = plt.subplots(figsize=(8, 4))\nax.plot(max_features_grid, train_acc.mean(axis=1), alpha=0.5, color='blue', label='train')\nax.plot(max_features_grid, val_acc.mean(axis=1), alpha=0.5, color='red', label='cv')\nax.fill_between(max_features_grid, val_acc.mean(axis=1) - val_acc.std(axis=1), val_acc.mean(axis=1) + val_acc.std(axis=1), color='#888888', alpha=0.4)\nax.fill_between(max_features_grid, val_acc.mean(axis=1) - 2*val_acc.std(axis=1), val_acc.mean(axis=1) + 2*val_acc.std(axis=1), color='#888888', alpha=0.2)\nax.legend(loc='best')\nax.set_ylim([0.55,0.65])\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"max_features\");\"\"\"","bc75ea0f":"train_acc = []\nval_acc = []\nrfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=23, max_features=42,random_state=42, n_jobs=-1, oob_score=True)\ntemp_train_acc = []\ntemp_val_acc = []\nfor train_index, val_index in skf.split(X_gtrain_scaled, train_labels):\n    X_train, X_val = X_gtrain_scaled[train_index], X_gtrain_scaled[val_index]\n    y_train, y_val = train_labels[train_index], train_labels[val_index]\n    rfc.fit(X_train, y_train)\n    temp_train_acc.append(rfc.score(X_train, y_train))\n    temp_val_acc.append(rfc.score(X_val, y_val))\ntrain_acc.append(temp_train_acc)\nval_acc.append(temp_val_acc)\nprint(\"train\/val acc = \", temp_train_acc, temp_val_acc)\ntrain_acc, val_acc = np.asarray(train_acc), np.asarray(val_acc)\nprint(\"Best accuracy on CV is {:.2f}%\".format(max(val_acc.mean(axis=1))*100))","e688dd2a":"rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=23, max_features=42,random_state=42, n_jobs=-1, oob_score=True)\nrfc.fit(X_gtrain_scaled, train_labels)\npredicted = rfc.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_rforest_1.csv', index=False)","e2e05695":"rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=24, max_features=43,random_state=42, n_jobs=-1, oob_score=True)\nrfc.fit(X_gtrain_scaled, train_labels)\npredicted = rfc.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_rforest_2.csv', index=False)","9ee39ae1":"rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=25, max_features=45,random_state=42, n_jobs=-1, oob_score=True)\nrfc.fit(X_gtrain_scaled, train_labels)\npredicted = rfc.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_rforest_3.csv', index=False)","9273d7e8":"rfc = RandomForestClassifier(n_estimators=1100, min_samples_leaf=3, max_depth=27, max_features=47,random_state=42, n_jobs=-1, oob_score=True)\nrfc.fit(X_gtrain_scaled, train_labels)\npredicted = rfc.predict(X_gtest_scaled)\nprint(predicted)\nsub['surface'] = predicted\nsub.to_csv('submission_rforest_4.csv', index=False)","ff901281":"from catboost import CatBoostClassifier, Pool\n\ntrain_dataset = Pool(X_gtrain_scaled, label=train_labels)\ntest_dataset = Pool(X_gtest_scaled)\n\ncc = CatBoostClassifier(learning_rate=0.016, random_seed=61, verbose=False, n_estimators=1100, task_type='GPU',loss_function='MultiClass')\ncc.fit(train_dataset)\npredicted = cc.predict(test_dataset)\nsub['surface'] = predicted\nsub.to_csv('submission_catboost.csv', index=False)","87d02128":"\u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0444\u0438\u0447 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0439 \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0435\u0440\u0438\u0438:"}}