{"cell_type":{"cbef7964":"code","26f78d5d":"code","57f577e1":"code","c8b04759":"code","6aad800d":"code","b8566fc8":"code","bc461bbf":"code","e7a79cfa":"code","50edd1b8":"code","3ed82e67":"code","d49c7a6b":"code","1114b3c5":"code","1a9a4851":"code","e5389a18":"code","9a5e0a67":"code","0a9fe8bd":"code","a9985fd7":"code","14897acb":"code","07062360":"code","632cf94d":"code","fe274fec":"code","95593011":"code","96a544a9":"code","c082c469":"code","866b9bb4":"code","50a7650b":"markdown","8b30c1a5":"markdown","60ff58f2":"markdown"},"source":{"cbef7964":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26f78d5d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as ssn\nimport numpy as np\nimport keras\nfrom keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout, MaxPool2D\nfrom keras.models import Sequential\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom pandas_profiling import ProfileReport\nimport time\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nbase={0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',\n      14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'}\n\n\n# Using tensorflow as backend","57f577e1":"train_data= pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train.csv')\ntest_data= pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test.csv')\n","c8b04759":"train_data.head()","6aad800d":"test_data.head()","b8566fc8":"train_labels=np.array(train_data['label'])\ndel train_data['label']\n\n","bc461bbf":"x_train= train_data.values\nx_train= x_train.reshape(-1,28,28,1)\n\n\nf, ax = plt.subplots(2,4)\n\nindex=0\n\nfor i in range(2):\n    for j in range(4):\n        ax[i,j].imshow(x_train[index].reshape(28,28),cmap='gray')\n        index+=1\n\n        \n","e7a79cfa":"#Images after normalising the inputs\n\n\nx_train=x_train\/255.\n\nw, mx= plt.subplots(4,4)\n\nk=0\nfor i in range(4):\n    for j in range(4):\n        mx[i,j].imshow(x_train[k].reshape(28,28),cmap='binary')\n        mx[i,j].set_title(base[train_labels[k]])\n        \n        k+=1\n        \n    plt.tight_layout()","50edd1b8":"print(\"The total number of labels are {}\".format(len(set(train_labels))))","3ed82e67":"train_labels_char=[]\nfor i in range(len(train_labels)):\n    train_labels_char.append(base[(train_labels[i])])\n\ntrain_labels_char=sorted(train_labels_char)\n\nssn.countplot(train_labels_char)","d49c7a6b":"test_labels=test_data['label']\n\ny=test_data['label']\n\ndel test_data['label']\n","1114b3c5":"test_data=test_data.values\ntest_data=test_data.reshape(-1,28,28,1)","1a9a4851":"#Checking the uniformity of testing labels\n\nssn.countplot(test_labels)","e5389a18":"import random\nx_test=test_data\nx_test=x_test\/255.\nx_test=x_test.reshape(-1,28,28,1)\nprint(\"The number of variables in x_test is {}\".format(len(x_test)))\nplt.imshow(x_test[random.choice(range(1,len(x_test)))].reshape(28,28),cmap='binary')","9a5e0a67":"#To overcome overfitting problem, I am trying to increase the training data by using ImageDataGenerator from the existing training data.\n\ndgen= ImageDataGenerator(featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,\n                        samplewise_std_normalization=False,zca_whitening=False, rotation_range=10, zoom_range=0.1,\n                        width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False, vertical_flip=False)\ndgen.fit(x_train)","0a9fe8bd":"\nmodel=Sequential()\n\n\n#Initial Conv2D layer with 64 filters with filter sizes of 3X3\nmodel.add(Conv2D(64,(3,3),strides=2,padding='same',activation='elu',input_shape=(28,28,1)))\n#Although RELU is common, I am experimenting with ELU. ELU is similar to RELU except negative inputs.\n\nmodel.add(MaxPool2D((2,2),strides=2,padding='same'))\n\n#Second Conv2D layer with 50 filters and 3X3 filter size\n\nmodel.add(Conv2D(50,(3,3),strides=1,padding='same',activation='elu'))\n\n#Third Conv2D layer with 128 filters and 3X3 filter size\n\nmodel.add(Conv2D(128,(3,3),strides=1,padding='same',activation='elu'))\n\nmodel.add(Flatten())\n\n#Output Layer\nmodel.add(Dense(units=24,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","a9985fd7":"#Using TPU v3-8\n# x_train, train_labels, x_test, test_labels\nl_binarizer=LabelBinarizer()\ntrain_labels= l_binarizer.fit_transform(train_labels)\ntest_labels= l_binarizer.fit_transform(test_labels)\n\n","14897acb":"start_time=time.time()\nhistory=model.fit(dgen.flow(x_train,train_labels,batch_size=50),epochs=20, validation_data=(x_test,test_labels))\nend_time=time.time()","07062360":"mins= int(round(end_time-start_time,2)\/\/60)\nseconds= round(round(end_time-start_time,2)%60)\nprint(\"The time taken to build the model is {} minutes {} seconds\".format(mins,seconds))","632cf94d":"print(\"The accuracy of the model is \",model.evaluate(x_test,test_labels)[1]*100,'%')","fe274fec":"training_accuracy=history.history['accuracy']\ntraining_loss= history.history['loss']\nvalidation_accuracy=history.history['val_accuracy']\nvalidation_loss= history.history['val_loss']\nepochs=list(range(1,21))\n","95593011":"#Accuracy Part\n\nm, ax= plt.subplots(1,2)\nax[0].plot(epochs,training_accuracy,'yo--',label='Train Accuracy')\nax[0].plot(epochs, validation_accuracy,'bo--',label='Validation Accuracy')\nax[0].set_title('Accuracy')\nax[0].legend()\n\n\n#Loss Part\n\nax[1].plot(epochs, training_loss, 'yo-',label='Training Loss')\nax[1].plot(epochs, validation_loss,'bo-',label='Validation Loss')\nax[1].set_title(\"Loss\")\nax[1].legend()","96a544a9":"pd= model.predict_classes(x_test)\nplt.figure(figsize=(16,16))\ncm= confusion_matrix(y,pd)\nssn.heatmap(cm, fmt=\"d\",cmap='PuRd',annot=True,linewidths=1,square=True)","c082c469":"total=0\n\nf, mx= plt.subplots(4,2)\nk=300\nfor i in range(4):\n    for j in range(2):\n        mx[i,j].imshow(x_test[k].reshape(28,28),cmap='pink')\n        mx[i,j].set_title(\"Predicted: {} Actual: {}\".format(pd[k],y[k]))\n        if pd[k]==y[k]:\n            total+=1\n        k+=1\n        \n    plt.tight_layout()\n","866b9bb4":"print(\"Total correctly classified results from random k is {} out of 8\".format(total))","50a7650b":"# Training the Model","8b30c1a5":"#### There is almost the similar count in all the labels. It means that our training data is varied properly among the labels.","60ff58f2":"#  SIGN-LANGUAGE\n\n![](https:\/\/assets.skyfilabs.com\/images\/blog\/sign-language-translator.webp)\n\n#### Sign languages (also known as signed languages) are languages that utilize the visual-manual methodology to pass on importance. Language is communicated through the manual sign stream in the mix with non-manual components. The dataset called (Sign Language MNIST) is of the American Sign Language hand gestures representing letters. This is a multi-class classification problem with 24 classes of letters ( excluding J and Z which require motion).  ####\n\n##### This dataset is licensed under the  CC0 1.0 Universal Public Domain Dedication license.#####\n\n\n"}}