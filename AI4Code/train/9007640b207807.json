{"cell_type":{"d0677fbe":"code","78631aa8":"code","9af6b450":"code","a0781ff5":"code","dda418dd":"code","07e08369":"code","8ee72ebb":"code","5020f9b3":"code","2ba98f8a":"code","796eaf6f":"code","5f4063ab":"code","23c5fb03":"code","d217822d":"code","24691560":"code","78894c07":"code","53ca4946":"code","f6f1ae28":"code","67a339e8":"code","d0acbcec":"code","1f0a9fd7":"code","308311a7":"code","3240ae3f":"code","d0dd82f8":"markdown","2d505d75":"markdown","8f0f692c":"markdown","4cb97621":"markdown","d8271d31":"markdown","10660552":"markdown","7f1bb77d":"markdown","c2354e79":"markdown","0831b39f":"markdown","c3dc7ee0":"markdown","fbfa4b21":"markdown","fdce0ade":"markdown","c41e3af8":"markdown"},"source":{"d0677fbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78631aa8":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras import Model, layers\nfrom keras.callbacks import *\nfrom keras.models import load_model, model_from_json","9af6b450":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random images of Weather\",\"..\/input\/multiclass-images-for-weather-classification\/dataset2\/**\")","a0781ff5":"from tqdm import tqdm\nfrom PIL import Image as Img\nfrom keras import Input\nfrom keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop","dda418dd":"\nPIC_DIR = f'..\/input\/multiclass-images-for-weather-classification\/dataset2\/'\n\nIMAGES_COUNT = 1125\n\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) \/\/ 2\n\nWIDTH = 128\nHEIGHT = 128\n\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic))","07e08369":"#Code By StackOverflow https:\/\/stackoverflow.com\/questions\/47186313\/valueerror-could-not-broadcast-input-array-from-shape-128-128-3-into-shape-1\n\nimport sys\n\nprint(len(images)) #to check the lenght of the list with elements having different shape\n\nfor item in images:\n    \n    if item.shape!=(128,128,3):\n    \n       images.remove(item)\n\nprint(len(images)) #you'll know how many corrupt sized images you had","8ee72ebb":"#Image shape\nimages = np.array(images) \/ 255\nprint(images.shape)","5020f9b3":"#Display first 25 images\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","2ba98f8a":"LATENT_DIM = 32\nCHANNELS = 3\n\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n\n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n\n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n\n    generator = Model(gen_input, x)\n    return generator","796eaf6f":"def create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n\n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n\n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n\n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n\n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n\n    return discriminator","5f4063ab":"from IPython.display import Image\nfrom keras.utils.vis_utils import model_to_dot","23c5fb03":"generator = create_generator()\ngenerator.summary()","d217822d":"Image(model_to_dot(generator, show_shapes=True).create_png())","24691560":"discriminator = create_discriminator()\ndiscriminator.trainable = False\ndiscriminator.summary()","78894c07":"Image(model_to_dot(discriminator, show_shapes=True).create_png())","53ca4946":"gan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)","f6f1ae28":"optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')","67a339e8":"gan.summary()","d0acbcec":"import time\niters = 15000\nbatch_size = 16\n\nRES_DIR = 'res2'\nFILE_PATH = '%s\/generated_%d.png'\nif not os.path.isdir(RES_DIR):\n    os.mkdir(RES_DIR)\n\nCONTROL_SIZE_SQRT = 6\ncontrol_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) \/ 2\n\nstart = 0\nd_losses = []\na_losses = []\nimages_saved = 0\nfor step in range(iters):\n    start_time = time.time()\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    generated = generator.predict(latent_vectors)\n\n    real = images[start:start + batch_size]\n    combined_images = np.concatenate([generated, real])\n\n    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n    labels += .05 * np.random.random(labels.shape)\n\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    d_losses.append(d_loss)\n\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    misleading_targets = np.zeros((batch_size, 1))\n\n    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n    a_losses.append(a_loss)\n\n    start += batch_size\n    if start > images.shape[0] - batch_size:\n        start = 0\n\n    if step % 50 == 49:\n        gan.save_weights('\/gan.h5')\n\n        print('%d\/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n\n        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n        control_generated = generator.predict(control_vectors)\n        \n        for i in range(CONTROL_SIZE_SQRT ** 2):\n            x_off = i % CONTROL_SIZE_SQRT\n            y_off = i \/\/ CONTROL_SIZE_SQRT\n            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n        im = Img.fromarray(np.uint8(control_image * 255))#.save(StringIO(), 'jpeg')\n        im.save(FILE_PATH % (RES_DIR, images_saved))\n        images_saved += 1","1f0a9fd7":"plt.figure(1, figsize=(12, 8))\nplt.subplot(121)\nplt.plot(d_losses, color='red')\nplt.xlabel('epochs')\nplt.ylabel('discriminant losses')\nplt.subplot(122)\nplt.plot(a_losses)\nplt.xlabel('epochs')\nplt.ylabel('adversary losses')\nplt.show()","308311a7":"import imageio\nimport shutilimages_to_gif = []\nfor filename in os.listdir(RES_DIR):\n    images_to_gif.append(imageio.imread(RES_DIR + '\/' + filename))\nimageio.mimsave('trainnig_visual.gif', images_to_gif)\nshutil.rmtree(RES_DIR)","3240ae3f":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, not a DS @mpwolke was Here.' )","d0dd82f8":"#Codes by Nagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/generate-realistic-human-face-using-gan ","2d505d75":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">GAN: Generative adversarial network<\/h3>\n\nA generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).\n\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proven useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\n\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, which itself is also being updated dynamically. This basically means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\n\nhttps:\/\/en.wikipedia.org\/wiki\/Generative_adversarial_network","8f0f692c":"# **<span style=\"color:#346888;\">Create a Discriminator<\/span>**","4cb97621":" # **<span style=\"color:#346888;\">Display the 1st (25) Images<\/span>**","d8271d31":"# **<span style=\"color:#346888;\">Define a Gan Model<\/span>**","10660552":"# **<span style=\"color:#346888;\">Training the GAN model<\/span>**","7f1bb77d":"#Code by Nagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/alienvspredator-transfer-learning","c2354e79":" # **<span style=\"color:#346888;\">Load data. Resize images<\/span>**","0831b39f":"# **<span style=\"color:#346888;\">Make a GIF of the output images that have been generated.<\/span>**","c3dc7ee0":"![](https:\/\/www.xenonstack.com\/images\/insights\/2019\/12\/generative-adversarial-networks-applications-xenonstack.png)xenonstack.com","fbfa4b21":"# **<span style=\"color:#346888;\">Create a Generator<\/span>**","fdce0ade":" # **<span style=\"color:#346888;\">Error: could not broadcast input array from shape (128,128,3) into shape (128,128). Solved by StackOverflow<\/span>**","c41e3af8":"The snippet above take a long time. I should Know when I read: Import Time= GPU!\n\n50 plus 50 till 15000. Let's do something else. "}}