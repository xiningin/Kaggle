{"cell_type":{"8b61fabb":"code","6e4c33ff":"code","3a93da50":"code","ca2f2d1d":"code","290a786a":"code","2b482401":"code","a044bc0b":"code","c25b5ad6":"code","175ccbee":"markdown"},"source":{"8b61fabb":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model","6e4c33ff":"train_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\nvalidation_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'\n\nIMG_SIZE = [250, 250]\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/225,\nsamplewise_center = False,\nrotation_range = 20,\nhorizontal_flip = False,\nwidth_shift_range = 0.2,\nheight_shift_range = 0.2,\nshear_range = 0.2,\nzoom_range = 0.2,\nvertical_flip = 0.2,\nfill_mode = 'nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/225)\n\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\ntarget_size = tuple(IMG_SIZE),\nbatch_size = 125,\nclass_mode = 'binary')\nvalidation_generator = validation_datagen.flow_from_directory(directory = validation_dir,\ntarget_size = tuple(IMG_SIZE),\nbatch_size = 125,\nshuffle = False,\nclass_mode = 'binary')","3a93da50":"#Calling MobileNetV2 from Tensorflow\napplication_mobilenet = MobileNetV2(input_shape = (224, 224, 3), weights = 'imagenet', include_top = False)\nfor layer in application_mobilenet.layers:\n    layer.trainable = False","ca2f2d1d":"#Adding MobileNetV2 to the deep learning model processing<\/h5>\nX = AveragePooling2D(pool_size=(7, 7))(application_mobilenet.output)\nX = Flatten(name=\"flatten\")(X)\nX = Dense(128, activation=\"relu\")(X)\nX = Dropout(0.5)(X)\nprediction = Dense(1, activation= 'sigmoid')(X)\nmodel = Model(inputs = application_mobilenet.input, outputs = prediction)","290a786a":"#Compile the model\nopt = Adam(lr=1e-4, decay=1e-4 \/ 8)\nmodel.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","2b482401":"#Putting dataset into the model<\/h5>\nfit_model = model.fit(train_generator, epochs = 8, validation_data= validation_generator,verbose = 1)\n","a044bc0b":"import matplotlib.pyplot as plt\n\ndef plotting(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.ylabel(string)\n    plt.xlabel(\"Epochs\")\n    plt.legend([string, \"val_\"+string])\n    plt.show()\n\nplotting(fit_model, \"accuracy\")","c25b5ad6":"pred_img_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithoutMask\/1000.png'\nimage = tf.keras.preprocessing.image.load_img(path=pred_img_dir,\n                                             target_size=tuple([224, 224]))\n\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)\nprint(np.around(predictions))\n\n# Image Display and Prediction\nif np.around(predictions) == 1:\n    plt.title('Without Mask')\nelse:\n    plt.title(\"With Mask\")\nplt.imshow(plt.imread(pred_img_dir))","175ccbee":"Modeling"}}