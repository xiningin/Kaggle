{"cell_type":{"4b7a27cc":"code","d6e2afce":"code","af280879":"code","40aee158":"code","043968e0":"code","90090fc9":"code","092ceddb":"code","078980cc":"code","e3fdb4e1":"code","dc782e81":"code","eee61347":"code","33374b30":"code","fca5008f":"code","545e8164":"code","73364f4f":"code","280d85a6":"code","ae3035c8":"code","29d5f2d0":"code","4218a70d":"code","32a2188f":"code","475310a4":"code","42a8f336":"code","2938594c":"code","64b9fd69":"code","de3aefda":"code","70d2334c":"code","77bcdc69":"code","f66aaac4":"code","bd325dc6":"code","6ce64824":"code","cdad55b0":"code","da87ca28":"code","2fffed8a":"code","8338ca7b":"code","d4add4bd":"code","27c595f6":"code","f1d04c2a":"code","d11ef2ca":"code","7bd140ef":"code","ed95a263":"markdown","eb016b14":"markdown","c456bf5d":"markdown","c5fb4101":"markdown","38594a4f":"markdown","d4104d13":"markdown","3bbfed07":"markdown","56f6e099":"markdown","85fbc5bc":"markdown","8a6a8052":"markdown"},"source":{"4b7a27cc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d6e2afce":"# packages \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import ExtraTreesRegressor","af280879":"# loading file\ndf = pd.read_excel(r'\/kaggle\/input\/covid19\/dataset.xlsx')","40aee158":"# initial exploring data\ndf.head()","043968e0":"df.columns","90090fc9":"# Patient ID isn't necessary\ndf = df.drop(columns='Patient ID')","092ceddb":"# Are there blank?\nnp.where(df.applymap(lambda x: x == ''))","078980cc":"# Searching for NaNs\ndf.info(verbose=True, null_counts=True)","e3fdb4e1":"def intitial_eda_checks(df):\n    '''\n    Thanks to: https:\/\/github.com\/FredaXin\/blog_posts\/blob\/master\/creating_functions_for_EDA.md\n    Takes df\n    Checks nulls\n    '''\n    if df.isnull().sum().sum() > 0:\n        mask_total = df.isnull().sum().sort_values(ascending=False) \n        total = mask_total[mask_total > 0]\n\n        mask_percent = df.isnull().mean().sort_values(ascending=False) \n        percent = mask_percent[mask_percent > 0] \n\n        missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    \n        print(f'Total and Percentage of NaN:\\n {missing_data}')\n    else: \n        print('No NaN found.')\n        \nintitial_eda_checks(df)","dc782e81":"def view_columns_w_many_nans(df, missing_percent):\n    '''\n    Thanks to: https:\/\/github.com\/FredaXin\/blog_posts\/blob\/master\/creating_functions_for_EDA.md\n    Checks which columns have over specified percentage of missing values\n    Takes df, missing percentage\n    Returns columns as a list\n    '''\n    mask_percent = df.isnull().mean()\n    series = mask_percent[mask_percent > missing_percent]\n    columns = series.index.to_list()\n    print(columns) \n    return columns","eee61347":"list_of_cols = view_columns_w_many_nans(df, .9)\ndf0 = df.drop(columns=list_of_cols)\n#Here they are: ","33374b30":"# the dataset for task 1\ndf1 = df0.drop(columns=['Patient addmited to regular ward (1=yes, 0=no)', \n                        'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n                       'Patient addmited to intensive care unit (1=yes, 0=no)'])","fca5008f":"# replacing text data to numbers - negative: 0, positive: 1.\ndf1['SARS-Cov-2 exam result'] = df1['SARS-Cov-2 exam result'].replace({'negative': 0, 'positive': 1})","545e8164":"# get dummies because machine learning algorithms prefers numbers!\ndf1_dummy = pd.get_dummies(df1)","73364f4f":"# correlation \ncorr_matrix_df1 = df1_dummy.corr()\n\ncorr_matrix_df1['SARS-Cov-2 exam result'].sort_values(ascending=False)","280d85a6":"# New DataFrame with target and selected features to plot correlation\ndf1_new = df1_dummy[['SARS-Cov-2 exam result','Monocytes', 'Red blood Cells', 'Mean platelet volume ',\n                    'Hemoglobin', 'Hematocrit','Basophils','Eosinophils', 'Platelets', 'Leukocytes']]","ae3035c8":"def heatmap_numeric_w_dependent_variable(df, dependent_variable):\n    '''\n    thanks to: https:\/\/github.com\/FredaXin\/blog_posts\/blob\/master\/creating_functions_for_EDA.md\n    Takes df, a dependant variable as str\n    Returns a heatmap of all independent variables' correlations with dependent variable \n    '''\n    plt.figure(figsize=(8, 10))\n    g = sns.heatmap(df.corr()[[dependent_variable]].sort_values(by=dependent_variable), \n                    annot=True, \n                    cmap='coolwarm', \n                    vmin=-1,\n                    vmax=1) \n    return g","29d5f2d0":"# plotting correlations with 'SARS-Cov-2 exam result' column\nheatmap_numeric_w_dependent_variable(df1_new, 'SARS-Cov-2 exam result')","4218a70d":"# defining features and target\nX1 = df1_new.drop(['SARS-Cov-2 exam result'], axis=1)\n\ny1 = df1_new['SARS-Cov-2 exam result']","32a2188f":"# imputation of missing values with multivariate imputation algorithm\nimp = IterativeImputer(max_iter=10, random_state=0)\n\nimp.fit(X1)\n\nX1 = imp.transform(X1)","475310a4":"# scaling X1\nscaler = MinMaxScaler()\n\nscaler.fit(X1)\n\nX1 = scaler.transform(X1)","42a8f336":"# train test split\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=33)     ","2938594c":"# LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)\n\nclf.fit(X1_train, y1_train)\n\ny1_pred = clf.predict(X1_test)","64b9fd69":"# cross-validation \nall_accuracies_clf_1 = cross_val_score(estimator=clf, X=X1_train, \n                                 y=y1_train, cv=5)","de3aefda":"# mean accuracy and standard deviation\nmean_acc_corrint = all_accuracies_clf_1.mean()*100\nstd_acc_corrint = all_accuracies_clf_1.std()","70d2334c":"# defining features and target\nX2 = df1_dummy.drop(['SARS-Cov-2 exam result'], axis=1)\n\ny2 = df1_dummy['SARS-Cov-2 exam result']","77bcdc69":"# I'll need this to apply SelectKBest algorithm \nX2_columns = X2.columns","f66aaac4":"# imputation of missing values with multivariate imputation algorithm\nimp = IterativeImputer(max_iter=10, random_state=0)\n\nimp.fit(X2)\n\nX2 = imp.transform(X2)","bd325dc6":"# scaling X2\nscaler = MinMaxScaler()\n\nscaler.fit(X2)\n\nX2 = scaler.transform(X2)","6ce64824":"# transforming X and y to DataFrame to apply SelectKbest and return the selected columns\ny2 = pd.DataFrame(data=y2, columns=['SARS-Cov-2 exam result'])\n\nX2 = pd.DataFrame(data=X2, columns=X2_columns) ","cdad55b0":"# applying\nselector = SelectKBest(chi2, k=5)\nselector.fit(X2, y2)","da87ca28":"# selected columns\n# thanks to: https:\/\/stackoverflow.com\/questions\/46927545\/get-feature-names-of-selectkbest-function-python\nX_new = selector.transform(X2)\nprint(X_new.shape)\n\nX2.columns[selector.get_support(indices=True)]\n\nvector_names = list(X2.columns[selector.get_support(indices=True)])\nprint(vector_names)\n\nX2.columns[selector.get_support(indices=True)].tolist()","2fffed8a":"# assigning target\ny_new = np.ravel(y2)","8338ca7b":"# train test split\n\nX_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_new, y_new, \n                                                                    random_state=33)                                                                     \n                                                                   ","d4add4bd":"# LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)\n\nclf.fit(X_new_train, y_new_train)\n\ny_new_pred = clf.predict(X_new_test)","27c595f6":"# cross-validation \nall_accuracies_clf_2 = cross_val_score(estimator=clf, X=X_new_train, \n                                 y=y_new_train, cv=5)","f1d04c2a":"# mean accuracy and standard deviation\nmean_acc_selector = all_accuracies_clf_2.mean()*100\nstd_acc_selector = all_accuracies_clf_2.std()","d11ef2ca":"print('The average accuracy of the first model is', mean_acc_corrint, '%')\nprint('and the standard deviation is', std_acc_corrint,'.')\nprint()\nprint('The average accuracy of the second model is', mean_acc_selector, '%')\nprint('and the standard deviation is', std_acc_selector, '.')","7bd140ef":"print('STAY HOME, IF YOU CAN.')","ed95a263":"# Take care of yourself! =)\n\nOn this kernel, I'll try to find the best features with two different methodologies: \n1. **Intuition** from correlation data.\n2. **SelectKBest** algorithm.\n\nWhich one is better? What will the difference between performances be?","eb016b14":"Ok, now it starts the intuition part.\n\nI chose the following features: \n\n***Monocytes, Red blood Cells, Mean platelet volume, Hemoglobin, Hematocrit, Basophils, Eosinophils, \nPlatelets and Leukocytes.***\n\nBut why?\n\n* As we know, it's necessary to choose the the furthest values from zero. \n* Features seems to be blood components. So I eliminated *Rhinovirus\/Enterovirus_detected* column to try set a pattern. \n* Finally, [there are reports](http:www.dw.com\/pt-br\/como-funciona-o-teste-r\u00e1pido-de-coronav\u00edrus\/a-52626671) that blood tests have been used to perform rapid coronavirus tests:\n\n> \"Realizam-se pesquisas em todo o mundo, e j\u00e1 est\u00e3o dispon\u00edveis as primeiras abordagens promissoras para um teste r\u00e1pido simplificado, semelhante ao teste da glicose no sangue.\n> Por exemplo, com o exame de uma gota de sangue, em apenas 15 minutos, o teste r\u00e1pido apresentado pela Comiss\u00e3o Nacional de Sa\u00fade da China \u00e9 capaz de detectar imunoglobulinas, os anticorpos que o corpo humano forma inicialmente quando ocorre uma nova infec\u00e7\u00e3o.\"\n\nOf course, I'm not assuming that this is an absolute truth. They're just clues to choose the features.\n\n--\nNotes:\n\nI tested the models with *Rhinovirus\/Enterovirus_detected* and the others blood components out of the selected range, but on the first case it was indifferent and on the second case the algorithm performed worst.\n\nRhinovirus\/Enterovirus detection isn't necessarily useless. For instance, in view of the difficulty in performing coronavirus exams and depending on the resources, I came up with the following hypothesis:\n\nSince among the exams, the Rhinovirus\/Enterovirus detection seems to be one that most correlates with exam results for the novel coronavirus, if a patient have certain symptoms, history, other specific informations etc and **Rhinovirus\/Enterovirus is not detected**, is there probability of being COVID-19?","c456bf5d":"What features to choose? Let's go to the two methods.","c5fb4101":"# **Resuming the results:**","38594a4f":"# **2. *SelectKBest***","d4104d13":"As we saw above, both methods had good performance. But the first was a little better, proving that our intuition and knowledge of the world can be useful to obtain good results in models of Machine Learning.\n\nFinally, it's always good to remember:","3bbfed07":"# **1. Intuition from correlation**","56f6e099":"Let's apply a function to check nulls ","85fbc5bc":"Now another function to drop columns with 90% of NaNs or more.","8a6a8052":"Now let's select features with a selector algorithm."}}