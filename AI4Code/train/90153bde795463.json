{"cell_type":{"a69f31d5":"code","56c3735d":"code","67b4a4ab":"code","5351c993":"code","a6250f28":"code","39563a4b":"code","de544d40":"code","8b93ec97":"code","2fc65002":"code","8d0d326d":"code","e0b22cf6":"code","eeaef1c4":"code","bf594920":"code","70d5b56f":"code","fb167133":"code","32dab41e":"code","80036249":"code","4bf22748":"code","9de7e043":"code","c7de5882":"code","de4654f1":"code","c3c694ff":"code","fb258f98":"code","8e5660ab":"code","a2a1184f":"code","45bd0bbe":"code","2a36fc84":"code","f2a1cea1":"code","d4db8077":"code","b38cac30":"code","6ba433ce":"markdown","51f92d52":"markdown","725a5675":"markdown","7fd132d9":"markdown","ee1c04a2":"markdown","6ccb3f13":"markdown","79b6bd41":"markdown","1055718f":"markdown","20b65dfc":"markdown","46f9242f":"markdown","34812967":"markdown","fae8271a":"markdown","6ca35c17":"markdown","8fbc250d":"markdown","818467ef":"markdown","4f1b1176":"markdown","9284d1e3":"markdown","45225c05":"markdown"},"source":{"a69f31d5":"# Load packages\nimport os\nimport random\nimport shutil\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\n\nfrom IPython.display import SVG\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.layers import Add, Dense, Dropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\nfrom time import time","56c3735d":"# Define some folders\nDATA_DIR = '\/kaggle\/input\/the-simpsons-characters-dataset\/simpsons_dataset'\nWORKING_DIR = '\/kaggle\/working'\nTRAIN_DIR = os.path.join(WORKING_DIR, 'train')\nVAL_DIR = os.path.join(WORKING_DIR, 'validation')","67b4a4ab":"def move_data(input_dir, output_dir, *args):\n    \"\"\"Move images from input_dir to output_dir.\n    :param input_dir: Input directory\n    :param output_dir: Output directory\n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.mkdir(output_dir)\n    for element in args:\n        if not os.path.exists(os.path.join(output_dir, element)):\n            os.mkdir(os.path.join(output_dir, element))\n        files = os.listdir(os.path.join(input_dir, element))\n        for file in files:\n            try:\n                shutil.copy(os.path.join(input_dir, element, file), \n                            os.path.join(output_dir, element, file))\n            except OSError as e:\n                raise\n                \ndef rearrange_folders(folder, n_val=500, *args):\n    \"\"\"Rearrange folders to be compliant with Keras requirement.\n    :param folder: Folder to rearrange\n    \"\"\"\n    # Create train and validation folder\n    if not os.path.exists(os.path.join(folder, 'train')):\n        os.mkdir(os.path.join(folder, 'train'))\n    if not os.path.exists(os.path.join(folder, 'validation')):\n        os.mkdir(os.path.join(folder, 'validation'))\n    \n    for element in args:\n        files = os.listdir(os.path.join(folder, element))\n        val_files = random.sample(files, k=n_val)\n        if not os.path.exists(os.path.join(folder, 'train', element)):\n            os.mkdir(os.path.join(folder, 'train', element))\n        if not os.path.exists(os.path.join(folder, 'validation', element)):\n            os.mkdir(os.path.join(folder, 'validation', element))\n        for file in files:\n            if file in val_files:\n                shutil.copy(os.path.join(folder, element, file), \n                            os.path.join(folder, 'validation', element, file))\n            else:\n                shutil.copy(os.path.join(folder, element, file), \n                            os.path.join(folder, 'train', element, file))\n        shutil.rmtree(os.path.join(WORKING_DIR, element))","5351c993":"# Move data\nmove_data(DATA_DIR, WORKING_DIR, 'homer_simpson', 'bart_simpson')\n# Reorder folder\nrearrange_folders(WORKING_DIR, 500, 'homer_simpson', 'bart_simpson')","a6250f28":"train_bart = os.listdir(os.path.join(TRAIN_DIR, 'bart_simpson'))\nimg = load_img(os.path.join(TRAIN_DIR, 'bart_simpson', train_bart[0]))\n\n# Convert image to array\nX = img_to_array(img)\n\nprint(f'Shape of the image array: {X.shape}.')","39563a4b":"# Show the image\nplt.imshow(X.astype(np.uint8))\nplt.axis('off')\nplt.show()","de544d40":"# Define ImageDataGenerator\naugmenting_data_gen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    channel_shift_range=9,\n    fill_mode='nearest'\n)","8b93ec97":"flow = augmenting_data_gen.flow(X[np.newaxis, :, :, :])\n\nplt.figure(figsize=(11, 5))\nfor i, x_augmented in zip(range(15), flow):\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(x_augmented[0])\n    plt.axis('off')\nplt.show()","2fc65002":"flow = augmenting_data_gen.flow_from_directory(TRAIN_DIR,\n                                               batch_size=1,\n                                               target_size=(224, 224))\n\nplt.figure(figsize=(11, 5))\nfor i, (X, y) in zip(range(15), flow):\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X[0])\n    plt.axis('off')\nplt.show()","8d0d326d":"# Load the model\nfull_imagenet_model = ResNet50(weights='imagenet')","e0b22cf6":"# Visualization of the model\nplot_model(full_imagenet_model, show_layer_names=False, show_shapes=True)","eeaef1c4":"# Define a model based on the previous one\noutput = full_imagenet_model.layers[-2].output\nbase_model = Model(full_imagenet_model.input, output)","bf594920":"def preprocess_function(x):\n    \"\"\"Preprocess x to be used in ResNet50\n    :param x: Input image\n    \"\"\"\n    if x.ndim == 3:\n        x = x[np.newaxis, :, :, :]\n    return preprocess_input(x)","70d5b56f":"BATCH_SIZE = 50\n\ndata_gen = ImageDataGenerator(preprocessing_function=preprocess_function)\n\ntrain_flow = data_gen.flow_from_directory(TRAIN_DIR, \n                                          batch_size=BATCH_SIZE,\n                                          target_size=(224, 224),\n                                          class_mode='binary',\n                                          shuffle=True)\n\nX, y = next(train_flow)\nprint(f'Shape of the input batch images: {X.shape}, and shape of the output batch images: {y.shape}.')","fb167133":"%%time\n\nfeatures = []\nlabels = []\n\ncount = 0\nfor X, y in train_flow:\n    labels.append(y)\n    features.append(base_model.predict(X))\n    count += len(y)\n    if count % 100 == 0:\n        print(f'Processed {count} images.')\n    if count >= 2500:\n        break","32dab41e":"# Concatenate the results\nlabels_train = np.concatenate(labels)\nfeatures_train = np.vstack(features)","80036249":"# Define the classification model\nn_samples, n_features = features_train.shape\n\ntop_model = Sequential()\ntop_model.add(Dense(1, input_dim=n_features, \n                    activation='sigmoid'))\ntop_model.compile(optimizer=Adam(lr=1e-4),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\nhistory = top_model.fit(features_train, labels_train,\n                        validation_split=0.1,\n                        verbose=2,\n                        epochs=15)","4bf22748":"# Define the complete model\nmodel = Model(base_model.input, top_model(base_model.output))","9de7e043":"flow = ImageDataGenerator().flow_from_directory(VAL_DIR,\n                                                batch_size=1,\n                                                target_size=(224, 224))\n\n# Predict some of the image in the validation set\nplt.figure(figsize=(12, 10))\nfor i, (X, y) in zip(range(15), flow):\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X[0] \/ 255)\n    pred = model.predict(preprocess_input(X))[0]\n    label = \"Homer\" if y[:, 1] > 0.5 else \"Bart\"\n    pred_label = \"Homer\" if pred > 0.5 else \"Bart\"\n    plt.title(f'Pred label: {pred_label}\\nProba: {pred[0]:.3}\\nTrue label: {label}')\n    plt.axis('off')\nplt.show()","c7de5882":"val_gen = ImageDataGenerator(preprocessing_function=preprocess_function)\nval_flow = val_gen.flow_from_directory(VAL_DIR, batch_size=BATCH_SIZE,\n                                       target_size=(224, 224),\n                                       shuffle=False,class_mode='binary')\n\npredicted_batches = []\nall_correct = []\nlabel_batches = []\nfor i, (X, y) in zip(range(val_flow.n \/\/ BATCH_SIZE), val_flow):\n    pred = model.predict(X).ravel()\n    predicted_batches.append(pred)\n    correct = list((pred > 0.5) == y)\n    all_correct.extend(correct)\n    label_batches.append(y)\n    print(f'Processed {len(all_correct)} images.')","de4654f1":"print(f'Accuracy on the validation set: {np.round(100 * np.mean(all_correct), 2)}%.')","c3c694ff":"predictions = np.concatenate(predicted_batches)\ntrue_labels = np.concatenate(label_batches)","fb258f98":"N_MISTAKES = 10\ntop_mistakes = np.abs(true_labels - predictions).argsort()[::-1][:N_MISTAKES]\n\nimages_names = np.array(val_flow.filenames, dtype=np.object)[top_mistakes]\n\nplt.figure(figsize=(15, 10))\nfor i, (img, pred, y) in enumerate(zip(images_names,\n                                    predictions[top_mistakes],\n                                    true_labels[top_mistakes])):\n    plt.subplot(2, 5, i + 1)\n    img_load = load_img(os.path.join(VAL_DIR, img))\n    img_arr = img_to_array(img_load)\n    label = \"Homer\" if y > 0.5 else \"Bart\"\n    pred_label = \"Homer\" if pred > 0.5 else \"Bart\"\n    plt.imshow(img_arr.astype(np.uint8))\n    plt.title(f'Pred label: {pred_label}\\nProba: {pred:.3}\\nTrue label: {label}')\n    plt.axis('off')\n\nplt.show()","8e5660ab":"[(i, l.output_shape) for (i, l) in enumerate(model.layers) if isinstance(l, Add)]","a2a1184f":"for i, layer in enumerate(model.layers):\n    layer.trainable = i >= 151","45bd0bbe":"augmenting_data_gen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_function\n)\n\ntrain_flow = augmenting_data_gen.flow_from_directory(TRAIN_DIR,\n                                                     target_size=(224, 224),\n                                                     batch_size=BATCH_SIZE,\n                                                     class_mode='binary',\n                                                     shuffle=True,\n                                                     seed=42)\n\nopt = SGD(lr=1e-4, momentum=0.9)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])","2a36fc84":"history = model.fit(train_flow,\n                    epochs=30,\n                    steps_per_epoch=train_flow.n \/\/ BATCH_SIZE,\n                    validation_data=val_flow,\n                    validation_steps=val_flow.n \/\/ BATCH_SIZE)","f2a1cea1":"plt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.legend()\nplt.title('Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.legend()\nplt.title('Accuracy')\n\nplt.show()","d4db8077":"val_gen = ImageDataGenerator(preprocessing_function=preprocess_function)\nval_flow = val_gen.flow_from_directory(VAL_DIR, batch_size=BATCH_SIZE,\n                                       target_size=(224, 224),\n                                       shuffle=False,class_mode='binary')\n\npredicted_batches = []\nall_correct = []\nlabel_batches = []\nfor i, (X, y) in zip(range(val_flow.n \/\/ BATCH_SIZE), val_flow):\n    pred = model.predict(X).ravel()\n    predicted_batches.append(pred)\n    correct = list((pred > 0.5) == y)\n    all_correct.extend(correct)\n    label_batches.append(y)\n    print(f'Processed {len(all_correct)} images.')","b38cac30":"print(f'Accuracy on the validation set: {np.round(100 * np.mean(all_correct), 2)}%.')","6ba433ce":"## Fine tuning\n\nLet's identify the location of the residual blocks (merge by addition in a residual architecture).","51f92d52":"## Data loading and data augmentation\n\nWe use the `Keras` utilities to manually load the first image file of the Bart folder. Make sure to have the `PIL` library.","725a5675":"The `ImageDataGenerator` object can be pointed to the dataset folder and both load the images and augment them on the fly and resize\/crop them to fit the input dimensions of the classification neural network.","7fd132d9":"So, we have a bit of improvement with fine tuning.","ee1c04a2":"The `Keras` image data helpers want images for different classes (*homer* and *bart*) to live in distinct subfolders.\n\n    data\/\n        train\/\n            homer\/\n                homer001.jpg\n                homer002.jpg\n                ...\n             bart\/\n                 bart001.jpg\n                 bart002.jpg\n                 ...\n        validation\/\n            homer\/\n                homer001.jpg\n                homer002.jpg\n                ...\n             bart\/\n                 bart001.jpg\n                 bart002.jpg\n                 ...\n\nWe build a validation dataset by taking $500$ images of Homer and $500$ of Bart out of the data. The remaining data constitute the training dataset.","6ccb3f13":"Let's compute the validation score on the full validation set.","79b6bd41":"Alright, so the transfer learning is around 0.9 accuracy. This is quite a good classification model as the Bart and Homer classes are not part of the ImageNet label set. As the validation set has $500$ images, an accuracy of $0.9$ means $50$ classification errors (which is not bad, I think).\n\nLet's plug this on top of the base model to be able to use it to make some classifications on our held out validation image folder.","1055718f":"Let's train a simple linear model on those features.","20b65dfc":"`Keras` provides tools to generate many variations from a single image: this is useful to augment the dataset with variants that should not affect the image label: a rotated image of Bart is an image of Bart. Doing data augmentation at train time make neural networks ignore such label-preserving transformations and therefore help reduce overfitting.","46f9242f":"Let's display the examples where the model makes the most confident mistakes. The filenames of items sampled by a flow (without random shuffling) can be accesses via: `val_flow.filenames`.","34812967":"Let's fine tune a bit the top level layers to see if we can further improve the accuracy of the model.","fae8271a":"We would like to write a function that iterate over $n$ images in the training set (batch after batch), extracts the activations of the last layer of `base_model` (by calling the `predicts` function) and collect the results in a big numpy array with dimensions $(n, 2048)$ for the features and $(n,)$ for the matching image labels.","6ca35c17":"The most important mistake appears to be Bart that is misclassified, it is probably because of the 1\/3 Bart - 2\/3 Homer ratio of images in the dataset. Another explication might be the croping of the image for the training.","8fbc250d":"# Fine Tuning a Pre-trained Deep CNN on a GPU Machine\n\nThis notebook is based on the Deep Learning course from the Master Datascience Paris Saclay. Materials of the course can be found [here](https:\/\/github.com\/m2dsupsdlclass\/lectures-labs).\nMorover, this session is inspired by [a blog post](https:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html) by Fran\u00e7ois Chollet, the creator of the `Keras` library.\n\n**Goal**\n* Fine tuned a pre-trained deep CNN on a new dataset.\n\n**Dataset used**\n* Some images from The Simpsons Characters Data from Kaggle [link](https:\/\/www.kaggle.com\/alexattia\/the-simpsons-characters-dataset).","818467ef":"Let's fix the wieghts of the low level layers and fine tune the top level layers.","4f1b1176":"When using this model, we need to be careful to apply the same image processing as was used during the training, otherwise the marginal distribution of the input pixels might not be on the right scale.","9284d1e3":"## Loading a pre-trained computer vision model\n\nLet us load a state of the art model with a good trade-off between prediction speed, model size and predictive accuracy, namely as Residual Network with $54$ parameterized layers ($53$ convolutional and one fully connected for the softmax).","45225c05":"## Transfert learning\n\nLet's remove the last dense classificaiton layer that is specific to the image net classes and use the previous later (after flatening) as a feature extractor."}}