{"cell_type":{"078575a1":"code","599a6976":"code","8a158d00":"code","385f3f59":"code","dcc124bc":"code","a815a64a":"code","1dcd5ffc":"code","f9dda632":"code","6b67c654":"code","fb3b7c69":"code","8f76b747":"code","d549060e":"code","9839ede4":"code","6c09f20b":"code","f35e0c92":"code","de1811b6":"code","b88d0f9b":"code","3c4575e0":"code","0b31ad60":"code","733a1245":"code","8e0cf996":"code","5be37318":"code","e78ca355":"code","ca0931ee":"code","9e88203b":"code","1d0f8a8a":"code","e79e648d":"code","0048f648":"code","a49c2642":"code","ccfda4d4":"code","4e95f301":"code","03670947":"code","1d2308d3":"code","e6bb20ec":"code","b580573c":"code","780f2e53":"code","baede4ae":"code","211ecd47":"code","c1bb8ccc":"code","1d417d7c":"code","bf9ee734":"markdown","a6372819":"markdown","07d5eab6":"markdown","0e1528c4":"markdown","17d5271c":"markdown","e86b3dbd":"markdown","d904bcf1":"markdown","79552372":"markdown","a36967e1":"markdown","5aea45e8":"markdown","a3378f2c":"markdown","90962cb2":"markdown","e80f88b3":"markdown","9dc29b57":"markdown","d209e89b":"markdown","d9b59ec7":"markdown","ce4d63f9":"markdown","7969e3c6":"markdown","f8f9eece":"markdown","b215d784":"markdown","ce474243":"markdown","6e5d77ed":"markdown","148fe83a":"markdown"},"source":{"078575a1":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","599a6976":"from fastai import *\nfrom fastai.vision import *\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image","8a158d00":"# hide warnings\nimport warnings\nwarnings.simplefilter('ignore')","385f3f59":"input_dir = Path(\"..\/input\/digit-recognizer\")\nos.listdir(input_dir)","dcc124bc":"train_df =  pd.read_csv(input_dir\/\"train.csv\")\ntrain_df.head(3)","a815a64a":"test_df =  pd.read_csv(input_dir\/\"test.csv\")\ntest_df.head(3)","1dcd5ffc":"train_dir = Path(\"..\/train\")\ntest_dir = Path(\"..\/test\")","f9dda632":"# Create training directory\nfor index in range(10):\n    try:\n        os.makedirs(train_dir\/str(index))\n    except:\n        pass","6b67c654":"# Test whether creating the training directory was successful\nsorted(os.listdir(train_dir))","fb3b7c69":"#Create test directory\ntry:\n    os.makedirs(test_dir)\nexcept:\n    pass","8f76b747":"# save training images\nfor index, row in train_df.iterrows():\n    \n    label,digit = row[0], row[1:]\n    \n    filepath = train_dir\/str(label)\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath\/filename)","d549060e":"# save testing images\nfor index, digit in test_df.iterrows():\n\n    filepath = test_dir\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath\/filename)","9839ede4":"tfms = get_transforms(do_flip=False)\ndata = ImageDataBunch.from_folder(\n    path = train_dir,\n    test = test_dir,\n    valid_pct = 0.2,\n    bs = 32,\n    size = 28,\n    ds_tfms = tfms,\n    num_workers = 0\n).normalize(imagenet_stats)\nprint(data)\nprint(data.classes)\ndata.show_batch(figsize=(5,5))","6c09f20b":"learn = cnn_learner(data, models.resnet18, metrics=accuracy, model_dir=\"\/tmp\/models\")","f35e0c92":"learn.fit_one_cycle(4)","de1811b6":"interp = ClassificationInterpretation.from_learner(learn)","b88d0f9b":"interp.plot_top_losses(9, figsize=(7, 7))","3c4575e0":"interp.plot_confusion_matrix()","0b31ad60":"#let's unfreeze the whole model!\nlearn.unfreeze()","733a1245":"learn.fit_one_cycle(1)","8e0cf996":"learn.lr_find()","5be37318":"learn.recorder.plot()","e78ca355":"learn.unfreeze()\nlearn.fit_one_cycle(4, max_lr=slice(1e-6,1e-4))","ca0931ee":"class_score, y = learn.get_preds(DatasetType.Test)\nclass_score = np.argmax(class_score, axis=1)","9e88203b":"sample_submission =  pd.read_csv(input_dir\/\"sample_submission.csv\")\ndisplay(sample_submission.head(2))\ndisplay(sample_submission.tail(2))","1d0f8a8a":"ImageId = []\nfor path in os.listdir(test_dir):\n    # '456.jpg' to '456'\n    path = path[:-4]\n    path = int(path)\n    # +1 because index starts at 1 in the submission file\n    path = path + 1\n    ImageId.append(path)","e79e648d":"submission  = pd.DataFrame({\n    \"ImageId\": ImageId,\n    \"Label\": class_score\n})\nsubmission.sort_values(by=[\"ImageId\"], inplace = True)\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission[:10]","0048f648":"learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir=\"\/tmp\/models\")","a49c2642":"learn.lr_find()","ccfda4d4":"learn.recorder.plot()","4e95f301":"learn.fit_one_cycle(5)","03670947":"learn.save('stage1')","1d2308d3":"learn.load('stage1')","e6bb20ec":"learn.unfreeze()","b580573c":"learn.lr_find()","780f2e53":"learn.recorder.plot()","baede4ae":"learn.unfreeze()\nlearn.fit_one_cycle(10, max_lr=slice(1e-6,1e-4))","211ecd47":"learn.lr_find()","c1bb8ccc":"learn.recorder.plot()","1d417d7c":"learn.unfreeze()\nlearn.fit_one_cycle(6)","bf9ee734":"We found 3 interesting files:\n- sample_submission.csv\n- train.csv\n- test.csv\n\n'sample_submission.csv' will show us, how we have to structure our data at the end before we submit it to the competition. We will only need this file at the end.\n\n'train.csv' is a file that contains all necessary information for training the CNN\n\n'test.csv' is the file we later use to test how good our CNN is\n\nLet's look at 'train.csv' and 'test.csv' to see how the data looks","a6372819":"OOH woow this is so good! why? it is supposed to be BAD! because we just unfreeze it! OK let's commit this for V3 and submit it!","07d5eab6":"## Predict\n\nGet the predictions on the test set","0e1528c4":"OK let's try to make the model even better than 0.99 accuracy! By using learning lr_find!****","17d5271c":"The next step is to select and create a CNN. In fast.ai creating a CNN is really easy. You just have to select one of the models from the [Computer Vision models zoo](https:\/\/docs.fast.ai\/vision.models.html#Computer-Vision-models-zoo)","e86b3dbd":"The last step is creating the submission file. \"sample_submission.csv\" is showing us the desired format","d904bcf1":"OK looks good ..let's do more epoch say 6 more","79552372":"## Evaluation\nCreate a ClassificationInterpretation object to generate confusion matrices and visualizations of the most incorrect images","a36967e1":"Columns the submission file has to have:\n- ImageId: index in the test set, starting from 1, going up to 28000\n- Label: the displayed digit","5aea45e8":"**LET's make our model better, we will unfreeze, fine tuning and learning rates**","a3378f2c":"A good way to summarize the performance of a classification algorithm is to create a confusion matrix. Confusion Matricies are used to understand which classes are most easily confused.","90962cb2":"Now it's time to train the neural network using the fit_one_cycle() function. <br>Parameters to modify: the number of epochs to train and the learning rate","e80f88b3":"OK this is for commit V6!","9dc29b57":"OK this looks good, I am lucky?? Is this a good method using fast.ai to generate really high accuracy??? I don't know, I hope so. let's commit this for V6 but I am not going to submit this! So, we are going up the cell to execute predict and submission process!****","d209e89b":"Plot the 9 images with the highest loss","d9b59ec7":"The data looks very interesting. Let's summarize what we got here:\n\nWhat we know about 'train.csv':\n- Each row is one image\n- The first row of each image is the label. It tells us which digit is shown.\n- The other 784 rows are the pixel for each digit and should be read like this\n\n`000 001 002 003 ... 026 027\n028 029 030 031 ... 054 055\n056 057 058 059 ... 082 083\n |   |   |   |  ...  |   |\n728 729 730 731 ... 754 755\n756 757 758 759 ... 782 783`\n\nWhat we know about 'test.csv':\n- The structure is the same as in train.csv, but there are no labels because it's our task to predict the labels\n\nTo read more about the data, read the ['Data' tab of the competition](https:\/\/www.kaggle.com\/c\/digit-recognizer\/data)\n\n#### Getting the data into the right format\nIn this tutorial I want to use the [fast.ai library](https:\/\/docs.fast.ai\/). Looking at the [documentation](https:\/\/docs.fast.ai\/vision.data.html#ImageDataBunch) we can quickly see, that fast.ai only accepts image files as data and not the format we were offered in this competition. Therefore we have to create images from the data we have. Fast.ai accepts image data in different formats. We will use the from_folder function of the ImageDataBunch class to load in the data. To do this we need all images in the following structure:\n\n`path\\\n  train\\\n    0\\\n      ___.jpg\n      ___.jpg\n      ___.jpg\n    1\\\n      ___.jpg\n      ___.jpg\n    2\\\n      ...\n    3\\\n      ...\n    ...\n  test\\\n    ___.jpg\n    ___.jpg\n    ...\n`\n\nLet's first create the folder structure!\n\n(nice to know: the input folder of Kaggle Competitions is always read-only, so if we want to add data or create folders, we have to do so outside of the input folder)","ce4d63f9":"#### Inspect and understand input data\nThe first step in most competitions is to check out the input data. Let's do this:","7969e3c6":"Okay, all folders are created! The next step is to create the images inside of the folders from 'train.csv' and 'test.csv'. We will use the Image module from PIL to do this.\n\n\nwe have to reshape each numpy array to have the desired dimensions of the image (28x28)\n\n`000 001 002 003 ... 026 027\n028 029 030 031 ... 054 055\n056 057 058 059 ... 082 083\n |   |   |   |  ...  |   |\n728 729 730 731 ... 754 755\n756 757 758 759 ... 782 783`\n\nthen we use the fromarray function to create a .jpg image from the numpy array and save it into the desired folder","f8f9eece":"Now that we have the right folder structure and images inside of the folders we can use the from_folder method of the ImageDataBunch class to create the dataset.\n\nWhenever we train a CNN we need to split the data into 3 parts:\n- training set: used to modify weights of neural network\n- validation set: prevent overfitting\n- test set: test accuracy of fully-trained model\n\nBut right now we only have a training and a test set. That's why we split the test set to get a validation set. We do this with the 'valid_pct' parameter. This is one of the parameters you could tune to increase the accuracy. To learn more about this read [this stackoverflow post](https:\/\/stackoverflow.com\/a\/13623707)","b215d784":"## Training","ce474243":"### work in progress\n<br>\nTo learn more about the fast.ai library check out the [documentation](https:\/\/docs.fast.ai) and the [fast.ai course 'Practical Deep Learning for Coders'](https:\/\/course.fast.ai\/)","6e5d77ed":"## Preparation\n#### Setup environment and import necessary modules","148fe83a":"OK we will commit this as V4!"}}