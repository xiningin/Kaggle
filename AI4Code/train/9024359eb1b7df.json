{"cell_type":{"dc5f837c":"code","f0ca7ca5":"code","f689b101":"code","83f1b9be":"code","c0b1c06b":"code","164b6316":"code","88828c82":"code","69323e64":"code","884c1c98":"code","37a90d7d":"code","9cb73997":"code","7d7979aa":"code","8da9cf43":"code","fe33fb99":"code","b6cd759c":"code","4ebd180d":"code","6294f4bd":"code","49020e54":"code","c7a3d1b0":"code","da1f1d09":"code","02d1dbfb":"code","f93057bc":"code","ddf66d48":"code","393a7319":"markdown","d55aedb0":"markdown"},"source":{"dc5f837c":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f0ca7ca5":"lol_df = pd.read_csv(\"..\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv\")","f689b101":"lol_df.head()","83f1b9be":"#Checking the general Information\n\nlol_df.info()","c0b1c06b":"#copying the dataframe in another variable\n\nlol = lol_df.copy()","164b6316":"#Lets Drop some columns that I think are unecessary\n#We will also try to drop maximum red cloumns since the data asks us to predict for blue\ncolumns = ['gameId', 'redFirstBlood', 'redKills', 'redEliteMonsters', 'redDragons','redTotalMinionsKilled',\n       'redTotalJungleMinionsKilled', 'redGoldDiff', 'redExperienceDiff', 'redCSPerMin', 'redGoldPerMin', 'redHeralds',\n       'blueGoldDiff', 'blueExperienceDiff', 'blueCSPerMin', 'blueGoldPerMin', 'blueTotalMinionsKilled']\n\nlol = lol.drop(columns, axis = 1)","88828c82":"lol.info()","69323e64":"#Compairing the relation between different features of Blue Team\n\np = sns.PairGrid(data = lol, vars = ['blueKills', 'blueAssists', 'blueWardsPlaced', 'blueTotalGold'],\n                  hue = 'blueWins', size=5, palette='Set2')\n\np.map_diag(plt.hist)\np.map_offdiag(plt.scatter)\np.add_legend();","884c1c98":"#plotting the Correlation Matrix\n\nplt.figure(figsize=(18,18))\nsns.heatmap(lol.drop('blueWins', axis =1 ).corr(),\ncmap = 'autumn_r', annot = True, fmt = '0.2f', vmin = 0, alpha = 0.6);","37a90d7d":"#From the correlation matrix, we can clean the data more\n\ncor_col = ['blueAvgLevel', 'redWardsPlaced', 'redWardsDestroyed', 'redDeaths', 'redAssists', 'redTowersDestroyed',\n       'redTotalExperience', 'redTotalGold', 'redAvgLevel']\n\nlol = lol.drop(cor_col, axis = 1)","9cb73997":"#Dropping tables that have very less correlation with the winning of Blue\n\ncor_list = lol[lol.columns[1:]].apply(lambda x: x.corr(lol['blueWins']))\n\ncols = []\n\nfor col in cor_list.index:\n    if(cor_list[col]>0.2 or cor_list[col]<-0.2):\n        cols.append(col)\n        \ncols","7d7979aa":"lol = lol[cols]\n\nlol.head()","8da9cf43":"lol.hist(alpha = 0.9, figsize=(15,15), bins=5);","fe33fb99":"#importing packages for model fitting and scalling\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn import tree\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport tensorflow as tf\nimport tensorflow.keras as keras","b6cd759c":"X = lol\ny = lol_df['blueWins']\n\nscaler = MinMaxScaler()\nscaler.fit(X)\n\nX = scaler.transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=32)","4ebd180d":"#Decision Tree\n\n\ntree = tree.DecisionTreeClassifier()\n\n\ngrid = {'min_samples_split': [5, 10, 20, 50, 100]},\n\nclf_tree = GridSearchCV(tree, grid, cv=5)\nclf_tree.fit(X_train, y_train)\n\npred_tree = clf_tree.predict(X_test)\n\n\nacc_tree = accuracy_score(pred_tree, y_test)\nprint(acc_tree)","6294f4bd":"#Naive Bayes\n\n\nclf_nb = GaussianNB()\nclf_nb.fit(X_train, y_train)\n\npred_nb = clf_nb.predict(X_test)\n\n\nacc_nb = accuracy_score(pred_nb, y_test)\nprint(acc_nb)","49020e54":"#Logistic Regression\n\nlm = LogisticRegression()\nlm.fit(X_train, y_train)\n\n\npred_lm = lm.predict(X_test)\nacc_lm = accuracy_score(pred_lm, y_test)\nprint(acc_lm)","c7a3d1b0":"#KNN Classification\n\nknn = KNeighborsClassifier() \n\n\ngrid = {\"n_neighbors\":np.arange(1,100)}\nclf_knn = GridSearchCV(knn, grid, cv=5)\nclf_knn.fit(X_train,y_train) \n\n\npred_knn = clf_knn.predict(X_test) \nacc_knn = accuracy_score(pred_knn, y_test)\nprint(acc_knn)","da1f1d09":"#Random Forest\n\nrf = RandomForestClassifier()\n\n# search the best params\ngrid = {'n_estimators':[100,200,300,400,500], 'max_depth': [2, 5, 10]}\n\nclf_rf = GridSearchCV(rf, grid, cv=5)\nclf_rf.fit(X_train, y_train)\n\npred_rf = clf_rf.predict(X_test)\n# get the accuracy score\nacc_rf = accuracy_score(pred_rf, y_test)\nprint(acc_rf)","02d1dbfb":"#Deep Learning\n\nmodel = keras.Sequential([keras.layers.InputLayer(input_shape = X_train.shape[1:]),\n                          keras.layers.Dense(100, activation = 'relu'),\n                          keras.layers.Dense(50, activation = 'relu'),\n                          keras.layers.Dense(25, activation = 'relu'),\n                          keras.layers.Dense(1, activation = 'softmax')\n                         ])\n\nmodel.compile(optimizer='RMSProp', loss='mae', metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, validation_split=0.2, epochs = 100)\n\n","f93057bc":"pred = model.evaluate(X_test, y_test)","ddf66d48":"prediction_table = {'Decision Tree': [acc_tree], 'Naive Bayes' : [acc_nb], 'Logistic Regression': [acc_lm], 'K_nearest Neighbors': [acc_knn], 'Random Forest': [acc_rf], 'Multi Layer NN': [pred[1]]}\n\np_table = pd.DataFrame.from_dict(prediction_table, orient = 'index', columns = [\"Accuracy Score\"])\n\nprint(p_table)","393a7319":"# Conclusion\n\nFrom the following models we can correlate and pick one which suits us. Tweaking with the different hyperparameters may improve the results.\n\nIn the end included a small NN model to show that sometimes even after NN's capability they can under-perform.","d55aedb0":"# **Intro**\n\nWe all love and have played league of legends, if you haven't don't there's still time.\nAnyways this is my first project on my #100DaysofCode Challenge.****"}}