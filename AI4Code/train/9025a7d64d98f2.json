{"cell_type":{"b91351fa":"code","610bb3e5":"code","dece514d":"code","f669362a":"code","d3a6e5c5":"code","009b5bb0":"code","c50b0e09":"code","4ee9bb21":"code","83b43588":"code","6d17de84":"code","9b8eca46":"code","105f8d2b":"code","f897eda4":"code","4cbdcd63":"code","2a587cf0":"code","e2b3c211":"code","d75c7d28":"code","0cb6ff8e":"code","796eaab2":"code","c679b5c8":"code","4a87dbe4":"code","3b384ae0":"code","0578a735":"code","f11944bc":"code","7c92cbd2":"code","17dd8502":"code","7f767703":"code","ae3a4c44":"code","687fccb5":"code","07403b76":"code","7e83dad2":"code","b9509d0d":"code","e74d44a5":"code","a9c08268":"code","f379ffca":"code","0d0027c3":"code","6ee331d8":"code","ea5aa28b":"code","eeb8a4da":"code","0917ba9a":"code","f29e8444":"code","7bcf752d":"code","5d741d21":"code","898402ca":"code","6e81da4e":"code","c2d5f717":"code","d002821d":"code","83f55c42":"code","297801f6":"code","ac03c389":"code","8844d90d":"code","7f2749f8":"code","941f9bad":"code","e4a03e50":"code","408e905d":"code","8fe6d0d5":"code","363457e1":"code","86482657":"code","c23233b7":"code","0491345f":"code","7cc189c3":"code","21db04ef":"markdown","027fbd55":"markdown","4ad68c50":"markdown","22d9c0c4":"markdown","61b478dc":"markdown","29713833":"markdown","5bdce7b6":"markdown","000fc8b1":"markdown","da7d7ffe":"markdown"},"source":{"b91351fa":"#Import our packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_log_error\nfrom xgboost import XGBRegressor","610bb3e5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dece514d":"pd.set_option('display.max_columns', None) # Show all columns of the dataset\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ntrain['HasPrice'] = 1\ntest['HasPrice'] = 0\n\ndf = pd.concat([train,test])\ndf","f669362a":"print(df.describe())","d3a6e5c5":"df.info()","009b5bb0":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr(),cmap='ocean')","c50b0e09":"df.corr().SalePrice.sort_values(ascending=False)","4ee9bb21":"sns.set_style('darkgrid')","83b43588":"sns.countplot(x='SaleCondition',data=df)\nplt.title('Sale Conditions')\nplt.xlabel('Condition')\nplt.ylabel('Count')","6d17de84":"sns.countplot(x='SaleType',data=df)\nplt.title('Sale Types')\nplt.xlabel('Type')\nplt.ylabel('Count')","9b8eca46":"plt.figure(figsize=(16,6))\nsns.countplot(y='Neighborhood',data=df)\nplt.title('Neighborhoods')\nplt.xlabel('Neighborhood')\nplt.ylabel('Count')","105f8d2b":"sns.countplot(x='BldgType',data=df)\nplt.title('Building Types')\nplt.xlabel('Type')\nplt.ylabel('Count')","f897eda4":"sns.countplot(x='HouseStyle',data=df)\nplt.title('House Styles')\nplt.xlabel('Style')\nplt.ylabel('Count')","4cbdcd63":"sns.countplot(x='YrSold',data=df)\nplt.title('Sales By Year')\nplt.xlabel('Year')\nplt.ylabel('Count')","2a587cf0":"sns.countplot(x='MSSubClass',data=df)\nplt.title('Class Counts')\nplt.xlabel('Class')\nplt.ylabel('Count')","e2b3c211":"#Transform years into decades\ndef get_decade_median(min,max):\n    return df.SalePrice[(df.YearBuilt >= min) & (df.YearBuilt < max)].median()\n\n#This list will be used to obtain the median housing price for each decade\ndecade = [str(i) + 's' for i in range(min(df.YearBuilt)-2,2020,10)]\nmed = [get_decade_median(i,i+10) for i in range(min(df.YearBuilt)-2,2020,10)]\nmedians = pd.DataFrame({'Decade' : decade,'Median' : med})\n\nmedplot = sns.lineplot(x='Decade', y='Median', data=medians, marker='o')\nplt.title('Medians For Each Decade')\nplt.draw()\nplt.xticks(rotation=35)\n\nnew_ticks = [str(int(x\/\/1000)) + 'K' for x in medplot.axes.get_yticks()]\nmedplot.axes.set_yticklabels(new_ticks)","d75c7d28":"medians","0cb6ff8e":"plt.figure(figsize=(10,6))\nsns.heatmap(pd.crosstab(df.MoSold,df.YrSold), annot=True, fmt='g')\nplt.title('Houses Sold on a Monthly Basis')\nplt.xlabel('Year')\nplt.ylabel('Month')","796eaab2":"sns.countplot(x='OverallQual',data=df)\nplt.title('Overall Quality')\nplt.xlabel('Quality')\nplt.ylabel('Count')","c679b5c8":"sns.countplot(x='OverallCond',data=df)\nplt.title('Overall Condition')\nplt.xlabel('Condition')\nplt.ylabel('Count')","4a87dbe4":"plt.figure(figsize=(10,6))\nsns.heatmap(pd.crosstab(df.OverallQual,df.OverallCond), annot=True, fmt='g')\nplt.title('Houses Sold Based on Condition and Quality')\nplt.xlabel('Quality')\nplt.ylabel('Condition')","3b384ae0":"plt.figure(figsize=(10,6))\nsns.heatmap(pd.crosstab(df.OverallQual,df.OverallCond), annot=True, fmt='g')\nplt.xlabel('Quality')\nplt.ylabel('Condition')","0578a735":"plt.figure(figsize=(10,6))\ns = sns.histplot(df.SalePrice, kde=True, bins=50)\nplt.title('Price Counts')\nplt.xlabel('Price')\n\n# new_ticks = [str(int(x\/\/1000)) + 'K' for x in s.axes.get_xticks()]\n# new_ticks[1] = 0\n# s.axes.set_xticklabels(new_ticks)","f11944bc":"plt.figure(figsize=(10,6))\nsns.histplot(df.LotArea, kde=True, bins=100)\nplt.title('Area Measures')\nplt.xlabel('Area')","7c92cbd2":"print(f'Amount of houses w\/ less than 25k sq. ft: {(len(df[df.LotArea < 25000]) * 100) \/ len(df)}%')\nprint(f'Amount of houses w\/ more than 25k sq. ft: {(len(df[df.LotArea > 25000]) * 100) \/ len(df)}%')","17dd8502":"plt.figure(figsize=(10,6))\nsns.histplot(df.GrLivArea, kde=True)\nplt.xlabel('Area Abv. Ground')","7f767703":"fig, (ax1,ax2) = plt.subplots(2,figsize=(10,6))\n\nsns.countplot(y='GarageCars', data=df, ax=ax1)\nax1.set_title('Sq. Ft Based on Car Capacity')\nax1.set_xlabel('')\nax1.set_yticklabels([int(t) for t in ax1.axes.get_yticks()])\nax1.set_ylabel('Car Spaces')\n\nsns.histplot(df.GarageArea, kde=True, ax=ax2)\nax2.set_title('Sq. Ft Based on Area')\nax2.set_xlabel('Area')\n\nfig.tight_layout()","ae3a4c44":"fig, ax = plt.subplots(1,2)\ncols_to_be_plotted = ['FullBath','HalfBath']\nxlabs = ['Full Baths', 'Half Baths']\nfor i in range(len(cols_to_be_plotted)):\n    sns.countplot(x=cols_to_be_plotted[i], data=df, ax=ax[i])\n    ax[i].set_xlabel(xlabs[i])\n    ax[i].set_ylabel('')\n\nfig.tight_layout()","687fccb5":"sns.heatmap(pd.crosstab(df.HalfBath,df.FullBath), annot=True, fmt='g')","07403b76":"plt.figure(figsize=(10,6))\nsns.countplot(y='BedroomAbvGr',data=df)\nplt.title('Bedrooms Above Ground')\nplt.xlabel('Bedrooms')\nplt.ylabel('')","7e83dad2":"plt.figure(figsize=(10,6))\nsns.countplot(y='KitchenAbvGr',data=df)\nplt.title('Kitchens Above Ground')\nplt.xlabel('Kitchens')\nplt.ylabel('')","b9509d0d":"plt.figure(figsize=(10,6))\nsns.countplot(y='Fireplaces',data=df)\nplt.xlabel('Fireplaces')\nplt.ylabel('')","e74d44a5":"plt.figure(figsize=(10,6))\nsns.countplot(y='TotRmsAbvGrd',data=df)\nplt.title('Total Rooms Above Ground')\nplt.xlabel('Total Rooms')\nplt.ylabel('')","a9c08268":"fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(10,6), sharey=True)\n\nsns.regplot(x='OverallQual', y='SalePrice', data=df, ax=ax1)\nax1.set_xlabel('Quality')\nax1.set_xticks(np.arange(10)+1)\nax1.set_ylabel('Price')\n\nsns.regplot(x='OverallCond', y='SalePrice', data=df, ax=ax2)\nax2.set_xlabel('Condition')\nax2.set_xticks(np.arange(10)+1)\nax2.set_ylabel('')\n\nplt.suptitle('Relation of Quality\/Condition to Price', fontsize=16)","f379ffca":"def boxplot(col, type_, xlab, rotation=0):\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=col, y=df.SalePrice, data=df)\n    plt.title('Quantiles of ' + type_)\n    plt.xlabel(xlab)\n    plt.xticks(rotation=rotation)\n    plt.ylabel('Price')","0d0027c3":"#Change to regression plot\nboxplot('OverallCond','Condition','Condition Rating')","6ee331d8":"boxplot('Neighborhood','Neighborhoods','Neighborhood',rotation=45)","ea5aa28b":"boxplot('MSZoning','Zoning','Zoning')","eeb8a4da":"boxplot('Street','Street Types','Street Type')","0917ba9a":"boxplot('Utilities','Utility Types','Utility Type')","f29e8444":"boxplot('LotConfig','Lot Configurations','Lot')","7bcf752d":"boxplot('BldgType','Building Types','Building Type')","5d741d21":"boxplot('HouseStyle','House Styles','House Style')","898402ca":"boxplot('KitchenQual','Kitchen Qualities','Kitchen Quality Rating')","6e81da4e":"boxplot('GarageType','Garage Types','Garage Type')","c2d5f717":"boxplot('SaleType','Sale Types','Sale Type')","d002821d":"boxplot('SaleCondition','Sale Conditions','Sale Condition')","83f55c42":"#Get the sum and the rate of missing values in each column\namt_of_null_vals = pd.Series([df[col].isnull().sum() for col in df.columns], index=df.columns)\npercentages = pd.Series([df[col].isnull().sum() \/ len(df) for col in train.columns], index=df.columns)\nnull_vals = pd.DataFrame({'missing_values': amt_of_null_vals, 'percentage': np.round(percentages,4)})\nnull_vals.sort_values(['missing_values'],ascending=False).head(20)","297801f6":"plt.figure(figsize=(15,8))\nsns.heatmap(df.isnull(), yticklabels=False)","ac03c389":"for name in df.select_dtypes('number'):\n    df[name].fillna(0, inplace=True)\nfor name in df.select_dtypes('object'):\n    df[name].fillna('None', inplace=True)","8844d90d":"pd.Series([df[col].isnull().sum() for col in df.columns], index=df.columns).sort_values(ascending=False).head(20)","7f2749f8":"#Separate the target variable from the data\nX = df.copy()\ny = X.pop('SalePrice')\n\n#Create Mutual Information\ndef mi_scores(X, y):\n    for col in X.select_dtypes(\"object\",'category'):\n        X[col], _ = X[col].factorize()\n    \n    scores = mutual_info_regression(X, y)\n    scores = pd.Series(scores, name='MI Scores', index=X.columns).sort_values(ascending=False)\n    return scores\n\nscores = mi_scores(X, y)\nscores[:20]","941f9bad":"plt.figure(figsize=(10,6))\nsns.barplot(scores.values[:20], scores.index[:20])\nplt.title('Mutual Information', fontsize=14)\nplt.xlabel('Importance')\nplt.ylabel('Column')","e4a03e50":"#The function we will use to get the mean squared error\ndef get_mae(X_train, X_test, y_train, y_test, model):\n    model.fit(X_train,y_train)\n    preds = model.predict(X_test)\n    return mean_absolute_error(preds, y_test)\n\ndef get_rmsle(X_train, X_test, y_train, y_test, model):\n    model.fit(X_train,y_train)\n    preds = model.predict(X_test)\n    return np.sqrt(mean_squared_log_error(y_test, preds))","408e905d":"gb = df.groupby('HasPrice')\ntest, train = [gb.get_group(x) for x in gb.groups]\n\n#Drop HasPrice column because we don't need it anymore\ntrain.drop(columns=['HasPrice'], inplace=True)\ntest.drop(columns=['HasPrice'], inplace=True)\n\nprint('Training dimensions:', train.shape)\nprint('Test dimensions:', test.shape)","8fe6d0d5":"#These features are ordinal, so we have to convert it to a categorical type\ntrain.MSSubClass = train.MSSubClass.astype('object')\ntrain.OverallQual = train.OverallQual.astype('object')\ntrain.OverallCond = train.OverallCond.astype('object')\ntest.MSSubClass = test.MSSubClass.astype('object')\ntest.OverallQual = test.OverallQual.astype('object')\ntest.OverallCond = test.OverallCond.astype('object')","363457e1":"#Features we will use for our model\nfeats = ['OverallQual','GrLivArea','YearBuilt','GarageArea','MSSubClass','1stFlrSF','2ndFlrSF']\n\nX_train = train[feats]\nX_test = test[feats]\ny_train = train.SalePrice\ny_test = test.SalePrice\n\n#Our features contain ordinal data, so they must be encoded\ncat_cols = list(X_test.select_dtypes('object').columns)\ncat_cols","86482657":"ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\nohe_cols_train = pd.DataFrame(ohe.fit_transform(X_train[cat_cols]))\nohe_cols_test = pd.DataFrame(ohe.transform(X_test[cat_cols]))\n\nohe_cols_train.index = X_train.index\nohe_cols_test.index = X_test.index\n\nnum_X_train = X_train.drop(cat_cols, axis=1)\nnum_X_test = X_test.drop(cat_cols, axis=1)\n\nX_train_encoded = pd.concat([num_X_train,ohe_cols_train], axis=1)\nX_test_encoded = pd.concat([num_X_test,ohe_cols_test], axis=1)","c23233b7":"#Create model\nmodel = XGBRegressor()\n\n#Obtain MAE\nprint('Our Mean Absolute Error is:')\nmae = get_mae(X_train_encoded,X_test_encoded,y_train,y_test,model)\nprint('{:.2f}'.format(mae))\nprint('Our RMSLE is:')\nrmsle = get_rmsle(X_train_encoded,X_test_encoded,y_train,y_test,model)\nprint('{:.2f}'.format(rmsle))","0491345f":"#Obtain predictions\npreds = model.predict(X_test_encoded)\noutput = pd.DataFrame({'ID': X_test_encoded.index + 1461, 'SalePrice': np.round(preds,2)})","7cc189c3":"#Create CSV file for submission!\noutput.to_csv('predictions.csv', index=False)\noutput","21db04ef":"We can see that the highest correlations with SalePrice are GrLivArea, GarageCars, GarageArea, TotalBsmtSF, 1stFlrSF, FullBath, TotalRmsAbvGrd, YearBuilt, and YearRemodAdd.","027fbd55":"This is a data visualization of the median house price in each decade beginning in the 1880s.\n","4ad68c50":"The years with the most purchases were 2007-2009","22d9c0c4":"We can see from this graph that prices began to rise in the 1970s and gradually increased until the 2000s. By 2010, the prices had more than doubled","61b478dc":"The houses were rated average in terms of both quality and condition based on both graphs of overall quality and condition","29713833":"Plotting a heatmap to see if there is any correlation between the columns","5bdce7b6":"Datasets are being loaded in Train and Test. And combining them into a single dataset","000fc8b1":"In terms of housing, it can be concluded that North Ames is the largest neighborhood, and College Creek is the second largest.","da7d7ffe":"To visualize the sata, I will plot the counts on some categories using Seaborn's countplot."}}