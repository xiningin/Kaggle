{"cell_type":{"c3c6f4db":"code","da4d93bd":"code","4a461559":"code","3f0a9748":"code","9541d30b":"code","a88b25ab":"code","17fa5c28":"code","3b879a90":"code","01fc127e":"code","6f1b9a6d":"code","881be488":"code","3b2f8bcd":"code","22f1e2be":"code","bc99c7ad":"code","80ab0a98":"code","2e057191":"code","b61331c1":"code","eb870176":"code","9c0f999c":"code","86b7de4f":"code","a0db87d9":"code","e94f5b7e":"code","dc901709":"code","2c285d16":"code","73aef046":"code","e7423ff9":"code","f7893fd6":"markdown","998c3fcd":"markdown","639b3c76":"markdown","8f609e82":"markdown","7c06f8a9":"markdown","f08ad297":"markdown","7c940970":"markdown","967bfe64":"markdown","9fea0587":"markdown","dc2116f4":"markdown","4121d077":"markdown","27c6ef16":"markdown","0ad63f59":"markdown"},"source":{"c3c6f4db":"import numpy as np        # Fundamental package for linear algebra and multidimensional arrays\nimport pandas as pd       # Data analysis and manipultion tool","da4d93bd":"ep_data  = pd.read_csv(\"..\/input\/electronics-product-pricing-dataset\/electronics_products_pricing.csv\" )","4a461559":"ep_data.head()","3f0a9748":"ep_data.info()","9541d30b":"col_to_drop = ['id', 'prices.sourceURLs', 'categories', 'dateAdded', 'dateUpdated', 'ean',\n              'imageURLs', 'keys', 'manufacturerNumber', 'name','sourceURLs','upc', 'prices.dateSeen']\n\nep_data.drop(col_to_drop, axis = 1, inplace=True)","a88b25ab":"ep_data = ep_data[ep_data.weight != 'Electronics']","17fa5c28":"def f(r):\n    if len(r) <20:\n        return float(r.split()[0])\n    else:\n      return 'z'\nep_data.weight = ep_data.weight.apply(f)","3b879a90":"ep_data = ep_data[ep_data.weight != 'z']","01fc127e":"ep_data.weight = ep_data.weight.astype('float')","6f1b9a6d":"# Fill missing data\nep_data['prices.shipping'].fillna(ep_data['prices.shipping'].mode().iloc[0], inplace = True)\nep_data['manufacturer'].fillna(ep_data['manufacturer'].mode().iloc[0], inplace = True)\nep_data.weight.fillna(ep_data.weight.mean(), inplace = True)","881be488":"ep_data.info()","3b2f8bcd":"col = ['prices.availability','prices.condition','prices.currency', 'prices.isSale', 'prices.merchant', 'prices.shipping', 'asins', 'brand', 'manufacturer', 'primaryCategories']","22f1e2be":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown='ignore')\nohe.fit(ep_data[col])\nencoded = ohe.transform(ep_data[col]).toarray()\nfeatures = ohe.get_feature_names(col)\nep_data[features] = encoded","bc99c7ad":"ep_data.drop(col, axis = 1, inplace=True)","80ab0a98":"# Input\/independent variables\nX = ep_data.drop('price', axis = 1)   # her we are droping the 'price' feature as this is the target and 'X' is input features, the changes are not \n                                              # made inplace as we have not used 'inplace = True'\n\ny = ep_data.price             # Output\/Dependent variable","2e057191":"# import train_test_split\nfrom sklearn.model_selection import train_test_split","b61331c1":"# split the data\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3, random_state = 42)","eb870176":"\n#import Linear regression from sklearn\nfrom sklearn.linear_model import LinearRegression","9c0f999c":"lr = LinearRegression()","86b7de4f":"lr.fit(X_train, y_train)","a0db87d9":"pred = lr.predict(X_val)","e94f5b7e":"# import mean squared error from sklearn.metric\nfrom sklearn.metrics import mean_squared_error","dc901709":"print('Root Mean Squared Error is: ', np.sqrt(mean_squared_error(y_val, pred))) \n\n# y_val is the original target value of the validation set (X_val)\n# pred is the predicted target value of the validation set","2c285d16":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(random_state = 1, max_depth = 5)","73aef046":"rfr.fit(X_train, y_train)","e7423ff9":"np.sqrt(mean_squared_error(y_val, rfr.predict(X_val)))","f7893fd6":"# Loading Dataset\nPandas module is used for reading files. \n\nYou can learn more about pandas [here](https:\/\/dphi.tech\/learn\/introduction-to-pandas)","998c3fcd":"## What do you need to do now?\n*  Perform EDA and Data Visualization \ud83d\udc40 to understand the data. Learn more about EDA [here](https:\/\/dphi.tech\/learn\/introduction-to-exploratory-data-analysis). Learn more about data visualization [here](https:\/\/dphi.tech\/learn\/introduction-to-data-visualization)\n*  Clean the data if required (like removing or filling missing values, treat outliers, etc.). Learn more about handling missing values [here](https:\/\/youtu.be\/EaGbS7eWSs0)\n*  Perform Data Preprocessing if you feel it's required. Learn one hot encoding [here](https:\/\/youtu.be\/9yl6-HEY7_s).","639b3c76":"# Data Cleaning & Data Preparation","8f609e82":"## Basic EDA","7c06f8a9":"# Building Model\nNow we are finally ready, and we can train the model.\n\nThere are tons of Machine Learning models like Linear Regression, Random Forest, Decision Tree, etc. to say you some. However here we are using Linear Regression (again, using the sklearn library).\n\nThen we would feed the model both with the data (X_train) and the answers for that data (y_train)","f08ad297":"## Model Evaluation\nEvaluating performance of the machine learning model that we have built is an essential part of any machine learning project. Performance of our model is done using some evaluation metrics.\n\nThere are so many evaluation metrics to use for regression problem, naming some - Mean Squared Error (in short MSE), Mean Absolute Error (in short MAE), Root Mean Squared Erro (in short RMSE), Root Mean Squared Log Error (in short RMSLE) etc. However, **RMSLE** is the metric for this data sprint. ","7c940970":"# Validate The Model\nWonder\ud83e\udd14 how well your model learned! Lets check it.\n\n### Predict on the validation data (X_val)\nNow we predict using our trained model on the validation set we created i.e. X_val and evaluate our model on unforeseen data.","967bfe64":"### Train the model","9fea0587":"## Model Evaluation","dc2116f4":"# Loading Libraries\nAll Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n\nIn data science, numpy and pandas are most commonly used libraries. Numpy is required for calculations like means, medians, square roots, etc. Pandas is used for data processin and data frames. We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd).\n\nNote: You can import all the libraries that you think will be required or can import it as you go along. \n\nHere we are importing two libraries - numpy and pandas\n","4121d077":"# Separating Input Features and Output Features\nBefore building any machine learning model, we always separate the input variables and output variables. Input variables are those quantities whose values are changed naturally in an experiment, whereas output variable is the one whose values are dependent on the input variables. So, input variables are also known as independent variables as its values are not dependent on any other quantity, and output variable\/s are also known as dependent variables as its values are dependent on other variable i.e. input variables. Like here in this data, we want to predict the price, so the 'price' variable is our target variable and remaining features are input variable.\n\nBy convention input variables are represented with 'X' and output variables are represented with 'y'.","27c6ef16":"## Random Forest","0ad63f59":"# Splitting the data into Train and Validation Set\nWe want to check the performance of the model that we built. For this purpose, we always split (both input and output data) the given data into training set which will be used to train the model, and test set which will be used to check how accurately the model is predicting outcomes.\n\nFor this purpose we have a class called 'train_test_split' in the 'sklearn.model_selection' module.\n\n"}}