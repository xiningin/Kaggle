{"cell_type":{"d1517430":"code","ebde5944":"code","8c0679b2":"code","8cbab4e8":"code","7c80a81b":"code","dc454fcf":"code","e67e48f3":"code","4fec2ce7":"code","baf195f7":"code","c3590446":"code","566541e2":"code","0f92e5e2":"code","adf8779c":"code","4c8ae1dd":"code","c887ae09":"code","65598b5f":"code","3c5b0b3d":"code","06afd208":"code","45749887":"code","c55511d1":"code","bfee7c22":"code","b03811e5":"code","8267bfe9":"code","409d75ee":"code","816f2a47":"code","5dd2f8f1":"code","0c880874":"code","36942a82":"code","0c51b6c3":"markdown","a6d8150d":"markdown","ed269ec9":"markdown","2d354ee3":"markdown","ff01c1cc":"markdown","cc8592c6":"markdown","5814b354":"markdown","83fb4148":"markdown","50b36233":"markdown","330355a4":"markdown","799d0f1f":"markdown","1002cc13":"markdown","82b169f4":"markdown","19d82b0c":"markdown","eb0e4edd":"markdown","a7a50282":"markdown"},"source":{"d1517430":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ebde5944":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\n\nimport matplotlib.pyplot as plt \nimport re\nimport string\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nfrom collections import Counter\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\nimport plotly.express as px\n\nsns.set(style=\"darkgrid\")","8c0679b2":"import os\nos.listdir('\/kaggle\/input\/')","8cbab4e8":"df = pd.read_csv(\"..\/input\/nigeria-endsars-tweets\/NigeriaEndSars data.csv\")\ndf.head(5)","7c80a81b":"df.shape","dc454fcf":"needed_columns=['username','date','content']\ndf=df[needed_columns]\ndf.head()","e67e48f3":"contents=df.content\ncontents","4fec2ce7":"remove_url=lambda x:re.sub(r'http\\S+','',str(x))\ncontents_lr=contents.apply(remove_url)\ncontents_lr","baf195f7":"to_lower=lambda x: x.lower()\ncontents_lr_lc=contents_lr.apply(to_lower)\ncontents_lr_lc","c3590446":"remove_puncs= lambda x:x.translate(str.maketrans('','',string.punctuation))\ncontents_lr_lc_np=contents_lr_lc.apply(remove_puncs)\ncontents_lr_lc_np","566541e2":"more_words=['say','going','like','U','u','hey','#epitwitter','amp',]\nstop_words=set(stopwords.words('english')) \nstop_words.update(more_words)\nremove_words=lambda x: ' '.join([word for word in x.split() if word not in stop_words]) \ncontents_lr_lc_np_ns=r=contents_lr_lc_np.apply(remove_words)\ncontents_lr_lc_np_ns","0f92e5e2":"words_list=[word for line in contents_lr_lc_np_ns for word in line.split()]\nwords_list[:5]","adf8779c":"word_counts=Counter(words_list).most_common(50)\nword_df=pd.DataFrame(word_counts)\nword_df.columns=['word','frq']\ndisplay(word_df.head(5))\n# px=import plotly.express\npx.bar(word_df,x='word',y='frq',title='Most common words')","4c8ae1dd":"display(df.head(5))\ndf.content=contents_lr_lc_np_ns\ndisplay(df.head(5))","c887ae09":"def clean_content(content):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    content = re.sub('\\[.*?\\]', '', content)\n    content = re.sub('https?:\/\/\\S+|www\\.\\S+', '', content)\n    content = re.sub('<.*?>+', '', content)\n    content = re.sub('[%s]' % re.escape(string.punctuation), '', content)\n    content = re.sub('\\n', '', content)\n    content = re.sub('\\w*\\d\\w*', '', content)\n    return content\ndf['content'] = df['content'].apply(lambda x: clean_content(x))\ndisplay(df)","65598b5f":"def remove_emoji(content):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', content)","3c5b0b3d":"df['content']=df['content'].apply(lambda x: remove_emoji(x))\ndisplay(df)","06afd208":"sid=SentimentIntensityAnalyzer()\nps=lambda x:sid.polarity_scores(x)\nsentiment_scores=df.content.apply(ps)\nsentiment_scores","45749887":"sentiment_df=pd.DataFrame(data=list(sentiment_scores))\ndisplay(sentiment_df)","c55511d1":"labelize=lambda x:'neutral' if x==0 else('positive' if x>0 else 'negative')\nsentiment_df['label']=sentiment_df.compound.apply(labelize)\ndisplay(sentiment_df.head(10))","bfee7c22":"display(df.head(5))\ndata=df.join(sentiment_df.label)\ndisplay(data.head(5))","b03811e5":"counts_df=data.label.value_counts().reset_index()\ndisplay(counts_df)","8267bfe9":"plt.figure(figsize=(8,5)) \nsns.barplot(x='index',y='label',data=counts_df)","409d75ee":"data_agg=data[['username','date','label']]\ndisplay(data_agg.head(5))","816f2a47":"data_agg.columns=['date','label','counts']\ndisplay(data_agg.head())","5dd2f8f1":"data_agg=data_agg.reset_index()\ndisplay(data_agg.head(5))","0c880874":"from wordcloud import WordCloud","36942a82":"cut_content = \" \".join(df.content)\nmax_words=100\nword_cloud = WordCloud(\n                    background_color='white',\n                    stopwords=set(stop_words),\n                    max_words=max_words,\n                    max_font_size=30,\n                    scale=5,\n    colormap='magma',\n                    random_state=1).generate(cut_content)\nfig = plt.figure(1, figsize=(50,50))\nplt.axis('off')\nplt.title('Word Cloud for Top '+str(max_words)+' words with # ENDSars on Twitter\\n', fontsize=100,color='blue')\nfig.subplots_adjust(top=2.3)\nplt.imshow(word_cloud)\nplt.show()","0c51b6c3":"let's streamline the needed columns","a6d8150d":"group number of counts by\n* date\n* positive,neutral,negative","ed269ec9":"Converting all tweets to lowercase","2d354ee3":"**Sentiment Analysis**","ff01c1cc":"addtional cleaning","cc8592c6":"Removing stopwords","5814b354":"put the Cleaned text in main dataframe","83fb4148":"join the two data frames","50b36233":"# **Importing the Dataset**\n","330355a4":"Removing punctuations","799d0f1f":"Getting the polarity scores for each tweet","1002cc13":"Labeling the scores based on the compound polarity value","82b169f4":"let's check the shape of the dataframe","19d82b0c":"Removing URLs from tweets","eb0e4edd":"Picking out the tweet texts","a7a50282":"Plotting the sentiment score counts"}}