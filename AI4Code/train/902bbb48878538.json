{"cell_type":{"5127b9a7":"code","e980a12c":"code","e0c081d5":"code","655b595e":"code","83721f6a":"code","73fad9d9":"code","0326d603":"code","5912bf39":"code","3d1bb237":"code","576283e7":"code","e37cbd66":"code","8e2b91d0":"markdown","ded79c8f":"markdown","5a23dd3d":"markdown","d446e7ff":"markdown","7ab2fd8f":"markdown","3abf0ae9":"markdown","ba155947":"markdown","f6776edf":"markdown","d52f9673":"markdown","6137c4ff":"markdown","48c26a5f":"markdown"},"source":{"5127b9a7":"# Install Rapids for faster SVM on GPUs\n\nimport sys\n!cp ..\/input\/rapids\/rapids.0.13.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path\n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","e980a12c":"import os\nimport h5py\nimport random\nimport numpy as np\nimport pandas as pd\nimport cudf\nimport cupy as cp\nimport warnings\nfrom cuml.neighbors import KNeighborsRegressor\nfrom cuml import SVR\nfrom cuml.linear_model import Ridge, Lasso\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import BaggingRegressor\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)\/np.sum(y_true, axis=0))","e0c081d5":"fnc_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/fnc.csv\")\nloading_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/loading.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\n\nlabels_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/train_scores.csv\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()","655b595e":"# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1\/600\n\ndf[fnc_features] *= FNC_SCALE\ntest_df[fnc_features] *= FNC_SCALE","83721f6a":"import nilearn as nl\nimport nibabel as nib\nfrom nilearn import image\nfrom nilearn import plotting\nfrom nilearn import datasets\nfrom nilearn import surface\nimport nilearn.plotting as nlplt","73fad9d9":"fmri_mask = '..\/input\/trends-assessment-prediction\/fMRI_mask.nii'","0326d603":"smri = 'ch2better.nii'\nmask_img = nl.image.load_img(fmri_mask)\n\ndef load_subject(filename, mask_img):\n    subject_data = None\n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_img = nl.image.new_img_like(mask_img, subject_data, affine=mask_img.affine, copy_header=True)\n\n    return subject_img\n\n\nfiles = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)     \n    plotting.plot_glass_brain(first_rsn,display_mode='lyrz')\n    print(\"-\"*50)","5912bf39":"motor_images = datasets.fetch_neurovault_motor_task()\nstat_img = motor_images.images[0]\nview = plotting.view_img_on_surf(stat_img, threshold='90%')\nview.open_in_browser()\nview","3d1bb237":"%%time\n\n# To suppress the \"Expected column ('F') major order, but got the opposite.\" warnings from cudf. It should be fixed properly,\n# although as the only impact is additional memory usage, I'll supress it for now.\nwarnings.filterwarnings(\"ignore\", message=\"Expected column\")\n\n# Take a copy of the main dataframe, to report on per-target scores for each model.\n# TODO Copy less to make this more efficient.\ndf_model1 = df.copy()\ndf_model2 = df.copy()\ndf_model3 = df.copy()\n\nNUM_FOLDS = 7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfeatures = loading_features + fnc_features\n\n# Blending weights between the three models are specified separately for the 5 targets. \n#                                 SVR,  Ridge, BaggingRegressor\nblend_weights = {\"age\":          [0.4,  0.55,  0.05],\n                 \"domain1_var1\": [0.55, 0.15,  0.3],\n                 \"domain1_var2\": [0.45, 0.0,   0.55],\n                 \"domain2_var1\": [0.55, 0.15,  0.3],\n                 \"domain2_var2\": [0.5,  0.05,  0.45]}\n\noverall_score = 0\nfor target, c, w in [(\"age\", 60, 0.3), (\"domain1_var1\", 12, 0.175), (\"domain1_var2\", 8, 0.175), (\"domain2_var1\", 9, 0.175), (\"domain2_var2\", 12, 0.175)]:    \n    y_oof = np.zeros(df.shape[0])\n    y_oof_model_1 = np.zeros(df.shape[0])\n    y_oof_model_2 = np.zeros(df.shape[0])\n    y_oof_model_3 = np.zeros(df.shape[0])\n    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n    \n    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n        train_df = train_df[train_df[target].notnull()]\n\n        model_1 = SVR(C=c, cache_size=3000.0)\n        model_1.fit(train_df[features].values, train_df[target].values)\n        model_2 = Ridge(alpha = 0.0001)\n        model_2.fit(train_df[features].values, train_df[target].values)\n        \n        ### The BaggingRegressor, using the Ridge regression method as a base, is added here. The BaggingRegressor\n        # is from sklearn, not RAPIDS, so dataframes need converting to Pandas.\n        model_3 = BaggingRegressor(Ridge(alpha = 0.0001), n_estimators=30, random_state=42, max_samples=0.3, max_features=0.3)\n        model_3.fit(train_df.to_pandas()[features].values, train_df.to_pandas()[target].values)\n\n        val_pred_1 = model_1.predict(val_df[features])\n        val_pred_2 = model_2.predict(val_df[features])\n        val_pred_3 = model_3.predict(val_df.to_pandas()[features])\n        val_pred_3 = cudf.from_pandas(pd.Series(val_pred_3))\n        \n        test_pred_1 = model_1.predict(test_df[features])\n        test_pred_2 = model_2.predict(test_df[features])\n        test_pred_3 = model_3.predict(test_df.to_pandas()[features])\n        test_pred_3 = cudf.from_pandas(pd.Series(test_pred_3))\n        \n        val_pred = blend_weights[target][0]*val_pred_1+blend_weights[target][1]*val_pred_2+blend_weights[target][2]*val_pred_3\n        val_pred = cp.asnumpy(val_pred.values.flatten())\n        \n        test_pred = blend_weights[target][0]*test_pred_1+blend_weights[target][1]*test_pred_2+blend_weights[target][2]*test_pred_3\n        test_pred = cp.asnumpy(test_pred.values.flatten())\n        \n        y_oof[val_ind] = val_pred\n        y_oof_model_1[val_ind] = val_pred_1\n        y_oof_model_2[val_ind] = val_pred_2\n        y_oof_model_3[val_ind] = val_pred_3\n        y_test[:, f] = test_pred\n        \n    df[\"pred_{}\".format(target)] = y_oof\n    df_model1[\"pred_{}\".format(target)] = y_oof_model_1\n    df_model2[\"pred_{}\".format(target)] = y_oof_model_2\n    df_model3[\"pred_{}\".format(target)] = y_oof_model_3\n    test_df[target] = y_test.mean(axis=1)\n    \n    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n    overall_score += w*score\n    \n    score_model1 = metric(df_model1[df_model1[target].notnull()][target].values, df_model1[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n    score_model2 = metric(df_model2[df_model2[target].notnull()][target].values, df_model2[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n    score_model3 = metric(df_model3[df_model3[target].notnull()][target].values, df_model3[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n\n    print(f\"For {target}:\")\n    print(\"SVR:\", np.round(score_model1, 6))\n    print(\"Ridge:\", np.round(score_model2, 6))\n    print(\"BaggingRegressor:\", np.round(score_model3, 6))\n    print(\"Ensemble:\", np.round(score, 6))\n    print()\n    \nprint(\"Overall score:\", np.round(overall_score, 6))","576283e7":"sub_df = cudf.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.head(10)","e37cbd66":"sub_df.to_csv(\"submission_rapids_ensemble_with_baggingregressor.csv\", index=False)","8e2b91d0":"![image.png](attachment:image.png)","ded79c8f":"# <span style='color:DarkOrange'> 3D Plots of statistical maps ","5a23dd3d":"![image.png](attachment:image.png)","d446e7ff":"# <span style='color:Red'> Thanks for reading the notebook \u2764 If you like, please Upvote \ud83d\udc95","7ab2fd8f":"# <span style=\"color:Brown\"> Introduction\n\n# <span style=\"color:Green\"> \u211d\ud835\udd38\u2119\ud835\udd40\ud835\udd3b\ud835\udd4a - \ud835\udd4b\u211d\ud835\udd56\u2115\ud835\udd3b\ud835\udd4a \u2115\ud835\udd56\ud835\udd66\ud835\udd63\ud835\udd60\ud835\udd5a\ud835\udd5e\ud835\udd52\ud835\udd58\ud835\udd5a\ud835\udd5f\ud835\udd58 \u2764\n    \n\n   \nImages of the human brain, in form and function, seem to be everywhere these days - on television, in glossy magazines, and on internet blogs worldwide. This is due, in many respects, to the incredible amount of information these images present and the sheer number of brain imaging research studies being performed to spy on the brain in action or at rest, to examine how it is built and wired, and what happens when things go wrong. Indeed, neuroimagers routinely collect more study data in a few days than was collected in over an entire year just a decade ago. These data are a rich source of information on detailed brain anatomy, the subtle variations in brain activity in response to cognitive stimuli, and complex patterns of inter-regional communication. Taken individually, these various data types would have once formed the basis for entire research programs. Now, with interests not only in multi-modal neuroimaging but the inclusion of co-occurring biological and clinical variable collection requiring linkage between geographically distributed researchers, neuroscience programs are rapidly becoming the brain-focused versions of projects more akin to those involving particle physics. The methods by which these data are obtained are themselves contributing to this growth, involving finer spatial and temporal resolution as MR physicists push the limits of what is possible and as brain scientists then rush to meet those limits. It is safe to say that human neuroimaging is now, officially, a \u201cbig data\u201d science.\n\nSuch examples of large-data, their promise and challenges, have not gone unnoticed. In the US, The National Science Foundation, the National Institutes of Health, the Defense Department, the Energy Department, Homeland Security Department as well as the U.S. Geological Survey have all made commitments toward \u201cbig data\u201d programs. The Obama Administration itself has even gotten in on the act. In response to recommendations from the President\u2019s Council of Advisors on Science and Technology, the White House sponsored a meeting bringing together a cross-agency committee to lay out specific actions agencies should take to coordinate and expand the government\u2019s investment in \u201cbig data\u201d, totaling $200 million in support (see http:\/\/www.whitehouse.gov\/sites\/default\/files\/microsites\/ostp\/big_data_fact_sheet_final.pdf). Among the examples of \u201cbig data\u201d featured at the meeting was \u2013 no surprise - human neuroimaging. Additionally, the recent anouncement of the Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative (http:\/\/nih.gov\/science\/brain\/index.htm) forms part of a new Presidential focus aimed at revolutionizing understanding of the human brain. Initiatives surrounding large-scale brain mapping are also underway in Europe (http:\/\/www.humanbrainproject.eu\/; Frisoni 2010) and examples of large-scale brain data sets have been on full display at recent annual meetings of the Organization for Human Brain Mapping (OHBM; http:\/\/www.humanbrainmapping.org) in Beijing, China in 2012 and Seattle, Washington in June 2013.\n\nHowever, as the richness of brain data sets continues to grow and the push to place it in accessible repositories mounts, there are many issues to be considered on how to handle the data, move it from place to place, how to store it, analyze it, and share it.","3abf0ae9":"# Load the data","ba155947":"## Results\n\nAfter doing an offline sweep of blending weights, the final weights show that for the best local CV, the BaggingRegressor was hardly used for the \"age\" target. However, the BaggingRegressor provided more benefits for the domain variables. In particular for \"domain1_var2\" and \"domain2_var2\" the BaggingRegressor almost completely replaces the basic Ridge regression method.\n\nIn terms of local CV, the result is almost identical to Bojan's notebook referenced above. On the leaderboard, adding the BaggingRegressor into the ensemble scores 0.1593, an improvement over Bojan's 0.1595. So the local CV to LB delta is successfully reduced, albeit by a little.\n\nI find it particularly interesting that only considering small subsets of the features, the BaggingRegressor is competitive for the domain variables but not at all for age.\n","f6776edf":"**References :**\n\n* https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3983169\/\n* https:\/\/www.kaggle.com\/aerdem4\/rapids-svm-on-trends-neuroimaging\n* https:\/\/www.kaggle.com\/aaroha33\/trends-neuroimaging-easy-notebook\n* https:\/\/www.kaggle.com\/andypenrose\/baggingregressor-rapids-ensemble\n* https:\/\/www.kaggle.com\/tunguz\/rapids-ensemble-for-trends-neuroimaging\n* https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model\n\n\n#### <span style=\"color:Green\"> Topic to know in more depth provided with Link :\n\n* Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans: [click here](https:\/\/arxiv.org\/pdf\/2001.01330)\n* Multi-Resolution 3D CNN for MRI Brain Tumor Segmentation and Survival Prediction: [click here](https:\/\/arxiv.org\/abs\/1911.08388)\n* Automatic Post-Stroke Lesion Segmentation on MR Images using 3D Residual Convolutional Neural Network: [click here](https:\/\/arxiv.org\/pdf\/1911.11209)\n* You can also check out the previuos competition occur on kaggle regard to this. [click here](https:\/\/www.kaggle.com\/c\/mlsp-2014-mri\/overview)\n* You can plot brain visualization using nilearn: [click here](https:\/\/nilearn.github.io\/plotting\/index.html)\n* Check out the various library in python for visulization of Brain MRI.[click here](https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/148175)\n* Thanks to soham for their great kernal help and giving Idea of visualization. [click here](https:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn)\n\n","d52f9673":"# <span style=\"color:DarkBlue\"> Glass brain visualization\nGlass Brain is a tool that maps the electrical activity of your brain in realtime.The anatomically realistic 3D brain will show realtime data from electroencephalographic (EEG) signals taken from a specially-designed EEG cap.This data is mapped to the source of that electrical activity, i.e. the specific part of the brain. The underlying brain model is generated through MRI scans so that the EEG data is accurately mapped to an individual's brain model.\n\nDifferent colours are given to the different signal frequency bands to create a beautiful interactive artwork that seems to crackle with energy, showing how information is transferred (or at least estimated to do so) between different regions of the brain.\n    \n#  <span style='color:Red'> Brain Image Visualization Library","6137c4ff":"# <span style ='color :#7F7D15 '> BaggingRegressor + RAPIDS Ensemble","48c26a5f":"## <span style=\"color:Blue\"> Please upvote this kernel if you like this notebook  \u2763"}}