{"cell_type":{"8619bb1a":"code","b05891f6":"code","19eb542a":"code","b31ff624":"code","712e1d5b":"code","6ddd0d35":"code","6645a993":"code","9310580f":"code","7fbd8dbe":"code","947beb4a":"code","64cae7ea":"code","c35713ff":"code","3fc471a2":"code","4af11fa8":"code","147518d6":"code","4bf0f665":"code","b366274e":"code","002a29e2":"markdown","aea7a79d":"markdown","0f526b7e":"markdown","9e24346e":"markdown","668851de":"markdown","6dd91bbe":"markdown","70646073":"markdown","39b4e110":"markdown","0ecbb0d5":"markdown","629bfe8e":"markdown","9f4c2750":"markdown"},"source":{"8619bb1a":"import warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nnp.random.seed(2022)\n\nimport seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom skimage import transform\n\nfrom tensorflow.keras import utils, models, layers, optimizers, callbacks, applications\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","b05891f6":"img_size = 32 # increase image height and width to this value\nepochs = 5","19eb542a":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\ny_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \ndel train \n\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = test.values.reshape(-1,28,28,1)\ndel test\n\nX_train = np.concatenate([X_train,X_train,X_train],axis=-1)\nX_test = np.concatenate([X_test,X_test,X_test],axis=-1)","b31ff624":"fig = plt.figure(figsize=[10,7])\ng = sns.countplot(y_train)","712e1d5b":"fig = plt.figure(figsize=[20,10])\nfor i in range(32):\n    plt.subplot(4,8,i+1)\n    plt.imshow(np.array(X_train[i]))\n    plt.title(f'Label: {y_train[i]}')\n    plt.xticks([])\n    plt.yticks([])","6ddd0d35":"def resize(imgs):\n    return transform.resize(imgs, (len(imgs), img_size, img_size, 3), preserve_range=True)\n\nX_train = resize(X_train)\nX_test = resize(X_test)\n\nX_train = X_train.astype('float32') \/ 255\nX_test  = X_test.astype('float32') \/ 255\n\ny_train = utils.to_categorical(y_train)","6645a993":"datagen = ImageDataGenerator(rotation_range=10,\n                             zoom_range = 0.1, \n                             width_shift_range=0.1,\n                             height_shift_range=0.1)\n\ndatagen.fit(X_train)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2022)","9310580f":"model = models.Sequential()\nmodel.add(applications.VGG16( weights='imagenet', include_top=False, input_shape=(img_size,img_size,3) ))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(512, activation = \"relu\"))\nmodel.add(layers.Dense(10, activation = \"softmax\"))","7fbd8dbe":"model.compile(optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), \n              loss = \"categorical_crossentropy\", \n              metrics=[\"accuracy\"])","947beb4a":"savePath = 'bestWeight.h5'\n\nlearning_rate_reduction = callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n                                                      patience=3,  \n                                                      factor=0.5, \n                                                      min_lr=0.00001)\n\ncheckpoint = callbacks.ModelCheckpoint(savePath,\n                                       monitor=\"val_loss\",\n                                       verbose=0,\n                                       save_best_only=True,\n                                       save_weights_only=True,\n                                       mode=\"auto\",\n                                       save_freq=\"epoch\",\n                                       options=None)\n\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=64),\n                              epochs = epochs, \n                              validation_data = (X_val,y_val), \n                              callbacks=[learning_rate_reduction, checkpoint],\n                              verbose = 1)","64cae7ea":"fig = plt.figure(figsize=(10,7))\nplt.subplot(211)\nplt.plot(history.history['loss'], color='b', label=\"Training loss\")\nplt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nplt.ylabel('Loss')\nplt.legend(loc='best')\n\nplt.subplot(212)\nplt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nplt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(loc='best')","c35713ff":"model.load_weights(savePath)\ny_pred = model.predict(X_val)\ny_pred = np.argmax(y_pred,axis = 1) \ny_val = np.argmax(y_val,axis = 1) \nconfusion_mtx = confusion_matrix(y_val, y_pred) \n","3fc471a2":"fig = plt.figure(figsize=[10,7])\nplt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Reds)\nplt.colorbar()\nplt.xlim(0,10)\nplt.ylim(0,10)\nplt.xlabel('True label')\nplt.ylabel('Predicted label')\nplt.show()","4af11fa8":"errors = (y_pred - y_val != 0)\n\ny_pred_errors = y_pred[errors]\ny_val_errors = y_val[errors]\nX_val_errors = X_val[errors]\n\nfig = plt.figure(figsize=[20,15])\nfor i in range(32):\n    plt.subplot(4,8,i+1)\n    \n    idx = np.random.randint(0, len(y_val_errors))\n    \n    plt.imshow(np.array(X_val_errors[idx]))\n    plt.title(f'True label: {y_val_errors[idx]}\\n Predicted label: {y_pred_errors[idx]}')\n    plt.xticks([])\n    plt.yticks([])","147518d6":"y_test = model.predict(X_test)\ny_test = np.argmax(y_test, axis=1)","4bf0f665":"fig = plt.figure(figsize=[20,15])\nfor i in range(32):\n    plt.subplot(4,8,i+1)\n    \n    idx = np.random.randint(0, len(y_test))\n    plt.imshow(np.array(X_test[idx]))\n    plt.title(f'Predicted label: {y_test[idx]}')\n    plt.xticks([])\n    plt.yticks([])","b366274e":"submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label'] = y_test\nsubmission.to_csv(\"submission.csv\",index=False)","002a29e2":"# Training","aea7a79d":"# Submission","0f526b7e":"# Validation","9e24346e":"# Data visualization","668851de":"# Prediction","6dd91bbe":"# Libraries","70646073":"# Data processing","39b4e110":"# Digit Recognizer with VGG16 \n### **Reference**: some parts of this notebook is inspired by a seminal work of [Yassine Ghouzam](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\/notebook). See also VGG16 model with augmentation using padding [here](https:\/\/www.kaggle.com\/sytuannguyen\/keras-convnets) and Keras CNN model training from scratch [here](https:\/\/www.kaggle.com\/sytuannguyen\/digit-recognizer-cnn-keras).\n### **Introduction**: some of the code in the original notebook is outdated, this notebook provides some clearnings\/updates and improvements\n### **Best practice**: do not forget to *Upvote* if you like\/copy this notebook","0ecbb0d5":"# Constants","629bfe8e":"# Data","9f4c2750":"# Model"}}