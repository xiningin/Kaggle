{"cell_type":{"3719b4c3":"code","75bad4e5":"code","0e14567e":"code","264ae211":"code","71df8f27":"code","a77898ee":"code","d0dcfe33":"code","d6df9edc":"code","01f202e4":"code","5b7fa3e7":"code","8fdb799c":"code","caa56168":"code","e8a00246":"code","345b0b87":"code","84c728df":"code","c472456b":"code","c8a4d1e2":"code","e687909a":"code","75b09de8":"code","24417765":"code","571acc33":"code","e675f2d2":"code","1a243a29":"code","7a866616":"code","72503bb2":"code","5860ee8e":"code","3646e683":"code","1325c478":"markdown","a8feb9a3":"markdown","173fe4d1":"markdown","b451b811":"markdown","05dc09dd":"markdown","dc0870d1":"markdown","2befd813":"markdown","936232b8":"markdown"},"source":{"3719b4c3":"#Allows using operating system dependent functionality\nimport os\n#Provides support for multidimensional arrays and high-level mathematical functions\nimport numpy as np\n #Provides support for data manipulation and analysis\nimport pandas as pd\n#Provides MATLAB-like plotting framework (based on numpy)\nimport matplotlib.pyplot as plt\n#Provides data visualisation interface for drawing and graphing (based on matplotlib)\nimport seaborn as sns\n#Provides a framework for fast numerical computing, machine learning and neural networks\nimport tensorflow as tf\n#Provides a random permutation cross-validator. Yields indices to split data into training and test sets\nfrom sklearn.model_selection import ShuffleSplit\n#Scales\/standartizes features by removing the mean and scaling to unit variance\nfrom sklearn.preprocessing import StandardScaler\n#Encodes labels with value between 0 and n_classes-1\nfrom sklearn.preprocessing import LabelEncoder\n#Encodes categorical integer features using a one-hot aka one-of-K scheme\nfrom sklearn.preprocessing import OneHotEncoder","75bad4e5":"#Chekcing input directory\nprint(os.listdir(\"..\/input\"))","0e14567e":"# Learning rate\nLEARNING_RATE = 0.001\n# Number of training iterations to run\nSTEPS = 25000 \n#Validation data size\nVALIDATION_SIZE = 1000 \n#Types of labels for digits 1 through 10\nLABELS = 10\n#Width\/height of the image\nDIMENSION = 28\n#Number of colors in the image (greyscale)\nCOLOUR_CHANNELS = 1\n#Batch size\nBATCH_SIZE = 100\n#Convolutional Kernel size\nCONVOLUTION_PATCH = 5\n#Number of Convolutional Kernels\nDEPTH = 32\n#Number of hidden neurons in the fully connected layer\nHIDDEN = 1024","264ae211":"#Read cvs files into pandas dataframes\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","71df8f27":"#Look at top 5 rows of train dataframe\ntrain.head()","a77898ee":"#Remove the labels as a numpy array from the dataframe\nlabels = np.array(train.pop('label'))\n#Encode labels\nlabels = LabelEncoder().fit_transform(labels)[:, None]","d0dcfe33":"#Look at encoded labels\nprint(labels.shape)\nprint('\\n')\nprint(labels[:5])","d6df9edc":"#Apply OneHot encoding\nlabels = OneHotEncoder().fit_transform(labels).todense()","01f202e4":"#Look at one hot encoded labels\nprint(labels.shape)\nprint('\\n')\nprint(labels[:5])","5b7fa3e7":"#Convert the dataframe to a numpy array\ntrain = StandardScaler().fit_transform(np.float32(train.values)) ","8fdb799c":"#Look at scaled train dataframe\nprint(train.shape)\nprint('\\n')\nprint(train[:5])","caa56168":"#Reshape the data into 42000 28x28 arrays (Number of images, height, width, colour channels)\ntrain = train.reshape(-1, DIMENSION, DIMENSION, COLOUR_CHANNELS) ","e8a00246":"#Look at reshaped train dataframe\nprint(train.shape)\nprint('\\n')\nprint(train[:1])","345b0b87":"#Split data into training and validation sets\nts_data, valids_data = train[:-VALIDATION_SIZE], train[-VALIDATION_SIZE:]\nts_labels, valids_labels = labels[:-VALIDATION_SIZE], labels[-VALIDATION_SIZE:]","84c728df":"#Initialize the input data with placeholders.\ntf_data = tf.placeholder(tf.float32, shape=(None, DIMENSION, DIMENSION, COLOUR_CHANNELS))\ntf_labels = tf.placeholder(tf.float32, shape=(None, LABELS))","c472456b":"#Initialise the biases\n#Convolutional layer 1 biases with depth of DEPTH\nb1 = tf.Variable(tf.zeros([DEPTH]))\n#Convolutional layer 2 biases (twice the depth of the first convolutional layer)\nb2 = tf.Variable(tf.constant(1.0, shape=[2 * DEPTH]))\n#Hidden\/Dense layer biases with HIDDEN of hidden nodes\nb3 = tf.Variable(tf.constant(1.0, shape=[HIDDEN]))\n#Output layer biases\nb4 = tf.Variable(tf.constant(1.0, shape=[LABELS]))\n\n#Initialise the weights with patch size of CONVOLUTION_PATCH\n#Convolutional layer 1 weights\nw1 = tf.Variable(tf.truncated_normal([CONVOLUTION_PATCH, CONVOLUTION_PATCH, COLOUR_CHANNELS, DEPTH], stddev=0.1))\n#Convolutional layer 2 weights (twice the depth of the first convolutional layer)\nw2 = tf.Variable(tf.truncated_normal([CONVOLUTION_PATCH, CONVOLUTION_PATCH, DEPTH, 2 * DEPTH], stddev=0.1))\n#Hidden\/Dense layer weights\nw3 = tf.Variable(tf.truncated_normal([DIMENSION \/\/ 4 * DIMENSION \/\/ 4 * 2 * DEPTH, HIDDEN], stddev=0.1))\n#Output layer biaweightsses\nw4 = tf.Variable(tf.truncated_normal([HIDDEN, LABELS], stddev=0.1))","c8a4d1e2":"#Assemble the layers\ndef logits(input):\n    #Convolutional layer 1\n    mnist_classifier = tf.nn.conv2d(input, w1, [1, 1, 1, 1], padding='SAME')\n    mnist_classifier = tf.nn.max_pool(mnist_classifier, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n    mnist_classifier = tf.nn.relu(mnist_classifier + b1)\n    #Convolutional layer 2\n    mnist_classifier = tf.nn.conv2d(mnist_classifier, w2, [1, 1, 1, 1], padding='SAME')\n    mnist_classifier = tf.nn.max_pool(mnist_classifier, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n    mnist_classifier = tf.nn.relu(mnist_classifier + b2)\n    #Hidden layer\n    mnist_classifier = tf.reshape(mnist_classifier, (-1, DIMENSION \/\/ 4 * DIMENSION \/\/ 4 * 2 * DEPTH))\n    mnist_classifier = tf.nn.relu(tf.matmul(mnist_classifier, w3) + b3)\n    return tf.matmul(mnist_classifier, w4) + b4\n\n#Prediction:\ntf_pred = tf.nn.softmax(logits(tf_data))","e687909a":"#Get the loss by using Categorical Cross Entropy Loss function for training the model.\ntf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits(tf_data), labels=tf_labels))\n#Get accuracy \ntf_acc = 100 * tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(tf_pred, 1), tf.argmax(tf_labels, 1))))\n\n#Set up one of the following (or other) optimisers\n\n#tf_opt = tf.train.RMSPropOptimizer(LEARNING_RATE)\ntf_opt = tf.train.AdamOptimizer(LEARNING_RATE)\n\ngrads_and_vars = tf_opt.compute_gradients(tf_loss)\ntf_step = tf_opt.minimize(tf_loss)","75b09de8":"#Open tensorflow session\ninit = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(init)","24417765":"#Initialise error log\nerror_log = [(0, 0, 10)] ","571acc33":"#Run the session\nss = ShuffleSplit(n_splits=STEPS, train_size=BATCH_SIZE)\n#Get the number of splitting iterations in the cross-validator\nss.get_n_splits(ts_data, ts_labels)\n#Go through the data for STEPS of steps\nfor step, (id, _) in enumerate(ss.split(ts_data,ts_labels), start=1):\n    #Get single image and its label at id of id and set it to fd\n    fd = {tf_data:ts_data[id], tf_labels:ts_labels[id]}\n    #Run the session for single image with the chosen optimiser\n    session.run(tf_step, feed_dict=fd)\n    #Every 500 steps do this\n    if step%1000 == 0:\n        #Get validation images and labels and assign them to fd\n        fd = {tf_data:valids_data, tf_labels:valids_labels}\n        #Get model loss and accuracy from the validation dataset\n        validation_loss, validation_accuracy = session.run([tf_loss, tf_acc], feed_dict=fd)\n        #Save model loss and accuracy at each 500 step to history\n        error_log.append((step, validation_loss, validation_accuracy))\n        #Print step and accuracy\n        print('Step %i \\t Valid. Acc. = %f'%(step, validation_accuracy), end='\\n')","e675f2d2":"#Unzip the history list into 3 tuples\nsteps, loss, accuracy = zip(*error_log)\n#Create a figure and set plot size\nfig = plt.figure(figsize=(16,6))\n#Add first subplot\nsub1 = fig.add_subplot(221)\n#Plot the data on first subplot\nsub1.plot(steps,loss, 'o-')\n#Set title for first subplot\nsub1.set_title('Validation Loss')\n#Set x label for first subplot\nsub1.set_xlabel('Steps')\n#Set y label for first subplot\nsub1.set_ylabel('Log(Loss)')\n#Add second subplot\nsub2 = fig.add_subplot(222)\n#Plot the data on second subplot\nsub2.plot(steps, accuracy, '.-')\n#Set x label for second subplot\nsub2.set_xlabel('Steps')\n#Set y label for second subplot\nsub2.set_ylabel('Accuracy')\n#Set title for second subplot\nsub2.set_title('Accuracy')\n#Make sure plots don't overlap\nplt.tight_layout()\n#Show plots\nplt.show()","1a243a29":"# Convert the test dataframe to a numpy array\ntest_data = StandardScaler().fit_transform(np.float32(test.values)) \n#Reshape test_data into 42000 28x28 matricies\ntest_data = test_data.reshape(-1, DIMENSION, DIMENSION, COLOUR_CHANNELS) ","7a866616":"#Make a prediction about the test labels\ntest_pred = session.run(tf_pred, feed_dict={tf_data:test_data})\ntest_labels = np.argmax(test_pred, axis=1)","72503bb2":"#Show the structure of the predictions\nprint(test_pred.shape)\nprint(test_labels.shape)\nprint(test_pred[:2])\nprint(test_labels[:2])","5860ee8e":"#Plotting an example\nimage = 34\nplt.axis('off')\nplt.imshow(test_data[image,:,:,0])\nplt.show()\nprint(\"Prediction: %i\"%test_labels[image])","3646e683":"#Save predictions to a dataframe\npredictions = pd.DataFrame(data={'ImageId':(np.arange(test_labels.shape[0])+1), 'Label':test_labels})\n#Write the datafram to a csv file\npredictions.to_csv('predictions2.csv', index=False)\n#Show sample of the submission dataframe\npredictions.head(5)","1325c478":"## 6. Classify Test Data","a8feb9a3":"## 3. Data Import and Preprocessing","173fe4d1":"## 7. Check and Save the Predictions","b451b811":"## 1. Import Libraries","05dc09dd":"I have created this kernel  as a reference for myself and other beginners to perform image recognition using Convolutional Neural Network using Tensorflow and Python. It contains step by step breakdown of the whole CNN classification from start to finish. The code is based on and referencing the following:\n\nhttps:\/\/www.tensorflow.org\/tutorials\/estimators\/cnn\n\nhttps:\/\/www.kaggle.com\/kakauandme\/tensorflow-deep-nn\n\nhttps:\/\/www.kaggle.com\/flaport\/tensorflow-cnn-lb-0-98929\n\nhttps:\/\/github.com\/aymericdamien\/TensorFlow-Examples\/blob\/master\/examples\/3_NeuralNetworks\/convolutional_network.py\n\nhttps:\/\/www.kaggle.com\/scolianni\/tensorflow-convolutional-neural-network-for-mnist\n\nIf you find this helpful, take a look at these sources for more information.","dc0870d1":"## 4. Build the Model","2befd813":"## 2. Settings Setup","936232b8":"## 5. Train the Model"}}