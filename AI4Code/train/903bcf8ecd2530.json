{"cell_type":{"9896cef0":"code","f80fe65a":"code","516cab06":"code","2bd5b64b":"code","0f3a3684":"code","21c9b299":"code","02dd99cb":"code","f5adafb7":"markdown","f55ec706":"markdown","4dea84a8":"markdown","d3a6e77e":"markdown","956d9e5a":"markdown","bd220b47":"markdown","68b2c407":"markdown","9408a921":"markdown"},"source":{"9896cef0":"try:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n    pass\n  \nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport numpy as np\nimport matplotlib.pyplot as plt","f80fe65a":"def map_image(image, label):\n    '''Normalizes and flattens the image. Returns image as input and label.'''\n    image = tf.cast(image, dtype=tf.float32)\n    image = image \/ 255.0\n    image = tf.reshape(image, shape=(784,))\n\n    return image, image","516cab06":"# Load the train and test sets from TFDS\n\nBATCH_SIZE = 128\nSHUFFLE_BUFFER_SIZE = 1024\n\ntrain_dataset = tfds.load('mnist', as_supervised=True, split=\"train\")\ntrain_dataset = train_dataset.map(map_image)\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\ntest_dataset = tfds.load('mnist', as_supervised=True, split=\"test\")\ntest_dataset = test_dataset.map(map_image)\ntest_dataset = test_dataset.batch(BATCH_SIZE).repeat()","2bd5b64b":"def deep_autoencoder():\n    '''Builds the encoder and decoder using Dense layers.'''\n    encoder = tf.keras.layers.Dense(units=128, activation='relu')(inputs)\n    encoder = tf.keras.layers.Dense(units=64, activation='relu')(encoder)\n    encoder = tf.keras.layers.Dense(units=32, activation='relu')(encoder)\n\n    decoder = tf.keras.layers.Dense(units=64, activation='relu')(encoder)\n    decoder = tf.keras.layers.Dense(units=128, activation='relu')(decoder)\n    decoder = tf.keras.layers.Dense(units=784, activation='sigmoid')(decoder)\n  \n    return encoder, decoder\n\n# set the input tensor\ninputs =  tf.keras.layers.Input(shape=(784,))\n\n# get the encoder and decoder output\ndeep_encoder_output, deep_autoencoder_output = deep_autoencoder()\n\n# setup the encoder because you will visualize its output later\ndeep_encoder_model = tf.keras.Model(inputs=inputs, outputs=deep_encoder_output)\n\n# setup the autoencoder\ndeep_autoencoder_model = tf.keras.Model(inputs=inputs, outputs=deep_autoencoder_output)","0f3a3684":"train_steps = 60000 \/\/ BATCH_SIZE\n\ndeep_autoencoder_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\ndeep_auto_history = deep_autoencoder_model.fit(train_dataset, steps_per_epoch=train_steps, epochs=50)","21c9b299":"def display_one_row(disp_images, offset, shape=(28, 28)):\n    '''Display sample outputs in one row.'''\n    for idx, test_image in enumerate(disp_images):\n        plt.subplot(3, 10, offset + idx + 1)\n        plt.xticks([])\n        plt.yticks([])\n        test_image = np.reshape(test_image, shape)\n        plt.imshow(test_image, cmap='gray')\n\n\ndef display_results(disp_input_images, disp_encoded, disp_predicted, enc_shape=(8,4)):\n    '''Displays the input, encoded, and decoded output values.'''\n    plt.figure(figsize=(15, 5))\n    display_one_row(disp_input_images, 0, shape=(28,28,))\n    display_one_row(disp_encoded, 10, shape=enc_shape)\n    display_one_row(disp_predicted, 20, shape=(28,28,))","02dd99cb":"# take 1 batch of the dataset\ntest_dataset = test_dataset.take(1)\n\n# take the input images and put them in a list\noutput_samples = []\nfor input_image, image in tfds.as_numpy(test_dataset):\n      output_samples = input_image\n\n# pick 10 random numbers to be used as indices to the list above\nidxs = np.random.choice(BATCH_SIZE, size=10)\n\n# get the encoder output\nencoded_predicted = deep_encoder_model.predict(test_dataset)\n\n# get a prediction for the test batch\ndeep_predicted = deep_autoencoder_model.predict(test_dataset)\n\n# display the 10 samples, encodings and decoded values!\ndisplay_results(output_samples[idxs], encoded_predicted[idxs], deep_predicted[idxs])","f5adafb7":"## Display sample results\n\nSee the results using the model you just trained.","f55ec706":"## Build the Model","4dea84a8":"## Compile and Train the Model","d3a6e77e":"## Prepare the Dataset","956d9e5a":"You will prepare the MNIST dataset just like in the previous lab.","bd220b47":"# MNIST Deep Autoencoder\n\nWill extend the shallow autoencoder built in the previous exercise. The model here will have a deeper network so it can handle more complex images.","68b2c407":"As mentioned, you will have a deeper network for the autoencoder. Compare the layers here with that of the shallow network you built in the previous lab.","9408a921":"## Imports"}}