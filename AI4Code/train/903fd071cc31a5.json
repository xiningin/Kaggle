{"cell_type":{"25039680":"code","f7fb26bb":"code","2f7736db":"code","55e350be":"code","b277f9da":"code","71c156ba":"code","8732fe22":"code","7750cb52":"code","9581e5f1":"code","3be9ac13":"code","d2e21a67":"code","1f91d51e":"code","ed8e7a3b":"code","1ea567e3":"code","eaeeed0c":"code","8918a82c":"code","3ec19ba9":"code","3d6e7c29":"code","bf44af66":"code","fc8b1882":"code","ddf29278":"code","913eb649":"code","2922fef9":"code","6f79f0b2":"code","158fb529":"code","13e89d63":"code","e81df63e":"code","3adb52f2":"code","3f666c28":"code","a17d5710":"code","672d4d66":"code","0fb4d4c4":"code","06615e56":"code","3f419411":"code","855d0a5e":"code","9dc5d644":"code","c3bde9ba":"code","50d98576":"code","fbbeba89":"code","3d8b46d9":"code","f4610e0f":"code","d5b4ada2":"code","f9892524":"code","d26a3b15":"code","1a25ca8b":"code","b58778b2":"code","95b07820":"code","85d50a57":"code","9510ee49":"markdown","5a6f3290":"markdown","26085bec":"markdown","94b0b646":"markdown","8817fc32":"markdown","ce703471":"markdown","7627add0":"markdown","f367d6a7":"markdown","beeb2910":"markdown","83e48c13":"markdown","3cdf88a5":"markdown","83210c5e":"markdown","c7c265a6":"markdown"},"source":{"25039680":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7fb26bb":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)","2f7736db":"df = pd.read_csv(r\"\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv\")","55e350be":"df.head(2)","b277f9da":"df.drop(['car_ID', 'CarName'], 1, inplace=True)","71c156ba":"df.shape","8732fe22":"df.head()","7750cb52":"df.info()","9581e5f1":"df.doornumber.value_counts()","3be9ac13":"df.loc[:, 'doornumber'] = df.loc[:, 'doornumber'].map({'four':4, 'two':2})","d2e21a67":"df.head()","1f91d51e":"df.cylindernumber.value_counts()","ed8e7a3b":"df.loc[:, 'cylindernumber'] = df.loc[:, 'cylindernumber'].map({'four':4, 'six':6, 'five':5, 'twelve':12, 'eight':8, 'three':3, 'two':2})","1ea567e3":"df.head(2)","eaeeed0c":"df.info()","8918a82c":"df.fueltype.value_counts()","3ec19ba9":"df.aspiration.value_counts()","3d6e7c29":"df.enginetype.value_counts()","bf44af66":"df.drivewheel.value_counts()","fc8b1882":"df.enginelocation.value_counts()","ddf29278":"df.enginetype.value_counts()","913eb649":"df.fuelsystem.value_counts()","2922fef9":"catg_cols = df.select_dtypes(include='object')","6f79f0b2":"catg_cols","158fb529":"from sklearn.preprocessing import LabelEncoder     ### way much more elegant than get_dummies <3\n\nle = LabelEncoder()\n\nfor col in catg_cols:\n    df.loc[:, col] = le.fit_transform(df.loc[:, col])","13e89d63":"df.head()","e81df63e":"df.fuelsystem.value_counts()   \n# previously these were strings\/ categorical columns                                \n                                # mpfi    1bbl\n                                # idi     bbl    \n                                # spdi    bbl    \n                                # spfi    \n                                # mfi ","3adb52f2":"df.enginetype.value_counts()","3f666c28":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr = df.corr()\n\nplt.figure(figsize=(20,15))\nsns.heatmap(corr, annot=True, cmap='RdYlGn')","a17d5710":"df.drop(['symboling', 'doornumber', 'carbody', 'enginetype', 'stroke', 'compressionratio', 'peakrpm'], 1, inplace=True)","672d4d66":"df.isnull().sum()","0fb4d4c4":"data = df.drop('price', 1)\ntargets = df['price']\n\n# 50 percent of 205 = 102\ntrain_data = data.iloc[:102] ############# 0 based so end at 143 @!%$#&^$&!@$\ntrain_targets = targets.iloc[:102]\n\n# 20 percent of 205 = 41\nvalidation_data = data.iloc[102: 143]\nvalidation_targets = targets.iloc[102: 143]\n\n# 30 percent for test\n# 205 - 143 = 62\ntest_data = data.iloc[143:]\ntest_targets = targets.iloc[143:]\n\n# cross checking\nprint('Data, Targets', end='\\n\\n')\nprint('TRAIN')\nprint(train_data.shape)\nprint(train_targets.shape)\nprint('#'*15)\n\nprint('VALIDATION')\nprint(validation_data.shape)\nprint(validation_targets.shape)\nprint('#'*15)\n\nprint('TEST')\nprint(test_data.shape)\nprint(test_targets.shape)","06615e56":"print(train_data.isnull().sum())\nprint('-'*25)\nprint(validation_data.isnull().sum())\nprint('-'*25)\nprint(test_data.isnull().sum())\nprint('-'*25)","3f419411":"df.shape","855d0a5e":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data \/= std\n\nvalidation_data-=mean\nvalidation_data \/= std\n\ntest_data-=mean\ntest_data \/= std","9dc5d644":"print(train_data.shape)\nprint(validation_data.shape)\nprint(test_data.shape)","c3bde9ba":"print(train_data.isnull().sum())\nprint('-'*25)\nprint(validation_data.isnull().sum())\nprint('-'*25)\nprint(test_data.isnull().sum())\nprint('-'*25)","50d98576":"df.enginelocation.value_counts() # 0 occurs 202 times, 1 occurs 3 time --- Im imputing the nans with 0s","fbbeba89":"train_data = train_data.fillna(0)\n\nvalidation_data = validation_data.fillna(0)\n\ntest_data = test_data.fillna(0)","3d8b46d9":"print(train_data.isnull().sum())\nprint('-'*25)\nprint(validation_data.isnull().sum())\nprint('-'*25)\nprint(test_data.isnull().sum())\nprint('-'*25)","f4610e0f":"print(train_targets.isnull().sum())\nprint('-'*25)\nprint(validation_targets.isnull().sum())\nprint('-'*25)\nprint(test_targets.isnull().sum())\nprint('-'*25)","d5b4ada2":"# train_data.drop('enginelocation', 1, inplace=True)\nvalidation_data.drop('enginelocation', 1, inplace=True)\ntest_data.drop('enginelocation', 1, inplace=True)","f9892524":"print(train_data.shape)\nprint(validation_data.shape)\nprint(test_data.shape)","d26a3b15":"# BUILDING BASE LINE MODEL\nfrom keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(10, activation='relu', input_shape=(train_data.shape[1],)))\n\nmodel.add(layers.Dense(8, activation='relu'))\n\nmodel.add(layers.Dense(6, activation='relu'))\n\nmodel.add(layers.Dense(1))","1a25ca8b":"# COMPILING\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])","b58778b2":"# FITTING\nhistory = model.fit(train_data, train_targets, epochs=500, batch_size=32, validation_data=(validation_data, validation_targets))","95b07820":"\nfrom keras import layers\nfrom keras import models\nfrom keras import regularizers\n\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],), kernel_regularizer=regularizers.l2(0.002)))\n\nmodel.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n\nmodel.add(layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n\nmodel.add(layers.Dense(1))\n\n\n# COMPILING\nmodel.compile(optimizer='adam', loss='mse', metrics=['mae'])\n\n# FITTING\nhistory = model.fit(train_data, train_targets, epochs=250, batch_size=32, validation_data= (validation_data, validation_targets))","85d50a57":"import matplotlib.pyplot as plt\nloss = history.history['mae']\nval_loss = history.history['val_mae']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label='Training mae')\nplt.plot(epochs, val_loss, 'b', label='Validation mae')\nplt.title('Training and validation mae')\nplt.xlabel('Epochs')\nplt.ylabel('MAE')\nplt.legend()\nplt.show()","9510ee49":"### splitting data","5a6f3290":"### dropping columns having no correaltion with price","26085bec":"sanity check","94b0b646":"#### ^ found the culprint","8817fc32":"### a quick look tells that doornumber and cylindernumber can be changed to numerical data","ce703471":"## one hot encoding","7627add0":"https:\/\/stackoverflow.com\/questions\/37232782\/nan-loss-when-training-regression-network","f367d6a7":"### IMPORTANT - looking for missing values","beeb2910":"### exploring each object column","83e48c13":"### Normalization","3cdf88a5":"## still nan values in validation","83210c5e":"### Changing Architecture","c7c265a6":"##### new day new problems - never saw nan before"}}