{"cell_type":{"7363bdda":"code","0a0a9a8d":"code","aef18ad2":"code","7b7ca505":"code","87901b58":"code","7e834a62":"code","42c8d6af":"code","a9da5865":"code","833f6b49":"code","8ff238d7":"code","8c96fa44":"code","392b82ef":"code","6da863ca":"code","f8246efc":"code","fac0010a":"code","04cea31c":"code","789089c7":"code","87b80315":"code","e8b27382":"code","b5dc0841":"code","21736bea":"code","ab6fc9e5":"code","a9d906f4":"code","4576d92b":"code","e9e6d1d2":"code","05dd628f":"code","4b29b147":"code","a2eb9ba1":"code","2c943647":"code","16286a40":"code","1bb82c2c":"code","44193997":"code","885b67bc":"code","5625a505":"code","2dbaebf8":"code","df587955":"code","ece55a9d":"code","6936c257":"code","f4fe39a3":"code","708691bc":"code","11c7974b":"code","86bea571":"code","4c65283d":"code","5af04128":"code","33ac37d2":"code","bd99a5ef":"code","59489c3e":"code","0ee0372a":"code","aa2e3d2c":"code","a50a4469":"code","b64fa066":"code","af82633d":"code","7e3730b5":"code","9194ee54":"code","40a9bca7":"code","ce9712c0":"code","bd4bb5c5":"code","f38fbf4d":"code","f013bf15":"code","ab71d787":"code","0605480c":"code","db486ad0":"code","b7764694":"code","bc91ffad":"code","306e458d":"code","1a58a533":"code","fc439e2c":"code","b83137d2":"code","c64c2810":"code","d58cd384":"code","3e5a29af":"code","5b476832":"code","541c00af":"code","e4ba9e15":"code","a8a1b659":"code","066288d3":"code","20c9dfeb":"code","3fce022b":"code","7900b6b7":"code","80f5fd05":"code","18767043":"code","4b2fef6e":"code","b6b1621f":"code","ce310aa1":"code","03db766e":"code","c4d84d99":"code","4a74a621":"code","324aa6db":"code","afc9f353":"code","2789ed33":"code","2c0cbdbb":"code","16104ce3":"code","5509fdb5":"code","385feb56":"code","a1fd8b84":"code","a04f5988":"code","691f1f63":"code","7df2f67d":"code","c1566e97":"code","0f15ca23":"code","9d28354b":"code","ada98242":"code","c45e4f81":"code","54d7923b":"code","f42b724d":"code","1daf2c5c":"code","42bb181a":"code","1433c5ae":"code","e42749ce":"code","28125551":"code","43c8ee24":"code","8b054202":"code","1916307c":"code","07299e82":"code","5e90bedb":"code","201cba84":"code","744b6816":"code","6bb588cd":"code","685513f2":"code","f560eebf":"code","91969479":"code","29107e99":"code","74b70333":"markdown","99f213fb":"markdown","32690c4f":"markdown","fe7d188e":"markdown","6f745f6b":"markdown","8e5bee2b":"markdown","1a9704f8":"markdown","b5236f03":"markdown","a9cc220c":"markdown","0e082cf4":"markdown","f1a8eeda":"markdown","c281a6eb":"markdown","1be283fb":"markdown","ae24dfe3":"markdown","937f1a5b":"markdown","9d1e1870":"markdown","2a0827ce":"markdown","eacfc8cf":"markdown","f16eed41":"markdown","3d289029":"markdown","306aecf5":"markdown","7cb32893":"markdown","b3154e88":"markdown","ad96452e":"markdown","a889a5d5":"markdown","6f999d13":"markdown","689ffc1a":"markdown","768d9e9a":"markdown","520aafbb":"markdown","831e5665":"markdown","aeb25ac3":"markdown","11a50820":"markdown","43ef6556":"markdown","3c5ce27c":"markdown","10cb3186":"markdown","b41a2767":"markdown","a46841a2":"markdown","5dd54178":"markdown","179789e5":"markdown","05e0b43f":"markdown","768baa0b":"markdown","bf3e5e85":"markdown","d09f8cb0":"markdown","b2e92121":"markdown","cddb8800":"markdown","9e9816aa":"markdown","6fab8e9b":"markdown","680fd1fa":"markdown"},"source":{"7363bdda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a0a9a8d":"my_filepath = \"..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\"","aef18ad2":"my_data = pd.read_csv(my_filepath, index_col=\"sl_no\")","7b7ca505":"my_data.head()","87901b58":"my_data.shape","7e834a62":"my_data.info","42c8d6af":"my_data.describe()","a9da5865":"my_data.describe(include=object)","833f6b49":"my_data.isna().sum()","8ff238d7":"my_data[\"salary\"]=my_data[\"salary\"].fillna(0)","8c96fa44":"my_data.columns","392b82ef":"print(my_data.status.value_counts(),\"\\n\",\nmy_data.status.value_counts(normalize=True))","6da863ca":"\nmy_data.status.value_counts().plot.bar(title='Count of employed and unemployed candidates')","f8246efc":"plt.figure(1) \nplt.subplot(131)\nmy_data.gender.value_counts().plot.bar(figsize=(10,8), title=\"Gender\")\nplt.subplot(132)\nmy_data.ssc_b.value_counts().plot.bar(figsize=(10,8),title=\"S S Board of Education\")\nplt.subplot(133)\nmy_data.hsc_b.value_counts().plot.bar(figsize=(10,8), title =\"Higher School Board of Education\")\nplt.show()\n","fac0010a":"plt.figure() \nmy_data.hsc_s.value_counts().plot.bar(figsize=(8,6), title=\"Count of students per Specialization in Higher Secondary\")\nplt.show()","04cea31c":"my_data.degree_t.value_counts().plot.bar(figsize=(8,6),title=\"Count of students per UnderGrad Degree type\")","789089c7":"my_data.workex.value_counts().plot.bar(figsize=(8,6), title =\"Count of students per Work experience\")","87b80315":"my_data.specialisation.value_counts().plot.bar(figsize=(8,6), title =\"Count of students per Post Graduation(MBA)- Specialization\")","e8b27382":"plt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Distribution of Secondary School Performance\")\nsns.distplot(a=my_data.ssc_p,kde=False)\nplt.xlabel(\"Secondary School Exam Percentage scored\")\nplt.ylabel(\"Number of candidates \")\nplt.subplot(142)\nsns.boxplot(x=my_data.ssc_p)\nplt.subplot(143)\nsns.boxplot(x=my_data.status, y=my_data.ssc_p)\nplt.subplot(144)\nsns.swarmplot(x=my_data.status, y=my_data.ssc_p)\nplt.show()","b5dc0841":"\nplt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Distribution of High School Performance\")\nsns.distplot(a=my_data.hsc_p,kde=False)\nplt.xlabel(\"High School Exam Percentage scored\")\nplt.ylabel(\"Number of candidates \")\nplt.subplot(142)\nsns.boxplot(x=my_data.hsc_p)\nplt.subplot(143)\nsns.boxplot(x=my_data.status, y=my_data.hsc_p)\nplt.subplot(144)\nsns.swarmplot(x=my_data.status, y=my_data.hsc_p)\nplt.show()","21736bea":"plt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Distribution of UnderGrad Performance\")\nsns.distplot(a=my_data.degree_p,kde=False)\nplt.xlabel(\"UnderGrad Exam Percentage scored\")\nplt.ylabel(\"Number of candidates\")\nplt.subplot(142)\nsns.boxplot(x=my_data.degree_p)\nplt.subplot(143)\nsns.boxplot(x=my_data.status, y=my_data.degree_p)\nplt.subplot(144)\nsns.swarmplot(x=my_data.status, y=my_data.degree_p)\nplt.show()","ab6fc9e5":"plt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Employability test percentage (conducted by college)\")\nsns.distplot(a=my_data.etest_p,kde=False)\nplt.xlabel(\"Employability Exam score\")\nplt.ylabel(\"Number of candidates\")\nplt.subplot(142)\nsns.boxplot(x=my_data.etest_p)\nplt.subplot(143)\nsns.boxplot(x=my_data.status, y=my_data.etest_p)\nplt.subplot(144)\nsns.swarmplot(x=my_data.status, y=my_data.etest_p)\nplt.show()","a9d906f4":"plt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Distribution of MBA percentage\")\nsns.distplot(a=my_data.mba_p,kde=False)\nplt.subplot(142)\nsns.boxplot(x=my_data.mba_p)\nplt.subplot(143)\nplt.title(\"Distribution of MBA percentage per placement status\")\nsns.boxplot(x=my_data.status, y=my_data.mba_p)\nplt.subplot(144)\nsns.swarmplot(x=my_data.status, y=my_data.mba_p)\nplt.show()","4576d92b":"plt.figure(figsize=(16,6))\nplt.subplot(141)\nplt.title(\"Distribution of salary\")\nsns.distplot(a=my_data.salary,kde=False)\nplt.subplot(142)\nsns.boxplot(x=my_data.salary)\nplt.subplot(143)\nplt.title(\"Distribution of salary per placement status\")\nsns.boxplot(x=my_data.gender, y=my_data.salary)\nplt.subplot(144)\nsns.swarmplot(x=my_data.gender, y=my_data.salary)\n\nplt.show()","e9e6d1d2":"Gender=pd.crosstab(my_data['gender'],my_data['status']) \nGender.div(Gender.sum(1), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\nssbe = pd.crosstab(my_data.ssc_b,my_data.status)\nssbe.div(ssbe.sum(1), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\nhsbe = pd.crosstab(my_data.hsc_b,my_data.status)\nhsbe.div(hsbe.sum(1), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n","05dd628f":"ssbe = pd.crosstab(my_data.ssc_b,my_data.status)\nssbe.div(ssbe.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","4b29b147":"hscs = pd.crosstab(my_data.hsc_s,my_data.status)\nhscs.div(hscs.sum(1),axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\ndegreeT = pd.crosstab(my_data.degree_t,my_data.status)\ndegreeT.div(degreeT.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\nworkX = pd.crosstab(my_data.workex,my_data.status)\nworkX.div(workX.sum(1), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\nspecialty = pd.crosstab(my_data.specialisation, my_data.status)\nspecialty.div(specialty.sum(1), axis=0).plot(kind=\"bar\", stacked=\"True\", figsize=(4,4))","a2eb9ba1":"mycorr = my_data[['ssc_p','hsc_p','degree_p','etest_p','mba_p','salary']].corr()\nsns.heatmap(mycorr,annot=True)","2c943647":"sns.lmplot(x=\"degree_p\", y=\"mba_p\", hue=\"status\", data=my_data)","16286a40":"sns.lmplot(x=\"ssc_p\", y=\"hsc_p\", hue=\"status\", data=my_data)","1bb82c2c":"sns.lmplot(x=\"etest_p\", y=\"mba_p\", hue=\"status\", data=my_data)","44193997":"sns.lmplot(x=\"mba_p\", y=\"salary\", hue=\"specialisation\", data=my_data)","885b67bc":"#Separating the the independent variable(X) and the target variable(y) from the dataset\nX = my_data.drop('status',axis=1)\ny = my_data.status","5625a505":"#OneHotEncoding will be deployed to change encode categorical variables with more than two unique items\ndegreedummy = pd.get_dummies(X.degree_t)\nhscsdummy = pd.get_dummies(X.hsc_s)","2dbaebf8":"X = pd.concat([X, degreedummy], axis=1)\nX = pd.concat([X, hscsdummy], axis=1)","df587955":"# drop original column of onehotencoded columns from X\nX.drop(\"degree_t\", axis = 1, inplace=True)\nX.drop(\"hsc_s\", axis = 1, inplace=True)\n\n#Droping Salary since unemployed candidates automatically have 0 salary\nX.drop(\"salary\", axis = 1, inplace=True)","ece55a9d":"#LabelEncoder will be deployed to encode variables with two unique items\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nX['gender'] = le.fit_transform(X.gender)\nX['ssc_b'] = le.fit_transform(X.ssc_b)\nX['hsc_b'] = le.fit_transform(X.hsc_b)\nX['workex'] = le.fit_transform(X.workex)\nX['specialisation'] = le.fit_transform(X.specialisation)\ny = le.fit_transform(y)","6936c257":"#Split data for training & validation\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state = 1,stratify=y)","f4fe39a3":"#Standardizing the data to ensure all distributions are normal and also suppress outliers\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","708691bc":"X.tail()","11c7974b":"X.shape, y.shape","86bea571":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","4c65283d":"#Decision Tree\n\n\ndmodel = DecisionTreeClassifier()\n\ndmodel.fit(X_train,y_train)\n\ny_train_predx = dmodel.predict(X_train)\n\ny_test_predx = dmodel.predict(X_test)","5af04128":"accuracy_score(y_train_predx,y_train)","33ac37d2":"accuracy_score(y_test_predx,y_test)","bd99a5ef":"print(classification_report(y_test,y_test_predx))","59489c3e":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predx))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predx),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","0ee0372a":"importances=pd.Series(dmodel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","aa2e3d2c":"#Random Forest\nrtmodel=RandomForestClassifier()\n\nrtmodel.fit(X_train,y_train)\ny_train_predr = rtmodel.predict(X_train)\ny_test_predr = rtmodel.predict(X_test)","a50a4469":"accuracy_score(y_train_predr,y_train)","b64fa066":"accuracy_score(y_test_predr,y_test)","af82633d":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predr))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predr),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","7e3730b5":"print(classification_report(y_test,y_test_predr))","9194ee54":"importances=pd.Series(rtmodel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","40a9bca7":"#Boost for random forest\n\nfrom sklearn.model_selection import GridSearchCV","ce9712c0":"# Provide range for max_depth from 1 to 20 with an interval of 2 and from 1 to 200 with an interval of 20 for n_estimators \nparamgrid = {'max_depth': list(range(1, 20, 2)), 'n_estimators': list(range(1, 200, 20))}\ngrid_search=GridSearchCV(RandomForestClassifier(random_state=1),paramgrid)","bd4bb5c5":"# Fit the grid search model \ngrid_search.fit(X_train,y_train)","f38fbf4d":"# Estimating the optimized value \ngrid_search.best_estimator_","f013bf15":"RFCmodel = RandomForestClassifier(max_depth=3, n_estimators=141, random_state=1)\nRFCmodel.fit(X_train,y_train)\ny_train_predrfc = RFCmodel.predict(X_train)\ny_test_predrfc = RFCmodel.predict(X_test)","ab71d787":"accuracy_score(y_train_predrfc,y_train)","0605480c":"accuracy_score(y_test_predrfc,y_test)","db486ad0":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predrfc))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predrfc),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","b7764694":"print(classification_report(y_test,y_test_predrfc))","bc91ffad":"importances=pd.Series(RFCmodel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","306e458d":"#pip install xgboost","1a58a533":"from xgboost import XGBClassifier","fc439e2c":"# fit model no training data\nXGmodel = XGBClassifier()\nXGmodel.fit(X_train, y_train)\ny_train_predXG = XGmodel.predict(X_train)\ny_test_predXG = XGmodel.predict(X_test)","b83137d2":"accuracy_score(y_train_predXG,y_train)","c64c2810":"accuracy_score(y_test_predXG,y_test)","d58cd384":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predXG))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predXG),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","3e5a29af":"print(classification_report(y_test,y_test_predXG))","5b476832":"importances=pd.Series(XGmodel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","541c00af":"parameters = {\n    'max_depth': range (2, 10, 1),\n    'n_estimators': range(60, 220, 40),\n    'learning_rate': [0.1, 0.01, 0.05]\n}","e4ba9e15":"estimator = XGBClassifier(\n    objective= 'binary:logistic',\n    nthread=4,\n    seed=42\n)","a8a1b659":"grid_search = GridSearchCV(\n    estimator=estimator,\n    param_grid=parameters,\n    scoring = 'roc_auc',\n    n_jobs = 10,\n    cv = 10,\n    verbose=True\n)","066288d3":"# Fit the grid search model \ngrid_search.fit(X_train,y_train)","20c9dfeb":"# Estimating the optimized value \ngrid_search.best_estimator_","3fce022b":"XGmodel2 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=5,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=180, n_jobs=4, nthread=4, num_parallel_tree=1,\n              random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              seed=42, subsample=1, tree_method='exact', validate_parameters=1,\n              verbosity=None)\nXGmodel2.fit(X_train,y_train)\ny_train_predXG2 = XGmodel2.predict(X_train)\ny_test_predXG2 = XGmodel2.predict(X_test)","7900b6b7":"accuracy_score(y_train_predXG2,y_train)","80f5fd05":"accuracy_score(y_test_predXG2,y_test)","18767043":"\nprint(confusion_matrix(y_test,y_test_predXG2))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predXG2),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","4b2fef6e":"print(classification_report(y_test,y_test_predXG2))","b6b1621f":"importances=pd.Series(XGmodel2.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","ce310aa1":"from lightgbm import LGBMClassifier","03db766e":"# fit the model on the whole dataset\nLGmodel = LGBMClassifier()\nLGmodel.fit(X_train, y_train)\ny_train_predL = LGmodel.predict(X_train)\ny_test_predL = LGmodel.predict(X_test)","c4d84d99":"accuracy_score(y_train_predL,y_train)","4a74a621":"accuracy_score(y_test_predL,y_test)","324aa6db":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predL))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predL),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","afc9f353":"print(classification_report(y_test,y_test_predL))","2789ed33":"importances=pd.Series(LGmodel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","2c0cbdbb":"#pip install catboost","16104ce3":"from catboost import CatBoostClassifier","5509fdb5":"CatModel = CatBoostClassifier()\nCatModel.fit(X_train,y_train)\ny_train_predCat = CatModel.predict(X_train)\ny_test_predCat = CatModel.predict(X_test)","385feb56":"accuracy_score(y_train_predCat,y_train)","a1fd8b84":"accuracy_score(y_test_predCat,y_test)","a04f5988":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_predCat))\n\nsns.heatmap(confusion_matrix(y_test,y_test_predCat),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","691f1f63":"print(classification_report(y_test,y_test_predCat))","7df2f67d":"importances=pd.Series(CatModel.feature_importances_, index=X.columns) \nimportances.plot(kind='barh', figsize=(8,6))","c1566e97":"from sklearn.ensemble import VotingClassifier","0f15ca23":"eclf = VotingClassifier(estimators=[('dt', dmodel), ('rf1', rtmodel), ('rf2', RFCmodel),('cat', CatModel), ('lgb', LGmodel),('xgb', XGmodel),('xgb2', XGmodel2)], voting='soft', weights=[1, 1, 1, 1, 1, 1, 1])\neclf.fit(X_train, y_train)\n","9d28354b":"y_train_pred_ens= eclf.predict(X_train)","ada98242":"y_test_pred_ens= eclf.predict(X_test)","c45e4f81":"accuracy_score(y_train_pred_ens,y_train)","54d7923b":"accuracy_score(y_test_pred_ens,y_test)","f42b724d":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_pred_ens))\n\nsns.heatmap(confusion_matrix(y_test,y_test_pred_ens),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","1daf2c5c":"print(classification_report(y_test,y_test_pred_ens))","42bb181a":"eclf2 = VotingClassifier(estimators=[('dt', dmodel), ('rf1', rtmodel), ('rf2', RFCmodel),('cat', CatModel), ('lgb', LGmodel),('xgb', XGmodel),('xgb2', XGmodel2)], voting='hard', weights=[1, 1, 1, 1, 1, 1, 1])\neclf2.fit(X_train, y_train)","1433c5ae":"y_train_pred_ens2 = eclf2.predict(X_train)","e42749ce":"y_test_pred_ens2 = eclf2.predict(X_test)","28125551":"accuracy_score(y_train_pred_ens2,y_train)","43c8ee24":"accuracy_score(y_test_pred_ens2,y_test)","8b054202":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,y_test_pred_ens2))\n\nsns.heatmap(confusion_matrix(y_test,y_test_pred_ens2),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","1916307c":"print(classification_report(y_test,y_test_pred_ens2))","07299e82":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.constraints import max_norm","5e90bedb":"model = Sequential()\n# input layer\nmodel.add(Dense(16,  activation='relu'))\nmodel.add(Dropout(0.2))\n\n# hidden layer\nmodel.add(Dense(39, activation='relu'))\nmodel.add(Dropout(0.2))\n\n# hidden layer\nmodel.add(Dense(19, activation='relu'))\nmodel.add(Dropout(0.2))\n\n# output layer\nmodel.add(Dense(units=1,activation='sigmoid'))\n\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam')","201cba84":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)","744b6816":"model.fit(x=X_train, \n          y=y_train, \n          epochs=500,\n          batch_size=100,\n          #validation_data=(X_test, y_test),\n          validation_split=0.2,\n          callbacks=[early_stop]\n          )","6bb588cd":"#from tensorflow.keras.models import load_model\n#model.save('project_model.h5')  ","685513f2":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","f560eebf":"predictions = model.predict_classes(X_test)","91969479":"#confusion matrix: Idea for a yes\/no predictions\nprint(confusion_matrix(y_test,predictions))\n\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True,lw =2,cbar=False)\nplt.ylabel(\"True Values\")\nplt.xlabel(\"Predicted Values\")\nplt.title(\"CONFUSSION MATRIX VISUALIZATION\")\nplt.show()","29107e99":"print(classification_report(y_test,predictions))","74b70333":"# Correlation Amongst numeric features","99f213fb":"***LIGHTGBM***","32690c4f":"# **MACHINE LEARNING**","fe7d188e":"# CONCLUSION","6f745f6b":"* The number of males employed are higher than that of the females\n* Cadidates that attend the institutions managed by the central body are less employed as compare to the others","8e5bee2b":"* This model made classifications with 82% accuracy.\n* 81% precision & recall, 82%\n* Secondary school percentage influence the decisions most.\n* The model correctly predicted 40 candidates as employed,it correctly predicted  13 candidates as unemployed. 5 candidates were wrongly predicted as employed and 7 candidates were wrongly predicted as unemployed","1a9704f8":"* Ensemblement learning(soft voting) produced a recall of 85%. Thus out of all positive classes, 85% was predicted correctly.\n* Precision was 84%, of all positve classes predicted correctly, 84% were actually positive.\n* 41 candidates were correctly predicted as employed, 4 were wrongly predicted as unemployed.\n* 14 candidates where were correctly predicted as unemployed while 6 were unemployed but model predicted them as employed.\n* The model made predictions with 85% accuracy across both classes.","b5236f03":"* A fairly normal distribution of cadidate secondary school exam score.\n* Most of the candidates performed well.\n* Majority of the candidates scored between 60 -70%\n* Candidates that scored below 49 happen to be unemployed.\n* Students that scored around 80 and above got hired.\n* There are students who scored fairly good grades but are unemployed.","a9cc220c":"**ENSEMBLEMENT LEARNING**","0e082cf4":"* 1. We see that there majority of the candidates are employed.","f1a8eeda":"Checking the number of candidates corresponding to the various categories  (categorical variables) below:","c281a6eb":"**GridSearchCV** is deployed to retrieve the most optimum parameters for the random tree regression model","1be283fb":"Non numeric value in salary is replaced with 0 since these persons are not placed","ae24dfe3":"* Most of the cadidates had no prior work experience","937f1a5b":"* Most of the students scored between 57% - 66%. \n* Students that did not land jobs did not perform terribly in their graduate studies.","9d1e1870":"There is a poor relationship between the MBA percentage score and employability test percentage.","2a0827ce":"* Most of the students that studied arts in high school are the least employed\n* Students that specialised in either Comm&Mgt or Sci&Tech are mostly employed.\n* Most of the cadidates with work experience had job placements.\n* Candidates that specialised in Marketing & Finance hard more job placements than those that studied Marketing & Human Resource.","eacfc8cf":"We have to change categorical data to numerical for the consumption of the models. This will be done by encoding the the categorical features","f16eed41":"**Implementing Classification models**","3d289029":"* Gender does not inflence your chances of getting hired.\n* Academic grades play a massive role in your chances of getting hired. Very high grades increases your chances of getting hired.\n* Candidates that specialised in Marketing and Finance relatively gain higher salaries than their counterparts in Marketing and Human Resource.\n* Employability test performance do not enhance your chances of getting hired.","306aecf5":"# DATA PROCESSING FOR CLASSIFICATION","7cb32893":"Below is the relationship between the employability status and the individual categories****","b3154e88":"Candidates that had high percentage in secondary school had high grades in higher school and are employed whereas those that had low grades in secondary school had low grades in higher school and are not employed","ad96452e":"* Candidates that specialized in Mk&Fin gain higher salaries than those in Mk&HR","a889a5d5":"* Most of the Candidates studied Comm&Mgmt in their undergraduate studies.\n","6f999d13":"* Most of the students performed well in their undergraduate studies.\n* Students that scored below 55% percent are not hired while those that scored very high grades are hired.\n* There is a good number of candidates that performed well but could not land jobs.","689ffc1a":"* The model correctly predicted 35 candidates as employed and 13 as unemployed. It made a combined 17(thus 10+7) wrong predictions.\n* Secondary percentage,MBA grade ,higher school percentage influence the model's decision most.\n* A precision of 79% and recall of 80%","768d9e9a":"***XGBoost***","520aafbb":"* Majority of students studied Commerce in Higher Secondary School.","831e5665":"* The model's prediction is 85% similar to the actual values.\n* There were 42 true positives (correctly predicted as employed), 13 true negatives(correctly predicted as negative),7 type 1 errors or false positives (wrongly predicted as employed) and 3 type 2 errors (wrongly predicted as umeployed).\n* The model had 84% precision and 85% recall.","aeb25ac3":"* Most of the students scored between 60% and 70% in High school\n* Students that scored below 50% are not hired.\n* Students that score very high marks are employed, however, there student(s) that score as high as 80% or more but are not hired.","11a50820":"* Ensemblement learning(hard voting) produced a recall of 82%. Thus out of all positive classes, 82% was predicted correctly.\n* Precision was 81%, of all positve classes predicted correctly, 81% were actually positive.\n* 40 candidates were correctly predicted as employed, 7 were wrongly predicted as unemployed.\n* 13 candidates where were correctly predicted as unemployed while 5 were unemployed but model predicted them as employed.\n* The model made predictions with 82% accuracy across both classes.","43ef6556":"* The model predicted 40 candidates correctly as employed and 5 employed candidates wrongly as unemployed.\n* 14 candidates were predicted correctly as unemployed and 6 unemployed candidates were predicted wrongly as unemployed.\n* Predictions were made with 83% recall.\n* High school performance had the most vital effect in decision making.","3c5ce27c":"Candidates with very high degree percentage had very high MBA percentage and they have job placement. Candidates with very low degree percentage, usually had a very low or low MBA percentage and are not placed. \nHowever, there are unmeployed candidates who had high degree percentage and high MBA score percentage. There is a positive correlation between degree score and MBA percentage for both employed and unemployed cadidates, but correlation between degree score and MBA percentage for employed candidates is stronger than unemployed candidates. ","10cb3186":"***Catboost***","b41a2767":"***DecisionTreeClassifier***","a46841a2":"* The prefared choice of post graduate studies amongst most of the students is Marketing and Finance","5dd54178":"* The model recorded 82% accuracy.\n* There was 82% precision and 82% recall.\n* Secondary school performance influenced the model's decion the most.\n* 41 true positives(correctly predicted as employed), 12 true negatives(correctly predicted as unemployed), 8 false positives(type 1 error)(wrongly predicted unemployed candidate as employed) and 4 false negatives (type 2 error)(wrongly predicted employed candidate as unemployed).","179789e5":"* XGBoost model provided an accuracy score of 88%\n* 88% precision and 88% recall\n* Correctly predicted 40 candidates as employed, 14 correctedly predicted as unemployed and 11 wrong predictions.","05e0b43f":"**Hyperparameter tuning of XGBoost with Grid Search**","768baa0b":"# Data Analysis And Machine Learning using Campus Placement Dataset","bf3e5e85":"        * Exploratory Data Analysis\n        * Predicting whether student gets hired or not \n        * Determining factors that influence placement\n        * Determining factors influencing salary of recruits.        ","d09f8cb0":"* The professional test does not influence the possibility of being employed much, because students that are unemployed did not perform poorly.","b2e92121":"* Most of the candidates are males.\n","cddb8800":"***RandomForestClassifier***","9e9816aa":"* The lightGBM model delivered an accuracy rate of 78%.\n* 78% Recall and 78% precision scores.\n* Secondary school percentage, High School percentage, MBA percentage and degree score, greatly influenced the    model's decisions.\n* Correctly predicted 38 candidates as employed, 13 correctedly predicted as unemployed and 14 wrong predictions.\n","6fab8e9b":"**TASK:** To predict whether a candidate got hired or not","680fd1fa":"* This is distribution is skew to the right.\n* The presence of outliers is due to the fact that few of the candidates receive very huge salaries.\n* Males receive higher salaries than females."}}