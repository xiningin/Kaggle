{"cell_type":{"f07199f9":"code","270745a4":"code","a2b2cdb1":"code","60b9cede":"code","d350854d":"code","17d19852":"code","8db45241":"code","1581c0b8":"code","7946c8bb":"code","d9a80a83":"code","410babd1":"code","4b3086e7":"code","31a99de6":"code","7d18da8a":"markdown","a3728017":"markdown","dd18bea3":"markdown","e52b8fd3":"markdown","b6ed1ce5":"markdown","44f2f246":"markdown","fdc6fd10":"markdown","b845029e":"markdown"},"source":{"f07199f9":"import pandas as pd\nimport numpy as np\nimport math\nimport datetime as dt\nimport sys, time\nfrom datetime import datetime\nfrom tqdm import tqdm_notebook\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nimport copy\nimport random","270745a4":"#function of delta_days = date1 - date2\ndef delta_days(date1, date2):\n    d1=dt.datetime.strptime(date1[:19], '%Y-%m-%d %H:%M:%S')\n    d2=dt.datetime.strptime(date2[:19], '%Y-%m-%d %H:%M:%S')\n    return (d1-d2).days+(d1-d2).seconds\/(3600*24)","a2b2cdb1":"#function of days_to_now\ndef days_to_now(date):\n    d1=dt.datetime.now()\n    d2=dt.datetime.strptime(date[:19], '%Y-%m-%d %H:%M:%S')\n    return (d1-d2).days+(d1-d2).seconds\/(3600*24)","60b9cede":"#Tokenizing function\nstopWords = set(stopwords.words('english'))\nstopWords |= set([\"n't\",\"'m\",\"'re\",\"'ve\",\"'s\",\".\", \"|\", '\uff0b', \"^\", \"=\"])\ndef get_word_list(text):\n    text_tokenized = [wt[0].lower() for wt in nltk.pos_tag(nltk.word_tokenize(text)) \\\n                      if ('NN'  in wt[1]) or ('JJ'  in wt[1]) or ('RB'  in wt[1]) or ('VB'  in wt[1])]\n    return [w for w in text_tokenized if w not in stopWords if w!='+']","d350854d":"#Function of getting tag list from text\ndef get_tag_list(text):\n    tag_name = []\n    wl=word_tokenize(text)\n    for i,w in enumerate(wl):\n        if ('#' in w) and (i != len(wl)-1) and (len(w)>0):\n            if len(wl[i+1])>1:\n                tag_name.append(wl[i+1].lower())\n    return tag_name","17d19852":"#jaccard similarity\ndef get_jac_sim(content1,content2):\n    a=set(content1)\n    b=set(content2)\n    if len(a.union(b))==0:\n        return 0\n    else:\n        return len(a.intersection(b))\/len(a.union(b))","8db45241":"#Reading and data preprocessing\ndef processing_data():\n    \n    #Update files\n    print('---  1\/10',\"\\r\", end=\"\")\n    answer_scores = pd.read_csv('..\/input\/answer_scores.csv')\n    answers = pd.read_csv('..\/input\/answers.csv')\n    comments = pd.read_csv('..\/input\/comments.csv')\n    professionals = pd.read_csv('..\/input\/professionals.csv')\n    question_scores = pd.read_csv('..\/input\/question_scores.csv')\n    questions = pd.read_csv('..\/input\/questions.csv')\n\n    #Copy three files for data processing\n    print('---  2\/10',\"\\r\", end=\"\")\n    answers_copy=copy.copy(answers)\n    questions_copy=copy.copy(questions)\n    professionals_copy=copy.copy(professionals)\n\n    #Add 'score' column from answer_scores to answers_copy\n    print(\"---  3\/10\",\"\\r\", end=\"\")\n    answers_copy['score']=0\n    answers_arr=answers_copy.values\n    answer_s_arr=answer_scores.values\n    for i in range(len(answers_arr)):\n        search_arr=np.any(answer_s_arr==answers_arr[i,0], axis=1)\n        if any(search_arr)==True:\n            answers_arr[i,5]=answer_s_arr[search_arr,1][0]\n    answers_copy=pd.DataFrame(answers_arr, index=answers_copy.index, columns=answers_copy.columns)\n\n    #Add 'score' column from question_scores to questions_copy\n    print(\"---  4\/10\",\"\\r\", end=\"\")\n    questions_copy['score']=0\n    questions_arr=questions_copy.values\n    question_s_arr=question_scores.values\n    for i in range(len(questions_arr)):\n        searchq_arr=np.any(question_s_arr==questions_arr[i,0], axis=1)\n        if any(searchq_arr)==True:\n            questions_arr[i,5]=question_s_arr[searchq_arr,1][0]\n    questions_copy=pd.DataFrame(questions_arr, index=questions_copy.index, columns=questions_copy.columns)\n\n    #Calculate response days from question to the answer, and add it to answers_copy\n    print(\"---  5\/10\",\"\\r\", end=\"\")\n    for i in answers.index:\n        answers_copy.loc[i,'Response_day']=delta_days(answers_copy.loc[i,'answers_date_added'],\n            questions_copy[questions_copy['questions_id']==answers_copy.loc[i,'answers_question_id']].iloc[0]['questions_date_added'])\n\n    #Tokenize from questions_title and questions_body to questions_words\n    print(\"---  6\/10\",\"\\r\", end=\"\")\n    questions_copy['questions_words']=[get_word_list(x) for x in (questions_copy['questions_body'] +\n                                                                  ' ' + questions_copy['questions_title'])]\n\n    #Get tags from questions_body to questions_body_tags\n    print(\"---  7\/10\",\"\\r\", end=\"\")\n    questions_copy['questions_body_tags']=[get_tag_list(x) for x in questions_copy['questions_body']]\n\n    #Merge (professionals_location,) professionals_industry and professionals_headline to ind_head\n    print(\"---  8\/10\",\"\\r\", end=\"\")\n    professionals_copy = professionals_copy.fillna('')\n    professionals_copy['ind_head'] = ''\n    for x in professionals_copy.index:\n        professionals_copy.at[x,'ind_head'] = set(get_word_list(professionals_copy.loc[x,'professionals_industry'])) | \\\n                set(get_word_list(professionals_copy.loc[x,'professionals_headline'])) \n\n    # Join ind_head to ind_head_sp with space for high-speed search \n    print(\"---  9\/10\",\"\\r\", end=\"\")\n    professionals_copy['ind_head_sp']=[\" \".join(x) for x in professionals_copy['ind_head']]\n\n    # Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n    print(\"--- 10\/10\",\"\\r\", end=\"\")\n    professionals_copy['professionals_date_joined_dt']=[dt.datetime.strptime(professionals_copy.loc[x,'professionals_date_joined'][:19],\n                                                                        '%Y-%m-%d %H:%M:%S') for x in professionals_copy.index]\n    print(\"Finished \",\"\\r\")\n    return answers_copy, questions_copy, professionals_copy, comments","1581c0b8":"%time answers_copy, questions_copy, professionals_copy, comments = processing_data()\n# it takes about 12minuts by PC(i7\/8GB)","7946c8bb":"def select_author(input_question, number_of_authors, sample_num, tag_coef, expiration_date, \n                  reseponse_time_limit, thank_coef, rand_coef):\n    \n    # calucurate questions_similarity in the case of type(input_question)==int: existing question on the data\n    print('---  1\/6',\"\\r\", end=\"\")\n    if type(input_question)==int:\n        if input_question in questions_copy['questions_words']:\n            questions_copy['questions_similarity'] = [(get_jac_sim(questions_copy['questions_words'][input_question],\n                            questions_copy['questions_words'][i]) + get_jac_sim(questions_copy['questions_body_tags'][input_question],\n                            questions_copy['questions_body_tags'][i])*tag_coef)* (math.log10(questions_copy['score'][i]+1)+1)\n                            * (1 - delta_days(questions_copy['questions_date_added'][input_question],\n                            questions_copy['questions_date_added'][i])\/expiration_date) for i in questions_copy.index]\n            if questions_copy.loc[input_question,'questions_id'] in answers_copy['answers_question_id'].values:\n                old_item=1\n            else:\n                old_item=0\n        else:\n            print('Err: No applicable questions.index')\n            sys.exit()\n\n    # calucurate questions_similarity in the case of type(input_question)==str: new question\n    elif type(input_question)==str:\n        word_list = get_word_list(input_question)\n        tag_list = get_tag_list(input_question)\n        questions_copy['questions_similarity'] = [(get_jac_sim(word_list, questions_copy['questions_words'][i]) \\\n                            + get_jac_sim(tag_list, questions_copy['questions_body_tags'][i])*tag_coef) \\\n                            * (math.log10(questions_copy['score'][i]+1)+1) * (1 - days_to_now(questions_copy['questions_date_added'][i]) \\\n                            \/expiration_date) for i in questions_copy.index]\n        old_item=0\n    else:\n        print('Err: type error')\n        sys.exit()\n        \n    #select questions similar to input\n    print('---  2\/6',\"\\r\", end=\"\")\n    questions_selected = questions_copy.sort_values('questions_similarity', ascending=False).iloc[old_item:sample_num+old_item,:]\n    \n    #select answers of the selected questions\n    print('---  3\/6',\"\\r\", end=\"\")\n    answers_selected=pd.DataFrame()\n    for i in questions_selected.index:        \n        for j in answers_copy[answers_copy['answers_question_id']==questions_selected['questions_id'].loc[i]].index:\n            answers_selected= answers_selected.append(answers_copy.loc[j,['answers_id','answers_question_id',\n                                                                     'answers_author_id', 'answers_date_added','Response_day','score']])\n            answers_selected.loc[j,'questions_similarity']= questions_selected.loc[i,'questions_similarity']\n            #Count 'thank' from the comments of each answer. \n            answers_selected.loc[j,'thank']=int(any(comments[(comments['comments_parent_content_id']==\n                                                              answers_selected.loc[j, 'answers_id'])]['comments_body'].str.contains('Thank|thank|thk|thnk')))\n    if len(answers_selected)==0:\n        print(\"Err: No similar answers, use larger 'sample_num'\")\n        sys.exit()            \n    #Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and thank\n    print('---  4\/6',\"\\r\", end=\"\")\n    author_selected = answers_selected.groupby('answers_author_id').agg({'answers_id':'count', 'score':'mean', \n                                                                         'Response_day':'mean', 'questions_similarity': 'mean', 'thank': 'mean'})\n    author_selected.columns=['answer_count', 'score_mean', 'respose_day_mean', 'similarity_mean', 'thank_mean']\n    author_selected['score_mean'] = [math.log10(author_selected.loc[x,'score_mean']+1)+1 for x in author_selected.index]\n    author_selected['author_priority'] = (1+author_selected['thank_mean']*thank_coef)*author_selected['similarity_mean']\\\n                * author_selected['answer_count']*(1-author_selected['respose_day_mean']\/reseponse_time_limit)\\\n                * author_selected['score_mean']\n    author_selected=author_selected[author_selected['author_priority']>0]\n    author_selected['ind_head']=''\n    for x in author_selected.index:\n        if any(professionals_copy['professionals_id']==x):\n            author_selected.at[x, 'ind_head']=[professionals_copy[professionals_copy['professionals_id']==x]['ind_head'].values[0]]\n\n    #Collect words from the selected authors and aggregate the author_priority.\n    print('---  5\/6',\"\\r\", end=\"\")\n    word_set=set()\n    for i in author_selected.index:\n        if author_selected.loc[i, 'ind_head'] != '':\n            word_set|=author_selected.loc[i, 'ind_head'][0]\n\n    word_dict = dict(zip(word_set,np.zeros(len(word_set))))\n    for i in author_selected.index:\n         if author_selected.loc[i, 'ind_head'] != '':\n                for j in author_selected.loc[i, 'ind_head'][0]:\n                    word_dict[j] = word_dict[j]+author_selected.loc[i, 'author_priority']\n\n    word_dict = {k: v for k, v in word_dict.items() if v != 0.0}\n\n    #Calculate professionals_priority by word_dict.\n    print('---  5\/6',\"\\r\", end=\"\")\n    professionals_copy['professionals_priority']=0.0\n    for k, v in word_dict.items():\n        professionals_copy.loc[professionals_copy['ind_head_sp'].str.contains(k),'professionals_priority']+=v\n    professionals_priority_max=professionals_copy['professionals_priority'].max()\n    #Set higher 'author_priority' for 'author_selected'\n    for i in author_selected.index:\n        professionals_copy.loc[(professionals_copy['professionals_id']==i),'professionals_priority']+= \\\n                author_selected.loc[i, 'author_priority']+professionals_priority_max\n    \n    #Sort professionals by the priority\n    print('---  6\/6',\"\\r\", end=\"\")\n    random.seed(dt.datetime.now().microsecond)\n    professionals_sorted = copy.copy(professionals_copy.sort_values(['professionals_priority','professionals_date_joined_dt'],\n                                                        ascending=[False, False]))\n    professionals_sorted['rank']=[i+1 for i in range(professionals_sorted.shape[0])]\n    selected_professionals = pd.DataFrame()    \n    # and select recommendation of professionals due to 'rand_coef'\n    if (rand_coef>=0) and (rand_coef<=1):\n        for i in range(number_of_authors):\n            ii = int((1-random.random()**(rand_coef))*professionals_sorted.shape[0])\n            selected_professionals = selected_professionals.append(professionals_sorted.iloc[ii,:])\n            professionals_sorted=professionals_sorted.drop(index=professionals_sorted.index[ii])\n        selected_professionals['rank']=selected_professionals['rank'].astype('int64')\n    else:\n        print(\"Err: Input 0. to 1. for 'rand_coef'\")\n        sys.exit()\n    \n    print(\"Finished \",\"\\r\")\n    return selected_professionals.drop(['ind_head', 'ind_head_sp', 'professionals_date_joined_dt','professionals_priority'], axis=1)","d9a80a83":"#parameters\nparams = {\n        'number_of_authors': 10,# Number of authors to select\n        'sample_num': 10, # Number of sample questions to compare similarity, the biggest factor of the processing time.\n        'tag_coef': 2, # Priority coefficient of Tag in calculating questions similarity\n        'expiration_date': 1000, # Similar questions prioritize newer ones within 'expiration_date'\n        'reseponse_time_limit': 30, # Similar answer prioritize faster response to the answer within in 30 days \n        'thank_coef': 1, # Priority coefficient of the number of \"thank\" included in the comment of the answer\n        'rand_coef': 0.} # Random coefficient of 0. to 1., 0.[default]: select from high order, 1.: 100% random","410babd1":"input_question_title=\"Is it hard to find a job in graphic design?\"\ninput_question_body=\"I'd like to know how hard it is to find a job straight out of school  #graphic-design #graphics\"\n\ninput_question=input_question_title+' '+input_question_body\n%time select_authors = select_author(input_question, **params)\nselect_authors","4b3086e7":"input_question=123\n%time select_authors = select_author(input_question, **params)\nselect_authors","31a99de6":"params['rand_coef']=0.0005\ninput_question=123\n%time select_authors = select_author(input_question, **params)\nselect_authors","7d18da8a":"The second method is a method of specifying the index of Framedata of \"questions\" by integer.","a3728017":"Two input methods are prepared.\nThe first method is to input title and body directly by str.","dd18bea3":"In the case of 'rand_coef' = 0.0005.\n    It can be used against cold start issue.","e52b8fd3":"Select author","b6ed1ce5":"Functions","44f2f246":"Reading and Data processing","fdc6fd10":"### This code was created for submission to Data Science for Good: CareerVillage.org\nHere are the codes for the following two processes:\n\n1, The first process is data reading, copying, tokenizing, etc. The execution time is about 10 minutes on the PC, and is executed when updating data.\n Processing items and flows are as followings.\n- Read csv data\n- Copy \"answers\", \"questions\", \"professionals\" for data processing and addition\n- Add 'score' column from answer_scores to answers_copy\n- Add 'score' column from question_scores to questions_copy\n- Calculate response days from question to the answer, and add it to answers_copy\n- Tokenize from questions_title and questions_body to questions_words\n- Get tags from questions_body to questions_body_tags\n- Merge professionals_industry and professionals_headline, and tokenize them to 'ind_head'.\n- Join ind_head to ind_head_sp with space, for high-speed search\n- Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n\n2, The second process actually enters a question and selects authors for the answer. \n  Processing items and flows are as follows, and it takes about 6 seconds by PC(i7\/8GB)\n- Two input methods are prepared.\n        (1)The first method is to input title and body directly by str.\n        (2)The second is a method of specifying the index of Framedata of \"questions\" by integer.\n- The hyper parameters are below.\n        'number_of_authors': Number of authors to select. default[10]\n        'sample_num': Number of questions to compare similarity, larger number takes processing time. default[10]\n        'tag_coef': Priority coefficient of tag for body words in calculating questions similarity. default[2]\n        'expiration_date': Similar questions prioritize newer ones within 'expiration_date'.  default[1000]\n        'reseponse_time_limit': Similar answer prioritize faster response to the answer within 'reseponse_time_limit'.  default[30] \n        'thank_coef':  Priority coefficient of the number of \"thank\" included in the comment of the answer. default[1]\n        'rand_coef': Random coefficient of 0. to 1., 0.[default]: select from rank high, 1.: 100% random.  default[0] 'rand_coef' can add fluctuation to the selection  \t\t\t\t\t \n- Calucurate questions_copy['questions_similarity'] to input question by Jaccard similarity.\n        questions_similarity = (jaccard_index(word)+jaccard_index(tag)*tag_coef)*(log(score+1)+1)*(1-delta_day\/expiration_date)\n- Choose 'questions_selected' of quantity of 'sample_num'\n- Select answers of the 'questions_selected'\n- Count 'thank' from the comments of each answer.\n- Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and number of \"thank\".      \n        author_selected['author_priority'] = (1 + author_selected['thank_mean'] * thank_coef) * author_selected['similarity_mean'] * author_selected['answer_count'] * (1 - author_selected['respose_day_mean'] \/ reseponse_time_limit) * author_selected['score_mean']\n- Collect words from the selected authors and aggregate the author_priority to each words.\n- Calculate professionals_priority for all of professionals by words' priority.\n- Set higher 'author_priority' for 'author_selected'\n- Sort professionals by the priority and select recommendation of professionals due to 'rand_coef'\n        select.index = int((1-random.random()**rand_coef)*professionals_sorted.shape[0])","b845029e":"Loading Libraries"}}