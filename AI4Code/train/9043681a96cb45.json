{"cell_type":{"1d7d80b2":"code","6e9835c9":"code","353156d4":"code","740a684f":"code","397ca57d":"code","8ef587e3":"code","78fa5cae":"code","8a2d4ebe":"code","4f0a0a41":"code","db38894b":"code","4ee0416a":"code","296fc78e":"code","aa06229a":"code","e0990cba":"code","0d4911a3":"code","b950a93a":"code","54671b27":"code","e3ac1a55":"code","63eaf104":"code","50d6c4df":"code","ee73ef62":"code","1897db46":"code","3fd73dab":"code","0bc60dc4":"code","3fd575d5":"code","55feed10":"code","d90d6a1d":"code","b43be7d1":"code","84cf540f":"code","9b82d677":"code","73cc55e1":"code","51a99d94":"code","5173262c":"code","e2fe3291":"code","f378ab57":"markdown","0ee18b57":"markdown","f8b7ed1a":"markdown","4eded70c":"markdown","0837dde1":"markdown","8a974449":"markdown","9501af58":"markdown","62da7a83":"markdown","3eee1f10":"markdown","74e065ef":"markdown","acc54497":"markdown","d4818bd1":"markdown","c8cda9fa":"markdown"},"source":{"1d7d80b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set_theme(color_codes=True)\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score, r2_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e9835c9":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\ndf_holidays = pd.read_csv('..\/input\/public-and-unofficial-holidays-nor-fin-swe-201519\/holidays.csv') #HOLIDAYS CALENDAR AVAILABLE HERE https:\/\/www.kaggle.com\/vpallares\/public-and-unofficial-holidays-nor-fin-swe-201519\ndf_oecd = pd.read_csv('..\/input\/oecd-data-fin-nor-swe-20152019\/oecd_monthly_data.csv') #ECONOMICS DATASET AVAILABLE HERE https:\/\/www.kaggle.com\/siukeitin\/oecd-data-fin-nor-swe-20152019\ndf_gdp = pd.read_csv('..\/input\/consumer-price-index-20152019-nordic-countries\/Best_CPI.csv')  #GDP DATASET https:\/\/www.kaggle.com\/sardorabdirayimov\/consumer-price-index-20152019-nordic-countries\n\n#DATAFRAMES USED IN PREVIOUS VERSIONS, DIDN'T WORK WELL FOR THI PROJECT\n#CHECK OUT ONE OF THE PREVIOUS VERSIONS FOR AN EXAMPLE OF STOCHASTIC REGRESSION WITH THE AMAZON DATAFRAME\n#df_macro_comp = pd.read_csv('..\/input\/macroeconomic-composite-finland-norway-sweden\/macro_economic_idx.csv') #MACRO-ECONOMICS COMPOSITE DATASET https:\/\/www.kaggle.com\/lucamassaron\/macroeconomic-composite-finland-norway-sweden\n#df_amazon = pd.read_csv('..\/input\/amazon-surge-for-tps-jan-2022\/Amazon search.csv') #AMAZON SEARCHES https:\/\/www.kaggle.com\/anirudhyadav9784\/amazon-surge-for-tps-jan-2022","353156d4":"df_train.isnull().sum() #there are no null values, so we don't have to clean the df","740a684f":"def set_date_features(df):\n    df['date'] = pd.to_datetime(df['date'])          \n    df['day_of_week']=df['date'].dt.dayofweek       \n    df['day_of_month']=df['date'].dt.day            \n    df['weekend']=(df['day_of_week']\/\/5 == 1)       \n    df['weekend']=df['weekend'].astype('int')       \n    df['week']=df['date'].dt.isocalendar().week     \n    df['week'][df['week']>52]=52                    \n    df['week']=df['week'].astype('int')             \n    df['month']=df['date'].dt.month                 \n    df['quarter']=df['date'].dt.quarter             \n    df['year']=df['date'].dt.year    \n    return df","397ca57d":"df_train = set_date_features(df_train)\ndf_test = set_date_features(df_test)","8ef587e3":"df_holidays['date'] = pd.to_datetime(df_holidays['date'])   ","78fa5cae":"def holiday_fe(row):    \n    df = df_holidays[(df_holidays['date'] == row['date']) & (df_holidays['country'] == row['country'])]\n    if len(df) > 0:\n        retval = df.iloc[0]['event']\n    else:\n        retval = 'None'\n    \n    #THIS FIXES A PROBLEM WITH THE HOLIDAY DATASET, IN 2019 THE NEW YEAR'S EVE IS MISSING!\n    if (retval == 'None') & (row['month'] == 12) & (row['day_of_month'] == 31):\n        retval = \"New Year's Eve\"\n        \n    return retval ","8a2d4ebe":"df_train['Holiday'] = df_train.apply(lambda row: holiday_fe(row), axis = 1)\ndf_test['Holiday'] = df_test.apply(lambda row: holiday_fe(row), axis = 1)","4f0a0a41":"df_oecd['year'] = df_oecd['date'].apply(lambda date: int(date.split('-')[0]))\ndf_oecd['month'] = df_oecd['date'].apply(lambda date: int(date.split('-')[1]))","db38894b":"df_oecd.drop('CCI', axis = 1, inplace = True) #THIS VALUES IS MISSING FOR NORWAY, WE DROP IT","4ee0416a":"def oecd_fe(df):\n    df_tmp = pd.merge(left=df, right=df_oecd, how='left', on=['year','month','country'])\n    df_tmp = df_tmp.drop('date_y', axis=1)\n    df_tmp.rename(columns={'date_x':'date'}, inplace=True)\n    return df_tmp","296fc78e":"df_train = oecd_fe(df_train)\ndf_test = oecd_fe(df_test)","aa06229a":"df_train = df_train.merge(df_gdp[['year','country','GDP']], how='left', on=['year','country'])\ndf_test = df_test.merge(df_gdp[['year','country','GDP']], how='left', on=['year','country'])","e0990cba":"g = sns.FacetGrid(df_train, \n                  col_wrap=2,\n                  col=\"year\", \n                  hue='country',\n                  height=5,\n                  aspect=1,\n                  sharex=True, \n                  xlim=(1, 12))\ng.map_dataframe(sns.lineplot, 'month', 'num_sold')\ng.add_legend()","0d4911a3":"#Removing unnecessary features\ndf_train = df_train.drop('date', axis = 1)\ndf_test = df_test.drop('date', axis = 1)","b950a93a":"def set_dummies(df):\n    dummies = pd.get_dummies(df[['country', 'store', 'product','Holiday']])\n    df = df.drop(columns=['country', 'store', 'product','Holiday'])\n    df = pd.concat([df,dummies],axis=1)\n    return df","54671b27":"df_train = set_dummies(df_train)\ndf_test = set_dummies(df_test)","e3ac1a55":"#WE HAVE TO DROP THE FEATURE 'Holiday_Fourth Sunday of Advent', THERE'S NO DATE FOR THE 2019\nnp.setdiff1d(df_train.columns,df_test.columns) ","63eaf104":"df_train.drop(columns='Holiday_Fourth Sunday of Advent', inplace=True)","50d6c4df":"X = df_train.drop('num_sold',axis=1).values\ny = df_train['num_sold'].values\nX_for_real_test = df_test.values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)","ee73ef62":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nX_for_real_test = scaler.transform(X_for_real_test)","1897db46":"X_train.shape","3fd73dab":"X_test.shape","0bc60dc4":"model = Sequential()\n\n# input layer - IT SHOULD ALWAYS HAVE THE SAME NUMBER OF NEURONS OF OUR FEATURES\nmodel.add(Dense(66,  activation='relu'))\n\n# hidden layer\nmodel.add(Dense(32, activation='relu'))\n\n# hidden layer\nmodel.add(Dense(16, activation='relu'))\n\n# hidden layer\nmodel.add(Dense(8, activation='relu'))\n\n# hidden layer\nmodel.add(Dense(4, activation='relu'))\n\n# hidden layer\nmodel.add(Dense(2, activation='relu'))\n\n# output layer\nmodel.add(Dense(units=1,activation='relu'))\n\noptimizer = Adam(learning_rate = 0.001)\n\n# Compile model\nmodel.compile(optimizer=optimizer,loss='mean_squared_error')\n\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)","3fd575d5":"model.fit(x=X_train,\n          y=y_train,\n          validation_data=(X_test,y_test),\n          epochs=100,\n          batch_size=32,\n          verbose = 1,\n          callbacks=[early_stop])","55feed10":"pd.DataFrame(model.history.history).plot()","d90d6a1d":"predictions = model.predict(X_test)\npredictions = np.squeeze(predictions)","b43be7d1":"mean_absolute_error(y_test,predictions)","84cf540f":"np.sqrt(mean_squared_error(y_test,predictions))","9b82d677":"explained_variance_score(y_test,predictions)","73cc55e1":"r2_score(y_test,predictions)","51a99d94":"def smape(a, f):\n    return 1\/len(a) * np.sum(2 * np.abs(f-a) \/ (np.abs(a) + np.abs(f))*100)","5173262c":"smape(y_test,predictions)","e2fe3291":"predictions = model.predict(X_for_real_test)\npredictions = np.squeeze(predictions)\noutput = pd.DataFrame({'row_id': df_test['row_id'],\n                       'num_sold': predictions})\n\noutput.to_csv('submission.csv', index=False)","f378ab57":"### GOAL\n\nCreate a model that will predict the num_sold for the given new data\n\n\n### Overview\n\nDue to the nature of the dataset, we'll probably want to preprocessing the features and then do some EDA to find the correlation. After that I'll implement the model with a small Neural Network using Keras.","0ee18b57":"Holidays","f8b7ed1a":"GDP","4eded70c":"### Scaling\n\nBefore creating the module, I'll scale the data fitting only the training ones, in order to prevent data leakage","0837dde1":"### Splitting","8a974449":"### Modelling","9501af58":"### Dummy Variables\n\nNext up, let's create dummy variables for country, store, product and Holiday","62da7a83":"### Feature Engineering\n\nThe date field is not so useful for training the model. I'll break it up to year and month, just to have an idea about the time period.","3eee1f10":"# Tabular Playground Jan 2022","74e065ef":"Train and Test Dates","acc54497":"OECD","d4818bd1":"### Model Evaluation","c8cda9fa":"### Simple EDA\n\nLet's plot out the num_sold based on the date"}}