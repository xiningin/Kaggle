{"cell_type":{"7e729cb2":"code","30db5d15":"code","ee52fa9e":"code","8806e03d":"code","00148353":"code","bea3c9ac":"code","29aac989":"code","a39159c9":"code","aebd88b8":"code","2d3fbe94":"code","8fcf7a49":"code","fb03f92f":"code","af6a9b2b":"code","d411e5fa":"code","b90e2875":"code","3dd38152":"code","5262882a":"code","f31b2d4c":"code","ba53f2bc":"markdown"},"source":{"7e729cb2":"# ALL imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style; style.use('ggplot')\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score","30db5d15":"# Create dataframes train and test\ntrain = pd.read_csv('..\/input\/drugsComTrain_raw.csv')\ntest = pd.read_csv('..\/input\/drugsComTest_raw.csv')","ee52fa9e":"\"\"\"\nNotes on CountVectorizer hyperparameters:\n- binary=True: all nonzero counts set to 1 (rather than integer counts)\n- stop_words=stopwords.words('english'): removes words like 'a', 'the', 'be', etc.\n- lowercase=True: all text lowercase\n- min_df=3: ignore terms that appear in less than 3 documents\n- max_df=0.9: ignore terms that appear in more than 90% of the documents\n- max_features=5000: feature vector size is 5000\n\"\"\"\n\n# Get review text\nreviews = np.vstack((train.review.values.reshape(-1, 1), \n                     test.review.values.reshape(-1, 1)))\n\n# Set up function to vectorize reviews\nvectorizer = CountVectorizer(binary=False, stop_words=stopwords.words('english'),\n                             lowercase=True, min_df=3, max_df=0.9, max_features=500)\n\n# Vectorize reviews\nX = vectorizer.fit_transform(reviews.ravel()).toarray()\n\n# Get ratings\nratings = np.concatenate((train.rating.values, test.rating.values)).reshape(-1, 1)\n\n# # Set up one-hot encoder\n# ohe = OneHotEncoder(categories='auto')\n\n# # One-hot encode ratings\n# y = ohe.fit_transform(ratings).toarray()","8806e03d":"y = ratings","00148353":"# stopwords.words('english')\n# ratings[:10], y[:10]","bea3c9ac":"# Train\/test split\nX_train, X_test = X[:train.values.shape[0], :], X[train.values.shape[0]:, :] \ny_train, y_test = y[:train.values.shape[0]], y[train.values.shape[0]:]","29aac989":"X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape","a39159c9":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train[:5000], y_train[:5000])","aebd88b8":"pred = lin_reg.predict(X_train[5000:])","2d3fbe94":"np.sum(np.abs(y_train[5000:] - pred[:])) \/ (161297 - 5000)","8fcf7a49":"from sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_train[5000:], pred)","fb03f92f":"# import keras as K\n# from keras.models import Sequential\n# from keras.layers import Dense, LSTM, Embedding\n# from keras import metrics, losses\n\n# model = Sequential()\n# \"\"\" TRY units=2500 \"\"\"\n# model.add(Dense(units=250, activation='relu', input_dim=5000))\n# model.add(Dense(units=10, activation='relu'))\n\n# model.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=[metrics.categorical_accuracy])\n# model.summary()","af6a9b2b":"# model.fit(X_train, y_train, epochs=1, batch_size=128, verbose=1, validation_data=(X_test, y_test));","d411e5fa":"# correct_count = 0\n\n# for i in range(y_test.shape[0]):\n# #     print(model.predict_classes(X_test[i].reshape(1, -1))[0] + 1, np.where(y_test[i] == 1)[0][0] + 1)\n#     if (model.predict_classes(X_test[i].reshape(1, -1))[0] + 1) == (np.where(y_test[i] == 1)[0][0] + 1):\n#         correct_count += 1\n        \n# correct_count \/ y_test.shape[0]","b90e2875":"# np.where(y_test[0] == 1)[0][0]","3dd38152":"# # Create neural net model\n# nn = MLPClassifier(hidden_layer_sizes=(2500,), activation='relu', max_iter=1000)\n# nn.fit(X_train, y_train)\n# accuracy_score(nn.predict(X), y)","5262882a":"# from sklearn.linear_model import LogisticRegression\n# log_reg = LogisticRegression(solver='lbfgs', multi_class='auto')\n# log_reg.fit(X_train, y_train)\n# accuracy_score(log_reg.predict(X_test), y_test)","f31b2d4c":"# from sklearn.svm import SVC\n# svm = SVC(kernel='rbf')\n# svm.fit(X_train, y_train)\n# accuracy_score(svm.predict(X_test), y_test)","ba53f2bc":"# Machine Learning Approach\n\nCrazy  experimentation for predicting rating given review (just a rough draft)!"}}