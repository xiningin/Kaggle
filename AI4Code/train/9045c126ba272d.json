{"cell_type":{"37368dd7":"code","efb5800d":"code","012e5ca0":"code","27182d46":"code","35bc6a3b":"code","c20c40bf":"code","34a50474":"code","88f0067d":"code","f029ad1b":"code","7d1da37d":"code","fe0abffd":"code","07ebf2ee":"code","c8e6c64d":"code","662adeca":"code","3f2b0d94":"code","c46e341c":"code","5cb8c7bb":"code","44706cd5":"code","3616e5d6":"code","dea714b2":"code","e806c7ae":"code","97f1ef07":"code","4a7fd1ad":"code","2937ab69":"code","616a8a47":"code","26003bc8":"code","b1330a70":"code","9977fc8a":"code","ec0020db":"code","308f6019":"code","66af3fd5":"code","5ad2bbbc":"code","5872f041":"code","a7e75f24":"code","e5e87221":"code","562251e1":"code","a60d7f19":"code","582b856a":"code","1ee403d2":"code","2961d517":"code","f47e2e1f":"code","6beca641":"code","b40606ec":"code","c1bb0ea8":"code","457ab0d5":"code","ab9eedb2":"code","768790ad":"code","1ace70f9":"code","f34da5f6":"code","e3219b38":"code","c93694f0":"code","b9ace53a":"code","126a2f42":"code","e109c702":"code","dd547575":"code","71b65d3d":"code","a3c8d33b":"code","acb638fb":"code","5f60a404":"code","deb55884":"code","3477ef22":"markdown","d7fd08e9":"markdown","dbdb0ce4":"markdown","f8f51051":"markdown","c4fe89ba":"markdown","3532b8c3":"markdown","e6e30f6d":"markdown","6142eaf7":"markdown","af887145":"markdown","85a84c15":"markdown","4ba9e2f8":"markdown","dde82061":"markdown"},"source":{"37368dd7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","efb5800d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","012e5ca0":"plt.style.use('seaborn-white')\n\nplt.rcParams['font.family'] = 'serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.labelweight'] = 'bold'\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\nplt.rcParams['legend.fontsize'] = 10\nplt.rcParams['figure.titlesize'] = 12","27182d46":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost as xgb\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.datasets import make_classification","35bc6a3b":"df = pd.read_csv('..\/input\/credit-card-customers\/BankChurners.csv')","c20c40bf":"df.drop(labels = df.columns[-2:], axis = 1,inplace = True)\ndf.drop(labels=['CLIENTNUM'], axis = 1, inplace = True)","34a50474":"df.head()","88f0067d":"df['Attrition_Flag'] = df['Attrition_Flag'].map(lambda x: 0 if x == 'Existing Customer' else 1)","f029ad1b":"df['Income_Category'].value_counts()","7d1da37d":"def process_eduaction_level(entry):\n    if entry == 'Less than $40K':\n        return '<40k'\n    elif entry == '$40K - $60K':\n        return '40k-60k'\n    elif entry == '$80K - $120K':\n        return '80k-120k'\n    elif entry == '$60K - $80K':\n        return '60k-80k'\n    elif entry == 'Unknown':\n        return 'Unknown'\n    elif entry == '$120K +':\n        return '>120k'","fe0abffd":"df['Income_Category'] = df['Income_Category'].map(process_eduaction_level)","07ebf2ee":"df.info()","c8e6c64d":"cat_feat = ['Gender','Education_Level','Marital_Status','Income_Category',\n           'Card_Category','Months_Inactive_12_mon']","662adeca":"cont_feat = ['Customer_Age','Months_on_book','Credit_Limit','Total_Revolving_Bal','Avg_Open_To_Buy',\n            'Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1',\n             'Avg_Utilization_Ratio','Dependent_count','Total_Relationship_Count','Contacts_Count_12_mon']","3f2b0d94":"cat_feat = ['Gender','Education_Level','Marital_Status','Income_Category',\n           'Card_Category','Months_Inactive_12_mon']","c46e341c":"semi_cat = ['Dependent_count','Total_Relationship_Count','Contacts_Count_12_mon']","5cb8c7bb":"len(cat_feat + cont_feat) + 1 == len(df.columns)","44706cd5":"fig, ax = plt.subplots(figsize=(6,6))\nsns.countplot(x = 'Attrition_Flag', data=df)\n[ ax.text(p.get_x()+p.get_width()\/2., p.get_height()\/2 , \n          '{:2.2f}%'.format(p.get_height()\/float(len(df))*100), ha=\"center\", \n          fontsize=20, color = 'white') for p in ax.patches]\nfig.show()","3616e5d6":"df_cont = df.drop(labels=cat_feat, axis = 1)","dea714b2":"fig = plt.figure(figsize=(16,16),dpi=300)\ni = 1\nfor feat in cont_feat:\n    ax1 = fig.add_subplot(6,3,i)\n    h1 = sns.distplot(a = df_cont[df_cont['Attrition_Flag'] == 0][feat], ax = ax1,\n                color = 'green', hist_kws={'alpha':0.3}, kde=False)\n    h2 = sns.distplot(a = df_cont[df_cont['Attrition_Flag'] == 1][feat], ax = ax1,\n                    color = 'red', hist_kws={'alpha':0.3}, bins = len(h1.patches), kde=False)\n    i += 1\nplt.tight_layout()\nfig.show()","e806c7ae":"df_cat = df.drop(labels=cont_feat, axis = 1)","97f1ef07":"fig = plt.figure(figsize=(15,15), dpi = 600)\ni = 1\nfor feat in cat_feat:\n    ax1 = fig.add_subplot(3,2,i)\n    d_temp = df_cat.groupby(feat)['Attrition_Flag']\n    sns.barplot(x = d_temp.std().index, y = d_temp.std().values, \n                color = 'royalblue', alpha = 0.5)\n    [ ax1.text(p.get_x()+p.get_width()\/2., p.get_height()\/2 , \n          '{:2.2f}%'.format(p.get_height()*100), ha=\"center\", fontsize=14, color = 'white') for p in ax1.patches]\n    i += 1\n    ax1.set_ylim(0,1)\nplt.tight_layout()","4a7fd1ad":"fig = plt.figure(figsize=(15,15), dpi = 600)\ni = 1\nfor feat in cat_feat:\n    ax1 = fig.add_subplot(3,2,i)\n    sns.pointplot(x = feat, y = 'Attrition_Flag', data = df_cat,\n                kind = 'point', ax = ax1)\n    i += 1\n    ax1.set_ylim(0,1)\nplt.tight_layout()","2937ab69":"df = pd.get_dummies(data = df, columns = cat_feat, drop_first = True)","616a8a47":"df.head()","26003bc8":"X = df.drop(labels = 'Attrition_Flag', axis = 1)\ny = df['Attrition_Flag']","b1330a70":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","9977fc8a":"scl = StandardScaler()","ec0020db":"X_train = pd.DataFrame(scl.fit_transform(X_train), columns=X_train.columns)\nX_test  = pd.DataFrame(scl.transform(X_test), columns=X_test.columns)","308f6019":"classifiers = ['Linear SVM', 'Radial SVM', 'LogisticRegression', \n               'RandomForestClassifier', 'AdaBoostClassifier', \n               'XGBoostClassifier', 'KNeighborsClassifier','GradientBoostingClassifier']\n\nscoring = ['precision', 'recall']\nindex = []\nfor clf in classifiers:\n    for scr in scoring:\n        idx = (clf,scr)\n        index.append(idx)\n        \nKFold_Score = pd.DataFrame(index = pd.MultiIndex.from_tuples(index,names=['Estimator','Scoring']), \n                           columns = ['f1','f2','f3','f4','f5'])\n\nmodels = [svm.SVC(kernel='linear'),\n          svm.SVC(kernel='rbf'),\n          LogisticRegression(max_iter = 1000),\n          RandomForestClassifier(n_estimators=200, random_state=42),\n          AdaBoostClassifier(random_state = 42),\n          xgb.XGBClassifier(n_estimators=100),\n          KNeighborsClassifier(),\n          GradientBoostingClassifier(random_state=42)\n         ]\nj = 0\nfor model in models:\n    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n    print('Running {:s}...'.format(classifiers[j]), end = \" \")\n    KFold_Score.loc[classifiers[j],'precision'] = (cross_val_score(model, X_train.values, y_train.values, scoring = 'precision', cv=cv, n_jobs = 5))\n    KFold_Score.loc[classifiers[j],'recall'] = (cross_val_score(model, X_train.values, y_train.values, scoring = 'recall', cv=cv, n_jobs = 5))\n    print(' finished!')\n    j = j+1","66af3fd5":"KFold_Score['mean'] = KFold_Score.mean(axis = 1)\nKFold_Score['std'] = KFold_Score.std(axis = 1)","5ad2bbbc":"KFold_Score_r = KFold_Score.reset_index()","5872f041":"KFold_Score_r = pd.concat([\n           KFold_Score_r[KFold_Score_r['Scoring'] == 'precision'][['Estimator','mean']].reset_index(),\n           KFold_Score_r[KFold_Score_r['Scoring'] == 'recall'][['Estimator','mean']].reset_index()],\n           ignore_index = True, keys = 'Estimator',axis = 1)","a7e75f24":"KFold_Score_r.drop(axis = 1, labels = [0,3,4], inplace = True)\nKFold_Score_r.columns = ['Estimator','precision','recall']","e5e87221":"KFold_Score_r['f1-score'] = KFold_Score_r.apply(lambda x: 2*x['precision']*x['recall']\/(x['precision'] + x['recall']),\n                                                axis = 1)","562251e1":"KFold_Score_r","a60d7f19":"fig, ax = plt.subplots(figsize = (8,8))\nsns.lineplot(x = 'Estimator',y = 'precision',  linewidth = 3, data = KFold_Score_r, \n             label = 'precision', color = 'blue')\nsns.lineplot(x = 'Estimator',y = 'recall',  linewidth = 3, data = KFold_Score_r,  \n             label = 'recall', color = 'red')\nsns.lineplot(x = 'Estimator',y = 'f1-score',  linewidth = 3, data = KFold_Score_r,  \n             label = 'f1-score', color = 'black')\nax.lines[2].set_linestyle(\"--\")\n\nfor tick in ax.get_xticklabels():\n    tick.set_rotation(45)\n\nax.tick_params(which='both', width=2)\nax.tick_params(which='major', length=7)\nax.grid(color='lightgray', linestyle='-', linewidth=1)","582b856a":"KFold_Score_r[(KFold_Score_r['Estimator'] == 'XGBoostClassifier') | (KFold_Score_r['Estimator'] == 'GradientBoostingClassifier')]","1ee403d2":"param_test0 = {\n                 'n_estimators': range(500,1600,100)\n                }","2961d517":"xgb_clf = xgb.XGBClassifier( \n                         learning_rate =0.1,\n                         n_estimators=1000,\n                         max_depth=3,\n                         min_child_weight=1,\n                         gamma=0,\n                         subsample=0.8,\n                         colsample_bytree=0.8,\n                         objective= 'binary:logistic',\n                         nthread=4,\n                         scale_pos_weight=1,\n                         seed=42,\n                         use_label_encoder=False)","f47e2e1f":"gsearch0 = GridSearchCV(estimator = xgb_clf, param_grid=param_test0, \n                        scoring = \"recall\", cv = 5, n_jobs=5, verbose = 2)","6beca641":"gsearch0.fit(X_train.values, y_train.values)","b40606ec":"gsearch0.best_params_","c1bb0ea8":"param_test1 = {\n                 'max_depth':range(1,8,2),\n                 'min_child_weight':range(1,6,2)\n                }","457ab0d5":"xgb_clf = xgb.XGBClassifier( \n                         silent = True,\n                         learning_rate =0.1,\n                         n_estimators=700,\n                         max_depth=3,\n                         min_child_weight=1,\n                         gamma=0,\n                         subsample=0.8,\n                         colsample_bytree=0.8,\n                         objective= 'binary:logistic',\n                         nthread=4,\n                         scale_pos_weight=1,\n                         seed=42,\n                         use_label_encoder=False)","ab9eedb2":"gsearch1 = GridSearchCV(estimator = xgb_clf, param_grid=param_test1, \n                        scoring = \"recall\", cv = 5, n_jobs = 5, verbose = 0)","768790ad":"gsearch1.fit(X_train.values, y_train.values)","1ace70f9":"gsearch1.best_score_","f34da5f6":"param_test2 = {\n                 'gamma':[0.1*i for i in range(0,20)],\n                }","e3219b38":"xgb_clf = xgb.XGBClassifier( \n                         \n                         learning_rate =0.1,\n                         n_estimators=700,\n                         max_depth=3,\n                         min_child_weight=1,\n                         gamma=0,\n                         subsample=0.8,\n                         colsample_bytree=0.8,\n                         objective= 'binary:logistic',\n                         nthread=4,\n                         scale_pos_weight=1,\n                         seed=42,\n                         use_label_encoder=False)","c93694f0":"gsearch2 = GridSearchCV(estimator = xgb_clf, param_grid=param_test2, \n                        scoring = \"recall\", cv = 5, n_jobs = 5, verbose = 2)","b9ace53a":"gsearch2.fit(X_train.values, y_train.values)","126a2f42":"gsearch2.best_score_","e109c702":"from xgboost import plot_importance","dd547575":"xgb_clf = gsearch2.estimator","71b65d3d":"feat_dict = {}\nfor i in range(0,len(X_train.columns)):\n    ky = f'f{i}'\n    feat_dict[ky] = X_train.columns[i]","a3c8d33b":"xgb_clf.fit(X_train.values,y_train.values)","acb638fb":"fig,ax = plt.subplots(figsize=(6,10))\n\nplot_importance(booster = xgb_clf, ax = ax, height = 0.6, )\nnew_labels = []\nfor tick in ax.get_yticklabels():\n    new_labels.append(feat_dict[tick.get_text()])\nax.set_yticklabels(new_labels)\nplt.tight_layout","5f60a404":"y_pred = xgb_clf.predict(X_test.values)","deb55884":"print(classification_report(y_pred,y_test))","3477ef22":"The data has been manually explored and divided into three categories: categorical, semicategorical and continuous features. Semicategorical refers to numerical features consisting on a relatively small number of integers.\n\nWe will start by taking a look at the correlation of the continuous features with the feature that we want to predict - 'Attrition_flag'. First of all we can see how there is are significantly more 'Existing', i.e. non attrited, customers than attrited ones.","d7fd08e9":"## Categorical features ","dbdb0ce4":"## Initial Data exploration","f8f51051":"## Model selection and training","c4fe89ba":"<div class=\"alert alert-block alert-success\">\n    <br> \n    <br> \n    <h3> 97% accuracy with 94% recall  <\/h3>\n    <br> \n<\/div>","3532b8c3":"The XGBoostClassifier has the best recall while the GradientBoostingClassifier has the highest precision. Both estimators scores lie very close to each other, therefore we will attempt to optimize the parameters for both of them.","e6e30f6d":"## Short data preprocessing","6142eaf7":"## Continuous features ","af887145":"## My Credit Card Customers\n\nThis is my first Kaggle notebook so I hope is not too bad ;-)","85a84c15":"This is my first go at it. I will continue to do some feature engineering and data preprocessing to try and improve this result. Nevertheless, it's a pretty good score to start with, I think.","4ba9e2f8":"## Results and feature importance","dde82061":"## Parameter optimization for the XGBoostClassifier"}}