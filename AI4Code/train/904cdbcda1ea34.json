{"cell_type":{"89bfe021":"code","9480a179":"code","f8d35c4e":"code","a0da9a22":"code","6e2bb4f1":"code","f5710aa1":"code","f4fb6461":"code","a2430d89":"code","7875016d":"code","76400829":"code","cc990470":"code","652410af":"code","d1e7d053":"code","8c25367d":"code","f3d873db":"code","edf118e9":"code","8e742bc1":"code","e95cc4e4":"code","1fc3512e":"code","b21d4ccb":"code","22a9b522":"code","ca2db178":"code","0a9ecefd":"code","58d8447f":"code","caa1cb68":"code","d9114d3f":"code","51a804b9":"code","03a3fac3":"code","219ae91f":"code","367a4b31":"code","e4659756":"code","5eb61df2":"code","9e1683b1":"code","b24ccb88":"code","d7237ae8":"code","047690da":"code","1ba04ff8":"code","70e92c9d":"code","08101c2f":"code","9088b5d8":"markdown"},"source":{"89bfe021":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import plot_confusion_matrix, classification_report, f1_score\nfrom sklearn.model_selection import train_test_split ,GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\n#Classification Models:\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\n\n#Supress Warnings:\nimport warnings\nwarnings.filterwarnings('ignore')","9480a179":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain_df = train_df.set_index(\"PassengerId\")\ntrain_df.head()","f8d35c4e":"train_df.info()","a0da9a22":"train_df.shape","6e2bb4f1":"train_df.isnull().sum()\/len(train_df)","f5710aa1":"train_df.describe()","f4fb6461":"test_df.isnull().sum()\/len(test_df)","a2430d89":"train_df.dropna(subset=[\"Embarked\"], inplace=True)\ntrain_df.drop(columns=['Cabin'],inplace=True)\n\ntrain_df.info()","7875016d":"train_df['Sex'].unique()","76400829":"train_df['Embarked'].unique()","cc990470":"df_all_corr = train_df.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_all_corr[df_all_corr['Feature 1'] == 'Age']","652410af":"age_by_pclass_sex = train_df.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(train_df['Age'].median()))\n\n# Filling the missing values in Age with the medians of Sex and Pclass groups\ntrain_df['Age'] = train_df.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","d1e7d053":"plt.figure(figsize=(14,8))\nsns.countplot(x=\"Survived\", data=train_df,hue='Sex')\nplt.show()","8c25367d":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","f3d873db":"plt.figure(figsize=(14,8))\nsns.countplot(x=\"Survived\", data=train_df,hue='Pclass')\nplt.show()","edf118e9":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8e742bc1":"plt.figure(figsize=(14,8))\nsns.countplot(x=\"Survived\", data=train_df,hue='Embarked')\nplt.show()","e95cc4e4":"train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1fc3512e":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in [train_df, test_df]:\n    # factorize Name column\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    # facotrize Sex column\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","b21d4ccb":"# extract number of family members\nfor dataset in [train_df, test_df]:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","22a9b522":"for dataset in [train_df, test_df]:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","ca2db178":"# factorize values in Embarked column \nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in [train_df, test_df]:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0a9ecefd":"train_df.columns","58d8447f":"features = ['Pclass',  'Sex', 'Age', 'SibSp', 'Parch', \n       'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone']","caa1cb68":"# fill missing values in test df\nfare_median = test_df['Fare'].dropna().median()\ntest_df['Fare'].fillna(fare_median, inplace=True)\ntest_df['Age'] = test_df.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\ntest_df.info()","d9114d3f":"X = train_df[features]\ny = train_df['Survived']\n\n#Split training data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2,stratify = y,random_state=42)\n\nX_train.info()","51a804b9":"# knn - k-nearest neighbours\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train, y_train)\n# print metric to get performance\nprint(\"Accuracy: \",model.score(X_val, y_val) * 100)\ny_pred = model.predict(X_val)\nf1 = f1_score(y_val, y_pred, average='micro')\nprint(\"f1_score: \",f1)","03a3fac3":"print(\"  Validation set Classification Report:\")\nprint(classification_report(y_val, y_pred, digits=4))","219ae91f":"fig, ax = plt.subplots(1, 2, figsize = (15, 5))\nax[0].set_title(\"Training Set Confusion Matrix\")\nplot_confusion_matrix(model, X_train, y_train, ax=ax[0], \n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\n\nax[1].set_title(\"Validation Set Confusion Matrix\")\nplot_confusion_matrix(model, X_val, y_val, ax=ax[1],\n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\nplt.show()","367a4b31":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf = BaggingClassifier(\n    DecisionTreeClassifier(), n_estimators=500,\n    max_samples=100, bootstrap=True, random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy: \",accuracy_score(y_val, y_pred)*100)\nf1 = f1_score(y_val, y_pred, average='micro')\nprint(\"f1_score: \",f1)","e4659756":"print(\"  Validation set Classification Report:\")\nprint(classification_report(y_val, y_pred, digits=4))","5eb61df2":"fig, ax = plt.subplots(1, 2, figsize = (15, 5))\nax[0].set_title(\"Training Set Confusion Matrix\")\nplot_confusion_matrix(clf, X_train, y_train, ax=ax[0], \n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\n\nax[1].set_title(\"Validation Set Confusion Matrix\")\nplot_confusion_matrix(clf, X_val, y_val, ax=ax[1],\n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\nplt.show()","9e1683b1":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=100,\n                               criterion=\"entropy\",\n                               max_depth=6,\n                               min_samples_split=4,\n                               bootstrap=True,\n                               max_samples=0.8,\n                               oob_score=True,\n                               n_jobs=-1,\n                               random_state=0)\n\nclf.fit(X_train, y_train)\nscores=cross_val_score(clf, X, y, cv=5)\nprint(\"Cross Validation:\\n  %0.5f accuracy with a standard deviation of %0.5f \\n\" % (scores.mean(), scores.std()))# print metric to get performance\nprint(\"Accuracy: \",clf.score(X_val, y_val) * 100)\ny_pred = clf.predict(X_val)\nf1 = f1_score(y_val, y_pred, average='micro')\nprint(\"f1_score: \",f1)","b24ccb88":"print(\"  Validation set Classification Report:\")\nprint(classification_report(y_val, y_pred, digits=4))","d7237ae8":"fig, ax = plt.subplots(1, 2, figsize = (15, 5))\nax[0].set_title(\"Training Set Confusion Matrix\")\nplot_confusion_matrix(clf, X_train, y_train, ax=ax[0], \n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\n\nax[1].set_title(\"Validation Set Confusion Matrix\")\nplot_confusion_matrix(clf, X_val, y_val, ax=ax[1],\n                      cmap=\"YlGnBu\", xticks_rotation=\"vertical\")\nplt.show()","047690da":"test_df.head()","1ba04ff8":"test_df.info()","70e92c9d":"predictions = clf.predict(test_df[features])","08101c2f":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","9088b5d8":"**DATA Visualization**"}}