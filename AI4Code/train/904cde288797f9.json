{"cell_type":{"90d837ae":"code","1563d02d":"code","4c13a2da":"code","801fcae7":"code","73104df7":"code","061ef915":"code","912a99cf":"code","b5ca77eb":"code","a5d167ae":"code","14d07e01":"code","56d87587":"code","8cf9b646":"code","9c865dc8":"code","d8b303d1":"code","bf10adb2":"code","3ead0d5b":"code","39b40727":"code","946bae3d":"code","2e910223":"code","cfa39b54":"code","1494cd7f":"code","4e0313cd":"code","1b42296a":"code","90c3c100":"code","0c9cf9b9":"code","2535365e":"code","fca6c827":"code","11619540":"code","7ca15488":"code","9d5fa3ad":"code","01fa0964":"code","4087d34e":"code","8ec924ad":"code","1966b997":"code","e6a20965":"code","c5190da8":"code","c23bcebb":"code","cd937718":"code","cc528c43":"code","0eb02c45":"code","5c42c72d":"code","28ea3808":"code","3778eff2":"code","2e6239f4":"markdown","dc570fd3":"markdown","b9650237":"markdown","2425362b":"markdown","ae4c5f3e":"markdown","d91ba1fe":"markdown","676b9dc6":"markdown","c496f176":"markdown","fcb17429":"markdown","54a9f7de":"markdown","6b77d181":"markdown","44d4d393":"markdown","fc1ddf50":"markdown","ff85b458":"markdown","291120c8":"markdown","30892e28":"markdown","15c3ccc5":"markdown","1123cb20":"markdown","6a50104d":"markdown","fa400801":"markdown","45734f77":"markdown","c6d885ab":"markdown","8fd2913a":"markdown","579bbd86":"markdown","42103787":"markdown","68961999":"markdown","dcde1085":"markdown","d0d5a09a":"markdown","05889827":"markdown","edaed774":"markdown","1b46ddac":"markdown","8b4dd3c8":"markdown","d43c6129":"markdown","f1784974":"markdown","b0d22bd8":"markdown","b2e01f2a":"markdown","2ccdd488":"markdown","fa2098f3":"markdown","567378ba":"markdown","42d9d623":"markdown","7b6c27e1":"markdown","cfc53dbb":"markdown","e8c85b3c":"markdown"},"source":{"90d837ae":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as rnd","1563d02d":"train_ds=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_ds=pd.read_csv('..\/input\/titanic\/test.csv')\ncombine=[train_ds,test_ds]","4c13a2da":"print(train_ds.columns.values)","801fcae7":"train_ds.head()","73104df7":"train_ds.tail()","061ef915":"train_ds.info()\nprint('*'*50)\ntest_ds.info()","912a99cf":"train_ds.describe()","b5ca77eb":"train_ds.describe(include='object')","a5d167ae":"plt.figure(figsize=(15,8))\nsns.kdeplot(train_ds[\"Age\"][train_ds.Survived == 1], color=\"springgreen\", shade=True)\nsns.kdeplot(train_ds[\"Age\"][train_ds.Survived == 0], color=\"salmon\", shade=True)\nplt.legend(['Survived', 'Died'])\nplt.title('Density Plot of Age for Surviving Population')\nplt.show()","14d07e01":"k = sns.FacetGrid(train_ds, col='Survived')\nk.map(plt.hist, 'Age', bins=20)","56d87587":"grid = sns.FacetGrid(train_ds, col='Survived', row='Pclass', height=2.0, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","8cf9b646":"grid = sns.FacetGrid(train_ds, row='Embarked', height=2.0, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","9c865dc8":"grid = sns.FacetGrid(train_ds, row='Embarked', col='Survived', height=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","d8b303d1":"train_ds = train_ds.drop(['PassengerId','Ticket','Cabin'], axis=1)\ntest_ds = test_ds.drop(['Ticket', 'Cabin'], axis=1)\n","bf10adb2":"combine=[train_ds,test_ds]\nfor dataset in combine:\n    dataset['Titles'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","3ead0d5b":"train_ds = train_ds.drop(['Name'], axis=1)\ntest_ds = test_ds.drop(['Name'], axis=1)","39b40727":"combine = [train_ds, test_ds]\nfor dataset in combine:\n    dataset['Titles'] = dataset['Titles'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n\n    dataset['Titles'] = dataset['Titles'].replace(['Mlle','Ms','Mme'], ['Miss','Miss','Mrs'])\n   ","946bae3d":"train_ds['Titles']=train_ds['Titles'].map({ \"Master\": 1,\"Miss\": 2,\"Mr\": 3, \"Mrs\": 4, \"Other\": 5})","2e910223":"test_ds['Titles']=test_ds['Titles'].map({ \"Master\": 1,\"Miss\": 2,\"Mr\": 3, \"Mrs\": 4, \"Other\": 5})","cfa39b54":"sns.barplot('Titles', 'Survived', data=train_ds, color=\"#2ecc71\")\nplt.show()","1494cd7f":"train_ds['Sex']=train_ds['Sex'].map({'female': 1, 'male': 0}).astype(int)\ntest_ds['Sex']=test_ds['Sex'].map({'female': 1, 'male': 0}).astype(int)","4e0313cd":"train_ds.head()","1b42296a":"guess_ages = np.zeros((2,3))\nguess_ages","90c3c100":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            guess_ages[i,j] = int(guess_df.mean())\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_ds.head()\n","0c9cf9b9":"Embark_common=train_ds.Embarked.dropna().mode()[0]\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(Embark_common)\n    \ntrain_ds.info()","2535365e":"test_ds['Fare'].fillna(test_ds['Fare'].dropna().median(), inplace=True)\ntest_ds.info()","fca6c827":"train_ds['Embarked']=train_ds['Embarked'].map({'S': 1, 'C': 2, 'Q':3}).astype(int)\ntest_ds['Embarked']=test_ds['Embarked'].map({'S': 1, 'C': 2, 'Q':3}).astype(int)\ntrain_ds.head()","11619540":"train_ds['AgeRange'] = pd.cut(train_ds['Age'], 5)\ntrain_ds[['AgeRange', 'Survived']].groupby(['AgeRange'], as_index=False).mean().sort_values(by='AgeRange', ascending=True)","7ca15488":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 4\n    dataset.loc[ dataset['Age'] > 64, 'Age']=5","9d5fa3ad":"train_ds = train_ds.drop(['AgeRange'], axis=1)\ncombine = [train_ds, test_ds]\ntrain_ds.head()","01fa0964":"train_ds['FareRange'] = pd.qcut(train_ds['Fare'], 5)\ntrain_ds[['FareRange', 'Survived']].groupby(['FareRange'], as_index=False).mean().sort_values(by='FareRange', ascending=True)","4087d34e":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.85, 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 7.85) & (dataset['Fare'] <= 10.5), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 10.5) & (dataset['Fare'] <= 21.67), 'Fare'] = 3\n    dataset.loc[(dataset['Fare'] > 21.67) & (dataset['Fare'] <= 39.68), 'Fare'] = 4\n    dataset.loc[ dataset['Fare'] > 39.68, 'Fare'] = 5\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_ds = train_ds.drop(['FareRange'], axis=1)\ncombine = [train_ds, test_ds]\ntrain_ds.head(10)","8ec924ad":"for dataset in combine:\n    dataset['family_count']=dataset['SibSp']+dataset['Parch']\n    dataset.loc[dataset['family_count']>0,'isAlone']=0\n    dataset.loc[dataset['family_count']==0,'isAlone']=1\n    dataset['isAlone']=dataset['isAlone'].astype(int)\ntrain_ds.head()","1966b997":"sns.barplot('isAlone', 'Survived', data=train_ds, color=\"coral\")\nplt.show()","e6a20965":"train_ds=train_ds.drop(['SibSp','Parch','family_count'],axis=1)\ntest_ds=test_ds.drop(['SibSp','Parch','family_count'],axis=1)\ntrain_ds.head()","c5190da8":"X_train = train_ds.drop(\"Survived\", axis=1)\nY_train = train_ds[\"Survived\"]\nX_test  = test_ds.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","c23bcebb":"#Fitting Logistic regression to the training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0)\nclassifier.fit(X_train,Y_train)\n \n#Predict the test set result\nY_pred=classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","cd937718":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the Test set results\nY_pred = classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","cc528c43":"from sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\nclassifier.fit(X_train,Y_train)\n\nY_pred=classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","0eb02c45":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, Y_train)\n\n# Predicting the Test set results\nY_pred = classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","5c42c72d":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the Test set results\nY_pred = classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","28ea3808":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the Test set results\nY_pred = classifier.predict(X_test)\n\nConfidence_score = round(classifier.score(X_train, Y_train) * 100, 2)\nConfidence_score","3778eff2":"Result = pd.DataFrame({\n        \"PassengerId\": test_ds[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nResult.to_csv('Submission.csv', index=False)","2e6239f4":"It would be safe to drop Name feature now.","dc570fd3":"* Pclass=3 had most passengers, however most did not survive.\n* Infant passengers in Pclass=2 and Pclass=3 mostly survived.\n* Most passengers in Pclass=1 survived.\n* Pclass varies in terms of Age distribution of passengers.\n\nSince Pclass feature shows strong corelation with Age and survival, it should be included in model training.","b9650237":"**Categorical features:** Survived, sex, embarked, pclass\n\n**Numerical:** \n*     Continous: Age, fare\n*     Discrete: SibSp, Parch","2425362b":"Completing the Fare feature in test set","ae4c5f3e":"* Applying SVC (Support vector machines)","d91ba1fe":"# Dropping unuseful features:","676b9dc6":"* Age feature can be completed based on Name feature using respective titles, hence extracting the Titles as feature.","c496f176":"Judging by the values and types it appears that Name, Ticket and Cabin values may require correction.\n\n**Checking columns for empty values:**","fcb17429":"Age feaure can be completed on the basis of Sex and Titles feature. But first both of these features need correction.","54a9f7de":"# Descriptive analysis:","6b77d181":"# #Analyzing by visualizing data :","44d4d393":"* Applying Naive Bayes :","fc1ddf50":"**Corelating Numerical features with Categorical features:**\nVisualizing survival rate on basis of fare with respect to sex and embarked features:","ff85b458":"**Completing age feature:**\n\nIn this case there is correlation among Age, Gender, and Pclass. Guess Age values using mean values for Age across sets of Pclass and Gender feature combinations. So, mean Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...\n\n\nUsing an empty array to contain guessed Age values based on Pclass and Gender combinations :","291120c8":"* Applying Random forest:","30892e28":"To complete Embarked feature, it appears that it has only two missing values in training set, which can be replaced with most common occurance.","15c3ccc5":"* It appears that The Random forest model gave the best confidence score so far.","1123cb20":"* Higher paying passengers had higher survival rate.\n* Embark ports S and C strongly corelate Fare with Survival thus indirectly Port of Embarkment has corelation with     Survival.\n\nThus:\nFare should be added to model in form of fare bands.","6a50104d":"Also sex feature can be converted to categorical variable:","fa400801":"Observations:\n\n* Infants (Age <=4) had high survival rate.\n* Oldest passengers (Age = 80) survived.\n* Large number of 15-25 year olds did not survive.\n* Most passengers are in 15-40 age range.\n\nthus:\n* Age should be considered in model training.\n* Complete the Age feature for null values.\n* Age should be band in age groups.","45734f77":"**Acquring data:**","c6d885ab":"**Distribution:**\n    1. Names are unique accros dataset.\n    2. sex var has 2 possible values with 65% males.\n    3. Cabin values have duplicates accross dataset, evidently servral passengers shared cabins.\n    4. Embarked feature has 3 possible values: Most embarked on post S.\n    5. Ticket features also has a high count of duplicate values.","8fd2913a":"Similarly for Fare feature:","579bbd86":"* Applying Decision Tree:","42103787":"Converting Title feature to categorical feature:","68961999":"* Applying KNN (K Nearest Neighbour):","dcde1085":"**Corelating Categorical features:**\n","d0d5a09a":"To Convert Age and Fare to Categorical features, it would make sense to convert these features to ranges and then into catgorical feature.\nTo verify if its needed:","05889827":"**Distribution of features:**","edaed774":"Thus converting Age feature into ordinal according to AgeRange:","1b46ddac":"Converting Embarked to Categorical feature:","8b4dd3c8":"By analyzying so far:\n    1. Age feature is possibly corelated with Survival, although it needs to be compleeted\/corrected.\n    2. Embarked feature may also be corelated with survival but this one also needs to be completed.\n    3. Ticket, cabin and PassengerId fetures can be dropped, since they do not seeem too contribute to survival.\n    4. Name feature is aslo not directly related with survival, but can be usefull to relate with other features. \n       A new feature title can be created out of name feature.\n    5. Age and Fare features can be converted into ranges\/bands so that they can be used as categorical features.\n  ","d43c6129":"Generalising Titles:","f1784974":"* Applying Logistic Regression:","b0d22bd8":"* Female passengers had much better survival rate than males.\n* Exception in Embarked=C where males had higher survival rate. This could be a indirect correlation between Pclass and   Embarked and in turn Pclass and Survived.\n* Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports.\n* Ports of embarkation have varying survival rates for Pclass=3 and among male passengers.\n\nThus:\nSex and Embarked features should be completed and added to the model.","b2e01f2a":"**Corelating numericall and ordinal features:**\n\nVisualizing survial rate with respect to Pclass and Age:","2ccdd488":"**Data Preview:**","fa2098f3":"**Corelation b\/w Age and Survival:**","567378ba":"Since the features are all  completed and corrected now starting with modeling and Predection:","42d9d623":"It appears that Age and Cabin fields have most empty values in both train and test dataset.\nAlso Embarked field in train dataset and fare fields in test dataset also have a few missing values.","7b6c27e1":"**Importing the libraries:**","cfc53dbb":"According to dataset description, Parch and SibSp can represent the family members aboard which can be used to create a new feature.","e8c85b3c":"It appears that those who travelled with family onboard had higher rate of survival, thus the newly created feature has a corelation with survival.\n\nSibSp, Parch and family_count features ca be dropped now."}}