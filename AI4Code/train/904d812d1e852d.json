{"cell_type":{"1fd4e8fd":"code","2bc0d3b3":"code","8d39ef5c":"code","7f45bd60":"code","f52cba79":"code","818965a5":"code","d93ac1aa":"code","b7d5ac5a":"code","99247f18":"code","13c2f35e":"code","0964b6f9":"code","aefbbd55":"code","26ae8637":"code","6f531333":"code","3a6436fd":"code","2e7f01ba":"code","c01728c5":"code","4b68babb":"code","f6214f06":"code","9df273fe":"code","f45f10f3":"code","7f2b5428":"code","dcf8c8bb":"code","69218277":"code","d0693ec5":"code","ad1f9035":"code","5fb0987c":"code","d29d5741":"code","30acb77b":"code","d552f932":"code","a706bdde":"code","29d7a65b":"code","ff25541f":"code","68b7de8d":"code","41b67636":"code","50c4949b":"code","22708ff3":"code","05cdfaf6":"code","372ca719":"markdown","aa1fbc06":"markdown","6b9ce430":"markdown","39027e8c":"markdown","f69ed768":"markdown","e329f174":"markdown","6861fafe":"markdown","8c633aef":"markdown","1a379bc0":"markdown","45572825":"markdown","47b10a4a":"markdown","e8c7ee59":"markdown","761b1161":"markdown","f8c427a8":"markdown","b3a78365":"markdown","54b7e842":"markdown","b6e1749e":"markdown","029de643":"markdown","29b5400d":"markdown","203c3879":"markdown","ff4e10fc":"markdown","4da9e6b4":"markdown","c2118e37":"markdown","8ac5a1c6":"markdown","a3e1b683":"markdown","c56381b6":"markdown","6457ebf8":"markdown","8f6a9d25":"markdown","196d03c6":"markdown","18c3b148":"markdown","86049216":"markdown","e57ea555":"markdown","571b8902":"markdown","82f7a6c6":"markdown","e4204196":"markdown","dc4a6163":"markdown","8aa0ea5f":"markdown","0fc444ac":"markdown"},"source":{"1fd4e8fd":"import numpy as np\nimport pandas as pd\nimport requests\nimport folium\nimport os\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.io.json import json_normalize\n\nsns.set()","2bc0d3b3":"# read the csv file and name it as 'monthly'\n# header=0 --> so that the first row (with all the categorical names, not values) is defined as the header of the table.\nmonthly = pd.read_csv('..\/input\/seouls-air-quality-and-sources-of-pollution\/seoul_monthly_average_air_pollution.csv', header=0)\n\n# head() function shows the first five rows of the table. \nmonthly.head()","8d39ef5c":"daily = pd.read_csv('..\/input\/seouls-air-quality-and-sources-of-pollution\/seoul_daily_average_air_pollution.csv', header=0)\ndaily.head()","7f45bd60":"yearly = pd.read_csv('..\/input\/seouls-air-quality-and-sources-of-pollution\/seoul_yearly_average_air_pollution.csv', header=0)\nyearly.head()","f52cba79":"# Changing the column names of the 'yearly' data table\nyearly.columns = ['Year', 'Place_Measured', 'Nitrogen_Dioxide(ppm)', 'Ozone(ppm)', 'Carbon_Monoxide(ppm)', 'Sulfur_Dioxide(ppm)', 'PM-10', 'PM-2.5']\nyearly.head()","818965a5":"gu_list_eng = ['Gangnam-gu', 'Gangdong-gu', 'Gangbuk-gu', 'Gangseo-gu', 'Gwanak-gu', 'Gwangjin-gu', 'Guro-gu',\n 'Geumcheon-gu', 'Nowon-gu', 'Dobong-gu', 'Dongdaemun-gu', 'Dongjak-gu', 'Mapo-gu',\n 'Seodaemun-gu', 'Seocho-gu', 'Seongdong-gu', 'Seongbuk-gu', 'Songpa-gu', 'Yangcheon-gu', 'Yeongdeungpo-gu',\n'Yongsan-gu', 'Eunpyeong-gu', 'Jongno-gu', 'Jung-gu', 'Jungnang-gu']\n\ngu_list_kor = ['\uac15\ub0a8\uad6c', '\uac15\ub3d9\uad6c', '\uac15\ubd81\uad6c', '\uac15\uc11c\uad6c', '\uad00\uc545\uad6c', '\uad11\uc9c4\uad6c', '\uad6c\ub85c\uad6c',\n '\uae08\ucc9c\uad6c', '\ub178\uc6d0\uad6c', '\ub3c4\ubd09\uad6c', '\ub3d9\ub300\ubb38\uad6c', '\ub3d9\uc791\uad6c', '\ub9c8\ud3ec\uad6c', '\uc11c\ub300\ubb38\uad6c', '\uc11c\ucd08\uad6c', '\uc131\ub3d9\uad6c', '\uc131\ubd81\uad6c', '\uc1a1\ud30c\uad6c', '\uc591\ucc9c\uad6c', '\uc601\ub4f1\ud3ec\uad6c',\n'\uc6a9\uc0b0\uad6c', '\uc740\ud3c9\uad6c', '\uc885\ub85c\uad6c', '\uc911\uad6c', '\uc911\ub791\uad6c']\n\n# The first item of gu_list_kor corresponds to the first item of gu_list_eng, and vice versa. ","d93ac1aa":"for index, row in yearly.iterrows(): # iterrows() allows the for loop to go through each and every row.\n    if yearly.iloc[index, 1] in gu_list_kor: # index is row number, the number 1 points to the column name 'Place_Measured'\n        i = gu_list_kor.index(yearly.iloc[index, 1]) # Get the list index of the matching word\n        yearly.iloc[index, 1] = gu_list_eng[i] #Find the corresponding word in the English list, and apply it.\n\nyearly.head(20)","b7d5ac5a":"yearly = yearly.loc[yearly['Place_Measured'].isin(gu_list_eng)]\n\nyearly.head()","99247f18":"yearly.to_csv('Processed_yearly_seoul_air_quality.csv')","13c2f35e":"print(yearly.Year.unique())","0964b6f9":"print(yearly.Place_Measured.unique())\n\n# Number of districts\nlen(yearly.Place_Measured.unique())","aefbbd55":"#The maximum pm-10 level recored in history\nprint(max(yearly.iloc[:, 6]))\n\n#The maximum pm-2.5 level recored in history\nprint(max(yearly.iloc[:, 7]))","26ae8637":"nowon = yearly.loc[yearly.Place_Measured == 'Nowon-gu']\n\n#Let's see the entire history\nnowon","6f531333":"def lineplot_gu(figsize=(20, 12), x='Year', y='PM-10', gu=''):\n    data = yearly.loc[yearly.Place_Measured == gu]\n    plt.figure(figsize=figsize)\n    sns.lineplot(x='Year', y='PM-10', data=data, markers=True)\n    plt.xlabel(x)\n    if y == 'PM-10' or y == 'PM-2.5':\n        plt.ylabel(y + ' (\u03bcg\/m3)')\n    plt.xticks(range(min(data['Year']), max(data['Year']) + 1))\n    plt.title('{} level in {} from {} to {}'.format(y, gu, min(data['Year']), max(data['Year'])))","3a6436fd":"#Let's visualize the level of PM-10 of Nowon-gu\nlineplot_gu(gu='Nowon-gu')","2e7f01ba":"lineplot_gu(y='Ozone', gu='Gangnam-gu')","c01728c5":"monthly.head()","4b68babb":"daily.head()","f6214f06":"monthly.columns = ['Time_Measured', 'Place_Measured', 'Nitrogen_Dioxide(ppm)', 'Ozone(ppm)', 'Carbon_Monoxide(ppm)', 'Sulfur_Dioxide(ppm)', 'PM-10', 'PM-2.5']\ndaily.columns = ['Time_Measured', 'Place_Measured', 'Nitrogen_Dioxide(ppm)', 'Ozone(ppm)', 'Carbon_Monoxide(ppm)', 'Sulfur_Dioxide(ppm)', 'PM-10', 'PM-2.5']","9df273fe":"# For Monthly table.\n\nfor index, row in monthly.iterrows():\n    if monthly.iloc[index, 1] in gu_list_kor:\n        i = gu_list_kor.index(monthly.iloc[index, 1])\n        monthly.iloc[index, 1] = gu_list_eng[i]\n\nmonthly = monthly.loc[monthly['Place_Measured'].isin(gu_list_eng)]\nmonthly.to_csv('Processed_monthly_seoul_air_quality.csv')\nmonthly.head()","f45f10f3":"# For Daily table.\n\nfor index, row in daily.iterrows():\n    if daily.iloc[index, 1] in gu_list_kor:\n        i = gu_list_kor.index(daily.iloc[index, 1])\n        daily.iloc[index, 1] = gu_list_eng[i]\n\ndaily = daily.loc[daily['Place_Measured'].isin(gu_list_eng)]\ndaily.to_csv('Processed_daily_seoul_air_quality.csv')\ndaily.head()","7f2b5428":"factory_emissions = pd.read_csv('..\/input\/seouls-air-quality-and-sources-of-pollution\/report_on_factory-emissions.txt', sep=' ', header=None)\nfactory_emissions.head(10)","dcf8c8bb":"# Use \\t as the separator\nfactories_emissions = pd.read_csv('..\/input\/seouls-air-quality-and-sources-of-pollution\/report_on_factory-emissions.txt', sep='\\t', header=None)\nfactories_emissions.head(10)","69218277":"factories_emissions = factories_emissions.loc[2:, :] #Get rid of the labels on the top two rows.\nfactories_emissions.head()","d0693ec5":"factories_emissions.columns = ['Year', 'District', 'Total', 'Category1', 'Category2', 'Category3', 'Category4', 'Category5']\nfactories_emissions.drop(factories_emissions.index[0], inplace=True) #Remove the first row, as it was supposed to be the labels.\nfactories_emissions.head()","ad1f9035":"#Now let's remove the rows that show the total of factories in every year.\nfactories_emissions = factories_emissions.loc[factories_emissions['District'] != '\ud569\uacc4']\nfactories_emissions.head()","5fb0987c":"factories_emissions.reset_index(drop=True, inplace=True)\nfactories_emissions.head()","d29d5741":"for index, row in factories_emissions.iterrows():\n    if factories_emissions.iloc[index, 1] in gu_list_kor:\n        i = gu_list_kor.index(factories_emissions.iloc[index, 1])\n        factories_emissions.iloc[index, 1] = gu_list_eng[i]\n\n#Save the data table as a separate file.\nfactories_emissions.to_csv('Processed_factories_emissions_seoul.csv')\nfactories_emissions.head()","30acb77b":"print(factories_emissions.Year.unique())","d552f932":"companies_info = pd.read_csv('..\/input\/seoul-air-qualit-data-extended\/seoul_pollutants_companies_information.csv', header=0)\ncompanies_info.head()","a706bdde":"companies_info.columns","29d7a65b":"companies_info.drop(['\ubc88\ud638', '\uc601\uc5c5\uc0c1\ud0dc\uba85', '\ud3d0\uc5c5\uc77c\uc790', '\ud734\uc5c5\uc2dc\uc791\uc77c\uc790', '\ud734\uc5c5\uc885\ub8cc\uc77c\uc790', '\uc7ac\uac1c\uc5c5\uc77c\uc790', '\uc18c\uc7ac\uc9c0\uba74\uc801', '\ubc29\uc9c0\uc2dc\uc124\uc5f0\uac04\uac00\ub3d9\uc77c\uc218', '\ubc29\uc9c0\uc2dc\uc124\uc870\uc5c5\uc2dc\uac04', '\ubc30\ucd9c\uc2dc\uc124\uc5f0\uac04\uac00\ub3d9\uc77c\uc218', '\ubc30\ucd9c\uc2dc\uc124\uc870\uc5c5\uc2dc\uac04', '\uc8fc\uc0dd\uc0b0\ud488\uba85', '\uc18c\uc7ac\uc9c0\uc6b0\ud3b8\ubc88\ud638', '\uc0c1\uc138\uc601\uc5c5\uc0c1\ud0dc\uba85', '\uc804\ud654\ubc88\ud638', '\ud658\uacbd\uc5c5\ubb34\uad6c\ubd84\uba85', '\uc778\ud5c8\uac00\ubc88\ud638'], 1, inplace=True)\n#inplace=true is used to change the data table directly. If it is omitted, the original data table remains as it is. ","ff25541f":"# The updated table.\ncompanies_info.head()","68b7de8d":"companies_info.columns = ['Name', 'Location_Address', 'Street_Address', 'Authorization_Date', 'Industry', 'Category', 'Location_X', 'Location_Y']\ncompanies_info.head()","41b67636":"# Save the table as a separate file.\ncompanies_info.to_csv('Processed_seoul_pollutants_companies_information.csv')","50c4949b":"pollution_monitors = pd.read_csv('..\/input\/seoul-air-qualit-data-extended\/seoul_air_pollution_monitors_information.csv', header=0)\npollution_monitors.head()","22708ff3":"pollution_monitors.columns = ['Monitor_Code', 'Monitor_Name', 'Address', 'Order', 'Authorized_Code']\npollution_monitors = pollution_monitors.iloc[:25, :]\npollution_monitors.shape","05cdfaf6":"for index, row in pollution_monitors.iterrows():\n    if pollution_monitors.iloc[index, 1] in gu_list_kor:\n        i = gu_list_kor.index(pollution_monitors.iloc[index, 1])\n        pollution_monitors.iloc[index, 1] = gu_list_eng[i]\n\npollution_monitors.to_csv('Processed_seoul_air_pollution_monitors_information.csv')\npollution_monitors.head()","372ca719":"### Korean version of the background reference (For Korean readers)\n\n\u25cb \ud1b5\uacc4\uac1c\uc694 \n* \ud1b5\uacc4\uba85 : \ud658\uacbd\uc624\uc5fc\ubb3c\uc9c8 \ubc30\ucd9c\uc2dc\uc124(\ub300\uae30) \n* \ud1b5\uacc4\uc885\ub958 : \uc11c\uc6b8\uc2dc \ub300\uae30\uc624\uc5fc\ubb3c\uc9c8 \ubc30\ucd9c\uc2dc\uc124 \ud604\ud669\uc744 \uc81c\uacf5\ud558\ub294 \uc77c\ubc18\u318d\ubcf4\uace0\ud1b5\uacc4 \n* \uc791\uc131\ubaa9\uc801 : \uc11c\uc6b8\uc2dc \ud658\uacbd\uc624\uc5fc\ubb3c\uc9c8 \ubc30\ucd9c\uc2dc\uc124 \uc2e4\ud0dc\ub97c \ud30c\uc545\ud558\uc5ec \uc2dc\uc124\uc758 \ud6a8\uc728\uc801\uc778 \uad00\ub9ac\u318d \n\uc9c0\ub3c4 \ubc0f \ud658\uacbd\ubcf4\uc804\ub300\ucc45 \uc218\ub9bd\uc744 \uc704\ud55c \uae30\ucd08\uc790\ub8cc\ub97c \uc81c\uacf5\ud558\ub294 \uac83\uc744 \ubaa9\uc801\uc73c\ub85c \ud568 \n* \uc870\uc0ac\uccb4\uacc4 : \uc790\uce58\uad6c \u2192 \uc2dc\ub3c4 \u2192 \ud658\uacbd\ubd80 \n* \uacf5\ud45c\uc8fc\uae30 : \uc815\uae30(\ub9e4\ub144, 12\uc6d4 \uae30\uc900) \n* \uacf5\ud45c\ubc94\uc704 : \uc9c0\uc5ed- \uc11c\uc6b8\uc2dc \ubc0f \uc790\uce58\uad6c \n\ub0b4\uc6a9 - \uc11c\uc6b8\uc2dc \ub300\uae30\uc624\uc5fc\ubb3c\uc9c8 \ubc30\ucd9c\uc2dc\uc124(1\uc885~5\uc885) \uac1c\uc18c \ub4f1 \n\n\u25cb \uc6a9\uc5b4\uc124\uba85 \n* \ub300\uae30\uc624\uc5fc\ubb3c\uc9c8 : \ub300\uae30\uc624\uc5fc\uc758 \uc6d0\uc778\uc774 \ub418\ub294 \uac00\uc2a4\u318d\uc785\uc790\uc0c1 \ubb3c\uc9c8 \ub610\ub294 \uc545\ucde8\ubb3c\uc9c8\ub85c\uc11c \n\ud658\uacbd\ubd80\ub839\uc774 \uc815\ud558\ub294 \uac83 \n\n\u25cb \uae30 \ud0c0 \n* \uc0ac\uc5c5\uc7a5\uc5d0\uc11c \ubc30\ucd9c\ub418\ub294 \uc624\uc5fc\ubb3c\uc9c8\ubc30\ucd9c\ub7c9\uc5d0 \ub530\ub77c 1~5\uc885\uc73c\ub85c \uad6c\ubd84   \n1\uc885 : \uc5f0\uac04 \uc624\uc5fc\ubb3c\uc9c8\ubc30\ucd9c\ub7c9\uc774 80\ud1a4\uc774\uc0c1\uc774\uac70\ub098 1\uc77c \ud3c9\uade0 \ud3d0\uc218\ubc30\ucd9c\ub7c9 2,000\u33a5\uc774\uc0c1   \n2\uc885 : \uc5f0\uac04 \uc624\uc5fc\ubb3c\uc9c8\ubc30\ucd9c\ub7c9\uc774 20\ud1a4\uc774\uc0c1 80\ud1a4\ubbf8\ub9cc\uc774\uac70\ub098, 1\uc77c\ud3c9\uade0 \ud3d0\uc218\ubc30\ucd9c\ub7c9 700\u33a5\uc774\uc0c1 2,000\u33a5\ubbf8\ub9cc   \n3\uc885 : \uc5f0\uac04 \uc624\uc5fc\ubb3c\uc9c8\ubc30\ucd9c\ub7c9\uc774 10\ud1a4\uc774\uc0c1 20\ud1a4\ubbf8\ub9cc\uc774\uac70\ub098 1\uc77c\ud3c9\uade0 \ud3d0\uc218\ubc30\ucd9c\ub7c9 200\u33a5\uc774\uc0c1 700\u33a5\ubbf8\ub9cc   \n4\uc885 : \uc5f0\uac04 \uc624\uc5fc\ubb3c\uc9c8\ubc30\ucd9c\ub7c9\uc774 2\ud1a4\uc774\uc0c1 10\ud1a4\ubbf8\ub9cc\uc774\uac70\ub098 1\uc77c\ud3c9\uade0 \ud3d0\uc218\ubc30\ucd9c\ub7c9 50\u33a5\uc774\uc0c1 200\u33a5\ubbf8\ub9cc   \n5\uc885 : \uadf8\uc678 \uae30\ud0c0 \ubc30\ucd9c\uc2dc\uc124 \ub610\ub294 \uc18c\uc74c\uc9c4\ub3d9 \ubc30\ucd9c\uc2dc\uc124 \uc0ac\uc5c5\uc7a5, \ud3d0\uc218\ubc30\ucd9c\ub7c9\uc5d0\ub294 \n\uc6a9\uc218 \uc0c1\uc6a9\ub7c9\uc744 \uae30\uc900\ud568   \n\n\u25cb \ucd9c \ucc98 : \uc11c\uc6b8\ud2b9\ubcc4\uc2dc \uae30\ud6c4\ub300\uae30\uacfc \n\n\u25cb \ub2f4 \ub2f9 : \uc11c\uc6b8\ud2b9\ubcc4\uc2dc \ud1b5\uacc4\ub370\uc774\ud130\ub2f4\ub2f9\uad00","aa1fbc06":"Let's change the column names of both tables.","6b9ce430":"Now, all the district names are changed to Korean! As you can notice, there is still some Korean left. These are additional areas that the government determined to collect data from. I do not need these regions, as it is enough to analyze the official districts (shown on the map in the introduction section). So I can simply remove the rows that are additional regions in one single line of code:","39027e8c":"All the datasets are ready to go! I will delve into these processed data tables in the next kernal, where I will analyze data, create visualizations and maps. Hopefully, I will be able to find meaningful patterns in the data. Changing the language of the data was somewhat a tedious task, but also a meaningful one. ","f69ed768":"## Thanks for reading this kernal!\nI hope this kernal gives kagglers an idea of how data processing techniques are used on datasets. There are a lot of other techniques that I did not include (not needed for this particular project), such as changing text to categorical values, transposing the table, replacing NaNs with 0, mean value, or removing the rows entirely, etc. You can look at other great kernals in Kaggle. \n\nIf you found this useful, please don't forget to upvote or leave a comment :) I am also very willing to receive critical feedback and notes on how to improve. \n\n**IMPORTANT: Feel free to use the processed data tables to analyze Seoul's Air Quality on your own! You can view the tables in the 'output' section of this kernel page. You can download the data, or create a new kernel based on it.**\n\n## Follow-up Kernel\nHere is a link to the kernel which uses processed data to analyze Seoul's air quality.","e329f174":"Because I can understand both Korean and English, I manually translated the column names and changed them to English. Now, let's change the Korean names for districts under the column name 'Place Measured.'\n\nBelow are the list of district names in both Korean and English, in correct order.","6861fafe":"As mentioned before, the above table shows the number of factories in each category for each district, over the course of multiple years. How many years are there?","8c633aef":"Currently, the table is very messy, with a lot of Korean text. The table also contains a lot of unnessary columns. What I need is the name of the business, its category (of air-pollution, from 1 to 5), and its location data. Let's take a look at the columns.","1a379bc0":"I'm almost there - I need to change the district names from Korean to English:","45572825":"You can see that there are some NaN values. I will deal with these null values later. \n\nBelow is code that allows me to visuallize the history of a specific district. I can choose one of the columns to display on the y-axis, plotted against the year. I used matplotlib library to define a function. A function is defined so that I can efficiently carry out the same task with just one line of code, which is calling the function with the arguments I want to input. ","47b10a4a":"---------\n## Third Dataset\n\nThis dataset shows all the air-pollution monitors and their locations in Seoul.","e8c7ee59":"### Some initial data exploration\n\nBefore I move onto process the remaining two data tables, let's do some initial analysis of the processed 'yearly' table. You can utilize the same techniques to gain insights into data efficiently. ","761b1161":"You can notoice that the indexes are showing from 4, 5, 6, and onward. I need to reset the index so that it is more accessible later on. ","f8c427a8":"Do not try to understand what all the text means as of now! You will be able to follow along step-by-step on how the language is changed to be understandable. \n\nBelow is a dataset showing the daily air pollution in Seoul.","b3a78365":"Now, I cannot change the individual values, as I would have to manually go through every row and translate. What is most important is being able to plot the location of these businesses and know their category, so there is no need to translate the name of the businesses or the street address.\n\nThis data table will be further processed in the next kernel I write, which is the analysis part. ","54b7e842":"Now all the datasets are processed and saved as separate files.","b6e1749e":"From here, I am going to drop unnecessary columns by using the drop() function of Pandas.","029de643":"# 3. Import and Process more Datasets\n\nIn addition to the data on yearly, monthly, and daily air pollution in Seoul, I decided to use another dataset that shows all the businesses Seoul that contribute to air pollution. This could be used to see if there are any districts with particularly many air-polluting factories or businesses, and the data is also great for trying out mapping. Before I import the data, I need to explain some background references to understand the data correctly. ","29b5400d":"### Processing the remaining two data tables\nI can use the identical techniques to process the remaining tables. The only difference between the tables is the frequency of data collection. The 'monthly' dataset collected data monthly over the course of multiple years.\n\nJust to take a look at both datasets again:","203c3879":"There are 25 monitors in total. Let's change the names of each district to English, and save it.","ff4e10fc":"Now, I will get rid of the unnecessary labels in Korean, and change them to English. If you see the final product, you will be understand the data. ","4da9e6b4":"## What additional data will be imported?\nThree datasets. \n\n* The first dataset I will import is specific to Seoul, showing a sum of all the businesses of each category for each district, over the course of multiple years. \n* The second dataset details the specific names of every air-polluting business in the whole of South Korea, as well as its geographical location. \n* The third dataset contains information about all air-pollution monitors in Seoul. This might be useful in understand the status of Seoul's response to air pollution. \n\nLet's import the first dataset.\n\n-------------\n## First Dataset (In addition to the data imported above)","c2118e37":"# 2. Data Pre-processing\nNow that all the data is imported, it is time to process it.   \nHere are the tasks I need to perform:\n* Change Korean text to English\n* Do some initial analysis to get an understanding of each data table\n* \n\n\nI will first change the header names from Korean to English:\n\n\uc774\uc0b0\ud654\uc9c8\uc18c: $NO_2$ Nitrogen Dioxide  \n\uc624\uc874\ub18d\ub3c4: Ozone  \n\uc77c\uc0b0\ud654\ud0c4\uc18c: $CO$ Carbon Monoxide  \n\uc544\ud669\uc0b0\uac00\uc2a4: $SO_2$ Sulfur Dioxide  \n\ubbf8\uc138\uba3c\uc9c0: PM-10   \n\ucd08\ubbf8\uc138\uba3c\uc9c0: PM-2.5  \n:: The measuring unit of PM-10 and PM-2,5 is (\u338d\/\u33a5).\n\nBelow, I set the column names of the table 'yearly' to the English names.","8ac5a1c6":"The above shows all the districts, as well as the number of districts represented. ","a3e1b683":"--------\n## Second Dataset\nNow, let's import the second dataset.","c56381b6":"Same process of changing the district names from Korean to English, and then removing any additional regions. ","6457ebf8":"Now, let's save this processed data as a new file:","8f6a9d25":"# 1. Import Libraries and Datasets\n\nHere are the python libraries that will be used:","196d03c6":"# Exploring Seoul's Air Quality \ud83c\uddf0\ud83c\uddf7 by each neighborhood - Data Processing\n\nWelcome to this kernel! \ud83e\udd73\n\n**If you want to learn data processing techniques in Python using various libraries, or you want to see an example of analyzing air quality data, you're in the right place!** \n\nIn this kernal, I will process data pulled from two datasets ([Dataset 1](https:\/\/www.kaggle.com\/sangwookchn\/seouls-air-quality-and-sources-of-pollution#seoul_daily_average_air_pollution.csv), [Dataset 2](https:\/\/www.kaggle.com\/sangwookchn\/seoul-air-qualit-data-extended)), which all explore air quality in Seoul and South Korea as a whole. **This is a significant task, as the data from open data portals of Korea are often in Korean, which means foreigners would have a hard time trying to analyze such data.** This translated and processed version of air quality data can be used by foreigners who are interested in studying the air quality of Korea.\n\nThis kernal might be useful to anyone who wants to see how data processing works in real examples, and I will add explanations and resources to help learning. The techniques used in this kernal can be applied to any other datasets. I am still learning how to most effectively carry out data science projects, so the methods used here might not be perfectly efficient. **Please let me know if there are better methods that I need to be aware of!**\n\nI have to note that much of the text in the original (unedited) data tables are in Korean, as the data was pulled from the Open Data Portal of Korea. I changed most of the texts into English for the purpose of future analysis, which is shown in this kernel.\n\nThe prepared data from this kernel will be used in a new kernel to begin analysis. Here is the link to the kernel (coming soon).\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a2\/Map_Seoul_districts_de.png\" width=\"600\"><\/img>  \n\nReference: this is a map of all the districts in Seoul. There is be a part in this kernal where I change the names of districts in Korean to English. \n\n# Contents\n* Import Libraries and Datasets\n* Data Preprocessing\n    * Some initial data exploration\n* Import three more separate datasets that are different from the data already processed.\n","18c3b148":"Oops, this is not how i want it to look like. It seems that '\\t' is the separator in the txt file. So:","86049216":"Now, the following code iterates through every row and changes the district in Korean to a corresponding English word.","e57ea555":"Now, to allow users to understand, I will change the column names to English.","571b8902":"### What kind of data is imported?\nI will import three data tables under the name of 'yearly', 'monthly', and 'daily'. \n\nBelow is a data table that shows the monthly average air pollution in Seoul. Currently all the text is in Korean, as it is unprocessed. It will be changed into English after all the relevant datasets are imported.","82f7a6c6":"The dataset reports on all the businesses that emit air pollutants in Seoul. The Seoul Open Data Portal said it aims to use this data to understand the status of emission of air-pollutants for effective management of businesses, and also use this as a foundational reference to come up with air-quality management policies. \n\nEach business is categorized into one of the five categories:\n\n:: Information about daily wastewater discharge as one of the criteria is omitted, as I am only concerned with total yearly emission of pollutants.\n* Category 1: Total yearly emission of pollutants is greater than or equal to 80 tons\n* Category 2: Total yearly emission of pollutants is greater than or equal to 20 tons, and less than 80 tons.\n* Category 3: Total yearly emission of pollutants is greater than or equal to 10 tons, and less than 20 tons.\n* Category 4: Total yearly emission of pollutants is greater than or equal to 2 tons, and less than 10 tons.\n* Category 5: Other businesses that emit pollutants or create sound pollution. ","e4204196":"I can also visualize other pollutants of other districts. ","dc4a6163":"Below is a dataset showing the yearly air pollution in Seoul.","8aa0ea5f":"Now, let's try looking at the history of air pollution of a specific district. Nowon-gu is one of the districts located in the northern part of Seoul, which is also where I came from. ","0fc444ac":"The table has data from the year 1987 to 2019."}}