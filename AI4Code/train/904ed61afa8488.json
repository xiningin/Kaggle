{"cell_type":{"cec6809f":"code","36752c84":"code","2e1dc7ad":"code","99a234ad":"code","f6fa2ca4":"code","a1414b83":"code","61d7c1c3":"code","a6e1a71d":"code","178de1ff":"code","2534e2c8":"code","f5b29fc1":"code","8bfa0057":"code","d866c0f4":"code","615f5184":"code","ddd4a9c8":"code","a0dda815":"code","26347ca8":"code","cb6cadd8":"code","8536dcd4":"code","7755848f":"code","0aee2258":"code","e5dfe57b":"code","e3967e11":"code","de5fb8db":"code","809adc5d":"code","bdbe3270":"code","1c366e8d":"code","b3df762c":"code","3b5927c5":"code","1b39e122":"code","61cc8de3":"code","0d58768b":"code","5c568a8d":"code","3bb52d51":"markdown","44a51029":"markdown","2036ac5c":"markdown"},"source":{"cec6809f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","36752c84":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\n\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n","2e1dc7ad":"churn = pd.read_csv('\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv')","99a234ad":"churn.head()","f6fa2ca4":"#churn[cat_col].head()\ndf = churn\n# Since surname, consumerid and rownumber does not have any impact w.r.t Exited, dropping.\ndf = churn.drop(['RowNumber','CustomerId','Surname'], axis = 1)","a1414b83":"# Checking missing values \n#churn.info()\ndef num_cat_features(df):\n    num_cols = []\n    cat_cols = []\n    s= df.dtypes\n    for i in s.index:\n        if (s[i] == 'int64' or s[i] == 'float64'):\n            num_cols.append(i)\n        elif s[i]== 'object':\n            cat_cols.append(i)\n        else:\n            pass\n    return num_cols, cat_cols\n\nnum_col, cat_col = num_cat_features(df)","61d7c1c3":"df[num_col].head()\ndf[cat_col].head()","a6e1a71d":"# Dummies in Geography and Gender\ndf_cat = df[cat_col]\ngeo = pd.get_dummies(df_cat['Geography'], prefix = 'Geo')\ngender = pd.get_dummies(df_cat['Gender'])\ndf.drop(cat_col,axis =1, inplace = True)\ndf = pd.concat([geo,gender,df], axis =1 )\ndf.head()","178de1ff":"#Scaling numeric columns\ncols_scale = ['CreditScore','Tenure','Balance','NumOfProducts', 'EstimatedSalary']","2534e2c8":"plt.figure(figsize = (15,15))\nsns.heatmap(df.corr(), annot = True)","f5b29fc1":"sns.set(style = \"darkgrid\")\nfig = plt.figure(figsize = (20,20))\nax1 = fig.add_subplot(3,3,1)\nax1. set_title(\"M vs F\")\n\nax2 = fig.add_subplot(3,3,2)\nax2. set_title(\"M vs F - Exited\")\n\nsns.barplot(x = churn['Gender'].value_counts().sort_index().index,y = churn['Gender'].value_counts().sort_index().values, ax= ax1 )\nsns.countplot(x = 'Exited', hue = 'Gender', data = churn, ax = ax2)\n","8bfa0057":"fig = plt.figure(figsize = (20,18))\nax3 = fig.add_subplot(3,3,1)\nax3.set_title(\"Geos\")\n\nax4 = fig.add_subplot(3,3,2)\nax4.set_title(\"Geos - Exited\")\n\nsns.barplot(x = churn['Geography'].value_counts().sort_index().index,y = churn['Geography'].value_counts().sort_index().values, ax = ax3)\nsns.countplot(x = 'Exited', hue = 'Geography', data = churn, ax = ax4)","d866c0f4":"fig = plt.figure(figsize = (20,18))\nax5 = fig.add_subplot(3,3,1)\nax5.set_title(\"Product\")\n\nax6 = fig.add_subplot(3,3,2)\nax6.set_title(\"Product - Exited\")\n\nsns.barplot(x = churn['NumOfProducts'].value_counts().sort_index().index,y = churn['NumOfProducts'].value_counts().sort_index().values, ax = ax5)\nsns.countplot(x = 'Exited', hue = 'NumOfProducts', data = churn, ax = ax6)","615f5184":"churn.head()","ddd4a9c8":"plt.figure(figsize = (10,7))\nsns.distplot(churn['Age'], kde = False ,bins = 10)\nplt.ylabel(\"Counts\")\n","a0dda815":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\n","26347ca8":"df.head()","cb6cadd8":"X = df.drop('Exited', axis =1)\ny = df['Exited']","8536dcd4":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","7755848f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)","0aee2258":"# Logistic Regression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n# Accuracy on Training set\nfrom sklearn.model_selection import cross_val_predict\ny_prob_train_lr = cross_val_predict(log_reg, X_train, y_train, cv = 10, method = 'decision_function')\n\n# y_pred_train_lr = log_reg.predict(X_train)\n# y_prob_train_lr = log_reg.predict_proba(X_train)\n\nfrom sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score ,confusion_matrix\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_lr)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_lr)\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - Logistic Regression - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall - Logistic Regression - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Logistic Regression - Training\")\n\n\nlr_auc_score_train = roc_auc_score(y_train,y_prob_train_lr ) # 0.76\n# lr_auc_score_train\n\n","e5dfe57b":"# Decision Tree Classifier\ndtree_clf = DecisionTreeClassifier()\ndtree_clf.fit(X_train, y_train)\n# Accuracy on Training set\nfrom sklearn.model_selection import cross_val_predict\ny_prob_train_dtree = cross_val_predict(dtree_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_dtree[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_dtree[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - Decision Tree Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Decision Tree Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Decision Tree Classifier- Training\")\n\n\ndtree_auc_score_train = roc_auc_score(y_train,y_prob_train_dtree[:,-1] ) # 0.67\n# dtree_auc_score_train ","e3967e11":"# Linear SVC  Classifier\nsvc_clf = LinearSVC(C = 1.0,random_state = 12, max_iter = 1500, loss = 'squared_hinge')\nsvc_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_svc = cross_val_predict(svc_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_svc)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_svc)\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - Linear SVC Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Linear SVC Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Linear SVC Classifier- Training\")\n\n\nsvc_auc_score_train = roc_auc_score(y_train,y_prob_train_svc) # 0.77\n# svc_auc_score_train ","de5fb8db":"# SVM  Classifier\nfrom sklearn.svm import SVC\nsvm_clf = SVC(random_state = 12)\nsvm_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_svm = cross_val_predict(svm_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_svm)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_svm)\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - SVM Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  SVM Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - SVM Classifier- Training\")\n\n\nsvm_auc_score_train = roc_auc_score(y_train,y_prob_train_svm) # 0.82\n# svm_auc_score_train ","809adc5d":"# Random Forest  Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrdm_frst_clf = RandomForestClassifier(random_state = 12, max_depth = 7, n_estimators=20)\nrdm_frst_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_forst = cross_val_predict(rdm_frst_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_forst[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_forst[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - Random Forest Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Random Forest Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Random Forest Classifier - Training\")\n\n\nfrst_auc_score_train = roc_auc_score(y_train,y_prob_train_forst[:,-1]) # 0.85\n# frst_auc_score_train ","bdbe3270":"# Stochastic Gradient Descent  Classifier\nfrom sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(alpha = 1,random_state = 12, penalty = 'l2', loss = 'modified_huber')\nsgd_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_sgd = cross_val_predict(sgd_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_sgd)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_sgd)\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - SGD Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  SGD Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - SGD Classifier - Training\")\n\n\nsgd_auc_score_train = roc_auc_score(y_train,y_prob_train_sgd) # 0.77\n# sgd_auc_score_train ","1c366e8d":"# KNN  Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n                     weights='distance')\nknn_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_knn = cross_val_predict(knn_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_knn[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_knn[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - KNN Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  KNN Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - KNN Classifier - Training\")\n\n\nknn_auc_score_train = roc_auc_score(y_train,y_prob_train_knn[:,-1]) # 0.78\n# sgd_auc_score_train ","b3df762c":"# XGboost  Classifier\nimport xgboost as xgb\nxgb_clf = xgb.XGBClassifier(random_state = 12)\nxgb_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_xgb = cross_val_predict(xgb_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_xgb[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_xgb[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision \/ Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision \/ Recall\")\nplt.title(\"Precision \/ Recall vs Threshold - XGB Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  XGB Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - XGB Classifier - Training\")\n\n\nxgb_auc_score_train = roc_auc_score(y_train,y_prob_train_xgb[:,-1]) # 0.86\n# xgb_auc_score_train ","3b5927c5":"# Performance on Test data\ny_pred_log = log_reg.predict(X_test)\ncm_log = confusion_matrix(y_test, y_pred_log)\n\ny_pred_dtree = dtree_clf.predict(X_test)\ncm_dtree = confusion_matrix(y_test, y_pred_dtree)\n\ny_pred_lsvc = svc_clf.predict(X_test)\ncm_lsvc = confusion_matrix(y_test, y_pred_lsvc)\n\ny_pred_svm = svm_clf.predict(X_test)\ncm_svm = confusion_matrix(y_test, y_pred_svm)\n\ny_pred_frst = rdm_frst_clf.predict(X_test)\ncm_frst = confusion_matrix(y_test, y_pred_frst)\n\ny_pred_sgd = sgd_clf.predict(X_test)\ncm_sgd = confusion_matrix(y_test, y_pred_sgd)\n\ny_pred_knn = knn_clf.predict(X_test)\ncm_knn = confusion_matrix(y_test, y_pred_knn)\n\ny_pred_xgb = xgb_clf.predict(X_test)\ncm_xgb = confusion_matrix(y_test, y_pred_xgb)","1b39e122":"fig = plt.figure(figsize = (15,15))\n\nax1 = fig.add_subplot(3,3,1)\nax1.set_title(\"Logistic Regression\")\n\nax2 = fig.add_subplot(3,3,2)\nax2.set_title(\"Decision Tree Classifier\")\n\nax3 = fig.add_subplot(3,3,3)\nax3.set_title(\"Linear SVC Classifier\")\n\nax4 = fig.add_subplot(3,3,4)\nax4.set_title(\"SVM Classifier\")\n\nax5 = fig.add_subplot(3,3,5)\nax5.set_title(\"Random Forest Classifier\")\n\nax6 = fig.add_subplot(3,3,6)\nax6.set_title(\"SGD Classifier\")\n\nax7 = fig.add_subplot(3,3,7)\nax7.set_title(\"KNN Classifier\")\n\nax8 = fig.add_subplot(3,3,8)\nax8.set_title(\"XGB Classifier\")\n\nsns.heatmap(cm_log, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax1)\nsns.heatmap(cm_dtree, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax2)\nsns.heatmap(cm_lsvc, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax3)\nsns.heatmap(cm_svm, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax4)\nsns.heatmap(cm_frst, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax5)\nsns.heatmap(cm_sgd, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax6)\nsns.heatmap(cm_knn, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax7)\nsns.heatmap(cm_xgb, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax8)\n","61cc8de3":"# Testing Scores\nlog_acc =   (cm_log[0,0] + cm_log[1,1]) \/ cm_log.sum()\ndtree_acc = (cm_dtree[0,0] + cm_dtree[1,1]) \/ cm_dtree.sum()\nlsvc_acc = (cm_lsvc[0,0] + cm_lsvc[1,1]) \/ cm_lsvc.sum()\nsvm_acc = (cm_svm[0,0] + cm_svm[1,1]) \/ cm_svm.sum()\nfrst_acc = (cm_frst[0,0] + cm_frst[1,1]) \/ cm_frst.sum()\nsgd_acc = (cm_sgd[0,0] + cm_sgd[1,1]) \/ cm_sgd.sum()\nknn_acc = (cm_knn[0,0] + cm_knn[1,1]) \/ cm_knn.sum()\nxgb_acc = (cm_xgb[0,0] + cm_xgb[1,1]) \/ cm_xgb.sum()\n","0d58768b":"acc_list = [log_acc,dtree_acc,lsvc_acc,svm_acc,frst_acc,sgd_acc,knn_acc,xgb_acc]\nmodels = ['Logistic Regression', 'Decision Tree Classifier', 'Linear SVC', 'SVM', 'Random Forest Classifier', 'SGDClassifier', 'KNN Classifier','XGboost Classifier']\n\nmodel_accuracy = {}\nmodel_accuracy['Model'] = models\nmodel_accuracy['Scores'] = acc_list\n\naccuracy_df = pd.DataFrame.from_dict(model_accuracy)\naccuracy_df.head()\n","5c568a8d":"plt.figure(figsize = (10,7))\nax = sns.barplot(x = 'Model', y = 'Scores', data = accuracy_df)\nplt.xticks(rotation='vertical')\nplt.ylim([0,1])\nplt.title(\"Accuracy Scores\")\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() \/ 2., p.get_height()),\n             ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')  #horizontal bars\n\n\n\n","3bb52d51":"**Logistic Regression**","44a51029":"More females exit than males. ","2036ac5c":"**Decision Tree Classifier**"}}