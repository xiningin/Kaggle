{"cell_type":{"427d545d":"code","e9f67856":"code","e596bfa8":"code","4d2937a9":"code","b5bf89bf":"code","db98d874":"code","19951b0c":"code","c78cc28c":"code","6bc26888":"code","2350df5f":"code","4c7d412a":"code","2926ba79":"code","db1eec43":"code","66a87ed0":"code","af4d5909":"code","5ecc9668":"code","c61d66a9":"code","595cad34":"code","9f8cc267":"code","b60e8bf7":"code","f38d8e2a":"code","2b743d4f":"code","2b82978b":"code","0997fc9d":"code","4de3bfae":"code","f78c4d64":"code","7137935f":"code","31196852":"code","7d57e6cb":"code","23e046f3":"code","ddc69187":"code","3ea476d5":"code","6dd05e9b":"code","8f369b38":"code","7a1b083b":"code","7c2d12a7":"code","89e145e8":"code","2175b7cb":"code","3f17ca83":"code","fbc1a31c":"code","ec31f84c":"code","edf4b483":"code","013283f5":"code","ee428a8f":"code","485ca8de":"code","a28e9ba4":"code","86dc669e":"code","362d217e":"code","8acdc2a3":"code","bfc210c6":"code","8cb84221":"code","a08f391c":"code","2ad79b4b":"code","415b50b0":"code","ef08f074":"code","3ca76ce1":"code","d5c16689":"code","25f2a826":"code","9d2d7036":"code","e48b939e":"code","52ccffcd":"code","15ea226e":"markdown","1a7efa25":"markdown","52487203":"markdown","342253bc":"markdown","dcf03c88":"markdown","ae5fdc2e":"markdown","98f29c30":"markdown","5482e963":"markdown","43381c4a":"markdown","8b552bd0":"markdown","098ed9ef":"markdown","8fe29e4c":"markdown","3092832d":"markdown","86a60a92":"markdown"},"source":{"427d545d":"import numpy as np \nimport pandas as pd \nfrom pathlib import Path\n\nimport pymc3 as pm\nimport arviz as az\n\nimport cufflinks as cf\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom ipywidgets import interact, interact_manual, fixed","e9f67856":"pd.set_option('display.max_rows', 500)\npd.set_option('use_inf_as_na', True)\ncf.set_config_file(offline=True, theme='pearl');\npath = Path(\"..\/input\/novel-corona-virus-2019-dataset\/\")","e596bfa8":"master_df = pd.read_csv(path\/'covid_19_data.csv')","4d2937a9":"recovered_df = (pd.read_csv(path\/'time_series_covid_19_recovered.csv')\n                .drop(columns=['Lat', 'Long'])\n                .groupby('Country\/Region')\n                .sum())\n\ndeaths_df = (pd.read_csv(path\/'time_series_covid_19_deaths.csv')\n             .drop(columns=['Lat', 'Long'])\n             .groupby('Country\/Region')\n             .sum())\n\nconfirmed_df = (pd.read_csv(path\/'time_series_covid_19_confirmed.csv')\n                .drop(columns=['Lat', 'Long'])\n                .groupby('Country\/Region')\n                .sum())","b5bf89bf":"sorted_country_list = confirmed_df.sort_values(by=confirmed_df.columns[-1], ascending=False).index.to_list()","db98d874":"@interact(country=sorted_country_list, threshold=(1, 1000, 10), fit=True)\ndef log_lin_visualise(country, fit, threshold=100):\n    \n    y = confirmed_df.filter(items=[country], axis=0).values.squeeze(0)\n    y = np.log(y[y > threshold])\n    x = np.arange(1, y.shape[0] + 1)\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(x, y, label='Observed')\n    \n    if fit:\n\n        lr = LinearRegression(normalize=True)\n        lr.fit(X=x.reshape(-1, 1) , y=y)\n        \u03b1, \u03b2 =  lr.intercept_, lr.coef_\n\n        y_fitted = lr.predict(X=x.reshape(-1, 1))\n\n        print(\"Solving linear regression using OLS ... \")\n        print(f\"* r2_score = {round(r2_score(y, y_fitted), 2)}\")\n        print(f\"* mean_squared_error = {round(mean_squared_error(y, y_fitted), 2)}\")\n\n        plt.plot(x, y_fitted, label=f\"{round(\u03b1, 2)} + {round(\u03b2[0], 2)}*x\")\n\n    plt.xlabel(f'Days Since {threshold}th Case')\n    plt.ylabel('Natural Logarithm of Confirmed Cases')\n    plt.legend()\n    plt.title(country)\n    plt.show()\n    plt.close()","19951b0c":"country = 'US'\nthreshold = 100\n\ny = confirmed_df.filter(items=[country], axis=0).values.squeeze(0)\ny = np.log(y[y > threshold])\nx = np.arange(1, y.shape[0] + 1)\n\n\nwith pm.Model() as unpooled_model:\n    \n    \n    # priors\n    \u03b1 = pm.Normal(name='\u03b1', mu=int(np.log(threshold)), sd=10)\n    \u03b2 = pm.Normal(name='\u03b2')\n    \n    # error\n    \u03c3 = pm.HalfNormal(name='\u03c3', sd=10)\n    \n    # expected value\n    \u03bc = pm.Deterministic(name='\u03bc', var= \u03b1 + \u03b2*x)\n    \n    # liklihood == 'prior_predictive'\n    pm.Normal(name=country, mu=\u03bc, sd=\u03c3, observed=y)\n    \n    pm.model_to_graphviz().save('unpooled_model.png')\n    \npm.model_to_graphviz(unpooled_model)","c78cc28c":"## shape-sanity checks\n\n# ((\u03b2.random()*x) + \u03b1.random()).shape\n# Y[4].shape\n\n# idx = [0, 0, 1, 1, 1, 4]\n# \u03b1.random()[idx]","6bc26888":"with unpooled_model:\n    \n    # sampling liklihood\n    prior = pm.sample_prior_predictive()\n    \n    # posterior\n    trace = pm.sample()\n    \n    # predictions == 'posterior_predictive'\n    pred = pm.sample_posterior_predictive(trace)","2350df5f":"unpooled = az.from_pymc3(trace=trace, prior=prior, posterior_predictive=pred, model=unpooled_model)\nprior_vars = ['\u03b1', '\u03b2', '\u03c3']\nunpooled","4c7d412a":"unpooled.posterior['\u03b1'].shape","2926ba79":"summary_df = az.summary(unpooled)\nsummary_df.to_csv(f'unpooled_{country}_summary.csv')","db1eec43":"az.plot_trace(data=unpooled, var_names=prior_vars);","66a87ed0":"az.plot_posterior(data=unpooled, var_names=prior_vars, group='posterior');","af4d5909":"az.plot_posterior(data=unpooled, var_names=prior_vars, group='prior');","5ecc9668":"az.plot_ppc(data=unpooled, group='posterior');","c61d66a9":"# pm.find_MAP(model=unpooled_model)","595cad34":"mean_priors = az.summary(unpooled).filter(items=prior_vars, axis=0)['mean']\ny_fitted = mean_priors['\u03b1'] + mean_priors['\u03b2']*x\n\nmean_priors","9f8cc267":"ci = 0.95\n\n\naz.plot_hpd(x=x, y=unpooled.posterior_predictive[country], credible_interval=ci)#, plot_kwargs={'label': f'Predictions ({ci})'});\n# az.plot_hpd(x=x, y=unpooled.posterior['\u03bc'], color='C2', credible_interval=ci)#, plot_kwargs={'label': f'Expectation ({ci})'});\nplt.plot(x, y, label='Observed');\nplt.plot(x, y_fitted, label=f\"{mean_priors['\u03b1']} + {mean_priors['\u03b2']}*x\", color='k');\n\nplt.xlabel(f'Days Since {threshold}th Case')\nplt.ylabel('Natural Logarithm of Confirmed Cases')\nplt.title(country)\nplt.legend()\nplt.show()\nplt.close()","b60e8bf7":"az.r2_score(y_true=y, y_pred=unpooled.posterior_predictive[country].data.reshape(-1, y.shape[0]))","f38d8e2a":"# az.plot_dist(unpooled.log_likelihood[country]);\n# az.plot_dist(unpooled.prior_predictive[country]);","2b743d4f":"## Mean of predicted values\n\ny_fitted = unpooled.posterior_predictive[country].data.reshape(-1, y.shape[0]).mean(axis=0)\nprint(f\"r2_score = {round(r2_score(y, y_fitted), 2)}\")\nprint(f\"mean_squared_error = {round(mean_squared_error(y, y_fitted), 2)}\")","2b82978b":"## Mean of expected values\n\n# y_fitted = unpooled.posterior['\u03bc'].data.reshape(-1, y.shape[0]).mean(axis=0)\n# print(f\"r2_score = {round(r2_score(y, y_fitted), 2)}\")\n# print(f\"mean_squared_error = {round(mean_squared_error(y, y_fitted), 2)}\")","0997fc9d":"# Data for all counties needs to be in similar dimensions.\n\ncumulative_threshold = 1e4 # to select countries\nthreshold = 100 # to select start_date\n\nhigh_confirmed_df = confirmed_df[confirmed_df.iloc[:, -1] > cumulative_threshold]\nhigh_confirmed_df = high_confirmed_df.where(cond=lambda x: x > threshold, other=np.nan) # or -1","4de3bfae":"# Dropping for now\n# high_confirmed_df = high_confirmed_df.drop(index=['China', 'Korea, South'])","f78c4d64":"majority = high_confirmed_df.shape[0]\/2\n\nhigh_confirmed_df.isna().sum().iplot(hline=majority,\n                                     xTitle='Date', yTitle=f'Countries below {threshold} cases', \n                                     title='Threshold Cases for Highly Infected Countries');","7137935f":"cross_over_date = (high_confirmed_df.isna().sum() < majority).idxmax()\ncross_over_date","31196852":"thresholded_high_confirmed_df = high_confirmed_df.iloc[:, high_confirmed_df.columns.to_list().index(cross_over_date):]\nthresholded_high_confirmed_df = thresholded_high_confirmed_df.dropna(how='any', axis=0)\nthresholded_high_confirmed_df = thresholded_high_confirmed_df.applymap(np.log)\n\nprint(thresholded_high_confirmed_df.shape)","7d57e6cb":"n_countries = thresholded_high_confirmed_df.shape[0]\ndate_points = thresholded_high_confirmed_df.shape[1]\nidx = np.repeat(a=np.arange(n_countries), repeats=date_points)","23e046f3":"x = np.arange(1, date_points + 1)\nX = np.stack([x]*n_countries, axis=0)\n\nY = thresholded_high_confirmed_df.values\n\nprint(X.shape, Y.shape)","ddc69187":"# vectorised implementation\n'''\nHere, \n    \u03bc.shape = (440,)\n    \u03c3[idx].shape = (440,) \n    Y.flatten().shape = (440,)\nData for each country is repeated, so first 40 points (index 0 to 39) are of first country, \nsecond 40 points (index 40 to 79) are of second country and so on.\n'''\n\n\ndef split_and_pack(labels, data, axis=2):\n    '''\n    Helper function to unpack values from a vectorised output\n    '''\n    splits = np.split(ary=data, axis=axis, indices_or_sections=len(labels))\n    d = dict(zip(labels, data))\n    return d\n    \n\nwith pm.Model() as pooled_model:\n\n    \n    X = pm.Data(name='X', value=X)\n    Y = pm.Data(name='Y', value=Y.flatten())\n    \n    # priors\n    \u03b1 = pm.Normal(name='\u03b1', mu=int(np.log(threshold)), sd=10, shape=n_countries)\n    \u03b2 = pm.Normal(name='\u03b2', sd=5, shape=n_countries)\n    \n    # error\n    \u03c3 = pm.HalfNormal(name='\u03c3', sd=10, shape=n_countries)\n    \n    # expected value\n    \n    \u03bc = pm.Deterministic(name='\u03bc', var= (\u03b1 + \u03b2*X.T).T.flatten())\n    \n    # liklihood == 'prior_predictive'\n    pm.Normal(name='pooled', mu=\u03bc, sd=\u03c3[idx], observed=Y)\n    \n    pm.model_to_graphviz().save('pooled_model.png')\n    \npm.model_to_graphviz(pooled_model)","3ea476d5":"# non-vectorised implementation\n# '''\n# All three parameters (mu, sd, observed) have to be of the same shape \/ broadcasteble\n# Here, \n#     \u03bc[i].shape = (40,)\n#     \u03c3[i].shape = (1,) # broadcasted to (40,)\n#     Y[i].shape = (40,)\n# '''\n\n# with pm.Model() as pooled_model:\n\n#     X = pm.Data(name='X', value=X)\n#     Y = pm.Data(name='Y', value=Y) # not using it since we will iterate over the dataframe\n    \n#     # priors\n#     \u03b1 = pm.Normal(name='\u03b1', mu=int(np.log(threshold)), sd=10, shape=n_countries)\n#     \u03b2 = pm.Normal(name='\u03b2', sd=5, shape=n_countries)\n    \n#     # error\n#     \u03c3 = pm.HalfNormal(name='\u03c3', sd=10, shape=n_countries)\n    \n#     # expected value -- Deterministic matrix \u03bc\n#     ## transpose is necessary because operations are performed row-major style\n# #     \u03bc = pm.Deterministic(name='\u03bc', var= (\u03b1 + \u03b2*X.T).T) \n    \n#     # liklihood == 'prior_predictive'\n#     for i, (index, row) in enumerate(thresholded_high_confirmed_df.iterrows()):\n        \n#         # use with Deterministic matrix \u03bc\n# #       pm.Normal(name=index, mu=\u03bc[i], sd=\u03c3[i], observed=row.values) \n        \n# #         \u03bc = \u03b1[i] + \u03b2[i]*x\n#         \u03bc = pm.Deterministic(name=f'\u03bc_{index}', var= \u03b1[i] + \u03b2[i]*X[i])  # to save \u03bc in the trace\n#         pm.Normal(name=index, mu=\u03bc, sd=\u03c3[i], observed=Y[i])  # or row.values\n            \n# pm.model_to_graphviz(pooled_model)","6dd05e9b":"## shape-sanity checks\n\n# ((\u03b2.random()*X.T) + \u03b1.random()).T.shape\n# Y[4].shape\n\n# idx = [0, 0, 1, 1, 1, 4]\n# \u03b1.random()[idx]","8f369b38":"with pooled_model:\n    \n    # sampling liklihood\n    prior = pm.sample_prior_predictive()\n    \n    # posterior\n    trace = pm.sample()\n    \n    # predictions == 'posterior_predictive'\n    pred = pm.sample_posterior_predictive(trace)","7a1b083b":"pooled = az.from_pymc3(trace=trace, prior=prior, posterior_predictive=pred, model=pooled_model)\nprior_vars = ['\u03b1', '\u03b2', '\u03c3']\npooled","7c2d12a7":"# pm.find_MAP(model=pooled_model)","89e145e8":"pooled.posterior['\u03b1'].shape # chains x samples x n_countries","2175b7cb":"summary_df = az.summary(pooled) \nsummary_df.to_csv('pooled_summary.csv')","3f17ca83":"countries = thresholded_high_confirmed_df.index.to_list()\nmeans = {var : split_and_pack(data=summary_df.filter(like=var, axis=0)['mean'], labels=countries, axis=0) for var in prior_vars }\nmeans_df = pd.DataFrame(means)\n\nmeans_df","fbc1a31c":"# az.plot_trace(data=pooled, var_names=prior_vars);","ec31f84c":"## Plotting posterior will give a combined view of all countries\n# az.plot_posterior(data=pooled, var_names=prior_vars, group='posterior');","edf4b483":"# az.plot_posterior(data=pooled, var_names=prior_vars, group='prior');","013283f5":"az.plot_forest(data=pooled, var_names=prior_vars, combined=True, credible_interval=0.99);","ee428a8f":"# posterior_predictive = split_and_pack(data=pooled.posterior_predictive['pooled'].data, labels=countries, axis=2) # not working??\nposterior_predictive = dict(zip(countries, np.split(ary=pooled.posterior_predictive['pooled'].data, axis=2, indices_or_sections=len(countries))))\n\nX_countrywise = split_and_pack(data=pooled.constant_data['X'].data, labels=countries, axis=0)\n\n# Y_countrywise = split_and_pack(data=pooled.constant_data['Y'].data, labels=countries, axis=0)\nY_countrywise = dict(zip(countries, np.split(ary=pooled.constant_data['Y'].data, axis=0, indices_or_sections=len(countries))))","485ca8de":"@interact(country=countries)\ndef plot_countrywise_posterior(country):\n    \n    ci = 0.95\n    \n    plt.figure(figsize=(15, 10))\n\n    az.plot_hpd(x=x, y=posterior_predictive[country], credible_interval=ci);\n    plt.plot(X_countrywise[country], Y_countrywise[country], label='Observed');\n    \n    y_fitted = means_df['\u03b1'][country] + means_df['\u03b2'][country]*X_countrywise[country]\n    \n    plt.plot(X_countrywise[country], y_fitted, label=f\"{means_df['\u03b1'][country]} + {means_df['\u03b2'][country]}*x\", color='k');\n\n    plt.xlabel(f'Days Since {threshold}th Case')\n    plt.ylabel('Natural Logarithm of Confirmed Cases')\n    plt.title(country)\n    plt.legend()\n    plt.show()\n    plt.close()\n    \n    bayesian_r2 = az.r2_score(y_true=Y_countrywise[country], y_pred=posterior_predictive[country].reshape(-1, Y_countrywise[country].shape[0]))\n    y_fitted_bayesian = posterior_predictive[country].reshape(-1, Y_countrywise[country].shape[0]).mean(axis=0)\n    print(f\"Bayesian r2_score = {round(bayesian_r2['r2'], 2)}\")\n    print(f\"Bayesian r2_score std = {round(bayesian_r2['r2_std'], 2)}\")\n    print('\\n')\n    print(f\"Point(mean) r2_score = {round(r2_score(Y_countrywise[country], y_fitted_bayesian), 2)}\")\n    print(f\"Point(mean) mean_squared_error = {round(mean_squared_error(Y_countrywise[country], y_fitted_bayesian), 2)}\")","a28e9ba4":"x = np.arange(1, date_points + 1)\nX = np.stack([x]*n_countries, axis=0)\n\nY = thresholded_high_confirmed_df.values\n\nprint(X.shape, Y.shape)","86dc669e":"# non-vectorised implementation\n'''\nAll three parameters (mu, sd, observed) have to be of the same shape \/ broadcasteble\nHere, \n    \u03bc[i].shape = (40,)\n    \u03c3[i].shape = (1,) # broadcasted to (40,)\n    Y[i].shape = (40,)\n'''\n\nwith pm.Model() as hierarchical_model:\n\n    X = pm.Data(name='X', value=X)\n    Y = pm.Data(name='Y', value=Y) # not using it since we will iterate over the dataframe\n    \n    # hyper-priors\n    \u03b1_\u03bc = pm.Normal(name='\u03b1_\u03bc', mu=int(np.log(threshold)), sd=10)\n    \u03b1_\u03c3 = pm.HalfNormal(name='\u03b1_\u03c3', sd=10)\n    \n    \u03b2_\u03bc = pm.Normal(name='\u03b2_\u03bc', sd=10)\n    \u03b2_\u03c3 = pm.HalfNormal(name='\u03b2_\u03c3', sd=10)\n    \n    # priors\n    \u03b1 = pm.Normal(name='\u03b1', mu=\u03b1_\u03bc, sd=\u03b1_\u03c3, shape=n_countries)\n    \u03b2 = pm.Normal(name='\u03b2', mu=\u03b2_\u03bc, sd=\u03b2_\u03c3, shape=n_countries)\n    \n    # error\n    \u03c3 = pm.HalfNormal(name='\u03c3', sd=10, shape=n_countries)\n    \n    # liklihood\n    for i, (index, row) in enumerate(thresholded_high_confirmed_df.iterrows()):\n        \n        \u03bc = pm.Deterministic(name=f'\u03bc_{index}', var= \u03b1[i] + \u03b2[i]*X[i])\n        pm.Normal(name=index, mu=\u03bc, sd=\u03c3[i], observed=Y[i])  # or observed=row.values\n        \n    pm.model_to_graphviz().save('hierarchical_model.png')\n            \npm.model_to_graphviz(hierarchical_model)","362d217e":"with hierarchical_model:\n    \n    # sampling liklihood\n    prior = pm.sample_prior_predictive()\n    \n    # posterior\n    trace = pm.sample()\n    \n    # predictions == 'posterior_predictive'\n    pred = pm.sample_posterior_predictive(trace)","8acdc2a3":"hierarchical = az.from_pymc3(trace=trace, prior=prior, posterior_predictive=pred, model=hierarchical_model)\nprior_vars = ['\u03b1', '\u03b2', '\u03c3']\nhierarchical","bfc210c6":"# pm.find_MAP(model=hierarchical_model)","8cb84221":"hierarchical.posterior['\u03b1'].shape # chains x samples x n_countries","a08f391c":"summary_df = az.summary(hierarchical) \nsummary_df.to_csv('hierarchical_summary.csv')","2ad79b4b":"countries = thresholded_high_confirmed_df.index.to_list()\nmeans = {var : split_and_pack(data=summary_df.filter(like=f\"{var}[\", axis=0)['mean'], labels=countries, axis=0) for var in prior_vars }\nmeans_df = pd.DataFrame(means)\n\nmeans_df","415b50b0":"# az.plot_trace(data=hierarchical, var_names=prior_vars);","ef08f074":"## Plotting posterior will give a combined view of all countries\n# az.plot_posterior(data=hierarchical, var_names=prior_vars, group='posterior');","3ca76ce1":"# az.plot_posterior(data=hierarchical, var_names=prior_vars, group='prior');","d5c16689":"az.plot_forest(data=hierarchical, var_names=prior_vars, combined=True, credible_interval=0.99);","25f2a826":"X_countrywise = split_and_pack(data=hierarchical.constant_data['X'].data, labels=countries, axis=0)\nY_countrywise = split_and_pack(data=hierarchical.constant_data['Y'].data, labels=countries, axis=0)","9d2d7036":"@interact(country=countries)\ndef plot_countrywise_posterior(country):\n    \n    ci = 0.95\n    \n    plt.figure(figsize=(15, 10))\n\n    az.plot_hpd(x=X_countrywise[country], y=hierarchical.posterior_predictive[country], credible_interval=ci);\n    plt.plot(X_countrywise[country], Y_countrywise[country], label='Observed');\n    \n    y_fitted = means_df['\u03b1'][country] + means_df['\u03b2'][country]*X_countrywise[country]\n    \n    plt.plot(X_countrywise[country], y_fitted, label=f\"{means_df['\u03b1'][country]} + {means_df['\u03b2'][country]}*x\", color='k');\n\n    plt.xlabel(f'Days Since {threshold}th Case')\n    plt.ylabel('Natural Logarithm of Confirmed Cases')\n    plt.title(country)\n    plt.legend()\n    plt.show()\n    plt.close()\n    \n    bayesian_r2 = az.r2_score(y_true=Y_countrywise[country], y_pred=hierarchical.posterior_predictive[country].data.reshape(-1, Y_countrywise[country].shape[0]))\n    y_fitted_bayesian = hierarchical.posterior_predictive[country].data.reshape(-1, Y_countrywise[country].shape[0]).mean(axis=0)\n    print(f\"Bayesian r2_score = {round(bayesian_r2['r2'], 2)}\")\n    print(f\"Bayesian r2_score std = {round(bayesian_r2['r2_std'], 2)}\")\n    print('\\n')\n    print(f\"Point(mean) r2_score = {round(r2_score(Y_countrywise[country], y_fitted_bayesian), 2)}\")\n    print(f\"Point(mean) mean_squared_error = {round(mean_squared_error(Y_countrywise[country], y_fitted_bayesian), 2)}\")","e48b939e":"datasets = {'unpooled' : unpooled,\n           'pooled' : pooled,\n           'hierarchical': hierarchical} ","52ccffcd":"az.plot_forest(data=list(datasets.values()), model_names=list(datasets.keys()), var_names=prior_vars, credible_interval=0.99, combined=True);\nplt.savefig('comparison.png')","15ea226e":"#### Observation\n\nWe can clearly observe a linear relationship between $ln(y)$ and $x$ for highly infected countries (except China and S. Korea)","1a7efa25":"## Rationale","52487203":"An exponential model is given by:\n\n$ y' = y_{0} * (1 + b)^x $\n\nwhere, $b$ is the growth rate\n\nBy taking a logarithmic transform, we obtain a (log-linear) regression model\n\n$ \\implies ln(y') = ln(y_{0}) + x*ln(1 + b)$\n\n$\\implies y = \\alpha + \\beta * x$","342253bc":"#### Preparing data \nFor both `pooled` and `hierarchical`","dcf03c88":"#### Finding appropriate start date for all data\nFor both `pooled` and `hierarchical`","ae5fdc2e":"Graphically, we can validate that a distribution follows a exponential growth model by plotting $ln(y)$ against $x$.\nIf the graph shows a linear relationship, we can solve for $\\alpha$ and $\\beta$ using linear regression techniques. \n\nValues for $a$ and $b$ can be obtained by:\n* $ y_{0} = e^{\\alpha}$\n* $ b = e^{\\beta} - 1$","98f29c30":"### Hierarchical Model\n\nShared hyper-priors but different priors for all countries","5482e963":"## Model","43381c4a":"### Pooled Model\n\nShared\/ grouped priors between all countries","8b552bd0":"## Objectives:\n\nTo implement an exponential model for CoVid-19 confirmed cases for every country.\nThe model may be implemented in three ways:\n1. Unpooled (with different priors for each country)\n2. Pooled (with same priors for each country)\n3. Hierarchical (with same hyper-priors, but different priors for each country)\n\nThis notebook shows all three implementations using pyMC3 and their analysis.\n\n\nA justification for using an exponential model is provided in the `Rationale` section.\n\nInspired from [Thomas Wiecki's CoVid-19](https:\/\/github.com\/twiecki\/covid19) notebooks.","098ed9ef":"**Note**: The notebook uses the `interact` widget. Please fork it and view in editor to interact with the output.","8fe29e4c":"### Unpooled Model\n\nDifferent priors for every country. \n\nThis model needs to be run separately for each country.","3092832d":"## To-Do:\n\n1. Implement a different model for China and S. Korea (preferably logistic growth model).\n2. Find the effect of intervention policy and try to determine the intervention date from the data.\n3. Comment your suggestions \ud83d\ude01.","86a60a92":"## Comparison"}}