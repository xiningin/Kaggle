{"cell_type":{"86b755eb":"code","cde7463e":"code","e25fbe7c":"code","58247cc6":"code","4ea65738":"code","f6646a65":"code","ad8892fb":"code","b2e19aa0":"code","c128eaf3":"code","e93ba8f2":"code","e525beab":"code","2413ddd5":"code","6d39a753":"code","09c39554":"code","1ee7ee3e":"code","ed039c13":"code","4cfbcc78":"code","cc59045b":"code","ea0c5f43":"code","9864ede5":"code","eb5fff5c":"code","a7886634":"code","e4bd52bc":"code","197ad1ab":"code","6e3cbfe4":"code","471319fa":"code","d0662322":"code","063dcf90":"code","f9abd6f7":"code","da1f76c9":"code","ca2cf901":"code","aae9feee":"code","e12a0477":"markdown","2d53ec6e":"markdown","2e79f702":"markdown","e47c3be0":"markdown","aed574f0":"markdown","3a187ad6":"markdown","65d608fd":"markdown"},"source":{"86b755eb":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport random\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm_notebook\n\npath = \"..\/input\/histopathologic-cancer-detection\/\"\n\ndata = pd.read_csv(path +\"train_labels.csv\")\ntrain_path = path +'train\/'\ntest_path = path + 'test\/'\n# quick look at the label stats\ndata['label'].value_counts()","cde7463e":"def readImage(path):\n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    return rgb_img","e25fbe7c":"# random sampling\nshuffled_data = shuffle(data)\n\nfig, ax = plt.subplots(2,5, figsize=(20,8))\nfig.suptitle('Histopathologic scans of lymph node sections',fontsize=20)\n# Negatives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 0]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[0,i].imshow(readImage(path + '.tif'))\n    # Create a Rectangle patch\n    box = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='b',facecolor='none', linestyle=':', capstyle='round')\n    ax[0,i].add_patch(box)\nax[0,0].set_ylabel('Negative samples', size='large')\n# Positives\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 1]['id'][:5]):\n    path = os.path.join(train_path, idx)\n    ax[1,i].imshow(readImage(path + '.tif'))\n    # Create a Rectangle patch\n    box = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='r',facecolor='none', linestyle=':', capstyle='round')\n    ax[1,i].add_patch(box)\nax[1,0].set_ylabel('Tumor tissue samples', size='large')","58247cc6":"data.head()","4ea65738":"!pip install -Uqq fastbook\nimport fastbook\nfrom fastai.vision.all import *","f6646a65":"path = \"..\/input\/histopathologic-cancer-detection\/\"\n","ad8892fb":"def get_x(r): return path+'train\/'+r['id']+'.tif'\ndef get_y(r): return r['label']\n\n\n# start with creatinga datablock\n\ndblock =  DataBlock(blocks=(ImageBlock, CategoryBlock),\n                    splitter=RandomSplitter(valid_pct=0.2,seed=42), \n                    get_x=get_x, \n                    get_y=get_y, \n                    item_tfms=RandomResizedCrop(128, min_scale=0.35))\ndls = dblock.dataloaders(data)\n\n","b2e19aa0":"dls.show_batch(nrows=1, ncols=3)","c128eaf3":"dblock =  DataBlock(blocks=(ImageBlock, CategoryBlock),\n                    splitter=RandomSplitter(valid_pct=0.2,seed=42), \n                    get_x=get_x, \n                    get_y=get_y, \n                    item_tfms= (CropPad(48, pad_mode='zeros'),DihedralItem(p=1.0, nm=None, before_call=None) ))\ndls = dblock.dataloaders(data)","e93ba8f2":"dls.show_batch()","e525beab":"learn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(4)","2413ddd5":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","6d39a753":"interp.plot_top_losses(16, nrows=8)","09c39554":"learn.predict('..\/input\/histopathologic-cancer-detection\/test\/00006537328c33e284c973d7b39d340809f7271b.tif')","1ee7ee3e":"path = \"..\/input\/histopathologic-cancer-detection\/\"","ed039c13":"preds, y = learn.tta()\nacc = accuracy(preds, y)\n","4cfbcc78":"from sklearn.metrics import roc_auc_score\ndef auc_score(y_pred,y_true,tens=True):\n    score = roc_auc_score(y_true,torch.sigmoid(y_pred)[:,1])\n    if tens:\n        score = tensor(score)\n    return score","cc59045b":"print('The validation accuracy is {} %.'.format(acc * 100))\npred_score = auc_score(preds,y).item()\nprint('The validation AUC is {}.'.format(pred_score))","ea0c5f43":"# # doesnt work\n# tf_fns = get_image_files(path + 'test')\n# test_data = DataBlock(get_items=get_image_files,\n#                  item_tfms=(CropPad(48, pad_mode='zeros'),DihedralItem(p=1.0, nm=None, before_call=None)))\n# dl_test = test_data.dataloaders(path+'test')\n# dl_test.show_batch()\n","9864ede5":"\ntest_images = get_image_files(path + 'test')\npreds,y = learn.get_preds(dl=dls.test_dl(test_images, shuffle=False, drop_last=False))","eb5fff5c":"pred_list = list(preds[:,1])","a7886634":"len(pred_list), len(test_images)","e4bd52bc":"submissions = pd.read_csv(path + 'sample_submission.csv')\nid_list = list(submissions.id)\nid_list","197ad1ab":"test_images_dict = {}\nfor i in range(len(test_images)):\n    test_images_dict[str(str(test_images[i]).split('\/')[-1].split('.')[0])] = float(pred_list[i])","6e3cbfe4":"test_images_dict['88a12685148c0d876fed1fba8228afc6e7ee937f']","471319fa":"prediction_list  = []\n\nfor i in id_list:\n    prediction_list.append(test_images_dict[i])","d0662322":"prediction_list[:5]","063dcf90":"\nsubmissions = pd.DataFrame({'id':id_list,'label':prediction_list})\nsubmissions.to_csv(\"submission.csv\".format(pred_score),index = False)","f9abd6f7":"from fastai.vision.widgets import *","da1f76c9":"btn_upload = widgets.FileUpload()\nbtn_upload","ca2cf901":"img =   PILImage.create(btn_upload.data[-1])","aae9feee":"out_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(600,600))\nout_pl","e12a0477":"visualisation from : https:\/\/www.kaggle.com\/qitvision\/a-complete-ml-pipeline-fast-ai","2d53ec6e":"Since definition of tta has changed I am unable currently to make it work, however creating a dataloader for test data","2e79f702":"baseline model has an accuracy of \\n\nScore!\nsubmission.csv\njust now\n1 seconds\n1 seconds\n0.9269\n\n[Screenshot%20%28119%29.png](attachment:Screenshot%20%28119%29.png)","e47c3be0":"from : https:\/\/www.kaggle.com\/mamamot\/fastai-v2-example and https:\/\/www.kaggle.com\/mentalwanderer\/image-classification-workflow-with-fast-ai\n\nfor more info on tta\nhttps:\/\/docs.fast.ai\/learner#Learner.tta","aed574f0":"### Problems with testing data\n\nfor submission again from : https:\/\/www.kaggle.com\/qitvision\/a-complete-ml-pipeline-fast-ai. Maybe U sould consider differnet way to evaluate any ideas ?","3a187ad6":"So we are able to create a dataloader however the images are too big right nowm we need a way to reduce the size of images. lets try for a crop to 48x48 at center with flip. and brightness. https:\/\/docs.fast.ai\/vision.augment#PadMode","65d608fd":"Rest not needed (down below) \nbut you can upload your own kaggle score image if you want !"}}