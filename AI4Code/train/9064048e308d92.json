{"cell_type":{"6bc309c1":"code","39625c84":"code","fce6fb15":"code","5f32d1b1":"code","fa5c6f8a":"code","f3aa054d":"code","66cae13f":"code","d2a38e9c":"code","064ba6fa":"code","f3a6809f":"code","fa177e5a":"code","081de463":"code","a52eb57e":"code","991a9441":"code","a8d93111":"code","1eedf585":"code","5695ce63":"code","5f70ca41":"code","b41640f6":"code","32003707":"code","ef7f46b7":"code","81160ce2":"code","81305889":"code","17a81a8a":"code","c5d85628":"code","19b7a464":"code","3f9bdf70":"code","d76575d3":"code","a5468cee":"code","7c93ab3d":"code","5253b324":"markdown","de4177e8":"markdown","76836c0c":"markdown","395acb06":"markdown","69269277":"markdown","9e7682f7":"markdown","11ff0c5c":"markdown"},"source":{"6bc309c1":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport os","39625c84":"traindata = '..\/input\/super-ai-image-classification\/train\/train\/train.csv'\ntestdata = '..\/input\/super-ai-image-classification\/val\/val\/val.csv'\ntrain = pd.read_csv(traindata)\n\nfirst_class = ['930195df-7e46-4ca6-91a0-2764f44e13c6.jpg',\n'5270bca6-2716-4f72-9601-004fba1c536e.jpg',\n'c0894ee2-a50a-4eea-aa01-6ab833017f1d.jpg',\n'39c1d8dd-5ee0-46f5-9422-45444db462c6.jpg',\n'd20bcabd-ca32-4e0d-929e-4f1e8f942e27.jpg',\n'7eb4e7cf-e503-4b85-9ede-7f01993d2f84.jpg',\n'dec754a3-04d2-44bb-9c1e-d2306be703fd.jpg',\n'e88bda06-4b3c-409c-90fc-56cbe973441e.jpg',\n'2494d994-b1f7-4c0e-ba4e-b6b213076e4e.jpg',\n'73565495-0aeb-42a3-9e29-17841fd75a36.jpg',\n'86181240-1ff5-456d-9ef2-0e79be13d63b.jpg',\n'd17010da-c97b-4e5b-9230-240f570ceb9c.jpg',\n'd16da93b-558d-4264-8115-f06f37d41338.jpg',\n'6e8eb027-d722-4a93-8d01-5003b1575bb4.jpg',\n'516f4d0c-8487-48d8-9ad8-acb1d13e71a9.jpg',\n'ddd8b119-43c0-4488-983e-f8d28835e453.jpg',\n'3f6cad70-f68e-434a-9eaf-7328d1b422bd.jpg']\n\naugment = transforms.Compose([transforms.RandomRotation(30),\n                              transforms.RandomResizedCrop(224),\n                              transforms.RandomHorizontalFlip(),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])])\n\ntransform = transforms.Compose([transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])])\n\nimgs = []\nlabels = []\nfor i in range(len(train)):\n    image = Image.open('..\/input\/super-ai-image-classification\/train\/train\/images\/' + train['id'][i])\n    if train['id'][i] in first_class:\n        print(i)\n    image_t = augment(image)\n    imgs.append(image_t)\n    labels.append(train['category'][i])\nlabels = np.array(labels)","fce6fb15":"imgs = torch.stack(imgs)","5f32d1b1":"holdout = int(0 * len(imgs))\n#x_valid = imgs[381:781]\n#y_valid = torch.from_numpy(labels[381:781])\n\n#x_train = []\n#y_train = []\n#for i in range(len(imgs)):\n#    if i >= 381 and i < 781:\n#        pass\n#    else:\n#        x_train.append(imgs[i])\n#        y_train.append(labels[i])\n#y_train = torch.from_numpy(np.array(y_train))\n#x_train = torch.stack(x_train)\nx_train = imgs[holdout:]\ny_train = torch.from_numpy(labels[holdout:])\n\ntrain_data = torch.utils.data.TensorDataset(x_train,y_train)\n#valid_data = torch.utils.data.TensorDataset(x_valid,y_valid)","fa5c6f8a":"y_train","f3aa054d":"trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\nloaders = {'train' : trainloader}","66cae13f":"trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)\nloaders = {'train' : trainloader, 'valid' : validloader}","d2a38e9c":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    global valid_loss_save\n    global train_loss_save\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n\n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for data, target in loaders['train']:\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            #clear gradient\n            optimizer.zero_grad()\n            ## find the loss and update the model parameters accordingly\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            ## record the average training loss, using something like\n            ## train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n            train_loss += loss.item()*data.size(0)\n            \n\n        ######################    \n        # validate the model #\n        ######################\n#         model.eval()\n#         for data, target in loaders['valid']:\n#             # move to GPU\n#             if use_cuda:\n#                 data, target = data.cuda(), target.cuda()\n#             ## update the average validation loss\n#             output = model(data)\n#             loss = criterion(output, target)\n#             valid_loss += loss.item()*data.size(0)\n            \n        # calculate average losses\n        train_loss = train_loss\/len(loaders['train'].dataset)\n#         valid_loss = valid_loss\/len(loaders['valid'].dataset)\n        \n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch,\n            train_loss,\n            valid_loss))\n        train_loss_save.append(train_loss)\n        valid_loss_save.append(valid_loss)\n        torch.save(model.state_dict(), save_path)\n        \n        ## TODO: save the model if validation loss has decreased\n#         if valid_loss <= valid_loss_min:\n#             print('Valid loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(\n#             valid_loss_min,\n#             valid_loss))\n#             torch.save(model.state_dict(), save_path)\n#             valid_loss_min = valid_loss\n    # return trained model\n\n    return model","064ba6fa":"import torchvision.models as models\nimport torch.nn as nn\n\nmodel_transfer = models.vgg16(pretrained=True)\n\nfor param in model_transfer.parameters():\n    param.requires_grad = False\n    \nclassifier = nn.Sequential(nn.Linear(25088,4096),\n                           nn.ReLU(),\n                           nn.Dropout(p=0.25),\n                           nn.Linear(4096,4096),\n                           nn.ReLU(),\n                           nn.Dropout(p=0.25),\n                           nn.Linear(4096,2))\n\n    \nmodel_transfer.classifier = classifier\n\nuse_cuda = torch.cuda.is_available() \n\nif use_cuda:\n   model_transfer = model_transfer.cuda()","f3a6809f":"import torch.optim as optim\ncriterion_transfer = nn.CrossEntropyLoss()\noptimizer_transfer = optim.Adam(model_transfer.classifier.parameters(), lr=0.0001)","fa177e5a":"valid_loss_save = []\ntrain_loss_save = []\nmodel_transfer = train(10, loaders, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')","081de463":"model_transfer.load_state_dict(torch.load('model_transfer.pt'))","a52eb57e":"model_transfer","991a9441":"import torch.nn as nn\nimport torch.nn.functional as F\nuse_cuda = torch.cuda.is_available()\n\n# define the CNN architecture\nclass Net(nn.Module):\n    ### TODO: choose an architecture, and complete the class\n    def __init__(self):\n        super(Net, self).__init__()\n        ## Define layers of a CNN\n        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n        self.conv7 = nn.Conv2d(256, 512, 3, padding=1)\n        self.conv8 = nn.Conv2d(512, 512, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(25088, 4096)\n        self.fc2 = nn.Linear(4096, 4096)\n        self.fc3 = nn.Linear(4096, 2)\n        #dropout\n        self.dropout = nn.Dropout(0.25)\n        \n    def forward(self, x):\n        ## Define forward behavior\n        x = F.relu(self.conv1(x))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = F.relu(self.conv5(x))\n        x = F.relu(self.conv6(x))\n        x = self.pool(F.relu(self.conv6(x)))\n        x = F.relu(self.conv7(x))\n        x = F.relu(self.conv8(x))\n        x = self.pool(F.relu(self.conv8(x)))\n        x = F.relu(self.conv8(x))\n        x = F.relu(self.conv8(x))\n        x = self.pool(F.relu(self.conv8(x)))\n        #flatten\n        x = x.view(-1, 25088)\n        #Ly\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n","a8d93111":"model = Net()\n\n# move tensors to GPU if CUDA is available\nif use_cuda:\n    model.cuda()","1eedf585":"model","5695ce63":"import torch.optim as optim\n\n### TODO: select loss function\ncriterion = nn.CrossEntropyLoss()\n\n### TODO: select optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\nvalid_loss_save = []\ntrain_loss_save = []","5f70ca41":"model = train(50, loaders, model, optimizer, \n                      criterion, use_cuda, 'model6.pt')","b41640f6":"model.load_state_dict(torch.load('model6.pt'))","32003707":"x_plot = range(len(valid_loss_save))\n\nplt.plot(x_plot, valid_loss_save, label = \"Valid\")\nplt.plot(x_plot[5:], train_loss_save[5:], label = \"Train\")\n\nplt.xlabel('Epoch')\nplt.ylabel('loss')\nplt.title('Compared Loss')\n\nplt.legend()\nplt.show()","ef7f46b7":"def test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(loaders['train']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data.float())\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n\n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))","81160ce2":"test(loaders, model, criterion, use_cuda)","81305889":"test_dir = os.listdir('..\/input\/super-ai-image-classification\/val\/val\/images\/')\ntest = pd.read_csv(testdata)\ntest_imgs = []\ntest_imgs_id = []\ntest_labels = []\nfor images in test_dir:\n    image = Image.open('..\/input\/super-ai-image-classification\/val\/val\/images\/' + images)\n    test_imgs_id.append(images)\n    image_t = transform(image)\n    test_imgs.append(image_t)\ntest_imgs = torch.stack(test_imgs)","17a81a8a":"test_data = torch.utils.data.TensorDataset(test_imgs,test_imgs)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\nmodel.load_state_dict(torch.load('model6.pt'))\nmodel.eval()\nfor data ,_ in test_loader:\n    if use_cuda:\n        data = data.cuda()\n    output = model(data)\n    test_labels.append(list(np.squeeze(output.data.max(1, keepdim=True)[1]).cpu().numpy()))","c5d85628":"result = []\nfor i in test_labels:\n    for j in i:\n        result.append(j)","19b7a464":"submit = pd.DataFrame(test_imgs_id,columns =['id'])\nsubmit['category'] = result","3f9bdf70":"predict = []\nfor i in range(len(submit)):\n    if submit['category'][i] == 1:\n        predict.append(submit['id'][i])","d76575d3":"len(predict)","a5468cee":"submit.to_csv('superAI_Submit_vgg16_architec30e.csv',index=False)","7c93ab3d":"from matplotlib.pyplot import imshow\nimage = Image.open('..\/input\/super-ai-image-classification\/val\/val\/images\/' + predict[20])\nimshow(np.asarray(image))","5253b324":"# Test","de4177e8":"# Network Architechture","76836c0c":"optional","395acb06":"# Prepare Data","69269277":"# Transfer Learning Test","9e7682f7":"# Split Validation","11ff0c5c":"# Covert to Data_loader"}}