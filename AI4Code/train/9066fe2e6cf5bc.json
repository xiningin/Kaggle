{"cell_type":{"55d0a6c2":"code","2f13b6cb":"code","4042210b":"code","56376a9d":"code","26650411":"code","416071ea":"code","271684e7":"code","8144479f":"code","e835ab64":"code","31e85a9d":"code","f6ff849a":"code","ab323fb7":"code","f125ead2":"code","f1fbc925":"code","78c4b4ad":"code","0d87eefa":"code","beb9e202":"code","af1aec65":"code","88595615":"code","80deb0e2":"code","6ad4e208":"code","dccfdaed":"code","619ca46c":"code","fb838903":"code","8ee1464d":"code","02c7f6a0":"code","bb2fbd26":"code","10a2e219":"code","63e93724":"code","be5b6b1e":"code","47aade09":"code","3bf27640":"code","800d2873":"code","c5f3e6b0":"code","b0216e39":"code","75663bbf":"code","f6660c0a":"code","0c1d3644":"code","83f5280c":"code","57e45ec3":"code","ffb1ccc8":"markdown","47ad1b1e":"markdown","faaa9aff":"markdown"},"source":{"55d0a6c2":"import numpy as np\nimport os\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nimport pickle\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport shutil\nimport random","2f13b6cb":"with open(\"..\/input\/datacleaningglassesnoglasses\/glasses.txt\", \"rb\") as fp:\n    glasses = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(glasses))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(glasses[ran_num[i]]))\n    plt.title(\"glasses\")\n    plt.axis(\"off\")","4042210b":"with open(\"..\/input\/datacleaningglassesnoglasses\/no_glasses.txt\", \"rb\") as fp: \n    no_glasses = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(no_glasses))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(no_glasses[ran_num[i]]))\n    plt.title(\"no_glasses\")\n    plt.axis(\"off\")","56376a9d":"with open(\"..\/input\/datacleaningglassesnoglasses\/no_clear.txt\", \"rb\") as fp: \n    no_clear = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(no_clear))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(no_clear[ran_num[i]]))\n    plt.title(\"no_clear\")\n    plt.axis(\"off\")","26650411":"print(\"The length of the different groups:\" + \"-Glasses: \" + str(len(glasses)) + \" -No glasses: \" + str(len(no_glasses)) + \" -No clear: \" + str(len(no_clear)))","416071ea":"BATCH_SIZE = 32\nIMG_SIZE = (256, 256)","271684e7":"all_images= glasses + no_glasses","8144479f":"data_dir= \"\/kaggle\/input\/datacleaningglassesnoglasses\/Images\/Images\/\"","e835ab64":"train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.25,\n    subset=\"training\",\n    shuffle=True,\n    seed=123456,\n    image_size= IMG_SIZE,\n    batch_size=BATCH_SIZE)","31e85a9d":"validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.25,\n    subset=\"validation\",\n    shuffle=True,\n    seed=123456,\n    image_size= IMG_SIZE,\n    batch_size=BATCH_SIZE)","f6ff849a":"class_names = train_dataset.class_names\nprint(class_names)\n","ab323fb7":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches \/\/ 5)\nvalidation_dataset = validation_dataset.skip(val_batches \/\/ 5)","f125ead2":"print('Number of training batches: %d' % tf.data.experimental.cardinality(train_dataset))\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","f1fbc925":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","78c4b4ad":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n    \n])","0d87eefa":"for image, _ in train_dataset.take(1):\n    plt.figure(figsize=(12, 12))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] \/ 255)\n        plt.axis('off')","beb9e202":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","af1aec65":"rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/127.5, offset= -1)","88595615":"IMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","80deb0e2":"base_model1=tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n   input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n","6ad4e208":"base_model2=tf.keras.applications.xception.Xception(\n   input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n\n","dccfdaed":"print(len(base_model.layers))\nprint(len(base_model1.layers))\nprint(len(base_model2.layers))","619ca46c":"base_model.trainable = True\nbase_model1.trainable = True\nbase_model2.trainable = True\nfine_tune_at = 140\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False\nfine_tune_at = 730\nfor layer in base_model1.layers[:fine_tune_at]:\n  layer.trainable =  False\nfine_tune_at = 110\nfor layer in base_model2.layers[:fine_tune_at]:\n  layer.trainable =  False\n","fb838903":"def get_model():\n    inputs = tf.keras.Input(shape=(256, 256, 3))\n    x = data_augmentation(inputs)\n    x = preprocess_input(x)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(10)(x)\n    return keras.Model(inputs, outputs)","8ee1464d":"def get_model1():\n    inputs1 = tf.keras.Input(shape=(256, 256, 3))\n    x = data_augmentation(inputs1)\n    x = preprocess_input(x)\n    x = base_model1(x, training=False)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs1 = tf.keras.layers.Dense(10)(x)\n    model1 = tf.keras.Model(inputs1, outputs1)\n    return keras.Model(inputs1, outputs1)\n    ","02c7f6a0":"def get_model2():\n    inputs1 = tf.keras.Input(shape=(256, 256, 3))\n    x = data_augmentation(inputs1)\n    x = preprocess_input(x)\n    x = base_model2(x, training=False)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs1 = tf.keras.layers.Dense(10)(x)\n    model2 = tf.keras.Model(inputs1, outputs1)\n    return keras.Model(inputs1, outputs1)","bb2fbd26":"model1 = get_model()\nmodel2 = get_model1()\nmodel3 = get_model2()\ninputs = keras.Input(shape=(256, 256, 3))\ny1 = model1(inputs)\ny2 = model2(inputs)\ny3 = model3(inputs)\n\noutputs = layers.average([y1, y2,y3])\noutputs = tf.keras.layers.Dense(5)(outputs)\noutputs = tf.keras.layers.Dense(1)(outputs)\nensemble_model = keras.Model(inputs=inputs, outputs=outputs)","10a2e219":"ensemble_model.summary()","63e93724":"ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n","be5b6b1e":"model_fit = ensemble_model.fit(train_dataset,\n                    epochs= 10,\n                    validation_data= validation_dataset,shuffle=True)","47aade09":"ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,LearningRateScheduler,ModelCheckpoint","3bf27640":"checkpoint_filepath = '.\/'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)","800d2873":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n                              patience=1)\n","c5f3e6b0":"def decay(epoch):\n  if epoch < 5:\n    return 1e-4\n  elif epoch >= 5 and epoch < 15:\n    return 1e-6\n  else:\n    return 1e-7\n\n\nschedule = tf.keras.callbacks.LearningRateScheduler(decay)","b0216e39":"fine_tune_epochs = 5\ntotal_epochs =  10 + fine_tune_epochs","75663bbf":"model_fit_fine = ensemble_model.fit(train_dataset,\n                         epochs= total_epochs,\n                         initial_epoch= model_fit.epoch[-1],\n                         validation_data= validation_dataset,\n                            callbacks=[reduce_lr,model_checkpoint_callback] )","f6660c0a":"ensemble_model.evaluate(test_dataset)","0c1d3644":"acc = model_fit.history['accuracy']\nval_acc = model_fit.history['val_accuracy']\nloss_ = model_fit.history['loss']\nval_loss_ = model_fit.history['val_loss']","83f5280c":"acc += model_fit_fine.history['accuracy']\nval_acc += model_fit_fine.history['val_accuracy']\nloss_ += model_fit_fine.history['loss']\nval_loss_ += model_fit_fine.history['val_loss']","57e45ec3":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss_, label='Training Loss')\nplt.plot(val_loss_, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n\n","ffb1ccc8":"## Glasess:","47ad1b1e":"## No clear:","faaa9aff":"## No glasses:"}}