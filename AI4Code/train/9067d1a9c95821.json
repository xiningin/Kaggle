{"cell_type":{"b21501dc":"code","4aac6cc1":"code","1a591f57":"code","8b46f613":"code","9b660b3a":"code","828b7751":"code","42e5bc4d":"code","66aebce0":"code","b0f69cb0":"code","ee52aeb0":"code","847e0402":"code","07c19e61":"code","4dfb12fe":"code","2740938b":"code","78831b27":"code","696d6cde":"code","ba6f1cd9":"code","c9573599":"code","58119130":"code","c0545a59":"code","9ec9ed51":"code","53bcbc7d":"code","3a631a81":"code","584487e9":"code","24608a2d":"code","7e1ee877":"code","f34b769a":"code","cc092a9e":"code","5c5203ed":"code","5e16f6fe":"code","2b37dd28":"code","557758f6":"code","cc02f67f":"code","73322057":"code","3273e2ed":"code","cf7d6ce5":"code","dc51db6d":"code","c8c6de45":"code","6ecddb01":"code","140d69a0":"code","c7457456":"markdown","6a149b5d":"markdown","4b046a67":"markdown","fe9b0cf5":"markdown","28b1f0c7":"markdown","fed09af5":"markdown","9797e377":"markdown","58332f26":"markdown","f5062a75":"markdown"},"source":{"b21501dc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport os, cv2, json, random, itertools, rasterio, math, time, psutil, warnings\n\n# np.random.seed(0)\n# tf.random.set_seed(0)\n\nfrom tqdm import tqdm\nfrom IPython.display import SVG\nfrom tensorflow.keras.utils import plot_model, model_to_dot, to_categorical, Sequence\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score\nfrom sklearn.preprocessing import *\n\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import (Add, Input, Conv2D, Dropout, Activation, BatchNormalization, MaxPooling2D, ZeroPadding2D, AveragePooling2D, Flatten, Dense, Concatenate)\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, Callback, LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.regularizers import *\n\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\nwarnings.filterwarnings(\"ignore\")","4aac6cc1":"def show_final_history(history):\n    \n    plt.style.use(\"ggplot\")\n    fig, ax = plt.subplots(1,2,figsize=(15,5))\n    \n    ax[0].set_title('Loss')\n    ax[1].set_title('Accuracy')\n    \n    ax[0].plot(history.history['loss'], 'r-', label='Training Loss')\n    ax[0].plot(history.history['val_loss'], 'g-', label='Validation Loss')\n    ax[1].plot(history.history['categorical_accuracy'], 'r-', label='Training Accuracy')\n    ax[1].plot(history.history['val_categorical_accuracy'], 'g-', label='Validation Accuracy')\n    \n    ax[0].legend(loc='upper right')\n    ax[1].legend(loc='lower right')\n    \n    plt.show();\n    pass","1a591f57":"def plot_learning_rate(loss_history):\n    \n    plt.style.use(\"ggplot\")\n    \n    plt.plot(np.arange(0,len(loss_history.lr)), loss_history.lr)\n    plt.show();\n    pass","8b46f613":"def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n    \n    cm = cm.astype('float')\/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar();\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()\/2.0\n    \n    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        \n        plt.text(j,i, format(cm[i,j], fmt),\n                horizontalalignment = 'center',\n                color = \"white\" if cm[i,j] > thresh else \"black\")\n        pass\n    \n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.grid(False);\n    pass","9b660b3a":"with open(\"..\/input\/eurosat-dataset\/EuroSATallBands\/label_map.json\",\"r\") as f:\n    class_names_encoded = json.load(f)\n    pass\n\nclass_names = list(class_names_encoded.keys())\nnum_classes = len(class_names)\nclass_names_encoded","828b7751":"bands = {'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'8a':9,'9':10,'10':11,'11':12,'12':13}","42e5bc4d":"def Normalise(arr_band):\n    \n    return StandardScaler().fit_transform(arr_band)","66aebce0":"basePath = \"..\/input\/eurosat-dataset\/EuroSATallBands\"\n\ndef data_generator(csv_file, num_classes, batch_size = 10, target_size = 64):\n    i = 0\n    classes = set()\n    df = pd.read_csv(csv_file)\n    num_samples = df.shape[0]\n    \n    while True:\n        for offset in range(0, num_samples, batch_size):\n            batch_samples_idx = df.index[offset:offset+batch_size]\n\n            X, y = [], []\n\n            for i in batch_samples_idx:\n                img_name = df.loc[i,'Filename']\n                label = df.loc[i,'Label']\n\n                src = rasterio.open(os.path.join(basePath,img_name))\n\n                arr_3, arr_4, arr_8 = src.read(bands['3']).astype(np.float32), src.read(bands['4']).astype(np.float32), src.read(bands['8']).astype(np.float32)\n                arr_6, arr_7 = src.read(bands['6']).astype(np.float32), src.read(bands['7']).astype(np.float32)\n                arr_11 = src.read(bands['11']).astype(np.float32)\n\n                arr_3 = Normalise(arr_3)\n                arr_4 = Normalise(arr_4)\n                arr_6, arr_7 = Normalise(arr_6), Normalise(arr_7)\n                arr_8 = Normalise(arr_8)\n                arr_11 = Normalise(arr_11)\n\n                bands_10_20 = np.dstack((arr_3, arr_4, arr_6, arr_7, arr_8, arr_11))\n\n                X.append(bands_10_20)\n                y.append(label)\n                pass\n\n            X = np.array(X)\n            y = np.array(y)\n            y = to_categorical(y, num_classes = num_classes)\n            \n            yield X, y\n            pass\n        pass\n    pass\n","b0f69cb0":"train_generator = data_generator(csv_file = \"..\/input\/eurosat-dataset\/EuroSATallBands\/train.csv\", num_classes = 10, batch_size = 10)\nval_generator = data_generator(csv_file = \"..\/input\/eurosat-dataset\/EuroSATallBands\/validation.csv\", num_classes = 10, batch_size = 10)","ee52aeb0":"train_df = pd.read_csv(\"..\/input\/eurosat-dataset\/EuroSATallBands\/train.csv\")\ntrain_labels = train_df.loc[:,'Label']\ntrain_labels = np.array(train_labels)\n\nnum_train_samples = train_labels.shape[0]\n\nval_df = pd.read_csv(\"..\/input\/eurosat-dataset\/EuroSATallBands\/validation.csv\")\nval_labels = val_df.loc[:,'Label']\nval_labels = np.array(val_labels)\n\nnum_val_samples = val_labels.shape[0]\n\nnum_train_samples, num_val_samples","847e0402":"def spectral_block(X,filters,stage,s=1):\n    \n    squeeze_base_name = 'squeeze_' + str(stage) + '_branch'\n    bn_base_name = 'bn_' + str(stage) + \"_branch\"\n    \n    F1,F2,F3 = filters\n    \n    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding='same', name=squeeze_base_name+'a')(X)\n    \n    X_11 = Conv2D(filters=F2, kernel_size=(1,1), strides=(s,s), padding='same', name=squeeze_base_name+'b')(X)\n    X_33 = Conv2D(filters=F3, kernel_size=(3,3), strides=(s,s), padding='same', name=squeeze_base_name+'c')(X)\n    \n    X = Concatenate(name=\"concatenate_\"+str(stage))([X_11, X_33])\n    X = BatchNormalization(name=bn_base_name)(X)\n    \n    X = Activation(\"relu\", name=\"spectral\"+str(stage))(X)\n    \n    return X\n    pass","07c19e61":"def SpectrumNet(input_shape, classes):\n    \n    X_input = Input(input_shape, name=\"input\")\n    \n    X = Conv2D(96, (1,1), strides=(2,2), name='conv1', padding=\"same\")(X_input)\n    \n    X = spectral_block(X, [16,96,32], 2)\n    X = spectral_block(X, [16,96,32], 3)\n    X = spectral_block(X, [32,192,64], 4)\n    \n    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\", name=\"maxpool4\")(X)\n    \n    X = spectral_block(X, [32,192,64], 5)\n    X = spectral_block(X, [48, 288, 96], 6)\n    X = spectral_block(X, [48, 288, 96], 7)\n    X = spectral_block(X, [64, 384, 128], 8)\n    \n    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\", name=\"maxpool8\")(X)\n    \n    X = spectral_block(X, [64,384,128], 9)\n    \n    X = Conv2D(10, kernel_size=(1,1), strides=(1,1), name=\"conv10\", padding='same')(X)\n    X = BatchNormalization(name=\"conv10_batchnormalisation\")(X)\n    X = Activation(\"relu\", name=\"conv10_activation\")(X)\n    \n    X = AveragePooling2D(pool_size=(8,8), strides=(1,1), name=\"avgpool10\")(X)\n    \n    X = Flatten(name=\"flatten10\")(X)\n    \n#     X = Dense(16, name=\"dense_1\")(X)\n#     X = Activation(\"relu\",name=\"dense_relu_1\")(X)\n    \n#     X = Dense(256, name=\"dense_2\")(X)\n#     X = Activation(\"relu\",name=\"dense_relu_2\")(X)\n    \n#     X = Dense(512,name=\"dense_3\")(X)\n#     X = Activation(\"relu\", name=\"dense_relu_3\")(X)\n    \n#     X = Dense(classes,activation=\"softmax\",name=\"fc\"+str(classes))(X)\n\n    X = Activation(\"softmax\", name=\"output\")(X)\n    \n    model = Model(inputs=X_input, outputs=X, name=\"SpectrumNet\")\n    \n    return model\n    pass","4dfb12fe":"model = SpectrumNet(input_shape = (64,64,6), classes=num_classes)","2740938b":"model.summary()","78831b27":"plot_model(model, to_file=\"6bands_v5-4.png\",show_shapes=True,show_layer_names=True)\nSVG(model_to_dot(model).create(prog=\"dot\", format='svg'))","696d6cde":"checkpoint = ModelCheckpoint(\"6bands_weights_v5-5_SC.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\nlogs = TensorBoard(\"6bands-logs-SC\", histogram_freq=1)","ba6f1cd9":"def step_decay(epoch):\n   initial_lrate = 0.001\n   drop = 0.10\n   epochs_drop = 30.0\n   lrate = initial_lrate * math.pow(drop,  \n           math.floor((1+epoch)\/epochs_drop))\n   return lrate","c9573599":"class LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n       self.losses = []\n       self.lr = []\n \n    def on_epoch_end(self, batch, logs={}):\n       self.losses.append(logs.get('loss'))\n       self.lr.append(step_decay(len(self.losses)))","58119130":"loss_history = LossHistory()\nlrate = LearningRateScheduler(step_decay)","c0545a59":"train_labels_encoded = to_categorical(train_labels,num_classes=10)\n\nclassTotals = train_labels_encoded.sum(axis=0)\nclassWeight = {}\n\nfor i in range(len(classTotals)):\n    classWeight[i] = classTotals.max()\/classTotals[i]\n    pass\n\nclassWeight","9ec9ed51":"# opt = Adam(lr=1e-3)\n# model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])","53bcbc7d":"opt = SGD(lr=1e-3, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['categorical_accuracy'])","3a631a81":"epochs = 100\nbatchSize = 100\n\nhistory = model.fit(train_generator,\n                   steps_per_epoch = num_train_samples\/\/batchSize,\n                   epochs = epochs,\n                   verbose = 1,\n                   validation_data = val_generator,\n                   validation_steps = num_val_samples\/\/batchSize,\n                   callbacks = [checkpoint, lrate, loss_history],\n                   class_weight = classWeight\n                   )","584487e9":"show_final_history(history)","24608a2d":"plot_learning_rate(loss_history)","7e1ee877":"def obtain_tif_images(csv_file):\n    \n    df = pd.read_csv(csv_file)\n    num_samples = df.shape[0]\n    \n    X, y = [], []\n    \n    for i in tqdm(range(num_samples)):\n        \n        img_name = df.loc[i,'Filename']\n        label = df.loc[i,'Label']\n\n        src = rasterio.open(os.path.join(basePath,img_name))\n        arr_3, arr_4, arr_8 = src.read(bands['3']), src.read(bands['4']), src.read(bands['8']) \n        arr_6, arr_7 = src.read(bands['6']), src.read(bands['7'])\n        arr_11 = src.read(bands['11'])\n\n        arr_3 = np.array(arr_3, dtype=np.float32)\n        arr_4 = np.array(arr_4, dtype=np.float32)\n        arr_6, arr_7 = np.array(arr_6, dtype=np.float32), np.array(arr_7, dtype=np.float32)\n        arr_8 = np.array(arr_8, dtype=np.float32)\n        arr_11 = np.array(arr_11, dtype=np.float32)\n\n        arr_3 = Normalise(arr_3)\n        arr_4 = Normalise(arr_4)\n        arr_6, arr_7 = Normalise(arr_6), Normalise(arr_7)\n        arr_8 = Normalise(arr_8)\n        arr_11 = Normalise(arr_11)\n\n        bands_10_20 = np.dstack((arr_3, arr_4, arr_6, arr_7, arr_8, arr_11))\n\n        X.append(bands_10_20)\n        y.append(label)\n        \n        pass\n    \n    X = np.array(X)\n    y = np.array(y)\n    \n    return X,y\n    pass","f34b769a":"test_tifs, test_labels = obtain_tif_images(csv_file=\"..\/input\/eurosat-dataset\/EuroSATallBands\/test.csv\")\n\ntest_labels_encoded = to_categorical(test_labels, num_classes = len(class_names))\n\ntest_tifs.shape, test_labels.shape, test_labels_encoded.shape","cc092a9e":"test_pred = model.predict(test_tifs)\ntest_pred = np.argmax(test_pred, axis=1)\ntest_pred.shape","5c5203ed":"cnf_mat = confusion_matrix(test_labels, test_pred)\n\nplot_confusion_matrix(cnf_mat, classes=class_names, title=\"6 Bands Confusion Matrix - V5-5 - SC\")\nplt.grid(False);","5e16f6fe":"for f1,class_name in zip(f1_score(test_labels, test_pred, average=None), class_names):\n    print(\"Class name: {}, F1 score: {:.3f}\".format(class_name, f1))\n    pass","2b37dd28":"model.save(\"6bands_v5-5_SC.h5\")","557758f6":"model_test = load_model(\".\/6bands_v5-5_SC.h5\")\n\nmodel_test.summary()","cc02f67f":"model_test.load_weights(\".\/6bands_weights_v5-5_SC.h5\")","73322057":"test_pred_2 = model_test.predict(test_tifs)\ntest_pred_2 = np.argmax(test_pred_2, axis=1)\ntest_pred_2.shape","3273e2ed":"for f1,class_name in zip(f1_score(test_labels, test_pred_2, average=None), class_names):\n    print(\"Class name: {}, F1 score: {:.3f}\".format(class_name, f1))\n    pass","cf7d6ce5":"cnf_mat = confusion_matrix(test_labels, test_pred_2)\n\nplot_confusion_matrix(cnf_mat, classes=class_names, title=\"Testing Model V5-5 CNF-MAT\")\nplt.grid(False)","dc51db6d":"val_tifs, val_labels = obtain_tif_images(csv_file=\"..\/input\/eurosat-dataset\/EuroSATallBands\/validation.csv\")\n\nval_labels_encoded = to_categorical(val_labels, num_classes = len(class_names))\n\nval_tifs.shape, val_labels.shape, val_labels_encoded.shape","c8c6de45":"val_pred = model_test.predict(val_tifs)\nval_pred = np.argmax(val_pred, axis=1)\nval_pred.shape","6ecddb01":"for f1,class_name in zip(f1_score(val_labels, val_pred, average=None), class_names):\n    print(\"Class name: {}, F1 score: {:.3f}\".format(class_name, f1))\n    pass","140d69a0":"cnf_mat = confusion_matrix(val_labels, val_pred)\n\nplot_confusion_matrix(cnf_mat, classes=class_names,title=\"Validation Model V5-5 CNF-MAT\")\nplt.grid(False)","c7457456":"# Validation Phase","6a149b5d":"# Training Model","4b046a67":"# Running TensorBoard","fe9b0cf5":"# Defining the Model","28b1f0c7":"# Importing Libraries","fed09af5":"# Utility Functions:","9797e377":"## Defining Normalisation","58332f26":"Notes:\n> Version 1: Without Class weights and tested on the testing dataset. Works much better than the RGB dataset's model.\n\n> Version 2: Loaded weights from previous version and retrained model using class weights. Tested by saving the model and loading the best saved weights. Satisfactory response. F1 scores for each class calculated. On average a difference of 0.2 between the validation and testing F1 score's.\n\n> Version 3-6: SpectrumNet\n     \n    Version 3: No normalization\n    Version 6: Standard Scaling\n    Version 7: L2 normalization\n\n* Model V5-4 : L2 Normalization\n* Model V5-5 : Added more tiles to SeaLake [Version 10]\n* Model V5-5.1 : Training only using CPU and Model V5-5 [Version 11]\n* Model V5-5.2 : Training only using CPU and StandardScaler is used to normalise the data. [Version 12]\n\nIssues:\n > Model confuses between PermanentCrop and HerbaceousVegetation.","f5062a75":"## Data Generator"}}