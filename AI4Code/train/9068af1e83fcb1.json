{"cell_type":{"8b0528c8":"code","f155c979":"code","47a7df80":"code","da719757":"code","33c16e26":"code","7144f659":"code","5a2174a5":"code","644b7a02":"code","2343894b":"code","0a2cd728":"code","1a6611b8":"code","f637bb65":"code","6e9cb09a":"code","7038d2aa":"code","91d42b4b":"code","691bd32e":"code","df5c4cb0":"code","46df4d5a":"code","4d5aae4a":"code","39bd5273":"code","da64436a":"code","ac53ca57":"code","1982861b":"code","4621a72b":"code","c7772a85":"code","001b9dfa":"code","e2915925":"code","ab3599f6":"code","bb022829":"code","85a63c9d":"code","15222c69":"code","fdba2574":"code","78631583":"code","bf75cd69":"code","2e583570":"code","df4ae9df":"code","0fc89d59":"markdown","a21b9304":"markdown","3eff9626":"markdown","8d7af46d":"markdown","89ca839e":"markdown","6fd1ca19":"markdown","6f631121":"markdown"},"source":{"8b0528c8":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nimport os\nos.listdir()","f155c979":"summary=pd.read_csv('\/kaggle\/input\/us-historical-stock-prices-with-earnings-data\/dataset_summary.csv')\nprices=pd.read_csv('\/kaggle\/input\/us-historical-stock-prices-with-earnings-data\/stocks_latest\/stock_prices_latest.csv')\nearnings=pd.read_csv('\/kaggle\/input\/us-historical-stock-prices-with-earnings-data\/stocks_latest\/earnings_latest.csv')\ndividends=pd.read_csv('\/kaggle\/input\/us-historical-stock-prices-with-earnings-data\/stocks_latest\/dividends_latest.csv')","47a7df80":"## prices\nprices.head()","da719757":"## earnings\nearnings.head()","33c16e26":"## dividends\ndividends.head()","7144f659":"masterQuote=prices.merge(dividends,on=['symbol','date'],how='left')","5a2174a5":"masterQuote=masterQuote.fillna(0.0)\ntickerCount=pd.DataFrame(masterQuote.groupby(['symbol']).count())\ntickerCount=tickerCount.reset_index()\ntickerCount=tickerCount[['symbol','date']]\nqualified=tickerCount[tickerCount['date']>250]","644b7a02":"msft=masterQuote[masterQuote['symbol']=='MSFT']\nmsft=msft.sort_values(by=['date'],ascending=True)","2343894b":"msft=msft[['close_adjusted','volume','split_coefficient','dividend']]","0a2cd728":"import matplotlib.pyplot as plt\nhistQuote=msft['close_adjusted'].tolist()\nplt.plot(histQuote)\nplt.show()","1a6611b8":"logRet=np.log(np.array(histQuote[1:])\/np.array(histQuote[:-1]))","f637bb65":"plt.plot(logRet)\nplt.show()","6e9cb09a":"paddedLogRet=[0]+list(logRet)","7038d2aa":"msft['logRet']=paddedLogRet","91d42b4b":"logvolume=np.log(msft['volume'].tolist())","691bd32e":"msft['logVolume']=logvolume","df5c4cb0":"def makeBatch():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')\n    ","46df4d5a":"Xs,Ys=makeBatch()","4d5aae4a":"## Last 1500 as test","39bd5273":"tf.reset_default_graph()\nnum_hidden = 64\n\ndata = tf.placeholder(tf.float32, [None,40,4]) \ntarget = tf.placeholder(tf.float32, [None,1])\n## LSTM\ncell = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\nval, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\nval = tf.transpose(val, [1, 0, 2])\nlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n## Dense 1\nweight = tf.Variable(tf.truncated_normal([num_hidden, 16]))\nbias = tf.Variable(tf.constant(0.1, shape=[16]))\nprediction1=tf.matmul(last, weight) + bias\n## Dense 2\nweight1 = tf.Variable(tf.truncated_normal([16,1]))\nbias1 = tf.Variable(tf.constant(0.1, shape=[1]))\nprediction = tf.matmul(prediction1, weight1) + bias1","da64436a":"val.shape","ac53ca57":"mse = tf.reduce_sum(tf.keras.losses.MSE(prediction,target))\noptimizer = tf.train.AdamOptimizer(0.003).minimize(mse)\n","1982861b":"init=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)\nXs,Ys=makeBatch()\nbatch_size=64\nfor i in range(200):\n    ptr = 0\n    for j in range(int(Xs.shape[0]\/batch_size)-1):\n        inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n        train=sess.run(optimizer,{data: inp, target: out})\n    loss=sess.run(mse,{data: inp, target: out})\n    if (i+1)%100==0:\n        print(\"Epoch - \"+str(i)+\": the loss is: \" +str(loss))","4621a72b":"predList=[]\nactualList =[]\n\nfor j in range(int(Xs.shape[0]\/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)","c7772a85":"predReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]","001b9dfa":"plt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()","e2915925":"## Test\ndef makeBatchTest():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40,tp.shape[0]-40-1):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')","ab3599f6":"predList=[]\nactualList =[]\nXs,Ys=makeBatchTest()\nfor j in range(int(Xs.shape[0]\/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)","bb022829":"predReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()","85a63c9d":"import math\nactual_Price=msft['close_adjusted'].tolist()\npredictChunk=actual_Price[-1500:]\npredSeed=actual_Price[-1501]\ngeneratedQuote=[]\nfor logret in predReturn:\n    generatedQuote.append(predSeed*math.exp(logret))\n    predSeed=predSeed*math.exp(logret)\n","15222c69":"plt.plot(generatedQuote)\nplt.plot(predictChunk)\nplt.show()","fdba2574":"import tensorflow as tf\ntf.reset_default_graph()\nnum_hidden = 64\n\ndata = tf.placeholder(tf.float32, [None,40,4]) \ntarget = tf.placeholder(tf.float32, [None,1])\n## LSTM\ncellfw = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\ncellbw = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\n\nlstm_fw_multicell = tf.nn.rnn_cell.MultiRNNCell([cellfw])\nlstm_bw_multicell = tf.nn.rnn_cell.MultiRNNCell([cellbw])\n\nvalAll, state= tf.nn.bidirectional_dynamic_rnn(lstm_fw_multicell, lstm_bw_multicell, data, dtype=tf.float32)\nout_fw, out_bw = valAll\noutput = tf.concat([out_fw, out_bw], axis=-1)\n#val, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\nval = tf.transpose(output , [1, 0, 2])\nlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n## Dense 1\nweight = tf.Variable(tf.truncated_normal([num_hidden*2, 16]))\nbias = tf.Variable(tf.constant(0.1, shape=[16]))\nprediction1=tf.matmul(last, weight) + bias\n## Dense 2\nweight1 = tf.Variable(tf.truncated_normal([16,1]))\nbias1 = tf.Variable(tf.constant(0.1, shape=[1]))\nprediction = tf.matmul(prediction1, weight1) + bias1","78631583":"mse = tf.reduce_sum(tf.keras.losses.MSE(prediction,target))\noptimizer = tf.train.AdamOptimizer(0.003).minimize(mse)\ninit=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)\nXs,Ys=makeBatch()\nbatch_size=64\nfor i in range(200):\n    ptr = 0\n    for j in range(int(Xs.shape[0]\/batch_size)-1):\n        inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n        train=sess.run(optimizer,{data: inp, target: out})\n    loss=sess.run(mse,{data: inp, target: out})\n    if (i+1)%100==0:\n        print(\"Epoch - \"+str(i)+\": the loss is: \" +str(loss))","bf75cd69":"predList=[]\nactualList =[]\n\nfor j in range(int(Xs.shape[0]\/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)\npredReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()\n","2e583570":"## Test\ndef makeBatchTest():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40,tp.shape[0]-40-1):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')\npredList=[]\nactualList =[]\nXs,Ys=makeBatchTest()\nfor j in range(int(Xs.shape[0]\/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)\npredReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()  ","df4ae9df":"import math\nactual_Price=msft['close_adjusted'].tolist()\npredictChunk=actual_Price[-1500:]\npredSeed=actual_Price[-1501]\ngeneratedQuote=[]\nfor logret in predReturn:\n    generatedQuote.append(predSeed*math.exp(logret))\n    predSeed=predSeed*math.exp(logret)\nplt.plot(generatedQuote)\nplt.plot(predictChunk)\nplt.show()","0fc89d59":"### Plot actual quotes instead of log-return","a21b9304":"## Smooth enough but not so good for long term prediction","3eff9626":"## LSTM on Log-Return\/MSFT","8d7af46d":"## Lets make it Bi-directional","89ca839e":"## Calc log-return\n#### & Visualizations","6fd1ca19":"## Use MSFT as an example","6f631121":"## Print out schemas of EQTY "}}