{"cell_type":{"a57b3db1":"code","9276a1d2":"code","bc65e36c":"code","894e77a2":"code","8d2cc48f":"code","238eaf0c":"code","fd0218a4":"code","691cf3d1":"code","805cfdf9":"code","518f069c":"code","326ceb28":"code","bcc2a0a1":"code","2629b6bf":"code","eea261e6":"code","1266cba8":"code","deea8c94":"code","76951974":"code","f28e0af7":"code","27c0be09":"code","edf7205c":"code","0e07fbfb":"code","c905322a":"code","1c678387":"code","463b31af":"code","74b755a4":"code","36b70907":"code","a6a039c5":"code","8bdea86a":"code","4a7d0ae4":"code","7d073cc1":"code","471862ac":"code","e19a40b5":"code","5b52edc9":"code","805b72e8":"code","34101123":"code","6c7c3e62":"code","e613bcc5":"code","0ca14f8a":"code","0effb654":"code","f9be1ef8":"code","f6d3ba91":"code","f94269e3":"code","104ffec2":"code","1b015fb0":"code","4ae8b437":"code","a76e79bb":"code","44300ece":"code","d948fccd":"code","b4b6a6b9":"code","8be05302":"code","c6f4b483":"code","ff26b82d":"code","329dffbd":"code","943be4b3":"code","92553d53":"markdown","a95353e7":"markdown","0c70c341":"markdown","09ac6eb0":"markdown","5b1444d9":"markdown","fd8d0a9a":"markdown","ff4c50a9":"markdown","4ab3f506":"markdown","4ddbd250":"markdown","fe9d9bb1":"markdown","b4bc22ef":"markdown","0fdb1180":"markdown","d7b0064b":"markdown","4ebc39e6":"markdown","8476ef7d":"markdown","a2a65bfd":"markdown","16438749":"markdown","a9450dea":"markdown","bf0bcea8":"markdown","1a0b12b4":"markdown","226e6fea":"markdown","6a402903":"markdown","97935996":"markdown"},"source":{"a57b3db1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Spliting data and creating model libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.models import Sequential #initialize neural network library\nfrom keras.layers import Dense #build our layers library\nfrom tensorflow import keras\nfrom keras.models import Sequential\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9276a1d2":"data_train = pd.read_csv(\"..\/input\/house-price2\/House-Price2.csv\")\ndata_train.head()","bc65e36c":"data_train.info()","894e77a2":"# We can observe number of sold House\nsns.countplot(data_train[\"Sold\"])\nplt.show()","8d2cc48f":"data_train.describe()","238eaf0c":"# Let's plot the distribution of Hot Room and sold\nsns.jointplot(x='n_hot_rooms', y='Sold', data=data_train)","fd0218a4":"sns.countplot(x='airport', data=data_train)","691cf3d1":"sns.countplot(x='waterbody', data=data_train)","805cfdf9":"sns.countplot(x='bus_ter', data=data_train)","518f069c":"data_train.info()","326ceb28":"np.percentile(data_train.n_hot_rooms,[99])","bcc2a0a1":"np.percentile(data_train.n_hot_rooms,[99])[0]","2629b6bf":"nv = np.percentile(data_train.n_hot_rooms,[99])[0]","eea261e6":"data_train[(data_train.n_hot_rooms > nv)]","1266cba8":"data_train.n_hot_rooms[(data_train.n_hot_rooms > 3 * nv)] = 3 * nv","deea8c94":"data_train[(data_train.n_hot_rooms > nv)]","76951974":"np.percentile(data_train.rainfall,[1])[0]","f28e0af7":"lv = np.percentile(data_train.rainfall,[1])[0]","27c0be09":"data_train[(data_train.rainfall < lv)]","edf7205c":"data_train[(data_train.rainfall < lv)]","0e07fbfb":"data_train.info()","c905322a":"#Impute Missing values for 1 columns\ndata_train.n_hos_beds = data_train.n_hos_beds.fillna(data_train.n_hos_beds.mean())\n# For all columns : df = df.fillna(df.mean())","1c678387":"data_train.info()","463b31af":"data_train.head()","74b755a4":"data_train['avg_dist'] = (data_train.dist1 + data_train.dist2 + data_train.dist3 + data_train.dist4) \/ 4","36b70907":"data_train.describe()","a6a039c5":"del data_train['dist1']","8bdea86a":"del data_train['dist2']","4a7d0ae4":"del data_train['dist3']","7d073cc1":"del data_train['dist4']","471862ac":"data_train.head()","e19a40b5":"data_train.shape","5b52edc9":"del data_train['bus_ter']","805b72e8":"data_train = pd.get_dummies(data_train)","34101123":"data_train.head()","6c7c3e62":"data_train.shape","e613bcc5":"del data_train['airport_NO']","0ca14f8a":"del data_train['waterbody_None']","0effb654":"data_train.head()","f9be1ef8":"data_train.shape","f6d3ba91":"data_train.corr()","f94269e3":"data_test = data_train","104ffec2":"data_test.shape","1b015fb0":"X = data_train.drop([\"Sold\"],axis=1)\nY = data_train[\"Sold\"]\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)\nprint(\"x_train shape: \",x_train.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"x_test shape: \",x_test.shape)\nprint(\"y_test shape: \",y_test.shape)","4ae8b437":"X.shape","a76e79bb":"my_model = Sequential() # initialize neural network\nmy_model.add(Dense(units = 128, activation = 'relu', input_dim = X.shape[1]))\nmy_model.add(Dense(units = 32, activation = 'relu'))\nmy_model.add(Dense(units = 16, activation = 'relu'))\nmy_model.add(Dense(units = 8, activation = 'relu'))\nmy_model.add(Dense(units = 4, activation = 'relu'))\nmy_model.add(Dense(units = 1, activation = 'sigmoid')) #output layer\nmy_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","44300ece":"my_model.summary()","d948fccd":"keras.utils.plot_model(my_model)","b4b6a6b9":"model = my_model.fit(x_train,y_train,epochs=750)\nmean = np.mean(model.history['accuracy'])\nprint(\"Accuracy mean: \"+ str(mean))","8be05302":"model.params","c6f4b483":"pd.DataFrame(model.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","ff26b82d":"y_predict = my_model.predict(X)\ncm = confusion_matrix(Y,np.argmax(y_predict, axis=1))\n\nf, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, ax=ax)","329dffbd":"ids = data_test['House_id']\n#predict = classifier.predict(data_test_x)\npredict = my_model.predict(X)\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'House_id' : ids, 'Sold': np.argmax(predict,axis=1)})\noutput.to_csv('submission.csv', index=False)","943be4b3":"submission = pd.read_csv('submission.csv', index_col=0)\nsubmission.head(50)","92553d53":"Outlier Treatment","a95353e7":"# 6. Neural Network : Keras Model","0c70c341":"# 5. Train and Test Split","09ac6eb0":"Variable Transformation and deletion","5b1444d9":"# 2. loading the Dataset","fd8d0a9a":"Our train data splitted as train and test data in order to feed in a Neural  Network correctly.\nTrain data is 80% and test data 20% of the House Prices Dataset.","ff4c50a9":"We are going to create an average variable for dist1, dist2, dist3 and dist4","4ab3f506":"Let's see the parameters for our trained model","4ddbd250":"Identifying Categorical Variables","fe9d9bb1":"The variable in the 19th column 'Sold' is the output variable to be predicted. All other variables are to be used as the predictor variables.\nWe are going to predict if the House can be sold or Not.","b4bc22ef":"The section code in above, You can find some information. \nThere are 19 features in the House Price data. \nIt has information about 506 Houses. \n2 features are integer type\n3 features are object type\n14 features are float type. \n \nSome features contain missing value.","0fdb1180":"# 4. Preparing Data","d7b0064b":"We have missing values in n_hos_beds variable : 498 of 506","4ebc39e6":"# 1. Importing Libraries","8476ef7d":"Now we can delete the variable dist1, dist2, dist3 and dist4","a2a65bfd":"Missing values Imputation","16438749":"# 3. Exploratory Data Analysis","a9450dea":"We have 3 Categorical variables : airport, Waterbody and bus terminal","bf0bcea8":"Dummy variable creation","1a0b12b4":"We got all the values of n_hot_rooms greater than percentile value.\n\nreplace the value of 101.12 and 81.12 by values close to 15.399519999999","226e6fea":"Model Evaluation using Confusion Matrix","6a402903":"Correlation Analysis","97935996":"We are going to create dummy variable for categorical variables"}}