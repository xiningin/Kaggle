{"cell_type":{"f887e48a":"code","2af920a1":"code","f4bdc966":"code","5931dc5f":"code","00738459":"code","6d0d6ad1":"code","e7000437":"code","cf322591":"code","12a86cd3":"code","67198f05":"code","6f721353":"code","a407a348":"code","823f2dff":"code","4bb2fdf3":"code","0481fd61":"code","0357253c":"code","222feaa6":"code","808e3a0f":"code","1847219b":"code","d1862c8a":"code","d9a11726":"code","19cffe92":"markdown"},"source":{"f887e48a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2af920a1":"#Importing the packages required\n\nimport cv2\nimport math\nimport matplotlib.pyplot as plt","f4bdc966":"def addNoise(image,magnitude):\n  '''This function adds noise to the image'''\n  temp=[]\n  for x in np.nditer(image):\n    random=np.random.rand()\n    if magnitude>random:\n      x=np.random.randint(255) # If magnitude is greater than random numeber then add noise to that pixel\n    temp.append(x)\n  temp=np.array(temp,dtype=np.uint8).reshape(image.shape[0],image.shape[1],image.shape[2])  \n  return temp","5931dc5f":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\n\n#Genereating some output noise images\n\nfig,axs=plt.subplots(1,4,figsize=(18,15))\n\nplt.subplot(141)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\nplt.subplot(142)\ni=addNoise(img,0.3)\nplt.title('With 0.3 Noise')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.subplot(143)\ni=addNoise(img,0.5)\nplt.title('With 0.5 Noise')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.subplot(144)\ni=addNoise(img,1)\nplt.title('With 1.0 Noise')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.show()","00738459":"def Brighten(image,magnitude):\n  '''This funtion Brightesns the given input images'''\n  temp=[]\n  for x in np.nditer(image):\n    x=x*magnitude\n    if x>255:\n      x=255\n    temp.append(x)\n  temp=np.array(temp,dtype=np.uint8).reshape(image.shape[0],image.shape[1],image.shape[2])  \n  return temp","6d0d6ad1":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\nfig,axs=plt.subplots(1,4,figsize=(18,15))\n\nplt.subplot(141)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\nplt.subplot(142)\ni=Brighten(img,0)\nplt.title('0 Brightness')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.subplot(143)\ni=Brighten(img,0.5)\nplt.title('0.5 Brightness')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.subplot(144)\ni=Brighten(img,1.5)\nplt.title('1.5 Brightness')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nplt.show()","e7000437":"def ChangeContrast(image,magnitude):\n  '''This function Generates contrast images'''\n  temp=[]\n  magnitude=magnitude*(255)-255\n  f=(259*(255+magnitude))\/(255*(259-magnitude))\n  for x in np.nditer(image):\n    x=f*(x-128)+128\n    temp.append(x)\n  temp=np.array(temp,dtype=np.uint8).reshape(image.shape[0],image.shape[1],image.shape[2])  \n  return temp","cf322591":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\nfig,axs=plt.subplots(1,4,figsize=(18,15))\n\nplt.subplot(141)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\n\ni=ChangeContrast(img,-0.5)\nplt.subplot(142)\nplt.title('-0.5 Contrast Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\ni=ChangeContrast(img,0)\nplt.subplot(143)\nplt.title('0 Contrast Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\ni=ChangeContrast(img,0.5)\nplt.subplot(144)\nplt.title('0.5 Contrast Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\n\nplt.show()","12a86cd3":"#https:\/\/www.imageeprocessing.com\/2014\/04\/gaussian-filter-without-using-matlab.html\ndef get_gaussian_filter(sigma):\n  '''This function gets the Gaussian filter for corresponding sigma'''\n  filter_width=int(math.ceil(3*sigma)*2+1)\n  x=filter_width\/\/2\n  gaussian_filter=np.zeros((filter_width,filter_width))\n  for i in range(-x,x+1):\n    for j in range(-x,x+1):\n      numerator=math.exp(-1*(i**2+j**2)\/(2*(sigma**2)))\n      denominator=2*math.pi*(sigma**2)\n      gaussian_filter[i][j]=numerator\/denominator\n  return gaussian_filter","67198f05":"import math\ndef Blur(image,magnitude):\n  '''This function blurs the images'''\n  sigma=magnitude\n  gaussian_filter=get_gaussian_filter(sigma)\n  blurred_image= np.zeros((image.shape[0]-gaussian_filter.shape[0], image.shape[1]-gaussian_filter.shape[0],image.shape[2]))\n  for x in range(image.shape[0]-gaussian_filter.shape[0]):\n    for y in range(image.shape[1]-gaussian_filter.shape[1]):\n      for z in range(image.shape[2]):\n        blurred_image[x,y,z]=(gaussian_filter * image[x: x+gaussian_filter.shape[0], y: y+gaussian_filter.shape[1],z]).sum()\n  blurred_image=np.array(blurred_image,dtype=np.uint8)\n  return blurred_image","6f721353":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\nfig,axs=plt.subplots(1,4,figsize=(18,15))\n\nplt.subplot(141)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\ni=Blur(img,0.8)\nplt.subplot(142)\nplt.title('0.8 Blurred Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\ni=Blur(img,2)\nplt.subplot(143)\nplt.title('2 Blurred Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\ni=Blur(img,8)\nplt.subplot(144)\nplt.title('8 Blurred Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\nplt.show()","a407a348":"def Sharpen(image):\n  '''This Function Sharpens the Images'''\n  #sigma=magnitude\n  sharpen_filter=np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n  image_padded = np.zeros((image.shape[0] + 2, image.shape[1] + 2,image.shape[2]))\n  image_padded[1:-1, 1:-1,:] = image\n  sharpened_image= np.zeros((image.shape[0], image.shape[1],image.shape[2]))\n  for x in range(image.shape[0]):\n    for y in range(image.shape[1]):\n      for z in range(image.shape[2]):\n        sharpened_image[x,y,z]=(sharpen_filter * image_padded[x: x+3, y:y+3,z]).sum()\n  sharpened_image=np.array(sharpened_image,dtype=np.uint8)\n  return sharpened_image","823f2dff":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\nfig,axs=plt.subplots(1,2,figsize=(8,6))\n\nplt.subplot(121)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\n\ni=Sharpen(img)\nplt.subplot(122)\nplt.title('Sharpened Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nplt.show()","4bb2fdf3":"def EdgeDetect(image):\n  '''This Function is used for edge detection'''\n  sharpen_filter=np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]) \n  image_padded = np.zeros((image.shape[0] + 2, image.shape[1] + 2,image.shape[2]))\n  image_padded[1:-1, 1:-1,:] = image\n  sharpened_image= np.zeros((image.shape[0], image.shape[1],image.shape[2]))\n  for x in range(image.shape[0]):\n    for y in range(image.shape[1]):\n      for z in range(image.shape[2]):\n        sharpened_image[x,y,z]=abs((sharpen_filter * image_padded[x: x+3, y:y+3,z]).sum())\n  sharpened_image=np.array(sharpened_image,dtype=np.uint8)\n  return sharpened_image","0481fd61":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/cube.jpg')\n\nfig,axs=plt.subplots(1,2,figsize=(8,6))\n\nplt.subplot(121)\nplt.title('Original Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\ni=EdgeDetect(img)\nplt.subplot(122)\nplt.title('Edge Detected Image')\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nplt.show()","0357253c":"def Upscaling(image,scale):\n  image_upscaled = np.zeros((image.shape[0] * scale, image.shape[1] * scale,image.shape[2]))\n  i,j=0,0\n  for x in range(image.shape[0]):\n    j=0\n    for y in range(image.shape[1]):\n      for s in range(scale):\n        image_upscaled[i+s,j+s,:]=image[x,y,:]\n      j+=scale\n    i+=scale\n  image_upscaled=np.array(image_upscaled,dtype=np.uint8)\n  return image_upscaled","222feaa6":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/sunflower.jpg')\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 7), dpi=80, sharex=True, sharey=True)\nfig.patch.set_visible(False)\n\nax[0].axis('off')\nax[0].set_title('Original Image',loc='left')\nax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\n\ni=Upscaling(img,2)\nax[1].axis('off')\nax[1].set_title('2x Image',loc='left')\nax[1].imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\n\ni=Upscaling(img,3)\nax[2].axis('off')\nax[2].set_title('3x Image',loc='left')\nax[2].imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nplt.show()","808e3a0f":"def Downsample(image,scale):\n  image_downscaled = np.zeros((int(image.shape[0] * scale),int( image.shape[1] * scale),image.shape[2]))\n  downscale_factor=int(1\/scale)\n  for x in range(image_downscaled.shape[0]):\n    for y in range(image_downscaled.shape[1]):\n      image_downscaled[x,y,:]=image[x*downscale_factor,y*downscale_factor,:]\n  image_downscaled=np.array(image_downscaled,dtype=np.uint8)\n  return image_downscaled","1847219b":"img=cv2.imread('..\/input\/imageprocessingtechniquesinput\/apples.jpg')\n\nfigsize = img.shape[1]\/80, img.shape[0]\/80\nfig = plt.figure(figsize=figsize)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nprint('Original Image')\nplt.show()\n\ni=Downsample(img,0.5)\nfigsize = i.shape[1]\/80, i.shape[0]\/80\nfig = plt.figure(figsize=figsize)\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nprint('Downscale Image 2x')\nplt.show()\n\ni=Downsample(img,0.3)\nfigsize = i.shape[1]\/80, i.shape[0]\/80\nfig = plt.figure(figsize=figsize)\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nprint('Downscale Image 3x')\nplt.show()\n\ni=Downsample(img,0.2)\nfigsize = i.shape[1]\/80, i.shape[0]\/80\nfig = plt.figure(figsize=figsize)\nplt.imshow(cv2.cvtColor(i, cv2.COLOR_BGR2RGB))\nprint('Downscale Image 5x')\nplt.show()","d1862c8a":"def composite(image,top,mask):\n  output=np.zeros(image.shape)\n  output=np.array(output,dtype=np.uint8)\n  for x in range(mask.shape[0]):\n    for y in range(mask.shape[1]):\n      if mask[x,y,:].sum()<=255:\n        output[x,y,:]=image[x,y,:]\n      else:\n        output[x,y,:]=top[x,y,:]\n  return output","d9a11726":"image=cv2.imread('..\/input\/imageprocessingtechniquesinput\/comp_background.jpg')\ntop=cv2.imread('..\/input\/imageprocessingtechniquesinput\/comp_foreground.jpg')\nmask=cv2.imread('..\/input\/imageprocessingtechniquesinput\/comp_mask.jpg')\n\nfig,axs=plt.subplots(1,4,figsize=(20,15))\n\nplt.subplot(141)\nplt.title('Base Image')\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\n\nplt.subplot(142)\nplt.title('Top Image')\nplt.imshow(cv2.cvtColor(top, cv2.COLOR_BGR2RGB))\n\nplt.subplot(143)\nplt.title('Mask Image')\nplt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n\nimg=composite(image,top,mask)\nplt.subplot(144)\nplt.title('Composite Image')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","19cffe92":"This Notebook has following Techniques implemenented: \n\nAll these image processing techniques are done from scratch in python\n\n* Brighten\n\n* addNoise\n\n* ChangeContrast\n\n* Blur\n\n* Sharpen\n\n* EdgeDetect\n\n* Upscaling\n\n* Downscaling\n\n* composite"}}