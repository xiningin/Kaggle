{"cell_type":{"be4f824d":"code","1cdcc67e":"code","d116be4c":"code","653b245b":"code","df8e8050":"code","d74a07a9":"code","f8402529":"code","3d95c655":"code","04f39b4a":"code","f8395c1e":"code","e43f1923":"code","c9b97430":"code","e434dd6f":"code","34c0810d":"code","21f7e9e8":"code","d97ec441":"code","48b9532b":"code","36a49605":"code","70a38644":"code","b928d42f":"code","5820832f":"code","e18ff4ab":"code","43255044":"code","b1a5770b":"code","ad03a078":"code","eeb0ceb1":"code","663b6b40":"code","dc21b7a0":"code","4677e865":"code","b78aade2":"code","f144251f":"code","6560a426":"code","96dab832":"code","d3427926":"code","ef963f5a":"code","10e2edbf":"code","ee906c68":"code","55688884":"markdown","266cc6cf":"markdown","cef6dece":"markdown","3b4e8397":"markdown","06586d43":"markdown","c922b89c":"markdown","2d4824e2":"markdown","c509740c":"markdown","37fdd13b":"markdown","254f10b0":"markdown","a679bebd":"markdown","bad4a2bc":"markdown","d16ace33":"markdown","68336552":"markdown","5f4ec214":"markdown","0184b338":"markdown","4774d88f":"markdown","22f1cfeb":"markdown"},"source":{"be4f824d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1cdcc67e":"# importing necessary libraries\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","d116be4c":"# loading datasets ODI_data_1971_2017 and ODI_data_2017_2021\ndata_1971_2017 = pd.read_csv('\/kaggle\/input\/odi-cricket-match-data\/ODI-data-1971-2017-2.csv')\ndata_2017_2021 = pd.read_csv('\/kaggle\/input\/odi-cricket-match-data\/ODI-Data-2017-2021.csv')","653b245b":"# ODI_data_1971_2017 data\ndata_1971_2017.head()","df8e8050":"# ODI_data_2017_2021 data\ndata_2017_2021.head()","d74a07a9":"data_1971_2017.shape, data_2017_2021.shape","f8402529":"data_2017_2021.drop(['Unnamed: 0'],axis=1,inplace=True)","3d95c655":"data_1971_2017.nunique()","04f39b4a":"data_2017_2021.nunique()","f8395c1e":"data_1971_2017['Match Date'].unique()","e43f1923":"data_2017_2021['Match Date'].unique()","c9b97430":"# droping rows with index range 0 to 116, reset index and drop old index of data\ndata_2017_2021 = data_2017_2021.drop(range(0,116))\ndata_2017_2021.reset_index(inplace=True,drop=True)","e434dd6f":"# loading data_1971_2021 dataset\ndata_1971_2021 = pd.concat([data_1971_2017,data_2017_2021],ignore_index=True)","34c0810d":"# droping values from 0 to 2936 as these are all samples before year 2010\n# Storing all remaining samples in new dataframe\ndata_2010_2021 = data_1971_2021.drop(range(0,2936),axis=0)\n\n# reseting index \ndata_2010_2021.reset_index(inplace=True,drop=True)","21f7e9e8":"data_2010_2021.head()","d97ec441":"# all column names\ndata_2010_2021.columns","48b9532b":"# info of complete dataset\ndata_2010_2021.info()","36a49605":"# information like total count in every columns\ndata_2010_2021.describe()","70a38644":"# printing len of datset, which tells total number of samples in dataset\nlen(data_2010_2021)","b928d42f":"# count of unique values of each column\ndata_2010_2021.nunique()","5820832f":"# missing values in all columnns of dataset\ndata_2010_2021.isnull().sum()","e18ff4ab":"# importing necessary libraries needed for performing Chi-square test\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import chi2\n# function for performing chi-square test\ndef applying_chiSquare_test(col1,col2):\n    # contingency table\n    contingency_table = pd.crosstab(data_2010_2021[col1],data_2010_2021[col2])\n    # observed values\n    observed_values = contingency_table.values\n    # expected values\n    chi2_contingency_val = chi2_contingency(contingency_table)\n    expected_values = chi2_contingency_val[3]\n    # degree of freedom\n    rows_number = len(contingency_table.iloc[0:,0])\n    columns_number = len(contingency_table.iloc[0,0:])\n    degree_of_freedom = (rows_number-1)*(columns_number-1)\n    print(f'Degree Of Freedom: {degree_of_freedom}')\n    # significance level 5%\n    alpha = 0.05\n    print(f'Significance Level: {alpha}')\n    # chi_square statistic\n    chi_square = sum([(od_V-ex_V)**2.\/ex_V for od_V,ex_V in zip(observed_values,expected_values)])\n    chi_square_stats = chi_square[0] + chi_square[1]\n    print(f'Chi Square Statistic: {chi_square_stats}')\n    # critical_value\n    critical_value = chi2.ppf(q=1 - alpha,df=degree_of_freedom)\n    print(f'Critical Value: {critical_value}')\n    # p-value\n    p_value = 1 - chi2.cdf(x=chi_square_stats,df=degree_of_freedom)\n    print(f'p-value: {p_value}')\n    \n    # checking condition based on chi_square_statistic and critical value for hypothesis rejection     \n    if chi_square_stats >= critical_value:\n        print('Reject H0,There is a relationship between 2 categorical variables')\n    else:\n        print('Reject H0,There is no relationship between 2 categorical variables')\n       \n    # checking condition based on p value and alpha for hypothesis rejection  \n    if p_value <= alpha:\n        print('Reject H0,There is a relationship between 2 categorical variables')\n    else:\n        print('Reject H0,There is no relationship between 2 categorical variables')\n        \n'''-----------------------------------------------'''       \n\n# looping on whole dataset for performing chi-square test\nfor col1 in data_2010_2021.columns:\n    \n    # inner loop on whole dataset columns name\n    for col2 in data_2010_2021.columns:\n\n        # condition check if both column names are not equal\n        if col1 != col2:\n            print(f\"Chi_Square Test On =>> [{col1,col2}]\\n\")\n            # passing both column names to chi-sqaure performance function\n            applying_chiSquare_test(col1,col2)\n            print('----'*16,'\\n')","43255044":"# importing scipy\nimport scipy\n# importing hierarchy from skleanr.cluster\nfrom scipy.cluster import hierarchy","b1a5770b":"# Plot a Dendrogram on the columns of the dataset\n\n# creating a varibake to store data_2010_2021 after dropin nan values\ntemp_data = data_2010_2021.dropna()\n\n# createing corr variable to store correlation results\ncorr = np.round(scipy.stats.spearmanr(temp_data ).correlation,4)\n# condensing corr variable\ncondensed_corr = hierarchy.distance.squareform(1-corr)\n# passing condensed_corr variable to hierarchy linkage for getting average and then sorting it in new varibale\navg = hierarchy.linkage(condensed_corr,method='average')\n\n# ploting a dendogram with values of new varibale just created above\nfig = plt.figure(figsize=(16,5))\ndendrogram = hierarchy.dendrogram(avg,labels=temp_data .columns,orientation='left')\nplt.show()","ad03a078":"data_2010_2021.isnull().sum()","eeb0ceb1":"# Droping rows with missing values and reseting index of samples\ndata_2010_2021.dropna().reset_index(inplace=True)\n","663b6b40":"data_2010_2021.Winner.unique()","dc21b7a0":"data_2010_2021.Winner.value_counts()","4677e865":"# Filtering out rows which contain winner column values as 'no result' and 'tied'\ndata_2010_2021 = data_2010_2021[(data_2010_2021.Winner != 'no result') & (data_2010_2021.Winner != 'tied')]\n# reseting index of samples and droping extra \"index\" column from dataset\ndata_2010_2021.reset_index().drop(['index'],axis=1,inplace=True)","b78aade2":"data_2010_2021.Margin.unique()","f144251f":"data_2010_2021.Margin.dtype","6560a426":"for element in data_2010_2021.Margin:\n    e = element","96dab832":"e","d3427926":"for element in data_2010_2021.Margin:\n    num_word_split_data = element.split(' ')\n    ","ef963f5a":"num_word_split_data","10e2edbf":"# creating a list for storing runs\nwon_by_runs = []\n# creating a list for storing wickets\nwon_by_wickets = []\n# looping through dataset column Margin\nfor element in data_2010_2021.Margin:\n# splitting string data by space and making a list\n    num_word_split_data = element.split(' ')\n    \n    ### Exception handling #####\n    try:    \n    # searching for index of \"run\" in string, after success index of \"run\" will be stored in index variable \n        run_index_search = num_word_split_data.index('run')\n    # appending first element from splitted data after converting to integer to won by run list created before looping \n        won_by_runs.append(int(num_word_split_data[run_index_search-1]))\n    # appending 0 from splitted data to won by wicket list created before looping\n        won_by_wickets.append(0)\n    except:\n    # if failed --> print(\"run_index_search_failes\")\n        #print('---run_index_search_failes---')\n        pass\n\n  ### Exceptin handling ###\n    try:\n    # searching for index of \"runs\" in string, after success index of \"runs\" will be stored in index variable \n        runs_index_search = num_word_split_data.index('runs')\n    # appending first element from splitted data after converting to integer to won by run list created before looping \n        won_by_runs.append(int(num_word_split_data[runs_index_search-1]))\n    # appending 0 from splitted data to won by wicket list created before looping\n        won_by_wickets.append(0)\n    except:\n    # if failed --> print(\"runs_index_search_failes\")\n        #print('---runs_index_search_failes---')\n        pass\n    \n\n  ### Exceptin handling ###\n    try:\n    # searching for index of \"wicket\" in string, after success index of \"wicket\" will be stored in index variable \n        wicket_index_search = num_word_split_data.index('wicket')\n    # appending first element from splitted data after converting to integer to won by wicket list created before looping \n        won_by_wickets.append(int(num_word_split_data[wicket_index_search-1]))\n    # appending 0 from splitted data to won by run list created before looping\n        won_by_runs.append(0)\n    except:\n    # if failed --> print(\"wicket_index_search_failes\")\n        #print('---wicket_index_search_failes---')\n        pass\n   \n\n  ### Exceptin handling ###\n    try:\n    # searching for index of \"wickets\" in string, after success index of \"wickets\" will be stored in index variable \n        wickets_index_search = num_word_split_data.index('wickets')\n    # appending first element from splitted data after converting to integer to won by wicket list created before looping \n        won_by_wickets.append(int(num_word_split_data[wickets_index_search-1]))\n    # appending 0 from splitted data to won by run list created before looping\n        won_by_runs.append(0)\n    except:\n    # if failed --> print(\"wickets_index_search_failes\")\n        #print('---wickets_index_search_failes---')\n        pass\n\n\n# adding a new column named 'won_by_runs' to Datframe with respectiev data list\ndata_2010_2021['Won_by_runs'] = won_by_runs\n# adding a new column named 'won_by_wickets' to Datframe with respectiev data list\ndata_2010_2021['Won_by_wickets'] = won_by_wickets","ee906c68":"data_2010_2021.head()","55688884":"Margin have 49 null values\n* I am droping these empty rows \n    * as all of the data is categorical and if we replace missing values with random values it will affect correctness of prediction","266cc6cf":"Observe `Team1` and `Winner` are `strongly correlated variables`\n","cef6dece":"# Feature Engineering -2 \n* Trying to find out which team bolled first and wise versa\n\n\nTrying to Extract `Team1_batted_first` and `Team2_batted_first` column data from `Won_by_runs` and `Won_by_wickets` columns\n\n**`Domain knowledge:`**<br>\n* if team wins by wickets means => team got first chance to bowl\n* if team wins by runs means => team got first chance to batt","3b4e8397":"Observe there is space between number and words[43 runs] or [3 wickets], I am trying to split the on basis of space","06586d43":"# Dataset Desciption\n\nDataset folder contains following file:\n\n>`ODI-data-1971-2017.csv` having `3932 rows x 7 columns`<br>\nColumns Provided in Dataset\n\n1. Scorecard\n2. Team 1\n3. Team 2\n4. Winner\n5. Margin\n6. Ground\n7. Match Date\n\n\n>`ODI-data-2017-2021.csv` having `495 x 8 columns`<br>\nColumns Provided in Dataset\n\n1. Scorecard\n2. Team 1\n3. Team 2\n4. Winner\n5. Margin\n6. Ground\n7. Match Date\n8. Unnamed: 0","c922b89c":"**`Trying to break down `Margin` column which is Object data type into two columns named `won_by_runs` and `won_by_wickets` both as numerical datatype int64`**","2d4824e2":"Trying to drop rows of `year 2017` present in `data_2017_2021` wich are alredy present in `data_1971_2017` as we are concerned about data between 2010 t0 2021\n\n`I have to concat both data to get data from 2010 to 2021`","c509740c":"# Dendrogram\n","37fdd13b":"# Feature Engineering -1\nThe most important step in workflow of machine learning\n* ML model work well if data provided to model is relevant and useful","254f10b0":"Observe there are some values as `no result` 10 times and `tied` 4 times","a679bebd":"# What is the Problem Statement\n\nTo predict future ODI cricket match winner based on previous year's match result\n\nI am intrusted in 2010 to 2021 data only as this is more recent","bad4a2bc":"Observe you will see \n* `object` -> String values  ==> All columns are of string datatype","d16ace33":"# EDA","68336552":"Observe there are missing values in the `Margin` column of dataset","5f4ec214":"# Chi-square Test\n\n","0184b338":"<h2><center>Work In Progress<\/center><\/h2>\n","4774d88f":"![image.png](attachment:0b05555d-6839-4321-a329-19307c3fd940.png)","22f1cfeb":"8th column is `Unnamed: 0` of no use this is index, so droping it"}}