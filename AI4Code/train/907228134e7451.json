{"cell_type":{"fcd787e7":"code","6703c39e":"code","004529ef":"code","4e82d846":"code","411d9157":"code","85fdbd07":"code","ec034152":"code","b466bb77":"code","a9221481":"code","add19f23":"code","719ded29":"code","1ba52814":"code","6bdb7810":"code","fbf8acb9":"markdown","d2e4ba0d":"markdown","92ea8715":"markdown","754c0b9b":"markdown"},"source":{"fcd787e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_context(\"talk\")\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6703c39e":"data = pd.read_csv('\/kaggle\/input\/emotion.data')\ndata.info()","004529ef":"data.head()","4e82d846":"data['emotions'].value_counts().plot.bar()\nplt.show()","411d9157":"data = data.drop(['Unnamed: 0'], axis=1)\nX = data['text']\ny = data['emotions']","85fdbd07":"train, test = train_test_split(data, test_size = 0.2, random_state = 12, stratify = data['emotions'])","ec034152":"X_train = train.text\ny_train = train.emotions\nX_test = test.text\ny_test = test.emotions","b466bb77":"vectorizer = TfidfVectorizer( max_df= 0.9).fit(X_train)\nX_train = vectorizer.transform(X_train)\nX_test = vectorizer.transform(X_test)\nprint(X_train.shape)","a9221481":"encoder = LabelEncoder().fit(y_train)\ny_train = encoder.transform(y_train)\ny_test = encoder.transform(y_test)","add19f23":"model = LogisticRegression(C=.1, class_weight='balanced')\nmodel.fit(X_train, y_train)\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\nprint(\"Training Accuracy : \", accuracy_score(y_train, y_pred_train))\nprint(\"Testing Accuracy  : \", accuracy_score(y_test, y_pred_test))\n","719ded29":"def predict_(x, plot=False):\n    tfidf = vectorizer.transform([x])\n    preds = model.predict_proba(tfidf)[0]\n    plt.figure(figsize=(8,4))\n    sns.barplot(x= encoder.classes_, y=preds)\n    plt.show()\n    return preds","1ba52814":"text = \"this kernel gives a baseline LR model for the problem fairly well, although we can improve it\"","6bdb7810":"predict_(text, plot=True)","fbf8acb9":"## Reading Data:","d2e4ba0d":"## Predictions:","92ea8715":"## Model Training:","754c0b9b":"## Data Modeling:"}}