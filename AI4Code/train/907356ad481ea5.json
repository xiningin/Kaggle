{"cell_type":{"2aee9d05":"code","e3744324":"code","bc5f3b4d":"code","9de0644c":"code","e9f6ded5":"code","eb28c7b5":"code","fedb17c9":"code","ca38f5e8":"code","80061f55":"code","41c6def7":"code","1d1d5fa5":"code","490973c3":"code","09b21d55":"code","4cd4254b":"code","442a98ab":"code","54de11bf":"code","33607ca0":"code","525fc8d2":"markdown","0b19c4c9":"markdown","1a6a5274":"markdown","0d4618ee":"markdown","bbf3d760":"markdown"},"source":{"2aee9d05":"from pathlib import Path","e3744324":"import pandas as pd\ndata_path = Path(\"..\/input\/google-smartphone-decimeter-challenge\")\ndf_test = pd.read_csv(\n    data_path \/ 'baseline_locations_test.csv')\ndf_sub    = pd.read_csv(\n    data_path \/ 'sample_submission.csv')","bc5f3b4d":"import numpy as np\nfrom tqdm.notebook import tqdm\ntruths = (data_path \/ 'train').rglob('ground_truth.csv')\n    # returns a generator\n\ndf_list = []\ncols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg',\n       'lngDeg']\n\nfor t in tqdm(truths, total=73):\n    df_phone = pd.read_csv(t, usecols=cols)  \n    df_list.append(df_phone)\ndf_truth = pd.concat(df_list, ignore_index=True)\n\ndf_basepreds = pd.read_csv(data_path \/ 'baseline_locations_train.csv', usecols=cols)\ndf_all = df_truth.merge(df_basepreds, how='inner', on=cols[:3], suffixes=('_truth', '_basepred'))","9de0644c":"def calc_haversine(lat1, lon1, lat2, lon2):\n    \"\"\"Calculates the great circle distance between two points\n    on the earth. Inputs are array-like and specified in decimal degrees.\n    \"\"\"\n    RADIUS = 6_367_000\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat\/2)**2 + \\\n        np.cos(lat1) * np.cos(lat2) * np.sin(dlon\/2)**2\n    dist = 2 * RADIUS * np.arcsin(a**0.5)\n    return dist","e9f6ded5":"df_all['dist'] = calc_haversine(df_all.latDeg_truth, df_all.lngDeg_truth, \n    df_all.latDeg_basepred, df_all.lngDeg_basepred)","eb28c7b5":"df_all.dist.describe()","fedb17c9":"df_all.sort_values(by = 'dist',ascending = False)[['collectionName','dist']].head(10)","ca38f5e8":"df_test['dist_pre'] = 0\ndf_test['dist_pro'] = 0","80061f55":"for i in tqdm(range(1,len(df_test))):\n    lat1 = df_test.loc[i-1,'latDeg']\n    lon1 = df_test.loc[i-1,'lngDeg']\n    lat2 = df_test.loc[i,'latDeg']\n    lon2 = df_test.loc[i,'lngDeg']\n    df_test.loc[i,'dist_pre'] = calc_haversine(lat1, lon1, lat2, lon2)\n\nlist_phone = df_test['phone'].unique()\nfor phone in list_phone:\n    ind = df_test[df_test['phone'] == phone].index[0]\n    df_test.loc[ind,'dist_pre'] = 0","41c6def7":"for i in tqdm(range(0,len(df_test)-1)):\n    lat1 = df_test.loc[i,'latDeg']\n    lon1 = df_test.loc[i,'lngDeg']\n    lat2 = df_test.loc[i+1,'latDeg']\n    lon2 = df_test.loc[i+1,'lngDeg']\n    df_test.loc[i,'dist_pro'] = calc_haversine(lat1, lon1, lat2, lon2)\nlist_phone = df_test['phone'].unique()\nfor phone in list_phone:\n    ind = df_test[df_test['phone'] == phone].index[-1]\n    df_test.loc[ind,'dist_pro'] = 0","1d1d5fa5":"df_test.dist_pre.describe()","490973c3":"pro_95 = df_test['dist_pro'].mean() + (df_test['dist_pro'].std() * 2)\npre_95 = df_test['dist_pre'].mean() + (df_test['dist_pre'].std() * 2)\nind = df_test[(df_test['dist_pro'] > pro_95)&(df_test['dist_pre'] > pre_95)][['dist_pre','dist_pro']].index\n\nfor i in ind:\n    df_test.loc[i,'latDeg'] = (df_test.loc[i-1,'latDeg'] + df_test.loc[i+1,'latDeg'])\/2\n    df_test.loc[i,'lngDeg'] = (df_test.loc[i-1,'lngDeg'] + df_test.loc[i+1,'lngDeg'])\/2","09b21d55":"!pip install simdkalman","4cd4254b":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport simdkalman\nfrom tqdm.notebook import tqdm","442a98ab":"T = 1.0\nstate_transition = np.array([[1, 1, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 1, 1, 0, T, 0],\n                             [0, 1, 0, 1, 0, T], [0, 1, 0, 0, 1, 0], [0, 1, 0, 0, 0, 1]])\nprocess_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\nobservation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\nobservation_noise = np.diag([5e-10, 5e-10]) + np.ones((2, 2)) * 1e-9\n#ecept 2nd all 6 has 2 on 2nd vlaue 5e-5.\nkf = simdkalman.KalmanFilter(\n        state_transition = state_transition,\n        process_noise = process_noise,\n        observation_model = observation_model,\n        observation_noise = observation_noise)","54de11bf":"def apply_kf_smoothing(df, kf_=kf):\n    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n    for collection, phone in tqdm(unique_paths):\n        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n        data = data.reshape(1, len(data), 2)\n        smoothed = kf_.smooth(data)\n        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n    return df","33607ca0":"kf_smoothed_baseline = apply_kf_smoothing(df_test)\ndf_sub = df_sub.assign(\n    latDeg = kf_smoothed_baseline.latDeg,\n    lngDeg = kf_smoothed_baseline.lngDeg\n)\ndf_sub.to_csv('submission.csv', index=False)","525fc8d2":"### Step.3 Kalman filter -----------------------------------------------------------------","0b19c4c9":"Finally, apply the Kalman filter.","1a6a5274":"#### Thank you for reading to the end.I look forward to your comments.","0d4618ee":"There seems to be an outlier, although it is smaller than the training data.","bbf3d760":"If the distance between the previous and next pass is large, it is either an outlier or a case of speed (straight line movement), so fix the value to the middle of the previous and next pass."}}