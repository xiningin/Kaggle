{"cell_type":{"08344d69":"code","effb553c":"code","17e9ef3b":"code","b5702d87":"code","471e0353":"code","84df4eb4":"code","193021a7":"code","4070992b":"code","11f6b5d1":"code","c7f41073":"markdown","8a5134bd":"markdown","807a7697":"markdown","06dfa766":"markdown","7bb97dcb":"markdown","f1f12bf5":"markdown","6db4648a":"markdown","4603c980":"markdown","e6419af7":"markdown"},"source":{"08344d69":"from pathlib import Path\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, optimizers, callbacks\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","effb553c":"# Load the CSV file\ndataset = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\n\n# Split into features\/X and labels\/y by reshaping all rows to 28x28x1 matrices\nX = np.array([np.array(row).reshape(28,28,1) for i,row in dataset.drop(columns=['label']).iterrows()])\ny = np.array(dataset.label)\nprint(X.shape, y.shape)","17e9ef3b":"fig, axs = plt.subplots(2, 5)\nfig.set_size_inches(24,10)\naxs = axs.flatten()\n# Iterate over all digits and plot a random sample\nfor i, number in enumerate(range(0,10)):\n    # Select random sample\n    image = X[np.random.choice(np.where(y==number)[0])]\n    axs[i].imshow(image, cmap='gray')\n    axs[i].set(title=f'Number {number}')\n    ","b5702d87":"model = tf.keras.Sequential(layers=[\n    layers.Input(shape=X[0].shape),\n    layers.Conv2D(32, 3, padding='same', activation=activations.relu),\n    layers.BatchNormalization(),\n    layers.Conv2D(32, 3, padding='same', activation=activations.relu),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation=activations.relu),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, 3, padding='same', activation=activations.relu),\n    layers.MaxPooling2D(),\n    layers.Conv2D(128, 3, padding='same', activation=activations.relu),\n    layers.BatchNormalization(),\n    layers.Conv2D(128, 3, padding='same', activation=activations.relu),\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(units=64, activation=activations.relu),\n    layers.Dense(units=32, activation=activations.relu),\n    layers.Dense(units=10, activation=activations.softmax)\n])\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.002), loss=losses.CategoricalCrossentropy(from_logits=True), \n              metrics=['accuracy'])\nprint(model.summary())","471e0353":"# Scale the data before splitting\nX = X \/ 255.0\n# Use train_test_split with 30% as testset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Encode the train labels\ny_train_enc = tf.one_hot(y_train, depth=10)\n\nprint(f'Trainset shape >> {X_train.shape} & {y_train_enc.shape}')\nprint(f'Testset shape >> {X_test.shape} & {y_test.shape}')","84df4eb4":"early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory = model.fit(X_train, y_train_enc, validation_split=0.3, batch_size=64, epochs=50, callbacks=[early_stopping])","193021a7":"# Plot loss and accuracy\nfig, axs = plt.subplots(ncols=2)\nfig.set_size_inches(12, 6)\nfor i, metric in enumerate(['loss', 'accuracy']):\n    axs[i].plot(history.epoch, history.history[f'{metric}'], label=f'Training {metric.title()}')\n    axs[i].plot(history.epoch, history.history[f'val_{metric}'], label=f'Validation {metric.title()}')\n    axs[i].legend()\n    axs[i].set(title=metric.title(), xlim=(0,max(history.epoch)))","4070992b":"# Predict the test set and create confusion matrix\ny_pred = np.argmax(model.predict(X_test), axis=1)\ncm = confusion_matrix(y_pred, y_test, normalize='true')\n\n# Plot the results\nfig, axs = plt.subplots()\nfig.set_size_inches(12, 12)\nsns.heatmap(cm, cmap='Blues', fmt='.2%', annot=True, ax=axs)\naxs.set(title='Confusion Matrix of Testset')\nplt.show()","11f6b5d1":"# Load the testset\nkaggle_dataset = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n# Transform and normalize\nkaggle_X = np.array([np.array(row).reshape(28,28,1) for i,row in kaggle_dataset.iterrows()]) \/ 255.0\n\n# Predict all samples and create submissions DataFrame\nkaggle_pred = np.argmax(model.predict(kaggle_X), axis=1)\nsubmissions_df = pd.DataFrame(data={'ImageId': np.arange(1, len(kaggle_X)+1), 'Label': kaggle_pred})\n\n# Save the results as CSV file\nsubmissions_df.to_csv('submission.csv', index=False)","c7f41073":"## Visualize some samples","8a5134bd":"## Predict the Kaggle Testset","807a7697":"## Evaluate the model","06dfa766":"## Train the model","7bb97dcb":"## Import the required libraries","f1f12bf5":"# Image Based Digit Classification using CNNs\n","6db4648a":"## Read in the dataset","4603c980":"## Create the model","e6419af7":"## Prepare the data"}}