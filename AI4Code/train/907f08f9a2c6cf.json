{"cell_type":{"d2efc634":"code","761539ac":"code","d5962024":"code","b14706d6":"code","ea1b973d":"code","a6bbc635":"code","10354cc9":"code","2135e08c":"code","28eb0824":"code","65fa80f9":"code","cc5075d7":"code","9e8808fc":"code","c9e1d7f5":"code","4db0fb2f":"code","65366453":"code","c40c2df3":"code","0a23f5c1":"code","0425fce4":"code","ba3a125a":"code","b5c34f75":"code","1decd10f":"code","7d6d749d":"code","accc7b00":"code","fb4b5a75":"code","ba5d6ec5":"code","a0590e04":"code","92e83613":"code","63eb99c9":"code","e2addfe3":"code","15f8f1fd":"code","d30a21fb":"code","5061e93a":"code","9efab34e":"code","7ea75dce":"code","0acd4ebd":"code","de9bbb51":"code","f8ab186b":"code","e5afbddb":"code","1dcfa97e":"code","b74cb47c":"code","77ace292":"code","d992fa06":"markdown","580a1fcd":"markdown","fdba6144":"markdown","1efadd13":"markdown","843049ec":"markdown","d4c2522d":"markdown","3b54a075":"markdown","7df0093e":"markdown","4dae36b2":"markdown","f7fdfde5":"markdown"},"source":{"d2efc634":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport random\nimport PIL\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\ndef seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    \nseed_everything(42)\nprint('ENVIRONMENT READY')","761539ac":"# Data augmentation\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n    T.RandomCrop(128, padding=8, padding_mode='reflect'),\n     #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.Resize((128, 128)),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(10),\n    T.ToTensor(), \n     T.Normalize(*imagenet_stats,inplace=True), \n    #T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n     T.Resize((128, 128)), \n    T.ToTensor(), \n     T.Normalize(*imagenet_stats)\n])","d5962024":"dataset = ImageFolder(root='\/kaggle\/input\/captchas-segmented\/data')\n\ndataset_size = len(dataset)\ndataset_size","b14706d6":"dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A',\n       11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K',\n       21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U',\n       31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e',\n       41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', \n       51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y',\n       61: 'z'}","ea1b973d":"random_image = np.random.randint(0, dataset_size)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","a6bbc635":"random_image = np.random.randint(0, dataset_size)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","10354cc9":"random_image = np.random.randint(0, dataset_size)\nprint('Random image number ', random_image)\nprint('Class label', dict[dataset[random_image][1]])\ndataset[random_image][0]","2135e08c":"classes = dataset.classes\nclasses","28eb0824":"num_classes = len(dataset.classes)\nnum_classes","65fa80f9":"test_size = 200\nnontest_size = len(dataset) - test_size\n\nnontest_df, test_df = random_split(dataset, [nontest_size, test_size])\nlen(nontest_df), len(test_df)","cc5075d7":"val_size = 200\ntrain_size = len(nontest_df) - val_size\n\ntrain_df, val_df = random_split(nontest_df, [train_size, val_size])\nlen(train_df), len(val_df)","9e8808fc":"test_df.dataset.transform = valid_tfms\nval_df.dataset.transform = valid_tfms\n\ntrain_df.dataset.transform = train_tfms\n","c9e1d7f5":"batch_size = 64\n\ntrain_dl = DataLoader(train_df, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\ntest_dl = DataLoader(test_df, batch_size*2, \n                    num_workers=2, pin_memory=True)","4db0fb2f":"for images, _ in train_dl:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","65366453":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","c40c2df3":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","0a23f5c1":"class CnnModel2(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.wide_resnet101_2(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs,62)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))","0425fce4":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","ba3a125a":"device = get_default_device()\ndevice","b5c34f75":"model = to_device(CnnModel2(), device)\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","1decd10f":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","7d6d749d":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","accc7b00":"# Set search to a larger number to test out more hyperparameters\nsearch = 1","fb4b5a75":"history = [evaluate(model, val_dl)]\nhistory","ba5d6ec5":"epochs = np.random.randint(2, 25)\nmax_lr = np.random.choice([5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6])\ngrad_clip = np.random.choice([0.5, 0.4, 0.3, 0.2, 0.1, 0.05])\nweight_decay = np.random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])\nopt_func = torch.optim.Adam\nprint('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)","a0590e04":"\n\ntorch.cuda.empty_cache()\n\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n\n","92e83613":"for j in range(search):\n    model = to_device(CnnModel2(), device)\n    history = [evaluate(model, val_dl)]\n    print(history)\n    epochs = np.random.randint(2, 25)\n    max_lr = np.random.choice([5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6])\n    grad_clip = np.random.choice([0.5, 0.4, 0.3, 0.2, 0.1, 0.05])\n    weight_decay = np.random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5])\n    opt_func = torch.optim.Adam\n    print('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)\n    torch.cuda.empty_cache()\n\n\n    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                                 grad_clip=grad_clip, \n                                 weight_decay=weight_decay, \n                                 opt_func=opt_func)","63eb99c9":"model = to_device(CnnModel2(), device)\nhistory = [evaluate(model, val_dl)]\nprint(history)\nepochs = 20\nmax_lr = 5e-5\ngrad_clip = 0.3\nweight_decay = 0.001\nopt_func = torch.optim.Adam\nprint('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)\ntorch.cuda.empty_cache()\n\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                                 grad_clip=grad_clip, \n                                 weight_decay=weight_decay, \n                                 opt_func=opt_func)","e2addfe3":"torch.save(model.state_dict(), 'captcha.pth')","15f8f1fd":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","d30a21fb":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)","5061e93a":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n\nplot_lrs(history)","9efab34e":"evaluate(model, val_dl)['val_acc']","7ea75dce":"evaluate(model, test_dl)['val_acc']","0acd4ebd":"dataset = ImageFolder(root='\/kaggle\/input\/captchas-segmented\/data')\n\ndataset_size = len(dataset)\ndataset_size\n\n# Data augmentation\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n    T.RandomCrop(128, padding=8, padding_mode='reflect'),\n     #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.Resize((128, 128)),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(10),\n    T.ToTensor(), \n     T.Normalize(*imagenet_stats,inplace=True), \n    #T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n     T.Resize((128, 128)), \n    T.ToTensor(), \n     T.Normalize(*imagenet_stats)\n])\n\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\ndevice = get_default_device()\ndevice\n\n\n\ntest_size = 200\nnontest_size = len(dataset) - test_size\n\nnontest_df, test_df = random_split(dataset, [nontest_size, test_size])\nlen(nontest_df), len(test_df)\n\nval_size = 200\ntrain_size = len(nontest_df) - val_size\n\ntrain_df, val_df = random_split(nontest_df, [train_size, val_size])\nlen(train_df), len(val_df)\n\ntest_df.dataset.transform = valid_tfms\nval_df.dataset.transform = valid_tfms\n\ntrain_df.dataset.transform = train_tfms\n\n\nbatch_size = 64\n\ntrain_dl = DataLoader(train_df, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\ntest_dl = DataLoader(test_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\n\n\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)\n\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\n","de9bbb51":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n\nclass CnnModel2(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.wide_resnet101_2(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs,62)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n\nmodel = to_device(CnnModel2(), device)\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\nmodel = to_device(CnnModel2(), device)\nmodel.load_state_dict(torch.load('\/kaggle\/input\/captcha-solver-ml\/captcha.pth'))","f8ab186b":"evaluate(model, val_dl)['val_acc']","e5afbddb":"evaluate(model, test_dl)['val_acc']","1dcfa97e":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","b74cb47c":"img, label = test_df[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","77ace292":"random_image = np.random.randint(0, len(test_df))\nprint('Random image number ', random_image)\nimg, label = test_df[random_image]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","d992fa06":"### EDA","580a1fcd":"### Test it out!","fdba6144":"### Conclusion\nOverall, this is a very good result. The final accuracy attained on the test set by the model is likely even higher than a human could have performed, considering the pixelated view of the characters. With the model that we exported, we can build a software capable of solving CAPTCHA images. To do that, we will now move onto the fourth and final notebook. Thank you for reading, and if you've made it this far please leave an upvote on this notebook, I really appreciate it!","1efadd13":"### Final Training with Best Hyperparameters","843049ec":"### Perform Train-Validation-Test Split","d4c2522d":"### Define the Models","3b54a075":"### Train the Model","7df0093e":"### Load in Data","4dae36b2":"# Captchas Classification\n## By Sergei Issaev\n### Introduction\nThis notebook is part of a pipeline which takes in CAPTCHA images and outputs the solution. This is the third notebook in the four part series. In this notebook, we will develop an MNIST-like model for digit recognition, with the goal of training a model to classify all of the segmented alphanumerics accurately. For a more complete description, please see my article published at: https:\/\/medium.com\/@sergei740.\n### Import Libraries \ud83d\udcda\u2b07","f7fdfde5":"### Final Results"}}