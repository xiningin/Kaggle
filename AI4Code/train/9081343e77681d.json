{"cell_type":{"b5da9287":"code","34edc457":"code","050f791d":"code","307fe488":"code","5c6807b4":"code","a8f0a91d":"code","fa6f88ef":"code","a001b0c5":"code","73c5687a":"code","c1e23dee":"code","f35cb042":"code","5c90de01":"code","99e821f2":"code","f35ad2c4":"code","3eadce90":"code","c4f6802c":"code","9cfd8cef":"code","e58160d0":"code","763bd29b":"code","f1631a7e":"code","2af857e9":"code","7b921be9":"code","d308993b":"code","9dc45913":"code","c12b626f":"code","8f1b2a2f":"code","b31768b9":"code","754472b1":"code","00c6c32b":"code","fc611a24":"code","10852d7d":"code","6ff6e637":"code","45b224d4":"code","69577247":"code","9d0226cd":"code","18b2d1b6":"code","98c792be":"code","3622caef":"code","9dbce570":"code","fef6e0ad":"code","3b043bb1":"code","67ffbebb":"code","915c57b3":"code","166e96b5":"code","5ba062a3":"code","8fdd57d1":"code","8f39f9eb":"code","e0c982a9":"code","908ce2f4":"code","3c88147b":"code","30868d3b":"markdown","0e85b85c":"markdown","3831ac90":"markdown","ec81f5c2":"markdown","c2d0b70c":"markdown","21ba97d3":"markdown","861c5d39":"markdown","d6f382ab":"markdown","86582f04":"markdown","2de4cd53":"markdown","dbe731c3":"markdown","1d9b34dd":"markdown","95c79c54":"markdown","5e4095ff":"markdown","818fc401":"markdown","5308c716":"markdown","6bf7f388":"markdown","8d47be21":"markdown","0912ddfe":"markdown","1b2934d7":"markdown","8e1a851c":"markdown"},"source":{"b5da9287":"# Libraries and some environment configurations\ntry:\n    import openpyxl\nexcept:\n    !pip install openpyxl\ntry:\n    import censusdata\nexcept:\n    !pip install censusdata\n    import censusdata\n\nimport pandas as pd\nimport re\nimport glob\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport geopandas as gpd\nfrom matplotlib.patches import Rectangle\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom warnings import simplefilter\nimport datetime as dt\nfrom IPython.display import Markdown as md\n# from IPython.display import Image\n\nimport gc\ngc.collect()\n\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n\npd.set_option('display.float_format', lambda x: '%.2f' % x)\npd.set_option('display.max_columns', None)\n\npal2 = [\"#ffcbf2\",\"#f3c4fb\",\"#ecbcfd\",\"#e5b3fe\",\"#e2afff\",\"#deaaff\",\"#d8bbff\",\"#d0d1ff\",\"#c8e7ff\",\"#c0fdff\"]","34edc457":"# Functions that will be used in the process\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n#     print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type) == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n#     print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n#     print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, index_col=None, header=0)\n    df = reduce_mem_usage(df)\n    return df\n","050f791d":"product_df = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\ndistrict_df = import_data(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\n\npath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\nli = []\nfor filename in all_files:\n    df = import_data(filename)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    if df.time.nunique() == 366:\n        li.append(df)\n    \nengagement_df = pd.concat(li, axis=0, ignore_index=True)\nengagement_df = engagement_df.reset_index(drop=True)\n\nengagement_df['district_id']=engagement_df['district_id'].astype(str)\ndistrict_df['district_id']=district_df['district_id'].astype(str)\ndistrict_df.loc[:,'district_id'] = district_df['district_id'].str.replace('\\.0', '')\n\n\ndel li, path, all_files\n\ngc.collect()","307fe488":"# Shape of the data files ( number of rows and number of columns) \nprint('\\033[1m'\"Shape of the Engagement File \"'\\033[0m',engagement_df.shape )\nprint('\\033[1m'\"Shape of the District File\"'\\033[0m', district_df.shape)\nprint('\\033[1m'\"Shape of the Product File\"'\\033[0m',product_df.shape)","5c6807b4":"show = district_df.head()\n\nshow = show.style.format(precision=0, na_rep='MISSING')\n\ncell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', '#ffffb3')]\n}\nindex_names = {\n    'selector': '.index_name',\n    'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n}\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': 'background-color: #000066; color: white;'\n}\nshow.set_table_styles([cell_hover, headers])\nshow.set_table_styles([\n    {'selector': 'th.col_heading','props': 'text-align: center; font-size:1.25em'},\n    {'selector': 'td', 'props': 'text-align: center;'},\n], overwrite=False)\nshow.set_caption(\"First 5 rows from district table\")\\\n .set_table_styles([{\n     'selector': 'caption',\n     'props': 'caption-side: bottom; font-size:1.25em;font-style: italic;'\n }], overwrite=False)\n\nshow.set_table_styles([  # create internal CSS classes\n    {'selector': '.border-red', 'props': 'border: 2px dashed red;'}\n], overwrite=False)\n\ncell_border = pd.DataFrame([[' ', ' ',' ',' ', ' ', ' ',' '],\n                           ['border-red ', 'border-red ', 'border-red ', 'border-red ','border-red ','border-red ','border-red '],\n                           [' ', ' ', ' ', ' ',' ',' ',' '],\n                           ['border-red ', 'border-red ', 'border-red ', 'border-red ','border-red ','border-red ','border-red '],\n                           ['border-red ', 'border-red ', 'border-red ', 'border-red ','border-red ','border-red ','border-red ']],\n                          index=show.index,\n                          columns=show.columns)\n\nshow.set_td_classes(cell_border)","a8f0a91d":"district_df.iloc[district_df[(district_df.isnull().sum(axis=1) ==6)].index].count()","fa6f88ef":"del show\ngc.collect()\n\ndistrict_df = district_df[['district_id','state','locale','pct_black\/hispanic']]\ndistrict_df = district_df[district_df.state.notna()]\ndistrict_df = district_df[district_df.district_id.isin(engagement_df.district_id.unique())].reset_index(drop=True)\ndistrict_df.head()","a001b0c5":"show = product_df.head()\n\nshow = show.style.format(precision=0, na_rep='MISSING')\n\ncell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', '#ffffb3')]\n}\nindex_names = {\n    'selector': '.index_name',\n    'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n}\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': 'background-color: #000066; color: white;'\n}\nshow.set_table_styles([cell_hover, headers])\nshow.set_table_styles([\n    {'selector': 'th.col_heading','props': 'text-align: center; font-size:1.25em'},\n    {'selector': 'td', 'props': 'text-align: center;'},\n], overwrite=False)\nshow.set_caption(\"First 5 rows from product table\")\\\n .set_table_styles([{\n     'selector': 'caption',\n     'props': 'caption-side: bottom; font-size:1.25em;font-style: italic;'\n }], overwrite=False)","73c5687a":"del show\ngc.collect()\n\ntemp_sectors = product_df['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproduct_df = product_df.join(temp_sectors)\n\ndel temp_sectors\ngc.collect()\n\nproduct_df['primary_function_main'] = product_df['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproduct_df['primary_function_sub'] = product_df['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproduct_df['primary_function_sub'] = product_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproduct_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\nproduct_df = product_df[product_df['LP ID'].isin(engagement_df.lp_id.unique())].reset_index(drop=True)","c1e23dee":"product_df.head()","f35cb042":"show = engagement_df.head()\n\nshow = show.style.format(precision=0, na_rep='MISSING')\n\ncell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', '#ffffb3')]\n}\nindex_names = {\n    'selector': '.index_name',\n    'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n}\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': 'background-color: #000066; color: white;'\n}\nshow.set_table_styles([cell_hover, headers])\nshow.set_table_styles([\n    {'selector': 'th.col_heading','props': 'text-align: center; font-size:1.25em'},\n    {'selector': 'td', 'props': 'text-align: center;'},\n], overwrite=False)\nshow.set_caption(\"First 5 rows from engagement table\")\\\n .set_table_styles([{\n     'selector': 'caption',\n     'props': 'caption-side: bottom; font-size:1.25em;font-style: italic;'\n }], overwrite=False)","5c90de01":"print(len(engagement_df))\nengagement_df = engagement_df[engagement_df.lp_id.isin(product_df['LP ID'].unique())]\nprint(len(engagement_df))\nengagement_df = engagement_df[engagement_df.district_id.isin(district_df['district_id'].unique())]\nprint(len(engagement_df))","99e821f2":"print(engagement_df.isna().sum())","f35ad2c4":"full_table = pd.merge(engagement_df,product_df, \"inner\", left_on='lp_id', right_on='LP ID')\nfull_table = pd.merge(full_table,district_df, \"inner\", on='district_id')\nfull_table = full_table[full_table.engagement_index.notna()]\nfull_table.dropna(subset = [\"state\"], inplace=True)","3eadce90":"full_table.shape","c4f6802c":"# full_table_sample1, full_table_sample2, state_sample1, state_sample2 = train_test_split(full_table.drop('state',axis=1), full_table['state'], stratify=full_table['state'], test_size=0.40)\n\n# del engagement_df, product_df, district_df\n\n# gc.collect()","9cfd8cef":"# import pandas as pd\n# import scipy.stats as stats\n\n# tstats = {}\n# ix_a = df['group'] == 'A'\n# for x in df:\n#     if x != 'group':\n#         tstats['t_' + x] = stats.ttest_ind(df[x][ix_a], df[x][~ix_a])[0]\n\n# df.groupby('group').mean().assign(**tstats)","e58160d0":"# alpha = 0.05 #Or whatever you want your alpha to be.\n# p_value = scipy.stats.f.cdf(F, df1, df2)\n# if p_value > alpha:\n#     # Reject the null hypothesis that Var(X) == Var(Y)","763bd29b":"# full_table_sample1.reset_index(drop=True, inplace=True)\n# state_sample1.reset_index(drop=True, inplace=True)\n# full_table = pd.concat([full_table_sample1.reset_index(drop=True), state_sample1], axis=1)\n# del full_table_sample1, full_table_sample2, state_sample1, state_sample2 \n# gc.collect()\n# full_table.head()","f1631a7e":"covid_19_state_policy = pd.read_excel(\"..\/input\/covid19-us-state-policy-database-3-29-2021\/COVID-19 US state policy database 3_29_2021.xlsx\")\ncovid_19_state_policy.dropna(subset = [\"STATE\"], inplace=True)\ncovid_19_state_policy.fillna(0,inplace=True)\ncovid_19_state_policy[0:5]","2af857e9":"covid_19_state_policy = covid_19_state_policy[['STATE','POSTCODE','STEMERG','STEMERGEND','CLDAYCR',\n                                              'OPNCLDCR','CLSCHOOL','CLBSNS','END_BSNS',\n                                              'CLGYM','ENDGYM','CLGYM2','END_CLGYM2',\n                                              'EMSTART','EMEND','EMSTART2','EMEND2','EMSTART3',\n                                              'EMEND3','SNAPALLO','SNAPEBT20','SNAPEBT21',\n                                              'RELIGEX','FMFINE','FMCITE','FMNOENF','ALCOPEN',\n                                              'GUNOPEN','SMALLBUSMINWAGE','MINWAGE2021',\n                                              'TIPMINWAGE2020','VBMEXC','MH19','POV18',\n                                              'UNEMP18','HMLS19','POP18','POPDEN18']][4:]\ncovid_19_state_policy = reduce_mem_usage(covid_19_state_policy)\ncovid_19_state_policy.head()","7b921be9":"\nfull_table_state = pd.merge(full_table,covid_19_state_policy, \"left\", left_on='state',right_on='STATE')\nfull_table_state['time'] = pd.to_datetime(full_table_state['time'], format='%Y-%m-%d', errors ='coerce').astype('datetime64[ns]')\nfull_table_state['week_year'] = full_table_state['time'].apply(lambda row: dt.datetime.strftime(row,format='%Y-%W'))\nfull_table_state['weekday'] = full_table_state['time'].apply(lambda row: dt.datetime.strftime(row,format='%Y-%w'))\n#emergency state\nfull_table_state['STEMERG'] = pd.to_datetime(full_table_state['STEMERG'], format='%Y-%m-%d')\nfull_table_state['STEMERGEND'] = np.where(full_table_state['STEMERGEND']!=0,\\\n                                          pd.to_datetime(full_table_state['STEMERGEND'], format='%Y-%m-%d').astype('datetime64[ns]'),\\\n                                          pd.to_datetime('today').date())\n#day care closed\nfull_table_state['CLDAYCR'] = np.where(full_table_state['CLDAYCR']!=0,\\\n                                       full_table_state['CLDAYCR'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['OPNCLDCR'] = np.where(full_table_state['OPNCLDCR']!=0,\\\n                                          full_table_state['OPNCLDCR'],\\\n                                          pd.to_datetime('today').date())\n\n# k-12 public school closed\nfull_table_state['CLSCHOOL'] = np.where(full_table_state['CLSCHOOL']!=0,\\\n                                          full_table_state['CLSCHOOL'],\\\n                                          pd.to_datetime('today').date())\n\n#non essential business closed \nfull_table_state['CLBSNS'] = np.where(full_table_state['CLBSNS']!=0,\\\n                                       full_table_state['CLBSNS'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['END_BSNS'] = np.where(full_table_state['END_BSNS']!=0,\\\n                                          full_table_state['END_BSNS'],\\\n                                          pd.to_datetime('today').date())\n\n#gym closed \nfull_table_state['CLGYM'] = np.where(full_table_state['CLGYM']!=0,\\\n                                       full_table_state['CLGYM'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['ENDGYM'] = np.where(full_table_state['ENDGYM']!=0,\\\n                                          full_table_state['ENDGYM'],\\\n                                          pd.to_datetime('today').date())\nfull_table_state['CLGYM2'] = np.where(full_table_state['CLGYM2']!=0,\\\n                                       full_table_state['CLGYM2'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['END_CLGYM2'] = np.where(full_table_state['END_CLGYM2']!=0,\\\n                                          full_table_state['END_CLGYM2'],\\\n                                          pd.to_datetime('today').date())\n\n#Overall eviction moratorium start\nfull_table_state['EMSTART'] = np.where(full_table_state['EMSTART']!=0,\\\n                                       full_table_state['EMSTART'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['EMEND'] = np.where(full_table_state['EMEND']!=0,\\\n                                          full_table_state['EMEND'],\\\n                                          pd.to_datetime('today').date())\nfull_table_state['EMSTART2'] = np.where(full_table_state['EMSTART2']!=0,\\\n                                       full_table_state['EMSTART2'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['EMEND2'] = np.where(full_table_state['EMEND2']!=0,\\\n                                          full_table_state['EMEND2'],\\\n                                          pd.to_datetime('today').date())\nfull_table_state['EMSTART3'] = np.where(full_table_state['EMSTART3']!=0,\\\n                                       full_table_state['EMSTART3'],\\\n                                       pd.to_datetime('today').date())\nfull_table_state['EMEND3'] = np.where(full_table_state['EMEND3']!=0,\\\n                                          full_table_state['EMEND3'],\\\n                                          pd.to_datetime('today').date())\n\n\n# SNAP waiver\nfull_table_state['SNAPALLO'] = pd.to_datetime(full_table_state['SNAPALLO'], format='%Y-%m-%d')\nfull_table_state['SNAPEBT20'] =  pd.to_datetime(full_table_state['SNAPEBT20'], format='%Y-%m-%d')\nfull_table_state['SNAPEBT21'] = np.where(full_table_state['SNAPEBT21']!=0,\\\n                                          full_table_state['SNAPEBT21'],\\\n                                          pd.to_datetime('today').date())\n\n\nfull_table_state['in_emergstate_period'] = np.where((full_table_state['time']>=full_table_state['STEMERG']) & (full_table_state['time']<=full_table_state['STEMERGEND']), 1,0)\nfull_table_state['in_closed_daycare_period'] = np.where((full_table_state['time']>=full_table_state['CLDAYCR']) & (full_table_state['time']<=full_table_state['OPNCLDCR']), 1,0)\nfull_table_state['in_closed_gym_period'] = np.where(((full_table_state['time']>=full_table_state['CLGYM']) & (full_table_state['time']<=full_table_state['ENDGYM'])) |\n                                                    ((full_table_state['time']>=full_table_state['CLGYM2']) & (full_table_state['time']<=full_table_state['END_CLGYM2'])), 1,0)\nfull_table_state['in_eviction_moratorium_period'] = np.where(((full_table_state['time']>=full_table_state['EMSTART']) & (full_table_state['time']<=full_table_state['EMEND'])) |\n                                                    ((full_table_state['time']>=full_table_state['EMSTART2']) & (full_table_state['time']<=full_table_state['EMEND2'])) |\n                                                    ((full_table_state['time']>=full_table_state['EMSTART3']) & (full_table_state['time']<=full_table_state['EMEND3'])) , 1,0)\nfull_table_state['in_closed_school_period'] = np.where((full_table_state['time']>=full_table_state['CLSCHOOL']), 1,0)\nfull_table_state['in_snap_emergency_allotments_period'] = np.where((full_table_state['time']>=full_table_state['SNAPALLO']), 1,0)\nfull_table_state['in_snap_ebt_school_period2020'] = np.where((full_table_state['time']>=full_table_state['SNAPEBT20']) & (full_table_state['time'] <= pd.to_datetime('2020-12-31')), 1,0)\nfull_table_state['in_snap_ebt_school_period2021'] = np.where((full_table_state['time']>=full_table_state['SNAPEBT21']), 1,0)\n\n# flagged columns\nfull_table_state.rename({'Provider\/Company Name':'company_name',\n                         'Product Name':'product_name',\n                         'POSTCODE':'state_short',\n                         'time':'date',\n                         'locale':'locale_type',\n                         'pct_black\/hispanic':'pct_black_hispanic',\n                         'Sector(s)':'sector_description',\n                         'sector_PreK-12':'sector_PreK',\n                         'RELIGEX': 'excep_relig_meet', \n                         'FMFINE': 'face_mask_enforced_by_fine',\n                         'FMCITE':'face_mask_enforced_by_criminal_charge',\n                         'FMNOENF':'face_mask_no_legal_enforcement',\n                         'ALCOPEN':'alchool_stores_open',\n                         'GUNOPEN':'guns_stores_open',\n                         'SMALLBUSMINWAGE':'small_business_min_wage',\n                         'MINWAGE2021':'min_wage_2021',\n                         'TIPMINWAGE2020':'tip_min_wage_2020',\n                         'VBMEXC':'covid_isnt_reason_to_request_vote_by_mail',\n                         'MH19':'mental_health_prof_per_100kpop_2019',\n                         'POV18':'perc_people_under_poverty_line_2018',\n                         'UNEMP18':'perc_unenployed_2018',\n                         'HMLS19':'number_homeless_2019',\n                         'POP18':'population_2018',\n                         'POPDEN18':'pop_density_2018'}, axis=1, inplace = True)\nfull_table_state = full_table_state[['state','state_short','company_name','product_name','locale_type',\n                                     'date','week_year','weekday','sector_description','pct_black_hispanic',\n                                     'sector_Corporate','sector_HigherEd','sector_PreK',\n                                     'primary_function_main','primary_function_sub',\n                                     'engagement_index','pct_access', 'in_emergstate_period',\n                                     'in_closed_daycare_period','in_closed_school_period',\n                                     'in_closed_gym_period','in_eviction_moratorium_period',\n                                     'in_snap_emergency_allotments_period','in_snap_ebt_school_period2020',\n                                     'in_snap_ebt_school_period2021',\n                                     'excep_relig_meet','face_mask_enforced_by_fine',\n                                     'face_mask_enforced_by_criminal_charge',\n                                     'face_mask_no_legal_enforcement',\n                                     'alchool_stores_open','guns_stores_open',\n                                     'small_business_min_wage','min_wage_2021',\n                                     'tip_min_wage_2020', 'covid_isnt_reason_to_request_vote_by_mail',\n                                     'mental_health_prof_per_100kpop_2019',\n                                     'perc_people_under_poverty_line_2018',\n                                     'perc_unenployed_2018','number_homeless_2019',\n                                     'population_2018','pop_density_2018']].copy()\n\nfull_table_state[['excep_relig_meet','face_mask_enforced_by_fine',\n                  'face_mask_enforced_by_criminal_charge','face_mask_no_legal_enforcement',\n                  'alchool_stores_open','guns_stores_open',\n                  'covid_isnt_reason_to_request_vote_by_mail',\n                  'population_2018']] = full_table_state[['excep_relig_meet','face_mask_enforced_by_fine',\n                          'face_mask_enforced_by_criminal_charge','face_mask_no_legal_enforcement',\n                          'alchool_stores_open','guns_stores_open','covid_isnt_reason_to_request_vote_by_mail','population_2018']].astype('int64', errors='ignore')\n\nfull_table_state[['small_business_min_wage','min_wage_2021','tip_min_wage_2020',\n                  'mental_health_prof_per_100kpop_2019','perc_people_under_poverty_line_2018',\n                  'perc_unenployed_2018','number_homeless_2019','pop_density_2018']] = full_table_state[['small_business_min_wage','min_wage_2021','tip_min_wage_2020',\n                          'mental_health_prof_per_100kpop_2019','perc_people_under_poverty_line_2018',\n                          'perc_unenployed_2018','number_homeless_2019','pop_density_2018']].astype('float32', errors='ignore')\n","d308993b":"\ngc.collect()\n\n\ncodes = ['DP05_0003PE', 'DP05_0004PE', 'DP05_0005PE', 'DP05_0006PE', 'DP05_0007PE',\n         'DP04_0002PE', 'DP04_0003PE', 'DP04_0028PE', 'DP04_0039PE', 'DP04_0040PE', \n         'DP04_0058PE', 'DP04_0075PE', 'DP04_0081PE','DP04_0091PE', 'DP04_0127E',\n         'DP03_0002PE', 'DP03_0006PE', 'DP03_0011PE','DP03_0011PE', 'DP03_0015PE', \n         'DP03_0017PE', 'DP03_0019PE', 'DP03_0020PE', 'DP03_0021PE',  'DP03_0022PE', \n         'DP03_0024PE', 'DP03_0025PE', 'DP02_0015E', 'DP02_0016E', 'DP02_0034PE',\n         'DP02_0035PE', 'DP02_0044PE','DP02_0050PE', 'DP02_0051PE', 'DP02_0053PE', \n         'DP02_0054PE', 'DP02_0055PE', 'DP02_0056PE', 'DP02_0057PE', 'DP02_0059PE', \n         'DP02_0060PE', 'DP02_0061PE', 'DP02_0066PE', 'DP02_0073PE', 'DP02_0075PE', \n         'DP02_0077PE', 'DP02_0092PE', 'DP02_0117PE', 'DP02_0119PE', 'DP02_0121PE', \n         'DP02_0150PE', 'DP02_0151PE', 'DP02_0152PE']\n\ncols_names = {\n    \"DP05_0003PE\":  \"Total population Female\",\n    \"DP05_0004PE\":  \"Under 5 years\",\n    \"DP05_0005PE\":  \"5 to 9 years\",\n    \"DP05_0006PE\":  \"10 to 14 years\",\n    \"DP05_0007PE\":  \"15 to 19 years\",\n    \"DP04_0002PE\":  \"Total housing units Occupied housing units\",\n    \"DP04_0003PE\":  \"Total housing units Vacant housing units\",\n    \"DP04_0028PE\":  \"Total housing units 1 room\",\n    \"DP04_0039PE\":  \"Total housing units No bedroom\",\n    \"DP04_0040PE\":  \"Total housing units 1 bedroom\",\n    \"DP04_0058PE\":  \"Occupied housing units No vehicles available\",\n    \"DP04_0075PE\":  \"Occupied housing units No telephone service available\",\n    \"DP04_0081PE\":  \"Owner-occupied units Less than $50,000\",\n    \"DP04_0091PE\":  \"Owner-occupied units Housing units with a mortgage\",\n    \"DP04_0127E\":   \"Occupied units paying rent Less than $500\",\n    \"DP03_0002PE\":  \"Population 16 years and over In labor force\",\n    \"DP03_0006PE\":  \"Population 16 years and over In labor force Armed Forces\",\n    \"DP03_0011PE\":  \"Females 16 years and over In labor force\",\n    \"DP03_0015PE\":  \"Children under 6 years with all parents in family in labor force\",\n    \"DP03_0017PE\":  \"Children 6 to 17 years with all parents in family in labor force\",\n    \"DP03_0019PE\":  \"Workers drove alone\",\n    \"DP03_0020PE\":  \"Workers carpooled\",\n    \"DP03_0021PE\":  \"Workers using Public transportation\",\n    \"DP03_0022PE\":  \"Workers Walked\",\n    \"DP03_0024PE\":  \"Workers Worked at home\",\n    \"DP03_0025PE\":  \"Mean travel time to work (minutes)\",\n    \"DP02_0015E\":   \"Average household size\",\n    \"DP02_0016E\":   \"Average family size\",\n    \"DP02_0034PE\":  \"Females 15 years and over Widowed\",\n    \"DP02_0035PE\":  \"Females 15 years and over Divorced\",\n    \"DP02_0044PE\":  \"Grandparents responsible for grandchildren\",\n    \"DP02_0050PE\":  \"Grandmother responsible for own grandchildren\",\n    \"DP02_0051PE\":  \"Married grandparents responsible for own grandchildren\",\n    \"DP02_0053PE\":  \"Population enrolled in school Nursery school, preschool\",\n    \"DP02_0054PE\":  \"Population enrolled in school Kindergarten\",\n    \"DP02_0055PE\":  \"Population enrolled in school Elementary school (grades 1-8)\",\n    \"DP02_0056PE\":  \"Population enrolled in school High school (grades 9-12)\",\n    \"DP02_0057PE\":  \"Population enrolled in school College or graduate school\",\n    \"DP02_0059PE\":  \"Adults Less than 9th grade\",\n    \"DP02_0060PE\":  \"Adults 9th to 12th grade, no diploma\",\n    \"DP02_0061PE\":  \"Adults High school graduate (includes equivalency)\",\n    \"DP02_0066PE\":  \"Adults high school graduate or higher\",\n    \"DP02_0073PE\":  \"Under 18 years With a disability\",\n    \"DP02_0075PE\":  \"18 to 64 years With a disability\",\n    \"DP02_0077PE\":  \"65 years and over With a disability\",\n    \"DP02_0092PE\":  \"Total population Foreign born\",\n    \"DP02_0117PE\":  \"Indo-European who don't speak english well\",\n    \"DP02_0119PE\":  \"Asian and Pacific Islander who don't speak english well\",\n    \"DP02_0121PE\":  \"Other languages who don't speak english well\",\n    \"DP02_0150PE\":  \"Total households\",\n    \"DP02_0151PE\":  \"Total households With a computer\",\n    \"DP02_0152PE\":  \"Total households With a broadband Internet subscription\",\n}\n\ncensus_data = censusdata.download('acs5', 2015, censusdata.censusgeo([('county', '*')]),\n                                   codes,\n                                   tabletype='profile')\ndef get_state(geo):\n  return geo.name.split(', ')[1]\ncensus_data = census_data.rename(index=get_state)  \ncensus_data.index.name='state'\ncensus_data=census_data.reset_index()\n\ncensus_data = census_data.groupby('state').mean().reset_index()\ncensus_data = census_data.rename(columns=cols_names)\n\ndel codes, cols_names","9dc45913":"gc.collect()\n\ncensus_data = census_data.drop(columns=['Mean travel time to work (minutes)', 'Total households', 'Total households With a computer', 'Total households With a broadband Internet subscription'])\ncensus_data.columns = map(str.lower, census_data.columns)\ncensus_data.columns = census_data.columns.str.replace(' ','_')\n\ncensus_data.head()","c12b626f":"del covid_19_state_policy\ngc.collect()\n\ncensus_data.shape","8f1b2a2f":"full_table_state = pd.merge(full_table_state, census_data, on='state')\n\ndel census_data\ngc.collect()\n\n# def cut_engagement(x):\n#     if x < 150:\n#         return 'low'\n#     elif x < 311:\n#         return 'medium'\n#     else:\n#         return 'high'\n# def cut_access(x):\n#     if x < 0.517:\n#         return 'low'\n#     elif x < 0.694:\n#         return 'medium'\n#     else:\n#         return 'high'\n    \n# full_table_state['engagement_categoy'] = full_table_state.engagement_index.apply(cut_engagement)\n# full_table_state['access'] = full_table_state.pct_access.apply(cut_access)\nfull_table_state.head()","b31768b9":"# link = 'https:\/\/data.cms.gov\/provider-data\/sites\/default\/files\/resources\/f0ac50d7d0a50b3b4bd21668bcc3b24a_1632852401\/HH_State_July2021.csv'\n# \n# health_care_data = pd.read_csv(link)\n# health_care_data.columns = map(str.lower, health_care_data.columns)\n# health_care_data.columns = health_care_data.columns.str.replace(' ','_')\n\n# health_care_data.rename({'state':'state_short'}, axis=1, inplace = True)\n\n# link = 'https:\/\/data.cms.gov\/provider-data\/sites\/default\/files\/resources\/8afcba3acd6f5791e7dc16df93fc7653_1631721917\/NH_StateUSAverages_Sep2021.csv'\n\n# health_care_data2 = pd.read_csv(link)\n# health_care_data2.columns = map(str.lower, health_care_data2.columns)\n# health_care_data2.columns = health_care_data2.columns.str.replace(' ','_')\n\n# health_care_data2.rename({'state_or_nation':'state_short'}, axis=1, inplace = True)\n# health_care_data2 = health_care_data2.drop('processing_date',axis=1)\n\n# health_care_data = pd.merge(health_care_data, health_care_data2, on='state_short')\n\n# health_care_data.head()","754472b1":"# full_table_state = pd.merge(full_table_state, health_care_data, on='state_short')\n\n# del health_care_data\n# gc.collect()\n\n# full_table_state.head()","00c6c32b":"# temp_sectors = pd.get_dummies(full_table_state[['locale_type', 'primary_function_main']]\n#                                , prefix=['locale_type', 'primary_function_main'])\n# full_table_state = full_table_state.join(temp_sectors)\n\n# del temp_sectors\n# gc.collect()\n# full_table_state.to_csv('full_table_state.csv')","fc611a24":"full_table_state.shape","10852d7d":"full_table_state.head()","6ff6e637":"gc.collect()\n\ncorr = full_table_state.corr()\n# corr = pd.DataFrame(corr['engagement_index'].sort_values(ascending=False).sort_values(ascending=False)\n\ndf1 = pd.DataFrame(corr['engagement_index']).reset_index().sort_values(by='engagement_index',ascending=False)[2:]\n\ndf1 =  df1.head(10)\n\ndf2 =  pd.DataFrame(corr['engagement_index']).reset_index().sort_values(by='engagement_index',ascending=False)[2:]\n                    \ndf2 = df2.tail(10)\n\nfig, ax = plt.subplots(1,2,figsize=(20,8))\nfig.suptitle('Top positive and negative correlations with engagement number',fontweight='bold',fontsize=20)\n\np1 = sns.barplot(x='engagement_index',y='index', data=df1,color = '#57799C', ax=ax[0])\n                    \nax[0].set_title('Top 10 Positive Correlations',fontsize=12)\nax[0].set_xlabel('Corr')\nax[0].set_ylabel('Feature')\n\n\nfor x in p1.patches:\n    width = x.get_width() \/5  # get bar length\n    p1.text(width + 0.01,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.3f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\n# ax[0].add_patch(Rectangle((0.01, -0.49), 69.5, 1,fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\np2 = sns.barplot(x='engagement_index',y='index', data=df2,color = '#57799C', ax=ax[1])\nax[1].set_title('Top 10 Negative Correlations',fontsize=12)\nax[1].set_xlabel('Corr')\nax[1].set_ylabel('Feature')\n\nfor x in p2.patches:\n    width = x.get_width() \/5   # get bar length\n    p2.text(width - 0.01,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.3f}'.format(width), # set variable to display, 2 decimals\n            ha = 'right',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\n\nplt.tight_layout()\nplt.show()","45b224d4":"gc.collect()\n\n\nstate_code = pd.read_excel(\"..\/input\/covid19-us-state-policy-database-3-29-2021\/COVID-19 US state policy database 3_29_2021.xlsx\")\nstate_code.dropna(subset = [\"STATE\"], inplace=True)\nstate_code.fillna(0,inplace=True)\nstate_code[0:5]\nstate_code = state_code[['STATE','POSTCODE']]\n\n\nplot_df = full_table_state[['state','engagement_index']].\\\n    groupby(by=['state']).sum().reset_index()\n\nplot_df = pd.merge(plot_df,state_code, 'left',left_on='state',right_on='STATE')\n\nfig = go.Figure(data=go.Choropleth(\n    locations=plot_df['POSTCODE'], # Spatial coordinates\n    z = plot_df['engagement_index'].astype(float), # Data to be color-coded\n    locationmode = 'USA-states', # set of locations match entries in `locations`\n    colorscale = 'Reds',\n    text=plot_df['state'], # hover text\n    colorbar_title = \"Engagement\"\n))\n\nfig.update_layout(\n    title_text = 'Total Engagement by State',\n    geo_scope='usa', # limite map scope to USA\n)\n\nfig.show()  # Output the plot to the screen","69577247":"gc.collect()\n\ndf1 = full_table_state[['state','engagement_index']].\\\n    groupby(by=['state']).sum().reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\ndf1['engagement_percent'] = df1.engagement_index.apply(lambda x: 100 * x \/ df1['engagement_index'].sum())\ndf1 =  df1.head(10)\n\ndf2 = full_table_state[['locale_type','engagement_index']].\\\n    groupby(by=['locale_type']).sum().reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\ndf2['engagement_percent'] = df2.engagement_index.apply(lambda x: 100 * x \/ df2['engagement_index'].sum())\ndf2.reset_index(inplace=True,drop=True)\n\nfig, ax = plt.subplots(1,2,figsize=(20,8))\nfig.suptitle('Engagement Rate per Location',fontweight='bold',fontsize=20)\n\np1 = sns.barplot(x='engagement_percent',y='state', data=df1,color = '#57799C', ax=ax[0])\nax[0].set_title('Engagement Rate per State',fontsize=12)\nax[0].set_xlabel('Engagement Rate (%)')\nax[0].set_ylabel('State')\nfor x in p1.patches:\n    width = x.get_width()    # get bar length\n    p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\n# ax[0].add_patch(Rectangle((0.01, -0.49), 69.5, 1,fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\np2 = sns.barplot(x='engagement_percent',y='locale_type', data=df2,color = '#57799C', ax=ax[1],order=df2['locale_type'])\nax[1].set_title('Engagement Rate per Location Type',fontsize=12)\nax[1].set_xlabel('Engagement Rate (%)')\nax[1].set_ylabel('Location Type')\nfor x in p2.patches:\n    width = x.get_width()    # get bar length\n    p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\n# ax[1].add_patch(Rectangle((0.01, -0.49), 35.5, 2, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n# ax[1].add_patch(Rectangle((0.01, 2.5), 35.5, 1, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n# ax[1].add_patch(Rectangle((0.01, 4.5), 35.5, 4, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\nplt.tight_layout()\nplt.show()","9d0226cd":"gc.collect()\n\ndf1 = full_table_state[['company_name','engagement_index']].\\\n    groupby(by=['company_name']).sum().reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\ndf1['engagement_percent'] = df1.engagement_index.apply(lambda x: 100 * x \/ df1['engagement_index'].sum())\ndf1 =  df1.head(10)\n\ndf2 = full_table_state[['product_name','engagement_index']].\\\n    groupby(by=['product_name']).sum().reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\ndf2['engagement_percent'] = df2.engagement_index.apply(lambda x: 100 * x \/ df2['engagement_index'].sum())\ndf2 = df2.head(10)\n\nfig, ax = plt.subplots(1,2,figsize=(20,8))\nfig.suptitle('Top companies and products in total engagement rate',fontweight='bold',fontsize=20)\n\np1 = sns.barplot(x='engagement_percent',y='company_name', data=df1,color = '#57799C', ax=ax[0])\nax[0].set_title('Top 10 Provider\/Company Engagement',fontsize=12)\nax[0].set_xlabel('Engagement Rate (%)')\nax[0].set_ylabel('Company Name')\nfor x in p1.patches:\n    width = x.get_width()    # get bar length\n    p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\nax[0].add_patch(Rectangle((0.01, -0.49), 69.5, 1,fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\np2 = sns.barplot(x='engagement_percent',y='product_name', data=df2,color = '#57799C', ax=ax[1])\nax[1].set_title('Top 10 Product Engagement',fontsize=12)\nax[1].set_xlabel('Engagement Rate (%)')\nax[1].set_ylabel('Product Name')\nfor x in p2.patches:\n    width = x.get_width()    # get bar length\n    p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\nax[1].add_patch(Rectangle((0.01, -0.49), 35.5, 2, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\nax[1].add_patch(Rectangle((0.01, 2.5), 35.5, 1, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\nax[1].add_patch(Rectangle((0.01, 4.5), 35.5, 4, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\nplt.tight_layout()\nplt.show()","18b2d1b6":"gc.collect()\n\n\ndf1 = full_table_state.groupby('company_name').product_name.nunique().reset_index().\\\n    sort_values(['product_name'],ascending=False).head(10)\n\ncompanies_more_engag = full_table_state[['company_name','engagement_index']].\\\n    groupby(by=['company_name']).sum().reset_index().\\\n    sort_values(['engagement_index'],ascending=False).head(10)\n\ndf2 = full_table_state.groupby('company_name').product_name.nunique().reset_index()\n# df2 = df2[df2['company_name'].isin(companies_more_engag['company_name'])]\ndf2 = pd.merge(df2,companies_more_engag, 'inner',on='company_name').reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\n\nfig, ax = plt.subplots(1,2,figsize=(20,8))\nfig.suptitle('Analysis of the number of products from the top 10 companies',fontweight='bold',fontsize=20)\n\np1 = sns.barplot(x='product_name',y='company_name', data=df1,color = '#57799C', ax=ax[0])\nax[0].set_title('Top 10 companies with the most mapped products',fontsize=12)\nax[0].set_xlabel('Number of products')\nax[0].set_ylabel('')\nfor x in p1.patches:\n    width = x.get_width()    # get bar length\n    p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\nax[0].add_patch(Rectangle((0.01, -0.49), 69.5, 1,fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\np2 = sns.barplot(x='product_name',y='company_name', data=df2,color = '#57799C', ax=ax[1])\nax[1].set_title('Number of products Top 10 companies in total engagement',fontsize=12)\nax[1].set_xlabel('Number of products')\nax[1].set_ylabel('')\n\nfor x in p2.patches:\n    width = x.get_width()    # get bar length\n    p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\n# ax[1].add_patch(Rectangle((0.01, -0.49), 35.5, 2, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\nax[1].add_patch(Rectangle((0.01, 1.5), 35.5, 1, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\nax[1].add_patch(Rectangle((0.01, 3.5), 35.5, 3, fc='#F5A294', ec='#F54434', linewidth=2.0, alpha=0.2,ls=\"--\"))\n\nplt.tight_layout()\nplt.show()","98c792be":"gc.collect()\n\ndf1 = full_table_state[['primary_function_main','engagement_index']].\\\n    groupby(by=['primary_function_main']).sum().reset_index()\ndf1['engagement_percent'] = df1.engagement_index.apply(lambda x: 100 * x \/ df1['engagement_index'].sum())\ndf1 =  df1.sort_values(['engagement_percent'],ascending=False).reset_index(drop=True).head(10)\n\ndf2 = full_table_state[['primary_function_sub','engagement_index']].\\\n    groupby(by=['primary_function_sub']).sum().reset_index()\ndf2['engagement_percent'] = df2.engagement_index.apply(lambda x: 100 * x \/ df2['engagement_index'].sum())\ndf2 = df2.sort_values(['engagement_percent'],ascending=False).reset_index(drop=True).head(10)\n\nfig, ax = plt.subplots(1,2,figsize=(20,8))\nfig.suptitle('Top category and sub-category in total engagement rate',fontweight='bold',fontsize=20)\n\np1 = sns.barplot(x='engagement_percent',y='primary_function_main', data=df1,color = '#57799C', order=df1['primary_function_main'], ax=ax[0])\nax[0].set_title('Top Main Function Engagement',fontsize=12)\nax[0].set_xlabel('Engagement Rate (%)')\nax[0].set_ylabel(None)\nfor x in p1.patches:\n    width = x.get_width()    # get bar length\n    p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\np2 = sns.barplot(x='engagement_percent',y='primary_function_sub', data=df2, color = '#57799C', order=df2['primary_function_sub'], ax=ax[1])\nax[1].set_title('Top 10 Sub-Category Function Engagement',fontsize=12)\nax[1].set_xlabel('Engagement Rate (%)')\nax[1].set_ylabel(None)\nfor x in p2.patches:\n    width = x.get_width()    # get bar length\n    p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n            x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center'\n            , color='black'\n            , fontsize=14)  # vertical alignment\n\nplt.tight_layout()\nplt.show()","3622caef":"# gc.collect()\n\n# df1 = full_table_state[['primary_function_main','date','in_emergstate_period','engagement_index']].\\\n#     groupby(by=['primary_function_main','in_emergstate_period','date']).sum().reset_index()\n\n# df1 = df1[['primary_function_main','in_emergstate_period','engagement_index']].\\\n#     groupby(by=['primary_function_main','in_emergstate_period']).mean().reset_index().\\\n#     sort_values(['engagement_index'],ascending=False).head(10)\n\n# df1 = df1.pivot(index='primary_function_main', columns = 'in_emergstate_period', values = 'engagement_index')\n# df1['avg_daily_engag_growth']=(df1[1]-df1[0])\/(df1[0])*100\n# df1 = df1.sort_values(['avg_daily_engag_growth'],ascending=False)\n# df1.reset_index(inplace=True)\n\n# df2 = full_table_state[['primary_function_sub','date','in_emergstate_period','engagement_index']].\\\n#     groupby(by=['primary_function_sub','in_emergstate_period','date']).sum().reset_index()\n\n# df2 = df2[['primary_function_sub','in_emergstate_period','engagement_index']].\\\n#     groupby(by=['primary_function_sub','in_emergstate_period']).mean().reset_index().\\\n#     sort_values(['engagement_index'],ascending=False).head(10)\n\n# df2 = df2.pivot(index='primary_function_sub', columns = 'in_emergstate_period', values = 'engagement_index')\n# df2['avg_daily_engag_growth']=(df2[1]-df2[0])\/(df2[0])*100\n# df2 = df2.sort_values(['avg_daily_engag_growth'],ascending=False)\n# df2.reset_index(inplace=True)\n\n# fig, ax = plt.subplots(1,2,figsize=(20,8))\n# fig.suptitle('Top states and locale type in total engagement rate',fontweight='bold',fontsize=20)\n\n\n# p1 = sns.barplot(x='avg_daily_engag_growth',y='primary_function_main', data=df1, order=df1['primary_function_main'], \n#                  ax=ax[0], color = '#57799C')\n# ax[0].set_title('Top Main Function Engagement',fontsize=12)\n# ax[0].set_xlabel('Engagement Rate (%)')\n# ax[0].set_ylabel(None)\n# for x in p1.patches:\n#     width = x.get_width()    # get bar length\n#     p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n#             x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n#             '{:1.0f}'.format(width), # set variable to display, 2 decimals\n#             ha = 'left',   # horizontal alignment\n#             va = 'center'\n#             , color='black'\n#             , fontsize=14)  # vertical alignment\n\n# p2 = sns.barplot(x='avg_daily_engag_growth',y='primary_function_sub', data=df2, order=df2['primary_function_sub'], \n#                  ax=ax[1], color = '#57799C')\n# ax[1].set_title('Top 10 Sub-Category Function Engagement',fontsize=12)\n# ax[1].set_xlabel('Engagement Rate (%)')\n# ax[1].set_ylabel(None)\n# for x in p2.patches:\n#     width = x.get_width()    # get bar length\n#     p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n#             x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n#             '{:1.0f}'.format(width), # set variable to display, 2 decimals\n#             ha = 'left',   # horizontal alignment\n#             va = 'center'\n#             , color='black'\n#             , fontsize=14)  # vertical alignment\n\n# plt.tight_layout()\n# plt.show()","9dbce570":"# datetime \nfull_table[\"time\"] = pd.to_datetime(full_table.time)\nfull_table[\"week\"] = full_table.time.dt.dayofweek \nfull_table[\"holiday\"] = full_table.week.apply(lambda x: 1 if x in [5, 6] else 0)\nd = pd.date_range(start=\"2020-01-01\", end=\"2020-01-19\")\nfull_table[\"is_pandemic\"] = full_table.time.apply(lambda x: 0 if x in d else 1)\nfull_table.drop(\"week\", axis=1, inplace=True)","fef6e0ad":"gc.collect()\n\nplt.figure(figsize=(10, 8))\n\nplot_df = full_table_state[['in_emergstate_period','date','engagement_index']].\\\n    groupby(by=['in_emergstate_period','date']).sum().reset_index()\nplot_df = plot_df[['in_emergstate_period','engagement_index']].\\\n    groupby(by=['in_emergstate_period']).mean().reset_index().\\\n    sort_values(['engagement_index'],ascending=False)\n# plot_df['engagement_percent'] = plot_df.engagement_index.apply(lambda x: 100 * x \/ plot_df['engagement_index'].sum())\nplot_df =  plot_df.head(10)\n\nsns.barplot(x='in_emergstate_period',y='engagement_index', data=plot_df,color = '#57799C')\nplt.title(\"Avg Daily Engagement in emergency state\",font=\"Serif\", size=20)\nplt.xlabel('Day in Emergency Period (1 if Yes, 0 if Not)')\nplt.ylabel('Average Daily Engagement')\nplt.show()","3b043bb1":"gc.collect()\n\nplt.figure(figsize=(20, 8))\n\nplot_df = full_table_state[['week_year','locale_type','date','in_emergstate_period','engagement_index']].\\\n    groupby(by=['week_year','locale_type','date']).sum().reset_index()\n\nplot_df = plot_df[['week_year','locale_type','engagement_index']].\\\n    groupby(by=['week_year','locale_type']).mean().reset_index().\\\n    sort_values(['week_year'],ascending=True)\n\n\nsns.lineplot(x='week_year',y='engagement_index', data=plot_df,hue='locale_type')\nplt.title(\"Avg Daily Engagement per Week (2020)\",size=20)\nplt.xticks(rotation=45)\nplt.show()","67ffbebb":"# gc.collect()\n\n# df1 = full_table_state.groupby('pct_black_hispanic')['engagement_index'].sum()\n\n# df1 = pd.DataFrame(df1).reset_index().sort_values(by='engagement_index',ascending=False)[2:]\n\n# df1 =  df1.head(10)\n\n# df2 = full_table_state.groupby('pct_black_hispanic')['pct_access'].sum()\n\n# df2 = pd.DataFrame(df2).reset_index().sort_values(by='pct_access',ascending=False)[2:]\n\n# fig, ax = plt.subplots(1,2,figsize=(20,8))\n# fig.suptitle('Top category and sub-category in total engagement rate',fontweight='bold',fontsize=20)\n\n# p1 = sns.barplot(x='engagement_index',y='pct_black_hispanic', data=df1,color = '#57799C', ax=ax[0])\n# ax[0].set_title('Top Main Function Engagement',fontsize=12)\n# ax[0].set_xlabel('Engagement Rate (%)')\n# ax[0].set_ylabel(None)\n# for x in p1.patches:\n#     width = x.get_width()    # get bar length\n#     p1.text(width + 0.05,       # set the text at 1 unit right of the bar\n#             x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n#             '{:1.0f}'.format(width), # set variable to display, 2 decimals\n#             ha = 'left',   # horizontal alignment\n#             va = 'center'\n#             , color='black'\n#             , fontsize=14)  # vertical alignment\n\n# p2 = sns.barplot(x='pct_access',y='pct_black_hispanic', data=df2, color = '#57799C', ax=ax[1])\n# ax[1].set_title('Top 10 Sub-Category Function Engagement',fontsize=12)\n# ax[1].set_xlabel('Engagement Rate (%)')\n# ax[1].set_ylabel(None)\n# for x in p2.patches:\n#     width = x.get_width()    # get bar length\n#     p2.text(width + 0.05,       # set the text at 1 unit right of the bar\n#             x.get_y() + x.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n#             '{:1.0f}'.format(width), # set variable to display, 2 decimals\n#             ha = 'left',   # horizontal alignment\n#             va = 'center'\n#             , color='black'\n#             , fontsize=14)  # vertical alignment\n\n# plt.tight_layout()\n# plt.show()","915c57b3":"# # define dataset\n# X = full_table_state.drop(columns='engagement_index').copy()\n# y = full_table_state['engagement_index']\n","166e96b5":"# from sklearn.ensemble import RandomForestClassifier\n\n# feature_names = [f'feature {i}' for i in range(X.shape[1])]\n# forest = RandomForestClassifier(random_state=0)\n# forest.fit(X, y)","5ba062a3":"\n# importances = forest.feature_importances_\n# std = np.std([\n#     tree.feature_importances_ for tree in forest.estimators_], axis=0)\n# forest_importances = pd.Series(importances, index=feature_names)","8fdd57d1":"# # define the model\n# model = LinearRegression()\n# # fit the model\n# model.fit(X, y)\n# # get importance\n# importance = model.coef_\n# # summarize feature importance\n# for i,v in enumerate(importance):\n# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n# # plot feature importance","8f39f9eb":"# pyplot.bar([x for x in range(len(importance))], importance)\n# pyplot.show()","e0c982a9":"# plt.figure(figsize=(20, 20))\n\n# abc = sns.heatmap(data=full_table_state.select_dtypes(include=['float','int']).corr(),annot=True)\n\n# abc.add_patch(Rectangle((3, 0), 1, 40, fc='#49EB61', ec='#49EB61', linewidth=2.0, alpha=0.2,ls=\"--\"))\n# abc.add_patch(Rectangle((0, 3), 40, 1, fc='#49EB61', ec='#49EB61', linewidth=2.0, alpha=0.2,ls=\"--\"))","908ce2f4":"# from sklearn.ensemble import RandomForestRegressor\n# from sklearn import preprocessing\n\n# X = full_table_state.drop(['engagement_index','state','state_short','company_name','product_name','locale_type','date','week_year','weekday','sector_description','primary_function_sub','primary_function_main'], axis=1)\n\n# y = full_table_state.engagement_index\n\n# min_max_scaler = preprocessing.MinMaxScaler()\n# X = min_max_scaler.fit_transform(X)\n\n# reg = RandomForestRegressor(random_state=0)\n# reg.fit(X, y)\n# importances =  pd.Series(reg.feature_importances_, index=X.columns, name='Importance')\n# importances = importances.sort_values(ascending=False).to_frame()\n# # importances.to_csv('importances_access.csv')\n# importances","3c88147b":"\n# pyplot.bar([x for x in range(len(importance))], importance)\n# pyplot.show()","30868d3b":"<div style=\"font-family:verdana; bold; word-spacing:1.5px;\">\n    <h1 id=\"methodology\">\n    1 Methodology\n    <\/h1>\n<\/div><br>\n\nIn this session we will explain a little bit about the process of understanding and transforming data.\nIn addition, we will present the external data that we have incorporated into the database to enrich our analyses.","0e85b85c":"In absolute terms, most engagement took place in schools in suburban (63%) and rural (21%) districts.","3831ac90":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"ovw-holydays\">\n    2.4 Demography\n    <\/h1>\n<\/div><br>","ec81f5c2":"Supplemental Nutrition Assistance Program (SNAP) (https:\/\/www.fns.usda.gov\/disaster\/pandemic\/covid-19\/snap-waivers-flexibilities)\n\nPandemic EBT (https:\/\/www.fns.usda.gov\/snap\/state-guidance-coronavirus-pandemic-ebt-pebt)","c2d0b70c":"When we analyze the average daily engagement, within or outside the state-of-emergency period decreed by each state, we can see that the average grows dramatically, going from *3,082,485* to *4,331,711*, an increase of *40.5%*.\n\nThis is a reflection of the closing of schools and other leisure activities that students in normal times would be involved in.","21ba97d3":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"cleaning\">\n    1.1 Understanding and cleaning data\n    <\/h1>\n<\/div>","861c5d39":"As the [challenge documentation](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data) informs you, the `district_info.csv` table contains information about the characteristics of school districts, from which identifiable information about school districts has been removed by LearnPlatform team.\n\nWe have 57 districts without *state* and *locale* informations.\n\nAs these districts do not have information, we removed them from the base.","d6f382ab":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"ovw-holydays\">\n    2.3 Access and engagement between pre- and post-pandemic holidays\n    <\/h1>\n<\/div><br>","86582f04":"Supplemental Nutrition Assistance Program (SNAP) (https:\/\/www.fns.usda.gov\/disaster\/pandemic\/covid-19\/snap-waivers-flexibilities)\n\nPandemic EBT (https:\/\/www.fns.usda.gov\/snap\/state-guidance-coronavirus-pandemic-ebt-pebt)","2de4cd53":"<p float=\"left\">\n\n<img src=\"https:\/\/github.com\/ac-garcia\/kaggle-imgs\/blob\/main\/Screenshot%20from%202021-09-29%2019-52-53.png?raw=true\" \/>\n<img src=\"https:\/\/github.com\/ac-garcia\/kaggle-imgs\/blob\/main\/Screenshot%20from%202021-09-29%2020-24-42.png?raw=true\" \/> \n<\/p>\n<cite>Image from What have we learned?, by UNESCO, UNICEF and The World Bank, pages 21 and 26.<\/cite>","dbe731c3":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"enrichment\">\n    1.2 Data enrichment\n    <\/h1>\n<\/div>","1d9b34dd":"Analyzing the all database, we can see that the company Google has an interaction domain in general, owning 67% of the interactions observed in the year 2020.\n\nWhen we look at the top 10 products, 7 are from Google. The first two, Google Docs and Google Classroom, added together, sum 50% of all tracked engagement.","95c79c54":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"ovw-location\">\n    2.1 Location\n    <\/h1>\n<\/div><br>","5e4095ff":"\nWith that, many were faced with a world of possibilities. Several platforms, different tools, countless providers...\n\nThis scenario, while sad for many families, allowed us the opportunity to collect teaching data in online enviroment that had never been possible before, mostly in high-income countries.\n\nDifferent social classes, different levels of education, different audiences. All passed needed to some extent use online tools to maintain their study schedule.\n\nThus, in this report, our proposal is to analyze how online engagement changes with different audiences and different tools in United States.","818fc401":"The `products_info.csv` table includes information about the features of the top 372 products that were most userd in 2020. The categories contained in the file are part of LearnPlatform's product taxonomy.\n\nSome products came without the sector information, however as in our analysis we didn't explore this point so much, we chose not to remove the lines without this data, keeping a more complete base.","5308c716":"The `engagement_table` is a compilation of student engagement data from schools across numerous US districts across digital platforms.\n\nIn addition to the engagement numbers, we have some relationships, such as the page\/platform where the engagement took place and the user's home district.\n\nTo select the events relevant to us, we filter the engagement base to have information only on the pages and districts contained in the tables mentioned above, after the first treatment done in them.\n\nThus, we had a base reduction of 18,612,528 lines to 7,784,803 lines, a reduction equivalent to 58% of the base.\n\nThis reduction is data that would make it impossible for us to make some classifications, since classification data was missing.","6bf7f388":"<div style=\"font-family:verdana; bold;word-spacing:1.5px;\">\n    <h1 id=\"overview\">\n    2 Overview\n    <\/h1>\n<\/div><br>","8d47be21":"<h1 style=\"font-family:'lucida console';\"> <center>\ud83d\udcda DIGITAL LEARNING IN THE PANDEMIC PERIOD (2020) \ud83d\udda5\ufe0f<\/center> <\/h1>","0912ddfe":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    <h1 id=\"ovw-products\">\n    2.2 Products\n    <\/h1>\n<\/div><br>","1b2934d7":"In 2020, the world was surprised by a lethal virus, taking the entire planet to change the way we were used to doing things and also forcing us to accelerate the digitization process that had been going on since the end of the 20th century.\n\nOne of the areas most affected by this process was education.\nOvernight, teachers needed to reinvent themselves and seek strategies for distance and online learning.\n\nIn a document published by UNESCO, UNICEF and The World Bank, entitled [What have we learned?](http:\/\/uis.unesco.org\/sites\/default\/files\/documents\/national-education-responses-to-covid-19-web-final_en_0.pdf), in which they present a survey of responses from ministries of education around the world, it is possible to notice a disparity between the environment provided by high-income and low\/low-middle income countries.\n\nIn high-income countries, where the United States is located, students missed fewer days of learning in the school year (*on average 27 days in high-income countries versus 70 days in low- and lower-middle-income countries*), kept monitoring their learning. of students by teachers (*while 26% of low- and lower-middle-income countries did not monitor student learning, this was the case in only 3% of high-income countries*).","8e1a851c":"\nTo bring more insights and information into our analysis, we pull data from other data sources.\n\nOne of the sources we looked for, which brought a lot of relevant information for our analysis, is the [US states' database of policies to combat COVID-19](https:\/\/www.openicpsr.org\/openicpsr\/project\/119446\/version\/V75\/view?path=\/openicpsr\/119446\/fcr:versions\/V75\/COVID-19-US-State-Policy-Database-master\/COVID-19-US-state-policy-database-3_29_2021.xlsx&type=file).\n\nWe also get [States averages of several home health agency quality measures for Home Health Agencies](https:\/\/data.cms.gov\/provider-data\/dataset\/tee5-ixt5) and others [States Health Averages data](https:\/\/data.cms.gov\/provider-data\/dataset\/xcdc-v8bm).\n\nIn this database, we have a lot of information about public policies adopted in relation to the pandemic in 2020, and we also have data on some demographic data for each state.\n\nIn addition, we have included Census data, obtained from an [API available on GitHub](https:\/\/jtleider.github.io\/censusdata\/), where there is additional information about each state, such as population age, household characteristics, among others.\n\nAt the end of the selection and transformation of the most relevant data, we arrive at the following table:"}}