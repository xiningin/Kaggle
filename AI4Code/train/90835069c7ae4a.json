{"cell_type":{"3924dc55":"code","a712a6d6":"code","3f49accb":"code","0691eab4":"code","d3afefca":"code","6a8971d3":"code","12d957b6":"code","60449364":"code","bb69843d":"code","bbcc6c37":"code","1e36fb23":"code","b2be8aac":"code","32fd2a36":"code","57de79bb":"code","69f8b4fa":"code","35444457":"code","97507def":"code","0eb3f560":"code","f4a9231f":"code","f07c4f5f":"code","cc228e4a":"code","015aeb22":"code","f0da8448":"code","2c5d7e09":"code","016cec70":"code","e41582a9":"code","52d0abb7":"code","82406980":"code","f93b3a85":"code","cc981d69":"code","b3b8cd7f":"code","4f0ac256":"code","bf0920aa":"code","65917dca":"code","d6f9f815":"code","f0316213":"code","395c58d1":"code","2a15f5a8":"code","97764502":"code","8168a33b":"code","1a23f066":"code","7d8f73a1":"code","0d9036cf":"code","a8f49376":"code","2d84b77e":"code","f051b5be":"code","edc4e785":"code","39516550":"code","caea6c21":"code","52971710":"code","0d12dafc":"code","a8abc6a2":"code","6a139143":"code","b93bf739":"code","0c074f59":"code","ef61cd0f":"code","352d9536":"code","fd7edca9":"code","75613b61":"code","4c2614ef":"code","fd7629b5":"code","34513741":"code","fd1278c1":"code","3f6e25ba":"code","9942d7a8":"code","5e669ecf":"code","22cab1bb":"code","9746d129":"code","d022b33d":"code","c24c0589":"code","ab1976c2":"code","90b5c497":"code","a74b8162":"code","cbf151d6":"code","56c30f08":"code","4e6727df":"code","bcf37e4b":"code","5f5ab014":"code","4fbe1eb7":"code","fb1d4c3d":"code","9be0ad10":"code","3cf37406":"code","61052ef2":"code","b8899631":"code","c502b760":"code","38a4053e":"markdown","e2e79077":"markdown","305e45e6":"markdown","fcf5d57f":"markdown","a324905e":"markdown","592a9970":"markdown","e98ef134":"markdown","adf92836":"markdown","245860d1":"markdown","2591ce14":"markdown","1a7ef7db":"markdown","0a236c0b":"markdown","64afedd5":"markdown","f44f9d57":"markdown","07f87378":"markdown","2a5ca66d":"markdown","bb5cb749":"markdown","7006b92d":"markdown","e12a0970":"markdown","2293a97a":"markdown","d3baed3b":"markdown","cd6a3628":"markdown","4cd58e33":"markdown","794f1560":"markdown","ff399778":"markdown","73ed213e":"markdown","f2039725":"markdown","2fc372a7":"markdown","6748586a":"markdown","e4fb1df6":"markdown","9cc898fd":"markdown","794ad98d":"markdown","53b9b9d7":"markdown","b069d1e6":"markdown","a52d2006":"markdown","11bd829c":"markdown","50ed6d6e":"markdown","50035a5a":"markdown","6d9d4ea6":"markdown","d3168891":"markdown","77dd3210":"markdown","6c26a9d6":"markdown","3998e8fb":"markdown","a143dc35":"markdown","75683e24":"markdown","b3cdec63":"markdown","b78c215a":"markdown","a5aa0c5b":"markdown"},"source":{"3924dc55":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a712a6d6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\nimport pickle\nfrom collections import defaultdict\nfrom mpl_toolkits.mplot3d import Axes3D\nimport gc\n\nsns.set()\ngc.enable()\n%matplotlib inline","3f49accb":"df_train = pd.read_csv(\"..\/input\/prepaired-data-of-customer-revenue-prediction\/train_flat.csv\", converters={'fullVisitorId': str})\ndf_test = pd.read_csv(\"..\/input\/prepaired-data-of-customer-revenue-prediction\/test_flat.csv\", converters={'fullVisitorId': str})","0691eab4":"df_train.head()","d3afefca":"df_train.shape, df_test.shape","6a8971d3":"df_train[\"totals_transactionRevenue\"] = df_train[\"totals_transactionRevenue\"].fillna(0)","12d957b6":"train_col = np.array(df_train.columns)\ntest_col = np.array(df_test.columns)\nprint(set(train_col) - set(test_col))","60449364":"df_train = df_train.drop(columns=[\"trafficSource_campaignCode\"])","bb69843d":"print(np.unique(df_train[\"socialEngagementType\"], return_counts=True))\nprint(np.unique(df_test[\"socialEngagementType\"], return_counts=True))","bbcc6c37":"df_train = df_train.drop(columns=[\"socialEngagementType\"])\ndf_test = df_test.drop(columns=[\"socialEngagementType\"])","1e36fb23":"df_train_eq_nan = df_train.fillna(-1543)","b2be8aac":"for col_name in np.array(df_train_eq_nan.columns):\n    print(col_name)\n    try:\n        un, cnt = np.unique(np.array(df_train_eq_nan[col_name]), return_counts=True)\n        print(un[:10], cnt[:10])\n    except Exception:\n        un, cnt = np.unique(np.array(df_train_eq_nan[col_name]).astype(str), return_counts=True)\n        print(un[:10], cnt[:10])\n    print(\"-\" * 43)","32fd2a36":"numerical = [\"visitNumber\", \"visitStartTime\", \"totals_bounces\", \"totals_hits\", \"totals_newVisits\", \"totals_pageviews\", \n            \"trafficSource_adwordsClickInfo.isVideoAd\", \"trafficSource_adwordsClickInfo.page\", \n            \"trafficSource_isTrueDirect\", \"device_isMobile\"]\n\ncategorial = [\"channelGrouping\", \"date\", \"device_browser\", \"device_deviceCategory\", \"device_operatingSystem\",\n               \"geoNetwork_city\", \"geoNetwork_continent\",\"geoNetwork_metro\", \"geoNetwork_country\",\n              \"geoNetwork_networkDomain\", \"geoNetwork_region\",\n               \"geoNetwork_subContinent\", \"trafficSource_adContent\", \"trafficSource_adwordsClickInfo.adNetworkType\",\n               \"trafficSource_adwordsClickInfo.slot\", \"trafficSource_campaign\", \"trafficSource_keyword\", \"trafficSource_medium\",\n               \"trafficSource_source\"]\n\nsaved_trash = [\"fullVisitorId\"]\n\ntrash_trash = [\"totals_visits\", \"device_browserSize\", \"device_browserVersion\",\n                \"device_flashVersion\", \"device_language\", \"device_mobileDeviceBranding\", \"device_mobileDeviceInfo\",\n                \"device_mobileDeviceMarketingName\", \"device_mobileDeviceModel\", \"device_mobileInputSelector\",\n                \"device_screenColors\", \"device_screenResolution\", \"geoNetwork_cityId\", \"geoNetwork_latitude\",\n                \"geoNetwork_longitude\", \"geoNetwork_networkLocation\", \"trafficSource_adwordsClickInfo.criteriaParameters\",\n                \"device_operatingSystemVersion\"]\n                \nwanted_to_trash = [\"sessionId\", \"visitId\", \"trafficSource_adwordsClickInfo.gclId\", \"trafficSource_referralPath\"]\n\nin_future_wanted_to_trash = [\"visitStartTime\", \"date\", \"device_isMobile\", \"geoNetwork_city\", \"geoNetwork_metro\",\n                \"geoNetwork_networkDomain\", \"trafficSource_adContent\", \"trafficSource_keyword\"]\n\nto_heal = [\"totals_bounces\", \"totals_newVisits\", \"totals_pageviews\", \"trafficSource_adwordsClickInfo.adNetworkType\",\n            \"device_browser\", \"trafficSource_adwordsClickInfo.isVideoAd\", \"trafficSource_adwordsClickInfo.slot\", \n            \"trafficSource_adwordsClickInfo.page\", \"trafficSource_campaign\", \"trafficSource_isTrueDirect\",\n            \"trafficSource_medium\", \"trafficSource_source\", \"device_operatingSystem\", \"geoNetwork_city\",\n            \"geoNetwork_region\",\n            \"geoNetwork_continent\", \"geoNetwork_country\", \"geoNetwork_metro\", \"geoNetwork_networkDomain\",\n            \"geoNetwork_subContinent\", \"trafficSource_adContent\", \"trafficSource_keyword\"]\n\nanswer_feature = [\"totals_transactionRevenue\"]","57de79bb":"df_train = df_train.drop(columns=trash_trash)\ndf_test = df_test.drop(columns=trash_trash)","69f8b4fa":"df_train_eq_nan = df_train.fillna(-1543)\nfor col_name in wanted_to_trash:\n    print(col_name)\n    un = None\n    try:\n        un = np.unique(np.array(df_train_eq_nan[col_name]), return_counts=True)\n    except Exception:\n        un = np.unique(np.array(df_train_eq_nan[col_name]).astype(str), return_counts=True)\n    print(un)\n    print(\"DIFFERENT COUNT: \", un[0].shape[0])\n    print(\"-\" * 43)","35444457":"un = np.unique(df_train[\"sessionId\"], return_counts=True)\nidx = np.where(un[1] != 1)[0]\nrepeat_session_id = un[0][idx]\n\nrepeated_df = df_train[df_train[\"sessionId\"].isin(repeat_session_id)].sort_values([\"sessionId\"]).iloc[:, :20]\nrepeated_df","97507def":"np.all(\n    df_train[df_train[\"sessionId\"].isin(repeat_session_id)][[\"date\", \"sessionId\"]].groupby(\"sessionId\").count() == 2)","0eb3f560":"def parse_datetime(strdate):\n    year, month, day = list(map(lambda x: int(x), [strdate[:4], strdate[4:6], strdate[6:8]]))\n    return dt.datetime(year=year, month=month, day=day)","f4a9231f":"bad_idxs = []\nfor session_id in repeat_session_id:\n    part_df = repeated_df[repeated_df[\"sessionId\"] == session_id]\n    dt1, dt2 = parse_datetime(str(part_df[\"date\"].iloc[0])), parse_datetime(str(part_df[\"date\"].iloc[1]))\n    if dt1 < dt2:\n        bad_idxs.append(part_df.iloc[0].name)\n    else:\n        bad_idxs.append(part_df.iloc[1].name)","f07c4f5f":"len(bad_idxs)","cc228e4a":"df_train = df_train.drop(bad_idxs)\ndf_train.shape","015aeb22":"df_train.index = np.arange(df_train.shape[0])","f0da8448":"df_train_eq_nan = df_train.fillna(-1543)\nfor col_name in wanted_to_trash:\n    print(col_name)\n    un = None\n    try:\n        un = np.unique(np.array(df_train_eq_nan[col_name]), return_counts=True)\n    except Exception:\n        un = np.unique(np.array(df_train_eq_nan[col_name]).astype(str), return_counts=True)\n    print(un)\n    print(\"DIFFERENT COUNT: \", un[0].shape[0])\n    print(\"-\" * 43)","2c5d7e09":"df_train = df_train.drop(columns=[\"sessionId\"])\ndf_test = df_test.drop(columns=[\"sessionId\"])","016cec70":"un = np.unique(df_train[\"visitId\"], return_counts=True)\nidx = np.where(un[1] > 1)[0]\nrepeat_session_id = un[0][idx]\nrepeated_df = df_train[df_train[\"visitId\"].isin(repeat_session_id)].sort_values([\"visitId\"]).iloc[:, :20]\nrepeated_df","e41582a9":"len(repeat_session_id)","52d0abb7":"df_train = df_train.drop(columns=[\"visitId\"])\ndf_test = df_test.drop(columns=[\"visitId\"])","82406980":"df_train_eq_nan = df_train.fillna(-1543)\nun = np.unique(np.array(df_train_eq_nan[\"trafficSource_adwordsClickInfo.gclId\"]).astype(str), return_counts=True)\nidx = np.where(un[0] != \"-1543\")[0]\nnot_null_CI_train = un[0][idx]\nnot_null_CI_train, not_null_CI_train.shape","f93b3a85":"df_test_eq_nan = df_test.fillna(-1543)\nun = np.unique(np.array(df_test_eq_nan[\"trafficSource_adwordsClickInfo.gclId\"]).astype(str), return_counts=True)\nidx = np.where(un[0] != \"-1543\")[0]\nnot_null_CI_test = un[0][idx]\nnot_null_CI_test, not_null_CI_test.shape","cc981d69":"CI_intersect = set(not_null_CI_train) & set(not_null_CI_test)\nlen(CI_intersect)","b3b8cd7f":"df_train = df_train.drop(columns=[\"trafficSource_adwordsClickInfo.gclId\"])\ndf_test = df_test.drop(columns=[\"trafficSource_adwordsClickInfo.gclId\"])","4f0ac256":"df_train_eq_nan = df_train.fillna(-1543)\nun = np.unique(np.array(df_train_eq_nan[\"trafficSource_referralPath\"]).astype(str), return_counts=True)\nidx = np.where(un[0] != \"-1543\")[0]\nnot_null_RP_train = un[0][idx]\nnot_null_RP_train, not_null_RP_train.shape","bf0920aa":"df_test_eq_nan = df_test.fillna(-1543)\nun = np.unique(np.array(df_test_eq_nan[\"trafficSource_referralPath\"]).astype(str), return_counts=True)\nidx = np.where(un[0] != \"-1543\")[0]\nnot_null_RP_test = un[0][idx]\nnot_null_RP_test, not_null_RP_test.shape","65917dca":"del df_train_eq_nan, df_test_eq_nan\ngc.collect()","d6f9f815":"revenues = df_train[df_train[\"trafficSource_referralPath\"].isin(not_null_RP_train)][\"totals_transactionRevenue\"]\nrevenues[revenues != 0].shape","f0316213":"df_train[df_train[\"totals_transactionRevenue\"] != 0].shape","395c58d1":"categorial.append(\"trafficSource_referralPath\")","2a15f5a8":"zero_filling = [\"totals_bounces\", \"totals_newVisits\", \"totals_pageviews\", \"trafficSource_adwordsClickInfo.isVideoAd\",\n                \"trafficSource_adwordsClickInfo.page\", \"trafficSource_isTrueDirect\"]\nempty_filling = [\"device_browser\", \"trafficSource_adwordsClickInfo.adNetworkType\",\n                 \"trafficSource_adwordsClickInfo.slot\", \"geoNetwork_city\", \"geoNetwork_continent\", \n                 \"geoNetwork_country\", \"geoNetwork_metro\", \"geoNetwork_networkDomain\", \"geoNetwork_region\",\n                 \"geoNetwork_subContinent\", \"trafficSource_adContent\", \"trafficSource_keyword\",\n                 \"trafficSource_campaign\", \"trafficSource_medium\", \"trafficSource_source\",\n                 \"device_operatingSystem\", \"trafficSource_referralPath\"]","97764502":"df_train[zero_filling] = df_train[zero_filling].fillna(0)\ndf_train[\"trafficSource_adwordsClickInfo.isVideoAd\"] = df_train[\"trafficSource_adwordsClickInfo.isVideoAd\"].apply(lambda x: 1 if x == 0 else 0)\ndf_train[\"trafficSource_isTrueDirect\"] = df_train[\"trafficSource_isTrueDirect\"].apply(lambda x: 1 if x else 0)","8168a33b":"df_test[zero_filling] = df_test[zero_filling].fillna(0)\ndf_test[\"trafficSource_adwordsClickInfo.isVideoAd\"] = df_test[\"trafficSource_adwordsClickInfo.isVideoAd\"].apply(lambda x: 1 if x == 0 else 0)\ndf_test[\"trafficSource_isTrueDirect\"] = df_test[\"trafficSource_isTrueDirect\"].apply(lambda x: 1 if x else 0)","1a23f066":"df_train[empty_filling] = df_train[empty_filling].fillna(\"@\")\ndf_test[empty_filling] = df_test[empty_filling].fillna(\"@\")","7d8f73a1":"df_train[\"device_isMobile\"] = df_train[\"device_isMobile\"].apply(lambda x: 1 if x else 0)\ndf_test[\"device_isMobile\"] = df_test[\"device_isMobile\"].apply(lambda x: 1 if x else 0)","0d9036cf":"set(df_train.columns) - (set(numerical) | set(categorial))","a8f49376":"len(numerical) + len(categorial), df_train.shape","2d84b77e":"#df_train.to_csv(\".\/kernel\/data\/train_filtered.csv\", sep=\",\", index=False)\n#df_test.to_csv(\".\/kernel\/data\/test_filtered.csv\", sep=\",\", index=False)","f051b5be":"df_train = pd.read_csv(\"..\/input\/prepaired-data-of-customer-revenue-prediction\/train_filtered.csv\", converters={'fullVisitorId': str}, sep=\",\")\ndf_test = pd.read_csv(\"..\/input\/prepaired-data-of-customer-revenue-prediction\/test_filtered.csv\", converters={'fullVisitorId': str}, sep=\",\")","edc4e785":"for col_name in categorial:\n    print(col_name)\n    un_train = np.unique(np.array(df_train[col_name]).astype(str), return_counts=True)\n    un_test = np.unique(np.array(df_test[col_name]).astype(str), return_counts=True)\n    print(\"TRAIN: \", un_train[0][:10])\n    print(\"TEST: \", un_test[0][:10])\n    print(\"DIFFERENT TRAIN COUNT: \", un_train[0].shape[0])\n    print(\"DIFFERENT TEST COUNT: \", un_test[0].shape[0])\n    print(\"-\" * 43)","39516550":"easy_OHE = [\"channelGrouping\", \"device_deviceCategory\", \"geoNetwork_continent\", \"geoNetwork_subContinent\", \"trafficSource_medium\"]\neasy_OHE_but_prepare = [\"trafficSource_adwordsClickInfo.adNetworkType\", \"trafficSource_adwordsClickInfo.slot\"]\n\nbad_categorial = [\"device_browser\", \"date\", \"device_operatingSystem\", \"geoNetwork_city\", \"geoNetwork_metro\", \"geoNetwork_country\",\n                  \"geoNetwork_networkDomain\", \"geoNetwork_region\", \"trafficSource_adContent\",\n                  \"trafficSource_campaign\", \"trafficSource_keyword\", \"trafficSource_source\",\n                 \"trafficSource_referralPath\"]","caea6c21":"from sklearn.preprocessing import OneHotEncoder as OHE\nfrom sklearn.preprocessing import LabelEncoder as OE","52971710":"y_train = np.array(df_train[answer_feature])\nid_numeration_train = np.array(df_train[saved_trash])\nX_train_numerical = np.array(df_train[numerical])\n\nid_numeration_test = np.array(df_test[saved_trash])\nX_test_numerical = np.array(df_test[numerical])","0d12dafc":"train_easy_OHE = np.array(df_train[easy_OHE])\ntest_easy_OHE = np.array(df_test[easy_OHE])\n\neasy_OEs = [OE() for i in range(train_easy_OHE.shape[1])]\nfor f in range(train_easy_OHE.shape[1]):\n    easy_OEs[f].fit(train_easy_OHE[:, f])\n    train_easy_OHE[:, f] = easy_OEs[f].transform(train_easy_OHE[:, f])\n    test_easy_OHE[:, f] = easy_OEs[f].transform(test_easy_OHE[:, f])","a8abc6a2":"easy_enc = OHE(sparse=False)\neasy_enc.fit(train_easy_OHE)\ntrain_easy_OHE_conv = easy_enc.transform(train_easy_OHE)\ntest_easy_OHE_conv = easy_enc.transform(test_easy_OHE)","6a139143":"errors = np.where(\n    np.array(train_easy_OHE_conv[:, 9]).astype(bool)\n    != np.array(df_train[\"device_isMobile\"]))[0]\nerrors.shape","b93bf739":"errors = np.where(\n    ((np.array(train_easy_OHE_conv[:, 10]).astype(bool)) | (np.array(train_easy_OHE_conv[:, 9]).astype(bool)))\n    != np.array(df_train[\"device_isMobile\"]))[0]\nerrors.shape","0c074f59":"display(df_train.iloc[errors, 10:])","ef61cd0f":"deviceCategory_idx = 11\nis_mobile_idx = 12","352d9536":"df_train.iloc[errors, deviceCategory_idx] = (\n    df_train.iloc[errors, is_mobile_idx].apply(lambda x: \"desktop\" if x == 0 else \"mobile\"))","fd7edca9":"errors_te = np.where(\n    ((np.array(test_easy_OHE_conv[:, 10]).astype(bool)) | (np.array(test_easy_OHE_conv[:, 9]).astype(bool)))\n    != np.array(df_test[\"device_isMobile\"]))[0]\nerrors_te.shape","75613b61":"df_test.iloc[errors_te, deviceCategory_idx - 1] = (\n    df_test.iloc[errors_te, is_mobile_idx - 1].apply(lambda x: \"desktop\" if x == 0 else \"mobile\"))","4c2614ef":"train_easy_OHE = np.array(df_train[easy_OHE])\ntest_easy_OHE = np.array(df_test[easy_OHE])\neasy_OEs = [OE() for i in range(train_easy_OHE.shape[1])]\nfor f in range(train_easy_OHE.shape[1]):\n    easy_OEs[f].fit(train_easy_OHE[:, f])\n    train_easy_OHE[:, f] = easy_OEs[f].transform(train_easy_OHE[:, f])\n    test_easy_OHE[:, f] = easy_OEs[f].transform(test_easy_OHE[:, f])\neasy_enc = OHE(sparse=False)\neasy_enc.fit(train_easy_OHE)\ntrain_easy_OHE_conv = easy_enc.transform(train_easy_OHE)\ntest_easy_OHE_conv = easy_enc.transform(test_easy_OHE)","fd7629b5":"errors2 = np.where(\n    ((np.array(train_easy_OHE_conv[:, 10]).astype(bool)) | (np.array(train_easy_OHE_conv[:, 9]).astype(bool)))\n    != np.array(df_train[\"device_isMobile\"]))[0]\nprint(errors2.shape)\nerrors_te2 = np.where(\n    ((np.array(test_easy_OHE_conv[:, 10]).astype(bool)) | (np.array(test_easy_OHE_conv[:, 9]).astype(bool)))\n    != np.array(df_test[\"device_isMobile\"]))[0]\nprint(errors_te2.shape)","34513741":"easy_OHE_names = ['channelGrouping_(Other)',\n 'channelGrouping_Affiliates',\n 'channelGrouping_Direct',\n 'channelGrouping_Display',\n 'channelGrouping_Organic Search',\n 'channelGrouping_Paid Search',\n 'channelGrouping_Referral',\n 'channelGrouping_Social',\n 'device_deviceCategory_desktop',\n 'device_deviceCategory_mobile',\n 'device_deviceCategory_tablet',\n 'geoNetwork_continent_@',\n 'geoNetwork_continent_Africa',\n 'geoNetwork_continent_Americas',\n 'geoNetwork_continent_Asia',\n 'geoNetwork_continent_Europe',\n 'geoNetwork_continent_Oceania',\n 'geoNetwork_subContinent_@',\n 'geoNetwork_subContinent_Australasia',\n 'geoNetwork_subContinent_Caribbean',\n 'geoNetwork_subContinent_Central America',\n 'geoNetwork_subContinent_Central Asia',\n 'geoNetwork_subContinent_Eastern Africa',\n 'geoNetwork_subContinent_Eastern Asia',\n 'geoNetwork_subContinent_Eastern Europe',\n 'geoNetwork_subContinent_Melanesia',\n 'geoNetwork_subContinent_Micronesian Region',\n 'geoNetwork_subContinent_Middle Africa',\n 'geoNetwork_subContinent_Northern Africa',\n 'geoNetwork_subContinent_Northern America',\n 'geoNetwork_subContinent_Northern Europe',\n 'geoNetwork_subContinent_Polynesia',\n 'geoNetwork_subContinent_South America',\n 'geoNetwork_subContinent_Southeast Asia',\n 'geoNetwork_subContinent_Southern Africa',\n 'geoNetwork_subContinent_Southern Asia',\n 'geoNetwork_subContinent_Southern Europe',\n 'geoNetwork_subContinent_Western Africa',\n 'geoNetwork_subContinent_Western Asia',\n 'geoNetwork_subContinent_Western Europe',\n 'trafficSource_medium_@',\n 'trafficSource_medium_affiliate',\n 'trafficSource_medium_cpc',\n 'trafficSource_medium_cpm',\n 'trafficSource_medium_organic',\n 'trafficSource_medium_referral']","fd1278c1":"df_test[\"trafficSource_adwordsClickInfo.adNetworkType\"] = (\n    df_test[\"trafficSource_adwordsClickInfo.adNetworkType\"].apply(lambda x: \"@\" if x == 'Content' else x))\ndf_test[\"trafficSource_adwordsClickInfo.slot\"] = (\n    df_test[\"trafficSource_adwordsClickInfo.slot\"].apply(lambda x: \"@\" if x == 'Google Display Network' else x))","3f6e25ba":"for col_name in easy_OHE_but_prepare:\n    print(col_name)\n    un_train = np.unique(np.array(df_train[col_name]).astype(str), return_counts=True)\n    un_test = np.unique(np.array(df_test[col_name]).astype(str), return_counts=True)\n    print(\"TRAIN: \", un_train[0][:10])\n    print(\"TEST: \", un_test[0][:10])\n    print(\"DIFFERENT TRAIN COUNT: \", un_train[0].shape[0])\n    print(\"DIFFERENT TEST COUNT: \", un_test[0].shape[0])\n    print(\"-\" * 43)","9942d7a8":"train_easy_OHE_prep = np.array(df_train[easy_OHE_but_prepare])\ntest_easy_OHE_prep = np.array(df_test[easy_OHE_but_prepare])\neasy_OEs_prep = [OE() for i in range(train_easy_OHE_prep.shape[1])]\nfor f in range(train_easy_OHE_prep.shape[1]):\n    easy_OEs_prep[f].fit(train_easy_OHE_prep[:, f])\n    train_easy_OHE_prep[:, f] = easy_OEs_prep[f].transform(train_easy_OHE_prep[:, f])\n    test_easy_OHE_prep[:, f] = easy_OEs_prep[f].transform(test_easy_OHE_prep[:, f])","5e669ecf":"easy_enc_prep = OHE(sparse=False)\neasy_enc_prep.fit(train_easy_OHE_prep)\ntrain_easy_OHE_prep_conv = easy_enc_prep.transform(train_easy_OHE_prep)\ntest_easy_OHE_prep_conv = easy_enc_prep.transform(test_easy_OHE_prep)","22cab1bb":"easy_OHE_prep_names = ['trafficSource_adwordsClickInfo.adNetworkType_@',\n 'trafficSource_adwordsClickInfo.adNetworkType_Google Search',\n 'trafficSource_adwordsClickInfo.adNetworkType_Search partners',\n 'trafficSource_adwordsClickInfo.slot_@',\n 'trafficSource_adwordsClickInfo.slot_RHS',\n 'trafficSource_adwordsClickInfo.slot_Top']","9746d129":"train_bad_cat = df_train[bad_categorial].copy()\ntest_bad_cat = df_test[bad_categorial].copy()\nfor f in bad_categorial:\n    train_bad_cat[f], indexer = pd.factorize(train_bad_cat[f])\n    test_bad_cat[f] = indexer.get_indexer(test_bad_cat[f])","d022b33d":"y_train_clf = (y_train.ravel() > 0).astype(int)","c24c0589":"with_rev = df_train.iloc[y_train_clf == True, :][bad_categorial]\nno_rev = df_train.iloc[y_train_clf == False, :][bad_categorial]","ab1976c2":"for feature in bad_categorial:\n    vals = with_rev[feature]\n    un, cnt = np.unique(vals, return_counts=True)\n    data = np.hstack((un.reshape((-1, 1)), cnt.reshape((-1, 1))))\n\n    top = 20\n    df = pd.DataFrame(data, columns=[\"feature\", \"count features\"])\n    plt.figure(figsize=(15, 8))\n    sns.barplot(x=\"count features\", y='feature', data=df.sort_values(\"count features\", ascending=False).iloc[:top])\n    plt.title(\"FEATURE {} HAVE REVENUE\".format(feature), fontsize=18)\n    plt.show()\n    \n    vals = no_rev[feature]\n    un, cnt = np.unique(vals, return_counts=True)\n    data = np.hstack((un.reshape((-1, 1)), cnt.reshape((-1, 1))))\n    top = 20\n    df = pd.DataFrame(data, columns=[\"feature\", \"count features\"])\n    plt.figure(figsize=(15, 8))\n    sns.barplot(x=\"count features\", y='feature', data=df.sort_values(\"count features\", ascending=False).iloc[:top])\n    plt.title(\"FEATURE {} HAVEN'T REVENUE\".format(feature), fontsize=18)\n    plt.show()","90b5c497":"top_rev =    [5, 0, 6, 20, 6, 4, 7, 10, 2, 5, 5, 16, 5]\ntop_no_rev = [11, 0, 6, 10, 5, 10, 7, 4, 3, 4, 5, 10, 7] ","a74b8162":"bad_cat_to_OHE = defaultdict(set)\n\nfor feature, t_r, t_n_r in zip(bad_categorial, top_rev, top_no_rev):\n    vals = with_rev[feature]\n    un, cnt = np.unique(vals, return_counts=True)\n    sortidx = np.argsort(cnt)\n    bad_cat_to_OHE[feature] |= set(un[sortidx][::-1][:t_r])\n    \n    vals = no_rev[feature]\n    un, cnt = np.unique(vals, return_counts=True)\n    sortidx = np.argsort(cnt)\n    bad_cat_to_OHE[feature] |= set(un[sortidx][::-1][:t_n_r])\n    if \"@\" in bad_cat_to_OHE[feature]:\n        bad_cat_to_OHE[feature].remove(\"@\")\n        \n    test_vals = set(df_test[feature])\n    bad_cat_to_OHE[feature] &= test_vals","cbf151d6":"ordered_dict = dict()\nfor (name, value) in bad_cat_to_OHE.items():\n    ordered_dict[name] = list(value)\n    \nbad_cat_features_OHE_names = []\nfor (name, value) in ordered_dict.items():\n    if len(value) > 0:\n        for val in value:\n            bad_cat_features_OHE_names.append(\"{}_{}\".format(name, val))","56c30f08":"add_len = len(bad_cat_features_OHE_names)\nadd_len","4e6727df":"train_bad_cat_to_OHE = np.zeros((df_train.shape[0], add_len))\ntest_bad_cat_to_OHE = np.zeros((df_test.shape[0], add_len))\nfor num, feature_value in enumerate(bad_cat_features_OHE_names):\n    idx = feature_value.rfind(\"_\")\n    feature, value = feature_value[:idx], feature_value[idx + 1:]\n    train_bad_cat_to_OHE[:, num] = np.array(df_train[feature] == value).astype(int)\n    test_bad_cat_to_OHE[:, num] = np.array(df_test[feature] == value).astype(int)","bcf37e4b":"bad_categorial += [\"weekday\"]","5f5ab014":"tr_wd = np.array(pd.to_datetime(df_train[\"date\"], format=\"%Y%m%d\").apply(lambda x: x.weekday())).reshape((-1, 1))\nte_wd = np.array(pd.to_datetime(df_test[\"date\"], format=\"%Y%m%d\").apply(lambda x: x.weekday())).reshape((-1, 1))","4fbe1eb7":"X_train = np.hstack((X_train_numerical, train_easy_OHE_conv,\n                      train_easy_OHE_prep_conv, train_bad_cat_to_OHE, train_bad_cat, tr_wd))\nX_test = np.hstack((X_test_numerical, test_easy_OHE_conv,\n                     test_easy_OHE_prep_conv, test_bad_cat_to_OHE, test_bad_cat, te_wd))","fb1d4c3d":"feature_names = numerical + easy_OHE_names + easy_OHE_prep_names + bad_cat_features_OHE_names + bad_categorial\nlen(feature_names), X_train.shape","9be0ad10":"from sklearn.decomposition import TruncatedSVD, PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport scipy\nimport pickle\nimport re\nimport time\nfrom sklearn.utils import shuffle as skshuffle","3cf37406":"def visualize_data(data_train, y_train, data_test, amount_train=None, amount_test=None,\n                   scale=True, threeD=False, shuffle=False, alpha=1.0):\n    \n    def visualize_2d(data_train, y_train, data_test):\n        tsvd = PCA(n_components=2)\n        tsvd.fit(data_train)\n        Z_train = tsvd.fit_transform(data_train)\n        Z_test = tsvd.transform(data_test)\n\n        classes_amount = np.unique(y_train).shape[0]\n        cm = plt.get_cmap('jet')\n        plt.figure(figsize=(18, 15))\n        plt.scatter(Z_train[:, 0], Z_train[:, 1],\n                    c=y_train.ravel(), cmap='RdYlGn_r', alpha=alpha) # green - 1 blue 0\n        plt.title(\"Train data\")\n        plt.figure(figsize=(18, 15))\n        plt.scatter(Z_test[:, 0], Z_test[:, 1],\n                    c=[\"plum\"] * Z_test.shape[0], alpha=alpha)\n        plt.title(\"Test data\")\n        plt.show()\n        \n    def visualize_3d(data_train, y_train, data_test):\n        tsvd = PCA(n_components=3)\n        tsvd.fit(data_train)\n        Z_train = tsvd.fit_transform(data_train)\n        Z_test = tsvd.transform(data_test)\n\n        classes_amount = np.unique(y_train).shape[0]\n        cm = plt.get_cmap('jet')\n        \n        fig = plt.figure(figsize=(18, 15))\n        ax = fig.add_subplot(111, projection='3d')\n        sc = ax.scatter(Z_train[:, 0], Z_train[:, 1], Z_train[:, 2],\n                c=y_train.ravel(), cmap='RdYlGn_r', alpha=alpha)\n        plt.title(\"Train data\")\n        fig = plt.figure(figsize=(18, 15))\n        ax = fig.add_subplot(111, projection='3d')\n        sc = ax.scatter(Z_test[:, 0], Z_test[:, 1], Z_test[:, 2],\n                c=[\"plum\"] * Z_test.shape[0], alpha=alpha)\n        plt.title(\"Test data\")\n        plt.show()\n        \n    if amount_train is None:\n        amount_train = data_train.shape[0]\n    else:\n        amount_train = int(amount_train * data_train.shape[0])\n        \n    if amount_test is None:\n        amount_test = data_test.shape[0]\n    else:\n        amount_test = int(amount_test * data_test.shape[0])\n        \n    if shuffle:\n        data_train, y_train = skshuffle(data_train, y_train)\n        data_test = skshuffle(data_test)\n    \n    if scale:\n        scaler = StandardScaler(copy=True)\n        scaler.fit(data_train)\n        X_train = scaler.transform(data_train)\n        X_test = scaler.transform(data_test)\n    else:\n        X_train = data_train\n        X_test = data_test\n        \n    start = time.time()\n    if threeD:\n        visualize_3d(X_train[:amount_train, :], y_train[:amount_train], X_test[:amount_train, :])\n    else:\n        visualize_2d(X_train[:amount_train, :], y_train[:amount_train], X_test[:amount_train, :])\n    print(time.time() - start)","61052ef2":"y_train_clf = np.copy(y_train)\ny_train_clf[y_train_clf > 0] = 1\ny_train_clf[y_train_clf == 0] = 0","b8899631":"visualize_data(X_train, y_train_clf, X_test, amount_train=0.2,\n               amount_test=0.2, threeD=False, alpha=0.5, scale=True, shuffle=True)","c502b760":"visualize_data(X_train, y_train_clf, X_test, amount_train=0.2,\n               amount_test=0.2, threeD=True, alpha=0.5, scale=True, shuffle=True)","38a4053e":"### 0. Intro\n\nIt's illustration of FE logic:\n* delete meaningless and trash features\n* correct mistakes in dataset\n* construct new features\n* visualize them","e2e79077":"**Save result**","305e45e6":"**Let's visualize train and test:**","fcf5d57f":"**Let's encode easy_OHE_but_prepare:**","a324905e":"**Explore features from wanted_to_trash**","592a9970":"**Assumption: since we will encode the device_deviceCategory, the isMobile feature can be thrown out, as it will be a duplicate. So we will check it**","e98ef134":"**So delete objects and SessionId:**","adf92836":"**Check if is that true that there are only two record for such \"bad\" equal SessionId:**","245860d1":"**There is no errors!**","2591ce14":"**Let explore how many objects has revenue when trafficSource_referralPath isn't a nan**","1a7ef7db":"**Add some new OHE features from categorial features**","0a236c0b":"**Explore the objects with same SessionId**","64afedd5":"**Seems that SessionId and visitId should be removed. Let see at them:**","f44f9d57":"* numerical -- _numerical features_\n* categorial -- _categorial features_\n* saved_trash -- _actually fullVisitorId_\n* trash_trash -- _unusefull features. Has a lot of nans or the same value for all objects_\n* wanted_to_trash -- _explore this featuers now but wants to delete them (e.g. all values are different for all objects)_\n* in_future_wanted_to_trash -- <i>features that can be dublicated by others (e.g. divice_isMobile may be duplicated by One-Hot-encoding of device_deviceCategory) or there is not any dependence between them and answer. But now don't remove them<\/i>\n* to_heal -- _fill nans by other value_\n* answer_feature -- _feature with answer_","07f87378":"**Collect all together:**","2a5ca66d":"* easy_OHE -- _easy to do One-Hot-Encoding_\n* easy_OHE_but_prepare -- _easy to do One-Hot-Encoding, but feature values in train and in test are not the same_\n* bad_categorial -- _other categorial features_","bb5cb749":"**Explore feature values in train**","7006b92d":"**Remove strange column trafficSource_campaignCode from test**","e12a0970":"### 2. Data exploring and filtering. Part 1","2293a97a":"**No, it's not a truth. Suppose that isMobile means that device_deviceCategory equals \"mobile\" or \"tablet\":**","d3baed3b":"**View dataset**","cd6a3628":"**Use this kernel https:\/\/www.kaggle.com\/ravann\/1-step-by-step-format-data-to-columnar-format\/notebook\n**","4cd58e33":"**Let's see on VisitId:**","794f1560":"**Let's see on features date and SessionId. Obviously if SessionIds are the same then fullVisitodIds are also the same. It seems that difference between dates for equal SessinId is 1 day. Perhaps the session was started at one day and ended at the next day, but there are two records about this one session.  So we can not only delete feature SessionId but also delete duplicated objects with the same SessionId (delete more earlier objects because there is much more information about later objects).**","ff399778":"**Load dataset**","73ed213e":"**So it seems that this feature is important**","f2039725":"**It's truth, but there is some errors that are needed to be fixed**","2fc372a7":"**Red points -- records with some revenue**","6748586a":"**Think about feature trafficSource_referralPath:**","e4fb1df6":"**View at \"socialEngagementType\"**","9cc898fd":"**Fill missing values in totals_transactionRevenues by zeros**","794ad98d":"**Think about feature trafficSource_adwordsClickInfo.gclId: it has a lot of nans**","53b9b9d7":"**But some of values of features let's convert via OHE. Explore how feature values are distributed for record with some revenue and with no revenue:**","b069d1e6":"**Apparently, there are errors in deviceCategory rather than in isMobie. Moreover, in erroneous examples in favor of the error says feature OS. Let's make this correction: where isMobile in erroneous examples = 0 -- set desktop, otherwise -- mobile.**","a52d2006":"### 3. Data exploring and filtering. Part 2","11bd829c":"**Remove features from trash_trash**","50ed6d6e":"**There is a little intersect and it seems to be such king of information coding. I suppose we should remove this feature**","50035a5a":"**Suppose that isMobile means that device_deviceCategory equals \"mobile\":**","6d9d4ea6":"**We can see that records with same visitId has different fullVisitorId but the same visitStartTime. Because of simultaneous sessions data was received concurrently and this sessions has the same visidId. So we can't remove records with same visitId but can remove feature visitId**","d3168891":"**We can select the following groups of categorial features:**","77dd3210":"**Fill nans:**","6c26a9d6":"**After watching this values I aggreagated the following groups of featues**","3998e8fb":"**Add to categorial features feature weekday:**","a143dc35":"**Remove this \"usefull\" feature from train and test**","75683e24":"**Check whether columns in train and in test are equal**","b3cdec63":"### 1. Convert data to json format","b78c215a":"**Let's make a top of values for each feature:**","a5aa0c5b":"**Let's factorize all bad_categorial features**"}}