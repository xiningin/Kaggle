{"cell_type":{"2f316de8":"code","1d33a4ef":"code","c0a4453b":"code","de7bddfd":"code","16af207e":"code","13ec0acb":"code","ee6f7d76":"code","dbc0eda6":"code","731156c5":"code","f1dc1f45":"markdown"},"source":{"2f316de8":"!pip install kaggle-environments -U > \/dev\/null 2>&1\n!cp -r ..\/input\/lux-ai-2021\/* .","1d33a4ef":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","c0a4453b":"model = torch.jit.load(\"..\/input\/models-lux\/model_dr.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_dr.pth')","de7bddfd":"model = torch.jit.load(\"..\/input\/models-lux\/model_toad.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_toad.pth')","16af207e":"model = torch.jit.load(\"..\/input\/models-lux\/model_rl.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_rl.pth')","13ec0acb":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\nfrom collections import Counter\nfrom torch import nn\n\n\npath = '\/kaggle_simulations\/agent' if os.path.exists('\/kaggle_simulations') else '.'\n\nmodel = torch.jit.load(f\"{path}\/model_dr.pth\")\nmodel.eval()\n\nmodel2 = torch.jit.load(f\"{path}\/model_toad.pth\")\nmodel2.eval()\n\nmodel3 = torch.jit.load(f\"{path}\/model_rl.pth\")\nmodel3.eval()\n\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) \/\/ 2\n    y_shift = (32 - height) \/\/ 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) \/ 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown \/ 6,\n                    (wood + coal + uranium) \/ 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]   \n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt \/ 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) \/ 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel \/ lightupkeep, 10) \/ 10\n    \n    # Day\/Night Cycle\n    b[17, :] = obs['step'] % 40 \/ 40\n    # Turns\n    b[18, :] = obs['step'] \/ 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\n\ndef get_action(policy, unit, dest):\n\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n\ndef get_action_unet(policy, unit, dest, shift):\n    logits = nn.Softmax(policy[:, unit.pos.x + shift, unit.pos.y + shift] )\n    action = unet_unit_actions[ np.argmax( policy[:, unit.pos.x + shift, unit.pos.y + shift] )]\n    pos = unit.pos.translate(action[-1], 1) or unit.pos\n    if pos not in dest or in_city(pos):\n        return call_func(unit, *action), pos\n    \n    return unit.move('c'), unit.pos \n\n\ndef agent(observation, configuration):\n    global game_state\n    \n    game_state = get_game_state(observation)    \n    player = game_state.players[observation.player]\n    actions = []\n    \n        \n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            if city_tile.can_act():\n                if unit_count < player.city_tile_count: \n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n                elif not player.researched_uranium():\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n    \n    dest = []\n\n    for unit in player.units:\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).unsqueeze(0))\n                p2 = model2(torch.from_numpy(state).unsqueeze(0))\n                p3 = model3(torch.from_numpy(state).unsqueeze(0))\n                \n            \n            policy = p.squeeze(0).numpy() \n            policy2 = p2.squeeze(0).numpy()\n            policy3 = p3.squeeze(0).numpy()\n            \n            softmax = nn.Softmax(dim=0)\n            logits1 = softmax(torch.from_numpy(policy))\n            logits2 = softmax(torch.from_numpy(policy2))\n            logits3 = softmax(torch.from_numpy(policy3))\n            \n            ensemble_logits = np.array( logits1 * 0.6 + logits2 * 0.2 + logits3 * 0.2)\n\n            action, pos = get_action(ensemble_logits, unit, dest)\n            \n        \n            #action2, pos = get_action(policy2, unit, dest)\n            #action3, pos = get_action(policy3, unit, dest)\n            #action4, pos = get_action_unet(policy4, unit, dest, shift)\n            \n            #action = Counter([action,action,action,\n            #                  action2,action2,]).most_common(1)[0][0]\n            actions.append(action)\n            dest.append(pos)\n\n    return actions","ee6f7d76":"np.argsort( np.array([1,2,44,7,5])[::-1] )","dbc0eda6":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","731156c5":"!tar -czf submission.tar.gz *","f1dc1f45":"# Submission"}}