{"cell_type":{"9b2b9227":"code","2cb4f6ea":"code","0a62e56c":"code","4c5e0c14":"code","e0d61420":"code","0a13c500":"code","dedb6d83":"code","cae5e519":"code","99084335":"code","938692d2":"code","bbd27e4a":"code","87d5a73a":"code","a5524c2f":"code","2776453a":"code","6f61fd03":"code","49326624":"code","c47b0cbd":"code","90e4f279":"code","aebf82c4":"code","76e69f98":"code","721877a7":"code","e01e2ab7":"code","f0387cbd":"code","697295e6":"code","799ddf85":"code","d4dee7bf":"code","1f870da1":"code","ef038b40":"code","73c889e4":"code","5babd31c":"code","5ae01869":"code","836f901e":"markdown","13b2eea0":"markdown","fb883eb2":"markdown","e4f9fabd":"markdown","5ed07835":"markdown","a72ffdf5":"markdown","758ac91f":"markdown","5d28b1ae":"markdown","0045eee9":"markdown","5ef5d632":"markdown","925c2092":"markdown"},"source":{"9b2b9227":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cb4f6ea":"data = pd.read_csv(\"\/kaggle\/input\/kdd-cyberattack\/kddcup.data_10_percent\")\ndata.head()","0a62e56c":"# Columns creation and reading of dataset\n\ncolumns = [\"duration\", \"protocoltype\", \"service\", \"flag\", \"srcbytes\", \"dstbytes\", \"land\", \"wrongfragment\",\n           \"urgent\", \"hot\", \"numfailedlogins\", \"loggedin\", \"numcompromised\", \"rootshell\", \"suattempted\",\n           \"numroot\", \"numfilecreations\", \"numshells\", \"numaccessfiles\", \"numoutboundcmds\", \"ishostlogin\",\n           \"isguestlogin\", \"count\", \"srvcount\", \"serrorrate\", \"srvserrorrate\", \"rerrorrate\", \"srvrerrorrate\",\n           \"samesrvrate\", \"diffsrvrate\", \"srvdiffhostrate\", \"dsthostcount\", \"dsthostsrvcount\",\n           \"dsthostsamesrvrate\", \"dsthostdiffsrvrate\", \"dsthostsamesrcportrate\", \"dsthostsrvdiffhostrate\",\n           \"dsthostserrorrate\", \"dsthostsrvserrorrate\", \"dsthostrerrorrate\", \"dsthostsrvrerror_rate\", \"labels\"]\n\n\ndata = pd.read_csv(\"\/kaggle\/input\/kdd-cyberattack\/kddcup.data_10_percent\", names=columns)\ndata.head()","4c5e0c14":"# Data set size\ndata.shape","e0d61420":"# Null values\n[col for col in data.columns if data[col].isnull().sum() > 0]","0a13c500":"data.dtypes","dedb6d83":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nsns.set_style(\"darkgrid\")\nplt.rcParams[\"figure.figsize\"] = (12,8)\nfont = {\"size\"   : 11}\n\nplt.rc('font', **font)\n\n\n\ngrouped_labels = data.groupby(\"labels\")[\"labels\"].count().sort_values(ascending=False)\nplt.xticks(rotation=45)\n\n\nsns.barplot(x=grouped_labels.index, y=grouped_labels.values)\nplt.title(\"Count of attacks and normal events\")\nplt.ylabel(\"Count\")","cae5e519":"grouped_labels = data.groupby(\"protocoltype\")[\"protocoltype\"].count().sort_values(ascending=False)\nplt.xticks(rotation=45)\n\n\nsns.barplot(x=grouped_labels.index, y=grouped_labels.values)\nplt.title(\"labels by Protocol type\")\nplt.ylabel(\"Count\")","99084335":"def remove_dot_nornalize(label):\n    \"\"\" Remove dot from labels and converts anything that is not normal to attack \"\"\"\n    label = label.replace(\".\", \"\")\n    return label if label == \"normal\" else \"attack\"\n\n\ndata[\"labels\"] = data[\"labels\"].apply(lambda label: remove_dot_nornalize(label))\nprint(pd.unique(data[\"labels\"]))","938692d2":"sns.countplot(x=\"labels\", data=data)\nplt.title(\"Class balance\")","bbd27e4a":"sns.catplot(x=\"protocoltype\", y=\"count\", hue=\"labels\", data=data)\nplt.title(\"Number of connections to the same host as the current connection in the past two seconds \")","87d5a73a":"sns.catplot(x=\"protocoltype\", y=\"numfilecreations\", hue=\"labels\", data=data)","a5524c2f":"sns.catplot(x=\"protocoltype\", y=\"numfailedlogins\", hue=\"labels\", data=data)","2776453a":"sns.catplot(x=\"protocoltype\", y=\"numshells\", hue=\"labels\", data=data)","6f61fd03":"sns.catplot(x=\"protocoltype\", y=\"numaccessfiles\", hue=\"labels\", data=data)","49326624":"sns.catplot(x=\"protocoltype\", y=\"numroot\", hue=\"labels\", data=data)","c47b0cbd":"sns.catplot(x=\"protocoltype\", y=\"suattempted\", hue=\"labels\", data=data)","90e4f279":"sns.catplot(x=\"protocoltype\", y=\"duration\", hue=\"labels\", data=data)","aebf82c4":"sns.catplot(x=\"protocoltype\", y=\"srcbytes\", hue=\"labels\", data=data)","76e69f98":"sns.catplot(x=\"protocoltype\", y=\"dstbytes\", hue=\"labels\", data=data)","721877a7":"# Creating feature vector and target vector.\nX = data.drop(\"labels\", axis=1)\ny = data[\"labels\"]\n\n\n# Constant features \n[col for col in X.columns if X[col].nunique() == 1]","e01e2ab7":"# Those two columns have no variance, thus they won't be of any use to our model. Let's drop them\nX.drop([\"numoutboundcmds\", \"ishostlogin\"], axis=1, inplace=True)","f0387cbd":"# Encode categorical columns and split data.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Encoding target variable\nlr = LabelEncoder()\ny = lr.fit_transform(y)\n\n\n# Encoding predictors\nenc_protocol = pd.get_dummies(data[\"protocoltype\"], prefix=\"protocol_\")\nenc_service = pd.get_dummies(data[\"service\"], prefix=\"service_\")\nenc_flag = pd.get_dummies(data[\"flag\"], prefix=\"flag_\")\n\nX = pd.concat([X, enc_protocol, enc_service, enc_flag], axis=1)\nX.drop(\"protocoltype\", axis=1, inplace=True)\nX.drop(\"service\", axis=1, inplace=True)\nX.drop(\"flag\", axis=1, inplace=True)\n\n\n# Splitting data into train and test...since our data is implaced we stratify it\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)","697295e6":"# Anova test for feature importance\nfrom sklearn.feature_selection import f_classif\n\n\nanova_f_classif = f_classif(X_train, y_train)\n\n\nanova_f_classif = pd.Series(anova_f_classif[1])\nanova_f_classif.index = X_train.columns\nanova_f_classif.sort_values(ascending=False).plot.bar(figsize=(20, 6))","799ddf85":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\n\nlr.fit(X_train, y_train)","d4dee7bf":"# Prediciton\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)","1f870da1":"from sklearn.metrics import f1_score, plot_confusion_matrix\n\n\nprint(\"Training f1 score {}\".format(f1_score(y_train, y_train_pred)))\nprint(\"Evaluation f1 score {}\".format(f1_score(y_test, y_test_pred)))","ef038b40":"plot_confusion_matrix(lr, X_test, y_test)\nplt.show()","73c889e4":"from sklearn.neighbors import KNeighborsClassifier\n\n\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)","5babd31c":"y_knn_predict = knn.predict(X_test)\nprint(\"Evaluation f1 score {}\".format(f1_score(y_test, y_knn_predict)))","5ae01869":"plot_confusion_matrix(knn, X_test, y_test)\nplt.show()","836f901e":"#### Many columns seem to have no big relevance to the target, but this method is univariate and sometimes some columns combined with others may have sense. So for now we'll keep them","13b2eea0":"#### There's a slight positive correlation between `tcp` protocol `maliscious` event and a high `duration` of the connection between the user and the host","fb883eb2":"#### Looks much better now, let's continue with EDA","e4f9fabd":"#### There seems to a high number of maliscious events within the `tcp` and `icmp` protocols having a high number of past connections to the current host within the last 2 seconds. That's a column that already exists within the dataset.","5ed07835":"#### Ok apart from `procotol`, `last connection to same host` and `duration` there is no another evident preliminary conclusion that we might draw between events and the target, let's have later on a featrue importance regarding the target. Next we'll drop `constant features` and `quasi constant features`","a72ffdf5":"#### First thing here we have no columns in our dataset so we need to create ones for ourselves and read back the data. Let's do this !","758ac91f":"#### Let's try out a diiferent algorithm","5d28b1ae":"#### KNN model is slightely better than LogisticRegression but it takes more time to train","0045eee9":"#### Our first model is going to be a Binomial one, so from here on we're going to map anything that is not normal to attack. Next data analysis will be basesd on this transformation","5ef5d632":"## In this notebook we're going to build a Network Traffic Classifier, which will yield if a given event if legit or maliscous.\n\n### The content will be as follows\n\n1. EDA\n2. Data Processing\n3. Model training\n4. Hyperparameter tuning","925c2092":"### We have few false negative (297) and false positives (1940)"}}