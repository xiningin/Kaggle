{"cell_type":{"03e0902b":"code","1bdb5a87":"code","544929eb":"code","e9384409":"code","ccaabc69":"code","584505ac":"code","098950e9":"code","14191f91":"code","7fd3c508":"code","2ae46cfa":"code","0cca9755":"code","509f5fe5":"code","b8817797":"code","1aaa3a3f":"markdown"},"source":{"03e0902b":"# disabling tensorflow warnings\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n\n# Importing Necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport glob\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\n# Importing visualization libraries\nimport matplotlib.pyplot as plt","1bdb5a87":"# data directories\nbase_dir = r\"..\/input\/100-bird-species\"\ntrain_dir = os.path.join(base_dir, \"train\")\nval_dir = os.path.join(base_dir, \"valid\")\ntest_dir = os.path.join(base_dir, \"test\")","544929eb":"# Dataset\nbatch_size=64\nimage_size=(256, 256)\ntrain_ds = image_dataset_from_directory(train_dir, label_mode=\"categorical\", batch_size=batch_size, image_size=image_size)\nval_ds = image_dataset_from_directory(val_dir, label_mode=\"categorical\", batch_size=batch_size, image_size=image_size)\ntest_ds = image_dataset_from_directory(test_dir, label_mode=\"categorical\", batch_size=batch_size, image_size=image_size)","e9384409":"# Class names\nclasses = train_ds.class_names","ccaabc69":"# visualizing images with labels\nfor images, labels in train_ds.take(1):\n    labels = np.argmax(labels, axis=-1)\n    plt.figure(figsize=(18, 10))\n    for i in range(18):\n        plt.subplot(3, 6, i+1)\n        plt.imshow(images[i].numpy().astype('uint8'))\n        plt.title(classes[labels[i]])\n        plt.axis('off')\n\nplt.show()","584505ac":"# Pretrained vgg16\nconv_base = VGG16(include_top=False, weights='imagenet', input_shape=(256, 256, 3))","098950e9":"# making conv_base non-trainable\nconv_base.trainable = False","14191f91":"# Defining model\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(1048, activation='relu'))\nmodel.add(Dense(325, activation='softmax'))\nmodel.summary()","7fd3c508":"# defining callback and compiling the model\ncallbacks = [EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n            ReduceLROnPlateau(monitor = 'val_loss', factor=0.1, patience=2, verbose=1)]\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])","2ae46cfa":"# training the model\nhistory = model.fit(train_ds, epochs=40, validation_data=val_ds, verbose=1, callbacks=callbacks)","0cca9755":"# visulizing results\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(len(loss))\nplt.plot(epochs, loss, \"b\", label=\"Training Loss\")\nplt.plot(epochs, val_loss, \"ro\", label=\"Validation Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\n\nplt.figure()\nacc = history.history[\"acc\"]\nval_acc = history.history[\"val_acc\"]\nplt.plot(epochs, acc, \"b\", label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, \"ro\", label=\"Validation Accuracy\")\nplt.title(\"Training and Validation Accuracies\")\nplt.legend(loc=\"lower right\")","509f5fe5":"# Final Results\nmodel.evaluate(test_ds)","b8817797":"for images, labels in test_ds.take(1):\n    pred = model.predict(images)\n    labels = np.argmax(labels, axis=-1)\n    pred = np.argmax(pred, axis=-1)\n    plt.figure(figsize=(24, 12))\n    for i in range(18):\n        plt.subplot(3, 6, i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(f\"Org: {classes[labels[i]]}\\nPred: {classes[pred[i]]}\")\n        plt.axis(\"off\")\n    plt.show()","1aaa3a3f":"# Birds Classification"}}