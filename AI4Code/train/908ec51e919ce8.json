{"cell_type":{"6cda49eb":"code","d1b6c113":"code","255292f2":"code","cc17208a":"code","ba3ca2f6":"code","39431b49":"code","9f5ab72e":"code","f309479c":"code","c9dd94f7":"markdown","c7bdf65c":"markdown","d3c84577":"markdown","6f34af7c":"markdown","6fb5cb3f":"markdown","5b9a92fe":"markdown","5848eeee":"markdown","01380a76":"markdown","82004792":"markdown","2d83b6e3":"markdown"},"source":{"6cda49eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.rcParams['axes.grid'] = True\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1b6c113":"train_before = pd.read_csv('\/kaggle\/input\/november21\/train.csv', index_col=0)\ntrain_after = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv', index_col=0)\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv', index_col=0)\nybefore = train_before.target\nyafter = train_after.target","255292f2":"plt.figure(figsize=(11,5))\nplt.xticks(np.arange(0,600000,60000))\n(ybefore-.5).cumsum().plot(label='before flip')\n(yafter-.5).cumsum().plot(label='after flip')\nplt.legend();","cc17208a":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVC\ndef fit_predict(train,test):\n    est = make_pipeline(StandardScaler(), LinearSVC(dual=False))\n    est.fit(train.drop(columns='target'), train.target)\n    return pd.Series(est.predict(test))\nplt.figure(figsize=(11,5))\nplt.xticks(np.arange(0,600000,60000))\n(fit_predict(train_before, test)-.5).cumsum().plot(label='before flip')\n(fit_predict(train_after, test)-.5).cumsum().plot(label='after flip')\nplt.legend();","ba3ca2f6":"mean_before = []\nmean_after = []\nfor start in range(0,600000,60000):\n    endx = start+60000\n    mean_before.append(ybefore[start:endx].mean())\n    mean_after.append(yafter[start:endx].mean())\nplt.xticks(np.arange(10))\nplt.scatter(np.arange(len(mean_before)), mean_before, label='before flip')\nplt.scatter(np.arange(len(mean_after)), mean_after, label='after flip')\nplt.plot(np.arange(10), [0.5]*10, linestyle='--')\nplt.xlabel('chunk')\nplt.ylabel('mean')\nplt.legend();","39431b49":"plt.scatter(mean_before, mean_after)\nplt.xlabel('mean before')\nplt.ylabel('mean after');","9f5ab72e":"flip01 = []\nflip10 = []\nfor start in range(0,600000,60000):\n    endx = start+60000\n    before = ybefore[start:endx]\n    after = yafter[start:endx]\n    flip01.append(((~before) & after).sum())\n    flip10.append((before & (~after)).sum())\ndf = pd.DataFrame(dict(\n    mean_before=mean_before, \n    mean_after=mean_after, \n    flip_0_1=flip01, \n    flip_1_0=flip10\n))\ndf.index.name = 'chunk'\ndf","f309479c":"df.plot.scatter('flip_0_1', 'mean_before');\ndf.plot.scatter('flip_1_0', 'mean_before');","c9dd94f7":"Let's take a look at the correlation between the average before flipping versus after flipping.","c7bdf65c":"The table above shows that for the flipping to be able to push the average closer to 0.5 =\n* If the average < 0.5 (label 0 is majority), then need to perform a lot of flipping of 0 into 1 (`flip_0_1`)\n* If the average > 0.5 (label 1 is majority), then need to perform a lot of flipping of 1 into 0 (`flip_1_0`)","d3c84577":"Both of them are almost linearly correlated with the initial average.","6f34af7c":"It's almost linearly correlated.\n\nHence probably we can predict the label average on the test set after the flipping too, but it's difficult to prove this.","6fb5cb3f":"As shown above, the flipping seems pushing the label average closer to **0.5**.\n\nThe further away the initial average from 0.5, it will get pushed at greater length, closer to 0.5.","5b9a92fe":"As already discussed in https:\/\/www.kaggle.com\/c\/tabular-playground-series-nov-2021\/discussion\/286731 that the label seems chunked for every 60000 rows.","5848eeee":"The predicted label of the **test** set seems chunked too for every 60000 rows, this can be observed using almost any available model (the chunk is always visible).","01380a76":"# Average\/mean on each chunk","82004792":"Let's have a closer look at the statistics of the flipping on each chunk = how many 0 flipped to 1, and vice versa","2d83b6e3":"Let's try to correlate the initial average into `flip_0_1` and `flip_1_0`."}}