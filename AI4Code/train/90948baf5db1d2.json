{"cell_type":{"3ed01d84":"code","dd4837d4":"code","76c77e13":"code","bb7b603a":"code","76ed9a52":"code","caadc889":"code","3747393f":"code","4b18271b":"code","b621e390":"code","9d9beebf":"code","6091dd28":"code","abdc4ed0":"code","5bc85919":"code","72490922":"code","d7ef260d":"code","d20de75a":"code","0d3b9bf6":"code","81eb3107":"code","499a26b1":"code","6cc2269f":"code","10c59c02":"code","e9539d72":"code","ee22b99c":"code","4e7d9ed1":"code","5f1cf250":"code","bdeec326":"code","467f90e3":"code","97a524e8":"code","591cfd05":"code","1ca7e2ec":"code","a4b041f3":"code","6ed0b4e8":"code","56105da4":"code","94c066c9":"code","64181c2e":"code","c050f6e1":"code","03cddb76":"code","c3cd0fd8":"code","376ee530":"code","d1ac4969":"code","16d8333a":"code","4feeeec8":"code","52845f71":"code","745ef059":"code","23e1df12":"code","19dcdeda":"code","2ec0289a":"code","e4bc00b7":"code","b4108e06":"code","e29c6cf8":"code","4ec20fa8":"code","8efae8bf":"code","7d475bf3":"code","7e38d4c4":"code","8d56a8e8":"code","743e73b4":"code","fd9a0cca":"code","9026b7d0":"code","b62ff579":"code","72e4776e":"code","56492a21":"code","90d9c563":"code","31b7c7b6":"code","34d7034d":"code","0da30f88":"code","8b01a7dc":"code","613b9078":"code","a8f0241a":"code","4fc3a307":"code","bb16c156":"code","0e9d3722":"code","00ec70dd":"code","50bd13e3":"code","a895246c":"code","7cdd2e43":"code","ebc3a61f":"code","8bd52f7c":"code","91ac771d":"code","ebcf4fba":"code","c5023265":"code","daad326a":"code","35f6a58a":"code","627dba6b":"code","67dab189":"code","778adb7e":"code","b067e200":"code","2e7634f0":"code","c2ce211b":"code","4366af82":"code","78d8dcb0":"code","1022852b":"code","9ab0c816":"code","a3c1c6cd":"code","5edec076":"code","b8b5aac4":"code","0d371a64":"code","8dfa2d30":"code","84539d4e":"code","7555cb1f":"code","685f32a6":"code","8c4b7114":"code","2f7b7195":"code","35e5fe92":"code","63502696":"code","e2672c5b":"code","77a0f35c":"markdown","abc92a99":"markdown","fb91f026":"markdown","2504fd1d":"markdown","72edb9cc":"markdown","72269899":"markdown","8059ef9e":"markdown","b2be8e5d":"markdown","5f85602f":"markdown","74dc7247":"markdown","152b349b":"markdown","9c64a94b":"markdown","24bdd643":"markdown","f08c371c":"markdown","be484adc":"markdown","c72516ec":"markdown","f5a6310b":"markdown","82260689":"markdown","e813242d":"markdown","7f59fef3":"markdown","b974350a":"markdown"},"source":{"3ed01d84":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom collections import Counter","dd4837d4":"df = pd.read_csv('..\/input\/fifa19\/data.csv')\ndf.head()","76c77e13":"df.dtypes","bb7b603a":"df.shape","76ed9a52":"for i, column in enumerate(df.columns):\n  print(i, column)","caadc889":"columns = [21, 26, 27]\ncolumns += range(54, 83)","3747393f":"df = df.iloc[:, columns]","4b18271b":"df.head()","b621e390":"df.isna().sum(axis = 0)","9d9beebf":"len(df)","6091dd28":"len(df.dropna())","abdc4ed0":"len(df) - len(df.dropna())","5bc85919":"df = df.dropna()","72490922":"df.isna().sum(axis = 0)","d7ef260d":"df_describe = df.describe()\ndf_describe","d20de75a":"def hist_boxplot(feature):\n  fig, ax = plt.subplots(1, 2)\n  ax[0].hist(feature)\n  ax[1].boxplot(feature)","0d3b9bf6":"df_describe.loc['min']","81eb3107":"hist_boxplot(df_describe.loc['min'])","499a26b1":"hist_boxplot(df_describe.loc['max'])","6cc2269f":"hist_boxplot(df_describe.loc['mean'])","10c59c02":"df.dtypes","e9539d72":"df.dtypes[(x not in ['int64', 'float64'] for x in df.dtypes)]","ee22b99c":"df['Height'].head()","4e7d9ed1":"df['Height'] = df['Height'].str.split('\\'')\ndf['Height']","5f1cf250":"df['Height'] = [30.48 * int(elem[0]) + 2.54 * int(elem[1]) for elem in df['Height']]\ndf['Height']","bdeec326":"hist_boxplot(df['Height'])","467f90e3":"df['Weight'].head()","97a524e8":"df['Weight'] = df['Weight'].str.split('l')\ndf['Weight']","591cfd05":"df['Weight'] = [int(elem[0]) * 0.453 for elem in df['Weight']]\ndf['Weight']","1ca7e2ec":"hist_boxplot(df['Weight'])","a4b041f3":"position = np.array(df['Position'])\nprint(position)","6ed0b4e8":"np.unique(position, return_counts=True)","56105da4":"df = df.drop(['Position'], axis=1)","94c066c9":"scaler = MinMaxScaler()\ndf_train = scaler.fit_transform(df)","64181c2e":"type(df_train)","c050f6e1":"df_train[0]","03cddb76":"wcss = []\nK = range(1, 12)\nfor k in K:\n  km = KMeans(n_clusters = k)\n  km = km.fit(df_train)\n  wcss.append(km.inertia_)","c3cd0fd8":"plt.plot(K, wcss, 'bx-')\nplt.xlabel('k')\nplt.ylabel('WCSS')\nplt.title('Elbow Method for Optimal k');","376ee530":"pca = PCA(n_components=2)\ndf_pca = pca.fit_transform(df_train)","d1ac4969":"df_pca","16d8333a":"df_train.shape","4feeeec8":"df_pca.shape","52845f71":"pca.explained_variance_ratio_","745ef059":"exp_var = [round(i, 1) for i in pca.explained_variance_ratio_ * 100]","23e1df12":"exp_var","19dcdeda":"range_n_clusters = range(2, 12)\nfor n_clusters in range_n_clusters:\n  fig, (ax1, ax2) = plt.subplots(1, 2)\n  fig.set_size_inches(18, 7)\n\n  ax1.set_xlim([-0.1, 1])\n  ax1.set_ylim([0, len(df_train) + (n_clusters + 1) * 10])\n\n  clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n  cluster_labels = clusterer.fit_predict(df_train)\n  #print(cluster_labels)\n  #print(np.unique(cluster_labels))\n\n  silhouette_avg = silhouette_score(df_train, cluster_labels)\n  print(\"For n_clusters = \", n_clusters, \" Average score: \", silhouette_avg)\n\n  sample_silhouette_values = silhouette_samples(df_train, cluster_labels)\n  #print(sample_silhouette_values)\n  #print(len(sample_silhouette_values))\n\n  y_lower = 10\n  for i in range(n_clusters):\n    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n    ith_cluster_silhouette_values.sort()\n    #print(ith_cluster_silhouette_values.shape)\n\n    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n\n    y_upper = y_lower + size_cluster_i\n    #print(y_upper)\n\n    ax1.fill_betweenx(np.arange(y_lower, y_upper), ith_cluster_silhouette_values)\n\n    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n    y_lower = y_upper + 10\n\n  ax1.set_title(\"The silhouette plot for the various clusters\")\n  ax1.set_xlabel(\"The silhouette coefficient values\")\n  ax1.set_ylabel(\"Cluster label\")   \n\n  ax1.axvline(x = silhouette_avg, color = \"red\", linestyle = \"--\")\n\n  ax1.set_yticks([])\n  ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n  colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n  ax2.scatter(df_pca[:, 0], df_pca[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')\n\n  centers = clusterer.cluster_centers_\n  centers = pca.transform(centers)\n  ax2.scatter(centers[:, 0], centers[:,1], marker='o', c='white', alpha=1, s=200, edgecolor='k')\n\n  for i, c in enumerate(centers):\n    ax2.scatter(c[0], c[1], marker='$%d$' % i, s=50, edgecolor='k')\n\n  ax2.set_title(\"The visualization of the clustered data\")\n  ax2.set_xlabel('PC1 (' + str(exp_var[0]) + '% variance explained')\n  ax2.set_ylabel('PC2 (' + str(exp_var[1]) + '% variance explained')\n\n  plt.suptitle((\"Silhouette analysis for Kmeans clustering on sample data with n_clusters = %d\" % n_clusters),\n               fontsize=14, fontweight='bold')","2ec0289a":"km = KMeans(n_clusters=4, n_init=100, random_state=0)\nkm.fit(df_train)","e4bc00b7":"print(km.cluster_centers_)","b4108e06":"print(km.labels_)","e29c6cf8":"len(km.labels_)","4ec20fa8":"len(position)","8efae8bf":"position[0]","7d475bf3":"groups = km.labels_\ncompar = []\nfor i in range(0, len(position)):\n  elem = tuple((position[i], groups[i]))\n  compar.append(elem)","7e38d4c4":"compar[0:4]","8d56a8e8":"count = Counter(compar)\ncount","743e73b4":"compar = pd.DataFrame({'Position': [i[0] for i in list(count.keys())],\n                       'Group': [i[1] for i in list(count.keys())],\n                       'N': list(count.values())})","fd9a0cca":"compar.head()","9026b7d0":"compar.shape","b62ff579":"compar = compar.sort_values(['Position', 'Group'])\ncompar.head()","72e4776e":"compar_perc = pd.DataFrame()\npos = compar['Position'].unique()\npos","56492a21":"compar[compar['Position'] == 'CAM']","90d9c563":"sum(compar[compar['Position'] == 'CAM']['N'])","31b7c7b6":"for p in pos:\n  compar_p = compar[compar['Position'] == p]\n  sum_N = sum(compar_p['N'])\n  compar_p['N'] = compar_p['N'] \/ sum_N\n  compar_perc = compar_perc.append(compar_p)\ncompar_perc = compar_perc.sort_values(['Group', 'N', 'Position'])","34d7034d":"compar_perc.head()","0da30f88":"compar_perc.tail()","8b01a7dc":"compar_perc_barplot = pd.DataFrame({'Position': sum([[elem] * 4 for elem in np.unique(position)], []),\n                                    'Group': sum([['0', '1', '2', '3'] * len(np.unique(position))], []),\n                                    'N': [0] * 4 * len(np.unique(position))})","613b9078":"compar_perc_barplot.head(8)","a8f0241a":"compar_perc_barplot.tail(8)","4fc3a307":"len(compar_perc_barplot)","bb16c156":"for row in range(0, len(compar_perc_barplot)):\n  pos = compar_perc_barplot.iloc[row, 0]\n  gro = int(compar_perc_barplot.iloc[row, 1])\n  reg = compar_perc.loc[(compar_perc['Position'] == pos) & (compar_perc['Group'] == gro), :]\n  if len(reg) > 0:\n    compar_perc_barplot.iloc[row, 2] = reg['N'].values","0e9d3722":"compar_perc_barplot.head(8)","00ec70dd":"compar_perc_barplot.tail(8)","50bd13e3":"p0 = plt.bar(compar_perc_barplot['Position'][compar_perc_barplot['Group'] == '0'],\n             compar_perc_barplot['N'][compar_perc_barplot['Group'] == '0'], color = 'b')\np1 = plt.bar(compar_perc_barplot['Position'][compar_perc_barplot['Group'] == '1'],\n             compar_perc_barplot['N'][compar_perc_barplot['Group'] == '1'], color = 'r',\n             bottom = np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '0']))\np2 = plt.bar(compar_perc_barplot['Position'][compar_perc_barplot['Group'] == '2'],\n             compar_perc_barplot['N'][compar_perc_barplot['Group'] == '2'], color = 'y',\n             bottom = np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '0']) + \n                      np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '1']))\np3 = plt.bar(compar_perc_barplot['Position'][compar_perc_barplot['Group'] == '3'],\n             compar_perc_barplot['N'][compar_perc_barplot['Group'] == '3'], color = 'g',\n             bottom = np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '0']) + \n                      np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '1']) +\n                      np.array(compar_perc_barplot['N'][compar_perc_barplot['Group'] == '2']))\nplt.xticks(rotation = 90)\nplt.axhline(0.5, color = 'black', linestyle='--')\nplt.legend((p0[0], p1[0], p2[0], p3[0]), ('Group 0', 'Group 1', 'Group 2', 'Group 3'))","a895246c":"counter1 = Counter(compar_perc[compar_perc['N'] >= 0.5]['Group'])\ncounter1","7cdd2e43":"counter1 = dict(sorted(counter1.items(), key = lambda x: x[0]))\ncounter1","ebc3a61f":"x = [str(elem) for elem in list(counter1.keys())]\nx","8bd52f7c":"p1 = plt.bar(x, counter1.values())\ncounter2 = Counter(compar_perc[compar_perc['N'] < 0.5]['Group'])\ncounter2 = dict(sorted(counter2.items(), key = lambda x: x[0]))\nx = [str(elem) for elem in list(counter2.keys())]\n\np2 = plt.bar(x, counter2.values(), bottom=list(counter1.values()))\nplt.title('Number of positions designated to each group')\nplt.xlabel('Group')\nplt.ylabel('Number of positions')\nplt.legend((p1[0], p2[0]), ('Proportion >= 0.5', 'Proportion < 0.5'))","91ac771d":"for i in range(4):\n  g = compar_perc[(compar_perc['Group'] == i) & (compar_perc['N'] >= 0.5)][['Position', 'N']]\n  g = g.sort_values(by = 'N')\n  plt.barh(g['Position'], g['N'])\n  plt.axvline(0.5, color = 'r', linestyle = '--')\n  plt.title('Positions best associated with Group ' + str(i))\n  plt.show()","ebcf4fba":"rfc = RandomForestClassifier()\nrfc.fit(df_train, groups)","c5023265":"importances = rfc.feature_importances_\nimportances","daad326a":"features = df.columns\nfeatures","35f6a58a":"df_imp = pd.DataFrame({'Features': features, 'Importance': importances})\ndf_imp.head()","627dba6b":"df_imp = df_imp.sort_values(by = 'Importance', ascending = False)\ndf_imp.head()","67dab189":"df_imp.tail()","778adb7e":"df_imp['Sum Importance'] = df_imp['Importance'].cumsum()\ndf_imp = df_imp.sort_values(by = 'Importance')\ndf_imp.head()","b067e200":"df_imp.tail()","2e7634f0":"plt.figure(figsize=(8,8))\nplt.barh(df_imp['Features'], df_imp['Importance'])\nl1 = plt.axhline(len(df_imp) - (len(df_imp['Features'][df_imp['Sum Importance'] < 0.50]) + 1.5), linestyle='-.', color = 'r')\nl2 = plt.axhline(len(df_imp) - (len(df_imp['Features'][df_imp['Sum Importance'] < 0.90]) + 1.5), linestyle='--', color = 'r')\nl3 = plt.axhline(len(df_imp) - (len(df_imp['Features'][df_imp['Sum Importance'] < 0.99]) + 1.5), linestyle='-', color = 'r')\nplt.legend(title = 'Cut-offs of acumulated importance', handles=(l1, l2, l3), labels = ('50%', '90%', '99%'))\nplt.title('Feature importance in group assignment')","c2ce211b":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix","4366af82":"X_train, X_test, y_train, y_test = train_test_split(df_train, groups, test_size = 0.2)","78d8dcb0":"X_train.shape","1022852b":"y_train.shape","9ab0c816":"X_test.shape","a3c1c6cd":"y_test.shape","5edec076":"import seaborn as sns\nsns.countplot(y_train)","b8b5aac4":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","0d371a64":"predictions = rfc.predict(X_test)\npredictions","8dfa2d30":"accuracy_score(predictions, y_test)","84539d4e":"cm = confusion_matrix(predictions, y_test)\ncm","7555cb1f":"!pip install yellowbrick --upgrade","685f32a6":"from yellowbrick.classifier import ConfusionMatrix\nconfusion_matrix = ConfusionMatrix(rfc)\nconfusion_matrix.fit(X_train, y_train)\nconfusion_matrix.score(X_test, y_test)\nconfusion_matrix.show();","8c4b7114":"new = X_test[0]\nnew","2f7b7195":"new.shape","35e5fe92":"new = new.reshape(1, -1)\nnew.shape","63502696":"rfc.predict(new)","e2672c5b":"rfc.predict_proba(new)","77a0f35c":"## Attributes selection with Random Forest","abc92a99":"## Classification with Random Forest","fb91f026":"### Implementing and evaluating","2504fd1d":"### Choosing final number of clusters ","72edb9cc":"### Dimensionality reduction","72269899":"## Getting to know the dataset","8059ef9e":"Deleting all NaN values as the amount is very low compared to the full dataset:","b2be8e5d":"## Clustering","5f85602f":"Code based on: https:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_silhouette_analysis.html","74dc7247":"### Missing Values","152b349b":"### Players' Weight","9c64a94b":"# FIFA 2019 Players Data Analysis and Clustering","24bdd643":"## Importing Packages","f08c371c":"### Players' Heights","be484adc":"## Visualizations","c72516ec":"## Data Preparation","f5a6310b":"### Choosing number of clusters","82260689":"## Evaluation - relationship between groups and positions","e813242d":"## K-means algorithm implementation","7f59fef3":"### Prediction for one player","b974350a":"## Cleaning the Dataset"}}