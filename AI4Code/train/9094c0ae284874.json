{"cell_type":{"d0b553f0":"code","477554ff":"code","55a07465":"code","e02f7df5":"code","d3164154":"code","4192cf68":"code","e8289b83":"code","9cd15a16":"code","2ee72fae":"code","3706e693":"code","9583fea3":"code","661bec92":"code","99ba0ba5":"code","78111e9c":"code","1f72845c":"code","2b6c4115":"code","ca3ff484":"code","e17473f9":"code","4207fffc":"code","16ac6cfa":"markdown"},"source":{"d0b553f0":"!pip install wwf timm -qqq","477554ff":"!pip install --upgrade fastai","55a07465":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\nimport random\nimport torch\nimport torchvision\nfrom torchvision import transforms\nimport albumentations as A\nfrom fastai.vision.all import *\nfrom fastai import *\nfrom wwf.vision.timm import *\nimport timm","e02f7df5":"def set_seed(seed=42):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)","d3164154":"set_seed()","4192cf68":"class CFG:\n    model = 'resnext101_32x8d' #Taken ViT, Place your model here!\n    train_bs = 16\n    valid_bs = 32\n    image_size = 224\n    tta = 5\n    epochs = 10\n    lr = 1e-3\n    fp16 = True\n    fp32 = True\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","e8289b83":"train_df = pd.read_csv('..\/input\/happy-whale-and-dolphin\/train.csv')\ntrain_df.head()","9cd15a16":"train_df['species'].value_counts()","2ee72fae":"DIR = \"..\/input\/happy-whale-and-dolphin\/train_images\"\nimage_path = f'{DIR}\/00103cbe9d25ce.jpg'","3706e693":"random_img = cv2.imread(image_path)\nplt.imshow(random_img)","9583fea3":"# Thanks to https:\/\/www.kaggle.com\/khoongweihao\/insect-augmentation-et-al\nalbumentation_list = [A.RandomSunFlare(p=1), \n                      A.RandomFog(p=1), \n                      A.RandomBrightness(p=1),\n                      A.RandomCrop(p=1,height = 512, width = 512), \n                      A.Rotate(p=1, limit=90),\n                      A.RGBShift(p=1), \n                      A.RandomSnow(p=1),\n                      A.HorizontalFlip(p=1), \n                      A.VerticalFlip(p=1), \n                      A.RandomContrast(limit = 0.5,p = 1),\n                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                      A.Cutout(p=1),\n                      A.Transpose(p=1), \n                      A.JpegCompression(p=1),\n                      A.CoarseDropout(p=1),\n                      A.IAAAdditiveGaussianNoise(loc=0, scale=(2.5500000000000003, 12.75), per_channel=False, p=1),\n                      A.IAAAffine(scale=1.0, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', p=1),\n                      A.IAAAffine(rotate=90., p=1),\n                      A.IAAAffine(rotate=180., p=1)]","661bec92":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = random_img)['image']\n    img_matrix_list.append(img)\n\nimg_matrix_list.insert(0,random_img)    \n\ntitles_list = [\"Original\",\"RandomSunFlare\",\"RandomFog\",\"RandomBrightness\",\n               \"RandomCrop\",\"Rotate\", \"RGBShift\", \"RandomSnow\",\"HorizontalFlip\", \"VerticalFlip\", \"RandomContrast\",\"HSV\",\n               \"Cutout\",\"Transpose\",\"JpegCompression\",\"CoarseDropout\",\"IAAAdditiveGaussianNoise\",\"IAAAffine\",\"IAAAffineRotate90\",\"IAAAffineRotate180\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, nrows=5,  main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=nrows, ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title=\"Different Types of Augmentations with Albumentations\")","99ba0ba5":"path = Path('..\/input\/happy-whale-and-dolphin')","78111e9c":"def get_x(x): return str(path\/'train_images') + os.path.sep + x['image']\ndef get_y(y): return y['species']","1f72845c":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)","2b6c4115":"def get_train_aug(sz): return A.Compose([\n                A.Transpose(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n                ),\n                A.RandomSnow(p=1),\n                A.HorizontalFlip(p=1), \n                A.VerticalFlip(p=1), \n                A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n                ),\n               A.CoarseDropout(p=0.9),\n               A.Cutout(p=0.5)\n])\n\ndef get_valid_aug(sz): return A.Compose([\n    A.Resize(sz,sz)\n], p=1.)","ca3ff484":"def get_dls(sz):\n    item_tfms = AlbumentationsTransform(get_train_aug(sz), get_valid_aug(sz))\n    WhaleBlock = DataBlock(\n    blocks = (ImageBlock, CategoryBlock),\n    splitter = RandomSplitter(valid_pct=0.2),\n    get_x=get_x,\n    get_y=get_y,\n    item_tfms=item_tfms,\n    batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)]\n     )\n    \n    return WhaleBlock","e17473f9":"block = get_dls(512)","4207fffc":"dls = block.dataloaders(train_df, batch_size=CFG.train_bs)\ndls.valid.show_batch(max_n=8, nrows=2)","16ac6cfa":"### Work In Progress :)"}}