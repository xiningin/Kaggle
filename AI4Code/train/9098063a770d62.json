{"cell_type":{"5d5bf535":"code","c4669fc5":"code","d18c40c7":"code","c3933e5c":"code","a90b3c97":"code","251c6048":"code","fbe57af2":"code","9b030d46":"code","eeff2d02":"code","9d843d23":"code","c539daed":"code","12d81c6f":"code","8e327486":"code","7ac39ef4":"code","ea06188f":"code","c01b6bf5":"markdown","31f271cf":"markdown","824cede3":"markdown","9b1c3dea":"markdown","ea785d80":"markdown","182957df":"markdown","4ad3d0ec":"markdown","2dfe9025":"markdown","f3cdca12":"markdown","74390a4f":"markdown","bbf50038":"markdown","cceadd15":"markdown","08ea8159":"markdown","ca6a7911":"markdown"},"source":{"5d5bf535":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport time\nfrom IPython import display\nfrom keras.layers import LeakyReLU\nimport os\nimport numpy as np\n\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import vstack\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom matplotlib import pyplot\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n","c4669fc5":"!pip install wget","d18c40c7":"import wget","c3933e5c":"!mkdir dataset_zip\n!mkdir dataset_unzip\n!mkdir dataset_unzip\/img\n!mkdir generated_img","a90b3c97":"url = \"https:\/\/storage.googleapis.com\/kaggle-data-sets\/854710\/1457725\/compressed\/portrait.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211117%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211117T143902Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=6f105d09823f9a36ded16aec5bb4f4b84ea162dc1456307dadad4d7dd67657c1da0629e01243ddb75d78b57b31d80e0c285dfc848e5411ae899eb5258dac6ff556a07f163a37cb5ac19d57e9ba0d81def2810203f1557b379e95f8b136679fbf204eee81c3aa38107408c2aa7b0d3b103fc5bfc4e84363be9291b94c809b4614ae4a5aa072a5ff904c4437ac09e4912e185f48cc8805ceaab798eba8632052d9c5ffcfcfe90d1b0903f744df6f17df06a1e7f2f1eb015476d6b3b1c9fc7db2cf0f031ac734d3fc2ae64a37b9840db3473ee97b182c16c1eec6a374c3e5c5f0b9edc82b40d5240143c50b4cfeb17c6a28b427a9274ffd0198fe9de5d2906b7143\"\nwget.download(url, 'dataset_zip\/')","251c6048":"!unzip dataset_zip\/portrait.zip -d dataset_unzip\/img\/","fbe57af2":"from struct import unpack\nfrom tqdm import tqdm\nimport os\n\n\nmarker_mapping = {\n    0xffd8: \"Start of Image\",\n    0xffe0: \"Application Default Header\",\n    0xffdb: \"Quantization Table\",\n    0xffc0: \"Start of Frame\",\n    0xffc4: \"Define Huffman Table\",\n    0xffda: \"Start of Scan\",\n    0xffd9: \"End of Image\"\n}\n\n\nclass JPEG:\n    def __init__(self, image_file):\n        with open(image_file, 'rb') as f:\n            self.img_data = f.read()\n    \n    def decode(self):\n        data = self.img_data\n        while(True):\n            marker, = unpack(\">H\", data[0:2])\n            # print(marker_mapping.get(marker))\n            if marker == 0xffd8:\n                data = data[2:]\n            elif marker == 0xffd9:\n                return\n            elif marker == 0xffda:\n                data = data[-2:]\n            else:\n                lenchunk, = unpack(\">H\", data[2:4])\n                data = data[2+lenchunk:]            \n            if len(data)==0:\n                raise TypeError(\"issue reading jpeg file\")           \n\n\nbads = []\nimg_dir = \"dataset_unzip\/img\/\"\n\nfor dirName, subdirList, fileList in os.walk(img_dir):\n    imagesList = fileList\n    for img in tqdm(imagesList):\n        image = os.path.join(img_dir,img)\n        image = JPEG(image) \n        try:\n            image.decode()   \n        except:\n            bads.append(img)\n\n\nfor name in bads:\n    os.remove(os.path.join(img_dir,name))","9b030d46":"BUFFER_SIZE = 15000\nBATCH_SIZE = 128\nimage_size = (64,64)\n\ndef load_real_samples(batch_size, image_size, BUFFER_SIZE):\n    data_dir = \"dataset_unzip\/\"\n    train_ds = image_dataset_from_directory(directory=data_dir, image_size=image_size, batch_size=batch_size)\n\n    X_batch_arr = []\n    X_batch_arr_list = []\n    for images, labels in train_ds:\n        X_batch = images.numpy().astype(\"float32\")\n        X_batch = (X_batch - 127.5) \/ 127.5  # Normalize the images to [-1, 1]\n        X_batch_arr.append(X_batch)\n    for X_batch in X_batch_arr:\n        for image in X_batch:\n            X_batch_arr_list.append(image)\n    dataset = tf.data.Dataset.from_tensor_slices(X_batch_arr_list).shuffle(buffer_size=BUFFER_SIZE)  # (shuffle => repeat => batch)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1) # prefech (add in cache x batch during processing an other one) \n\n    return dataset\n\ndataset = load_real_samples(BATCH_SIZE, image_size, BUFFER_SIZE)","eeff2d02":"for batch in dataset:\n    plt.figure(figsize=(10, 10))\n    for i in range (4*4):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(batch[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n    break\n\nplt.show()","9d843d23":"def define_generator(noise_dim):\n    model = Sequential()\n    # foundation for 4x4 image\n    n_nodes = 512 * 4 * 4\n    model.add(Dense(n_nodes, input_dim=noise_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization())\n    model.add(Reshape((4, 4, 512)))\n    # 8x8\n    model.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization())\n    # 16x16\n    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization())\n    # 32x32\n    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization())\n    # 64x64\n    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization())\n    # output layer\n    model.add(Conv2D(3, kernel_size=4, activation='tanh', padding='same'))\n    return model","c539daed":"def define_discriminator(in_shape=(64,64,3)):\n    model = Sequential()\n    # 64x64\n    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', use_bias=False, input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    # 32x32\n    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.2))\n    # 16x16\n    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.2))\n    # 8x8\n    model.add(Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.2))\n    # 4x4\n    model.add(Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.2))\n    # 1x1\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","12d81c6f":"def define_gan(g_model, d_model):\n    # make weights in the discriminator not trainable\n    d_model.trainable = False\n    model = Sequential([g_model, d_model])\n    # compile model\n    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model","8e327486":"noise_dim = 100\nEPOCHS = 200\n\n# Generate images based just on noise\ndef generation_images(BATCH_SIZE, noise_dim, generator):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    generated_image = generator(noise, training=True)\n    return generated_image\n\n# Save and plot images\ndef generate_and_save_images(static_noise, epoch, generator):\n  generated_images = generator(static_noise, training=False)\n  plt.figure(figsize=(10, 10))\n\n  for i in range (6*6):\n      plt.subplot(6, 6, i+1)\n      plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('generated_img\/image_at_epoch_{:04d}.png'.format(epoch+1))\n  plt.show()\n\n\ndef train_model(EPOCHS, BATCH_SIZE, dataset, noise_dim, static_noise, model):\n    generator, discriminator = model.layers\n\n    for epoch in range(EPOCHS):\n        print(f\"Currently on Epoch {epoch+1}\")\n        i = 0\n        # For every batch in the dataset\n        for X_batch in dataset:\n            i=i+1\n                \n            ###### TRAINING THE DISCRIMINATOR \n\n            # Generate images based just on noise input\n            gen_images = generation_images(BATCH_SIZE, noise_dim, generator)\n\n            # Concatenate Generated Images against the Real Ones\n            X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch,tf.float32)], axis=0)\n\n            # Set to zero for fake images and 0.9 for real images\n            y1 = tf.constant([[0.]] * BATCH_SIZE + [[0.9]] * BATCH_SIZE)\n\n            # Train the discriminator on this batch\n            d_loss = discriminator.train_on_batch(X_fake_vs_real, y1)\n\n            ###### TRAINING THE GENERATOR\n\n            # Create some noise\n            noise = tf.random.normal(shape=[BATCH_SIZE, noise_dim])\n\n            # We want discriminator to believe that fake images are real\n            y2 = tf.constant([[1.]] * BATCH_SIZE)\n\n            g_loss = model.train_on_batch(noise, y2)\n   \n        # save image every 5 epochs\n        if (epoch+1) % 2 == 0:\n            print(f'\\t Discriminator Loss: {d_loss} \\t\\t Generator Loss: {g_loss}')\n            generate_and_save_images(static_noise, epoch, generator)\n        # Save model every 50 epochs\n        if (epoch+1) % 50 == 0:\n            filename = 'model\/generator_cars_model_%03d.h5' % (epoch+1)\n            generator.save(filename)\n\n# create the discriminator\nd_model = define_discriminator()\n# create the generator\ng_model = define_generator(noise_dim)\n# create the gan\ngan_model = define_gan(g_model, d_model)\n# load data \n#dataset = load_real_samples(BATCH_SIZE, image_size)\n# static noise\nstatic_noise = tf.random.normal([BATCH_SIZE, noise_dim])\n# train model\ntrain_model(EPOCHS, BATCH_SIZE, dataset, noise_dim, static_noise, gan_model)","7ac39ef4":"!pip install -q git+https:\/\/github.com\/tensorflow\/docs \nimport tensorflow_docs.vis.embed as embed","ea06188f":"anim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('generated_img\/image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n    \n    \nembed.embed_file(anim_file)","c01b6bf5":"# IMPORT","31f271cf":"Plot some images","824cede3":"Create keras dataset","9b1c3dea":"Delete corrupted images","ea785d80":"Combine both of the models","182957df":"# DATA","4ad3d0ec":"Create the discriminator","2dfe9025":"Train the model","f3cdca12":"Download the data","74390a4f":"Unzip the folder","bbf50038":"Create the generator","cceadd15":"# Create GIF","08ea8159":"Create directories to save the input data, the images generated and the model","ca6a7911":"# MODEL"}}