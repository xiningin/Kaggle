{"cell_type":{"d796e802":"code","ca7e24a1":"code","299a99b6":"code","215ecd71":"code","db8c56b9":"code","d03821fc":"code","89e05db3":"code","fc98c80f":"code","89346955":"code","c7963f8e":"code","efdf0907":"code","17fd82d2":"code","7ea2c9e8":"code","93d38a04":"code","21edcf14":"code","9f1d7d3b":"code","f4babab1":"code","6d5da422":"code","41a1565c":"code","86a07cd9":"code","e291ac68":"code","63eb2ba3":"code","059071b4":"code","78c9b76f":"code","94979884":"code","3510e655":"code","acf8f449":"code","2ee6e3e0":"code","0cfe84d9":"code","66b3ec02":"code","743cd6ab":"code","beda8b4c":"code","f539ea6e":"code","9e4b3e84":"code","84e93c18":"code","9cfb78a5":"code","e7c2f8f9":"code","33e5bc57":"code","52d43aa0":"code","fa3319f3":"code","4189b22c":"code","be2f5e68":"code","19dda9e2":"markdown","e868b309":"markdown","2cbde1f8":"markdown","714fe158":"markdown","69ba9ccf":"markdown","5a47cc11":"markdown"},"source":{"d796e802":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as ptl\nimport pandas_profiling as pdp\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import model_selection\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import ensemble\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ca7e24a1":"df= pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv')\ntest.head()","299a99b6":"pdp.ProfileReport(df)","215ecd71":"for i in df.columns:\n    print (df[i].value_counts())","db8c56b9":"for i in test.columns:\n    print (test[i].value_counts())","d03821fc":"\ndf['cat0'].value_counts()","89e05db3":"df.shape","fc98c80f":"cat_map ={ 'A':0,\n      'B':1,\n      'C':2,\n      'D':3,\n      'E':4,\n      'F':5,\n      'G':6,\n      'H':7,\n      'I':8,\n      'J':9,\n      'K':10,\n      'L':11,\n      'M':12,\n      'N':13,\n      'O':14,\n      'P':15,\n      'Q':16,\n      'R':17,\n      'S':18,\n      'T':19,\n      'U':20,\n      'V':21,\n      'W':22,\n      'X':23,\n      'Y':24,\n      'Z':25,\n      '': 26\n    \n}\n","89346955":"df['cat5_1']=df.cat5.str.slice(start=1)","c7963f8e":"df['cat5_2']=df.cat5.str.slice(stop=1)","efdf0907":"df['cat5_1'].head()","17fd82d2":"df['cat5_1'].value_counts()","7ea2c9e8":"df['cat5_2'].value_counts()","93d38a04":"df['cat7_1']=df.cat7.str.slice(start=1)\ndf['cat7_2']=df.cat7.str.slice(stop=1)\ndf['cat7_1'].value_counts()","21edcf14":"display(df['cat7_2'].value_counts())","9f1d7d3b":"df['cat8_1']=df.cat8.str.slice(start=1)\ndf['cat8_2']=df.cat8.str.slice(stop=1)\ndf['cat8_1'].value_counts()","f4babab1":"df['cat8_2'].value_counts()","6d5da422":"df['cat10_1']=df.cat10.str.slice(start=1)\ndf['cat10_2']=df.cat10.str.slice(stop=1)\ndf['cat10_1'].value_counts()","41a1565c":"df['cat10_2'].value_counts()","86a07cd9":"df.columns","e291ac68":"cat_features=[ 'cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5_1', 'cat5_2', 'cat6', 'cat7_1', 'cat7_2',\n       'cat8_1', 'cat8_2', 'cat9', 'cat10_1','cat10_2', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15','cat16', 'cat17', 'cat18']","63eb2ba3":"for i in cat_features:\n    df.loc[:,i]= df[i].map(cat_map)","059071b4":"for i in cat_features:\n    print (df[i].value_counts())","78c9b76f":"df['cat8_2'].head()","94979884":"df.head()","3510e655":"drop_col=['cat5','cat7','cat8','cat10']\nfor i in drop_col:\n    df.drop","acf8f449":"df['target'].value_counts()","2ee6e3e0":"df[\"kfold\"] = -1\n# the next step is to randomize the rows of the data\ndf = df.sample(frac=1).reset_index(drop=True)\n# fetch targets\ny = df['target'].values\n# initiate the kfold class from model_selection module\nkf = model_selection.StratifiedKFold(n_splits=10)\n# fill the new kfold column\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n# save the new csv with kfold column\ndf.to_csv(\"train_folds.csv\", index=False)","0cfe84d9":"df.head()","66b3ec02":"df_train= df[df.kfold < 9]\ndf_test= df[df.kfold == 9]","743cd6ab":"df.columns","beda8b4c":"test.columns","f539ea6e":"features=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat6', 'cat9', 'cat11', 'cat12', 'cat13',\n    'cat14', 'cat15',\n      'cat16', 'cat17', 'cat18', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4',\n       'cont5', 'cont6', 'cont7', 'cont8', 'cont9','cont10',\n       'cat5_1', 'cat5_2', 'cat7_1', 'cat7_2', 'cat8_1', 'cat8_2', 'cat10_1',\n       'cat10_2']","9e4b3e84":"X=df_train[features]\ny=df_train['target'].values\nX_test=df_test[features]\ny_test=df_test['target'].values","84e93c18":"print(y)","9cfb78a5":"model= XGBClassifier(random_state=0,tree_method='gpu_hist',booster= 'gbtree',objective= 'binary:logistic',eval_metric= 'auc',predictor= 'gpu_predictor',learning_rate= 0.055259617966271525, max_depth= 17,gpu_id= 0,subsample= 0.8558107221838249,n_estimators= 552,min_child_weight= 115.85158439509448,colsample_bytree= 0.25704795929046986,reg_alpha= 0.16085318169229096,gamma=0.1378721352250649,max_delta_step=2.2855102006362893,colsample_bylevel= 0.7567272708177056,colsample_bynode= 0.9449337223213273)\nmodel.fit(X,y)","e7c2f8f9":"prediction=model.predict_proba(X_test)[:,1]\nrmse=roc_auc_score(y_test, prediction)\nprint(rmse)","33e5bc57":"print(prediction)","52d43aa0":"test['cat5_1']=test.cat5.str.slice(start=1)\ntest['cat5_2']=test.cat5.str.slice(stop=1)\n\ntest['cat7_1']=test.cat7.str.slice(start=1)\ntest['cat7_2']=test.cat7.str.slice(stop=1)\n\ntest['cat8_1']=test.cat8.str.slice(start=1)\ntest['cat8_2']=test.cat8.str.slice(stop=1)\n\ntest['cat10_1']=test.cat10.str.slice(start=1)\ntest['cat10_2']=test.cat10.str.slice(stop=1)\ntest['cat10_1'].value_counts()","fa3319f3":"for i in cat_features:\n    test.loc[:,i]= test[i].map(cat_map)","4189b22c":"for i in cat_features:\n    print(test[i].value_counts())","be2f5e68":"X_sub =test[features]\npredictions= model.predict_proba(X_sub)[:,1]\n\nsub_df=pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsub_df.head()\nID=sub_df['id']\nsubmission = pd.DataFrame({'id': ID, 'target': predictions})\nsubmission.to_csv('submissionCats.csv', index = False)","19dda9e2":"# Semi-AutoEDA and data wrangling","e868b309":"# Libraries","2cbde1f8":"# Introduction\nWe are playing with kaggle's competition that enables us to learn the nuts and bolts of machine learning.In this notebook we are mainly focusing on categorical features.This dataset has 30 features and 1 target.In which 19 features are categorical and 11 of them are numerical features.We will not incorporate any scikit-learn incodindg we will use manual encoding for the preprocessing.\n\n**What is Categorical features and why we need to care bout them?**\n\nCategorical features are the features that includes only a limited and fixed values.Categorical variables represent types of data which may be divided into groups. Examples of categorical variables are race, sex, age group, and educational level.Machine learning models require all input and output variables to be numeric.\nThis means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model.Encoding is a required pre-processing step when working with categorical data for machine learning algorithms.\n","714fe158":"# Till now I done a little bit model tuning so we can expect some more accuracy in roc_auc_score.Please consider upvoting if you like it. Feel free to give suggetions","69ba9ccf":"**As we can see that the target is skewed.And if we use random data to fit in the model we may end up with a biased model.So in order to deal with this problem it is required to incorporate stratified cross-validation technique. So let's go and watch the implementation.**","5a47cc11":"# Observations\n\nSo we got some insight such as\n* Dataset don't have missing values in the datasets.\n* There are 4 columns that are even tricky they have combination of 2 letters and 1 letters values.They are cat5,cat7,cat8 and cat10.\n* Mainly we are dealing with values in range (A-Z) values so and for our tricky features we also need to a value for missing values.\n* We are going to split cat5,cat7,cat8 nad cat10 in two columns each.So that we can extract helpful information out of these columns."}}