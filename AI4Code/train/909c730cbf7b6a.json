{"cell_type":{"84697118":"code","dc13aa68":"code","0e8e0616":"code","c282bd06":"code","16bf1be5":"code","55bc2b62":"code","a009ea68":"code","a49bc5af":"code","303f9f5d":"code","b7cb744f":"code","128f24fb":"code","c81babbf":"code","ee098d0e":"code","dac8acc8":"code","3c1db825":"code","e924ea62":"code","de0a8f5e":"code","71e7e77d":"code","4b4179be":"code","bf39b7a0":"code","3279f62a":"code","30672205":"code","c7720bd8":"code","4881efbb":"code","10c4304a":"code","fff39ec4":"code","5f9bd77e":"code","13bc19e0":"code","6e7fc52d":"code","e92f19ad":"code","5de0da33":"code","2a37dca1":"code","87ff53ce":"code","8e7911cf":"code","964b352c":"code","1bde60b3":"code","c13875f9":"code","60f2211d":"code","a1627138":"code","99a7efc0":"code","bfbb6d71":"code","434d50c3":"code","16b699da":"code","d8573472":"code","0a43e8b0":"code","7c6eff42":"code","6569004d":"code","d33174ad":"markdown","15438ecb":"markdown","84404b50":"markdown","48b9b272":"markdown","921b4e2e":"markdown","d723ce4d":"markdown","f3031a59":"markdown","ce51fcee":"markdown","e0e95aa3":"markdown","0a5be583":"markdown","f753de3b":"markdown","5a6b28d1":"markdown","4dcb305b":"markdown","0f8c1f71":"markdown","1e6d65fd":"markdown","7eec3078":"markdown","70887a65":"markdown","6bc9e3f1":"markdown","a32651ab":"markdown","7ea92906":"markdown","fcb01df5":"markdown","7579b2f3":"markdown"},"source":{"84697118":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dc13aa68":"data = pd.read_csv('\/kaggle\/input\/gender-classification-dataset\/gender_classification_v7.csv')\nprint(data.shape)\ndata.head()","0e8e0616":"data.info()","c282bd06":"data.describe()","16bf1be5":"data.describe(include='object')","55bc2b62":"df = data.copy()\ndf['gender'] = df.gender.replace({0:'Male',1:'Female'}).astype('object')\ndf_male = df[df['gender'] == 'Male']\ndf_female = df[df['gender'] == 'Female']","a009ea68":"data['gender'].value_counts()","a49bc5af":"colors=('#063EBA','#85BA06')\nexplode=[0,0.1]\ndata['gender'].value_counts().plot(kind='pie',shadow=True,explode=explode,colors=colors,autopct='%.2f',figsize=(8,6))\nplt.title('Ratio of gender')\nplt.show()","303f9f5d":"sns.heatmap(data.corr(),annot=True)","b7cb744f":"sns.distplot(df_male['forehead_width_cm'],label='Male')\nsns.distplot(df_female['forehead_width_cm'],label='Female')\nplt.legend()","128f24fb":"sns.distplot(df_male['forehead_height_cm'],label='Male')\nsns.distplot(df_female['forehead_height_cm'],label='Female')\nplt.legend()","c81babbf":"sns.scatterplot(x='forehead_width_cm',y='forehead_height_cm',hue='gender',data=data)","ee098d0e":"plt.title('count of Long Hair colored by gender')\nsns.countplot(data=data,x='long_hair',hue='gender')","dac8acc8":"plt.title('count of Nose Wide colored by gender')\nsns.countplot(data=data,x='nose_wide',hue='gender')","3c1db825":"plt.title('count of Nose Long colored by gender')\nsns.countplot(data=data,x='nose_long',hue='gender')","e924ea62":"plt.title('count of Lips Thin colored by gender')\nsns.countplot(data=data,x='lips_thin',hue='gender')","de0a8f5e":"plt.title('count of distance Nose to Lip long colored by gender')\nsns.countplot(data=data,x='distance_nose_to_lip_long',hue='gender')","71e7e77d":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder() \n\ndata['gender'] = label_encoder.fit_transform(data['gender'])\ndata['long_hair'] = label_encoder.fit_transform(data['long_hair'])\ndata['nose_wide'] = label_encoder.fit_transform(data['nose_wide'])\ndata['nose_long'] = label_encoder.fit_transform(data['nose_long'])\ndata['lips_thin'] = label_encoder.fit_transform(data['lips_thin'])\ndata['distance_nose_to_lip_long'] = label_encoder.fit_transform(data['distance_nose_to_lip_long'])\ndata.head()","4b4179be":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nstd_col = ['forehead_width_cm','forehead_height_cm']\ndata[std_col] = scaler.fit_transform(data[std_col])\ndata.head()","bf39b7a0":"features = data.drop('gender',axis=1)\ntarget = data['gender']","3279f62a":"cols = features.columns","30672205":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nfeatures = scaler.fit_transform(features)\nfeatures = pd.DataFrame(features,columns=[cols])\nfeatures.head()","c7720bd8":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.2,random_state=0)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","4881efbb":"from sklearn.metrics import accuracy_score,recall_score,precision_score\nfrom sklearn.metrics import f1_score,confusion_matrix,roc_auc_score\n\ndef evaluation(y_test,y_pred):\n  acc = accuracy_score(y_test,y_pred)\n  rcl = recall_score(y_test,y_pred)\n  f1 = f1_score(y_test,y_pred)\n  auc_score = roc_auc_score(y_test,y_pred)\n  prec_score = precision_score(y_test,y_pred)\n \n\n  metric_dict={'accuracy': round(acc,3),\n               'recall': round(rcl,3),\n               'F1 score': round(f1,3),\n               'auc score': round(auc_score,3),\n               'precision': round(prec_score,3) \n              }\n\n  return print(metric_dict)","10c4304a":"Results = pd.DataFrame({'Model': [],'Accuracy Score': [], 'Recall':[], 'F1score':[]})","fff39ec4":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train,y_train)\ny_pred1 = tree.predict(X_test)\nres = pd.DataFrame({\"Model\":['DecisionTreeClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred1,y_test)],\n                    \"Recall\": [recall_score(y_test,y_pred1)],\n                    \"F1score\": [f1_score(y_test,y_pred1)]})\nResults = Results.append(res)","5f9bd77e":"pd.crosstab(y_test,y_pred1,rownames=['Real data'],colnames=['Predicted'])","13bc19e0":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\ny_pred2 = rfc.predict(X_test)\nres = pd.DataFrame({\"Model\":['RandomForestClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred2,y_test)],\n                    \"Recall\": [recall_score(y_test,y_pred2)],\n                    \"F1score\": [f1_score(y_test,y_pred2)]})\nResults = Results.append(res)","6e7fc52d":"pd.crosstab(y_test,y_pred2,rownames=['Real data'],colnames=['Predicted'])","e92f19ad":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\ny_pred3 = lr.predict(X_test)\nres = pd.DataFrame({\"Model\":['LogisticRegression'],\n                    \"Accuracy Score\": [accuracy_score(y_pred3,y_test)],\n                    \"Recall\": [recall_score(y_test,y_pred3)],\n                    \"F1score\": [f1_score(y_test,y_pred3)]})\nResults = Results.append(res)","5de0da33":"pd.crosstab(y_test,y_pred3,rownames=['Real data'],colnames=['Predicted'])","2a37dca1":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\ny_pred4 = lr.predict(X_test)\nres = pd.DataFrame({\"Model\":['XGBClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred4,y_test)],\n                    \"Recall\": [recall_score(y_test,y_pred4)],\n                    \"F1score\": [f1_score(y_test,y_pred4)]})\nResults = Results.append(res)","87ff53ce":"pd.crosstab(y_test,y_pred4,rownames=['Real data'],colnames=['Predicted'])","8e7911cf":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\ny_pred5 = lr.predict(X_test)\nres = pd.DataFrame({\"Model\":['KNeighborsClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred5,y_test)],\n                    \"Recall\": [recall_score(y_test,y_pred5)],\n                    \"F1score\": [f1_score(y_test,y_pred5)]})\nResults = Results.append(res)","964b352c":"pd.crosstab(y_test,y_pred5,rownames=['Real data'],colnames=['Predicted'])","1bde60b3":"Results.sort_values(by='Accuracy Score',ascending=True)","c13875f9":"from sklearn.model_selection import RandomizedSearchCV\n\ndef randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_rs_scores = {}\n    model_rs_best_param = {}\n    \n    for name, model in models.items():\n        rs_model = RandomizedSearchCV(model,\n                                     param_distributions=params[name],\n                                     cv=5,\n                                     n_iter=20,\n                                     verbose=1)\n        rs_model.fit(X_train,y_train)\n        model_rs_scores[name] = rs_model.score(X_test,y_test)\n        model_rs_best_param[name] = rs_model.best_params_\n        \n    return model_rs_scores, model_rs_best_param","60f2211d":"params = {'KNeighborsClassifier' : {'n_neighbors': np.arange(1,100,10)},\n          'XGBClassifier': {'learning_rate': np.linspace(0,1,20),\n                            'gamma': [0,2,4,10],\n                            'max_depth': [2,3,6],\n                            'lambda': [0,1],\n                            'alpha' : [0,0.1,0.2],\n                            }}\nmodels = {'KNeighborsClassifier': KNeighborsClassifier(),\n         'XGBClassifier': XGBClassifier(eval_metric='mlogloss')}","a1627138":"model_rs_scores, model_rs_best_param = randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test)","99a7efc0":"model_rs_scores","bfbb6d71":"model_rs_best_param","434d50c3":"from sklearn.metrics import classification_report,plot_confusion_matrix,plot_roc_curve","16b699da":"model = XGBClassifier(max_depth=2,learning_rate=0.7894736842105263,gamma=4,alpha=0.2)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)","d8573472":"print(\" Best evaluation parameters achieved with XGBClassifier:\") \nevaluation(y_test,y_pred)","0a43e8b0":"print(classification_report(y_test,y_pred))","7c6eff42":"plot_confusion_matrix(model,X_test,y_test,cmap='RdPu')","6569004d":"plot_roc_curve(model,X_test,y_test)","d33174ad":"#### Logistic Regression","15438ecb":"From the baseline modeling, we will choose the follow model to have an in-depth look:\n\n* XGBClassifier\n* KNeighborsClassifier","84404b50":"**Conclusion:**\n\nI got maximum accuracy score of 0.969 on XGBClassifier.","48b9b272":"#### (B)Modeling","921b4e2e":"**LabelEncoder**","d723ce4d":"**Great! Our data are quite blanced.**","f3031a59":"#### (C)HyperTuning using Random Search CV","ce51fcee":"#### KNeighbors Classifier","e0e95aa3":"**StandardScaler**","0a5be583":"#### Visualization for Numerical Variables","f753de3b":"**Seems that some features are categorical but be treated as numercial**","5a6b28d1":"#### XGB Classifier","4dcb305b":"## 2. Data Visualization","0f8c1f71":"#### RandomForest Classifier","1e6d65fd":"## 3. Data Preprocessing","7eec3078":"#### DecisionTree Classifier","70887a65":"#### Probability of target","6bc9e3f1":"## 5. Model Evalution","a32651ab":"#### Visualization for Categorical Variables","7ea92906":"#### (A)Split train test data","fcb01df5":"## 1. Reading Dataset","7579b2f3":"## 4. Building Model"}}