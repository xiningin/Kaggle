{"cell_type":{"c5ab98a9":"code","67d86127":"code","29a1a9e8":"code","91fb1ec7":"code","f7bdf005":"code","f0375ddc":"code","c1cd4ffe":"code","823cea64":"code","e72b3c19":"code","ebfcdbe9":"code","4053e566":"code","451b22e7":"code","595683dd":"code","090cbfff":"code","339b6360":"code","b048a86c":"code","2077f32a":"code","63f7d255":"code","d96bca82":"code","3ebef8e6":"code","18bb0f45":"code","45bb486e":"code","728da3a2":"code","be64d5aa":"code","c65add84":"code","dc674056":"code","b93b870d":"code","03ccbb02":"code","0d9cb7eb":"code","25248b58":"code","5070e5fd":"code","b7db763c":"markdown","5f0e36b2":"markdown","f9ce8281":"markdown","5162ae4e":"markdown","73292e4c":"markdown","e95bfa18":"markdown","d9f3a513":"markdown","158a0690":"markdown","3efc2f49":"markdown","cf92ddce":"markdown","bed72960":"markdown","70f3beb8":"markdown","59f1d070":"markdown","f0d5b76f":"markdown","6103b941":"markdown","d056e69d":"markdown","648d5db7":"markdown","136f76c6":"markdown","bd51b99e":"markdown","3769e0df":"markdown","3a03fb5b":"markdown","a69015e6":"markdown","2991c719":"markdown","db87e2a5":"markdown","aa4acca0":"markdown"},"source":{"c5ab98a9":"import pandas as pd","67d86127":"diamonds = pd.read_csv('..\/input\/ceupe-big-data-analytics\/diamonds_train.csv')\ndiamonds_predict = pd.read_csv('..\/input\/ceupe-big-data-analytics\/diamonds_test.csv')","29a1a9e8":"diamonds.head().T","91fb1ec7":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder","f7bdf005":"NUM_FEATS = ['carat', 'depth', 'table', 'x', 'y', 'z']\nCAT_FEATS = ['cut', 'color', 'clarity']\nFEATS = NUM_FEATS + CAT_FEATS\nTARGET = 'price'","f0375ddc":"numeric_transformer = \\\nPipeline(steps=[('imputer', SimpleImputer(strategy='median')), \n                ('scaler', StandardScaler())])","c1cd4ffe":"categorical_transformer = \\\nPipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n                ('onehot', OneHotEncoder(handle_unknown='ignore'))])","823cea64":"preprocessor = \\\nColumnTransformer(transformers=[('num', numeric_transformer, NUM_FEATS),\n                                ('cat', categorical_transformer, CAT_FEATS)])","e72b3c19":"preprocessor","ebfcdbe9":"pd.DataFrame(data=preprocessor.fit_transform(diamonds)).head()","4053e566":"from sklearn.model_selection import train_test_split","451b22e7":"diamonds_train, diamonds_test = train_test_split(diamonds)","595683dd":"print(diamonds_train.shape)\nprint(diamonds_test.shape)","090cbfff":"from sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel= Pipeline(steps=[('preprocessor', preprocessor),\n                       ('regressor', RandomForestRegressor())])","339b6360":"model.fit(diamonds_train[FEATS], diamonds_train[TARGET]);","b048a86c":"from sklearn.metrics import mean_squared_error","2077f32a":"y_test = model.predict(diamonds_test[FEATS])\ny_train = model.predict(diamonds_train[FEATS])","63f7d255":"print(f\"test error: {mean_squared_error(y_pred=y_test, y_true=diamonds_test[TARGET], squared=False)}\")\nprint(f\"train error: {mean_squared_error(y_pred=y_train, y_true=diamonds_train[TARGET], squared=False)}\")","d96bca82":"from sklearn.model_selection import cross_val_score","3ebef8e6":"scores = cross_val_score(model, \n                         diamonds[FEATS], \n                         diamonds[TARGET], \n                         scoring='neg_root_mean_squared_error', \n                         cv=5, n_jobs=-1)","18bb0f45":"import numpy as np\nnp.mean(-scores)","45bb486e":"from sklearn.model_selection import RandomizedSearchCV","728da3a2":"param_grid = {\n    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n    'regressor__n_estimators': [16, 32, 64, 128, 256, 512],\n    'regressor__max_depth': [2, 4, 8, 16],\n}\n\ngrid_search = RandomizedSearchCV(model, \n                                 param_grid, \n                                 cv=5, \n                                 verbose=10, \n                                 scoring='neg_root_mean_squared_error', \n                                 n_jobs=-1,\n                                 n_iter=32)\n\ngrid_search.fit(diamonds[FEATS], diamonds[TARGET])","be64d5aa":"grid_search.best_params_","c65add84":"grid_search.best_score_","dc674056":"y_pred = grid_search.predict(diamonds_predict[FEATS])","b93b870d":"submission_df = pd.DataFrame({'id': diamonds_predict['id'], 'price': y_pred})","03ccbb02":"submission_df.head()","0d9cb7eb":"submission_df.describe()","25248b58":"submission_df.price.clip(0, 20000, inplace=True)","5070e5fd":"submission_df.to_csv('diamonds_rf.csv', index=False)","b7db763c":"## 2. eda","5f0e36b2":"for learning purposes, libraries will be imported inside its corresponding usage section...","f9ce8281":"first, lets train a simple model using holdout, train - test split...","5162ae4e":"let's define a preprocessing transformer for numerical columns...","73292e4c":"## 8. prepare submission","e95bfa18":"this section is up to you! this guided lesson is about a machine learning pipeline...","d9f3a513":"at least in this case, it is at the cost of interpretability of transformed DataFrame...","158a0690":"## 7. optimize model using grid search","3efc2f49":"## 4. train a simple model","cf92ddce":"## 0. python imports & setup","bed72960":"let's join these transformers using a `ColumnTransformer`:","70f3beb8":"## 5. check model performance on test and train data","59f1d070":"inspecting the full preprocessor:","f0d5b76f":"* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html","6103b941":"let's define a preprocessing transformer for categorical columns...","d056e69d":"## 9. let's try more models...","648d5db7":"in this section I will teach how to use scikit-learn's Pipiline and ColumnTransformer, one of the best practices for composing preprocessing and modeling in a single and elegand class... pay attention as it is hard to understand...","136f76c6":"## 1. data loading","bd51b99e":"## 3. ml preprocessing","3769e0df":"as you can see, there are both categorical and numerical columns...","3a03fb5b":"let's identify numerical and categorical features...","a69015e6":"how does this preprocessing looks like?","2991c719":"let's choose a model from scikit-learn cheatsheet: https:\/\/scikit-learn.org\/stable\/tutorial\/machine_learning_map\/index.html","db87e2a5":"## 6. check model performance using cross validation","aa4acca0":"* diamonds: labeled data we can use for training and testing\n* diamonds_predict: diamonds to predict its price and upload result to Kaggle"}}