{"cell_type":{"4e54abd2":"code","24e77c6e":"code","2b94c521":"code","94cb1092":"code","82676a04":"code","81383ac4":"code","a873fe38":"code","68bb2e0b":"code","4e4d72e6":"code","0c52e31e":"code","49b39943":"code","924da8eb":"code","ae9b7ee7":"code","ca461603":"code","3313a422":"code","bcf45ade":"code","92d48cad":"code","68e98915":"code","c47e8d0a":"code","cc6dabdf":"code","66675389":"markdown","23ff9b98":"markdown","6aaf161c":"markdown","8ae9a84f":"markdown","2673b3a5":"markdown","089eb42b":"markdown","1ec5eafc":"markdown","ce5ece67":"markdown","88322567":"markdown","0a06d8ce":"markdown","83f41279":"markdown","0cab96f4":"markdown","409fd478":"markdown","06e3c416":"markdown","4b1c8ee9":"markdown","6020553b":"markdown"},"source":{"4e54abd2":"import os\nfrom pathlib import Path\nfrom warnings import filterwarnings\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\nfilterwarnings('ignore')\nprint(tf.__version__)","24e77c6e":"direc = Path('..\/input\/mammals-classification\/mammals')\nfilepaths = list(direc.glob(r'**\/*.jpg'))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],filepaths))\n\n\nfilepaths = pd.Series(filepaths, name='FilePaths').astype(str)\nLabels = pd.Series(Labels, name='Labels').astype(str)\n\n\nimg_df = pd.merge(filepaths, Labels, right_index=True, left_index=True)\n\nimg_df = img_df[ img_df['Labels'].apply(lambda x: x[-2:]!='GT') ]\n\n#Resampling it\nimg_df = img_df.sample(frac = 1).reset_index(drop=True)\nimg_df.head()","2b94c521":"# There seems to be some bad files in the dataset let's find it\nimport PIL\nfrom PIL import UnidentifiedImageError\n\nPIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfor img_p in img_df.FilePaths:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_df.loc[img_df['FilePaths'] == img_p].index)\n            img_df = img_df.drop(img_df.loc[img_df['FilePaths'] == img_p].index).reset_index()\n            print(img_p)","94cb1092":"# Let's look at some of the images\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nf, a = plt.subplots(nrows=3, ncols=3,figsize=(13, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    ax.imshow(plt.imread(img_df.FilePaths[i]))\n    ax.set_title(img_df.Labels[i])\n    \nplt.tight_layout()\nplt.show()","82676a04":"print(f\" Number of Rows: {img_df.shape[0]} \\n Number of Columns: {img_df.shape[1]} \")","81383ac4":"vals = dict(img_df['Labels'].value_counts())\nsns.barplot(x=list(vals.keys()), y=list(vals.values()))\nplt.show()","a873fe38":"X_train, X_test = train_test_split(img_df, test_size=.20)\n\nprint(f'Shape of Training Data : ',X_train.shape)\nprint(f'Shape of Testing Data : ',X_test.shape)","68bb2e0b":"img_datagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\nimg_size = (224, 224)\n\nX_train = img_datagen.flow_from_dataframe(dataframe=X_train, x_col='FilePaths', y_col='Labels',\n                                          target_size=img_size, color_mode='rgb', class_mode='categorical', batch_size=32)\nX_test = img_datagen.flow_from_dataframe(dataframe=X_test, x_col='FilePaths', y_col='Labels',\n                                         target_size=img_size, color_mode='rgb', class_mode='categorical', batch_size=32)\n","4e4d72e6":"effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(224,224,3))","0c52e31e":"model = effnet.output\nmodel = GlobalAveragePooling2D()(model)\nmodel = Dropout(rate=0.5)(model)\nmodel = Dense(9, activation='softmax')(model)\nmodel = Model(inputs=effnet.input, outputs = model)\n\nmodel.summary()","49b39943":"model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(\"Model compiled!\")","924da8eb":"earlystopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20)\n\ncheckpointer = ModelCheckpoint(\n    filepath=\".\/mammal.h5\",\n    verbose=1,\n    save_best_only=True,\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10, min_delta=0.0001, factor=0.2\n)","ae9b7ee7":"history = model.fit(X_train,\n                    validation_data=X_test, \n                    epochs=20, batch_size=32,\n                    callbacks=[earlystopping, checkpointer, reduce_lr])","ca461603":"# Load the best model saved\nmodel = tf.keras.models.load_model(\".\/mammal.h5\")\nloss, acc = model.evaluate(X_test)\nprint(f\"Test Accuracy: {acc}\")\nprint(f\"Test Loss: {loss}\")","3313a422":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nepochs = [i for i in range(20)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","bcf45ade":"!wget https:\/\/cdn.britannica.com\/07\/5207-050-5BC9F251\/Gray-wolf.jpg","92d48cad":"def perdict(img):\n    class_index = list(X_test.class_indices.keys())\n    test_img = cv2.imread(img)\n    test_img = cv2.resize(test_img, (224, 224))\n    test_img = test_img.reshape((1, 224, 224, 3))\n    pred = model.predict(test_img)\n    return class_index[np.argmax(pred)], max(pred.ravel())","68e98915":"pred, confidence = perdict(\"Gray-wolf.jpg\")\nplt.imshow(plt.imread(\"Gray-wolf.jpg\"))\nplt.title(f\"{pred} : {round(confidence, 2)*100}%\")\nplt.show()","c47e8d0a":"!wget https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/1\/1a\/Elephant_Diversity.jpg\/220px-Elephant_Diversity.jpg","cc6dabdf":"pred, confidence = perdict(\"220px-Elephant_Diversity.jpg\")\nplt.imshow(plt.imread(\"220px-Elephant_Diversity.jpg\"))\nplt.title(f\"{pred} : {round(confidence, 2)*100}%\")\nplt.show()","66675389":"<h3><b>7. Time to test out the model.<\/b><\/h3>","23ff9b98":"<h3><b>4. Data Augmentation<\/b><\/h3>\nImage data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\\\nThe augmentation methods we are going to use\n- Shear Range - Distort the image along an axis\n- Random Zoom Augmentation - Randomly zooms each image\n- Horizontal Flip Augmentation","6aaf161c":"<h3><b>1. Importing The Modules<\/b><\/h3>\n\n","8ae9a84f":"**85%** Test accuracy, not too bad.","2673b3a5":"<h3><b>3. Time to split the data<\/b><\/h3>\n\nThe train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n\n- X_train - The data used to train the model.\n- X_test - The data used to test the model after training.","089eb42b":"<h3><b>6. Let's train the model!<\/b><\/h3>","1ec5eafc":"<b><center>If you found this notebook useful, kindly leave an upvote!<center>\n    <center>This helps me to keep going \u2764\ufe0f<\/center><\/b>\n\n","ce5ece67":"<h3><b>5.1 Transfer Learning<\/b><\/h3>\nLarge convolutional neural network models may take days or even weeks to train on very large datasets.\n\nBut we don't have that much time, So we take a shortcut. We can re-use the weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks.\n\nFor the task in hand I'll be using the **EfficientNetB0** model which was trained on the ImageNet dataset.","88322567":"<h4><b>2.1. Let's have a look at the data \ud83d\udc40<\/b><h4>","0a06d8ce":"# <center><b>\ud83e\udd81 <span style=\"color:darkblue\">Let's Classify mammals<\/span> \ud83e\udd81<\/b><\/center>\n<center>There are over 4,200 species of mammals. We'll classify 9 of them today.<center>\n","83f41279":"![elephant](https:\/\/media.kidadl.com\/6052b9312b6c3675846c31c4_elephant_quotes_project_how_magnificent_these_creatures_are_8973ec9082.jpeg)","0cab96f4":"<h3><b>5.4 The callbacks<\/b><\/h3>\nCallbacks are a neat way to chnage some of the parameters of the model based on the training process.\n\n- Early Stopping -> Early stopping is a method that allows us to specify a large number of training epochs and stop training once the model performance stops getting on the validation dataset.\n\n- Checkpointer -> Save the best model with lowest validation loss.\n\n- Reduce LR On Plateau -> Reduce learning rate when a metric has stopped improving. This change helps the model learn better.","409fd478":"<center><h1><span style=\"color:crimson\">Objective<\/span><\/h1>\nEfficient classification of the mammals  with Tensorflow and Keras.","06e3c416":"<h3><b>5.3 Compile the model<\/b><\/h3>\nWe'll use the Adam optimizer. The loss function is categorical crossentropy because we have one-hot encoded the labels, and we'll be using the accuracy metric.","4b1c8ee9":"<h3><b>5.2 The rest of the model.<\/b><\/h3>\nThe EfficientNetB0 has an output size of 1000. We don't have 1000 classes to predict so we'll remove the output layers and add our own.\n\nGlobalAveragePooling2D -> This layer acts similar to the Max Pooling layer in CNNs, the only difference being is that it uses the Average values instead of the Max value while pooling. This really helps in decreasing the computational load on the machine while training.\n\nDropout -> This layer omits some of the neurons at each step from the layer making the neurons more independent from the neibouring neurons. It helps in avoiding overfitting. Neurons to be ommitted are selected at random. The rate parameter is the liklihood of a neuron activation being set to 0, thus dropping out the neuron\n\nDense -> This is the output layer which classifies the image into 1 of the 9 possible classes. It uses the softmax function which is a generalization of the sigmoid function.","6020553b":"<h3><b>2. Let's load the data \ud83d\udcca<\/b><h3>"}}