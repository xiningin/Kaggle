{"cell_type":{"a89bb03a":"code","81ab2578":"code","675d3d43":"code","f2d70666":"code","eb4bfcc3":"code","33f4dc3e":"code","4aaa9170":"code","4feb6226":"code","876e87c8":"code","5ed72bea":"code","fb15cd7a":"code","e36f8033":"code","7c10f926":"code","c5dd1b9c":"code","23337d00":"code","282ec1de":"code","edaf8642":"code","624ff720":"code","38712411":"code","177c3216":"code","5e572cfd":"code","94752181":"markdown","f9bfbfd7":"markdown","663b2dc0":"markdown","dfe9e3cd":"markdown","ce2aae28":"markdown","fd9a7dfb":"markdown","4ba44bba":"markdown","3164a082":"markdown","0c8a32ac":"markdown","7fc9225e":"markdown"},"source":{"a89bb03a":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold,TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\n\nimport math\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\nfrom keras.models import Model\n","81ab2578":"train = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")\nminmax = MinMaxScaler()","675d3d43":"train = train[(train['target_nitrogen_oxides'] <1100) & (train['target_nitrogen_oxides'] > 10) == True]\nprint(\"NEW TRAIN SIZE : \")\nlen(train[(train['target_nitrogen_oxides'] < 1100 ) & (train['target_nitrogen_oxides']>10) == True])","f2d70666":"train = train[train['target_carbon_monoxide'] < 8.5 ]\nprint(\"NEW TRAIN SIZE : \")\nlen(train[train['target_carbon_monoxide'] < 8.5])","eb4bfcc3":"train = train[train['target_benzene'] < 40]\nprint(\"NEW TRAIN SIZE : \")\nlen(train[(train['target_benzene'] < 40)])\n","33f4dc3e":"train['date_time'] = train['date_time'].astype('datetime64[ns]')\ntrain['hour'] = train['date_time'].dt.hour\ntrain['day'] = train['date_time'].dt.day\ntrain['weekday'] = train['date_time'].dt.dayofweek\ntrain[\"working_hours\"] =  train[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\ntrain[\"weekend\"] = (train[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","4aaa9170":"test['date_time'] = test['date_time'].astype('datetime64[ns]')\ntest['hour'] = test['date_time'].dt.hour\ntest['day'] = test['date_time'].dt.day\ntest['weekday'] = test['date_time'].dt.dayofweek\ntest[\"working_hours\"] =  test[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\ntest[\"weekend\"] = (test[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","4feb6226":"train = train[['date_time',\n                'deg_C',\n                'hour',\n                'day',\n                'weekday',\n                'weekend',\n                'working_hours',\n                'relative_humidity',\n                'absolute_humidity',\n                'sensor_1',\n                'sensor_2',\n                'sensor_3',\n                'sensor_4',\n                'sensor_5',\n                'target_carbon_monoxide',\n                'target_benzene',\n                'target_nitrogen_oxides'\n                 ]]","876e87c8":"test = test[['date_time',\n                'deg_C',\n                'hour',\n                'day',\n                'weekday',\n                'weekend',\n                'working_hours',\n                'relative_humidity',\n                'absolute_humidity',\n                'sensor_1',\n                'sensor_2',\n                'sensor_3',\n                'sensor_4',\n                'sensor_5'\n                 ]]","5ed72bea":"#train all targets\ntrain_df = train.iloc[:,1:-3]\ntest_df = test.iloc[:,1:]\nall_df = pd.concat([train_df,test_df], axis = 0)\nall_df = pd.DataFrame(minmax.fit_transform(all_df))\ntrain_sc = all_df.iloc[:len(train),:]\ntest_sc = all_df.iloc[len(train):,:]\ny_sc = train.iloc[:,-3:]\ntrain_sc.shape,test_sc.shape,y_sc.shape","fb15cd7a":"msle = tf.keras.losses.MeanSquaredLogarithmicError()\nmse = tf.keras.losses.MeanSquaredError()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor= 'val_loss', min_delta=1e-12, patience=10, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.7, patience=2, verbose=0,\n    mode='auto')","e36f8033":"# Not used\ndef rectifier(x):\n    #x = tf.math.log(x)\n    x = x\n    return x\n","7c10f926":"def reg_model():\n\n    reg_inputs = layers.Input(shape = (13))\n   \n    x = layers.Dense(\n            units = 32, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(reg_inputs)\n    \n    x = layers.Dense(\n            units = 256, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n    \n    x = layers.Dropout(0.1)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(\n            units = 512, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n\n    x = layers.Dropout(0.1)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(\n            units = 256, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n\n    x = layers.Dense(\n            units = 32, \n            activation ='relu',\n            kernel_initializer ='he_uniform')(x)\n        \n    x = layers.Dense(\n            units = 3,\n        activation = 'linear',\n        kernel_initializer ='he_uniform',name = 'last')(x)\n    \n    #x = tf.keras.backend.clip(x, 0.1,1100)\n    \n    reg_outputs = layers.Lambda(rectifier)(x)\n\n    #----------- Model instantiation  ---------------\n    model = Model(reg_inputs,reg_outputs)\n\n    return model","c5dd1b9c":"split = 0.025\nind_tr = np.round(len(train_sc)*(1-split),0).astype('int')\nX_train = train_sc.iloc[:ind_tr,:]\ny_train = y_sc.iloc[:ind_tr]\nX_test = train_sc.iloc[ind_tr:,:]\ny_test = y_sc.iloc[ind_tr:]\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","23337d00":"y_train_log = y_train.copy()\ny_test_log = y_test.copy()\ny_train_log.iloc[:,0] = y_train.iloc[:,0].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,1] = y_train.iloc[:,1].map(lambda x : math.log(x+1))\ny_train_log.iloc[:,2] = y_train.iloc[:,2].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,0] = y_test.iloc[:,0].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,1] = y_test.iloc[:,1].map(lambda x : math.log(x+1))\ny_test_log.iloc[:,2] = y_test.iloc[:,2].map(lambda x : math.log(x+1))","282ec1de":"\"\"\"\nfrom Somayyeh Gholami & Mehran Kazeminia, smart ensembling based upon :\nThanks to: @paddykb https:\/\/www.kaggle.com\/paddykb\/tps-07-gam-baseline\nThanks to: @junhyeok99 https:\/\/www.kaggle.com\/junhyeok99\/automl-pycaret\n\"\"\"\nbench = pd.read_csv(\"..\/input\/benchmark1\/submission.csv\")\nbench = bench.iloc[:,1:]\nbench_stat = bench.describe()","edaf8642":"ROUND = 50 # Several iterations because of the stochastic calculation\npred_final = np.zeros((len(test_sc),3))\nprint('======== TRAINING STARTING ============\\n')\napproved = 0\n\nfor i in range(ROUND):\n    model = reg_model()\n    model.compile(loss=msle,optimizer = keras.optimizers.Adam())\n    model.fit(X_train,y_train_log,\n              batch_size = 64, \n              epochs = 100,\n              validation_data=(X_test,y_test_log),\n              callbacks=[es, plateau],\n              verbose =0)\n    pred = model.predict(X_test)\n    pred[:,0] = np.exp(pred[:,0])-1\n    pred[:,1] = np.exp(pred[:,1])-1\n    pred[:,2] = np.exp(pred[:,2])-1\n    pred = np.where(pred>0,pred,0)\n    \n    score = mean_squared_log_error(y_test, pred)\n    print(f\"Score for round {i} on X_test :\", score)\n    pred_all = model.predict(train_sc)\n    pred_all[:,0] = np.exp(pred_all[:,0])-1\n    pred_all[:,1] = np.exp(pred_all[:,1])-1\n    pred_all[:,2] = np.exp(pred_all[:,2])-1\n    pred_all = np.where(pred_all>0.01,pred_all,0.01)\n    score_all = mean_squared_log_error(y_sc, pred_all)\n    print(f\"Score for round {i} on all dataset :\", score_all)\n    \n    # In case of multiple iterations, we can reject anomalous predictions :\n    if (score < 0.15) == True:\n        approved += 1\n        print(f\"round {i} approved for benchmarking analysis \")\n        pred_test = model.predict(test_sc)\n        pred_test[:,0] = np.exp(pred_test[:,0])-1\n        pred_test[:,1] = np.exp(pred_test[:,1])-1\n        pred_test[:,2] = np.exp(pred_test[:,2])-1\n        pred_test = np.where(pred_test>0,pred_test,0.05)\n        \n        pred_test[:,0] = np.where(pred_test[:,0]<9.5,pred_test[:,0],9.5)\n        pred_test[:,0] = np.where(pred_test[:,0]>0.24,pred_test[:,0],0.24)\n\n        pred_test[:,1] = np.where(pred_test[:,1]< 45,pred_test[:,1],45)\n        \n        pred_test[:,2] = np.where(pred_test[:,2]< 1100,pred_test[:,2],1100)\n        pred_test[:,2] = np.where(pred_test[:,2]> 24,pred_test[:,2],24)\n            \n        # Run analysis :\n        df = pd.concat([pd.DataFrame(pred_test).describe(),pd.DataFrame(bench_stat)], axis = 1)\n        \n        carbon_75 = np.abs((df.iloc[6,0]-df.iloc[6,3])\/df.iloc[6,3])\n        benzene_75 = np.abs((df.iloc[6,1]-df.iloc[6,4])\/df.iloc[6,4])\n        nitrogen_75 = np.abs((df.iloc[6,2]-df.iloc[6,5])\/df.iloc[6,5])\n        \n        carbon_50 = np.abs((df.iloc[5,0]-df.iloc[5,3])\/df.iloc[5,3])\n        benzene_50 = np.abs((df.iloc[5,1]-df.iloc[5,4])\/df.iloc[5,4])\n        nitrogen_50 = np.abs((df.iloc[5,2]-df.iloc[5,5])\/df.iloc[5,5])\n        \n        carbon_25 = np.abs((df.iloc[4,0]-df.iloc[4,3])\/df.iloc[4,3])\n        benzene_25 = np.abs((df.iloc[4,1]-df.iloc[4,4])\/df.iloc[4,4])\n        nitrogen_25 = np.abs((df.iloc[4,2]-df.iloc[4,5])\/df.iloc[4,5])\n        \n        run_75 =100 *(carbon_75 + benzene_75 + nitrogen_75)\/3\n        run_50 =100 *(carbon_50 + benzene_50 + nitrogen_50)\/3\n        run_25 =100 *(carbon_25 + benzene_25 + nitrogen_25)\/3\n        \n        print('GAP WITH BENCHMARK :',run_75,run_50,run_25,'%\\n')\n        if ((run_75 < 3) & (run_50 < 5) & (run_25 < 6))== True :\n            pred_final += pred_test\n            print(\"PREDICTION RECORDED\")\n            print(f\"GAP 75% :{run_75} GAP 50% :{run_50} GAP 25% :{run_25}\")\n            break\n        else :\n            print('PREDICTION REJECTED \\n')\n    else :\n        print(f\"round {i} rejected \\n\")\n\n    \nprint(f\"\\n====== End of the training :{approved} accepted rounds for this training =====\\n\")","624ff720":"print(\"=================== NEURAL NETWORK ===================== \")\nbench_pred = pd.DataFrame(pred_final, columns = ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides'])\ndisplay(bench_pred.head(5))\nprint(\"===================== BENCHMARK ======================== \")\ndisplay(bench.head(5).astype('float32'))","38712411":"print(\"================= NEURAL NETWORK STATISTIC =================\")\ndisplay(bench_pred.describe())\nprint(\"=================== BENCHMARK STATISTIC ===================\")\ndisplay(bench.describe())","177c3216":"sample_submission['target_carbon_monoxide'] = pred_final[:,-3]\nsample_submission['target_benzene'] = pred_final[:,-2]\nsample_submission['target_nitrogen_oxides'] = pred_final[:,-1]","5e572cfd":"sample_submission.to_csv('sub_NN16.csv',index = False)","94752181":"<h2> Model definition","f9bfbfd7":"<h2> Benchmark preparation before training and submission (no blending)","663b2dc0":"<h2> Loss and metric functions for NN","dfe9e3cd":"<h2> Features rescaling","ce2aae28":"<h2> Internal updates of the NN (unused)","fd9a7dfb":"![image.png](attachment:6b536dc9-9c14-4c8a-a80b-2f36adc29ef0.png)\n\n<h2>We increase the dimension to 512 neurons and then reduce it for convergence<h2>","4ba44bba":"<h2> Training and best prediction choice","3164a082":"<h2> Features augmentation","0c8a32ac":"<h2> Outliers hunting","7fc9225e":"<h2> Benchmark analysis (no blending)"}}