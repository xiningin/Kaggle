{"cell_type":{"41f482c4":"code","2e819e75":"code","d2ace815":"code","d876b7bd":"code","8945a0c8":"code","e099e6ec":"code","ddf7b5f0":"code","5672e92b":"code","8caa6992":"code","d42aed7c":"code","2926c44b":"code","72634fb5":"code","32cddb63":"code","ddabcb28":"code","0ec5335b":"code","a53ea1f3":"code","73419cab":"code","8c02f40e":"code","5b86b1f8":"code","8c0ead3c":"code","5e8a0950":"code","8c69b008":"code","ff935ec5":"code","c2b1a334":"code","cbe2be06":"code","3a42a03a":"code","3994a25e":"markdown","8dbafcf1":"markdown","033556e4":"markdown","e14a2c25":"markdown","7ff4f55c":"markdown","71fdada0":"markdown","1e0a04c1":"markdown","d7f32202":"markdown","20ebd2f5":"markdown","6756e47c":"markdown","2fa91dd7":"markdown","9707e67c":"markdown","70d45b40":"markdown","ace6d92b":"markdown","bb1bb307":"markdown"},"source":{"41f482c4":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm","2e819e75":"path = '..\/input\/datajam-2021'\nall_data_path = path + \"\/train.csv\" #path where data is stored","d2ace815":"all_data = pd.read_csv(all_data_path) #load data in dataframe using pandas","d876b7bd":"all_data.head()","8945a0c8":"all_data.isnull().sum()","e099e6ec":"# age              2\n# sex              2\n# test_time        2\n# motor_UPDRS      2\n# total_UPDRS      2\n# Jitter(%)        2\n# Jitter(Abs)      2\n# Jitter:RAP       2\n# Jitter:PPQ5      2\n# Jitter:DDP\nall_data['subject'] = all_data['subject'].fillna(0) #Filling the Null Values with 0\nall_data['PPE'] = all_data['PPE'].fillna(0)\nall_data['DFA'] = all_data['DFA'].fillna(0)\nall_data['RPDE'] = all_data['RPDE'].fillna(0)\nall_data['HNR'] = all_data['HNR'].fillna(0)\nall_data['NHR'] = all_data['NHR'].fillna(0)\nall_data['Shimmer:DDA'] = all_data['Shimmer:DDA'].fillna(0)\nall_data['Shimmer:APQ11'] = all_data['Shimmer:APQ11'].fillna(0)\nall_data['Shimmer:APQ5'] = all_data['Shimmer:APQ5'].fillna(0)\nall_data['Shimmer:APQ3'] = all_data['Shimmer:APQ3'].fillna(0)\nall_data['Shimmer(dB)'] = all_data['Shimmer(dB)'].fillna(0)\nall_data['Shimmer'] = all_data['Shimmer'].fillna(0)\nall_data['Jitter:DDP'] = all_data['Jitter:DDP'].fillna(0)\nall_data['Jitter:PPQ5'] = all_data['Jitter:PPQ5'].fillna(0)\nall_data['Jitter:RAP'] = all_data['Jitter:RAP'].fillna(0)\nall_data['Jitter(Abs)'] = all_data['Jitter(Abs)'].fillna(0)\nall_data['Jitter(%)'] = all_data['Jitter(%)'].fillna(0)\nall_data['total_UPDRS'] = all_data['total_UPDRS'].fillna(0)\nall_data['motor_UPDRS'] = all_data['motor_UPDRS'].fillna(0)\nall_data['test_time'] = all_data['test_time'].fillna(0)\nall_data['sex'] = all_data['sex'].fillna(0)\nall_data['age'] = all_data['age'].fillna(0)\n","ddf7b5f0":"all_data.isnull().sum()","5672e92b":"X_train, X_val= train_test_split(all_data, test_size=0.2, random_state=42)","8caa6992":"X_train,y_train = X_train.drop(['motor_UPDRS','Id'], axis=1),X_train.drop(['subject','Id','age','sex','test_time','total_UPDRS','Jitter(%)','Jitter(Abs)','Jitter:RAP','Jitter:PPQ5','Jitter:DDP','Shimmer','Shimmer(dB)','Shimmer:APQ3','Shimmer:APQ5','Shimmer:APQ11','Shimmer:DDA','NHR','HNR','RPDE','DFA','PPE'], axis=1)\nX_val, y_val = X_val.drop(['motor_UPDRS','Id'], axis=1),X_val.drop(['subject','Id','age','sex','test_time','total_UPDRS','Jitter(%)','Jitter(Abs)','Jitter:RAP','Jitter:PPQ5','Jitter:DDP','Shimmer','Shimmer(dB)','Shimmer:APQ3','Shimmer:APQ5','Shimmer:APQ11','Shimmer:DDA','NHR','HNR','RPDE','DFA','PPE'], axis=1)","d42aed7c":"X_train","2926c44b":"y_train","72634fb5":"X_val","32cddb63":"y_val","ddabcb28":"# from sklearn.linear_model import LogisticRegression\n# regressor = LogisticRegression()\n\nregressor = svm.SVR()","0ec5335b":"X_train.isnull().sum()","a53ea1f3":"regressor.fit(X_train, y_train)","73419cab":"y_pred = regressor.predict(X_val)","8c02f40e":"from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_val,y_pred)","5b86b1f8":"print(\"MSE of the model is :\" ,mse)","8c0ead3c":"pred_csv_path = path + \"\/test.csv\" #This path is only for getting the Id of the test csv so that we can do a final submission.\npred_csv = pd.read_csv(pred_csv_path)","5e8a0950":"final_test_path = path + \"\/test.csv\"\nfinal_test = pd.read_csv(final_test_path)","8c69b008":"final_test.head()","ff935ec5":"final_test = final_test.drop(['Id'],axis=1) ##We are dropping the Id beacuse we donot have taken this varible in Training Phase also,\n#Because this variable only contribute a uneccary variable thus making our results bad.","c2b1a334":"predictions = regressor.predict(final_test)","cbe2be06":"submission = {\n    'Id': pred_csv.Id.values, # Id from test.csv\n    'motor_UPDRS': predictions # predicitions for test.csv\n}\n\nsolution = pd.DataFrame(submission)\nsolution.head()","3a42a03a":"#make the submission file\nsolution.to_csv('submission.csv',index=False)","3994a25e":"**Define the Model**\n* We have fixed our data and now we are ready to train our model.\n\n* There are a ton of regressor to choose from some being Logistic Regression, SVM, Random Forests, Decision Trees, etc.\ud83e\uddd0\n\n* Remember that there are no hard-laid rules here. you can mix and match classifiers, it is advisable to read up on the numerous techniques and choose the best fit for your solution , experimentation is the key.\n\n* A good model does not depend solely on the regressor but also on the features you choose. So make sure to analyse and understand your data well and move forward with a clear view of the problem at hand. you can gain important insight from here.\ud83e\uddd0","8dbafcf1":"### Generate Submission.csv","033556e4":"## Load Data\n\n* We use pandas \ud83d\udc3c library to load our data.\n* Pandas loads the data into dataframes and facilitates us to analyse the data.","e14a2c25":"### Validation Phase \ud83e\udd14","7ff4f55c":"* pred_csv: It is for getting Id for Submission.csv(Both have same csv test.csv)\n* final_test: For getting our preds on test data(Both have same csv test.csv)","71fdada0":"## Fix the Null Values :D","1e0a04c1":"## Congrats You've Made Your First Submission :D","d7f32202":"## Split Data into Train and Validation \ud83d\udd2a\n\n* The next step is to think of a way to test how well our model is performing. we cannot use the test data given as it does not contain the data labels for us to verify.\n\n* The workaround this is to split the given training data into training and validation. Typically validation sets give us an idea of how our model will perform on unforeseen data. it is like holding back a chunk of data while training our model and then using it to for the purpose of testing. it is a standard way to fine-tune hyperparameters in a model.\n\n* There are multiple ways to split a dataset into validation and training sets. following are two popular ways to go about it, k-fold, leave one out 1. \ud83e\uddd0\n\n* Validation sets are also used to avoid your model from overfitting on the train dataset.","20ebd2f5":"## Import packages","6756e47c":"## TRAINING PHASE \ud83c\udfcb\ufe0f","2fa91dd7":"## Train the Regressor","9707e67c":"## Visualize the data \ud83d\udc40\n\n\n\n\n","70d45b40":"### Predict on Validation","ace6d92b":"* We have decided to split the data with 20 % as validation and 80 % as training.\n* To learn more about the train_test_split function. \ud83e\uddd0\n* This is of course the simplest way to validate your model by simply taking a random chunk of the train set and setting it aside solely for the purpose of testing our train model on unseen data. as mentioned in the previous block, you can experiment \ud83d\udd2c with and choose more sophisticated techniques and make your model better.\n* Now, since we have our data splitted into train and validation sets, we need to get the corresponding labels separated from the data.\n* with this step we are all set move to the next step with a prepared dataset.","bb1bb307":"MSE are the metrics for this challenge"}}