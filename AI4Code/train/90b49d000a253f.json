{"cell_type":{"7ac38b04":"code","6048849d":"code","ac126127":"code","53f8b3b3":"code","bb91f4e8":"code","1912d32f":"code","f74e41d9":"code","fbab9752":"code","ed6990e3":"code","d1f4f972":"code","b4809ff5":"code","67ddd00e":"code","8e1ca1ee":"code","aa31c2cc":"code","506ca553":"code","e3783908":"code","62c3c613":"code","0f8ba0d6":"code","eadd9eb7":"code","de26177f":"code","04cd8f46":"code","c9b16ea8":"code","61ca2d76":"code","36989973":"code","23f31cae":"code","bf7031b0":"code","af87be71":"code","eb1ac456":"code","f3129231":"code","55e16739":"code","40e1f326":"code","889a656e":"code","ab69eed8":"code","bc689573":"code","c0710f05":"markdown","b8e21316":"markdown","9c61fbf9":"markdown","4acb32ab":"markdown","a791c632":"markdown","5acd85a1":"markdown","f67ad9b8":"markdown"},"source":{"7ac38b04":"mkdir \/kaggle\/working\/weights","6048849d":"class CFG:\n    SEED = 0\n    size = 224\n    batch_size = 16\n    num_workers = 2\n    efficientnet_feature = 1792\n    model_name = \"efficientnet_b4\"\n    pretrained = True\n    \n    dropout = None\n    linear = None\n    margin = 1\n    scheduler = \"ReduceLROnPlateau\"\n    step = \"epoch\"\n\n    learning_rate = 1e-3\n    factor =0.5\n    patience = 2\n    epochs = 5\n","ac126127":"import numpy as np\nimport pandas as pd\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\nimport albumentations\n!pip install timm\nimport timm\n\nfrom tqdm.autonotebook import tqdm\n\n!pip install pytorch-metric-learning\nfrom pytorch_metric_learning import losses\n\nimport gc\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import KFold\nimport cv2\n\nfrom annoy import AnnoyIndex","53f8b3b3":"def fix_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    #gpu randomseed fixed\n    torch.backends.cudnn.deterministic = True\n   \nfix_seed(CFG.SEED)","bb91f4e8":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","1912d32f":"df = pd.read_csv(\"\/kaggle\/input\/happy-whale-and-dolphin\/train.csv\")","f74e41d9":"df.head()","fbab9752":"df[\"path\"] = \"\/kaggle\/input\/happy-whale-and-dolphin\/train_images\/\" + df[\"image\"].astype(str)\ndf[\"index\"] = df.index","ed6990e3":"df.head()","d1f4f972":"df_id_idx = pd.DataFrame({\"individual_id\":df[\"individual_id\"].unique(),\n              \"idx\":range(len(df[\"individual_id\"].unique()))})","b4809ff5":"train_transforms = albumentations.Compose([\n            albumentations.Resize(CFG.size,CFG.size),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.Rotate(limit=10, p=0.8),\n            albumentations.RandomBrightness(limit=(0.09,0.6),p=0.5),\n            albumentations.Normalize(),\n            ToTensorV2(p=1.0),\n            ])\n    \ndef train_albumentations_transform(image, transform=train_transforms):\n    if transform:\n        image_np = np.array(image)\n        augmented = transform(image=image_np)\n    return augmented\n\ntrain_data_transform = transforms.Compose([\n    transforms.Lambda(train_albumentations_transform),\n])","67ddd00e":"valid_transforms = albumentations.Compose([\n            albumentations.Resize(CFG.size,CFG.size, always_apply=True),\n            albumentations.Normalize(),\n            ToTensorV2(p=1.0),\n            ])\n    \ndef valid_albumentations_transform(image, transform=valid_transforms):\n    if transform:\n        image_np = np.array(image)\n        augmented = transform(image=image_np)\n    return augmented\n\nvalid_data_transform = transforms.Compose([\n    transforms.Lambda(valid_albumentations_transform),\n])\n","8e1ca1ee":"class ContrasiveDataset(Dataset):\n    def __init__(self, df, df_id_idx, transforms):\n        self.transforms=transforms\n        self.individual_id = list(df[\"individual_id\"].unique())\n        self.individual_id_to_imgs = {individual_id: df[df[\"individual_id\"] == individual_id].path.values for individual_id in self.individual_id}\n        self.df = df\n        self.df_id_idx = df_id_idx\n\n    def __getitem__(self, idx):\n        id = self.individual_id[idx]\n\n        if random.random()  > 0.5:\n            same = True\n            same_id_images = self.individual_id_to_imgs[id]\n            if len(same_id_images)==1:\n                img1 = same_id_images[0]\n                img2 = same_id_images[0]\n            else:\n                img1, img2 = np.random.choice(same_id_images, size=2, replace=False if len(same_id_images) > 1 else True)\n        else:\n            same = False\n            img1 = np.random.choice(self.individual_id_to_imgs[id], size=1)[0]\n\n            while True:\n                different_label = np.random.choice(self.individual_id, size=1)[0]\n\n                if different_label != id:\n                    break\n            \n            img2 = np.random.choice(self.individual_id_to_imgs[different_label], size=1)[0]\n\n        img1_tensor, img2_tensor= self.process_imgs(img1, img2)\n\n        return {\"images1\":img1_tensor,\n                \"images2\":img2_tensor,\n                \"same\":torch.tensor(same).float(),\n                \"label1\":df_id_idx[df_id_idx[\"individual_id\"]==id][\"idx\"].values[0],\n                \"label2\":df_id_idx[df_id_idx[\"individual_id\"]==id][\"idx\"].values[0] if same else df_id_idx[df_id_idx[\"individual_id\"]==different_label][\"idx\"].values[0],\n                \"image1_name\":img1,\n                \"image2_name\":img2}\n\n\n    def read_transform_one(self, img):\n        img = cv2.imread(img)[..., :: -1]\n\n        if self.transforms is not None:\n            img = self.transforms(img)[\"image\"]\n        return img\n\n    def process_imgs(self, img1, img2):\n        img1 = self.read_transform_one(img1)\n        img2 = self.read_transform_one(img2)\n        return img1, img2\n    \n    def __len__(self):\n        return len(self.individual_id)\n","aa31c2cc":"class Model(nn.Module):\n    def __init__(self,\n                 model_name=CFG.model_name,\n                 pretrained=True,\n                 dropout=0.2,\n                 linear=128):\n\n                 super().__init__()\n                 model = timm.create_model(model_name,\n                                           pretrained=pretrained,\n                                           num_classes=0)\n                 self.num_features=model.num_features\n                 self.linear = None\n                 if linear is not None and linear >0:\n                     self.linear = nn.Linear(self.num_features, linear)\n                 self.backbone = nn.Sequential(model,\n                                              self.linear if self.linear is not None else nn.Identity(),\n                                              nn.ReLU() if self.linear is not None else nn.Identity(),\n                                              nn.Dropout(0.2) if dropout is not None else nn.Identity())\n\n    def forward(self, batch):\n        images_1 = self.backbone(batch[\"images1\"].to(device))\n        images_2 = self.backbone(batch[\"images2\"].to(device))\n        \n        return images_1, images_2","506ca553":"class AvgMeter:\n    def __init__(self, name=\"Metric\"):\n        self.name = name\n        self.reset()\n\n    def reset(self):\n        self.avg, self.sum, self.count = [0]*3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += val * count\n        self.avg = self.sum \/ self.count\n    \n    def __repr__(self):\n        text = \"{}:{:.4f}\".format(self.name,self.avg)\n        return text\n    \ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]","e3783908":"def one_epoch(model,\n              criterion,\n              loader,\n              optimizer=None,\n              lr_scheduler=None,\n              mode=\"train\",\n              step=\"batch\"):\n    loss_meter = AvgMeter()\n    distances = None\n    labels = None\n    tqdm_object = tqdm(enumerate(loader), total=len(loader))\n    for i, batch in tqdm_object:\n        images1_f, images2_f = model(batch)\n        \n        embeddings = torch.cat((images1_f, images2_f))\n        labels = torch.cat((batch[\"label1\"], batch[\"label2\"]))\n        loss = criterion(embeddings, labels).to(device)\n\n        if mode == \"train\":\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if step ==  \"batch\":\n                lr_scheduler.step()\n\n        count = len(labels)\n        loss_meter.update(loss.item(), count)\n\n        if mode == \"train\":\n            tqdm_object.set_postfix(train_loss=loss_meter.avg, lr=get_lr(optimizer))\n        else:\n            tqdm_object.set_postfix(validloss=loss_meter.avg)\n    \n    return loss_meter","62c3c613":"def train_eval(epochs, model, train_loader, valid_loader,\n               criterion, optimizer, lr_scheduler=None, fold=None, li=None):\n    best_loss = float(\"inf\")\n\n    for epoch in range(epochs):\n        print(\"*\"*30)\n        print(\"Epoch{}\".format(epoch+1))\n        current_lr = get_lr(optimizer)\n\n        model.train()\n        train_loss = one_epoch(model,\n                                        criterion,\n                                        train_loader,\n                                        optimizer=optimizer,\n                                        lr_scheduler=lr_scheduler,\n                                        mode=\"train\",\n                                        step=CFG.step)\n        \n        model.eval()\n        with torch.no_grad():\n            valid_loss = one_epoch(model,\n                                            criterion,\n                                            valid_loader,\n                                            optimizer=None,\n                                            mode=\"valid\")\n        li[fold].append(float(valid_loss.avg))\n            \n        if valid_loss.avg < best_loss:\n            best_loss = valid_loss.avg\n\n            if fold is not None:\n                weight_name = \"\/kaggle\/working\/weights\/best\" + str(fold) + \".pt\"\n            else:\n                weight_name = \"\/kaggle\/working\/weights\/best.pt\"\n\n            torch.save(model.state_dict(), weight_name)\n            print(\"Saved best model!\")\n        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            lr_scheduler.step(train_loss.avg)","0f8ba0d6":"n_splits = 5\n\nlosses_list = [[] for i in range(n_splits)]\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=CFG.SEED)\nids = df[\"individual_id\"].unique()\nfor fold, (train_ids, valid_ids) in enumerate(kf.split(ids)):\n    train_df= df[df[\"index\"].isin(train_ids)].reset_index(drop=True)\n    valid_df = df[df[\"index\"].isin(valid_ids)].reset_index(drop=True)\n    train_dataset = ContrasiveDataset(train_df,df_id_idx, train_data_transform)\n    valid_dataset = ContrasiveDataset(valid_df,df_id_idx, valid_data_transform)\n    train_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=CFG.batch_size,\n                                           num_workers=CFG.num_workers,\n                                           pin_memory=True,\n                                           shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                           batch_size=CFG.batch_size,\n                                           num_workers=CFG.num_workers,\n                                           pin_memory=True,\n                                           shuffle=False)\n    \n    model = Model(CFG.model_name, CFG.pretrained, CFG.dropout, CFG.linear)\n    model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)\n\n    if CFG.scheduler ==\"ReduceLROnPlateau\":\n        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                                mode=\"min\",\n                                                                factor=CFG.factor,\n                                                                patience=CFG.patience)\n    CFG.step = \"epoch\"\n\n    criterion = losses.ContrastiveLoss(pos_margin=0, neg_margin=CFG.margin)\n    criterion = losses.CrossBatchMemory(criterion, CFG.efficientnet_feature, memory_size=2000)\n\n    train_eval(CFG.epochs,\n            model,\n            train_loader,\n            valid_loader,\n            criterion,\n            optimizer,\n            lr_scheduler,\n            fold,\n            losses_list)\n    \n    print(losses_list)\n\n    gc.collect()\n    torch.cuda.empty_cache()","eadd9eb7":"try:\n    del model, Model, train_loader, valid_loader, train_dataset, valid_dataset, optimizer, criterion, train_eval, lr_scheduler, labels, one_epoch, train_df, valid_df, train_labels, valid_labels, AvgMeter, get_lr, ContrasiveDataset, train_transforms, train_albumentations_transform, train_data_transform\nexcept:\n    print(\"some variable do not exist\")","de26177f":"gc.collect()\ntorch.cuda.empty_cache()","04cd8f46":"df_2 = pd.read_csv(\"\/kaggle\/input\/happy-whale-and-dolphin\/sample_submission.csv\")\ndf_2 = df_2.drop('predictions', axis=1)\ndf_2[\"path\"] = \"\/kaggle\/input\/happy-whale-and-dolphin\/test_images\/\" + df_2[\"image\"].astype(str)","c9b16ea8":"df_list = df.values.tolist()\ndf_2_list = df_2.values.tolist()","61ca2d76":"class TrainDataset(Dataset):\n    def __init__(self, List, transforms=None):\n        self.transforms=transforms\n        self.List = List\n\n    def __len__(self):\n        return len(self.List)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.List[idx][3])[...,::-1]\n        if self.transforms is not None:\n            img = self.transforms(img)[\"image\"]\n        return {\"images1\":img}","36989973":"train_dataset = TrainDataset(df_list, valid_data_transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                          batch_size=CFG.batch_size,\n                                          num_workers=os.cpu_count(),\n                                          pin_memory=True,\n                                          shuffle=False)","23f31cae":"class Model(nn.Module):\n    def __init__(self,\n                 model_name=CFG.model_name,\n                 pretrained=True,\n                 dropout=0.2,\n                 linear=128):\n\n                 super().__init__()\n                 model = timm.create_model(model_name,\n                                           pretrained=pretrained,\n                                           num_classes=0)\n                 self.num_features=model.num_features\n                 self.linear = None\n                 if linear is not None and linear >0:\n                     self.linear = nn.Linear(self.num_features, linear)\n                 self.backbone = nn.Sequential(model,\n                                              self.linear if self.linear is not None else nn.Identity(),\n                                              nn.ReLU() if self.linear is not None else nn.Identity(),\n                                              nn.Dropout(0.2) if dropout is not None else nn.Identity())\n    def forward(self, batch):\n        images = self.backbone(batch[\"images1\"].to(device))\n        return images","bf7031b0":"models = []\nfor i in range(5):\n    model = Model(CFG.model_name, CFG.pretrained, CFG.dropout, CFG.linear)\n    models.append(model)\n    model_path = \"\/kaggle\/working\/weights\/best\"+str(i)+\".pt\"\n    models[i].load_state_dict(torch.load(model_path))\n    models[i].to(device)","af87be71":"def calc_norm(array):\n    array = array\/np.linalg.norm(array)\n    return array.tolist()","eb1ac456":"n_trees = 100\nindex = AnnoyIndex(CFG.efficientnet_feature, metric=\"euclidean\")\nfor i in range(len(models)):\n    models[i].eval()\n\nlabel_index = 0\n\nfor batch in train_loader:\n    with torch.inference_mode():\n        for i in range(len(models)):\n            if i == 0:\n                outputs = models[i](batch).cpu()\n            else:\n                outputs += models[i](batch).cpu()\n        outputs = outputs\/float(len(models))\n\n    for i, feature in enumerate(outputs):\n        feature=feature.numpy().copy()\n        feature = calc_norm(feature)\n        index.add_item(label_index, feature)\n        label_index += 1\n\nindex.build(n_trees, n_jobs=-1)\nindex.save(\"\/kaggle\/working\/feature.ann\")","f3129231":"class TestDataset(Dataset):\n    def __init__(self, List, transforms=None):\n        self.transforms=transforms\n        self.List = List\n\n    def __len__(self):\n        return len(self.List)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.List[idx][1])[...,::-1]\n        if self.transforms is not None:\n            img = self.transforms(img)[\"image\"]\n        return {\"images1\":img}","55e16739":"test_dataset = TestDataset(df_2_list, valid_data_transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=CFG.batch_size,\n                                          num_workers=os.cpu_count(),\n                                          pin_memory=True,\n                                          shuffle=False)","40e1f326":"n_trees = 3\nindex_test = AnnoyIndex(CFG.efficientnet_feature, metric=\"euclidean\")\nfor i in range(len(models)):\n    models[i].eval()\nlabel_index = 0\n\nfor batch in test_loader:\n    with torch.inference_mode():\n        for i in range(len(models)):\n            if i == 0:\n                outputs = models[i](batch).cpu()\n            else:\n                outputs += models[i](batch).cpu()\n        outputs = outputs\/float(len(models))\n    for i, feature in enumerate(outputs):\n        feature=feature.numpy().copy()\n        feature = calc_norm(feature)\n        index_test.add_item(label_index, feature)\n        label_index += 1\n\nindex_test.build(n_trees, n_jobs=-1)","889a656e":"def query_expansion(query_vec, similar_vec):\n    query_vec = np.array(query_vec)\n    similar_vec = np.array(similar_vec)\n    similarity = np.dot(query_vec, similar_vec)\n    similarity = float(similarity)\n\n    vec = (1*query_vec + similarity*similar_vec)\/(1+similarity)\n    vec = calc_norm(vec)\n    return vec","ab69eed8":"!touch submission.csv\n!echo \"image,predictions\">> submission.csv","bc689573":"with open(\"submission.csv\", \"a\") as f:\n    for i in range(len(df_2)):\n        test_query_vec = index_test.get_item_vector(i)\n        result = index.get_nns_by_vector(test_query_vec,1)#****\n        tmp_index_vec = index.get_item_vector(result[0])#****\n\n        test_query_vec = query_expansion(test_query_vec, tmp_index_vec)\n\n        result = index.get_nns_by_vector(test_query_vec,4)\n        results =str(df_2.iloc[i][\"image\"])+\",\"\n        for k in range(5):\n            if k == 4:\n                results = results+ \"new_individual\" +\"\\n\"\n            else:\n                results = results+ str(df_list[result[k]][2]) + \" \"\n        f.writelines(\"{}\".format(results))","c0710f05":"# data","b8e21316":"# Augmentation","9c61fbf9":"Public LB: \n- 0.114 (12621.2s - GPU)(epoch=1(\/folds),ntree=10)(February 2, 2022)  \n- 0.121 (35601.9s - GPU)(epoch=5(\/folds),ntree=100)(February 3, 2022)\n\nI'm using **EfficientNet_b4** & **ContrastiveLoss** & **CrossBatchMemory(2000)** & **\u03b1QE(\u03b1=1,K=1)**.  \n\nIn this model, no distinction is made between different types of animals. \n\n**Increasing the value of \"epoch\" or increasing the value of \"ntree\" in Annoy will improve the performance.**  \n\nI'm a beginner, so I'm sharing my notebook for study.  \nThe code is messed up, but if you run it from above, you will get submisson.csv.  \nIf there are any mistakes, I would appreciate it if you could point them out.  \n\nI referred to [this notebook](https:\/\/www.kaggle.com\/moeinshariatnia\/contrastive-loss-pretraining-in-depth-explanation) .    \nI recommend this notebook for its detailed description of metric learning.","4acb32ab":"# Making Embeddings","a791c632":"# Settings","5acd85a1":"# Train","f67ad9b8":"# Functions"}}