{"cell_type":{"204d295b":"code","700e920c":"code","34329930":"code","70bf03b7":"code","1d8ec9de":"code","2f81b52a":"code","d190070a":"code","5404d146":"code","48065b80":"code","c34d774e":"code","4e5e4cf6":"code","e284bb95":"code","3d1c2378":"markdown"},"source":{"204d295b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","700e920c":"!pip install pyspark\nimport pyspark\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n#sc = SparkContext(appName = \"car_name\")\nspark = SparkSession.Builder().getOrCreate()","34329930":"ratings = spark.read.option(\"inferSchema\",True)\\\n                    .option(\"header\",True)\\\n                    .csv(\"..\/input\/uit-spring-2021-ds200-assignment-8\/ratings.csv\")\ntesting = spark.read.option(\"inferSchema\",True)\\\n                    .option(\"header\",True)\\\n                    .csv(\"..\/input\/uit-spring-2021-ds200-assignment-8\/test.csv\")\nratings.show(5)\ntesting.show(5)","70bf03b7":"from pyspark.ml.recommendation import ALS\nratings = ratings.drop('timestamp')\nals = ALS(maxIter=10, regParam=0.5, userCol=\"userId\",\n                      itemCol = \"movieId\", ratingCol =    \"rating\", )\n\ntrain = ratings","1d8ec9de":"\"\"\"\ntrain, val = ratings.randomSplit([0.8, 0.2])\n#Training the Model\nalsModel = als.fit(train)\n\n#Generating Predictions\nprediction = alsModel.transform(val)\nprediction.show(10)\nnewpre = prediction.filter(col('prediction') != np.nan)\n\"\"\"\n","2f81b52a":"\n\"\"\"\nfrom pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(metricName=\"mse\", labelCol=\"rating\",  predictionCol=\"prediction\")\nmse = evaluator.evaluate(newpre)\nprint(mse)\n\"\"\"","d190070a":"#Training the Model\nalsModel = als.fit(train)\n\n#Generating Predictions\nsub_fail = alsModel.transform(testing)\nsub_fail = sub_fail.drop('userId','movieId')\nsub_fail=sub_fail.withColumnRenamed(\"prediction\",\"rating\")\nnewpredic = sub_fail.filter(col('prediction') != np.nan)\nsub_fail = sub_fail.toPandas()\n","5404d146":"sub_fail","48065b80":"#mean =newpredic.toPandas().mean()\n#meanrating = mean[1]\nmeanrating = 3","c34d774e":"sub_fail['rating']= sub_fail['rating'].replace(np.nan,meanrating)\nsub_fail","4e5e4cf6":"sub_fail","e284bb95":"sub_fail.to_csv('submission.csv', index = False)","3d1c2378":"Danh s\u00e1ch sinh vi\u00ean:\n\n-Ph\u1ea1m Xu\u00e2n Thi\u00ean - 18520158\n\n-Tr\u1ea7n Tu\u1ea5n V\u0129 - 18520245"}}