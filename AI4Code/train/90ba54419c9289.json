{"cell_type":{"ec9c504d":"code","479c43f8":"code","0cecb043":"code","e2c7dede":"code","46824a9f":"code","491a3750":"code","cd68385e":"code","119d8a6e":"code","267cbb73":"code","f3f3971c":"code","89ab8fe9":"code","bc7c1089":"code","31b40862":"code","7e561123":"code","6cf9027a":"code","edc2f974":"code","9d311cd6":"code","fb3b61ba":"code","f8f76a8a":"code","051e2e78":"code","c5d87a29":"markdown","35291659":"markdown","8a918ac8":"markdown","bf3fb0eb":"markdown","7980d9eb":"markdown","1d6a8d9e":"markdown","340d8af9":"markdown","843c6fb9":"markdown","002cf9bb":"markdown","eaa8c6c5":"markdown","c67b75e9":"markdown"},"source":{"ec9c504d":"import numpy as np # Algebra linear\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport itertools\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.utils import to_categorical #(one-hot-encoding)\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","479c43f8":"# Importando a base de dados\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","0cecb043":"train.shape, test.shape # Modo como os dados est\u00e3o estrutudados (42000 linhas, 785 colunas), (28000 linhas, 784 colunas) ","e2c7dede":"train.head() ","46824a9f":"X_train = train.iloc[:,1:].values.astype('float32')\ny_train = train['label'].values.astype('int32')\ntest = test.values.astype('float32')\n\ndel train","491a3750":"X_train = X_train \/ 255.0 # Normalizando os dados de treino\ntest = test \/ 255.0 # Normalizando os dados de teste","cd68385e":"# Converte o dataset de treino para o formato (num_imagens, img_linhas, img_colunas)\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\ntest = test.reshape(test.shape[0], 28, 28, 1)","119d8a6e":"y_train","267cbb73":"y_train = to_categorical(y_train)\ny_train","f3f3971c":"np.random.seed(2) #usado para que seja possivel reproduzir a aleatoriedade do experimento com os mesmos resultados","89ab8fe9":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.0001, random_state = 2)","bc7c1089":"model = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation = 'softmax'))","31b40862":"# Colocamos como metrica de acerto: acur\u00e1cia\n# Fun\u00e7\u00e3o de perda(exibe o quanto o algoritimo esta errado): categorical_crossentropy\n# optimizer: adam (um dos melhores optimizadores atualmente)\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])","7e561123":"epochs = 38 # N\u00famero epocas do modelo\nbatch_size = 64 ","6cf9027a":"datagen = ImageDataGenerator(featurewise_center=False,\n                            samplewise_center=False,\n                            featurewise_std_normalization=False,\n                            samplewise_std_normalization=False,\n                            zca_whitening=False,\n                            rotation_range=10,\n                            zoom_range=0.1,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            horizontal_flip=False,\n                            vertical_flip=False)\ndatagen.fit(X_train)","edc2f974":"# Ajusta e Treina o modelo\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","9d311cd6":"# Usa o modelo treinado para prever e classificar os dados sem classifica\u00e7\u00e3o\n# nesse caso, os dados que ser\u00e3o submetidos na competi\u00e7\u00e3o.\nresults = model.predict(test) \n\n# O algoritimo retorna uma lista de probabilidades pra cada n\u00famero","fb3b61ba":"# Seleciona os indices com maior probabilidade\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","f8f76a8a":"# Gera um dataframe com o Id e a resposta de cada imagem\noutput = pd.concat([pd.Series(range(1,28001), name = 'ImageId'), results], axis = 1)\noutput","051e2e78":"#Para finalizar, vamos gerar um aquivo csv a partir do dataframe.\noutput.to_csv('submission.csv', index=False)","c5d87a29":"Agora, vamos separar o conjunto de dados entre a parte que sera usada para treinar o modelo e a parte de teste, que sera utilizada para descobrirmos o qu\u00e3o bom o modelo \u00e9, antes de submetelo na Competi\u00e7\u00e3o.","35291659":"Como pode-se ver acima, cada coluna da linha representa um pixel da imagem, e o n\u00famero no pixel representa a cor(RGB) dele.\n\nOBS: As imagens dos n\u00fameros est\u00e3o em escala de cinza. ","8a918ac8":" Keras \u00e9 uma biblioteca desenvolvida pela google que possui \u00f3timas fun\u00e7\u00f5es a serem ultilizadas \n em algoritimos de aprendizado de maquina ","bf3fb0eb":"# Importa\u00e7\u00f5es Iniciais","7980d9eb":"\u00c9 comum que bases de dados como essa, tenham os resultados das classifica\u00e7\u00f5es de imagens como mostrado no ultimo c\u00f3digo. Entretanto, o algoritmo utilizado lida melhor com outro tipo de dado, por isso, vamos categoriza-lo de uma forma diferente. Nesse caso, usaremos o one-hot encoding:\n\nExemplo:\n\n    O que era apenas o n\u00famero 2 vira um array de zeros no qual o indice 2 do array \u00e9 igual a 1\n    2 -> [0,0,1,0,0,0,0,0,0,0]","1d6a8d9e":"# Aumento de Dados\n   Essa tecnica pode ser utilizada para aumentar a quantidade de dados de forma artificial. No codigo abaixo, por exemplo, essa tecnica foi empregada pegando os dados das imagens originais do dataset, e gerando novas imagens modificadas.\n\n**Caracteristicas modificadas:**\n* Zoom da imagem\n* Inclina\u00e7\u00e3o\/rota\u00e7\u00e3o da imagem(Nesse caso, temos que tomar cuidado com a rota\u00e7\u00e3o pois o n\u00famero 6 pode ser confundido com o 9 ou o contr\u00e1rio)\n* Centro da imagem\n* Largura\n* Altura","340d8af9":"Esse c\u00f3digo, comentado e explicado em portugu\u00eas, foi feito para pessoas que tem interesse em aprender mais sobre o uso de Redes Neurais Covolucionais, mas que ainda n\u00e3o tenham tanta facilidade com ingl\u00eas.\n\nCaso tenha alguma sugest\u00e3o de melhoria coloque nos coment\u00e1rios.","843c6fb9":"# Fontes:\n\n* https:\/\/keras.io\/\n* https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n* https:\/\/www.kaggle.com\/elcaiseri\/mnist-simple-cnn-keras-accuracy-0-99-top-1","002cf9bb":"MNIST \u00e9 uma base de dados com n\u00fameros \"desenhados\" e com seus respectivos rotulos que indicam qual n\u00famero esta desenhado. Nesse desafio, temos a base de dados com os r\u00f3tulos que ser\u00e1 usada para treinar o modelo(base de treino), e a sem r\u00f3tulos, que devemos prever qual n\u00famero ser\u00e1.\n\nPara isso, no c\u00f3digo foi usado, principalmente, a API keras(Tensorflow backend) e foi obtido uma acur\u00e1cia de  99,47%","eaa8c6c5":"# Rede Neural Covolucional\n\nQuando se trata de imagens, as CNN(Covolutional Neural Network) ganham destaque. Isso ocorre pois, se utiliza de forma correta, esse modelo tende a ter um dos melhores indices de acerto na classifica\u00e7\u00e3o de imagens.\n\n**Assim, no modelo abaixo:**\n\n1. Come\u00e7amos com camadas de Convolu\u00e7\u00e3o que recebem a imagem e aplicam filtros nela.\n2. Colocamos a camada de pooling, a qual reduz as dimen\u00e7\u00f5es dos dados .\n3. A camada de Dropout, simplesmente exclui parte do processamento na imagem at\u00e9 o momento. Ela \u00e9 necess\u00e1ria para minimizar a possibilidade de superajustamento aos dados de treino.\n\n\n4. Depois todas as camadas anteriores s\u00e3o repetidas para uma melhor performance.\n\n\n5. A camada de Flattening, transforma os dados(que at\u00e9 ent\u00e3o eram matrizes) em vetores, para que as camadas Densas consigam processar os dados.\n6. A primeira camada Densa possui 256 \"neur\u00f4nios\", que processam o dado e manda para a ultima camada.\n7. Essa ultima camada possui 10 \"ne\u00fbronios\" pois \u00e9 a quantidade de saidas(os n\u00fameros de 0 \u00e1 9) que precisamos.","c67b75e9":"# Introdu\u00e7\u00e3o"}}