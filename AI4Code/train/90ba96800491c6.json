{"cell_type":{"64bd6ce5":"code","613bf7f0":"code","bec1cc3c":"code","fe94e237":"code","a301e83d":"code","f2268fae":"code","836d8a0f":"code","b2b9b5d8":"code","9a9d4d64":"code","77aa929a":"code","06fadcb4":"code","dce169c8":"markdown","4cedba2c":"markdown","cc201fe1":"markdown","9866da53":"markdown","cc91896e":"markdown","2ab5405a":"markdown","0481dc75":"markdown","c16f82d1":"markdown"},"source":{"64bd6ce5":"import pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor","613bf7f0":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')","bec1cc3c":"train.head()","fe94e237":"X = train.iloc[:,1:-1]\ny = train.loss","a301e83d":"X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=1)","f2268fae":"def get_mae(nodes):\n    model = DecisionTreeRegressor(max_leaf_nodes=nodes, random_state=1)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_val)\n    mae = mean_absolute_error(preds, y_val)\n    return mae","836d8a0f":"n_nodes_l = [5, 10, 50, 100, 200]\nmaes=[]\nfor n in n_nodes_l:\n    maes.append(get_mae(n))\n\nbest_n_index = maes.index(min(maes))\nbest_n = n_nodes_l[best_n_index]","b2b9b5d8":"best_n","9a9d4d64":"final_model = DecisionTreeRegressor(max_leaf_nodes=10, random_state=1)\nfinal_model.fit(X,y)","77aa929a":"test_preds = final_model.predict(test.iloc[:,1:])","06fadcb4":"output = pd.DataFrame({'id': test.id,\n                       'loss': test_preds})\noutput.to_csv('submission.csv', index=False)","dce169c8":"Split the data into train and validation sets.","4cedba2c":"Making a function which predicts and then calculates the mae.","cc201fe1":"Let's have a look at our data.","9866da53":"That's it! Thank you very much.","cc91896e":"Let's try different numbers of max leaf nodes for our tree.","2ab5405a":"## Load the data","0481dc75":"The best number was 10, let's now use all of our data to train our final model.","c16f82d1":"# Decision Trees just like Kaggle's Intro to Machine Learning course.\nFor those of you who just finished the 'Intro to Machine Learning' Kaggle course, I've basically nearly copied lesson 5. Hopefully an easy notebook so you don't get intimidated (because I do)."}}