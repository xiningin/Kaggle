{"cell_type":{"460a26db":"code","5de6fc30":"code","0c98b883":"code","9c27c788":"code","7a64d0f7":"code","58286cf9":"code","b7771113":"code","d6c74dbd":"code","0ad1394f":"code","d64d9635":"code","c0c72907":"code","d7e47daf":"code","1365f825":"code","753919a6":"code","4e9a2501":"code","04c1ccde":"code","de4fb18d":"markdown","ff43d1a2":"markdown","24ffee73":"markdown","f56eff4f":"markdown","ec1a9a97":"markdown","f2adeffb":"markdown","ec1e46f2":"markdown","34ba22e7":"markdown"},"source":{"460a26db":"# Computing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Graphical libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom pylab import rcParams\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5de6fc30":"path = '\/kaggle'\ninput_path = path + '\/input\/gearbox-fault-diagnosis-elaborated-datasets\/gearbox-fault-diagnosis-elaborated-datasets\/stdev\/'\nbroken_dataset  = \"broken30hz_stdev_100.csv\"\nhealthy_dataset = \"healthy30hz_stdev_100.csv\"","0c98b883":"healthyDataset = pd.read_csv(input_path + healthy_dataset)\nbrokenDataset = pd.read_csv(input_path + broken_dataset)\n\ndataset = pd.concat([healthyDataset, brokenDataset], axis=0)\ndataset.describe()","9c27c788":"plt.figure(figsize=(12,28*4))\ngs = gridspec.GridSpec(28, 1)\nfor i, cn in enumerate(dataset[['a1','a2','a3','a4']]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(dataset[cn][dataset.load == 0], bins=50)\n    sns.distplot(dataset[cn][dataset.load == 50], bins=50)\n    sns.distplot(dataset[cn][dataset.load == 90], bins=50)\n    ax.set_xlabel('')\n    plt.legend(['0%', '50%', '90%'])\n    ax.set_title('histogram for ' + str(cn) + ': healthy & broken')\n    ax.set_title('histogram for ' + str(cn))\nplt.show()","7a64d0f7":"# Broken and healthy gearbox at once\nrcParams['figure.figsize'] = 8, 6\ncolumns = ['failure','a1', 'a2', 'a3', 'a4', 'load']\nsns.heatmap(dataset[columns].corr(),annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nplt.show()","58286cf9":"# Healthy gearbox\ndataset0 = dataset[dataset.failure == 0]\ncolumns = ['a1', 'a2', 'a3', 'a4', 'load']\nsns.heatmap(dataset0[columns].corr(),annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nplt.show()","b7771113":"# Broken gearbox\ndataset1 = dataset[dataset.failure == 1]\ncolumns = ['a1', 'a2', 'a3', 'a4', 'load']\nsns.heatmap(dataset1[columns].corr(),annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nplt.show()","d6c74dbd":"plt.figure(figsize=(12,28*4))\ngs = gridspec.GridSpec(28, 1)\nfor i, cn in enumerate(dataset[['a1']]): # [['a1','a2','a3','a4']]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(dataset[cn][dataset.load == 0], bins=50)\n    sns.distplot(dataset[cn][dataset.load == 50], bins=50)\n    sns.distplot(dataset[cn][dataset.load == 90], bins=50)\n    ax.set_xlabel('')\n    plt.legend(['0%', '50%', '90%'])\n    ax.set_title('histogram for ' + str(cn) + ': healthy & broken')\nplt.show()","0ad1394f":"plt.figure(figsize=(12,28*4))\ngs = gridspec.GridSpec(28, 1)\nfor i, cn in enumerate(dataset[['a1']]): # [['a1','a2','a3','a4']]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(dataset[cn][ (dataset.load == 50) & (dataset.failure == 1) ], bins=50)\n    sns.distplot(dataset[cn][ (dataset.load == 50) & (dataset.failure == 0)  ], bins=50)\n    sns.distplot(dataset[cn][ (dataset.load == 90) & (dataset.failure == 1) ], bins=50)\n    sns.distplot(dataset[cn][ (dataset.load == 90) & (dataset.failure == 0)  ], bins=50)\n    ax.set_xlabel('')\n    plt.legend(['50%, broken', '50%, healthy','90%, broken', '90%, healthy'])\n    ax.set_title('histogram for ' + str(cn) + ': healthy & broken')\n    ax.set_title('histogram for ' + str(cn))\nplt.show()","d64d9635":"# Predictor variable (features)\ncolumns = ['a1', 'a2', 'a3', 'a4']\n\nX = healthyDataset[columns]\n# Target variable: Load\ny = healthyDataset[['load']]","c0c72907":"# Split the dataset: 80% train, 20% test\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n\n# Logistic regression classifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Setup the model\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)","d7e47daf":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n# Define the model evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate the model and collect the scores\nn_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n# report the model performance\nprint('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","1365f825":"# Train the model\nmodel.fit(X_train, y_train)\n\n# Predict Load for the test set\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:,1]\n\n# Print np arrays with 2 decimal places, without scientifc notation\nnp.set_printoptions(suppress=True, precision=2)\nprint(\"Predicted probabilities test (first 10 rows): \", y_prob[:10])\nprint(\"Prediction for the test data (first 10 rows): \", y_pred[:10])\n#print(X_test.iloc[:10,:])\n\n# Actual loal for the test set\nprint(\"Actual load for the test data (first 10 rows):\", np.array(y_test)[:,0][:10] )","753919a6":"from sklearn.metrics import mean_squared_error, r2_score","4e9a2501":"# The coefficients\nprint('Coefficients: \\n', model.coef_)\n# The mean squared error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(y_test, y_pred))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_pred))","04c1ccde":"# Plot outputs: take X axis as the best stdev predictor (a4, see correlation matrix)\nplt.plot(X_test['a4'], y_test, 'o', color='black');\nplt.plot(X_test['a4'], y_pred, 'x', color='blue', linewidth=1)\nplt.xlabel('stdev of acceleration a4')\nplt.ylabel('load level %')\n\nplt.show()","de4fb18d":"# Exploring the dataset","ff43d1a2":"# Multinomial logistic regression","24ffee73":"## Training and prediction","f56eff4f":"## Evaluate the model","ec1a9a97":"## Evaluate the model","f2adeffb":"## Selected histograms","ec1e46f2":"## Correlation matrix","34ba22e7":"## Build healthy\/broken dataset"}}