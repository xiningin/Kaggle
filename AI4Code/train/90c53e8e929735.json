{"cell_type":{"09597f96":"code","7ee58320":"code","8295471a":"code","ad37f6ef":"code","54ac25ff":"code","d2a0bf60":"code","e4ce39c1":"code","c35feb71":"code","6f10379e":"code","a81cc7e8":"code","768871f3":"code","fcc96ba2":"code","defd3ad1":"code","f4566b3f":"code","aaca1429":"code","2b08b1ad":"code","dcb01cd8":"code","4fecdd5f":"code","9e63b8f6":"code","33bb23c1":"code","81e06da7":"code","074878d2":"code","797119a8":"code","fe215913":"markdown","4f6e1255":"markdown","7684d855":"markdown","90d8db07":"markdown"},"source":{"09597f96":"!pip install imutils","7ee58320":"import os\nimport cv2\nimport numpy as np\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory \n\nplt.style.use('ggplot')","8295471a":"os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_pred\")","ad37f6ef":"image_size = (299,299)\nbatch_size = 32\n\ntrain_data_path = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\"\ntest_data_path = \"\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\"\n\ntrain_set = image_dataset_from_directory(train_data_path, \n                                         label_mode ='categorical',\n                                         validation_split=0.2,\n                                         subset=\"training\",\n                                         seed=1337,\n                                         image_size=image_size,\n                                         batch_size=batch_size)\n\nvalidation_set = image_dataset_from_directory(train_data_path,\n                                   label_mode ='categorical',\n                                   validation_split=0.2,\n                                   subset=\"validation\",\n                                   seed=1337,\n                                   image_size=image_size,\n                                   batch_size=batch_size)\n\ntest_set = image_dataset_from_directory(test_data_path,\n                                   label_mode ='categorical',\n                                   seed=1337,\n                                   image_size=image_size,\n                                   batch_size=batch_size)\n\nm_train_set = train_set.map(lambda x, y: (preprocess_input(x), y))\nm_validation_set = validation_set.map(lambda x, y: (preprocess_input(x), y))\nm_test_set = test_set.map(lambda x, y: (preprocess_input(x), y))","54ac25ff":"INIT_LR = 1e-4\nEPOCHS = 20\nBS = 32","d2a0bf60":"baseModel = Xception(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(299,299,3)))\n\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7,7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.2)(headModel)\nheadModel = Dense(6, activation=\"softmax\")(headModel)\n\n\nmodel = Model(inputs=baseModel.input, outputs=headModel)\nfor layer in baseModel.layers:\n\tlayer.trainable = True\n    \nmetrics = ['accuracy',metrics.Precision(name='precision'),metrics.Recall(name='recall')] \n\nopt = Adam(lr=INIT_LR, decay=INIT_LR\/EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=metrics)","e4ce39c1":"model.summary()","c35feb71":"plot_model(model, to_file='model.png', dpi=300)","6f10379e":"HR2 = model.fit_generator(m_train_set, steps_per_epoch=16, validation_data = m_validation_set, validation_steps=8, epochs=EPOCHS)","a81cc7e8":"predIdxs = model.evaluate_generator(m_test_set)\n\nprint(\"Test Loss: \", round(predIdxs[0],2))\nprint(\"Test Accuracy: \", round(predIdxs[1]*100,2), '%')\nprint(\"Test Precision: \", round(predIdxs[2]*100,2), '%')\nprint(\"Test Recall: \", round(predIdxs[3]*100,2), '%')","768871f3":"N = EPOCHS\n\nplt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"loss\"], label=\"Training Loss\")\nplt.plot(np.arange(0, N), HR2.history[\"val_loss\"], label=\"Validation Loss\")\nplt.title(\"Training Loss and Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"upper right\")","fcc96ba2":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"accuracy\"], label=\"Training Accuracy\")\nplt.plot(np.arange(0, N), HR2.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.title(\"Training Accuracy and Validation Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc=\"lower right\")","defd3ad1":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"precision\"], label=\"Training Precision\")\nplt.plot(np.arange(0, N), HR2.history[\"val_precision\"], label=\"Validation Precision\")\nplt.title(\"Training Precision and Validation Precision\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Precision\")\nplt.legend(loc=\"lower right\")","f4566b3f":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"recall\"], label=\"Training Recall\")\nplt.plot(np.arange(0, N), HR2.history[\"val_recall\"], label=\"Validation Recall\")\nplt.title(\"Training Recall and Validation Recall\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Recall\")\nplt.legend(loc=\"lower right\")","aaca1429":"pred_path = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\"","2b08b1ad":"def mapper(val):\n    if val == 0:\n        return 'Buildings'\n    elif val == 1:\n        return 'Forest'\n    elif val == 2:\n        return 'Glacier'\n    elif val == 3:\n        return 'Mountain'\n    elif val == 4:\n        return 'Sea'\n    elif val == 5:\n        return 'Street'","dcb01cd8":"def genPred(PATH,image):\n    o_test_image = cv2.imread(os.path.join(PATH, image))\n    o_test_image = cv2.cvtColor(o_test_image, cv2.COLOR_BGR2RGB)\n\n    test_image = cv2.resize(o_test_image, image_size)\n    test_image = preprocess_input(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n\n    y_hat = model.predict(test_image)\n    y_hat = np.argmax(y_hat, axis=1)\n    pred_lab = mapper(y_hat)\n\n    print(\"===========================================================================================\")\n    print(\"PREDICTED LABEL: \"+pred_lab)\n    print(\"===========================================================================================\")\n    print(\"\")\n\n    plt.imshow(o_test_image)","4fecdd5f":"genPred(pred_path, '10052.jpg')","9e63b8f6":"genPred(pred_path, '10059.jpg')","33bb23c1":"genPred(pred_path, '10005.jpg')","81e06da7":"genPred(pred_path, '10012.jpg')","074878d2":"genPred(pred_path, '1003.jpg')","797119a8":"genPred(pred_path, '10034.jpg')","fe215913":"## ***Load and Preprocess Data***","4f6e1255":"## ***Performance Analysis***","7684d855":"## ***Construction of Model***","90d8db07":"## ***Generate Predictions***"}}