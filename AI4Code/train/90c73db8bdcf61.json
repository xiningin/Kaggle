{"cell_type":{"dcc0f145":"code","53b3923d":"code","b333ae36":"code","89993132":"code","6c053dca":"code","25643662":"code","e7e0c1af":"code","694932cd":"code","c997fbda":"code","bfe29149":"code","384c6a41":"markdown","633477ec":"markdown","a805b70e":"markdown","ae9d9425":"markdown","b333e083":"markdown"},"source":{"dcc0f145":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport matplotlib.pyplot as plt\nimport json\nimport torch\nfrom skimage import exposure\nimport math\nfrom shutil import copyfile\nfrom IPython.display import Image, clear_output","53b3923d":"# D\/L and install YOLOv5\n!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd yolov5\n%pip install -qr requirements.txt\n%cd ..\/\nclear_output()\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","b333ae36":"# Copy the requirements file over so we don't have to change directory later. Is there an argument for this?\ncopyfile('yolov5\/requirements.txt', '\/kaggle\/working\/requirements.txt');","89993132":"# Load the image dataframe so we can get BB coords\nbase_path = \"\/kaggle\/input\/siim-covid19-detection\/\"\nimages_df = pd.read_csv(os.path.join(base_path,\"train_image_level.csv\"))","6c053dca":"# Load a DICOM file\ndef load_file(filename):\n    img = pydicom.dcmread(filename)\n    pixels = img.pixel_array\n    max_pixel = np.max(pixels)\n\n    if img.PhotometricInterpretation == \"MONOCHROME1\":\n        pixels = max_pixel - pixels\n        \n    pixels = exposure.equalize_adapthist(pixels)\n    pixels = (pixels * 255).astype(np.uint8)\n    return pixels","25643662":"# Convert YOLO coords to pixel coords\ndef box2coords(x,y,w,h,image_w, image_h):\n    x1, y1 = round((x-w\/2) * image_w), round((y-h\/2) * image_h)\n    x2, y2 = round((x+w\/2) * image_w), round((y+h\/2) * image_h)\n    return x1, y1, x2, y2","e7e0c1af":"# Function to get the BB data from the images DF\ndef get_boxes(image_id):\n    \n    image = image_id.replace('.dcm','_image')\n    ti = images_df[images_df['id'] == image]\n    bx = [[],[]]\n    bx[0] = [0,0,0,0,\"\"]\n    bx[1] = [0,0,0,0,\"\"]\n    \n    if str(ti['boxes'].values[0]) != \"nan\":\n        box = str(ti['boxes'].values[0]).replace(\"'\",\"\\\"\")\n        boxes = json.loads(box)\n        lab = ti['label'].values[0].split(\" \")\n        i = 0\n        for b in boxes:\n            bx[i] = [int(b['x']), int(b['y']), int(b['width']),int(b['height']),lab[0]]\n            i = i+1\n    return bx","694932cd":"# This function draws boxes on images, one line at a time\ndef draw_boxes(boxes, z):\n\n    for i in boxes:     \n        # Top\n        x = [i[0] - z[0], i[0] + i[2] - z[0]]        # [ x1 , x2 ]\n        y = [i[1] - z[1], i[1] - z[1]]               # [ y1 , y2 ]\n        plt.plot(x,y, color='#ff8838', linewidth=2)\n        \n        # Bottom\n        y = [i[1] + i[3] - z[1], i[1] + i[3] - z[1]]\n        plt.plot(x,y, color='#ff8838', linewidth=2)\n        \n        # Left\n        x = [i[0] - z[0], i[0] - z[0]]\n        y = [i[1] - z[1], i[1] + i[3] - z[1]]\n        plt.plot(x,y, color='#ff8838', linewidth=2)\n\n        # Right         \n        x = [i[0] + i[2] - z[0], i[0] + i[2] - z[0]]\n        plt.plot(x,y, color='#ff8838', linewidth=2)","c997fbda":"# Call YOLO detect.py with the image we exported\ndef detect():\n    # Clean up results from the last run\n    if os.path.exists('\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt'):\n        os.remove('\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt')\n\n    # Call yolo detect\n    !python yolov5\/detect.py --source test.jpg --weights ..\/input\/cxr-anatomy-detection\/anatomy_detection.pt --img 640 --exist-ok --line-thickness 10 --save-txt","bfe29149":"# Load one of these DICOM files\n\n#filename = '..\/input\/siim-covid19-detection\/train\/00fceac64e6a\/38de9f0745e7\/b98508598396.dcm'\n#filename = '..\/input\/siim-covid19-detection\/train\/01206a422293\/875992cad804\/f8ded2e15154.dcm'\n#filename = '..\/input\/siim-covid19-detection\/train\/0142feaef82f\/8f0c767d4e3f\/55e22c0c5de0.dcm'\n#filename = '..\/input\/siim-covid19-detection\/train\/0147e3c530f2\/fbfa6b7a400e\/6b730a1a4271.dcm'\nfilename = '..\/input\/siim-covid19-detection\/train\/01494b9b4423\/fb5ef1804d54\/336db847af0e.dcm'\n    \npixels = load_file(filename)\n\n# Export a JPG for YOLO\ncv2.imwrite('test.jpg',pixels);\n\n# Run detect\ndetect()\n\n# Get the predicted boxes into a dataframe\nboxes = pd.read_csv(\"\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt\", delim_whitespace=True, header=None, index_col=False)\n\n# Convert the normalized YOLO BB data of the predicted anatomy to pixel coords and add them to the dataframe\nfor index, row in boxes.iterrows():\n    \n    x, y, xx, yy = box2coords(row[1], row[2], row[3], row[4], pixels.shape[1], pixels.shape[0])\n    boxes.at[index,'x'] = x\n    boxes.at[index,'y'] = y\n    boxes.at[index,'xx'] = xx\n    boxes.at[index,'yy'] = yy\n    \n# Get only the lung coords .. class 0 and 1 .. you could choose shoulders or clavicles instead .. or all of them\nlungs = boxes[(boxes[0] == 0) | (boxes[0] == 1)]\nlungs.head()\n\n# Figure out the max dimensions of the predicted anatomy, and crop the image to those coords\nx1 = int(lungs['x'].min())\nx2 = int(lungs['xx'].max())\ny1 = int(lungs['y'].min())\ny2 = int(lungs['yy'].max())\n\ncropped = pixels[y1:y2, x1:x2]\n\n# Get the annotated BB coordinates\nbb = get_boxes(str(os.path.basename(filename)))\n\nplt.figure(figsize=(16,16)) \n\n# Plot the original image with BBs\nplt.subplot(2, 2, 1)\ndraw_boxes(bb, [0,0,0,0])\nplt.imshow(pixels, cmap='gray')  \n\n# Plot the predicted anatomy\nplt.subplot(2, 2, 2)\nimg = cv2.imread('\/kaggle\/working\/runs\/detect\/exp\/test.jpg')\nplt.imshow(img, cmap='gray')\n\n# Plot the original image with no crop\nplt.subplot(2, 2, 3)\ndraw_boxes(bb,[0,0,0,0])\nplt.imshow(pixels,cmap='gray'); \n\n# Plot cropped image with scaled BBs\nplt.subplot(2, 2, 4)\ndraw_boxes(bb,[x1,y1,x2,y2])\nplt.imshow(cropped,cmap='gray');  ","384c6a41":"#### - Notice the image on the  bottom right is cropped, yet the original BB is still in the correct place.\n\n### - Conclusion\n\n- We can significantly reduce the noise in images by cropping out unnecessary parts of the image.\n- Original bounding boxes can be scaled to match the cropped image.\n- The cropped coords will need to be normalized back to YOLO format (Pascal VOC) and updated in the images DF.\n- The image could\/should be re-equalized based on the cropped coordinates. This eliminates unnecessary pixels in the histogram calculations and should result in a better distribution of pixels.","633477ec":"### - Load stuff and install YOLOV5","a805b70e":"<div class='alert alert-info' style='text-align:center'><h1>Smart cropping with YOLOV5<\/h1>\n- yet another chest x-ray processing notebook -<\/div>\n\n![chest_anatomy.jpg](attachment:63ea98db-cd4d-4d2c-bf8d-3531283367ce.jpg)\n\n#### **- Use a custom Torch\/YOLOv5 anatomy detection model to detect specific anatomy on a CXR.**\n#### **- Crop the image to the bounds of the detected anatomy.**\n#### **- Scale the original annotated bounding boxes to fit the cropped image.**\n\n- I trained the **cxr-anatomy-detection** model on a small set of chest x-rays from the train set.\n- Train notebook -> https:\/\/www.kaggle.com\/davidbroberts\/chest-anatomy-detection-train\n- Train dataset -> https:\/\/www.kaggle.com\/davidbroberts\/chest-anatomy-yolov5-train-set\n- Anatomy detection inference notebook -> https:\/\/www.kaggle.com\/davidbroberts\/cxr-anatomy-detection-with-yolov5\n- Model dataset -> https:\/\/www.kaggle.com\/davidbroberts\/cxr-anatomy-detection\n- It can detect Lungs, Heart, Clavicles, Shoulders, Carina, Trachea and Gastric Bubble .. pretty accurately, but the carina is hard to find sometimes!\n- The model prediction exports bounding box data for each section of anatomy.\n- In this notebook, I'll use the lung fields to crop the image, and then scale the original bounding boxes.\n\nThe class predictions and their BBs are stored in the text file **\/kaggle\/working\/runs\/detect\/exp\/labels\/test.txt** and can be filtered as needed. The classes are:\n- 0 = Left Lung\n- 1 = Right Lung\n- 2 = Left Clavicle\n- 3 = Right Clavicle\n- 4 = Left Humeral Head\n- 5 = Right Humeral Head\n- 6 = Heart\n- 7 = Gastric Bubble\n- 8 = Carina\n- 9 = Trachea","ae9d9425":"### - Define some functions","b333e083":"### - Load and Predict\n\n#### *Then crop the image to the anatomy*"}}