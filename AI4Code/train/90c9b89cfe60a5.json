{"cell_type":{"4124134f":"code","08565383":"code","f4e7b2e3":"code","4b0a9a4a":"code","09895563":"code","c46cf83e":"code","da9ae6d7":"code","f4d8fcfc":"code","998f543d":"code","f076fe5d":"code","f9e98451":"code","744ec615":"code","56b68b2d":"code","c36c1363":"code","c2d82202":"code","ea4d2c14":"code","00086b47":"code","a50e389c":"code","effd32d6":"code","c441d61e":"code","744cba72":"code","94e7b58d":"code","87500b2b":"code","84b9430e":"code","a4c46369":"code","b1e61475":"code","1d9d892e":"markdown","bc9f3414":"markdown","88238f05":"markdown","f58515cf":"markdown"},"source":{"4124134f":"import numpy as np\nimport pandas as pd\n\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1","08565383":"data.head()","f4e7b2e3":"delete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","4b0a9a4a":"X_train.head()","09895563":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)","c46cf83e":"categorical_features = ['Embarked', 'Pclass', 'Sex']","da9ae6d7":"params = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}","f4d8fcfc":"import lightgbm as lgb\n\n\nlgb_train = lgb.Dataset(X_train, y_train,\n                                         categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train,\n                                        categorical_feature=categorical_features)\n\nmodel = lgb.train(params, lgb_train,\n                               valid_sets=[lgb_train, lgb_eval],\n                               verbose_eval=10,\n                               num_boost_round=1000,\n                               early_stopping_rounds=10)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","998f543d":"y_pred[:10]","f076fe5d":"y_pred = (y_pred > 0.5).astype(int)\ny_pred[:10]","f9e98451":"sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n\nsub['Survived'] = y_pred\nsub.to_csv('submission_lightgbm_holdout.csv', index=False)\n\nsub.head()","744ec615":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ndelete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)\n\nX_train.head()","56b68b2d":"from sklearn.model_selection import KFold\n\n\ny_preds = []\nmodels = []\noof_train = np.zeros((len(X_train),))\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\n\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}\n\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    lgb_train = lgb.Dataset(X_tr, y_tr,\n                                             categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,\n                                            categorical_feature=categorical_features)\n\n    model = lgb.train(params, lgb_train,\n                                   valid_sets=[lgb_train, lgb_eval],\n                                   verbose_eval=10,\n                                   num_boost_round=1000,\n                                   early_stopping_rounds=10)\n\n\n    oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n    y_preds.append(y_pred)\n    models.append(model)","c36c1363":"pd.DataFrame(oof_train).to_csv('oof_train_kfold.csv', index=False)\n\nscores = [\n    m.best_score['valid_1']['binary_logloss'] for m in models\n]\nscore = sum(scores) \/ len(scores)\nprint('===CV scores===')\nprint(scores)\nprint(score)","c2d82202":"from sklearn.metrics import accuracy_score\n\n\ny_pred_oof = (oof_train > 0.5).astype(int)\naccuracy_score(y_train, y_pred_oof)","ea4d2c14":"len(y_preds)","00086b47":"y_preds[0][:10]","a50e389c":"y_sub = sum(y_preds) \/ len(y_preds)\ny_sub = (y_sub > 0.5).astype(int)\ny_sub[:10]","effd32d6":"sub['Survived'] = y_sub\nsub.to_csv('submission_lightgbm_kfold.csv', index=False)\n\nsub.head()","c441d61e":"from sklearn.model_selection import KFold\n\n\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    print(f'fold_id: {fold_id}')\n    print(f'y_tr y==1 rate: {sum(y_tr)\/len(y_tr)}')\n    print(f'y_val y==1 rate: {sum(y_val)\/len(y_val)}')","744cba72":"from sklearn.model_selection import StratifiedKFold\n\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    print(f'fold_id: {fold_id}')\n    print(f'y_tr y==1 rate: {sum(y_tr)\/len(y_tr)}')\n    print(f'y_val y==1 rate: {sum(y_val)\/len(y_val)}')","94e7b58d":"from sklearn.model_selection import StratifiedKFold\n\n\ny_preds = []\nmodels = []\noof_train = np.zeros((len(X_train),))\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}\n\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    lgb_train = lgb.Dataset(X_tr, y_tr,\n                                             categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,\n                                            categorical_feature=categorical_features)\n\n    model = lgb.train(params, lgb_train,\n                                   valid_sets=[lgb_train, lgb_eval],\n                                   verbose_eval=10,\n                                   num_boost_round=1000,\n                                   early_stopping_rounds=10)\n\n    oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n    y_preds.append(y_pred)\n    models.append(model)","87500b2b":"pd.DataFrame(oof_train).to_csv('oof_train_skfold.csv', index=False)\nprint(oof_train[:10])\n\nscores = [\n    m.best_score['valid_1']['binary_logloss'] for m in models\n]\nscore = sum(scores) \/ len(scores)\nprint('===CV scores===')\nprint(scores)\nprint(score)","84b9430e":"from sklearn.metrics import accuracy_score\n\n\ny_pred_oof = (oof_train > 0.5).astype(int)\naccuracy_score(y_train, y_pred_oof)","a4c46369":"y_sub = sum(y_preds) \/ len(y_preds)\ny_sub = (y_sub > 0.5).astype(int)\ny_sub[:10]","b1e61475":"sub['Survived'] = y_sub\nsub.to_csv('submission_lightgbm_skfold.csv', index=False)\n\nsub.head()","1d9d892e":"# \u30db\u30fc\u30eb\u30c9\u30a2\u30a6\u30c8\u691c\u8a3c","bc9f3414":"# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5206\u5272\u65b9\u6cd5","88238f05":"This notebook is a sample code with Japanese comments.\n\n# 2.7 submit\u306e\u305d\u306e\u524d\u306b\uff01\u3000\u300cCross Validation\u300d\u306e\u5927\u5207\u3055\u3092\u77e5\u308d\u3046","f58515cf":"# \u4ea4\u5dee\u691c\u8a3c\uff08Cross Validation\uff09"}}