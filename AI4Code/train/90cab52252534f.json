{"cell_type":{"e181b636":"code","30942949":"code","0a5f27ac":"code","9a1c3ab6":"code","b98e4448":"code","f2c08fda":"code","b11f8995":"code","b2d757b2":"code","466efca4":"code","438daabf":"code","dd01c45d":"code","c2465e1a":"code","e13b52a8":"code","baf579e3":"code","c16472ce":"code","59e6096d":"code","0d037334":"code","b69edf4b":"code","2226a97e":"code","2143af40":"code","5d96b18c":"markdown","bd031b15":"markdown","c14a2ad8":"markdown","fe35aa46":"markdown","78ee1702":"markdown","04a7a2a6":"markdown","f027e793":"markdown","47402b80":"markdown","4d618c0e":"markdown","fbd64a87":"markdown","5c20abbd":"markdown","93305fc8":"markdown","363cc05e":"markdown","72633511":"markdown","2e11a9af":"markdown","1e5281d4":"markdown","c55c8d92":"markdown"},"source":{"e181b636":"import pandas as pd\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport os\nprint(os.listdir(\"..\/input\"))","30942949":"# load data\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('..\/input\/train.csv')\ndf.head()","0a5f27ac":"len(df)","9a1c3ab6":"ix = random.randint(0, len(df)-1)\nlabel, pixels = df.loc[ix][0], df.loc[ix][1:]\nimg = np.array(pixels).reshape((28,28))\nprint('label: ' + str(label))\nplt.imshow(img)","b98e4448":"# transforming df for easier manipulation\ndef transform_df(df):\n    labels, imgs = [], []\n    for index, row in df.iterrows():\n        label, pixels = row[0], row[1:]\n        img = np.array(pixels)\n        labels.append(label)\n        imgs.append(img)\n\n    df_img = pd.DataFrame({'label': labels, 'img': imgs})\n    # to speed up the process we can use for example only 1000 samples\n    # df_img = df_img[:1000]\n    return df_img\n\ndf_img = transform_df(df)\ndf_img.head()","f2c08fda":"# checking images using new df structure\nix = random.randint(0, len(df_img)-1)\nimg = df_img.loc[ix].img.reshape((28,28))\nlabel = df_img.loc[ix].label\nprint('label: ' + str(label))\nplt.imshow(img)","b11f8995":"train_df, test_df = train_test_split(df_img, test_size=0.2, shuffle=True)\nprint(len(train_df), len(test_df))","b2d757b2":"train_df.head()","466efca4":"# create torch dataset\nfrom torch.utils.data import Dataset\nclass MNISTDataset(Dataset):\n  def __init__(self, imgs, labels):    \n    super(MNISTDataset, self).__init__()\n    self.imgs = imgs\n    self.labels = labels\n  def __len__(self):\n    return len(self.imgs)\n  def __getitem__(self, ix):\n    img = self.imgs[ix]\n    label = self.labels[ix]\n    return torch.from_numpy(img).float(), label\n\ndataset = {\n    'train': MNISTDataset(train_df.img.values, train_df.label.values),\n    'test': MNISTDataset(test_df.img.values, test_df.label.values)\n} \n\nlen(dataset['train'])","438daabf":"# again checking image, now based on torch dataset\nix = random.randint(0, len(dataset['train'])-1)\nimg, label = dataset['train'][ix]\nprint(img.shape, img.dtype)\nprint(label)\nplt.imshow(img.reshape((28,28)))","dd01c45d":"# create model\nimport torch.nn as nn\ndef block(in_f, out_f):\n  return nn.Sequential(\n      nn.Linear(in_f, out_f),\n      nn.BatchNorm1d(out_f),\n      nn.ReLU(inplace=True),\n      #nn.Dropout(),\n  )\nmodel = nn.Sequential(\n  block(784,512),\n  block(512,256),\n  block(256,128),\n  nn.Linear(128, 10)\n)\nmodel.to(device)","c2465e1a":"from torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.1)\nscheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.1, patience=3, min_lr=0.0001, verbose=True)\n\ndataloader = {\n    'train': DataLoader(dataset['train'], batch_size=32, shuffle=True, num_workers=4),\n    'test': DataLoader(dataset['test'], batch_size=32, shuffle=False, num_workers=4),\n}","e13b52a8":"# train\nbest_acc, stop, early_stop = 0, 0, 10\nfor e in range(100):\n\n    model.train()\n    total_loss = []\n    for imgs, labels in tqdm(dataloader['train']):\n        imgs, labels = imgs.to(device), labels.to(device)\n        preds = model(imgs)\n        optimizer.zero_grad()\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss.append(loss.data)\n\n    model.eval()\n    val_loss, acc = [], 0.\n    with torch.no_grad():\n        for imgs, labels in tqdm(dataloader['test']):\n            imgs, labels = imgs.to(device), labels.to(device)\n            preds = model(imgs)\n            loss = criterion(preds, labels)\n            val_loss.append(loss.data)\n            _, preds = torch.max(preds, 1)\n            acc += (preds == labels).sum().item()\n\n    acc \/= len(dataset['test'])\n    if acc > best_acc:\n        print('\\n Best model ! saved.')\n        torch.save(model.state_dict(), 'best_model.pt')\n        best_acc = acc\n        stop = -1\n\n    stop += 1\n    if stop >= early_stop:\n        break\n\n    scheduler.step(acc)\n\n    print('\\n Epoch {}, Training loss: {:4f}, Val loss: {:4f}, Val acc: {:4f}'.format(\n        e + 1, torch.mean(torch.stack(total_loss)), torch.mean(torch.stack(val_loss)), acc))\n\nprint('\\n Best model with acc: {}'.format(best_acc))","baf579e3":"# test\nmodel.load_state_dict(torch.load('best_model.pt'))\nmodel.to(device)\nmodel.eval()\n\nix = random.randint(0, len(dataset['test'])-1)\nimg, label = dataset['test'][ix]\npred = model(img.unsqueeze(0).to(device)).cpu()\npred_label = torch.argmax(pred)\nprint('Ground Truth: {}, Prediction: {}'.format(label, pred_label))\nplt.imshow(img.reshape((28,28)))","c16472ce":"submission = pd.read_csv('..\/input\/test.csv')\nsubmission.head()","59e6096d":"imgs = []\nfor index, row in submission.iterrows():\n    pixels = row[0:]\n    img = np.array(pixels)\n    imgs.append(img)\n\nsubmission_transf = pd.DataFrame({'img': imgs})\nsubmission_transf.head()","0d037334":"# converting into pytorch dataset\n# inserting index values as labels\nsubmission_pt = {\n    'test': MNISTDataset(submission_transf.img.values, submission_transf.index.values)\n} ","b69edf4b":"# test individual samples from dropout dataset\nmodel.load_state_dict(torch.load('best_model.pt'))\nmodel.to(device)\nmodel.eval()\n\nix = random.randint(0, len(dataset['test'])-1)\nimg, idx = submission_pt['test'][ix]\npred = model(img.unsqueeze(0).to(device)).cpu()\npred_label = torch.argmax(pred)\nprint(type(idx))\nprint('Prediction: {}'.format(pred_label))\nplt.imshow(img.reshape((28,28)))","2226a97e":"# make predictions on every image\nsubm_dict = dict()\n\nfor ix in range(0,len(submission_pt['test'])):\n    img, idx = submission_pt['test'][ix]\n    pred = model(img.unsqueeze(0).to(device)).cpu()\n    pred_label = torch.argmax(pred)\n    subm_dict[idx+1] = pred_label.item()","2143af40":"# create submission file\nfinal_df = pd.DataFrame.from_dict(subm_dict, orient='index')\nfinal_df.index.name = 'ImageId'\nfinal_df.columns = ['Label']\nfinal_df.to_csv('submission.csv')","5d96b18c":"## Training and Evaluating the Model","bd031b15":"We checked the length, the head of datasets \u2013 all good, we can start building our model. For this we will use pytorch.\n\nNext, we have to transform our data into pytorch Dataset. torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n\n* *(double_underscore)len(double_underscore)* so that len(dataset) returns the size of the dataset.\n* *(double_underscore)getitem(double_underscore)* to support the indexing such that dataset[i] can be used to get its sample","c14a2ad8":"With all above we can start training and evaluating our model. Although we define 100 epochs, it is also useful to stop the loop if model doesn\u2019t improve with time. Here we have set up early_stop = 10, so if model doesn\u2019t change for 10 epochs in a row we will stop the training process.\n\nTraining process: we iterate through our train data by assigning each image and label to a device defined previously, we give our model an image and it tries to find the correct class (preds), we clear all gradients (zero_grad()) and calculate the loss function and the gradient (loss), perform an optimizer step and append new value to a total_loss array.\n\nTesting process: we iterate through the test data, make predictions, calculate the loss and accuracy of the model. In torch.max() we are looking for an index of the maximum value as it will represent the class of a digit and in our case it will match labels. Then by comparing labels and predictions we calculate the accuracy of our model.\n\nEvery time we find the best model we save it and if we hit the early_stop we exit and report the results. Usually it won\u2019t need all those 100 epochs.","fe35aa46":"## Submission of results","78ee1702":"We start with importing all the necessary packages.","04a7a2a6":"When we have our data prepared, we want to split it into 2 datasets: one to traing our model and another to test it\u2019s performance. And the best way to do that is using sklearn. We set up a test_size=0.2 which is standard value for this operation (usually for test we leave 20-30% of data), which means that for training remains 80%. It is also a good practice to set shuffle=True as some datasets might have ordered data, so the model will learn to recognize 0s and 1s, but won\u2019t have any idea that 8 exists for example.","f027e793":"Digit recognition is not something that difficult or advanced. It is kind of \u201cHello world!\u201d program \u2013 not that cool, but you start exactly here. So I decided to share my work and at the same time refresh the knowledge \u2013 it\u2019s being a long ago I played with images.","47402b80":"When we found our best model and saved it, we can play with it by feeding it with new data and see how it performs.","4d618c0e":"Now we need to create few additional parameters for our model:\n\n* criterion \u2013 to calculate loss function, in our case CrossEntropyLoss\n* optimizer \u2013 to set up learning rate\n* scheduler \u2013 to update learning rate if model doesn\u2019t improve with time (quite powerful technique, allows us to tweak the system on the go)\n* dataloader \u2013 class for pytorch that provides single- or multi-process iterators over the dataset","fbd64a87":"## Building a Model","5c20abbd":"## Data Import and Exploration","93305fc8":"The beauty of pytorch is its simplicity in defining the model. We define our layer with inputs and outputs, we add some batch normalization to improve our model (It is a technique to provide any layer in a neural network with inputs that are zero mean\/unit variance) and activation function, in this case ReLU.\n\nFor the first input we have 784 neurons (one neuron per each pixel) and 512 for output (this one is almost random \u2013 I tried few different values and this one performed pretty well, so I left it). Next layer will have 512 inputs (input_layer[n+1] == output_layer[n]) and 256 for output, next 256 inputs and 128 outputs and the last one \u2013 128 inputs and 10 for output (each neuron represents one of 10 digits)","363cc05e":"MNIST dataset, which contains 40 thousands hand-written digits is a \u201cHello World\u201d dataset for this task, we will use the data from the competition here at Kaggle. No need to invent a wheel.","72633511":"As we can see from the head() method, first column in dataset contains labels and the rest pixels of the image 28\u00d728 \u2013 that is why we have 784 columns more. It is also useful to check the length of the dataset each time after some modification to make sure we did everything correct.\n\nNext, let\u2019s visualize our pixels and watch the images we have. We use randint() to select random image every time we run the code below. Also we have to transform our pixels to numpy array (now its\u2019 type is Series) and reshape it to the size 28\u00d728 to be able to plot them.","2e11a9af":"## Data Preprocessing","1e5281d4":"Now, to make our life little bit easier we will transform our dataframe to have only two columns \u2013 label and image, where image is a numpy array of pixels. Also we will reduce the size of dataframe for faster computation (first we want to make sure everything works and then we start playing with model)","c55c8d92":"Like it was said in the beginning it is a \u201cHello World\u201d for the image recognition, we didn\u2019t use convolutional neural network which is normally used in tasks like this, just entry level to understand the flow. I don\u2019t usually work with images, so if there are some mistakes, please let me know. It was a nice refresher for me, hopefully it helped someone else."}}