{"cell_type":{"96a3fc15":"code","b944b26c":"code","9f7318eb":"code","c698241d":"code","c166c039":"code","47d13794":"code","33056cb8":"code","65b47ceb":"code","5f619984":"code","3d97b50a":"code","2b07a407":"code","28b2e31b":"code","4f8c887f":"code","e6c8f30b":"code","b56b0bec":"code","7dd65449":"code","ac63ac08":"code","3d50397f":"code","8b209285":"code","0fc15727":"code","a3262bae":"code","6570a3d1":"code","207fc1d4":"code","4ad00213":"code","d447ee26":"code","72f1a118":"code","0955c2bc":"code","23628124":"code","be9f11b5":"code","4b63f8b1":"code","88481b5b":"markdown","31dcc451":"markdown","264e4b04":"markdown","5f58d7e7":"markdown","a7889bb8":"markdown","f1c8af98":"markdown","f784fb9e":"markdown","315d0732":"markdown","c240ba07":"markdown","7fd7840d":"markdown","f653f227":"markdown"},"source":{"96a3fc15":"import pandas as pd\nimport numpy as np\nimport requests\nfrom bs4 import BeautifulSoup","b944b26c":"for i in range(1,3):\n    try_url = \"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=HSL01&scat=&pageno=\"+str(i)+\"&next=0&durationType=Y&Year=2020&duration=1&news_type=\"\n    print(try_url)","9f7318eb":"from time import sleep","c698241d":"url_dict_hdfc = {}\ncontent = []\nfor i in range(1,3):\n    try_url = \"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=HSL01&scat=&pageno=\"+str(i)+\"&next=0&durationType=Y&Year=2020&duration=1&news_type=\"\n    response = requests.get(try_url)\n    sleep(1)\n    if response.status_code == 200:\n        results_page = BeautifulSoup(response.content,'lxml')\n        div_flr = results_page.findAll('div',attrs={'class':\"MT15 PT10 PB10\"})\n        links = []\n        for link in div_flr:\n            url_all = link.find(\"a\")\n            if url_all != None:\n                links.append(url_all.get(\"href\"))\n        for i in links:\n            url_new = \"https:\/\/www.moneycontrol.com\" + i\n            response_new = requests.get(url_new)\n            results_page_new = BeautifulSoup(response_new.content,'lxml')\n            table =  results_page_new.find('div',attrs={\"class\":\"arti-flow\"})\n            p_article = table.findAll(\"p\")\n            for i in p_article:\n                content.append(i.get_text())\n            title = results_page_new.find('h1',class_=\"artTitle\").getText()\n            time_publish = results_page_new.find('div',class_=\"arttidate_pub\").getText()\n            url_dict_hdfc[url_new] = title, content, time_publish\n            content = []\n            \n    else:\n        print(\"Failure\")\n\ndf_news_hdfc = pd.DataFrame.from_dict(url_dict_hdfc, orient = \"index\").reset_index()\ndf_news_hdfc = df_news_hdfc.rename({\"index\" : \"URL\", 0 : \"Title\", 1 : \"Text\", 2 : \"Time\"}, axis = 1)\ndf_news_hdfc[\"Text\"] = df_news_hdfc[\"Text\"].apply(', '.join)\ndf_news_hdfc","c166c039":"links","47d13794":"for i in range(1,3):\n    try_url = \"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=IPL01&scat=&pageno=\"+str(i)+\"&next=0&durationType=Y&Year=2020&duration=1&news_type=\"\n    print(try_url)","33056cb8":"url_dict_icici = {}\ncontent = []\nfor i in range(1,3):\n    try_url = \"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=IPL01&scat=&pageno=\"+str(i)+\"&next=0&durationType=Y&Year=2020&duration=1&news_type=\"\n    response = requests.get(try_url)\n    sleep(1)\n    if response.status_code == 200:\n        results_page = BeautifulSoup(response.content,'lxml')\n        div_flr = results_page.findAll('div',attrs={'class':\"MT15 PT10 PB10\"})\n        links = []\n        for link in div_flr:\n            url_all = link.find(\"a\")\n            if url_all != None:\n                links.append(url_all.get(\"href\"))\n        for i in links:\n            url_new = \"https:\/\/www.moneycontrol.com\" + i\n            response_new = requests.get(url_new)\n            results_page_new = BeautifulSoup(response_new.content,'lxml')\n            table =  results_page_new.find('div',attrs={\"class\":\"arti-flow\"})\n            if(table == None):\n                continue\n            else:\n                p_article = table.findAll(\"p\")\n                #print(p_article)\n                #print(\"\\n\" + \"\\n\")\n                for i in p_article:\n                    content.append(i.get_text())\n                title = results_page_new.find('h1',class_=\"artTitle\").getText()\n                time_publish = results_page_new.find('div',class_=\"arttidate_pub\").getText()\n                url_dict_icici[url_new] = title, content, time_publish\n                content = []\n            \n            \n    else:\n        print(\"Failure\")\n\ndf_news_icici = pd.DataFrame.from_dict(url_dict_icici, orient = \"index\").reset_index()\ndf_news_icici = df_news_icici.rename({\"index\" : \"URL\", 0 : \"Title\", 1 : \"Text\", 2 : \"Time\"}, axis = 1)\ndf_news_icici[\"Text\"] = df_news_icici[\"Text\"].apply(', '.join)\ndf_news_icici","65b47ceb":"links","5f619984":"url_dict_bajaj = {}\ncontent = []\n\n\nimport re\n\n'''\nfor tag in soup.find_all(re.compile(\"^value_xxx_c_1_f_8_a_\")):\n    print(tag.name)\n'''\n\ntry_url = \"https:\/\/www.moneycontrol.com\/news\/tags\/bajaj-allianz-life-insurance.html\/news\/\"\nresponse = requests.get(try_url)\nsleep(1)\nif response.status_code == 200:\n    results_page = BeautifulSoup(response.content,'lxml')\n    div_flr = results_page.findAll('li',attrs={'id': re.compile(\"^newslist-\")})\n    links = []\n    for link in div_flr:\n        url_all = link.find(\"a\")\n        if url_all != None:\n            links.append(url_all.get(\"href\"))\n    \n    for i in links:\n        url_new = i\n        response_new = requests.get(url_new)\n        results_page_new = BeautifulSoup(response_new.content,'lxml')\n        table =  results_page_new.find('div',attrs={\"class\":\"arti-flow\"})\n        if(table == None):\n            continue\n        else:\n            p_article = table.findAll(\"p\")\n            #print(p_article)\n            #print(\"\\n\" + \"\\n\")\n            for i in p_article:\n                content.append(i.get_text())\n            title = results_page_new.find('h1',class_=\"artTitle\").getText()\n            time_publish = results_page_new.find('div',class_=\"arttidate_pub\").getText()\n            url_dict_bajaj[url_new] = title, content, time_publish\n            content = []\n                    \nelse:\n    print(\"Failure\")\n\ndf_news_bajaj = pd.DataFrame.from_dict(url_dict_bajaj, orient = \"index\").reset_index()\ndf_news_bajaj = df_news_bajaj.rename({\"index\" : \"URL\", 0 : \"Title\", 1 : \"Text\", 2 : \"Time\"}, axis = 1)\ndf_news_bajaj[\"Text\"] = df_news_bajaj[\"Text\"].apply(', '.join)\ndf_news_bajaj","3d97b50a":"links","2b07a407":"import nltk\nfrom nltk import FreqDist\nnltk.download('stopwords')\nimport numpy as np\nimport re\nimport spacy\n\nimport gensim\nfrom gensim import corpora\n\n# libraries for visualization\nimport pyLDAvis\nimport pyLDAvis.gensim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","28b2e31b":"# function to plot most frequent terms\ndef freq_words(x, terms = 30):\n    all_words = ' '.join([text for text in x])\n    all_words = all_words.split()\n\n    fdist = FreqDist(all_words)\n    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n\n    # selecting top 20 most frequent words\n    d = words_df.nlargest(columns=\"count\", n = terms) \n    plt.figure(figsize=(20,5))\n    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n    ax.set(ylabel = 'Count')\n    plt.show()","4f8c887f":"freq_words(df_news_hdfc[\"Text\"])","e6c8f30b":"import string\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\ni_stp = [\"per\",\"rs\",\"life\",\"insurance\",\"said\", \"cent\",\"ltd\",\"r\"]\nfor i in i_stp:\n    stop_words.append(i)\n\ndf_news_hdfc.Text = df_news_hdfc.Text.apply(lambda x: x.lower())\ndf_news_hdfc.Text = df_news_hdfc.Text.apply(lambda x: x.translate(str.maketrans(\"\",\"\", string.punctuation)))\ndf_news_hdfc.Text = df_news_hdfc.Text.apply(lambda x: x.translate(str.maketrans(\"\",\"\", string.digits)))\n\ndef remove_stopwords(text):    \n    clean_text = \" \".join([i for i in text if i not in stop_words])\n    return clean_text\n\nclean_news = [remove_stopwords(r.split()) for r in df_news_hdfc[\"Text\"]]\nfreq_words(clean_news)","b56b0bec":"import spacy\nnlp = spacy.load('en', disable=['parser', 'ner'])\ndef lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective\n    output = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        output.append([token.lemma_ for token in doc if token.pos_ in tags])\n    return output","7dd65449":"tokenized_news = pd.Series(clean_news).apply(lambda x: x.split())\nprint(tokenized_news[1])","ac63ac08":"clean_news_2 = lemmatization(tokenized_news)\nprint(clean_news_2[1]) ","3d50397f":"clean_news_3 = []\ndf = pd.DataFrame()\nfor i in range(len(clean_news_2)):\n    clean_news_3.append(' '.join(clean_news_2[i]))\n\ndf[\"clean_news\"] = clean_news_3\n\nfreq_words(df[\"clean_news\"], 35)","8b209285":"dictionary = corpora.Dictionary(clean_news_2)\ndoc_term_matrix = [dictionary.doc2bow(news) for news in clean_news_2]\n# Creating the object for LDA model using gensim library\nLDA = gensim.models.ldamodel.LdaModel\n\n# Build LDA model\nlda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n                chunksize=1000, passes=50)","0fc15727":"lda_model.print_topics()","a3262bae":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\nvis","6570a3d1":"freq_words(df_news_hdfc[\"Title\"])","207fc1d4":"import string\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\ni_stp = [\"per\",\"rs\",\"life\",\"insurance\",\"said\", \"cent\",\"ltd\",\"r\"]\nfor i in i_stp:\n    stop_words.append(i)\n\ndf_news_hdfc.Title = df_news_hdfc.Title.apply(lambda x: x.lower())\ndf_news_hdfc.Title = df_news_hdfc.Title.apply(lambda x: x.translate(str.maketrans(\"\",\"\", string.punctuation)))\ndf_news_hdfc.Title = df_news_hdfc.Title.apply(lambda x: x.translate(str.maketrans(\"\",\"\", string.digits)))\n\ndef remove_stopwords(text):    \n    clean_text = \" \".join([i for i in text if i not in stop_words])\n    return clean_text\n\nclean_news = [remove_stopwords(r.split()) for r in df_news_hdfc[\"Title\"]]\nfreq_words(clean_news)","4ad00213":"import spacy\nnlp = spacy.load('en', disable=['parser', 'ner'])\ndef lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective\n    output = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        output.append([token.lemma_ for token in doc if token.pos_ in tags])\n    return output","d447ee26":"tokenized_news = pd.Series(clean_news).apply(lambda x: x.split())\nprint(tokenized_news[1])","72f1a118":"clean_news_2 = lemmatization(tokenized_news)\nprint(clean_news_2[1]) ","0955c2bc":"clean_news_3 = []\ndf = pd.DataFrame()\nfor i in range(len(clean_news_2)):\n    clean_news_3.append(' '.join(clean_news_2[i]))\n\ndf[\"clean_news\"] = clean_news_3\n\nfreq_words(df[\"clean_news\"], 35)","23628124":"dictionary = corpora.Dictionary(clean_news_2)\ndoc_term_matrix = [dictionary.doc2bow(news) for news in clean_news_2]\n# Creating the object for LDA model using gensim library\nLDA = gensim.models.ldamodel.LdaModel\n\n# Build LDA model\nlda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n                chunksize=1000, passes=50)","be9f11b5":"lda_model.print_topics()","4b63f8b1":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\nvis","88481b5b":"https:\/\/www.moneycontrol.com\/news\/tags\/bajaj-allianz-life-insurance.html\/news\/","31dcc451":"## HDFC -  Headline Topic Modelling","264e4b04":"## HDFC Life","5f58d7e7":"## Building LDA  - Text","a7889bb8":"## ICICI Prudential","f1c8af98":"## HDFC -  Text Topic Modelling","f784fb9e":"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=HSL01&scat=&pageno=2&next=0&durationType=Y&Year=2020&duration=1&news_type=","315d0732":"https:\/\/www.moneycontrol.com\/stocks\/company_info\/stock_news.php?sc_id=IPL01&scat=&pageno=2&next=0&durationType=Y&Year=2020&duration=1&news_type=","c240ba07":"## Bajaj Allianz","7fd7840d":"## Building LDA  - Headlines","f653f227":"# Topic Modelling"}}