{"cell_type":{"b588a321":"code","8ed2310f":"code","7d37c45e":"code","999872ae":"code","e6d3e746":"code","2bd389a3":"code","0d32662b":"code","599f3933":"code","47e44634":"code","e696736c":"code","f7444ae9":"code","d1a8e766":"code","97129420":"code","420231ce":"code","7f2ae76d":"code","afde9903":"code","0c671247":"code","3d6e0d5f":"code","7834a76f":"code","1ac598d0":"code","027864eb":"code","3c45db1a":"code","e8d4f1f3":"code","2ae122e1":"code","1a3af1c6":"code","0d2e0ce3":"code","dc45a2f6":"code","eba2e4c1":"code","5755b575":"code","558f99d0":"code","6191accb":"code","5d1869ad":"code","4c4e0ae8":"code","2d89e449":"code","83390199":"code","5e66b6d6":"code","b884e556":"code","4b7519d5":"code","17255661":"code","81449773":"code","70f491fb":"code","afeb3124":"code","eab9be2e":"code","8a8b76ec":"code","d1bc979a":"code","eac7cf1d":"code","2b654e7e":"code","ccd16944":"code","41948b98":"code","9d98e06d":"code","d312471f":"code","4a32adb8":"code","debf8ecc":"code","4c1cb0e9":"code","f539be24":"code","9ae625e8":"code","76e5d9cc":"code","de379968":"code","e5df1853":"code","f4bbbded":"code","94157820":"code","865729e1":"code","92d8ed1d":"code","1c33d525":"code","ec51fd00":"code","aa038336":"code","b4f66316":"code","18f6be3c":"code","762b8dd7":"code","1f5bba37":"code","a3a09569":"code","36a01ce6":"code","ec953ba8":"code","ef3d03a0":"code","4da58cdd":"code","8897d462":"code","b5e3760a":"code","6805d968":"code","63c42672":"code","eec2edf2":"code","75af42cf":"code","a375f659":"code","95707e5d":"code","9c165715":"code","a0527478":"code","a32b3f65":"code","79efd338":"code","14cf3423":"code","56e1b692":"markdown","27e34e22":"markdown","e255deb0":"markdown","cea27ae1":"markdown","51180a1a":"markdown","9dc161c3":"markdown","fabeade8":"markdown","5261e962":"markdown","789697fe":"markdown","0e25525e":"markdown","ec32ba66":"markdown","5ed9f3f9":"markdown","9d601c64":"markdown","d91d3fe6":"markdown","d140092d":"markdown","4e06df28":"markdown","3c2db68e":"markdown","56e46cd0":"markdown","fa259573":"markdown","11307c1a":"markdown","d5f77926":"markdown","f08d71c6":"markdown"},"source":{"b588a321":"!pip install opendatasets --upgrade --quiet\n!pip install scikit-learn --upgrade --quiet\n!pip install pandas --upgrade --quiet\n!pip install matplotlib --upgrade --quiet\n!pip install seaborn --upgrade --quiet\n!pip install numpy --upgrade --quiet","8ed2310f":"import opendatasets as od\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport zipfile","7d37c45e":"for zf in ['macro.csv.zip','train.csv.zip','test.csv.zip', 'sample_submission.csv.zip']:\n    input_file=open('..\/input\/sberbank-russian-housing-market\/'+zf,'rb')\n    output_file=open(zf,'wb')\n    output_file.write(input_file.read())\n    output_file.close(); input_file.close()\n    zipf=zipfile.ZipFile(zf,'r')\n    zipf.extractall(''); zipf.close()\nmacro=pd.read_csv('macro.csv')\ntrain=pd.read_csv('train.csv')\ntest=pd.read_csv('test.csv')","999872ae":"train.info()","e6d3e746":"macro.info()","2bd389a3":"test.info()","0d32662b":"train.head()","599f3933":"test.head()","47e44634":"# Creating a list of input columns\ninput_col=list(train.columns)[1:-1]","e696736c":"# Creating a list of target column\ntarget_col='price_doc'","f7444ae9":"inputs=train[input_col].copy()","d1a8e766":"target=train[target_col]","97129420":"numeric_cols=inputs.select_dtypes(include=['int64','float64']).columns.tolist()","420231ce":"categorical_cols=inputs.select_dtypes(include=['object']).columns.tolist()","7f2ae76d":"#For train inputs\nmissing_counts = inputs[numeric_cols].isna().sum().sort_values(ascending=False)\nmissing_counts[missing_counts>0]","afde9903":"from sklearn.impute import SimpleImputer\nimputer=SimpleImputer(strategy='mean').fit(train[numeric_cols])\ninputs[numeric_cols]=imputer.transform(inputs[numeric_cols])","0c671247":"inputs","3d6e0d5f":"inputs.drop('build_year', inplace=True, axis=1)\ninputs.drop('timestamp', inplace=True, axis=1)","7834a76f":"numeric_cols.remove('build_year')\ncategorical_cols.remove('timestamp')","1ac598d0":"missing_counts = inputs[numeric_cols].isna().sum().sort_values(ascending=False)\n","027864eb":"inputs[numeric_cols].describe().loc[['min', 'max']]","3c45db1a":"from sklearn.preprocessing import MinMaxScaler\n# Create the scaler\nscaler = MinMaxScaler()\n# Fit the scaler to the numeric columns\nscaler.fit(train[numeric_cols])\n# Transform and replace the numeric columns\ninputs[numeric_cols] = scaler.transform(inputs[numeric_cols])\n","e8d4f1f3":"inputs[numeric_cols].describe().loc[['min', 'max']]","2ae122e1":"inputs[categorical_cols].nunique().sort_values(ascending=False)","1a3af1c6":"from sklearn.preprocessing import OneHotEncoder\n#Creating the encoder\nencoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n#Fitting the encoder to the categorical colums\nencoder.fit(train[categorical_cols])\n#Generating column names for each category\nencoded_cols = list(encoder.get_feature_names(categorical_cols))\n# Transforming and adding new one-hot category columns\ninputs[encoded_cols] = encoder.transform(train[categorical_cols])\n","0d2e0ce3":"inputs","dc45a2f6":"from sklearn.model_selection import train_test_split","eba2e4c1":"train_inputs, val_inputs, train_targets, val_targets = train_test_split(inputs[numeric_cols + encoded_cols], \n                                                                        target, \n                                                                        test_size=0.25, \n                                                                        random_state=31)","5755b575":"train_inputs.head()","558f99d0":"val_inputs.head()","6191accb":"train_targets.head()","5d1869ad":"val_targets.head()","4c4e0ae8":"from sklearn.linear_model import Ridge\n# Create the model\nmodel = model = Ridge()\n# Fit the model using inputs and targets\nmodel.fit(train_inputs[numeric_cols + encoded_cols], train_targets)","2d89e449":"from sklearn.metrics import mean_squared_error","83390199":"X_train = train_inputs[numeric_cols + encoded_cols]\nX_val = val_inputs[numeric_cols + encoded_cols]","5e66b6d6":"train_preds = model.predict(X_train)\ntrain_preds","b884e556":"print('The RMSE loss for the training set is \u20bd {}.'.format(mean_squared_error(train_targets, train_preds, squared=False)))","4b7519d5":"val_preds = model.predict(X_val)\nval_preds","17255661":"print('The RMSE loss for the valication set is \u20bd {}.'.format(mean_squared_error(val_targets, val_preds, squared=False)))","81449773":"weights=model.coef_","70f491fb":"weights_df = pd.DataFrame({\n    'feature': train_inputs.columns,\n    'weight': weights\n}).sort_values('weight', ascending=False)","afeb3124":"plt.title('Feature Importance')\nsns.barplot(data=weights_df.head(10), x='weight', y='feature')","eab9be2e":"test_input_cols = list(test.columns)[1:]\n\ntest_inputs_df = test[test_input_cols].copy()\ntest_numeric_cols = test_inputs_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntest_categorical_cols =  test_inputs_df.select_dtypes(include=['object']).columns.tolist()","8a8b76ec":"missing_counts = test_inputs_df[test_numeric_cols].isna().sum().sort_values(ascending=False)\nmissing_counts","d1bc979a":"test_imputer = SimpleImputer(strategy = 'mean').fit(test[test_numeric_cols])\ntest_inputs_df[test_numeric_cols] = test_imputer.transform(test_inputs_df[test_numeric_cols])\ntest_inputs_df.drop('build_year', inplace=True, axis=1)\ntest_inputs_df.drop('timestamp', inplace=True, axis=1)\ntest_numeric_cols.remove('build_year')\ntest_categorical_cols.remove('timestamp')","eac7cf1d":"scaler.fit(test[test_numeric_cols])\ntest_inputs_df[test_numeric_cols] = scaler.transform(test_inputs_df[test_numeric_cols])\ntest_inputs_df[test_numeric_cols].describe().loc[['min', 'max']]","2b654e7e":"encoder.fit(test[test_categorical_cols])\ntest_encoded_cols = list(encoder.get_feature_names(test_categorical_cols))\ntest_inputs_df[test_encoded_cols] = encoder.transform(test[test_categorical_cols])","ccd16944":"X_test = test_inputs_df[test_numeric_cols + test_encoded_cols]","41948b98":"test_preds = model.predict(X_test)","9d98e06d":"print('The test predictions are \u20bd {}.'.format(test_preds))","d312471f":"submission_df = pd.read_csv('sample_submission.csv')","4a32adb8":"submission_df['price_doc'] = test_preds","debf8ecc":"submission_df.to_csv('submission.csv', index=False)","4c1cb0e9":"from sklearn.tree import DecisionTreeRegressor","f539be24":"tree = DecisionTreeRegressor(random_state=41)","9ae625e8":"tree.fit(train_inputs, train_targets)","76e5d9cc":"tree_train_preds = tree.predict(train_inputs)","de379968":"tree_train_rmse = mean_squared_error(train_targets,tree_train_preds, squared=False )","e5df1853":"tree_val_preds = tree.predict(val_inputs)","f4bbbded":"tree_val_rmse = mean_squared_error(val_targets,tree_val_preds, squared=False )","94157820":"print('Train RMSE: {}, Validation RMSE: {}'.format(tree_train_rmse, tree_val_rmse))","865729e1":"from sklearn.tree import plot_tree, export_text","92d8ed1d":"plt.figure(figsize=(30,15))\n\n# Visualize the tree graphically using plot_tree\nplot_tree(tree,max_depth=3,feature_names=train_inputs.columns, filled=False, rounded=True);","1c33d525":"# Visualize the tree textually using export_text\ntree_text = export_text(tree)","ec51fd00":"# Display the first few lines\nprint(tree_text[:1000])","aa038336":"# Check feature importance\ntree_importances = tree.feature_importances_\ntree_importance_df = pd.DataFrame({\n    'feature': train_inputs.columns,\n    'importance': tree_importances\n}).sort_values('importance', ascending=False)\ntree_importance_df","b4f66316":"plt.title('Decision Tree Feature Importance')\nsns.barplot(data=tree_importance_df.head(10), x='importance', y='feature');","18f6be3c":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score, confusion_matrix","762b8dd7":"# Create the model\nrf1 = RandomForestRegressor(n_jobs=-1, random_state=21)\n# Fit the model\nrf1.fit(train_inputs,train_targets)\nrf1.score(train_inputs,train_targets)","1f5bba37":"rf1_train_preds=rf1.predict(train_inputs)","a3a09569":"rf1_train_rmse= mean_squared_error(train_targets,rf1_train_preds, squared=False )","36a01ce6":"rf1_val_preds=rf1.predict(val_inputs)","ec953ba8":"rf1_val_rmse= mean_squared_error(val_targets,rf1_val_preds, squared=False )","ef3d03a0":"print('Train RMSE: {}, Validation RMSE: {}'.format(rf1_train_rmse, rf1_val_rmse))","4da58cdd":"def test_params(**params):\n    model = RandomForestRegressor(random_state=21, n_jobs=-1, **params).fit(train_inputs, train_targets)\n    train_rmse = mean_squared_error(model.predict(train_inputs), train_targets, squared=False)\n    val_rmse = mean_squared_error(model.predict(val_inputs), val_targets, squared=False)\n    return train_rmse, val_rmse","8897d462":"def test_param_plot(param_name, param_values):\n    train_errors, val_errors = [], [] \n    for value in param_values:\n        params = {param_name: value}\n        train_rmse, val_rmse = test_params(**params)\n        train_errors.append(train_rmse)\n        val_errors.append(val_rmse)\n    plt.figure(figsize=(10,6))\n    plt.title('Overfitting curve: ' + param_name)\n    plt.plot(param_values, train_errors, 'b-o')\n    plt.plot(param_values, val_errors, 'r-o')\n    plt.xlabel(param_name)\n    plt.ylabel('RMSE')\n    plt.legend(['Training', 'Validation'])","b5e3760a":"test_param_plot('n_estimators', [10,20,30,40,50,60,70])","6805d968":"test_param_plot('max_depth', [ 10, 15, 20, 25, 30])","63c42672":"rf2 = RandomForestRegressor(n_jobs=-1, max_depth = 15 , n_estimators = 30, random_state=21)","eec2edf2":"# Fit the model\nrf2.fit(train_inputs,train_targets)","75af42cf":"rf2_train_preds = rf2.predict(train_inputs)\nrf2_train_rmse =  mean_squared_error(train_targets,rf2_train_preds, squared=False )","a375f659":"rf2_val_preds = rf2.predict(val_inputs)\nrf2_val_rmse= mean_squared_error(val_targets,rf2_val_preds, squared=False )","95707e5d":"print('Train RMSE: {}, Validation RMSE: {}'.format(rf2_train_rmse, rf2_val_rmse))","9c165715":"rf2_test_preds = rf2.predict(X_test)","a0527478":"print('The test predictions are \u20bd {}.'.format(test_preds))","a32b3f65":"submission_df2 = pd.read_csv('sample_submission.csv')","79efd338":"submission_df['price_doc'] = test_preds","14cf3423":"submission_df.to_csv('submission2.csv', index=False)","56e1b692":"# Random Forest Decision Tree","27e34e22":"# Data Cleaning","e255deb0":"# Hyperparameter Tuning","cea27ae1":"# Encoding catergorical Columns","51180a1a":"# Decision Tree","9dc161c3":"# Prepareing the Dataset","fabeade8":"# Test Predictions","5261e962":"# Test Prediction","789697fe":"build_year is quite high and impracticle. It need to be dropped. Same for timestamp","0e25525e":"# Evaluating the model","ec32ba66":"# Sberbank Russian Housing Market\n\nUse the \"Run\" button to execute the code.","5ed9f3f9":"# Making Predictions","9d601c64":"Dividing the data into Numeric and Categorical types","d91d3fe6":"# Visualizing the decision Tree","d140092d":"# References","4e06df28":"Dataset :https:\/\/www.kaggle.com\/c\/sberbank-russian-housing-market\/overview\n\nNotebook reference: https:\/\/jovian.ai\/aakashns\/sklearn-decision-trees-random-forests\n                    https:\/\/jovian.ai\/shlok-ramteke24\/python-random-forests-assignment","3c2db68e":"# Downloading Dataset and EDA","56e46cd0":"The train and test data are divided on the basis of timespaces. First the input and target columns need to be determined","fa259573":"# Linear Regression Model","11307c1a":"# Training and validation","d5f77926":"# Feature Importance","f08d71c6":"# Scaling of Numerical values"}}