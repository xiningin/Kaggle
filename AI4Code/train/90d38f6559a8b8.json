{"cell_type":{"ac114a8a":"code","6ba154b8":"code","ae74573c":"code","1b0a4760":"code","e0b8a018":"code","a0e1dec6":"code","8caa3f44":"code","a3bea941":"code","4d339262":"code","7851ab09":"code","b07afffd":"code","aa901561":"code","68f41c9e":"code","b58b62e8":"code","58b53915":"code","98a4b81a":"code","7b68c83e":"code","bf3edd44":"code","5bdbd090":"code","03ab5b98":"code","becf1208":"code","41937242":"code","7dd6ccb5":"code","ce873c20":"code","bc097570":"code","c6bfa4b0":"code","5257be0f":"code","1bc1a480":"code","d950569e":"code","518609e7":"code","63174de0":"code","0d7ce081":"code","18864ff7":"code","cb241fbb":"code","600230f4":"code","539c6e70":"code","005c14aa":"code","4b081c19":"code","f459f7bf":"code","140ce3a8":"code","7d72f43a":"code","fe56f5d5":"code","781b78c6":"code","6fb9a73c":"code","c3d2b31a":"code","43fb1bec":"code","440e0395":"code","b6a5df45":"code","cb36aadc":"code","42a2aee9":"code","5a5a2521":"code","982bafa0":"code","78eb856c":"code","462ae81a":"code","5569067b":"code","5b884557":"code","e33b294f":"code","a63b115d":"code","c991b064":"code","f2e97585":"code","3ec5eef7":"code","c3b0da40":"code","d29621f2":"code","accb7c3c":"code","2d9e5760":"code","8ae1a79f":"code","2f35a2bd":"code","e3e48bc2":"code","841f867e":"code","285b2adf":"code","370a016f":"code","1c71e057":"code","eb4c8381":"code","70a63bbb":"code","8606af7c":"code","b51cf394":"code","899955e4":"code","1aba4477":"code","721f5aca":"code","386aab8e":"code","79125315":"code","6c0fe35f":"code","8a47f74f":"code","08a4735a":"code","a4900d92":"code","ebdcba86":"code","83eb6330":"code","6c69a66e":"code","d44dd118":"markdown","278e79e9":"markdown","8b0c2730":"markdown","10109cf1":"markdown","8a011d3a":"markdown","fef34f4b":"markdown","92a31d84":"markdown","518f9ea1":"markdown","1634e9e4":"markdown","cd2b6625":"markdown","d036db7e":"markdown","70593291":"markdown","a83d01db":"markdown","460c2c96":"markdown","3a8409bc":"markdown","6b9225fa":"markdown"},"source":{"ac114a8a":"import warnings\nwarnings.filterwarnings(\"ignore\")","6ba154b8":"import sys\n# INSTALL RAPIDS\n!cp ..\/input\/rapids\/rapids.0.16.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","ae74573c":"!pip install -q \/kaggle\/input\/iterative-stratification\/iterative-stratification-master\/","1b0a4760":"from fastai.basics import *","e0b8a018":"datapath = Path(\"\/kaggle\/input\/lish-moa\")","a0e1dec6":"datapath.ls().map(lambda o: o.name)","8caa3f44":"train_features_df = pd.read_csv(datapath\/'train_features.csv')\ntest_features_df = pd.read_csv(datapath\/'test_features.csv')\ntrain_targets_scored_df = pd.read_csv(datapath\/'train_targets_scored.csv')\ntrain_targets_nonscored_df = pd.read_csv(datapath\/'train_targets_nonscored.csv')","a3bea941":"train_features_df.shape, test_features_df.shape, train_targets_scored_df.shape, train_targets_nonscored_df.shape","4d339262":"nonscored_cols = list(train_targets_nonscored_df.columns[1:])\nscored_cols = list(train_targets_scored_df.columns[1:])","7851ab09":"len(nonscored_cols), len(scored_cols)","b07afffd":"assert set(nonscored_cols).intersection(scored_cols) == set()","aa901561":"train_features_df.head()","68f41c9e":"test_features_df.head()","b58b62e8":"train_targets_scored_df.head()","58b53915":"train_targets_scored_df.iloc[1:].mean().hist()","98a4b81a":"train_target_distrib = dict(train_targets_scored_df.iloc[:,1:].sum())","7b68c83e":"train_target_distrib;","bf3edd44":"[(k,train_target_distrib[k]) for k in train_target_distrib if train_target_distrib[k] == 1]","5bdbd090":"n_train, n_test = train_features_df.shape[0], test_features_df.shape[0]\ntrain_test_features_df = pd.concat([train_features_df, test_features_df]).reset_index(drop=True)\ng_cols = list(o for o in train_test_features_df.columns if o.startswith(\"g-\"))\nc_cols = list(o for o in train_test_features_df.columns if o.startswith(\"c-\"))\ngc_cols = g_cols + c_cols\n\nlen(g_cols), len(c_cols), len(gc_cols)","03ab5b98":"from seaborn import distplot","becf1208":"def plot_dist():\n    fig, axes = plt.subplots(2, 5, figsize=(15,6))\n    axes = axes.flatten()\n    for c, ax in zip(list(np.random.choice(c_cols, 5))+list(np.random.choice(g_cols,5)), axes): distplot(train_test_features_df[c], ax=ax)","41937242":"plot_dist()","7dd6ccb5":"ParamConfig = SimpleNamespace(\n    do_rank_gauss = True,\n    \n    do_quantile_tfms = False,\n    n_quantiles = 100,\n    \n    do_pca = False,\n    pca_reduction_factor = 3,\n\n    do_umap = False,\n    umap_reduction_factor = 3,\n    umap_n_neighbors = 150,\n    \n    do_knn_encoding = True,\n    knn_k = 100,\n    \n    do_transfer_learning = False,\n    tl_n_epochs = 30,\n    tl_smoothing = 0.001,\n    tl_lr = 0.001,\n    \n    ft_n_epochs = 30,\n    ft_smoothing = 0.001,\n    ft_lr = 0.001,\n    \n    model_n_layers = 2,\n    model_layer_width = 512,\n    model_ps = 0.25\n)","ce873c20":"import cupy as cp\nfrom cupyx.scipy.special import erfinv\nimport cudf as gd\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import erfinv as sp_erfinv","bc097570":"def to_rankgauss(x):\n    \"https:\/\/medium.com\/rapids-ai\/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy-7c947e3397da\"\n    x_cpu = x\n    r_cpu = x_cpu.argsort().argsort() \n    epsilon = 1e-6\n    r_cpu = (r_cpu\/r_cpu.max()-0.5)*2 # scale to (-1,1)\n    r_cpu = cp.clip(r_cpu,-1+epsilon,1-epsilon)\n    r_cpu = sp_erfinv(r_cpu) # map to gaussian\n    return r_cpu","c6bfa4b0":"if ParamConfig.do_rank_gauss: \n    for col in gc_cols: \n        train_test_features_df[col] = to_rankgauss(train_test_features_df[col])","5257be0f":"from sklearn.preprocessing import QuantileTransformer","1bc1a480":"if ParamConfig.do_quantile_tfms:\n    transformer = QuantileTransformer(n_quantiles=ParamConfig.n_quantiles, random_state=0, output_distribution=\"normal\")\n    train_test_features_df[gc_cols] = transformer.fit_transform(train_test_features_df[gc_cols])","d950569e":"plot_dist()","518609e7":"len(g_cols), len(c_cols), len(gc_cols)","63174de0":"train_test_features_df","0d7ce081":"train_test_features_df.groupby(['cp_type', 'cp_time', 'cp_dose'])[['sig_id']].count()","18864ff7":"len(train_test_features_df['sig_id'].unique())","cb241fbb":"# ctl_vehicle have no MoA hence all 0 target labels\nall(train_test_features_df.merge(train_targets_scored_df, on='sig_id').query(\"cp_type == 'ctl_vehicle'\")[scored_cols].sum()==0)","600230f4":"# ctl_vehicle have no MoA hence all 0 target labels\nall(train_test_features_df.merge(train_targets_nonscored_df, on='sig_id').query(\"cp_type == 'ctl_vehicle'\")[nonscored_cols].sum()==0)","539c6e70":"test_features_df","005c14aa":"from cuml.decomposition import PCA as cumlPCA","4b081c19":"%%time\nif ParamConfig.do_pca:\n    # add pca features\n    pca_feats = []\n    colnames = []\n    for name, cols in [(\"gene\", g_cols), (\"cell\", c_cols)]:\n        n_comp = int(len(cols)\/ParamConfig.pca_reduction_factor)\n        pca = cumlPCA(n_components=n_comp, iterated_power=500)\n        pca_feat = pca.fit_transform(train_test_features_df[cols])\n        pca_feats += [pca_feat]\n        colnames += [f\"pca_{name}_{i}\" for i in range(n_comp)]\n        \n    pca_feats = np.hstack(pca_feats)\n    train_test_features_df[colnames] = pca_feats","f459f7bf":"train_test_features_df","140ce3a8":"from cuml.manifold import UMAP as cumlUMAP","7d72f43a":"%%time\n# add umap features\nif ParamConfig.do_umap:\n    umap_feats = []\n    colnames = []\n    for name, cols in [(\"gene\", g_cols), (\"cell\", c_cols)]:\n        n_comp = int(len(cols)\/ParamConfig.umap_reduction_factor)\n        umap = cumlUMAP(n_components=n_comp, n_neighbors=ParamConfig.umap_n_neighbors)\n        umap_feat = umap.fit_transform(train_test_features_df[cols])\n        umap_feats += [umap_feat]\n        colnames += [f\"umap_{name}_{i}\" for i in range(n_comp)]\n\n    umap_feats = np.hstack(umap_feats)\n    train_test_features_df[colnames] = umap_feats","fe56f5d5":"train_test_features_df","781b78c6":"for ohe_col in ['cp_type', 'cp_time', 'cp_dose']:\n    vals = train_test_features_df[ohe_col].unique()\n    if len(vals) == 2:\n        col = ohe_col+\"s\"\n        cat2code = {v:k for k,v in enumerate(vals)}\n        train_test_features_df[col] = train_test_features_df[ohe_col].map(cat2code)\n\n    else:\n        cat2code = {v:k for k,v in enumerate(vals)}\n        encoded = train_test_features_df[ohe_col].map(cat2code)\n        ohe_arr = np.zeros((len(vals), len(vals)))\n        ohe_arr[np.diag_indices_from(ohe_arr)] = 1\n        col = [f\"{ohe_col}s_{o}\" for o in vals]   \n        train_test_features_df[col] = ohe_arr[encoded]","6fb9a73c":"train_test_features_df = train_test_features_df.drop(\"cp_types\", 1)","c3d2b31a":"train_test_features_df","43fb1bec":"from cuml.neighbors import KNeighborsRegressor as cumlKNN","440e0395":"if ParamConfig.do_knn_encoding:\n    knn = cumlKNN(n_neighbors=ParamConfig.knn_k)\n    merged_nonscored_train_test_df = train_test_features_df.merge(train_targets_nonscored_df, on='sig_id', how='left')\n    unique_cp_time, unique_cp_dose = merged_nonscored_train_test_df['cp_time'].unique(), merged_nonscored_train_test_df['cp_dose'].unique()","b6a5df45":"if ParamConfig.do_knn_encoding:\n    # create pairwise groups\n    knn_groups = []\n    for i in unique_cp_time:\n        for j in unique_cp_dose: knn_groups.append((i,j))\n\n    # initialize knn feature cols\n    knn_cols = [f\"knn{ParamConfig.knn_k}_{i}\" for i in range(len(nonscored_cols))]\n    for c in knn_cols: train_test_features_df[c] = 0","cb36aadc":"if ParamConfig.do_knn_encoding:\n    \n    for time, dose in knn_groups:\n\n        # filter data by time and dose group\n        X = merged_nonscored_train_test_df.query(f\"cp_time == '{time}' & cp_dose == '{dose}'\")[gc_cols]\n        y = merged_nonscored_train_test_df.query(f\"cp_time == '{time}' & cp_dose == '{dose}'\")[nonscored_cols]\n\n        # find corresponding indexes from dataframe\n        idxs = array(list(X.index))\n        train_idxs = idxs[np.where((y.isna().sum(1) == 0))[0]]\n        test_idxs = idxs[np.where((y.isna().sum(1) != 0))[0]]\n\n        # fit KNN\n        X_train, y_train, X_test, y_test = X.loc[train_idxs], y.loc[train_idxs], X.loc[test_idxs], y.loc[test_idxs]\n        knn.fit(X_train, y_train)\n\n        # predict and put encoded features\n        train_preds, test_preds = knn.predict(X_train), knn.predict(X_test)\n        train_test_features_df.loc[train_idxs, knn_cols] = train_preds\n        train_test_features_df.loc[test_idxs, knn_cols] = test_preds","42a2aee9":"train_test_features_df","5a5a2521":"train_features_df = train_test_features_df[:n_train].reset_index(drop=True)\ntest_features_df = train_test_features_df[n_train:].reset_index(drop=True)\nassert np.sum(train_features_df.isna()).sum() == 0\nassert np.sum(test_features_df.isna()).sum() == 0","982bafa0":"train_features_df.shape, test_features_df.shape","78eb856c":"train_features_df.head()","462ae81a":"test_features_df.head()","5569067b":"train_features_df.shape","5b884557":"from fastai.tabular.all import *","e33b294f":"# Loss\n@log_args\nclass LabelSmoothingBCEWithLogits(Module):\n    y_int = True\n    def __init__(self, eps:float=0.1): store_attr('eps')\n\n    def forward(self, output, target):\n        target = target + self.eps*(1-2*target)\n        return F.binary_cross_entropy_with_logits(output, target)\n\n    def decodes(self, x):    return x>self.thresh\n    def activation(self, x): return torch.sigmoid(x)","a63b115d":"# Metric\ndef clipped_bce(inp, targ): return F.binary_cross_entropy(torch.clamp(inp.sigmoid(),1e-15, 1-1e-15), targ.float())\nmetric = AvgMetric(clipped_bce)","c991b064":"cat_names = []\ncont_names = L(list(train_features_df.columns[4:]))\ny_names = nonscored_cols","f2e97585":"merged_nonscored_train_df = train_features_df.merge(train_targets_nonscored_df, on='sig_id', how='left')","3ec5eef7":"logspath = Path(\"logs\")\nif not logspath.exists(): logspath.mkdir()","c3b0da40":"# drop control perturbation\nctl_sig_ids = merged_nonscored_train_df.query(\"cp_type=='ctl_vehicle'\")['sig_id'].values\ntrn_df = merged_nonscored_train_df[~merged_nonscored_train_df['sig_id'].isin(ctl_sig_ids)]","d29621f2":"trn_df","accb7c3c":"trn_df.shape","2d9e5760":"procs = []\ndls = TabularDataLoaders.from_df(merged_nonscored_train_df,\n                                 procs=procs,\n                                 cat_names=cat_names, \n                                 cont_names=cont_names, \n                                 y_names=y_names,\n                                 valid_idx=[], # use all data\n                                 bs=128)","8ae1a79f":"tl_learner = tabular_learner(dls,\n                             layers=ParamConfig.model_n_layers*[ParamConfig.model_layer_width],\n                             config = {\"ps\": ParamConfig.model_n_layers*[ParamConfig.model_ps]},\n                             n_out=len(nonscored_cols), \n                             loss_func=LabelSmoothingBCEWithLogits(ParamConfig.tl_smoothing),\n                             metrics=[metric])","2f35a2bd":"tl_learner.model","e3e48bc2":"if ParamConfig.do_transfer_learning: tl_learner.fit_flat_cos(ParamConfig.tl_n_epochs, lr=ParamConfig.tl_lr)","841f867e":"if ParamConfig.do_transfer_learning:  tl_learner.save(\"pretrained_tabular\", with_opt=False);","285b2adf":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","370a016f":"merged_scored_train_df = train_features_df.merge(train_targets_scored_df, on='sig_id', how='left')\n# drop control perturbation\nctl_sig_ids = merged_scored_train_df.query(\"cp_type=='ctl_vehicle'\")['sig_id'].values\ntrn_df = merged_scored_train_df[~merged_scored_train_df['sig_id'].isin(ctl_sig_ids)]","1c71e057":"y_names = scored_cols","eb4c8381":"N_FOLDS = 10\nmskf = MultilabelStratifiedKFold(n_splits=N_FOLDS)","70a63bbb":"sig_ids = trn_df['sig_id'].values\ncv_idxs = list(mskf.split(sig_ids, y=trn_df[y_names]))","8606af7c":"cvpath = Path(\"cv_sig_ids\")\nif not cvpath.exists(): cvpath.mkdir()\nfor i, idxs in enumerate(cv_idxs): pd.to_pickle(sig_ids[idxs[1]], cvpath\/f'sig_ids_fold{i}.pkl')","b51cf394":"merged_scored_train_df.head()","899955e4":"if ParamConfig.do_transfer_learning: pretrained_statedict = torch.load(\"models\/pretrained_tabular.pth\", map_location=default_device())","1aba4477":"def load_top_layers(learner, pretrained_statedict):\n    i = 0\n    for n, p in learner.model.named_parameters():\n        try:\n            p.data.copy_(pretrained_statedict[n])\n            print(f\"Loaded {n}\")\n            i += 1\n        except:\n            continue\n    \n    if i == 0: \n        print(\"No parameter is loaded\")\n        if ParamConfig.do_transfer_learning: raise Exception(\"Transfer learning is set True but no parameter loaded!\")\n    else: \n        print(f\"Total of loaded params: {i}\")","721f5aca":"for FOLD in range(N_FOLDS):\n    valid_sig_ids = pd.read_pickle(cvpath\/f'sig_ids_fold{FOLD}.pkl')\n    valid_idxs = np.where(trn_df.sig_id.isin(valid_sig_ids))[0]\n    procs = []\n    dls = TabularDataLoaders.from_df(trn_df,\n                                     procs=procs,\n                                     cat_names=cat_names, \n                                     cont_names=cont_names,\n                                     y_names=y_names,\n                                     valid_idx=valid_idxs,\n                                     bs=128)\n    learner = tabular_learner(dls,\n                              layers=ParamConfig.model_n_layers*[ParamConfig.model_layer_width],\n                              config = {\"ps\": ParamConfig.model_n_layers*[ParamConfig.model_ps]},\n                              n_out=len(scored_cols), \n                              loss_func=LabelSmoothingBCEWithLogits(ParamConfig.ft_smoothing),\n                              metrics=[metric])\n    \n    if ParamConfig.do_transfer_learning: load_top_layers(learner, pretrained_statedict)\n    \n    learner.fit_flat_cos(ParamConfig.ft_n_epochs,\n                         lr=ParamConfig.ft_lr,\n                         cbs=[SaveModelCallback(monitor='clipped_bce', \n                                                fname=f'tabular_fold{FOLD}',\n                                                comp=np.less),\n                              EarlyStoppingCallback(monitor='clipped_bce', \n                                                    patience=5,\n                                                    comp=np.less),\n                              CSVLogger(fname=f\"logs\/tabular_logs_fold{FOLD}.csv\")])\n    \n    learner.export(f'models\/tabular_fold{FOLD}_export.pkl')","386aab8e":"fold_metrics = [pd.read_csv(logspath\/f'tabular_logs_fold{FOLD}.csv')['clipped_bce'].min() for FOLD in range(10)]","79125315":"np.mean(fold_metrics), np.std(fold_metrics)","6c0fe35f":"modelspath = Path(\"models\")","8a47f74f":"fold_preds = []\nfor i in range(10):\n    learner = load_learner(modelspath\/f'tabular_fold{i}_export.pkl')\n    test_dl = learner.dls.test_dl(test_features_df)\n    preds, _ = learner.get_preds(dl=test_dl)\n    fold_preds += [preds]\npreds = torch.stack(fold_preds)","08a4735a":"mean_preds = preds.mean(0)","a4900d92":"sub_df = pd.DataFrame(mean_preds, columns=test_dl.y_names)\nsub_df['sig_id'] = test_dl.items['sig_id']\nsub_df = sub_df[['sig_id']+test_dl.y_names]","ebdcba86":"ctl_sig_ids = test_features_df.query(\"cp_type == 'ctl_vehicle'\")['sig_id'].values","83eb6330":"sub_df.loc[sub_df.sig_id.isin(ctl_sig_ids), test_dl.y_names] = 0","6c69a66e":"sub_df.to_csv(\"submission.csv\", index=False)","d44dd118":"### QuantileTransform","278e79e9":"### KNN Non-Scored Target Encoding","8b0c2730":"### New train, test ","10109cf1":"### Pretrained Model (Non-Scored)","8a011d3a":"### PCA","fef34f4b":"### Scored Model","92a31d84":"### Inference","518f9ea1":"### Scored Model","1634e9e4":"### Loss\/Metric\/Model","cd2b6625":"### Validation","d036db7e":"### Config\n\nUseful for hyperparameter search","70593291":"### Plot Dist","a83d01db":"### UMAP","460c2c96":"### One-hot Encode","3a8409bc":"### Feature Distributions","6b9225fa":"### RankGauss"}}