{"cell_type":{"7439aa9d":"code","da2380b8":"code","1ef6fc28":"code","030f8bd6":"code","9022765a":"code","940bd94a":"code","1d4212d9":"code","11c99da1":"code","0839f74a":"code","3dfb19aa":"code","56f2b3b2":"code","fe9a4b94":"code","eab3bbbe":"code","732beaf8":"code","988c4f65":"code","4fa10683":"code","ef4b624b":"code","b94b4363":"code","81db2df3":"code","dc1c1a7f":"code","650d6ab7":"code","ad13f25f":"code","e5422126":"markdown","9ebfefb7":"markdown","0b2d5631":"markdown","b2b438ca":"markdown","8a3afe52":"markdown"},"source":{"7439aa9d":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\n\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom shutil import copyfile, rmtree","da2380b8":"input_dir = '..\/input\/brain-mri-images-for-brain-tumor-detection\/'\nbase_dir = '..\/working\/'\n\nno_dir = os.path.join(input_dir, 'no\/')\nyes_dir = os.path.join(input_dir, 'yes\/')\ntraining_dir = os.path.join(base_dir, 'brain-mri-images-for-brain-tumor-detection\/training\/')\ntesting_dir = os.path.join(base_dir, 'brain-mri-images-for-brain-tumor-detection\/testing\/')\nno_training_dir = os.path.join(training_dir, 'no\/')\nyes_training_dir = os.path.join(training_dir, 'yes\/')\nno_testing_dir = os.path.join(testing_dir, 'no\/')\nyes_testing_dir = os.path.join(testing_dir, 'yes\/')","1ef6fc28":"try:\n    rmtree(training_dir)\n    rmtree(testing_dir)\nexcept OSError:\n    pass","030f8bd6":"try:\n    os.makedirs(training_dir)\n    os.makedirs(testing_dir)\n    os.makedirs(no_training_dir)\n    os.makedirs(yes_training_dir)\n    os.makedirs(no_testing_dir)\n    os.makedirs(yes_testing_dir)\nexcept OSError:\n    pass","9022765a":"def split_data(source, training, testing, split_size):\n    files = []\n    for filename in os.listdir(source):\n        filename = filename.replace('\/', '\/\/')\n        file = source + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \" is zero length, so ignoring.\")\n\n    training_length = int(len(files) * split_size)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[-testing_length:]\n\n    for filename in training_set:\n        this_file = source + filename\n        destination = training + filename\n        copyfile(this_file,\n                 destination)\n\n    for filename in testing_set:\n        this_file = source + filename\n        destination = testing + filename\n        copyfile(this_file,\n                 destination)","940bd94a":"split_size = .9\nsplit_data(no_dir, no_training_dir, no_testing_dir, split_size)\nsplit_data(yes_dir, yes_training_dir, yes_testing_dir, split_size)","1d4212d9":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(training_dir,\n                                                    batch_size=64,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(testing_dir,\n                                                              batch_size=64,\n                                                              class_mode='binary',\n                                                              target_size=(150, 150))","11c99da1":"# View images\nfig, ax = plt.subplots(nrows=1, ncols=6, figsize=(20,20))\n\nfor i in range(6):\n    # convert to unsigned integers for plotting\n    batch = next(train_generator)\n    image = batch[0]\n    label = batch[1]\n    image = np.squeeze(image[i])\n    # plot raw pixel data\n    ax[i].imshow(image)\n    ax[i].axis('off')\n    ax[i].title.set_text(f'tumor = {label[i]}')\n","0839f74a":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), 4,  activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=RMSprop(learning_rate=0.00001),\n              loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                    epochs=200,\n                    verbose=1,\n                    validation_data=validation_generator)","3dfb19aa":"model.summary()","56f2b3b2":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","fe9a4b94":"predictions = model.predict(validation_generator)\npredictions = np.round(predictions).tolist()\n\ny_true = validation_generator.labels\ny_pred = predictions","eab3bbbe":"print(classification_report(y_true, y_pred))","732beaf8":"print(confusion_matrix(y_true, y_pred))","988c4f65":"model.evaluate(validation_generator)","4fa10683":"model = tf.keras.models.Sequential([\n    tf.keras.applications.InceptionResNetV2(weights='imagenet', \n                                            input_shape = (150,150,3),\n                                            include_top=False),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')])\n\nmodel.compile(optimizer=RMSprop(learning_rate=0.00001),\n              loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                    epochs=25,\n                    verbose=1,\n                    validation_data=validation_generator)","ef4b624b":"model.summary()","b94b4363":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","81db2df3":"predictions = model.predict(validation_generator)\npredictions = np.round(predictions).tolist()\n\ny_true = validation_generator.labels\ny_pred = predictions","dc1c1a7f":"print(classification_report(y_true, y_pred))","650d6ab7":"print(confusion_matrix(y_true, y_pred))","ad13f25f":"model.evaluate(validation_generator)","e5422126":"# Create neural network","9ebfefb7":"# Transfer Learning","0b2d5631":"# Setup ","b2b438ca":"# Images","8a3afe52":"# My first kaggle notebook\n\nWelcome to my first kaggle notebook, I'm working on developing my deep learning\/neural network skills so any comments\/feedback is welcome :)"}}