{"cell_type":{"38e5a82d":"code","eb17b1fa":"code","d810f46e":"code","6be46d45":"code","f40a32e1":"code","8c3e5c8b":"code","98fbfb24":"code","776a158c":"code","5f1b8ee8":"code","35c4cd9b":"code","c2f1c6e1":"code","1d1e6a62":"code","6db815a9":"code","306e2815":"code","cbc3da97":"code","2b421ed8":"code","bc050c39":"code","909064a1":"code","d5276faa":"code","22692232":"code","529af72c":"code","3b239492":"code","15fca50e":"code","3f148402":"code","6f8b4ac8":"code","9d1f676e":"markdown","4bf661e2":"markdown","2b892f18":"markdown","1b6064c3":"markdown","898198dc":"markdown","7063b87a":"markdown","1dda20ce":"markdown","16f6fd3c":"markdown","b0f728ed":"markdown","780d1cc6":"markdown","af9b6493":"markdown","6e4f447d":"markdown","552bd5c0":"markdown","70ddd30f":"markdown","916c100b":"markdown","542f39e0":"markdown","06981019":"markdown","2e99a7c4":"markdown","755bb1d7":"markdown","d8cd153e":"markdown","a25543cf":"markdown","3312cfc2":"markdown","63599f94":"markdown"},"source":{"38e5a82d":"# Import\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport fastai\nfrom fastai.tabular.all import *","eb17b1fa":"# Check for version\nfastai.__version__","d810f46e":"# Load data\ndf_train = pd.read_csv('..\/input\/widsdatathon2021\/TrainingWiDS2021.csv', index_col=1)\ndf_test = pd.read_csv('..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv', index_col=1)\ndf_train.shape, df_test.shape","6be46d45":"# Print first 5 rows of train data\ndf_train.head()","f40a32e1":"# Drop Unnamed: 0 column from train and test dataframe\ndf_train = df_train.drop(columns=['Unnamed: 0'])\ndf_test = df_test.drop(columns=['Unnamed: 0'])","8c3e5c8b":"# # Define continous and categorical columns\n# numerical_feats = train.dtypes[df_train.dtypes != \"object\"].index\n# print(\"Number of Numerical features: \", len(numerical_feats))\n\n# categorical_feats = train.dtypes[df_train.dtypes == \"object\"].index\n# print(\"Number of Categorical features: \", len(categorical_feats))","98fbfb24":"cont_nn, cat_nn = cont_cat_split(df_train, dep_var='diabetes_mellitus')\nprint(len(cont_nn))\nprint(len(cat_nn))","776a158c":"# print 5 features each from cont and categorical features\nprint(cont_nn[:5])\nprint(cat_nn[:5])","5f1b8ee8":"# Define processes\nprocs = [FillMissing, Categorify, Normalize]","35c4cd9b":"# Split train data to train and validation parts\nsplits = RandomSplitter(valid_pct=0.3)(range_of(df_train))\nsplits","c2f1c6e1":"# df_train['diabetes_mellitus'] = df_train['diabetes_mellitus'].astype(np.float32)","1d1e6a62":"dls = TabularDataLoaders.from_df(df=df_train, y_names=\"diabetes_mellitus\",\n            cat_names = cat_nn,\n            cont_names = cont_nn,\n            procs = [Categorify, FillMissing, Normalize],\n            splits = splits,\n            bs = 64)","6db815a9":"dls.show_batch()","306e2815":"learn = tabular_learner(dls, metrics = accuracy )","cbc3da97":"learn.summary()","2b421ed8":"learn.fit_one_cycle(n_epoch=2,lr_max=1e-3)","bc050c39":"import sklearn.metrics as skm\n \ndef _accumulate(self, learn):\n    #pred = learn.pred.argmax(dim=self.dim_argmax) if self.dim_argmax else learn.pred\n    m = nn.Sigmoid()\n    pred = learn.pred\n    pred = torch.round(m(pred))\n    targ = learn.y\n    pred,targ = to_detach(pred),to_detach(targ)\n    self.preds.append(pred)\n    self.targs.append(targ)\n\nAccumMetric.accumulate = _accumulate\n\ndef BinAccu():\n    return skm_to_fastai(skm.roc_auc_score)","909064a1":"binaccu = BinAccu()\nlearn = tabular_learner(dls, metrics=[binaccu])","d5276faa":"learn.lr_find()","22692232":"learn.fit_one_cycle(2,1e-3)","529af72c":"learn.recorder.plot_loss()","3b239492":"learn.show_results()","15fca50e":"binaccu = BinAccu()\nlearn = tabular_learner(dls, layers=[256,256], n_out=1, metrics=[binaccu])","3f148402":"learn.fit_one_cycle(2,1e-5)","6f8b4ac8":"learn.export()","9d1f676e":"![image.png](attachment:image.png)\n\n\n*Image credit: Google Images*\n\n*FastAI Documentation: [https:\/\/docs.fast.ai\/](https:\/\/docs.fast.ai\/)*","4bf661e2":"*Finally, lets put all pieces together*","2b892f18":"*As seen in many public notebooks and my analysis notebook, we have missing values in data, categorical values and data with different units that needs normalization.*\n\n*In FastAI, we can just utilize existing functions and make a list of processes to be done on data.*\n\n*I have taken only three processes for demonstration purpose.*","1b6064c3":"*Training the model, using provided metric accuracy*","898198dc":"<span style=\"background: yellow; color:blue\">Explanation:<\/span>\n\n*Predictions by tabular_learner are floating point values. MSE loss function will perform good for these values. Numbers will not be in range 0-1 anymore. It can be anything. This will cause malfunction with accuracy as metric. So, we need to define our own metric.*\n\n*Use of sigmoid function in this case can bring values between 0 and 1.*","7063b87a":"*At last, target variable should be should be float type. Because our loss function is going to be mse.*","1dda20ce":"*This is my 3rd notebook in this competition. The objective is to getting started and try out deep learning for tabular data classification in WiDS 2021.*\n\n*Before starting with this notebook, I would recommend to analyze the data and get some insights. Please refer to my notebook [Statistical Analysis: Univariate and Multivariate](https:\/\/www.kaggle.com\/reverie5\/statistical-analysis-univariate-multivariate) for the detailed analysis.*\n\n*Also refer to my second notebook for where I have performed performance comparison of different ML algorithms. Link to notebook: [[PyCaret] ML models comparison | Blends](https:\/\/www.kaggle.com\/reverie5\/pycaret-ml-models-comparison-blends)*","16f6fd3c":"*Note:*\n\n>FillMissing: Ofcourse it fills the missing value. But it also provide boolean type column if a feature has missing value or not.","b0f728ed":"*To see model structure\/ summary*","780d1cc6":"*As next step, lets just split training data into train and validation part. For this we can utlize another cool feature that is RandomSplitter. I'll use 30% of train data as validation.*","af9b6493":"*To start with, we have to separate separate categorical and continous variables (features). We can either write few lines of code to separate datatypes as commented below.*","6e4f447d":"<span style=\"background: yellow; color:blue\">Learning rate finder:<\/span>\n\n*From FastAI documentation, this is what learning learning rate finder does:*\n\n*It plots lr vs loss relationship for a Learner. The idea is to reduce the amount of guesswork on picking a good starting learning rate.*\n\n    First run lr_find learn.lr_find()\n    Plot the learning rate vs loss learn.recorder.plot()\n    Pick a learning rate before it diverges then start training","552bd5c0":"<span style=\"background: yellow; color:blue\">Observation:<\/span>\n\n*Goal is to minimize loss function.* \n\n*Our training and validation loss is decreasing. That is good thing. But our accuracy remains same. Why?*","70ddd30f":"**What is this notebook about??**\n\n- The objective of this notebook is to do <span style=\"background:yellow; font-weight: bold\">step by step implementation of deeplearning for tabular data using FastAI<\/span> version 2 to predict diabetes_mellitus.\n- This is supposed to be a Starter notebook to help beginners start their journey.","916c100b":"**If you found this notebook useful, Kindly upvote.**\n\n**You can leave your suggestions\/ queries in comment box below. Thank you. :)**","542f39e0":"*Custom metrics in FastAI can be defined using skm_to_fastai method.*\n\n[Credit: this article](https:\/\/lschmiddey.github.io\/fastpages_\/2020\/10\/01\/Tabular-Data-with-custom-metric.html)","06981019":"*Export and save model in pkl file format*\n\n*Default save location: .\/export.pkl*","2e99a7c4":"*Or, we can make use of the \"cont_cat_split\" function from FastAI to easily get a list of column names for each categorical and continuous variable.*","755bb1d7":"*In this notebook, we are going to use FastAI on our tabular data to predict diabetes_mellitus*\n\n*Lets start by importing some libraries.*","d8cd153e":"### To be continued...","a25543cf":"*FastAI has two major versions. The latest version is FastAI version 2.*","3312cfc2":"<span style=\"background: yellow; color:blue\">What is FastAI?<\/span>\n\n*Before answering this, lets see what different deeplearning libraries we have -*\n\n*We have numerous deeplearning libraries, TensorFlow, Pytorch, Theano, ML.NET, mlpack, Flux etc. But the two most popular ones are TensorFlow and Pytorch.*\n\n*FastAI is emerging framework. It is focused on making implementation of deeplearning networks simple and accessible to all. FastAI is a deep learning library for python. Basically its a layered API for deep learning built on top of Pytorch. (Though in earlier days it used to have TensorFlow as backend. :))*\n\n<span style=\"background: yellow; color:blue\">Why layered API?<\/span>\n\n*It has 3 levels of APIs, High, mid and low. So a beginner can use high level API to apply pre-existing methods and develop a good model in few lines of code. Similary, for a person with some experience in coding and data science, mid and low level API methods can offer a wide range of customization.*\n\n<span style=\"background: yellow; color:blue\">What all can we do with FastAI?<\/span>\n\n*It's main application areas are vision, text, tabular and time-series analysis, and collaborative filtering.*","63599f94":"*For explaining workflow, I have trained for 2 epoch only. Please train till validation loss and training loss no longer improves.*"}}