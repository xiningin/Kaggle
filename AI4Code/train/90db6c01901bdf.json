{"cell_type":{"98f0ff0d":"code","9f25473a":"code","55e95337":"code","44d685fd":"code","92444e26":"code","e05f9fb6":"code","98e0a643":"code","ac81a97d":"code","6deb0908":"code","972bc0e9":"code","fa50dc9e":"code","cbc8222e":"code","b9108bd3":"code","5d6601df":"code","36c987b7":"code","72aa86ac":"code","78f6f282":"code","b84fc9b1":"code","99bf394d":"markdown"},"source":{"98f0ff0d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9f25473a":"import keras\nfrom keras.preprocessing.text import one_hot, Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import *\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import Sequential\nimport pyprind","55e95337":"# https:\/\/pypi.org\/project\/keras-self-attention\/\nimport sys\nsys.path.insert(0, '..\/input\/attention')\nfrom seq_self_attention import SeqSelfAttention","44d685fd":"df = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')","92444e26":"trainig_sample = df.sample(100000, random_state=0)\nX_train = trainig_sample['comment_text'].astype(str)\nX_train = X_train.fillna('DUMMY')\ny_train = trainig_sample['target']\ny_train = y_train.apply(lambda x: 1 if x > 0.5 else 0)","e05f9fb6":"max_num_words = 20000\nmax_length = 128\ntokenizer = Tokenizer(num_words=max_num_words)\ntokenizer.fit_on_texts(X_train)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","98e0a643":"def get_seqs(text):\n    sequences = tokenizer.texts_to_sequences(text)\n    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n    return padded_sequences","ac81a97d":"model = Sequential()\nmodel.add(Embedding(max_num_words, 100, input_length=max_length))\nmodel.add(Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(SeqSelfAttention(attention_activation='sigmoid'))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))","6deb0908":"model.summary()","972bc0e9":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","fa50dc9e":"model.fit(get_seqs(X_train), y_train, epochs=2)","cbc8222e":"validation_sample = df.sample(500, random_state=42)\nX_val = validation_sample['comment_text'].astype(str)\nX_val = X_val.fillna('DUMMY')\ny_val = validation_sample['target']\ny_val = y_val.apply(lambda x: 1 if x > 0.5 else 0)","b9108bd3":"loss, accuracy = model.evaluate(get_seqs(X_val), y_val)\nprint('Evaluation accuracy: {0}'.format(accuracy))","5d6601df":"test = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')","36c987b7":"X_test = test['comment_text'].astype(str)\nX_test = X_test.fillna('DUMMY')","72aa86ac":"probs = model.predict(get_seqs(X_test), verbose=1)","78f6f282":"probs = [x[0] for x in probs]","b84fc9b1":"submission = pd.DataFrame(test['id']).reset_index(drop=True)\nsubmission['prediction'] = pd.Series(probs, name='prediction')\nsubmission.to_csv('submission.csv', index=False)","99bf394d":"# A simple Keras based bidirectional LSTM with self-attention ready for tuning!"}}