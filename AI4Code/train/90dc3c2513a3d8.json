{"cell_type":{"49c530ea":"code","d81fa854":"code","c7c3ab14":"code","b9e540d0":"code","1c794782":"code","336bb6d9":"code","dc1e3e52":"code","f188f316":"code","87608cd6":"code","45c8e776":"code","03d643c8":"code","00c31cdc":"code","ad76d446":"code","e65eea81":"code","077a359f":"code","e9ec01c4":"code","5eef3ca1":"markdown","af8a1f34":"markdown","59ae0366":"markdown","99542ef8":"markdown","fb6c1e50":"markdown","19322aba":"markdown","b0da8ee6":"markdown","9e62978e":"markdown","e09e452f":"markdown","2c17df0b":"markdown","96e7689d":"markdown","b5e8551a":"markdown","497dc2e0":"markdown"},"source":{"49c530ea":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport lightgbm as lgb\n\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn import metrics\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d81fa854":"train =pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\ntest =pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\nsample=pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/sample_submission.csv\")","c7c3ab14":"train.head()","b9e540d0":"print(train.shape)\nprint(test.shape)\nprint(train.columns)\nprint(test.columns)\nprint(train.info())\nprint(train.describe().transpose())\nprint(\"\\n\",train.isnull().sum())","1c794782":"print(set(test['breath_id'].unique()).intersection(set(train['breath_id'].unique())))\nprint(set(train['breath_id'].unique()).intersection(set(test['breath_id'].unique())))","336bb6d9":"print(test['breath_id'].nunique())\nprint(train['breath_id'].nunique())\nprint(train.shape ,test.shape)","dc1e3e52":"fig, ax = plt.subplots(figsize = (12, 8))\nfor i in range(1,3):\n    plt.subplot(2, 2, i)\n    sns.countplot(x='R', data=train)\n    plt.title('Counts of R in train');\nplt.show()\nfig, ax = plt.subplots(figsize = (12, 8))\nfor i in range(1,3):\n    plt.subplot(2, 2, i)\n    sns.countplot(x='R', data=test)\n    plt.title('Counts of R in test');\nplt.show()\nfig, ax = plt.subplots(figsize = (12, 8))\nfor i in range(1,3):\n    plt.subplot(2, 2, i)\n    sns.countplot(x='C', data=train)\n    plt.title('Counts of C in train');\nplt.show()\nfig, ax = plt.subplots(figsize = (12, 8))\nfor i in range(1,3):\n    plt.subplot(2, 2, i)\n    sns.countplot(x='C', data=test)\n    plt.title('Counts of C in test');\nplt.show()","f188f316":"fig, ax1 = plt.subplots(figsize = (12, 6))\n\nbreath_1 = train.loc[train['breath_id'] == 1]\nax2 = ax1.twinx()\n\nax1.plot(breath_1['time_step'], breath_1['pressure'], 'r-', label='pressure')\nax1.plot(breath_1['time_step'], breath_1['u_in'], 'g-', label='u_in')\nax2.plot(breath_1['time_step'], breath_1['u_out'], 'b-', label='u_out')\n\nax1.set_xlabel('Timestep')\n\nax1.legend(loc=(1.1, 0.8))\nax2.legend(loc=(1.1, 0.7))\nplt.show()","87608cd6":"# some of ideas from this notebook: https:\/\/www.kaggle.com\/mst8823\/google-brain-lightgbm-baseline\n\ntrain['last_value_u_in'] = train.groupby('breath_id')['u_in'].transform('last')\ntrain['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1)\ntrain['u_out_lag1'] = train.groupby('breath_id')['u_out'].shift(1)\ntrain['u_in_lag_back1'] = train.groupby('breath_id')['u_in'].shift(-1)\ntrain['u_out_lag_back1'] = train.groupby('breath_id')['u_out'].shift(-1)\ntrain['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\ntrain['u_out_lag2'] = train.groupby('breath_id')['u_out'].shift(2)\ntrain['u_in_lag_back2'] = train.groupby('breath_id')['u_in'].shift(-2)\ntrain['u_out_lag_back2'] = train.groupby('breath_id')['u_out'].shift(-2)\ntrain['u_in_lag3'] = train.groupby('breath_id')['u_in'].shift(3)\ntrain['u_out_lag3'] = train.groupby('breath_id')['u_out'].shift(3)\ntrain['u_in_lag_back3'] = train.groupby('breath_id')['u_in'].shift(-3)\ntrain['u_out_lag_back3'] = train.groupby('breath_id')['u_out'].shift(-3)\ntrain = train.fillna(0)\n\n\ntrain['R__C'] = train[\"R\"].astype(str) + '__' + train[\"C\"].astype(str)\n\n# max value of u_in and u_out for each breath\ntrain['breath_id__u_in__max'] = train.groupby(['breath_id'])['u_in'].transform('max')\ntrain['breath_id__u_out__max'] = train.groupby(['breath_id'])['u_out'].transform('max')\n\n# difference between consequitive values\ntrain['u_in_diff1'] = train['u_in'] - train['u_in_lag1']\ntrain['u_out_diff1'] = train['u_out'] - train['u_out_lag1']\ntrain['u_in_diff2'] = train['u_in'] - train['u_in_lag2']\ntrain['u_out_diff2'] = train['u_out'] - train['u_out_lag2']\n# from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\ntrain.loc[train['time_step'] == 0, 'u_in_diff'] = 0\ntrain.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n\n# difference between the current value of u_in and the max value within the breath\ntrain['breath_id__u_in__diffmax'] = train.groupby(['breath_id'])['u_in'].transform('max') - train['u_in']\ntrain['breath_id__u_in__diffmean'] = train.groupby(['breath_id'])['u_in'].transform('mean') - train['u_in']\n\n# OHE\ntrain = train.merge(pd.get_dummies(train['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntrain = train.merge(pd.get_dummies(train['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntrain = train.merge(pd.get_dummies(train['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n# https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\ntrain['u_in_cumsum'] = train.groupby(['breath_id'])['u_in'].cumsum()\ntrain['time_step_cumsum'] = train.groupby(['breath_id'])['time_step'].cumsum()","45c8e776":"\n#Same for the test data as we did for trian as above\ntest['last_value_u_in'] = test.groupby('breath_id')['u_in'].transform('last')\ntest['u_in_lag1'] = test.groupby('breath_id')['u_in'].shift(1)\ntest['u_out_lag1'] = test.groupby('breath_id')['u_out'].shift(1)\ntest['u_in_lag_back1'] = test.groupby('breath_id')['u_in'].shift(-1)\ntest['u_out_lag_back1'] = test.groupby('breath_id')['u_out'].shift(-1)\ntest['u_in_lag2'] = test.groupby('breath_id')['u_in'].shift(2)\ntest['u_out_lag2'] = test.groupby('breath_id')['u_out'].shift(2)\ntest['u_in_lag_back2'] = test.groupby('breath_id')['u_in'].shift(-2)\ntest['u_out_lag_back2'] = test.groupby('breath_id')['u_out'].shift(-2)\ntest['u_in_lag3'] = test.groupby('breath_id')['u_in'].shift(3)\ntest['u_out_lag3'] = test.groupby('breath_id')['u_out'].shift(3)\ntest['u_in_lag_back3'] = test.groupby('breath_id')['u_in'].shift(-3)\ntest['u_out_lag_back3'] = test.groupby('breath_id')['u_out'].shift(-3)\ntest = test.fillna(0)\ntest['R__C'] = test[\"R\"].astype(str) + '__' + test[\"C\"].astype(str)\n\ntest['breath_id__u_in__max'] = test.groupby(['breath_id'])['u_in'].transform('max')\ntest['breath_id__u_out__max'] = test.groupby(['breath_id'])['u_out'].transform('max')\n\ntest['u_in_diff1'] = test['u_in'] - test['u_in_lag1']\ntest['u_out_diff1'] = test['u_out'] - test['u_out_lag1']\ntest['u_in_diff2'] = test['u_in'] - test['u_in_lag2']\ntest['u_out_diff2'] = test['u_out'] - test['u_out_lag2']\ntest.loc[test['time_step'] == 0, 'u_in_diff'] = 0\ntest.loc[test['time_step'] == 0, 'u_out_diff'] = 0\n\ntest['breath_id__u_in__diffmax'] = test.groupby(['breath_id'])['u_in'].transform('max') - test['u_in']\ntest['breath_id__u_in__diffmean'] = test.groupby(['breath_id'])['u_in'].transform('mean') - test['u_in']\n\ntest = test.merge(pd.get_dummies(test['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntest = test.merge(pd.get_dummies(test['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntest = test.merge(pd.get_dummies(test['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\ntest['u_in_cumsum'] = test.groupby(['breath_id'])['u_in'].cumsum()\ntest['time_step_cumsum'] = test.groupby(['breath_id'])['time_step'].cumsum()\n","03d643c8":"scores = []\nfeature_importance = pd.DataFrame()\nmodels = []\ncolumns = [col for col in train.columns if col not in ['id', 'breath_id', 'pressure']]\nX = train[columns]\ny = train['pressure']\n\nparams = {'objective': 'regression',\n          'learning_rate': 0.3,\n          \"boosting_type\": \"gbdt\",\n          \"metric\": 'mae',\n          'n_jobs': -1,\n          'min_data_in_leaf':32,\n          'num_leaves':1024,\n         }","00c31cdc":"folds = GroupKFold(n_splits=5)\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params, n_estimators=10000)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=1000, early_stopping_rounds=15)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = columns\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)","ad76d446":"print('Mean score: {0:.4f}, Std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","e65eea81":"feature_importance[\"importance\"] \/= 5\ncols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)[:50].index\n\nbest_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\nplt.figure(figsize=(16, 12));\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\nplt.title('LGB Features (avg over folds)');","077a359f":"samplemodel in models:\n    sample['pressure'] += model.predict(test[columns])\nsample['pressure'] \/= 5","e9ec01c4":"sample.to_csv('My_Submission.csv', index=False)","5eef3ca1":"# Feature Engineering","af8a1f34":"From the above we canc see both R and C categorical variables have a similar distribution in train and test data.       Now, let's have a look at one of the series in the data.\n\n\n","59ae0366":"From the above we can confirm that the breath id's in train and test don't overlap! This means we should use GroupKFold validation using this variable.","99542ef8":"# Make Predictions","fb6c1e50":"We can see that at first the pressure (our target) is rising and then, after the u_out becomes equal to 1, it has an abrupt drop. I think it would be useful to create new features based on the behavior of these features.","19322aba":"# Finding the number of unique values ","b0da8ee6":"# Submission","9e62978e":"From the above dataset we can able to see that the data is quite large which as more than 6 million rows ","e09e452f":"# Data Preprocessing","2c17df0b":"# Visualising the Actual number of Folds","96e7689d":" Importance of LightGBM you can ref. my blog https:\/\/wordpress.com\/post\/sandeepraji.wordpress.com\/125","b5e8551a":"# Model Building ","497dc2e0":"# Performing EDA - first visualising the catergorical variables (R & C) for both train and test datasets"}}