{"cell_type":{"82222730":"code","c8b4d4bd":"code","be9d1024":"code","d0c0a43a":"code","4dffa65b":"code","673651ef":"code","27d1a8c1":"code","64f56131":"code","09c96608":"code","290df5c4":"code","97cbb28b":"code","ab56a1ff":"code","b1ead857":"code","99bd4688":"code","70d5a37e":"code","91ed7143":"code","15e5f7ef":"code","ce0e7344":"code","2bf9ee9c":"code","3f32563d":"code","e6035119":"code","8336b852":"code","e29b392b":"code","f27acd1d":"markdown","35da0e5b":"markdown","1cda7793":"markdown","a1d7be5f":"markdown","451fdf51":"markdown","b47bb0e2":"markdown","31d71d9b":"markdown","06e927eb":"markdown","4e484961":"markdown","05edac53":"markdown","d874a9fb":"markdown","edfb22c0":"markdown","55b652b8":"markdown","46900ef2":"markdown","20283b0b":"markdown","cfa4cc25":"markdown","3ccdb9b2":"markdown","91062d90":"markdown","3de989c0":"markdown","a88f497f":"markdown","5cec4220":"markdown","14c2031c":"markdown","46e7ab86":"markdown"},"source":{"82222730":"import os\nimport re\nimport string\nimport spacy\nimport nltk\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom spacy import displacy\nimport plotly.express as px \nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix,accuracy_score\nfrom sklearn.metrics import plot_precision_recall_curve,plot_roc_curve\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.linear_model import LogisticRegression\nfrom collections import Counter\nimport warnings\nnltk.download(\"vader_lexicon\")\nwarnings.filterwarnings('ignore')","c8b4d4bd":"data = pd.read_csv(\"..\/input\/amazonreviews\/amazonreviews.tsv\",sep=\"\\t\")\n","be9d1024":"data.head()","d0c0a43a":"sns.set(rc={'figure.figsize':(20,10)})\npx.histogram(data, x=\"label\",color='label')","4dffa65b":"def drop_nulls(data):\n    \n    empty_list = []\n    for index,label,reviews in data.itertuples():\n        if type(reviews)==str:\n            if reviews.isspace():\n                empty_list.append(reviews)\n     \n    \n    print('Is there any missing value?\\n')\n    if len(empty_list)==0:\n        print('-- \ud83d\udd2cThere is no missing value in this dataframe\ud83d\udd2c --')\n    else:\n        \n        print('Dataframe includes null values\ud83d\ude21. Missing value count is :{} \\n Missing value percentage is : {}'.format(len(empty_list),len(empty_list)\/len(data)))\n        data.drop(empty_list,inplace=True)\n        \n    return data","673651ef":"data = drop_nulls(data)","27d1a8c1":"analysis_sa = SentimentIntensityAnalyzer()","64f56131":"random_text = 'the most exciting book i have ever read'\nprint(analysis_sa.polarity_scores(random_text))","09c96608":"random_text = 'This was the worst film to ever disgrace the screen.'\nprint(analysis_sa.polarity_scores(random_text))","290df5c4":"data['score']= data['review'].apply(lambda rew: analysis_sa.polarity_scores(rew))\ndata['compound']= data['score'].apply(lambda score: score['compound'])\ndata['predict']= data['compound'].apply(lambda value: 'pos' if value >=0 else 'neg')","97cbb28b":"data","ab56a1ff":"print('Overall accuracy is {}\\n'.format(accuracy_score(data['label'],data['predict'])*100))\n\nprint(classification_report(data['label'],data['predict']))\nprint(confusion_matrix(data['label'],data['predict']))","b1ead857":"data['label_num'] = pd.get_dummies(data['label'],drop_first=True)","99bd4688":"class PredictReview:\n    \n    def vectorize(self,train_data,test_data):\n        \n        tfidf = TfidfVectorizer()\n        train = tfidf.fit_transform(train_data.values.astype('U'))\n        test = tfidf.transform(test_data.values.astype('U'))\n        \n        return train,test,tfidf\n    \n    def split(self,data,train_size=0.1,shuffle=101):\n        \n        input_data = data['review']\n        output_data = data['label_num']\n        train_data, test_data, train_output, test_output = train_test_split(input_data, output_data, test_size=train_size, random_state=shuffle)\n        return train_data, test_data, train_output, test_output\n    \n    def base(self,data):\n        \n        log_reg = LogisticRegression()\n        data = self.prepare_data_for_train(data)\n        train_data, test_data, train_output, test_output = self.split(data)\n        train,test,tfidf = self.vectorize(train_data,test_data)\n        log_reg.fit(train,train_output)\n        pred = log_reg.predict(test)\n        self.performance(pred,test,test_output,log_reg)\n        return log_reg,tfidf\n    \n   \n    def prepare_data_for_train(self,input_data):\n        \n        nlp = spacy.load('en_core_web_sm')\n        stopword = nltk.corpus.stopwords.words('english')\n        empty_list  = []\n        for text in input_data.review:\n            text = text.lower()\n            text = re.sub('\\[.*?\\]', '', text)\n            text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n            text = re.sub('<.*?>+', '', text)\n            text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n            text = re.sub('\\n', '', text)\n            text = re.sub('\\w*\\d\\w*', '', text)\n            text = re.sub(r'[^\\w\\s]', '',str(text))            \n            text=re.split(\"\\W+\",text)                          \n            text=[word for word in text if word not in stopword]\n            text = ' '.join(text)       \n            empty_list.append(text)\n        #input_data.drop('review',axis=1,inplace=True)\n        input_data['review'] = empty_list\n        return input_data\n    \n    \n    def performance(self,_data,test_data,test_output,model):\n        \n        plt.figure(figsize=(12,12))\n       \n        print(plot_confusion_matrix(model,test_data,test_output))\n        print(plot_precision_recall_curve(model,test_data,test_output))\n        print(plot_roc_curve(model,test_data,test_output))\n        print('\\033[36m'+classification_report(_data,test_output))\n        print('\\033[4m'+'\\033[91m'+'\\033[1m' +'Overall accuracy is {}% \ud83d\udca3\\n'.format(round(accuracy_score(_data,test_output)*100),0))\n        plt.show()\n     \n        \n    def test_sample(self,text,tfidf,base_model):\n        \n        text = self.clean_df(text)\n        text_sample = tfidf.transform([text])\n        pred = base_model.predict(text_sample)\n        if pred[0] == 1:\n            return 'positive'\n        else:\n            return 'negative'\n        \n    def  clean_df(self,text):\n        text = text.lower()\n        nlp = spacy.load('en_core_web_sm')\n        stopword = nltk.corpus.stopwords.words('english')\n        text = re.sub(r'[^\\w\\s]', '',str(text))            \n        text=re.split(\"\\W+\",text)                          \n        text=[word for word in text if word not in stopword]\n        text = ' '.join(text)                              \n        return text","70d5a37e":"review_predictor = PredictReview()","91ed7143":"model,coverter = review_predictor.base(data)","15e5f7ef":"def quick_preictor(text):\n    answer = review_predictor.test_sample(text,coverter,model)\n    if answer == 'negative':\n        print('\\033[1m'+'\\033[91m'+'Prediction is : '+answer+\"\\n\")\n        print(text)\n    else:\n        print('\\033[1m'+'\\033[92m'+'Prediction is : '+answer+\"\\n\")\n        print(text)","ce0e7344":"text = 'Purchased this keyboard in September 2018 and it has already stopped working. Some keys do not work while others simply input a gibberish combination of characters. I also purchased the 4 year squaretrade warranty but since it is under the manufacturer warranty they wont allow me to make a claim.'\nquick_preictor(text)","2bf9ee9c":"text = 'Love it just have to sync it up with all the other RGB but love it. Big Razor fan'\nquick_preictor(text)","3f32563d":"text = \"I get cold really easy and this jacket is great if you want a warm one. I'm 5'10 and weigh 135lbs and the small fits me well. It has fleece lined pockets and a fleece lined hood. It has a good quality YKK zipper. The coat snaps shut in addition to zippering shut. It has elastic around the wrists for a nice tight fit that won't allow breezes to flow up your arm. There a fleece-line inside pocket about chest high big enough for a cell phone or wallet. It has a velcro enclosure.\"\nquick_preictor(text)","e6035119":"text = \"Dont do it ! It will tell u steps and heartbeat .. But dont bother connecting it to your phone \ud83d\udc4e Not android anyways.\"\nquick_preictor(text)","8336b852":"text = \"I have owned two Samsung smartwatches, one Fitbit, and a new Apple watch 6 for wife, but I am looking for a simple, light, long battery life particularly with Alexa control function smart device. I finally made decision to try it. It took less than 5 minutes to setup EVERYTHING. The screen is beautiful, super crisp text. The Alexa function works perfectly even without the ability of speaker. I can read text message, and get phone call notification. It has a lot of basic health fitness tracker features that are very useful. I would give it 5+ stars.\"\nquick_preictor(text)","e29b392b":"text = \"The WATCH is awesome! Does what i need it to do. Counts my steps and my calories while doing my workout.The battery life is great! Better than my previous watch. You can also change the strap with other ones used for other watches.\"\nquick_preictor(text)","f27acd1d":"#### I HOPE YOU ENJOY \u270c\ud83c\udffb\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/i2.wp.com\/www.thirstydaddy.com\/wp-content\/uploads\/2015\/05\/thanks-for-reading.png\" alt=\"Heat beating\" style=\"height:300px;margin-top:3rem;\"> <\/div>","35da0e5b":"# Sentiment Intensity Analyzer \ud83d\udcda","1cda7793":"### \ud83d\udcddTest Random Review \ud83d\udcdd","a1d7be5f":"###### Create instance","451fdf51":"## How it works?\u2699","b47bb0e2":"`amazonreviews.tsv` Amazone Review Anlysis\n\nHeader | Definition\n---|---------\n`Label`| Status of Comments shows that reviews positive(pos) or negative(neg)\n`Review` | Actual Reviews from Amazone","31d71d9b":"# \ud83d\udcdaLibraries","06e927eb":"> It Looks Like We Have a Normal Distributions","4e484961":"## \ud83c\udf40CALL OUR CLASS\ud83c\udf40","05edac53":"# `CONSEPT OF DATA`\ud83d\udc68\u200d\ud83d\udd2c","d874a9fb":"##### TRAIN DATA","edfb22c0":"## \ud83d\udcd6Read Data","55b652b8":"### Let's write function for prediction and make it looks simple \ud83d\udee0","46900ef2":"\n### \u2618 `We read and analyze\ud83d\udcca what is written about the product before purchase it. `\n### `What if the machine reads instead of us? In this notebook, we will analyze the comments on the products on the Amazon site and build a machine learning model\ud83d\udcc9.`\n### `We'll predict whether general reviews on products are negative or positive. In order to do this, we will first use Sentiment Intensity Analyzer \ud83d\udcda, then we will try to increase our accuracy by the usning Logistic regression\u2728`","20283b0b":"### We are going to create class for logistic regression.","cfa4cc25":"> `Sentiment analysis is a text analysis method that detects polarity (e.g. a positive or negative opinion) within the text, whether a whole document, paragraph, sentence, or clause.`\n\n>`Sentiment analysis aims to measure the attitude, sentiments, evaluations, attitudes, and emotions of a speaker\/writer based on the computational treatment of subjectivity in a text.`","3ccdb9b2":"### \u26a1Measure the peformance\u26a1","91062d90":"> Everything looks great so far \ud83d\udc4c","3de989c0":"### Checking missing values","a88f497f":"## Let's apply analyzed to our data ","5cec4220":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/media.giphy.com\/media\/A7rTdPxXP9fqM\/giphy.gif?w=640\" alt=\"Heat beating\" style=\"height:700px;margin-top:3rem;\"> <\/div>","14c2031c":"# END\ud83d\ude07","46e7ab86":"# \ud83d\udcccNLP FOR SEGMENT\ud83d\udccc"}}