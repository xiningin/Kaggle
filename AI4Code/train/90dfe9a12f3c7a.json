{"cell_type":{"8b964de9":"code","8c647f3d":"code","d51d6fb9":"code","bc19f26f":"code","a5e45dcf":"code","91e556ea":"code","63cc7cb7":"code","7b164dc3":"markdown","ba49637d":"markdown","54e37fec":"markdown","0d60843a":"markdown","9646350d":"markdown","f6a012cc":"markdown"},"source":{"8b964de9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c647f3d":"# Library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nimport itertools\nimport tensorflow as tf\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\n\n# Modul\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n                        module=\"sklearn\")\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.YlGn):\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","d51d6fb9":"file = pd.read_csv('..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv')\ncol = file.columns\ndf_data = pd.DataFrame(file, index=None)\nnp_data = np.array(file)\ndf_data.head(10)","bc19f26f":"kondisi = ['Sehat', 'Sakit']\njumlah = [np_data[:,-1][np_data[:,-1]==0].shape[0], np_data[:,-1][np_data[:,-1]==1].shape[0]]\nplt.bar(kondisi,jumlah, color=['seagreen', 'red'])\nplt.show()\nprint(f\"Sehat: {jumlah[0]}, Sakit: {jumlah[1]}\")","a5e45dcf":"fitur = []\ntarget = []\nfitur = StandardScaler().fit_transform(np_data)\n# fitur = fitur[:,:-1].reshape(297, 13, 1)\ntarget = tf.keras.utils.to_categorical(fitur[:,-1])\nx_train, x_test, y_train, y_test = train_test_split(fitur[:,:-1], target, test_size=0.2, shuffle = True, random_state=1)","91e556ea":"mlp = MLPClassifier(hidden_layer_sizes=[72,39],solver='sgd',learning_rate_init= 0.01, max_iter=100)\n\n# Train the model\nmlp.fit(x_train, y_train)\nprint(f'Accuracy Training: {round(mlp.score(x_train, y_train),4)*100}%')\n\n# Test the model\ny_pred = mlp.predict(x_test)\n\n# Confusion Matrix\ncx=confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\nplot_confusion_matrix(cx,classes=['Sehat', 'Sakit'], normalize=False)\nplt.show()\n# Accuracy\naccuracy=accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n# Precision\nprecision=precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='binary')\n# Recall\nrecall=recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='binary')\n\nprint(f\"accuracy: {round(accuracy,4)*100}%\")\nprint(f\"precision: {round(precision,4)*100}%\")\nprint(f\"recall: {round(recall,4)*100}%\")","63cc7cb7":"import numpy as np\nimport mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# Build the model.\nmodel = Sequential([\n  Dense(72, activation='relu', input_shape=(237,13)),\n  Dense(39, activation='relu'),\n  Dense(2, activation='softmax'),\n])\n\n# Compile the model.\nmodel.compile(\n  optimizer='adam',\n  loss='categorical_crossentropy',\n  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n)\n\n# Train the model.\nmodel.fit(\n  x_train,\n  y_train,\n  epochs=50,\n  batch_size=39,\n)\n\n# Test the model\ny_pred = model.predict(x_test)\n\n# Confusion Matrix\ncx=confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\nplot_confusion_matrix(cx,classes=['Sehat', 'Sakit'], normalize=False)\nplt.show()\n# Accuracy\naccuracy=accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n# Precision\nprecision=precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='binary')\n# Recall\nrecall=recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='binary')\n\nprint(f\"accuracy: {round(accuracy,4)*100}%\")\nprint(f\"precision: {round(precision,4)*100}%\")\nprint(f\"recall: {round(recall,4)*100}%\")","7b164dc3":"# Definisikan file","ba49637d":"# Model Keras","54e37fec":"# Analisa Jumlah Label target","0d60843a":"# Model","9646350d":"# Definisikan library dan Modul","f6a012cc":"# Normalisasi dan Partisi Fitur"}}