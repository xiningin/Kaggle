{"cell_type":{"5e63e189":"code","315f7928":"code","da0e3cec":"code","b7269131":"code","1a1bb428":"code","e00eab17":"code","9bcb085a":"code","4c9ae055":"code","94cfebfc":"code","bffed8c7":"code","2edfd0a2":"code","1e81e71a":"code","00ccf667":"code","1c44095b":"code","66554b9a":"code","878dd78e":"code","e5342d34":"code","71c3a94a":"code","92a5fb54":"code","b8b31151":"code","dbfc262c":"code","e46181a3":"code","f71f5b4f":"code","a29cc576":"code","86254acf":"code","88fa1492":"code","d3676b43":"code","ae283184":"code","44b0a807":"code","e99f8419":"code","d7665757":"code","1cf00369":"code","defbea3a":"code","9533cce6":"code","ca0716c8":"code","c0db892d":"code","84c96737":"code","173d3841":"code","85989543":"code","e7ec57b9":"code","f8458d89":"code","44fe0ceb":"code","08206b1a":"code","e00b34af":"code","ec98b2e4":"code","bce135b7":"code","2ad4da85":"code","ec170812":"code","4d9028bb":"code","6cc5e311":"code","17a7a084":"code","d73320cd":"code","d463d8c6":"code","864acd2c":"code","4eddaee0":"code","1d231549":"code","0574a8e0":"code","9b5aeb0d":"code","284b41f1":"code","cb44ef21":"code","36c7da47":"code","ec4a415a":"code","f4d8c8bb":"code","028bf749":"code","dc3d4639":"code","8062c792":"markdown","8de1f07c":"markdown","2543ce43":"markdown"},"source":{"5e63e189":"! pip install jcopml","315f7928":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da0e3cec":"import matplotlib.pyplot as plt\n\nimport seaborn as sns \nfrom scipy.stats import norm\n","b7269131":"df_train=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")","1a1bb428":"df_test=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","e00eab17":"#save ID\ntrain_id = df_train['Id']\ntest_id = df_test['Id']\n\n#drop ID\ndf_train.drop(\"Id\", axis = 1, inplace = True)\ndf_test.drop(\"Id\", axis = 1, inplace = True)\n","9bcb085a":"print(df_train.shape)\nprint(df_test.shape)","4c9ae055":"house_data=pd.concat([df_train,df_test],axis=0)","94cfebfc":"house_data = house_data.reset_index(drop=True)","bffed8c7":"house_data.tail(4)","2edfd0a2":"house_data.info()","1e81e71a":"def show_missing_info(house_data):\n    missing_info = house_data.isna().sum().reset_index(drop=False)\n    missing_info.columns = [\"column\",\"rows\"]\n    missing_info[\"missing_percent\"] = (missing_info[\"rows\"]\/house_data.shape[0])*100\n    missing_info = missing_info[missing_info[\"rows\"]>0].sort_values(by=\"missing_percent\",ascending=False)\n    return missing_info\nmissing_df = show_missing_info(house_data)\nmissing_df","00ccf667":"delete_rows_cols = missing_df[missing_df[\"rows\"]<20][\"column\"].tolist()\ndelete_rows_cols","1c44095b":"house_data.dropna(axis=0,how=\"any\",subset=delete_rows_cols,inplace=True)\nprint(house_data.shape)","66554b9a":"df_train[\"SalePrice\"].describe()","878dd78e":"sns.distplot(df_train['SalePrice'], fit=norm);","e5342d34":"corrmat = df_train.corr(method='pearson')\nf, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corrmat , square=True,annot=True,cmap='RdYlBu');","71c3a94a":"f, ax = plt.subplots(figsize=(10, 10))\nk = 11 \ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, fmt='.2f', square=True, annot_kws={'size': 12}, \n                 yticklabels=cols.values, xticklabels=cols.values, cmap='RdYlBu')\nplt.show()","92a5fb54":"sns.set(style='whitegrid')\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath']\nsns.pairplot(df_train[cols], height = 2.5)\nplt.show()","b8b31151":"sns.set(style='whitegrid')\nfig = plt.figure()\naxes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\nsns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice']);\n\naxes2 = fig.add_axes([1.1, 0.1, 0.8, 0.8])\nsns.scatterplot(x=df_train['TotalBsmtSF'], y=df_train['SalePrice']);","dbfc262c":"df_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\ndf_train.drop(df_train.index[1298], inplace=True)\ndf_train.drop(df_train.index[523], inplace=True)\n\ndf_train.sort_values(by = 'TotalBsmtSF', ascending = False)[:1]\ndf_train.drop(df_train.index[1298], inplace=True)","e46181a3":"sns.set(style='whitegrid')\nfig = plt.figure()\naxes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\nsns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice'],color='g');\n\naxes2 = fig.add_axes([1.1, 0.1, 0.8, 0.8])\nsns.scatterplot(x=df_train['TotalBsmtSF'], y=df_train['SalePrice'],color='g');","f71f5b4f":"def input(df):\n    col_name = df.columns\n    for col_name in df:\n        \n        df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n        df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")\n        df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\n        df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\n        df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\n\n        df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n\n        for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n                        df[col] = df[col].fillna('None')\n\n        for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n                        df[col] = df[col].fillna(0)\n\n        for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n            df[col] = df[col].fillna(0)\n\n        for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n            df[col] = df[col].fillna('None')\n\n        df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n        df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)\n\n        df['MSZoning'] = df['MSZoning'].fillna('RL')\n\n        df[\"Functional\"] = df[\"Functional\"].fillna('Typ')\n\n        df['Electrical'] = df['Electrical'].fillna('SBrkr')\n\n        df['KitchenQual'] = df['KitchenQual'].fillna('TA')\n\n        df['Exterior1st'] = df['Exterior1st'].fillna('VinylSd')\n        df['Exterior2nd'] = df['Exterior2nd'].fillna('VinylSd')\n\n        df['SaleType'] = df['SaleType'].fillna('WD')\n\n        df['MSSubClass'] = df['MSSubClass'].fillna(\"None\")\n\n        df.drop(columns=['Utilities','1stFlrSF','GarageYrBlt','TotRmsAbvGrd','GarageArea'],inplace=True)\n        return df","a29cc576":"df_train=input(df_train)","86254acf":"df_train.info()","88fa1492":"print('df_train shape = {}'.format(df_train.shape))\ndf_train.head()","d3676b43":"df_test=input(df_test)\ndf_test.shape","ae283184":"sns.distplot(df_train['SalePrice'], fit=norm);","44b0a807":"from sklearn.compose import ColumnTransformer\nfrom jcopml.pipeline import num_pipe","e99f8419":"target_transformer = ColumnTransformer([('target', num_pipe(scaling='standard',transform='box-cox'),['SalePrice'])])\ny_target = target_transformer.fit_transform(df_train)\ny_target = pd.Series(y_target.flatten())","d7665757":"sns.distplot(y_target, fit=norm);","1cf00369":"num = df_train.select_dtypes(exclude=['object'])\ncat = df_train.select_dtypes(include=['object'])","defbea3a":"# Ordinal\ncat_or = cat[['Street', 'Alley', 'LandContour', 'LandSlope', 'ExterQual', 'ExterCond',\n            'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n            'BsmtFinType2', 'HeatingQC','CentralAir', 'KitchenQual', 'Functional',\n            'FireplaceQu','GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n            'PoolQC', 'Fence', 'SaleCondition' ]]\n\n# Nominal\ncat_nom = cat[['MSZoning', 'LotShape', 'LotConfig', 'Neighborhood','Condition1', 'Condition2',\n             'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n             'MasVnrType', 'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType']]","9533cce6":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split","ca0716c8":"X = df_train.drop(columns='SalePrice')\ny = y_target #target yang sudah di scaling dan transform\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","c0db892d":"num_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler()),\n    ('transformer', PowerTransformer(method='yeo-johnson'))   \n])\n\ncat_ord_pipe = Pipeline([\n    ('encoder', OrdinalEncoder())\n])\n\ncat_nom_pipe = Pipeline([\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])","84c96737":"preprocessor = ColumnTransformer([\n    ('numeric1', num_pipe,  [\n       'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n       'KitchenAbvGr', 'Fireplaces', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold']),\n    \n    ('categoric1', cat_ord_pipe , [\n       'Street', 'Alley', 'LandContour', 'LandSlope', 'ExterQual', 'BsmtQual', \n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','CentralAir', 'KitchenQual',\n       'FireplaceQu','GarageFinish', 'GarageQual', 'PavedDrive', 'Fence', 'SaleCondition' ]),\n    \n    ('categoric2', cat_nom_pipe, [\n       'MSZoning', 'LotShape', 'LotConfig', 'Neighborhood','Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n       'MasVnrType', 'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType',\n       'Foundation', 'HeatingQC','Functional','ExterCond','BsmtCond','GarageCond', 'PoolQC'])    \n])","173d3841":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV","85989543":"pipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', RandomForestRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter = {'algo__n_estimators': np.arange(100,200),\n 'algo__max_depth': np.arange(20,80),\n 'algo__max_features': np.arange(0.1,1),\n 'algo__min_samples_leaf': np.arange(1,20)}\n\nmodel = RandomizedSearchCV(pipeline, parameter, cv=3, n_iter=50, n_jobs=-1, verbose=1, random_state=42)\nmodel.fit(X_train, y_train)\n\nprint(model.best_params_)\nprint(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))","e7ec57b9":"from sklearn.preprocessing import LabelEncoder \n# df.apply(LabelEncoder().fit_transform)\n# le = LabelEncoder() \n# filled=fil.le.fit_transform\ndef dummyEncode(train):\n    columnsToEncode = list(df_train.select_dtypes(include=['object']))\n    le = LabelEncoder()\n    for feature in columnsToEncode:\n        try:\n            df_train[feature] = le.fit_transform(df_train[feature])\n        except:\n            print('Error encoding '+feature)\n    return train\n\nfill = dummyEncode(df_train)\n","f8458d89":"fill.info()","44fe0ceb":"corrmat1 = fill.corr(method='pearson')\nf, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corrmat1)","08206b1a":"f, ax = plt.subplots(figsize=(10, 10))\nk = 11 \ncols = corrmat1.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(fill[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, fmt='.2f', square=True, annot_kws={'size': 12}, \n                 yticklabels=cols.values, xticklabels=cols.values, cmap='RdYlBu')\nplt.show()","e00b34af":"features= fill[[ 'OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars',\n       'FullBath', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'Fireplaces',\n       'BsmtFinSF1']]","ec98b2e4":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","bce135b7":"X=features\ncalc_vif(X)","2ad4da85":"feat1=features.drop([\"YearBuilt\",'YearRemodAdd'],axis=1)","ec170812":"X=feat1\ncalc_vif(X)","4d9028bb":"feat2=feat1.drop(['OverallQual'],axis=1)","6cc5e311":"X_=feat2\ncalc_vif(X)","17a7a084":"Y=df_train['SalePrice']","d73320cd":"X_train, X_test, Y_train, Y_test = train_test_split(X_,Y,test_size=0.2,random_state=42)","d463d8c6":"from sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","864acd2c":"regressor = LinearRegression()  \nregressor.fit(X_train, Y_train)","4eddaee0":"coeff_df = pd.DataFrame(regressor.coef_.T, X_.columns, columns=['Coefficient'])  \ncoeff_df","1d231549":"y_pred = regressor.predict(X_test)","0574a8e0":"y_pred=pd.DataFrame(data=y_pred)","9b5aeb0d":"y_pred","284b41f1":"print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred))*100)","cb44ef21":"regressor.score(X_test,Y_test)","36c7da47":"from sklearn.svm import SVR\nregressor_sr = SVR(kernel='linear',C=1.0,degree=6)\nregressor_sr.fit(X_train,Y_train)","ec4a415a":"from sklearn import metrics\ny_pred_sr = regressor_sr.predict(X_test)\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",regressor_sr.score(X_test,Y_test))","f4d8c8bb":"from sklearn.tree import DecisionTreeRegressor\nregressor_dr = DecisionTreeRegressor(random_state = 42,max_depth=7)  \n  \n# fit the regressor with X and Y data \nregressor_dr.fit(X_train, Y_train)\ny_pred_dr = regressor_dr.predict(X_test)\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",regressor_dr.score(X_test,Y_test))","028bf749":"from sklearn import ensemble \nreg = ensemble.GradientBoostingRegressor()\nreg.fit(X_train, Y_train)\npreds=reg.predict(X_test)\nreg.score(X_test,Y_test)","dc3d4639":"from xgboost import XGBRegressor \nxg_reg = XGBRegressor(objective ='reg:squarederror',booster='gbtree',random_state=42,learning_rate = 0.1, alpha = 10, n_estimators = 100)\nxg_reg.fit(X_train,Y_train)\npreds = xg_reg.predict(X_test)\nxg_reg.score(X_test,Y_test)","8062c792":"Seperating the Id an the Sales Price from the test and train data , because we reqiured them in the prediction ","8de1f07c":"Drop PoolQC,MiscFeature,Alley features from the dataset because of over 90% of the data is missing and imputing will add bias to the model","2543ce43":"Selecting those features that have missing rows are less than 20 and delete those rows"}}