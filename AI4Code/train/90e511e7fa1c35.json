{"cell_type":{"ba1ea3c0":"code","bf98c1c6":"code","fa525aab":"code","b7024c5b":"code","9a6d7b29":"code","6044e21e":"code","85f98abc":"code","9a5791b5":"code","a8b98d40":"code","b22d913e":"code","9a39e84a":"code","306cc467":"code","018f7d9c":"code","2850a839":"code","b034fdc7":"code","93c28899":"code","f1e8f41a":"code","f3ec8321":"code","a7a067da":"code","339aeabe":"code","36cb0664":"code","2b4f7cc1":"code","f2e5bf11":"code","732eed7a":"code","25753535":"code","bdc40f8f":"code","7647d264":"code","99b0ef6a":"code","ea2016e6":"code","1f6cc1fa":"markdown","e0519d76":"markdown","8328663c":"markdown","51d45bf2":"markdown","a14364d0":"markdown","718bd36e":"markdown","bf10868e":"markdown","f0779986":"markdown","4affe507":"markdown","c3be7c74":"markdown","bf884066":"markdown","dc007a17":"markdown","3ac7ce75":"markdown","b0608802":"markdown","9e950fd9":"markdown","2bf8276b":"markdown","4096e6b8":"markdown"},"source":{"ba1ea3c0":"!pip install proplot","bf98c1c6":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To impute missing Values\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.preprocessing import RobustScaler\n\nfrom xgboost import XGBRegressor","fa525aab":"# setting up the chart size and background\nplt.rcParams['figure.figsize'] = (16, 8)\nplt.style.use('fivethirtyeight')\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n# for Interactive Shells\nfrom IPython.display import display","b7024c5b":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\ndf_test= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\ndisplay(df.head())\nprint(f\"Number of Rows = {df.shape[0]} \\nNumber of Columns = {df.shape[1]}\")","9a6d7b29":"#printing only 20 columns with highest number of Null values\ndf.isnull().sum().sort_values(ascending = False).head(20).to_frame().rename({0:'Counts'}, axis = 1).style.background_gradient('crest')","6044e21e":"#printing only 20 columns with highest percentage of Null values\nround((df.isnull().sum() \/ (len(df.index)) * 100) , 2).sort_values(ascending = False).head(20).to_frame().rename({0:'Count'}, axis = 1).style.background_gradient('crest')","85f98abc":"df.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'Utilities'], axis = 1, inplace = True)\ndisplay(df.isnull().sum().sort_values(ascending = False).head(10).to_frame().rename({0:'Missing Values'}, axis = 1).style.background_gradient('YlOrRd'))\n","9a5791b5":"numeric_cols = [cname for cname in df.columns if df[cname].dtype in ['int64', 'float64']]\nnumeric_cols.remove('SalePrice')\ncategorical_cols = [cname for cname in df.columns if df[cname].nunique() < 10 and df[cname].dtype == \"object\"]\nuseful_cols = numeric_cols + categorical_cols\n\nprint(\"Numerical Columns\")\ndisplay(df[numeric_cols].head(2))\n\nprint(\"Categorical Columns\")\ndisplay(df[categorical_cols].head(2))","a8b98d40":"\"\"\"Creating Train-Test Split\"\"\"\nX = df[useful_cols]\nY = df[['SalePrice']]\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size = 0.2, random_state = 7)\nX_test = df_test[useful_cols].copy()\nprint(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","b22d913e":"for col in numeric_cols:\n    X_train[col].fillna(value=X_train[col].median(),inplace=True)\n    X_valid[col].fillna(value=X_valid[col].median(),inplace=True)\n    X_test[col].fillna(value=X_test[col].median(),inplace=True)","9a39e84a":"for col in categorical_cols:\n    X_train[col].fillna(value=X_train[col].mode()[0],inplace=True)\n    X_valid[col].fillna(value=X_valid[col].mode()[0],inplace=True)\n    X_test[col].fillna(value=X_test[col].mode()[0],inplace=True)","306cc467":"X_train.shape, X_valid.shape, X_test.shape","018f7d9c":"X_train.isnull().sum().sum(), X_valid.isnull().sum().sum(), X_test.isnull().sum().sum()","2850a839":"df[numeric_cols+ ['SalePrice']].corr().style.background_gradient('Purples') ","b034fdc7":"plt.rcParams['figure.figsize'] = (17, 17)\nax = sns.heatmap(df[numeric_cols+ ['SalePrice']].corr(), mask = df[numeric_cols+ ['SalePrice']].corr() <0.6,lw=0.5,linecolor = 'gold', cmap = 'copper_r', square=True, annot = True)\nplt.title(\"Heatmap of Correlation\",fontsize = 20)\nplt.xlabel(\" \")\nplt.ylabel(\" \")\nplt.xticks(fontsize = 15)\nplt.show();\n","93c28899":"# Defining plots design\ndef plots_design():\n    fig.patch.set_facecolor('black')\n    ax.patch.set_facecolor('black')\n    ax.tick_params(axis='both', which='major', labelsize=8)\n    ax.yaxis.set_label_coords(0, 0)\n    ax.grid(color='white', linewidth=2)\n    # Remove ticks\n    ax.xaxis.set_ticks_position('none')\n    ax.yaxis.set_ticks_position('none')\n    # Remove axes splines\n    for i in ['top', 'bottom', 'left', 'right']:\n        ax.spines[i].set_visible(False)\n    ax.tick_params(axis='x', colors='white')\n    ax.tick_params(axis='y', colors='white')\n    # Font\n    mpl.rcParams['font.family'] = 'Source Sans Pro'","f1e8f41a":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport proplot as pplt\n\n\ncorr = df[df.columns].corr()['SalePrice'][:].sort_values(ascending=True).to_frame()\ncorr = corr.drop(corr[corr.SalePrice > 0.99].index)\n\n# Visualization\nfig, ax = plt.subplots(figsize =(12, 9))\n\nax.barh(corr.index, corr.SalePrice, align='center', color = np.where(corr['SalePrice'] < 0, 'orange', '#89CFF0'))\n\nplots_design()\n\nplt.text(-0.10, 39, \"Correlation\", size=24, color=\"grey\", fontweight=\"bold\");\nplt.text(0.120, 39, \"of\", size=24, color=\"grey\");\nplt.text(0.185, 39, \"SalePrice\", size=24, color=\"#89CFF0\", fontweight=\"bold\");\nplt.text(0.37, 39, \"to\", size=24, color=\"grey\");\nplt.text(0.452, 39, \"Other Features\", size=24, color=\"grey\", fontweight=\"bold\");\n\n","f3ec8321":"correlation = df[numeric_cols + ['SalePrice']].corr()\ncorrelation[['SalePrice']].sort_values(['SalePrice'], ascending=False).T.style.background_gradient('crest')","a7a067da":"col_remove = ['GarageCars', 'BedroomAbvGr', '2ndFlrSF', 'FullBath', 'Id', 'BsmtFullBath', '1stFlrSF', 'TotRmsAbvGrd', 'YearRemodAdd', 'GarageYrBlt']\nnumeric_cols = [col for col in numeric_cols if col not in col_remove ]","339aeabe":"plt.figure(figsize = (18,18))\nax = sns.heatmap(df[numeric_cols + ['SalePrice']].corr(), mask = df[numeric_cols+ ['SalePrice']].corr() <0.6,lw=0.5,linecolor = 'gold', cmap = 'copper_r', square=True, annot = True)\nplt.title(\"Heatmap of Correlation (threshold = 0.6)\",fontsize = 30)\nplt.xlabel(\" \")\nplt.ylabel(\" \")\nplt.xticks(fontsize = 15)\nplt.show()","36cb0664":"\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[categorical_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[categorical_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[categorical_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\nOH_cols_test.index = X_test.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(categorical_cols, axis=1)\nnum_X_valid = X_valid.drop(categorical_cols, axis=1)\nnum_X_test = X_test.drop(categorical_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nX_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nX_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\nX_test = pd.concat([num_X_test, OH_cols_test], axis=1)","2b4f7cc1":"X_train.shape, X_valid.shape, X_test.shape","f2e5bf11":"X_train.isnull().sum().sum(), X_valid.isnull().sum().sum(), X_test.isnull().sum().sum()","732eed7a":"import optuna\nfrom sklearn.metrics import mean_squared_error\nfrom optuna.visualization import plot_optimization_history, plot_param_importances","25753535":"\"\"\"Uncomment for tuning the model\"\"\"\n\n# def run(trial):\n#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 0.1)\n#     reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n#     reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n#     subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n#     colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n#     max_depth = trial.suggest_int(\"max_depth\", 3, 6)\n#     n_estimators = trial.suggest_int(\"n_estimators\", 9000, 12000)\n\n\n#     model = XGBRegressor(\n#             random_state=7,\n#             tree_method=\"gpu_hist\",\n#             gpu_id=0,\n#             predictor=\"gpu_predictor\",\n#             objective='reg:squarederror',\n#             n_estimators=n_estimators,\n#             learning_rate=learning_rate,\n#             reg_lambda=reg_lambda,\n#             reg_alpha=reg_alpha,\n#             subsample=subsample,\n#             colsample_bytree=colsample_bytree,\n#             max_depth=max_depth,\n#         )\n#     model.fit(X_train, y_train, early_stopping_rounds=300,eval_set=[(X_valid, y_valid)],  verbose=5000)\n#     preds_valid = model.predict(X_valid)\n#     rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n#     return rmse\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(run, n_trials=200)\n\n# study.best_params","bdc40f8f":"\"\"\"Uncomment to know hyperparameter importances\"\"\"\n# Plotting Important Parameters\n# plot_param_importances(study)","7647d264":"final_test_predictions = []\nscores = []\nmodel = XGBRegressor(\n        random_state=7,\n        tree_method=\"gpu_hist\",\n        gpu_id=1,\n        predictor=\"gpu_predictor\",\n        n_estimators=11779,\n        learning_rate=0.049181047586005396,\n        reg_lambda= 4.882234099929202e-07,\n        reg_alpha=4.2812318406113477e-07,\n        subsample=0.5115703128724058,\n        colsample_bytree= 0.8810694603696589,\n        max_depth=4)\n\nmodel.fit(X_train, y_train, early_stopping_rounds=300,eval_set=[(X_valid, y_valid)],  verbose=3000)\npreds_valid = model.predict(X_valid)\ntest_preds = model.predict(X_test)\nfinal_test_predictions.append(test_preds)\nrmse = mean_squared_error(y_valid, preds_valid, squared=False)\nprint(rmse)\n","99b0ef6a":"test_preds_f = test_preds\ntest_preds_f","ea2016e6":"submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': test_preds_f})\noutput.to_csv('submission.csv', index=False)\n\n","1f6cc1fa":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \"> Checking Correlations<\/li>\n\n<div style=\"background:#efddc2;color:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:20px\">\n\n<p style=\"font-family:cursive;font-size:20px;color:  #c1531f\"> Correlation Metrix of All Numerical Variables. \n<b style= \"color:#2025bd\"> Dark Color : High Correlation <\/b>\n\n<\/div>","e0519d76":"**Reference = https:\/\/www.kaggle.com\/miguelfzzz\/house-price-prediction-lasso-ridge-and-more**","8328663c":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color:  #c1531f   \">Competition Description<\/li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:15px;color:  #2025bd\">\n><li > Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.<\/li>\n> <li> With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.<\/li>\n><\/ul>\n><\/div>\n","51d45bf2":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \"> Impute Missing Values<\/li>\n\n><\/div>","a14364d0":"<div style=\"background:#efddc2;color:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px\"><b>Observarions: <\/b>\n<ul style=\"font-family:cursive;font-size:15px;color:#c1531f\"> \n<li> Multicollinearity exists: Independent variables have high correlation with other independent variables. I am keeping threshold as 0.60 for calling two variables in collinear relationship<\/li>\n<li> corr (th = 0.60): GarageArea-GarageCars, GarageYrBlt-GarageCars, TotRmsAbvGrd-BedroomAbvGr, BedroomAbvGr-GrLivArea, 2ndFlrSF-TotRmsAbvGrd, HalfBath-2ndFlrSF, FullBath-GrLivArea, 2ndFlrSF-FullBath, 1stFlrSF-TotalBsmtSF, BsmtFinSF1-FullBath, BsmtFullBath-BsmtFinSF1<\/li>   \n<li>After checking the correlation with Target Variable (SalePrice) we can remove <b>GarageCars, BedroomAbvGr, 2ndFlrSF, FullBath, BsmtFullBath, 1stFlrSF, TotRmsAbvGrd<\/b><\/li>    \n<\/ul>\n<\/div> \n    ","718bd36e":"<div style=\"background:#efddc2;color:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px\"><b>Observarions: <\/b>\n<ul style=\"font-family:cursive;font-size:15px;color:#c1531f\"> \n<li> PoolQC, MiscFeature, Alley, Fence, FireplaceQu has 99.52%, 96.3%, 93.8%, 80.75%, 47.26 missing values respectively.<\/li>\n<li> Hence, dropping the columns PoolQC, MiscFeature, Alley, fence, FireplaceQu.<\/li>    \n<\/ul>\n<\/div> \n    ","bf10868e":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Modelling<\/li>","f0779986":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Checking Null Values<\/li>","4affe507":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px\">\n<li> Separating Numerical and Categorical Columns <\/li>\n<li> Categorical columns contain cols with low cardinality i.e. number of unique values = 10<\/li>\n<\/div>","c3be7c74":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Importing Required Libraries<\/li>\n","bf884066":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Setting up some parameters for Visualization, outputs etc<\/li>\n","dc007a17":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Percentage of Null Values =(sum of null values \/ total number of rows) * 100<\/li>\n\n","3ac7ce75":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color:  #c1531f   \">Assignment 7.2<\/li>\n<div class=\"alert alert-info\" role=\"alert\">\n<ul style=\"font-family:cursive;font-size:18px;color:  #2025bd\">\n<p >Kaggle Competition on house-prices-regression-techniques<\/p>\n<p><a style=\"font-family:cursive;font-size:18px\" href=\"https:\/\/www.linkedin.com\/company\/regexsoftware\/\" target=\"_blank\"> <u>REGex Software Services<\/u><\/a><\/p>\n<\/ul>\n<\/div>","b0608802":"<div style=\"background:#efddc2;color:#2b6684; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:25px\"><b>For One Hot Encoding<\/b>","9e950fd9":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color:  #c1531f   \">Data Fields<\/li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:15px;color:  #2025bd\">\n><li> <b> SalePrice <\/b>: the property's sale price in dollars. This is the target variable that you\\'re trying to predict.\n><li> <b> MSSubClass <\/b>: The building class\n><li> <b> MSZoning <\/b>: The general zoning classification\n><li> <b> LotFrontage <\/b>: Linear feet of street connected to property\n><li> <b> LotArea <\/b>: Lot size in square feet\n><li> <b> Street <\/b>: Type of road access\n><li> <b> Alley <\/b>: Type of alley access\n><li> <b> LotShape <\/b>: General shape of property\n><li> <b> LandContour <\/b>: Flatness of the property\n><li> <b> Utilities <\/b>: Type of utilities available\n><li> <b> LotConfig <\/b>: Lot configuration\n><li> <b> LandSlope <\/b>: Slope of property\n><li> <b> Neighborhood <\/b>: Physical locations within Ames city limits\n><li> <b> Condition1 <\/b>: Proximity to main road or railroad\n><li> <b> Condition2 <\/b>: Proximity to main road or railroad (if a second is present)\n><li> <b> BldgType <\/b>: Type of dwelling\n><li> <b> HouseStyle <\/b>: Style of dwelling\n><li> <b> OverallQual <\/b>: Overall material and finish quality\n><li> <b> OverallCond <\/b>: Overall condition rating\n><li> <b> YearBuilt <\/b>: Original construction date\n><li> <b> YearRemodAdd <\/b>: Remodel date\n><li> <b> RoofStyle <\/b>: Type of roof\n><li> <b> RoofMatl <\/b>: Roof material\n><li> <b> Exterior1st <\/b>: Exterior covering on house\n><li> <b> Exterior2nd <\/b>: Exterior covering on house (if more than one material)\n><li> <b> MasVnrType <\/b>: Masonry veneer type\n><li> <b> MasVnrArea <\/b>: Masonry veneer area in square feet\n><li> <b> ExterQual <\/b>: Exterior material quality\n><li> <b> ExterCond <\/b>: Present condition of the material on the exterior\n><li> <b> Foundation <\/b>: Type of foundation\n><li> <b> BsmtQual <\/b>: Height of the basement\n><li> <b> BsmtCond <\/b>: General condition of the basement\n><li> <b> BsmtExposure <\/b>: Walkout or garden level basement walls\n><li> <b> BsmtFinType1 <\/b>: Quality of basement finished area\n><li> <b> BsmtFinSF1 <\/b>: Type 1 finished square feet\n><li> <b> BsmtFinType2 <\/b>: Quality of second finished area (if present)\n><li> <b> BsmtFinSF2 <\/b>: Type 2 finished square feet\n><li> <b> BsmtUnfSF <\/b>: Unfinished square feet of basement area\n><li> <b> TotalBsmtSF <\/b>: Total square feet of basement area\n><li> <b> Heating <\/b>: Type of heating\n><li> <b> HeatingQC <\/b>: Heating quality and condition\n><li> <b> CentralAir <\/b>: Central air conditioning\n><li> <b> Electrical <\/b>: Electrical system\n><li> <b> 1stFlrSF <\/b>: First Floor square feet\n><li> <b> 2ndFlrSF <\/b>: Second floor square feet\n><li> <b> LowQualFinSF <\/b>: Low quality finished square feet (all floors)\n><li> <b> GrLivArea <\/b>: Above grade (ground) living area square feet\n><li> <b> BsmtFullBath <\/b>: Basement full bathrooms\n><li> <b> BsmtHalfBath <\/b>: Basement half bathrooms\n><li> <b> FullBath <\/b>: Full bathrooms above grade\n><li> <b> HalfBath <\/b>: Half baths above grade\n><li> <b> Bedroom <\/b>: Number of bedrooms above basement level\n><li> <b> Kitchen <\/b>: Number of kitchens\n><li> <b> KitchenQual <\/b>: Kitchen quality\n><li> <b> TotRmsAbvGrd <\/b>: Total rooms above grade (does not include bathrooms)\n><li> <b> Functional <\/b>: Home functionality rating\n><li> <b> Fireplaces <\/b>: Number of fireplaces\n><li> <b> FireplaceQu <\/b>: Fireplace quality\n><li> <b> GarageType <\/b>: Garage location\n><li> <b> GarageYrBlt <\/b>: Year garage was built\n><li> <b> GarageFinish <\/b>: Interior finish of the garage\n><li> <b> GarageCars <\/b>: Size of garage in car capacity\n><li> <b> GarageArea <\/b>: Size of garage in square feet\n><li> <b> GarageQual <\/b>: Garage quality\n><li> <b> GarageCond <\/b>: Garage condition\n><li> <b> PavedDrive <\/b>: Paved driveway\n><li> <b> WoodDeckSF <\/b>: Wood deck area in square feet\n><li> <b> OpenPorchSF <\/b>: Open porch area in square feet\n><li> <b> EnclosedPorch <\/b>: Enclosed porch area in square feet\n><li> <b> 3SsnPorch <\/b>: Three season porch area in square feet\n><li> <b> ScreenPorch <\/b>: Screen porch area in square feet\n><li> <b> PoolArea <\/b>: Pool area in square feet\n><li> <b> PoolQC <\/b>: Pool quality\n><li> <b> Fence <\/b>: Fence quality\n><li> <b> MiscFeature <\/b>: Miscellaneous feature not covered in other categories\n><li> <b> MiscVal <\/b>: $Value of miscellaneous feature\n><li> <b> MoSold <\/b>: Month Sold\n><li> <b> YrSold <\/b>: Year Sold\n><li> <b> SaleType <\/b>: Type of sale\n><li> <b> SaleCondition <\/b>: Condition of sale\n\n\n><\/ul>\n><\/div>\n","2bf8276b":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color:  #c1531f   \">Data Description<\/li>\n<div style= \"background:#2b6684; color:white\">\n<ul style=\"font-family:cursive;font-size:15px\">\n<p style=\"font-family:cursive;font-size:15px; color:white\">Want to know more about data? <\/p>\n<a href=\"https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/data\/?\" target=\"_blank\"><p style=\"font-family:cursive;font-size:15px; color:yellow\">Check out Data_description.txt<\/a>\n\n","4096e6b8":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:30px;color: #c1531f  \">Loading and Glimpse of the data<\/li>"}}