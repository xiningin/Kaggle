{"cell_type":{"519aaa0e":"code","ba7cc016":"code","94a6bdc5":"code","6fdbb1b1":"code","f2adfee7":"code","d79d7cdb":"code","df33ae38":"code","d3115029":"code","6fcf3a16":"code","220e4a44":"code","a1ba7a14":"code","5dacdc24":"code","f1c3ff2b":"code","e88ce6a6":"code","a4c35291":"code","952f69eb":"code","c506035d":"code","8eb6e234":"code","ae858ac2":"code","1d1cb1b1":"code","6f9caa26":"code","aec86e5e":"code","725c5ecd":"code","9bba79c4":"code","b735e2fe":"code","a0c60be1":"code","836218bb":"code","fcafda26":"code","872bfbd0":"code","6b821271":"code","438b3b1e":"code","6a33c4b3":"code","37cd093e":"code","a2d0de23":"code","94d6d42f":"code","dcb4f8c0":"markdown","c49a8e7a":"markdown","e7a00491":"markdown","3e29e1ad":"markdown","17b78e0d":"markdown","7c838e50":"markdown","b663c6a4":"markdown","d0143b00":"markdown","d4ad942e":"markdown","0d572943":"markdown","48bef72f":"markdown","b25828e4":"markdown","59fc71c3":"markdown","7c368533":"markdown","a28acd48":"markdown","524fc66d":"markdown","d4288f09":"markdown","9ada8d80":"markdown","367c0aad":"markdown","2a292345":"markdown","72afcc86":"markdown","e5bd270d":"markdown","f3db5b03":"markdown","5b0c7740":"markdown","c6d21268":"markdown","9bf675ae":"markdown","ccb718bd":"markdown","334cd57c":"markdown","9b01b4cd":"markdown","9688786e":"markdown","dda8ac15":"markdown","76375575":"markdown","2100c5cb":"markdown","0ab22c29":"markdown","9df6c10f":"markdown","efda8ce8":"markdown","9af6c278":"markdown","519928d3":"markdown","75eb86f2":"markdown","785df8fc":"markdown","5cc01c1a":"markdown","91497f58":"markdown","cb32672f":"markdown","b1c96c0a":"markdown"},"source":{"519aaa0e":"import sys\nsys.path.append('..\/input\/draw-rna')","ba7cc016":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\nfrom ipynb.draw import draw_struct\nimport seaborn as sns\n\nplt.style.use('ggplot')","94a6bdc5":"train = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/test.json', lines=True)","6fdbb1b1":"# we define the columns separately (this is gonna be usefull later)\nerr_cols = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']\nmes_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","f2adfee7":"train.info()","d79d7cdb":"test.info()","df33ae38":"#taking a sample from our training data\n    #samples with good confidence \ntrain_hsnr = train.query('signal_to_noise > 5')\nsample = train_hsnr.iloc[49, :]\nseq = sample['sequence']\nstruc = sample['structure']\n\n#ploting the structure with different measurements as alpha\n\nfig, axs = plt.subplots(3, 2, figsize=(20,20))\naxs = axs.flatten()\n    #for figure Legend\n_measured = mlines.Line2D([], [], color='blue', linestyle='None', marker='o', markersize=15, label='Measured')\n_unmeasured = mlines.Line2D([], [], color='red', linestyle='None', marker='o', markersize=15, label='Unmeasured')\n\nfor i, mes_col in enumerate(mes_cols):\n    measure = np.array(sample[mes_col])\n    #the last 39 bases aren't measured\n    unmeasured = len(seq) - len(measure)\n    #normalized the measurement vector (alpha require [0-1] range values)\n    norm = (measure - measure.min()) \/ ( measure.max() - measure.min())\n    #padding with ones to have same length\n    alpha = np.concatenate((norm, np.ones(unmeasured)))\n    #this is to distiguich measured\/unmeasured bases\n    color = np.concatenate((np.zeros(len(measure)), np.ones(unmeasured)))\n    draw_struct(seq, struc, c=color, cmap='bwr', alpha=alpha, ax=axs[i])\n    axs[i].set_title(mes_col)\n    axs[i].legend(handles=[_measured, _unmeasured])\n    \naxs[-1].axis('off')","d3115029":"ax = train['signal_to_noise'].plot(kind='hist', bins=40, figsize=(15,3))\ntrain['signal_to_noise'].plot(kind='kde', ax=ax, secondary_y=True)","6fcf3a16":"#pd.DataFrame(train.query('signal_to_noise == 0').reactivity.values.tolist()).head(2)","220e4a44":"#pd.DataFrame(train.query('signal_to_noise == 0').reactivity_error.values.tolist()).head(2)","a1ba7a14":"train['signal_to_noise'].describe()","5dacdc24":"def calc_snr(sample):\n    \"\"\"This function takes a row and return signal to noise\n        ratio accross all measurments\"\"\"\n    ratios = np.zeros(5)\n    for i , (deg, err) in enumerate(zip(mes_cols, err_cols)):\n        ratio = (np.array(sample[deg]) \/ np.array(sample[err])).mean()\n        ratios[i] = ratio\n    return ratios.mean()","f1c3ff2b":"train['snr'] = train.apply(calc_snr, axis=1)","e88ce6a6":"train[['signal_to_noise', 'snr']].sample(10)","a4c35291":"train.eval('signal_to_noise - snr').mean()","952f69eb":"train.SN_filter.hist(bins=3)","c506035d":"train['avg_err'] = train[err_cols].applymap(np.mean).mean(axis=1)","8eb6e234":"train['avg_err'].plot.hist(bins=10)\n","ae858ac2":"train['avg_err'].describe()","1d1cb1b1":"train['avg_err'].quantile(0.94)","6f9caa26":"#mask = train.query('signal_to_noise > 1')[mes_cols].apply(lambda row: np.any([np.any(np.array(c) == 0) for c in row]), axis=1)\n#filtred = train.query('signal_to_noise > 1')[mask]","aec86e5e":"fig, axs = plt.subplots(5,1, figsize=(10, 15))\naxs.flatten()\nsample = train[train.SN_filter == 1].sample(1).iloc[0]\n\nfor i, err_col in enumerate(err_cols):\n    axs[i].plot(sample[err_col],color='red', drawstyle='steps-mid')\n    axs[i].set_title(err_col)","725c5ecd":"fig, axs = plt.subplots(5,1, figsize=(10, 15))\naxs.flatten()\n\nfor i, err_col in enumerate(err_cols):\n    errs = np.array(train[train.signal_to_noise > 1][err_col].values.tolist())\n    for err in errs:\n        axs[i].plot(err,color='black', alpha=0.01, zorder=-32)\n    errs_avg = errs.mean(axis=0)\n    errs_std = errs.std(axis=0)\n    axs[i].errorbar(np.arange(68), errs_avg, yerr=errs_std, color='red', ecolor='yellow',  drawstyle='steps-mid')\n    axs[i].set_ylim(0, 0.7)\n    axs[i].set_title(err_col)","9bba79c4":"#Calculating the variances for each measurements\nall_var = np.array(train.query('SN_filter == 1')[err_cols].applymap(lambda c: np.array(c) ** 2).values.tolist()) # shape: (1589, 5, 68)\n\n#averaging along the sequence and samples axis\nmse = all_var.mean(2).mean(0)\n\n#square root and column-wise mean\nmcrmse = np.sqrt(mse).mean()\nmcrmse","b735e2fe":"fig, axs = plt.subplots(5,1, figsize=(10, 15))\naxs.flatten()\n\nfor i, mes_col in enumerate(mes_cols):\n    mess = np.array(train[train.SN_filter == 1][mes_col].values.tolist())\n    for mes in mess:\n        axs[i].plot(mes,color='black', alpha=0.01, zorder=-32)\n    mess_avg = mess.mean(axis=0)\n    mess_std = mess.std(axis=0)\n    axs[i].errorbar(np.arange(68), mess_avg, yerr=mess_std, color='lime', ecolor='yellow', drawstyle='steps-mid')\n    axs[i].set_ylim(0, 4)\n    axs[i].set_title(err_col)","a0c60be1":"fig, axs = plt.subplots(5,1, figsize=(10, 15))\naxs.flatten()\nsample = train[train.SN_filter == 1].sample(1).iloc[0]\n\nfor i, (mes_col, err_col) in enumerate(zip(mes_cols, err_cols)):\n    err = np.array(sample[err_col])\n    mes = np.array(sample[mes_col])\n    axs[i].errorbar(np.arange(68), mes, yerr=err, color='blue', ecolor='red', drawstyle='steps-mid', barsabove=True)\n    axs[i].set_title(mes_col)","836218bb":"sample_id = 'id_20dec87f6'\nsample_dist = np.load('..\/input\/stanford-covid-vaccine\/bpps\/' + sample_id + '.npy')","fcafda26":"plt.figure(figsize=(8,8))\nplt.imshow(sample_dist)\nplt.colorbar()","872bfbd0":"def is_loop(sub_struc):\n    balance = 0\n    for c in sub_struc:\n        if balance < 0:\n            return True\n        if c == b'(':\n            balance += 1\n        if c == b')':\n            balance -= 1\n    return balance != 0\n    \ndef sample_struc(_id, min_prob = 0.4):\n    dist = np.load('..\/input\/stanford-covid-vaccine\/bpps\/' + _id + '.npy')\n    struc = np.chararray(dist.shape[0])\n    struc[:] = '.'\n    dist = np.tril(dist)\n    while(True):\n        if dist.max() < min_prob:\n            break\n        args = np.argwhere(dist == dist.max())\n        for [i, j] in args:\n            if not is_loop(struc[j:i]) and struc[i] == b'.':\n                #print([j, i, dist.max()])\n                struc[i] = ')'\n                struc[j] = '('\n            dist[i, j] = 0\n    return struc.tostring().decode(\"utf-8\") \n        ","6b821271":"sample_struct = sample_struc(sample_id)\nsample_struct","438b3b1e":"train.query('id == @sample_id').iloc[0]['structure']","6a33c4b3":"ds = pd.concat([train, test])\nds['sample_struc'] = ds['id'].apply(sample_struc)\nshape = ds.query('structure == sample_struc').shape","37cd093e":"ds.query('structure == sample_struc').shape[0] \/ ds.shape[0]","a2d0de23":"true = list()\nfor i, c in enumerate(true_struc):\n    if c == '(':\n        balance = 0\n        for j , _c in enumerate(true_struc[i + 1:]):\n            if _c == ')' and balance == 0:\n                true.append(((i, i + j + 1), sample_dist[i][i + j + 1]))\n                break;\n            if _c == ')':\n                balance -= 1\n            if _c == '(':\n                balance += 1\ntrue.sort(key=lambda x: x[1], reverse=True)","94d6d42f":"smpld = list()\ndist = np.tril(sample_dist)\nmin_prob = 0.1\nwhile(True):\n    if dist.max() < min_prob:\n        break\n    args = np.argwhere(dist == dist.max())\n    for [i, j] in args:\n        smpld.append(((j,i), dist.max()))\n        dist[i, j] = 0","dcb4f8c0":"I don't know exactly what the statistical significance of these numbers is, one of the Hosts posted a reference about how these columns were obtained: [https:\/\/www.kaggle.com\/c\/stanford-covid-vaccine\/discussion\/182417](https:\/\/www.kaggle.com\/c\/stanford-covid-vaccine\/discussion\/182417)","c49a8e7a":"Some correlation is indeed present. let see the average overage all samples.","e7a00491":"$$snr = Avg({\\dfrac{measurement_{base}}{error_{base}}})$$","3e29e1ad":"![](https:\/\/ib.bioninja.com.au\/_Media\/trna-structure_med.jpeg)\nIn this Notebook I'll try to go through all the data avialable in this competition and give meaning to each aspect, I'll also do some calculations that will shed some light on the nature of this data.\n\n**Side note:** I'm trying to keep this notebook as short as possible wihle highlighiting the most important parts, I'll be updating this notebook regularly to keep up with the  most relevant information related to the problem.","17b78e0d":"### Loding the json data:","7c838e50":"## Sequence:","b663c6a4":"Ploting one sample with the corresponding error as error bars. (you'll get different sample each time you run the cell bellow ;) ).","d0143b00":"We are off with just a 1, probably this is due to the fact that the numbers where reduced to lower precision floating numbers.","d4ad942e":"The numpy arrays in this folder gives the the probability distribution for each base pair to be connected, the structure feature was basically sampled from these distributions with highest probability. For more details about this refferer to: [What is the bpps folder and the data in each file?](https:\/\/www.kaggle.com\/c\/stanford-covid-vaccine\/discussion\/182021).\n\nLet's plot the distribution:","0d572943":"I'm going to use a custom function to caculate the ratio with respect to each row and add it as a new column:","48bef72f":"## How is Signal to noise calculated:","b25828e4":"## Structure:","59fc71c3":"## Estimating the irreducible error:","7c368533":"## The measurements:","a28acd48":"The numbers are pretty close to what we calculated, let's see how far the calculated numbers are far from the numbers on the dataset:","524fc66d":"## Measurement errors:","d4288f09":"There is an obvious correlation between the mesurements.","9ada8d80":"This feature was creted from the structure, you think of it as an engineered feature (no additional information is added).","367c0aad":"(working on it)","2a292345":"We can see that the values varies significantly from 2 folds relative to the error to 6 folds, I guess a value of 6 is much more confident than 2.\nThis feature should be taken is consideration when making a model, for example you could use it as training weights.","72afcc86":"$$\\text{MSE} = E\\big[(y - \\hat{f}(x))^2\\big]$$\n$$= \\text{Var}(y) + \\text{Var}(\\hat{f}(x)) + (y - E[\\hat{f}(x)])^2$$\n$$= \\varepsilon^2 + \\text{Var}[\\hat{f}(x)] + \\text{Bias}[\\hat{f}(x)]^2$$\n\nby putting $$\\hat{f}(x) = f(x)$$ the bias and variance terms cancel out and we get: $$\\text{MSE} = \\varepsilon^2$$\n\n(for more details check this [notebook](https:\/\/www.kaggle.com\/residentmario\/bias-variance-tradeoff)).","e5bd270d":"The majority of the values are lower than 1 as we can see from the quantiles.\n\nLet's look why some datapoints have a great error value:","f3db5b03":"Fair enough!","5b0c7740":"Plotting errors for one sample. ","c6d21268":"the distribution has a long tail, 25000 as an error is probably an outlier, let's look upclose:","9bf675ae":"The structure column is a string with the same length as the sequence, it indicates if the two bases in the sequence are connected which is noted by parentheses.\n\nWe're gonna use the draw_rna tool to plot the structure and also see how the structure impact the measurements.","ccb718bd":"## Signal to noise:","334cd57c":"I have made a small algorithm that samples from this distribution, this algorithm gives advantage to pair-base with higher probabilities and has a probability threshold.","9b01b4cd":"Now we're gonna analyse these errors, let's start by getting the average:\n\n-- we will first avrage with respect to each row then we aggregate:","9688786e":"The errors tend to decrease and rise slightly by the end of the sequence.","dda8ac15":"#### Imported packages:\n[draw_rna](https:\/\/github.com\/DasLab\/draw_rna)","76375575":"On this sample the algorithm ouputed the same structure from the dataset, let's see how accurate the algorithm is with all the structures in the instances:","2100c5cb":"## bbps files:","0ab22c29":"As you see the train dataframe has 10 more columns, all these columns are about the measurements and their errors.\n\n#### Our goal is to predict the measurement columns, the errors might be usefull for training the model.\n\nBelow we take a look at each column, describe it and try to analyze it.","9df6c10f":"There seems to be two clusters in this distribution, one in the middle and the other around 0 seems to be some outliers.","efda8ce8":"## SN Filter:","9af6c278":"## Predicted Loop-type:","519928d3":"This value is calculated by dividing the each base measurement with it corresponding error value, then averaging all these ratios, as it is shown in the formula below:","75eb86f2":"I'm assuming the errors are one standard deviation of the mean value accross multiple measurements. We're gonna use only the filtered instances since the private data will be filtered too and also they don't have outliers with huge error values.","785df8fc":"Signal to noise is a sort of quality control feature, it's the measurements relative to their errors (we're gonna calculate this column in the next section), this feature can tell us how confident measurements are, the higher value the more confident measurements are.\n\nLet's see how these numbers are distributed:","5cc01c1a":"Averaging over all instances with standard deviation as errorbar.","91497f58":"The measured bases seems to have corrolated values (bases on same positions have same opacity for different measurements), we will investigate this further when we analyse these columns.\n\nI have only used a single sample as a visualization, you can be creative try to plot accross different sample taking in regard other parameters.","cb32672f":"Let's take a look at how they are distributed:","b1c96c0a":"About 42% of the instances have the same structure sampled by this simple algorithm, other algorithms probably use other assumptions like give priority to structures with lower energy."}}