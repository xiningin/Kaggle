{"cell_type":{"3bd89809":"code","a10f046d":"code","ecdefe1e":"code","36e4c679":"code","d8304999":"code","f88fae5a":"code","dccd0894":"code","567628af":"code","36dba3e0":"code","d4739672":"code","04034d8e":"code","010dcb32":"code","57ac5d5d":"code","7125befa":"code","43b7b881":"code","4a96150b":"code","cabf0790":"code","df5779e6":"code","5a3272d5":"code","161d7796":"code","39793f4f":"code","dd4f65c0":"code","b77b5f76":"code","0b74678f":"code","8cedc3ce":"code","014d0de6":"code","b910604f":"code","88cad2bb":"code","8226240a":"code","806fd453":"code","61986b07":"code","7d44699f":"code","53084568":"code","1b7172d2":"code","c0655755":"code","a3750f38":"code","523b5ebf":"code","9ee4ba38":"code","9fed23eb":"code","089a8be3":"code","e7a374b9":"code","b2237354":"code","6f4d769b":"code","7fb438e0":"code","824cf185":"code","6167941a":"code","0eda5758":"code","588ae36c":"code","1c00b0ca":"code","6d205c5f":"code","b24db2a2":"code","8f7ef982":"code","d26e424d":"code","67d70088":"code","79df659f":"code","79e21938":"code","ec13157c":"code","c0070724":"code","29233cda":"code","f5e043bb":"code","d31129a8":"code","3c8c3a58":"code","4e6638cf":"code","100bcb82":"code","41e3884a":"code","c61ee846":"code","5a11eaf2":"code","7cf29f9d":"code","6d10e003":"code","14a90759":"code","09f5b1e6":"code","81f4986b":"code","93b46cac":"code","6983f283":"code","ed732d55":"code","4ada6f34":"code","6c351f76":"code","5c00487d":"code","cd2ddf02":"code","f74245e9":"code","167e1784":"code","1eb2ee8f":"code","f17a61ee":"code","1f53bb6c":"code","1b5d5472":"code","6a10f77c":"code","64999819":"code","4aa9eba9":"code","954f4f80":"code","ede63974":"code","ad1ce5f3":"code","63dd14f9":"code","f189695b":"markdown","49632a9b":"markdown","096a56a2":"markdown","37b0457f":"markdown","28ac7573":"markdown","cde1e387":"markdown","340aabb8":"markdown","25f86b8e":"markdown","1ede919d":"markdown","deef59f2":"markdown","1a298f1a":"markdown","8bb21a17":"markdown","d017a0fa":"markdown","b0886e32":"markdown","2b98ea76":"markdown","d7b21018":"markdown","6f79189a":"markdown","a8e041b6":"markdown","31e93b01":"markdown","e99bcbb7":"markdown","2ad9d803":"markdown","4f6c3e9c":"markdown","97b69e9b":"markdown","ffeb3b30":"markdown","1acf6054":"markdown","88a48ded":"markdown","aace4b47":"markdown","17d0fd04":"markdown","9b8ad4d5":"markdown","64f8ada6":"markdown","547b9429":"markdown","5a15838d":"markdown","6172d8b4":"markdown","f8fdf7c9":"markdown","b9956b91":"markdown","2bf3ba50":"markdown","5cfddda2":"markdown","2476bcd5":"markdown","04637688":"markdown","d19e5192":"markdown","9bc0cc32":"markdown","6f55a47a":"markdown","be88cd51":"markdown","908291ab":"markdown","9ed5c409":"markdown","e240c08c":"markdown","b3138270":"markdown","c825b101":"markdown"},"source":{"3bd89809":"import pandas as pd\nimport warnings\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn\nimport numpy as np\nimport random as rd\nimport seaborn as sns\nwarnings.filterwarnings(\"ignore\")","a10f046d":"#!kaggle datasets download -d jaideep08\/bank-customer-churn-prediction -p \/content\n#!unzip \\*.zip","ecdefe1e":"data = pd.read_csv(r\"..\/input\/churn_prediction.csv\")","36e4c679":"data.head()","d8304999":"data.shape","f88fae5a":"data.dtypes","dccd0894":"data.describe()","567628af":"data['churn'].value_counts()","36dba3e0":"fig = plt.figure(figsize = (20,20))\nax = fig.gca()\ndata.hist(ax =  ax, bins = 25, color='orangered')","d4739672":"# dropping customer id variable\ndata.drop('customer_id', axis = 1, inplace = True)","04034d8e":"data.isnull().sum()","010dcb32":"data['gender'].value_counts()","57ac5d5d":"data['gender'].fillna(value='Male',inplace=True)","7125befa":"data.isnull().sum()","43b7b881":"data.boxplot('dependents')","4a96150b":"data['dependents'] = np.where(data['dependents'] >10, data['dependents'].median(),data['dependents'])","cabf0790":"data.boxplot('dependents')","df5779e6":"temp = ['gender','occupation','dependents']\nfor i in temp:\n    print('************ Value Count in', i, '************')\n    print(data[i].value_counts())\n    print('')","5a3272d5":"data.plot.scatter('age','dependents', color='royalblue')\n# no strong pattern found though","161d7796":"# so imputing missing dependents values using mode i.e. 0\ndata['dependents'].fillna(0,inplace=True)","39793f4f":"data['occupation'].fillna(value = 'self_employed', inplace=True)","dd4f65c0":"data['occupation'].value_counts()","b77b5f76":"data.isnull().sum()","0b74678f":"data = data[data['city'].notna()]\n# taken rows where city is not null, not dropped","8cedc3ce":"data.plot.scatter('days_since_last_transaction','dependents', color='b')","014d0de6":"data.plot.scatter('days_since_last_transaction','age', color='k')","b910604f":"# for days since last transaction imputing them with mode i.e. 0 because majority have 0\ndata['days_since_last_transaction'].fillna(0,inplace=True)","88cad2bb":"data.isnull().sum()","8226240a":"# target variable is churn\ndata['churn'].value_counts().plot(kind = 'bar', color='r')\nplt.xlabel('Churn')\nplt.ylabel('Frequency')","806fd453":"data['age'].plot.hist(bins = 20, color='c')\nplt.xlabel('age', fontsize=12)\nplt.xlabel('Age')","61986b07":"data['age'].value_counts()","7d44699f":"data['occupation'].value_counts()","53084568":"data['gender'].value_counts()\/len(data)","1b7172d2":"plt.figure(figsize=(6,3))\ndata['vintage'].plot.hist(bins=30,color='0.25')\n\nplt.figure(figsize=(6,3))\ndata['days_since_last_transaction'].plot.hist(bins=30,color='0.25')","c0655755":"data['vintage'] = data['vintage'].transform(func='sqrt')\ndata['days_since_last_transaction'] = data['days_since_last_transaction'].transform(lambda x:x**0.5)","a3750f38":"plt.figure(figsize=(6,3))\ndata['vintage'].plot.hist(bins=30,color='orangered')\n\nplt.figure(figsize=(6,3))\ndata['days_since_last_transaction'].plot.hist(bins=30,color='orangered')","523b5ebf":"data.columns","9ee4ba38":"data.plot.scatter('average_monthly_balance_prevQ','churn', color='#ba9723')\nplt.ylabel('Churn')","9fed23eb":"fig, ax = plt.subplots()\ncolors = {'self_employed':'red', 'salaried':'blue', 'student':'green', 'retired':'yellow', 'company':'black'}\nax.scatter(data['customer_nw_category'], data['churn'], c=data['occupation'].apply(lambda x: colors[x]))\nplt.title('plot between customer_nw_category, occupation and churn value')\nplt.xlabel('Customer Net Worth Category')\nplt.ylabel('Churn value')\nplt.legend()\nplt.show()","089a8be3":"fig, ax = plt.subplots()\ncolors = {'self_employed':'red', 'salaried':'blue', 'student':'green', 'retired':'yellow', 'company':'black'}\nax.scatter(data['age'], data['churn'], c=data['occupation'].apply(lambda x: colors[x]))\nplt.title('Plot between age, occupation and churn value')\nplt.xlabel('Age')\nplt.ylabel('Churn Value')\n#plt.legend(['self_employed','salaried','student','retired','company'])\nplt.show()","e7a374b9":"pd.crosstab(data['churn'],data['occupation']).plot.bar()\nplt.ylabel('Frequency')\nplt.xlabel('Churn')","b2237354":"data.groupby('occupation')['vintage'].mean()","6f4d769b":"data.groupby('churn')['vintage'].mean().plot.bar(color='#b81c8b')\nplt.ylabel('Frequency')\nplt.xlabel('Churn')","7fb438e0":"data.groupby('occupation')['vintage'].mean().plot.bar(color='hotpink')\nplt.xlabel('Occupation')\nplt.ylabel('Vintage')","824cf185":"temp_data = data.loc[(data['occupation']=='self_employed')&(data['age']<20)]\ntemp_data['churn'].plot.hist(bins=50, color='orangered')\nplt.xlabel('Churn')\nplt.title('For self employed younger than 20')","6167941a":"temp_data = data.loc[(data['occupation']=='salaried')&(data['age']>20)&(data['age']<60)]\ntemp_data['churn'].plot.hist(bins=50, color='r')\nplt.title('For Salaried between 20-60 Age Group')\nplt.xlabel('Churn Value')","0eda5758":"temp_data = data.loc[(data['occupation']=='retired')&(data['age']>60)]\ntemp_data['churn'].plot.hist(bins=50, color='orangered')\nplt.title('For retired')\nplt.xlabel('Churn Value')","588ae36c":"fig, ax = plt.subplots()\ncolors = {0:'green', 1:'red'}\nax.scatter(data['vintage'], data['average_monthly_balance_prevQ'], c=data['churn'].apply(lambda x: colors[x]))\nplt.title('plot between vintage, average_monthly_balance_prevQ and churn value')\nplt.xlabel('Vintage')\nplt.ylabel('Average Monthly Balance Previous Quarter')\nplt.legend()\nplt.show()","1c00b0ca":"data['vintage'].corr(data['churn'])","6d205c5f":"data['average_monthly_balance_prevQ2'].corr(data['churn'])","b24db2a2":"#data.corr()\nplt.rcParams['figure.figsize'] = (30, 20)\nsns.heatmap(data[['vintage','age','dependents','customer_nw_category','days_since_last_transaction','current_balance','previous_month_end_balance','average_monthly_balance_prevQ','average_monthly_balance_prevQ2','current_month_credit','previous_month_credit','current_month_debit','previous_month_debit','current_month_balance','previous_month_balance','churn',]].corr(), annot = True)\n\nplt.title('Histogram of the Dataset', fontsize = 30)\nplt.show()","8f7ef982":"data = pd.get_dummies(data,dtype = 'int')\nx = data.drop('churn',axis=1)\ny = data['churn']\nx.shape, y.shape","d26e424d":"#from sklearn.preprocessing import OneHotEncoder","67d70088":"from sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y= train_test_split(x, y, test_size = 0.20, stratify = y, random_state = 42)","79df659f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain_x = scaler.fit_transform(train_x)\nvalid_x = scaler.fit_transform(valid_x)","79e21938":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(train_x, train_y)","ec13157c":"pred_train = lr.predict_proba(train_x)\npred_valid = lr.predict_proba(valid_x)","c0070724":"from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, precision_score, plot_roc_curve, f1_score\nfrom sklearn.metrics import plot_confusion_matrix, plot_precision_recall_curve, recall_score, precision_score","29233cda":"print('ROC score for predict_proba w.r.t train data: ',roc_auc_score(train_y, pred_train[:,1]))\nprint('ROC score for predict_proba w.r.t validation data: ',roc_auc_score(valid_y, pred_valid[:,1]))\nvalid_prediction = lr.predict(valid_x)\nprint('Accuracy score for predict: ',accuracy_score(valid_prediction, valid_y))","f5e043bb":"confusion_matrix(valid_prediction, valid_y)","d31129a8":"without_city_branch = data.drop(['city','branch_code'], axis = 1)\nwithout_city_branch.columns","3c8c3a58":"x_without_city_branch = without_city_branch.drop('churn',axis=1)\ny_without_city_branch = without_city_branch['churn']","4e6638cf":"train_x_wc, valid_x_wc, train_y_wc, valid_y_wc= train_test_split(x_without_city_branch, y_without_city_branch, test_size = 0.20, stratify = y_without_city_branch, random_state = 42)\ntrain_x_wc = scaler.fit_transform(train_x_wc)\nvalid_x_wc = scaler.fit_transform(valid_x_wc)\nlr = LogisticRegression()\nlr.fit(train_x_wc, train_y_wc)\npred_train_wc = lr.predict_proba(train_x_wc)\npred_valid_wc = lr.predict_proba(valid_x_wc)\n#probs = pred_valid_wc[:,1]\nvalid_prediction_wc = lr.predict(valid_x_wc)\nprint('ROC score for predict_proba w.r.t train data without city: ',roc_auc_score(train_y_wc, pred_train_wc[:,1]))\nprint('ROC score for predict_proba w.r.t validation data without city: ',roc_auc_score(valid_y_wc, pred_valid_wc[:,1]))\nprint('ROC score for predict w.r.t validation data without city: ',roc_auc_score(valid_prediction_wc, valid_y_wc))\n\nprint('Accuracy score for predict without city ',accuracy_score(valid_prediction_wc, valid_y_wc))\nprint('Recall score for predict without city ',recall_score(valid_prediction_wc, valid_y_wc))","100bcb82":"confusion_matrix(valid_prediction_wc, valid_y_wc)","41e3884a":"# plot roc curve\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, threshold = roc_curve(valid_prediction_wc,valid_y_wc)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc, color='royalblue')\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--', color='#8B0000')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.rcParams['figure.figsize'] = (6, 5)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","c61ee846":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz","5a11eaf2":"from sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y= train_test_split(x, y, test_size = 0.20, stratify = y, random_state = 42)\n\ntrain_x = scaler.fit_transform(train_x)\nvalid_x = scaler.fit_transform(valid_x)\ntrain_x.shape, valid_x.shape","7cf29f9d":"dt = DecisionTreeClassifier(criterion=\"gini\", max_depth = 3,splitter=\"random\")\ndt.fit(train_x,train_y)","6d10e003":"dt_pred = dt.predict(valid_x)","14a90759":"print(\"Decision Trees Accuracy: \", accuracy_score(dt_pred,valid_y))\nprint(\"F1 Score: \", f1_score(valid_y, dt_pred, average='weighted'))\ndt.score(train_x,train_y), dt.score(valid_x,valid_y)","09f5b1e6":"x_without_city_branch = without_city_branch.drop('churn',axis=1)\ny_without_city_branch = without_city_branch['churn']","81f4986b":"train_x_wc, valid_x_wc, train_y_wc, valid_y_wc= train_test_split(x_without_city_branch, y_without_city_branch, test_size = 0.20, stratify = y_without_city_branch, random_state = 42)\ntrain_x_wc = scaler.fit_transform(train_x_wc)\nvalid_x_wc = scaler.fit_transform(valid_x_wc)\nvalid_acc_score = []\ntrain_acc_score = []\ntrainscore = []\nvalidscore = []\nfor md in range(2,10):\n    dt = DecisionTreeClassifier(criterion=\"gini\", max_depth = md, splitter=\"random\")\n    dt.fit(train_x_wc,train_y_wc)\n    dt_pred_wc = dt.predict(valid_x_wc)\n    valid_acc_score.append(accuracy_score(dt_pred_wc, valid_y_wc))\n    trainscore.append(dt.score(train_x_wc, train_y_wc))\n    validscore.append(dt.score(valid_x_wc, valid_y_wc))\n\nplt.plot(valid_acc_score, color='orangered')\nplt.ylabel('Accuracy score')\nplt.xlabel('Values for maximum depth')\nplt.figure(figsize = (15,10))\nplt.show()","93b46cac":"frame = pd.DataFrame({'max_depth':range(2,10), 'train_acc':trainscore, 'valid_acc':validscore})\nplt.figure(figsize=(12,6))\nplt.plot(frame['max_depth'], frame['train_acc'], marker='o', label='train_acc')\nplt.plot(frame['max_depth'], frame['valid_acc'], marker='o', label='valid_acc')\nplt.xlabel('Depth of tree')\nplt.ylabel('performance')\nplt.legend()","6983f283":"train_x_wc, valid_x_wc, train_y_wc, valid_y_wc= train_test_split(x_without_city_branch, y_without_city_branch, test_size = 0.20, stratify = y_without_city_branch, random_state = 42)\ntrain_x_wc = scaler.fit_transform(train_x_wc)\nvalid_x_wc = scaler.fit_transform(valid_x_wc)\ndt = DecisionTreeClassifier(criterion=\"gini\", max_depth = 2, splitter=\"random\")\ndt.fit(train_x_wc,train_y_wc)\ndt_pred_wc = dt.predict(valid_x_wc)\nprint('Accuracy score for decisiontree-predict without city and branch code: ',accuracy_score(dt_pred_wc, valid_y_wc))\nprint(\"F1 Score without city and branch code: \", f1_score(dt_pred_wc, valid_y_wc, average='weighted'))\ndt.score(train_x_wc,train_y_wc), dt.score(valid_x_wc,valid_y_wc)","ed732d55":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(DecisionTreeClassifier(criterion=\"gini\", max_depth = 5), X=train_x_wc, y=train_y_wc, cv=10)\nscore","4ada6f34":"score.mean()*100, score.std()*100","6c351f76":"dtc = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5, splitter='random')\ndtc.fit(train_x_wc,train_y_wc)\nscore = dtc.score(train_x_wc,train_y_wc)\nscore1 = dtc.score(valid_x_wc,valid_y_wc)\nscore,score1","5c00487d":"from sklearn import tree\n!pip install graphviz\ndecision_tree_image = tree.export_graphviz(dtc,out_file='tree.dot',feature_names=x_without_city_branch.columns,max_depth=2,filled=True)","cd2ddf02":"#!dot -Tpng tree.dot -o tree.png\nimage = plt.imread('..\/input\/tree.png')\nplt.figure(figsize=(15,15))\nplt.imshow(image)","f74245e9":"model1 = LogisticRegression()\nmodel1.fit(train_x_wc, train_y_wc)\npred1 = model1.predict(valid_x_wc)\nmodel1.score(valid_x_wc, valid_y_wc)\n#pred1[:10], valid_y_wc[:10]","167e1784":"model2 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 2, splitter='random')\nmodel2.fit(train_x_wc, train_y_wc)\npred2 = model2.predict(valid_x_wc)\nmodel2.score(valid_x_wc, valid_y_wc)\n#pred2[:10], valid_y_wc[:10]","1eb2ee8f":"from sklearn.ensemble import RandomForestClassifier\nmodel3 = RandomForestClassifier(max_depth=5,n_estimators=30,random_state = 42, max_leaf_nodes=2)\nmodel3.fit(train_x_wc, train_y_wc)\npred3 = model3.predict(valid_x_wc)\nmodel3.score(valid_x_wc, valid_y_wc)\n#pred3[:10], valid_y_wc[:10]","f17a61ee":"from statistics import mode\nfinal_pred_mode = np.array([])\nfor i in range(0,len(valid_x_wc)):\n    final_pred_mode = np.append(final_pred_mode, mode([pred1[i], pred2[i], pred3[i]]))","1f53bb6c":"from sklearn.metrics import accuracy_score\naccuracy_score(valid_y_wc, pred1), accuracy_score(valid_y_wc, pred2), accuracy_score(valid_y_wc, pred3), accuracy_score(valid_y_wc, final_pred_mode)","1b5d5472":"df = pd.DataFrame(columns=['M1', 'M2', 'M3', 'Final_mode', 'Actual'])\ndf['M1'] = pred1\ndf['M2'] = pred2\ndf['M3'] = pred3\ndf['Final_mode'] = final_pred_mode\ndf['Actual'] = np.array(valid_y)\ndf.head()","6a10f77c":"from sklearn.ensemble import RandomForestClassifier","64999819":"from sklearn.model_selection import train_test_split\ntrain_x_rf, valid_x_rf, train_y_rf, valid_y_rf= train_test_split(x_without_city_branch, y_without_city_branch, test_size = 0.2, stratify = y_without_city_branch)\n\ntrain_x_rf = scaler.fit_transform(train_x_rf)\nvalid_x_rf = scaler.fit_transform(valid_x_rf)","4aa9eba9":"lnodes_vals = []\ntrain_x_rf, valid_x_rf, train_y_rf, valid_y_rf= train_test_split(x_without_city_branch, y_without_city_branch, test_size = 0.20, stratify = y_without_city_branch)\ntrain_x_rf = scaler.fit_transform(train_x_rf)\nvalid_x_rf = scaler.fit_transform(valid_x_rf)\nfor n in range(2,7):\n    RF = RandomForestClassifier(max_depth=22,n_estimators=30,random_state = 42, max_leaf_nodes=n)\n    RF.fit(train_x_rf,train_y_rf)\n    pred_RF = RF.predict(valid_x_rf)\n    lnodes_vals.append(accuracy_score(valid_y_rf, pred_RF))\n    \nplt.plot(lnodes_vals, color='orangered')\nplt.ylabel('Accuracy score')\nplt.xlabel('Values for max leaf nodes')\nplt.xlim(0,6)\nplt.show()","954f4f80":"RF = RandomForestClassifier(max_depth=22,n_estimators=30,random_state = 42, max_leaf_nodes=2)\nRF.fit(train_x_rf,train_y_rf)","ede63974":"pred_RF = RF.predict(valid_x_rf)","ad1ce5f3":"print(\"Random Forest's Accuracy: \", accuracy_score(valid_y_rf, pred_RF))\nprint(\"F1 SCORE: \", f1_score(valid_y_rf, pred_RF, average='weighted'))\nRF.score(train_x_rf,train_y_rf),RF.score(valid_x_rf,valid_y_rf)","63dd14f9":"importances = RF.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in RF.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1][:40]\n\n# Print the feature ranking\nprint(\"Feature Ranking:\")\n\nfor f in range(train_x_rf.shape[1]):\n    print(\"%d. Feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nfig = plt.figure(figsize=(20, 10));\nplt.title(\"Relative Feature Importances\")\nplt.bar(range(train_x_rf.shape[1]), importances[indices],\n       color=\"#FF6347\", yerr=std[indices], align=\"center\", ecolor='k')\nplt.xticks(range(train_x_rf.shape[1]), indices)\nplt.xlim([-1, train_x_rf.shape[1]])\nplt.show()","f189695b":"# 3. Imputing Missing Values with Some Analysis","49632a9b":"- Scaling","096a56a2":"### 3.1. Imputing missing gender with male because missing are only 525 but the dataset is very large 28382 and males are 5000+ more than females","37b0457f":"### 3.5. Imputing missing occupation values with max. occuring value i.e. self_employed","28ac7573":"## 6.3 Ensemble","cde1e387":"## 6.1. Logistic Regression","340aabb8":"# 4. Univariate Analysis","25f86b8e":"- Train","1ede919d":"- Splitting","deef59f2":"#### WITHOUT THE CITY AND BRANCH CODE VARIABLE","1a298f1a":"- Training","8bb21a17":"- People with more than 4 dependents are very less make less transactions or have less recent transactions\n- From 0-20 and above 70 aged people are less and make less transactions or have less recent transactions","d017a0fa":"- Predict","b0886e32":"# 1. Loading the Dataset i.e. Churn Prediction Dataset","2b98ea76":"# 8. Conclusion","d7b21018":"### 3.3. Value Counts","6f79189a":"- Predicting and Evaluating","a8e041b6":"# 5. Bivariate Analysis","31e93b01":"## 6.4. Random Forest","e99bcbb7":"### 3.4. To impute missing dependents we can use try finding relation between age, gender, net worth","2ad9d803":"### 5.1. Hypothesis:\n- Tendency to churn could increase with less frequent transactions or more number of days_since_last_transaction\n- Tendency to churn could increase with less less (average_monthly_balance_prevQ and average_monthly_balance_prevQ2) than threshold\n- Tendency to churn could increase with more (current_month_debit + previous_month_debit) and less (current_month_credit + previous_month_credit) than threshold , OR the current_month_balance + previous_month_balance","4f6c3e9c":"- Evaluate","97b69e9b":"- Split and Scale","ffeb3b30":"# 6. Modeling","1acf6054":"- Evaluating","88a48ded":"- Most people are in the 30-65 age group\n- Age data is very slightly left-skewed","aace4b47":"- Data seems pretty balanced for features of net worth and occupation","17d0fd04":"##### Transforming vintage and days_since_last_transaction using square root, as they were right-skewed","9b8ad4d5":"## 6.2. Decision Tree Classification","64f8ada6":"- Predicting","547b9429":"### 4.2. Value counts","5a15838d":"### 3.6. Taking records with city value present, instead of removing records with null city value, as they count only 803, i.e. approx 3% of total data","6172d8b4":"#### WITHOUT CITY AND BRANCH CODE VARIABLE","f8fdf7c9":"# Customer Churn Prediction\n\n__A Bank wants to take care of customer retention for its product: savings accounts. The bank wants you to identify customers likely to churn balances below the minimum balance. You have the customers information such as age, gender, demographics along with their transactions with the bank.__\n\n__Your task as a data scientist would be to predict the propensity to churn for each customer.__\n\n## Data Dictionary\n\n__There are multiple variables in the dataset which can be cleanly divided into 3 categories:__\n\n### I. Demographic information about customers\n\n\u2022\t__customer_id - Customer id__ \n\n\u2022\t__vintage - Vintage of the customer with the bank in a number of days__ \n\n\u2022\t__age - Age of customer__ \n\n\u2022\t__gender - Gender of customer__ \n\n\u2022\t__dependents - Number of dependents__ \n\n\u2022\t__occupation - Occupation of the customer__ \n\n\u2022\t__city - City of the customer (anonymized)__ \n\n### II. Customer Bank Relationship\n\n\u2022\t__customer_nw_category - Net worth of customer (3: Low 2: Medium 1: High)__ \n\n\u2022\t__branch_code - Branch Code for a customer account__ \n\n\u2022\t__days_since_last_transaction - No of Days Since Last Credit in Last 1 year__ \n\n### III. Transactional Information\n\n\u2022\t__current_balance - Balance as of today__ \n\n\u2022\t__previous_month_end_balance - End of Month Balance of previous month__ \n\n\u2022\t__average_monthly_balance_prevQ - Average monthly balances (AMB) in Previous Quarter__ \n\n\u2022\t__average_monthly_balance_prevQ2 - Average monthly balances (AMB) in previous to the previous quarter__ \n\n\u2022\t__current_month_credit - Total Credit Amount current month__ \n\n\u2022\t__previous_month_credit - Total Credit Amount previous month__ \n\n\u2022\t__current_month_debit - Total Debit Amount current month__ \n\n\u2022\t__previous_month_debit - Total Debit Amount previous month__ \n\n\u2022\t__current_month_balance - Average Balance of current month__ \n\n\u2022\t__previous_month_balance - Average Balance of previous month__ \n\n\u2022\t__churn - Average balance of customer falls below minimum balance in the next quarter (1\/0)__","b9956b91":"Data looks imbalanced, as there are only 22.7% entries who'd churn","2bf3ba50":"- Split and Scale all without City and Branch Code variables","5cfddda2":"### 3.2. Imputing outliers in dependents with median i.e. 0","2476bcd5":"- Correlations","04637688":"# FINAL PROJECT SOLUTION BY: JAIDEEP SINGH\n# EMAIL: jaideepjssingh@gmail.com","d19e5192":"# 7. Observations and Result","9bc0cc32":"## 7.1. Relative feature Importance","6f55a47a":"# 2. Data Exploration","be88cd51":"### 4.1. Plots","908291ab":"- No duplicates were found","9ed5c409":"# PROBLEM STATEMENT AND DATA DESCRIPTION","e240c08c":"### The customers who are likely to churn may:\n#### Have lesser current balance\n#### Have more previous month debit\n#### Have less vintage\n#### Have average balance fall below minimum, in the next quarter","b3138270":"## From the above, plot it is evident that some features impact churn more than others. \n- Previous Month Debit\n- Days Since Last Transaction\n- Previous Month Credit\n- Customer Net Worth Category\n- Current Balance","c825b101":"- Fitting"}}