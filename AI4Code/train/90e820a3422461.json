{"cell_type":{"2708d121":"code","16ecaec4":"code","ca281bd2":"code","3d0fc28c":"code","01c57496":"code","6d84755f":"code","66fa87a3":"code","a239a569":"code","b2b11205":"code","40cd91ee":"code","bf2b90bf":"code","1b3e67c5":"code","5f8f597b":"code","465f7cd0":"code","6fe1a08e":"code","10db8817":"code","39983c60":"code","3bf63407":"code","2c0a5e5d":"code","3d3efbda":"code","ea7872d2":"code","f4f257ea":"code","20368029":"code","f493ff9b":"code","01cf1220":"code","419c60c9":"markdown","f573e81f":"markdown","5ef46c3c":"markdown","4169679f":"markdown","ac116143":"markdown","934d4783":"markdown","e4592dfb":"markdown","9e0834da":"markdown","129ef4fe":"markdown","a3403e6f":"markdown"},"source":{"2708d121":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","16ecaec4":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.optim as optim\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn import preprocessing","ca281bd2":"device = 'cuda'\n\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","3d0fc28c":"# \ucf54\ub7a9 \ud658\uacbd\n# from google.colab import files\n# files.upload()","01c57496":"# ! mkdir -p ~\/.kaggle\n# ! cp kaggle.json ~\/.kaggle\/\n# ! chmod 600 ~\/.kaggle\/kaggle.json","6d84755f":"# ! kaggle competitions download -c carclassification","66fa87a3":"#train=pd.read_csv('car5_train.csv')\ntrain=pd.read_csv('\/kaggle\/input\/carclassification\/car5_train.csv')","a239a569":"x_train=train.loc[:,[i for i in train.keys()[1:-1]]]\ny_train=train[train.keys()[-1]]","b2b11205":"Scaler=preprocessing.StandardScaler()\nx_train=Scaler.fit_transform(x_train)","40cd91ee":"x_train=np.array(x_train)\ny_train=np.array(y_train)\nx_train=torch.FloatTensor(x_train)\ny_train=torch.LongTensor(y_train)","bf2b90bf":"train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=40,\n                                          shuffle=True,\n                                          drop_last=True)","1b3e67c5":"import torch.nn.functional as F\nimport torch.optim as optim\n\nnb_class=8\nnb_data=len(y_train)","5f8f597b":"l1 = torch.nn.Linear(8, 4)#\ub525\ub7ec\ub2dd \ubaa8\ub378\ub85c \uc218\uc815\nl2 = torch.nn.Linear(4, nb_class)\nrelu = torch.nn.ReLU()\ntorch.nn.init.xavier_uniform_(l1.weight)\ntorch.nn.init.xavier_uniform_(l2.weight)\nmodel = torch.nn.Sequential(l1, relu, l2).to(device)\nmodel","465f7cd0":"loss = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1) ","6fe1a08e":"total_batch = len(data_loader)\nmodel_history = []\nerr_history = []\nfor epoch in range(1, 1+300):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost\n    avg_cost \/= total_batch\n    model_history.append(model)\n    err_history.append(avg_cost)\n\n    if epoch % 50 == 1 :\n        print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))","10db8817":"import matplotlib.pyplot as plt\n\nplt.plot(err_history)\nplt.show()","39983c60":"best_model = model_history[np.argmin(err_history)] # Error\uac00 \uac00\uc7a5 \uc801\uc5c8\ub358 Epoch\uc758 \ubaa8\ub378 \ubd88\ub7ec\uc624\uae30","3bf63407":"test=pd.read_csv('\/kaggle\/input\/carclassification\/car5_test.csv')","2c0a5e5d":"x_test=test.loc[:,[i for i in test.keys()[1:]]]","3d3efbda":"x_test=Scaler.transform(x_test) # Fit_transform \ud558\uba74 \uc548\ub428\nx_test=np.array(x_test)\nx_test=torch.FloatTensor(x_test)","ea7872d2":"with torch.no_grad():\n    x_test = x_test.to(device)\n    pred = best_model(x_test)\n    predict=torch.argmax(pred,dim=1)\n\n    print(predict.shape)","f4f257ea":"predict[:5]","20368029":"submit=pd.read_csv('\/kaggle\/input\/carclassification\/car5_submit.csv')\n\nsubmit[:5]","f493ff9b":"predict=predict.cpu().numpy().reshape(-1,1)\n\nid=np.array([i for i in range(len(predict))]).reshape(-1,1)\nresult=np.hstack([id,predict])\n\nsubmit=pd.DataFrame(result,columns=[\"Id\",\"Category\"])\nsubmit.to_csv(\"baseline.csv\",index=False,header=True)","01cf1220":"submit[:5]","419c60c9":"# \ub9ac\ub354\ubcf4\ub4dc \uacf5\uaca9 by \ubc31\uc9c0\uc624\n[\ube44\ub300\uba74 \ubc1c\ud45c\uc601\uc0c1](https:\/\/youtu.be\/qGxWjlJDyss)\n\n19011484 \ubc31\uc9c0\uc624\n\n\uae30\uc874\uacfc\uc758 \ucc28\ubcc4\uc810\n- test_data\uc5d0 Fit_transform -> transform\n- linear \ubaa8\ub378 \ub300\uc2e0 2\uacc4\uce35 \ub525\ub7ec\ub2dd \ubaa8\ub378 \uc0ac\uc6a9\n- mini-batch \uc774\uc6a9\n","f573e81f":"# \ubaa8\ub378\ud559\uc2b5","5ef46c3c":"# \uc81c\ucd9c \ud30c\uc77c \ub9cc\ub4e4\uae30","4169679f":"# \ubaa8\ub378 \uc608\uce21","ac116143":"# \ucc28\ubcc4\uc8103: Fit_transform \ub300\uc2e0 transform \uc0ac\uc6a9\n- \uc5ec\uae30\uc11c Fit_Transform \ud558\uba74 x_train\uacfc \ub2e4\ub978 \uc2a4\ucf00\uc77c\ub85c normalize \ub418\uc11c \ubd84\ud3ec\uac00 \ub9dd\uac00\uc9d0","934d4783":"# \ucc28\ubcc4\uc8102: \ub525\ub7ec\ub2dd \ubaa8\ub378","e4592dfb":"# \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30","9e0834da":"# Test \ub370\uc774\ud130","129ef4fe":"# \ucc28\ubcc4\uc810 1: \ubc30\uce58\uc774\uc6a9 \ud559\uc2b5\n- \ubbf8\ub2c8\ubc30\uce58\ub97c \uc774\uc6a9\ud558\uc5ec \ud559\uc2b5\uc2dc\ud0b4\n- \ubc30\uce58 \uc0ac\uc774\uc988\ub294 8\uc758 \ubc30\uc218\uc778 40\uc744 \uc0ac\uc6a9.\n- \ub0a8\ub294 \ub370\uc774\ud130\ub294 drop \ud568","a3403e6f":"# Train \ub370\uc774\ud130"}}