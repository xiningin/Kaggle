{"cell_type":{"30072b8b":"code","8fc80740":"code","f8e6b500":"code","5ded64f5":"code","23ed6135":"code","daafcafe":"code","86af3879":"code","dc8eab64":"code","a6f5bb8d":"code","5b02149b":"code","2b170b22":"code","a826ac72":"code","c931612a":"code","aa7fd016":"code","f34641f1":"markdown","b8af8821":"markdown","dfe2fb3d":"markdown"},"source":{"30072b8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fc80740":"\ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv',header=0)\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv',header=0)\n","f8e6b500":"# I expect that having other people to think about will \n# affect someone's chance of survival\ntrain[\"Alone\"] = train[\"Parch\"] == 0\ntrain[\"Relatives\"] = train[\"Parch\"] + train[\"SibSp\"]\n\ntest[\"Alone\"] = test[\"Parch\"] == 0\ntest[\"Relatives\"] = test[\"Parch\"] + test[\"SibSp\"]\n\ntrain.sample(5)","5ded64f5":"median = train['Age'].median()\ntrain['Age'].fillna(median, inplace = True)\ntest['Age'].fillna(median, inplace = True)\n\nbins = [0, 2, 12, 17, 60, np.inf]\nlabels = ['baby', 'child', 'teenager', 'adult', 'elderly']\nage_groups = pd.cut(train.Age, bins, labels = labels)\ntrain['AgeGroup'] = age_groups\n\nage_groups = pd.cut(test.Age, bins, labels = labels)\ntest['AgeGroup'] = age_groups\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","23ed6135":"median = train['Fare'].median()\ntrain['Fare'].fillna(median, inplace = True)\ntest['Fare'].fillna(median, inplace = True)","daafcafe":"from sklearn.preprocessing import KBinsDiscretizer\n\ncontinuous = ['Age', 'Fare']\n\nfig, axs = plt.subplots(1, len(continuous),figsize=(len(continuous) * 6,6))\n\nfor ind,feature in enumerate(continuous):\n    bin_feature = feature + 'Bin'\n    est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n    est.fit(train[[feature]])\n    train[bin_feature] = est.transform(train[[feature]])\n    test[bin_feature]= est.transform(test[[feature]])\n    sns.barplot(x=bin_feature, y=\"Survived\", data=train, ax = axs[ind])\n    \ntrain","86af3879":"from sklearn.preprocessing import LabelEncoder\n\ncategorical = ['Sex', 'AgeBin','FareBin','AgeGroup']\nfor feature in categorical:\n    label = LabelEncoder()\n    print(feature)\n    label.fit(train[feature])\n    train[feature] = label.transform(train[feature])\n    test[feature] = label.transform(test[feature])\ntrain","dc8eab64":"features = ['Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked', 'Alone', 'Relatives', 'FareBin']\nfig, axs = plt.subplots(1, len(features),figsize=(len(features) * 6,6))\nfor ind, x in enumerate(features):\n\n    g = sns.countplot(\n        data=train, ax = axs[ind],\n        x=x,  palette=\"dark\", alpha=.6\n    )","a6f5bb8d":"features = ['Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked', 'Alone', 'Relatives', 'FareBin']\nfig, axs = plt.subplots(1, len(features),figsize=(len(features) * 6,6))\nfor ind, x in enumerate(features):\n    print('Survival Probability by', x)\n    print(train[[x, \"Survived\"]].groupby(x, as_index=False).mean()) \n    print()\n    print()\n\n    sns.barplot(x, y=\"Survived\", data=train, ax = axs[ind])\n    ","5b02149b":"# Collinearity of Port and class\none_hot_train = pd.get_dummies(train[[\"Pclass\", \"Embarked\"]],  columns=[\"Pclass\", \"Embarked\"])\ncorr = one_hot_train.corr()\n\ncmap = sns.diverging_palette(210, 20, as_cmap=True)\nsns.heatmap(corr, cmap=cmap,\n            square=True, linewidths=.5)\n\ncorr","2b170b22":"corr = pd.get_dummies(train[[\"FareBin\", \"Pclass\"]], columns=[\"FareBin\", \"Pclass\"]).corr()\n\ncmap = sns.diverging_palette(210, 20, as_cmap=True)\nsns.heatmap(corr, cmap=cmap,\n            square=True, linewidths=.5)\n\ncorr","a826ac72":"main_features = ['Sex',\"Relatives\",'AgeBin',\"FareBin\"]\nX_test = test[main_features]\nX_train = train[main_features]\ny_train = train['Survived']\n","c931612a":"from sklearn.model_selection import cross_validate\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nensemble = [\n    (\"RandomForestClassifier\", RandomForestClassifier(max_leaf_nodes=10)), \n    (\"KNeighborsClassifier\", KNeighborsClassifier(n_neighbors=3)),\n    (\"SVM Classifier\",make_pipeline(StandardScaler(), SVC(gamma='auto')))\n]\n\nvoting = VotingClassifier(ensemble, voting='hard')\n\ncv_results = cross_validate(voting, X_train, y_train, cv=5)\nprint(cv_results['test_score'].mean())\n\nvoting.fit(X_train, y_train)\ny_pred = voting.predict(X_test)","aa7fd016":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_pred.astype(int)})\noutput.to_csv('submission.csv', index=False)","f34641f1":"# Feature Engineering","b8af8821":"We learn that \n - Being alone reduces survival probability but having too many relatives reduces chances\n - Women are a lot more likely to survive\n - The rich are more likely to survive (position of rooms like in the movie?)\n - Where you got on board affects survival probability\n \n## Questions\n - Do the ports of embarkation correlate with class? Do the poor people come from S? Are Embarked and Pclass collinear?","dfe2fb3d":"No, looks like a very weak correlation between port and pclass."}}