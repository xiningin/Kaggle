{"cell_type":{"d4a43c6e":"code","f701724e":"code","d30eb23d":"code","1b9b6fa7":"code","373015db":"code","85a1b7aa":"code","dfeec5fb":"code","1dde2e07":"code","90475ab8":"code","e669cfc0":"code","eb9fc605":"code","1f6c8d6c":"code","177e5c42":"code","9f260701":"code","b1910e90":"code","d5631aaa":"code","482763c3":"code","fad53f3d":"code","d6517cd0":"code","a7c26674":"code","e2554b6c":"code","05570cda":"code","a72a8857":"code","4856a892":"code","7ea90a3a":"code","1d9bc49f":"code","b9cf4b22":"code","631659a6":"code","31ae813f":"code","528e02db":"code","ca871031":"code","1d5e2c50":"code","a5ddb9fe":"code","8258d43b":"code","0aac311b":"code","474a7278":"code","fc5c1cd0":"code","0096ff4c":"code","c78d4905":"code","e60fe6dc":"code","797ebb99":"code","3c2539a1":"code","dee7a382":"code","0dc256a9":"code","274513bb":"code","e2d7d0ce":"code","1d2b8819":"code","1165640f":"markdown","80ebe869":"markdown","b36b5429":"markdown","55aeb79f":"markdown","f1b352b9":"markdown","28cd4e2f":"markdown","b9804559":"markdown","d0cfda52":"markdown","056817f6":"markdown","dbeaa4bf":"markdown","8f5456fe":"markdown","4e0e1f59":"markdown","5fc00729":"markdown","0f8237fc":"markdown","801c2ee0":"markdown","58d2bb70":"markdown","a365c1a3":"markdown","29afbc56":"markdown","1500ee52":"markdown","b58dfa56":"markdown","ccc9fb3a":"markdown","f5807ede":"markdown","9d3bef13":"markdown","b6075d1e":"markdown","f5b6a8d5":"markdown","9ef06466":"markdown","88b78c46":"markdown","9cb1f184":"markdown","f65c2fe8":"markdown","7f2d8edf":"markdown","6a09cc0d":"markdown","6dc6d95e":"markdown","77303c6c":"markdown","2a4775f9":"markdown","58b5218d":"markdown","87ec186d":"markdown","cf183de4":"markdown","98883c8d":"markdown","7526fb69":"markdown","e87b6020":"markdown"},"source":{"d4a43c6e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f701724e":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","d30eb23d":"train_data.head()","1b9b6fa7":"import seaborn as sns\ndisplay(train_data[['Sex','Survived']].groupby('Sex').mean())\nsns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", kind=\"bar\", data=train_data)","373015db":"sns.violinplot(x=\"Sex\", y=\"Age\",hue=\"Survived\", data=train_data, split=False, s=5)","85a1b7aa":"train_data['Age'].hist(bins=20,color='darkred',alpha=0.7)","dfeec5fb":"# Let's have a look on the train and test data\n\nprint(\"The total number of rows and columns in train data is: \", train_data.shape,\"\\n\")\nprint(\"\\nMissing values in train data:\\n \\n\",train_data.isnull().sum(),\"\\n\")\nprint(\"\\n\\nThe total number of rows and columns in test data is: \", test_data.shape)\nprint(\"\\nMissing values in test data:\\n \\n\",test_data.isnull().sum())","1dde2e07":"# Let's look at the missing values in the dataset with the help of heatmaps.\n# The yellow lines represent the NaN(Not a Number) values or missing values.\n\nimport matplotlib.pyplot as plt \nplt.figure(figsize=(10,10))\nprint(\"Train data\",sns.heatmap(train_data.isnull(),cmap = 'viridis'))","90475ab8":"plt.figure(figsize=(10,10))\nprint(\"Test data\",sns.heatmap(test_data.isnull(),cmap = 'viridis'))","e669cfc0":"# Extract all the titles\ntrain_data['Title'] = train_data['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\ntest_data['Title'] = test_data['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()","eb9fc605":"pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)","1f6c8d6c":"display(\"Train data Titles\",train_data.groupby(['Title'])['Age'].agg(['mean','count']))\ndisplay(\"Test data Titles\",test_data.groupby(['Title'])['Age'].agg(['mean','count']))","177e5c42":"# The mean age of passengers with 'Ms' title returns a missing value.\n# We see that there is only one passenger who has this title and her age is missing.\n# This explains it. But let's not bother about that right now.\ntest_data[test_data['Title']=='Ms']","9f260701":"titles = {\"Capt\": \"Officer\",\"Col\": \"Officer\",\"Major\": \"Officer\",\"Jonkheer\": \"Royalty\", \\\n             \"Don\": \"Royalty\", \"Dona\": \"Royalty\", \"Sir\" : \"Royalty\",\"Dr\": \"Royalty\",\"Rev\": \"Royalty\", \\\n             \"the Countess\":\"Royalty\", \"Mme\": \"Mrs\", \"Mlle\": \"Miss\", \"Ms\": \"Mrs\",\"Mr\" : \"Mr\", \\\n             \"Mrs\" : \"Mrs\",\"Miss\" : \"Miss\",\"Master\" : \"Master\",\"Lady\" : \"Royalty\"}","b1910e90":"train_data['Title'] = train_data['Title'].map(titles)\ntrain_data.groupby(['Title'])['Age'].agg(['mean','count'])","d5631aaa":"test_data['Title'] = test_data['Title'].map(titles)\ntest_data.groupby(['Title'])['Age'].agg(['mean','count'])","482763c3":"# Determining the age of females using 'Miss' title and 'Parch'\n\nall_miss = train_data[train_data.Title==\"Miss\"]['Age']\n\nfem_adult = train_data[(train_data.Title==\"Miss\") & (train_data.Parch==0)]['Age']\n\nfem_child = train_data[(train_data.Title==\"Miss\") & (train_data.Parch!=0)]['Age']\n\nprint (\"Average age of 'Miss' Title\", all_miss.mean())\n\nprint (\"Average age of 'Miss' Title travelling without Parents\", fem_adult.mean())\n\nprint (\"Average age of 'Miss' Title travelling with Parents\", fem_child.mean())","fad53f3d":"# Separating Titles for female children and adults\nfor i in train_data[(train_data.Title==\"Miss\") & (train_data.Parch==0)]['PassengerId']:\n    train_data.loc[i-1,'Title'] = \"Miss_adult\"\n    \nfor i in train_data[(train_data.Title==\"Miss\") & (train_data.Parch!=0)]['PassengerId']:\n    train_data.loc[i-1,'Title'] = \"Miss_child\"\n","d6517cd0":"train_data.groupby(['Title'])['Age'].agg(['mean','count'])","a7c26674":"# # Let's separate the tites in test data as well\nfor i in (test_data[(test_data.Title==\"Miss\") & (test_data.Parch==0)]['PassengerId']):\n    test_data.loc[i-892,'Title'] = \"Miss_adult\" # (i-892) as the PssengerId starts from 892\n    \nfor i in test_data[(test_data.Title==\"Miss\") & (test_data.Parch!=0)]['PassengerId']:\n    test_data.loc[i-892,'Title'] = \"Miss_child\"\n","e2554b6c":"test_data.groupby(['Title'])['Age'].agg(['mean','count'])","05570cda":"# Filling train data with the mean ages of their groups\ntrain_data.Age.fillna(train_data.groupby('Title').Age.transform(np.mean), inplace=True)","a72a8857":"# Let's check\ntrain_data.isnull().sum()","4856a892":"# Filling test data with the mean ages of respective groups of train data to prevent test train leakage\ntest_data.Age.fillna(train_data.groupby('Title').Age.transform(np.mean), inplace=True)","7ea90a3a":"test_data.isnull().sum()","1d9bc49f":"# Dropping 'Cabin' column from train data\ntrain_data.drop('Cabin', axis=1, inplace=True);","b9cf4b22":"# Dropping 'Cabin' column from test data\ntest_data.drop('Cabin', axis=1, inplace=True);","631659a6":"train_data['Embarked'].describe()","31ae813f":"train_data.fillna('S', inplace=True);","528e02db":"test_data.fillna(test_data['Fare'].mean(),inplace=True);","ca871031":"print(\"Train data\",sns.heatmap(train_data.isnull()))","1d5e2c50":"print(\"Test data\",sns.heatmap(test_data.isnull()))","a5ddb9fe":"X = train_data.drop(columns = ['Survived','PassengerId'])\ny = train_data['Survived']\nX_test = test_data.drop('PassengerId',axis=1)","8258d43b":"# Let's see how it looks\nX.head()","0aac311b":"# Look at the data type of the columns. Our machine learning model can easily \n# handle 'int' and 'float' (numerical) values but not 'object' (categorical) values\nX.info()","474a7278":"# Hence we need to encode the categorical columns  \n# We'll make a function to select the columns with low cardinality as labels with \n# high cardinality lead to poor performance\n\ndef encoder(df):\n    # Select categorical columns\n    categorical_cols = [col for col in df.columns if\n                        df[col].nunique() < 10 and \n                        df[col].dtype == \"object\"]\n\n    # Select numerical columns\n    numerical_cols = [col for col in df.columns if \n                    df[col].dtype in ['int64', 'float64']]\n\n    # To keep only the required columns\n    df = df[numerical_cols + categorical_cols].copy()\n    return df","fc5c1cd0":"# Applying the above function\nX = encoder(X)\nX_test = encoder(X_test)","0096ff4c":"X_test.head()","c78d4905":"# Using get_dummies function to convert categorical columns to dummy variables\nX = pd.get_dummies( X, columns = ['Sex','Embarked','Title'], drop_first=True )\nX.head()","e60fe6dc":"X_test = pd.get_dummies( X_test, columns = ['Sex','Embarked','Title'], drop_first=True )\nX_test.head()","797ebb99":"from sklearn.preprocessing import scale","3c2539a1":"X = scale(X)\nX_test = scale(X_test)","dee7a382":"predictions = pd.DataFrame([])\npredictions['PassengerId'] = test_data['PassengerId']","0dc256a9":"from sklearn.linear_model import LogisticRegressionCV\nmodel1 = LogisticRegressionCV(max_iter = 10000 , cv= 5, random_state=45, solver = 'liblinear')\nmodel1.fit(X,y)\npred_y1 = model1.predict(X_test)\npredictions['Survived'] = pd.DataFrame(pred_y1)\npredictions[['PassengerId','Survived']].to_csv(\"Sub1.csv\",index=False)","274513bb":"from sklearn.linear_model import RidgeClassifier\nmodel2 = RidgeClassifier()\nmodel2.fit(X,y)\npred_y2 = model2.predict(X_test)\npredictions['Survived'] = pd.DataFrame(pred_y2)\npredictions[['PassengerId','Survived']].to_csv(\"Sub2.csv\",index=False)","e2d7d0ce":"from sklearn.linear_model import SGDClassifier\nmodel3 = SGDClassifier()\nmodel3.fit(X,y)\npred_y3 = model3.predict(X_test)\npredictions['Survived'] = pd.DataFrame(pred_y3)\npredictions[['PassengerId','Survived']].to_csv(\"Sub3.csv\",index=False)","1d2b8819":"from sklearn.svm import LinearSVC\nmodel4 = LinearSVC()\nmodel4.fit(X,y)\npred_y4 = model4.predict(X_test)\npredictions['Survived'] = pd.DataFrame(pred_y4)\npredictions[['PassengerId','Survived']].to_csv(\"Sub4.csv\",index=False)","1165640f":"Let's map these to reduce the cardinality ang group the similar aged people with different titles together","80ebe869":"Getting a score of 0.78229","b36b5429":"Great!! All null values have been fixed. ","55aeb79f":"Getting a score of 0.78229.","f1b352b9":"Getting a score of 0.72727","28cd4e2f":"## Dropping some missing values","b9804559":"## NOMALIZATION ","d0cfda52":"Perfect!","056817f6":"# FITTING MODELS","dbeaa4bf":"### 2. Calculating the mean ages","8f5456fe":"But there's a one more problem to deal with. Since the chilren had higher survival than adults(as we saw in EDA), it'd be really unfair if use the mean age of adults to fill in the ages of children.","4e0e1f59":"### 1.  Extracting titles from the names of the passenngers","5fc00729":"Let's also separate the 'Survived' column from the train data and do some Label Encoding","0f8237fc":"## SGDClassifier","801c2ee0":"Since a lot of rows in 'Cabin' are missing and there's no point imputing it as it'll lead to unnecessary overfitting, we'll drop that column.","58d2bb70":"## RidgeClassifier","a365c1a3":"Label Encoding refers to converting the categorical labels into numeric form so as to convert it into the machine-readable form.","29afbc56":"Now, it's easy to determine the adult males and male  children with their titles 'Mr' and 'Master' respectively. But the titles of adult unmarried females and the female children is same, 'Miss'. One way to separate them is to consider that the females travelling without parents and children are more likely to be adults. While the females travelling with their parents are children.","1500ee52":"There are 891 rows and 12 columns in our training dataset that will be used to train the model. Now, the yellow area shows us that the columns 'Age', 'Cabin' and 'Embarked contain missing values.","b58dfa56":"# DATA CLEANING","ccc9fb3a":"The features provided in the data are:\n\n* Passenger Id: An ID given to each traveler on the boat\n* Pclass: The passenger class. It has three possible values: 1,2,3 (first, second and third class)\n* Name : The Name of the passenger\n* Sex\n* Age\n* SibSp: Number of siblings and spouses traveling with the passenger\n* Parch: Number of parents and children traveling with the passenger\n* The ticket number\n* The ticket Fare\n* The cabin number\n* The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q","f5807ede":"Let's check if it worked","9d3bef13":"## Label Encoding","b6075d1e":"# EXPLORATORY DATA ANALYSIS","f5b6a8d5":"We've fixed the 'Age' column let's look at other columns","9ef06466":"## Logistic Regression","88b78c46":"Perfect!!","9cb1f184":"Let's replace the titles of adult females and children","f65c2fe8":"# LinearSVC","7f2d8edf":"Getting a score of 0.77511.","6a09cc0d":"Below are all the titles in our train and test set","6dc6d95e":"Our next step is dealing with this missing data and you must be aware that we can do that in following ways:\n1. Listwise deletion - It means deleting all data from any participant with missing values which is not possible here with 177 and 687 values missing in 'Age' and 'Cabin' column respectively. If we remove these rows we will lose 77.1% data. Although we can remove 2 rows containing missing values from 'Embarked' column.\n2. Imputation - It means filling in the missing values by the average or median age of the rest of the passengers. But we have to calculate the mean ages of all the males, females and children(male an female) separately as we just saw that females have high survivl rate. If we impute the 'Age' column with the mean age of all the passengers, it may lead to underfitting.","77303c6c":"We've also seen that there are 2 missing values in 'Embarked' column in train set and 1 missing value in 'Fare' column. We'll fill the 'Embarked' with the most frequent port and 'Fare' with the average fare.","2a4775f9":"Okay we've filled all the rows in Age column of train data with the mean ages of the passengers. It's time to fill the column of test data.","58b5218d":"# Dealing with the missing values","87ec186d":"Now that we've grouped the people with similar ages and genders, we can not find their  mean and fill the missing values with their corresponding means. ","cf183de4":"### 3. Imputing values","98883c8d":"The below chart shows that more female passengers survived as compared to males","7526fb69":"### Let's begin with importing datasets and assigning it to separate variables.","e87b6020":"We have to predict the survival or the death of a given passenger based on the features given"}}