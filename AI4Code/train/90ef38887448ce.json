{"cell_type":{"7e3c829f":"code","c6bebfde":"code","70c84eca":"code","209de3e5":"code","b40ae5c1":"code","38b03113":"code","840c0bcc":"code","9b4cdeba":"code","8969eb71":"code","61c98f89":"code","4e254ad8":"code","079d1c71":"code","2d911d7d":"code","b73f889c":"code","81e3f6c7":"code","c19b97f4":"code","526b1c91":"code","0a6e935d":"code","de9b73ac":"code","8f68f460":"code","59f3e2fe":"code","b02fcce6":"code","87ff4782":"code","2d5b65dc":"code","fc37e155":"code","445e66e8":"code","5c388b3e":"markdown","0d3d6237":"markdown","0fb70f0a":"markdown","3f44c9d2":"markdown","88b128a1":"markdown","84e66e5b":"markdown","fd4ab8e7":"markdown","ac6f9283":"markdown","3feb5d22":"markdown","02d852db":"markdown","7ee631f7":"markdown","c0245696":"markdown","b73c3de8":"markdown","bc7c7317":"markdown","ad10098d":"markdown","212bfc09":"markdown","90d13879":"markdown","92344499":"markdown","cc5dab40":"markdown","bb46eca6":"markdown","6a783c68":"markdown","93947425":"markdown","b9e7767c":"markdown","c78aacb1":"markdown","392f5a75":"markdown","fa584e63":"markdown","a6180acf":"markdown","dfa95b47":"markdown","f9b38a55":"markdown","206bee6b":"markdown"},"source":{"7e3c829f":"import numpy as np\nimport pandas as pd\nimport os\nimport json\n\npd.set_option('max_rows', 500)","c6bebfde":"train = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\ntrain.head()","70c84eca":"train.loc[:, 'timestamp'] = pd.to_datetime(train.timestamp)\ntrain.sort_values('timestamp', inplace=True)","209de3e5":"new_order = ['timestamp', 'installation_id', 'game_session', 'world', 'type', 'title', 'game_time', 'event_count' , 'event_code', 'event_id', 'event_data']\ntrain = train.loc[:, new_order]\ntrain.head()","b40ae5c1":"d_world_type_title = {'TREETOPCITY': {'Activity': ['Fireworks', 'Flower Waterer', 'Bug Measurer'], \n                                      'Assessment': ['Mushroom Sorter', 'Bird Measurer'], \n                                      'Clip': ['Tree Top City - Level 1', 'Ordering Spheres', 'Costume Box', '12 Monkeys', \n                                               'Tree Top City - Level 2', \"Pirate's Tale\", 'Treasure Map', 'Tree Top City - Level 3', 'Rulers'], \n                                      'Game': ['All Star Sorting', 'Air Show', 'Crystals Rule']}, \n                      'MAGMAPEAK': {'Activity': ['Sandcastle Builder', 'Watering Hole', 'Bottle Filler'], \n                                    'Assessment': ['Cauldron Filler'], \n                                    'Clip': ['Magma Peak - Level 1', 'Slop Problem', 'Magma Peak - Level 2'], \n                                    'Game': ['Scrub-A-Dub', 'Dino Drink', 'Bubble Bath', 'Dino Dive']}, \n                      'CRYSTALCAVES': {'Activity': ['Chicken Balancer', 'Egg Dropper'], \n                                       'Assessment': ['Cart Balancer', 'Chest Sorter'], \n                                       'Clip': ['Crystal Caves - Level 1', 'Balancing Act', 'Crystal Caves - Level 2', \n                                                'Crystal Caves - Level 3', 'Lifting Heavy Things', 'Honey Cake', 'Heavy, Heavier, Heaviest'], \n                                       'Game': ['Chow Time', 'Pan Balance', 'Happy Camel', 'Leaf Leader']}}","38b03113":"train.installation_id.nunique()","840c0bcc":"train.groupby('installation_id')['type'].apply(lambda s: s.isin(['Assessment']).any()).value_counts()","9b4cdeba":"sessions = train.groupby('installation_id')['game_session'].nunique()","8969eb71":"ax = sessions.value_counts().iloc[:30].plot.bar(title='Sessions per installation (top 30)')","61c98f89":"my_inst = train.installation_id.iloc[12345]  # and others...\ndf_inst = train.loc[train.installation_id==my_inst]\nprint(len(df_inst))\ndf_inst.head()","4e254ad8":"df_sessions = df_inst.groupby('game_session')\\\n    .apply(lambda df_session: {'timestamp': df_session.timestamp.min(),\n                               'world': df_session.world.iloc[0],\n                               'title': df_session.title.iloc[0],\n                               'type': df_session.type.iloc[0], \n                               'length': df_session.game_time.max(), \n                               'events': df_session.event_count.max()})\\\n    .apply(pd.Series)","079d1c71":"df_sessions.head(30)","2d911d7d":"my_session = df_sessions.loc[df_sessions.type=='Assessment'].index[0]\ndf_session = df_inst.loc[df_inst.game_session==my_session]\ndf_session.head()","b73f889c":"df_session.set_index('timestamp')['event_code'] \\\n    .plot(style='.')","81e3f6c7":"for idx, row in df_inst.iterrows():\n    if row.type=='Assessment':\n        if row.event_code in [4100, 4110]:\n            event_data = json.loads(row.event_data)\n            print(f\"{row.game_session:20}, {row.title:30}, {event_data['correct']}\")","c19b97f4":"train_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\ntrain_labels.head()","526b1c91":"my_train_labels = train_labels.loc[train_labels.installation_id==my_inst]\nmy_train_labels","0a6e935d":"test = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv')\ntest.loc[:, 'timestamp'] = pd.to_datetime(test.timestamp)\ntest.sort_values('timestamp', inplace=True)","de9b73ac":"labels_map = dict(train_labels.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0])) # get the mode\nlabels_map","8f68f460":"test_predictions = test.groupby('installation_id').last()['title'].map(labels_map).rename(\"accuracy_group\")\ntest_predictions","59f3e2fe":"submission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')\nsubmission.head()","b02fcce6":"submission = submission\\\n    .join(test_predictions, on='installation_id', lsuffix='_orig')\\\n    .drop('accuracy_group_orig', axis=1)","87ff4782":"submission.to_csv('submission.csv', index=None)","2d5b65dc":"my_inst = test.installation_id.iloc[123]\ndf_inst = test.loc[test.installation_id==my_inst]","fc37e155":"df_sessions = df_inst.groupby('game_session')\\\n    .apply(lambda df_session: {'timestamp': df_session.timestamp.min(),\n                               'world': df_session.world.iloc[0],\n                               'title': df_session.title.iloc[0],\n                               'type': df_session.type.iloc[0], \n                               'length': df_session.game_time.max(), \n                               'events': df_session.event_count.max()})\\\n    .apply(pd.Series)","445e66e8":"df_sessions.sort_values('timestamp')","5c388b3e":"# Follow an installation","0d3d6237":"# Get the data","0fb70f0a":"As explained in the competition page, this dataset is not really necessary, as it can be derived from the `train` dataset (and the `event_data` column in particular).","3f44c9d2":"> **Note:** More information about the events can be found in the `specs.csv` file, but I will not use it in this notebook.\n\n```python\nspecs = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/specs.csv')\nspecs.head()\n```","88b128a1":"> **Note:** The `accuracy_group` is evaluated per *session*, while the predicted `accuracy_group` is per *installation*. This is because we are asked to predict the `accuracy_group` of the last given session, from which we get only the opening event.","84e66e5b":"We note that most of the users do not have assessments at all (in the test data the last record of every installation has `type=='Assessment'`).","fd4ab8e7":"> **Reference:** This is a good point to understand the evaluation metric defined in this competition, the [quadratic weighted kappa](https:\/\/en.wikipedia.org\/wiki\/Cohen%27s_kappa). A good explanation about this metric and its relevancy to this competition can be found in [this discussion](https:\/\/www.kaggle.com\/c\/data-science-bowl-2019\/discussion\/114539). You can calculate this metric in Scikit-learn using [`cohen_kappa_score(a, p, weights=\"quadratic\")`](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.cohen_kappa_score.html), however [this kernel](https:\/\/www.kaggle.com\/cpmpml\/ultra-fast-qwk-calc-method) offers a 300x faster implementation.","ac6f9283":"The installation is made of separate sessions, and it is easier to follow the progress of the user by following an aggregative overview of its session. ","3feb5d22":"> **Reference:** [An explanation about some in-app terms](https:\/\/www.kaggle.com\/c\/data-science-bowl-2019\/discussion\/115034)","02d852db":"For the analysis of the data it is important to understand what `game_session` means exactly. By the description page of the competition we know that `game_session` is a \"Randomly generated unique identifier grouping events within a single game or video play **session**\". The usage of the *Measure Up!* app is repetitive by nature (because kids watch the same clip many times and repeat the same activities many times), this identifier allows us to distinguish between otherwise identical sessions.\n\nSo to put it all together, we can describe the usage of the app like this: An installation is made of many sessions. Within a single `game_session`, the user selects a `type` of activity with a given `title` from the available options of the selected `world`. Then the session it is described as sequence of one or more events. To see the data more clearly we change the order of columns.","7ee631f7":"First we modify the `timestamp` to be a datetime and sort by it. This will be very useful later when we will follow the progress of a specific user.","c0245696":"As explained in the competition page, this is a classification problem, where the target is the `accuracy_group`. The `accuracy` is an auxiliary column, evaluated by the trials of the user, as derived from the event data (illustrated below).","b73c3de8":"# Model 1","bc7c7317":"Now if we consider our specific installation we will find the session(s) we've looked at ealier.","ad10098d":"We can use the `event_code` (which will be explored later) as a discriminator for visualization (idea taken from [this kernel](https:\/\/www.kaggle.com\/robikscube\/2019-data-science-bowl-an-introduction)).","212bfc09":"> **Note:** Many kernels consider the problem as a regression problem for the accuracy.","90d13879":"There are 17000 unique installations.","92344499":"A normal user has 1-30 sessions.","cc5dab40":"# Assessment session","bb46eca6":"# Analyzing the test dataset","6a783c68":"<center> **GOAL OF THIS NOTEBOOK: Understand what is going on (assuming you've read the [description of the competition](https:\/\/www.kaggle.com\/c\/data-science-bowl-2019\/overview))** <\/center>","93947425":"## Event data","b9e7767c":"To illustrate the event data we follow the `event_code` 4100 or 4110, which are correlated with assessment attempts.","c78aacb1":"It is easy to conclude that `title` is the name of a specific type of activity (e.g. by `pd.crosstab(df_inst.title, df_inst.type)` and `pd.crosstab(train.world, train.title)`). Based on this understanding we can construct on auxiliary dictionary (manually). I don't know whether I will use it or not, but it helps me.","392f5a75":"This section simply illustrates how each test installation ends with a single event of an Assessment session.","fa584e63":"For our first model (taken from [this kernel](https:\/\/www.kaggle.com\/mhviraf\/a-baseline-for-dsb-2019)) we will ignore the specific installation and look at the entire data. For any assessment, regardless of the specific installation data, we predict the mode (most frequent value) of the `accuracy_group` for this assessment.","a6180acf":"# Basic statistics","dfa95b47":"> **Note:** The target variable is not given explicitly in this table, but rather given in `train_labels.csv`, which will be discussed later.","f9b38a55":"We start by looking at the `train` dataset. It takes some time to upload.","206bee6b":"# The *train_labels* dataset"}}