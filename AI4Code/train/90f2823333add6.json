{"cell_type":{"fc9a60cd":"code","ceb76906":"code","f2a8cd36":"code","192c2fe8":"code","b5f7a5ad":"code","232405d2":"code","7d2db3c5":"code","60ed395c":"code","6c6ada28":"code","c95dfd33":"code","2aee84a2":"code","bc444bc2":"code","64a4d744":"code","bfab3477":"code","572501e5":"code","68af294c":"code","5444ee2e":"code","340557fc":"code","4c03645c":"code","cd7562d1":"code","e8ac71a6":"code","81d3ca79":"code","b7681acc":"code","ee8e3d50":"code","0b473a99":"code","9f3cce33":"code","0f0b95da":"code","a0f63dad":"code","054792d0":"code","fa7189d6":"code","4192e9f6":"code","3126f1f5":"code","472c5ff9":"code","d1990d20":"code","2d826138":"code","09066ab4":"code","6256fb2f":"code","d2362fd2":"markdown"},"source":{"fc9a60cd":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nimport random\nfrom fastai.vision import *\n\nimport math\nimport tensorflow as tf\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import plot_model \nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import to_categorical \nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras import backend, models\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.applications import VGG16, MobileNet\nfrom keras.applications.vgg16 import preprocess_input\nprint(\"library loaded\")","ceb76906":"train_dir = \"..\/input\/cat-and-dog\/training_set\/training_set\"\ntest_dir= \"..\/input\/cat-and-dog\/test_set\/test_set\"","f2a8cd36":"categories = os.listdir(train_dir)\nprint(str(len(categories)),'CATEGORIES are ', categories)\n\nCategory_count = len(categories);","192c2fe8":"image = load_img(\"..\/input\/cat-and-dog\/training_set\/training_set\/dogs\/dog.1005.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()\n\nimagedata = img_to_array(image)\nshape = imagedata.shape\nprint('Figures are ', shape)","b5f7a5ad":"datagen = ImageDataGenerator(rescale=1.\/255, )","232405d2":"train_data =datagen.flow_from_directory(train_dir, target_size=(224,224))\ntest_data = datagen.flow_from_directory(test_dir, target_size=(224,224))","7d2db3c5":"train_data.class_indices","60ed395c":"Train_groups = len(train_data)\nTest_groups = len(test_data)","6c6ada28":"imgs, labels = next(train_data)","c95dfd33":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(30,30))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","2aee84a2":"plotImages(imgs)\nprint(labels)","bc444bc2":"model = Sequential()\n\n\nmodel.add(Conv2D(64, (3, 3), padding='same',input_shape=(224,224,3))) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3))) \nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization()) \n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35)) #64 --> 42\n\nmodel.add(Conv2D(64, (3, 3), padding='same')) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten()) \nmodel.add(Dropout(0.5)) \nmodel.add(Dense(512)) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(2)) \nmodel.add(Activation('softmax'))\n\nmodel.summary()","64a4d744":"model.compile(optimizer = 'adam',\n               loss = 'categorical_crossentropy',\n               metrics = ['accuracy'])","bfab3477":"Augment_datagen = ImageDataGenerator(rescale=1.\/255,\n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    zoom_range=0.2,  \n    horizontal_flip=True,\n    fill_mode='nearest') \nAugmentation_train = Augment_datagen.flow_from_directory(train_dir, target_size=(224,224))","572501e5":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","68af294c":"history = model.fit_generator( \n    Augmentation_train, \n    epochs = 20,\n    validation_data = test_data, verbose = 2, callbacks=[es]\n    )","5444ee2e":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","340557fc":"model.evaluate(test_data, verbose=1)\n","4c03645c":"test_imgs, test_labels = next(test_data)\n","cd7562d1":"plotImages(test_imgs)\nprint(test_labels)","e8ac71a6":"predictions = model.predict(x=test_data, verbose=0)","81d3ca79":"np.round(predictions)\n","b7681acc":"cm = confusion_matrix(y_true=test_data.classes, y_pred=np.argmax(predictions, axis=-1))","ee8e3d50":"cm","0b473a99":"pred = model.predict(test_data)\npred = np.argmax(pred,axis=1)","9f3cce33":"labels = (train_data.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","0f0b95da":"train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory=train_dir, target_size=(224,224), classes=['cats', 'dogs'], batch_size=10)\ntest_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory=test_dir, target_size=(224,224), classes=['cats', 'dogs'], batch_size=10, shuffle=False)","a0f63dad":"vgg16_model = tf.keras.applications.vgg16.VGG16()\n","054792d0":"vgg16_model.summary()\n","fa7189d6":"model = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)","4192e9f6":"for layer in model.layers:\n    layer.trainable = False","3126f1f5":"model.add(Dense(units=2, activation='softmax'))\n","472c5ff9":"model.summary()\n","d1990d20":"model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])","2d826138":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","09066ab4":"model.fit(x = train_batches, \n          steps_per_epoch = len(train_batches),\n          epochs = 50,\n          verbose = 2, callbacks=[es]\n         )","6256fb2f":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","d2362fd2":"# vgg16"}}