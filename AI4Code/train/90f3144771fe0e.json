{"cell_type":{"2d4dbdc0":"code","2c577c0d":"code","e774f580":"code","e88a8c2b":"code","49a73662":"code","99e17acf":"code","9c76ab32":"code","6980c3c9":"code","b6ff3fd1":"markdown","52777ce6":"markdown","3f0e3299":"markdown","8c7b23c6":"markdown","84c7f396":"markdown","f576c2d2":"markdown","4049b536":"markdown","87bd0c1c":"markdown","67621199":"markdown","6b13ce12":"markdown","8f4e5bed":"markdown","ead4eadb":"markdown","ab4005a9":"markdown"},"source":{"2d4dbdc0":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow\nimport keras\nfrom keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom sklearn.datasets import load_files\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.models import Sequential\nimport cv2\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras_preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n\n#Test & Train dirs \n\ntrain_dir='\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/train\/'\ntest_dir='\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/test\/'","2c577c0d":"def load_dataset(path):\n    data = load_files(path) #load all files from the path\n    files = np.array(data['filenames']) #get the file  \n    targets = np.array(data['target'])#get the the classification labels as integer index\n    target_labels = np.array(data['target_names'])#get the the classification labels \n    return files,targets,target_labels\n    \nx_train, y_train,target_labels = load_dataset(train_dir)\nx_test, y_test,_ = load_dataset(test_dir)\n\nprint('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0])","e774f580":"image = load_img(x_train[1])\nplt.imshow(image)","e88a8c2b":"im = cv2.imread(x_train[5])\nh, w, c = im.shape\nprint('width:  ', w)\nprint('height: ', h)\nprint('channel:', c)","49a73662":"num_classes = 2\nFAST_RUN       = False\nIMAGE_WIDTH    =64\nIMAGE_HEIGHT   =64\nbatch_size=50\nimage_size = 64\nepoch =15\nIMAGE_SIZE     =(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS =3\nDROP_OUT_VALUE =0.1\nFILTER_SIZE    =(3, 3)\nPOOL_SIZE      =(2, 2)","99e17acf":"model = Sequential()\n\nmodel.add(Conv2D(32, FILTER_SIZE, activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=POOL_SIZE))\n#model.add(Dropout(DROP_OUT_VALUE))\n\nmodel.add(Conv2D(64, FILTER_SIZE, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=POOL_SIZE))\nmodel.add(Dropout(DROP_OUT_VALUE))\n\nmodel.add(Conv2D(128, FILTER_SIZE, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=POOL_SIZE))\nmodel.add(Dropout(DROP_OUT_VALUE))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(DROP_OUT_VALUE))\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","9c76ab32":"\n\n\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip=True,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2)\n\n\ntrain_generator = data_generator.flow_from_directory(\n        train_dir,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(test_dir,target_size=(image_size, image_size),\n        class_mode='categorical')\n\nhistory=model.fit_generator(\n        train_generator,\n        epochs=epoch, \n        validation_data=validation_generator,\n        validation_steps=1)","6980c3c9":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","b6ff3fd1":"Let's extract data from dir : for each dir we have target=y(0\/1 - without\/with mask) filenames=x(image path)","52777ce6":"![Wearing-face-masks-at-home-might-help-ward-off-COVID-19-spread-among-family-members-375x195.jpg](attachment:Wearing-face-masks-at-home-might-help-ward-off-COVID-19-spread-among-family-members-375x195.jpg)","3f0e3299":"Show image shape","8c7b23c6":"Plot accuracy & lost for train & test set ","84c7f396":"# Parameters","f576c2d2":"Anyone travelling by bus, train, ferry or plane should wear a face covering to help reduce the risk of coronavirus transmission.\n\nThe new rules coincided with a further easing of lockdown in different countries - including the return to class of  school pupils and the reopening of shops.\nIn the following work We\u2019ll try to classify if the person is using a mask or not .","4049b536":"Show image example","87bd0c1c":"# Imports","67621199":"This is a basic implementation using the ResNet50 model. I am a beginner so please feel free to offer corrections and suggestions.","6b13ce12":"# Mask Classier - using CNN for COVID-19 #  ","8f4e5bed":"Preprocessing the data via ImageDataGenerator.The data here is categorical as it is divided into two categories namely with & without mask.","ead4eadb":"Create model :)","ab4005a9":"Great results :)"}}