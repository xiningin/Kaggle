{"cell_type":{"a0318ec0":"code","bfa9fbc9":"code","305e0bc6":"code","f881665e":"code","c0cb5dcc":"code","44003bbc":"code","d5d95ffe":"code","a0c5c311":"code","214626b7":"code","6b5c769e":"code","a9010c5f":"code","9214912e":"code","596a25f5":"code","98266783":"code","29d35d2d":"code","85423bfd":"code","e83b72f8":"code","73972efc":"code","a50f5687":"code","826ba935":"code","c4fc9c68":"code","36485abe":"code","bd5d0cf5":"code","2aa53b5c":"code","d9b598f7":"code","d373e5a3":"code","e193e2da":"code","48240dd3":"code","1ff7e6aa":"code","856e8eb9":"code","13e61ee8":"code","988bdec6":"code","54e8e88b":"code","bcb25fd8":"code","8e38392e":"code","cec27eb7":"code","d65c8052":"code","67e218b5":"code","02943afa":"code","ddefacee":"markdown","0e010686":"markdown","1d19ec48":"markdown","5129fcf8":"markdown","0d4dabcd":"markdown","451c17c9":"markdown","bae86fae":"markdown","0f1817f9":"markdown","f9f1ac22":"markdown","4c105912":"markdown","e762efdc":"markdown","ff9af2d8":"markdown","2045541e":"markdown","bb1a5b6d":"markdown","d0fe4f92":"markdown","8aac88db":"markdown","660c1763":"markdown","84d8e578":"markdown","3128cab7":"markdown","fc40fb4b":"markdown","6e208ed5":"markdown","eed736d5":"markdown","d621d133":"markdown","7eab888b":"markdown","8572b433":"markdown","ea679111":"markdown","85c5bbd1":"markdown"},"source":{"a0318ec0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nfrom pprint import pprint\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom os import path\nimport os\nfrom PIL import Image\nfrom collections import defaultdict\nimport networkx as nx\n# import geopandas\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bfa9fbc9":"with open(\"..\/input\/train.json\") as f:\n  train = json.load(f)\n    \nwith open(\"..\/input\/test.json\") as f:\n  test = json.load(f)","305e0bc6":"pprint(train[0])                \npprint(train[0][\"cuisine\"])","f881665e":"train_data = pd.DataFrame()\nvar_list = [\"id\", \"ingredients\", \"cuisine\"]\nfor v in var_list:\n  train_data[v] = [train[i][v] for i in range(len(train))]\n    \ntest_data = pd.DataFrame()\nvar_list = [\"id\", \"ingredients\"]\nfor v in var_list:\n  test_data[v] = [test[i][v] for i in range(len(test))]    ","c0cb5dcc":"train_data[\"ingredients_list\"] = train_data[\"ingredients\"].apply(lambda x: \", \".join(x))\ntest_data[\"ingredients_list\"] = test_data[\"ingredients\"].apply(lambda x: \", \".join(x))","44003bbc":"train_data[\"num_ingred\"] = train_data[\"ingredients\"].apply(lambda x: len(x))\ntest_data[\"num_ingred\"] = test_data[\"ingredients\"].apply(lambda x: len(x))","d5d95ffe":"%matplotlib inline\nplt.rcParams[\"font.size\"] = 10\nplt.rcParams[\"figure.figsize\"] = (15, 10)","a0c5c311":"sns.countplot(train_data.num_ingred)","214626b7":"sns.countplot(test_data.num_ingred)","6b5c769e":"train_data.cuisine.value_counts()","a9010c5f":"train_data.groupby(\"cuisine\")[\"num_ingred\"].max()","9214912e":"sns.barplot(x = \"cuisine\", y = \"num_ingred\", data = train_data, estimator = max)","596a25f5":"train_data.groupby(\"cuisine\")[\"num_ingred\"].mean()","98266783":"sns.barplot(x = \"cuisine\", y = \"num_ingred\", data = train_data)  # default estimator is mean","29d35d2d":"sns.boxplot(x = \"cuisine\", y = \"num_ingred\", data = train_data)","85423bfd":"sns.violinplot(x = \"num_ingred\", y = \"cuisine\", data = train_data)","e83b72f8":"X = train_data.ingredients_list\n\nvect = CountVectorizer(tokenizer = lambda x: x.split(\", \"), lowercase = False)\nX_dtm = vect.fit_transform(X)\n\n# store document term matrix as sparse dataframe\nsdf = pd.SparseDataFrame(X_dtm, columns = vect.get_feature_names(), default_fill_value = 0)\n\n# append cuisine to sparse dataframe\nsdf[\"cuisine\"] = train_data[\"cuisine\"]","73972efc":"grouped = sdf.groupby(\"cuisine\")\ngrouped.groups\n\ncuisine_ingred = grouped.agg(np.sum)","a50f5687":"cuisine_ingred","826ba935":"most_comm_ingred = pd.DataFrame({\"most_common_ingred\": cuisine_ingred.idxmax(axis=1), \"count\": cuisine_ingred.max(axis=1)})\nprint(most_comm_ingred)                                                                                                      ","c4fc9c68":"top_10_ingred = pd.DataFrame(cuisine_ingred.columns[np.argsort(-cuisine_ingred.values, axis = 1)[:,:10]], \n                             index=cuisine_ingred.index)\ntop_10_ingred","36485abe":"top_50_ingred = pd.DataFrame(cuisine_ingred.columns[np.argsort(-cuisine_ingred.values, axis = 1)[:,:50]], \n                             index=cuisine_ingred.index)","bd5d0cf5":"ding = defaultdict(int)\nfor i in range(0, len(top_50_ingred)):\n  for j in range(0, 50):\n    ding[top_50_ingred.iloc[i][j]] += 1\n\nd = dict((k,v) for k, v in ding.items() if v >= 15)","2aa53b5c":"# get values for these common items\ncommon_ingred_list = list(d.keys())\n# subset cuisine_ingred\ncommon_ingreds = cuisine_ingred[common_ingred_list]\n# scale common_ingreds by number of recipes\ncommon_ingreds_scaled = common_ingreds.apply(lambda x: x \/ train_data.cuisine.value_counts())\n\n# generate heatmap\nsns.heatmap(common_ingreds_scaled, cmap=\"YlGnBu\")","d9b598f7":"plt.rcParams[\"figure.figsize\"] = (12, 8)","d373e5a3":"def gen_wordcloud(subset, cols):\n  ingred_sum = subset.tolist()              \n  sum_dict = {cols[i]: ingred_sum[i] for i in range(0, len(subset))}\n    \n  wordcloud = WordCloud(background_color = \"white\", max_words = 100).fit_words(sum_dict)\n  plt.imshow(wordcloud, interpolation = \"bilinear\")\n  plt.axis(\"off\")","e193e2da":"gen_wordcloud(cuisine_ingred.agg(np.sum), sdf.columns)","48240dd3":"# generate wordclouds for different types of cuisine\nfor i, cuisine  in enumerate(cuisine_ingred.index):\n  cuisine_subset = cuisine_ingred.iloc[i]\n  fig, ax = plt.subplots()\n  ax.set_title(cuisine)\n  gen_wordcloud(cuisine_subset, sdf.columns)","1ff7e6aa":"plt.rcParams[\"figure.figsize\"] = (15, 10)","856e8eb9":"# create common ingredients count dataframe for common ingredients that are used in 5 different cuisines or more\nd = dict((k,v) for k, v in ding.items() if v >= 5)\ncommon_ingred_list = list(d.keys())\ncommon_ingreds = cuisine_ingred[common_ingred_list]\n\ncommon_ingred_T = common_ingreds.transpose()\n\ncommon_ingred_T = common_ingred_T.rename_axis(None).rename_axis(None, axis=1)\n\ncorr = common_ingred_T.corr()\n\nlinks = corr.stack().reset_index()\nlinks.columns = [\"c1\", \"c2\", \"corr_value\"]\n\n# choose cuisines with correlation > 0.6 and remove corr = 1.0\nlinks_filtered = links.loc[ (links[\"corr_value\"] > 0.5) & (links[\"c1\"] != links[\"c2\"]) ]\n\nG = nx.from_pandas_edgelist(links_filtered, 'c1', 'c2')\n\nnx.draw(G, with_labels = True, node_color = range(20), node_size = 1000, \n        edge_color = \"black\", width = 1, font_size = 10, cmap = \"tab20\")","13e61ee8":"# number of ingredients vs number of recipes\nratio_df = pd.DataFrame({\"num_ingred\": np.sum(cuisine_ingred, axis = 1), \n                         \"num_recipes\": train_data.cuisine.value_counts()})\nratio_df[\"total_ingreds\"] = train_data.groupby(\"cuisine\").num_ingred.sum()\n\np1 = sns.scatterplot(x = \"num_recipes\", y = \"num_ingred\", data = ratio_df, hue = ratio_df.index, alpha = 1, legend = False)\nfor line in range(0, ratio_df.shape[0]):\n  p1.text(ratio_df.num_recipes[line]+0.2, ratio_df.num_ingred[line], ratio_df.index[line], horizontalalignment = \"left\", size = \"small\", color = \"black\") \nplt.xlabel(\"number of recipes\")\nplt.ylabel(\"number of ingredients\")","988bdec6":"specialty_bool = cuisine_ingred != 0\n# sum across cuisines to get the number of cuisines which uses a particular ingredient\nspecialty_bool_sum = specialty_bool.sum(axis = 0)\n# evaluate whether each ingredient is used only for one type of cuisine\nspecialty_ingred = pd.DataFrame({\"special\": specialty_bool_sum == 1}, index = None)\nspecialty_ingred","54e8e88b":"# subset ingredients that are only used in one type of cuisine\nspecialty = specialty_ingred[specialty_ingred.special == True]\nprint(len(specialty))","bcb25fd8":"specialty_ingred_list = specialty.index\n# get the number of specialty ingredients for each cuisine\nspecialty_bool_subset = specialty_bool[specialty_ingred_list]\nspecialty_bool_subset.sum(axis = 1)","8e38392e":"specialty_df = cuisine_ingred[specialty_ingred_list]\ncuisines = specialty_df.index\nfor cuisine in cuisines:\n    print(cuisine + \" cuisine's top 10 specialty ingredients\")\n    print(specialty_df.loc[cuisine].sort_values(ascending = False).head(10))\n    print(\"\\n\")","cec27eb7":"X_test = test_data.ingredients_list\n\nvect = CountVectorizer(tokenizer = lambda x: x.split(\", \"), lowercase = False)\nX_test_dtm = vect.fit_transform(X_test)\n\n# store document term matrix as sparse dataframe\nsdf_test = pd.SparseDataFrame(X_test_dtm, columns = vect.get_feature_names(), default_fill_value = 0)","d65c8052":"ingred_test_sum = sdf_test.sum(axis = 0)\ningred_test_sum","67e218b5":"ingred_test_sum.sort_values(ascending = False)[:10]","02943afa":"gen_wordcloud(ingred_test_sum, sdf_test.columns)","ddefacee":"## 1. Read and Load ```train.json``` and ```test.json```","0e010686":"### 5.6 Scatterplot: relationship between number of ingredients and number of recipes","1d19ec48":"## 6. Specialty Ingredients","5129fcf8":"convert ```ingredients``` (list) to ```ingredients``` (string)","0d4dabcd":"## 7. EDA for ingredients (test data)\n\n### 7.1 Tokenization","451c17c9":"generate wordcloud for all types of cuisine combined","bae86fae":"### 5.4 Wordcloud","0f1817f9":"### 7.2 calculate the number of times each ingredients is used in test data","f9f1ac22":"### 4.2 Barplot: number of ingredients for each cuisine\n#### 4.2.1 Max number of ingredients","4c105912":"### 5.2 sum of each ingredients for each cuisines\nuse ```groupby``` to create aggregated values for each ingredients across cuisines, stored as new dataframe ```cuisine_ingred```","e762efdc":"## 5. EDA for common ingredients (train data)","ff9af2d8":"### 4.3 Boxplots: value distribution of number of ingredients by cuisine ","2045541e":"## 3. Feature Engineering\n### 3.1 Create new variable: number of ingredients used","bb1a5b6d":"### 7.3 generate wordcloud - top 100 ingredients","d0fe4f92":"There are 2595 ingredients that are used in only one type of cuisine","8aac88db":"## 4. Exploratory Data Analysis (Overall)\n### 4.1 Histogram: distribution of number of ingredients","660c1763":"#### 5.2.2 Top 10 ingredients for each cuisine","84d8e578":"top 10 ingredients (pretty similar to train data)","3128cab7":"find common ingredients across all types of cuisine (ingredients which are available in at least 15 out of 20 cuisines)\n","fc40fb4b":"### 5.5 Network Graph: Similarity of cuisines based on common ingredients","6e208ed5":"#### 4.2.2 Average number of ingredients","eed736d5":"#### 5.2.1 what is the most common ingredient for each cuisine?","d621d133":"## 2. store values from ```train.json``` and ```test.json``` in DataFrame","7eab888b":"### 5.1 Tokenization ","8572b433":"create dataframe of Top 50 common ingredients","ea679111":"### 4.4 Violinplot - similar to boxplot but show the shape of the distribution ","85c5bbd1":"### 5.3 Heatmap of ingredients "}}