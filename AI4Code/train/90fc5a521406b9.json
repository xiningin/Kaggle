{"cell_type":{"a66d0e02":"code","0a2cc4eb":"code","3b7e8ca5":"code","a1cab0f8":"code","424958af":"code","da719261":"code","7193d68e":"code","adf11d08":"code","766188f6":"code","3ee00cf3":"code","921a8ec9":"code","6d72b53c":"code","0d077551":"code","5d27ae0d":"code","5097ad96":"code","b8b592a5":"code","229ba155":"code","b71e5482":"code","6b6803bd":"code","2868079f":"code","3f5221e1":"code","6d154cdd":"code","6837e676":"code","b7303e97":"code","f233bd0d":"code","198f6fcb":"markdown","53f983d1":"markdown","ecb72554":"markdown","f5889f2c":"markdown","ca5be120":"markdown","cc8d4e14":"markdown","324409c3":"markdown","c6ce9f10":"markdown","b2f131da":"markdown","342fd52e":"markdown","8aa2d18e":"markdown","5942fd8b":"markdown","8da1c0f3":"markdown","9a69f8e8":"markdown","91178889":"markdown","372f2213":"markdown","bb00860f":"markdown","1592af8b":"markdown","7c14f081":"markdown","fbf5524f":"markdown","fe0f5fce":"markdown","147a07fa":"markdown","644eba86":"markdown","02608a9d":"markdown","251a3457":"markdown","51b6f83a":"markdown","801cffcb":"markdown","75a1f0ce":"markdown","2fb127f2":"markdown","9b1571b3":"markdown"},"source":{"a66d0e02":"!pip install missingno --quiet","0a2cc4eb":"import numpy as np\nfrom scipy import stats\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n%matplotlib inline\n\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, TransformedTargetRegressor\nfrom sklearn.linear_model import ARDRegression, BayesianRidge, ElasticNet, HuberRegressor, Lasso, LassoLars, LinearRegression, PassiveAggressiveRegressor, Ridge, SGDRegressor, TheilSenRegressor\nfrom sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","3b7e8ca5":"df = pd.read_csv('..\/input\/housesalesprediction\/kc_house_data.csv')","a1cab0f8":"df.head()","424958af":"df.info()","da719261":"df.describe()","7193d68e":"df.drop(columns=['id', 'date', 'zipcode', 'lat', 'long'], inplace=True)","adf11d08":"msno.matrix(df)","766188f6":"df.isnull().sum() * 100 \/ len(df)","3ee00cf3":"plt.figure(figsize=(12, 6))\nfor feature in df.columns:\n    if is_numeric_dtype(df[feature]):\n        sns.displot(kind='hist', x=feature, data=df, kde=True, aspect=3)","921a8ec9":"print(f\"# of 'price' rows before using Z-Score: {len(df['price'])}\")\nprint(f\"Skewness of 'price' before using Z-Score: {df['price'].skew()}\")\ndf['price'] = df[np.abs(stats.zscore(df['price']) < 3)]['price']\ndf.dropna(subset=['price'], inplace=True)\nprint(f\"# of 'price' rows after using Z-Score: {len(df['price'])}\")\nprint(f\"Skewness of 'price' after using Z-Score: {df['price'].skew()}\")\n\nprint(f\"# of 'sqft_living' rows before using Z-Score: {len(df['sqft_living'])}\")\nprint(f\"Skewness of 'sqft_living' before using Z-Score: {df['sqft_living'].skew()}\")\ndf['sqft_living'] = df[np.abs(stats.zscore(df['sqft_living']) < 3)]['sqft_living']\ndf.dropna(subset=['sqft_living'], inplace=True)\nprint(f\"# of 'sqft_living' rows after using Z-Score: {len(df['sqft_living'])}\")\nprint(f\"Skewness of 'sqft_living' after using Z-Score: {df['sqft_living'].skew()}\")\n\nprint(f\"# of 'sqft_lot' rows before using Z-Score: {len(df['sqft_lot'])}\")\nprint(f\"Skewness of 'sqft_lot' before using Z-Score: {df['sqft_lot'].skew()}\")\ndf['sqft_lot'] = df[np.abs(stats.zscore(df['sqft_lot']) < 3)]['sqft_lot']\ndf.dropna(subset=['sqft_lot'], inplace=True)\nprint(f\"# of 'sqft_lot' rows after using Z-Score: {len(df['sqft_lot'])}\")\nprint(f\"Skewness of 'sqft_lot' after using Z-Score: {df['sqft_lot'].skew()}\")\n\nprint(f\"# of 'sqft_above' rows before using Z-Score: {len(df['sqft_above'])}\")\nprint(f\"Skewness of 'sqft_above' before using Z-Score: {df['sqft_above'].skew()}\")\ndf['sqft_above'] = df[np.abs(stats.zscore(df['sqft_above']) < 3)]['sqft_above']\ndf.dropna(subset=['sqft_above'], inplace=True)\nprint(f\"# of 'sqft_above' rows after using Z-Score: {len(df['sqft_above'])}\")\nprint(f\"Skewness of 'sqft_above' after using Z-Score: {df['sqft_above'].skew()}\")\n\nprint(f\"# of 'sqft_basement' rows before using Z-Score: {len(df['sqft_basement'])}\")\nprint(f\"Skewness of 'sqft_basement' before using Z-Score: {df['sqft_basement'].skew()}\")\ndf['sqft_basement'] = df[np.abs(stats.zscore(df['sqft_basement']) < 3)]['sqft_basement']\ndf.dropna(subset=['sqft_basement'], inplace=True)\nprint(f\"# of 'sqft_basement' rows after using Z-Score: {len(df['sqft_basement'])}\")\nprint(f\"Skewness of 'sqft_basement' after using Z-Score: {df['sqft_basement'].skew()}\")\n\nprint(f\"# of 'sqft_living15' rows before using Z-Score: {len(df['sqft_living15'])}\")\nprint(f\"Skewness of 'sqft_living15' before using Z-Score: {df['sqft_living15'].skew()}\")\ndf['sqft_living15'] = df[np.abs(stats.zscore(df['sqft_living15']) < 3)]['sqft_living15']\ndf.dropna(subset=['sqft_living15'], inplace=True)\nprint(f\"# of 'sqft_living15' rows after using Z-Score: {len(df['sqft_living15'])}\")\nprint(f\"Skewness of 'sqft_living15' after using Z-Score: {df['sqft_living15'].skew()}\")\n\nprint(f\"# of 'sqft_lot15' rows before using Z-Score: {len(df['sqft_lot15'])}\")\nprint(f\"Skewness of 'sqft_lot15' before using Z-Score: {df['sqft_lot15'].skew()}\")\ndf['sqft_lot15'] = df[np.abs(stats.zscore(df['sqft_lot15']) < 3)]['sqft_lot15']\ndf.dropna(subset=['sqft_lot15'], inplace=True)\nprint(f\"# of 'sqft_lot15' rows after using Z-Score: {len(df['sqft_lot15'])}\")\nprint(f\"Skewness of 'sqft_lot15' after using Z-Score: {df['sqft_lot15'].skew()}\")","6d72b53c":"plt.figure(figsize=(12, 6))\nfor feature in df.columns:\n    if is_numeric_dtype(df[feature]):\n        sns.displot(kind='hist', x=feature, data=df, kde=True, aspect=3)","0d077551":"for categorical_feature in ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade']:\n    sns.catplot(kind='count', x=categorical_feature, data=df, aspect=3)","5d27ae0d":"plt.figure(figsize=(12, 8))\nsns.heatmap(df.corr(method='pearson'), annot=True)","5097ad96":"plt.figure(figsize=(12, 6))\nfor numerical_feature in ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']:\n    sns.relplot(kind='scatter', x='price', y=numerical_feature, data=df, aspect=3)","b8b592a5":"plt.figure(figsize=(12, 6))\nfor categorical_feature in ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade']:\n    sns.catplot(kind='box', x=categorical_feature, y='price', data=df, aspect=3)","229ba155":"df['basement'] = df['sqft_basement'].apply(lambda x: 0 if x == 0 else 1)\ndf.drop(columns=['sqft_basement'], inplace=True)","b71e5482":"sns.catplot(kind='count', x='basement', data=df)","6b6803bd":"df['renovated'] = df['yr_renovated'].apply(lambda x: 0 if x == 0 else 1)\ndf.drop(columns=['yr_renovated'], inplace=True)","2868079f":"sns.catplot(kind='count', x='renovated', data=df)","3f5221e1":"X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['price']), df['price'], test_size=0.2, random_state=101)","6d154cdd":"nc_feature_names = ['waterfront', 'basement', 'renovated']\nn_feature_names = ['sqft_living', 'sqft_lot', 'sqft_above', 'yr_built', 'sqft_living15', 'sqft_lot15']\noc_feature_names = ['bedrooms', 'bathrooms', 'floors', 'view', 'condition', 'grade']\n\nncfp = Pipeline([\n    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\nnfp = Pipeline([\n    ('scaler', MinMaxScaler())\n])\n\npreprocessor = ColumnTransformer([\n    ('nc', ncfp, nc_feature_names),\n    ('n', nfp, n_feature_names)\n], remainder='passthrough')\n\nX_train = preprocessor.fit_transform(X_train)\nX_test = preprocessor.transform(X_test)\n\nX_train_df = pd.DataFrame(X_train, columns=[\n    *preprocessor.named_transformers_['nc']['encoder'].get_feature_names(nc_feature_names),\n    *n_feature_names,\n    *oc_feature_names\n])","6837e676":"models = [\n    ('ARDR', ARDRegression()),\n    ('ADR', AdaBoostRegressor()),\n    ('BR', BayesianRidge()),\n    ('DTR', DecisionTreeRegressor()),\n    ('EN', ElasticNet()),\n    ('ETR', ExtraTreeRegressor()),\n    ('ETSR', ExtraTreesRegressor()),\n    ('GBR', GradientBoostingRegressor()),\n    ('HGBR', HistGradientBoostingRegressor()),\n    ('HR', HuberRegressor(max_iter=10000)),\n    ('KNR', KNeighborsRegressor()),\n    ('LASSO', Lasso()),\n    ('LL', LassoLars()),\n    ('LR', LinearRegression()),\n    ('MLPR', MLPRegressor(max_iter=10000)),\n    ('PAR', PassiveAggressiveRegressor()),\n    ('RFR', RandomForestRegressor()),\n    ('R', Ridge()),\n    ('SGDR', SGDRegressor()),\n    ('SVR', SVR()),\n    ('TSR', TheilSenRegressor()),\n    ('LGBMR', LGBMRegressor()),\n    ('XGBR', XGBRegressor(eval_metric='error', use_label_encoder=False)),\n    ('CBR', CatBoostRegressor(verbose=False))\n]\n\nnames = []\nresults = []\nfor name, model in models:\n    kfold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=101)\n    cv_results = cross_val_score(TransformedTargetRegressor(regressor=model, transformer=MinMaxScaler()), X_train, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n    cv_results = np.absolute(cv_results)\n    names.append(name)\n    results.append(cv_results)\n    print(f'{name}: {cv_results.mean()} ({cv_results.std()})')\n\nfig = plt.figure(figsize=(16, 9))\nfig.suptitle('Model Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","b7303e97":"# model_pipeline = Pipeline([\n#     ('model', TransformedTargetRegressor(\n#         regressor=CatBoostRegressor(verbose=False),\n#         transformer=MinMaxScaler()\n#     ))\n# ])\n\n# param_grid = {\n#     'model__regressor__iterations': [500, 1000, 1500, 2000, 2500, 3000],\n#     'model__regressor__depth': [4, 5, 6, 7, 8, 10],\n#     'model__regressor__leaf_estimation_iterations': [10],\n#     'model__regressor__loss_function': ['MAE'],\n#     'model__regressor__l2_leaf_reg': np.logspace(-20, -19, 3),\n#     'model__regressor__eval_metric': ['MAE'],\n#     'model__regressor__random_seed': [101]\n# }\n\n# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=101)\n# search = GridSearchCV(model_pipeline, param_grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n# search_result = search.fit(X_train, y_train)\n# print(f'Best Score: {search_result.best_score_}')\n# print(f'Best Hyper-parameters: {search_result.best_params_}')","f233bd0d":"model = CatBoostRegressor(iterations=1500, depth=8, loss_function='MAE', eval_metric='MAE', random_seed=101, verbose=False)\nttr = TransformedTargetRegressor(regressor=model, transformer=MinMaxScaler())\nttr.fit(X_train, y_train)\nprediction = ttr.predict(X_test)\nprint(f\"MAE: {mean_absolute_error(y_test, prediction)}\")\nprint(f\"MSR: {mean_squared_error(y_test, prediction)}\")\nprint(f\"R2: {r2_score(y_test, prediction)}\")","198f6fcb":"### Evaluate a Model","53f983d1":"### Tune Hyper-parameters","ecb72554":"**Remark:** We got no categorical features that got perfect linear relationship with the price. However, in a majority of cases the direction of change in price is predictably increasing as the value on the x-axis increases.","f5889f2c":"**Numerical:** id, price, sqft_living, sqft_lot, sqft_above, sqft_basement, sqft_living15, sqft_lot15\n**Categorical:** bedrooms, bathrooms, floors, waterfront, view, condition, grade\n**Temporal:** date, yr_built, yr_renovated\n**Spatial:** zipcode, lat, long","ca5be120":"# House Sales in King County, USA","cc8d4e14":"## Feature Engineering","324409c3":"### Explore","c6ce9f10":"**Remark:** The `sqft_basement` and `yr_renovated` are a good candidates to be transformed into categorical features.","b2f131da":"#### Handle Outliers","342fd52e":"## Install Packages","8aa2d18e":"### Train\/Test Split","5942fd8b":"## Imports","8da1c0f3":"**Remark:** The best performing machine learning model is `CatBoostRegressor`, with a mean absolute error (MAE) of ~99173.","9a69f8e8":"### Clean and Prepare","91178889":"**Remark:** The majority of the houses does not have a good view and are in somewhat good condition (3\/5). It's evident that the 3-4 bedroom houses represent the majority in our dataset. Also, the majority of the houses got between 1 and 2.5 bathrooms.","372f2213":"## Model Training","bb00860f":"**Remark:** The dataset does not contain any missing values.","1592af8b":"## Load Data","7c14f081":"## Exploratory Data Analysis (EDA)","fbf5524f":"### Feature Transformation","fe0f5fce":"### Pick a Model","147a07fa":"#### Drop Features with >=50% Missing Values","644eba86":"This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n\n**Features:**\n* id - Unique ID for each home sold\n* date - Date of the home sale\n* price - Price of each home sold\n* bedrooms - Number of bedrooms\n* bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n* sqft_living - Square footage of the apartments interior living space\n* sqft_lot - Square footage of the land space\n* floors - Number of floors\n* waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not\n* view - An index from 0 to 4 of how good the view of the property was\n* condition - An index from 1 to 5 on the condition of the apartment,\n* grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n* sqft_above - The square footage of the interior housing space that is above ground level\n* sqft_basement - The square footage of the interior housing space that is below ground level\n* yr_built - The year the house was initially built\n* yr_renovated - The year of the house\u2019s last renovation\n* zipcode - What zipcode area the house is in\n* lat - Lattitude\n* long - Longitude\n* sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n* sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors","02608a9d":"**Remark:** Since `yr_built` has almost zero (0.0088) correlation with the `price`, it *might* be a good idea to drop it.","251a3457":"**Remark:** All of the numerical features are unnormalised to a certain degree. When handling outliers, ignore `yr_built` and `yr_renovated` as those are not true continuous numerical features.","51b6f83a":"### Impute, Scale and Encode","801cffcb":"**Remark:** We got no continuous numerical features that got strong linear relationship with the price.","75a1f0ce":"#### Drop Irrelevant Features","2fb127f2":"#### Feature Creation","9b1571b3":"### Analyse"}}