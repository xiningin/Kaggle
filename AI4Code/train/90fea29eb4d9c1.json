{"cell_type":{"c96477b8":"code","d78ce3a7":"code","3c57e89a":"code","81770a36":"code","2c301665":"code","5488854f":"code","ba880445":"code","1955ea45":"code","a6f31a49":"code","8977f443":"code","ec66a31e":"code","7ce61488":"markdown","81b54fda":"markdown","1e02c8fe":"markdown","ad515b93":"markdown"},"source":{"c96477b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d78ce3a7":"import warnings\nimport nltk\nimport spacy\nimport re\nfrom spacy import displacy\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport plotly.express as px\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.models import load_model\nfrom wordcloud import WordCloud\nwarnings.filterwarnings('ignore')","3c57e89a":"path_of_file = '..\/input\/graphs-web\/web-NotreDame.txt'\ntext = open(path_of_file, 'r').read()","81770a36":"text[:1000]","2c301665":"path_of_file1 = '..\/input\/graphs-web\/web-BerkStan.txt'\ntext1 = open(path_of_file1, 'r').read()","5488854f":"text1[:1000]","ba880445":"nlp = spacy.load('en_core_web_sm')\nstopword = nltk.corpus.stopwords.words('english')\ndef text_cleaning(text):\n    \n    text = re.sub(r'[^\\w\\s]', '',str(text))             #Punctuations\n    text=re.split(\"\\W+\",text)                           #Tokenizing\n    text=[word for word in text if word not in stopword]#Stop words\n    text = ' '.join(text)                              \n    return text","1955ea45":"def frequent_of_words(string):\n    \n    clean_string = text_cleaning(string)\n    split_string = pd.DataFrame(clean_string.split(),columns=['Words'])\n    split_string = split_string.value_counts()[:1000].reset_index(drop=False)[:1000]\n    split_string.columns = ['Words','Count']\n    return split_string","a6f31a49":"frequent_words = frequent_of_words(text)\nfrequent_words[:15].style.background_gradient(cmap='Blues')","8977f443":"fig = px.funnel(frequent_words[:15], x='Count', y='Words')\nfig.show()","ec66a31e":"list_for_cloud = []\nfor i in frequent_words.Words:\n    list_for_cloud.append(str(i))","7ce61488":"Since I don't have words in my txt file, I'll stop here. And search for a txt.file with words to plot","81b54fda":"#How it likes?","1e02c8fe":"#Berkeley Stanford","ad515b93":"#Codes by Mammad Abbasli  https:\/\/www.kaggle.com\/mammadabbasli\/friends-text-generator"}}