{"cell_type":{"fa61fada":"code","97395988":"code","1095caff":"code","a432be0b":"markdown","f3cacb82":"markdown","98350732":"markdown"},"source":{"fa61fada":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97395988":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n\n# Importing the dataset\ndataset = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv').values\n\nX_train = dataset.iloc[:, 1:].values\ny_train = dataset.iloc[:, 0].values\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28)\/255.0\nX_train = X_train.reshape(X_train.shape[0], 28,28,1)\n\ntest = test.reshape(test.shape[0], 28, 28)\/255.0\ntest = test.reshape(test.shape[0], 28,28,1)","1095caff":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Conv2D(16, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n\n# Adding the second hidden layer\nclassifier.add(Conv2D(32, kernel_size = 3, padding=\"same\", activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Dropout(0.25))\n\n# Adding the third hidden layer\nclassifier.add(Conv2D(64, kernel_size = 3, padding=\"same\", activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Dropout(0.25))\n\n# Adding the forth hidden layer\nclassifier.add(Conv2D(128, kernel_size = 3, padding=\"same\", activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Dropout(0.25))\n\nclassifier.add(Conv2D(256, kernel_size = 3, padding=\"same\", activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\nclassifier.add(Dropout(0.25))\n\nclassifier.add(Flatten())\nclassifier.add(Dense(256, activation='relu'))\nclassifier.add(Dropout(0.5))\n\n# Adding the output layer\nclassifier.add(Dense(10, activation='softmax'))\n\n# Compiling the ANN\noptmize = tensorflow.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nclassifier.compile(loss = 'sparse_categorical_crossentropy', optimizer = optmize,  metrics=['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 128, epochs = 100)\n\ndata_out = pd.DataFrame({'id': range(1,len(test)+1), 'label': results})\ndata_out.to_csv('submission.csv', index = None)","a432be0b":"**Model**","f3cacb82":"## We want to run a model for the Digit Recognizer Competition. ","98350732":"Train on 42000 samples\nEpoch 1\/100\n42000\/42000 [==============================] - 7s 158us\/sample - loss: 0.5112 - accuracy: 0.8272\nEpoch 2\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.1068 - accuracy: 0.9683\nEpoch 3\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0773 - accuracy: 0.9767\nEpoch 4\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0608 - accuracy: 0.9822\nEpoch 5\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0534 - accuracy: 0.9846\nEpoch 6\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0456 - accuracy: 0.9871\nEpoch 7\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0422 - accuracy: 0.9877\nEpoch 8\/100\n42000\/42000 [==============================] - 3s 66us\/sample - loss: 0.0379 - accuracy: 0.9894\nEpoch 9\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0357 - accuracy: 0.9897\nEpoch 10\/100\n42000\/42000 [==============================] - 3s 63us\/sample - loss: 0.0334 - accuracy: 0.9900\nEpoch 11\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0303 - accuracy: 0.9908\nEpoch 12\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0295 - accuracy: 0.9915\nEpoch 13\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0290 - accuracy: 0.9914\nEpoch 14\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0262 - accuracy: 0.9926\nEpoch 15\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0266 - accuracy: 0.9922\nEpoch 16\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0252 - accuracy: 0.9932\nEpoch 17\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0231 - accuracy: 0.9926\nEpoch 18\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0224 - accuracy: 0.9930\nEpoch 19\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0230 - accuracy: 0.9935\nEpoch 20\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0224 - accuracy: 0.9933\nEpoch 21\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0184 - accuracy: 0.9946\nEpoch 22\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0223 - accuracy: 0.9932\nEpoch 23\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0185 - accuracy: 0.9946\nEpoch 24\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0176 - accuracy: 0.9946\nEpoch 25\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0199 - accuracy: 0.9938\nEpoch 26\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0179 - accuracy: 0.9945\nEpoch 27\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0169 - accuracy: 0.9952\nEpoch 28\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0187 - accuracy: 0.9945\nEpoch 29\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0168 - accuracy: 0.9950\nEpoch 30\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0158 - accuracy: 0.9952\nEpoch 31\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0168 - accuracy: 0.9950\nEpoch 32\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0167 - accuracy: 0.9949\nEpoch 33\/100\n42000\/42000 [==============================] - 3s 62us\/sample - loss: 0.0143 - accuracy: 0.9958\nEpoch 34\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0160 - accuracy: 0.9951\nEpoch 35\/100\n42000\/42000 [==============================] - 3s 62us\/sample - loss: 0.0156 - accuracy: 0.9953\nEpoch 36\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0146 - accuracy: 0.9955\nEpoch 37\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0160 - accuracy: 0.9951\nEpoch 38\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0141 - accuracy: 0.9959\nEpoch 39\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0130 - accuracy: 0.9961\nEpoch 40\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0098 - accuracy: 0.9969\nEpoch 41\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0167 - accuracy: 0.9950\nEpoch 42\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0112 - accuracy: 0.9963\nEpoch 43\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0137 - accuracy: 0.9962\nEpoch 44\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0135 - accuracy: 0.9962\nEpoch 45\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0126 - accuracy: 0.9964\nEpoch 46\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0130 - accuracy: 0.9966\nEpoch 47\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0122 - accuracy: 0.9963\nEpoch 48\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0138 - accuracy: 0.9960\nEpoch 49\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0171 - accuracy: 0.9950\nEpoch 50\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0141 - accuracy: 0.9959\nEpoch 51\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0119 - accuracy: 0.9966\nEpoch 52\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0117 - accuracy: 0.9966\nEpoch 53\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0119 - accuracy: 0.9967\nEpoch 54\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0095 - accuracy: 0.9970\nEpoch 55\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0112 - accuracy: 0.9964\nEpoch 56\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0114 - accuracy: 0.9965\nEpoch 57\/100\n42000\/42000 [==============================] - 3s 60us\/sample - loss: 0.0104 - accuracy: 0.9968\nEpoch 58\/100\n42000\/42000 [==============================] - 3s 65us\/sample - loss: 0.0116 - accuracy: 0.9968\nEpoch 59\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0114 - accuracy: 0.9965\nEpoch 60\/100\n42000\/42000 [==============================] - 3s 62us\/sample - loss: 0.0098 - accuracy: 0.9971\nEpoch 61\/100\n42000\/42000 [==============================] - 3s 60us\/sample - loss: 0.0120 - accuracy: 0.9967\nEpoch 62\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0121 - accuracy: 0.9966\nEpoch 63\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0109 - accuracy: 0.9971\nEpoch 64\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0124 - accuracy: 0.9964\nEpoch 65\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0107 - accuracy: 0.9968\nEpoch 66\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0124 - accuracy: 0.9963\nEpoch 67\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0091 - accuracy: 0.9971\nEpoch 68\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0131 - accuracy: 0.9965\nEpoch 69\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0116 - accuracy: 0.9967\nEpoch 70\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0115 - accuracy: 0.9965\nEpoch 71\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0117 - accuracy: 0.9966\nEpoch 72\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0107 - accuracy: 0.9968\nEpoch 73\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0117 - accuracy: 0.9964\nEpoch 74\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0118 - accuracy: 0.9965\nEpoch 75\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0091 - accuracy: 0.9971\nEpoch 76\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0094 - accuracy: 0.9977\nEpoch 77\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0095 - accuracy: 0.9972\nEpoch 78\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0114 - accuracy: 0.9968\nEpoch 79\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0110 - accuracy: 0.9970\nEpoch 80\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0103 - accuracy: 0.9969\nEpoch 81\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0083 - accuracy: 0.9977\nEpoch 82\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0116 - accuracy: 0.9965\nEpoch 83\/100\n42000\/42000 [==============================] - 3s 62us\/sample - loss: 0.0101 - accuracy: 0.9970\nEpoch 84\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0100 - accuracy: 0.9972\nEpoch 85\/100\n42000\/42000 [==============================] - 3s 61us\/sample - loss: 0.0097 - accuracy: 0.9972\nEpoch 86\/100\n42000\/42000 [==============================] - 2s 59us\/sample - loss: 0.0130 - accuracy: 0.9966\nEpoch 87\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0114 - accuracy: 0.9968\nEpoch 88\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0115 - accuracy: 0.9968\nEpoch 89\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0077 - accuracy: 0.9975\nEpoch 90\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0137 - accuracy: 0.9964\nEpoch 91\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0098 - accuracy: 0.9969\nEpoch 92\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0105 - accuracy: 0.9968\nEpoch 93\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0107 - accuracy: 0.9972\nEpoch 94\/100\n42000\/42000 [==============================] - 2s 56us\/sample - loss: 0.0103 - accuracy: 0.9971\nEpoch 95\/100\n42000\/42000 [==============================] - 2s 58us\/sample - loss: 0.0072 - accuracy: 0.9978\nEpoch 96\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0115 - accuracy: 0.9970\nEpoch 97\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0125 - accuracy: 0.9968\nEpoch 98\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0112 - accuracy: 0.9970\nEpoch 99\/100\n42000\/42000 [==============================] - 2s 57us\/sample - loss: 0.0103 - accuracy: 0.9970\nEpoch 100\/100\n42000\/42000 [==============================] - 2s 55us\/sample - loss: 0.0110 - accuracy: 0.9970\nOut[10]:\n<tensorflow.python.keras.callbacks.History at 0x7f1113400780>"}}