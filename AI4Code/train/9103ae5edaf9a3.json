{"cell_type":{"e396d554":"code","06cd524e":"code","526e8a33":"code","a61e0127":"code","5e4d6914":"code","c698f2bd":"code","58d70ece":"code","bb3e37c4":"code","3b7c4c43":"code","21a63574":"code","fa98c6e4":"code","cfcabd30":"markdown","56b02602":"markdown","2eb9757e":"markdown","16105ee9":"markdown","2c475e1b":"markdown"},"source":{"e396d554":"!pip install simpletransformers","06cd524e":"import os, re, string\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\n\nimport torch\n\nfrom simpletransformers.classification import ClassificationModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold","526e8a33":"seed = 1337\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","a61e0127":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e4d6914":"# Zero pre-processing of training data\n# I have tried doing some preprcessing\/cleaning but the result \n# does not seem significant\ntrain_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain_data = train_data[['text', 'target']]","c698f2bd":"# Using 'bert-large-uncased' here. For a list of other models, please refer to \n# https:\/\/github.com\/ThilinaRajapakse\/simpletransformers\/#current-pretrained-models \nbert_uncased = ClassificationModel('bert', 'bert-large-uncased') \n\n# Print out all the default arguments for reference\nbert_uncased.args","58d70ece":"# This is where we can tweak based on the default arguments above\ncustom_args = {'fp16': False, # not using mixed precision \n               'train_batch_size': 4, # default is 8\n               'gradient_accumulation_steps': 2,\n               'do_lower_case': True,\n               'learning_rate': 1e-05, # using lower learning rate\n               'overwrite_output_dir': True, # important for CV\n               'num_train_epochs': 2} # default is 1","bb3e37c4":"n=5\nkf = KFold(n_splits=n, random_state=seed, shuffle=True)\nresults = []\n\nfor train_index, val_index in kf.split(train_data):\n    train_df = train_data.iloc[train_index]\n    val_df = train_data.iloc[val_index]\n    \n    model = ClassificationModel('bert', 'bert-base-uncased', args=custom_args) \n    model.train_model(train_df)\n    result, model_outputs, wrong_predictions = model.eval_model(val_df, acc=sklearn.metrics.accuracy_score)\n    print(result['acc'])\n    results.append(result['acc'])","3b7c4c43":"for i, result in enumerate(results, 1):\n    print(f\"Fold-{i}: {result}\")\n    \nprint(f\"{n}-fold CV accuracy result: Mean: {np.mean(results)} Standard deviation:{np.std(results)}\")","21a63574":"model = ClassificationModel('bert', 'bert-base-uncased', args=custom_args) \nmodel.train_model(train_data)","fa98c6e4":"test_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\npredictions, raw_outputs = model.predict(test_data['text'])\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","cfcabd30":"A minimal approach to use transformers using the simpletransformers package (https:\/\/github.com\/ThilinaRajapakse\/simpletransformers\/) that allows for:\n1. Easy switching between different pre-trained models\n2. Simple hyperparameter tuning\n3. Basic k-fold cross validation\n4. Zero pre-processing of data\n\nHowever, language model fine-tuning is not available with this method.\n\nUpdates:\n12 Jan 2020 - Update to set random seed to ensure deterministic prediction.","56b02602":"# Full Training","2eb9757e":"# Check default value of model and tweak","16105ee9":"# Predict","2c475e1b":"# 5-Fold CV"}}