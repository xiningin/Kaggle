{"cell_type":{"e8ea3316":"code","74434aef":"code","02c36b44":"code","32b2da01":"code","83130bbc":"code","8b168979":"code","e6884799":"code","9057c974":"code","87c7a246":"code","72a0672f":"code","887ea6e2":"code","62e13117":"code","99452e10":"code","e3fc8bf2":"code","86146982":"code","7fd90789":"code","c1662bf2":"code","2442af74":"code","2e15c044":"code","a2ad1935":"code","86bf733a":"code","22151995":"code","e0ae5791":"code","91215bed":"code","90ee10e6":"code","0e3f226b":"code","a89749d5":"code","564ade64":"code","d4403d07":"code","0c2e428c":"code","09cdc7f9":"code","b8c80742":"code","24f4c8bf":"code","25dd9706":"code","0a4e08c4":"code","f10508e4":"code","df8ef7b8":"code","4a059b26":"code","f1b8d8fe":"code","94478e9b":"code","354e13d2":"code","830eb9f5":"code","491937c3":"code","4e378b68":"code","65a5ce66":"code","152ebfbc":"code","30c7ce3c":"code","ecf61af2":"code","1457200e":"code","c8a9ee89":"code","32ad0c60":"code","f009eb94":"code","8b3320cd":"code","a21b0691":"code","34851d41":"code","e6d6e89f":"markdown","5e06959b":"markdown","1b907fba":"markdown","3b53cc33":"markdown","d0838527":"markdown"},"source":{"e8ea3316":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74434aef":"FILEPATH = '\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv'","02c36b44":"df = pd.read_csv(FILEPATH, encoding='cp852', engine = 'c') # engine 'c' used instead of 'python' for higher performance\ndf.head(5)","32b2da01":"# delete unnecessary cols\ncols = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n\ndf.drop(cols, axis = 1, inplace = True)","83130bbc":"df.head()","8b168979":"# Title change v1 = result, v2 = input\n\ndf.columns = ['result', 'input']\n\n# we can also use df.rename() option here","e6884799":"df.head()","9057c974":"# reorder options - must be applicable for all cols\ndf = df[['input','result']]\n ","87c7a246":"df.head()","72a0672f":"# Buggy, please don't use\nnew_cols = ['my_input', 'my_result']\n\ndf1 = df.reindex(columns = new_cols)\n# df1.to_csv(FILEPATH)\n# df1.head()","887ea6e2":"# Rename cols by using .rename - can be used for selected cols\n\ndf.rename(columns = {'input' : 'my_new_input', 'result' : 'my_new_result'}, inplace = True)","62e13117":"df.head()","99452e10":"df.count()","e3fc8bf2":"# print first string\n\ndf.iloc[1][0]","86146982":"df.iloc[2][0]","7fd90789":"def find_message_length(msg):\n    \n    msg_words = msg.split(' ')\n    \n    msg_len = len(msg_words)\n    \n    return msg_len","c1662bf2":"print(find_message_length(df.iloc[0][0]))","2442af74":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_words_count'] = df['my_new_input'].apply(find_message_length)\ndf.head()\n\n# ref: https:\/\/rajacsp.github.io\/mlnotes\/python\/data-wrangling\/advanced-custom-lambda\/","2e15c044":"# show the unique labels\n\nset(df['my_new_result'])","a2ad1935":"def find_length(msg):\n    \n    msg_len = len(msg)\n    \n    return msg_len","86bf733a":"print(find_length(df.iloc[0][0]))","22151995":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_char_length'] = df['my_new_input'].apply(find_length)\ndf.head()","e0ae5791":"# History words count\n\nimport matplotlib.pyplot as plt\n\n# to avoid popups use inline\n%matplotlib inline ","91215bed":"# plt.hist(data['label'], bins=3, weights=np.ones(len(data['label'])) \/ len(data['label']))\n\nimport numpy as np\n\nplt.hist(df['input_words_count'], bins = 100, weights = np.ones(len(df['input_words_count'])) \/ len(df['input_words_count']))\n\nplt.xlabel('Word Length')\nplt.ylabel('Group Count')\nplt.title('Word Length Histogram')","90ee10e6":"# Find more than 80 words\ndf['input_words_count']","0e3f226b":"df_above_80 = df[df['input_words_count'] > 80]","a89749d5":"df_above_80","564ade64":"import numpy as np\n\nplt.hist(df['input_char_length'], bins = 100, weights = np.ones(len(df['input_char_length'])) \/ len(df['input_char_length']))\n\nplt.xlabel('Char Length')\nplt.ylabel('Group Count')\nplt.title('Char Length Histogram')","d4403d07":"spams = df['my_new_input'].iloc[(df['my_new_result'] == 'spam').values]\nhams = df['my_new_input'].iloc[(df['my_new_result'] == 'ham').values]\nprint(spams[:10])\nprint(hams[:10])","0c2e428c":"import spacy","09cdc7f9":"#Spacy implementation of NLTK given in example\nnlp = spacy.load('en')","b8c80742":"def normalize(msg):\n    \n    doc = nlp(msg)\n    res=[]\n    \n    for token in doc:\n        if(token.is_stop or token.is_digit or token.is_punct or not(token.is_oov)):\n            pass\n        else:\n            res.append(token.lemma_.lower())\n    \n    return res","24f4c8bf":"#Stop words removal\nfor word in spams:\n    word = normalize(word)\n\nfor word in hams:\n    word = normalize(word)\n\nprint(spams)\nprint(hams)","25dd9706":"from collections import Counter","0a4e08c4":"def tokenise(words):\n    res = []\n    \n    for word in words:\n        doc = nlp(word)\n        \n        for token in doc:\n            res.append(token.text)\n    return res","f10508e4":"spam_tokens = tokenise(spams)\nham_tokens = tokenise(hams)","df8ef7b8":"spam_most_common = Counter(spam_tokens).most_common(25)\n\nham_most_common = Counter(ham_tokens).most_common(25)\n#Method did not work\n'''\nfor word in spams:\n    spam_most_common.append(most_common(word))\n'''\nprint(spam_most_common)\n\nprint(ham_most_common)","4a059b26":"from sklearn.model_selection import train_test_split","f1b8d8fe":"tr, te = train_test_split(df, test_size = 0.2)\nprint(\"Training set length:\", len(tr))\nprint(\"Test set length:\", len(te))","94478e9b":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","354e13d2":"#Can be called by using binary = True in Count Vectorizer\nbin_vectorizer = CountVectorizer(binary=True)\ncount_vectorizer = CountVectorizer()\ntfidf_vectorizer = TfidfVectorizer()","830eb9f5":"def feature_extraction(msg):\n    \n    matrix = pd.DataFrame(tfidf_vectorizer.fit_transform(msg).toarray(),columns=tfidf_vectorizer.get_feature_names(),index=None)\n    \n    return matrix","491937c3":"from sklearn.model_selection import train_test_split","4e378b68":"df['my_new_result'] = df['my_new_result'].map({'ham':0,'spam':1})","65a5ce66":"k = feature_extraction(df['my_new_input'])\n\nprint(k.shape, df['my_new_result'].shape)","152ebfbc":"tr_x, tr_y, te_x, te_y = train_test_split(k, df['my_new_result'], test_size=0.2)","30c7ce3c":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score, confusion_matrix","ecf61af2":"classifiers = {\n    'mnb': MultinomialNB(),\n    'gnb': GaussianNB(),\n    'svm1': SVC(kernel='linear'),\n    'svm2': SVC(kernel='rbf'),\n    'svm3': SVC(kernel='sigmoid'),\n    'mlp1': MLPClassifier(),\n    'mlp2': MLPClassifier(hidden_layer_sizes=[100,100]),\n    'ada': AdaBoostClassifier(),\n    'dtc': DecisionTreeClassifier(),\n    'rfc': RandomForestClassifier(),\n    'gbc': GradientBoostingClassifier(),\n    'lr': LogisticRegression()\n}","1457200e":"f1_scores = dict()\n\nfor classifier in classifiers:\n    \n    clf = classifiers[classifier]\n    clf.fit(tr_x,te_x)\n    y_pred = clf.predict(tr_y)\n    f1_scores[classifier] = f1_score(y_pred, te_y)\n    print(classifier, f1_scores[classifier])","c8a9ee89":"possible_solvers = ['lbfgs', 'sgd', 'adam']\nm_f1_score = float('-inf')\nbest_solver = None\n\nfor solver in possible_solvers:\n    classifier = MLPClassifier(solver = solver)\n    classifier.fit(tr_x, te_x)\n    y_pred = classifier.predict(tr_y)\n    curr_f1_score = f1_score(y_pred, te_y)\n    if curr_f1_score > m_f1_score:\n        m_f1_score = curr_f1_score\n        best_solver = solver\n        \nprint(best_solver,'is the best one')","32ad0c60":"alphas = [i * 0.1 for i in range(11)]\nm_f1_score = float('-inf')\nbest_alpha = None\n\nfor alpha in alphas:\n    \n    classifier = MLPClassifier(solver = 'lbfgs')\n    classifier.fit(tr_x, te_x)\n    y_pred = classifier.predict(tr_y)\n    curr_f1_score = f1_score(y_pred, te_y)\n    if curr_f1_score > m_f1_score:\n        m_f1_score = curr_f1_score\n        best_alpha = alpha\n        \nprint(\"Best alpha is\",best_alpha,\"and highest f1_score is\",m_f1_score)","f009eb94":"classifier = MLPClassifier(solver = 'lbfgs', alpha=0.2)\n#Maybe change this based on hyperparameter tuning\nclassifier.fit(tr_x, te_x)\ny_pred = classifier.predict(tr_y)\nprint(confusion_matrix(y_pred, te_y))","8b3320cd":"import seaborn as sns","a21b0691":"sns.regplot(x=te_y, y=y_pred, marker=\"*\")","34851d41":"txt = \"\"","e6d6e89f":"**Testing 1, 2, 3**","5e06959b":"![final_5f5b9a2130b744009a1d389b_698054.png](attachment:final_5f5b9a2130b744009a1d389b_698054.png)","1b907fba":"Tokenisation","3b53cc33":"**Prediction Time**","d0838527":"Source:\n\nhttps:\/\/docs.python.org\/3\/library\/codecs.html#standard-encodings\n\nhttps:\/\/www.kaggle.com\/devghiles\/step-by-step-solution-with-f1-score-as-a-metric\n\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html\n\nTo rename:\nhttps:\/\/stackoverflow.com\/questions\/11346283\/renaming-columns-in-pandas\n\nTo change cols:\nhttps:\/\/stackoverflow.com\/questions\/12329853\/how-to-rearrange-pandas-column-sequence\/23741704\n\nhttps:\/\/rajacsp.github.io\/mlnotes\/python\/data-wrangling\/advanced-custom-lambda\/\n"}}