{"cell_type":{"20dd427d":"code","97debcbe":"code","fed3876d":"code","210d39dd":"code","cf029f18":"code","73fc734e":"code","3e9c648a":"code","9c2f2fec":"code","b84d137b":"code","6a56d67a":"code","9a4c0835":"code","9af6ecf2":"code","468b963b":"code","09f23d78":"code","27ea8243":"code","84c95c39":"code","77e81c14":"code","ea1b46ad":"code","c292d89a":"code","48194baa":"code","3f05f693":"code","14dfd95f":"code","956eea35":"code","7acfc58a":"code","06891682":"code","b6c872e0":"code","d1237347":"code","7ee9a2f6":"code","627cf009":"code","a1bfadcb":"code","7cedd515":"code","dc00884c":"code","e996448d":"code","93bcd0dd":"code","36dd363d":"code","73afaaf6":"code","c25474a3":"code","8ca06eaf":"code","11d1a899":"code","9874c862":"code","0deb2b33":"code","cb6bea17":"code","f212b7ab":"code","2d46b5b7":"code","e0530700":"code","fcc1897d":"code","59ac0dfa":"code","e274c207":"code","1107ea0f":"code","e8c9b0c0":"code","42008d12":"code","8107d80b":"code","80c2d5bc":"code","247e7eb7":"code","c1a36541":"code","5e2af767":"code","fe8a8091":"code","c946e10a":"code","da23b824":"code","4a474fa7":"code","15d4d00d":"code","0554fe56":"code","052f3cb3":"code","df53dde7":"code","fe49b91e":"code","88e8b774":"code","67ffd4ed":"code","4f96fda3":"code","9b5ddeb2":"code","d5b59ff6":"code","b18b9ccd":"code","f4b0a1ce":"code","8818228f":"code","15c41214":"code","8fd89920":"code","76311cfd":"code","8b5bfd30":"code","203935c1":"code","706d1d97":"code","4a441d79":"markdown","f3fe662e":"markdown","5fb9ef22":"markdown","61198044":"markdown","27632560":"markdown"},"source":{"20dd427d":"import datetime\nnow = datetime.datetime.now()\nprint(now)","97debcbe":"%matplotlib inline\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot","fed3876d":"import os\nimport shutil\nprint(os.listdir(\"..\/input\"))","210d39dd":"try:\n    os.makedirs('\/tmp\/.keras\/datasets')\nexcept FileExistsError:\n    pass","cf029f18":"try:\n    shutil.copytree(\"..\/input\/keras-pretrained-models\", \"\/tmp\/.keras\/models\")\nexcept FileExistsError:\n    pass","73fc734e":"import os.path\nimport itertools\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n    Conv1D, Conv2D, Conv3D, \\\n    Conv2DTranspose, \\\n    AveragePooling1D, AveragePooling2D, \\\n    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n    GlobalAveragePooling1D, \\\n    GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalMaxPooling3D, \\\n    LocallyConnected1D, LocallyConnected2D, \\\n    concatenate, Flatten, Average, Activation, \\\n    RepeatVector, Permute, Reshape, Dot, \\\n    multiply, dot, add, \\\n    PReLU, \\\n    Bidirectional, TimeDistributed, \\\n    SpatialDropout1D, \\\n    BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras import losses\nfrom keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.metrics import categorical_accuracy\nfrom keras.constraints import maxnorm, non_neg\nfrom keras.optimizers import RMSprop\nfrom keras.utils import to_categorical, plot_model\nfrom keras import backend as K","3e9c648a":"from PIL import Image\nfrom zipfile import ZipFile\nimport h5py\nimport cv2\nfrom tqdm import tqdm","9c2f2fec":"src_dir = '..\/input\/human-protein-atlas-image-classification'","b84d137b":"train_labels = pd.read_csv(os.path.join(src_dir, \"train.csv\"))\nprint(train_labels.shape)\ntrain_labels.head(10)","6a56d67a":"test_labels = pd.read_csv(os.path.join(src_dir, \"sample_submission.csv\"))\nprint(test_labels.shape)\ntest_labels.head()","9a4c0835":"def show_arr(arr, nrows = 1, ncols = 4, figsize=(15, 5)):\n    fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n    for ii in range(ncols):\n        iplt = subs[ii]\n        try:\n            img_array = arr[:,:,ii]\n            if ii == 0:\n                cp = 'Greens'\n            elif ii == 1:\n                cp = 'Blues'\n            elif ii == 2:\n                cp = 'Reds'\n            else:\n                cp = 'Oranges'\n            iplt.imshow(img_array, cmap=cp)\n        except:\n            pass","9af6ecf2":"def get_arr0(Id, test=False):\n    def fn(Id, color, test=False):\n        if test:\n            tgt = 'test'\n        else:\n            tgt = 'train'\n        with open(os.path.join(src_dir, tgt, Id+'_{}.png'.format(color)), 'rb') as fp:\n            img = Image.open(fp)\n            arr = (np.asarray(img) \/ 255.)\n        return arr\n    res = []\n    for icolor in ['green', 'blue', 'red', 'yellow']:\n        arr0 = fn(Id, icolor, test)\n        res.append(arr0)\n    arr = np.stack(res, axis=-1)\n    return arr","468b963b":"arr = get_arr0('00008af0-bad0-11e8-b2b8-ac1f6b6435d0', test=True)\nprint(arr.shape)\nshow_arr(arr)","09f23d78":"arr = get_arr0('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0')\nprint(arr.shape)\nshow_arr(arr)","27ea8243":"SH_ALL = (512, 512)\nSH = (256, 256)\nID_LIST_TRAIN = train_labels.Id.tolist()","84c95c39":"# def get_arr(Id, test=False, spl=2):\n#     if test:\n#         arr = get_arr0(Id, test=True)\n#     else:\n#         arr = get_arr0(Id)\n#     arr = arr[:].astype('float32')\n#     res = []\n#     arr2 = [res.extend(np.hsplit(ee, spl)) for ee in np.vsplit(arr, spl)]\n#     return np.stack(res)","77e81c14":"# get_arr('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0').shape","ea1b46ad":"# arr = get_arr('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0')\n# print(arr.shape)\n# show_arr(arr[0])\n# show_arr(arr[1])\n# show_arr(arr[2])\n# show_arr(arr[3])","c292d89a":"# arr = get_arr('00008af0-bad0-11e8-b2b8-ac1f6b6435d0', test=True)\n# print(arr.shape)\n# show_arr(arr[0])\n# show_arr(arr[1])\n# show_arr(arr[2])\n# show_arr(arr[3])","48194baa":"y_cat_train_dic = {}\nfor icat in range(28):\n    target = str(icat)\n    y_cat_train_5 = np.array([int(target in ee.split()) for ee in train_labels.Target.tolist()])\n    y_cat_train_dic[icat] = y_cat_train_5","3f05f693":"up_sample = {}\nfor k in y_cat_train_dic:\n    v = y_cat_train_dic[k].sum()\n    up_sample[k] = np.ceil((train_labels.shape[0]\/28) \/ v)\n\nup_sample","14dfd95f":"up_sample2 = list(zip(*sorted(list(up_sample.items()), key=lambda x: x[0])))[1]\nup_sample2 = np.array(up_sample2)\nup_sample2","956eea35":"import random\n\nclass Seq(object):\n    sections = None\n    index = None\n    SPLIT_LIST = [\n        np.array(range(256)),\n        np.array(range(256)) + 256\n    ]\n    \n    def __init__(self, df, extend=False, aug=False, test=False, batch_size=32):\n        self.shaffle = None\n        self.extend = extend\n        self.aug = aug\n        self.test = test\n        self.batch_size = batch_size\n        self.df = df\n        \n        # proccess\n        self.ids = self.df.Id.tolist()\n        self.reversed = sorted(range(SH_ALL[0]), reverse=True)\n        \n        # estimate self length\n        self.initialize_it()\n        self.len = 1\n        for _ in self.it:\n            self.len += 1\n        \n        self.initialize_it()\n    \n    def initialize_it(self):\n        if self.shaffle:\n            '''not implemented yet'''\n            raise NotImplementedError\n            #random.seed(self.state)\n            #random.shuffle(self.ids)\n        \n        self.it = iter(range(0, len(self.ids), self.batch_size))\n        self.idx_next = self.it.__next__()\n    \n    def __len__(self):\n        return self.len\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        idx = self.idx_next\n        self.ids_part = self.ids[idx:((idx+self.batch_size) if idx+self.batch_size<len(self.ids) else len(self.ids))]\n        res = self.getpart(self.ids_part)\n        try:\n            self.idx_next = self.it.__next__()\n        except StopIteration:\n            self.initialize_it()\n        return res\n    \n    def __getitem__(self, id0):\n        arr, tgts = self.get_data(id0)\n        cat = self.convert_tgts(tgts)\n        return arr, cat\n    \n    k_list = list(range(4))\n    def random_transform(self, arr):\n        k = random.choice(self.k_list)\n        arr0 = np.rot90(arr, k=k)\n        if random.randint(0,1):\n            arr0 = arr0[self.reversed,:,:]\n        if random.randint(0,1):\n            arr0 = arr0[:,self.reversed,:]\n        return arr0\n    \n    def convert_tgts(self, tgts):\n        try:\n            cats = to_categorical(tgts, num_classes=28)\n            cat = cats.sum(axis=0)\n        except TypeError:\n            cat = np.zeros((28,))\n        return cat\n    \n    def get_data(self, id0):\n        arr = get_arr0(id0, test=self.test)\n        \n        try:\n            y0 = (self.df.Target[self.df.Id == id0]).tolist()[0]\n            y1 = y0.split()\n            y = [int(ee) for ee in y1]\n        except AttributeError:\n            y = None\n        return arr, y\n    \n    def getpart(self, ids):\n        xs = []\n        ys = []\n        for id0 in ids:\n            self.extend_data(id0, xs, ys)\n        \n        x = np.stack(xs)\n        y = np.stack(ys)\n        x_dummy = np.zeros((len(x), 1))\n        x_ret = {\n            'input': x,\n            'input_cls': y,\n        }\n        y_ret = {\n            'path_fit_cls_img': x_dummy,\n            'path_cls_img_cls': y,\n            'path_fit_imgA': x_dummy,\n            'path_fit_img_cls_img': x_dummy,\n            'path_cls_cls': y,\n            'path_img_cls': y,\n            'path_img_img_cls': y,\n            'path_fit_cls_img_imgE': x_dummy,\n        }\n        return (x_ret, y_ret)\n    \n    def split(self, arr):\n        res = []\n        for row_idx in self.SPLIT_LIST:\n            for col_idx in self.SPLIT_LIST:\n                #print(arr.shape, row_idx, col_idx)\n                res.append(arr[:, col_idx][row_idx].flatten())\n        return res\n    \n    def extend_data(self, id0, xs, ys):\n        arr0, cat = self[id0]\n        \n        # data augmentation\n        if self.extend:\n            mm = up_sample2[cat==1].max()\n            mm = int(mm)\n            #print(mm)\n            for ii in range(mm):\n                if self.aug:\n                    img = self.random_transform(arr0)\n                else:\n                    img = arr0\n                xs.append(img.flatten())\n                ys.append(cat)\n        else:\n            if self.aug:\n                img0 = self.random_transform(arr0)\n            else:\n                img0 = arr0\n            res = self.split(img0)\n            res = np.concatenate(res)\n            xs.append(res)\n            ys.append(cat)","7acfc58a":"seq = Seq(train_labels, extend=False, aug=True, batch_size=8)\nprint(len(seq))","06891682":"print(len(seq.ids))\nlen(seq)","b6c872e0":"arr, y = seq.get_data('ad5a4858-bb9d-11e8-b2b9-ac1f6b6435d0')\nprint(arr.shape)\nshow_arr(arr)","d1237347":"x, y = seq['ad5a4858-bb9d-11e8-b2b9-ac1f6b6435d0']\nprint(x.shape)\nshow_arr(x)","7ee9a2f6":"xs, ys = next(seq)\nprint(xs['input'].shape)\nprint(xs['input_cls'].shape)","627cf009":"show_arr(xs['input'][0].reshape((4,256,256,4))[0])","a1bfadcb":"show_arr(xs['input'][0].reshape((4,256,256,4))[1])","7cedd515":"from keras import applications","dc00884c":"def make_trainable_false(model_resnet, trainable=False):\n    layers = model_resnet.layers\n    for ilayer in layers:\n        ilayer.trainable = trainable\n    return","e996448d":"img_shape = tuple(list(SH) + [4])\nprint(img_shape)\nimg_dim = 4 * np.array(img_shape).prod()\nprint(img_dim)","93bcd0dd":"def make_model_cnvt(img_dim, img_shape):\n    '''==============================\n    inputs\n    =============================='''\n    inp = Input(shape=(img_dim,))\n    oup = Reshape(img_shape)(inp)\n    #oup = Conv2D(3, kernel_size=1, strides=1, padding='same')(oup)\n    #oup = Conv2D(3, kernel_size=1, strides=1, padding='same', activation='sigmoid')(oup)\n    oup = Conv2D(3,\n                 kernel_size=1,\n                 strides=1,\n                 padding='same',\n                 activation='tanh',\n                 kernel_regularizer=regularizers.l2(0))(oup)\n    #kernel_regularizer=regularizers.l2(1e-4)\n    model_cnvt = Model(inp, oup, name='model_cnvt')\n    return model_cnvt","36dd363d":"def make_model_classifier(input_dim=1536):\n    inp_cls = Input((input_dim,))\n    oup_cls = Dense(28)(inp_cls)\n    oup_cls = Activation('sigmoid')(oup_cls)\n    model_classifier = Model(inp_cls, oup_cls, name='classifier')\n    return model_classifier","73afaaf6":"def make_model(img_dim, model_cnvt, model_resnet, model_classifier):\n    inp0 = Input(shape=(int(img_dim\/4),), name='input0')\n    oup0 = model_cnvt(inp0)\n    oup0 = model_resnet(oup0)\n    oup0 = model_classifier(oup0)\n    oup0 = Activation('linear', name='path_cls_cls')(oup0)\n    model0 = Model(inp0, oup0, name='model0')\n    \n    '''==============================\n    inputs\n    =============================='''\n    def fn(x, idx):\n        x1 = K.permute_dimensions(x, (1,0,2,))\n        x2 = K.gather(x1, idx)\n        return x2\n    inp = Input(shape=(img_dim,), name='input')\n    oup = Reshape((4,int(img_dim\/4)))(inp)\n    img0 = Lambda(lambda x: fn(x, 0))(oup)\n    img1 = Lambda(lambda x: fn(x, 1))(oup)\n    img2 = Lambda(lambda x: fn(x, 2))(oup)\n    img3 = Lambda(lambda x: fn(x, 3))(oup)\n    oup = Lambda(lambda x: K.stack(x, 1))([model0(img0), model0(img1), model0(img2), model0(img3)])\n    oup = GlobalMaxPooling1D()(oup)\n    oup = Activation('linear', name='path_cls_cls')(oup)\n    model = Model(inp, oup, name='model')\n    \n    return {\n        'model_classifier': model_classifier,\n        'model_resnet': model_resnet,\n        'model_cnvt': model_cnvt,\n        'model': model,\n        'model0': model0\n    }","c25474a3":"# models = make_model(img_dim, model_cnvt, model_resnet, model_classifier)\n# models['model0'].summary()","8ca06eaf":"# models['model'].summary()","11d1a899":"model_cnvt = make_model_cnvt(int(img_dim\/4), img_shape)\nmodel_cnvt.summary()","9874c862":"model_cnvt.layers[2].get_weights()","0deb2b33":"model_cnvt.load_weights('..\/input\/resnet50-4x256-max-1\/model_1_cnvt.h5')\nmodel_cnvt.layers[2].get_weights()","cb6bea17":"model_resnet = applications.resnet50.ResNet50(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=list(SH)+[3],\n    pooling='avg',\n    classes=None)","f212b7ab":"# model_resnet.summary()","2d46b5b7":"model_resnet.layers[2].get_weights()[0][0,0,0]","e0530700":"model_resnet.load_weights('..\/input\/resnet50-4x256-max-1\/model_1_resnet.h5')\nmodel_resnet.layers[2].get_weights()[0][0,0,0]","fcc1897d":"model_classifier = make_model_classifier(1024*2)\nmodel_classifier.summary()","59ac0dfa":"model_classifier.layers[1].get_weights()[0][0]","e274c207":"model_classifier.load_weights('..\/input\/resnet50-4x256-max-1\/model_1_classifier.h5')\nmodel_classifier.layers[1].get_weights()[0][0]","1107ea0f":"models = make_model(img_dim, model_cnvt, model_resnet, model_classifier)\nmodels['model0'].summary()","e8c9b0c0":"models['model'].summary()","42008d12":"THRESHOLD = 0.5\n\n# credits: https:\/\/www.kaggle.com\/guglielmocamporese\/macro-f1-score-keras\n\nK_epsilon = K.epsilon()\ndef f1(y_true, y_pred):\n    #y_pred = K.round(y_pred)\n    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K_epsilon)\n    r = tp \/ (tp + fn + K_epsilon)\n\n    f1 = 2*p*r \/ (p+r+K_epsilon)\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef f1_loss(y_true, y_pred):\n    \n    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K_epsilon)\n    r = tp \/ (tp + fn + K_epsilon)\n\n    f1 = 2*p*r \/ (p+r+K_epsilon)\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1-K.mean(f1)","8107d80b":"'''\nThanks Iafoss.\npretrained ResNet34 with RGBY\nhttps:\/\/www.kaggle.com\/iafoss\/pretrained-resnet34-with-rgby-0-460-public-lb\n'''\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","80c2d5bc":"class LearningRateReducer(Callback):\n\n    def __init__(self, schedule,\n                 cycle_epoch=2, steps_per_epoch=100,\n                 start_lr=0.001, end_lr=0.0001, verbose=0):\n        super(LearningRateReducer, self).__init__()\n        self.schedule = schedule\n        self.steps_per_epoch = steps_per_epoch\n        self.cycle_epoch = cycle_epoch\n        self.start_lr = start_lr\n        self.end_lr = end_lr\n        self.verbose = verbose\n\n    def on_train_begin(self, epoch, logs=None):\n        self.lrf = {'lr': [], 'loss': []}\n        self.epoch = None\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch = epoch\n    \n    def on_batch_begin(self, batch, logs=None):\n        #print(batch)\n        lr = self.schedule(self.epoch, batch,\n                           cycle_epoch=self.cycle_epoch,\n                           steps_per_epoch=self.steps_per_epoch,\n                           start_lr=self.start_lr, end_lr=self.end_lr)\n        K.set_value(self.model.optimizer.lr, lr)\n        self.lrf['lr'].append(lr)\n        return\n    \n    def on_batch_end(self, batch, logs={}):\n        loss = logs.get('loss')\n        self.lrf['loss'].append(loss)","247e7eb7":"def lr_schedule(epoch, batch,\n                cycle_epoch=2, steps_per_epoch=100,\n                start_lr=0.002, end_lr=0.0002):\n    by = (np.log(start_lr) - np.log(end_lr)) \/ (steps_per_epoch*cycle_epoch-1)\n    ii = divmod(epoch, cycle_epoch)[1]*steps_per_epoch + batch # use amari\n    lr = np.exp(np.log(start_lr) - ii * by)\n    #print('Learning rate: ', lr)\n    return lr","c1a36541":"LEARNING_RATE = 0.001\nprint(datetime.datetime.now() - now)","5e2af767":"models['model'].compile(loss='binary_crossentropy',\n                        optimizer='adam',\n                        metrics=['categorical_accuracy', 'binary_accuracy', f1])","fe8a8091":"seq = Seq(train_labels, extend=False, aug=True, batch_size=8)\nprint(len(seq))\n\nlr_scheduler = LearningRateReducer(lr_schedule,\n                                   cycle_epoch=1, steps_per_epoch=len(seq),\n                                   start_lr=LEARNING_RATE, end_lr=LEARNING_RATE\/10)\ncallbacks = [lr_scheduler]\n\nhst = models['model'].fit_generator(seq, epochs=1,\n                              steps_per_epoch=len(seq),\n                              callbacks=callbacks)","c946e10a":"plt.subplots(1, 1, figsize=(10,10))\nplt.plot(lr_scheduler.lrf['lr'], lr_scheduler.lrf[\"loss\"])\nplt.xscale('log')\nplt.title('learning rate')","da23b824":"seq = Seq(train_labels, extend=False, aug=False, batch_size=32)\nprint(len(seq))\nxs, ys = next(seq)\nprint(xs['input'].shape)\nxs['input'].reshape((32,4,-1)).shape\ny_pred = models['model_cnvt'].predict(xs['input'].reshape((32,4,-1))[0])\nprint(y_pred.shape)","4a474fa7":"y_pred[0]","15d4d00d":"tmp = np.vstack(\n    [\n        np.hstack([y_pred[0], y_pred[1]]),\n        np.hstack([y_pred[2], y_pred[3]])\n    ])\ntmp.shape","0554fe56":"show_arr(tmp)","052f3cb3":"Image.fromarray(np.uint8((tmp+1)\/2*255))","df53dde7":"seq_pred = Seq(train_labels, test=False, aug=False, batch_size=32)\nlen(seq_pred)","fe49b91e":"pred = models['model'].predict_generator(seq_pred, steps=len(seq_pred), verbose=1)\npred.shape","88e8b774":"def calc_threshold(pred):\n    ### calc threshold\n    threshold_dic = {}\n    for idx in tqdm(range(28)):\n        threshold_dic[idx] = 0.5\n        m = 0\n        for ii in range(100):\n            threshold0 = ii*0.01\n            f1_val = f1_score(y_cat_train_dic[idx], threshold0<(pred[:,idx]))\n            if m < f1_val:\n                threshold_dic[idx] = threshold0+0.005\n                m = f1_val\n    return threshold_dic","67ffd4ed":"import warnings\nwarnings.filterwarnings('ignore')\n\nthreshold_dic = calc_threshold(pred)\nthreshold_dic","4f96fda3":"'''use threshold_dic'''\nfor ii in range(28):\n    print(ii, f1_score(y_cat_train_dic[ii], threshold_dic[ii]<pred[:,ii]))","9b5ddeb2":"'''threshold = 0.5'''\nfor ii in range(28):\n    print(ii, f1_score(y_cat_train_dic[ii], 0.5<pred[:,ii]))","d5b59ff6":"seq_test = Seq(test_labels, test=True, aug=False, batch_size=32)\nseq_test","b18b9ccd":"pred_test = models['model'].predict_generator(seq_test, steps=len(seq_test), verbose=1)\npred_test.shape","f4b0a1ce":"def make_test(pred):\n    test_labels1 = test_labels.copy()\n    test_labels1['Predicted'] = [str(ee) for ee in np.argmax(pred, axis=1)]\n    print(test_labels1.head())\n    #test_labels1.to_csv(fn0, index=False)\n    \n    test_labels2 = test_labels1.copy()\n    for ii in range(test_labels2.shape[0]):\n        threshold = list(zip(*sorted(list(threshold_dic.items()), key=lambda x:x[0], reverse=False)))[1]\n        idx = threshold < pred[ii,:]\n        tgt = test_labels2['Predicted'][ii]\n        tgt = [tgt] + [str(ee) for ee in np.arange(28)[idx]]\n        tgt = set(tgt)\n        tgt = ' '.join(tgt)\n        test_labels2['Predicted'][ii] = tgt\n    print(test_labels2.head())\n    #test_labels2.to_csv(fn, index=False)\n    return test_labels1, test_labels2","8818228f":"test_labels1_1, test_labels1_2 = make_test(pred_test)","15c41214":"test_labels1_2.head()","8fd89920":"test_labels1_2.to_csv('InceptionResNetV1_2.csv', index=False)","76311cfd":"'''save weights for later loading'''\nNo = 1\nmodels['model_cnvt'].save_weights('model_{}_cnvt.h5'.format(No))\nmodels['model_resnet'].save_weights('model_{}_resnet.h5'.format(No))\nmodels['model_classifier'].save_weights('model_{}_classifier.h5'.format(No))","8b5bfd30":"df_pred1 = pd.DataFrame(pred)\ndf_pred1.columns = ['cls'+ str(ii) for ii in range(28)]\ndf_pred1 = pd.concat([train_labels.copy(), df_pred1], axis=1)\n\ndf_pred1.head()\ndf_pred1.to_csv('proba_{}.csv'.format(No), index=False)","203935c1":"df_pred1_test = pd.DataFrame(pred_test)\ndf_pred1_test.columns = ['cls'+ str(ii) for ii in range(28)]\ndf_pred1_test = pd.concat([test_labels.copy(), df_pred1_test], axis=1)\n\ndf_pred1_test.head()\ndf_pred1_test.to_csv('proba_test_{}.csv'.format(No), index=False)","706d1d97":"print(datetime.datetime.now() - now)","4a441d79":"* Please refer to the comments for the overview.","f3fe662e":"## save weights for later loading","5fb9ef22":"### make model","61198044":"## #1","27632560":"### predict and submit"}}