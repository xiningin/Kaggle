{"cell_type":{"38ff2f58":"code","a077994b":"code","2a0e101c":"code","371fec2e":"code","0e9c80a3":"code","b0daef37":"code","43790060":"code","154e5248":"code","6979c05c":"code","a09698ec":"code","51438587":"code","7503f41b":"code","792de403":"code","55be65c1":"code","a5053ac3":"code","d9db77a1":"code","3432fb04":"code","eab6ccec":"code","a4aa7e35":"code","f131a784":"code","81e1e282":"code","603de026":"code","a60bf2d6":"code","4ba62356":"markdown","4432b947":"markdown","a0b8c2d4":"markdown","5771d5c4":"markdown","7de5627d":"markdown","37770ceb":"markdown","8213209c":"markdown","ab2e14a3":"markdown","9533cc71":"markdown","488fbd47":"markdown","1fe6f5c0":"markdown"},"source":{"38ff2f58":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport missingno\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV","a077994b":"train = pd.read_csv(\"\/kaggle\/input\/iba-ml2-mid-project\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/iba-ml2-mid-project\/test.csv\")","2a0e101c":"train.head()","371fec2e":"train.shape","0e9c80a3":"train.columns","b0daef37":"test.describe()","43790060":"train.dtypes","154e5248":"train.credit_line_utilization = train.credit_line_utilization.apply(lambda x: str(x).strip().replace(\",\",\".\")).astype(float)\ntest.credit_line_utilization = test.credit_line_utilization.apply(lambda x: str(x).strip().replace(\",\",\".\")).astype(float)\ntrain.dtypes","6979c05c":"train.isnull().sum()","a09698ec":"missingno.matrix(train)","51438587":"test.isnull().sum()","7503f41b":"fig, ax = plt.subplots()\ncorrelation = train.corr()\nsns.heatmap(data = correlation, annot = False)\nplt.show()\n# As it seems, there are not strong correlations betwween the features except of number_of_credit_lines and reapl_estate_loans","792de403":"fig, ax = plt.subplots(figsize = (15,10))\nsns.countplot(x = train.age, ax = ax)\ntrain.age = train.age.apply(lambda x: float(x))\nages = [int(i) for i in train.age.value_counts().index.tolist()]\nax.set_xticklabels(sorted(ages), rotation = 80)\nplt.show()","55be65c1":"train.describe()","a5053ac3":"fig, ax = plt.subplots()\nsns.boxplot(x = train.number_dependent_family_members, ax = ax)\nplt.show()\n#Since there are some outliers in this feauture, i am going to treat them with replacing median value","d9db77a1":"train.loc[train.number_dependent_family_members > 4, \"number_dependent_family_members\"] = train.number_dependent_family_members.median()","3432fb04":"fig, ax = plt.subplots()\nsns.violinplot(x = train.monthly_income, ax = ax)\nplt.show()","eab6ccec":"#removing the incomes higher than 1000000 which is not convincing from datasets.\ntrain.drop(train.loc[train.monthly_income > 1000000].index.tolist(), axis = 0, inplace = True)\n","a4aa7e35":"# In this column, 3rd quartile is about 0.4. But we have some values which are quite bigger than this number. we are gonna drop them.\ntrain.drop(train.loc[train.ratio_debt_payment_to_income > 120].index.tolist(), axis = 0, inplace = True)","f131a784":"#changing value for outliers\ntrain.loc[train.credit_line_utilization > 2, \"credit_line_utilization\"] = train.credit_line_utilization.median()","81e1e282":"train.drop(train.loc[train.number_of_previous_late_payments_up_to_59_days > 20].index.tolist(), axis = 0, inplace = True)\n","603de026":"train.drop(train.loc[train.number_of_previous_late_payments_up_to_89_days > 20].index.tolist(), axis = 0, inplace = True)","a60bf2d6":"train.drop(train.loc[train.number_of_previous_late_payments_90_days_or_more > 20].index.tolist(), axis = 0, inplace = True)","4ba62356":"**Reading csv files**","4432b947":" ****Changing the data types of column called credit_line_utilization to float after some corrections**** ","a0b8c2d4":"### Dropping outliers from columns shown below","5771d5c4":"**Checking missing values**","7de5627d":"**Importing necessary libraries**","37770ceb":"**Recognizing the data**","8213209c":"# Visualizations for better understanding and interpretation","ab2e14a3":"*I won't treat the outliers for number_dependent_family_member column in test data, because I do not think it is typo or error. If I think for others as typo, I will.*","9533cc71":"**Insights into Correlation between features**","488fbd47":"**Better description of missing values**","1fe6f5c0":"# Outlier treatment"}}