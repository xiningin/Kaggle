{"cell_type":{"a551a8c6":"code","0e700a0f":"code","e6bb78f8":"code","b476878c":"code","b105161f":"code","5bc5cbf7":"code","1e93c83e":"code","ec3ec8fb":"code","5a60444b":"code","2bad1cd0":"code","3830ac30":"code","3f13679e":"code","b5957b4c":"code","6230fb77":"code","7949d3fb":"code","382741fb":"code","290cd668":"code","73dcf3bf":"code","259fb5cb":"code","58b0d9ef":"code","fa0ee8cb":"code","e2888b99":"markdown"},"source":{"a551a8c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # Matlab-style plotting\nimport seaborn as sns #plotting package\nimport re\n\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew \nfrom scipy.special import boxcox1p #for Box Cox transformation\nfrom sklearn.preprocessing import LabelEncoder\n\n#Regressors\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#Pipeline related\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.feature_selection import SelectFromModel\n\n#Base classes to be inherited\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n\n#Cross Validation related\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n#Model Tuning related\nfrom sklearn.model_selection import GridSearchCV, ParameterGrid, RandomizedSearchCV\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\npd.options.display.max_rows = 80\n\nfrom subprocess import check_output\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nsns.set()\n\ntrain.drop(\"PassengerId\", axis = 1, inplace = True)\ntrain.drop(\"Name\", axis = 1, inplace = True)\ntrain.drop(\"Ticket\", axis = 1, inplace = True)\n#train.drop(\"Cabin\", axis = 1, inplace = True)\n\ntest_id = test['PassengerId']\ntest.drop(\"PassengerId\", axis = 1, inplace = True)\ntest.drop(\"Name\", axis = 1, inplace = True)\ntest.drop(\"Ticket\", axis = 1, inplace = True)\n#test.drop(\"Cabin\", axis = 1, inplace = True)\n# Any results you write to the current directory are saved as output.","0e700a0f":"def plot_dist_norm(dist, title):\n    sns.distplot(dist, fit=norm);\n    (mu, sigma) = norm.fit(dist);\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n    plt.ylabel('Frequency')\n    plt.title(title)\n    fig = plt.figure()\n    res = stats.probplot(dist, plot=plt)\n    plt.show()","e6bb78f8":"train.dtypes","b476878c":"train.head()","b105161f":"decks = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n\ntrain['Cabin'] = train['Cabin'].fillna(\"U0\")\n\ntrain['Deck'] = train['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group()).map(decks)\n\ntrain['Deck'] = train['Deck'].fillna(0)\ntrain['Deck'] = train['Deck'].astype(int)\ntrain.drop(\"Cabin\", axis = 1, inplace = True)","5bc5cbf7":"#train['Pclass'].value_counts().plot.bar()\nx_axis_a = train['Survived'].sort_values().unique()\ny_axis_a = train['Pclass'].sort_values().unique()\n\ny_axis_b = train['Survived'].sort_values().unique()\nx_axis_b = train['Pclass'].sort_values().unique()\n\ny_axis_0_0 = train[(train['Pclass']==y_axis_a[0])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_1_0 = train[(train['Pclass']==y_axis_a[1])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_2_0 = train[(train['Pclass']==y_axis_a[2])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_0_1 = train[(train['Pclass']==y_axis_a[0])&(train['Survived']==x_axis_a[1])]['Survived'].count()\ny_axis_1_1 = train[(train['Pclass']==y_axis_a[1])&(train['Survived']==x_axis_a[1])]['Survived'].count()\ny_axis_2_1 = train[(train['Pclass']==y_axis_a[2])&(train['Survived']==x_axis_a[1])]['Survived'].count()\n\ntotal_0a = y_axis_0_0+y_axis_1_0+y_axis_2_0\ntotal_1a = y_axis_0_1+y_axis_1_1+y_axis_2_1\n\ntotal_0b = y_axis_0_0+y_axis_0_1\ntotal_1b = y_axis_1_0+y_axis_1_1\ntotal_2b = y_axis_2_0+y_axis_2_1\n\ny_axis_0a = (y_axis_0_0\/total_0a,y_axis_0_1\/total_1a)\ny_axis_1a = (y_axis_1_0\/total_0a,y_axis_1_1\/total_1a)\ny_axis_2a = (y_axis_2_0\/total_0a,y_axis_2_1\/total_1a)\ny_axis_01a = ((y_axis_0_0+y_axis_1_0)\/total_0a,(y_axis_0_1+y_axis_1_1)\/total_1a)\n\ny_axis_0b = (y_axis_0_0\/total_0b,y_axis_1_0\/total_1b,y_axis_2_0\/total_2b)\ny_axis_1b = (y_axis_0_1\/total_0b,y_axis_1_1\/total_1b,y_axis_2_1\/total_2b)\n\nplot_1a = plt.bar(x_axis_a,y_axis_0a)\nplot_2a = plt.bar(x_axis_a,y_axis_1a,bottom=y_axis_0a)\nplot_3a = plt.bar(x_axis_a,y_axis_2a,bottom=y_axis_01a)\nplt.title('Pclasses')\nplt.xlabel('Survived')\nplt.xticks(x_axis_a,x_axis_a)\nplt.legend((plot_1a[0],plot_2a[0],plot_3a[0]),y_axis_a)\nplt.show()\n\nplot_1b = plt.bar(x_axis_b,y_axis_0b)\nplot_2b = plt.bar(x_axis_b,y_axis_1b,bottom=y_axis_0b)\nplt.title('Survived')\nplt.xlabel('Pclass')\nplt.xticks(x_axis_b,x_axis_b)\nplt.legend((plot_1b[0],plot_2b[0]),y_axis_b)\nplt.show()","1e93c83e":"x_axis_a = train['Survived'].sort_values().unique()\ny_axis_a = train['Sex'].sort_values().unique()\n\ny_axis_b = train['Survived'].sort_values().unique()\nx_axis_b = train['Sex'].sort_values().unique()\n\ny_axis_0_0 = train[(train['Sex']==y_axis_a[0])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_1_0 = train[(train['Sex']==y_axis_a[1])&(train['Survived']==x_axis_a[0])]['Survived'].count()\n\ny_axis_0_1 = train[(train['Sex']==y_axis_a[0])&(train['Survived']==x_axis_a[1])]['Survived'].count()\ny_axis_1_1 = train[(train['Sex']==y_axis_a[1])&(train['Survived']==x_axis_a[1])]['Survived'].count()\n\ntotal_0a = y_axis_0_0+y_axis_1_0\ntotal_1a = y_axis_0_1+y_axis_1_1\n\ntotal_0b = y_axis_0_0+y_axis_0_1\ntotal_1b = y_axis_1_0+y_axis_1_1\n\n\ny_axis_0a = (y_axis_0_0\/total_0a,y_axis_0_1\/total_1a)\ny_axis_1a = (y_axis_1_0\/total_0a,y_axis_1_1\/total_1a)\n\ny_axis_0b = (y_axis_0_0\/total_0b,y_axis_1_0\/total_1b)\ny_axis_1b = (y_axis_0_1\/total_0b,y_axis_1_1\/total_1b)\n\nplot_1a = plt.bar(x_axis_a,y_axis_0a)\nplot_2a = plt.bar(x_axis_a,y_axis_1a,bottom=y_axis_0a)\n\nplt.title('Sex')\nplt.xlabel('Survived')\nplt.xticks(x_axis_a,x_axis_a)\nplt.legend((plot_1a[0],plot_2a[0]),y_axis_a)\nplt.show()\n\nplot_1b = plt.bar(x_axis_b,y_axis_0b)\nplot_2b = plt.bar(x_axis_b,y_axis_1b,bottom=y_axis_0b)\nplt.title('Survived')\nplt.xlabel('Sex')\nplt.xticks(x_axis_b,x_axis_b)\nplt.legend((plot_1b[0],plot_2b[0]),y_axis_b)\nplt.show()","ec3ec8fb":"train['Age']=train['Age'].fillna(train['Age'].mean())\nplot_dist_norm(train['Age'],'Age')","5a60444b":"train['SibSp'].value_counts().sort_index().plot.bar()","2bad1cd0":"train['Parch'].value_counts().sort_index().plot.bar()","3830ac30":"train['Fare'].replace(0,train[train['Fare']>0]['Fare'].mode()[0],inplace=True)\nplot_dist_norm(np.log(train['Fare']),'Fare')","3f13679e":"train['Embarked']=train['Embarked'].fillna(train['Embarked'].mode()[0])","b5957b4c":"x_axis_a = train['Survived'].sort_values().unique()\ny_axis_a = train['Embarked'].sort_values().unique()\n\ny_axis_b = train['Survived'].sort_values().unique()\nx_axis_b = train['Embarked'].sort_values().unique()\n\ny_axis_0_0 = train[(train['Embarked']==y_axis_a[0])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_1_0 = train[(train['Embarked']==y_axis_a[1])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_2_0 = train[(train['Embarked']==y_axis_a[2])&(train['Survived']==x_axis_a[0])]['Survived'].count()\ny_axis_0_1 = train[(train['Embarked']==y_axis_a[0])&(train['Survived']==x_axis_a[1])]['Survived'].count()\ny_axis_1_1 = train[(train['Embarked']==y_axis_a[1])&(train['Survived']==x_axis_a[1])]['Survived'].count()\ny_axis_2_1 = train[(train['Embarked']==y_axis_a[2])&(train['Survived']==x_axis_a[1])]['Survived'].count()\n\ntotal_0a = y_axis_0_0+y_axis_1_0+y_axis_2_0\ntotal_1a = y_axis_0_1+y_axis_1_1+y_axis_2_1\n\ntotal_0b = y_axis_0_0+y_axis_0_1\ntotal_1b = y_axis_1_0+y_axis_1_1\ntotal_2b = y_axis_2_0+y_axis_2_1\n\ny_axis_0a = (y_axis_0_0\/total_0a,y_axis_0_1\/total_1a)\ny_axis_1a = (y_axis_1_0\/total_0a,y_axis_1_1\/total_1a)\ny_axis_2a = (y_axis_2_0\/total_0a,y_axis_2_1\/total_1a)\ny_axis_01a = ((y_axis_0_0+y_axis_1_0)\/total_0a,(y_axis_0_1+y_axis_1_1)\/total_1a)\n\ny_axis_0b = (y_axis_0_0\/total_0b,y_axis_1_0\/total_1b,y_axis_2_0\/total_2b)\ny_axis_1b = (y_axis_0_1\/total_0b,y_axis_1_1\/total_1b,y_axis_2_1\/total_2b)\n\nplot_1a = plt.bar(x_axis_a,y_axis_0a)\nplot_2a = plt.bar(x_axis_a,y_axis_1a,bottom=y_axis_0a)\nplot_3a = plt.bar(x_axis_a,y_axis_2a,bottom=y_axis_01a)\nplt.title('Embarked')\nplt.xlabel('Survived')\nplt.xticks(x_axis_a,x_axis_a)\nplt.legend((plot_1a[0],plot_2a[0],plot_3a[0]),y_axis_a)\nplt.show()\n\nplot_1b = plt.bar(x_axis_b,y_axis_0b)\nplot_2b = plt.bar(x_axis_b,y_axis_1b,bottom=y_axis_0b)\nplt.title('Survived')\nplt.xlabel('Embarked')\nplt.xticks(x_axis_b,x_axis_b)\nplt.legend((plot_1b[0],plot_2b[0]),y_axis_b)\nplt.show()","6230fb77":"train['Family']=train['SibSp']+train['Parch']\n\n#plt.bar(train['Family'].sort_values().unique(), train.groupby(['Family'])['Survived'].sum()\/train.groupby(['Family'])['Survived'].count())\n#plt.show()\n\ntrain.drop(\"SibSp\", axis = 1, inplace = True)\ntrain.drop(\"Parch\", axis = 1, inplace = True)","7949d3fb":"new_train = train\n\nnew_train['Fare'] = np.log(new_train['Fare'])\n#new_train.Embarked = new_train.Embarked.astype('category', ordered=True, categories=['C','Q','S']).cat.codes\nnew_train=pd.get_dummies(new_train)\nnew_train.drop(\"Sex_male\", axis = 1, inplace = True)","382741fb":"corrmat = new_train.corr()\nfeatures = corrmat.nlargest(12,'Survived')['Survived'].index\nsns.set(font_scale=1.2)\nplt.subplots(figsize=(12,9))\nrelevant_features = features\nsns.heatmap(new_train[relevant_features].corr(), cbar=True, annot=True, fmt='.2f', annot_kws={'size':10}, yticklabels=relevant_features.values, xticklabels=relevant_features.values, vmax=1, square=True, cmap='Blues')","290cd668":"test['Fare'].replace(0,test[test['Fare']>0]['Fare'].mode()[0],inplace=True)\ntest['Embarked']=test['Embarked'].fillna(test['Embarked'].mode()[0])\ntest['Age']=test['Age'].fillna(test['Age'].mean())\ntest['Family']=test['SibSp']+test['Parch']\ntest.drop(\"SibSp\", axis = 1, inplace = True)\ntest.drop(\"Parch\", axis = 1, inplace = True)\ntest['Fare'].fillna(test['Fare'].mode()[0],inplace=True)\n\ndecks = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n\ntest['Cabin'] = test['Cabin'].fillna(\"U0\")\n\ntest['Deck'] = test['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group()).map(decks)\n\ntest['Deck'] = test['Deck'].fillna(0)\ntest['Deck'] = test['Deck'].astype(int)\ntest.drop(\"Cabin\", axis = 1, inplace = True)\n\nnew_test = test\n\nnew_test['Fare'] = np.log(new_test['Fare'])\n#new_test.Embarked = new_test.Embarked.astype('category', ordered=True, categories=['C','Q','S']).cat.codes\n\nnew_test=pd.get_dummies(new_test)\nnew_test.drop(\"Sex_male\", axis = 1, inplace = True)","73dcf3bf":"nfold=5\ny_train = new_train.Survived.values\nnew_train.drop('Survived', axis=1, inplace=True)\n\ndef cv_score(model):\n    kf = KFold(nfold, shuffle=True, random_state=42).get_n_splits(new_train.values)\n    return cross_val_score(model, new_train.values, y_train, scoring=\"balanced_accuracy\", cv = kf)\n","259fb5cb":"flag=True\nif flag:\n    steps = [('scaler',RobustScaler()),('select',SelectFromModel(SVC(C=1,kernel='linear') )),\n            ('randomforest',RandomForestClassifier(n_estimators=100,criterion='gini',bootstrap=True  ) )]\n    randomforest_p = Pipeline(steps)\n    n_estimatorss=[100,200,400,800]\n    criteria=['gini','entropy']\n    bootstraps=[True,False]\n    gscv = GridSearchCV(randomforest_p, cv=nfold, param_grid={'randomforest__n_estimators': n_estimatorss, 'randomforest__criterion': criteria, 'randomforest__bootstrap': bootstraps}, n_jobs=-1, verbose=1,scoring='balanced_accuracy')\n    gscv.fit(new_train.values, y_train)\n    randomforest_ = gscv.best_estimator_.named_steps.randomforest\n    randomforest = gscv.best_estimator_\n    score = cv_score(randomforest_)\n    print(\"\\nRandomForest score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n    print('Best RandomForest: ',randomforest_)\n","58b0d9ef":"randomforest.fit(new_train.values,y_train)\nrandomforest_pred = randomforest.predict(new_test.values)\nprediction = randomforest_pred","fa0ee8cb":"sub = pd.DataFrame()\nsub['PassengerId'] = test_id\nsub['Survived'] = prediction\nsub.to_csv('submission.csv',index=False)","e2888b99":"Training begins here"}}