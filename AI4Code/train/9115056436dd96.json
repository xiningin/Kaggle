{"cell_type":{"c16a2dfd":"code","319dc3ad":"code","1d4e4d05":"code","49669433":"code","62b4548b":"code","3d7470cc":"code","7c8b0899":"code","a45d066a":"code","828c86dc":"code","73d82e5e":"code","bb3aa0d1":"code","ed873d3d":"code","3bafa09c":"code","617aeb1b":"code","44c1b310":"code","fc796697":"code","b161be74":"code","f8d5b16d":"code","62643179":"code","d3d24fcd":"code","01e9d0cd":"code","e22c8f85":"code","e1cc7922":"code","315321ed":"code","c981b379":"code","344bfa48":"code","ece68641":"code","9f6d232e":"code","ddd516dc":"code","46376726":"markdown","561940bf":"markdown","ef6cb295":"markdown","1db8a6bf":"markdown","3ab8aa42":"markdown","66548096":"markdown","c408148b":"markdown","856672aa":"markdown","825d7e76":"markdown","6e015218":"markdown","074a48f7":"markdown"},"source":{"c16a2dfd":"import os\nimport requests\nimport json","319dc3ad":"def read_squad(path):\n    with open(path, 'rb') as f:\n        squad_dict = json.load(f)\n\n    # initialize lists for contexts, questions, and answers\n    contexts = []\n    questions = []\n    answers = []\n    # iterate through all data in squad data\n    for group in squad_dict['data']:\n        for passage in group['paragraphs']:\n            context = passage['context']\n            for qa in passage['qas']:\n                question = qa['question']\n                if 'plausible_answers' in qa.keys():\n                    access = 'plausible_answers'\n                else:\n                    access = 'answers'\n                for answer in qa['answers']:\n                    # append data to lists\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append(answer)\n    # return formatted data lists\n    return contexts, questions, answers","1d4e4d05":"train_contexts, train_questions, train_answers = read_squad('..\/input\/stanford-question-answering-dataset\/train-v1.1.json')\nval_contexts, val_questions, val_answers = read_squad('..\/input\/stanford-question-answering-dataset\/dev-v1.1.json')","49669433":"def add_end_idx(answers, contexts):\n    # loop through each answer-context pair\n    for answer, context in zip(answers, contexts):\n        # gold_text refers to the answer we are expecting to find in context\n        gold_text = answer['text']\n        # we already know the start index\n        start_idx = answer['answer_start']\n        # and ideally this would be the end index...\n        end_idx = start_idx + len(gold_text)\n\n        # ...however, sometimes squad answers are off by a character or two\n        if context[start_idx:end_idx] == gold_text:\n            # if the answer is not off :)\n            answer['answer_end'] = end_idx\n        else:\n            for n in [1, 2]:\n                if context[start_idx-n:end_idx-n] == gold_text:\n                    # this means the answer is off by 'n' tokens\n                    answer['answer_start'] = start_idx - n\n                    answer['answer_end'] = end_idx - n","62b4548b":"add_end_idx(train_answers, train_contexts)\nadd_end_idx(val_answers, val_contexts)","3d7470cc":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n\ntrain_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\nval_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)","7c8b0899":"def add_token_positions(encodings, answers):\n    # initialize lists to contain the token indices of answer start\/end\n    start_positions = []\n    end_positions = []\n    for i in range(len(answers)):\n        # append start\/end token position using char_to_token method\n        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length\n        # end position cannot be found, char_to_token found space, so shift one token forward\n        go_back = 1\n        while end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n            go_back +=1\n    # update our encodings object with the new token-based start\/end positions\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n\n# apply function to our data\nadd_token_positions(train_encodings, train_answers)\nadd_token_positions(val_encodings, val_answers)","a45d066a":"import torch\n\nclass SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\ntrain_dataset = SquadDataset(train_encodings)\nval_dataset = SquadDataset(val_encodings)","828c86dc":"from transformers import DistilBertForQuestionAnswering\nmodel = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")","73d82e5e":"from torch.utils.data import DataLoader\nfrom transformers import AdamW\nfrom tqdm import tqdm\n\n# setup GPU\/CPU\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# move model over to detected device\nmodel.to(device)\n# activate training mode of model\nmodel.train()\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\noptim = AdamW(model.parameters(), lr=5e-5)\n\n# initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nfor epoch in range(3):\n    # set model to train mode\n    model.train()\n    # setup loop (we use tqdm for the progress bar)\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        # train model on batch and return outputs (incl. loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optim.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())","bb3aa0d1":"p=5","ed873d3d":"model_path = 'models\/distilbert-custom'\nmodel.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)","3bafa09c":"# switch model out of training mode\nmodel.eval()\n\n#val_sampler = SequentialSampler(val_dataset)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\nacc = []\n\n# initialize loop for progress bar\nloop = tqdm(val_loader)\n# loop through batches\nfor batch in loop:\n    # we don't need to calculate gradients as we're not training\n    with torch.no_grad():\n        # pull batched items from loader\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_true = batch['start_positions'].to(device)\n        end_true = batch['end_positions'].to(device)\n        # make predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        # pull preds out\n        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n        # calculate accuracy for both and append to accuracy list\n        acc.append(((start_pred == start_true).sum()\/len(start_pred)).item())\n        acc.append(((end_pred == end_true).sum()\/len(end_pred)).item())\n# calculate average accuracy in total\nacc = sum(acc)\/len(acc)","617aeb1b":"from transformers import DistilBertForQuestionAnswering\nmodel = DistilBertForQuestionAnswering.from_pretrained('..\/input\/bertmodel\/')\n#Tokenizer\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained('..\/input\/bertmodel\/')","44c1b310":"question = \"Who ruled Macedonia\"\n\ncontext = \"\"\"Macedonia was an ancient kingdom on the periphery of Archaic and Classical Greece, \nand later the dominant state of Hellenistic Greece. The kingdom was founded and initially ruled \nby the Argead dynasty, followed by the Antipatrid and Antigonid dynasties. Home to the ancient \nMacedonians, it originated on the northeastern part of the Greek peninsula. Before the 4th \ncentury BC, it was a small kingdom outside of the area dominated by the city-states of Athens, \nSparta and Thebes, and briefly subordinate to Achaemenid Persia.\"\"\"","fc796697":"inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\") \n\n# 2. OBTAIN MODEL SCORES\n# the AutoModelForQuestionAnswering class includes a span predictor on top of the model. \n# the model returns answer start and end scores for each word in the text\nanswer_start_scores, answer_end_scores = model(**inputs)\nanswer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\nanswer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n\n# 3. GET THE ANSWER SPAN\n# once we have the most likely start and end tokens, we grab all the tokens between them\n# and convert tokens back to words!\ntokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))","b161be74":"answer_text=\"\"\"India (Hindi: Bh\u0101rat), officially the Republic of India (Hindi: Bh\u0101rat Ga\u1e47ar\u0101jya),[23] is a country in South Asia. It is the second-most populous country, the seventh-largest country by land area, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.\"\"\"\n\nquestion = \"What is official name of India?\"\nimport torch\nfrom transformers import BertForQuestionAnswering\n\n\n\n\n#tokenize\n\nencoded_dict = tokenizer.encode_plus(text=question,text_pair=answer_text, add_special=True)\n    \n    \n# Apply the tokenizer to the input text, treating them as a text-pair.\ninput_ids = encoded_dict['input_ids']\n\n# Report how long the input sequence is.\nprint('Query has {:,} tokens.\\n'.format(len(input_ids)))\n\n# Segment Ids\nsegment_ids = encoded_dict['token_type_ids']\n\n# evaluate\noutput = model(torch.tensor([input_ids]))\n\n# Find the tokens with the highest `start` and `end` scores.\nanswer_start = torch.argmax(output['start_logits'])\nanswer_end = torch.argmax(output['end_logits'])\n\n# Get the string versions of the input tokens.\ntokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n# Start with the first token.\nanswer = tokens[answer_start]\n\n# Select the remaining answer tokens and join them with whitespace.\nfor i in range(answer_start + 1, answer_end + 1):\n\n    # If it's a subword token, then recombine it with the previous token.\n    if tokens[i][0:2] == '##':\n        answer += tokens[i][2:]\n\n    # Otherwise, add a space then the token.\n    else:\n        answer += ' ' + tokens[i]","f8d5b16d":"def BertQnA(answer_text,question):\n    \n    \n    #tokenize\n\n    encoded_dict = tokenizer.encode_plus(text=question,text_pair=answer_text, add_special=True)\n\n\n    # Apply the tokenizer to the input text, treating them as a text-pair.\n    input_ids = encoded_dict['input_ids']\n\n    # Report how long the input sequence is.\n    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n\n    # Segment Ids\n    segment_ids = encoded_dict['token_type_ids']\n\n    # evaluate\n    output = model(torch.tensor([input_ids]))\n\n    # Find the tokens with the highest `start` and `end` scores.\n    answer_start = torch.argmax(output['start_logits'])\n    answer_end = torch.argmax(output['end_logits'])\n\n    # Get the string versions of the input tokens.\n    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n    # Start with the first token.\n    answer = tokens[answer_start]\n\n    # Select the remaining answer tokens and join them with whitespace.\n    for i in range(answer_start + 1, answer_end + 1):\n\n        # If it's a subword token, then recombine it with the previous token.\n        if tokens[i][0:2] == '##':\n            answer += tokens[i][2:]\n\n        # Otherwise, add a space then the token.\n        else:\n            answer += ' ' + tokens[i]\n            \n    return answer","62643179":"text=\"\"\"Roger Federer (German pronunciation: [\u02c8r\u0254d\u0292\u0259r \u02c8fe\u02d0d\u0259r\u0259r]; born 8 August 1981) is a Swiss professional tennis player. He is ranked No. 5 in the world by the Association of Tennis Professionals (ATP). He has won 20 Grand Slam men's singles titles, an all-time record shared with Rafael Nadal. Federer has been No. 1 in the ATP rankings a record total of 310 weeks \u2013 including a record 237 consecutive weeks \u2013 and has finished as the year-end No. 1 five times. Federer has won 103 ATP singles titles, the second-most all-time behind Jimmy Connors and including a record six ATP Finals.\n\nFederer has played in an era where he dominated men's tennis together with Nadal and Novak Djokovic, who have been collectively referred to as the Big Three in reference to their place as three of the greatest male tennis players of all-time.[c] A Wimbledon junior champion in 1998, Federer won his first Grand Slam singles title at Wimbledon in 2003 at age 21. In 2004, he established himself as the best player in men's tennis by winning three out of four major singles titles and the ATP Finals,[d] a feat he repeated in both 2006 and 2007. Over a stretch from 2005 to 2010, Federer made 18 out of 19 major singles finals. During this span, he won his fifth consecutive titles at both Wimbledon and the US Open. He completed the career Grand Slam at the 2009 French Open after three previous runner-ups to Nadal, his main rival up until 2010. At age 27, he also surpassed Pete Sampras's then-record of 14 Grand Slam men's singles titles at Wimbledon in 2009.\n\nFederer and Stan Wawrinka led the Switzerland Davis Cup team to their first title in 2014, adding to the gold medal they won together in doubles at the 2008 Beijing Olympics. Federer also has a silver medal in singles from the 2012 London Olympics, where he finished runner-up to Andy Murray. After taking half a year off in late 2016 to recover from back surgery, Federer had a renaissance at the majors. He won three more Grand Slam singles titles over the next two years, including the 2017 Australian Open over Nadal and a men's singles record eighth Wimbledon title in 2017 later that year. He also became the oldest ATP world No. 1 in 2018 at age 36.\"\"\"\nquestion = \"what is federers world rank\"\nBertQnA(text,question)","d3d24fcd":"print('Answer: \"' + answer + '\"')","01e9d0cd":"# Apply the tokenizer to the input text, treating them as a text-pair.\ninput_ids = tokenizer.encode(question, answer_text)\n\nprint('The input has a total of {:} tokens.'.format(len(input_ids)))","e22c8f85":"# BERT only needs the token IDs, but for the purpose of inspecting the \n# tokenizer's behavior, let's also get the token strings and display them.\ntokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n# For each token and its id...\nfor token, id in zip(tokens, input_ids):\n    \n    # If this is the [SEP] token, add some space around it to make it stand out.\n    if id == tokenizer.sep_token_id:\n        print('')\n    \n    # Print the token string and its ID in two columns.\n    print('{:<12} {:>6,}'.format(token, id))\n\n    if id == tokenizer.sep_token_id:\n        print('')","e1cc7922":"# Search the input_ids for the first instance of the `[SEP]` token.\nsep_index = input_ids.index(tokenizer.sep_token_id)\n\n# The number of segment A tokens includes the [SEP] token istelf.\nnum_seg_a = sep_index + 1\n\n# The remainder are segment B.\nnum_seg_b = len(input_ids) - num_seg_a\n\n# Construct the list of 0s and 1s.\nsegment_ids = [0]*num_seg_a + [1]*num_seg_b\n\n# There should be a segment_id for every input token.\nassert len(segment_ids) == len(input_ids)","315321ed":"# Run our example through the model.\nstart_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n                                 token_type_id=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\nstart_index = torch.argmax(start_scores)\n\nend_index = torch.argmax(end_scores)","c981b379":"def answer_question(question, answer_text):\n    '''\n    Takes a `question` string and an `answer_text` string (which contains the\n    answer), and identifies the words within the `answer_text` that are the\n    answer. Prints them out.\n    '''\n    # ======== Tokenize ========\n    # Apply the tokenizer to the input text, treating them as a text-pair.\n    input_ids = tokenizer.encode(question, answer_text)\n\n    # Report how long the input sequence is.\n    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n\n    # ======== Set Segment IDs ========\n    # Search the input_ids for the first instance of the `[SEP]` token.\n    sep_index = input_ids.index(tokenizer.sep_token_id)\n\n    # The number of segment A tokens includes the [SEP] token istelf.\n    num_seg_a = sep_index + 1\n\n    # The remainder are segment B.\n    num_seg_b = len(input_ids) - num_seg_a\n\n    # Construct the list of 0s and 1s.\n    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n\n    # There should be a segment_id for every input token.\n    assert len(segment_ids) == len(input_ids)\n\n    # ======== Evaluate ========\n    # Run our example question through the model.\n    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n\n    # ======== Reconstruct Answer ========\n    # Find the tokens with the highest `start` and `end` scores.\n    answer_start = torch.argmax(start_scores)\n    answer_end = torch.argmax(end_scores)\n\n    # Get the string versions of the input tokens.\n    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n    # Start with the first token.\n    answer = tokens[answer_start]\n\n    # Select the remaining answer tokens and join them with whitespace.\n    for i in range(answer_start + 1, answer_end + 1):\n        \n        # If it's a subword token, then recombine it with the previous token.\n        if tokens[i][0:2] == '##':\n            answer += tokens[i][2:]\n        \n        # Otherwise, add a space then the token.\n        else:\n            answer += ' ' + tokens[i]\n\n    print('Answer: \"' + answer + '\"')","344bfa48":"import textwrap\n\n# Wrap text to 80 characters.\nwrapper = textwrap.TextWrapper(width=80) \n\nbert_abstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n\nprint(wrapper.fill(bert_abstract))","ece68641":"import torch","9f6d232e":"question = \"What does the 'B' in BERT stand for?\"\n\nanswer_question(question, bert_abstract)","ddd516dc":"print(\"T\/F\\tstart\\tend\\n\")\nfor i in range(len(start_true)):\n    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")","46376726":"# Convention Method (not working)","561940bf":"## Read","ef6cb295":"# Implementation of Bert (1p missin')","1db8a6bf":"# Fine-Tuning With SQuAD 2.0","3ab8aa42":"---\n# Get and Prepare Data\n\n## Download SQuAD data","66548096":"# Answer ","c408148b":"---\n\n# PyTorch Fine-tuning","856672aa":"## Prepare","825d7e76":"## Save Model","6e015218":"# Function for convinience","074a48f7":"## Encode"}}