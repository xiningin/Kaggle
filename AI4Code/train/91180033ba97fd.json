{"cell_type":{"629fc041":"code","1f484255":"code","c30fc831":"code","7d7c409a":"code","cbf01718":"code","c8486606":"code","1610ec87":"code","ed4e70a6":"code","14061908":"code","d3c180ce":"code","a5d33b4d":"code","59b7e915":"code","36bf0e46":"code","aa6ebd15":"code","7abe5632":"code","0cdbf7ca":"code","3067f3f3":"code","1a3cd364":"markdown","ffa80fb7":"markdown","ab320570":"markdown","4ea873db":"markdown","ab771a1a":"markdown","0ecd40dd":"markdown","983298f0":"markdown","ca67a687":"markdown"},"source":{"629fc041":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.chunk import ne_chunk","1f484255":"#Example Sentence\n\nex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'","c30fc831":"#Apply word tokenization and part-of-speech tagging to the sentence.\ndef preprocess(sent):\n    sent = nltk.word_tokenize(sent)\n    sent = nltk.pos_tag(sent)\n    return sent","7d7c409a":"#Sentence filtered with Word Tokenization\n\nsent = preprocess(ex)\nprint(\"POS_Tags for Sentence\")\nsent","cbf01718":"#Chunking Pattern \n\npattern = 'NP: {<DT>?<JJ>*<NN>}'","c8486606":"#create a chunk parser and test it on our sentence.\ncp = nltk.RegexpParser(pattern)\ncs = cp.parse(sent)\nprint(cs)","1610ec87":"#Chunker formed for sentence\n\nNPChunker = nltk.RegexpParser(pattern) \nresult = NPChunker.parse(sent)\n#result.draw()","ed4e70a6":"import spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()","14061908":"doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\nprint([(X.text, X.label_) for X in doc.ents])","d3c180ce":"print([(X, X.ent_iob_, X.ent_type_) for X in doc])","a5d33b4d":"from bs4 import BeautifulSoup\nimport requests\nimport re","59b7e915":"def url_to_string(url):\n    res = requests.get(url)\n    html = res.text\n    soup = BeautifulSoup(html, 'html5lib')\n    for script in soup([\"script\", \"style\", 'aside']):\n        script.extract()\n    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))","36bf0e46":"ny_bb = url_to_string('https:\/\/www.nytimes.com\/2018\/08\/13\/us\/politics\/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\narticle = nlp(ny_bb)\nprint(article.ents)\nlen(article.ents)","aa6ebd15":"labels = [x.label_ for x in article.ents]\nCounter(labels)","7abe5632":"#most common used items\n\nitems = [x.text for x in article.ents]\nCounter(items).most_common(3)","0cdbf7ca":"sentences = [x for x in article.sents]\nprint(sentences[20])","3067f3f3":"#Displaying detecing the name entities, Marking down.\n\ndisplacy.render(nlp(str(sentences[20])), jupyter=True, style='ent')","1a3cd364":"## Spacy\n\n![spacy.PNG](attachment:spacy.PNG)","ffa80fb7":"### Chunking\n\nChunk pattern consists of one rule, that a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN.","ab320570":"One of the nice things about Spacy is that we only need to apply nlp once, the entire background pipeline will return the objects.","4ea873db":"![nltk%20ner.PNG](attachment:nltk%20ner.PNG)","ab771a1a":"# Named Entity Recognition NLTK\n\nNamed Entity Recognition is a process where an algorithm takes a string of text (sentence or paragraph) as input and identifies relevant nouns (people, places, and organizations) that are mentioned in that string.","0ecd40dd":"The output can be read as a tree or a hierarchy with S as the first level, denoting sentence. we can also display it graphically.","983298f0":"![spacy%202.PNG](attachment:spacy%202.PNG)","ca67a687":"There are 153 entities in the article and they are represented as 8 unique labels:"}}