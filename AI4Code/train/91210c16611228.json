{"cell_type":{"120a180b":"code","e7ded887":"code","51fc9c1a":"code","8414e1a4":"code","e9775670":"code","9d1d1fe8":"code","4ea3e9b3":"code","ca0f85cc":"markdown","adc8acfe":"markdown","16472ec5":"markdown"},"source":{"120a180b":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nnp.seterr(divide='ignore')\n\ndataset = pd.read_csv('\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv')\ndataset.head()","e7ded887":"print(\"possible value of 'parental level of education'\")\ndataset['parental level of education'].unique()","51fc9c1a":"from sklearn.preprocessing import MinMaxScaler\n\ndataset['gender'] = dataset['gender'].apply(lambda x: [0, 1][x == 'male'])\ndataset['parental level of education'] = dataset['parental level of education'].apply(\n    lambda x: [0, 1][x in ['high school', 'some high school', 'some college']]\n)\ndataset['lunch'] = dataset['lunch'].apply(lambda x: [0, 1][x == 'standard'])\ndataset['test preparation course'] = dataset['test preparation course'].apply(lambda x: [0, 1][x == 'none'])\n\n# for key in ['group A', 'group B', 'group C', 'group D', 'group E']:\n#     dataset[key] = dataset['race\/ethnicity'].apply(lambda x: [0, 1][x == key])\ndataset = dataset.drop(['race\/ethnicity'], axis=1)\n\ndataset['passed math'] = dataset['math score'].apply(lambda x: [0, 1][x >= 60])\ndataset = dataset.drop(['math score'], axis=1)\n\nscaler = MinMaxScaler()\nscaler.fit(dataset[['reading score']])\ndataset['reading score'] = scaler.transform(dataset[['reading score']])\n\nscaler = MinMaxScaler()\nscaler.fit(dataset[['writing score']])\ndataset['writing score'] = scaler.transform(dataset[['writing score']])","8414e1a4":"y = dataset['passed math']\nX = dataset.drop(['passed math'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\nX_train","e9775670":"from sklearn.neighbors import KDTree\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nclass KNNClassifier():\n\n    def __init__(\n        self,\n        n_neighbors=5,\n        weights='uniform',\n        algorithm='brute',\n        leaf_size=30,\n    ):\n        if int(n_neighbors) <= 0:\n            raise Exception('n_neighbors should be a positive integer')\n        if weights not in ['uniform', 'distance'] and not callable(weights):\n            raise Exception(\"weights should be 'uniform' or 'distance' or a callable\")\n        if algorithm not in ['brute', 'kd_tree']:\n            raise Exception(\"algorithm should be either 'brute' or 'kd_tree'\")\n        if int(leaf_size) <= 0:\n            raise Exception('leaf_size should be a positive integer')\n        self.K = int(n_neighbors)\n        self.weights = weights\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n\n    def fit(self, X, y):\n        self.X = np.array(X)\n        self.y = np.array(y)\n        # build a k-d tree\n        if self.algorithm == 'kd_tree':\n            self.kd_tree = KDTree(self.X, leaf_size=self.leaf_size)\n\n    def compute_k_nearest(self, x_predict):\n        if self.algorithm == 'brute':\n            # Euclidean metric\n            dists = np.array([np.linalg.norm(x_predict - x) for x in self.X])\n            k_nearest_indices = np.argsort(dists)[:self.K]\n            k_nearest_dists = dists[k_nearest_indices]\n            return k_nearest_dists, k_nearest_indices\n        else:\n            k_nearest_dists, k_nearest_indices = self.kd_tree.query(np.array([x_predict]), self.K)\n            return k_nearest_dists[0], k_nearest_indices[0]\n\n    def compute_weights(self, dists):\n        if self.weights == 'uniform':\n            return np.ones(dists.shape[0])\n        elif self.weights == 'distance':\n            return np.reciprocal(dists.astype(np.float32))\n        else:\n            return self.weights(dists)\n\n    def predict(self, X):\n        X_predict = np.array(X)\n        y_predict = np.empty(X_predict.shape[0])\n        for i in range(X_predict.shape[0]):\n            k_nearest_dists, k_nearest_indices = self.compute_k_nearest(X_predict[i])\n            y_k_nearest = self.y[k_nearest_indices]\n            weights = self.compute_weights(k_nearest_dists)\n            y_predict[i] = np.argmax(np.bincount(y_k_nearest, weights=weights))\n        return y_predict\n\n\nknn = KNNClassifier(n_neighbors=5, weights='distance', algorithm='kd_tree')\nknn.fit(X_train, y_train)\ny_predict = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_predict)\nprecision, recall, fscore, support = precision_recall_fscore_support(y_test, y_predict, average='weighted')\nprint('Accuracy:', accuracy)\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('F score:', fscore)\n# print('Support:', support)","9d1d1fe8":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import KDTree\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nknn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='kd_tree')\nknn.fit(X_train, y_train)\ny_predict = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_predict)\nprecision, recall, fscore, support = precision_recall_fscore_support(y_test, y_predict, average='weighted')\nprint('Accuracy:', accuracy)\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('F score:', fscore)\n# print('Support:', support)\n","4ea3e9b3":"import matplotlib.pyplot as plt\n\nx = []\nuniform_y = []\ndistance_y = []\nfor k in range(1, 50):\n    knn = KNNClassifier(n_neighbors=k, weights='uniform', algorithm='kd_tree')\n    knn.fit(X_train, y_train)\n    y_predict = knn.predict(X_test)\n    accuracy = accuracy_score(y_test, y_predict)\n    x.append(k)\n    uniform_y.append(accuracy)\n    knn = KNNClassifier(n_neighbors=k, weights='distance', algorithm='kd_tree')\n    knn.fit(X_train, y_train)\n    y_predict = knn.predict(X_test)\n    accuracy = accuracy_score(y_test, y_predict)\n    distance_y.append(accuracy)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 5), sharey=True)\naxes[0].set_xlabel('k')\naxes[1].set_xlabel('k')\naxes[0].set_ylabel('accuracy')\naxes[0].plot(x, uniform_y)\naxes[0].axvline(x=5, color='red')\naxes[1].plot(x, distance_y)\naxes[1].axvline(x=5, color='red')\nfig.show()","ca0f85cc":"## Preprocessing","adc8acfe":"## Predict student will pass or fail on Math","16472ec5":"\u4f7f\u7528 Sklean \u9a57\u7b97"}}