{"cell_type":{"a718470e":"code","ffc40fb4":"code","0aaac6ae":"code","2caafb5f":"code","2471a175":"code","0da5b324":"code","d7e61879":"code","fa565116":"code","31287b8c":"code","79f7d178":"code","935a27c1":"code","8539df4f":"code","dd36f2e4":"markdown","6c553254":"markdown","141c7ca9":"markdown","1018dd72":"markdown","50379cc6":"markdown","11388ad1":"markdown"},"source":{"a718470e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import these folowing libraries functions for feature slection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\n# To display all the columns of the dataframe\npd.set_option('max_columns', None)","ffc40fb4":"# import data\ntrain= pd.read_csv('..\/input\/feature-engineered-advanced-house-prices-data\/train.csv')\ntest= pd.read_csv('..\/input\/feature-engineered-advanced-house-prices-data\/test.csv')","0aaac6ae":"# shape of train dataset (rows, columns)\nprint(train.shape)\n# Top 5 rows of train dataset\ntrain.head()","2caafb5f":"from sklearn.model_selection import train_test_split\nX_train,X_valid,y_train,y_valid=train_test_split(train.drop(['Id','SalePrice'],axis=1),train['SalePrice'],test_size=0.2,random_state=0)\nprint(X_train.shape)\nprint(X_valid.shape)","2471a175":"feature_select_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\nfeature_select_model.fit(X_train, y_train)","0da5b324":"feature_select_model.get_support()","d7e61879":"# Now print the number of total and selected features\n\n# This is how we can make a list of the selected features\nselected_features = X_train.columns[(feature_select_model.get_support())]\n\n# let's print some stats\nprint('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_features)))\nprint('features with coefficients shrank to zero: {}'.format(np.sum(feature_select_model.estimator_.coef_ == 0)))","fa565116":"selected_features","31287b8c":"X_train=X_train[selected_features]","79f7d178":"X_valid=X_valid[selected_features]","935a27c1":"X_train.head()","8539df4f":"X_train.shape","dd36f2e4":"#### **Please note that:** The folowing imported train data is feature engineered train data of advance house price.\n#### All process of feature enginnering on train data of advance house price is done in this [note book](https:\/\/www.kaggle.com\/wajahatparvez99\/feature-engineering-advance-house-data\/).","6c553254":"#### The main aim of Feature Selection is to select those feature which have more impact on the data, which we will discuss as we go ahead","141c7ca9":"## Feature Selection\n#### **Do the folowing steps for feature selction:**\n1. #### Specify the Lasso Regression model\n2. #### Select a suitable alpha (equivalent of penalty)\n3. #### The bigger the alpha the less features that will be selected\n4. #### Then use the selectFromModel object from sklearn\n5. #### selectFromModel from sklearn will select features which coefficients are non-zero","1018dd72":"## Complete Lifecycle of a Data Science Project\n#### 1. [Data Analysis](https:\/\/www.kaggle.com\/wajahatparvez99\/exploratory-data-analysis-advance-house-data)\n#### 2. [Feature Engineering](https:\/\/www.kaggle.com\/wajahatparvez99\/feature-engineering-advance-house-data\/)\n#### **3. Feature Selection**\n#### 4. Model Building\n#### 5. Model Deployment","50379cc6":"#### **Note: In this note book feature selection is done only on train dataset. But you have to do the same process on your test dataset also while working on real life project.**","11388ad1":"#### This note book is the third Part of the Lifecycle of a Data Science Project.\n#### First two note book are [1. Exploratory Data Analysis](https:\/\/www.kaggle.com\/wajahatparvez99\/exploratory-data-analysis-advance-house-data) [2. Feature Engineering](https:\/\/www.kaggle.com\/wajahatparvez99\/feature-engineering-advance-house-data\/) "}}