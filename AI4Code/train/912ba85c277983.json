{"cell_type":{"2e218e31":"code","e2bf4496":"code","d9271f7a":"code","0340d2a0":"code","2522fa19":"code","e51f5790":"code","fe3d34f6":"code","039f5d65":"code","28be1d5a":"code","f02b3cef":"code","71ad5f9a":"code","190a66b4":"code","fa2e37c4":"code","b95aaa94":"code","5d23b1df":"code","c5cfb029":"code","3b3e9885":"code","b3411b88":"code","860f82e2":"code","9d7e1c0d":"code","18440e1c":"code","4cca47d3":"code","1958bff8":"code","a426c0ce":"code","8d2ac283":"code","e7277816":"markdown","64e8f17a":"markdown","34e4c7ed":"markdown","0336bcc7":"markdown"},"source":{"2e218e31":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport scipy\nimport cv2\n\nimport torch\nimport torchvision\nfrom torchvision import models\nimport torch.nn as nn\nfrom torchvision import transforms,datasets\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader,Dataset,ConcatDataset\nfrom PIL import Image\nimport torch.nn.functional as F\nfrom torch.nn.modules.pooling import AvgPool3d\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.model_selection import train_test_split\nfrom itertools import product","e2bf4496":"torch.cuda.is_available()","d9271f7a":"train=pd.read_csv('..\/input\/aerial-cactus-identification\/train.csv')\nsample=pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')","0340d2a0":"train.head()","2522fa19":"train.info()","e51f5790":"train['has_cactus'].value_counts().plot(kind='pie')","fe3d34f6":"\"\"\"extra=train[train.has_cactus==0]\ntrain=pd.concat([train,extra],axis=0)\"\"\"","039f5d65":"image_transforms={\n    'train':transforms.Compose([\n        transforms.RandomRotation(degrees=0),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5,0.5,0.5],\n                            [0.2,0.2,0.2])]),\n    'test':transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.5,0.5,0.5],\n                            [0.2,0.2,0.2])\n    ])\n}\n        ","28be1d5a":"train_set,val_set=train_test_split(train,stratify=train.has_cactus,test_size=0.2)\n\nlen1=len(train_set)\nlen2=len(val_set)\n\n# Loading Data From Folders\ntrain_dir='train\/train'\ntest_dir='test\/test'","f02b3cef":"class dataset_(torch.utils.data.Dataset):\n    def __init__(self,labels,data_directory,transform):\n        super().__init__()\n\n        #characterizes a dataset for Pytorch\n        \n        self.list_id=labels.values[:,0]\n        self.labels=labels.values[:,1]\n        self.data_dir=data_directory\n        self.transform=transform\n    \n    def __len__(self):\n        # Denotes the tota number of samples\n        return len(self.list_id)\n    \n    def __getitem__(self,index):\n        name=self.list_id[index]\n        img=Image.open('..\/input\/aerial-cactus-identification\/{}\/{}'.format(self.data_dir,name))\n        img=self.transform(img)\n        return img,torch.tensor(self.labels[index],dtype=torch.float32)","71ad5f9a":"train_set=dataset_(train_set,train_dir,image_transforms['train'])\n#train_df=DataLoader(train_df,batch_size=120,shuffle=True)\n\nval_set=dataset_(val_set,train_dir,image_transforms['test'])\n#val_df=DataLoader(val_df,batch_size=120,shuffle=True)","190a66b4":"#test=dataset_(ter)","fa2e37c4":"lst,labels=next(iter(train_set))","b95aaa94":"lst.shape,labels.shape,labels","5d23b1df":"def size(image_size,ker,stri,pad=0):\n    return (image_size-ker+2*pad)\/stri +1","c5cfb029":"size(8,2,2)","3b3e9885":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Convolutional Layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        self.dense_1=nn.BatchNorm2d(16)\n        \n        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1)\n        self.dense_2=nn.BatchNorm2d(32)\n        \n        self.conv3 = nn.Conv2d(in_channels=32, out_channels= 64,kernel_size= 3, padding=1)\n        self.dense_3=nn.BatchNorm2d(64)\n        \n        self.conv4 = nn.Conv2d(in_channels=64,out_channels= 128,kernel_size= 3, padding=1)\n        self.dense_4=nn.BatchNorm2d(128)\n        \n        # Linear layer\n        self.fc1 = nn.Linear(in_features=128*2*2,out_features= 128)\n        self.fc_dense1=nn.BatchNorm1d(128)\n        self.out = nn.Linear(in_features=128,out_features=2)\n        # Set Dropout\n        self.d1 = nn.Dropout(0.5)\n        self.f=nn.Sigmoid()\n\n\n    def forward(self,t):\n        #input layer\n        t=t\n        #first convolutional layer\n        t=F.max_pool2d(F.leaky_relu(self.dense_1(self.conv1(t))),kernel_size=2,stride=2)\n        \n        #Second Convolutional Layer\n        \n        t=F.max_pool2d(F.leaky_relu(self.dense_2(self.conv2(t))),stride=2,kernel_size=2)\n        \n        #Third Convolution Layer\n        \n        t=F.max_pool2d(F.leaky_relu(self.dense_3(self.conv3(t))),stride=2,kernel_size=2)\n        \n        # Fourth Convolutional Layer\n        t=F.max_pool2d(F.leaky_relu(self.dense_4(self.conv4(t))),stride=2,kernel_size=2)\n        \n        # First linear Layer\n        t=t.reshape(-1,128*2*2)\n        t=F.leaky_relu(self.fc_dense1(self.fc1(t)))\n        t=self.d1(t)\n        \n        #Second Linear Layer\n        t=self.f(self.out(t))\n        return t","b3411b88":"batch_sizes=120\nlrs=0.2\ntrain_loss=[]\nval_loss=[]\ntrain_correct=[]\nval_correct=[]\nepoch=[]\nmodel=Model()\nmodel=model.to('cuda:0')\noptimizer=optim.SGD(model.parameters(),lr=lrs)\n\ntrain_df=DataLoader(train_set,batch_size=batch_sizes,shuffle=True)\nval_df=DataLoader(val_set,batch_size=batch_sizes,shuffle=True)\n\nfor i in range(30):\n    total_loss=0 # Total loss for an epoch\n    total_correct=0 #Total correct number of predictions\n    for batch in train_df:\n        images,labels=batch #loading a batch\n\n        images=images.to('cuda:0') #changing the device\n        labels=labels.to('cuda:0') \n        #changing data type\n        labels=labels.long()\n        preds=model(images) #passing the images batch through the model\n        \n        #f=nn.Softmax()\n        #preds=f(preds)\n        loss=F.cross_entropy(preds,labels) #CALCULATING lOSS\n            \n        \n        #Setting the last gradient matrix to zero\n        optimizer.zero_grad()\n\n        loss.backward() # Calculating the gradient\n        optimizer.step()# Updating the parameters\n        total_loss+=loss.item() # calculating the total loss \n        total_correct+=preds.argmax(dim=1).eq(labels).sum().item()#Calculating the correct prediction in a single epoch\n        del images,labels # \n        \n    train_loss.append(total_loss)\n    train_correct.append(total_correct\/len1)\n    epoch.append(i+1)\n\n    with torch.no_grad():\n        total_val_loss=0\n        total_val_correct=0\n        for val_batch in val_df:\n            val_im,val_lab=val_batch\n            val_im=val_im.to('cuda:0')\n            val_lab=val_lab.to('cuda:0')\n            val_lab=val_lab.long()\n            \n            val_preds=model(val_im)\n            \n            \n            loss_val=F.cross_entropy(val_preds,val_lab)\n            total_val_loss+=loss_val\n            total_val_correct+=val_preds.argmax(dim=1).eq(val_lab).sum().item()\n\n        val_loss.append(total_val_loss)\n        val_correct.append(total_val_correct\/len2)\n\n        print(\"Epoch {}\\t train_loss {}\\t train_accuracy{}\\t val_loss {}\\t val_accuracy {}\\n\".format(epoch[i],total_loss,\n                                                                                                     total_correct\/len1,total_val_loss,total_val_correct\/len2))","860f82e2":"ep=[i for i in range(1,30)]\nplt.plot(ep,train_loss,label='train')\nplt.plot(ep,val_loss,label='test')\nplt.legend()","9d7e1c0d":"plt.plot(ep,train_correct,label='train',color='magenta')\nplt.plot(ep,val_correct,label='test',color='royalblue')\nplt.legend()","18440e1c":"class dataset_(torch.utils.data.Dataset):\n    def __init__(self,data_directory,transform):\n        super().__init__()\n\n        #characterizes a dataset for Pytorch\n        self.list_id=os.listdir(\"..\/input\/aerial-cactus-identification\/test\/test\")\n        self.labels=[0]*len(self.list_id)\n        self.data_dir=data_directory\n        self.transform=transform\n    \n    def __len__(self):\n        # Denotes the tota number of samples\n        return len(self.list_id)\n    \n    def __getitem__(self,index):\n        name=self.list_id[index]\n        img=Image.open('{}\/{}'.format(self.data_dir,name))\n        img=self.transform(img)\n        return img,torch.tensor(self.labels[index],dtype=torch.float32)","4cca47d3":"test=dataset_(\"..\/input\/aerial-cactus-identification\/test\/test\",image_transforms['test'])\ntest=DataLoader(test,batch_size=batch_sizes)","1958bff8":"name=os.listdir(\"..\/input\/aerial-cactus-identification\/test\/test\")\nlabel=[]\nwith torch.no_grad():\n    for test_batch in test:\n        test_img,test_lab=test_batch\n        test_img,test_lab=test_img.to('cuda:0'),test_lab.to('cuda:0')\n        test_lab=model(test_img)\n        test_lab=torch.max(test_lab,dim=1)\n        #test_lab=test_lab.cpu().tolist()\n        test_predict=[]\n        for i in range(test_lab[0].shape[0]):\n            if test_lab[1][i]==0:\n                test_predict.append(1-test_lab[0][i].item())\n            else:\n                test_predict.append(test_lab[0][i].item())\n        label=label+test_predict","a426c0ce":"submissions=pd.DataFrame({\"id\":name,\"has_cactus\":label})","8d2ac283":"submissions.to_csv('samplesubmission.csv',index=False)","e7277816":"# Load The Data","64e8f17a":"# Image Transformation","34e4c7ed":"# Creating A Model","0336bcc7":"# Training Process"}}