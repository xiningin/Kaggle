{"cell_type":{"5d88b4f4":"code","92360d9f":"code","8ae000b7":"code","f2ad6172":"code","8c9f09f5":"code","55368e16":"code","0dfd005c":"code","f7606794":"code","e222e076":"code","bec75248":"code","88c9f5d2":"code","74cccfb5":"code","d011fbab":"code","20ce64b8":"code","631fefb0":"code","a465cc48":"code","c88748e5":"code","a55eeacf":"code","a7a55c3d":"code","ae400e19":"code","cabbdffb":"code","aff62601":"code","b919bbf4":"code","3caf44b0":"code","12761404":"code","d446e9aa":"code","c731e950":"code","54580599":"code","a1e04835":"code","79eb04ca":"code","db3d9a3d":"code","63d3b280":"code","e061fbd1":"code","b2a64b7f":"code","027bf3d6":"code","a7ff185b":"code","a24412db":"code","ac8f04cc":"code","beb8c949":"code","404a5f26":"code","e633ccce":"code","626d470a":"code","c7c0c418":"code","1c09c9ab":"code","7d3eeaa7":"code","5d4309c6":"code","9f3eeeec":"code","9c0d5e68":"code","2dc14b95":"code","799e6f47":"code","ba12c5e0":"code","2f62ef74":"markdown","8827097e":"markdown","d60af698":"markdown","5f2d816c":"markdown","0a06c4c8":"markdown","f3ff8f3e":"markdown","0b13123c":"markdown","2897e0fb":"markdown","1a6cd34f":"markdown","5cf350dc":"markdown","e7e069cd":"markdown"},"source":{"5d88b4f4":"try:\n  import google.colab\n  IN_COLAB = True\nexcept:\n  IN_COLAB = False","92360d9f":"if IN_COLAB:\n  from google.colab import drive\n  drive.mount(\"\/gdrive\", force_remount=True)","8ae000b7":"if IN_COLAB:\n  # !pip install -Uqq fastcore --upgrade\n  !pip install --upgrade fastai==2.5.2","f2ad6172":"!pip show fastai","8c9f09f5":"if IN_COLAB:\n  !pip uninstall -y kaggle\n  !pip install kaggle\n  !mkdir \/root\/.kaggle\n  !cp \/gdrive\/MyDrive\/kaggle\/kaggle.json \/root\/.kaggle\n  !kaggle competitions download -c petfinder-pawpularity-score\n  !mkdir -p ..\/input\/petfinder-pawpularity-score\n  !unzip -n -qq 'petfinder-pawpularity-score.zip' -d ..\/input\/petfinder-pawpularity-score\n\n  !kaggle datasets download -d  tanlikesmath\/swin-transformer\n  !mkdir -p ..\/input\/swin-transformer\n  !unzip -n -qq swin-transformer.zip -d ..\/input\/swin-transformer\n\n  !kaggle datasets download -d  kozodoi\/timm-pytorch-image-models\n  !mkdir -p ..\/input\/timm-pytorch-image-models\n  !unzip -n -qq timm-pytorch-image-models.zip -d ..\/input\/timm-pytorch-image-models\n\n#   !kaggle datasets download -d  bobber\/petfinder-fastai-kf-11-weight-no-loss-v1-dec10\n#   !mkdir -p ..\/input\/petfinder-fastai-kf-11-weight-no-loss-v1-dec10\n#   !unzip -n -qq petfinder-fastai-kf-11-weight-no-loss-v1-dec10.zip -d ..\/input\/petfinder-fastai-kf-11-weight-no-loss-v1-dec10\n\n  !kaggle datasets download -d  bobber\/petfinderfastaikf11noweightnormalization\n  !mkdir -p ..\/input\/petfinderfastaikf11noweightnormalization\n  !unzip -n -qq petfinderfastaikf11noweightnormalization.zip -d ..\/input\/petfinderfastaikf11noweightnormalization\n\n  !mkdir -p \/gdrive\/MyDrive\/kaggle\/petfinder\/models\n  !ln -s \/gdrive\/MyDrive\/kaggle\/petfinder\/models models","55368e16":"import cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')","0dfd005c":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model\n#from timm.data.mixup import Mixup","f7606794":"from fastai.vision.all import *\n#from fastai.callback.hook import *","e222e076":"#set_seed(999, reproducible=True)\nseed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\nBATCH_SIZE = 32\nNEED_TRAIN = True\n\nN_TTA = 10","bec75248":"dataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","88c9f5d2":"train_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df.head()","74cccfb5":"# #removed duplicates that has lower score than the same image\n# removed_id = ['5ef7ba98fc97917aec56ded5d5c2b099',\n#              '1feb99c2a4cac3f3c4f8a4510421d6f5',\n#              '5a642ecc14e9c57a05b8e010414011f2',\n#              '0422cd506773b78a6f19416c98952407',\n#              '9b3267c1652691240d78b7b3d072baf3',\n#              '1059231cf2948216fcc2ac6afb4f8db8',\n#              '8ffde3ae7ab3726cff7ca28697687a42',\n#              '78a02b3cb6ed38b2772215c0c0a7f78e',\n#              'bf8501acaeeedc2a421bac3d9af58bb7',\n#              'fe47539e989df047507eaa60a16bc3fd',\n#              'dd042410dc7f02e648162d7764b50900',\n#              '988b31dd48a1bc867dbc9e14d21b05f6',\n#              'e359704524fa26d6a3dcd8bfeeaedd2e',\n#              '6ae42b731c00756ddd291fa615c822a1',\n#              '9a0238499efb15551f06ad583a6fa951',\n#              'a9513f7f0c93e179b87c01be847b3e4c',\n#              '38426ba3cbf5484555f2b5e9504a6b03',\n#              'cd909abf8f425d7e646eebe4d3bf4769',\n#              '9f5a457ce7e22eecd0992f4ea17b6107',\n#              '3877f2981e502fe1812af38d4f511fd2',\n#              'b190f25b33bd52a8aae8fd81bd069888',\n#              '94c823294d542af6e660423f0348bf31',\n#              '2b737750362ef6b31068c4a4194909ed',\n#              '01430d6ae02e79774b651175edd40842',\n#              '72b33c9c368d86648b756143ab19baeb',\n#              'dbc47155644aeb3edd1bd39dba9b6953',\n#              'b49ad3aac4296376d7520445a27726de',\n#              '54563ff51aa70ea8c6a9325c15f55399',\n#              '87c6a8f85af93b84594a36f8ffd5d6b8',\n#              '16d8e12207ede187e65ab45d7def117b']","d011fbab":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")\ntrain_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","20ce64b8":"# train_df_100 = train_df[train_df['Pawpularity']==100].copy()\n# rain_df = train_df[train_df['Pawpularity']!=100].copy()","631fefb0":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")\ntrain_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","a465cc48":"train_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","c88748e5":"print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","a55eeacf":"train_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']","a7a55c3d":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","ae400e19":"im","cabbdffb":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'\n","aff62601":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","b919bbf4":"#Sturges' rule\nnum_bins = int(np.floor(1+np.log2(len(train_df))))\nnum_bins","3caf44b0":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","12761404":"#from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 11\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","d446e9aa":"train_df[train_df['fold']==0].head()","c731e950":"train_df[train_df['fold']==0]['bins'].value_counts()","54580599":"train_df[train_df['fold']==1]['bins'].value_counts()","a1e04835":"train_df_group = train_df.groupby('bins')['Pawpularity'].agg(['min', 'max', 'mean', 'std', 'count'])\ntrain_df_group","79eb04ca":"def petfinder_rmse(input,target):\n    # print('target shape', target.shape)\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","db3d9a3d":"def get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    # It looks if seed of RandomSplitter is set, it reduce the score. So we don't set seed here\n    splitter = RandomSplitter(0.2)\n\n    validate_idx = splitter(range(len(train_df)))[1]\n    #find pawpularity 100\n    idx_100 = train_df.loc[train_df['Pawpularity']==100].index\n\n    # Add pawpularity 100 here\n    # validate_idx = list(set(validate_idx).union(set(idx_100)))\n\n    # print(validate_idx)\n    print(f'validat dataset size is {len(validate_idx)} including {len(idx_100)} images with pawpularity 100')\n\n    # Change RandomSplitter to IndexSplitter\n    splitter = IndexSplitter(validate_idx)\n    \n    dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader('path'),\n                get_y=ColReader('norm_score'),\n                splitter=splitter,\n                item_tfms=Resize(224), #pass in item_tfms\n                batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Normalize.from_stats(*imagenet_stats)])\n               )\n    \n    paw_dls = dls.dataloaders(train_df_f, \n                          bs=BATCH_SIZE,\n                          num_workers=8,\n                          seed=seed)\n    \n    return paw_dls, splitter\n","63d3b280":"#Valid Kfolder size\n# the_data, splitter = get_data(0)\n# assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)\/\/BATCH_SIZE)","e061fbd1":"@delegates()\nclass BCEWithLogitsLossFlatWeight(BaseLoss):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    @use_kwargs_dict(keep=True, weight=None, reduction='mean', pos_weight=None)\n    def __init__(self, *args, axis=-1, floatify=True, thresh=0.5, **kwargs):\n        if kwargs.get('pos_weight', None) is not None and kwargs.get('flatten', None) is True:\n            raise ValueError(\"`flatten` must be False when using `pos_weight` to avoid a RuntimeError due to shape mismatch\")\n        if kwargs.get('pos_weight', None) is not None: kwargs['flatten'] = False\n        super().__init__(nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n        self.thresh = thresh\n\n    def decodes(self, x):    return x>self.thresh\n    def activation(self, x): return torch.sigmoid(x)\n\n    def __call__(self, inp, targ, **kwargs):\n        # print(f'input shape: {inp.shape}, target shape: {targ.shape}')\n        # Set weight for all targets\n        weight = targ * 100\n        # Only set weight for bin 10\n        weight = torch.where((weight >= 72) & (weight <= 78), 256, 1)\n        self.func.register_buffer('weight', weight)\n#         print(f'weight: {weight}')\n        return super().__call__(inp, targ, **kwargs)","b2a64b7f":"def get_learner(fold_num):\n    data, splitter = get_data(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    loss = BCEWithLogitsLossFlatWeight()\n    \n\n    learn = Learner(data, model, loss_func=loss, metrics=petfinder_rmse, cbs=[MixUp(0.2)]).to_fp16()\n    \n    return learn, splitter","027bf3d6":"test_df = pd.read_csv(dataset_path\/'test.csv')\ntest_df.head()","a7ff185b":"if len(test_df) != 8:\n    NEED_TRAIN = True","a24412db":"test_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']\/100","ac8f04cc":"# if NEED_TRAIN:\n#     get_learner(fold_num=0).lr_find(end_lr=3e-2)","beb8c949":"import gc","404a5f26":"from sklearn.metrics import mean_squared_error\ndef get_cv_for_bins(bins, pred_col='pred'):\n  cv_score = mean_squared_error(train_df.loc[(train_df[pred_col]!=-1) & (train_df['bins']==bins), 'Pawpularity'], \n                                train_df.loc[(train_df[pred_col]!=-1) & (train_df['bins']==bins), pred_col], squared=False)\n  return cv_score\n\n\ndef print_cv_for_all_bins(pred_col='pred', num_bins=13):\n  cv_scores = []\n  for bins in range(num_bins):\n    cv = get_cv_for_bins(bins, pred_col)\n    print(f'bin {bins} cv: {cv}')\n    cv_scores.append(cv)\n\n  cv_score = mean_squared_error(train_df.loc[(train_df[pred_col]!=-1), 'Pawpularity'], \n                                train_df.loc[(train_df[pred_col]!=-1), pred_col], squared=False)\n  print(f'Total cv {pred_col}:{cv_score}')\n  return cv_scores","e633ccce":"#####################################################################################################################\n# no weight\n#####################################################################################################################","626d470a":"@delegates()\nclass BCEWithLogitsLossFlatWeight(BaseLoss):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    @use_kwargs_dict(keep=True, weight=None, reduction='mean', pos_weight=None)\n    def __init__(self, *args, axis=-1, floatify=True, thresh=0.5, **kwargs):\n        if kwargs.get('pos_weight', None) is not None and kwargs.get('flatten', None) is True:\n            raise ValueError(\"`flatten` must be False when using `pos_weight` to avoid a RuntimeError due to shape mismatch\")\n        if kwargs.get('pos_weight', None) is not None: kwargs['flatten'] = False\n        super().__init__(nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n        self.thresh = thresh\n\n    def decodes(self, x):    return x>self.thresh\n    def activation(self, x): return torch.sigmoid(x)\n\n    def __call__(self, inp, targ, **kwargs):\n        # print(f'input shape: {inp.shape}, target shape: {targ.shape}')\n        # Set weight for all targets\n#         weight = targ * 100\n#         # Only set weight for bin 13\n#         weight = torch.where(weight >= 93, 512, 1)\n        #self.func.register_buffer('weight', weight)\n        # print(f'weight: {weight}')\n        return super().__call__(inp, targ, **kwargs)","c7c0c418":"N_TTA = 10","1c09c9ab":"torch.cuda.empty_cache()\ngc.collect()","7d3eeaa7":"#SVR\n\ndef forward_without_head(self, x):\n    x = self.forward_features(x)\n    # x = self.head(x)\n    return x\n\ndef forward_org(self, x):\n    x = self.forward_features(x)\n    x = self.head(x)\n    return x\n\ndef get_preds_for_svr(learn, df, dls=None):\n  #Change forward method to get feature output\n  learn.model.forward_org = learn.model.forward\n  learn.model.forward = types.MethodType(forward_without_head, learn.model)\n\n  paw_dls = dls\n  if paw_dls==None:\n      paw_dls = learn.dls\n\n  # test_dl = paw_dls.test_dl(test_df)\n  test_dl = paw_dls.test_dl(df)\n  # test_dl = paw_dls.test_dl(train_df.loc[val_idx])\n  preds, _ = learn.tta(dl=test_dl, n=N_TTA, beta=0)\n\n  #Restore forward method\n  # learn.model.forward = learn.model.forward_org\n  learn.model.forward = types.MethodType(forward_org, learn.model)\n\n  return preds\n\ndef fit_SVR(preds, target, i):\n  clf = SVR(C=20.0)\n  clf.fit(preds, target)\n\n  name = f\"SVR_fold_{i}.pkl\"\n  pickle.dump(clf, open(name, \"wb\"))\n  print(f'Fit SVR {name}')\n  return clf\n\ndef predict_SVR(model_path, preds, i, clf=None):\n  if clf==None:\n    name = f\"{model_path}\/SVR_fold_{i}.pkl\"\n    clf = pickle.load(open(name, \"rb\"))\n    print(f'Load SVR {name}')\n  preds_svr = clf.predict(preds)\n  #reshape to right size\n  preds_svr = preds_svr.reshape((-1,1))\n  return preds_svr, clf","5d4309c6":"META_COL = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group',\n            'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n","9f3eeeec":"model_base_folder = '..\/input\/petfinderfastaikf11noweightnormalization'\n\nN_TTA = 10\n\nif NEED_TRAIN:\n    all_preds = []\n    train_df['pred'] = -1\n    train_df['preds_svr'] = -1\n    train_df['preds_dual'] = -1\n\n    for i in range(N_FOLDS):\n\n        print(f'Fold {i} results')\n\n#         learn, splitter = get_learner(fold_num=i)\n\n#         learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n#         learn.recorder.plot_loss()  \n#         learn.export(f'model_fold_{i}.pkl')\n        path = f'{model_base_folder}\/model_fold_{i}.pkl'\n        learn = load_learner(path, cpu=False)\n        print('Loaded model from ', path)\n\n        paw_dls, splitter = get_data(i)\n        # paw_dls = learn.dls\n        \n        test_dl = paw_dls.test_dl(test_df)\n\n        preds, _ = learn.tta(dl=test_dl, n=N_TTA, beta=0)\n\n        all_preds.append(preds)\n\n        #SVR model\n        preds = get_preds_for_svr(learn, test_df, paw_dls)\n        #Add meta data\n        preds = np.concatenate((preds.numpy(), test_df[META_COL].to_numpy()), axis=1)\n        preds_svr, clf = predict_SVR('..\/input\/petfinderfastaikf11singlepretrainsvrmeta', preds, i)\n        #Norm SVR prediction\n        preds_svr = preds_svr\/100\n        print(preds_svr[:5])\n        \n        all_preds.append(preds_svr)\n        print('test_df.shape:', test_df.shape, 'preds_svr.shape:', preds_svr.shape)\n      \n        \n        #Only do CV for public train\n        if len(test_df) == 8:\n#             val_idx = splitter(range(len(train_df)))[1]\n            val_idx = np.load(f'{model_base_folder}\/val_idx_{i}.npy')\n            # Save validation idx here\n#             np.save(f'val_idx_{i}', val_idx)\n            val_df = train_df.loc[val_idx]\n            val_pred, _ = learn.tta(dl=paw_dls.test_dl(val_df), n=N_TTA, beta=0)\n            print(val_df['Pawpularity'][:5], val_pred[:5])\n            score = mean_squared_error(val_df['Pawpularity'], val_pred*100, squared=False)\n            print(f'Fold {i} | Score: {score}')\n            # Save prediction of validation as pred\n            train_df.loc[val_idx, 'pred'] = val_pred*100\n            \n            print_cv_for_all_bins()\n\n            #SVR\n            preds = get_preds_for_svr(learn, train_df.loc[val_idx], paw_dls)\n            #Add meta data\n            preds = np.concatenate((preds.numpy(), train_df.loc[val_idx, META_COL].to_numpy()), axis=1)\n            preds_svr, clf = predict_SVR('..\/input\/petfinderfastaikf11singlepretrainsvrmeta', preds, i, clf)\n            print(val_df['Pawpularity'][:5], preds_svr[:5])\n            train_df.loc[val_idx, 'preds_svr'] = preds_svr\n            print_cv_for_all_bins('preds_svr')\n            \n            train_df.loc[val_idx, 'preds_dual'] = (train_df.loc[val_idx, 'preds_svr']+train_df.loc[val_idx, 'pred'])\/2\n            print(val_df['Pawpularity'][:5], val_df['preds_dual'][:5])\n            print_cv_for_all_bins('preds_dual')\n\n            \n            del val_pred\n        \n\n        del learn\n\n        torch.cuda.empty_cache()\n\n        gc.collect()\n        \n        #Only run one fold for public train as we don't have so many GPU time\n#         if len(test_df) == 8 and (not IN_COLAB):\n#             break\n    if len(test_df) == 8:\n        cv_score = mean_squared_error(train_df.loc[train_df['pred']!=-1, 'Pawpularity'], \n                                      train_df.loc[train_df['pred']!=-1, 'pred'], squared=False)\n        print(f'CV Score: {cv_score}')","9c0d5e68":"if NEED_TRAIN:\n    all_preds, np.mean(np.stack(all_preds*100))\nsample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\n\nif NEED_TRAIN:\n    preds = np.mean(np.stack(all_preds), axis=0)\n    sample_df['Pawpularity'] = preds*100\nsample_df.to_csv('submission.csv',index=False)\nsample_df.to_csv('submission_no_weight.csv',index=False)","2dc14b95":"#####################################################################################################################\n# finally\n#####################################################################################################################","799e6f47":"# save CV prediction\ntrain_df.to_csv('train_df.csv',index=False)","ba12c5e0":"pd.read_csv('submission.csv').head()","2f62ef74":"Let's check the distribution of the Pawpularity Score:","8827097e":"Let's do some quick processing of the image filenames to make it easier to access:","d60af698":"Let's check what data is available to us:","5f2d816c":"The metadata provided includes information about key visual quality and composition parameters of the photos. The Pawpularity Score is derived from the profile's page view statistics. This is the target we are aiming to predict.","0a06c4c8":"\n# Petfinder.my - Pawpularity Contest: Simple EDA and fastai starter\n\nIn this competition, we will use machine learning to predict the \"pawpularity\" of a pet using images and metadata. If successful, solutions will be adapted into AI tools that will guide shelters and rescuers around the world to improve the appeal of their pet profiles, automatically enhancing photo quality and recommending composition improvements. As a result, stray dogs and cats can find families much faster, and these tools will help improve animal welfare.\n\nIn this notebook, I will present a quick 'n dirty EDA and a (image-only, for now) fastai starter. \n\n**As of 10\/26, it's currently the best-scoring notebook for the competition, beating 10-fold ensemble models that are bigger while only using a single and smaller model.**\n\nV0: Change get_data(fold) to correct K-Fold, use is_valid for validation data\nV0: change K-Fold to 11\n\nV1: use cleaned dataset 0fold CV:16.225714855\n\nV3: dropped images has 100 Pawpularity\n\nV4: add BCEWithLogitsLossFlatWeight to set different weight for different class\n\nV5: test different weights\n\n\nHere is the rmse in different bins for fold 0 for our best model\n\nFold 0 | Score: 17.45813597262292\\\nbin 0 cv: 37.49209602111998\\\nbin 1 cv: 22.772208169008607\\\nbin 2 cv: 13.207977427382245\\\nbin 3 cv: 10.522804120560147\\\nbin 4 cv: 8.483168163797071\\\nbin 5 cv: 9.485671151318567\\\nbin 6 cv: 11.804965067115697\\\nbin 7 cv: 15.564434605405175\\\nbin 8 cv: 18.247221142730872\\\nbin 9 cv: 23.35765871546634\\\nbin 10 cv: 31.41751025239491\\\nbin 11 cv: 35.20542376392687\\\nbin 12 cv: 39.36972325654612\\\nbin 13 cv: 43.24318517984522\n\nHere is the rmse in different bin for fold 0 if I apply weight as norm_score * 100\n\nFold 0 | Score: 18.592372146023237\\\nbin 0 cv: 44.05764906073716\\\nbin 1 cv: 28.184224977673757\\\nbin 2 cv: 17.87528334312377\\\nbin 3 cv: 15.530264285947883\\\nbin 4 cv: 12.524930627037255\\\nbin 5 cv: 12.766057617128045\\\nbin 6 cv: 12.442131854766735\\\nbin 7 cv: 12.350161312759775\\\nbin 8 cv: 14.791775884854397\\\nbin 9 cv: 17.55045425213173\\\nbin 10 cv: 25.36814697660495\\\nbin 11 cv: 27.56101416173055\\\nbin 12 cv: 30.351763733535304\\\nbin 13 cv: 33.257458912599766\\\n\nIf I set weight only for bin 13 like:\n        weight = torch.where(weight >= 93, 30, 1)\nThe result is\n\nFold 0 | Score: 23.954549314305204\\\nbin 0 cv: 53.36884523690475\\\nbin 1 cv: 35.6026245439023\\\nbin 2 cv: 23.641181526441343\\\nbin 3 cv: 22.686988182680597\\\nbin 4 cv: 19.547315548671225\\\nbin 5 cv: 21.731360981274825\\\nbin 6 cv: 20.46953579887746\\\nbin 7 cv: 17.563321793279\\\nbin 8 cv: 17.185965318359507\\\nbin 9 cv: 16.80244003243514\\\nbin 10 cv: 24.518560469789914\\\nbin 11 cv: 22.199209214749857\\\nbin 12 cv: 24.355108733215193\\\nbin 13 cv: 24.449208502609913\n\nIf I set weight = torch.where(weight >= 93, 512, 1), I got very good rmsp for bin 11-13 as following:\n\nFold 0 | Score: 48.74278342925127\\\nbin 0 cv: 80.58898903204448\\\nbin 1 cv: 66.79452060481921\\\nbin 2 cv: 57.446016762789775\\\nbin 3 cv: 52.970257956221815\\\nbin 4 cv: 48.60457566314422\\\nbin 5 cv: 46.099067746755104\\\nbin 6 cv: 40.55932192012693\\\nbin 7 cv: 35.27638789027249\\\nbin 8 cv: 30.567799892895714\\\nbin 9 cv: 25.14620826375468\\\nbin 10 cv: 18.789601181269767\\\nbin 11 cv: 12.719151272973464\\\nbin 12 cv: 6.599604111712022\\\nbin 13 cv: 7.356627632656249\n","f3ff8f3e":"## Data loading\nAfter my quick 'n dirty EDA, let's load the data into fastai as DataLoaders objects. We're using the normalized score as the label. I use some fairly basic augmentations here.","0b13123c":"We can see that we have our train csv file with the train image names, metadata and labels, the test csv file with test image names and metadata, the sample submission csv with the test image names, and the train and test image folders.\n\nLet's check the train csv file:","2897e0fb":"Let's check an example image to see what it looks like:","1a6cd34f":"Okay, let's check how many images are available in the training dataset:","5cf350dc":"## A look at the data\nLet's start out by setting up our environment by importing the required modules and setting a random seed:","e7e069cd":"Note that the Pawpularity score is an integer, so in addition to being a regression problem, it could also be treated as a 100-class classification problem. Alternatively, it can be treated as a binary classification problem if the Pawpularity Score is normalized between 0 and 1:"}}