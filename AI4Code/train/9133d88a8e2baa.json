{"cell_type":{"67fb40c4":"code","d89ffb8a":"code","8884fb16":"code","dc27bf99":"code","0de1888a":"code","272650de":"code","ba980a09":"code","9106f301":"code","0de354f6":"code","40aaffce":"code","6630226a":"code","5a1d25cb":"code","664a0887":"code","2335d9a1":"code","bb603a60":"code","f1f7f1fa":"code","edee18ac":"code","43cfb1e8":"code","a2977ea3":"code","d7d2ffee":"code","5398e6d9":"code","5d713ecb":"code","8a0a1038":"code","2daaf386":"markdown","ccc16f92":"markdown","92b261c6":"markdown","8dc3cd01":"markdown","e55cfb6b":"markdown","c6438f96":"markdown","bdc9a44c":"markdown","40ea448a":"markdown","fc63ffbd":"markdown","764f599b":"markdown","7909d012":"markdown","00f5b001":"markdown"},"source":{"67fb40c4":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline\nimport scipy\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.options.display.max_colwidth=300","d89ffb8a":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\nprint(df.shape)\n\n# Give more weight to severe toxic \ndf['severe_toxic'] = df.severe_toxic * 2\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndf.sample(5)","8884fb16":"df['y'].value_counts()","dc27bf99":"df = pd.concat([df[df.y>0] , \n                df[df.y==0].sample(int(len(df[df.y>0])*1.5)) ], axis=0).sample(frac=1)\n\nprint(df.shape)","0de1888a":"df['y'].value_counts()","272650de":"def clean(data, col):\n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([\/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    \n    return data","ba980a09":"pipeline = Pipeline(\n    [\n        (\"vect\", TfidfVectorizer(min_df= 3, \n                                 max_df=0.5, \n                                 lowercase=False,\n                                 analyzer = 'char_wb', \n                                 ngram_range = (3,5))),\n        (\"clf\", Ridge()),\n    ]\n)","9106f301":"# Train the pipeline\ndf = clean(df, 'text')\npipeline.fit(df['text'], df['y'])","0de354f6":"df_val = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")","40aaffce":"df_val = clean(df_val, 'less_toxic')\ndf_val = clean(df_val, 'more_toxic')\n\np1 = pipeline.predict(df_val['less_toxic'])\np2 = pipeline.predict(df_val['more_toxic'])","6630226a":"f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}'","5a1d25cb":"df_val['p1'] = p1\ndf_val['p2'] = p2\ndf_val['diff'] = np.abs(p2 - p1)\n\ndf_val['correct'] = (p1 < p2).astype('int')\n","664a0887":"df_val[df_val.correct == 0]['diff'].hist(bins=100)","2335d9a1":"# vect_an = pipeline['vect'].build_analyzer()\n# vocab = pipeline['vect'].vocabulary_\n# [v for v in vect_an(df_val.more_toxic[5247]) if (v not in vocab) & (v.strip() not in pipeline['vect'].stop_words_)]","bb603a60":"\n### Incorrect predictions with similar scores\n\ndf_val[df_val.correct == 0].sort_values('diff', ascending=True).head(20)","f1f7f1fa":"### Incorrect predictions with dis-similar scores\n\n\ndf_val[df_val.correct == 0].sort_values('diff', ascending=False).head(20)","edee18ac":"df_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ndf_sub = clean(df_sub, 'text')\n","43cfb1e8":"# Predict using pipeline\n\nsub_preds = pipeline.predict(df_sub['text'])\n\ndf_sub['score'] = sub_preds","a2977ea3":"# Cases with duplicates scores\n\ndf_sub['score'].count() - df_sub['score'].nunique()","d7d2ffee":"df_sub['score'].value_counts().reset_index()[:10]","5398e6d9":"df_sub['score'].rank().nunique()","5d713ecb":"# Rank the predictions \n\ndf_sub['score']  = scipy.stats.rankdata(df_sub['score'], method='ordinal')\n\nprint(df_sub['score'].rank().nunique())","8a0a1038":"df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","2daaf386":"## 0.816 score by single TF-Idf and Ridge regression on __CLEANED__ data\n\n### Some cleaning patterns shown here - \nhttps:\/\/www.kaggle.com\/samarthagarwal23\/y-patterns-in-nlp-data\n","ccc16f92":"#### Some of these just look incorrectly tagged \n","92b261c6":" \n### Incorrect predictions with similar scores\n### Incorrect predictions with different scores","8dc3cd01":"# Imports","e55cfb6b":"#### Built on top of the amazing notebook here : \n- https:\/\/www.kaggle.com\/julian3833\/jigsaw-incredibly-simple-naive-bayes-0-768\n","c6438f96":"# Create Sklearn Pipeline with \n## TFIDF - Take 'char_wb' as analyzer to capture subwords well\n## Ridge - Ridge is a simple regression algorithm that will reduce overfitting ","bdc9a44c":"# Validate the pipeline ","40ea448a":"# Predict on test data ","fc63ffbd":"# Analyze bad predictions","764f599b":"## Correct the rank ordering","7909d012":"# Training data \n\n## Convert the label to SUM of all toxic labels (This might help with maintaining toxicity order of comments)","00f5b001":"## Reduce the rows with 0 toxicity "}}