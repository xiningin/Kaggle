{"cell_type":{"daac817d":"code","761fee91":"code","0a12592a":"code","d77d700f":"code","731bfd6c":"code","9df1bd26":"code","5bec8a03":"code","b1c544a6":"code","96cb052b":"code","d2bf802a":"code","f3076267":"code","edba775a":"code","4fc1b7e7":"code","d749171b":"code","ab4520c0":"code","7728abcc":"code","b925a1b0":"code","bfd06ec3":"code","3efd3a22":"code","2e1187bd":"code","f7d694dd":"code","ca69a844":"code","ad255ab8":"code","b3a90863":"code","a5462b6b":"code","d3524dba":"code","0734e71f":"code","eddcda8c":"code","5e107eb6":"code","3c296e1c":"code","7c731516":"code","3a60b0bd":"code","8f5f295c":"code","b4633306":"code","f02292be":"code","6acb39b3":"code","498f0760":"code","c5023369":"code","aee4b2da":"code","6320100f":"code","cad80d4a":"code","b59bf3b5":"code","4c1649b3":"code","cda62c0c":"code","c6659ee7":"code","2efa46be":"code","3c811ded":"code","a4735773":"code","af57020b":"code","30426bab":"code","43480047":"code","486069eb":"code","b8d70ddd":"code","d4e66d87":"code","2468a187":"code","0fd5adb0":"code","33c3fe3d":"code","dccaa999":"code","6d235e7d":"code","08879849":"code","8c977e48":"code","3dacfd9b":"code","9708e610":"code","0d479009":"code","125d34c3":"code","accd1ad2":"code","6e591852":"code","8f0d8542":"code","8f776348":"code","0e6b63f4":"markdown","5efcd546":"markdown","a43f9e85":"markdown","64f8e3b8":"markdown","b365902d":"markdown","da47d9db":"markdown","13e41987":"markdown","41683a18":"markdown","633b0c9d":"markdown","e63f5102":"markdown","a548907e":"markdown","6d424774":"markdown","cdf97a08":"markdown","3e656691":"markdown","a522a325":"markdown","8becb3b4":"markdown","4b49546e":"markdown","e78d8243":"markdown","1ecd3a24":"markdown","e7773581":"markdown","8e25bc7b":"markdown","ea15cbee":"markdown","7744956b":"markdown","ad49cc80":"markdown","d66e0d8e":"markdown","77ad24ec":"markdown","e773054c":"markdown","07f0f4c2":"markdown","1d4fecc0":"markdown","c12bf0de":"markdown","4c513a0c":"markdown"},"source":{"daac817d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","761fee91":"import torch","0a12592a":"x = torch.tensor([2,3,3.])\nx","d77d700f":"import torch.nn as nn\n# Input (temp, rainfall, humidity)\ninputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n                  dtype='float32')\n\n# Targets (apples, oranges)\ntargets = np.array([[56, 70], [81, 101], [119, 133], \n                    [22, 37], [103, 119], [56, 70], \n                    [81, 101], [119, 133], [22, 37], \n                    [103, 119], [56, 70], [81, 101], \n                    [119, 133], [22, 37], [103, 119]], \n                   dtype='float32')\n\ninputs = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)","731bfd6c":"from torch.utils.data import DataLoader, TensorDataset\ntrain_ds = TensorDataset(inputs, targets)\n# Define data loader\nbatch_size = 5\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True)","9df1bd26":"def sigmoid(x):\n    return 1\/(1-torch.exp(-x))\n\ntorch.manual_seed(7)\n\nfeatures = torch.randn((1,5))\nweights = torch.randn_like(features)\nbais = torch.randn((1,1))\ny_prob = sigmoid(torch.sum(features*weights) + bais)\ny_prob, features, weights, bais","5bec8a03":"y_prob = sigmoid(torch.mm(features,weights.t()) + bais)\ny_prob","b1c544a6":"y_prob = sigmoid(torch.matmul(features,weights.t()) + bais)\ny_prob, weights.t()","96cb052b":"y_prob = sigmoid(torch.matmul(features,weights.reshape(5,1)) + bais)\ny_prob, weights.reshape(5,1)","d2bf802a":"y_prob = sigmoid(torch.matmul(features,weights.resize(5,1)) + bais)\ny_prob, weights.reshape(5,1)","f3076267":"y_prob = sigmoid(torch.matmul(features,weights.view(5,1)) + bais)\ny_prob, weights.reshape(5,1)","edba775a":"featutes = torch.randn((1,3))\nn_input = featutes.shape[1]\nn_hidden = 2\nn_output = 1\n\nW1 = torch.randn(n_input, n_hidden)\nW2 = torch.randn(n_hidden, n_output)\n\nb1 = torch.randn(1, n_hidden)\nb2 = torch.randn(1, n_output)\n\nh = sigmoid(torch.mm(featutes, W1)+b1)\ny = sigmoid(torch.mm(h, W2)+b2)\ny, h, W1, W2, b1, b2","4fc1b7e7":"%matplotlib inline\n\nimport numpy as np\nimport torch\nimport helper\nimport matplotlib.pyplot as plt\n\nfrom torchvision import datasets, transforms","d749171b":"transform = transforms.Compose([transforms.ToTensor(),\n                               transforms.Normalize((0.5), (0.5)),])\ntrainset = datasets.MNIST('MNIST_data\/', download=True, train=True, transform=transform)\ntrainset","ab4520c0":"trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)","7728abcc":"dataiter = iter(trainloader)\nimages, label = next(dataiter)\nprint(type(images))\nprint(images.shape)\nprint(label.shape)","b925a1b0":"plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')","bfd06ec3":"import torch\n\ndef sigmoid(x):\n    return 1\/(1-torch.exp(-x))\n\nn_input = 784\nn_hidden = 256\nn_output = 10\n\ninputs = images.view(images.shape[0], -1)\n\nW1 = torch.randn(n_input, n_hidden)\nW2 = torch.randn(n_hidden, n_output)\n\nb1 = torch.randn(n_hidden)\nb2 = torch.randn(n_output)\n\nh = sigmoid(torch.mm(inputs, W1)+b1)\ny = torch.mm(h, W2)+b2\n","3efd3a22":"def softmax(x):\n    return torch.exp(x)\/(torch.sum(torch.exp(x), dim=1).view(-1,1))\n\nprob = softmax(y)\nprint(prob.shape)\nprint(prob.sum(dim=1))","2e1187bd":"import torch.nn as nn\n\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.hidden = nn.Linear(784, 256)\n        self.output = nn.Linear(256, 10)\n\n        self.sigmoid =nn.Sigmoid()\n        self.softmax = nn.Softmax(dim=1)\n    \n    def forward(self, x):\n        return self.softmax(self.output(self.sigmoid(self.hidden(x))))","f7d694dd":"model = Network()\nmodel.forward(inputs)","ca69a844":"import torch.nn.functional as F\n\nclass Network_1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.hidden = nn.Linear(784, 256)\n        self.output = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        return F.softmax(self.output(torch.sigmoid(self.hidden(x))), dim=1)","ad255ab8":"model1 = Network_1()\nmodel1.forward(inputs)","b3a90863":"class Network_2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.hidden1 = nn.Linear(784, 128)\n        self.hidden2 = nn.Linear(128, 64)\n        self.output = nn.Linear(64, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.hidden1(x))\n        x = F.relu(self.hidden2(x))\n        x = F.softmax(self.output(x))\n        return x","a5462b6b":"model2 = Network_2()\nx = model2.forward(inputs)","d3524dba":"#this shows how we can define a Sequential Model\nmodel = nn.Sequential(nn.Linear(784, 128),\n                     nn.ReLU(),\n                     nn.Linear(128, 64),\n                     nn.ReLU(),\n                     nn.Linear(64, 10))\n\ncretion = nn.CrossEntropyLoss()\nloss = cretion(x, label)\nprint(loss)","0734e71f":"#this shows how we can define a Sequential Model\nmodel = nn.Sequential(nn.Linear(784, 128),\n                     nn.ReLU(),\n                     nn.Linear(128, 64),\n                     nn.ReLU(),\n                     nn.Linear(64, 10),\n                     nn.LogSoftmax(dim=1))\n\ncretion = nn.CrossEntropyLoss()\nx=model(inputs)\nloss = cretion(x, label)\nprint(loss)","eddcda8c":"torch.set_grad_enabled(True)","5e107eb6":"data = torch.randn((2,2), requires_grad=True)","3c296e1c":"y=data**2","7c731516":"y.grad_fn","3a60b0bd":"z=y.mean()\nz.grad_fn","8f5f295c":"z.backward()\nprint(data.grad)\nprint(data\/2)","b4633306":"#this shows how we can define a Sequential Model\nmodel = nn.Sequential(nn.Linear(784, 128),\n                     nn.ReLU(),\n                     nn.Linear(128, 64),\n                     nn.ReLU(),\n                     nn.Linear(64, 10),\n                     nn.LogSoftmax(dim=1))\n\ncretion = nn.CrossEntropyLoss()\nx=model(inputs)\nloss = cretion(x, label)\nprint(loss)\n\nprint(\"Before\",model[0].weight.grad)\nloss.backward()\nprint(\"After\", model[0].weight.grad)","f02292be":"import torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nprint(\"Initial Weigts:---\", model[0].weight)\n\noptimizer.zero_grad()\n\noutput=model.forward(inputs)\nloss = cretion(output, label)\nloss.backward()\nprint(\"Gradinet--\", model[0].weight.grad)","6acb39b3":"optimizer.step()\nprint(\"Updated weights --\",model[0].weight)","498f0760":"model = nn.Sequential(nn.Linear(784, 128),\n                     nn.ReLU(),\n                     nn.Linear(128, 64),\n                     nn.ReLU(),\n                     nn.Linear(64, 10),\n                     nn.LogSoftmax(dim=1))\n\ncretion = nn.CrossEntropyLoss()\n\nimport torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nepoch = 5\nfor e in range(epoch):\n    running_loss = 0\n    for images, labels in trainloader:\n        inputs = images.view(images.shape[0], -1)\n        optimizer.zero_grad()\n        output=model.forward(inputs)\n        loss = cretion(output, labels)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    else:\n        print(f\"Training Loss:{running_loss\/len(trainloader)}\")","c5023369":"model = nn.Sequential(nn.Linear(784, 128),\n                     nn.ReLU(),\n                     nn.Linear(128, 64),\n                     nn.ReLU(),\n                     nn.Linear(64, 10),\n                     nn.LogSoftmax(dim=1))\n\ncretion = torch.nn.NLLLoss()\n\nimport torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nepoch = 5\nfor e in range(epoch):\n    running_loss = 0\n    for images, labels in trainloader:\n        inputs = images.view(images.shape[0], -1)\n        optimizer.zero_grad()\n        output=model.forward(inputs)\n        loss = cretion(output, labels)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    else:\n        print(f\"Training Loss:{running_loss\/len(trainloader)}\")","aee4b2da":"%matplotlib inline\n\ndef view_classify(img, ps, version=\"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == \"MNIST\":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == \"Fashion\":\n        ax2.set_yticklabels(['T-shirt\/top',\n                            'Trouser',\n                            'Pullover',\n                            'Dress',\n                            'Coat',\n                            'Sandal',\n                            'Shirt',\n                            'Sneaker',\n                            'Bag',\n                            'Ankle Boot'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n    \n\nimages, labels = next(iter(trainloader))\n\nimg = images[0].view(1, 784)\n\nwith torch.no_grad():\n    logits = model.forward(img)\n    \nps = F.softmax(logits, dim=1)\nview_classify(img.view(1,28,28), ps)","6320100f":"from torch import nn, optim\nfrom torchvision import transforms, datasets\nimport torch.nn.functional as F\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np","cad80d4a":"transform = transforms.Compose([transforms.ToTensor(),\n                               transforms.Normalize((0.5), (0.5)),])\ntrainset = datasets.FashionMNIST('FashionMNIST_data\/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\nprint(trainset)","b59bf3b5":"testset = datasets.FashionMNIST('FashionMNIST_data\/test\/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\ntestset, testloader","4c1649b3":"model = nn.Sequential(nn.Linear(784, 256),\n                      nn.ReLU(),\n                      nn.Linear(256, 128),\n                      nn.ReLU(),\n                      nn.Linear(128, 64),\n                      nn.ReLU(),\n                      nn.Linear(64, 10),\n                      nn.LogSoftmax(dim=1))\nprint(model)\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","cda62c0c":"epoch = 5\n\nfor e in range(epoch):\n    running_loss = 0\n    for images, labels in trainloader:\n        images=images.view(images.shape[0], -1)\n        inp = model(images)\n        loss = criterion(inp, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss +=loss.item()\n    else:\n        print(f\"Training Loss:{running_loss}\")","c6659ee7":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\ndef view_classify(img, ps, version=\"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == \"MNIST\":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == \"Fashion\":\n        ax2.set_yticklabels(['T-shirt\/top',\n                            'Trouser',\n                            'Pullover',\n                            'Dress',\n                            'Coat',\n                            'Sandal',\n                            'Shirt',\n                            'Sneaker',\n                            'Bag',\n                            'Ankle Boot'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n    \n\nimages, labels = next(iter(testloader))\n\nimg = images[0].view(1, 784)\n\nwith torch.no_grad():\n    logits = model.forward(img)\n    \nps = torch.exp(logits)\nview_classify(img.view(1,28,28), ps, version='Fashion')","2efa46be":"top_p, top_class = ps.topk(1, dim=1)\nprint(f\"Predicted Class is: {top_class[0][0]}\")\nprint(f\"Predicted Class Probability: {top_p[0][0]}\")","3c811ded":"equals = top_class == labels\naccuracy = torch.mean(equals.type(torch.FloatTensor))\nprint(f\"Accuracy: {accuracy.item()*100}%\")","a4735773":"epoch = 30\nsteps = 0\n\ntrain_losses, test_losses = [], []\nfor e in range(epoch):\n    running_loss = 0\n    for images, labels in trainloader:\n        images=images.view(images.shape[0], -1)\n        inp = model(images)\n        loss = criterion(inp, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss +=loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        with torch.no_grad():\n            for images, labels in trainloader:\n                inp=images.view(images.shape[0], -1)\n                log_ps = model.forward(inp)\n                test_loss += criterion(log_ps, labels)\n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class = labels\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n        \n        print(\"Epoch: {}\/{}..\".format(e+1, epoch),\n             \"Training Loss: {:.3f}..\".format(running_loss\/len(trainloader)),\n              \"Test Loss {:.3f}..\".format(test_loss\/len(testloader)),\n              \"Test Accuarcy: {:.3f}..\".format(accuracy\/len(testloader)))\n            ","af57020b":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(test_losses, label=\"Testing Loss\")\nplt.legend(frameon=False)","30426bab":"model = nn.Sequential(nn.Linear(784, 256),\n                      nn.ReLU(),\n                      nn.Dropout(p=0.2),\n                      nn.Linear(256, 128),\n                      nn.ReLU(),\n                      nn.Dropout(p=0.2),\n                      nn.Linear(128, 64),\n                      nn.ReLU(),\n                      nn.Dropout(p=0.2),\n                      nn.Linear(64, 10),\n                      nn.LogSoftmax(dim=1))\nmodel","43480047":"epoch = 30\nsteps = 0\n\ntrain_losses, test_losses = [], []\nfor e in range(epoch):\n    running_loss = 0\n    for images, labels in trainloader:\n        images=images.view(images.shape[0], -1)\n        inp = model(images)\n        loss = criterion(inp, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss +=loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        with torch.no_grad():\n            model.eval()\n            for images, labels in trainloader:\n                inp=images.view(images.shape[0], -1)\n                log_ps = model.forward(inp)\n                test_loss += criterion(log_ps, labels)\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class = labels\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        model.train()\n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n        \n        print(\"Epoch: {}\/{}..\".format(e+1, epoch),\n             \"Training Loss: {:.3f}..\".format(running_loss\/len(trainloader)),\n              \"Test Loss {:.3f}..\".format(test_loss\/len(testloader)),\n              \"Test Accuarcy: {:.3f}..\".format(accuracy\/len(testloader)))\n            ","486069eb":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(test_losses, label=\"Testing Loss\")\nplt.legend(frameon=False)","b8d70ddd":"print(\"our Model: \\n\\n\", model, \"\\n\")\nprint(\"The state dict keys: \\n\\n\", model.state_dict().keys())","d4e66d87":"torch.save(model.state_dict(), 'checkpoint.path')","2468a187":"state_dict= torch.load('checkpoint.path')\nprint(state_dict.keys())","0fd5adb0":"model.load_state_dict(state_dict)","33c3fe3d":"from torchvision import datasets, transforms\nimport torch\nimport matplotlib.pyplot as plt","dccaa999":"transform = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), \n                                transforms.ToTensor(), \n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\ntest_dataset = datasets.ImageFolder(\"..\/input\/cat-and-dog\/test_set\", transform=transform)\ntestloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)","6d235e7d":"transform = transforms.Compose([transforms.RandomRotation(30), transforms.RandomResizedCrop(224),\n                                transforms.RandomHorizontalFlip(),transforms.ToTensor(), \n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\ntrain_dataset = datasets.ImageFolder(\"..\/input\/cat-and-dog\/training_set\", transform=transform)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)","08879849":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\ndata_iter = iter(trainloader)\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,4), ncols=4)\nfor ii in range(4):\n    ax = axes[ii]\n    imshow(images[ii], ax=ax, normalize=False)","8c977e48":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\ndata_iter = iter(testloader)\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,4), ncols=4)\nfor ii in range(4):\n    ax = axes[ii]\n    imshow(images[ii], ax=ax, normalize=False)","3dacfd9b":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport torch\nfrom torchvision import datasets, transforms, models\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.autograd import Variable\nimport time","9708e610":"train_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\ntest_dataset = datasets.ImageFolder(\"..\/input\/cat-and-dog\/test_set\", transform=test_transforms)\ntestloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n\ntrain_dataset = datasets.ImageFolder(\"..\/input\/cat-and-dog\/test_set\", transform=train_transforms)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)","0d479009":"model = models.densenet121(pretrained=True)\nmodel","125d34c3":"for param in model.parameters():\n    param.requires_grad = False","accd1ad2":"from collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(1024, 500)),\n                          ('relu', nn.ReLU()),\n                          ('fc2', nn.Linear(500, 2)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.classifier = classifier","6e591852":"for device in ['cpu', 'cuda']:\n\n    criterion = nn.NLLLoss()\n    # Only train the classifier parameters, feature parameters are frozen\n    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\n    model.to(device)\n\n    for ii, (inputs, labels) in enumerate(trainloader):\n\n        # Move input and label tensors to the GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        start = time.time()\n\n        outputs = model.forward(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        if ii==3:\n            break\n        \n    print(f\"Device = {device}; Time per batch: {(time.time() - start)\/3:.3f} seconds\")\n","8f0d8542":"# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nmodel = models.densenet121(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.classifier = nn.Sequential(nn.Linear(1024, 256),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(256, 2),\n                                 nn.LogSoftmax(dim=1))\n\ncriterion = nn.NLLLoss()\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\nmodel.to(device);","8f776348":"epochs = 1\nsteps = 0\nrunning_loss = 0\nprint_every = 5\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        #steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n        if True:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    \n                    test_loss += batch_loss.item()\n                    \n                    # Calculate accuracy\n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                    \n            print(f\"Epoch {epoch+1}\/{epochs}.. \"\n                  f\"Train loss: {running_loss\/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss\/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy\/len(testloader):.3f}\")\n            running_loss = 0\n            model.train()","0e6b63f4":"##### In the following, we do both training followed by testing","5efcd546":"# Dogs and Cats dataset","a43f9e85":"## Visualization\n\nwe use frameon=False, we will remove the frame surronding the legend","64f8e3b8":"# MNIST","b365902d":"Now we need to replace the densenet121 classifier with our classifier, so we initialize our model","da47d9db":"## Downloading Model, Transforming data","13e41987":"## Training using MNIST dataset\n\nIt uses a Sequential Neural Network, Cross Entropy Loss and Stochastic Gradeint Descent Optimizer","41683a18":"We can see the difference in time between using a GPU and not using a GPU","633b0c9d":"## Training using MNIST dataset\n\nIt uses a Sequential Neural Network, Negative Likelihood Loss and Stochastic Gradeint Descent Optimizer","e63f5102":"Below shows we can calculate the gradient using the .backward() method","a548907e":"#### Visualization","6d424774":"# Saving Models and Loading them back","cdf97a08":"## Training","3e656691":"#### Loading Dataset","a522a325":"## Visulalization","8becb3b4":"#### To display the model","4b49546e":"# Fashion-MNIST","e78d8243":"## Model Creation, Loss and Oprimizer declaration","1ecd3a24":"## to load the saved model","e7773581":"## Visualiztion\n\nFollowing shows our prediction vs the input image","8e25bc7b":"The following shows the gradient function is Sqaure, we can make any changes and it will change accordingly.","ea15cbee":"## Validation\n\nWe can use topk() to get the most likely value corresponding to the prediction.\n\ntopk(num_of_values), returns two value: the most likely value and its corresponding probability","7744956b":"The derivative of sum of squares is data\/2, and hence we can see that data.grad and data\/2 has same value","ad49cc80":"Since densenet121 has been trained on ImageNet, and it has 1000 output layers, so we need to re-train the classifier, to only has 2 output layers i.e. dog and cat\n\nSo for that we need to freeze the input layers of the classifier","d66e0d8e":"## Handling Overfitting\n\nFrom the above data it is very clear, that the model is overfitting as the train loss is decreassing but the test loss is increading or decreasing by very little.\n\nSo to Handle overfitting, we add Dropout layer to our model, so the model need to predict between weights, hence it will predict better on validation or test data\n\np \u2013 probability of an element to be zeroed. Default: 0.5","77ad24ec":"#### to load the saved model to a network variable","e773054c":"In the below we can see that, we have changed the function to Mean and hence the gradient function is MeanBackward0","07f0f4c2":"## Training and Validation on model impoloying Dropout Layers\n\nWe use model.eval() when we want to do processing on Test or Validation dataset, and then to turn on Dropout layers, we use model.train()","1d4fecc0":"To get the accuacy, we need to make sure that the ByteTensor returned should be converted to FloatTesnor","c12bf0de":"## to Save the model","4c513a0c":"# Transfer Learning\n\nUsing the pre-trained model from the torchvision.module"}}