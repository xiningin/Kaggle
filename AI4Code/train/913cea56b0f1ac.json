{"cell_type":{"93df76ac":"code","9989e6a0":"code","52083d47":"code","07403bb8":"code","a883a36b":"code","bb510f02":"code","fa128e24":"code","7b39a73e":"code","8a37e3e2":"code","7e2de84b":"code","86954045":"code","20567934":"code","1b224325":"code","6832446d":"code","3e6d5eef":"code","6ffb6c43":"code","72b71e2a":"code","f4255ebc":"code","6687b9f4":"code","a6b27a9e":"code","4eedb83d":"code","e2b2b424":"code","f91003a6":"code","3a885b6e":"code","7098ec28":"code","664172c4":"code","729511b1":"code","bcf21e95":"markdown","1635706e":"markdown","ec487491":"markdown","9df2ef47":"markdown","a80401f8":"markdown","561c0d33":"markdown","aa73189f":"markdown","525da3c2":"markdown","c036efb2":"markdown"},"source":{"93df76ac":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense,AveragePooling2D,Lambda\nfrom tensorflow.keras.models import  Model\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import SparseCategoricalAccuracy\nfrom tensorflow.keras.optimizers import Nadam, Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image, ImageOps\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport tensorflow as tf\nimport torch\nfrom keras.models import Sequential\ntorch.cuda.empty_cache()\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom os.path import dirname, basename\nimport glob\nimport random\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam,SGD,RMSprop\nfrom sklearn.preprocessing import LabelBinarizer\nimport os\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","9989e6a0":"# df = pd.read_csv('')","52083d47":"X_train = []\ny_train = []\n\nX_valid = []\ny_valid = []\n\nX_test = []\ny_test = []\n\ncount_train = []\ncount_valid = []\ncount_test = []\n\nSIZE_IMAGE = [90,90]\n\ngen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.01, zoom_range=0.1, \n            channel_shift_range=10., horizontal_flip=True)\n\nlabels = glob.glob( '..\/input\/triplesmarket\/dataset5\/dataset\/*\/')\nlist_labels = [basename(dirname(lbl)) for lbl in labels]\n\nfor idx in range(len(list_labels)):\n    image_paths = glob.glob('..\/input\/triplesmarket\/dataset5\/dataset\/'+str(list_labels[idx])+'\/*.jpg')\n    random.shuffle(image_paths)\n    c_train=0\n    c_valid=0\n    c_test=0\n    gate = 0\n    for path in image_paths[:int(len(image_paths)*.2)]:\n        if gate%2 == 0:\n            c_valid+=1\n            imagee = np.array(Image.open(path).resize(SIZE_IMAGE))\n            X_valid.append(imagee)\n            y_valid.append(str(list_labels[idx]))\n        if gate%2 != 0:\n            c_test+=1\n            imagee = np.array(Image.open(path).resize(SIZE_IMAGE))\n            X_test.append(imagee)\n            y_test.append(str(list_labels[idx]))\n        gate +=1\n\n    for path in image_paths[int(len(image_paths)*.2):]:\n        \n        imagee = Image.open(path).resize(SIZE_IMAGE)\n        \n        image = np.expand_dims(imagee,0)\n        aug_iter = gen.flow(image)\n        \n        aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(10)]\n        for img in aug_images:\n            c_train+=1\n            X_train.append(img)\n            y_train.append(str(list_labels[idx]))\n    count_train.append(c_train)\n    count_valid.append(c_valid)\n    count_test.append(c_test)","07403bb8":"fig = plt.figure(figsize=(10, 10))\nindex = 1\nx = random.randint(0,len(X_train)-13)\nfor i in range(x, x+12):\n    fig.add_subplot(3, 4, index)\n    fig.tight_layout()\n    plt.imshow(X_train[i])\n    index+=1\nplt.show()","a883a36b":"%matplotlib inline\n\nx = np.arange(len(list_labels))  \nwidth = 0.3 \n\nfig, ax = plt.subplots(figsize=(20,7))\nfig. tight_layout(pad=3.0)\n\nrects1 = ax.bar(x  , [x\/\/10 for x in count_train], width, label='Train')\nrects2 = ax.bar(x + width , count_valid, width, label='Valid')\nrects3 = ax.bar(x + (width*2), count_test, width, label='Test')\n\nax.set_title('Train-Valid-Test before Generate')\nax.set_xticks(x)\nax.set_xticklabels(list_labels,rotation = 45, ha=\"right\")\nax.legend()\n\nax.bar_label(rects1, padding=3)\nax.bar_label(rects2, padding=3)\nax.bar_label(rects3, padding=3)\n\nplt.show()","bb510f02":"idx = random.randint(0,len(X_train))\nplt.imshow(X_train[idx])\nplt.title(y_train[idx])","fa128e24":"data_train = list(zip(X_train,y_train))\n\nrandom.shuffle(data_train)\nX_train_ran = []\ny_train_ran = []\nfor val in data_train :\n    X_train_ran.append(val[0])\n    y_train_ran.append(val[1])\n\n    \ndata_valid = list(zip(X_valid,y_valid))\n\nrandom.shuffle(data_valid)\nX_valid_ran = []\ny_valid_ran = []\nfor val in data_valid :\n    X_valid_ran.append(val[0])\n    y_valid_ran.append(val[1])\n    \ndata_test = list(zip(X_test,y_test))\n\nrandom.shuffle(data_test)\nX_test_ran = []\ny_test_ran = []\nfor val in data_test :\n    X_test_ran.append(val[0])\n    y_test_ran.append(val[1])","7b39a73e":"for i in range(len(X_train_ran)):\n    image_without_alpha_t = X_train_ran[i][:,:,:3]\n    X_train_ran[i] = image_without_alpha_t\n    \nfor i in range(len(X_valid_ran)):\n    image_without_alpha_v = X_valid_ran[i][:,:,:3]\n    X_valid_ran[i] = image_without_alpha_v\n    \nfor i in range(len(X_test_ran)):\n    image_without_alpha_v = X_test_ran[i][:,:,:3]\n    X_test_ran[i] = image_without_alpha_v","8a37e3e2":"label = {\n    \"ao-len-cardigan\": 0,\n    \"quan-nu\": 1,\n    \"quan-nam\": 2,\n    \"dam-nu\": 3,\n    \"ao-nguc\": 4,\n    \"bo-vest-nu\": 5,\n    \"ao-nu\": 6,\n    \"trang-phuc-cosplay\": 7,\n    \"ao-dai\": 8,\n    \"do-boi-nam\": 9,\n    \"vay-chong-nang-khau-trang\": 10,\n    \"do-hoa-trang-trang-phuc-cosplay-nam\": 11,\n    \"ao-polo-nam\": 12,\n    \"thoi-trang-nu-quan-dai\": 13,\n    \"quan-jogger-nam\": 14,\n    \"ao-len-nam\": 15,\n    \"dam-dao-pho\": 16,\n    \"quan-vo-nu\": 17,\n    \"do-lot-do-ngu-nam\": 18,\n    \"ao-hoodie-nu\": 19,\n    \"ao-vest-blazer-nu\": 20,\n    \"ao-khoac-kieu-nam\": 21,\n    \"do-mac-nha\": 22,\n    \"ao-thun-ba-lo\": 23\n}","7e2de84b":"for i in range(len(y_train_ran)):\n    y_train_ran[i] = label[y_train_ran[i]]\n    \nfor i in range(len(y_valid_ran)):\n    y_valid_ran[i] = label[y_valid_ran[i]]\n    \nfor i in range(len(y_test_ran)):\n    y_test_ran[i] = label[y_test_ran[i]]","86954045":"catLB = LabelBinarizer()\ncatLabels_train = catLB.fit_transform(y_train_ran)\ncatLabels_valid = catLB.fit_transform(y_valid_ran)","20567934":"catLabels_train","1b224325":"x_train_stack = np.stack(X_train_ran)\ny_train_stack = np.stack(catLabels_train)\n\nx_valid_stack = np.stack(X_valid_ran)\ny_valid_stack = np.stack(catLabels_valid)","6832446d":"class FashionNet:\n    @staticmethod\n    def build_category_model(inputs,numCat):\n        \n        x = Conv2D(32, (3, 3),strides=2, padding=\"same\",activation='relu')(inputs)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(3, 3))(x)\n        \n        x = Conv2D(64, (3, 3),strides=1, padding=\"same\",activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.6)(x)\n        x = Conv2D(64, (3, 3), padding=\"same\",activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(3, 3))(x)\n        x = Dropout(0.5)(x)\n        \n        x = Conv2D(128, (3, 3), padding=\"same\",activation='relu',kernel_regularizer =tf.keras.regularizers.l2( l=0.01))(x)\n        x = Dropout(0.4)(x)\n        x = BatchNormalization()(x)\n        \n        x = Conv2D(256, (3, 3), padding=\"same\",activation='relu',kernel_regularizer =tf.keras.regularizers.l2( l=0.01))(x)\n        x = Dropout(0.1)(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D(pool_size=(3, 3))(x)\n        \n        x = Flatten()(x)\n        x = Dense(256, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dense(numCat, activation='softmax',name='category_output')(x)\n        \n        return x\n    @staticmethod\n    def build(height,width,channels,numCat):\n        inputShape = (height,width,channels)\n        \n        inputs = Input(shape=inputShape)\n        \n        categoryBranch = FashionNet.build_category_model(inputs,numCat)\n        \n        model = Model(inputs=inputs , outputs=[categoryBranch],name='fashionnet')\n        \n        return model","3e6d5eef":"EPOCHS = 100\nINIT_LR = 1e-3\nBS = 128","6ffb6c43":"model = FashionNet.build(90,90,3,numCat=len(catLB.classes_))\n\nlosses = {\n \"category_output\": \"categorical_crossentropy\",\n}\nlossWeights = {\"category_output\": 1.0}\n\nopt = Adam(lr=INIT_LR, decay=INIT_LR\/EPOCHS)\n\nmodel.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,metrics=[\"accuracy\"])\n\nprint(model.summary())\n\nkeras_callbacks   = [\n#           EarlyStopping( patience=20, verbose=1, restore_best_weights=False),\n    \n#           ReduceLROnPlateau( factor=0.1, patience=10, min_lr=1e-6, verbose=1),\n    \n          ModelCheckpoint('model\/sss.hdf5',monitor = 'val_loss',save_best_only = True, verbose = 1 )\n        ]","72b71e2a":"from collections import Counter\nitemCt = Counter(y_train_ran)\nmaxCt = float(max(itemCt.values()))\ncw = {clsID : maxCt\/numImg for clsID, numImg in itemCt.items()}","f4255ebc":"cw","6687b9f4":"from sklearn.utils import class_weight\n\n\nhistory = model.fit(x_train_stack,y_train_stack,\n              validation_data=(x_valid_stack,y_valid_stack),\n              steps_per_epoch=len(x_train_stack)\/\/BS,\n              shuffle = True,\n              epochs=EPOCHS,\n              validation_steps=len(x_valid_stack)\/\/BS,\n              batch_size=BS,\n              callbacks=[keras_callbacks],\n              class_weight=cw)","a6b27a9e":"model = load_model('model\/sss.hdf5')","4eedb83d":"y_hat = [np.argmax(model.predict(np.array([img]))) for img in X_test_ran]","e2b2b424":"from sklearn.metrics import f1_score\nf1_score(y_test_ran, y_hat, average='micro')","f91003a6":"fig = plt.figure(figsize=(14, 14))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    idx = random.randint(0,len(X_test)-1)\n    img = X_test[idx]\n    y_hat = np.argmax(model.predict(np.array([img])))\n    lbl = ''\n    truth = ''\n    for key, value in label.items():\n        if str(y_hat) == str(value):\n            lbl = key\n        if str(y_test_ran[idx]) == str(value):\n            truth = key\n    fig.add_subplot(rows, columns, i)\n    fig.tight_layout()\n    plt.imshow(img)\n    plt.title(lbl+'\/'+str(y_test[idx]))\nplt.show()","3a885b6e":"from matplotlib.pyplot import figure\n\nfigure(figsize=(10, 8), dpi=80)\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 5])\nplt.legend(loc='lower right')\n\nfigure(figsize=(10, 8), dpi=80)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy') \nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0 ,1])\nplt.legend(loc='lower right')","7098ec28":"y_hat = []\nfor img in X_test_ran:\n    tmp = model.predict(np.array([img]))\n    y_hat.append(tmp)\ny_hat = np.array(y_hat)","664172c4":"def arg_sort_desc(ar):\n    P = np.argsort(ar)\n    Q=[]\n    for i in range(P.shape[0]):\n        p=list(P[i,:][::-1])\n        Q.append(p)\n    R=np.array(Q)\n    return(P)\n\ndef top_n_accuracy(A,C,n):\n    B = arg_sort_desc(C)\n    topn = B[:,:,:n]\n    A = np.array(A)\n    return np.mean(np.array([1 if A[k] in topn[k] else 0 for k in range(len(topn))]))","729511b1":"top_n_accuracy(y_test_ran,y_hat,5)","bcf21e95":"### Change label in Train&Valid set to int","1635706e":"### Random shuffle dataset","ec487491":"## Load given csv file && dip into it","9df2ef47":"## Import Library","a80401f8":"## Load dataset \n* Load images (resize to [90,90] ) and labels from dir\n* Divive 8\/1\/1 || Train-Valid-Test \n* Generate images in Train Set by ImageDataGenerator","561c0d33":"## Calculate Top-N Accuracy (1;3;5)","aa73189f":"### Visualize data set","525da3c2":"### Random show sample image in train set","c036efb2":"# Classify Clothes into 24 classes Using CNN\n> author: LHK    \n> date: 29\/07\/2021"}}