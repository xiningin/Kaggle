{"cell_type":{"46ad550b":"code","daf1c101":"code","ad3abb09":"code","54f6377a":"code","32d09ae1":"code","11eccb18":"code","5e9b3a98":"code","ce63268e":"code","152521a0":"code","f5036db1":"markdown","4b5c9fc1":"markdown","d82c4ba7":"markdown","92aebbe0":"markdown"},"source":{"46ad550b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport re\n\n%matplotlib inline","daf1c101":"df_train = pd.read_csv('..\/input\/kuzushiji-recognition\/train.csv')\nunicode_map = {codepoint: char for codepoint, char in \n               pd.read_csv('..\/input\/kuzushiji-recognition\/unicode_translation.csv').values}","ad3abb09":"def convert_labels_set(labels_str):\n    labels = []\n    for one_label_str in re.findall(r'U\\+\\S+\\s\\S+\\s\\S+\\s\\S+\\s\\S+', labels_str):\n        charcode, x, y, w, h = one_label_str.split(' ')\n        labels.append([charcode, int(x), int(y), int(w), int(h)])\n    return labels\n\ndef visualize_training_data(image_path, labels):\n    fs = 8\n    # Read image\n    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    for label in convert_labels_set(labels):\n        _, x, y, w, h = label\n        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3)\n    return img","54f6377a":"n_sheets = 2\n\nfor _ in range(n_sheets):\n    img_filename, labels = df_train.values[np.random.randint(len(df_train))]\n    viz_img = visualize_training_data('..\/input\/kuzushiji-recognition\/train_images\/{}.jpg'.format(img_filename), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img_filename)\n    plt.imshow(viz_img)\n    plt.show()","32d09ae1":"n_labels = 0\nchars_counts = {}\n\nfor labels_set in df_train.values[:, 1]:\n    if type(labels_set) is not str:\n        continue\n\n    labels = convert_labels_set(labels_set)\n    n_labels += len(labels)\n    for label in labels:\n        try:\n            chars_counts[label[0]] += 1\n        except KeyError:\n            chars_counts.update({label[0]: 1})","11eccb18":"chars_counts_list = [chars_counts[k] for k in chars_counts]\nn_classes = len([k for k in chars_counts])","5e9b3a98":"print('Number of labels:                  {}'.format(n_labels))\nprint('Number of classes:                 {}'.format(n_classes))\nprint('Min max number of items per class: {} {}'.format(np.min(chars_counts_list), np.max(chars_counts_list)))\nprint('Median number of items per class:  {}'.format(np.median(chars_counts_list)))\nprint('Mean number of items per class:    {}'.format(np.mean(chars_counts_list)))","ce63268e":"def get_char_images_from_sheet(src_image_path, labels_str, blur_kernel_size=3, img_size=64):\n    src_img = cv2.imread(src_image_path, cv2.IMREAD_COLOR)\n\n    char_imgs = []\n    for label in convert_labels_set(labels_str):\n        char_img = np.zeros((img_size, img_size), dtype=np.uint8)\n        _, x, y, w, h = label\n\n        label_img = src_img[y:y + h, x:x + w, :]\n        label_img = cv2.GaussianBlur(label_img, \n                                     (blur_kernel_size, blur_kernel_size), \n                                     cv2.BORDER_DEFAULT)\n        label_img = cv2.cvtColor(label_img, cv2.COLOR_RGB2GRAY)\n        _, label_img = cv2.threshold(label_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        label_img = 255 - label_img\n        \n        if w > h:\n            label_img = cv2.resize(label_img, (img_size, int(img_size * h \/ w)))\n            dy = int((img_size - int(img_size * h \/ w)) \/ 2)\n            char_img[dy:dy + int(img_size * h \/ w), :] += label_img\n        \n        else:\n            label_img = cv2.resize(label_img, (int(img_size * w \/ h), img_size))            \n            dx = int((img_size - int(img_size * w \/ h)) \/ 2)\n            char_img[:, dx:dx + int(img_size * w \/ h)] += label_img\n        \n        char_imgs.append(char_img)\n    return char_imgs","152521a0":"img_filename, labels = df_train.values[np.random.randint(len(df_train))]\n\nchar_imgs = get_char_images_from_sheet('..\/input\/kuzushiji-recognition\/train_images\/{}.jpg'.format(img_filename), labels)\n\nfor i in np.random.choice(len(char_imgs), 10):\n    plt.figure(figsize=(2, 2))\n    plt.imshow(char_imgs[i], cmap='Greys')\n    plt.show()","f5036db1":"## Kuzushiji images mining","4b5c9fc1":"## Statistics","d82c4ba7":"## Visualisiung the training data\nDon't forget to add dataset!\nhttps:\/\/www.kaggle.com\/c\/kuzushiji-recognition","92aebbe0":"# Converting scanned kuzushiji sheets to bw images with a single character   "}}