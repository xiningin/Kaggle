{"cell_type":{"c2e0eff6":"code","f92f2f3e":"code","a168173c":"code","89e40457":"code","33a46ac8":"code","9b5a7da7":"code","a8f4d857":"code","45df8cc8":"code","fc1b7326":"code","0d5ab76c":"code","25fec8d4":"code","92b0ef54":"code","76e4644c":"code","6fb60fe7":"code","5330d2fe":"code","be225dbc":"code","28f6cb49":"code","3086cfdb":"code","907901f4":"code","a4037358":"markdown","e24d66f3":"markdown","82f2edf6":"markdown","aef4d1f9":"markdown","31699718":"markdown","6b8ebd0d":"markdown","60103eb6":"markdown","06802765":"markdown","dda6a94b":"markdown"},"source":{"c2e0eff6":"import pandas as pd\nimport category_encoders as ce\nfrom sklearn.preprocessing import LabelEncoder\n\nimport numpy as np\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate, GridSearchCV\nfrom sklearn import metrics\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4\n\ntarget = 'Survived'\nIDcol = 'PassengerId'","f92f2f3e":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntrain.head()","a168173c":"test = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")\ntest.head()","89e40457":"def label_encoder(c):\n    lc = LabelEncoder()\n    return lc.fit_transform(c)\n\ndef feature_engineering(df):\n    data = df\n    # Age fillna with mean age for each class\n    age_map = data[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\n    data.Age = data.Age.fillna(data.Pclass.map(age_map['Age']))\n    \n    data['Embarked'] = data['Embarked'].fillna('X')\n\n    fare_map = data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n    data['Fare'] = data['Fare'].fillna(data['Pclass'].map(fare_map['Fare']))\n\n    # Cabin, fillna with 'X' and take first letter\n    data.Cabin = data.Cabin.map(lambda x: str(x)[0].strip().lower())\n\n    # Ticket, fillna with 'X', split string and take first split \n    data.Ticket = data.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n    # Fare, fillna with mean value \n    # (THE ONLY FILLNA LEFT BECAUSE HERE WE USE TEST DATASET - LightAutoML can't do it in real life because of strict distinction between train and test stages)\n    data.Fare = data.Fare.fillna(data.Fare.mean())\n    \n#     # Name, take only surnames\n#     data.Name = data.Name.map(lambda x: str(x).split(',')[0])\n    \n#     data['relatives'] = data['SibSp'] + data['Parch']\n#     data.loc[data['relatives'] > 0, 'travelled_alone'] = 'No'\n#     data.loc[data['relatives'] == 0, 'travelled_alone'] = 'Yes'\n    \n    label_cols = ['Ticket']\n#     label_cols = ['Name', 'Ticket']\n    label_encoded_df = data[label_cols].apply(label_encoder)\n    data = data.join(label_encoded_df.add_suffix(\"_lb\"))\n    \n    onehot_features = ['Pclass', 'Sex', 'Cabin', 'Embarked']\n    cat_oh = pd.get_dummies(data[onehot_features])\n    data = data.join(cat_oh.add_suffix(\"_oh\"))\n    \n    data['FirstName'] = data.Name.map(lambda x: str(x).split(',')[0])\n    data['Surname'] = data.Name.map(lambda x: str(x).split(',')[1])\n    \n    count_encode_features = [\"FirstName\", \"Surname\"]\n    for col in count_encode_features:\n        data['Counter_' + col] = data[col].map(data.groupby(col)['PassengerId'].count().to_dict())\n#     count_en = ce.CountEncoder()\n#     cat_ce = count_en.fit_transform(data[count_encode_features])\n#     data = data.join(cat_ce.add_suffix(\"_ce\"))\n\n    data.drop(columns=count_encode_features+[\"Name\"], inplace=True)\n\n    data.drop(columns=label_cols+onehot_features, inplace=True)\n    \n    return data","33a46ac8":"final_train_data = feature_engineering(train)\nfinal_test_data = feature_engineering(test)\nfor col in (set(final_train_data.columns).symmetric_difference(final_test_data.columns)):\n    if col not in final_train_data:\n        final_train_data[col] = 0\n    elif col != 'Survived':\n        final_test_data[col] = 0","9b5a7da7":"final_train_data.head()","a8f4d857":"#Choose all predictors except target & IDcols\npredictors = [x for x in final_train_data.columns if x not in [target, IDcol]]\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42, sampling_strategy=1.0)\ntrain_x = final_train_data[predictors]\ntrain_y = final_train_data[target]\ntrain_x, train_y = sm.fit_resample(train_x, train_y)","45df8cc8":"def modelfit(alg, X, Y,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(X.values, label=Y.values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(X, Y,eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(X)\n    dtrain_predprob = alg.predict_proba(X)[:,1]\n        \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(Y, dtrain_predprob))\n    print(metrics.classification_report(Y.values, dtrain_predictions))\n\n    plot_importance(alg)","fc1b7326":"xgb1 = XGBClassifier(\n    learning_rate=0.1,\n    n_estimators=200,\n    max_depth=5,\n    min_child_weight=1,\n    gamma=0,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    use_label_encoder=False,\n    objective= 'binary:logistic',\n    nthread=4,\n    scale_pos_weight=1,\n    seed=27\n)\n\nmodelfit(xgb1, train_x, train_y)","0d5ab76c":"param_test1 = {\n    'max_depth':range(7,12,2),\n    'min_child_weight':range(1,6,2)\n}\ngsearch1 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=5,\n        min_child_weight=1,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test1,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n\n# gsearch1.fit(train_x,train_y)\n# gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_","25fec8d4":"param_test2 = {\n    'max_depth':[6,7,8],\n    'min_child_weight':[0,1,2]\n}\ngsearch2 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=5,\n        min_child_weight=1,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test2,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n\n# gsearch2.fit(train_x,train_y)\n# gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_","92b0ef54":"param_test3 = {\n    'gamma':[i\/10.0 for i in range(0,5)]\n}\ngsearch3 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test3,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch3.fit(train_x,train_y)\n# gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_","76e4644c":"param_test4 = {\n    'colsample_bytree':[i\/10.0 for i in range(7,9)],\n    'subsample':[i\/10.0 for i in range(7,9)]\n}\ngsearch4 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0.4,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test4,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch4.fit(train_x,train_y)\n# gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_","6fb60fe7":"param_test5 = {\n    'colsample_bytree':[i\/100.0 for i in range(75,90,5)],\n    'subsample':[i\/100.0 for i in range(75,90,5)]\n}\ngsearch5 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0.4,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test5,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch5.fit(train_x,train_y)\n# gsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_","5330d2fe":"param_test6 = {\n    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n}\ngsearch6 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0.4,\n        subsample=0.75,\n        colsample_bytree=0.85,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test6,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch6.fit(train_x,train_y)\n# gsearch6.cv_results_, gsearch6.best_params_, gsearch6.best_score_","be225dbc":"param_test6b = {\n    'reg_alpha':[0, 1, 5, 10, 20]\n}\ngsearch6b = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0.4,\n        subsample=0.75,\n        colsample_bytree=0.85,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test6b,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch6b.fit(train_x,train_y)\n# gsearch6b.cv_results_, gsearch6b.best_params_, gsearch6b.best_score_","28f6cb49":"param_test7 = {\n    'learning_rate':[i\/100.0 for i in range(1,10,1)]\n}\ngsearch7 = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate =0.1,\n        n_estimators=200,\n        max_depth=7,\n        min_child_weight=1,\n        gamma=0.4,\n        subsample=0.75,\n        colsample_bytree=0.85,\n        use_label_encoder=False,\n        objective= 'binary:logistic',\n        nthread=4,\n        reg_alpha=10,\n        scale_pos_weight=1,\n        seed=27\n    ),\n    param_grid = param_test7,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5\n)\n# gsearch7.fit(train_x,train_y)\n# gsearch7.cv_results_, gsearch7.best_params_, gsearch7.best_score_","3086cfdb":"import gc\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, recall_score\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\n\n# Display\/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('features_importances.png')\n    \ndef display_roc_curve(y_, oof_preds_,sub_preds_,folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n#         score = 2 * auc(fpr, tpr) -1\n        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n#     score = 2 * auc(fpr, tpr) -1\n    score = roc_auc_score(y_, oof_preds_)\n    plt.plot(fpr, tpr, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    \n    plt.savefig('roc_curve.png')\n\n\ndef kfold_cv(train_df, test_df, num_folds, stratified = False, debug= False):\n    print(\"Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    gc.collect()\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=25000)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=25000)\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['Survived','PassengerId']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['Survived'])):        \n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['Survived'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['Survived'].iloc[valid_idx]\n        \n        sm = SMOTE(random_state=42, sampling_strategy=1.0)\n        train_x, train_y = sm.fit_resample(train_x, train_y)\n\n        clf = XGBClassifier(\n            learning_rate=0.07,\n            n_estimators=200,\n            max_depth=7,\n            min_child_weight=1,\n            gamma=0.4,\n            subsample=0.75,\n            colsample_bytree=0.85,\n            use_label_encoder=False,\n            objective= 'binary:logistic',\n            nthread=4,\n            reg_alpha=10,\n            scale_pos_weight=1,\n            seed=27\n        )\n\n        clf.fit(train_x, train_y.ravel(), eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric='auc', verbose= 1000, early_stopping_rounds= 200)\n\n        oof_pred = clf.predict(valid_x)\n        \n        pred = clf.predict(valid_x)\n        print('F1 Score: ' + str( f1_score(valid_y, pred) ))\n        print('Recall Score: ' + str( recall_score(valid_y, pred) ))\n        \n        sub_pred = clf.predict(test_df[feats]) \/ folds.n_splits\n        oof_preds[valid_idx] = oof_pred\n        sub_preds += sub_pred\n                \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    print('Full AUC score %.6f' % roc_auc_score(train_df['Survived'], oof_preds))\n    \n    folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df[feats], train_df['Survived'])]\n    display_roc_curve(y_=train_df['Survived'],oof_preds_=oof_preds,sub_preds_ = sub_preds, folds_idx_=folds_idx)\n    \n    # Write submission file and plot feature importance\n    if not debug:\n        test_df['Survived'] = sub_preds\n        test_df = test_df.astype({'Survived': 'int32'})\n        test_df[['PassengerId', 'Survived']].to_csv('submission.csv', index= False)\n        \n    display_importances(feature_importance_df)\n    return feature_importance_df","907901f4":"feature_importance = kfold_cv(final_train_data, final_test_data, 5, True)","a4037358":"```\n# Output\n({'mean_fit_time': array([270.72046261, 266.66264801, 264.71653447, 273.68775826,\n         270.43560157, 269.8571672 , 275.6143332 , 275.91246095,\n         219.58569078]),\n  'std_fit_time': array([ 4.58014369,  2.719242  ,  3.78624711,  2.84064368,  4.42293908,\n          3.81819455,  5.21964478,  2.58611285, 91.04814611]),\n  'mean_score_time': array([0.34822335, 0.35122457, 0.39520702, 0.33346424, 0.32467709,\n         0.32508726, 0.30490289, 0.32646446, 0.22578835]),\n  'std_score_time': array([0.02182779, 0.01044297, 0.04105881, 0.01235056, 0.03607853,\n         0.01665893, 0.04933165, 0.01546562, 0.09601044]),\n  'param_colsample_bytree': masked_array(data=[0.75, 0.75, 0.75, 0.8, 0.8, 0.8, 0.85, 0.85, 0.85],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'param_subsample': masked_array(data=[0.75, 0.8, 0.85, 0.75, 0.8, 0.85, 0.75, 0.8, 0.85],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'colsample_bytree': 0.75, 'subsample': 0.75},\n   {'colsample_bytree': 0.75, 'subsample': 0.8},\n   {'colsample_bytree': 0.75, 'subsample': 0.85},\n   {'colsample_bytree': 0.8, 'subsample': 0.75},\n   {'colsample_bytree': 0.8, 'subsample': 0.8},\n   {'colsample_bytree': 0.8, 'subsample': 0.85},\n   {'colsample_bytree': 0.85, 'subsample': 0.75},\n   {'colsample_bytree': 0.85, 'subsample': 0.8},\n   {'colsample_bytree': 0.85, 'subsample': 0.85}],\n  'split0_test_score': array([0.84906952, 0.84858363, 0.84901598, 0.84784835, 0.84823407,\n         0.84892459, 0.84841866, 0.84765768, 0.84861848]),\n  'split1_test_score': array([0.85600722, 0.85670832, 0.8566435 , 0.85567189, 0.85700608,\n         0.85622788, 0.85555861, 0.85637197, 0.85614243]),\n  'split2_test_score': array([0.84909758, 0.84905184, 0.84908512, 0.8486399 , 0.8483266 ,\n         0.84817649, 0.84904721, 0.84863791, 0.84851062]),\n  'split3_test_score': array([0.88300251, 0.88316477, 0.88381258, 0.88269211, 0.88289486,\n         0.88342418, 0.88358259, 0.88357333, 0.88322687]),\n  'split4_test_score': array([0.95711203, 0.957082  , 0.95796146, 0.95791735, 0.95880465,\n         0.95836932, 0.95652797, 0.95694413, 0.95764367]),\n  'mean_test_score': array([0.87885777, 0.87891811, 0.87930373, 0.87855392, 0.87905325,\n         0.87902449, 0.87862701, 0.878637  , 0.87882841]),\n  'std_test_score': array([0.0410757 , 0.04106843, 0.04135545, 0.041658  , 0.04184512,\n         0.04169472, 0.04101897, 0.04125959, 0.04141897]),\n  'rank_test_score': array([5, 4, 1, 9, 2, 3, 8, 7, 6], dtype=int32)},\n {'colsample_bytree': 0.75, 'subsample': 0.85},\n 0.8793037298289728)\n```","e24d66f3":"```\n# Output\n({'mean_fit_time': array([264.73518562, 258.43494062, 273.45296659, 268.5024518 ]),\n  'std_fit_time': array([5.60000943, 5.07955074, 4.58229505, 5.13243651]),\n  'mean_score_time': array([0.32740898, 0.33808775, 0.33355627, 0.23618708]),\n  'std_score_time': array([0.02487408, 0.02665582, 0.01449516, 0.10075778]),\n  'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.8, 0.8],\n               mask=[False, False, False, False],\n         fill_value='?',\n              dtype=object),\n  'param_subsample': masked_array(data=[0.7, 0.8, 0.7, 0.8],\n               mask=[False, False, False, False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'colsample_bytree': 0.7, 'subsample': 0.7},\n   {'colsample_bytree': 0.7, 'subsample': 0.8},\n   {'colsample_bytree': 0.8, 'subsample': 0.7},\n   {'colsample_bytree': 0.8, 'subsample': 0.8}],\n  'split0_test_score': array([0.84840981, 0.84907788, 0.84871567, 0.84823407]),\n  'split1_test_score': array([0.85602778, 0.85674356, 0.85591018, 0.85700608]),\n  'split2_test_score': array([0.84843902, 0.84850159, 0.84790089, 0.8483266 ]),\n  'split3_test_score': array([0.88294695, 0.88357348, 0.88313872, 0.88289486]),\n  'split4_test_score': array([0.9566038 , 0.95690679, 0.95625421, 0.95880465]),\n  'mean_test_score': array([0.87848547, 0.87896066, 0.87838393, 0.87905325]),\n  'std_test_score': array([0.04107082, 0.04101515, 0.04098995, 0.04184512]),\n  'rank_test_score': array([3, 2, 4, 1], dtype=int32)},\n {'colsample_bytree': 0.8, 'subsample': 0.8},\n 0.8790532516640599)\n```","82f2edf6":"```\n# Output\n({'mean_fit_time': array([275.51043258, 276.02718916, 284.80924888, 278.52208066,\n         223.55131669]),\n  'std_fit_time': array([ 3.60772008,  4.03648455,  2.52794731,  3.42733534, 93.9355048 ]),\n  'mean_score_time': array([0.34229422, 0.35052695, 0.35500917, 0.3653419 , 0.23838854]),\n  'std_score_time': array([0.016226  , 0.0136301 , 0.0188017 , 0.02159019, 0.10474294]),\n  'param_reg_alpha': masked_array(data=[0, 1, 5, 10, 20],\n               mask=[False, False, False, False, False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'reg_alpha': 0},\n   {'reg_alpha': 1},\n   {'reg_alpha': 5},\n   {'reg_alpha': 10},\n   {'reg_alpha': 20}],\n  'split0_test_score': array([0.84841866, 0.84870609, 0.84906648, 0.84951319, 0.8500191 ]),\n  'split1_test_score': array([0.85555861, 0.85584093, 0.8565433 , 0.85687631, 0.85723906]),\n  'split2_test_score': array([0.84904721, 0.84885707, 0.84965501, 0.84988758, 0.85036728]),\n  'split3_test_score': array([0.88358259, 0.88366919, 0.88294375, 0.88301965, 0.88267709]),\n  'split4_test_score': array([0.95652797, 0.9568714 , 0.95613531, 0.95509408, 0.95242409]),\n  'mean_test_score': array([0.87862701, 0.87878893, 0.87886877, 0.87887816, 0.87854532]),\n  'std_test_score': array([0.04101897, 0.04110521, 0.04056296, 0.04003213, 0.03882486]),\n  'rank_test_score': array([4, 3, 2, 1, 5], dtype=int32)},\n {'reg_alpha': 10},\n 0.8788781621408062)\n\n```","aef4d1f9":"```\n# Output\n({'mean_fit_time': array([274.27435656, 272.03669429, 275.16715016, 278.57269487,\n         166.68242221]),\n  'std_fit_time': array([ 4.90697192,  2.53208601,  2.60412937,  2.64154721, 71.90902853]),\n  'mean_score_time': array([0.3345221 , 0.33835368, 0.353792  , 0.32983398, 0.23151541]),\n  'std_score_time': array([0.00992549, 0.01864636, 0.02415058, 0.03667023, 0.10200377]),\n  'param_reg_alpha': masked_array(data=[1e-05, 0.01, 0.1, 1, 100],\n               mask=[False, False, False, False, False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'reg_alpha': 1e-05},\n   {'reg_alpha': 0.01},\n   {'reg_alpha': 0.1},\n   {'reg_alpha': 1},\n   {'reg_alpha': 100}],\n  'split0_test_score': array([0.84841864, 0.84798174, 0.84858742, 0.84870609, 0.84853058]),\n  'split1_test_score': array([0.85555861, 0.85564686, 0.85542842, 0.85584093, 0.85666766]),\n  'split2_test_score': array([0.84904722, 0.84848004, 0.84865261, 0.84885707, 0.85002616]),\n  'split3_test_score': array([0.88358259, 0.88322205, 0.88347661, 0.88366919, 0.8802367 ]),\n  'split4_test_score': array([0.95652799, 0.95659384, 0.95742614, 0.9568714 , 0.93509948]),\n  'mean_test_score': array([0.87862701, 0.87838491, 0.87871424, 0.87878893, 0.87411211]),\n  'std_test_score': array([0.04101897, 0.0411721 , 0.04140483, 0.04110521, 0.03254482]),\n  'rank_test_score': array([3, 4, 2, 1, 5], dtype=int32)},\n {'reg_alpha': 1},\n 0.8787889342699449)\n```","31699718":"```\n# Output\n({'mean_fit_time': array([227.09031415, 220.99125409, 215.32283955, 285.30846672,\n         269.19676309, 261.3322155 , 349.79917583, 324.81722174,\n         262.03395381]),\n  'std_fit_time': array([ 2.69721289,  4.69311073,  2.06245283,  3.38722253,  4.66644057,\n          2.80817646,  5.50213699,  3.29204117, 82.70124183]),\n  'mean_score_time': array([0.29869275, 0.28568945, 0.28238034, 0.34796915, 0.34466705,\n         0.33007789, 0.38365641, 0.37955399, 0.25225396]),\n  'std_score_time': array([0.0094437 , 0.04343774, 0.04030966, 0.01947428, 0.01948299,\n         0.0313189 , 0.02556979, 0.0241019 , 0.11835266]),\n  'param_max_depth': masked_array(data=[6, 6, 6, 7, 7, 7, 8, 8, 8],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'param_min_child_weight': masked_array(data=[0, 1, 2, 0, 1, 2, 0, 1, 2],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'max_depth': 6, 'min_child_weight': 0},\n   {'max_depth': 6, 'min_child_weight': 1},\n   {'max_depth': 6, 'min_child_weight': 2},\n   {'max_depth': 7, 'min_child_weight': 0},\n   {'max_depth': 7, 'min_child_weight': 1},\n   {'max_depth': 7, 'min_child_weight': 2},\n   {'max_depth': 8, 'min_child_weight': 0},\n   {'max_depth': 8, 'min_child_weight': 1},\n   {'max_depth': 8, 'min_child_weight': 2}],\n  'split0_test_score': array([0.84904146, 0.84927021, 0.84904328, 0.84811467, 0.84867964,\n         0.84829193, 0.84648884, 0.84660514, 0.84743688]),\n  'split1_test_score': array([0.85794388, 0.85740102, 0.857815  , 0.85660939, 0.85657295,\n         0.85673058, 0.85468494, 0.85482016, 0.85429351]),\n  'split2_test_score': array([0.84948941, 0.84950027, 0.84965347, 0.84857447, 0.8487202 ,\n         0.84854944, 0.84643161, 0.84677379, 0.84733819]),\n  'split3_test_score': array([0.88332711, 0.88303194, 0.88321182, 0.88311222, 0.88349159,\n         0.88291708, 0.88255384, 0.88267127, 0.88265084]),\n  'split4_test_score': array([0.95515361, 0.95474342, 0.95493367, 0.9576826 , 0.95772282,\n         0.95719749, 0.95898348, 0.95833289, 0.95923679]),\n  'mean_test_score': array([0.87899109, 0.87878937, 0.87893145, 0.87881867, 0.87903744,\n         0.8787373 , 0.87782854, 0.87784065, 0.87819124]),\n  'std_test_score': array([0.04007454, 0.03993423, 0.03997766, 0.04144552, 0.04136814,\n         0.04122134, 0.04268963, 0.04236292, 0.04256081]),\n  'rank_test_score': array([2, 5, 3, 4, 1, 6, 9, 8, 7], dtype=int32)},\n {'max_depth': 7, 'min_child_weight': 1},\n 0.8790374408410356)\n```","6b8ebd0d":"```\n# Output\n({'mean_fit_time': array([310.02117634, 302.40386853, 296.49384093, 291.0676362 ,\n         290.1681962 , 285.81479111, 283.90757165, 283.79644413,\n         225.64013681]),\n  'std_fit_time': array([  2.70587367,   4.02507028,   2.64717498,   3.67896398,\n           2.23926685,   4.08376128,   3.60766283,   2.31671398,\n         102.87196643]),\n  'mean_score_time': array([0.3807838 , 0.37723298, 0.32812343, 0.34239044, 0.32590175,\n         0.34391332, 0.34846554, 0.34919987, 0.27772937]),\n  'std_score_time': array([0.03526834, 0.0165861 , 0.02764899, 0.03012603, 0.05415552,\n         0.02491196, 0.03945512, 0.01410936, 0.12914528]),\n  'param_learning_rate': masked_array(data=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'learning_rate': 0.01},\n   {'learning_rate': 0.02},\n   {'learning_rate': 0.03},\n   {'learning_rate': 0.04},\n   {'learning_rate': 0.05},\n   {'learning_rate': 0.06},\n   {'learning_rate': 0.07},\n   {'learning_rate': 0.08},\n   {'learning_rate': 0.09}],\n  'split0_test_score': array([0.84799126, 0.84990173, 0.85065057, 0.85069628, 0.85067647,\n         0.85034422, 0.85045547, 0.85023372, 0.85007281]),\n  'split1_test_score': array([0.85561522, 0.85746034, 0.85808133, 0.85816636, 0.85818866,\n         0.85781694, 0.85776686, 0.85745461, 0.85737084]),\n  'split2_test_score': array([0.84947623, 0.85095675, 0.85151307, 0.8514018 , 0.85126894,\n         0.85106383, 0.85101527, 0.85040059, 0.85048767]),\n  'split3_test_score': array([0.87876346, 0.88080307, 0.88205728, 0.88287393, 0.88300376,\n         0.88318071, 0.8830507 , 0.88312628, 0.88278265]),\n  'split4_test_score': array([0.9365298 , 0.94615062, 0.94973019, 0.95032134, 0.95192121,\n         0.95356768, 0.95450251, 0.95427359, 0.9544222 ]),\n  'mean_test_score': array([0.8736752 , 0.8770545 , 0.87840649, 0.87869194, 0.87901181,\n         0.87919468, 0.87935816, 0.87909776, 0.87902724]),\n  'std_test_score': array([0.03331069, 0.03630598, 0.0374357 , 0.03767776, 0.03830895,\n         0.03905876, 0.03940857, 0.0394784 , 0.03954837]),\n  'rank_test_score': array([9, 8, 7, 6, 5, 2, 1, 3, 4], dtype=int32)},\n {'learning_rate': 0.07},\n 0.8793581617792399)\n```","60103eb6":"```\n# Output\n({'mean_fit_time': array([272.11131663, 260.83970675, 255.30913534, 383.37809596,\n         357.81840076, 351.80142932, 504.15682721, 465.49360337,\n         375.60504947]),\n  'std_fit_time': array([  1.67645035,   3.85691721,   4.24622363,   2.84621593,\n           7.08090777,   6.36768253,   7.58772393,   6.50357653,\n         104.76211844]),\n  'mean_score_time': array([0.33333292, 0.31011777, 0.32633858, 0.44162273, 0.42505212,\n         0.4127224 , 0.56222205, 0.53651485, 0.35870881]),\n  'std_score_time': array([0.01749353, 0.01518372, 0.02228676, 0.02101094, 0.03439906,\n         0.03042925, 0.02745548, 0.04289937, 0.15277742]),\n  'param_max_depth': masked_array(data=[7, 7, 7, 9, 9, 9, 11, 11, 11],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5],\n               mask=[False, False, False, False, False, False, False, False,\n                     False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'max_depth': 7, 'min_child_weight': 1},\n   {'max_depth': 7, 'min_child_weight': 3},\n   {'max_depth': 7, 'min_child_weight': 5},\n   {'max_depth': 9, 'min_child_weight': 1},\n   {'max_depth': 9, 'min_child_weight': 3},\n   {'max_depth': 9, 'min_child_weight': 5},\n   {'max_depth': 11, 'min_child_weight': 1},\n   {'max_depth': 11, 'min_child_weight': 3},\n   {'max_depth': 11, 'min_child_weight': 5}],\n  'split0_test_score': array([0.84867964, 0.848416  , 0.84871055, 0.84510666, 0.84536172,\n         0.84576957, 0.84040074, 0.84145019, 0.84226035]),\n  'split1_test_score': array([0.85657295, 0.85642851, 0.85667076, 0.85234729, 0.85223843,\n         0.85300753, 0.84902852, 0.84786708, 0.84964006]),\n  'split2_test_score': array([0.8487202 , 0.84836042, 0.84830478, 0.84538275, 0.84568105,\n         0.84593315, 0.84224065, 0.8418523 , 0.84326009]),\n  'split3_test_score': array([0.88349159, 0.88343288, 0.88293238, 0.88192533, 0.88170851,\n         0.88165236, 0.87945831, 0.87988275, 0.87916737]),\n  'split4_test_score': array([0.95772282, 0.9572616 , 0.95553898, 0.95985901, 0.95927461,\n         0.95671505, 0.96216332, 0.96187734, 0.9586757 ]),\n  'mean_test_score': array([0.87903744, 0.87877988, 0.87843149, 0.87692421, 0.87685286,\n         0.87661553, 0.87465831, 0.87458593, 0.87460071]),\n  'std_test_score': array([0.04136814, 0.04129873, 0.04057168, 0.0436221 , 0.04332705,\n         0.04216995, 0.04595985, 0.04589382, 0.04413757]),\n  'rank_test_score': array([1, 2, 3, 4, 5, 6, 7, 9, 8], dtype=int32)},\n {'max_depth': 7, 'min_child_weight': 1},\n 0.8790374408410356)\n```","06802765":"**Reference**\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/tps-apr-2021-voting-pseudo-labeling\n\nhttps:\/\/www.kaggle.com\/alexryzhkov\/n3-tps-april-21-lightautoml-starter","dda6a94b":"```\n# Output\n({'mean_fit_time': array([269.09461918, 269.72219725, 270.3569695 , 270.25370035,\n         223.87595577]),\n  'std_fit_time': array([ 2.24053036,  3.67366006,  2.23530612,  1.95032911, 97.76524852]),\n  'mean_score_time': array([0.33340855, 0.37081723, 0.32860589, 0.32713428, 0.25316916]),\n  'std_score_time': array([0.03999725, 0.04447045, 0.02231321, 0.02351676, 0.11302583]),\n  'param_gamma': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4],\n               mask=[False, False, False, False, False],\n         fill_value='?',\n              dtype=object),\n  'params': [{'gamma': 0.0},\n   {'gamma': 0.1},\n   {'gamma': 0.2},\n   {'gamma': 0.3},\n   {'gamma': 0.4}],\n  'split0_test_score': array([0.84867964, 0.84828056, 0.84803939, 0.84876785, 0.84823407]),\n  'split1_test_score': array([0.85657295, 0.85668415, 0.85690292, 0.85684749, 0.85700608]),\n  'split2_test_score': array([0.8487202 , 0.84868282, 0.84862791, 0.84821527, 0.8483266 ]),\n  'split3_test_score': array([0.88349159, 0.88380635, 0.88333698, 0.88342794, 0.88289486]),\n  'split4_test_score': array([0.95772282, 0.95780495, 0.95750645, 0.95747198, 0.95880465]),\n  'mean_test_score': array([0.87903744, 0.87905177, 0.87888273, 0.87894611, 0.87905325]),\n  'std_test_score': array([0.04136814, 0.0414587 , 0.04135531, 0.04130341, 0.04184512]),\n  'rank_test_score': array([3, 2, 5, 4, 1], dtype=int32)},\n {'gamma': 0.4},\n 0.8790532516640599)\n```"}}