{"cell_type":{"63ab4292":"code","500ab62c":"code","782f551f":"code","ff8f1e4a":"code","798b7d78":"code","3cf6aceb":"code","191299f4":"code","f396ad94":"code","c59a26ab":"code","71963220":"code","8b27905d":"code","d831265e":"code","66c9846a":"code","bc073720":"code","1ef80d1c":"code","40d72ad3":"code","f418c245":"code","b559a4c4":"code","27c6316c":"code","ee4e16a3":"code","52691d89":"code","8cb8c197":"code","f5333db6":"code","d02434a4":"code","fbd99735":"code","b18ce116":"code","455a5297":"code","8176fc17":"code","afe26988":"code","f6d864b1":"code","e1d9ea63":"code","58c313e3":"code","a4ab25ec":"code","b286d3d3":"code","fe952fbd":"code","6ac9e112":"markdown","9b46278f":"markdown","dca85b51":"markdown","4fd22efb":"markdown","0f4d908d":"markdown","016a42b3":"markdown","4d528654":"markdown","738a4c81":"markdown","80d31cce":"markdown","f45eade0":"markdown","71ffe995":"markdown"},"source":{"63ab4292":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","500ab62c":"# Import the necessary packages\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport PIL\nimport seaborn as sns\nimport pickle\nfrom PIL import *\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.keras import Input\nfrom tensorflow.python.keras import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","782f551f":"keyfacial_df = pd.read_csv('..\/input\/facial-keypoints-detection\/training.zip', compression='zip', header=0, sep=',', quotechar='\"')\ntest_data = pd.read_csv('..\/input\/facial-keypoints-detection\/test.zip', compression='zip', header=0, sep=',', quotechar='\"')\nIdLookupTable = pd.read_csv('..\/input\/facial-keypoints-detection\/IdLookupTable.csv',header=0, sep=',', quotechar='\"')\nSampleSubmission = pd.read_csv('..\/input\/facial-keypoints-detection\/SampleSubmission.csv',header=0, sep=',', quotechar='\"')","ff8f1e4a":"keyfacial_df.head()","798b7d78":"keyfacial_df.info()","3cf6aceb":"keyfacial_df.isnull().sum()","191299f4":"keyfacial_df.fillna(method = 'ffill',inplace = True)","f396ad94":"keyfacial_df['Image'].shape","c59a26ab":"keyfacial_df['Image']=keyfacial_df['Image'].apply(lambda x:np.fromstring(x,dtype=int,sep=' ').reshape(96,96))","71963220":"keyfacial_df['Image'][0].shape","8b27905d":"keyfacial_df.describe()","d831265e":"# Plot a random image from the dataset along with facial keypoints. \n# Image data is obtained from df['Image'] and plotted using plt.imshow\n# 15 x and y coordinates for the corresponding image \n# since x-coordinates are in even columns like 0,2,4,.. and y-coordinates are in odd columns like 1,3,5,..\n# we access their value using .loc command, which get the values for coordinates of the image based on the column it is refering to.\n\ni = np.random.randint(1, len(keyfacial_df))\nplt.imshow(keyfacial_df['Image'][i], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n","66c9846a":"import random\n# Let's view more images in a grid format\nfig = plt.figure(figsize=(20, 20))\n\nfor i in range(16):\n    k=random.randint(1,len(keyfacial_df))\n    ax = fig.add_subplot(4, 4, i + 1)\n    image = plt.imshow(keyfacial_df['Image'][k],cmap = 'gray')\n    for j in range(1,31,2):\n        plt.plot(keyfacial_df.loc[k][j-1], keyfacial_df.loc[k][j], 'rx')\n    ","bc073720":"#Creating a new copy of the dataframe\nimport copy\nkeyfacial_df_copy=copy.copy(keyfacial_df)","1ef80d1c":"columns =keyfacial_df_copy.columns[:-1]\ncolumns","40d72ad3":"#horizontal-flip\nkeyfacial_df_copy['Image']=keyfacial_df_copy['Image'].apply(lambda x:np.flip(x,axis=1))\n#As Flipping horizontally , y coordiantes will be same \n# only x cordinate values will change ,So Subtract our x-coordinate  values from width of the image 96\nfor i in range(len(columns)):\n    if i%2 == 0:\n         keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x:96.-float(x))","f418c245":"\n# Original image\nplt.imshow(keyfacial_df['Image'][1], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df.loc[1][j-1], keyfacial_df.loc[1][j], 'rx')\n","b559a4c4":"\n# horizontal flip  image\nplt.imshow(keyfacial_df_copy['Image'][1], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')\n","27c6316c":"# Concatenating the original dataframe with the augmented dataframe\naugmented_df = np.concatenate((keyfacial_df, keyfacial_df_copy))","ee4e16a3":"augmented_df.shape","52691d89":"# Randomingly increasing the brightness of the images\n# We multiply pixel values by random values between 1.5 and 2 to increase the brightness of the image\n# we clip the value between 0 and 255\n\nimport random\n\nkeyfacial_df_copy = copy.copy(keyfacial_df)\nkeyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x:np.clip(random.uniform(1.5, 2)* x, 0.0, 255.0))\naugmented_df = np.concatenate((augmented_df, keyfacial_df_copy))\naugmented_df.shape","8cb8c197":"#Image with increased brightness\n\nplt.imshow(keyfacial_df_copy['Image'][1], cmap='gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')","f5333db6":"#Vertical flip \n#x-coordiantes will not change\n#y-coordinates will change \n#horizontal-flip\nkeyfacial_df_copy['Image']=keyfacial_df_copy['Image'].apply(lambda x:np.flip(x,axis=0))\nfor i in range(len(columns)):\n    if i%2 == 1:\n         keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x:96.-float(x))","d02434a4":"plt.imshow(keyfacial_df_copy['Image'][1], cmap='gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')","fbd99735":"#values of Image\nimg=augmented_df[:,30]\n\n#Normalize the image\nimg=img\/255.\n\n# empty array to feed the model of shape(96,96,1)\nX= np.empty((len(img),96,96,1))\n\n#expanding dimensions to (96,96,1)\nfor i in range(len(img)):\n    X[i,]=np.expand_dims(img[i],axis=2)\n\n#Converting array type to float\nX=np.asarray(X).astype(np.float32)\n","b18ce116":"X.shape","455a5297":"y=augmented_df[:,:30]\ny=np.asarray(y).astype(np.float32)\ny.shape","8176fc17":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","afe26988":"X_train.shape","f6d864b1":"X_test.shape","e1d9ea63":"def res_block(X, filter, stage):\n    \n    \n\n  # Convolutional_block\n    X_copy = X\n\n    f1 , f2, f3 = filter\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = MaxPool2D((2,2))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n\n  # Short path\n    X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n    X_copy = MaxPool2D((2,2))(X_copy)\n    X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n  # Identity Block 1\n    X_copy = X\n\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n  # Identity Block 2\n    X_copy = X\n\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n    return X","58c313e3":"input_shape = (96, 96, 1)\n\n# Input tensor shape\nX_input = Input(input_shape)\n\n# Zero-padding\nX = ZeroPadding2D((3,3))(X_input)\n\n# 1 - stage\nX = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\nX = BatchNormalization(axis =3, name = 'bn_conv1')(X)\nX = Activation('relu')(X)\nX = MaxPooling2D((3,3), strides= (2,2))(X)\n\n# 2 - stage\nX = res_block(X, filter= [64,64,256], stage= 2)\n\n# 3 - stage\nX = res_block(X, filter= [128,128,512], stage= 3)\n\n\n# Average Pooling\nX = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n\n# Final layer\nX = Flatten()(X)\nX = Dense(4096, activation = 'relu')(X)\nX = Dropout(0.2)(X)\nX = Dense(2048, activation = 'relu')(X)\nX = Dropout(0.1)(X)\nX = Dense(30, activation = 'relu')(X)\n\n\nmodel_1_facialKeyPoints = Model( inputs= X_input, outputs = X)\nmodel_1_facialKeyPoints.summary()","a4ab25ec":"adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\nmodel_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = adam , metrics = ['accuracy'])","b286d3d3":"# save the best model with least validation loss\ncheckpointer = ModelCheckpoint(filepath = \"FacialKeyPoints_weights.hdf5\", verbose = 1, save_best_only = True)","fe952fbd":"history = model_1_facialKeyPoints.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data=(X_test,y_test), callbacks=[checkpointer])","6ac9e112":"> * Vertical Flip","9b46278f":"# Image visulaization","dca85b51":"# Data Normalization and Scaling","4fd22efb":"# Missing values","0f4d908d":"# Reading Data","016a42b3":"# Residual Neural Network","4d528654":"> * Horizontal flip","738a4c81":"# Image Augmentation","80d31cce":"> * Brightness","f45eade0":"# Reshape Image","71ffe995":"# Compile and Traning"}}