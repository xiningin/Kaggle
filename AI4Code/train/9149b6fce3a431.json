{"cell_type":{"61a909b3":"code","705da274":"code","f4e037c2":"code","987d415b":"code","862141be":"code","bfc1257b":"code","08e01786":"code","33ddb7d9":"code","0fc9cf3b":"code","7d290b47":"markdown","fbe78110":"markdown","99a5a522":"markdown","41a9caab":"markdown","6324d6a1":"markdown","36b6e157":"markdown","32db10f1":"markdown","3e78e5ea":"markdown","aa8354d6":"markdown"},"source":{"61a909b3":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom PIL import Image\nimport urllib.request\nfrom io import BytesIO\n\n%matplotlib inline\n\nurl = str('https:\/\/scontent.fhan2-3.fna.fbcdn.net\/v\/t1.0-9\/31131205_1655267761229858_8661840822800482304_n.jpg?_nc_cat=109&_nc_ht=scontent.fhan2-3.fna&oh=a3c56598e53490f95d3648ab894f4ee0&oe=5C476E67')\nwith urllib.request.urlopen(url) as url:\n    f = BytesIO(url.read())\n\nX = np.array(Image.open(f))\nprint('Image shape: %s'%str(X.shape))\n# Convert to grey\nX = X.dot([0.299, 0.5870, 0.114])\nprint('Image shape: %s'%str(X.shape))\nplt.imshow(X)","705da274":"#T\u1ea1o b\u1ed9 l\u1ecdc ngang F1\nF1 = np.array([[-1, -1, -1],\n              [0, 0, 0],\n              [1, 1, 1]])\n#T\u00ednh t\u00edch ch\u1eadp 2 chi\u1ec1u.\ndef conv2d(X, F, s = 1, p = 0):\n    \"\"\"\n    X: Ma tr\u1eadn \u0111\u1ea7u v\u00e0o\n    F: Ma tr\u1eadn b\u1ed9 l\u1ecdc\n    s: B\u01b0\u1edbc tr\u01b0\u1ee3t\n    p: \u0110\u1ed9 r\u1ed9ng l\u1ec1 th\u00eam v\u00e0o\n    \"\"\"\n    (w1, h1) = X.shape\n    f = F.shape[0]\n    w2 = int((w1 + 2*p - f)\/s) + 1\n    h2 = int((h1 + 2*p - f)\/s) + 1\n    Y = np.zeros((w2, h2))\n    X_pad = np.pad(X, pad_width = p, mode = 'constant', constant_values = 0)\n    for i in range(w2):\n        for j in range(h2):\n            idw = i*s\n            idh = j*s\n            Y[i, j] = np.abs(np.sum(X_pad[idw:(idw+f), idh:(idh+f)]*F))\n    return Y\n\nY1 = conv2d(X, F1, s = 1, p = 0)\nplt.imshow(Y1)","f4e037c2":"#T\u1ea1o b\u1ed9 l\u1ecdc d\u1ecdc F2\nF2 = np.array([[1, 0, -1],\n             [1, 0, -1],\n             [1, 0, -1]])\nY2 = conv2d(X, F2, s = 3, p = 0)\nplt.imshow(Y2)","987d415b":"import tensorflow as tf \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\ndef cnn_model_fn(features, labels, mode):\n    \"\"\"Model function for CNN\"\"\"\n    #Input layer\n    input_layer = tf.reshape(features['x'], shape = [-1, 28, 28, 1])\n    \n    #Convolution layer 1\n    conv1 = tf.layers.conv2d(\n        inputs = input_layer,\n        filters = 32,\n        kernel_size = [5, 5],\n        padding = 'same',\n        activation = tf.nn.relu)\n    #Apply formula:N1 = (N+2P-f)\/S + 1\n    #in which: N is input image size, P is padding size, f is filter size and S is step\n    #Output tensor shape: N1 = (28-5)\/1+1 = 24 => shape = [-1, 24, 24, 1]\n    #But we at parameter we set padding = 'same' in order to keep output shape unchange to input shape \n    #Thus output shape is [-1, 28, 28, 1]\n    \n    #Max pooling layer 1\n    pool1 = tf.layers.max_pooling2d(\n        inputs = conv1, \n        pool_size = [2, 2],\n        strides = 2)\n    #Output tensor shape: N2 = (28-2)\/2+1 = 14 => shape = [-1, 14, 14, 1]\n    \n    #Convolution layer 2\n    conv2 = tf.layers.conv2d(\n        inputs = pool1,\n        filters = 64,\n        kernel_size = [5, 5],\n        padding = 'same',\n        activation = tf.nn.relu)\n    #Output tensor shape: N3 = (14-5)\/1+1 = 10 => shape = [-1, 10, 10, 1]\n    #But padding = 'same' so output shape is [-1, 14, 14, 1]\n    \n    #Max pooling layer 2\n    pool2 = tf.layers.max_pooling2d(\n        inputs = conv2,\n        pool_size = [2, 2],\n        strides = 2)\n    #Output tensor shape: N4 = (14-2)\/2+1 = 7 => shape = [-1, 7, 7, 1]\n    \n    #Dense layer\n    flat = tf.reshape(pool2, [-1, 7*7*64])\n    dense = tf.layers.dense(\n        inputs = flat, \n        units = 1024,\n        activation = tf.nn.relu)\n    \n    dropout = tf.layers.dropout(\n        inputs = dense,\n        rate = 0.4,\n        training = mode == tf.estimator.ModeKeys.TRAIN)\n    \n    #Logits layer\n    logits = tf.layers.dense(inputs = dropout, units = 10)\n    \n    predictions = {\n        'classes': tf.argmax(input = logits, axis = 1, name = 'class_tensor'),\n        'probabilities': tf.nn.softmax(logits, name = 'softmax_tensor')}\n    \n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)\n\n    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n    \n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n        train_op = optimizer.minimize(\n            loss = loss, \n            global_step = tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)\n    \n    if mode == tf.estimator.ModeKeys.EVAL:\n        eval_metric_ops = {\n            'accuracy': tf.metrics.accuracy(\n            labels = labels, predictions = predictions['classes'])}\n        return tf.estimator.EstimatorSpec(\n            mode = mode, loss = loss, eval_metric_ops = eval_metric_ops)","862141be":"import sys\n!{sys.executable} -m pip install python-mnist\n\nfrom mnist import MNIST\nmndata = MNIST('..\/input')\n\nmndata.load_training()\ntrain_data = np.asarray(mndata.train_images)\/255.0\ntrain_labels = np.array(mndata.train_labels.tolist())\n\nmndata.load_testing()\ntest_data = np.asarray(mndata.test_images)\/255.0\ntest_labels = np.array(mndata.test_labels.tolist())\n\nprint('Train images shape      : %s'%str(train_data.shape))\nprint('Train labels shape shape: %s'%str(train_labels.shape))\nprint('Test  images shape      : %s'%str(test_data.shape))\nprint('Test  labels shape shape: %s'%str(test_labels.shape))","bfc1257b":"#Create the Estimator\nmnist_classifier = tf.estimator.Estimator(\n    model_fn = cnn_model_fn, \n    model_dir = '.\/tmp\/conv2_checkpoints' #temporary file to save model\n)\n#Create the Logging Hook to tracking processing\n# tensors_to_log = {'probability': 'softmax_tensor',\n#                  'class_values': 'class_tensor'}\n\n# logging_hook = tf.train.LoggingTensorHook(\n#     tensors = tensors_to_log, \n#     every_n_iter = 50\n# )","08e01786":"#Training model\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {'x': train_data},\n    y = train_labels, \n    batch_size = 100,\n    num_epochs = 50,\n    shuffle = True\n)","33ddb7d9":"mnist_classifier.train(\n    input_fn = train_input_fn,\n    steps = 10000\n#     hooks = [logging_hook]\n)","0fc9cf3b":"#Validation on test\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x = {\"x\": test_data},\n      y = test_labels,\n      num_epochs = 1,\n      shuffle = False)\n\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\nprint(eval_results)","7d290b47":"Kh\u1edfi t\u1ea1o Estimator","fbe78110":"Kh\u1edfi t\u1ea1o h\u00e0m truy\u1ec1n d\u1eef li\u1ec7u","99a5a522":"# 3. T\u00e0i li\u1ec7u \n1. [T\u00e0i li\u1ec7u CS231n - M\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp \u1ee9ng d\u1ee5ng trong nh\u1eadn di\u1ec7n h\u00ecnh \u1ea3nh - Standford](http:\/\/cs231n.github.io\/convolutional-networks\/)\n2. [T\u00edch ch\u1ea5p 2 chi\u1ec1u - Blog machine learning c\u01a1 b\u1ea3n - V\u0169 H\u1eefu Ti\u1ec7p](https:\/\/machinelearningcoban.com\/2018\/10\/03\/conv2d)\n3. [X\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp s\u1eed d\u1ee5ng estimator - Tensoflow](https:\/\/www.tensorflow.org\/tutorials\/estimators\/cnn)\n4. [Image kenel - Victor Powell](http:\/\/setosa.io\/ev\/image-kernels\/)\n5. [Image Filtering - Blog Machine Learning Guru](http:\/\/machinelearninguru.com\/computer_vision\/basics\/convolution\/image_convolution_1.html)","41a9caab":"\u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh tr\u00ean t\u1eadp test","6324d6a1":"H\u00e0m truy\u1ec1n d\u1eef li\u1ec7u s\u1ebd bao g\u1ed3m 2 bi\u1ebfn ch\u00ednh l\u00e0 bi\u1ebfn d\u1ef1 b\u00e1o $\\mathbf{x}$ v\u00e0 nh\u00e3n $\\mathbf{y}$ v\u1edbi k\u00edch th\u01b0\u1edbc bach_size = 100 v\u00e0 m\u1ed7i batch s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt d\u1eef li\u1ec7u 1 l\u1ea7n. Khi chuy\u1ec3n qua batch m\u1edbi s\u1ebd thay \u0111\u1ed5i v\u1ecb tr\u00ed c\u00e1c quan s\u00e1t.\n\nHu\u1ea9n luy\u1ec7n m\u00f4 h\u00ecnh","36b6e157":"Ta nh\u1eadn th\u1ea5y b\u1ed9 l\u1ecdc tr\u00ean c\u00f3 t\u00e1c d\u1ee5ng nh\u1eadn di\u1ec7n nh\u1eefng \u0111\u01b0\u1eddng n\u00e9t theo chi\u1ec1u ngang c\u1ee7a b\u1ee9c \u1ea3nh nh\u01b0 c\u00e1c \u0111\u01b0\u1eddng vi\u1ec1n c\u1ee7a b\u1ea3ng, m\u00e9p d\u01b0\u1edbi c\u1ee7a \u00e1o, m\u00e9p d\u01b0\u1edbi c\u1ee7a ch\u00e2n t\u01b0\u1eddng,.... S\u1edf d\u0129 b\u1ed9 l\u1ecdc n\u00e0y l\u00e0m n\u1ed5i b\u1eadt c\u00e1c \u0111\u01b0\u1eddng n\u00e9t n\u1eb1m ngang l\u00e0 b\u1edfi v\u00ec t\u00edch ch\u1eadp c\u1ee7a ch\u00fang b\u1eb1ng hi\u1ec7u c\u1ee7a t\u1ed5ng gi\u00e1 tr\u1ecb c\u00e1c \u0111i\u1ec3m ph\u00eda d\u01b0\u1edbi tr\u1eeb c\u00e1c \u0111i\u1ec3m ph\u00eda tr\u00ean. \u0110\u1ed1i v\u1edbi c\u00e1c \u0111\u01b0\u1eddng n\u00e9t n\u1eb1m ngang th\u00ec c\u01b0\u1eddng \u0111\u1ed9 s\u00e1ng n\u1eb1m ngang theo \u0111\u01b0\u1eddng n\u00e9t \u0111\u00f3 kh\u00f4ng kh\u00e1c bi\u1ec7t l\u1edbn nh\u01b0ng x\u00e9t theo chi\u1ec1u d\u1ecdc th\u00ec ch\u00fang s\u1ebd kh\u00e1c nhau. Do \u0111\u00f3 hi\u1ec7u gi\u1eefa 2 t\u1ed5ng ph\u00eda tr\u00ean v\u00e0 d\u01b0\u1edbi c\u00e0ng l\u1edbn d\u1eabn t\u1edbi gi\u00e1 tr\u1ecb c\u1ee7a t\u00edch ch\u1eadp c\u00e0ng l\u1edbn khi tr\u01b0\u1ee3t theo c\u00e1c \u0111\u01b0\u1eddng n\u00e9t n\u1eb1m ngang n\u00e0y. Khi ho\u00e0n th\u00e0nh thi\u1ec7n ma tr\u1eadn t\u00edch ch\u1eadp c\u00e1c \u0111\u01b0\u1eddng n\u00e9t n\u1eb1m ngang s\u1ebd c\u00f3 c\u01b0\u1eddng \u0111\u1ed9 s\u00e1ng l\u1edbn h\u01a1n n\u00ean n\u1ed5i b\u1eadt h\u01a1n. Ch\u00fang ta s\u1ebd th\u1eed nghi\u1ec7m m\u1ed9t b\u1ed9 l\u1ecdc kh\u00e1c \u0111\u1ec3 nh\u1eadn di\u1ec7n chi\u1ec1u d\u1ecdc c\u1ee7a b\u1ee9c \u1ea3nh.","32db10f1":"B\u1ed9 l\u1ecdc cho th\u1ea5y c\u00e1c \u0111\u01b0\u1eddng n\u00e9t d\u1ecdc theo b\u1ee9c \u1ea3nh nh\u01b0 d\u00e1ng ng\u01b0\u1eddi \u0111\u1ee9ng th\u1eb3ng \u0111\u00e3 \u0111\u01b0\u1ee3c nh\u1eadn di\u1ec7n r\u00f5 r\u00e0ng, c\u00e1c \u0111\u01b0\u1edbng n\u00e9t ngang nh\u01b0 vi\u1ec1n b\u1ea3ng, ch\u00e2n t\u01b0\u1eddng, vi\u1ec1n d\u01b0\u1edbi \u00e1o,... \u0111\u00e3 bi\u1ebfn m\u1ea5t. Nh\u01b0 v\u1eady ch\u00fang ta c\u00f3 th\u1ec3 th\u1ea5y m\u1ed7i b\u1ed9 l\u1ecdc s\u1ebd c\u00f3 1 t\u00e1c d\u1ee5ng chi\u1ebft xu\u1ea5t \u0111\u1eb7c tr\u1eebng kh\u00e1c nhau t\u1eeb c\u00f9ng 1 b\u1ee9c \u1ea3nh.\n\n## 1.3. M\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp\n\nT\u00edch ch\u1eadp \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng ph\u1ed5 bi\u1ebfn trong l\u0129nh v\u1ef1c th\u1ecb gi\u00e1c m\u00e1y t\u00ednh. Th\u00f4ng qua c\u00e1c ph\u00e9p t\u00edch ch\u1eadp, c\u00e1c \u0111\u1eb7c tr\u01b0ng ch\u00ednh t\u1eeb \u1ea3nh \u0111\u01b0\u1ee3c chi\u1ebft xu\u1ea5t v\u00e0 truy\u1ec1n v\u00e0o c\u00e1c l\u1edbp *t\u00edch ch\u1eadp* (layer convolution). M\u1ed7i m\u1ed9t l\u1edbp t\u00edch ch\u1eadp s\u1ebd bao g\u1ed3m nhi\u1ec1u \u0111\u01a1n v\u1ecb m\u00e0 k\u1ebft qu\u1ea3 \u1edf m\u1ed7i \u0111\u01a1n v\u1ecb l\u00e0 m\u1ed9t ph\u00e9p bi\u1ebfn \u0111\u1ed5i t\u00edch ch\u1eadp t\u1eeb layer tr\u01b0\u1edbc \u0111\u00f3 th\u00f4ng qua ph\u00e9p nh\u00e2n t\u00edch ch\u1eadp v\u1edbi b\u1ed9 l\u1ecdc. \n\nV\u1ec1 c\u01a1 b\u1ea3n thi\u1ebft k\u1ebf c\u1ee7a m\u1ed9t m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp 2 chi\u1ec1u c\u00f3 d\u1ea1ng nh\u01b0 sau:\n\nINPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC\n\nTrong \u0111\u00f3:\n\nINPUT: L\u1edbp \u0111\u1ea7u v\u00e0o\n\nCONV: L\u1edbp t\u00edch ch\u1eadp\n\nRELU: L\u1edbp bi\u1ebfn \u0111\u1ed5i th\u00f4ng qua h\u00e0m k\u00edch ho\u1ea1t relu \u0111\u1ec3 k\u00edch ho\u1ea1t t\u00ednh phi tuy\u1ebfn\n\nPOOL: L\u1edbp t\u1ed5ng h\u1ee3p, th\u00f4ng th\u01b0\u1eddng l\u00e0 Max pooling ho\u1eb7c c\u00f3 th\u1ec3 l\u00e0 Average pooling d\u00f9ng \u0111\u1ec3 gi\u1ea3m chi\u1ec1u c\u1ee7a ma tr\u1eadn \u0111\u1ea7u v\u00e0o.\n\nFC: L\u1edbp k\u1ebft n\u1ed1i ho\u00e0n to\u00e0n. Th\u00f4ng th\u01b0\u1eddng l\u1edbp n\u00e0y n\u1eb1m \u1edf sau c\u00f9ng v\u00e0 k\u1ebft n\u1ed1i v\u1edbi c\u00e1c \u0111\u01a1n v\u1ecb \u0111\u1ea1i di\u1ec7n cho nh\u00f3m ph\u00e2n lo\u1ea1i.\n\nC\u00e1c k\u00ed hi\u1ec7u []*N, []*M ho\u1eb7c []*K \u00e1m ch\u1ec9 c\u1ea5u tr\u00fac b\u00ean trong [] c\u00f3 th\u1ec3 l\u1eb7p l\u1ea1i nhi\u1ec1u l\u1ea7n li\u00ean ti\u1ebfp nhau. M, K l\u00e0 s\u1ed1 l\u1ea7n l\u1eb7p l\u1ea1i. \nK\u00ed hi\u1ec7u -> \u0111\u1ea1i di\u1ec7n cho c\u00e1c l\u1edbp li\u1ec1n k\u1ec1 nhau m\u00e0 l\u1edbp \u0111\u1ee9ng tr\u01b0\u1edbc -> s\u1ebd l\u00e0m \u0111\u1ea7u v\u00e0o cho l\u1edbp \u0111\u1ee9ng sau ->.\n\n\nNh\u01b0 v\u1eady ta c\u00f3 th\u1ec3 th\u1ea5y m\u1ed9t m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp v\u1ec1 c\u01a1 b\u1ea3n c\u00f3 3 qu\u00e1 tr\u00ecnh kh\u00e1c nhau:\n\n* Qu\u00e1 tr\u00ecnh chi\u1ebft xu\u1ea5t \u0111\u1eb7c tr\u01b0ng: Th\u00f4ng qua c\u00e1c t\u00edch ch\u1eadp gi\u1eefa ma tr\u1eadn \u0111\u1ea7u v\u00e0o v\u1edbi b\u1ed9 l\u1ecdc \u0111\u1ec3 t\u1ea1o th\u00e0nh c\u00e1c \u0111\u01a1n v\u1ecb trong m\u1ed9t l\u1edbp m\u1edbi. Qu\u00e1 tr\u00ecnh n\u00e0y c\u00f3 th\u1ec3 di\u1ec5n ra li\u00ean t\u1ee5c \u1edf ph\u1ea7n \u0111\u1ea7u c\u1ee7a m\u1ea1ng v\u00e0 th\u01b0\u1eddng s\u1eed d\u1ee5ng h\u00e0m k\u00edch ho\u1ea1t relu.\n\n* Qu\u00e1 tr\u00ecnh t\u1ed5ng h\u1ee3p: C\u00e1c l\u1edbp \u1edf v\u1ec1 sau qu\u00e1 tr\u00ecnh chi\u1ebft xu\u1ea5t \u0111\u1eb7c tr\u01b0ng s\u1ebd c\u00f3 k\u00edch th\u01b0\u1edbc l\u1edbn do s\u1ed1 \u0111\u01a1n v\u1ecb \u1edf c\u00e1c l\u1edbp sau th\u01b0\u1eddng t\u0103ng ti\u1ebfn theo c\u1ea5p s\u1ed1 nh\u00e2n. \u0110i\u1ec1u \u0111\u00f3 l\u00e0m t\u0103ng s\u1ed1 l\u01b0\u1ee3ng h\u1ec7 s\u1ed1 v\u00e0 kh\u1ed1i l\u01b0\u1ee3ng t\u00ednh to\u00e1n trong m\u1ea1ng n\u01a1 ron. Do \u0111\u00f3 \u0111\u1ec3 gi\u1ea3m t\u1ea3i t\u00ednh to\u00e1n ch\u00fang ta s\u1ebd c\u1ea7n gi\u1ea3m chi\u1ec1u c\u1ee7a ma tr\u1eadn ho\u1eb7c gi\u1ea3m s\u1ed1 \u0111\u01a1n v\u1ecb c\u1ee7a l\u1edbp. V\u00ec m\u1ed7i m\u1ed9t \u0111\u01a1n v\u1ecb s\u1ebd l\u00e0 k\u1ebft qu\u1ea3 \u0111\u1ea1i di\u1ec7n c\u1ee7a vi\u1ec7c \u00e1p d\u1ee5ng 1 b\u1ed9 l\u1ecdc \u0111\u1ec3 t\u00ecm ra m\u1ed9t \u0111\u1eb7c tr\u01b0ng c\u1ee5 th\u1ec3 n\u00ean vi\u1ec7c gi\u1ea3m s\u1ed1 \u0111\u01a1n v\u1ecb s\u1ebd kh\u00f4ng kh\u1ea3 thi. Gi\u1ea3m k\u00edch th\u01b0\u1edbc ma tr\u1eadn th\u00f4ng qua vi\u1ec7c t\u00ecm ra 1 gi\u00e1 tr\u1ecb \u0111\u1ea1i di\u1ec7n cho m\u1ed7i m\u1ed9t v\u00f9ng kh\u00f4ng gian m\u00e0 b\u1ed9 l\u1ecdc \u0111i qua s\u1ebd kh\u00f4ng l\u00e0m thay \u0111\u1ed5i c\u00e1c \u0111\u01b0\u1eddng n\u00e9t ch\u00ednh c\u1ee7a b\u1ee9c \u1ea3nh nh\u01b0ng l\u1ea1i gi\u1ea3m \u0111\u01b0\u1ee3c k\u00edch th\u01b0\u1edbc c\u1ee7a \u1ea3nh. Do \u0111\u00f3 qu\u00e1 tr\u00ecnh gi\u1ea3m chi\u1ec1u ma tr\u1eadn \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng. Qu\u00e1 tr\u00ecnh n\u00e0y g\u1ecdi l\u00e0 t\u1ed5ng h\u1ee3p.\n\n* Qu\u00e1 tr\u00ecnh k\u1ebft n\u1ed1i ho\u00e0n to\u00e0n: Sau khi \u0111\u00e3 gi\u1ea3m s\u1ed1 l\u01b0\u1ee3ng tham s\u1ed1 \u0111\u1ebfn m\u1ed9t m\u1ee9c \u0111\u1ed9 h\u1ee3p l\u00fd, ma tr\u1eadn c\u1ea7n \u0111\u01b0\u1ee3c l\u00e0m d\u1eb9t (flatten) th\u00e0nh m\u1ed9t vector v\u00e0 s\u1eed d\u1ee5ng c\u00e1c k\u1ebft n\u1ed1i ho\u00e0n to\u00e0n gi\u1eefa c\u00e1c l\u1edbp. Qu\u00e1 tr\u00ecnh n\u00e0y s\u1ebd di\u1ec5n ra cu\u1ed1i m\u1ea1ng t\u00edch ch\u1eadp v\u00e0 s\u1eed d\u1ee5ng h\u00e0m k\u00edch ho\u1ea1t l\u00e0 relu. K\u1ebft n\u1ed1i cu\u1ed1i c\u00f9ng s\u1ebd d\u1eabn t\u1edbi c\u00e1c \u0111\u01a1n v\u1ecb l\u00e0 \u0111\u1ea1i di\u1ec7n cho m\u1ed7i l\u1edbp v\u1edbi h\u00e0m k\u00edch ho\u1ea1t l\u00e0 softmax nh\u1eb1m m\u1ee5c \u0111\u00edch t\u00ednh x\u00e1c xu\u1ea5t.\n\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*NQQiyYqJJj4PSYAeWvxutg.png)\n\n$\\text{H\u00ecnh 3: C\u1ea5u tr\u00fac \u0111\u1ea1i di\u1ec7n c\u1ee7a m\u1ed9t m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp, source: }$ [Mathworks.com](\u200aSource: https:\/\/www.mathworks.com\/videos\/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)\n\n\n## 1.4. T\u00ednh ch\u1ea5t c\u1ee7a m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp\n\n**T\u00ednh k\u1ebft n\u1ed1i tr\u01b0\u1ee3t:** Kh\u00e1c v\u1edbi c\u00e1c m\u1ea1ng n\u01a1 ron th\u00f4ng th\u01b0\u1eddng, m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp kh\u00f4ng k\u1ebft n\u1ed1i t\u1edbi to\u00e0n b\u1ed9 h\u00ecnh \u1ea3nh m\u00e0 ch\u1ec9 k\u1ebft n\u1ed1i t\u1edbi t\u1eebng *v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng* (local region) c\u00f3 k\u00edch th\u01b0\u1edbc b\u1eb1ng k\u00edch th\u01b0\u1edbc b\u1ed9 l\u1ecdc c\u1ee7a h\u00ecnh \u1ea3nh \u0111\u00f3. C\u00e1c b\u1ed9 l\u1ecdc s\u1ebd tr\u01b0\u1ee3t theo chi\u1ec1u c\u1ee7a \u1ea3nh t\u1eeb tr\u00e1i qua ph\u1ea3i v\u00e0 t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi \u0111\u1ed3ng th\u1eddi t\u00ednh to\u00e1n c\u00e1c gi\u00e1 tr\u1ecb t\u00edch ch\u1eadp v\u00e0 \u0111i\u1ec1n v\u00e0o *b\u1ea3n \u0111\u1ed3 k\u00edch ho\u1ea1t* (activation map).\n\n![](https:\/\/developer.apple.com\/library\/archive\/documentation\/Performance\/Conceptual\/vImage\/Art\/kernel_convolution.jpg)\n\n$\\text{H\u00ecnh 4: T\u00ednh t\u00edch ch\u1eadp tr\u00ean b\u1ea3n \u0111\u1ed3 k\u00edch ho\u1ea1t, \u200aSource:}$ [developer.apple.com](https:\/\/developer.apple.com\/library\/archive\/documentation\/Performance\/Conceptual\/vImage\/Art\/kernel_convolution.jpg)\n\n![](https:\/\/raw.githubusercontent.com\/iamaaditya\/iamaaditya.github.io\/master\/images\/conv_arithmetic\/full_padding_no_strides_transposed.gif)\n\n$\\text{H\u00ecnh 5: Qu\u00e1 tr\u00ecnh tr\u01b0\u1ee3t v\u00e0 t\u00ednh t\u00edch ch\u1eadp c\u1ee7a m\u1ed9t b\u1ed9 l\u1ecdc k\u00edch th\u01b0\u1edbc 3x3 tr\u00ean \u1ea3nh v\u00e0 k\u1ebft n\u1ed1i t\u1edbi b\u1ea3n \u0111\u1ed3 k\u00edch ho\u1ea1t, \u200aSource:}$ [github - iamaaditya](https:\/\/raw.githubusercontent.com\/iamaaditya\/iamaaditya.github.io\/master\/images\/conv_arithmetic\/full_padding_no_strides_transposed.gif)\n\n**C\u00e1c kh\u1ed1i n\u01a1 ron 3D:** Kh\u00f4ng gi\u1ed1ng nh\u01b0 nh\u1eefng m\u1ea1ng n\u01a1 ron th\u00f4ng th\u01b0\u1eddng khi c\u1ea5u tr\u00fac \u1edf m\u1ed7i l\u1edbp l\u00e0 m\u1ed9t ma tr\u1eadn 2D (s\u1ed1 quan s\u00e1t v\u00e0 s\u1ed1 \u0111\u01a1n v\u1ecb \u1edf m\u1ed7i l\u1edbp). C\u00e1c k\u1ebft qu\u1ea3 \u1edf m\u1ed7i l\u1edbp c\u1ee7a m\u1ed9t m\u1ea1ng n\u01a1 ron l\u00e0 m\u1ed9t kh\u1ed1i 3D \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp m\u1ed9t c\u00e1ch h\u1ee3p l\u00fd theo 3 chi\u1ec1u `width, height, depth`. Trong \u0111\u00f3 c\u00e1c chi\u1ec1u width v\u00e0 height \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n theo c\u00f4ng th\u1ee9c t\u00edch ch\u1eadp m\u1ee5c 1.1. Gi\u00e1 tr\u1ecb width ( height) c\u1ee7a m\u1ed9t l\u1edbp ph\u1ee5 thu\u1ed9c v\u00e0o k\u00edch th\u01b0\u1edbc c\u1ee7a b\u1ed9 l\u1ecdc, chi\u1ec1u width (height) c\u1ee7a l\u1edbp tr\u01b0\u1edbc, \u0111\u1ed9 r\u1ed9ng vi\u1ec1n v\u00e0 b\u01b0\u1edbc tr\u01b0\u1ee3t b\u1ed9 l\u1ecdc. Tuy nhi\u00ean chi\u1ec1u depth l\u1ea1i ho\u00e0n to\u00e0n kh\u00f4ng ph\u1ee5 thu\u1ed9c v\u00e0o nh\u1eefng tham s\u1ed1 n\u00e0y m\u00e0 n\u00f3 b\u1eb1ng v\u1edbi s\u1ed1 \u0111\u01a1n v\u1ecb trong l\u1edbp \u0111\u00f3. Qu\u00e1 tr\u00ecnh t\u00ednh b\u1ea3n \u0111\u1ed3 k\u00edch ho\u1ea1t d\u1ef1a tr\u00ean m\u1ed9t b\u1ed9 l\u1ecdc s\u1ebd t\u1ea1o ra m\u1ed9t ma tr\u1eadn 2D. Nh\u01b0 v\u1eady khi \u00e1p d\u1ee5ng cho d b\u1ed9 l\u1ecdc kh\u00e1c nhau, m\u1ed7i b\u1ed9 l\u1ecdc \u1ee9ng v\u1edbi m\u1ed9t \u0111\u01a1n v\u1ecb tr\u00ean m\u1ea1ng n\u01a1 ron, ta s\u1ebd thu \u0111\u01b0\u1ee3c d ma tr\u1eadn 2D c\u00f3 c\u00f9ng k\u00edch th\u01b0\u1edbc. Khi s\u1eafp x\u1ebfp ch\u1ed3ng l\u1ea5n c\u00e1c ma tr\u1eadn n\u00e0y k\u1ebft qu\u1ea3 \u0111\u1ea7u ra l\u00e0 m\u1ed9t kh\u1ed1i n\u01a1 ron 3D. Th\u00f4ng th\u01b0\u1eddng \u0111\u1ed1i v\u1edbi x\u1eed l\u00fd \u1ea3nh th\u00ec l\u1edbp \u0111\u1ea7u v\u00e0o n\u1ebfu c\u00e1c b\u1ee9c \u1ea3nh \u0111ang \u0111\u1ec3 \u1edf d\u1ea1ng m\u00e0u RBG th\u00ec depth = 3 (s\u1ed1 channels). B\u00ean d\u01b0\u1edbi l\u00e0 m\u1ed9t c\u1ea5u tr\u00fac m\u1ea1ng n\u01a1 ron \u0111i\u1ec3n h\u00ecnh c\u00f3 d\u1ea1ng kh\u1ed1i.\n![](https:\/\/www.mdpi.com\/remotesensing\/remotesensing-09-00848\/article_deploy\/html\/images\/remotesensing-09-00848-g001.png)\n\n$\\text{H\u00ecnh 6: C\u1ea5u tr\u00fac c\u00e1c kh\u1ed1i n\u01a1 ron 3D m\u1ea1ng Alexnet, \u200aSource:}$ [mdpi.com](https:\/\/www.mdpi.com\/remotesensing\/remotesensing-09-00848\/article_deploy\/html\/images\/remotesensing-09-00848-g001.png)\n\n**T\u00ednh chia s\u1ebb k\u1ebft n\u1ed1i v\u00e0 k\u1ebft n\u1ed1i c\u1ee5c b\u1ed9:** Ch\u00fang ta \u0111\u00e3 bi\u1ebft qu\u00e1 tr\u00ecnh bi\u1ebfn \u0111\u1ed5i trong m\u1ea1ng t\u00edch ch\u1eadp s\u1ebd k\u1ebft n\u1ed1i c\u00e1c kh\u1ed1i n\u01a1 ron 3D. Tuy nhi\u00ean c\u00e1c \u0111\u01a1n v\u1ecb s\u1ebd kh\u00f4ng k\u1ebft n\u1ed1i t\u1edbi to\u00e0n b\u1ed9 kh\u1ed1i 3D tr\u01b0\u1edbc \u0111\u00f3 theo chi\u1ec1u width v\u00e0 height m\u00e0 ch\u00fang s\u1ebd ch\u1ecdn ra c\u00e1c *v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng* c\u00f3 k\u00edch th\u01b0\u1edbc b\u1eb1ng v\u1edbi b\u1ed9 l\u1ecdc gi\u1ed1ng nh\u01b0 qu\u00e1 tr\u00ecnh t\u00ednh t\u00edch ch\u1eadp. C\u00e1c v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng s\u1ebd \u0111\u01b0\u1ee3c chia s\u1ebb chung m\u1ed9t b\u1ed9 si\u00eau tham s\u1ed1 g\u1ecdi l\u00e0 tr\u01b0\u1eddng ti\u1ebfp nh\u1eadn (receptive field) c\u1ee7a b\u1ed9 l\u1ecdc. Tuy nhi\u00ean c\u00e1c k\u1ebft n\u1ed1i c\u1ee5c b\u1ed9 ch\u1ec9 di\u1ec5n ra theo chi\u1ec1u width v\u00e0 height. K\u1ebft n\u1ed1i s\u1ebd m\u1edf r\u1ed9ng ho\u00e0n to\u00e0n theo chi\u1ec1u depth. Nh\u01b0 v\u1eady s\u1ed1 tham s\u1ed1 trong m\u1ed9t l\u1edbp s\u1ebd l\u00e0 $F \\times F \\times D$ ($F, D$ l\u1ea7n l\u01b0\u1ee3t l\u00e0 k\u00edch th\u01b0\u1edbc b\u1ed9 l\u1ecdc v\u00e0 chi\u1ec1u depth).\n\nM\u1ed7i b\u1ed9 l\u1ecdc \u0111\u1ea1i di\u1ec7n cho m\u1ed9t kh\u1ea3 n\u0103ng chi\u1ebft xu\u1ea5t m\u1ed9t \u0111\u1eb7c tr\u01b0ng n\u00e0o \u0111\u00f3. Do \u0111\u00f3 khi \u0111i qua to\u00e0n b\u1ed9 c\u00e1c v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng c\u1ee7a kh\u1ed1i n\u01a1 ron 3D, c\u00e1c \u0111\u1eb7c tr\u01b0ng \u0111\u01b0\u1ee3c chi\u1ebft xu\u1ea5t s\u1ebd hi\u1ec3n th\u1ecb tr\u00ean l\u1edbp m\u1edbi.\n\n\n![](http:\/\/cs231n.github.io\/assets\/cnn\/depthcol.jpeg)\n\n$\\text{H\u00ecnh 7: K\u1ebft n\u1ed1i c\u1ee5c b\u1ed9, \u200aSource:}$ [cs231n - stanford](http:\/\/cs231n.github.io\/assets\/cnn\/depthcol.jpeg)\n\n> Gi\u1ea3 s\u1eed ta c\u00f3 \u0111\u1ea7u v\u00e0o l\u00e0 m\u1ed9t b\u1ee9c \u1ea3nh 3 chi\u1ec1u k\u00edch t\u01b0\u1edbc 32x32x3. Khi \u0111\u00f3 m\u1ed7i \u0111\u01a1n v\u1ecb s\u1ebd ch\u1ec9 k\u1ebft n\u1ed1i t\u1edbi m\u1ed9t v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng theo chi\u1ec1u width v\u00e0 height nh\u01b0ng s\u1ebd m\u1edf r\u1ed9ng ho\u00e0n to\u00e0n k\u1ebft n\u1ed1i theo chi\u1ec1u depth. Ch\u00fang ta c\u00f3 t\u1ed5ng c\u1ed9ng 5 \u0111\u01a1n v\u1ecb (n\u01a1 ron) trong l\u1edbp c\u00f9ng nh\u00ecn v\u00e0o m\u1ed9t v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng n\u00e0y v\u00e0 s\u1ebd t\u1ea1o ra c\u00f9ng 1 v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng k\u00edch th\u01b0\u1edbc 1x1x5 tr\u00ean kh\u1ed1i n\u01a1 ron 3D m\u1edbi.\n\n**T\u00ednh t\u1ed5ng h\u1ee3p:** Ch\u00fang ta t\u01b0\u1edfng t\u01b0\u1ee3ng r\u1eb1ng \u1edf c\u00e1c l\u1edbp t\u00edch ch\u1eadp g\u1ea7n cu\u1ed1i s\u1ed1 tham s\u1ed1 s\u1ebd c\u1ef1c k\u00ec l\u1edbn do s\u1ef1 gia t\u0103ng c\u1ee7a chi\u1ec1u depth v\u00e0 th\u00f4ng th\u01b0\u1eddng s\u1ebd theo c\u1ea5p s\u1ed1 nh\u00e2n. Nh\u01b0 v\u1eady n\u1ebfu kh\u00f4ng c\u00f3 m\u1ed9t c\u01a1 ch\u1ebf ki\u1ec3m so\u00e1t s\u1ef1 gia t\u0103ng tham s\u1ed1, chi ph\u00ed t\u00ednh to\u00e1n s\u1ebd c\u1ef1c k\u00ec l\u1edbn v\u00e0 v\u01b0\u1ee3t qu\u00e1 kh\u1ea3 n\u0103ng c\u1ee7a m\u1ed9t s\u1ed1 m\u00e1y t\u00ednh c\u1ea5u h\u00ecnh y\u1ebfu (*Nh\u01b0 m\u00e1y c\u1ee7a m\u00ecnh ch\u1eb3ng h\u1ea1n, h\u01a1i \u0111\u00e1ng bu\u1ed3n*). M\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean l\u00e0 ch\u00fang ta s\u1ebd gi\u1ea3m k\u00edch th\u01b0\u1edbc c\u00e1c chi\u1ec1u width v\u00e0 height (down sampling) m\u00e0 v\u1eabn gi\u1eef nguy\u00ean \u0111\u01b0\u1ee3c c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u1ee7a kh\u1ed1i. C\u00e1c th\u1ef1c hi\u1ec7n t\u01b0\u01a1ng t\u1ef1 nh\u01b0 t\u00ednh t\u00edch ch\u1eadp nh\u01b0ng thay v\u00ec t\u00ednh t\u00edch hadamard gi\u1eefa ma tr\u1eadn b\u1ed9 l\u1ecdc v\u00e0 v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng ta s\u1ebd t\u00ednh trung b\u00ecnh (average pooling) ho\u1eb7c gi\u00e1 tr\u1ecb l\u1edbn nh\u1ea5t (max pooling) c\u1ee7a c\u00e1c ph\u1ea7n t\u1eed trong v\u00f9ng \u0111\u1ecba ph\u01b0\u01a1ng. Tr\u01b0\u1edbc \u0111\u00e2y c\u00e1c t\u00ednh trung b\u00ecnh \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng nhi\u1ec1u nh\u01b0ng c\u00e1c m\u00f4 h\u00ecnh hi\u1ec7n \u0111\u1ea1i \u0111\u00e3 thay th\u1ebf b\u1eb1ng gi\u00e1 tr\u1ecb l\u01a1n nh\u1ea5t do t\u1ed1c \u0111\u1ed9 t\u00ednh max nhanh h\u01a1n so v\u1edbi trung b\u00ecnh.\n\n![](http:\/\/cs231n.github.io\/assets\/cnn\/pool.jpeg)\n$\\text{H\u00ecnh 7: Qu\u00e1 tr\u00ecnh t\u1ed5ng h\u1ee3p, \u200aSource:}$ [cs231n - stanford](http:\/\/cs231n.github.io\/assets\/cnn\/depthcol.jpeg)\n\n> Ch\u1eb3ng h\u1ea1n ch\u00fang ta c\u00f3 m\u1ed9t kh\u1ed1i n\u01a1 ron 3D k\u00edch th\u01b0\u1edbc 224x224x64. S\u1ebd c\u1ea7n 224x224x64 = 3211264 tham s\u1ed1 \u0111\u1ec3 k\u1ebft n\u1ed1i t\u1edbi kh\u1ed1i n\u00e0y. Ch\u00fang ta s\u1ebd gi\u1ea3m k\u00edch th\u01b0\u1edbc k\u1ebft n\u1ed1i \u0111\u1ebfn kh\u1ed1i 4 l\u1ea7n th\u00f4ng qua gi\u1ea3m chi\u1ec1u width v\u00e0 height m\u1ed7i chi\u1ec1u 2 l\u1ea7n. Qu\u00e1 tr\u00ecnh gi\u1ea3m chi\u1ec1u d\u1eef li\u1ec7u s\u1ebd th\u1ef1c hi\u1ec7n l\u1ea7n l\u01b0\u1ee3t tr\u00ean c\u00e1c l\u00e1t c\u1eaft c\u1ee7a chi\u1ec1u depth v\u00e0 kh\u00f4ng l\u00e0m thay \u0111\u1ed5i \u0111\u1ed9 l\u1edbn depth. Kh\u1ed1i m\u1edbi c\u00f3 \u0111\u1eb7c tr\u01b0ng kh\u00f4ng \u0111\u1ed5i.\n\n**\u0110\u1ed9 ph\u1ee9c t\u1ea1p ph\u00e1t hi\u1ec7n h\u00ecnh \u1ea3nh t\u0103ng d\u1ea7n:** \u1ede l\u1edbp \u0111\u1ea7u ti\u00ean h\u00ecnh \u1ea3nh m\u00e0 ch\u00fang ta c\u00f3 ch\u1ec9 l\u00e0 nh\u1eefng gi\u00e1 tr\u1ecb pixels. Sau khi \u0111i qua l\u1edbp th\u1ee9 2 m\u00e1y t\u00ednh s\u1ebd nh\u1eadn di\u1ec7n \u0111\u01b0\u1ee3c c\u00e1c h\u00ecnh d\u1ea1ng c\u1ea1nh, r\u00eca v\u00e0 c\u00e1c \u0111\u01b0\u1eddng n\u00e9t \u0111\u01a1n gi\u1ea3n. C\u00e0ng \u1edf nh\u1eefng l\u1edbp t\u00edch ch\u1eadp v\u1ec1 sau c\u00e0ng c\u00f3 kh\u1ea3 n\u0103ng ph\u00e1t hi\u1ec7n c\u00e1c \u0111\u01b0\u1eddng n\u00e9t ph\u1ee9c t\u1ea1p ho\u1eb7c v\u1eadt th\u1ec3. \u0110\u1ea7u ra \u1edf l\u1edbp cu\u1ed1i c\u00f9ng l\u00e0 x\u00e1c xu\u1ea5t thu\u1ed9c v\u1ec1 m\u1ed7i l\u1edbp. \n\n![](https:\/\/i.stack.imgur.com\/oGBRR.jpg)\n$\\text{H\u00ecnh 8: H\u00ecnh \u1ea3nh m\u00f4 ph\u1ecfng c\u00e1c ph\u00e1t hi\u1ec7n sau m\u1ed7i l\u1edbp}$\n\n# 2. X\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp\n\nB\u00ean d\u01b0\u1edbi ta s\u1ebd ti\u1ebfn hanh x\u00e2y d\u1ef1ng m\u1ed9t m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp ph\u00e2n bi\u1ec7t ch\u1eef s\u1ed1 vi\u1ebft tay trong b\u1ed9 s\u1ed1 li\u1ec7u mnist th\u00f4ng qua s\u1eed d\u1ee5ng API estimator c\u1ee7a tensorflow. Ph\u1ea7n source code n\u00e0y \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb trang ch\u1ee7 c\u1ee7a tensorflow v\u00e0 \u0111\u01b0\u1ee3c hi\u1ec7u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi m\u1ee5c \u0111\u00edch c\u1ee7a b\u00e0i vi\u1ebft.","3e78e5ea":"Nh\u01b0 v\u1eady m\u1ea1ng n\u01a1 ron c\u1ee7a ch\u00fang ta s\u1ebd c\u00f3 c\u1ea5u tr\u00fac:\n\n* L\u1edbp input: C\u00f3 k\u00edch th\u01b0\u1edbc [-1, 28, 28, 1], s\u1ed1 -1 bi\u1ec3u th\u1ecb b\u1ea5t k\u00ec s\u1ed1 l\u01b0\u1ee3ng b\u1ee9c \u1ea3nh n\u00e0o c\u00f3 th\u1ec3 truy\u1ec1n v\u00e0o m\u00f4 h\u00ecnh. 3 th\u00e0nh ph\u1ea7n c\u00f2n l\u1ea1i l\u00e0 chi\u1ec1u r\u1ed9ng, chi\u1ec1u cao v\u00e0 k\u00eanh c\u1ee7a b\u1ee9c \u1ea3nh.\n\n* L\u1edbp t\u00edch ch\u1eadp s\u1ed1 1: G\u1ed3m 32 b\u1ed9 l\u1ecdc c\u00f3 k\u00edch th\u01b0\u1edbc [5, 5]. Ch\u00fang ta c\u00f3 th\u1ec3 khai b\u00e1o \u0111\u01a1n gi\u1ea3n l\u00e0 `kernel_size = 5` trong tr\u01b0\u1eddng h\u1ee3p b\u1ed9 l\u1ecdc l\u00e0 vu\u00f4ng. Tham s\u1ed1 `padding = same` \u0111\u1ec3 c\u1ed1 \u0111\u1ecbnh k\u00edch th\u01b0\u1edbc c\u1ee7a \u0111\u1ea7u ra so v\u1edbi \u0111\u1ea7u v\u00e0o. Khi \u0111\u00f3 l\u1edbp s\u1ebd t\u1ef1 \u0111\u1ed9ng th\u00eam vi\u1ec1n ngo\u00e0i \u0111\u1ec3 k\u00edch th\u01b0\u1edbc kh\u00f4ng \u0111\u1ed5i theo c\u00f4ng th\u1ee9c $P = \\frac{W_1(S-1)-1+F}{2}$. Nh\u01b0 v\u1eady sau b\u01b0\u1edbc n\u00e0y k\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra v\u1eabn s\u1ebd l\u00e0 [-1, 28, 28, 1].\n\n* L\u1edbp ch\u1ed3ng ch\u1ea5t s\u1ed1 1: C\u00f3 k\u00edch th\u01b0\u1edbc c\u1ee7a b\u1ed9 l\u1ecdc l\u00e0 [2, 2] v\u00e0 b\u01b0\u1edbc nh\u1ea3y l\u00e0 2. \u00c1p d\u1ee5ng c\u00f4ng th\u1ee9c t\u00ednh k\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra ta s\u1ebd suy ra w2 = h2 = (28-2)\/2+1 = 14. K\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra sau b\u01b0\u1edbc n\u00e0y l\u00e0 [-1, 14, 14, 1].\n\n* L\u1edbp t\u00edch ch\u1eadp s\u1ed1 2: G\u1ed3m 64 b\u1ed9 l\u1ecdc c\u00f3 k\u00edch th\u01b0\u1edbc [5, 5] v\u00e0 th\u00e1m s\u1ed1 `padding = same` s\u1ebd kh\u00f4ng thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra so v\u1edbi l\u1edbp tr\u01b0\u1edbc l\u00e0 [-1, 14, 14, 1].\n\n* L\u1edbp ch\u1ed3ng ch\u1ea5t s\u1ed1 2: Gi\u1ed1ng v\u1edbi l\u1edbp ch\u1ed3ng ch\u1ea5t s\u1ed1 1 v\u1edbi b\u1ed9 l\u1ecdc k\u00edch th\u01b0\u1edbc [2, 2] v\u00e0 b\u01b0\u1edbc nh\u1ea3y 2. Do \u0111\u00f3 chi\u1ec1u d\u00e0i v\u00e0 r\u1ed9ng c\u1ee7a ma tr\u1eadn \u0111\u1ea7u ra s\u1ebd l\u00e0 w2 = h2 = (14-2)\/2+1 = 7. K\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra: [-1, 7, 7, 1].\n\n* L\u1edbp vector d\u00e0n ph\u1eb3ng: Ma tr\u1eadn \u1edf l\u1edbp tr\u01b0\u1edbc s\u1ebd \u0111\u01b0\u1ee3c d\u00e0nh ph\u1eb3ng n\u00ean c\u00f3 k\u00edch th\u01b0\u1edbc l\u00e0 7x7. K\u1ebft h\u1ee3p v\u1edbi chi\u1ec1u s\u00e2u = 64 l\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u0111\u01a1n v\u1ecb \u1edf layer tr\u01b0\u1edbc ta suy ra k\u00edch th\u01b0\u1edbc c\u1ee7a l\u1edbp n\u00e0y l\u00e0 7x7x64 = 3136.\n\n* L\u1edbp dropout: L\u1edbp n\u00e0y kh\u00f4ng l\u00e0m thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc c\u1ee7a l\u1edbp tr\u01b0\u1edbc m\u00e0 ch\u1ec9 t\u00e1c \u0111\u1ed9ng v\u00e0o qu\u00e1 tr\u00ecnh training khi s\u1ebd t\u1eaft ng\u1eabu nhi\u00ean c\u00e1c \u0111\u01a1n v\u1ecb c\u1ee7a l\u1edbp tr\u01b0\u1edbc v\u1edbi x\u00e1c xu\u1ea5t l\u00e0 `rate = 0.4` b\u1eb1ng c\u00e1ch g\u00e1n cho tr\u1ecdng s\u1ed1 \u1ee9ng v\u1edbi \u0111\u01a1n v\u1ecb b\u1ecb t\u1eaft b\u1eb1ng 0. \u0110\u00e2y l\u00e0 m\u1ed9t k\u0129 thu\u1eadt trong *ki\u1ec3m so\u00e1t* (regularization) m\u00f4 h\u00ecnh nh\u1eb1m gi\u1ea3m thi\u1ec3u overfiting v\u00e0 t\u0103ng m\u1ee9c \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a d\u1ef1 b\u00e1o v\u00e0 t\u1ed1c \u0111\u1ed9 hu\u1ea5n luy\u1ec7n.\n\n* L\u1edbp output: L\u00e0 m\u1ed9t k\u1ebft n\u1ed1i ho\u00e0n to\u00e0n t\u1edbi 10 \u0111\u01a1n v\u1ecb \u0111\u1ea1i di\u1ec7n cho 10 nh\u00f3m ch\u1eef s\u1ed1 c\u1ea7n ph\u00e2n lo\u1ea1i.\n\nB\u00ean d\u01b0\u1edbi ch\u00fang ta s\u1ebd load d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o d\u01b0\u1edbi d\u1ea1ng numpy.","aa8354d6":"# 1. L\u00fd thuy\u1ebft v\u1ec1 m\u1ea1ng t\u00edch ch\u1eadp\n\n## 1.1. Gi\u1edbi thi\u1ec7u t\u00edch ch\u1eadp\n\nT\u00edch ch\u1eadp l\u00e0 m\u1ed9t kh\u00e1i ni\u1ec7m trong x\u1eed l\u00fd t\u00edn hi\u1ec7u s\u1ed1 nh\u1eb1m bi\u1ebfn \u0111\u1ed5i th\u00f4ng tin \u0111\u1ea7u v\u00e0o th\u00f4ng qua m\u1ed9t ph\u00e9p t\u00edch ch\u1eadp v\u1edbi b\u1ed9 l\u1ecdc \u0111\u1ec3 tr\u1ea3 v\u1ec1 \u0111\u1ea7u ra l\u00e0 m\u1ed9t t\u00edn hi\u1ec7u m\u1edbi. T\u00edn hi\u1ec7u n\u00e0y s\u1ebd l\u00e0m gi\u1ea3m nh\u1eefng \u0111\u1eb7c tr\u01b0ng m\u00e0 b\u1ed9 l\u1ecdc kh\u00f4ng quan t\u00e2m v\u00e0 ch\u1ec9 gi\u1eef nh\u1eefng \u0111\u1eb7c tr\u01b0ng ch\u00ednh. \n\nT\u00edch ch\u1eadp th\u00f4ng d\u1ee5ng nh\u1ea5t l\u00e0 t\u00edch ch\u1eadp 2 chi\u1ec1u \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng tr\u00ean ma tr\u1eadn \u0111\u1ea7u v\u00e0o v\u00e0 ma tr\u1eadn b\u1ed9 l\u1ecdc 2 chi\u1ec1u. Ph\u00e9p t\u00edch ch\u1eadp c\u1ee7a m\u1ed9t ma tr\u1eadn $\\mathbf{X} \\in \\mathbb{R}^{W_1 \\times H_1}$ v\u1edbi m\u1ed9t *b\u1ed9 l\u1ecdc* (receptive field) $\\mathbf{F} \\in \\mathbb{R}^{F \\times F}$ l\u00e0 m\u1ed9t ma tr\u1eadn $\\mathbf{Y} \\in \\mathbb{R}^{W_2 \\times H_2}$ s\u1ebd tr\u1ea3 qua nh\u1eefng b\u01b0\u1edbc sau:\n\n* T\u00ednh t\u00edch ch\u1eadp t\u1ea1i 1 \u0111i\u1ec3m:\nT\u1ea1i v\u1ecb tr\u00ed \u0111\u1ea7u ti\u00ean tr\u00ean c\u00f9ng c\u1ee7a ma tr\u1eadn \u0111\u1ea7u v\u00e0o ta s\u1ebd l\u1ecdc ra m\u1ed9t ma tr\u1eadn con $\\mathbf{X}_{sub} \\in \\mathbb{R}^{F \\times F}$ c\u00f3 k\u00edch th\u01b0\u1edbc b\u1eb1ng v\u1edbi k\u00edch th\u01b0\u1edbc c\u1ee7a b\u1ed9 l\u1ecdc. Gi\u00e1 tr\u1ecb $y_{11}$ t\u01b0\u01a1ng \u1ee9ng tr\u00ean $\\mathbf{Y}$ l\u00e0 t\u00edch ch\u1eadp c\u1ee7a $\\mathbf{X}_{sub}$ v\u1edbi $\\mathbf{F}$ \u0111\u01b0\u1ee3c t\u00ednh nh\u01b0 sau:\n$$y_{11}= \\sum_{i = 1}^{F}  \\sum_{j = 1}^{F} x_{ij} f_{ij}$$ \n* Ti\u1ebfn h\u00e0nh tr\u01b0\u1ee3t d\u1ecdc theo ma tr\u1eadn theo chi\u1ec1u t\u1eeb tr\u00e1i qua ph\u1ea3i, t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi theo *b\u01b0\u1edbc nh\u1ea3y* (stride) $S$ ta s\u1ebd t\u00ednh \u0111\u01b0\u1ee3c c\u00e1c gi\u00e1 tr\u1ecb $y_{ij}$ ti\u1ebfp theo. Sau khi qu\u00e1 tr\u00ecnh n\u00e0y k\u1ebft th\u00fac ta thu \u0111\u01b0\u1ee3c tr\u1ecdn v\u1eb9n ma tr\u1eadn $\\mathbf{Y}$.\n\nTrong m\u1ed9t m\u1ea1ng n\u01a1 ron t\u00edch ch\u1eadp, c\u00e1c l\u1edbp li\u1ec1n sau l\u1ea5y \u0111\u1ea7u v\u00e0o t\u1eeb l\u1edbp li\u1ec1n tr\u01b0\u1edbc n\u00f3. Do \u0111\u00f3 \u0111\u1ec3 h\u1ea1n ch\u1ebf l\u1ed7i trong thi\u1ebft k\u1ebf m\u1ea1ng n\u01a1 ron ch\u00fang ta c\u1ea7n x\u00e1c \u0111\u1ecbnh k\u00edch th\u01b0\u1edbc \u0111\u1ea7u ra \u1edf m\u1ed7i l\u1edbp. \u0110i\u1ec1u \u0111\u00f3 c\u00f3 ngh\u0129a l\u00e0 d\u1ef1a v\u00e0o k\u00edch th\u01b0\u1edbc ma tr\u1eadn \u0111\u1ea7u v\u00e0o $(W_1, H_1)$, k\u00edch th\u01b0\u1edbc b\u1ed9 l\u1ecdc $(F, F)$ v\u00e0 b\u01b0\u1edbc nh\u1ea3y $S$ \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh k\u00edch th\u01b0\u1edbc ma tr\u1eadn \u0111\u1ea7u ra $(W_2, H_2)$.\n\nX\u00e9t qu\u00e1 tr\u00ecnh tr\u01b0\u1ee3t tr\u00ean chi\u1ec1u $W_1$ c\u1ee7a ma tr\u1eadn \u0111\u1ea7u v\u00e0o. \n\n![](https:\/\/raw.githubusercontent.com\/phamdinhkhanh\/Tensorflow\/master\/ConvWidthStep.png)\n$$\\text{H\u00ecnh 1: Qu\u00e1 tr\u00ecnh tr\u01b0\u1ee3t theo chi\u1ec1u r\u1ed9ng (W1)}$$\n\nGi\u1ea3 s\u1eed qu\u00e1 tr\u00ecnh n\u00e0y s\u1ebd d\u1eebng sau $W_2$ b\u01b0\u1edbc. T\u1ea1i b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean qu\u00e1 tr\u00ecnh \u0111i \u0111\u01b0\u1ee3c \u0111\u1ebfn v\u1ecb tr\u00ed th\u1ee9 $F$. Sau m\u1ed7i b\u01b0\u1edbc li\u1ec1n sau s\u1ebd t\u0103ng so v\u1edbi v\u1ecb tr\u00ed li\u1ec1n tr\u01b0\u1edbc l\u00e0 $S$. Nh\u01b0 v\u1eady \u0111\u1ebfn b\u01b0\u1edbc th\u1ee9 $i$ qu\u00e1 tr\u00ecnh tr\u01b0\u1ee3t s\u1ebd \u0111i \u0111\u1ebfn v\u1ecb tr\u00ed $F+(i-1)S$. Suy ra t\u1ea1i b\u01b0\u1edbc cu\u1ed1i c\u00f9ng $W_2$ ma tr\u1eadn s\u1ebd \u0111i \u0111\u1ebfn v\u1ecb tr\u00ed $F+(W_2-1)S$. \u0110\u00e2y l\u00e0 v\u1ecb tr\u00ed l\u1edbn nh\u1ea5t g\u1ea7n v\u1edbi v\u1ecb tr\u00ed cu\u1ed1i c\u00f9ng l\u00e0 $W_1$. Trong tr\u01b0\u1eddng h\u1ee3p l\u00fd t\u01b0\u1edfng th\u00ec $F+(W_2-1)S = W_1$. T\u1eeb \u0111\u00f3 ta suy ra:\n$$W_2 = \\frac{W_1-F}{S}+1 \\tag{1}$$\nKhi v\u1ecb tr\u00ed cu\u1ed1i c\u00f9ng kh\u00f4ng tr\u00f9ng v\u1edbi $W_1$ th\u00ec s\u1ed1 b\u01b0\u1edbc $W_2$ s\u1ebd \u0111\u01b0\u1ee3c l\u1ea5y ph\u1ea7n nguy\u00ean:\n$$W_2 = [\\frac{W_1-F}{S}]+1$$\n\nCh\u00fang ta lu\u00f4n c\u00f3 th\u1ec3 t\u1ea1o ra \u0111\u1eb3ng th\u1ee9c (1) nh\u1edd th\u00eam ph\u1ea7n *\u0111\u01b0\u1eddng vi\u1ec1n* (padding) t\u1ea1i c\u00e1c c\u1ea1nh c\u1ee7a \u1ea3nh v\u1edbi \u0111\u1ed9 r\u1ed9ng vi\u1ec1n l\u00e0 $P$ sao cho ph\u00e9p chia cho $S$ l\u00e0 chia h\u1ebft. Khi \u0111\u00f3: $$W_2 = \\frac{W_1+2P-F}{S}+1$$\n\n![](https:\/\/raw.githubusercontent.com\/phamdinhkhanh\/Tensorflow\/master\/WidthPadding.png)\n$$\\text{H\u00ecnh 2: Th\u00eam padding k\u00edch th\u01b0\u1edbc P v\u00e0o 2 l\u1ec1 chi\u1ec1u r\u1ed9ng (W1)}$$\n\nHo\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 ta c\u0169ng c\u00f3 c\u00f4ng th\u1ee9c \u1ee9ng v\u1edbi chi\u1ec1u cao: $$H_2 = \\frac{H_1+2P-F}{S}+1$$\n\n## 1.2. Th\u1ef1c h\u00e0nh m\u1ea1ng t\u00edch ch\u1eadp\n\nTrong v\u00ed d\u1ee5 b\u00ean d\u01b0\u1edbi ta s\u1ebd th\u1ef1c h\u00e0nh s\u1eed d\u1ee5ng m\u1ea1ng t\u00edch ch\u1eadp \u0111\u1ec3 chi\u1ebft xu\u1ea5t c\u00e1c \u0111\u1eb7c tr\u01b0ng ch\u00ednh c\u1ee7a m\u1ed9t b\u1ee9c \u1ea3nh. Th\u00f4ng qua hai b\u1ed9 l\u1ecdc th\u00f4ng d\u1ee5ng nh\u1ea5t l\u00e0 b\u1ed9 l\u1ecdc ngang $\\left[\\begin{matrix} -1 & -1 & -1 \\\\ 0\n& 0 & 0 \\\\ 1 & 1 & 1\\end{matrix}\\right]$ \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 chi\u1ebft xu\u1ea5t c\u00e1c \u0111\u01b0\u1eddng n\u1eb1m ngang v\u00e0 b\u1ed9 l\u1ecdc d\u1ecdc $\\left[\\begin{matrix} -1 & 0 & 1 \\\\ -1\n& 0 & 1 \\\\ -1 & 0 & 1\\end{matrix}\\right]$ d\u00f9ng \u0111\u1ec3 chi\u1ebft xu\u1ea5t c\u00e1c \u0111\u01b0\u1eddng n\u00e9t n\u1eb1m d\u1ecdc t\u1eeb 1 b\u1ee9c \u1ea3nh."}}