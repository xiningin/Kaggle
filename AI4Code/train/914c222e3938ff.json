{"cell_type":{"bd382c7e":"code","89bc377f":"code","551835c1":"code","ab338bc2":"code","f16bb14d":"code","3e2f1459":"code","b3c5acac":"code","636c40e3":"code","3c3fa629":"code","91b66b1c":"code","fd53e18f":"code","4d3b5be1":"code","d2eafc17":"code","94964a08":"code","9633c03e":"code","d9876e64":"code","487f7614":"code","880d2de0":"code","17d58050":"code","e7ac6748":"code","0833fbb1":"code","130dfe50":"code","263036c5":"code","64fd32ed":"code","0b663307":"code","42fa7458":"code","bfacd7cd":"code","974c0f2c":"code","5d06b412":"code","6353e79a":"code","62af956e":"code","df736722":"code","cc514b12":"code","ede12a3b":"code","8b911eb7":"code","6de0eefe":"markdown","451950a1":"markdown","4ec52aff":"markdown","2a01d214":"markdown","134bcc85":"markdown","7b7bf0cf":"markdown","e1c3062d":"markdown"},"source":{"bd382c7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89bc377f":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","551835c1":"from PIL import Image\n\nimg = Image.open(\"..\/input\/maleandfemale\/data1\/validation\/male\/7733.jpg\")\nimg\n","ab338bc2":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)","f16bb14d":"def _add1(x): return x+1\ndumb_tfm = RandTransform(enc=_add1, p=0.5)\nstart,d1,d2 = 2,False,False\nfor _ in range(40):\n    t = dumb_tfm(start, split_idx=0)\n    if dumb_tfm.do: test_eq(t, start+1); d1=True\n    else:           test_eq(t, start)  ; d2=True\nassert d1 and d2\ndumb_tfm","3e2f1459":"_,axs = subplots(1,2)\nshow_image(img, ctx=axs[0], title='original')\nshow_image(img.flip_lr(), ctx=axs[1], title='flipped');","b3c5acac":"img.resize((64,64))","636c40e3":"timg = TensorImage(image2tensor(img))\ntpil = PILImage.create(timg)","3c3fa629":"tpil.resize((64,64))","91b66b1c":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)\n\ndef flip_lr(x:Image.Image): return x.transpose(Image.FLIP_LEFT_RIGHT)\ndef flip_lr(x:TensorImageBase): return x.flip(-1)\ndef flip_lr(x:TensorPoint): return TensorPoint(_neg_axis(x.clone(), 0))\ndef flip_lr(x:TensorBBox):  return TensorBBox(TensorPoint(x.view(-1,2)).flip_lr().view(-1,4))","fd53e18f":"img = PILImage(PILImage.create(timg).resize((600,400)))\nimg","4d3b5be1":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(img.crop_pad(sz), ctx=ax, title=f'Size {sz}');","d2eafc17":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,mode in zip(axs.flatten(), [PadMode.Zeros, PadMode.Border, PadMode.Reflection]):\n    show_image(img.crop_pad((600,700), pad_mode=mode), ctx=ax, title=mode);","94964a08":"_,axs = plt.subplots(1,3,figsize=(12,4))\nf = RandomCrop(200)\nfor ax in axs: show_image(f(img), ctx=ax);","9633c03e":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax in axs: show_image(f(img, split_idx=1), ctx=ax);","d9876e64":"test_eq(ResizeMethod.Squish, 'squish')","487f7614":"Resize(224)","880d2de0":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,method in zip(axs.flatten(), [ResizeMethod.Squish, ResizeMethod.Pad, ResizeMethod.Crop]):\n    rsz = Resize(256, method=method)\n    show_image(rsz(img, split_idx=0), ctx=ax, title=method);","17d58050":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,method in zip(axs.flatten(), [ResizeMethod.Squish, ResizeMethod.Pad, ResizeMethod.Crop]):\n    rsz = Resize(256, method=method)\n    show_image(rsz(img, split_idx=1), ctx=ax, title=method);","e7ac6748":"crop = RandomResizedCrop(256)\n_,axs = plt.subplots(3,3,figsize=(9,9))\nfor ax in axs.flatten():\n    cropped = crop(img)\n    show_image(cropped, ctx=ax);","0833fbb1":"_,axs = subplots(1,3)\nfor ax in axs.flatten(): show_image(crop(img, split_idx=1), ctx=ax);","130dfe50":"test_eq(cropped.shape, [256,256])","263036c5":"RatioResize(256)(img)","64fd32ed":"test_eq(RatioResize(256)(img).size[0], 256)\ntest_eq(RatioResize(256)(img.dihedral(3)).size[1], 256)","0b663307":"timg = TensorImage(array(img)).permute(2,0,1).float()\/255.\ndef _batch_ex(bs): return TensorImage(timg[None].expand(bs, *timg.shape).clone())","42fa7458":"tflip = FlipItem(p=1.)","bfacd7cd":"bbox = TensorBBox(((tensor([[1.,0., 2.,1]]) -1)[None]))\nx=test_eq(tflip(bbox,split_idx=0), tensor([[1.,0., 0.,1]]) -1)","974c0f2c":"_,axs = subplots(2, 4)\nfor ax in axs.flatten():\n    show_image(DihedralItem(p=1.)(img, split_idx=0), ctx=ax)","5d06b412":"x = flip_mat(torch.randn(100,4,3))\ntest_eq(set(x[:,0,0].numpy()), {-1,1}) #might fail with probability 2*2**(-100) (picked only 1s or -1s)","6353e79a":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(img.crop_pad(sz), ctx=ax, title=f'Size {sz}')","62af956e":"_,axs = plt.subplots(1,3,figsize=(12,4))\nf = RandomCrop(200)\nfor ax in axs: show_image(f(img), ctx=ax)","df736722":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax in axs: show_image(f(img, split_idx=1), ctx=ax)","cc514b12":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,method in zip(axs.flatten(), [ResizeMethod.Squish, ResizeMethod.Pad, ResizeMethod.Crop]):\n    rsz = Resize(256, method=method)\n    show_image(rsz(img, split_idx=0), ctx=ax, title=method)","ede12a3b":"crop = RandomResizedCrop(256)\n_,axs = plt.subplots(3,3,figsize=(9,9))\nfor ax in axs.flatten():\n    cropped = crop(img)\n    show_image(cropped, ctx=ax)","8b911eb7":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks Johar M. Ashfaque (@ukveteran) for fixing this Notebook' )","6de0eefe":"#Randomly flip with probability p","451950a1":"#I tried to make some augmentation with fastai V2. Some of the snippets worked.I hope anyone could give tips to fix the issues. ","4ec52aff":"#From now, only Errors. I hope anyone say something, so that I can fix that snippets.","2a01d214":"#Randomly crop an image to size","134bcc85":"#Image.flip","7b7bf0cf":"#Center crop","e1c3062d":"#Script fixed by Johar M. Ashfaque https:\/\/www.kaggle.com\/ukveteran\/tiger-fastai-jma\/notebook"}}