{"cell_type":{"e030e69a":"code","9cc60c66":"code","0ad12437":"code","f6061e18":"code","70b8427b":"code","3415fe53":"code","6a9a6265":"code","2d01a1c8":"code","12f856de":"code","95811a8d":"code","21dbf08a":"code","59365fe1":"code","76c8e1c4":"code","82246656":"code","b644ed23":"code","d89eef64":"code","12479db2":"code","b486c460":"code","ffd54744":"code","bb2e72e3":"code","1e0ecfa4":"code","a9e41414":"code","c1c21e2a":"code","856128d6":"code","e11eddf8":"code","2e650a64":"code","5872c0a7":"code","23b763b0":"code","b55ec73f":"code","c04ff304":"code","7a51c12b":"code","a1e9b01e":"code","3a2206a1":"code","ccba7134":"code","1e05e4f7":"code","e3640c7d":"code","893e14bf":"code","0ee2ebc6":"code","907a3d48":"code","082fdca0":"code","4a408576":"code","d3d29a3c":"code","6e7ef1c8":"markdown","2a6ecaab":"markdown","fe3ca8d5":"markdown","6097fbf5":"markdown","dba0d423":"markdown","09d06481":"markdown","c0f189aa":"markdown","fe199334":"markdown","3cc9fe88":"markdown","e1a1b237":"markdown","cea45aaf":"markdown","08dcfa8c":"markdown","00289bbb":"markdown","1a7c7dd0":"markdown","f585da96":"markdown","07ebfaab":"markdown","e79cad1e":"markdown","218fd890":"markdown","119c3c27":"markdown","f418cf97":"markdown","cb6f0a7c":"markdown","59878979":"markdown","39633ad7":"markdown","203dede7":"markdown","1c8c832f":"markdown","e9300ae8":"markdown","1d77cfbf":"markdown","db536ac5":"markdown","47ee7e5d":"markdown","d74e7c0a":"markdown","9f22bca4":"markdown","3398e7f6":"markdown"},"source":{"e030e69a":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier","9cc60c66":"data = pd.read_csv(\"..\/input\/Iris.csv\")\ndata.shape","0ad12437":"data.head(10)","f6061e18":"data.tail(10)","70b8427b":"data.isnull().any().any()","3415fe53":"# Dropping the ID column\ndata.drop('Id',inplace=True,axis=1)","6a9a6265":"data.columns\ncols = list(data.columns)\ncols\n","2d01a1c8":"range = data[\"SepalLengthCm\"].max() - data[\"SepalLengthCm\"].min()\nrange","12f856de":"data[\"SepalLengthCm\"] = (data[\"SepalLengthCm\"] - data[\"SepalLengthCm\"].min())\/range\ndata.head()","95811a8d":"data[\"SepalLengthCm\"] = data[\"SepalLengthCm\"] \/ data[\"SepalLengthCm\"].max()","21dbf08a":"data.head()","59365fe1":"data = pd.read_csv(\"..\/input\/Iris.csv\")\ndata.shape","76c8e1c4":"data.head()","82246656":"group_names = data['Species'].unique().tolist()\ngroup_names","b644ed23":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d89eef64":"sns.scatterplot(x = 'SepalLengthCm', y = 'SepalWidthCm', data = data, hue = 'Species')\nplt.title('Sepal Length vs Sepal Width')\nplt.show()","12479db2":"data['SepalLengthCm'].corr(data['SepalWidthCm'])","b486c460":"sns.scatterplot(x = 'PetalLengthCm', y = 'PetalWidthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Petal Width')\nplt.show()","ffd54744":"data['PetalLengthCm'].corr(data['PetalWidthCm'])","bb2e72e3":"sns.scatterplot(x = 'PetalLengthCm', y = 'SepalLengthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Sepal Length')\nplt.show()","1e0ecfa4":"data['PetalLengthCm'].corr(data['SepalLengthCm'])","a9e41414":"sns.scatterplot(x = 'PetalWidthCm', y = 'SepalWidthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Sepal Length')\nplt.show()","c1c21e2a":"data['PetalWidthCm'].corr(data['SepalWidthCm'])","856128d6":"sns.boxplot(x = \"Species\", y = \"PetalLengthCm\", data = data)","e11eddf8":"no_id_data = data.copy()\nno_id_data.drop(\"Id\", axis = 1, inplace = True)\nsns.heatmap(data = no_id_data.corr(), annot = True)\nplt.show()","2e650a64":"x_values = data['PetalLengthCm'].copy()\ny_values = data['PetalWidthCm'].copy()","5872c0a7":"x_train, x_test, y_train1, y_test1 = train_test_split(x_values, y_values, test_size = 0.33, random_state = 3)","23b763b0":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","b55ec73f":"species_dummy = pd.get_dummies(data[\"Species\"])\nspecies_dummy.head()","c04ff304":"assigned_data = data.copy()","7a51c12b":"assigned_data = pd.concat([data, species_dummy], axis = 1)\nassigned_data.head()","a1e9b01e":"assigned_data.drop([\"Id\"], inplace = True, axis = 1)\nassigned_data.head()","3a2206a1":"target = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\nfeatures = cols[0:4]\nprint(target)\nprint(features)","ccba7134":"y = assigned_data[target].copy()\nX = assigned_data[features].copy()","1e05e4f7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 3)","e3640c7d":"print(X_train.describe())\nX_train.head()","893e14bf":"y_train.head(10)","0ee2ebc6":"iris_classifier = DecisionTreeClassifier(max_leaf_nodes = 4, random_state = 0)\niris_classifier.fit(X_train, y_train)","907a3d48":"y_prediction = iris_classifier.predict(X_test)","082fdca0":"y_prediction[0 : 10]","4a408576":"y_test[0:10]","d3d29a3c":"accuracy_score(y_true = y_test, y_pred = y_prediction)","6e7ef1c8":"#### PetalLength vs PetalWidth","2a6ecaab":"> **Analysis**: This is a very insightful graph. It tells us that we can use PetalLength to predict PetalWidth and it's category because of the proper clustrering of data points. The correlation is also very high. We can use these features for regression analysis later. **","fe3ca8d5":"Importing necessary libraries ","6097fbf5":"### Scatterplots","dba0d423":"<p style=\"font-family: Arial; font-size:1.75em; color:blue; font-style:bold\"><br>\n\nPredict on Test Set \n\n<br><br><\/p>\n","09d06481":"We can see that there is a very high correlation between Petal Length and Petal Width. ","c0f189aa":"Let's divide the data into training and test sets","fe199334":"Classification ","3cc9fe88":"#### PetalWidth vs SepalWidth","e1a1b237":"## Conclusion \n<br> \nI want to know  the reason for this 100% accuracy. Is it because these are highly correlated variables? \n\nThings to note:- \n1. If I decrease the size of the training set, I can reduce the accuracy which is obvious but still mentioning. **Is it a bad practice to take 0.1 as the test size? **\n2. Even if I do not scale the values, I can get a 100% result. The scaling was for my own knowledge. ","cea45aaf":"### Boxplot","08dcfa8c":"## Data Cleaning \nLet's look for any null values to find out whether there needs to be null values. ","00289bbb":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\">\nConvert to a Classification Task <br><\/p>\n","1a7c7dd0":"We can see now that we have quite a randomized group of values for y_train and X_train. Let's build our classifier model. ","f585da96":"#### SepalLength vs SepalWidth ","07ebfaab":"#### PetalLength vs SepalLength","e79cad1e":"Importing necessary libraries","218fd890":"Regression Libraries","119c3c27":"### Adding Dummy Variables \n","f418cf97":"We will use the min - max method to scale the values down ","cb6f0a7c":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nCreating a Pandas DataFrame from a CSV file<br><\/p>\n\n","59878979":"## Plotting \n\nLet's plot scatter plots to see the differences in the different features across different Species ","39633ad7":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nMeasure Accuracy of the Classifier\n<br><br><\/p>\n","203dede7":"## Correlation Heat Map\nLet's make a correlation heatmap to understand the correlation between different species.","1c8c832f":"> **Analysis**: There isn't a lot of correlation. There is good clustering but let's see if we can get something better ","e9300ae8":"# IRIS DATASET \nExploring Iris dataset through different methods. \n\n1. Plotting various features against their categories\n3. Linear Regression \n4. Correlation \n4. Decision Tree Classification \n5. Accuracy Measurement","1d77cfbf":"> **Analysis**: We can see that there is a lot of correlation in Iris-Setosa category when it comes to Sepal Length and SepalWidth but not a similar distinction for the other two categories. The correlation does not seem very strong either. ","db536ac5":"As we can see, there are no null values in this data. Hence, we do not need to perform data cleaning. ","47ee7e5d":"## Linear Regression ( Extra Work : Skip ahead to the 100% accuracy classification ) \nLet's try and predict the Petal Width from the Petal Length","d74e7c0a":"## Scaling the values ( Data Normalisation) ","9f22bca4":"> **Analysis**: There is high correlation but we still do not get a very linear graph which is important. There is good  clustering but let's see if we can get something better ","3398e7f6":"## Reverting \nI reverted back to the same values to avoid major scale down and maintain some variance to allow for distinguishable features. "}}