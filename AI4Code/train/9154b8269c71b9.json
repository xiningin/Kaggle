{"cell_type":{"50e3966a":"code","aebaa28f":"code","c583eddf":"code","80023732":"code","194a10d9":"code","c29875f8":"code","0391154d":"code","e096f19b":"code","0561039a":"code","cb1847d5":"code","8b82a803":"code","27b6b47f":"code","4509b610":"code","b6627099":"code","01c14d69":"code","c4745dac":"code","4706c3f7":"code","2a2ca04d":"code","57c0939d":"code","3f490f25":"code","66b84292":"markdown","221aca04":"markdown"},"source":{"50e3966a":"# https:\/\/medium.com\/swlh\/8-automl-libraries-to-automate-machine-learning-pipeline-3da0af08f636","aebaa28f":"%%capture\n!pip install autoviml","c583eddf":"%%capture\n!pip install shap","80023732":"from __future__ import print_function\nimport sys,tempfile, urllib, os\nimport pandas as pd","194a10d9":"from sklearn.model_selection import train_test_split\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\ny = train.SalePrice\n\ntrain.drop(['Id', 'SalePrice'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\n\ntrain_df, test_df, y_train, y_test = train_test_split(train, y, test_size=0.3, random_state=42)","c29875f8":"train_df['sale'] = y_train\ntest_df['sale'] = y_test","0391154d":"from autoviml.Auto_ViML import Auto_ViML","e096f19b":"target='sale'","0561039a":"model, features, trainm, testm = Auto_ViML(train_df, target, test_df, sample_submission='',\n                                    scoring_parameter='',\n                                    hyper_param='RS',feature_reduction=True,\n                                     Boosting_Flag=True,Binning_Flag=False,\n                                    Add_Poly=0, Stacking_Flag=False, \n                                    Imbalanced_Flag=True, \n                                    verbose=1)","cb1847d5":"features","8b82a803":"testm","27b6b47f":"from sklearn.metrics import mean_squared_log_error","4509b610":"print(mean_squared_log_error(test_df[target].values,testm['sale_LassoLarsCV_predictions'].values))","b6627099":"print(mean_squared_log_error(test_df[target].values,testm['sale_KNN_Regressor_predictions'].values))","01c14d69":" print(mean_squared_log_error(test_df[target].values,testm['sale_RF_Regressor_predictions'].values))","c4745dac":"print(mean_squared_log_error(test_df[target].values,testm['sale_XGBoost_predictions'].values))","4706c3f7":"print(mean_squared_log_error(test_df[target].values,testm['sale_Ensembled_predictions'].values))","2a2ca04d":"print(mean_squared_log_error(test_df[target].values,testm['sale_predictions'].values))","57c0939d":"import pandas as pd\nfrom autoviml.Auto_ViML import Auto_ViML\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\ny = train.SalePrice\n\ntrain.drop(['Id', 'SalePrice'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\n\ntrain['sale'] = y\ntest['sale'] = test.shape[0]*[0]\ntest.fillna('0', inplace=True)\nmodel, features, trainm, testm = Auto_ViML(train, 'sale', test, sample_submission='',\n                                    scoring_parameter='',\n                                    hyper_param='RS',feature_reduction=True,\n                                     Boosting_Flag=True,Binning_Flag=False,\n                                    Add_Poly=0, Stacking_Flag=False, \n                                    Imbalanced_Flag=True, \n                                    verbose=1)\n","3f490f25":"yp = testm['sale_predictions'].values\nwith open('pred.csv', 'w') as out, open('test.csv') as inp:\n    out.write('Id,SalePrice\\n')\n    inp.readline()\n    for v in yp:\n        line = inp.readline().split(\",\")[0]\n        out.write(line + \",\" + str(v) + \"\\n\")","66b84292":"hyper_param: Tuning options are GridSearch ('GS') and RandomizedSearch ('RS'). Default is 'GS'.\n\nfeature_reduction: Default = 'True' but it can be set to False if you don't want automatic    \n\nBoosting Flag: you have 4 possible choices (default is False):                               \n  None = This will build a Linear Model                                                  \n  False = This will build a Random Forest or Extra Trees model (also known as Bagging)        \n  True = This will build an XGBoost model                                                     \n  CatBoost = THis will build a CatBoost model (provided you have CatBoost installed)          \n\n","221aca04":"# https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques"}}