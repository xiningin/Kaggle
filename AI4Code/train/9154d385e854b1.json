{"cell_type":{"9ae1f1a3":"code","68e77789":"code","675c68ff":"code","e8c3bd4c":"code","119d8805":"code","adcaf22a":"code","fdaac3ff":"code","7341d7cd":"code","15eb5230":"code","d74ea6c5":"code","90765067":"code","f89c02e0":"code","2867d85b":"code","ce2fe9d7":"code","1b642a44":"code","a70a7300":"code","b71e4e2b":"code","68b09579":"code","2051c199":"code","32820155":"code","79923737":"code","27b0ae8b":"code","d9874ac8":"code","b3eef4d4":"code","d1dcbac0":"code","c297750a":"code","7710bf01":"code","760e5c8d":"code","1fc6c302":"code","9b503f44":"code","973ad758":"code","ba8a7cd2":"code","7874ad19":"code","956d5d7e":"code","d0928558":"code","9c3db0f2":"code","267d85bc":"code","038f8b46":"code","79ee4c79":"code","1711896d":"code","ebc98bd4":"markdown","394ee590":"markdown","e4302b53":"markdown","43e1c48e":"markdown","5015c71d":"markdown","0caaf9ff":"markdown","b5bb6ae6":"markdown","cb0b4830":"markdown","8187dd44":"markdown","e141624a":"markdown","cf0fb7e2":"markdown","1466fbec":"markdown","6675a085":"markdown","1b40fda3":"markdown","15a56e59":"markdown","391741bb":"markdown","ed9bd86b":"markdown","8b238f4c":"markdown","7a5e82bf":"markdown","3c6c254f":"markdown","816efffa":"markdown","00812369":"markdown","e8c01c04":"markdown","073004b2":"markdown","45cfbfb2":"markdown","81ee5ac5":"markdown","bab85572":"markdown","042d0626":"markdown","18dc5432":"markdown","fb633e76":"markdown","a820401e":"markdown"},"source":{"9ae1f1a3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Representacion de datos\nimport seaborn as sns\nimport matplotlib.pyplot as plt","68e77789":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","675c68ff":"seed = 12737","e8c3bd4c":"filepath = \"..\/input\/pima-indians-diabetes-database\/diabetes.csv\"\ntarget = 'Outcome'\n\ndata = utils.load_data(filepath, None, target)","119d8805":"data.sample(5,random_state=seed)","adcaf22a":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","fdaac3ff":"X.sample(5, random_state=seed)","7341d7cd":"y.cat.categories","15eb5230":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","d74ea6c5":"X_train.sample(5, random_state=seed)","90765067":"data.info(memory_usage=False)","f89c02e0":"data_train = utils.join_dataset(X_train, y_train)","2867d85b":"utils.plot_histogram(data_train)","ce2fe9d7":"valor_nulo = 0\ndata_train['SkinThickness'].value_counts(normalize = True)[valor_nulo] * 100","1b642a44":"data_train['Insulin'].value_counts(normalize = True)[valor_nulo] * 100","a70a7300":"data_train['BloodPressure'].value_counts(normalize = True)[valor_nulo] * 100","b71e4e2b":"def plot_distribution(data):\n    \n    #Busca el n\u00famero de columnas mayor para que las gr\u00e1ficas se representen como una matriz\n    col = 0\n    for i in range(1,10):\n        if len(data.columns)%i == 0 and i != len(data.columns):\n            col = i\n    \n    x = (len(data.columns)\/\/col)\n    if col == 1:\n        x,col = 1,len(data.columns) \n    fig, axes = plt.subplots(nrows=x, ncols=col, figsize=(15,15))\n    k = 0\n    print()\n    for i in range(0,x):\n        for j in range(0,col):\n            column = list(data)[k]\n            k+=1\n            sns.distplot(data[column],ax=axes[i,j])\n        ","68b09579":"plot_distribution(X_train)","2051c199":"utils.plot_barplot(data_train)","32820155":"print(\"Valores:\\n\",data_train['Outcome'].value_counts(), \"\\n\\nFrecuencia:\\n\",data_train['Outcome'].value_counts(normalize = True)*100)","79923737":"data_train.describe(include=\"number\")","27b0ae8b":"#utils.plot_pairplot(data_train.iloc[:,0:3],target=\"Outcome\")","d9874ac8":"utils.plot_pairplot(utils.join_dataset(data_train.iloc[:,0:3], y_train), target='Outcome')","b3eef4d4":"utils.plot_pairplot(utils.join_dataset(X_train.iloc[:,5:9], y_train), target='Outcome')","d1dcbac0":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import QuantileTransformer\n\nfrom sklearn.preprocessing import StandardScaler","c297750a":"delete_colum = ['SkinThickness','Insulin']\ndef drop_column(X, columns = delete_colum):\n    return X.drop(columns, axis=1)\n#X_test = drop_column(X_test,delete_colum)\n#X_train = drop_column(X_train,delete_colum)","7710bf01":"#X_train = X_train.drop(columns = ['SkinThickness','Insulin'])\n#X_test = X_test.drop(columns = ['SkinThickness','Insulin'])","760e5c8d":"quantile_transformer = preprocessing.QuantileTransformer(n_quantiles = 10,output_distribution='normal',random_state=seed)","1fc6c302":"imputer_col = list(set(list(X)) - set(delete_colum) - set(['Pregnancies']))\nprint(imputer_col)","9b503f44":"imputer = make_column_transformer((KNNImputer(n_neighbors=3, weights=\"uniform\",missing_values=0), imputer_col))","973ad758":"#plot_distribution(X_imputer)","ba8a7cd2":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","7874ad19":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","956d5d7e":"tree_model = DecisionTreeClassifier(random_state=seed)","d0928558":"discretize_tree_model = make_pipeline(discretizer, tree_model)","9c3db0f2":"pip = make_pipeline(FunctionTransformer(drop_column),imputer,discretizer, tree_model)","267d85bc":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","038f8b46":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","79ee4c79":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","1711896d":"utils.evaluate(pip,\n               X_train, X_test,\n               y_train, y_test)","ebc98bd4":"Una vez estudiadas las variables de forma individual, para completar el estudio de las variables, tenemos que ver las relaciones entre estas variables. Este estudio llamado `multievaluado`, nos muestra informaci\u00f3n imporante sobre el discretizado de las variables y su potencia discriminatoria. Tamb\u00eden, sobre los valores ruidosos que se pueden encontrar en una zona con gran cantidad de otros valores clase.","394ee590":"Por \u00faltimo, para el an\u00e1lisis univariado, vamos a comprobar el n\u00famero de casos diferentes para la variable clase. Comprobando si nuestra base de datos de entrenamiento esta `balanceada`.","e4302b53":"En primer lugar, cargamos la base de datos guardada como un fichero .csv y cargamos las principales librerias de python.","43e1c48e":"A partir de la informaci\u00f3n que ya conocemos de las variables, vamos a representar los datos en de diferentes formas. Esto lo haremos para realizar un an\u00e1lisis en profundidad.\n\nPrimero vamos a utilizar m\u00e9todos `univariados`. Al analizar las variables por separados podemos estudiar si alguna de estas variables contiene datos ruidosos o `outliers`. Tambi\u00e9n podemos observar de esta manera la distribuci\u00f3n de valores de una variable, si una variable es uniforme no nos aportar\u00e1 mucha informaci\u00f3n ya que tendr\u00e1 siempre el mismo valor. Mientras que, si nuestra distribuci\u00f3n es gaussiana nos ayudar\u00e1 a la hora de realizar el estudio.\n\nAntes de nada, las variables de entrenamiento las unimos para tener una base de datos de entrenamiento completa.","5015c71d":"Con el siguiente codigo, vamos a mostar la informaci\u00f3n de todas las variables de nuestra base de datos para ayudarnos en nuestro estudio.\n","0caaf9ff":"Est\u00e1s gr\u00e1ficas nos dan una representaci\u00f3n de los valores de `Outcome` para cada par de variables. Podemos sacar un valor de corte y las variables necesarias para discretizar una variable clase y tener un modelo correcto. Pero, al tener tantas variables la claridad de sacar a simple vista un resultado correcto se vuelve muy dif\u00edcil.","b5bb6ae6":"## Preprocesamiento de datos.","cb0b4830":"## Acceso y almacenamiento de datos.\n\nCargamos el conjunto de datos de diabetes, a trav\u00e9s de la libreria de pandas.","8187dd44":"Vamos a comprobar que la divisi\u00f3n de la base de datos se ha realizado de forma correcta y tiene todas las variables predictoras.","e141624a":"Para `SkinThickness` 29.24% de los valores del atributo son valores nulos, a 0. Entonces, esta variable la quitaremos de nuestra base de datos.","cf0fb7e2":"Nuestra base de datos tiene 9 columnas o variables:\n\n### Variables predictoras\n* `Pregnancies (Embarazos)`\n\n* `Glucose (Glucosa)`\n\n* `BloodPressure (Presi\u00f3n de sangre)`\n\n* `SkinThickness (Espesor de la piel)`\n\n* `Insulin (Insulina)`\n\n* `BMI (IMC)`\n\n* `DiabetesPedigreeFunction (Funci\u00f3n de pedigr\u00ed de la diabetes)`\n\n* `Age (Edad)`\n\n### Variable clase\n* `Outcome (Resultado)`\n","1466fbec":"Dividimos la base de datos en las variables predictoras, guardadas en el atributo `X`. Y la variable clase en el atributo `y`.","6675a085":"Para `Insulin` el 48.6% de los valores son nulos, por tanto esta variable contiene una gran cantidad de estos valores y ser\u00e1 eliminada.","1b40fda3":"Como hemos comentado anteriormente, hay variables con gran cantidad de valores nulos. Vamos a dar el porcentaje que supone estos valores y si es `mayor que el 20%`, eliminaremos completamente todo el atributo. Estas variables son `SkinThickness` e `Insulin`. ","15a56e59":"A continuaci\u00f3n, vamos a estudiar la distribuci\u00f3n de cada atributo. Mediante la libreria `seaborn` y la funci\u00f3n `displot` podemos conocer cada distribuci\u00f3n de una forma gr\u00e1fica y ver que atributos se acercan a una distribuci\u00f3n gaussiana o normal.\n\nCon una funci\u00f3n creada por nosotros, llamada `plot_distribution` y guardada en el script de `utils`, representaremos gr\u00e1ficamente la distribuci\u00f3n de todas las variables para estudiarla de una forma m\u00e1s comoda. Ignorando los valores nulos y ruidosos que hemos visto en el anterior apartado.","391741bb":"# **Pr\u00e1ctica 1: An\u00e1lisis exploratorio de datos, preprocesamiento y validaci\u00f3n de modelos de clasificaci\u00f3n.**\n## Base de datos: Diabetes","ed9bd86b":"Vamos a imprimir por pantalla 5 ejemplos de nuestra base de datos de forma aleatoria, para que nuestra muestra imprimida no est\u00e9 `sesgada` y ver como se estructura la informaci\u00f3n.","8b238f4c":"A partir de un histograma podemos ver la densidad de ejemplos para distintos valores de una variable num\u00e9rica. Tamb\u00eden nos permite conocer informaci\u00f3n de las variables por separado como hemos dicho anteriormente. La siguiente gr\u00e1fica interactiva permite ver la distribuci\u00f3n de cada variable por separado, pudiendo ver a simple vista valores ruidosos o la distribuci\u00f3n de cada variable. En este caso, la gr\u00e1fica lo utilizaremos para observar `outliers`.","7a5e82bf":"Importamos el resto de librerias necesarias para realizar el an\u00e1lisis y un script que nos ayudar\u00e1 a mostrar este cuaderno de una forma m\u00e1s ordenada sin la necesidad de a\u00f1adir funciones dentro de este.","3c6c254f":"A\u00f1adimos una semilla para que los procesos creados en el estudio sean repetibles y reproducibles. Vamos a utilizar la misma semilla que en el estudio \"iris\".","816efffa":"El n\u00famero de ejemplos en nuestra base de datos de entrenamiento esta `desbalanceado`. El n\u00famero de resultados que son `0` es de **350 ejemplos**, mientras que de resultado `1` es de **187 ejemplos**. Esto supone que el `65.18%` de nuestra variable clase, es de valor `0`.","00812369":"## Visualizaci\u00f3n de los datos.","e8c01c04":"La variable clase `Outcome` en este estudio es una variable num\u00e9rica entera, discreta con dos posibles valores: 0 y 1. Este valor indica si dada la instancia de la base de datos, el resultado de su diagnostico es positivo en diabetes.\n\nEl resto de variables, las predictoras, tambien son num\u00e9ricas de tipo entero. Excepto `BMI` y `DiabetePedigreeFunction`, que son de tipo flotante.","073004b2":"Aunque en las gr\u00e1ficas salgan las variables Insulin y SkinThickness, no las estudiaremos ya que estos atributos los elimaneremos de nuestra base de datos como hemos comentado anteriormente.\n\nEn las gr\u00e1ficas podemos observar distribuciones gaussianas o normales en forma de campana, estos atributos son: `BloodPressure`, `Glucose` y `BMI`.\n\nEl resto de atributos se asemejan tambi\u00e9n a una campana pero tienen valores que hacen que esa distribuci\u00f3n cambie. Quitando `outliers` como en la variable `Pregnancies`, tendremos una distribuci\u00f3n m\u00e1s gaussiana. Entonces, para este tipo de atributos necesitaremos un m\u00e9todo para quitar estos valores at\u00edpicos.","45cfbfb2":"Por \u00faltimo, para la variable `BloodPressure` el 4.66% son valores nulos. Por tanto esta variable no ser\u00e1 eliminada y realizaremos una imputaci\u00f3n para dar un valor correcto a estos valores nulos.","81ee5ac5":"## An\u00e1lisis exploratorio de datos.","bab85572":"Est\u00e1s estad\u00edsticas una vez realizado el preprocesamiento variar\u00e1n, al quitar valores que hemos estudiado que resultar\u00e1n un problema para la discretizaci\u00f3n y la creaci\u00f3n de buenos modelos.","042d0626":"## Algoritmos de clasificaci\u00f3n.","18dc5432":"Vamos a separar el conjunto de datos en dos conjuntos diferentes: `Entrenamiento` y `test`.\n\nEste proceso llamado `houldout`, lo utilizamos para no sobreajustar el modelo de entrenamiento y validar de una forma m\u00e1s honesta los resultados dados por el modelo.\n\n* La muestra de entrenamiento ser\u00e1 el 70% de la base de datos.\n* La muestra de test ser\u00e1 el 30% de la base de datos.","fb633e76":"Podemos observar en las gr\u00e1ficas como hay variables que poseen valores nulos, en este caso estos valores nulos estan representados por un valor `0`. Ya que, muchos atributos no tienen sentido porque no se puede tener este valor, pero hay algunos atributos que tener valores a 0 si tienen sentido. Lo estudiaremos a continuaci\u00f3n.\n\nVamos a estudiar los atributos y si tienen *outliers* por orden que aparecen en la gr\u00e1fica.\n\n`Pregnancies`: Tiene algunso ejemplos en la base de datos que se aleja de la distribuci\u00f3n de valores para este atributo. Esta variable al indicar los embarazos, tener valores tan altos no tiene sentido, lo cual manejaremos en el preprocesamiento.\n\n`Glucose`: Este atributo pose\u00e9 dos ejemplos con valores a 0. Lo cu\u00e1l es un valor erroneo, ya que se necesita una medida. Este valor es un valor nulo para nuestra base de datos. Estos valores nulos los controlaremos en el preprocesamiento.\n\n`BloodPressure`: Al igual que en Glucose tambi\u00e9n tiene valores a 0, a su vez tamb\u00eden hay muestras de datos que est\u00e1n alejados de la distribuci\u00f3n normal de la variable.\n\n`SkinThickness`: Posee muchos ejemplos en la base de datos con un valor a 0 o nulo. Esto supondr\u00e1 un problema para el score que nos dar\u00e1n los modelos. En estos casos si el `20%` de los valores del atributo son nulos, eliminaremos la variable completa, ya que no introduce conocimiento adicional.\n\n`Insulin`: Tienen muchos *outliers* que se alejan mucho de la distribuci\u00f3n, tambi\u00e9n posee una gran cantidad de valores nulos. Es la variable con m\u00e1s valores a 0. Al igual que el anterior atributo, estudiaremos si la variable puede ser eliminada y en caso de que sea as\u00ed lo haremos en el preprocesamiento.\n\n`BMI`: Otro atributo que posee valores nulos que tendremos que manejar en el preprocesamiento.\n\n`DiabetesPedigreeFunction`: Este atributo es similar a Insulin, tiene *outliers* muy alejados de la media de la distribuci\u00f3n del atributo. Con unos pocos ejemplos de valores nulos.\n\n`Age`: Esta variable no supone muchos problemas con los *outliers*, teniendo muy pocos ejemplos de estos en la base de datos.\n\n","a820401e":"El preprocesamiento de datos es la tarea m\u00e1s importante del proceso KDD. En este apartado realizaremos:\n\n* `Limpieza de datos`: Suavizaremos el ruido y eliminaremos datos problematicos\n* `Integraci\u00f3n de datos`: Introduciremos datos donde sean nulos, se utilizar\u00e1 una imputaci\u00f3n de los valores perdidos mediante un estimador.\n* `Transformaci\u00f3n de datos`: Normalizaremos los datos.\n* `Reducci\u00f3n de datos`: Discretizaremos los datos si es necesario.\n\nPara esta tarea se utilizara un `pipeline` para no cometer una `fuga de datos` y no introducir datos del conjunto de entrenamiento donde se aprender\u00e1 el modelo en el conjunto de prueba donde los datos de este conjunto son `datos crudos`. Una vez elaborado este apartado se tendr\u00e1 que validad el modelo entrenado."}}