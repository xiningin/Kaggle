{"cell_type":{"78823d5b":"code","cabe2f75":"code","1396b632":"code","c80d815b":"code","fc5138aa":"code","19d49b55":"code","56d331ec":"code","7fa754bf":"code","0056456f":"code","981e299f":"code","e8f5295b":"code","aaa62b19":"code","d8d22826":"code","148dcaae":"code","a6ac4eac":"code","1c60b7cb":"code","b1dfce15":"code","e32a9433":"code","da5c9c82":"code","34dc505d":"code","d7d974c6":"code","65ed2905":"code","3e9687fa":"code","83a0bfb2":"code","bbea6468":"code","a10a726c":"code","0d0dc412":"code","b5614e74":"code","0286397f":"markdown","c5e60e99":"markdown","52b4b21f":"markdown","bf19441b":"markdown","de1b52fc":"markdown"},"source":{"78823d5b":"import numpy as np\nimport pandas as pd\npd.options.display.max_rows = 1000\npd.options.display.max_columns = 1000\n\nfrom collections import Counter\n%matplotlib inline\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode()\n\nimport gc","cabe2f75":"# Daily transaction file\n\n# productid - unique id for each product (int32)\n# date - date of product action\n# soldquantity - sales of product (int16)\n# stock - beginning stock count of product (int32)\n# clickcount - # of clicks of product (int32)\n# favoredcount - # of favored click of product (int16)\n\ndf = pd.read_csv('..\/input\/dailyProductActions.csv', parse_dates=['date'], dtype={'productid': 'int32'})\ndf['soldquantity'] = df['soldquantity'].fillna(0).astype(np.int16)\n#df['stock'] = df['stock'].fillna(0).astype(np.int32)\ndf['clickcount'] = df['clickcount'].fillna(0).astype(np.int32)\ndf['favoredcount'] = df['favoredcount'].fillna(0).astype(np.int16)\ndf = df.sort_values(by=['productid', 'date']).reset_index(drop=True)\nprint(df.shape)\ndisplay(df.head())","1396b632":"# Submission file\nsubmission = pd.read_csv('..\/input\/SampleSubmission.csv')\nprint(submission.shape)\ndisplay(submission.head())","c80d815b":"# Products file\nproducts = pd.read_csv('..\/input\/product.csv').sort_values(by='productid')\nprint(products.shape)\ndisplay(products.head())","fc5138aa":"date_start = pd.to_datetime('2018-11-01')\ndate_end = pd.to_datetime('2019-01-11')\ndate_days = int((date_end - date_start) \/ pd.to_timedelta('1d')) + 1\nprint(date_days)","19d49b55":"df.groupby('date')['soldquantity'].mean().plot.bar(figsize=(16, 4))","56d331ec":"#\n# 9, 10, 11 Kas\u0131m \u0130ndirimi\n# https:\/\/www.trendyol.com\/s\/11-kasim-indirim-gunleri\n#\n# 20-25 Kas\u0131m Efsane G\u00fcnler\n# https:\/\/www.trendyol.com\/s\/black-friday\n# Black Friday, November 29\n#\n# 20 - 21 Aral\u0131k\n# https:\/\/www.trendyol.com\/s\/21-aralik-en-uzun-gece\n#\n# 2019-01-05 from observation ?\n#\n\nindirim_gunleri = [\n    '2018-11-09', '2018-11-10', '2018-11-11', '2018-11-20', '2018-11-21',\n    '2018-11-22', '2018-11-23', '2018-11-24', '2018-12-20', '2018-12-21',\n    #'2019-01-05'\n]\nindirim_gunleri = [pd.to_datetime(c) for c in indirim_gunleri]\ndf_indirim = pd.DataFrame(indirim_gunleri, columns=['date'])\ndf_indirim['indirim'] = 1\ndf_indirim = df_indirim.set_index('date')\ndf_indirim = df_indirim.reindex(pd.date_range(date_start, date_end), fill_value=0).reset_index()\ndf_indirim = df_indirim.rename(columns={'index':'date'})\ndf_indirim['indirim_next7days'] = df_indirim['indirim'].rolling(7).sum().shift(-7).fillna(0) \/ 7\ndf_indirim['indirim_prev7days'] = df_indirim['indirim'].rolling(7).sum().fillna(0) \/ 7\n#for i in range(1, 8):\n#    df_indirim[f'indirim_next_{i}'] = df_indirim['indirim'].shift(-i).fillna(0).astype(int)\ndf_indirim.head(10)","7fa754bf":"print('gender = ', products.gender.max())\nprint('color = ', products.color.max())\nprint('categoryid = ', products.categoryid.max())\nprint('brandid = ', products.brandid.max())\nprint('subcategoryid = ', products.subcategoryid.max())","0056456f":"# Generate expanded transaction matrix\nproductids = sorted(set(submission.productid.unique()) | \n                    set(df.productid.sample(10000)))\n#productids = sorted(set(df.productid.unique()))\nprint(len(productids))\ntmp = df[df.productid.isin(set(productids))]\nprint(tmp.shape)\ntmp2 = pd.DataFrame({\n    'productid': np.repeat(productids, date_days),\n    'date': np.tile(pd.date_range(date_start, date_end), len(productids)),\n})\ntmp = tmp2.merge(tmp, on=['productid', 'date'], how='left')\ndel tmp2\ntmp['stock'] = tmp.groupby('productid')['stock'].apply(lambda x:x.fillna(method='ffill').fillna(method='bfill')) #.clip(0,1000) \/ 1000\ntmp = tmp.fillna(0)\nprint(tmp.shape)\ntmp.head(30)","981e299f":"tmp = tmp.merge(tmp.groupby('date')['clickcount'].mean().to_frame('daily_clickcount').reset_index(),\n               on='date',\n               how='left')\ntmp['clickratio'] = tmp['clickcount'] \/ tmp['daily_clickcount']\ntmp.head()","e8f5295b":"tmp = tmp.merge(tmp.groupby('date')['favoredcount'].mean().to_frame('daily_favoredcount').reset_index(),\n               on='date',\n               how='left')\ntmp['favoredratio'] = tmp['favoredcount'] \/ tmp['daily_favoredcount']\ntmp.head()","aaa62b19":"tmp = tmp.merge(tmp.groupby('date')['soldquantity'].mean().to_frame('daily_soldquantity').reset_index(),\n               on='date',\n               how='left')\ntmp['soldratio'] = tmp['soldquantity'] \/ tmp['daily_soldquantity']\ntmp.head()","d8d22826":"tmp = tmp.merge(tmp.groupby('date')['stock'].mean().to_frame('daily_stock').reset_index(),\n               on='date',\n               how='left')\ntmp['stockratio'] = tmp['stock'] \/ tmp['daily_stock']\ntmp.head()","148dcaae":"# Define Target\n\n# Target hesaplamak i\u00e7in 7 g\u00fcn kayd\u0131r\u0131yoruz. Ancak, b\u00fct\u00fcn \u00fcr\u00fcnleri 7 kere\n# kayd\u0131rd\u0131\u011f\u0131m\u0131z i\u00e7in, bir sonraki \u00fcr\u00fcn\u00fcn ilk 7 g\u00fcn toplam\u0131, bir \u00f6nceki \u00fcr\u00fcn\u00fcn son target'\u0131ym\u0131\u015f gibi geliyor.\n# Bunu \u00f6nlemek i\u00e7in her \u00fcr\u00fcn\u00fcn en son 73. de\u011ferini siliyoruz.\nrs = tmp['soldquantity'].fillna(0).copy()\nrss = []\nfor i in range(1, 8):\n    rs = rs.shift(-1)\n    rs[71::72] = np.nan\n    rss.append(rs)\ntmp[f'target'] = np.sum(rss, axis=0)\ntmp.head()","a6ac4eac":"for alpha in [0.2, 0.1]:\n    for col in ['soldquantity', 'stock', 'clickcount', 'favoredcount',\n               'clickratio', 'favoredratio', 'soldratio', 'stockratio']:\n        print(f'ewm_{alpha}_{col}')\n        tmp[f'ewm_{alpha}_{col}'] = tmp.groupby('productid')[col].apply(lambda x:x.ewm(alpha=alpha).mean())\ntmp['ewm_0.2_fc'] = tmp['ewm_0.2_favoredcount'] \/ tmp['ewm_0.2_clickcount']\ntmp['ewm_0.2_sc'] = tmp['ewm_0.2_soldquantity'] \/ tmp['ewm_0.2_clickcount']\ntmp['ewm_0.2_sf'] = tmp['ewm_0.2_soldquantity'] \/ tmp['ewm_0.2_favoredcount']\n\ntmp.head()","1c60b7cb":"tmp = tmp.merge(df_indirim, on='date', how='left')\ntmp = tmp.merge(products, on='productid', how='left')\ntmp = tmp.sort_values(by=['productid', 'date'])\nprint(tmp.shape)\ntmp.head()","b1dfce15":"submissionids = sorted(set(submission.productid.unique()))\n\nprediction_days = 7\ndate_predict = pd.to_datetime('2019-01-11') - pd.to_timedelta(f'{prediction_days}d')\ndate_train   = date_predict - pd.to_timedelta('8d')\ndate_test    = date_predict - pd.to_timedelta('1d')\nprint(date_train)\nprint(date_test)\n\ndf_train   = tmp[(tmp.date <= date_train)]\n                 #(tmp[f'indirim_next7days'] == 0) &\n                 #(tmp.productid.isin(set(submissionids)))]\n\ndf_test    = tmp[(tmp.date > date_train) &\n                 (tmp.date <= date_test) &\n                 (tmp.productid.isin(set(submissionids)))]\n\ndf_val     = tmp[(tmp.date > date_test) &\n                 (tmp.date <=  date_predict) &\n                 (tmp.productid.isin(set(submissionids)))]\n\n#df_predict = tmp[(tmp.productid.isin(set(submissionids))) &\n#                 (tmp.target.isnull())]\n\nprint(f'df_train.shape   : {df_train.shape}')\nprint(f'df_test.shape    : {df_test.shape}')\nprint(f'df_val.shape     : {df_val.shape}')\n#print(f'df_predict.shape : {df_predict.shape}')","e32a9433":"col_target = f'target'\ncol_not_use = ['productid', 'date', 'target']\ncol_not_use += ['ewm_soldratio_trend']\ncol_not_use += [c for c in tmp.columns if c.startswith('target')]\n#col_not_use += [c for c in tmp.columns if c.startswith('daily')]\n#col_not_use += [c for c in tmp.columns if c.endswith('stockratio')]\n#col_not_use += [c for c in tmp.columns if 'stockratio' in c]\n#col_not_use += [c for c in tmp.columns if c.startswith('stat_productid')]\n#col_not_use += [c for c in tmp.columns if c.startswith('ewm_0.1_stat')]\n\ncol_use = [c for c in tmp.columns if c not in col_not_use]\ncol_cat = ['gender', 'color', 'categoryid', 'brandid', 'subcategoryid']\n#col_cat = [c for c in col_cat if c in col_use]\n\nprint('col_use', col_use)\nprint('col_target',col_target)\n\nfrom lightgbm import LGBMRegressor\n#models = dict()\n#for col_target in col_targets:\n\nmodels = []\nfor random_state in [42,84,1,2,3]:\n    print(f'Model for {col_target}')\n\n    model = LGBMRegressor(objective='regression',\n                          num_leaves=31,\n                          random_state=random_state,\n                          subsample=0.8,\n                          colsample_bytree=0.8,\n                          learning_rate=0.05,\n                          n_estimators=2000,\n                          reg_alpha=5,\n                          reg_lambda=5,)\n    print(model)\n    model.fit(df_train[col_use], df_train[col_target],\n              categorical_feature=col_cat,\n              early_stopping_rounds=100,\n              eval_set=(df_test[col_use], df_test[col_target]),\n              eval_metric=['rmse'],\n              verbose=100)\n    col_pred = col_target.replace('target', 'pred')\n    #models[col_pred] = model\n    from sklearn.metrics import mean_squared_error\n    preds = model.predict(df_test[col_use])\n    print('test rmse:', np.sqrt(mean_squared_error(preds.clip(0), df_test[col_target])))\n\n    preds = model.predict(df_val[col_use])\n    print('val rmse:', np.sqrt(mean_squared_error(preds.clip(0), df_val[col_target])))\n    \n    models.append(model)\n\nprint('OK')\nprint('Done')","da5c9c82":"import eli5\neli5.explain_weights_lightgbm(model, top=500)","34dc505d":"# subm 15 : val rmse: 7.884177554137836\n# subm 16 : val rmse: 7.752352602499219\npreds = []\nfor model in models:\n    preds.append(model.predict(df_val[col_use]))\n\nprint('val rmse:', np.sqrt(mean_squared_error(pd.DataFrame(np.array(preds)).median(axis=0).clip(0), df_val[col_target])))\n","d7d974c6":"# subm 15 : val rmse: 7.884177554137836\n# subm 16 : val rmse: 7.752352602499219\npreds = model.predict(df_val[col_use])\nprint('val rmse:', np.sqrt(mean_squared_error(preds.clip(0), df_val[col_target])))\n","65ed2905":"#print(np.sqrt(mean_squared_error(model.predict(df_test[col_use]), df_test[col_target])))\nfor i in range(-30, -6):\n    dt = pd.to_datetime('2019-01-11') + pd.to_timedelta(f'{i}D')\n    df_tmp = tmp[(tmp.date == dt)]\n    df_tmp = df_tmp[(df_tmp.productid.isin(set(submissionids)))]\n    print(i, dt, np.sqrt(mean_squared_error(model.predict(df_tmp[col_use].clip(0)), df_tmp[col_target])))","3e9687fa":"py.iplot([\n    go.Scattergl(x=tmp[tmp.date == pd.to_datetime('2019-01-01')][col_target], y=model.predict(tmp[tmp.date == pd.to_datetime('2019-01-01')][col_use]), mode='markers'),\n    go.Scattergl(x=tmp[tmp.date == pd.to_datetime('2019-01-02')][col_target], y=model.predict(tmp[tmp.date == pd.to_datetime('2019-01-02')][col_use]), mode='markers'),\n    go.Scattergl(x=tmp[tmp.date == pd.to_datetime('2019-01-03')][col_target], y=model.predict(tmp[tmp.date == pd.to_datetime('2019-01-03')][col_use]), mode='markers'),\n    go.Scattergl(x=tmp[tmp.date == pd.to_datetime('2019-01-04')][col_target], y=model.predict(tmp[tmp.date == pd.to_datetime('2019-01-04')][col_use]), mode='markers')\n])","83a0bfb2":"preds = dict()\nfor i in range(1, 8):\n    dt = pd.to_datetime('2019-01-04') + pd.to_timedelta(f'{i}D')\n    print(f'predicting {i}, {dt}')\n    df_predict = tmp[tmp.productid.isin(set(submissionids))]\n    df_predict = df_predict[df_predict.date == dt]\n    #display(df_predict.head())\n    preds[i] = model.predict(df_predict[col_use])\nprint(len(preds))","bbea6468":"# Genel bak\u0131\u015f.\npd.DataFrame(preds).clip(0)","a10a726c":"df_subm = pd.DataFrame()\ndf_subm['productid'] = df_predict['productid']\n#df_subm['sales'] = preds[7].clip(0)\ndf_subm['sales'] = pd.DataFrame(preds).max(axis=1).values\ndf_subm.head()","0d0dc412":"df_subm.to_csv('..\/submission_16.csv', index=False)","b5614e74":"# Kategori i\u00e7erisinde bir \u00fcr\u00fcn di\u011fer \u00fcr\u00fcnlere g\u00f6re tercih ediliyor olabilir.\n# Bunun belirleyicisi fiyat, renk ya da ba\u015fka bir\u015fey olabilir.\n# Belirli bir renk, belirli bir marka di\u011ferlerine g\u00f6re daha \u00e7ok tercih ediliyor olabilir.\n# Stokta kalmad\u0131 hikayesi de \u00f6nemli olabilir.\n# Baz\u0131 \u00fcr\u00fcnlerin \u00e7ok sat\u0131\u015f\u0131 yok. Onlar\u0131 elemek gerekebilir.\n# Baz\u0131 g\u00fcnlerde sat\u0131\u015flar anormal devam ediyor. Onlar\u0131 elemek gerekebilir. Onun d\u0131\u015f\u0131nda d\u00fczenli gidiyor mesela.\n","0286397f":"# Prepare For Preprocessing","c5e60e99":"Arkada\u015flar selam,\n\n@yvztpe 'nin forumdaki \u00e7a\u011fr\u0131s\u0131na kay\u0131ts\u0131z kalamad\u0131m, 6.l\u0131k \u00e7\u00f6z\u00fcm\u00fcm\u00fc payla\u015fmak istedim. Yo\u011funluk sebebiyle ge\u00e7 payla\u015f\u0131yorum, ancak umar\u0131m ilgilenen arkada\u015flar i\u00e7in faydal\u0131 olur.\n\nBu arada, ilk 5'teki arkada\u015flar\u0131 \u00f6zel olarak kutluyorum, ama di\u011fer t\u00fcm arkada\u015flar\u0131 da bu alana ilgi g\u00f6sterdikleri i\u00e7in ayr\u0131ca kutluyorum.\n\nA\u015fa\u011f\u0131daki \u00e7\u00f6z\u00fcm do\u011frudan 6.l\u0131k \u00e7\u00f6z\u00fcm\u00fc olmayabilir ama, LB'de 6. s\u0131ra ya bu ya da buna \u00e7ok yak\u0131n bir \u00e7\u00f6z\u00fcm oldu. A\u00e7\u0131k\u00e7as\u0131 LSTM ya da ba\u015fka derin \u00f6\u011frenme metodlar\u0131n\u0131n bu problemde daha ba\u015far\u0131l\u0131 olaca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcn\u00fcyorum, ancak s\u00fcre \u00e7ok k\u0131s\u0131tl\u0131 oldu\u011fu i\u00e7in daha pratik bir \u00e7\u00f6z\u00fcmle devam ettim.\n\nG\u00f6r\u00fc\u015fmek \u00fczere! \n","52b4b21f":"# Load Files","bf19441b":"# LightGBM","de1b52fc":"# Preprocess"}}