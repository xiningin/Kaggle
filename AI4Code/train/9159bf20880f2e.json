{"cell_type":{"e65a5753":"code","54b81cb5":"code","61bb45c4":"code","7cbef49a":"code","dd071b95":"code","3ac35c95":"code","ca9d75b5":"code","9845d3f8":"code","faf8c94d":"code","a969d317":"code","6a7b7271":"code","17aa9a1b":"code","2736d280":"code","bddd6c76":"code","0c9fa263":"code","0a94b542":"code","b901884f":"code","30d00088":"code","0fc91a8b":"code","9c80a862":"code","1aa8c63e":"code","5e432ca9":"code","8fbe6cae":"code","65135672":"code","fbd1db7b":"code","0880a6d3":"code","667583f8":"code","24fd7e85":"code","267553d7":"code","5b43ee64":"code","77f0ed0d":"code","9cd1c6aa":"code","3103c0f3":"code","8eba8368":"code","c276268f":"markdown","ae185ecf":"markdown","b174844b":"markdown","93862d96":"markdown","714fc06b":"markdown","df5d53e0":"markdown","1c0fc53b":"markdown","58485751":"markdown","ff306c0d":"markdown","5035a3df":"markdown"},"source":{"e65a5753":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor,RandomForestRegressor,GradientBoostingRegressor","54b81cb5":"data=pd.read_csv(\"\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent.csv\")\ndf=data.copy()\ndf.head()","61bb45c4":"df.info()","7cbef49a":"df.drop([\"Unnamed: 0\"],1,inplace=True)","dd071b95":"df=df.rename(columns={\"parking spaces\":\"parking_spaces\",\n             \"rent amount\":\"rent_amount\",\n             \"property tax\":\"property_tax\",\n             \"fire insurance\":\"fire_insurance\"})\n\ndf.head()","3ac35c95":"def removing(x):\n    s =  x[2:] #removes first two chr\n    snc = \"\"\n    for i in s:\n        if i.isdigit() is True:\n            snc = snc + i\n    return snc\n\ndf[\"hoa\"] = pd.to_numeric(df[\"hoa\"].apply(removing), errors= \"ignore\")\ndf[\"rent_amount\"] = pd.to_numeric(df[\"rent_amount\"].apply(removing), errors= \"ignore\")\ndf[\"property_tax\"] = pd.to_numeric(df[\"property_tax\"].apply(removing), errors= \"ignore\")\ndf[\"fire_insurance\"] = pd.to_numeric(df[\"fire_insurance\"].apply(removing), errors= \"ignore\")\ndf[\"total\"] = pd.to_numeric(df[\"total\"].apply(removing), errors= \"ignore\")","ca9d75b5":"df.head()","9845d3f8":"df.describe()","faf8c94d":"df[\"floor\"]=df['floor'].replace('-', np.nan)\n\ndf[\"floor\"].fillna(df[\"floor\"].median(),inplace=True)\ndf[\"hoa\"].fillna(df[\"hoa\"].mean(),inplace=True)\ndf[\"property_tax\"].fillna(df[\"property_tax\"].mean(),inplace=True)\n\ndf[\"floor\"]=df[\"floor\"].astype(\"int64\")\ndf[\"furniture\"]=df[\"furniture\"].astype(\"category\")\n\ndf[\"furniture\"]=[1 if i==\"furnished\" else 0 for i in df[\"furniture\"]]\ndf.drop([\"animal\"],1,inplace=True)\n\ndf.isnull().sum()","a969d317":"df.dtypes","6a7b7271":"plt.figure(figsize=(10,5))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","17aa9a1b":"sns.relplot(x=\"fire_insurance\", y=\"rent_amount\", hue=\"bathroom\",\n            data=df);\nplt.title(\"Fire Insurance-Rent Amount with Bathroom\",color=\"red\")\nplt.xlabel(\"Fire Insurance\")\nplt.ylabel(\"Rent Amount\")\nplt.show()","2736d280":"g = sns.FacetGrid(df, hue=\"rooms\",size=7)\ng.map(plt.scatter, \"hoa\", \"total\", alpha=.7)\ng.add_legend();\nplt.title(\"Hoa-Total Relationship\")","bddd6c76":"g = sns.FacetGrid(df,hue=\"furniture\",palette=\"Set1\", height=5, hue_kws={\"marker\": [\"^\", \"v\"]},size=7)\ng.map(plt.scatter, \"fire_insurance\", \"total\", s=100, linewidth=.5, edgecolor=\"white\")\ng.add_legend();","0c9fa263":"plt.figure(figsize=(12,6))\nsns.pointplot(x=\"bathroom\",y=\"total\",hue=\"parking_spaces\",data=df)\nplt.title(\"Bathroom-Total Relationship with Parking Spaces\")","0a94b542":"g = sns.FacetGrid(df,col=\"furniture\", hue=\"floor\",size=7)\ng.map(plt.scatter, \"rent_amount\", \"total\", alpha=.7)\ng.add_legend();","b901884f":"f,ax1 = plt.subplots(figsize =(20,10))\nsns.pointplot(x=df['rooms'], y=df['total'],color='red',alpha=0.8)\nsns.pointplot(x=df['floor'], y=df['total'],color='lime',alpha=0.8)\nplt.xlabel('Rooms-Floor',fontsize = 15,color='blue')\nplt.ylabel('Total',fontsize = 15,color='blue')\nplt.title('Floor and Rooms relationship with Total',fontsize = 20,color='blue')\nplt.grid()","30d00088":"df.drop([\"furniture\",\"city\",\"area\",\"floor\"],1,inplace=True)","0fc91a8b":"df.drop([\"fire_insurance\"],1,inplace=True)","9c80a862":"total_df=df[\"total\"].copy()\n\nq1=total_df.quantile(0.25)\nq3=total_df.quantile(0.75)\nIQR=q3-q1\n\nl_bound=q1-1.5*IQR\nu_bound=q3+1.5*IQR\n\nprint(l_bound)\nprint(u_bound)\n\ntable_min=total_df.min()\ntable_max=total_df.max()\n\nfor e in range(len(total_df)):\n    if total_df.iloc[e]<l_bound:\n        total_df.iloc[e]=l_bound\n        \n    elif total_df.iloc[e] >u_bound:\n        total_df.iloc[e]=u_bound\n        \n\ndf[\"total\"]=total_df","1aa8c63e":"# lets check it\nsns.boxplot(df[\"total\"])","5e432ca9":"X=df.drop([\"total\"],1)\ny=df[\"total\"]","8fbe6cae":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)","65135672":"lm=sm.OLS(y,X)\nmodel=lm.fit()\nmodel.summary()","fbd1db7b":"lr_model=LinearRegression()\nlr_model.fit(X_train,y_train)\nlr_pred=lr_model.predict(X_test)\n\nprint(\"Test error:\",np.sqrt(mean_squared_error(y_test,lr_pred)))\nprint(\"Train error:\",np.sqrt(mean_squared_error(y_train,lr_model.predict(X_train))))\nprint(\"score:\",lr_model.score(X_train,y_train))","0880a6d3":"knn_params={\"n_neighbors\":np.arange(1,30,1)}\nknn=KNeighborsRegressor()\nknn_cv=GridSearchCV(knn,knn_params,cv=10)\nknn_cv.fit(X_train,y_train)\nknn_tuned=KNeighborsRegressor(n_neighbors=knn_cv.best_params_[\"n_neighbors\"]).fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test,knn_tuned.predict(X_test))))\nprint(\"score:\",knn_tuned.score(X_train,y_train))","667583f8":"cart=DecisionTreeRegressor()\ncart.fit(X_train,y_train)\ncart_params={\"min_samples_split\":range(2,100),\n            \"max_leaf_nodes\":range(2,10)}\ncart_cv=GridSearchCV(cart,cart_params,cv=10,n_jobs=-1,verbose=2)\ncart_cv.fit(X_train,y_train)\ncart_tuned=DecisionTreeRegressor(min_samples_split=cart_cv.best_params_[\"min_samples_split\"],\n                                 max_leaf_nodes=cart_cv.best_params_[\"max_leaf_nodes\"]).fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test,cart_tuned.predict(X_test))))","24fd7e85":"print(\"score:\",cart_tuned.score(X_test,y_test))","267553d7":"Importance = pd.DataFrame({\"Importance\": cart_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable importance types\")\nplt.title(\"Variable importance values\")","5b43ee64":"bag_model=BaggingRegressor(bootstrap_features=True).fit(X_train,y_train)\nbag_params={\"n_estimators\":range(2,20)}\nbag_cv=GridSearchCV(bag_model,bag_params,cv=10,verbose=2,n_jobs=-1)\nbag_cv.fit(X_train,y_train)\nbag_tuned=BaggingRegressor(bootstrap_features=True,n_estimators=bag_cv.best_params_[\"n_estimators\"]).fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test,bag_tuned.predict(X_test))))\nprint(\"score:\",bag_tuned.score(X_test,y_test))","77f0ed0d":"rf_model=RandomForestRegressor().fit(X_train,y_train)\nrf_params={\"max_depth\":list(range(2,9)),\n          \"max_features\":[3,5,10,15],\n          \"n_estimators\":[100,200,500,1000]}\n\nrf_cv=GridSearchCV(rf_model,rf_params,cv=10,n_jobs=-1,verbose=2)\nrf_cv.fit(X_train,y_train)\nrf_tuned=RandomForestRegressor(max_depth=rf_cv.best_params_[\"max_depth\"],\n                               max_features=rf_cv.best_params_[\"max_features\"],\n                               n_estimators=rf_cv.best_params_[\"n_estimators\"]).fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test,rf_tuned.predict(X_test))))\nprint(\"score:\",rf_tuned.score(X_train,y_train))","9cd1c6aa":"Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable importance types\")","3103c0f3":"from xgboost import XGBRegressor\n\nxgb=XGBRegressor().fit(X_train,y_train)\nxgb_params={\n     'n_estimators':[100, 200, 500, 1000],\n     'max_depth': [2,3,4,5,6],\n     'learning_rate': [0.1, 0.01, 0.5]}\n\nxgb_cv=GridSearchCV(xgb,xgb_params,cv=10,verbose=2,n_jobs=-1).fit(X_train,y_train)  \nxgb_tuned=XGBRegressor(\n                       n_estimators=xgb_cv.best_params_[\"n_estimators\"],\n                       max_depth=xgb_cv.best_params_[\"max_depth\"],\n                       learning_rate=xgb_cv.best_params_[\"learning_rate\"] )\nxgb_tuned.fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test,xgb_tuned.predict(X_test))))\nprint(\"score:\",xgb_tuned.score(X_test,y_test))                          ","8eba8368":"from lightgbm import LGBMRegressor\n\nlgbm_grid = {\n    'colsample_bytree': [0.4, 0.5,0.6,0.9,1],\n    'learning_rate': [0.01, 0.1, 0.5,1],\n    'n_estimators': [20, 40, 100, 200, 500,1000],\n    'max_depth': [1,2,3,4,5,6,7,8] }\n\nlgbm = LGBMRegressor()\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs = -1, verbose = 2)\nlgbm_cv_model.fit(X_train, y_train)\nlgbm_cv_model.best_params_\nlgbm_tuned = LGBMRegressor(learning_rate = lgbm_cv_model.best_params_[\"learning_rate\"], \n                           max_depth = lgbm_cv_model.best_params_[\"max_depth\"], \n                           n_estimators = lgbm_cv_model.best_params_[\"n_estimators\"],\n                          colsample_bytree = lgbm_cv_model.best_params_[\"colsample_bytree\"])\n\nlgbm_tuned = lgbm_tuned.fit(X_train,y_train)\nprint(\"test error:\",np.sqrt(mean_squared_error(y_test, lgbm_tuned.predict(X_test))))\nprint(\"score:\",lgbm_tuned.score(X_test,y_test))","c276268f":"## LINEAR REGRESSION","ae185ecf":"## KNeighbors Model","b174844b":"## DUMMY VARIABLE TRAP\n- There is a 0.99 correlation between the two independent variables. Based on this situation, we subtract one of these variables from the dataset. ( between fire insurance and rent amount )","93862d96":"### OUTLIER VALUES and Fill with Suppression\n","714fc06b":"## CART MODEL","df5d53e0":"##  Bagged Trees Regresyon","1c0fc53b":"# XGBOOST MACHINE\n","58485751":"- \"total\" variable shows the highest correlation relationship with -  - \"property_tax\".\n- There is a correlation between \"total\" variable and \"hoa\", -  --  \"rent_amount\" and \"fire_insurance\" in the range of 0.50-0.60.\n- There is corelation between \"fire_insurance\" and \"rent_amount\"\n- There is low corelation between \"city\", \"area\",\"floor\",\"furniture\" and \"total\". We will drop this four","ff306c0d":"## RANDOM FOREST","5035a3df":"## LIGHT GBM"}}