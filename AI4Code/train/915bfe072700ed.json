{"cell_type":{"f5aad93a":"code","5d716698":"code","f13579c2":"code","9676b730":"code","6fe70e07":"code","14f69dbf":"code","4f6ef784":"code","4ee74a83":"code","75be95bd":"code","c9f13ec3":"code","733e07b5":"code","00f0edb2":"code","dcf25583":"code","d660460e":"code","01f186bc":"code","25048039":"code","94adcbbb":"code","d89c694c":"code","900a1bfb":"code","652ad035":"code","5901ab22":"code","a98afbfc":"code","2e588932":"code","99bb98ab":"code","c40891d9":"code","ebb111fc":"code","af18b4e0":"code","41642904":"markdown","f0289a5b":"markdown","99367abc":"markdown","22d04f7a":"markdown","4c7c33c8":"markdown"},"source":{"f5aad93a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d716698":"import pandas as pd\nimport os \nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub","f13579c2":"# Location of training file for our training dataset\ntrain_file = \"..\/input\/landmark-recognition-2021\/train.csv\"","9676b730":"# Reading file using pandas \"read_csv\" \ndata = pd.read_csv(train_file)","6fe70e07":"# Exploring the dataset\ndata.head()","14f69dbf":"# Exploring the target values and that is one the crucial task need to be taken care of\n\nprint(data[\"landmark_id\"].max(), data[\"landmark_id\"].min(), data[\"landmark_id\"].nunique())\n\n# seems like our data containes label inconsistent so we need a mapping dictiory for mapping our target values associated with \n#our input_image\n\nreverse_target_mapping = { i : value for i,value in enumerate(sorted(data[\"landmark_id\"].unique()))}\n\n# Here we are exchaning the keys and values in each other for mapping purpose\ntarget_mapping = {value : key for key,value in zip(reverse_target_mapping.keys(), reverse_target_mapping.values())}\n\ntarget_mapping","4f6ef784":"# Colleting our input image file location using tf.io.gfile.glob, for more info look at official documentation\n\n\nfiles = tf.io.gfile.glob(\"..\/input\/landmark-recognition-2021\/train\/*\/*\/*\/*.jpg\")","4ee74a83":"# Checking the files consistency with our input train file whether any value is missing or not\nlen(files)","75be95bd":"# Sorting the value for concatnating our input image train file for processing\ndata.sort_values(inplace = True, by = \"id\")","c9f13ec3":"# Reseting the indices\n\ndata.reset_index(inplace = True)","733e07b5":"# droping the previous indices column , this can be done using reset index = True, but i forgot\ndata.drop(columns = [\"index\"] , inplace = True)","00f0edb2":"# As we can see in the output , our landmark id contains inconsistent label values so we need to reverse map with\n# our target dictionary\ndata.head()","dcf25583":"data[\"landmark_id\"] = data[\"landmark_id\"].map(target_mapping)\n\n# we can double check for target mapping\nprint(target_mapping[107382])\n\ndata.head()","d660460e":"# Saving processed this input_file into input directory\nos.makedirs(\".\/precessed\")\ndata.to_csv(\".\/precessed\/training_file_processed.csv\")\n\nseries = pd.DataFrame(data = {\"true_label\" : target_mapping.keys(), \"mapped_label\" : target_mapping.values()})\n\nseries.to_csv(\".\/precessed\/label_mapping.csv\")","01f186bc":"data[\"input_file_loc\"] = sorted(files)","25048039":"data.head()","94adcbbb":"data[\"id\"].loc[0], data[\"input_file_loc\"].loc[0]","d89c694c":"# Dataset making \n\n\nfile_dataset = tf.data.Dataset.from_tensor_slices(data[\"input_file_loc\"].values)\ntarget_dataset = tf.data.Dataset.from_tensor_slices(data[\"landmark_id\"].values)\n\n","900a1bfb":"\nnext(iter(file_dataset)), next(iter(target_dataset))","652ad035":"# Normalizing the images to [-1, 1]\ndef normalize(img):\n    img = (img \/ 127) - 1\n    return img\n\ndef prepare_dataset(image):\n    img = tf.io.read_file(image)\n    img = tf.image.decode_jpeg(img , channels = 3)\n    img = tf.image.resize(img, size = (299, 299))\n    \n    return img\n\n","5901ab22":"file_dataset = file_dataset.map(prepare_dataset, num_parallel_calls = tf.data.AUTOTUNE)\nfile_dataset = file_dataset.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)","a98afbfc":"next(iter(file_dataset)), next(iter(target_dataset))","2e588932":"final_dataset = tf.data.Dataset.zip((file_dataset, target_dataset)).batch(32, drop_remainder = True)","99bb98ab":"# Model Building\nnext(iter(final_dataset))[0].shape, next(iter(final_dataset))[1].shape","c40891d9":"model = tf.keras.applications.MobileNetV3Large(include_top = True,weights = None ,input_shape = (299,299,3), classes = 81313)\nmodel.summary()","ebb111fc":"model.compile(optimizer = tf.keras.optimizers.Adam(),\n              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics = [\"accuracy\"])","af18b4e0":"model.fit(final_dataset, epochs = 1, workers = 4, use_multiprocessing = True)","41642904":"# Model Fitting and Evaluation","f0289a5b":"# Processing function","99367abc":"# Final Dataset Making","22d04f7a":"# Model Compilation","4c7c33c8":"# Model building"}}