{"cell_type":{"2e092621":"code","00f4a4d3":"code","02bd8ba0":"code","4a260037":"code","2587c81e":"code","76e7d51c":"code","ec9cda9d":"code","543a4e29":"code","d0e73e4b":"code","0c4e49f9":"code","947a7c10":"code","8b24dea3":"code","1d29192a":"code","7074a212":"code","8166719e":"markdown","79107705":"markdown","64bd04fc":"markdown","a64278d7":"markdown","3416878d":"markdown","b1c799df":"markdown","135835bc":"markdown","944899ff":"markdown","0fa3603b":"markdown","60155bbc":"markdown","ad906e93":"markdown","3e0a85fe":"markdown","88077b8a":"markdown","b12631f9":"markdown"},"source":{"2e092621":"import pandas as pd","00f4a4d3":"df = pd.read_csv('..\/input\/filtered-wdidata\/filtered_WDIData.csv')","02bd8ba0":"df.head()","4a260037":"df = df.drop(['Unnamed: 0', 'Country Name', 'Country Code'], axis=1)","2587c81e":"df = pd.melt(df, id_vars=['Indicator Name', 'Indicator Code'])","76e7d51c":"df.head()","ec9cda9d":"df[df['Indicator Code'] == 'EG.CFT.ACCS.ZS']","543a4e29":"df.shape","d0e73e4b":"df = df.dropna(axis=0, how='any')","0c4e49f9":"df.shape","947a7c10":"str(85728-33075) + ' null rows'","8b24dea3":"df.groupby('Indicator Name').size().sort_values(ascending=False)","1d29192a":"df = df.rename(index=str, columns={\"variable\": \"Year\", 'value' : 'Value'})","7074a212":"df.to_csv('reshaped_US_WDIData.csv')","8166719e":"#### Let's pick a specific indicator and check out all it's values. We'll look at Access to clean fuels and technologies with Indicator Code EG.CFT.ACCS.ZS.","79107705":"#### We've now cleaned up our data in a way that will be significantly smaller than when we started and much easier to work with in programs like Tableau. Before we save our results, let's make one final change. The year column is now called 'variable'. Let's change this to 'Year' and rename 'value' to 'Value'.","64bd04fc":"This exercise demonstrates a few more techniques in pandas data shaping. First we will import the required libraries for the data work we need to conduct. ","a64278d7":"# Loading and Shaping Data in Python","3416878d":"#### Yikes, it looks like there are still many NaN values in this dataset. We can remove all these nulls using the pandas .dropna() method. In this case we will specify that axis=0 so we wild drop rows and how='any' so we will drop any rows that contain a null value. First let's take a look at the shape of the data frame which will give a result in (rows, cols):","b1c799df":"#### We've picked up an extra column which was the index from our old dataframe. Let's remove it. Since we are just working with the US we can also remove Country Name and Country Code.","135835bc":"#### Now let's output the results to csv.","944899ff":"#### We are now down to 33,076 rows. This means we dropped a total of:","0fa3603b":"#### Now that we've loaded data into our dataframe, we can use the pandas method .head() to look at the first 5 rows of data.","60155bbc":"#### Now let's look at the shape again:","ad906e93":"#### The data has 85,728 rows and 4 columns. Now let's drop those rows with null values","3e0a85fe":"#### We can use a combination of pandas methods to see how many rows exist for each indicator after we removed the nulls. The .groupby() method will group rows by the values of a column, in this case Indicator Name, the .size() method will count the number of rows in each group, and the .sort_values(ascending=False) will sort the results in descending order.","88077b8a":"### Loading the data\nIn this case, our data is in a CSV file called 'filtered_WDIData.csv' which we created in the previous lesson, so we will use the pandas method .read_csv() to retrieve it. You can add it from your own datasets, or you can get it from my datasets. Click on Add Data in the right hand tray and search Kaggle for the file: reshaped_US_WDIData.csv  Add it to your notebook.\n\nThen load it into a pandas dataframe:","b12631f9":"#### Currently each year is a separate column, while each indicator is a separate row. To make analysis easier in most analytics tools, we will want to make the a column called 'Year', where each row is a year and contains other columns contain indicator values. This is the pivot technique we've learned about, though in pandas it is called pd.melt()."}}