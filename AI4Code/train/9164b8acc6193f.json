{"cell_type":{"779ad77b":"code","dbba8fb8":"code","a3d40deb":"code","5af1e149":"code","6950b43e":"code","cb631036":"code","367bcc5f":"code","c5b9d60b":"code","a880570a":"code","849d1a45":"code","636618ab":"code","8460d89d":"code","697a9272":"code","d045ca9f":"code","ef8c57bb":"code","17ef2bb7":"code","e26aa3b2":"code","75294532":"code","70e86c00":"markdown","0a5d1fc3":"markdown","960de064":"markdown","d34b09b2":"markdown","29f27d54":"markdown","197c049c":"markdown","06686ede":"markdown","300bf0ee":"markdown","a4c658a0":"markdown","214407d7":"markdown"},"source":{"779ad77b":"#IMPORTING LIBRARIES\nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","dbba8fb8":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","a3d40deb":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","5af1e149":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","6950b43e":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","cb631036":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","367bcc5f":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","c5b9d60b":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","a880570a":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","849d1a45":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","636618ab":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","8460d89d":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","697a9272":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","d045ca9f":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","ef8c57bb":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')","17ef2bb7":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n\n#converting image to array\ntest_img = image.img_to_array(test_img)\n\n#we selected a batch size of 64 and it's a single phote, therefore we would be expanding it's dimensions\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = cnn.predict(test_img)\nprint(result)","e26aa3b2":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')","75294532":"import numpy as np\nfrom keras.preprocessing import image\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = cnn.predict(test_img)\nprint(result)","70e86c00":"**CLASSIYING WHETHER THEIR IS A DOG OR A CAT IN A PICTURE USING CNN.**\n","0a5d1fc3":"**IT'S A CAT**","960de064":"# **PREDICTING VALUES**","d34b09b2":"**STEP - 1) ADDING CONVOLUTIONAL LAYER**","29f27d54":"**IT'S A DOG**","197c049c":"**STEP - 4 ) FULL CONNECTION**","06686ede":"**STEP -3 ) FLATTENING**","300bf0ee":"# HERE CNN IS DIVIDED INTO 4 STEPS\n**1. CONVOLUTION**\n\n**2. POOLING**\n\n**3. FLATTENING**\n\n**4. FULL CONNECTION**","a4c658a0":"**STEP - 2) APPLYING MAX POOLING**","214407d7":"**0 MEANS CATS AND 1 MEANS DOGS**"}}