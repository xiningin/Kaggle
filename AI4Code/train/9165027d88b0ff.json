{"cell_type":{"03786bcf":"code","fa5d9a5b":"code","ff24428d":"code","a3804c14":"code","b96c48ad":"code","c1b667a2":"code","b6fa314f":"code","9cc8c4e3":"code","af1f2c3e":"code","5029903a":"code","cb3c5895":"code","3dda32f8":"code","4cfc6487":"code","65af52d7":"code","c49faaff":"code","37924301":"code","a6e4b472":"code","5ed6a1d5":"code","67698ace":"code","c2975929":"code","bd4fc6ee":"code","5a961b01":"code","2f31fa67":"code","c06134e8":"code","238d9e72":"code","e34d497f":"code","ad012a40":"code","a8fb3058":"code","e5535426":"markdown","82a1c6ec":"markdown","83187d08":"markdown","4f77dd75":"markdown"},"source":{"03786bcf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa5d9a5b":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport missingno as miss\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport plotly.express as px","ff24428d":"df = pd.read_csv(\"\/kaggle\/input\/newyork-room-rentalads\/room-rental-ads.csv\")","a3804c14":"df.head()","b96c48ad":"df.shape","c1b667a2":"df.dtypes","b6fa314f":"df.isna().sum()","9cc8c4e3":"miss.bar(df)\nplt.show()","af1f2c3e":"df.dropna(how=\"any\", inplace=True)\ndf = df.reset_index(drop=True)","5029903a":"df[\"Vague\/Not\"].value_counts()","cb3c5895":"df.rename(columns = {\"Vague\/Not\":\"Target\"},inplace = True)\ndf.Target = df.Target.astype(\"int\").astype(\"category\")\ndf","3dda32f8":"df.Description.sample(10)","4cfc6487":"#check for duplicates\n\nlen(df[df.duplicated()])","65af52d7":"#drop duplicates\n\ndf = df.drop_duplicates(subset=['Description'])\nprint(df.head())\nprint(df.shape)","c49faaff":"#normalization\n\nimport re\nimport spacy\nnlp = spacy.load('en')\n\ndef normalize(msg):\n    \n    msg = re.sub('[^A-Za-z]+', ' ', msg) #remove special character and intergers\n    doc = nlp(msg)\n    res=[]\n    for token in doc:\n        if(token.is_stop or token.is_punct or token.is_currency or token.is_space or len(token.text) <= 2): #word filteration\n            pass\n        else:\n            res.append(token.lemma_.lower())\n    return res","37924301":"df[\"Description\"] = df[\"Description\"].apply(normalize)\ndf.head()","a6e4b472":"words_collection = Counter([item for sublist in df['Description'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(20))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","5ed6a1d5":"fig = px.scatter(freq_word_df, x=\"frequently_used_word\", y=\"count\", color=\"count\", title = 'Frequently used words - Scatter plot')\nfig.show()","67698ace":"df[\"Description\"] = df[\"Description\"].apply(lambda m : \" \".join(m))","c2975929":"from sklearn.feature_extraction.text import TfidfVectorizer #vectorize the string\nc = TfidfVectorizer(ngram_range=(1,2))\nmat=pd.DataFrame(c.fit_transform(df[\"Description\"]).toarray(),columns=c.get_feature_names(),index=None)\nmat","bd4fc6ee":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix","5a961b01":"clfs = {\n    'mnb': MultinomialNB(),\n    'gnb': GaussianNB(),\n    'svm1': SVC(kernel='linear'),\n    'svm2': SVC(kernel='rbf'),\n    'svm3': SVC(kernel='sigmoid'),\n    'mlp1': MLPClassifier(),\n    'mlp2': MLPClassifier(hidden_layer_sizes=[100, 100]),\n    'ada': AdaBoostClassifier(),\n    'dtc': DecisionTreeClassifier(),\n    'rfc': RandomForestClassifier(),\n    'gbc': GradientBoostingClassifier(),\n    'lr': LogisticRegression()\n}","2f31fa67":"train_x, train_y, test_x, test_y = train_test_split(mat, df['Target'], test_size=0.3)","c06134e8":"accuracy_scores = dict()\n\nfor clf_name in clfs:\n    \n    clf = clfs[clf_name]\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    accuracy_scores[clf_name] = accuracy_score(y_pred, test_y)\n    print(clf_name, accuracy_scores[clf_name])","238d9e72":"accuracy_scores = dict(sorted(accuracy_scores.items(), key = lambda kv:(kv[1], kv[0]), reverse= True))\nh = list(accuracy_scores.keys())[0]\nprint(\"Classifier with high accuracy --> \",clfs[h])\nprint(\"With the accuracy of\",accuracy_scores[h])","e34d497f":"cm = confusion_matrix(clfs[h].predict(train_y), test_y)\nprint(cm)","ad012a40":"#graph with confusion matrix\n\ngroup_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()\/np.sum(cm)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')\nplt.show()","a8fb3058":"fig,ax=plt.subplots(figsize=(10,5))\nsns.regplot(y=test_y,x=clfs[h].predict(train_y),marker=\"*\")\nplt.show()","e5535426":"## Let's start prediction","82a1c6ec":"<font color=\"blue\" size=+1.5><b>Check out my other kernels<\/b><\/font>\n\n<div style=\"margin-bottom: 20px;\">\n    &nbsp;\n<div style=\"float:left; margin-right:10px;\">\n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/amazon-review-prediction-using-spacy\" class=\"btn btn-info\" style=\"color:white;\">Amazon review prediction using spaCy<\/a>\n<\/div>\n \n<div style=\"float:left; margin-right:10px;\"> \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/titanic-prediction\" class=\"btn btn-info\" style=\"color:white;\">Titanic Prediction<\/a>\n<\/div>\n\n<div style=\"float:left; margin-right:10px;\">   \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/loan-status-prediction\" class=\"btn btn-info\" style=\"color:white;\">Loan Status Prediction<\/a>\n<\/div>\n<\/div>\n    \n<div style=\"float:left; margin-right:10px;\">    \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/kollywood-prediction\" class=\"btn btn-info\" style=\"color:white;\">Kollywood Data Prediction<\/a><br><br>\n<\/div>    \n\n<div style=\"float:left; margin-right:10px;\">    \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/sms-spam-or-not-base\" class=\"btn btn-info\" style=\"color:white;\">SMS Spam or Not Prediction<\/a><br><br>\n<\/div> \n\n<div style=\"float:left; margin-right:10px;\">    \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/future-sales-prediction\" class=\"btn btn-info\" style=\"color:white;\">Future Sales Prediction<\/a><br><br>\n<\/div>","83187d08":"**Final Notes:**\n\nI am adding things still. You can come back and check for more information.\n\nAlso, if you **like my notebook**, <font style=\"color:blue;size:14px;\">upvote it<\/font> as it will motivate me to come up with better approach in the upcoming notebooks.","4f77dd75":"## Let's look at the accuracy of different classifiers"}}