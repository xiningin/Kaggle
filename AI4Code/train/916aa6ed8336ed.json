{"cell_type":{"fe51d186":"code","fa6f7444":"code","e6747b24":"code","1a2ff99e":"code","f2dca532":"code","3f0c24f5":"code","d87c06e7":"code","f540862b":"code","a1432618":"code","0583e5d8":"code","7a3c6a15":"code","83cf94e0":"code","7ea68e1c":"code","12df1f97":"code","7df09218":"code","9518ebdd":"code","0c7b61ef":"code","5a730ef2":"code","4db2db68":"code","e016617c":"code","be38d6a8":"code","0fc0cc30":"code","c2ac09b1":"code","e58ec551":"code","5be210c7":"code","4cfd492f":"markdown","fe369786":"markdown","886d1ad8":"markdown","731857c8":"markdown","8139fa19":"markdown","0634b73b":"markdown","4cdd8896":"markdown","90cd3675":"markdown","c58d4531":"markdown","1c423447":"markdown","1f0a9f41":"markdown","ab2d7fe2":"markdown","c5e915e7":"markdown","bce21422":"markdown","4802c1e5":"markdown","187ffd77":"markdown","b18b0b92":"markdown","32da7333":"markdown","724a1d59":"markdown","ecee0f3f":"markdown","10a8bee5":"markdown","ec9a5d8c":"markdown","b7b52338":"markdown","fead3ce8":"markdown","e4c45c9a":"markdown","9f14bd0b":"markdown","2c50281c":"markdown","a43c8f84":"markdown","e7ac0193":"markdown","98bb99eb":"markdown","4c2d2778":"markdown","e0749034":"markdown","80fa1ef0":"markdown","7d930f8f":"markdown","2f1ed953":"markdown","65cd214c":"markdown","48d8daa9":"markdown","cf9ca153":"markdown","480d93da":"markdown"},"source":{"fe51d186":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import applications\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras import backend as K\nimport gc\nfrom tensorflow.keras.models import Model\nimport pickle","fa6f7444":"train_dir=\"..\/input\/re-arranged-data\/sign_data\/Dataset\/train\"\ntest_dir=\"..\/input\/re-arranged-data\/sign_data\/Dataset\/test\"","e6747b24":"img = plt.imread('..\/input\/re-arranged-data\/sign_data\/Dataset\/train\/001\/001_01.PNG')\nplt.imshow(img)","1a2ff99e":"img1 = plt.imread('..\/input\/re-arranged-data\/sign_data\/Dataset\/train\/001_forg\/0119001_01.png')\nplt.imshow(img1)","f2dca532":"SIZE = 224","3f0c24f5":"train_data_names = []\ntest_data_names = []\n\ntrain_data = []\ntrain_labels = []\n\nfor per in os.listdir('..\/input\/re-arranged-data\/sign_data\/Dataset\/train'):\n    for data in glob.glob('..\/input\/re-arranged-data\/sign_data\/Dataset\/train\/'+per+'\/*.*'):\n        \n        train_data_names.append(data)\n        img = cv2.imread(data)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (SIZE,SIZE))\n        train_data.append([img])\n        if per[-1]=='g':\n            train_labels.append(np.array(1))\n        else:\n            train_labels.append(np.array(0))\n\ntrain_data = np.array(train_data)\/255.0\ntrain_labels = np.array(train_labels)\n\n#Test Data\n\ntest_data = []\ntest_labels = []\n\nfor per in os.listdir('..\/input\/re-arranged-data\/sign_data\/Dataset\/test'):\n    for data in glob.glob('..\/input\/re-arranged-data\/sign_data\/Dataset\/test\/'+per+'\/*.*'):\n        test_data_names.append(data)\n        img = cv2.imread(data)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (SIZE,SIZE))\n        test_data.append([img])\n        if per[-1]=='g':\n            test_labels.append(np.array(1))\n        else:\n            test_labels.append(np.array(0))\n\ntest_data = np.array(test_data)\/255.0\ntest_labels = np.array(test_labels)","d87c06e7":"with open('.\/train_data_names.pkl', 'wb') as fp:\n    pickle.dump(train_data_names, fp)\n\nwith open('.\/test_data_names.pkl', 'wb') as fp:\n    pickle.dump(test_data_names, fp)","f540862b":"# Categorical labels\n#print(train_labels)\ntrain_labels = to_categorical(train_labels)\n#print(train_data.shape)\n# Reshaping\ntrain_data = train_data.reshape(-1, SIZE,SIZE, 3)\ntest_data = test_data.reshape(-1, SIZE,SIZE, 3)","a1432618":"input_ = (224,224,3)\nEPOCHS = 20\nBS = 64\noutput_ = 2","0583e5d8":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/VGG16_Adam_train', intermediate_output_train)\nnp.save('.\/VGG16_Adam_test', intermediate_output_test)","7a3c6a15":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/VGG16_SGD_train', intermediate_output_train)\nnp.save('.\/VGG16_SGD_test', intermediate_output_test)","83cf94e0":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/VGG16_RMSprop_train', intermediate_output_train)\nnp.save('.\/VGG16_RMSprop_test', intermediate_output_test)","7ea68e1c":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adagrad(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/VGG16_Adagrad_train', intermediate_output_train)\nnp.save('.\/VGG16_Adagrad_test', intermediate_output_test)","12df1f97":"base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/InceptionV3_Adam_train', intermediate_output_train)\nnp.save('.\/InceptionV3_Adam_test', intermediate_output_test)","7df09218":"base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/InceptionV3_SGD_train', intermediate_output_train)\nnp.save('.\/InceptionV3_SGD_test', intermediate_output_test)","9518ebdd":"base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/InceptionV3_RMSprop_train', intermediate_output_train)\nnp.save('.\/InceptionV3_RMSprop_test', intermediate_output_test)","0c7b61ef":"base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adagrad(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/InceptionV3_Adagrad_train', intermediate_output_train)\nnp.save('.\/InceptionV3_Adagrad_test', intermediate_output_test)","5a730ef2":"base_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/ResNet50_Adam_train', intermediate_output_train)\nnp.save('.\/ResNet50_Adam_test', intermediate_output_test)","4db2db68":"base_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/ResNet50_SGD_train', intermediate_output_train)\nnp.save('.\/ResNet50_SGD_test', intermediate_output_test)","e016617c":"base_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/ResNet50_RMSprop_train', intermediate_output_train)\nnp.save('.\/ResNet50_RMSprop_test', intermediate_output_test)","be38d6a8":"base_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adagrad(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/ResNet50_Adagrad_train', intermediate_output_train)\nnp.save('.\/ResNet50_Adagrad_test', intermediate_output_test)","0fc0cc30":"base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/Xception_Adam_train', intermediate_output_train)\nnp.save('.\/Xception_Adam_test', intermediate_output_test)","c2ac09b1":"base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/Xception_SGD_train', intermediate_output_train)\nnp.save('.\/Xception_SGD_test', intermediate_output_test)","e58ec551":"base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/Xception_RMSprop_train', intermediate_output_train)\nnp.save('.\/Xception_RMSprop_test', intermediate_output_test)","5be210c7":"base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=input_)\n\nmodel = Sequential()\ndata_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.1)])\nmodel.add(base_model)\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(output_, activation='softmax'))\n\nmodel = Model(inputs=model.input, outputs=model.output)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adagrad(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()\n\nearlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=3,\n                              verbose=1)\n\nearly_stop=[earlyStopping]\nprogess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=early_stop,validation_split=.3)\nacc = progess.history['accuracy']\nval_acc = progess.history['val_accuracy']\nloss = progess.history['loss']\nval_loss = progess.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.layers[-2].output)\nintermediate_output_train = intermediate_layer_model.predict(train_data)\nintermediate_output_test = intermediate_layer_model.predict(test_data)\n\nnp.save('.\/Xception_Adagrad_train', intermediate_output_train)\nnp.save('.\/Xception_Adagrad_test', intermediate_output_test)","4cfd492f":"<h1> VGG16 - Adagrad <\/h1>","fe369786":"<h1> Xception - Adam <\/h1>","886d1ad8":"<h1> HANDWRITTEN SIGNATURE VERIFICATION \nUSING \nCONVOLUTION NEURAL NETWORK (CNN) <\/h1>","731857c8":"<h2> Part 1 <\/h2>","8139fa19":"![image.png](attachment:8470a278-87b0-4da0-9e5f-6823f84fbfdc.png)","0634b73b":"<h1> Inception_v3 - SGD <\/h1>","4cdd8896":"![image.png](attachment:a23ab6f3-9629-4231-ad62-abfcc26b1f04.png)","90cd3675":"<h2> The Proposed Methodology <\/h2>","c58d4531":"1. Convolution neural network (CNN) are popular neural network architectures for working on image dataset. \n2. Total 16 models were trained to compare the accuracy.\n3. 4 Architectures Used for Feature Extraction are:-\n- VGG16\n- Inception-v3\n- ResNet-50\n- Xception\n4. Optimizers used to compile the models are:-\n- Stochastic gradient descent (SGD)\n- Root Mean Square Propagation (RMSprop\n- Adaptive Gradient Algorithm (Adagrad) \n- Active Design and Analysis Modelling (Adam)","1c423447":"<h1> Xception - Adagrad <\/h1>","1f0a9f41":"<h3> Feature Extraction <\/h3>","ab2d7fe2":"- e-KYC\n- Instant Document Verification \n- Banking and Financial Services\n- Government Official work","c5e915e7":"- In depth study of 25 Research Paper is done before proceeding with the project. Notable Research Paper are mentioned below.\n\n- Fierrez, J., Galbally, J., Ortega-Garcia, J., Freire, M. R., Alonso-Fernandez, F., Ramos, D., ... & Gracia-Roche, J. J. (2010).  An online signature verification methodology has been introduced. The system uses a timeline set with Hidden Markov Models (HMMs). \n\n- Yang, L., Widjaja, B. K., & Prasad, R. (1995). Application of hidden Markov models for signature verification. Pattern recognition, 28(2), 161-170. The Baum-Welch algorithm is used for training and segregation. Test results based on 496 signatures from 31 studies were presented showing that the HMM process has potential for signature verification.\n\n- Sam, S. M., Kamardin, K., Sjarif, N. N. A., & Mohamed, N. (2019). Offline signature verification using deep learning convolutional neural network (CNN) architectures GoogLeNet inception-v1 and inception-v3.","bce21422":"<h1> Inception_v3 - RMSprop <\/h1>","4802c1e5":"<h1> VGG16 - ADAM <\/h1>","187ffd77":"<h1> VGG16 - SGD <\/h1>","b18b0b92":"<h4>\n1. Dataset <br><br>\n2. Proposed System<br><br>\n3. Feature Extraction<br><br>\n4. Feature Selection<br><br>\n5. Classification<br>\n<\/h4>","32da7333":"<h1> ResNet50 - RMSprop <\/h1>","724a1d59":"<h2> Outline <\/h2>","ecee0f3f":"<h2> INTRODUCTION <\/h2>","10a8bee5":"- Introduction\n- Literature Survey\n- The Proposed Methodology \n- Industrial Application\n- Conclusion\n- References","ec9a5d8c":"<h1> Inception_v3 - Adagrad <\/h1>","b7b52338":"<h3> Feature Selection <\/h3>","fead3ce8":"1. The first observation from above tables VGG16 architecture outperformed all other architectures and features from the models which can be used for classification are with at least 95% training accuracy and 60% validation accuracy. \n2. Four models which we choose to test our classification algorithms are:- \n- VGG16 - Adam\n- VGG16 \u2013 RMSprop\n- Inception-v3 \u2013 Adam\n- Inception-v3 \u2013 Adagrad","e4c45c9a":"<h2> Industrial Application <\/h2>","9f14bd0b":"<h1> Xception - RMSprop <\/h1>","2c50281c":"![image.png](attachment:5e5176a7-51fa-4496-b248-93e77a2df510.png)","a43c8f84":"<h3> Graphs of Best Performing Models <\/h3>","e7ac0193":"<h1> VGG16 - RMSProp <\/h1>","98bb99eb":"<h1> ResNet50 - Adagrad <\/h1>","4c2d2778":"<h4> \n    \n**Problem Statement**  :  \n    *The objective is to develop the handwritten verification system using latest advancement in deep learning. Input parameter to this system is pair of two signature in portable network graphics images (PNG) format and outputs the Boolean value (1 or 0).* <br>\n\n**Motivation**  :  \n    *Signature is an important aspect for authentication of an individual. Before biometric and even today in the financial field. Signature are the primary way to authenticate personal Identity.*  <br>\n\n**Abstract**   :   \n    *We present the convolutional neural networks for feature extraction and supervised machine learning techniques for the verification of handwritten signatures. Raw images of signatures are used to train CNN models for extracting features along with data augmentation. CNN Architectures used are VGG16, Inception-v3, ResNet50, and Xception. The Extracted features are classified into two classes genuine or forgery using Euclidean distance, cosine similarity and supervised learning algorithm such as Logistic Regression, Random Forest, SVM and its variations. Data used for testing is extracted from ICDAR 2011 Signature Dataset and organized in pairwise fashion. The database contains signatures of 69 subjects.*   <br>\n    \n<\/h4>","e0749034":"<h1> Xception - SGD <\/h1>","80fa1ef0":"<h1>  ResNet50 - SGD <\/h1>","7d930f8f":"_This is Yash Gupta, India Institute of Information Technology, Nagpur representing final year project. Stay and upvote if you like the notebook._","2f1ed953":"<h1> ResNet50 - Adam <\/h1>","65cd214c":"<h3> Feature Extraction Results <\/h3>","48d8daa9":"<h1> Parameters <\/h1>","cf9ca153":"<h2> Literature Survey <\/h2>","480d93da":"<h1> Inception_v3 - ADAM <\/h1>"}}