{"cell_type":{"ecd1cbb2":"code","9bd89458":"code","91e58aba":"code","3ade3da6":"code","3c3f55c7":"code","c06a82cf":"code","c0ddd2ef":"code","cbe83498":"code","38eb07b2":"code","a7f073a9":"code","91c8cea0":"code","d0d525be":"code","ca20de6c":"code","a240e546":"code","3111b28f":"code","0ed268e6":"code","794b91d9":"code","6483fd67":"code","b5b81f52":"code","78f9994b":"code","22a8f9f7":"code","01ca5a9b":"code","920f9b3c":"code","01794202":"code","e3b8408d":"code","9433727e":"markdown","d8b6de4e":"markdown","6e9b59fe":"markdown","ff859baa":"markdown","54cd0bbf":"markdown","befe398e":"markdown","ea5986c8":"markdown"},"source":{"ecd1cbb2":"import pandas as pd\nimport numpy as np\n#from catboost import CatBoostClassifier\n#from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\n#from sklearn.metrics import accuracy_score\n\n#Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n#For Missing Value and Feature Engineering\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, VarianceThreshold\nfrom sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\nimport time\n","9bd89458":"train = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/test.csv\")","91e58aba":"train.head()","3ade3da6":"#create X and y datasets for splitting \nX = train.drop(['ID', 'TARGET'], axis=1)\ny = train['TARGET']","3c3f55c7":"all_features = X.columns","c06a82cf":"all_features = all_features.tolist()","c0ddd2ef":"numerical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind in ['i','f'] and c !='PassengerId']\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind not in ['i','f']]","cbe83498":"numerical_features","38eb07b2":"categorical_features","a7f073a9":"#import train_test_split library\nfrom sklearn.model_selection import train_test_split\n\n# create train test split\nX_train, X_test, y_train, y_test = train_test_split( X,  y, test_size=0.3, random_state=0)  ","91c8cea0":"preprocessor = make_column_transformer(\n    \n    (make_pipeline(\n    #SimpleImputer(strategy = 'median'),\n    KNNImputer(n_neighbors=2, weights=\"uniform\"),\n    MinMaxScaler()), numerical_features),\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n    OneHotEncoder(categories = 'auto', handle_unknown = 'ignore')), categorical_features),\n    \n)","d0d525be":"preprocessor_best = make_pipeline(preprocessor, \n                                  VarianceThreshold(), \n                                  SelectKBest(f_classif, k = 10), \n                                  PCA(n_components = 3))","ca20de6c":"RF_Model = make_pipeline(preprocessor_best, RandomForestClassifier(n_estimators = 100))","a240e546":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n#Maximum number of levels in tree\nmax_depth = [2,4,6,8]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]","3111b28f":"# Create the param grid\nparam_grid = {'randomforestclassifier__n_estimators': n_estimators,\n               'randomforestclassifier__max_features': max_features,\n               'randomforestclassifier__max_depth': max_depth,\n               'randomforestclassifier__min_samples_split': min_samples_split,\n               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n               'randomforestclassifier__bootstrap': bootstrap\n             }\nprint(param_grid)","0ed268e6":"from sklearn.model_selection import RandomizedSearchCV\nrf_RandomGrid = RandomizedSearchCV(estimator = RF_Model, param_distributions = param_grid, cv = 5, verbose=3, n_jobs = -1, scoring = 'roc_auc', n_iter = 5)","794b91d9":"rf_RandomGrid.fit(X_train, y_train)","6483fd67":"rf_RandomGrid.best_estimator_","b5b81f52":"print(f'Train : {rf_RandomGrid.score(X_train, y_train):.3f}')\nprint(f'Test : {rf_RandomGrid.score(X_test, y_test):.3f}')","78f9994b":"from sklearn.metrics import roc_auc_score","22a8f9f7":"print(f'Train AUC : {roc_auc_score(y_train, rf_RandomGrid.predict_proba(X_train)[:,1]):.3f}')\nprint(f'Train AUC : {roc_auc_score(y_test, rf_RandomGrid.predict_proba(X_test)[:,1]):.3f}')","01ca5a9b":"test_pred = rf_RandomGrid.predict_proba(test[X.columns])[:,1]\n#test_pred = rf_RandomGrid.predict(test[X.columns])","920f9b3c":"AllSub = pd.DataFrame({ 'ID': test['ID'],\n                       'TARGET' : test_pred\n    \n})","01794202":"#AllSub['TARGET'] = AllSub['TARGET'].apply(lambda x: 1 if x > 0.5 else 0)","e3b8408d":"AllSub.to_csv('Santander_RF_Better_Pipe.csv', index = False)","9433727e":"## Import Libraries","d8b6de4e":"## Import Data","6e9b59fe":"## Grid Search","ff859baa":"## Divide Dataset into X and Y","54cd0bbf":"## Setup Pipeline ","befe398e":"## Submission ","ea5986c8":"## Accuracy"}}