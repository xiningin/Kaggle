{"cell_type":{"d8d91f16":"code","7dc47108":"code","cc152770":"code","bdc5bd00":"code","924bcca9":"code","1252b468":"code","72c6c983":"code","af415817":"code","ad820f9e":"code","fd5875d6":"code","d1b2bb4a":"code","56d52931":"code","8e084e91":"code","783187c8":"code","2375c184":"code","abd335b7":"code","078a1a88":"code","9b20975d":"code","73046af9":"code","f89f3834":"code","6207b8bf":"code","703c06f6":"code","786794b6":"code","19d87469":"code","c10e5a1c":"code","7233ab7d":"code","9c8d871b":"markdown","70755a83":"markdown","32bccbed":"markdown","c69eaa85":"markdown","224a2eb1":"markdown","7feeaeda":"markdown","08158257":"markdown","8e9cc61f":"markdown"},"source":{"d8d91f16":"import gc\nimport glob\nimport os\nimport json\nimport matplotlib.pyplot as plt\nimport pprint\nimport numpy as np\nimport pandas as pd\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nfrom PIL import Image\nimport re\nimport matplotlib\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn import datasets, manifold, mixture, model_selection\nfrom gensim.models import Word2Vec\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom xgboost import XGBClassifier\nimport cv2\nfrom keras.applications.densenet import preprocess_input, DenseNet121\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, MaxPooling1D, concatenate\nimport keras.backend as K\nfrom sklearn.decomposition import TruncatedSVD, NMF\n\n%matplotlib inline","7dc47108":"import os\n\nprint(os.listdir(\"..\/input\/cute-cats-and-dogs-from-pixabaycom\/\"))\nprint(os.listdir(\"..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\"))\nprint(os.listdir(\"..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/cats\/\"))\nprint(os.listdir(\"..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/dogs\/\"))","cc152770":"!mkdir ..\/input\/root ..\/input\/root\/pets ..\/input\/root\/pets\/0 ..\/input\/root\/pets\/1","bdc5bd00":"!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/cats\/0\/*.jpg ..\/input\/root\/pets\/0\/\n!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/dogs\/0\/*.jpg ..\/input\/root\/pets\/0\/\n!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/cats\/1\/*.jpg ..\/input\/root\/pets\/1\/\n!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/dogs\/1\/*.jpg ..\/input\/root\/pets\/1\/","924bcca9":"labels = pd.read_csv(\"..\/input\/cute-cats-and-dogs-from-pixabaycom\/labels.csv\")\nprint(labels.shape)\nprint(labels.id.nunique())\nlabels.head()","1252b468":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torchvision.transforms import functional as F\nimport random\nimport tensorflow as tf\n\nimport os\nimport time\nimport copy\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nkaeru_seed = 1337\nseed_everything(seed=kaeru_seed)\n# ======================================","72c6c983":"data_dir = os.path.join('..\/input', 'root')\nimage_dataset = datasets.ImageFolder(os.path.join(data_dir, 'pets'))\n# image_dataset = datasets.ImageFolder(os.path.join(data_dir))\nprint(len(image_dataset))  # 41272\u679a\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\nimage, label = image_dataset[0]  # 0\u756a\u76ee\u306e\u753b\u50cf\u3068\u30e9\u30d9\u30eb","af415817":"plt.figure()\nplt.imshow(image)\n\nt = transforms.RandomResizedCrop(224)\ntrans_image = t(image)\n\nplt.figure()\nplt.imshow(trans_image)","ad820f9e":"batchsize = 32 \nepochs = 20 \nepoch_start =1","fd5875d6":"data_dir = os.path.join('..\/input', 'root\/')\n# data_dir = os.path.join('..\/input', 'cute-cats-and-dogs-from-pixabaycom\/pixabay\/')\ndata_transform = transforms.Compose([\n transforms.Resize([224, 224]), transforms.RandomHorizontalFlip(),\n transforms.ToTensor(),\n transforms.Normalize((0.4914, 0.4822, 0.4465),\n (0.2023, 0.1994, 0.2010)), \n]) \n# full_Dataset = datasets.ImageFolder(data_dir,transform=data_transform) \nfull_Dataset = datasets.ImageFolder(os.path.join(data_dir, 'pets'),transform=data_transform) \n# full_Dataset = datasets.ImageFolder(os.path.join(data_dir, 'cats'),transform=data_transform) \nprint(len(full_Dataset)) \ntrain_size = int(0.8 * len(full_Dataset)) \ntest_size = len(full_Dataset) - train_size \ntrain_Dataset, test_Dataset = torch.utils.data.random_split(full_Dataset, [train_size, test_size]) \nprint(len(train_Dataset)) \nprint(len(test_Dataset)) \ntrain_loader = torch.utils.data.DataLoader(train_Dataset,batch_size=batchsize, shuffle=True) \ntest_loader = torch.utils.data.DataLoader(test_Dataset,batch_size=batchsize, shuffle=False) \nprint(\"train images: {}\".format(len(train_Dataset)))\nprint(\"test images: {}\".format(len(test_Dataset))) \nprint(\"epoch: {}\".format(epochs))\nprint(\"batch size: {}\".format(batchsize))","d1b2bb4a":"print(full_Dataset.classes)\nprint(full_Dataset.class_to_idx)","56d52931":"import torch.backends.cudnn as cudnn \n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"cuda is available!\")\n    cudnn.benchmark = True\n    cudnn.deterministic = True","8e084e91":"print(os.listdir(\"..\/input\/pytorch-pretrained-image-models\/\"))","783187c8":"n_classes = 2\n# n_classes = 1\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n\nmodel = models.resnet34().to(device) \nmodel.load_state_dict(torch.load('..\/input\/pytorch-pretrained-image-models\/resnet34.pth'))\n\nfor p in model.parameters():\n    p.requires_grad=False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, n_classes)\nif use_gpu:\n    model.cuda()","2375c184":"def eval_net(model, data_loader, device=\"cpu\"):\n    model.eval()\n    ys=[]\n    ypreds=[]\n    for x, y in data_loader:\n        x = x.to(device)\n        y = y.to(device)\n        \n        with torch.no_grad():\n            _, y_pred = model(x).max(1)\n        ys.append(y)\n        ypreds.append(y_pred)\n    ys = torch.cat(ys)\n    ypreds = torch.cat(ypreds)\n    acc = (ys == ypreds).float().sum() \/ len(ys)\n    return acc.item()","abd335b7":"def train_net(model, train_loader, test_loader, only_fc=True, optimizer_cls=optim.Adam,\n              loss_fn=nn.CrossEntropyLoss(), n_iter=10, device=\"cpu\"):\n    train_losses = []\n    train_acc = []\n    val_acc = []\n    if only_fc:\n        optimizer = optimizer_cls(model.fc.parameters())\n    else:\n        optimizer = optimizer_cls(model.parameters())\n    \n    for epoch in range(n_iter):\n        running_loss = 0.0\n    \n        model.train()\n        n = 0\n        n_acc = 0\n        for i, (xx, yy) in tqdm(enumerate(train_loader), total=len(train_loader)):\n            xx = xx.to(device)\n            yy = yy.to(device)\n            h = model(xx)\n            loss = loss_fn(h, yy)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            n += len(xx)\n            _, y_pred = h.max(1)\n            n_acc += (yy == y_pred).float().sum().item()\n        train_losses.append(running_loss \/ i)\n        train_acc.append(n_acc \/ n)\n        val_acc.append(eval_net(model, test_loader, device))\n        \n        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)","078a1a88":"model.to(\"cuda:0\")\n\ntrain_net(model, train_loader, test_loader, n_iter=20, device=\"cuda:0\")","9b20975d":"# \u4fdd\u5b58\ntorch.save(model, 'cute_model')\n# torch.save(model, 'binary_cute_model')","73046af9":"def imshow(images, title=None):\n    images = images.numpy().transpose((1, 2, 0))  # (h, w, c)\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    images = std * images + mean\n    images = np.clip(images, 0, 1)\n    plt.imshow(images)\n    if title is not None:\n        plt.title(title)\n\nimages, classes = next(iter(train_loader))\nprint(images.size(), classes.size())  # torch.Size([4, 3, 224, 224]) torch.Size([4])\nimages = torchvision.utils.make_grid(images)\nimshow(images)","f89f3834":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torchvision.transforms import functional as F\nimport random\nimport tensorflow as tf\n\nimport os\nimport time\nimport copy\nimport numpy as np\nimport matplotlib.pyplot as plt","6207b8bf":"def get_profile_path(category):\n\n    data = []\n\n    for path in sorted(glob.glob('..\/input\/petfinder-adoption-prediction\/%s_images\/*-1.jpg' % category)):\n\n        data.append({\n            'PetID': path.split('\/')[-1].split('-')[0],\n            'path': path,\n        })\n            \n    return pd.DataFrame(data)\n\ndef resize_to_square(image, size):\n    h, w, d = image.shape\n    ratio = size \/ max(h, w)\n    resized_image = cv2.resize(image, (int(w*ratio), int(h*ratio)), cv2.INTER_AREA)\n    return resized_image\n\ndef image_to_tensor(image, normalize=None):\n    tensor = torch.from_numpy(np.moveaxis(image \/ (255. if image.dtype == np.uint8 else 1), -1, 0).astype(np.float32))\n    if normalize is not None:\n        return F.normalize(tensor, **normalize)\n    return tensor\n\ndef pad(image, min_height, min_width):\n    h,w,d = image.shape\n\n    if h < min_height:\n        h_pad_top = int((min_height - h) \/ 2.0)\n        h_pad_bottom = min_height - h - h_pad_top\n    else:\n        h_pad_top = 0\n        h_pad_bottom = 0\n\n    if w < min_width:\n        w_pad_left = int((min_width - w) \/ 2.0)\n        w_pad_right = min_width - w - w_pad_left\n    else:\n        w_pad_left = 0\n        w_pad_right = 0\n\n    return cv2.copyMakeBorder(image, h_pad_top, h_pad_bottom, w_pad_left, w_pad_right, cv2.BORDER_CONSTANT, value=(0,0,0))\n\nclass Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, df, size):\n        self.df = df\n        self.size = size\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n\n        row = self.df.iloc[idx]\n\n        image = cv2.imread(row.path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = resize_to_square(image, self.size)\n        image = pad(image, self.size, self.size)\n        tensor = image_to_tensor(image, normalize={'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]})\n            \n        return tensor","703c06f6":"size = 224\ntrain_image_files = get_profile_path('train')\ntest_image_files = get_profile_path('test')","786794b6":"import itertools\nimport torch\n\n# model = torch.load('..\/input\/cute-model-cat\/cute_model')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n\ndef get_cute_feats(df, model):\n    model.eval()\n    \n    cute_or_not = []\n\n    dataset = Dataset(df, size)\n    loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n    \n    for xx in tqdm(loader, total=len(loader)):\n        xx = xx.to(device)\n        h = model(xx).max(1)\n        cute_or_not.append(h)\n        \n    li = []\n    for i in range(len(cute_or_not)):\n        li.append(list(cute_or_not[i][1].cpu().numpy()))\n\n    features = [ flatten for inner in li for flatten in inner ]\n    \n    features = np.array(features)\n    features = pd.DataFrame(features)\n    features = features.add_prefix('cute_or_not_')\n    features.loc[:,'PetID'] = df['PetID']\n    \n    return features","19d87469":"train_cute = get_cute_feats(train_image_files, model)\nprint(train_cute.shape)\ntrain_cute.head()","c10e5a1c":"test_cute = get_cute_feats(test_image_files, model)\nprint(test_cute.shape)\ntest_cute.head()","7233ab7d":"# train_cute.to_csv('train_cute.csv', index=False)\n# test_cute.to_csv('test_cute.csv', index=False)","9c8d871b":"!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/cats\/1\/*.jpg ..\/input\/root\/pets\/1\/\n!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/dogs\/1\/*.jpg ..\/input\/root\/pets\/1\/","70755a83":"make feature part","32bccbed":"Version 9 : XEntropyLoss, 2 class","c69eaa85":"!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/cats\/0\/*.jpg ..\/input\/root\/pets\/0\/\n!cp ..\/input\/cute-cats-and-dogs-from-pixabaycom\/pixabay\/dogs\/0\/*.jpg ..\/input\/root\/pets\/0\/","224a2eb1":"training functions","7feeaeda":"visualize","08158257":"GPU","8e9cc61f":"network"}}