{"cell_type":{"b1bcd320":"code","3b4540e7":"code","04bcad7a":"code","2d935928":"code","551d6387":"code","17257d6c":"code","924deeed":"code","f267b5ac":"code","8120d18b":"code","3a5fea31":"code","9e5af913":"code","9d0f9a67":"code","01f67003":"code","341e4083":"code","7ea95722":"code","df26c23b":"code","abbe7b8b":"code","b86a0a8a":"code","001f197c":"code","5c771610":"code","26efb0a0":"code","81d894fe":"code","9d348dda":"code","a4ec0818":"code","95133fe3":"code","baa8d342":"code","9ce06347":"code","4d710b7e":"code","bd0cd9e2":"code","2628d2b9":"code","afb0bebb":"code","fae5f976":"code","79dd225d":"code","c35fd4fb":"code","29144633":"code","ee53185d":"code","96f6172f":"code","625a78d6":"code","83fa0287":"code","9c70cb61":"code","e2b76e9f":"code","96688819":"code","52e40342":"code","b8330e6e":"code","a35e06a1":"code","9fb7eb53":"code","94cab43d":"markdown","5e4677c4":"markdown","24d16eed":"markdown","c6bbd51f":"markdown","43cb3775":"markdown","36a8dd47":"markdown","8ac32252":"markdown","d33232e9":"markdown","fc9a5ef5":"markdown","e3085a78":"markdown","ad5f241a":"markdown","863d7900":"markdown","1fd226f7":"markdown","764039eb":"markdown","0896627a":"markdown","7607e139":"markdown"},"source":{"b1bcd320":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3b4540e7":"import numpy as np\nimport pandas as pd\nimport os\n# print current file directory\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt","04bcad7a":"# read csv\n# In pandas, you can call function read_csv() to read the csv file with given parameters\n# such as the path of the file, and the encoding, \n# if the file is large, you can add parameter \"low_memory=False\" to read large csv file\ndf = pd.read_csv(\"..\/input\/avocado.csv\", encoding='utf-8')","2d935928":"#########################\n# show some random datapoints\n# in pandas, once you put all the file into a dataframe (df in my case), \n# you are able to use function sample(n) to extract n random samples from the dataframe\n# if the n is not given, the default value of n is 1\n#########################\ndf.sample(3)","551d6387":"######################\n# you can also use .dtypes to see the data types of each column in the dataframe\n# int: Integer\n# object: String\n# float: Float\n######################\ndf.dtypes","17257d6c":"######################\n# you can also use .info() to see if there are any null value\n######################\ndf.info()","924deeed":"######################\n# use describe() to get statistical analysis of the data\n######################\ndf.describe()","f267b5ac":"df[\"type\"].value_counts()","8120d18b":"df[\"Date\"].value_counts()","3a5fea31":"df[\"region\"].value_counts()","9e5af913":"# convert data type of the column \"Date\"\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n# sample to data points to check the content and the data type\ndf[\"Date\"].sample(2)","9d0f9a67":"# import packages \nimport seaborn as sns\nimport matplotlib.pyplot as plt","01f67003":"# set the size of the figure\nplt.figure(figsize=(16,8))\n# set the title\nplt.title(\"Distribution of the Average Price\")\n# plot the distribution\nax = sns.distplot(df[\"AveragePrice\"])","341e4083":"# set the size of the figure\nplt.figure(figsize=(16,8))\n# set the title\nplt.title(\"BoxPlot of AveragePrice\")\n# plot the boxplot\nax = sns.boxplot(df[\"AveragePrice\"])","7ea95722":"# set the size of the figure\nplt.figure(figsize=(16,8))\n# set the title\nplt.title(\"Type v.s. AveragePrice\")\n# plot Type v.s. AveragePrice\nax = sns.boxplot(y=\"type\", x=\"AveragePrice\", data=df, palette = 'pink')","df26c23b":"# conventional avocado X regions X Year\n# filter out all conventional avocado (type = conventional)\nconventional_avo = df[df[\"type\"].isin(['conventional'])]\n# sort by average price\nconventional_avo = conventional_avo.sort_values(by='AveragePrice')\n# plot\nax = sns.factorplot('AveragePrice','region',data=conventional_avo,\n                   hue='year', # category\n                   height=13,\n                   aspect=0.8,\n                   palette='muted',\n                   join=False)","abbe7b8b":"# organic avocado X regions X Year\n# filter out all organic avocado (type = organic)\norganic_avo = df[df[\"type\"].isin(['organic'])]\n# sort by average price\norganic_avo = organic_avo.sort_values(by='AveragePrice')\n# plot\nax = sns.factorplot('AveragePrice','region',data=organic_avo,\n                   hue='year', # category\n                   height=13,\n                   aspect=0.8,\n                   palette='muted',\n                   join=False)","b86a0a8a":"# plt date vs. AveragePrice\n# set the size of the figure\nplt.figure(figsize=(16,8))\n# set the title\nplt.title(\"Date v.s. AveragePrice\")\n\nax = sns.tsplot(data=df, time=\"Date\", unit=\"region\",condition=\"type\", value=\"AveragePrice\")\n","001f197c":"# Non-numerical data conversion\n# Encode type into dummy variables\n\n# convert type into dummies by separating it into 2 other columns: organic and conventional\ndummy_type = pd.get_dummies(df['type'])\n# print sample\ndummy_type.sample(2)\n# concat\ndf = pd.concat([df, dummy_type], axis=1)\nprint(df.sample(2))","5c771610":"import matplotlib.pyplot as plt\n# quick chack of column \"region\"\nregion_dict = dict(df[\"region\"].value_counts())\ny_pos = np.arange(len(region_dict))\nplt.figure(figsize=(16,18))\nplt.barh(y_pos, list(region_dict.values()), align='center', alpha=0.5)\nplt.yticks(y_pos, region_dict.keys())\nplt.xlabel('Counts')\nplt.title('Region Distribution')","26efb0a0":"len(region_dict)","81d894fe":"# covert region to categorical data\ndf['region'] = df['region'].astype('category')\ndf.dtypes","9d348dda":"df['region'] = df['region'].cat.codes\ndf['region'].sample(3)","a4ec0818":"df['Date_Q'] = df['Date'].apply(lambda x: x.quarter)","95133fe3":"df['Date_Q'].value_counts()","baa8d342":"# plot correlation martix\n# set the size of the figure\nplt.figure(figsize=(22,12))\n# set the title\nplt.title(\"Correlation Matrix\")\n\ncoe_col = ['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', \n           'year', 'organic', 'conventional', 'Date_Q', 'region']\ncm = np.corrcoef(df[coe_col].values.T)\nsns.set(font_scale = 1.7)\nax = sns.heatmap(cm,cbar = True, annot = True,square = True, fmt = '.2f', annot_kws = {'size':15}, yticklabels = coe_col, \n                 xticklabels = coe_col)","9ce06347":"df.columns","4d710b7e":"# import packages\nfrom sklearn.model_selection import train_test_split\n# split the dataframe to X and Y\nX_columns = ['Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'conventional', 'organic', \n             'Date_Q', 'year', 'region']\nX = df[X_columns]\nY = df['AveragePrice']","bd0cd9e2":"# check X and Y shape\nprint('X Shape:', X.shape)\nprint('Y Shape:', Y.shape)","2628d2b9":"# Split data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=2018)","afb0bebb":"print('X_train Shape:', X_train.shape)\nprint('X_test Shape:', X_test.shape)\nprint('y_train Shape:', y_train.shape)\nprint('y_test Shape:', y_test.shape)","fae5f976":"# import packages\n# for linear regression\nimport statsmodels.api as sm\nfrom sklearn.metrics import explained_variance_score\n# built regression function\nmodel = sm.OLS(y_train, X_train)\nres = model.fit()\nprint(res.summary())","79dd225d":"from sklearn.feature_selection import mutual_info_regression\ndependencies = mutual_info_regression(X_train, y_train)\ncolumn_list = list(X_train.columns)\nprint('Mean among dependencies of X v.s. Y', np.mean(dependencies))\nfor i in range(len(dependencies)):\n    if dependencies[i] > np.mean(dependencies):\n        print('* ', column_list[i], dependencies[i])\n    else:\n        print(column_list[i], dependencies[i])","c35fd4fb":"X_train.columns","29144633":"selected_features = ['Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'conventional', 'organic']\nX_train_sel = X_train[selected_features]","ee53185d":"model_2 = sm.OLS(y_train, X_train_sel)\nres_2 = model_2.fit()\nprint(res_2.summary())","96f6172f":"strong_relation_features = ['conventional', 'organic', 'Date_Q', 'year']\nX_train_strong = X_train[strong_relation_features]","625a78d6":"model_3 = sm.OLS(y_train, X_train_strong)\nres_3 = model_3.fit()\nprint(res_3.summary())","83fa0287":"from sklearn.feature_selection import f_regression\nf_reg = f_regression(X_train, y_train)\ncolumn_list = list(X_train.columns)\nprint('Mean of F-Regression', np.mean(f_reg[0]))\nprint('Mean of F-Regression p-value', np.mean(f_reg[1]))\nfor i in range(len(column_list)):\n    print(column_list[i],'\\t', f_reg[0][i],'\\t', f_reg[1][i])","9c70cb61":"sorted(f_reg[1])","e2b76e9f":"fre_features = ['conventional', 'organic', '4046', 'Total Volume']\nX_train_fre = X_train[fre_features]\n\nmodel_4 = sm.OLS(y_train, X_train_fre)\nres_4 = model_4.fit()\nprint(res_4.summary())","96688819":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_trian_new = scaler.fit_transform(X_train)","52e40342":"model_5 = sm.OLS(y_train, X_trian_new)\nres_5 = model_5.fit()\nprint(res_5.summary())","b8330e6e":"import xgboost\n# XGBoost Regressor\nxgb = xgboost.XGBRegressor(n_estimators=500, learning_rate=0.1, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=8)\n# fit data\nxgb.fit(X_train,y_train)","a35e06a1":"predictions = xgb.predict(X_test)\nprint(explained_variance_score(predictions,y_test))","9fb7eb53":"# Calculate R-squared\nresiduals = y_test - predictions\nRMSE = np.sqrt(np.mean(residuals**2))\ny_test_mean = np.mean(y_test)\ntss =  np.sum((y_test - y_test_mean)**2 ) # total sum of square\nrss =  np.sum(residuals**2) # sum of residuals\nrsq  =  1 - (rss\/tss)\nprint('R^2 of XGBoost', rsq)","94cab43d":"# Data Discription","5e4677c4":"### Convert type into dummies","24d16eed":"### Step 1. Read data\nOnce you imported the package-Pandas, you'll be able to use all the functions under this pacakge. The very first function you should use to get the data from the csv file is definitely read_csv().","c6bbd51f":"### Convert region into catrgorical data","43cb3775":"### Feature Selection","36a8dd47":"## Regression Model","8ac32252":"### Step 2. Simple Data Exploratory with Pandas\nFor example, by sample(n), you can randomly choose n samples from the dataframe (df). If the n is not given, the default value would be 1.","d33232e9":"#### Mutual_info_regression\n\nConclusion: The performance is not as good as the baseline.","fc9a5ef5":"### Re-scale data\nConclusion: Not as good as the baseline","e3085a78":"# Import packages","ad5f241a":"## Data Conversion","863d7900":"# Based on the R^2 results, XGBoost model is the winning solution!","1fd226f7":"### Feature Selection based on baseline model\n\nConclusion: Not as good as baseline","764039eb":"## Using XGBoost","0896627a":"## Convert Datatime into quarters","7607e139":"# Building Models"}}