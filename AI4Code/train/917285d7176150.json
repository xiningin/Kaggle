{"cell_type":{"01d02051":"code","d90bdb16":"code","458b3c3b":"code","ce6fdbba":"code","9302c128":"code","a5b3c100":"code","ce4ea2a4":"code","a820b608":"code","1ae5bab7":"code","81f94156":"code","ee5d1e24":"code","62798761":"code","08097755":"code","088ff249":"code","875525ac":"code","3323bc58":"code","2097c87d":"code","51519adc":"code","9d11b8cb":"code","c8d72218":"code","c8aa7eee":"code","6b4703cf":"code","57f60581":"code","8d4309ef":"code","80037799":"code","669ecb71":"code","7ad26e4a":"code","526c41e9":"code","872fe6f6":"code","f72de2ac":"code","47edae24":"code","716af432":"code","3db64176":"code","dcd46a62":"code","6a914860":"code","0698a82a":"code","3fe7ca94":"code","93e26258":"code","19fe84aa":"code","1312f16b":"code","722db18d":"code","1a153581":"code","a2dba977":"code","8566d148":"code","da07a865":"code","7ceab526":"code","529cb243":"code","cd0e48c3":"code","5e460e60":"code","0827eaf0":"code","a55b4f1f":"code","26c1964c":"code","4ff59329":"code","74e46a3a":"code","4ae12268":"code","118c63e6":"code","0d14fd28":"code","ae7237fe":"code","7fc98536":"code","d9c44e11":"code","5e5e84b2":"code","45f5c6e0":"code","621b59b5":"markdown","37d7ca9d":"markdown","9a89e3b4":"markdown","e8e8e4bf":"markdown","130bf56e":"markdown","3cbff038":"markdown","f8d5bfd9":"markdown","f6422c7b":"markdown","555d8706":"markdown","57f7fafb":"markdown","f1879a7a":"markdown","d2923c91":"markdown","62b5f49f":"markdown","cf303cae":"markdown","6e49ce7d":"markdown","4902c0c0":"markdown","9edaaecc":"markdown","ec1f5663":"markdown","db8af626":"markdown","30d81ef2":"markdown"},"source":{"01d02051":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\nnum_classes = 10\nepochs = 20","d90bdb16":"train_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv',sep=',')\ntest_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv', sep = ',')","458b3c3b":"train_df.head()","ce6fdbba":"test_df.head()","9302c128":"train_data = np.array(train_df, dtype = 'float32')","a5b3c100":"test_data = np.array(test_df, dtype='float32')","ce4ea2a4":"x_train = train_data[:,1:]\/255\n\ny_train = train_data[:,0]\n\nx_test= test_data[:,1:]\/255\n\ny_test=test_data[:,0]","a820b608":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","1ae5bab7":"class_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nplt.figure(figsize=(10, 10))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    label_index = int(y_train[i])\n    plt.title(class_names[label_index])\nplt.show()","81f94156":"W_grid = 15\nL_grid = 15\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (16,16))\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\nn_train = len(train_data) # get the length of the train dataset\n\n# Select a random number from 0 to n_train\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_train)\n    # read and display an image with the selected index    \n    axes[i].imshow( train_data[index,1:].reshape((28,28)) )\n    labelindex = int(train_data[index,0])\n    axes[i].set_title(class_names[labelindex], fontsize = 9)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.3)","ee5d1e24":"image_rows = 28\nimage_cols = 28\nbatch_size = 4096\nimage_shape = (image_rows,image_cols,1) ","62798761":"x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\nx_validate = x_validate.reshape(x_validate.shape[0],*image_shape)","08097755":"dnn_model = keras.models.Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Dropout(0.2),\n    Flatten(), # flatten out the layers\n    keras.layers.BatchNormalization(),\n    Dense(800,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(400,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(200,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(100,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(50,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(10,activation = 'softmax')    \n    ])","088ff249":"dnn_model.summary()","875525ac":"dnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","3323bc58":"history = dnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","2097c87d":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['acc'], label='Accuracy')\nplt.plot(history.history['val_acc'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","51519adc":"score = dnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","9d11b8cb":"cnn_model_1 = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Flatten(), # flatten out the layers\n    #keras.layers.BatchNormalization(),\n    Dense(300,activation='relu'),\n    #keras.layers.BatchNormalization(),\n    Dense(100,activation='relu'),\n    #keras.layers.BatchNormalization(),\n    Dense(10,activation = 'softmax')\n    \n])","c8d72218":"cnn_model_2 = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='elu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Flatten(), # flatten out the layers\n    #keras.layers.BatchNormalization(),\n    Dense(300,activation='elu'),\n    #keras.layers.BatchNormalization(),\n    Dense(100,activation='elu'),\n    #keras.layers.BatchNormalization(),\n    Dense(10,activation = 'softmax')\n    \n])","c8aa7eee":"cnn_model_3 = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='selu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Flatten(), # flatten out the layers\n    #keras.layers.BatchNormalization(),\n    Dense(300,activation='selu'),\n    #keras.layers.BatchNormalization(),\n    Dense(100,activation='selu'),\n    #keras.layers.BatchNormalization(),\n    Dense(10,activation = 'softmax')\n    \n])","6b4703cf":"cnn_model = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Dropout(0.2),\n    Flatten(), # flatten out the layers\n    keras.layers.BatchNormalization(),\n    Dense(300,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(100,activation='relu'),\n    Dropout(0.25),\n    keras.layers.BatchNormalization(),\n    Dense(10,activation = 'softmax')    \n])","57f60581":"\n\ncnn_model = keras.models.Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Flatten()])\n\n#input_ = keras.layers.Input(shape=image_shape)\nhidden1 = keras.layers.Dense(300, activation=\"relu\")\nhidden2 = keras.layers.Dense(100, activation=\"relu\")(hidden1)\nconcat = keras.layers.concatenate([input_, hidden2])\noutput = keras.layers.Dense(1)(concat)\n\ncnn_model.add(input_)\ncnn_model.add(hidden1)\ncnn_model.add(hidden2)\ncnn_model.add(concat)\ncnn_model.add(output)\n#output2= keras.layers.Dense(10,activation=\"softmax\")(output)\n#cnn_model = keras.models.Model(inputs=[input_], outputs=[output2])","8d4309ef":"cnn_model.summary()","80037799":"cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","669ecb71":"cnn_model_1.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])\ncnn_model_2.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])\ncnn_model_3.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","7ad26e4a":"history = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","526c41e9":"history_1 = cnn_model_1.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)\nhistory_2 = cnn_model_2.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)\nhistory_3 = cnn_model_3.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","872fe6f6":"history.params","f72de2ac":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history_1.history['loss'], label='relu Loss')\nplt.plot(history_2.history['loss'], label='elu Loss')\nplt.plot(history_3.history['loss'], label='selu Loss')\nplt.legend()\nplt.title('Train - Loss')\n\nplt.subplot(2, 2, 2)\nplt.plot(history_1.history['val_loss'], label='relu Val Loss')\nplt.plot(history_2.history['val_loss'], label='elu Val Loss')\nplt.plot(history_3.history['val_loss'], label='selu Val Loss')\nplt.legend()\nplt.title('Validation - Loss')\n\nplt.subplot(2, 2, 3)\nplt.plot(history_1.history['acc'], label='relu Accuracy')\nplt.plot(history_2.history['acc'], label='elu Accuracy')\nplt.plot(history_3.history['acc'], label='selu Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')\n\nplt.subplot(2, 2, 4)\nplt.plot(history_1.history['val_acc'], label='relu Val Accuracy')\nplt.plot(history_2.history['val_acc'], label='elu Val Accuracy')\nplt.plot(history_3.history['val_acc'], label='selu Val Accuracy')\nplt.legend()\nplt.title('Validation - Accuracy')","47edae24":"score = cnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","716af432":"score_1 = cnn_model_1.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss relu : {:.4f}'.format(score_1[0]))\nprint('Test Accuracy relu : {:.4f}'.format(score_1[1]))\nprint()\nscore_2 = cnn_model_2.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss elu : {:.4f}'.format(score_2[0]))\nprint('Test Accuracy elu : {:.4f}'.format(score_2[1]))\nprint()\nscore_3 = cnn_model_3.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss selu : {:.4f}'.format(score_3[0]))\nprint('Test Accuracy selu : {:.4f}'.format(score_3[1]))\nprint()","3db64176":"import matplotlib.pyplot as plt\n%matplotlib inline\naccuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and Validation loss')\nplt.legend()","dcd46a62":"cnn_model.evaluate(x_test,y_test)","6a914860":"x_new=x_test[:3]\ny_proba=cnn_model.predict(x_new)\ny_proba.round(2)","0698a82a":"y_pred=cnn_model.predict_classes(x_new)\ny_pred\nnp.array(class_names)[y_pred]","3fe7ca94":"#Get the predictions for the test data\npredicted_classes = cnn_model.predict_classes(x_test)\n#Get the indices to be plotted\ny_true = test_df.iloc[:, 0]\ncorrect = np.nonzero(predicted_classes==y_true)[0]\nincorrect = np.nonzero(predicted_classes!=y_true)[0]\nfrom sklearn.metrics import classification_report\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(y_true, predicted_classes, target_names=target_names))","93e26258":"L = 5\nW = 5\nfig, axes = plt.subplots(L, W, figsize = (12,12))\naxes = axes.ravel()\n\nfor i in np.arange(0, L * W):  \n    axes[i].imshow(x_test[i].reshape(28,28))\n    axes[i].set_title(f\"Prediction Class = {predicted_classes[i]:0.1f}\\n Original Class = {y_test[i]:0.1f}\")\n    axes[i].axis('off')\n\nplt.subplots_adjust(wspace=0.5)","19fe84aa":"#from __future__ import print_function\n\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\n\nk_range = range(1,10)\nk_scores = []\n\nfor k in k_range:\n    print('k ========================= %f' % k)\n    knn = KNeighborsClassifier(n_neighbors=k, algorithm='auto', weights='distance', n_jobs=1)\n    # \u4ea4\u53c9\u9a8c\u8bc1\n    # loss = -cross_val_score(knn, X, y, cv=10, scoring='mean_squared_error') # for regression\n    # scores = cross_val_score(knn, X, y, cv=4,scoring='accuracy') # for classification\n    knn.fit(x_train,y_train)\n    predict = knn.predict(x_test)\n    accuracy = metrics.accuracy_score(y_test, predict)\n    k_scores.append(accuracy)\n    \nplt.figure()\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","1312f16b":"x_train","722db18d":"#from __future__ import print_function\n\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nk=6\n#k_scores = []\n\nprint('k ========================= %f' % k)\nknn = KNeighborsClassifier(n_neighbors=k, algorithm='auto', weights='distance', n_jobs=1)\n\n# \u4ea4\u53c9\u9a8c\u8bc1\n#loss = -cross_val_score(knn, train_data[:,1:]\/255 , train_data[:,0], cv=10, scoring='mean_squared_error') # for regression\n#scores = cross_val_score(knn, train_data[:,1:]\/255 , train_data[:,0], cv=5,  scoring='accuracy') # for classification\n\nknn.fit(x_train,y_train)\npredict = knn.predict(x_test)\naccuracy = metrics.accuracy_score(y_test, predict)\n#k_scores.append(accuracy)\n    \n#plt.figure()\n#plt.plot(k_range, k_scores)\n#plt.xlabel('Value of K for KNN')\n#plt.ylabel('Cross-Validated Accuracy')\n#plt.show()\n\n#print('Test Loss : {:.4f}'.format(loss))\nprint('Test Accuracy : {:.4f}'.format(accuracy))","1a153581":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(knn, train_data[:,1:]\/255 , train_data[:,0], cv=5,  scoring='accuracy') # for classification\nprint(scores)\nprint(scores.mean())","a2dba977":"plt.figure(figsize=(15, 10))\nplt.plot(scores, label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","8566d148":"import xgboost as xgb\n\nmodel = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=100, silent=False, objective='multi:softmax')\nmodel.fit(x_train,y_train)\n\npredict = model.predict(x_test)\naccuracy = metrics.accuracy_score(y_test, predict)\n#k_scores.append(accuracy)\n    \n#print('Test Loss : {:.4f}'.format(loss))\nprint('Test Accuracy : {:.4f}'.format(accuracy))\n","da07a865":"from sklearn import metrics\n\naccuracy = metrics.accuracy_score(y_test, predict)\n#k_scores.append(accuracy)\n    \n#print('Test Loss : {:.4f}'.format(loss))\nprint('Test Accuracy : {:.4f}'.format(accuracy))\n","7ceab526":"model","529cb243":"print('Test Accuracy : {:.4f}'.format(accuracy))","cd0e48c3":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, train_data[:,1:]\/255 , train_data[:,0], cv=5,  scoring='accuracy') # for classification\nprint(scoresprint(scores.mean())","5e460e60":"print(scores.round(4))\nprint('Validation Accuracy : {:.4f}'.format(scores.mean()))","0827eaf0":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\n\nn = range(1,6,1)\nmean=[scores.mean(),scores.mean(),scores.mean(),scores.mean(),scores.mean()]\nplt.plot(n, scores, label='Validation Acc')\nplt.plot(n, mean, label='Mean Acc')\nplt.xlabel('Value of n for CV')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy')\nplt.legend()\nplt.show()","a55b4f1f":"from sklearn.tree import DecisionTreeClassifier\n\n# Create the classifier\ndecision_tree_classifier = DecisionTreeClassifier()\n\n# Train the classifier on the training set\ndecision_tree_classifier.fit(x_train, y_train)\n\n# Validate the classifier on the testing set using classification accuracy\npredict=decision_tree_classifier.predict(x_test)\naccuracy = metrics.accuracy_score(y_test, predict)\n#k_scores.append(accuracy)\n    \n#print('Test Loss : {:.4f}'.format(loss))\nprint('Test Accuracy : {:.4f}'.format(accuracy))","26c1964c":"decision_tree_classifier","4ff59329":"from sklearn.model_selection import cross_val_score\n\n#decision_tree_classifier = DecisionTreeClassifier()\nc_scores = cross_val_score(decision_tree_classifier, train_data[:,1:]\/255 , train_data[:,0], cv=5,  scoring='accuracy')\n\nprint(c_scores.round(4))\nprint('Validation Accuracy : {:.4f}'.format(c_scores.mean()))","74e46a3a":"print(cv_scores.round(4))\nprint('Validation Accuracy : {:.4f}'.format(cv_scores.mean()))","4ae12268":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\n\nn = range(1,6,1)\ncv_mean=[cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean()]\nplt.plot(n, cv_scores, label='Validation Acc')\nplt.plot(n, cv_mean, label='Mean Acc')\nplt.xlabel('Value of n for CV')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy')\nplt.legend()\nplt.show()","118c63e6":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\n\nn = range(1,6,1)\nmean=[scores.mean(),scores.mean(),scores.mean(),scores.mean(),scores.mean()]\ncv_mean=[cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean()]\nplt.plot(n, cv_scores, label='DT Val Acc')\nplt.plot(n, scores, label='XGB Val Acc')\n#plt.plot(n, cv_mean, label='DT Mean Acc')\n#plt.plot(n, mean, label='XGB Mean Acc')\nplt.xlabel('Value of n for CV')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy')\nplt.legend()\nplt.show()\n","0d14fd28":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection  import GridSearchCV\n\nrandom_forest_classifier = RandomForestClassifier(n_estimators=10)\n\nrandom_forest_classifier.fit(x_train, y_train)\n\npredict=random_forest_classifier.predict(x_test)\naccuracy = metrics.accuracy_score(y_test, predict)\n#k_scores.append(accuracy)\n    \n#print('Test Loss : {:.4f}'.format(loss))\nprint('Test Accuracy : {:.4f}'.format(accuracy))","ae7237fe":"random_forest_classifier","7fc98536":"from sklearn.model_selection import cross_val_score\n\n#decision_tree_classifier = DecisionTreeClassifier()\ncv_scores = cross_val_score(random_forest_classifier, train_data[:,1:]\/255 , train_data[:,0], cv=5,  scoring='accuracy')\n\nprint(cv_scores.round(4))\nprint('Validation Accuracy : {:.4f}'.format(cv_scores.mean()))","d9c44e11":"print(cv_scores.round(4))\nprint('Validation Accuracy : {:.4f}'.format(cv_scores.mean()))","5e5e84b2":"plt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\n\nn = range(1,6,1)\ncv_mean=[cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean()]\nplt.plot(n, cv_scores, label='Validation Acc')\nplt.plot(n, cv_mean, label='Mean Acc')\nplt.xlabel('Value of n for CV')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy')\nplt.legend()\nplt.show()","45f5c6e0":"plt.figure(figsize=(8,5))\n\nn = range(1,6,1)\nmean=[scores.mean(),scores.mean(),scores.mean(),scores.mean(),scores.mean()]\nc_mean=[c_scores.mean(),c_scores.mean(),c_scores.mean(),c_scores.mean(),c_scores.mean()]\ncv_mean=[cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean(),cv_scores.mean()]\n\nplt.plot(n, scores, label='XGB Val Acc')\nplt.plot(n, cv_scores, label='RF Val Acc')\nplt.plot(n, c_scores, label='DT Val Acc')\n\nplt.plot(n, mean)\nplt.plot(n, cv_mean)\nplt.plot(n, c_mean)\n\nplt.xlabel('Value of n for CV')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy')\n\nplt.legend()\nplt.show()\n","621b59b5":"#### Define the model \n\nThe first layer in model network, keras.layers.Flatten, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). This layer unstacks rows of pixels in the image and lining them up and has no parameters to learn; it only reformats the data.\n\nAfter the pixels are flattened, the network consists of a sequence of two keras.layers.Dense layers. These are densely connected, or fully connected, neural layers. The first Dense layer has 32 nodes (or neurons). The second (and last) layer is a 10-node softmax layer that returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.","37d7ca9d":"#### Train Model:\nTraining the neural network model requires the following steps:\n\n* Feed the training data to the model. In this example, the training data is in the x_train and y_train arrays.\n* The model learns to associate images and labels.\n* You ask the model to make predictions about a test set\u2014in this example, the x_test array. Verify that the predictions match the labels from the y_test array.\n\nTo start training, call the model.fit method\u2014so called because it \"fits\" the model to the training data:","9a89e3b4":"\nLet's plot training and validation accuracy as well as loss.","e8e8e4bf":"**Create dataframes for train and test datasets**","130bf56e":"It's apparent that our classifier is underperforming for class 6 in terms of both precision and recall. For class 2, classifier is slightly lacking precision whereas it is slightly lacking recall (i.e. missed) for class 4.\n\nPerhaps we would gain more insight after visualizing the correct and incorrect predictions.\n\nLet us examine the test label and check if it the right classification or not.","3cbff038":"Let us plot the Training Accuracy vs Loss to get a better understanding of the model training.","f8d5bfd9":"Now we need to do more formating on the x_train,x_test and x_validate sets.","f6422c7b":"- #### Evaluate \/Score the model","555d8706":"Now we are gonna split the training data into validation and actual training data for training the model and testing it using the validation set. This is achieved using the train_test_split method of scikit learn library.","57f7fafb":"As you can observe above the shape of shoe from the sample image\n\n### Create the Convolutional Neural Networks (CNN)\n\n#### Define model\n\n#### Compile model\n\n#### Train model\n\nFirst of all let us define the shape of the image before we define the model. Defined the shape of the image as 3d with rows and columns and 1 for the 3d visualisation\n","f1879a7a":"### I hope you had a good understanding of CNN Model and its usage in practice using Fashion MNIST dataset.\n\n# Please do share your comments\/suggestions and if you like this  kernel appreciate to UPVOTE.\n\nI recently created few useful kernels like below which might be of great interest to you in your data science work .Do visit them and share your thoughts\/comments\/upvote.","d2923c91":"### Classification Report\nWe can summarize the performance of our classifier as follows","62b5f49f":"Now it is observed that the first column is the label data and because it has 10 classes so it is going to have from 0 to 9.The remaining columns are the actual pixel data.Here as you can see there are about 784 columns that contain pixel data.\nHere each row is a different image representation in the form pixel data.\n\nNow let us split the train data into x and y arrays where x represents the image data and y represents the labels.\n\nTo do that we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras.","cf303cae":"Labels\nEach training and test example is assigned to one of the following labels as shown below:\n\n* 0 T-shirt\/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot\n\nI think the best way is to visualise the above 10 types of classes to get a feel of what these items look like :) .So let us visualise\n","6e49ce7d":"Now let us visualise the some samples after the resize of the data which needs to be ready for train the network .\n","4902c0c0":"Now let us slice the train arrays into x and y arrays namely x_train,y_train to store all image data and label data respectively.\ni.e \n\n- x_train contains all the rows and all columns except the label column and excluding header info .\n- y_train contains all the rows and first column and excluding header info .\n\n\nSimilarly slice the test arrays into x and y arrays namely x_train,y_train to store all image data and label data respectively.\ni.e \n\n- x_test contains all the rows and all columns except the label column and excluding header info .\n- y_test contains all the rows and first column and excluding header info .\n\n####  Important Note : Since the image data in x_train and x_test is from 0 to 255 ,  we need to rescale this from 0 to 1.To do this we need to divide the x_train and x_test by 255 . It's important that the training set and the testing set be preprocessed in the same way:","9edaaecc":"#### Compile the model\n\nBefore the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n\n* Loss function \u2014This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.Here we will use \"sparse_categorical_crossentropy\"\n* Optimizer \u2014This is how the model is updated based on the data it sees and its loss function.\n* Metrics \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.","ec1f5663":"Similarly let us do the same process for test data","db8af626":"### Results\n\n","30d81ef2":"Let us explore the train and test data"}}