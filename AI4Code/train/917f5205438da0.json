{"cell_type":{"e19f822e":"code","809c27d9":"code","da6da912":"code","cc21c70e":"code","326d09b9":"code","90cbc521":"code","3b53d500":"code","ede7a131":"code","5f022b40":"code","bf5c5eca":"code","be8a52a2":"code","bf0e02c8":"code","fa14485e":"code","60ccc8ec":"code","5b4e2a2e":"markdown","352109ee":"markdown","6ce0e955":"markdown","cb92212b":"markdown","17cf46c5":"markdown","6920513c":"markdown","26ea6a2a":"markdown","369f8c4b":"markdown","38974589":"markdown"},"source":{"e19f822e":"from keras.losses import binary_crossentropy, categorical_crossentropy\nimport keras.backend as K\nimport numpy as np\nfrom prettytable import PrettyTable\nfrom prettytable import ALL\nfrom sklearn.metrics import f1_score\nfrom matplotlib import pyplot as plt","809c27d9":"# ground truth\nY = np.zeros((5,2))\n# first label is assigned to 20 % of observations\nY[0,0] = 1\n# second label is assigned to 80 % of observations\nY[0:4,1] = 1\n\n# ground truth with shape (BATCH_SIZE, NO_OF_LABELS)\nprint(Y)","da6da912":"first = {}\n\nfor TP in range(2): # TP can be 0..1\n    for FP in reversed(range(5)): # FP can be 0..4\n        idx = TP*5+(4-FP)\n        name = 'TP' + str(TP) + 'FP' + str(FP)\n        Yhat1 = np.zeros(5)\n        Yhat1[0:TP] = 1\n        Yhat1[5-FP:] = 1\n        first.update({name: Yhat1})\n\nsecond = {}\n\nfor TP in range(5): # TP can be 0..4\n    for FP in reversed(range(2)): # FP can be 0..1\n        idx = TP*5+(4-FP)\n        name = 'TP' + str(TP) + 'FP' + str(FP)\n        Yhat2 = np.zeros(5)\n        Yhat2[0:TP] = 1\n        Yhat2[5-FP:] = 1\n        second.update({name: Yhat2})","cc21c70e":"t = PrettyTable(['1st\/2nd']+list(first.keys()))\npltX = []\npltY = []\n\nfor name2,data2 in second.items():\n\n    row = [name2]\n    for name1,data1 in first.items():\n        data = np.stack((data1, data2), axis=1)\n        loss = np.mean(K.eval(binary_crossentropy(K.variable(Y), K.variable(data))))\n        f1 = f1_score(Y, data, average='macro')\n        pltX.append(loss)\n        pltY.append(f1)\n        row.append('{:2f}\\n{:2f}'.format(loss, f1))\n    t.add_row(row)\n\n","326d09b9":"print('Displaying result')\nprint('Columns = prediction for first label (20 % of 1s in ground truth)')\nprint('Rows = prediction for second label (80 % of 1s in ground truth)')\nprint('Cell = 1st number binary_crossentropy loss, 2nd number macro F1-score')\nprint('')\nt.hrules = ALL\nprint(t)","90cbc521":"plt.scatter(pltX, pltY)\nplt.ylabel('Macro F1-score')\nplt.xlabel('Binary crossentropy loss')\nplt.show()","3b53d500":"t = PrettyTable(['2nd\\1st']+list(first.keys()))\npltX = []\npltY = []\n\nfor name2,data2 in second.items():\n\n    row = [name2]\n    for name1,data1 in first.items():\n        data = np.stack((data1, data2), axis=1)\n        # nan -> 0 this is dubious, is that correct? \n        loss = np.mean(np.nan_to_num(K.eval(categorical_crossentropy(K.variable(Y), K.variable(data)))))\n        f1 = f1_score(Y, data, average='macro')\n        pltX.append(loss)\n        pltY.append(f1)\n        row.append('{:2f}\\n{:2f}'.format(loss, f1))\n    t.add_row(row)","ede7a131":"print('Displaying result')\nprint('Columns = prediction for first label (20 % of 1s in ground truth)')\nprint('Rows = prediction for second label (80 % of 1s in ground truth)')\nprint('Cell = 1st number categorical_crossentropy loss, 2nd number macro F1-score')\nprint('')\nt.hrules = ALL\nprint(t)","5f022b40":"plt.scatter(pltX, pltY)\nplt.ylabel('Macro F1-score')\nplt.xlabel('Categorical crossentropy loss')\nplt.show()","bf5c5eca":"import tensorflow as tf\n\ndef f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef f1_loss(y_true, y_pred):\n    \n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - K.mean(f1)","be8a52a2":"from keras.layers import Dense\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(2, input_dim=2, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss=f1_loss, metrics=['accuracy', f1])\nmodel.summary()","bf0e02c8":"t = PrettyTable(['1st\/2nd']+list(first.keys()))\npltX = []\npltY = []\n\nfor name2,data2 in second.items():\n\n    row = [name2]\n    for name1,data1 in first.items():\n        data = np.stack((data1, data2), axis=1)\n        loss = K.eval(f1_loss(Y, data))\n        f1 = f1_score(Y, data, average='macro')\n        pltX.append(loss)\n        pltY.append(f1)\n        row.append('{:2f}\\n{:2f}'.format(loss, f1))\n    t.add_row(row)","fa14485e":"print('Displaying result')\nprint('Columns = prediction for first label (20 % of 1s in ground truth)')\nprint('Rows = prediction for second label (80 % of 1s in ground truth)')\nprint('Cell = 1st number focal loss, 2nd number macro F1-score')\nprint('')\nt.hrules = ALL\nprint(t)","60ccc8ec":"plt.scatter(pltX, pltY)\nplt.ylabel('Macro F1-score')\nplt.xlabel('Differentiable F1 loss')\nplt.show()","5b4e2a2e":"Let's define the ground truth with 2 possible labels. First label is in 20 % of cases, second label in 80 % of cases. We make 5 observations to make it simple.","352109ee":"Now the results are not any better.","6ce0e955":"# Optimal loss function - macro F1 score","cb92212b":"You might notice, that binary crossentropy loss is not performing very well. Let's study, why's that and look for other possibilities.","17cf46c5":"The best loss function would be, of course the metric itself. Then the misalignment disappears.\nThe macro F1-score has one big trouble. It's non-differentiable. Which means we cannot use it as a loss function.\n\nBut we can modify it to be differentiable. Instead of accepting 0\/1 integer predictions, let's accept probabilities instead. Thus if the ground truth is 1 and the model prediction is 0.4, we calculate it as 0.4 true positive and 0.6 false negative. If the ground truth is 0 and the model prediction is 0.4, we calculate it as 0.6 true negative and 0.4 false positive.\n\nAlso, we minimize 1-F1 (because minimizing $1-f(x)$ is same as maximizing $f(x)$)\n\nI took the function in [this great Kernel](https:\/\/www.kaggle.com\/guglielmocamporese\/macro-f1-score-keras) and took the liberty to modify it:","6920513c":"# Binary crossentropy\nThis is the standard logloss.\nLet's calculate binary crossentropy loss for all the possibilities and compare them with macro F1-score.","26ea6a2a":"Let's calculate all the possible predictions for the first and second label. For first, you can have 0 or 1 true positive and 0, 1, 2, 3 or 4 false positives.\nFor second, you can have 0, 1, 2, 3 or 4 true positives and 0 or 1 false positives.","369f8c4b":"# Crosscategorical entropy\nFor multilabel problem, crosscategorical entropy is not recommended as well. From keras documenation: \n\n> when using the categorical_crossentropy loss, your targets should be in categorical format (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except for a 1 at the index corresponding to the class of the sample). \n\nUsing crosscategorical entropy is therefore not optimal from theoretical point of view. In practice, however, it may still work. Let's have a look.","38974589":"**This does not look good at all!** To maximize our metric we need a loss function, that is aligned with the metric. Here we can see many examples, when loss differs while the metric stays same (see first 5 columns). And also example when loss is same and a metric differs (see the last column of first row vs pre-last columns of the second row).\nThis misalignment between a loss function and a metric can lead to the suboptimal convergence."}}