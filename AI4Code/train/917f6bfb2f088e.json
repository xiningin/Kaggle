{"cell_type":{"b0115501":"code","366ab783":"code","79047185":"code","5d65141b":"code","456b0592":"code","ef573daa":"code","da3bf8a1":"code","a7307191":"code","ed00f275":"code","a3f23998":"code","8104225e":"code","29af1487":"code","4adc9262":"code","e0edc431":"code","a405042b":"code","544f2550":"code","0d44f590":"code","6971fc82":"code","786e58d6":"code","6e6a4473":"code","339069cd":"code","30542731":"markdown","3cb356de":"markdown","543c3ec4":"markdown","5250ec2b":"markdown","67c4630d":"markdown","3565a50a":"markdown","9effef42":"markdown","bab184d4":"markdown","cb746292":"markdown","9ff11f3e":"markdown","ce6c6f72":"markdown","9bad9014":"markdown","69b8b5dd":"markdown","47e9869d":"markdown"},"source":{"b0115501":"import os\nimport numpy as np\nimport pandas as pd\n\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\n\nfrom tensorflow.keras.applications import DenseNet121\n\nimport cv2\nfrom IPython.display import SVG\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","366ab783":"TRAIN_PATH = '..\/input\/fruits\/fruits-360\/Training'\nTEST_PATH = '..\/input\/fruits\/fruits-360\/Test'\nTRAIN_FOLDERS = np.sort(os.listdir(TRAIN_PATH))\nTEST_FOLDERS = np.sort(os.listdir(TEST_PATH))\n\n# Working on 10 fruits only (130 varities will take a long time to train)\nTRAIN_FOLDERS = np.array(pd.DataFrame(TRAIN_FOLDERS).sample(10)).reshape(-1)\n\nTEST_FOLDERS = TRAIN_FOLDERS","79047185":"print(TRAIN_FOLDERS)","5d65141b":"## Creating an array of one sample of each type of fruit\n\ntrain_images = []\n\npath_root = '..\/input\/fruits\/fruits-360\/Test\/'\nfor fruit_name in TEST_FOLDERS:\n    images = os.listdir(path_root + fruit_name)[:1]\n    for file_name in images:\n        image_path = path_root+fruit_name+'\/'+file_name\n        \n        image = cv2.imread(image_path)\n        train_images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        \ntrain_images = np.array(train_images)","456b0592":"def display_images():\n    rows, col = 2, 5\n    #rows, col = 2, 2\n    fig = plt.figure(figsize=(15,7))\n    for index, image in enumerate(train_images):\n        ax = fig.add_subplot(rows, col, index+1)\n        ax.imshow(train_images[index])\n        ax.set_title(TRAIN_FOLDERS[index])\n        ax.axis('off')\n        \n    plt.show()\n    \ndisplay_images()","ef573daa":"train_labels = []\ntest_labels = []\n\ndef generate_train_labels():\n    for fruit_name in TRAIN_FOLDERS:\n        images = os.listdir('..\/input\/fruits\/fruits-360\/Training\/'+fruit_name)\n        for image in range(len(images)):\n            train_labels.append(fruit_name)\n            \ndef generate_test_labels():\n    for fruit_name in TEST_FOLDERS:\n        images = os.listdir('..\/input\/fruits\/fruits-360\/Test\/'+fruit_name)\n        for image in range(len(images)):\n            test_labels.append(fruit_name)\n\ngenerate_train_labels()\ngenerate_test_labels()\n\ntrain_labels = pd.get_dummies(train_labels)\ntest_labels = pd.get_dummies(test_labels)\n\nlabels = train_labels\n\ntrain_labels = np.float32(train_labels[list(TRAIN_FOLDERS)].values)\ntest_labels = np.float32(test_labels[list(TEST_FOLDERS)].values)\n\ntrain_labels[:3]","da3bf8a1":"fig = go.Figure(\n                [go.Pie(labels=TRAIN_FOLDERS, \n                        values=labels.sum().values,\n                        marker=dict(colors=['#026416','#C73104','#C05209','#6F2F05']))\n                ])\n\nfig.update_layout(width=900, height=400, title= {'text': \"Fruit Categories Distribution\",\n                                                'y':0.95,'x':0.43,\n                                                'xanchor': 'center','yanchor': 'top'},\n                 margin = dict(l=50, r=10, t=50, b=30))","a7307191":"GCS_PATH = KaggleDatasets().get_gcs_path()\n\ntest_path = []\ntrain_path = []\n\ndef generate_test_path():\n    path_root = GCS_PATH + '\/fruits-360\/Test\/'\n    for fruit_name in TEST_FOLDERS:\n        images = os.listdir('..\/input\/fruits\/fruits-360\/Test\/'+fruit_name)\n        for image in images:\n            test_path.append(path_root+fruit_name+'\/'+image)\n\ndef generate_train_path():\n    path_root = GCS_PATH + '\/fruits-360\/Training\/'\n    for fruit_name in TRAIN_FOLDERS:\n        images = os.listdir('..\/input\/fruits\/fruits-360\/Training\/'+fruit_name)\n        for image in images:\n            train_path.append(path_root+fruit_name+'\/'+image)\n            \ngenerate_train_path()\ngenerate_test_path()","ed00f275":"train_path[:2]","a3f23998":"print('Train :')\nprint('   Labels')\nprint('   ',train_labels.shape)\nprint('   Images')\nprint('   ',len(train_path))\nprint('')\nprint('Test :')\nprint('   Labels')\nprint('   ',test_labels.shape)\nprint('   Images')\nprint('   ',len(test_path))","8104225e":"def decode_image(filename, label):\n    image_size = (512,512)\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    return image, label\n\ndef augment_image(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    return image, label","29af1487":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n\n# instantiate a distribution strategy\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","4adc9262":"AUTO = tf.data.experimental.AUTOTUNE\n\ntrain_dataset = (\n        tf.data.Dataset\\\n        .from_tensor_slices((train_path, train_labels))\\\n        .map(decode_image, num_parallel_calls=AUTO)\\\n        .map(augment_image, num_parallel_calls=AUTO)\\\n        .repeat()\\\n        .shuffle(512)\\\n        .batch(BATCH_SIZE)\\\n        .prefetch(AUTO)\\\n        )\n\ntest_dataset = (\n    tf.data.Dataset\\\n    .from_tensor_slices((test_path, test_labels))\\\n    .map(decode_image, num_parallel_calls=AUTO)\\\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","e0edc431":"with strategy.scope():\n    model = tf.keras.models.Sequential()\n\n    model.add(DenseNet121(\n                     input_shape=(512,512,3),\n                     weights = 'imagenet',\n                     include_top=False))\n\n    model.add(tf.keras.layers.GlobalAveragePooling2D())\n\n    model.add(tf.keras.layers.Dense(train_labels.shape[1],\n                                   activation='softmax'))\n\n    model.compile(optimizer='adam', \n                 loss='categorical_crossentropy',\n                 metrics=['categorical_accuracy'])\n","a405042b":"# Learning rate scheduler\n\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\ncallbacks_list = [lr_schedule]\nSTEPS_PER_EPOCH = train_labels.shape[0]\/\/BATCH_SIZE","544f2550":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","0d44f590":"history = model.fit(train_dataset,\n                    epochs = 10,\n                    callbacks = callbacks_list,\n                    steps_per_epoch = STEPS_PER_EPOCH,\n                    validation_data = test_dataset)","6971fc82":"EPOCHS = 10\ndef display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","786e58d6":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","6e6a4473":"acc_df = pd.DataFrame(np.transpose([[*np.arange(1, EPOCHS+1).tolist()*3], [\"Train\"]*EPOCHS + [\"Val\"]*EPOCHS + [\"Benchmark\"]*EPOCHS,\n                                     history.history['categorical_accuracy'] + history.history['val_categorical_accuracy'] + [1.0]*EPOCHS]))\nacc_df.columns = [\"Epochs\", \"Stage\", \"Accuracy\"]\nfig = px.bar(acc_df, x=\"Accuracy\", y=\"Stage\", animation_frame=\"Epochs\", title=\"Accuracy vs. Epochs\", color='Stage',\n       color_discrete_map={\"Train\":\"dodgerblue\", \"Val\":\"darkorange\", \"Benchmark\":\"seagreen\"}, orientation=\"h\")\n\nfig.update_layout(\n    xaxis = dict(\n        autorange=False,\n        range=[0, 1]\n    )\n)\n\nfig.update_layout(template=\"plotly_white\")","339069cd":"def process(img):\n    return cv2.resize(img\/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\nfig = make_subplots(rows=10, cols=2)\n\n\npreds = predict(train_images[0])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[0]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[0], (205, 136))), row=1, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=1, col=2)\nfig.update_layout(height=800, width=600, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\n\npreds = predict(train_images[1])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[1]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[1], (205, 136))), row=2, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=2, col=2)\nfig.update_layout(height=800, width=600, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\npreds = predict(train_images[2])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[2]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[2], (205, 136))), row=3, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=3, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\npreds = predict(train_images[3])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[3]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[3], (205, 136))), row=4, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=4, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\npreds = predict(train_images[4])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[4]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[4], (205, 136))), row=5, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=5, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\npreds = predict(train_images[5])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[5]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[5], (205, 136))), row=6, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=6, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\npreds = predict(train_images[6])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[6]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[6], (205, 136))), row=7, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=7, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\npreds = predict(train_images[7])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[7]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[7], (205, 136))), row=8, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=8, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\n\npreds = predict(train_images[8])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[8]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[8], (205, 136))), row=9, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=9, col=2)\n\n\npreds = predict(train_images[9])\n\ncolors = {TRAIN_FOLDERS[0]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[1]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[2]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[3]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[4]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[5]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[6]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[7]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[8]:px.colors.qualitative.Plotly[0], TRAIN_FOLDERS[9]:px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[0]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[1]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[2]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[3]\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = TRAIN_FOLDERS[4]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[5]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[6]\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = TRAIN_FOLDERS[7]\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = TRAIN_FOLDERS[8]\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = TRAIN_FOLDERS[9]\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[TRAIN_FOLDERS[9]] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[9], (205, 136))), row=10, col=1)\nfig.add_trace(go.Bar(x=[TRAIN_FOLDERS[0],TRAIN_FOLDERS[1],TRAIN_FOLDERS[2],TRAIN_FOLDERS[3],TRAIN_FOLDERS[4],TRAIN_FOLDERS[5],TRAIN_FOLDERS[6],TRAIN_FOLDERS[7],TRAIN_FOLDERS[8],TRAIN_FOLDERS[9]], y=preds, marker=dict(color=colors)), row=10, col=2)\nfig.update_layout(height=1800, width=1000, title_text=\"DenseNet Predictions\", showlegend=False)\nfig.update_layout(template=\"plotly_white\")","30542731":"![image.png](attachment:image.png)","3cb356de":"## Imports","543c3ec4":"## Reading Images","5250ec2b":"## Generating GCS path for TPU processing","67c4630d":"### Creating Train and Validation TF dataset\n\n#### Parameters definition:\n    \n    1. Shuffle : the file names will be shuffled randomly\n    \n    2. Repeat: Repeats the dataset so each original value is seen multiple times , since we are \n               randomly augmenting(flipping) our images\n    \n    3. Prefetch : This allows later elements to be prepared while the current element is being processed. \n                  This often improves latency and throughput, at the cost of using additional memory to store \n                  prefetched elements.\n    \n    4. num_parallel_calls : tf.data.experimental.AUTOTUNE is used, then the number of parallel calls \n                            is set dynamically based on available CPU.","3565a50a":"### Animation of Score vs EPOCH (click \u25b6\ufe0f)","9effef42":"### Displaying Training Curves","bab184d4":"## Training DenseNet","cb746292":"### Learning rate scheduler","9ff11f3e":"## TPU Configuration\n\n* TPUs are network-connected accelerators and you must first locate them on the network. This is what TPUClusterResolver() does.\n\n* Two additional lines of boilerplate and you can define a TPUStrategy. This object contains the necessary distributed training code that will work on TPUs with their 8 compute cores\n\n* Batch size, learning rate\n    \n    To go fast on a TPU, increase the batch size. The rule of thumb is to use batches of 128 elements per core           (ex:      batch size of 128*8=1024 for a TPU with 8 cores).\n            BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n* tf.data.Dataset and TFRecords\n    \n    Because TPUs are very fast, many models ported to TPU end up with a data bottleneck. The TPU is sitting             idle, waiting for data for the most part of each training epoch. TPUs read training data exclusively from           GCS (Google Cloud Storage). And GCS can sustain a pretty large throughput if it is continuously streaming           from multiple files in parallel.","ce6c6f72":"## Image decoding and Augmentation","9bad9014":"## Model Architecture","69b8b5dd":"## Predicting Images from each class\n\nLet's visualize some sample predictions made by the DenseNet model. \nThe <font color=\"red\">red<\/font> bars represent the model's prediction gone wrong, <br>\nthe <font color=\"green\">green<\/font> represent the ground truth (label), and the rest of the bars are \n<font color=\"blue\">blue<\/font>. <br>\nWhen the model predicts correctly, the prediction bar is <font color=\"green\">green<\/font>. <br>\n\nHover over the bars to check the probablity of prediction","47e9869d":"## Modelling with DenseNet"}}