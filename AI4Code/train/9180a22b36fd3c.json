{"cell_type":{"c7b1d868":"code","a1726c7d":"code","9e62ddd9":"code","cbaae5cd":"code","de2cf870":"code","b1333b3c":"code","74cc6606":"code","03c48b3f":"code","364e4297":"code","236a16c5":"code","1ec18a09":"code","75f8d2d5":"code","9c93a8b3":"code","6b62517a":"code","ad36f854":"code","f0a28855":"code","1894c8f8":"code","8fd99c77":"code","c46a8f1e":"code","ee22c1d6":"code","8f735c8a":"markdown","4c6e1d9a":"markdown","91fcc7ad":"markdown","8f424ca7":"markdown","9736f7a0":"markdown","5be96790":"markdown","55a67f3a":"markdown","52d457cb":"markdown","a5b16f38":"markdown","7b4ab4fc":"markdown","202230be":"markdown","3144d217":"markdown"},"source":{"c7b1d868":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a1726c7d":"import matplotlib.pyplot as plt    # Graphics\nimport matplotlib.style as style    # Graphic style \nimport seaborn as sns    # Graphics \nimport statistics as sts    #Statistical analysis ","9e62ddd9":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","cbaae5cd":"titanic_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")   # Importing the training dataset\n\n# It's important to do an overview of the dataset, so we described the data with the code bellow \ntitanic_train.head(5)","de2cf870":"titanic_train.describe()","b1333b3c":"t_df = titanic_train\n\n#Evaluating the missing data\n\nt_df.isnull().sum()","74cc6606":"style.use('seaborn-colorblind')\n\nplt.figure(figsize=(8,4))\nplt.title('Age Distribution')\nsns.histplot(t_df['Age'], bins=20)","03c48b3f":"# Adding the age group information\n\nage_intervals = [t_df.Age.min()-1, 10, 18, 65, t_df.Age.max()] \nage_groups = ['children', 'teenager', 'adult', 'elders']\nt_df['Age_Group'] = pd.cut(t_df['Age'], age_intervals, labels= age_groups)\n\ntest_data['Age_Group'] = pd.cut(t_df['Age'], age_intervals, labels= age_groups)","364e4297":"plt.figure(figsize=(8,4))\nsns.countplot(x=t_df['Age_Group'])\nplt.title('Age Group distribution')\nplt.xlabel('Age Group')","236a16c5":"sex_split = t_df.groupby(['Pclass','Sex']).size()\nsex_split.plot(kind='bar')\nplt.title('Sex per Class')\nplt.ylabel('Quantity')\nplt.xlabel('Class and Sex')\nplt.xticks(rotation=45)\n","1ec18a09":"print('Median for age separated by Sex and Pclass')\nt_df.pivot_table(values=['Age'], index=['Pclass','Sex'], aggfunc = np.median)","75f8d2d5":"# Filling the missing data with the group median\nt_df['Age'] = t_df.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\ntest_data['Age'] = t_df.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","9c93a8b3":"# Filters by Sex\nmale_group = t_df.loc[t_df['Sex'] == 'male']\nmale_survivors = male_group.loc[male_group['Survived'] == 1]\n\nfemale_group = t_df.loc[t_df['Sex'] == 'female']\nfemale_survivors = female_group.loc[female_group['Survived'] == 1]","6b62517a":"# Looking at the survival rate\nmale_survival_rate = (male_survivors['PassengerId'].count()) \/ (male_group['PassengerId'].count())\nfemale_survival_rate = (female_survivors['PassengerId'].count()) \/ (female_group['PassengerId'].count())\ntotal_survival_rate = ((male_survivors['PassengerId'].count()) + female_survivors['PassengerId'].count()) \/ t_df['PassengerId'].count()\n\n\nprint(f' Male survival rate was: {round(male_survival_rate*100)}% \\n Female survival rate was: {round(female_survival_rate*100)}%')\nprint(f' Disaster total survival rate: {round(total_survival_rate*100)}%')","ad36f854":"features = ['Sex','Age', 'Age_Group','SibSp', 'Pclass', 'Parch', 'Embarked']\ntarget = t_df['Survived']","f0a28855":"# Transforming the categoirical data into numeric \n\nfeatures_df = t_df[features]\nfeatures_df =  pd.get_dummies(features_df)\nfeatures_df.head()","1894c8f8":"# Data for testing\n\ny = target\n\nX = features_df","8fd99c77":"from sklearn.linear_model import LogisticRegression\n\nlog_reg_model = LogisticRegression()\nlog_reg_model.fit(X, y)\n\ny_pred_log = log_reg_model.predict(X)\nscore_rlog = log_reg_model.score(X, y)\nprint(score_rlog)","c46a8f1e":"from sklearn.ensemble import RandomForestClassifier\n\nX_test = pd.get_dummies(test_data[features])\n\nrandom_forest_model = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=42)\nrandom_forest_model.fit(X, y)\n\npredictions = random_forest_model.predict(X_test)\n\nscore_rf = random_forest_model.score(X, y)\nprint(score_rf)","ee22c1d6":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8f735c8a":"### Dictionary\n\nOur collumns have meaning (I don't) \n\nsurvival = Survival; ____________ Key: {0 = No}, {1 = Yes}\n\npclass   = Ticket class __ Key: 1 = 1st, 2 = 2nd, 3 = 3rd\n\nsex = no need to explain \n\nAge = Age in years\n\nsibsp = # of siblings \/ spouses aboard the Titanic\n\nparch = # of parents \/ children aboard the Titanic \n\nfare = Passenger fare\t\n\ncabin\t= Cabin number\n\nembarked = Port of Embarkation\t___ Key: C = Cherbourg, Q = Queenstown, S = Southampton\n\n\n---","4c6e1d9a":"## Informations \n","91fcc7ad":"### Random Forest","8f424ca7":"# Feature selection","9736f7a0":"### Variable Notes\n\npclass: A proxy for socio-economic status (SES)\n* 1st = Upper\n* 2nd = Middle\n* 3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\n\nSibling = brother, sister, stepbrother, stepsister\n\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\n\nParent = mother, father\n\nChild = daughter, son, stepdaughter, stepson\n\nSome children travelled only with a nanny, therefore parch=0 for them.\n\n\n---","5be96790":"Since the Age column has some null values, we need to fill this gaps with some data. \nLooking at the distribution above, most of the passengers have an age between 18 and 40. \nWe also have a considerable quantity of children. \n\nThose insights maybe can have an impact in our analysis, since we know the **\"Women and children first\"** (Birkenhead Drill) protocol was active at the time. ","55a67f3a":"### Logistic Regression","52d457cb":"Looking at our columns, we can start feature selection, but some problems are\nvisible, since we don't know much about the cabins, and almost 25% of our sample don't  have an age register.","a5b16f38":"#  Titanic (Overview) \n\nOur goal in this project is to predict if a passenger survived the sinking of the  Titanic or not. \n\n* I'll write my first real code using machine learning, and applying the sevens basic steps to solve a Data  Science problem:\n  * Data gathering;\n  * Data preparation;\n  * Model selection; \n  * Model trainning; \n  * Model evaluation\n  * Parameters tuning\n  * Getting preditctions","7b4ab4fc":"Now we have valuable information about our data, the vast majority was male in adult age and had a 3rd class ticket. <br>\nFor filling the missing values, we'll use thoses conclusions. ","202230be":"# Feature engeniring","3144d217":"# Data Preparation"}}