{"cell_type":{"6c50eae3":"code","be778b91":"code","67026f81":"code","048bb1c8":"code","7c55024d":"code","c893599b":"code","244c1e9d":"code","1c1af152":"code","0d7d5141":"code","0617ff46":"code","71ec8d1d":"code","9fdef627":"code","ba4016e5":"code","f9103aaf":"code","4abe3c55":"code","5233d8ab":"code","0b22f15a":"code","75124fd9":"code","6dfa63d5":"code","863b7256":"code","55232bd7":"code","9aa2c498":"code","8661da2f":"code","bcbd76d5":"code","4ae1f13d":"code","e737e1e7":"code","a6cf9a51":"code","a896d29d":"code","3a49be71":"code","5a5fcc8c":"code","ff5abe67":"code","b4d702c4":"code","13e477df":"code","d582b269":"code","6c9f93af":"markdown","462a33d2":"markdown","92835b6b":"markdown","aaf7d332":"markdown","4d7cc26c":"markdown","cef6f91c":"markdown","c910422f":"markdown","b1db11fe":"markdown","93b9f1a7":"markdown"},"source":{"6c50eae3":"# Importing the libraries\nimport numpy as np \nimport pandas as pd ","be778b91":"df = pd.read_csv('..\/input\/fake-news\/train.csv')\ndf.head()","67026f81":"# Shape of the data\ndf.shape","048bb1c8":"# Creating the feature matrix\nX = df.drop('label', axis = 1)\nX.head()","7c55024d":"# Get the dependent variable\ny = df['label']\ny.head()","c893599b":"# Removing the NaN values\ndf = df.dropna()","244c1e9d":"# Shape of the data after removing Nan values \ndf.shape","1c1af152":"# Importing the essential libraries\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional","0d7d5141":"# Vocabulary size\nvocab_size = 5000","0617ff46":"messages = df.copy()","71ec8d1d":"# Resetting the indices after the removal of NaN values\nmessages.reset_index(inplace = True)","9fdef627":"# Example text from our data \nprint(messages['title'][5])\nprint(messages['text'][5])","ba4016e5":"# Again importing the essential libraries\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","f9103aaf":"ps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","4abe3c55":"corpus","5233d8ab":"onehot_rep = [one_hot(words,vocab_size) for words in corpus]\nonehot_rep","0b22f15a":"sent_len = 20\nembedded = pad_sequences(onehot_rep, padding = 'pre', maxlen = sent_len)\nprint(embedded)","75124fd9":"len(embedded)","6dfa63d5":"embedded[0]","863b7256":"embedding_vector_features = 40\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_vector_features, input_length = sent_len))\nmodel.add(LSTM(100))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())","55232bd7":"y = messages['label']","9aa2c498":"import numpy as np\nX_final = np.array(embedded)\ny_final = np.array(y)","8661da2f":"X_final.shape,y_final.shape","bcbd76d5":"# Train-Test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=30)","4ae1f13d":"# Train the model\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","e737e1e7":"y_pred = (model.predict_classes(X_test))","a6cf9a51":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nconfusion_matrix(y_test,y_pred)\naccuracy_score(y_test,y_pred)","a896d29d":"from tensorflow.keras.layers import Dropout\n# Creating the model\nembedding_vector_features = 50\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_vector_features, input_length = sent_len))\n#model.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())","3a49be71":"X_final = np.array(embedded)\ny_final = np.array(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=0)\n\n# Train the model\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","5a5fcc8c":"y_pred = (model.predict_classes(X_test))\nprint('\\n Confusion Matrix:- \\n',confusion_matrix(y_test,y_pred))\nprint('\\n Accuracy:',accuracy_score(y_test,y_pred)* 100,'%')","ff5abe67":"# Creating model\nembedding_vector_features=40\nmodel1=Sequential()\nmodel1.add(Embedding(vocab_size, embedding_vector_features, input_length=sent_len))\nmodel1.add(Bidirectional(LSTM(100)))\n# Adding the dropout rate of 0.3\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(1,activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model1.summary())","b4d702c4":"len(embedded),y.shape","13e477df":"X_final=np.array(embedded)\ny_final=np.array(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state = 1)\n\nmodel1.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=10, batch_size=64)","d582b269":"y_pred = (model.predict_classes(X_test))\nprint('\\n Confusion Matrix:- \\n',confusion_matrix(y_test,y_pred))\nprint('\\n Accuracy:',accuracy_score(y_test,y_pred)* 100,'%')","6c9f93af":"### Embedding Representation","462a33d2":"### Adding Dropout","92835b6b":"### Loading the dataset","aaf7d332":"***Bi-Directional LSTM***","4d7cc26c":"### Performance Metrics","cef6f91c":"*Data Pre-processing*","c910422f":"### Creating the Model","b1db11fe":"***LSTM***","93b9f1a7":"### One-Hot Representation"}}