{"cell_type":{"bd1a87da":"code","f5b5af1d":"code","c7c0aa96":"code","b8604746":"code","1d94d76b":"code","3881b442":"code","180587dc":"code","c01aa2bb":"code","04e44f21":"code","26abf1ae":"code","57ddadeb":"code","1ebb142a":"code","f3ff1767":"code","d6e1ae34":"code","2f1a51fe":"code","ca921e3e":"code","50dba64d":"code","5527d301":"code","3b308e71":"code","fb343e6b":"code","bd2dac43":"code","12e09387":"code","e1eda288":"code","cd256bae":"code","f01a809f":"code","328d69f7":"code","910f7f5c":"code","22df2afa":"code","fa7625d6":"code","388950c4":"code","bf53b614":"code","9280b028":"code","4c7fd18b":"markdown","4137cd33":"markdown","4207770a":"markdown","1aafbe0a":"markdown","f369b7ea":"markdown","333a3b12":"markdown","9d68a392":"markdown","27380320":"markdown","a6188163":"markdown","793cc507":"markdown"},"source":{"bd1a87da":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f5b5af1d":"mall=pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","c7c0aa96":"mall.head(5)","b8604746":"mall.isnull().sum()","1d94d76b":"mall.shape","3881b442":"mall.describe().T","180587dc":"mall.Gender.value_counts()","c01aa2bb":"mall.dtypes","04e44f21":"#find relation ship among the data sets\n#percentage of mail and feail\nsns.countplot(mall['Age'],palette = 'rainbow')\nplt.title('Distrbution of the age',fontsize=15)\nlabel=['Male','Female']\nvalues=mall['Gender'].value_counts().values\ncolors=['blue','green']\nfig,ax1=plt.subplots()\nplt.axis('off')\nexplode = [0, 0.2]\nax1.pie(values,labels=label,shadow=True,startangle=90,autopct ='%.2f%%',explode = explode,colors=colors)\nplt.title('Gender', fontsize =10)\nplt.legend()\nplt.show()","26abf1ae":"plt.figure(figsize=(5,5))\nsns.barplot(x='Gender',y='Age',data=mall)\nplt.title('relation between age and gender')\nplt.legend()","57ddadeb":"import warnings\nwarnings.filterwarnings('ignore')\n\nsns.set(style='whitegrid')\nplt.rcParams['figure.figsize'] = (14, 10)\n\nplt.subplot(1,2,1)\nsns.distplot(mall['Annual Income (k$)'],bins=100,color='y',vertical=True,rug=True)\nplt.ylabel('anual income')\nplt.xlabel('count')\nplt.title('distrbution of annual income',fontsize=15)\nplt.show()","1ebb142a":"\nsns.set(style='whitegrid')\nplt.subplot(1,2,2)\nsns.distplot(mall['Age'],bins=100,color='b',vertical=True,rug=True)\nplt.ylabel('age of the person')\nplt.xlabel('count')\nplt.title('age of the persion',fontsize=15)\nplt.legend()\nplt.show()","f3ff1767":"\nsns.set(style='whitegrid')\nplt.subplot(1,2,2)\nsns.distplot(mall['Spending Score (1-100)'],color='g',bins=100,vertical=True,rug=True)\nplt.ylabel('spending of the persion')\nplt.xlabel('count')\nplt.legend()\nplt.show()","d6e1ae34":"plt.rcParams['figure.figsize']=(14,10)\nsns.countplot(mall['Annual Income (k$)'],palette='viridis_r')\n#relation\nplt.figure(figsize=(15,15))\nsns.relplot(y='Age',x='Annual Income (k$)',hue='Gender',style='Gender',data=mall,s=100,label='Gender',palette='twilight_shifted')","2f1a51fe":"sns.countplot(mall['Spending Score (1-100)'], palette='autumn')","ca921e3e":"sns.pairplot(mall.drop('CustomerID',axis=1))","50dba64d":"sns.heatmap(mall.corr(),annot=True,cmap='mako')","5527d301":"sns.relplot(x='Annual Income (k$)',y='Spending Score (1-100)',hue='Gender',s=200,data=mall)\nx=mall.iloc[:,[3,4]].values","3b308e71":"#here we need standerd scaler to the scale the data\nfrom sklearn.preprocessing import StandardScaler\nscale=StandardScaler()\nscale.fit(x)\nscaled_x=scale.fit_transform(x)\nscaled_x","fb343e6b":"inertia=[]\nfrom sklearn.cluster import KMeans\nfor k in range(1,11):\n    kmm=KMeans(n_clusters=k,random_state=0,max_iter=300,n_init = 10,init ='k-means++')\n    kmm.fit(scaled_x)\n    inertia.append(kmm.inertia_)\n\nplt.plot(range(1,11), inertia)\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('inertia')\nplt.show()","bd2dac43":"print(kmm.cluster_centers_)\nprint(kmm.labels_)","12e09387":"from sklearn.cluster import KMeans\nkmm=KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means=kmm.fit_predict(scaled_x)\nprint(y_means)\n\nplt.scatter(scaled_x[y_means == 0, 0], scaled_x[y_means == 0, 1], s = 100, c = 'green', label = 'lower-class')\nplt.scatter(scaled_x[y_means==1, 0], scaled_x[y_means==1, 1], s=100, c='g', label ='lowe-middle-class')\nplt.scatter(scaled_x[y_means==2, 0], scaled_x[y_means==2, 1], s=100, c='r', label ='middle-class')\nplt.scatter(scaled_x[y_means==3, 0], scaled_x[y_means==3, 1], s=100, c='y', label ='upper-class')\nplt.scatter(scaled_x[y_means==4, 0], scaled_x[y_means==4, 1], s=100, c='orange', label ='high-class')\nplt.scatter(kmm.cluster_centers_[:,0], kmm.cluster_centers_[:, 1], s = 200, c = 'cyan' , label = 'centeroid')\nplt.style.use('fivethirtyeight')\nplt.title('K Means Clustering', fontsize = 15)\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.show()\nplt.show()","e1eda288":"#age vs spending \nsns.relplot(x='Age',y='Spending Score (1-100)',hue='Gender',s=200,data=mall)","cd256bae":"mall.head(1)\nX = mall.iloc[:, [2, 4]].values\nX","f01a809f":"from sklearn.preprocessing import StandardScaler\nscale=StandardScaler()\nscale.fit(X)\nscalex=scale.fit_transform(X)\nscalex","328d69f7":"inertia=[]\nfrom sklearn.cluster import KMeans\nfor k in range(1,11):\n    km=KMeans(n_clusters=k,random_state=0,max_iter=300,n_init = 10,init ='k-means++')\n    km.fit(scalex)\n    inertia.append(km.inertia_)\n\nplt.plot(range(1,11), inertia)\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('inertia')\nplt.show()","910f7f5c":"km = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(scalex)\nplt.scatter(scalex[y_means == 0, 0], scalex[y_means == 0, 1], s = 100, c = 'green', label = 'usualcustomer')\nplt.scatter(scalex[y_means == 1, 0], scalex[y_means == 1, 1], s = 100, c = 'b', label = 'perority customer')\nplt.scatter(scalex[y_means == 2, 0], scalex[y_means == 2, 1], s = 100, c = 'r', label = 'main customer')\nplt.scatter(scalex[y_means == 3, 0], scalex[y_means == 3, 1], s = 100, c = 'y', label = 'maincustomer')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 200, c = 'cyan' , label = 'centeroid')\nplt.style.use('fivethirtyeight')\nplt.xlabel('Age')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.grid()\nplt.show()","22df2afa":"import scipy.cluster.hierarchy as sch\n\ndendrogram = sch.dendrogram(sch.linkage(scalex, method = 'complete'))\nplt.title('Dendrogam', fontsize = 15)\nplt.xlabel('Customers')\nplt.ylabel('Ecuclidean Distance')\nplt.show()","fa7625d6":"from sklearn.cluster import AgglomerativeClustering\n\nhc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(scaled_x)\nplt.scatter(scalex[y_hc == 0, 0], scalex[y_hc == 0, 1], s = 100, c = 'green', label = 'usualcustomer')\nplt.scatter(scalex[y_hc == 1, 0], scalex[y_hc == 1, 1], s = 100, c = 'b', label = 'perority customer')\nplt.scatter(scalex[y_hc == 2, 0], scalex[y_hc == 2, 1], s = 100, c = 'r', label = 'main customer')\nplt.scatter(scalex[y_hc == 3, 0], scalex[y_hc == 3, 1], s = 100, c = 'y', label = 'maincustomer')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 200, c = 'cyan' , label = 'centeroid')\nplt.style.use('fivethirtyeight')\nplt.title('Hierarchial Clustering', fontsize = 15)\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.grid()\nplt.show()","388950c4":"from sklearn.cluster import DBSCAN\ndbscan=DBSCAN(eps=3,min_samples=4)\n#Fitting the model\n\nmodel=dbscan.fit(scaled_x)\n\nlabels=model.labels_","bf53b614":"from sklearn import metrics\n\n#identifying the points which makes up our core points\nsample_cores=np.zeros_like(labels,dtype=bool)\n\nsample_cores[dbscan.core_sample_indices_]=True","9280b028":"n_clusters=len(set(labels))- (1 if -1 in labels else 0)\nn_clusters","4c7fd18b":"# Here we Apply clusters ","4137cd33":"# Visualizaing the Clusters","4207770a":"Customer Segmentation and Analysis\nSteps to solve the problem :\n\n\nEDA and visualization.\nClustering using K-Means.\nSelection of Clusters.\nPloting the Cluster Boundry and Clusters.\n3D Plot of Clusters.\n\n\nDescription Variables:\nCustomerID: Unique ID assigned to the customer\nGender: Gender of the customer\nAge: Age of the customer\nAnnual Income (k$): Annual Income of the customee\nSpending Score (1\u2013100): Score assigned by the mall based on customer behavior and spending nature.\n\n\n# clustering:-\nAll the data points in a cluster should be similar to each other.\nThe data points from different clusters should be as different as possible.","1aafbe0a":"# DbscaN","f369b7ea":"Hdbscan","333a3b12":"cluster using annual income  and spendiing score ","9d68a392":"# import library and data sets","27380320":"# #clustring based on there age","a6188163":"# used k-means clustring \nusing elbow method for optimal value (inertia:-sum of sequared distance and there closet point on the center)","793cc507":"# EDA and visualization"}}