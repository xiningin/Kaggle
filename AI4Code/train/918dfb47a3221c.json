{"cell_type":{"dc694278":"code","642622e2":"code","647b6a60":"code","287a6a22":"code","41d027ea":"code","def36c21":"code","360b6f15":"code","a3789cb8":"code","ebd5f3f5":"code","c5043748":"code","d5f3ada4":"code","34b4d3c9":"code","1e1307ca":"code","af2b4a74":"code","02f44010":"code","d69c1764":"code","a93df283":"code","3fb4b067":"code","65baa15f":"code","b6761139":"code","67f9ddfa":"code","5a8643b7":"code","3b9a6f35":"code","946cea13":"code","4977b76b":"code","f9d3139a":"code","6154cb37":"code","27a3f833":"code","32955de6":"code","35772b7b":"code","21ffa402":"code","8fc1f60e":"code","6e6f6bc8":"code","7e600d54":"code","c67af315":"code","2f17f015":"code","0b7b966c":"markdown","7d0e9b96":"markdown","0895d7ee":"markdown","56ab1cd6":"markdown","6bad9053":"markdown","8fe1d039":"markdown","14e57272":"markdown","aca6cb24":"markdown","77b14d13":"markdown","9f9995d7":"markdown","2f6c021b":"markdown","af28e165":"markdown","ecf7dd01":"markdown","6f4ea2b6":"markdown","90607cb4":"markdown","3727a7ed":"markdown","2ce45df3":"markdown","3610a1ad":"markdown","32159b99":"markdown","fcf21533":"markdown","c3ae3578":"markdown","b9c5da9c":"markdown","d267edb8":"markdown","d18f6558":"markdown","53a32954":"markdown","8a88deb4":"markdown","c7ee19a6":"markdown","9602b2fa":"markdown","d283f207":"markdown","fa6d44cb":"markdown","c668c781":"markdown","5582e54e":"markdown","02cfb88d":"markdown","ef8ec921":"markdown","12431b3c":"markdown","8d3a9206":"markdown","97667d73":"markdown","d2d7b13a":"markdown","f501b045":"markdown","1885b5d0":"markdown","011192c3":"markdown","cecb4484":"markdown","ea8bdd1a":"markdown","141828b1":"markdown","8e9cb311":"markdown","75b54b92":"markdown","81c6bb7d":"markdown","fa27e4a2":"markdown","19d1d882":"markdown","dbfa7c4b":"markdown","1aace1c3":"markdown","e24df8e6":"markdown","871e538e":"markdown","0794cf49":"markdown","314abde9":"markdown","310579bc":"markdown","7085c86f":"markdown","342bcf6e":"markdown","1d4386a4":"markdown","f8e0f1b5":"markdown","28f7b143":"markdown"},"source":{"dc694278":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","642622e2":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dateutil import parser\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport pickle\nfrom lightgbm import LGBMClassifier\nimport warnings\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')","647b6a60":"\ndata=pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndata.head()","287a6a22":"data.shape","41d027ea":"data.isnull().sum()","def36c21":"cols = data.columns\ncols","360b6f15":"print(\"# Rows in the dataset {0}\".format(len(data)))\nprint(\"---------------------------------------------------\")\nfor col in cols:\n    print(\"# Rows in {1} with ZERO value: {0}\".format(len(data.loc[data[col] ==0]),col))","a3789cb8":"data.dtypes","ebd5f3f5":"print('Rows     :',data.shape[0])\nprint('Columns  :',data.shape[1])\nprint('\\nFeatures :\\n     :',data.columns.tolist())\nprint('\\nMissing values    :',data.isnull().values.sum())\nprint('\\nUnique values :  \\n',data.nunique())","c5043748":"data.describe().T","d5f3ada4":"data.hist(figsize = (12,12))\nplt.show()","34b4d3c9":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata['target'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Rate of Heart Disease')\nax[0].set_ylabel('Count')\nsns.countplot('target',data=data,ax=ax[1],order=data['sex'].value_counts().index)\nax[1].set_title('Rate of Heart Disease')\nplt.show()","1e1307ca":"#Creating subplots\nplt.figure(figsize=(15, 12))\n#Subplot1 \nplt.subplot(2,2,1)\nplt.title('Distribution of Age')\nsns.distplot(data['age'], rug = True)\n\n#Subplot2\nplt.subplot(2,2,2)\nplt.title('Distribution of Resting Blood Pressure')\nsns.distplot(data['trestbps'], rug = True)\n\n#Subplot3\nplt.subplot(2,2,3)\nplt.title('Distribution of Cholesterol')\nsns.distplot(data['chol'], rug = True)\n\n\n#Subplot4\nplt.subplot(2,2,4)\nplt.title('Distribution of Max Hear Rate')\nsns.distplot(data['thalach'], rug = True)\nplt.ioff()\n#plt.show()","af2b4a74":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata['cp'].value_counts().plot.pie(explode=[0,0.05,0.05,0.05],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Chest Pain Type')\nax[0].set_ylabel('Count')\nsns.countplot('cp',data=data,ax=ax[1],order=data['cp'].value_counts().index)\nax[1].set_title('Chest Pain Type')\nplt.show()","02f44010":"sns.barplot(x=\"sex\",y ='age',hue ='target',data=data)\npass","d69c1764":"sns.catplot(x='cp',y='target',kind='point',data=data,col='sex')\npass","a93df283":"\nfig,ax = plt.subplots(nrows=4, ncols=2, figsize=(18,18))\nplt.suptitle('Violin Plots',fontsize=24)\nsns.violinplot(x=\"ca\", data=data,ax=ax[0,0],palette='Set3')\nsns.violinplot(x=\"trestbps\", data=data,ax=ax[0,1],palette='Set3')\nsns.violinplot (x ='chol', data=data, ax=ax[1,0], palette='Set3')\nsns.violinplot(x='fbs', data=data, ax=ax[1,1],palette='Set3')\nsns.violinplot(x='restecg', data=data, ax=ax[2,0], palette='Set3')\nsns.violinplot(x='thalach', data=data, ax=ax[2,1],palette='Set3')\nsns.violinplot(x='exang', data=data, ax=ax[3,0],palette='Set3')\nsns.violinplot(x='age', data=data, ax=ax[3,1],palette='Set3')\nplt.show()","3fb4b067":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(\"sex\",\"trestbps\",hue=\"target\", data=data,split=True)\nplt.subplot(2,2,2)\nsns.violinplot(\"sex\",\"chol\",hue=\"target\", data=data,split=True)\nplt.subplot(2,2,3)\nsns.violinplot(\"sex\",\"thalach\",hue=\"target\", data=data,split=True)\nplt.subplot(2,2,4)\nsns.violinplot(\"sex\",\"fbs\",hue=\"target\", data=data,split=True)\n#ax[0].set_title('Sex and trestbps vs target')\n#ax[0].set_yticks(range(0,110,10))\n#sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\n#ax[1].set_title('Sex and Age vs Survived')\n#ax[1].set_yticks(range(0,110,10))\nplt.ioff()\nplt.show()","65baa15f":"pd.crosstab(data.age,data.target).plot(kind='bar',figsize=(20,6))\nplt.title('Heart Disease Vs Age')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.savefig('HeartDiseaseAge.png')\nplt.ioff()","b6761139":"# Bar chart for age with sorted index\n# Changing title fontsize -> We have to use alternative matplotlib set_title function\nplot = data[data.target == 1].age.value_counts().sort_index().plot(kind = \"bar\", figsize=(15,5), fontsize = 15)\nplot.set_title(\"Heart disease: Age distribution\", fontsize = 15)\nplt.ioff()","67f9ddfa":"plt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nplt.scatter(x=data.age[data.target==1],y=data.thalach[data.target==1],c='red')\nplt.scatter(x=data.age[data.target==0],y=data.thalach[data.target==0],c='green')\nplt.xlabel('Age')\nplt.ylabel('Max Heart Rate')\nplt.legend(['Disease','No Disease'])\n\nplt.subplot(1,3,2)\nplt.scatter(x=data.age[data.target==1],y=data.chol[data.target==1],c='red')\nplt.scatter(x=data.age[data.target==0],y=data.chol[data.target==0],c='green')\nplt.xlabel('Age')\nplt.ylabel('Cholesterol')\nplt.legend(['Disease','No Disease'])\n\nplt.subplot(1,3,3)\nplt.scatter(x=data.age[data.target==1],y=data.trestbps[data.target==1],c='red')\nplt.scatter(x=data.age[data.target==0],y=data.trestbps[data.target==0],c='green')\nplt.xlabel('Age')\nplt.ylabel('Resting Blood Pressure')\nplt.legend(['Disease','No Disease'])\n\nplt.tight_layout()\nplt.ioff()","5a8643b7":"corrmat = data.corr()\nfig = plt.figure(figsize = (16,16))\nsns.heatmap(corrmat,vmax = 1,square = True,annot = True,vmin = -1)\nplt.show()","3b9a6f35":"cols","946cea13":"final_cols1 = cols\nfinal_cols1 = list(final_cols1)\n#final_cols\nlist_to_remove = ['ca','cp','exang','fbs','restecg','sex','slope','target','thal']\n\nfinal_cols = list(set(final_cols1) - set(list_to_remove))\nfinal_cols","4977b76b":"X = data.drop('target',axis=1) #predictor feature columns\ny = data.target\ny.value_counts()","f9d3139a":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\nX_res_OS , Y_res_OS = sm.fit_resample(X,y)\npd.Series(Y_res_OS).value_counts()","6154cb37":"X_res_OS = pd.DataFrame(X_res_OS,columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'])\nY_res_OS = pd.DataFrame(Y_res_OS,columns=['target'])","27a3f833":"X_train,X_test,y_train,y_test = train_test_split(X_res_OS,Y_res_OS,test_size = 0.1,random_state=10)\nprint('Training Set :',len(X_train))\nprint('Test Set :',len(X_test))\nprint('Training labels :',len(y_train))\nprint('Test labels :',len(y_test))","32955de6":"final_cols","35772b7b":"from sklearn.impute import SimpleImputer \nfill = SimpleImputer(missing_values=np.nan, strategy='mean')\n\nX_train = fill.fit_transform(X_train[final_cols])\nX_test = fill.fit_transform(X_test[final_cols])","21ffa402":"from sklearn.ensemble import RandomForestRegressor\nrf_model = RandomForestRegressor(n_estimators = 1000,random_state = 123)\ncolumns = ['target']\n#admt.drop(columns, inplace=True, axis=1)\n#X = admt.drop('target',axis = 1)\n#y = admt['target']\n#X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = .25,random_state = 123)\nrf_model = RandomForestRegressor(n_estimators = 1000,random_state = 123)\nrf_model.fit(X_train,y_train)\nfeature_importance = pd.DataFrame(sorted(zip(rf_model.feature_importances_, X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(10, 6))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_importance.sort_values(by=\"Value\", ascending=False))\nplt.xlabel('Value',fontsize=20)\nplt.ylabel('Feature',fontsize=20)\nplt.title('Random Forest Feature Importance',fontsize=25)\nplt.grid()\nplt.ioff()\nplt.tight_layout()","8fc1f60e":"def FitModel(X_train,y_train,X_test,y_test,algo_name,algorithm,gridSearchParams,cv):\n    np.random.seed(10)\n    \n    grid = GridSearchCV(\n         estimator = algorithm,\n         param_grid = gridSearchParams,\n         cv=cv,scoring='accuracy',verbose=1,n_jobs=-1)\n        \n    grid_result = grid.fit(X_train,y_train)\n    best_params = grid_result.best_params_\n    pred = grid_result.predict(X_test)\n    cm = confusion_matrix(y_test,pred)\n    print(pred)\n    \n    print('Best Params :',best_params)\n    print('Classification Report :',classification_report(y_test,pred))\n    print('Accuracy Score :'+ str(accuracy_score(y_test,pred)))\n    print('Confusion Matrix : \\n',cm)","6e6f6bc8":"# Creating Regularization penalty\npenalty = ['l1','l2']\n\n# Create regularization hyperparameter space \nC = np.logspace(0,4,10)\n\n# Create hyperparameter options \nhyperparameters = dict(C=C,penalty = penalty)\n\nFitModel(X_train,y_train,X_test,y_test,'LogisticRegression',LogisticRegression(),hyperparameters,cv=5)","7e600d54":"param = {\n           'n_estimators':[100,500,1000,1500,2000],\n           'max_depth':[2,3,4,5,6,7],\n           'learning_rate':np.arange(0.01,0.1,0.01).tolist()\n         }\nFitModel(X_train,y_train,X_test,y_test,'XGBoost',XGBClassifier(),param,cv=5)","c67af315":"param = {\n           'n_estimators':[100,500,1000,1500,2000],\n           'max_depth':[2,3,4,5,6,7],\n        \n         }\nFitModel(X_train,y_train,X_test,y_test,'Random Forest',RandomForestClassifier(),param,cv=5)","2f17f015":"param = {\n           'C':[0.1,1,100,1000],\n           'gamma':[0.0001,0.001,0.005,0.1,1,3,5],\n           \n         }\nFitModel(X_train,y_train,X_test,y_test,'SVC',SVC(),param,cv=5)","0b7b966c":"### Chest Pain Type ","7d0e9b96":"### SVC","0895d7ee":"### Logistic Regression","56ab1cd6":"### XGBoost","6bad9053":"### You can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","8fe1d039":"We can see that women with chest pain type 3 have more chance of heart disease.\n\nMen with chest pain type 1 have more chance of heart disease.","14e57272":"### Importing Python Modules","aca6cb24":"We can see that there is not much correlation between the features in the dataset.If corelation was high we can face issue of multicollinearity.In that case we would need to use feature engineering to avoid multi colinearity.","77b14d13":"### Grid Search ","9f9995d7":"Above Violin Plots show the range of Critcal Medical Parameters for Patients.Few of the observations are\n\n1.Most people are in the category zero typical angina\n\n2.Resting blood pressure for most people is around 130 bpm\n\n3.Maximum heart rate is around 160 bpm.","2f6c021b":"### Age  Vs Heart Disease ","af28e165":"### Data contains following information\n\nage: The person's age in years\n\nsex: The person's sex (1 = male, 0 = female)\n\ncp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n\ntrestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n\nchol: The person's cholesterol measurement in mg\/dl\n\nfbs: The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n\nrestecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n\nthalach: The person's maximum heart rate achieved\n\nexang: Exercise induced angina (1 = yes; 0 = no)\n\noldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n\nslope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n\nca: The number of major vessels (0-3)\n\nthal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n\ntarget: Heart disease (0 = no, 1 = yes)","ecf7dd01":"### Heat Map","6f4ea2b6":"\nWe can see that more men have heart issues than women.\n\nMen dont show emotions keep everything in their heart and finally suffer with heart diease.\n\nHormones also play a big role in all this.","90607cb4":"We can see Age,Cholosterol and Chest Pain have highest importance while predicting Heart disease.","3727a7ed":"### Vilon Plots Based on Sex","2ce45df3":"### Balancing Dataset","3610a1ad":"From the above Violin Plots we can see that resting blood pressure,cholesterol and maximum heart rate have an effect on the cause of heart Disease.In fact all this parameters are directly correlated.Surprisingly people with higher fasting sugar levels dont seem to be affected with heart disease.","32159b99":"### Missing Values","fcf21533":"Value 0: typical angina\n\nValue 1: atypical angina\n\nValue 2: non-anginal pain\n\nValue 3: asymptomatic","c3ae3578":"# 4.Predictig Heart Disease ","b9c5da9c":"# 5.Conclusion\n1.Most people fall in category 0 ie typical angina for chest pain\n\n2.Resting blood pressure for most people is around 130 bpm.Resting Blood Pressure doesnt have a clear correlation to Heart Disease\n\n3.Surprisingly people with higher fasting sugar levels dont seem to be affected with heart disease\n\n4.We can clearly see that heart disease strikes more in early 40s and early 50s.Age group of 41-45 and 51-55 have high chance of having heart problem.\n\n5.Higher cholesterol is dangerous irrespective of age\n\n6.We can see that higher heart rate at a younger age can be more dangerous.\n\n7.We can see that women with chest pain type 3 have more chance of heart disease.Men with chest pain type 1 have more chance of heart disease.\n\n8.More Men have Heart Issues than Women\n\n9.We are getting the best accuracy in Predicting Heart Disease with XGGoost Algorithm","d267edb8":"In this Kernel we will be covering following things\n\n1.Data Preprocessing\n\n2.Data Vizualizaion\n\n3.Feature Engineering\n\n4.Predicting Heart Disease\n\n5.Conclusion\n\nYou can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","d18f6558":"### Histogram","53a32954":"### 1.From the above Stats we can conclude that the Mean age of patients in datset is 54.3 years\n\n2.There are more men in the Dataset 68%\n\n3.Mean Resting Blood Pressure value is 132 mm of Hg with a min of 94mm and maximum of 200mm\n\n4.Mean Cholesterol level is 246 mg\/dl with a mainimum value of 126 mg\/dl and maximum value of 564 mg\/dl","8a88deb4":"### Effect of body parameters on Heart Disease based on Age","c7ee19a6":"### Replacing Zero Values in Numerical Feature with Mean of Column","9602b2fa":"### Important Features","d283f207":"1.From the above Stats we can conclude that the Mean age of patients in datset is 54.3 years\n\n2.There are more men in the Dataset 68%\n\n3.Mean Resting Blood Pressure value is 132 mm of Hg with a min of 94mm and maximum of 200mm\n\n4.Mean Cholesterol level is 246 mg\/dl with a mainimum value of 126 mg\/dl and maximum value of 564 mg\/dl\n\nHistogram","fa6d44cb":"### Distribution of Parameters","c668c781":"### Test Train Split ","5582e54e":"### Numpy Arrat to Dataframe Conversion","02cfb88d":"The columns which have categorical values can have ZERO values.But columns like cp,trestbps,chol,fbs,exang,oldpean and Slope should not have value ZERO.The presence of ZERO in this columns indicate the presence of null values.","ef8ec921":"### Random Forest","12431b3c":"### Heart Disease Based on Sex","8d3a9206":"We have dropped the columns with categorical columns.This is because when we do feature engineering we will be repacing the numerical column Zero values with the mean values.This is not needed for the columns with categorical variables.","97667d73":"### Shape of Data","d2d7b13a":"We can see that the dataset is unbalanced.First we will balance the dataset.Balancing data set is a good approach to improve the accuracy of the machine learning model.","f501b045":"### Effect of body parameters on Heart Disease based on Age","1885b5d0":"We can see that heart disease frequency increases once a person is above 40 Years old.Age group of 41-45 and 51-55 have high chance of having heart problem.","011192c3":"We can clearly see that heart disease strikes more in early 40s and early 50s.Now to get a better picture we can plot the distribution of people with heart disease and their age.","cecb4484":"### Vilon Plots","ea8bdd1a":"# 2.Data Visualisation","141828b1":"### Cat plot","8e9cb311":"Data Set has 54 % cases where the Patient has Heart Disease","75b54b92":"### Data Types","81c6bb7d":"### Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https:\/\/lnkd.in\/gj7bMQA","fa27e4a2":"# 1.Importing and Data Exploration data","19d1d882":"We can see that\n\n1.Age,cholestrol,max heart rate,resting blood pressure and st_depression are numerical variables.\n\n2.Chest pain type,exercie induced angina,fasting blood sugar,number major vessels,rest ecg,sex,st slope,target and thalassemia are categorical variables.","dbfa7c4b":"The number of rows of data is very low in the dataset.This may not be sufficient to build a good model.Let us see how our model works out.","1aace1c3":"1.We can see that higher heart rate at a younger age can be more dangerous.\n\n2.Higher cholesterol is dangerous irrespective of age\n\n3.Resting Blood Pressure doesnt have a clear correlation to Heart Disease.","e24df8e6":"### Summary Of Data Set","871e538e":"We are very lucky here there are no Null Values in the dataset.But in this data the missing values are present in the form of value ZERO. Our next task would be to find out numbers of ZEROS in each column.","0794cf49":"# 3.Feature Engineering","314abde9":"As all the columns are either integer or float there is no need to convert categorical values numeric values.","310579bc":"### Importing Data","7085c86f":"### Matrix of Features","342bcf6e":"### Describing the DataSet","1d4386a4":"### Heart Disease Distribution in Dataset","f8e0f1b5":"Above plots show the distribution of all the key parameters resbonsible for heart health.This are all close to Gaussian Distribution.","28f7b143":"### Finding out Zero's"}}