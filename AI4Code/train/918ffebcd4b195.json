{"cell_type":{"2404c682":"code","775d68eb":"code","1da9eaa8":"code","65f55c91":"code","afebc127":"code","71d69216":"code","078c6217":"code","956ae47e":"code","e38bc70f":"code","5f081b58":"code","e0f3ebc2":"code","50f18754":"code","9436733b":"code","9dda8ac2":"code","31f5ff59":"code","9e0b70b3":"code","339bba87":"code","34d3a450":"markdown","a0d90b35":"markdown","fda572cb":"markdown","00159e2a":"markdown","2b5070f9":"markdown","f1c55a5d":"markdown","63cebb8e":"markdown","db957092":"markdown","a2d9a1ec":"markdown","227b2959":"markdown","e8deb847":"markdown"},"source":{"2404c682":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom keras.applications import DenseNet121\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport keras\nimport csv\nimport gc\nimport cv2\nfrom tqdm import tqdm_notebook\n\ntrain_csv = \"..\/input\/aptos2019-blindness-detection\/train.csv\"\ntest_csv = \"..\/input\/aptos2019-blindness-detection\/test.csv\"\ntrain_dir = \"..\/input\/aptos2019-blindness-detection\/train_images\/\"\ntest_dir = \"..\/input\/aptos2019-blindness-detection\/test_images\/\"","775d68eb":"df = pd.read_csv(train_csv) \nsize = 256,256 # input image size","1da9eaa8":"# cropping function (uses edge detection to crop images)\ndef get_cropped_image(image):\n    img = cv2.blur(image,(2,2))\n    slice1Copy = np.uint8(img)\n    canny = cv2.Canny(slice1Copy, 0, 50)\n    pts = np.argwhere(canny>0)\n    y1,x1 = pts.min(axis=0)\n    y2,x2 = pts.max(axis=0)\n    cropped_img = img[y1:y2, x1:x2]\n    cropped_img = cv2.resize(cropped_img, size)\n    return cropped_img","65f55c91":"sample_to_show = ['07419eddd6be.png','0124dffecf29.png']\n\ndef get_cropped_image_demo(image):\n    img = cv2.blur(image,(2,2))\n    slice1Copy = np.uint8(img)\n    canny = cv2.Canny(slice1Copy, 0, 50)\n    pts = np.argwhere(canny>0)\n    y1,x1 = pts.min(axis=0)\n    y2,x2 = pts.max(axis=0)\n    cropped_img = img[y1:y2, x1:x2]\n    return np.array(cropped_img)\n\nnames = []\nsamples = []\ncropped_images = []\nfor i in sample_to_show:\n    path = train_dir + str(i)\n    img_ = cv2.imread(path)\n    img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n    samples.append(img_)\n    cropped_ = get_cropped_image_demo(img_)\n    cropped_images.append(cropped_)\n    \nfig = plt.figure(figsize = (5,5))\nax1 = fig.add_subplot(2,2,1)\nax1.title.set_text('original image'), ax1.axis(\"off\"), plt.imshow(samples[0])\nax2 = fig.add_subplot(2,2,2)\nax2.title.set_text('cropped image'), ax2.axis(\"off\"), plt.imshow(cropped_images[0])\nax3 = fig.add_subplot(2,2,3)\nax3.title.set_text('original image'), ax3.axis(\"off\"), plt.imshow(samples[1])\nax4 = fig.add_subplot(2,2,4)\nax4.title.set_text('cropped image'), ax4.axis(\"off\"), plt.imshow(cropped_images[1]);","afebc127":"def load_image(path):\n    img = cv2.resize(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB), size)\n    img = get_cropped_image(img)\n    return img","71d69216":"training_paths = [train_dir + str(x) + str(\".png\") for x in df[\"id_code\"]]\nimages = np.empty((len(df), 256,256,3), dtype = np.uint8)\nfor i, path in tqdm_notebook(enumerate(training_paths)):\n    images[i,:,:,:] = load_image(path)","078c6217":"labels = df[\"diagnosis\"].values.tolist()\nlabels = keras.utils.to_categorical(labels)","956ae47e":"images, x_val, labels, y_val = train_test_split(images, labels, test_size = 0.15)","e38bc70f":"train_aug = ImageDataGenerator(horizontal_flip = True,\n                               zoom_range = 0.25,\n                               rotation_range = 360,\n                               vertical_flip = True)\n\ntrain_generator = train_aug.flow(images, labels, batch_size = 8)","5f081b58":"input_layer = Input(shape = (256,256,3))\nbase_model = DenseNet121(include_top = False, input_tensor = input_layer, weights = \"..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5\")\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.5)(x)\nout = Dense(5, activation = 'softmax')(x)\n\nmodel = Model(inputs = input_layer, outputs = out)","e0f3ebc2":"optimizer = keras.optimizers.Adam(lr=3e-4)\n\nes = EarlyStopping(monitor='val_loss', mode='min', patience = 5, restore_best_weights = True)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience = 2, factor = 0.5, min_lr=1e-6)\n    \ncallback_list = [es, rlrop]\n\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) ","50f18754":"model.fit_generator(generator = train_generator, steps_per_epoch = len(train_generator), epochs = 20, validation_data = (x_val, y_val), callbacks = callback_list)","9436733b":"del train_generator, images\ngc.collect()","9dda8ac2":"test_df = pd.read_csv(test_csv)\ntest_paths = [test_dir + str(x) + str(\".png\") for x in test_df[\"id_code\"]]\ntest_images = np.empty((len(test_df), 256,256,3), dtype = np.uint8)\nfor i, path in tqdm_notebook(enumerate(test_paths)):\n    test_images[i,:,:,:] = cv2.resize(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB), size)","31f5ff59":"predprobs = model.predict(test_images)","9e0b70b3":"predictions = []\nfor i in predprobs:\n    predictions.append(np.argmax(i)) ","339bba87":"id_code = test_df[\"id_code\"].values.tolist()\nsubfile = pd.DataFrame({\"id_code\":id_code, \"diagnosis\":predictions})\nsubfile.to_csv('submission.csv',index=False)","34d3a450":"Imports","a0d90b35":"Demonstration of above function :\n","fda572cb":"#### ImageDataGenerator (Training data)","00159e2a":"#### CROPPING FUNCTION :","2b5070f9":"MODEL:","f1c55a5d":"* In this kernel we are going to use ImageDataGenerator to load images in batches of 8, and adding augmentation.\n* Augmentations - rotation, zoomimg, horizontal and vertical flips.\n* *CROPPING IMAGE* : We will also use image cropping to crop the extra black part in the images in the training data.\n* We will use the DenseNet121 model.","63cebb8e":"Submission :","db957092":"This kernel helped me choose the model parameters, and callbacks - [APTOS Blindness Detection - EDA and Keras ResNet50](https:\/\/www.kaggle.com\/dimitreoliveira\/aptos-blindness-detection-eda-and-keras-resnet50?scriptVersionId=16639594)","a2d9a1ec":"#### PREDICTION","227b2959":"Loading Images :","e8deb847":"TEST:"}}