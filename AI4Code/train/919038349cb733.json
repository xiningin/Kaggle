{"cell_type":{"51465963":"code","3cd80ecb":"code","361d185c":"code","ff9794d6":"code","c451ff5d":"code","f659d914":"code","609fa555":"code","d051d1c1":"code","714aa29a":"code","b3e52de4":"code","8fa0e106":"code","f4cec809":"markdown","ccc98bad":"markdown","525915cc":"markdown","b0009e9b":"markdown","daafe4eb":"markdown","5568962e":"markdown","cf0db715":"markdown","bfa868b8":"markdown","23a53435":"markdown","08cdfc27":"markdown","bc19bb7c":"markdown"},"source":{"51465963":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport numpy as np\nimport time\nimport os\nfrom IPython.display import clear_output\npd.set_option('display.max_colwidth', None)","3cd80ecb":"html_text=requests.get('http:\/\/www.howstat.com\/cricket\/Statistics\/Matches\/MatchListCountry_ODI.asp?A=IND')\nprint(html_text.status_code)\nprint(html_text.url) #shows the url for the response object\n#print(html_text.text) contains server response","361d185c":"soup_text= BeautifulSoup(\"<p><li><\/p>\",'lxml')\nprint(soup_text)","ff9794d6":"soup=BeautifulSoup(html_text.text,'lxml')","c451ff5d":"#<font size=\"5\">\ncountries=[]\ncontent= soup.find('select',{'name':'cboCountry1'}).find_all('option')\nfor i in content:\n    countries.append(i.text)\n#convert the list elements into data frame\ndf_countries=pd.DataFrame({'countries':countries})\ndf_countries.to_csv('countries_list.csv')    ","f659d914":"\nmatches1=soup.find_all('tr',bgcolor='#FFFFFF')\nmatches2=soup.find_all('tr',bgcolor='#E3FBE9')","609fa555":"print(matches1[0].find_all('td'))\n#each match content is within  td tag with lots of space and \/n ","d051d1c1":"lst1=[]\nfor j in range(len(matches1)):\n    lst=[]\n    for i in matches1[j].find_all('td'):\n        lst.append(i.text.strip())\n    lst1.append(lst)\nlst2=[]\nfor j in range(len(matches2)):\n    lst=[]\n    for i in matches2[j].find_all('td'):\n        lst.append(i.text.strip())\n    lst2.append(lst)","714aa29a":"#fucntions for combinging the 2 lists alternatively\nlst=[]\ndef mergeListALT(lst1, lst2):\n    return [sub[item] for item in range(len(lst2)) for sub in [lst1, lst2]]\nlst=mergeListALT(lst1,lst2)\nlst.append(lst1[-1])\nprint(lst[0],lst[1])","b3e52de4":"#converting the list into DataFrame\ndf=pd.DataFrame({\n    'Index': [i[0] for i in lst],\n    'Date':[i[1] for i in lst],\n    'Series':[i[2] for i in lst],\n    'Ground':[i[3] for i in lst],\n    'result':[i[4] for i in lst],\n})\ndf.head(5)","8fa0e106":"#saving it as .csv file\ndf.to_csv('file_cricket.csv')","f4cec809":"![image.png](attachment:70577666-184b-44f3-aee6-3d8c55aa33a4.png)\n\n<font size=\"5\">We see that it is under select tag and witht the name cboCountry1.\nWe use this identity to bring out the elements of dropdown box.<\/font>\n    \n    \n<font size=\"4\">The .text extension brings out all the contents between the tags which is countries in this case.<\/font>\n","ccc98bad":"<font  size =\"4\">There are lots of other parameters for requests.get  but for this excerise these are out of scope.\nhttps:\/\/docs.python-requests.org\/en\/master\/user\/quickstart\/\nif  you are intersted to know more about .get then go through the above link.<\/font>","525915cc":"<font size=\"6\">Each element in  lst contains information about one single match<\/font>","b0009e9b":"<font size= \"5\">**Let's import the libraries first :**<\/font>","daafe4eb":"<font size= \"5\">**Web Scraping**\n    is a process of extracting large amounts of data from websites.\nIn this notebook we will be using BeautifulSoup python library for webscraping.<\/font>\n\n <font size= \"4\">For this notebook we will webscrape the data which contains all the information about the ODI(one day internationals) played by India since the beginning of the format.\n we are gonna scrape from this URL.\n http:\/\/www.howstat.com\/cricket\/Statistics\/Matches\/MatchListCountry_ODI.asp?A=IND <\/font>\n ![image.png](attachment:6c22b23f-d946-4de9-80d3-422f580f7e41.png)","5568962e":"<font size=\"4\">Now Let's create a beautiful Soup Object using Html text and lxml parser.\nWhat are these Parsers?\nParsing means to breakdown a text into some meaning ful content.\nThis is done by specific rules which are defined by parsers.\n\n<font size=\"5\">**Let's actually do a small excerise to understand importance of parsers.**<\/font>","cf0db715":"<font size=\"6\">**Now come to our Main task scraping for the ODI tabular data.**<\/font>\n![image.png](attachment:15e0af1f-582d-4f96-a070-fc58c6902b5b.png)\n\n<font size=\"5\">we see all the rows with tr tag. Each alternating row has same color. This way we have 2 types of bg colors: #FFFFFF, #E3FBE9\nwe take out both of them and then merge them alternatively.<\/font>","bfa868b8":"<font size=\"5\">See how it added all the additional tags to make the whole html text meaningful. \nThis is what it does, it creates proper tags and make itself easier for identifying tags while scraping.<\/font>\n","23a53435":"<font size=\"5\">Firstly, before scraping the tabular data. I wanted to scrape all the countries that played internation ODI cricket.\nThis Information is present in the drop down Box.<\/font>\n![image.png](attachment:b121fcb8-1bc2-4afa-b11b-75da9814a0f2.png)","08cdfc27":"<font size=\"4\">**Requests.get asks website permission for webscrapping.\nNow the html_text called as Response Object stores the html_text of the URL.\nWe can check the status using **\n> html_text.status_code\n\n**If it prints 200 then we are good to go.**<\/font>","bc19bb7c":"<font size=\"5\">For scraping all the 5 column content for each row we find it through td tag under each tr tag.\n![image.png](attachment:14dd679c-43a1-4b28-950e-5028291d0bd0.png)\nThis is one whole tr block with all 5 column values for one match.<\/font>"}}