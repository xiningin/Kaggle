{"cell_type":{"71e9f6fc":"code","8de25efe":"code","a282de7a":"code","70a67c4b":"code","26ee88d4":"code","0e41dc66":"code","51ecdedb":"code","aa2e79df":"code","cf2242a1":"code","9cbf8771":"code","4fcba1f2":"code","33941a4c":"code","8f549600":"code","7c298557":"code","3ccad3a9":"code","1641ae7a":"code","d43a9162":"code","7e664aff":"code","5a351942":"code","3cf3dfe6":"code","9c4c086b":"code","b144d259":"code","41ccc492":"code","bbf2b249":"code","eb1a7ff1":"code","8099b403":"code","ce8a11b7":"code","6d888528":"code","bb48361c":"code","c74c5f39":"code","6d889f59":"code","b8ed956b":"code","8399bb0c":"code","ea801ec1":"code","7944ee05":"code","ea279cb6":"code","954a2c20":"code","d472b273":"markdown","abd2979b":"markdown","d9d496fa":"markdown","bfc0f2f4":"markdown","5f88c5aa":"markdown"},"source":{"71e9f6fc":"import numpy as np\nimport pandas as pd\nimport pydicom as dicom\nimport cv2\nimport os \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras_preprocessing.image.dataframe_iterator import DataFrameIterator\nimport matplotlib.pylab as plt\nfrom tensorflow.keras.utils import Sequence\nfrom keras.utils import data_utils\nfrom keras.applications.vgg19 import VGG19\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nimport tensorflow as tf\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.core import Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nimport pandas as pd\nfrom glob import glob","8de25efe":"train_df = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\ntest_df = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntrain_array = np.array(train_df['BraTS21ID'])\ntrain_label =  np.array(train_df['MGMT_value'])\ntest_array = np.array(test_df['BraTS21ID'])\ntest_label =  np.array(test_df['MGMT_value'])\nDIM = 512\nNB_CHANNELS = 1\ni = 0\nBATCH_SIZE = 32\na = 0\ntrain_ds = pd.DataFrame(columns = ['path','label'] )\ntest_ds = pd.DataFrame(columns = ['path','label'] )","a282de7a":"len(train_df)","70a67c4b":"test_df","26ee88d4":"print(str(10).zfill(5))","0e41dc66":"dataframe_values = []\nfor a,b in zip(train_df['BraTS21ID'],train_df['MGMT_value']):\n    folders_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{str(a).zfill(5)}')\n    for folder in folders_list :  \n        img_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{str(a).zfill(5)}\/{folder}')\n        for img in img_list : \n            dataframe_values.append({'path' : f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{str(a).zfill(5)}\/{folder}\/{img}','label' : b})\ntrain_ds  = pd.DataFrame.from_dict(dataframe_values)\n\n","51ecdedb":"val_ds = train_ds[300000:].reset_index()\ntrain_ds = train_ds[:300000]","aa2e79df":"train_ds","cf2242a1":"dataframe_values = []\nfor a,b in zip(test_df['BraTS21ID'],test_df['MGMT_value']):\n    folders_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{str(a).zfill(5)}')\n    for folder in folders_list :    \n        img_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{str(a).zfill(5)}\/{folder}')\n        for img in img_list : \n            dataframe_values.append({'path' : f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{str(a).zfill(5)}\/{folder}\/{img}','label' : b})\ntest_ds  = pd.DataFrame.from_dict(dataframe_values)\n","9cbf8771":"test_ds","4fcba1f2":"\"\"\"train_augmentation_parameters = dict(\n    rescale=1.0\/255.0,\n    rotation_range=10,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    brightness_range = [0.8, 1.2])\n\nvalid_augmentation_parameters = dict(\n    rescale=1.0\/255.0)\n\n# Using the training phase generators \ntrain_augmenter = ImageDataGenerator(**train_augmentation_parameters)\nvalid_augmenter = ImageDataGenerator(**valid_augmentation_parameters)\"\"\"","33941a4c":"\"\"\"class Frames_Generator(data_utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self,Sample_array, batch_size=1, dim=(512,512), shuffle=True,  train = True ):\n        'Initialization'\n        self.batch_size = batch_size\n        self.Sample_array = Sample_array \n        self.shuffle = shuffle\n        self.dim = dim\n        self.train = train\n        self.on_epoch_end()\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.Sample_array) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [str(self.Sample_array[k]).zfill(5) for k in indexes]\n        #list_IDs_temp = [20]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp, index)\n        X =  np.array([X])[0]\n        y =  np.array([y])\n        y = y.reshape(y.shape[1])\n        randomize = np.arange(y.shape[0])\n        np.random.shuffle(randomize)\n        X = X[randomize]\n        y = y[randomize]\n        #train_generator = train_augmenter.flow(X ,y,batch_size = 32 )\n        return X, y\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.Sample_array))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp,index):\n        label_train  = []\n        Frame_train = [] \n        global a \n        global b\n        print(list_IDs_temp[0])\n        if self.train :\n            folders_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{list_IDs_temp[0]}')\n            for folder in folders_list : \n                img_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{list_IDs_temp[0]}\/{folder}')\n                for img in img_list :\n                    ds = dicom.dcmread(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{list_IDs_temp[0]}\/{folder}\/{img}').pixel_array\n                    img = cv2.resize(ds,self.dim)\n                    img = img.reshape(self.dim[0],self.dim[1],1)\n                    label_train.append(train_label[index])\n                    Frame_train.append(img)\n        else : \n            folders_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{list_IDs_temp[0]}')\n            for folder in folders_list : \n                img_list = os.listdir(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{list_IDs_temp[0]}\/{folder}')\n                for img in img_list :\n                    ds = dicom.dcmread(f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{list_IDs_temp[0]}\/{folder}\/{img}').pixel_array\n                    img = cv2.resize(ds,self.dim)\n                    img = img.reshape(dim[0],dim[1],1)\n                    label_train.append(test_label[index])\n                    Frame_train.append(img)    \n        return Frame_train, label_train\"\"\"","8f549600":"\"\"\"# Parameters\nparams = {'dim': (512,512),\n          'batch_size': 1,\n          'shuffle': True, \n           'train' : True }\nvalid_params = {'dim': (512,512),\n          'batch_size': 1,\n          'shuffle': True,\n          'train':False}\ntraining_generator = Frames_Generator(train_array, **params)\nvalidation_generator = Frames_Generator(test_array, **valid_params)\"\"\"\n","7c298557":"class Frames_Generator(data_utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self,Sample_df = np.arange(len(train_ds)\/\/BATCH_SIZE-32) , batch_size=1, dim=(512,512), shuffle=True ,train_ds = train_ds,nb_steps = 0 ):\n        'Initialization'\n        self.batch_size = batch_size\n        self.Sample_df = Sample_df\n        self.shuffle = shuffle\n        self.dim = dim\n        self.train_ds = train_ds\n        self.nb_steps = nb_steps\n        self.on_epoch_end()\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.Sample_df) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [str(self.Sample_df[k]).zfill(5) for k in indexes]\n        #list_IDs_temp = [20]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        X =  np.array([X])[0]\n        y =  np.array([y])\n        y = y.reshape(y.shape[1])\n        randomize = np.arange(y.shape[0])\n        np.random.shuffle(randomize)\n        X = X[randomize]\n        y = y[randomize]\n        #train_generator = train_augmenter.flow(X ,y,batch_size = 32 )\n        return X\/255, y\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.Sample_df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        label_train  = []\n        Frame_train = [] \n        i = 0\n        while(i<32) : \n            ds = dicom.dcmread(self.train_ds['path'][self.nb_steps]).pixel_array\n            img = cv2.resize(ds,self.dim)\n            img = img.reshape(self.dim[0],self.dim[1],1)\n            \n            label = self.train_ds['label'][self.nb_steps]\n            label_train.append(self.train_ds['label'][self.nb_steps])\n            Frame_train.append(img)\n            self.nb_steps += 1 \n            i +=1\n            if  self.nb_steps == len(self.train_ds) :\n                self.nb_steps = 0\n        return Frame_train, label_train","3ccad3a9":"len(train_ds)\/\/BATCH_SIZE-32","1641ae7a":"# Parameters\ntrain_params = {'Sample_df':np.arange(len(train_ds)\/\/BATCH_SIZE-32),\n          'dim': (512,512),\n          'batch_size': 1,\n          'shuffle': True, \n           'train_ds' : train_ds,\n         'nb_steps': 0}\ntest_params = {'Sample_df':np.arange(len(test_ds)\/\/BATCH_SIZE-32),\n          'dim': (512,512),\n          'batch_size': 1,\n          'shuffle': True, \n           'train_ds' : test_ds,\n         'nb_steps': 0}\nval_params = {'Sample_df':np.arange(len(val_ds)\/\/BATCH_SIZE-32),\n          'dim': (512,512),\n          'batch_size': 1,\n          'shuffle': True, \n           'train_ds' : val_ds,\n         'nb_steps': 0}\ntraining_generator = Frames_Generator(**train_params)\ntest_generator = Frames_Generator(**val_params)\nvalidation_generator = Frames_Generator(**test_params)\n","d43a9162":"\"\"\"x , y = validation_generator.__getitem__(0)\"\"\"","7e664aff":"arr = np.arange(len(train_ds)\/\/BATCH_SIZE)\nlen(arr)","5a351942":"\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape = (DIM , DIM , NB_CHANNELS)))\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Dropout(0.2))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512))\nmodel.add(Dropout(0.2))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64))\nmodel.add(Dropout(0.2))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(16))\nmodel.add(Dropout(0.2))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\nmodel.build((0,512,512,1))\nmodel.summary()","3cf3dfe6":"\n# Create the base model of VGG19\nvgg19 = VGG19( include_top=False, input_shape = (512, 512, 3) , weights = 'imagenet')","9c4c086b":"vgg19.summary()\n","b144d259":"vgg = Sequential()\nvgg.add(Conv2D(3, (3, 3), padding=\"same\",input_shape = (DIM , DIM , NB_CHANNELS)))\nfor layer in vgg19.layers[1:-1]: # this is where I changed your code\n    vgg.add(layer)    \n# Freeze the layers \n#for layer in model.layers:\n#    layer.trainable = False","41ccc492":"\nvgg.add(Flatten())\nvgg.add(Dense(64 , activation = 'relu'))\nvgg.add(Dense(32 , activation = 'relu'))\nvgg.add(Dense(1, activation='sigmoid'))","bbf2b249":"vgg.summary()\n","eb1a7ff1":"from keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy',\n                                            patience = 1,\n                                            verbose=1,\n                                            factor=0.1,\n                                            min_lr=0.000001)\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy'])","8099b403":"model.fit(training_generator,validation_data = test_generator , epochs = 4,callbacks = [learning_rate_reduction])","ce8a11b7":"model.save(\".\/model.h5\")\n","6d888528":"#model = tf.keras.models.load_model('..\/input\/tumor-model\/model.h5')","bb48361c":"result = model.predict(validation_generator, verbose = True, workers = 2)\n","c74c5f39":"result.shape","6d889f59":"data_dir = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test'\npatients_test = sorted(os.listdir(data_dir))","b8ed956b":"patients_test","8399bb0c":"final_result = []\ni = 0\nfor patient in patients_test:\n    arr = os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/' + patient)\n    length = 0\n    for j in arr : \n        lenn = len(glob('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/' + patient +'\/'+j+'\/*.dcm'))\n        length = lenn + length \n    final_result.append(result[i:i+length].sum()\/length)\n    i += length\n    \n","ea801ec1":"final_result","7944ee05":"test = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\n","ea279cb6":"submission = pd.DataFrame({\"BraTS21ID\": test['BraTS21ID'].apply(lambda x: str(x).zfill(5)), \"MGMT_value\": final_result})\nsubmission\n","954a2c20":"submission.to_csv('submission.csv', index = 0)","d472b273":"# unlabeled Data","abd2979b":"# VGG19 Model ","d9d496fa":"# in this part of code , i use keras dataGenerator  ,the problem here is that it generates the whole folder, so the first layer input for example is [900,512,512,1] which is going to give an OOM Error , so the solution here is to make a 16 (just an example ) FramesDatagenerator","bfc0f2f4":"# Baseline model","5f88c5aa":"# part2 "}}