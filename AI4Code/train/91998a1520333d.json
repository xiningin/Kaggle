{"cell_type":{"31e01f97":"code","350530db":"code","7152d4ff":"code","d8176cdb":"code","ed38246c":"code","4f2cb17e":"code","208ad82f":"code","41dca4f4":"code","4a53056a":"code","86f34916":"code","d902d430":"code","0684dec3":"code","1ba465af":"code","e6feee98":"code","8a9b65a1":"code","e0e95461":"code","ccee7e54":"code","31870c84":"code","cb672e29":"code","137029aa":"code","047899eb":"code","6fea4ea6":"code","9519214d":"code","eef7ef99":"code","27a03a5d":"code","21632dac":"code","af4e63af":"code","bc334e43":"code","05164f48":"code","3e35a8ac":"code","11b9f338":"code","c74fe30a":"markdown","995e285a":"markdown","444ccd18":"markdown","ade28d07":"markdown","fe424cbf":"markdown","60cf93b9":"markdown","293f7d64":"markdown","db9d5deb":"markdown"},"source":{"31e01f97":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n    \nfrom datetime import datetime\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info\n\nimport joblib","350530db":"df_train = pd.read_csv(\"..\/input\/rossmann-store-sales\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/rossmann-store-sales\/test.csv\")\nstore = pd.read_csv(\"..\/input\/rossmann-store-sales\/store.csv\")","7152d4ff":"df_train['Id'] = 0\ndf_train['data_type'] = 1\n\ndf_train.reindex(sorted(df_train.columns), axis='columns')","d8176cdb":"df_test['Customers'] = 9999\ndf_test['Sales'] = 0\ndf_test['data_type'] = 2\n\ndf_test.reindex(sorted(df_test.columns), axis='columns')","ed38246c":"df = pd.concat([df_train, df_test])\ndf = pd.merge(df, store, how='left', on='Store')","4f2cb17e":"df.count()","208ad82f":"# \u6e1b\u5c11\u8a18\u61b6\u9ad4\u7528\u91cf\ndel df_train\ndel df_test\ndel store","41dca4f4":"df.dtypes","4a53056a":"#\u6642\u9593\u8655\u7406\n\ndef is_weekend(dates):\n    results = []\n    for date_value in pd.DatetimeIndex(dates.values):\n        weekno = date_value.weekday()\n        result = 0 if weekno < 5 else 1\n        results.append(result)\n    return results\n\n\ndate_to_season_mapping = {1: [12, 2], 2: [3, 5], 3: [6, 8], 4: [9, 11]}\n\n\ndef date_to_season(dates):\n    results = []\n    date_values = dates.values\n    for date in date_values:\n        month = int(date.split('-')[1])\n        result = 'None'\n        for each_season in date_to_season_mapping:\n            start, end = date_to_season_mapping[each_season]\n            if ((start < end) and (start <= month <= end)) or \\\n               ((start > end) and ((month >= start) or (month <= end))):\n                result = each_season\n                break\n\n        results.append(result)\n    return results\n\nmonth_no_to_name_mapping = [\n    1,2,3,4,5,6,7,8,9,10,11,12\n]\n\ndef date_to_month_name(dates):\n    month_values = pd.DatetimeIndex(dates).month.values\n    results = []\n    for month in month_values:\n        result = month_no_to_name_mapping[month - 1]\n        results.append(result)\n    return results\n\n# def weekday_or_weekend(dates):\n#     results = []\n#     for date_value in pd.DatetimeIndex(dates.values):\n#         weekno = date_value.weekday()\n#         result = \"Weekday\" if weekno < 5 else \"Weekend\"\n#         results.append(result)\n#     return results\n\n# def weekday(dates):\n#     results = []\n#     for date_value in pd.DatetimeIndex(dates.values):\n#         weekno = date_value.weekday()\n#         result = weekno\n#         results.append(result)\n#     return results\n\n\nimport holidays\nholidays_usa = holidays.USA()\n\ndef is_holiday(dates):\n    results = []\n    for date_value in pd.DatetimeIndex(dates.values):\n        result = 1 if date_value.date() in holidays_usa else 0\n        results.append(result)\n    return results\n\n\n# date_to_day_period_mapping = {'Morning': [4, 11], 'Afternoon': [12, 17], \n#                               'Evening': [18, 19], 'Night': [20, 4]}\n# def date_to_day_period(datetimes):\n#     results = []\n#     datetime_values = datetimes.values\n#     for datetime in datetime_values:\n#         _, time_of_day = datetime.split(' ')\n#         hour, _, _ = time_of_day.split(':')\n#         hour = int(hour)\n#         result = 'None'\n#         for each_day_period in date_to_day_period_mapping:\n#             start, end = date_to_day_period_mapping[each_day_period]\n#             if ((start < end) and (start <= hour <= end)) or \\\n#                ((start > end) and ((hour >= start) or (hour <= end))):\n#                 result = each_day_period\n#                 break\n\n#         results.append(result)\n#     return results\n","86f34916":"df['is_weekend'] = is_weekend(df['Date'])\ndf['Month'] = date_to_month_name(df['Date'])\ndf['Year'] = pd.DatetimeIndex(df['Date']).year\ndf['Season'] = date_to_season(df['Date'])\ndf['is_holiday'] = is_holiday(df['Date'])\n\ndf.head()","d902d430":"def lag_feature(df, lags, col):\n    tmp = df[['num_of_week','Store',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['num_of_week','Store', col+'_lag_'+str(i)]\n        shifted['num_of_week'] += i\n        shifted = shifted.groupby(['num_of_week','Store'], as_index=False).agg({col+'_lag_'+str(i): 'mean'})\n        df = pd.merge(df, shifted, on=['num_of_week','Store'], how='left')\n    return df\n\ndf['date'] = df['Date'].apply( lambda x: np.datetime64(x))\ndf['num_of_week'] = (df.date.dt.year-2013)*52 + df.date.dt.week\n\nts = time.time()\ndf = lag_feature(df, [4,13,26,52], 'Sales')\ntime.time() - ts","0684dec3":"# df['date'] = df['Date'].apply( lambda x: np.datetime64(x))\ndf['yyyymm'] = df['date'].dt.strftime('%Y%m')\ndf['last_year'] = df['date'] - np.timedelta64(1, 'Y')\ndf['last_yyyymm'] = df['last_year'].dt.strftime('%Y%m')\n\ntmp = df.groupby(['Store', 'yyyymm'])['Customers'].mean().reset_index()\ndf = df.merge(tmp, left_on = ['Store','last_yyyymm'], right_on = ['Store', 'yyyymm'], how ='left')\n\ndf.drop('yyyymm_y', axis=1, inplace=True)\ndf = df.rename(columns= {'Customers_x':'Customers', 'Customers_y':'last_Customers', 'yyyymm_x':'yyyymm'})","1ba465af":"df.dtypes","e6feee98":"# \u6709\u91cd\u8907\u6578\u503c\u9808\u5148\u8655\u7406\ndf['StateHoliday'] = np.where(df['StateHoliday']=='a', 'a', \n                              np.where(df['StateHoliday']=='b', 'b',\n                                      np.where(df['StateHoliday']=='c', 'c', 0)\n                             ))","8a9b65a1":"cat_col = [\n    'StateHoliday',\n    'StoreType',\n    'Assortment',\n    'PromoInterval'\n]\n\n# SchoolHiliday \u53ea\u67091\/0\u4e0d\u505aone-hot","e0e95461":"df_cat = pd.get_dummies(df[cat_col])\ndf_cat = df_cat.astype(float)","ccee7e54":"num_col = list(set(df.columns.tolist())-set(cat_col))\ndf_num = df[num_col]","31870c84":"print(df_cat.shape)\nprint(df_num.shape)","cb672e29":"df_all = pd.concat([df_num, df_cat], axis=1)","137029aa":"df_all.head()","047899eb":"#dummy\n\n# data_temp = df.copy()\n# data_temp.drop(columns = ['Date'], inplace=True)\n\n# description = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\n# numerical = []\n# categorical = []\n# for col in data_temp.columns:\n#     obs = data_temp[col].size\n#     p_nan = round(data_temp[col].isna().sum()\/obs, 2)\n#     num_nan = f'{p_nan}% ({data_temp[col].isna().sum()}\/{obs})'\n#     dtype = 'categorical' if data_temp[col].dtype == object else 'numerical'\n#     numerical.append(col) if dtype == ['numerical','int64'] else categorical.append(col)\n#     rng = f'{len(data_temp[col].unique())} labels' if dtype == 'categorical' else f'{data_temp[col].min()}-{data_temp[col].max()}'\n#     description[col] = [obs, num_nan, dtype, rng]\n\n# data_num = data_temp.copy()    \n# data_num.drop(columns = categorical, inplace=True)\n\n# data_dummy = pd.get_dummies(data_temp[categorical], drop_first=True)\n# data_dummy.head()\n# display(description)\n\n\n\n# data_dummy.head()\n","6fea4ea6":"exclude_col = [\n    'Date',\n    'date',\n    'yyyymm',\n    'last_year',\n    'last_yyyymm',\n    'data_type',\n    'Id',\n    'Customers'\n]\n\ny_col = ['Sales']","9519214d":"x_col = list(set(df_all.columns.tolist())-set(exclude_col)-set(y_col))","eef7ef99":"x_train = df_all[df_all['data_type']==1][x_col]\ny_train = df_all[df_all['data_type']==1][y_col]","27a03a5d":"x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.3, random_state = 1)","21632dac":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=7,\n    n_estimators=1000,\n    min_child_weight=100, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,    \n    seed=42)\n\nmodel.fit(\n    x_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(x_train, y_train), (x_valid, y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\ntime.time() - ts","af4e63af":"x_test = df_all[df_all['data_type']==2][x_col]","bc334e43":"y_pred = model.predict(x_test)","05164f48":"y_pred","3e35a8ac":"df_y = pd.DataFrame()\ndf_y['Id'] = df_all[df_all['data_type']==2]['Id']\ndf_y['Sales'] = y_pred\ndf_y.to_csv('submission.csv', index=False)","11b9f338":"plot_features(model, (10,14))","c74fe30a":"submission","995e285a":"predict","444ccd18":"feature importance","ade28d07":"import tools & data","fe424cbf":"data processing","60cf93b9":"modeling","293f7d64":"one-hot encoding","db9d5deb":"merge data"}}