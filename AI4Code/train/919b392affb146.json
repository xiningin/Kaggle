{"cell_type":{"3b077b3d":"code","552a52ea":"code","79317a90":"code","b5372093":"code","b8f15165":"code","af16ed29":"code","e2cc40cb":"code","0b660c6f":"code","a51fab90":"code","1db23133":"code","41a76c2c":"code","86171909":"code","2933235d":"code","d23db091":"code","46461629":"code","8ca7d8a2":"code","e83857dd":"code","af122e38":"code","7f807bca":"code","80458542":"code","44510b32":"code","a6890f9e":"code","d36e47d3":"code","58e29424":"code","d866e7ac":"code","a0d9dfe1":"code","70a83296":"code","8bb6ebaf":"code","a7e04cbc":"code","802c2216":"code","bf2a72d6":"code","79cfe3c0":"code","26aa8ab3":"code","8dc11ee7":"code","0c8dc76e":"code","7ed80e66":"code","81989b87":"code","fdfac2e7":"code","2582d53e":"code","2ade75e1":"code","21882bf0":"code","470261ce":"code","523bfe09":"markdown","181d3a76":"markdown","bd31e2ef":"markdown","3acecd6e":"markdown","1aa0df42":"markdown","f7a8d8f2":"markdown","c7b298a6":"markdown","bd04ab3b":"markdown","ab6e7a60":"markdown","9dcc70d1":"markdown","ee5175d7":"markdown","d2d685f3":"markdown","2eceb050":"markdown","c1e967ce":"markdown","09dd0d41":"markdown","4caa3abf":"markdown","5160475b":"markdown","fa793f86":"markdown","4e75e399":"markdown","87eee3a6":"markdown","fe9bd193":"markdown","7a5d505c":"markdown","d8d9d5d3":"markdown","65ef0490":"markdown","83196b04":"markdown","4dc6dc60":"markdown","53d3ae09":"markdown","01f44862":"markdown","4808239e":"markdown","ecbe2f38":"markdown","401f44e5":"markdown","306699dd":"markdown","69b8cb1a":"markdown"},"source":{"3b077b3d":"#importing required packages\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport numpy as np\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nimport missingno as msno\n#Interactive\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nfrom IPython.display import display, HTML","552a52ea":"#Reading data\ngoogledata = pd.read_csv(\"..\/input\/google-play-store-apps\/googleplaystore.csv\")\n\nprint(\"\\n First 5 rows in our dataset\")\ndisplay(googledata.head())\n\nprint(\"\\n Number of rows in the dataset = \" + str(googledata.shape[0]))","79317a90":"\ngoogledata.info()","b5372093":"googledata.describe(include='all')","b8f15165":"# dropping the unwanted Genres column\ngoogledata.drop(\"Genres\",axis=1, inplace=True)","af16ed29":"# separating Last Updated column into 2 different columns and then dropping LAst Updated column\ngoogledata[['Date','Year']] = googledata[\"Last Updated\"].str.split(\",\",expand=True)\ngoogledata.drop(\"Last Updated\", axis=1, inplace=True)\n\n# Removing the special characters from the Install column \ngoogledata['Install1'] = googledata[\"Installs\"].str.replace('+','')\ngoogledata['Install']=googledata['Install1'].str.replace(',','')\ngoogledata.Size = [x.strip().replace('M', '') for x in googledata.Size]\ngoogledata.Size = [x.strip().replace('k', '') for x in googledata.Size]\n\n\n#dropping all the ewxtra columns that were created on the way\ngoogledata.drop(\"Installs\",axis=1, inplace =True)\ngoogledata.drop(\"Install1\",axis=1, inplace =True)\n","e2cc40cb":"googledata.head(7)","0b660c6f":"googledata.isnull().sum()","a51fab90":"#Rating column\ngoogledata['Rating'].fillna(googledata['Rating'].mean(),inplace=True)\n\n# Current Version\ngoogledata['Current Ver'].fillna(method='ffill',inplace=True)\n\n#Androi Version\ngoogledata['Android Ver'].fillna(method='ffill',inplace=True)\n\n# Type\ngoogledata['Type'].fillna(method='ffill',inplace=True)\n\n#Content Rating\ngoogledata['Content Rating'].fillna(method='ffill',inplace=True)\n\n#Year\ngoogledata['Year'].fillna(method='ffill',inplace=True)","1db23133":"googledata.isnull().sum()","41a76c2c":"googledata['Rating'].max()","86171909":"googledata[googledata['Rating'] == 19.0]","2933235d":"googledata.drop([10472],inplace=True)","d23db091":"googledata[\"Reviews\"]= googledata.Reviews.apply(lambda x: int(x))\ngoogledata[\"Rating\"]= googledata.Reviews.apply(lambda x: int(x))\ngoogledata[\"Year\"]= googledata.Year.apply(lambda x: int(x))\ngoogledata[\"Price\"]= googledata.Price.apply(lambda x: str(x).replace(\"$\",\"\"))\ngoogledata[\"Price\"] = googledata.Price.apply(lambda x: float(x))\ngoogledata[\"Size\"] = googledata[\"Size\"].apply(lambda x: float(x) if x != \"Varies with device\" else str(x))\n\ngoogledata['Install']= [int(x) if x.isnumeric() else x for x in googledata['Install']]","46461629":"googledata.dtypes","8ca7d8a2":"# IDENTIFYING NUMERICAL FEATURES\n\nnumeric_data = googledata.select_dtypes(include=np.number) # select_dtypes selects data with numeric features\nnumeric_col = numeric_data.columns                                                                \n\n# we will store the numeric features in a variable\n\nprint(\"Numeric Features:\")\nprint(numeric_data.head())","e83857dd":"# IDENTIFYING CATEGORICAL FEATURES\n\ncat_data = googledata.select_dtypes(exclude=np.number) # select_dtypes selects data with numeric features\ncat_col = cat_data.columns                                                                \n\n# we will store the numeric features in a variable\n\nprint(\"Numeric Features:\")\nprint(cat_data.head())","af122e38":"class_values = (googledata['Install'].value_counts()\/googledata['Install'].value_counts().sum())*100\nprint(class_values)","7f807bca":"#Number of categories of apps in the store.\ndef plot_number_category():\n    fig, ax = plt.subplots()\n    fig.set_size_inches(15, 7)\n    fig.autofmt_xdate()\n    countplot=sns.categorical.countplot(googledata.Category,ax=ax)\n    plt.xticks(rotation = 90)\n    plt.show(countplot)\n\nplot_number_category()\n\n# Tabular representation\ntop_cat=googledata.groupby('Category').size().reset_index(name='Count').nlargest(5,'Count')\ndisplay(top_cat)\n","80458542":"top5_cat = top_cat['Category'].tolist()\ndata_top5 = googledata.groupby('Category')['Install'].agg('sum').loc[top5_cat].reset_index(name='Number_Installations')\ndata =  googledata.groupby('Category')['Install'].agg('sum').reset_index(name='Number_Installations')","44510b32":"fig = plt.figure(figsize=(10,5))\ntitle=plt.title('Comparing top 5 category on the basis of Installs')\nbar=sns.barplot(y=data_top5['Category'],x=data_top5['Number_Installations'])\nplt.show(bar)","a6890f9e":"plt.figure(figsize=(15,15))\nplt.title(\"Comparing all categories to Install\")\nsns.barplot(y=data[\"Category\"],x=data['Number_Installations'])\nplt.show(bar)","d36e47d3":"data_cont =  googledata.groupby('Content Rating')['Install'].agg('sum').reset_index(name='Number_Installations')\nplt.figure(figsize=(10,5))\nsns.barplot(x=data_cont['Content Rating'], y=data_cont['Number_Installations'])\nplt.show()","58e29424":"data_cont =  googledata.groupby('Content Rating')['Install'].agg('sum').reset_index(name='Number_Installations')\nplt.figure(figsize=(10,5))\nsns.barplot(x=data_cont['Content Rating'], y=data_cont['Number_Installations'])\nplt.show()","d866e7ac":"top_app = googledata.groupby('App').size().reset_index(name='Count').nlargest(5,'Count')\ntop5_app = top_app['App'].tolist()\ndata_app = googledata.groupby('App')['Install'].agg('sum').loc[top5_app].reset_index(name='Number_Installations')\nplt.figure(figsize=(10,5))\nsns.barplot(x=data_app['Number_Installations'], y=data_app['App'])\nplt.show()","a0d9dfe1":"x= googledata.Type.value_counts()\nlabel= [\"Paid\",\"free\"]\nmycolors = [\"hotpink\",\"black\"]\nplt.pie(x,labels= label,autopct= \"%1.1f%%\", colors = mycolors)\nplt.show()","70a83296":"x= googledata.groupby(\"App\").Install.sum().sort_values(ascending= False).head(10)\nsns.barplot(x.values,x.index)","8bb6ebaf":"correlation = numeric_data.corr() \n#The value 'numeric_data' is taken from above when we found out the numerical and categorical variables from the dataset \n#after the data type conversions\n\ncolour = sns.color_palette(\"cubehelix\")\nsns.heatmap(correlation, cmap=colour)","a7e04cbc":"correlation","802c2216":"#number of installations per Content rating\ninstall_sum_content = googledata.groupby('Content Rating')['Install'].agg('sum').reset_index(name='Number_Installations')\n\n# number of installations per app per content rating\napp_sum_content = googledata.groupby('Content Rating')['Install'].size().reset_index(name='Number_Apps')","bf2a72d6":"install_sum_content","79cfe3c0":"app_sum_content","26aa8ab3":"fig=plt.figure(figsize=(12,6))\n    \ntitle=plt.title('Comparison of content ratings (Number of Installations)')\ncontent_bar = sns.barplot(x=install_sum_content['Content Rating'],y=install_sum_content['Number_Installations'])\nplt.show(content_bar)","8dc11ee7":"fig=plt.figure(figsize=(12,6))\ntitle=plt.title('Comparision of content ratings (Number of Apps in Market)')\ncontent_bar = sns.barplot(x=app_sum_content['Content Rating'],y=app_sum_content['Number_Apps'])\nplt.show(content_bar) ","0c8dc76e":"#Temporary dataframe with improved comparison metric for content rating\ncontent=pd.DataFrame()\ncontent['Content Rating'] = app_sum_content['Content Rating']\ncontent['No_Installations\/Total_Apps']=install_sum_content['Number_Installations']\/app_sum_content['Number_Apps']","7ed80e66":"content","81989b87":"#Visualize content\nfigure=plt.figure(figsize=(12,7))\ntitle=plt.title('Content Rating Comparision')\nbar=sns.barplot(x=content['Content Rating'],y=content['No_Installations\/Total_Apps'])\nplt.show(bar)","fdfac2e7":"install_sum_type = googledata.groupby('Type')['Install'].agg('sum').reset_index(name='Number_Installations')\n\nfig=plt.figure(figsize=(12,6))\n    \ntitle=plt.title('Comparison of  types (Number of Installations)')\ncontent_bar = sns.barplot(x=install_sum_type['Type'],y=install_sum_type['Number_Installations'])\nplt.show(content_bar)","2582d53e":"googledata['Name_check']=['>2 words' if len(x.split())>2 else '<=2words' for x in googledata['App'] ]\n\ndata_install= googledata.groupby('Name_check')['Install'].agg('sum').reset_index(name='Number_Installations')\ndata_apps= googledata.groupby('Name_check').size().reset_index(name='Number_Apps')\n\n\nfig,axes = plt.subplots(figsize=(15,3),ncols=2, nrows=1)\n\ntitle=axes[0].set_title(\"No. of Installations\", y = 1.1)\ntitle=axes[1].set_title(\"No of Apps\", y = 1.1)\n\nplot1=sns.barplot( x=data_install['Name_check'],y=data_install['Number_Installations'] , ax=axes[0])\n\nplot2=sns.barplot( x=data_apps['Name_check'],y=data_apps['Number_Apps'] , ax=axes[1])\n\nplt.show(fig)\n","2ade75e1":"# No. of installation \/ No. of apps\n\nfigure=plt.figure(figsize=(12,5))\ntitle=plt.title(\"Installations\/Total Apps\", y = 1.0)\nplot3=sns.barplot( x=data_apps['Name_check'],y=data_install['Number_Installations']\/data_apps['Number_Apps'] ,palette=sns.color_palette(palette=\"Set1\",n_colors=2,desat=.8))\nplt.show(figure)","21882bf0":"#Extracting the size variable and converting it into float data type\ngoogledata_num = googledata[googledata[\"Size\"]!='Varies with device']\ngoogledata_num[\"Size\"] = [float(x) if isinstance(x,float) else x for x in googledata_num[\"Size\"]]\n\n#creating new temporary data frame iwth just Install and Size variables.\ngdnum = pd.DataFrame()\ngdnum[\"Size\"] = googledata_num[\"Size\"]\ngdnum[\"Install\"] = googledata_num[\"Install\"]\ngdnum.head()","470261ce":"# Using violin plot to plot the relation \nplt.figure(figsize=(20,10))\nsns.violinplot(x=gdnum.Install, y=gdnum.Size)\nplt.xticks(rotation = 90)","523bfe09":"We can see from the plot that there is a profound impact by the size of the app on the number of installations. \n\n- The tiny white circle in middle of each plot shows the median value of each value of installations. Across the plot, we can see the median grows steadliy higher.\n- It is found that at the lower end of the Install axis, there is a higher number of outliers with respect to the size of the apps. \n- As we progress across the Install axis, the number of outliers decreases and the number of installations increases\n- As the number of installations reaches the maximum value, we see that the app size has reached the lowest values, peaking at posiibly, 100 -110 MB.\n\nFrom this we can safely predict that bigger the app, lesser the chance for it to be installed","181d3a76":"## Correlation\n\n<b>Correlation<\/b> is a statistical term describing the degree to which two variables move in coordination with one-another. Correlation coefficients are used to measure the strength of the linear relationship between two variables. There are different types of correlation:\n\n- If the two variables move in the same direction, then those variables are said to have a positive correlation. In this case, the correlation coefficient is greater than zero.\n- If they move in opposite directions, then they have a negative correlation. In this case, the correlation coefficient is less than zero.\n- In certain cases, the correlation coefficient is exactly zero. This means that there is no relation between the variables.\n\nThe value of correlation coefficent varies anywhewre between 1 and -1. The closer the value is to 0, the weaker is the relation and the closer it is to 1 or -1, the stronger is the relation.\n","bd31e2ef":"Now that all the null values are removed, columns are split appropriately and unwanted columns are dropped, let us now move on to actually analyzing each variable and whether or not, our target variable, <b><i>Install<\/i><\/b> is dependent on it. Also, we can plot the inferred dependencies.","3acecd6e":"Next, we need to deal with the missing values in the data to be able to analyze it.\n\nOne of the main steps in data preprocessing is handling missing data. Missing data means absence of observations in columns that can be caused while procuring the data, lack of information, incomplete results etc.\n\nFeeding missing data to your machine learning model could lead to wrong prediction or classification. Hence it is necessary to identify missing values and treat them","1aa0df42":"We can see a definite variations in the our plot. It can be inferred that users prefer apps with smaller names(2 words or lesser) over apps that have long tedious names. As a user myself, I cannot agree more on this.","f7a8d8f2":"Lastly, we are taking the Size variable and trying to find whether it has any profound effect on our target variable, Install. We have cleaned the Size variable but there still remains a String value in the column, 'Varies with device'. Hence we are creating a temporary dataframe with only the float values and using that to find the relation between Install and Size.","c7b298a6":"<center><h1 style=\"color:lightsalmon\"><b>Google Playstore Analysis and Visualization<\/b><\/hi><\/center>","bd04ab3b":"## Description of Dataset","ab6e7a60":"Here we can conclude that the variable 'Type' does not have any influence as most installed apps are free.","9dcc70d1":"<h3>We are using a csv file \"googleplaystore.csv\", available on Kaggle.  \nBefore getting into actual EDA, we will familiarize with the variables :- <\/h3> \n\n    1) App :- Name of the App\n    2) Category :- Category under which the App falls.\n    3) Rating :- Application's rating on playstore\n    4) Reviews :- Number of reviews of the App.\n    5) Size :- Size of the App.\n    6) Install :- Number of Installs of the App\n    7) Type :- If the App is free\/paid\n    8) Price :- Price of the app (0 if it is Free)\n    9) Content Rating :- Appropiate Target Audience of the App.\n    10) Genres:- Genre under which the App falls.\n    11) Last Updated :- Date when the App was last updated\n    12) Current Ver :- Current Version of the Application\n    13) Android Ver :- Minimum Android Version required to run the App\n","ee5175d7":"## Business Task\n\nWe are on a venture to find out how many times an app will be downloaded based on the Google Play Apps Data set.This Dataset gives information about the Ratings, Reviews, Size, Genre etc of an app. We are here to find out which of this variable have an undenibale effect and influence of the app being published on the Google Play store.","d2d685f3":"Now let us convert some of the categorical variables into numerical for ease of analysis.","2eceb050":"So, as the trend of the visualization goes, we can see that it can be a bit difficult to draw an inference from the analysis done. But, there is a small step that can be done to check the relation between the variables in our data. Let us look in to that next.","c1e967ce":"### Numerical And Categorical Columns","09dd0d41":"We see that this entry of our dataset is having a Rating of 19.0 which is way higher than the maximum rating of 5.0. Also, The value in the Reviews column has an alphabet which makes it a lone entry to have so. Hence we are removing this particular row to make our analysis easier. ","4caa3abf":"We can see that out of our 10000 rows, almost 1500 of the rows have null values in place of Ratings. Hence we are taking the mean of the Rating column and filling up the null values.\n\nIn case of other variables like, Type, Android Ver etc, the number of null values are too negligible that one can either drop it or fill it. I am just using a fillna command with forward fill to remove null values in the rest of the columns.","5160475b":"Here we did a plot between the content rating and number of installations by total apps. We see that there are significant amoutn of installations. Hence, we can deduce that Content Rating too play an important part in predicting our Target variable, Install.\n\nLet us now try to find out if any variation in data is caused depending on whether the app is free or paid.","fa793f86":"We can see that there are many NaN (missing) values in our dataset, especially in the Rating column.\n\nThere are two methods to deal with missing data:\n- Dropping them\n- Imputing them.\nDepending on the case we can allow a specific proportion of missing values, beyond which we might want to drop the variable from analysis. But this varies from case to case on the amount of information you think the variable has. \n\nIf the information contained in the variable is not that high, you can drop the variable if it has more than 50% missing values. There are projects \/ models where imputation of even 20 - 30% missing values provided better results - the famous Titanic dataset on Kaggle being one such case. Age is missing in ~20% of cases, but you benefit by imputing them rather than ignoring the variable.","4e75e399":"Since the <b>Installs<\/b> is our target variable, we are looking only at teh correlation cofficient values between Install and other variables. Let us take a look at the values:\n\n- Year vs Install : 0.089368\n- Price vs Install : -0.011689\n- Reviews vs Install : 0.643122\n- Rating vs Install : 0.643122\n\nWe can see that Year and Price do not have any significant impact on Install variable.\nBut Reviews and Ratings do seem to have an impact on our target variable.\n","87eee3a6":"## Conclusion\n\nWe have reached the end of our EDA on the Google Playstore dataset. Taking number of isntallationsa s our dataset, we have found out the following infereneces:\n\n- Ratings have an effect on our target variable. The higher the rating, more people will be inclined to download the app.\n- Similarly, the better the Reviews, more are the chances for the app to be downloaded by more people.\n- Apps with shorter names, preferably less than 3 words in name, have a higher chance of being downloaded by the general public.\n- People are always inclined to download apps that are free of cost.\n- Apps that falls under the Content Rating, 'Everyone', 'Teens' and 'Everyone 10+' has the highest chance to be downloaded. For prospective app developers and publishers, it will be worthwhile to invest in apps falling under these Content Ratings.\n- The apps with smaller sizes have more chance to be downloaded.\n- Subway surfer is the most downloaded app followed by Instagram, Hangouts and Google Drive\n- 92.6% of the apps in the app store are free.","fe9bd193":"Next, we are taking the name of the apps and checking whether there is any influence of this variable on the number of installations.","7a5d505c":"Thank you for staying with me till the end. Please let know your suggestions below.","d8d9d5d3":"### In this notebook, we are aiming to understand the trend of current Google Playstore market.  \n\nWe are trying to create an analysis and visualization to interpret our findings on the Google Play Apps Dataset, available on Kaggle. This is my first ever project on Kaggle. So, pardon the errors and shortcomings that may come up in this notebook.\n\n\n------------------------------------------------------------------------------------------------------\n    ","65ef0490":"This shows that the top most category is <b>Family<\/b> followed by Games, Tools, Medical and Business","83196b04":"### Features Engineering  \n\nOur target variable is <b><i>'Installs'<\/i><\/b>\nAs we can see from the above snippet of the csv file, the  Genres and Category columns are somewhat same. So we are dropping the Genres column as Category column is easier to analyze.\n\nBefore getting into the Analysis and Visualization part, we need to first ensure that the format of our our data is ready to be analyzed.\n    ","4dc6dc60":"Let us now check if categorical variables have an effect","53d3ae09":"Looking at the dataset, we think we can identify the categorical and continuous columns in it. Right? But it might also be possible that the numerical values are represented as strings in some feature. Or the categorical values in some features might be represented as some other datatypes instead of strings. Hence it's good to check for the datatypes of all the feature","01f44862":"### Data Cleaning","4808239e":"### Missing Values","ecbe2f38":"On studying the dataset further, it was found that there was a data with some kind of weird anomaly. Let us find out the row in the data and purge it.","401f44e5":"First step is to Load the data","306699dd":"The above graphs depicts that there is a significant number of installations on content other than Everyone like Teens and Evryone 10+. SO let us know break it down and look for more information on this one.","69b8cb1a":"## Visualization"}}