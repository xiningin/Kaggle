{"cell_type":{"729423e0":"code","4c8598a4":"code","6633423c":"code","0ae5c3ca":"code","daacf8ac":"code","0f9d3288":"code","a415c307":"code","2527dee8":"code","fdfa0c00":"code","003464b6":"code","a5940b0f":"code","e7636e4a":"code","8349e075":"code","9b04a413":"code","1c65483d":"code","ffe6f359":"code","93b05f0c":"code","5c2470ba":"code","168f8bf4":"code","5e2037dc":"code","236e7c0a":"code","aa06b569":"code","b8e14dcd":"code","c34180f8":"code","5cb41852":"code","06979a5e":"code","f4a68c70":"code","3d3c79b3":"code","f30f94be":"code","493aadd6":"code","de52ff76":"code","ae01fd63":"code","f7f46dbe":"code","8438be0e":"code","55aa48c9":"code","13ae6a27":"code","7266d5fb":"code","02cd00fb":"code","1b0de3ba":"code","bdf0a862":"code","bc9c2742":"code","7b0ed4df":"code","3f81d490":"code","3373dd0a":"markdown","7d8928c2":"markdown","53f0f5a0":"markdown","56007e93":"markdown","99e041f5":"markdown","19670931":"markdown","824fe906":"markdown","4ac30ed1":"markdown","e8fa770e":"markdown","c0c6d27b":"markdown","689f3fee":"markdown","37eededb":"markdown","5282d132":"markdown","1de4cb98":"markdown","10376024":"markdown","143d255f":"markdown","0373cf6c":"markdown","c4a93473":"markdown","bd9f3fcf":"markdown","ffb0dfc4":"markdown","a260cbb3":"markdown","e2ba6673":"markdown","aec601b7":"markdown","fb9bd616":"markdown","bb6f071c":"markdown","60b447db":"markdown","3869c03c":"markdown","256eeb77":"markdown","7fe88ecc":"markdown","e0b61762":"markdown","1240bd30":"markdown","d693f1b5":"markdown"},"source":{"729423e0":"!pip install emoji","4c8598a4":"import re\nimport regex\nimport pandas as pd\nimport numpy as np\nimport emoji\nimport plotly.express as px\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n% matplotlib inline","6633423c":"! git clone https:\/\/github.com\/amueller\/word_cloud.git\n% cd word_cloud\n! pip install .","0ae5c3ca":"def startsWithDateAndTime(s):\n    pattern = '^([0-9]+)(\\\/)([0-9]+)(\\\/)([0-9]+), ([0-9]+):([0-9][0-9]) (AM|PM|am|pm)? -'\n    result = re.match(pattern, s)\n    if result:\n        return True\n    return False","daacf8ac":"def FindAuthor(s):\n    patterns = [\n        '([\\w]+):',                        # First Name\n        '([\\w]+[\\s]+[\\w]+):',              # First Name + Last Name\n        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # First Name + Middle Name + Last Name\n        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number (India)\n        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Mobile Number (US)\n        '([\\w]+)[\\u263a-\\U0001f999]+:',    # Name and Emoji              \n    ]\n    pattern = '^' + '|'.join(patterns)\n    result = re.match(pattern, s)\n    if result:\n        return True\n    return False","0f9d3288":"def getDataPoint(line):   \n    splitLine = line.split(' - ') \n    dateTime = splitLine[0]\n    date, time = dateTime.split(', ') \n    message = ' '.join(splitLine[1:])\n    if FindAuthor(message): \n        splitMessage = message.split(': ') \n        author = splitMessage[0] \n        message = ' '.join(splitMessage[1:])\n    else:\n        author = None\n    return date, time, author, message\n","a415c307":"parsedData = [] # List to keep track of data so it can be used by a Pandas dataframe\n\n#conversationPath = '\/content\/WAMEME.txt' #replace 'WAMEME.txt' with the name of your file\nconversationPath = '..\/input\/wameme\/WAMEME.txt'\n\n\nwith open(conversationPath, encoding=\"utf-8\") as fp:\n    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n    messageBuffer = [] \n    date, time, author = None, None, None\n    while True:\n        line = fp.readline() \n        if not line: \n            break\n        line = line.strip() \n        if startsWithDateAndTime(line): \n            if len(messageBuffer) > 0: \n                parsedData.append([date, time, author, ' '.join(messageBuffer)]) \n            messageBuffer.clear() \n            date, time, author, message = getDataPoint(line) \n            messageBuffer.append(message) \n        else:\n            messageBuffer.append(line)","2527dee8":"df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])","fdfa0c00":"df.head()","003464b6":"df.info()","a5940b0f":"df.Author.unique()","e7636e4a":"df = df.dropna()\ndf.info()","8349e075":"df.Author.unique()","9b04a413":"total_messages = df.shape[0]\nprint(total_messages)","1c65483d":"media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\nprint(media_messages)","ffe6f359":"def split_count(text):\n\n    emoji_list = []\n    data = regex.findall(r'\\X', text)\n    for word in data:\n        if any(char in emoji.UNICODE_EMOJI for char in word):\n            emoji_list.append(word)\n\n    return emoji_list\n\ndf[\"emoji\"] = df[\"Message\"].apply(split_count)","93b05f0c":"emojis = sum(df['emoji'].str.len())\nprint(emojis)","5c2470ba":"URLPATTERN = r'(https?:\/\/\\S+)'\ndf['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\n","168f8bf4":"links = np.sum(df.urlcount)","5e2037dc":"print(\"Group Wise Stats\")\nprint(\"Messages:\",total_messages)\nprint(\"Media:\",media_messages)\nprint(\"Emojis:\",emojis)\nprint(\"Links:\",links)","236e7c0a":"media_messages_df = df[df['Message'] == '<Media omitted>']","aa06b569":"messages_df = df.drop(media_messages_df.index)","b8e14dcd":"messages_df.info()","c34180f8":"messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\nmessages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\nmessages_df[\"MessageCount\"]=1","5cb41852":"messages_df.head()","06979a5e":"messages_df[\"emojicount\"]= df['emoji'].str.len()","f4a68c70":"# Creates a list of unique Authors - ['Manikanta', 'Teja Kura', .........]\nl = messages_df.Author.unique()\n\nfor i in range(len(l)):\n  # Filtering out messages of particular user\n  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n  # req_df will contain messages of only one particular user\n  print(f'Stats of {l[i]} -')\n  # shape will print number of rows which indirectly means the number of messages\n  print('Messages Sent', req_df.shape[0])\n  #Word_Count contains of total words in one message. Sum of all words\/ Total Messages will yield words per message\n  words_per_message = (np.sum(req_df['Word_Count']))\/req_df.shape[0]\n  print('Words per message', words_per_message)\n  #media conists of media messages\n  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n  print('Media Messages Sent', media)\n  # emojis conists of total emojis\n  emojis = sum(req_df['emoji'].str.len())\n  print('Emojis Sent', emojis)\n  #links consist of total links\n  links = sum(req_df[\"urlcount\"])   \n  print('Links Sent', links)   \n  print()","3d3c79b3":"total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))\ntotal_emojis = len(total_emojis_list)\nprint(total_emojis)","f30f94be":"total_emojis_list = list([a for b in messages_df.emoji for a in b])\nemoji_dict = dict(Counter(total_emojis_list))\nemoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\nprint(emoji_dict)","493aadd6":"emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\nemoji_df","de52ff76":"import plotly.express as px\nfig = px.pie(emoji_df, values='count', names='emoji')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","ae01fd63":"# Creates a list of unique Authors - ['Manikanta', 'Teja Kura', .........]\nl = messages_df.Author.unique()\nfor i in range(len(l)):\n  dummy_df = messages_df[messages_df['Author'] == l[i]]\n  total_emojis_list = list([a for b in dummy_df.emoji for a in b])\n  emoji_dict = dict(Counter(total_emojis_list))\n  emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n  print('Emoji Distribution for', l[i])\n  author_emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n  fig = px.pie(author_emoji_df, values='count', names='emoji')\n  fig.update_traces(textposition='inside', textinfo='percent+label')\n  fig.show()","f7f46dbe":"def f(i):\n  l = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n  return l[i];\nday_df=pd.DataFrame(messages_df[\"Message\"])\nday_df['day_of_date'] = messages_df['Date'].dt.weekday\nday_df['day_of_date'] = day_df[\"day_of_date\"].apply(f)\nday_df[\"messagecount\"] = 1\nday = day_df.groupby(\"day_of_date\").sum()\nday.reset_index(inplace=True)","8438be0e":"fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)\nfig.update_traces(fill='toself')\nfig.update_layout(\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n    )),\n  showlegend=False\n)\nfig.show()","55aa48c9":"date_df = messages_df.groupby(\"Date\").sum()\ndate_df.reset_index(inplace=True)\nfig = px.line(date_df, x=\"Date\", y=\"MessageCount\")\nfig.update_xaxes(nticks=20)\nfig.show()","13ae6a27":"auth = messages_df.groupby(\"Author\").sum()\nauth.reset_index(inplace=True)\nfig = px.bar(auth, y=\"Author\", x=\"MessageCount\", color='Author', orientation=\"h\",\n             color_discrete_sequence=[\"red\", \"green\", \"blue\", \"goldenrod\", \"magenta\"],\n             title=\"Explicit color sequence\"\n            )\n\nfig.show()","7266d5fb":"messages_df['Time'].value_counts().head(10).plot.barh() # Top 10 Times of the day at which the most number of messages were sent\nplt.xlabel('Number of messages')\nplt.ylabel('Time')","02cd00fb":"messages_df['Date'].value_counts().head(10).plot.barh()\nprint(messages_df['Date'].value_counts())\nplt.xlabel('Number of Messages')\nplt.ylabel('Date')","1b0de3ba":"messages_df.iloc[messages_df['Word_Count'].argmax()]","bdf0a862":"text = \" \".join(review for review in messages_df.Message)\nprint (\"There are {} words in all the messages.\".format(len(text)))","bc9c2742":"  stopwords = set(STOPWORDS)\n  stopwords.update([\"ra\", \"ga\", \"na\", \"ani\", \"em\", \"ki\", \"ah\",\"ha\",\"la\",\"eh\",\"ne\",\"le\",\"ni\",\"lo\",\"Ma\",\"Haa\",\"ni\"])\n  # Generate a word cloud image\n  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n  # Display the generated image:\n  # the matplotlib way:\n  \n  plt.figure( figsize=(10,5))\n  plt.imshow(wordcloud, interpolation='bilinear')\n  plt.axis(\"off\")\n  plt.show()","7b0ed4df":"l = messages_df.Author.unique()\nfor i in range(len(l)):\n  dummy_df = messages_df[messages_df['Author'] == l[i]]\n  text = \" \".join(review for review in dummy_df.Message)\n  stopwords = set(STOPWORDS)\n  stopwords.update([\"ra\", \"ga\", \"na\", \"ani\", \"em\", \"ki\", \"ah\",\"ha\",\"anta\",\"kuda\",\"ante\",\"la\",\"eh\",\"Nen\",\"ne\",\"haa\",\"Haa\",\"le\"])\n  # Generate a word cloud image\n  print('Author name',l[i])\n  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n  # Display the generated image:\n  # the matplotlib way:\n  \n  plt.figure( figsize=(10,5))\n  plt.imshow(wordcloud, interpolation='bilinear')\n  plt.axis(\"off\")\n  plt.show()","3f81d490":"\"\"","3373dd0a":"We successfully removed None author.","7d8928c2":"It might be interesting to count the number of letters and words used by each author in each message. So, let us add 2 new columns to the data frame called \u201cLetter_Count\u201d and \u201cWord_Count\u201d, using the following code:","53f0f5a0":"#Author wise stats","56007e93":"# Whatsapp Chat Data Analysis","99e041f5":"# Group Wise Stats.","19670931":"### **Message Having Maximum number of words**","824fe906":"# **Data Preparation:**\n\n\nThis plain text file will have to be parsed and tokenized in a meaningful manner in order to be served (stored) in a Pandas dataframe.\n\nLet us consider just a single line from the text (which we will call \u201craw text\u201d) and see how we can extract relevant columns from it:\n\n18\/06\/17, 9:47 PM - Teja: Why do you have 2 numbers?\n\nIn our sample line of text, our main objective is to automatically break down the raw message into 4 tokens.\n\n{Date}, {Time} - {Author}: {Message}\n\n{18\/06\/17}, {9:47 PM} - {Teja}: {Why do you have 2 numbers?}\n\n\n\n\n","4ac30ed1":"### **Chatter**","e8fa770e":"**Notes**\n<br>\n1. Run this notebook in Google Colab.<br>\nTo run the notebook in Kaggle using the input, suggestion are appreciated in the comment or [connect with me](https:\/\/www.linkedin.com\/in\/ashraf-ul\/)\n<br>\n2. For data collection:Open Whatsapp chat > Go to Settings > Click on Export Chat > Click on without media.\n<br>\n3. This notebook contains code for data with 12h time format.So if you use 24h time format in your phone, then switch to 12h time format and then export chat.\n<br><br>\nTo analyze your own chat,you need to make one change [here](#1)","c0c6d27b":"### **The early bird**\n[connect for collaboration](https:\/\/www.linkedin.com\/in\/ashraf-ul\/)","689f3fee":"# To analyze your chat file make changes in the cell below<a id=\"1\"><\/a>","37eededb":"### **Number of messages as times move on**","5282d132":"### **The most happening day was -**","1de4cb98":"**None** which is the first element in array indicates few messages which do not have authors like,\n\n\n*   Group was created.\n*   Teja was added and so on.\n\n","10376024":"### **Day wise Distribution**","143d255f":"Working on improvement : \"Sentiment analysis on messages\"<br>\nIf you would like to collaborate [connect with me](https:\/\/www.linkedin.com\/in\/ashraf-ul\/)\n<br><br><br>\nNotebook Credit : [Whatsapp Group Chat Analysis using Python and Plotly - Saiteja Kura](https:\/\/medium.com\/towards-artificial-intelligence\/whatsapp-group-chat-analysis-using-python-and-plotly-89bade2bc382)","0373cf6c":"### The Late Owl\n[connect for collaboration](https:\/\/www.linkedin.com\/in\/ashraf-ul\/)","c4a93473":"### Person Wise Emoji Distribution","bd9f3fcf":"Let us now find out the total Media Messages","ffb0dfc4":"We can see '\ud83d\ude02 '   dominates the list.","a260cbb3":"# Some more Stats","e2ba6673":"# Emoji Stats","aec601b7":"## Let us Separate the media messages and text messages","fb9bd616":"### Emoji distribution visualisation","bb6f071c":"Let us remove the messages created by None","60b447db":"# Sentiment Analysis \n[connect for collaboration](https:\/\/www.linkedin.com\/in\/ashraf-ul\/)","3869c03c":"## Printing Participants","256eeb77":"### **Word Cloud**","7fe88ecc":"### **When are the group members most active?**","e0b61762":"### Unique emojis used in group","1240bd30":"### Most used emoji","d693f1b5":"# Most used Emoji in Group"}}