{"cell_type":{"ee57eb5a":"code","0837c511":"code","753c92b9":"code","f32b3732":"code","7a551334":"code","745afc96":"code","3eb1af68":"code","24030a44":"code","a77beba9":"code","095ad321":"code","0f575f2d":"code","860d664e":"code","723d3af0":"code","c749455a":"code","2a0544d9":"code","48e7b10f":"code","d9edede2":"code","6c53e877":"code","05528dc0":"code","eb947bd4":"code","44a81bd5":"code","2be5d095":"code","ad8151bf":"code","8ee69488":"markdown","23a65b5b":"markdown","dd816ba0":"markdown","b42820f7":"markdown"},"source":{"ee57eb5a":"# Importing necessary Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n","0837c511":"# Reading the dataset using pandas built-in function 'read_csv'\n\nds = pd.read_csv('\/kaggle\/input\/sloan-digital-sky-survey\/Skyserver_SQL2_27_2018 6_51_39 PM.csv')\nds","753c92b9":"# GETTING INFO OF dataset\nds.info()","f32b3732":"# Checking whether the dataset have 'nan' values or not\n\nds.isnull().sum()","7a551334":"# Encoding the Class\/Target labels from object type to int..!\n\nfrom sklearn.preprocessing import LabelEncoder\n\nClass = LabelEncoder()\nds['Class_n'] = Class.fit_transform(ds['class'])\n\nds.drop('class', axis=1, inplace=True)\nds.head()","745afc96":"# checking the total values of target labels \nds['Class_n'].value_counts()","3eb1af68":"galaxy_ds = ds[ds['Class_n'] == 0]                      # have all values that have class\/target label as 'Galaxy'\nqso_ds = ds[ds['Class_n'] == 1]                         # have all values that have class\/target label as 'QSO'\nstar_ds = ds[ds['Class_n'] == 2]                        # have all values that have class\/target label as 'Star'\n\ngalaxy_ds = galaxy_ds.sample(qso_ds.shape[0])           # getting any 850 random values from 'galaxy_ds' dataset\nstar_ds = star_ds.sample(qso_ds.shape[0])               # getting any 850 random values from 'star_ds' dataset\n\n# now we have to append these three datasets\ndf = qso_ds.append(galaxy_ds, ignore_index=True)        \nds = star_ds.append(df, ignore_index=True)","24030a44":"ds.shape","a77beba9":"ds['Class_n'].value_counts()\n\n# now the dataset is balanced ","095ad321":"# spliting the dataset into train and test\n\nfrom sklearn.model_selection import train_test_split\n\nx = ds.drop('Class_n', axis=1)\ny = ds['Class_n']\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.24)\n\nx_train.shape , x_test.shape","0f575f2d":"from sklearn.feature_selection import VarianceThreshold\n\nfilter = VarianceThreshold()\n\nx_train = filter.fit_transform(x_train)\nx_test = filter.fit_transform(x_test)\n\nx_train.shape , x_test.shape","860d664e":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","723d3af0":"# converting the labels series into numpy array because it is more faster..!\n\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()","c749455a":"# Importing Machine Learning Algorithm \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier","2a0544d9":"# Decision tree training with accuracy result\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ndt.score(x_test,y_test)","48e7b10f":"# Random Forest training with accuracy result\nrf = RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf.score(x_test,y_test)","d9edede2":"# XGBClassifier training with accuracy result\nxgb = XGBClassifier()\nxgb.fit(x_train,y_train)\nxgb.score(x_test,y_test)","6c53e877":"# Naive byes training with accuracy result\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nnb.score(x_test,y_test)","05528dc0":"# KNeighborsClassifier training with accuracy result\nknn = KNeighborsClassifier()\nknn.fit(x_train,y_train)\nknn.score(x_test,y_test)","eb947bd4":"# SVM training with accuracy result\nsvm = SVC()\nsvm.fit(x_train,y_train)\nsvm.score(x_test,y_test)","44a81bd5":"from sklearn.metrics import accuracy_score, confusion_matrix\n\ny_pred = xgb.predict(x_test)\n\nacs = accuracy_score(y_test, y_pred)\nprint('Accuracy Score of XGB Classifier: ', acs)","2be5d095":"cm = confusion_matrix(y_test, y_pred)\nprint('Confusion matrix\\n\\n',cm)","ad8151bf":"plt.figure(figsize=(7,5))\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('truth')","8ee69488":"# Confusion matrix","23a65b5b":"# Balancing the DataSet","dd816ba0":"# **Removing Constant & Quasi Constant**","b42820f7":"# Standardizing the DataSet"}}