{"cell_type":{"b649769d":"code","55093a97":"code","4b4920fd":"code","11fc6ae2":"code","615f7d7a":"code","144d1a45":"code","b6d53179":"code","88c3459f":"code","a2cf89a8":"code","cef83344":"code","82f524da":"code","703d26d4":"code","f778bd80":"code","a3cb1fdc":"code","7c56bc2d":"code","180de303":"code","af5472d7":"code","929d7231":"code","bc8c4fac":"code","266d095b":"code","32d7c53b":"code","214bcfc3":"code","25a467b4":"code","a9cfc00a":"code","78241406":"code","6030895a":"markdown","ad1e5fff":"markdown","c0db67cb":"markdown","5ec63b8a":"markdown","18587724":"markdown","15df4ca9":"markdown"},"source":{"b649769d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","55093a97":"import pandas as pd\nimport numpy as np","4b4920fd":"df = pd.read_csv(\"\/kaggle\/input\/usp-pj01\/train_Iris.csv\")\ndf.head()","11fc6ae2":"#Retira a coluna de Id pois \u00e9 desnecess\u00e1ria\ndf.drop(\"Id\", axis = 1, inplace = True)\n\n#Para a visualiza\u00e7\u00e3o dos dados ficar sem sobrepor nomes\ndf.replace({\"Iris-versicolor\":\"versicolor\", \"Iris-virginica\":\"virginica\",\n           \"Iris-setosa\": \"setosa\"}, inplace = True)","615f7d7a":"import seaborn as sns\nimport matplotlib.pyplot as plt","144d1a45":"#Valores NAs\ndf.isna().sum()","b6d53179":"#Estat\u00edsticas das colunas\ndf.describe()","88c3459f":"fig, axes = plt.subplots(nrows=1, ncols=4)\nfor i in range(len(df.columns[:-1])):\n    column = df.columns[i]\n    sns.boxplot(x=\"Species\", y=column, data=df, ax=axes[i])\n    axes[i].set_xlabel(\"Esp\u00e9cie\")\n    axes[i].set_ylabel(\"\")\n    axes[i].set_title(column.replace(\"_\",\" \").title(), fontsize=14)\n    axes[i].tick_params(axis='y', labelsize=14)\nfig.suptitle(\"\")\nfig.set_figwidth(15)\nplt.show();","a2cf89a8":"plt.figure()\nsns.pairplot(df, hue=\"Species\")\nplt.show()","cef83344":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score","82f524da":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import GaussianNB","703d26d4":"#Separa os dados em covari\u00e1veis e vari\u00e1vel dependente\ndf1 = df.copy()\ny = df1.iloc[:, -1]\nX = df1.iloc[:, :-1]\n\n#Como o Naive Bayes necessita da premissa de dados com distribui\u00e7\u00e3o normal,\n#  deve-se fazer uma transforma\u00e7\u00e3o para tornar os dados o mais pr\u00f3ximo de uma normal padr\u00e3o.\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","f778bd80":"#Separa-se os dados em Treino e Valida\u00e7\u00e3o para ter uma ideia do qu\u00e3o bem o modelo se ajusta aos dados,\n#  pois como o Naive Bayes n\u00e3o tem hiper par\u00e2metros, n\u00e3o h\u00e1 a necessidade de usar valida\u00e7\u00e3o\n#  cruzada para otimiza\u00e7\u00e3o deles.\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 2)","a3cb1fdc":"#Ajuste do modelo\nclf = GaussianNB()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\n\n#Mensurar a qualidade do modelo\nprint(\"Acur\u00e1cia NB: {:.2f}\".format(accuracy_score(y_val, y_pred)))\nprint(\"F1 score NB: {:.2f}\".format(f1_score(y_val, y_pred, average = \"weighted\")))\nprint(\"Precision NB: {:.2f}\".format(precision_score(y_val, y_pred, average = \"weighted\")))","7c56bc2d":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder","180de303":"#Separa os dados em covari\u00e1veis e vari\u00e1vel dependente\ndf1 = df.copy()\n\ny = df1.iloc[:, -1]\nX = df1.iloc[:, :-1]\n\n#Como o KNN \u00e9 influenciado pela escala dos dados, portanto\n#  \u00e9 preciso transformar os dados para que fiquem em um determinado intervalo,\n#  mas sem alterar a sua distribui\u00e7\u00e3o.\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)","af5472d7":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 2)","929d7231":"#Hiper par\u00e2metros para otimiza\u00e7\u00e3o\nn_neighbors = np.arange(1,11)\nweights = [\"uniform\", \"distance\"]\nmetric = [\"euclidean\", \"minkowski\", \"manhattan\"]\nk_fold = 10\n\n#GridSearch para achar a melhor combina\u00e7\u00e3o de valores dos hiper par\u00e2metros.\n#   aplicando ainda uma valida\u00e7\u00e3o cruzada com 10 folds.\nmodel = GridSearchCV(KNeighborsClassifier(), cv = k_fold,\n                     param_grid={\"n_neighbors\": n_neighbors, 'weights': weights, \"metric\":metric})\nmodel.fit(X_train, y_train.ravel())\ny_pred = model.predict(X_val)\n\n\n#Mensurar a qualidade do modelo ajustado\nprint(\"Acur\u00e1cia KNN: {:.2f}\".format(accuracy_score(y_val, y_pred)))\nprint(\"F1 score KNN: {:.2f}\".format(f1_score(y_val, y_pred, average = \"weighted\")))\nprint(\"Precision KNN: {:.2f}\".format(precision_score(y_val, y_pred, average = \"weighted\")))","bc8c4fac":"test = pd.read_csv(\"\/kaggle\/input\/usp-pj01\/test_Iris.csv\")\ntest.head()","266d095b":"#Separa o Id das plantas do teste para futuro envio no Kaggle.\ntest_id = test.Id\ntest.drop(\"Id\", axis = 1, inplace = True)","32d7c53b":"df1 = df.copy()\n\n#Mudar o nome das categorias para ficar do jeito que \u00e9 pedido na competi\u00e7\u00e3o\ndf1.replace({\"versicolor\": \"Iris-versicolor\", \"setosa\": \"Iris-setosa\", \"virginica\":\"Iris-virginica\"}, inplace = True)\ny_train = df1.iloc[:, -1]\nX_train = df1.iloc[:, :-1]\n\nX_test = test.copy()","214bcfc3":"#Transforma os dados para ficarem no intervalo de 0 a 1, igual mencionado anteriormente.\nscaler_train = MinMaxScaler()\nX_train = scaler_train.fit_transform(X_train)\n\nscaler_test = MinMaxScaler()\nX_test = scaler_test.fit_transform(X_test)","25a467b4":"#Identifica-se o melhor modelo, com a melhor combina\u00e7\u00e3o de hiperpar\u00e2metros\n#  aplicados no conjunto de treino para, agora, aplicar no conjunto de teste.\nmodel = model.best_estimator_\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","a9cfc00a":"#Gera um csv com as predi\u00e7\u00f5es feitas pelo modelo para o conjunto de teste\ntest_id = pd.DataFrame(data = {\"Id\": test_id, \"Category\": y_pred})\ntest_id.to_csv(\"resposta.csv\", index = False)","78241406":"test_id.head()","6030895a":"### KNN","ad1e5fff":"# Modelagem","c0db67cb":"Deseja-se usar apenas 1 modelo para prever os dados. Como o KNN apresentou um melhor resultado no treino, usa-se ele para a predi\u00e7\u00e3o.","5ec63b8a":"### Naive Bayes","18587724":"# An\u00e1lise Explorat\u00f3ria dos Dados","15df4ca9":"# Predi\u00e7\u00e3o"}}