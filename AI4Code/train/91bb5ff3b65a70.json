{"cell_type":{"b362d90e":"code","f92c7d90":"code","061f6409":"code","36621544":"code","5efe8525":"code","33bbb668":"code","6257a9d8":"code","cedc1dae":"code","272cce94":"code","c355206f":"markdown","dfbf7071":"markdown","2557391e":"markdown","6918d4a3":"markdown","51b09391":"markdown","69d88d0c":"markdown","22defcbb":"markdown","c70bc295":"markdown","24ba7a4a":"markdown","98ea1f73":"markdown","f840b4b6":"markdown","f895b445":"markdown","8de6bd93":"markdown","3b1e5f4d":"markdown","cd68f50a":"markdown","3c69113a":"markdown"},"source":{"b362d90e":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ndf_in = pd.read_csv('..\/input\/covid-data\/no_zero_time_series_covid_19_deaths_2021.csv')\ndf_in.head()","f92c7d90":"df_in.tail()","061f6409":"import numpy as np \nimport pandas as pd ","36621544":"dates_vec = list(df_in.columns)[3:]\naverage_time_vec = [None] * df_in.shape[0]\n\nfor i, row_index in enumerate(df_in.index):\n\n    weighted_sum, total_deaths = 0, 0\n    \n    for j, date in enumerate(dates_vec):\n        current_term = df_in.at[row_index, date]\n        weighted_sum += j * current_term\n        total_deaths += current_term\n    \n    average_time_vec[i] = weighted_sum \/ total_deaths\n    \ndf_in['avg_time'] = average_time_vec\n\nn_lines = int((df_in.shape[0] * (df_in.shape[0] - 1)) \/ 2)\ncountry1 = [None] * n_lines\ncountry2 = [None] * n_lines\nlw = [None] * n_lines\nld = [None] * n_lines\n\nline_index = 0\nepsilon = 0.001\nfor i in range(0, df_in.shape[0] - 1):\n    for j in range(i + 1, df_in.shape[0]):\n        index_i = df_in.index[i]\n        index_j = df_in.index[j]\n        country1[line_index] = df_in.at[index_i, 'Country\/Region']\n        country2[line_index] = df_in.at[index_j, 'Country\/Region']\n        diff_time = df_in.at[index_i, 'avg_time'] - df_in.at[index_j,'avg_time']\n        lw[line_index] = (1 \/ (abs(diff_time) + epsilon))\n        ld[line_index] = abs(diff_time)\n        line_index += 1\n        \ndf_graph = pd.DataFrame(dict( Source = country1, Target = country2, Weight = lw, Distance = ld ))\n\ndf_graph.head()","5efe8525":"df_graph.to_csv('Final_Outcome.csv', index=False)\ndf_graph.head()","33bbb668":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ndf_in = pd.read_csv('..\/input\/covid-data\/no_zero_time_series_covid_19_deaths_2021.csv')\ndf_in.head()","6257a9d8":"import numpy as np\nimport pandas as pd","cedc1dae":"dates_vec = list(df_in.columns)[4:]\n\nn_lines = int((df_in.shape[0] * (df_in.shape[0] - 1)) \/ 2) \ncountry1 = [None] * n_lines\ncountry2 = [None] * n_lines \nld = [None] * n_lines\nlw = [None] * n_lines\n\nline_index = 0\nfor i in range(0, df_in.shape[0] - 1):\n    for j in range(i + 1, df_in.shape[0]):\n        index_i, index_j = df_in.index[i], df_in.index[j]\n        a = df_in.iloc[index_i,4:]\n        b = df_in.iloc[index_j,4:]\n        country1[line_index] = df_in.at[index_i, 'Country\/Region'] \n        country2[line_index] = df_in.at[index_j, 'Country\/Region'] \n        diff = np.linalg.norm(abs(a-b)) \n        lw[line_index] = (1\/abs(diff))\n        ld[line_index] = diff\n        line_index += 1\n        \ndf_graph = pd.DataFrame(dict(\n    Source = country1, Target = country2, Weight = lw, Distance = ld,\n))\n\ndf_graph.head()","272cce94":"df_graph.to_csv('New_Final_Outcome.csv', index=False)\ndf_graph.head()","c355206f":"You probably have already noticed that I used 'Euclidean Distance' again for this methodology. That's because Euclidean is the simplest and also on the more convenient spectrum for combining with python and Network theory than distances such as Minkowski, Cosin similarity, Chebyshev, Hamming, Jaccard, etc.","dfbf7071":"# The application of K-means clustering for regional clustering in the world of the risk of the COVID-19 pandemic based on COVID-19 data.\n\nThis notebook is my first data science portfolio.  In this notebook, I will be displaying my python codes and network graphs that I have been producing under professor Yun Joo YOO at Seoul National University. This is my 'long-term project' supervised by Professor Yoo, so I will keep updating my progress every week or every month.\n\n## COVID-19 and Network Theory \/ Graph Theory\n\nCOVID-19 is causing terrible loss of lives all around the world, and also has a devastating impact on economics.\n\nI used mathematics, statistics, computer science, and data science to work out graphs and clusters to help to visualize, and perhaps fight, the COVID-19 pandemic in the world.\n\nNetwork theory, which is also known as Graph theory, is a part of all mathematics, statistics, and data science that studies graphs, which are mathematical structures that can be used to model certain similarities or differences among objects.\n\nIn this project, I will demonstrate how network theory can be used to model various situation that occurs during a pandemic and helps fighting COVID-19 by slowing down the process of spreading the virus.\n\nThank you.","2557391e":"![screenshot_231654.png](attachment:673afde9-612e-4cc6-993b-ad6a221cd5c6.png)","6918d4a3":"Our primary interest is finding the best, most efficient, and fastest route from one place to another. In this section of python codes, I am examing to find a fast algorithm for 'Source' and 'Target' using Euclidean networks (distance), which are networks whose vertices are points in the plane and whose edge weights are defined by the geometric distances between the points. \n\n\n![1_9LeaMTcOXxeTPN-VCbKloQ.png](attachment:30dbb64e-1f97-4339-a56e-eec5740960f0.png)\n\n\nAlso, if you look at the lines of code in 'input 4,' you may have spotted that the average value of a function is a weighted average of the function along the time axis with all different times having the same weight. So, we can generalize that to take the average \"x\" but, this time, we will use the function values as weights. The final value is indeed something with the same units of \"x\" - in our case - the time. We are calculating the average data of the deaths. \n\nFor your interest, Weight and Euclidean distance in Clustering Algorithms are inversely proportional to each other. ","51b09391":"# [5] K-means Clustering","69d88d0c":"Now, you can see that the nodes in the above graph got much larger than the nodes when I produced using 'weighted sum values.' This is probably because I have converted each entire column in the CSV file as a vector from 'Input 8.' What's also convenient about using vector form in this context is that I didn't have to use epsilon nor create my weighted sum function to produce new algorithms. In fact, the vector is also highly compatible with Euclidean distance, so Euclidean vector space methodology is simpler and more insightful than the 'weighted sum values' method. ","22defcbb":"The above graph is much simpler than the first graph. This is because I have used filters called 'Degree Range' and 'Giant Component' in Gephi to filter out smaller nodes with their weighted degrees smaller than a certain boundary (number). Hence, I was able to extract only the main points: 'China,' 'France,' 'UK,' 'Canada,' 'Australia,' 'Netherlands,' and 'Denmark.' \n\nAs you can see, edges connected from China to the other 6 countries are exclusively bolded in thicker lines, that is due to the higher degree of weighted edges which present the strong and high propagation of COVID-19 from Mainland China. You may have also already noticed that the spectrum of the colors of the edges is also directly proportional to the weighted value of the edges. \n\nThere are also self-loops in the major transmission groups (countries). For example, if you look at China, you can see that there is a curve edge that comes out and goes directly back into China, that's called 'self-loop.' Although the meaning of the self-loop depends on its context, self-loop, in this case, represents the COVID-19 transmitted by people from the same country.\n\nThe graph also shows us that the Commonwealth realm, such as the United Kingdom, Australia, and Canada, is connected with the higher weighted degree and common similarity. Moreover, for the strong link between Canada and France, we could infer that the high cultural proximity between Quebec and France may have contributed to the higher weighted degree of the edges and propagation of the virus between the two countries. Hence, it is interesting to see that proximity in cultural and linguistics backgrounds also contribute to the propagation of COVID-19 among the countries. ","c70bc295":"After using the same filters as before, 'Giant Component' and 'Degree Range,' we got a similar network as before. We can see the same transmission countries that were also present from the filtered network of weighted sum values. What's also interesting about this graph is that the nodes of Canada, France, Denmark, and Australia are as big as and as dark as that of China. This is possibly due to higher in-degree values of the aforementioned 4 countries than China's. (China was indeed responsible for transmitting COVID-19 globally, but the chance that COVID-19 cases in China rose because of other foreign countries is minuscule because China went to severe lock-downs and stuck to its \"zero-COVID policy.\" Thereby, the total size of China's node in the vector form has to be smaller than the 4 countries.) \n\nInterestingly, two thick edges are coming from Australia and Canada to China. That may be due to the high population of Australians or Canadians identifying themselves as being of Chinese ethnic origin: 1.77 million people in Canada (about 5.1% of the Canadian population) and 1.2 million people in Australia (about 5% of the total population) according to the 2016 census. \n\nLastly, we can see that weighted edges and their colors for the connection among the Commonwealth realm stand out. Thus, we can, once again, draw out a similar assumption\/ conclusion for the three transmission groups. \n\nNow we are going to move on to a little bit more analytically heavy content, where I am going to display hierarchical clustering and classify the nodes based on Geographical regions (using Latitude and Longitude), Cultures, or Languages.","24ba7a4a":"![screenshot_232623.png](attachment:2aa4d444-9aa5-41d9-ac3d-e6713e606378.png)","98ea1f73":"# [2] Visualizing Network (Graph) using Gephi\n\nThe graph was generated using the Gephi editor. \n\nAlthough you could create and edit the graph using the NetworkX in the python library, I suggest you avoid NetworkX as it is more tricky and inefficient to plot your graph later than using Gephi. \n\nWhereas, if you use Gephi software like me, you just have to download the CSV file from the previous step and easily customize it by using various algorithms that Gephi provides in their folder. Also, you will see that Gephi produces more insightful networks and graphs for COVID-19. \n\nThere are also many useful and easy Gephi tutorials on Youtube, so you should definitely check them out.","f840b4b6":"![screenshot_231339.png](attachment:49a418b3-f4d9-4d3f-af05-4fd06fe54b36.png)","f895b445":"# [3] n-dimensional Vector Space Analysis + Network Theory using Python\n\nNow we are going to look at the similar but more \"compact\" method of producing the new lines of python code using n-dimensional vector space to display the spread of COVID-19. This method is also more visually direct to analyze if you use different settings of nodes in Gephi such as 'Out-degree' and 'In-degree,' which will help you by a lot to filter out and identify the major transmission group in the world. (Of course, I have still used additional filter options like 'Giant Component' and 'Degree Range' to study the propagation of COVID-19)","8de6bd93":"# [4] Visualizing Network (Graph) using Gephi (n-dimensional vector space)\n\nThe graphs were produced with Gephi again using the CSV files from the previous section. \n\nYou probably have already seen the benefits of using Gephi is an open-source software for network visualization and analysis. Gephi helped me to intuitively reveal statistical patterns, trends, and tell stories with input\/output data. ","3b1e5f4d":"# [1] Raw Data Process using Python\n\nDown below are the lines of python code that I wrote to produce raw data files. (This step is before the 'Data Cleansing' process.)\n\nBefore moving into the coding parts, you may question why don't we use the number of confirmed or recovered cases. \n\nIt's simply because we cannot trust the number of confirmed or recovered cases. In fact, some countries in the past struggled and had limited COVID medical kits to test infected people. Moreover, some of the infected people were asymptomatic. Hence, I decided to use \"death cases\" as when someone dies of COVID symptoms, all of them are double-tested to verify their cause of death. ","cd68f50a":"![screenshot_182350.png](attachment:6f671111-0ca2-425a-adde-6bd03b9c85ce.png)","3c69113a":"As you can see nodes and edges of the above graph have different gradients of green colors that's because I used the size of the nodes and the colors of the nodes and edges to be directly related to the weighted average of each node, where the weight is bigger if the average spreading time of COVID-19 is similar. \n\nSo, what can we extract from the graph above?\n\nWell, we can see that China takes a central role in the COVID-19 propagation. However, it seems like a similar \"high-level\" of propagation happens in France, Canada, the United Kingdom, Australia, Denmark, and Netherland. Then we could deduce that spread of COVID-19 from Europe and Mainland China has contributed to the fast propagation of the airborne virus in the rest of African and Asian countries."}}