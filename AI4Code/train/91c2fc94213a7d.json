{"cell_type":{"5d0580db":"code","97bdf01b":"code","d79e96d7":"code","7368adc0":"code","d4656cfd":"code","ba0be4d9":"code","9ad567ae":"code","06482174":"code","367033a1":"code","e41ed266":"code","d6a5f8fd":"code","7529342e":"markdown"},"source":{"5d0580db":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn import preprocessing\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","97bdf01b":"# Get data, normalize it, split into ttrain-test sets\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n\nX_train = []\nY_train = []\nX_test = []\n\nfor index, row in train_df.iterrows():\n    X_train.append(row.values[1 : ].reshape((28, 28, 1)))\n    Y_train.append(row['label'])\n\nfor index, row in test_df.iterrows():\n    X_test.append(row.values.reshape((28, 28, 1)))\n\nX_train = np.array(X_train) \/ 255.\nY_train = np.array(Y_train)\nX_test = np.array(X_test) \/ 255.\n\nlb = preprocessing.LabelBinarizer()\nlb.fit(Y_train)\nY_train = lb.transform(Y_train)\n\nsss = StratifiedShuffleSplit(10, 0.2, random_state = 15)\nfor train_idx, val_idx in sss.split(X_train, Y_train):\n    X_train_tmp, X_val = X_train[train_idx], X_train[val_idx]\n    Y_train_tmp, Y_val = Y_train[train_idx], Y_train[val_idx]\n\nX_train = X_train_tmp\nY_train = Y_train_tmp","d79e96d7":"img_size = (28, 28, 1)\nn_classes = 10\n\nif os.path.exists('keras_model.h5'):\n    model = load_model('keras_model.h5')\nelse:\n    model = Sequential()\n    model.add(Conv2D(32, (5, 5), input_shape = img_size, kernel_initializer = 'normal'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Conv2D(64, (5, 5), kernel_initializer = 'normal'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(n_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])","7368adc0":"# Augment Data\ndatagen = ImageDataGenerator(\n    featurewise_center = False,\n    samplewise_center = False,\n    featurewise_std_normalization = False,\n    samplewise_std_normalization = False,\n    zca_whitening = False,\n    rotation_range = 0,\n    zoom_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = False,\n    vertical_flip = False\n)\n\ndatagen.fit(X_train)","d4656cfd":"# Train Model\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size = 1000),\n                   epochs = 20,\n                   validation_data = (X_val, Y_val),\n                   steps_per_epoch = X_train.shape[0] \/ 1000,\n                   verbose = 1)\nscore, acc = model.evaluate(X_val, Y_val, verbose = 1)\nprint('\\nLoss:', score, '\\nAcc:', acc)\nmodel.save('keras_model.h5')","ba0be4d9":"# Make Predictions\nY_test = model.predict(X_test)\nY_test = lb.inverse_transform(Y_test)\nY_test = [[y] for y in Y_test]\nindex = [[i] for i in range(1, X_test.shape[0] + 1)]\noutput_np = np.concatenate((index, Y_test), axis = 1)\noutput_df = pd.DataFrame(data = output_np, columns = ['ImageId', 'Label'])\noutput_df.to_csv('out.csv', index = False)","9ad567ae":"Y_train_label = lb.inverse_transform(Y_train)\nY_train_label[:30]\nclass_indices = [3, 5, 0, 22, 1, 9, 2, 28, 4, 7]","06482174":"# Visualize filters\nfrom keras import backend as K\nK.set_learning_phase(1)\nimport tensorflow as tf\n\nmodel = load_model('keras_model.h5')\n\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n#print('Layer dict', layer_dict)","367033a1":"# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x \/= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    #x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x","e41ed266":"# Create Saliency Heat Map\nfrom keras.layers import Input, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.initializers import Ones, Zeros\n\nclass SaliencyMask(object):\n    def __init__(self, model, output_index=0):\n        pass\n\n    def get_mask(self, input_image):\n        pass\n\n    def get_smoothed_mask(self, input_image, stdev_spread=.2, nsamples=50):\n        stdev = stdev_spread * (np.max(input_image) - np.min(input_image))\n\n        total_gradients = np.zeros_like(input_image, dtype = np.float64)\n        for i in range(nsamples):\n            noise = np.random.normal(0, stdev, input_image.shape)\n            x_value_plus_noise = input_image + noise\n\n            total_gradients += self.get_mask(x_value_plus_noise)\n\n        return total_gradients \/ nsamples\n\nclass GradientSaliency(SaliencyMask):\n\n    def __init__(self, model, output_index = 0):\n        # Define the function to compute the gradient\n        input_tensors = [model.input]\n        gradients = model.optimizer.get_gradients(model.output[0][output_index], model.input)\n        self.compute_gradients = K.function(inputs = input_tensors, outputs = gradients)\n\n    def get_mask(self, input_image):\n        # Execute the function to compute the gradient\n        x_value = np.expand_dims(input_image, axis=0)\n        gradients = self.compute_gradients([x_value])[0][0]\n\n        return gradients\n\nclass VisualBackprop(SaliencyMask):\n    def __init__(self, model, output_index = 0):\n        inps = [model.input]           # input placeholder\n        outs = [layer.output for layer in model.layers]    # all layer outputs\n        self.forward_pass = K.function(inps, outs)         # evaluation function\n        \n        self.model = model\n\n    def get_mask(self, input_image):\n        x_value = np.expand_dims(input_image, axis=0)\n        \n        visual_bpr = None\n        layer_outs = self.forward_pass([x_value, 0])\n\n        for i in range(len(self.model.layers) - 1, -1, -1):\n            if 'Conv2D' in str(type(self.model.layers[i])):\n                layer = np.mean(layer_outs[i], axis = 3, keepdims = True)\n                layer = layer - np.min(layer)\n                layer = layer \/ (np.max(layer) - np.min(layer) + 1e-6)\n\n                if visual_bpr is not None:\n                    if visual_bpr.shape != layer.shape:\n                        visual_bpr = self._deconv(visual_bpr)\n                    visual_bpr = visual_bpr * layer\n                else:\n                    visual_bpr = layer\n\n        return visual_bpr[0]\n    \n    def _deconv(self, feature_map):\n        x = Input(shape = (None, None, 1))\n        y = Conv2DTranspose(filters = 1, \n                            kernel_size = (3, 3), \n                            strides = (2, 2), \n                            padding = 'same', \n                            kernel_initializer = Ones(), \n                            bias_initializer = Zeros())(x)\n\n        deconv_model = Model(inputs=[x], outputs=[y])\n\n        inps = [deconv_model.input]   # input placeholder                                \n        outs = [deconv_model.layers[-1].output]           # output placeholder\n        deconv_func = K.function(inps, outs)              # evaluation function\n        \n        return deconv_func([feature_map, 0])[0]","d6a5f8fd":"Y_train_label = lb.inverse_transform(Y_train)\n\nfig, ax = plt.subplots(10, 2, figsize = (5, 25))\ni=-1\nfor c in class_indices:\n    img = np.array(X_train[c])\n    i=i+1\n    \n    vanilla = GradientSaliency(model, Y_train_label[c])\n    mask = vanilla.get_mask(img)\n    filter_mask = (mask > 0.0).reshape((28, 28))\n    smooth_mask = vanilla.get_smoothed_mask(img)\n    filter_smoothed_mask = (smooth_mask > 0.0).reshape((28, 28))\n    \n    fig.subplots_adjust(hspace=.8)\n    ax[i, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n    cax = ax[i, 1].imshow(mask.reshape((28, 28)), cmap = 'jet')\n    fig.colorbar(cax, ax = ax[i, 1])","7529342e":"# Introduction"}}