{"cell_type":{"84063946":"code","5d6fc38d":"code","6c502d2f":"code","a08c39e8":"code","273d4c34":"code","f00d7a8c":"code","38db18a7":"code","2164d76d":"code","3d75bd80":"code","5f491466":"code","4d9e2fdd":"code","5266b720":"code","a775bf17":"code","48687c39":"code","75bc6b3f":"code","f7c6c98b":"code","ed771b7d":"code","050d1153":"code","c04905c5":"code","dbad6ee3":"code","7c09b336":"code","dba38ef5":"code","ad0ddede":"code","aca020f0":"code","dbaa2813":"code","9ba88825":"code","281b1df0":"markdown"},"source":{"84063946":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5d6fc38d":"array = [[1, 2, 3], [4, 5, 6]]\nfirst_array = np.array(array)\nprint(\"Array Type: {}\".format(type(first_array)))\nprint(\"Array Shape {}:\".format(first_array.shape))\nprint(first_array)","6c502d2f":"import torch\ntensor = torch.tensor(array)\nprint(\"Array Type: {}\".format(tensor.type))\nprint(\"Array Shape {}:\".format(tensor.shape))\nprint(tensor)","a08c39e8":"print(np.ones((2, 3)))","273d4c34":"print(torch.ones((2, 3)))","f00d7a8c":"print(np.random.randn(2, 3))","38db18a7":"print(torch.randn(2, 3))","2164d76d":"array = np.random.rand(2, 3)\nprint(\"Type {}, Shape:{}\".format(type(array), array.shape))\nprint(array)","3d75bd80":"tensor = torch.from_numpy(array)\nprint(\"Type {}, Shape:{}\".format(type(tensor), tensor.shape))\nprint(tensor)","5f491466":"tensor = torch.ones(3, 3)\ntensor2 = tensor * 4\nprint(tensor)\nprint(\"View: \\n{}\\n{}\".format(tensor.view(9), tensor.view(9).shape))\nprint(\"Add: \\n{}\\n{}\".format(torch.add(tensor, tensor2), torch.add(tensor, tensor2).shape))\nprint(\"Add 2: \\n{}\\n{}\".format(tensor.add(tensor2), tensor.add(tensor2).shape))\nprint(\"Subtract: \\n{}\\n{}\".format(torch.sub(tensor2, tensor), torch.sub(tensor2, tensor).shape))\nprint(\"Subtract 2: \\n{}\\n{}\".format(tensor2.sub(tensor), tensor2.sub(tensor).shape))\nprint(\"Multiply: \\n{}\\n{}\".format(torch.mul(tensor, tensor2), torch.mul(tensor, tensor2).shape))\nprint(\"Multiply 2: \\n{}\\n{}\".format(tensor.mul(tensor2), tensor.mul(tensor2).shape))","4d9e2fdd":"tensor = torch.Tensor([1, 2, 3, 4, 5])\nprint(\"Mean {}\".format(tensor.mean()))","5266b720":"tensor1 = torch.Tensor([1, 2, 3, 4, 5])\ntensor2 = torch.tensor([1, 2, 3, 4, 5])\n\nprint(\"Type {}\".format(tensor1.type()))\nprint(\"Type {}\".format(tensor2.type()))","a775bf17":"from torch.autograd import Variable","48687c39":"var = Variable(torch.ones(3), requires_grad = True)\nprint(var)","75bc6b3f":"array = [2, 4]\ntensor = torch.Tensor(array)\n\nx = Variable(tensor, requires_grad = True)\ny = x ** 2\nprint(\"y {}\".format(y))","f7c6c98b":"o = 1\/2 * sum(y)\nprint(\"o {}\".format(o))","ed771b7d":"o.backward()\n\nprint(\"x gradient {}\".format(x.grad))","050d1153":"print(x.grad)","c04905c5":"car_prices_array = [3, 4, 5, 6, 7, 8, 9]\ncar_prices_np = np.array(car_prices_array, dtype=np.float32)\ncar_prices_np = car_prices_np.reshape(-1, 1)\ncar_prices_tensor = Variable(torch.from_numpy(car_prices_np))","dbad6ee3":"car_prices_np.shape","7c09b336":"car_sell_array = [ 7.5, 7, 6.5, 6.0, 5.5, 5.0, 4.5]\ncar_sell_np = np.array(car_sell_array,dtype=np.float32)\ncar_sell_np = car_sell_np.reshape(-1,1)\ncar_sell_tensor = Variable(torch.from_numpy(car_sell_np))","dba38ef5":"car_sell_np.shape","ad0ddede":"import matplotlib.pyplot as plt\nplt.scatter(car_prices_array, car_sell_array)\nplt.show()","aca020f0":"import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn","dbaa2813":"class LinearRegression(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n        \n    def forward(self, x):\n        return self.linear(x)\n    \ninput_dim = 1\noutput_dim = 1\nmodel = LinearRegression(input_dim, output_dim)\n\nmse = nn.MSELoss()\n\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n\nloss_list = []\n\niteration_number = 1001\nfor iteration in range(iteration_number):\n    optimizer.zero_grad()\n    \n    results = model(car_prices_tensor)\n    \n    loss = mse(results, car_sell_tensor)\n    \n    loss.backward()\n    \n    optimizer.step()\n    \n    loss_list.append(loss.data)\n    \n    if (iteration % 50 == 0):\n        print(\"epoch {}, loss {}\".format(iteration, loss.data))\n    \nplt.plot(range(iteration_number), loss_list)\nplt.show()","9ba88825":"predicted = model(car_prices_tensor).data.numpy()\nplt.scatter(car_prices_np, predicted, c=\"red\")\nplt.scatter(car_prices_np, car_sell_np, c = \"blue\")\nplt.show()\n","281b1df0":"## Linear Regression"}}