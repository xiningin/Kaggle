{"cell_type":{"b2b1bcb2":"code","cdef0470":"code","5c7c1c3d":"code","e411c77e":"code","e9d9bc9f":"code","c84052c3":"code","f4eb4863":"code","02f951c2":"code","9d65f479":"code","109adcf0":"code","02e99d07":"markdown","d2373046":"markdown","b9a097db":"markdown","a94bb700":"markdown","1335573e":"markdown","2a9037c1":"markdown","de13f821":"markdown","49c8b453":"markdown","1036ebd2":"markdown","94e3c547":"markdown","8d4883f6":"markdown","939f7289":"markdown","07e72ed2":"markdown","34284791":"markdown"},"source":{"b2b1bcb2":"# Set up code checking\nimport os\nif not os.path.exists(\"..\/input\/train.csv\"):\n    os.symlink(\"..\/input\/home-data-for-ml-course\/train.csv\", \"..\/input\/train.csv\")  \n    os.symlink(\"..\/input\/home-data-for-ml-course\/test.csv\", \"..\/input\/test.csv\")  \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_intermediate.ex1 import *\nprint(\"Setup Complete\")","cdef0470":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read the data\ntrain_data = pd.read_csv('..\/input\/train.csv', index_col='Id')\ntest_data = pd.read_csv('..\/input\/test.csv', index_col='Id')","5c7c1c3d":"corrmat = train_data.corr(method='spearman')\nf, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(corrmat, ax=ax, annot=True, fmt=\".1f\", annot_kws={'size':8}, center=0, linewidths=0.1)","e411c77e":"features = ['LotArea', 'LotFrontage', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', '2ndFlrSF','MasVnrArea', 'OverallQual', 'FullBath', 'HalfBath',\n            'BedroomAbvGr', 'TotRmsAbvGrd', 'GrLivArea', 'GarageArea', 'Fireplaces', 'OpenPorchSF', 'WoodDeckSF', 'TotalBsmtSF', 'BsmtFinSF1']","e9d9bc9f":"condition = ['KitchenQual', 'PoolQC', 'GarageCond', 'BsmtCond', 'FireplaceQu', 'HeatingQC', 'BsmtQual', 'GarageQual', 'ExterQual', 'ExterCond']\n\nfor i in condition:\n    train_nan = train_data.loc[:,i].isna()\n    test_nan = test_data.loc[:,i].isna()\n    for j in train_data.index:\n        if train_data.loc[j,i]=='Gd':\n            train_data.loc[j,i]=4\n        elif train_data.loc[j, i]=='Po':\n            train_data.loc[j,i]=1\n        elif train_data.loc[j, i]=='Ex':\n            train_data.loc[j, i]=5\n        elif train_data.loc[j, i]=='Fa':\n            train_data.loc[j, i]=2\n        elif train_data.loc[j, i]=='TA':\n            train_data.loc[j, i]=3\n        elif train_data.loc[j, i]=='NA' or train_data.loc[j, i]=='na' or train_nan[j]==True:\n            train_data.loc[j, i]=0\n    for z in test_data.index:\n        if test_data.loc[z,i]=='Gd':\n            test_data.loc[z,i]=4\n        elif test_data.loc[z, i]=='Po':\n            test_data.loc[z,i]=1\n        elif test_data.loc[z, i]=='Ex':\n            test_data.loc[z, i]=5\n        elif test_data.loc[z, i]=='Fa':\n            test_data.loc[z, i]=2\n        elif test_data.loc[z, i]=='TA':\n            test_data.loc[z, i]=3\n        elif test_data.loc[z, i]=='NA' or test_data.loc[z, i]=='na' or test_nan[z]==True:\n            test_data.loc[z, i]=0","c84052c3":"features.extend(condition)\n\ncorr_check = features\ncorr_check.append('SalePrice')\n\nfor i in condition:\n    train_data[i] = train_data[i].astype(float)\n    test_data[i] = test_data[i].astype(float)\n\ntrain_reduced = train_data[corr_check]\ncorrmat = train_reduced.corr(method='spearman')\nf, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(corrmat, ax=ax, annot=True, fmt=\".1f\", annot_kws={'size':8}, center=0, linewidths=0.1)\n\nfeatures.remove('SalePrice')","f4eb4863":"features.remove('PoolQC')\nfeatures.remove('ExterCond')\n\ny = train_data['SalePrice']\nX = train_data[features]\nX_realtest = test_data[features]\n\nprint(X.isnull().sum())\nprint(X_realtest.isnull().sum())","02f951c2":"values = {'LotFrontage': 0, 'MasVnrArea': 0}\ntest_values = {'GarageArea':0, 'TotalBsmtSF': X_realtest['TotalBsmtSF'].mean(), 'BsmtFinSF1': X_realtest['BsmtFinSF1'].mean()}\nX.fillna(value=values, inplace=True)\nX_realtest.fillna(value=values, inplace=True)\nX_realtest.fillna(value=test_values, inplace=True)","9d65f479":"from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nmodel1 = RandomForestRegressor()\nmodel2 = GaussianProcessRegressor()\nmodel3 = AdaBoostRegressor()\nmodel4 = GradientBoostingRegressor()\nmodel5 = XGBRegressor()","109adcf0":"models = [model1, model2, model3, model4, model5]\n\ndef score_model(model, X_t=X_train, X_v=X_test, y_t=y_train, y_v=y_test):\n    model.fit(X_t, y_t)\n    y_pred = model.predict(X_v)\n    return mean_squared_log_error(y_v, y_pred)\n\nfor model in models:\n    print(score_model(model))","02e99d07":"As can be seen from the results; the best performing models are GradientBoosting, RandomForest and XGBoost.\nOf course the models can be further improved by hyperparameter tuning before submitting results.","d2373046":"# Step 1: Evaluate feature importances\n\nThe next code will plot the correlation matrix for the numerical features and sale price. ","b9a097db":"So there are missing values for LotFrontage and MasVnrArea in both train and test data. In addition there are missing values for GarageArea, TotalBsmtSF and BsmtFinSF1.\nLet's fill these values.\nLotfrontage, MasVnrArea and GarageArea are 0 if they are missing. Other values are filled with data mean.","a94bb700":"# Housing Prices Competition - Sample Notebook for beginners","1335573e":"# Setup\n\nSetting up the environment (directly taken from intermediate ML course :))","2a9037c1":"# Step 3: Possible further improvement steps\n\nAs mentioned above; the prediction can be improved by following the below steps.\n- Hyperparameter tuning\n- Trying to add other categorial variables not used in this notebook\n- Trying other possible regression models\n\nI hope that this notebook is useful to other users.\n","de13f821":"Let's fit and calculate the log mean errors for each model","49c8b453":"In addition to these; one can check the data set and see that there are text information about quality and condition of kitchen, garage, heating etc.\nThese show the level of quality\/condition of a specific part of the house. You can check it from this website: https:\/\/insidevaluation.wordpress.com\/2012\/06\/27\/property-condition-an-objective-guideline-for-a-subjective-concept\/\n\nThese are set as:\n* Ex: Excellent\n* Gd: Good\n* TA: Typical (meaning average)\n* Fa: Fair\n* Po: Poor\n\nExcellent is the top level, poor is the lowest. \nFor some of the values there are NA values especially in fireplace column. This means that there is no fireplace so it should be set as 0.\nI have removed these text by noting them instead. So excellent is 5, poor is 1 and NA is 0.","1036ebd2":"So the data is ready to fit different models.","94e3c547":"# Step 2: Fit the model\n\nLet's fitt different models with default hyperparameter values and observe the error. We should also split the data to train and test values to compare models.","8d4883f6":"Add the above parameters as features as well. \nAlso add the saleprice to these features and check the correlation matrix with new parameters so we will see if there are any parameters that can be eliminated.","939f7289":"As it can be observed direclty, PoolQC and ExterCond features have very week correlation to saleprice. Therefore we remove these parameters from the model as well.\nThen let us set the features and labels and see missing and NA values","07e72ed2":"Black color means that there is weak correlation between the two values. \nSince there are too many parameters by checking the correlation matrix, I have eliminated features with absolute values less than 0.3\nSo we end up with the below list of features","34284791":"We will work with housing prices data from competition so first import necessary libraries and data \n\n![Ames Housing dataset image](https:\/\/i.imgur.com\/lTJVG4e.png)"}}