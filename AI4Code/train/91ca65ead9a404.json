{"cell_type":{"30570f06":"code","b5eb3645":"code","d65adfa4":"code","e61197b5":"code","9d22e105":"code","6ad5f7d1":"code","076e3aaa":"code","7281a124":"code","29081e5d":"code","4d31834c":"code","9e489400":"code","d0ed8e26":"code","688a1b96":"code","24724ffb":"code","c97e2792":"code","3b141545":"code","86d4bc79":"code","a1e388f2":"code","e3fa93c2":"code","b65f7133":"code","9eeffb05":"code","85eb898a":"code","720ac9a0":"code","ee0f23ab":"code","2250187e":"code","c953c4f6":"code","70ea5da0":"code","48a2998f":"code","a4533497":"code","0ef9d818":"code","cd572123":"code","ed4bc59d":"code","5188c56b":"code","7e72217e":"code","909c9885":"code","d7ed1557":"code","f05d1c67":"code","9ad09132":"code","13c65bf6":"code","a5f4716a":"code","b27bd10c":"code","75586444":"code","deccb0e6":"code","7bce501c":"code","2d4c8788":"code","f3643fc1":"code","fe55bbfd":"code","73a4ee74":"code","f363ecc1":"code","96b7327f":"code","1123477b":"code","3e074615":"code","1e3eaa26":"code","47d36bcb":"code","e715cd23":"code","d6374d8b":"code","1749f8f1":"code","21ebd557":"code","b5389218":"code","dfccfb8c":"code","231434ad":"code","4f4b22a4":"code","3a287a71":"code","248fce45":"code","e66f41c8":"code","8215a13a":"code","93e3e42e":"code","2afec056":"code","c11834e1":"code","f604578b":"code","1e40232d":"code","137e0663":"code","f3c01af2":"code","75736654":"markdown","d899ee4d":"markdown","fd073a6d":"markdown","73e5cf68":"markdown","05d2cf47":"markdown","7246ca44":"markdown","4a729314":"markdown","40c00f51":"markdown","bda8e3f0":"markdown","1b85a275":"markdown","22c899ae":"markdown","68cd98a2":"markdown","ebf7463e":"markdown","f9668d97":"markdown","9fb29304":"markdown","252d0930":"markdown","ea37732b":"markdown","c4a12bac":"markdown","441bd4e9":"markdown","6fa13366":"markdown","ad783dd7":"markdown","22b5cb7a":"markdown","69de10bf":"markdown","c33f94a3":"markdown","677c0e13":"markdown","77c8b719":"markdown"},"source":{"30570f06":"#Import Necessary Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,accuracy_score,mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_rows',200)\npd.set_option('display.max_columns',200)\n","b5eb3645":"#Read Data\nbike=pd.read_csv(\"..\/input\/boom-bike-dataset\/bike_sharing_data.csv\")","d65adfa4":"# Looking at the first five rows\nbike.head()","e61197b5":"#Checking the shape of the data\nbike.shape","9d22e105":"#checking for null values in dataset\nbike.isnull().sum()","6ad5f7d1":"# Let's see the statistical information of the dataset\nbike.describe()","076e3aaa":"#checking for datatypes of columns\nbike.info()","7281a124":"#Dropping the unwanted columns from the given dataset\nbike=bike.drop(['instant','dteday','casual','registered'],axis=1)","29081e5d":"# After dropping lets have a look at the first five rows\nbike.head()","4d31834c":"# Renaming some columns for better understanding\nbike.rename(columns={'yr':'year','mnth':'month','hum':'humidity','cnt':'count'},inplace=True)","9e489400":"# After Renaming the columns lets have a look at the first five rows\nbike.head()","d0ed8e26":"#From data we can see that: season,year,holiday,workingday,month,weekday,weathersit all are categorical variables\n#We will replace season,weekday,month and weathersit with appropriate values","688a1b96":"bike['season']=bike['season'].replace({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\nbike['month']=bike['month'].replace({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\nbike['weathersit']=bike['weathersit'].replace({1:'clear',2:'Mist',3:'Light snow',4:'Heavy rain'})\nbike['weekday']=bike['weekday'].replace({0:'Sun',1:'Mon',2:'Tue',3:'Wed',4:'Thu',5:'Fri',6:'Sat'})","24724ffb":"#Checking the datatypes after replacing the categorical columns with appropriate values\nbike.info()","c97e2792":"#Lets see the first five rows\nbike.head()","3b141545":"# PAIRPLOTS TO UNDERSTAND NUMERICAL VARIABLES\nsns.pairplot(data=bike)\nplt.show()","86d4bc79":"#Visualising categorical Variables to understand data better\nsns.barplot(data=bike,x=bike['season'],y=bike['count'])\nplt.show()","a1e388f2":"plt.figure(figsize=(10,5))\nsns.barplot(data=bike,x=bike['month'],y=bike['count'],hue='year')","e3fa93c2":"bike.groupby('weekday')['count'].sum().plot(kind='bar')","b65f7133":"plt.figure(figsize=(8,6))\nbike.groupby('workingday')['count'].sum().plot(kind='bar')","9eeffb05":"plt.figure(figsize=(5,5))\nsns.barplot(data=bike,x='year',y='count')","85eb898a":"sns.barplot(data=bike,x='weathersit',y='count')","720ac9a0":"plt.scatter(data=bike,x='temp',y='count')","ee0f23ab":"plt.scatter(data=bike,x='atemp',y='count')","2250187e":"plt.scatter(data=bike,x='humidity',y='count')","c953c4f6":"bike.corr()","70ea5da0":"plt.figure(figsize=(15,8))\nsns.heatmap(bike.corr(),annot=True)","48a2998f":"#correlation between temp and atemp is 0.99 which is almost 1\n#Let us drop atemp and consider temp to avoid multicollinearity\nbike=bike.drop(['atemp'],axis=1)","a4533497":"bike.head()","0ef9d818":"plt.figure(figsize=(15,8))\nsns.heatmap(bike.corr(),annot=True)","cd572123":"#Creating dummy variables\nseasons=pd.get_dummies(bike['season'],drop_first=True)\nmonths=pd.get_dummies(bike['month'],drop_first=True)\nweekdays=pd.get_dummies(bike['weekday'],drop_first=True)\nweather=pd.get_dummies(bike['weathersit'],drop_first=True)","ed4bc59d":"bike=pd.concat([bike,seasons,months,weekdays,weather],axis=1)","5188c56b":"bike.head()","7e72217e":"bike.shape","909c9885":"#Deleting the orginal columns season,weathersit,weekday,month\nbike=bike.drop(['season','month','weathersit','weekday'],axis=1)","d7ed1557":"bike.head()","f05d1c67":"bike.shape","9ad09132":"\nfrom sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(bike, train_size = 0.7, test_size = 0.3, random_state = 100)","13c65bf6":"#Rescaling the Features\nscaler = MinMaxScaler()","a5f4716a":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['temp', 'humidity', 'windspeed', 'count']\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","b27bd10c":"#Dividing into X and Y sets for the model building\ny_train = df_train.pop('count')\nX_train = df_train","75586444":"from sklearn.feature_selection import RFE\n# Running RFE with the output number of the variable equal to 15\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             # running RFE\nrfe = rfe.fit(X_train, y_train)","deccb0e6":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","7bce501c":"col = X_train.columns[rfe.support_]\ncol","2d4c8788":"X_train.columns[~rfe.support_]","f3643fc1":"bike.info()","fe55bbfd":"X_train_rfe = X_train[col]","73a4ee74":"# Building model using Statsmodel and Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","f363ecc1":"lm= sm.OLS(y_train,X_train_rfe).fit()\nprint(lm.summary())","96b7327f":"vif = pd.DataFrame()\nX = X_train_rfe.drop('const',axis=1)\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","1123477b":"#column humidity has a very high VIF so we drop it\nX_train_new1 =X_train_rfe.drop('workingday', axis=1)\nlm= sm.OLS(y_train,X_train_new1).fit()\nprint(lm.summary())","3e074615":"vif = pd.DataFrame()\nX = X_train_new1.drop('const',axis=1)\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","1e3eaa26":"#column clear has a very high VIF so we drop it\nX_train_new2 =X_train_new1.drop('humidity', axis=1)\nlm= sm.OLS(y_train,X_train_new2).fit()\nprint(lm.summary())","47d36bcb":"#column Nov has a  high pvalue so we drop it\nX_train_new3 =X_train_new2.drop('Sat', axis=1)\nlm= sm.OLS(y_train,X_train_new3).fit()\nprint(lm.summary())","e715cd23":"vif = pd.DataFrame()\nX = X_train_new3.drop('const',axis=1)\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","d6374d8b":"#temp variable has high VIF, but when we drop temp column, our R-square is dropping. \n#To maintain the R-square dropping windspeed column\nX_train_new4 =X_train_new3.drop('clear', axis=1)\nlm= sm.OLS(y_train,X_train_new4).fit()\nprint(lm.summary())","1749f8f1":"vif = pd.DataFrame()\nX = X_train_new4.drop('const',axis=1)\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","21ebd557":"#temp variable has high VIF, but when we drop temp column, our R-square is dropping. \n#To maintain the R-square dropping windspeed column\nX_train_new5 =X_train_new4.drop('windspeed', axis=1)\nlm= sm.OLS(y_train,X_train_new5).fit()\nprint(lm.summary())","b5389218":"vif = pd.DataFrame()\nX = X_train_new5.drop('const',axis=1)\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","dfccfb8c":"#Residual analysis","231434ad":"y_pred = lm.predict(X_train_new5)","4f4b22a4":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_pred), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)    ","3a287a71":"num_vars = ['temp', 'humidity', 'windspeed', 'count']\ndf_test[num_vars] = scaler.transform(df_test[num_vars])","248fce45":"y_test = df_test.pop('count')\nX_test = df_test","e66f41c8":"Xnew = X_train_new5.drop('const',axis=1)","8215a13a":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[Xnew.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","93e3e42e":"#Making predicitons\ny_pred_test = lm.predict(X_test_new)","2afec056":"## Plotting y_test and y_pred to understand the spread.\n\nfig = plt.figure()\nplt.scatter(y_test,y_pred_test)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)   ","c11834e1":"from sklearn.metrics import r2_score, adjusted_rand_score\n#Calculate the r square for test\n\nr_squared = r2_score(y_test, y_pred_test)\nr_squared\n","f604578b":"#Calculate the adjusted r square for test\nn=X_test.shape[0]\np=X_test.shape[1]\nadjr2=1-(1-r_squared)*(n-1)\/(n-p-1)\nadjr2","1e40232d":"#Calculate the r square for train\nr_squared = r2_score(y_train, y_pred)\nr_squared\n","137e0663":"#Calculate the adjusted r square for train\nn=X_train.shape[0]\np=X_train.shape[1]\nadjr2=1-(1-r_squared)*(n-1)\/(n-p-1)\nadjr2","f3c01af2":"print(lm.summary())","75736654":"#### Now we have all the variables with p-value less than 0.05","d899ee4d":"#### Bike Rentals are more during the Fall(Monsoon) season.","fd073a6d":"### let check the correlation","73e5cf68":"# Final Result Comparison\n\n#### Train R^2:0.77\n#### Train Adjusted R^2:0.76\n#### Test R^2:0.77\n#### Test Adjusted R^2:0.74","05d2cf47":"## Making Predictions","7246ca44":"#### All the variables have VIF less than 5 and it's perfect!","4a729314":"### weathersit\n#### 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n#### 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n#### 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n####  4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n#### Bikes seem to be rented more in Partly cloudy weather.","40c00f51":"# Problem Statement\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes.\nHow well those variables describe the bike demands Based on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n\n## Business Goal: \nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market.","bda8e3f0":"## Importing and understanding Data","1b85a275":"#### Bike Rentals are observed at higher temperatures","22c899ae":"##  Dealing With Categorical Variables","68cd98a2":"##  Residual Analysis of the train data","ebf7463e":"##  Splitting the Data into Training and Testing Sets","f9668d97":"#### From above graphs we can say that temp and atemp have a relationship.Lets check correlation in further analysis\n\n","9fb29304":"#### Bike Rentals are observed at higher \"feel-like\" temperatures.","252d0930":"## We can see that the equation for best fitted line is:\n### count=0.1319+0.2382*year-0.0934*holiday+0.5190*temp-0.0691*spring+0.0375*summer+0.074*winter-0.0532*Jul+0.0709*Sep-0.0410*Sun-0.0668*Mist\n\n## We can see the demand for bikes depends mainly on below variables:\n### Year,holiday,temp,spring,summer,winter,Jul,Sep,Sun,Mist\n\n### Demand increases for year,temp,summer,winter,sep\n\n### Demand decreases if it is holiday,spring,Jul,Sun,Mist\n\n\n### Final recommendations for the company:\n#### year,temp,summer,winter,sep","ea37732b":"#### if day is neither weekend nor holiday is 1,\n#### otherwise is 0\n\n### Bikes seem to be rented more on working days","c4a12bac":"#### Bike Rentals are maximum on Weekdays","441bd4e9":"#### {2018:0 ,2019:1}\n#### Bike Rental popularity has increased in 2019 when compared to 2018","6fa13366":"#### 2019 has more rentals than 2018\n#### {2018:0 ,2019:1}","ad783dd7":"### Dividing into X_test and y_test","22b5cb7a":"#### Temperature being directly proportional to Humidity, Bike Rentals are making during high humidity.","69de10bf":"#### We have a model that seems good enough to predict demand of bikes. The actual and predicted cnt i.e demand significantly overlapped, thus indicating that the model is able to explain the change in demand very well.","c33f94a3":"## Encoding the Labels & Visualization","677c0e13":"#### Now we have all the variables with p-value less than 0.05","77c8b719":"### Performing EDA"}}