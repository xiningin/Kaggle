{"cell_type":{"1f6c460f":"code","495fc66e":"code","cf7fb136":"code","99be1d62":"code","f8ea24bd":"code","c3b9bb15":"code","dfd75c27":"code","1a23b795":"code","afd5e33b":"code","03d6da6d":"code","50f23d94":"code","9a7879b0":"code","5406a0b2":"code","aedad5c7":"code","70e16873":"code","cc7f2514":"code","77bc17ae":"code","987a0a67":"code","7602aa07":"code","0cb97896":"code","5b891268":"code","eac16c60":"code","9540e6b8":"code","64763e97":"code","f50d9e42":"code","23eddbc6":"code","e7acbff8":"code","ed00f675":"code","8f2032ed":"code","b561b5b4":"code","20e31ff9":"code","8053c071":"code","b8b05278":"code","19e00105":"code","e1052c4a":"code","933f0d95":"code","031a4d06":"code","3d6fdc24":"code","b61f45f6":"code","3d318e25":"code","ca44b9b1":"code","9c72710d":"code","41d129c2":"code","57a6014f":"code","25825a5d":"code","dff3064d":"markdown","bf7eeafd":"markdown","d1ffd78c":"markdown","140fe08c":"markdown"},"source":{"1f6c460f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\nstyle.use(\"fivethirtyeight\")","495fc66e":"data=pd.read_csv(\"..\/input\/customer-personality-analysis\/marketing_campaign.csv\", sep=\"\\t\")","cf7fb136":"data.head()","99be1d62":"data.shape","f8ea24bd":"data.isna().sum()","c3b9bb15":"data.info()","dfd75c27":"data.drop('ID', axis=1, inplace=True)","1a23b795":"for col in data.columns:\n    print(f\"Number of values in  the '{col}' column:\\n{len(data[col].value_counts())}\\n\\n\")","afd5e33b":"data.drop([\"Z_Revenue\", \"Z_CostContact\", 'Dt_Customer'], axis=1, inplace=True)","03d6da6d":"categoricals = [\"Education\", 'Marital_Status', \"Kidhome\", \"Teenhome\", \"Complain\", \"Response\",\n                \"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\"]\nnumericals = []\nfor col in data.columns:\n    if not col in categoricals:\n        numericals.append(col)","50f23d94":"for col in numericals:\n    plt.figure(figsize=(20,8))\n    sns.histplot(data[col], color=\"lime\")\n    plt.show()\nfor col in categoricals:\n    plt.figure(figsize=(20,8))\n    sns.countplot(x=data[col])\n    plt.show()","9a7879b0":"plt.figure(figsize=(20,12))\nsns.heatmap(data[numericals].corr(), annot=True, cmap=\"coolwarm_r\", annot_kws={\"fontsize\":12}, fmt=\".2f\", vmin=-1)\nplt.show()","5406a0b2":"for val in [\"Absurd\", \"YOLO\", \"Alone\"]:\n    data = data[data[\"Marital_Status\"] != val]","aedad5c7":"filler = data[\"Income\"].median()\ndata[\"Income\"] = data[\"Income\"].fillna(filler)","70e16873":"orig_data = data.copy(deep=True)","cc7f2514":"from category_encoders import CountEncoder\nenc = CountEncoder(normalize=True, cols=['Education', 'Marital_Status'])\ndata = enc.fit_transform(data)","77bc17ae":"from sklearn.preprocessing import RobustScaler\nrs = RobustScaler()\nscaleddata = rs.fit_transform(data)\ndata = pd.DataFrame(scaleddata, columns=data.columns)","987a0a67":"data.shape","7602aa07":"import umap\nump = umap.UMAP(random_state=42)\numap_data = ump.fit_transform(data)","0cb97896":"plt.figure(figsize=(20,12))\nsns.scatterplot(x=umap_data[:,0], y=umap_data[:,1], hue=data[\"Kidhome\"], palette='cool')\nplt.show()","5b891268":"from sklearn.cluster import DBSCAN","eac16c60":"dbscan = DBSCAN(eps=0.32, min_samples=5)","9540e6b8":"dbscan.fit(umap_data)","64763e97":"plt.figure(figsize=(20,12))\nsns.scatterplot(x=umap_data[:,0], y=umap_data[:,1], hue=dbscan.labels_, palette='Set2')\nplt.show()","f50d9e42":"clusterlabels = pd.Series(dbscan.labels_)","23eddbc6":"clusterlabels[clusterlabels>3] = 2","e7acbff8":"plt.figure(figsize=(20,12))\nsns.scatterplot(x=umap_data[:,0], y=umap_data[:,1], hue=clusterlabels, palette='Set2')\nplt.show()","ed00f675":"orig_data.shape","8f2032ed":"clusterlabels.shape","b561b5b4":"orig_data.index = clusterlabels.index","20e31ff9":"orig_data","8053c071":"clusterlabels.index","b8b05278":"orig_data = orig_data[clusterlabels!=-1]","19e00105":"data = data[clusterlabels!=-1]","e1052c4a":"clusterlabels = clusterlabels[clusterlabels!=-1]","933f0d95":"clusterlabels.value_counts()","031a4d06":"orig_data[\"Cluster\"] = clusterlabels","3d6fdc24":"mypalette = [\"orange\", \"blue\", \"pink\", \"green\"]","b61f45f6":"for col in numericals:\n    plt.figure(figsize=(20,12))\n    sns.violinplot(x=col, data=orig_data, y=\"Cluster\", palette=mypalette, orient='h')\n    plt.show()\nfor col in categoricals:\n    plt.figure(figsize=(20,12))\n    sns.countplot(hue=col, data=orig_data, x=\"Cluster\", palette=\"Set2\")\n    plt.show()","3d318e25":"for clus in range(4):\n    plt.figure(figsize=(20,12))\n    sns.heatmap(orig_data[orig_data[\"Cluster\"]==clus][numericals].corr(), annot=True, cmap=\"coolwarm_r\", annot_kws={\"fontsize\":12}, fmt=\".2f\", vmin=-1)\n    plt.title(f\"\\nCorrelation Matrix\\nCluster {clus}\\n\\n\")\n    plt.show()","ca44b9b1":"from sklearn.feature_selection import mutual_info_classif\nfrom sklearn.metrics.cluster import normalized_mutual_info_score","9c72710d":"def mutual_info_matrix(df):\n    ncols = df.shape[1]\n    mim = pd.DataFrame( np.empty(shape=(ncols, ncols) ), index=df.columns, columns=df.columns)\n    for col in mim.columns:\n            mim.loc[:,col] = mutual_info_classif(df, df[col].astype(\"int64\"))\n    return mim","41d129c2":"data[orig_data[\"Cluster\"]==3]","57a6014f":"enc = CountEncoder(normalize=True, cols=['Education', 'Marital_Status'])\norig_data = enc.fit_transform(orig_data)","25825a5d":"for clus in range(4):\n    clus_data = orig_data[orig_data[\"Cluster\"]==clus]\n    mim = mutual_info_matrix(clus_data[categoricals])\n    plt.figure(figsize=(20,12))\n    sns.heatmap(mim, annot=True, cmap=\"coolwarm_r\", annot_kws={\"fontsize\":12}, fmt=\".2f\", vmax=0.1)\n    plt.title(f\"\\nMutual Info: Categorical Features\\nCluster {clus}\\n\\n\", fontsize=30)\n    plt.show()","dff3064d":"# Cluster Analysis \/ Profiling","bf7eeafd":"# EDA & Processing","d1ffd78c":"# Dimensionality Reduction & Clustering (with UMAP & DBSCAN)","140fe08c":"### This is a Cluster Analysis tutorial i presented as a Data Science & Machine Learning instructor in GDSC ENET'COM.  \n### It was explained during the live workshop but perhaps i will add commentary."}}