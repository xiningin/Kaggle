{"cell_type":{"e5c2aafd":"code","bc813be6":"code","0c4549ea":"code","366ec003":"code","90109848":"code","66cbd11f":"code","9fe84224":"code","6656ba54":"code","af9ea83d":"code","c262708e":"code","998c1dc1":"code","f998a0c6":"code","d731faa3":"markdown","384a06cd":"markdown"},"source":{"e5c2aafd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bc813be6":"df = pd.read_csv('..\/input\/creditcard.csv')\ndf.head()","0c4549ea":"df.dropna()\ndf.drop(['Time','Amount'], axis=1, inplace=True)\ndf.describe()","366ec003":"import matplotlib.pyplot as plt\n\ncount_classes = pd.value_counts(df['Class'], sort = True).sort_index()\ncount_classes.plot(kind = 'bar')\nplt.title(\"Fraud class histogram\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")","90109848":"number_records_fraud = len(df[df.Class == 1])\nprint(number_records_fraud)\nfraud_indices = np.array(df[df.Class == 1].index)\nnormal_indices = df[df.Class == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n\n# Under sample dataset\nunder_sample_data = df.iloc[under_sample_indices,:]\n\nX_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\ny_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']\n\n# Showing ratio\nprint(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])\/len(under_sample_data))\nprint(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])\/len(under_sample_data))\nprint(\"Total number of transactions in resampled data: \", len(under_sample_data))","66cbd11f":"from sklearn.manifold import TSNE\n\ntsne2 = TSNE(n_components=2, perplexity=20, early_exaggeration=6)\nX_tsne2 = tsne2.fit_transform(X_undersample)\n\n# Plot the training points\nx_min, x_max = X_tsne2[:, 0].min() - .5, X_tsne2[:, 0].max() + .5\ny_min, y_max = X_tsne2[:, 1].min() - .5, X_tsne2[:, 1].max() + .5\n\nfig = plt.figure(1, figsize=(8, 6))\ncol = y_undersample.values[:,0]\nplt.scatter(X_tsne2[:, 0], X_tsne2[:, 1], c=col, cmap=plt.cm.Set1, edgecolor='k')\nplt.show()","9fe84224":"from sklearn.model_selection import train_test_split\n\n# Undersampled dataset\nX_train, X_test, y_train, y_test = train_test_split(X_undersample,y_undersample,test_size = 0.3,random_state = 0,shuffle=True)\n\nprint(\"\")\nprint(\"Number transactions train dataset: \", len(X_train))\nprint(\"Number transactions test dataset: \", len(X_test))\nprint(\"Total number of transactions: \", len(X_train)+len(X_test))","6656ba54":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.regularizers import l2 # L2-regularisation\nfrom keras.callbacks import EarlyStopping\nprint(keras.__version__)","af9ea83d":"def create_model(units, optimizer, kernel_initializer):\n    model = Sequential()\n    model.add(Dense(units = units, activation = 'relu', input_dim = 28))\n    model.add(Dropout(0.1))\n    model.add(Dense(units = units, activation = 'relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(units = 1, activation = 'sigmoid'))\n    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","c262708e":"UNITS = 8\nEPOCHS = 100\nBATCH_SIZE = 32\n\nmodel = create_model(UNITS, 'adam', 'glorot_uniform')\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = BATCH_SIZE, epochs = EPOCHS, \n                    verbose=1, shuffle=True, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])","998c1dc1":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='center right')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='center right')\nplt.show()","f998a0c6":"df.drop(['Class'], axis=1, inplace=True)\npredictions = model.predict(df.values)\n\n#submitting the prediction results\nsub_df=pd.DataFrame(data=predictions,columns=['predicted'])\n#Save to csv file\nsub_df.to_csv('submission.csv',index=False)","d731faa3":"## Importing Keras libraries and packages","384a06cd":"## Prepare traing set"}}