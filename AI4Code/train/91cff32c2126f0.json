{"cell_type":{"b5c5e0f9":"code","266c5b32":"code","8b2f3a86":"code","67762463":"code","17aace79":"code","130865f9":"code","ff8a3998":"code","8db3c269":"code","eee8be86":"code","45c13402":"code","065424ef":"code","b9fd8710":"code","871e1b12":"code","23bd4698":"code","65fdb976":"code","33b26bf6":"code","7ec80bb7":"code","f2688a10":"code","c8629969":"code","ad68867c":"code","4e0da549":"code","2159fd88":"code","af51de7f":"code","057087e0":"code","97afbb53":"code","bb818b6a":"code","9aa3d3e3":"code","90a56874":"code","64e5ab7c":"code","b47ecd1b":"code","0faa29fb":"code","fb2b44af":"code","86f115f3":"code","c114f2ec":"code","d6e442f8":"code","d76b59a5":"code","e1724795":"code","5a17e64e":"code","71554010":"code","7bed6783":"code","4c485979":"code","cb5e1b63":"code","3fc8db03":"code","5fac8291":"code","ffacba7f":"code","77af2548":"code","298f9679":"code","508e20ee":"code","3eaa28d7":"code","57735f41":"code","bde9ccb2":"code","fbec8739":"code","20a45b20":"code","c7b6436b":"code","89afe614":"code","971fc81b":"code","f8f41e1c":"markdown","236b622a":"markdown","892b732c":"markdown","600e4637":"markdown","2d528e55":"markdown","41a82a67":"markdown","73554c19":"markdown","d387ba94":"markdown","940aa8d1":"markdown","86328010":"markdown","9577ae02":"markdown","5ed092d7":"markdown","13e73733":"markdown"},"source":{"b5c5e0f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","266c5b32":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain_data.head()","8b2f3a86":"test_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_data.head()","67762463":"train_data.isnull().sum()","17aace79":"test_data.isnull().sum()","130865f9":"train_data.Survived[train_data.Sex == \"male\"].value_counts(normalize=True).plot(kind=\"bar\")","ff8a3998":"train_data.Survived[train_data.Sex == \"female\"].value_counts(normalize=True).plot(kind=\"bar\")","8db3c269":"# Convert Sex to numerical value\ntrain_data['Sex'] = train_data['Sex'].map({\"male\": 0, \"female\": 1}).astype(int)\ntest_data['Sex'] = test_data['Sex'].map({\"male\": 0, \"female\": 1}).astype(int)","eee8be86":"# Is there a pattern in the Name Titles?\ntrain_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data['Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nprint(train_data['Title'].value_counts())\nprint(test_data['Title'].value_counts())","45c13402":"train_data.Survived[train_data.Title == \"Mr\"].value_counts(normalize=True).plot(kind=\"bar\")","065424ef":"train_data.Survived[train_data.Title == \"Miss\"].value_counts(normalize=True).plot(kind=\"bar\")","b9fd8710":"train_data.Survived[train_data.Title == \"Mrs\"].value_counts(normalize=True).plot(kind=\"bar\")","871e1b12":"train_data.Survived[train_data.Title == \"Master\"].value_counts(normalize=True).plot(kind=\"bar\")","23bd4698":"# Since Mr, Miss, and Mrs have a pattern give special lables to them and group the rest together\ntitle_map = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n\n# Convert Title to numerical value\ntrain_data['Title'] = train_data['Title'].map(title_map).astype(int)\ntest_data['Title'] = test_data['Title'].map(title_map).astype(int)\n\n# Drop Name\ntrain_data.drop('Name', axis=1, inplace=True)\ntest_data.drop('Name', axis=1, inplace=True)","65fdb976":"train_data.head()","33b26bf6":"test_data.head()","7ec80bb7":"# Fill in null Ages with median of each Title\ntrain_data[\"Age\"].fillna(train_data.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest_data[\"Age\"].fillna(test_data.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","f2688a10":"# Fill in null AND 0 fare with median of that Pclass (as price goes up with class)\ntrain_data['Fare'] = train_data['Fare'].replace(0,np.NaN)\ntest_data['Fare'] = test_data['Fare'].replace(0,np.NaN)\n\ntrain_data[\"Fare\"].fillna(train_data.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest_data[\"Fare\"].fillna(test_data.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)","c8629969":"# Fill in missing embarked with most popular embark location\n# What is the most popular embark location?\nprint(train_data['Embarked'].value_counts())","ad68867c":"# S is the most so use that \ntrain_data['Embarked'].fillna('S', inplace=True)","4e0da549":"# Is there a relationship between embark and survival?\ntrain_data.Survived[train_data.Embarked == \"S\"].value_counts(normalize=True).plot(kind=\"bar\")","2159fd88":"train_data.Survived[train_data.Embarked == \"C\"].value_counts(normalize=True).plot(kind=\"bar\")","af51de7f":"train_data.Survived[train_data.Embarked == \"Q\"].value_counts(normalize=True).plot(kind=\"bar\")","057087e0":"# Convert Embarked to numerical value\ntrain_data['Embarked'] = train_data['Embarked'].map({\"S\": 0, \"C\": 1, \"Q\": 2}).astype(int)\ntest_data['Embarked'] = test_data['Embarked'].map({\"S\": 0, \"C\": 1, \"Q\": 2}).astype(int)","97afbb53":"train_data","bb818b6a":"train_data.isnull().sum()","9aa3d3e3":"test_data.isnull().sum()","90a56874":"train_data['AgeBand'] = pd.cut(train_data['Age'], 5)\ntrain_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","64e5ab7c":"train_data.drop('AgeBand', axis=1, inplace=True)\n# Create Age Groups\nfor data in [train_data, test_data]:\n    data.loc[ data['Age'] <= 17, 'Age'] = 0,\n    data.loc[(data['Age'] > 17) & (data['Age'] <= 30), 'Age'] = 1\n    data.loc[(data['Age'] > 30) & (data['Age'] <= 50), 'Age'] = 2,\n    data.loc[(data['Age'] > 50) & (data['Age'] <= 65), 'Age'] = 3,\n    data.loc[ data['Age'] > 65, 'Age'] = 4 # Senior ","b47ecd1b":"# Is there a relationship between Age and survival?\nfor x in [0,1,2,3]:\n    plt.show(train_data.Survived[train_data.Age == x].value_counts(normalize=True).plot(kind=\"bar\"))","0faa29fb":"# Create Fare Groups\n# How? look at stats for both combines\n\n# Split fares into 4 parts\ntrain_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\n\n# Get median of each part\ntrain_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n","fb2b44af":"train_data.drop('FareBand', axis=1, inplace=True)\nfor data in [train_data, test_data]:\n    data.loc[ data['Fare'] <= 8, 'Fare'] = 0,\n    data.loc[(data['Fare'] > 8) & (data['Fare'] <= 15), 'Fare'] = 1,\n    data.loc[(data['Fare'] > 15) & (data['Fare'] <= 30), 'Fare'] = 2,\n    data.loc[ data['Fare'] > 30, 'Fare'] = 3","86f115f3":"# Is there a relationship between Fare and survival?\nfor x in [0,1,2,3]:\n    plt.show(train_data.Survived[train_data.Fare == x].value_counts(normalize=True).plot(kind=\"bar\"))","c114f2ec":"# Combine SibSp & Parch into a new column to get the size of a family\ntrain_data[\"Family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\ntest_data[\"Family\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1\n\n# Is there a relationship between family size and survival?\ntrain_data[\"Family\"].value_counts()","d6e442f8":"train_data.Survived[train_data.Family == 1].value_counts(normalize=True).plot(kind=\"bar\")","d76b59a5":"train_data.Survived[train_data.Family == 2].value_counts(normalize=True).plot(kind=\"bar\")","e1724795":"train_data.Survived[train_data.Family == 3].value_counts(normalize=True).plot(kind=\"bar\")","5a17e64e":"train_data.Survived[train_data.Family == 4].value_counts(normalize=True).plot(kind=\"bar\")","71554010":"train_data.Survived[train_data.Family == 5].value_counts(normalize=True).plot(kind=\"bar\")","7bed6783":"train_data.Survived[train_data.Family == 6].value_counts(normalize=True).plot(kind=\"bar\")","4c485979":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\ntrain_data['Family'] = train_data['Family'].map(family_mapping)\ntest_data['Family'] = test_data['Family'].map(family_mapping)","cb5e1b63":"# drop unused columns\ntrain_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('SibSp', axis=1, inplace=True)\n\ntrain_data.drop('Parch', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)\n\ntrain_data.drop('PassengerId', axis=1, inplace=True)\n\n# Drop Ticket as information is not needed\ntrain_data.drop('Ticket', axis=1, inplace=True)\ntest_data.drop('Ticket', axis=1, inplace=True)\n\n# Drop Cabin as there are too many empty rows\n# train_data.drop('Cabin', axis=1, inplace=True)\n# test_data.drop('Cabin', axis=1, inplace=True)","3fc8db03":"train_data.Cabin.value_counts()","5fac8291":"# Lets quantify Cabin by the first letter\ntrain_data['Cabin'] = train_data['Cabin'].str[:1]\ntest_data['Cabin'] = test_data['Cabin'].str[:1]\n\ntrain_data.Cabin.value_counts()","ffacba7f":"# Is there a relationship between cabin and survival\ntrain_data.Survived[train_data.Cabin == \"C\"].value_counts(normalize=True).plot(kind=\"bar\")","77af2548":"train_data.Survived[train_data.Cabin == \"B\"].value_counts(normalize=True).plot(kind=\"bar\")\n","298f9679":"train_data.Survived[train_data.Cabin == \"D\"].value_counts(normalize=True).plot(kind=\"bar\")\n","508e20ee":"train_data.Survived[train_data.Cabin == \"E\"].value_counts(normalize=True).plot(kind=\"bar\")\n","3eaa28d7":"train_data.Survived[train_data.Cabin == \"A\"].value_counts(normalize=True).plot(kind=\"bar\")\n","57735f41":"train_data.Survived[train_data.Cabin == \"F\"].value_counts(normalize=True).plot(kind=\"bar\")","bde9ccb2":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\ntrain_data['Cabin'] = train_data['Cabin'].map(cabin_mapping)\ntest_data['Cabin'] = test_data['Cabin'].map(cabin_mapping)\n\n# fill in null\ntrain_data[\"Cabin\"].fillna(train_data.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest_data[\"Cabin\"].fillna(test_data.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","fbec8739":"train_data","20a45b20":"test_data","c7b6436b":"# Model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nkfold = KFold(10, True, 1)\nX = train_data.drop(\"Survived\", axis=1)\ny = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()\n\n\n# kNN\nmodel = KNeighborsClassifier(n_neighbors = 13)\nscore = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='accuracy')\nprint(\"kNN: \" + str(round(np.mean(score)*100, 2)))\n\n# Naive Bayes\nmodel = GaussianNB()\nscore = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='accuracy')\nprint(\"Naive Bayes: \" + str(round(np.mean(score)*100, 2)))\n\n# Decision Tree\nmodel = DecisionTreeClassifier()\nscore = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='accuracy')\nprint(\"Decision Tree: \" + str(round(np.mean(score)*100, 2)))\n\n# Logistic Regression\nmodel = LogisticRegression()\nscore = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='accuracy')\nprint(\"Logistic Regression: \" + str(round(np.mean(score)*100, 2)))\n\n# Random Forest\nmodel = RandomForestClassifier(n_estimators=100) #, max_depth=8, random_state=1\nscore = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='accuracy')\nprint(\"Random Forest: \" + str(round(np.mean(score)*100, 2)))","89afe614":"# Commented out to run faster\n# rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n# param_grid = {\"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10], \"max_depth\" : [4, 7, 8, 9], \"n_estimators\": [50, 100, 400]}\n# gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n# gs = gs.fit(train_data.iloc[:, 1:], train_data.iloc[:, 0])\n\n# print(gs.best_score_)\n# print(gs.best_params_)","971fc81b":"model = RandomForestClassifier(criterion='gini', \n                             n_estimators=50,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_depth=7,\n                             random_state=1)\nmodel.fit(X,y)\npredictions = model.predict(X_test)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f8f41e1c":"## Higher chance of survival for kids under 18, lower chance of survival for seniors and young adults","236b622a":"## Families of size 2,3 and 4 have the highest chance of survival","892b732c":"# Predict","600e4637":"# Hyperparameter Tuning","2d528e55":"# Goal: To predict survival of Titanic Passengers","41a82a67":"## Identify patterns to convert descriptive data to numerical","73554c19":"## We can see that \n### 1. \"Mr\" has a high chance of dying\n### 2. \"Miss\" and \"Mrs\" have a high chance of surviving \n### 3. \"Master\" has a 55-45 split\n","d387ba94":"## Use Random Forest as that is the best","940aa8d1":"# Model Selection","86328010":"## Embarking on \"S\" and \"Q\" have a higher rate of survival","9577ae02":"# Feature Engineering","5ed092d7":"## Females are more likely to survive than males","13e73733":"# Setup"}}