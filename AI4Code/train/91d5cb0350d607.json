{"cell_type":{"b5579b2f":"code","b582c0e7":"code","d89178c2":"code","48bafe37":"code","523bb47a":"code","2a66fff6":"code","3349f788":"code","ba27d2e7":"code","c37f8444":"code","49e6788d":"code","c754abef":"code","50d39829":"code","cde33a16":"code","dde6bbfa":"code","47cbfd93":"code","4765105a":"code","01e8483d":"code","864f0c37":"code","8ee330c3":"code","319e6b90":"code","825199f9":"code","9cb9bc0d":"code","6a3c4d19":"code","778f4fee":"code","8d63e7eb":"code","75dd41f0":"code","b1093ea3":"code","afa9f58e":"code","efce56a5":"code","a65bec24":"code","1452f16b":"code","b3e407af":"code","206fdd90":"code","bb19e44c":"code","ff2838d2":"code","2743eb95":"code","f62e2f14":"code","6d746b81":"code","ea2e126f":"code","f12b3bb4":"code","22e46f05":"code","de023c30":"code","5855a399":"code","b00f36d3":"code","dac42305":"code","abd67e59":"code","348cd579":"code","ef9746f9":"code","8f095feb":"markdown","ed1fbfa2":"markdown"},"source":{"b5579b2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b582c0e7":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, models\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom torchvision import transforms, utils\nfrom torch.utils.data import DataLoader\nfrom skimage import io, transform\n\nimport glob\nimport re\n\nimport cv2 as cv\n","d89178c2":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","48bafe37":"train = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")","523bb47a":"train","2a66fff6":"y=train['Pawpularity']\ny","3349f788":"class Pet_Data(Dataset):\n\n    def __init__(self, path=None, transform=None):\n        self.transform = transform\n        self.path = path\n        self.img_path = [] \n        for dirname, _, filenames in os.walk(self.path):\n            for filename in filenames:\n                self.img_path.append(os.path.join(dirname, filename))\n\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_path)\n\n    def __getitem__(self, idx):\n        img_name = os.path.splitext(os.path.relpath(self.img_path[idx],self.path))[0]\n#         print(img_name)\n        i = np.where((train['Id'] == img_name))\n#         print(f\" i:{i[0][0]}\")\n        i = i[0][0]\n        pwp = train['Pawpularity'][i] \n#         pwp = pwp\/100\n        image = io.imread(self.img_path[idx])\n\n        if self.transform:\n            trns_image = self.transform(image)\n        \n        sample = {'image': trns_image, 'name': img_name, 'pwp':pwp}\n        return sample","ba27d2e7":"# class Rescale_Img(object):\n#     def __init__(self, output_size):\n#         self.output_size = int(output_size)\n#         print(self.output_size)\n\n#     def __call__(self, sample):\n#         image,name, pwp =sample['image'], sample['name'], sample['pwp']\n#         img = transform.resize(image, (self.output_size, self.output_size,3))\n#         return {'image': img, 'name': name, 'pwp':pwp}\n    \n\n\n# class Normalize_Img(object):\n#     def __call__(self,sample):\n#         image,name,pwp= sample['image'],sample['name'],sample['pwp']\n# #         mn = np.min(image)\n# #         mx = np.max(image)\n# #         img = (image - mn) * (1.0 \/ (mx - mn) )\n# #         img = cv.imread(image)\n#         norm_img = np.zeros((256,256))\n#         final_img = cv.normalize(image,  norm_img, 0, 1, cv.NORM_MINMAX)\n# #         print(f\"img: {image} \\n norm: {final_img}\")\n#         return {'image': final_img, 'name': name, 'pwp':pwp}\n\n\n# class ToTensor(object):\n#     \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n\n#     def __call__(self, sample):\n#         image,name,pwp= sample['image'],sample['name'],sample['pwp']\n\n#         # swap color axis because\n#         # numpy image: H x W x C\n#         # torch image: C x H x W\n#         image = torch.from_numpy(image.transpose((2, 0, 1)))\n#         print(f\"type: {type(image)}\")\n#         return {'image': image,\n#                 'name': name,\n#                 'pwp':pwp}","c37f8444":"# train_data = Pet_Data(path='\/kaggle\/input\/petfinder-pawpularity-score\/train\/',transform = transforms.Compose([Rescale_Img(256),Normalize_Img(),ToTensor() ]) )\n# test_data = Pet_Data(path='\/kaggle\/input\/petfinder-pawpularity-score\/test\/',transform = transforms.Compose([Rescale_Img(256), Normalize_Img(),ToTensor(), ]) )\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\ntrain_data = Pet_Data(path='\/kaggle\/input\/petfinder-pawpularity-score\/train\/', transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((512,512)),\n    transforms.RandomHorizontalFlip(),\n#     transforms.RandomRotation(90),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=MEAN, std=STD),\n\n]) )\n\ntest_data = Pet_Data(path='\/kaggle\/input\/petfinder-pawpularity-score\/test\/', transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((512,512)),\n    transforms.RandomHorizontalFlip(),\n#     transforms.RandomRotation(90),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=MEAN, std=STD),\n]) )","49e6788d":"train_dataloader = DataLoader(train_data, batch_size=32, shuffle=False)\ntest_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)","c754abef":"len(train_data)","50d39829":"# train_data[2]","cde33a16":"for i in range (10):\n    print(f\"val : {train_data[i]['image'].shape}  id: {train_data[i]['name']}  pwp: {train_data[i]['pwp']}\")","dde6bbfa":"# class CNN_Net(nn.Module):\n    \n#     def __init__(self):\n#         super(CNN_Net,self).__init__()\n#         self.model_layers =nn.Sequential(\n            \n#             nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1),\n#             nn.ReLU(),\n\n# #             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3),\n#             nn.ReLU(),\n\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1),\n#             nn.ReLU(),\n            \n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, stride=2),\n#             nn.ReLU(),\n#             nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2),\n#             nn.ReLU(),\n            \n#             nn.MaxPool2d(kernel_size=2, stride=2),\n            \n#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1),\n#             nn.ReLU(),\n               \n#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1),\n#             nn.ReLU(),\n            \n#             nn.Flatten(),\n            \n#             nn.Linear(4608,2024),\n#             nn.ReLU(),\n#             nn.Linear(2024,100),\n#             nn.ReLU(),\n#             nn.Linear(100,10),\n#             nn.ReLU(),\n\n#             nn.Linear(10,1),\n\n#         )\n    \n    \n#     def forward(self,x):\n#         x = self.model_layers(x)\n#         return x\n    ","47cbfd93":"# model = CNN_Net().to(device)\n# model=model.float()","4765105a":"import torch\nimport torch.nn as nn\n\nfrom functools import partial\nfrom dataclasses import dataclass\nfrom collections import OrderedDict","01e8483d":"class Conv2dAuto(nn.Conv2d):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.padding =  (self.kernel_size[0] \/\/ 2, self.kernel_size[1] \/\/ 2) # dynamic add padding based on the kernel_size\n        \nconv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False) ","864f0c37":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.in_channels, self.out_channels =  in_channels, out_channels\n        self.blocks = nn.Identity()\n        self.shortcut = nn.Identity()   \n    \n    def forward(self, x):\n        residual = x\n        if self.should_apply_shortcut: residual = self.shortcut(x)\n        x = self.blocks(x)\n        x += residual\n        return x\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.out_channels","8ee330c3":"from collections import OrderedDict\n\nclass ResNetResidualBlock(ResidualBlock):\n    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n        super().__init__(in_channels, out_channels)\n        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n        self.shortcut = nn.Sequential(OrderedDict(\n        {\n            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n                      stride=self.downsampling, bias=False),\n            'bn' : nn.BatchNorm2d(self.expanded_channels)\n            \n        })) if self.should_apply_shortcut else None\n        \n        \n    @property\n    def expanded_channels(self):\n        return self.out_channels * self.expansion\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.expanded_channels","319e6b90":"from collections import OrderedDict\ndef conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n                          'bn': nn.BatchNorm2d(out_channels) }))","825199f9":"class ResNetBasicBlock(ResNetResidualBlock):\n    expansion = 1\n    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n        super().__init__(in_channels, out_channels, *args, **kwargs)\n        self.blocks = nn.Sequential(\n            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n            activation(),\n            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n        )\n    ","9cb9bc0d":"class ResNetBottleNeckBlock(ResNetResidualBlock):\n    expansion = 4\n    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n        self.blocks = nn.Sequential(\n           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n             activation(),\n             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n             activation(),\n             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n        )\n    ","6a3c4d19":"class ResNetLayer(nn.Module):\n    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n        super().__init__()\n        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n        downsampling = 2 if in_channels != out_channels else 1\n        \n        self.blocks = nn.Sequential(\n            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n            *[block(out_channels * block.expansion, \n                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n        )\n\n    def forward(self, x):\n        x = self.blocks(x)\n        return x","778f4fee":"class ResNetEncoder(nn.Module):\n    \"\"\"\n    ResNet encoder composed by increasing different layers with increasing features.\n    \"\"\"\n    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n        super().__init__()\n        \n        self.blocks_sizes = blocks_sizes\n        \n        self.gate = nn.Sequential(\n            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(self.blocks_sizes[0]),\n            activation(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n        self.blocks = nn.ModuleList([ \n            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n                        block=block,  *args, **kwargs),\n            *[ResNetLayer(in_channels * block.expansion, \n                          out_channels, n=n, activation=activation, \n                          block=block, *args, **kwargs) \n              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n        ])\n        \n        \n    def forward(self, x):\n        x = self.gate(x)\n        for block in self.blocks:\n            x = block(x)\n        return x","8d63e7eb":"class ResnetDecoder(nn.Module):\n    \"\"\"\n    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n    correct class by using a fully connected layer.\n    \"\"\"\n    def __init__(self, in_features, n_classes):\n        super().__init__()\n        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.decoder = nn.Linear(in_features, n_classes)\n\n    def forward(self, x):\n        x = self.avg(x)\n        x = x.view(x.size(0), -1)\n        x = self.decoder(x)\n        return x","75dd41f0":"class ResNet(nn.Module):\n    \n    def __init__(self, in_channels, n_classes, *args, **kwargs):\n        super().__init__()\n        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","b1093ea3":"def resnet18(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n\ndef resnet34(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n\ndef resnet50(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n\ndef resnet101(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n\ndef resnet152(in_channels, n_classes):\n    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])","afa9f58e":"# conv = conv3x3(in_channels=32, out_channels=64)\n# print(conv)\n# del conv","efce56a5":"class MyModifiedModel(nn.Module):\n    def __init__(self, resnet50):\n        super(MyModifiedModel,self).__init__()\n        self.resnet = resnet50\n        self.ln1 = nn.Linear(1000,10)\n        self.ln2 = nn.Linear(10,1)\n\n        \n    def forward(self, x):\n        x = self.resnet(x)\n        x = self.ln1(x)\n        x = self.ln2(x)\n\n        return x","a65bec24":"resnet50 = resnet18(3, 1000)\n\nfor params in resnet50.parameters():\n    params.required_grad=False\nmodel = MyModifiedModel(resnet50)\nmodel.to('cuda')","1452f16b":"# !pip install torchsummary","b3e407af":"# from torchsummary import summary\n# summary(model,(3,512,512))","206fdd90":"learning_rate = 0.001\nbatch_size = 16\nepochs = 5","bb19e44c":"loss_fn = nn.MSELoss()","ff2838d2":"# model = model.cuda()","2743eb95":"optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","f62e2f14":"def train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    train_loss =0\n    for i,sample in enumerate(dataloader):\n        optimizer.zero_grad()\n        pred = model(sample['image'].float().cuda())\n#         print((sample['image'].float().cuda()))\n        true_val = sample['pwp'].float().cuda()\n        true_val = true_val.unsqueeze(1)\n#         print(f\"true Val: {true_val} \\t Pred: {pred}\")\n        loss = torch.sqrt(loss_fn(pred,true_val ))\n#         print(f\"loss: {loss.item()}\")\n        train_loss+=loss.item()\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n\n        if(i>0 and i % 20 == 0):\n            print(f\"loss: {train_loss\/i:>4f}  [{i:>5d}\/{size:>5d}]\")\n            print(f\"true Val: {true_val} \\t Pred: {pred}\")\n    return train_loss\n\n# def test_loop(dataloader, model, loss_fn):\n#     size = len(dataloader.dataset)\n#     num_batches = len(dataloader)\n#     test_loss, correct = 0, 0\n\n#     with torch.no_grad():\n#         for batch,sample in enumerate(dataloader):\n#             pred = model(sample['image'].float().cuda())\n#             true_val = sample['label'].long()\n#             true_val = np.argmax(true_val,axis=1).cuda()\n#             test_loss += loss_fn(pred, true_val).item()\n#             correct += (1 if torch.equal(np.argmax(pred, axis=1), np.argmax(sample['label'], axis=1)) else 0)\n# # (pred == sample['label'])\n#     test_loss \/= num_batches\n#     correct \/= size\n#     print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")","6d746b81":"def train_loop_without_batch(train_data, model, loss_fn, optimizer):\n    invMean = [-m\/s for (m, s) in zip(MEAN, STD)]\n    invStd = [1\/s for s in STD]\n    # define our de-normalization transform\n    deNormalize = transforms.Normalize(mean=invMean, std=invStd)\n    train_loss = 0\n    for i,sample in enumerate(train_data):\n#         print(sample['image'])\n#         image = deNormalize(sample['image']).cpu().numpy()\n#         image = (image * 255).astype(\"uint8\")\n#         image = image.transpose((1, 2, 0))\n#         plt.imshow(image)\n        pred = model(sample['image'].float().cuda().unsqueeze(0))\n#         pred = model(image)\n#         print(sample['image'].float().cuda().unsqueeze(0))\n        true_val = sample['pwp']\n        true_torch = torch.from_numpy(np.asarray(true_val))\n\n#         print(f\"true Val: {true_val} \\t Pred: {pred}\")\n#         print(f\"Pred: {pred.size()}\")\n\n#         print(f\"true Val: {true_torch.size()}\") \n\n        loss = torch.sqrt(loss_fn(pred.to(device).float(),true_torch.to(device).float() ))\n#         print(f\"loss: {loss}\")\n        train_loss+=loss.item()\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if(i>0 and i % 200 == 0):\n            print(f\"\\n{i} \/ {len(train_data)} \\n ----------------\")\n            print(f\"Avg Loss :{train_loss\/200}\")\n            print(f\"true Val: {true_val} \\t Pred: {pred}\")\n            train_loss=0\n","ea2e126f":"epochs = 70\n# train_loss = []\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n#     train_loss.append(loss)\n#     test_loop(test_dataloader, model, loss_fn)\nprint(\"Done!\")","f12b3bb4":"# torch.save(model,\"..\/input\")","22e46f05":"class Test_Pet_Data(Dataset):\n\n    def __init__(self, path=None, transform=None):\n        self.transform = transform\n        self.path = path\n        self.img_path = [] \n        for dirname, _, filenames in os.walk(self.path):\n            for filename in filenames:\n                self.img_path.append(os.path.join(dirname, filename))\n\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_path)\n\n    def __getitem__(self, idx):\n        img_name = os.path.splitext(os.path.relpath(self.img_path[idx],self.path))[0]\n#         print(img_name)\n#         i = np.where((train['Id'] == img_name))\n#         print(f\" i:{i[0][0]}\")\n#         i = i[0][0]\n#         pwp = train['Pawpularity'][i] \n#         pwp = pwp\/100\n        image = io.imread(self.img_path[idx])\n\n        if self.transform:\n            trns_image = self.transform(image)\n        \n        sample = {'image': trns_image, 'name': img_name,}\n        return sample","de023c30":"test_data = Test_Pet_Data(path='\/kaggle\/input\/petfinder-pawpularity-score\/test\/', transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((512,512)),\n    transforms.RandomHorizontalFlip(),\n#     transforms.RandomRotation(90),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=MEAN, std=STD),\n]) )","5855a399":"for i in range (len(test_data)):\n    print(f\"val : {test_data[i]['image'].shape}  id: {test_data[i]['name']}\")","b00f36d3":"df = pd.DataFrame(columns=['Id','Pawpularity' ])","dac42305":"df","abd67e59":"# test_pred = []\nfor i,sample in enumerate(test_data):\n#         print(sample['image'])\n#         image = deNormalize(sample['image']).cpu().numpy()\n#         image = (image * 255).astype(\"uint8\")\n#         image = image.transpose((1, 2, 0))\n#         plt.imshow(image)\n        pred = model(sample['image'].float().cuda().unsqueeze(0))\n#         print(f\"{sample['name']} , {pred.squeeze(0).squeeze(0)}\")\n#         pred = model(image)\n        pred_val = pred.squeeze(0).squeeze(0)\n        pred_val = float(pred_val)\n        df=df.append({'Id':sample['name'], 'Pawpularity':pred_val},ignore_index=True)","348cd579":"df","ef9746f9":"df.to_csv('submission.csv',index=False)","8f095feb":"Resnet implementaion ends here","ed1fbfa2":"Manual Resnet Implementation\n\nsource to original [github](https:\/\/github.com\/FrancescoSaverioZuppichini\/ResNet\/blob\/master\/ResNet.ipynb)"}}