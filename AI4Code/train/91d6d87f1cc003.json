{"cell_type":{"cc2d81d5":"code","664e00d7":"code","bf16c462":"code","75a3a01b":"code","0690acb7":"code","5f3c0730":"code","ce184d83":"code","f8e2753e":"code","151cf045":"code","58943b79":"code","92852574":"code","ee5ac0f9":"code","d4d7f3b5":"code","5ddb3300":"code","b58023f4":"code","c34295f9":"code","ebcd8ab1":"code","b85806c6":"code","1c7496ef":"code","b5788a5f":"code","3924dd61":"code","18bd616d":"code","ea22c7c6":"code","b478f5ad":"code","8e9e5075":"markdown","f00353b8":"markdown","41b1c2d6":"markdown","c6448b8f":"markdown","8d7108c1":"markdown","48ae6bbe":"markdown","18c42721":"markdown","daedf3c1":"markdown","6538490c":"markdown","ab84f6dc":"markdown","393c58a4":"markdown","469cf4e1":"markdown","32261ba6":"markdown","e7a698b5":"markdown"},"source":{"cc2d81d5":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing","664e00d7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bf16c462":"filep = \"\/kaggle\/input\/heart-disease-uci\/heart.csv\"\ndf = pd.read_csv(filep)\nnp.random.seed(42)","75a3a01b":"#rows and columns\nprint(df.shape)\ndf.head()","0690acb7":"df.info()","5f3c0730":"#checking for missing values\ndf.isnull().sum()","ce184d83":"plt.rcParams['figure.dpi'] = 200\nsns.set_style('darkgrid')\nfig=plt.figure(figsize=(20,8),facecolor='white')\nax=[None for i in range(2)]\ngs=fig.add_gridspec(2,1)\ngs.update(wspace=0, hspace=0.8)\n\nax[0]=fig.add_subplot(gs[0,0])\nax[1]=fig.add_subplot(gs[1,0])\n\nsns.kdeplot(data=df[df.target==1],x='age',ax=ax[0],shade=True,alpha=1)\nsns.kdeplot(data=df[df.target==0],x='age',ax=ax[0],shade=True,alpha=0.5)\nsns.kdeplot(data=df[df.target==1],x='chol',ax=ax[1],shade=True,alpha=1)\nsns.kdeplot(data=df[df.target==0],x='chol',ax=ax[1],shade=True,alpha=0.5)\n\nfor i in range(2):\n    ax[i].set_yticklabels('')\n    ax[i].set_ylabel('')\n    ax[i].tick_params(axis='y',length=0)\n    \n    for direction in ['top','right','left']:\n        ax[i].spines[direction].set_visible(False)","f8e2753e":"plt.figure(figsize=(15,8))\nsns.countplot(df[\"age\"])","151cf045":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.countplot(df['fbs'])\n\nplt.subplot(2,3,2)\nsns.countplot(df['exang'])\n\nplt.subplot(2,3,3)\nsns.countplot(df['slope'])\n\nplt.subplot(2,3,4)\nsns.countplot(df['ca'])\n\nplt.subplot(2,3,5)\nsns.countplot(df['thal'])\n\nplt.subplot(2,3,6)\nsns.countplot(df['target'])\n","58943b79":"plt.figure(figsize=(8, 4))\nsns.scatterplot(x=df[\"age\"], y=df[\"chol\"], hue=df[\"target\"])\nplt.legend()","92852574":"plt.figure(figsize=(14, 6))\nsns.lmplot(x=\"age\", y=\"chol\", hue=\"target\", data=df,size=4, aspect=1)\nplt.legend()","ee5ac0f9":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.barplot(x=df[\"target\"], y=df[\"fbs\"] )\n\nplt.subplot(2,3,2)\nsns.barplot(x=df[\"target\"], y=df['exang'])\n\nplt.subplot(2,3,3)\nsns.barplot(x=df[\"target\"], y=df['slope'])\n\nplt.subplot(2,3,4)\nsns.barplot(x=df[\"target\"], y=df['ca'])\n\nplt.subplot(2,3,5)\nsns.barplot(x=df[\"target\"], y=df['thal'])\n\nplt.subplot(2,3,6)\nsns.barplot(x=df[\"target\"], y=df['age'])","d4d7f3b5":"plt.figure(figsize=(20,10))\nsns.barplot(x=\"trestbps\", y=\"chol\", data=df)","5ddb3300":"plt.figure(figsize=(20,15))\n\nplt.subplot(3,2,1)\nsns.distplot(df['age'])\n\nplt.subplot(3,2,2)\nsns.distplot(df['chol'])\n\nplt.subplot(3,2,3)\nsns.distplot(df['thalach'])\n\nplt.subplot(3,2,4)\nsns.distplot(df['oldpeak'])\n\nplt.subplot(3,2,5)\nsns.distplot(df['trestbps'])","b58023f4":"sns.pairplot(df[['age','chol','trestbps',\"target\"]],hue=\"target\",  height=3)","c34295f9":"plt.figure(figsize=(12,8)) \nsns.heatmap(df.corr(), annot=True, cmap='gist_yarg', linewidths = 2)","ebcd8ab1":"X = df.drop(\"target\",axis=1,  inplace=False)\ny = df[\"target\"].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","b85806c6":"stan_scaler = StandardScaler()\nX_train = stan_scaler.fit_transform(X_train)\nX_test = stan_scaler.transform(X_test)","1c7496ef":"def report(model_predict, model_acc):\n    print(\"Model accuracy:\" ,model_acc*100,\"%\" )\n    print(\"\\n\", classification_report(y_test, model_predict.round()))","b5788a5f":"#Our vanilla Linear Regression model\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nlin_reg_predict = lin_reg.predict(X_test)\nlin_reg_acc = accuracy_score(y_test, lin_reg_predict.round())\nreport(lin_reg_predict, lin_reg_acc)","3924dd61":"from sklearn.neighbors import KNeighborsClassifier\n\nknc = KNeighborsClassifier()\nknc.fit(X_train, y_train)\nknc_predict = knc.predict(X_test)\nknc_acc = accuracy_score(y_test, knc_predict)\nreport(knc_predict, knc_acc)","18bd616d":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=15, max_depth=5, random_state=42)\nrfc.fit(X_train, y_train)\nrfc_predict = rfc.predict(X_test)\nrfc_acc = accuracy_score(y_test, rfc_predict)\nreport(rfc_predict, rfc_acc)","ea22c7c6":"from xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=3, learning_rate=0.1,objective=\"binary:logistic\", n_estimators=15)\nxgb.fit(X_train, y_train)\nxgb_predict = xgb.predict(X_test)\nxgb_acc = accuracy_score(y_test, xgb_predict)\nreport(xgb_predict, xgb_acc)","b478f5ad":"print(\"Linear Regression model has a accuracy score of: {x:.5f}% \\n\".format(x=(lin_reg_acc*100)))\nprint(\"KNeighbors model has a accuracy score of: {x:.5f}%\\n\".format(x=(knc_acc*100)))\nprint(\"RandomForest model has a accuracy score of: {x:.5f}%\\n\".format(x=(rfc_acc*100)))\nprint(\"Extreme Gradient Boost model has a accuracy score of: {x:.5f}%\".format(x=(xgb_acc*100)))","8e9e5075":"# Data Visualization\n> A couple quick kde plots to see the relationship between \"age\" and \"chol\" to \"target","f00353b8":"# Getting ready for ML models","41b1c2d6":"> No missing values on the data set","c6448b8f":"**Countplots**","8d7108c1":"# ML models \n> I'm using a couple reggression , classification models and of course Kaggle's favorite model: XGB (Extreme Gradient Boost). Not using NN this time because the dataset is too small and the task seems fairly easy to handle with simpler models.","48ae6bbe":"# Get the data","18c42721":"**Heatmap**","daedf3c1":"# K nearest neighbors wins with 90% acc\n\n> I plan on revisiting this small project to polish the data visualization and models hyperparamenter.\n\n> Any feed back is appreciated!\n\n> Have a great day.","6538490c":"Description per column:\n\n    -age\n    -sex\n    -cp: chest pain type (1, 2, 3, 4)\n    -trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n    -chol: serum cholestoral in mg\/dl\n    -fbs: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n    -restecg: resting electrocardiographic results (0, 1, 2)\n    -thalach: maximum heart rate achieved\n    -exang: exercise induced angina (1 = yes; 0 = no)\n    -oldpeak = ST depression induced by exercise relative to rest\n    -slope: the slope of the peak exercise ST segment (1, 2, 3)\n    -ca: number of major vessels colored by flourosopy (0, 1, 2, 3)\n    -thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n    -target: diagnosis of heart disease (0: < 50% diameter narrowing, 1: > 50% diameter narrowing)\n    \nDescriptions retrieved from https:\/\/archive.ics.uci.edu\/ml\/datasets\/heart+Disease","ab84f6dc":"**Scatterplots**","393c58a4":"**Barplots**","469cf4e1":"**Distplots**","32261ba6":"**Pairplot**","e7a698b5":"# Importing libraries"}}