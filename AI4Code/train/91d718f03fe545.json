{"cell_type":{"156aa053":"code","fa6e7d20":"code","de62bc15":"code","965e77af":"code","61654637":"code","f0104871":"code","e4a950a8":"code","79537a53":"code","0056e263":"code","f1c36591":"code","0a3576a3":"code","1d38710f":"code","ed99e9a1":"code","12839148":"code","9046045d":"code","80774eef":"markdown","6747111d":"markdown","34be5a75":"markdown","29155159":"markdown","eb9f56c9":"markdown"},"source":{"156aa053":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom functools import reduce\nimport matplotlib.pyplot as plt\n%matplotlib inline","fa6e7d20":"df = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndf.head()","de62bc15":"species = dict(zip(list(df['Species'].unique()), ([0, 1, 2])))\nprint(\"Species:\",species)","965e77af":"categories = { v:k for (k,v) in species.items() }\nprint(\"Categories:\", categories)","61654637":"# Replace species by one hot encodings\ndf['Species'].replace(species, inplace=True)\ndf['Species'].unique()\n\n# Training DataFrame\niris = df[['PetalLengthCm', 'PetalWidthCm', 'Species']]\niris.head()","f0104871":"d = 2\n\nfeatures = iris[['PetalLengthCm', 'PetalWidthCm']].values\nlabels = iris['Species'].values\n\nX = torch.from_numpy(features.astype(np.float32))\ny = torch.from_numpy(labels)","e4a950a8":"def torch_kron_prod(a, b):\n    res = torch.einsum('ij,ik->ijk', [a, b])\n    res = torch.reshape(res, [-1, np.prod(res.shape[1:])])\n    return res","79537a53":"def torch_bin(x, cut_points, temperature=0.1):\n    # x is a N-by-1 matrix (column vector)\n    # cut_points is a D-dim vector (D is the number of cut-points)\n    # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n    D = cut_points.shape[0]\n    W = torch.reshape(torch.linspace(1.0, D + 1.0, D + 1), [1, -1])\n    cut_points, _ = torch.sort(cut_points)  # make sure cut_points is monotonically increasing\n    b = torch.cumsum(torch.cat([torch.zeros([1]), -cut_points], 0),0)\n    h = torch.matmul(x, W) + b\n    res = torch.exp(h-torch.max(h))\n    res = res\/torch.sum(res, dim=-1, keepdim=True)\n    return h","0056e263":"def nn_decision_tree(x, cut_points_list, leaf_score, temperature=0.1):\n    # cut_points_list contains the cut_points for each dimension of feature\n    leaf = reduce(torch_kron_prod,\n                  map(lambda z: torch_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))\n    return torch.matmul(leaf, leaf_score)","f1c36591":"# \"Petal length\" and \"Petal width\"\nnum_cut = [1, 1]\nnum_leaf = np.prod(np.array(num_cut) + 1)\nnum_class = 3","0a3576a3":"cut_points_list = [torch.rand([i], requires_grad=True) for i in num_cut]\nleaf_score = torch.rand([num_leaf, num_class], requires_grad=True)\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(cut_points_list + [leaf_score], lr=0.01)","1d38710f":"model = nn.Sequential(\n          nn.Linear(2,16),\n          nn.ReLU(),\n          nn.Linear(16,2),\n          nn.Sigmoid()\n        )","ed99e9a1":"for i in range(3000):\n    optimizer.zero_grad()\n    out = model(X)\n    y_pred = nn_decision_tree(out, cut_points_list, leaf_score, temperature=0.1)\n    loss = loss_function(y_pred, y)\n    loss.backward()\n    optimizer.step()\n    if i % 200 == 0:\n        print(\"i:{:4d} -- Loss:{:}\".format(i, loss.detach().numpy()))\nprint('Error rate %.2f' % (1-np.mean(np.argmax(y_pred.detach().numpy(), axis=1)==y.detach().numpy())))","12839148":"def predict(petal_length, petal_width):\n    X = torch.tensor([[petal_length, petal_width]]).type(torch.float32)\n    out = model(X)\n    y_pred = nn_decision_tree(out, cut_points_list, leaf_score, temperature=0.1)\n    return categories[torch.max(y_pred, axis=1)[1].item()]","9046045d":"# predict using parameters\n\npetal_length = 2.0\npetal_width = 4.0\n\ncategory = predict(petal_length, petal_width)\n\nprint(\"Category:\", category)","80774eef":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:white; background:#a185cf; border:1px dashed green;\" role=\"tab\" aria-controls=\"home\"><center>Prepare Data<\/center><\/h3>","6747111d":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:white; background:#a185cf; border:1px dashed green;\" role=\"tab\" aria-controls=\"home\"><center>Prediction<\/center><\/h3>","34be5a75":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:white; background:#a185cf; border:1px dashed green;\" role=\"tab\" aria-controls=\"home\"><center>Implementation<\/center><\/h3>","29155159":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:white; background:#a185cf; border:1px dashed green;\" role=\"tab\" aria-controls=\"home\"><center>Training<\/center><\/h3>","eb9f56c9":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/19\/19\/default-backgrounds\/dataset-cover.jpg\"\/>\n<\/div>"}}