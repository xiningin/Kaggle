{"cell_type":{"42437d2e":"code","2c0881a2":"code","378fe5f8":"code","448f13df":"code","7dfa3e77":"code","57d4fc9e":"code","6f5ec6f3":"code","607398a3":"code","a79b4b7b":"code","91478c28":"code","0384ed4b":"code","a716a568":"code","31f1ba0b":"code","ae9fb9d3":"markdown","8d474b19":"markdown","57b711ad":"markdown","3ea7ed37":"markdown","ca8810ec":"markdown","f9013a0d":"markdown","0bcb24ff":"markdown","74cd75cb":"markdown","998a6ffa":"markdown","af52d95f":"markdown","fc444a9a":"markdown","ee7109a3":"markdown"},"source":{"42437d2e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n","2c0881a2":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata=pd.read_csv('\/kaggle\/input\/heightvsweight-for-linear-polynomial-regression\/HeightVsWeight.csv')\n","378fe5f8":"#data=pd.read_csv(\"HeightVsWeight.csv\")\ndata.head(4)","448f13df":"## Make a plot to see how the data is distributed","7dfa3e77":"sns.scatterplot(x=\"Age\", y=\"Height\", data=data) \n","57d4fc9e":"x=data.iloc[:,:-1].values ## Independent variable\ny=data.iloc[:,-1].values ## Dependent variable","6f5ec6f3":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(x,y)","607398a3":"## First let's create a plot with our data, to see the distribution of the data\nplt.scatter(x,y, color=\"red\")\nplt.plot(x, lin_reg.predict(x), color=\"blue\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Height\")\nplt.title(\"Linear Regression for Height and Weight\")","a79b4b7b":"lin_reg.predict([[30]]) ## there shall be a list inside","91478c28":"from sklearn.preprocessing import PolynomialFeatures ## This is those degrees of X like x\u201c2 or x\u201c3 and so on\npoly_reg=PolynomialFeatures(degree=3)\nx_poly=poly_reg.fit_transform(x)\n\nlin_reg2=LinearRegression()\nlin_reg2.fit(x_poly,y)\n\n## Created a linear regresssion based on the matrix of features and y\n","0384ed4b":"x_grid=np.arange(min(x),max(x),0.1) ## step is 0.1 increasing the density of the curve\nx_grid=x_grid.reshape((len(x_grid),1))\n\n\nplt.scatter(x,y,color=\"red\")\nplt.plot(x,lin_reg2.predict(x_poly), color=\"blue\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Height\")\nplt.title(\"Polynomial Linear Regression \")","a716a568":"lin_reg2.predict(poly_reg.fit_transform([[30]]))","31f1ba0b":"data[data[\"Age\"]==30]","ae9fb9d3":"So according to our linear model, for the age 30, the height shall be 146---- Does not seem right","8d474b19":" It does not seem that the regression model fits to our data","57b711ad":"## Training the Linear Regression model on the whole dataset","3ea7ed37":"## Predicting a new result with Linear Regression \n","ca8810ec":" ## Predicting a new result with Polynomial Linear Regression \n","f9013a0d":"Conclusion: Better regression model is the polynomial regression with Degree - 3","0bcb24ff":" As it seems that linear regression does not fit properly, let's try to build a polynomial regression","74cd75cb":" It is definitelly better, but need more adjustment","998a6ffa":"## Polynomial Regression ","af52d95f":"## Visualising the Polynomial Regression results (for higher resolution and smoother curve)\n\n","fc444a9a":"## Visualising the Linear Regression results","ee7109a3":"## Let's find out what is the predicted height for the particular age groups"}}