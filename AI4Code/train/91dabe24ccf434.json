{"cell_type":{"fd0335ad":"code","154bc915":"code","fd2167c7":"code","f088e7bc":"code","148193c8":"code","66ffc554":"code","997069e1":"code","58fc0328":"code","3e620acf":"code","6dfde396":"code","d287561d":"code","fd98d2f8":"code","6ae95d68":"code","2874ec2c":"code","b4db0aca":"code","e31988f7":"code","648d9754":"code","cacd0bf9":"code","6f04a664":"code","8bc69ce0":"code","9868817e":"code","2f68c593":"code","e3182e5a":"code","8043d419":"code","22601ec1":"code","c85539de":"code","b21505cb":"code","c4bb7de2":"code","d6ae1620":"code","9a1ce43e":"code","d2cfdcff":"code","a5abf3e2":"code","6f608021":"code","73b4a65a":"code","0e02d659":"code","0acbb7f5":"code","6085f60e":"code","ef3d4504":"code","d02d04b5":"code","7c283dc1":"code","dfe130dd":"code","48b19ca1":"code","07a54967":"code","54a30f4b":"code","e00dd790":"code","0e2dff4e":"code","ef4e6361":"code","c262d741":"code","f4bd352c":"code","710334d2":"code","66c88cef":"code","e053a32c":"code","daa17540":"code","9a97d6ef":"code","92355c0c":"code","907c3bea":"code","630f4ae4":"code","6ed3222e":"code","92b4fb25":"code","63cbe8d6":"code","06c01846":"markdown","8fa161ba":"markdown","b099b31b":"markdown","f1e5e4d8":"markdown","279dedfc":"markdown","227fc128":"markdown","d73f9935":"markdown","f5bcc12e":"markdown","469c22cf":"markdown","9ab59520":"markdown","752ff3d5":"markdown","7a6427d2":"markdown","49e2a966":"markdown"},"source":{"fd0335ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","154bc915":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom imblearn.under_sampling import NearMiss\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter","fd2167c7":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","f088e7bc":"df.info()","148193c8":"df.describe().T","66ffc554":"plt.figure(figsize=(12, 6))\nsns.countplot(df['Class'])\nprint('Count 0s = {}'.format((df['Class']==0).sum()))\nprint('Count 1s = {}'.format((df['Class']==1).sum()))\nprint('Percentage of fraud transactions = {}%'.format((df['Class']==1).sum() \/ (df['Class']==0).sum() * 100))","997069e1":"# Each feature visualized\n\nfor each in df.drop(columns='Class').columns:\n    print('Please scroll down this winndow')\n    fig = plt.subplots(figsize=(12, 4))\n    sns.distplot(df[each], kde=False)\n    plt.show()","58fc0328":"# Each feature visualised by class\n\ndf0s = df[df['Class']==0]\ndf1s = df[df['Class']==1]\n\nfor each in df.drop(columns='Class').columns:\n    print('Please scroll down this window')\n    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=(12, 2))\n    sns.distplot(df0s[each], kde=False, ax=axs[0], label='Class = 0')\n    axs[0].legend()\n    sns.distplot(df1s[each], kde=False, ax=axs[1], label='Class = 1')\n    axs[1].legend()\n    plt.show()","3e620acf":"X = df.drop(columns='Class').values\ny = df['Class'].values","6dfde396":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","d287561d":"nm = NearMiss()\nX_train_us, y_train_us = nm.fit_resample(X_train, y_train)\nprint('Shape of X_train is {}, and y_train is {}'.format(X_train.shape, y_train.shape))\nprint('Shape of UNDERSAMPLED X_train_us is {}, and y_train_us is {}'.format(X_train_us.shape, y_train_us.shape))","fd98d2f8":"clf_models = []\nclf_models.append(('MLPClf', MLPClassifier()))\nclf_models.append(('KNN', KNeighborsClassifier()))\nclf_models.append(('SVC', SVC()))\nclf_models.append(('GausProcess', GaussianProcessClassifier()))\nclf_models.append(('DTree', DecisionTreeClassifier()))\nclf_models.append(('RandForest', RandomForestClassifier()))\nclf_models.append(('AdaBoost', AdaBoostClassifier()))\nclf_models.append(('GausNB', GaussianNB()))\nclf_models.append(('QuadDiscAna', QuadraticDiscriminantAnalysis()))\n\nresults = []\nnames = []\n\nfor name, model in clf_models:\n    kfold = KFold(n_splits=5, shuffle=True)\n    cv_results = cross_val_score(model, X_train_us, y_train_us, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    note = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(note)","6ae95d68":"plt.figure(figsize=(15, 8))\nsns.boxplot(names, results)","2874ec2c":"abc = AdaBoostClassifier()\n\nabc_param = {'n_estimators' : [140], 'learning_rate' : [0.5]}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\nabc_gs = GridSearchCV(abc, param_grid=abc_param, cv=5)\n\nabc_gs.fit(X_train_us, y_train_us)","b4db0aca":"print(abc_gs.best_params_)","e31988f7":"adaboost = AdaBoostClassifier(**abc_gs.best_params_)\n\nadaboost.fit(X_train_us, y_train_us)","648d9754":"ada_preds = adaboost.predict(X_test)","cacd0bf9":"ada_cm = confusion_matrix(y_test, ada_preds)\n\nsns.heatmap(ada_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","6f04a664":"ada_cr = classification_report(y_test, ada_preds)\nprint('AdaBoostClassifier classification report' '\\n', ada_cr)","8bc69ce0":"ada_us_metrics = {'Precision' : precision_score(y_test, ada_preds), 'Recall' : recall_score(y_test, ada_preds),\n                  'F1 Score' : f1_score(y_test, ada_preds)}\nprint(ada_us_metrics)","9868817e":"rf = RandomForestClassifier()\n\nrf_param = {'n_estimators' : [50, 60, 70], 'max_depth' : [None, 30, 50], \n            'min_samples_split' : [40, 45, 50, 55, 60], 'min_samples_leaf' : [1], \n            'max_features' : ['log2']}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\nrf_gs = GridSearchCV(estimator=rf, param_grid=rf_param, cv=5, n_jobs=-2)\n\nrf_gs.fit(X_train_us, y_train_us)","2f68c593":"rf_gs.best_params_","e3182e5a":"rf_clf = RandomForestClassifier(**rf_gs.best_params_)\n\nrf_clf.fit(X_train_us, y_train_us)","8043d419":"rf_preds = rf_clf.predict(X_test)","22601ec1":"rf_cm = confusion_matrix(y_test, rf_preds)\n\nsns.heatmap(rf_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","c85539de":"rf_cr = classification_report(y_test, rf_preds)\nprint('Random Forest Classifier classificaction report' '\\n', rf_cr)","b21505cb":"rf_us_metrics = {'Precision' : precision_score(y_test, rf_preds), 'Recall' : recall_score(y_test, rf_preds),\n                  'F1 Score' : f1_score(y_test, rf_preds)}\nprint(rf_us_metrics)","c4bb7de2":"dtree = DecisionTreeClassifier()\n\ndtree_grid = {'max_depth' : [None, 6, 7], 'min_samples_split' : [6, 7], 'min_samples_leaf' : [1, 2]}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\ndtree_gs = GridSearchCV(estimator=dtree, param_grid=dtree_grid, cv=5)\n\ndtree_gs.fit(X_train_us, y_train_us)","d6ae1620":"dtree_gs.best_params_","9a1ce43e":"dtree_clf = DecisionTreeClassifier(**dtree_gs.best_params_)\ndtree_clf.fit(X_train_us, y_train_us)","d2cfdcff":"dtree_preds = dtree_clf.predict(X_test)","a5abf3e2":"dtree_cm = confusion_matrix(y_test, dtree_preds)\n\nsns.heatmap(dtree_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","6f608021":"dtree_cr = classification_report(y_test, dtree_preds)\nprint('Decision Tree Classifier classificaction report' '\\n', rf_cr)","73b4a65a":"dtree_us_metrics = {'Precision' : precision_score(y_test, dtree_preds), 'Recall' : recall_score(y_test, dtree_preds),\n                  'F1 Score' : f1_score(y_test, dtree_preds)}\nprint(dtree_us_metrics)","0e02d659":"# Over sampling the training set only\n\nros = RandomOverSampler()\nX_train_os, y_train_os = ros.fit_sample(X_train, y_train)","0acbb7f5":"print('Original training dataset class counts {}'.format(Counter(y_train)))\nprint('Over sampled dataset class counts {}'.format(Counter(y_train_os)))","6085f60e":"# abc = AdaBoostClassifier()\n\n# abc_param = {'n_estimators' : [2000], 'learning_rate' : [1.0]}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\n# abc_gs = GridSearchCV(abc, param_grid=abc_param, cv=5)\n\n# abc_gs.fit(X_train_os, y_train_os)","ef3d4504":"# print(abc_gs.best_params_)","d02d04b5":"adaboost = AdaBoostClassifier(n_estimators=2000, learning_rate=1.0)\n\nadaboost.fit(X_train_os, y_train_os)","7c283dc1":"ada_preds = adaboost.predict(X_test)","dfe130dd":"ada_cm = confusion_matrix(y_test, ada_preds)\n\nsns.heatmap(ada_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","48b19ca1":"ada_cr = classification_report(y_test, ada_preds)\nprint('AdaBoostClassifier classification report' '\\n', ada_cr)","07a54967":"ada_os_metrics = {'Precision' : precision_score(y_test, ada_preds), 'Recall' : recall_score(y_test, ada_preds),\n                  'F1 Score' : f1_score(y_test, ada_preds)}\nprint(ada_os_metrics)","54a30f4b":"rf = RandomForestClassifier()\n\nrf_param = {'n_estimators' : [200, 300, 400, 500, 1000, 2000, 3000], 'max_depth' : [30], \n            'min_samples_split' : [30], 'max_features' : ['log2']}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\nrf_gs = GridSearchCV(estimator=rf, param_grid=rf_param, cv=5, n_jobs=-2)\n\nrf_gs.fit(X_train_os, y_train_os)","e00dd790":"rf_gs.best_params_","0e2dff4e":"rf_clf = RandomForestClassifier(**rf_gs.best_params_)\n\nrf_clf.fit(X_train_os, y_train_os)","ef4e6361":"rf_preds = rf_clf.predict(X_test)","c262d741":"rf_cm = confusion_matrix(y_test, rf_preds)\n\nsns.heatmap(rf_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","f4bd352c":"rf_cr = classification_report(y_test, rf_preds)\nprint('Random Forest Classifier classificaction report' '\\n', rf_cr)","710334d2":"rf_os_metrics = {'Precision' : precision_score(y_test, rf_preds), 'Recall' : recall_score(y_test, rf_preds),\n                  'F1 Score' : f1_score(y_test, rf_preds)}\nprint(rf_os_metrics)","66c88cef":"dtree = DecisionTreeClassifier()\n\ndtree_grid = {'splitter' : ['best'], 'max_depth' : [None],\n              'min_samples_split' : [7], 'min_samples_leaf' : [1]}\n# Why am I using this parameter grid with these particular values? \n# I have run grid search several times on this dataset before, \n# in order to save resources and time, I am using the relevant values only\n\ndtree_gs = GridSearchCV(estimator=dtree, param_grid=dtree_grid, cv=5)\n\ndtree_gs.fit(X_train_os, y_train_os)","e053a32c":"dtree_gs.best_params_","daa17540":"dtree_clf = DecisionTreeClassifier(**dtree_gs.best_params_)\ndtree_clf.fit(X_train_os, y_train_os)","9a97d6ef":"dtree_preds = dtree_clf.predict(X_test)","92355c0c":"dtree_cm = confusion_matrix(y_test, dtree_preds)\n\nsns.heatmap(dtree_cm, annot=True, annot_kws={'size' : 24}, fmt='g')\nplt.xlabel('Predictions', size=24)\nplt.ylabel('y-true', size=24)","907c3bea":"dtree_cr = classification_report(y_test, dtree_preds)\nprint('Decision Tree Classifier classificaction report' '\\n', rf_cr)","630f4ae4":"dtree_os_metrics = {'Precision' : precision_score(y_test, dtree_preds), 'Recall' : recall_score(y_test, dtree_preds),\n                  'F1 Score' : f1_score(y_test, dtree_preds)}\nprint(ada_os_metrics)","6ed3222e":"all_metrics = [ada_us_metrics, rf_us_metrics, dtree_us_metrics, ada_os_metrics, rf_os_metrics, ada_os_metrics]\nprint(all_metrics)","92b4fb25":"mdf = pd.DataFrame(all_metrics, index= ['ada_under_samp', 'rf_under_samp', 'dtree_undersamp', \n                                        'ada_over_samp', 'rf_over_samp', 'ada_over_samp'])\nmdf","63cbe8d6":"mdf.plot(kind='bar', figsize=(12, 8))","06c01846":"### Ada Boost Classifier on oversampled dataset","8fa161ba":"## It looks like undersampling method has failed to produce a remarkable model. This is not a surprise anyway. \n\n# Next, let's try over-sampling","b099b31b":"### Decision Tree Classifier on oversampled dataset","f1e5e4d8":"# Key findings from the data description\n## 1 - The dataset presents transaction that occued over two days\n## 2 - There are 492 fraud transaction out of total 284,807 transactions, thus the dataset is extremely imbalanced\n## 3 - The variables are derived by PCA transformation - This means the data has already been scaled and no further PCA is needed\n## 4 - PCA was not applied on 'Time' and 'Amount' features","279dedfc":"### Ada Boost Classifier on under-sampled data","227fc128":"# Undersampling technique\n## We will be under sampling (us) only the training data. Once a model is trained, we will test it on the test data, which remains untouched","d73f9935":"# Conclusion\n### While the under-sampling technique resulted in slightly better true positives (TP), and thus better recall rates, the number of false positives (FP) was too high. This resulted in a poor precision rate. Also, in a real world scenario, this would cause customer dissatisfaction and a huge number of calls to the customer services department. Not good!\n### The over-sampling technique has significantly improved the precision score, thanks to few false positives (FP), while pretty much maintaining the recall \n## Happy days","f5bcc12e":"### Decision Tree Classifier on under-sampled data","469c22cf":"## Models compared","9ab59520":"## It looks like AdaBoost, Random Forest and Decision Tree classifiers have performed better than the other models. Now we fine tune these three to see if we can get even better results","752ff3d5":"### Random Forest Classifier on oversampled dataset","7a6427d2":"# Data Description\n### (https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud)\n\nDescription\nContext\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n\nContent\nThe datasets contains transactions made by credit cards in September 2013 by european cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\nInspiration\nIdentify fraudulent credit card transactions.\n\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n\nAcknowledgements\nThe dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http:\/\/mlg.ulb.ac.be) of ULB (Universit\u00e9 Libre de Bruxelles) on big data mining and fraud detection.\nMore details on current and past projects on related topics are available on https:\/\/www.researchgate.net\/project\/Fraud-detection-5 and the page of the DefeatFraud project","49e2a966":"### Random Forest Classifier on under-sampled data"}}