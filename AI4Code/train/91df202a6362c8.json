{"cell_type":{"1c945622":"code","b663ea7a":"code","23d1f5f1":"code","904ce5ec":"code","04cd4a81":"code","b2107eaf":"code","1f5007e9":"code","9824f38e":"code","8d4c9e41":"code","9d43d22e":"code","b809d7bb":"code","ab007640":"code","c07a7f21":"code","b1b1f424":"code","d9e254ac":"code","57736578":"code","36dd3561":"code","5f42bc75":"code","4d5ae682":"code","de0a1237":"code","c06c0019":"code","16dd16c5":"code","84296481":"code","5043ed28":"code","fb27dd05":"code","a448d88a":"code","a4b3f546":"code","75ede790":"code","6c490151":"code","2914b294":"code","2dbf8338":"code","1c976cdc":"code","c7782b67":"code","7edd2e31":"code","caf3ee65":"markdown","f2ab955b":"markdown","dd49e82d":"markdown","4d58d96d":"markdown","82c30618":"markdown","2c35e26d":"markdown","9e2c4174":"markdown","a8512916":"markdown","06089878":"markdown","aaa764fd":"markdown","9206de04":"markdown","1cd006b3":"markdown","c1f74a2a":"markdown","29492000":"markdown","08b6324d":"markdown","2fb55c2a":"markdown","919b8494":"markdown","b8ce81a4":"markdown","26564c6c":"markdown","3b02d2ee":"markdown","efc3525e":"markdown","ba1f9e47":"markdown","e6ba2bdf":"markdown","3c182d92":"markdown","5e73cfed":"markdown","3790ac3d":"markdown"},"source":{"1c945622":"from numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk  # For test pre-processing\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn import preprocessing\nimport scikitplot as skplt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import roc_curve,auc\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import Sequential\nfrom keras.layers import Embedding,LSTM,Dense\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"..\/input\"))\n","b663ea7a":"Movie_df=pd.read_csv('..\/input\/IMDB Dataset.csv')\nprint('Shape of dataset::',Movie_df.shape)\nMovie_df.head(10)","23d1f5f1":"print(\"General stats::\")\nprint(Movie_df.info())\nprint(\"Summary stats::\\n\")\nprint(Movie_df.describe())","904ce5ec":"Movie_df.sentiment.value_counts()\n","04cd4a81":"reviews=Movie_df['review']\nsentiment=Movie_df['sentiment']","b2107eaf":"#Summarize no. of classes\nprint('Classes::\\n',np.unique(sentiment))","1f5007e9":"train_reviews=reviews[:30000]\ntrain_sentiment=sentiment[:30000]\ntest_reviews=reviews[30000:]\ntest_sentiment=sentiment[30000:]\n#Shape of train & test dataset\nprint('Shape of train dataset::',train_reviews.shape,train_sentiment.shape)\nprint('Shape of test dataset::',test_reviews.shape,test_sentiment.shape)","9824f38e":"lb=preprocessing.LabelBinarizer()\n#Encode 1 for positive label & 0 for Negative label\ntrain_sentiment=lb.fit_transform(train_sentiment)\ntest_sentiment=lb.transform(test_sentiment)\n#Reshape the array\ntrain_sentiment=train_sentiment.ravel()  \ntest_sentiment=test_sentiment.ravel()\n#Convert categoricals to numeric ones\ntrain_sentiment=train_sentiment.astype('int64')\ntest_sentiment=test_sentiment.astype('int64')\n","8d4c9e41":"train_reviews[0]","9d43d22e":"test_reviews[30001]","b809d7bb":"train_sentiment[0:10]","ab007640":"test_sentiment[0:10]","c07a7f21":"\nps=PorterStemmer()\nstopwords=set(stopwords.words('english'))\n# Define function for data mining\ndef normalize_reviews(review):\n    #Excluding html tags\n    data_tags=re.sub(r'<[^<>]+>',\" \",review)\n    #Remove special characters\/whitespaces\n    data_special=re.sub(r'[^a-zA-Z0-9\\s]','',data_tags)\n    #converting to lower case\n    data_lowercase=data_special.lower()\n    #tokenize review data\n    data_split=data_lowercase.split()\n    #Removing stop words\n    meaningful_words=[w for w in data_split if not w in stopwords]\n    #Appply stemming\n    text= ' '.join([ps.stem(word) for word in meaningful_words])\n    return text\n","b1b1f424":"norm_train_reviews=train_reviews.apply(normalize_reviews)\nnorm_test_reviews=test_reviews.apply(normalize_reviews)","d9e254ac":"\nnorm_train_reviews[0]","57736578":"norm_test_reviews[30001]","36dd3561":"cv=CountVectorizer(ngram_range=(1,2))\ntrain_cv=cv.fit_transform(norm_train_reviews)\ntest_cv =cv.transform(norm_test_reviews)\nprint('Shape of train_cv::',train_cv.shape)\nprint('Shape of test_cv::',test_cv.shape)","5f42bc75":"%%time\n#Training the classifier\nrfc=RandomForestClassifier(n_estimators=20,random_state=42)\nrfc=rfc.fit(train_cv,train_sentiment)\nscore=rfc.score(train_cv,train_sentiment)\nprint('Accuracy of trained model is ::',score)","4d5ae682":"%%time\n#Making predicitions\nrfc_predict=rfc.predict(test_cv)","de0a1237":"#How accuate our model is?\ncm=confusion_matrix(test_sentiment,rfc_predict)\n#plot our confusion matrix\nskplt.metrics.plot_confusion_matrix(test_sentiment,rfc_predict,normalize=False,figsize=(12,8))\nplt.show()\n","c06c0019":"#print classification report for performance metrics\ncr=classification_report(test_sentiment,rfc_predict)\nprint('Classification report is::\\n',cr)\n","16dd16c5":"# ROC curve for Random Forest Classifier\nfpr_rf,tpr_rf,threshold_rf=roc_curve(test_sentiment,rfc_predict)\n#Area under curve (AUC) score, fpr-False Positive rate, tpr-True Positive rate\nauc_rf=auc(fpr_rf,tpr_rf)\nprint('AUC score for Random Forest classifier::',np.round(auc_rf,3))","84296481":"#Train dataset\nX_train=train_cv\nX_train=[str(x[0]) for x in X_train]\ny_train=train_sentiment\n# Test dataset\nX_test=test_cv\nX_test=[str(x[0]) for x in X_test]\ny_test=test_sentiment\n","5043ed28":"# Tokenize the train & test dataset\nMax_Review_length=500\ntokenizer=Tokenizer(num_words=Max_Review_length,lower=False)\ntokenizer.fit_on_texts(X_train)\n#tokenizig train data\nX_train_token=tokenizer.texts_to_sequences(X_train)\n#tokenizing test data\nX_test_token=tokenizer.texts_to_sequences(X_test)\n\n#Truncate or pad the dataset for a length of 500 words for each review\nX_train=pad_sequences(X_train_token,maxlen=Max_Review_length)\nX_test=pad_sequences(X_test_token,maxlen=Max_Review_length)","fb27dd05":"print('Shape of X_train datset after padding:',X_train.shape)\nprint('Shape of X_test dataset after padding:',X_test.shape)","a448d88a":"%%time\n# Most poplar words found in the dataset\nvocabulary_size=5000 \nembedding_size=64\nmodel=Sequential()\nmodel.add(Embedding(vocabulary_size,embedding_size,input_length=Max_Review_length))\nmodel.add(LSTM(30))\nmodel.add(Dense(1,activation='sigmoid',kernel_initializer='random_uniform'))\nmodel.summary()","a4b3f546":"#Complile our model\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","75ede790":"%%time\n#Train our model\nbatch_size=128\nnum_epochs=6\nX_valid,y_valid=X_train[:batch_size],train_sentiment[:batch_size]\nX_train1,y_train1=X_train[batch_size:],train_sentiment[batch_size:]\n# Fit the model\nmodel.fit(X_train1,y_train1,validation_data=(X_valid,y_valid),validation_split=0.2,\n          batch_size=batch_size,epochs=num_epochs, verbose=1,shuffle=True)\n","6c490151":"%%time\n# Predictions\ny_predict_rnn=model.predict(X_test)\n#Changing the shape of y_predict to 1-Dimensional\ny_predict_rnn1=y_predict_rnn.ravel()\ny_predict_rnn1=(y_predict_rnn1>0.5)\ny_predict_rnn1[0:10]","2914b294":"#Confusion matrix for RNN with LSTM\ncm_rnn=confusion_matrix(y_test,y_predict_rnn1)\n#plot our confusion matrix\nskplt.metrics.plot_confusion_matrix(y_test,y_predict_rnn1,normalize=False,figsize=(12,8))\nplt.show()\n\n","2dbf8338":"#Classification report for performance metrics\ncr_rnn=classification_report(y_test,y_predict_rnn1)\nprint('The Classification report is::\\n',cr_rnn)\n","1c976cdc":"#ROC curve for RNN with LSTM\nfpr_rnn,tpr_rnn,thresold_rnn=roc_curve(y_test,y_predict_rnn)\n#AUC score for RNN\nauc_rnn=auc(fpr_rnn,tpr_rnn)\nprint('AUC score for RNN with LSTM ::',np.round(auc_rnn,3))","c7782b67":"%%time\nplt.figure(1)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr_rnn,tpr_rnn,label='RNN(area={:.3f})'.format(auc_rnn))\nplt.plot(fpr_rf,tpr_rf,label='Random Forest (area={:.3f})'.format(auc_rf))\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n","7edd2e31":"#Model Evaluation on unseen dataset\nModel_evaluation=pd.DataFrame({'Model':['Random Forest Classifier','RNN with LSTM'],\n                              'f1_score':[0.81,0.79],\n                              'roc_auc_score':[0.809,0.879]})\nModel_evaluation","caf3ee65":"> **Receiver Operating Characterstic (ROC) Curve for Model Evaluation**","f2ab955b":"> Let's build our traditional ML models","dd49e82d":"**This invlolves the Sentiment prediction for a number of movies reviews obtained from Internet Movie data (IMDB).This dataset containes 50,000 movie reviews.Here we are predicting the sentiment of 20,000 labeled movie reviews and using remaining 30,000 reviews for training our models.**","4d58d96d":"> Normalize the train & test data","82c30618":"Let's normalize our data to remove stopwords, html tags and so on.","2c35e26d":"> Now, let's plot the ROC for both Random Forest Classifier &  RNN with LSTM","9e2c4174":"\nLet's explore our data before normalization","a8512916":"The confusion matrix plot states that the RNN with LSTM model classified 79% of reviews (15866 reviews) correctly & remaining 21% of reviews (4134 reviews) are misclassified.","06089878":"> Data Pre-processing","aaa764fd":"> **Import required libraries**","9206de04":"> Random Forest model","1cd006b3":"Stats of our data","c1f74a2a":"> Encode our target labels","29492000":"** Let's build our deep learning model**","08b6324d":"\nLet's look at our normalized data","2fb55c2a":"In above paragraphs, we can observe stopwords,html tags,special charcters & numbers, which are not required for sentiment analysis.So we need to remove those by normalizing the review data to reduce dimensionality & noise in the data.","919b8494":"> 0-Negative class,\n> 1-Positive class","b8ce81a4":"Our train & test dataset contains 1929440 attributes each.","26564c6c":"> Load the data","3b02d2ee":"\n> Recurrent neural network (RNN) with LSTM (Long Short Term Memory) model","efc3525e":"> Number of poitive & negative reviews","ba1f9e47":"The f1_score for Random forest classier is higher than for RNN with LSTM model & the roc_auc score for Random forest classifier is lower than for RNN with LSTM model. From the above scores, it is good to consider Random forest classifier than RNN with LSTM because it is comparatively less computationally expensive & works well on small & large amount of datasets.","e6ba2bdf":"> 0-Negative class,\n> 1-Positive class","3c182d92":"> Let's create features using bag of words model","5e73cfed":"> Split the data into train & test datasets","3790ac3d":"From the confusion matrix plot, it is concluded that, the Random Forest classifier with 20 decision trees classified the 81% of the reviews (16183 reviews) correctly & remaining 19% of reviews (3817 reviews) are misclassified."}}