{"cell_type":{"8c2148d7":"code","692e2822":"code","fa8be48a":"code","9233e632":"code","567174df":"code","63018a07":"code","8588e05d":"code","b382d00f":"code","fbf794cd":"code","3f92c154":"code","5089ffca":"code","5c3d16c8":"code","93d46009":"code","76fc805f":"code","373ca5a9":"code","b1c5990d":"code","0127b426":"code","68452882":"code","8da7431a":"code","078c72ce":"code","ec2cf0e7":"code","edd9da6d":"code","00529ca7":"code","eb0e08ca":"code","8156d686":"code","7b291b2c":"code","024e9d82":"code","e60947fa":"code","c41d7e81":"code","33925738":"code","a23ceab9":"code","493a22ef":"code","be2d1c06":"code","0b0406df":"code","fc2a6ece":"code","f3da431a":"code","0213a2b6":"code","cf9b0920":"code","4602a228":"markdown","799bbdca":"markdown","146d7fd1":"markdown","081b4e5e":"markdown","364bd59f":"markdown"},"source":{"8c2148d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","692e2822":"# Read data file csv\ndf = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')","fa8be48a":"# Size of dataframe\ndf.shape","9233e632":"# Print head of dataframe\ndf.head()","567174df":"# Fillter data to visualization, filter top shop best seller by [date, shop_id, item_id]","63018a07":"df['shop_id'].value_counts()","8588e05d":"lst_top_shop = df['shop_id'].value_counts()","b382d00f":"df_top_shop = df[df['shop_id'] == lst_top_shop.index[0]]","fbf794cd":"df_top_shop","3f92c154":"sales = df_top_shop.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[['date_block_num','date', 'shop_id', 'item_id', 'item_price', 'item_cnt_day']].agg({\"date_block_num\":'mean',\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","5089ffca":"sales","5c3d16c8":"sales = sales.item_cnt_day.apply(list).reset_index()","93d46009":"sales.head()","76fc805f":"sales_data = sales.pivot_table(index = ['shop_id', 'item_id'], columns='date_block_num', values='sum', aggfunc='sum')","373ca5a9":"sales_data.fillna(0, inplace=True)","b1c5990d":"sales_data","0127b426":"from matplotlib import pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES","68452882":"def MAPE(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ np.maximum(np.ones(len(y_true)), np.abs(y_true))))*100","8da7431a":"import warnings\nwarnings.filterwarnings(\"ignore\")","078c72ce":"def Average(lst):\n    return sum(lst) \/ len(lst)","ec2cf0e7":"dfids = pd.DataFrame(sales_data.iloc[6][:])\ndfids.columns = ['sale']\ndfids.index.freq = 'MS'\ndfids['sale'] = dfids['sale'] + 0.01 # Cong tat ca cac so sale len 0.01\n\nif dfids[dfids['sale']==0.01].shape[0] < 20: # Chi chay predict cho nhung item co so so 0 nho hon 20 (20 thang trong 33)\n    #plot the data\n    #dfids.plot()\n    #plt.show()\n\n    from statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES\n\n    print(\"Name of dataframe row: \", 6)\n    #split between the training and the test data sets. The last 12 periods form the test data\n    df_train = dfids.iloc[:-6]\n    df_test = dfids.iloc[-6:]\n    #build and train the model on the training data\n    model = HWES(df_train, seasonal_periods=12, trend='add', seasonal='add')\n    fitted = model.fit(optimized=True, use_brute=True)\n    #create an out of sample forcast for the next 12 steps beyond the final data point in the training data set\n    sales_forecast = fitted.forecast(steps=6)\n    mse_  = mean_squared_error(df_test, sales_forecast)\n    mae_  = mean_absolute_error(df_test, sales_forecast)\n    mape_ = MAPE(df_test, sales_forecast)\n    print(\"evaluation metric mse = {}, mae = {}, mape = {}\".format(round(mse_, 3),round(mae_, 3),round(mape_, 3)))\n\n    #plot the training data, the test data and the forecast on the same plot\n    #fig = plt.figure()\n    fig, ax = plt.subplots()\n    ci = 1.96 * np.std(sales_forecast)\/np.sqrt(len(sales_forecast))\n    fig.suptitle('Retail Sales')\n    past, = plt.plot(df_train.index, df_train, 'b.-', label='Sales History')\n    future, = plt.plot(df_test.index, df_test, 'r.-', label='Actual Sales')\n    predicted_future, = plt.plot(df_test.index, sales_forecast, 'g.-', label='Sales Forecast')\n    \n    ax.fill_between(df_test.index, (sales_forecast-ci), (sales_forecast+ci), color='b', alpha=.1)\n    \n    plt.legend(handles=[past, future, predicted_future])\n    plt.show()\n    print(\"_\"*50)","edd9da6d":"count_stop = 0\n\nlst_mse = []\nlst_mae = []\nlst_mape = []\nfor i in range(sales_data.shape[0]):\n    dfids = pd.DataFrame(sales_data.iloc[i][:])\n    dfids.columns = ['sale']\n    dfids.index.freq = 'MS'\n    dfids['sale'] = dfids['sale'] + 0.01 # Cong tat ca cac so sale len 0.01\n    \n    if dfids[dfids['sale']==0.01].shape[0] < 20: # Chi chay predict cho nhung item co so so 0 nho hon 20 (20 thang trong 33)\n        #plot the data\n        #dfids.plot()\n        #plt.show()\n        try:\n            from statsmodels.tsa.holtwinters import ExponentialSmoothing as HWES\n            \n            print(\"Name of dataframe row: \", i)\n            #split between the training and the test data sets. The last 12 periods form the test data\n            df_train = dfids.iloc[:-6]\n            df_test = dfids.iloc[-6:]\n\n            #build and train the model on the training data\n            model = HWES(df_train, seasonal_periods=12, trend='add', seasonal='add')\n            fitted = model.fit(optimized=True, use_brute=True)\n\n            #create an out of sample forcast for the next 12 steps beyond the final data point in the training data set\n            sales_forecast = fitted.forecast(steps=6)\n            mse_  = mean_squared_error(df_test, sales_forecast)\n            mae_  = mean_absolute_error(df_test, sales_forecast)\n            mape_ = MAPE(df_test, sales_forecast)\n            lst_mse.append(mse_)\n            lst_mae.append(mae_)\n            lst_mape.append(mape_)\n            print(\"evaluation metric mse = {}, mae = {}, mape = {}\".format(round(mse_, 3),round(mae_, 3),round(mape_, 3)))\n            \n            #plot the training data, the test data and the forecast on the same plot\n            #fig = plt.figure()\n            fig, ax = plt.subplots()\n            ci = 1.96 * np.std(sales_forecast)\/np.sqrt(len(sales_forecast))\n            fig.suptitle('Retail Sales')\n            past, = plt.plot(df_train.index, df_train, 'b.-', label='Sales History')\n            future, = plt.plot(df_test.index, df_test, 'r.-', label='Actual Sales')\n            predicted_future, = plt.plot(df_test.index, sales_forecast, 'g.-', label='Sales Forecast')\n            plt.legend(handles=[past, future, predicted_future])\n            ax.fill_between(df_test.index, (sales_forecast-ci), (sales_forecast+ci), color='b', alpha=.1)\n            plt.show()\n            print(\"_\"*50)\n            count_stop = count_stop + 1\n        except:\n            pass\n    if count_stop == 10:\n        break","00529ca7":"lst_mse","eb0e08ca":"lst_mae","8156d686":"lst_mape","7b291b2c":"Average(lst_mse)","024e9d82":"Average(lst_mae)","e60947fa":"Average(lst_mape)","c41d7e81":"from statsmodels.tsa.arima.model import ARIMA\n\nfrom math import sqrt","33925738":"dfids = pd.DataFrame(sales_data.iloc[6][:])\ndfids.columns = ['sale']\ndfids.index.freq = 'MS'\ndfids['sale'] = dfids['sale'] + 0.01\n\n\nprint(\"Name of dataframe row: \", 6)\nX = dfids['sale'].values\ntrain, test = X[:-6], X[-6:]\nhistory = [x for x in train]\npredictions = list()\n\n# walk-forward validation\nfor t in range(len(test)):\n    model = ARIMA(history, order=(1,1,0))\n    model_fit = model.fit()\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n\n# evaluate forecasts\nmse_  = mean_squared_error(test, predictions)\nmae_  = mean_absolute_error(test, predictions)\nmape_ = MAPE(test, predictions)\nprint(\"evaluation metric mse = {}, mae = {}, mape = {}\".format(round(mse_, 3),round(mae_, 3),round(mape_, 3)))\n\n# plt.plot(test)\n# plt.plot(predictions, color='red')\n# plt.show()\n# print(\"_\"*50)\n\n\nfig, ax = plt.subplots()\nci = 1.96 * np.std(predictions)\/np.sqrt(len(predictions))\nfig.suptitle('Retail Sales')\npast, = plt.plot(dfids[:-6].index, train, 'b.-', label='Sales History')\nfuture, = plt.plot(dfids[-6:].index, test, 'r.-', label='Actual Sales')\npredicted_future, = plt.plot(dfids[-6:].index, predictions, 'g.-', label='Sales Forecast')\nplt.legend(handles=[past, future, predicted_future])\nax.fill_between(df_test.index, (predictions-ci), (predictions+ci), color='b', alpha=.1)\nplt.show()","a23ceab9":"count_stop = 0\n\nlst_arima_mse = []\nlst_arima_mae = []\nlst_arima_mape = []\nfor i in range(sales_data.shape[0]):\n    dfids = pd.DataFrame(sales_data.iloc[i][:])\n    dfids.columns = ['sale']\n    dfids.index.freq = 'MS'\n    dfids['sale'] = dfids['sale'] + 0.01\n    \n    if dfids[dfids['sale']==0.01].shape[0] < 20:\n        try:\n            print(\"ARIMA: Name of dataframe row: \", i)\n            X = dfids['sale'].values\n            train, test = X[:-6], X[-6:]\n            history = [x for x in train]\n            predictions = list()\n\n            # walk-forward validation\n            for t in range(len(test)):\n                model = ARIMA(history, order=(1,1,0))\n                model_fit = model.fit()\n                output = model_fit.forecast()\n                yhat = output[0]\n                predictions.append(yhat)\n                obs = test[t]\n                history.append(obs)\n\n            # evaluate forecasts\n            mse_  = mean_squared_error(test, predictions)\n            mae_  = mean_absolute_error(test, predictions)\n            mape_ = MAPE(test, predictions)\n            lst_arima_mse.append(mse_)\n            lst_arima_mae.append(mae_)\n            lst_arima_mape.append(mape_)\n            print(\"evaluation metric mse = {}, mae = {}, mape = {}\".format(round(mse_, 3),round(mae_, 3),round(mape_, 3)))\n\n#             plt.plot(test)\n#             plt.plot(predictions, color='red')\n#             plt.show()\n            fig, ax = plt.subplots()\n    \n            ci = 1.96 * np.std(predictions)\/np.sqrt(len(predictions))\n            fig.suptitle('Retail Sales')\n            past, = plt.plot(dfids[:-6].index, train, 'b.-', label='Sales History')\n            future, = plt.plot(dfids[-6:].index, test, 'r.-', label='Actual Sales')\n            predicted_future, = plt.plot(dfids[-6:].index, predictions, 'g.-', label='Sales Forecast')\n            plt.legend(handles=[past, future, predicted_future])\n            ax.fill_between(df_test.index, (predictions-ci), (predictions+ci), color='b', alpha=.1)\n            plt.show()\n            print(\"_\"*50)\n            \n            count_stop = count_stop + 1\n        except:\n            pass\n    if count_stop == 10:\n        break","493a22ef":"lst_arima_mse","be2d1c06":"lst_arima_mae","0b0406df":"lst_arima_mape","fc2a6ece":"Average(lst_arima_mse)","f3da431a":"Average(lst_arima_mae)","0213a2b6":"Average(lst_arima_mape)","cf9b0920":"len(lst_arima_mape)","4602a228":"# 1. READ DATA","799bbdca":"# 2. Preprocess data top 1 shop","146d7fd1":"## holt winters","081b4e5e":"## ARIMA","364bd59f":"# 3. Predict & visualization"}}