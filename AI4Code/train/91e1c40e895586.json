{"cell_type":{"f94bb11e":"code","0258e2f9":"code","a96adbc0":"code","6bd66ea8":"code","2cd5eb87":"code","0bd01244":"code","6ca27df6":"code","1e7ce96d":"code","290ceebf":"code","3f44b51d":"markdown","88dfbf10":"markdown","9b556048":"markdown","736f489b":"markdown","9bf1e92e":"markdown","3dffc339":"markdown","92985fc7":"markdown","ee20b01b":"markdown"},"source":{"f94bb11e":"import os \nimport pandas as pd\nimport traceback","0258e2f9":"# Set your own project id here\nPROJECT_ID = 'mlflow-sample'\n# from google.cloud import bigquery\n# bigquery_client = bigquery.Client(project=PROJECT_ID)\nfrom google.cloud import storage\nstorage_client = storage.Client(project=PROJECT_ID)","a96adbc0":"def create_bucket(dataset_name):\n    \"\"\"Creates a new bucket. https:\/\/cloud.google.com\/storage\/docs\/ \"\"\"\n    bucket = storage_client.create_bucket(dataset_name)\n    print('Bucket {} created'.format(bucket.name))\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Uploads a file to the bucket. https:\/\/cloud.google.com\/storage\/docs\/ \"\"\"\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n    \ndef list_blobs(bucket_name):\n    \"\"\"Lists all the blobs in the bucket. https:\/\/cloud.google.com\/storage\/docs\/\"\"\"\n    blobs = storage_client.list_blobs(bucket_name)\n    for blob in blobs:\n        print(blob.name)\n        \ndef download_to_kaggle(bucket_name,destination_directory,file_name):\n    \"\"\"Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook\"\"\"\n    os.makedirs(destination_directory, exist_ok = True)\n    full_file_path = os.path.join(destination_directory, file_name)\n    blobs = storage_client.list_blobs(bucket_name)\n    for blob in blobs:\n        blob.download_to_filename(full_file_path)","6bd66ea8":"bucket_name = 'mlflow-sample-curry'\ntry:\n    create_bucket(bucket_name)   \nexcept:\n    traceback.print_exc()","2cd5eb87":"local_data = '\/kaggle\/input\/titanic\/train.csv'\nfile_name = 'train.csv' \nupload_blob(bucket_name, local_data, file_name)\nprint('Data inside of',bucket_name,':')\nlist_blobs(bucket_name)","0bd01244":"destination_directory = '\/kaggle\/working\/'\nfile_name = 'train.csv'\ndownload_to_kaggle(bucket_name,destination_directory,file_name)","6ca27df6":"!pwd","1e7ce96d":"ls","290ceebf":"new_file = pd.read_csv('train.csv')\nnew_file.head()","3f44b51d":"* kaggle\u306enotebook\u3068GSC\u306e\u9593\u3067\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u3084\u308a\u3068\u308a\u3092\u3059\u308b\u65b9\u6cd5\u3067\u3059\u3002\n* \u6b21\u306e3\u3064\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n  * \u30d0\u30b1\u30c3\u30c8\u306e\u4f5c\u6210\n  * \u30b3\u30f3\u30da\u30c6\u30a3\u30b7\u30e7\u30f3\u306ecsv\u30d5\u30a1\u30a4\u30eb\u3092GSC\u306b\u4fdd\u5b58\n  * GSC\u306e\u30d5\u30a1\u30a4\u30eb\u3092notebook\u306b\u8aad\u307f\u8fbc\u307f\n* \u3053\u306e[notebook](https:\/\/www.kaggle.com\/paultimothymooney\/how-to-move-data-from-kaggle-to-gcs-and-back\/data)\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n* \u8a73\u3057\u304f\u306f[\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](https:\/\/www.kaggle.com\/docs\/notebooks)\u306eGoogle Cloud Storage (GCS)\u306e\u7b87\u6240\u3092\u8aad\u307f\u307e\u3057\u3087\u3046\u3002","88dfbf10":"# Step 4: Upload your data to a GCS Bucket","9b556048":"# step2 Import Data from Kaggle","736f489b":"GSC\u306e\u30c7\u30fc\u30bf\u3092\u3001\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","9bf1e92e":"# Step 6: Preview the data that you just downloaded","3dffc339":"# step1 Import Python Modules","92985fc7":"# Step 3: Create a new GCS Bucket\n\nBucket\u3092\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u65e2\u306b\u4f5c\u6210\u6e08\u307f\u306e\u305f\u3081\u3001\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002","ee20b01b":"# Step 5: Download your data from the GCS Bucket"}}