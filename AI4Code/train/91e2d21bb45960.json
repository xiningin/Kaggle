{"cell_type":{"fa96fa01":"code","14c7a0bf":"code","1ae8e238":"code","053661ca":"code","063546e3":"code","b91e3b61":"code","6e4514f4":"code","76371520":"code","a20f08ad":"code","4b76729b":"code","91f913ef":"code","337ee0fa":"code","9920cf79":"code","784a2795":"code","7430fbc2":"markdown","aed656b5":"markdown"},"source":{"fa96fa01":"import torch\nfrom torch import nn\n\n\ncfgs = {\n    'vgg_test': [16, 'M', 32, 'M', 64, 'M', 128, 'M', 512, 'M'],\n    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}\n\nclass VGG(nn.Module):\n    def __init__(self, cfg, vgg_name, in_channels=3, num_classes=10, Batch_norm=True, init_weights=True):\n        super(VGG, self).__init__()\n        self.name = vgg_name\n        if Batch_norm:\n            self.name += '_bn'\n        self.features = self._make_layers(cfg[vgg_name], in_channels, Batch_norm)\n        self.classifier = nn.Linear(512, num_classes)\n        if init_weights:\n            self._initialize_weights()\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n                \n    def _make_layers(self, cfg, in_channels , batch_norm):\n        layers = []\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)","14c7a0bf":"from dlpipeline import DLpipeline, Executor, Progbar, Reporter, Saver, FileNameManager, output_to_score_fun\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\n\ntry:\n    from torchsummary import summary\nexcept:\n    !pip install torchsummary\n    from torchsummary import summary\n    \n''' \ntry:\n    from thop import profile, clever_format\nexcept:\n    !pip install thop\n    from thop import profile, clever_format\n'''\n\n'''\ndef state_fun(pipeline):\n    state = {'param': pipeline.model.state_dict(),\n             'acc': pipeline.reporter.acc,\n             'epoch': pipeline.epoch}\n    return state\n'''\n\ndef summary_fun(pipeline):\n    from torchsummary import summary\n    print('Model: %s' % pipeline.model_name)\n    summary(pipeline.model, input_size=(3, 32, 32), device = pipeline.device.type)\n    '''\n    from thop import profile, clever_format\n    input = torch.randn(1, 3, 32, 32)\n    macs, params = profile(pipeline.model, inputs=(input, ))\n    macs, params = clever_format([macs, params], \"%.3f\")\n    print(macs, params)\n    '''\n    print('Optimizer:\\n', pipeline.optimizer)\n    \ndef get_device():\n    if torch.cuda.is_available():\n        device = 'cuda'\n    else:\n        device = 'cpu'\n    return torch.device(device)\n\n\ndevice = get_device()\n\nbatch_size = 256\nsave_dir = '.\/checkpoint of vgg for cifar10\/'\nlabels = [i for i in range(10)]\n\nprint('==> Preparing data ...')\ntransform_train = transforms.Compose([\n    #transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616)),\n])\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616)),\n])\n\ntrainset = CIFAR10('.\/cifar10', train=True, download=True, transform=transform_train)\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\ntestset = CIFAR10('.\/cifar10', train=False, download=True, transform=transform_test)\ntestloader = DataLoader(testset, batch_size=250, shuffle=False, num_workers=2)\n\n\nif device.type == 'cuda':\n    #model = torch.nn.DataParallel(model)\n    torch.backends.cudnn.benchmark = True\n    \nprint('==> Bulding pipeline ...')\n'''\n# This can be use, but I prefer to use dict.\npipeline = DLpipeline(executor=Executor(),\n                      progressbar=Progbar(dynamic = True),\n                      reporter=Reporter(labels = labels, report_interval = 3, summary_fun = summary_fun),\n                      saver=Saver(save_dir = save_dir,\n                                  save_meta_file = True,\n                                  save_ckpt_model = True, \n                                  save_val_model = True, \n                                  save_final_model = True,\n                                  save_interval = 2, \n                                  test_model_use = 'final', \n                                  save_history = True),\n                      file_name_manager=FileNameManager(),\n                      device=device,\n                      criterion=nn.CrossEntropyLoss(),\n                      trainloader=trainloader,\n                      #valloader=testloader,\n                      testloader=testloader,\n                     )\n'''\n\nbasic_config = {'executor': Executor(),\n                'progressbar': Progbar(dynamic = True),\n                'reporter': Reporter(labels = labels, \n                                     need_confusion_matrix = True,\n                                     output_to_score_fun = output_to_score_fun, \n                                     report_interval = 0,\n                                     show_train_report = False,\n                                     summary_fun = summary_fun),\n                'saver': Saver(save_dir = save_dir,\n                               save_meta_file = True,\n                               save_ckpt_model = True, \n                               save_val_model = True, \n                               save_final_model = True,\n                               save_final_optim = True,\n                               save_interval = 5, \n                               test_model_use = 'final', \n                               save_history = True,\n                               save_train_report = False,\n                               save_test_report = True),\n                'file_name_manager': FileNameManager(),\n                'device': device,\n                'criterion': nn.CrossEntropyLoss(),\n                'trainloader': trainloader,\n                'valloader': testloader,\n                'testloader': testloader,\n               }\n\npipeline = DLpipeline(**basic_config)\n","1ae8e238":"learning_rate = 0.05\nweight_decay = 1e-3\nmomentum = 0.9\n\n#print('==> Building model ...')\nmodel = VGG(cfgs, 'vgg11', Batch_norm=False).to(device)\n#summary(model, input_size=(3, 32, 32), device=device.type)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\npipeline.setup(model = model, model_name = model.name, optimizer = optimizer)\n","053661ca":"pipeline.create_pipeline()  # create a new pipeline\npipeline.summary()","063546e3":"pipeline(end_epoch = 20)  # train 20 epoch, from epoch=1 to epoch=20","b91e3b61":"pipeline(40)  # continue training, from epoch=21 to epoch=40","6e4514f4":"# report the result\npipeline.report()","76371520":"# change model (reset optimizer) and pipeline\nmodel = VGG(cfgs, 'vgg11', Batch_norm=True).to(device)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\npipeline.setup(model = model, model_name = model.name, optimizer = optimizer)\n\n# Now we specify the folder, and create a new pipeline\npipeline.create_pipeline(save_dir + 'vgg_test\/')\npipeline.summary()","a20f08ad":"pipeline(20)  # train 20 epoch, from epoch=1 to epoch=20","4b76729b":"# change model (reset optimizer) and pipeline\nmodel = VGG(cfgs, 'vgg11', Batch_norm=True).to(device)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\npipeline.setup(model = model, model_name = model.name, optimizer = optimizer)\n\n# and we load the previous pipeline\npipeline.load('pipeline', save_dir + 'vgg_test\/')\npipeline.summary()","91f913ef":"# continue training\npipeline(50)  # train 30 epoch, from epoch=21 to epoch=50","337ee0fa":"import os\nimport re\n\n# load history in epoch 40 (from a model file)\nfiles = os.listdir(save_dir + 'vgg_test\/')\nfor file in files:\n    e = re.search(\"epoch_\\d+\", file)\n    if e and int(e.group()[6:]) == 40:\n        break\n\npipeline.load('history', save_dir + 'vgg_test\/' + file)\n\n# report the result, but only report train result \n# becansue we don't have test result in this file\npipeline.report(modes = 'train')","9920cf79":"# load history in epoch 50\nfiles = os.listdir(save_dir + 'vgg_test\/')\nfor file in files:\n    h = file[:7] == 'history'\n    e = re.search(\"epoch_\\d+\", file)\n    if h and e and int(e.group()[6:]) == 50:\n        break\n\npipeline.load('history', save_dir + 'vgg_test\/' + file)\n\n# report the result, but only report test result\npipeline.report(modes = 'test')","784a2795":"# load pipeline in epoch 15 (from a model file)\nfiles = os.listdir(save_dir + 'vgg_test\/')\nfor file in files:\n    e = re.search(\"epoch_\\d+\", file)\n    if e and int(e.group()[6:]) == 15:\n        break\npipeline.load('pipeline', save_dir + 'vgg_test\/' + file)\n\n# continue training, from epoch=16 to epoch=25\n# this is a new training branch. The previous one ends at epoch=50\npipeline(25)","7430fbc2":"# Basic operation\n\nUse this to create a new pipeline, it will create a new folder under *saver.save\\_dir*. Then every thing will be saved in this folder (if enable save). The name of the created folder is controlled by FileNameManager, default to time+model_name.\n\n```python\npipeline.create_pipeline()\n```\n\nUse this to create a new pipeline, it will create a new folder with its path as user specify. Then every thing will save in this folder (if enable save). If the folder exists, then it will load the satify file with the max epoch. If not satify file, it will start a new training branch (two different pipeline share the same folder, try to avoid this because file cover will happen)\n```python\npipeline.create_pipeline(save_dir + 'vgg_test\/')\n```\n\nUse this to load an exist pipeline (mainly model+optim+hist+last_epoch).\n```python\npipeline.load('pipeline', save_dir + 'vgg_test\/20200923_225741 vgg_test epoch_18 val.pt')\n```\n\nUse this to load an exist pipeline, without specify file name, let the program to find the satify file with the max epoch. If not satify file, it will start a new training branch (two different pipelines share the same folder, try to avoid this because file cover will happen).\n```python\npipeline.load('pipeline', save_dir + 'vgg_test\/')\n```\n\nWhen you are ready to train, simply use the following code to start training (and testing).\n\n```python\npipeline(end_epoch=30)\n# or\npipeline(30)\n# train from epoch=pipline.start_epoch to epoch=end_epoch\n```\n\nUse this to load a exist history, this history is not mean to serve as continue training. If you want to continue training, load pipeline or model instead of history.\n```python\npipeline.load('history', save_dir + 'vgg_test\/history 20200923_225937 vgg_test epoch_20.hist')\n```\n\nUse this to report the result (train and test).\n\n```python\npipeline.report()\n```\n\nUse this to report the train result.\n```python\npipeline.report(modes = ['train', 'val'])\n```\n\nUse this to report the test result.\n``` python\npipeline.report(modes = 'test') \n```\n\nThe state of the pipeline (or *pipeline.start\\_epoch*) only change when successfully load or create 'pipeline' using:\n\n```python\npipeline.load('pipeline', ...)\n# or\npipeline.create_pipeline(...)\n```\n\nMore infomation can be explore by using *\\_\\_dict\\_\\_*\n\n```python\npipeline.__dict__\npipeline.saver.__dict__\npipeline.reporter.__dict__\n\nhistory = pipeline.reporter.history\nhistory.keys()\n```","aed656b5":"Test for DLpipeline, using VGGs on cifar-10.\n\nProject website: [https:\/\/github.com\/HuadingLing\/DLpipeline](https:\/\/github.com\/HuadingLing\/DLpipeline)"}}