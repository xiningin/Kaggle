{"cell_type":{"a5ea98ce":"code","6d08b291":"code","817d3cdb":"code","a4e40175":"code","0fc2a969":"code","9cf8aa33":"code","c1bea249":"code","4aaa217c":"code","3cc2d408":"code","0628ba8c":"code","5c7307c8":"code","55f59f88":"code","9268207e":"code","b0a0fe14":"code","cb7e8fdc":"code","e9773c40":"code","9dfe3553":"code","aa6b1207":"code","f788c1d7":"code","05952ac7":"code","82f2858e":"code","b09808c0":"code","a5481029":"code","0ae96a6c":"code","833147ca":"code","0e0ea073":"code","1a8a2b30":"code","207c5117":"code","eb3199ea":"code","373ea5b5":"code","3a6008f7":"code","638cb208":"code","70825b0f":"code","d122f4b9":"code","4d23a2c9":"code","9d78d7cc":"code","aca04beb":"code","a650f4d5":"code","23aa80d0":"markdown","dafb18e2":"markdown","745dea8d":"markdown","731acb9f":"markdown","8fe06604":"markdown","f60192b3":"markdown","35e8c31d":"markdown","d7a70846":"markdown","d9fad61b":"markdown","7834fd02":"markdown","05084c88":"markdown"},"source":{"a5ea98ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d08b291":"#loading data\ndata = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","817d3cdb":"data.head()","a4e40175":"data.isnull().any().any()","0fc2a969":"data.size","9cf8aa33":"data.info()","c1bea249":"data.describe()","4aaa217c":"data['Class'].value_counts()","3cc2d408":"sns.countplot('Class', data = data)\nplt.title(\"Distribution of Classes for Transactions\")","0628ba8c":"#Categorizing fraud and normal cases \nfraud = data[data['Class']== 1]\nnormal= data[data['Class'] == 0]","5c7307c8":"#Checking pattern of the amounds withdrawn for both classes\nfig, ax = plt.subplots(2, 1)\nplt.suptitle(\"Amount per transaction\")\nax[0].hist(fraud[\"Amount\"], histtype = \"bar\", bins = 50)\nax[0].set_title(\"Fraud transations\")\nax[0].set_xlabel(\"Amount\")\nax[0].set_ylabel(\"number of transactions\")\nax[1].hist(normal[\"Amount\"], histtype = \"bar\", bins = 50)\nax[1].set_xlabel(\"Amount\")\nax[1].set_ylabel(\"number of transactions\")\nplt.title(\"Normal transactions\")\nplt.tight_layout()\n","55f59f88":"#Checking the pattern for occurance time for both classes\nfig, ax = plt.subplots(2, 1)\nplt.suptitle(\"Time elapsed since first transaction\")\nax[0].hist(fraud[\"Time\"], histtype = \"bar\", bins = 50)\nax[0].set_title(\"Fraud Transations\")\nax[0].set_xlabel(\"time in seconds \")\nax[0].set_ylabel(\"Frequency\")\nax[1].hist(normal[\"Time\"], histtype = \"bar\", bins = 50)\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"Time in seconds\")\nplt.title(\"Normal transactions\")\nplt.tight_layout()","9268207e":"#Checking if features are correlated\ncorrmat = data.corr()\nfig = plt.figure(figsize = (12, 9))\nsns.heatmap(corrmat, vmax = 0.8, square = True)\nplt.show()","b0a0fe14":"#categorizing feature and target array for training model \nX = data.drop(\"Class\", axis = 1)\ny = data[\"Class\"]\nprint(X.shape, y.shape)","cb7e8fdc":"xdata = X.values\nydata = y.values","e9773c40":"#Training the model without resampling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nX_train, X_test, y_train, y_test = train_test_split(xdata, ydata, test_size=0.2)\nclf = RandomForestClassifier(n_estimators=100, random_state = 0)","9dfe3553":"clf.fit(X_train, y_train)","aa6b1207":"y_pred=clf.predict(X_test)","f788c1d7":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))","05952ac7":"# class count\nclass_count_0, class_count_1 = data['Class'].value_counts()\n\n# Separate class\nclass_0 = data[data['Class'] == 0]\nclass_1 = data[data['Class'] == 1]# print the shape of the class\nprint('class 0:', class_0.shape)\nprint('class 1:', class_1.shape)","82f2858e":"#undersampling\nclass_0_under = class_0.sample(class_count_1)\n\ntest_under = pd.concat([class_0_under, class_1], axis=0)\n\nprint(\"total class of 1 and0:\",test_under['Class'].value_counts())# plot the count after under-sampeling\ntest_under['Class'].value_counts().plot(kind='bar', title='count (target)')","b09808c0":"#Oversampling\nclass_1_over = class_1.sample(class_count_0, replace=True)\n\ntest_over = pd.concat([class_1_over, class_0], axis=0)\n\nprint(\"total class of 1 and 0:\",test_under['Class'].value_counts())# plot the count after under-sampeling\ntest_over['Class'].value_counts().plot(kind='bar', title='count (target)')","a5481029":"#Define feature array and target array\nX= test_under.drop(\"Class\", axis = 1)\ny = test_under[\"Class\"]\nprint(X.shape, y.shape)\nX_under= X.values\ny_under = y.values","0ae96a6c":"#spliting test data and train data \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nX_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2)\nclf = RandomForestClassifier(n_estimators=25, random_state = 0)\n\n","833147ca":"#Fitting the model\nclf.fit(X_train, y_train)","0e0ea073":"#predicting the labels \ny_pred = clf.predict(X_test)","1a8a2b30":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))","207c5117":"print(y_test.shape, y_pred.shape)","eb3199ea":"sns.heatmap(metrics.confusion_matrix( y_test, y_pred), annot = True )","373ea5b5":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(fpr, tpr, thresholds)\nns_probs = [0 for _ in range(len(y_test))]\nrf_probs = y_pred\nrf_auc = roc_auc_score(y_test, rf_probs)\nns_auc = roc_auc_score(y_test, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('Random Forest: ROC AUC=%.3f' % (rf_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nrf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n","3a6008f7":"#Train Naive Bayes Model\nGNB = GaussianNB()\nGNB.fit(X_train, y_train)\ny_pred = GNB.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nsns.heatmap(metrics.confusion_matrix( y_test, y_pred), annot = True )","638cb208":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(fpr, tpr, thresholds)\nns_probs = [0 for _ in range(len(y_test))]\nmodel_probs = y_pred\nmodel_auc = roc_auc_score(y_test, model_probs)\nns_auc = roc_auc_score(y_test, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('GaussianNB: ROC AUC=%.3f' % (model_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nmodel_fpr, model_tpr, _ = roc_curve(y_test, model_probs)\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(rf_fpr, rf_tpr, marker='.', label='GaussianNB')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","70825b0f":"XGB = XGBClassifier()\nXGB.fit(X_train, y_train)\ny_pred = XGB.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nsns.heatmap(metrics.confusion_matrix( y_test, y_pred), annot = True )","d122f4b9":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(fpr, tpr, thresholds)\nns_probs = [0 for _ in range(len(y_test))]\nmodel_probs = y_pred\nmodel_auc = roc_auc_score(y_test, model_probs)\nns_auc = roc_auc_score(y_test, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('XGBoost: ROC AUC=%.3f' % (model_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nmodel_fpr, model_tpr, _ = roc_curve(y_test, model_probs)\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(rf_fpr, rf_tpr, marker='.', label='XGBoost')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","4d23a2c9":"LR = LogisticRegression()\nLR.fit(X_train, y_train)\ny_pred = LR.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nsns.heatmap(metrics.confusion_matrix( y_test, y_pred), annot = True )","9d78d7cc":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(fpr, tpr, thresholds)\nns_probs = [0 for _ in range(len(y_test))]\nmodel_probs = y_pred\nmodel_auc = roc_auc_score(y_test, model_probs)\nns_auc = roc_auc_score(y_test, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('XGBoost: ROC AUC=%.3f' % (model_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nmodel_fpr, model_tpr, _ = roc_curve(y_test, model_probs)\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(rf_fpr, rf_tpr, marker='.', label='XGBoost')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","aca04beb":"Model = SVC()\nModel.fit(X_train, y_train)\ny_pred = Model.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nsns.heatmap(metrics.confusion_matrix( y_test, y_pred), annot = True )","a650f4d5":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(fpr, tpr, thresholds)\nns_probs = [0 for _ in range(len(y_test))]\nmodel_probs = y_pred\nmodel_auc = roc_auc_score(y_test, model_probs)\nns_auc = roc_auc_score(y_test, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('SVC: ROC AUC=%.3f' % (model_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nmodel_fpr, model_tpr, _ = roc_curve(y_test, model_probs)\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\nplt.plot(rf_fpr, rf_tpr, marker='.', label='SVC')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","23aa80d0":"That seems a pretty good accuracy but we seem to forget that this is a balanced dataset, that means even though the accuracy is high, still it's not a good reflection of the accuracy of our predictions because it majority cases are normal cases and even if it is not able to detect minority fraud cases,it will show very high accuracy. Therefore accuracy is not a good measure in this case.Recall is a better estimate here and we can see that recall for positive cases is low. Hence we will use the above model as baseline model and optimize it.","dafb18e2":"We observe that fraud cases are very less as compared to normal cases, hence we have to train a model considering the nature of balanced dataset.","745dea8d":"We have trained multiple models but the best ROC AUC score 0.937 and F1 score 93% is obtained by Randomforest Classifier. Such a model can prove to be very useful while discriminating fraud cases from normal cases.","731acb9f":"All metrics have greately improved after undersampling.\n","8fe06604":"From the above observation it is clear that, for fraud transactions,lesser amount than normal transactions has been withdrawn","f60192b3":"For optimizing recall we will use resampling techniques","35e8c31d":"Above observation implies that fraud transactions do not usually happen and the chances of them occuring is far less than normal transactions that are far more consistent","d7a70846":"We have got a good enough ROC AUC score of 0.937.","d9fad61b":"By performing undersampling we have equalized the size of both classes equal to the majority class.","7834fd02":"By performing undersampling we have equalized the size of both classes equal to the minority class.","05084c88":"The correlation matrix shows that most features are not really correlated so we will keep the features intact as they are all useful."}}