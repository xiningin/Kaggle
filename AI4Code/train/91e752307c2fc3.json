{"cell_type":{"731f0a9b":"code","ab098ad2":"code","6226067e":"code","ec71bdd9":"code","45a608cf":"code","2ac9f91d":"code","98cf7b8a":"code","2e2e50e8":"code","278abfb3":"code","be9a39fc":"code","8a2d8845":"code","a2c013fb":"code","41239edd":"code","3ccf0f12":"code","533823a8":"code","c9629f1f":"code","39dfbe6c":"code","3d45d122":"code","41d2fdb8":"code","0a1bfbe3":"code","9638b4bd":"markdown","d004e48b":"markdown","35a6258b":"markdown","6477f2fb":"markdown","b480f18c":"markdown","50d71e61":"markdown","dc80a637":"markdown","777361b4":"markdown"},"source":{"731f0a9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab098ad2":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\npd.set_option('display.max_columns',100)\npd.set_option('display.max_rows',100)\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\n\nimport plotly.figure_factory as ff\nfrom plotnine import *\nimport plotnine as pn\n\nimport seaborn as sns","6226067e":"# read data\ntrain  = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv')","ec71bdd9":"# train and test data shape\nshape_df = pd.DataFrame({'Data':['Train','Test'],\n                       'Shape':[train.shape[0], test.shape[0]]})\ncolors = ['#FFBF00','#40E0D0']\ndata = go.Bar(x =shape_df.Shape[::-1],y=shape_df.Data[::-1], orientation='h', text=shape_df.Shape[::-1], textposition='auto', marker_color=colors)\nlayout = go.Layout(font=dict(family='Arial',size=14),\n                  paper_bgcolor='white',\n                  plot_bgcolor = '#FFFAFA',\n                 showlegend=False,width=800, height=400,title='Train & Test Data Size')\nfig = go.Figure(data=data, layout=layout)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black')\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black')\nfig.show()\nplt.savefig('data_shape.png')","45a608cf":"# get column dtype counts\nlabels = ['float','int']\nvalues = [118,0]\ndata = go.Pie(labels=labels, values=values,pull=[0.2,0],textinfo='label+value', marker=dict(colors=colors))\nlayout = go.Layout(font=dict(family='Arial',size=14),\n                  paper_bgcolor='white',\n                  plot_bgcolor = '#FFFAFA',\n                 showlegend=False,title='Feature Count by Data Type', height=500, width=500)\nfig = go.Figure(data=data,layout=layout)\nfig.show()","2ac9f91d":"missing_value_count = train.drop(['id','claim'], axis=1).isna().sum()\nmissing_value_count_df = pd.DataFrame({'Feature':missing_value_count.index,'Missing Value Count':missing_value_count.values})\nmissing_value_count_df['Missing %'] = np.round(missing_value_count_df['Missing Value Count']\/train.shape[0] * 100, 1)\nmissing_value_count_df =  missing_value_count_df.sort_values(by='Missing %', ascending=False)\n\ndata = go.Bar(x =missing_value_count_df.Feature[::-1],y=missing_value_count_df['Missing %'][::-1],\n              text=missing_value_count_df['Missing %'][::-1], textposition='auto', marker_color='#FFBF00')\nlayout = go.Layout(font=dict(family='Arial',size=14),\n                  paper_bgcolor='white',\n                  plot_bgcolor = '#FFFAFA',\n                 showlegend=False,title='Missing Values - Train Data')\nfig = go.Figure(data=data, layout=layout)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black', title='Feature')\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black',title='Missing %')\nfig.show()\nplt.savefig('missing_values.png')","98cf7b8a":"target_count = train.claim.value_counts()\ntarget_count_df = pd.DataFrame({'Target':target_count.index,'Count':target_count.values})\n\ntarget_map = {1:'Claim',0:'No Claim'}\ntarget_count_df['Target'] = target_count_df['Target'].map(target_map)\n\ncolors = ['#FFBF00','#40E0D0']\ndata = go.Bar(x =target_count_df.Count[::-1],y=target_count_df.Target[::-1], orientation='h', text=target_count_df.Count[::-1], \n              textposition='auto', marker_color=colors)\nlayout = go.Layout(font=dict(family='Arial',size=14),\n                  paper_bgcolor='white',\n                  plot_bgcolor = '#FFFAFA',\n                 showlegend=False,width=800, height=400,title='Train Data - Claim & No Claim Counts')\nfig = go.Figure(data=data, layout=layout)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black')\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black')\nfig.show()\nplt.savefig('target_counts.png')","2e2e50e8":"feat_list = train.drop(['id','claim'], axis=1).columns\nclaim_df = train[train.claim == 1][feat_list]\nno_claim_df = train[train.claim == 0][feat_list]\n\nfeat_list_set1 = feat_list[0:20]\n\nfig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set1[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()\nplt.savefig('feature_distribution.png')","278abfb3":"feat_list_set2 = feat_list[20:40]\n\nfig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set2[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","be9a39fc":"feat_list_set3 = feat_list[40:60]\n\nfig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set3[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","8a2d8845":"feat_list_set4 = feat_list[60:80]\n\nfig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set4[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","a2c013fb":"feat_list_set5 = feat_list[80:100]\n\nfig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set5[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","41239edd":"feat_list_set6 = feat_list[100:119]\n\nfig, axes = plt.subplots(6, 3,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(6):\n    for col in range(3):\n        feat = feat_list_set6[n] \n        sns.kdeplot(claim_df[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(no_claim_df[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","3ccf0f12":"fig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set1[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","533823a8":"fig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set2[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","c9629f1f":"fig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set3[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","39dfbe6c":"fig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set4[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","3d45d122":"fig, axes = plt.subplots(5, 4,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(5):\n    for col in range(4):\n        feat = feat_list_set5[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","41d2fdb8":"fig, axes = plt.subplots(6, 3,figsize=(21, 20))\n\nn = 0\nsns.despine()\nfor row in range(6):\n    for col in range(3):\n        feat = feat_list_set6[n] \n        sns.kdeplot(train[feat],shade=True, color=\"#FFBF00\", alpha=0.1, ax=axes[row,col])\n        sns.kdeplot(test[feat], shade=True, color=\"#40E0D0\", alpha=0.1, ax=axes[row,col])\n        axes[row,col].set(xlabel='', ylabel='')\n        axes[row,col].set_title('Feature: '+str(feat),fontdict= { 'fontsize': 12, 'fontweight':'bold'})\n        n += 1\nplt.tight_layout()","0a1bfbe3":"corr = train.drop(['id','claim'], axis=1).corr()\n\nf, ax = plt.subplots(figsize=(16, 16))\n\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","9638b4bd":"There seems to be no correlation between the features. Since we have no specific information about the features, we can jump directly to feature engineering and modeling.\n\n_**As always...work in progress!**_\n\n**Keep learning and have fun**","d004e48b":"The distributions for the features are similar for the 'claim' and 'no claim' targets. And some distributions are very weird! These need to be tackled seprately with some transformations.","35a6258b":"The data is very balanced. Phew! One challenge less.","6477f2fb":"## 3. Features\nWe will compare the feature distribution for the train and test data. Yellow shows train data and green indicates test data. We will also plot and study the correlation between the features.","b480f18c":"Again, the distribution of features for the train and test data are near identical.","50d71e61":"## 2. Target Variable - Claim\nWe will explore the target variable in this section. As per the description thought the 'claim' variable is binary, the probability that a person will make a claim is what is needed for the submission. The predictions will be evaluated on the auc score.\n\nFirst, we look at the counts for the 'claim' and no'claim' in the training dataset.","dc80a637":"## 1. Data Overview\n\nThis section provides a summary of the data.\n\n**Summary**\n* Total number of observations in the train data is 957,919. Observations to be predicted on (test data) is 493,474.\n* About 1.6% of the data is missing in each column. This will need a further deep dive for modeling.\n* Overall, there are 118 features (named from f1 to f118) that we will be used to predict the target variable (claim). Includes an 'id' column of type integer, which from a cursory look is just a row identifier and will be dropped.\n* All 118 predictor variables not including the id column are float variables.\n* The target variable, claim is a probablility prediction and will be evaluated on the auc score.","777361b4":"### 2.1 Feature Distribution for Target\n\nWe will compare the feature distribution for the 'Claim' and 'No Claim'."}}