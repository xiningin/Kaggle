{"cell_type":{"2cb58f66":"code","bdf2f499":"code","ed881be2":"code","9d5d2228":"code","5d5e7443":"code","80d123ad":"code","3129a412":"code","c0c4318d":"code","06168d51":"code","4d1091a6":"code","644f1ff7":"code","48ea29e5":"code","c3391649":"code","15f34a05":"code","e7155dc5":"code","0453e2e0":"code","f35eecaa":"code","17524b9a":"code","ee77a644":"code","9fcf521b":"code","a67112ad":"code","25605628":"code","682c386d":"code","c0a77ed9":"code","4d361f0f":"code","734b39d9":"code","b73268a5":"code","58ec7fc6":"code","3ee471a2":"code","5f4d1082":"code","76583101":"code","9c8a0105":"code","d6f96b7c":"code","0510a8fc":"code","393f1309":"code","f9ec8803":"code","42149c33":"code","25eb4668":"code","77eecac1":"code","faabfdef":"code","10797cdf":"code","7dbdda1d":"code","26fd429c":"code","07b98a3a":"code","6c6d6ea0":"code","ef7f6812":"code","a72262f7":"code","4da9cd27":"code","4d4eba38":"code","b8986773":"code","92b72c43":"code","34018b27":"code","668167fb":"code","85f80469":"code","e2ddcb74":"code","4af20422":"code","528c89d4":"code","f7e0e917":"code","5dcfdb17":"code","8a7a20cd":"code","575c37bf":"code","b72e86c7":"code","70b72cc2":"code","36771964":"code","7939273f":"code","808dda3c":"code","e5057847":"code","d2bd0efc":"code","1a1fea27":"code","3fb46334":"code","78680df7":"code","ff31bcfc":"code","cb4d4f82":"code","afb62ba6":"markdown","e8513a96":"markdown","a5c3016e":"markdown","5aee30b8":"markdown","f5af82bf":"markdown","05a33ead":"markdown","240e73d9":"markdown","307a3cdd":"markdown","f7ade15e":"markdown","27dbacc8":"markdown","8b4d3781":"markdown","93a6ac2d":"markdown","b8e37f7b":"markdown","ef881c60":"markdown","51bbfb1c":"markdown","865806e1":"markdown","6cddabec":"markdown","9876a92c":"markdown","71e12ffb":"markdown","211e5dda":"markdown","07556348":"markdown","ec3f5e21":"markdown","3c0cf142":"markdown","69668375":"markdown","88fd0502":"markdown","c4cf7235":"markdown","7a875568":"markdown","09a0b5c6":"markdown","02fa4403":"markdown","697b560b":"markdown","69ed36c8":"markdown","b6aacd32":"markdown","8177fdd3":"markdown","5a6dd845":"markdown","d9172be8":"markdown","6e96ef91":"markdown","e959398a":"markdown","c9f11c98":"markdown","fd1ab06c":"markdown","2a647a14":"markdown","f7480505":"markdown","77646986":"markdown","c1149dae":"markdown","415d68b3":"markdown","3b9f61a5":"markdown","82cb9f19":"markdown","a9f7942d":"markdown","602c5a64":"markdown","46053ebb":"markdown","7f478ea8":"markdown","f790b114":"markdown","0ee93492":"markdown","90f07535":"markdown","3280275c":"markdown","de1d78bc":"markdown","4f9809aa":"markdown","c597a39e":"markdown","5bb8e2d3":"markdown","72c376a1":"markdown","398341c6":"markdown","ab9da038":"markdown","235b7840":"markdown","25d2f915":"markdown","5ee3daf6":"markdown","7becaa28":"markdown"},"source":{"2cb58f66":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_predict\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV","bdf2f499":"import os\nlistA =[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        listA.append(os.path.join(dirname, filename))\n\nprint(listA)\n\nflight = pd.read_csv(\"\/kaggle\/input\/datavidia2019\/flight.csv\")\nhotel = pd.read_csv(\"\/kaggle\/input\/datavidia2019\/hotel.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/datavidia2019\/test.csv\")\nss = pd.read_csv(\"\/kaggle\/input\/datavidia2019\/sample_submission.csv\")","ed881be2":"flight.info()","9d5d2228":"hotel.info()","5d5e7443":"test.info()","80d123ad":"ss.info()","3129a412":"flight.head()","c0c4318d":"hotel.head()","06168d51":"test.head()","4d1091a6":"ss.head()","644f1ff7":"for column in flight.columns:\n    print(flight[column].value_counts())","48ea29e5":"for column in hotel.columns:\n    print(hotel[column].value_counts())","c3391649":"for column in test.columns:\n    print(test[column].value_counts())","15f34a05":"for column in ss.columns:\n    print(ss[column].value_counts())","e7155dc5":"# merge data flight dan hotel berdasarkan hotel id\n\nflight = flight.merge(hotel, how='left', left_on='hotel_id', right_on='hotel_id')","0453e2e0":"del flight['route']\ndel test['route']","f35eecaa":"flight['is_cross_sell'] = [0 if x == 'None' else 1 for x in flight['hotel_id']]","17524b9a":"flight['count_visited_city'] = [len(x.strip('[]').split(',')) for x in flight['visited_city']]","ee77a644":"test['count_visited_city'] = [len(x.strip('[]').split(',')) for x in test['visited_city']]","9fcf521b":"flight['count_transaction'] = [len(x.strip('[]').split(',')) for x in flight['log_transaction']]","a67112ad":"test['count_transaction'] = [len(x.strip('[]').split(',')) for x in test['log_transaction']]","25605628":"flight['is_tx_promo_yes'] = [0 if x == 'NO' else 1 for x in flight['is_tx_promo']]","682c386d":"test['is_tx_promo_yes'] = [0 if x == 'NO' else 1 for x in test['is_tx_promo']]","c0a77ed9":"flight['gender_m'] = [0 if x == 'F' else 1 for x in flight['gender']]","4d361f0f":"test['gender_m'] = [0 if x == 'F' else 1 for x in test['gender']]","734b39d9":"flight['service_class_business'] = [0 if x == 'ECONOMY' else 1 for x in flight['service_class']]","b73268a5":"test['service_class_business'] = [0 if x == 'ECONOMY' else 1 for x in test['service_class']]","58ec7fc6":"def func(row):\n    if row['trip'] == 'roundtrip':\n        return 0\n    elif row['trip'] == 'trip':\n        return 1 \n    else:\n        return 2","3ee471a2":"flight['trip_round'] = flight.apply(func, axis=1)","5f4d1082":"test['trip_round'] = test.apply(func, axis=1)","76583101":"tmp_set = {x for x in flight['visited_city']}\ntmp_dict = {j : i for i,j in enumerate(tmp_set)}","9c8a0105":"flight['visited_city_id'] = [tmp_dict[x] for x in flight['visited_city']]\ntest['visited_city_id'] = [tmp_dict[x] for x in test['visited_city']]","d6f96b7c":"tmp_set = {x for x in flight['airlines_name']}\ntmp_dict = {j : i for i,j in enumerate(tmp_set)}","0510a8fc":"flight['airlines_name_id'] = [tmp_dict[x] for x in flight['airlines_name']]\ntest['airlines_name_id'] = [tmp_dict[x] for x in test['airlines_name']]","393f1309":"s = flight['account_id'].tolist()\ns.extend(test['account_id'].tolist())\ntmp_set = {x for x in s}\ntmp_dict = {j : i for i,j in enumerate(tmp_set)}","f9ec8803":"flight['account_id_int'] = [tmp_dict[x] for x in flight['account_id']]\ntest['account_id_int'] = [tmp_dict[x] for x in test['account_id']]","42149c33":"# set order_id sebagai index column\n\ntrain = flight.set_index('order_id')\ntest = test.set_index('order_id')","25eb4668":"sns.countplot(x='no_of_seats', hue='is_cross_sell', data=train)\npd.crosstab(train.no_of_seats, train.is_cross_sell, normalize='index')","77eecac1":"sns.countplot(x='count_visited_city', hue='is_cross_sell', data=train)\npd.crosstab(train.count_visited_city, train.is_cross_sell, normalize='index')","faabfdef":"sns.countplot(x='is_tx_promo_yes', hue='is_cross_sell', data=train)\npd.crosstab(train.is_tx_promo_yes, train.is_cross_sell, normalize='index')","10797cdf":"sns.countplot(x='gender_m', hue='is_cross_sell', data=train)\npd.crosstab(train.gender_m, train.is_cross_sell, normalize='index')","7dbdda1d":"sns.countplot(x='service_class_business', hue='is_cross_sell', data=train)\npd.crosstab(train.service_class_business, train.is_cross_sell, normalize='index')","26fd429c":"sns.countplot(x='trip_round', hue='is_cross_sell', data=train)\npd.crosstab(train.trip_round, train.is_cross_sell, normalize='index')","07b98a3a":"sns.countplot(x='visited_city_id', hue='is_cross_sell', data=train)\npd.crosstab(train.visited_city_id, train.is_cross_sell, normalize='index')","6c6d6ea0":"sns.countplot(x='airlines_name_id', hue='is_cross_sell', data=train)\npd.crosstab(train.airlines_name_id, train.is_cross_sell, normalize='index')","ef7f6812":"pd.crosstab(train.account_id_int, train.is_cross_sell, normalize='index')","a72262f7":"sns.boxplot(x='is_cross_sell', y='member_duration_days', data=train)","4da9cd27":"sns.boxplot(x='is_cross_sell', y='price', data=train)","4d4eba38":"sns.boxplot(x='is_cross_sell', y='count_transaction', data=train)","b8986773":"mean = train['is_cross_sell'].mean()\nmean_encode = train.groupby('account_id_int')['is_cross_sell'].mean()\ntrain['account_id_enc'] = train['account_id_int'].map(mean_encode).fillna(mean)\ntest['account_id_enc'] = test['account_id_int'].map(mean_encode).fillna(mean)","92b72c43":"sns.heatmap(train.corr())","34018b27":"X = train.drop(['account_id', 'gender', 'trip', 'service_class', \n                'is_tx_promo', 'airlines_name', 'service_class_business',\n                'hotel_id', 'visited_city', 'log_transaction', 'starRating', 'city', 'free_wifi',\n                'pool_access', 'free_breakfast', 'count_visited_city', 'account_id_int'], axis=1)","668167fb":"test_ss = test.drop(['account_id', 'gender', 'trip', 'service_class',\n                     'is_tx_promo', 'airlines_name', 'service_class_business',\n                     'visited_city', 'log_transaction', 'count_visited_city', 'account_id_int'], axis=1)","85f80469":"X.columns","e2ddcb74":"y = X['is_cross_sell']\nX = X.drop(['is_cross_sell'],axis=1)","4af20422":"# Hasil parameter tunning masing-masing base-classifier\n\nrf = RandomForestClassifier(n_estimators=64, criterion= 'gini', max_depth=20, max_features=7, random_state= 1234,\n                            class_weight= 'balanced', min_samples_split=2)\n\net = ExtraTreesClassifier(n_estimators=16, criterion= 'gini', max_depth=24, max_features= 6, random_state= 1234, \n                          class_weight= 'balanced', min_samples_split=2)\n\nbc = BaggingClassifier(n_estimators=128, max_features=6, random_state=1234, bootstrap=False)\n\nab = AdaBoostClassifier(rf, n_estimators=10, random_state= 1234, learning_rate=0.005)","528c89d4":"vc = VotingClassifier(estimators=[('et', et), ('rf', rf), ('bc', bc), ('ab', ab)], voting='soft')","f7e0e917":"scoring = {'accuracy' : make_scorer(accuracy_score), \n           'precision' : make_scorer(precision_score),\n           'recall' : make_scorer(recall_score), \n           'f1_score' : make_scorer(f1_score)}","5dcfdb17":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234, stratify = y)","8a7a20cd":"kfold = KFold(n_splits=5, random_state=1234, shuffle = True)","575c37bf":"# Skor prediksi Random Forest Classifier\n\nresults_rf = cross_validate(estimator=rf,X=X_train,\n                                          y=y_train,\n                                          cv=kfold,\n                                          scoring=scoring)\nresults_rf","b72e86c7":"# Validasi hold out test\n\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nrf_f1_score = f1_score(y_pred, y_test)\nrf_acc = accuracy_score(y_pred, y_test)\n\nprint(\"Hold out prediction score: \", rf_f1_score)\nprint(\"Accuracy score: \", rf_acc)","70b72cc2":"# Skor prediksi Extra Trees Classifier\n\nresults_et = cross_validate(estimator=et,X=X_train,\n                                          y=y_train,\n                                          cv=kfold,\n                                          scoring=scoring)\nresults_et","36771964":"# Validasi hold out test\n\net.fit(X_train, y_train)\ny_pred = et.predict(X_test)\net_f1_score = f1_score(y_pred, y_test)\net_acc = accuracy_score(y_pred, y_test)\n\nprint(\"Hold out prediction score: \", et_f1_score)\nprint(\"Accuracy score: \", et_acc)","7939273f":"# Skor prediksi Bagging Classifier\n\nresults_bc = cross_validate(estimator=bc,X=X_train,\n                                          y=y_train,\n                                          cv=kfold,\n                                          scoring=scoring)\nresults_bc","808dda3c":"# Validasi hold out test\n\nbc.fit(X_train, y_train)\ny_pred = bc.predict(X_test)\nbc_f1_score = f1_score(y_pred, y_test)\nbc_acc = accuracy_score(y_pred, y_test)\n\nprint(\"Hold out prediction score: \", bc_f1_score)\nprint(\"Accuracy score: \", bc_acc)","e5057847":"# Skor prediksi AdaBoost Classifier\n\nresults_ab = cross_validate(estimator=ab,X=X_train,\n                                          y=y_train,\n                                          cv=kfold,\n                                          scoring=scoring)\nresults_ab","d2bd0efc":"# Validasi hold out test\n\nab.fit(X_train, y_train)\ny_pred = ab.predict(X_test)\nab_f1_score = f1_score(y_pred, y_test)\nab_acc = accuracy_score(y_pred, y_test)\n\nprint(\"Hold out prediction score: \", ab_f1_score)\nprint(\"Accuracy score: \", ab_acc)","1a1fea27":"# Skor prediksi Voting Classifier\n\nresults_vc = cross_validate(estimator=vc,X=X_train,\n                                          y=y_train,\n                                          cv=kfold,\n                                          scoring=scoring)\nresults_vc","3fb46334":"# Validasi hold out test\n\nvc.fit(X_train, y_train)\ny_pred = vc.predict(X_test)\nvc_f1_score = f1_score(y_pred, y_test)\nvc_acc = accuracy_score(y_pred, y_test)\n\nprint(\"Hold out prediction score: \", vc_f1_score)\nprint(\"Accuracy score: \", vc_acc)","78680df7":"est = ['Random Forest Classifier', 'Extra Trees Classifier', 'Bagging Classifier', 'AdaBoost Classifier', 'Voting Classifier']\nacc = [rf_acc, et_acc, bc_acc, ab_acc, vc_acc]\nf1 = [rf_f1_score, et_f1_score, bc_f1_score, ab_f1_score, vc_f1_score]","ff31bcfc":"(pd.Series(f1, index=est).sort_values(ascending= True)\n   .plot(kind='barh'))\nplt.xlim(0.83,0.86)\nplt.title('F1-Score on Test data')\nplt.show()\n\n(pd.Series(acc, index=est).sort_values(ascending= True)\n   .plot(kind='barh'))\nplt.xlim(0.97,0.99)\nplt.title('Accuracy on Test data')\nplt.show()","cb4d4f82":"rf.fit(X,y)\n\n(pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending= True)\n   .plot(kind='barh'))\nplt.title('Feature importances')","afb62ba6":"### Check Top 5 of the Dataset","e8513a96":"## A. Conclusion\n\nPreprocessing data dilakukan untuk memahami data dan mentransformasinya agar siap diproses oleh machine learning. Exploratory data analysis diperlukan untuk mengetahui keterhubungan antara tiap fitur dengan target fitur, yaitu cross selling. Dari proses ini diambil insight bahwa banyak terjadi imbalance pada data.\n\nLalu, berdasarkan teori \"repeat-buying\" kami berhipotesis account_id merupakan salah satu fitur yang paling berpengaruh terhadap cross selling. Hal ini juga didukung hasil exploratory data analysis. Oleh karena itu, pada feature engineering target encoder diterapkan pada account. Selain itu, feature yang tidak digunakan dapat dibuang.\n\nHipotesis mengenai \"repeat-buying\" terbukti dapat berpengaruh besar pada prediksi, di mana fitur account_id_enc memiliki fitur importance yang jauh lebih tinggi dibandingkan fitur lainnya. Implementasi` account_id_enc` dapat meningkatkan score prediksi pada private leaderboard kaggle dari 79,428 menjadi 83,228. Teknik stacking classifier yang diterapkan untuk mendapatkan prediksi juga terbukti dapat menghasilkan F1-score dan Accuracy cross validation lebih tinggi dibanding pada single classifier saja, namun perbedaan yang ada tidak begitu banyak.\n\nHasil akhir yang didapatkan adalah 0,83288 untuk metrik F1-score di private leaderboard kaggle.","a5c3016e":"# Datavidia 2019\n## By: Tim BEBAS - University of Indonesia\n### 1. Muhammad Ridho Ananda(Captain) - mridho2828@gmail.com\n### 2. Jonathan Edwin - edwin.ryth@gmail.com\n### 3. Lulu Ilmaknun Qurotaini - lulu.ilmaknun.q@gmail.com","5aee30b8":"## D. Feature Impotance","f5af82bf":"## A. Understand the Business","05a33ead":"# 3. Exploratory Data Analysis","240e73d9":"# 5. Modelling","307a3cdd":"### Memeriksa setiap Column dan hitung value counts","f7ade15e":"### Random Forest Classifier Validation","27dbacc8":"## B. Recommendation \n\nDari pekerjaan yang telah dilakukan, kami menyadari bahwa pekerjaan kami jauh dari kata sempurna, terdapat beberapa saran-saran agar pekerjaan berikutnya lebih baik:\n\n- Dari data perusahaan yang telah disediakan, kita dapat membuat profiling orang-orang dengan bantuan unsupervised machine learning atau Recommendation system, agar memberikan rekomendasi hotel yang sesuai dengan profile orang tersebut.\n- Jika data ini memiliki tanggal setiap transaksi, kita bisa menggunakan model machine learning seperti *Long Short Term Memory* untuk melihat transaksi pembelian.\n- Membuat fitur baru seperti dari jumlah hari member menjadi jumlah tahun member dapat dilakukan, menggunakan jumlah transaksi dan melakukan rata-rata jumlah transaksi. ","8b4d3781":"### Features Correlation","93a6ac2d":"Pada proses ini akan dilakukan visualisasi data yang telah melalui preprocessing. Tujuannya untuk mendapatkan keterhubungan antara suatu fitur dengan fitur target (is_cross_sell).","b8e37f7b":"## Merge data flight dan hotel","ef881c60":"## Membuat Column account_id_int","51bbfb1c":"### Target encoding by mean value","865806e1":"Pada bagian ini, kami berusaha untuk mengerti segala informasi awal dari segi bisnis. Terdapat beberapa hal yang kami ketahui adalah, data tersebut berasal dari salah satu ticketing company terbesar di Indonesia. Pada kompetisi ini, kami diminta untuk membuat model yang dapat memprediksi apakah seseorang pelanggan akan membuat booking hotel bersamaan dengan membeli tiket pesawat atau yang disebut sebagai cross selling.\n\nCross Selling adalah suatu praktek penjualan dengan melibatkan promosi produk tambahan agar konsumen memberli produk awal dan produk tambahan tersebut. Untuk kasus ini, produk awalnya adalah tiket pesawat dan produk tambahannya adalah booking hotel. Sehingga dari sini dapat kita buat `problem statement` sebagai berikut:\n\n`Problem Statement:` Prediksi 'apakah pada sebuah transaksi pembelian tiket pesawat terjadi booking hotel (cross sell)'\n\nDengan melakukan prediksi ini, perusahaan tersebut dapat mengetahui pelanggan yang mungkin akan melakukan cross selling sehingga dapat memberikan iklan booking hotel yang sesuai agar orang tersebut melakukan cross selling dan perusahaan dapat meningkatkan revenue.","6cddabec":"## Drop Column route","9876a92c":"## B. Train\/Test Splitting\n\nTrain\/Test Split digunakan untuk memvalidasi overfitting dan underfitting pada prediksi. Terdapat 20% dari data yang menjadi Hold out data. Model hanya akan melakukan train pada 80% data, sehingga Hold out data dapat dijadikan validasi model.\n\n![Train\/Test split diagram](https:\/\/drive.google.com\/uc?id=10s102L6TmmAKuGdEVJ2pEwXCxVnJ5iIj)\n\nGambar 6. Train\/Test split diagram","71e12ffb":"### Membuat Column `count_visited_city`","211e5dda":"## B. Feature selection\n\nFeature selection pertama kali dilakukan pada feature yang *imbalance* dan berkorelasi tinggi dengan feature lain, seperti `city`, `service_class`, `trip`, dll.\n\nEliminasi terhadap feature secara berkala dilakukan setelah tahap validasi dengan melihat *feature importance* dan hasil akurasi dari validasi.","07556348":"# 8. References ","ec3f5e21":"![Feature engineering implementation](https:\/\/drive.google.com\/uc?id=1VPGI6t3IAZTbH7tmg7R59fc5EYLHZZ8e)\n\nGambar 2. Feature engineering flow","3c0cf142":"## C. Cross Validation\nTeknik cross-validation digunakan dalam melakukan validasi terhadap hasil prediksi.\n\n![cross-validation](https:\/\/drive.google.com\/uc?id=12lYGhLigD3GTGLK6IVtsTYkma1_s9FKM)\n\nGambar 7. 5-Fold Validation\n","69668375":"![validation flow](https:\/\/drive.google.com\/uc?id=1yVe1wWpP_BKrYDM8rfkp2lXLjxw7eSEL)\n\nGambar 4. Alur proses validasi","88fd0502":"Berikut data-data yang akan digunakan:\n\n- flight.csv - Data training yang berisi berbagai flight transaction beserta atribut-atributnya\n- test.csv - Data test yang berisi flight transactions yang harus diprediksi apakah terjadi cross sell atau tidak\n- hotel.csv - Berisi data hotel dan atribut-atributnya\n- Data Dictionary.pdf - Berisi makna-makna variable dari pada tiap data\n- sample_submission.csv - Berisi format submisi ke Kaggle","c4cf7235":"## B. Visualisasi Fitur Kuantitatif terhadap Cross Selling\n\nFitur kuantitatif yang akan divisualisasi adalah `member_duration_days`, `price`, dan `count_transaction`. Cara yang digunakan untuk visualisasi adalah dengan boxplot.","7a875568":"### Features Elimination","09a0b5c6":"### Info for every Dataset","02fa4403":"# 1. Understand the Problem (Business and Data)","697b560b":"### AdaBoost Classifier Validation","69ed36c8":"# 6. Validation\n\n\n\n","b6aacd32":"### Membuat Column `is_cross_sell`","8177fdd3":"[1] Wirth, R. & Hipp, J.(2000). CRISP-DM: Towards a standard process model for data mining. *Proceedings of the Fourth International Conference on the Practical Applicationof Knowledge Discovery and Data Mining*; April 11-13, 2000; Manchester, UK p. 29-39.\n\n[2] Micci-Barreca, D. (2001). A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems. *SIGKDD Explorations*, 3, 27\u201332.\n\n[3] Rahul Bhagat, Srevatsan Muralidharan, Alex Lobzhanidze, and Shankar Vishwanath. (2018). Buy It Again: Modeling Repeat Purchase Recommendations. *Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*. ACM, 62\u201370\n\n[4] Dzeroski, S. & Zenko, B. (2004). Is Combining Classifiers with Stacking better than Selecting the Best One?. *Machine Learning*, 54, 255-273.\n\n[5] Ali, K. M. & Pazzani, M. J. (1996). Error reduction through learning multiple descriptions. *Machine Learning*, 4, 173-202.\n\n[6] Bauer, E., & Kohavi, R. (1999). An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. *Machine Learning*, 36, 105\u2013142.\n","5a6dd845":"### Base-classifier","d9172be8":"### Membuat Column `trip_round`","6e96ef91":"### Membuat Column `is_tx_promo_yes`","e959398a":"## B. Model estimators\n\nPemilihan metode dan model *base-classifier* dan *meta-classifier* didasari atas kelebihan *ensemble learning* dalam meningkatkan akurasi prediksi (Stacking), mengurasi variance (Bagging), dan mengurangi bias (Boosting).[[6]](http:\/\/robotics.stanford.edu\/~ronnyk\/vote.pdf) Metode Bagging dan Boosting diimplementasikan pada penggunaan *base-classifier* dan metode Stacking digunakan sebagai improvisasi prediksi akhir.\n\nDengan menggunakan metode stacking, beberapa *base-classifier* hasil tunning digunakan dalam melakukan prediksi fase pertama, yaitu:\n\n* `Random Forest Classifier: `model menggabungkan beberapa decision tree dengan teknik Bagging. Di samping penerapan bagging, Random forest juga dapat menilai *feature importance* dari proses prediksinya, sehingga dipilih dalam permasalahan ini.\n\n* `Extra Trees Classifier: `model menggabungkan beberapa decision tree. Setiap tree dibentuk dari subset feature yang dirandom (Extremely Randomized Trees).\n\n* `AdaBoost Classifier: `model menggabungkan classifier dengan seleksi data training di setiap iterasi dan memberi bobot untuk prediksi akhir dari model.\n\n* `Bagging Classifier: `pengimplementasian dari teknik Bagging dengan base estimator tertentu. Membangun beberapa model dari subset data yang diambil secara random dan menggabungkannya.\n\n\n\nKemudian `Voting Classifier` digunakan pada fase kedua sebagai *meta-classifier* penentu prediksi akhir. `Voting Classifier` menggunakan sistem `wisdom of crowd`, kami percaya bahwa beberapa machine learning yang dijadikan sistem voting akan memiliki nilai lebih baik dibandingkan hanya menggunakan 1 model machine learning saja.\n\n![Method implementation](https:\/\/drive.google.com\/uc?id=1NMl41NFYoF6hePEDQ86l-h7b-kcES_q_)\n\nGambar 3. Stacking diagram","c9f11c98":"## A. Target Encoding\n\n*Target encoding* merupakan salah satu metode *categorical encoding* yang didasari oleh pemetaan atribut independen dengan nilai individual kardinalitas tinggi (seperti id, email, dll) untuk mengestimasi probabilitas atau nilai ekspektasi dari dependen atibut dengan pengukuran statistika tertentu.[[2]](http:\/\/helios.mm.di.uoa.gr\/~rouvas\/ssi\/sigkdd\/sigkdd.vol3.1\/barreca.pdf)\n\nTarget encoding dilakukan terhadap feature `account_id_int`. Hal ini didasari atas hipotesis yang diambil dari teori \"repeat-buying\" [[3]](https:\/\/www.researchgate.net\/publication\/326500216_Buy_It_Again_Modeling_Repeat_Purchase_Recommendations) bahwa user yang melakukan cross selling dengan frekuensi lebih tinggi, akan memiliki probabilitas lebih tinggi juga untuk melakukan cross selling kembali. Sehingga dapat dibuat sebuah fitur probabilitas kejadian cross selling pada user tertentu dari kemunculannya pada transaksi sebelumnya. Hal ini juga didukung oleh hasil visualisasi pada bagian *Exploratory Data Analysis* dimana mayoritas account mendapatkan cross selling untuk semua order atau tidak mendapatkan cross selling sama sekali.\n\nKami membuat fitur baru yaitu `account_id_enc` yang merupakan hasil dari target encoding untuk tiap account berdasarkan **mean** dari semua nilai cross selling untuk account yang bersangkutan. ","fd1ab06c":"### Membuat Column `count_transaction`","2a647a14":"## Membuat Column airplanes_id","f7480505":"## A. Validation score\n\nValidation score metric yang menjadi acuan adalah F1-score. Score digunakan untuk melakukan komparasi apakah sebuah modal dan hasil prediksinya sudah cukup baik atau belum.\n\nF1-score mengukur keseimbangan antara precision dan recall, di mana yang menjadi pertimbangan adalah False Negative dan False Positive. Dapat digunakan untuk menjadi metric ketika terdapat imbalance pada data.\n\n![F1-score formula](https:\/\/www.mikulskibartosz.name\/assets\/images\/2019-02-04-f1-score-explained\/formula.png)\n\nGambar 5. F1-score formula\n\nDi samping metric F1-score, accuracy tetap dijadikan acuan berikutnya untuk mengukur seberapa tepat model sudah memprediksi data dengan benar.","77646986":"Dari bagian Data Understandinng dan Business Understanding, terdapat beberapa hal yang kami ketahui:\n\n- `Target Variable:` `is_cross_sell` Namun saat ini belum ada fitur tersebut, perlu dibuat.\n\n- `Problem Type: ` Klasifikasi Binary dengan class 'yes' dan 'no'\n\n- `Metric: ` Mean F1-Score\n\n- Tidak ada column yang memiliki missing value untuk setiap dataset\n- Data pada Train dan Test itu konsisten\n- Columns `route` hanya memiliki 1 unique value sehingga akan didrop\n- Terdapat 2 value di column `airlines_name` yang ada di Train tetapi tidak ada di Test\n- Column `account_id`, `gender`, `service_class`, ` trip` dan `is_tx_promo` memiliki value berupa string, perlu dilakukan Label Encoding\n- Column `visited_city` dan `log_transaction` masih dalam bentuk list, sehingga perlu dilakukan transformation column\n- Column `hotel_id`dapat diubah menjadi `is_cross_sell` \n- Column `gender` memiliki value bernilai `None`","c1149dae":"# 4. Feature Engineering","415d68b3":"### Test score plot","3b9f61a5":"# 7. Conclusion and Recommendation ","82cb9f19":"## A. Visualisasi Fitur Categorical terhadap Cross Selling\n\nFitur kategorikal yang akan divisualisasikan adalah `no_of_seats`, `count_visited_city`, `is_tx_promo_yes`, `gender_m`, `service_class_business`, `trip_round`, `visited_city_id`, `airlines_name_id`, dan `account_id_int`. Cara visualisasinya adalah dengan grafik countplot dan cross tabulation. Khusus untuk `account_id_int` hanya dilakukan cross tabulation karena jumlah classnya yang sangat banyak. Lalu, ada fitur seperti `no_of_seats` dan `count_visited_city` yang juga bisa diperlakukan sebagai fitur kuantitatif, namun karena class dalam fitur-fitur tersebut sedikit, maka kami memprosesnya sebagai fitur categorical.","a9f7942d":"### Membuat Column `gender_m`","602c5a64":"Proses melakukan data preprocessing adalah memastikan data tersebut sudah bersih, bisa digunakan jika ingin dimasukkan ke machine learning. Salah satu yang penting adalah membuat fitur-fitur seperti melakukan ordinal encoding terhadap column gender.","46053ebb":"### Bagging Classifier Validation","7f478ea8":"### Disclaimer\n\nKelompok kami tidak menggunakan data yang berasal dari `hotel.csv`. Karena row tersebut akan hanya dimiliki bagi orang yang melakukan cross sell. Data tersebut tidak boleh ada di dalam training set karena akan membuat terjadi data leakage, suatu kejadian ketika data yang ada di masa depan digunakan untuk melakukan prediksi. Sehingga membuat orang menganggap memiliki performa model yang baik, namun sebenarnya tidak bisa digunakan secara umum.","f790b114":"### Voting Classifier Validation","0ee93492":"### Import Library","90f07535":"# CRISP - DM\n\nDalam melakukan pengerjaan lomba ini, kami menggunakan proses bernama `Cross-Industry Standard Process Model for Data Mining` atau yang sering disingkat sebagai `CRISP-DM`. `CRISP-DM` adalah suatu metodologi yang sudah digunakan secara umum untuk melakukan penambangan data. Metodologi tersebut terbagi menjadi enam tahap, yaitu:\n    \n    - Business Understanding\n    - Data Understanding\n    - Data Preparation\n    - Modeling\n    - Evaluation\n    - Deployment","3280275c":"## A. State-of-the-art: Stacking Classifier\n\nMetode *Stacking* merupakan salah satu metode *ensemble learning* yang berkaitan dengan menggabungkan hasil klasifikasi dengan menggunakan algoritma learning berbeda pada suatu dataset. [[4]](http:\/\/kt.ijs.si\/bernard_zenko\/papers\/02-dze_zen-icml02.pdf) Metode didasari atas teori *Bayesian learning* yang menetapkan bahwa untuk memaksimalkan akurasi prediksi, daripada hanya menggunakan model learning tunggal, idealnya menggunkaan semua model dalam ruang hipotesis.[[5]](http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.78.3420&rep=rep1&type=pdf)\n\nVoting merupakan salah satu metode yang biasa digunakan untuk menggabungkan hasil klasifikasi dari *base-classifier*. Pada fase pertama, beberapa *base-classifier* akan ditrain pada data. Pada fase kedua, prediksi final ditentukan oleh *meta-classifier* dari mayoritas prediksi di antara *base-classifier* pada fase pertama.","de1d78bc":"## C. Hyperparameter Tunning\n\nHyperparameter tunning dilakukan secara empiris sehingga didapatkan hyperparameter yang dapat mengoptimalkan skor.\n","4f9809aa":"### Membuat Column `service_class_business`","c597a39e":"## C. Feature Target","5bb8e2d3":"# 2. Data preprocessing","72c376a1":"### Extra Trees Classifier Validation","398341c6":"![Diagram CRISP-DM](https:\/\/drive.google.com\/uc?id=1QQz-M2iYNlwFnION6hI5IT-i_haqnlro)\n\nGambar 1. Diagram CRISP-DM [1]\n\n\n\n\n\n","ab9da038":"### Import Files","235b7840":"### Meta-classifier","25d2f915":"Fase Understand the Data dimulai dengan kami berusaha mengetahui data seperti apa yang kami miliki dan seperti apa kualitasnya. Data pada kenyataan di lapangan paling sering memiliki kualitas yang buruk, bisa karena banyak missing value, atau bahkan invalid sehingga kita tidak bisa mempercayai data tersebut. Sehingga pada fase ini, adalah fase penting untuk mengetahui data yang digunakan","5ee3daf6":"## B. Understand the Data","7becaa28":"## Membuat Column visited_city_id\n"}}