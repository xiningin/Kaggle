{"cell_type":{"7c0032a4":"code","9c24949c":"code","b40d0ded":"code","29f02eaa":"code","8b6bf73b":"code","ee515591":"code","c80db32a":"code","42b87a27":"code","8421899b":"code","ef2257b7":"code","672931ce":"code","730f8c2c":"code","3f36a29f":"code","7001652d":"code","55f63bbe":"code","d2745115":"code","7d032a44":"code","1a9bdfaf":"code","ff5074ef":"markdown","525b63cb":"markdown"},"source":{"7c0032a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9c24949c":"messages=pd.read_csv(\"..\/input\/sms-spam-collection-dataset\/spam.csv\",encoding = \"ISO-8859-1\")","b40d0ded":"messages.head()","29f02eaa":"import re\nimport nltk","8b6bf73b":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","ee515591":"stemmer=PorterStemmer()\n","c80db32a":"corpus=[]\nfor i in range(0,len(messages)):\n    review=re.sub('[^a-zA-Z]',' ',messages['v2'][i])\n    review=review.lower()\n    review=review.split()\n    review=[stemmer.stem(word) for word in review if not word in stopwords.words('english')]\n    review=' '.join(review)\n    corpus.append(review)","42b87a27":"print(corpus)","8421899b":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer=CountVectorizer(max_features=5000)\nX=vectorizer.fit_transform(corpus).toarray()","ef2257b7":"print(X)","672931ce":"y=pd.get_dummies(messages['v1'])\ny=y.iloc[:,1].values","730f8c2c":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","3f36a29f":"from sklearn.linear_model import LogisticRegression\n","7001652d":"LR=LogisticRegression()\nLR=LR.fit(X_train,y_train)\ny_pred=LR.predict(X_test)","55f63bbe":"from sklearn.metrics import accuracy_score","d2745115":"accuracy=accuracy_score(y_pred,y_test)\nprint(accuracy)","7d032a44":"from sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()\n","1a9bdfaf":"\nclassifier=classifier.fit(X_train,y_train)\ny_pred_NB=classifier.predict(X_test)\naccuracy_NB=accuracy_score(y_pred_NB,y_test)\nprint(accuracy_NB)","ff5074ef":"## Naive Bayes Classifier","525b63cb":"## Logistic Regression Classifier"}}