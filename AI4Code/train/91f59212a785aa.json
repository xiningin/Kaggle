{"cell_type":{"8d32969b":"code","6963b483":"code","1d88d523":"code","55f83536":"code","ed57ba47":"code","ee4fa80f":"code","d81d610b":"code","2e302e18":"code","a4057488":"code","61c87d90":"code","d596d7bb":"code","c78612c8":"code","89050f01":"code","96a2b4c5":"code","a25395ae":"code","63884574":"markdown","1400de1c":"markdown","3e03430a":"markdown","c3a73bbc":"markdown","92c93370":"markdown","098d6981":"markdown","71d908b4":"markdown","74a50e01":"markdown","5d23e25a":"markdown","a8d122ef":"markdown","3f377e67":"markdown","9ac95614":"markdown","ca341d85":"markdown","c7579f1a":"markdown","97aa9868":"markdown","b76f6bf2":"markdown"},"source":{"8d32969b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6963b483":"import math\nimport plotly.express as px\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt","1d88d523":"# Importing the Data:\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/test.csv\")\nsub_file = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","55f83536":"train.describe()","ed57ba47":"train = train.drop(['id'], axis=1)\ntest = test.drop(['id'], axis=1)","ee4fa80f":"## Bar Graph providing info about target values count:\nplt.figure(figsize=(8,6))\nsns.countplot(x='target', data=train, order=train['target'].value_counts().index);","d81d610b":"train['target'].value_counts()","2e302e18":"u = np.array([57497,21420,12593,8490])\nmylabels = [\"class 1\", \"class 2\", \"class 2\",\"Class 0\"]\nplt.pie(u, labels = mylabels)\nplt.show() ","a4057488":"# HeatMap to Check for any Missing Values:\nplt.figure(figsize=(16,9))\nsns.heatmap(train.isnull())","61c87d90":"train.describe().T\\\n        .style.bar(subset=['mean'], color=px.colors.qualitative.G10[0])\\\n        .background_gradient(subset=['std'], cmap='Greens')\\\n        .background_gradient(subset=['50%'], cmap='BuGn')","d596d7bb":"## Used Label Encoder to Encode the Target Column:\nlabel_encoder = LabelEncoder()\ntrain['target'] = label_encoder.fit_transform(train['target'])","c78612c8":"!pip install -U lightautoml\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task\nfrom sklearn.metrics import log_loss","89050f01":"%%time\ntabautoml = TabularUtilizedAutoML(timeout = 1500,\n                               task = Task('multiclass'),\n                               cpu_limit = 8,\n                               verbose=1,\n                               reader_params = {'num_threads':8,'advanced_roles': True,'learning_rate':0.15,'n_folds':15,'num_leaves':128,'n_jobs': 8,'cv':5,'random_state':42},\n                               tuning_params = {'max_tuning_iter': 50, 'max_tuning_time': 60},)","96a2b4c5":"## Here roles define the parameters to be given to AutoML\ntarget_col = 'target'\nroles = {\n    'target': target_col ,\n    'drop': ['id'],\n     }\nLAML_pred = tabautoml.fit_predict(train, roles = roles)","a25395ae":"LiAML_pred= tabautoml.predict(test)\npreds_df = LiAML_pred.data\npred = pd.DataFrame(preds_df)\n\n## Taking the Submission file Index column for creating Output File:\nLiAML_predi = pd.concat([sub_file['id'],pred],axis=1)\nLiAML_predi.columns=['id','Class_1','Class_2','Class_3','Class_4']\nLiAML_predi.to_csv('.\/LiAML_Output.csv',index=False)\nLiAML_predi.head(10)","63884574":"### Importing the libraries required to AutoML.","1400de1c":"### Fit the prediction for training the data:","3e03430a":"## Importing the Data:","c3a73bbc":"### So, we see from the above graph the there are no any missing values present.","92c93370":"## Importing the required Libraries:","098d6981":"### Notebook of Top 15% in Private Leaderboard","71d908b4":"### Drop Unwanted Columns:","74a50e01":"![](https:\/\/mykidstale.com\/wp-content\/uploads\/2016\/12\/PE-1704-01.jpg)","5d23e25a":"### From above graph we see as the mean is increased Standard Deviation Increases.","a8d122ef":"<hr style='border-top:1px solid yellow;'>\n<hr style='border-top:1px dotted green;'>\n<h1 style='color:Blue;text-align:center;'> <i> TABULAR PLAYGROUND SERIES MAY <\/i> <\/h1>\n<hr style='border-top:1px dotted orange;'>\n<hr style='border-top:1px dotted red;'>","3f377e67":"### Testing data sent to AutoML for predictions:","9ac95614":"# Encoding:","ca341d85":"# Data Analysis:","c7579f1a":"<h1 style='font-family:Calibri-body;background-color: #92a8d1;text-align:center;height:32px;'> << AUTOML ALGORITHM  >> <\/h1> ","97aa9868":"<hr style='border-top:1px solid brown;'>\n<h2 style='color:Green;text-align:center;'> <i> THANK YOU PLEASE DO UPVOTE <\/i> <\/h2>\n<hr style='border-top:1px solid blue;'> ","b76f6bf2":"### Tabular Specification provided to the AutoML as its Parameters."}}