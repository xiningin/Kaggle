{"cell_type":{"638b9e40":"code","27dcb978":"code","f59f682a":"code","94e12dc1":"code","1007d41c":"code","3ef2ed1b":"code","bddc1c6f":"code","9c4a2ea8":"code","5c766822":"code","1567548f":"code","53a682ad":"code","2c9c0c03":"code","a22dfd83":"code","3f8defcc":"code","0397a044":"code","4402f587":"code","d5f2ca1b":"code","39a0bfea":"code","3a68b970":"code","5f9ee2cd":"code","814b18c3":"code","90e3df60":"code","1859fea1":"code","b4218300":"code","145f3cce":"code","82bb650c":"markdown"},"source":{"638b9e40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27dcb978":"image_path = '\/kaggle\/input\/vocdataset\/VOCdevkit\/VOC2012\/JPEGImages\/'\nos.mkdir('\/kaggle\/working\/sketch-img')\nos.mkdir('\/kaggle\/working\/real-img-test')\nos.mkdir('\/kaggle\/working\/sketch-img-test')\nos.mkdir('\/kaggle\/working\/PaintsTensorFlowDraftModel\/')","f59f682a":"os.mkdir('\/kaggle\/working\/real-img')","94e12dc1":"os.mkdir('\/kaggle\/working\/model-save\/')","1007d41c":"len(os.listdir('\/kaggle\/working\/sketch-img'))","3ef2ed1b":"import cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef sketch(image):\n    #converting_image_to_grayscale\n    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    #blurring_image_to_remove_noise\n    img_blur=cv2.GaussianBlur(img_gray,(3,3),0)\n    #extracting_edges\n    edges=cv2.Canny(img_blur,10,80)\n    #applying_threshold_inverse\n    ret,mask=cv2.threshold(edges,50,255,cv2.THRESH_BINARY_INV)\n    return mask\nimport imageio\n\ncount = 0\nfor images in os.listdir(image_path):\n    img = str(image_path + '\/'+images)\n    s = imageio.imread(img)\n    save_image = '\/kaggle\/working\/sketch-img\/img_'+ str(count)+'.jpeg'\n    plt.imsave(save_image, sketch(s), cmap='gray', vmin=0, vmax=255)\n    count += 1 \n    if count == 3000:\n        break","bddc1c6f":"count = 0\nfor images in os.listdir(image_path):\n    if count > 3000 and count < 4000:\n        img = str(image_path + '\/'+images)\n        s = imageio.imread(img)\n        save_image = '\/kaggle\/working\/sketch-img-test\/img_'+ str(count)+'.jpeg'\n        plt.imsave(save_image, sketch(s), cmap='gray', vmin=0, vmax=255)\n    count += 1 \n    if count == 4000:\n        break","9c4a2ea8":"from PIL import Image\ncount = 0\nfor files in os.listdir(image_path):\n    if count > 3000 and count < 4000:\n        img = Image.open(image_path +'\/'+files)\n        path = '\/kaggle\/working\/real-img-test\/imgreal_'+str(count)+'.jpeg'\n        img.save(path)\n    count += 1\n    if count == 4000:\n        break","5c766822":"count = 0\nfor files in os.listdir(image_path):\n    img = Image.open(image_path +'\/'+files)\n    path = '\/kaggle\/working\/real-img\/imgreal_'+str(count)+'.jpeg'\n    img.save(path)\n    count += 1\n    if count == 3000:\n        break","1567548f":"plt.imshow(Image.open('\/kaggle\/working\/real-img-test\/imgreal_3540.jpeg'))","53a682ad":"plt.imshow(Image.open('\/kaggle\/working\/sketch-img-test\/img_3540.jpeg'))","2c9c0c03":"loadEpochs = 10\nimport tensorflow as tf\nimport cv2\nfrom glob import glob\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\n\nfrom tqdm import tqdm\n\n# edit by your path\n__SAVED_MODEL_PATH__ = \"\/kaggle\/working\/PaintsTensorFlowDraftModel\/\"\n","a22dfd83":"# hyperparameters.py\nbatch_steps = 0\n\ngf_dim = 64\ndf_dim = 64\nc_dim = 3\n\nlr = 1e-5\nbeta1 = 0.9\nbeta2 = 0.99\n\nl1_scaling = 100\nl2_scaling = 10\n\nepoch = 2\nbatch_size = 4\n\nlog_interval = 10\nsampling_interval = 200\nsave_interval = 4000\n\ntrain_image_datasets_path = \"\/kaggle\/working\/real-img\/*\"\ntrain_line_datasets_path = \"\/kaggle\/working\/sketch-img\/*\"\ntest_image_datasets_path = \"\/kaggle\/working\/real-img-test\/*\"\ntest_line_datasets_path = \"\/kaggle\/working\/sketch-img-test\/*\"","3f8defcc":"os.listdir(\"\/kaggle\/working\/sketch-img\/\")","0397a044":"# utils.py\ndef get_line(imgs):\n    def img_liner(img):\n        k = 3\n        kernal = np.ones((k, k), dtype=np.uint8)\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        dilated = cv2.dilate(gray, kernal, iterations=1)\n        diff = cv2.absdiff(dilated, gray)\n        img = 255 - diff\n        return img\n\n    lines = np.array([img_liner(l) for l in imgs])\n    return np.expand_dims(lines, 3)\n\n\ndef convert2f32(img):\n    img = img.astype(np.float32)\n    return (img \/ 127.5) - 1.0\n\n\ndef convert2uint8(img):\n    img = (img + 1) * 127.5\n    return img.astype(np.uint8)\n\n\ndef convertRGB(imgs):\n    imgs = np.asarray(imgs, np.uint8)\n    return np.array([cv2.cvtColor(img, cv2.COLOR_YUV2RGB) for img in imgs])\n\n\ndef mkdir(path):\n    try:\n        os.mkdir(path)\n    except FileExistsError:\n        pass\n\n\ndef initdir(model_name):\n    base = os.path.join(\"\/kaggle\/working\/\", model_name)\n    mkdir(base)\n    mkdir(os.path.join(base, \"board\"))\n    mkdir(os.path.join(base, \"image\"))","4402f587":"#SubNet.py\n__INITIALIZER__ = tf.random_normal_initializer(0., 0.02)\n__MOMENTUM__ = 0.9\n__EPSILON__ = 1e-5\n\n\ndef res_net_block_v2(inputs, filters):\n    with tf.name_scope(\"ResNetBlock\"):\n        shortcut = inputs\n        tensor = tf.keras.layers.BatchNormalization()(inputs)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n\n        tensor = tf.keras.layers.BatchNormalization()(tensor)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n        tensor = tf.keras.layers.add([shortcut, tensor])\n    return tensor\n\n\ndef GenConvBlock(inputs, filters, k, s, res_net_block=True, name=\"GenConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                        padding=\"SAME\", kernel_initializer=__INITIALIZER__)(inputs)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.LeakyReLU()(tensor)\n\n        return tensor\n\n\ndef GenUpConvBlock(inputs_a, inputs_b, filters, k, s, res_net_block=True, name=\"GenUpConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Concatenate(3)([inputs_a, inputs_b])\n        tensor = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                                 padding=\"SAME\", kernel_initializer=__INITIALIZER__)(tensor)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.ReLU()(tensor)\n\n        return tensor\n\n\nclass DisConvBlock(tf.keras.Model):\n    def __init__(self, filters, k, s, apply_bat_norm=True, name=None):\n        super(DisConvBlock, self).__init__(name=name)\n        initializer = tf.random_normal_initializer(0., 0.02)\n        filters = int(filters)\n        self.apply_bat_norm = apply_bat_norm\n        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s,\n                                           padding=\"SAME\", kernel_initializer=initializer)\n        if self.apply_bat_norm:\n            self.bn = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)\n\n        self.act = tf.keras.layers.LeakyReLU(alpha=0.2)\n\n    def call(self, inputs, training):\n        tensor = self.conv(inputs)\n\n        if self.apply_bat_norm:\n            tensor = self.bn(tensor, training=training)\n\n        tensor = self.act(tensor)\n        return tensor\n\n\ndef tf_int_round(num):\n    return tf.cast(tf.round(num), dtype=tf.int32)\n\n\nclass resize_layer(tf.keras.layers.Layer):\n    def __init__(self, size=(512, 512), **kwargs, ):\n        super(resize_layer, self).__init__(**kwargs)\n        (self.height, self.width) = size\n\n    def build(self, input_shape):\n        super(resize_layer, self).build(input_shape)\n\n    def call(self, x, method=\"nearest\"):\n        height = 512\n        width = 512\n\n        if method == \"nearest\":\n            return tf.image.resize_nearest_neighbor(x, size=(height, width))\n        elif method == \"bicubic\":\n            return tf.image.resize_bicubic(x, size=(height, width))\n        elif method == \"bilinear\":\n            return tf.image.resize_bilinear(x, size=(height, width))\n\n    def get_output_shape_for(self, input_shape):\n        return (self.input_shape[0], 512, 512, 3)","d5f2ca1b":"#PaintsTensorflow\ndef Generator(inputs_size=None, res_net_block=True, name=\"PaintsTensorFlow\"):\n    inputs_line = tf.keras.Input(shape=[inputs_size, inputs_size, 1], dtype=tf.float32, name=\"inputs_line\")\n    inputs_hint = tf.keras.Input(shape=[inputs_size, inputs_size, 3], dtype=tf.float32, name=\"inputs_hint\")\n    tensor = tf.keras.layers.Concatenate(3)([inputs_line, inputs_hint])\n\n    e0 = GenConvBlock(tensor,gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"E0\")  # 64\n    e1 = GenConvBlock(e0, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"E1\")\n    e2 = GenConvBlock(e1, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"E2\")\n    e3 = GenConvBlock(e2, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"E3\")\n    e4 = GenConvBlock(e3, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"E4\")\n    e5 = GenConvBlock(e4, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"E5\")\n    e6 = GenConvBlock(e5, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"E6\")\n    e7 = GenConvBlock(e6, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"E7\")\n    e8 = GenConvBlock(e7, gf_dim * 8, 3, 1, res_net_block=res_net_block, name=\"E8\")\n\n    d8 = GenUpConvBlock(e7, e8, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"D8\")\n    d7 = GenConvBlock(d8, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"D7\")\n    d6 = GenUpConvBlock(e6, d7, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"D6\")\n    d5 = GenConvBlock(d6, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"D5\")\n    d4 = GenUpConvBlock(e4, d5, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"D4\")\n    d3 = GenConvBlock(d4, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"D3\")\n    d2 = GenUpConvBlock(e2, d3, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"D2\")\n    d1 = GenConvBlock(d2, gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"D1\")\n\n    tensor = tf.keras.layers.Concatenate(3)([e0, d1])\n    outputs = tf.keras.layers.Conv2D(c_dim, kernel_size=3, strides=1, padding=\"SAME\",\n                                     use_bias=True, name=\"output\", activation=tf.nn.tanh,\n                                     kernel_initializer=tf.random_normal_initializer(0., 0.02))(tensor)\n\n    inputs = [inputs_line, inputs_hint]\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n    return model\n\nclass Discriminator(tf.keras.Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.h0 = DisConvBlock(df_dim \/ 2, 4, 2)\n        self.h1 = DisConvBlock(df_dim \/ 2, 3, 1)\n        self.h2 = DisConvBlock(df_dim * 1, 4, 2)\n        self.h3 = DisConvBlock(df_dim * 1, 3, 1)\n        self.h4 = DisConvBlock(df_dim * 2, 4, 2)\n        self.h5 = DisConvBlock(df_dim * 2, 3, 1)\n        self.h6 = DisConvBlock(df_dim * 4, 4, 2)\n        self.flatten = tf.keras.layers.Flatten()\n        self.last = tf.keras.layers.Dense(1, activation=\"linear\", kernel_initializer=tf.initializers.he_normal())\n\n#     @tf.contrib.eager.defun\n    def call(self, inputs, training):\n        tensor = self.h0(inputs, training)\n        tensor = self.h1(tensor, training)\n        tensor = self.h2(tensor, training)\n        tensor = self.h3(tensor, training)\n        tensor = self.h4(tensor, training)\n        tensor = self.h5(tensor, training)\n        tensor = self.h6(tensor, training)\n        tensor = self.flatten(tensor)  # (?,16384)\n        tensor = self.last(tensor)\n        return tensor","39a0bfea":"def loadImage(imagePath, linePath, isTrain = 'True'):\n#     print (imagePath)\n#     print (linePath)\n    image = tf.io.read_file(imagePath)\n    image = tf.image.decode_jpeg(image, channels=3)\n#     print (image.shape)\n    line = tf.io.read_file(linePath)\n    line = tf.image.decode_jpeg(line, channels=1)   # png read\n#     print (line.shape)\n    image = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n    line = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.BICUBIC)\n    image = convert2float(image)\n    line = convert2float(line)\n    image, line, hint = tf.py_function(_preprocess,\n                                       [np.float32(image), np.float32(line), str(isTrain)],\n                                       [tf.float32, tf.float32, tf.float32])\n    return image, line, hint\nimport cv2\ndef _preprocess(image, line, isTrain):\n    if isTrain == 'True':\n        if np.random.rand() < 0.5:\n            image = cv2.flip(np.float32(image), 0)\n            line = cv2.flip(np.float32(line), 0)\n#             print (line.shape)\n#             line = np.expand_dims(line, axis=3)\n        if np.random.rand() < 0.5:\n            image = cv2.flip(np.float32(image), 1)\n            line = cv2.flip(np.float32(line), 1)\n#             line = np.expand_dims(line, axis=3)\n#             print (line.shape)\n    return image, line, _buildHint_resize(image)\n\ndef _buildHint_resize(image):\n    plt.imshow(image)\n#     print ('yes')\n    random = np.random.rand\n    hint = np.ones_like(image)\n    hint += 1\n    leak_count = np.random.randint(16, 120)\n    if random() < 0.4:\n        leak_count = 0\n    elif random() < 0.7:\n        leak_count = np.random.randint(2, 16)\n    # leak position\n    x = np.random.randint(1, image.shape[0] - 1, leak_count)\n    y = np.random.randint(1, image.shape[1] - 1, leak_count)\n    def paintCel(i):\n        color = image[x[i]][y[i]]\n        hint[x[i]][y[i]] = color\n        if random() > 0.5:\n            hint[x[i]][y[i] + 1] = color\n            hint[x[i]][y[i] - 1] = color\n        if random() > 0.5:\n            hint[x[i] + 1][y[i]] = color\n            hint[x[i] - 1][y[i]] = color\n    for i in range(leak_count):\n        paintCel(i)\n#     print ('no')\n#     plt.imshow(hint)\n#     print (hint.shape)\n    return hint\n\ndef convert2float(image):\n    image = tf.cast(image, tf.float32)\n    image = (image \/ 127.5) - 1\n    return image\n","3a68b970":"#Datasets.py\nimport cv2\nclass Datasets:\n    def __init__(self, prefetch=-1, batch_size=1, shuffle=False):\n        self.prefetch = prefetch\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n\n    def _preprocess(self, image, line, training = 'True'):\n        if training == 'True':\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 0)\n                line = cv2.flip(np.float32(line), 0)\n#                 line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 1)\n                line = cv2.flip(np.float32(line), 1)\n#                 line = np.expand_dims(line, 3)\n\n        return image, line, self._buildHint_resize(image)\n\n    def _buildHint_resize(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n\n        return hint\n\n    def convert2float(self, image):\n        image = tf.cast(image, tf.float32)\n        image = (image \/ 127.5) - 1\n        return image\n\n    def __line_threshold(self, line):\n        if np.random.rand() < 0.3:\n            line = np.reshape(line, newshape=(512, 512))\n            _, line = cv2.threshold(line, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            line = np.reshape(line, newshape=(512, 512, 1))\n        return line\n\n    def loadImage(self, imagePath, linePath, isTrain='True'):\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n\n        image, line, hint = tf.py_function(self._preprocess,\n                                       [np.float32(image), np.float32(line), str(isTrain)],\n                                       [tf.float32, tf.float32, tf.float32])\n\n        return image, line, hint\n\n    def buildDataSets(self):\n        def build_dataSets(image, line, shuffle=False, isTrain=False):\n            image = glob(image)\n            image.sort()\n            line = glob(line)\n            line.sort()\n\n            if shuffle is False and isTrain is False:\n                image.reverse()\n                line.reverse()\n\n            batch_steps = int(len(line) \/ self.batch_size)\n            datasets = tf.data.Dataset.from_tensor_slices((image, line))\n#             datasets = datasets.map(lambda x, y: self.loadImage(x, y, isTrain))\n            image_data = []\n            line_data = []\n            hint_data = []\n            for ele in datasets:\n                x, y ,z = self.loadImage(ele[0], ele[1], str(isTrain))\n                image_data.append(x)\n                line_data.append(y)\n                hint_data.append(z)\n#             datasets = datasets.batch(self.batch_size)\n            image_data_batch = []\n            line_data_batch = []\n            hint_data_batch = []\n            for i in range(0, len(image_data), self.batch_size):\n                image_data_batch.append(image_data[i:i+self.batch_size])\n                line_data_batch.append(line_data[i:i+self.batch_size])\n                hint_data_batch.append(hint_data[i:i+self.batch_size])\n\n            return image_data_batch, line_data_batch, hint_data_batch\n\n        testDatasets = build_dataSets(test_image_datasets_path,\n                                      test_line_datasets_path,\n                                      shuffle=False, isTrain=False)\n\n        trainDatasets = build_dataSets(train_image_datasets_path,\n                                       train_line_datasets_path,\n                                       shuffle=False, isTrain=True)\n\n        return trainDatasets, testDatasets\n\nclass Datasets_512(Datasets):\n    def __init__(self ,batch_size):\n        self.batch_size = batch_size\n        super().__init__(self, batch_size = self.batch_size)\n    def _flip(self, image, line, training):\n        if training:\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 0)\n                line = cv2.flip(line, 0)\n                line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 1)\n                line = cv2.flip(line, 1)\n                line = np.expand_dims(line, 3)\n\n        return image, line\n\n    def _buildHint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 128)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n\n    def loadImage(self, imagePath, linePath, train):\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image_128 = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line_128 = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n        image_128 = self.convert2float(image_128)\n        line_128 = self.convert2float(line_128)\n\n        hint_128 = tf.py_function(self._buildHint,\n                                  [image_128],\n                                  tf.float32)\n\n        hint_128.set_shape(shape=image_128.shape)\n        hint = tf.image.resize(hint_128, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        return line_128, hint_128, image, line, hint","5f9ee2cd":"#PaintsTensorflowTraining\nclass PaintsTensorFlowTrain:\n    def __init__(self, model_name=\"PaintsTensorFlow\"):\n        self.data_sets = Datasets_512(batch_size=batch_size)\n        self.model_name = \"{}\".format(model_name)\n        initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n        self.ckpt_path = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n        self.ckpt_prefix = os.path.join(self.ckpt_path, \"model_GS:{}\")\n\n#         self.generator_128 =  tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        self.generator_512 = Generator(res_net_block=False)\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n\n        self.check_point = tf.train.Checkpoint(generator_512=self.generator_512,\n                                               optimizer=self.optimizer,\n                                               globalSteps=self.global_steps,\n                                               epochs=self.epochs)\n\n#     def __loging(self, name, scalar):\n#         with tf.contrib.summary.always_record_summaries():\n#             tf.contrib.summary.scalar(name, scalar)\n\n    def __loss(self, output, target):\n        loss = tf.reduce_mean(tf.abs(target - output))\n        return loss\n\n    def __pred_image(self, model, image, line, hint, draft, epoch=None):\n        gs = self.global_steps.numpy()\n        predImage = model.predict([line, draft])\n        file_name = \".\/ckpt\/{}\/image\/{}.jpg\".format(self.model_name, gs)\n\n        if epoch is not None:\n            loss = self.__loss(predImage, image)\n#             self.__loging(\"Sample_LOSS\", loss)\n            loss = \"{:0.05f}\".format(loss).zfill(7)\n            print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, self.global_steps.numpy(), loss))\n            file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, gs, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        lineImage = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([lineImage, hint, draft, predImage, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n    def __draft_image(self, line_128, hint_128):\n        draft = self.generator_128.predict([line_128, hint_128])\n        draft = tf.image.resize(draft, size=(512, 512),\n                                       method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        return draft\n\n    def training(self, loadEpochs=0):\n        train_sets, test_sets = self.data_sets.buildDataSets()\n        print (train_sets, test_sets)\n#         log = self.__loging\n\n        self.check_point.restore(tf.train.latest_checkpoint(self.ckpt_path.format(loadEpochs)))\n\n        if self.global_steps.numpy() == 0:\n            self.check_point.save(file_prefix=self.ckpt_prefix.format(0, 0))\n            print(\"------------------------------SAVE_INIT-------------------------------------\")\n\n        for epochss in range(epoch):\n            print(\"GS: \", self.global_steps.numpy())\n\n            for line_128, hint_128, image, line, hint in tqdm(train_sets, total=batch_steps):\n                draft = self.__draft_image(line_128, hint_128)\n\n                with tf.GradientTape() as tape:\n                    genOut = self.generator_512(inputs=[line, draft], training=True)\n                    loss = self.__loss(genOut, image)\n\n                # Training\n                gradients = tape.gradient(loss, self.generator_512.variables)\n                self.optimizer.apply_gradients(zip(gradients, self.generator_512.variables),\n                                               global_step=self.global_steps)\n                # Loging\n                gs = self.global_steps.numpy()\n                if gs % log_interval == 0:\n                    log(\"LOSS\", loss)\n                    if gs % sampling_interval == 0:\n                        # test image Save\n                        for line_128, hint_128, image, line, hint in test_sets.take(1):\n                            draft = self.__draft_image(line_128, hint_128)\n                            self.__pred_image(self.generator_512, image, line, hint, draft, self.epochs.numpy())\n\n                    if gs % save_interval == 0:\n                        self.check_point.save(file_prefix=self.ckpt_prefix.format(self.epochs.numpy(), gs))\n                        print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n                              .format(self.epochs.numpy(), gs))\n\n            self.check_point.save(file_prefix=self.ckpt_prefix.format(self.epochs.numpy(), self.global_steps.numpy()))\n            self.epochs = self.epochs + 1\n\n        for line_128, hint_128, image, line, hint in test_sets.take(1):\n            hint = hint.numpy()\n            draft = self.__draft_image(line_128, hint_128)\n            self.__pred_image(self.generator_512, image, line, hint, draft, self.epochs.numpy())\n\n        self.generator_512.summary()\n        print(self.global_steps)\n\n        save_path = \"\/kaggle\/working\/model-save\" + self.model_name + \"\/{}.h5\".format(self.generator_512.name)\n        self.generator_512.save(save_path, include_optimizer=False)  # for keras Model\n        save_path = tf.keras.models.save_model(self.generator_512, save_path)  # saved_model\n        print(\"saved_model path = {}\".format(save_path))\n        print(\"------------------------------Training Done-------------------------------------\")","814b18c3":"#PaintsTensorflowDraftModel\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\nimport time\nclass PaintsTensorFlowDraftModelTrain:\n    def __init__(self, model_name=\"PaintsTensorFlowDraftModel\"):\n        self.data_sets = Datasets(batch_size=4)\n        self.model_name = model_name\n        # utils.initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n\n        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n        self.ckptPath = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n        self.ckptPrefix = os.path.join(self.ckptPath, \"model_GS:{}\")\n\n        self.generator = Generator(name=\"PaintsTensorFlowDraftNet\")\n        self.discriminator = Discriminator()\n\n#         self.logWriter = tf.contrib.summary.create_file_writer(\".\/ckpt\/{}\/board\/log\".format(self.model_name))\n#         self.logWriter.set_as_default()\n\n        self.check_point = tf.train.Checkpoint(generator=self.generator,\n                                               genOptimizer=self.generator_optimizer,\n                                               disOptimizer=self.discriminator_optimizer,\n                                               discriminator=self.discriminator,\n                                               globalSteps=self.global_steps,\n                                               epochs=self.epochs)\n\n    def __discriminator_loss(self, real, fake):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.real_loss = SCE(tf.ones_like(real), logits=real)\n        self.fake_loss = SCE(tf.zeros_like(fake), logits=fake)\n        loss = self.real_loss + self.fake_loss\n        return loss\n\n    def __generator_loss(self, disOutput, output, target):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.gan_loss = SCE(tf.ones_like(disOutput), logits=disOutput)\n        self.image_loss = tf.reduce_mean(tf.abs(target - output)) * l1_scaling\n        loss = self.image_loss + self.gan_loss\n        return loss\n\n    def __pred_image(self, model, image, line, hint, epoch=None):\n        global_steps = self.global_steps.numpy()\n        pred_image = model.predict([line, hint])\n\n        zero_hint = tf.ones_like(hint)\n        zero_hint += 1\n        pred_image_zero = model.predict([line, zero_hint])\n\n        dis_fake = self.discriminator(pred_image, training=False)\n        loss = self.__generator_loss(dis_fake, pred_image, image)\n\n#         self.__loging(\"Sample_LOSS\", loss)\n        loss = \"{:0.05f}\".format(loss).zfill(7)\n        print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, global_steps, loss))\n        file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, global_steps, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        line_image = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([line_image, hint, pred_image_zero, pred_image, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        #use plt.save for viasualization\n        # tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n#     def __loging(self, name, scalar):\n#         with tf.contrib.summary.always_record_summaries():\n#             tf.contrib.summary.scalar(name, scalar)\n\n    def __check_point_save(self):\n        file_prefix = self.ckptPrefix.format(self.epochs.numpy(), self.global_steps.numpy())\n        self.check_point.save(file_prefix=file_prefix)\n\n    def training(self, loadEpochs=0):\n        train_sets, test_sets = self.data_sets.buildDataSets()\n        t = time.time()\n        batch_steps = 750\n        def fast_fetch(size, Traindata):        \n            if (size==(4,128,128,3)):\n                x=np.zeros(size)\n                print(x.shape)\n                for i in range(0,4):\n                    t = Traindata[i]\n                    x[i] = np.asarray(t, np.float32)        \n                print (x.shape)\n                return x\n            else:\n                x=np.zeros(size)\n                print(x.shape)\n                for i in range(4):\n                    t = Traindata[i]\n                    x[i,:,:,0] = np.asarray(t,np.float32).reshape(128,128)\n                    plt.imshow(x[i,:,:,0])\n                return x\n            \n        for epoch in range(loadEpochs):\n\n            print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n            for batch in range(batch_steps):\n                print (batch)\n                t1 = time.time()\n                print(\"Time of for loop {}\".format(t1-t))\n                \n                \n                \n                \n                \n                image = tf.convert_to_tensor(fast_fetch((4,128,128,3), train_sets[0][batch]), dtype=tf.float32, dtype_hint=None, name=None)\n                t2 = time.time()\n                print(\"Time of tensorlayer {}\".format(t2-t1))\n                line = tf.convert_to_tensor(fast_fetch((4,128,128,1), train_sets[1][batch]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint = tf.convert_to_tensor(fast_fetch((4,128,128,3), train_sets[2][batch]), dtype=tf.float32, dtype_hint=None, name=None)\n                \n                with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n                    pred_image = self.generator(inputs=[line, hint], training=True)\n                    dis_real = self.discriminator(inputs=image, training=True)\n                    dis_fake = self.discriminator(inputs=pred_image, training=True)\n                    generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n                    discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n                discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n                generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n                self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n                self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables))\n                gs = self.global_steps.numpy()\n\n                print ('LOSS_G {}\\nLOSS_G_Image {}\\nLOSS_G_GAN {} \\nLOSS_D {}\\nLOSS_D_Real {}\\nLOSS_D_Fake {}'.format(generator_loss,self.image_loss,self.gan_loss,discriminator_loss\n                                                                                                                     ,self.real_loss,self.fake_loss))\n#                     log(\"LOSS_G\", generator_loss)\n#                     log(\"LOSS_G_Image\", self.image_loss)\n#                     log(\"LOSS_G_GAN\", self.gan_loss)\n#                     log(\"LOSS_D\", discriminator_loss)\n#                     log(\"LOSS_D_Real\", self.real_loss)\n#                     log(\"LOSS_D_Fake\", self.fake_loss)\n                    \n#                     if gs % sampling_interval == 0:\n#                         for image, line, hint in test_sets[:]:\n#                             self.__pred_image(self.generator, image, line, hint, self.epochs.numpy())\n\n                if gs % save_interval == 0:\n                    print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\".format(self.epochs.numpy(), gs))\n            self.epochs = self.epochs + 1\n            \n        self.generator.summary()\n    def save_model(self):\n        save_path = \"\/kaggle\/working\/model-save\/{}.h5\".format(self.generator.name)\n        self.generator.save(save_path, include_optimizer=False)  # for keras Model\n#         save_path = tf.contrib.saved_model.save_keras_model(self.generator, \".\/saved_model\")\n        \n\n                \n\n#         log = self.__loging\n\n#         self.check_point.restore(tf.train.latest_checkpoint(self.ckptPath.format(loadEpochs)))\n\n#         for epoch in range(10):\n#             print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n\n#             for image, line, hint in tqdm(train_sets, total=batch_steps):\n#                 # get loss\n#                 with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n\n#                     pred_image = self.generator(inputs=[line, hint], training=True)\n\n#                     dis_real = self.discriminator(inputs=image, training=True)\n#                     dis_fake = self.discriminator(inputs=pred_image, training=True)\n\n#                     generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n#                     discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n\n#                 # Gradients\n#                 discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n#                 generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n\n#                 self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n#                 self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables),\n#                                                          global_step=self.global_steps)\n#                 gs = self.global_steps.numpy()\n\n#                 if gs % log_interval == 0:\n#                     log(\"LOSS_G\", generator_loss)\n#                     log(\"LOSS_G_Image\", self.image_loss)\n#                     log(\"LOSS_G_GAN\", self.gan_loss)\n#                     log(\"LOSS_D\", discriminator_loss)\n#                     log(\"LOSS_D_Real\", self.real_loss)\n#                     log(\"LOSS_D_Fake\", self.fake_loss)\n\n#                     if gs % sampling_interval == 0:\n#                         for image, line, hint in test_sets.take(1):\n#                             self.__pred_image(self.generator, image, line, hint, self.epochs.numpy())\n\n#                     if gs % save_interval == 0:\n#                         self.__check_point_save()\n#                         print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n#                               .format(self.epochs.numpy(), gs))\n#             self.epochs = self.epochs + 1\n\n#         self.generator.summary()\n#         save_path = \"'\/kaggle\/working\/model-save\/'\" + self.model_name + \"\/{}.h5\".format(self.generator.name)\n#         self.generator.save(save_path, include_optimizer=False)  # for keras Model\n#         save_path = tf.contrib.saved_model.save_keras_model(self.generator, \".\/saved_model\")  # saved_model\n#         print(\"saved_model path = {}\".format(save_path))\n\n#         print(\"------------------------------Training Done-------------------------------------\")","90e3df60":"model = PaintsTensorFlowDraftModelTrain()","1859fea1":"model.training(loadEpochs=1)","b4218300":"model.save_model()","145f3cce":"os.listdir('\/kaggle\/working\/model-save')","82bb650c":"**converting color image to sketch**"}}