{"cell_type":{"693bdbd6":"code","c094e1e4":"code","4ed907b8":"code","42efc473":"code","bbe4542e":"code","9d800ff8":"code","402765b3":"markdown","840d7145":"markdown","4266fb24":"markdown","84f1bab7":"markdown","ada33231":"markdown","20f2a9ff":"markdown","bb1f241a":"markdown","87347051":"markdown"},"source":{"693bdbd6":"from sklearn import model_selection, metrics\n# model_selection for model optimizing, metrics for calculating performance\nfrom sklearn.preprocessing import MinMaxScaler\n# minmaxscaler for preprocessing input data\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","c094e1e4":"class DataSet:\n    def __init__(self, X, y, nb_classes, scaling=True, test_size=0.2, random_state=0):\n        # X = input, y = output, number of classes = nb_classes\n        \"\"\"\n        X is originally vector. Hence, it will be transformed\n        to 2D images with a channel (i.e, 3D).\n        \"\"\"\n        self.X = X\n        self.add_channels()\n        X = self.X\n        \n        # the data, shuffled and split between train and test sets\n        X_train, X_test, y_train, y_test = model_selection.train_test_split(\n            X, y, test_size=0.2, random_state=random_state)\n\n        print(X_train.shape, y_train.shape)\n\n        # some images has integer type, we make them all float\n        X_train = X_train.astype('float32')\n        X_test = X_test.astype('float32')\n\n        if scaling:\n            # scaling to have (0, 1) for each feature (each pixel) in only X_train\n            scaler = MinMaxScaler()\n            n = X_train.shape[0]\n            X_train = scaler.fit_transform(\n                X_train.reshape(n, -1)).reshape(X_train.shape)\n            # X_test just follows X_train standard\n            n = X_test.shape[0]\n            X_test = scaler.transform(\n                X_test.reshape(n, -1)).reshape(X_test.shape)\n            self.scaler = scaler\n\n        print('X_train shape:', X_train.shape)\n        print(X_train.shape[0], 'train samples')\n        print(X_test.shape[0], 'test samples')\n\n        # convert class vectors to binary class matrices\n        Y_train = np_utils.to_categorical(y_train, nb_classes)\n        Y_test = np_utils.to_categorical(y_test, nb_classes)\n\n        self.X_train, self.X_test = X_train, X_test\n        self.Y_train, self.Y_test = Y_train, Y_test\n        self.y_train, self.y_test = y_train, y_test\n        # self.input_shape = input_shape\n\n    def add_channels(self):\n        X = self.X\n\n        if len(X.shape) == 3:\n            N, img_rows, img_cols = X.shape\n\n            if K.image_dim_ordering() == 'th':\n                X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n                input_shape = (1, img_rows, img_cols)\n            else:\n                X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n                input_shape = (img_rows, img_cols, 1)\n        else:\n            input_shape = X.shape[1:]  # channel is already included.\n\n        self.X = X\n        self.input_shape = input_shape\n","4ed907b8":"class CNN(Model):\n    def __init__(model, nb_classes, in_shape=None):\n        super().__init__()\n        model.nb_classes = nb_classes\n        model.in_shape = in_shape\n        model.build_model()\n        super().__init__(model.x, model.y)\n        model.compile()\n\n    def build_model(model):\n        nb_classes = model.nb_classes\n        in_shape = model.in_shape\n\n        x = Input(in_shape)\n\n        h = Conv2D(32, kernel_size=(3, 3), activation='relu',\n                   input_shape=in_shape)(x)\n        h = Conv2D(64, (3, 3), activation='relu')(h)\n        h = MaxPooling2D(pool_size=(2, 2))(h)\n        h = Dropout(0.25)(h)\n        h = Flatten()(h)\n        z_cl = h\n\n        h = Dense(128, activation='relu')(h)\n        h = Dropout(0.5)(h)\n        z_fl = h\n\n        y = Dense(nb_classes, activation='softmax', name='preds')(h)\n\n        model.cl_part = Model(x, z_cl)\n        model.fl_part = Model(x, z_fl)\n\n        model.x, model.y = x, y\n\n    def compile(model):\n        Model.compile(model, loss='categorical_crossentropy',\n                      optimizer='adadelta', metrics=['accuracy'])\n","42efc473":"# we can skip this code, just for visualization\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nimport matplotlib\n\ndef save_history_history(fname, history_history, fold=''):\n    np.save(os.path.join(fold, fname), history_history)\n\n\ndef load_history_history(fname, fold=''):\n    history_history = np.load(os.path.join(fold, fname)).item(0)\n    return history_history\n\n\ndef plot_acc(history, title=None):\n    # summarize history for accuracy\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['acc'])\n    plt.plot(history['val_acc'])\n    if title is not None:\n        plt.title(title)\n    plt.ylabel('Accracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Training data', 'Validation data'], loc=0)\n    # plt.show()\n\n\ndef plot_loss(history, title=None):\n    # summarize history for loss\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    if title is not None:\n        plt.title(title)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Training data', 'Validation data'], loc=0)\n    # plt.show()\n\n\ndef plot_history(history):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 2, 1)\n    plot_acc(history)\n    plt.subplot(1, 2, 2)\n    plot_loss(history)\n\n    \ndef plot_loss_acc(history):\n    plot_loss(history, '(a) Loss trajectory')\n    plt.show()            \n    plot_acc(history, '(b) Accracy trajectory')\n    plt.show()\n    \n    \ndef plot_acc_loss(history):\n    plot_acc(history, '(a) Accracy trajectory')\n    plt.show()\n    plot_loss(history, '(b) Loss trajectory')\n    plt.show()           \n\nimport datetime\nimport uuid\nimport os\n\n\ndef unique_filename(type='uuid'):\n    if type == 'datetime':\n        filename = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n    else:  # type == \"uuid\"\n        filename = str(uuid.uuid4())\n    return filename\n\n\ndef makenewfold(prefix='output_', type='datetime'):\n    suffix = unique_filename('datetime')\n    foldname = 'output_' + suffix\n    os.makedirs(foldname)\n    return foldname","bbe4542e":"class Machine():\n    def __init__(self, X, y, nb_classes=2, fig=True):\n        self.nb_classes = nb_classes\n        self.set_data(X, y)\n        self.set_model()\n        self.fig = fig\n\n    def set_data(self, X, y):\n        nb_classes = self.nb_classes\n        self.data = DataSet(X, y, nb_classes)\n        print('data.input_shape', self.data.input_shape)\n\n    def set_model(self):\n        nb_classes = self.nb_classes\n        data = self.data\n        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)\n        # cnn_lenet(nb_classes=nb_classes, in_shape=data.input_shape)\n\n    def fit(self, epochs=10, batch_size=128, verbose=1):\n        data = self.data\n        model = self.model\n\n        history = model.fit(data.X_train, data.Y_train, batch_size=batch_size, epochs=epochs,\n                            verbose=verbose, validation_data=(data.X_test, data.Y_test))\n        return history\n\n    \n    # performance evaluation\n    def run(self, epochs=100, batch_size=128, verbose=1):\n        data = self.data\n        model = self.model\n        fig = self.fig\n\n        history = self.fit(epochs=epochs,\n                           batch_size=batch_size, verbose=verbose)\n\n        score = model.evaluate(data.X_test, data.Y_test, verbose=0)\n\n        print('Confusion matrix')\n        Y_test_pred = model.predict(data.X_test, verbose=0)\n        y_test_pred = np.argmax(Y_test_pred, axis=1)\n        print(metrics.confusion_matrix(data.y_test, y_test_pred))\n\n        print('Test score:', score[0])\n        print('Test accuracy:', score[1])\n\n        # Save results\n        suffix = unique_filename('datatime')\n        foldname = 'output_' + suffix\n        os.makedirs(foldname)\n        save_history_history(\n            'history_history.npy', history.history, fold=foldname)\n        model.save_weights(os.path.join(foldname, 'dl_model.h5'))\n        print('Output results are saved in', foldname)\n          \n        if fig:\n            skeras.plot_acc_loss(history)\n\n        self.history = history\n\n        return foldname","9d800ff8":"from keras import datasets\nimport keras\nassert keras.backend.image_data_format() == 'channels_last'\n\n\n\nclass Machine1(Machine):\n    def __init__(self):\n        (X, y), (x_test, y_test) = datasets.cifar10.load_data()\n        super().__init__(X, y, nb_classes=10)\n\n\ndef main():\n    m = Machine1()\n    m.run()\n\nif __name__ == '__main__':\n    main()","402765b3":"<a id=\"three\"><\/a>\n# 3. Modeliing","840d7145":"<a id=\"four\"><\/a>\n# 4. Training & Evaluation","4266fb24":"<a id=\"two\"><\/a>\n# 2. Prepare Data","84f1bab7":"* We use **Lenet neural network** from Yann LeCun, a rectangular box needs to handel Channel \n\n\n![12.PNG](attachment:12.PNG)\n* **Maxpooling :** pick biggest one\n![244.PNG](attachment:244.PNG)\n* **Dropout(P) :** Send a signal with P probability","ada33231":"<a id=\"one\"><\/a>\n# 1. Import Libraries","20f2a9ff":"# Simple CNN\n\nCNN (Convolutional Neural Network)\n* **CNN (Convolutional Neural Network):** A **CNN** is an artificial neural network with **convolution filter**\n* **Convolution Filter(kernel):** is finding Feature in Filter size\n* **Stride** : how many will you move ?\n* **CNN (Convolutional Neural Network)** is most commonly applied to analyzing visual imagery\n* Our **CNN** is focusing on classification which ficture is, when **CNN** gets ficture of 10 classes (CIFAR-10)\n* We are using Keras module\n\n![23.PNG](attachment:23.PNG)\n\n<hr>\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful !\n\n<hr>\n\n## Content\n1. [Import Libraries](#one)\n2. [Prepare Data](#two)\n3. [Modeling](#three)\n4. [Training & Evaluation](#four)\n\n<hr>","bb1f241a":"* CNN is diffent from DNN with 2 things  \n    1. First : CNN doesn't have to make 1-dimention vector  \n    ![123.PNG](attachment:123.PNG)\n    2. Second : CNN needs to put channel data ex) RGB - 3, B&W - 1\n    \n    \n* 60000 data ( 50000 for training, 10000 for test)\n* 32 * 32 * 3 (RGB image),(each pixel can have 0~255 value)\n* 0 ~ 9 (10 classes)\n* https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html","87347051":"## Reference\n* Coding chef 3 minute deep learning  -(https:\/\/github.com\/jskDr\/keraspp\/blob\/master\/ex4_2_cnn_cifar10_cl.py)\n* [Simple DNN](https:\/\/www.kaggle.com\/gigunlee\/beginner-simple-dnn)"}}