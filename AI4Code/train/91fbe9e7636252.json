{"cell_type":{"bf666185":"code","2bd50dc6":"code","e8c4d1dd":"code","b42d5e15":"code","463dbc52":"code","19b66d04":"code","31cbecc6":"code","884347be":"code","8aeee1b9":"code","edf51bf3":"code","fdbe3bd3":"code","61dfdf60":"code","da176e36":"code","96db4c82":"code","e2ec3981":"code","5fb8f321":"code","6169a413":"code","74baff62":"code","1a667757":"code","715e9c49":"code","62e2cbbb":"code","07620663":"code","0fa12bec":"code","d910ece9":"code","eb492c80":"code","8145fdf3":"code","d0a58289":"code","fae63722":"code","1d0bb469":"code","d5e6a423":"code","c992ccfe":"code","7efc6b83":"code","55ead026":"code","efc86cb2":"code","e9d2be63":"code","6e841140":"code","60d061f7":"markdown","1a3408c0":"markdown","71079d5f":"markdown","4d4f2c4e":"markdown","8c7c7079":"markdown","d8368543":"markdown"},"source":{"bf666185":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.z\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.","2bd50dc6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom eli5.sklearn import PermutationImportance\nimport warnings\n#perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n#eli5.show_weights(perm, feature_names = X_test.columns.tolist())\nwarnings.filterwarnings(\"ignore\")\nsns.set_style(\"darkgrid\")\n%matplotlib inline","e8c4d1dd":"df=pd.read_csv(\"..\/input\/heart.csv\")","b42d5e15":"df.head()","463dbc52":"df.info()","19b66d04":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)\n#No much of correlation","31cbecc6":"df['target'].value_counts()","884347be":"sns.distplot(df['age'],color='Red',hist_kws={'alpha':1,\"linewidth\": 2}, kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\n#Most people age is from 40 to 60","8aeee1b9":"fig,ax=plt.subplots(figsize=(24,6))\nplt.subplot(1, 3, 1)\nage_bins = [20,30,40,50,60,70,80]\ndf['bin_age']=pd.cut(df['age'], bins=age_bins)\ng1=sns.countplot(x='bin_age',data=df ,hue='target',palette='plasma',linewidth=3)\ng1.set_title(\"Age vs Heart Disease\")\n#The number of people with heart disease are more from the age 41-55\n#Also most of the people fear heart disease and go for a checkup from age 55-65 and dont have heart disease (Precautions)\n\nplt.subplot(1, 3, 2)\ncho_bins = [100,150,200,250,300,350,400,450]\ndf['bin_chol']=pd.cut(df['chol'], bins=cho_bins)\ng2=sns.countplot(x='bin_chol',data=df,hue='target',palette='plasma',linewidth=3)\ng2.set_title(\"Cholestoral vs Heart Disease\")\n#Most people get the heart disease with 200-250 cholestrol \n#The others with cholestrol of above 250 tend to think they have heart disease but the rate of heart disease falls\n\nplt.subplot(1, 3, 3)\nthal_bins = [60,80,100,120,140,160,180,200,220]\ndf['bin_thal']=pd.cut(df['thalach'], bins=thal_bins)\ng3=sns.countplot(x='bin_thal',data=df,hue='target',palette='plasma',linewidth=3)\ng3.set_title(\"Thal vs Heart Disease\")\n#People who have thalach between 140-180 have a very high chance of getting the heart disease ","edf51bf3":"fig,ax=plt.subplots(figsize=(24,6))\nplt.subplot(131)\nx1=sns.countplot(x='cp',data=df,hue='target',palette='spring',linewidth=3)\nx1.set_title('Chest pain type')\n#Chest pain type 2 people have highest chance of heart disease\n\nplt.subplot(132)\nx2=sns.countplot(x='thal',data=df,hue='target',palette='spring',linewidth=3)\nx2.set_title('Thal')\n#People with thal 2 have the highest chance of heart disease\n\nplt.subplot(133)\nx3=sns.countplot(x='slope',data=df,hue='target',palette='spring',linewidth=3)\nx3.set_title('slope of the peak exercise ST segment')\n#Slope 2 people have higher chance of heart disease","fdbe3bd3":"fig,ax=plt.subplots(figsize=(16,6))\nplt.subplot(121)\ns1=sns.boxenplot(x='sex',y='age',hue='target',data=df,palette='YlGn',linewidth=3)\ns1.set_title(\"Figure 1\")\n#Figure 1 says most of females having heart disease range from 40-70yrs and men from 40-60yrs\n\nplt.subplot(122)\ns2=sns.pointplot(x='sex',y='age',hue='target',data=df,palette='autumn',capsize=.2)\ns2.set_title(\"Figure 2\")\n#Figure 2 says mean age for female with heart disease around 54yrs and for males around 51yrs","61dfdf60":"fig,ax=plt.subplots(figsize=(16,6))\nsns.pointplot(x='age',y='cp',data=df,color='Lime',hue='target',linestyles=[\"-\", \"--\"])\nplt.title('Age vs Cp')\n#People with heart disease tend to have higher 'cp' at all ages only exceptions at age 45 and 49","da176e36":"fig,ax=plt.subplots(figsize=(16,6))\nsns.lineplot(y='thalach',x='age',data=df,hue=\"target\",style='target',palette='magma',markers=True, dashes=False,err_style=\"bars\", ci=68)\nplt.title('Age vs Thalach')\n#Thalach always high in people having heart disease and as age increases the thalach seems to reduce and other factors might play a role in heart disease","96db4c82":"sns.pointplot(x='sex',y='thal',data=df,hue='target',markers=[\"o\", \"x\"],linestyles=[\"-\", \"--\"],capsize=.2,palette='coolwarm')\n#Both males and females without heart disease have higher thal value and males with heart diseases tend to have higher thal than females","e2ec3981":"sns.countplot(x='ca',data=df,hue='target',palette='YlOrRd',linewidth=3)\n# People with 'ca' as 0 have highest chance of heart disease","5fb8f321":"sns.countplot(x='slope',hue='target',data=df,palette='bwr',linewidth=3)\n#Slope 2 has highest people with heart disease","6169a413":"fig,ax=plt.subplots(figsize=(24,6))\nplt.subplot(131)\nold_bins = [0,1,2,3,4,5,6]\ndf['bin_old']=pd.cut(df['oldpeak'], bins=old_bins)\nsns.countplot(x='bin_old',hue='target',data=df,palette='hot',linewidth=3)\nplt.title(\"Figure 1\")\n#Figure 1: As the value of oldpeak increases the rate of heart disease decreases\n\nplt.subplot(132)\nsns.boxplot(x='slope',y='oldpeak',data=df,hue='target',palette='hot',linewidth=3)\nplt.title(\"Figure 2\")\n#Figure 2: slope-s and target = 1; for s=0 --> Median Oldpeak=~1.4; for s=1 --> Median Oldpeak=~0.7; for s=2 --> Median Oldpeak=~0\n\nplt.subplot(133)\nsns.pointplot(x='slope',y='oldpeak',data=df,hue='target',palette='hot')\nplt.title(\"Figure 3\")\n#Figure 3: As the value of slope increases the oldpeak values decrease and heart disease people have lower oldpeak","74baff62":"df.head()","1a667757":"df.drop(['bin_age','bin_chol','bin_thal','bin_old'],axis=1,inplace=True)","715e9c49":"df.head()","62e2cbbb":"#Outlier Detection\n\nfrom collections import Counter\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(df,2,['trestbps', 'chol','thalach'])","07620663":"df.loc[Outliers_to_drop] # Show the outliers rows\n\n#No outliers to drop as the values of all the columns are in ranges.","0fa12bec":"#Checking Missing Data\ndf.isnull().sum()\n#No missing data","d910ece9":"df.head()","eb492c80":"#df=pd.read_csv('..\/input\/heart.csv')","8145fdf3":"df.dtypes","d0a58289":"#Conversion to categorical variables\ndf['sex']=df['sex'].astype('category')\ndf['cp']=df['cp'].astype('category')\ndf['fbs']=df['fbs'].astype('category')\ndf['restecg']=df['restecg'].astype('category')\ndf['exang']=df['exang'].astype('category')\ndf['slope']=df['slope'].astype('category')\ndf['ca']=df['ca'].astype('category')\ndf['thal']=df['thal'].astype('category')\ndf['target']=df['target'].astype('category')\ndf.dtypes","fae63722":"y=df['target']","1d0bb469":"df=pd.get_dummies(df,drop_first=True)\ndf.head()","d5e6a423":"X=df.drop('target_1',axis=1)\nX.head()","c992ccfe":"X.head()","7efc6b83":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)","55ead026":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n#from sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\nclassifiers=[['Logistic Regression :',LogisticRegression()],\n       ['Decision Tree Classification :',DecisionTreeClassifier()],\n       ['Random Forest Classification :',RandomForestClassifier()],\n       ['Gradient Boosting Classification :', GradientBoostingClassifier()],\n       ['Ada Boosting Classification :',AdaBoostClassifier()],\n       ['Extra Tree Classification :', ExtraTreesClassifier()],\n       ['K-Neighbors Classification :',KNeighborsClassifier()],\n       ['Support Vector Classification :',SVC()],\n       ['Gaussian Naive Bayes :',GaussianNB()]]\ncla_pred=[]\nfor name,model in classifiers:\n    model=model\n    model.fit(X_train,y_train)\n    predictions = model.predict(X_test)\n    cla_pred.append(accuracy_score(y_test,predictions))\n    print(name,accuracy_score(y_test,predictions))","efc86cb2":"from sklearn.metrics import classification_report,confusion_matrix\n\nlogmodel=LogisticRegression()\nlogmodel.fit(X_train,y_train)\nlog_pred=logmodel.predict(X_test)\nprint(confusion_matrix(y_test,log_pred))\nprint(classification_report(y_test,log_pred))\nprint(accuracy_score(y_test,log_pred))","e9d2be63":"#Hyperparameter tuning for Logistic Regression\nfrom sklearn.model_selection import GridSearchCV\npenalty = ['l1', 'l2']\nC = np.logspace(0, 4, 10)\nhyperparameters = dict(C=C, penalty=penalty)\nh_logmodel = GridSearchCV(logmodel, hyperparameters, cv=5, verbose=0)\nbest_logmodel=h_logmodel.fit(X,y)\nprint('Best Penalty:', best_logmodel.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_logmodel.best_estimator_.get_params()['C'])","6e841140":"logmodel=LogisticRegression(penalty='l1',C=2.7825594022071245)\nlogmodel.fit(X_train,y_train)\nh_log_pred=logmodel.predict(X_test)\nprint(confusion_matrix(y_test,h_log_pred))\nprint(classification_report(y_test,h_log_pred))\nprint(accuracy_score(y_test,h_log_pred))\n\n#3% increase in the accuracy!!","60d061f7":"# So on Hyperparameter tuning we get a model with  Logistic Regression with 90% accuray!!","1a3408c0":"> # If you find this notebook helpful , some upvotes would be very much appreciated - That will keep me motivated \ud83d\udc4d","71079d5f":"## Data Cleaning","4d4f2c4e":"### Always open to suggestions and Thank you for you're time.","8c7c7079":"* age- in years\n* sex-(1 = male; 0 = female)\n* cp- chest pain type\n* trestbps- resting blood pressure (in mm Hg on admission to the hospital)\n* chol- serum cholestoral in mg\/dl\n* fbs-(fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* restecg-resting electrocardiographic results\n* thalach-maximum heart rate achieved\n* exang-exercise induced angina (1 = yes; 0 = no)\n* oldpeak-ST depression induced by exercise relative to rest\n* slope-the slope of the peak exercise ST segment\n* ca-number of major vessels (0-3) colored by flourosopy\n* thal- 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target- 1 or 0","d8368543":"# Modelling \n"}}