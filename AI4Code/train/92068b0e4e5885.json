{"cell_type":{"d72cf5ff":"code","597ece0e":"code","21883ac0":"code","06068d07":"code","9ba8bbf9":"code","824518db":"code","825d03ee":"code","e92fbb2e":"code","0b02cc9e":"code","2bf3bb59":"code","8fcc2972":"code","a8f5fb6a":"code","7febc190":"code","31c043df":"code","c7c893d3":"code","b5066022":"code","b7e7910e":"code","813205b5":"code","3b5859a8":"code","55f19d87":"code","3aeaa2f4":"code","d77ad8d0":"code","15b3efdb":"code","30235d04":"code","ed8558a3":"code","4c8b371a":"code","d5ee6c7b":"code","f42a1750":"code","470aa4cb":"code","6f6fbede":"code","7a7df2b0":"code","69dc5d3b":"code","3db66a4e":"code","f354eca8":"code","d1160076":"code","ed806ee1":"code","07a31e51":"code","e0bd3186":"code","ebfd9001":"code","4a3234b9":"code","35a20b0c":"code","462d9797":"code","853e372b":"code","b49f087c":"code","b05a9c74":"code","4df30401":"code","93556d72":"code","cccd4c4e":"code","21d1c40c":"code","d7440dd9":"code","082da1e6":"code","379fb90e":"code","854d0daf":"code","1fd71c3c":"code","b300efe8":"code","9a4e05b2":"code","a459c911":"code","ba06968f":"code","76abfc76":"code","6441b3bd":"code","a99578ea":"code","cb136340":"code","b5e9ad49":"code","5932c226":"code","0b8740fc":"code","bf4d1f78":"code","4c43a608":"code","c81c9887":"code","54432478":"code","4ad7045c":"code","5c349e3d":"code","df042242":"code","dd736a0f":"code","1eec90ca":"code","d93b8f03":"code","80b3c569":"code","82f09c80":"code","78bcdcd7":"code","1ac3d497":"code","5eead0ca":"code","cb0261a8":"code","a4715f38":"code","4d154945":"code","4d843640":"code","c5d4bf9b":"code","762715d3":"code","78908d93":"code","6ed429c3":"code","93ce4da5":"code","b68b92c3":"code","05e6d485":"code","23ab442e":"code","33b56791":"code","13e26108":"code","507c6ebb":"code","d33afb2c":"code","38db9803":"code","bb74db53":"code","2245ee53":"code","3754519d":"code","c51fa39a":"code","d07224f9":"code","f8649fd2":"code","0024279e":"code","7c065705":"code","22455d85":"code","19af7e9a":"code","6ab7cf95":"code","8f9eff5c":"code","d3c03102":"code","856d0ddc":"code","ed336488":"code","65f6b91d":"code","18eb33f5":"code","fdfadaf5":"code","59abad34":"code","7cc501e3":"code","59076168":"code","106c522f":"code","3d336474":"code","1e887eac":"code","1331cb2b":"code","89a85f43":"code","8bc55366":"markdown","071cfc77":"markdown","5947d40c":"markdown","eb731e8d":"markdown","1f75afdf":"markdown","9f1db1cc":"markdown","e1b24ad0":"markdown","f254e6d2":"markdown","ec985bd0":"markdown","fba84eb3":"markdown","4e65253c":"markdown","64032eb1":"markdown","0da468ff":"markdown","fe4a187b":"markdown","0471e713":"markdown","78e86533":"markdown","9ced0b5f":"markdown","3431a092":"markdown","e2355471":"markdown","034012d8":"markdown","9025c088":"markdown","289aadd3":"markdown","ec918799":"markdown","f1e0aca3":"markdown","b323c0b7":"markdown","bb02da73":"markdown","f37019a9":"markdown","1e6115c8":"markdown","ea0c9a94":"markdown","19184c20":"markdown","efbc4edf":"markdown","846631cf":"markdown","a273f58c":"markdown","582b41b3":"markdown","d94411cb":"markdown","37df2309":"markdown","5af968bc":"markdown","58f82b17":"markdown","1f5f426a":"markdown","f49d774a":"markdown","af01aa14":"markdown","b55fe59e":"markdown","11501b37":"markdown","9fb67988":"markdown","7f3a44ab":"markdown","24c07d62":"markdown","30a5a8a9":"markdown"},"source":{"d72cf5ff":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('grayscale')\nmpl.rcParams['figure.figsize'] = 16, 8\nmpl.rcParams['lines.linewidth'] = 0.7\nmpl.rcParams['grid.color'] = 'k'\nmpl.rcParams['grid.linestyle'] = ':'\nmpl.rcParams['grid.linewidth'] = 0.5\nmpl.rcParams['axes.edgecolor'] = 'grey'\nmpl.rcParams['axes.facecolor'] = 'white'\nmpl.rcParams['figure.facecolor'] = 'white'\n\npd.set_option('display.max_columns', None) # shows all columns\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(88)","597ece0e":"# Loading data\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain['train_test'] = 1\ntest['train_test'] = 0\ntest['Survived'] = np.NaN\n\ndatasets = pd.concat([train, test])","21883ac0":"datasets","06068d07":"# Quick exploration\nimport pandas_profiling\npandas_profiling.ProfileReport(train)","9ba8bbf9":"# Exploratory\ntrain.info()","824518db":"test.info()","825d03ee":"train.describe(include='all')","e92fbb2e":"test.describe(include='all')","0b02cc9e":"# look at numeric and categorical values separately \ndf_num = train[['Age','SibSp','Parch','Fare']]\ndf_cat = train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","2bf3bb59":"#distributions for all numeric variables \nfig, ax = plt.subplots(2, 2)\nfor i, col in enumerate(df_num.columns):\n    plt.subplot(2, 2, i+1)\n    plt.hist(df_num[col])\n    plt.title(col)\n    plt.grid()\n    ","8fcc2972":"train['Fare'].sort_values(ascending=False)[:10]","a8f5fb6a":"train.query('Fare == 512.3292')","7febc190":"sns.countplot(train['Survived'])","31c043df":"# Survived by sex\ntrain.groupby('Sex').mean()['Survived'].plot(kind='bar')","c7c893d3":"# Survived by Sex and Pclass\ntrain.groupby(['Sex', 'Pclass'])['Survived'].mean().unstack()","b5066022":"# Alternative\ntrain.pivot_table(index='Sex', columns='Pclass',\n                  values='Survived', aggfunc='mean',\n                  margins=True)","b7e7910e":"train['Age'].describe().loc[['min', 'max']]","813205b5":"# Continuous data into categorical data\ntrain['cat_age'] = pd.cut(train['Age'], \n                          bins=[0, 18, 25, 99], \n                          labels=['child', 'young adult', 'adult'])\n","3b5859a8":"# Survived by Sex and Age\ntrain.pivot_table(index='Sex',\n                  columns=['cat_age', 'Pclass'],\n                  values='Survived',\n                  aggfunc=['mean', 'count'],\n                  margins=True)\n","55f19d87":"# Survived vs Embarked\ntrain.pivot_table(index='Sex', \n                  columns='Embarked', \n                  values='Survived',\n                  aggfunc=['mean', 'count'])","3aeaa2f4":"sns.heatmap(train.iloc[:,1:].corr(), linewidths=0.1, cmap='gray_r', annot=True)","d77ad8d0":"train['cabin_multiple'] = train['Cabin'].apply(\n    lambda x: 0 if pd.isna(x) else len(x.split(' '))\n)\n\n# For model implementation\ndatasets['cabin_multiple'] = datasets['Cabin'].apply(\n    lambda x: 0 if pd.isna(x) else len(x.split(' '))\n)\n","15b3efdb":"train['cabin_multiple'].value_counts()","30235d04":"train.pivot_table(index='Survived',\n                  columns='cabin_multiple',\n                  values='Ticket',\n                  margins=True,\n                  aggfunc='count')","ed8558a3":"#creates categories based on the cabin letter (n=null)\n\ntrain['cabin_adv'] = train['Cabin'].apply(lambda x: str(x)[0])\nprint(train['cabin_adv'].value_counts())\n\n# for model implementation\ndatasets['cabin_adv'] = datasets['Cabin'].apply(lambda x: str(x)[0])","4c8b371a":"train.pivot_table(index='Survived',\n                  columns='cabin_adv',\n                  values='Ticket',\n                  margins=True,\n                  aggfunc='count')","d5ee6c7b":"train['is_num_ticket'] = train['Ticket'].apply(\n    lambda x: 1 if x.isnumeric() else 0\n)\ntrain['ticket_letters'] = train['Ticket'].apply(lambda x: ''.join(x.split(' ')[:-1])\n                                                .replace('\/', '')\n                                                .replace('.', '')\n                                                .lower()\n                                                if  len(x.split(' ')[:-1]) > 0 else 0\n                                                )\n\n# For model implementation\ndatasets['is_num_ticket'] = datasets['Ticket'].apply(\n    lambda x: 1 if x.isnumeric() else 0\n)\ndatasets['ticket_letters'] = datasets['Ticket'].apply(lambda x: ''.join(x.split(' ')[:-1])\n                                                .replace('\/', '')\n                                                .replace('.', '')\n                                                .lower()\n                                                if  len(x.split(' ')[:-1]) > 0 else 0\n                                                )","f42a1750":"train['is_num_ticket'].value_counts()","470aa4cb":"# pd.set_option(\"max_rows\", None)\ntrain['ticket_letters'].value_counts()","6f6fbede":"train.pivot_table(index='Survived',\n                  columns='ticket_letters',\n                  values='Ticket',\n                  margins=True,\n                  aggfunc='count')","7a7df2b0":"\ntrain['title'] = train['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain['title'] = train['title'].replace(['Dona', 'Lady', 'the Countess', 'Countess', 'Capt',\n                                   'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', \n                                   'Jonkheer', 'Ms', 'Mme', 'Mlle'], 'Other',\n                                  regex=True)\n\n# For model implementation\ndatasets['title'] = datasets['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ndatasets['title'] = datasets['title'].replace(['Dona', 'Lady', 'the Countess', 'Countess', 'Capt',\n                                   'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', \n                                   'Jonkheer', 'Ms', 'Mme', 'Mlle'], 'Other',\n                                  regex=True)","69dc5d3b":"train['title'].value_counts()","3db66a4e":"train['SibSp'].value_counts()","f354eca8":"train['Parch'].value_counts()","d1160076":"train.query('Parch == 0 and SibSp == 0')","ed806ee1":"def family(x):\n    if x < 2:\n        return 'Single'\n    elif x == 2:\n        return 'Couple'\n    elif x <= 4:\n        return 'InterM'\n    else:\n        return 'Large'\n\ntrain['family_size'] = train['SibSp'] + train['Parch'] + 1\ntrain['family_size'] = train['family_size'].apply(family)\n\n# For model implementation\ndatasets['family_size'] = datasets['SibSp'] + datasets['Parch'] + 1\ndatasets['family_size'] = datasets['family_size'].apply(family)\n","07a31e51":"train['family_size'].value_counts()","e0bd3186":"train.pivot_table(index='Survived',\n                 columns='family_size',\n                 values='Ticket',\n                  margins=True,\n                  aggfunc='count')","ebfd9001":"def sex_age(s, a):\n    if (s == 'female') & (a < 18):\n        return 'girl'\n    elif (s == 'male') & (a < 18):\n        return 'boy'\n    elif (s == 'female') & (a > 18):\n        return 'adult female'\n    elif (s == 'male') & (a > 18):\n        return 'adult male'\n    elif (s == 'female') & (a > 50):\n        return 'old female'\n    else:\n        return 'old male'\n        ","4a3234b9":"train['Age'].fillna(train['Age'].median(), inplace=True)\ntrain['sex_age'] = train.apply(lambda x: sex_age(x['Sex'], x['Age']), axis=1)\n\n# For model implemnetation\n\ndatasets['Age'].fillna(datasets['Age'].median(), inplace=True)\ndatasets['sex_age'] = datasets.apply(lambda x: sex_age(x['Sex'], x['Age']), axis=1)\n","35a20b0c":"train['sex_age'].value_counts()","462d9797":"train.pivot_table(index='Survived',\n                 columns='sex_age',\n                 values='Ticket',\n                  margins=True,\n                  aggfunc='count')","853e372b":"train.isnull().sum()\/len(train)","b49f087c":"sns.heatmap(train.isnull().T, xticklabels=False, cbar=True, cmap='viridis_r')","b05a9c74":"datasets.isnull().sum()","4df30401":"datasets['Fare'].fillna(datasets['Fare'].median(), inplace=True)\ndatasets.dropna(subset=['Embarked'],inplace = True)","93556d72":"print(datasets.isnull().sum())","cccd4c4e":"datasets['Fare'].min()","21d1c40c":"sns.distplot(np.log(datasets['Fare']+1));","d7440dd9":"# log norm of fare\ndatasets['norm_fare'] = np.log(datasets['Fare']+1)","082da1e6":"datasets.head(1).T","379fb90e":"## Dropping useless columns [for now]\ndatasets.drop(['PassengerId', 'Name', \n               'Ticket', 'Cabin', 'Sex',\n              'Fare', ], axis=1, inplace=True)\n    \n","854d0daf":"datasets.head(2).T","1fd71c3c":"from sklearn.preprocessing import LabelEncoder\n### Label Encoding family_size, Pclass\nenc = LabelEncoder()\ndatasets['sex_age'] = enc.fit_transform(datasets['sex_age'])\ndatasets['family_size'] = enc.fit_transform(datasets['family_size'])\ndatasets['Pclass'] = enc.fit_transform(datasets['Pclass']) \ndatasets['SibSp'] = enc.fit_transform(datasets['SibSp']) \ndatasets['Parch'] = enc.fit_transform(datasets['Parch'])\ndatasets['cabin_multiple'] = enc.fit_transform(datasets['cabin_multiple'])","b300efe8":"datasets.head()","9a4e05b2":"datasets= pd.get_dummies(data=datasets, \n                         columns=['Parch', 'Embarked', 'cabin_adv',\n                                  'is_num_ticket', 'ticket_letters',\n                                  'title'], drop_first=True)\n","a459c911":"datasets.head()","ba06968f":"for col in datasets.columns[1:]:\n    assert datasets[col].notnull().all(),\\\n    f'You still have some missing values in {col}'","76abfc76":"train_data = datasets[datasets['train_test'] == 1].drop(\n    ['train_test'], axis=1)\n\ntest_data = datasets[datasets['train_test'] == 0].drop(\n    ['train_test'], axis=1)\n","6441b3bd":"print(train_data.shape, test_data.shape)","a99578ea":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.utils import shuffle\nfrom sklearn.pipeline import Pipeline","cb136340":"import os\nimport random\n# Set seed for reproducability\nSEED = 88\nos.environ['PYTHONHASHSEED'] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\nnp.random.RandomState(SEED)","b5e9ad49":"# Splitting the data\ntrain_data = shuffle(train_data)\nx = train_data.iloc[:, 1:].values\ny = train_data.iloc[:, 0].values\n\nX_train, X_test, y_train, y_test = \\\n    train_test_split(x, y, test_size=0.15, stratify=y)\n\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","5932c226":"from collections import Counter\nprint(Counter(y_train))\nprint(Counter(y_test))","0b8740fc":"def display_scores(scores, metric):\n#     print('Scores:', scores)\n    print('Metric:', metric)\n    print('Mean:', scores.mean())\n    print('Standard deviation:', scores.std())\n    \n\ndef save_submission(model, test_data, name=''):\n    try:\n        y_pred = model.predict(test_data.iloc[:, 1:].values).astype(int)\n        submission = {'PassengerId': test.PassengerId, \n                      'Survived': y_pred}\n        submission = pd.DataFrame(data=submission)\n        submission.to_csv(f'{name}_submission.csv', index=False)\n    except Exception as e:\n        print('Submission not saved', e)","bf4d1f78":"from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, make_scorer\nfrom sklearn.metrics import average_precision_score\ndef pr_auc(y_true, probs_pred):\n  \"\"\"Calculate precision-recall area under curve\"\"\"\n  #   p, r, _ = precision_recall_curve(y_true, probs_pred)\n  # calculate area under curve\n  return average_precision_score(y_true, probs_pred)\n\ndef roc_auc(y_true, probs_pred):\n    \"\"\"Calculate ROC area under curve\"\"\"\n    return roc_auc_score(y_true, probs_pred)\n    \ndef evaluate_model(model, x, y):\n    \"\"\" Evaluate the model using Stratified KFold \"\"\"\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5)\n    metric = make_scorer(pr_auc, needs_proba=True)\n#     scores = cross_val_score(model, x, y, scoring=metric, cv=cv, n_jobs=-1, verbose=0)\n    \n    scores = cross_val_score(model, x, y, scoring=metric, cv=cv, n_jobs=-1, verbose=0)\n    return scores","4c43a608":"from sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\ndef models():\n    \"\"\" Generator for the models \"\"\"\n    base_p = Pipeline(steps=[('s', StandardScaler()), ('BASE', DummyClassifier())])\n    lr_p = Pipeline(steps=[('s', StandardScaler()), ('LR', LogisticRegression())])\n    rf_p = Pipeline(steps=[('s', StandardScaler()), ('RF', RandomForestClassifier())])\n    bc_p = Pipeline(steps=[('s', StandardScaler()), ('BC', BaggingClassifier())])\n    knn_p = Pipeline(steps=[('s', StandardScaler()), ('KNN', KNeighborsClassifier())])\n    svc_p = Pipeline(steps=[('s', StandardScaler()), ('SVM', SVC(probability=True))])\n    xgb_p = Pipeline(steps=[('s', StandardScaler()), ('XGB', XGBClassifier())])\n    lgbm_p = Pipeline(steps=[('s', StandardScaler()), ('LGBM', LGBMClassifier())])\n    \n    models = [base_p, lr_p, rf_p, bc_p, knn_p, svc_p, xgb_p, lgbm_p]\n    names = 'BASE LR RF BC KNN SVM XGB LGBM'.split(' ')\n\n    for n, m in zip(names, models):\n        yield n, m\n    \n    ","c81c9887":"from functools import partial\nmetric = 'auc_pr'\ndisplay_scores = partial(display_scores, metric=metric)","54432478":"results = []\nnames = []\n\nfor name, model in models():\n    print('-'*20)\n    print(name)\n    scores = evaluate_model(model, X_train, y_train)\n    results.append(scores)\n    names.append(name)\n    display_scores(scores)\n    \n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('AUC_PR Scores')\nplt.grid()\nplt.show()\n","4ad7045c":"# colors = ['#129845','#271254', '#FA4411', '#098765', '#000009','#A71254', '#BA4411']\n\n# for i, (name, model) in enumerate(models()):\n#     model.fit(X_train, y_train)\n#     preds_prob = model.predict_proba(X_test)\n#     fpr, tpr, _ = roc_curve(y_test, preds_prob[:,1])\n#     plt.plot(fpr, tpr, label=name, c=colors[i])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.legend()\n# plt.grid()","5c349e3d":"import plotly.graph_objects as go\nimport plotly.express as px\n\nfig = go.Figure()\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfor i, (name, model) in enumerate(models()):\n    model.fit(X_train, y_train)\n    preds_prob = model.predict_proba(X_test)\n    fpr, tpr, _ = roc_curve(y_test, preds_prob[:,1])\n    auc_score = roc_auc(y_test, preds_prob[:,1])\n    name = f\"{name} (AVGPR={auc_score:.2f})\"\n    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n\n    fig.add_shape(\n        type='line', line=dict(dash='dash'),\n        x0=0, x1=1, y0=0, y1=1\n    )\n\nfig.update_layout(\n    title=f'ROC Curves',\n    xaxis_title='False Positive Rate',\n    yaxis_title='True Positive Rate',\n    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n    xaxis=dict(constrain='domain'),\n    width=800, height=500\n)\nfig.show()","df042242":"fig = go.Figure()\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=1, y1=0\n)\n\nfor i, (name, model) in enumerate(models()):\n    model.fit(X_train, y_train)\n    preds_prob = model.predict_proba(X_test)\n    pr, rc, _ = precision_recall_curve(y_test, preds_prob[:,1])\n    auc_score = average_precision_score(y_test, preds_prob[:,1])\n    name = f\"{name} (AVGPR={auc_score:.2f})\"\n    \n    fig.add_trace(go.Scatter(x=rc, y=pr,\n                             name=name,\n                             mode='lines'))\n\nfig.update_layout(\n    title=f'PR Curves',\n    xaxis_title='Recall',\n    yaxis_title='Precision',\n    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n    xaxis=dict(constrain='domain'),\n#     width=700, height=500\n)\nfig.show()","dd736a0f":"import optuna","1eec90ca":"pr_metric = make_scorer(pr_auc, needs_proba=True)","d93b8f03":"def objective(trial):\n    # Hyperparameters space #\n    n_estimators = trial.suggest_int('n_estimators', 700, 1000)\n    max_features = trial.suggest_uniform('max_features', 0.01, 1.0)\n    max_depth = trial.suggest_int('max_depth', 10, 50)\n    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 25)\n    min_samples_split = trial.suggest_loguniform('min_samples_split',1e-2, 1.0)\n    ########################\n    \n    pipeline = Pipeline([\n        ('sc', StandardScaler()),\n        ('clf', RandomForestClassifier(n_estimators=n_estimators,\n                                      max_features=max_features,\n                                      max_depth=max_depth,\n                                      criterion=criterion,\n                                      min_samples_leaf=min_samples_leaf,\n                                      min_samples_split=min_samples_split,\n                                      n_jobs=-1))])\n    \n    for step in range(50):\n        intermediate_value = cross_val_score(pipeline, \n                                             X_train,\n                                             y_train,\n                                             scoring=pr_metric).mean()\n        trial.report(intermediate_value, step)\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n    \n    return cross_val_score(pipeline, \n                            X_train,\n                            y_train,\n                            scoring=pr_metric).mean()\n\n\nif 'study_rf.pkl' in os.listdir():\n    study = joblib.load('study_rf.pkl')\n\nelse:\n    study = optuna.create_study(direction='maximize',\n                               pruner=optuna.pruners.HyperbandPruner(\n                                   min_resource=2,\n                                   max_resource='auto',\n                                   reduction_factor=4))\n    study.optimize(objective, n_trials=20)\n\ntrial = study.best_trial\nprint('AUC_PR: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))","80b3c569":"os.listdir()","82f09c80":"import joblib\njoblib.dump(study, 'study_rf.pkl')","78bcdcd7":"optuna.visualization.plot_optimization_history(study)","1ac3d497":"optuna.visualization.plot_slice(study)","5eead0ca":"optuna.visualization.plot_contour(study, params=['max_features', 'max_depth'])","cb0261a8":"study.best_params","a4715f38":"best_rf = Pipeline(\n    [('sc', StandardScaler()), \n    ('rf', RandomForestClassifier(**study.best_params))])\n\nbest_rf.fit(X_train, y_train)\n# Cross-Validation\nscores = evaluate_model(best_rf, X_test, y_test)\ndisplay_scores(scores)\nprint('-'*10)\nprint(classification_report(best_rf.predict(X_test), y_test))\nprint('-'*10)\nprint(confusion_matrix(best_rf.predict(X_test), y_test))\n\nsave_submission(best_rf, test_data, 'rf')","4d154945":"# from sklearn.ensemble import RandomForestClassifier\n\n# # Pipeline\n# rf_pipeline = Pipeline(\n#                 [('sc', StandardScaler()), \n#                  ('rf', RandomForestClassifier())])\n# # cv\n# cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3)\n\n# # Grid Search\n# param_grid = { \n#     'rf__n_estimators': [int(x) for x in np.linspace(start = 10, stop = 500, num = 20)],\n#     'rf__max_features': ['auto', 'sqrt', 'log2'],\n#     'rf__max_depth' : [int(x) for x in np.linspace(1, 100, num = 11)],\n#     'rf__criterion' :['gini', 'entropy'],\n#     'rf__min_samples_leaf': [1, 2, 4, 5, 10, 20],\n#     'rf__min_samples_split': [2, 4, 5, 10, 20],\n# }\n\n# metric = make_scorer(roc_auc, needs_proba=True)\n# clf = RandomizedSearchCV(rf_pipeline, param_distributions=param_grid,\n#                          n_iter=1000, scoring=metric, cv=cv,\n#                          error_score=0, verbose=3, n_jobs=-1)\n# search = clf.fit(X_train, y_train)\n","4d843640":"# print(search.best_score_)\n# print(search.best_estimator_)","c5d4bf9b":"# # Cross-Validation\n# best_rf = search.best_estimator_\n\n# scores = evaluate_model(best_rf, X_test, y_test)\n# display_scores(scores)\n# print('-'*10)\n# print(classification_report(best_rf.predict(X_test), y_test))\n# print(confusion_matrix(best_rf.predict(X_test), y_test))\n\n# save_submission(best_rf, test_data, 'rf')","762715d3":"def objective(trial):\n    # Hyperparameters space #\n    C = trial.suggest_loguniform('C', 0.01, 1)\n    kernel = trial.suggest_categorical('kernel', ['rbf', 'sigmoid'])\n    gamma = trial.suggest_loguniform('gamma', 0.1, 20)\n    ########################\n#     if kernel == 'linear':\n#         pipeline = Pipeline([\n#             ('sc', StandardScaler()),\n#             ('clf', SVC(C=C, \n#                         kernel=kernel, \n#                         probability=True))])\n#     else:\n    pipeline = Pipeline([\n        ('sc', StandardScaler()),\n        ('clf', SVC(C=C, \n                    kernel=kernel, \n                    gamma=gamma,\n                    probability=True))])\n\n    \n    for step in range(50):\n        # Report intermediate objective value.\n        intermediate_value = cross_val_score(pipeline, X_train, y_train,\n                                             scoring=pr_metric).mean()\n        trial.report(intermediate_value, step)\n        \n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n            \n    return cross_val_score(pipeline, X_train, y_train,\n                            scoring=pr_metric).mean()\n\n\nstudy = optuna.create_study(direction='maximize',\n                           pruner=optuna.pruners.HyperbandPruner(\n                               min_resource=2,\n                               max_resource='auto',\n                               reduction_factor=3))\nstudy.optimize(objective, n_trials=20)\n\ntrial = study.best_trial\nprint('AUC_PR: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))\n","78908d93":"optuna.visualization.plot_optimization_history(study)","6ed429c3":"optuna.visualization.plot_slice(study)","93ce4da5":"study.best_params","b68b92c3":"best_svc = Pipeline(\n    [('sc', StandardScaler()), \n    ('svc', SVC(**study.best_params, probability=True))])\nprint(best_svc)\nbest_svc.fit(X_train, y_train)\n# Cross-Validation\nscores = evaluate_model(best_svc, X_test, y_test)\ndisplay_scores(scores)\nprint('-'*10)\nprint(classification_report(best_svc.predict(X_test), y_test))\nprint('-'*10)\nprint(confusion_matrix(best_svc.predict(X_test), y_test))\n\nsave_submission(best_svc, test_data, 'svc')","05e6d485":"def objective(trial):\n    # Hyperparameters space #\n    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n    max_samples = trial.suggest_loguniform('max_samples', 0.1, 1.0)\n    max_features = trial.suggest_loguniform('max_features', 0.01, 1.0)\n    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n    oob_score = trial.suggest_categorical('oob_score', [True, False])\n    ########################\n    \n    pipeline = Pipeline([\n        ('sc', StandardScaler()),\n        ('clf', BaggingClassifier(n_estimators=n_estimators,\n                                      max_features=max_features,\n                                      max_samples=max_samples,\n                                      bootstrap=bootstrap,\n                                      oob_score=oob_score,\n                                      n_jobs=-1))])\n\n    \n    for step in range(50):\n        # Report intermediate objective value.\n        intermediate_value = cross_val_score(pipeline, X_train, y_train,\n                                             scoring=pr_metric).mean()\n        trial.report(intermediate_value, step)\n        \n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n            \n    return cross_val_score(pipeline, X_train, y_train,\n                            scoring=pr_metric).mean()\n\n\nstudy = optuna.create_study(direction='maximize',\n                           pruner=optuna.pruners.HyperbandPruner(\n                               min_resource=2,\n                               max_resource='auto',\n                               reduction_factor=4))\nstudy.optimize(objective, n_trials=20)\n\ntrial = study.best_trial\nprint('AUC_PR: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))","23ab442e":"optuna.visualization.plot_optimization_history(study)","33b56791":"optuna.visualization.plot_slice(study)","13e26108":"# Evaluation\n\nbest_bc = Pipeline(\n    [('sc', StandardScaler()), \n    ('bc', BaggingClassifier(**study.best_params))])\nprint(best_bc)\nbest_bc.fit(X_train, y_train)\n# Cross-Validation\nscores = evaluate_model(best_bc, X_test, y_test)\ndisplay_scores(scores)\nprint('-'*10)\nprint(classification_report(best_bc.predict(X_test), y_test))\nprint('-'*10)\nprint(confusion_matrix(best_bc.predict(X_test), y_test))\n\nsave_submission(best_bc, test_data, 'bc')","507c6ebb":"def objective(trial):    \n    # Hyperparameters space # \n    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n#     booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"])\n    booster = trial.suggest_categorical(\"booster\", [\"gblinear\"])\n    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-3, 1.0, log=True) # 1e-3, 1.0, log=True\n    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-3, 1.0, log=True) # 1e-3, 1.0, log=True\n    subsample = trial.suggest_float(\"subsample\", 1e-3, 1.0, log=True) \n    scale_pos_weight = trial.suggest_int('scale_pos_weight', 1, 10)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0, log=True)\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 2.0, log=True)\n\n#     if booster == \"gbtree\" or booster == \"dart\":\n#         max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n#         learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True)\n#         gamma = trial.suggest_uniform(\"gamma\", 2.0, 10.0) # 1e-3, 5.0\n        \n#         pipeline = Pipeline([\n#             ('sc', StandardScaler()),\n#             ('clf', XGBClassifier(n_estimators=n_estimators,                 \n#                                   max_depth=max_depth,\n#                                   learning_rate=learning_rate,\n#                                   verbosity=0,\n#                                   booster=booster,\n#                                   gamma=gamma,\n#                                   subsample=subsample,\n#                                   reg_alpha=reg_alpha,\n#                                   reg_lambda=reg_lambda,\n#                                   scale_pos_weight=scale_pos_weight,\n#                                   n_jobs=-1\n#                                  ))])\n#     else:\n    pipeline = Pipeline([\n        ('sc', StandardScaler()),\n        ('clf', XGBClassifier(n_estimators=n_estimators,                 \n                              verbosity=0,\n                              learning_rate=learning_rate,\n                              booster=booster,\n                              subsample=subsample,\n                              reg_alpha=reg_alpha,\n                              reg_lambda=reg_lambda,\n                              scale_pos_weight=scale_pos_weight,\n                              n_jobs=-1\n                             ))])\n########################\n\n    for step in range(100):\n        # Report intermediate objective value.\n        intermediate_value = cross_val_score(pipeline, X_train, y_train,\n                                             scoring=pr_metric).mean()\n        trial.report(intermediate_value, step)\n        \n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n            \n    return cross_val_score(pipeline, X_train, y_train,\n                            scoring=pr_metric).mean()\n\n\nstudy = optuna.create_study(direction='maximize',\n                           pruner=optuna.pruners.HyperbandPruner(\n                               min_resource=6,\n                               max_resource='auto',\n                               reduction_factor=4))\nstudy.optimize(objective, n_trials=25)\n\ntrial = study.best_trial\nprint('AUC_PR: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))","d33afb2c":"optuna.visualization.plot_optimization_history(study)","38db9803":"optuna.visualization.plot_slice(study)","bb74db53":"best_xgb = Pipeline(\n    [('sc', StandardScaler()), \n    ('xgb', XGBClassifier(**study.best_params))])\nprint(best_xgb)\nbest_xgb.fit(X_train, y_train)\n# Cross-Validation\nscores = evaluate_model(best_xgb, X_test, y_test)\ndisplay_scores(scores)\nprint('-'*10)\nprint(classification_report(best_xgb.predict(X_test), y_test))\nprint('-'*10)\nprint(confusion_matrix(best_xgb.predict(X_test), y_test))\n\nsave_submission(best_xgb, test_data, 'xgb')","2245ee53":"# help(LGBMClassifier)","3754519d":"from lightgbm import LGBMClassifier\n\ndef objective(trial):    \n    # Hyperparameters space # \n    boosting_type = trial.suggest_categorical(\"boosting_type\", [\"dart\"])\n    n_estimators = trial.suggest_int('n_estimators', 10, 600)\n    max_depth = trial.suggest_int(\"max_depth\", 5, 15)\n    num_leaves = trial.suggest_int(\"num_leaves\", 10, 50)\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True)\n    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-3, 1.0, log=True) # 1e-3, 1.0, log=True\n    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-3, 2.0, log=True) # 1e-3, 1.0, log=True\n    subsample = trial.suggest_float(\"subsample\", 1e-3, 2.0, log=True) \n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0, log=True)\n#     gamma = trial.suggest_uniform(\"gamma\", 2.0, 10.0) # 1e-3, 5.0\n    subsample_for_bin = trial.suggest_int(\"subsample_for_bin\", 5, 50)\n    ########################\n\n    pipeline = Pipeline([\n        ('sc', StandardScaler()),\n        ('clf', LGBMClassifier(boosting_type=boosting_type,\n                              n_estimators=n_estimators,                 \n                              max_depth=max_depth,\n                              learning_rate=learning_rate,\n                              num_leaves=num_leaves,\n#                               gamma=gamma,\n                              min_child_weight=min_child_weight,\n                              subsample=subsample,\n                              reg_alpha=reg_alpha,\n                              reg_lambda=reg_lambda,\n                              colsample_bytree=colsample_bytree,\n                              subsample_for_bin=subsample_for_bin,\n                              n_jobs=-1\n                             ))])\n\n\n    for step in range(200):\n        # Report intermediate objective value.\n        intermediate_value = cross_val_score(pipeline, X_train, y_train,\n                                             scoring=pr_metric).mean()\n        trial.report(intermediate_value, step)\n        \n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n            \n    return cross_val_score(pipeline, X_train, y_train,\n                            scoring=pr_metric).mean()\n\n\nstudy = optuna.create_study(direction='maximize',\n                           pruner=optuna.pruners.HyperbandPruner(\n                               min_resource=10,\n                               max_resource='auto',\n                               reduction_factor=5))\nstudy.optimize(objective, n_trials=20)\n\ntrial = study.best_trial\nprint('AUC_PR: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))","c51fa39a":"optuna.visualization.plot_optimization_history(study)","d07224f9":"optuna.visualization.plot_slice(study)","f8649fd2":"best_lgbm = Pipeline(\n    [('sc', StandardScaler()), \n    ('lgbm', LGBMClassifier(**study.best_params))])\nprint(best_lgbm)\nbest_lgbm.fit(X_train, y_train)\n# Cross-Validation\nscores = evaluate_model(best_lgbm, X_test, y_test)\ndisplay_scores(scores)\nprint('-'*10)\nprint(classification_report(best_lgbm.predict(X_test), y_test))\nprint('-'*10)\nprint(confusion_matrix(best_lgbm.predict(X_test), y_test))\n\nsave_submission(best_lgbm, test_data, 'lgbm')","0024279e":"import plotly.graph_objects as go\nimport plotly.express as px\n\ntuned_models = [('RF', best_rf),\n               ('SVC', best_svc),\n               ('BG', best_bc),\n               ('XGB', best_xgb),\n               ('LGBM', best_lgbm)\n               ]","7c065705":"# ROC-Curve\n\nfig = go.Figure()\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfor i, (name, model_) in enumerate(tuned_models):\n    probs = model_.predict_proba(X_test)[:, 1]\n    # PR_Curves\n    fpr, tpr, _ = roc_curve(y_test, probs)\n    auc_score = roc_auc(y_test, probs)\n    name = f\"{name} (AVGPR={auc_score:.2f})\"\n    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n\n    fig.add_shape(\n        type='line', line=dict(dash='dash'),\n        x0=0, x1=1, y0=0, y1=1\n    )\n\nfig.update_layout(\n    title=f'ROC Curves',\n    xaxis_title='False Positive Rate',\n    yaxis_title='True Positive Rate',\n    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n    xaxis=dict(constrain='domain'),\n    width=800, height=500\n)\nfig.show()","22455d85":"# PR-Curve Plot\n\nfig = go.Figure()\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=1, y1=0\n)\n\n\nfor i, (name, model_) in enumerate(tuned_models):\n    probs = model_.predict_proba(X_test)[:, 1]\n    # PR_Curves\n    pr_, rc_, _ = precision_recall_curve(y_test, probs)\n    auc_score = average_precision_score(y_test, probs)\n    name = f\"{name} (AVGPR={auc_score:.2f})\"     \n    fig.add_trace(go.Scatter(x=rc, y=pr,\n                             name=name,\n                             mode='lines'))\n\nfig.update_layout(\n    title=f'PR Curves',\n    xaxis_title='Recall',\n    yaxis_title='Precision',\n    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n    xaxis=dict(constrain='domain'),\n#     width=700, height=500\n)\nfig.show()    \n    \n","19af7e9a":"from sklearn.ensemble import VotingClassifier\n\neclf = VotingClassifier(estimators=[('RF', best_rf),\n                                    ('SVC', best_svc),\n                                    ('BC', best_bc),\n                                    ('XGB', best_xgb), \n                                    ('LGBM', best_lgbm)], \n                        voting='hard')\n\neclf_hard_p = Pipeline(steps=[('sc', StandardScaler()),\n                              ('eclf', eclf)])\n\neclf_hard_p.fit(X_train, y_train)\n\nresults = []\n\ntry:\n    for label, m in tuned_models:\n        print('-'*20)\n        print(label)\n        scores = evaluate_model(m, X_test, y_test)\n        results.append(scores)\n        display_scores(scores)\nexcept Exception as e:\n    print(e)\n    \nsave_submission(eclf, test_data, 'ensemble_hard')","6ab7cf95":"eclf = VotingClassifier(estimators=[('RF', best_rf),\n                                    ('SVC', best_svc),\n                                    ('BC', best_bc),\n                                    ('XGB', best_xgb), \n                                    ('LGBM', best_lgbm)], \n                        voting='soft')\n\neclf_soft_p = Pipeline(steps=[('sc', StandardScaler()),\n                              ('eclf', eclf)])\neclf_soft_p.fit(X_train, y_train)\n\nresults = []\n\nfor label, m in tuned_models:\n    print('-'*20)\n    print(label)\n    scores = evaluate_model(m, X_test, y_test)\n    results.append(scores)\n    display_scores(scores)\n    \nsave_submission(eclf, test_data, 'ensemble_soft')","8f9eff5c":"plt.boxplot(results, labels=names, showmeans=True)\nplt.title('ROC-AUC Scores')\nplt.grid()\nplt.show()","d3c03102":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset","856d0ddc":"# Splitting the data\nX = train_data.iloc[:, 1:].values\ny = train_data.iloc[:, 0].values\n\nX_train, X_test, y_train, y_test =\\\n    train_test_split(X, y, test_size=0.15, stratify=y , random_state=25)\n\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)\n\n\nprint(len(X_train), len(X_test))\nprint(X_train_sc.mean(), X_train_sc.std())\nprint(X_test_sc.mean(), X_test_sc.std())","ed336488":"sns.countplot(y_test)","65f6b91d":"X_train_t = torch.from_numpy(X_train_sc.astype(np.float32))\nX_test_t = torch.from_numpy(X_test_sc.astype(np.float32))\ny_train_t = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\ny_test_t = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))\n\ntrain_ds = TensorDataset(X_train_t, y_train_t)\nvalid_ds = TensorDataset(X_test_t, y_test_t)\n\ntrain_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=128, shuffle=False)","18eb33f5":"class ModelANN(nn.Module):\n    def __init__(self, n_in, n_h, n_out):\n        super(ModelANN, self).__init__()\n        self.n_out = n_out\n\n        self.fc1 = nn.Linear(n_in, n_h)\n        self.bn1 = nn.BatchNorm1d(n_h)\n        self.fc2 = nn.Linear(n_h, n_h)\n        self.bn2 = nn.BatchNorm1d(n_h)\n        self.fc3 = nn.Linear(n_h, n_h)\n        self.bn3 = nn.BatchNorm1d(n_h)\n        self.fc4 = nn.Linear(n_h, n_h)\n        self.bn4 = nn.BatchNorm1d(n_h)\n        self.output = nn.Linear(n_h, n_out)\n\n    def forward(self, x):\n        x = self.bn1(self.fc1(x))\n        x = F.leaky_relu(x)\n        x = F.dropout(x, 0.4)\n        x = self.bn2(self.fc2(x))\n        x = F.leaky_relu(x)\n        x = F.dropout(x, 0.3)\n        x = self.bn3(self.fc3(x))\n        x = F.leaky_relu(x)\n        x = F.dropout(x, 0.3)\n        x = self.bn4(self.fc4(x))\n        x = F.leaky_relu(x)\n        x = self.output(x)\n        return x\n\n        \n#         for layer in model.children(): \n#             if layer.out_features == self.n_out:\n#                 return layer(x)\n#             else:\n#                 x = F.relu(layer(x))\n#                 x = F.dropout(x, p=0.55)\n\n","fdfadaf5":"# To initialize weights\ndef weights_init(m):\n    if isinstance(m, nn.Linear):\n#         nn.init.kaiming_normal_(m.weight.data)\n#         nn.init.kaiming_uniform_(m.weight.data)\n#          nn.init.xavier_uniform_(m.weight.data)\n         n = m.in_features\n         y = 1.0\/np.sqrt(n)\n         m.weight.data.uniform_(-y, y)\n#          nn.init.xavier_normal_(m.weight.data)\n         m.bias.data.fill_(0.01)","59abad34":"def accuracy(outputs, targ):\n    preds = outputs > 0.0\n    return torch.tensor(torch.sum(preds == targ).item()\/ targ.size()[0])\n    ","7cc501e3":"def train(model, criterion, optimizer, train_dl, valid_dl, epochs=10):\n    train_losses, val_losses = np.zeros(epochs), np.zeros(epochs)\n    train_accs, val_accs = np.zeros(epochs), np.zeros(epochs)\n    best_acc = 0.\n    \n    for epoch in range(epochs):\n        tot_train_loss, tot_val_loss = [], []\n        tot_train_acc, tot_val_acc = [], []\n        \n        model.train()\n        for x_batch, y_batch in train_dl:\n            \n            # Move data to device\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n            # Reset gradients\n            optimizer.zero_grad()\n            \n            # Forward step\n            outputs = model(x_batch)\n            loss = criterion(outputs, y_batch)\n            tot_train_loss.append(loss.item())\n            tot_train_acc.append(accuracy(outputs, y_batch))\n            \n            # Backward step\n            loss.backward()  # Calculate the gradients\n#             print(model.fc6.weight.grad)  # To check the gradients of the output\n#             print(model.fc1.weight.grad)  # To check the gradients of the first layer\n            optimizer.step()  # Update the parameters\n            \n\n            \n        # Validation Loss\/Accuracy\n        model.eval()\n        with torch.no_grad():\n            for x_batch, y_batch in valid_dl:\n                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n                outputs = model(x_batch)\n                loss = criterion(outputs, y_batch)\n                tot_val_loss.append(loss.item())\n                tot_val_acc.append(accuracy(outputs, y_batch))\n\n            \n        # Save epoch loss\n        tot_train_loss = np.mean(tot_train_loss)\n        tot_val_loss = np.mean(tot_val_loss)\n        \n        train_losses[epoch] = tot_train_loss\n        val_losses[epoch] = tot_val_loss\n    \n        # save epoch accuracy\n        tot_train_acc = np.mean(tot_train_acc)\n        tot_val_acc = np.mean(tot_val_acc)\n        train_accs[epoch] = tot_train_acc\n        val_accs[epoch] = tot_val_acc\n\n        if (tot_val_acc > best_acc) and (tot_val_acc - best_acc) > 1e-2:\n            best_acc = tot_val_acc\n            print(f'Saving model with accuracy: {best_acc}')\n            torch.save(model, f'best-model-torch-{best_acc:.2f}.pt') \n            \n        if (epoch+1)%20 == 0:\n            print('-'*20)\n            print(f'Epoch: {epoch+1}\/{epochs}')\n            print(f'train_loss: {tot_train_loss:.4f}, train_acc: {tot_train_acc:.4f}, val_loss: {tot_val_loss:.4f}, val_acc: {tot_val_acc:.4f}')\n    \n    return train_losses, val_losses, train_accs, val_accs\n\n","59076168":"# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# print(device)\n\n# n_hid = 64\n# k = 1\n\n# model = ModelANN(X_train_t.shape[1], n_hid, k)\n# model.apply(weights_init)\n# model.to(device)\n        ","106c522f":"# criterion = nn.BCEWithLogitsLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","3d336474":"\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nn_hid = 8\nk = 1\n\n# Create model and send it to device\nmodel = ModelANN(X_train_t.size(1), n_hid, k)\nmodel.apply(weights_init)\nmodel.to(device)\n\ntorch.backends.cudnn.benchmark = True\n\n#Loss and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.RMSprop(model.parameters(),\n                                lr=0.003, \n                                momentum=0.99)\n#                                 weight_decay=0.01)\n\ntrain_losses, val_losses,\\\n     train_accs, val_accs = train(model, \n                                  criterion, \n                                  optimizer,\n                                  train_dl, valid_dl, \n                                  epochs=1000)\n\nx_valid, y_valid = valid_ds.tensors\ny_pred = model(x_valid.to(device)) > 0.\nprint('-'*20)\nprint(confusion_matrix(y_valid, y_pred))\nprint(classification_report(y_valid, y_pred))\nprint('-'*20)\n\nplt.plot(train_losses, ls='--', label='train-loss')\nplt.plot(val_losses, label='val-loss')\nplt.legend()\n\n\n","1e887eac":"from glob import glob\nfiles = glob('best-model-torch-*')\n\nbest_models = [m for m in files if float(m.split('-')[3][0:4]) >= 0.8]\nprint(best_models)\n\nfor m in best_models:\n    best_torch_model = torch.load(m)\n\n    with torch.no_grad():\n        outputs = best_torch_model(X_test_t.to(device))\n        y_pred = (outputs > 0.).cpu().numpy()\n    \n    print('-'*20)\n    print(m)\n    print(confusion_matrix(y_test_t, y_pred))\n    print(classification_report(y_test_t, y_pred))\n    print('-'*20)","1331cb2b":"# # # Remove old files\n# import os\n# from glob import glob\n# files = glob('best-model-torch-*')\n# for f in files:\n#     os.remove(f)","89a85f43":"best_torch_model = torch.load(best_models[-1])\ntry:\n    test_data_sc = sc.transform(test_data.iloc[:, 1:].values)\n    with torch.no_grad():\n        outputs = best_torch_model(torch.from_numpy(test_data_sc.astype(np.float32)).to(device))\n        y_pred = (outputs > 0).cpu().numpy().astype(int).reshape(-1,)\n\n\n    submission = {'PassengerId': test.PassengerId, \n                  'Survived': y_pred}\n    submission = pd.DataFrame(data=submission)\n    submission.to_csv('nn_submission.csv', index=False)\nexcept Exception as e:\n    print('Submission not saved', e)\n\n","8bc55366":"<span style=\"color:red\">Note<\/span>: Default numeric type in PyTorch is 32-bit floating-point, while for Numpy arrays it is 64-bit. So we need to make sure we have tensors of dtype float32 after converting","071cfc77":"### Setting up the device and move the model","5947d40c":"## Label encoding and dummy variables","eb731e8d":"# PyTorch","1f75afdf":"### Setting up the model","9f1db1cc":"Correlation Matrix","e1b24ad0":"## Results for the first stage","f254e6d2":"## Supporting functions","ec985bd0":"## Training the models\n\nFirst, we are going to train some baseline models to get a better idea of which model works better for our data","fba84eb3":"## Optimizing LightGBM ","4e65253c":"## Optimizing BaggingClassifier with Decision Tree as base estimator","64032eb1":"## Metrics","0da468ff":"### Extracting title from Name column","fe4a187b":"### Extracting family size","0471e713":"## Votting Classifier\n\nThe idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.\nhttps:\/\/scikit-learn.org\/stable\/modules\/ensemble.html#voting-classifier","78e86533":"### Accuracy metric","9ced0b5f":"## Split to train test again","3431a092":"## Dealing with missing values","e2355471":"### Weights Initialization","034012d8":"## Optimizing SVC","9025c088":"# Hyperparameter optimization with Optuna","289aadd3":"# Feature Engineering","ec918799":"### Evaluating BC","f1e0aca3":"### Train Loop","b323c0b7":"## Cabin - Simplify cabins","bb02da73":"## Optimizing XGBoost\n[Example](https:\/\/github.com\/optuna\/optuna\/blob\/master\/examples\/pruning\/xgboost_integration.py)","f37019a9":"## Feature transformation","1e6115c8":"Now, let's try if we can improve the scores for Random Forest, BaggingClassifier, SVC, XGBoost and LightGBM using Hyperparameters Optimization.\n\nWe are going to use Optuna for this. [Optuna](https:\/\/optuna.readthedocs.io\/en\/stable\/index.html) is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user AP\n\nOptuna uses Tree-structured Parzen Estimater (TPE), which is a form of Bayesian Optimization to search more efficiently than a random search, by choosing points closer to previous good results.","ea0c9a94":"## Precision-Recall Curve for the tuned models","19184c20":"## Titanic Project \n\nThis is my first notebook just for fun, I followed most of the procedures for EDA described in https:\/\/www.kaggle.com\/kenjee\/titanic-project-examplede by KenJee, and added extra work for modeling comparing and the use PyTorch. I'll keep adding and fixing things so I hope this is useful for someone.\n","efbc4edf":"### Evaluating SVC","846631cf":"### Evaluating LGBM","a273f58c":"### Loss function and optimizer\n","582b41b3":"# EDA","d94411cb":"### Setting up the data generators","37df2309":"### Evaluating RF","5af968bc":"### Load best models","58f82b17":"### Log transformation [Fare]","1f5f426a":"### RandomSearch [Optional]","f49d774a":"## Ticket values","af01aa14":"### Check for missing values","b55fe59e":"### Interactive ROC\/PR Curves","11501b37":"Potential outliers","9fb67988":"### Combine sex-age","7f3a44ab":"### Train the model","24c07d62":"## Optimizing Random Forest\n\nFirst, we need to define our objective function that we want to optimize. ","30a5a8a9":"# Implementation of the models\n"}}