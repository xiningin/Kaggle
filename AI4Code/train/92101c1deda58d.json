{"cell_type":{"4c560b21":"code","e5a4e53a":"code","0d5e6d15":"code","2c5703e5":"code","a31476f5":"code","0a7fca52":"code","717dac05":"code","8630ade0":"code","2dea980c":"code","4f67f0be":"code","289c16dc":"code","cbfb4e38":"code","ac5b30ca":"code","dbafd438":"code","c7188b17":"code","f523c0b6":"code","6f40a39f":"code","2fc05087":"code","7cb11bb2":"code","dcae142b":"code","b46bc601":"code","52999c74":"code","3bec4886":"code","cccabb84":"code","b904e1aa":"code","5857a72c":"code","9fed8201":"code","9a08b2e6":"code","db691a8e":"code","f579707c":"code","856b71fc":"code","36c8ae1a":"code","155d8cd4":"code","caa378c8":"code","48b06e1b":"code","80d7ad33":"code","3c0df9b6":"code","b37a2b56":"code","1fdafcf1":"code","8229bc9c":"code","cfd41bb2":"code","f906c650":"code","c68a1530":"code","1c039a86":"code","c64ceeb6":"code","aa84457d":"code","c9f579d9":"code","2b5f5e8d":"code","6133da5b":"code","8db77ff6":"code","ad87850a":"code","90bfd263":"code","1c368f3f":"code","21115206":"code","a245af37":"code","6bac822e":"code","a2e1d579":"code","21b165fc":"code","ba968980":"code","d1991d90":"code","039a2fb0":"code","689321fe":"code","5e76d978":"code","ac1a22dc":"code","29b33374":"code","b5e60396":"code","420793f0":"code","d63753df":"code","b51be69a":"code","c4a148bd":"code","e84d6612":"code","dfeb31d0":"code","cd5b0803":"code","098c1231":"code","6a1a44ec":"code","4de7ea3a":"code","02b8fafe":"code","926ad890":"code","e7a95dd3":"code","8a4b25f4":"code","61aa5479":"code","c8f167da":"code","6cb0d145":"code","8cdcbcc5":"code","0c419add":"code","b4888112":"code","a257cf90":"code","f1c405e7":"code","d747ed56":"code","f416adb3":"code","2361b692":"code","ea8040d2":"code","f1f8d7be":"code","8fbaab29":"markdown","5a5b823d":"markdown","273b6e3b":"markdown","be6c547f":"markdown","a152d0f7":"markdown","5cfabe52":"markdown","3cdd11c0":"markdown","c2300bab":"markdown","8d153a6e":"markdown","ad962f2d":"markdown","48b2d5c3":"markdown","0ed143f3":"markdown","f93b9884":"markdown","8478e1a7":"markdown","8026c92d":"markdown","e78fbbab":"markdown","79da6074":"markdown","0267cf58":"markdown","e1933682":"markdown","b33742b2":"markdown","a0cf5088":"markdown","6a544cca":"markdown","0be0ae40":"markdown","ec42c55b":"markdown","9471c51a":"markdown","86912f0a":"markdown","9c9f9dce":"markdown","3604fefa":"markdown","a82d437d":"markdown","46851dae":"markdown","aeaca4cd":"markdown","4b85bae7":"markdown","5454562c":"markdown","e4f7ec68":"markdown","5c30b410":"markdown","cd6918e3":"markdown","499674e7":"markdown","f0722cc0":"markdown","c4cd69b2":"markdown","fe0b8717":"markdown","58a1fee0":"markdown","e968fb75":"markdown","4c814077":"markdown","d591e3f5":"markdown","3d8a4e59":"markdown","cb2854be":"markdown","070c21c2":"markdown","2e46c4c7":"markdown","53d01668":"markdown","18b550f8":"markdown","e36b8a1d":"markdown","582d1a7e":"markdown","36f58d4f":"markdown","a6cdbdb8":"markdown","86b796dd":"markdown","90af3af4":"markdown","8d7e0c7c":"markdown","e8f8e1dc":"markdown","4eaf8c74":"markdown","ca371ae2":"markdown","36d57891":"markdown","1b69af89":"markdown","a81a8924":"markdown","3dc31541":"markdown","e0431ccb":"markdown","e3e06f39":"markdown","bf3f0fe4":"markdown","004c43c3":"markdown","215b76bb":"markdown","ca759155":"markdown","46258807":"markdown","64fb7868":"markdown","e499af9b":"markdown"},"source":{"4c560b21":"#!pip install optuna","e5a4e53a":"# Data Wrangling and Data Analysis\n\nimport pandas as pd , numpy as np\n\n# Visualization\n\nfrom matplotlib import pyplot as plt, style\nimport seaborn as sns\nimport plotly\nfrom yellowbrick.model_selection import ValidationCurve\n\n\n# Feature Engineering \/ Feature Selection\n\nfrom sklearn.feature_selection import mutual_info_regression, VarianceThreshold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nimport scipy.stats as stats\nfrom category_encoders import TargetEncoder, OneHotEncoder, OrdinalEncoder, CatBoostEncoder, LeaveOneOutEncoder, GLMMEncoder\nfrom sklearn import base\nfrom sklearn.model_selection import validation_curve, learning_curve\nimport optuna\nfrom optuna import Trial, visualization\nfrom optuna.samplers import TPESampler\nfrom optuna.pruners import HyperbandPruner\nfrom functools import partial\n\n\n# Model Building\n\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\n\n# Ignore Warings\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0d5e6d15":"# Train Data\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\n\n#Test Data\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n\n# Submission\n\nsubmission = test['Id']\n\n# Set Index\n\nfor df in [train, test]:\n    df.drop(columns='Id', inplace = True)\n\n\n# View data\ntrain.head()","2c5703e5":"for i in train.columns:\n    if i not in test.columns:\n        print(\"Target Variable : \",i)","a31476f5":"print(\"Train Shape : \",train.shape)\nprint(\"Test Shape : \",test.shape)","0a7fca52":"train.info()","717dac05":"obj_col = list(train.select_dtypes(np.object).columns)\nint_col = list(train.select_dtypes(np.int64).columns)\nfloat_col = list(train.select_dtypes(np.float64).columns)\n\nprint(\"object Columns : \\n\\n\",obj_col,\"\\n\\n\")\nprint(\"Integer Columns : \\n\\n\",int_col,\"\\n\\n\")\nprint(\"Float Columns : \\n\\n\",float_col)","8630ade0":"print(\"object Columns Count : \",len(obj_col))\nprint(\"Integer Columns Count : \",len(int_col))\nprint(\"Float Columns Count :\",len(float_col))","2dea980c":"null_obj_cols = train[obj_col].isna().sum()\/train[obj_col].shape[0]*100\nnull_obj_cols","4f67f0be":"null_obj_cols[null_obj_cols > 15.0]","289c16dc":"# Getting Unique Values\ntrain.PoolQC.unique()","cbfb4e38":"train.PoolQC.fillna('No Pool',inplace = True)","ac5b30ca":"style.use('seaborn-whitegrid')\ntrain.PoolQC.value_counts().plot(kind='bar',figsize = (8, 4), color = 'royalblue', edgecolor = 'k', linewidth = 3)\nplt.title('Count for Pool Quality')\nplt.xticks([0,1,2,3],['No Pool','Good',\"Excellent\",'Fair'],rotation=0)\nplt.show()","dbafd438":"# Plotting Significance of PoolQC with Respect to SalesPrice\n\nplt.figure(figsize=(8,4))\nsns.barplot(x = train.PoolQC, y = train.SalePrice)\nplt.show()","c7188b17":"# Checking For Qutliers \n\nplt.figure(figsize=(10,6))\nsns.boxplot(x = train.PoolQC, y = train.SalePrice).set_title('Outliers in Pool Quality')\nplt.show()","f523c0b6":"# Function For Creating new Feature\n\ndef create(val):\n    if val ==\"Ex\" or val == \"Fa\" or val == \"Gd\":\n        return(1)\n    else:\n        return(0)","6f40a39f":"# Creating isPool Feature in train and test\n\nfor df in [train,test]:\n    df['isPool'] = df.PoolQC.apply(create)\n\ntrain.isPool.unique()","2fc05087":"train.isPool.value_counts().plot(kind='bar',figsize = (8, 4), color = 'royalblue', edgecolor = 'k', linewidth = 3)\nplt.title('Count for isPool')\nplt.xticks([0,1],['No Pool','Pool'],rotation=0)\nplt.show()","7cb11bb2":"# Plotting Significance of PoolQC with Respect to SalesPrice\n\nplt.figure(figsize=(8,4))\nsns.barplot(x = train.isPool, y = train.SalePrice).set_title('Significance of isPool in Prediction of House Price')\nplt.show()","dcae142b":"# Checking For Correlation\n\nplt.figure(figsize=(18,6))\n\nplt.subplot(1,2,1)\nsns.barplot(x = train.LandSlope, y = train.SalePrice, hue = train.PoolQC).set_title('SalePrice with respect to Landslope and Pool Quality')\n\nplt.subplot(1,2,2)\nsns.barplot(x = train.LandSlope, y = train.SalePrice, hue = train.isPool).set_title('SalePrice with respect to Landslope and isPool')\n\nplt.tight_layout(pad=3.0)\nplt.show()","b46bc601":"# Checking For Correlation\n\nplt.figure(figsize=(18,6))\nplt.tight_layout(pad=3.0)\n\nplt.subplot(1,2,1)\nsns.barplot(x = train.LotConfig, y = train.SalePrice, hue = train.PoolQC).set_title('SalePrice with respect to plot location  and Pool Quality')\n\nplt.subplot(1,2,2)\nsns.barplot(x = train.LotConfig, y = train.SalePrice, hue = train.isPool).set_title('SalePrice with respect to plot location  and Pool Quality')\n\nplt.show()","52999c74":"# Checking For Correlation\n\nplt.figure(figsize=(10,6))\nplt.show()","3bec4886":"# Checking For Correlation\n\nplt.figure(figsize=(18,6))\nplt.tight_layout(pad=3.0)\n\nplt.subplot(1,2,1)\nsns.barplot(x = train.MSZoning, y = train.SalePrice, hue = train.PoolQC).set_title('SalePrice with respect to Zone type  and Pool Quality')\n\nplt.subplot(1,2,2)\nsns.barplot(x = train.MSZoning, y = train.SalePrice, hue = train.isPool).set_title('SalePrice with respect to Zone type  and isPool')\nplt.ylim(0,750000)\n\nplt.show()","cccabb84":"# Checking For Correlation\n\nplt.figure(figsize=(18,6))\nplt.tight_layout(pad=3.0)\n\n\nplt.subplot(1,2,1)\nsns.barplot(x = train.BldgType, y = train.SalePrice, hue = train.PoolQC).set_title('SalePrice with respect to Building type  and Pool Quality')\n\nplt.subplot(1,2,2)\nsns.barplot(x = train.BldgType, y = train.SalePrice, hue = train.isPool).set_title('SalePrice with respect to Building type  and IsPool')\nplt.ylim(0,750000)\n\nplt.show()","b904e1aa":"# Checking For Correlation\n\nplt.figure(figsize=(18,6))\nplt.tight_layout(pad=3.0)\n\nplt.subplot(1,2,1)\nsns.barplot(x = train.HouseStyle, y = train.SalePrice, hue = train.PoolQC).set_title('SalePrice with respect to Housing Style  and Pool Quality')\n\nplt.subplot(1,2,2)\nsns.barplot(x = train.HouseStyle, y = train.SalePrice, hue = train.isPool).set_title('SalePrice with respect to Housing type  and IsPool')\nplt.ylim(0,750000)\n\nplt.show()","5857a72c":"# Getting Unique Values\ntrain.Fence.unique()","9fed8201":"train.Fence.fillna('No Fence',inplace = True)","9a08b2e6":"train.Fence.value_counts().plot(kind='bar',figsize = (8, 4), color = 'royalblue', edgecolor = 'k', linewidth = 3)\nplt.title('Count for Fence Quality')\nplt.xticks([0,1,2,3,4],['No fence','Minimum Privacy',\"Good wood\",'GoodPrivacy','Minimum Wood\/wire'],rotation=0)\nplt.show()","db691a8e":"# Plotting Significance of Fence with Respect to SalesPrice\n\nplt.figure(figsize=(8,4))\nsns.barplot(x = train.Fence, y = train.SalePrice).set_title('Significance of Fence in Prediction of House Price')\nplt.show()","f579707c":"# Checking For Qutliers \n\nplt.figure(figsize=(10,6))\nsns.boxplot(x = train.Fence, y = train.SalePrice).set_title('Outliers in Fence')\nplt.show()","856b71fc":"# Function For Creating new Feature\n\ndef create(val):\n    if val ==\"MnPrv\" or val == \"GdWo\" or val == \"GdPrv\" or val == \"MnWw\":\n        return(1)\n    else:\n        return(0)","36c8ae1a":"# Creating isPool Feature in train and test\n\nfor df in [train,test]:\n    df['isFence'] = df.Fence.apply(create)\n\ntrain.isFence.unique()","155d8cd4":"\ntrain.isFence.value_counts().plot(kind='bar',figsize = (8, 4), color = 'royalblue', edgecolor = 'k', linewidth = 3)\nplt.title('Count for isFence')\nplt.xticks([0,1],['No Fence','Fence'],rotation=0)\nplt.show()","caa378c8":"# Plotting Significance of Fence with Respect to SalesPrice\n\nplt.figure(figsize=(8,4))\nsns.barplot(x = train.isFence, y = train.SalePrice).set_title('Significance of isFence in Prediction of House Price')\nplt.show()","48b06e1b":"fig, axes = plt.subplots(3, 2, figsize=(16, 16), sharey=True)\nfig.suptitle('SalePrice Correlation with Fence and Various Features',fontsize=20)\nfig.tight_layout(pad=4.0)\n\n# Correlation between Sales Price with respect to landslope and Fence\nsns.barplot(ax=axes[0,0], x = train.LandSlope, y = train.SalePrice, hue = train.Fence)\naxes[0,0].set_title('SalePrice with respect to Landslope and Fence',fontsize=15)\n\n# Correlation between Sales Price with respect to landslope and isFence\nsns.barplot(ax=axes[0,1],  x = train.LandSlope, y = train.SalePrice, hue = train.isFence)\naxes[0,1].set_title('SalePrice with respect to Landslope and isFence',fontsize=15)\n\n# Correlation between Sales Price with respect to MSZoning and Fence\nsns.barplot(ax=axes[1,0],  x = train.MSZoning, y = train.SalePrice, hue = train.Fence)\naxes[1,0].set_title('SalePrice with respect to MSZoning and Fence',fontsize=15)\n\n# Correlation between Sales Price with respect to MSZoning and isFence\nsns.barplot(ax=axes[1,1],  x = train.MSZoning, y = train.SalePrice, hue = train.isFence)\naxes[1,1].set_title('SalePrice with respect to MSZoning and isFence',fontsize=15)\n\n# Correlation between Sales Price with respect to Functional and Fence\nsns.barplot(ax=axes[2,0],x = train.Functional, y = train.SalePrice, hue = train.Fence)\naxes[2,0].set_title('SalePrice with respect to Functional and Fence',fontsize=15)\n\n# Correlation between Sales Price with respect to Housing and isFence\nsns.barplot(ax=axes[2,1],x = train.HouseStyle, y = train.SalePrice, hue = train.Fence)\naxes[2,1].set_title('SalePrice with respect to HousingStyle and Fence',fontsize=15)\n\nplt.show()","80d7ad33":"# Get the column names \n\nnull_obj_cols = train[obj_col].isna().sum()\/train[obj_col].shape[0]*100\nlist(null_obj_cols[null_obj_cols > 15.0].index)","3c0df9b6":"for df in [train,test]:\n    df['Alley'].fillna('No Alley',inplace=True)\n    df['FireplaceQu'].fillna('No Fireplace',inplace=True)\n    df['MiscFeature'].fillna('No MiscFeature',inplace=True)\n    \n            \n# Check for Unique Values\n\nfor column in ['Alley', 'FireplaceQu', 'MiscFeature']:\n    print(\"\\n\",column,'Uniques : ',train[column].unique())","b37a2b56":"# Check for Null Values > 15 %\n\nnull_obj_cols = train[obj_col].isna().sum()\/train[obj_col].shape[0]*100\nnull_obj_cols[null_obj_cols > 15.0]","1fdafcf1":"# Function For Creating isAlley\n\nfor df in [train, test]:\n    df['isAlley'] = df.Alley.apply(lambda x: 0 if x == \"No Alley\" else 1)\n    df['isFireplaceQu'] = df.FireplaceQu.apply(lambda x: 0 if x == \"No Fireplace\" else 1)\n    df['isMiscFeature'] = df.MiscFeature.apply(lambda x: 0 if x == \"No MiscFeature\" else 1)\n    \n\n# Check for Unique Values\n\nfor column in ['isAlley', 'isFireplaceQu', 'isMiscFeature']:\n    print(\"\\n\",column,'Uniques : ',train[column].unique())\n\nprint(\"\\n\\n\")\n# Check for Value counts\n\nfor column in ['isAlley', 'isFireplaceQu', 'isMiscFeature']:\n    print(train[column].value_counts(),\"\\n\")","8229bc9c":"fig, axes = plt.subplots(3, 2, figsize=(15, 15), sharey=False)\nfig.suptitle('Value Counts of Features',fontsize=20,)\nfig.tight_layout(pad=4.0)\nfig.subplots_adjust(top=0.9)\nprint(\"\\n\")\n# Count of  Alley\nsns.countplot(ax=axes[0,0], x = train.Alley)\naxes[0,0].set_title('Alley',fontsize=15)\n\n# Count of  isAlley\nsns.countplot(ax=axes[0,1], x = train.isAlley)\naxes[0,1].set_title('isAlley',fontsize=15)\n\n# Count of FireplaceQu\nsns.countplot(ax=axes[1,0], x = train.FireplaceQu)\naxes[1,0].set_title('FirePlaceQu',fontsize=15)\n\n# Count of  isFireplaceQu\nsns.countplot(ax=axes[1,1], x = train.isFireplaceQu)\naxes[1,1].set_title('isFirePlaceQu',fontsize=15)\n\n# Count of  MiscFeatures\nsns.countplot(ax=axes[2,0], x = train.MiscFeature)\naxes[2,0].set_title('MiscFeature',fontsize=15)\n\n# Count of  isMiscFeatures\nsns.countplot(ax=axes[2,1], x = train.isMiscFeature)\naxes[2,1].set_title('isMiscFeature',fontsize=15)\n\nplt.show()","cfd41bb2":"fig, axes = plt.subplots(3, 2, figsize=(16, 16), sharey=True)\nfig.suptitle('SalePrice Correlation with Alley and Various Features',fontsize=20)\nfig.tight_layout(pad=4.0)\n\n# Correlation between Sales Price with respect to Alley\nsns.barplot(ax=axes[0,0], x = train.Alley, y = train.SalePrice)\naxes[0,0].set_title('SalePrice with respect to Alley',fontsize=15)\n\n# Correlation between Sales Price with respect isAlley\nsns.barplot(ax=axes[0,1],  x = train.isAlley, y = train.SalePrice)\naxes[0,1].set_title('SalePrice with respect to isAlley',fontsize=15)\n\n# Correlation between Sales Price with respect FireplaceQu\nsns.barplot(ax=axes[1,0],  x = train.FireplaceQu, y = train.SalePrice)\naxes[1,0].set_title('SalePrice with respect FireplaceQu',fontsize=15)\n\n# Correlation between Sales Price with respect isFirePlaceQu\nsns.barplot(ax=axes[1,1],  x = train.isFireplaceQu, y = train.SalePrice)\naxes[1,1].set_title('SalePrice with respect isFirePlaceQu',fontsize=15)\n\n# Correlation between Sales Price with respect to MiscFeatures\nsns.barplot(ax=axes[2,0],x = train.MiscFeature, y = train.SalePrice)\naxes[2,0].set_title('SalePrice with respect to MiscFeature',fontsize=15)\n\n# Correlation between Sales Price with respect to isMiscFeatures\nsns.barplot(ax=axes[2,1],x = train.isMiscFeature, y = train.SalePrice)\naxes[2,1].set_title('SalesPrice with respect to isMiscFeatures',fontsize=15)\n\nplt.show()","f906c650":"# outliers\nsns.boxplot(x = train.isMiscFeature, y = train.SalePrice)\nplt.show()","c68a1530":"null_obj_cols = train[obj_col].isna().sum()\/train[obj_col].shape[0]*100\nnull_obj_cols[null_obj_cols > 0.0]","1c039a86":"for df in [train,test]:\n    df[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']] = df[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].fillna('No Basement')\n    df[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']] = df[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']].fillna('No Garage')\n    df['MasVnrType'].fillna('No Wall', inplace = True)\n    df['Electrical'].fillna(train.Electrical.mode()[0], inplace = True)","c64ceeb6":"#Check for Unique Values\n\nfor column in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n               'MasVnrType','Electrical']:\n    print(\"\\n\",column,'Uniques : ',train[column].unique())","aa84457d":"# Confirm the Null Percentage for Object Columns \n\nnull_obj_cols = train[obj_col].isna().sum()\/train[obj_col].shape[0]*100\nnull_obj_cols[null_obj_cols > 0.0]","c9f579d9":"for df in [train, test]:\n    df['isGarage'] = df['GarageType'].apply(lambda x: 0 if x == 'No Garage' else 1)\n    df['isBsmt'] = df['BsmtExposure'].apply(lambda x: 0 if x == 'No Basement' else 1)\n    df['isMasVnr'] = df['MasVnrType'].apply(lambda x: 0 if x == 'No Wall' else 1)\n \nprint(\"\\n\\n\")\n# Check for Value counts\n\nfor column in ['isGarage', 'isBsmt', 'isMasVnr']:\n    print(train[column].value_counts(),\"\\n\")","2b5f5e8d":"a = 7  # number of rows\nb = 2  # number of columns\nc = 1  # initialize plot counter\nplt.figure(figsize=(15,30))\n\nfor feature in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n               'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','MasVnrType',\n               'Electrical','isGarage', 'isBsmt','isMasVnr']:\n    plt.subplot(a, b, c)\n    sns.barplot(x = train[feature], y = train.SalePrice).set_title(f'SalesPrice Correlation with {feature}',fontsize=15)\n    c = c + 1\nplt.tight_layout(pad = 4.0)\nplt.show()","6133da5b":"# Null Count for Integer Columns\n\ntrain[int_col].isna().sum().any()","8db77ff6":"# Null Count for Float Variables\n\npd.DataFrame({'Missing value Count':train[float_col].isna().sum(),'Missing Value %':(train[float_col].isna().sum()\/train[float_col].shape[0])*100})","ad87850a":"# Missing value with respect to masonry veener type\n\ntrain['MasVnrType'].loc[train['MasVnrArea'].isna()].value_counts()","90bfd263":"# Missing value with respect to Street type\n\ntrain.Street.loc[train.LotFrontage.isna()].value_counts()","1c368f3f":"# Missing Value With Respect to Garage Condition\n\ntrain.GarageCond.loc[train.GarageYrBlt.isna()].value_counts()","21115206":"for df in [train, test]:\n    df['LotFrontage'] = df.groupby('Street')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n    for column in ['MasVnrArea', 'GarageYrBlt']:\n       df[column] = df[column].fillna(0)","a245af37":"# Confirm If any Missing Value Present For whole Data Set\n\ntrain.isna().sum().any()","6bac822e":"Numeric = float_col+int_col\n\ntest_normality = lambda x: stats.shapiro(x.fillna(0))[1] < 0.01\nnormal = pd.DataFrame(train[Numeric])\nnormal = normal.apply(test_normality)\nprint(not normal.any())","a2e1d579":"# Setting Features and Target\n\nfeatures = train.drop(columns=['SalePrice'])\ntarget = train.SalePrice","21b165fc":"# Converting GarageYrBult to int type\n\nfor df in [train, test]:\n    df['GarageYrBlt'] = df['GarageYrBlt'].astype('int64')","ba968980":"# Get the List of Derived Variables\n\nlist(train.columns[train.columns.str.startswith('is')])","d1991d90":"# Set Categorical Variables\n\nfor df in [train, test]:\n    for col in list(train.select_dtypes('object').columns):\n        df[col] = df[col].astype('category')\n    \n#     for col in ['MSSubClass','OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n#                'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','isPool', 'isFence', 'isAlley', 'isFireplaceQu', 'isMiscFeature',\n#        'isGarage', 'isBsmt', 'isMasVnr']:\n#         df[col] = df[col].astype('category')","039a2fb0":"# Store the Categorical Columns In List\n\nCategorical_columns = list(train.select_dtypes('category').columns)","689321fe":"# Leave One Out\nLVE = LeaveOneOutEncoder(verbose = 1,cols = Categorical_columns, random_state=101).fit(features, target)\ntrain_LVE = LVE.transform(features)\ntest_Lve = LVE.transform(test)\ntrain_LVE['SalePrice'] = target\n\n# GLLM\nGLLM = GLMMEncoder(cols = Categorical_columns,random_state=101).fit(features, target)\ntrain_GLLM = GLLM.transform(features)\ntest_GLLM = GLLM.transform(test)\ntrain_GLLM['SalePrice'] = target\n","5e76d978":"plt.figure(figsize=(20,20))\nsns.heatmap(train_LVE.corr(method='spearman'))\nplt.show()","ac1a22dc":"# Creating Threshold Object\nvar_thres = VarianceThreshold(0.001)\n\n\nfeatures_GLLM = train_GLLM.drop(columns=['SalePrice'])\nfeatures_LVE = train_LVE.drop(columns=['SalePrice'])\n\n# Fitting the DataFrame\nvar_thres.fit(features_GLLM)\n\n# Getting column names with zero variance\n\nconstant_columns = [column for column in features_GLLM.columns if column not in features_GLLM.columns[var_thres.get_support()]]\n\nprint(\"Varible with Zero Variance : \",constant_columns)","29b33374":"# Creating a function through which we can select highly correlated features and dropping the first feature that is correlated with any other feature\n\ndef correlation(dataset, threshold):\n    col_corr = set() # Set of all names of correlated columns\n    corr_matrix = dataset.corr() # Correlation Matrix\n    \n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:    # we are interested in absolute coeff value\n                    \n                colname = corr_matrix.columns[i] # getting the name of columns\n                col_corr.add(colname)\n    return(col_corr)\n","b5e60396":"# Getting the Features with High Correlation in GLLM\n\n\ncorr_features = correlation(features_GLLM,0.95) # Setting Threshold as features having correlation above 85%\nprint(\"\\n\")\nprint(\"Correlated Features :\\n \",corr_features)\nprint(\"\\n\")\nprint(\"No. of Features Correlated: \",len(corr_features))\n\n# Dropping the Highly Correlated Features From Train and Test Data set of GLLM\n\nfeatures_GLLM.drop(columns=corr_features, inplace = True)\nfor df in [train_GLLM,test_GLLM]:\n    df.drop(columns=corr_features,inplace = True)","420793f0":"# Check if any correlated features Remaining\nfor name,feat in {\"GLLM\":train_GLLM, \"LVE\":train_LVE}.items():\n    corr_features = correlation(feat,0.95) # Setting Threshold as features having correlation above 85%\n    print(\"\\n\")\n    print(name,\"No. of Features Correlated: \",len(corr_features))\n    print(\"\\n\")","d63753df":"# Defining Kfold With 10 Splits\n\nkf = KFold(n_splits = 10, shuffle = True, random_state = 101)","b51be69a":"# %%time\n\n# from optuna.integration import OptunaSearchCV\n\n# grid_param = {'n_estimators': optuna.distributions.IntUniformDistribution(220,3000,100),\n#                'max_features': optuna.distributions.CategoricalDistribution(['sqrt']),\n#                'max_depth': optuna.distributions.IntLogUniformDistribution(2,90,2),\n#                'min_samples_split': optuna.distributions.IntUniformDistribution(2,6),\n#                'min_samples_leaf': optuna.distributions.IntUniformDistribution(1,3),\n#                'bootstrap': optuna.distributions.CategoricalDistribution([False]),\n#                'criterion': optuna.distributions.CategoricalDistribution(['mse', 'mae'])}\n\n# optuna_search = OptunaSearchCV(estimator=RandomForestRegressor(random_state=101, n_jobs=-1), param_distributions = grid_param,\n#                                cv = kf, n_jobs = -1, n_trials=30, random_state = 101, refit = True,\n#                                scoring = 'neg_root_mean_squared_error', verbose = 3)\n\n# optuna_search.fit(features_GLLM, target)\n\n# optuna_search.best_estimator_\n\n# #optuna_search.best_score_","c4a148bd":"#Creating Model Object\nrfModel = RandomForestRegressor(bootstrap=False, max_depth=21, max_features='sqrt',\n                      min_samples_split=3, n_estimators=2620, n_jobs=-1,\n                      random_state=101)\n\nrfModel.fit(features_GLLM,target)\n\n\nrfModel_Predict = model_selection.cross_val_predict(rfModel,features_GLLM,target,cv=kf,n_jobs=-1)\n\n# Cross Validation Score(Accuracy)\n\nrf_all_score = model_selection.cross_val_score(rfModel,features_GLLM,target,cv=kf,n_jobs=-1,scoring='neg_root_mean_squared_error').mean()\nprint(\"\\n Root Mean Squared Error  : \", rf_all_score,\"\\n\" )\n\nrf_all_r2 = np.round(metrics.r2_score(target,rfModel_Predict),4)*100\nprint(\"\\n R-Squared : \",rf_all_r2)\nprint(\"\\n Mean Absolute Error : \",metrics.mean_absolute_error(target,rfModel_Predict))","e84d6612":"# Get Important Features\n\nlabels = list(features_GLLM.columns)\nfeature_importances = pd.DataFrame({'Importance':rfModel.feature_importances_},index=labels).sort_values(by='Importance',ascending=False)","dfeb31d0":"# Features Having almost zero variance\n\ndrop_zero_var = feature_importances[feature_importances.Importance < 0.001]\ndrop_zero_var","cd5b0803":"# Lets drop Zero Variance Features\n\nfeature_importances = feature_importances[feature_importances.Importance > 0.001]","098c1231":"# lets plot them\n\nfeature_importances.Importance.sort_values(ascending=True).plot(kind='barh', figsize=(20, 20))\nplt.xlabel('Importance')\n\nplt.title(\"Feature Importances\")\nplt.show()\n","6a1a44ec":"# lets plot them\n\n# Features Having almost zero variance\n\nfeature_importances = feature_importances[feature_importances.Importance > 0.005]\n\nfeature_importances.Importance.sort_values(ascending=True).plot(kind='barh', figsize=(12, 8))\nplt.xlabel('Importance')\n\nplt.title(\"Feature Importances\")\nplt.show()\n","4de7ea3a":"Features_sig = train_GLLM[feature_importances.index]","02b8fafe":"# Optuna Search\n\n# %%time\n# optuna_search.fit(Features_sig, target)\n\n# print(optuna_search.best_estimator_)\n\n# print(optuna_search.best_score_)","926ad890":"%%time\n#Creating Model Estimator\n\nrfModel_sig = RandomForestRegressor(bootstrap=False, criterion='mae', max_depth=37,\n                      max_features='sqrt', min_samples_split=3,\n                      n_estimators=1820, n_jobs=-1, random_state=101)\n\n#Fit Model\n\nrfModel_sig.fit(Features_sig,target)\n\nrfModel_Predict_Sig = model_selection.cross_val_predict(rfModel_sig,Features_sig,target,cv=kf,n_jobs=-1)\n\n# Cross Validation Score(RMSE)\n\nrf_sig_score = model_selection.cross_val_score(rfModel_sig,Features_sig,target,cv=kf,n_jobs=-1,scoring='neg_root_mean_squared_error').mean()\nprint(\"\\n Root Mean Squared Error  : \", rf_sig_score,\"\\n\" )\n\nrf_sig_r2 = np.round(metrics.r2_score(target,rfModel_Predict_Sig),4)*100\n\nprint(\"\\n R-Squared : \",rf_sig_r2)\nprint(\"\\n Mean Absolute Error : \",metrics.mean_absolute_error(target,rfModel_Predict_Sig))","e7a95dd3":"from xgboost import XGBRegressor\n\ndef objective(trial, X, y, random_state , n_splits, n_jobs, early_stopping_rounds):\n\n# Param Space\n    params = {\n            \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n            'objective': 'reg:squarederror',\n            'tree_method':'gpu_hist',# Use GPU acceleration\n            'predictor': 'gpu_predictor',\n            'eval_metric' : 'rmse',\n            \"seed\": random_state,\n            'n_jobs': n_jobs,\n            \"alpha\": trial.suggest_loguniform(\"alpha\", 0.01, 10.0),\n            \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n            \"gamma\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n            \"colsample_bytree\": trial.suggest_loguniform(\"colsample_bytree\", 0.2, 0.6),\n            \"subsample\": trial.suggest_loguniform(\"subsample\", 0.5, 0.8),\n            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 0.05),\n            'n_estimators': 4000,\n            'max_depth': trial.suggest_int(\"max_depth\", 1,20,log = True),\n            \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1, 300),\n        }\n\n\n    # Call Back For pruning unpromising trails\n    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation_0-rmse\")\n    model = XGBRegressor(**params)\n    \n    # Defining Kfold Loop Inputs\n    X_values = X.values\n    y_values = y.values\n    metric = []\n    \n    # Cross-Validation Loop:\n\n    for train_index, test_index in kf.split(X_values):\n        X_train, X_test = X_values[train_index, :], X_values[test_index, :]\n        y_train, y_test = y_values[train_index], y_values[test_index]\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_test, y_test)],\n            eval_metric=\"rmse\",\n            verbose=0,\n            callbacks=[pruning_callback],\n            early_stopping_rounds=early_stopping_rounds,\n        )\n        y_pred = model.predict(X_test)\n        \n        # Storing Each Prediction accuracy of Kfold in List\n        metric.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n        \n    metric = np.mean(metric)\n    return (metric)","8a4b25f4":"%%time\n\n# Creating Study\n\nstudy_xgb = optuna.create_study(direction=\"minimize\",pruner=optuna.pruners.HyperbandPruner())\nstudy_xgb.optimize(\n    lambda trial: objective(\n        trial,\n        features_GLLM,\n        target,\n        random_state=101,\n        n_splits=10,\n        n_jobs=-1,\n        early_stopping_rounds=40,\n    ),\n    n_jobs=-1,\n    n_trials=100\n)","61aa5479":"# Calculating the pruned and completed trials\n\npruned_trials = [t for t in study_xgb.trials if t.state == optuna.trial.TrialState.PRUNED]\ncomplete_trials = [t for t in study_xgb.trials if t.state == optuna.trial.TrialState.COMPLETE]\n\nprint(\"  Number of finished trials: \", len(study_xgb.trials))\nprint(\"  Number of pruned trials: \", len(pruned_trials))\nprint(\"  Number of complete trials: \", len(complete_trials))","c8f167da":"print(\"Best Value : \",study_xgb.best_value)\nprint(\"\\n\\n Best Params : \",study_xgb.best_params)","6cb0d145":"# Plotting Trails with best values\nvisualization.plot_optimization_history(study_xgb).show()","8cdcbcc5":"# Plotting best values of each parameters\n\nvisualization.plot_slice(study_xgb).show()","0c419add":"visualization.plot_param_importances(study_xgb)","b4888112":"# Train Model with best params\n\nbest_params = study_xgb.best_params\nbest_params['objective'] = 'reg:squarederror'\nbest_params[\"tree_method\"] = 'gpu_hist'# Use GPU acceleration\nbest_params[\"predictor\"] =  'gpu_predictor'\nbest_params[\"eval_metric\"] = 'rmse'\nbest_params[\"seed\"] =   101\nbest_params[\"n_jobs\"] = -1\nbest_params[\"n_estimators\"] = 10000\n\n# Model With Best Params:\nmodel_xgb = XGBRegressor(**best_params)\n\nc\n# Cross-Validation Loop:\nX_values = features_GLLM.values\ny_values = target.values\n\nprediction_xgb = np.zeros(len(y_values))\n\nfor train_index, test_index in kf.split(X_values):\n    X_train, X_test = X_values[train_index, :], X_values[test_index, :]\n    y_train, y_test = y_values[train_index], y_values[test_index]\n    model_xgb.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_test, y_test)],\n        eval_metric=\"rmse\",\n        verbose=0,\n        early_stopping_rounds=100,\n    )\n    prediction_xgb += model_xgb.predict(X_values)\nprediction_xgb \/= 10\n\nxgb_all_score = np.sqrt(metrics.mean_squared_error(target,prediction_xgb))\nxgb_all_r2 = np.round(metrics.r2_score(target,prediction_xgb),4)*100\n\nprint(\"Root Mean Squared Error : \",xgb_all_score)\nprint(\"R-Squared : \",xgb_all_r2)","a257cf90":"# Getting Optimum Number Of Estimators\n\nprint(\"Optimum Number of n_estimators : \",model_xgb.best_ntree_limit)","f1c405e7":"# Get Important Features\n\nlabels = list(features_GLLM.columns)\nfeature_importances = pd.DataFrame({'Importance':model_xgb.feature_importances_},index=labels).sort_values(by='Importance',ascending=False)","d747ed56":"# lets plot them\n\nfeature_importances.Importance.sort_values(ascending=True).plot(kind='barh', figsize=(20, 20))\nplt.xlabel('Importance')\n\nplt.title(\"Feature Importances\")\nplt.show()\n","f416adb3":"# Checking Model With Best Score\n\nModels = pd.DataFrame({\n    'R-Squared': [rf_all_r2,rf_sig_r2,xgb_all_r2],\n    'RMSE': [rf_all_score,rf_sig_score,xgb_all_score],})\n\nModels.index = ['Random_Forest_All', 'Random_Forest_Sig', 'XGB_ALL']\n\nModels.sort_values(by='RMSE', ascending=False)","2361b692":"# Train Model with best params\n\nbest_params = study_xgb.best_params\nbest_params['objective'] = 'reg:squarederror'\nbest_params[\"tree_method\"] = 'gpu_hist'# Use GPU acceleration\nbest_params[\"predictor\"] =  'gpu_predictor'\nbest_params[\"eval_metric\"] = 'rmse'\nbest_params[\"seed\"] =   101\nbest_params[\"n_jobs\"] = -1\nbest_params[\"n_estimators\"] = 10000\n\n# Model With Best Params:\nmodel_xgb = XGBRegressor(**best_params)\n\n\n# Cross-Validation Loop:\n\nX_values = features_GLLM.values\ny_values = target.values\ntest_X = test_GLLM\nprediction_xgb_final = np.zeros(len(test_X.OverallCond.values))\n\nfor train_index, test_index in kf.split(X_values):\n    X_train, X_test = X_values[train_index, :], X_values[test_index, :]\n    y_train, y_test = y_values[train_index], y_values[test_index]\n    model_xgb.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_test, y_test)],\n        eval_metric=\"rmse\",\n        verbose=0,\n        early_stopping_rounds=100,\n    )\n    prediction_xgb_final += model_xgb.predict(test_X.values)\nprediction_xgb_final \/= 10","ea8040d2":"# Getting Optimum Number Of Estimators\n\nprint(\"Optimum Number of n_estimators : \",model_xgb.best_ntree_limit)","f1f8d7be":"# Save Prediction in Csv File\n\nmy_submission_best = pd.DataFrame({'Id': submission, 'SalePrice': prediction_xgb_final})\n\n# Submit\nmy_submission_best.to_csv('submission.csv', index=False)","8fbaab29":"- Incase of **BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2** are having missing values as these features os basement wont be present if basement itself is not present so we will Replace the *Na with 'No Basement'*\n\n- Incase of **MasVnrType** which actually represents **Masonry veneer walls** consist of a single non-structural external layer of masonry, typically made of **brick, stone or manufactured stone**. so if Masonry Venner walls are not present obviously the materials used in such walls will have null indication, so we will simply Replace the *Na with 'No Wall'*\n\n- Incase of **Garage(type\/finish,quality\/condition)** Missing values represents that house doesnt have the Garage so we willReplace the *Na with 'No Garage'*\n\n- Incase Of **Electrical** it has true missing value, Lets Impute it with **Mode** of the Feature\n\n<hr>","5a5b823d":"<font color = \"maroon\" size=3px><b>1.1 lets replace **\"nan\"** with **\"No Pool\"** <\/b><\/font>","273b6e3b":"<font color = \"maroon\" size=3px><b>2.6. lets check for correlation with SalePrice<\/b><\/font>","be6c547f":"<font color = \"maroon\" size=3px><b>3.1 Lets Check for Null Values<\/b><\/font>","a152d0f7":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Houses without Fence are having higher variance in prediction of SalesPrice<\/font>\n* <font color = \"red\" size=4px>Which doesnt Explain anything... lets keep this feature for experimental pupose and do further analysis<\/font>\n\n<hr>","5cfabe52":"# Get Important Features","3cdd11c0":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px> 2-Story houses are having most Pools <\/font>\n\n<hr>","c2300bab":"<font color = \"maroon\" size=3px><b>1.4 lets derive new variable IsPool from PoolQc, which states wether house contains Pool or not <\/b><\/font>","8d153a6e":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Lets Look more closely , why these columns are having null values<\/font>\n* <font color = \"red\" size=4px>Lets get data description for above variables<\/font>\n\n\n**PoolQC: Pool quality**           \n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       NA\tNo Pool\n       \n**Fence: Fence quality**\n\t\t\n       GdPrv\tGood Privacy\n       MnPrv\tMinimum Privacy\n       GdWo\tGood Wood\n       MnWw\tMinimum Wood\/Wire\n       NA\tNo Fence\n\t\n    \n**Alley: Type of alley access to property**\n\n       Grvl\tGravel\n       Pave\tPaved\n       NA \tNo alley access\n\t\t\n\n**FireplaceQu: Fireplace quality**\n\n       Ex\tExcellent - Exceptional Masonry Fireplace\n       Gd\tGood - Masonry Fireplace in main level\n       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n       Fa\tFair - Prefabricated Fireplace in basement\n       Po\tPoor - Ben Franklin Stove\n       NA\tNo Fireplace\n       \n**MiscFeature: Miscellaneous feature not covered in other categories**\n\n       Elev   Elevator\n       Gar2    2nd Garage (if not described in garage section)\n       Othr    Other\n       Shed    Shed (over 100 SF)\n       TenC    Tennis Court\n       NA    None\n       \n* <font color = \"red\" size=4px>So basically there's no rating available for misssing feature of house like pool, alley ,fence etc.. and it makes sense right.. why will we rate something which doesnot exist<\/font>\n* <font color = \"red\" size=4px>Lets Replace the Na Values with missing feature name eg. for PoolQC Na = No pool,  and do this for all suh features<\/font>\n\n\n<hr>","ad962f2d":"<font color = \"maroon\" size=4px><b>1. lets learn about PoolQC<\/b><\/font>","48b2d5c3":"<font color = \"#191970\" size=6px><center><b>Data Cleaning and EDA<\/b><\/font>","0ed143f3":"<font color = \"maroon\" size=3px><b>3.2 Applying Different Encoding Types <\/b><\/font>","f93b9884":"<font color = \"maroon\" size=3px><b>3.3 Lets Test For Normality for all Numeric Features<\/b><\/font>","8478e1a7":"<font color = \"maroon\" size=3px><b>2.1. Replace Na for each columns  <\/b><\/font>","8026c92d":"<font color = \"maroon\" size=3px><b>2.5 lets check for correlations for some features with Fence and isFence <\/b><\/font>","e78fbbab":"## XGB Model With Best Parameters","79da6074":"<font color = \"maroon\" size=3px><b>2.4 lets derive new variable IsFence from Fence, which states wether house contains Fence or not <\/b><\/font>","0267cf58":"<font color = \"maroon\" size=4px><b>3. Now its time to deal with Numeric Features<\/b><\/font>","e1933682":" <font size = 1000px color = 'royalblue'><center><b>House Prices - Advanced Regression Techniques<b><\/center><\/font>\n ","b33742b2":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>It makes sense that houses build for single family will have private pools , the rest types of houses won't consider having pools <\/font>\n\n<hr>","a0cf5088":"<font color = \"maroon\" size=3px><b>3.2 Lets Find out the Reason Behind Missing Values <\/b><\/font>","6a544cca":"<font color = \"maroon\" size=4px><b>2. lets learn about Fence<\/b><\/font>","0be0ae40":"<font color = \"#191970\" size=6px><center><b>Import Required Libraries<\/b><\/font>","ec42c55b":"<font color = \"maroon\" size=3px><b>2.1 lets replace **\"nan\"** with **\"No Fence\"** <\/b><\/font>","9471c51a":"<font color = \"#191970\" size=6px><center><b>Data Collection<\/b><\/font>","86912f0a":"- ### Since Data Is not Normally distributed we will use Spearman Correlation as it works well with skewed data","9c9f9dce":"<font color = \"maroon\" size=4px><b>lets check shape of data<\/b><\/font>","3604fefa":"<font color = \"#191970\" size=5px><center><b>Lets Build Model With Significant Variables<\/b><\/font>","a82d437d":"<font color = \"maroon\" size=3px><b>2.3. lets check Null Object Column Counts <\/b><\/font>","46851dae":"<font color = \"maroon\" size=4px><b>lets remove Highly Correlated Features <\/b><\/font>","aeaca4cd":"<font color = \"maroon\" size=3px><b>1.4 lets see correlation between LandSlope and PoolQc <\/b><\/font>","4b85bae7":"<hr>\n\n# <u>Problem Statement<\/u> : -\n\n\n* Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\n* With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home..\n\n# Data Description : -\nMSSubClass: Identifies the type of dwelling involved in the sale.\t\n\n        20\t1-STORY 1946 & NEWER ALL STYLES\n        30\t1-STORY 1945 & OLDER\n        40\t1-STORY W\/FINISHED ATTIC ALL AGES\n        45\t1-1\/2 STORY - UNFINISHED ALL AGES\n        50\t1-1\/2 STORY FINISHED ALL AGES\n        60\t2-STORY 1946 & NEWER\n        70\t2-STORY 1945 & OLDER\n        75\t2-1\/2 STORY ALL AGES\n        80\tSPLIT OR MULTI-LEVEL\n        85\tSPLIT FOYER\n        90\tDUPLEX - ALL STYLES AND AGES\n       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n       150\t1-1\/2 STORY PUD - ALL AGES\n       160\t2-STORY PUD - 1946 & NEWER\n       180\tPUD - MULTILEVEL - INCL SPLIT LEV\/FOYER\n       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n\nMSZoning: Identifies the general zoning classification of the sale.\n\t\t\n       A\tAgriculture\n       C\tCommercial\n       FV\tFloating Village Residential\n       I\tIndustrial\n       RH\tResidential High Density\n       RL\tResidential Low Density\n       RP\tResidential Low Density Park \n       RM\tResidential Medium Density\n\t\nLotFrontage: Linear feet of street connected to property\n\nLotArea: Lot size in square feet\n\nStreet: Type of road access to property\n\n       Grvl\tGravel\t\n       Pave\tPaved\n       \t\nAlley: Type of alley access to property\n\n       Grvl\tGravel\n       Pave\tPaved\n       NA \tNo alley access\n\t\t\nLotShape: General shape of property\n\n       Reg\tRegular\t\n       IR1\tSlightly irregular\n       IR2\tModerately Irregular\n       IR3\tIrregular\n       \nLandContour: Flatness of the property\n\n       Lvl\tNear Flat\/Level\t\n       Bnk\tBanked - Quick and significant rise from street grade to building\n       HLS\tHillside - Significant slope from side to side\n       Low\tDepression\n\t\t\nUtilities: Type of utilities available\n\t\t\n       AllPub\tAll public Utilities (E,G,W,& S)\t\n       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n       NoSeWa\tElectricity and Gas Only\n       ELO\tElectricity only\t\n\t\nLotConfig: Lot configuration\n\n       Inside\tInside lot\n       Corner\tCorner lot\n       CulDSac\tCul-de-sac\n       FR2\tFrontage on 2 sides of property\n       FR3\tFrontage on 3 sides of property\n\t\nLandSlope: Slope of property\n\t\t\n       Gtl\tGentle slope\n       Mod\tModerate Slope\t\n       Sev\tSevere Slope\n\t\nNeighborhood: Physical locations within Ames city limits\n\n       Blmngtn\tBloomington Heights\n       Blueste\tBluestem\n       BrDale\tBriardale\n       BrkSide\tBrookside\n       ClearCr\tClear Creek\n       CollgCr\tCollege Creek\n       Crawfor\tCrawford\n       Edwards\tEdwards\n       Gilbert\tGilbert\n       IDOTRR\tIowa DOT and Rail Road\n       MeadowV\tMeadow Village\n       Mitchel\tMitchell\n       Names\tNorth Ames\n       NoRidge\tNorthridge\n       NPkVill\tNorthpark Villa\n       NridgHt\tNorthridge Heights\n       NWAmes\tNorthwest Ames\n       OldTown\tOld Town\n       SWISU\tSouth & West of Iowa State University\n       Sawyer\tSawyer\n       SawyerW\tSawyer West\n       Somerst\tSomerset\n       StoneBr\tStone Brook\n       Timber\tTimberland\n       Veenker\tVeenker\n\t\t\t\nCondition1: Proximity to various conditions\n\t\n       Artery\tAdjacent to arterial street\n       Feedr\tAdjacent to feeder street\t\n       Norm\tNormal\t\n       RRNn\tWithin 200' of North-South Railroad\n       RRAn\tAdjacent to North-South Railroad\n       PosN\tNear positive off-site feature--park, greenbelt, etc.\n       PosA\tAdjacent to postive off-site feature\n       RRNe\tWithin 200' of East-West Railroad\n       RRAe\tAdjacent to East-West Railroad\n\t\nCondition2: Proximity to various conditions (if more than one is present)\n\t\t\n       Artery\tAdjacent to arterial street\n       Feedr\tAdjacent to feeder street\t\n       Norm\tNormal\t\n       RRNn\tWithin 200' of North-South Railroad\n       RRAn\tAdjacent to North-South Railroad\n       PosN\tNear positive off-site feature--park, greenbelt, etc.\n       PosA\tAdjacent to postive off-site feature\n       RRNe\tWithin 200' of East-West Railroad\n       RRAe\tAdjacent to East-West Railroad\n\t\nBldgType: Type of dwelling\n\t\t\n       1Fam\tSingle-family Detached\t\n       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n       Duplx\tDuplex\n       TwnhsE\tTownhouse End Unit\n       TwnhsI\tTownhouse Inside Unit\n\t\nHouseStyle: Style of dwelling\n\t\n       1Story\tOne story\n       1.5Fin\tOne and one-half story: 2nd level finished\n       1.5Unf\tOne and one-half story: 2nd level unfinished\n       2Story\tTwo story\n       2.5Fin\tTwo and one-half story: 2nd level finished\n       2.5Unf\tTwo and one-half story: 2nd level unfinished\n       SFoyer\tSplit Foyer\n       SLvl\tSplit Level\n\t\nOverallQual: Rates the overall material and finish of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\n       5\tAverage\n       4\tBelow Average\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\t\nOverallCond: Rates the overall condition of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\t\n       5\tAverage\n       4\tBelow Average\t\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\t\t\nYearBuilt: Original construction date\n\nYearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n\nRoofStyle: Type of roof\n\n       Flat\tFlat\n       Gable\tGable\n       Gambrel\tGabrel (Barn)\n       Hip\tHip\n       Mansard\tMansard\n       Shed\tShed\n\t\t\nRoofMatl: Roof material\n\n       ClyTile\tClay or Tile\n       CompShg\tStandard (Composite) Shingle\n       Membran\tMembrane\n       Metal\tMetal\n       Roll\tRoll\n       Tar&Grv\tGravel & Tar\n       WdShake\tWood Shakes\n       WdShngl\tWood Shingles\n\t\t\nExterior1st: Exterior covering on house\n\n       AsbShng\tAsbestos Shingles\n       AsphShn\tAsphalt Shingles\n       BrkComm\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       CemntBd\tCement Board\n       HdBoard\tHard Board\n       ImStucc\tImitation Stucco\n       MetalSd\tMetal Siding\n       Other\tOther\n       Plywood\tPlywood\n       PreCast\tPreCast\t\n       Stone\tStone\n       Stucco\tStucco\n       VinylSd\tVinyl Siding\n       Wd Sdng\tWood Siding\n       WdShing\tWood Shingles\n\t\nExterior2nd: Exterior covering on house (if more than one material)\n\n       AsbShng\tAsbestos Shingles\n       AsphShn\tAsphalt Shingles\n       BrkComm\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       CemntBd\tCement Board\n       HdBoard\tHard Board\n       ImStucc\tImitation Stucco\n       MetalSd\tMetal Siding\n       Other\tOther\n       Plywood\tPlywood\n       PreCast\tPreCast\n       Stone\tStone\n       Stucco\tStucco\n       VinylSd\tVinyl Siding\n       Wd Sdng\tWood Siding\n       WdShing\tWood Shingles\n\t\nMasVnrType: Masonry veneer type\n\n       BrkCmn\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       None\tNone\n       Stone\tStone\n\t\nMasVnrArea: Masonry veneer area in square feet\n\nExterQual: Evaluates the quality of the material on the exterior \n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nExterCond: Evaluates the present condition of the material on the exterior\n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nFoundation: Type of foundation\n\t\t\n       BrkTil\tBrick & Tile\n       CBlock\tCinder Block\n       PConc\tPoured Contrete\t\n       Slab\tSlab\n       Stone\tStone\n       Wood\tWood\n\t\t\nBsmtQual: Evaluates the height of the basement\n\n       Ex\tExcellent (100+ inches)\t\n       Gd\tGood (90-99 inches)\n       TA\tTypical (80-89 inches)\n       Fa\tFair (70-79 inches)\n       Po\tPoor (<70 inches\n       NA\tNo Basement\n\t\t\nBsmtCond: Evaluates the general condition of the basement\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical - slight dampness allowed\n       Fa\tFair - dampness or some cracking or settling\n       Po\tPoor - Severe cracking, settling, or wetness\n       NA\tNo Basement\n\t\nBsmtExposure: Refers to walkout or garden level walls\n\n       Gd\tGood Exposure\n       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n       Mn\tMimimum Exposure\n       No\tNo Exposure\n       NA\tNo Basement\n\t\nBsmtFinType1: Rating of basement finished area\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\t\t\nBsmtFinSF1: Type 1 finished square feet\n\nBsmtFinType2: Rating of basement finished area (if multiple types)\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\nBsmtFinSF2: Type 2 finished square feet\n\nBsmtUnfSF: Unfinished square feet of basement area\n\nTotalBsmtSF: Total square feet of basement area\n\nHeating: Type of heating\n\t\t\n       Floor\tFloor Furnace\n       GasA\tGas forced warm air furnace\n       GasW\tGas hot water or steam heat\n       Grav\tGravity furnace\t\n       OthW\tHot water or steam heat other than gas\n       Wall\tWall furnace\n\t\t\nHeatingQC: Heating quality and condition\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nCentralAir: Central air conditioning\n\n       N\tNo\n       Y\tYes\n\t\t\nElectrical: Electrical system\n\n       SBrkr\tStandard Circuit Breakers & Romex\n       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n       Mix\tMixed\n\t\t\n1stFlrSF: First Floor square feet\n \n2ndFlrSF: Second floor square feet\n\nLowQualFinSF: Low quality finished square feet (all floors)\n\nGrLivArea: Above grade (ground) living area square feet\n\nBsmtFullBath: Basement full bathrooms\n\nBsmtHalfBath: Basement half bathrooms\n\nFullBath: Full bathrooms above grade\n\nHalfBath: Half baths above grade\n\nBedroom: Bedrooms above grade (does NOT include basement bedrooms)\n\nKitchen: Kitchens above grade\n\nKitchenQual: Kitchen quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       \t\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n\nFunctional: Home functionality (Assume typical unless deductions are warranted)\n\n       Typ\tTypical Functionality\n       Min1\tMinor Deductions 1\n       Min2\tMinor Deductions 2\n       Mod\tModerate Deductions\n       Maj1\tMajor Deductions 1\n       Maj2\tMajor Deductions 2\n       Sev\tSeverely Damaged\n       Sal\tSalvage only\n\t\t\nFireplaces: Number of fireplaces\n\nFireplaceQu: Fireplace quality\n\n       Ex\tExcellent - Exceptional Masonry Fireplace\n       Gd\tGood - Masonry Fireplace in main level\n       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n       Fa\tFair - Prefabricated Fireplace in basement\n       Po\tPoor - Ben Franklin Stove\n       NA\tNo Fireplace\n\t\t\nGarageType: Garage location\n\t\t\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage\n\t\t\nGarageYrBlt: Year garage was built\n\t\t\nGarageFinish: Interior finish of the garage\n\n       Fin\tFinished\n       RFn\tRough Finished\t\n       Unf\tUnfinished\n       NA\tNo Garage\n\t\t\nGarageCars: Size of garage in car capacity\n\nGarageArea: Size of garage in square feet\n\nGarageQual: Garage quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\t\t\nGarageCond: Garage condition\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\t\t\nPavedDrive: Paved driveway\n\n       Y\tPaved \n       P\tPartial Pavement\n       N\tDirt\/Gravel\n\t\t\nWoodDeckSF: Wood deck area in square feet\n\nOpenPorchSF: Open porch area in square feet\n\nEnclosedPorch: Enclosed porch area in square feet\n\n3SsnPorch: Three season porch area in square feet\n\nScreenPorch: Screen porch area in square feet\n\nPoolArea: Pool area in square feet\n\nPoolQC: Pool quality\n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       NA\tNo Pool\n\t\t\nFence: Fence quality\n\t\t\n       GdPrv\tGood Privacy\n       MnPrv\tMinimum Privacy\n       GdWo\tGood Wood\n       MnWw\tMinimum Wood\/Wire\n       NA\tNo Fence\n\t\nMiscFeature: Miscellaneous feature not covered in other categories\n\t\t\n       Elev\tElevator\n       Gar2\t2nd Garage (if not described in garage section)\n       Othr\tOther\n       Shed\tShed (over 100 SF)\n       TenC\tTennis Court\n       NA\tNone\n\t\t\nMiscVal: $Value of miscellaneous feature\n\nMoSold: Month Sold (MM)\n\nYrSold: Year Sold (YYYY)\n\nSaleType: Type of sale\n\t\t\n       WD \tWarranty Deed - Conventional\n       CWD\tWarranty Deed - Cash\n       VWD\tWarranty Deed - VA Loan\n       New\tHome just constructed and sold\n       COD\tCourt Officer Deed\/Estate\n       Con\tContract 15% Down payment regular terms\n       ConLw\tContract Low Down payment and low interest\n       ConLI\tContract Low Interest\n       ConLD\tContract Low Down\n       Oth\tOther\n\t\t\nSaleCondition: Condition of sale\n\n       Normal\tNormal Sale\n       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n       AdjLand\tAdjoining Land Purchase\n       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n       Family\tSale between family members\n       Partial\tHome was not completed when last assessed (associated with New Homes)\n\n# Work Flow:\n\n1. Acquire the Data\n2. Data Exploration\n3. Check For Correlation Among Features and Between Features and Target\n4. Creating New Features That May Impact Significance in prediction\n5. Data Cleaning and Preprocessing\/ Feature Engineering\n6. Feature Selection using Random Forest\n7. Evaluating Different Models\n8. Selecting Model With Best Score And Predicting the unseen Test data to Model\n\n\n\n<hr>\n\n","5454562c":"<font color = \"maroon\" size=3px><b>1.2 lets see the value counts of PoolQc <\/b><\/font>","e4f7ec68":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Almost all houses doesnt have  Fence<\/font>\n* <font color = \"red\" size=4px>lets now check with How much variance it plays for predicting SalePrice of house<\/font>\n\n<hr>","5c30b410":"<hr>\n\n<font color = \"maroon\" size=3px><b>2.4. lets Fill in the missing values for rest feeatures <\/b><\/font>","cd6918e3":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Almost all houses doesnt have  Pool<\/font>\n* <font color = \"red\" size=4px>lets now check with How much variance it plays for predicting SalePrice of house<\/font>\n\n<hr>","499674e7":"<font color = \"red\" size=6px><center><b>Xtreme Gradient Boosting<\/b><\/font>","f0722cc0":"<font color = \"maroon\" size=3px><b>2.2 lets see the value counts of PoolQc <\/b><\/font>","c4cd69b2":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>It makes sense that land with gentle slope had most ratings for pool as there was pool available in this type of land...<\/font>\n* <font color = \"red\" size=4px>there were no pools in moderate to severe slope lands<\/font>\n\n<hr>","fe0b8717":"<font color = \"maroon\" size=4px><b>lets find target variable<\/b><\/font>","58a1fee0":"<font color = \"maroon\" size=4px><b>lets check info of data<\/b><\/font>","e968fb75":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Inspite of No Pool being the most Fashionable category, Excellent Pool Quality is havimg higher variance in prediction of SalesPrice<\/font>\n* <font color = \"red\" size=4px>it means there must be some outliiers in PoolQC Lets Check them<\/font>\n\n<hr>","4c814077":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Houses with severe slope has no fence significance<\/font>\n* <font color = \"red\" size=4px>Most Of the Good wood\/wire fence is in moderate slope<\/font>\n* <font color = \"red\" size=4px>Most Of the Good wood\/wire fence is in Farming zone which makes sense <\/font>\n* <font color = \"red\" size=4px>Severly Damaged and major defect Houses were having no fence at all which makes sense <\/font>\n* <font color = \"red\" size=4px>2.5 story finished house had good privacy fence, in our previous analysis for Pool Quality this house type had higher significance, so it seems 2.5 story houses are luxurious<\/font>\n\n<hr>","d591e3f5":"<font color = \"#191970\" size=6px><center><b>Feature Engineering and Feature Selection<\/b><\/font>","3d8a4e59":"MSZoning: Identifies the general zoning classification of the sale.\n\t\t\n       A\tAgriculture\n       C\tCommercial\n       FV\tFloating Village Residential\n       I\tIndustrial\n       RH\tResidential High Density\n       RL\tResidential Low Density\n       RP\tResidential Low Density Park \n       RM\tResidential Medium Density\n       \n       \n<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>It is evidend that low density residential have pools, whereas other categories have no pool at all<\/font>\n* <font color = \"red\" size=4px>Which makes sense , Obviously high density residential, comercial and idustrial areas, wil have no space for pool <\/font>\n\n<hr>","cb2854be":"<hr>\n\n<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Houses with higher ratings for Features were having higher sales price , such as Basemnt quality and basement finishing, which makes sense higher the quality higher the Price<\/font>\n* <font color = \"red\" size=4px>Howere Houses with Good Condition Garage has more SalePrice than Excellent , There must be some outliers Present<\/font>\n* <font color = \"red\" size=4px>Houses with Standard Circuit Breakers & Romex are having higher SalePrice<\/font>\n* <font color = \"red\" size=4px>House with Basemnet and Garage were Having significantly Higher SalePrice , although houses without Masonry walls were having higher sales price which makes sense these types of walls have less material cost<\/font>\n\n<hr>","070c21c2":"<font color = \"red\" size=6px><center><b>Random Forest All Variables<\/b><\/font>","2e46c4c7":"<font color = \"maroon\" size=3px><b>2.2. Now Lets Derive New Features isAlley, isFirePlace, isMiscFeatures which states wether category is present or absent   <\/b><\/font>","53d01668":"<font color = \"maroon\" size=4px><b>lets analyze data with different dtypes<\/b><\/font>","18b550f8":"<font color = \"maroon\" size=4px><b>lets remove Features with Zero Variance In OneHot<\/b><\/font>","e36b8a1d":"<font color = \"maroon\" size=3px><b>2.5 lets check count for Fence vs No Fence <\/b><\/font>","582d1a7e":"### <font color = \"#191970\" size=5px><center><b>Model Evaluation<\/b><\/font>","36f58d4f":"<font color = \"maroon\" size=4px><b>lets get Null Pecentage for object columns<\/b><\/font>","a6cdbdb8":"<font color = \"maroon\" size=4px><b>lets get column counts for different dtypes<\/b><\/font>","86b796dd":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Inspite of No Fence being the most Fashionable category, Good Privacy fence  is havimg higher variance in prediction of SalesPrice<\/font>\n* <font color = \"red\" size=4px>it means there must be some outliiers in Fence Lets Check them<\/font>\n\n<hr>","90af3af4":"# Optuna Sk-learn\n","8d7e0c7c":"<hr>\n\n **Great !** we have successfully **Cleaned Our Data With Missing value** not just by bunch of **thumb of rules** rather by **understanding and analysing our data** and finding the root Cause for missing Values\n\n- Also we have Concluded that Mostly there are outliers present in every Feature in Our Data Set and Every Feature is Skewed , hence No Normality\n- By this we have understood that we cannot use Linear Models as our Predictive Modeling , Tree based models doesnt expect normal distribution and handles Outliers Pretty well so Mostly we will be using Tree Based Ensemble Modeling\n- Lets get Our Data Ready for Modeling !  lets do some Feature Engineering and Feature Selection \n\n<hr>","e8f8e1dc":"<font color = \"maroon\" size=4px><b>K-Fold<\/b><\/font>","4eaf8c74":"<hr>\n\n<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Best Model is XGB with **R-Squared of 97%** and **RMSE of 14174.077109** <\/font>\n\n\n<hr>","ca371ae2":"<font color = \"#191970\" size=8px><center><b>Model Building<\/b><\/font>","36d57891":"# Final Prediction on Unseen Test Data","1b69af89":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Inspite of No Pool being the most Fashionable category, Houses with Pool  is havimg higher variance in prediction of SalesPrice<\/font>\n\n<hr>","a81a8924":"### Set Significant Features ","3dc31541":"<font color = \"maroon\" size=3px><b>3.3 Lets Fill in the missing values <\/b><\/font>","e0431ccb":"<font color = \"maroon\" size=3px><b>2.5. lets Derive New Features isGarage, isMasVnr, isBsmt, which denotes if garage , MasVnr and Masement is present in house or not <\/b><\/font>","e3e06f39":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Most of the Features Doesnot have Alley<\/font>\n* <font color = \"red\" size=4px>Most Of the Houses do have fire places<\/font>\n* <font color = \"red\" size=4px>Most Of the houses does not have miscellaneous features <\/font>\n* <font color = \"red\" size=4px>Lets Now Check correlation of such with SalesPrice<\/font>\n\n<hr>","bf3f0fe4":"<font color = \"maroon\" size=3px><b>2.3. lets check for values counts for each of them <\/b><\/font>","004c43c3":"<font color = \"maroon\" size=3px><b>2. lets study Alley, FirePlaceQu and MiscFeature  <\/b><\/font>","215b76bb":"<hr>\n\n<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Its evident that if Masonry veneer(wall) is not present , there is missing value in MasVnrArea, which makes sense right , if there is no wall why would be there entry for its area<\/font>\n* <font color = \"red\" size=4px>It seems Paved steets are Having almost all Missing value for the width of steet aka LotFrontage, so we will replace the value with median Age with respect to Steet type<\/font>\n* <font color = \"red\" size=4px>Its evident that GarageYrBlt is having missing values for houses with no garage which makes sense so we will simply fill it with zero<\/font>\n\n<hr>","ca759155":"<font color = \"maroon\" size=4px><b>3 Lets Beging with Encoding Our Categorical Variables<\/b><\/font>\n\n- As we are dealing with high Cardinality and also we will be using tree based model , basic Encoding techniques such as One-hot Encoding or Label Encoding wont be Effective...\n- Lets Try different Encoding Techniques and Evaluate the Result for Each","46258807":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Houses without Alley has More Value as compared to houses with Alley<\/font>\n* <font color = \"red\" size=4px>Houses with excellent quality fireplace has most value also its evident that Houses with fireplace have more value<\/font>\n* <font color = \"red\" size=4px>Houses with TenC - Tennis Court has most value , it makes sense as houses with tennis court will come under luxurious house<\/font>\n* <font color = \"red\" size=4px>Still its evident that houses without Miscellanous Feature is having Higher SalePrice, the must be some outliers Present <\/font>\n\n<hr>","64fb7868":"<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>It is evidend that corner plot have excellent pool quality<\/font>\n\n<hr>","e499af9b":"<hr>\n\n<font color = \"blue\" size=4px> <b>Interpretation : <\/b><\/font>\n\n* <font color = \"red\" size=4px>Lets Set The Threshold as 0.005 and Get Significant Features<\/font>\n\n\n<hr>"}}