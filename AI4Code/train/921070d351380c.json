{"cell_type":{"7e014341":"code","5be5e39f":"code","341c4d6e":"code","34d9dda7":"code","6c2907a3":"code","cb9813cc":"code","8740e471":"code","b4d557a6":"code","5ad7475d":"code","d018ad85":"code","41988a60":"code","6c31880a":"code","1fdb4200":"code","aaefa499":"code","01586995":"code","b408809f":"code","3200f1c7":"code","88849e9e":"code","24cecfd4":"code","0c55173e":"code","85973c7b":"code","beeefefd":"code","30b401ae":"markdown","0b8caa9a":"markdown","5ecb77b0":"markdown","c939ea75":"markdown","ad7dbc65":"markdown","95c71b56":"markdown","26d344fa":"markdown","a907a699":"markdown","2579f0c7":"markdown","51754fb4":"markdown"},"source":{"7e014341":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nimport imageio\nimport shutil\nimport time\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom IPython.display import Image\nfrom shutil import copy","5be5e39f":"data_dir = '\/kaggle\/input\/butterfly-dataset\/leedsbutterfly\/'\nworking_dir = '\/kaggle\/working'\nmodel_dir = '\/kaggle\/working\/models'\nimage_dir = os.path.join(data_dir, \"images\")\nsegmentation_dir = os.path.join(data_dir, \"segmentations\")","341c4d6e":"image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\nsegmentation_files = [f for f in os.listdir(segmentation_dir) if os.path.isfile(os.path.join(segmentation_dir, f))]\nlabels = np.array([f[:3] for f in image_files]).astype('int32') - 1\n\nimage_files = [os.path.join(image_dir, f) for f in image_files]\nsegmentation_files = [os.path.join(segmentation_dir, f) for f in segmentation_files]\n\ntry: \n    os.mkdir(model_dir) \nexcept OSError as error:\n    print(\"\")","34d9dda7":"def copy_files(filenames, dest_dir, labelname):\n    label_dest_dir = os.path.join(dest_dir, str(label))\n\n    if os.path.isdir(label_dest_dir):\n        shutil.rmtree(label_dest_dir, ignore_errors=True)\n\n    os.makedirs(label_dest_dir)\n\n    \n    [copy(file , label_dest_dir) for file in filenames]\n    \n    return","6c2907a3":"def copy_images_and_masks(samples, masks, sample_dir, mask_dir, labels, current_label):\n    sample_idx = np.where(labels == label)[0]\n    sample_data = np.array(samples)[sample_idx]\n    masks_data = np.array(masks)[sample_idx]\n\n    copy_files(sample_data, sample_dir, label)\n    copy_files(masks_data, mask_dir, label)","cb9813cc":"image_segment_files = list(zip(image_files, segmentation_files))\nX_train_seg, X_test_seg, y_train, y_test = train_test_split(image_segment_files, labels, train_size=0.8, random_state=5634)\nX_train, X_train_segment = zip(*X_train_seg)\nX_test, X_test_segment = zip(*X_test_seg)\n\nunique_labels = np.unique(labels)\ntrain_dest_dir = os.path.join(working_dir, \"train\")\ntrain_segment_dest_dir = os.path.join(working_dir, \"train_segment\")\ntest_dest_dir = os.path.join(working_dir, \"test\")\ntest_segment_dest_dir = os.path.join(working_dir, \"test_segment\")\n\nfor label in unique_labels:\n    copy_images_and_masks(X_train, X_train_segment, train_dest_dir, train_segment_dest_dir, y_train, label)\n    copy_images_and_masks(X_test, X_test_segment, test_dest_dir, test_segment_dest_dir, y_test, label)\n","8740e471":"def show_images_from_file(base_dir, label, num_images=25, num_per_row=5):\n    image_dir = os.path.join(base_dir, str(label))\n\n    files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n    files = files[:num_images]\n    \n    images_per_row = min(num_images, num_per_row)\n    n_rows = (num_images - 1) \/\/ images_per_row + 1\n\n    row_images = []\n    \n    for row in range(n_rows):\n        current_files = files[row * images_per_row : (row + 1) * images_per_row]\n        images = [tf.image.resize(imageio.imread(file), [96, 96], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) for file in current_files]\n        row_images.append(np.concatenate(images, axis=1))\n\n    image = np.concatenate(row_images, axis=0)\n\n    plt.figure(figsize = (images_per_row * 2, n_rows * 2))\n    plt.imshow(image, interpolation='nearest')\n    plt.axis(\"off\")\n\n    return","b4d557a6":"for label in np.unique(labels):\n    print(\"-----------------------------\")\n    print(\"Label: {}\".format(label))\n    print(\"\")\n    show_images_from_file(test_dest_dir, label, num_images=1)\n    plt.show()","5ad7475d":"show_images_from_file(train_dest_dir, 0)\nshow_images_from_file(train_dest_dir, 1)\nshow_images_from_file(test_dest_dir, 0, num_images=5)\nshow_images_from_file(test_dest_dir, 1, num_images=5)","d018ad85":"def create_data_generator(data_dir, batch_size, data_seed, target_size, args):\n    datagen = ImageDataGenerator(**args)\n    \n    data_generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        seed=data_seed\n    )\n    \n    return data_generator","41988a60":"def create_sample_mask_generator(sample_dir, mask_dir, batch_size, data_seed, target_size, args):\n    sample_datagen = create_data_generator(sample_dir, batch_size, data_seed, target_size, args)\n    mask_datagen = create_data_generator(mask_dir, batch_size, data_seed, target_size, args)\n    \n    return [sample_datagen, mask_datagen]","6c31880a":"batch_size = 32\ndata_seed = 432\ntarget_size = (92,92)\n\ntrain_data_gen_args = dict(\n    rescale=1.\/255,\n    rotation_range=25,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\n\ntest_data_gen_args = dict(\n    rescale=1.\/255\n)\n\ntrain_generator, train_mask_generator = create_sample_mask_generator(\n    train_dest_dir,\n    train_segment_dest_dir,\n    batch_size,\n    data_seed,\n    target_size,\n    train_data_gen_args\n)\n\ntest_generator, test_mask_generator = create_sample_mask_generator(\n    test_dest_dir,\n    test_segment_dest_dir,\n    batch_size,\n    data_seed,\n    target_size,\n    test_data_gen_args\n)","1fdb4200":"image_shape = target_size + (3,)\n\nmodel = models.Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=image_shape, name='conv_1'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', name='conv_2'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name='conv_3'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu', name='dense_1'),\n    layers.Dropout(0.5),\n    layers.Dense(10, activation='sigmoid', name='outputs')\n])\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","aaefa499":"model.fit_generator(\n    train_generator,\n    steps_per_epoch=len(X_train) \/\/ batch_size,\n    epochs=50,\n    validation_data=test_generator,\n    validation_steps=len(X_test) \/\/ batch_size\n)","01586995":"timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\nmodel_filename = os.path.join(model_dir, \"model_no_mask_{}.h5\".format(timestamp))\n\nprint(\"Saving model in file {}\".format(model_filename))\nmodel.save(model_filename)","b408809f":"history = model.history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","3200f1c7":"timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\nmodel_filename = os.path.join(model_dir, \"model_no_mask_{}.h5\".format(timestamp))\n\nearly_stop = EarlyStopping(monitor='loss', mode='min', patience=50)\nmodel_checkpoint = ModelCheckpoint(model_filename, monitor='val_accuracy', mode='max', save_best_only=True)\n\nmodel_enhanced = models.Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', input_shape=image_shape, name='conv_1'),\n    layers.Conv2D(filters=32, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', name='conv_2'),\n    layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n    layers.Dropout(0.2),\n    layers.Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', name='conv_3'),\n    layers.Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', name='conv_4'),\n    layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n    layers.Dropout(0.2),\n    layers.Conv2D(filters=128, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', name='conv_5'),\n    layers.Conv2D(filters=128, kernel_size=(3, 3), kernel_initializer='he_normal', bias_initializer='random_uniform', activation='relu', name='conv_6'),\n    layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n    layers.Dropout(0.3),\n    layers.Flatten(),\n    layers.Dense(64, kernel_initializer='he_normal', activation='relu', name='dense_1', use_bias=False),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(10, bias_initializer='random_uniform', activation='sigmoid', name='outputs')\n])\n\nmodel_enhanced.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nprint(model.summary())\n\nmodel_enhanced.fit_generator(\n    train_generator,\n    steps_per_epoch=len(X_train) \/\/ batch_size,\n    epochs=1000,\n    validation_data=test_generator,\n    validation_steps=len(X_test) \/\/ batch_size,\n    callbacks=[\n        early_stop,\n        model_checkpoint\n    ]\n)","88849e9e":"history = model_enhanced.history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","24cecfd4":"# Predictions are very slow, so we'll store them in a variable\n\ndef generate_predictions(file_dir, model):\n    predictions = []\n\n    for label in os.listdir(file_dir):\n        images = []\n        files = os.listdir(os.path.join(file_dir, label))\n        \n        print(\"Generating predictions for label: {} with {} files\".format(label, len(files)))\n\n        for file in files:\n            raw_image = imageio.imread(os.path.join(file_dir, label, file))\n            resize_image = tf.image.resize(raw_image, target_size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n            resize_image = resize_image \/ 255\n\n            images.append(resize_image)\n\n        class_predictions = model.predict_classes(np.array(images), batch_size=len(images))\n        \n        predictions.append([label, class_predictions])\n        \n    return predictions","0c55173e":"saved_model = tf.keras.models.load_model(model_filename)","85973c7b":"predictions = generate_predictions(test_dest_dir, saved_model)","beeefefd":"for label, prediction in predictions:\n    misclassification_idx = np.where(np.array(prediction) != np.int(label))[0]\n\n    print(\"----------------------------------------\")\n    print(\"Class {} has {} misclassifications\".format(label, len(misclassification_idx)))\n    print(\"\")\n\n    files = os.listdir(os.path.join(test_dest_dir, label))\n    \n    for i in misclassification_idx:\n        print(\"Misclassified as {}\".format(prediction[i]))\n\n        misclass_file = files[i]\n        image = imageio.imread(os.path.join(test_dest_dir, label, misclass_file))\n        plt.imshow(image, interpolation='nearest')\n        plt.axis(\"off\")\n        plt.show()","30b401ae":"## Generate the Model\nI wasn't able to resolve issues when training both the images and the segments, so I'll train only the images for now","0b8caa9a":"## Create Model\nCreate model with a network of 3 Convolutional layers and 2 layers of fully connected neurons. Use a dropout rate of 50% to perform regularisation.\nSince this is a multi-classification problem, use categorical_crossentropy for the loss, and adam as the optimizer.","5ecb77b0":"Using a more sophisticated model, we can achieve 98% accuracy. We'll use early stopping and save only the most accurate model. This model can take a few hours to run on Kaggle.","c939ea75":"## Example Images\nLet's see what the Butterflies look like","ad7dbc65":"# Butterfly Classifier\nThis dataset contains 10 species of Butterflies with over 800 images. Using a basic CNN, we can classify Butterflies with over 90% accuracy. We vastly increase the size of the training  dataset by using the ImageDataGenerator from Keras to dynamically augment our images. A neural network is then trained to learn how to classify Butterflies without looking at the same image twice, which serves as a good tool for reducing overfitting.\nSegmentations are included in the dataset, but I was unsuccessful in using this data while training. Perhaps when this issue is resolved, the segmentation data could help improve the accuracy of the model.","95c71b56":"## Copy Images and Segmentations\nCopy images and segmentations into the correct folder hierarchy in order for *tensorflow.keras.preprocessing.image.ImageDataGenerator* to correctly read and label the image files. We should end up with the following file structure\n\n```bash\n.\n\u251c\u2500\u2500 test\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010008.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010010.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010011.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020008.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020016.png\n\u251c\u2500\u2500 test_segment\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010009_seg0.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010086_seg0.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020119_seg0.png\n\u251c\u2500\u2500 train\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010001.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010002.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020003.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020004.png\n\u2514\u2500\u2500 train_segment\n    \u251c\u2500\u2500 0\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010026_seg0.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0010049_seg0.png\n    \u251c\u2500\u2500 1\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020004_seg0.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0020058_seg0.png\n```","26d344fa":"## Create Batch Image Generator\nUse the *tensorflow.keras.preprocessing.image.ImageDataGenerator* to generate new images by augmenting existing images. Rescale RGB values from 0-255 to 0-1 to improve training. Perform slight shear and zoom on images to improve training and auto generate more training data. Ensure that the image and mask generators use the same seeds, so they batch the correct image and masks ","a907a699":"## Model Analysis\nLet's check the predictions and investigate misclassified results","2579f0c7":"## Listing Files and Creating Labels\n\nWe start by retrieving a list of filenames for the images and segments. The labels for each image are the first 3 characters of the filename, so we need to find all the filenames and generate the labels. I've subracted 1 from the labels, so the labels are 0 indexed, which will ensure classifications and predictions are consistent.","51754fb4":"## Model Performance\nLet's look at the model accuracy and loss history to see how performance improved over time.\n\nWe can see that the model can achieve over 80% accuracy, but then it starts to overfit. We will need to add more regularisation if we want to run more epochs and improve the accuracy."}}