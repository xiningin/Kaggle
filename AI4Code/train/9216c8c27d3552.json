{"cell_type":{"23b65297":"code","a54559d4":"code","bb65eb69":"code","7ede66b4":"code","571a88e4":"code","d6a35a2f":"code","b38813b5":"code","7d37613a":"code","a3807c51":"code","b9dfb2f4":"code","36e1d4b6":"code","d4db8e87":"code","62cd84d3":"code","452e0746":"code","f6ba469b":"markdown","78ed34b1":"markdown","a29232ee":"markdown","42eee68a":"markdown","cd8ef804":"markdown","c279f2c0":"markdown","a2fa7ef3":"markdown","2779cc7d":"markdown","9335a2b0":"markdown"},"source":{"23b65297":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","a54559d4":"image_width = 256\nimage_height = 256","bb65eb69":"train_files = []\nmask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\n\nfor i in mask_files:\n    train_files.append(i.replace('_mask',''))\n\nprint(train_files[:10])\nprint(mask_files[:10])","7ede66b4":"rows, cols = 3,3\nfig = plt.figure(figsize=(10,10))\nfor i in range(1, rows*cols+1):\n    fig.add_subplot(rows, cols, i)\n    img_path = train_files[i]\n    msk_path = mask_files[i]\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    msk = cv2.imread(msk_path)\n    plt.imshow(img)\n    plt.imshow(msk, alpha=0.4)\nplt.show()    ","571a88e4":"df = pd.DataFrame(data={'filename': train_files, 'mask': mask_files})\ndf_train, df_test = train_test_split(df, test_size = 0.1)\ndf_train, df_val = train_test_split(df_train, test_size = 0.2)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","d6a35a2f":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    \n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n    \n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img, mask)\n        \ndef adjust_data(img, mask):\n    img = img \/ 255\n    mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","b38813b5":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) \/ (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)","7d37613a":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","a3807c51":"model = unet()\nmodel.summary()","b9dfb2f4":"EPOCHS = 10\nBATCH_SIZE = 32\nlearning_rate = 1e-4","36e1d4b6":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=(image_height, image_width))\n    \ntest_gener = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=(image_height, image_width))\n    \nmodel = unet(input_size=(image_height, image_width, 3))\n\n\n\ndecay_rate = learning_rate \/ EPOCHS\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer='adam', loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gener,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)","d4db8e87":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","62cd84d3":"model = load_model('unet_brain_mri_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","452e0746":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['filename'].iloc[index])\n    img = cv2.resize(img ,(image_height, image_width))\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","f6ba469b":"> \u0130lk a\u015famada kullan\u0131lacak k\u00fct\u00fcphaneleri projemize ekliyoruz.","78ed34b1":"> Verilerimizi train ve mask olmak \u00fczere train_files adl\u0131 bir listede tutup ilk 10 resmi konsola yazd\u0131r\u0131yoruz.","a29232ee":"> Verilerimizi her ihtimale kar\u015f\u0131 kontrol etmek i\u00e7in matplotlib k\u00fct\u00fcphanesini kullanarak konsolda g\u00f6rmeyi deniyoruz.","42eee68a":"> Verilerimiz eksizsiz bir \u015fekilde train_files adl\u0131 listemizde tutuluyor.","cd8ef804":"### Verilerin Haz\u0131rlanmas\u0131\nVerilerimiz E\u011fitim(train) ve Test verileri olarak ikiye ayr\u0131lmadan \u00f6nce modelin i\u015flenmesine uygun olarak yeniden boyutland\u0131rma, filtreleme i\u015flemleri uygulanmas\u0131 gerekir. ","c279f2c0":"> Maskelenmi\u015f ve E\u011fitim verilerini df adl\u0131 bir de\u011fi\u015fkende ayn\u0131 \u00e7at\u0131 alt\u0131na getiriyoruz. Egitim ve test verisi olarak 2 ana b\u00f6l\u00fcme ay\u0131r\u0131yoruz. Ard\u0131ndan boyutlar\u0131na (shape) g\u00f6z gezdiriyoruz.","a2fa7ef3":"E\u011fitim ve test verilerini olu\u015fturduk.","2779cc7d":"> Gerekli olan yeniden boyutland\u0131rma i\u015flemini uyguluyoruz yeni boyutumuzu 256x256 olarak belirliyoruz.","9335a2b0":"# Brain Segmentation\nMerhaba,\nBu projede T\u00fcm\u00f6rl\u00fc ve Sa\u011fl\u0131kl\u0131 olmak \u00fczere 2 t\u00fcrden veri bulunmaktad\u0131r. Projede bu 2 farkl\u0131 t\u00fcre sahip verileri ay\u0131rt edip ard\u0131ndan T\u00fcm\u00f6rl\u00fc t\u00fcrden verilerde maskeleme i\u015fleme uygulayarak T\u00fcmor\u00fcn daha belirgin hale getirilmesi ama\u00e7lanmaktad\u0131r. \nProje verilerin haz\u0131rlanmas\u0131, \u00f6n i\u015fleme, yapay zeka modelinin olu\u015fturulmas\u0131, egitim ve test a\u015famas\u0131 olarak 4 a\u015famadan olu\u015fmaktad\u0131r."}}