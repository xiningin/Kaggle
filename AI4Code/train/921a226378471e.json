{"cell_type":{"efa67b7e":"code","d40291a0":"code","b5bddf18":"code","10656002":"code","32280c80":"code","145ac597":"code","a4c47903":"code","e1fb37d1":"code","d06b97d8":"code","c728eaab":"code","b45c1863":"code","f9c921c2":"code","ae092afc":"code","5cb3e723":"code","e4530a5d":"code","e18239ba":"code","279e67a9":"code","bf6c90a4":"code","6165b921":"code","5090e186":"code","598be38e":"markdown","e3671b5a":"markdown","3b6defc3":"markdown","4b0d4f09":"markdown","128b8599":"markdown","e352bc21":"markdown","c6c8e8da":"markdown","1bea98f2":"markdown","85f8f64a":"markdown","f6293095":"markdown","97fa67ec":"markdown","1cc1a313":"markdown","f2ae9143":"markdown","88bcb52b":"markdown","7879cd71":"markdown"},"source":{"efa67b7e":"import pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport cv2\nimport os\nimport math\nfrom math import ceil, floor, log\n\n# to be used to get better performance\n# from sklearn.model_selection import KFold\n!pip install -q efficientnet\nimport efficientnet.tfkeras as efn\n\nimport scikitplot as skplt\n\nprint(\"TF version:\", tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","d40291a0":"N_epochs = 30\nSEED = 1970\nN_TTA = 5\n# in the version 9 of the botebook I made images size = 300 for all models\nMODELS = {\n          'ResNet50':[tf.keras.applications.ResNet50,32,300],\n          'DenseNet121':[tf.keras.applications.DenseNet121,32,300],\n          'EfficientNetB3':[efn.EfficientNetB3,8,300],\n          'EfficientNetB6':[efn.EfficientNetB6,8,300]\n         }\npath = '..\/input\/'\npath_org = 'bee-vs-wasp\/kaggle_bee_vs_wasp\/' #path to the main dataset\npath_flowers = 'flowers-blossom\/' # path to 370 images of just flowers\ndf = pd.read_csv(path + path_org + \"labels.csv\")\ndf_flowers = pd.read_csv(path + path_flowers + \"flowers.csv\")\ndf.head(5)","b5bddf18":"# transorm path column so we will get valid full path to the images\ndf['path'] = df.path.apply(lambda x: x.replace('\\\\', '\/') )\ndf['path'] = df.path.apply(lambda x: path_org + x )\n\ndf_flowers['path'] = df_flowers.path.apply(lambda x: x.replace('\\\\', '\/') )\ndf_flowers['path'] = df_flowers.path.apply(lambda x: path_flowers + x )\n\n# generate file lists and labels\nlabels_cols = ['is_bee', 'is_wasp', 'is_otherinsect', 'is_other']\ndf_train = df.loc[(df.is_validation == 0) & (df.is_final_validation == 0)]\ndf_valid = df.loc[(df.is_validation == 1)]\ndf_test = df.loc[(df.is_final_validation == 1)]\n\ndf_test_ext = pd.concat([df_test, df_flowers])\n\ny_train = df_train.loc[:,['id']+labels_cols]\ny_train.set_index('id', inplace = True)\ny_valid = df_valid.loc[:,['id']+labels_cols]\ny_valid.set_index('id', inplace = True)\ny_test = df_test.loc[:,['id']+labels_cols]\ny_test.set_index('id', inplace = True)\ny_test_ext = df_test_ext.loc[:,['id']+labels_cols]\ny_test_ext.set_index('id', inplace = True)\n\ndf_train.head(5)","10656002":"# check that we've got extened test set labels \nprint(y_test_ext.head(-5))","32280c80":"# n_samples must be multiples of 5\ndef img_plot(df_list, n_samples):\n    df = df_list.sample(n = n_samples, random_state = SEED)\n    images = []\n    f, ax = plt.subplots(n_samples\/\/5, 5, figsize=(12,8))\n    i = 0\n    for img_path in df['path']:\n        img = cv2.imread(path+img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        images.append(img)\n        ax[i\/\/5, i%5].imshow(img)\n        ax[i\/\/5, i%5].axis('off')\n        ax[i\/\/5, i%5].set_title('label: %s' % df.iloc[i]['label'])\n        i +=1\n    plt.show()","145ac597":"img_plot(df,25)","a4c47903":"def get_lr_callback(batch_size = 16, plot=False):\n    start_lr = 0.001\n    def step_decay(epoch):\n        drop = 0.5\n        epochs_drop = 5.0\n        lr = start_lr * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n        return lr\n    \n    lr_callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n    if plot == True:\n        rng = [i for i in range(N_epochs)]\n        y = [step_decay(x) for x in rng]\n        plt.plot(rng, y)\n        plt.xlabel('epoch', size=14)\n        plt.ylabel('learning_rate', size=14)\n        plt.title('Training Schedule', size=16)\n        plt.show()\n        \n    return lr_callback\n\n\nes_callback = tf.keras.callbacks.EarlyStopping(patience=10, \n                                               monitor='val_loss',\n                                               verbose=1, \n                                               restore_best_weights=True)\nlr = get_lr_callback(plot=True)","e1fb37d1":"def gen_init(BS, IMG_Size):\n    train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=30,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        vertical_flip = True,\n        horizontal_flip=True)\n\n    valid_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)    \n    train_generator = train_gen.flow_from_dataframe(dataframe=df_train, directory=path, \n                                                  x_col=\"path\", y_col=labels_cols, \n                                                  class_mode=\"raw\", \n                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n\n    valid_generator = valid_gen.flow_from_dataframe(dataframe=df_valid, directory=path, \n                                                  x_col=\"path\", y_col=labels_cols, \n                                                  class_mode=\"raw\", \n                                                  # class_mode=\"categorical\", \n                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n\n    test_generator = valid_gen.flow_from_dataframe(dataframe=df_test, directory=path, \n                                                  x_col=\"path\", y_col=labels_cols, \n                                                  class_mode=\"raw\", \n                                                  shuffle = False,\n                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n    return   train_generator,   valid_generator, test_generator","d06b97d8":"train_generator, valid_generator, test_generator = gen_init(32,200)","c728eaab":"ti, tl = train_generator.next()\nimgs = []\nfor i in range(ti.shape[0]):\n    img = np.array(ti[i]*255, dtype = 'int32')\n    imgs.append(img)\n\nf, ax = plt.subplots(4, 8, figsize=(15,10))\nfor i, img in enumerate(imgs):\n    ax[i\/\/8, i%8].imshow(img)\n    ax[i\/\/8, i%8].axis('off')\n    ax[i\/\/8, i%8].set_title('label: %s' % tl[i])\nplt.show()","b45c1863":"def build_model(model_engine, IMG_Size):\n    inp = tf.keras.layers.Input(shape=(IMG_Size,IMG_Size,3))\n    base = model_engine(input_shape=(IMG_Size,IMG_Size,3),weights='imagenet',include_top=False)\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(4,activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 0.001)   \n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","f9c921c2":"all_model = []\nall_history = []\nall_preds = []\nall_accuracies = []\nall_confusion_matrices = []","ae092afc":"for model_name in MODELS:\n    engine = MODELS[model_name][0]\n    BS = MODELS[model_name][1]\n    IMG_Size = MODELS[model_name][2]\n    train_generator, valid_generator, test_generator = gen_init(BS, IMG_Size)\n    \n    model = build_model(engine, IMG_Size)\n    print('------------------------------------------------------------------')\n    print('Training model ', model_name)\n    history = model.fit(train_generator,\n              steps_per_epoch=len(df_train) \/ BS, epochs = N_epochs, verbose = 1,\n              callbacks=[es_callback, get_lr_callback(BS)],\n              validation_data = valid_generator)\n\n    model.save('model-%s.h5'%model_name)  \n    all_history.append(history)\n    \n    pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n    pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n    plt.show()\n\n    preds = model.predict(test_generator, verbose = 1)\n    all_preds.append(preds)\n    cm = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))\n    all_confusion_matrices.append(cm)\n    acc = accuracy_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))    \n    all_accuracies.append(acc)\n    print('------------------------------------------------------------------')\n    print(cm)\n    print(acc)\n    ","5cb3e723":"for i, model_name in enumerate(MODELS):\n    skplt.metrics.plot_confusion_matrix(\n        np.argmax(np.array(y_test), axis=1), np.argmax(all_preds[i], axis = 1),\n        figsize=(8,8))","e4530a5d":"for i, model_name in enumerate(MODELS):\n    skplt.metrics.plot_confusion_matrix(\n        np.argmax(np.array(y_test), axis=1), np.argmax(all_preds[i], axis = 1), normalize=True,\n        figsize=(8,8))","e18239ba":"print(all_accuracies)","279e67a9":"def gen_test_init(df, BS, IMG_Size):\n    tta_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=30,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        vertical_flip = True,\n        horizontal_flip=True)\n\n    valid_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)    \n\n    test_generator = valid_gen.flow_from_dataframe(dataframe=df, directory=path, \n                                                  x_col=\"path\", y_col=labels_cols, \n                                                  class_mode=\"raw\", \n                                                  shuffle = False,\n                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n    tta_test_generator = tta_gen.flow_from_dataframe(dataframe=df, directory=path, \n                                                  x_col=\"path\", y_col=labels_cols, \n                                                  class_mode=\"raw\", \n                                                  shuffle = False,\n                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n    return  tta_test_generator, test_generator","bf6c90a4":"all_preds_tta = []\nall_accuracies_tta = []\nall_confusion_matrices_tta = []\n\nmodel_name = 'EfficientNetB6'\nengine = MODELS[model_name][0]\nBS = MODELS[model_name][1]\nIMG_Size = MODELS[model_name][2]\ntta_test_generator, test_generator = gen_test_init(df_test, BS, IMG_Size)\n\nmodel = tf.keras.models.load_model('model-%s.h5'%model_name)\nprint('Predicting original images', model_name)\n\npreds_org = model.predict(test_generator, verbose = 1)\nall_preds_tta.append(preds_org)\ncm_org = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(preds_org, axis = 1))\nall_confusion_matrices_tta.append(cm_org)\nacc_org = accuracy_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds_org, axis = 1))    \nall_accuracies_tta.append(acc_org)\nprint(cm_org)\nprint(acc_org)\n\nfor i in range(N_TTA):\n    print('Predicting images TTA %i for %s'%(i, model_name))\n\n    preds_tta = model.predict(tta_test_generator, verbose = 1)\n    all_preds_tta.append(preds_tta)\n    cm_tta = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(preds_tta, axis = 1))\n    all_confusion_matrices_tta.append(cm_tta)\n    acc_org = accuracy_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds_tta, axis = 1))    \n    all_accuracies_tta.append(acc_org)\n    print(cm_tta)\n    print(acc_org)\n\navg_preds = np.mean(np.array(all_preds_tta),axis = 0)\ncm_tta = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(avg_preds, axis = 1))\nall_confusion_matrices_tta.append(cm_tta)\nacc_org = accuracy_score(np.argmax(np.array(y_test), axis=1), np.argmax(avg_preds, axis = 1))    \nall_accuracies_tta.append(acc_org)\nprint('Confusion matrix with %i TTA : '%N_TTA)\nprint(cm_tta)\nprint('Prediction with TTA - averaged accuracy %.4f' %acc_org) \n","6165b921":"all_preds_tta = []\nall_accuracies_tta = []\nall_confusion_matrices_tta = []\n\ntta_test_generator, test_generator = gen_test_init(df_test_ext, BS, IMG_Size)\nprint('Predicting original images', model_name)\n\npreds_org = model.predict(test_generator, verbose = 1)\nall_preds_tta.append(preds_org)\ncm_org = confusion_matrix(np.argmax(np.array(y_test_ext), axis=1), np.argmax(preds_org, axis = 1))\nall_confusion_matrices_tta.append(cm_org)\nacc_org = accuracy_score(np.argmax(np.array(y_test_ext), axis=1), np.argmax(preds_org, axis = 1))    \nall_accuracies_tta.append(acc_org)\nprint(cm_org)\nprint(acc_org)\n\nfor i in range(N_TTA):\n    print('Predicting augmented images batch %i for %s'%(i+1, model_name))\n\n    preds_tta = model.predict(tta_test_generator, verbose = 1)\n    all_preds_tta.append(preds_tta)\n    cm_tta = confusion_matrix(np.argmax(np.array(y_test_ext), axis=1), np.argmax(preds_tta, axis = 1))\n    all_confusion_matrices_tta.append(cm_tta)\n    acc_org = accuracy_score(np.argmax(np.array(y_test_ext), axis=1), np.argmax(preds_tta, axis = 1))    \n    all_accuracies_tta.append(acc_org)\n    print(cm_tta)\n    print(acc_org)\n\navg_preds = np.mean(np.array(all_preds_tta),axis = 0)\ncm_tta = confusion_matrix(np.argmax(np.array(y_test_ext), axis=1), np.argmax(avg_preds, axis = 1))\nall_confusion_matrices_tta.append(cm_tta)\nacc_org = accuracy_score(np.argmax(np.array(y_test_ext), axis=1), np.argmax(avg_preds, axis = 1))    \nall_accuracies_tta.append(acc_org)\nprint('Confusion matrix with %i TTA : '%N_TTA)\nprint(cm_tta)\nprint('Prediction with TTA - averaged accuracy %.4f' %acc_org) ","5090e186":"skplt.metrics.plot_confusion_matrix(\n        np.argmax(np.array(y_test_ext), axis=1), np.argmax(avg_preds, axis = 1), normalize=False,\n        figsize=(8,8))\nskplt.metrics.plot_confusion_matrix(\n        np.argmax(np.array(y_test_ext), axis=1), np.argmax(avg_preds, axis = 1), normalize=True,\n        figsize=(8,8))","598be38e":"# Import libraries","e3671b5a":"And now for an alternative view here all these matrices are normalized.","3b6defc3":"# Preparations\nInitialize hyperparameters","4b0d4f09":"Let's check a few of the original images","128b8599":"We will also test if **Test Time Augmentation** (TTA) will help in this case","e352bc21":"And here we clearly see that unfortunately our model learnt to recognize flowers\/blossom for both bees and wasps. And surprisingly the problem is more severe with images of wasps than bees. <br> We shall have more such images in our data set, and include them in the training set to cope with the issue.","c6c8e8da":"Creating all dataframes","1bea98f2":"Looks like EfficientNetB6 is winning with all other parameters set similarly for all models. Although EfficientNetB3 performs well too.\nLets analyze what will happen when we add some flowers\/blossom without any insects, to find out if the model simply recognizes flowers or bees in fact (Task 2 that George Rey defined for the dataset).\nWe'll add the new images to the test set only.","85f8f64a":"And we see that we get a significant boost from the **TTA** . <br>\nNow lets check what happens when we add images of flowers without bees from mine dataset to the test set","f6293095":"\nLets check the result of the train data generator preprocessing, just a single batch of images","97fa67ec":"Define data generators","1cc1a313":"Defining learning rate scheduler and early stopping callbacks","f2ae9143":"# Main part\nBuild a basic model template, so we can try a few different engines from the MODEL dictionary","88bcb52b":"First of all I want to thank @jerzydziewierz for the interesting challenge.\nIn this notebook I'm trying to address 2 questions: selection of the most efficient model, and if the model learning to recognize insects of flowers. <br>\nI'm selecting between 4 models, using Tensorflow generators for image delivery and augmentations. There is also Test Time Augmentations applied to see how efficient it can be in this case. <br>\nI created a supplemental dataset consisiting of 370 images of just flowers to verify the bias of the model.","7879cd71":"# Analysis\nLets have a look at all of the confusion matrices"}}