{"cell_type":{"e2283514":"code","1a325726":"code","982435f0":"code","284153d9":"code","6da8bd19":"code","b5d930f3":"code","7c5c28ab":"markdown","e215f9a8":"markdown","7a75af4a":"markdown","0484d2dd":"markdown","982935ff":"markdown","13959580":"markdown"},"source":{"e2283514":"#Import the neccessary modules\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup","1a325726":"number_titles = 2000\nmovie_text = pd.read_csv('movies_metadata.csv', low_memory=False)[:number_titles][['original_title','overview']]","982435f0":"#Import neccessary modules\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\n#Read the first 2000 parts of the dataset\nnumber_titles = 2000\nmovie_text = pd.read_csv('movies_metadata.csv', low_memory=False)[:number_titles][['original_title','overview']]\nmovie_text = movie_text.fillna(\"none\")\n#Create a list with the movie overviews(summaries)\nmovie_overview = list(np.array(movie_text['overview']))\n\n#Begin making the lists that will be used for the parsing\ntitles = [title for title in movie_text['original_title']]\nratings = []\nfor title in titles:\n    #Format the title so that the rotten tomatoes website can read it\n    title = '_'.join(title.split())\n    #Get the URL based off of the title, and use BeautifulSoup and requests to parse through it in html\n    theURL = 'https:\/\/www.rottentomatoes.com\/m\/{}'.format(title)\n    google_page = requests.get(theURL)\n    soup_google = BeautifulSoup(google_page.text, \"html.parser\")\n    #In the span class, there is the Rotten Tomatoes rating, and this line of code finds it\n    rating_html = soup_google.find_all('span', {'class':'mop-ratings-wrap__percentage'})\n    #There are some movies that Rotten Tomatoes hasn't rated. This try except code will append 'no rating' if that's the case\n    canDo = True\n    try:\n        the_split = str(rating_html[0]).split('>')[1]\n    except:\n        canDo = False\n        ratings.append('no rating')\n    #If there was no exception, the code then appends the actual rating to the list\n    if canDo:\n        the_num = int(the_split.rstrip('\\n').split('%')[0])\n        ratings.append(the_num)\n        \n#Make everything into numpy arrays for the pd DataFrame to understand        \ntitles = np.array(titles)\nratings = np.array(ratings)\nmovie_overview = np.array(movie_overview)\n\n#Finally, make everything into a pandas datafram and convert that to a csv file\ndataset = pd.DataFrame({\n    \"title\":titles,\n    \"RT rating\":ratings,\n    \"overview\":movie_overview\n})\ndataset.to_csv('movie_rating_overview.csv', index=False)","284153d9":"original_dataset = pd.read_csv('movie_rating_overview_2.csv') #My dataset\nnew_dataset = pd.DataFrame({\n    \"title\":titles,\n    \"RT rating\":ratings,\n    \"overview\":movie_overview\n})\noriginal_dataset = original_dataset.append(new_dataset)\noriginal_dataset.to_csv('better_movie_rating_overview.csv', index=False)","6da8bd19":"#This code is inside the for loop:\ntheURL = 'https:\/\/www.google.com\/search?safe=strict&rlz=1C1CHBF_enUS851US851&sxsrf=ALeKk02JvMu2BU4Qp3tBW4ULuXTXIRqljA%3A1606182990021&ei=Tmi8X7ZpxIq1BdOukcgI&q=rotten+tomatoes+score{}&oq=infinity+war+movie&gs_lcp=CgZwc3ktYWIQAzIHCC4QDRCTAjIECAAQDTIECAAQDTIECAAQDTIGCAAQBxAeMgQIABANMgQIABANMgQIABANMgQIABANMgQIABANOgcILhBDEJMCOgQIABBDOgUIABCxAzoHCAAQsQMQQzoECC4QQzoCCAA6CgguEBQQhwIQkwI6BAguEApQqb4rWJiALGDMgCxoAHABeACAAYYCiAGCDZIBBjAuMTAuMpgBAKABAaoBB2d3cy13aXrAAQE&sclient=psy-ab&ved=0ahUKEwi2yMH0iZrtAhVERa0KHVNXBIkQ4dUDCA0&uact=5'.format(title)\ngoogle_page = requests.get(theURL)\nsoup_google = BeautifulSoup(google_page.text, \"html.parser\")\nrating_html = soup_google.find_all('span', {'class':'XLloXe AP7Wnd'})\ncanDo = True\ntry:\n    #This is the way in order to get the rotten tomatoes score that pops up when you search it up\n    theNum = int(str(soup_google).split('%<\/span>')[0].split('Jd\">')[1]) \nexcept:\n    canDo = False\n    ratings.append('no rating')\nif canDo:\n    ratings.append(theNum)","b5d930f3":"#Import neccessary modules\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\n#Read the first 4000 parts of the dataset\nthe_amount = 4000\nmovie_text = pd.read_csv('movies_metadata.csv', low_memory=False)[:the_amount][['original_title','overview']]\nmovie_text = movie_text.fillna(\"none\")\n#Create a list with the movie overviews(summaries)\nmovie_overview = list(np.array(movie_text['overview']))\n\n#Begin making the lists that will be used for the parsing\ntitles = [title for title in movie_text['original_title']]\nratings = []\ncounter = 0\nfor title in titles:\n    title = title.lower()\n    title = '_'.join(title.split())\n    #Use the Google URL and parse through it\n    theURL = 'https:\/\/www.google.com\/search?safe=strict&rlz=1C1CHBF_enUS851US851&sxsrf=ALeKk02JvMu2BU4Qp3tBW4ULuXTXIRqljA%3A1606182990021&ei=Tmi8X7ZpxIq1BdOukcgI&q=rotten+tomatoes+score{}&oq=infinity+war+movie&gs_lcp=CgZwc3ktYWIQAzIHCC4QDRCTAjIECAAQDTIECAAQDTIECAAQDTIGCAAQBxAeMgQIABANMgQIABANMgQIABANMgQIABANMgQIABANOgcILhBDEJMCOgQIABBDOgUIABCxAzoHCAAQsQMQQzoECC4QQzoCCAA6CgguEBQQhwIQkwI6BAguEApQqb4rWJiALGDMgCxoAHABeACAAYYCiAGCDZIBBjAuMTAuMpgBAKABAaoBB2d3cy13aXrAAQE&sclient=psy-ab&ved=0ahUKEwi2yMH0iZrtAhVERa0KHVNXBIkQ4dUDCA0&uact=5'.format(title)\n    google_page = requests.get(theURL)\n    soup_google = BeautifulSoup(google_page.text, \"html.parser\")\n    rating_html = soup_google.find_all('span', {'class':'XLloXe AP7Wnd'})\n    #Use a try and except to see if google displays the rotten tomatoes score or not\n    canDo = True\n    try:\n        theNum = int(str(soup_google).split('%<\/span>')[0].split('Jd\">')[1])\n    except:\n        canDo = False\n        ratings.append('no rating')\n    #If it can, append the number to the ratings array\n    if canDo:\n        ratings.append(theNum)\n        \n#Make everything into numpy arrays for the pd DataFrame to understand        \ntitles = np.array(titles)\nratings = np.array(ratings)\nmovie_overview = np.array(movie_overview)\n\n#Finally, make everything into a pandas datafram and convert that to a csv file\ndataset = pd.DataFrame({\n    \"title\":titles,\n    \"RT rating\":ratings,\n    \"overview\":movie_overview\n})\ndataset.to_csv('movie_rating_overview.csv', index=False)","7c5c28ab":"This is the full code for parsing through the Google Website, just in case you need it:","e215f9a8":"This is the code that I used in order to get the rating and overview data for this dataset. In case you want to tamper with this code to add extra data as you need, feel free to do just that. However, it takes a while to get the data, which is why I only used the first 2000 datasets. I have added the dataset with 11000 movie titles in this notebook.","7a75af4a":"In case you want to add to the original dataset so you don't have to waste time going through the first 2000 titles that I've already done in the dataset, here's what you can do:","0484d2dd":"As you can see in this line of code, I searched through the first 2000 titles and overview of the dataset. You can tamper this as you wish","982935ff":"The next batch of code will be the whole code that I used to make this, in case you want to change number_titles","13959580":"However, if you get blocked by the Rotten Tomatoes website for parsing through their website, another option is to parse through the google website itself:"}}