{"cell_type":{"795494dd":"code","4409ab5a":"code","7fd7eef9":"code","0a27b5ac":"code","fa40afd1":"code","a1192eb3":"code","4b88f898":"code","e7f1eeda":"code","5340d472":"code","d9fc7720":"code","6d33dbf8":"code","043bfb38":"code","28e0e4e9":"code","21b206cb":"code","d0ccc5fd":"code","57f1d478":"code","9bbcc275":"code","1d9c93a4":"code","f7e1d49c":"code","3f14fdc8":"code","b2c8d0e4":"code","074b9d55":"code","cf2be98f":"code","2db305ef":"code","4b4d3d19":"markdown","54692f2f":"markdown","9d0d530f":"markdown","83e7ea23":"markdown","bc171ee9":"markdown","d9e04944":"markdown","945751ee":"markdown","1f7f5596":"markdown","ef8ee43f":"markdown","7d16c3d3":"markdown","ece68c91":"markdown","f506b223":"markdown","4ec0f019":"markdown"},"source":{"795494dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4409ab5a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import RandomizedSearchCV","7fd7eef9":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","0a27b5ac":"train.info()\nprint('.'*38)\ntest.info()","fa40afd1":"train.head()","a1192eb3":"train.describe()","4b88f898":"train.set_index('PassengerId', inplace=True)\ntest.set_index('PassengerId', inplace=True)","e7f1eeda":"train.drop(['Ticket','Cabin'], axis=1, inplace=True)\ntest.drop(['Ticket','Cabin'], axis=1, inplace=True)","5340d472":"\ntrain['Embarked'].fillna('S', inplace=True)","d9fc7720":"test[test['Fare'].isnull()]","6d33dbf8":"test['Fare'].fillna(7.9, inplace=True)","043bfb38":"train['Sex'] = preprocessing.LabelEncoder().fit_transform(train['Sex'].values)\ntest['Sex'] = preprocessing.LabelEncoder().fit_transform(test['Sex'].values)\ntrain['Embarked'] = preprocessing.LabelEncoder().fit_transform(train['Embarked'].values)\ntest['Embarked'] = preprocessing.LabelEncoder().fit_transform(test['Embarked'].values)","28e0e4e9":"for dataset in train, test:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","21b206cb":"train[\"Age\"] = train[['Pclass', 'Sex', 'Age']].groupby(['Pclass', 'Sex']).transform(lambda x: x.fillna(x.median()))\ntest[\"Age\"] = test[['Pclass', 'Sex', 'Age']].groupby(['Pclass', 'Sex']).transform(lambda x: x.fillna(x.median()))","d0ccc5fd":"for dataset in train, test:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n    dataset['Age'] = dataset['Age'].astype(int)","57f1d478":"train.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","9bbcc275":"y_train = train[\"Survived\"]\ntrain.drop('Survived', axis=1, inplace=True)\ntrain.shape, y_train.shape, test.shape","1d9c93a4":"random_forest = RandomForestClassifier()\nrandom_forest.fit(train, y_train)\nscores = cross_validate(random_forest, train, y_train, scoring='roc_auc', cv=5, return_train_score=True)\nscores","f7e1d49c":"n_est = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_feat = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_est,\n               'max_features': max_feat,\n               'max_depth': max_depth,\n               'criterion' :['gini', 'entropy'],\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nrandom_grid","3f14fdc8":"# Random grid to search for best hyperparameters\n#rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 4, verbose=2, random_state=42, n_jobs = -1)\n#rf_random.fit(train, y_train)","b2c8d0e4":"#rf_random.best_estimator_","074b9d55":"#scores = cross_validate(rf_random.best_estimator_, train, y_train, scoring='roc_auc', cv=4, return_train_score=True)\n#scores","cf2be98f":"model = RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=5,\n                       min_samples_leaf=2, min_samples_split=10,\n                       n_estimators=1800)\nmodel.fit(train, y_train)\ny_pred = model.predict(test)","2db305ef":"submission = pd.DataFrame({\n        \"PassengerId\": test.index,\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('.\/submission.csv', index=False)","4b4d3d19":"Just one null value. Fill with most frequent value.","54692f2f":"Encode label based on age and survival correlation.","9d0d530f":"Label Encoding for categorical values. Is get_dummies better?","83e7ea23":"Tune Hyperparameters","bc171ee9":"Parameter derivation code commented out as its output is saved below.","d9e04944":"Ticket has too much noise and doesn't have any visible correlation with survived.\nCabin has too many null values with no significant correlation.","945751ee":"**Classifier**","1f7f5596":"Encode label based on pClass and fare range.","ef8ee43f":"Guess null values with median based on pClass relation. Better notebooks infer age based on name(title).","7d16c3d3":"Just one null value. Fill with Pclass relation.","ece68c91":"**This notebook shows only the workings of the final model without the initial data exploration process.**","f506b223":"Random forest classifier with tuned parameters.","4ec0f019":"RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=5,\n                       min_samples_leaf=2, min_samples_split=10,\n                       n_estimators=1800)"}}