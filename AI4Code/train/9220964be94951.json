{"cell_type":{"a82c3c45":"code","db983963":"code","9f3d9f21":"code","24770e86":"code","1fd06fce":"code","b306bbb1":"code","3b4c6851":"code","0ea0d14a":"code","9e22301b":"code","4136651c":"code","0f3791e7":"code","6674d11d":"code","1f8f175d":"code","78303158":"code","c865a593":"code","769f54f3":"code","5c44b76d":"code","8f1d493a":"code","0b6ce504":"code","ffb638ff":"code","ddc436bf":"code","40e701e2":"code","bf59dd74":"code","a35fbb48":"code","314c2707":"code","b6964309":"code","ad1448da":"code","a82313ae":"code","84a99823":"code","d17a7783":"code","016c6f5b":"code","4b76af2d":"code","4c5d8757":"code","b926845e":"code","2d5f20a4":"code","17b27e05":"code","fa2eaba4":"code","680e4de8":"markdown","1b8fb071":"markdown"},"source":{"a82c3c45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings('ignore')","db983963":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom random import randrange\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9f3d9f21":"data = np.load('\/kaggle\/input\/pair_data.npy', allow_pickle=True)\ndata_length = data.__len__()","24770e86":"atoms = np.zeros(shape=(data_length, 32))\nenvs = np.zeros(shape=(data_length, 32))\nfreqs = np.zeros(shape=data_length)\n\nfor i in range(data.__len__()):\n    x = data[i]\n    atoms[i] = x['center']\n    envs[i] = x['env']\n    freqs[i] = x['freq']","1fd06fce":"def atom_hash(atom):\n    hash = 0\n    for i in range(atom.__len__()):\n        hash += atom[i] * 2**i\n    return hash","b306bbb1":"set_atom_hash = set()\nfor i in range(atoms.__len__()):    \n    set_atom_hash.add(atom_hash(atoms[i]))\nset_atom_hash.__len__()","3b4c6851":"set_env_hash = set()\nfor i in range(envs.__len__()):    \n    set_env_hash.add(atom_hash(envs[i]))\nset_env_hash.__len__()","0ea0d14a":"atom_train, atom_test, env_train, env_test = train_test_split(atoms, envs, test_size=0.1, random_state=42)","9e22301b":"label_1 = np.concatenate((env_train, atom_train), axis=1)","4136651c":"def generate_label_0(atom_data, env_data, num_label=4):\n    data_length = atom_data.__len__()\n    label_0_data = []\n    for i in range(atom_data.__len__()):\n        count_random_index = 0\n        while count_random_index < num_label:\n            random_index = randrange(data_length)\n            if random_index != i:                \n                label_0_data.append(np.concatenate((env_data[i], atom_data[int(random_index)])))\n                count_random_index += 1\n    return label_0_data","0f3791e7":"label_0 = generate_label_0(atom_train, env_train)\nlabel_0_ndarray = np.array(label_0)","6674d11d":"label_1.shape, label_0_ndarray.shape","1f8f175d":"train_label_0 = pd.DataFrame(label_0_ndarray)\ntrain_label_1 = pd.DataFrame(label_1)","78303158":"train_label_0['label'] = 0\ntrain_label_1['label'] = 1","c865a593":"data_columns = ['env_' + str(i) for i in range(32)] + ['atom_' + str(i) for i in range(32)] + ['label']\ntrain = pd.concat((train_label_0, train_label_1), axis=0)\ntrain.columns = data_columns","769f54f3":"train['label'].value_counts()","5c44b76d":"from keras.layers import Dense, Input\nfrom keras.layers import concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, Adagrad","8f1d493a":"atom_inp = Input(shape=(32, ))\nenv_inp = Input(shape=(32, ))\nh_1_atom = Dense(100, activation='relu')(atom_inp)\nh_1_env = Dense(100, activation='relu')(env_inp)\nh_1_combine = concatenate([h_1_atom, h_1_env])\nh_2 = Dense(100, activation='relu')(h_1_combine)\nout = Dense(1, activation='sigmoid')(h_2)\nmodel = Model(inputs=[atom_inp, env_inp], outputs=out)","0b6ce504":"model.summary()","ffb638ff":"X_all = train.drop(columns='label')\ny_all = train['label']\nX_all._is_copy = False\nX_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=42)","ddc436bf":"env_columns = ['env_' + str(i) for i in range(32)]\natom_columns = ['atom_' + str(i) for i in range(32)]","40e701e2":"X_train[env_columns].head(10)","bf59dd74":"all_atoms = []\natom_hashs = set()\nfor atom in atoms:\n    a_hash = atom_hash(atom)\n    if not atom_hashs.__contains__(a_hash):\n        all_atoms.append(atom)\n        atom_hashs.add(a_hash)","a35fbb48":"atom_hash_test = []\nfor atom in atom_test:\n    atom_hash_test.append(atom_hash(atom))","314c2707":"test_env_hash = [atom_hash(env) for env in env_test]","b6964309":"env_test_df = pd.DataFrame(env_test)\nenv_test_df.columns = ['env_' + str(i) for i in range(32)]\nenv_test_df['true_atom_hash'] = atom_hash_test\nenv_test_df['env_hash'] = test_env_hash","ad1448da":"all_atom_hash = [atom_hash(atom) for atom in all_atoms]","a82313ae":"all_atom_df = pd.DataFrame(all_atoms)\nall_atom_df.columns = ['atom_' + str(i) for i in range(32)]\nall_atom_df['atom_hash'] = all_atom_hash","84a99823":"env_test_df['tmp'] = 1\nall_atom_df['tmp'] = 1\ntest_data = pd.merge(env_test_df, all_atom_df, how='left', on='tmp')","d17a7783":"# opt = Adam(lr=1e-3, decay=1e-3 \/ 200)\nopt = Adagrad(lr=0.001, epsilon=None, decay=0.0)\nmodel.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=['accuracy'])\n# model.compile(loss=\"binary_crossentropy\", optimizer=opt,  metrics=['accuracy'])\n \n# train the model\nprint(\"[INFO] training model...\")\nmodel.fit([X_train[env_columns], X_train[atom_columns]], y_train,\n          validation_data=([X_val[env_columns], X_val[atom_columns]], y_val),\n          epochs=10, batch_size=128, verbose=2)","016c6f5b":"from keras import backend as K\nK.tensorflow_backend._get_available_gpus()","4b76af2d":"test_data.sample(3)","4c5d8757":"test_data.columns.__len__()","b926845e":"# make predictions on the testing data\nprint(\"[INFO] predicting molecule properties...\")\nlabel_predict = model.predict([test_data[env_columns], test_data[atom_columns]])","2d5f20a4":"test_data['predict'] = label_predict","17b27e05":"top_k = 1\ncount_match = 0\nfor env_hash in test_data['env_hash'].unique():\n    a_env = test_data[test_data.env_hash == env_hash]\n    true_atom_hash = a_env['true_atom_hash'].values[0]\n    a_env_data = a_env[['predict', 'atom_hash']].values\n    a_env_data = [(x0, x1) for x0, x1 in a_env_data]\n    a_env_data.sort(key=lambda x: x[0], reverse=True)\n    top_k_atoms = [x[1] for x in a_env_data[:top_k]]\n    if top_k_atoms.__contains__(true_atom_hash):\n        count_match += 1","fa2eaba4":"count_match\/test_data['env_hash'].unique().__len__()","680e4de8":"## generate test data","1b8fb071":"## Train model"}}