{"cell_type":{"52693560":"code","d89e4e46":"code","94f111ea":"code","355be376":"code","ea6538c9":"code","00addbb6":"code","db18a982":"code","9fc945be":"code","650dfe30":"markdown","7a5e0424":"markdown","1cda07d6":"markdown","e5845140":"markdown"},"source":{"52693560":"from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns","d89e4e46":"from sklearn.datasets import load_digits\ndigits = load_digits()\n\ndigits_df =  pd.DataFrame(digits.data)\ndigits_df['image'] = list(digits.images)\ndigits_df['target'] = digits.target\ndigits_df['target_names'] = [digits.target_names[t] for t in digits.target]\ndigits_target_col = 'target'\ndigits_feature_col = np.arange(0,64)","94f111ea":"digits_df","355be376":"# Splitting\nX, y = digits_df.iloc[:,:64], digits_df['target']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=112)\n\n# Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler().fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# KNN model\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nmodel = knn(n_neighbors=5).fit(X_train_scaled, y_train)\n\n# Evaluate\nmodel.score(X_test_scaled, y_test)","ea6538c9":"from sklearn.datasets import make_blobs\n\n# Create Data\ndata, real_cluster = make_blobs(n_samples=200, n_features=2, \n                        centers=4, cluster_std=1.0,random_state=112)\n\n# Normalize\nscaler = MinMaxScaler().fit(data)\ndata_scaled = scaler.transform(data)\n\n# Visualize\nplt.scatter(data_scaled[:,0],data_scaled[:,1],c=real_cluster,cmap='jet');","00addbb6":"from sklearn.cluster import KMeans\n\nk = 4\nmodel = KMeans(n_clusters=k).fit(data_scaled)\n\nprint(f\"Assigned clusters : {model.labels_}\\n\\nCentroid of each cluster : \\n{model.cluster_centers_}\")","db18a982":"fig, ax = plt.subplots(1,2, figsize=(12,4))\n\nax[0].set_title(\"Real cluster\")\nax[0].scatter(data_scaled[:,0],data_scaled[:,1],c=real_cluster,cmap='jet')\n\nax[1].set_title(\"Assigned cluster\")\nax[1].scatter(data_scaled[:,0],data_scaled[:,1],c=model.labels_,cmap='viridis')\nax[1].scatter(model.cluster_centers_[:,0], model.cluster_centers_[:,1], label='centroid', c='red')\nplt.legend();","9fc945be":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(data_scaled)\n    distortions.append(model.inertia_)\n    \nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","650dfe30":"From k=2 to k=3, the distortion decrease **significantly**. So, it's **worth** to go further (use k=3). <br>\nFrom k=4 to k=5, the distortion decrease **trivialy**. So, we can **stop** at k=4.","7a5e0424":"# KNN classifier\n---\n<div class='alert alert-success'>\n    <ol>\n        <li>Put a query data point in the <strong>feature space<\/strong> <\/li>\n        <li>Data point class = the most common class of <i>k nearest neighbors<\/i><\/li>\n    <\/ol>\n<\/div>\n\n**feature space** -> All features have to be in the <strong><u>same scale<\/u><\/strong>!!! <br>\n**k** -> Hyperparameter, if too low -> very sensitive to surrounding datapoints. If too high -> baseline model.","1cda07d6":"# K-mean clustering\n___\n<div class='alert alert-success'>\n    <h4>We want to make <i>k<\/i> clusters out of our data<\/h4>\n    <ol>\n        <li>Randomly place <i>k<\/i> <strong>centroid<\/strong> in the feature space<\/li>\n        <li>Repeat until no update : \n            <ul>\n                <li>Assign each point to be a member of nearest centriod<\/li>\n                <li>Calculate the new centriod of each cluster<\/li>\n            <\/ul>\n        <\/li>\n    <\/ol>\n<\/div>\n\n**feature space** -> All features have to be in the <strong><u>same scale<\/u><\/strong>!!! <br>\n**k** -> Specify by <strong><u>elbow-method<\/u><\/strong>","e5845140":"### Elbow method"}}