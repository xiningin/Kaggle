{"cell_type":{"6c26acc8":"code","e9741fd5":"code","7a1e5866":"code","ec3af2b7":"code","5db7e374":"code","62f0ee81":"code","c4988ae9":"code","d4059be9":"code","72f33b24":"code","d51d04c7":"code","05c47dd6":"code","99e4a529":"code","b612353d":"code","3d1374c2":"code","335b75e6":"code","6c950070":"code","ac5128d7":"code","98b56c97":"code","a0b7fbaa":"code","f2a7dee5":"code","b878a1a5":"code","f882dbed":"code","a919ae40":"code","050933ce":"code","b26e9520":"code","7db5b10f":"code","0bba5f86":"code","e2d6a562":"code","4c4f9b32":"markdown","6490f042":"markdown","3e59f176":"markdown","fe909d98":"markdown","d6505621":"markdown","16941818":"markdown","31871712":"markdown","27866d93":"markdown","6b0bf414":"markdown","4bf82d26":"markdown","a052cb06":"markdown","66e0633a":"markdown","789c39b8":"markdown","de2480ac":"markdown"},"source":{"6c26acc8":"%%html\n<style> \n@import url('https:\/\/fonts.googleapis.com\/css?family=Orbitron|Roboto&effect=3d');\nbody {background-color: gainsboro;} \nh3 {color:#818286; font-family:Roboto;}\nspan {color:black; text-shadow:4px 4px 4px #aaa;}\ndiv.output_prompt,div.output_area pre {color:slategray;}\ndiv.input_prompt,div.output_subarea {color:#37c9e1;}      \ndiv.output_stderr pre {background-color:gainsboro;}  \ndiv.output_stderr {background-color:slategrey;}                \n<\/style>","e9741fd5":"import warnings; warnings.filterwarnings(\"ignore\")\nimport numpy as np,pandas as pd\nimport pylab as plt,seaborn as sns\nimport matplotlib.colors as mcolors\nfrom descartes import PolygonPatch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import median_absolute_error,mean_absolute_error\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.metrics import explained_variance_score\nfrom keras.models import Sequential,Model\nfrom keras.optimizers import SGD,RMSprop\nfrom keras.layers import Dense,Dropout,LSTM\nfrom keras.layers import Activation,Flatten,Input,BatchNormalization\nfrom keras.layers import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom keras.callbacks import ModelCheckpoint\ncmap=plt.cm.get_cmap('Spectral',4)\nspectral_cmap=[]\nfor i in range(cmap.N):\n    rgb=cmap(i)[:3]\n    spectral_cmap.append(mcolors.rgb2hex(rgb))\nplt.style.use('seaborn-whitegrid'); path='..\/input\/'\nfw='weights.passnyc.hdf5'","7a1e5866":"def scores(regressor,y_train,y_valid,y_test,\n           y_train_reg,y_valid_reg,y_test_reg):\n    print(20*\"<=>\"); print(regressor); print(20*\"<=>\")\n    print(\"EV score. Train: \",\n          explained_variance_score(y_train,y_train_reg))\n    print(\"EV score. Valid: \",\n          explained_variance_score(y_valid,y_valid_reg))\n    print(\"EV score. Test: \",\n          explained_variance_score(y_test,y_test_reg))\n    print(20*\"<=>\")\n    print(\"R2 score. Train: \",r2_score(y_train,y_train_reg))\n    print(\"R2 score. Valid: \",r2_score(y_valid,y_valid_reg))\n    print(\"R2 score. Test: \",r2_score(y_test,y_test_reg))\n    print(20*\"<=>\")\n    print(\"MSE score. Train: \",\n          mean_squared_error(y_train,y_train_reg))\n    print(\"MSE score. Valid: \",\n          mean_squared_error(y_valid,y_valid_reg))\n    print(\"MSE score. Test: \",\n          mean_squared_error(y_test,y_test_reg))\n    print(20*\"<=>\")\n    print(\"MAE score. Train: \",\n          mean_absolute_error(y_train,y_train_reg))\n    print(\"MAE score. Valid: \",\n          mean_absolute_error(y_valid,y_valid_reg))\n    print(\"MAE score. Test: \",\n          mean_absolute_error(y_test,y_test_reg))\n    print(20*\"<=>\")\n    print(\"MdAE score. Train: \",\n          median_absolute_error(y_train,y_train_reg))\n    print(\"MdAE score. Valid: \",\n          median_absolute_error(y_valid,y_valid_reg))\n    print(\"MdAE score. Test: \",\n          median_absolute_error(y_test,y_test_reg))\ndef history_plot(fit_history,n):\n    keys=list(fit_history.history.keys())[0:4]\n    plt.figure(figsize=(11,10)); plt.subplot(211)\n    plt.plot(fit_history.history[keys[0]][n:],\n             color='slategray',label='train')\n    plt.plot(fit_history.history[keys[2]][n:],\n             color='#37c9e1',label='valid')\n    plt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\")\n    plt.legend(); plt.title('Loss Function')    \n    plt.subplot(212)\n    plt.plot(fit_history.history[keys[1]][n:],\n             color='slategray',label='train')\n    plt.plot(fit_history.history[keys[3]][n:],\n             color='#37c9e1',label='valid')\n    plt.xlabel(\"Epochs\"); plt.ylabel(\"MAE\"); plt.legend()\n    plt.title('Mean Absolute Error'); plt.show() ","ec3af2b7":"school_explorer=pd.read_csv(path+'2016 School Explorer.csv')\nd5_shsat=pd.read_csv(path+'D5 SHSAT Registrations and Testers.csv')\nschool_explorer.shape,d5_shsat.shape","5db7e374":"drop_list=['Adjusted Grade','New?','Other Location Code in LCGMS']\nschool_explorer=school_explorer.drop(drop_list,axis=1)\nschool_explorer.loc[[427,1023,712,908],'School Name']=\\\n['P.S. 212 D12','P.S. 212 D30','P.S. 253 D21','P.S. 253 D27']\nschool_explorer['School Income Estimate']=\\\nschool_explorer['School Income Estimate'].astype('object') \nfor s in [\",\",\"$\",\" \"]:\n    school_explorer['School Income Estimate']=\\\n    school_explorer['School Income Estimate'].str.replace(s,\"\")\nschool_explorer['School Income Estimate']=\\\nschool_explorer['School Income Estimate'].str.replace(\"nan\",\"0\")\nschool_explorer['School Income Estimate']=\\\nschool_explorer['School Income Estimate'].astype(float)\nschool_explorer['School Income Estimate'].replace(0,np.NaN,inplace=True)\npercent_list=['Percent ELL','Percent Asian','Percent Black',\n              'Percent Hispanic','Percent Black \/ Hispanic',\n              'Percent White','Student Attendance Rate',\n              'Percent of Students Chronically Absent',\n              'Rigorous Instruction %','Collaborative Teachers %',\n              'Supportive Environment %','Effective School Leadership %',\n              'Strong Family-Community Ties %','Trust %']\ntarget_list=['Average ELA Proficiency','Average Math Proficiency']\neconomic_list=['Economic Need Index','School Income Estimate']\nrating_list=['Rigorous Instruction Rating','Collaborative Teachers Rating',\n             'Supportive Environment Rating','Effective School Leadership Rating',\n             'Strong Family-Community Ties Rating','Trust Rating',\n             'Student Achievement Rating']\nfor el in percent_list:\n    school_explorer[el]=school_explorer[el].astype('object')\n    school_explorer[el]=school_explorer[el].str.replace(\"%\",\"\")\n    school_explorer[el]=school_explorer[el].str.replace(\"nan\",\"0\")\n    school_explorer[el]=school_explorer[el].astype(float)\n    school_explorer[el].replace(0,np.NaN,inplace=True)\n    school_explorer[el]=school_explorer[el].interpolate()\nfor el in target_list+economic_list:\n    school_explorer[el]=school_explorer[el].interpolate()\nfor el in rating_list:\n    moda_value=school_explorer[el].value_counts().idxmax()\n    school_explorer[el]=school_explorer[el].fillna(moda_value)    \ncategory_list=['District','Community School?','City','Grades']               \nfor feature in category_list:\n    feature_cat=pd.factorize(school_explorer[feature])\n    school_explorer[feature]=feature_cat[0]    \nfor feature in rating_list:\n    feature_pairs=dict(zip(['Not Meeting Target','Meeting Target', \n                            'Approaching Target','Exceeding Target'],\n                            ['0','2','1','3']))\n    school_explorer[feature].replace(feature_pairs,inplace=True)\n    school_explorer[feature]=school_explorer[feature].astype(int)    \ncategory_list=list(category_list+rating_list)\nnumeric_list=list(school_explorer\\\n.columns[[4,5]+list(range(13,24))+[25,27,29,31,33]+list(range(38,158))])    \nprint('Number of Missing Values: ',sum(school_explorer.isna().sum())) ","62f0ee81":"sat_list=['DBN','Number of students who registered for the SHSAT',\n          'Number of students who took the SHSAT']\nd5_shsat_2016=d5_shsat[sat_list][d5_shsat['Year of SHST']==2016]\\\n.groupby(['DBN'],as_index=False).agg(np.sum)\nd5_shsat_2016['Took SHSAT %']=\\\nd5_shsat_2016['Number of students who took the SHSAT']\\\n\/d5_shsat_2016['Number of students who registered for the SHSAT']\nd5_shsat_2016['Took SHSAT %']=\\\nd5_shsat_2016['Took SHSAT %'].fillna(0).apply(lambda x:round(x,3))\nd5_shsat_2016.rename(columns={'DBN':'Location Code'},inplace=True)\nd5_shsat_2016=\\\npd.merge(school_explorer[['Location Code']+numeric_list+\\\n                         category_list+target_list],\n         d5_shsat_2016,on='Location Code')\nd5_shsat_2016.shape","c4988ae9":"features1=school_explorer[numeric_list+target_list]\\\n.drop(economic_list,axis=1).values\ntargets1=school_explorer['Economic Need Index'].values\nX_train1,X_test1,y_train1,y_test1=\\\ntrain_test_split(features1,targets1,test_size=.2,random_state=1)\nn=int(len(X_test1)\/2)\nX_valid1,y_valid1=X_test1[:n],y_test1[:n]\nX_test1,y_test1=X_test1[n:],y_test1[n:]\n# data = school_explorer\n# features = numeric variables + target_list - economic_list\n# targets = Economic Need Index\n[X_train1.shape,X_test1.shape,X_valid1.shape,\ny_train1.shape,y_test1.shape,y_valid1.shape]","d4059be9":"features2=school_explorer[numeric_list+target_list]\\\n.drop(economic_list, axis=1).values\ntargets2=school_explorer['School Income Estimate'].values\nX_train2,X_test2,y_train2,y_test2=\\\ntrain_test_split(features2,targets2,test_size=.2,random_state=1)\nn=int(len(X_test2)\/2)\nX_valid2,y_valid2=X_test2[:n],y_test2[:n]\nX_test2,y_test2=X_test2[n:],y_test2[n:]\nscale_y2=RobustScaler()\ny_train2=scale_y2.fit_transform(y_train2.reshape(-1,1))\ny_valid2=scale_y2.transform(y_valid2.reshape(-1,1))\ny_test2=scale_y2.transform(y_test2.reshape(-1,1))\n# data = school_explorer\n# features = numeric variables + target_list - economic_list \n# targets = School Income Estimate\n[X_train2.shape,X_test2.shape,X_valid2.shape,\ny_train2.shape,y_test2.shape,y_valid2.shape]","72f33b24":"def mlp_model1():\n    model=Sequential()    \n    model.add(Dense(138,input_dim=138))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dense(138))\n    model.add(LeakyReLU(alpha=.02))   \n    model.add(Dense(138*16))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dense(138*16))\n    model.add(LeakyReLU(alpha=.02))    \n    model.add(Dense(1))    \n    model.compile(loss='mse',optimizer='rmsprop',\n                  metrics=['mae'])\n    return model\nmlp_model1=mlp_model1()","d51d04c7":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=mlp_model1.fit(\n    X_train1,y_train1,\n    epochs=100,batch_size=16,verbose=2,\n    validation_data=(X_valid1,y_valid1),\n    callbacks=[checkpointer,lr_reduction])","05c47dd6":"history_plot(history,50)\nmlp_model1.load_weights(fw)\ny_train_mlp1=mlp_model1.predict(X_train1)\ny_valid_mlp1=mlp_model1.predict(X_valid1)\ny_test_mlp1=mlp_model1.predict(X_test1)\nscores('MLP; Economic Need Index',\n       y_train1,y_valid1,y_test1,\n       y_train_mlp1,y_valid_mlp1,y_test_mlp1)","99e4a529":"def mlp_model2():\n    model=Sequential()    \n    model.add(Dense(138,input_dim=138))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dense(138))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dense(138*16))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dense(138*16))\n    model.add(LeakyReLU(alpha=.02))   \n    model.add(Dense(1))    \n    model.compile(loss='mse',optimizer='rmsprop',\n                  metrics=['mae'])\n    return model\nmlp_model2=mlp_model2()","b612353d":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=mlp_model2.fit(X_train2,y_train2, \n                       epochs=100,batch_size=16,verbose=2,\n                       validation_data=(X_valid2,y_valid2),\n                       callbacks=[checkpointer,lr_reduction])","3d1374c2":"history_plot(history,50)\nmlp_model2.load_weights(fw)\ny_train_mlp2=mlp_model2.predict(X_train2)\ny_valid_mlp2=mlp_model2.predict(X_valid2)\ny_test_mlp2=mlp_model2.predict(X_test2)\nscores('MLP; School Income Estimate',\n       y_train2,y_valid2,y_test2,\n       y_train_mlp2,y_valid_mlp2,y_test_mlp2)","335b75e6":"def cnn_model1():\n    model=Sequential()        \n    model.add(Conv1D(138,3,padding='valid',\n                     input_shape=(138,1)))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.25))\n    model.add(Conv1D(138*4,3,padding='valid'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.25))    \n    model.add(Flatten())\n    model.add(Dense(138*8,kernel_initializer='normal'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dropout(.5))\n    model.add(Dense(1, kernel_initializer='normal'))    \n    model.compile(loss='mse',optimizer='rmsprop',\n                  metrics=['mae'])\n    return model\ncnn_model1=cnn_model1()","6c950070":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=cnn_model1.fit(\n    X_train1.reshape(-1,138,1),y_train1, \n    epochs=100,batch_size=16,verbose=2,\n    validation_data=(X_valid1.reshape(-1,138,1),y_valid1),\n    callbacks=[checkpointer,lr_reduction])","ac5128d7":"history_plot(history,50)\ncnn_model1.load_weights(fw)\ny_train_cnn1=cnn_model1\\\n.predict(X_train1.reshape(-1,138,1))\ny_valid_cnn1=cnn_model1\\\n.predict(X_valid1.reshape(-1,138,1))\ny_test_cnn1=cnn_model1\\\n.predict(X_test1.reshape(-1,138,1))\nscores('CNN; Economic Need Index',\n       y_train1,y_valid1,y_test1,\n       y_train_cnn1,y_valid_cnn1,y_test_cnn1)","98b56c97":"def cnn_model2():\n    model=Sequential()\n    model.add(Conv1D(138,5,padding='valid',\n                     input_shape=(138,1)))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.25))\n    model.add(Conv1D(138*4,5,padding='valid'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.25))   \n    model.add(Flatten())\n    model.add(Dense(138*8,kernel_initializer='normal'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dropout(.5))\n    model.add(Dense(1,kernel_initializer='normal'))    \n    model.compile(loss='mse',optimizer='rmsprop',\n                  metrics=['mae'])\n    return model\ncnn_model2=cnn_model2()","a0b7fbaa":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=cnn_model2.fit(\n    X_train2.reshape(-1,138,1),y_train2, \n    epochs=100,batch_size=16,verbose=2,\n    validation_data=(X_valid2.reshape(-1,138,1),y_valid2),\n    callbacks=[checkpointer,lr_reduction])","f2a7dee5":"history_plot(history,50)\ncnn_model2.load_weights(fw)\ny_train_cnn2=cnn_model2\\\n.predict(X_train2.reshape(-1,138,1))\ny_valid_cnn2=cnn_model2\\\n.predict(X_valid2.reshape(-1,138,1))\ny_test_cnn2=cnn_model2\\\n.predict(X_test2.reshape(-1,138,1))\nscores('CNN; School Income Estimate',\n       y_train2,y_valid2,y_test2,\n       y_train_cnn2,y_valid_cnn2,y_test_cnn2)","b878a1a5":"def rnn_model1():\n    model=Sequential()    \n    model.add(LSTM(138,return_sequences=True,\n                   input_shape=(1,138)))\n    model.add(LSTM(138*4,return_sequences=False))     \n    model.add(Dense(138*8,kernel_initializer='normal'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dropout(.1))    \n    model.add(Dense(1))\n    model.compile(optimizer='rmsprop',loss='mse',\n                  metrics=['mae'])     \n    return model \nrnn_model1=rnn_model1()","f882dbed":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=rnn_model1.fit(\n    X_train1.reshape(-1,1,138),y_train1, \n    epochs=100,batch_size=16,verbose=2,\n    validation_data=(X_valid1.reshape(-1,1,138),y_valid1),\n    callbacks=[checkpointer,lr_reduction])","a919ae40":"history_plot(history,10)\nrnn_model1.load_weights(fw)\ny_train_rnn1=rnn_model1\\\n.predict(X_train1.reshape(-1,1,138))\ny_valid_rnn1=rnn_model1\\\n.predict(X_valid1.reshape(-1,1,138))\ny_test_rnn1=rnn_model1\\\n.predict(X_test1.reshape(-1,1,138))\nscores('RNN; Economic Need Index',\n       y_train1,y_valid1,y_test1,\n       y_train_rnn1,y_valid_rnn1,y_test_rnn1)","050933ce":"def rnn_model2():\n    model=Sequential()   \n    model.add(LSTM(138,return_sequences=True,\n                   input_shape=(1,138)))\n    model.add(LSTM(138*4,return_sequences=False))     \n    model.add(Dense(138*8,kernel_initializer='normal'))\n    model.add(LeakyReLU(alpha=.02))\n    model.add(Dropout(.1))    \n    model.add(Dense(1))\n    model.compile(optimizer='rmsprop',loss='mse',\n                  metrics=['mae'])     \n    return model \nrnn_model2=rnn_model2()","b26e9520":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.75)\nhistory=rnn_model2.fit(\n    X_train2.reshape(-1,1,138),y_train2, \n    epochs=100,batch_size=16,verbose=2,\n    validation_data=(X_valid2.reshape(-1,1,138),y_valid2),\n    callbacks=[checkpointer,lr_reduction])","7db5b10f":"history_plot(history,10)\nrnn_model2.load_weights(fw)\ny_train_rnn2=rnn_model2\\\n.predict(X_train2.reshape(-1,1,138))\ny_valid_rnn2=rnn_model2\\\n.predict(X_valid2.reshape(-1,1,138))\ny_test_rnn2=rnn_model2\\\n.predict(X_test2.reshape(-1,1,138))\nscores('RNN; School Income Estimate',\n       y_train2,y_valid2,y_test2,\n       y_train_rnn2,y_valid_rnn2,y_test_rnn2)","0bba5f86":"plt.figure(figsize=(11,7)); n=50\nplt.plot(y_test1[1:n],'-o',\n         color=spectral_cmap[3],label='Real Data')\nplt.plot(y_test_mlp1[1:n],'-o',\n         color=spectral_cmap[0],label='MLP')\nplt.plot(y_test_cnn1[1:n],'-o',\n         color=spectral_cmap[1],label='CNN')\nplt.plot(y_test_rnn1[1:n],'-o',\n         color=spectral_cmap[2],label='RNN')\nti=\"Economic Need Index. \"+\\\n   \"NN Test Predictions vs Real Data\"\nplt.legend(); plt.title(ti);","e2d6a562":"plt.figure(figsize=(11,7))\nplt.plot(y_test2[1:n],'-o',\n         color=spectral_cmap[3],label='Real Data')\nplt.plot(y_test_mlp2[1:n],'-o',\n         color=spectral_cmap[0],label='MLP')\nplt.plot(y_test_cnn2[1:n],'-o',\n         color=spectral_cmap[1],label='CNN')\nplt.plot(y_test_rnn2[1:n],'-o',\n         color=spectral_cmap[2],label='RNN')\nti=\"School Income Estimate. \"+\\\n   \"NN Test Predictions vs Real Data\"\nplt.legend(); plt.title(ti);","4c4f9b32":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'> &#x1F310; &nbsp; Display Predictions<\/h1>\n\n### The first set of features and targets","6490f042":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'>  &#x1F310; &nbsp; Data Splitting for Neural Networks<\/h1>\nThe predictions of economic indicators for schools are based on the data about social environment, ethnic composition and educational results.\n\n### The first set of features and targets","3e59f176":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'> &#x1F310; &nbsp; Data Loading and Preprocessing<\/h1>","fe909d98":"### RNN => The second set of features and targets","d6505621":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'> &#x1F310; &nbsp; Code Library, Styling, and Links<\/h1>\n<details><summary style='color:#37c9e1; font-family:Orbitron;'>Github<\/summary><br\/>\n\nThe current notebook\n    \n&#x1F4D8; &nbsp; [Python Version](https:\/\/github.com\/OlgaBelitskaya\/kaggle_notebooks\/blob\/master\/passnyc-neural-networks.ipynb)\n\nThe previous notebook\n    \n&#x1F4D8; &nbsp; [Python Version](https:\/\/github.com\/OlgaBelitskaya\/kaggle_notebooks\/blob\/master\/passnyc-regression-methods.ipynb)","16941818":"### RNN => The first set of features and targets","31871712":"### MLP => The second set of features and targets","27866d93":"<details><summary style='color:#37c9e1; font-family:Orbitron;'>Useful Links<\/summary><br\/>\n\n&#x1F4E1; &nbsp; [School Quality Reports. Educator Guide](http:\/\/schools.nyc.gov\/NR\/rdonlyres\/967E0EE1-7E5D-4E47-BC21-573FEEE23AE2\/0\/201516EducatorGuideHS9252017.pdf)\n    \n&#x1F4E1; &nbsp; [New York City Department of Education](https:\/\/www.schools.nyc.gov)\n\n&#x1F4E1; &nbsp; [NYC OpenData](https:\/\/opendata.cityofnewyork.us\/)\n\n&#x1F4E1; &nbsp; [Pandas Visualization](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/visualization.html)\n    \n&#x1F4E1; &nbsp; [Pandas Styling](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/style.html)\n\n&#x1F4E1; &nbsp; [ggplot2](https:\/\/ggplot2.tidyverse.org\/)\n\n&#x1F4E1; &nbsp; [R Tutorial](https:\/\/www.tutorialspoint.com\/r\/index.htm)","6b0bf414":"### CNN => The second set of features and targets","4bf82d26":"### The second set of features and targets","a052cb06":"### The second set of features and targets","66e0633a":"### CNN => The first set of features and targets","789c39b8":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'> &#x1F310; &nbsp; Neural Network Regressors<\/h1>\n\n### MLP => The first set of features and targets","de2480ac":"<h1 class='font-effect-3d' style='color:#37c9e1; font-family:Orbitron;'> &#x1F310; &nbsp;  Let's Go Ahead<\/h1>\n\nThe results obtained could be a base for several generalizing assumptions:\n\n1) Neural networks such as a multilayer perceptron (MLP) and a recurrent neural network (RNN) better than a convolutional neural network (CNN) cope with the prediction of regression in the presence of mixed data (financial, sociological, etc.)\n\n2) Characteristics of the educational process and results, social environment, ethnic composition, administrative affiliation are sufficient to predict the level of the indicator \"Economic Need Index\".\n\n3) The same variables are not enough for predicting \"School Income Estimate\". The information must be supplemented with indicators of economic activity in general for the state and the economic situation in the district adjacent to the school.\n\nIt' s time to move to the next step.\n\n&#x1F4D8; &nbsp; [PASSNYC. Neural Networks 2](https:\/\/www.kaggle.com\/olgabelitskaya\/passnyc-neural-networks-2)"}}