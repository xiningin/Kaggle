{"cell_type":{"0d42f03d":"code","4b55bc6a":"code","07b21dfb":"code","075b5586":"code","500d8732":"code","66e6668d":"code","5f817adb":"code","645f9c76":"code","d7bd007b":"code","c3344570":"code","8caf9dca":"code","5721ace2":"code","6c62d1e9":"code","9442f545":"code","3fe99045":"markdown","25fb89ca":"markdown","141ab4c6":"markdown","032ae8b9":"markdown","f2679bc2":"markdown","78e00ca5":"markdown"},"source":{"0d42f03d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b55bc6a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","07b21dfb":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv')","075b5586":"train.info()\nprint('-'*70)\nprint('-'*70)\ntest.info()","500d8732":"train.describe()","66e6668d":"test.describe()","5f817adb":"fig, axes = plt.subplots(5,3,figsize=(16,15))\nplt.subplots_adjust(hspace=0.4, wspace=0.3)\n\nfor i in range(14):\n    sns.histplot(train['cont' + str(i+1)], ax=axes[i\/\/3, i%3])\n    axes[i\/\/3, i%3].set(title='cont' + str(i+1), xlabel='')\n    \nsns.histplot(train['target'], ax=axes[4,2])\naxes[4,2].set(title='target', xlabel='')\n\nplt.show()","645f9c76":"train.drop(['id', 'cont5'], axis=1, inplace=True)\ntest.drop('cont5', axis=1, inplace=True)","d7bd007b":"train_x, val_x, train_y, val_y = train_test_split(train.drop(['target'], axis=1), \n                                                  train.target, \n                                                  test_size=0.2)","c3344570":"model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, input_shape=(13,)),\n                                    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(1, activation=tf.nn.relu)])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n\nmodel.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10)","8caf9dca":"model.summary()","5721ace2":"pred = model.predict(test.drop('id', axis=1))\npred.shape","6c62d1e9":"sub = pd.DataFrame({'id':list(test['id']) , 'target':pred[:,0]})\nsub","9442f545":"sub.to_csv('.\/submission.csv', index=False)","3fe99045":"## Import libraries","25fb89ca":"## Looking at the distribution of each feature","141ab4c6":"The feature 'cont5' seems to be very distorted as more than $1\/3^{rd}$ of the values are concentrated around zero. So, we can ignore that column, neglecting its effect on the prediction of the target value.","032ae8b9":"## Importing data","f2679bc2":"Here, we will split the training dataset into training \\& validation sets.","78e00ca5":"## NN Model"}}