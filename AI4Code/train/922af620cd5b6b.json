{"cell_type":{"66c6d1a1":"code","41be3499":"code","cfdf83d6":"code","c76050f0":"code","390603c1":"code","65d3cda9":"code","f820eb54":"code","fcb8b8e5":"code","44336f1e":"code","1c4f90d9":"code","e121d9ca":"code","8087e398":"code","054a60e5":"code","e413af05":"code","fc18c8d4":"code","def8cb37":"code","22b76304":"code","392fce28":"code","e59317df":"code","fbb3a286":"code","5450481e":"code","13c2457f":"code","b3c9aacc":"code","79042384":"code","0938deb5":"code","5959dd0b":"code","80b85411":"markdown","347ba409":"markdown","c6041299":"markdown"},"source":{"66c6d1a1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n%matplotlib inline\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/carvana-image-masking-challenge\"]).decode(\"utf8\"))","41be3499":"train_zip_path = '..\/input\/carvana-image-masking-challenge\/train_hq.zip'\nmasks_zip_path = '..\/input\/carvana-image-masking-challenge\/train_masks.zip'","cfdf83d6":"import zipfile\n#Extract train images.\nwith zipfile.ZipFile(train_zip_path,'r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working')\n#Extract train masks\/labels.\nwith zipfile.ZipFile(masks_zip_path,'r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working')\ndata_size = len(os.listdir('\/kaggle\/working\/train_hq'))\nwith zipfile.ZipFile('..\/input\/carvana-image-masking-challenge\/train.zip','r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working')\ndata_size = len(os.listdir('\/kaggle\/working\/train_hq'))\nwith zipfile.ZipFile('..\/input\/carvana-image-masking-challenge\/metadata.csv.zip','r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working')\ndata_size = len(os.listdir('\/kaggle\/working\/train_hq'))\nprint('Number of train images: ', len(os.listdir('\/kaggle\/working\/train_hq')))\nprint('Number of train masks: ', len(os.listdir('\/kaggle\/working\/train_masks')))","c76050f0":"import os\nfrom glob import glob\ntrain_files = glob(os.path.join('\/kaggle\/working\/train', \"*.jpg\"))\ntrain_ids = [s[len('\/kaggle\/working\/train')+1:-4] for s in train_files]","390603c1":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        ext = 'jpg'\n        data_path = '\/kaggle\/working\/train'\n        suffix = ''\n    elif \"Train_mask\" in image_type:\n        ext = 'gif'\n        data_path = TRAIN_MASKS_DATA\n        suffix = '_mask'\n    elif \"Test\" in image_type:\n        ext = 'jpg'\n        data_path = TEST_DATA\n        suffix = ''\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}{}.{}\".format(image_id, suffix, ext))","65d3cda9":"import cv2\nfrom PIL import Image\n\n\ndef get_image_data(image_id, image_type, **kwargs):\n    if 'mask' in image_type:\n        img = _get_image_data_pil(image_id, image_type, **kwargs)\n    else:\n        img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef _get_image_data_pil(image_id, image_type, return_exif_md=False, return_shape_only=False):\n    fname = get_filename(image_id, image_type)\n    try:\n        img_pil = Image.open(fname)\n    except Exception as e:\n        assert False, \"Failed to read image : %s, %s. Error message: %s\" % (image_id, image_type, e)\n\n    if return_shape_only:\n        return img_pil.size[::-1] + (len(img_pil.getbands()),)\n\n    img = np.asarray(img_pil)\n    assert isinstance(img, np.ndarray), \"Open image is not an ndarray. Image id\/type : %s, %s\" % (image_id, image_type)\n    if not return_exif_md:\n        return img\n    else:\n        return img, img_pil._getexif()","f820eb54":"all_images = os.listdir('\/kaggle\/working\/train_hq')\ntrain_images, validation_images = train_test_split(all_images, train_size=0.8, test_size=0.2)","fcb8b8e5":"data_dir = '\/kaggle\/working\/train_hq\/'\nmask_dir = '\/kaggle\/working\/train_masks\/'","44336f1e":"car_ids = sorted(os.listdir('\/kaggle\/working\/train_hq'))\nmask_ids = sorted(os.listdir('\/kaggle\/working\/train_masks'))\nrnd_ind = list(np.random.choice(data_size,8))\nfor i in rnd_ind:\n    print(\"Car image id: '{}' -- Corressponding Mask id '{}'\".format(car_ids[i], mask_ids[i]))","1c4f90d9":"n = 0\ncar_id = car_ids[n]\nmask_id = mask_ids[n]\ncar = load_img('\/kaggle\/working\/train_hq\/' + car_id)\nmask = load_img('\/kaggle\/working\/train_masks\/' + mask_id)\nprint(\"Image Size: \", car.size)\nprint(\"Mask Size: \", mask.size)\nfig, ax = plt.subplots(1, 2, figsize=(20,20))\nfig.subplots_adjust(hspace=.1, wspace=.01)\nax[0].imshow(car)\nax[0].axis('off')\nax[0].title.set_text('Car Image')\nax[1].imshow(mask)\nax[1].axis('off')\nax[1].title.set_text('Car Mask')","e121d9ca":"from sklearn.model_selection import train_test_split\nX_train_ids, X_val_ids, y_train_ids, y_val_ids= train_test_split(car_ids, mask_ids,\n                                                                 test_size=.2, train_size=.8,\n                                                                 random_state=42)\nX_train_size = len(X_train_ids)\nX_val_size = len(X_val_ids)\nprint('Training images size:', X_train_size)\nprint('Validation images size:', X_val_size)","8087e398":"_train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:50]\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        img = cv2.resize(img, dsize=tile_size)\n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n    if counter == len(_train_ids):\n        break    ","054a60e5":"m = complete_image.shape[0] \/ (tile_size[0] + 2)\nk = 5\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])\n    plt.title(\"Training dataset, part %i\" % i)","e413af05":"TRAIN_MASKS_CSV['id'] = TRAIN_MASKS_CSV['img'].apply(lambda x: x[:-7])\nall_318_car_ids = TRAIN_MASKS_CSV['id'].unique()\nall_318_cars_image_ids = [_id + '_03' for _id in all_318_car_ids]\n\n_train_ids = list(all_318_cars_image_ids)\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        img = cv2.resize(img, dsize=tile_size)\n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n    if counter == len(_train_ids):\n        break   ","fc18c8d4":"m = complete_image.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])","def8cb37":"img1 = get_image_data('683ddec95b82_03','Train')\nimg2 = get_image_data('42b3feca1993_03', 'Train')\nimage = [img1, img2]\nplt.figure(figsize=(14, 6))\nfor i in image:\n    plt.figure(figsize=(5, 5))\n    plt.imshow(i)","22b76304":"input_size = [128, 128, 3]\ndef data_generator(images_path, masks_path, image_ids, mask_ids, batch_size, img_size=input_size):\n    data_size = len(image_ids)\n    while True:\n        rnd_ind = np.random.choice(np.arange(data_size),batch_size)\n        imgs = []\n        masks = []\n        for i in rnd_ind:\n            img_id, mask_id = image_ids[i], mask_ids[i]\n            img = load_img(images_path + img_id, target_size=img_size) \n            mask = load_img(masks_path + mask_id, target_size=img_size[:-1], color_mode = 'grayscale')\n            imgs.append(img_to_array(img))\n            masks.append(img_to_array(mask).reshape(img_size[:-1] + [1]))\n        yield np.array(imgs, dtype=np.float16) \/ 255., np.array(masks, dtype=np.float16) \/ 255.","392fce28":"gen = data_generator('\/kaggle\/working\/train_hq\/', '\/kaggle\/working\/train_masks\/',\n                    X_val_ids, y_val_ids, batch_size=32)\n\nimgs, masks = next(gen)\nprint('Images batch shape: ', imgs.shape)\nprint('Masks batch shape: ', imgs.shape)","e59317df":"fig, ax = plt.subplots(2, 4, figsize=(15,7))\nfig.subplots_adjust(hspace=.1, wspace=.05)\ncar_samples, mask_samples = imgs[:4].astype(np.float32), masks[:4][:,:,:,0].astype(np.float32)\nfor i, (car, mask) in enumerate(zip(car_samples, mask_samples)):\n    ax[0, i].imshow(car)\n    ax[0, i].axis('off')\n    ax[0, i].title.set_text('Car Image')\n    \n    ax[1, i].imshow(mask, cmap='gray')\n    ax[1, i].axis('off')\n    ax[1, i].title.set_text('Car Mask')\nplt.show() ","fbb3a286":"import keras\nimport keras.backend as K\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\n\ndef Unet(input_shape=(128, 128, 3),\n                 num_classes=1):\n    inputs = Input(shape=input_shape)\n\n    down1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    down1 = BatchNormalization()(down1)\n    down1 = Activation('relu')(down1)\n    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n    down1 = BatchNormalization()(down1)\n    down1 = Activation('relu')(down1)\n    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n\n    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n    down2 = BatchNormalization()(down2)\n    down2 = Activation('relu')(down2)\n    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n    down2 = BatchNormalization()(down2)\n    down2 = Activation('relu')(down2)\n    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n\n    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n    down3 = BatchNormalization()(down3)\n    down3 = Activation('relu')(down3)\n    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n    down3 = BatchNormalization()(down3)\n    down3 = Activation('relu')(down3)\n    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n\n    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n    down4 = BatchNormalization()(down4)\n    down4 = Activation('relu')(down4)\n    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n    down4 = BatchNormalization()(down4)\n    down4 = Activation('relu')(down4)\n    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n\n    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n    center = BatchNormalization()(center)\n    center = Activation('relu')(center)\n    center = Conv2D(1024, (3, 3), padding='same')(center)\n    center = BatchNormalization()(center)\n    center = Activation('relu')(center)\n\n    up4 = UpSampling2D((2, 2))(center)\n    up4 = concatenate([down4, up4], axis=3)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n\n    up3 = UpSampling2D((2, 2))(up4)\n    up3 = concatenate([down3, up3], axis=3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n\n    up2 = UpSampling2D((2, 2))(up3)\n    up2 = concatenate([down2, up2], axis=3)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n\n    up1 = UpSampling2D((2, 2))(up2)\n    up1 = concatenate([down1, up1], axis=3)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n\n    \n    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n\n    model = Model(inputs=inputs, outputs=classify)\n\n    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n\n    return model\n\nmodel = Unet()","5450481e":"X_train_size","13c2457f":"batch_size = 40\ntrain_gen = data_generator('\/kaggle\/working\/train_hq\/', '\/kaggle\/working\/train_masks\/',\n                           X_train_ids, y_train_ids, batch_size=batch_size)","b3c9aacc":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","79042384":"model.fit_generator(train_gen, steps_per_epoch=100, epochs=10)","0938deb5":"pred_masks = model.predict(imgs)","5959dd0b":"fig, ax = plt.subplots(32, 3, figsize=(20,150))\nfor i in range(32):\n    ax[i, 0].imshow(imgs[i].astype(np.float32))\n    ax[i, 0].axis('off')\n    ax[i, 0].title.set_text('Car')\n    \n    ax[i, 1].imshow(masks[i,:,:,0].astype(np.float32), cmap='gray')\n    ax[i, 1].axis('off')\n    ax[i, 1].title.set_text('Real Mask')\n    \n    ax[i, 2].imshow(pred_masks[i,:,:,0], cmap='gray')\n    ax[i, 2].axis('off')\n    ax[i, 2].title.set_text('Predicted Mask')\nplt.show() ","80b85411":"# Display car and mask","347ba409":"# Resize","c6041299":"# Build Model U-net"}}