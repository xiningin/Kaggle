{"cell_type":{"3b99d5c5":"code","fce9fc7f":"code","1c850a66":"code","c896b549":"code","120f78a9":"code","26e53f20":"code","2ced3fa8":"code","945699ae":"code","9bd8f3e5":"code","f5a53b83":"code","5892fff5":"code","40910100":"code","35060e2a":"code","277763f1":"code","464490aa":"code","10a01b64":"code","bc6f764a":"code","51c46765":"code","32b70cad":"code","e078f4f0":"code","0f7b432c":"code","25ad67fa":"code","ec1a7918":"code","191a68c5":"code","f3564732":"code","7f48da1e":"code","d0aa5a43":"code","8c32ec48":"code","604d5536":"code","7390bf63":"markdown","a30ca5ca":"markdown","82bf692e":"markdown","5f91455e":"markdown","b378e363":"markdown"},"source":{"3b99d5c5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#This is in order to ignore errors that may appear.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fce9fc7f":"data=pd.read_csv(\"..\/input\/mushroom-classification\/mushrooms.csv\")","1c850a66":"data.shape","c896b549":"data.head()","120f78a9":"list(data.columns)","26e53f20":"len(data.columns)","2ced3fa8":"# We note that data has only one type, which is the object\ndata.info()","945699ae":"for i in data.columns:\n  print(i, data[i].unique())","9bd8f3e5":"from sklearn.preprocessing import LabelEncoder\nobject_1=LabelEncoder()\n# During the conversion process, we used the first projection.\nfor i in data.columns:\n    data[i] = object_1.fit_transform(data[i])","f5a53b83":"data.head()","5892fff5":"grouped_data = data.groupby('class')\nprint(grouped_data)","40910100":"plt.hist(data[\"class\"])\nplt.show() ","35060e2a":"#This drawing looks better than the figure.\nsns.countplot(data[\"class\"])\nplt.title(\"Countplot for class\")\nplt.show()","277763f1":"# Now we will calculate the correlation coefficient for each feature\ndata.corr()","464490aa":"# Now we will draw a heat map.\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)\nplt.show()","10a01b64":"# Here we have deleted one of the columns that has no connection with the rest of the data.\ndata.drop(['veil-type'], axis=1, inplace=True)","bc6f764a":"# Now we will draw a heat map.\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)\nplt.show()","51c46765":"# Here we get the top 5 characteristics of the target \"class\" that affect the algorithm.\ncorr_1=data.corr()\nmost_eff=corr_1.nlargest(5,\"class\")\nmost_eff","32b70cad":"sns.lineplot(data=most_eff)","e078f4f0":"sns.lineplot(data=data, x=\"class\", y=\"bruises\")","0f7b432c":"# use to set style of background of plot\nsns.set(style=\"whitegrid\")\n \n# plotting strip plot with seaborn\n# deciding the attributes of dataset on\n# which plot should be made\nax = sns.stripplot(x='class', y='gill-size', data=data)\n \n# giving title to the plot\nplt.title('Graph')\n \n# function to show plot\nplt.show()","25ad67fa":"target= data[\"class\"].values\nfeature= data.drop([\"class\"],axis=1)","ec1a7918":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(feature,target, test_size=0.2, random_state=11)","191a68c5":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","f3564732":"# Now we are going to use a neural network for classification\n# Here we will call the libraries that we need.\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # empty neural network\nfrom keras.layers import Dense # layer constitution\n","7f48da1e":"def build_classifier():\n    classifier = Sequential() # initialize neural network architecture\n    classifier.add(Dense(units = 8, kernel_initializer=\"uniform\", activation=\"relu\", input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 8, kernel_initializer=\"uniform\", activation=\"relu\")) #kernel_initializer: to initialize weights\n    classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", activation=\"sigmoid\")) #output layer\n    classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return classifier\n\nclassifier = KerasClassifier(build_fn = build_classifier, epochs=70, batch_size=10)\n# epoch = number of iteration, batch size : efers to the number of training examples utilized in one iteration.\naccurisies = cross_val_score(estimator=classifier, X=x_train, y = y_train, cv = 2)\nmean = accurisies.mean()\nvariance = accurisies.std()\nprint(\"Accuracy mean : \", str(mean))\nprint(\"Accuracy variance : \", str(variance))","d0aa5a43":"# Here we are working to increase the efficiency of the algorithm in validation data.\nhistory = classifier.fit(x_test, y_test, validation_split=0.20, epochs=70, batch_size=10, verbose=1)","8c32ec48":"# Accurasy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy vs Epoch')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","604d5536":"# Loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss vs Epoch')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","7390bf63":"Now we will convert those characters and values that have no meaning in the table into numeric values.","a30ca5ca":"Here we try to convert those meanings and letters into meaningful words by knowing which letters belong to which columns.","82bf692e":"# Thank you for your time and thank you for voting.","5f91455e":"Now here we will start the process of partitioning the data.\nFirst, we will credit the results column over the rest of the columns.","b378e363":"# mushroom-classification\n\nWith this data, we will use artificial neural networks to classify that data.\nAnd also we will use algorithms for design using machine learning.."}}