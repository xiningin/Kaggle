{"cell_type":{"6e1993f8":"code","3de5d9b1":"code","ac69c1f6":"code","62f1aa8d":"code","dc206af4":"code","b27f432c":"code","486d4b4d":"code","b6d2001e":"code","f1d20d60":"code","c8090255":"code","21c64815":"code","d0ebbf79":"code","d5dcbef4":"code","0dac4d82":"code","db6baa75":"code","b7187328":"code","f4de9e8e":"code","e97f0af7":"code","f7cc45cb":"code","496d471c":"code","773ac9f2":"code","6f794032":"code","64e6948f":"code","ec354fea":"code","a9abaf69":"code","6d7fbc86":"code","9916fb2b":"code","35181d6a":"code","0e31a1af":"code","c33dfc88":"code","874a7c5e":"code","788293b4":"code","d25d31b7":"code","8a2d7fb8":"code","4fae142e":"code","2c2cdff0":"code","0c4fb66e":"code","5905f354":"code","f6ad3cae":"code","42f46a26":"code","80c8d6e4":"code","eed4da85":"code","5ee4bfa5":"code","bf973bef":"markdown","78c9e55f":"markdown","d5274647":"markdown","5ff8ac7d":"markdown","8983a890":"markdown","c3a6d66a":"markdown","cb0cc83c":"markdown","cca628d3":"markdown","cba57250":"markdown","4ddc41ee":"markdown","37afd9b3":"markdown","cf810bd5":"markdown","23dd6b69":"markdown","ae2a0dcc":"markdown","2a119758":"markdown","b0afb7a3":"markdown","3ac340c2":"markdown","3cdf92e4":"markdown","bd763ca2":"markdown","b3d26dcf":"markdown","d8e511f8":"markdown","c2053812":"markdown","b96cd8e3":"markdown","358eb94b":"markdown","61f672a8":"markdown","958bf1dd":"markdown","5a449e69":"markdown","be1e5f4b":"markdown","7d6cfdd2":"markdown","828eabb9":"markdown","aea42b46":"markdown","719e8611":"markdown","d35c656a":"markdown","ad2fdb9f":"markdown"},"source":{"6e1993f8":"!pip install -q efficientnet","3de5d9b1":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\nfrom IPython.display import SVG\nimport efficientnet.tfkeras as efn\nfrom keras.utils import plot_model\nimport tensorflow.keras.layers as L\nfrom keras.utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import DenseNet121\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nnp.random.seed(0)\ntf.random.set_seed(0)","ac69c1f6":"IMAGE_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/images\/\"\nTRAIN_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/train.csv\"\n\ntrain_data = pd.read_csv(TRAIN_PATH)\n\ndisplay(train_data.sample(3))","62f1aa8d":"def load_image(image_id):\n    file_path = image_id + '.jpg'\n    image = cv2.imread(IMAGE_PATH + file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ntrain_images = train_data['image_id'][:200].progress_apply(load_image)","dc206af4":"fig = px.imshow(cv2.resize(train_images[0],(200, 150)))\nfig.update_layout(\n    margin=dict(l=25, r=20, t=20, b=20),\n)\nfig.show()","b27f432c":"red_values = [np.mean(train_images[idx][:,:,0]) for idx in range(len(train_images))]\ngreen_values = [np.mean(train_images[idx][:,:,1]) for idx in range(len(train_images))]\nblue_values = [np.mean(train_images[idx][:,:,2]) for idx in range(len(train_images))]\n\n# All Channels\nvalues = [np.mean(train_images[idx]) for idx in range(len(train_images))]","486d4b4d":"fig = ff.create_distplot([values], group_labels=['Channels'], colors=['#868686'])\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribution of all channel values\")\nfig.show()","b6d2001e":"fig = ff.create_distplot([red_values], group_labels=['Red'], colors=['#C70404'])\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribution of Red channel values\")\nfig.show()","f1d20d60":"fig = ff.create_distplot([green_values], group_labels=['Green'], colors=['#048F58'])\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribution of Green channel values\")\nfig.show()","c8090255":"fig = ff.create_distplot([blue_values], group_labels=['Blue'], colors=['#0479C7'])\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribution of Blue channel values\")\nfig.show()","21c64815":"fig = go.Figure()\n\nfor idx, values in enumerate([red_values, green_values, blue_values]):\n    if idx == 0:\n        color = 'Red'\n    if idx == 1:\n        color = 'Green'\n    if idx == 2:\n        color = 'Blue'\n    \n    fig.add_trace(go.Box(x=[color]*len(values), y=values, name=color, marker=dict(color=color.lower())))\n\nfig.update_layout(yaxis_title = 'Channels', \n                  xaxis_title = 'Mean Value', \n                  title='Mean Value vs Color Channel',\n                  template='simple_white')","d0ebbf79":"fig = ff.create_distplot([red_values, green_values, blue_values], \n                         group_labels=['Red','Green','Blue'],\n                         colors=['#C70404','#048F58','#0479C7']\n                        )\nfig.update_layout(title_text=\"Distribution of Different channel values\", template='simple_white')","d5dcbef4":"def display_leaves(condition):\n    # Assign a filter condition for querying the image data\n    if condition == 'healthy':\n        query_filter = 'healthy == 1'\n    if condition == 'multiple_diseases':\n        query_filter = 'multiple_diseases == 1'\n    if condition == 'rust':\n        query_filter = 'rust == 1'\n    if condition == 'scab':\n        query_filter = 'scab == 1'\n    \n    # Fetch the indexes from train_data based on condition\n    image_index = train_data.query(query_filter)[:9].index\n    \n    # Create a list of images based on above indexes fetched \n    image_data = [train_images.loc[idx] for idx in image_index]\n    \n    cols = 3\n    rows = 3\n    \n    fig = plt.figure(figsize=(15,10))\n    \n    for idx in range(cols * rows):     \n        ax = fig.add_subplot(rows, cols, idx+1)\n        ax.imshow(image_data[idx])\n        _ = ax.axis('off')\n    \n    plt.show()","0dac4d82":"display_leaves('healthy')","db6baa75":"display_leaves('rust')","b7187328":"display_leaves('scab')","f4de9e8e":"display_leaves('multiple_diseases')","e97f0af7":"fig = px.parallel_categories(train_data[[\"healthy\", \"scab\", \"rust\", \"multiple_diseases\"]], \n                             color=\"healthy\", color_continuous_scale=['#FB8729','#DD6605','#03811C','#027219'])\n\nfig.update_layout(width=900, height=400, title= {'text': \"Parallel categories plot of targets\",\n                                                'y':0.95,'x':0.5,\n                                                'xanchor': 'center','yanchor': 'top'},\n                 margin = dict(l=25, r=10, t=100, b=70))","f7cc45cb":"fig = go.Figure(\n                [go.Pie(labels=train_data.columns[1:], \n                        values=train_data.iloc[:, 1:].sum().values,\n                        marker=dict(colors=['#026416','#C73104','#C05209','#6F2F05']))\n                ])\n\nfig.update_layout(width=900, height=400, title= {'text': \"Diseases\",\n                                                'y':0.95,'x':0.43,\n                                                'xanchor': 'center','yanchor': 'top'},\n                 margin = dict(l=50, r=10, t=50, b=30))\n","496d471c":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n\n# instantiate a distribution strategy\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_PATH = KaggleDatasets().get_gcs_path()","773ac9f2":"# Google Cloud Storage Path for the kaggle datasets\nGCS_PATH = KaggleDatasets().get_gcs_path()\n\ndef generate_path(image_id):\n    return  GCS_PATH + '\/images\/' + image_id + '.jpg'\n\ndef decode_image(filename, label):\n    image_size = (512,512)\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    return image, label\n\ndef augment_image(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    return image, label","6f794032":"from sklearn.model_selection import train_test_split\n\ntrain_labels = np.float32(train_data.iloc[:,1:].values)\ntrain_path = train_data['image_id'].apply(generate_path).values\n\ntrain_path, valid_path, train_labels, valid_labels = \\\n            train_test_split(train_path, train_labels, test_size = 0.2, random_state=123)","64e6948f":"image_id = train_data['image_id'].values\nAUTO = tf.data.experimental.AUTOTUNE\n\ntrain_dataset = (\n        tf.data.Dataset\\\n        .from_tensor_slices((train_path, train_labels))\\\n        .map(decode_image, num_parallel_calls=AUTO)\\\n        .map(augment_image, num_parallel_calls=AUTO)\\\n        .repeat()\\\n        .shuffle(512)\\\n        .batch(BATCH_SIZE)\\\n        .prefetch(AUTO)\\\n        )\n\nvalid_dataset = (\n    tf.data.Dataset\\\n    .from_tensor_slices((valid_path, valid_labels))\\\n    .map(decode_image, num_parallel_calls=AUTO)\\\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","ec354fea":"with strategy.scope():\n    model = tf.keras.models.Sequential()\n\n    model.add(DenseNet121(\n                     input_shape=(512,512,3),\n                     weights = 'imagenet',\n                     include_top=False))\n\n    model.add(tf.keras.layers.GlobalAveragePooling2D())\n\n    model.add(tf.keras.layers.Dense(train_labels.shape[1],\n                                   activation='softmax'))\n\n    model.compile(optimizer='adam', \n                 loss='categorical_crossentropy',\n                 metrics=['categorical_accuracy'])\n","a9abaf69":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","6d7fbc86":"# learning rate schedule\n\"\"\"\ndef step_decay(epoch):\n    initial_lrate = 0.1\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n    return lrate\n\"\"\"\n\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\ncallbacks_list = [lr_schedule]\nSTEPS_PER_EPOCH = train_labels.shape[0]\/\/BATCH_SIZE","9916fb2b":"history = model.fit(train_dataset,\n                    epochs = 20,\n                    callbacks = callbacks_list,\n                    steps_per_epoch = STEPS_PER_EPOCH,\n                    validation_data = valid_dataset)","35181d6a":"EPOCHS = 20\ndef display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","0e31a1af":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","c33dfc88":"acc_df = pd.DataFrame(np.transpose([[*np.arange(1, EPOCHS+1).tolist()*3], [\"Train\"]*EPOCHS + [\"Val\"]*EPOCHS + [\"Benchmark\"]*EPOCHS,\n                                     history.history['categorical_accuracy'] + history.history['val_categorical_accuracy'] + [1.0]*EPOCHS]))\nacc_df.columns = [\"Epochs\", \"Stage\", \"Accuracy\"]\nfig = px.bar(acc_df, x=\"Accuracy\", y=\"Stage\", animation_frame=\"Epochs\", title=\"Accuracy vs. Epochs\", color='Stage',\n       color_discrete_map={\"Train\":\"dodgerblue\", \"Val\":\"darkorange\", \"Benchmark\":\"seagreen\"}, orientation=\"h\")\n\nfig.update_layout(\n    xaxis = dict(\n        autorange=False,\n        range=[0, 1]\n    )\n)\n\nfig.update_layout(template=\"plotly_white\")","874a7c5e":"def process(img):\n    return cv2.resize(img\/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\nfig = make_subplots(rows=4, cols=2)\npreds = predict(train_images[2])\n\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Scab\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Multiple diseases\"\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Healthy\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[2], (205, 136))), row=1, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=1, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\npreds = predict(train_images[0])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Multiple diseases\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[0], (205, 136))), row=2, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=2, col=2)\n\npreds = predict(train_images[3])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Rust\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[3], (205, 136))), row=3, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=3, col=2)\n\npreds = predict(train_images[1])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Scab\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[1], (205, 136))), row=4, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=4, col=2)\n\nfig.update_layout(template=\"plotly_white\")","788293b4":"with strategy.scope():\n    model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(512, 512, 3),\n                                                    weights='imagenet',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n    \n    \n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])","d25d31b7":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","8a2d7fb8":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","4fae142e":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","2c2cdff0":"acc_df = pd.DataFrame(np.transpose([[*np.arange(1, EPOCHS+1).tolist()*3], [\"Train\"]*EPOCHS + [\"Val\"]*EPOCHS + [\"Benchmark\"]*EPOCHS,\n                                     history.history['categorical_accuracy'] + history.history['val_categorical_accuracy'] + [1.0]*EPOCHS]))\nacc_df.columns = [\"Epochs\", \"Stage\", \"Accuracy\"]\nfig = px.bar(acc_df, x=\"Accuracy\", y=\"Stage\", animation_frame=\"Epochs\", title=\"Accuracy vs. Epochs\", color='Stage',\n       color_discrete_map={\"Train\":\"dodgerblue\", \"Val\":\"darkorange\", \"Benchmark\":\"seagreen\"}, orientation=\"h\")\n\nfig.update_layout(\n    xaxis = dict(\n        autorange=False,\n        range=[0, 1]\n    )\n)\n\nfig.update_layout(template=\"plotly_white\")","0c4fb66e":"def process(img):\n    return cv2.resize(img\/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\nfig = make_subplots(rows=4, cols=2)\npreds = predict(train_images[2])\n\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Scab\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Multiple diseases\"\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Healthy\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[2], (205, 136))), row=1, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=1, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"EfficientNet Predictions\", showlegend=False)\n\npreds = predict(train_images[0])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Multiple diseases\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[0], (205, 136))), row=2, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=2, col=2)\n\npreds = predict(train_images[3])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Rust\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[3], (205, 136))), row=3, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=3, col=2)\n\npreds = predict(train_images[1])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Scab\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[1], (205, 136))), row=4, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=4, col=2)\nfig.update_layout(template=\"plotly_white\")","5905f354":"with strategy.scope():\n    model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(512, 512, 3),\n                                                    weights='noisy-student',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n    \n    \n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])","f6ad3cae":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","42f46a26":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","80c8d6e4":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","eed4da85":"acc_df = pd.DataFrame(np.transpose([[*np.arange(1, EPOCHS+1).tolist()*3], [\"Train\"]*EPOCHS + [\"Val\"]*EPOCHS + [\"Benchmark\"]*EPOCHS,\n                                     history.history['categorical_accuracy'] + history.history['val_categorical_accuracy'] + [1.0]*EPOCHS]))\nacc_df.columns = [\"Epochs\", \"Stage\", \"Accuracy\"]\nfig = px.bar(acc_df, x=\"Accuracy\", y=\"Stage\", animation_frame=\"Epochs\", title=\"Accuracy vs. Epochs\", color='Stage',\n       color_discrete_map={\"Train\":\"dodgerblue\", \"Val\":\"darkorange\", \"Benchmark\":\"seagreen\"}, orientation=\"h\")\n\nfig.update_layout(\n    xaxis = dict(\n        autorange=False,\n        range=[0, 1]\n    )\n)\n\nfig.update_layout(template=\"plotly_white\")","5ee4bfa5":"def process(img):\n    return cv2.resize(img\/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\nfig = make_subplots(rows=4, cols=2)\npreds = predict(train_images[2])\n\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Scab\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Multiple diseases\"\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Healthy\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[2], (205, 136))), row=1, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=1, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"EfficientNet NoisyStudent Predictions\", showlegend=False)\n\npreds = predict(train_images[0])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Multiple diseases\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[0], (205, 136))), row=2, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=2, col=2)\n\npreds = predict(train_images[3])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Rust\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[3], (205, 136))), row=3, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=3, col=2)\n\npreds = predict(train_images[1])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Scab\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[1], (205, 136))), row=4, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=4, col=2)\nfig.update_layout(template=\"plotly_white\")","bf973bef":"### R,G & B Channels","78c9e55f":"### Model Architecture","d5274647":"### Observation:\n\n1. After hovering over the image pixels, we found that the healthy part(Green) have low blue values whereas the defective parts (Brown) have high values of blue channel\n        **The blue channel may be the key to detecting diseases in plants**.","5ff8ac7d":"### Observations:\n1. Healthy leaves are almost 1\/3rd of unhealthy leaves\n2. Less than 40% of the leaves that are not suffering from SCAB are healthy, Similar is the case for Rust\n3. There are very few Leaves that are suffering from multiple diseases.","8983a890":"### 1. Imports","c3a6d66a":"### Sample predictions\n\nLet's visualize some sample predictions made by the DenseNet model. The <font color=\"red\">red<\/font> bars represent the model's prediction (maximum probability), the <font color=\"green\">green<\/font> represent the ground truth (label), and the rest of the bars are <font color=\"blue\">blue<\/font>. When the model predicts correctly, the prediction bar is <font color=\"green\">green<\/font>.","cb0cc83c":"### Sample predictions\n\nLet's visualize some sample predictions made by the EfficentNet model. The <font color=\"red\">red<\/font> bars represent the model's prediction (maximum probability), the <font color=\"green\">green<\/font> represent the ground truth (label), and the rest of the bars are <font color=\"blue\">blue<\/font>. When the model predicts correctly, the prediction bar is <font color=\"green\">green<\/font>.","cca628d3":"### Model Architecture","cba57250":"### Observations:\n1. From above plots it is clear that the Green channel has higher values followed by red and Blue\n2. The distribution of blue channel is close to Normal distribution.\n3. The red channel has +ve Skew whereas the Green channel has -ve Skew.","4ddc41ee":"### Creating Train and Validation TF dataset\n\n#### Parameters definition:\n    \n    1. Shuffle : the file names will be shuffled randomly\n    \n    2. Repeat: Repeats the dataset so each original value is seen multiple times , since we are \n               randomly augmenting(flipping) our images\n    \n    3. Prefetch : This allows later elements to be prepared while the current element is being processed. \n                  This often improves latency and throughput, at the cost of using additional memory to store \n                  prefetched elements.\n    \n    4. num_parallel_calls : tf.data.experimental.AUTOTUNE is used, then the number of parallel calls \n                            is set dynamically based on available CPU.","37afd9b3":"* TPUs are network-connected accelerators and you must first locate them on the network. This is what TPUClusterResolver() does.\n\n* Two additional lines of boilerplate and you can define a TPUStrategy. This object contains the necessary distributed training code that will work on TPUs with their 8 compute cores\n\n* Batch size, learning rate\n    \n    To go fast on a TPU, increase the batch size. The rule of thumb is to use batches of 128 elements per core           (ex:      batch size of 128*8=1024 for a TPU with 8 cores).\n            BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n* tf.data.Dataset and TFRecords\n    \n    Because TPUs are very fast, many models ported to TPU end up with a data bottleneck. The TPU is sitting             idle, waiting for data for the most part of each training epoch. TPUs read training data exclusively from           GCS (Google Cloud Storage). And GCS can sustain a pretty large throughput if it is continuously streaming           from multiple files in parallel.\n            ","cf810bd5":"### 4. Image Processing","23dd6b69":"### iv. Multiple Diseases","ae2a0dcc":"### Modelling with DenseNet","2a119758":"### Different Types of Leaves","b0afb7a3":"## Introduction\n\n![image.png](attachment:image.png)\n\n\n\n\n<center>\nThe Problem is to diagnose plant diseases solely based on leaf images. \nThe categories include \"healthy\", \"scab\", \"rust\", and \"multiple diseases\". \n\nSolving this problem is important because diagnosing plant diseases early can save tonnes of agricultural produce every year. \nThis will benefit not only the general population by reducing hunger, but also the farmers by ensuring they get the harvest they deserve.\n<\/center>\n\n<br>\n<font color=\"red\" size=3>Please upvote this kernel if you like it.:)<\/font>","3ac340c2":"### ii. Rust","3cdf92e4":"### Training EfficientNet NoisyStudent","bd763ca2":"### i. Healthy","b3d26dcf":"### 4. Configuring TPU","d8e511f8":"### Training the DenseNet Model","c2053812":"### 2. Reading Data","b96cd8e3":"### Animation (click \u25b6\ufe0f)","358eb94b":"### Animation (click \u25b6\ufe0f)","61f672a8":"### iii. Scab","958bf1dd":"### Function to display Leaf samples of different types","5a449e69":"### Training and Validation split","be1e5f4b":"The mean values of all the channels are dense at around 105","7d6cfdd2":"### Training EfficientNet Model","828eabb9":"### 3. Loading Train images samples for exploration","aea42b46":"### Model Architecture","719e8611":"### Sample predictions\n\nLet's visualize some sample predictions made by the EfficentNet model. The <font color=\"red\">red<\/font> bars represent the model's prediction (maximum probability), the <font color=\"green\">green<\/font> represent the ground truth (label), and the rest of the bars are <font color=\"blue\">blue<\/font>. When the model predicts correctly, the prediction bar is <font color=\"green\">green<\/font>.","d35c656a":"### EfficientNet\n\n\n     EfficientNet is another popular (more recent) CNN-based ImageNet model which achieved the SOTA on several image-based tasks in 2019. \n     EfficientNet performs model scaling in an innovative way to achieve excellent accuracy with significantly fewer parameters. \n     It achieves the same if not greater accuracy than ResNet and DenseNet with a mcuh shallower architecture. \n     Now let us train EfficientNet on leaf images and evaluate its performance.","ad2fdb9f":"### EfficientNet NoisyStudent \n\n    EfficientNet NoisyStudent, released in 2020, is based on EfficientNet and uses semi-supervised learning on noisy images to learn rich visual representation. \n    It outperformed EfficientNet on several tasks. \n    Now let us train EfficientNet NoisyStudent on leaf images and evaluate its performance."}}