{"cell_type":{"e520d483":"code","3388ca9b":"code","dfc4f9dd":"code","476f452f":"code","209f7778":"code","0ecb114b":"code","fa368a2c":"code","58a45cf1":"code","8f94d0cf":"code","2669f43c":"code","2ec81c35":"code","98be0512":"code","8ac3a20f":"code","7f4b8519":"code","3871cca0":"code","3406ba68":"code","061f0d34":"code","d09d2b8c":"code","3607f36b":"code","63959e01":"code","663e1dc2":"code","4306f49e":"code","0cb94437":"code","d4166ade":"code","da22fa36":"code","d4fed7e6":"code","7fd23a2d":"code","03e005bb":"code","d79f6bb1":"code","39174c97":"code","3b6889ed":"code","51d5719b":"code","561a873f":"code","6b87fc5a":"code","88e64c64":"code","9c8ae5b6":"code","de300d4e":"code","6fd9fca8":"code","bf8459f7":"code","5b16ecde":"code","96fed098":"code","6dc3b97f":"code","08a13d65":"code","890a8e64":"code","bb29e475":"code","ad724c83":"code","c8b1b431":"code","30bc147f":"code","3d8737f5":"code","a81ed98a":"code","afb96e7a":"code","cc11f5b3":"code","f36229e1":"code","6e2dd196":"code","47a04a39":"code","ca5d656d":"code","be70c875":"code","b0a0b5a8":"code","688d16e3":"code","1ab4eae7":"code","1c0a37c7":"code","cf7354fd":"code","4ae710d6":"code","9df17c68":"code","0162792f":"markdown","352de442":"markdown","bb898f91":"markdown","d43c0d6f":"markdown","5a915231":"markdown","a3d871a5":"markdown","105208b6":"markdown","55eb6d56":"markdown","086a7f84":"markdown","aadf3f10":"markdown","c1a144d3":"markdown"},"source":{"e520d483":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3388ca9b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport operator","dfc4f9dd":"data_train = pd.read_csv('\/kaggle\/input\/into-the-future\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/into-the-future\/test.csv')","476f452f":"data_train.head()","209f7778":"data_train.describe()","0ecb114b":"data_train.info()","fa368a2c":"train = data_train.copy()","58a45cf1":"data_test.head()","8f94d0cf":"data_test.describe()","2669f43c":"data_test.info()","2ec81c35":"test = data_test.copy()","98be0512":"data_train['feature_1'].plot(kind = 'line', color = 'green', figsize = (5,5))","8ac3a20f":"data_train['feature_2'].plot(kind = 'line', color = 'blue', figsize = (5,5))","7f4b8519":"pd.isna(data_train).sum()","3871cca0":"pd.isna(data_test).sum()","3406ba68":"data_train['time'] = pd.to_datetime(data_train['time'])\ndata_train.head()","061f0d34":"data_train.shape","d09d2b8c":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = MinMaxScaler()\ndata_train[['feature_1', 'feature_2']] = scaler.fit_transform(data_train[['feature_1', 'feature_2']])","3607f36b":"data_train","63959e01":"data_train.index = data_train['time']\ndata_train","663e1dc2":"data_train = data_train.drop(['id', 'time'], axis = 1)","4306f49e":"data_train.head()","0cb94437":"corr = data_train.corr()\nsns.heatmap(corr, vmax=-1.0, vmin=-0.6)","d4166ade":"feature_1_inspect = train['feature_1']\nfeature_1_inspect = feature_1_inspect.append(pd.Series(test['feature_1'].values))","da22fa36":"len(feature_1_inspect.values)","d4fed7e6":"feature_1_inspect.describe()","7fd23a2d":"plt.plot(feature_1_inspect.values)","03e005bb":"plt.plot(data_train['feature_1'])","d79f6bb1":"plt.plot(data_test['feature_1'])","39174c97":"plt.plot(train.loc[30:180, 'feature_1'])","3b6889ed":"plt.plot(train.loc[30:180, 'feature_2'])","51d5719b":"sns.heatmap(train.corr())","561a873f":"sns.pairplot(data=data_train)","6b87fc5a":"train_copy = train.copy()","88e64c64":"train = train.drop(['id' , 'time'], axis = 1)\ntrain.head()","9c8ae5b6":"test_copy = test.copy()","de300d4e":"test = test.drop(['time'], axis = 1)\ntest.head()","6fd9fca8":"test[['feature_1', 'id']] = scaler.transform(test[['feature_1', 'id']])\ntest.head()\n","bf8459f7":"test['feature_1'].plot()","5b16ecde":"scaler = StandardScaler()\ntrain[['feature_1', 'feature_2']] = scaler.fit_transform(train[['feature_1', 'feature_2']])\ntrain.head()","96fed098":"sns.relplot(x='feature_1', y='feature_2', data=train, kind='scatter')","6dc3b97f":"train['feature_1'] = train[train['feature_1'] < 3]\ntrain = train.dropna()\ntrain.describe()","08a13d65":"sns.regplot(x='feature_1', y='feature_2', data=train)","890a8e64":"from sklearn.model_selection import train_test_split, cross_val_score\nx_train,x_test, y_train,  y_test = train_test_split(train['feature_1'], train['feature_2'], test_size=0.2)","bb29e475":"x_train, y_train = pd.DataFrame(x_train, columns=['feature_1']), pd.DataFrame(y_train, columns=['feature_2'])\nx_test, y_test = pd.DataFrame(x_test, columns=['feature_1']), pd.DataFrame(y_test, columns=['feature_2'])","ad724c83":"from sklearn.linear_model import LinearRegression\nLR = LinearRegression()\nLR.fit(x_train, y_train)","c8b1b431":"pred_test = LR.predict(x_test)\nprint(pred_test)","30bc147f":"r2_score(y_test, pred_test)","3d8737f5":"plt.figure(figsize=(5, 5))\nplt.scatter(x_train, y_train, color = \"green\")\nplt.plot(x_train, LR.predict(x_train), 'go')\nplt.title(\"LR Fit\")\nplt.xlabel(\"feature_1\")\nplt.ylabel(\"feature_2\")\nplt.show()\n","a81ed98a":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor()\nknn_param = {'n_neighbors': [1, 3, 5],\n            'leaf_size': [10, 20, 40, 50]}","afb96e7a":"grid_search = GridSearchCV(knn, knn_param, n_jobs=-1, cv=10)\n\ngrid_search.fit(x_train, y_train)","cc11f5b3":"model = grid_search.best_estimator_\nmodel.fit(x_train, y_train)","f36229e1":"pred = model.predict(x_test)","6e2dd196":"r2_score(y_test, pred )","47a04a39":"plt.figure(figsize = (5,5))\nplt.scatter(x_train, y_train, color = \"red\")\nplt.plot(x_train, model.predict(x_train), 'go')\nplt.title(\"Knn Fit\")\nplt.xlabel(\"feature_1\")\nplt.ylabel(\"feature_2\")\nplt.show()","ca5d656d":"x_test = pd.DataFrame(test['feature_1'], columns=['feature_1'])\npred_test = pd.DataFrame(model.predict(x_test), columns=['feature_2'])\npred_test","be70c875":"pred_test_data = pd.concat([test_copy['id'], pred_test], axis=1, copy=False)\npred_test_data","b0a0b5a8":"id_copy = test_copy['id']","688d16e3":"pred_test_data[['id', 'feature_2']] = scaler.inverse_transform(pred_test_data[['id', 'feature_2']])\npred_test_data['id'] = id_copy\nprint(pred_test_data.shape)\nprint(pred_test_data.head())","1ab4eae7":"len(id_copy)","1c0a37c7":"pred_test_data['feature_2']","cf7354fd":"submission = pd.DataFrame({'id': id_copy, 'feature_2':pred_test_data['feature_2'].values})","4ae710d6":"submission.head()","9df17c68":"submission.to_csv(r'submission.csv', index=False)","0162792f":"**Same for feature_2**","352de442":"**No Null Values** ","bb898f91":"# **Looking into feature_1**","d43c0d6f":"# Prediction_Model","5a915231":"# Removal of Outliers","a3d871a5":"Dealing with overfitting in KNN","105208b6":"**Scaling Dataset**","55eb6d56":"# KNN","086a7f84":"# Counclusion after Visualizations:\n*  feature_1 and feature_2 are negatively co-related.\n*  id and feature_2 are positively co-related\n*  Outliers present in both feature_1 and feature_2\n","aadf3f10":"# Linear Regression","c1a144d3":"# Outliers spotted"}}