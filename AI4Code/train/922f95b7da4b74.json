{"cell_type":{"14c4da89":"code","60376b4b":"code","90181dbc":"code","252f86e8":"code","1478b666":"code","07b0e2d2":"code","4cf0575d":"code","49dae52c":"code","e95b3bdb":"code","73c3e04d":"code","523dc724":"code","136860e1":"code","c94c54a9":"code","4f3dffda":"code","b29e552a":"code","01b15a1b":"code","39a5b021":"code","a46843e9":"code","f66eca3f":"code","3e415794":"code","71a5d78c":"code","379f651b":"code","98fb3f10":"code","550fba70":"code","27104c77":"code","42370ac2":"code","9ef74dd1":"code","e8e8bf96":"code","9965abb7":"code","ae0632cc":"code","04c152e1":"code","b627d54e":"code","360f21e6":"code","f7b66d60":"code","645e6a46":"code","edafc7a4":"code","6b174f40":"code","2486644c":"code","21a5ce2d":"code","b7382075":"code","3eb69e99":"markdown","e26063c2":"markdown","e8b0dc3f":"markdown","7115f51f":"markdown","d2bf09e0":"markdown","08949a8f":"markdown","37458e74":"markdown","5fceda79":"markdown","bfe5c7cf":"markdown","da325c9c":"markdown","487202cc":"markdown","d36dec65":"markdown","4897f191":"markdown","9a743044":"markdown","11667833":"markdown","04d53db3":"markdown","9d80bb37":"markdown","96b9de6f":"markdown","5cdcb13f":"markdown","8b624e75":"markdown","86b075e7":"markdown","40d8448e":"markdown","60e6f174":"markdown","ce89fa64":"markdown","8a61c2a1":"markdown","21845441":"markdown","8ae39479":"markdown","d1953fdc":"markdown","1f788253":"markdown","fef42637":"markdown","3b503ffb":"markdown","0ab4b9e6":"markdown","94388ca9":"markdown"},"source":{"14c4da89":"from fastai import *\nfrom fastai.vision import *","60376b4b":"# Exclude first gen commodores, they are giving me headaches\n\nclasses = ['andy', 'rafael', 'joker']","90181dbc":"!ls -la","252f86e8":"# Explain your data set in one word\ndata_name = \"tennis\"","1478b666":"for model in classes:\n    folder = model\n    file = model + '.csv'\n    path = Path(\"data\/\" + data_name)\n    print(file)\n    dest = path\/folder\n    dest.mkdir(parents=True, exist_ok=True)\n    !cp ..\/input\/* {path}\/\n    download_images(path\/file, dest, max_pics=299)","07b0e2d2":"for c in classes:\n    print(c)\n    verify_images(path\/c, delete=True, max_size=500)","4cf0575d":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=224, num_workers=0).normalize(imagenet_stats)","49dae52c":"\n# If you already cleaned your data, run this cell instead of the one before\n# np.random.seed(42)\n# data = ImageDataBunch.from_csv(path, folder=\".\", valid_pct=0.2, csv_labels='cleaned.csv',\n#         ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","e95b3bdb":"data.classes","73c3e04d":"data.show_batch(rows=3, figsize=(9,12))","523dc724":"learner = cnn_learner(data, models.resnet34, metrics=error_rate)","136860e1":"learner.fit_one_cycle(6)","c94c54a9":"learner.save('stage-1')","4f3dffda":"learner.unfreeze()","b29e552a":"learner.lr_find()","01b15a1b":"learner.recorder.plot()","39a5b021":"learner.fit_one_cycle(2, max_lr=slice(1e-4,1e-3))","a46843e9":"learner.save('stage-2')","f66eca3f":"learner.load('stage-2');","3e415794":"interp = ClassificationInterpretation.from_learner(learner)","71a5d78c":"interp.most_confused(min_val=2)[:10]","379f651b":"interp.plot_confusion_matrix()","98fb3f10":"from fastai.widgets import *","550fba70":"ds, idxs = DatasetFormatter().from_toplosses(learner, n_imgs=100)","27104c77":"ImageCleaner(ds, idxs, path)","42370ac2":"ds, idxs = DatasetFormatter().from_similars(learner)","9ef74dd1":"#import fastai\n#fastai.defaults.device = torch.device('cpu')","e8e8bf96":"#img = open_image(path\/'black'\/'00000021.jpg')\n#img","9965abb7":"#classes = ['black', 'grizzly', 'teddys']","ae0632cc":"#data2 = ImageDataBunch.single_from_classes(path, classes, tfms=get_transforms(), size=224).normalize(imagenet_stats)","04c152e1":"#learn = create_cnn(data2, models.resnet34).load('stage-2')","b627d54e":"#pred_class,pred_idx,outputs = learn.predict(img)\n#pred_class","360f21e6":"#learn = create_cnn(data, models.resnet34, metrics=error_rate)","f7b66d60":"#learn.fit_one_cycle(5, max_lr=1e-5)","645e6a46":"#learn.recorder.plot_losses()","edafc7a4":"#learn = create_cnn(data, models.resnet34, metrics=error_rate, pretrained=False)","6b174f40":"#learn.fit_one_cycle(1)","2486644c":"# np.random.seed(42)\n# data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.9, bs=32, \n#        ds_tfms=get_transforms(do_flip=False, max_rotate=0, max_zoom=1, max_lighting=0, max_warp=0\n#                              ),size=224, num_workers=4).normalize(imagenet_stats)","21a5ce2d":"# learn = create_cnn(data, models.resnet50, metrics=error_rate, ps=0, wd=0)\n# learn.unfreeze()","b7382075":"# learn.fit_one_cycle(40, slice(1e-6,1e-4))","3eb69e99":"## Deployment: Putting your model in production\n> \nYou probably want to use CPU for inference, except at massive scale (and you almost certainly don't need to train in real-time). If you don't have a GPU that happens automatically. You can test your model on CPU like so:","e26063c2":"### Tuning","e8b0dc3f":"### Observations of Performance\n* Commodore VX and VT are very similar\n* Commodore VY and VZ are very similar\n* Quality Commodore images via Google Images can be hard with lots of rubbish\n* May need a lot more quality images to be a robust solution","7115f51f":"## Agenda\n\nThis evening session is a mirror of Jeremy Howard and the Fast.ai course content (lecture 2). Thank you Fast.ai. There are some minor tweaks by yours truly to ensure the session is even more easier for folks with no Python skills.\n\n1. Introduction & Setup\n2. Data Gathering\n3. Preprocessing & Modeling\n4. Performance Tuning & Evaluation\n5. Data Cleaning & Retraining\n6. Next time (maybe): Deployment","d2bf09e0":"## Data Gathering\n\n**Steps**\n\nHere we will:\n\n* Go to images.google.com and search the classes of images you are keen to train a model on\n* For each image class you search, scroll down for a little bit to ensure you have enough images in view, then run the following commands in Chrome:\n    ```\n    First:\n    Press Ctrl + Shift + J in Windows\/Linux and Cmd + Opt + J in Mac\n    ```\n    ```\n    Then:\n    urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n    window.open('data:text\/csv;charset=utf-8,' + escape(urls.join('\\n')));\n```\n* Now you have some labeled URLs, come back to your kaggle kernel and click \"+ Add Data\" then click \"upload\". Then name your dataset and upload the relevant csv files you just created.\n\n","08949a8f":"As well as taking a really long time, it's getting too many looks at each image, so may overfit.","37458e74":"### Prerequisites\n\n* Grown mindset and attitude\n* An idea of what code looks like\n\nMoving forward with this club, a basic understanding of Python will go a long way. A great resource to start this journey is Google's introduction Python course:\n[Google's Python Class](https:\/\/developers.google.com\/edu\/python\/)\n\nThis very course is where it all began for me 3 years ago when I decided to start coding again.","5fceda79":"Then we can remove any images that can't be opened:","bfe5c7cf":"- Most of the time things will train fine with the defaults\n- There's not much you really need to tune (despite what you've heard!)\n- Most likely are\n  - Learning rate\n  - Number of epochs","da325c9c":"## Cleaning Up\n\nSome of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.\n\nUsing the `ImageCleaner` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong.","487202cc":"### Too few epochs","d36dec65":"Flag photos for deletion by clicking 'Delete'. Then click 'Next Batch' to delete flagged photos and keep the rest in that row. ImageCleaner will show you a new row of images until there are no more to show. In this case, the widget will show you images until there are none left from top_losses.ImageCleaner(ds, idxs)\n\nYou can also find duplicates in your dataset and delete them! To do this, you need to run .from_similars to get the potential duplicates' ids and then run ImageCleaner with duplicates=True. The API works in a similar way as with misclassified images: just choose the ones you want to delete and click 'Next Batch' until there are no more images left.","4897f191":"### Fast.ai resources\n\nThis session wouldn't be possible without the fantastic Fast.ai offerings, as well as, Sanyam Bhutani who authored the Kaggle version of Lesson 2. For more information access the below links:[](http:\/\/)","9a743044":"# Cyber Analytics Club\n# Evening 1: Building your very own image classifier using Fast.ai","11667833":"### Transfer Learning using ResNet trained on ImageNet\n\nTransfer learning is a technique where you use a model trained on a very large dataset (usually ImageNet in computer vision) and then adapt it to your own dataset. The idea is that it has learned to recognize many features on all of this data, and that you will benefit from this knowledge, especially if your dataset is small, compared to starting from a randomly initialized model. It has been proved in this article on a wide range of tasks that transfer learning nearly always give better results.\n\nThe fastai library includes several pretrained models from torchvision, namely:\n\n* resnet18, resnet34, resnet50, resnet101, resnet152\n* squeezenet1_0, squeezenet1_1\n* densenet121, densenet169, densenet201, densenet161\n* vgg16_bn, vgg19_bn\n* alexnet","04d53db3":"## Preprocessing & Modeling","9d80bb37":"### Too many epochs","96b9de6f":"So you might create a route something like this ([thanks](https:\/\/github.com\/simonw\/cougar-or-not) to Simon Willison for the structure of this code):\n\n```\n\n@app.route(\"\/classify-url\", methods=[\"GET\"])\nasync def classify_url(request):\n    bytes = await get_bytes(request.query_params[\"url\"])\n    img = open_image(BytesIO(bytes))\n    _,_,losses = learner.predict(img)\n    return JSONResponse({\n        \"predictions\": sorted(\n            zip(cat_learner.data.classes, map(float, losses)),\n            key=lambda p: p[1],\n            reverse=True\n        )\n    })\n    \n    ```\n    \n","5cdcb13f":"## Performance Tuning & Evaluation","8b624e75":"# Lab: Creating your own dataset from Google Images\n## Example \"Never forget the Aussie-made Commodore Classifier\"\nMore information:\n[Holden Commodore Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Holden_Commodore)","86b075e7":"## Things that can go wrong","40d8448e":"Remember to recreate your ImageDataBunch from your cleaned.csv to include the changes you made in your data!","60e6f174":"(This [example](https:\/\/www.starlette.io\/) is for the Starlette web app toolkit.)","ce89fa64":"### Interpretation ","8a61c2a1":"First we need to get the file paths from our top_losses. We can do this with `.from_toplosses`. We then feed the top losses indexes and corresponding dataset to `ImageCleaner`.\n\nNotice that the widget will not delete images directly from disk but it will create a new csv file `cleaned.csv` from where you can create a new ImageDataBunch with the corrected labels to continue training your model.","21845441":"### Training","8ae39479":"### Define labels","d1953fdc":"Note: Please Set the Number of images to a number that you'd like to view:\nex: ```n_imgs=100```","1f788253":"### View data","fef42637":"### Prepare image data","3b503ffb":"### Learning rate (LR) too low","0ab4b9e6":"References:\n* Lecture 2, Practical Deep Learning for Coders, Francisco Ingham and Jeremy Howard 2019. For complete info on the course, visit course.fast.ai\n* Google Images data set inspired by [Adrian Rosebrock](https:\/\/www.pyimagesearch.com\/2017\/12\/04\/how-to-create-a-deep-learning-dataset-using-google-images\/)*","94388ca9":"[Lesson Video Link](https:\/\/course.fast.ai\/videos\/?lesson=2)\n\n[Lesson resources and updates](https:\/\/forums.fast.ai\/t\/lesson-2-official-resources-and-updates\/28630)\n\n[Lesson chat](https:\/\/forums.fast.ai\/t\/lesson-2-chat\/28722)\n\n[Further discussion thread](https:\/\/forums.fast.ai\/t\/lesson-2-further-discussion\/28706)"}}