{"cell_type":{"d4896a6f":"code","749517f5":"code","b26b7078":"code","ff967c03":"code","b01a7916":"code","d63df9c4":"markdown","2c4e3ce6":"markdown","329cd1f2":"markdown","edafbbdf":"markdown","ff6a3587":"markdown","f93b2ba7":"markdown","616ad3ea":"markdown","2cc96425":"markdown"},"source":{"d4896a6f":"import pandas as pd\nwhite_wine = pd.read_csv('..\/input\/white-wine-quality\/WhiteWineQualityCSV.csv')\nwhite_wine.describe()","749517f5":"from sklearn.impute import SimpleImputer\n\n\n# Create training and validation splits\ndf_train = white_wine.sample(frac=0.7, random_state=0)\ndf_valid = white_wine.drop(df_train.index)\ndisplay(df_train.head(4))\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_df_train = pd.DataFrame(my_imputer.fit_transform(df_train))\nimputed_df_valid = pd.DataFrame(my_imputer.transform(df_valid))\n\n# Imputation removed column names; put them back\nimputed_df_train.columns = df_train.columns\nimputed_df_valid.columns = df_valid.columns\n\n# Scale to [0, 1]\nmax_ = imputed_df_train.max(axis=0)\nmin_ = imputed_df_train.min(axis=0)\ndf_train = (df_train - min_) \/ (max_ - min_)\ndf_valid = (df_valid - min_) \/ (max_ - min_)\n\n# Split features and target\nX_train = imputed_df_train.drop('quality', axis=1)\nX_valid = imputed_df_valid.drop('quality', axis=1)\ny_train = imputed_df_train['quality']\ny_valid = imputed_df_valid['quality']","b26b7078":"X_train.shape # This helps us to find out the number of inputs in our Deep Learning network","ff967c03":"from tensorflow import keras\nfrom tensorflow.keras import layers,callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\nmodel = keras.Sequential([\n    layers.Dense(512, activation='relu', input_shape=[11]),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='mae',\n)","b01a7916":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=256,\n    epochs=600,\n    callbacks=[early_stopping],\n    verbose=0,\n)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\nprint(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))","d63df9c4":"The first stage of the process invloves reading the file using the **pandas library** , and doing some basic data investigation using the .describe() method.\n\n","2c4e3ce6":"From our Deep learning model, we obtained a loss of about 0.577\n\nSo we can say that on average that our predictions of a White Wine's quality using this model, will be about 0.577 above or below the exact value. It's not very ideal, and it's possible for us to still work on it and obtain better results. \n\nThanks for reading. Do well to comment and leave questions below.","329cd1f2":"# **4. Fitting of Model and Visualization of loss**\n\n   In this stage, we will be fitting our model and viewing how our validation loss and in-dataset loss performs as we apply our earlystopping method()\n","edafbbdf":"# **AN OPTIMIZED DEEP LEARNING MODEL FOR PREDICTING THE QUALITY OF A PORTUGUESE WHITE WINE USING ITS PHYSIOCHEMICAL PROPERTIES**","ff6a3587":"#  2. **Data Preparation, Splitting, Scaling and Choosing Target values**\n   To solve the problem of missing values, we are going to solve the problem using the **SimpleImputer()method**  from the *sk.learn library*. To read more about how to handle missing values in a dataset, i will recommend you check out this lesson in one of  Kaggle's machine learning course https:\/\/www.kaggle.com\/alexisbcook\/missing-values.\n   \n   \n*    **Splitting**\n      \n      In order to avoid overfitting , we are going to split the dataset into two parts - The training set and the validation set (also known as test set). I chose to have it in a ratio 70% to 30% , some people also like to have it as 80% to 20% . So either of these two ratios are fine.\n       \n*    **Scaling**    \n\n       This is usually advised, because it enables most models to perform better with the dataset. So we scale our data to fit into [0,1].\n     \n*   **Choosing Target values**    \n\n      Since we are trying to predict the quality of a white wine, given all it's physiochemical properties, we have to exclude it from the dataset and have it as our target value.","f93b2ba7":"# **3. Deploying a Deep Learning model using TensorFlow**\n\n*  In this stage , we will be deploying a **3-layered deep learning network** from Keras and utilizing the **callbacks library** to apply **EarlyStopping method()** for obtaining an optimum value of weights , in order for us to minimise the validation loss.  \n\n*  Also, we will compile our model by specifying the performance metric and our optimizer- which are **MEAN ABSOLUTE ERRROR(MAE)** and **ADAM** respectively ","616ad3ea":" # 1. **DATA LOADING AND EXPLORATION**","2cc96425":"It can be seen from the data description that our dataset contains **12 columns** and from the **count value** we can see that each column has varying . Some have 4890, 4891,4898 ,etc. Hence, we can infer that there are some missing values in certain places in our dataset. Hence, we will need to do some data preparation and preprocessing."}}