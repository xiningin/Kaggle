{"cell_type":{"963cb045":"code","4c2eee33":"code","cb3c9e87":"code","b9c66845":"code","2b42dbca":"code","2adb81ca":"code","d9c02ff3":"code","0a75d47d":"code","2406af42":"code","18d4bc5a":"code","27a2c07f":"code","270e384c":"code","ddb5eaef":"code","3019e6ee":"code","8a638904":"code","8a84fa02":"code","8db6238a":"code","92d5fa91":"code","6ca95cf2":"code","6b122f6d":"code","1cdc042d":"code","58fb084d":"code","60e63318":"code","3484edb5":"code","e8883449":"code","e2afbeab":"code","2a945a2e":"code","1617955b":"code","3568ebb3":"code","d525a128":"code","a3cf8676":"code","e3205ff6":"code","c2877378":"code","45c67c9e":"code","94f4a23a":"code","08e5c583":"code","c37e0b9b":"code","7db67d6d":"code","7589da16":"code","9a3721df":"code","8b0d6e19":"code","ac6f1c7e":"code","05b05238":"code","d41b4a61":"code","b4b7f72c":"code","203de4fc":"code","8ef1a7c3":"markdown","08a9d21b":"markdown","9e28952c":"markdown","7d9c7f22":"markdown"},"source":{"963cb045":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport zipfile\nimport cv2\nfrom skimage import io\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.keras import backend as K\nfrom sklearn.preprocessing import StandardScaler, normalize\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4c2eee33":"defect_df = pd.read_csv('\/kaggle\/input\/steel-defect-detection\/train.csv')\ndefect_df.head()","cb3c9e87":"traindf = pd.read_csv('\/kaggle\/input\/steel-defect-detection\/defect_and_no_defect.csv')\ntraindf.head()","b9c66845":"defect_df['mask'] = defect_df['ClassId'].map(lambda x: 1)\ndefect_df.head()","2b42dbca":"sns.countplot(defect_df.ClassId)\nplt.show()","2adb81ca":"train_dir = '\/kaggle\/input\/steel-defect-detection\/train_images\/'\n\nfor i in range(10):\n  img = io.imread(os.path.join(train_dir, defect_df.ImageId[i]))\n  plt.figure()\n  plt.title(defect_df.ClassId[i])\n  plt.imshow(img)","d9c02ff3":"def rle2mask(rle, height, width):\n  #creating a one dimentional array containing 0's of length obtained by multiplying height and width of the image\n  mask = np.zeros(height*width).astype(np.uint8)\n\n  #spliting the rle based on space , try running the rle.split() on separate cell to see how the values are separated based on space\n  rle = rle.split()\n\n  #selecting every second value in the list like obtaining values corresponding to indexes 0,2,4,....\n  start = rle[0::2]\n\n  #selecting every second value in the list like obtaining values corresponding to indexes 1,3,5,....\n  length = rle[1::2]\n  \n  for i in range(len(start)):\n    mask[int(start[i]):(int(start[i])+int(length[i]))] = 1\n  \n  #Now the shape of the mask is in one dimension, we need to convert the mask to the same dimension as the image, initally using reshape and followed by Transpose\n  img = mask.reshape(width, height)\n  img = img.T\n  return img\n\n\ndef mask2rle(mask):\n\n  #We do the reverse of what we did in the above function, initially apply Transpose to the mask image and then flatten to one dimension\n  pixels = mask.T.flatten()\n\n  #Here, we add extra values at front and end , this would help in finding the correct length of pixels that have been masked\n  pixels = np.concatenate([[0], pixels, [0]])\n    \n  rle = np.where(pixels[1:] != pixels[:-1])[0]\n\n  #here we subtract values in even index in the obtained list(i.e) [2,5], from the odd index, (i.e.)5-2 = 3, Now the list would look like [2, 3]\n  rle[1::2] -= rle[0::2]\n  \n  #finally join to rle format, in this case it would look like ('2 3')\n  return ' '.join(str(x) for x in rle)\n\n  ","0a75d47d":"image_index = 23\nimg = io.imread(os.path.join(train_dir, defect_df.ImageId[image_index]))\nplt.imshow(img)\nplt.show()\nmask = rle2mask(defect_df.EncodedPixels[image_index], img.shape[0], img.shape[1])\nplt.imshow(mask)\nplt.show()","2406af42":"img = io.imread(os.path.join(train_dir, defect_df.ImageId[image_index]))\nplt.imshow(img)\nplt.show()","18d4bc5a":"for i in range(10):\n\n  # Read the images using opencv and converting to rgb format\n  img = io.imread(os.path.join(train_dir, defect_df.ImageId[i]))\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n  # Get the mask for the image from rle\n  mask = rle2mask(defect_df.EncodedPixels[i], img.shape[0], img.shape[1])\n  \n  # Let's color the pixels with values = 1 \n  img[mask == 1,1] = 255\n  plt.figure()\n  plt.imshow(img)\n  plt.title(defect_df.ClassId[i])","27a2c07f":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(traindf, test_size=0.2)\ntrain.shape,test.shape","270e384c":"from keras_preprocessing.image import ImageDataGenerator\n\ntrain_dir = '\/kaggle\/input\/steel-defect-detection\/train_images\/'\n\ndatagen = ImageDataGenerator(rescale=1.\/255., validation_split = 0.2)\ntest_datagen = ImageDataGenerator(rescale=1.\/255.)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe = train,directory = train_dir,x_col = \"ImageID\",\n                                              y_col = \"label\",subset = \"training\",batch_size = 16,shuffle = True,\n                                              class_mode = \"other\",target_size = (256, 256))\n\nvalid_generator = datagen.flow_from_dataframe(dataframe = train,directory = train_dir,x_col = \"ImageID\",\n                                              y_col = \"label\",subset = \"validation\",batch_size = 16,shuffle = True,\n                                              class_mode = \"other\",target_size = (256, 256))\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe = test,directory = train_dir,x_col = \"ImageID\",\n                                              y_col = None,batch_size = 16,shuffle = False,\n                                              class_mode = None,target_size = (256, 256))","ddb5eaef":"basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))\nbasemodel.summary()","3019e6ee":"# Freezing the model\nfor layer in basemodel.layers:\n  layers.trainable = False","8a638904":"headmodel = basemodel.output\nheadmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\nheadmodel = Flatten(name= 'flatten')(headmodel)\nheadmodel = Dense(256, activation = \"relu\")(headmodel)\nheadmodel = Dropout(0.3)(headmodel)\nheadmodel = Dense(1, activation = 'sigmoid')(headmodel)\n\nmodel = Model(inputs = basemodel.input, outputs = headmodel)","8a84fa02":"model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics= [\"accuracy\"])","8db6238a":"earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n\ncheckpointer = ModelCheckpoint(filepath=\"resnet-weights.hdf5\", verbose=1, save_best_only=True)","92d5fa91":"history = model.fit_generator(train_generator, steps_per_epoch= train_generator.n \/\/ 16, epochs = 40, validation_data= valid_generator, validation_steps= valid_generator.n \/\/ 16, callbacks=[checkpointer, earlystopping])","6ca95cf2":"#Saving the model\nmodel_json = model.to_json()\nwith open(\"resnet-classifier-model.json\",\"w\") as json_file:\n  json_file.write(model_json)","6b122f6d":"with open('\/kaggle\/working\/resnet-classifier-model.json', 'r') as json_file:\n    json_savedModel= json_file.read()\n\n# Using the model with the weights\nmodel = tf.keras.models.model_from_json(json_savedModel)\nmodel.load_weights('\/kaggle\/working\/resnet-weights.hdf5')\nmodel.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics= [\"accuracy\"])","1cdc042d":"# Making our prediction\ntest_predict = model.predict(test_generator, steps = test_generator.n \/\/ 16, verbose =1)\ntest_predict.shape","58fb084d":"predict = []\n\nfor i in test_predict:\n  if i < 0.5: #0.5\n    predict.append(0)\n  else:\n    predict.append(1)\n\npredict = np.asarray(predict)\npredict.shape","60e63318":"original = np.asarray(test.label)[:2592]\noriginal.shape","3484edb5":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(original, predict)\naccuracy","e8883449":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['loss'])\n\nplt.title('Model Loss and Accuracy Progress During Training')\nplt.xlabel('Epoch')\nplt.ylabel('Training Accuracy and Loss')\nplt.legend(['Training Accuracy', 'Training Loss'])\nplt.show()","e2afbeab":"plt.plot(history.history['val_loss'])\nplt.title('Model Loss During Cross-Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Loss')\nplt.legend(['Validation Loss'])\nplt.show()","2a945a2e":"plt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy Progress During Cross-Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Accuracy')\nplt.legend(['Validation Accuracy'])\nplt.show()","1617955b":"from sklearn.metrics import confusion_matrix,classification_report\nmatrix = confusion_matrix(original, predict)\nsns.heatmap(matrix, annot=True, fmt=\"d\", cmap='Blues', square=True)\nplt.xlabel(\"predicted\")\nplt.ylabel(\"actual\")\nplt.show()","3568ebb3":"print(classification_report(original,predict, labels = [0,1]))","d525a128":"X_train, X_val = train_test_split(defect_df, test_size=0.2)\n\ntrain_ids = list(X_train.ImageId)\ntrain_class = list(X_train.ClassId)\ntrain_rle = list(X_train.EncodedPixels)\n\nval_ids = list(X_val.ImageId)\nval_class = list(X_val.ClassId)\nval_rle = list(X_val.EncodedPixels)","a3cf8676":"class DataGenerator(tf.keras.utils.Sequence):\n  def __init__(self, ids , list_class, list_rle, image_dir, batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n\n    self.ids = ids\n    self.class_type = list_class\n    self.rle = list_rle\n    self.image_dir = image_dir\n    self.batch_size = batch_size\n    self.img_h = img_h\n    self.img_w = img_w\n    self.shuffle = shuffle\n    self.on_epoch_end()\n\n  def __len__(self):\n    'Get the number of batches per epoch'\n\n    return int(np.floor(len(self.ids)) \/ self.batch_size)\n\n  def __getitem__(self, index):\n    'Generate a batch of data'\n\n    #generate index of batch_size length\n    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n\n    #get the ImageId corresponding to the indexes created above based on batch size\n    list_ids = [self.ids[i] for i in indexes]\n\n    #get the ClassId corresponding to the indexes created above based on batch size\n    list_class = [self.class_type[i] for i in indexes]\n\n    #get the rle corresponding to the indexes created above based on batch size\n    list_rle = [self.rle[i] for i in indexes]\n\n    #generate data for the X(features) and y(label)\n    X, y = self.__data_generation(list_ids, list_class, list_rle)\n    #returning the data\n    return X, y\n\n  def on_epoch_end(self):\n    'Used for updating the indices after each epoch, once at the beginning as well as at the end of each epoch'\n    \n    #getting the array of indices based on the input dataframe\n    self.indexes = np.arange(len(self.ids))\n\n    #if shuffle is true, shuffle the indices\n    if self.shuffle:\n      np.random.shuffle(self.indexes)\n\n  def __data_generation(self, list_ids, list_class, list_rle):\n    'generate the data corresponding the indexes in a given batch of images'\n\n    # create empty arrays of shape (batch_size,height,width,depth) \n    #Depth is 1 for input and depth is taken as 4 for output becasue of 4 types of defect\n    X = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n    y = np.empty((self.batch_size, self.img_h, self.img_w, 4))\n\n    #iterate through the dataframe rows, whose size is equal to the batch_size\n    for index, id in enumerate(list_ids):\n      #path of the image\n      path = '\/kaggle\/input\/steel-defect-detection\/train_images\/' + str(id)\n\n      #reading the image along blue channel(0)\n      img = io.imread(path)\n      img =img[:,:,0]\n\n      #resizing the image and coverting them to array of type float64\n      img = cv2.resize(img,(self.img_h,self.img_w))\n      img = np.array(img, dtype = np.float64)\n\n      #standardising the image\n      img -= img.mean()\n      img \/= img.std()\n\n      #creating a empty mask for label\n      mask = np.empty((self.img_h,self.img_w,4))\n\n      #iterating through the 4 class id to creat mask for each defect of the same image\n      for j, class_id in enumerate([1,2,3,4]):\n\n        #getting rle from list, using index used to get the image id\n        rle = list_rle[index]\n\n        #create a mask using rle if it belongs to a class_id else create mask with zeros if there no rle belonging to a class_id\n        if list_class[index] == class_id:\n          class_mask = rle2mask(rle,256,1600)\n        else:\n          class_mask = np.zeros((256,1600))\n        \n        #resizing the mask to shape (256,256)\n        resized_mask = cv2.resize(class_mask,(self.img_h,self.img_w))\n\n        #adding mask corresponding to each class_id\n        mask[...,j] = resized_mask \n      \n      #expanding the dimnesion of the image from (256,256) to (256,256,1)\n      X[index,] = np.expand_dims(img, axis = 2)\n      y[index,] = mask\n    \n    #normalizing y\n    y = (y > 0).astype(int)\n    y = tf.cast(y, tf.float64)\n\n    return X, y","e3205ff6":"training_generator = DataGenerator(train_ids,train_class, train_rle, train_dir)\nvalidation_generator = DataGenerator(val_ids,val_class,val_rle, train_dir)","c2877378":"def resblock(X, f):\n  X_copy = X\n\n  X = Conv2D(f, kernel_size = (1,1), strides = (1,1), kernel_initializer ='he_normal')(X)\n  X = BatchNormalization()(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n  X = BatchNormalization()(X)\n\n  X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n  X_copy = BatchNormalization()(X_copy)\n  \n  X = Add()([X,X_copy])\n  X = Activation('relu')(X)\n\n  return X\n\n\ndef upsample_concat(x, skip):\n  x = UpSampling2D((2,2))(x)\n  merge = Concatenate()([x, skip])\n\n  return merge","45c67c9e":"input_shape = (256,256,1)\n\n#Input tensor shape\nX_input = Input(input_shape)\n\n#Stage 1\nconv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\nconv1_in = BatchNormalization()(conv1_in)\nconv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\nconv1_in = BatchNormalization()(conv1_in)\npool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n\n#Stage 2\nconv2_in = resblock(pool_1, 32)\npool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n\n#Stage 3\nconv3_in = resblock(pool_2, 64)\npool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n\n#Stage 4\nconv4_in = resblock(pool_3, 128)\npool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n\n#Stage 5\nconv5_in = resblock(pool_4, 256)\n\n#Upscale stage 1\nup_1 = upsample_concat(conv5_in, conv4_in)\nup_1 = resblock(up_1, 128)\n\n#Upscale stage 2\nup_2 = upsample_concat(up_1, conv3_in)\nup_2 = resblock(up_2, 64)\n\n#Upscale stage 3\nup_3 = upsample_concat(up_2, conv2_in)\nup_3 = resblock(up_3, 32)\n\n#Upscale stage 4\nup_4 = upsample_concat(up_3, conv1_in)\nup_4 = resblock(up_4, 16)\n\n#Final Output\noutput = Conv2D(4, (1,1), padding = \"same\", activation = \"sigmoid\")(up_4)\n\nmodel_seg = Model(inputs = X_input, outputs = output )","94f4a23a":"def tversky(y_true, y_pred, smooth = 1e-6):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)\/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n\ndef focal_tversky(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)","08e5c583":"adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nmodel_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])","c37e0b9b":"earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n\ncheckpointer = ModelCheckpoint(filepath=\"resunet-segmentation-weights.hdf5\", verbose=1, save_best_only=True)","7db67d6d":"history = model_seg.fit_generator(training_generator, epochs = 40, validation_data= validation_generator, callbacks=[checkpointer, earlystopping])","7589da16":"model_json = model_seg.to_json()\nwith open(\"resunet-segmentation-model.json\",\"w\") as json_file:\n  json_file.write(model_json)","9a3721df":"with open('\/kaggle\/working\/resunet-segmentation-model.json', 'r') as json_file:\n    json_savedModel= json_file.read()\n\nmodel_seg = tf.keras.models.model_from_json(json_savedModel)\nmodel_seg.load_weights('\/kaggle\/working\/resunet-segmentation-weights.hdf5')\nadam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nmodel_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])","8b0d6e19":"test_df = pd.read_csv('\/kaggle\/input\/steel-defect-detection\/test.csv')\ntest_df.head()","ac6f1c7e":"def prediction(test, model, model_seg):\n  '''\n  Predcition function which takes dataframe containing ImageID as Input and perform 2 type of prediction on the image\n  Initially, image is passed through the classification network which predicts whether the image has defect or not, if the model\n  is 99% sure that the image has no defect, then the image is labeled as no-defect, if the model is not sure, it passes the image to the\n  segmentation network, it again checks if the image has defect or not, if it has defect, then the type and location of defect is found\n  '''\n\n  #directory\n  directory = \"\/kaggle\/input\/steel-defect-detection\/train_images\"\n\n  #Creating empty list to store the results\n  mask = []\n  defect_type = []\n  image_id = []\n\n  #iterating through each image in the test data\n  for i in test.ImageId:\n\n    path = os.path.join(directory, i)\n\n    #reading the image\n    img = io.imread(path)\n\n    #Normalizing the image\n    img = img * 1.\/255.\n\n    #Reshaping the image\n    img = cv2.resize(img,(256,256))\n\n    #Converting the image into array\n    img = np.array(img, dtype = np.float64)\n    \n    #reshaping the image from 256,256,3 to 1,256,256,3\n    img = np.reshape(img, (1,256,256,3))\n\n    #making prediction on the image\n    defect_or_no_defect = model.predict(img)\n\n    #if the image has defect we append the details of the image to the list\n    if defect_or_no_defect < 0.01:\n      image_id.append(i)\n      defect_type.append(0)\n      mask.append('0 0')\n      continue\n\n    #reading the image along blue channel (0)( we can take any channel or 3 channel as itself, if we are taking 3 channels we need to change X depth to 3)\n    img = io.imread(path)\n    img =img[:,:,0]\n\n    #Creating a empty array of shape 1,256,256,1\n    X = np.empty((1, 256, 256, 1))\n\n    #resizing the image and coverting them to array of type float64\n    img = cv2.resize(img,(256,256))\n    img = np.array(img, dtype = np.float64)\n\n    #standardising the image\n    img -= img.mean()\n    img \/= img.std()\n\n    #converting the shape of image from 256,256 to 1,256,256,1\n    X[0,] = np.expand_dims(img, axis = 2)\n\n    #make prediction\n    predict = model_seg.predict(X)\n\n    #if the sum of predicted values is equal to 0 then there is no defect\n    if predict.round().astype(int).sum() == 0:\n      image_id.append(i)\n      defect_type.append(0)\n      mask.append('0 0')\n      continue\n\n    #iterating 4 times to get the prediction of 4 different classes\n    for j in range(4):\n      #since j values through iteration are 0,1,2,3 , we add 1 to j to make it as classIDs corresponding to 1,2,3,4\n      class_id = j + 1\n\n      #get the mask values of each class\n      mask_value = predict[0,:,:,j].round().astype(int)\n\n      #if the sum of mask values is greater than 0.5(anything greater than 0 ), that class has defect\n      if mask_value.sum() > 0.5:\n        try:\n            #applying mask to image, area with defect will be highlighted in white(255)\n            img[mask_value == 1] = 255\n            #since our original shape is 256,1600, we reshape to that size\n            img = cv2.resize(img,(1600,256))\n            #Now, we mask the image such that, areas which are not white(defected areas) to be black(0)\n            img[img < 255] = 0\n            #we again normalize the values\n            img = img * 1.\/255.\n            #get the rle for the create masked image\n            rle = mask2rle(img)\n        except:\n            continue\n\n        #append the valeues to the respective listes\n        image_id.append(i)\n        defect_type.append(class_id)\n        mask.append(rle)\n\n  return image_id, defect_type, mask","05b05238":"image_id, defect_type, mask = prediction(test_df, model, model_seg)","d41b4a61":"df_pred= pd.DataFrame({'ImageId': image_id,'EncodedPixels': mask,'ClassId': defect_type})\ndf_pred.head()","b4b7f72c":"for i in range(10):\n  img = io.imread(os.path.join(train_dir,test_df.ImageId[i]))\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n  mask = rle2mask(test_df.EncodedPixels[i],img.shape[0],img.shape[1])\n\n  img[mask == 1,1] = 255\n  plt.figure()\n  plt.title(test_df.ClassId[i])\n  plt.imshow(img)","203de4fc":"directory = \"\/kaggle\/input\/steel-defect-detection\/train_images\"\n\nfor i in range(10):\n  img = io.imread(os.path.join(directory,df_pred.ImageId[i]))\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n  mask = rle2mask(df_pred.EncodedPixels[i],img.shape[0],img.shape[1])\n  \n  img[mask == 1,0] = 255\n  plt.figure()\n  plt.title(df_pred.ClassId[i])\n  plt.imshow(img)","8ef1a7c3":"# Classifier","08a9d21b":"# EDA","9e28952c":"# ResUNet","7d9c7f22":"# Evaluating the classifier"}}