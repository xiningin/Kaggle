{"cell_type":{"9b3eba54":"code","74606193":"code","a4003000":"code","e388560f":"code","4c28fe75":"code","eb3d20a1":"code","e739fb4a":"code","55ceeb1d":"code","aa373db8":"code","76a08e7f":"code","59001294":"code","545091ab":"code","e463ddd5":"code","2e64b52d":"code","b50b96c0":"code","225d2d0e":"code","a69d23d3":"code","96b73eda":"code","6e43ddb5":"code","70198126":"code","31d2555f":"code","f30c3711":"code","7f400fd8":"code","a7888d9c":"code","b6e1e605":"code","c2349657":"code","3af02f6b":"code","274ce006":"code","17da6f3d":"code","44754cfb":"code","57a0ce98":"code","266a899b":"code","0254f18a":"code","0f25ec48":"code","feec2c0e":"code","01174ec3":"code","b89ca1b9":"code","df665e05":"markdown","4007617e":"markdown","24cb6e11":"markdown","103b887d":"markdown","4e5cfe72":"markdown","46b33ca9":"markdown","27aeb9b0":"markdown","5ef9068b":"markdown","85b8716c":"markdown","0667e261":"markdown","3cd2b37d":"markdown","cac72217":"markdown","a99aa890":"markdown","2e6498da":"markdown","535e9da8":"markdown","e6e7c2df":"markdown","afc66b12":"markdown","92de7736":"markdown","0e7c8102":"markdown","dbe25cae":"markdown","3f1dd4f3":"markdown","0040c811":"markdown","6dd50ebd":"markdown","0a68fd5b":"markdown","5972ecc0":"markdown","ab35ec9d":"markdown","9af57dd4":"markdown","1786ec52":"markdown","5033ab63":"markdown","d0a33741":"markdown","d52c457e":"markdown","3b539721":"markdown"},"source":{"9b3eba54":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file\n\n# For visvalization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\n\n%matplotlib inline","74606193":"# Reading the csv files\ndf=pd.read_csv('..\/input\/world-happiness-report-2021\/world-happiness-report-2021.csv')\ndf1=pd.read_csv('..\/input\/world-happiness-report-2021\/world-happiness-report.csv')\n\ndf.head()","a4003000":"df1.head()","e388560f":"# df.info() shows the basic information about the data like column names, data types, number of rows, memory usages, etc.\ndf.info()","4c28fe75":"# Checking for missing values\ndf.isnull().sum()","eb3d20a1":"# Visvalization of numeric columns\n\nfig, ax=plt.subplots(3,6, figsize=(15,10)) # Creates a grid of 3 rows and 6 colums as we have 18 numeric columns.\nnumeric_col=df.select_dtypes('float64').columns # For selecting perticuler datatype\nfor num_col, axis in zip(numeric_col, ax.ravel()): # ax.ravel() kind of flattens the 2d grid we created, for iteration\n    sns.boxplot(x=num_col, data=df, ax=axis)\n\nplt.tight_layout() # makes the layout of the plot tight, i.e. to avoid overlapping of plots","e739fb4a":"# Getting countries details for plotting them on map. \n#Geopandas has inbuild dataset of that, so you don't have to search it elsewhere.\n\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nworld.head()","55ceeb1d":"world['geometry'][1]","aa373db8":"# Checking for different country names. There can be missmatch in spelling of country names in 'df' and 'world'\ncountry_data = list(df['Country name'].unique())\ncountry_geo = list(world['name'])\n\ncountry_diff = [country for country in country_data if country not in country_geo]\ncountry_diff","76a08e7f":"# Replacing the misspelled country names in 'df' as per 'world', you can do it the other way also.\ndf['Country name'] = df['Country name'].replace({'United States' : 'United States of America',\n                                          'Taiwan Province of China':'Taiwan',\n                                          'Bosnia and Herzegovina':'Bosnia and Herz.',\n                                          'Dominican Republic':'Dominican Rep.',\n                                          'North Cyprus':'N. Cyprus',\n                                          'Swaziland':'Switzerland'})","59001294":"# Function for plotting on world map.\n# It takes 3 arguments - the data frame, the columns which is to be plotted and the title of the plot\n\ndef plot_on_worldmap(df, col_to_map, title=None):\n    # Plotting on world map\n    mapped = world.set_index('name').join(df.set_index('Country name')).reset_index() # Joins the df with world data for plotting\n\n    to_be_mapped = col_to_map # The column name which is to shown on map\n    vmin, vmax = df[col_to_map].min(), df[col_to_map].max()# Minimum and maximum values for the column\n\n    fig, ax = plt.subplots(1, figsize=(20,10))\n\n    mapped.dropna().plot(column=to_be_mapped, cmap='Blues', linewidth=0.8,legend=True, ax=ax, \n                         edgecolors='0.8', legend_kwds={'shrink': 0.5})\n\n    ax.set_title(title, fontdict={'fontsize':20})","545091ab":"plot_on_worldmap(df, 'Ladder score', 'Happiness Index')","e463ddd5":"# The most and least happy country\n# df.sort_values sorts the numeric values in ascending oreder\n# If 'ignore_index'=False, the original index of the dataframe won't change after sorting\n\nleat_happy_country=df.sort_values(by='Ladder score', ignore_index=True)['Country name'].iloc[0]\nmost_happy_country=df.sort_values(by='Ladder score', ignore_index=True)['Country name'].iloc[-1]\n\nprint(f'The most happy country is {most_happy_country}, and the least happy country is {leat_happy_country}')","2e64b52d":"from sklearn.ensemble import RandomForestRegressor\n\ny=df['Ladder score']\n\ncol_to_consider=['Explained by: Log GDP per capita', 'Explained by: Social support',\n       'Explained by: Healthy life expectancy',\n       'Explained by: Freedom to make life choices',\n       'Explained by: Generosity', 'Explained by: Perceptions of corruption',\n       'Dystopia + residual']\n\nX= df[col_to_consider]","b50b96c0":"prior_col=['Logged GDP per capita', 'Social support', 'Healthy life expectancy',\n       'Freedom to make life choices', 'Generosity',\n       'Perceptions of corruption', 'Ladder score in Dystopia']\n\nfig, ax=plt.subplots(2,4, figsize=(10,8))\nfor prior_col, after_col, axis in zip(prior_col, col_to_consider, ax.ravel()):\n    sns.scatterplot(x=prior_col, y=after_col, data=df, ax=axis)\n\nplt.tight_layout()","225d2d0e":"# n_estimators - Number of trees to build\n# max_depth - maximum depth to which tree can grow, if we increase it very much then, model can overfit\n# min_samples_leaf - minimum number of samples a leaf can have\n# min_samples_split - minimum number of samples a node should have to further split\n\nrandom_forest= RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=20, min_samples_split=40).fit(X,y)","a69d23d3":"# Getting the feature importance\nfeature_importances_=random_forest.feature_importances_\nfeature_importances=pd.DataFrame({'Feature_name':col_to_consider, 'Feature_importance':feature_importances_})\n\nfig, ax=plt.subplots(1, figsize=(15,8))\nsns.barplot(x='Feature_name', y='Feature_importance', data=feature_importances, ax=ax)\n\n# For making the graph look good\nplt.xticks(fontsize=12, rotation=30); # Rotating the names by 30 degrees as the names were mixing with each other \nplt.yticks(fontsize=14);\n\nplt.xlabel('Feature name',fontsize=18)\nplt.ylabel('Feature importance',fontsize=18)","96b73eda":"# Happy Vs Unhappy Countries\nthresold=df['Ladder score'].mean() # Above the thresold all the countries are happy, you can choose other value of thresold also\n\ndf['Happy_Unhappy']=df['Ladder score'].apply(lambda x: 1 if x>=thresold else 0)\n\nplot_on_worldmap(df, 'Happy_Unhappy', 'Happy and Unhappy Countries')","6e43ddb5":"# Let's see how Happy and Unhappy contries varies based on varies parameters\n# 0 =>Unhappy (Blue), 1 =>Happy (Orange)\n# x_vars- variables on x-axis, and same for y_vars, hue=> column of your interest\nax=sns.pairplot(x_vars=col_to_consider, y_vars=col_to_consider, hue='Happy_Unhappy', data=df, height=3)\n\n# use plt.savefig ('fignure_name.png') for saving the image","70198126":"sns.lmplot(x='Ladder score', y='Logged GDP per capita', data=df)","31d2555f":"# 1. using 'hue'\nsns.lmplot(x='Ladder score', y='Logged GDP per capita', data=df, hue='Happy_Unhappy')","f30c3711":"# 2. using 'col'\nsns.lmplot(x='Ladder score', y='Logged GDP per capita', data=df, col='Happy_Unhappy')","7f400fd8":"kinds=['strip','violin','boxen','point','box','swarm']\n\nfor kind in kinds:\n    #By changing the 'kind', you can have various type of plots\n    ax=sns.catplot(y='Logged GDP per capita', x='Happy_Unhappy', data=df, kind=kind)\n    ax.fig.suptitle(f'{kind} plot')","a7888d9c":"# Importing Plotly\nimport plotly.express as px","b6e1e605":"# color => exactly like 'hue' in seaborn\n# hover_name => shows the name related to the data point, when mouse is hovered over it\n\nfig1=px.scatter(data_frame=df,x='Ladder score', y='Logged GDP per capita', color='Happy_Unhappy', hover_name='Country name')\nfig1.update_layout(title=dict(text='Happiness Index Vs GDP per capita', xanchor='center', yanchor='top', x=0.5))\nfig1.show()","c2349657":"# Adding Continent to df\ncontient_country=world[['name','continent']]\ncontient_country.columns=['Country name', 'Continent']\ndf=df.merge(contient_country, on='Country name')","3af02f6b":"fig2=px.sunburst(data_frame=df, path=['Continent','Country name'], values='Ladder score')\nfig2.update_layout(title=dict(text='Happiness Index across Contients and Contries', xanchor='center', yanchor='top', x=0.5))\nfig2.show()","274ce006":"df3=df.groupby(['Continent', 'Country name']).mean(['Logged GDP per capita']).reset_index()\n\nfig3=px.bar(data_frame=df3, x='Continent', y='Logged GDP per capita', \n            color='Happy_Unhappy', hover_name='Country name', color_continuous_scale='burg')\nfig3.update_layout(title=dict(text='GDP per capita across Continents', xanchor='center', yanchor='top', x=0.5))\n\nfig3.show()","17da6f3d":"df4=df.groupby(['Continent', 'Country name']).mean(['Healthy life expectancy']).reset_index()\ndf4['World']='World'\n\nfig4=px.treemap(data_frame=df4, path=['World', 'Continent', 'Country name'], values='Healthy life expectancy')\nfig4.update_layout(title=dict(text='Health life expectaancy across Continents', xanchor='center', yanchor='top', x=0.5))\nfig4.show()","44754cfb":"from sklearn.preprocessing import MinMaxScaler # For bringing the values to scale\n\ncol=col_to_consider.copy()\ncol.append('Continent')\n\n# Creating df_continent, having continents and their corresponding mean values of all columns\ndf_continent=df[col].groupby(['Continent']).mean().reset_index()\n\n# Scaling the values, to make them into one scale for easy comparison\nscalar=MinMaxScaler()\ndf_continent[col_to_consider]=scalar.fit_transform(df_continent[col_to_consider])","57a0ce98":"import plotly.graph_objects as go\n\n# Plotting the comparative Polar plot for continent1 and continent2\ndef plot_polar(continent1,continent2):\n    \n    theta=df_continent.columns[1:]\n    r1= df_continent[df_continent['Continent']==continent1].iloc[:,1:].values.flatten().tolist()\n    r2= df_continent[df_continent['Continent']==continent2].iloc[:,1:].values.flatten().tolist()\n\n    graph1=go.Scatterpolar(r = r1,theta = theta,fill = 'toself',name=continent1)\n    graph2=go.Scatterpolar(r = r2,theta = theta,fill = 'toself',name=continent2)\n    \n    data = [graph1, graph2]\n    fig = go.Figure(data = data)\n    fig.update_layout(title=dict(text='Continent comparison', xanchor='center', yanchor='top', x=0.5))\n    fig.show()","266a899b":"plot_polar('Africa','Asia')","0254f18a":"plot_polar('Europe','Asia')","0f25ec48":"df1.head()","feec2c0e":"# Replacing the misspelled country names in 'df' as per 'world', you can do it the other way also.\ndf1['Country name'] = df1['Country name'].replace({'United States' : 'United States of America',\n                                          'Taiwan Province of China':'Taiwan',\n                                          'Bosnia and Herzegovina':'Bosnia and Herz.',\n                                          'Dominican Republic':'Dominican Rep.',\n                                          'North Cyprus':'N. Cyprus',\n                                          'Swaziland':'Switzerland'})","01174ec3":"# GDP per capita across countries\ndf_choropleth=df1.groupby(['Country name','year']).mean(['Log GDP per capita']).reset_index()\n\nfig = px.choropleth(data_frame=df_choropleth, locations='Country name',locationmode=\"country names\", \n                    color='Log GDP per capita', projection='orthographic', \n                    color_continuous_scale=[(0, \"red\"), (0.5, \"white\"), (1, \"blue\")])\n\nfig.update_layout(title=dict(text='GDP per capita across countries', xanchor='center', yanchor='top', x=0.47))\nfig.show()","b89ca1b9":"category_order=[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\ndf_choropleth=df1.groupby(['year','Country name']).mean(['Log GDP per capita']).reset_index()\n\nfig = px.choropleth(data_frame=df_choropleth, locations='Country name',locationmode=\"country names\", \n                    color='Log GDP per capita',animation_frame='year',\n                    color_continuous_scale=[(0, \"red\"), (0.5, \"white\"), (1, \"blue\")])\n\nfig.update_layout(title=dict(text='GDP per capita across countries from 2005 to 2020', xanchor='center', yanchor='top', x=0.47))\nfig.show()","df665e05":"# 1. Data Cleaning","4007617e":"## 2. Sunburst plot","24cb6e11":"## Catplot - One numeric and One categorical variable\n\n#### Catplot has many types (kinds) of plotting the data - stripplot, violinplot, boxenplot, pointplot, boxplot, swarmplot","103b887d":"#### If you are new to data science, let me tell you that, most of the time your data is not clean and all data scientists have to do this dirty work of cleaning it first. EDA is like taking pictures in various directions, so to look good in photos you have to clean yourself, were some good clothes, set your hair, etc., and the same thing we are doing with our data. If you want correct and appropriate visuals, you have to clean your data.\n\n#### Data may have missing values, wrong data types, outliers, etc. So, before you do EDA on your data, please check for these things and if they are present, you have to clean the data before moving further otherwise you can get misleading and incorrect visuals. So let's fold the sleeves and get ready for cleaning!","4e5cfe72":"#### We have many factors like GDP, Social support, Health, Freedom, Corruption, Dystopia, and Generosity for deciding how happy a country is. Now let's find which factor influence more to the happiness index. Before you go further, what do you feel is most important for happiness? Please comment below, I am curious to know what you think!\n\n#### For this purpose, we will make a Machine Learning model and using the [feature importance](https:\/\/scikit-learn.org\/stable\/auto_examples\/ensemble\/plot_forest_importances.html), we can know which factor is most important for happiness.","46b33ca9":"#### Everything looks fine here as all numeric values are 'float' and strings are 'object', so let's proceed for further steps. But if your data have incorrect data types you can use [df.astype()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.astype.html) for changing the data types.","27aeb9b0":"#### The North and the South America, Austrilia and west Europian countris are very happy! While Asians and Africans are not much happy. ","5ef9068b":"### 1. Scatterplot","85b8716c":"#### Tip:\n#### Use 'pairplot' for getting a detailed view of the data.\n#### If both columns are numeric => relplot, regplot, lmplot.\n#### If both columns are categorical or one categorical and one numeric => catplot, barplot, countplot.","0667e261":"## 3. Barplot","3cd2b37d":"#### As there are no missing values in our data we shall proceed with further steps, but if your data have some missing values you can either remove them by using [df.dropna](http:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.dropna.html) or substitute the missing values with mean or mode with [df.fillna](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.fillna.html) . Some models can give you an error if missing values are present and some will show incorrect results, so it is important to remove them.","cac72217":" **PLEASE UPVOTE GUYS AND RECOMMEND THAT SHOULD IMPLEMENT**","a99aa890":"## EDA using Plotly\n\n#### Unlike seaborn and matplotlib, were you can't interact with the plots easily, this can be easily done with Plotly. It is a open source library and widly used for vivalizations and interactive plots. I am covering basic plots in Plotly, for more deatails you can go through [Plotly documentation](https:\/\/plotly.com\/python\/). ","2e6498da":"#### This was the brief for doing EDA. I have just scrached the surface, there are many parameters in each type of plot which you can explore. I highly recommend you, if you are biginner to Data Science to go through the [seaborn library tutorial](https:\/\/seaborn.pydata.org\/tutorial.html) as it is widly used and user friendly library, also you can go through [plotly library](https:\/\/plotly.com\/python\/) for interactive plots. At any point of time, you will surely come accross, plotting the data and if you know this then you will be ahead of others.\n\n#### Hope you find this helpful, if you like this notebook don't forget to upvote!","535e9da8":"#### You might be wondering why I am using the Random Forest algorithm and why I am using 'Explained by:' columns for building the ML model, not other columns. The answer to the first question is that Random Forest comes with ready use 'feature importance' method. You can also use [XGBoost](https:\/\/stackoverflow.com\/questions\/37627923\/how-to-get-feature-importance-in-xgboost) and [Catboost](https:\/\/catboost.ai\/docs\/concepts\/python-reference_catboost_get_feature_importance.html) for this purpose, but Random Forest takes a little less time in training, I am using that.\n#### For the second question, you can use prior columns also, as they are the same as 'Explained by:' columns. Let me show you,","e6e7c2df":"#### Now, if you want to add a new dimention to this, it can be done in two ways - \n#### 1. hue (Uses same image for displaying the 3rd dimention)\n#### 2. col or row (Uses multiple rows or columns for displaying the 3rd dimention)\n\n#### Caution: The new dimention column should be categorical. If you want to do this with numeric column, you have to first convert it into a categorical one by using [pd.cut](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.cut.html)","afc66b12":"#### We are using geopandas for displaying happiness index, as it gives feel about which place of the world is how much happy at one glace. It is used for working with geospatial data. To dive deep, you go through this: [Geopandas](https:\/\/geopandas.org\/). \n\n#### Don't worry more about the geopandas for now, the code is simple and you can very well use it for your dataset.","92de7736":"# 2. EDA + ML","0e7c8102":"# Introduction\n\n#### This notebook is especially more useful for beginners in Data Science. It gives step by step guide for EDA, after reading this notebook, I am sure you will be more comfortable in EDA and you will be able to present your data with better visuals. You can apply the methods mentioned in this notebook to any dataset.\n\n#### I have divided the notebook into 2 major parts:\n\n#### 1. Data Cleaning\n#### 2. Exploratory Data Analysis (EDA)","dbe25cae":"## EDA using Seaborn","3f1dd4f3":"#### The column 'geometry' is having cordinates for the bounding box for each country. One of them is plotted below.","0040c811":"#### You can use any of these, whichever you like. Everyone has a unique purpose, you can go through this for more details: [Catplot](https:\/\/seaborn.pydata.org\/generated\/seaborn.catplot.html)","6dd50ebd":"## 4. Treemap","0a68fd5b":"#### For identifying the outliers from numeric columns and understand the spread of the data, we will use a box plot which is commonly used.\n\n![box plot](https:\/\/miro.medium.com\/max\/18000\/1*2c21SkzJMf3frPXPAR_gZA.png)","5972ecc0":"#### Now will do EDA using [seaborn](https:\/\/seaborn.pydata.org\/) library. If you don't have any idea, about which plots will be suitable for you data, and how to express of the columns quickly, you can use [pairplot](https:\/\/seaborn.pydata.org\/generated\/seaborn.pairplot.html) in seaborn.","ab35ec9d":"#### Wow! Did you get it right? To be honest, I thought 'Freedom to make choices' would have more influence on the Happiness index. \n\n#### Let's do some further exploration","9af57dd4":"#### There are many box plots where the values are more than 75 percentile and less than 25 percentile. The data can vary greatly with each country so these values may not be considered outliers. The data is an outlier or not is the decision of the field expert. We can also tell for some of the data like 'age' - it can't be more than 100 or less than 0, etc. but in this case, I am not removing these values as some countries  may actually have such abnormal stats.\n\n#### Data cleaning part is over, now let's move to EDA, which you will be eager to do. I want to mention that, as this data was already clean, we didn't face any problem and this part is done quickly, but this won't be the same for other datasets. So, if you are working hard for cleaning your data, don't get frustrated and be patient. ","1786ec52":"#### North America is a happy continent as most of the countries have a very high happiness index, while overall Africa's continent doesn't seem to be happy.\n\n#### Now we got an idea of how the happiness index varies with countries and continents, let's explore more!","5033ab63":"## regplot, relplot and lmplot - Both numeric variables\n\n#### All the 3 [regplot](https:\/\/seaborn.pydata.org\/generated\/seaborn.regplot.html), [relplot](https:\/\/seaborn.pydata.org\/generated\/seaborn.relplot.html) and [lmplot](https:\/\/seaborn.pydata.org\/generated\/seaborn.lmplot.html) can be used when both of your variables are numeric. I will show you the basic of 'lmplot', once you practice and become confident using lmplot, you will find that other 2 are just piece of cake!","d0a33741":"#### I am not scaling the data, as it is not required for Random Forest (to know more, click [here](https:\/\/stackoverflow.com\/questions\/8961586\/do-i-need-to-normalize-or-scale-data-for-randomforest-r-package#:~:text=No%2C%20scaling%20is%20not%20necessary,%2C%20aren't%20so%20important.)). Also, I am not splitting the data into train and test, because the focus is to find the important features contributing to happiness and not predicting happiness from given features. ","d52c457e":"#### The prior columns and 'Explained by:' columns are correlated (except for the Dystopia), the 'Explained by:' columns are just scaled and nothing else. So, the ML model will give similar results whether you feed it prior columns or 'Explained by:' columns.","3b539721":"## 5. Polar plot"}}