{"cell_type":{"26cdf69f":"code","0b175033":"code","c3e1cc07":"code","fdb2470a":"code","7e62547f":"code","4d6ede47":"code","7931cba4":"code","48ebdc04":"code","404aa150":"code","30a3941f":"code","619add84":"code","e4fbd2af":"code","a10ffe31":"code","f8c1357e":"code","4ec80425":"code","63229313":"code","47c67a29":"code","c6bddc81":"markdown","585b09ef":"markdown","a975f225":"markdown","1bc9ce5d":"markdown","89c1035e":"markdown","b4d84c0f":"markdown","0512b829":"markdown","ea01af6e":"markdown","64ef06d3":"markdown","5a48ed02":"markdown","a306c4f5":"markdown","ebdf1a86":"markdown","e9f8f7a6":"markdown","2de34f9b":"markdown","a33fd2d6":"markdown"},"source":{"26cdf69f":"###################\n# Import packages #\n###################\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\npd.options.display.max_rows\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","0b175033":"########################\n# Read the input files #\n########################\n# Use the pandas library to read the csv file.\ndf = pd.read_csv(\"\/kaggle\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n# Print the first few rows\ndf.head()","c3e1cc07":"# TODO: list columns and values","fdb2470a":"# TODO: Fix datatype of TotalCharges\n\n\n# TODO: Fix datatype of SeniorCitizen and replace values\n\n\n# TODO: Drop the column customerID (Hint: add errors=\"ignore\" to allow this statement to run multiple times)\n","7e62547f":"for col in ['SeniorCitizen', 'TotalCharges']:\n    # TODO: print type and values\n    pass","4d6ede47":"# TODO: Render cotinuous variables. Hint: There is a single pandas function that does exactly this.\n","7931cba4":"# TODO: Show the pairwise correlation. Hint: There is a single pandas function that does exactly this.\n","48ebdc04":"# TODO: Create a visualization for the pairwise correlation between all continuous variables. (Hint: check out seaborn pairplots)\n","404aa150":"# TODO discretize \"tenure\", \"MonthlyCharges\" and \"TotalCharges\" in 10 equal width bins\n# df['tenure-bin'] = \n# df['MonthlyCharges-bin'] = \n# df['TotalCharges-bin'] = \n\nfor col in ['tenure-bin', 'MonthlyCharges-bin', 'TotalCharges-bin']:\n    print(col)\n    # TODO inspect the frequency of each bucket.\n    ","30a3941f":"df.groupby(['Churn', 'gender']).size().unstack(fill_value=0).plot.bar()","619add84":"# TODO: Plot two more interesting variables together with churn.\nprint(\"=========== My 1st example ===========\")\n# TODO: Plot\n\n# TODO: Explain why\nprint(\"Is interesting because\", \"TODO\")","e4fbd2af":"print(\"=========== My 2nd example ===========\")\n# TODO: Plot\n\n# TODO: Explain why\nprint(\"Is interesting because\", \"TODO\")","a10ffe31":"def dataframeToTransactions(df):\n    \"\"\" Converts a Pandas dataframe to a list of transactions \"\"\"\n    rows = df.to_dict(orient=\"records\")\n    data = [tuple(f\"{k}={v}\" for k, v in row.items()) for row in rows]\n    return data\n\ntransactions = dataframeToTransactions(df)\n[\", \".join(t) for t in transactions[:5]]","f8c1357e":"from collections import defaultdict\n\ndef transactionsToTidlist(transactions):\n    \"\"\" Converts transactions matrix to tidlist.\n        Return: List of the form [(item1, {tids1}), (item2, {tids2})]\n        (Hint: Store them in a dict d (item -> set) and return list(d.items()) \n    \"\"\"\n    # TODO: Implement\n    return []\n\n# DEBUG CODE\ntidlist = transactionsToTidlist(transactions)\nfor item, tids in tidlist[:10]:\n    print(item, len(tids))\n     \n# == Expected Output ==\n# gender=Female 3488\n# SeniorCitizen=No 5901\n# Partner=Yes 3402\n# Dependents=No 4933\n# tenure=1 613\n# PhoneService=No 682\n# MultipleLines=No phone service 682\n# InternetService=DSL 2421\n# OnlineSecurity=No 3498\n# OnlineBackup=Yes 2429","4ec80425":"def eclat(df, minsup):\n    transactions = dataframeToTransactions(df)\n    tidlist = transactionsToTidlist(transactions)\n    return _eclat([], tidlist, minsup)\n    \n    \ndef _eclat(prefix, tidlist, minsup):\n    \"\"\" Implement the Eclat algorithm recursively.\n        prefix: items in this depth first branch (the set alpha).\n        tidlist: tids of alpha-conditional db.\n        minsup: minimum support.\n        return: list of itemsets with support >= minsup. Format: [({item1, item2}, supp1), ({item1}, supp2)]\n    \"\"\"\n    # TODO: Implement\n    return []\n\n# DEBUG CODE\n# Reference implementation takes at most 10 seconds to compute the following\nitemsets = eclat(df, 800)\nprint(\"Itemsets:\", len(itemsets))\nsorted(itemsets, key=lambda x: x[1], reverse=True)[:10]\n\n# == Expected Output (or similar) ==\n# Itemsets: 18427\n# [({'PhoneService=Yes'}, 6361),\n#  ({'SeniorCitizen=No'}, 5901),\n#  ({'PhoneService=Yes', 'SeniorCitizen=No'}, 5323),\n#  ({'Churn=No'}, 5174),\n#  ({'Dependents=No'}, 4933),\n#  ({'Churn=No', 'PhoneService=Yes'}, 4662),\n#  ({'Churn=No', 'SeniorCitizen=No'}, 4508),\n#  ({'Dependents=No', 'PhoneService=Yes'}, 4457),\n#  ({'PaperlessBilling=Yes'}, 4171),\n#  ({'Churn=No', 'PhoneService=Yes', 'SeniorCitizen=No'}, 4056)]","63229313":"from itertools import chain, combinations\n\ndef subsets(itemset):\n    \"\"\" List all strict subsets of an itemset without the empty set\n        subsets({1,2,3}) --> [{1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}]\n    \"\"\"\n    s = list(itemset)\n    return map(set, chain.from_iterable(combinations(s, r) for r in range(1, len(s))))\n\ndef deriveRules(itemsets, minconf):\n    \"\"\" Returns all rules with conf >= minconf that can be derived from the itemsets.\n        Return: list of association rules in the format: [(antecedent, consequent, supp, conf), ...]  where antecedent and consequent are itemsets.\n    \"\"\"\n    # TODO implement\n    return []\n        \n\n# DEBUG CODE\nrules = deriveRules(itemsets, 0.9)\nprint(\"Rules:\", len(rules))\nsorted(rules, key=lambda x: x[3], reverse=True)[:5]\n\n# == Expected Output (or similar) ==\n# Rules: 747880\n# [({'MonthlyCharges-bin=(78.55, 88.6]'}, {'PhoneService=Yes'}, 953, 1.0),\n#  ({'InternetService=Fiber optic', 'SeniorCitizen=Yes'},\n#   {'PhoneService=Yes'},\n#   831,\n#   1.0),\n#  ({'StreamingMovies=No internet service'},\n#   {'MonthlyCharges-bin=(18.15, 28.3]'},\n#   1526,\n#   1.0),\n#  ({'StreamingMovies=No internet service'},\n#   {'MonthlyCharges-bin=(18.15, 28.3]', 'StreamingTV=No internet service'},\n#   1526,\n#   1.0),\n#  ({'StreamingTV=No internet service'},\n#   {'MonthlyCharges-bin=(18.15, 28.3]', 'StreamingMovies=No internet service'},\n#   1526,\n#   1.0)]","47c67a29":"# TODO: Create a subset of the data\n\n\n# TODO: Mine itemsets and association rules (find a good minsup and minconf value yourself)\n\n\n# The rules inside a DataFrame\nrulesFrame = pd.DataFrame(rules, columns=['Antecedent', 'Consequent', 'Supp', 'Conf'])\n\n# TODO: Filter rulesFrame to only show rows with \"Churn=Yes\" as consequent\n","c6bddc81":"### Task 3: Visualization (0.25pt)\nThere are better ways to visualize continuous variables. Render a plot for each continuous column that shows its distribution.","585b09ef":"### Task 1: Frequent Itemsets (2.5pt)\nImplement the eclat algorithm in the template below (fill in TODOs).","a975f225":"### Task 6: Categorical Correlation (1.5pt)\nGender obviously has no influence on churn rate. Find at least two variables that do have a higher correlation with Churn. Plot them together as shown and explain why you think they are interesting.","1bc9ce5d":"### Task 2: Association Rules (1.5pt)\nDerive association rules from itemsets.","89c1035e":"# Assignment 6: FPM\n\n### Instructions\n\n 1. To get started on this assignment, first fork this Notebook by clicking \"Copy and Edit\" in the top right corner. You should be presented with a personal version of the assignment that you can work in. Make sure that the visibility of your Notebook is set to private!\n 2. Make sure you can run the first two code blocks (import and df.head()). If so, you're all set to start the assignment, good luck!\n ","b4d84c0f":"### Task 3: Inspect Patterns (2pt)\nIt is clear that classical frequent pattern mining with so many columns leads to too many itemsets and association rules. Select a subset of the columns that you think is interesting and mine patterns on that subset. Then put the resulting association rules in a dataframe and filter it so only the ones with \"Churn=Yes\" in the consequent remain. Pick one pattern and describe what it means and why you think it is interesting.\n","0512b829":" > Feedback here","ea01af6e":"### Task 5: Discretize Continuous Columns (0.5pt)\nThere are still some issues in the dataset with respect to pattern mining. Continuous variables often cannot form patterns because their exact values simply don't occur often enough to meet the minsup threshold. We need to group them together first if we want to use them in pattern mining.\n\n\nApply a discretization for the columns \"tenure\", \"MonthlyCharges\" and \"TotalCharges\". Divide them in 10 buckets\/bins of equal width. Then inspect the amount of times each value occurs.","64ef06d3":"Describe one of the patterns in the table above and explain why it is interesting:\n> Your answer","5a48ed02":"## 1. Data Exploration and Preprocessing (4pt)","a306c4f5":"## 4. Feedback (0pt)\nOptionally include feedback on the assignment, specifically remarks on the workload, difficulty and relevance of the assignment. Suggestions on how to improve it towards next year are also welcome. Naturally what you write here will not affect your grades in any way.\n","ebdf1a86":"### Task 2: Clean up (1pt)\nYou should see that there's something wrong with the columns \"SeniorCitizen\" and \"TotalCharges\". We want the first one to be of type 'object' with values \"Yes\" and \"No\". The latter column should be a 'float' type, but since it also contains empty values (empty or spaces), you will first need to convert those to `np.nan`. Furthermore the column \"customerID\" is not required and can be dropped from the dataframe. \n\n\nClean up the data as described above. Then print their type and values again.","e9f8f7a6":"### Task 4: Correlation (0.25pt)\n 1. Inspect the pairwise correlation between these variables (pearson).\n 2. Create a plot to show the correlation.","2de34f9b":"## 2. Frequent Pattern Mining (6pt)\nFor this part you will implement the Eclat algorithm and perform frequent pattern mining on the dataset. Then you can derive association rules from the itemsets and look for interesting patterns. ","a33fd2d6":"### Task 1: Overview (0.5pt)\nPrint the columns in the dataset with their type and [unique](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.unique.html) values (without duplicates)."}}