{"cell_type":{"cc0f9476":"code","2e991bab":"code","7e911244":"code","597f2868":"code","f5dbf612":"code","8e19794f":"code","d4da2262":"code","22a46dd2":"code","c123d795":"code","f5f0a396":"code","1f819f88":"code","6cffa3d6":"code","c30d66af":"code","a5f90f0b":"code","f953151e":"code","6c7831bb":"code","38a46110":"code","249e92e5":"code","56a71be0":"code","433ac2d6":"code","5a6b7443":"markdown","06aa1bd9":"markdown","00d8ed7d":"markdown","abc32a16":"markdown","47734268":"markdown","48c8065e":"markdown","e8142cf6":"markdown","f97050bd":"markdown","77addd6f":"markdown","ef8b8b4e":"markdown","b323f34c":"markdown","d53b4fbc":"markdown","26907d79":"markdown","1944fef8":"markdown","7b5af1a1":"markdown","55a07ef6":"markdown","8a098b2d":"markdown","a4ef70dd":"markdown","fefd4a08":"markdown","12f415d9":"markdown","1bcb0d9c":"markdown","78a4e01f":"markdown","f6a65a8c":"markdown"},"source":{"cc0f9476":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ndf=pd.read_csv('\/kaggle\/input\/real-estate-price-prediction\/Real estate.csv')\ndf.head()","2e991bab":"df.info()\ndf.shape","7e911244":"\ndf.drop('No',axis=1,inplace=True)","597f2868":"sns.pairplot(df)","f5dbf612":"sns.distplot(df['Y house price of unit area'])","8e19794f":"df.corr()","d4da2262":"sns.heatmap(df.corr(), annot=True,cmap='Greens')","22a46dd2":"df.head()\nX=df.drop('Y house price of unit area',axis=1)\ny=df['Y house price of unit area']\nX","c123d795":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\nprint(X_train)\nprint(X_test)\nprint(y_train)\nprint(y_test)","f5f0a396":"X_train.shape\n\n","1f819f88":"X_test.shape","6cffa3d6":"from sklearn.linear_model import LinearRegression\nmodel= LinearRegression()     #create the model\nmodel.fit(X_train, y_train)  # Apply created model on train data to learn how to predict target","c30d66af":"pd.DataFrame(model.coef_, X.columns, columns=['Coeficient'])","a5f90f0b":"y_pred=model.predict(X_test)    \n","f953151e":"from sklearn import metrics\nMAE= metrics.mean_absolute_error(y_test, y_pred)  #input : diffrent between real y and predicted y \nMSE= metrics.mean_squared_error(y_test, y_pred)\nRMSE=np.sqrt(MSE)\n\npd.DataFrame([MAE, MSE, RMSE], index=['MAE', 'MSE', 'RMSE'], columns=['Metrics'])","6c7831bb":"df['Y house price of unit area'].mean()","38a46110":"test_residuals=y_test-y_pred\ntest_residuals.head()\n","249e92e5":"\nsns.scatterplot(x=y_test, y=y_pred)\nplt.xlabel('Y-Test')\nplt.ylabel('Y-Pred')","56a71be0":"sns.scatterplot(x=y_test, y=test_residuals)\nplt.axhline(y=0, color='g', ls='-')","433ac2d6":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_converter=PolynomialFeatures(degree=2, include_bias=False)","5a6b7443":"# Define test  and train","06aa1bd9":"A **coefficient** refers to a number or quantity placed with a variable. It is usually an integer that is multiplied by the variable next to it. The variables which do not have a number with them are assumed to be having 1 as their coefficient. For example, in the expression 3x, 3 is the coefficient but in the expression x2 + 3, 1 is the coefficient of x2. In other words, a coefficient is a multiplicative factor in the terms of a polynomial, a series, or any expression. It is generally a number. Observe the following expression which shows that 5 is the coefficient of x2 and 8 is the coefficient of y.","00d8ed7d":"# Train the model(linear regretion):","abc32a16":"-----------------------------------------------------------------------------------------------------","47734268":"# Import necessary libraries and read dataset and  draw the visualization plots\n# Define X(features) and y (target) , Determine the Features & Target Variable (same as linear regession analyze)","48c8065e":"There are 3 main metrics for model evaluation in regression:\n1. R Square\/Adjusted R Square\n2. Mean Square Error(MSE)\/Root Mean Square Error(RMSE)\n3. Mean Absolute Error(MAE)\nR Square\/Adjusted R Square\nR Square measures how much variability in dependent variable can be explained by the model. It is the square of the Correlation Coefficient(R) and that is why it is called R Square.\n\nR square formula\nR Square is calculated by the sum of squared of prediction error divided by the total sum of the square which replaces the calculated prediction with mean. R Square value is between 0 to 1 and a bigger value indicates a better fit between prediction and actual value.\nR Square is a good measure to determine how well the model fits the dependent variables. However, it does not take into consideration of overfitting problem. If your regression model has many independent variables, because the model is too complicated, it may fit very well to the training data but performs badly for testing data. That is why Adjusted R Square is introduced because it will penalize additional independent variables added to the model and adjust the metric to prevent overfitting issues.","e8142cf6":"# Linear Regression\n Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.\nBefore attempting to fit a linear model to observed data, a modeler should first determine whether or not there is a relationship between the variables of interest. This does not necessarily imply that one variable causes the other (for example, higher SAT scores do not cause higher college grades), but that there is some significant association between the two variables. A scatterplot can be a helpful tool in determining the strength of the relationship between two variables. If there appears to be no association between the proposed explanatory and dependent variables (i.e., the scatterplot does not indicate any increasing or decreasing trends), then fitting a linear regression model to the data probably will not provide a useful model. A valuable numerical measure of association between two variables is the correlation coefficient, which is a value between -1 and 1 indicating the strength of the association of the observed data for the two variables.","f97050bd":"![image.png](attachment:3fbc7eef-d010-4ac5-973f-5f107c6a6a3e.png)","77addd6f":"> there is no pattern between residuals and it shows that they are random. ","ef8b8b4e":"**select the model and apply on train data**","b323f34c":"# Drop unuseful columns","d53b4fbc":"# Exploratory Data Analysis","26907d79":"289+125=414 (all rows)\n70% (189\/414) of data are in train set and 30%  (125\/414) of them are in test set","1944fef8":"# Evaluating the model","7b5af1a1":"# Preprocessing for polynomial regresion","55a07ef6":"# Analyza the Dataset with polynomial regression\n","8a098b2d":"# What is Polynomial Regression?\nPolynomial regression is a special case of linear regression where we fit a polynomial equation on the data with a curvilinear relationship between the target variable and the independent variables.\n\nIn a curvilinear relationship, the value of the target variable changes in a non-uniform manner with respect to the predictor (s).\n\nIn Linear Regression, with a single predictor, we have the following equation:\n\nlinear regression equation","a4ef70dd":"# About Data set:\nNumber of rows:414\n\nNumber of columns:8\n\nsubject: house pricing\n","fefd4a08":"# Define the Features & Target ","12f415d9":"# calculate the residual","1bcb0d9c":"# Predicting Target","78a4e01f":"# show the corrolation between features","f6a65a8c":"# Import necessary libraries and read dataset"}}