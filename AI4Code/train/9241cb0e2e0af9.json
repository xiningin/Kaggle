{"cell_type":{"f031b91f":"code","f9a79e67":"code","b063660e":"code","d59ff09c":"code","68e0b35d":"code","3e3f318a":"code","a7565a0e":"code","d260a0d3":"code","d759eb8f":"code","eca91aa3":"code","b1336136":"code","7679f1cd":"code","84d728d2":"code","feb2220d":"code","8d6f7263":"code","abeea251":"code","a160658d":"code","5172550d":"code","07a88df9":"code","abe35bb3":"code","ba890801":"code","580b6be0":"code","71ee734b":"code","bc519462":"code","62d8f406":"code","9e31705d":"code","1170e2a5":"code","b1a11963":"code","447d358d":"code","cd4dc4c2":"code","db76a0e1":"code","57e6b6f5":"code","657bde9e":"code","b6a62def":"code","5fc48ada":"code","0110c4d6":"code","dfccc2f0":"code","74b37687":"code","65f932b3":"code","c2860ccc":"markdown","f1dbe6ee":"markdown"},"source":{"f031b91f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f9a79e67":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections","b063660e":"# Other Libraries\nfrom imblearn.datasets import fetch_datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n","d59ff09c":"df = pd.read_csv('..\/input\/creditcard.csv')\ndf.head()","68e0b35d":"df.describe()","3e3f318a":"df.isnull().sum().max()","a7565a0e":"df.columns","d260a0d3":"# The classes are heavily skewed we need to solve this issue later.\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","d759eb8f":"colors = [\"#0101DF\", \"#DF0101\"]\n\nsns.countplot('Class', data=df, palette=colors)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)","eca91aa3":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\ntime_val = df['Time'].values\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\n\nplt.show()","b1336136":"\nindex = 1\nfor k in range(1, 9):\n    fig, ax = plt.subplots(1, 3, figsize=(18,4))\n\n    for i in range(1, 4):\n        \n        currentFeature = 'V' + str(index)\n\n        feature = df[currentFeature].values\n\n        sns.distplot(feature, ax=ax[i-1], color='r')\n        ax[i-1].set_title('Distribution ' + currentFeature, fontsize=14)\n        ax[i-1].set_xlim([min(feature), max(feature)])\n        index += 1\n    plt.show()\n    ","7679f1cd":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\nfeaturePositiveAmount = df[df.Class == 0]['Amount'].values\nfeatureNegativeAmount = df[df.Class == 1]['Amount'].values\n    \ntime_val = df['Time'].values\nfeaturePositiveTime = df[df.Class == 0]['Time'].values\nfeatureNegativeTime = df[df.Class == 1]['Time'].values\n\nsns.distplot(featurePositiveAmount, ax=ax[0], color='r')\nsns.distplot(featureNegativeAmount, ax=ax[0], color='b')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.distplot(featurePositiveTime, ax=ax[1], color='r')\nsns.distplot(featureNegativeTime, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\n\nplt.show()","84d728d2":"index = 1\nfor k in range(1, 9):\n    fig, ax = plt.subplots(1, 3, figsize=(18,4))\n\n    for i in range(1, 4):\n        \n        currentFeature = 'V' + str(index)\n        feature = df[currentFeature].values\n        featurePositive = df[df.Class == 0][currentFeature].values\n        featureNegative = df[df.Class == 1][currentFeature].values\n\n        sns.distplot(featurePositive, ax=ax[i-1], color='r')\n        sns.distplot(featureNegative, ax=ax[i-1], color='b')\n        ax[i-1].set_title('Distribution ' + currentFeature, fontsize=14)\n        ax[i-1].set_xlim([min(feature), max(feature)])\n        index += 1\n    plt.show()","feb2220d":"# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\n# RobustScaler is less prone to outliers.\n\nstd_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","8d6f7263":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels\n\n\n# Turn into an array\nxtrain = original_Xtrain.values\nxtest = original_Xtest.values\n\nytrain = original_ytrain.values\nytest = original_ytest.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(ytest, return_counts=True)\nprint('-' * 100)\nprint('Label Distributions: \\n')\nprint('-' * 100)\nprint('Train distribution:')\nprint(train_unique_label, train_counts_label )\nprint(train_counts_label\/ len(original_ytrain))\nprint('')\nprint('Test distribution:')\nprint(test_unique_label, test_counts_label)\nprint(test_counts_label\/ len(original_ytest))\nprint('-' * 100)\n\n\n\n","abeea251":"classifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n}","a160658d":"for key, classifier in classifiers.items():\n    classifier.fit(xtrain, ytrain)\n    ypred = classifier.predict(xtest)\n    print(\"Classifiers: \", classifier.__class__.__name__, \" has the following scores\")\n    print('Recall Score: {:.2f}'.format(recall_score(ytest, ypred)))\n    print('Precision Score: {:.2f}'.format(precision_score(ytest, ypred)))\n    print('F1 Score: {:.2f}'.format(f1_score(ytest, ypred)))\n    print('Accuracy Score: {}'.format(accuracy_score(ytest, ypred)))\n    \n    fig, ax = plt.subplots(1, 1,figsize=(22,12))\n        \n\n    cf = confusion_matrix(ytest, ypred)\n\n    sns.heatmap(cf, annot=True, cmap=plt.cm.copper)\n    plt.show()","5172550d":"# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n\n# Lets shuffle the data before creating the subsamples\n\ndf = df.sample(frac=1) # Return a random sample of items from an axis of object.\n\n# amount of fraud classes 492 rows.\nfraud_df_train = df.loc[df['Class'] == 1][0:394]\nnon_fraud_df_train = df.loc[df['Class'] == 0][0:394]\n\nfraud_df_test = df.loc[df['Class'] == 1][394:]\nnon_fraud_df_test = df.loc[df['Class'] == 0][394:394+int(len(df)\/5)]\n\nnormal_distributed_df = pd.concat([fraud_df_train, non_fraud_df_train])\n\n# Shuffle dataframe rows\nnew_df_train = normal_distributed_df.sample(frac=1, random_state=42)\nnew_df_train.head()\n\n\nnormal_distributed_df_test = pd.concat([fraud_df_test, non_fraud_df_test])\n# Shuffle dataframe rows\nnew_df_test = normal_distributed_df_test.sample(frac=1, random_state=42)\nnew_df_test.head()","07a88df9":"print(len(new_df_test))","abe35bb3":"print('Distribution of the Classes in the subsample dataset')\nprint(new_df_train['Class'].value_counts()\/len(new_df_train))\n\n\nsns.countplot('Class', data=new_df_train, palette=colors)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.show()","ba890801":"print('Distribution of the Classes in the subsample testset dataset')\nprint(new_df_test['Class'].value_counts()\/len(new_df_test))\n\n\nsns.countplot('Class', data=new_df_train, palette=colors)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.show()","580b6be0":"Xtrain = new_df_train.drop('Class', axis=1)\nytrain = new_df_train['Class']\n\nXtest = new_df_test.drop('Class', axis=1)\nytest = new_df_test['Class']","71ee734b":"# Turn the values into an array for feeding the classification algorithms.\nXtrain = Xtrain.values\nXtest = Xtest.values\nytrain = ytrain.values\nytest = ytest.values","bc519462":"# Let's implement simple classifiers\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n}","62d8f406":"# Wow our scores are getting even high scores even when applying cross validation.\n\nfor key, classifier in classifiers.items():\n    classifier.fit(Xtrain, ytrain)\n    ypred = classifier.predict(Xtest)\n    print(\"Classifiers: \", classifier.__class__.__name__, \" has the following scores\")\n    print('Recall Score: {:.2f}'.format(recall_score(ytest, ypred)))\n    print('Precision Score: {:.2f}'.format(precision_score(ytest, ypred)))\n    print('F1 Score: {:.2f}'.format(f1_score(ytest, ypred)))\n    print('Accuracy Score: {}'.format(accuracy_score(ytest, ypred)))\n    \n    fig, ax = plt.subplots(1, 1,figsize=(22,12))\n        \n\n    cf = confusion_matrix(ytest, ypred)\n\n    sns.heatmap(cf, annot=True, cmap=plt.cm.copper)\n    plt.show()","9e31705d":"# Use GridSearchCV to find the best parameters.\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Logistic Regression \nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\n\n\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(Xtrain, ytrain)\n# We automatically get the logistic regression with the best parameters.\nlog_reg = grid_log_reg.best_estimator_\nprint(log_reg)\n\nknears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(Xtrain, ytrain)\n# KNears best estimator\nknears_neighbors = grid_knears.best_estimator_\nprint(knears_neighbors)\n\n# Support Vector Classifier\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(Xtrain, ytrain)\n\n# SVC best estimator\nsvc = grid_svc.best_estimator_\nprint(svc)\n\n# DecisionTree Classifier\ntree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(Xtrain, ytrain)\n\n# tree best estimator\ntree_clf = grid_tree.best_estimator_\nprint(tree_clf)\n\ntrainedClassifiers = [log_reg, knears_neighbors, svc, tree_clf]","1170e2a5":"for classifier in trainedClassifiers:\n \n    print(classifier)\n    ypred = classifier.predict(Xtest)\n    \n    print('Recall Score: {:.2f}'.format(recall_score(ytest, ypred)))\n    print('Precision Score: {:.2f}'.format(precision_score(ytest, ypred)))\n    print('F1 Score: {:.2f}'.format(f1_score(ytest, ypred)))\n    print('Accuracy Score: {}'.format(accuracy_score(ytest, ypred)))\n    \n    fig, ax = plt.subplots(1, 1,figsize=(22,12))\n        \n\n    cf = confusion_matrix(ytest, ypred)\n\n    sns.heatmap(cf, annot=True, cmap=plt.cm.copper)\n    plt.show()\n     ","b1a11963":"from imblearn.over_sampling import SMOTE\n \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels\n\n\n# Turn into an array\nxtrain = original_Xtrain.values\nxtest = original_Xtest.values\nytrain = original_ytrain.values\nytest = original_ytest.values","447d358d":"sm = SMOTE(random_state=42, ratio='minority')\nxtrainSmote, ytrainSmote = sm.fit_resample(xtrain, ytrain)","cd4dc4c2":"train_unique_label, train_counts_label = np.unique(ytrainSmote, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(ytest, return_counts=True)\nprint('-' * 100)\nprint('Label Distributions: \\n')\nprint('-' * 100)\nprint('Train distribution:')\nprint(train_unique_label, train_counts_label )\nprint(train_counts_label\/ len(ytrainSmote))\nprint('')\nprint('Test distribution:')\nprint(test_unique_label, test_counts_label)\nprint(test_counts_label\/ len(ytest))\nprint('-' * 100)","db76a0e1":"classifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n}","57e6b6f5":"for key, classifier in classifiers.items():\n    classifier.fit(xtrainSmote, ytrainSmote)\n    ypred = classifier.predict(xtest)\n    print(\"Classifiers: \", classifier.__class__.__name__, \" has the following scores\")\n    print('Recall Score: {:.2f}'.format(recall_score(ytest, ypred)))\n    print('Precision Score: {:.2f}'.format(precision_score(ytest, ypred)))\n    print('F1 Score: {:.2f}'.format(f1_score(ytest, ypred)))\n    print('Accuracy Score: {}'.format(accuracy_score(ytest, ypred)))\n    \n    fig, ax = plt.subplots(1, 1,figsize=(22,12))\n        \n\n    cf = confusion_matrix(ytest, ypred)\n\n    sns.heatmap(cf, annot=True, cmap=plt.cm.copper)\n    plt.show()","657bde9e":"import keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy","b6a62def":"n_inputs = xtrainSmote.shape[1]\n\noversample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(2, activation='softmax')\n])","5fc48ada":"oversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","0110c4d6":"oversample_model.fit(xtrainSmote, ytrainSmote, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)","dfccc2f0":"ypred = oversample_model.predict(xtest, batch_size=200, verbose=0)","74b37687":"ypred = ypred.argmax(axis=1)","65f932b3":"\nprint('Recall Score: {:.2f}'.format(recall_score(ytest, ypred)))\nprint('Precision Score: {:.2f}'.format(precision_score(ytest, ypred)))\nprint('F1 Score: {:.2f}'.format(f1_score(ytest, ypred)))\nprint('Accuracy Score: {}'.format(accuracy_score(ytest, ypred)))\n    \nfig, ax = plt.subplots(1, 1,figsize=(22,12))\n        \n\ncf = confusion_matrix(ytest, ypred)\n\nsns.heatmap(cf, annot=True, cmap=plt.cm.copper)\nplt.show()","c2860ccc":"Oversampling","f1dbe6ee":"**UnderSampling the data**"}}