{"cell_type":{"497369ca":"code","50f481d1":"code","f1c046af":"code","72fdf66b":"code","8d8090b1":"code","1b2e73c0":"code","32197b53":"code","e8b537bc":"code","bc20f1fd":"code","9ece9523":"code","0feb7802":"code","83ca4fec":"code","3e278d73":"code","4ddb830b":"code","278cc344":"code","64202ba0":"code","b102e11f":"code","5d3ace0d":"code","fed7de5b":"code","2a116022":"code","0a4af629":"code","eae1be84":"code","5402f78e":"code","c4426920":"code","0bdb1b88":"code","58aab861":"code","bf248c2b":"code","8c0e1867":"code","1280a68a":"code","8a92e9a1":"code","882740b8":"code","9f009ff2":"code","ad8598b5":"code","97a72d4c":"code","9ec3eff1":"code","52fe7378":"code","efe32bd1":"code","10362c7c":"code","68e9b33f":"code","a6b147ef":"code","ea31e066":"code","ad56f808":"code","186f8855":"code","62275ef0":"code","f1ea2d3b":"code","b94b1bcd":"code","38fb5e9c":"code","fc5bda86":"code","20365885":"code","98f5e68d":"code","2474331a":"code","a99e79f0":"code","373f2d82":"code","b37f56fe":"code","622e6e93":"code","35a079a1":"code","fed229b2":"code","cb37fc07":"code","741f900a":"code","0565a459":"code","32a0c3aa":"code","70104bd9":"code","a1b2b7d2":"code","049c7bf0":"code","efffd8f6":"code","6b24197a":"code","bad76cf5":"code","ccbb984f":"code","f22f7b34":"code","aad8258f":"code","2326fd17":"code","bc1d904c":"code","d3584e17":"code","ca236166":"code","3a983903":"code","8e063d37":"code","d36d2f83":"code","342d848f":"code","e422a052":"code","3d2cc4db":"code","5aefcc37":"code","0401b344":"code","2fd368e5":"code","d8eeca3e":"code","c9865e36":"code","8b1f1f97":"code","110a8d36":"markdown","4687c2a3":"markdown","9ff830cb":"markdown","d0f33027":"markdown","3cefcad0":"markdown","4f773832":"markdown","05d4c457":"markdown","ff21d044":"markdown","1df609c0":"markdown","e3bb9400":"markdown","a72cc361":"markdown","3e8a1ec1":"markdown","915d6499":"markdown","ff3bff35":"markdown","4fe55489":"markdown","955648d4":"markdown","3e139c75":"markdown","18b6debf":"markdown"},"source":{"497369ca":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","50f481d1":"train = pd.read_csv(\"..\/input\/time-series-forecasting\/Train_SU63ISt.csv\")\ntrain.head(5)","f1c046af":"test=pd.read_csv(\"..\/input\/time-series-forecasting\/Test_0qrQsBZ.csv\")\ntest.head()","72fdf66b":"train.shape","8d8090b1":"test.shape","1b2e73c0":"train_original=train.copy() \ntest_original=test.copy()","32197b53":"train.Datetime=pd.to_datetime(train.Datetime, format='%d-%m-%Y %H:%M')\ntrain.index=train.Datetime\ntrain.head(5)","e8b537bc":"train_original.Datetime=pd.to_datetime(train_original.Datetime, format='%d-%m-%Y %H:%M')\ntest_original.Datetime=pd.to_datetime(test_original.Datetime, format='%d-%m-%Y %H:%M')","bc20f1fd":"test.Datetime=pd.to_datetime(test.Datetime, format='%d-%m-%Y %H:%M')\ntest.index=test.Datetime\ntest.head(5)","9ece9523":"for i in (train, test, train_original, test_original):\n    i['year']=i.Datetime.dt.year \n    i['month']=i.Datetime.dt.month \n    i['day']=i.Datetime.dt.day\n    i['Hour']=i.Datetime.dt.hour","0feb7802":"train['day of week']=train['Datetime'].dt.dayofweek \ntemp = train['Datetime']","83ca4fec":"def applyer(row):\n    if row.dayofweek == 5 or row.dayofweek == 6:\n        return 1\n    else:\n        return 0 \ntemp2 = train['Datetime'].apply(applyer) \ntrain['weekend']=temp2","3e278d73":"train.drop(['ID','Datetime'],axis=1,inplace=True)","4ddb830b":"ts = train['Count'] \nplt.figure(figsize=(16,8)) \nplt.plot(ts, label='Passenger Count') \nplt.title('Time Series') \nplt.xlabel(\"Time(year-month)\") \nplt.ylabel(\"Passenger count\") \nplt.legend(loc='best')","278cc344":"train.groupby('year')['Count'].mean().plot.bar()","64202ba0":"train.groupby('month')['Count'].mean().plot.bar()","b102e11f":"temp=train.groupby(['year', 'month'])['Count'].mean() \ntemp.plot(figsize=(15,5), title= 'Passenger Count(Monthwise)', fontsize=14)","5d3ace0d":"train.groupby('day')['Count'].mean().plot.bar()","fed7de5b":"train.groupby('Hour')['Count'].mean().plot.bar()","2a116022":"train.groupby('weekend')['Count'].mean().plot.bar()","0a4af629":"train.groupby('day of week')['Count'].mean().plot.bar()","eae1be84":"# Hourly time series \nhourly = train.resample('H').mean() \n# Converting to daily mean \ndaily = train.resample('D').mean() \n# Converting to weekly mean \nweekly = train.resample('W').mean() \n# Converting to monthly mean \nmonthly = train.resample('M').mean()\n\n# Let\u2019s look at the hourly, daily, weekly and monthly time series.\n\nfig, axs = plt.subplots(4,1) \nhourly.Count.plot(figsize=(15,8), title= 'Hourly', fontsize=14, ax=axs[0]) \ndaily.Count.plot(figsize=(15,8), title= 'Daily', fontsize=14, ax=axs[1]) \nweekly.Count.plot(figsize=(15,8), title= 'Weekly', fontsize=14, ax=axs[2]) \nmonthly.Count.plot(figsize=(15,8), title= 'Monthly', fontsize=14, ax=axs[3]) \n\nplt.show()","5402f78e":"# # Converting to daily mean \n# test = test.resample('D').mean() ","c4426920":"monthly=train.resample('D').mean()","0bdb1b88":"monthly.head()","58aab861":"monthly.shape","bf248c2b":"# train.drop(['year','month','day','Hour','day of week', 'weekend'],axis=1,inplace=True)","8c0e1867":"train.plot(figsize=(20, 4))\nplt.legend(loc='best')\nplt.title('Jetrail traffic on hourly basis')\nplt.show(block=False)","1280a68a":"monthly.plot(figsize=(20, 4))\nplt.legend(loc='best')\nplt.title('Jetrail traffic on monthly basis')\nplt.show(block=False)","8a92e9a1":"import seaborn as sns\nfig = plt.subplots(figsize=(12, 2))\nax = sns.boxplot(x=monthly['Count'],whis=1.5)","882740b8":"fig = monthly.Count.hist(figsize = (12,4))","9f009ff2":"from pylab import rcParams\nimport statsmodels.api as sm\nrcParams['figure.figsize'] = 12, 8\ndecomposition = sm.tsa.seasonal_decompose(monthly.Count, model='additive') # additive seasonal index\nfig = decomposition.plot()\nplt.show()","ad8598b5":"decomposition = sm.tsa.seasonal_decompose(monthly.Count, model='multiplicative') # multiplicative seasonal index\nfig = decomposition.plot()\nplt.show()","97a72d4c":"# train_len = 650\n# train = monthly[0:train_len] # first 120 months as training set\n# test = monthly[train_len:] # last 24 months as out-of-time test set\nTrain=monthly.loc['2012-08-25':'2014-06-24'] \nvalid=monthly.loc['2014-06-25':'2014-09-25']","9ec3eff1":"Train.shape","52fe7378":"Train.head()","efe32bd1":"valid.shape","10362c7c":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\n\ny_hat_hwa = valid.copy()\nmodel = ExponentialSmoothing(np.asarray(Train['Count']) ,seasonal_periods=4,trend='add', seasonal='add')\nmodel_fit = model.fit(optimized=True)\nprint(model_fit.params)\ny_hat_hwa['hw_forecast'] = model_fit.forecast(len(valid))","68e9b33f":"plt.figure(figsize=(12,4))\nplt.plot(Train['Count'], label='Train')\nplt.plot(valid['Count'], label='Test')\nplt.plot(y_hat_hwa['hw_forecast'], label='Holt Winters\\'s additive forecast')\nplt.legend(loc='best')\nplt.title('Holt Winters\\' Additive Method')\nplt.show()","a6b147ef":"from sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_hwa['hw_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_hwa['hw_forecast'])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Holt Winters\\' additive method'], 'RMSE': [rmse],'MAPE': [mape]})\n# results = pd.concat([results, tempResults])\nresults = tempResults[['Method', 'RMSE', 'MAPE']]\nresults","ea31e066":"from statsmodels.tsa.stattools import adfuller\nadf_test = adfuller(monthly['Count'])\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","ad56f808":"from scipy.stats import boxcox\ndata_boxcox = pd.Series(boxcox(monthly['Count'], lmbda=0), index = monthly.index)\n\nplt.figure(figsize=(12,4))\nplt.plot(data_boxcox, label='After Box Cox tranformation')\nplt.legend(loc='best')\nplt.title('After Box Cox transform')\nplt.show()","186f8855":"data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), monthly.index)\nplt.figure(figsize=(12,4))\nplt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\nplt.legend(loc='best')\nplt.title('After Box Cox transform and differencing')\nplt.show()","62275ef0":"data_boxcox_diff.dropna(inplace=True)","f1ea2d3b":"data_boxcox_diff.tail()","b94b1bcd":"data_boxcox_diff.head()","38fb5e9c":"adf_test = adfuller(data_boxcox_diff)\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","fc5bda86":"from statsmodels.graphics.tsaplots import plot_acf\nplt.figure(figsize=(12,4))\nplot_acf(data_boxcox_diff, ax=plt.gca(), lags = 20)\nplt.show()","20365885":"from statsmodels.graphics.tsaplots import plot_pacf\nplt.figure(figsize=(12,4))\nplot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 20)\nplt.show()","98f5e68d":"train_len = 669\ntrain_data_boxcox = data_boxcox[:train_len]\ntest_data_boxcox = data_boxcox[train_len:]\ntrain_data_boxcox_diff = data_boxcox_diff[:train_len-1]\ntest_data_boxcox_diff = data_boxcox_diff[train_len-1:]","2474331a":"train_data_boxcox_diff","a99e79f0":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(train_data_boxcox_diff, order=(1, 0, 0)) \nmodel_fit = model.fit()\nprint(model_fit.params)","373f2d82":"y_hat_ar = data_boxcox_diff.copy()\ny_hat_ar['ar_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox_diff'].cumsum()\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox'].add(data_boxcox[0])\ny_hat_ar['ar_forecast'] = np.exp(y_hat_ar['ar_forecast_boxcox'])","b37f56fe":"plt.figure(figsize=(12,4))\nplt.plot(Train['Count'], label='Train')\nplt.plot(valid['Count'], label='Test')\nplt.plot(y_hat_ar['ar_forecast'][valid.index.min():], label='Auto regression forecast')\nplt.legend(loc='best')\nplt.title('Auto Regression Method')\nplt.show()","622e6e93":"rmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_ar['ar_forecast'][valid.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_ar['ar_forecast'][valid.index.min():])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive (AR) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","35a079a1":"model = ARIMA(train_data_boxcox_diff, order=(0, 0, 1)) \nmodel_fit = model.fit()\nprint(model_fit.params)","fed229b2":"y_hat_ma = data_boxcox_diff.copy()\ny_hat_ma['ma_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox_diff'].cumsum()\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox'].add(data_boxcox[0])\ny_hat_ma['ma_forecast'] = np.exp(y_hat_ma['ma_forecast_boxcox'])\n","cb37fc07":"plt.figure(figsize=(12,4))\nplt.plot(monthly['Count'][:train_len], label='Train')\nplt.plot(monthly['Count'][train_len:], label='Test')\nplt.plot(y_hat_ma['ma_forecast'][valid.index.min():], label='Moving average forecast')\nplt.legend(loc='best')\nplt.title('Moving Average Method')\nplt.show()\n","741f900a":"rmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_ma['ma_forecast'][valid.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_ma['ma_forecast'][valid.index.min():])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Moving Average (MA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","0565a459":"model = ARIMA(train_data_boxcox_diff, order=(1, 0, 1))\nmodel_fit = model.fit()\nprint(model_fit.params)","32a0c3aa":"y_hat_arma = data_boxcox_diff.copy()\ny_hat_arma['arma_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_arma['arma_forecast_boxcox'] = y_hat_arma['arma_forecast_boxcox_diff'].cumsum()\ny_hat_arma['arma_forecast_boxcox'] = y_hat_arma['arma_forecast_boxcox'].add(data_boxcox[0])\ny_hat_arma['arma_forecast'] = np.exp(y_hat_arma['arma_forecast_boxcox'])","70104bd9":"plt.figure(figsize=(12,4))\nplt.plot(monthly['Count'][:train_len-1], label='Train')\nplt.plot(monthly['Count'][train_len-1:], label='Test')\nplt.plot(y_hat_arma['arma_forecast'][valid.index.min():], label='ARMA forecast')\nplt.legend(loc='best')\nplt.title('ARMA Method')\nplt.show()","a1b2b7d2":"rmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_arma['arma_forecast'][train_len-1:])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_arma['arma_forecast'][train_len-1:])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive moving average (ARMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","049c7bf0":"model = ARIMA(train_data_boxcox, order=(1, 1, 1))\nmodel_fit = model.fit()\nprint(model_fit.params)","efffd8f6":"y_hat_arima = data_boxcox_diff.copy()\ny_hat_arima['arima_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_arima['arima_forecast_boxcox'] = y_hat_arima['arima_forecast_boxcox_diff'].cumsum()\ny_hat_arima['arima_forecast_boxcox'] = y_hat_arima['arima_forecast_boxcox'].add(data_boxcox[0])\ny_hat_arima['arima_forecast'] = np.exp(y_hat_arima['arima_forecast_boxcox'])","6b24197a":"plt.figure(figsize=(12,4))\nplt.plot(Train['Count'], label='Train')\nplt.plot(valid['Count'], label='Test')\nplt.plot(y_hat_arima['arima_forecast'][valid.index.min():], label='ARIMA forecast')\nplt.legend(loc='best')\nplt.title('Autoregressive integrated moving average (ARIMA) method')\nplt.show()","bad76cf5":"rmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_arima['arima_forecast'][valid.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_arima['arima_forecast'][valid.index.min():])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive integrated moving average (ARIMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","ccbb984f":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\nmodel = SARIMAX(train_data_boxcox, order=(3, 1, 4), seasonal_order=(0, 1, 1, 7)) \nmodel_fit = model.fit()\nprint(model_fit.params)","f22f7b34":"y_hat_sarima = data_boxcox_diff.copy()\ny_hat_sarima['sarima_forecast_boxcox'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\ny_hat_sarima['sarima_forecast'] = np.exp(y_hat_sarima['sarima_forecast_boxcox'])","aad8258f":"plt.figure(figsize=(12,4))\nplt.plot(Train['Count'], label='Train')\nplt.plot(valid['Count'], label='Test')\nplt.plot(y_hat_sarima['sarima_forecast'][valid.index.min():], label='SARIMA forecast')\nplt.legend(loc='best')\nplt.title('Seasonal autoregressive integrated moving average (SARIMA) method')\nplt.show()","2326fd17":"rmse = np.sqrt(mean_squared_error(valid['Count'], y_hat_sarima['sarima_forecast'][valid.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(valid['Count']-y_hat_sarima['sarima_forecast'][valid.index.min():])\/valid['Count'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Seasonal autoregressive integrated moving average (SARIMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","bc1d904c":"# test.drop(['ID','year','month','day','Hour'],axis=1,inplace=True)","d3584e17":"print(len(test))\ntest.head()","ca236166":"test1=test.copy()\ntest1.drop(['ID','year','month','day','Hour','Datetime'],axis=1,inplace=True)\ntest1.head()","3a983903":"predict=model_fit.predict(start=\"2014-9-26\", end=\"2015-4-26\", dynamic=True)\npredict=np.exp(predict)","8e063d37":"test['prediction']=predict","d36d2f83":"test.head()","342d848f":"# Remember this is the daily predictions. \n# We have to convert these predictions to hourly basis. \n# To do so we will first calculate the ratio of passenger count for each hour of every day. \n# Then we will find the average ratio of passenger count for every hour and we will get 24 ratios. \n# Then to calculate the hourly predictions we will multiply the daily prediction with the hourly ratio.\n\n# Calculating the hourly ratio of count \ntrain_original['ratio']=train_original['Count']\/train_original['Count'].sum() \n\n\n# Grouping the hourly ratio \ntemp=train_original.groupby(['Hour'])['ratio'].sum() ","e422a052":"# Groupby to csv format \npd.DataFrame(temp, columns=['Hour','ratio']).to_csv('GROUPby.csv') ","3d2cc4db":"\ntemp2=pd.read_csv(\"GROUPby.csv\") \ntemp2=temp2.drop('Hour.1',1) \ntemp2.head()","5aefcc37":"# Merge Test and test_original on day, month and year \nmerge=pd.merge(test, test_original, on=('day','month','year','Hour'), how='left') \n\nfor i in range(0,len(merge)+1):\n        merge['prediction'].fillna(method ='pad', inplace=True) \nmerge.head(50)\nmerge=merge.drop(['year', 'month','Datetime_x','Datetime_x','Datetime_y'], axis=1) \n","0401b344":"# Predicting by merging merge and temp2 \nprediction=pd.merge(merge, temp2, on='Hour', how='left') ","2fd368e5":"# Converting the ratio to the original scale \nprediction['Count']=prediction['prediction']*prediction['ratio']*24","d8eeca3e":"prediction['ID']=prediction['ID_y'] \nsubmission=prediction.drop(['day','Hour','ratio','prediction', 'ID_x', 'ID_y'],axis=1) ","c9865e36":"# Converting the final submission to csv format \npd.DataFrame(submission, columns=['ID','Count']).to_csv('SARIMA.csv',index=False)","8b1f1f97":"submission.head()","110a8d36":"### Boxcox transformation to make the variance constant","4687c2a3":"### Autoregressive Methods","9ff830cb":"### Auto regressive integrated moving average","d0f33027":"### partial auto correlation function","3cefcad0":"#### again a dickey fuller test","4f773832":"### differencing to remove trend","05d4c457":"### Auto regressive moving average method","ff21d044":"### Holt's Winter additive forecast","1df609c0":"### Time Series Decomposition","e3bb9400":"### Auto Regressive Method","a72cc361":"### Moving average Method","3e8a1ec1":"### Plot train, test and forecast","915d6499":"### Outlier detection","ff3bff35":"#### Additive","4fe55489":"### Seasonal ARIMA","955648d4":"### Plot time series data","3e139c75":"### Auto correlation function","18b6debf":"#### Multiplicative"}}