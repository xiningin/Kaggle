{"cell_type":{"ba65ccab":"code","02124735":"code","f2e686b4":"code","5058d07a":"code","076c3056":"code","1bba719d":"code","013db2c9":"code","0a2148e4":"code","19497b6f":"code","ba6aafef":"code","f5931e9c":"code","c452bcc7":"code","b4bfe85b":"code","951819ed":"code","6c20a7a9":"code","805a92a8":"code","3cb5166a":"code","21a3be29":"code","dcc5c01a":"code","854606ab":"code","04bef1c9":"code","2351ec56":"code","7e086360":"markdown","f6e2ac8e":"markdown"},"source":{"ba65ccab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02124735":"import os\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold","f2e686b4":"pizza_data = pd.read_csv(\"\/kaggle\/input\/pizza-price-prediction\/pizza_v1.csv\")\npizza_data.describe()","5058d07a":"pizza_data.head()","076c3056":"#checking for any missing data\npizza_data.isnull().sum()","1bba719d":"#re-format price_rupiah column\npizza_data['price_rupiah'].dtype\nprice = []\nfor item in pizza_data['price_rupiah']:\n    price.append(int(item.replace('Rp','').replace(',','')))\npizza_data['price_rupiah'] = price\npizza_data.head()","013db2c9":"#checing varities\nprint(pizza_data['topping'].value_counts(), pizza_data['variant'].value_counts(), pizza_data['size'].value_counts(), pizza_data['company'].value_counts(), sep='\\n\\n')\n","0a2148e4":"#now just converting categorical data to numeric data to simply visualize it, then we will transform it again to see the relation between each column and price\nfrom sklearn.preprocessing import LabelEncoder\ncol = ['topping', 'variant', 'size','company','extra_sauce','extra_cheese']\n\npizza_labelled = pizza_data.copy()\nfor item in col:\n    if(pizza_labelled[item].dtype == 'object'):\n        pizza_labelled[item] = pizza_labelled[item].fillna('N')\n        lbl= LabelEncoder()\n        lbl.fit(pizza_labelled[item].values)\n        pizza_labelled[item] = lbl.transform(pizza_labelled[item].values)\npizza_labelled.head()","19497b6f":"pizza_labelled.hist(figsize=(13,13))\nplt.show()","ba6aafef":"#now through pair plot we will see the relation between every 2 columns\n\ndata_plt = pizza_labelled[pizza_labelled.columns.tolist()]\nsns.pairplot(data_plt)","f5931e9c":"#now we will go to our original data and use label encoder again to transform it to new columns instead of different values in the data frame\n\ncol = ['topping', 'variant', 'size','company','extra_sauce','extra_cheese']\n\npizza_categoried = pizza_data.copy()\n#print(pd.get_dummies(pizza_categoried[col]))\n#pizza_categoried.head()\n\npd.get_dummies(pizza_categoried, columns= col)","c452bcc7":"pip install sweetviz","b4bfe85b":"# we can also do automatic EDA with GML\nimport sweetviz as sv\nreport = sv.analyze(pizza_data)\nreport.show_html('pizza_data.html')","951819ed":"comparision = sv.compare(pizza_data[100:], pizza_data[:100])\ncomparision.show_html('compare.html')","6c20a7a9":"#correlation value of price_rupiah with another columns that have the most impact on price\npizza_labelled.corr()['price_rupiah'].sort_values()","805a92a8":"#We can fit a regression model for column diameter and calculate the R^2\nfrom sklearn.linear_model import LinearRegression\n\nsns.regplot(x=\"diameter\", y='price_rupiah', data = pizza_data)","3cb5166a":"X = pizza_data[['diameter']]\nY = pizza_data['price_rupiah']\nlm = LinearRegression()\nlm.fit(X,Y)\nlm.score(X,Y) #R^2 score (cofficient relation)\n","21a3be29":"features = col\nX= pizza_labelled[features] # as this df has the numerical value and pizza_data has categorical\nY= pizza_data['price_rupiah']\nlm = LinearRegression()\nlm.fit(X,Y)\nlm.score(X,Y) #R^2 score (cofficient relation)","dcc5c01a":"# Now we will create a list of tupples to make piplelines, model, and evaluation\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,PolynomialFeatures\n\nInput=[('scale',StandardScaler()),('polynomial', PolynomialFeatures(include_bias=False)),('model',LinearRegression())]\n\n# we will make a pipeline object to predict the price\n\npipe = Pipeline(Input)\npipe.fit(X,Y)\npipe.score(X,Y)","854606ab":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\nfeatures = pizza_labelled.columns.to_list()\nfeatures.remove('price_rupiah')\nX= pizza_labelled[features]\nY= pizza_labelled['price_rupiah']\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=1)\nprint(\"number of test samples:\", x_test.shape[0])\nprint(\"number of training samples:\",x_train.shape[0])","04bef1c9":"from sklearn.linear_model import Ridge\nridge = Ridge(alpha=0.1)\nridge.fit(x_train, y_train)\nridge.score(x_test, y_test)","2351ec56":"# performing a second order polynomial\npf = PolynomialFeatures(degree=2)\nx_test_data = pf.fit_transform(x_test)\nx_train_data = pf.fit_transform(x_train)\nridge1=Ridge(alpha=0.1)\nridge1.fit(x_train_data,y_train)\nridge1.score(x_test_data, y_test)","7e086360":"## MODEL EVALUATION AND REFINEMENT\n","f6e2ac8e":"## Data Preprocessing and cleaning"}}