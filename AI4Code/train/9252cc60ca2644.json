{"cell_type":{"f3c4cd4a":"code","02614922":"code","4e32a2c8":"code","95f2b64c":"code","4ec22918":"code","4a98581b":"code","ac5148b9":"code","2943ce65":"code","fdd2ccf2":"code","feb55aa0":"code","e326f56e":"code","0fea3e6a":"code","2f89a46a":"code","878d8308":"code","670c2202":"code","57e1aa8d":"code","18e6c288":"code","f39913ea":"code","b693230b":"code","db522714":"code","80781326":"code","9b67ffde":"code","26be9455":"code","1d52cb67":"code","90050e14":"code","5f92530d":"code","92cf900a":"code","3d7335e3":"code","99123f02":"code","b34a0811":"code","9a9fdc1e":"markdown","6ea85690":"markdown","297c2547":"markdown","090bb811":"markdown","86769bee":"markdown","4190ee69":"markdown","fa6436e5":"markdown","ee5fcf02":"markdown","8525f356":"markdown","d2155df3":"markdown","13df5e3c":"markdown","d7925368":"markdown","58e0d8da":"markdown","1f76156c":"markdown","ead50062":"markdown","74fd16cd":"markdown","91eca874":"markdown","3f1fb733":"markdown","8f590272":"markdown"},"source":{"f3c4cd4a":"# -------------------------------\n# Import des librairies n\u00e9cessaires\n# -------------------------------\n\nimport matplotlib.pyplot as plt       # Plotting\nimport numpy as np                    # Tableau Multidimensionnel\nimport pandas as pd                   # Manipulation des Dataframe\nimport seaborn as sns                 # Librairie de visualisation\n\n# Librairies Scikit Learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# Dataset des chiffres du MNIST\nfrom keras.datasets import mnist\n\n# Librairies Keras pour la constructino du r\u00e9seau CNN\nfrom keras.models import Model, Sequential\nfrom keras.models import load_model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import UpSampling2D, Dropout, Dense, Flatten\nfrom keras.callbacks import TensorBoard","02614922":"# Fonction pour afficher les donn\u00e9es matricielles sous forme d'images\ndef display_image(X, y, n, label=False):\n    plt.figure(figsize=(20,2))\n    for i in range(10):\n        ax = plt.subplot(1, n, i+1)\n        plt.imshow(X.values[i].reshape(28,28))\n        if label:\n            plt.title(\"Digit: {}\".format(y[i]))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()","4e32a2c8":"# Path vers les jeux de donn\u00e9es\ntrain_dir = \"..\/input\/train.csv\"\ntest_dir = \"..\/input\/test.csv\"","95f2b64c":"# Lecture du jeu d'entrainement via pandas \u00e0 partir d'un fichier csv\ndf_train = pd.read_csv(train_dir)\n\n# R\u00e9cup\u00e9ration des informations sur le Dataframe du jeu de donn\u00e9es\ndf_train.info()","4ec22918":"df_train.head()","4a98581b":"y_train = df_train['label']\nX_train = df_train.drop(columns=['label'])","ac5148b9":"# Les labels prennent les valeurs des classes de chiffres\ny_train.head()","2943ce65":"# Visualisation de la r\u00e9partition des labels\nsns.set(style='white', context='notebook', palette='deep')\nax = sns.countplot(y_train)","fdd2ccf2":"# On affiche les images connues avec leur labels\n# X_train.values[0].reshape(28,28)\ndisplay_image(X_train, y_train, n=10, label=True)","feb55aa0":"# 1. Split entre jeu d'entrainement et jeu de validation avec un ratio de 90\/10\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=False)","e326f56e":"# 2. Reshape des data pour les formatter en 28x28x1\nX_train = X_train.values.reshape(-1, 28,28,1)\nX_val = X_val.values.reshape(-1, 28,28,1)","0fea3e6a":"# Affichage de la nouvelle shape des donn\u00e9es (maintenant sous forme de matrice 28x28)\nX_train.shape","2f89a46a":"# 3. Normalisation des donn\u00e9es pour avoir des valeurs de pixels entre 0 et 255\nX_train = X_train \/ 255.0\nX_val = X_val \/ 255.0","878d8308":"# 4. Remplacement des valeurs des labels par des valeurs cat\u00e9goriques\nY_train  = pd.get_dummies(y_train).values\nY_val  = pd.get_dummies(y_val).values","670c2202":"print(\"La valeur {} est encod\u00e9e vers le vecteur {}\".format(y_train[0], Y_train[0]))\nprint(\"valeur {} transform\u00e9e en vecteur: {}\".format(y_train[20], Y_train[20]))","57e1aa8d":"# Augmentation des images avec un processing :\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n          featurewise_center=False,            # set input mean to 0 over the dataset\n          samplewise_center=False,             # set each sample mean to 0\n          featurewise_std_normalization=False, # divide inputs by std of the dataset\n          samplewise_std_normalization=False,  # divide each input by its std\n          zca_whitening=False,                 # apply ZCA whitening\n          rotation_range=20,                   # randomly rotate images in the range (degrees, 0 to 180)\n          zoom_range = 0.1,                    # Randomly zoom image \n          width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n          height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n          horizontal_flip=False,               # randomly flip images\n          vertical_flip=False)                 # randomly flip images","18e6c288":"# Initialisation \nmodel = Sequential()\n\n# ------------------------------------\n# Couche de Convolution et MaxPooling\n# ------------------------------------\n\n# Conv2D : https:\/\/keras.io\/layers\/convolutional\/\n#     filters : nombres de filtres de convolutions\n#     kernel_size : taille des filtres de la fen\u00eatre de convolution \n#     input_shape : taille de l'image en entr\u00e9e (\u00e0 pr\u00e9ciser seulement pour la premi\u00e8re couche)\n#     activation  : choix de la fonction d'activation\n# BatchNormalisation : permet de normaliser les coefficients d'activation afin de les maintenirs proche de 0 pour simplifier les calculs num\u00e9riques\n# MaxPooling : Op\u00e9ration de maxPooling sur des donn\u00e9es spatiales (2D) : voir illustration ci-dessus\n# Dropout : permet de d\u00e9sactiver al\u00e9atoirement une proportion de neurones (afin d'\u00e9viter le surentrainement sur le jeu d'entrainement)\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5, 5), activation='relu', padding='Same', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (5, 5), activation='relu', padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(strides=(2,2)))\nmodel.add(Dropout(0.25))","f39913ea":"# ------------------------------------\n# Classifier (couche enti\u00e8rement Connect\u00e9e)\n# Voir illustration ci-dessous\n# ------------------------------------\n# Flatten : conversion d'une matrice en un vecteur plat\n# Dense   : neurones\nmodel.add(Flatten())     # Applatissement de la sortie du r\u00e9seau de convolution\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.25))\n# Couche de sortie : nombre de neurones = nombre de classe \u00e0 pr\u00e9dire\nmodel.add(Dense(units=10, activation='softmax'))","b693230b":"# R\u00e9capitulatif de l'architecture mod\u00e8le\nmodel.summary()","db522714":"# S\u00e9lection de l'optimiser pour la decente de gradient\nfrom keras.optimizers import Adam\nmodel.compile(loss='categorical_crossentropy', optimizer = Adam(lr=0.0001), metrics=[\"accuracy\"])","80781326":"# D\u00e9marrage de l'entrainement du r\u00e9seau\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n                           steps_per_epoch=1000,             # nombre image entrainement \/ batch_size\n                           epochs=25,                        # nombre de boucle \u00e0 r\u00e9aliser sur le jeu de donn\u00e9es complet\n                           verbose=1,                        # verbosit\u00e9\n                           validation_data=(X_val, Y_val))   # donn\u00e9es de validation (X(donn\u00e9es) et y(labels))","9b67ffde":"# Evaluation de la performance du mod\u00e8le\nfinal_loss, final_acc = model.evaluate(X_val, Y_val, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","26be9455":"plt.plot(hist.history['loss'], color='b')\nplt.plot(hist.history['val_loss'], color='r')\nplt.show()\nplt.plot(hist.history['acc'], color='b')\nplt.plot(hist.history['val_acc'], color='r')\nplt.show()","1d52cb67":"# Pr\u00e9dictions et vecteur de probabilit\u00e9\nY_hat = model.predict(X_val)\nY_hat[0]","90050e14":"# G\u00e9n\u00e9ration des vecteurs de verit\u00e9 (Y_true) et de pr\u00e9diction (Y_pred)\nY_pred = np.argmax(Y_hat, axis=1)\nY_true = np.argmax(Y_val, axis=1)","5f92530d":"# G\u00e9n\u00e9ration d'une matrice de confusion pour observer les erreurs\n# Toutes les valeurs sortant de la diagonales sont les erreurs de classification\ncm = confusion_matrix(Y_true, Y_pred)\nprint(cm)","92cf900a":"# Lecture jeu de test\nX_test = pd.read_csv(test_dir)\n\n# Traitement des donn\u00e9es de la m\u00eame fa\u00e7on que pour l'entrainement\n# Reshape\nX_test = X_test.values.reshape(-1, 28,28,1)\n# Normalisation\nX_test = X_test \/ 255.0","3d7335e3":"# Pr\u00e9dictions sur le jeu de test\nY_hat = model.predict(X_test, verbose=1)\nY_pred = np.argmax(Y_hat, axis=1)","99123f02":"# Affichage des images pr\u00e9dites\ndisplay_image(pd.DataFrame(X_test.reshape(-1, 784)), Y_pred, n=10, label=True)","b34a0811":"# Soumission et Enregistrement des r\u00e9sultats\nresults = pd.Series(Y_pred, name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_predictions.csv\",index=False)","9a9fdc1e":"## Conclusions et Optimisations possibles\n\nNous voyons qu'avec quelques lignes de la librairies Keras nous pouvons facilement mettre en oeuvre un r\u00e9seau de classification des images.\n\nCe r\u00e9seau est **tr\u00e9s performant** puisqu'il classifie correctement avec un **taux > 99% de reconnaissance** des chiffres.\n\n### Pistes d'optimisations\n\nLes pistes d'optimisations d'une **mani\u00e8re g\u00e9n\u00e9rale** sur un jeu de donn\u00e9es se situent : \n\n* Lors du feature Engineering (non possible sur ce jeu de donn\u00e9es)\n* Lors la pr\u00e9paration et le traitement des donn\u00e9es (dont augmentation des donn\u00e9es)\n* Lors du choix de l'architecture du r\u00e9seau de neurones\n* Lors du choix de l'optimiseur et de ces param\u00e8tres\n\nL'**optimisation principale est li\u00e9e \u00e0 l'architecture du r\u00e9seau**.\n\n* Le nombre de couches de Convolutions \/ Pooling\n* Les param\u00e8tres associ\u00e9es aux couches de Convolutions et de Pooling (strides, filters, kernel_size...)\n* Les couches de Regularization (limitation de l'overfitting)\n\n**Concernant le traitement des donn\u00e9es** :\n\n* Param\u00e8tre de transformation d'images (rotation, zoom, flip ...)\n* Nombres de transformations\n* Nombres d'images d'entrainement\n\n\n**Concernant l'optimizeur**:\n\n* Choix de l'optimiseur (Adam , RMSProp...)\n* Choix du learning Rate et diminution gr\u00e2ce \u00e0 des callbacks\n* Choix des autres param\u00e8tres\n\n**Assemblage de mod\u00e8les**\n\n* Il est possible d'assembler plusieurs mod\u00e8les diff\u00e9rents\n* Les pr\u00e9dictions sont alors moyenn\u00e9es entre les diff\u00e9rents mod\u00e8les\n\n\nVoir : https:\/\/www.kaggle.com\/cdeotte\/how-to-choose-cnn-architecture-mnist\n\n\nMerci de votre attention\nSt\u00e9phane","6ea85690":"Nous observons qu'il y a 42 000 enregistrements sur 785 colonnes dans le Dataframe de type entier.\n\nRegardons les premiers enregistrements a l'aide de la commande head() de panda","297c2547":"## Mod\u00e8le CNN\n\nCr\u00e9ation du mod\u00e8le de **R\u00e9seau de Convolution**\n\nL'image ci-dessous explique le fonctionnement global d'un r\u00e9seau de Convolution (CNN) avec sa couche enti\u00e8rement connect\u00e9e \"Classification\" (Fully Connected).\n\nIl s'agit d'un processus permettant \u00e0 partir d'une entr\u00e9e (image) d'obtenir une probabilit\u00e9 d'appartenance \u00e0 une classe en sortie.\n\nLe **processus de Convolution** sous-entend g\u00e9n\u00e9ralement constitu\u00e9 de plusieurs \u00e9tapes qui se r\u00e9p\u00e8tent dans cet ordre :\n* Couche de Convolution\n* Max Pooling\n* Regularization\n\nLa derni\u00e8re couche est le **classifier** qui permet de donner la probabilit\u00e9 du r\u00e9sultat de classification de l'image (chien \/ chat). \nNous allons d\u00e9tailler cette \u00e9tape un peu plus loin.\n\n![image.png](attachment:image.png)\n\nNous allons \u00e9tudier les diff\u00e9rentes couches ci-dessous","090bb811":"## Entrainement du mod\u00e8le et \u00e9valuation","86769bee":"### Convolution 2D\nLa partie convolution utilise des \"**filtres**\" pour r\u00e9p\u00e9rer des \"**features**\" dans l'image. Les Features sont les \u00e9l\u00e9ments distinctifs de l'image r\u00e9p\u00e9r\u00e9s par le r\u00e9seau (pour les premi\u00e8res couches de convolution cel\u00e0 est des formes simples ie des lignes horizontales, verticales, diagonales... et pour les couches suivantes cel\u00e0 peut \u00eatre des formes plus complexes). Ces \u00e9l\u00e9ments r\u00e9p\u00e9r\u00e9s par les diff\u00e9rents filtres sont appel\u00e9s des **features Map**. Chaque features Map repr\u00e9sente une **dimension suppl\u00e9mentaire** de \"l'image\" cr\u00e9e en sortie. \n\nExemple : si la premi\u00e8re couche de Convolution comporte 16 filtres, alors l'image r\u00e9siduels sera compos\u00e9e de 16 dimensions (constitu\u00e9s par les features map)\n\nLa documentation de l'API : https:\/\/keras.io\/layers\/convolutional\/","4190ee69":"### 3. Split Train \/ validation , reshape et normalisation\n\nNous allons dans cette partie traiter les donn\u00e9es pour mieux les exploiter:\n\n**1.  S\u00e9paration du jeu d'entrainement en un jeu d'entrainement + un jeu de validation ( ratio usuel 80\/20 )**\n\nCette partie a pour objet de permettre de valider la performance du mod\u00e8le lors de l'entrainement du r\u00e9seau en utilisant des images d\u00e9di\u00e9es \u00e0 la validation (ce qui \u00e9vite les biais d'utiliser des images du jeu d'entrainement d\u00e9j\u00e0 vues par le mod\u00e8le). Il existe plusieurs mani\u00e8res de r\u00e9aliser cette \u00e9tape: une fa\u00e7on simple de le faire consiste \u00e0 utiliser la m\u00e9thode train_test_split() de scikit_learn\n\n**2.  Reshape de la matrice des donn\u00e9es**\n\nDans cette partie nous allons restructurer les donn\u00e9es qui sont sur une ligne de 784 colonnes en une matrice de 28x28 ( permettant par exemple l'affichage des images et le bon fonctionnement du m\u00e9chanisme de convolution par le r\u00e9seau de neurones). Pour cette op\u00e9ration nous allons simplement utiliser le reshape() fourni par la librairie numpy.\n\n**3.  Normalisation des valeurs**\n\nCette \u00e9tape permet d'\u00e9viter les \"explosions de gradients\" qui peuvent se produire avec des \"poids\" non normalis\u00e9s. L'id\u00e9al pour les algorithmes \u00e9tant de travailler avec des valeurs comprises entre 0 et 1. Pour ce faire nous allons simplement diviser le chiffre des pixels par la plus haute valeur pouvant \u00eatre prise (255). A noter qu'il existe des m\u00e9thodes et des librairies permettant de normaliser et standardiser les valeurs d'un dataset en se basant sur l'ecart type et les d\u00e9viations standards\n\n**4.  Remplacement des labels par des valeurs cat\u00e9goriques**\n\nCette \u00e9tape est \u00e9galement destin\u00e9e \u00e0 ce que l'algorithme fonctionne de mani\u00e8re optimale. Elle consiste \u00e0 remplacer dans notre cas le label qui peut prendre 10 valeurs diff\u00e9rentes (de 0 \u00e0 9) par un vecteur codant ce label. Exemple une classe \"2\" sera cod\u00e9e [0 0 1 0 0 0 0 0 0 0] une classe \"5\" sera cod\u00e9e [0 0 0 0 0 1 0 0 0 0] ....","fa6436e5":"## Pr\u00e9paration des donn\u00e9es\n### 1. Lecture des donn\u00e9es","ee5fcf02":"**Affichage des courbes d'apprentissages**\n\nNous allons dans cette partie afficher les courbes de l'apprentissage du r\u00e9seau. Les courbes nous permettent de s'assurer que le mod\u00e8le apprend correctement. Voir illustration sur les learning rates plus haut. \n\nIl est important de s'assurer que la courbe de cout descend et que l'accuracy monte au fur et \u00e0 mesure des passages (epoch). Dans le cas id\u00e9al la courbe des donn\u00e9es de validation reste proche de la courbe des donn\u00e9es d'entrainement (sinon il faut rechercher si il n'y a pas surapprentissage ou sous-apprentissage)","8525f356":"## Choix de l'optimiseur\n\nIl existe **plusieurs optimiseurs** pour le calcul num\u00e9rique. Nous avons choisi d'utiliser 'Adam' qui est un bon choix dans la plupart des cas et qui permet g\u00e9n\u00e9rallement une descente de gradient rapide. Il existe des comparaisons entre les diff\u00e9rents optimiseurs que l'on pouvons trouver dans des papiers sur Internet. \n\nA noter \u00e9galement que le **learning Rate** est un \u00e9l\u00e9ment primordial lui aussi. Trop bas la d\u00e9cente de gradient pour le calcul du co\u00fbt va \u00eatre lente et peut ne pas trouver les optimums, trop haut il est m\u00eame possible que les fonctions divergent et que le cout augmentent. Il est donc important lors des optimisations de faire des tests sur les bons choix du couple optimiseurs \/ learning Rate\n\n![image.png](attachment:image.png)","d2155df3":"On voit que chaque **pixel est cod\u00e9 de 0 \u00e0 255**\nIl y a 784 pixels ce qui repr\u00e9sente une image de dimension (28 x 28)\nLa premi\u00e8re colonne repr\u00e9sente le label appel\u00e9 y (de 0 \u00e0 9) les autres colonnes les donn\u00e9es des pixels\n\nNous allons les extraire de la fa\u00e7on suivante: \n\n* y_train = Les labels d'entrainements \n* X_train = les donn\u00e9es r\u00e9els avec les pixels des images","13df5e3c":"## Classifier\n\nEn derni\u00e8re \u00e9tape, apr\u00e8s le r\u00e9seau de convolution, l'image r\u00e9siduelle est transform\u00e9e en un \"vecteur\" permettant l'apprentissage via classification par un ANN (r\u00e9seau de neurones) classique. \n\nCe r\u00e9seau de neurones prend en entr\u00e9e le vecteur applati du r\u00e9seau de Convolution et effectue les \u00e9tapes de **FeedForward** et de **Backpropagation** afin de permettre la **descente de gradient** pour l'optimisation de la fonction de cout de **regression logistique** (classification).\n\nLa couche de sortie contient 10 neurones c'est \u00e0 dire le m\u00eame nombre que les classes de chiffre \u00e0 pr\u00e9dire. \n\nChaque **neurone de sortie** se verra affecter une **probabilit\u00e9** que l'image soit de la classe du chiffre du neurone en question.\n\n\n![image.png](attachment:image.png)\n\n\n**En synth\u00e8se**: il s'agit d'op\u00e9rations de calcul num\u00e9riques qui permettent de construire un mod\u00e8le de pr\u00e9dictions des images. Ceci fonctionne gr\u00e2ce au vecteur  fourni en entr\u00e9e et au label connu associ\u00e9 \u00e0 ce vecteur, ce qui permet au r\u00e9seau de calculer les param\u00e8tres d'une \u00e9quation permettant d'optimiser les probabilit\u00e9s de classification.\n\nPour approfondir ces notions : http:\/\/neuralnetworksanddeeplearning.com\/chap1.html\n\n**Cr\u00e9ation de notre classifier**","d7925368":"## CNN Classification des Chiffres du Dataset du MNIST\n\nTutorial pour les d\u00e9butants sur un exemple classique de **classification des chiffres** avec un r\u00e9seau de Convolution.\n\nNous entrons ici dans l'apprentissage dit '**supervis\u00e9**' cat le jeu d'entrainement nous informe de la classe du chiffre \u00e0 pr\u00e9dire (le label)\n\nNous allons utiliser le jeu de r\u00e9f\u00e9rence du MNIST pour la classification des chiffres.\n\n![image.png](attachment:image.png)\n\nNous allons voir \u00e9tape par \u00e9tape comment proc\u00e9der \u00e0 la classification des images de ce jeu de donn\u00e9es gr\u00e2ce \u00e0 l'excellente **librairie Keras** permettant des op\u00e9rations de Haut niveau sur le framework de calcul **TensorFlow** sans entrer dans les d\u00e9tails d'impl\u00e9mentation des op\u00e9rations de FeedFowards et de Backpropagation.\n\n### Compl\u00e9ments\nhttp:\/\/cs231n.github.io\/convolutional-networks\/\nhttps:\/\/keras.io\/layers\/convolutional\/\nhttps:\/\/blog.keras.io\/how-convolutional-neural-networks-see-the-world.html\nhttps:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html\nhttps:\/\/www.pyimagesearch.com\/2018\/12\/31\/keras-conv2d-and-convolutional-layers\/\n","58e0d8da":"Lecture des donn\u00e9es d'entrainnement (train) et des donn\u00e9es de test. \n\nLes donn\u00e9es d'entrainement **contiennent les labels** correspondants (classe des chiffres \u00e0 pr\u00e9dire). \n\nLes donn\u00e9es de test quand \u00e0 elle ne contiennent aucun label.","1f76156c":"On voit dans la capture ci-dessus que chaque ligne contient la classe de l'image qui est repr\u00e9sent\u00e9e\n* la ligne 0 est un 1\n* la ligne 1 est un 0\n* la ligne 3 est un 4\n\nV\u00e9rifions avec la fonction ci-dessous si les images sont correctement r\u00e9parties dans les 10 classes possibles","ead50062":"## Pr\u00e9dictions sur le jeu de test\n\nNous attaquons maintenant la partie finale ou il faut pr\u00e9dire les r\u00e9sultats sur un jeu de test sans label !\nAu pr\u00e9alable il nous faurt charger les donn\u00e9es de tests (gr\u00e2ce \u00e0 Panda) puis appliquer les m\u00eames traitements que ceux qui ont \u00e9t\u00e9 appliqu\u00e9s pour les images d'entrainement","74fd16cd":"**Fonction d'affichage**:\n\nTout d'abord nous allons developper une fonction avec matplotlib permettant d'afficher nos donn\u00e9es de mani\u00e8re visuelle.","91eca874":"## G\u00e9n\u00e9rateurs d'images\n\nNous allons maintenant  une classe de la librarie Keras appel\u00e9e **ImageDataGenerator**  qui permet d'**augmenter les images en temps r\u00e9el**. \n\nCeci est un moyen permettant \u00e0 partir d'un jeu de donn\u00e9es de **multiplier les donn\u00e9es disponibles** pour l'entrainement du r\u00e9seau afin de permettre d'avoir plus de data pour r\u00e9aliser l'entrainement et la mise \u00e0 jour des poids du r\u00e9seau.\n\nLa g\u00e9n\u00e9rateur ci-dessous permet donc de transformer les images via des **op\u00e9rations de transformations** \u00e0 la vol\u00e9e sur les images du jeu de donn\u00e9es :","3f1fb733":"**Cr\u00e9ation du Mod\u00e8le de convolution**\n\nDans cette partie nous allons **cr\u00e9er le r\u00e9seau de Convolution**. Ce r\u00e9seau est bas\u00e9 sur plusieurs couche qui r\u00e9p\u00e8tent le motif de Couche de Convolution , Normalisation , MaxPooling. Le choix de la structure du r\u00e9seau de Convolution est primordial pour l'optimisation des performances. Il est important de proc\u00e9der \u00e0 des tests pour valider le mod\u00e8le de r\u00e9seau qui permet d'obtenir les meilleurs performances","8f590272":"### Max Pooling\n\nLes op\u00e9rations de \"**maxPooling**\" r\u00e9duise la taille des images (g\u00e9n\u00e9ralement par 2 en fonction des param\u00e8tre). \nElles permettent d'extraires les caract\u00e9ristiques les plus importantes et de briser la lin\u00e9arit\u00e9 de l'image.\n\nLa documentation de l'API :  https:\/\/keras.io\/layers\/pooling\/\n\nIllustration de l'\u00e9tape de **MaxPooling** qui extrait les valeurs maximum de certains pixel de l'image via une fen\u00eatre glissante. \n\nCeci aboutit \u00e0 un r\u00e9duction de la taille de l'image:\n\n![image.png](attachment:image.png)\n"}}