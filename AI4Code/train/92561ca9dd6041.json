{"cell_type":{"244452be":"code","ac5a89f0":"code","c6e5acfa":"code","af05d3b4":"code","926544d6":"code","46accb01":"code","49f793fe":"code","45daf670":"code","28b6815f":"code","9d41a758":"code","d5499827":"code","f49100c7":"code","8f4d170b":"code","4921f1a6":"code","6994f65d":"code","022b0d1b":"code","30d97864":"code","3582c124":"code","5e317caf":"code","97ccb1de":"code","7e0f62b9":"code","93bdd090":"code","5103500b":"code","f7e30408":"code","b1b7c623":"code","e1b4d5b7":"code","cf582314":"code","ea578415":"code","7b11c67e":"code","a1b4f45d":"markdown"},"source":{"244452be":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom sklearn.preprocessing import RobustScaler, Normalizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.neighbors import LocalOutlierFactor\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ac5a89f0":"import warnings\nwarnings.simplefilter(action = \"ignore\")","c6e5acfa":"#Reading data set and the first 5 observation\ndata=pd.read_excel('\/kaggle\/input\/uci-online-retail-ii-data-set\/online_retail_II.xlsx', sheet_name = \"Year 2010-2011\")\ntoday_date = dt.datetime(2011,12,30)\ndata.head()","af05d3b4":"#Data set consists of 541910 observation units and 8 variables.\ndata.shape","926544d6":"data.nunique()","46accb01":"#Descriptive statistics of the data set accessed.\ndata.describe([0.10,0.25,0.50,0.75,0.90,0.99]).T","49f793fe":"#How many of which products are there?\ndata[\"Description\"].value_counts().head()","45daf670":"#What is the most ordered product?\ndata.groupby(\"Description\").agg({\"Quantity\":\"sum\"}).sort_values(\"Quantity\", ascending = False).head()","28b6815f":"data[\"TotalPrice\"] = data[\"Quantity\"]*data[\"Price\"]\ndata.groupby(\"Invoice\").agg({\"TotalPrice\":\"sum\"}).head()","9d41a758":"#How many orders came from which country?\ndata[\"Country\"].value_counts().head()","d5499827":"#Which country earned how much?\ndata.groupby(\"Country\").agg({\"TotalPrice\":\"sum\"}).sort_values(\"TotalPrice\", ascending = False).head()","f49100c7":"def prepare_rfm_base_dataframe(for_comparison):\n    rfm_base_df = data.copy()\n    rfm_base_df.dropna(inplace=True) # Customer ID NaN olan g\u00f6zlemleri drop ediyoruz.\n\n    rfm_base_df[\"Customer ID\"] = rfm_base_df[\"Customer ID\"].astype(int) # Customer ID datatipini de\u011fi\u015ftiriyoruz.\n\n    rfm_base_df[\"Monetary\"] = rfm_base_df[\"Quantity\"] * rfm_base_df[\"Price\"] # Total_amount degerlerini buluyoruz\n\n    rfm_base_df[\"Recency\"] = (today_date - rfm_base_df[\"InvoiceDate\"])\n\n    rfm_base_df[\"Recency\"] = rfm_base_df[\"Recency\"].apply(lambda x: x.days)\n\n    df_recency = rfm_base_df.groupby([\"Customer ID\"]).agg({\"Recency\":max})\n\n    df_frequency = rfm_base_df.groupby([\"Customer ID\"]).agg({\"Invoice\":\"count\"})\n    df_frequency.rename(columns={\"Invoice\": \"Frequency\"}, inplace = True)\n\n    df_monetary = rfm_base_df.groupby([\"Customer ID\"]).agg({\"Monetary\":sum})\n\n    rfm_base_df =  pd.concat([df_recency, df_frequency, df_monetary], axis=1)\n    \n    if(for_comparison):\n        rfm_base_df[\"RecencyScore\"] = pd.qcut(rfm_base_df['Recency'], 5, labels = [5, 4, 3, 2, 1])\n        rfm_base_df[\"FrequencyScore\"] = pd.qcut(rfm_base_df['Frequency'].rank(method=\"first\"), 5, labels = [1, 2, 3, 4, 5])\n        rfm_base_df[\"MonetaryScore\"] = pd.qcut(rfm_base_df['Monetary'], 5, labels = [1, 2, 3, 4, 5])\n        rfm_base_df[\"RFM_SCORE\"] = (rfm_base_df['RecencyScore'].astype(str) \n                                + rfm_base_df['FrequencyScore'].astype(str) \n                                + rfm_base_df['MonetaryScore'].astype(str))\n    \n        seg_map = {\n            r'[1-2][1-2]': 'Hibernating',\n            r'[1-2][3-4]': 'At Risk',\n            r'[1-2]5': 'Can\\'t Loose',\n            r'3[1-2]': 'About to Sleep',\n            r'33': 'Need Attention',\n            r'[3-4][4-5]': 'Loyal Customers',\n            r'41': 'Promising',\n            r'51': 'New Customers',\n            r'[4-5][2-3]': 'Potential Loyalists',\n            r'5[4-5]': 'Champions'\n        }\n    \n        rfm_base_df['Segment'] = rfm_base_df['RecencyScore'].astype(str) + rfm_base_df['FrequencyScore'].astype(str)\n        rfm_base_df['Segment'] = rfm_base_df['Segment'].replace(seg_map, regex=True)\n\n    return rfm_base_df","8f4d170b":"def modify_for_k_means(rfm_base_df, features):\n    # K-Means\n    # K-Means'de tranform edilecek degerlerin orjinallerini ayr\u0131 birer de\u011fi\u015fkene at\u0131yoruz.\n    rfm_base_df[[\"Recency_Base\",\"Frequency_Base\",\"Monetary_Base\"]] = rfm_base_df[[\"Recency\",\"Frequency\",\"Monetary\"]]\n    # log veya root cube transformasyona sokuyoruz. Da\u011f\u0131l\u0131m\u0131 normale yakla\u015ft\u0131rabilmek i\u00e7in\n    manage_skewness(rfm_base_df, features)\n    return rfm_base_df","4921f1a6":"def manage_skewness(df, columns):\n    for column in columns:\n        if(df[df[column] < 0].values.size):\n            df[column] = np.cbrt(df[column])\n        else:\n            if(df[df[column] == 0].values.size):\n                df[column] = df[column] + 0.1\n\n            df[column] = np.log(df[column])","6994f65d":"def run_kmeans(df_rfm, k_means_features, n_clusters):\n    normalizer = RobustScaler()\n    normalized = normalizer.fit_transform(df_rfm[k_means_features])\n    df_rfm[k_means_features] = pd.DataFrame(normalized, columns= k_means_features, index=df_rfm.index)\n\n    model = KMeans(n_clusters=n_clusters)\n    model.fit_transform(df_rfm[k_means_features])\n    df_rfm[\"Cluster_No\"]  = model.labels_\n    df_rfm[\"Cluster_No\"] = df_rfm[\"Cluster_No\"] + 1","022b0d1b":"# Klasik RFM Analizi\ndf_rfm = prepare_rfm_base_dataframe(True)\ndf_rfm[[\"Segment\" ,\"Recency\",\"Frequency\",\"Monetary\"]].groupby([\"Segment\"]).agg([\"mean\",\"count\"])","30d97864":"# K_Means For Comparision\n# K-means'de kullan\u0131lacak feature listesi\nk_means_features_for_comparision = [\"Recency\",\"Frequency\"]\ndf_rfm = modify_for_k_means(df_rfm, k_means_features_for_comparision)","3582c124":"kmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k = (2,20))\nvisu.fit(df_rfm[k_means_features_for_comparision])\nvisu.poof();","5e317caf":"# 6 cluster ile modelimizi \u00e7al\u0131\u015ft\u0131yoruz\nrun_kmeans(df_rfm, k_means_features_for_comparision, 6)","97ccb1de":"# Final dataframe'i olusturuyoruz\ndf_rfm_final = df_rfm[[\"Recency_Base\",\"Frequency_Base\",\"Monetary_Base\",\"Segment\",\"Cluster_No\"]]\ndf_rfm_final = df_rfm_final.rename(columns={\"Recency_Base\":\"Recency\", \"Frequency_Base\":\"Frequency\",\"Monetary_Base\":\"Monetary\"})","7e0f62b9":"df_rfm_final[[\"Segment\", \"Cluster_No\" ,\"Recency\",\"Frequency\",\"Monetary\"]].groupby([\"Cluster_No\",\"Segment\"]).agg([\"mean\",\"count\"])","93bdd090":"# Cluster gorsel\nsns.lmplot(data=df_rfm, x=\"Recency\", y=\"Frequency\", hue='Cluster_No', fit_reg=False, legend=True, legend_out=True);","5103500b":"df_rfm_2 = prepare_rfm_base_dataframe(False)\n#df_rfm_2.drop(columns=[\"RecencyScore\",\"FrequencyScore\",\"MonetaryScore\",\"RFM_SCORE\",\"Segment\"])\nk_means_features_for_individual = [\"Recency\",\"Frequency\",\"Monetary\"]\ndf_rfm_2 = modify_for_k_means(df_rfm_2, k_means_features_for_individual)","f7e30408":"kmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k = (2,20))\nvisu.fit(df_rfm_2[k_means_features_for_individual])\nvisu.poof();","b1b7c623":"# 6 cluster ile modelimizi \u00e7al\u0131\u015ft\u0131yoruz\nrun_kmeans(df_rfm_2, k_means_features_for_individual, 5)","e1b4d5b7":"# Cluster gorsel\nsns.lmplot(data=df_rfm_2, x=\"Recency\", y=\"Frequency\", hue='Cluster_No', fit_reg=False, legend=True, legend_out=True);","cf582314":"df_rfm_final[[\"Cluster_No\", \"Monetary\"]].groupby([\"Cluster_No\"]).agg([\"mean\",\"count\",\"sum\"])","ea578415":"df_rfm_final[[\"Cluster_No\", \"Frequency\"]].groupby([\"Cluster_No\"]).agg([\"mean\",\"max\",\"min\",\"count\"])","7b11c67e":"df_rfm_final[[\"Cluster_No\", \"Recency\"]].groupby([\"Cluster_No\"]).agg([\"mean\",\"max\",\"min\",\"count\"])","a1b4f45d":"### **K-Means Application**"}}