{"cell_type":{"af392a08":"code","11e4e13c":"code","394f2c29":"code","f41e0201":"code","68fcd4c1":"code","5b4b068b":"code","c2dec322":"code","b27913ac":"code","00c5f7e0":"code","b3c58192":"code","e82769d9":"code","99a8b9b3":"code","32d57e0f":"code","330072a8":"code","e6715884":"code","479412bd":"code","103e794a":"code","593dc14b":"code","34fc74f7":"code","f38862aa":"code","a434020f":"code","9339a66c":"code","34a3b5c8":"markdown","57956b7a":"markdown","b61da201":"markdown","de12d5bf":"markdown","a9b77d2c":"markdown","2f9071ef":"markdown","15f63d5b":"markdown","b3e00c1c":"markdown","cb21d3a2":"markdown","95ed49a5":"markdown","789274d8":"markdown","65536fff":"markdown","047d30da":"markdown","28053e31":"markdown","318f6693":"markdown","232b232f":"markdown","4d904b7a":"markdown","a8e55353":"markdown"},"source":{"af392a08":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","11e4e13c":"os.listdir('..\/input\/volcanoes_train\/')\ntrain_images = pd.read_csv('..\/input\/volcanoes_train\/train_images.csv', header = None)\ntrain_labels = pd.read_csv('..\/input\/volcanoes_train\/train_labels.csv')\ntest_images = pd.read_csv('..\/input\/volcanoes_test\/test_images.csv', header = None)\ntest_labels = pd.read_csv('..\/input\/volcanoes_test\/test_labels.csv')\ntrain_images.shape, train_labels.shape","394f2c29":"train_images.head()","f41e0201":"train_labels.head()","68fcd4c1":"train_counts = train_labels['Volcano?'].value_counts()\ntest_counts = test_labels['Volcano?'].value_counts()\n\nplt.figure(figsize = (8,4))\nplt.subplot(121)\nsns.barplot(train_counts.index, train_counts.values)\nplt.title('volcanos in training set')\nplt.subplot(122)\nsns.barplot(test_counts.index, test_counts.values)\nplt.title('volcanos in testing set')\n","5b4b068b":"pos_samples = train_images[train_labels['Volcano?'] == 1].sample(5)\nneg_samples = train_images[train_labels['Volcano?'] == 0].sample(5)\n\nplt.subplots(figsize = (15,6))\nfor i in range(5):\n    plt.subplot(2,5,i+1)\n    plt.imshow(pos_samples.iloc[i,:].values.reshape((110, 110)), cmap = 'gray')\n    if i == 0: plt.ylabel('Volcano')\nfor i in range(5):\n    plt.subplot(2,5,i+6)\n    if i == 0: plt.ylabel('No Volcano')\n    plt.imshow(neg_samples.iloc[i,:].values.reshape((110,110)), cmap = 'gray')","c2dec322":"Xtrain_raw = train_images\/256\nytrain_raw = train_labels['Volcano?']\nXtest_raw = test_images\/256\nytest_raw = test_labels['Volcano?']","b27913ac":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nXtrain, Xvali, ytrain, yvali = train_test_split(Xtrain_raw, ytrain_raw, test_size = 0.2, random_state = 3)\nXtest, ytest = Xtest_raw, ytest_raw\nmodelLR = LogisticRegression()\n\nfrom time import time\nstart = time()\nmodelLR.fit(Xtrain, ytrain)\nend = time()\nprint('training time: {} mins.'.format((end-start)\/60))","00c5f7e0":"from sklearn.metrics import classification_report\npredVali = modelLR.predict(Xvali)\npredTest = modelLR.predict(Xtest)\nprint('validation report:','\\n',classification_report(yvali, predVali))\nprint('testing report:', '\\n', classification_report(ytest, predTest))","b3c58192":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, MaxPool2D, Dropout","e82769d9":"#  can be used to fix the random seed to get reproducable result\n# from numpy.random import seed\n# from tensorflow import set_random_seed\n# seed(42)\n# set_random_seed(42)","99a8b9b3":"img_rows, img_cols = 110, 110\n\nX = Xtrain_raw.values.reshape((-1, img_rows, img_cols, 1))\ny = ytrain_raw.values\nX_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size = 0.2, random_state = 3)\n\nX_test = Xtest_raw.values.reshape((-1, img_rows, img_cols, 1))\ny_test = ytest_raw.values\n\n","32d57e0f":"# kernel_initializer can be tuned for the first conv2D layer\ninit = keras.initializers.RandomNormal(mean=0, stddev=0.1 )\nmodelCNN1 = Sequential()\nmodelCNN1.add(Conv2D(6, kernel_size = (3,3),kernel_initializer=init, activation = 'relu', input_shape = (img_rows, img_cols, 1)))\nmodelCNN1.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN1.add(Dropout(0.5))\nmodelCNN1.add(Conv2D(12, kernel_size = (3,3), activation = 'relu'))\nmodelCNN1.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN1.add(Dropout(0.5))\nmodelCNN1.add(Conv2D(24, kernel_size = (3,3), activation = 'relu'))\nmodelCNN1.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN1.add(Dropout(0.5))\nmodelCNN1.add(Flatten())\nmodelCNN1.add(Dense(1, activation = 'sigmoid'))\n\nmodelCNN1.summary()","330072a8":"# the line bolow can be used for tuning the adam optimizer, e.g. different initial learning rate\n# adam = keras.optimizers.Adam(lr=1e-6, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodelCNN1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n# the callBack parameter can be added to model.fit as 'callbacks = [callBack]' for early termination\nfrom keras.callbacks import EarlyStopping\ncallBack = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='auto')\n\n\ndef reset_weights(model):\n    session = keras.backend.get_session()\n    for layer in model.layers: \n        if hasattr(layer, 'kernel_initializer'):\n            layer.kernel.initializer.run(session=session)\n\nepochs = 100\nbatch_size = 64\n                        \nreset_weights(modelCNN1)            \nhistory = modelCNN1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n                        validation_data=(X_vali, y_vali),\n                        callbacks=[callBack]\n                       )","e6715884":"def report(model):\n    predVali = model.predict_classes(X_vali)\n    predTest = model.predict_classes(X_test)\n    print('validation report:','\\n',classification_report(y_vali, predVali))\n    print('validation accuracy:', accuracy_score(y_vali, predVali))\n    print('testing report:', '\\n', classification_report(y_test, predTest))\n    print('test accuracy:', accuracy_score(y_test, predTest))\n\ndef plotLearningCurves(history):\n    fig, ax = plt.subplots(1,2, figsize = (14,6))\n    ax[0].plot(history.epoch, history.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history.epoch, history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    ax[0].legend(loc='best', shadow=True)\n    ax[0].set_title('loss vs epoch')\n\n    ax[1].plot(history.epoch, history.history['acc'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history.epoch, history.history['val_acc'], color='r',label=\"Validation accuracy\")\n    ax[1].legend(loc='best', shadow=True)\n    ax[1].set_title('accuracy vs epoch')\n\nplotLearningCurves(history)    \nreport(modelCNN1)","479412bd":"modelCNN2 = keras.models.clone_model(modelCNN1)\nmodelCNN2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nreset_weights(modelCNN2)\n\n# the block below computes the class weights from the training set\nfrom collections import Counter\ncounter = Counter(y_train) \nmax_val = float(max(counter.values()))       \nclass_weight = {class_id : max_val\/num_images for class_id, num_images in counter.items()}\n\nepochs = 80\nbatch_size = 64\nhistory2 = modelCNN2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n                         validation_data=(X_vali, y_vali),\n                         # callbacks=[callBack],\n                         class_weight = class_weight\n                        )","103e794a":"plotLearningCurves(history2)\nreport(modelCNN2)","593dc14b":"from keras.preprocessing.image import ImageDataGenerator\n\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = False, # Randomly zoom image \n        width_shift_range= False,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range= False,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\n\ndatagen.fit(X_train)\ngenerator = datagen.flow(X_train, y_train, batch_size= batch_size)\n","34fc74f7":"modelCNN3 = keras.models.clone_model(modelCNN1)\nmodelCNN3.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nepochs = 60\nreset_weights(modelCNN3)\nhistory3 = modelCNN3.fit_generator(generator,epochs = epochs, validation_data = (X_vali,y_vali),\n                                   class_weight = class_weight,\n                                   #callbacks=[callBack]\n                                  )","f38862aa":"plotLearningCurves(history3)\nreport(modelCNN3)","a434020f":"init = keras.initializers.RandomNormal(mean=0, stddev=0.1 )\nmodelCNN4 = Sequential()\nmodelCNN4.add(Conv2D(32, kernel_size = (3,3),kernel_initializer=init, activation = 'relu', input_shape = (img_rows, img_cols, 1)))\nmodelCNN4.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN4.add(Dropout(0.5))\nmodelCNN4.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\nmodelCNN4.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN4.add(Dropout(0.5))\nmodelCNN4.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\nmodelCNN4.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN4.add(Dropout(0.5))\nmodelCNN4.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\nmodelCNN4.add(MaxPool2D(pool_size=(2,2), strides=2))\nmodelCNN4.add(Dropout(0.5))\nmodelCNN4.add(Flatten())\nmodelCNN4.add(Dense(1, activation = 'sigmoid'))\n\nmodelCNN4.summary()\nmodelCNN4.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nreset_weights(modelCNN4)\nepochs = 80\nbatch_size = 64\nhistory4 = modelCNN4.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n                         validation_data=(X_vali, y_vali),\n                         callbacks=[callBack],\n                         class_weight = class_weight\n                        )","9339a66c":"plotLearningCurves(history4)\nreport(modelCNN4)","34a3b5c8":"Model 4 achieves near 0.97 accuracy and the recall rates are above 0.9. No overfitting yet. ","57956b7a":"Examine the result from logistic regression:\n\nThe accuracy score is good (>0.9), however a lot of it is contributed from the imbalance of the data, the recall score is only 0.59.","b61da201":"Let's try to use image augumentation to increase the training data.","de12d5bf":"Although the accuracy did not increase much,  the recall rate for volcano increased a lot, which I consider a great improvement compared to the previous two models. Looking at the curve it seems like there is still a small room to improve modelCNN2.","a9b77d2c":"### Pixel Normalization\nWhen working with images, a generally good idea is to normalize the pixel values to between 0 and 1. In this case, divide the pixel values by 256.","2f9071ef":"## Model","15f63d5b":"Let's Evaluate the result from CNN model by looking at the learning curve and classification report. Both the accuracy and recall improved.","b3e00c1c":"So for model3 with augumented data, I got similar result from model2, contray to some other kernals. ","cb21d3a2":"Notice our label is not balanced, let's give the class different weights to account for the imbalance","95ed49a5":"### simple logistic regression","789274d8":"build up the model with 3 convolution layers, each followed by a maxpooling and a drop out","65536fff":"The last three labels are only valid if the is a volcano in the photo. \nFor this project, we are focusing on predicting where there is a volcano, i.e. the label 'Volcano?'\n\nNow let's look at the label distribution","047d30da":"## A simple CNN model","28053e31":"## Pre-Process Data","318f6693":"## Import and Observe data","232b232f":"Plot a few photos with different labels. We can also see some 'no volvano' images are corrupted. We'll leave them as is for now.","4d904b7a":"prepare the image data to appropriate dimention, and split the training data to train and validation data.","a8e55353":"### CNN model 4, adding model complexity"}}