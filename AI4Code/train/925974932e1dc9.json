{"cell_type":{"f23ac30a":"code","e9b515ef":"code","62ea1f70":"code","e00b9f02":"code","1c8eeb29":"code","a5e0aa1c":"code","9dcedf51":"code","c15203f8":"code","ae0a096f":"code","b94c3816":"markdown","23af71cf":"markdown","4758c1fc":"markdown","92620e4d":"markdown","fd784006":"markdown"},"source":{"f23ac30a":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\n\nimport urllib\nimport cv2","e9b515ef":"import torch\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader","62ea1f70":"base_path = '..\/input\/google-landmarks-dataset\/'\n\n# load train data\ndf_train = pd.read_csv(base_path + 'train.csv')\nprint(df_train.head())\n\n# load boxes data and merge into one\ndf_boxes_split1 = pd.read_csv(base_path + 'boxes_split1.csv')\ndf_boxes_split2 = pd.read_csv(base_path + 'boxes_split2.csv')\ndf_boxes = pd.concat([df_boxes_split1, df_boxes_split2])\n\nprint(df_boxes.head())","e00b9f02":"# merge train and boxes on id\ndf_train = pd.merge(df_train, df_boxes, on='id',  how='right')\ndf_train.head()","1c8eeb29":"def get_transform(train):\n    transforms = []\n    if train:\n        # random horizontal flip with 50% probability\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","a5e0aa1c":"class GoogleLandmarks(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.dim = (512, 512)\n        self.transforms = transforms\n        self.ids = np.unique(df['id'].values)\n        self.ids_dic = {k:v for k,v in enumerate(self.ids)}\n    \n    def url_to_image(self, url, dim):\n        try:\n            resp = urllib.request.urlopen(url)\n        except:\n            return np.array([])\n        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n        if(image.size != 0):\n            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n            image = Image.fromarray(np.uint8(image))\n            if(image):\n                image = self.transforms(image)\n        return image\n    \n    def get_rect(self, boxes):\n        try:\n            y = boxes[0]\n            x = boxes[1]\n            h = boxes[2] - boxes[0]\n            w = boxes[3] - boxes[1]\n        except:\n            return None\n        return plt.Rectangle((x, y), w, h, color='y', alpha=0.3)\n    \n    def draw_bbox(self, img, rect):\n        fig, ax = plt.subplots() \n        plt.imshow(img)\n        if(rect):\n            ax.add_patch(rect)\n    \n    def format_boxes(self, boxes, dim):\n        return (np.array(boxes.split(' ')).astype(np.float32) * dim[0]).astype(np.int64)\n    \n    def __getitem__(self, idx):\n        id = self.ids_dic[idx]\n        url = self.df[self.df.id == id].url.values[0]\n        boxes = self.df[self.df.id == id].box.values[0]\n        \n        \n        # format boxes\n        boxes = self.format_boxes(boxes, self.dim)\n        \n        target = {}\n        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.int64)\n        target[\"labels\"] = torch.ones((1,), dtype=torch.int64)\n        target[\"image_id\"] = torch.tensor([idx])\n        target[\"area\"] = (boxes[3] - boxes[1]) * (boxes[2] - boxes[0])\n        target[\"iscrowd\"] = torch.zeros((1,), dtype=torch.int64)\n        \n        image = self.url_to_image(url, self.dim)\n        \n        if(image is None):\n            return None, None\n \n        return image, target\n        \n    def __len__(self):\n        return len(self.ids)","9dcedf51":"google_ds = GoogleLandmarks(df_train, get_transform(train=True))","c15203f8":"image, target = google_ds[2]","ae0a096f":"rect = google_ds.get_rect(target['boxes'])\ngoogle_ds.draw_bbox(image, rect)","b94c3816":"# Google Landmarks Startup Notebook","23af71cf":"# Google Landmarks Dataset","4758c1fc":"# Draw an image with Bounding Boxes","92620e4d":"# Prepare Data","fd784006":"# Augmentations"}}