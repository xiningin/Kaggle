{"cell_type":{"557c1100":"code","1e5de3d4":"code","02c6f452":"code","52cdd9f7":"code","fc5a3ebe":"code","848b720d":"code","ffa5ab99":"code","83b3690e":"code","acffd6d5":"code","04ea707d":"code","d00503d5":"code","1a09c05e":"code","eedc3187":"code","a5abfc52":"code","26dd578f":"code","bffe1eff":"code","8d7269c1":"code","f09fab3a":"code","4033dd46":"code","99377ca5":"code","00f0b409":"code","2eddccb4":"markdown","91aa527d":"markdown","b8f05d00":"markdown","2d49342c":"markdown","f7be9b43":"markdown","0fef61ff":"markdown","ad8d3486":"markdown","eb635932":"markdown","1de9cfce":"markdown","09e7fbc5":"markdown"},"source":{"557c1100":"#import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,r2_score   # for mean ,vairance and diff from pred and actual\nfrom sklearn.metrics import accuracy_score\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","1e5de3d4":"!ls \"..\/input\/\"","02c6f452":"#import data set\ndf=pd.read_csv('..\/input\/automobile-from-california\/imports-85.csv')\ndf.head()\n","52cdd9f7":"# print bool if any  index in train set have null value every rows = df['gas'].isnull()\n# df.gas.isnull().any() print if exist at least one value is null \n\ndf.gas.isnull()","fc5a3ebe":"df.isnull().any()  # for every colum print bool if exist at least one value is null\n\ndf.dtypes  # print every data type in data set object rep ---> string not int , not float\n","848b720d":"# Exist '?' in columns in dataset .. so add columns in dataset from description file  \n\ncol=['symboling','normalized_losses','make','fuel_type','aspiration','num_of_doors','body_style','drive_wheels','engine_locatio','wheel_base'\n     ,'length','width','height','curb_weight','engine_type','num_of_cylinders','engine_size','fuel_system'\n     ,'bore','stroke','compression_ratio','horsepower','peak_rpm','city_mpg','highway_mpg','price']\n","ffa5ab99":"df.index\n# header -1 remove header na_values='?' replace  ? by NAN and add cloum(names) to headrer\ndf=pd.read_csv('..\/input\/automobile-from-california\/imports-85.csv',header =None,na_values='?',names=col) ","83b3690e":"df.head()","acffd6d5":"print(df.isnull().any())\n#df.columns[df.isnull().any]   print columns that has misssing data \"NAN\"\nprint(df[df.columns[df.isnull().any()]].isnull().sum()) # print the summation if train points has missing values","04ea707d":"# print every missing data with her column and row \ndf[df.isnull().any(axis=1)][df.columns[df.isnull().any()]] ","d00503d5":"df.drop(['make','symboling','normalized_losses'],axis=1,inplace=True)   #drop un unsed values in data \ndf.head()","1a09c05e":"df[df.num_of_doors.isnull()] # print missing values bt row , column in num_of_doors\ndf.num_of_doors[df.body_style=='sedan'].value_counts()   #take value of another attribute and get high count of num_of_doors \ndf.loc[27,'num_of_doors']='four'   #change the value of missing data to the highest value predict in another attribute of data\ndf.loc[63,'num_of_doors']='four'","eedc3187":"df[df.bore.isnull()]\ndf.bore.fillna(df.bore.mean(),inplace=True) #replave the missing data by mean of bore by using fillna method\n\ndf[df.stroke.isnull()]         #the change missing data to depenent data only not to y\n \ndf.stroke.fillna(df.stroke.mean(),inplace=True)\n\ndf.horsepower.fillna(df.horsepower.mean(),inplace=True)\n\ndf.peak_rpm.fillna(df.peak_rpm.mean(),inplace=True)\n\ndf.drop(df[df.price.isnull()].index,axis=0,inplace=True)      #if exist any missing data in Y delte it and delet trainging point all\n\ndf[df.columns[df.isnull().any()]].isnull().sum() #this line to check if exist any missing data or not\n","a5abfc52":"# first method\ndf.num_of_cylinders.value_counts()      #for num_of_cylinders\ndf.loc[df.num_of_cylinders=='two','num_of_cylinders']=2\ndf.loc[df.num_of_cylinders=='four','num_of_cylinders']=4\ndf.loc[df.num_of_cylinders=='five','num_of_cylinders']=5\ndf.loc[df.num_of_cylinders=='six','num_of_cylinders']=6\ndf.loc[df.num_of_cylinders=='seven','num_of_cylinders']=7\ndf.loc[df.num_of_cylinders=='eight','num_of_cylinders']=8\ndf.loc[df.num_of_cylinders=='twelve','num_of_cylinders']=12\ndf.loc[df.num_of_cylinders=='three','num_of_cylinders']=3\n","26dd578f":"#Seond method\ncol=['body_style','drive_wheels','engine_locatio','engine_type','fuel_system','num_of_doors','aspiration',\n     'fuel_type']\ndf=pd.get_dummies(df,columns=col,drop_first=True)\n","bffe1eff":"train,test=train_test_split(df,test_size=0.2,random_state=0)","8d7269c1":"y_train=train.price\ny_test=test.price\ntrain.drop('price',axis=1,inplace=True)\ntest.drop('price',axis=1,inplace=True)","f09fab3a":"regressor=LinearRegression()\nregressor.fit(train,y_train)\n\ny_pred=regressor.predict(test)","4033dd46":"actual_data=np.array(y_test)\nfor i in range(len(y_pred)):\n    expl=((actual_data[i]-y_pred[i])\/actual_data[i])*100.0\n    print('Actual Value ${:,.2f},Predicted value ${:,.2f} (%{:,.2f})'.format(actual_data[i],y_pred[i],expl))","99377ca5":"#calc perforamnce of Data in train and test\nr_square=r2_score(y_test,y_pred)*100.0  #in LinearRegression not exist accuracy exist the r2_square to calc diff**2 between predict and actual \nr_train=r2_score(y_train,regressor.predict(train))*100.0\nprint('Accuracy of Test,Predict  Data  is %{:,.2f}'.format(r_square))\nprint('Accuracy of Train Data is %{:,.2f}'.format(r_train))","00f0b409":"plt.scatter(y_pred,y_test,color='blue')\nplt.title('Automobile Data set represntation')\nplt.show()","2eddccb4":"####   Encoding the text 'Categorical values'  \n1. first method by your hand\n2. second method by get dummies from pandas lib","91aa527d":"#### droping not necessary colummns(Attributes)","b8f05d00":"### missing data and change it by good value to predict perfect  [](http:\/\/)","2d49342c":"### Make Model LinearRegression","f7be9b43":"#### This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process \"symboling\". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.\n\n#### The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports\/speciality, etc...), and represents the average loss per car per year.","0fef61ff":"#### Exploration Dataset to know null values","ad8d3486":"### calc perforamnce of Data in train and test","eb635932":"### divide trainging set to train and test","1de9cfce":"### plotting data","09e7fbc5":"#### Second step remove NaN values from Dataset with :\n1. by Mean \n2. by remove row from data\n3. take random values from dataset column"}}