{"cell_type":{"c9d04b98":"code","351b33be":"code","20dffd0b":"code","e1d141ff":"code","dcb3c558":"code","6c88d238":"code","653262d8":"code","e55146a6":"code","35de33c8":"code","606db234":"code","d86a040b":"code","052c7e71":"code","6c990927":"code","d36f05fa":"code","331e71b9":"code","7f9091a8":"markdown","520c7717":"markdown","1c93c02c":"markdown","7778f8c8":"markdown","c3aa68e0":"markdown","8794d9cf":"markdown","a9cc1f9a":"markdown","37a5f12b":"markdown","0df1aba5":"markdown","abc1c75c":"markdown"},"source":{"c9d04b98":"import pandas as pd\nimport numpy as np\nimport json\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport optuna","351b33be":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ntrain.head()","20dffd0b":"%%time\ndef join_list(tab):\n    return \" \".join(tab)\n\ndef transform_keyword(word) :\n    return word.split('%20')\n\ndef transform_text(text):    \n    text = re.sub(r'(&amp;|&gt;|&lt;)', \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r'\\t', ' ', text)\n    text = re.sub(r'\\n', ' ', text)\n    text = re.sub(r'https?:\/\/\\S+|www\\.\\S+', ' ',text)\n    text = re.sub(r'@\\S{0,}', ' USER ', text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r'\\b(USER)( \\1\\b)+', r'\\1', text)\n    text = re.sub(r'([a-zA-Z])\\1{1,}', r'\\1\\1', text)\n    text = re.sub(r\"htt\\S{0,}\", \" \", text)\n    text = re.sub(r\"[^a-zA-Z\\d\\s]\", \" \", text)\n    text = re.sub(r'^\\d\\S{0,}| \\d\\S{0,}| \\d\\S{0,}$', ' NUMBER ', text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r'\\b(NUMBER)( \\1\\b)+', r'\\1', text)\n    text = re.sub(r\"[0-9]\", \" \", text)\n    text = text.strip()\n    text = re.sub(r' via\\s{1,}USER$', ' ', text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = text.strip()\n    return text\n\ntrain.text = train.text.apply(join_list)\ntest.text = test.text.apply(join_list)\n\ntrain.keyword = train.keyword.fillna(\" \")\ntest.keyword = test.keyword.fillna(\" \")\n\ntrain.keyword = train.keyword.apply(transform_keyword).apply(join_list)\ntest.keyword = test.keyword.apply(transform_keyword).apply(join_list)\n\ntrain.text = train.keyword + \" \" + train.text\ntest.text = test.keyword + \" \" + test.text\n\ntrain.text = train.text.apply(transform_text)\ntest.text = test.text.apply(transform_text)","e1d141ff":"x_train = train.text\nx_test = test.text\ny_train = train.target","dcb3c558":"%%time\ntfv = TfidfVectorizer(strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1, stop_words = 'english')\n\ntfv.fit(pd.concat([x_train, x_test]))\nxtrain_tfv =  tfv.transform(x_train) \nxtest_tfv =  tfv.transform(x_test) \n\nxtrain_tfv.shape, xtest_tfv.shape","6c88d238":"x_train_sub, x_val, y_train_sub, y_val = train_test_split(xtrain_tfv, y_train, random_state = 42, test_size=0.20)","653262d8":"def objective(trial):\n    from sklearn.svm import SVC\n    params = {\n        'C': trial.suggest_loguniform('C', 1e-4, 1e4),\n        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n        'kernel': trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n    }\n\n    svc = SVC(**params)\n    svc.fit(x_train_sub, y_train_sub)\n    return svc.score(x_val, y_val)","e55146a6":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"maximize\",\n                            pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)","35de33c8":"print(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","606db234":"!pip install scikit-learn-intelex --progress-bar off >> \/tmp\/pip_sklearnex.log","d86a040b":"from sklearnex import patch_sklearn\npatch_sklearn()","052c7e71":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"maximize\",\n                            pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)","6c990927":"print(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","d36f05fa":"from sklearn.svm import SVC\nbest_svc = SVC(**study.best_params)\nbest_svc.fit(xtrain_tfv, y_train)\ny_pred_test = best_svc.predict(xtest_tfv)","331e71b9":"sub = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\nsub[\"target\"] = y_pred_test\nsub.to_csv(\"submission_scikit-learn-intelex.csv\",index=False)","7f9091a8":"# \ud83d\ude80 Optimizing Kaggle kernels using Intel(R) Extension for Scikit-learn*\nFor classical machine learning algorithms, we often use the most popular Python library, scikit-learn. We use it to fit models and search for optimal parameters, but\u202fscikit-learn\u202fsometimes works for hours, if not days. Speeding up this process is something anyone who uses scikit-learn would be interested in.\n\nI want to show you how to get results faster without changing the code. To do this, we will use another Python library,\u202f**[scikit-learn-intelex](https:\/\/github.com\/intel\/scikit-learn-intelex)**. It accelerates scikit-learn and does not require you changing the code written for scikit-learn.\n\nI will show you how to speed up your kernel from **45 minutes to 2 minutes** without changes of your code!\n\n# \ud83d\udcd8 Problem Statement\nWe want to predict which Tweets are about real disasters and which ones are not.\n\nMain steps in this kernel:\n\n- Preprocessing data\n- TF-IDF\n- Search optmimal parameters for SVC algorithm from **scikit-learn** using **optuna**\n- Search optmimal parameters for SVC algorithm from **scikit-learn-intelex** using **optuna**\n- Fit final model and submit result","520c7717":"# \u23f3 Search optmimal parameters for SVC algorithm from scikit-learn using optuna","1c93c02c":"# \u26a1 Search optmimal parameters for SVC algorithm from scikit-learn-intelex using optuna\n\n Let's try to use scikit-learn-intelex. First, download it:","7778f8c8":"## \ud83d\udd0d TF-IDF","c3aa68e0":"# \ud83d\udca1 Fit final model and submit result","8794d9cf":"# \ud83d\udcdc Conclusions\nWith scikit-learn-intelex patching you can:\n\n- Use your scikit-learn code for training and inference without modification.\n- Train and predict scikit-learn models **up to 25 times faster**.\n- Get the same quality of predictions as other tested frameworks.\n\n*Please, upvote if you like.*","a9cc1f9a":"To get optimizations, patch scikit-learn using Intel(R) Extension:","37a5f12b":"# \ud83d\udccb Preprocessing data","0df1aba5":"The search optimal parameters for SVM model took almost **45 minutes**.","abc1c75c":"This time, the search optimal parameters took a **little over two minutes**, which saved us **almost 45 minutes**. Let\u2019s make sure that the quality has not changed!"}}