{"cell_type":{"71236c9e":"code","533f8883":"code","4fe3c7cf":"code","b8bc7b2c":"code","9ed1c7c0":"code","3f5238a9":"code","f2fc9d79":"code","c39d750c":"code","3c1194b8":"code","075b8a27":"code","fae499c1":"code","3f37b522":"code","a36f37de":"code","3f1121bd":"code","be3639db":"code","7dcb3d6c":"code","c882c77c":"code","6647ac48":"code","461cb427":"markdown","d933dc7e":"markdown","ddbd4fb9":"markdown","e708e58a":"markdown","98765fc5":"markdown","ac9bfcdc":"markdown","198cc1b2":"markdown","8035d442":"markdown","86e8321f":"markdown","d713543e":"markdown","0e74bf12":"markdown","ec4dec2d":"markdown","b0ce22ac":"markdown","98ed204e":"markdown","20c9003f":"markdown","448a409e":"markdown","851da283":"markdown","d3e927c8":"markdown","b51511e0":"markdown","91a61860":"markdown","bbd385a6":"markdown","1cb9e844":"markdown","b550df55":"markdown","81a5c334":"markdown","6a9bc4af":"markdown","06c8a0e5":"markdown","908a0a7f":"markdown","522b132f":"markdown","df5cfd50":"markdown","762d1c59":"markdown"},"source":{"71236c9e":"import pandas as pd\nimport numpy as np\nimport sklearn","533f8883":"pd.options.display.float_format = lambda x: f' {x:,.2f}'\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4fe3c7cf":"titanic = pd.read_csv('..\/input\/train.csv', index_col='PassengerId')\ntitanic.head()","b8bc7b2c":"titanic.corr()","9ed1c7c0":"X = titanic['Fare'].values\nX[:5]","3f5238a9":"y = titanic['Survived'].values\ny[:5]","f2fc9d79":"X.ndim, y.ndim","c39d750c":"X = X.reshape(-1, 1)\nX.ndim, y.ndim","3c1194b8":"from sklearn.linear_model import LogisticRegression\nlogr = LogisticRegression()\nlogr.fit(X, y)","075b8a27":"titanic_test_data = pd.read_csv('..\/input\/test.csv', index_col='PassengerId')\ntitanic_test_data.head()","fae499c1":"titanic_test_data['Fare'].head()","3f37b522":"titanic_test_data['Fare'].isna().sum()","a36f37de":"titanic_test_data[['Fare']] = titanic_test_data[['Fare']].fillna(titanic_test_data['Fare'].mean())\ntitanic_test_data['Fare'].isna().sum()","3f1121bd":"X_test = titanic_test_data['Fare'].values\nX_test[:5]","be3639db":"X_test = X_test.reshape(-1, 1)\nX_test[:5]","7dcb3d6c":"predictions = logr.predict(X_test).reshape(-1,1)\npredictions[:5]","c882c77c":"dfpredictions = pd.DataFrame(predictions, index=titanic_test_data.index)\ndfpredictions.head(15)","6647ac48":"dfpredictions = dfpredictions.rename(columns={0:'Survived'}).to_csv('submission.csv', header=True)","461cb427":"NOW, we'll be okay.","d933dc7e":"## Preliminary Code","ddbd4fb9":"It looks like what we expect. So now we can focus on just the bits we need.","e708e58a":"***\n<a id='eda_viz'><\/a>","98765fc5":"From this it looks like `Fare` and `Pclass` have the most possibility. I'll choose `Fare` since it's continuous, more interesting and positive. *#OptimismCounts*","ac9bfcdc":"ARG! There's ONE little missing value. And that one will put a monkey in our wrench. So let's fix it.\n\nI'm going to fill in that one value with the average of all the values. I may give more thought to this if there were a lot of these, but only one - I could just put in 42 and move on, almost.","198cc1b2":"And these are my personal prettifiers (not required): ","8035d442":"[jump back to the top](#top)","86e8321f":"## Choose a Feature","d713543e":"***\n<a id='top'><\/a>","0e74bf12":"I used the `reshape` method to get it ready to be put into a dataframe.","ec4dec2d":"And when it's submitted to the Kaggle competition we get a 64.5% accuracy!","b0ce22ac":"In order to decide which single feature to use, I can look at the correlation of `Survived` to the numeric features.","98ed204e":"Recall scikit-learn has a hinky stick when it comes to the input feature array - it pouts if you don't have a 2 dimensional object. ","20c9003f":"## Load the _Titanic_ Dataset","448a409e":"And I need to isolate my target as well. That, of course, is `Survived`.","851da283":"## Basic Machine Learning","d3e927c8":"### Testing the Model","b51511e0":"## Meanings of Variables","91a61860":"![Screen%20Shot%202018-10-19%20at%202.44.16%20PM.png](attachment:Screen%20Shot%202018-10-19%20at%202.44.16%20PM.png)","bbd385a6":"And that will fix it.","1cb9e844":"We'll start off by segregating the feature set, `Fare`.","b550df55":"So lets push this round peg into that square hole and reshape X:","81a5c334":"First to get the test data in and take a peek at it. (Just in case I accidentally read in something totally unrelated, I'd like to know about the error early.)","6a9bc4af":"Here are the dependencies:","06c8a0e5":"To understand what those funky words are, let's look at the variable notes given on Kaggle.\n\n`pclass`: A proxy for socio-economic status (SES)\n\n1st = Upper <br \/>\n2nd = Middle<br \/>\n3rd = Lower<br \/>\n\n`age`: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n`sibsp`: The dataset defines family relations in this way...<br \/>\nSibling = brother, sister, stepbrother, stepsister<br \/>\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n`parch`: The dataset defines family relations in this way...<br \/>\nParent = mother, father<br \/>\nChild = daughter, son, stepdaughter, stepson\n\nSome children travelled only with a nanny, therefore parch=0 for them.","908a0a7f":"And this next compound command will\n1. Change the prediction column name to `Survived`, and\n2. Save it to a `*.csv` file.\n3. Include `PassengerID` and `Survived` on the `*.csv` file.","522b132f":"We're almost ready to roll. Don't forget to put the feature set into a 2-d shape.","df5cfd50":"In the training data, `Fare` had no missing values. But we can't assume that to be true for the test data as well. So let's check it.","762d1c59":"# <center>Titanic Survivors Prediction with One Feature<\/center>\n### <center>by Bon Crowder<\/center>"}}