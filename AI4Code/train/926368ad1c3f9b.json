{"cell_type":{"b7b6a815":"code","111408e5":"code","ac97a729":"code","6b835c86":"code","487a10cd":"code","d7c48e7d":"code","42d4c178":"code","3facdda8":"code","155dec29":"code","65c51cee":"code","19d7aab8":"code","b5be9b38":"code","6e1acd06":"code","32116e65":"code","f3c6ffca":"code","7721cef0":"code","fe7e9db1":"code","4081a395":"code","f677037e":"code","f814c3d8":"code","290d7feb":"code","bd9a9238":"code","805f36c0":"code","ab40e9ce":"code","7f0e4408":"code","f0c09986":"markdown","7ccfc521":"markdown","df7a9ffd":"markdown","533ef2af":"markdown","6c45f08e":"markdown","fe847c6c":"markdown","485f6cc2":"markdown","00ac8c86":"markdown","3563c26c":"markdown","2abdf7fd":"markdown","9099d31f":"markdown","6453beae":"markdown","5a6469b4":"markdown","1839ef2a":"markdown","e004aa6b":"markdown","b7a3999f":"markdown","d1f32fbb":"markdown","0c1e66ef":"markdown","73533cdb":"markdown","8d4e8d07":"markdown","705b4a8f":"markdown","37bf65a2":"markdown","0099b215":"markdown","3a23d7a8":"markdown","c2af961e":"markdown","7cd12560":"markdown","161d2513":"markdown","8a5a92c3":"markdown","355ac30a":"markdown","2fa13312":"markdown","85ad3f42":"markdown","61256a4c":"markdown","b5bf143d":"markdown","58581c3a":"markdown"},"source":{"b7b6a815":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\nimport torch\nfrom torchtext.data import get_tokenizer\ntokenizer = get_tokenizer(\"basic_english\")\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader","111408e5":"glove = dict()\nembedding_dim = 100\n\nwith open('\/kaggle\/input\/glove6b100dtxt\/glove.6B.100d.txt') as fp:\n    for line in fp.readlines():\n        records = line.split()\n        word = records[0]\n        vector_dimensions = np.asarray(records[1:], dtype='float32')\n        glove [word] = vector_dimensions","ac97a729":"is_cuda = torch.cuda.is_available()","6b835c86":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","487a10cd":"device","d7c48e7d":"if is_cuda:\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")","42d4c178":"df = pd.read_csv(\"\/kaggle\/input\/music-dataset-1950-to-2019\/tcc_ceds_music.csv\")\ndf.head()","3facdda8":"df = df[df.len > 4]","155dec29":"df[\"topic\"].value_counts(normalize=True)","65c51cee":"df = df[df['topic'] != 'feelings']","19d7aab8":"df[\"topic\"].value_counts()","b5be9b38":"lyrics = df[['lyrics']]\nlyrics['a'] = range(len(lyrics))\nlyrics = lyrics.set_index('a')\n\ntopic = df[['topic']]\ntopic = topic.replace(pd.unique(topic['topic']),range(len(pd.unique(topic['topic']))))\ntopic.head()","6e1acd06":"rus = RandomUnderSampler() \nlyrics, topic = rus.fit_resample(lyrics, topic)\nprint(topic.value_counts())","32116e65":"def tokens(data):\n    tokenized_data = []\n    for sentence in data:\n        sentence = tokenizer(sentence)\n        tokenized_data.append(sentence)\n    return tokenized_data\nlyrics = tokens(lyrics['lyrics'])\n\nprint(len(max(lyrics,key = len)))","f3c6ffca":"X_train, X_test, y_train, y_test = train_test_split(lyrics, topic, test_size=0.2, random_state=42)","7721cef0":"def embedd_list(lst):\n    embedded_tens = np.zeros((199, 100))\n    for i in range(199-len(lst),199):\n        try:\n         embedded_tens[i] = glove[lst[i-199+len(lst)]]\n        except:\n            pass       \n    return embedded_tens\nmap_object_train = map(embedd_list, X_train)\nX_train_embedded = list(map_object_train)\nX_train_embedded = np.stack(X_train_embedded)\ny_train = torch.from_numpy(y_train.values).to(device)\nmap_object_test = map(embedd_list, X_test)\nX_test_embedded = list(map_object_test)\nX_test_embedded = np.stack(X_test_embedded)\ny_test = torch.from_numpy(y_test.values).to(device)","fe7e9db1":"X_test_embedded = torch.from_numpy(X_test_embedded).to(device)\nX_train_embedded = torch.from_numpy(X_train_embedded).to(device)","4081a395":"X_train_embedded = X_train_embedded.view(len(X_train_embedded), 1, 199, 100).to(device)\nX_test_embedded = X_test_embedded.view(len(X_test_embedded), 1, 199, 100).to(device)","f677037e":"class CNN(nn.Module):\n    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n        super(CNN,self).__init__()\n        self.convs = nn.ModuleList([\n                                    nn.Conv2d(in_channels = 1, \n                                              out_channels = n_filters, \n                                              kernel_size = (fs, embedding_dim)) \n                                    for fs in filter_sizes\n                                    ])\n        self.linear = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, input):\n        conved = [F.relu(conv(input)).squeeze(3) for conv in self.convs]\n        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n        cat = self.dropout(torch.cat(pooled, dim = 1))\n        return self.linear(cat)","f814c3d8":"EMBEDDING_DIM = 100\nN_FILTERS = 100\nFILTER_SIZES = [2,3,4]\nOUTPUT_DIM = 8\nDROPOUT = 0.5\n\nmodel = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES,  OUTPUT_DIM, DROPOUT)\nmodel.to(device)","290d7feb":"def categorical_accuracy(preds, y):\n    top_pred = preds.argmax(1, keepdim = True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() \/ y.shape[0]\n    return acc","bd9a9238":"lr=10**-4\ncriterion = nn.CrossEntropyLoss()\ncriterion.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\ndef train_model(x,y,model, iterator, optimizer, criterion,batch):\n    costs = []\n    for epoch in range(iterator):\n      loader = DataLoader(TensorDataset(x,y), batch_size= batch)\n      for x_batch, y_batch in loader:\n        y_batch = y_batch.squeeze_()\n        y_pred = model(x_batch.float())\n        loss = criterion(y_pred,y_batch)\n        loss_num = loss.cpu().detach().numpy()\n        accuracy = categorical_accuracy(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n      costs.append(loss_num)\n      print('loss:'+str(loss_num)+' accuracy:'+str(accuracy.item()))\n    return costs","805f36c0":"train = train_model(X_train_embedded,y_train,model, 60, optimizer, criterion,16) ","ab40e9ce":"plt.plot(range(len(train)),train)\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.show()","7f0e4408":"def evaluate(x,y,model,batch,iterator):\n    epoch_acc = 0\n    model.eval()\n    with torch.no_grad():\n        for epoch in range(iterator):\n           loader = DataLoader(TensorDataset(x,y), batch_size= batch)\n           for x_batch, y_batch in loader:\n                predictions = model(x_batch.float())\n            \n                acc = categorical_accuracy(predictions, y_batch.squeeze_())\n           epoch_acc += acc.item()\n        \n    return epoch_acc \/ iterator\nprint(evaluate(X_test_embedded[:len(X_test)-1],y_test[:len(X_test)-1],model,32,25))","f0c09986":"**6.3 Defining an evaluation function and testing accuracy**","7ccfc521":"Checks and returns a Boolean True if a GPU is available, else it'll return False","df7a9ffd":"Load GloVe 100D embeddings","533ef2af":"Objective: generate a model, with the use of the pytorch library for famous songs, that understand their main topics","6c45f08e":"<a id=\"5\"><\/a> <br>\n# 5. Train-test split and embedding","fe847c6c":"Songs about feelings are less than 3% of the data, and the topic is ambiguous, it can be argued that sadness and love are also feeling, therefore those songs will be removed.","485f6cc2":"**5.1 Train-test split**","00ac8c86":"converting the embedded numpy arrays to torch tensor and saving tham in the gpu, and adding a fourth dimension in preparation for CNN","3563c26c":"we can see from the graph's descent, and high accuracy that the model was trained succesfuly. we exepct on the evalution accuracy of atleast 85%\n\nnext cell, I'll define an evalution function similar to the train function, but with no gradient descent","2abdf7fd":"the longest sentence has 199 words","9099d31f":"If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.","6453beae":"**1.1 Imported libraries** \ud83d\udcda","5a6469b4":"defining a train function with adam optimizer and categorical cross entropy criterion","1839ef2a":"defining an accuracy function for categorical cross entropy for multiple labels","e004aa6b":"**6.2 Defining a training function**","b7a3999f":"the topics are feeling-0, music-1, night\/time-2, obscene-3, romantic-4, sadness-5, violence-6, world\/life-7","d1f32fbb":"<a id=\"3\"><\/a> <br>\n# 3. Preprocessing","0c1e66ef":"1.1. Read and check the data from the music dataset","73533cdb":"**6.1 Defining a CNN model**","8d4e8d07":"embedding and padding all sentences to the length of 199","705b4a8f":"We can not understand the context of a song with less than 5 words, therefore they will be removed","37bf65a2":"<a id=\"4\"><\/a> <br>\n# 4. Tokenzation","0099b215":"**5.2 embedding**","3a23d7a8":"<a id=\"6\"><\/a> <br>\n# 6. Defining, training and testing a CNN model","c2af961e":"The data is unbalanced, sadaness and violence are approximately 4 times more prevalent than romantic and time. I'll use the undersampling method","7cd12560":"The embedding function doesn't give values for words which are not included in the glove file. This fact might hurt the accuracy","161d2513":"we'll use a CNN model with three conv2d layers with 2,3,4 filters respectively, in order to detect 2,3,4 words expression","8a5a92c3":"**1.2 defining glove dictionary**","355ac30a":"**conclusion**\nthe model predict the main topics of the songs with accuracy of 90%,which is good but not enough the missing words might had an impact on the result, or there some overfitting","2fa13312":"tokenizing the lyrics","85ad3f42":"<a id=\"1\"><\/a> <br>\n# 1. Libraries and functions","61256a4c":"<a id=\"2\"><\/a> <br>\n# 2. Setting gpu device","b5bf143d":"# **Table of contents**\n1. Libraries and functions\n2. Setting gpu device\n3. Preprocessing\n4. Tokenization\n5. Train-test split and embedding\n6. Defining, training and testing a CNN model","58581c3a":"creating dataframes for the lyrics and the topic and replacing the topics with integers for softmax activation"}}