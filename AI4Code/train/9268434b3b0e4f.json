{"cell_type":{"d9807020":"code","63a261a5":"code","ddf802a0":"code","6cdc1866":"code","8afe7552":"code","d0e8af7c":"code","76058c21":"code","6e65d494":"code","0e84bad1":"code","5ffbb646":"code","0735255b":"code","066f253e":"code","6b9c35df":"code","788f294d":"code","daba5c6c":"code","ab9115b0":"code","5455385f":"code","df319959":"code","ede0f986":"code","94851b22":"code","8530e141":"code","ba57c725":"markdown","c463fd3d":"markdown","0033fef0":"markdown","300f9d5c":"markdown","e155a581":"markdown","de751e4c":"markdown","65903c76":"markdown","68923e49":"markdown","8c0371e8":"markdown","9e293e96":"markdown"},"source":{"d9807020":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os,glob,re,math\n#from pathlib import Path\n\n#from tqdm import tqdm_notebook as tqdm\nimport cv2\nimport librosa\n#from itertools import islice\nimport matplotlib.pyplot as plt\n#from multiprocessing.pool import Pool\n#from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\nfrom scipy.signal import freqz\nimport warnings\nwarnings.filterwarnings('ignore')","63a261a5":"from librosa.display import waveplot","ddf802a0":"from scipy.signal import butter, lfilter\nfrom skimage.restoration import denoise_wavelet \nfrom scipy import signal","6cdc1866":"ROOT_DIR = '..\/input\/birdsong-recognition\/'\nTRAIN_AUDIO = f'{ROOT_DIR}\/train_audio'","8afe7552":"CLASS = os.listdir('..\/input\/birdsong-recognition\/train_audio')","d0e8af7c":"train_audio = glob.glob('..\/input\/birdsong-recognition\/train_audio\/*\/*.mp3')\ntrain_audio_1 =glob.glob('..\/input\/xeno-canto-bird-recordings-extended-a-m\/A-M\/*\/*.mp3')\ntrain_audio_2 = glob.glob('..\/input\/xeno-canto-bird-recordings-extended-n-z\/N-Z\/*\/*.mp3')","76058c21":"df = pd.read_csv('..\/input\/birdsong-recognition\/train.csv')","6e65d494":"df = df[['ebird_code', 'filename', 'duration','author','country','rating']]\ndf1 = pd.read_csv('..\/input\/xeno-canto-bird-recordings-extended-a-m\/train_extended.csv')[['ebird_code', 'filename', 'duration','author','country','rating']]\ndf2 = pd.read_csv('..\/input\/xeno-canto-bird-recordings-extended-n-z\/train_extended.csv')[['ebird_code', 'filename', 'duration','author','country','rating']]","0e84bad1":"frames = pd.concat([df,df1,df2])\n#frames = frames.loc[frames.duration <= 30]","5ffbb646":"path = train_audio + train_audio_1 + train_audio_2\npath.remove('..\/input\/birdsong-recognition\/train_audio\/lotduc\/XC195038.mp3')\npath.remove('..\/input\/xeno-canto-bird-recordings-extended-a-m\/A-M\/houspa\/XC555482.mp3')","0735255b":"from scipy.signal import butter, lfilter\n\n#https:\/\/scipy-cookbook.readthedocs.io\/items\/ButterworthBandpass.html\n\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyq =  fs\/\/2 # Nyquist sampling rate\n    low = lowcut\/ nyq\n    high = highcut \/ nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y","066f253e":"def waveletDenoising(data):\n        \n    #Wavelet Denosing using scikit-image\n    \n    im_bayes = denoise_wavelet(data,)\n    \n    return im_bayes\n\ndef audio_norm(data):\n    '''Normalization of audio'''\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data - min_data)\/(max_data - min_data + 1e-6)\n    return data","6b9c35df":"class config:\n    shape = (128,256)\n    rate = 32000\n    low_cut = 500.0 #low pass filter\n    high_cut = 15000.0 #high pass filter\n    order = 5\n    duration = 30 #sec\n    nq_rate = 0.2 * rate\n    n_fft = 4096\n    hop_len = 1024\n    n_mels = 128\n    fmin = 100.0\n    fmax = 15000.0\n    ","788f294d":"def read_audio(audio):\n    sig, rt = librosa.load(audio, duration = config.duration, mono = True,sr = config.rate,res_type='kaiser_fast')\n    \n    return sig,rt","daba5c6c":"def mel_spec(sig, preemphasis = True, normalize = True):\n    \n        #Split an audio signal into non-silent intervals,\n        #from discussion https:\/\/www.kaggle.com\/c\/birdsong-recognition\/discussion\/167264\n        sig = librosa.effects.trim(y = sig)\n        \n        if preemphasis:\n            sig = librosa.effects.preemphasis(y=sig[0],) #coef = 0.95\n        #Librosa mel-spectrum\n        \n        HOP_LEN = len(sig) \/\/ (config.shape[1] - 1)\n        \n        melspec = librosa.feature.melspectrogram(y=sig, sr=config.rate, \n                                       hop_length = HOP_LEN,\n                                      n_mels = config.n_mels,\n                                      fmax = config.fmax, \n                                      fmin = config.fmin,center = True,\n                                      window = 'hamming')\n        \n\n        \n        melspec = librosa.power_to_db(melspec,ref=np.max,) #using default top_db = 80 sometime works better\n        \n        #melspec = librosa.core.pcen(melspec,)\n        \n        #mfcc \n        #melspec = librosa.feature.mfcc(S=s,n_mfcc = config.n_mels)\n               \n        melspec =  melspec[::-1, ...] #flip lower frequency\n        \n        melspec = melspec[:config.shape[0], :config.shape[1]] #trim to desired shape\n     \n        # Normalize values between 0 and 1\n        if normalize:\n            melspec  = audio_norm(melspec)\n    \n        return melspec.astype('float32')","ab9115b0":"def filtered(audiof):\n    sig = read_audio(audiof)[0] #read audio\n    sig_fit = butter_bandpass_filter(sig,config.low_cut, config.high_cut, config.rate, config.order)\n    return waveletDenoising(mel_spec(sig_fit))","5455385f":"sig,rt = read_audio('..\/input\/birdsong-recognition\/train_audio\/bkbmag1\/XC114081.mp3')\n\ny = butter_bandpass_filter(sig,config.low_cut, config.high_cut, config.rate, config.order)\n\nplt.figure()\nplt.subplot(3,1,1)\nwaveplot(y=sig, sr = rt)\nplt.title('original_signal')\nplt.subplot(3,1,2)\nwaveplot(y=y, sr = rt)\nplt.title('filtered_signal')","df319959":"sig,rt = read_audio(path[6969])\n\ny = waveletDenoising(butter_bandpass_filter(sig,config.low_cut, config.high_cut, config.rate, config.order))\n\nplt.figure()\nplt.subplot(3,1,1)\nwaveplot(y=sig, sr = rt)\nplt.title('original_signal')\nplt.subplot(3,1,2)\nwaveplot(y=y, sr = rt)\nplt.title('filtered_signal')","ede0f986":"# settings\nh, w = 10, 10       \nnrows, ncols = 8, 4  \nfigsize = [12, 12]  \n\n\nxs = np.linspace(0, 2*np.pi, 60)  \nys = np.abs(np.sin(xs))           \n\n\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n\n\nfor i, axi in enumerate(ax.flat):\n    \n    img = path[i]\n    axi.imshow(filtered(img))    \n    rowid = i \/\/ ncols\n    colid = i % ncols\n    \n    axi.set_title(\"Row:\"+str(rowid)+\", Col:\"+str(colid))\n\n\nax[0][2].plot(xs, 3*ys, color='red', linewidth=3)\nax[4][3].plot(ys**2, xs, color='green', linewidth=3)\n\nplt.tight_layout(True)\nplt.show()","94851b22":"img = filtered(path[10])\n#img = mono_to_color(img)\ncv2.imwrite('melspec.png', img*255)","8530e141":"plt.imshow(cv2.imread('.\/melspec.png'))","ba57c725":"### Visualsing","c463fd3d":"### Extended data thanks to [Vopani](https:\/\/www.kaggle.com\/rohanrao)","0033fef0":"### Simple Spectogram ","300f9d5c":"### Wave plot \nButterworth Filter","e155a581":"### Read Audio ","de751e4c":"Lets Try wavelet Denoising","65903c76":"### For using saving spectogram ","68923e49":"### Butter worth Bandpass filter \n\n\n[Bird song and anthropogenic noise: vocalconstraints may explain why birds singhigher-frequency songs in cities](https:\/\/royalsocietypublishing.org\/doi\/10.1098\/rspb.2012.2798#d3e769)\n\n* The forest birds used the frequency band from 1.8 to 1.9 kHz most often (16% of all motif elements), whereas the city birds sang the highest number of elements in the range between 2.2 and 2.3 kHz. Forest males used frequencies below 2 kHz significantly more often than city birds did.\n* Also, [Wavelet Denoising](https:\/\/in.mathworks.com\/help\/wavelet\/ug\/wavelet-denoising.html) for removing noise in signal basically reconstruct a signal from a noisy one.\n\nI am using wavelet desnoising after melspectogram bit it will be better to use after filtering the signal","8c0371e8":"### Create Melspec","9e293e96":"Below two audios causing error for some reasons "}}