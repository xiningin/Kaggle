{"cell_type":{"9eb4c42e":"code","3d4c9dfa":"code","30742b4f":"code","b014d2f4":"code","fd9e9bb9":"code","f583209e":"code","a3cac6a9":"code","b03daada":"code","adbf3462":"code","f4adc3e0":"code","870bb7da":"code","77835da3":"code","5dca4c77":"code","86527e2b":"code","cec3a19b":"code","084c95db":"code","8677e397":"code","1c36e821":"code","75128c26":"code","b6eb7a05":"code","69cb4c7e":"code","66c6f38f":"code","7857d304":"code","5b9fd76a":"code","d640c0ee":"code","f1c3df47":"code","4a13df87":"code","1e66edad":"code","04ca4adc":"code","bdd1603a":"code","722c19a9":"code","abc034ec":"code","740e7b6a":"code","e9723cf7":"code","32f02348":"code","94698f3f":"code","b56d8cc1":"code","c1b9e8ff":"code","037774bc":"code","bdb7564f":"code","4178c225":"code","d7fecafc":"markdown","937d85cb":"markdown","bd8cafe0":"markdown","55add2ae":"markdown","1d0819e4":"markdown","b25028eb":"markdown","3f04631d":"markdown","707bfa2b":"markdown","de896e5f":"markdown","ca7255f5":"markdown","8f441c6e":"markdown","91e25cef":"markdown","8ccfded8":"markdown","6dd2fcef":"markdown","c69532b6":"markdown","4070553a":"markdown","e78bfd7c":"markdown","bdd7e182":"markdown","527c2094":"markdown","97e6616e":"markdown","328bea5b":"markdown","64755747":"markdown","cf9e5ca3":"markdown","79b8fc40":"markdown","5cb8e55a":"markdown","efd2df87":"markdown","c2ab6b8b":"markdown","63a446ba":"markdown","0b3f0c93":"markdown"},"source":{"9eb4c42e":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3d4c9dfa":"train = pd.read_csv(\"\/kaggle\/input\/human-activity-recognition-with-smartphones\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/human-activity-recognition-with-smartphones\/test.csv\")","30742b4f":"print('Number of duplicates in train : ',sum(train.duplicated()))\nprint('Number of duplicates in test : ', sum(test.duplicated()))","b014d2f4":"print('Total number of missing values in train : ', train.isna().values.sum())\nprint('Total number of missing values in train : ', test.isna().values.sum())","fd9e9bb9":"plt.figure(figsize=(10,8))\nplt.title('Barplot of Activity')\nsns.countplot(train.Activity)\nplt.xticks(rotation=90)","f583209e":"facetgrid = sns.FacetGrid(train, hue='Activity', height=5,aspect=3)\nfacetgrid.map(sns.distplot,'tBodyAccMag-mean()', hist=False).add_legend()\nplt.annotate(\"Static Activities\", xy=(-.996,21), xytext=(-0.9, 23),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})\nplt.annotate(\"Static Activities\", xy=(-.999,26), xytext=(-0.9, 23),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})\nplt.annotate(\"Static Activities\", xy=(-0.985,12), xytext=(-0.9, 23),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})\nplt.annotate(\"Dynamic Activities\", xy=(-0.2,3.25), xytext=(0.1, 9),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})\nplt.annotate(\"Dynamic Activities\", xy=(0.1,2.18), xytext=(0.1, 9),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})\nplt.annotate(\"Dynamic Activities\", xy=(-0.01,2.15), xytext=(0.1, 9),arrowprops={'arrowstyle': '-', 'ls': 'dashed'})","a3cac6a9":"plt.figure(figsize=(12,8))\nplt.subplot(1,2,1)\nplt.title(\"Static Activities(closer view)\")\nsns.distplot(train[train[\"Activity\"]==\"SITTING\"]['tBodyAccMag-mean()'],hist = False, label = 'Sitting')\nsns.distplot(train[train[\"Activity\"]==\"STANDING\"]['tBodyAccMag-mean()'],hist = False,label = 'Standing')\nsns.distplot(train[train[\"Activity\"]==\"LAYING\"]['tBodyAccMag-mean()'],hist = False, label = 'Laying')\nplt.axis([-1.02, -0.5, 0, 35])\nplt.subplot(1,2,2)\nplt.title(\"Dynamic Activities(closer view)\")\nsns.distplot(train[train[\"Activity\"]==\"WALKING\"]['tBodyAccMag-mean()'],hist = False, label = 'Sitting')\nsns.distplot(train[train[\"Activity\"]==\"WALKING_DOWNSTAIRS\"]['tBodyAccMag-mean()'],hist = False,label = 'Standing')\nsns.distplot(train[train[\"Activity\"]==\"WALKING_UPSTAIRS\"]['tBodyAccMag-mean()'],hist = False, label = 'Laying')","b03daada":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Activity', y='tBodyAccMag-mean()',data=train, showfliers=False)\nplt.ylabel('Body Acceleration Magnitude mean')\nplt.title(\"Boxplot of tBodyAccMag-mean() column across various activities\")\nplt.axhline(y=-0.7, xmin=0.05,dashes=(3,3))\nplt.axhline(y=0.020, xmin=0.35, dashes=(3,3))\nplt.xticks(rotation=90)","adbf3462":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Activity', y='angle(X,gravityMean)', data=train, showfliers=False)\nplt.axhline(y=0.08, xmin=0.1, xmax=0.9,dashes=(3,3))\nplt.ylabel(\"Angle between X-axis and gravityMean\")\nplt.title('Box plot of angle(X,gravityMean) column across various activities')\nplt.xticks(rotation = 90)","f4adc3e0":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Activity', y='angle(Y,gravityMean)', data = train, showfliers=False)\nplt.ylabel(\"Angle between Y-axis and gravityMean\")\nplt.title('Box plot of angle(Y,gravityMean) column across various activities')\nplt.xticks(rotation = 90)\nplt.axhline(y=-0.35, xmin=0.01, dashes=(3,3))","870bb7da":"from sklearn.manifold import TSNE","77835da3":"X_for_tsne = train.drop(['subject', 'Activity'], axis=1)","5dca4c77":"%time\ntsne = TSNE(random_state = 42, n_components=2, verbose=1, perplexity=50, n_iter=1000).fit_transform(X_for_tsne)","86527e2b":"plt.figure(figsize=(12,8))\nsns.scatterplot(x =tsne[:, 0], y = tsne[:, 1], hue = train[\"Activity\"],palette=\"bright\")","cec3a19b":"y_train = train.Activity\nX_train = train.drop(['subject', 'Activity'], axis=1)\ny_test = test.Activity\nX_test = test.drop(['subject', 'Activity'], axis=1)\nprint('Training data size : ', X_train.shape)\nprint('Test data size : ', X_test.shape)","084c95db":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8677e397":"parameters = {'C':np.arange(10,61,10), 'penalty':['l2','l1']}\nlr_classifier = LogisticRegression()\nlr_classifier_rs = RandomizedSearchCV(lr_classifier, param_distributions=parameters, cv=5,random_state = 42)\nlr_classifier_rs.fit(X_train, y_train)\ny_pred = lr_classifier_rs.predict(X_test)","1c36e821":"lr_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy using Logistic Regression : \", lr_accuracy)","75128c26":"# function to plot confusion matrix\ndef plot_confusion_matrix(cm,lables):\n    fig, ax = plt.subplots(figsize=(12,8)) # for plotting confusion matrix as image\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]),\n    yticks=np.arange(cm.shape[0]),\n    xticklabels=lables, yticklabels=lables,\n    ylabel='True label',\n    xlabel='Predicted label')\n    plt.xticks(rotation = 90)\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, int(cm[i, j]),ha=\"center\", va=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()","b6eb7a05":"cm = confusion_matrix(y_test.values,y_pred)\nplot_confusion_matrix(cm, np.unique(y_pred))  # plotting confusion matrix","69cb4c7e":"#function to get best random search attributes\ndef get_best_randomsearch_results(model):\n    print(\"Best estimator : \", model.best_estimator_)\n    print(\"Best set of parameters : \", model.best_params_)\n    print(\"Best score : \", model.best_score_)","66c6f38f":"# getting best random search attributes\nget_best_randomsearch_results(lr_classifier_rs)","7857d304":"from sklearn.svm import LinearSVC","5b9fd76a":"parameters = {'C':np.arange(1,12,2)}\nlr_svm = LinearSVC(tol=0.00005)\nlr_svm_rs = RandomizedSearchCV(lr_svm, param_distributions=parameters,random_state = 42)\nlr_svm_rs.fit(X_train, y_train)\ny_pred = lr_svm_rs.predict(X_test)","d640c0ee":"lr_svm_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy using linear SVM : \",lr_svm_accuracy)","f1c3df47":"cm = confusion_matrix(y_test.values,y_pred)\nplot_confusion_matrix(cm, np.unique(y_pred)) # plotting confusion matrix","4a13df87":"# getting best random search attributes\nget_best_randomsearch_results(lr_svm_rs)","1e66edad":"from sklearn.svm import SVC","04ca4adc":"np.linspace(2,22,6)","bdd1603a":"parameters = {'C':[2,4,8,16],'gamma': [0.125, 0.250, 0.5, 1]}\nkernel_svm = SVC(kernel='rbf')\nkernel_svm_rs = RandomizedSearchCV(kernel_svm,param_distributions=parameters,random_state = 42)\nkernel_svm_rs.fit(X_train, y_train)\ny_pred = kernel_svm_rs.predict(X_test)","722c19a9":"kernel_svm_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy using Kernel SVM : \", kernel_svm_accuracy)","abc034ec":"cm = confusion_matrix(y_test.values,y_pred)\nplot_confusion_matrix(cm, np.unique(y_pred)) # plotting confusion matrix","740e7b6a":"# getting best random search attributes\nget_best_randomsearch_results(kernel_svm_rs)","e9723cf7":"from sklearn.tree import DecisionTreeClassifier\nparameters = {'max_depth':np.arange(2,10,2)}\ndt_classifier = DecisionTreeClassifier()\ndt_classifier_rs = RandomizedSearchCV(dt_classifier,param_distributions=parameters,random_state = 42)\ndt_classifier_rs.fit(X_train, y_train)\ny_pred = dt_classifier_rs.predict(X_test)","32f02348":"dt_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy using Decision tree : \", dt_accuracy)","94698f3f":"cm = confusion_matrix(y_test.values,y_pred)\nplot_confusion_matrix(cm, np.unique(y_pred)) # plotting confusion matrix","b56d8cc1":"# getting best random search attributes\nget_best_randomsearch_results(dt_classifier_rs)","c1b9e8ff":"from sklearn.ensemble import RandomForestClassifier\nparams = {'n_estimators': np.arange(20,101,10), 'max_depth':np.arange(2,16,2)}\nrf_classifier = RandomForestClassifier()\nrf_classifier_rs = RandomizedSearchCV(rf_classifier, param_distributions=params,random_state = 42)\nrf_classifier_rs.fit(X_train, y_train)\ny_pred = rf_classifier_rs.predict(X_test)","037774bc":"rf_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy using Random forest : \", rf_accuracy)","bdb7564f":"cm = confusion_matrix(y_test.values,y_pred)\nplot_confusion_matrix(cm, np.unique(y_pred)) # plotting confusion matrix","4178c225":"# getting best random search attributes\nget_best_randomsearch_results(rf_classifier_rs)","d7fecafc":"#### 3.b Checking for missing values","937d85cb":"Using t-SNE data can be visualized from a extremely high dimensional space to a low dimensional space and still it retains lots of actual information.\nGiven training data has 561 unqiue features, using t-SNE let's visualize it to a 2D space.","bd8cafe0":"Similarly, using Angle between Y-axis and gravityMean we can seperate LAYING from other activities but again it leads to some misclassification error.  ","55add2ae":"### 1. Importing necessary libraries","1d0819e4":"There is almost same number of observations across all the six activities so this data does not have class imbalance problem. ","b25028eb":"### 5.b Linear SVM model with Hyperparameter tuning and cross validation","3f04631d":"### Notebook - Table of Content\n\n1. [**Importing necessary libraries**](# 1.-Importing-necessary-libraries)   \n2. [**Loading data**](#2.-Loading-data)  \n3. [**Data preprocessing**](#3.-Data-preprocessing)  \n    3.a [**Checking for duplicates **](#3.a-Checking-for-duplicates)  \n    3.b [**Checking for missing values**](#3.b-Checking-for-missing-values)  \n    3.c [**Checking for class imbalance**](#3.c-Checking-for-class-imbalance)  \n4. [**Exploratory Data Analysis**](#4.-Exploratory-Data-Analysis)  \n    4.a [**Analysing tBodyAccMag-mean feature**](#4.a-Analysing-tBodyAccMag-mean-feature)  \n    4.b [**Analysing Angle between X-axis and gravityMean feature**](#4.b-Analysing-Angle-between-X-axis-and-gravityMean-feature)  \n    4.c [**Analysing Angle between Y-axis and gravityMean feature**](#4.c-Analysing-Angle-between-Y-axis-and-gravityMean-feature)   \n    4.d [**Visualizing data using t-SNE**](#4.d-Visualizing-data-using-t-SNE)\n5. [**Headline based similarity on new articles**](#6.-Headline-based-similarity-on-new-articles)  \n    5.a [**Logistic regression model with Hyperparameter tuning and cross validation**](#5.a-Logistic-regression-model-with-Hyperparameter-tuning-and-cross-validation)  \n    5.b [**Linear SVM model with Hyperparameter tuning and cross validation**](#5.b-Linear-SVM-model-with-Hyperparameter-tuning-and-cross-validation)  \n    5.c [**Kernel SVM model with Hyperparameter tuning and cross validation**](#5.c-Kernel-SVM-model-with-Hyperparameter-tuning-and-cross-validation)   \n    5.d [**Decision tree model with Hyperparameter tuning and cross validation**](#5.d-Decision-tree-model-with-Hyperparameter-tuning-and-cross-validation)  \n    5.e [**Random forest model with Hyperparameter tuning and cross validation**](#5.e-Random-forest-model-with-Hyperparameter-tuning-and-cross-validation)  ","707bfa2b":"### 5.a Logistic regression model with Hyperparameter tuning and cross validation","de896e5f":"Using boxplot again we can come with conditions to seperate static activities from dynamic activities.\n\n``` \nif(tBodyAccMag-mean()<=-0.8):\n    Activity = \"static\"\nif(tBodyAccMag-mean()>=-0.6):\n    Activity = \"dynamic\"\n``` \n\nAlso, we can easily seperate WALKING_DOWNSTAIRS activity from others using boxplot.\n\n``` \nif(tBodyAccMag-mean()>0.02):\n    Activity = \"WALKING_DOWNSTAIRS\"\nelse:\n    Activity = \"others\"\n```\n\nBut still 25% of WALKING_DOWNSTAIRS observations are below 0.02 which are misclassified as **others** so this condition makes an error of 25% in classification.","ca7255f5":"### 5. ML models","8f441c6e":"### 5.c Kernel SVM model with Hyperparameter tuning and cross validation","91e25cef":"### Conclusion\n\nIn this kernel we built multiple different models using various classification algorithms. The accuracy obtained through these models is as follows - \n\n|  Logistic  |  Linear SVM  |  Kernel SVM  |  Decision Trees  | Random Forest |\n|------|------|------|------|------|\n|  96.20 | 96.84| 94.16 | 85.34 | 90.32 |","8ccfded8":"#### 3.c Checking for class imbalance","6dd2fcef":"The insights obtained through density plots can also be represented using Box plots.\nLet's plot the boxplot of Body Accelartion Magnitude mean(tBodyAccMag-mean()) across all the six categories.","c69532b6":"#### 4.b Analysing Angle between X-axis and gravityMean feature","4070553a":"Using the above density plot we can easily come with a condition to seperate static activities from dynamic activities.\n\n``` \nif(tBodyAccMag-mean()<=-0.5):\n    Activity = \"static\"\nelse:\n    Activity = \"dynamic\"\n```\n\nLet's have a more closer view on the PDFs of each activity under static and dynamic categorization.","e78bfd7c":"### 2. Loading data","bdd7e182":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python\/","527c2094":"### 5.d Decision tree model with Hyperparameter tuning and cross validation","97e6616e":"### 4.d Visualizing data using t-SNE","328bea5b":"#### 4.c Analysing Angle between Y-axis and gravityMean feature","64755747":"#### 3.a Checking for duplicates ","cf9e5ca3":"#### 4.a Analysing tBodyAccMag-mean feature","79b8fc40":"From the boxplot we can observe that angle(X,gravityMean) perfectly seperates LAYING from other activities.\n``` \nif(angle(X,gravityMean)>0.01):\n    Activity = \"LAYING\"\nelse:\n    Activity = \"others\"\n```","5cb8e55a":"### 4. Exploratory Data Analysis\n\nBased on the common nature of activities we can broadly put them in two categories.\n- **Static and dynamic activities : **\n    - SITTING, STANDING, LAYING can be considered as static activities with no motion involved\n    - WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS can be considered as dynamic activities with significant amount of motion involved    \n    \nLet's consider **tBodyAccMag-mean()** feature to differentiate among these two broader set of activities.\n\nIf we try to build a simple classification model to classify the **activity** using one variable at a time then probability density function(PDF) is very helpful to assess importance of a continuous variable.","efd2df87":"### 3. Data preprocessing","c2ab6b8b":"### 5.e Random forest model with Hyperparameter tuning and cross validation","63a446ba":"Using the two new components obtained through t-SNE we can visualize and seperate all the six activities in a 2D space. ","0b3f0c93":"#### Getting training and test data ready"}}