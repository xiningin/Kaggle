{"cell_type":{"973f6e28":"code","bd23660f":"code","eefb8b00":"code","30915a79":"code","4062234f":"code","5967e48e":"code","755ae996":"code","73aadc58":"code","09cba24d":"code","f072282f":"code","7ce94e16":"code","4ff4e167":"code","bbd20b79":"code","168e2493":"code","7e6ff1de":"code","ff041f2f":"code","67328aac":"code","02b3b086":"code","d4bd429c":"code","6e7ab96d":"code","1f98332f":"code","f624d8ba":"code","23d71c2e":"code","6c67e5f7":"code","16213c77":"code","7fc9828d":"code","c4d99ec0":"code","9bd53955":"code","bc77deec":"code","ca04f2f6":"markdown","b35ea7a7":"markdown","f13704bf":"markdown","f6e34b3d":"markdown","73d30e52":"markdown","00ad039f":"markdown","401df181":"markdown","4ab834e5":"markdown"},"source":{"973f6e28":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport tensorflow ","bd23660f":"dataset_path = \"..\/input\/brain-tumor-images-with-masks\/Brain Images with tumor masks\/\"","eefb8b00":"image_path = os.path.join(dataset_path,\"yes\/\")\nmask_path  = os.path.join(dataset_path,\"masks\/\")\ndataset = pd.read_csv(dataset_path + \"train_data.csv\")","30915a79":"dataset.head()","4062234f":"def get_image_mask(img_name):\n    img = cv2.imread(img_name)\n    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    plt.figure(figsize=(10,8))\n    plt.subplot(141)\n    plt.imshow(gray_img,\"gray\")\n    \n    ret, thresh = cv2.threshold(gray_img,0,255,cv2.THRESH_OTSU)\n    plt.subplot(142)\n    plt.imshow(thresh,\"gray\")\n    \n    ret, markers = cv2.connectedComponents(thresh)\n    marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0]\n    largest_component = np.argmax(marker_area)+1  \n    brain_mask = markers==largest_component\n    \n    brain_out = img.copy()\n    brain_out[brain_mask==False] = (0,0,0)\n    \n    brain_out_gray = cv2.cvtColor(brain_out,cv2.COLOR_BGR2GRAY)\n    plt.subplot(143)\n    plt.imshow(brain_out_gray,\"gray\")\n    \n    \n    blurred = cv2.blur(brain_out_gray,(5,5))\n    ret, thresh_mask = cv2.threshold(blurred,170,255,cv2.THRESH_BINARY)\n    plt.subplot(144)\n    plt.imshow(thresh_mask,cmap=\"gray\")\n    plt.show()\n    \n    return thresh_mask","5967e48e":"image = image_path + dataset.iloc[0][0]\nmask = get_image_mask(image)","755ae996":"#extra processing if needed\nkernel = np.ones((5,5),np.uint8)\nmask_eroded = cv2.erode(mask,kernel,iterations = 4)\nplt.imshow(mask_eroded,cmap='gray')","73aadc58":"#processing masks form Imagebox\nplt.figure()\nfor i in range(len(dataset.head())):\n    image,mask = dataset.iloc[i]\n    plt.subplot(121)\n    img = cv2.imread(image_path + image)\n    plt.imshow(img)\n    plt.title(image)\n    plt.subplot(122)\n    mask_img = cv2.imread(mask_path +  mask)\n    plt.imshow(mask_img)\n    plt.title(mask)\n    plt.show()","09cba24d":"#Preparing Train and Validation set\nfrom sklearn.model_selection import train_test_split\ntotal = len(dataset)\ntest_split = 0.2\ntrain, test = train_test_split(dataset,test_size = test_split,random_state = 50)","f072282f":"height = 256\nwidth = 256\nchannels = 3\nbatch_size = 32","7ce94e16":"import sys\nfrom skimage.transform import resize\nfrom tqdm import tqdm\ndef data_generator(dataset,image_path,mask_path,height,width):\n    \n    X_train = np.zeros((len(dataset),height,width,3),dtype = np.uint8)\n    y_train = np.zeros((len(dataset),height,width,1),dtype = np.uint8)\n    \n    sys.stdout.flush()\n    \n    for i in tqdm(range(len(dataset)),total=len(dataset)):\n        image = cv2.imread(image_path + dataset.iloc[i][0])\n        img_resized = resize(image,(height,width),mode='constant',preserve_range=True)\n        X_train[i] = img_resized\n        \n        mask = cv2.imread(mask_path + dataset.iloc[i][1])[:,:,:1]\n        mask_resized = resize(mask,(height,width),mode='constant',preserve_range=True)\n        y_train[i] = mask_resized\n        \n    return X_train,y_train","4ff4e167":"X_train,y_train = data_generator(train,image_path,mask_path,height,width)","bbd20b79":"y_train = y_train \/ 255","168e2493":"def dice_coef(y_true,y_pred,epsilon=0.001):\n  y_true_sum  = K.sum(y_true)\n  y_pred_sum  = K.sum(y_pred)\n  intersection = K.sum(y_true * y_pred)\n  return ((2 * intersection + epsilon)\/(y_true_sum + y_pred_sum + epsilon))\n\ndef dice_coef_loss(y_true,y_pred):\n    return 1 - dice_coef(y_true,y_pred)","7e6ff1de":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import UpSampling2D, concatenate\nfrom tensorflow.keras.layers import Activation, BatchNormalization\nimport tensorflow.keras.backend as K","ff041f2f":"def unet(input_size=(256,256,3)):\n    \n    inputs = Input(input_size)\n    x = Lambda(lambda x: x \/ 255)(inputs)\n    \n    #Contracting Path\n    down_block_0_layer_0 = Conv2D(16,kernel_size=(3,3),padding=\"same\")(x)\n    down_block_0_layer_0 = Activation(\"relu\")(down_block_0_layer_0)\n    down_block_0_layer_1 = Conv2D(16,kernel_size=(3,3),padding='same')(down_block_0_layer_0)\n    down_block_0_layer_1 = BatchNormalization(axis=3)(down_block_0_layer_1)\n    down_block_0_layer_1 = Activation(\"relu\")(down_block_0_layer_1)\n    down_block_0_pool = MaxPool2D((2,2),strides=(2,2))(down_block_0_layer_1)\n    \n    down_block_1_layer_0 = Conv2D(32,kernel_size=(3,3),padding=\"same\")(down_block_0_pool)\n    down_block_1_layer_0 = Activation(\"relu\")(down_block_1_layer_0)\n    down_block_1_layer_1 = Conv2D(32,kernel_size=(3,3),padding='same')(down_block_1_layer_0)\n    down_block_1_layer_1 = BatchNormalization(axis=3)(down_block_1_layer_1)\n    down_block_1_layer_1 = Activation(\"relu\")(down_block_1_layer_1)\n    down_block_1_pool = MaxPool2D((2,2),strides=(2,2))(down_block_1_layer_1)\n    \n    down_block_2_layer_0 = Conv2D(64,kernel_size=(3,3),padding=\"same\")(down_block_1_pool)\n    down_block_2_layer_0 = Activation(\"relu\")(down_block_2_layer_0)\n    down_block_2_layer_1 = Conv2D(64,kernel_size=(3,3),padding='same')(down_block_2_layer_0)\n    down_block_2_layer_1 = BatchNormalization(axis=3)(down_block_2_layer_1)\n    down_block_2_layer_1 = Activation(\"relu\")(down_block_2_layer_1)\n    down_block_2_pool = MaxPool2D((2,2),strides=(2,2))(down_block_2_layer_1)\n    \n    down_block_3_layer_0 = Conv2D(128,kernel_size=(3,3),padding=\"same\")(down_block_2_pool)\n    down_block_3_layer_0 = Activation(\"relu\")(down_block_3_layer_0)\n    down_block_3_layer_1 = Conv2D(128,kernel_size=(3,3),padding='same')(down_block_3_layer_0)\n    down_block_3_layer_1 = BatchNormalization(axis=3)(down_block_3_layer_1)\n    down_block_3_layer_1 = Activation(\"relu\")(down_block_3_layer_1)\n    down_block_3_pool = MaxPool2D((2,2),strides=(2,2))(down_block_3_layer_1)\n    \n    down_block_4_layer_0 = Conv2D(256,kernel_size=(3,3),padding=\"same\")(down_block_3_pool)\n    down_block_4_layer_0 = Activation(\"relu\")(down_block_4_layer_0)\n    down_block_4_layer_1 = Conv2D(256,kernel_size=(3,3),padding='same')(down_block_4_layer_0)\n    down_block_4_layer_1 = BatchNormalization(axis=3)(down_block_4_layer_1)\n    down_block_4_layer_1 = Activation(\"relu\")(down_block_4_layer_1)\n    \n    #Expanding Path\n    up_block_0_upsample =  UpSampling2D((2,2))(down_block_4_layer_1)\n    concat_block_0 =  concatenate([up_block_0_upsample,down_block_3_layer_1],axis=3)\n    up_block_0_layer_0 = Conv2D(128,kernel_size=(3,3),padding=\"same\")(concat_block_0)\n    up_block_0_layer_0 = Activation(\"relu\")(up_block_0_layer_0)\n    up_block_0_layer_1 = Conv2D(128,kernel_size=(3,3),padding='same')(up_block_0_layer_0)\n    up_block_0_layer_1 = BatchNormalization(axis=3)(up_block_0_layer_1)\n    up_block_0_layer_1 = Activation(\"relu\")(up_block_0_layer_1)\n    \n    up_block_1_upsample =  UpSampling2D((2,2))(up_block_0_layer_1)\n    concat_block_1 =  concatenate([up_block_1_upsample,down_block_2_layer_1],axis=3)\n    up_block_1_layer_0 = Conv2D(64,kernel_size=(3,3),padding=\"same\")(concat_block_1)\n    up_block_1_layer_0 = Activation(\"relu\")(up_block_1_layer_0)\n    up_block_1_layer_1 = Conv2D(64,kernel_size=(3,3),padding='same')(up_block_1_layer_0)\n    up_block_1_layer_1 = BatchNormalization(axis=3)(up_block_1_layer_1)\n    up_block_1_layer_1 = Activation(\"relu\")(up_block_1_layer_1)\n    \n    up_block_2_upsample =  UpSampling2D((2,2))(up_block_1_layer_1)\n    concat_block_2 =  concatenate([up_block_2_upsample,down_block_1_layer_1],axis=3)\n    up_block_2_layer_0 = Conv2D(32,kernel_size=(3,3),padding=\"same\")(concat_block_2)\n    up_block_2_layer_0 = Activation(\"relu\")(up_block_2_layer_0)\n    up_block_2_layer_1 = Conv2D(32,kernel_size=(3,3),padding='same')(up_block_2_layer_0)\n    up_block_2_layer_1 = BatchNormalization(axis=3)(up_block_2_layer_1)\n    up_block_2_layer_1 = Activation(\"relu\")(up_block_2_layer_1)\n    \n    up_block_3_upsample =  UpSampling2D((2,2))(up_block_2_layer_1)\n    concat_block_3 =  concatenate([up_block_3_upsample,down_block_0_layer_1],axis=3)\n    up_block_3_layer_0 = Conv2D(16,kernel_size=(3,3),padding=\"same\")(concat_block_3)\n    up_block_3_layer_0 = Activation(\"relu\")(up_block_3_layer_0)\n    up_block_3_layer_1 = Conv2D(16,kernel_size=(3,3),padding='same')(up_block_3_layer_0)\n    up_block_3_layer_1 = BatchNormalization(axis=3)(up_block_3_layer_1)\n    up_block_3_layer_1 = Activation(\"relu\")(up_block_3_layer_1)\n        \n\n    outputs = Conv2D(1,(1,1),activation=\"sigmoid\")(up_block_3_layer_1)\n    \n    return Model(inputs = [inputs], outputs = [outputs])","67328aac":"model = unet(input_size=(height,width,channels))\nmodel.summary()","02b3b086":"epochs = 120\nsteps_per_epoch = len(train) \/\/ batch_size\nbatch_size = 16\nlearning_rate = 1e-4","d4bd429c":"from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam","6e7ab96d":"model_path = \"unet_model.h5\"\n\ncheckpoint = ModelCheckpoint(model_path,\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\ndecay_rate = learning_rate \/ epochs\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)","1f98332f":"model.compile(optimizer=opt,loss=dice_coef_loss,metrics=[dice_coef,'binary_accuracy'])\nresults = model.fit(X_train, y_train, validation_split=0.1,batch_size=batch_size, epochs=epochs,callbacks=[checkpoint])","f624d8ba":"    plt.plot(results.history['binary_accuracy'])\n    plt.plot(results.history['val_binary_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    \n    plt.plot(results.history['dice_coef'])\n    plt.plot(results.history['val_dice_coef'])\n    plt.title('Dice Coeff')\n    plt.ylabel('dice coeff')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    # \"Loss\"\n    plt.plot(results.history['loss'])\n    plt.plot(results.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()","23d71c2e":"image,mask = test.iloc[2]\npred_img = cv2.imread(image_path + image)\nimg_resized = resize(pred_img, (height, width), mode='constant', preserve_range=True)\nimg_test = img_resized.reshape((1,height,width,channels)).astype(np.uint8)\n\nimg_mask = cv2.imread(mask_path + mask)\nimg_resized = resize(img_mask, (height, width), mode='constant', preserve_range=True)\nmask_org = img_resized.reshape((1,height,width,channels)).astype(np.uint8)","6c67e5f7":"model_pred = model.predict(img_test)\nmodel_pred = (model_pred > 0.5).astype(np.uint8)","16213c77":"plt.figure(figsize=(10,5))\nplt.subplot(131)\nplt.imshow(img_test.squeeze())\nplt.title(\"Image\")\nplt.subplot(132)\nplt.imshow(mask_org.squeeze(),cmap='gray')\nplt.title('Mask')\nplt.subplot(133)\nplt.imshow(model_pred.squeeze(),cmap='gray')\nplt.title('Predicted Mask')\nplt.show()","7fc9828d":"from tensorflow.keras.models import load_model\nmodel = load_model(\"unet_model.h5\",custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef})","c4d99ec0":"X_test,y_test = data_generator(test,image_path,mask_path,height,width)\ny_test = y_test \/ 255","9bd53955":"results = model.evaluate(X_test,y_test,steps=len(X_test)\/batch_size)\nprint('Dice Loss: ',results[0])\nprint('Dice coeff: ',results[1])\nprint('Accuracy: ',results[2])","bc77deec":"for image,mask in zip(X_test,y_test):\n    img = image.reshape((1,height,width,channels)).astype(np.uint8)\n    pred_mask = model.predict(img)\n    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n    \n    plt.figure(figsize=(12,12))\n    plt.subplot(131)\n    plt.imshow(image)\n    plt.title(\"Brain Image\")\n    plt.subplot(132)\n    plt.imshow(mask.squeeze(),cmap='gray')\n    plt.title(\"Original Mask\")\n    plt.subplot(133)\n    plt.imshow(pred_mask.squeeze(),cmap='gray')\n    plt.title('Predicted Mask')\n    plt.show()","ca04f2f6":"# **Model Training**","b35ea7a7":"# **Data Split and Generator**","f13704bf":"# **Visualizing Images and Masks**","f6e34b3d":"# **Model Testing**","73d30e52":"# **Trying out Image Processing techinques to get mask**","00ad039f":"# **Training Results**","401df181":"## **Metrics and Loss**","4ab834e5":"# **Model Definition**"}}