{"cell_type":{"1c755843":"code","ff157157":"code","98666429":"code","e6341ac6":"code","f681c036":"code","e646196b":"code","55d8f276":"code","10716338":"code","d8cff4cf":"code","7ae76651":"code","93080fb2":"code","24bebe41":"code","f8dd3d10":"code","ee9038ad":"code","68c9aa10":"code","f5e61145":"code","c55b1f15":"code","d67a63dc":"code","e718b88a":"code","b3204e9f":"code","eca2874d":"code","e0adbcae":"code","330a156a":"code","d76d30fe":"code","094334f8":"code","07965920":"code","a8485e0c":"code","db1c5853":"code","00a93ed8":"code","396b4058":"code","fdd173cf":"code","5dbc680b":"markdown","c517350b":"markdown","804fdb69":"markdown","6485d727":"markdown"},"source":{"1c755843":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff157157":"import tensorflow as tf\nfrom tensorflow import keras\n#Version of tensorflow\nprint(tf.__version__)","98666429":"file_name = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ndata = pd.read_csv(file_name)\ntarget = pd.DataFrame(data['label'])\nfeatures = data.drop('label',axis=1)\nprint(data.shape)\nprint(data.describe)\n","e6341ac6":"import tensorflow as tf\nfrom tensorflow import keras\n#Building a neural network\nmodel = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Dense(128,input_dim=784,activation=tf.nn.relu))\n#model.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(21,activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))","f681c036":"model_23 = tf.keras.models.Sequential([\n                            tf.keras.layers.Dense(132,input_dim=784,activation = tf.nn.relu),\n                            tf.keras.layers.Dense(40,activation=tf.nn.relu),\n                            tf.keras.layers.Dense(10,activation=tf.nn.sigmoid)\n    \n])","e646196b":"model_23.summary()","55d8f276":"#Compliing the model\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","10716338":"model_23.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])","d8cff4cf":"#Fit the model i.e find the patterns in the training data\nmodel.fit(features,target,epochs=8)","7ae76651":"model_23.fit(features,target,epochs=10)","93080fb2":"scores = model.evaluate(features,target)\nprint(scores)","24bebe41":"scores_23 = model_23.evaluate(features,target)","f8dd3d10":"#testing data\ntest_data=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest_target = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\ns = model.evaluate(test_data,test_target['Label'])\n","ee9038ad":"features , test_data = np.array(features),np.array(test_data)\nfeatures,test_data = features.reshape(42000,28,28,1),test_data.reshape(28000,28,28,1)","68c9aa10":"#Building a convolutional layer \nmodel_update = tf.keras.models.Sequential([tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu,input_shape=(28,28,1)),\n                                           tf.keras.layers.MaxPooling2D(2,2),\n                                           tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu,input_shape=(28,28,1)),\n                                           tf.keras.layers.MaxPooling2D(2,2),\n                                           tf.keras.layers.Flatten(),\n                                           tf.keras.layers.Dense(512,activation=tf.nn.relu),\n                                           tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n                                            ])","f5e61145":"model_update.summary()\n# Explains how the convolutions are acting on the images by concentrating on the main features\n# and pooling helps in compressing the image but keeping the features intact","c55b1f15":"# Compiling the Convolutional model\nmodel_update.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])","d67a63dc":"model_update.fit(features,target,epochs=5)","e718b88a":"# Evaluating the test data with a convolutional model, I hope there is an improvement\nmodel_update.evaluate(test_data,np.array(test_target['Label']))","b3204e9f":"# Not much of an improvement ","eca2874d":"#Normalizing\nfeatures , test_data = features , test_data\n#Converting features and test_data into numpy arrays\nfeatures , test_data = np.array(features),np.array(test_data)\n#Reshaping them\nfeatures , test_data = features.reshape(42000,28,28,1),test_data.reshape(28000,28,28,1)\n\"\"\"\nfeatures , test_data = np.array(features),np.array(test_data)\nfeatures,test_data = features.reshape(42000,28,28,1),test_data.reshape(28000,28,28,1)\n\"\"\"","e0adbcae":"#Building a Convolutional Neural Network with 3 Convolutional layers with their respective pooling\nmodel_3 = tf.keras.models.Sequential([\n                                tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu,input_shape=(28,28,1)),\n                                tf.keras.layers.MaxPooling2D(2,2),\n                                tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu),\n                                tf.keras.layers.MaxPooling2D(2,2),\n                                tf.keras.layers.Flatten(),\n                                tf.keras.layers.Dense(1028,activation=tf.nn.relu),\n                                tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n                                     ])\n","330a156a":"#Compiling the model\nmodel_3.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])","d76d30fe":"# Fit the model to find the patterns\nmodel_3.fit(features,target,epochs=10)","094334f8":"model_3.evaluate(features,target)","07965920":"model_3.evaluate(test_data,np.array(test_target['Label']))","a8485e0c":"model_4 = tf.keras.models.Sequential([\n                                tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu,input_shape=(28,28,1)),\n                                tf.keras.layers.MaxPooling2D(2,2),\n                                tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu),\n                                tf.keras.layers.MaxPooling2D(2,2),\n                                tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu),\n                                tf.keras.layers.MaxPooling2D(2,2),\n                                tf.keras.layers.Flatten(),\n                                tf.keras.layers.Dense(512,activation = tf.nn.relu),\n                                tf.keras.layers.Dense(10,activation = tf.nn.softmax)\n                                ])","db1c5853":"# Helping us how the Convolutional layers and MaxPooling layers reduce the parameters by concentrating\n#on the main features and copressing the image by keeping the features  intact\nmodel_4.summary()","00a93ed8":"#model compiling bysetting up the optimizer(which tries to minimize the error by making sure that the weights and baises \n#helps in reaching the global minima or  good enough local minima)\n\nmodel_4.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])","396b4058":"# Find the main features by update the weights and biases of the network\nmodel_4.fit(features,target,batch_size=32,epochs=5)","fdd173cf":"model_4.evaluate(test_data,test_target['Label'])","5dbc680b":"Lets try normalizing the features and test_data which contain the pixel values \nof the pictures being feeded into the Convolutional Neural Network\n","c517350b":"Lets try another Convolutional Neural Network having 3 Convolutional layers along with Max Pooling layers","804fdb69":"Evaluating our model on the training data (which is actually not a good idea as our model has learnt the features to look out from the training data)","6485d727":" taking another model but using the Stochastic greadient descent algorithm as an optimizer"}}