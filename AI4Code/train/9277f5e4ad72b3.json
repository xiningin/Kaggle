{"cell_type":{"7044dbc1":"code","b9571302":"code","56ac2872":"code","865c13c2":"code","e856ab45":"code","3878f5fe":"code","756d723c":"code","0801dd6c":"code","93d77bab":"code","b67993b3":"code","3fdec794":"code","8f14c418":"markdown","5f2a8a34":"markdown","ed0a4768":"markdown","c9c9c813":"markdown"},"source":{"7044dbc1":"import tensorflow as tf\nimport keras \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport sys\nimport random","b9571302":"from keras.preprocessing.image import ImageDataGenerator#\nimage_size = 1024\ninput_size = 331\ntrain_dir = '..\/input\/neuron cy5 train data\/Neuron Cy5 Train Data'\ntest_dir = '..\/input\/neuron cy5 test data\/Neuron Cy5 Test Data'\n\n# Create generator with augmentation for training\ntrain_gen = ImageDataGenerator(horizontal_flip=True,\n                               vertical_flip=True,\n                               samplewise_center=True,\n                               samplewise_std_normalization=True).flow_from_directory(train_dir, \n                                                                                      target_size=(image_size,image_size),\n                                                                                      color_mode='grayscale',\n                                                                                      class_mode='categorical',\n                                                                                      batch_size=16,\n                                                                                      shuffle=True)\n# Create generator with no augmentation for testing\ntest_gen = ImageDataGenerator(samplewise_center=True,\n                              samplewise_std_normalization=True).flow_from_directory(test_dir, \n                                                                                     target_size=(input_size,input_size),\n                                                                                     color_mode='grayscale',\n                                                                                     class_mode='categorical',\n                                                                                     batch_size=16,\n                                                                                     shuffle=True)\nclasses = dict((v, k) for k, v in train_gen.class_indices.items())\nnum_classes = len(classes)","56ac2872":"def rand_crop(img):\n    # Select size of crop\n    h = random.randint(input_size, image_size) \n    # Select lower left corner for crop\n    cx = random.randint(0, image_size-h)\n    cy = random.randint(0, image_size-h)\n    # Crop and resize image to input_size\n    cropped_img = img[cx:cx+h,cy:cy+h,:]\n    return cv2.resize(cropped_img, (input_size,input_size))","865c13c2":"def crop_gen(batch_gen):\n    '''Generator of cropped images.\n    Takes a generator as it's input and returns cropped versions of the generators output.    \n    '''\n    while True:\n        batch_x, batch_y = next(batch_gen)\n        batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 1))\n        for i in range(batch_x.shape[0]):\n            batch_crops[i,...,0] = rand_crop(batch_x[i])\n        yield (batch_crops, batch_y)","e856ab45":"from keras import backend as K\n    \ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n        Only computes a batch-wise average of recall.\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n        Only computes a batch-wise average of precision.\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","3878f5fe":"from tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.applications import VGG19\nfrom tensorflow.python.keras.layers import GlobalMaxPooling2D, Dense\nfrom tensorflow.python.keras.optimizers import Adam\n\n# Create a VGG19 architecture\npretrained_model = VGG19(include_top=False,\n                         pooling='none',\n                         input_shape=(input_size, input_size, 3),\n                         weights='imagenet')\nx = GlobalMaxPooling2D()(pretrained_model.output)\nx = Dense(2048, activation='relu')(x)\nx = Dense(2048, activation='relu')(x)\noutput = Dense(num_classes, activation='softmax')(x)\nvgg19_model = Model(pretrained_model.input, output)\n\n# Create new model with modified config which accepts the input shape: [input_size, input_size, 1]\ncfg = vgg19_model.get_config()\ncfg['layers'][0]['config']['batch_input_shape'] = (None, input_size, input_size, 1)\nmodel = Model.from_config(cfg)\n\n# Set the model weights to that of the pretrained VGG19\n# and freeze all layers except the final Dense layers.\nfor i, layer in enumerate(model.layers):\n    if i == 1:\n        new_weights = np.reshape(vgg19_model.layers[i].get_weights()[0].sum(axis=2),(3,3,1,64))\n        model.set_weights([new_weights])\n        layer.trainable = False\n    elif len(model.layers) - i > 3: # Freeze all but last 3 layers\n        layer.trainable = False\n        layer.set_weights(vgg19_model.layers[i].get_weights())\n    else:\n        layer.trainable = True \n        layer.set_weights(vgg19_model.layers[i].get_weights())\n\n# Compile the model with Adam optimizer, binary crossentropy loss and f1 score as the metric\nadam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) # 10x smaller than standard\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=[f1])\nmodel.summary()","756d723c":"# Train the model\nhistory = model.fit_generator(crop_gen(train_gen),\n                              epochs=5,\n                              steps_per_epoch=4*len(train_gen), # Effectively 1 run through every possibility of reflected data\n                              validation_data=test_gen,\n                              validation_steps=len(test_gen), \n                              verbose=1)","0801dd6c":"# Plot learning curve\nplt.figure(figsize=(15,15))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss','val_loss'], loc='upper right',prop={'size': 15});\nplt.title('Learning curve for the training of Dense Layers', fontsize=15)\nplt.show()\nprint('Best test F1 score: ' + max(history.history['val_f1']).astype(str))","93d77bab":"from tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint\n\n# Unfreeze all weights\nfor layer in model.layers:\n    layer.trainable = True\n    \n# Recompile with Adam optimizer with smaller initial learning rate\nadam_fine = Adam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) # 50x smaller than standard\ncheckpoint = ModelCheckpoint('VGG19_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=0)\n\nmodel.compile(optimizer=adam_fine, loss='binary_crossentropy', metrics=[f1])","b67993b3":"# Train the model\nhistory2 = model.fit_generator(crop_gen(train_gen),\n                              epochs=10,\n                              steps_per_epoch=4*len(train_gen), #effectively 1 run through every possibility of reflected data\n                              validation_data=test_gen,\n                              validation_steps=len(test_gen), \n                              callbacks =[checkpoint],\n                              verbose=1)","3fdec794":"# Plot learning curve for the whole training process\nfull_history = dict()\nfor key in history.history.keys():\n    full_history[key] = history.history[key]+history2.history[key]\n\nplt.figure(figsize=(15,15))\nplt.plot(full_history['loss'])\nplt.plot(full_history['val_loss'])\nplt.legend(['loss','val_loss'], loc='upper right',prop={'size': 15});\nplt.title('Learning curve for the full training process', fontsize=15)\nplt.show()\nprint('Best test F1 score: ' + max(full_history['val_f1']).astype(str))","8f14c418":"The pretrained model to be used is the VGG19. The original Dense layers are removed and replaced with three Dense Layers, two with 2048 nodes and the final one with 2 for classification\n\nAs the images are being fed in as grayscale and hence have only one channel, the standard weights in the first Convolution layer of the VGG19 must be summed over the channel dimension to produce filters with shape (3, 3, 1) as opposed to (3, 3, 3).  Then all layers apart from the final Dense layers are frozen and the model is trained for 10 epochs using the Adam optimizer with a slightly reduced learning rate.\n\nThe F1 metric was removed in Keras 2.0 so has to be defined before it can be used during training.","5f2a8a34":"Instead of loading the data manually, Keras' ImageDataGenerators will be used to do all the work instead. \n\nThe training set is fed into the model after being randomly cropped and flipped but the test set will be fed as-is. The augmentations will lead to the model being scale invariant; critical if the regional classification is to work.","ed0a4768":"Firstly some standard imports.","c9c9c813":"To further increase model performance, the entire model is unfrozen and trained for a further 10 epochs. This time, however, the learning rate used in the Adam optimiser is dropped by a factor of 20.\n\nModelCheckpoint is used to ensure that only the weights of the best model are saved. This becomes particularly useful if the model begins to overfit towards the end of the training process."}}