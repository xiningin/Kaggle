{"cell_type":{"b8c21cb3":"code","11ed5e1d":"code","243197c1":"code","94e551b0":"code","00a2cdb7":"code","125ac931":"markdown","d85db646":"markdown","adf54650":"markdown","d926b490":"markdown","bd2a1d7d":"markdown"},"source":{"b8c21cb3":"import time\nimport numpy as np\nimport pandas as pd\n\ntr = pd.read_csv('..\/input\/training_set.csv')\ngroups = tr.groupby(['object_id'])","11ed5e1d":"# Version using pandas Series\ndef compute_all_aggregated_features(df):\n    # Compute weighted mean\n    a_s = df['flux'] * np.power(df['flux'] \/ df['flux_err'], 2)\n    b_s = np.power(df['flux'] \/ df['flux_err'], 2)\n    wmean = np.sum(a_s) \/ np.sum(b_s)\n\n    flux_med = np.median(df['flux'])\n    # Compute normed flux\n    normed_flux = (df['flux'].max() - df['flux'].min()) \/ wmean\n\n    # normed_median_flux\n    normed_median_flux = np.median(np.abs(df['flux'] - flux_med) \/ wmean)\n    \n    return pd.Series([wmean, flux_med, normed_flux, normed_median_flux])\n\n# Same as above but using arrays\ndef compute_all_aggregated_features_v2(df):\n    # Compute weighted mean\n    a_s = df['flux'].values * np.power(df['flux'].values \/ df['flux_err'].values, 2)\n    b_s = np.power(df['flux'].values \/ df['flux_err'].values, 2)\n    wmean = np.sum(a_s) \/ np.sum(b_s)\n\n    flux_med = np.median(df['flux'].values)\n    # Compute normed flux\n    normed_flux = (np.max(df['flux'].values) - np.min(df['flux'].values)) \/ wmean\n\n    # normed_median_flux\n    normed_median_flux = np.median(np.abs(df['flux'] - flux_med) \/ wmean)\n    \n    return pd.Series([wmean, flux_med, normed_flux, normed_median_flux])\n\n# Arrays version + optimizations\ndef compute_all_aggregated_features_v3(df):\n    flux = df['flux'].values\n    flux_err = df['flux_err'].values\n    # Compute weighted mean\n    b_s = np.power(flux \/ flux_err, 2)\n    a_s = flux * b_s\n    wmean = np.sum(a_s) \/ np.sum(b_s)\n\n    flux_med = np.median(flux)\n    # Compute normed flux\n    normed_flux = (np.max(flux) - np.min(flux)) \/ wmean\n\n    # normed_median_flux\n    normed_median_flux = np.median(np.abs(flux - flux_med) \/ wmean)\n    \n    return pd.Series([wmean, flux_med, normed_flux, normed_median_flux])\n\nt1 = time.time()\nz1 = groups.apply(compute_all_aggregated_features)\nt2 = time.time()\nz2 = groups.apply(compute_all_aggregated_features_v2)\nt3 = time.time()\nz3 = groups.apply(compute_all_aggregated_features_v3)\nt4 = time.time()\nprint('pandas.Series: {0:.3f} s'.format(t2-t1))\nprint('arrays: {0:.3f} s'.format(t3-t2))\nprint('arrays+optimizations: {0:.3f} s'.format(t4-t3))\n","243197c1":"# Check results\nfor col in z1.columns:\n    a = np.abs(z1[col] - z2[col])\n    b = np.abs(z1[col] - z3[col])\n    print(col, np.max(a), np.max(b))","94e551b0":"def get_initial_aggregations():\n    return {\n        'flux': ['min', 'max', 'mean', 'median', 'std']\n    }\n\ndef get_initial_aggregations_v2(df):\n    flux = df['flux'].values\n    return pd.Series([np.min(flux), np.max(flux), np.mean(flux), np.median(flux), np.std(flux, ddof=1)])\n\nt1 = time.time()\nz1 = groups.agg(get_initial_aggregations())\nt2 = time.time()\nz2 = groups.apply(get_initial_aggregations_v2)\nt3 = time.time()\nprint('aggregations: {0:.3f} s'.format(t2-t1))\nprint('apply with arrays: {0:.3f} s'.format(t3-t2))","00a2cdb7":"# Check results\nz1.columns = ['_'.join([i, j]) for i, j in z1.columns]\nz2.columns = z1.columns\nfor col in z1.columns:\n    a = np.abs(z1[col] - z2[col])\n    print(col, np.max(a))","125ac931":"With the **apply** function it's clearly more efficient to use arrays than series.","d85db646":"### Aggregations vs apply","adf54650":"For statistics on series, the best option is using aggregations","d926b490":"### \"Apply\" function","bd2a1d7d":"Simple time benchmarks to know how to process features efficiently. Special thanks to Olivier's kernel: https:\/\/www.kaggle.com\/ogrellier\/multi-core-aggregations\/code, which has some differences with my code and made me think how pandas processes the data. I'll use some of his features and single core for simplicity ;)"}}