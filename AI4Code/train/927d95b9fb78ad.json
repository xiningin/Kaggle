{"cell_type":{"10c45fff":"code","f5f61253":"code","dee0e9f4":"code","d73395c9":"code","6a79849e":"code","d2f8d227":"code","ff8265a8":"code","0547d83f":"code","f7f534be":"code","ad0bd9ed":"code","a87284d1":"code","d33f0d5e":"code","f207c08a":"code","fb166102":"code","d53ba8cd":"code","59cdc54c":"code","dc601f0d":"code","f92a6dd1":"code","ffcd35b6":"code","26e3f8da":"code","f607c487":"code","44ed4c0b":"code","4cf6f976":"code","0e899180":"code","d3d49ed0":"code","5b7a7548":"code","aa83ffc8":"code","13f5a0d0":"code","148771df":"code","c08f7987":"code","ad90c715":"code","1533f54f":"code","0ebd2e6b":"code","49b52cfc":"code","d4773a1a":"code","ed357299":"code","435ca4b5":"code","0ff63d56":"code","adeaf1dd":"code","37d0f820":"markdown","5863620e":"markdown","278e09c9":"markdown","f677b4ca":"markdown","09ef278c":"markdown"},"source":{"10c45fff":"import torch\nimport pandas as pd,numpy as np\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\nfrom torch import nn\nimport os\nimport matplotlib.pyplot as plt\n","f5f61253":"torch.backends.cudnn.benchmarks =True","dee0e9f4":"# Reading the data houseSalesPrediction\npath = r'..\/input\/house-prices-advanced-regression-techniques'\ndata = pd.read_csv(os.path.join(path,'train.csv'))","d73395c9":"device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')","6a79849e":"#Finding out the columns\ndata.columns","d2f8d227":"# Drop the NA columns\ndata = data.replace(to_replace='NA',value=np.NaN)\ndata.dropna(inplace=True,axis=1)","ff8265a8":"data.shape","0547d83f":"# Lets take columns with unique values less than 90% or less than total values ( This will contribute to some learning)\n\ndataImpColumns = {columns:data[columns].count() for columns in list(data.columns) if len(data[columns].value_counts())<=0.9*data.shape[0]}","f7f534be":"# Take columns which are only important\ndata = data[list(dataImpColumns.keys())]","ad0bd9ed":"dict(zip(data['MSZoning'].unique(),range(len(data['MSZoning'].unique()))))","a87284d1":"#These columns needs to be lable encoded and will be required for Testing Purpose also\nlableEncodedColumnsDict = {column:dict(zip(data[column].unique(),range(len(data[column].unique())))) for column in data.columns if data[column].dtype=='O'}","d33f0d5e":"lableEncodedColumnsDict.keys()","f207c08a":"# Lets Label Encode the columns","fb166102":"data.replace(lableEncodedColumnsDict, inplace=True)\ndata.head()","d53ba8cd":"# Normalize the individual column\nnormalizeDict = {}\ndef normalize(series):\n    global normalizeDict\n    columnName = series.name\n    mean,std = series.mean(),series.std()\n    normalizeDict[columnName] = (mean,std)\n    return (series-mean)\/std","59cdc54c":"# Taking Features\ndatax = data[[column for column in data.columns if column!='SalePrice']].apply(normalize,axis=0)\n\n# The Predictor\ndatay = data[['SalePrice']].apply(normalize,axis=0)","dc601f0d":"# The Scaled Data\ndatascaled = (torch.tensor(datax.values,requires_grad=True).type(torch.float32),torch.tensor(datay.values,requires_grad=True).type(torch.float32))","f92a6dd1":"# Will be used to store the scaling factors\nnormalizeDict.keys()","ffcd35b6":"class datasetclass(Dataset):\n    \n    def __init__(self,):\n        super(datasetclass,self).__init__()\n        self.trainX = torch.Tensor(datascaled[0]).to(device)\n        self.trainY = torch.Tensor(datascaled[1]).to(device)\n\n\n    def __getitem__(self,index):\n        return self.trainX[index],self.trainY[index]\n    \n    def __len__(self,):\n        return len(self.trainX)","26e3f8da":"class modelClass(nn.Module):\n    \n    def __init__(self,inputDim,outputDim):\n        super(modelClass,self).__init__()\n        self.LinearLayer1 = nn.Linear(inputDim,inputDim)\n        self.LinearLayer2 = nn.Linear(inputDim,inputDim)\n        self.LinearLayer3 = nn.Linear(inputDim,inputDim)\n        self.LinearLayer4 = nn.Linear(inputDim,inputDim)\n        self.LinearLayer5 = nn.Linear(inputDim,outputDim)\n        self.ReLULayer1 =  nn.ReLU(inputDim)\n        self.ReLULayer2 = nn.ReLU(inputDim)\n        self.ReLULayer3 = nn.ReLU(inputDim)\n        self.ReLULayer4 = nn.ReLU(inputDim)\n        self.LReLULayer1 = nn.LeakyReLU(inputDim)\n        self.BatchNorm1 = nn.BatchNorm1d(inputDim)\n        self.BatchNorm2 = nn.BatchNorm1d(inputDim)\n        self.BatchNorm3 = nn.BatchNorm1d(inputDim)\n        self.optimizer = torch.optim.Adam(self.parameters(),lr=0.0001)\n        self.lossMSE = nn.modules.MSELoss()\n        self.output = torch.tensor([0.1])\n        \n    def forward(self,x):\n        x = self.LinearLayer1(x)\n        x = self.BatchNorm1(x)\n        x = self.ReLULayer1(x)\n        x = self.LinearLayer2(x)\n        x = self.BatchNorm2(x)\n        x = self.ReLULayer2(x)\n        x = self.LinearLayer3(x)\n        x = self.BatchNorm3(x)\n        x = self.ReLULayer3(x)\n        x = self.LinearLayer4(x)\n        x = self.ReLULayer4(x)\n        x = self.LinearLayer5(x)\n        return x\n    \n    def lossFunc(self,y,yhat):\n        return self.lossMSE(yhat,y)\n    \n    def backward(self,x,y):\n        yhat = self.forward(x)\n        self.output = self.lossFunc(y,yhat)\n        self.output.backward()\n        with torch.no_grad():\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n        ","f607c487":"# The batch size is 512\nbs = 512\nepochs = 500\ninputDim = len(datascaled[0][0])\noutputDim = 1","44ed4c0b":"datasetObj = datasetclass()\ndata_loader = DataLoader(datasetObj, batch_size=bs, shuffle=True)","4cf6f976":"# 8 feature is taken into consideration and a single output is compared to the actual to the loss.\nmodelObj = modelClass(inputDim,outputDim)\nmodelObj.to(device)","0e899180":"data_loader = DataLoader(datasetObj, batch_size=bs, shuffle=True)","d3d49ed0":"# 500 epochs are taken and trained and loss is calculated.\nloss_values = []\nfor epoch in range(epochs):\n    for x,y in data_loader:\n        modelObj.train()\n        modelObj.backward(x,y)\n        running_loss = modelObj.output\n    loss_values.append(running_loss)\n    plt.plot(loss_values)\nprint('epoch is ', epoch , 'Final loss is ',modelObj.output)\n\n","5b7a7548":"# Feature Columns\ndataImpColumnsWithoutSalePrice = list(set(list(dataImpColumns.keys()))-{'SalePrice'})","aa83ffc8":"# sample_submission is read for comparing the actual\ndataValid = pd.read_csv(os.path.join(path,'test.csv'))\nsampleSubmission = pd.read_csv(os.path.join(path,'sample_submission.csv'))[['SalePrice']]","13f5a0d0":"# Filling NaN values with 0 , so the input to the model is not NaN\ndataValid = dataValid[dataImpColumnsWithoutSalePrice].fillna(0)\nsampleSubmission = sampleSubmission.fillna(0)\nprint(dataValid.shape,sampleSubmission.shape)","148771df":"# Label Encode for the test sample\ndataValid.replace(lableEncodedColumnsDict, inplace=True)","c08f7987":"# Normalize the columns\ndef normalizeValid(series):\n    columnName = series.name\n    mean,std = normalizeDict[columnName]\n    return (series-mean)\/std","ad90c715":"# Normalize the columns\ndatascaledTestX = dataValid.apply(normalizeValid,axis=0)\ndatascaledTestY = sampleSubmission.apply(normalizeValid,axis=0)","1533f54f":"# Normalize the columns\ndatascaledTestX = torch.tensor(datascaledTestX.values).type(torch.float32)\ndatascaledTestY = torch.tensor(datascaledTestY.values).type(torch.float32)","0ebd2e6b":"# Batch Input the columns\nclass datasetclassValid(Dataset):\n    \n    def __init__(self,):\n        super(datasetclassValid,self).__init__()\n        self.testX = datascaledTestX\n        self.testY = datascaledTestY\n        \n    def __getitem__(self,index):\n        return self.testX[index],self.testY[index]\n    \n    def __len__(self,):\n        return self.testX.shape[0]","49b52cfc":"datasetclassValidObj = datasetclassValid()\ndata_loader_valid = DataLoader(datasetclassValidObj, batch_size=bs, shuffle=False)","d4773a1a":"mean,std = normalizeDict['SalePrice']","ed357299":"## Submission Frame\nsubmit = pd.DataFrame(columns=['SalePrice'])","435ca4b5":"loss = []\nfor x,y in data_loader_valid:\n    modelObj.eval()\n    prediction = modelObj(x.to(device))*std+mean\n    submit = submit.append(pd.DataFrame(prediction.to(torch.device('cpu')).detach().numpy(),columns=['SalePrice']))","0ff63d56":"submit.tail()","adeaf1dd":"submit.to_csv('submisson.csv',index=False)","37d0f820":"## Model and Dataset Building","5863620e":"## Next Steps\n1. Feature importance is required for training the model and increase the accuracy\n2. EDA needs to be done.","278e09c9":"### Train Data","f677b4ca":"## Denormalized And Testing Module","09ef278c":"## Lets understand the data"}}