{"cell_type":{"7dc3cc33":"code","9c371ab9":"code","6c19f4cc":"code","10ef0c8c":"code","5297c0cc":"code","03862818":"code","c120352b":"code","845ebe7e":"code","72a27334":"code","f063d3de":"code","9b353e2f":"code","1f68c3db":"code","7eb4bf6e":"code","d7aebb76":"code","412d427b":"code","0c514c49":"code","3742b4aa":"code","c9b1fc7d":"code","b033d976":"code","edb63f69":"code","5432bfb9":"code","f4f49ad2":"code","31d8b014":"code","42f3153f":"code","4d7a543e":"code","91da384d":"code","eb6aab40":"code","9122e2fd":"code","163d31ac":"code","9bfead7f":"code","72f801a0":"code","cf772294":"markdown","c5dd87c3":"markdown","234c2e2a":"markdown","afedf34f":"markdown","5c2759bc":"markdown","0ab62025":"markdown","ccbd3085":"markdown","cc57fa53":"markdown","5e9683a6":"markdown","221ee9be":"markdown","79237339":"markdown","dfbaf1f6":"markdown","823756e3":"markdown","41305eb1":"markdown","f661ee6d":"markdown","f334d25b":"markdown","1f87a604":"markdown","167834b8":"markdown","bdb42762":"markdown","879dc635":"markdown","a39e3b2c":"markdown","a29a2c20":"markdown","41892843":"markdown","b8aa9ec0":"markdown","5fdc51c0":"markdown","875334b8":"markdown","49924d97":"markdown","d746f80a":"markdown","14063685":"markdown"},"source":{"7dc3cc33":"import sys\nprint(sys.executable)","9c371ab9":"import os\nimport glob\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nimport cv2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nprint(\"Python version used = \", sys.version)\nprint(\"Numpy version used = \", np.__version__)\nprint(\"OpenCV version used = \", cv2.__version__)\nprint(\"pydicom version used = \", pydicom.__version__)","6c19f4cc":"train = pd.DataFrame(pd.read_csv(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\"))\n\nprint(\"Shape of dataframe = \", train.shape)","10ef0c8c":"train.head()","5297c0cc":"train['class_name'].value_counts()","03862818":"train_class_distribution = train['class_name'].value_counts().sort_values()","c120352b":"train.info()","845ebe7e":"train.isna().sum().to_frame().rename(columns = {0 : \"NaN_count\"}).style.background_gradient(cmap = \"copper\")","72a27334":"map_name_to_id = {\n    \"Aortic enlargement\" : 0,\n    \"Atelectasis\" : 1,\n    \"Calcification\" : 2,\n    \"Cardiomegaly\" : 3,\n    \"Consolidation\" : 4,\n    \"ILD\" : 5,\n    \"Infiltration\" : 6,\n    \"Lung Opacity\" : 7,\n    \"Nodule\/Mass\" : 8,\n    \"Other lesion\" : 9,\n    \"Pleural effusion\" : 10,\n    \"Pleural thickening\" : 11,\n    \"Pneumothorax\" : 12,\n    \"Pulmonary fibrosis\" : 13,\n    \"No Finding(healthy)\" : 14\n}","f063d3de":"train.class_name.unique(), len(train.class_name.unique())","9b353e2f":"label_count = dict()\nfor label in tqdm(train.class_id.values) : \n    if label not in label_count : \n        label_count[label] = 1\n    else:\n        label_count[label] += 1\n\nlabels = [\"Aortic Enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\", \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung Opacity\", \"Nodule\/Mass\",\n         \"Other lesion\", \"Pleural effusion\", \"Pleural thickening\", \"Pneumothorax\", \"Pulmonary fibrosis\", \"No finding\"]\ncounts = [label_count[0], label_count[1], label_count[2], label_count[3], label_count[4], label_count[5], label_count[6], label_count[7], label_count[8],\n         label_count[9], label_count[10], label_count[11], label_count[12], label_count[13], label_count[14]]\nexplode = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n\nfig, ax = plt.subplots(figsize = (20, 12))\nax.pie(counts, explode = explode, labels = labels, shadow = True, startangle = 90)\nax.axis(\"equal\")","1f68c3db":"train.rad_id.unique()","7eb4bf6e":"r_count = dict()\nfor rad_id in train.rad_id.values : \n    if rad_id in r_count : \n        r_count[rad_id] += 1\n    else:\n        r_count[rad_id] = 1\n\nrad_ids = ['R11', 'R7', 'R10', 'R9', 'R17', 'R3', 'R8', 'R6', 'R5', 'R4', 'R2', 'R16', 'R1', 'R15', 'R13', 'R12', 'R14']\ncounts = [r_count['R11'], r_count['R7'], r_count['R10'], r_count['R9'], r_count['R17'], r_count['R3'], r_count['R8'], r_count['R6'],\n         r_count['R5'], r_count['R4'], r_count['R2'], r_count['R16'], r_count['R1'], r_count['R15'], r_count['R13'], r_count['R12'], r_count['R14']]\nexplode = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n\nfig, ax = plt.subplots(figsize = (20, 12))\nax.pie(counts, explode = explode, labels = rad_ids, shadow = True, startangle = 90)\nax.axis(\"equal\")","d7aebb76":"def dicom2numpy(path, voi_lut = True, fix_monochrome = True) : \n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut == True : \n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    \n    if fix_monochrome == True and dicom.PhotometricInterpretation == \"MONOCHROME1\" : \n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    return data","412d427b":"sample_image1 = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0007d316f756b3fa0baea2ff514ce945.dicom\")\nprint(\"Shape = \", sample_image1.shape)\n\n\n\n#plt.imshow(dcm.pixel_array,cmap='gray')\n\nplt.figure(figsize = (20, 12))\nplt.imshow(sample_image1,cmap='gray')\nplt.grid(False)\nplt.title(\"Sample Image\", fontsize = 16)","0c514c49":"\n# importing required libraries of opencv \nimport cv2 \n  \n# importing library for plotting \nfrom matplotlib import pyplot as plt \n  \n# reads an input image \nsample_image1 = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0007d316f756b3fa0baea2ff514ce945.dicom\")\nprint(\"Shape = \", sample_image1.shape)\n\n\n  \n# find frequency of pixels in range 0-255 \nhistr = cv2.calcHist([sample_image1],[0],None,[256],[0,256]) \n  \n# show the plotting graph of an image \n\nplt.plot(histr) \nplt.show() ","3742b4aa":"sample_image2 = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/006e2726c6aa72f042a08b1406c39d52.dicom\")\nprint(\"Shape = \", sample_image2.shape)\n\n\n\n#plt.imshow(dcm.pixel_array,cmap='gray')\n\nplt.figure(figsize = (20, 12))\nplt.imshow(sample_image2,cmap='gray')\nplt.grid(False)\nplt.title(\"Sample Image\", fontsize = 16)","c9b1fc7d":"\n# importing required libraries of opencv \nimport cv2 \n  \n# importing library for plotting \nfrom matplotlib import pyplot as plt \n  \n# reads an input image \nsample_image2 = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/006e2726c6aa72f042a08b1406c39d52.dicom\")\nprint(\"Shape = \", sample_image2.shape)\n\n\n  \n# find frequency of pixels in range 0-255 \nhistr = cv2.calcHist([sample_image2],[0],None,[256],[0,256]) \n  \n# show the plotting graph of an image \n\nplt.plot(histr) \nplt.show() ","b033d976":"plt.figure(figsize = (20, 20))\n\nplt.subplot(1,3,1)\nsample_image = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/000434271f63a053c4128a0ba6352c7f.dicom\")\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sample Image\", fontsize = 18)\n\nplt.subplot(1,3,2)\nsample_image = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/000434271f63a053c4128a0ba6352c7f.dicom\", voi_lut = False)\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sample Image + VOI_LUT = False\", fontsize = 18)\n\nplt.subplot(1,3,3)\nsample_image = dicom2numpy(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/000434271f63a053c4128a0ba6352c7f.dicom\", fix_monochrome = False)\nplt.imshow(sample_image, cmap = \"gray\")\nplt.grid(False)\nplt.title(\"Sample Image + Fix Monochrome = False\", fontsize = 18)\n","edb63f69":"print(pydicom.read_file(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/000434271f63a053c4128a0ba6352c7f.dicom\"))","5432bfb9":"train_image_ids = train.image_id.unique() # one person might have multiple diseases.\nprint(\"Number of unique IDS = \", len(train_image_ids))","f4f49ad2":"rows = []\ncolumns = []\nsex = []\nfor pat_id in tqdm(train_image_ids) : \n    path = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/\"+pat_id+\".dicom\"\n    dicom_file = pydicom.read_file(path, stop_before_pixels = True)\n    rows.append(dicom_file.Rows)\n    columns.append(dicom_file.Columns)\n    sex.append(dicom_file.PatientSex)\n\nadditional_metadata = pd.DataFrame({\n    \"image_id\" : train_image_ids,\n    \"rows\" : rows,\n    \"columns\" : columns,\n    \"sex\" : sex\n})\n\nprint(\"Shape of additional metadata frame = \", additional_metadata.shape)\nadditional_metadata.head()","31d8b014":"male_count = len(additional_metadata[additional_metadata[\"sex\"] == \"M\"])\nfemale_count = len(additional_metadata[additional_metadata[\"sex\"] == \"F\"])\n\nprint(\"Male : Female Ratio = \", male_count \/ female_count )","42f3153f":"additional_metadata.sex.unique()","4d7a543e":"plt.figure(figsize = (12, 8))\nsns.countplot(additional_metadata[\"sex\"], palette = \"dark\")\nplt.grid(True)\nplt.axis('on')\nplt.title(\"Gender Count\", fontsize = 18)","91da384d":"plt.figure(figsize = (20, 12))\nx = additional_metadata[\"rows\"]\ny = additional_metadata[\"columns\"]\nplt.scatter(x, y, cmap = \"plasma\", label = \"Training Images\")\nplt.title(\"Shape Analysis Of Training Images\", fontsize = 18)\nplt.xlabel(\"Number Of Rows\", fontsize = 18)\nplt.ylabel(\"Number Of Columns\", fontsize = 18)\nplt.grid(True)\nplt.axis('on')\nplt.legend()","eb6aab40":"plt.figure(figsize = (12, 8))\nx = additional_metadata[\"rows\"]\ny = additional_metadata[\"columns\"]\nsns.distplot(x * y, kde = True, color = \"brown\")\nplt.xlabel(\"pixel count\", fontsize = 16)\nplt.title(\"Pixel Count Analysis\", fontsize = 18)\nplt.grid(True)\nplt.axis(\"on\")","9122e2fd":"train.head()","163d31ac":"df = train[train[\"class_id\"] != 14]\n\nimages = []\nimage_ids = df.image_id.values\nclass_ids = df.class_id.unique()\n\n# map label id to a random color(distinct for each class)\ncolor_mapping = dict()\nfor class_id in class_ids : \n    color_code = [random.randint(0, 255) for i in range(3)]\n    color_mapping[class_id] = color_code\n\nbox_thickness = 3\nscale = 4 # to scale the axes by this factor as images are real huge.\n\nfor i in tqdm(range(6)) : \n    image_id = np.random.choice(image_ids)\n    image_path = f\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/{image_id}.dicom\"\n    image = dicom2numpy(image_path)\n    image = cv2.resize(image, None, fx = 1\/scale, fy = 1\/scale)\n    \"\"\"\n    dsize is required param but if you still want the resize method to calculate the dsize for you then you may pass the param as None.\n    \"\"\"\n    image = np.stack([image, image, image], axis = -1)\n    \n    bounding_boxes = df.loc[df[\"image_id\"] == image_id, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values\/scale\n    \"\"\"\n    as we previously scaled the axes, it makes sense to scale these values too.\n    \"\"\"\n    labels = df.loc[df[\"image_id\"] == image_id, [\"class_id\"]].values.squeeze()\n    \n    for label_id, box in zip(labels, bounding_boxes) : \n        color = color_mapping[label_id]\n        image = cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, box_thickness)\n    image = cv2.resize(image, (500, 500))\n    images.append(image)\n\nplt.figure(figsize = (20, 20))\nfor n in range(6) : \n    plt.subplot(3, 2, n+1)\n    annotated_image = images[n]\n    plt.imshow(annotated_image, cmap = \"gray\")\n    plt.grid(False)\n    plt.axis('off')\nplt.tight_layout()","9bfead7f":"def plot_selected(class_name) :\n    class_id = map_name_to_id[class_name]\n    df = train[train[\"class_id\"] == class_id]\n    images = []\n    image_ids = df.image_id.values\n    color_mapping = [random.randint(0, 255) for i in range(3)]\n    box_thickness = 3\n    scale = 4\n    \n    for i in tqdm(range(6)) :\n        image_id = np.random.choice(image_ids)\n        image_path = f\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/{image_id}.dicom\"\n        image = dicom2numpy(image_path)\n        image = cv2.resize(image, None, fx = 1\/scale, fy = 1\/scale)\n        \"\"\"\n        dsize is required param but if you still want the resize method to calculate the dsize for you then you may pass the param as None.\n        \"\"\"\n        image = np.stack([image, image, image], axis = -1)\n    \n        bounding_boxes = df.loc[df[\"image_id\"] == image_id, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values\/scale\n        \"\"\"\n        as we previously scaled the axes, it makes sense to scale these values too.\n        \"\"\"\n        \n        for box in bounding_boxes :\n            image = cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color_mapping, box_thickness)\n        image = cv2.resize(image, (500, 500))\n        images.append(image)\n\n    plt.figure(figsize = (20, 20))\n    for n in range(6) : \n        plt.subplot(3, 2, n+1)\n        annotated_image = images[n]\n        plt.imshow(annotated_image, cmap = \"gray\")\n        plt.title(class_name, fontsize = 16)\n        plt.grid(False)\n        plt.axis('off')\n    plt.tight_layout()   ","72f801a0":"for class_name in map_name_to_id : \n    if class_name != \"No Finding(healthy)\" : \n        print(f\"Samples of {class_name} images\")\n        plot_selected(class_name)","cf772294":"So, we have significant missing values in our dataset. Let's see the exact NaN count per feature. \n\nDifferent colormaps available can be found here : [matplotlib_colormaps](https:\/\/matplotlib.org\/3.1.0\/tutorials\/colors\/colormaps.html)","c5dd87c3":"So, yes there is heavy imbalance when contribution of radiologists are concerned. R10, R9 and R8 collectively dominate the overall space!","234c2e2a":"# Class Name : \n\nThough we know there are 14 + 1(no finding) classes into which images are classified, and a single image may be diagnosed with multiple diseases, hence it becomes imperative to at least check whether the labels are available altogether in one entry(*we have to separate them if that's the case*), or the entry is repeated in the dataframe, having new label corresponding to it, till all the classes it's been diagnosed with are covered.","afedf34f":"# Radiologist Contribution Imbalance Study\n\nAs we have several radiologists labeling each image, it might be helpful to know whether there is existing of an imbalance in their respective work. Let's have a look at that.","5c2759bc":"# Visualize Each Class Of Disease","0ab62025":"We are only interested in visualizing bounding boxes. However, a good fraction of the bulk is healthy. So, it seems wise to drop it for this visualization purpose, as no bounding box exists for these cases. In dataframe, all coordinates are marked by NaN, indicating this fact.","ccbd3085":"# Bounding Box Visualization","cc57fa53":"# Shape Analysis","5e9683a6":"# A Note ON DICOM File Format : \n\n![O8sWTt0.jpg](https:\/\/i.imgur.com\/O8sWTt0.jpg)\n\n\nDICOM stands for **Digital Imaging and Communications in Medicine**. It is a standard, internationally accepted format to view, store, retrieve and share medical images. DICOM conforms to set protocols to maintain accuracy of information relayed through medical images. \n\nAny DICOM medical image consists of two parts \u2014 **a header and the actual image itself**. \n\n![image.png](attachment:image.png)\n\n* The header consists of data that describes the image, the most important being patient data. This includes the patient\u2019s demographic information such as the patient\u2019s name, age, gender, and date of birth. \n* The header may also give information on image characteristics such as acquisition parameters, pixel intensity, matrix size, and dimensions of the image. All info in DICOM(.dcm) files are provided using **separate tags**. \n\n16 bit DICOM images have values ranging from -32768 to 32768 while 8-bit grey-scale images store values from 0 to 255. The value ranges in DICOM images are useful as they correlate with the Hounsfield Scale which is a quantitative scale for describing radio-density (or a way of viewing different tissues densities).\n\n## Hounsfield Units : \n\nThe Hounsfield Units (HU) make up the grayscale in medical CT imaging. **It is a scale from black to white of 4096 values (12 bit) and ranges from -1024 HU to 3071 HU (zero is also a value). It is defined by the following:**\n\n*-1024 HU is black and represents air (in the lungs). 0 HU represents water (since we consist mostly out of water, there is a large peak here). 3071 HU is white and represents the densest tissue in a human body, tooth enamel. All other tissues are somewhere within this scale; fat is around -100 HU, muscle around 100 HU and bone spans from 200 HU (trabecular\/spongeous bone) to about 2000 HU (cortical bone).**\n\nMetal implants typically have very high Hounsfield units. Therefore, they are attributed the maximum value in typical 12-bit CT scans (3071).\n\n## DICOM LUT : \n\n* **Modality LUT** : A \"Modality LUT \" allows the transformation of manufacturer-dependent pixel values into manufacturer-independent pixel values (e.g., Hounsfield units for CT images). \n* **VOI LUT** : A \"VOI LUT\" allows the transformation of the modality pixel values into pixel values that are meaningful for print or display. This transformation is applied after any \"Modality LUT\".","221ee9be":"**Aortic enlargement** == An abnormal bulge that occurs in the wall of the major blood vessel.\n\n**Atelectasis** == Collapse of a part of the lung due to a decrease in the amount of air in the alveoli resulting in volume loss and increased density.\n\n**Calcification** == Deposition of calcium salts in the lung.\n\n**Cardiomegaly** == Enlargement of the heart, occurs when the heart of an adult patient is larger than normal and the cardiothoracic ratio is greater than 0.5.\nConsolidation == Any pathologic process that fills the alveoli with fluid, pus, blood, cells (including tumor cells) or other substances resulting in lobar, diffuse or multifocal ill-defined opacities.\n\n**Interstitial lung disease (ILD)** == Involvement of the supporting tissue of the lung parenchyma resulting in fine or coarse reticular opacities or small nodules.\n\n**Infiltration** == An abnormal substance that accumulates gradually within cells or body tissues or any substance or type of cell that occurs within or spreads as through the interstices (interstitium and\/or alveoli) of the lung, that is foreign to the lung, or that accumulates in greater than normal quantity within it.\n\n**Lung opacity** == Any abnormal focal or generalized opacity or opacities in lung fields (blanket tag including but not limited to consolidation, cavity, fibrosis, nodule, mass, calcification, interstitial thickening, etc.)\n\n**Nodule\/Mass** == Any space occupying lesion either solitary or multiple.\n\n**Other lesion**== Other lesions that are not on the list of findings or abnormalities mentioned above.\n\n**Pleural effusion** == Abnormal accumulations of fluid within the pleural space.\n\n**Pleural thickening** == Any form of thickening involving either the parietal or visceral pleura.\n\n**Pneumothorax **== The presence of gas (air) in the pleural space.\n\n**Pulmonary fibrosis** == An excess of fibrotic tissue in the lung.**","79237339":"## Image Pixel Encapsulation\n\nHigher pixel count directly corresponds to quality and size of the image. Let's have a look at that too.","dfbaf1f6":"Indeed, there are. Let's have a look at the count of them all.","823756e3":"Data Description In this competition, we are classifying common thoracic lung diseases and localizing critical findings. This is an object detection and classification problem.\n\nFor each test image, you will be predicting a bounding box and class for all findings. If you predict that there are no findings, you should create a prediction of \"14 1 0 0 1 1\" (14 is the class ID for no finding, and this provides a one-pixel bounding box with a confidence of 1.0).\n\nThe images are in DICOM format, which means they contain additional data that might be useful for visualizing and classifying.","41305eb1":"# DICOM to Numpy Tensor : \n\nInsights taken from  : **[raddar notebook](https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way)**\n\nRaw dicom data is not actually linearly convertable to \"human-friendly\" png\/jpg. In fact, most of DICOM's store pixel values in exponential scale.\n\nSo in order to get jpg\/png we need to apply some transformations. DICOM metadata stores information how to make such \"human-friendly\" transformations.\n\n## Fix Monochrome : \n\nRegarding fix_monochrome, we use that since .dcm images contains many shades of grey and black in it. Hence, to bring down it to the same level (normalize), we do this. It helps in getting better insights from the medical images. Also, MONOCHROME2 images have intensities inverted vs MONOCHROME1. One goes from 0=air to XXXX=bone, while the other goes from 0=bone to XXXX=air. Hence the operation `data = np.amax(data) - data` is needed.","f661ee6d":"This is quite a healthy ratio between both genders. However, before closing the book on this one, let's cross confirm whether there are other genders too, in the dicom dataset.","f334d25b":"**Inference** : \n\nIn terms of skewness, it's quite a number. We can observe nearly 45%+ cases thankfully healthy(no-finding), however the diseased ones, the distribution of diseases is skewed. From overall perspective too, the imbalance is high enough to ring danger alarms! Down the line, this will have to be addressed.","1f87a604":"## Data Description","167834b8":"# Label Count : ","bdb42762":"## A Note On Dataset Feature - Class ID: \n\nFollowing are the class names and ids which are used on the metadata dataframe.\n\n* 0 - Aortic enlargement\n* 1 - Atelectasis\n* 2 - Calcification\n* 3 - Cardiomegaly\n* 4 - Consolidation\n* 5 - ILD\n* 6 - Infiltration\n* 7 - Lung Opacity\n* 8 - Nodule\/Mass\n* 9 - Other lesion\n* 10 - Pleural effusion\n* 11 - Pleural thickening\n* 12 - Pneumothorax\n* 13 - Pulmonary fibrosis\n* 14 - No Finding(healthy)","879dc635":"Majority of images have rows in range [2500, 3000] and columns = [2000, 3000].","a39e3b2c":"**References** : \n\n* [Building Neural Network for Medical Imaging using Deep Learning in Tensorflow (Part 1)](https:\/\/medium.com\/@verma.chandan\/building-neural-network-for-medical-imaging-using-deep-learning-in-tensorflow-part-1-ab993b7fb04f)\n* [Understanding DICOMs](https:\/\/towardsdatascience.com\/understanding-dicoms-835cd2e57d0b)\n* [DISCUSSION THREAD] : [Doubts With Dicom](https:\/\/www.kaggle.com\/c\/vinbigdata-chest-xray-abnormalities-detection\/discussion\/211855#1157539)","a29a2c20":"## VinBigData Chest X-ray Abnormalities Detection\n### Automatically localize and classify thoracic abnormalities from chest radiographs\n","41892843":"Extracting Metadata from this.","b8aa9ec0":"### import library","5fdc51c0":"Also, let's look at the metadata header of DICOM as well.","875334b8":"**Dataset information**\nThe dataset comprises 18,000 postero-anterior (PA) CXR scans in DICOM format, which were de-identified to protect patient privacy. All images were labeled by a panel of experienced radiologists for the presence of 14 critical radiographic findings as listed below:\n\n> 0 - Aortic enlargement 1 - Atelectasis 2 - Calcification 3 - Cardiomegaly 4 - Consolidation 5 - ILD 6 - Infiltration 7 - Lung Opacity 8 - Nodule\/Mass 9 - Other lesion 10 - Pleural effusion 11 - Pleural thickening 12 - Pneumothorax 13 - Pulmonary fibrosis","49924d97":"So, we don't have a scenario where labels are merged like *\"Aortic enlargmenet| Lung opacity\"*, which we would have to separate otherwise.","d746f80a":"# Gender Analysis","14063685":"![LhW7qsw.png](https:\/\/i.imgur.com\/LhW7qsw.png)"}}