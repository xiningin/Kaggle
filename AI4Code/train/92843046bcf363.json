{"cell_type":{"13a7d7be":"code","1c05b0de":"code","fce9d27b":"code","8534c804":"code","a88fffe5":"code","47b68e9e":"code","75708eb3":"code","11cb8794":"code","6c52c1a3":"code","32f8898c":"code","76765f70":"code","b53464ee":"code","741d2807":"code","2e82b410":"code","8f5a6fdc":"code","f77a1f0e":"code","db41c0ff":"code","1e9a55f7":"code","c4c29011":"code","722b4f2b":"code","7b5ede99":"code","b10ec3e4":"code","a7714ed6":"code","c121486a":"code","7bef2832":"code","aa698d79":"code","1ca7437e":"code","13667346":"code","a82425a6":"code","32a471df":"code","82814c64":"code","0a8c28fd":"code","0274710a":"code","14ba0c6f":"code","07c3e402":"code","7da0365f":"code","a8f7d8ab":"code","113ea0d0":"code","cafa0dc3":"code","e6f2abd0":"code","25ff5226":"code","2d115d13":"code","e9eb27dd":"code","d37bdc82":"code","a214b048":"code","c9cbd1ae":"code","3d84fd9a":"code","69dde7cc":"code","6bad5b5a":"code","37b52bf6":"code","088b524a":"code","167fa67d":"code","8f382136":"code","93a0a38a":"code","f09ba85c":"code","f00532e2":"code","26ba1055":"code","5775458d":"code","4c60907c":"code","982f8d2a":"code","60f0077a":"code","f044bf91":"code","e0b391ed":"code","e8c24307":"code","c2ffa2c8":"code","f5038153":"code","7acd9fe1":"code","d412b409":"code","f7b0db10":"code","9e1a64ca":"code","80e2331d":"code","15a059b9":"code","9832eeaa":"code","8b56fde3":"code","0efb0f0a":"code","43876e6d":"code","d7e6fecb":"code","20ffc77c":"code","cb3a0eff":"code","304edc9a":"code","4ed256e7":"code","0ba0617a":"code","b5eb4e17":"code","e87ab05d":"code","d4db78f9":"code","0581af31":"code","fe26af3f":"code","0e06bb8d":"code","91e961d7":"code","2f5e36be":"code","542a9557":"code","1f858b09":"code","8a369b7c":"code","45fc708b":"code","9c330dad":"code","ebaa733b":"code","25694a0b":"code","33203e17":"code","940ee83b":"markdown","9825f80e":"markdown","af39a964":"markdown","ea2408eb":"markdown"},"source":{"13a7d7be":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","1c05b0de":"# to import train and test of titanic dataset from kaggle\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","fce9d27b":"#  to copy titanic datasets ( as train and test) into another variable.\ndtr = train_data.copy()\ndts = test_data.copy()","8534c804":"dtr.info()","a88fffe5":"dts.info()","47b68e9e":"# To combine the dtr and dts data into one variable. \n# (We do this so as not to repeat the same operations on both notebooks (dtr and dts) on both datasets.)\ndf = pd.concat([dtr,dts], ignore_index=True)","75708eb3":"df.head()","11cb8794":"df.tail()","6c52c1a3":"# some of the operations on dataset that has numerical varibales. it is meaningless for categorical variables.\ndf.describe().T","32f8898c":"df[\"Pclass\"].value_counts()","76765f70":"df[\"Sex\"].value_counts()","b53464ee":"df[\"Embarked\"].value_counts()","741d2807":"df[\"SibSp\"].value_counts()","2e82b410":"df[\"Parch\"].value_counts()","8f5a6fdc":"df[\"Ticket\"].value_counts()","f77a1f0e":"sns.barplot(x= \"Pclass\", y = \"Survived\", data = df);","db41c0ff":"sns.barplot(x= \"Sex\", y = \"Survived\", data = df);","1e9a55f7":"sns.barplot(x= \"Embarked\", y= \"Survived\", data =df);","c4c29011":"sns.barplot(x= \"SibSp\", y = \"Survived\", data= df);","722b4f2b":"sns.barplot(x= \"Parch\", y = \"Survived\", data= df);","7b5ede99":"df.head()","b10ec3e4":"# To assign categorically 1 to passengers with any cabin number and 0 to those without a cabin number.\ndf[\"Cabin\"] = df[\"Cabin\"].notnull().astype(\"int\")","a7714ed6":"df[\"Cabin\"].value_counts()","c121486a":"sns.barplot(x= \"Cabin\", y = \"Survived\", data= df);","7bef2832":"df[\"Embarked\"].value_counts()","aa698d79":"df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")","1ca7437e":"df.info()","13667346":"df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())","a82425a6":"df.isnull().sum()","32a471df":"df[df[\"Fare\"].isnull()]","82814c64":"\ndf[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean()","0a8c28fd":"df[\"Fare\"][1043] = 13","0274710a":"df.isnull().sum()","14ba0c6f":"df.head()","07c3e402":"df.describe().T","7da0365f":"sns.boxplot(x=df[\"Fare\"])","a8f7d8ab":"Q1 = df[\"Fare\"].quantile(0.25)\nQ1","113ea0d0":"Q3 =  df[\"Fare\"].quantile(0.75)\nQ3","cafa0dc3":"IQR = Q3-Q1","e6f2abd0":"low_limit = Q1 - 1.5*IQR\nhigh_limit = Q3 + 1.5*IQR\nhigh_limit","25ff5226":"df[df[\"Fare\"] > high_limit]","2d115d13":"df[\"Fare\"].sort_values(ascending=False).head()","e9eb27dd":"df[\"Fare\"] = df[\"Fare\"].replace(512.3292, 263)","d37bdc82":"df.info()","a214b048":"df.head()","c9cbd1ae":"embarked_mapping = {\"S\":1, \"C\":2, \"Q\": 3} \ndf[\"Embarked\"] = df[\"Embarked\"].map(embarked_mapping)\n\n#2. method\n\n# for i in range(0, len(df[\"Embarked\"])):\n#     if df[\"Embarked\"][i] == \"S\":\n#         df[\"Embarked\"][i] = 1\n#     elif df[\"Embarked\"][i] == \"C\":\n#         df[\"Embarked\"][i] = 2\n#     elif df[\"Embarked\"][i] == \"Q\":\n#         df[\"Embarked\"][i] = 3","3d84fd9a":"df.head(20)","69dde7cc":"df.drop([\"Ticket\"],axis =1, inplace = True)","6bad5b5a":"df.head()","37b52bf6":"for i in range(0, len(df[\"Sex\"])):\n    if df[\"Sex\"][i] == \"male\":\n        df[\"Sex\"][i] = 1\n    elif df[\"Sex\"][i] == \"female\":\n        df[\"Sex\"][i] = 0\n# 2. method\n# # from sklearn import preprocessing\n# # lbe = preprocessing.LabelEncoder()\n# # df.Sex = lbe.fit_transform(df.Sex)\n   \n","088b524a":"df.head()","167fa67d":"df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","8f382136":"df.head()","93a0a38a":"df[\"Title\"].value_counts()","f09ba85c":"df.Title = df['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ndf.Title = df['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ndf.Title = df['Title'].replace('Mlle', 'Miss')\ndf.Title = df['Title'].replace('Ms', 'Miss')\ndf.Title = df['Title'].replace('Mme', 'Mrs')","f00532e2":"df.Title.value_counts()","26ba1055":"df[[\"Title\", \"Survived\"]].groupby([\"Title\"], as_index = False ).mean()\n","5775458d":"Title_mapping = {\"Mr\":1, \"Miss\":2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5} \ndf[\"Title\"] = df[\"Title\"].map(Title_mapping)","4c60907c":"df.head()","982f8d2a":"df.drop(\"Name\", axis =1, inplace= True)","60f0077a":"df.head()","f044bf91":"\n#  to make an Agegroup\n# df[\"AgeGroup\"] = 0\n# for i in range(0, len(df[\"Age\"])):\n#     if df[\"Age\"][i] <= 5:\n#         df[\"AgeGroup\"][i] = 1\n#     elif df[\"Age\"][i] <= 12:\n#         df[\"AgeGroup\"][i] = 2\n#     elif df[\"Age\"][i] <= 18:\n#         df[\"AgeGroup\"][i] = 3\n#     elif df[\"Age\"][i] <= 24:\n#         df[\"AgeGroup\"][i] = 4\n#     elif df[\"Age\"][i] <= 35:\n#         df[\"AgeGroup\"][i] = 5\n#     elif df[\"Age\"][i] <= 60:\n#         df[\"AgeGroup\"][i] = 6\n#     elif df[\"Age\"][i] > 60:\n#         df[\"AgeGroup\"][i] = 7\n# 2. Method\n# bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n# mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n# df['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = mylabels)\n\n# age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n# df['AgeGroup'] = df['AgeGroup'].map(age_mapping)\n\n# df.drop(\"Age\", axis = 1, inplace = True)","e0b391ed":"#  to make Fares in Group\n\n# df[\"FareBand\"]= pd.qcut(df[\"Fare\"], 5 , [1,2,3,4,5])\n# df.FareBand.value_counts()\n# df.drop(\"Fare\", axis= 1, inplace = True)","e8c24307":"df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]+1","c2ffa2c8":"df.head()","f5038153":"df[\"Single\"] = df[\"FamilySize\"].map(lambda x: 1 if x ==   1 else 0)\ndf[\"SmaFam\"] = df[\"FamilySize\"].map(lambda x: 1 if x ==   2 else 0)\ndf[\"MedFam\"] = df[\"FamilySize\"].map(lambda x: 1 if 3<=x<= 4 else 0)\ndf[\"LarFam\"] = df[\"FamilySize\"].map(lambda x: 1 if x >    4 else 0)","7acd9fe1":"df.head(5)","d412b409":"df = pd.get_dummies( df, columns = [\"Title\"], prefix = \"Tit\")\ndf = pd.get_dummies( df, columns = [\"Embarked\"], prefix = \"Em\")","f7b0db10":"df.head()","9e1a64ca":"df.info()","80e2331d":"# Applying \"One Hot Encoding\" method in \"Pclass\" Variable\n# df[\"Pclass\"] = df[\"Pclass\"].astype(\"category\")\n# df = pd.get_dummies(df, columns = [\"Pclass\"], prefix = \"Pc\")\n# df.head()","15a059b9":"df.drop([\"Parch\",\"SibSp\"], axis =1, inplace =True)","9832eeaa":"df.info()","8b56fde3":"df.head()","0efb0f0a":"dtr = df[0:891]","43876e6d":"dtr.info()","d7e6fecb":"dtr.head()","20ffc77c":"dtr[\"Survived\"] = dtr[\"Survived\"].astype(\"int\")","cb3a0eff":"dtr.head()","304edc9a":"dts = df[891:]\ndts.index = dts.index -891\n","4ed256e7":"dts.head()","0ba0617a":"dts.info()","b5eb4e17":"dts.drop(\"Survived\", axis =1, inplace =True)\ndts.head(5)","e87ab05d":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = dtr.drop([\"Survived\",\"PassengerId\"], axis = 1)\ntarget = dtr[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 42)","d4db78f9":"x_train.shape","0581af31":"x_test.shape","fe26af3f":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","0e06bb8d":"dts.head(5)","91e961d7":"# Random  Forest Classifier Maschine Learning Model\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","2f5e36be":"#set ids as PassengerId and predict survival \nids = dts['PassengerId']\npredictions = logreg.predict(dts.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv',index=False)","542a9557":"output.head()","1f858b09":"# GradientBoosting Classifier Maschine Learning Model\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","8a369b7c":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","45fc708b":"xgb = GradientBoostingClassifier()\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","9c330dad":"xgb_cv_model.fit(x_train, y_train)","ebaa733b":"xgb_cv_model.best_params_","25694a0b":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","33203e17":"xgb_tuned =  xgb.fit(x_train,y_train)\ny_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","940ee83b":"Data Visulation","9825f80e":"Data preparation","af39a964":"To find out how many different types of observation units are in categorical variables (**.value_counts()** function is for that.)","ea2408eb":"test ve train datasetini islemleri kisaltmak adina birlestirlim. en sonunda tekrar ayiracagiz"}}