{"cell_type":{"80aed4bb":"code","43443f72":"code","60881d0e":"code","c076fb77":"code","9466fd37":"code","2f2f5e03":"code","82bd74bd":"code","ff6307f3":"code","430e58f0":"code","7438ecf1":"code","19b318b6":"code","a0548f4d":"code","0fa2f47c":"code","d069aa6a":"code","f0a634fd":"code","4c4cbbe9":"code","7499c97c":"code","331f10f2":"code","9e426cef":"markdown","2dd1604d":"markdown","efbc95d7":"markdown","634a5499":"markdown"},"source":{"80aed4bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","43443f72":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","60881d0e":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","c076fb77":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","9466fd37":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","2f2f5e03":"# Look at page 5\npdf = os.path.join(outputFolder,'Quinn16.pdf[5]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Quinn16.jpg') # intro page to preview later","82bd74bd":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/Quinn16.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","ff6307f3":"# Plot WordCloud of page 5\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 5 of Quinn\")","430e58f0":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/Quinn16.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","7438ecf1":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p5\npdf = os.path.join(outputFolder,'Quinn16.pdf[5]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Quinn16.jpg')\npdfimage5 = Image.open('\/kaggle\/working\/Quinn16.jpg')","19b318b6":"# PDF to JPG for p7\npdf = os.path.join(outputFolder,'Quinn16.pdf[7]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Quinn16.jpg')\npdfimage7 = Image.open('\/kaggle\/working\/Quinn16.jpg')\n\n# PDF to JPG for p8\npdf = os.path.join(outputFolder,'Quinn16.pdf[8]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Quinn16.jpg')\npdfimage8 = Image.open('\/kaggle\/working\/Quinn16.jpg')","a0548f4d":"# Parse a PDF file and convert it to CSV using PyTesseract (p5)\ntext = pytesseract.image_to_string(pdfimage5)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","0fa2f47c":"# Parse a PDF file and convert it to CSV using Tika-Python (p290-291)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/Quinn16.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/Quinn16.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 289-291","d069aa6a":"#Explore page 3 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage8.size # crop image\npdfimage8.crop((0, 1240, w, h-1300)) # display exerpt of PDF","f0a634fd":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p5\npdf = os.path.join(outputFolder,'Quinn16.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Quinn16.jpg')\npdfimage3 = Image.open('\/kaggle\/working\/Quinn16.jpg')","4c4cbbe9":"#Explore page 3 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage3.size # crop image\npdfimage3.crop((0, 1240, w, h-1300)) # display exerpt of PDF","7499c97c":"# Pages 2, 3 and 8\ndfcombined.head() # preview csv of 289-291","331f10f2":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","9e426cef":"#PDF to CSV\n\nConvert Page 3 of PDF to CSV (Method 1 of 2: PyTesseract)","2dd1604d":"The name of the file was Quinn16 so when we join the number of the page it changes the name of the file and the programm can't regognize it. Therefore, I couldn't perform parse correctly. ","efbc95d7":"Das War's. Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","634a5499":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook"}}