{"cell_type":{"fee52033":"code","cb33593c":"code","786a6332":"code","cd4edacc":"code","99fbc065":"code","0acc6aa0":"code","89fc84ed":"code","1e342858":"code","fe4cc2e8":"code","b303892f":"code","53eea97b":"code","a6b119fd":"code","aa1f0af9":"code","9b740e57":"code","1798ec58":"code","b719664c":"code","78d47810":"code","b4475712":"code","ee6b3286":"code","daff3cbc":"code","28832893":"code","ce573a60":"code","ea8976d2":"code","2b0ad2ad":"code","26d6343a":"code","5238b77e":"code","8c6ea3b3":"code","f76c159c":"code","232786c1":"code","149cb3e2":"code","27dcb182":"code","38c96dae":"code","d84adbb6":"code","949f863a":"code","8eead028":"code","ef66e194":"code","10e2a5fd":"code","57abd480":"code","d115233d":"code","539ddc71":"code","276815b0":"code","a718408a":"code","344df681":"code","411eb7f7":"code","4f049e22":"code","7bce5691":"code","98404a95":"code","04b78961":"code","c024cb15":"code","05df76e1":"code","daa96f1e":"code","ea429306":"code","8abeb957":"code","f20b3660":"code","cf8c4626":"code","f98517d9":"code","49574053":"code","8d0ba859":"code","22e48697":"code","935dbcd4":"code","ee3ba37f":"code","2aeb672d":"code","f2a250bd":"code","1ac5bec3":"markdown","d61f0c01":"markdown","81c907f5":"markdown","c4c79d3a":"markdown","f28312f6":"markdown","55f1163a":"markdown","5cf2ea10":"markdown","2cc05597":"markdown","e1df3dd5":"markdown","d78d57f2":"markdown","b73fbcc7":"markdown","1e9b4bea":"markdown","84403e7c":"markdown","d6dee768":"markdown","220c1558":"markdown","3aaddc75":"markdown","befdced5":"markdown","2a191f77":"markdown","387f4eb6":"markdown","eab2570b":"markdown","f9cf5f2e":"markdown","10525ec0":"markdown","7c5a38ac":"markdown","766fb4f3":"markdown","4e257edd":"markdown","d1ebcdda":"markdown","62c955fd":"markdown","0e68bfa4":"markdown","e9417622":"markdown","326397ab":"markdown","2c8989f7":"markdown","3b296a15":"markdown","a81745fe":"markdown","29d72335":"markdown","8d5df4cb":"markdown","0fbefcb3":"markdown","cd5142af":"markdown","834fc21b":"markdown","754a876a":"markdown","9c3057ff":"markdown","5a0caeee":"markdown","7ba76a5b":"markdown","cabd9113":"markdown","730cbcb1":"markdown","45894b79":"markdown","4ff5aa8c":"markdown","d0b2815d":"markdown","d8829cc6":"markdown","3720d5ad":"markdown","90d56ccd":"markdown","68952b44":"markdown","987cb225":"markdown","14d94c57":"markdown","6b9cd50d":"markdown","1003dfa4":"markdown","206cd748":"markdown"},"source":{"fee52033":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cb33593c":"# import necessary libraries for visualization.\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\n\n# import sklearn text_processing library\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport spacy\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom wordcloud import WordCloud\n\nsns.set()\n\n%matplotlib inline","786a6332":"df = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\ndf.head(5)","cd4edacc":"# DataFrame Column can be found by using .dtypes method of DataFrame object\ndf.dtypes","99fbc065":"# In these case, we can use to_datetime method of pandas\ndf[\"date_added\"] = pd.to_datetime(df[\"date_added\"])","0acc6aa0":"df.dtypes","89fc84ed":"df.info()","1e342858":"# show_id should be unique,so let's check its uniqueness \n# nunique method can show the number of unique values in dataframe\ndf.nunique()","fe4cc2e8":"# First of all, let's check the value of type column\ndf[\"type\"].head()","b303892f":"sns.countplot(\"type\", data=df)\nplt.title(\"Show Type Count in Netflix dataset\")","53eea97b":"df[\"title\"]","a6b119fd":"# CountVectorizer?","aa1f0af9":"# Use Bag of Words, and vectorize all the words.\ncountvectorizer = CountVectorizer(stop_words=\"english\")\nbow = countvectorizer.fit_transform(df[\"title\"])\nbow.toarray(), bow.shape","9b740e57":"# Get feature names\nfeature_names = countvectorizer.get_feature_names()\n\n# View some feature names\nfeature_names[150:160]","1798ec58":"# Create data frame (column: words in title, row: each row of original dataframe)\nbow_result_df = pd.DataFrame(bow.toarray(), columns=feature_names)\nbow_result_df.head()","b719664c":"# Let's see the word that is used for 20 times.\nfrequent_word_df = pd.DataFrame(bow_result_df.sum(), bow_result_df.columns)\nfrequent_word_df = frequent_word_df.rename(columns={0:\"count\"})\nfrequent_word_df = frequent_word_df[frequent_word_df[\"count\"] > 20]\nfrequent_word_df.head(5)","78d47810":"frequent_word_sorted_df = frequent_word_df.sort_values(\"count\", ascending=False)\nfrequent_word_sorted_df.head()","b4475712":"plt.figure(figsize=(12, 4))\nsns.barplot(frequent_word_sorted_df.index, frequent_word_sorted_df[\"count\"])\nplt.xticks(rotation=60)\nplt.xlabel(\"Word\")\nplt.title(\"Word Count of Movie Titles\")","ee6b3286":"# How many NaN is included here?\ndf[\"director\"].isnull().sum()","daff3cbc":"# pick up directors who directs more than twice.\ndirector_df = df[\"director\"]\ndirector_removed_nan_df = director_df.dropna()\ndirector_removed_nan_df.head()","28832893":"# I want a dictionary which contains how many times does each director appear?\n# Key: Director(s) Name, Value: Appearance Count of each directors\ndirector_count = {}\n\nfor i in director_removed_nan_df.index:\n    director_count.setdefault(director_removed_nan_df[i], 0)\n    director_count[director_removed_nan_df[i]] += 1","ce573a60":"# In the director_count dictionary, we pick up the frequent directors.\n# Criteria: Appearance Count is 6 times and above.\nfrequent_director_count = {}\n\nfor key,value in director_count.items():\n    if value >= 6:\n        frequent_director_count.setdefault(key, value)","ea8976d2":"frequent_director_count","2b0ad2ad":"sorted_dict = sorted(frequent_director_count.items(), key=lambda x:x[1], reverse=True)\nx = []\ny = []\nfor i in range(len(sorted_dict)):\n    x.append(sorted_dict[i][0])\n    y.append(sorted_dict[i][1])","26d6343a":"plt.figure(figsize=(12,4))\nsns.barplot(x, y)\nplt.xticks(rotation=90)\nplt.yticks(np.arange(0, 20, step=1))\nplt.title(\"Director Count in Netflix\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Director(s)\")","5238b77e":"df[\"country\"][0]","8c6ea3b3":"df[\"country\"].dropna()[0].split(\",\")","f76c159c":"# Let's create the dictionary that contains how many times does each country appear?\n# Key: Country Name, Value: Times that each country appears.\nfrequent_country = {}\n\nfor i in df[\"country\"].dropna().index:\n    country_list = df[\"country\"].dropna()[i].split(\",\")\n    for country in country_list:\n        frequent_country.setdefault(country, 0)\n        frequent_country[country] += 1","232786c1":"# Sort it by using sorted function in dictionary.\nsorted_dict = sorted(frequent_country.items(), key=lambda x:x[1], reverse=True)\nx = []\ny = []\nfor i in range(len(sorted_dict)):\n    x.append(sorted_dict[i][0])\n    y.append(sorted_dict[i][1])","149cb3e2":"# Plot the result of the countries which is in top 20.\nplt.figure(figsize=(12, 4))\nsns.barplot(x[:20], y[:20])\nplt.xticks(rotation=90)\nplt.xlabel(\"Country\")\nplt.ylabel(\"Count\")\nplt.title(\"Country Count in Netflix\")","27dcb182":"df[\"date_added\"]","38c96dae":"df[\"date_added\"].isnull().sum()","d84adbb6":"date_count_series = df.groupby(\"date_added\")[\"show_id\"].count()\ndate_count_series.head()","949f863a":"plt.figure(figsize=(16, 4))\nplt.plot(date_count_series.index, date_count_series.values)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())","8eead028":"plt.figure(figsize=(16, 4))\nplt.plot(date_count_series[date_count_series.index >= \"2016-01-01\"].index, date_count_series[date_count_series.index >= \"2016-01-01\"].values)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\nplt.gca().xaxis.set_major_locator(mdates.YearLocator())","ef66e194":"plt.figure(figsize=(16, 4))\nplt.plot(date_count_series[date_count_series.index >= \"2019-01-01\"].index, date_count_series[date_count_series.index >= \"2019-01-01\"].values)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator())","10e2a5fd":"date_type_df = pd.DataFrame(date_count_series)\ndate_type_df[\"day_type\"] = date_count_series.index.dayofweek\ndate_type_df.head(5)","57abd480":"grouped_date_type_series = date_type_df.groupby(\"day_type\").count()\ngrouped_date_type_series","d115233d":"day_type=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n\nplt.bar(x=grouped_date_type_series.index, height=grouped_date_type_series[\"show_id\"])\nplt.xticks(np.arange(7), labels=day_type)\nplt.ylabel(\"Count\")\nplt.title(\"Day type Count in Netflix\")","539ddc71":"release_year_series = df.groupby(\"release_year\")[\"show_id\"].count()\nrelease_year_series.index = pd.to_datetime(release_year_series.index, format=\"%Y\")\nrelease_year_series.head(5)","276815b0":"plt.figure(figsize=(16, 4))\nplt.plot(release_year_series.index, release_year_series.values)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\nplt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\nplt.xticks(rotation=60)\nplt.title(\"Publish Year in all shows\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Year\")","a718408a":"df[\"rating\"].nunique()","344df681":"sns.countplot(df[\"rating\"])\nplt.xticks(rotation=90)\nplt.title(\"Rating Count in Netflix\")","411eb7f7":"df[\"duration\"]","4f049e22":"movie_duration_series = pd.DataFrame(df[df[\"type\"] == \"Movie\"][\"duration\"])\nmovie_duration_series.head(5)","7bce5691":"movie_duration_series = movie_duration_series.replace(\"(\\d*) min\", r\"\\1\", regex=True)\nmovie_duration_series[\"duration\"] = movie_duration_series[\"duration\"].astype(\"int64\")\nmovie_duration_series.head()","98404a95":"plt.hist(movie_duration_series[\"duration\"], bins=20)\nplt.xlabel(\"duration\")\nplt.ylabel(\"count\")\nplt.title(\"Movies duration histgram in Netflix\")","04b78961":"plt.hist(movie_duration_series[\"duration\"], bins=20, density=True)\nplt.xlabel(\"duration\")\nplt.ylabel(\"count\")\nplt.title(\"Relative Frequency Distribution of Movies duration in Netflix\")","c024cb15":"movie_duration_series.describe()","05df76e1":"df[\"listed_in\"]","daa96f1e":"# Key: show classification, Value: Count \nfrequent_listed_in = {}\n\nfor i in df[\"listed_in\"].index:\n    listed_in_list = df[\"listed_in\"][i].split(\",\")\n    for listed_in in listed_in_list:\n        frequent_listed_in.setdefault(listed_in, 0)\n        frequent_listed_in[listed_in] += 1\n","ea429306":"sorted_dict = sorted(frequent_listed_in.items(), key=lambda x:x[1], reverse=True)\nx = []\ny = []\nfor i in range(len(sorted_dict)):\n    x.append(sorted_dict[i][0])\n    y.append(sorted_dict[i][1])","8abeb957":"plt.figure(figsize=(12, 4))\nsns.barplot(x[:20], y[:20])\nplt.xticks(rotation=90)\nplt.xlabel(\"Show Type\")\nplt.ylabel(\"Count\")\nplt.title(\"Show Type Count in Netflix\")","f20b3660":"df[\"description\"][0]","cf8c4626":"# Use Bag of Words, and vectorize all the words.\ncountvectorizer = CountVectorizer(stop_words=\"english\")\nbow = countvectorizer.fit_transform(df[\"description\"])\nbow.toarray(), bow.shape","f98517d9":"# Get feature names\nfeature_names = countvectorizer.get_feature_names()\n\n# View feature names\nfeature_names[1500:1510]","49574053":"# Create data frame (column: words in description, row: each row of original dataframe)\nbow_result_df = pd.DataFrame(bow.toarray(), columns=feature_names)\nbow_result_df.head()","8d0ba859":"# Let's see the word that is used for 200 times.\nfrequent_word_df = pd.DataFrame(bow_result_df.sum(), bow_result_df.columns)\nfrequent_word_df = frequent_word_df.rename(columns={0:\"count\"})\nfrequent_word_df = frequent_word_df[frequent_word_df[\"count\"] > 200]\nfrequent_word_df.head(5)","22e48697":"frequent_word_sorted_df = frequent_word_df.sort_values(\"count\", ascending=False)\nfrequent_word_sorted_df.head()","935dbcd4":"plt.figure(figsize=(12, 4))\nsns.barplot(frequent_word_sorted_df.index, frequent_word_sorted_df[\"count\"])\nplt.xticks(rotation=60)\nplt.xlabel(\"Word\")\nplt.title(\"Word Count of Movie Description\")","ee3ba37f":"wordcloud = WordCloud(background_color=\"white\")","2aeb672d":"wordcloud.generate(\" \".join(df[\"description\"]))","f2a250bd":"plt.figure(figsize=(12, 6))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title(\"Show Description WordCloud in Netflix dataset\")","1ac5bec3":"Many movies are around 100 minutes.  \nAnd it seems the probability distribution is log-normal distribution.  \nWe can get some statistical values by describe method!","d61f0c01":"Oh, it is not weekly peak, but it is rather monthly than weekly.  \n(You can find the peaks in the first day of each month.)  \nNext, which day is the most popular day for publishing shows in Netflix? (Sunday? Saturday? or Weekday?)  \nWe can get the day type by using dayofweek \n(0. Monday, 1.Tuesday, ... 6. Sunday)","81c907f5":"OK, show_id is unique.  \nSo let's move on to next column, type!","c4c79d3a":"### type_column","f28312f6":"The number of unique values of \"type\" column is 2.  \nSo, it seems\"type\" is consisted of \"Movie\" and \"TV Show\". (No Null values in this column.)  \nThus, this time, let's use countplot of seaborn.","55f1163a":"The type of rating column is object.  \nHowever, it seems there are only some rating types  \n(i.e. they have some list in this column and pick out one respectively)  \nSo we have to know how many unique values are there in this column!","5cf2ea10":"OK, so far, we could prepare the object that we need to plot the graph.  \nThe only thing we have to do is just plotting!!!","2cc05597":"This result is very interesting.  \nAccording to the above result, **\"love\" is used most frequently in movie titles**.  \nAnd man the 2nd is man, 3rd is story.","e1df3dd5":"Next, before diving into each column data visualization, we should check each column type.  ","d78d57f2":"OK, date_added column can be now used as datetime","b73fbcc7":"### Description column\nFinally. let's move on to the last column, Description column.  \nLet's take a look at the first item.","1e9b4bea":"Hmm, most of the columns are object type.  \nAt least, date_added column should be used by **datetime64** type, **not by object** type","84403e7c":"## Data_and_Library_Import","d6dee768":"## Data Visualization of each column","220c1558":"In Netflix, International Movies are the most popular.  \nAlso, Dramas and Comedies are very popular in Netflix.  \nTo my surprise, Romantic Movies are nost so many in this dataset.","3aaddc75":"By using WordCloud, we can easily visualize the trends in Netflix show description.  \nLooking at this figure, \"life\", \"family\", and \"find\" are most important keywords in this Netflix dataset.","befdced5":"Each movie or show may include multiple countries like above.  \nSo use .split method and create country list in these cases.","2a191f77":"Then, let's plot the above result!! ","387f4eb6":"### Year column","eab2570b":"OK, we only have 14 unique values in this column, so plot the count below!","f9cf5f2e":"In this column, we can use Bag of Words and process the dataset.","10525ec0":"In title column, they are the text data type.  \nProcessing text data is more difficult than processing other numerical data.  \nIn this notebook, we process text data by using sklearn!  \nLet's find out the most frequent word in title using Bag of Words! ","7c5a38ac":"### Country column\nLet's move on to country column. Which country is the most frequent in this dataset?","766fb4f3":"To my surprise, Friday is the most typical day for publishing shows in one week.","4e257edd":"### listed_in column","d1ebcdda":"This result is very interesting.  \nAs you can see, from 2016, the number of shows in this dataset gradually increased.  \n\nOK, so let's check more detail from 2016.","62c955fd":"OK, in this column, it seems some NaN values are included.  \nLet's count how many NaNs is this column included at first.","0e68bfa4":"## Check_dataset","e9417622":"### Title column","326397ab":"# Let's Watch Movie! Netflix Data Visualization\n## What is the Trend of Netflix ?\n\nThis notebook is made for visualizing Netflix Dataset and figuring out the Trend of Netflix.\n\nFor example, in this notebook, following questions are answered.\n\n* Which is more common in this Netflix dataset, **movie or TV show**?\n* What is **the most frequent word in show Title** in this dataset? (Love? Man? Woman? Peace? ...)\n* Who is **the most frequent director** in this Netflix dataset? \n* **Which country** is the most frequent for these shows? (U.S? U.K? India? China? Korea? Japan? ...)\n* **Which day** is the most popular for publishing shows in Netflix? (Saturday? Sunday? Monday? ...)\n* **From which year**, has the total number of shows in Netflix increased? (About 2016? or more recently?...)\n* **How long** is the typical for the movie? (90 - 120 minutes or so? ...)\n* **Which show type** is the most frequent in Netflix? (Comedy? Love Romance? Action? ...)\n* **Which word** is the most frequent in movie description? (Life? Family? Love? ...)\n\nHere is table of contents in this notebook.\n\n[Data and Library Import](#Data_and_Library_Import)  \n[Check dataset](#Check_dataset)  \n[Data Visualization of each column](#Data-Visualization-of-each-column)  \n* [show_id](#show_id-column)  \n* [type](#type-column)\n* [Title](#Title-column)\n* [Director](#Director-column)\n* [Country](#Country-column)\n* [Date-added](#date_added-column)\n* [Year](#Year-column)\n* [Rating](#Rating-column)\n* [Duration](#duration-column)\n* [Listed_in](#listed_in-column)\n* [Description](#Description-column)  \n\n[Future Work](#Future-Work)","2c8989f7":"Next, let's take a look at title column.","3b296a15":"OK, the total number of missing data in this column is 11.  \nThen, let's plot how many movies or TV shows are published in each day\nIn such a case, **groupby** method is super useful.  \nBy doing the command below, we can get series data which has the publish date as index and the count of the shows as values.","a81745fe":"In some cases, plotting histgram with normed is better than just plotting the real count value.\nSo let's normalize the above graph.  \nIt is super easy! Just set density=True in hist function.","29d72335":"As you can guess, **United States** is the most frequent countries in Netflix!  \nMy country, Japan, is the 6th.","8d5df4cb":"## Future Work","0fbefcb3":"Ok, then let's visualize this result!   \nFirst of all, we want a sorted dataframe by count.","cd5142af":"Now Let's check each dataset one by one.  \nAnd visualize it with **matplotlib and seaborn** !","834fc21b":"TV show -> Season  \nMovie -> min  \nIn this notebook, I only focus on the duration time of Movie.","754a876a":"In this Netflix dataset, the number of Movie is about twice as many as that of TV show. ","9c3057ff":"Before doing anything, taking a look at dataset is the very first step of data science !!","5a0caeee":"As you can guess, netflix supplies many movies that is published in recent years.  \nEspecially, from 2015, many movies are published and supplied by Netflix.","7ba76a5b":"OK, we've done data visualization briefly.  \nHere I propose some future work!\n\n- Clustering of all shows in this dataset is interesting\n- Use stemming and get more accurate result in Bag of Words is important.\n- If we have users' ratings of all dataset, we can create recommendation system.\n\nThat's all. **Let's watch Movies in Netflix and Stay Home !!**\n\n**I appreciate your goods, all comments and feedbacks! Thank you!**","cabd9113":"Like what we've done in previous column, that is,  date-added column, we can use groupby to process data by release year!","730cbcb1":"### date_added column","45894b79":"Oh, Raul Campos and Jan Suter are the most frequent direcors in this Netflix dataset.  \nHave you seen the movies by them?","4ff5aa8c":"Sort this directory by values and visualize it.","d0b2815d":"Next, let's check about NaN data of each column.  \nBy using *.info method*, we can find the number of null obeject in each column, and the total length of dataset","d8829cc6":"### duration column","3720d5ad":"### Rating column","90d56ccd":"Oh, this result seems interesting, too.  \nObviously, peaks appear in some regular intervals.  \nIt seems weekly, so let's check it out more precisely!","68952b44":"Then check the column types and make sure date_added is datetime64 [ns]","987cb225":"This is very interesting, we can guess the popular topics in Netflix by using this result.  \nSome movies and shows are about someone's life, young people, family, and world.  \nIn this case, we can visualize by using word clowd.  ","14d94c57":"OK, length of the dataset is 6234.  \nAnd some columns include NaN values (ex. director, country ...)","6b9cd50d":"### show_id column","1003dfa4":"By the way, in jupyte notebook, if you wanna know how to use command,  \nyou can find out by using ? keyword like below.   \n(For now, I commented out because the method popped up a window)","206cd748":"### Director column\nFirst, let's take a look at this column.  \nIn this case, we can count the number of directors in the dataset. "}}