{"cell_type":{"b8889f80":"code","850f612d":"code","755923bb":"code","702be83e":"code","d07025b9":"code","53255ff8":"code","fcddf3db":"code","25951663":"code","7400b5dd":"code","b3a481d3":"code","bea52ef8":"markdown","1458e02b":"markdown"},"source":{"b8889f80":"from pathlib import Path\nimport json\nimport sys\nimport warnings\nwarnings.filterwarnings(\"ignore\")","850f612d":"import pandas as pd\nimport numpy as np\nfrom scipy import sparse\n\nfrom nltk.tokenize import TweetTokenizer\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC","755923bb":"DATA_DIR = Path('..\/input')\n\nBEAUTY_JSON = DATA_DIR \/ 'beauty_profile_train.json'\nFASHION_JSON = DATA_DIR \/ 'fashion_profile_train.json'\nMOBILE_JSON = DATA_DIR \/ 'mobile_profile_train.json'\n\nBEAUTY_TRAIN_CSV = DATA_DIR \/ 'beauty_data_info_train_competition.csv'\nFASHION_TRAIN_CSV = DATA_DIR \/ 'fashion_data_info_train_competition.csv'\nMOBILE_TRAIN_CSV = DATA_DIR \/ 'mobile_data_info_train_competition.csv'\n\nBEAUTY_TEST_CSV = DATA_DIR \/ 'beauty_data_info_val_competition.csv'\nFASHION_TEST_CSV = DATA_DIR \/ 'fashion_data_info_val_competition.csv'\nMOBILE_TEST_CSV = DATA_DIR \/ 'mobile_data_info_val_competition.csv'","702be83e":"with open(BEAUTY_JSON) as f:\n     beauty_attribs = json.load(f)\n        \nwith open(FASHION_JSON) as f:\n     fashion_attribs = json.load(f)\n        \nwith open(MOBILE_JSON) as f:\n     mobile_attribs = json.load(f)\n\nbeauty_train_df = pd.read_csv(BEAUTY_TRAIN_CSV)\nfashion_train_df = pd.read_csv(FASHION_TRAIN_CSV)\nmobile_train_df = pd.read_csv(MOBILE_TRAIN_CSV)\n\nbeauty_test_df = pd.read_csv(BEAUTY_TEST_CSV)\nfashion_test_df = pd.read_csv(FASHION_TEST_CSV)\nmobile_test_df = pd.read_csv(MOBILE_TEST_CSV)","d07025b9":"# sanity check\nlen(beauty_train_df), len(fashion_train_df), len(mobile_train_df)","53255ff8":"# sanity check\nlen(beauty_test_df), len(fashion_test_df), len(mobile_test_df)","fcddf3db":"# sanity check\nlen(beauty_test_df)*5 + len(fashion_test_df)*5 + len(mobile_test_df)*11","25951663":"categories = ['beauty', 'fashion', 'mobile']\nattrib_dicts = [beauty_attribs, fashion_attribs, mobile_attribs]\ntrain_dfs = [beauty_train_df, fashion_train_df, mobile_train_df]\ntest_dfs = [beauty_test_df, fashion_test_df, mobile_test_df]","7400b5dd":"def run_classifier(clf, output_filename):\n    predictions_df = pd.DataFrame()\n    for cat, attrib_dict, train_df, test_df in zip(categories, attrib_dicts, train_dfs, test_dfs):\n        print(cat)\n        for attrib in attrib_dict:\n            tokenizer = TweetTokenizer()\n            \n            # Optimization1: this list was compiled after testing with various ngram length\n            ngram4_list = ['Benefits', 'Pattern', 'Collar Type', 'Fashion Trend', \n                           'Clothing Material', 'Features', 'Network Connections', \n                           'Warranty Period', 'Color Family']\n            ngram_max = 4 if attrib in ngram4_list else 3\n            \n             # Optimization 2: different value C compiled after repeated testing \n            if attrib == 'Brand':\n                if cat == 'Beauty':\n                    clf.C = 1.0\n                elif cat == 'Mobile':\n                    clf.C = 0.8\n            elif attrib in ('Benefits', 'Product_texture', 'Sleeves', 'Operating System', \n                            'Network Connections', 'Storage Capacity'):\n                clf.C = 1.0\n            elif attrib in ('Pattern', 'Features', 'Warranty Period', 'Color Family', \n                            'Camera', 'Phone Screen Size'):\n                clf.C = 0.7\n            else:\n                clf.C = 0.8\n            \n            vectorizer = TfidfVectorizer(ngram_range=(1, 4), tokenizer=tokenizer.tokenize, \n                                         min_df=2, max_df=1.0, strip_accents='unicode', \n                                         use_idf=1, smooth_idf=1, sublinear_tf=1 )\n            print(f'\\t{attrib} with {len(attrib_dict[attrib])} different classes')\n            X = train_df[['title', attrib]].dropna()\n            X_train = vectorizer.fit_transform(list(X.title))\n            y_train = X[attrib]\n\n            # these two lines are cross-validation to gauge the performance of the model\n            # it will not be necessary for actual training and prediction\n            scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', n_jobs=-1, cv=5)\n            print(f'\\t5-fold CV mean accuracy {(np.mean(scores) * 100):.2f}%, std {(np.std(scores) * 100):.2f}.')\n            \n            # actual training\n            clf.fit(X_train, y_train)\n            \n            # actual prediction\n            X_test = vectorizer.transform(list(test_df.title))\n            predictions = clf.predict(X_test)\n            \n            # convert prediction to desire output format\n            cur_prediction_df = pd.DataFrame({'id':test_df.itemid, 'tagging':predictions})\n            cur_prediction_df['id'] = cur_prediction_df['id'].apply(lambda row: str(row) + f'_{attrib}')\n            cur_prediction_df['tagging'] = cur_prediction_df['tagging'].astype('int')\n\n            predictions_df = pd.concat([predictions_df, cur_prediction_df], axis=0)\n            print()\n\n    predictions_df.to_csv(output_filename, index=None)","b3a481d3":"%%time\nrun_classifier(LinearSVC(), 'LinearSVC_predictions.csv')","bea52ef8":"# Using LinearSVC to predict the single best answer (without second answer)","1458e02b":"Besides deep learning with all the fancy LSTM models and embeddings and whatnot, I discovered the the SKLearn's LinearSVC performs the best among most of the machine learning models (compared to Logistic Regression, Multinomial NaiveBayes, RandomForest) with great speed. I am talking about sub 1-hour for training+prediction from end to end.\n\nHowever, the LinearSVC only gives one best prediction and not multiple predictions or by probabilities. There are ways to overcome this via CalibratedClassifierCV (https:\/\/www.kaggle.com\/c\/home-credit-default-risk\/discussion\/63499) but the results are far from consistent.\n\nSo I have used this prediction to overwrite my Deep Learning model predictions where they don't match and shift the original DL's first prediction to second prediction. I was assuming that the LinearSVC should perform better than my DL models based on the rough comparison between LinearSVC's 5-fold CV vs DL's train-test-split validation accuracy.\n\nDoing this gave me quite a huge boost in the leaderboard score.\n\nSo the following is the code just to **only predict the single best possible answer** for each test data, without second best prediction."}}