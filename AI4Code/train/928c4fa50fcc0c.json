{"cell_type":{"9c4bb5cb":"code","3f72ec13":"code","1e217e58":"code","295fe49e":"code","8946c4de":"code","283e4c3c":"code","d0b42a88":"markdown","b1ee6209":"markdown"},"source":{"9c4bb5cb":"import numpy as np\nimport pandas as pd\nimport json\nimport gc\nimport ast\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_columns', 100)\npd.set_option('max_rows', 100)","3f72ec13":"%%time\ntrain_csv = '\/kaggle\/input\/data-science-bowl-2019\/train.csv'\ntest_csv = '\/kaggle\/input\/data-science-bowl-2019\/test.csv'\nspecs_csv = '\/kaggle\/input\/data-science-bowl-2019\/specs.csv'\n\nall_train_event_attributes, all_test_event_attributes = [], []\ntrain_count, test_count = 0, 0\nfor chunk in pd.read_csv(train_csv,chunksize=10000):\n    chunk_attributes = chunk['event_data'].apply(lambda x: list(json.loads(x).keys()))\n    all_train_event_attributes.extend([y for x in chunk_attributes.to_list() for y in x])\n    train_count += chunk.shape[0]\n    \nfor chunk in pd.read_csv(test_csv,chunksize=10000):\n    chunk_attributes = chunk['event_data'].apply(lambda x: list(json.loads(x).keys()))\n    all_test_event_attributes.extend([y for x in chunk_attributes.to_list() for y in x])\n    test_count += chunk.shape[0]","1e217e58":"%%time\ncount_train = Counter(all_train_event_attributes)\ncount_test = Counter(all_test_event_attributes)\n\ndef get_count_df(count_dict, total):\n    df = pd.DataFrame.from_dict(count_dict, orient='index')\n    df['attribute']=df.index\n    df.columns = ['count', 'attribute']\n    df.sort_values(by=['count'], axis=0, ascending=False, inplace=True)\n    df['pct'] = df['count'] \/ total\n    return df\n\ncount_train_df = get_count_df(count_train, train_count)\ncount_test_df = get_count_df(count_test, test_count)","295fe49e":"plt.figure(figsize=(10, 30))\nsns.set(style='whitegrid')\nax = sns.barplot(x='pct', y='attribute', data=count_train_df.head(50))","8946c4de":"plt.figure(figsize=(10, 30))\nsns.set(style='whitegrid')\nax = sns.barplot(x='pct', y='attribute', data=count_test_df.head(50))","283e4c3c":"specs = pd.read_csv(specs_csv)\nspecs_parse = lambda _col:str([x['name'] for x in json.loads(_col)])\nspecs['attribute_list'] = specs['args'].apply(lambda _col: specs_parse(_col))\nspecs.head()","d0b42a88":"### to check the attributes to which events, we can check spec table","b1ee6209":"## This Kernel is a start point to analyze attributes of events\n\nThe `event_data` column is informative, but hard to break down, especially with the time and memory limitation.\nThis kernel gives a chunk-wise data loading and the distribution of attributes in both train and test data."}}