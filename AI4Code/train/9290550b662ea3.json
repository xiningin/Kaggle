{"cell_type":{"470c2af1":"code","6cf31418":"code","7b7eacf2":"code","90faa9be":"code","910673b1":"code","64faa447":"code","0d1ef3f3":"code","8e41dec5":"code","938aa655":"code","dd483448":"code","d6708cd9":"code","691a16fe":"code","659778a3":"code","fedda3fc":"code","77995b48":"code","04cf058d":"code","08510c43":"code","5496bd28":"code","502bf470":"code","3a4af73d":"code","6eb14027":"code","6dba4041":"code","19d3a7c0":"code","f119e4ed":"code","88a7efec":"code","c695e30c":"code","e665eb64":"code","5207f481":"code","31e22401":"code","780fa456":"code","c55cec6d":"code","708fec12":"code","09118e5d":"code","a6b6a3fe":"code","e70e17fe":"markdown","7a553250":"markdown","fa471b1e":"markdown","d5127982":"markdown","2bf1bb0d":"markdown","5e5c4db0":"markdown","e3784192":"markdown","c726d26c":"markdown","39cbbaca":"markdown","dcc9c1a7":"markdown","f9a5fc88":"markdown","a69ab2e3":"markdown","c3a0b241":"markdown","1c3cfc37":"markdown","dbb152b0":"markdown","b97c3d16":"markdown","1d6acd00":"markdown","9adf604f":"markdown","77ff924a":"markdown","8008a8b9":"markdown","979c969f":"markdown"},"source":{"470c2af1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","6cf31418":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","7b7eacf2":"from fastai import *\nfrom fastai.vision import *\nimport imageio\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns","90faa9be":"path = Path('..\/input\/Kannada-MNIST')\ntrain = pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest  =pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')","910673b1":"train.head(5)","64faa447":"train.describe()","0d1ef3f3":"y=train.label.value_counts()\nsns.barplot(y.index,y)\n","8e41dec5":"def to_img_shape(data_X, data_y=[]):\n    data_X = np.array(data_X).reshape(-1,28,28)\n    data_X = np.stack((data_X,)*3, axis=-1)\n    data_y = np.array(data_y)\n    return data_X,data_y","938aa655":"data_X, data_y = train.loc[:,'pixel0':'pixel783'], train['label']\n","dd483448":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(data_X, data_y, test_size=0.10,random_state=7,stratify=data_y)","d6708cd9":"train_X,train_y = to_img_shape(train_X, train_y)\nval_X,val_y = to_img_shape(val_X,val_y)","691a16fe":"def save_imgs(path:Path, data, labels):\n    path.mkdir(parents=True,exist_ok=True)\n    for label in np.unique(labels):\n        (path\/str(label)).mkdir(parents=True,exist_ok=True)\n    for i in range(len(data)):\n        if(len(labels)!=0):\n            imageio.imsave( str( path\/str(labels[i])\/(str(i)+'.jpg') ), data[i] )\n        else:\n            imageio.imsave( str( path\/(str(i)+'.jpg') ), data[i] )\n\nsave_imgs(Path('\/data\/train'),train_X,train_y)\nsave_imgs(Path('\/data\/valid'),val_X,val_y)","659778a3":"tfms = get_transforms(do_flip=False )","fedda3fc":"data = (ImageList.from_folder('\/data\/') \n        .split_by_folder()          \n        .label_from_folder()        \n        .add_test_folder()          \n        .transform(tfms, size=64)   \n        .databunch())","77995b48":"data","04cf058d":"data.show_batch(3,figsize=(6,6))","08510c43":"# Copying pretrained models from fastai-pretrained models in data to adequate folder\n!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp \/kaggle\/input\/fastai-pretrained-models\/resnet101-5d3b4d8f.pth \/tmp\/.cache\/torch\/checkpoints\/resnet101-5d3b4d8f.pth\n","5496bd28":"learn = cnn_learner(data, models.resnet101, metrics=[error_rate, accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"))","502bf470":"learn.fit_one_cycle(3)","3a4af73d":"learn.lr_find()","6eb14027":"learn.recorder.plot()","6dba4041":"lr = slice(2e-05)","19d3a7c0":"learn.save('stage-1')","f119e4ed":"learn.unfreeze()","88a7efec":"learn.fit_one_cycle(2,lr)","c695e30c":"learn.save('stage-2')","e665eb64":"test_csv = pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\ntest_csv.drop('id',axis = 'columns',inplace = True)\nsub_df = pd.DataFrame(columns=['id','label'])","5207f481":"test_data = np.array(test_csv)","31e22401":"# Handy function to get the image from the tensor data\ndef get_img(data):\n    t1 = data.reshape(28,28)\/255\n    t1 = np.stack([t1]*3,axis=0)\n    img = Image(FloatTensor(t1))\n    return img","780fa456":"from fastprogress import progress_bar\nmb=progress_bar(range(test_data.shape[0]))","c55cec6d":"for i in mb:\n    timg=test_data[i]\n    img = get_img(timg)\n    sub_df.loc[i]=[i+1,int(learn.predict(img)[1])]","708fec12":"def decr(ido):\n    return ido-1\n\nsub_df['id'] = sub_df['id'].map(decr)\nsub_df.to_csv('submission.csv',index=False)","09118e5d":"# Displaying the submission file\nsub_df.head()","a6b6a3fe":"# interfering the learner class with one image\n\nimg = data.train_ds[0][0]\nlearn.predict(img)","e70e17fe":"## About the contest\n\nThe goal of this competition is to provide a simple extension to the classic MNIST competition we're all familiar with. Instead of using classic MNIST with La LeCunn, it uses a recently-released dataset of Kannada digits.Kannada is a language spoken predominantly by people of Karnataka in southwestern India. The language has roughly 45 million native speakers and is written using the [Kannada script](https:\/\/en.wikipedia.org\/wiki\/Kannada). This work was made available by efforts of amazing research paper written by Prabhu, Vinay Uday on [Kannada-MNIST: A new handwritten digits dataset for the Kannada language.](https:\/\/arxiv.org\/abs\/1908.01242)\n\n\n![Screenshot-2019-10-1%20Kannada%20MNIST%20Kaggle.png](attachment:Screenshot-2019-10-1%20Kannada%20MNIST%20Kaggle.png)\n\n\nNote: This is a fork of @faizu07 kernel","7a553250":"Using the function `to_img_shape`, you reshape the input data which is passed in the form:\n\n`data_X:` Represents the various pixels of our data which is being passed and is reshaped adequately using numpy.\n\n`data_y:` We make our label into a numpy array","fa471b1e":"### Splitting train and test\n\n\n\nNow we will split out training data into train and validation data.10% of the training data will be used for validation purpose.\n","d5127982":"### Checking the contents of data","2bf1bb0d":"### Choosing the appropriate model\n\nUsing the correct model at the proper time is always, necessary. Use of internet is not allowed in this competiton, So we are using pre-trained models in the added kaggle dataset.","5e5c4db0":"### Making Submission","e3784192":"**Label:** This contains the label which are going to predict.That is our target value.Here it is numbers from 0 to 9 which represents the various Kannada characters.\n\n**pixel0-783:** These are the pixel values of the image metrics.That is each row contains 28 * 28 = 784 (0-783 here) values here.Each one of these values indicates the pixel value at i x 28 + j th pixel position in the image metric.Simple !","c726d26c":"**Preprocessing**","39cbbaca":"We have an balanced dataset with equal no of images in each classes.There are 6000 examples of each numbers in kannada in the the training dataset.Cool !\n","dcc9c1a7":"### Training our model for 2 more epochs","f9a5fc88":"In order to avoid both these problems and to have a balanced model, we are using Image augmentation techniques to double or triple the available data.\n\nSome popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\nTo learn more about Image augmentation techniques check out @init27s [amazing article](https:\/\/towardsdatascience.com\/introduction-to-image-augmentations-using-the-fastai-library-692dfaa2da42).","a69ab2e3":"### Thank You\n\n\n<div align='left'><font size='5' color=' #a93226 '>  If you like my work,please do upvote ^ <\/font><\/div>","c3a0b241":"<a href=\".\/submission.csv\"> Download Submission File <\/a>\n","1c3cfc37":"### Displaying a data bunch\n\nNicely displaying 9 images of given Kannada Alphabets","dbb152b0":"**Note**:\n\nKannada-MNIST dataset contains the following files:\n\n- train.csv\n- test.csv\n- sample_submission.csv\n\nRest of files in Input are `fastai-pretrained-models` from the [Kaggle Dataset](https:\/\/www.kaggle.com\/pronkin\/fastai-pretrained-models) fastiai-pretrained models with trained models:\n- VGG16\n- Resnets\n- Densenet\n- SqueezeNet ","b97c3d16":"## References\n\n- https:\/\/www.kaggle.com\/shahules\/indian-way-to-learn-cnn\n- https:\/\/docs.fast.ai\/","1d6acd00":"We are using **Resnet 101** for training our model. It fundamentally works on the principle of Resblocks which is a very revolutionary idea in the history of Deep Learning.\n\n\n![Screenshot-2019-10-3%20Lesson%207%20-%20ResNets,%20U-Nets,%20GANs%20and%20RNNs.png](attachment:Screenshot-2019-10-3%20Lesson%207%20-%20ResNets,%20U-Nets,%20GANs%20and%20RNNs.png)\n\nI am quoting what Jeremy Howards said during [Fastai Deep Learning Lesson7](https:\/\/www.youtube.com\/watch?v=9spwoDYwW_I) about Resnets and how Resblocks originated:\n\n![Screenshot-2019-10-3%20Lesson%207%20-%20ResNets,%20U-Nets,%20GANs%20and%20RNNs%281%29.png](attachment:Screenshot-2019-10-3%20Lesson%207%20-%20ResNets,%20U-Nets,%20GANs%20and%20RNNs%281%29.png)\n> The problem was pointed out in this paper, very influential paper called \"Deep Residual Learning for Image Recognition\" by Kaiming He and colleagues then at Microsoft Research. They did something interesting. Let's look at the training error. So forget generalization even. Let's look at the training error of a network train on CIFAR-10 and let's try one network with 20 layers just basic 3x3 conv basically the same network I've showed you but without BatchNorm. So I train a 20-layer one and the 56-layer one on the training set. So the 56-layer one has a lot more parameters, it got a lot more this stride 1 convs in the middle. The one with a lot more parameters should seriously overfit. You would expect the 56-layer one to zip down to zero-ish training error pretty quickly. And that is not what happened. It is worst for the shallower network.\n\n> So when you see something wierd happen, really good researcher don't go \"No it is not working.\". They go \"That's interesting.\". Kaiming He said \"That's interesting. What is going on?\". He said \"I don't know but what I do know is this. I could take this 56-layer network and make a new version of it which is identical but has to be at least as good as the 20-layer network and here's how. Every 2 convolutions, I am going to add together the input to those 2 convolutions, add it together with the result of those 2 convolutions.\". In other words, he is saying instead of saying output = c2(c1(x)), instead he is saying output = x + c2(c1(x)). That 56-layer worth of convolutions in that.\n\n> His theory was has to be at least as good as the 20-layer version because it could always just set conv2 and conv1 to a bunch of weights for everything except for the first 20 layers because the x, the input can just go straight through. So this thing here as you can see called an identity connection. It's the \"identity\" function, nothing happen at all. It is also known as the skip connection.\nSo that was the theory. That is what the paper described as the intuition behind this is what would happen if we created something which has to train at least as well as the 20-layer neural network because it kind of contains the 20-layer neural network is literally a path you can skip over all the convolutions","9adf604f":"### Analysing the given data\n","77ff924a":"### Loading the libraries\n\n**FastAI:** Fast.ai is amazing Deep Learning library to make Deep neural networks uncool again. Their fast.ai Massive Open Online Course (MOOC) on [Practical Deep Learning for Coders is simply amazing.](https:\/\/course.fast.ai\/)\n\n**Numpy:** For Mathematical operations\n\n**Pandas:** For handling CSV files\n\n**matplotlib & seaborn:** Used for charting and plotting.","8008a8b9":"### Applying Image augmentation\n\nCurrently we have about 6000 images of various characters in the classes. Yet in deep learning we usually face two problems ie Overfitting and Underfitting.\n\n**Overfitting:** Our learned models gets too specific for the given problem, and is not able to generalise the solution for a data outside of the trained images. Have you ever\nhad that weird experience of getting very high accuracy and seeing it perform bad in real life example. This is why generally we prefer to have a bigger validation dataset.\n\n**Underfitting:** Our model on having too less data is not able to learn the patterns from the given data\n\n![mlconcepts_image5.png](attachment:mlconcepts_image5.png)","979c969f":"We will make the final prediction for Test dataset using our trained ML model `learn`. \n\nNote: fastprogress is used to calculate the interference time as progess bar for the dataset"}}