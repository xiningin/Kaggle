{"cell_type":{"2c95c3b6":"code","eae86b2e":"code","520f9f57":"code","f73d15cb":"code","5d537669":"code","2875f255":"code","c2187660":"code","62847512":"code","5496165b":"code","298f3441":"code","60c60d29":"markdown","befd2bf4":"markdown","a9d790ad":"markdown","04f1e821":"markdown","59ba8b69":"markdown","3daa8098":"markdown","4c2c4dc5":"markdown","7ae7e186":"markdown","db9bbcb5":"markdown","0b5bc3a8":"markdown","9bf08a85":"markdown","f651d478":"markdown","e07aaffc":"markdown","bfc9ea5b":"markdown","78159273":"markdown","b9906ac8":"markdown","91ae4468":"markdown"},"source":{"2c95c3b6":"import os\nimport cv2\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","eae86b2e":"images=[]\nlabels=[]\nfor folders in os.listdir('..\/input\/tamilcharacterdataset\/classified_dataset\/classified_dataset'):\n    for files in os.listdir('..\/input\/tamilcharacterdataset\/classified_dataset\/classified_dataset\/'+folders):\n        img=cv2.imread('..\/input\/tamilcharacterdataset\/classified_dataset\/classified_dataset\/'+folders+'\/'+files,0)\/255\n        img=cv2.resize(img,(128,128))\n        img.shape=(128,128,1)\n        images.append(img)\n        labels.append(folders)\nimages=np.array(images)\nlabels=np.array(labels)        ","520f9f57":"from IPython.display import Image\nImage(\"..\/input\/cnnimage\/CNN-architecture-used-for-classification.png\")","f73d15cb":"model = Sequential()\nmodel.add(Conv2D(64, (5, 5), input_shape=(128,128,1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(32, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(32, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(11, activation='softmax'))\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","5d537669":"y_labels=to_categorical(labels)","2875f255":"X_train, X_test, y_train, y_test = train_test_split(images, y_labels, test_size=0.33, random_state=42)\nkeras.initializers.lecun_uniform(seed=None)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\n#datagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\n#model.fit_generator(datagen.flow(X_train, y_train, batch_size=320),\n #                   steps_per_epoch=len(X_train) \/ 32, epochs=20)\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=100, verbose=1)\nscores = model.evaluate(images, y_labels, verbose=1)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","c2187660":"model.predict(images[1233:1234])","62847512":"from IPython.display import Image\nImage(images[1233])","5496165b":"from matplotlib import pyplot as plt\nimg=images[1233]\nimg.shape=(128,128)\nplt.imshow(img)","298f3441":"model.predict_classes(images[1233:1234])","60c60d29":"### **Training** \n1.Spliting the data for training and validation \n2.Fitting the model and evaluating it","befd2bf4":"```python\n#please change directories according to your file system\nimport re\nfor files in  os.listdir(\".\/processed_dataset\"):\n    index1=re.findall(r'\\d\\dt',files)\n    index=int(index1[0][0:2])\n    img=cv2.imread('.\/processed_dataset\/'+str(files),0)\n    print(index)\n    if not os.path.exists('.\/classified_dataset\/'+str(index)+'\/'):\n        os.makedirs('.\/classified_dataset\/'+str(index)+'\/')\n    cv2.imwrite('.\/classified_dataset\/'+str(index)+'\/'+files,img)\n    ```","a9d790ad":"### Importing necessary packages","04f1e821":"1. Extracting images from the dataset and resizing it to shape 224,224. \n2. Binarizing the image using opencv-python","59ba8b69":"## **Data Classification**","3daa8098":"## **Dataset**","4c2c4dc5":"#### Converting 11 classes into one-hot encoding","7ae7e186":"## **Character Classification**","db9bbcb5":"Classification of images into seperate class folders","0b5bc3a8":"## **Data Preprocessing**","9bf08a85":"### **Generating image files from folders**","f651d478":"The dataset consists of 3000 images of Tamil Characters from  \u0b85 to \u0b93 . Each letter consists of approx. 300 images. Each of images are of different shapes. Dataset can be downloaded from [https:\/\/drive.google.com\/file\/d\/1fnfdaAAQA-v1l7USrpJAKSWzx3fD0ln8\/view?usp=sharing](https:\/\/drive.google.com\/file\/d\/1fnfdaAAQA-v1l7USrpJAKSWzx3fD0ln8\/view?usp=sharing)","e07aaffc":"### **Predicting Classes**","bfc9ea5b":"### **Defining the model**","78159273":"### **Classification of Tamil Characters using Convolutional Neural Networks**","b9906ac8":"Extract images from Files and append into images and coressponding classes into labels","91ae4468":"```python\n#please change directories according to your file system\nimport cv2 \nimport os\nfor files in  os.listdir(\".\/dataset\"):\n    print(files)\n    img=cv2.imread('.\/dataset\/'+str(files),0)\n    img2=255-img\n    img2=cv2.resize(img2, (224, 224)) \n```"}}