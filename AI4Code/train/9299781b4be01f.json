{"cell_type":{"ad19b8d6":"code","cf9bdc5c":"code","917c255d":"code","ef1a8e06":"code","949fb87e":"code","95d019be":"code","9262a815":"code","c03555e9":"code","c4b3a23b":"code","b3fef587":"code","ec8c9322":"code","11ce9209":"code","5538c88d":"code","d368b3fc":"code","809be519":"code","4d8f901e":"code","7f772f51":"code","7bd5561d":"code","91127b5a":"code","b4e57e47":"code","561e89c8":"code","b105113d":"code","f13bbb8f":"code","30aa87e2":"code","85ede32b":"code","399fa6b0":"code","255ce3f0":"code","38132a30":"code","2e9a8f46":"code","8713326a":"code","b6efa1dc":"code","67ee8366":"code","2ad11cfa":"markdown","e65dbaf9":"markdown","b6ee133f":"markdown","0396fada":"markdown","a6decca1":"markdown","467bcb7c":"markdown"},"source":{"ad19b8d6":"import numpy as np \nimport pandas as pd \n\n# for standardization\nfrom sklearn.preprocessing import StandardScaler as ss\n\n# for splitting into train and test datasets\nfrom sklearn.model_selection import train_test_split \n\n# for modelling\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# for balancing dataset by oversampling\nfrom imblearn.over_sampling import SMOTE, ADASYN\n\n# for performance metrics\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import auc, roc_curve, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# for data visualization\nimport matplotlib.pyplot as plt\n\n#Miscellaneous\nimport time\nimport random\nimport os\n","cf9bdc5c":"print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","917c255d":"# set number of rows to be displayed\npd.options.display.max_columns = 300\n\n# reading the dataset\ndata = pd.read_csv(\"..\/input\/creditcard.csv\")","ef1a8e06":"#Shape\ndata.shape\n","949fb87e":"#Columns\ndata.columns.values","95d019be":"# check if there are null values in the dataset\ndata.isnull().sum().sum()","9262a815":"#datatypes\ndata.dtypes.value_counts()","c03555e9":"#Checking unbalance data\ndata.Class.value_counts()","c4b3a23b":"data.head()\n","b3fef587":"data.tail()","ec8c9322":"import seaborn as sns\nsns.countplot(data['Class'])","11ce9209":"#Splitting Data as features and target","5538c88d":"X = data.iloc[:,0:30]\ny = data.iloc[:,30]","d368b3fc":"X_train, X_test, y_train, y_test =   train_test_split(X, y, test_size = 0.3, stratify = y)","809be519":"X_train.shape","4d8f901e":"y_train.value_counts()","7f772f51":"sm = SMOTE(random_state=42)\nX_bal, y_bal = sm.fit_sample(X_train, y_train)\n\ncolumns = X_train.columns\nX_bal = pd.DataFrame(data = X_bal, columns = columns)\n","7bd5561d":"print(X_train.shape)\nprint(X_bal.shape)\nprint(np.unique(y_bal, return_counts=True))","91127b5a":"# Intantiating RandomForest and XGBoost Models to train balanced data\nrf_sm = RandomForestClassifier(n_estimators=80)\nxg_sm = XGBClassifier(learning_rate=0.8,\n                   reg_alpha= 0.7,\n                   reg_lambda= 0.5\n                   )\n\n# training the models\nrf_sm1 = rf_sm.fit(X_bal,y_bal)\nxg_sm1 = xg_sm.fit(X_bal,y_bal)","b4e57e47":"# Predictions on the test data\n#For Random Forest\ny_pred_rf1 = rf_sm1.predict(X_test)\n#For XQBoost\ny_pred_xg1= xg_sm1.predict(X_test)","561e89c8":"#Probability\ny_pred_rf_prob1 = rf_sm1.predict_proba(X_test)\ny_pred_xg_prob1 = xg_sm1.predict_proba(X_test)","b105113d":"#fpr and tpr\n#For Random Forest\nfpr_rf, tpr_rf, thresholds = roc_curve(y_test,\n                                 y_pred_rf_prob1[: , 1],\n                                 pos_label= 1\n                                 )\n\n#For XQBoost\nfpr_xg, tpr_xg, thresholds = roc_curve(y_test,\n                                 y_pred_xg_prob1[: , 1],\n                                 pos_label= 1\n                                 )","f13bbb8f":"#Precision, Recall And F1 Score for RF and XGBoost\np_rf,r_rf,f_rf,_ = precision_recall_fscore_support(y_test,y_pred_rf1)\np_xg,r_xg,f_xg,_ = precision_recall_fscore_support(y_test,y_pred_xg1)\n","30aa87e2":"print(\"Accuracy of Randaom Forest : \",accuracy_score(y_test,y_pred_rf1))\nprint(\"Accuracy of XGBoost        : \",accuracy_score(y_test,y_pred_xg1))\nprint(\"Confusion Matrix for RF    :\\n \",confusion_matrix(y_test,y_pred_rf1))\nprint(\"Confusion Matrix XGBoost   :\\n \",confusion_matrix(y_test,y_pred_xg1))\nprint(\"AUC for Randaom Forest     : \",auc(fpr_rf,tpr_rf))\nprint(\"AUC for XGBoost            : \",auc(fpr_xg,tpr_xg))\nprint(\"Random Forest Precision, Recall and F1 Score are :\")\nprint(p_rf)\nprint(r_rf)\nprint(f_rf)\n\nprint(\"XGBoost Precision, Recall and F1 Score are :\")\nprint(p_xg)\nprint(r_xg)\nprint(f_xg)","85ede32b":"ad = ADASYN()\nX_ad, y_ad = ad.fit_sample(X_train, y_train)\n \nX_ad = pd.DataFrame(data = X_ad, columns = X_train.columns)\n","399fa6b0":"#Dataset is balanced now\nprint(X_train.shape)\nprint(X_ad.shape)\nprint(np.unique(y_ad, return_counts=True))","255ce3f0":"# Intantiating RandomForest and XGBoost Models to train balanced data\nrf_ad = RandomForestClassifier(n_estimators=80)\nxg_ad = XGBClassifier(learning_rate=0.9,\n                   reg_alpha= 0.8,\n                   reg_lambda= 1\n                   )\n\n# training the models\nrf_ad1 = rf_ad.fit(X_ad,y_ad)\nxg_ad1 = xg_ad.fit(X_ad,y_ad)","38132a30":"# Predictions on the test data\n#For Random Forest\ny_pred_rf2 = rf_ad1.predict(X_test)\n#For XQBoost\ny_pred_xg2= xg_ad1.predict(X_test)","2e9a8f46":"#Probability\ny_pred_rf_prob2 = rf_ad1.predict_proba(X_test)\ny_pred_xg_prob2 = xg_ad1.predict_proba(X_test)","8713326a":"#fpr and tpr\n#For Random Forest\nfpr_rf1, tpr_rf1, thresholds = roc_curve(y_test,\n                                 y_pred_rf_prob2[: , 1],\n                                 pos_label= 1\n                                 )\n\n#For XQBoost\nfpr_xg1, tpr_xg1, thresholds = roc_curve(y_test,\n                                 y_pred_xg_prob2[: , 1],\n                                 pos_label= 1\n                                 )","b6efa1dc":"#Precision, Recall And F1 Score for RF and XGBoost\np_rf2,r_rf2,f_rf2,_ = precision_recall_fscore_support(y_test,y_pred_rf2)\np_xg2,r_xg2,f_xg2,_ = precision_recall_fscore_support(y_test,y_pred_xg2)","67ee8366":"print(\"Accuracy of Randaom Forest : \",accuracy_score(y_test,y_pred_rf2))\nprint(\"Accuracy of XGBoost        : \",accuracy_score(y_test,y_pred_xg2))\nprint(\"Confusion Matrix for RF    :\\n \",confusion_matrix(y_test,y_pred_rf2))\nprint(\"Confusion Matrix XGBoost   :\\n \",confusion_matrix(y_test,y_pred_xg2))\nprint(\"AUC for Randaom Forest     : \",auc(fpr_rf1,tpr_rf1))\nprint(\"AUC for XGBoost            : \",auc(fpr_xg1,tpr_xg1))\nprint(\"Random Forest Precision, Recall and F1 Score are :\")\nprint(p_rf2)\nprint(r_rf2)\nprint(f_rf2)\n\nprint(\"XGBoost Precision, Recall and F1 Score are :\")\nprint(p_xg2)\nprint(r_xg2)\nprint(f_xg2)","2ad11cfa":"#Importing Necessary Libraries","e65dbaf9":"Splitting data into Train and Test","b6ee133f":"#Building model on dataset balanced using SMOTE","0396fada":"#Building model on dataset balanced using ADASYN","a6decca1":"Now the data is balanced","467bcb7c":"Reading Dataset and Exploration"}}