{"cell_type":{"e400c41f":"code","0fe5c13a":"code","78a60fc0":"code","466c71a2":"code","afc64c58":"code","d4bdd244":"code","a9c3f29b":"code","e54ebca8":"code","dd86fdca":"code","650b4aa3":"code","eb37924b":"code","c7404d65":"code","1ad33133":"code","d70d8046":"code","8d7388ac":"code","2dbefd9e":"code","5452e222":"code","362ed399":"code","fea5ebd7":"code","09fadacb":"code","23c2f490":"code","694c0adf":"code","6acd1ade":"code","ee4ab2f4":"code","ab8f5e82":"code","ac4b886b":"code","e1f87bb7":"code","1c95c8bc":"code","fc644f7f":"code","5dc985cd":"code","2abeab6b":"code","f8547488":"code","de7fa5a3":"markdown","5308f682":"markdown","24914d06":"markdown","b6476dd8":"markdown","04298433":"markdown"},"source":{"e400c41f":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error","0fe5c13a":"# Original code from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16 or not. feather format does not support float16.\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","78a60fc0":"%%time\nroot = Path('..\/input\/ashrae-feather-format-for-fast-loading')\ntrain_df = pd.read_feather(root\/'train.feather')\ntest_df = pd.read_feather(root\/'test.feather')\nbuilding_meta_df = pd.read_feather(root\/'building_metadata.feather')","466c71a2":"leak_df = pd.read_feather('..\/input\/ashrae-leak-data-station\/leak.feather')\n\nleak_df.fillna(0, inplace=True)\nleak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\nleak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 \nleak_df = leak_df[leak_df.building_id!=245]","afc64c58":"leak_df.meter.value_counts()","d4bdd244":"print (leak_df.duplicated().sum())","a9c3f29b":"print (len(leak_df) \/ len(train_df))","e54ebca8":"! ls ..\/input","dd86fdca":"del train_df\ngc.collect()","650b4aa3":"sample_submission1 = pd.read_csv('..\/input\/ashrae-kfold-lightgbm-without-leak-1-08\/submission.csv', index_col=0)\nsample_submission2 = pd.read_csv('..\/input\/ashrae-half-and-half\/submission.csv', index_col=0)\nsample_submission3 = pd.read_csv('..\/input\/ashrae-highway-kernel-route4\/submission.csv', index_col=0)\nsample_submission4 = pd.read_csv('..\/input\/stratifiedkfoldlgbxopy\/submission.csv', index_col=0)","eb37924b":"test_df['pred1'] = sample_submission1.meter_reading\ntest_df['pred2'] = sample_submission2.meter_reading\ntest_df['pred3'] = sample_submission3.meter_reading\ntest_df['pred4'] = sample_submission4.meter_reading\n\ntest_df.loc[test_df.pred3<0, 'pred3'] = 0 \ntest_df.loc[test_df.pred3<0, 'pred4'] = 0 \n\ndel  sample_submission1,  sample_submission2,  sample_submission3, sample_submission4\ngc.collect()\n\ntest_df = reduce_mem_usage(test_df)\nleak_df = reduce_mem_usage(leak_df)","c7404d65":"leak_df = leak_df.merge(test_df[['building_id', 'meter', 'timestamp', 'pred1', 'pred2', 'pred3', 'pred4', 'row_id']], left_on = ['building_id', 'meter', 'timestamp'], right_on = ['building_id', 'meter', 'timestamp'], how = \"left\")\nleak_df = leak_df.merge(building_meta_df[['building_id', 'site_id']], on='building_id', how='left')","1ad33133":"leak_df['pred1_l1p'] = np.log1p(leak_df.pred1)\nleak_df['pred2_l1p'] = np.log1p(leak_df.pred2)\nleak_df['pred3_l1p'] = np.log1p(leak_df.pred3)\nleak_df['pred4_l1p'] = np.log1p(leak_df.pred4)\nleak_df['meter_reading_l1p'] = np.log1p(leak_df.meter_reading)","d70d8046":"leak_df.head()","8d7388ac":"leak_df[leak_df.pred1_l1p.isnull()]","2dbefd9e":"#ashrae-kfold-lightgbm-without-leak-1-08\nsns.distplot(leak_df.pred1_l1p)\nsns.distplot(leak_df.meter_reading_l1p)\n\nleak_score = np.sqrt(mean_squared_error(leak_df.pred1_l1p, leak_df.meter_reading_l1p))\nprint ('score1=', leak_score)","5452e222":"#ashrae-half-and-half\nsns.distplot(leak_df.pred2_l1p)\nsns.distplot(leak_df.meter_reading_l1p)\n\nleak_score = np.sqrt(mean_squared_error(leak_df.pred2_l1p, leak_df.meter_reading_l1p))\nprint ('score2=', leak_score)","362ed399":"# meter split based\nsns.distplot(leak_df.pred3_l1p)\nsns.distplot(leak_df.meter_reading_l1p)\n\nleak_score = np.sqrt(mean_squared_error(leak_df.pred3_l1p, leak_df.meter_reading_l1p))\nprint ('score3=', leak_score)","fea5ebd7":"# kfold lgbm\nsns.distplot(leak_df.pred4_l1p)\nsns.distplot(leak_df.meter_reading_l1p)\n\nleak_score = np.sqrt(mean_squared_error(leak_df.pred4_l1p, leak_df.meter_reading_l1p))\nprint ('score4=', leak_score)","09fadacb":"leak_df['mean_pred'] = np.mean(leak_df[['pred1', 'pred2', 'pred3', 'pred4']].values, axis=1)\nleak_df['mean_pred_l1p'] = np.log1p(leak_df.mean_pred)\nleak_score = np.sqrt(mean_squared_error(leak_df.mean_pred_l1p, leak_df.meter_reading_l1p))\n\nsns.distplot(leak_df.mean_pred_l1p)\nsns.distplot(leak_df.meter_reading_l1p)\n\nprint ('mean score=', leak_score)","23c2f490":"class GAOptimizer:\n    def __init__(self, function, min_value=0.2, max_value=0.8, population_size=50, dimention=4):\n        self.function = function\n        self.population = np.random.uniform(min_value, max_value, (population_size, dimention))\n        self.population_size = population_size\n        self.dimention = dimention\n        half_dim1 = int(dimention\/2)\n        half_dim2 = int(dimention\/2) + 1 if dimention%2 else int(dimention\/2)\n        self.co_weights = np.hstack([np.ones((population_size, half_dim1)), np.zeros((population_size, half_dim2))])\n        \n    def crossover(self):\n        old_population = np.copy(self.population)\n        population = np.copy(self.population)\n        np.random.shuffle(population)\n        new_population = old_population*self.co_weights + population*(1 - self.co_weights) + np.random.normal(0, 0.1, (self.population_size, self.dimention))\n        \n        return np.vstack([old_population, new_population])\n    \n    def selector(self, n=None):\n        f_values = self.function(self.population)\n        self.population = self.population[np.argsort(f_values)[:self.population_size]]\n        if n:\n            return self.population[np.argsort(f_values)[:n]], self.function(self.population[np.argsort(f_values)[:n]])\n        \n\n    def fit(self, iters):\n        for i in range(iters):\n            self.population = self.crossover()\n            self.selector()\n        return self.selector(1)","694c0adf":"def func_to_opt(scores):\n    score = []\n    for x in scores:\n        v = x[0] * leak_df['pred1'].values + x[1] * leak_df['pred2'].values + \\\n        x[2] * leak_df['pred3'].values + x[3] * leak_df['pred4'].values\n        val  = (v > 0).astype(int)*v\n        vl1p = np.log1p(val)\n        curr_score = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p)) \n        score.append(curr_score)\n    return np.array(score)","6acd1ade":"%%time\nga_holder = GAOptimizer(function=lambda l: func_to_opt(l))\nresult = ga_holder.fit(40)  \nprint(result)","ee4ab2f4":"final = result[0].flatten()\/result[0].flatten().sum()\nprint(final)","ab8f5e82":"func_to_opt(np.array([final]))","ac4b886b":"sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\n\nw1 = final[0]\nw2 = final[1]\nw3 = final[2]\nw4 = final[3]\n\nsample_submission['meter_reading'] = w1 * test_df.pred1 +  w2 * test_df.pred2  + w3 * test_df.pred3 +\\\nw4 * test_df.pred4\nsample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0","e1f87bb7":"sample_submission.head()","1c95c8bc":"sns.distplot(np.log1p(sample_submission.meter_reading))","fc644f7f":"leak_df = leak_df[['meter_reading', 'row_id']].set_index('row_id').dropna()\nsample_submission.loc[leak_df.index, 'meter_reading'] = leak_df['meter_reading']","5dc985cd":"sns.distplot(np.log1p(sample_submission.meter_reading))","2abeab6b":"sample_submission.isna().sum()","f8547488":"sample_submission.to_csv('submission.csv', index=False, float_format='%.5f')","de7fa5a3":"# Genetic Algorithm","5308f682":"# Leak Validation for public kernels without leaks","24914d06":"# Submit","b6476dd8":"### Based on Kernels: \n\nhttps:\/\/www.kaggle.com\/khoongweihao\/ashrae-leak-validation-bruteforce-heuristic-search\n\nhttps:\/\/www.kaggle.com\/roydatascience\/ashrae-stratified-kfold-lightgbm\n","04298433":"# Leak Validation for Blending"}}