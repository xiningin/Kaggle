{"cell_type":{"8ae9308f":"code","e186183d":"code","542b32c5":"code","dd90be77":"code","bfe61b9c":"code","de4359ce":"code","483a0894":"code","9fa6e80b":"code","75132382":"code","7beee251":"code","30edbf99":"code","6ea85d05":"code","757e2f9c":"code","a7563d3f":"code","cb408057":"code","91a8079f":"code","3ac59417":"code","368e1abf":"code","0301b29a":"code","3f1c41b6":"code","3b85e81d":"code","70bdcca2":"code","92426e2c":"code","c3ac27ea":"code","81a62af0":"code","ec697ffe":"code","7cb551fd":"code","87e273f1":"code","a378ba54":"code","d6408e88":"code","82e000dd":"code","6beb056e":"code","612f9ce7":"code","05d8bbd2":"code","3a329c09":"code","5bcfdc85":"code","70fa1f5b":"code","be57ba10":"code","5708e8ca":"code","ad5489b1":"code","e4c5c68a":"code","a77b54c1":"code","d00a2ab5":"code","34118d9c":"code","2a41a77a":"code","a7259253":"code","d752500a":"code","b60d12a1":"code","c73d8033":"code","563601a8":"code","92d166e2":"code","e05e35cd":"code","36b18052":"code","e68a0482":"code","688229cf":"code","70aeefa3":"code","d9b4825c":"code","1da139a6":"code","8387d324":"code","4ba6a4c1":"code","eb6f6cf5":"code","5242de41":"code","7ee67088":"code","14af646e":"code","022bb322":"code","7c404fe0":"code","dc2d3acc":"code","8cf003f7":"code","8279f2ac":"code","f9ecc14f":"code","7563a056":"code","96d1aa9d":"code","35e6e6c1":"code","fd15422b":"code","2dfaa5db":"code","a3712c14":"code","1c202586":"code","2a67a22c":"code","8481ce5a":"code","eb6df7ef":"code","7e916d6d":"code","da213dd9":"code","bae48bc4":"code","e8ab71b0":"code","8dd32c45":"code","959334eb":"code","c0ea10de":"code","4034a558":"code","28373b5e":"code","a10c43c6":"code","d09dc9aa":"code","da4d977e":"code","1b4a70e3":"code","c1b0489e":"markdown","acac951d":"markdown","9e71056b":"markdown","a96dc8bd":"markdown","57c82c45":"markdown","bf5c92a8":"markdown","fcd2bb99":"markdown","af7da303":"markdown","e03b9a84":"markdown","9fd87744":"markdown","f4f0884f":"markdown","a8627dbd":"markdown","4ee9a413":"markdown","685a5e8d":"markdown","a334e2c6":"markdown","cc484d09":"markdown","fac20f6f":"markdown","79bc34e3":"markdown","3be61484":"markdown","042be81d":"markdown","05efcea5":"markdown","8bba1ca8":"markdown","dfa403d7":"markdown"},"source":{"8ae9308f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e186183d":"data = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\n#pd.read_csv(\"..\/input\/globalterrorismdb_0718dist.csv\",encoding=\"utf8\")\n","542b32c5":"data.info()","dd90be77":"data.corr()","bfe61b9c":"data.describe()","de4359ce":"data.head(100)","483a0894":"data.tail()","9fa6e80b":"data.columns\n","75132382":"data.dtypes\n","7beee251":"# terrorism correlation map\nf,ax = plt.subplots(figsize =(30,30))\nsns.heatmap(data.corr(),annot=True,linewidths=0.4, fmt='.0f',ax=ax)\nplt.show()\n","30edbf99":"data.isnull()\n#data.isnull().sum()","6ea85d05":"#line y\ndata.iyear.plot(kind = 'line', color = 'r',label = 'iyear',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.country.plot(kind = 'line', color = 'b' ,label = 'country ',linewidth=1,alpha = 0.5 ,grid = True,linestyle = '-.')\nplt.legend(loc = 'upper right') #show label and determine location\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line plot')\nplt.show() ","757e2f9c":"#scatter plot\n#x =iyear y =nkill\ndata.plot(kind='scatter',x ='iyear',y ='nkill',alpha = 0.6,color = 'b')\nplt.xlabel('iyear')\nplt.ylabel('nkill')\nplt.title(\"nkill year Scatter plot\")\nplt.show()","a7563d3f":"#histogram\n#bins = number of bar in plot\ndata.eventid.plot(kind ='hist',bins = 30,figsize = (10,10))\nplt.show","cb408057":"#clf=Clear the current figure\ndata.eventid.plot(kind='hist',bins=30)\nplt.clf()\n# we  can't see figure of clf","91a8079f":"series=data['iyear'] # series\nprint(type(series))\ndata_frame=data[['iyear']] #data frame\nprint(type(data_frame))","3ac59417":"#filtering pandas data frame\ny =data['iyear']>1998 \ndata[y]","368e1abf":"#filtering pandas with  logical _and\ndata[np.logical_and(data['iyear']>1998, data['imonth']<6)]\n","0301b29a":"#loops\nlist =[1,2,3,4,5]\nfor each in list :\n    print(\"i is \" , each)\nprint('')","3f1c41b6":"# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index ,value in enumerate(list):\n print(index ,\":\",value)","3b85e81d":"# For dictionaries\n# We can use for loop to achive key and value of dictionary\ndic = {'spain' : 'madrid','turkey': 'istanbul'}\nfor key, value in dic.items():\n    print(key, \":\",value)","70bdcca2":"# For pandas we can achieve index and value\nfor index ,value in data[['country_txt']][0:1].iterrows():\n    print(index,\":\",value)","92426e2c":"data.head()","c3ac27ea":"data.tail()","81a62af0":"data.shape # shape gives row and columns in tuple","ec697ffe":"data.columns\n","7cb551fd":"data.info()","87e273f1":"print(data.resolution.value_counts(dropna=True))","a378ba54":"data.describe()","d6408e88":"data.boxplot(column=\"iyear\",by=\"region\")\n# Black line at top is max\n# Blue line at top is 75%\n# green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n","82e000dd":"data_new=data.head()\ndata_new","6beb056e":"melted=pd.melt(frame=data_new,id_vars=\"country_txt\",value_vars=[\"city\",\"region_txt\"])\nmelted","612f9ce7":"melted.pivot(index=\"country_txt\",columns=\"variable\",values=\"value\")","05d8bbd2":"data1=data.head()\ndata2=data.tail()\ndata_con_row = pd.concat([data1,data2],axis=0,ignore_index =True) ## axis = 0 : adds dataframes in row\ndata_con_row","3a329c09":"data1=data['country_txt'].head()\ndata2=data[\"region\"].head()\ndata_con_col=pd.concat([data1,data2],axis=1)#axis =1 columns horizontiol\ndata_con_col","5bcfdc85":"data.dtypes","70fa1f5b":"data['iyear']=data['iyear'].astype(\"category\")\ndata[\"ndays\"]=data[\"ndays\"].astype(\"str\")","be57ba10":"data.dtypes\n# As you can see iyear is converted from integer to categorical\n# And Speed ,s converted from float to string ","5708e8ca":"data.info()","ad5489b1":"data[\"country_txt\"].value_counts(dropna=False)\n#we see 205 nan value","e4c5c68a":"# Lets drop nan values\ndata1=data\ndata1[\"country_txt\"].dropna(inplace=True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","a77b54c1":"#lets check assert with statement\nassert 1==1 #if return nothing it is true\n","d00a2ab5":"# In order to run all code, we need to make this line comment\n#assert 1==2 # return error because it is false","34118d9c":"assert data[\"country_txt\"].notnull().all() ## returns nothing because we drop nan values","2a41a77a":"data[\"country_txt\"].fillna(\"emtpy\",inplace=True)","a7259253":"assert data[\"country_txt\"].notnull().all() #return nothing  because we do not  have  nan vlaues","d752500a":"# # With assert statement we can check a lot of thing. \nassert data.columns[1]==\"country_txt\"\nassert data.ndays.dypes ==np.str","b60d12a1":"#data frame from dictionary\ncountry=[\"spain\",\"italy\"]\npopulation=[110,120]\nlist_label=[\"country\",\"population\"]\nlist_col=[country,population]\nzipped =list(zip(list_label,list_col))\ndata_dic=dict(zipped)\ndf=pd.DataFrame(data_dic)\ndf","c73d8033":"#add new colums\ndf[\"capital\"]=[\"madrid\",\"roma\"]\ndf","563601a8":"#broadcasting\ndf[\"income\"]=0\ndf","92d166e2":"data1 = data.loc[:,[\"attacktype1\",\"country\",\"iyear\"]]\ndata1.plot()\n# Plotting all data \n","e05e35cd":"data1.plot(subplots=True)\nplt.show()","36b18052":"data1.plot(kind=\"scatter\",x=\"country\",y=\"attacktype1\")\nplt.show()","e68a0482":"data1.plot(kind=\"hist\",y=\"country\",bins=50,range=(0,600),normed=True)\nplt.show()","688229cf":"data.describe()","70aeefa3":"time_list=[\"1999-02-12\",\"1999-03-06\"] \nprint(type(time_list[1])) # date = string\n## however we want it to be datetime object\ndatetime_object=pd.to_datetime(time_list)\nprint(type(datetime_object))","d9b4825c":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndata2 = data.head()\ndate_list =[\"1999-08-09\",\"1999-09-14\",\"1998-04-09\",\"1998-05-30\",\"1999-10-09\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\ndata2 =data2.set_index(\"date\") #set index date\ndata2","1da139a6":"print(data2.loc[\"1999-09-14\"])\nprint(data2.loc[\"1998-04-01\":\"1999-12-12\"])","8387d324":"data2.resample(\"M\").mean() #avareage month","4ba6a4c1":"data2.resample(\"A\").mean() #avareage year","eb6f6cf5":"# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","5242de41":" data2.resample(\"M\").mean().interpolate(\"linear\")","7ee67088":"data = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\n#data= data.set_index([\"#\"])\n#data.head()","14af646e":"data[\"iyear\"][1]","022bb322":"data.iyear[1]","7c404fe0":"#using loc accessor.loc[\ndata.loc[1,[\"iyear\"]]","dc2d3acc":"# Selecting only some columns\ndata[[\"iyear\",\"country_txt\"]]","8cf003f7":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"country_txt\"]))\nprint(type(data[[\"country_txt\"]]))","8279f2ac":"# Slicing and indexing series\ndata.loc[1:10,\"iyear\":\"country_txt\"]\ndata.loc[1:10,\"iyear\":\"region\"]","f9ecc14f":"#reverse slicing\ndata.loc[10:1:-1,\"iyear\":\"country_txt\"]","7563a056":"# From something to end\ndata.loc[1:10,\"country\":]\ndata.loc[1:10,\"city\":]","96d1aa9d":"#creating boolean  series\nboo=data.iyear>2000\ndata[boo]","35e6e6c1":"# Combining filters\nfirst_filter=data.iyear>2000\nsecond_filter=data.iyear<2005\ndata[first_filter&second_filter]","fd15422b":"# Filtering column based others\ndata.country_txt[data.iyear>=2016]","2dfaa5db":"#plain python funtion\ndef div(n) :\n  return n\/2\ndata.eventid.apply(div)","a3712c14":"# or we can use faster fuction lambda \ndata.eventid.apply(lambda n : n\/2)","1c202586":"data.describe()\n","2a67a22c":"## Defining column using other columns\ndata[\"total_targ\"]=data.targtype1+data.targsubtype1\ndata.head()","8481ce5a":"# our index name is this:\nprint(data.index.name)\n#lets change index name \ndata.index.name =\"index name\"\ndata.head(101)\ndata.tail()\n","eb6df7ef":"#if we want to modify index we need to change all of the\ndata.head()\n# first copy of our data to data3 then change index \ndata3 =data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\n#data3.index = range(100,106,1)\ndata3.head()","7e916d6d":"data = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv',encoding='ISO-8859-1')\ndata.head()","da213dd9":"data1 =data.set_index([\"iyear\",\"region\"])\ndata1.head()","bae48bc4":"dic = {\"treament\":[\"a\",\"a\",\"b\",\"b\"],\"gender\":[\"m\",\"f\",\"f\",\"m\"],\"response\":[12,32,45,16],\"age\":[16,25,30,45]}\ndf=pd.DataFrame(dic)\ndf","e8ab71b0":"#pivoting\ndf.pivot(index=\"treament\",columns=\"gender\",values=\"response\")","8dd32c45":"df1 =df.set_index([\"treament\",\"gender\"])\ndf1","959334eb":"# level determines indexes\ndf1.unstack(level=0)\n","c0ea10de":"df1.unstack(level=1)\n","4034a558":"# change inner and outer level index position\ndf2=df1.swaplevel(0,1)\ndf2","28373b5e":"#we using df dataframe\ndf","a10c43c6":"# according to treatment take means of other features\ndf.groupby(\"treament\").mean()\n#there are other methods like sum,std,max or min etc.\n","d09dc9aa":"#we can only chosee one of feature\ndf.groupby(\"treament\").age.min()\n#df.groupby(\"treament\").age.max() \n","da4d977e":"#if want to we can chose multiple features\ndf.groupby(\"treament\")[[\"age\",\"response\"]].min()","1b4a70e3":"df.info()\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\ndf[\"gender\"] = df[\"gender\"].astype(\"category\")\ndf[\"treament\"] = df[\"treament\"].astype(\"category\")\ndf.info()","c1b0489e":"<a id=\"19\"><\/a><br>\n### PIVOTING DATA FRAMES\n   * pivoting: reshape tool\n    \n\n","acac951d":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","9e71056b":"<a id=\"18\"><\/a> <br>\n### data types\n* There are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear","a96dc8bd":"<a id=\"25\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","57c82c45":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing","bf5c92a8":"<a id=\"15\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","fcd2bb99":"<a id=\"22\"><\/a> <br>\n### Missind data and testin with  assert\n<br>If we encounter with missing data, what we can do:\n*     leave as is\n*     drop them with dropna()\n*     fill missing value with fillna()\n*     fill missing values with test statistics like mean\n*     Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n","af7da303":"<a id =\"19\"><\/a><br>\n###  TRANSFORMING DATA\n*     Plain python functions\n*     Lambda function: to apply arbitrary python function to every element\n*     Defining column using other columns\n* \n","e03b9a84":"<a id=\"19\"><\/a><br>\n### INDEX OBJECTS AND LABELED DATA\n* index: sequence of label\n","9fd87744":"<a id=\"16\"><\/a><br>\n#  building data frames from scratch \n* we can build data frames from csv as we did earlier\n* also we can build dataframe from dictionaries\n* zip() method:this fuction returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterabels\n* adding new colums\n* broadcasting: creating new columns and assing a value to entire column\n","f4f0884f":"<a id=\"20\"><\/a> <br>\n# visual exploratory data analysis\n* plot\n* subplot\n* histgram\n* bins:number of bars\n* ange(tuble):min and max values of bins\n* normed(boolean):normalize or not\n* cumulative(boolean)   :compute comulative distribution\n   ","a8627dbd":"<a id=\"30\"><\/a> <br>\n<a id=\"30\"><\/a> <br>\n### indexing pandas time series\n* datatime =object\n* parse_dates(boolean):Transform date to ISO 8601(yyyy-mm-dd hh:mm:ss) format\n","4ee9a413":"<a id=\"16\"><\/a><br>\n#  Cleaning  data\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>unclean data\n* differennt language\n*missing  data\n*upper- lower caser or space between word\n","685a5e8d":"<a id=\"16 \"><\/a><br>\n  ### RESAMPLING PANDAS TIME SERIES\n       \n*     Resampling: statistical method over different time intervals\n*      Needs string to specify frequency like \"M\" = month or \"A\" = year\n*     Downsampling: reduce date time rows to slower frequency like from daily to weekly\n*     Upsampling: increase date time rows to faster frequency like from daily to hourly\n*     Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 ","a334e2c6":"<a id=\"20\"><\/a><br>\n### FILTERING DATA FRAMES\nCreating boolean series Combining filters Filtering column based others\n","cc484d09":"<a id=\"20\"><\/a><br>\n### STACKING and UNSTACKING DATAFRAME\n*     deal with multi label indexes\n*     level: position of unstacked index\n*     swaplevel: change inner and outer level index position\n\n","fac20f6f":"<a id=\"20\"><\/a><br>\n### MELTING DATA FRAMES\n* Reverse of pivoting\n\n","79bc34e3":"<a id=\"19\"><\/a><br>\n### SLICING DATA FRAME\n*     Difference between selecting columns\n  *         Series and data frames\n*     Slicing and indexing series\n*     Reverse slicing\n*     From something to end\n\n","3be61484":"<a id =\"22\"><\/a> <br>\n### Concatenating data\n* We can concatenate two dataframe ","042be81d":"<a id=\"15\"><\/a> <br>\n### pivoting data\n* reverse melt","05efcea5":"<a id= \"17\" ><\/a> <br>\n### MANIPULATING DATA FRAMES WITH PANDAS\n<br>INDEXING DATA FRAMES\n*     Indexing using square brackets\n*     Using column attribute and row label\n*     Using loc accessor\n*     Selecting only some columns\n","8bba1ca8":"<a id =\"16\"><\/a><br>\n# pandas foundation\n### brief  of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy","dfa403d7":"<a id=\"15\"><\/a> <br>\n### Tidy data\n* We tidy data with melt().\n* Describing melt is confusing."}}