{"cell_type":{"238a0d5d":"code","3eb20154":"code","89c79944":"code","d371c4c6":"code","e1ca600c":"code","28f38f40":"code","cf9db78a":"code","ff7fdc65":"code","69a85593":"code","8f646dca":"code","8dc602c9":"code","f2b7ac48":"code","66065d01":"code","09adc35f":"code","d3438618":"code","61c93211":"code","3f37e65c":"code","6971bc29":"code","1140113f":"code","c3e1fc1e":"code","ee128a3b":"code","ab301249":"code","5c45e64e":"code","86a486f1":"code","e7c4bfc5":"code","8ef5d4f2":"code","d8403411":"code","e1c594ef":"code","8b21cd77":"code","f3b1aa07":"code","fe49a60f":"code","a1e1f079":"markdown","8c5610df":"markdown","08b011d1":"markdown","38e664c7":"markdown","1db0cb2e":"markdown"},"source":{"238a0d5d":"#we used cnn architecture with sigmoid and binary-crossentropy, and 10 epochs and 256 * 256 \nfrom multiprocessing.pool import ThreadPool\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense,Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n%matplotlib inline\nimport os\nimport random\nimport glob\nimport itertools\nfrom keras.utils import to_categorical\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras import regularizers","3eb20154":"import pandas as pd\nrandom.seed(10)\ntrainLabels = pd.read_csv(\"..\/input\/diabetic-retinopathy-detection\/trainLabels.csv.zip\")\ntrainLabels.head()\n","89c79944":"from PIL import Image\nfrom keras.preprocessing import image\nimport os\nimport numpy as np\nimport zipfile \n# resize the image to 300x300\nimg_rows, img_cols = 350,350\n\nlisting = os.listdir(\"..\/input\/diabetic-retinopathy-detection\") \nlisting.remove(\"trainLabels.csv.zip\")\nlisting.remove(\"sampleSubmission.csv.zip\")\n\n\nimmatrix = []\nimlabel = []\n\n    \nfor file in listing:\n    print(file)\n    zf = zipfile.ZipFile(\"..\/input\/diabetic-retinopathy-detection\/\" + file)\n    print(zf.filename)\n    #zf.extractall()\n    imageslist = zf.namelist()\n    \n    \n    for imagefile in imageslist: \n        fileName = os.path.splitext(imagefile)[0]\n        print(fileName)\n        print(trainLabels.loc[image==fileName][level])\n        imlabel.append(str(trainLabels.loc[image==fileName][level]))\n        im = Image.open(imagefile)\n        img = np.array(im.resize((img_rows,img_cols)))\n        immatrix.append(np.array(img))","d371c4c6":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]\n\nimport matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","e1ca600c":"#split the dataset into 60% training , 20% test, 20% validation dataset \nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size = 0.1, random_state = 42)\n\n\nprint(np.array(x_train).shape)\nprint(np.array(y_train).shape)","28f38f40":"from keras.utils import np_utils\n\ny_train = np_utils.to_categorical(np.array(y_train), 5)\ny_test = np_utils.to_categorical(np.array(y_test), 5)\n\n\nx_train = np.array(x_train).astype(\"float32\")\/255.\nx_test = np.array(x_test).astype(\"float32\")\/255.\n\n\nprint(np.array(y_train).shape)","cf9db78a":"#specify the green channel of the images..\nim = Image.fromarray(immatrix[1],'RGB')\nprint(\"level:\",imlabel[1])\nim","ff7fdc65":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]","69a85593":"import matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","8f646dca":"from keras.applications import InceptionResNetV2\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras.applications import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import MobileNet\nfrom keras.applications import InceptionResNetV2\n\ndef create_model(input_shape, n_out):\n    pretrain_model = InceptionResNetV2(\n        include_top=False, \n        weights='imagenet', \n        input_shape=input_shape)    \n    input_tensor = Input(shape=input_shape)\n    bn = BatchNormalization()(input_tensor)\n    x = pretrain_model(bn)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_out, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    \n    return model\n#x = GlobalAveragePooling2D()(backbone.output)\n#outputs = Dense(5, activation=\"softmax\")(x)\n","8dc602c9":"keras.backend.clear_session()\n\nmodel = create_model(\n    input_shape=x_train[0].shape, \n    n_out=5)\n\nmodel.summary()","f2b7ac48":"model.save_weights('inceptionResNetv2_model_wieghts.h5')\nmodel.save('inceptionResNetv2_model_keras.h5')\nmodel_json=model.to_json()\nwith open(\"model.json\", \"w\")as json_file:\n    json_file.write(model_json)\n\n","66065d01":"def f1(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('f1')\n    ax[1].plot(history.epoch, history.history[\"f1\"], label=\"Train f1\")\n    ax[1].plot(history.epoch, history.history[\"val_f1\"], label=\"Validation f1\")\n    ax[2].set_title('acc')\n    ax[2].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[2].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()\n\n\n","09adc35f":"#from keras.optimizers import SGD\n#from tensorflow.keras.optimizers import RMSprop\nimport torchvision\nfrom numpy import *\nhistory_InceptionResNetV2 =  model.compile(optimizer=Adam(1e-3)\n\n                    , loss='binary_crossentropy'\n                    , metrics=['acc',f1])","d3438618":"def brightness_adjustment(img):\n    # turn the image into the HSV space\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    # creates a random bright\n    ratio = .5 + np.random.uniform()\n    # convert to int32, so you don't get uint8 overflow\n    # multiply the HSV Value channel by the ratio\n    # clips the result between 0 and 255\n    # convert again to uint8\n    hsv[:,:,2] =  np.clip(hsv[:,:,2].astype(np.int32) * ratio, 0, 255).astype(np.uint8)\n    # return the image int the BGR color space\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV)","61c93211":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_train = numpy.array(x_train, copy=True) \nY_train = numpy.array(y_train, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. \/255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_train)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntrain_x  = numpy.concatenate((x_train, X_train), axis=0)\ntrain_y  = numpy.concatenate((y_train, Y_train), axis=0)\nprint(train_x.shape)\nprint(train_y.shape)","3f37e65c":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nbest_save_model_file = '..\/working\/inception_model.h5'\ncallbacks = [EarlyStopping(monitor='val_loss',\n                           patience=20,\n                           verbose=1,\n                           min_delta=0.00001,\n                           mode='min'),\n             ReduceLROnPlateau(monitor='val_loss',\n                               factor=0.1,\n                               patience=2,\n                               verbose=1,\n                               min_delta=0.0001,\n                               mode='min'),\n             ModelCheckpoint(monitor='val_loss',save_weights_only=True,\n                             filepath=best_save_model_file,\n                             save_best_only=True,\n                             mode='min') ,\n             ]","6971bc29":"history_InceptionResNetV2 =model.fit(train_x, train_y, batch_size = 32, epochs=100,validation_split=0.1, verbose=1,\n                               shuffle=True)\n","1140113f":"#history_inceptionv3= model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=0.0001), metrics=['acc', f1])","c3e1fc1e":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_test = numpy.array(x_test, copy=True) \nY_test = numpy.array(y_test, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. \/255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_test)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntest_x  = numpy.concatenate((x_test, X_test), axis=0)\ntest_y  = numpy.concatenate((y_test, Y_test), axis=0)","ee128a3b":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","ab301249":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]\/\/16)","5c45e64e":"show_history(history_InceptionResNetV2)","86a486f1":"t=154\ntest=test_x[t].reshape(-1,350,350,3)\narr=model.predict(test)\narr=arr.flatten()\n\nmaxm=arr[0]\nfor i in range(0,5):\n    if(arr[i]>=maxm):\n        predicted_label=i+1\n        maxm=arr[i]\nfor i in range(0,5):\n    if(int(test_y[t][i])==1):\n        actual_label=i+1\n        break\nname={1:\"NO level of Diabetic Retinopathy\",2:\"MILD level of Diabetic Retinopathy\",3:\"MODERATE level of Diabetic Retinopathy\",4:\"SEVERE level of Diabetic Retinopathy\",5:\"PROLIFERATIVE level of Diabetic Retinopathy\"\n}\n\nimport matplotlib.pyplot as plt\nplt.imshow(x_test[t])\nplt.show\n\nprint(\"Predicted  : The patient is having \" + name[predicted_label])\nprint(\"Expected   : The patient should have \"+name[actual_label])","e7c4bfc5":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","8ef5d4f2":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]\/\/16)","d8403411":"score = model.evaluate(test_x,test_y, verbose=0)\nprint(score)","e1c594ef":"from sklearn.metrics import roc_curve, roc_auc_score\nsick_vec = test_Y_cat>0\nsick_score = np.sum(pred_Y[:,1:],1)\nfpr, tpr, _ = roc_curve(sick_vec, sick_score)\nfig, ax1 = plt.subplots(1,1, figsize = (6, 6), dpi = 150)\nax1.plot(fpr, tpr, 'b.-', label = 'Model Prediction (AUC: %2.2f)' % roc_auc_score(sick_vec, sick_score))\nax1.plot(fpr, fpr, 'g-', label = 'Random Guessing')\nax1.legend()\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\n","8b21cd77":"score = model.evaluate(test_x, test_y , verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","f3b1aa07":"show_history(history_inceptionvResNetV2)","fe49a60f":"results = pd.DataFrame({'ImageId': pd.Series(range(1, len(test_Y_cat) + 1)), 'Label': pd.Series(pred_Y_cat)})\nresults.to_csv('results.csv', index=False)\nresults.head(200)","a1e1f079":"\n#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n\n\nprint(FP \/ float(TN + FP))","8c5610df":"#Sensitivity: When the actual value is positive, how often is the prediction correct?\n\n###How \"sensitive\" is the classifier to detecting positive instances?\n#Also known as \"True Positive Rate\" or \"Recall\"\n\nprint(TP \/ float(TP + FN))\nprint(metrics.recall_score(test_Y_cat, pred_Y_cat))","08b011d1":"from sklearn import metrics\nprint(metrics.accuracy_score(test_Y_cat, pred_Y_cat))\nconfusion = metrics.confusion_matrix(test_Y_cat, pred_Y_cat)\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]","38e664c7":"\n#Also known as \"Misclassification Rate\"\n\nprint((FP + FN) \/ float(TP + TN + FP + FN))\nprint(1 - metrics.accuracy_score(test_Y_cat, pred_Y_cat))","1db0cb2e":"#Specificity: When the actual value is negative, how often is the prediction correct?\n\n#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n\nprint(TN \/ float(TN + FP))\n"}}