{"cell_type":{"37c3dd2a":"code","aa16ed3b":"code","b9c21b59":"code","ccd6a200":"code","efa45b47":"code","ac090806":"code","b467cc44":"code","4fd93a1a":"code","493b6689":"code","f900daee":"code","2ed1b9a4":"code","dbb00ac8":"code","e1468ab8":"code","68252bc9":"code","46b94c85":"code","b7a14744":"code","fa959abd":"code","f91a6bd9":"code","3cd1face":"code","c7051d13":"code","8b7a9c55":"code","0a23ea17":"markdown","5c655fce":"markdown"},"source":{"37c3dd2a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nfrom keras.layers import Input, Dense\nfrom keras.models import Model, Sequential\nfrom keras import regularizers\nfrom keras.layers import BatchNormalization\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn import preprocessing \nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport numpy as np\nimport re as re\n\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nfull_data = [train, test]\n\n# Any results you write to the current directory are saved as output.","aa16ed3b":"train.head()","b9c21b59":"print (train.info())","ccd6a200":"# length of name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n\n# Has Cabin \ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)","efa45b47":"print (train[['Pclass','Survived']].groupby(['Pclass'], as_index=False).mean())","ac090806":"print (train[['Sex','Survived']].groupby(['Sex'], as_index=False).mean())","b467cc44":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","4fd93a1a":"for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())","493b6689":"for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","f900daee":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())","2ed1b9a4":"for dataset in full_data:\n    age_avg \t   = dataset['Age'].mean()\n    age_std \t   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","dbb00ac8":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nprint(pd.crosstab(train['Title'], train['Sex']))","e1468ab8":"for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping FamilySize\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n    \n    \n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\nX = train.drop([\"Survived\"], axis=1)\ny = train[\"Survived\"].values","68252bc9":"model = Sequential()\n\n## encoding part\nmodel.add(Dense(100, input_shape=(X.shape[1],), activation='tanh', activity_regularizer=regularizers.l1(10e-5)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(50, activation='relu'))\n\n\n## decoding part\nmodel.add(Dense(50, activation='tanh'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(100, activation='relu'))\n\n\nmodel.add(Dense(X.shape[1], activation='relu'))\n\nmodel.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])","46b94c85":"model.summary()","b7a14744":"# Before training, let's perform min max scaling.\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(X.values)\nX_scale = scaler.transform(X.values)\ntest_x_scale = scaler.transform(test.values)\n\nx_perished, x_survived = X_scale[y == 0], X_scale[y == 1]\nhistory = model.fit(x_perished, x_perished, epochs = 20, shuffle = True, validation_split = 0.2)","fa959abd":"train_result = pd.DataFrame(history.history)\n\nstyle = {'loss': 'go--', 'val_loss': 'bo--'}\ntrain_result[['loss', 'val_loss']].plot(style=style)","f91a6bd9":"hidden_representation = Sequential()\nhidden_representation.add(model.layers[0])\nhidden_representation.add(model.layers[1])\nhidden_representation.add(model.layers[2])","3cd1face":"perished_hid_rep = hidden_representation.predict(x_perished)\nsurvived_hid_rep = hidden_representation.predict(x_survived)\n\nrep_x = np.append(perished_hid_rep, survived_hid_rep, axis = 0)\ny_n = np.zeros(perished_hid_rep.shape[0])\ny_f = np.ones(survived_hid_rep.shape[0])\nrep_y = np.append(y_n, y_f)","c7051d13":"train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.2)\nclf = LogisticRegression().fit(train_x, train_y)\npred_y = clf.predict(val_x)\n\nprint (classification_report(val_y, pred_y))\nprint (accuracy_score(val_y, pred_y))","8b7a9c55":"temp = pd.DataFrame(pd.read_csv(\"..\/input\/test.csv\")['PassengerId'])\ntest_rep_x = hidden_representation.predict(test_x_scale)\ntemp['Survived'] = [int(x) for x in clf.predict(test_rep_x)]\ntemp.to_csv(\"submission.csv\", index = False)\ntemp.head()","0a23ea17":"References\n- https:\/\/www.kaggle.com\/shivamb\/semi-supervised-classification-using-autoencoders\n- https:\/\/www.kaggle.com\/sinakhorami\/titanic-best-working-classifier\n","5c655fce":"create model using autoencoder"}}