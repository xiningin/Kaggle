{"cell_type":{"6e8d1a05":"code","81e00f18":"code","b1549d53":"code","b3eca572":"code","4e016868":"code","8806adad":"code","53a18f13":"code","2058da14":"code","b87f09f1":"code","42fcf3fe":"code","f547b57f":"code","dea72c70":"code","3fbb7ca0":"code","30044c98":"code","4b3d6c79":"code","48d82be0":"code","34eaece3":"code","3d570183":"code","1ea959b7":"code","83d8b97e":"code","d7bd1a77":"code","fbdea175":"code","40d48f3b":"markdown","ef87d335":"markdown","275dff0f":"markdown","1b12ffed":"markdown","21fb79fe":"markdown","9634747d":"markdown","63657a15":"markdown"},"source":{"6e8d1a05":"import numpy as np \nimport pandas as pd\nimport matplotlib.pylab as plt\nimport os\nfrom os import listdir\nfrom os.path import isfile, join","81e00f18":"# Resized images directory\ndir_2019_images = \"\/kaggle\/input\/resizedsiimisic\/train_resized\/\"\nimages_2019 = [f for f in listdir(dir_2019_images) if isfile(join(dir_2019_images, f))]\n\n# CSV file\ntrain_df = pd.read_csv('\/kaggle\/input\/resizedsiimisic\/train.csv')","b1549d53":"train_df.head()","b3eca572":"print(\"Train shape:\", train_df.shape)","4e016868":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\n\nX = train_df\ny = train_df['target']","8806adad":"# Split into train, validation and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2, \n                                                    stratify=y,\n                                                    random_state=42)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size=0.2,\n                                                  stratify=y_train,\n                                                  random_state=42)\n\nprint(\"Conjunto de train:\", X_train.shape)\nprint(\"Conjunto de validacion:\", X_val.shape)\nprint(\"Conjunto de prueba:\", X_test.shape)\nprint(\"-----------------------\")\nprint('Distribucion de train ->', Counter(y_train))\nprint('Distribucion de validacion ->', Counter(y_val))\nprint(\"Distribucion de prueba ->\", Counter(y_test))","53a18f13":"X_train[\"target\"] = X_train['target'].astype(str)\nX_val[\"target\"] = X_val['target'].astype(str)\nX_test[\"target\"] = X_test['target'].astype(str)","2058da14":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet121 # input size 224x224\nfrom tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, AUC\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Model","b87f09f1":"datagen = ImageDataGenerator(rescale=1.\/255.)\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=X_train,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=X_val,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=X_test,\n    directory=dir_2019_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"binary\"\n)\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size","42fcf3fe":"encoder = DenseNet121(input_shape=(None,None,3), \n                      include_top=False, \n                      weights='imagenet')","f547b57f":"# for layer in encoder.layers:\n#    layer.trainable = False\n\ninputs = Input(shape=(None, None, 3))\nx = encoder(inputs, training=False)\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(1, activation='sigmoid')(x)\nmodel = Model(inputs=inputs, outputs=predictions)","dea72c70":"model.summary()","3fbb7ca0":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'),\n      AUC(name='auc')\n]","30044c98":"checkpoint_filepath = '\/kaggle\/working\/base_model.h5'\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n                                            monitor='val_auc',\n                                            mode='max',\n                                            verbose=1,\n                                            save_best_only=True)","4b3d6c79":"model.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=METRICS\n)","48d82be0":"history = model.fit(train_generator,  \n                    validation_data =valid_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN, \n                    validation_steps=STEP_SIZE_VALID,\n                    callbacks=[model_checkpoint_callback],\n                    epochs = 100)","34eaece3":"plt.plot(history.history['auc'], \n         label='Training AUC (area = {:.3f})'.format(history.history['auc'][-1]))\nplt.plot(history.history['val_auc'], \n         label='Validation AUC ( area = {:.3f})'.format(history.history['val_auc'][-1]))\nplt.title('Base model')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","3d570183":"plt.plot(history.history['loss'], label='Training loss (loss = {:.3f})'.format(history.history['loss'][-1]))\nplt.plot(history.history['val_loss'], label='Validation loss (loss = {:.3f})'.format(history.history['val_loss'][-1]))\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","1ea959b7":"eval_metrics = model.evaluate(test_generator, \n                              steps=STEP_SIZE_TEST,\n                              return_dict=True,\n                              use_multiprocessing=False,\n                              verbose=1)","83d8b97e":"true_labels = test_generator.classes\npredict = model.predict(test_generator,\n                        verbose=1)","d7bd1a77":"from sklearn import metrics\n\nfpr, tpr, tr = metrics.roc_curve(true_labels, predict)\nauc = metrics.roc_auc_score(true_labels, predict)\nplt.plot(fpr,tpr,'b',label=\"AUC=\"+str(auc))\nplt.plot([0,1],[0,1],'k--')\nplt.title('Test evaluation')\nplt.grid()\nplt.legend(loc='best')\nplt.show()","fbdea175":"import seaborn as sns\n\ncm = [eval_metrics['tn'], eval_metrics['fp'], eval_metrics['fn'], eval_metrics['tp']]\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm\/np.sum(cm)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap([[cm[0], cm[1]], [cm[2], cm[3]]], annot=labels, fmt='', cmap='Blues')","40d48f3b":"## <font color=red>2. <\/font>Dividir conjunto de datos","ef87d335":"# Modelo base","275dff0f":"## <font color=red>3. <\/font>Crear y entrenar el modelo","1b12ffed":"## <font color=red>1. <\/font>Cargar las im\u00e1genes y los datos tabulares","21fb79fe":"## <font color=red>4. <\/font>Evaluar el modelo","9634747d":"#### Finalmente, se observa la curva ROC-AUC y la matriz de confusi\u00f3n.","63657a15":"#### Se obtiene las predicciones y las etiquetas del conjunto de prueba."}}