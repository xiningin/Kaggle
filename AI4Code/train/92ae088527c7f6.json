{"cell_type":{"97ea6314":"code","282d9aec":"code","bcbe9652":"code","4ac0013e":"code","47a93999":"code","c3642842":"code","f9b46e7a":"code","0b2735e8":"code","7eaacd33":"code","0686a7ff":"code","f44b7fbb":"code","77dddfe1":"code","58d14f16":"code","da4aebd4":"code","b94a13fa":"code","9b564358":"code","63c4b0df":"code","792492ab":"code","3af8c976":"code","bdc7dc57":"code","e78a03bd":"code","d943b20f":"code","df84c75a":"code","09590785":"code","4e6a0324":"code","2f204c7a":"code","1d46f07c":"code","9081cb87":"code","a4bb3115":"code","450f54ac":"code","d98ff7ef":"code","f322d8d3":"code","6b581cf1":"code","ea6d771b":"code","72dfad79":"code","72262980":"code","3925e130":"code","4a5ab3f7":"code","02b23c68":"code","155c55ab":"code","c517871e":"code","05319606":"code","420cb078":"code","46e37c5f":"code","3f242c87":"code","21159980":"code","f1c6eade":"code","9bb4d7ef":"code","e72a94bd":"code","f92c182d":"code","bbcc129e":"code","1dfb881a":"code","de98d2d9":"code","5e903d2b":"code","c158f8b4":"code","5f9277cf":"code","4490ddc3":"code","38985261":"code","911ad2cd":"code","3b8bc77f":"code","c95c929f":"code","b06a9361":"code","7146205f":"code","4d8f3a12":"markdown","bfee078b":"markdown","d4542f8f":"markdown","53eb9423":"markdown","066438a9":"markdown","d65e0438":"markdown","1b051985":"markdown","6cf328b1":"markdown","1658e1a2":"markdown","92f91ae9":"markdown","d5402d05":"markdown","4c4be649":"markdown","ef40b3bd":"markdown","3ce0a098":"markdown","a64d8295":"markdown","67ce8e8c":"markdown","51644ac1":"markdown","d1b70f1b":"markdown","1a9f0894":"markdown","79ed8a6d":"markdown","57aa6d6c":"markdown","2d2c0627":"markdown","b7b5d94a":"markdown","279a38dd":"markdown","e66b7707":"markdown","a72d8590":"markdown","eac9fcec":"markdown","8640355b":"markdown","49966e94":"markdown","f6e7f7bc":"markdown","f1c3e137":"markdown","7c24c932":"markdown","2d18ec98":"markdown","08bdf49a":"markdown","3a71945f":"markdown"},"source":{"97ea6314":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","282d9aec":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as mode\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nimport xgboost as xgb\n\n# Setting a figure size of all the graphs at first\nplt.rcParams['figure.figsize'] = 12,8\nplt.style.use('ggplot')\n\n# Disabling warnings\nimport warnings\nwarnings.filterwarnings('ignore')","bcbe9652":"df_train = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Test.csv')","4ac0013e":"print('Train set shape : ', df_train.shape)\nprint('Test set shape : ', df_test.shape)","47a93999":"df_train.head(4)","c3642842":"df_train.describe()","f9b46e7a":"df_train.info()","0b2735e8":"t = df_train.groupby(['Outlet_Location_Type'])['Item_Outlet_Sales', 'Item_MRP'].mean()\nt.style.background_gradient(cmap = 'BuPu')","7eaacd33":"ob = df_train.groupby('Outlet_Location_Type')\n\nfor name,group in ob:\n    print(name, 'contains', group.shape[0], 'rows')","0686a7ff":"ob.get_group('Tier 2').head(10)","f44b7fbb":"sns.distplot(df_train.Item_Outlet_Sales, bins=50, color = 'red')\nplt.xlabel('Item Outlet Sales')\nplt.ylabel('No. of scales')\nplt.title('Item Outlet Sales distribution')","77dddfe1":"num_feature = df_train.select_dtypes(include=[np.number])\nnum_feature.dtypes","58d14f16":"num_feature.corr()","da4aebd4":"plt.style.use('bmh')\nprint(num_feature.corr()['Item_Outlet_Sales'].sort_values(ascending=False))\nsns.heatmap(num_feature.corr(), annot=True, cmap = 'magma');","b94a13fa":"plt.plot(df_train['Item_MRP'], df_train['Item_Outlet_Sales'], '_', color = '#E2A50F')\nplt.xlabel('Item MRP')\nplt.ylabel('Sales')\nplt.title('Impact of MRP of an Item on Sales');","9b564358":"# Checking all categorical variables\ncat_features = df_train.select_dtypes(include=[np.object])\ncat_features.dtypes","63c4b0df":"print(df_train.Item_Identifier.value_counts().head(10))\nprint()\nprint('No. of Unique itmes : ', df_train.Item_Identifier.nunique())","792492ab":"df_train.Item_Fat_Content.value_counts()","3af8c976":"df_train['Item_Fat_Content'] = df_train['Item_Fat_Content'].replace('LF','Low Fat')\ndf_train['Item_Fat_Content'] = df_train['Item_Fat_Content'].replace('low fat', 'Low Fat')\ndf_train['Item_Fat_Content'] = df_train['Item_Fat_Content'].replace('reg', 'Regular')","bdc7dc57":"plt.style.use('bmh')\ncolor = '#7FD59E', '#D57FB3'\nplt.pie(df_train.Item_Fat_Content.value_counts(), data = df_train, labels = ('Low Fat', 'Regular Fat'), \n        colors = color, autopct='%1.1f%%', startangle = 70, shadow = True, explode = (0.08, 0), textprops={'fontsize': 16})\nplt.title('Fat Content in items');","e78a03bd":"# Lets see if fat content has any impact on the sales\nFat_cont_pivot = df_train.pivot_table(index = 'Item_Fat_Content', values = 'Item_Outlet_Sales', aggfunc = np.mean)\nprint(Fat_cont_pivot)\n\nFat_cont_pivot.plot(kind = 'bar', color = '#91992C')\nplt.xlabel('Item_Fat_Content')\nplt.xticks(rotation = 0)\nplt.ylabel('Item_Outlet_sales')\nplt.title('Impact of Fat content on Sales');","d943b20f":"print(df_train['Item_Type'].value_counts())\nsns.countplot(y=df_train['Item_Type'], palette = 'tab20b');","df84c75a":"Item_type_pivot = df_train.pivot_table(index = 'Item_Type', values = 'Item_Outlet_Sales', aggfunc = np.mean)\nprint(Item_type_pivot)\n\nItem_type_pivot.plot(kind = 'bar', color = '#91992C')\nplt.xlabel('Item Type')\nplt.xticks(rotation = 90)\nplt.ylabel('Item_Outlet_sales')\nplt.title('Impact of Item types on Sales');","09590785":"print(df_train['Outlet_Size'].value_counts())\nsns.countplot(x=df_train['Outlet_Size'], palette = 'cubehelix');","4e6a0324":"out_size_pivot = df_train.pivot_table(index = 'Outlet_Size', values = 'Item_Outlet_Sales', aggfunc = np.mean)\nprint(out_size_pivot)\n\nout_size_pivot.plot(kind = 'bar', color = '#91992C')\nplt.xlabel('Outlet Size')\nplt.xticks(rotation = 0)\nplt.ylabel('Item_Outlet_sales')\nplt.title('Impact of Outlet Size on Sales');","2f204c7a":"print(df_train['Outlet_Location_Type'].value_counts())\nsns.countplot(x=df_train['Outlet_Location_Type'], palette = 'viridis');","1d46f07c":"out_loc_pivot = df_train.pivot_table(index = 'Outlet_Location_Type', values = 'Item_Outlet_Sales', aggfunc = np.mean)\nprint(out_loc_pivot)\n\nout_loc_pivot.plot(kind = 'bar', color = '#91992C')\nplt.xlabel('Outlet Location Type')\nplt.xticks(rotation = 0)\nplt.ylabel('Item_Outlet_sales')\nplt.title('Impact of Location Type on Sales');","9081cb87":"print(df_train['Outlet_Type'].value_counts())\nsns.countplot(x=df_train['Outlet_Type'], palette = 'rocket_r');","a4bb3115":"out_type_pivot = df_train.pivot_table(index = 'Outlet_Type', values = 'Item_Outlet_Sales', aggfunc = np.mean)\nprint(out_type_pivot)\n\nout_type_pivot.plot(kind = 'bar', color = '#91992C')\nplt.xlabel('Outlet Type')\nplt.xticks(rotation = 0)\nplt.ylabel('Item_Outlet_sales')\nplt.title('Impact of Outlet Type on Sales');","450f54ac":"df_train.isnull().sum()","d98ff7ef":"df_test.isnull().sum()","f322d8d3":"# We can simply impute the missing values of Item weight by its mean.\ndf_train['Item_Weight'].fillna(df_train['Item_Weight'].mean(), inplace=True)\ndf_test['Item_Weight'].fillna(df_test['Item_Weight'].mean(), inplace=True)","6b581cf1":"# Determing the mode for each -Train Data\nout_size_mode_train = df_train.pivot_table(values = 'Outlet_Size', columns = 'Outlet_Type', aggfunc = lambda x: x.mode())","ea6d771b":"# Determing the mode for each -Test Data\nout_size_mode_test = df_test.pivot_table(values = 'Outlet_Size', columns = 'Outlet_Type', aggfunc = lambda x: x.mode())","72dfad79":"def nan_out_size_train(cols):\n    size = cols[0]\n    Type = cols[1]\n    if pd.isnull(size):\n        return out_size_mode_train.loc['Outlet_Size'] [out_size_mode_train.columns == Type][0]\n    else:\n        return size\n    \ndf_train['Outlet_Size'] = df_train[['Outlet_Size', 'Outlet_Type']].apply(nan_out_size_train, axis = 1)","72262980":"def nan_out_size_test(cols):\n    size = cols[0]\n    Type = cols[1]\n    if pd.isnull(size):\n        return out_size_mode_test.loc['Outlet_Size'] [out_size_mode_test.columns == Type][0]\n    else:\n        return size\n    \ndf_test['Outlet_Size'] = df_test[['Outlet_Size', 'Outlet_Type']].apply(nan_out_size_test, axis = 1)","3925e130":"agg_visible = df_train.pivot_table(values='Item_Visibility', index='Item_Identifier')\nagg_visible","4a5ab3f7":"def visible_mean(cols):\n    visible = cols[0]\n    items = cols[1]\n    if visible == 0:\n        return agg_visible['Item_Visibility'][agg_visible.index ==items]\n    else:\n        return visible\n    \ndf_train[['Item_Visibility', 'Item_Identifier']].apply(visible_mean, axis = 1).astype(float)","02b23c68":"# For Training data\nfunct_tr = lambda x: x['Item_Visibility']\/agg_visible['Item_Visibility'][agg_visible.index == x['Item_Identifier']][0]\ndf_train['Item_Vis_Mean'] = df_train.apply(funct_tr,axis=1).astype(float)\ndf_train['Item_Vis_Mean'].describe()","155c55ab":"# For Test Data\nfunct_ts = lambda x: x['Item_Visibility']\/agg_visible['Item_Visibility'][agg_visible.index == x['Item_Identifier']][0]\ndf_test['Item_Vis_Mean'] = df_test.apply(funct_ts,axis=1).astype(float)\ndf_test['Item_Vis_Mean'].describe()","c517871e":"# Let's Consider the outlet establishment years\nprint(df_train['Outlet_Establishment_Year'].unique())\nprint()\nprint(df_test['Outlet_Establishment_Year'].unique())","05319606":"# The data we have is from year 2013, so we would consider 2013 for calculating that how old is the outlet\ndf_train['Outlet_years'] = 2013 - df_train['Outlet_Establishment_Year']\ndf_test['Outlet_years'] = 2013 - df_test['Outlet_Establishment_Year']","420cb078":"df_train['Outlet_years'].describe()","46e37c5f":"df_test['Outlet_years'].describe()","3f242c87":"# For Train data\ndf_train['Combined_Item_Type'] = df_train['Item_Identifier'].apply(lambda x: x[0:2])\n\ndf_train['Combined_Item_Type'] = df_train['Combined_Item_Type'].map({'FD':'Food',\n                                                             'NC':'Non-Consumable',\n                                                             'DR':'Drinks'})\ndf_train['Combined_Item_Type'].value_counts()","21159980":"# For Test data\ndf_test['Combined_Item_Type'] = df_test['Item_Identifier'].apply(lambda x: x[0:2])\n\ndf_test['Combined_Item_Type'] = df_test['Combined_Item_Type'].map({'FD':'Food',\n                                                             'NC':'Non-Consumable',\n                                                             'DR':'Drinks'})\ndf_test['Combined_Item_Type'].value_counts()","f1c6eade":"df_train['Item_Fat_Content'] = df_train['Item_Fat_Content'].replace({'LF':'Low Fat', 'reg':'Regular', 'low fat':'Low Fat'})","9bb4d7ef":"df_train.loc[df_train['Combined_Item_Type'] == 'Non-Consumable', 'Item_Fat_Content'] = 'In-edible'\ndf_train['Item_Fat_Content'].value_counts()","e72a94bd":"df_test['Item_Fat_Content'] = df_test['Item_Fat_Content'].replace({'LF':'Low Fat', 'reg':'Regular', 'low fat':'Low Fat'})","f92c182d":"df_test.loc[df_test['Combined_Item_Type'] == 'Non-Consumable', 'Item_Fat_Content'] = 'In-edible'\ndf_test['Item_Fat_Content'].value_counts()","bbcc129e":"label_encode = LabelEncoder()\n#New variable for outlet\ndf_train['Outlet'] = label_encode.fit_transform(df_train['Outlet_Identifier'])\nvar_mod_train = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Combined_Item_Type','Outlet_Type','Outlet']\nfor i in var_mod_train:\n    df_train[i] = label_encode.fit_transform(df_train[i])","1dfb881a":"label_encode = LabelEncoder()\n#New variable for outlet\ndf_test['Outlet'] = label_encode.fit_transform(df_test['Outlet_Identifier'])\nvar_mod_test = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Combined_Item_Type','Outlet_Type','Outlet']\nfor i in var_mod_test:\n    df_test[i] = label_encode.fit_transform(df_test[i])","de98d2d9":"#Dummy Variables:\ndf_train = pd.get_dummies(df_train, columns =['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type',\n                                  'Combined_Item_Type','Outlet'])\n\n\ndf_test = pd.get_dummies(df_test, columns =['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type',\n                                  'Combined_Item_Type','Outlet'])\n","5e903d2b":"df_train.drop(df_train[['Item_Type', 'Item_Identifier', 'Outlet_Identifier']], axis=1, inplace=True)\ndf_test.drop(df_test[['Item_Type', 'Item_Identifier', 'Outlet_Identifier']], axis=1, inplace=True)","c158f8b4":"print(df_train.shape)\nprint(df_test.shape)","5f9277cf":"x = df_train.drop(['Item_Outlet_Sales'], axis=1).values\ny = df_train.Item_Outlet_Sales.values","4490ddc3":"train_x, test_x, train_y, test_y = train_test_split(x,y, test_size = 0.2, random_state = 42)\ntrain_x.shape, test_x.shape, train_y.shape, test_y.shape","38985261":"feature_scale = StandardScaler()\ntrain_x = feature_scale.fit_transform(train_x)\ntest_x = feature_scale.transform(test_x)","911ad2cd":"#Linear Regression\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(train_x,train_y)\nprint('Root Mean Squared Error : ', np.sqrt(metrics.mean_squared_error(test_y, lin_reg.predict(test_x))))","3b8bc77f":"#Random Forest\nrf = RandomForestRegressor(n_estimators=1000, max_depth=10, min_samples_leaf=100, random_state=42)\nrf.fit(train_x, train_y)\n\nprint('Root Mean Squared Error : ', np.sqrt(metrics.mean_squared_error(test_y, rf.predict(test_x))))","c95c929f":"#Decision Tree\nDT = DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\nDT.fit(train_x, train_y)\n\nprint('Root Mean Squared Error : ', np.sqrt(metrics.mean_squared_error(test_y, DT.predict(test_x))))","b06a9361":"#Xtreme Gradient Boosting\nboost = xgb.XGBRegressor(learning_rate = 0.01, n_estimators=1000, max_depth = 4, random_state = 42)\nboost.fit(train_x, train_y)\n\nprint('Root Mean Squared Error : ', np.sqrt(metrics.mean_squared_error(test_y, boost.predict(test_x))))","7146205f":"test_pred_rf = rf.predict(df_test)\ntest_pred_rf","4d8f3a12":"#### We see, medium outlet are more in number when compared to two. Infact, big outlets are very less when compared to the other two","bfee078b":"Since we have a category of food as Non-Consumable, then these substances would be Inedible, so we can create a seperate category for these items in content variable","d4542f8f":"### Ploting some of categorical variables.","53eb9423":"### Oulet Location Type and its impact on Sales","066438a9":"## Data Pre-processing","d65e0438":"### Item Type and its impact on Sales","1b051985":"Let's check the distribution of our target column - ``Item_Outlet_Sales``","6cf328b1":"#### Few observations we can make from here are:\n\n1. The very first outlet was established in year 1985 & the latest was in 2009\n\n2. The item has atleat a weight of 4lbs with the maximum going up to 21lbs\n\n3. Visibility of any time cannot '0' as we can see here, there would be some manipulation happening here in this column\n\n4. The average sales of all the outlet is 2181 and the overall sales ranges from - 33 to 13086 dollars\n","1658e1a2":"Now is the time we deal with the categorical variables, using label encoding which will convert categorical variables to numerical and creating dummy varibles of those numeric columns.","92f91ae9":"From the first look at the data, I assume the variables that will have higher impact on the Outlet sales are: \n``Item_Visibility`` , ``Item_Type`` , ``OutletSize`` , ``Outlet_Location_Type`` , ``Outlet_Type``.\n\n\nThe target variable is ``Item_Outlet_Sales`` .","d5402d05":"There are total 7 categoical columns & few missing values which can be delt with a little later","4c4be649":"Here we can make a hypothesis, that the product with high visibility will result in higher sales. So here we can create 1 more variable according the importance given to the item in all the outlets according to the mean of significance given to the same product in all other stores.","ef40b3bd":"``Item_Identifier`` is the unique id of a particular item in all the stores","3ce0a098":"After performing EDA, we are finally able to make some conclusions:\n\n1. The variables which we thought have higher impact on the outlet sales amongst that ``Item_Visibilty`` and ``Item_Type`` seem to have no high positive correlation with the sales, were as the Outlet's Size, Location & Type have high impact on the sales.\n\n\n2. While looking at the ``Item_Identifier`` variable, we observed there are some letters present in the id as FD, DR, NC, which we can assume to be as Food, Drinks & Non-Consumable. Perfect, we can extract a new variable from it.\n\n\n3. As we saw earlier variable ``Item_Visiblity`` has some values as ZERO, which does not make any sense, as this just means that the item is not present in the store.\n\n\n4. From ``Outlet_Establishment_Year`` we saw its values vary from 1985 to 2009, we can create a varibale indicating how old the outlet is.\n\n\n5. We saw that there are missing values in ``Item_Weight`` and ``Outlet_Size`` variable.\n","a64d8295":"Let's find out correlation between numerical features","67ce8e8c":"Cities that are just beginning to wake up have more number of outlets compared to the other developed cities. Let's see if sales are impacted byt the Location","51644ac1":"There are quite a good number of ``grocery stores`` but sale happening there is very minimal. Also, ``Type 1 Supermarket`` is higher in number but it is not performing well it seems. The highest sales is happening is ``Type 3 Supermarket`` despite of, there are not many outlets of it.","d1b70f1b":"On an average the Big Mart stores are about 15 years old, the last outlet was opened 4 years back from 2013 ie; in 2009","1a9f0894":"The other categorical variable is ``Item_type``, lets check what are the different items sold in the outlet and does it have any impact on the sales.","79ed8a6d":"We can clearly see Mrp of any item is correlated with the sales of the outlet. ","57aa6d6c":"## Exploratory Data Analysis","2d2c0627":"Let's create a broad category of the ``Item_Identifier`` as we saw there are 1559 unique items each starting with some letters such as ``FD, DR, NC``, we can replace them with ``FOOD, DRINKS & NON-CONSUMABLE``","b7b5d94a":"There are total ``1559`` unique products present across all the stores","279a38dd":"## Feature Engineering","e66b7707":"As we saw in ``Item_Visibilty`` variable there are values which are zero, but it should not be like this as it has be visible to everyone to make sales, so lets treat it as missing value and replace it with the mean.","a72d8590":"The sales out smaller outlets is very low though they were more in number compared to higher outlets and there is very minimal difference between the sales higher size of outlets and medium sized outlets, though the number of large outlets are less in number.","eac9fcec":"We shall plot each categorical variable and its impact on sales","8640355b":"### Fat Content & its Impact on Sales","49966e94":"Natural counterpart of histograms are frequency and bar charts for categorical variables","f6e7f7bc":"Type 1 Supermarket is a lot more in number compared to the other supermarkets or grocery store, lets see if that impacts the sale","f1c3e137":"### Outlet Size & its impact on Sales","7c24c932":"### Outlet Type and its impact on Sales","2d18ec98":"Our target column is left skewed.","08bdf49a":"Let's check if there are null values & we can impute all the null values ","3a71945f":"If we notice there is some repition in the data, boardly we can divide this in 2 categories i.e; ``Low Fat`` & ``Regular``. We can remove that in during feature engineering, right now we can manupulate it just to graphically represent it."}}