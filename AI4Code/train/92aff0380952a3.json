{"cell_type":{"431f6441":"code","7c99bec7":"code","80aa334a":"code","d1e9ac8d":"code","32e59caa":"code","1e3cc5c2":"code","21c665f0":"code","b51324ca":"code","66ac16c3":"code","96deefe7":"code","4cbbfc9f":"code","f6e47d0c":"code","1fcc0ef9":"code","2cf69c4b":"code","b3f0952b":"code","a26669d2":"code","85d44c66":"code","b958e810":"code","2bc07113":"code","f186d1aa":"code","99fb4568":"code","1c4df309":"code","4e199b54":"code","4913a195":"code","1598594a":"code","3c584373":"code","db78f0a1":"code","8fa32d15":"code","6a860dc9":"code","ad0d1ee7":"code","1c5bea69":"code","e58d2256":"code","2268ebc9":"code","a6d233ef":"code","50885686":"code","a52b28a1":"code","abd1376c":"code","ccefc8c0":"code","f526146b":"code","40d98ef3":"markdown","6f6588d9":"markdown","e7a5c27c":"markdown","e984e54d":"markdown","ed21023e":"markdown","944d7c72":"markdown","90284da2":"markdown","16a790fe":"markdown","ff18c80d":"markdown","b8ae6220":"markdown","b0cd61ca":"markdown","15949c7b":"markdown","0684b82f":"markdown","a23c10a2":"markdown","0ef22a21":"markdown","9ca92944":"markdown","156bc970":"markdown"},"source":{"431f6441":"import pandas as pd\nimport numpy as np","7c99bec7":"# Read data\n# Test - to be predicted\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n# Train - training data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')","80aa334a":"# get PassengerId from test columns. This will help in prediction later\ntestPassengerIds = test['PassengerId']\ntestPassengerIds.head()","d1e9ac8d":"# Drop some columns\ntrain.drop(['PassengerId', 'Name', 'Ticket'], inplace = True, axis = 1)\ntest.drop(['PassengerId', 'Name', 'Ticket'], inplace = True, axis = 1)","32e59caa":"train.head()","1e3cc5c2":"test.head()","21c665f0":"train.isnull().any()","b51324ca":"test.isnull().any()","66ac16c3":"train['Cabin'].unique()","96deefe7":"# Dictionary for mappinig\n# Fill each place with First letter to label mapping\n\ntrain['Cabin'].fillna(0, inplace = True)\ndef getCabin(value):\n    val_dict = {\n        'A' : 6,\n        'B' : 5,\n        'C' : 4,\n        'D' : 3,\n        'E' : 2,\n        'F' : 1,\n        'T' : 1   ## Taking T same as F, taking it to be an error     \n    }\n    return val_dict.get(str(value)[0], 0)\n\ntrain['Cabin'] = train[\"Cabin\"].apply(getCabin)\ntest['Cabin'] = test['Cabin'].apply(getCabin)","4cbbfc9f":"train.head()","f6e47d0c":"# Fill with most common values\ntrain['Embarked'].fillna(train['Embarked'].mode().item() , inplace = True)\n# To ensure no discrepancy\ntest['Embarked'].fillna(train['Embarked'].mode().item(), inplace = True)","1fcc0ef9":"import plotly.express as px\nfig = px.sunburst(train, path=['Embarked', 'Pclass', 'Sex'], values='Survived', title = 'Embarked -> Class -> Sex')\nfig.show()","2cf69c4b":"# One hot encode the Data\ntrain = pd.get_dummies(train, drop_first=True)\ntest = pd.get_dummies(test, drop_first=True)","b3f0952b":"# Impute age with median\nmean = train['Age'].median()\ntrain['Age'].fillna(mean, inplace = True)\ntest['Age'].fillna(mean, inplace = True)","a26669d2":"# using `|` makes or operator, checks if missing in train or test\ntrain.isnull().any() | test.isnull().any()","85d44c66":"# Impute fare with mean of training data\nmeanFare = train['Fare'].mean()\ntest['Fare'].fillna(meanFare, inplace = True)","b958e810":"train.head()","2bc07113":"test.head()","f186d1aa":"# Put the log of fare and class\ndef correctedLog(value):  # So that we do not get infinity\n    return np.log(1 + value)\n\ntrain['Status'] = train['Pclass'] + train['Fare'].apply(correctedLog)\ntest['Status'] = test['Pclass'] + test['Fare'].apply(correctedLog)","99fb4568":"train['RootAgeTimesClass'] = train['Age'].apply(np.sqrt) * train['Pclass']\ntest['RootAgeTimesClass'] = test['Age'].apply(np.sqrt) * test['Pclass']","1c4df309":"train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = train['SibSp'] + train['Parch'] + 1","4e199b54":"train.head()","4913a195":"train['Young'] = train['Age'] <= train['Age'].mean()\ntest['Young'] = test[\"Age\"] <= train['Age'].mean()","1598594a":"train['YoungMale'] = train['Young'] & train['Sex_male']\ntest['YoungMale'] = test[\"Young\"] & test['Sex_male']","3c584373":"train.head()","db78f0a1":"X = train.iloc[:, 1: ]\ny = train.iloc[:, 0]\ny.shape, X.shape","8fa32d15":"import matplotlib.pyplot as plt\nplt.hist(train['Fare']);\n","6a860dc9":"# Visualising the Box Cox Transform\nfrom scipy.stats import boxcox\nxt,_ = boxcox(train['Fare'] + 1)\nplt.hist(xt);","ad0d1ee7":"# Apply Box Cox Transformation\ntrain['Fare'], maxlog = boxcox(train['Fare'] + 1)\ntest['Fare'] = boxcox(test['Fare'] + 1, lmbda = maxlog)","1c5bea69":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","e58d2256":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state =55, test_size = 0.2, shuffle = True)\ny_train.shape, y_val.shape","2268ebc9":"X_train.head()","a6d233ef":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nnp.random.seed(0)","50885686":"# Parameters for Grid Search\nparamDict = {\n    'n_estimators' : [5, 10, 25, 50, 75, 100, 200, 500],\n    'max_depth' : [4, 8, 10, 15, 20, 50],\n    \n}\n# Random Forest Model\nmodel = RandomForestClassifier(n_jobs = 8)\n# Grid Search CV\nclf = GridSearchCV(estimator=model, param_grid=paramDict, n_jobs=10)","a52b28a1":"clf.fit(X_train, y_train)","abd1376c":"clf.best_params_, clf.best_score_","ccefc8c0":"f1_score(clf.predict(X_val), y_val)","f526146b":"# Make model with best parameters, fit with all data now\nfinalModel = RandomForestClassifier(**clf.best_params_)\n\n# Fit Data\nfinalModel.fit(X, y)\n\n# Generate Predictions\ny_preds = finalModel.predict(test)\n\n#########################################################################\n# Submission File Generation\nfile_name = \"Submission_16_08_6.csv\"\n\ny_pred_series = pd.Series(y_preds.flatten(), name = 'Survived')\n\nfile = pd.concat([testPassengerIds, y_pred_series], axis = 1)\n\nfile.to_csv(file_name, index = False);","40d98ef3":"## Final Submission\nFor training the final model, we will use all of the training data to give us additional boost","6f6588d9":"<h2><span style = 'text-shadow: 2px 2px 5px green;'>Box Cox Transform<\/span><\/h2>\n\nBox Cox transform converts skewed values to Approximately a normal distribution. I came across and thought, lets apply!","e7a5c27c":"## 3. Age\nWe will impute age with the median age","e984e54d":"# Feature Engineering\n\nNumber of features is less. So let us use Feature Engineering to add features","ed21023e":"# Model Fitting\n\nWe will use Random Forest Model for predictions. We will also use GridSearchCV to tune hyperparameters","944d7c72":"<style>\n@import url('https:\/\/fonts.googleapis.com\/css2?family=Pangolin&display=swap');\n<\/style>\n\n<h1>\n    <span style = 'font-family : Pangolin, cursive;'>\n    Titanic Experimentation!\n    <\/span>\n<\/h1>\n \n\n<span style = \"color : blue\"> This is my second attempt at Titanic Dataset. This was mainly for experimenting with techniques<\/span>\n<hr>\n\nYou can view my First notebook [here](https:\/\/www.kaggle.com\/duttasd28\/titanic-0-8-accuracy-nn)","90284da2":"# Imputation\n\nThere are many null values in the data. We will need to impute them that is fill them","16a790fe":"Let us replace the values with the first letters. For example **A3** will become **A**. Also, lets assign numeric values to the data. \n\nSo, some column like 'A32' will become 'A' and then 6","ff18c80d":"Hope you like my work! If you do, please UPvote! \ud83d\ude03\ud83d\ude03","b8ae6220":"# Visualisation","b0cd61ca":"Get the best parameters and score","15949c7b":"## 2. Embarked\n\nEmbarked column has few missing values, so let us fill it with the most common value that is `mode`","0684b82f":"## 1. Cabin\n\nWe will fill the`Cabin` column with our own label mapping.","a23c10a2":"Let us use plotly to visualise this interactively","0ef22a21":"# Train Test Split","9ca92944":"# Import Necessary libraries and manage DataFrames\n\nWe will import necessary libraries and use pandas and numpy for our purposes","156bc970":"We see that Test data has only `Fare` missing."}}