{"cell_type":{"de0f25f6":"code","01d005ed":"code","381f6c4f":"code","898aec2b":"code","41bb5303":"code","5f3983eb":"code","61aab907":"code","a844137b":"code","95c473af":"code","ecb72681":"code","b19a7272":"code","0a55f004":"code","168794ba":"code","8d71fe2b":"code","5d834ccf":"code","e5b14168":"code","148343bf":"code","d323bf51":"code","4240b22c":"code","dd675a26":"code","e5f26436":"code","c16d761c":"code","f6f8d302":"code","a07a9842":"markdown","47a07a66":"markdown","9cfce6e6":"markdown","99828c5f":"markdown","a1a4eb08":"markdown","1d766bb5":"markdown","5333c95a":"markdown","84aa770d":"markdown","7ce55073":"markdown","18be3a66":"markdown","2f51e459":"markdown","9e8ad195":"markdown"},"source":{"de0f25f6":"# modify Cooking.py --> substitute raise StopIteration to return\n# modify Generator.py --> embed brighten, add brightness_range to match keras.preprocessing.image.ImageDataGenerator\n#                         change image.flip_axis() to image.image.flip_axis()\n!git clone https:\/\/github.com\/rkuo2000\/AutonomousDrivingCookbook\n%cd AutonomousDrivingCookbook\/AirSimE2EDeepLearning","01d005ed":"import numpy as np\nimport pandas as pd \nimport h5py\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nimport os","381f6c4f":"RAW_DATA_DIR = '\/kaggle\/input\/airsim-e2e-rawdata\/data_raw\/'\nCOOKED_DATA_DIR = 'data_cooked\/'\nMODEL_OUTPUT_DIR = 'model'\nDATA_FOLDERS = ['normal_1', 'normal_2', 'normal_3', 'normal_4', 'normal_5', 'normal_6', 'swerve_1', 'swerve_2', 'swerve_3']\nFIGURE_SIZE = (10,10)","898aec2b":"sample_tsv_path = os.path.join(RAW_DATA_DIR, 'normal_1\/airsim_rec.tsv')\nsample_tsv = pd.read_csv(sample_tsv_path, sep='\\t')\nsample_tsv.head()","41bb5303":"sample_image_path = os.path.join(RAW_DATA_DIR, 'swerve_1\/images\/img_0.png')\nsample_image = Image.open(sample_image_path)\nplt.title('Sample Image')\nplt.axis('off')\nplt.imshow(sample_image)\nplt.show()","5f3983eb":"sample_image_roi = sample_image.copy()\n\nfillcolor=(255,0,0)\ndraw = ImageDraw.Draw(sample_image_roi)\npoints = [(1,76), (1,135), (255,135), (255,76)]\nfor i in range(0, len(points), 1):\n    draw.line([points[i], points[(i+1)%len(points)]], fill=fillcolor, width=3)\ndel draw\n\nplt.title('Image with sample ROI')\nplt.axis('off')\nplt.imshow(sample_image_roi)\nplt.show()","61aab907":"full_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\n\ndataframes = []\nfor folder in full_path_raw_folders:\n    current_dataframe = pd.read_csv(os.path.join(folder, 'airsim_rec.txt'), sep='\\t')\n    current_dataframe['Folder'] = folder\n    dataframes.append(current_dataframe)\n    \ndataset = pd.concat(dataframes, axis=0)\n\nprint('Number of data points: {0}'.format(dataset.shape[0]))\n\ndataset.head()","a844137b":"min_index = 100\nmax_index = 1100\nsteering_angles_normal_1 = dataset[dataset['Folder'].apply(lambda v: 'normal_1' in v)]['Steering'][min_index:max_index]\nsteering_angles_swerve_1 = dataset[dataset['Folder'].apply(lambda v: 'swerve_1' in v)]['Steering'][min_index:max_index]\n\nplot_index = [i for i in range(min_index, max_index, 1)]\n\nfig = plt.figure(figsize=FIGURE_SIZE)\nax1 = fig.add_subplot(111)\n\nax1.scatter(plot_index, steering_angles_normal_1, c='b', marker='o', label='normal_1')\nax1.scatter(plot_index, steering_angles_swerve_1, c='r', marker='o', label='swerve_1')\nplt.legend(loc='upper left');\nplt.title('Steering Angles for normal_1 and swerve_1 runs')\nplt.xlabel('Time')\nplt.ylabel('Steering Angle')\nplt.show()","95c473af":"dataset['Is Swerve'] = dataset.apply(lambda r: 'swerve' in r['Folder'], axis=1)\ngrouped = dataset.groupby(by=['Is Swerve']).size().reset_index()\ngrouped.columns = ['Is Swerve', 'Count']\n\ndef make_autopct(values):\n    def my_autopct(percent):\n        total = sum(values)\n        val = int(round(percent*total\/100.0))\n        return '{0:.2f}%  ({1:d})'.format(percent,val)\n    return my_autopct\n\npie_labels = ['Normal', 'Swerve']\nfig, ax = plt.subplots(figsize=FIGURE_SIZE)\nax.pie(grouped['Count'], labels=pie_labels, autopct = make_autopct(grouped['Count']))\nplt.title('Number of data points per driving strategy')\nplt.show()","ecb72681":"bins = np.arange(-1, 1.05, 0.05)\nnormal_labels = dataset[dataset['Is Swerve'] == False]['Steering']\nswerve_labels = dataset[dataset['Is Swerve'] == True]['Steering']","b19a7272":"def steering_histogram(hist_labels, title, color):\n    plt.figure(figsize=FIGURE_SIZE)\n    n, b, p = plt.hist(hist_labels.to_numpy(), bins, density=1, stacked=True, facecolor=color)\n    plt.xlabel('Steering Angle')\n    plt.ylabel('Normalized Frequency')\n    plt.title(title)\n    plt.show()\n\nsteering_histogram(normal_labels, 'Normal label distribution', 'g')\nsteering_histogram(swerve_labels, 'Swerve label distribution', 'r')","0a55f004":"from Generator import DriveDataGenerator\nfrom Cooking import checkAndCreateDir","168794ba":"import Cooking\ntrain_eval_test_split = [0.7, 0.2, 0.1]\nfull_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\nCooking.cook(full_path_raw_folders, COOKED_DATA_DIR, train_eval_test_split)","8d71fe2b":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers, callbacks\nimport tensorflow_addons as tfa \nimport tqdm\n\nimport json\nimport os\nimport numpy as np\nimport pandas as pd\nfrom Generator import DriveDataGenerator\nfrom Cooking import checkAndCreateDir\nimport h5py\nfrom PIL import Image, ImageDraw\nimport math\nimport matplotlib.pyplot as plt\n\nCOOKED_DATA_DIR  = 'data_cooked' # cooked data path from previous cooking step\nMODEL_OUTPUT_DIR = 'model'       # model output path","5d834ccf":"train_dataset= h5py.File(os.path.join(COOKED_DATA_DIR, 'train.h5'), 'r')\neval_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'eval.h5'), 'r')\ntest_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'test.h5'), 'r')\n\nnum_train_examples = train_dataset['image'].shape[0]\nnum_eval_examples = eval_dataset['image'].shape[0]\nnum_test_examples = test_dataset['image'].shape[0]\n\nbatch_size=32","e5b14168":"data_generator = DriveDataGenerator(rescale=1.\/255., horizontal_flip=True)\ntrain_generator= data_generator.flow(train_dataset['image'], train_dataset['previous_state'], train_dataset['label'], batch_size=batch_size, zero_drop_percentage=0.5, roi=[76,135,0,255])\neval_generator = data_generator.flow(eval_dataset['image'], eval_dataset['previous_state'], eval_dataset['label'], batch_size=batch_size, zero_drop_percentage=0.5, roi=[76,135,0,255])","148343bf":"from keras.preprocessing import image \nimport keras.backend as K\ndef draw_image_with_label(img, label, prediction=None):\n    theta = label * 0.69 #Steering range for the car is +- 40 degrees -> 0.69 radians\n    line_length = 50\n    line_thickness = 3\n    label_line_color = (255, 0, 0)\n    prediction_line_color = (0, 0, 255)\n    print(img.shape)\n    pil_image = image.array_to_img(img, K.image_data_format(), scale=True)\n    print('Actual Steering Angle = {0}'.format(label))\n    draw_image = pil_image.copy()\n    image_draw = ImageDraw.Draw(draw_image)\n    first_point = (int(img.shape[1]\/2),img.shape[0])\n    second_point = (int((img.shape[1]\/2) + (line_length * math.sin(theta))), int(img.shape[0] - (line_length * math.cos(theta))))\n    image_draw.line([first_point, second_point], fill=label_line_color, width=line_thickness)\n    \n    if (prediction is not None):\n        print('Predicted Steering Angle = {0}'.format(prediction))\n        print('L1 Error: {0}'.format(abs(prediction-label)))\n        theta = prediction * 0.69\n        second_point = (int((img.shape[1]\/2) + (line_length * math.sin(theta))), int(img.shape[0] - (line_length * math.cos(theta))))\n        image_draw.line([first_point, second_point], fill=prediction_line_color, width=line_thickness)\n    \n    del image_draw\n    plt.axis('off')\n    plt.imshow(draw_image)\n    plt.show()\n\n[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i], sample_batch_test_data[i])","d323bf51":"image_input_shape = sample_batch_train_data[0].shape[1:]\nstate_input_shape = sample_batch_train_data[1].shape[1:]\n\n#Create the convolutional stacks\npic_input = layers.Input(shape=image_input_shape)\n\nx = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(pic_input)\nx = layers.MaxPooling2D(pool_size=(2,2))(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.2)(x)\n\n#Inject the state input\nstate_input = layers.Input(shape=state_input_shape)\nm = layers.concatenate([x, state_input])\n\n# Add a few dense layers to finish the model\nm = layers.Dense(64, activation='relu')(m)\nm = layers.Dropout(0.2)(m)\nm = layers.Dense(10, activation='relu')(m)\nm = layers.Dropout(0.2)(m)\nm = layers.Dense(1)(m)\n\nmodel = models.Model(inputs=[pic_input, state_input], outputs=m)\n\nmodel.summary()","4240b22c":"#adam = Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodel.compile(optimizer='Adam', loss='mse')","dd675a26":"plateau_callback = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\ncheckpoint_filepath = os.path.join(MODEL_OUTPUT_DIR, 'models', '{0}_model.{1}-{2}.h5'.format('model', '{epoch:02d}', '{val_loss:.7f}'))\ncheckAndCreateDir(checkpoint_filepath)\ncheckpoint_callback = callbacks.ModelCheckpoint(checkpoint_filepath, save_best_only=True, verbose=1)\ncsv_callback = callbacks.CSVLogger(os.path.join(MODEL_OUTPUT_DIR, 'training_log.csv'))\nearly_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\ncallbacks=[plateau_callback, csv_callback, checkpoint_callback, early_stopping_callback, tfa.callbacks.TQDMProgressBar()]","e5f26436":"history = model.fit(train_generator, steps_per_epoch=num_train_examples\/\/batch_size, epochs=500, callbacks=callbacks,\\\n                   validation_data=eval_generator, validation_steps=num_eval_examples\/\/batch_size, verbose=2)","c16d761c":"models.save_model(model, \"airsim_e2e.h5\")","f6f8d302":"[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\npredictions = model.predict([sample_batch_train_data[0], sample_batch_train_data[1]])\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i], sample_batch_test_data[i], predictions[i])","a07a9842":"### Train Model","47a07a66":"## [Raw Data](https:\/\/aka.ms\/AirSimTutorialDataset) \n* https:\/\/www.kaggle.com\/rkuo2000\/airsim-e2e-rawdata<br \/>\nrecorded from AirSim-LandscapeMountains Car","9cfce6e6":"## distribution of labels look likes for the two strategies","99828c5f":"### Number of data points per driving strategy","a1a4eb08":"### Steering Angles from normal_1 and swerve_1 runs","1d766bb5":"### Repro [Github](https:\/\/github.com\/Microsoft\/AutonomousDrivingCookbook)","5333c95a":"# AirSim End-to-End Learning for Autonomous Driving","84aa770d":"## Model Training","7ce55073":"### Save Model","18be3a66":"### Extracting ROI will both reduce the training time and the amount of data needed to train the model. ","2f51e459":"## Test Model","9e8ad195":"## Data Exploration and Preparation"}}