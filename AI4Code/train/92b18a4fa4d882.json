{"cell_type":{"c4bed8f6":"code","f6b8c25a":"code","852855ab":"code","2bc664cd":"code","4238a238":"code","04bfd665":"code","46447f94":"code","95250d38":"code","c99dc64b":"code","a0b36718":"code","1f7cbdbc":"code","61bcf0b2":"code","6f57e191":"code","0039297b":"code","36ec0c09":"code","be681845":"code","cabbcb4d":"code","601e347c":"markdown","0aa56b01":"markdown","9f6091fd":"markdown","af1beb00":"markdown","a0078fe6":"markdown","42e41a87":"markdown","cd08236b":"markdown"},"source":{"c4bed8f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6b8c25a":"!pip install segmentation_models_pytorch\n! git clone https:\/\/github.com\/Bjarten\/early-stopping-pytorch.git\n! mv .\/early-stopping-pytorch .\/lib","852855ab":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom pathlib import Path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport time\nimport torchvision\nimport cv2\nimport re\nimport segmentation_models_pytorch as smp\nfrom lib.pytorchtools import *","2bc664cd":"class NerveDataset(Dataset):\n    def __init__(self, directory, pytorch=True, is_test=False):\n        super().__init__()\n        \n        # Loop through the files in 'directory' folder and combine, into a dictionary, the masks\n        self.files = []\n        for file_name in directory.iterdir():\n            \n            if 'mask' in str(file_name):\n                continue\n                \n            self.files.append(self.combine_files(file_name))\n            \n        # Sorting files list\n        self.files = sorted(self.files, key=lambda file: int(re.search(r'\\d+', str(file['image'])).group(0)))\n        #print(self.files)\n        \n        self.pytorch = pytorch\n        self.resize = torchvision.transforms.Resize((224,224),interpolation=Image.NEAREST)\n        self.is_test = is_test\n        \n    def combine_files(self, file_name: Path):\n        \n        files = {\n            'image': file_name, \n            'mask': '..' + str(file_name).split('.')[2] + '_mask.tif',\n        }\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def open_as_array(self, idx, invert=False):\n        \n        raw_image = self.resize(Image.open(self.files[idx]['image']))\n        raw_image = raw_image = np.stack([ np.array(raw_image) ], axis=2)\n    \n        if invert:\n            raw_image = raw_image.transpose((2,0,1))\n    \n        # normalize\n        return (raw_image \/ np.iinfo(raw_image.dtype).max)\n    \n\n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = self.resize(Image.open(self.files[idx]['mask']))\n        raw_mask = np.array(raw_mask)\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch), dtype=torch.float32)\n        \n        if not self.is_test:    \n            y = torch.tensor(self.open_mask(idx, add_dims=True), dtype=torch.torch.float32)\n            return x, y\n        \n        return x\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'L')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s\n","4238a238":"images_path = Path('..\/input\/ultrasound-nerve-segmentation\/train')\ndata = NerveDataset(images_path)\nlen(data)","04bfd665":"fig, ax = plt.subplots(1,2, figsize=(10,9))\nax[0].imshow(data.open_as_array(5))\nax[1].imshow(data.open_mask(5))","46447f94":"split_rate = 0.7\ntrain_ds_len = int(len(data) * split_rate)\nvalid_ds_len = len(data) - train_ds_len\n\ntrain_ds, valid_ds = torch.utils.data.random_split(data, (train_ds_len, valid_ds_len))\n\nprint(f'Train dataset length: {len(train_ds)}\\n')\nprint(f'Validation dataset length: {len(valid_ds)}\\n')\nprint(f'All data length: {len(data)}\\n')","95250d38":"# Model\nunet = model = smp.Unet(\n    encoder_name=\"resnet34\",\n    encoder_weights=\"imagenet\",\n    in_channels=1,\n    classes=1,\n    activation = \"sigmoid\"\n)\n# Device type\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Params\nlearning_rate = 0.001\nepochs = 50\nmetrics = [smp.utils.metrics.IoU()]\n# Loss & optimizer\nloss_function = smp.utils.losses.DiceLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n# Scheduler & stopper\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\nstopper = EarlyStopping(patience=3)\n# Train & vallidation functions\ntrain_epoch = smp.utils.train.TrainEpoch(model,\n                                          loss=loss_function,\n                                          optimizer=optimizer,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)\nval_epoch = smp.utils.train.ValidEpoch(model,\n                                          loss=loss_function,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)\n\n# Data loaders\ntrain_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=16, shuffle=True)","c99dc64b":"train_loss = []\nval_loss = []\n\ntrain_acc = []\nval_acc = []\n\nfor epoch in range(epochs):\n    # training proccess\n    print('\\nEpoch: {}'.format(epoch))\n    train_log = train_epoch.run(train_dl)\n    val_log = val_epoch.run(valid_dl)\n\n    scheduler.step()\n\n    train_loss.append(train_log[loss_function.__name__])\n    val_loss.append(val_log[loss_function.__name__])\n\n    train_acc.append(train_log['iou_score']) \n    val_acc.append(val_log['iou_score'])\n\n    stopper(val_log[loss_function.__name__], model)\n    if stopper.early_stop:\n        break","a0b36718":"plt.figure(figsize=(10, 10))\nplt.plot(range(len(train_loss)), train_loss, label='tain_loss')\nplt.plot(range(len(val_loss)), val_loss, label='val_loss')\nplt.legend()\nplt.title('Train and validation losses for each epoch', fontdict={'fontsize': 30,}, pad=20)","1f7cbdbc":"plt.figure(figsize=(10, 10))\nplt.plot(range(len(train_acc)), train_acc, label='train_acc')\nplt.plot(range(len(val_acc)), val_acc, label='val_acc')\nplt.legend()\nplt.title('Train and validation accuracy for each epoch', fontdict={'fontsize': 30,}, pad=20)","61bcf0b2":"test_images_path = Path('..\/input\/ultrasound-nerve-segmentation\/test')\ntest_data = NerveDataset(test_images_path, is_test=True)\ntest_dl = DataLoader(test_data, batch_size=1, shuffle=False)\nlen(test_data)","6f57e191":"unet.train(False)\n\ndataiter = iter(valid_dl)\n\nfx, ax = plt.subplots(3, 5, figsize=(10,10))\n\nfor i in range(5):\n    images, masks = dataiter.next()\n    \n    ax[0][i].imshow(np.transpose(images[0], (1, 2, 0)))\n    ax[1][i].imshow(np.transpose(masks[0], (1, 2, 0)))\n    \n    if torch.cuda.is_available():\n        images = images.cuda()\n    \n    pred = unet(images)\n    pred = pred.cpu().detach().numpy()\n    # print(pred)\n    ax[2][i].imshow(np.transpose(pred[0], (1, 2, 0)))\n    \n    #ax[3][i].imshow(pred[0][1] - pred[0][0])\n    \n    \n    ","0039297b":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","36ec0c09":"encodings = []\ncounter = 0\n\n# fx, ax = plt.subplots(1, 5, figsize=(10,10))\n\nfor image in test_dl:\n    \n    if torch.cuda.is_available():\n        image = image.cuda()\n        \n    pr_mask = unet(image)\n    \n    pr_mask = pr_mask[0]\n    \n    pr_mask = pr_mask.squeeze().cpu().detach().numpy().round().astype(np.uint8)\n    pr_mask = cv2.resize(pr_mask,(580,420), interpolation=cv2.INTER_CUBIC)\n\n    encodings.append(rle_encoding(pr_mask))\n    \n    print(f'Image: {counter} ')\n    \n    counter += 1\n#     ax[counter].imshow(pr_mask)\n#     if counter == 5:\n#         break\n","be681845":"len(encodings)","cabbcb4d":"df_submission = pd.DataFrame(columns=[\"img\", \"pixels\"])\nfor i, encoding in enumerate(encodings):\n    pixels = ' '.join(map(str, encoding))\n    df_submission.loc[i] = [str(i+1), pixels]\n\ndf_submission.to_csv('.\/submission.csv', index=False)\nprint('Done!')","601e347c":"# Model configuring","0aa56b01":"### Creating cumstom Pytorch dataset","9f6091fd":"# **Creating Dataset**","af1beb00":"# Model training","a0078fe6":"### Split data to train and validation sets","42e41a87":"## Useful imports","cd08236b":"# Train results"}}