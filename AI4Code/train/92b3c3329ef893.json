{"cell_type":{"14e01393":"code","77ced18f":"code","dcae291c":"code","c72476c7":"code","11dd137d":"code","6d0e140d":"code","78b9a2b7":"code","993a7825":"code","bd2b7942":"code","f39da5fa":"code","7d39ec21":"code","00d1604a":"code","c101b7de":"code","91018326":"code","0acbc0f9":"code","cdcc68ff":"code","5935cfe7":"code","dfde8452":"markdown","6df2c0f4":"markdown","53a77f8d":"markdown","9b66d201":"markdown","89b4ebd4":"markdown","14862480":"markdown","c27e7229":"markdown","a58b8752":"markdown","c987e9b6":"markdown","8c9e73d3":"markdown"},"source":{"14e01393":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77ced18f":"Train_Dir = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/train\" \nTrain_Dir_humans = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/train\/humans\"\nTrain_Dir_horses = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/train\/horses\"\n\nVal_Dir=\"..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\nVal_Dir_humans = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/humans\"\nVal_Dir_horses = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/horses\"","dcae291c":"\nimport os\nNum_humans_train = len(os.listdir(Train_Dir_humans))\nNum_horses_train = len(os.listdir(Train_Dir_horses))\n\n#total validation data\nNum_humans_val = len(os.listdir(Val_Dir_humans))\nNum_horses_val = len(os.listdir(Val_Dir_horses))\n\n\nTotal_train_data=Num_humans_train + Num_horses_train\nTotal_val_data=Num_humans_val+Num_horses_val\n\n","c72476c7":"print('total training human images:', Num_humans_train)\nprint('total training horses images:', Num_horses_train)\n\nprint('total validation human images:', Num_humans_val)\nprint('total validation horses images:', Num_horses_val)\nprint(\"--\")\nprint(\"Total training images:\", Total_train_data)\nprint(\"Total validation images:\", Total_val_data)","11dd137d":"Img_Size = 150 #keeping the resolition of all images to 150x150 to feed the neural network\nBatch_size= 100","6d0e140d":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen=ImageDataGenerator(1.\/255) #rescale all images to 1\/255\ntest_datagen=ImageDataGenerator(1.\/255)\n\ntrain_generator= train_datagen.flow_from_directory(Train_Dir,target_size=(Img_Size,Img_Size),batch_size=Batch_size,class_mode='binary') # because we use binary cross entropy for our loss calcualtion\nval_generator= test_datagen.flow_from_directory(Val_Dir,target_size=(Img_Size,Img_Size),batch_size=Batch_size,class_mode='binary')","78b9a2b7":"import tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(Img_Size, Img_Size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\n\nmodel.summary()","993a7825":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","bd2b7942":"history=model.fit(train_generator,epochs=30,steps_per_epoch=100,validation_data=val_generator,validation_steps=50)","f39da5fa":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(1, len(acc) +1 )\n\nplt.plot(epochs_range, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs_range, val_acc, 'b' ,label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs_range, loss,'bo', label='Training Loss')\nplt.plot(epochs_range, val_loss,'b', label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","7d39ec21":"model1 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(Img_Size, Img_Size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5), #add dropout layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\n\nmodel1.summary()\n\nmodel1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","00d1604a":"train_datagen_augmented=ImageDataGenerator(1.\/255, rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,zoom_range=0.2,horizontal_flip=True) #use augmentation\ntest_datagen=ImageDataGenerator(1.\/255)\n\ntrain_generator_augmented= train_datagen_augmented.flow_from_directory(Train_Dir,target_size=(Img_Size,Img_Size),batch_size=Batch_size,class_mode='binary') # because we use binary cross entropy for our loss calcualtion\nval_generator= test_datagen.flow_from_directory(Val_Dir,target_size=(Img_Size,Img_Size),batch_size=Batch_size,class_mode='binary')","c101b7de":"history=model1.fit(train_generator_augmented,epochs=100,steps_per_epoch=100,validation_data=val_generator,validation_steps=50)","91018326":"from keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\nconv_base.summary()","0acbc0f9":"from keras import models\nfrom keras import layers\n\nmodel_FE=models.Sequential()\nmodel_FE.add(conv_base)\nmodel_FE.add(layers.Flatten())\nmodel_FE.add(layers.Dense(256,activation='relu'))\nmodel_FE.add(layers.Dense(1,activation='sigmoid'))\nmodel_FE.summary()\n","cdcc68ff":"\ntrain_datagen=ImageDataGenerator(1.\/255, rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,zoom_range=0.2,horizontal_flip=True,shear_range=0.2,fill_mode='nearest') #use augmentation\ntest_datagen=ImageDataGenerator(1.\/255)\n\ntrain_generator= train_datagen.flow_from_directory(Train_Dir,target_size=(150,150),batch_size=100,class_mode='binary') # because we use binary cross entropy for our loss calcualtion\nval_generator= test_datagen.flow_from_directory(Val_Dir,target_size=(150,150),batch_size=100,class_mode='binary')\n\n","5935cfe7":"from keras import optimizers\nmodel_FE.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss='binary_crossentropy',metrics=['acc'])\nhistory=model_FE.fit_generator(train_generator,epochs=50,steps_per_epoch=100,validation_data=val_generator,validation_steps=50)","dfde8452":"**Run the model and check the accuracy**","6df2c0f4":"**understand the data\ntotal training data**","53a77f8d":"**Setting the model parameters**","9b66d201":"**Divide Training and Testing data**","89b4ebd4":"**Lets do Feature Extraction**","14862480":"**Lets use drop out and image augmentation to fix over fitting problem**","c27e7229":"**compile your model**","a58b8752":"****","c987e9b6":"**Data Preprocessing**","8c9e73d3":"**Build Model**"}}