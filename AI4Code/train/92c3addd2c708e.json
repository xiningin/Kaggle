{"cell_type":{"d4ac479f":"code","47313760":"code","b8dec3b6":"code","3e813578":"code","341a05bd":"code","0c3e724e":"code","ddbddab8":"code","b4033178":"code","9d76234a":"code","c384eac1":"code","242953e1":"code","63e9103c":"code","74ac3aae":"code","42174054":"code","2a2e1dc2":"code","745832af":"code","8cb425f4":"code","607402a1":"code","203bcfa3":"code","66f74c2f":"code","8a937396":"code","20a38597":"code","d36fad3d":"code","36881aaf":"code","668c5c0c":"code","c192270b":"code","2b976cae":"markdown","0a1acbf9":"markdown","cf8eca2c":"markdown","2c86608f":"markdown","72dc7195":"markdown","2af0b04a":"markdown","b583a82f":"markdown","0dfe4427":"markdown"},"source":{"d4ac479f":"!pip install tensorflow==1.15","47313760":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport tensorflow_hub as hub","b8dec3b6":"print(tf.__version__)","3e813578":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","341a05bd":"import glob\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n%matplotlib inline\nimport cv2\nfrom collections import defaultdict\nfrom IPython.display import SVG\nfrom tqdm.notebook import tqdm\nfrom PIL import Image","0c3e724e":"#import tensorflow as tf\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","ddbddab8":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\nos.chdir('Mask_RCNN')","b4033178":"!wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n!ls -lh mask_rcnn_coco.h5","9d76234a":"import sys\n# Root directory of the project\n#ROOT_DIR = os.path.abspath(\"..\/..\/\")\nROOT_DIR = ('..\/kaggle\/working\/')\n# Import Mask RCNN\nsys.path.append(ROOT_DIR)  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log\n\n\n# Directory to save logs and trained model\n#MODEL_DIR = os.path.join(ROOT_DIR, \"..\/output\/kaggle\/working\/logs\")\nMODEL_DIR = ('..\/kaggle\/working\/Mask_RCNN')\n\n# Local path to trained weights file\n#COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\n#if not os.path.exists(COCO_MODEL_PATH):\n#    utils.download_trained_weights(COCO_MODEL_PATH)","c384eac1":"class DetectorConfig(Config):\n   \n    # Configuration name  \n    NAME = 'instances'\n    \n    # We have one GPU available, but can put multiple images on it\n    # Batch size is 8 (GPUs * images\/GPU)\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 8\n    \n    BACKBONE = 'resnet101' #'resnet101' would be another option\n    \n    NUM_CLASSES = 2  # background + pneumonia classes -->semantic segmentation\n    \n    IMAGE_MIN_DIM = 256\n    IMAGE_MAX_DIM = 256\n    TRAIN_ROIS_PER_IMAGE = 32 #or 16\n    MAX_GT_INSTANCES = 4 #or 3\n    DETECTION_MAX_INSTANCES = 3\n    DETECTION_MIN_CONFIDENCE = 0.78  #or 0.7\n    DETECTION_NMS_THRESHOLD = 0.01 #or 0.3\n    STEPS_PER_EPOCH = 200 #or 500\n    \nconfig = DetectorConfig()\nconfig.display()","242953e1":"sys.path.append(os.path.join('Mask_RCNN'))  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log\n \n#!cd coco_weight && wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n#!ls -lh mask_rcnn_coco.h5\nCOCO_WEIGHTS_PATH = \"\/kaggle\/working\/Mask_RCNN\/mask_rcnn_coco.h5\"","63e9103c":"MODEL_DIR\nCOCO_WEIGHTS_PATH","74ac3aae":"# Create model in training mode\nmodel = modellib.MaskRCNN(mode='training', config=config, model_dir=MODEL_DIR)\nmodel.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n    \"mrcnn_bbox\", \"mrcnn_mask\"])","42174054":"image_path = '\/kaggle\/input\/open-images-instance-segmentation-rvc-2020\/test\/'\nfile_list = os.listdir(image_path)\ntype(file_list)\ntest_df = pd.DataFrame(file_list)\ntest_df.rename(columns = {0:'image_ids'}, inplace = True)","2a2e1dc2":"img = plt.imread( image_path + '00001a21632de752.jpg')\nplt.imshow(img)\nIMG_SHAPE = img.shape\nprint (IMG_SHAPE)","745832af":"def display_images(flnames):\n    f, ax = plt.subplots(3,4, figsize=(20,40))\n    image_path = '\/kaggle\/input\/open-images-instance-segmentation-rvc-2020\/test\/'\n    #for img in path.iterdir():\n\n    for i, fl in enumerate(flnames):\n        ax[i\/\/4,i%4].set_axis_off()\n        img = cv2.imread( image_path+fl)\n        ax[i\/\/4,i%4].imshow(img)\n        ax[i\/\/4,i%4].set_title(f'{fl}')\n        f.tight_layout()","8cb425f4":"display_images(list(test_df['image_ids'][:12]))","607402a1":"'''\nfig, axes = plt.subplots(10, figsize=(20,20))\nfor i in range(10):\n    img = cv2.imread( image_path+test_df['image_ids'][i])\n    axes[i].imshow(img)\n''' ","203bcfa3":"def resize_image(image):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (self.IMAGE_SIZE, self.IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n    return img","66f74c2f":"#hs, ws = [], []\ntest_df['height'] = \"\"\ntest_df['weight'] = \"\"\n#test_df = pd.DataFrame(file_list)\nfor i, row in tqdm(test_df.iterrows(), total = len(test_df)): #total = len(test_df)):\n    img = Image.open(Path(path)\/(test_df['image_ids'][i]))\n    h, w = img.size\n    test_df['height'][i] = h\n    test_df['weight'][i] = w\n    #hs.append(h)\n    #ws.append(w)","8a937396":"test_df.head(5)","20a38597":"test_df.to_csv('\/kaggle\/working\/test_df.csv')","d36fad3d":"# example of inference with a pre-trained coco model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom mrcnn.visualize import display_instances\nfrom mrcnn.config import Config\nfrom mrcnn.model import MaskRCNN\n \n# define 81 classes that the coco model knows about\n\nclass_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n               'bus', 'train', 'truck', 'boat', 'traffic light',\n               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n               'teddy bear', 'hair drier', 'toothbrush']\n\n#class_names = ['car','Car'] \n# define the test configuration\nclass ImgConfig(Config):\n     NAME = \"images\"\n     GPU_COUNT = 1\n     IMAGES_PER_GPU = 1\n     NUM_CLASSES = 1 + 80\n\n# define the model\nrcnn = MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=ImgConfig())\n# load coco model weights\nrcnn.load_weights(COCO_WEIGHTS_PATH, by_name=True)\n# load image\nimg = load_img(image_path + test_df['image_ids'][29])\n#print(img)\nimg = img_to_array(img)\n# make prediction\nresults = rcnn.detect([img], verbose=0)\n# get dictionary for first prediction\nr = results[0]\n# show photo with bounding boxes, masks, class labels and scores\n#if (class_names == 'person'):\ndisplay_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","36881aaf":"# load image\nimg = load_img(image_path + test_df['image_ids'][15])\nimg = img_to_array(img)\n# make prediction\nresults = rcnn.detect([img], verbose=0)\n# get dictionary for first prediction\nr = results[0]\n# show photo with bounding boxes, masks, class labels and scores\n#if (class_names == 'car'):\ndisplay_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","668c5c0c":"# load image\nimg = load_img(image_path + test_df['image_ids'][19])\nimg = img_to_array(img)\n# make prediction\nresults = rcnn.detect([img], verbose=0)\n# get dictionary for first prediction\nr = results[0]\n# show photo with bounding boxes, masks, class labels and scores\n#if (class_names == 'car'):\ndisplay_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","c192270b":"# load image\nimg = load_img(image_path + test_df['image_ids'][100])\nimg = img_to_array(img)\n# make prediction\nresults = rcnn.detect([img], verbose=0)\n# get dictionary for first prediction\nr = results[0]\n# show photo with bounding boxes, masks, class labels and scores\n#if (class_names == 'car'):\ndisplay_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])","2b976cae":"Submissions are evaluated by computing mean Average Precision, with the mean taken over the 300 segmentable classes of the challenge. It follows the same spirit as the Object Detection evaluation, but takes into account mask-to-mask matching.","0a1acbf9":"### Lets load another image and check","cf8eca2c":"### We need to downgrade to TF 1.x in order to use MaskRCNN model","2c86608f":"# Open Images Instance Segmentation RVC 2020 edition\n## Outline segmentation masks of objects in images","72dc7195":"### Evaluation Metric","2af0b04a":"### Lets try One more gray image","b583a82f":"[Acknowledgement : MaskRCNN](https:\/\/github.com\/matterport\/Mask_RCNN)","0dfe4427":"![image.png](attachment:image.png)"}}