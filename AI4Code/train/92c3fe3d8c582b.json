{"cell_type":{"f58426da":"code","b776b921":"code","27fac57f":"code","95819c1d":"code","802af86f":"code","6604bde1":"code","9d7798ed":"code","822f44e9":"code","19a6f637":"code","79c8064f":"code","68dde931":"code","8f3fa2e5":"code","c8105a35":"code","4df7a831":"markdown","f1e978ae":"markdown","c65360c3":"markdown","bc4fc0d4":"markdown","77c1193d":"markdown","9d0172ff":"markdown","39fbd643":"markdown","5dcc9380":"markdown","89bf712e":"markdown","67bf1702":"markdown","22f7b89f":"markdown","1cb96aab":"markdown","6c354fed":"markdown","be08b429":"markdown","e78cf952":"markdown"},"source":{"f58426da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd \ntrain = pd.read_csv('..\/input\/learn-together\/train.csv')\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')","b776b921":"train.isnull().sum()","27fac57f":"train.head()","95819c1d":"train.info()","802af86f":"#no of unique values in each feature\nfor column in list(train.columns):\n    print (\"{0:25} {1}\".format(column, train[column].nunique()))","6604bde1":"#  droping not so useful training columns \ndropable_attributes = ['Id','Soil_Type7','Soil_Type15','Cover_Type']\nX = train.drop((dropable_attributes), axis =1)\ny = train['Cover_Type']\n\n# creating test-train set  \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, random_state=42, test_size=.20)\n ","9d7798ed":"from sklearn.ensemble import RandomForestClassifier\n# define\nrf = RandomForestClassifier()\n# train\nrf.fit(X_train,y_train)\n","822f44e9":"from sklearn.model_selection import cross_val_score\naccuracy = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\nacc = accuracy.mean()\nacc","19a6f637":"#### random search cv \n# Note: this code block will take time  to execute\nfrom sklearn.model_selection import RandomizedSearchCV\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n \nparams = {\n        \"n_estimators\": [200, 400, 600   ],\n        \"criterion\" : [\"entropy\", \"gini\"],\n        \"max_depth\" : [  20, 40, 60],\n        \"max_features\" : [ .30, .50 , .70 ],    \n        \"bootstrap\" : [True, False]\n           }\n\nrs = RandomizedSearchCV(rf, params, cv=3, scoring='accuracy',verbose=10)\nrs.fit(X_train, y_train) \n","79c8064f":"rs.best_params_","68dde931":"rf_rs = RandomForestClassifier(n_estimators= 400,max_features =0.3,\n                               max_depth =40,criterion ='entropy', bootstrap= False )\nrf_rs.fit(X_train,y_train)\naccuracy = cross_val_score(rf_rs , X, y, cv=5, scoring='accuracy')\nacc = accuracy.mean()\nacc","8f3fa2e5":"def create_submission_file( predictions, name):\n    submission = pd.DataFrame()\n    submission['ID'] = test['Id']     \n    submission['Cover_Type'] = predictions\n    submission.to_csv( name+'.csv',index=False, header= True)","c8105a35":"testcopy = test.drop((['Id','Soil_Type7','Soil_Type15']), axis =1)\npredictions = rf_rs.predict(testcopy) \ncreate_submission_file( predictions, 'out')","4df7a831":"Data set  features ('Wilderness_Area' & 'Soil_Type') are already one hot encoded ","f1e978ae":"Features 'Soil_Type7' and 'Soil_Type15' has only single value hence will be dropped before modeling.\n","c65360c3":"### Randomized SearchCV","bc4fc0d4":"#### cross validation accuracy measure","77c1193d":"This is a very basic solution of forestCover problem using RandomForest and followed by hyperparameter tuning  using RandomSerachCV ","9d0172ff":"### Explore data","39fbd643":"Data set has no missing data","5dcc9380":"### Data Modeling","89bf712e":"Lets do cross validation accuracy measure for rs model","67bf1702":"After RandomizedSearch, model accuracy has improved from .75 to .801\nLets create submission file for leaderboard score","22f7b89f":"Lets do hyperparameter tuning using RandomSearchCV","1cb96aab":"#### Random Forest Classifier","6c354fed":"### Fetch Data","be08b429":"#### Train-test split ","e78cf952":"#### Prepare Submission file "}}