{"cell_type":{"a5e820a0":"code","90eb0046":"code","78ca371e":"code","8fb91568":"code","8f2db1a1":"code","6c790767":"code","a2d6a5fa":"code","f96fefd5":"code","af32c0ed":"code","29239d1a":"code","77370281":"code","1c124c56":"code","d4f8c4f8":"code","a106d756":"code","1a526413":"code","1568050d":"code","4738e21a":"code","94bb61ae":"code","c41c735b":"code","13a967d7":"code","590eb8c8":"code","051cd041":"markdown","c1f11c83":"markdown","9d837e66":"markdown","d90062c8":"markdown","abc9aad9":"markdown","01358691":"markdown","514afbff":"markdown","075c1ad9":"markdown","10f5f357":"markdown","c48b2e33":"markdown"},"source":{"a5e820a0":"import pickle\nimport os\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nimport plotly.express as px\nimport kerastuner as kt\nfrom kerastuner.tuners import RandomSearch\nfrom kerastuner import HyperModel\nfrom sklearn.model_selection import train_test_split","90eb0046":"os.makedirs('\/kaggle\/tmp\/', exist_ok=True)","78ca371e":"# This will tell us the columns we are predicting\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","8fb91568":"def parse_trial_state(trial):\n    state = trial.get_state()\n    out = {}\n    out['best_step'] = state['best_step']\n    out['trial_id'] = state['trial_id']\n    out['score'] = state['score']\n    out.update(state['hyperparameters']['values'])\n    \n    return out","8f2db1a1":"class HyperGRU(HyperModel):\n\n    def __init__(self, embed_size, seq_len=107, pred_len=68):\n        self.embed_size = embed_size\n        self.seq_len = seq_len\n        self.pred_len = pred_len\n\n    def MCRMSE(self, y_true, y_pred):\n        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\n    def gru_layer(self, hidden_dim, dropout):\n        return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True))\n    \n    def build(self, hp):\n        # Hyperparameters we will explore\n        lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n        dropout = hp.Choice('dropout', values=[0., 0.1, 0.25, 0.5])\n        embed_dim = hp.Int('embed_dim', min_value=50, max_value=150, step=25)\n        hidden_dim = hp.Int('hidden_dim', min_value=32, max_value=256, step=32)\n        n_layers = hp.Int('n_layers', 2, 3)\n        \n        inputs = L.Input(shape=(self.seq_len, 3))\n\n        embed = L.Embedding(input_dim=self.embed_size, output_dim=embed_dim)(inputs)\n        hidden = tf.reshape(\n            embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n        )\n        \n        for i in range(n_layers):\n            hidden = self.gru_layer(hidden_dim, dropout)(hidden)\n\n        # Since we are only making predictions on the first part of each sequence, we have\n        # to truncate it\n        truncated = hidden[:, :self.pred_len]\n\n        out = L.Dense(5, activation='linear')(truncated)\n\n        model = tf.keras.Model(inputs=inputs, outputs=out)\n\n        model.compile(tf.keras.optimizers.Adam(lr), loss=self.MCRMSE)\n\n        return model","6c790767":"def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","a2d6a5fa":"train = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsample_df = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')","f96fefd5":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","af32c0ed":"train_inputs = preprocess_inputs(train, token2int)\ntrain_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))","29239d1a":"# Is seed 34 a magic number? We shall find out\nx_train, x_val, y_train, y_val = train_test_split(\n    train_inputs, train_labels, test_size=.1, random_state=34\n)","77370281":"hypermodel = HyperGRU(embed_size=len(token2int))","1c124c56":"tuner = kt.tuners.RandomSearch(\n    hypermodel,\n    objective='val_loss',\n    max_trials=35,\n    executions_per_trial=3,\n    seed=2020,\n    directory='\/kaggle\/tmp\/',\n    project_name='open_vaccine'\n)\n\ntuner.search(\n    x_train, y_train,\n    batch_size=64,\n    epochs=100,\n    verbose=0,\n    validation_data=(x_val, y_val),\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=4),\n        tf.keras.callbacks.EarlyStopping(patience=8)\n    ]\n)","d4f8c4f8":"trials_df = pd.DataFrame([\n    parse_trial_state(t) for t in tuner.oracle.trials.values()\n])\n\ntrials_df.to_csv('trials_table.csv', index=False)\n\ntrials_df","a106d756":"best_hp = tuner.get_best_hyperparameters(1)[0]\nbest_hp.get_config()['values']","1a526413":"pickle.dump(best_hp, open('best_hp.pickle', 'wb'))\n\nbest_model = tuner.get_best_models(1)[0]\nbest_model.save('best_model.h5')","1568050d":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df, token2int)\nprivate_inputs = preprocess_inputs(private_df, token2int)","4738e21a":"# Caveat: The prediction format requires the output to be the same length as the input,\n# although it's not the case for the training data.\nmodel_short = HyperGRU(seq_len=107, pred_len=107, embed_size=len(token2int)).build(best_hp)\nmodel_long = HyperGRU(seq_len=130, pred_len=130, embed_size=len(token2int)).build(best_hp)\n\nmodel_short.load_weights('best_model.h5')\nmodel_long.load_weights('best_model.h5')","94bb61ae":"public_preds = model_short.predict(public_inputs)\nprivate_preds = model_long.predict(private_inputs)","c41c735b":"print(public_preds.shape, private_preds.shape)","13a967d7":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)","590eb8c8":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","051cd041":"## Build and train model","c1f11c83":"Unhide below to see all trials results:","9d837e66":"For each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e. $629 \\times 107, 5$ or $3005 \\times 130, 5$):","d90062c8":"The best hyperparameter is:","abc9aad9":"## Load and preprocess data","01358691":"Save model and best hyperparams","514afbff":"## Post-processing and submit","075c1ad9":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes.","10f5f357":"## Define helper functions and useful vars","c48b2e33":"## Predict on test set"}}