{"cell_type":{"9dcd682f":"code","d93b945b":"code","0effa678":"code","41cb9d65":"code","df9b12cd":"code","b948c081":"code","00231441":"code","6d40474c":"code","35847a3d":"code","0b2d9423":"code","c5728d46":"code","6c03c423":"code","9376e4a6":"code","ff35acd8":"code","59dbf651":"code","60d51d19":"code","1641ce96":"code","af9021c9":"code","c8046dfd":"code","f1141717":"code","4c4743b2":"code","05c19ca4":"code","e311ecd6":"code","14da1393":"code","cc9445e6":"code","a9a7b0a5":"code","6d60b171":"code","803646ad":"code","2fa7fca2":"code","bd0631bd":"code","60281e97":"code","7b971dda":"code","52350c90":"code","bc59c597":"code","619c3ffd":"code","3608f12f":"code","d0a54dd6":"code","b539e839":"code","7f104906":"code","813d277b":"code","9eaa5526":"code","4eb7944a":"code","fddcf6d1":"code","0fa08b02":"code","c1af1a2b":"code","0ca1b495":"code","f4cbd812":"code","8bbcc74e":"code","10633751":"code","3f02a481":"code","6ab0f8bb":"code","03c784d5":"code","95ae1f2d":"code","83b269a8":"code","c1dde699":"code","7b813311":"code","df0dc621":"code","30c5cb71":"code","1cc71d34":"code","62bff733":"code","67f28ff0":"code","e76c83fa":"code","129bcbde":"code","61e38a5f":"code","a5e56c96":"code","88c45991":"code","66d517ab":"code","8d17774c":"code","371dfb7c":"code","f9134f56":"code","b8fe9b58":"code","97513d50":"code","372eec6e":"code","37c9a1ca":"code","9ad792a8":"code","b3405868":"code","e63b454e":"code","c3e483a3":"code","de86088f":"code","70807294":"markdown","487b0595":"markdown","02f8a9f8":"markdown","9535ce76":"markdown","cebb93e5":"markdown","5a35be63":"markdown","17126b36":"markdown","ae5b8691":"markdown","67830375":"markdown","4578fc92":"markdown","fa8de663":"markdown","cd22cd67":"markdown","92b1b92d":"markdown","dbbdb8d2":"markdown","e33c0c6c":"markdown","8269a638":"markdown","22b533e1":"markdown","13bcd45e":"markdown","4ce1b9ad":"markdown","8b5407c6":"markdown"},"source":{"9dcd682f":"# Loading Libraries","d93b945b":"import pandas as pd # for data analysis\nimport numpy as np # for scientific calculation\nimport seaborn as sns # for statistical plotting\nimport datetime # for working with date fields\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline\nimport math # for mathematical calculation","0effa678":"import os\n#Reading NYC Taxi Trip given Data Set.\nimport os\nfor dirname, _, filenames in os.walk('kaggle\/input\/NYC_taxi_trip_train.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","41cb9d65":"#Reading NYC taxi trip given Data Set.\nnyc_taxi=pd.read_csv('\/kaggle\/input\/NYC_taxi_trip_train.csv') ","df9b12cd":"#Perform Pandas profiling to understand quick overview of columns\n\n#import pandas_profiling\n#report = pandas_profiling.ProfileReport(nyc_taxi)\n#covert profile report as html file\n#report.to_file(\"nyc_taxi.html\")","b948c081":"# Checking Null Values : We can See there are No Null Values \nnyc_taxi.isnull().sum()","00231441":"#Checking shape of data\n#Observation: It contains 1.4 million records approx. and 11 columns (10 features with 1 feature as a target variable)\nnyc_taxi.shape","6d40474c":"#Checking duplicates in the given dataset.\n#Observations: No duplicates exists as it's row count shows '0'.\ncheck_duplicates = nyc_taxi[nyc_taxi.duplicated()]\nprint(check_duplicates.shape)","35847a3d":"#Exploring data by using info() method. It doesn't contains any null values.\n#Observation: No null values exists.\nnyc_taxi.info()","0b2d9423":"# Verifying top 2 sample records of data.\n# Observation: The data consists of, vendor_id, pickup and dropoff datetime, longitude and latitude information, trip_duration\n# values plays major part in predicting the tripduration here.\nnyc_taxi.head(2)","c5728d46":"# Describe method is used to view some basic statistical details like percentile, mean, std etc. of a data frame of numeric values.\n#Observation: Due to huge dataset and the columns values has been given in the form of +\/- (e.g., longitude and Latitude)\n# it shows data in the form of exponentials.Moving ahead with EDA and visualization to understand data better.\nnyc_taxi.describe()","6c03c423":"# Distance  function to calculate distance between given longitude and latitude points.\n# Observation: This piece of code taken from blogs. When I thought how to get pickup point and drop point information\n# I found this code and I can able to calculate distance here. It's as been called as 'Haversine Formula'\nfrom math import radians, cos, sin, asin, sqrt\n\ndef distance(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians \n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n\n    # haversine formula \n    dlon = lon2 - lon1 \n    dlat = lat2 - lat1 \n    a = sin(dlat\/2)**2 + cos(lat1) * cos(lat2) * sin(dlon\/2)**2\n    c = 2 * asin(sqrt(a)) \n    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n    return c * r","9376e4a6":"#Calculate Trip Distance & Speed here.\n#Observation: Introduced New Columns Distance and Speed here.\n# Converted dropoff_datetime and pickup_datetime into datetime format datatype\nnyc_taxi['distance'] = nyc_taxi.apply(lambda x: distance(x['pickup_longitude'],x['pickup_latitude'],x['dropoff_longitude'],x['dropoff_latitude']), axis = 1)\nnyc_taxi['speed']= (nyc_taxi.distance\/(nyc_taxi.trip_duration\/3600))\nnyc_taxi['dropoff_datetime']= pd.to_datetime(nyc_taxi['dropoff_datetime']) \nnyc_taxi['pickup_datetime']= pd.to_datetime(nyc_taxi['pickup_datetime'])","ff35acd8":"#Verify the column list\nnyc_taxi.columns\n","59dbf651":"#Copied dataframe into another dataframe.\n# Observation: Using another dataframe for data visualization and keeping original copy for ML pipeline.\nnyc_taxi_visual = nyc_taxi.copy()","60d51d19":"#Verifying columns.\nnyc_taxi_visual.columns","1641ce96":"#Drop unused columns for data visualization\nnyc_taxi_visual = nyc_taxi_visual.drop(['pickup_datetime','dropoff_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','store_and_fwd_flag'],axis=1)\nnyc_taxi_visual.columns","af9021c9":"# Verifying datatype, count, null values by using info() method.\nnyc_taxi_visual.info()","c8046dfd":"#Converting distance and speed values into int datatype.\nnyc_taxi_visual['distance']=nyc_taxi_visual['distance'].apply(lambda x:int(x))\nnyc_taxi_visual['speed']=nyc_taxi_visual['speed'].apply(lambda x:int(x))","f1141717":"#Verifying the datatype for all columns\nnyc_taxi_visual.info()","4c4743b2":"# Seaborn scatter plot with regression line\n# Observation: We can see her we are having outliers when distance is >50 miles  and trip duration is >15000 seconds and\n# we can say most of the trip_duration >15000 seconds mostly related to long distance or due to traffic jam on odd days.\n# We can see regression line fits here when we remove outliers.\nsns.lmplot(x='trip_duration', y='distance', data=nyc_taxi_visual, aspect=2.0, scatter_kws={'alpha':0.8})","05c19ca4":"# Removing outliers for distance and trip_duration.\nnyc_taxi_visual_final=nyc_taxi_visual[nyc_taxi_visual['distance']<=600]\nnyc_taxi_visual_final=nyc_taxi_visual[nyc_taxi_visual['trip_duration']<=36000]\nnyc_taxi_visual_final.head(1)","e311ecd6":"# Distribution plot for trip_Duration.\n# Observation: Data is right skewed here and most of datapoints is having very short trip_durations.\n# Will apply scaling techniques before we train the model.\nsns.distplot(nyc_taxi_visual_final['trip_duration'],kde = False)","14da1393":"# Distribution plot for Passenger Count.\n# Observations: Most of the times, only single passenger has booked taxi. New york city most of the times, only one passenger\n# travels due to population density and business center. It makes sense here. Very few trips for > 3 passengers.\nsns.distplot(nyc_taxi_visual_final['passenger_count'],kde=False, bins=None)\nplt.title('Distribution of Passenger Count')\nplt.show()","cc9445e6":"#Verifying column details\nnyc_taxi_visual_final.columns","a9a7b0a5":"# Groupby function to calculate passenger_count who has taken trips from Vendors.\n#Observations: Vendor_id 1 is having more trips for passenger 1 and \n# for Vendor_id 2 is having good number trips for passenger 1 and when passenger_count> 3 when compare to vendor_id 1\nnyc_taxi_visual_final.groupby(by=['vendor_id','passenger_count'])['passenger_count'].count()","6d60b171":"#Box plot for passenger_count for both vendors.\n# Observation: Based on the given huge dataset it's clear that, we are having outliers for both vendors when passenger\n# count increases more than 2.\n# for vendor_id 1 we can see outliers when passenger_count is 0. might be because of empty trips or some other reasons.\nplt.figure(figsize=(15,5))\nsns.boxplot(x=\"vendor_id\", y=\"passenger_count\",data = nyc_taxi_visual_final)","803646ad":"#Box plot for trip_duration for both vendors.\n#Observation: We can see more outliders for both vendors when trip_duration is > 1000 seconds. It's a fact that\n# new_york is one of the costliest and expensive life style city and most of the passenger can book trips <10 minutes travel.\n# Might be these outliers trip_duration belongs to tourists.\nplt.figure(figsize=(15,5))\nsns.boxplot(x=\"vendor_id\", y=\"trip_duration\",data = nyc_taxi_visual_final)","2fa7fca2":"#np.max(nyc_taxi_visual_final['distance'])","bd0631bd":"# Plotly Scatter bubble chart used to visualize trip_duration and distance details vendor_id wise distribution.\n# Observation: Most of datapoints lies between distance<50 and trip_duration <15K\n# Vendor_id 1 is having outliers for distance > 100 miles.\n# Vendor_id 2 is having outliers for trip_duration > 15000 seconds.\nimport plotly.express as px\nfig=px.scatter(nyc_taxi_visual_final,\n                           x='trip_duration',\n                           y='distance',\n                           size='trip_duration',color='vendor_id'\n                           )\nfig.update_layout(title=\"Trip Duration details vendor_id wise distribution\")\nfig.show()","60281e97":"# Plotly Pie chart used to visualize Share of each vendor_id in the given data set.\n# Observation: Vendor_id 1 is having 46.5% and 2 is having 53.5% share in NYC Taxi Trips.\n# Vendor_id 2 is having more than 15% of share when we compare with Vendor_id 1 share contribution.\nimport plotly.graph_objects as go\ndf1=nyc_taxi_visual['vendor_id'].value_counts().reset_index()\nfig=go.Figure(data=[go.Pie(labels=df1['index'],\n                          values=df1['vendor_id'],\n                          hole=.4,\n                          title=\"Share of each Vendor\")])\nfig.update_layout(title=\"NYC_Taxi Vendor Details\")\nfig.show()","7b971dda":"# Plotly BAr chart used to visualize number of trips contributed by each vendor in the given data set.\n# Observation: Vendor_id 2 is having more number of trips when compare to vendor_id 1.\nsns.barplot(nyc_taxi_visual_final['vendor_id'].value_counts().index, nyc_taxi_visual_final['vendor_id'].value_counts().values, alpha=0.8, palette = sns.color_palette('RdBu'))","52350c90":"#Analyzing given datapoint based on distance travelled by passenger.  \n#Need to remove\nnyc_taxi.sort_values(by='distance',ascending=False).head(10)","bc59c597":"# Dropping unused columns\nnyc_taxi_final=nyc_taxi.drop(['vendor_id','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','store_and_fwd_flag'],axis=1)\n","619c3ffd":"# Creating new feature columns.\nnyc_taxi_final['pickup_min'] = nyc_taxi_final['pickup_datetime'].apply(lambda x : x.minute)\nnyc_taxi_final['pickup_hour'] = nyc_taxi_final['pickup_datetime'].apply(lambda x : x.hour)\nnyc_taxi_final['pickup_day'] = nyc_taxi_final['pickup_datetime'].apply(lambda x : x.day)\nnyc_taxi_final['pickup_month']= nyc_taxi_final['pickup_datetime'].apply(lambda x : int(x.month))\nnyc_taxi_final['pickup_weekday'] = nyc_taxi_final['pickup_datetime'].dt.day_name()\nnyc_taxi_final['pickup_month_name'] = nyc_taxi_final['pickup_datetime'].dt.month_name()\n\nnyc_taxi_final['drop_hour'] = nyc_taxi_final['dropoff_datetime'].apply(lambda x : x.hour)\nnyc_taxi_final['drop_month'] = nyc_taxi_final['dropoff_datetime'].apply(lambda x : int(x.month))\nnyc_taxi_final['drop_day'] = nyc_taxi_final['dropoff_datetime'].apply(lambda x : x.day)\nnyc_taxi_final['drop_min'] = nyc_taxi_final['dropoff_datetime'].apply(lambda x : x.minute)\n\n","3608f12f":"#Verifying newly created columns.\nnyc_taxi_final.columns","d0a54dd6":"## Removing all those records where speed is less than 1 and distance is 0\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[(nyc_taxi_final['speed']<1)&(nyc_taxi_final['distance']==0)]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","b539e839":"# Identified some of trips are not valid from the given dataset.\n# For e.g., Index 531 clearly says that pick up adn drop off date and time is having morethan 23 hours trip_duration\n# by covering distance only 3 miles which is not possible in realtime scenarios. Removing those outliers. Total 1416 records.\nnyc_taxi_final[(nyc_taxi_final['pickup_day']< nyc_taxi_final['drop_day'])& (nyc_taxi_final['trip_duration']> 10000) &(nyc_taxi_final['distance'] <5) & (nyc_taxi_final['pickup_hour']<23)]","7f104906":"# Dropping records for those whose pickup and drop timings are more and distance travel <3 miles. (Outliers.)\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[(nyc_taxi_final['pickup_day']< nyc_taxi_final['drop_day'])& (nyc_taxi_final['trip_duration']> 10000) &(nyc_taxi_final['distance'] <5) & (nyc_taxi_final['pickup_hour']<23)]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","813d277b":"# Droppring records where speed and distance is <1. (Outliers)\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[(nyc_taxi_final['speed']<1) & (nyc_taxi_final['distance']< 1) ]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","9eaa5526":"# Removing outliers identified based on trip_duration and distance.\nnyc_taxi_final[nyc_taxi_final['trip_duration']\/60 >10000][['trip_duration','distance']]\nprint(nyc_taxi_final.shape)\nnyc_taxi_final[nyc_taxi_final['trip_duration']\/60 >10000]['trip_duration']\nnyc_taxi_final.drop([978383,680594,355003],inplace=True)\nprint(nyc_taxi_final.shape)","4eb7944a":"# Removing outliers whose distance is less 200 meters. In real scenario, no-one will pick taxi for lesstance 200 meters. \nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[nyc_taxi_final['distance']< .2]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","fddcf6d1":"# Removing outliers those trips where passenger_count is 0.\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[nyc_taxi_final['passenger_count']==0]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","0fa08b02":"# Verifying whether given data set is having other than 2016 year or not. \n# Observation: It contains only 2016 year data.\nimport datetime as dt\nprint(nyc_taxi_final[nyc_taxi_final['dropoff_datetime'].dt.year>2016])\nprint(nyc_taxi_final[nyc_taxi_final['dropoff_datetime'].dt.year<2016])","c1af1a2b":"# Removing outliers where trip_duration <120 seconds. In real-time scenario passengers will take trip for more than 2 mins.\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[nyc_taxi_final['trip_duration']<120]\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","0ca1b495":"# Distribution plot to verify the speed of trip.\n# Observations: Most of trips is having speed < 40 miles\/per hour. It's valid in newyork city trips.\ndist_plot=nyc_taxi_final[nyc_taxi_final['speed']<100]['speed']\nsns.distplot(dist_plot,bins=10)","f4cbd812":"# Distribution plot to verify the speed of trip for complete dataset.\n# Observations: Most of the trips is having speed <50 miles\/per hour and removed outliers.\nprint(nyc_taxi_final.shape)\ndf=nyc_taxi_final[nyc_taxi_final['speed']>50]['speed']\nsns.distplot(df,bins=10)\nnyc_taxi_final.drop(df.index,inplace=True)\nprint(nyc_taxi_final.shape)","8bbcc74e":"#Verify column details.\nnyc_taxi_final.columns","10633751":"# Verifying the Day-Wise trip counts.\n#Observation: We are having less trips on sunday and monday here.\nprint(\"Day-wise pickup totals\")\nprint(nyc_taxi_final['pickup_weekday'].value_counts())\n","3f02a481":"# Countplot visualization for Day-wise trip counts.\n# Observations: Friday and Saturday is having more trips when compare to other days.\nsns.countplot(x='pickup_weekday',data=nyc_taxi_final)","6ab0f8bb":"# Histogram plot to visualize for hour-wise trips \n# Observations: Most ot trip counts is having between 5am to 23 pm and 0am(midnight) to 2am.\n\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n\nnyc_taxi_final['pickup_hour']=nyc_taxi_final['pickup_datetime'].dt.hour\nnyc_taxi_final.pickup_hour.hist(bins=24,ax=ax[0])\nax[0].set_title('Distribution of pickup hours')\n\nnyc_taxi_final['dropoff_hour']=nyc_taxi_final['dropoff_datetime'].dt.hour\nnyc_taxi_final.dropoff_hour.hist(bins=24,ax=ax[1])\nax[1].set_title('Distribution of dropoff hours')","03c784d5":"#Import Sklearn and models\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score, KFold\n","95ae1f2d":"#Verifying final dataframe columns\nnyc_taxi_final.columns","83b269a8":"# Due to huge dataset, training the model by applying datasampling technique. Random Sample taken 500000 records.\nnyc_taxi_final_sampling=nyc_taxi_final.sample(n=500000,replace=\"False\")","c1dde699":"#Verify the shape of data\nnyc_taxi_final_sampling.shape","7b813311":"# Dropping unused columns and copied required columns to the feature_columns to train the model.\n# Used to verify co-efficient values.\nfeature_columns=nyc_taxi_final_sampling.drop(['id','pickup_month_name','pickup_weekday','pickup_datetime','dropoff_datetime','trip_duration','passenger_count','speed'],axis=1)","df0dc621":"#Verifying whether feature_columns is having null values or not.\nnyc_taxi_final_sampling.distance=nyc_taxi_final_sampling.distance.astype(np.int64)\nnyc_taxi_final_sampling.info()","30c5cb71":"#Applying Standard Scaler\nX2=nyc_taxi_final_sampling.drop(['id','pickup_month_name','pickup_weekday','pickup_datetime','dropoff_datetime','trip_duration','passenger_count','speed'],axis=1)\nX1=preprocessing.scale(X2)\nX=pd.DataFrame(X1)\ny=nyc_taxi_final_sampling['trip_duration']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\nreg =linear_model.LinearRegression()\n\nreg.fit(X_train,y_train)\nprint(\"reg.intercept_=> %10.10f\" %(reg.intercept_))\nprint(list(zip(feature_columns, reg.coef_)))\ny_pred=reg.predict(X_test)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=reg.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(reg,X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())\n\n","1cc71d34":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nfrom sklearn.model_selection import RandomizedSearchCV ,cross_val_score, KFold\n\nX2=nyc_taxi_final_sampling.drop(['id','pickup_month_name','pickup_weekday','pickup_datetime','dropoff_datetime','trip_duration','passenger_count','speed'],axis=1)\nX1=preprocessing.scale(X2)\nX=pd.DataFrame(X1)\ny=nyc_taxi_final_sampling['trip_duration']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nmodel = xgb.XGBRegressor()\nmodel.fit(X_train,y_train)\nprint(model)\ny_pred = model.predict(data=X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n# Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=model.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(model,X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())\n","62bff733":"from sklearn.linear_model import Ridge\n\nX2=nyc_taxi_final_sampling.drop(['id','pickup_month_name','pickup_weekday','pickup_datetime','dropoff_datetime','trip_duration','passenger_count','speed'],axis=1)\nX1=preprocessing.scale(X2)\nX=pd.DataFrame(X1)\ny=nyc_taxi_final_sampling['trip_duration']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nridgeReg = Ridge(alpha=0.05, normalize=True)\nridgeReg.fit(X_train,y_train)\n\ny_pred = ridgeReg.predict(X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# NULL RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=ridgeReg.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(ridgeReg,X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","67f28ff0":"from sklearn.linear_model import RidgeCV\n## training the model\n\nX2=nyc_taxi_final_sampling.drop(['id','pickup_month_name','pickup_weekday','pickup_datetime','dropoff_datetime','trip_duration','passenger_count','speed'],axis=1)\nX1=preprocessing.scale(X2)\nX=pd.DataFrame(X1)\ny=nyc_taxi_final_sampling['trip_duration']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nridgeRegCV = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\nridgeRegCV.fit(X_train,y_train)\n\n\ny_pred = ridgeRegCV.predict(X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=ridgeRegCV.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(ridgeRegCV,X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","e76c83fa":"#Metrics Overview\ndf = {'Model_Before_PCA':['Linear_Reg', 'XGB', 'Ridge','RidgeCV'],\n'RMSE': ['875', '1249', '1605','876' ],\n'NULL_RMSE': ['1701','1701','1701','1701'],\n'Max_error': ['66971','84155','85443','67179'],\n'Min_error': ['-80844','-52886','-4015','-78683'],\n'Score':['72','44','11','72']}\nprint(\"Metrics Overview Before_PCA\")\ndataframe = pd.DataFrame(df, columns=['Model','RMSE', 'NULL_RMSE', 'Max_error', 'Min_error','Score'])\ndataframe","129bcbde":"#Verify the shape of data\nnyc_taxi_final_sampling.shape","61e38a5f":"#Aligning data for PCA.\nnyc_taxi_final_sampling.columns\nnyc_taxi_pca=nyc_taxi_final_sampling.copy()\nnyc_taxi_pca.drop(['id','pickup_weekday', 'pickup_month_name','pickup_datetime','dropoff_datetime','speed'],axis=1,inplace=True)","a5e56c96":"# seperate target variable for PCA.\ntarget = nyc_taxi_pca['trip_duration']","88c45991":"from sklearn import datasets\nfrom sklearn.decomposition import PCA","66d517ab":"# PCA\n# normalize data\nnyc_taxi_pca_norm = (nyc_taxi_pca - nyc_taxi_pca.mean()) \/ nyc_taxi_pca.std()\n\npca = PCA(n_components=12) # 12 features\npca.fit_transform(nyc_taxi_pca_norm.values)\nprint (pca.explained_variance_ratio_)\n#print (nyc_taxi_final.feature_names)\nprint (pca.explained_variance_)\nvariance_ratio_cum_sum=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\nprint(variance_ratio_cum_sum)\nprint (pca.components_)","8d17774c":"# Taken variance ratio of 7 PCA components at 93.6%.\npca.explained_variance_ratio_[:7].sum()","371dfb7c":"#Plot Elbow Curve\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variance')\nplt.annotate('7',xy=(7, .93))","f9134f56":"# consider first 7 components as they are explaining the 93% of variation in the data\nx_pca = PCA(n_components=7)\nnyc_taxi_pca_norm_final = x_pca.fit_transform(nyc_taxi_pca_norm)","b8fe9b58":"# correlation between the variables after transforming the data with PCA is 0\ncorrelation = pd.DataFrame(nyc_taxi_pca_norm_final).corr()\nsns.heatmap(correlation, vmax=1, square=True,cmap='viridis')\nplt.title('Correlation between different features')","97513d50":"X2=preprocessing.scale(nyc_taxi_pca_norm_final)\nX=pd.DataFrame(X2)\ny=target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\nreg =linear_model.LinearRegression()\n\nreg.fit(X_train,y_train)\nprint(\"reg.intercept_=> %10.10f\" %(reg.intercept_))\nprint(list(zip(feature_columns, reg.coef_)))\ny_pred=reg.predict(X_test)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# NULL RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=reg.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(reg,X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","372eec6e":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import RandomizedSearchCV ,cross_val_score, KFold\n\nX2=preprocessing.scale(nyc_taxi_pca_norm_final)\nX=pd.DataFrame(X2)\ny=target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nmodel = xgb.XGBRegressor()\nmodel.fit(X_train,y_train)\nprint(model)\ny_pred = model.predict(data=X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n    \n# Train RMSE\ny_pred_test=model.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(model, X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())\n\n","37c9a1ca":"X2=preprocessing.scale(nyc_taxi_pca_norm_final)\nX=pd.DataFrame(X2)\ny=target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nridgeReg = Ridge(alpha=0.05, normalize=True)\nridgeReg.fit(X_train,y_train)\n\ny_pred = ridgeReg.predict(X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n#Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=ridgeReg.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(ridgeReg, X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","9ad792a8":"X2=preprocessing.scale(nyc_taxi_pca_norm_final)\nX=pd.DataFrame(X2)\ny=target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nridgeRegCV = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\nridgeRegCV.fit(X_train,y_train)\n\n\ny_pred = ridgeRegCV.predict(X_test)\n\nrmse_val=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\n# Null RMSE\ny_null = np.zeros_like(y_test, dtype=int)\ny_null.fill(y_test.mean())\nN_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_null))\n# Metrics\nprint('Mean Absolute Error    :', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error     :', metrics.mean_squared_error(y_test, y_pred)) \nprint(\"Root Mean Squared Error = \",rmse_val)\nprint(\"Null RMSE = \",N_RMSE)\nif N_RMSE < rmse_val:print(\"Model is Not Doing Well Null RMSE Should be Greater\")\nelse:print(\"Model is Doing Well Null RMSE is Greater than RMSE\")\n# Train RMSE\ny_pred_test=ridgeRegCV.predict(X_train)\nrmse_val=np.sqrt(metrics.mean_squared_error(y_train, y_pred_test))\nprint('Train Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_test)))\n# Error Percentage\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,'Error':y_test -y_pred})\nprint(\"Maximum Error is :\",df.Error.max())\nprint(\"Minimum Error is :\",df.Error.min())\n# Score\nscores = cross_val_score(ridgeRegCV, X_train,y_train,cv=5)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","b3405868":"df = {'Model_Before_PCA':['Linear_Reg', 'XGB', 'Ridge','RidgeCV'],\n'RMSE': ['875', '1249', '1605','876' ],\n'NULL_RMSE': ['1701','1701','1701','1701'],\n'Max_error': ['66971','84155','85443','67179'],\n'Min_error': ['-80844','-52886','-4015','-78683'],\n'Score':['72','44','11','72']}\nprint(\"Metrics Overview Before_PCA\")\ndataframe = pd.DataFrame(df, columns=['Model_Before_PCA','RMSE', 'NULL_RMSE', 'Max_error', 'Min_error','Score'])\ndataframe","e63b454e":"df = {'Model_After_PCA':['Linear_Reg', 'XGB', 'Ridge','RidgeCV'],\n'RMSE': ['988', '108', '990','988' ],\n'NULL_RMSE': ['1701','1701','1701','1701'],\n'Max_error': ['42900','13824','44918','42900'],\n'Min_error': ['-12259','-9575','-11434','-12259'],\n'Score':['66','99','66','66']}\nprint(\"Metrics Overview After_PCA\")\ndataframe = pd.DataFrame(df, columns=['Model_After_PCA','RMSE', 'NULL_RMSE', 'Max_error', 'Min_error','Score'])\ndataframe\n","c3e483a3":"X2=preprocessing.scale(nyc_taxi_pca_norm_final)\nX=pd.DataFrame(X2)\ny=target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\n\nmodel = xgb.XGBRegressor()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(data=X_test)\n\nx_ax = range(len(y_test))\nplt.figure(figsize=(20,10))\nplt.scatter(x_ax, y_test, s=10, color=\"blue\", label=\"original\")\nplt.scatter(x_ax, y_pred, s=10, color=\"red\", label=\"predicted\")\nplt.legend()\nplt.show()","de86088f":"# From above plot you can see index:59891 is having trip_duration of 86391 acutal value(blue point) \n# predicated value (red point)\nnyc_taxi_final_sampling.sort_values(by='trip_duration',ascending=False).head(2)","70807294":"#### After comparing accuracy between model before and after PCA analysis. It has been decided that \n#### XGB Regressor is the best model which RMSE value: 108 when compare to other models and model accuracy is 99%. \n#### Accuracy Score is 99% with Max trip_duration error 13824,Min trip_duration error -9575 and RMSE 108","487b0595":"## Ridge Regression CV after PCA","02f8a9f8":"## Final Conclusion:","9535ce76":"## Ridge Regression after PCA","cebb93e5":"## Ridge Regression","5a35be63":"## Linear Regression after PCA","17126b36":"# Running Model with PCA ","ae5b8691":"# ML Pipeline for DataModeling","67830375":"## XG Boost Regressor","4578fc92":"# Data Cleaning and Data Understanding.","fa8de663":"# Exploratory Data Analysis (EDA) and Feature Engineering\n","cd22cd67":"## Linear Regression","92b1b92d":"## Data Visualization","dbbdb8d2":"## Data Sampling, Feature Engineering and Importance","e33c0c6c":"## Model Building, Evalutaion & Hyper parameter Tuning","8269a638":"## XGB Regressor after PCA","22b533e1":"# NYC Taxi Trip Duration Prediction\n## Domain: Transportation\n### Objective:Build a model that predicts the total trip duration of taxi trips in New York City.\n","13bcd45e":"#After PCA, there is no correlation among any components.","4ce1b9ad":"### Data Sampling Technique","8b5407c6":"## RidgeCV (Cross Validation -  Hyper Tuning parameter)"}}