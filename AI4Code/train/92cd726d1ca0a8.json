{"cell_type":{"dac9a69f":"code","dbbb4b31":"code","43fb09d8":"code","63f2855a":"code","abccb52f":"code","cfffffa1":"code","554cd439":"code","2cabe9c8":"code","bbf5d7ca":"code","c39006d3":"code","f944af5a":"code","3c07fe2e":"code","f7876564":"code","f01de5cb":"code","d466190a":"code","54fc82b3":"code","ba952b26":"code","127c221c":"code","8a5beba5":"code","20277a2f":"code","efede15a":"code","a69d4f95":"code","e4f40613":"code","923a7444":"code","3649eb52":"code","1a53b8d9":"code","350f400c":"code","960a61e5":"code","3b274ca1":"code","cf635346":"code","750c7f09":"code","e9badc8d":"markdown","c3ad409c":"markdown","7a1f487a":"markdown","7d001699":"markdown","47a08dfe":"markdown","eea9c422":"markdown","da7b9e6c":"markdown","fb394151":"markdown","b919f162":"markdown","76c7f315":"markdown","bb2c6d8a":"markdown","45421622":"markdown","fbddc404":"markdown","0ad290c1":"markdown","b87d864e":"markdown","b0a9b3a4":"markdown"},"source":{"dac9a69f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python","dbbb4b31":"# it ensures any edits to libraries you make are reloaded here automatically\n%reload_ext autoreload\n%autoreload 2 \n\n# any charts or images displayed are shown in this notebook.\n%matplotlib inline \n\n# avoid priniting warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n#display is equivalent to print but in case of data frame it makes prity print\nfrom IPython.display import display as disp ","43fb09d8":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","63f2855a":"!pwd # pwd (present working directory) our default current working directroy is \/kaggle\/working","abccb52f":"def list_files(dir_name='\/kaggle\/input'):\n    for dirname, _, filenames in os.walk(dir_name):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n        ","cfffffa1":"# list_files(\"\/kaggle\/input\/\")","554cd439":"train_csv_path = \"..\/input\/severstal-steel-defect-detection\/train.csv\"\nsample_submission_csv_path = \"..\/input\/severstal-steel-defect-detection\/sample_submission.csv\"\ntrain_image_path = \"..\/input\/severstal-steel-defect-detection\/train_images\/\"\ntest_image_path = \"..\/input\/severstal-steel-defect-detection\/test_images\/\"\n","2cabe9c8":"def explore_csv(path):\n    df = pd.read_csv(path)    \n    disp(df)\n    print(\"Path:\", path)\n    print(\"File Name:\", path.split(\"\/\")[-1])\n    print()\n    print(\"Shape:\", df.shape)\n    print()\n    print(df.info())\n    return df","bbf5d7ca":"explore_csv(train_csv_path)","c39006d3":"# Exploring train.csv file\n\ntrain_df = pd.read_csv(train_csv_path)\ndisp(train_df.head())\nprint(\"\\nTotal numberof Rows, Columns:\",train_df.shape)\n# Total numberof Rows in Training CSV\nprint(\"\\nTotal numberof Rows in Training CSV:\",train_df.shape[0])\nprint()\n\n# Number of images with defects\ndefect_count = train_df.EncodedPixels.count()\nprint(\"Number of images with defects (as per CSV):\",defect_count)\n# Number of images with NO defects\nno_defect_count = train_df.EncodedPixels.isna().sum()\nprint(\"Number of images with no defects(as per CSV):\",no_defect_count)\nprint(\"Note: For each image there ar 4 rows in CSV\\n\")\n\n# Number of jpegs in  training and test sets\ntrain_fns = os.listdir('\/kaggle\/input\/severstal-steel-defect-detection\/train_images')\nprint(\"The number of Training Images:\", len(train_fns))\ntest_fns = os.listdir('\/kaggle\/input\/severstal-steel-defect-detection\/test_images')\nprint(\"The number of Test Images:\", len(test_fns))\n\n# Number of images has at least one defect (max of 4 defects)\ndf = train_df.dropna()\ndf['ImageId'] = [x.split('_')[0] for x in df['ImageId_ClassId']]\nprint(\"\\nNumber of images has AT LEAST ONE DEFECT:\",len(df.ImageId.unique()))\nprint(\"Number of NO Defect images in training set:\", len(train_fns) - len(df.ImageId.unique()))\nprint()\nnote = \"\"\"Note: There is possible to have maximum of 4 defects \n    but in this case there are only 2 images has 3 Defects\n    \"\"\"\nprint(note)\n\n\n","f944af5a":"# ploting a pie chart to show the percentage of \"Defect vs No Defect\"\nlabels = 'Defect', 'No Defect'\nsizes = [defect_count, no_defect_count]\nexplode=(0.1,0)\nplt.pie(sizes, labels=labels, autopct='%1.2f%%', explode=explode, colors=['r','g'], shadow=True, startangle=0)\nplt.title('Defect vs No Defect')\nplt.show()","3c07fe2e":"# Number of images has at least one defect (max of 4 defects)\ndf = train_df.dropna()\ndf['ClassId'] = [x.split('_')[1] for x in df['ImageId_ClassId']]\ndf['ImageId'] = [x.split('_')[0] for x in df['ImageId_ClassId']]\n\nimages_per_class = df.groupby('ClassId')['ImageId'].count()\ndisp(images_per_class)","f7876564":"# plot number of images per defect class (4 classes)\nfig, ax = plt.subplots() \nplt.barh(\n    y=[1,2,3,4],\n    width=images_per_class, \n    color=['magenta', 'red', 'green', 'cyan'], \n    tick_label=[\"Defect Class1\",\"Defect Class2\",\"Defect Class3\",\"Defect Class4\"]    \n)\nfor y, v in enumerate(images_per_class, 1):\n    ax.text(1,y,v)\nplt.show()","f01de5cb":"# ploting a pie chart to show the percentage of \"Defect vs No Defect\"\nlabels = [\"Defect Class1\",\"Defect Class2\",\"Defect Class3\",\"Defect Class4\"]\nsizes = images_per_class\nplt.pie(sizes, labels=labels, autopct='%1.2f%%',  colors=['r','g','m','y'], shadow=True, startangle=0)\nplt.title('Defect Classes % wise')\nplt.show()","d466190a":"defect_classes_per_image = pd.DataFrame({ 'NoOfDefects': df.groupby('ImageId')['ClassId'].count()})\none_defect_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(1).index.values.tolist()\ntwo_defects_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(2).index.values.tolist()\nthree_defects_imgs = defect_classes_per_image.groupby(\"NoOfDefects\").get_group(3).index.values.tolist()\nno_of_defects = defect_classes_per_image.groupby(\"NoOfDefects\").size()\nprint(f\"Image with One defect: {no_of_defects[1]} \\nImage with Two defects: {no_of_defects[2]}\\nImage with Three defects: {no_of_defects[3]}\")","54fc82b3":"# plot number of defects in each images\nfig, ax = plt.subplots() \nplt.barh(\n    y=[1,2,3],\n    width=no_of_defects, \n    color=['magenta', 'red', 'green'],\n    tick_label=[\"1 Defect\",\"2 Defects\",\"3 Defects\"]    \n)\nfor y, v in enumerate(no_of_defects, 1):\n    ax.text(1,y,v)\nplt.show()","ba952b26":"# Note: it can display only 10 images in 2 cols\ndef display_images_in_two_cols(image_file_names):\n    nrows=(len(image_file_names)\/\/2)\n    fig, ax = plt.subplots( nrows=nrows, ncols=2, figsize=(22, 2*nrows))\n    ax = ax.flatten()\n    for i in range(len(image_file_names)):\n        img = plt.imread('\/kaggle\/input\/severstal-steel-defect-detection\/train_images\/'+image_file_names[i])\n        plt.tight_layout()\n        ax[i].axis(\"off\")\n        ax[i].imshow(img)\n\n# Note: it can display given images in 1 column        \ndef display_images(filenames):\n    for i in range(len(filenames)):\n        img = plt.imread('\/kaggle\/input\/severstal-steel-defect-detection\/train_images\/'+filenames[i])\n        plt.figure(figsize=[19,65])\n        plt.axis(\"off\")\n        plt.tight_layout()\n        plt.imshow(img)        ","127c221c":"\nfilenames = os.listdir('\/kaggle\/input\/severstal-steel-defect-detection\/train_images')\ndisplay_images_in_two_cols(filenames[0:12])","8a5beba5":"filenames = os.listdir('\/kaggle\/input\/severstal-steel-defect-detection\/train_images')\ndisplay_images(filenames[0:12])","20277a2f":"path = '..\/input\/severstal-steel-defect-detection\/'\ntrain = pd.read_csv(path + 'train.csv')\n\nimport numpy as np\n\n# Unstack the EncodedPixels and store into new Dataframe\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['D1'] = train['EncodedPixels'][0::4].values\ntrain2['D2'] = train['EncodedPixels'][1::4].values\ntrain2['D3'] = train['EncodedPixels'][2::4].values\ntrain2['D4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1)\ndisp(train2.head())\nprint()\nprint(\"Shape:\",train2.shape)\nprint(\"\\nNumber of Defects for each Defect Class:\")\nprint(np.sum(train2.iloc[:,1:]!='',axis=0))\nZeroDefectsImages = train2[train2['count']==0].ImageId.values\ndisp(\"Zero Defect Images:\")\ndisp(ZeroDefectsImages.shape)\ndisp(ZeroDefectsImages)","efede15a":"import numpy as np \n# reading in the training set\ndata = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\n\n# isolating the file name and class\ndata['ImageId'], data['ClassId'] = data.ImageId_ClassId.str.split('_').str\ndata['ClassId'] = data['ClassId'].astype(np.uint8)\n\n# keep only the images with EncodedPixels\nsquashed = data.dropna(subset=['EncodedPixels'], axis='rows')\ndisp( squashed)\nprint(squashed.shape)\n\n# squash multiple rows per image into a list\nsquashed = squashed[['ImageId', 'EncodedPixels', 'ClassId']].groupby('ImageId', as_index=False).agg(list) \n\n# count the amount of class labels per image\nsquashed['Distinct Defect Types'] = squashed.ClassId.apply(lambda x: len(x))\n\n# select images has more than 2 defects\ndisp(squashed[squashed['Distinct Defect Types']> 2])\n\n# display squashed sample\ndisp(squashed.sample(10))\nprint(f\"Number of images with at least One defect: {squashed.shape[0]}\")\nprint(squashed.shape)\n\n# Discovering Zero Defect image file names\ntempdf = data[['ImageId', 'EncodedPixels', 'ClassId']].fillna(\"RAM\")\ntempdf = tempdf[['ImageId', 'EncodedPixels', 'ClassId']].groupby('ImageId', as_index=False).agg(list)\ntempdf['all_nan'] = tempdf.EncodedPixels.apply(lambda x: x.count(\"RAM\") )\nZeroDefectsImages=tempdf[tempdf[\"all_nan\"]==4].ImageId.values\nprint(f\"Number of images with Zero defect: {ZeroDefectsImages.shape[0]}\")\ndisp(ZeroDefectsImages.shape)\ndisp(ZeroDefectsImages)","a69d4f95":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# import torch.backends.cudnn as cudnn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensor\nimport cv2","e4f40613":"path = '..\/input\/severstal-steel-defect-detection\/train_images\/'\n#path = '..\/input\/severstal-steel-defect-detection\/test_images\/'\nsample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\/\"\npalet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n","923a7444":"np.random.seed(123)\nudf = pd.DataFrame()\nudf['ImageId'] = squashed[squashed['Distinct Defect Types'] == 1].ImageId\nudf['ClassId'] = squashed[squashed['Distinct Defect Types'] == 1].ClassId\nudf.ClassId = udf.ClassId.apply(lambda x: x[0])\n\n# Converting ClassId (1,2,3,4) into Labels (0,1,2,3)\nudf1 = udf[udf.ClassId == 1]\nudf1[\"ClassId\"] = 0\nudf2 = udf[udf.ClassId == 2]\nudf2[\"ClassId\"] = 1\nudf3 = udf[udf.ClassId == 3]\nudf3[\"ClassId\"] = 2\nudf4 = udf[udf.ClassId == 4]\nudf4[\"ClassId\"] = 3\nprint(\"Single Defect Count:\")\nprint(\"Class1:{}, Class2:{}, Class3:{}, Class4:{}\"\n      .format( len(udf1), len(udf2), len(udf3), len(udf4)))\n\n\n# (Solving Class Imbalance problem)\n# Since Defect 2 type images are lesser than other defects, we are reusing the same images \n# udf2 = pd.concat([udf2,udf2,udf2])  \n\nsample_size = len(udf2)\nudf1 = udf1[0:sample_size]\nudf2 = udf2[0:sample_size]\nudf3 = udf3[0:sample_size]\nudf4 = udf4[0:sample_size]\n\nudf = pd.concat([udf1, udf2, udf3,  udf4 ])\nudf.reset_index(drop=True,inplace=True)\n\nprint()\nprint(\"Label Distribution\")\nprint(\"Total Rec:{}, Class1:{}, Class2:{}, Class3:{}, Class4:{}\" \n      .format( len(udf),\n               len(udf[udf[\"ClassId\"] == 0]),\n               len(udf[udf[\"ClassId\"] == 1]),\n               len(udf[udf[\"ClassId\"] == 2]), \n               len(udf[udf[\"ClassId\"] == 3])))\n\n\ntrain_df, val_df = train_test_split(udf, test_size=0.2, stratify=udf[\"ClassId\"], random_state=39)\nprint()\nprint(\"Train DF Shape:\",train_df.shape)\nprint(\"Val DF Shape:  \",val_df.shape)","3649eb52":"def mask2rle(img):\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle2mask(rle, imgshape=(256,1600)):\n    width = imgshape[0]\n    height= imgshape[1]\n    mask= np.zeros( width*height ).astype(np.uint8)    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1 \n    mask = mask.reshape(height,width)\n    return mask.T\n\n\ndef draw_mask(imageid, rle, classid):\n    masks = np.zeros((256,1600,4), dtype=np.uint8)\n    for r, c in zip(rle,classid):\n        index = c - 1\n        masks[:,:,index] = rle2mask(r) \n    return masks\n\n\ndef draw_contour(image, masks):\n    for i in range(4):\n        contours, hierarchy = cv2.findContours(masks[:,:,i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        image = cv2.drawContours(image, contours, -1, palet[i], 2)        \n    return image\n\ndef draw_plot(img, imageid, classid):\n    plt.figure(figsize=(20,5))\n    plt.axis(\"off\")\n    plt.title(imageid+ \" \"+str(classid))\n    plt.imshow(img)\n\n\ndef draw_OMG(imageids):\n    \"\"\" Drawing Original Image, Masked Image , Guided Image (Contour Image)\n    \"\"\"\n    for imageid in imageids:\n        try:\n            rle = squashed[squashed.ImageId == imageid].EncodedPixels.tolist()[0]\n            classid = squashed[squashed.ImageId == imageid].ClassId.tolist()[0]\n\n            img = cv2.imread(path+imageid)\n            draw_plot(img, imageid, classid)\n\n            masks=draw_mask(imageid,rle,classid)\n            img = draw_contour(img,masks)\n            draw_plot(img, imageid, classid)\n\n            \n            for i in range(4):\n                for j in range(3):\n                    img[masks[:,:,i]==1,j] = palet[i][j]                    \n            draw_plot(img, imageid, classid)\n            \n        except IndexError:\n            try:\n                img = plt.imread(path+imageid)\n                plt.imshow(img)\n            except FileNotFoundError:\n                print(\"File Not Found:\"+imageid)","1a53b8d9":"# Visualization Original, Mask, Guided(Contour) \n\nconditions = [\n    squashed['ClassId'].astype(str)=='[1]',\n    squashed['ClassId'].astype(str)=='[2]',\n    squashed['ClassId'].astype(str)=='[3]',\n    squashed['ClassId'].astype(str)=='[4]',\n    squashed['Distinct Defect Types']==2,\n    squashed['Distinct Defect Types']==3\n]\nsample_size = 2\nfor condition in conditions:\n    sample = squashed[condition].sample(sample_size) \n    draw_OMG(sample.ImageId.values)\n\ndraw_OMG([\"000f6bf48.jpg\", \"db4867ee8.jpg\", \"0025bde0c.jpg\"]) # 4, 1 2 3,  3 4\ndraw_OMG([\"a0906d0b3.jpg\"])","350f400c":"mean=(0.485, 0.456, 0.406)\nstd=(0.229, 0.224, 0.225)\nphase=\"train\"\n_tasks = Compose([\n    ToTensor(),\n    #Normalize(mean=mean, std=std),\n    ])\nclass TrainDataset(Dataset):\n    \n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        self.fnames = self.df[\"ImageId\"]\n        \n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx].ImageId \n        label = self.df.iloc[idx].ClassId\n        img = plt.imread(path+image_id)\n        img = self.transforms(image=img)               \n        return img,label,image_id\n    \n    def __len__(self):\n        return len(self.fnames)\n\n    \ntrain_dataset = TrainDataset(train_df, _tasks)\nval_dataset = TrainDataset(val_df, _tasks)\n\n\ntr_sampler = SubsetRandomSampler(range(len(train_df)))\nval_sampler = SubsetRandomSampler(range(len(val_df)))\n\n\nbatch_size = 16 \nnum_workers = 4\n\ntrain_loader = DataLoader(train_dataset,batch_size=batch_size,\n                          num_workers=num_workers,pin_memory=True,\n                          shuffle=False,sampler=tr_sampler)\nval_loader = DataLoader(val_dataset,batch_size=batch_size,\n                        num_workers=num_workers,pin_memory=True,\n                        shuffle=False,sampler=val_sampler) \n\nprint(\"Done\", np.random.randint(1000))","960a61e5":"def draw_loader_raw(k):\n    batch_size = len(k[1])\n    filenames = k[2]\n    print(filenames)\n    print(\"Image Shape:\",k[0][\"image\"].shape)\n    print(\"Label Shape:\",k[1].shape)\n    print(\"Batch Size:\",batch_size)\n    counter = np.zeros(4)\n    for i in range(batch_size):        \n        plt.figure(figsize=(20,5))\n        plt.title(\"Class Id: \"+str(k[1][i].item()+1)+ \"  \"+k[2][i])\n        plt.imshow(k[0][\"image\"][i].permute(1,2,0))        \n        counter[k[1][i].item()] += 1\n        draw_OMG([k[2][i]])\n    print(\"Defect Class distribution of {} images of type [1, 2, 3, 4] respectively:\".format(batch_size), counter)    \n\n\n\nk = next(iter(train_loader))    \ndraw_loader_raw(k)\n\n","3b274ca1":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        ## define the layers\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)       \n        self.pool = nn.MaxPool2d(2, 2)\n        self.linear1 = nn.Linear(256*1600, 512)\n        self.linear2 = nn.Linear(512, 24)\n        self.linear3 = nn.Linear(24, 4)\n        \n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x\n\nmodel = Model()\nprint(model)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","cf635346":"import torch.optim as optim\nloss_function = nn.CrossEntropyLoss()\n#optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay= 1e-6, momentum = 0.9, nesterov = True)\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 1e-6, betas=(0.9,0.999), eps=1e-08,amsgrad=False)\n## run for 30 Epochs \nfor epoch in range(50):\n    train_loss, val_loss = [], []\n    \n    ## training part \n    model.train()\n    for data, target, imageid in tqdm(train_loader,desc=\"Epoch {}: \".format(epoch+1)):\n        data, target = data[\"image\"].to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_function(output, target)  \n        loss.backward()\n        optimizer.step()        \n        train_loss.append(loss.item()) \n        \n    # evaluation part \n    model.eval()\n    for data, target, imageid in tqdm(val_loader, desc=\"Epoch {}: \".format(epoch+1)):\n        data, target =  data[\"image\"].to(device), target.to(device)\n        output = model(data)\n        loss = loss_function(output, target)\n        val_loss.append(loss.item())\n    \n    print(\"Train Loss:(max, min):\",max(train_loss), min(train_loss))\n    print(\"Val   Loss:(max, min):\",max(val_loss), min(val_loss))\n    \nprint(\"DONE\")","750c7f09":"## dataloader for validation dataset \nac = [0,0,0,0] # Actual Count\npc = [0,0,0,0] # Predicted Count\ncount = 0\nlc = 0\nfor data, labels, imageid in val_loader:\n    lc += 1\n    data, labels = data[\"image\"].to(device), labels.to(device)\n    output = model(data)    \n    _, preds_tensor = torch.max(output, 1)\n    actual = np.squeeze(labels.cpu().numpy()) + 1\n    preds = np.squeeze(preds_tensor.cpu().numpy()) + 1\n    for i, l in enumerate(actual):\n        ac[l-1] += 1\n        if l == preds[i]:\n            count = count+1\n            pc[l-1] += 1\n\nprint(\"Actual Count\")\nprint(\"     vs\")\nprint(\"Predicted Count\")\nprint(ac)\nprint(pc)\nprint()\nprint(\"****** PERCENTAGE ********\")\nprint((np.array(pc)\/np.array(ac))*100 \/\/1)\nprint()\n\nprint(\"******* OVER ALL *********\")\nprint(count\/len(val_df))\n","e9badc8d":"### Reshaping-1 Training Data Set\nImageId_ClassId, EncodedPixels --> ImageId,D1,D2,D3,D4,Count","c3ad409c":"### Exploring CSV file","7a1f487a":"### Dataframe (ImageId, ClassId)\n#### creating Dataframe based on defects types (minimum one defect type)","7d001699":"### Reshaping-2 Training Data Set","47a08dfe":"> ### Constants","eea9c422":"### Exploring Training Data (CSV File)","da7b9e6c":"### End-To-End Severstal Steel Defect Detection (EDA, Validation)","fb394151":"### Dataset & Data Loader ","b919f162":"### Utility Functions","76c7f315":"### Visualization - From data loader (batch by batch)","bb2c6d8a":"### Utility Functions \n#### (mask2rle, rle2mask, draw_mask, draw_contour, draw_plot, draw_OMG)","45421622":"### Importing all required packages and libraries ","fbddc404":"### Training","0ad290c1":"## Model Training\n","b87d864e":"### Custom Model (extended from nn.Module)","b0a9b3a4":"### Prediction on Validation Set"}}