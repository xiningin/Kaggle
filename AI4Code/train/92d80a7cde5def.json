{"cell_type":{"07efb189":"code","88758640":"code","ff899ba0":"code","85a1995b":"code","f33b4eba":"code","56c401d5":"code","aa4a7b3c":"code","50870063":"code","30d4a650":"code","988daa87":"code","f7f16432":"code","4cf0f153":"code","0c17e767":"code","25fe82e2":"code","bf9214d1":"code","745d2da3":"code","a71fb43c":"code","b282aacd":"code","089fdf8f":"code","b95250ac":"code","a58c681f":"code","6e2031ee":"code","93ff25c1":"code","9a4fa768":"code","05f6dcfb":"code","959c4f2c":"code","a6ffc8ed":"code","e9d15860":"markdown","c20994d1":"markdown"},"source":{"07efb189":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","88758640":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv\")","ff899ba0":"train_df","85a1995b":"Summary = pd.DataFrame(train_df.dtypes)\nSummary[\"isnull\"] = train_df.isnull().sum()\nSummary[\"max\"] = train_df.max()\nSummary[\"min\"] = train_df.min()\nSummary[\"isunique\"] = train_df.nunique()\nSummary[\"first\"] = train_df.iloc[0]\nSummary[\"second\"] = train_df.iloc[1]\nSummary[\"third\"] = train_df.iloc[2]\npd.set_option('display.max_rows', None)\nSummary","f33b4eba":"len(train_df.columns)","56c401d5":"len(test_df.columns)","aa4a7b3c":"target = train_df[\"loss\"]\ntrain_df = train_df.drop(\"loss\", axis = 1)","50870063":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.feature_selection import mutual_info_regression","30d4a650":"X_train, X_test, y_train, y_test = train_test_split(train_df, target, random_state = 123,test_size = 0.2)","988daa87":"sc = StandardScaler()\nsc.fit(X_train)\nX_train = sc.transform(X_train)\nX_test = sc.transform(X_test)","f7f16432":"from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(n_estimators=100, learning_rate=0.01)\nmodel.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)])\ny_pred = model.predict(X_test)","4cf0f153":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(y_pred, y_test)))\nprint(\"Mean Square Error: \" + str(np.sqrt(mean_squared_error(y_pred, y_test))))\n# print(np.sqrt(4))","0c17e767":"model1 = LinearRegression()\nmodel1.fit(X_train, y_train)\ny_pred1 = model1.predict(X_test)","25fe82e2":"print(\"Mean square Error: \" + str(np.sqrt(mean_squared_error(y_pred1, y_test))))","bf9214d1":"# y_fin = y_pred + y_pred1\ny_fin = y_pred1","745d2da3":"y_fin = y_fin.reshape(-1,1)","a71fb43c":"y_pred1 = model1.predict(test_df)\n# y_pred = model.predict(test_df)","b282aacd":"# y_fin = y_pred + y_pred1\ny_fin = y_pred1\nlen(y_fin)","089fdf8f":"sub = y_fin.reshape(-1,1)","b95250ac":"sub.shape","a58c681f":"fin= [round(val[0]) for val in sub]","6e2031ee":"submission_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")","93ff25c1":"submission_df.columns","9a4fa768":"submission_df.shape","05f6dcfb":"len(fin)","959c4f2c":"submission_df[\"loss\"] = fin","a6ffc8ed":"submission_df.to_csv('submission.csv', index=False)","e9d15860":"It is a very first attempt to see how it does on the leaderboard. A very basic model is used, a combination of XGRegressor and LinearRegression and then the average of predictions with a round off is used as a final result.\n\n### Do let me know how can I improve. Your feedback can really help so please do not refrain to suggest.","c20994d1":"As we can see from above summary that there are no null values in the train dataset and all values are either integer or float so no worries there as well. We can see that mostly all columns does have some negative values and the range is not very wide for any of the column. The target feature has the max value of 43 and min value of 0, that is it does not contain any negative value. \n\nThere are total 102 columns in the train dataset and 250k rows in it. The first column of both test and train dataset are just id columns and they do not really tell anything much."}}