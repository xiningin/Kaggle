{"cell_type":{"79351666":"code","78a29123":"code","7e109ba1":"code","c3337b29":"code","9b84eee8":"code","0e0edd9a":"code","cfaa5c32":"code","d2df7250":"code","cda1765f":"code","d2cf162a":"code","ceb541a3":"code","c96ec2af":"code","0bf3e5cd":"code","915b6f0b":"code","8669200f":"code","83e2b61b":"code","4ee0af82":"code","e65f986d":"code","92543ba9":"code","adc1ea0e":"code","cfbdf7b9":"code","a6fe6a61":"code","3e6596aa":"code","897fe325":"code","2efba6ff":"code","8bfc6241":"code","a4e35ce9":"code","29110a67":"code","eb41f978":"code","a3800085":"code","8677f4e5":"code","51df9947":"markdown","95d26402":"markdown","b9e0063f":"markdown","2d26598d":"markdown","22969fc0":"markdown","a2476a54":"markdown"},"source":{"79351666":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.applications import imagenet_utils\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam,SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.datasets import cifar10\nfrom keras.metrics import categorical_crossentropy\nimport pandas as pd\nfrom keras.models import Model\nfrom keras import regularizers\nimport keras\nimport os\nfrom keras.layers import Input\nimport tensorflow as tf\nfrom keras.models import Sequential,load_model\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Dense,Activation,Flatten,MaxPool2D,Conv2D,Dropout\nfrom keras.layers.normalization import BatchNormalization\nimport keras.backend as K\nimport itertools\n%matplotlib inline","78a29123":"# Training parameters\nbatch_size = 32\nepochs = 120\nnum_classes = 10","7e109ba1":"# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","c3337b29":"# Normalize data.\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255","9b84eee8":"# Subtracting pixel mean improves accuracy\nx_train_mean = np.mean(x_train, axis=0)\nx_train -= x_train_mean\nx_test -= x_train_mean","0e0edd9a":"# Input image dimensions.\ninput_shape = x_train.shape[1:]\ninput_shape","cfaa5c32":"print('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)","d2df7250":"# Convert class vectors to binary class matrices.\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)","cda1765f":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 120:\n        lr *= 1e-2\n    return lr","d2cf162a":"model = load_model('..\/input\/reslatest\/resnet50.h5')\nmodel.summary()","ceb541a3":"model.load_weights('..\/input\/reslatest\/resnet50_w.hdf5')\n","c96ec2af":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","0bf3e5cd":"n = 3\ndepth = n * 6 + 2","915b6f0b":"def resnet(input_shape, depth, num_classes=10):\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) \/ 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model","8669200f":"datagen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.,\n    zoom_range=0.,\n    channel_shift_range=0.,\n    fill_mode='nearest',\n    cval=0.,\n    horizontal_flip=True,\n    vertical_flip=False,\n    rescale=None,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.0)\n    \ndatagen.fit(x_train)","83e2b61b":"import pickle\n\nf=open('..\/input\/reslatest\/resnet50_h (1).pckl','rb')\nhistory = pickle.load(f)\nf.close()","4ee0af82":"model.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=lr_schedule(0)),\n              metrics=['accuracy'])","e65f986d":"model.summary()","92543ba9":"# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'ResNet'\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)","adc1ea0e":"# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]","cfbdf7b9":"h=model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                    validation_data=(x_test, y_test),\n                    epochs=epochs, verbose=1, workers=4,\n                    callbacks=callbacks)","a6fe6a61":"model.save('resnet50.h5')","3e6596aa":"model.save_weights('resnet50_w.hdf5')","897fe325":"import pickle\n\nf=open('resnet50_h.pckl','wb')\npickle.dump(h.history,f)\nf.close()","2efba6ff":"import matplotlib.pyplot as plt\nepoch_nums = range(1, epochs+1)\ntraining_loss = history[\"loss\"]\nvalidation_loss = history[\"val_loss\"]\nplt.plot(epoch_nums , training_loss)\nplt.plot(epoch_nums , validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training','validation'], loc='upper right')\nplt.show()","8bfc6241":"import matplotlib.pyplot as plt\nepoch_nums = range(1, epochs+1)\ntraining_loss = history[\"accuracy\"]\nvalidation_loss = history[\"val_accuracy\"]\nplt.plot(epoch_nums , training_loss)\nplt.plot(epoch_nums , validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training','validation'], loc='upper right')\nplt.show()","a4e35ce9":"scores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","29110a67":"def testimage(result):\n    print(result) \n    if result[0][0]==1: \n        print(\"Airplane\") \n    elif result[0][1]==1: \n        print('Automobile') \n    elif result[0][2]==1: \n        print('Bird') \n    elif result[0][3]==1: \n        print('Cat') \n    elif result[0][4]==1: \n        print('Deer') \n    elif result[0][5]==1: \n        print('Dog') \n    elif result[0][6]==1: \n        print('Frog') \n    elif result[0][7]==1: \n        print('Horse') \n    elif result[0][8]==1: \n        print('Ship') \n    elif result[0][9]==1: \n        print('Truck') \n    else:\n        print('Error')","eb41f978":"from keras.preprocessing import image\n\ntest_image1 =image.load_img(\"..\/input\/Image\/dog1.jpg\",target_size =(32,32,3))\ntest_image =image.img_to_array(test_image1)\ntest_image =np.expand_dims(test_image, axis =0) \nresult = model.predict(test_image)\n#result = result.astype(int)\nplt.imshow(test_image1)\ntestimage(result)","a3800085":"y_pred_test = model.predict(x_test)\ny_pred_test_classes = np.argmax(y_pred_test, axis=1)\ny_pred_test_max_probas = np.max(y_pred_test, axis=1)","8677f4e5":"cols = 8\nrows = 2\nNUM_CLASSES = 10\n# load data\n(x_train2, y_train2), (x_test2, y_test2) = cifar10.load_data()\ncifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\nfig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\nfor i in range(cols):\n    for j in range(rows):\n        random_index = np.random.randint(0, len(y_test2))\n        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n        ax.grid('off')\n        ax.axis('off')\n        ax.imshow(x_test2[random_index, :])\n        pred_label =  cifar10_classes[y_pred_test_classes[random_index]]\n        pred_proba = y_pred_test_max_probas[random_index]\n        true_label = cifar10_classes[y_test2[random_index, 0]]\n        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n               pred_label, pred_proba, true_label\n        ))\nplt.show()\n ","51df9947":"# Train the Model","95d26402":"# Compile the Model","b9e0063f":"# Test the Model","2d26598d":"# Trained Model Score","22969fc0":"# Data Augmentation","a2476a54":"# Loss"}}