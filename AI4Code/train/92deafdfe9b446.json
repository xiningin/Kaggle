{"cell_type":{"2d77d004":"code","eacb33a8":"code","9a5a57c4":"code","58493018":"code","fe3d5f83":"code","521e798f":"code","5262fb2d":"code","58626251":"code","c37e7b7d":"code","62e66f69":"code","822bcc73":"code","117a30b3":"code","255f468d":"code","1761898b":"code","3fca7e2d":"code","6fa480f7":"code","e2bdcaa8":"code","624db398":"code","499af257":"code","dad5fab8":"code","b5d14fed":"code","98e647a7":"code","53f3499c":"code","7740c2eb":"code","5c774548":"code","8c7ecef8":"code","68dfae8d":"code","27c0f206":"code","dc73a7d4":"code","58fe994c":"code","5d95dec4":"code","60814c8f":"code","60a8985a":"code","2b91b7ff":"code","db02a55d":"code","86c4811f":"code","86fe2dcd":"code","9f4e0f5e":"code","301dd01f":"code","caeb2881":"code","525e8365":"code","6e39ab41":"code","9863df51":"code","61adaa69":"code","cb8f928e":"code","2e5037db":"code","8f663c54":"code","6829821a":"code","c987cc4e":"code","44780da2":"code","e97b78f4":"code","816b5255":"code","6a17858b":"code","f4c7b2cb":"code","483aafe8":"code","66285a70":"code","8596c31f":"code","77fb5acf":"code","485f4b40":"code","d8be96e2":"code","414247fc":"code","39dfa33d":"markdown","24243da9":"markdown","9a547749":"markdown","f16a25d8":"markdown","4b9a347a":"markdown","ef8f1be7":"markdown","9b8ead65":"markdown","e1453a6b":"markdown","2db2d256":"markdown","adfd8a05":"markdown","67af024c":"markdown","c58dcbe1":"markdown","4832cd5f":"markdown","33833de6":"markdown","bb16b26d":"markdown","7f328c82":"markdown","ede75e31":"markdown","0dc41aff":"markdown","fbd7b74f":"markdown","4e2b0ae5":"markdown","5a086730":"markdown","8a06e86f":"markdown","4a727668":"markdown","45af1eca":"markdown","a513f043":"markdown","aedd02da":"markdown","4cdbce87":"markdown","705c743e":"markdown","89b20ba0":"markdown","013691bb":"markdown","5692b212":"markdown","b5ef2ed2":"markdown","488ed410":"markdown","8bbac514":"markdown","c111d4be":"markdown","95cb43f0":"markdown","0b899162":"markdown","7cecc0e5":"markdown","e6e917e1":"markdown","acac3236":"markdown"},"source":{"2d77d004":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eacb33a8":"train_df=pd.read_csv('\/kaggle\/input\/loan-prediction-practice-av-competition\/train_csv.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/loan-prediction-practice-av-competition\/test.csv.csv')","9a5a57c4":"print(train_df.shape)\nprint(test_df.shape)","58493018":"train_df.head().T","fe3d5f83":"train_df.describe().T","521e798f":"train_df.info()","5262fb2d":"train_df.describe(include=['object'])","58626251":"train_df.isnull().sum(axis=0)","c37e7b7d":"test_df.isnull().sum()","62e66f69":"train_df.nunique()","822bcc73":"test_df.nunique()","117a30b3":"train_df['Property_Area'].value_counts()","255f468d":"target_map={\"Y\":1, \"N\": 0}\ndataset=[train_df]\nfor data in dataset:\n    data['Loan_Status']=data['Loan_Status'].map(target_map)","1761898b":"cat_cols=['Gender','Married','Dependents','Self_Employed','Credit_History']\nfor col in cat_cols:\n    train_df[col].fillna(train_df[col].mode()[0],inplace=True)\n    test_df[col].fillna(test_df[col].mode()[0],inplace=True)","3fca7e2d":"target=train_df['Loan_Status']\ntrain_df=train_df.drop('Loan_Status',1)","6fa480f7":"gender_map={\"Male\": 1,\"Female\": 0}\nmarry_map={\"Yes\":1,\"No\":0}\neducation_map={\"Graduate\": 1,\"Not Graduate\":0}\nproperty_map={\"Semiurban\":2,\"Urban\":1,\"Rural\":0}\ndataset=[train_df]\nfor data in dataset:\n    data['Gender']=data['Gender'].map(gender_map)\n    data['Married']=data['Married'].map(marry_map)\n    data['Self_Employed']=data['Self_Employed'].map(marry_map)\n    data['Education']=data['Education'].map(education_map)\n    data['Property_Area']=data['Property_Area'].map(property_map)\n#dependents contains numeric value except 3+, so we just need to replace 3+ with 3 and then  convert their type to numeric\ntrain_df = train_df.replace({'Dependents': r'3+'}, {'Dependents': 3}, regex=True)\ntrain_df['Dependents']=train_df['Dependents'].astype('float64')\n#test_df = train_df.replace({'Dependents': r'3+'}, {'Dependents': 3},regex=True)\n#test_df['Dependents']=test_df['Dependents'].astype('float64')\ntrain_df.info()","e2bdcaa8":"gender_map={\"Male\": 1,\"Female\": 0}\nmarry_map={\"Yes\":1,\"No\":0}\neducation_map={\"Graduate\": 1,\"Not Graduate\":0}\nproperty_map={\"Semiurban\":2,\"Urban\":1,\"Rural\":0}\ndataset=[test_df]\nfor data in dataset:\n    data['Gender']=data['Gender'].map(gender_map)\n    data['Married']=data['Married'].map(marry_map)\n    data['Self_Employed']=data['Self_Employed'].map(marry_map)\n    data['Education']=data['Education'].map(education_map)\n    data['Property_Area']=data['Property_Area'].map(property_map)\n#dependents contains numeric value except 3+, so we just need to replace 3+ with 3 and then  convert their type to numeric\ntest_df = test_df.replace({'Dependents': r'3+'}, {'Dependents': 3},regex=True)\ntest_df['Dependents']=test_df['Dependents'].astype('float64')\ntest_df.info()","624db398":"test_df.isnull().sum()","499af257":"train_df.isnull().sum()","dad5fab8":"train_df['Loan_Amount_Term'].value_counts()","b5d14fed":"train_df['LoanAmount'].value_counts()","98e647a7":"train_df['Loan_Amount_Term'].fillna(360,inplace=True)\ntrain_df['LoanAmount'].fillna(train_df['LoanAmount'].median(),inplace=True)\ntrain_df.isnull().sum()","53f3499c":"train_df.info()","7740c2eb":"test_df.isnull().sum()","5c774548":"test_df['Loan_Amount_Term'].value_counts()","8c7ecef8":"test_df['LoanAmount'].value_counts()","68dfae8d":"test_df['Loan_Amount_Term'].fillna(360,inplace=True)\ntest_df['LoanAmount'].fillna(test_df['LoanAmount'].median(),inplace=True)\ntest_df.isnull().sum()","27c0f206":"test_df.info()","dc73a7d4":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inLine","58fe994c":"corr=train_df.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,cmap=colormap,xticklabels=corr.columns,yticklabels=corr.columns,annot=True)\nplt.show()","5d95dec4":"features=['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area']","60814c8f":"for fea in features:\n    print(train_df[fea].value_counts(sort=True))\n    print('---------------------------')","60a8985a":"fea_normalize=['Dependents','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Property_Area']","2b91b7ff":"for fea in fea_normalize:\n    train_df[fea]=(train_df[fea])\/(train_df[fea].max())","db02a55d":"train_df=train_df.drop('Loan_ID',1)","86c4811f":"from sklearn.model_selection import train_test_split","86fe2dcd":"X_train, X_val, y_train,y_val= train_test_split(train_df,target,test_size=0.30, random_state=np.random.randint(0,100))","9f4e0f5e":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()","301dd01f":"lr.fit(X_train,y_train)","caeb2881":"from sklearn import metrics","525e8365":"y_pred=lr.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","6e39ab41":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }","9863df51":"from sklearn.model_selection import GridSearchCV","61adaa69":"clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\nclf.fit(X_train,y_train)","cb8f928e":"y_pred_cv=clf.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred_cv)\nprint(acc)","2e5037db":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","8f663c54":"dt_base=DecisionTreeClassifier(max_depth=10,random_state=4)\ndt_base.fit(X_train,y_train)\n","6829821a":"from sklearn import metrics","c987cc4e":"y_pred=dt_base.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","44780da2":"dt_base.tree_.node_count","e97b78f4":"param_grid = {\n    'max_depth' : range(4,25),\n    'min_samples_leaf' : range(20,200,10),\n    'min_samples_split' : range(20,200,10),\n    'criterion' : ['gini','entropy'] \n}\nn_folds = 5","816b5255":"from sklearn.model_selection import GridSearchCV\n","6a17858b":"dt = DecisionTreeClassifier(random_state=np.random.randint(0,100))\ngrid = GridSearchCV(dt, param_grid, cv = n_folds, return_train_score=True,verbose=3)\n#grid.fit(X_train,y_train)","f4c7b2cb":"#grid.best_params_","483aafe8":"best_tree=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_leaf=20,min_samples_split=80,random_state=np.random.randint(0,100))\nbest_tree.fit(X_train,y_train)\ny_pred_best=best_tree.predict(X_val)","66285a70":"acc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","8596c31f":"test_df.info()","77fb5acf":"loanID=test_df['Loan_ID']\ntest_df=test_df.drop('Loan_ID',1)","485f4b40":"y_pred_t=lr.predict(test_df)\ny_final=[]\nfor y in y_pred_t:\n    if y==1:\n        y_final.append(\"Y\")\n    elif y==0:\n        y_final.append(\"N\")\ny_best=np.array(y_final)\ntype(y_best)\n      ","d8be96e2":"submission = pd.DataFrame({\n        \"Loan_ID\": loanID,\n        \"Loan_Status\": y_best\n    })\nsubmission.head(10)","414247fc":"submission.to_csv('submission_lr.csv', index=False)","39dfa33d":"We can see that training set has now no missing values and that all features are numeric type( except Loan_ID, which I think, for now, provides less information)<br>\nLet's complete our test data too.","24243da9":"We can see that the  following features are categorical:\n* Gender\n* Married\n* Dependents\n* Education\n* Self_Employed\n* Credit_History\n* Property_Area\n<br>and, <br>\n* Loan_Status","9a547749":"Only LoanAmount and Loan_Amount_Term is left, let's see them.","f16a25d8":"Let's see a correlation heatmap to visualize how are features correlated.","4b9a347a":"Now, all that is left is to convert the object categorical data to numeric form","ef8f1be7":"The features whose values are to be normalized are--","9b8ead65":"Our accuracy score is increased to 78.9%","e1453a6b":"The evaluation metric here is accuracy. So, let's check it's accuracy","2db2d256":"# Logitics Regression","adfd8a05":"We can see that not only train but also some data is missing in case of test datasets.","67af024c":"Let's train our best model and find it's accuracy.","c58dcbe1":"We are using GridSearchCV","4832cd5f":"<h1>Base Model<\/h1>","33833de6":"Let's predict the results for test file and store in csv file","bb16b26d":"Now, we have worked with our categorical data for both training and our test datasets","7f328c82":"Well, like training set, we need to do the same in case of test set.","ede75e31":"We can see that our base model is 72% accurate. ","0dc41aff":"Let's check if there are any missing values left for categorical features","fbd7b74f":"<h3>HyperParameter Tuning<\/h3>","4e2b0ae5":"Let's check their shapes.","5a086730":"From the data description, as well as on checking some data, we can see that under what categories they are divided. Let's first set the target variable which either 'Yes' or 'No' to 1 or 0. ","8a06e86f":"We have 3 files. Let's get them using pandas!","4a727668":"This code is for Loan Prediction practice problem organized by Analytics Vidhya. Competition link is:\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-loan-prediction-iii\/#ProblemStatement","45af1eca":"<h1>Data Preprocessing and EDA<\/h1>","a513f043":"Before fitting the model, let's normalize the features of LoanAmount and Loan_Amount_term","aedd02da":"Now, our test set is ready","4cdbce87":"<h2>Decision Tree Classifier<\/h2>","705c743e":"The most thing we can understand, even from the data description, that our target variable (Loan_Status) contains 2 possibility. Thus, it is a binary classification problem.","89b20ba0":"We can see that their are 13 features each containing 614 training examples and 614 test examples. Let's analyze them.","013691bb":"With Logistics Regression, the accuracy came to be 0.8108","5692b212":"Let's check if there are any missing data that is left","b5ef2ed2":"But we cannot say the same for LoanAmount data, so it's better to replace it's missing value with it's median.","488ed410":"We can see that features are not correlated to each other as much.","8bbac514":"Since, it is a binary classification problem, we would be solving using Decision Tree Classifier and Logisitics Regression. Let's see one by one. But before, let's split our training data to training and validation","c111d4be":"<h2>Categorical Data<\/h2>","95cb43f0":"Let's understand what we got from here one by one. <br>\n**Features** Gender(1),Married(2), Dependents(3), Education(4), Self_Employed(5), Property_Area(11), and Loan_Status(12) are object data type. <br>\n**Features** Gender(1), Married(2), Dependents(3), Self_Employed(5), LoanAmount(8), Loan_Amount_Term(9), Credit_History(10) have some of their data missing.<br>\nWe can also see that some of the features may be categorical.","0b899162":"We need to map the rest of the categorical variables but this time to both training and test dataset. But before \ndoing it, we should fill the missing values with the mode of the corresponding features.","7cecc0e5":"For non-numerical features,\n","e6e917e1":"Let's check the number of features containing NaN and number of unique values in each feature.","acac3236":"We can see that Loan_Amount_Term has majority of data containing value 360, so it would be better if we replace the missing values with 360(most frequent value)."}}