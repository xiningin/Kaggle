{"cell_type":{"c1f1fdf7":"code","d744649e":"code","67919147":"code","a0bced10":"code","8710545c":"code","9b3dda01":"code","30ad0fe1":"code","706d4712":"code","052cbfe7":"code","296e7d5b":"code","85e8df2a":"code","60eeb84b":"code","2f8c4704":"code","a258b4ee":"code","3e70dde3":"code","88f43428":"code","282af882":"code","4b07bd3b":"code","3e9ea812":"code","bca5ec01":"code","40314ef6":"markdown","79354d80":"markdown","51848930":"markdown","ab3fbf21":"markdown","36e7e6f4":"markdown","9472c96a":"markdown","a318e4c9":"markdown","966f82a9":"markdown","c60addf1":"markdown","bb2fcaa2":"markdown","a5618e2c":"markdown","46958d35":"markdown","11247353":"markdown","1e86c6d3":"markdown"},"source":{"c1f1fdf7":"#Import Library\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as skm\nimport copy\nimport sys\nimport cv2\nimport os","d744649e":"# Specify image size\nimg_size = 224\n\n# Making function for create data from path\ndef create_data(test_data=False):\n    \n    # Checking for test or train data conditions\n    \n    # Test data\n    if test_data:\n        cracked = '..\/input\/tire-texture-image-recognition\/Tire Textures\/testing_data\/cracked\/'\n        normal = '..\/input\/tire-texture-image-recognition\/Tire Textures\/testing_data\/normal\/'\n        \n    # Train data    \n    else:\n        cracked = '..\/input\/tire-texture-image-recognition\/Tire Textures\/training_data\/cracked\/'\n        normal = '..\/input\/tire-texture-image-recognition\/Tire Textures\/training_data\/normal\/'\n    \n    \n    # Labels for train and test\n    Labels = {cracked:0, normal:1}\n    \n    # Initializing list for storing train and test data\n    data = []\n    \n    # Initializing list for storing train and test label\n    labels = np.array([])\n    \n    # Looping through each label\n    for label in Labels:\n        \n        # Looping through cracked train data\n        for ls in os.listdir(label):\n            \n            # Join each ls element with file path\n            path = os.path.join(label, ls)\n\n            # Read images from path using cv2\n            img = cv2.imread(path, cv2.IMREAD_COLOR)\n            img = cv2.resize(img, (img_size, img_size))\n\n            # Adding data into data and labels list\n            data.append(np.array(img))\n            labels = np.append(labels, Labels[label])\n    \n    return np.array(data), labels\n        ","67919147":"# Create train and test data with label\ntrain_data, train_label = create_data(test_data=False)\ntest_data, test_label = create_data(test_data=True)\n\n# Look at data size\nprint(f\"Train data with shape {train_data.shape}\")\nprint(f\"Test data with shape {test_data.shape}\")","a0bced10":"# Randomly choose image index\nrandom_idx = np.random.randint(low=0, high=train_data.shape[0], size=10)\n\n# Initializing fig and ax variables\nfig, axs = plt.subplots(2, 5, figsize=(16,8))\n\n# Looping through each axs\nfor i, ax in enumerate(axs.flatten()):\n\n    # Showing image\n    ax.imshow(train_data[random_idx[i],:], cmap='gray')\n    ax.axis('off')\n    \n    # Set title for each image\n    if train_label[random_idx[i]] ==0:\n        ax.set_title(f\"Cracked tire\")\n    else:\n        ax.set_title(f\"Normal tire\")\nfig.tight_layout()\nplt.show()","8710545c":"# Normalize data\ntrain_data = train_data\/np.max(train_data)\ntest_data = test_data\/np.max(test_data)\nprint(np.max(train_data))\nprint(np.max(test_data))","9b3dda01":"#Adding noise to data\nnoise_traindata = copy.deepcopy(train_data)\nnoise_traindata = (noise_traindata + np.random.rand(*noise_traindata.shape)\/1.1)\nnoise_traindata = noise_traindata\/np.max(noise_traindata)","30ad0fe1":"train_data = np.concatenate((train_data, noise_traindata))\ntrain_label = np.concatenate((train_label, train_label))\nprint(train_data.shape)\nprint(train_label.shape)","706d4712":"# Randomly choose image index\nrandom_idx = np.random.randint(low=0, high=train_data.shape[0]\/2, size=10)\n\n# Initializing fig and ax variables\nfig, axs = plt.subplots(2, 5, figsize=(16,8))\n\n# Looping through each axs\nfor i, ax in enumerate(axs.flatten()):\n\n    # Showing image\n    ax.imshow(noise_traindata[random_idx[i],:], cmap='gray')\n    ax.axis('off')\n    \n    # Set title for each image\n    if train_label[random_idx[i]] ==0:\n        ax.set_title(f\"Cracked tire\")\n    else:\n        ax.set_title(f\"Normal tire\")\nfig.tight_layout()\nplt.show()","052cbfe7":"# Turn train data, test_data, train_label, test_data from numpy to torch\ntrain_dataT = torch.tensor(train_data.reshape(train_data.shape[0], 3, img_size, img_size)).float()\ntest_dataT = torch.tensor(test_data.reshape(test_data.shape[0], 3, img_size, img_size)).float()\n# Label has to be a vector\ntrain_labelT = torch.tensor(train_label.reshape(-1, 1)).float()\ntest_labelT = torch.tensor(test_label.reshape(-1, 1)).float()\n\nprint(f\"Train data with shape {train_dataT.shape}\")\nprint(f\"Test data with shape {test_dataT.shape}\")\n\nprint(f\"Train label with shape {train_labelT.shape}\")\nprint(f\"Test label with shape {test_labelT.shape}\")","296e7d5b":"# Split 50% to test and another to validation\ntest_data_split, val_data_split, test_label_split, val_label_split = train_test_split(\n                                                                    test_dataT, test_labelT, test_size=.5,\n                                                                    stratify=test_labelT)\n\n# Create TensorDataset Object\ntrain_tensor = torch.utils.data.TensorDataset(train_dataT, train_labelT)\ntest_tensor = torch.utils.data.TensorDataset(test_data_split, test_label_split)\nval_tensor = torch.utils.data.TensorDataset(val_data_split, val_label_split)\n\n# Create DataLoader Object\nbatch_size = 16\ntrain_loader = torch.utils.data.DataLoader(train_tensor, batch_size=batch_size, shuffle=True, drop_last=True)\ntest_loader = torch.utils.data.DataLoader(test_tensor, batch_size=test_tensor.tensors[0].shape[0])\nval_loader = torch.utils.data.DataLoader(val_tensor, batch_size=batch_size, shuffle=True)","85e8df2a":"# Inspecting batches\nprint(f\"Train batch size {len(train_loader)}\")\nprint(f\"Test batch size {len(test_loader)}\")\nprint(f\"Val batch size {len(val_loader)}\")","60eeb84b":"# Create function for create my CNN models, optimizer, Loss function\n\ndef create_model(printsize=False):\n    \n    # CNN model class\n    \n    class TireNet(nn.Module):\n        \n        def __init__(self, printsize):\n            \n            super().__init__()\n            \n            # For printing size for each layer\n            self.printsize = printsize\n            \n            # Model architecture (CNN Layers)\n            \n            self.con1 = nn.Conv2d(3, 32, 3, padding=1)\n            self.bn1 = nn.BatchNorm2d(32)\n            self.con2 = nn.Conv2d(32, 64, 5, stride=2)\n            self.bn2 = nn.BatchNorm2d(64)\n            self.con3 = nn.Conv2d(64, 128, 5, stride=2)\n            self.bn3 = nn.BatchNorm2d(128)\n#             self.con4 = nn.Conv2d(128, 128, 3)\n#             self.bn4 = nn.BatchNorm2d(128)\n\n            \n            # Maxpool \n            self.pool = nn.MaxPool2d(2)\n\n            # FFN layer\n            self.fnn1 = nn.Linear(4608, 50)\n            self.bnfnn = nn.BatchNorm1d(50)\n            self.dropfnn = nn.Dropout(0.5)\n            self.output = nn.Linear(50, 1)\n        \n        def forward(self, x):\n            \n            # CNN Layer 1\n            if self.printsize: print(f\"Input shape is {x.shape} before go to con1\")\n            x = F.relu(self.con1(x))\n            x = self.bn1(x)\n            x = self.pool(x)\n            \n            # CNN Layer 2 with maxpool\n            if self.printsize: print(f\"Input shape is {x.shape} after con1\")\n            x = F.relu(self.con2(x))\n            x = self.bn2(x)\n            x = self.pool(x)\n            \n            # CNN Layer 3\n            if self.printsize: print(f\"Input shape is {x.shape} after con2 and maxpool\")\n            x = F.relu(self.con3(x))\n            x = self.bn3(x)\n            x = self.pool(x)\n            \n#             # CNN Layer4 with maxpool\n#             if self.printsize: print(f\"Input shape is {x.shape} after con3\")\n#             x = F.relu(self.con4(x))\n#             x = self.bn4(x)\n#             x = self.pool(x)\n            \n            \n                \n            # Reshape x into vector\n            x = x.view(x.shape[0], -1)\n            if self.printsize: print(f\"x size after reshape is {x.shape}\")\n                \n            # FNN Layer 1 - 2\n            x = F.relu(self.fnn1(x))\n            x = self.bnfnn(x)\n\n            return self.output(x)\n    \n    # Create variables for model, loss function, optimizer\n    model = TireNet(printsize)\n    lossfunc = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    \n    return model, lossfunc, optimizer\n     ","2f8c4704":"# Test model with fake data and printsize for each CNN Layer\ntest_model= create_model(True)[0]\n\n#Print Architecture in TireNet model\nprint(test_model)\nprint('='*100)\n# Create some fake data\nsample = torch.randn((10, 3, img_size, img_size))\n\n# Use Noise model predict fake data\nypred = test_model(sample)\n\n# Look at its shape and some result\nprint('='*100)\nprint(ypred.shape)\nprint('='*100)\nprint(ypred)","a258b4ee":"# Checking for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","3e70dde3":"# Create train_model function\ndef train_model(model, lossfunc, optimizer, n_epochs, train_data, val_data):\n    \n    # For storing best perfrom model!\n    bestmodel = {'acc': 0, 'net': None}\n    \n    # Initializing variables for storing result\n    train_losses = []\n    val_losses = []\n    train_acc = []\n    val_acc = []\n    \n    # Use GPU for our model\n    model = model.to(device)\n    \n    # Training loop\n    for epochi in range(n_epochs):\n        \n        # Training mode\n        model.train()\n        \n        # Variable for storing result each batch\n        batch_train = []\n        batch_loss = []\n        \n        # Training in train_data\n        for X, y in train_data:\n            \n            # Push data into GPU\n            X = X.to(device)\n            y = y.to(device)\n            \n            # Predict model\n            pred = model(X)\n            # How many error in this prediction ? (compute for error)\n            loss = lossfunc(pred, y)\n            \n            # Set gradient to zero\n            optimizer.zero_grad()\n            # Compute Loss\n            loss.backward()\n            # Do back prop\n            optimizer.step()\n            \n            # Storing loss this batch into batch_loss\n            batch_loss.append(loss.item())\n            \n            # move pred, y to CPU\n            pred = pred.cpu()\n            y = y.cpu()\n            \n            # Computing accuracy and storing result\n            matches = ((pred>0)==y).float()\n            batch_train.append(100*torch.mean(matches).item())\n        \n        # Compute average of batch_train and batch_loss\n        train_acc.append(np.mean(batch_train))\n        train_losses.append(np.mean(batch_loss))\n            \n        # Using eval mode\n        model.eval()\n        \n        batch_val = []\n        batch_val_loss = []\n        # Testing in validation_data to avoid overfitting\n        for X, y in val_data:\n        \n            # Push data into GPU\n            X = X.to(device)\n            y = y.to(device)\n\n            # Using torch.no_grad() to switch off gradient computation\n            with torch.no_grad():\n                # Predict model\n                pred = model(X)\n\n            loss = lossfunc(pred, y)\n            # Store test loss\n            batch_val_loss.append(loss.item())\n\n            # move pred to CPU\n            pred = pred.cpu()\n            y = y.cpu()\n\n            matches = ((pred>0)==y).float()\n            batch_val.append(100*torch.mean(matches).item())\n        \n        val_acc.append(np.mean(batch_val))\n        val_losses.append(np.mean(batch_val_loss))\n        # Craete msg for printing result\n        msg = f\"Epoch {epochi+1} out of {n_epochs} with Train acc {train_acc[-1]:.2f}% Val acc {val_acc[-1]:.2f}% and Val Loss {val_losses[-1]:.8f}\"\n        sys.stdout.write('\\r'+msg)\n        \n        # Storing bestmodel\n        if val_acc[-1] > bestmodel['acc']:\n            \n            bestmodel['acc'] = val_acc[-1].item()\n            bestmodel['net'] = copy.deepcopy(model.state_dict())\n    \n    return train_acc, val_acc, train_losses, val_losses, model, bestmodel","88f43428":"# Create model instance\nmodel, lossfunc, optimizer = create_model()\n# Train with 150 epochs\nnumepochs = 50\ntrain_acc, val_acc, train_losses, val_losses, model, bestmodel = train_model(model, lossfunc, optimizer, numepochs, train_loader, val_loader)","282af882":"# Recreate new model\nmodel = create_model()[0]\n\n# Load best model\nmodel.load_state_dict(bestmodel['net'])","4b07bd3b":"# Testing set\ntest_set, test_set_label = next(iter(test_loader))\n\n# Testing model on test set\ntest_result = model(test_set).cpu()\ntest_acc = 100*(torch.mean(((test_result>0)==test_set_label).float()).item())\n\nprint(\"Test accuracy is {:.2f}%\".format(test_acc))","3e9ea812":"fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n\n# Plot loss\naxs[0].plot(train_losses, 'b^-', alpha=.8)\naxs[0].plot(val_losses, 'rs-', alpha=.7)\naxs[0].set_title('Loss')\naxs[0].set_xlabel(\"Epoch\")\naxs[0].set_ylabel(\"Loss\")\n\naxs[1].plot(train_acc, 'bo-', alpha=.8, label='Train')\naxs[1].plot(val_acc, 'rs-', alpha=.9, label='Val')\naxs[1].plot(numepochs, test_acc, 'kx', alpha=1, markersize=20, label='Test')\naxs[1].set_xlabel(\"Epoch\")\naxs[1].set_ylabel(\"Accuracy\")\naxs[1].set_title(\"Train and Validation Accuracy\")\naxs[1].legend()\nplt.show()","bca5ec01":"# Calculating Confusion matrix\ntest_confu = skm.confusion_matrix(test_loader.dataset.tensors[1], (test_result>0).float(), labels=[1, 0])\n\nfig, ax = plt.subplots(figsize=(12,8))\nsns.heatmap(test_confu, cmap='PuBu', annot=True, ax=ax)\nax.set_xticks([0.5,1.5])\nax.set_xticklabels(['normal', 'cracked'])\nax.set_yticks([0.5,1.5])\nax.set_yticklabels(['normal', 'cracked'])\nax.set_xlabel('Predicted by TireNet')\nax.set_ylabel('True labels')\nax.set_title('Confusion matrix :D')\nplt.show()\n\n# Just testing :D\n# tn, fp, fn, tp = test_confu.ravel()\n# print('True negative: {}'.format(tn))\n# print('False positive: {}'.format(fp))\n# print('False negative: {}'.format(fn))\n# print('True positive: {}'.format(tp))\nprint(\"It's look like our model think it is cracked tire even it is normal :C\")","40314ef6":"# Data augmentation and Normalize data","79354d80":"# Plotting training result","51848930":"# Create Model","ab3fbf21":"# Thank you so much for your time ! Have a good day :D","36e7e6f4":"# Look at images!!","9472c96a":"### Confusion matrix!","a318e4c9":"# Make DataLoader object and turn train_data, test_data into Torch","966f82a9":"# Import Library","c60addf1":"# Make function to train TireNet !!","bb2fcaa2":"## If you have any suggestion, you can comment in this post. Thanks again !","a5618e2c":"# Import images :V","46958d35":"# Using best model! :D","11247353":"## Welcome to my first notebook and first project\n## I feel really happy to publish this :D\n## and i hope you enjoy it too!\n### I hope this notebook gives you some new knowledge or anything\n### If it does please give it upvote\n#### Thank you so much! Enjoy :D ","1e86c6d3":"# Train da model !!"}}