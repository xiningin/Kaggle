{"cell_type":{"3a71fec0":"code","af0d295b":"code","53695782":"code","43bd282a":"code","6bf5e86c":"code","7e9c94d5":"code","b3bbc7fb":"code","1d65a041":"code","7bdd8aa2":"code","44467213":"code","5ff14552":"code","af874823":"code","df3621c1":"code","f8dfd472":"code","eb465694":"code","cbbee8db":"code","f4df61f4":"code","ee5e4dc1":"code","397e77e9":"code","b852ced9":"markdown","0d6e1c35":"markdown","55f7ec0f":"markdown","a1836b59":"markdown","4fc17e5e":"markdown","670e4974":"markdown","7696cd7e":"markdown","b923f74f":"markdown","c43ce82a":"markdown","a291be61":"markdown","d4bc39b9":"markdown"},"source":{"3a71fec0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af0d295b":"df_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","53695782":"df_train","43bd282a":"totalNull = df_train.isnull().sum().sort_values(ascending=False)\npercentage = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissingData = pd.concat([totalNull, percentage], axis=1, keys=['Total', 'Percent'])\nmissingData.head()","6bf5e86c":"X_cols = ['PassengerId',  'Pclass', 'Sex',  'SibSp','Parch',  'Embarked']\ny_cols = ['Survived']\n\n# Training Data \nX_df_train = df_train[X_cols]\ny_df_train = df_train[y_cols]\n\n# Drop the mssing rows \ndf_train = df_train.drop(df_train.loc[df_train['Embarked'].isnull()].index)\n\n# Testing Data\nX_df_test = df_test[X_cols]","7e9c94d5":"X_df_train","b3bbc7fb":"X_df_test","1d65a041":"y_df_train.isnull().sum().max()","7bdd8aa2":"X_df_test.isnull().sum().max()","44467213":"embarked_dummies = pd.get_dummies(X_df_train.Embarked, prefix='Embarked')\nX_df_train = pd.concat([X_df_train, embarked_dummies], axis=1)\nX_df_train = X_df_train.drop('Embarked',axis=1)","5ff14552":"embarked_dummies = pd.get_dummies(X_df_test.Embarked, prefix='Embarked')\nX_df_test = pd.concat([X_df_test, embarked_dummies], axis=1)\nX_df_test = X_df_test.drop('Embarked',axis=1)","af874823":"sex_dummies = pd.get_dummies(X_df_train.Sex, prefix='sex')\nX_df_train = pd.concat([X_df_train, sex_dummies], axis=1)\nX_df_train = X_df_train.drop('Sex',axis=1)\n","df3621c1":"sex_dummies = pd.get_dummies(X_df_test.Sex, prefix='sex')\nX_df_test = pd.concat([X_df_test, sex_dummies], axis=1)\nX_df_test = X_df_test.drop('Sex',axis=1)\n","f8dfd472":"X_df_train","eb465694":"X_df_test","cbbee8db":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_df_train,y_df_train)","f4df61f4":"pred = lin_reg.predict(X_df_test)","ee5e4dc1":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\nmodel.fit(X_df_train,y_df_train.values.ravel())\npredictions = model.predict(X_df_test)","397e77e9":"my_submission = pd.DataFrame({'PassengerId': list(X_df_test['PassengerId']), 'Survived': predictions.ravel()})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","b852ced9":"# Finally, Time to train the model","0d6e1c35":"Finally, our data looks like this now","55f7ec0f":"# Have a look on the training and testing data","a1836b59":"# Encoding the categorical columns for training the model","4fc17e5e":"## Estimation of missing data across different columns","670e4974":"## Liner Regression","7696cd7e":"# Making sure if there are no more missing data in out dataset","b923f74f":"# Load the Data","c43ce82a":"## Random Forest Classifier","a291be61":"This is how our data set looks like after encoding","d4bc39b9":"We can clear see that the columns \"Cabin\" and \"Age\" has the highest amount of data missing. It will be much better if we drop these columns. On the other hand we can see the column \"Embarked\" has only 2 rows of mssing data, so we just drop the missing rows and fit the model."}}