{"cell_type":{"178680b4":"code","67379839":"code","afd70467":"code","28a048cc":"code","74503746":"code","d29d9b6c":"code","b8e118fd":"code","c0731bb9":"code","69410d54":"code","92265a25":"code","b955ad29":"code","aeaf5e1e":"code","0f185ef1":"code","f47b13aa":"code","07c7e7e7":"code","8ff5ad11":"code","f2d84e8b":"code","07e15e5d":"code","f4fa8a7b":"code","8ec6144d":"code","ea8fe7ef":"code","3f1bee99":"code","cf008e98":"code","c0a53578":"code","03696bb1":"code","a1e7a239":"code","ad78bcb2":"code","5fb91018":"code","01bb4a3c":"code","57a21907":"markdown","46493089":"markdown","30148d9d":"markdown","ee9ff2dc":"markdown","cece3ecc":"markdown","4827a1b7":"markdown","48e473df":"markdown","bfa1260c":"markdown","817875c9":"markdown","43f0b98a":"markdown","7963dad7":"markdown","17830a8e":"markdown","ccbd0c59":"markdown","d800fcf6":"markdown","bfc0c63a":"markdown","48a0e328":"markdown","523e7a87":"markdown","eeac2c29":"markdown","497b2270":"markdown","05be66d0":"markdown"},"source":{"178680b4":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n","67379839":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved ","afd70467":"# loading data \ntrain_data = pd.read_csv(\"\/kaggle\/input\/minist\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/minist\/test.csv\")\n","28a048cc":"# display first five rows of train_data\ntrain_data.head()","74503746":"test_data.head()","d29d9b6c":"# checking shape of train_data\ntrain_data.shape # \n","b8e118fd":"# checking shape of test_data\n\ntest_data.shape","c0731bb9":"# check the data\ntrain_data.describe()","69410d54":"# check missing and null values\ntest_data.isnull().sum()","92265a25":"train_data.isnull().sum()","b955ad29":"Y_train = train_data[\"label\"]\n\n# Drop 'label' column\nX_train = train_data.drop(labels = [\"label\"],axis = 1) \n\n# free some space\ndel train_data \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","aeaf5e1e":"# Normalize the data\nX_train= X_train \/ 255.0\ntest_data= test_data \/ 255.0","0f185ef1":"# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\nX_train = X_train.values.reshape((-1,28,28,1))\ntest_data = test_data.values.reshape((-1,28,28,1))","f47b13aa":"test_data.shape","07c7e7e7":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)\n","8ff5ad11":"# Set the random seed\nrandom_seed = 2","f2d84e8b":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","07e15e5d":"# Some examples\nimport matplotlib.pyplot as plt\n\nh = plt.imshow(X_train[0][:,:,0])","f4fa8a7b":"k = plt.imshow(X_train[10][:,:,0])","8ec6144d":"from tensorflow.keras import layers\nfrom tensorflow.keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))","ea8fe7ef":"model.summary()","3f1bee99":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))","cf008e98":"model.summary()","c0a53578":"# Define the optimizer\n#optimizer = rmsprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","03696bb1":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","a1e7a239":"model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(X_train, Y_train, epochs=30, batch_size=40)","ad78bcb2":"test_loss, test_acc = model.evaluate(X_val, Y_val)\ntest_acc","5fb91018":"results = model.predict(test_data)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","01bb4a3c":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_submission5.csv\",index=False)","57a21907":"**Reshape**","46493089":"There is no missing values in the train and test dataset. So we can safely go ahead.","30148d9d":"**label_encoding**","ee9ff2dc":"**importing libraries**","cece3ecc":"Let\u2019s evaluate the model on the test data.","4827a1b7":"  i choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.","48e473df":"<a href=\"https:\/\/colab.research.google.com\/github\/komalaftab\/kaggle_Competitions\/blob\/master\/digit_recognizer.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","bfa1260c":"**load_Data**","817875c9":"**Check for null and missing values**","43f0b98a":"**Objective**\n","7963dad7":"We perform a grayscale normalization to reduce the effect of illumination's differences.\n\nMoreover the CNN converg faster on [0..1] data than on [0..255].","17830a8e":"**Learn computer vision fundamentals with the famous MNIST data**","ccbd0c59":"We\u2019ll do 10-way classification, using a final layer with 10 outputs and a softmax activation.\nHere\u2019s what the network looks like now","d800fcf6":"Let\u2019s display the architecture of the convnet so far.","bfc0c63a":"\n\n1.   data load\n2.   data preparation\n*   Normalization\n*   reshape\n*   label encoding\n*   spliting training and validation \n3.   introduction to convents\n4.   saving submission file\n\n\n\n\n\n\n\n\n\n","48a0e328":"**Normalization**","523e7a87":"**Adding a classifier on top of the convnet**","eeac2c29":"**Split training and valdiation set**","497b2270":"**submission file**","05be66d0":"**Introduction to convnets**"}}