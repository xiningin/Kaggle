{"cell_type":{"505e970d":"code","02e7d425":"code","8b7535fd":"code","28bc822e":"code","06edea7f":"code","66808793":"code","33b1963f":"code","53940465":"code","f4759b21":"code","13020794":"code","3cdaabc2":"code","027c4321":"code","77a9e9db":"code","c94f0f3c":"code","542f024e":"code","e2fc562a":"code","f44572c5":"code","274ab759":"code","eb4238bd":"code","d736719d":"markdown","1d878feb":"markdown","7422ab49":"markdown","ca0da437":"markdown","7ccdd0cc":"markdown","ee036ff8":"markdown","caa8e566":"markdown","6edc41a5":"markdown","b6373304":"markdown","4bf0505a":"markdown","61bae06f":"markdown","69e71785":"markdown","40cbf9a4":"markdown","44a1a5ab":"markdown","1eb13d8b":"markdown","13f04139":"markdown","55828842":"markdown"},"source":{"505e970d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","02e7d425":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython.display import clear_output\nfrom time import sleep\n\nfrom math import sin, cos, pi\nimport cv2\nfrom tqdm.notebook import tqdm","8b7535fd":"horizontal_flip = False\nrotation_augmentation = True\nbrightness_augmentation = True\nshift_augmentation = True\nrandom_noise_augmentation = True\n\ninclude_unclean_data = True    # Whether to include samples with missing keypoint values. Note that the missing values would however be filled using Pandas' 'ffill' later.\nsample_image_index = 20    # Index of sample train image used for visualizing various augmentations\n\nrotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\npixel_shifts = [12] ","28bc822e":"Train_Dir = '..\/input\/fpoints\/training.csv'\nTest_Dir = '..\/input\/fpoints\/test.csv'\nlookid_dir = '..\/input\/fpoints\/IdLookupTable.csv'\ntrain_data = pd.read_csv(Train_Dir)  \ntest_data = pd.read_csv(Test_Dir)\nlookid_data = pd.read_csv(lookid_dir)\nos.listdir('..\/input')","06edea7f":"train_data.info()","66808793":"'''\nthere are total 31 columns, of with 30 are cordinates of 15 points and 31st column have \nthe pixel in 1d array of size 96*96=9216 .\n28 columns have null values which is filled by its previous value using ffill command\n\nAfter that we reshape the image into 96*96 matrix\nand then we split the training set using train test split method with split ratio 1:10\n\nafter that 2d image is converted to image like rgb image so as to applt resnet model which is CNN model\n'''","33b1963f":"print(\"Length of train data: {}\".format(len(train_data)))\nprint(\"Number of Images with missing pixel values: {}\".format(len(train_data) - int(train_data.Image.apply(lambda x: len(x.split())).value_counts().values)))","53940465":"train_data.isnull().sum()","f4759b21":"clean_train_data = train_data.dropna()\nprint(\"clean_train_data shape: {}\".format(np.shape(clean_train_data)))\n\nunclean_train_data = train_data.fillna(method = 'ffill')\nprint(\"unclean_train_data shape: {}\\n\".format(np.shape(unclean_train_data)))","13020794":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2],c='red', marker='x', s=20)\n    plt.title(title)","3cdaabc2":"#Separate data into clean & unclean subsets\ndef load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)\/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images: {}\".format(np.shape(clean_train_images)))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints: {}\".format(np.shape(clean_train_keypoints)))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images: {}\".format(np.shape(test_images)))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, \"Sample image & keypoints\")\n\nif include_unclean_data:\n    unclean_train_images = load_images(unclean_train_data)\n    print(\"Shape of unclean_train_images: {}\".format(np.shape(unclean_train_images)))\n    unclean_train_keypoints = load_keypoints(unclean_train_data)\n    print(\"Shape of unclean_train_keypoints: {}\\n\".format(np.shape(unclean_train_keypoints)))\n    train_images = np.concatenate((train_images, unclean_train_images))\n    train_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","027c4321":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nif horizontal_flip:\n    flipped_train_images, flipped_train_keypoints = left_right_flip(clean_train_images, clean_train_keypoints)\n    print(\"Shape of flipped_train_images: {}\".format(np.shape(flipped_train_images)))\n    print(\"Shape of flipped_train_keypoints: {}\".format(np.shape(flipped_train_keypoints)))\n    train_images = np.concatenate((train_images, flipped_train_images))\n    train_keypoints = np.concatenate((train_keypoints, flipped_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(flipped_train_images[sample_image_index], flipped_train_keypoints[sample_image_index], axis, \"Horizontally Flipped\") ","77a9e9db":"def rotate_augmentation(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi\/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https:\/\/in.mathworks.com\/matlabcentral\/answers\/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nif rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(clean_train_images, clean_train_keypoints)\n    print(\"\\nShape of rotated_train_images: {}\".format(np.shape(rotated_train_images)))\n    print(\"Shape of rotated_train_keypoints: {}\\n\".format(np.shape(rotated_train_keypoints)))\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[sample_image_index], rotated_train_keypoints[sample_image_index], axis, \"Rotation Augmentation\")","c94f0f3c":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif brightness_augmentation:\n    altered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(clean_train_images, clean_train_keypoints)\n    print(f\"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}\")\n    print(f\"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}\")\n    train_images = np.concatenate((train_images, altered_brightness_train_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[sample_image_index], altered_brightness_train_keypoints[sample_image_index], axis, \"Increased Brightness\") \n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[len(altered_brightness_train_images)\/\/2+sample_image_index], altered_brightness_train_keypoints[len(altered_brightness_train_images)\/\/2+sample_image_index], axis, \"Decreased Brightness\") ","542f024e":"def shift_images(images, keypoints):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    # Augmenting over several pixel shift values\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(clean_train_images, clean_train_keypoints)\n    print(f\"Shape of shifted_train_images: {np.shape(shifted_train_images)}\")\n    print(f\"Shape of shifted_train_keypoints: {np.shape(shifted_train_keypoints)}\")\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[sample_image_index], shifted_train_keypoints[sample_image_index], axis, \"Shift Augmentation\")","e2fc562a":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif random_noise_augmentation:\n    noisy_train_images = add_noise(clean_train_images)\n    print(f\"Shape of noisy_train_images: {np.shape(noisy_train_images)}\")\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, clean_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, \"Random Noise Augmentation\")","f44572c5":"print(\"Shape of final train_images: {}\".format(np.shape(train_images)))\nprint(\"Shape of final train_keypoints: {}\".format(np.shape(train_keypoints)))\n\nprint(\"\\n Clean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, \"\")\nplt.show()\n\nif include_unclean_data:\n    print(\"Unclean Train Data: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif horizontal_flip:\n    print(\"Horizontal Flip Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(flipped_train_images[i], flipped_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif rotation_augmentation:\n    print(\"Rotation Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(rotated_train_images[i], rotated_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif brightness_augmentation:\n    print(\"Brightness Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(altered_brightness_train_images[i], altered_brightness_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif shift_augmentation:\n    print(\"Shift Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(shifted_train_images[i], shifted_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif random_noise_augmentation:\n    print(\"Random Noise Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(noisy_train_images[i], clean_train_keypoints[i], axis, \"\")\n    plt.show()","274ab759":"train_keypoints.shape","eb4238bd":"np.save('train_images', train_images)\nnp.save('train_keypoints', train_keypoints)\nnp.save('test_images', test_images)\n","d736719d":"print(x_val[:,:,:,0].shape)\nx_val=np.array([x_val[:,:,:,0],x_val[:,:,:,0],x_val[:,:,:,0]])\nprint(x_val.shape)\n\nx_val=np.swapaxes(x_val,0,1)\nx_val=np.swapaxes(x_val,1,2)\nx_val=np.swapaxes(x_val,2,3)\nx_val.shape","1d878feb":"print(x_train[:,:,:,0].shape)\nx_train=np.array([x_train[:,:,:,0],x_train[:,:,:,0],x_train[:,:,:,0]])\nprint(x_train.shape)\n\nx_train=np.swapaxes(x_train,0,1)\nx_train=np.swapaxes(x_train,1,2)\nx_train=np.swapaxes(x_train,2,3)\nx_train.shape","7422ab49":"x_train = (x_train\/255)\nx_val = (x_val\/255)\ntest = (text\/255)","ca0da437":"precomputed_val = base_model.predict(x_val, batch_size=256, verbose=1)\nprecomputed_val.shape","7ccdd0cc":"print(test_images[:,:,:,0].shape)\ntest=np.array([test_images[:,:,:,0],test_images[:,:,:,0],test_images[:,:,:,0]])\nprint(test.shape)\n\n\ntest=np.swapaxes(test,0,1)\ntest=np.swapaxes(test,1,2)\ntest=np.swapaxes(test,2,3)\ntest.shape","ee036ff8":"We can observe that approximately 70% of data is missing for several keypoints","caa8e566":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)\nrowid = list(lookid_data['RowId'])\n","6edc41a5":"\n\nfeature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))\n    \n    \npreded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])\n","b6373304":"from keras.applications.resnet50 import ResNet50\n\nbase_model = ResNet50(include_top=False, input_shape=(96,96,3), pooling='avg')\nbase_model.trainable = False\nbase_model.summary()","4bf0505a":"(2140, 30)\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Flatten,BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n\ntop_model = Sequential([\n    Dense(512, activation='relu', input_shape=(2048,),kernel_initializer='he_normal'), \n    Dense(256, activation='relu',kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(96, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dropout(0.7),\n    Dense(48, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer='he_normal'),\n    Dense(30)\n])\ntop_model.compile(loss='mse', optimizer=Adam(0.001), metrics=['mae'])\ntop_model.summary()","61bae06f":"final_model = Sequential([base_model, top_model])\nfinal_model.compile(loss='mse', optimizer=Adam(0.001), metrics=['mae'])\nfinal_model.summary()","69e71785":"pred = final_model.predict(test)","40cbf9a4":"precomputed_train = base_model.predict(x_train, batch_size=256, verbose=1)\nprecomputed_train.shape","44a1a5ab":"print(f'MAE final: {final_model.evaluate(x_val, y_val)[1]}')\n","1eb13d8b":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(train_images, train_keypoints, test_size=0.05, random_state=42)\nx_train.shape, x_val.shape","13f04139":"log = top_model.fit(precomputed_train, y_train, epochs=600,\n                    batch_size=256, validation_data=[precomputed_val, y_val])","55828842":"rowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('face_key_detection_submission.csv',index = False)"}}