{"cell_type":{"54f16739":"code","c21c3022":"code","69321473":"code","e4d0d1a4":"code","a062c430":"code","5b8c0f2c":"code","2fcace0b":"code","bd900a81":"code","08b624c6":"code","052ceda2":"code","34bb7b84":"code","267a9fb9":"code","16e76a64":"code","bf940f41":"code","1566efeb":"code","569eed0d":"code","19d4dc9d":"code","cc27af89":"code","a35dfc5a":"code","861c4c20":"code","014aff8d":"code","97b2cf09":"code","c5434d6c":"code","444df06b":"code","4b5304d7":"code","09c1cc93":"code","8d4d7f1b":"code","bae0b275":"code","561731ed":"code","78b58799":"code","ff40f9e1":"code","2eab6065":"code","6698743d":"code","aaa04d67":"code","51cf87bf":"code","34c2352c":"code","b7ee3fb6":"code","6a63d615":"code","0663a0ce":"code","4b5a8ee9":"code","1545dc12":"code","04201f8a":"code","d584621f":"code","b572710e":"code","9f1b4427":"code","9f0ea89d":"code","ce9b037f":"code","0259d50c":"code","6a488726":"code","ed64997b":"code","b7d5e047":"code","99fe3b86":"code","831ba665":"code","6ee06cce":"code","295ec3f3":"code","f4217aa2":"code","2df6bcaa":"code","ec31b25e":"code","70655460":"code","c49ece09":"code","de33f844":"code","bb0eb78e":"code","ac452ad6":"code","ed834cf7":"code","8c81cce7":"code","5cb8833e":"code","54fc764a":"code","965f9566":"code","a9f3da24":"code","f4d9df5f":"code","fcd5b1e5":"code","1fbc7a1d":"code","e5cf0988":"code","50ee80a2":"code","0f91864c":"code","d92af841":"code","c7aa2c1e":"code","71896300":"code","1f0b541e":"markdown","4ddfa588":"markdown","66f10c6f":"markdown","dcbf3113":"markdown","4c2fa31d":"markdown","43e4e356":"markdown","ee3cc89f":"markdown","900bebfb":"markdown","3c949c12":"markdown","cefc6b8e":"markdown","a95bb1a6":"markdown","4050319c":"markdown","fb7647aa":"markdown","032c56cb":"markdown","0002a70a":"markdown","59691642":"markdown","2d097326":"markdown","f8fb9206":"markdown"},"source":{"54f16739":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c21c3022":"trainData = pd.read_csv('..\/input\/titanic\/train.csv')","69321473":"testData = pd.read_csv('..\/input\/titanic\/test.csv')","e4d0d1a4":"trainData.head()","a062c430":"trainData.Survived","5b8c0f2c":"plt.hist(trainData.Survived, bins = 2)","2fcace0b":"trainData.describe()","bd900a81":"pie_data = trainData.drop(columns=['PassengerId', 'Name', 'Ticket', 'Age','Fare','Cabin'])","08b624c6":"fig = plt.figure(figsize=(15,15))\nfor i in range(1, pie_data.shape[1] +1):\n    plt.subplot(2, 3, i)\n    \n    fig = plt.gca()\n    fig.axes.get_yaxis().set_visible(False)\n    \n    fig.set_title(pie_data.columns.values[i-1])\n    values =  pie_data.iloc[:, i-1].value_counts(normalize = True).values\n    index =  pie_data.iloc[:, i-1].value_counts(normalize = True).index\n    fig = plt.pie(values, labels = index, autopct = '%1.1f%%')\n    \n    plt.axis('equal')\nplt.tight_layout(rect = [0, 0.03, 1, 0.95])","052ceda2":"sns.set_style('darkgrid')\nplt.figure(figsize=(12,12))\ntrainData.drop(columns=['Survived','PassengerId']).corrwith(trainData.Survived).plot.bar()\nplt.title('Correlation with the dependent vairable')\nplt.show()","34bb7b84":"plt.figure(figsize=(12,12))\nsns.heatmap(trainData.corr(),annot = True, fmt='g')","267a9fb9":"trainData.isnull().sum()","16e76a64":"trainData2 = trainData.copy(deep = True)","bf940f41":"testData2 = testData.copy(deep=True)","1566efeb":"trainData2.drop(columns = ['Cabin'], inplace = True)","569eed0d":"testData2.drop(columns = ['Cabin'], inplace = True)","19d4dc9d":"trainData2.Age.fillna(trainData2.Age.mean(),inplace = True)","cc27af89":"testData2.Age.fillna(testData2.Age.mean(),inplace = True)\ntestData2.Fare.fillna(testData2.Fare.mean(), inplace = True)","a35dfc5a":"trainData2.isnull().sum()","861c4c20":"testData2.isnull().sum()","014aff8d":"trainData2[trainData2.Embarked.isnull()].index","97b2cf09":"trainData2.drop(index=[61,829],inplace=True)","c5434d6c":"trainData2.isnull().sum()","444df06b":"trainData2.shape","4b5304d7":"testData2.shape","09c1cc93":"name = trainData.Name","8d4d7f1b":"title = np.asarray([])\nfor i in name:\n    if i.find('Mrs') != -1:\n        r = i.find('Mrs')\n        re = i[r: r+3]\n    elif i.find('Mr') != -1:\n        r = i.find('Mr')\n        re = i[r:r+2]\n    elif i.find('Master') != -1:\n        r = i.find('Master')\n        re = i[r:r+6]\n    else:\n        r = i.find('Miss')\n        re = i[r:r+4]\n    title = np.append(title, re)\n    ","bae0b275":"title.head()","561731ed":"title = pd.DataFrame(title)","78b58799":"title[0].unique()","ff40f9e1":"indexes = title[title[0] ==''].index","2eab6065":"for i in indexes:\n    if trainData.iloc[i, 4] == 'male':\n        if trainData.iloc[i, 5] >= 18:\n            title.iloc[i,0] = 'Mr'\n        else:\n            title.iloc[i,0] = 'Master'\n    else:\n        title.iloc[i,0] = 'Miss'","6698743d":"title[0].unique()","aaa04d67":"name_test = testData2.Name\ntitle_test = np.asarray([])\nfor i in name_test:\n    if i.find('Mrs') != -1:\n        r = i.find('Mrs')\n        re = i[r: r+3]\n    elif i.find('Mr') != -1:\n        r = i.find('Mr')\n        re = i[r:r+2]\n    elif i.find('Master') != -1:\n        r = i.find('Master')\n        re = i[r:r+6]\n    else:\n        r = i.find('Miss')\n        re = i[r:r+4]\n    title_test = np.append(title_test, re)","51cf87bf":"title_test = pd.DataFrame(title_test)\ntitle_test[0].unique()","34c2352c":"indexes_test = title_test[title_test[0] ==''].index\nfor i in indexes_test:\n    if testData2.iloc[i, 3] == 'male':\n        if testData2.iloc[i, 4] >= 18:\n            title_test.iloc[i,0] = 'Mr'\n        else:\n            title_test.iloc[i,0] = 'Master'\n    else:\n        title_test.iloc[i,0] = 'Miss'","b7ee3fb6":"title_test[0].unique()","6a63d615":"trainData2['Title'] = title[0]","0663a0ce":"trainData2.head()","4b5a8ee9":"testData2['Title'] = title_test[0]\ntestData2.head()","1545dc12":"y=trainData2.Survived\nId = trainData2.PassengerId\nx = trainData2.drop(columns = ['PassengerId', 'Name', 'Ticket','Survived'])","04201f8a":"Id_test = testData2.PassengerId\ntestData2.drop(columns = ['PassengerId','Name','Ticket'], inplace = True)","d584621f":"x_dummies = pd.get_dummies(x, drop_first=True)\ntestData_dummies = pd.get_dummies(testData2, drop_first = True)","b572710e":"x_dummies.head()","9f1b4427":"testData_dummies.head()","9f0ea89d":"x = x_dummies","ce9b037f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","0259d50c":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)","6a488726":"sc = StandardScaler()","ed64997b":"x_train2 = pd.DataFrame(sc.fit_transform(x_train), columns = x_train.columns.values)","b7d5e047":"x_test2 = pd.DataFrame(sc.transform(x_test), columns = x_test.columns.values)","99fe3b86":"testData_dummies2 = pd.DataFrame(sc.transform(testData_dummies), columns = testData_dummies.columns.values)","831ba665":"x_train2","6ee06cce":"x_test2","295ec3f3":"testData_dummies2","f4217aa2":"from sklearn.ensemble import RandomForestClassifier\n","2df6bcaa":"classifier = RandomForestClassifier()","ec31b25e":"classifier.fit(x_train2,y_train)","70655460":"y_pred = classifier.predict(x_test2)","c49ece09":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score","de33f844":"confusion_matrix(y_test,y_pred)","bb0eb78e":"precision_score(y_test,y_pred)","ac452ad6":"accuracy_score(y_test, y_pred)","ed834cf7":"from sklearn.model_selection import RandomizedSearchCV","8c81cce7":"param = {'n_estimators':[100,300,500],'criterion':['gini','entropy'],'max_depth':[3,5,7],'max_features':['sqrt','log2','auto']}","5cb8833e":"classifier = RandomForestClassifier()\nrandom = RandomizedSearchCV(estimator=classifier,param_distributions=param,n_iter=10,scoring='accuracy',n_jobs = -1,cv = 5)","54fc764a":"random.fit(x_train2,y_train)","965f9566":"random.best_params_","a9f3da24":"classifier2 = RandomForestClassifier(n_estimators=100,\n                                     max_features='sqrt',\n                                     max_depth=5,\n                                     criterion='entropy')\n","f4d9df5f":"classifier2.fit(x_train2,y_train)","fcd5b1e5":"y_pred2 = classifier2.predict(x_test2)","1fbc7a1d":"confusion_matrix(y_test,y_pred2)","e5cf0988":"precision_score(y_test,y_pred2)","50ee80a2":"accuracy_score(y_test,y_pred2)","0f91864c":"classifier.fit(x_train2,y_train)","d92af841":"prediction = classifier.predict(testData_dummies2)","c7aa2c1e":"Id = pd.DataFrame(Id_test, columns = ['Id'])\n\npredi = pd.DataFrame(prediction, columns = ['Survived'])","71896300":"result = pd.concat([Id,predi],axis = 1)\n","1f0b541e":"Importing Libraries","4ddfa588":"We can now drop the Name variable","66f10c6f":"# Data Exploration\nLets do some exploration","dcbf3113":"Lets have a look at our dataset","4c2fa31d":"# Feature Engineering\nI'll be extracting the titles from the Name column and drop the name column as it is of no use to us","43e4e356":"Let's do some Feature engineering next","ee3cc89f":"I dont know why I didnt get a better accuracy here . If someone can help me out with it...it would be great.","900bebfb":"Let's clean the Data next","3c949c12":"# Hello Community!\nLets find out who are more likely to survive...","cefc6b8e":"I'll drop the cabin column and replace the null values in age column with the mean. Also I'll remove the 2 rows which have null values in Embarked column","a95bb1a6":"So this is it \nI would really appreciate if someone can help me out with improving my model\nHappy Learning!","4050319c":"# Training the model\nI'll be using Random Forest ","fb7647aa":"# Data Cleaning","032c56cb":"Now that the data is ready, I'll jump to building the model.\n# Standardization","0002a70a":"The missing value can be filled as","59691642":"Great! Now lets read the data.","2d097326":"----","f8fb9206":"Survived - dependent variable"}}