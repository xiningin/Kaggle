{"cell_type":{"69867bec":"code","30a0d1ca":"code","5a9faebb":"code","e0c31ae9":"code","34afd679":"code","c047776a":"code","f0a970db":"code","5e7d1ef0":"code","0c02fa71":"code","b0f04171":"code","50bd57da":"code","107b8742":"code","c8a4d0f0":"code","df756a7f":"code","c3fd085f":"markdown","316648ab":"markdown","664d8132":"markdown","c642e9af":"markdown","d92239ec":"markdown","a1a1cfa9":"markdown"},"source":{"69867bec":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')","30a0d1ca":"train['Survived'].value_counts().plot.bar()\nplt.title('Counts of Survived')\nplt.figtext(0.90, 0.01, '0 = No, 1 = Yes', horizontalalignment='right')\nplt.xticks(rotation=360);","5a9faebb":"print('Count:')\nprint(train['Survived'].value_counts())\nprint('\\n')\nprint('Percent:')\nprint(train['Survived'].value_counts() \/ len(train) * 100)\nprint('\\n')\nprint('0 = No, 1 = Yes')","e0c31ae9":"X_train = train.drop(['Survived'], axis=1)\ny_train = train['Survived'].copy()","34afd679":"# For numerical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')), # impute missing values with median\n    ('minmax_scaler', MinMaxScaler()),             # scale features\n])","c047776a":"# For categorical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')), # impute missing values with mode\n    ('cat_encoder', OneHotEncoder())                      # convert text to numbers\n])","f0a970db":"# Full pipeline\nfrom sklearn.compose import ColumnTransformer\n\nnum_attribs_all = X_train.select_dtypes(['float64', 'int64']).columns\nnum_attribs = num_attribs_all.drop('PassengerId')\n\ncat_attribs_all = X_train.select_dtypes('object').columns\ncat_attribs = cat_attribs_all.drop(['Ticket', 'Cabin', 'Name'])\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", cat_pipeline, cat_attribs),\n    ])","5e7d1ef0":"from sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n\n\nclassifiers = [\n    SGDClassifier(),\n    LogisticRegression(),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier()\n    ]\n\nfor classifier in classifiers:\n    pipe = Pipeline(\n        [('full_pipeline', full_pipeline), \n         ('classifier', classifier)\n        ])\n    pipe.fit(X_train, y_train)   \n    print(classifier)\n    print(\"Accuracy: %.3f\" % pipe.score(X_train, y_train))","0c02fa71":"knn = Pipeline([\n    ('full_pipeline', full_pipeline),\n    ('classifier', KNeighborsClassifier(3))\n])\n\ndecision_tree = Pipeline([\n    ('full_pipeline', full_pipeline),\n    ('classifier', DecisionTreeClassifier())\n])\n\nrandom_forest = Pipeline([\n    ('full_pipeline', full_pipeline),\n    ('classifier', RandomForestClassifier())\n])\n\nada_boost = Pipeline([\n    ('full_pipeline', full_pipeline),\n    ('classifer', AdaBoostClassifier())\n])\n\ngradient_boosting = Pipeline([\n    ('full_pipeline', full_pipeline),\n    ('classifier', GradientBoostingClassifier())\n])\n\nknn.fit(X_train, y_train)\ndecision_tree.fit(X_train, y_train)\nrandom_forest.fit(X_train, y_train)\nada_boost.fit(X_train, y_train)\ngradient_boosting.fit(X_train, y_train);","b0f04171":"from sklearn.model_selection import cross_val_score\n\nclassifiers = [knn, decision_tree, random_forest, ada_boost, gradient_boosting]\n\nlabels = [\n    'KNeighborsClassifier(3)',\n    'DecisionTreeClassifier()',\n    'RandomForestClassifier()',\n    'AdaBoostClassifier()',\n    'GradientBoostingClassifier()'\n    ]\n\nprint('Cross-validation:')\ni = 0\nfor classifier in classifiers:\n    accuracy_cv = cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy')\n    print(labels[i])\n    print(np.mean(accuracy_cv))\n    i += 1","50bd57da":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import roc_auc_score\n\nprint('ROC AUC scores:')\ni = 0\nfor classifier in classifiers:\n    y_pred = cross_val_predict(classifier, X_train, y_train)\n    print(labels[i])\n    print(roc_auc_score(y_train, y_pred))\n    i += 1","107b8742":"from sklearn.metrics import precision_score\nfrom sklearn.model_selection import cross_val_predict\n\nprint('Precision:')\ni = 0\nfor classifier in classifiers:\n    y_train_pred = cross_val_predict(classifier, X_train, y_train, cv=5)\n    print(labels[i])\n    print(precision_score(y_train, y_train_pred))\n    i +=1","c8a4d0f0":"from sklearn.metrics import recall_score\nfrom sklearn.model_selection import cross_val_predict\n\nprint('Recall:')\ni = 0\nfor classifier in classifiers:\n    y_train_pred = cross_val_predict(classifier, X_train, y_train, cv=5)\n    print(labels[i])\n    print(recall_score(y_train, y_train_pred))\n    i +=1","df756a7f":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_predict\n\nprint('F\u2081 scores:')\ni = 0\nfor classifier in classifiers:\n    y_train_pred = cross_val_predict(classifier, X_train, y_train, cv=5)\n    print(labels[i])\n    print(f1_score(y_train, y_train_pred))\n    i += 1","c3fd085f":"## Introduction\n\nThe goal of this notebook is to shortlist 2\u20135 promising models for predicting passenger survival in the Titanic dataset. I will try to automate this as much as possible using `Pipeline` from scikit-learn. I will then compare my shortlist of models using the following performance measures: cross-validation, precision, recall, F\u2081 scores, and ROC AUC scores.\n\nFor evaluating the performance of a classifier, generally you would use precision-recall when the positive class for the label is rare or you care more about false positives than negatives, otherwise you would use the ROC curve.","316648ab":"Based on this, I would not consider the positive class (`1`) to be rare. Also, I don't have a preference regarding false positives vs. negatives.","664d8132":"## Model selection","c642e9af":"## Get the data","d92239ec":"## A shortlist of promising models","a1a1cfa9":"## Prepare the data"}}