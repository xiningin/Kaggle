{"cell_type":{"029f6f74":"code","3333eff4":"code","d803c358":"code","8fa440d7":"code","0593ba39":"code","51ade572":"code","4c5c5864":"code","b553c925":"code","81a513ee":"code","414703e6":"code","4e773c19":"code","5e3299a3":"code","33324323":"code","2a8b3956":"code","43c7471e":"code","410b5d7b":"code","757d786e":"code","24eb3bc5":"code","69375a9b":"code","14d6175a":"code","1f847212":"code","45568486":"code","b25879f1":"code","d76389ab":"code","002339d1":"code","cfccf276":"markdown","bc1530ca":"markdown","2be6e44c":"markdown","76cf7358":"markdown","9df2c62e":"markdown","073e92de":"markdown","4faa989d":"markdown","333f682a":"markdown","f59c100c":"markdown","a77a77e1":"markdown","4376a873":"markdown","36f218a0":"markdown","9a0956fd":"markdown","47afb83a":"markdown","92f9bffc":"markdown"},"source":{"029f6f74":"\n!pip install --upgrade tensorflow","3333eff4":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import applications\nfrom keras import utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.preprocessing.image import load_img\n\nfrom keras.preprocessing.image import img_to_array\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport PIL\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","d803c358":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 100 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [224,224]\nEPOCHS = 1000","8fa440d7":"#!pip install tf-nightly\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    '..\/input\/breastcancerultrasoundimages\/breast cancer-ultrasound-dataset\/breast cancer-train-dataset',\n    validation_split= 0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    \"..\/input\/breastcancerultrasoundimages\/breast cancer-ultrasound-dataset\/breast cancer-train-dataset\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)","0593ba39":"print(train_ds)","51ade572":"class_names = ['benign', 'malignant','normal']\ntrain_ds.class_names = class_names\nval_ds.class_names = class_names\n\nNUM_CLASSES = len(class_names)\n\nprint(class_names)","4c5c5864":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(12):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(train_ds.class_names[labels[i]])\n    plt.axis(\"off\")","b553c925":"def one_hot_label(image, label):\n    label = tf.one_hot(label, NUM_CLASSES)\n    return image, label\n\ntrain_ds = train_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)","81a513ee":"train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","414703e6":"datagen = ImageDataGenerator(\n        rotation_range=5,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=False,\n        fill_mode='nearest')\n\nimg = load_img('..\/input\/breastcancerultrasoundimages\/breast cancer-ultrasound-dataset\/breast cancer-test-dataset\/benign\/benign (1).png')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview\/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,\n                          save_to_dir=None , save_prefix=\"\", save_format='png'):\n    i += 1\n    if i > 20:\n        break  # otherwise the generator would loop indefinitely","4e773c19":"NUM_IMAGES = []\n\nfor label in class_names:\n    dir_name = \"..\/input\/breastcancerultrasoundimages\/breast cancer-ultrasound-dataset\/breast cancer-train-dataset\" + label[:-2] \n    #+ 'ed'\n    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))","5e3299a3":"NUM_IMAGES","33324323":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n    ]\n    )\n    \n    return block","2a8b3956":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","43c7471e":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        \n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(pool_size=(2, 2)\n        \n),\n        \n        conv_block(20),\n        conv_block(50),\n                                  \n        \n        conv_block(96),\n        tf.keras.layers.Dropout(0.2),\n                                  \n        \n        #conv_block(256),\n        #tf.keras.layers.Dropout(0.2),\n        \n        \n       tf.keras.layers.Flatten(),\n       # dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n    ])\n    \n    return model","410b5d7b":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        \n        keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n        \n        tf.keras.metrics.AUC(name='auc')]\n    \n    model.compile(\n        optimizer='adam',\n        loss=tf.losses.CategoricalCrossentropy(),\n        metrics=METRICS\n    )","757d786e":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 10)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\n#checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n                                                     restore_best_weights=True)","24eb3bc5":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n    epochs=EPOCHS\n)","69375a9b":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['auc', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])\n    \n\n    ","14d6175a":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","1f847212":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","45568486":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/breastcancerultrasoundimages\/breast cancer-ultrasound-dataset\/breast cancer-test-dataset\",\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\ntest_ds = test_ds.map(one_hot_label, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","b25879f1":"_ = model.evaluate(test_ds)\n","d76389ab":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy']):\n    ax[i].plot(history.history[met])\n   # ax[i].plot(history.history[ met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    #ax[i].legend(['train', 'test'])","002339d1":"model.save_weights('first_try.h5')","cfccf276":"We'll be renaming the class names and specifying the number of classes. In this case, we have 4 classes of dementia.","bc1530ca":"# Feature Engineering\n\nBecause we are working with categorical and noncontinuous data, we want to convert our model into one-hot encodings. One-hot encodings are a way for the model to understand that we're looking at categorial instead of continuous data. Transforming features so that they'll be more understandable is called feature engineering. Learn more about feature engineering [here](https:\/\/developers.google.com\/machine-learning\/crash-course\/representation\/feature-engineering).","2be6e44c":"# Visualize the data\n\nNow that our data has been easily loaded in, the next step is to visualize our images. This helps us understand what is being used as an input for our model. It also serves as a check to see if our images have been loaded in correctly.","76cf7358":"# Visualize Model Metrics\n\nLet's graph the ROC AUC metric and loss after each epoch for the training and validation data. Although we didn't use a random seed for our notebook, the results may slightly vary, generally the scores for the validataion data is similar, if not better, than the training dataset.","9df2c62e":"# Data pre-processing and data augmentation\u00b6","073e92de":"# Evaluate the Model\n\nAlthough we used the validatation dataset to continually evaluate the model, we also have a separate testing dataset. Let's prepare the testing dataset.","4faa989d":"# Deciding a Metric\n\nThe most conventional metric to use is probably accuracy. Accuracy, however, cannot be used for imbalanced datasets. Let's check how many images are in each class for our training data.","333f682a":"# Training the Model\n\nTo more efficiently train our model. We will be using callbacks to adjust our learning rate and to stop our model once it converges.\n\nThe [learning rate](https:\/\/developers.google.com\/machine-learning\/glossary#learning-rate) is a very important hyperparameter in the model. Having a LR that is too high will prevent the model from converging. Having a LR that is too slow will make the process too long. Stopping our model early is one mechanism that prevents overfitting.","f59c100c":"It's always a good idea to set constant variables instead of hard coding numbers into your code. It saves time later when you want to change certain parameters.","a77a77e1":"# Data Loading\n\nWe'll be using a [Kaggle Alzheimer's dataset](https:\/\/www.kaggle.com\/tourist55\/alzheimers-dataset-4-class-of-images) for our tutorial. `tf.keras` has a new preprocessing function that can easily load in images for a directory. In order for this function to work, the data has to be structured in a file directory format.\n\n```\nmain_directory\/\n    class1\/\n        class1_images\n    class2\/\n        class2_images\n```\n\nIf you input the `main_directory` into the `tf.keras` function, it will figure out the rest!\nIn our case, the `train` directory is our main directory.\n\nWe are also specifying a 80:20 split for our training and validation datasets. To learn more about the importance of having a validation split, check out this [lesson](https:\/\/developers.google.com\/machine-learning\/crash-course\/validation\/another-partition) from Google's Machine Learning Crash Course.","4376a873":"Let's fit our model!","36f218a0":"Our dataset is not balanced, so we cannot use accuracy as our metric. For this tutorial, we will be using ROC AUC. Intuitively, ROC AUC gives a score, with higher scores closer to 1 indicating that the different classes can be distinguishable for the model. A lower score closer indicates that the the model cannot distinguish between different classes. A score of 0.5 indicates that the ordering the images is pretty much random. Learn more about ROC AUC [here](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc).","9a0956fd":"# Build the ML Model\n\nWe'll be using the same architecture for our model as my [Pneumonia Classification NB](https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays#4.-Build-the-CNN). Using `tf.keras`, we can easily build up the layers of our CNN.","47afb83a":"The following cell makes calling images from our dataset more efficient.","92f9bffc":"# Introduction + Set-up\n\nMachine learning has a phenomenal range of application in the health sciences. This tutorial will go over the complete pipeline to build a model that can determine the dementia level of an Alzheimer's patient from their MRI image. This model achieves an a high ROC AUC score.\n\nThis tutorial highlights the ease of building a CNN using `tf.keras`. Additionally, TensorFlow 2.3 has new features, including easy data loading utilities that were previously not available in TensorFlow 2.2. We'll be seeing how easy data loading is with these additional features.\n\nWe'll be using a GPU accelerator for this NB."}}