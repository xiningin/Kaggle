{"cell_type":{"277ec83e":"code","378c7881":"code","4b0600d3":"code","208e3669":"code","fe6f01fb":"code","e4e6cd7e":"code","ca2f7419":"code","77fe17b2":"code","79fb97c4":"code","f33f76e3":"markdown","31d758e6":"markdown","e4696a0e":"markdown","00ca82b7":"markdown"},"source":{"277ec83e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm.classes import OneClassSVM\nfrom sklearn.neural_network.multilayer_perceptron import MLPClassifier\nfrom sklearn.neighbors.classification import RadiusNeighborsClassifier\nfrom sklearn.neighbors.classification import KNeighborsClassifier\nfrom sklearn.linear_model.stochastic_gradient import SGDClassifier\nfrom sklearn.linear_model.ridge import RidgeClassifierCV\nfrom sklearn.linear_model.ridge import RidgeClassifier\nfrom sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier    \nfrom sklearn.gaussian_process.gpc import GaussianProcessClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.semi_supervised import LabelSpreading\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.naive_bayes import MultinomialNB  \nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.svm import NuSVC\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.mixture import BayesianGaussianMixture\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n#import h2o\n#from h2o.automl import H2OAutoML\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n#h2o.init()\n\n# Any results you write to the current directory are saved as output.\n\ntrain = pd.read_csv('..\/input\/learn-together\/train.csv')\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')\nID = test['Id']\n\n\ntrain = train.drop(['Soil_Type7','Soil_Type15','Id'], axis =1)\ntest = test.drop(['Soil_Type7','Soil_Type15','Id'], axis =1)\n\n#train_auto = h2o.H2OFrame(train)\n#test_auto = h2o.H2OFrame(test)\n\n\n\n#x_auto = list(train.columns)\n#y_auto = 'Cover_Type'\n#train_auto['Cover_Type'] = train_auto['Cover_Type'].asfactor()\n\n\n\ny = train.Cover_Type\nX = train.drop(['Cover_Type'], axis = 1)\nx_train, x_test, y_train, y_test = train_test_split(X,y, random_state=1)","378c7881":"### This took forever to run you will just have to trust me that the results are correct, or you could uncomment this and run it \n#aml_ti = H2OAutoML(nfolds = 10)\n#aml_ti.train(x = x_auto, y = y_auto, training_frame = train_auto)\n          \n#check the leaderboard\n#lb_ti = aml_ti.leaderboard\n#lb_ti\n","4b0600d3":"'''\n-                                                       mpce      logloss   rmse     mse\n- StackedEnsemble_AllModels_AutoML_20190912_165033\t    0.12123\t  0.340173\t0.31537\t 0.0994582\n- StackedEnsemble_BestOfFamily_AutoML_20190912_165033\t0.126124  0.347805\t0.319726 0.102225\n- DRF_1_AutoML_20190912_165033\t                        0.13545\t  0.418555\t0.36234\t 0.13129\n- XGBoost_1_AutoML_20190912_165033\t                    0.13631\t  0.363222\t0.332949 0.110855\n- GBM_1_AutoML_20190912_165033\t                        0.140476  0.378649\t0.340086 0.115659\n- XGBoost_2_AutoML_20190912_165033\t                    0.145238  0.391099\t0.348184 0.121232\n- GBM_2_AutoML_20190912_165033\t                        0.168585  0.481562\t0.393332 0.15471\n- XGBoost_3_AutoML_20190912_165033\t                    0.174471  0.453391\t0.381124 0.145256\n- GBM_3_AutoML_20190912_165033\t                        0.219114  1.20778\t0.689493 0.475401\n- GLM_grid_1_AutoML_20190912_165033_model_1\t            0.394709  1.64125\t0.801555 0.64249\n'''","208e3669":"models = ['ExtraTreeClassifier','DecisionTreeClassifier','MLPClassifier','KNeighborsClassifier',\n         'SGDClassifier', 'RidgeClassifier', 'PassiveAggressiveClassifier','AdaBoostClassifier', 'GradientBoostingClassifier', \n          'BaggingClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'BernoulliNB',\n          'CalibratedClassifierCV', 'GaussianNB', 'LinearDiscriminantAnalysis', 'LinearSVC', 'LogisticRegression',\n          'LogisticRegressionCV', 'NearestCentroid', 'Perceptron', 'QuadraticDiscriminantAnalysis', 'SVC', 'LGBMClassifier', 'XGBClassifier','CatBoostClassifier' \n         ]\n\n\n\n# models that didn't work : 'GaussianMixture','BayesianGaussianMixture', neareastcentroid, nuSVC, oneclassSVM, LabelPropagation', 'LabelSpreading'\n\n","fe6f01fb":"results_dict = {'auto_ml_stacked': 0.8787}  # I am assuming that mean_per_class_error is similar to accuracy, this may not be the case. I did 1 - mpce\nresults_dict2 = {}","e4e6cd7e":"\n\nfor model in models:\n    \n    k_fold = KFold( n_splits=10, shuffle=True, random_state=0)\n\n    if model == 'CatBoostClassifier':\n        clf = CatBoostClassifier(logging_level='Silent')\n    else:\n        clf = eval(model+'()')\n        scoring = 'accuracy'\n\n    cv_results = cross_val_score(clf, x_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\n    results_dict[model] = pd.Series(cv_results).mean()\n    results_dict2[model] = cv_results\n    msg = \"%s: %f (%f)\" % (model, cv_results.mean(), cv_results.std())\n    print(msg)\n    \n  ","ca2f7419":"import matplotlib.pyplot as plt\nfrom collections import OrderedDict\nimport seaborn as sns\nD1 = dict(OrderedDict(sorted(results_dict.items(), key = lambda t: t[1])))","77fe17b2":"labels = list(D1.keys())\nvalues = list(D1.values())\nplt.subplots(figsize=(30,10))\nsns.barplot(x = labels, y =  values)\nplt.xticks(rotation= 90,  fontsize=15)\nplt.hlines(0.51,0,30.47, linestyles = 'dotted')\nplt.ylabel('Accuracy')\n","79fb97c4":"\n\ndf = pd.DataFrame(results_dict2)\n\ndf.boxplot(figsize=(30,10), rot=90, fontsize=15)\nplt.hlines(0.7,0,30.47, linestyles = 'dotted', color = 'g')\nplt.hlines(0.5,0,30.47, linestyles = 'dotted', color = 'r')","f33f76e3":"### Seeing as this is a competition for learning I thought I would run every model I could get my hands on and see how they work. \n\n### I will continue working on this, my end goal is to try and understand why all of these models do the things they do.","31d758e6":"#### models that didn't work : 'GaussianMixture','BayesianGaussianMixture', neareastcentroid, nuSVC, oneclassSVM, LabelPropagation', 'LabelSpreading'\n\nOkay, some of these did run, but there scores were 0.14 -- nuSVC, oneclassSVM, LabelPropagation', 'LabelSpreading'. The others in the above list did not run at all.","e4696a0e":"I have set the line so that those we can see the classifiers that were worse than 50% accuracy.\n\nYou can notice that, of those that perform the worst. The score is always 0.14? I am sure that means that it is just using one value or something, do you know?\n\nFor me the most impressive thing is how Knn is quite accurate and takes < 1 second to train. I wouldn't have expected this model to be so effective.\n\nThe best model was the automl model, but seeing as I couldn't figure out how to display accuracy I am not sure it is correct. However, bases on the results from others I would expect a stacked model to perform the best.","00ca82b7":"From these boxplots it would seem that the models are quite reliable with there predicitons. Those that are better than 50\/50 anyway. It may be my kaggle-addled brain, but it looks as if there are three distinct zones. Those above 70% those below 70% but above 50%, then those between 20% and 50%. The mlp classifier seems to be one of the most interesting as it is better than 50% half of the time.\n\n### If you know of any other models that I can add to the list please let me know!\n\n"}}