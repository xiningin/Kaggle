{"cell_type":{"64426b2d":"code","02ce7033":"code","7bed50b3":"code","21f892fd":"code","9e10304d":"code","37730a37":"code","3e366c1a":"code","aaa6651e":"code","defa55c6":"code","78df757d":"code","1dd8d7f8":"code","2ed36cb0":"code","ae893faa":"code","97b68cee":"code","31cbdb12":"code","fad5f1df":"code","33ddf042":"code","e2709d20":"code","8908c327":"code","6adcb9e2":"code","365599cc":"code","5f590f9d":"code","a5287952":"code","8203cf5b":"code","0ef347a8":"code","65a38660":"code","924159e1":"code","3f0982fd":"code","b962deda":"code","ec379d39":"code","541084dc":"code","3ab12a4d":"code","ca17b7f2":"code","558b338c":"code","da74b11d":"code","9ae3b1e4":"code","b86b35a7":"code","a0b66a56":"code","d2f24a29":"code","6d5ff6da":"code","da1d44e9":"code","28187479":"code","c6930750":"code","72781f15":"code","a98a9d1c":"code","db367fe6":"code","9d99adb9":"markdown","f094815b":"markdown","e8088f2c":"markdown","eacac90c":"markdown","ea7f6b55":"markdown","b632ae2f":"markdown","285dfbd7":"markdown","13bb7c91":"markdown","147aa73b":"markdown","198de60b":"markdown","36ad0548":"markdown","71b718f3":"markdown","06c68fb3":"markdown","15a9d7cc":"markdown","84b6be24":"markdown","0135cf93":"markdown","7458215d":"markdown","2de1d286":"markdown","e01559ec":"markdown","dc6045b8":"markdown","d15b2c6b":"markdown","5d26cd66":"markdown","cd19351c":"markdown"},"source":{"64426b2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02ce7033":"!pip install -U pip","7bed50b3":"!pip install xlrd\n!pip install openpyxl\n!pip install lifetimes\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.preprocessing import MinMaxScaler\nfrom lifetimes import BetaGeoFitter\nfrom lifetimes import GammaGammaFitter\nfrom lifetimes.plotting import plot_period_transactions\nimport warnings\nwarnings.filterwarnings(\"ignore\")","21f892fd":"# reading the dataset\n\ndf1=pd.read_excel(\"\/kaggle\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name=\"Year 2009-2010\")","9e10304d":"#copy\n\ndf=df1.copy()","37730a37":"df.head()","3e366c1a":"#Checking Variables\n\ndef check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(3))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(3))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","aaa6651e":"#Are there any missing observations in the dataset?\ndf.isnull().sum()","defa55c6":"def crm_data(dataframe):\n    dataframe.dropna(axis=0, inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n    return dataframe","78df757d":"df=crm_data(df)\ncheck_df(df)","1dd8d7f8":"#Missing values are deleted\ndf.isnull().sum()","2ed36cb0":"#How many unique items in the dataset?\ndf[\"Description\"].nunique()","ae893faa":"#How many product in the dataset?\ndf[\"Description\"].value_counts()","97b68cee":"#Rank the 5 most ordered products from most to least\ndf.groupby(\"Description\").agg({\"Quantity\":\"sum\"}).sort_values(\"Quantity\", ascending=False).head(5)","31cbdb12":"df.describe().T","fad5f1df":"msno.matrix(df)","33ddf042":"# there is no specific correlation between missing values\nmsno.heatmap(df)","e2709d20":"sns.boxplot(df[\"Quantity\"])","8908c327":"sns.boxplot(df[\"Price\"])","6adcb9e2":"#Let's check which product has been purchased more often so far\nplt.figure(figsize=(10,8))\ndf.groupby(\"Description\").sum().sort_values(by = \"Quantity\", ascending = False).head(30)[\"Quantity\"].plot(kind = \"bar\", color = 'mediumseagreen')","365599cc":"#Top 8 Countries With Popular Products\ntop_8_countries = [\"United Kingdom\", \"Netherlands\", \"EIRE\", \"Denmark\", \"Germany\", \"France\", \"Australia\", \"Sweden\"]","5f590f9d":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n","a5287952":"replace_with_thresholds(df,\"Quantity\")\nreplace_with_thresholds(df,\"Price\")","8203cf5b":"# outliers values are now cleaner.\n\ndf.describe([0.01,0.25,0.50,0.75,0.99]).T","0ef347a8":"def crm_data_prep(dataframe):\n    dataframe.dropna(axis=0, inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n    return dataframe\n\n","65a38660":"df=crm_data_prep(df)\ncheck_df(df)\n","924159e1":"sns.boxplot(df[\"Quantity\"])","3f0982fd":"sns.boxplot(df[\"Price\"]);","b962deda":" # When was the last time a customer made a purchase?\n\ndf[\"InvoiceDate\"].max()\n","ec379d39":"# In order to get logical results and avoid zero values, we set 2 days later as today's date.\ntoday_date = dt.datetime(2011, 12, 11)\ntoday_date","541084dc":"def create_rfm(dataframe):\n    # RFM Metrics\n    \n\n    today_date = dt.datetime(2010, 12, 11)\n\n    rfm = dataframe.groupby('Customer ID').agg({'InvoiceDate': lambda date: (today_date - date.max()).days,\n                                                'Invoice': lambda num: num.nunique(),\n                                                \"TotalPrice\": lambda price: price.sum()})\n\n    rfm.columns = ['recency', 'frequency', \"monetary\"]\n\n    rfm = rfm[(rfm['monetary'] > 0)]\n\n\n    # RFM score\n    rfm[\"recency_score\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n    rfm[\"frequency_score\"] = pd.qcut(rfm[\"frequency\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n\n\n\n    # segment naming\n    rfm['rfm_segment'] = rfm['recency_score'].astype(str) + rfm['frequency_score'].astype(str)\n\n    seg_map = {\n        r'[1-2][1-2]': 'hibernating',\n        r'[1-2][3-4]': 'at_risk',\n        r'[1-2]5': 'cant_loose',\n        r'3[1-2]': 'about_to_sleep',\n        r'33': 'need_attention',\n        r'[3-4][4-5]': 'loyal_customers',\n        r'41': 'promising',\n        r'51': 'new_customers',\n        r'[4-5][2-3]': 'potential_loyalists',\n        r'5[4-5]': 'champions'\n    }\n\n    rfm['rfm_segment'] = rfm['rfm_segment'].replace(seg_map, regex=True)\n    rfm = rfm[[\"recency\", \"frequency\", \"monetary\", \"rfm_segment\"]]\n    return rfm\n\n\n","3ab12a4d":"rfm = create_rfm(df)\nrfm.head()","ca17b7f2":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"rfm_segment\", y=\"frequency\", data=rfm)","558b338c":"check_df(rfm)","da74b11d":"\ndef create_cltv_calculated(dataframe):\n    # avg_order_value\n    dataframe['avg_order_value'] = dataframe['monetary'] \/ dataframe['frequency']\n\n    # purchase_frequency\n    dataframe[\"purchase_frequency\"] = dataframe['frequency'] \/ dataframe.shape[0]\n\n    # repeat rate & churn rate\n    repeat_rate = dataframe[dataframe.frequency > 1].shape[0] \/ dataframe.shape[0]\n    churn_rate = 1 - repeat_rate\n\n    # profit_margin\n    dataframe['profit_margin'] = dataframe['monetary'] * 0.05\n\n    # Customer Value\n    dataframe['cv'] = (dataframe['avg_order_value'] * dataframe[\"purchase_frequency\"])\n\n    # Customer Lifetime Value\n    dataframe['cltv'] = (dataframe['cv'] \/ churn_rate) * dataframe['profit_margin']\n\n    # minmaxscaler\n    scaler = MinMaxScaler(feature_range=(1, 100))\n    scaler.fit(dataframe[[\"cltv\"]])\n    dataframe[\"cltv_calculated\"] = scaler.transform(dataframe[[\"cltv\"]])\n\n    dataframe[\"cltv_calculated_segment\"] = pd.qcut(dataframe[\"cltv_calculated\"], 3, labels=[\"C\", \"B\", \"A\"])\n\n    dataframe = dataframe[[\"recency\", \"frequency\", \"monetary\", \"rfm_segment\",\n                           \"cltv_calculated\", \"cltv_calculated_segment\"]]\n\n    return dataframe\n\n","9ae3b1e4":"rfm_cltv = create_cltv_calculated(rfm)\ncheck_df(rfm_cltv)\n","b86b35a7":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"rfm_segment\", y=\"cltv_calculated\", data=rfm_cltv)","a0b66a56":"rfm_cltv.head()","d2f24a29":"plt.figure(figsize=(15,7))\nsns.barplot(x=\"cltv_calculated\", y=\"cltv_calculated_segment\", data=rfm_cltv)","6d5ff6da":"# The correlation seems very weak. \n\nplt.scatter(rfm_cltv.monetary,rfm_cltv.frequency,s=75)\n\n\nplt.xlabel(\"monetary\")\nplt.ylabel(\"frequency\")\nplt.legend()\nplt.show()","da1d44e9":"def create_cltv_predicted(dataframe):\n    today_date = dt.datetime(2010, 12, 11)\n\n    ## recency value customized\n    rfm = dataframe.groupby('Customer ID').agg({'InvoiceDate': [lambda date: (date.max()-date.min()).days,\n                                                                lambda date: (today_date - date.min()).days],\n                                                'Invoice': lambda num: num.nunique(),\n                                                'TotalPrice': lambda TotalPrice: TotalPrice.sum()})\n\n    rfm.columns = rfm.columns.droplevel(0)\n\n    ## recency_cltv_predicted\n    rfm.columns = ['recency_cltv_predicted', 'T', 'frequency', 'monetary']\n\n    ## basic monetary_avg\n    rfm[\"monetary\"] = rfm[\"monetary\"] \/ rfm[\"frequency\"]\n\n    rfm.rename(columns={\"monetary\": \"monetary_avg\"}, inplace=True)\n\n\n  \n    ## recency_weekly_cltv_predicted\n    rfm[\"recency_weekly_cltv_predicted\"] = rfm[\"recency_cltv_predicted\"] \/ 7\n    rfm[\"T_weekly\"] = rfm[\"T\"] \/ 7\n\n\n\n    # CONTROL\n    rfm = rfm[rfm[\"monetary_avg\"] > 0]\n\n    ## recency filter\n    rfm = rfm[(rfm['frequency'] > 1)]\n\n    rfm[\"frequency\"] = rfm[\"frequency\"].astype(int)\n\n    # BGNBD\n    bgf = BetaGeoFitter(penalizer_coef=0.01)\n    bgf.fit(rfm['frequency'],\n            rfm['recency_weekly_cltv_predicted'],\n            rfm['T_weekly'])\n\n\n    # Gamma Gamma\n    ggf = GammaGammaFitter(penalizer_coef=0.01)\n    ggf.fit(rfm['frequency'], rfm['monetary_avg'])\n    rfm[\"expected_average_profit\"] = ggf.conditional_expected_average_profit(rfm['frequency'],\n                                                                             rfm['monetary_avg'])\n    # 6 months cltv_p\n    cltv = ggf.customer_lifetime_value(bgf,\n                                       rfm['frequency'],\n                                       rfm['recency_weekly_cltv_predicted'],\n                                       rfm['T_weekly'],\n                                       rfm['monetary_avg'],\n                                       time=6,\n                                       freq=\"W\",\n                                       discount_rate=0.01)\n\n    rfm[\"cltv_predicted\"] = cltv\n\n    # minmaxscaler\n    scaler = MinMaxScaler(feature_range=(1, 100))\n    scaler.fit(rfm[[\"cltv_predicted\"]])\n    rfm[\"cltv_predicted\"] = scaler.transform(rfm[[\"cltv_predicted\"]])\n\n    # rfm.fillna(0, inplace=True)\n\n    # cltv_predicted_segment\n    rfm[\"cltv_predicted_segment\"] = pd.qcut(rfm[\"cltv_predicted\"], 3, labels=[\"C\", \"B\", \"A\"])\n\n    ## recency_cltv_predicted, recency_weekly_cltv_predicted\n    rfm = rfm[[\"recency_cltv_predicted\", \"T\", \"monetary_avg\", \"recency_weekly_cltv_predicted\", \"T_weekly\",\n               \"expected_average_profit\",\"cltv_predicted\", \"cltv_predicted_segment\"]]\n\n\n    return rfm\n","28187479":"rfm_cltv_predicted = create_cltv_predicted(df)\ncheck_df(rfm_cltv_predicted)","c6930750":"rfm_cltv_predicted.head()","72781f15":"rfm_cltv_predicted.groupby('cltv_predicted_segment').agg('expected_average_profit').mean().plot(kind='bar', colormap='copper_r');\n\nplt.ylabel(\"profit\");","a98a9d1c":"crm_final = rfm_cltv.merge(rfm_cltv_predicted, on=\"Customer ID\", how=\"left\")\ncheck_df(crm_final)","db367fe6":"# will be effective in campaign decisions\n\ncrm_final.sort_values(by=\"monetary_avg\", ascending=False).head()","9d99adb9":" <font color = '#F1C40F'>\n\n<a id = \"10\"><\/a><br>\n# RFM\n","f094815b":"<font color = '#D35400'>\n\n* This time we divided people into A, B, C segments. (Not to be confused with rfm segmentation.) Let's remember we do life-time value calculations.\n\n* The calculations in the table have been made.\n\n* Standardization process was done for better understanding.","e8088f2c":"<font color = '#F1C40F'>\n    \n<a id = \"15\"><\/a><br>\n\n### CLTV Preticted","eacac90c":"<font color = '#D35400'>\nOutlier values are trimmed (very little) without damaging the data.Here we have set a lower and upper limit. But since the lower limit is set, we'll only assign it to the upper limit. We'll do it for Quantity and Price.","ea7f6b55":"\n    \n<font color = '#F1C40F'>\n\n<a id = \"6\"><\/a><br>\n#  Library Import","b632ae2f":"# # \n    \n<font color = '#FF7F50'>\n\nContent:\n1. [Customer Relationship Management (CRM)](#1)\n* [What is CRM?](#2)\n* [What is the purpose?](#3)\n* [Content of Dataset](#4)\n* [Attribute Information](#5)\n2. [Library Import](#6)\n3. [Data Preprocessing](#7)\n4. [RFM](#10)\n* [What is RFM?](#11)\n* [RFM Segments](#12)\n5. [What is Customer Lifetime Value(CLV or CLTV)?](#13)\n* [CLTV Calculated](#14)\n6. [CLTV Predicted](#15)\n* [What is a cohort model?](#16)\n* [BG-NBD](#17)\n* [Gamma Gamma](#18)\n7. [Result](#19)\n8. [Summary](#20)","285dfbd7":"\n<font color = '#34495E'>\n\n <a id = \"2\"><\/a><br>\n### What is CRM? \n\nCustomer relationship management (CRM) is the combination of practices, strategies and technologies that companies use to manage and analyze customer interactions and data throughout the customer lifecycle. The goal is to improve customer service relationships and assist in customer retention and drive sales growth. CRM systems compile customer data across different channels, or points of contact, between the customer and the company, which could include the company's website, telephone, live chat, direct mail, marketing materials and social networks. CRM systems can also give customer-facing staff members detailed information on customers' personal information, purchase history, buying preferences and concerns.\n    \n    * Quelle https:\/\/keap.com\/product\/what-is-crm\n\n <a id = \"3\"><\/a><br>\n### What is the purpose?\n\nWe will add statistics and probability pattern to the above formula. There will be BG \/ NBD and Gamma Gamma models that will make this happen to us. These models will do such a thing that they will model the purchasing behavior of all customers of this company, after modeling the purchasing behavior of all customers, they will replace the individual's personal characteristics in this model and reduce the expected number of sales to the person from the general audience pattern.\n\nBG NBD and Gamma Gamma models are statistical models, not machine learning models. In fact, these models have the expression \"Conditional\" at the beginning.\n<a id = \"4\"><\/a><br>\n### Content of Dataset\n\nThis Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01\/12\/2009 and 09\/12\/2011.The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.\n\n<a id = \"5\"><\/a><br>\n### Attribute Information:\n\nInvoiceNo: Invoice number. If this code starts with the letter 'c', it indicates a cancellation.\nStockCode: Product code.\nDescription: Product name.\nQuantity: The quantities of each product per transaction.\nInvoiceDate: Invoice date and time.The day and time when a transaction was generated.\nUnitPrice: Unit price. Product price per unit in sterling.\nCustomerID: Customer number.A 5-digit integral number uniquely assigned to each customer.\nCountry: Country name. The name of the country where a customer resides.\n\n\n\n","13bb7c91":"<font color = '#D35400'>\nVariables are as follows after they are cleared of outliers values.","147aa73b":"<font color = '#F1C40F'>\n    \n<a id = \"14\"><\/a><br>\n\n### CLTV Calculated","198de60b":"<font color = '#F1C40F'>\n<p><img style=\"float: right;margin:-10px 20px 20px 5px; max-width:380px\" src=\"https:\/\/www.the-digital-insurer.com\/wp-content\/uploads\/2020\/10\/CLV2-800x655.png\">\n \n\n<a id = \"13\"><\/a><br>\n\n #   What is Customer Lifetime Value(CLV or CLTV)?\n    \n    ","36ad0548":"<font color = '#D35400'>\n    \n<a id = \"20\"><\/a><br>\n\n# Summary\n\n* The result of my analysis is that we can reach customers in different segments and offer them different campaigns.","71b718f3":"\n\n<font color = '#F1C40F'>\n    \n<a id = \"19\"><\/a><br>\n    \n# Result!","06c68fb3":"<font color = '#F1C40F'>\n\n<a id = \"1\"><\/a><br>\n#  CUSTOMER RELAT\u0130ONSH\u0130P MANAGEMENT(CRM) \n<img style=\"float: margin:1000px 50px 50px 1px; max-width:500px\" src=\"https:\/\/www.it-zoom.de\/fileadmin\/user_upload\/a-crm-kunden_gi_istock_gip-1600.jpg\">\n","15a9d7cc":"<font color = '#F1C40F'>\n\n <a id = \"7\"><\/a><br>\n# Data Preprocessing","84b6be24":"<a id = \"17\"><\/a><br>\n### Customer Life Time Value Prediction by Using BG-NBD\n\n\nIn short, expected sales value. Used to estimate how many purchases customers can make over a period of time\n\nThis method computes the probability that a customer with history (frequency, recency_weekly, T_weekly) is currently alive.(relationship between recency & frequency)\n\n<a id = \"18\"><\/a><br>\n### Customer Life Time Value Prediction by Using Gamma-Gamma Models\n\n-conditional expected number of purchases up to time-\n\n**Note1**: There should be no correlation between the **frequency of transactions** and **their monetary value.**\n\n**Note2:** We are considering only customers who made repeat purchases with the business i.e., frequency > 0. Because, if the frequency is 0, it means that they are a one-time customer and are considered already dead.\n","0135cf93":"# Dataset import","7458215d":"<a id = \"16\"><\/a><br>\n What is a cohort model?\n\nInstead of simply assuming all the customers to be one group, we can try to split them into multiple groups and calculate the CLTV for each group. \n\n **Note**: recency value customized. (One of the key differences between RFM and CLTV)","2de1d286":" <font color = '#34495E'>\n\n\n Now, we are creating RFM.\n\n  <a id = \"11\"><\/a><br>\n ### What is RFM?\n<p><img style=\"float: right;margin:-10px 20px 20px 5px; max-width:380px\" src=\"https:\/\/miro.medium.com\/max\/1400\/1*HiwX6vul8c4PBEueq3yBMw.png\"><p>RFM is a method used for analyzing customer value. It is commonly used in database marketing and direct marketing and has received particular attention in retail and professional services industries.RFM stands for the three dimensions:\n\n* Recency \u2013 How recently did the customer purchase?\n* Frequency \u2013 How often do they purchase?\n* Monetary Value \u2013 How much do they spend?\nCustomer purchases may be represented by a table with columns for the customer name, date of purchase and purchase value. One approach to RFM is to assign a score for each dimension on a scale from 1 to 10.\n    \n    * Quelle https:\/\/en.wikipedia.org\/wiki\/RFM_(market_research)\n\n\n\n","e01559ec":"<a id = \"12\"><\/a><br>\nThen segments are created. \n\n**So why are we doing this?**\n\nWe look for answers to these questions;\n\n-Who is our most profitable customer?\n-What is it they appreciate in my products or services?\n-Who are my new customers?\n-How do I attract new customers to the company?\n\nThe answers to the questions are hidden in the segmentation.\n\nWith better RFM segmentation, we\u2019ll be able to address certain segments in a personalized manner, based on their needs and preferences.\n\nBrowse the scheme to more easily understand segmentation.\n","dc6045b8":"\n![](https:\/\/images.squarespace-cdn.com\/content\/v1\/5846da08f5e231d83261e223\/1624227413790-Z1UYINIFMP4SYO77JTWV\/rfm_grid.png) ","d15b2c6b":"<font color = '#D35400'>\nMissing values are deleted. Canceled Invoices are not received and and a new variable was created.","5d26cd66":"\n<font color = '#34495E'>\n\n\n\nCustomer lifetime value (CLV) is a measure of the total income a business can expect to bring in from a typical customer for as long as that person or account remains a client.\n\nWhen measuring CLV, it\u2019s best to look at the total average revenue generated by a customer and the total average profit. Each provides important insights into how customers interact with your business and if your overall marketing plan is working as expected.\n\nFor a more in-depth look, you may want to break down your company\u2019s CLV by quartile or some other segmentation of customers. This can give greater insight into what\u2019s working well with high-value customers, so you can work to replicate that success across your entire customer base.\n    \n  * Quelle https:\/\/www.netsuite.com\/portal\/resource\/articles\/ecommerce\/customer-lifetime-value-clv.shtml\n","cd19351c":"<font color = '#D35400'>\n\nCheck out descriptive statistics of numerical variables. See the difference between 75% and 99% values and then See the difference between 99% and max values. We can think that there are some outliers."}}