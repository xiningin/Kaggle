{"cell_type":{"3f81f2b6":"code","07621bef":"code","f51c396f":"code","68aa2080":"code","6eed1d33":"code","8457d587":"code","6d564d59":"code","f0a58c60":"code","8469f80d":"code","5411178f":"code","dfd08013":"code","d952b0ce":"code","af75a1d0":"code","f8f989f4":"code","eccfad21":"code","5eff2469":"code","286baaab":"code","2eb0b8a0":"code","452b564a":"code","89ffe085":"code","c64ca9bd":"code","d1283ba2":"code","6f0cc515":"code","c103f8db":"code","8cb095af":"code","f0624f74":"code","abb70ce1":"code","f5dbadff":"code","0a6630b8":"code","262f63c8":"code","c83187d3":"code","f29c8a19":"code","970e2b3f":"code","01bcc782":"code","ecd57dd5":"code","24916444":"code","22f93026":"code","9510764e":"code","1018c715":"code","54725baa":"code","0d76b541":"code","55922077":"code","410586fa":"code","2c8aa190":"code","72f43332":"code","cbb78c13":"code","3b5fdd3f":"code","1d40e927":"code","eb0a84e2":"markdown","22df9f5c":"markdown","5eb69dba":"markdown","f0f9d751":"markdown","391bb102":"markdown","d4d3a2e3":"markdown","e4826d51":"markdown","3ca9e782":"markdown","102749c3":"markdown","2cf71d84":"markdown","f5b17e7c":"markdown","9aa2fb05":"markdown","a33d91f5":"markdown","ceea6ffb":"markdown","1cbdc257":"markdown","c5d953fa":"markdown","1393fdc8":"markdown","944bb229":"markdown","410b129c":"markdown","afd41083":"markdown","0deb1ed8":"markdown","8354a8b1":"markdown","a86e527d":"markdown","e29b45dc":"markdown","76c13385":"markdown","22b19764":"markdown","f7ae1195":"markdown","52a808f7":"markdown","f7893ec2":"markdown","6e46dcc5":"markdown","7794cfc9":"markdown","77395ad6":"markdown","e0d4db6d":"markdown","7502a6fa":"markdown","b02caf5c":"markdown","21c13e3d":"markdown","28813bd0":"markdown","7830aeb3":"markdown","df757eb1":"markdown"},"source":{"3f81f2b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07621bef":"import seaborn as sns\nfrom matplotlib import pylab\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score,log_loss\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","f51c396f":"train_df = pd.read_csv('..\/input\/machinehack-ml-merchandise-popularity-prediction\/MPP_Dataset\/Train.csv')\ntest_df = pd.read_csv('..\/input\/machinehack-ml-merchandise-popularity-prediction\/MPP_Dataset\/Test.csv')","68aa2080":"# Make a copy of the dataset\ndata = train_df","6eed1d33":"train_df.head()","8457d587":"test_df.head()","6d564d59":"# Check the shape of train dataset\ntrain_df.shape","f0a58c60":"# Check the shape of test dataset\ntest_df.shape","8469f80d":"# Check the columns in the train dataset\ntrain_df.columns","5411178f":"# Check which columns are having categorical, numerical or boolean values of train dataset\ntrain_df.info()","dfd08013":"# Check which columns are having categorical, numerical or boolean values of test dataset\ntest_df.info()","d952b0ce":"# For more information on the train dataset like total count in all columns\n# min, max values and more information of the respective columns \n\ntrain_df.describe()","af75a1d0":"# For more information on the train dataset like the total count in all the columns\n# min, max values and more information of the respective columns  \n\ntest_df.describe()","f8f989f4":"# check the lenght of test and train dataset\nprint(f'train data length: {train_df.shape[0]}')\nprint(f'test data length: {test_df.shape[0]}')","eccfad21":"# Check for missing values in all the columnns of the train dataset\ntrain_df.isnull().sum()","5eff2469":"# Check for missing values in all the columnns of the test dataset\ntest_df.isnull().sum()","286baaab":"# get unique values in train dataset\ntrain_df.nunique()","2eb0b8a0":"for i in train_df.columns:\n    print(i,':',len(train_df[i].unique()))","452b564a":"# get unique values in test dataset\ntest_df.nunique()","89ffe085":"for i in test_df.columns:\n    print(i,':',len(test_df[i].unique()))","c64ca9bd":"# correlation (pandas)\n\ncorr = train_df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","d1283ba2":"#perfoming correlation matrix Using seaborn\nplt.figure(figsize=(10,5))\nsns.heatmap(corr,cmap='rainbow',annot=True)\nplt.show()","6f0cc515":"# perform scatterplot \ntrain_df_columns = train_df.columns\n# Loop through the different columns\ndef scat_plot(col1,col2):\n    plt.scatter(train_df[col1],train_df[col2])\n    plt.xlabel(col1,fontsize=11,color='r')\n    plt.ylabel(col2,fontsize=11,color='r')\n    plt.show()\n    \n# Loop through numerical data list and use function to scatter plot between two columns \nfor col_i in train_df_columns:\n    for col_j in train_df_columns:\n        if col_i != col_j:\n            scat_plot(col_i,col_j)","c103f8db":"from tqdm import tqdm","8cb095af":"def hist_p(col1): \n    #bins=np.arange(min(train_data[col1]),max(train_data[col1]) + 1,1) \n    plt.hist(train_df[col1],alpha=0.8,edgecolor='g')\n    plt.xlabel(col1,fontsize=11,color='b')\n    plt.show()\n\nfor col_i in tqdm(train_df_columns): \n    hist_p(col_i)","f0624f74":"# creating a dataframe of just numerical values from train_dataset\ntrain_df_for_vif = train_df.drop(['popularity'],axis=1)\n\n# target values from train_dataset\ntarget = train_df['popularity']\n\n# numerical values column names\ntrain_df_columns = train_df_columns[:-1]\ntrain_df_columns","abb70ce1":"(train_df_for_vif.isnull().sum()\/train_df_for_vif.shape[0])*100","f5dbadff":"# droping rows with from new dataframe empty cells\ntrain_df_for_vif = train_df_for_vif.dropna()","0a6630b8":"# import statsmodle library for vif \nimport statsmodels.api as sm","262f63c8":"# loop for calculating VIF for each feature.\nfor count in range(0,len(train_df_for_vif.columns)):\n    # taking one column as target variable\n    one_col = train_df_for_vif.loc[:,train_df_for_vif.columns==train_df_columns[count]]\n    # taking all other remaining columns as fetaure variable\n    all_other_col = train_df_for_vif.loc[:,train_df_for_vif.columns!=train_df_columns[count]]\n    # fiting the OLS model on y and x\n    model = sm.OLS(one_col,all_other_col)\n    model = model.fit()\n    # geting the r^2 value of results\n    r_sqrd = model.rsquared\n    # calculating vif value\n    var_infla_factor = round(1\/(1-r_sqrd),3)\n    print(f': R Square value of [-{train_df_columns[count]}-] column is {round(r_sqrd,3)} keeping all other columns as features')\n    print(f': Variance inflation Factor of [-{train_df_columns[count]}-] column is {var_infla_factor}.\\n')","c83187d3":"# Perform a box plot on Store_Ratio\ntrain_df.boxplot(column='Store_Ratio',figsize=(5,6))\nplt.show()","f29c8a19":"# Perform a box plot on Basket_Ratio\ntrain_df.boxplot(column='Basket_Ratio',figsize=(5,6))\nplt.show()","970e2b3f":"# Perform a box plot on time\ntrain_df.boxplot(column='time',figsize=(5,6))\nplt.show()","01bcc782":"# Perform a box plot on Score_4 \ntrain_df.boxplot(column='Score_4',figsize=(5,6))\nplt.show()","ecd57dd5":"# Perform a box plot on Score_3\ntrain_df.boxplot(column='Score_3',figsize=(5,6))\nplt.show()","24916444":"# Perform a box plot on Score_2\ntrain_df.boxplot(column='Score_2',figsize=(5,6))\nplt.show()","22f93026":"# Perform a box plot on Score_1\ntrain_df.boxplot(column='Score_1',figsize=(5,6))\nplt.show()","9510764e":"# Perform a box plot on Store_Presence\ntrain_df.boxplot(column='Store_Presence',figsize=(5,6))\nplt.show()","1018c715":"# Perform a box plot on Category_2\ntrain_df.boxplot(column='Category_2',figsize=(5,6))\nplt.show()","54725baa":"# Perform a box plot on Category_1\ntrain_df.boxplot(column='Category_1',figsize=(5,6),fontsize=11,color='b')\nplt.show()","0d76b541":"# Perform a box plot on popularity\ntrain_df.boxplot(column='popularity',figsize=(5,6))\nplt.show()","55922077":"for i in train_df.columns:\n    print(i)\n    plt.figure(figsize=(22,8))\n    sns.countplot(train_df[i],palette='rainbow')\n    plt.show()","410586fa":"# Loop through the different columns\ndef point_plot(col1,col2):\n    print(f'{col1}-{col2}')\n    plt.figure(figsize=(22,8))\n    sns.pointplot(train_df[col1],train_df[col2],palette='rainbow')\n    plt.xlabel(col1,fontsize=15,color='r')\n    plt.ylabel(col2,fontsize=15,color='r')\n    plt.show()\n    \n# Loop through numerical data list and use function to scatter plot between two columns \nfor col_i in train_df_columns:\n    for col_j in train_df_columns:\n        if col_i != col_j:\n            point_plot(col_i,col_j)","2c8aa190":"#Perform distplot for all the columns in dataset\nfor col in train_df_columns:\n    print(f'### {col} ####\\n')\n\n    fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(22,8))\n    sns.distplot(train_df[col],ax=ax[0],color='b')\n    sns.distplot(train_df[col],ax=ax[2],rug=True,hist=False)\n    sns.kdeplot(train_df[col],ax=ax[1],shade=True,color=\"r\")\n\n    plt.show()","72f43332":"import scipy\nfrom scipy import stats\nfrom scipy.cluster import hierarchy","cbb78c13":"# droping the NaN values if any\ntrain_data_no_nan = train_df.dropna()\n\n# Plot a Dendrogram on the columns of the dataset\ncorr = np.round(scipy.stats.spearmanr(train_data_no_nan).correlation,4)\ncorr_condensed = hierarchy.distance.squareform(1-corr) # non -ve val and compresed\n\nplt.figure(figsize=(14,9))\nhierarchy.dendrogram(hierarchy.linkage(corr_condensed,method='average'),\n                     labels=train_data_no_nan.columns,orientation='left',leaf_font_size=15)\nplt.show()","3b5fdd3f":"# Loop through the different columns\ndef boxen_plot(col1,col2):\n    print(f'{col1}-{col2}')\n    plt.figure(figsize=(22,8))\n    sns.boxenplot(train_df[col1],train_df[col2],palette='rainbow')\n    plt.xlabel(col1,fontsize=15,color='r')\n    plt.ylabel(col2,fontsize=15,color='r')\n    plt.show()\n    \n# Loop through numerical data list and use function to scatter plot between two columns \nfor col_i in train_df_columns:\n    for col_j in train_df_columns:\n        if col_i != col_j:\n            boxen_plot(col_i,col_j)","1d40e927":"# Loop through the different columns\ndef violin_plot(col1,col2):\n    print(f'{col1}-{col2}')\n    plt.figure(figsize=(22,8))\n    sns.violinplot(train_df[col1],train_df[col2],palette='rainbow')\n    plt.xlabel(col1,fontsize=15,color='r')\n    plt.ylabel(col2,fontsize=15,color='r')\n    plt.show()\n    \n# Loop through numerical data list and use function to scatter plot between two columns \nfor col_i in train_df_columns:\n    for col_j in train_df_columns:\n        if col_i != col_j:\n            violin_plot(col_i,col_j)","eb0a84e2":"`Observation:`\n\n* Data distribution of store presence is bimodal\n* Score_2, score 1, score3 and time data distribution is skewed left\n* Store score and popularity data distribution is skewed right\n* distribution of basket ratio, carwgort 1 is multimodal\n* distribution of store eatio is bimodal and skewed","22df9f5c":"# Dendrogram\nDendrogram is a visual representation of compound correlation data \n\nIndividual compounds are arranged along the bottom of dendrogram and referred to as leaf nodes <br>\n\nCompound clusters are formed by joining individual compounds or existing compound clusters with the join point referred to as a node","5eb69dba":"# EDA\n# CORRELATION MATRIX What? |Why? | How?\nIts is a table showing correlation coefficients between variables\n\n\nThree broad reasons for computing a correlation matrix:\n\n* `To summarize a large amount of data where goal is to see patterns`. In our case observable pattern is that all variables highly correlate with each other\n* `To input into other analyses` Say: people commonly use correlation matrixes as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise\n* `As a diagnostic when checking other analyses` Say: with linear regression, a high amount of correlations suggests that the linear regression estimates will be unreliable\n","f0f9d751":"`Observations`\n* As value of store presence increases value of basket ratio decreases\n* As value of store scrore increases value of basket ratio increases\n* Increase in value of store ratio results in the increase of basket ratio's value","391bb102":"Run this notebook to observe all EDA","d4d3a2e3":"`Score_4`\n\n1. 25% of  score 4 have value between range 40 to 90\n2. 25% of score 4 have value between range 90 to 125\n3. 25% of score 4 have value between range 125 to 140\n4. 25% of score 4 have value between range 140 to 200\n\nMean Score_4 is around less then 125","e4826d51":"`Score_2`\n\n1. 25% of  score2 have value between range 0 to 0.1\n2. 25% of score2 have value between range 0.1 to 0.12\n3. 25% of score2 have value between range 0.12 to 0.18\n4. 25% of score2 have value between range 0.18 to 1\n\nMean Score_2 is around 0.12","3ca9e782":"`Observation:`\n* Store_Ratio is strongly correlated with Basket_Ratio,Store_Score,score3,store presence,score1\n* Basket_Ratio is correlatd to store score, store presence, score1 score3.\n* Category_1 is correlated with category2\n* Store_Presence is correlated with score1,score2,score3,popularity\n* Score_1 is correlated with score3,score4,time,popularity","102749c3":"Trying to Predict popularity from all other data of dataset like Store_Ratio, Basket Ratio, Store Score\n\n`NOTE`:<br>\n* Big Brands spend a significant amount on popularizing a product\n* Their efforts go in vain while establishing merchandise in hyperlocal market(process of targeting prospective customers in a highly specific, geographically restricted area, sometimes just a few blocks or streets, often with intention of targeting people conducting \"near me\" searches on their mobile devic)\n* Based on different geographical conditions same attributes can communicate a piece of much different information about customer\n\n`So undestanding these insights are a must for any brand owner`","2cf71d84":"# Get total number of samples in the dataset using the len() function","f5b17e7c":"# Histogram Why?\n* Gives an approximate representation of distribution of numerical data\n\nTo construct a histogram steps:\n1. \"bin\" (or \"bucket\") range of values\u2014that divides entire range of values into a series of intervals\n2. count how many values fall into each interval\n\nWords used to describe patterns in a histogram are: `\"symmetric\", \"skewed left\" or \"right\", \"unimodal\", \"bimodal\" or \"multimodal\"`","9aa2fb05":"# SCATTER PLOT\nUses Cartesian coordinates to display values for typically two variables for a set of data\n\n* Data are displayed as a collection of points, each having value of one variable determining position on horizontal axis and value of other variable determining position on vertical axis\n\n\n`Scatter plot's are used to observe and show relationships between two numeric variables`\n\n","a33d91f5":"`Score_1`\n\n1. 25% of  score1 have value between range 0 to 0.0\n2. 25% of score1 have value between range 0.0 to 0.0\n3. 25% of score1 have value between range 0.0 to 0.9\n4. 25% of score1 have value between range 0.9 to 1\n\nMean score1 is around 0.0","ceea6ffb":"`Observation:`\n\n* distribution of store ratio, store presence, score3 and popularity are right skewed\n* distribution of basket ratio, score2 and time are skewed left\n* distribution of category 1 is multimodal\n* distribution of category2 and score1 are bimodal","1cbdc257":"# Point Plot\n* Uses scatter plot glyphs to visualize features like point estimates and confidence intervals\n* Uses scatter plot points to represent the central tendency of numeric data\n* These plots make use of error bars to indicate any uncertainty around the numeric","c5d953fa":"`Basket_Ratio`\n\n1. 25% of  basket ratio have value between range 0 to 0.2\n2. 25% of basket ratio have value between range 0.4 to 0.52\n3. 25% of basket ratio have value between range 0.52 to 0.78\n4. 25% of basket ratio have value between range 0.78 to 1\n\nMean basket ratio is around 0.52","1393fdc8":"># 1- Preprocessing\n># 2- Scaling\n># 3- Modelling\n># 4- Comparing n models","944bb229":"# Boxenplot\n* Otherwise known as a Letter-value plot, is a box plot meant for large data sets (n > 10,000)\n* Very similar to box plot, except for the fact that it plots different quartile values\n* By plotting different quartile values, we are able to understand the shape of the distribution particularly in head end and tail end","410b129c":"* `object` - String values\n* `float64` - Numerical values\n* `int64` - Numerical values\n\n\n\n`Observation`<br>\nThere are no String values so there are no categorical data","afd41083":"* `target`: popularity","0deb1ed8":"`Category_2`\n\n1. 25% of  category2 have value between range 0 to 0.0\n2. 25% of category2 have value between range 0.0 to 0.1\n3. 25% of category2 have value between range 0.1 to 0.1\n4. 25% of category2 have value between range 0.1 to 1\n\nMean Category_2 is around 0.1","8354a8b1":"# I will continue rest of this part in => [second notebook](https:\/\/www.kaggle.com\/mukeshmanral\/2-diff-model-merchandise-popularity\/edit)","a86e527d":"# DistPlot\nDistplot represents univariate distribution of data i.e. data distribution of a variable against density distribution","e29b45dc":"[Why boxen not box](https:\/\/stackoverflow.com\/questions\/52403381\/how-boxen-plot-is-different-from-box-plot)","76c13385":"# Variance inflation factor (VIF) Why?\n* It quantifies extent of correlation between one predictor and other predictors in a model\n* It is used for diagnosing collinearity\/multicollinearity\n* Higher values signify that it is difficult or impossible to assess accurately contribution of predictors to a model","22b19764":"* There is no missing values in this dataset","f7ae1195":"`Score_3`\n\n1. 25% of  score3 have value between range 0 to 0.2\n2. 25% of score3 have value between range 0.2 to 0.4\n3. 25% of score3 have value between range 0.4 to 0.62\n4. 25% of score3 have value between range 0.62 to 1\n\nMean Score_3 is around 0.4","52a808f7":"# Box Plot\nA boxplot is a standardized way of displaying the dataset based on a five-number summary:\n\n1. Minimum (Q0 or 0th percentile): the lowest data point excluding any outliers.\n\n2. Maximum (Q4 or 100th percentile): the largest data point excluding any outliers.\n\n3. Median (Q2 or 50th percentile): the middle value of the dataset.\n\n4. First quartile (Q1 or 25th percentile): also known as the lower quartile qn(0.25), is the median of the lower half of the dataset.\n\n5. Third quartile (Q3 or 75th percentile): also known as the upper quartile qn(0.75), is the median of the upper half of the dataset","f7893ec2":"`time`\n\n1. 25% of  time have value between range 0 to 0.2\n2. 25% of time have value between range 0.2 to 0.25\n3. 25% of time have value between range 0.25 to 0.3\n4. 25% of time have value between range 0.3 to 0.4\n\nMean time is around 0.25","6e46dcc5":"`Strongly correlated variables`\n\n* score3 and store ratio\n* store score and basket ratio\n* score1 and store presence","7794cfc9":"# Violin Plot\n* Used in plotting of numeric data\n* Similar to box plots, except that they also show the probability density of the data at different values, usually smoothed by a kernel density estimator\n\nIt has:\n\n1. Median (a white dot on the violin plot)\n2. Interquartile range (the black bar in the center of violin)\n\n3. The lower\/upper adjacent values (the black lines stretched from the bar) \u2014 defined as first quartile \u2014 1.5 IQR and third quartile + 1.5 IQR respectively.","77395ad6":"* `object` - String values\n* `float64` - Numerical values\n* `int64` - Numerical values\n\n\n\n`Observation`<br>\nThere are no String values so there are no categorical data","e0d4db6d":"# Counting the total number of missing values\n\n","7502a6fa":"`Store_Ratio`\n\n1. 25% of  store ratio have value between range 0 to 0.4\n2. 25% of store ratio have value between range 0.4 to 0.6\n3. 25% of store ratio have value between range 0.6 to 0.7\n4. 25% of store ratio have value between range 0.7 to 1\n\nMean store ratio is around 0.58","b02caf5c":"`Category_1`\n\n1. 25% of  category1 have value between range 0 to 0.2\n2. 25% of category1 have value between range 0.2 to 0.5\n3. 25% of category1 have value between range 0.5 to 0.8\n4. 25% of category1 have value between range 0.8 to 1\n\nMean Category_1 is around 0.5","21c13e3d":"`Observations:`\n\nthere is colinearity\/multicolinearity between variables as the VIF value is almost upto 2.5\n\nStore_Ratio, Basket_Ratio, Category_1, Store_Score, Category_2, Store_Presence, Score_1, Score_2, Score_3, Score_4, time they all have colinearity with all the variables","28813bd0":"# Get unique values","7830aeb3":"`Store_Presence`\n\n1. 25% of  store presence have value between range 0 to 0.35\n2. 25% of store presence have value between range 0.35 to 0.42\n3. 25% of store presence have value between range 0.42 to 0.95\n4. 25% of store presence have value between range 0.95 to 1\n\nMean store presence is around 0.42","df757eb1":"# Count Plot\n* Kind of histogram or a bar graph for some categorical area\n* It simply shows number of occurrences of an item based on a certain type of category"}}