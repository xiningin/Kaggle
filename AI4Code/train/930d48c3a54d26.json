{"cell_type":{"bb6feb11":"code","2c907893":"code","ee35a88e":"code","10f60901":"code","dbc3b250":"code","b38ac36c":"code","f2257f3a":"code","91cbfbd2":"code","7d4b5ecd":"code","8f1f3b59":"code","75845875":"markdown","39beef7e":"markdown","94d2b4e3":"markdown","a46b9688":"markdown","be6d10a3":"markdown","0bc0cfff":"markdown","ab54aa0b":"markdown","c50e3803":"markdown"},"source":{"bb6feb11":"import numpy as np # for arrays and algebra\nimport pandas as pd # for data processing\n\n#For visualising data\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n#For Data Preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import  train_test_split\n\n\n\n\nimport os #for operating system operations\nprint(os.listdir(\"..\/input\")) #Here we list the files in input folder\n","2c907893":"dataset=pd.read_csv(\"..\/input\/train.csv\")#We read our data\ntest_set=pd.read_csv(\"..\/input\/test.csv\")\n\n\n","ee35a88e":"dataset.head()","10f60901":"test_set.head()","dbc3b250":"dataset=dataset.filter([\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"])\n\ntest_id=test_set.iloc[:,0].values\ntest_set=test_set.filter([\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"])\ntest_id","b38ac36c":"le=LabelEncoder()\ndataset.iloc[:,2]=le.fit_transform(dataset.iloc[:,2])\n\ndataset[\"Age\"].fillna(dataset[\"Age\"].mean(),inplace=True)\ndataset['Cabin'] = dataset['Cabin'].apply(lambda x: 1 if not pd.isnull(x) else 0)\n\ndef Embark(x):\n    if x==\"C\":\n        return 0\n    elif x==\"S\":\n        return 1\n    elif x==\"Q\":\n        return 2\n    else:\n        return 3\n\ndataset[\"Embarked\"]=dataset[\"Embarked\"].apply(Embark)\ndataset.head()\n","f2257f3a":"le=LabelEncoder()\ntest_set.iloc[:,1]=le.fit_transform(test_set.iloc[:,1])\n\ntest_set[\"Age\"].fillna(test_set[\"Age\"].mean(),inplace=True)\ntest_set['Cabin'] = test_set['Cabin'].apply(lambda x: 1 if not pd.isnull(x) else 0)\n\ndef Embark(x):\n    if x==\"C\":\n        return 0\n    elif x==\"S\":\n        return 1\n    elif x==\"Q\":\n        return 2\n    else:\n        return 3\n\ntest_set[\"Embarked\"]=test_set[\"Embarked\"].apply(Embark)\n\ntest_set.head()","91cbfbd2":"X=dataset.iloc[:,1:]\nY=dataset.iloc[:,0]\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33)","7d4b5ecd":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nknn=KNeighborsRegressor(n_neighbors=3)\nknn.fit(x_train,y_train)\nknn_pred=np.round(knn.predict(x_test))\nknn_cm=confusion_matrix(y_test,knn_pred)\nknn_acc=(knn_cm[0][0]+knn_cm[1][1])\/(knn_cm[0][0]+knn_cm[1][1]+knn_cm[0][1]+knn_cm[1][0])\n\nlr=LinearRegression()\nlr.fit(x_train,y_train)\nlr_pred=np.round(lr.predict(x_test))\nlr_cm=confusion_matrix(y_test,lr_pred)\nlr_acc=(lr_cm[0][0]+lr_cm[1][1])\/(lr_cm[0][0]+lr_cm[1][1]+lr_cm[0][1]+lr_cm[1][0])\n\nlor=LogisticRegression()\nlor.fit(x_train,y_train)\nlor_pred=np.round(lor.predict(x_test))\nlor_cm=confusion_matrix(y_test,lor_pred)\nlor_acc=(lor_cm[0][0]+lor_cm[1][1])\/(lor_cm[0][0]+lor_cm[1][1]+lor_cm[0][1]+lor_cm[1][0])\n\nsvr=SVR(kernel=\"rbf\")\nsvr.fit(x_train,y_train)\nsvr_pred=np.round(svr.predict(x_test))\nsvr_cm=confusion_matrix(y_test,svr_pred)\nsvr_acc=(svr_cm[0][0]+svr_cm[1][1])\/(svr_cm[0][0]+svr_cm[1][1]+svr_cm[0][1]+svr_cm[1][0])\n\nrf=RandomForestRegressor(n_estimators=10)\nrf.fit(x_train,y_train)\nrf_pred=np.round(rf.predict(x_test))\nrf_cm=confusion_matrix(y_test,rf_pred)\nrf_acc=(rf_cm[0][0]+rf_cm[1][1])\/(rf_cm[0][0]+rf_cm[1][1]+rf_cm[0][1]+rf_cm[1][0])\n\nxgb=XGBRegressor()\nxgb.fit(x_train,y_train)\nxgb_pred=np.round(xgb.predict(x_test))\nxgb_cm=confusion_matrix(y_test,xgb_pred)\nxgb_acc=(xgb_cm[0][0]+xgb_cm[1][1])\/(xgb_cm[0][0]+xgb_cm[1][1]+xgb_cm[0][1]+xgb_cm[1][0])\n\nprint(knn_acc)\nprint(lr_acc)\nprint(lor_acc)\nprint(svr_acc)\nprint(rf_acc)\nprint(xgb_acc)","8f1f3b59":"classifier=XGBRegressor()\nclassifier.fit(X,Y)\n\nresult=np.round(classifier.predict(test_set))\nresult\n\ndata=list(zip(test_id,result))\nsubmission=pd.DataFrame(data=data,columns=[\"PassengerId\",\"Survived\"])\nsubmission.to_csv(\"result.csv\",index=False)\n","75845875":"<h3>Data Preprocessing<\/h3>\n<p>First we should eliminate the columns that will cause overfitting.<\/p>","39beef7e":"<h3>Importing Data<\/h3>","94d2b4e3":"Lastly, we should split our data.","a46b9688":"<h2>Goal<\/h2>\n<p>Here we will analyze data of survivors from Titanic and predict whether other people will survive or not<\/p>","be6d10a3":"As we can see from the results, XGBoost algorithm is best for our problem. Now we will create another model and predict our actual data.","0bc0cfff":"<h3>Model Building<\/h3>\n<p>Here we will build a KNN model and train it.<\/p>","ab54aa0b":"<h3>Importing Libraries<\/h3>","c50e3803":"<p>Then we should overcome the categorical and missing values<\/p>"}}