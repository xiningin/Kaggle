{"cell_type":{"b1f11bc6":"code","6d707fa8":"code","e9f6229b":"code","7b329dbe":"code","5ce7d1a6":"code","7e61570e":"code","5a49fdd0":"code","9e854b02":"code","7f116044":"code","4b5af2ba":"code","3ec02348":"code","6b9cfa62":"code","1d9a6ae9":"code","180bb36d":"code","5d3957e6":"code","87e9162a":"code","e5cf594f":"code","56c43a42":"code","ca9304f8":"code","0ed17f23":"code","2b09ff2c":"code","38f564f4":"code","6c1d5ad9":"code","d6cf34ba":"code","45efeb02":"code","85d18b07":"markdown","b737d17a":"markdown","930dd067":"markdown","1b08a200":"markdown","28547ae5":"markdown","59a39439":"markdown","09c915eb":"markdown","d97374b3":"markdown","40526dc4":"markdown","e5044bba":"markdown","b0db50a1":"markdown","e401ff01":"markdown","f3b66980":"markdown","81cb18df":"markdown","2e48962d":"markdown","7f257309":"markdown","354cde2c":"markdown","632e7b67":"markdown","5839cfcf":"markdown","1168ee6b":"markdown","5532bcd9":"markdown","aee72a65":"markdown","a3943c37":"markdown","fb6a238a":"markdown","048e8aa7":"markdown"},"source":{"b1f11bc6":"import dython.nominal as dm\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nplt.style.use('seaborn')\npd.set_option(\"display.max_rows\", 100)","6d707fa8":"data = pd.read_csv(\"..\/input\/pulsar_stars.csv\")\ndata.columns = ['mean_ip', 'sd_ip', 'ek_ip', 'skw_ip', 'mean_dm', 'sd_dm', 'ek_dm', 'skw_dm', 'pulsar']\ndata.head()","e9f6229b":"data.describe()","7b329dbe":"def donut_chart(data):\n    fig, ax = plt.subplots(figsize=(12, 8), subplot_kw=dict(aspect=\"equal\"))\n\n    recipe = [str(i) for i in list(data.value_counts().index)]\n\n    info = data.value_counts()\n\n    def pcts(val_list):\n        pct = []\n        for val in val_list:\n            pct.append(\" ({:.1f}k obs - {:.1f}%)\".format(val\/1000, 100*val\/np.sum(val_list)))\n        return pct\n\n    recipe2 = pcts(info)\n\n    wedges, texts = ax.pie(info, wedgeprops=dict(width=0.5), startangle=-40)\n\n    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n    kw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n              bbox=bbox_props, zorder=0, va=\"center\")\n\n    for i, p in enumerate(wedges):\n        ang = (p.theta2 - p.theta1)\/2. + p.theta1\n        y = np.sin(np.deg2rad(ang))\n        x = np.cos(np.deg2rad(ang))\n        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n        connectionstyle = f\"angle,angleA=0,angleB={ang}\"\n        kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n        kw[\"color\"] = 'k'\n        ax.annotate(recipe[i]+recipe2[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n                     horizontalalignment=horizontalalignment, **kw)\n\n    ax.set_title(\"Proportion of classes\")\n    plt.show()\n    \ndonut_chart(data['pulsar'])","5ce7d1a6":"from matplotlib import colors\n\npreds = [col for col in data.columns if col != \"pulsar\"]\nnum_preds = len(preds)\nfig, axes = plt.subplots(num_preds, 2, figsize=(10,20))\n\nfor i, j in itertools.zip_longest(preds, range(num_preds)):\n    N, bins, patches = axes[j, 0].hist(data[i], bins=\"auto\", density=True)\n    axes[j, 0].set_title(f\"PDF of {i}\")\n    \n    axes[j, 0].axvline(data[i].mean(), color = \"c\", linestyle=\"dashed\", label=\"mean\", linewidth=3)\n    axes[j, 0].axvline(data[i].std(), color = \"m\", linestyle=\"dotted\", label=\"std\", linewidth=3)\n    axes[j, 0].legend((\"mean\", \"std\"), loc=\"best\")\n    \n    fracs = N \/ N.max()\n    norm = colors.Normalize(fracs.min(), fracs.max())\n\n    for thisfrac, thispatch in zip(fracs, patches):\n        color = plt.cm.plasma(norm(thisfrac))\n        thispatch.set_facecolor(color)\n    \n    axes[j, 1].hist(data[i], bins=\"auto\", cumulative=True, density=True)\n    axes[j, 1].set_title(f\"CDF of {i}\")\n\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\nplt.show()","7e61570e":"pulsars = data[data['pulsar'] == 1].drop('pulsar', axis=1)\nnon_pul = data[data['pulsar'] == 0].drop('pulsar', axis=1)\n\nfig, axes = plt.subplots(num_preds, 2, figsize=(10,20))\n\nfor i, j in itertools.zip_longest(preds, range(num_preds)):\n    axes[j, 0].hist(pulsars[i], bins=\"auto\", label=\"pulsars\", color = \"g\", alpha=0.5, density=True)\n    axes[j, 0].hist(non_pul[i], bins=\"auto\", label=\"non-pulsars\", color = \"r\", alpha=0.5, density=True)\n    axes[j, 0].set_title(f'PDF comparison for {i}')\n    axes[j, 0].legend(loc=\"best\")\n    \n    axes[j, 1].hist(pulsars[i], bins=\"auto\", label=\"pulsars\", color = \"g\", alpha=0.5)\n    axes[j, 1].hist(non_pul[i], bins=\"auto\", label=\"non-pulsars\", color = \"r\", alpha=0.5)\n    axes[j, 1].set_title(f'Frequency comparison for {i}')\n    axes[j, 1].legend(loc=\"best\")\n\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\nplt.show()","5a49fdd0":"plt.figure(figsize=(15,25))\n\nfor i in range(num_preds):\n    plt.subplot(10,1,i+1)\n    sns.violinplot(x=data['pulsar'],y=data.iloc[:, i],\n                   palette=sns.color_palette(\"hls\", 7),alpha=.5)\n    plt.title(data.columns[i])\n    \nplt.tight_layout()\nplt.show()","9e854b02":"plt.figure(figsize=(13,25))\n\nfor i in range(num_preds):\n    plt.subplot(10,1,i+1)\n    sns.boxplot(data['pulsar'],y=data.iloc[:, i], \n                palette=sns.color_palette(\"husl\", 7), color=\"w\")\n    plt.title(data.columns[i])\n    \nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\nplt.show()","7f116044":"g = sns.pairplot(data,hue=\"pulsar\")\nplt.show()","4b5af2ba":"correlation = data.corr()\nax = sns.heatmap(correlation, annot=True, cmap=sns.color_palette(\"pastel\"),\n                 linewidth=2,edgecolor=\"k\")\nplt.title(\"Correlation Between Features\")\nplt.show()","3ec02348":"corr_ratios = [dm.correlation_ratio(data['pulsar'], data[pred]) for pred in preds]\ndf_cr = pd.DataFrame({'feature': preds, 'correlation_ratio':corr_ratios})\n\nax = sns.barplot(x=\"correlation_ratio\", y=\"feature\", data=df_cr)\nax.set_title(\"Correlation Ratio for features\")\nplt.show()","6b9cfa62":"def get_outliers(feature):\n    data_out = data[feature]\n    q1 = data_out.quantile(0.25)\n    q3 = data_out.quantile(0.75)\n    iqr = q3 - q1\n\n    out_l = data_out[data_out < (q1 - 1.5*iqr)].index\n    out_r = data_out[data_out > (q3 + 1.5*iqr)].index\n    \n    return(iqr, out_l, out_r)","1d9a6ae9":"def print_outlier_group():\n    for i in preds:\n        print(f'Predictor: {i}\\n')\n\n        iqr, out_l, out_r = get_outliers(i)\n\n        full_count = pd.DataFrame()\n\n        lower_count = data.iloc[out_l].groupby('pulsar').size().to_frame('lower_count')\n        upper_count = data.iloc[out_r].groupby('pulsar').size().to_frame('upper_count')\n\n        if not lower_count.empty:\n            lower_count['lower_ratio'] = lower_count\/lower_count.sum()\n        else:\n            lower_count['lower_ratio'] = np.nan\n        if not upper_count.empty:\n            upper_count['upper_ratio'] = upper_count\/upper_count.sum()\n        else:\n            upper_count['upper_ratio'] = np.nan\n\n        full_count = pd.concat([lower_count, upper_count], axis=1)\n        print(full_count)\n        print('\\n======\\n')\n\nprint_outlier_group()","180bb36d":"def update_outlier_dict(ou, out_list, label, i):\n    for elem in list(out_list):\n        if ou.get(elem) is None:\n            ou.update({elem: dict.fromkeys(preds, None)})\n        ou.get(elem).update({i: label})\n        \ndef print_outliers_df():\n    ou = {}\n    for i in preds:\n        iqr, out_l, out_r = get_outliers(i)\n        \n        update_outlier_dict(ou, out_l, \"L\", i)\n        update_outlier_dict(ou, out_r, \"R\", i)\n\n    df = pd.DataFrame.from_dict(ou, orient='index')\n    df['count'] = df.count(axis=1)\n    df['pulsar'] = data['pulsar'].iloc[df.index]\n    #print(df.groupby('pulsar').size().to_frame('count_r'))\n    print(df.sort_values('count', ascending=False))\n    #print(df.groupby('count').size())\n    plt.hist(df[df['pulsar']==0]['count'], bins='auto', color = \"m\", alpha=0.5)\n    plt.hist(df[df['pulsar']==1]['count'], bins='auto', color = \"y\", alpha=0.5)\n    plt.legend(labels=['non-pulsars', 'pulsars'])\n    plt.title(\"Frequency of observations that are outliers for x features\")\n    plt.xlabel(\"Number of features\")\n    plt.ylabel(\"Frequency of observations\")\n    plt.show()\n\nprint_outliers_df()","5d3957e6":"from sklearn.preprocessing import RobustScaler\n\nfloat_data = data[preds].astype(np.float64)\nrobust_trans = RobustScaler().fit(float_data)\nrobust_data = pd.DataFrame(robust_trans.transform(data[preds]), \n                     columns= ['mean_ip', 'sd_ip', 'ec_ip', \n                               'sw_ip', 'mean_dm', 'sd_dm', \n                               'ec_dm', 'sw_dm'])\n\nrobust_data.describe()","87e9162a":"from sklearn.decomposition import PCA\n\npca_all = PCA()\npca_all.fit(robust_data)\n\ncum_var = (np.cumsum(pca_all.explained_variance_ratio_))\nn_comp = [i for i in range(1, pca_all.n_components_ + 1)]\n\nax = sns.pointplot(x=n_comp, y=cum_var)\nax.set(xlabel='# components', ylabel='cumulative explained variance')\nplt.show()","e5cf594f":"pca_2 = PCA(2)\npca_2.fit(robust_data)\ndata_2pc = pca_2.transform(robust_data)\n\nax = sns.scatterplot(x=data_2pc[:,0], \n                     y=data_2pc[:,1], \n                     hue=data['pulsar'],\n                     palette=sns.color_palette(\"muted\", n_colors=2))\n\nax.set(xlabel='1st PC', ylabel='2nd PC', title='Scatterplot for first two Principal Components')\nplt.show()","56c43a42":"from mpl_toolkits.mplot3d import Axes3D\n\npca_3 = PCA(3)\npca_3.fit(robust_data)\ndata_3pc = pca_3.transform(robust_data)\n\npulsar_index = list(pulsars.index)\nnon_pulsar_index = list(non_pul.index)\n\nx = data_3pc[:,0]\ny = data_3pc[:,1]\nz = data_3pc[:,2]\n\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot(111, projection='3d')\n\nax.scatter(np.take(x, pulsar_index), \n           np.take(y, pulsar_index), \n           np.take(z, pulsar_index),\n           edgecolors='none', color='g',\n           alpha=0.8, label='pulsar')\n\n\nax.scatter(np.take(x, non_pulsar_index), \n           np.take(y, non_pulsar_index), \n           np.take(z, non_pulsar_index),\n           edgecolors='none', color='r',\n           alpha=0.8, label='non-pulsar')\n\nax.set_xlabel(\"1st PC\", fontsize=20)\nax.set_ylabel(\"2nd PC\", fontsize=20)\nax.set_zlabel(\"3rd PC\", fontsize=20)\nax.legend(fontsize=\"xx-large\")\nplt.show()","ca9304f8":"X = data[preds]\ny = data[['pulsar']]","0ed17f23":"from sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate\n\ndef eval_model(model):\n    pipe = make_pipeline(RobustScaler(), model)\n    cv_results = cross_validate(pipe, X, y.values.ravel(), cv=3, scoring=('balanced_accuracy',\n                                                                           'recall'))\n    \n    print(\"=== Mean Test Results for {} ===\".format(type(model).__name__))\n    print(\"BALANCED ACCURACY: {:.3f}\".format(cv_results.get('test_balanced_accuracy').mean()))\n    print(\"RECALL: {:.3f}\".format(cv_results.get('test_recall').mean()))\n","2b09ff2c":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), \n                                                    test_size=0.1, random_state=0,\n                                                    stratify=y)\n\ntuned_parameters = {\n    'n_neighbors': [3, 5, 11, 19],\n    'weights': ['uniform', 'distance'],\n    'metric': ['euclidean', 'manhattan']\n}\n\nrob_scal = RobustScaler()\nrob_scal.fit(X_train)\nX_train = rob_scal.transform(X_train)\n\nclf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=3, scoring='balanced_accuracy')\nclf.fit(X_train, y_train)\n\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\n\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f (+\/-%0.03f) for %r\" % (mean, std * 2, params))","38f564f4":"from sklearn.metrics import balanced_accuracy_score\n\nknn_tuning = KNeighborsClassifier(3, weights='distance', metric='euclidean')\nknn_tuning.fit(X_train, y_train)\nX_test = rob_scal.transform(X_test)\nknn_tuning_preds = knn_tuning.predict(X_test)\n\nprint(balanced_accuracy_score(y_test, knn_tuning_preds))","6c1d5ad9":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n \ngnb = GaussianNB()\nlogit = LogisticRegression(solver='liblinear', class_weight='balanced')\nknn = KNeighborsClassifier(3, weights='distance', metric='euclidean')\nxgb = XGBClassifier()\n\nclassifiers = [gnb, logit, knn, xgb]\n\nfor classifier in classifiers:\n    eval_model(classifier)","d6cf34ba":"def eval_model_pca(model):\n    pipe = make_pipeline(RobustScaler(), PCA(3), model)\n    cv_results = cross_validate(pipe, X, y.values.ravel(), cv=3, scoring=('balanced_accuracy',\n                                                                           'recall'))\n    \n    print(\"=== Mean Test Results for {} ===\".format(type(model).__name__))\n    print(\"BALANCED ACCURACY: {:.3f}\".format(cv_results.get('test_balanced_accuracy').mean()))\n    print(\"RECALL: {:.3f}\".format(cv_results.get('test_recall').mean()))\n","45efeb02":"classifiers = [gnb, logit, knn, xgb]\n\nfor classifier in classifiers:\n    eval_model_pca(classifier)","85d18b07":"Classes are heavily unbalanced, which means we will need a stratified splitting strategy latter on for the classification algorithms.\n\nNext, let's check the PDF and CDF for each feature:","b737d17a":"One of the algorithms used is a KNN, which needs some hyperparameter tuning. Let's do that:","930dd067":"Let's use PCA to reduce the dimension of this problem. Before doing this the data should be scaled so PCA doesn't interpret one feature as having more variance due to its scale.\n\nSince we decided to leave outliers untouched a standard scaler would perfom badly. A robust scaler is used instead:","1b08a200":"Indeed, we can see that the distributions present outliers. In cases such as for skw_ip or mean_dm the effect of outliers is very extreme. \n\nWe need to determine what to do with these observations.\n\nLet's check the distributions, comparing the two classes for every feature:","28547ae5":"Some variables are very closely correlated with others, because of this, regularization should be considered during the defition of the classifiers. Also, dimension reduction techniques such as PCA might come in handy.","59a39439":"To end the exploratory analysis, let's create a barplot with the correlation ratio for each feature with respect to the response variable. \n\nThis is a metric that tries to capture the \"correlation\" between continuous and categorical variables.\n\nThe bigger the correlation ratio, the more info of a given class we can get from a given feature.","09c915eb":"In most of the cases there seems to be a correlation between the proportion of either left or right outliers and the class we are trying to predict. \n\nThis seems to indicate that the outliers contain information about the class to which a celestial object belongs.\n\nTo dive even deeper into this, let's create a dataframe that for every observation contains the info of it being a left or right outlier for every feature, as well as the total count of features in which it is an outlier and the class it belongs to.","d97374b3":"The reason why we did a train test split is to have a separate split of the data in which we can test the selected hyperparameters. If all of the data was used, we would have leaked info and that should be avoided.\n\nSeems that the best configuration is {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}. \n\nHowever all scores are quite similar, which indicates the KNN classifier is insensitive to tuning for this particular problem.\n\nLet's check for overfitting:","40526dc4":"Now we compare the different classifiers:","e5044bba":"Logistic regression is the clear winner for this problem, presenting the max score for the two metrics. \n\nNow let's use PCA (with 3 components, as it explains most of the variance) as an intermediate transform to see if prediction can be improved by removing noise from the data:","b0db50a1":"# Exploratory Analysis","e401ff01":"# Pulsar Star Detection\n\nHi! Thanks for checking this notebook. \n\nCan we predict a pulsar star in the universe? \n\nLet's use the HTRU2 dataset and ML techniques to find out!","f3b66980":"Now we'll focus our attention in the outliers since they seem to be predominant across the dataset. We want to know what to do with them, should we drop or keep them?\n\nFirst let's define a function that returns a tuple containing the interquantile range, the list of \"left\" outliers (values much smaller than the others in the distribution) and the list of \"right\" outliers (values much greater than the others) for a given pandas series:","81cb18df":"With few components we can explain most of the variance of the data. This indicates that PCA is gonna be really useful for the classification of this dataset.\n\nLet's visualize the 2 and 3 first principal components:","2e48962d":"Using the previous function, let's print the quantity and proportion of left and right outliers for each feature across the two classes:","7f257309":"It seems there are outliers for a good share of the features.\n\nLet's check how balanced are the two classes we want to predict:","354cde2c":"# Dimension Reduction - PCA","632e7b67":"We can see that for all features, the two classes overlap in some degree. \n\nOf course, some variables will provide better info for the classification since they do a better job at separating the two classes. This is the case for: mean_ip, ek_ip and sd_dm.\n\nAlso, the outliers may play an important role in the classification.\n\nLet's check the correlation between all pair of variables (including the response): ","5839cfcf":"# Outlier Analysis","1168ee6b":"It is possible to see that there exists and hyperplane that will do a good job at correctly classifying a pulsar star. \n\nProbably not perfectly but we'll see if good enough.","5532bcd9":"# Classifiers","aee72a65":"For comparing the different classifiers we need to define a proper metric. \n\nSince this problem has a strong class imbalance we'll be using balanced accuracy as the main metric, which is the average of recall for both classes. \n\nAs a secondary metric we'll use recall as I assume that False Negatives are worst than False Positives because pulsars are very rare and failing to correctly detect them (while misclassifying non-pulsars as pulsars) is worst than the other way around. \n\n**However, I don't have any background in astrophysics and this is merely an assumption**\n\nLet's begin by separating the response variable from the predictors:","a3943c37":"We can see that in a general sense, the probability of an observation being a pulsar star increases with the number of features it is an outlier of. \n\nThis relationship can be more complex than this but there is a correlation between being an outlier and belonging to a specific class. In this case outliers are not merely noise, but provide useful info for the classification procedure and **must not be removed**","fb6a238a":"PCA doesn't improve prediction. \n\nHowever, the results are similar while successfully reducing the dimension of the problem.\n\nWe didn't achieve perfect pulsar classification or perfect recall but gained a glimpse of the performance of different ML algorithms for this dataset. \n\nThe task of classyfing pulsar stars is a difficult one and other techniques such as Neural Networks could improve our classification procedure, maybe in the future I will add them to this notebook. Also a more selective treatment or removal of outliers might help, but for the time being I'm satisfied with the visualization and analysis performed.\n\nThat's it! Thanks for reading!","048e8aa7":"With the help of cross validation, let's define a function that will help us compare the ML algorithms:"}}