{"cell_type":{"9f0c081e":"code","5c996082":"code","38162cec":"code","37559efd":"code","42357149":"code","cd48fb57":"code","22fb9b52":"code","ce6a0a65":"code","6a64ceb3":"code","6ca95c91":"code","35a55b13":"code","7e5a9a66":"code","40bc4d17":"code","c45fdbec":"code","b12795b4":"code","797b7390":"code","49f0677e":"code","4038d13a":"code","22bc99cc":"code","74b7e573":"code","dc7cda7a":"markdown","7d52a57b":"markdown","eb75e6cb":"markdown","737ec5ee":"markdown"},"source":{"9f0c081e":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport os\nimport math\nimport h5py\nimport random\nimport nilearn as nl\nfrom nilearn import image, datasets, plotting\nfrom nilearn.image import get_data\nfrom random import randint\nfrom tqdm.notebook import tqdm\nfrom sklearn.impute import KNNImputer","5c996082":"source = \"..\/input\/trends-assessment-prediction\"","38162cec":"img_train = []\nfor name in os.listdir(source+'\/fMRI_train'):\n    img_train.append(int(name[:5]))\nimg_train.sort()","37559efd":"t = h5py.File(source+'\/fMRI_train\/10001.mat', 'r')['SM_feature'][()]\nfor i in range(53):\n    print(i)\n    x_axis = t[:,:,i].transpose(1,2,0)\n    plt.imshow(x_axis[:, :,28], cmap=plt.cm.Set1)\n    plt.show()","42357149":"X_train_x = np.array([])\nfor id_img in tqdm(img_train):\n    t = h5py.File(source+f'\/fMRI_train\/{id_img}.mat', 'r')['SM_feature'][()]\n    x_axis = t[:,:,17].transpose(1,2,0)\n    \n    if len(X_train_x) == 0:\n        X_train_x = x_axis[:, :,28]\n    elif X_train_x.shape[1] == 53:\n        X_train_x = np.append([X_train_x], [x_axis[:, :,28]], axis=0)\n    else:\n        X_train_x = np.append(X_train_x, [x_axis[:, :,28]], axis=0)","cd48fb57":"img_test = []\nfor name in os.listdir(source+'\/fMRI_test'):\n    img_test.append(int(name[:5]))\nimg_test.sort()","22fb9b52":"X_test_x = np.array([])\nfor id_img in tqdm(img_test):\n\n    t = h5py.File(source+f'\/fMRI_test\/{id_img}.mat', 'r')['SM_feature'][()]\n    x_axis = t[:,:,17].transpose(1,2,0)\n    \n    if len(X_test_x) == 0:\n        X_test_x = x_axis[:, :,28]\n    elif X_test_x.shape[1] == 53:\n        X_test_x = np.append([X_test_x], [x_axis[:, :,28]], axis=0)\n    else:\n        X_test_x = np.append(X_test_x, [x_axis[:, :,28]], axis=0)","ce6a0a65":"X_train_x = X_train_x.reshape(X_train_x.shape[0], 1, 52, 53)\nX_test_x = X_test_x.reshape(X_test_x.shape[0], 1, 52, 53)","6a64ceb3":"train_scores = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv\")\nfnc = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/fnc.csv\")\nloading = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/loading.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv\")","6ca95c91":"train_scores = train_scores.drop(['Id'], axis=1)","35a55b13":"train_scores.head()","7e5a9a66":"impute = KNNImputer(n_neighbors=20)\ny_train = impute.fit_transform(train_scores)","40bc4d17":"import tensorflow.keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","c45fdbec":"def weighted_NAE(yTrue,yPred):\n    weights = K.constant([.3, .175, .175, .175, .175], dtype='float32')\n    \n    return K.sum(weights*K.sum(K.abs(yTrue-yPred))\/K.sum(yPred))","b12795b4":"model = Sequential()\nmodel.add(BatchNormalization()) \nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,52,53), data_format='channels_first'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization()) \nmodel.add(Dropout(0.4))\nmodel.add(Convolution2D(32, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \nmodel.add(Flatten())\nmodel.add(BatchNormalization()) \nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(5, activation='relu'))\n\nmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=[weighted_NAE])","797b7390":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode='min',\n                              patience=3, min_lr=0.001)","49f0677e":"history = model.fit(X_train_x, y_train, epochs=20, batch_size=1024, validation_split=0.1, shuffle=True, callbacks=[reduce_lr])","4038d13a":"model.summary()","22bc99cc":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, 21)\nplt.plot(epochs, loss_values, 'b', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.figure(figsize=(15,10))\nplt.show()","74b7e573":"pred=pd.DataFrame()\npred[\"Id\"]=sample_submission.Id\npred[\"Predicted\"]=model.predict(X_test_x).flatten()\npred.to_csv('out.csv', index=False)","dc7cda7a":"#### I think the 17th picture is the most representative. But you can try another one.","7d52a57b":"# Let's create a dataset","eb75e6cb":"# You can also improve the model or use other axes when cutting pictures. Good luck!","737ec5ee":"# Let's create CNN"}}