{"cell_type":{"c82d3659":"code","bc545caa":"code","1a1d5aa5":"code","a0492788":"code","e207930c":"code","d45a1f72":"code","9827508e":"code","aaded208":"code","3efc595c":"code","607209d7":"code","21d63c00":"code","fa66b62a":"code","9153eddc":"code","80792b87":"code","032a030b":"code","d80f4a5d":"code","f9886b48":"code","98e223ec":"code","6e0e9a1e":"code","79a834f0":"code","fff04d01":"code","02bcb920":"code","6efff383":"code","816f6087":"code","3db73af4":"code","ba573de8":"code","204383f4":"code","5f2eb843":"code","3765a88e":"code","dd673428":"code","2b510786":"code","8bf16899":"markdown","65e0c76b":"markdown","2348479a":"markdown"},"source":{"c82d3659":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc545caa":"os.getcwd()","1a1d5aa5":"!ls","a0492788":"import fasttext","e207930c":"import spacy\nimport numpy as np\nimport pandas as pd\nimport re\n\nnlp = spacy.load(\"en_core_web_sm\")","d45a1f72":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle","9827508e":"df = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\n\ndf = df.dropna(subset=['text'])\ndf.head()","aaded208":"df.info()","3efc595c":"df.text = df.text.apply(lambda x : str(x).lower())\ndf.head()","607209d7":"df[df.keyword.notnull()].head()","21d63c00":"def combine_key_loc_text(x, combine_keyword=False):\n    loc = x['location']\n    key = x['keyword']\n    text = x['text']\n    if str(key) == \"nan\":\n        key = \" \"\n    if str(loc)==\"nan\":\n        loc = \" \"\n\n    if combine_keyword:\n        combined_text = f\"{key} {loc} {text}\"\n    else:\n        combined_text = f\"{loc} {text}\"\n\n    return combined_text.strip()","fa66b62a":"df['loc_text'] = df.apply(lambda x: combine_key_loc_text(x), axis=1)\ndf['key_loc_text'] = df.apply(lambda x: combine_key_loc_text(x, combine_keyword=True), axis=1)\ndf[df.location.notna()].head()","9153eddc":"def spacy_process(text):\n    doc = nlp(text)\n    return doc\n\ndef spacy_process(text):\n    doc = nlp(text)\n    return doc\n\ndef normalize_text(text):\n    text = str(text).lower()\n\n    temp_t = []\n    for t in text.split():\n        if t[0]!='@' and 'http' not in t:\n            temp_t.append(t)\n    text = ' '.join(temp_t)\n  \n    doc = spacy_process(text)\n    #Lemmatize\n    lemma_list = [token.lemma_.lower().strip() if token.lemma_ != '-PRON-' else token.lower_ for token in doc]\n  \n    #Filter the stopwords\n    filtered_sentence =[] \n    for word in lemma_list:\n        lexeme = nlp.vocab[word]\n        if not lexeme.is_stop:\n            filtered_sentence.append(word)\n\n    text = ' '.join(filtered_sentence)\n    text = re.sub('[^a-zA-Z]', ' ', text) \n    text = re.sub('\\s+', ' ', text) \n\n    return text","80792b87":"normalize_text(\"@bbc I used to play 6, cricket in college https:\/\/afaf.fa\")","032a030b":"df['norm_text'] = df.loc[:,'text'].apply(lambda x : normalize_text(x))","d80f4a5d":"df['norm_loc_text'] = df.loc[:,'loc_text'].apply(lambda x : normalize_text(x))","f9886b48":"df['norm_key_loc_text'] = df.loc[:,'key_loc_text'].apply(lambda x : normalize_text(x))","98e223ec":"df.loc[30:33]","6e0e9a1e":"df.head(1)","79a834f0":"# Give entire data set for training\nsamples = [f\"__label__{yi} {Xi}\" for yi, Xi in zip(df.target, df.norm_key_loc_text)]\ndf_train = pd.DataFrame(samples)\ndf_train.to_csv(\"dftrain.csv\",header=None, index=False)","fff04d01":"model = fasttext.train_supervised(input=\"dftrain.csv\", lr=0.1, epoch=100, wordNgrams=2)","02bcb920":"model.lr, model.epoch","6efff383":"model.predict(\"deed reason earthquake allah forgive\")","816f6087":"df_test =  pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\ndf_test.head(1)","3db73af4":"df_test['loc_text'] = df_test.apply(lambda x: combine_key_loc_text(x), axis=1)\ndf_test['key_loc_text'] = df_test.apply(lambda x: combine_key_loc_text(x, combine_keyword=True), axis=1)\ndf_test[df_test.location.notna()].head()","ba573de8":"df_test['norm_text'] = df_test.loc[:,'text'].apply(lambda x : normalize_text(x))\ndf_test['norm_loc_text'] = df_test.loc[:,'loc_text'].apply(lambda x : normalize_text(x))\ndf_test['norm_key_loc_text'] = df_test.loc[:,'key_loc_text'].apply(lambda x : normalize_text(x))","204383f4":"df_test.head(2)","5f2eb843":"def get_prediction(x, model):\n    temp = model.predict(x)\n    return temp[0][0].split(\"__label__\")[-1], round(temp[-1][0],3)","3765a88e":"df_test['target'], df_test['y_pred_conf'] = zip(*df_test['norm_key_loc_text'].apply(lambda x: get_prediction(x, model)))   \ndf_test1 = df_test.loc[:,['id','norm_key_loc_text','target','y_pred_conf']]\ndf_test1.head()","dd673428":"df_test2 = df_test1.loc[:,['id','target']]","2b510786":"df_test2.to_csv(\"my_pred.csv\",index=False)","8bf16899":"## Prediction on Test File","65e0c76b":"# Training","2348479a":"# Preprocessing"}}