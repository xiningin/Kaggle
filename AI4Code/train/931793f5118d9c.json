{"cell_type":{"55d3a8ea":"code","1017814f":"code","1e815cfe":"code","18f1bc3d":"code","dcb09545":"code","953a09e4":"code","4a19b3d0":"code","ea8ed128":"code","428db96c":"code","955e1686":"code","6c361c66":"code","c9df8ca8":"code","e0728a06":"code","30a04045":"code","443cc994":"code","ecfee59d":"code","9b230869":"code","772c22f7":"code","0c4e6ff0":"code","9e63add3":"code","5ea91237":"code","c78e9fbd":"code","f52d43f2":"code","ffecbb3e":"markdown","c01ed029":"markdown","f2a148f3":"markdown","58ec72dc":"markdown","18f58594":"markdown","5ebb6866":"markdown","737babff":"markdown","98cb17b9":"markdown","e1f4c4ce":"markdown","5b2e2167":"markdown","19622aec":"markdown","3f4a8b86":"markdown","09b0b81e":"markdown","1fa004e0":"markdown","4ef469ee":"markdown","5c8973da":"markdown","59156464":"markdown","ec988434":"markdown","32358cf7":"markdown","b86ca868":"markdown","30344747":"markdown","434cb120":"markdown","2e187694":"markdown","a0c3be2f":"markdown","526f5982":"markdown","8bfd4746":"markdown","68361154":"markdown","cd568f8d":"markdown","5e781a25":"markdown","b58d8755":"markdown","db976e15":"markdown","672433f5":"markdown","e5fb8fd9":"markdown","ec2075a4":"markdown","7a15cbd4":"markdown"},"source":{"55d3a8ea":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport nltk\nimport re\nfrom tensorflow import keras\nfrom sklearn.manifold import TSNE\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\npd.set_option(\"display.max_rows\", 50, \"display.max_columns\", 50)","1017814f":"data = pd.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")","1e815cfe":"label_encoder = preprocessing.LabelEncoder()\ndata['sentiment'] = label_encoder.fit_transform(data['sentiment'])\ndata.head()","18f1bc3d":"plt.figure(figsize=(6,3))\ndata.sentiment.value_counts().plot(kind='bar', rot=360)\nplt.show()","dcb09545":"print(data.review[0])","953a09e4":"stopWords = nltk.corpus.stopwords.words('english')\nsnoStemmer = nltk.stem.SnowballStemmer('english')\nwnlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef clean_html(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\n\ndef clean_punc(word):\n    cleaned = re.sub(r'[?|!|\\'|#]', r'', word)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]', r' ', cleaned)\n    return cleaned\n\ndef filtered_sents(data_frame):\n    # Creating a list of filtered sentences:\n    final_string = []\n    s = ''\n    for sentence in data_frame:\n        filtered_sentence = []\n        sentence = clean_html(sentence)\n        for word in sentence.split():\n            for cleaned_word in clean_punc(word).split():\n                if (cleaned_word.isalpha() and (len(cleaned_word) > 2) and cleaned_word not in stopWords):\n                    lemmatized_word = wnlemmatizer.lemmatize(cleaned_word.lower())\n                    stemmed_word = snoStemmer.stem(lemmatized_word)\n                    filtered_sentence.append(stemmed_word)\n                else:\n                    continue\n        strl = ' '.join(filtered_sentence)\n        final_string.append(strl)\n    return final_string\n\ndata.cleaned_review = filtered_sents(data.review)","4a19b3d0":"print(data.cleaned_review[0])","ea8ed128":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(data.cleaned_review)\nlist_tokenized_data = tokenizer.texts_to_sequences(data.cleaned_review)\nword_index = tokenizer.word_index\nindex_word = dict([(value, key) for (key, value) in word_index.items()])","428db96c":"print(pd.Series(word_index).head())\nprint('\\n')\nprint(pd.Series(word_index).tail())","955e1686":"length_list = []\nfor i in list_tokenized_data:\n    length_list.append(len(i))\n\nf, axes = plt.subplots(1, 2, figsize=(8, 4), sharex=False)\npd.Series(length_list).hist(bins=100, ax = axes[0])\npd.Series(length_list).hist(bins=100, ax = axes[1])\nplt.xlim(0,400)\nplt.show()","6c361c66":"MAX_LEN = 256\nX = keras.preprocessing.sequence.pad_sequences(list_tokenized_data,\n                                                        padding='post',\n                                                        maxlen=MAX_LEN)\ny = data.sentiment\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.20, random_state = 0)\nprint(f'SHAPE: \\n X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val:{y_val.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')","c9df8ca8":"vocab_size = max(np.max(X_train), np.max(X_test)) + 1\nemb_size = 16\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(vocab_size, emb_size, input_length = MAX_LEN, name = 'word_embedding'))\nmodel.add(keras.layers.GlobalAveragePooling1D())\nmodel.add(keras.layers.Dense(emb_size, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)))\nmodel.add(keras.layers.Dropout(0.5, seed=0))\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))\nmodel.summary()","e0728a06":"LEARNING_RATE = 1e-3\nOPTIMIZER = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=OPTIMIZER,\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\nCALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]\nhistory = model.fit(X_train,\n            y_train,\n            epochs=100,\n            batch_size=512,\n            validation_data=(X_val, y_val),\n            verbose=1,\n            callbacks=CALLBACKS)","30a04045":"y_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5).astype(int)\naccuracy = accuracy_score(y_test, y_pred)\nprint(accuracy)","443cc994":"history_dict = history.history\nmetric_list = list(history_dict.keys())\n\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n# \"bo\" is for \"blue dot\"\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'b', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'g', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\nplt.clf()   # clear figure\n\nif 'acc' in metric_list:\n    acc = history_dict['acc']\n    val_acc = history_dict['val_acc']\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.ylabel('Accuracy')\n    plt.title('Training and validation accuracy')\n    \nelif 'auc' in metric_list:\n    auc = history_dict['auc']\n    val_auc = history_dict['val_auc']\n    plt.plot(epochs, auc, 'bo', label='Training auc')\n    plt.plot(epochs, val_auc, 'b', label='Validation auc')\n    plt.ylabel('AUC')\n    plt.title('Training and validation auc')\n    \nelif 'precision' and 'recall' in list(metric_list):\n    precision = history_dict['precision']\n    val_precision = history_dict['val_precision']\n    recall = history_dict['recall']\n    val_recall = history_dict['val_recall']\n    plt.plot(epochs, precision, 'bo', label='Training precision')\n    plt.plot(epochs, val_precision, 'b', label='Validation precision')\n    plt.plot(epochs, recall, 'ro', label='Training recall')\n    plt.plot(epochs, val_recall, 'r', label='Validation recall')\n    plt.ylabel('Precision and Recall')\n    plt.title('Training and validation precision and recall')\n\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","ecfee59d":"# Extract embeddings\nword_layer = model.get_layer('word_embedding')\nword_weights = word_layer.get_weights()[0]\nword_weights.shape","9b230869":"word_weights = word_weights \/ np.linalg.norm(word_weights, axis = 1).reshape((-1, 1))\nword_weights[0][:10]\nnp.sum(np.square(word_weights[0]))","772c22f7":"%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 15\n\ndef find_similar(name, weights, index_name = 'word', n = 10, least = False, return_dist = False, plot = False):\n    \"\"\"Find n most similar items (or least) to name based on embeddings. Option to also plot the results\"\"\"\n    \n    # Select index and reverse index\n    if index_name == 'word':\n        index = word_index\n        rindex = index_word\n    elif index_name == 'page':\n        index = link_index\n        rindex = index_link\n    \n    # Check to make sure `name` is in index\n    try:\n        # Calculate dot product between word and all others\n        dists = np.dot(weights, weights[index[name]])\n    except KeyError:\n        print(f'{name} Not Found.')\n        return\n    \n    # Sort distance indexes from smallest to largest\n    sorted_dists = np.argsort(dists)\n    \n    # Plot results if specified\n    if plot:\n        \n        # Find furthest and closest items\n        furthest = sorted_dists[:(n \/\/ 2)]\n        closest = sorted_dists[-n-1: len(dists) - 1]\n        items = [rindex[c] for c in furthest]\n        items.extend(rindex[c] for c in closest)\n        \n        # Find furthest and closets distances\n        distances = [dists[c] for c in furthest]\n        distances.extend(dists[c] for c in closest)\n        \n        colors = ['r' for _ in range(n \/\/2)]\n        colors.extend('g' for _ in range(n))\n        \n        data = pd.DataFrame({'distance': distances}, index = items)\n        \n        # Horizontal bar chart\n        data['distance'].plot.barh(color = colors, figsize = (10, 8),\n                                   edgecolor = 'k', linewidth = 2)\n        plt.xlabel('Cosine Similarity');\n        plt.axvline(x = 0, color = 'k');\n        \n        # Formatting for italicized title\n        name_str = f'{index_name.capitalize()}s Most and Least Similar to'\n        for word in name.split():\n            # Title uses latex for italize\n            name_str += ' $\\it{' + word + '}$'\n        plt.title(name_str, x = 0.2, size = 28, y = 1.05)\n        \n        return None\n    \n    # If specified, find the least similar\n    if least:\n        # Take the first n from sorted distances\n        closest = sorted_dists[:n]\n         \n        print(f'{index_name.capitalize()}s furthest from {name}.\\n')\n        \n    # Otherwise find the most similar\n    else:\n        # Take the last n sorted distances\n        closest = sorted_dists[-n:]\n        \n        # Need distances later on\n        if return_dist:\n            return dists, closest\n        \n        \n        #print(f'{index_name.capitalize()}s closest to {name}.\\n')\n        \n    # Need distances later on\n    if return_dist:\n        return dists, closest\n    \n    \n    # Print formatting\n    max_width = max([len(rindex[c]) for c in closest])\n    \n    # Print the most similar and distances\n    #for c in reversed(closest):\n        #print(f'{index_name.capitalize()}: {rindex[c]:{max_width + 2}} Similarity: {dists[c]:.{2}}')\n        \n    return closest","0c4e6ff0":"find_similar('amaz', word_weights, least = True, n = 5, plot = True)","9e63add3":"find_similar('livingroom', word_weights, least = True, n = 5, plot = True)","5ea91237":"def reduce_dim(weights, components = 2, method = 'tsne'):\n    \"\"\"Reduce dimensions of embeddings\"\"\"\n    if method == 'tsne':\n        return TSNE(components, metric = 'cosine', random_state=0).fit_transform(weights)\n    elif method == 'umap':\n        # Might want to try different parameters for UMAP\n        return UMAP(n_components=components, metric = 'cosine', \n                    init = 'random', n_neighbors = 5).fit_transform(weights)","c78e9fbd":"word_r = reduce_dim(word_weights, components = 2, method = 'tsne')\nword_r.shape","f52d43f2":"clustered_pos = find_similar('great', word_weights, n = 10)\nclustered_neg = find_similar('bad', word_weights, n = 10)\nclustered_neutral = find_similar('livingroom', word_weights, n = 10)\nnp.random.seed(seed=0)\nclustered_pos = np.random.choice(clustered_pos, 5)\nnp.random.seed(seed=0)\nclustered_neg = np.random.choice(clustered_neg, 5)\nnp.random.seed(seed=0)\nclustered_neutral = np.random.choice(clustered_neutral, 5)\nclustered_words = np.concatenate((clustered_pos, clustered_neg))\nclustered_words = np.concatenate((clustered_words, clustered_neutral))\n\nInteractiveShell.ast_node_interactivity = 'last' \nplt.figure(figsize = (14, 12))\n\n#Plot all words\nfig = plt.scatter(word_r[:, 0], word_r[:, 1], marker = '.', color = 'lightblue')\n\nplt.xlabel('TSNE 1'); plt.ylabel('TSNE 2'); plt.title('TSNE Visualization of Word Embeddings');\nnp.random.seed(seed=0)\nfor index in clustered_words: \n    x, y = word_r[index, 0], word_r[index, 1];\n    s = ''.join([' $\\it{'+ i + '}$' for i in index_word[index].split()])\n    plt.scatter(x, y, s = 250, color = 'r', marker = '*', edgecolor = 'k')\n    plt.text(x + np.random.randint(-5,5), y + np.random.randint(-5,5), s, fontsize = 14);\nplt.show()","ffecbb3e":"## Preprocessing","c01ed029":"We can see in the review above that there is some HTML code in the review. Now, what we want to do is to get rid of the HTML code and do some other cleaning with reviews. The other cleaning we want to do is:\n\n* Transform all the words into low case characters\n* Stem and lematize the words\n* Remove stopwords\n\nA good page you can read about stemming and lematization is found [here](https:\/\/www.datacamp.com\/community\/tutorials\/stemming-lemmatization-python).","f2a148f3":"Let's have a look at the embeddings with help the of t-SNE. \n\nIn the plot below we can see three clusters. One for positive words, one for negative words and one that seems to be for the neutral words. In the plot it is shown the five most similar words to the positive word \"great\", five most similar words to the negative word \"bad\" and the five most similar words to the neutral word \"livingroom\".\n\nDo not know why there are multiple occurances of the same word in the plot at the moment, haven't figured that out yet. ","58ec72dc":"Let's have a look at the cleaned review.","18f58594":"## Tokenization","5ebb6866":"# WORK IN PROGRESS","737babff":"We encode the sentiment variable (response) as positive -> 1 and negative -> 0","98cb17b9":"Let's have a look at the reviews. We print the first review in the data set.","e1f4c4ce":"## Minor analysis of response variable","5b2e2167":"Looks pretty reasonable.\n\nNow, let's have a look at a more neutral word as 'livingroom'.","19622aec":"We see that most reviews contain around 60-80 words and that there are few reviews longer than 300 words. Now we need to have the reviews in the same form. What we want is a matrix X that represent the reviews as rows and the features as columns. This means that we neew to have a fixed length of every review so that every review has the same amount of features. I chose to have a length of 256 because I think it is a nice number :).\n\nWhen we have created the matrix X with all of the reviews, we then divide the rows into train, validation and test sets.","3f4a8b86":"## Preprocessing of the embedding layer","09b0b81e":"Seems like the words that are similar to 'livingroom' are quite neutral as well.\n\nWe continue with the t-SNE analysis.","1fa004e0":"![emb.png](attachment:emb.png)","4ef469ee":"# Data cleaning and preprocessing","5c8973da":"We see that the data is *balanced*. This means that accuracy can be used as an evaluation metric. If we would have an imbalanced data set, then another metric would have been more suitable such as AUC or F1-score.","59156464":"I chose the architecture to be a simple feed forward neural network with an embedding layer. The model has regularization in the dense layer and a dropout layer (with quite high dropout number) in order to prevent overfit.\n\n","ec988434":"What is the distribution of positive and negative reviews?","32358cf7":"# Modelling","b86ca868":"In order to get an understanding about the embeddings of the words we can compare the cosine similarity of the words. \n\nFurther, we can use t-SNE and plot the results in order to see the representation of the words in the embedding.","30344747":"We see that the training and the validation curves behave OK (but we might be able to tune the regularization or dropout to reduce the minor overfit). You can read about how to interpret learning and validation curves [here](https:\/\/machinelearningmastery.com\/learning-curves-for-diagnosing-machine-learning-model-performance\/).","434cb120":"## Data cleaning","2e187694":"# Introduction","a0c3be2f":"In the output below we see that the words have been transformed as the following:\n\n* movi (movie) -> 1\n* film -> 2\n* the -> 3\n* one -> 4\n* like -> 5\n\nWe also see in the cell beneath that we have 66020 unique words in total.\n","526f5982":"How many words (numbers) do the reviews contain? Let's have a look at the length of the reviews.","8bfd4746":"Let's have a look at the similarities and dissimilarities of the word 'amaz' ('amazing').","68361154":"This notebook is under construction so mistakes\/errors are probably present. Again, let me know if you have any input! ","cd568f8d":"Now we need to tokenize the reviews. This means that instead of having words in the reviews, we will have numbers that represent the words. Every word is represented by a unique number which in turn will have a unique coordinate in our embedding layer, see the figure ([ref](https:\/\/medium.com\/@JMangia\/coreml-with-glove-word-embedding-and-recursive-neural-network-part-2-ab238ca90970)) below.","5e781a25":"# Embeddings and t-SNE","b58d8755":"# Model evaluation","db976e15":"# Import libraries & data","672433f5":"This notebook is partly based on the work of Will Koehrsen's [Book Recommendation System.ipynb](http:\/\/github.com\/WillKoehrsen\/wikipedia-data-science\/blob\/master\/notebooks\/Book%20Recommendation%20System.ipynb) and Georgios Drakos' [Sentiment Analysis on IMDB movie dataset - Achieve state of the art result using a simple Neural Network](https:\/\/gdcoder.com\/sentiment-analysis-on-imdb-movie-dataset-achieve-state-of-the-art-result-using-a-simple-neural-network\/). \n\nIt involves an NLP excercise of the [IMDB sentiment data set](https:\/\/www.kaggle.com\/lakshmi25npathi\/imdb-dataset-of-50k-movie-reviews) where I have used a simple neural network with an embedding layer in order to predict whether a film review has a positive or negative sentiment. \n\nThe notebook starts out with some minor EDA and data cleaning & preprocessing. The latter part contains the modelling, model evaluation and some analysis of the embeddings.\n\nPlease, if you have any input or feedback regarding this notebook, comment below.","e5fb8fd9":"## Visualizations of the embedding","ec2075a4":"The review may not make so much sense to us when we read it, but it is now cleaned from stopwords, it is lower cased, stemmed and lematized, as we want it to be.","7a15cbd4":"How well are we fitting the data? Do we underfit, overfit or are we just about right? Let's have a look at the training and validation curves."}}