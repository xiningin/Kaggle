{"cell_type":{"55d368d0":"code","72c14dd8":"code","7403987b":"code","b4cde4a4":"code","e9b2f1b2":"code","4ff938ec":"code","97406804":"code","f3181494":"code","c1ae1e25":"code","b9c42256":"code","ee72a235":"code","7b99c1be":"code","2f68ef73":"code","14de2aa0":"code","c848b0bd":"code","c70cd7c9":"code","db1b769c":"code","bfd5f7ab":"code","db851e81":"code","eba228cc":"code","865b0341":"code","6202cc7c":"code","757e0295":"code","ac99fb1c":"code","93237157":"code","62f52244":"code","02de4e1d":"code","3a2a53e4":"code","e2dd0091":"code","cd06650c":"code","95f77be9":"code","5637bb6d":"code","e51aa731":"code","baa9be01":"code","0ca05f87":"code","0e6ae11f":"code","ea87dd14":"code","66d3ba5e":"code","56c12178":"code","f5470e35":"code","2ca60be2":"code","ca67b942":"code","7722e240":"code","600d959d":"code","1489707a":"code","8c8bc60f":"code","eb87c258":"code","024af98a":"code","61e17e4f":"code","d53acd26":"code","653b622f":"code","7e169cf1":"code","133a6a07":"code","5586a6dc":"code","0f61aff8":"code","0c5d2c53":"code","c964510b":"code","d63f5885":"code","0cb6d882":"code","967e37d0":"code","3897b0f1":"code","217530d5":"code","49ccb887":"code","b5802725":"markdown","470f0b6c":"markdown","8b3dcb84":"markdown","1cea125d":"markdown","f5cf236b":"markdown","409818ab":"markdown","6b9428ab":"markdown","e7db88fc":"markdown","87b76ed9":"markdown","9961d4fa":"markdown","e1be8667":"markdown","34ea9e61":"markdown","3acb76ff":"markdown","a07c304c":"markdown","6e402aef":"markdown","bd0df013":"markdown","b41cebc9":"markdown","7fff00c9":"markdown","920d35c5":"markdown","c39fec28":"markdown","9a9107e6":"markdown","96dc97f2":"markdown","da6ed992":"markdown","c3c4225d":"markdown","a898a481":"markdown","207eb989":"markdown","e89a5512":"markdown","a2ec0af7":"markdown","72d67d2a":"markdown","76c2c8c2":"markdown","36ae1e79":"markdown","1bababe0":"markdown","0af9bab5":"markdown"},"source":{"55d368d0":"# Importamos las librer\u00edas necesarias\nimport pandas as pd\nimport numpy as np\nimport os\n# Establecemos la semilla para asegurarnos que los resultados se repitan\nfrom numpy.random import seed\nseed(123)\nimport tensorflow\ntensorflow.random.set_seed(123)\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.metrics import binary_accuracy\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport itertools\nimport shutil\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline","72c14dd8":"# Estas l\u00edneas de c\u00f3digo nos permiten instalar opencv desde Jupyter Notebook, que vamos a necesitar para \n# importar 'cv2'\nimport sys\n!{sys.executable} -m pip install opencv-python --user","7403987b":"# Importamos la biblioteca de visi\u00f3n artificial que vamos a utilizar en el trabajo\nimport cv2","b4cde4a4":"# Definimos las medidas de algunas de las variables que vamos a utilizar m\u00e1s adelante\nIMAGE_HEIGHT = 96\nIMAGE_WIDTH = 96\nNUM_HOLDOUT_IMAGES = 200\nNUM_EPOCHS = 10\nNUM_FOLDS = 5\nPADDING = 10\nBATCH_SIZE = 10\nNUM_FINAL_MODEL_EPOCHS = 10","e9b2f1b2":"# Establecemos el directorio en el que se encuentran las im\u00e1genes\npath_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected'\npath_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized'\nlista_sanos = os.listdir(path_sanos)\nlista_infectados = os.listdir(path_infectados)\n# Comprobamos el n\u00famero de im\u00e1genes que corresponden a cada tipo de paciente\nprint('N\u00famero de im\u00e1genes correspondientes a pacientes sanos:', len(lista_sanos))\nprint('N\u00famero de im\u00e1genes correspondientes a pacientes infectados:', len(lista_infectados))","4ff938ec":"path_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\npath_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/'\n# Establecemos el tama\u00f1o de cada casilla, as\u00ed como su disposici\u00f3n (n\u00famero de filas y columnas)\nplt.figure(figsize=(24,14))\nplt.subplot(2,5,1)\n# Vamos a desplegar diez im\u00e1genes en total\nfor i in range(1,11):\n    plt.subplot(2,5,i)\n# Van a ser im\u00e1genes elegidas al azar\n    image = lista_sanos[i] \n    plt.imshow(plt.imread(path_sanos + image))\n# Indicamos el texto que va a haber debajo de cada imagen as\u00ed como el tama\u00f1o de su fuente, en este caso, 'Sano'\n    plt.xlabel('Sano', fontsize=22)","97406804":"path_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\npath_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/'\n# Repetimos los pasos para las im\u00e1genes de infectados\nplt.figure(figsize=(24,14))\nplt.subplot(2,5,1)\nfor i in range(1,11):\n    plt.subplot(2,5,i)\n    image = lista_infectados[i]  \n    plt.imshow(plt.imread(path_infectados + image))\n    plt.xlabel('Infectado', fontsize=22)","f3181494":"# A continuaci\u00f3n, comprobamos si hay alg\u00fan archivo que no sea una imagen en la carpeta de sanos, ya que esto \n# podr\u00eda traer problemas\nfor item in lista_sanos:\n# Utilizamos la funci\u00f3n .split()\nlista_archivo = item.split('.')\n# Comprobamos si hay alg\u00fan caso en el que la extensi\u00f3n del archivo no sea la de una imagen, es decir, .png\n    if lista_archivo[1] != 'png':\n        print('Carpeta de sanos:', item)","c1ae1e25":"# Repetimos los pasos para la carpeta de infectados\nfor item in lista_infectados:\n    lista_archivo = item.split('.')\n    if lista_archivo[1] != 'png':\n        print('Carpeta de infectados:',item)","b9c42256":"# Creamos un dataframe de la carpeta de sanos y eliminamos el archivo que no es una imagen\ndf_sanos = pd.DataFrame(lista_sanos, columns=['image_id'])\ndf_sanos = df_sanos[df_sanos['image_id'] != 'Thumbs.db']\n# A\u00f1adimos una columna objetivo o 'target'\ndf_sanos['target'] = 0\n# Repetimos el proceso para los infectados\ndf_infectados = pd.DataFrame(lista_infectados, columns=['image_id'])\ndf_infectados = df_infectados[df_infectados['image_id'] != 'Thumbs.db']\ndf_infectados['target'] = 1\n# Creamos otro dataframe que combine los dos anteriores\ndf_combinado = pd.concat([df_sanos, df_infectados], axis=0).reset_index(drop=True)","ee72a235":"# Observamos los seis primeros datos o im\u00e1genes que aparecen\ndf_combinado.head(6)","7b99c1be":"# Comprobamos la forma del dataframe creado en combinaci\u00f3n de los dos anteriores\ndf_combinado.shape","2f68ef73":"# Tenemos que verificar que los nombres de las im\u00e1genes sean \u00fanicos, deber\u00eda salir el mismo resultado \n# que el n\u00famero de filas de la l\u00ednea de c\u00f3digo anterior\ndf_combinado['image_id'].nunique()","14de2aa0":"# Comprobamos con las siguientes l\u00edneas de c\u00f3digo la forma de las seis im\u00e1genes previamente seleccionadas, con el\n# width y height (anchura y altura, representados como 'w' y 'h'), los canales, que son im\u00e1genes en escala de \n# grises del mismo tama\u00f1o que la imagen en color, hecha de cada uno de los colores primarios (en imagen digital: \n# verde, azul y rojo), as\u00ed como el valor m\u00e1ximo y m\u00ednimo de p\u00edxeles (para averiguar si ha tenido lugar alg\u00fan tipo \n# de preprocesado) y para finalizar a\u00f1adimos esta informaci\u00f3n al dataframe original\ndef tamano_imagenes(file_name):    \n    path_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\n    path_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/' \n    if file_name in lista_sanos:\n        path = path_sanos\n    else:\n        path = path_infectados   \n    image = cv2.imread(path + file_name)\n    max_pixel_val = image.max()\n    min_pixel_val = image.min()\n    img_format = file_name.split('.')[1]\n    output = [image.shape[0], image.shape[1], image.shape[2], max_pixel_val, min_pixel_val, img_format]\n    return output\nm = np.stack(df_combinado['image_id'].apply(tamano_imagenes))\ndf = pd.DataFrame(m,columns=['w','h','c','max_pixel_valor','min_pixel_valor', 'imagen_formato'])\ndf_combinado = pd.concat([df_combinado,df],axis=1, sort=False)\ndf_combinado.head(6)","c848b0bd":"# Verificamos que todas las im\u00e1genes tengan los tres canales que acabamos de mencionar\ndf_combinado['c'].value_counts()","c70cd7c9":"# Comprobamos que todas las im\u00e1genes tengan formato .png\ndf_combinado['imagen_formato'].value_counts()","db1b769c":"# Nos cercioramos de que no haya ninguna imagen en negro\nlen(df_combinado[(df_combinado['max_pixel_valor'] == 0) & (df_combinado['max_pixel_valor'] == 0)])","bfd5f7ab":"# Hacemos lo mismo para las im\u00e1genes en blanco\nlen(df_combinado[(df_combinado['max_pixel_valor'] == 255) & (df_combinado['max_pixel_valor'] == 255)])","db851e81":"# Reorganizamos las im\u00e1genes con el m\u00e9todo shuffle()\ndf_combinado = shuffle(df_combinado, random_state=123)\n# Creamos un conjunto de reserva de 200 im\u00e1genes (definimos esta variable en la cuarta c\u00e9lula del Notebook)\ndf_aparte = df_combinado.sample(NUM_HOLDOUT_IMAGES, random_state=123)\nlista_imagenes_aparte = list(df_aparte['image_id'])\n# A continuaci\u00f3n seleccionamos las filas que no forman parte del conjunto de reserva. Son las filas con las \n# que vamos a trabajar a partir de ahora\ndatos = df_combinado[~df_combinado['image_id'].isin(lista_imagenes_aparte)]","eba228cc":"# Mostramos las primeras seis filas del conjunto de reserva, \"df_aparte\"\ndf_aparte.head(6)","865b0341":"# Mostramos las primeras seis filas del conjunto que no incluye al de reserva, al que hemos denominado \"datos\"\ndatos.head(6)","6202cc7c":"# Comprobamos la forma de ambos conjuntos\nprint(df_aparte.shape)\nprint(datos.shape)","757e0295":"# Vemos el n\u00famero de im\u00e1genes de la variable objetivo en el conjunto de reserva para cada clase, siendo el 0\n# para los sanos y el 1 para los infectados\ndf_aparte['target'].value_counts()","ac99fb1c":"# Iniciamos creando una carpeta en nuestro escritorio, \"directorio_base\"\ndirectorio_base = 'directorio_base'\nos.mkdir(directorio_base)\n# Que contendr\u00e1 dos carpetas, \"train\" y \"validaci\u00f3n\"\ntrain = os.path.join(directorio_base, 'train')\nos.mkdir(train)\nvalidacion = os.path.join(directorio_base, 'validacion')\nos.mkdir(validacion)\n# Y dentro de cada carpeta creamos otras dos diferenciando pacientes sanos de infectados\nsanos_A = os.path.join(train, 'sanos_A')\nos.mkdir(sanos_A)\ninfectados_B = os.path.join(train, 'infectados_B')\nos.mkdir(infectados_B)\nsanos_A = os.path.join(validacion, 'sanos_A')\nos.mkdir(sanos_A)\ninfectados_B = os.path.join(validacion, 'infectados_B')\nos.mkdir(infectados_B)","93237157":"# Seleccionamos la columna que vamos a utilizar para dividir los datos; se aplica estratificaci\u00f3n\ny = datos['target']\ntrain_df, validacion_df = train_test_split(datos, test_size=0.15, random_state=123, stratify=y)\n# Comprobamos la forma de cada nuevo dataframe creado\nprint(train_df.shape)\nprint(validacion_df.shape)","62f52244":"# Verificamos que los datos de la variable objetivo est\u00e1n equilibrados para cada clase en el set de validaci\u00f3n\nvalidacion_df['target'].value_counts()","02de4e1d":"# Establecemos 'image_id' como index de \"datos\"\ndatos.set_index('image_id', inplace=True)","3a2a53e4":"# Visualizamos las primeras seis filas del conjunto\ndatos.head(6)","e2dd0091":"# Iniciamos obteniendo listas de im\u00e1genes para cada carpeta\npath_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\npath_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/'\ncarpeta_1 = os.listdir(path_sanos)\ncarpeta_2 = os.listdir(path_infectados)\n# Hacemos lo mismo para train y validaci\u00f3n\nlista_train = list(train_df['image_id'])\nlista_validacion = list(validacion_df['image_id'])\n# Transferimos las im\u00e1genes de train\nfor image in lista_train:\n    fname = image\n    target = datos.loc[image,'target']\n    if target == 0:\n        label = 'sanos_A'\n    else:\n        label = 'infectados_B'\n    if fname in carpeta_1:\n# Hemos definido \"ini\" como origen y \"fin\" como destino\n# Directorio de origen\n        ini = os.path.join(path_sanos, fname)\n# Directorio de destino\n        fin = os.path.join(train, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n# Guardamos las im\u00e1genes en destino\n        cv2.imwrite(fin, image)\n    if fname in carpeta_2:\n        ini = os.path.join(path_infectados, fname)\n        fin = os.path.join(train, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)      \n# Repetimos el proceso para las im\u00e1genes de validaci\u00f3n\nfor image in lista_validacion:\n    fname = image\n    target = datos.loc[image,'target']\n    if target == 0:\n        label = 'sanos_A'\n    else:\n        label = 'infectados_B'\n    if fname in carpeta_1:\n        ini = os.path.join(path_sanos, fname)\n        fin = os.path.join(validacion, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)\n    if fname in carpeta_2:\n        ini = os.path.join(path_infectados, fname)\n        fin = os.path.join(validacion, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)","cd06650c":"# Verificamos el n\u00famero de im\u00e1genes en cada carpeta\n# Set de train\nprint(len(os.listdir('directorio_base\/train\/sanos_A')))\nprint(len(os.listdir('directorio_base\/train\/infectados_B\/')))\n# Set de validaci\u00f3n\nprint(len(os.listdir('directorio_base\/validacion\/sanos_A')))\nprint(len(os.listdir('directorio_base\/validacion\/infectados_B\/')))","95f77be9":"# Volvemos a hacer uso de algunas variables que hab\u00edamos previamente establecido en la c\u00e9lula cuatro, como\n# BATCH_SIZE (o tama\u00f1o del lote) = 10\npath_train = 'directorio_base\/train'\npath_validacion = 'directorio_base\/validacion'\ntrain_mu = len(train_df)\nvalidacion_mu = len(validacion_df)\nbatch_size_train = BATCH_SIZE\nbatch_size_validacion = BATCH_SIZE\npasos_train = np.ceil(train_mu \/ batch_size_train)\npasos_validacion = np.ceil(validacion_mu \/ batch_size_validacion)","5637bb6d":"# Normalizamos las im\u00e1genes dentro del 'generator'\ndatagen = ImageDataGenerator(rescale=1.0\/255)\ngen_train = datagen.flow_from_directory(path_train,\n                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                        batch_size=batch_size_train,\n                                        class_mode='categorical')\ngen_validacion = datagen.flow_from_directory(path_validacion,\n                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                        batch_size=batch_size_validacion,\n                                        class_mode='categorical')\n# Indicamos shuffle=False en la \u00faltima l\u00ednea de c\u00f3digo para que el dataset no sea reorganizado\ngen_test = datagen.flow_from_directory(path_validacion,\n                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                        batch_size=batch_size_validacion,\n                                        class_mode='categorical',\n                                        shuffle=False)","e51aa731":"# Arquitectura del modelo obtenida de GitHub. Fuente: https:\/\/gist.github.com\/Mishaall\/f52e717eae11080c\n# 4fc530e9ef5082ff\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\ndropout_conv = 0.3\ndropout_dense = 0.3\nmodelo = Sequential()\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                 input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\nmodelo.add(ZeroPadding2D(padding=(PADDING, PADDING), data_format=None))\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size)) \nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size))\nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size))\nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Flatten())\nmodelo.add(Dense(256, activation = \"relu\"))\nmodelo.add(Dropout(dropout_dense))\nmodelo.add(Dense(2, activation = \"softmax\"))\nmodelo.summary()","baa9be01":"modelo.compile(Adam(lr=0.0001, decay=1e-6), loss='binary_crossentropy', \n              metrics=['accuracy'])","0ca05f87":"# Fuente para la arquitectura: https:\/\/machinelearningmastery.com\/check-point-deep-learning-models-keras\/\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')          \nlista_callbacks = [checkpoint]\nhistory = modelo.fit(gen_train, steps_per_epoch=pasos_train, \n                            validation_data=gen_validacion,\n                            validation_steps=pasos_validacion,\n                            epochs=NUM_EPOCHS, verbose=1,\n                           callbacks=lista_callbacks)","0e6ae11f":"# Comprobamos el nombre de las medidas\nmodelo.metrics_names","ea87dd14":"# Importamos el paquete necesario para poder guardar el modelo\nimport h5py\nfrom keras.models import load_model\nmodelo.save('model.h5')","66d3ba5e":"# Utilizaremos la mejor repetici\u00f3n o epoch\nmodelo.load_weights(\"model.h5\")\nval_loss, val_acc = \\\nmodelo.evaluate(gen_test, \n                        steps=pasos_validacion)\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","56c12178":"# Procederemos a representar gr\u00e1ficamente la curva de p\u00e9rdida ('loss') y la de exactitud ('accuracy')\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Curva de p\u00e9rdida')\nplt.legend()\nplt.figure()\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Curva de exactitud')\nplt.legend()\nplt.figure()","f5470e35":"# Obtenemos las etiquetas para las im\u00e1genes de test\ntest_etiquetas = gen_test.classes","2ca60be2":"test_etiquetas","ca67b942":"# Mostramos la etiqueta y su clase asociada\ngen_test.class_indices","7722e240":"# Realizamos una predicci\u00f3n\npredicciones = modelo.predict(gen_test, steps=pasos_validacion, verbose=1)","600d959d":"# Comprobamos el n\u00famero de predicciones\npredicciones.shape","1489707a":"# Con la siguiente funci\u00f3n creamos la Confusion Matrix. Se puede aplicar normalizaci\u00f3n con normalize=True,\n# pero decidimos no aplicarla\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Confusion matrix normalizada\")\n    else:\n        print('Confusion matrix, sin normalizar')\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.ylabel('Etiqueta real')\n    plt.xlabel('Predicci\u00f3n')\n    plt.tight_layout()","8c8bc60f":"# Mostramos la forma del dataframe\ntest_etiquetas.shape","eb87c258":"# A continuaci\u00f3n hacemos uso de argmax(), que es una funci\u00f3n que proporciona el \u00edndice del mayor n\u00famero en la\n# fila o columna dada y la fila o columna se puede decidir utilizando el atributo de eje de argmax funci\u00f3n. \n# Si damos axis=0 entonces dar\u00e1 el \u00edndice de las columnas y si damos axis=1 entonces dar\u00e1 el \u00edndice de las filas.\ncm = confusion_matrix(test_etiquetas, predicciones.argmax(axis=1))","024af98a":"# Mostramos de nuevo la etiqueta y su clase asociada\ngen_test.class_indices","61e17e4f":"# Indicamos c\u00f3mo se van a llamar las etiquetas en la 'Confusion Matrix'\ncm_plot_etiquetas = ['Sanos', 'Infectados']\nplot_confusion_matrix(cm, cm_plot_etiquetas, title='Confusion Matrix')","d53acd26":"# Para obtener la secuencia en la que el generator ha procesado las im\u00e1genes de test\ntest_nombres = gen_test.filenames\n# Obtenemos las etiquetas reales, es decir, si la imagen se corresponde a una persona infectada o no\ny_real = gen_test.classes\n# As\u00ed como las etiquetas de las predicciones\ny_prediccion = predicciones.argmax(axis=1)","653b622f":"# Hacemos una tabla para verlo con mayor claridad\nclasificacion = classification_report(y_real, y_prediccion, target_names=cm_plot_etiquetas)\nprint(clasificacion)","7e169cf1":"# Juntamos en un mismo dataframe image_id, las etiquetas y predicciones de validaci\u00f3n\nvali_pred_dict = {\n    'image_id': gen_test.filenames,\n    'vali_labels': gen_test.classes,\n    'vali_preds': predicciones.argmax(axis=1)\n}\n# Creamos otro dataframe\ndf_vali_preds = pd.DataFrame(vali_pred_dict)\n# Acortamos el nombre de los archivos\ndef adjust_file_names(x):\n# Los dividimos en una lista bas\u00e1ndonos en '\/'\n    fname = x.split('\/')\n# Elegimos el segundo elemento de la lista que es el nombre de la imagen\n    fname = fname[1]\n    return fname\ndf_vali_preds['image_id'] = df_vali_preds['image_id'].apply(adjust_file_names)\n# Guardamos el \u00faltimo dataframe creado, \"df_vali_preds\" para poder analizar los resultados despu\u00e9s\npickle.dump(df_vali_preds,open('df_vali_preds.pickle','wb'))","133a6a07":"# Visualizamos las seis primeras filas del dataframe\ndf_vali_preds.head(6)","5586a6dc":"# A continuaci\u00f3n mostramos las filas para las que el modelo acert\u00f3 en sus predicciones\ndf_correc = df_vali_preds[df_vali_preds['vali_labels'] == df_vali_preds['vali_preds']]\n# As\u00ed como las filas en las que el modelo fall\u00f3 en sus predicciones\ndf_incorrec = df_vali_preds[df_vali_preds['vali_labels'] != df_vali_preds['vali_preds']]\nprint(df_correc.shape)\nprint(df_incorrec.shape)","0f61aff8":"# Iniciamos creando las cinco particiones o folds\n# Para ello primero reorganizamos \"df_combinado\"\ndatos = shuffle(df_combinado.copy())\ny = datos['target']\n# Iniciamos con StratifiedKFold, que primero baraja los datos, luego los divide en 'n_splits' partes y despu\u00e9s\n# usar\u00e1 cada parte como un conjunto de prueba\nkf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=123)\n# Definimos la y\ny = datos['target']\n# Metemos todas las tuplas (cada fold es una tupla) en una lista\nlista_fold = list(kf.split(datos, y))\n# Creamos una lista para guardar las predicciones\nvali_pred_list = []\n# Y otra para los niveles de accuracy, loss y AUC\nvali_acc_list = []\nvali_loss_list = []\nvali_auc_list = []\nfor i, fold in enumerate(lista_fold):\n# Eliminamos el directorio que hemos creado anteriormente\n    if os.path.isdir('directorio_base') == True:   \n        shutil.rmtree('directorio_base')         \n# Establecemos cu\u00e1les son los datos que se van a tratar\n        datos = df_combinado.copy()    \n    print('=== Fold_' + str(i) + ' ===')\n    print('\\n')\n# Y los \u00edndices de train y validaci\u00f3n como filas de un dataframe\n    train_df = datos[datos.index.isin(fold[0])]\n    validacion_df = datos[datos.index.isin(fold[1])]  \n# Creamos un directorio nuevo\n    directorio_base = 'directorio_base'\n    os.mkdir(directorio_base)\n# Repetimos el proceso de crear las carpetas diferenciadas para train y validaci\u00f3n as\u00ed como sus respectivos\n# sanos e infectados en otras carpetas dentro de las primeras\n    train = os.path.join(directorio_base, 'train')\n    os.mkdir(train)\n    validacion = os.path.join(directorio_base, 'validacion')\n    os.mkdir(validacion)\n    sanos_A = os.path.join(train, 'sanos_A')\n    os.mkdir(sanos_A)\n    infectados_B = os.path.join(train, 'infectados_B')\n    os.mkdir(infectados_B)\n    sanos_A = os.path.join(validacion, 'sanos_A')\n    os.mkdir(sanos_A)\n    infectados_B = os.path.join(validacion, 'infectados_B')\n    os.mkdir(infectados_B)\n# A continuaci\u00f3n vamos a pasar las im\u00e1genes a las carpetas\n# Establecemos image_id como el valor index de datos\n    datos.set_index('image_id', inplace=True\n# Y obtenemos una lista de im\u00e1genes para cada una de las dos carpetas\n    path_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\n    path_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/'\n    carpeta_1 = os.listdir(path_sanos)\n    carpeta_2 = os.listdir(path_infectados)\n# As\u00ed como una lista para train y validaci\u00f3n\n    lista_train = list(train_df['image_id'])\n    lista_validacion = list(validacion_df['image_id'])\n# Transferimos las im\u00e1genes como hemos hecho en c\u00e9lulas de c\u00f3digo anteriores\n# En el caso de train, escribimos lo siguiente\n    for image in lista_train:\n        fname = image\n        target = datos.loc[image,'target']\n        if target == 0:\n            label = 'sanos_A'\n        else:\n            label = 'infectados_B'\n        if fname in carpeta_1:\n# Como ya hemos explicado anteriormente, hemos definido \"ini\" como origen y \"fin\" como destino\n# Para el directorio de origen, escribiremos la siguiente l\u00ednea de c\u00f3digo\n            ini = os.path.join(path_sanos, fname)\n# Para el directorio de destino\n            fin = os.path.join(train, label, fname)\n            image = cv2.imread(ini)\n            image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n# Guardamos las im\u00e1genes en destino\n            cv2.imwrite(fin, image)\n        if fname in carpeta_2:\n            ini = os.path.join(path_infectados, fname)\n            fin = os.path.join(train, label, fname)\n            image = cv2.imread(ini)\n            image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n            cv2.imwrite(fin, image)\n# Repetimos el proceso para validaci\u00f3n\n    for image in lista_validacion:\n        fname = image\n        target = datos.loc[image,'target']\n        if target == 0:\n            label = 'sanos_A'\n        else:\n            label = 'infectados_B'\n        if fname in carpeta_1:\n            ini = os.path.join(path_sanos, fname)\n            fin = os.path.join(validacion, label, fname)\n            image = cv2.imread(ini)\n            image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n            cv2.imwrite(fin, image)\n        if fname in carpeta_2:\n            ini = os.path.join(path_infectados, fname)\n            fin = os.path.join(validacion, label, fname)\n            image = cv2.imread(ini)\n            image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n            cv2.imwrite(fin, image)\n# Generadores o generators\n    path_train = 'directorio_base\/train'\n    path_validacion = 'directorio_base\/validacion'\n    train_mu = len(train_df)\n    validacion_mu = len(validacion_df)\n    batch_size_train = BATCH_SIZE\n    batch_size_validacion = BATCH_SIZE\n    pasos_train = np.ceil(train_mu \/ batch_size_train)\n    pasos_validacion = np.ceil(validacion_mu \/ batch_size_validacion)\n    datagen = ImageDataGenerator(rescale=1.0\/255)\n    gen_train = datagen.flow_from_directory(path_train,\n                                            target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                            batch_size=batch_size_train,\n                                            class_mode='categorical')\n    gen_validacion = datagen.flow_from_directory(path_validacion,\n                                            target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                            batch_size=batch_size_train,\n                                            class_mode='categorical')\n# Indicamos shuffle=False en la \u00faltima l\u00ednea de c\u00f3digo para que el dataset no sea reorganizado\n    gen_test = datagen.flow_from_directory(path_validacion,\n                                            target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                            batch_size=batch_size_validacion,\n                                            class_mode='categorical',\n                                            shuffle=False)    \n    print('\\n') \n# Indicamos las caracter\u00edsticas del modelo\n    kernel_size = (3,3)\n    pool_size= (2,2)\n    first_filters = 32\n    second_filters = 64\n    third_filters = 128\n    dropout_conv = 0.3\n    dropout_dense = 0.3\n    modelo = Sequential()\n    modelo.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                     input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)))    \n    modelo.add(ZeroPadding2D(padding=(PADDING, PADDING), data_format=None))    \n    modelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n    modelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n    modelo.add(MaxPooling2D(pool_size = pool_size)) \n    modelo.add(Dropout(dropout_conv))\n    modelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n    modelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n    modelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n    modelo.add(MaxPooling2D(pool_size = pool_size))\n    modelo.add(Dropout(dropout_conv))\n    modelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n    modelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n    modelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n    modelo.add(MaxPooling2D(pool_size = pool_size))\n    modelo.add(Dropout(dropout_conv))\n    modelo.add(Flatten())\n    modelo.add(Dense(256, activation = \"relu\"))\n    modelo.add(Dropout(dropout_dense))\n    modelo.add(Dense(2, activation = \"softmax\"))\n# ENTRENAMIENTO O TRAINING DEL MODELO\n    modelo.compile(Adam(lr=0.0001, decay=1e-6), loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    filepath = \"model.h5\"\n    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                                 save_best_only=True, mode='max')\n    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                       verbose=1, mode='max', min_lr=0.00001)\n    lista_callbacks = [checkpoint, reduce_lr]\n    history = modelo.fit(gen_train, steps_per_epoch=pasos_train, \n                                validation_data=gen_validacion,\n                                validation_steps=pasos_validacion,\n                                epochs=NUM_EPOCHS, verbose=1,\n                               callbacks=lista_callbacks)\n# EVALUAMOS EL MODELO EN VALIDACI\u00d3N\n    modelo.load_weights('model.h5')\n    val_loss, val_acc = \\\n    modelo.evaluate_generator(gen_test, \n                            steps=pasos_validacion)    \n# Utilizamos el m\u00e9todo .append() la puntuaci\u00f3n de accuracy y loss a las listas\n    vali_acc_list.append(val_acc)\n    vali_loss_list.append(val_loss)    \n# Calculamos al puntuaci\u00f3n de AUC\n    test_etiquetas = gen_test.classes\n# Realizamos una predicci\u00f3n\n    predicciones = modelo.predict_generator(gen_test, steps=pasos_validacion, verbose=1)    \n# Con .append() las a\u00f1adimos a la lista\n    vali_pred_list.append(predicciones)    \n    vali_auc = roc_auc_score(test_etiquetas, predicciones.argmax(axis=1))   \n    vali_auc_list.append(vali_auc)       ","0c5d2c53":"# Visualizamos el valor de las puntuaciones\nprint('Val Acc')\nfor item in vali_acc_list:\n    print(item)    \nprint('\\n')\nprint('Val Loss')\nfor item in vali_loss_list:\n    print(item)    \nprint('\\n')\nprint('Val AUC')\nfor item in vali_auc_list:\n    print(item)\n# Calculamos la media de las puntuaciones de las cinco particiones o folds\nmed_acc = sum(vali_acc_list)\/len(vali_acc_list)\nmed_loss = sum(vali_loss_list)\/len(vali_loss_list)\nmed_auc = sum(vali_auc_list)\/len(vali_auc_list)\nprint('\\n')\nprint('Media de los 5 folds:\\n')\nprint('Media de Accuracy: ', med_acc)\nprint('Media de Loss: ', med_loss)\nprint('Media de AUC: ', med_auc)","c964510b":"# Eliminamos el directorio que hemos creado nuevamente\nif os.path.isdir('directorio_base') == True:\n        shutil.rmtree('directorio_base')        \nlista_imagenes_aparte = list(df_aparte['image_id'])\n# Seleccionamos s\u00f3lo las filas que no pertenecen al conjunto apartado con ~\ndatos = df_combinado[~df_combinado['image_id'].isin(lista_imagenes_aparte)]\ntrain_df = datos.copy()\nvalidacion_df = df_aparte.copy()\n# Creamos un directorio de nuevo\ndirectorio_base = 'directorio_base'\nos.mkdir(directorio_base)\n# Repetimos el proceso de creaci\u00f3n de carpetas dentro del mismo, tanto para train y validaci\u00f3n como sanos e\n# infectados\ntrain = os.path.join(directorio_base, 'train')\nos.mkdir(train)\nvalidacion = os.path.join(directorio_base, 'validacion')\nos.mkdir(validacion)\nsanos_A = os.path.join(train, 'sanos_A')\nos.mkdir(sanos_A)\ninfectados_B = os.path.join(train, 'infectados_B')\nos.mkdir(infectados_B)\nsanos_A = os.path.join(validacion, 'sanos_A')\nos.mkdir(sanos_A)\ninfectados_B = os.path.join(validacion, 'infectados_B')\nos.mkdir(infectados_B)","d63f5885":"# Pasamos las im\u00e1genes a carpetas\n# Establecemos image_id como el valor index de \"datos\"\ndatos.set_index('image_id', inplace=True)\n# Establecemos image_id como el valor index del conjunto apartado \"df_aparte\"\ndf_aparte.set_index('image_id', inplace=True)\n# Obtenemos una lista de im\u00e1genes para cada una de las dos carpetas\npath_sanos = '\/Users\/gemma\/Desktop\/cell_images\/Uninfected\/'\npath_infectados = '\/Users\/gemma\/Desktop\/cell_images\/Parasitized\/'\ncarpeta_1 = os.listdir(path_sanos)\ncarpeta_2 = os.listdir(path_infectados)\n# As\u00ed como una lista para train y validaci\u00f3n\nlista_train = list(train_df['image_id'])\nlista_validacion = list(validacion_df['image_id'])\n# Transferimos las im\u00e1genes de train \nfor image in lista_train:\n    fname = image\n    target = datos.loc[image,'target']\n    if target == 0:\n        label = 'sanos_A'\n    else:\n        label = 'infectados_B'\n    if fname in carpeta_1:\n        ini = os.path.join(path_sanos, fname)\n        fin = os.path.join(train, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)\n    if fname in carpeta_2:\n        ini = os.path.join(path_infectados, fname)\n        fin = os.path.join(train, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)\n# Hacemos lo mismo para las im\u00e1genes de validaci\u00f3n\nfor image in lista_validacion:\n    fname = image\n    target = df_aparte.loc[image,'target']\n    if target == 0:\n        label = 'sanos_A'\n    else:\n        label = 'infectados_B'\n    if fname in carpeta_1:\n        ini = os.path.join(path_sanos, fname)\n        fin = os.path.join(validacion, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)\n    if fname in carpeta_2:\n        ini = os.path.join(path_infectados, fname)\n        fin = os.path.join(validacion, label, fname)\n        image = cv2.imread(ini)\n        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n        cv2.imwrite(fin, image)","0cb6d882":"# Generadores o generators\npath_train = 'directorio_base\/train'\npath_validacion = 'directorio_base\/validacion'\ntrain_mu = len(train_df)\nvalidacion_mu = len(validacion_df)\nbatch_size_train = BATCH_SIZE\nbatch_size_validacion = BATCH_SIZE\npasos_train = np.ceil(train_mu \/ batch_size_train)\npasos_validacion = np.ceil(validacion_mu \/ batch_size_validacion)\ndatagen = ImageDataGenerator(rescale=1.0\/255)\ngen_train = datagen.flow_from_directory(path_train,\n                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                        batch_size=batch_size_train,\n                                        class_mode='categorical')\n# Indicamos shuffle=False en la \u00faltima l\u00ednea de c\u00f3digo para que el dataset no sea reorganizado\ngen_test = datagen.flow_from_directory(path_validacion,\n                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n                                        batch_size=batch_size_train,\n                                        class_mode='categorical',\n                                        shuffle=False)\nprint('\\n')\n# Indicamos las caracter\u00edsticas del modelo\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\ndropout_conv = 0.3\ndropout_dense = 0.3\nmodelo = Sequential()\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                 input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\nmodelo.add(ZeroPadding2D(padding=(PADDING, PADDING), data_format=None))\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodelo.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size)) \nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size))\nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodelo.add(MaxPooling2D(pool_size = pool_size))\nmodelo.add(Dropout(dropout_conv))\nmodelo.add(Flatten())\nmodelo.add(Dense(256, activation = \"relu\"))\nmodelo.add(Dropout(dropout_dense))\nmodelo.add(Dense(2, activation = \"softmax\"))\n# ENTRENAMIENTO DEL MODELO\nmodelo.compile(Adam(lr=0.0001, decay=1e-6), loss='binary_crossentropy', \n              metrics=['accuracy'])\n# Guardamos el modelo bas\u00e1ndonos en la exactitud en el entrenamiento\nfilepath = \"final_model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, \n                             save_best_only=True, mode='max')\nlista_callbacks = [checkpoint]\nhistory = modelo.fit(gen_train, steps_per_epoch=pasos_train, \n                            epochs=NUM_FINAL_MODEL_EPOCHS, verbose=1,\n                            callbacks=lista_callbacks)\nimport h5py\nfrom keras.models import load_model\nmodelo.save('final_model.h5')\n# EVALUAMOS EL MODELO EN VALIDACI\u00d3N\nmodelo.load_weights('final_model.h5')\nval_loss, val_acc = \\\nmodelo.evaluate_generator(gen_test, \n                        steps=pasos_validacion)\n# Calculamos al puntuaci\u00f3n de AUC\ntest_etiquetas = gen_test.classes\n# Hacemos una predicci\u00f3n\npredicciones = modelo.predict_generator(gen_test, steps=pasos_validacion, verbose=1)\nvali_auc = roc_auc_score(test_etiquetas, predicciones.argmax(axis=1))","967e37d0":"# Mostramos las puntuaciones de accuracy, loss y AUC\nprint('\\n')\nprint('Accuracy: ', val_acc)\nprint('Loss: ', val_loss)\nprint('AUC: ', vali_auc)","3897b0f1":"# Utilizamos argmax(), que nos devuelve el \u00edndice del valor m\u00e1ximo de una fila\ncm = confusion_matrix(test_etiquetas, predicciones.argmax(axis=1))\ngen_test.class_indices","217530d5":"# Representamos la Confusion Matrix especificando las etiquetas\ncm_plot_etiquetas = ['Sanos', 'Infectados']\nplot_confusion_matrix(cm, cm_plot_etiquetas, title='Confusion Matrix')","49ccb887":"# Obtenemos los nombres de los archivos, etiquetas y predicciones asociadas y gracias al procesamiento del\n# generator, procedemos a obtener un informe de clasificaci\u00f3n\ntest_nombres = gen_test.filenames\n# Obtenemos las etiquetas reales\ny_real = gen_test.classes\n# As\u00ed como las predicciones\ny_prediccion = predicciones.argmax(axis=1)\n# Y generamos un archivo de clasificaci\u00f3n a modo de informe\nclasificacion = classification_report(y_real, y_prediccion, target_names=cm_plot_etiquetas)\nprint(clasificacion)","b5802725":"### Establecimiento de las caracter\u00edsticas del modelo","470f0b6c":"### Valoraci\u00f3n del modelo con el set de validaci\u00f3n","8b3dcb84":"## 7. Validaci\u00f3n cruzada de 5 iteraciones","1cea125d":"### Confusion Matrix","f5cf236b":"## 1. Introducci\u00f3n","409818ab":"### Visualizaci\u00f3n de im\u00e1genes","6b9428ab":"# TRABAJO DE FIN DE M\u00c1STER - Gemma","e7db88fc":"## 8. Entrenamiento del modelo final","87b76ed9":"### Creaci\u00f3n de los sets de train y validaci\u00f3n","9961d4fa":"### Generators","e1be8667":"## 10. Referencias","34ea9e61":"### Puntuaciones","3acb76ff":"### Creaci\u00f3n del directorio","a07c304c":"### Representaci\u00f3n gr\u00e1fica de las curvas de loss y accuracy","6e402aef":"## 6. An\u00e1lisis de errores","bd0df013":"<a href='#Introducci\u00f3n'>1. Introducci\u00f3n<\/a><br>\n<a href='#An\u00e1lisis Exploratorio de los Datos'>2. An\u00e1lisis Exploratorio de los Datos<\/a><br>\n<a href='#Creaci\u00f3n del conjunto de reserva'>3. Creaci\u00f3n del conjunto de reserva<\/a><br>\n<a href='#Divisi\u00f3n de datos en train y test'>4. Divisi\u00f3n de datos en train y test<\/a><br>\n<a href='#Entrenamiento del modelo'>5. Entrenamiento del modelo<\/a><br>\n<a href='#An\u00e1lisis de errores'>6. An\u00e1lisis de errores<\/a><br>\n<a href='#Validaci\u00f3n cruzada de 5 iteraciones'>7. Validaci\u00f3n cruzada de 5 iteraciones<\/a><br>\n<a href='#Entrenamiento del modelo final'>8. Entrenamiento del modelo final<\/a><br>\n<a href='#Evaluaci\u00f3n del modelo final en el conjunto de reserva'>9. Evaluaci\u00f3n del modelo final en el conjunto de reserva<\/a><br>\n<a href='#Referencias'>10. Referencias<\/a><br>","b41cebc9":"### Importaci\u00f3n de los datos","7fff00c9":"### \u00bfExiste alg\u00fan tipo de archivo que no sea una imagen?","920d35c5":"### Informe de clasificaci\u00f3n","c39fec28":"### Organizaci\u00f3n de las im\u00e1genes en dataframes","9a9107e6":"## 2. An\u00e1lisis Exploratorio de los Datos","96dc97f2":"Listado de webs a las que se ha hecho referencia en distintas c\u00e9lulas del c\u00f3digo:\n\n**Cell 36**: Arquitectura del modelo de red neuronal convolucional https:\/\/gist.github.com\/Mishaall\/f52e717eae11080c4fc530e9ef5082ff\n\n**Cell 38**: *How to Check-Point Deep Learning Models in Keras* https:\/\/machinelearningmastery.com\/check-point-deep-learning-models-keras\/","da6ed992":"### Traslado de las im\u00e1genes a carpetas","c3c4225d":"### Informe de clasificaci\u00f3n","a898a481":"## \u00cdndice","207eb989":"### Entrenamiento del modelo","e89a5512":"## 3. Creaci\u00f3n del conjunto de reserva","a2ec0af7":"### Tama\u00f1o de las im\u00e1genes y canales","72d67d2a":"## Clasificaci\u00f3n de im\u00e1genes de c\u00e9lulas sangu\u00edneas en pacientes infectados y no infectados de malaria mediante t\u00e9cnicas de Aprendizaje Profundo","76c2c8c2":"### Confusion Matrix","36ae1e79":"## 9. Evaluaci\u00f3n del modelo final en el conjunto de reserva","1bababe0":"## 4. Divisi\u00f3n de datos en train y validaci\u00f3n","0af9bab5":"## 5. Entrenamiento del modelo"}}