{"cell_type":{"a0394fd5":"code","a9407e64":"code","f81fff17":"code","5ffc7b26":"code","dfd08224":"code","270d6ec1":"code","8fd0374d":"code","b54c88f7":"code","62cf2a74":"code","3e8899b7":"code","a468331e":"code","555cd00e":"code","7d9b560d":"code","21c8ae87":"code","86c1c2f7":"code","2b7cdf71":"code","53aca2e8":"code","fbb19718":"code","3cf41133":"markdown","1ff50cef":"markdown","0fca3f9c":"markdown","a059959c":"markdown","048b5791":"markdown","77b9a401":"markdown","4a650d5b":"markdown","846d08c6":"markdown","62210853":"markdown","3ef795de":"markdown","9c8cae75":"markdown","7109e655":"markdown","dcb3354b":"markdown","2ed9880d":"markdown","34bf85a8":"markdown","3eec1b98":"markdown","4c39ee1f":"markdown","9ea30ef6":"markdown","ae95f324":"markdown","f47a9e4c":"markdown","5877b987":"markdown"},"source":{"a0394fd5":"import numpy as np\nimport pandas as pd \nimport random\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras.applications.xception as xception\nimport zipfile\nimport sys\nimport time\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport re\n\nfrom PIL import Image\nfrom keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom keras.layers.experimental.preprocessing import Normalization\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing import image\nfrom keras.utils import to_categorical\nfrom keras.layers import Lambda\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nprint('setup successful!')","a9407e64":"# Increasing the image size didn't result in increasing the training accuracy\nIMAGE_WIDTH = 320    \nIMAGE_HEIGHT = 320\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS = 3\n\n\n# Path where our data is located\nbase_path = \"..\/input\/garbage-classification\/garbage_classification\/\"\n\n# Dictionary to save our 12 classes\ncategories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'trash', 5: 'battery',\n              6: 'shoes', 7: 'clothes', 8: 'green-glass', 9: 'brown-glass', 10: 'white-glass',\n              11: 'biological'}\n\nprint('defining constants successful!')","f81fff17":"# Add class name prefix to filename. So for example \"\/paper104.jpg\" become \"paper\/paper104.jpg\"\ndef add_class_name_prefix(df, col_name):\n    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '\/' + x)\n    return df\n\n# list conatining all the filenames in the dataset\nfilenames_list = []\n# list to store the corresponding category, note that each folder of the dataset has one class of data\ncategories_list = []\n\nfor category in categories:\n    filenames = os.listdir(base_path + categories[category])\n    \n    filenames_list = filenames_list  +filenames\n    categories_list = categories_list + [category] * len(filenames)\n    \ndf = pd.DataFrame({\n    'filename': filenames_list,\n    'category': categories_list\n})\n\ndf = add_class_name_prefix(df, 'filename')\n\n# Shuffle the dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\n\nprint('number of elements = ' , len(df))","5ffc7b26":"df.head()","dfd08224":"# see sample image, you can run the same cell again to get a different image\nrandom_row = random.randint(0, len(df)-1)\nsample = df.iloc[random_row]\nrandomimage = image.load_img(base_path +sample['filename'])\nprint(sample['filename'])\nplt.imshow(randomimage)","270d6ec1":"df_visualization = df.copy()\n# Change the catgegories from numbers to names\ndf_visualization['category'] = df_visualization['category'].apply(lambda x:categories[x] )\n\ndf_visualization['category'].value_counts().plot.bar(x = 'count', y = 'category' )\n\nplt.xlabel(\"Garbage Classes\", labelpad=14)\nplt.ylabel(\"Images Count\", labelpad=14)\nplt.title(\"Count of images per class\", y=1.02);","8fd0374d":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nimport keras.applications.xception as xception\n\nxception_layer = xception.Xception(include_top = False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS),\n                       weights = '..\/input\/xception\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n# We don't want to train the imported weights\nxception_layer.trainable = False\n\n\nmodel = Sequential()\nmodel.add(keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n\n#create a custom layer to apply the preprocessing\ndef xception_preprocessing(img):\n  return xception.preprocess_input(img)\n\nmodel.add(Lambda(xception_preprocessing))\n\nmodel.add(xception_layer)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(Dense(len(categories), activation='softmax')) \n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n\nmodel.summary()","b54c88f7":"early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_categorical_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n\ncallbacks = [early_stop]\n\nprint('call back defined!')","62cf2a74":"#Change the categories from numbers to names\ndf[\"category\"] = df[\"category\"].replace(categories) \n\n# We first split the data into two sets and then split the validate_df to two sets\ntrain_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\nvalidate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\nprint('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])","3e8899b7":"batch_size=64\n\ntrain_datagen = image.ImageDataGenerator(\n    \n    ###  Augmentation Start  ###\n    \n    #rotation_range=30,\n    #shear_range=0.1,\n    #zoom_range=0.3,\n    #horizontal_flip=True,\n    #vertical_flip = True,\n    #width_shift_range=0.2,\n    #height_shift_range=0.2\n    \n    ##  Augmentation End  ###\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","a468331e":"validation_datagen = image.ImageDataGenerator()\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","555cd00e":"EPOCHS = 20\nhistory = model.fit_generator(\n    train_generator, \n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","7d9b560d":"model.save_weights(\"model.h5\")","21c8ae87":"fig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_yticks(np.arange(0, 0.7, 0.1))\nax1.legend()\n\nax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nax2.legend()\n\nlegend = plt.legend(loc='best')\nplt.tight_layout()\nplt.show()","86c1c2f7":"test_datagen = image.ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe= test_df,\n    directory=base_path,\n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=1,\n    shuffle=False \n)","2b7cdf71":"filenames = test_generator.filenames\nnb_samples = len(filenames)\n\n_, accuracy = model.evaluate_generator(test_generator, nb_samples)\n\nprint('accuracy on test set = ',  round((accuracy * 100),2 ), '% ') ","53aca2e8":"# We defined at the beginning of this notebook a dictionary that maps the categories number to names, but the train generator\n# generated it's own dictionary and it has assigned different numbers to our categories and the predictions made by the model \n# will be made using the genrator's dictionary.\n\ngen_label_map = test_generator.class_indices\ngen_label_map = dict((v,k) for k,v in gen_label_map.items())\nprint(gen_label_map)","fbb19718":"# get the model's predictions for the test set\npreds = model.predict_generator(test_generator, nb_samples)\n\n# Get the category with the highest predicted probability, the prediction is only the category's number and not name\npreds = preds.argmax(1)\n\n# Convert the predicted category's number to name \npreds = [gen_label_map[item] for item in preds]\n\n# Convert the pandas dataframe to a numpy matrix\nlabels = test_df['category'].to_numpy()\n\nprint(classification_report(labels, preds))","3cf41133":"# Split the Data Set","1ff50cef":"We will use the EarlyStopping call back to stop our training if the validation_accuray is not improving for a certain number of epochs.","0fca3f9c":"The table above shows among other info the F1 score of each category. In the bottom of the F1 score column notice two numbers accuracy and macro avg. Accuracy is the same accuracy that we evaluated above for the test set, it is a weighted average. \n\nHowever the macro avg (unweighted average) is a bit less than accuracy. This is because the clothes category, the category which has by far the largest number of images, has a very high F1 score, so accuracy (the weighted average) is higher than the unweighted average (macro avg).\n\nFor this problem I would consider the macro avg a better measure of accuracy as it takes an average of all the F1 scores regardless of how much data we have in the training data for each category.","a059959c":"# Train the model","048b5791":"## End Note","77b9a401":"To evaluate the performance of our model we will create a test generator to load the images from the input data directory and evaluate the results.","4a650d5b":"# Visualize the training process\n","846d08c6":"If you liked this kernel please upvote! I also created a small web app to classify the garbage images, https:\/\/mostafa-portfolio.azurewebsites.net\/ feel free to play around with it!","62210853":"We will first create the training data generator, that will get the images from the input data directory to train on them. We will also create a generator for the validation set.\n\nApplying Data Augmentation on the training set was taking too long to be executed and the initial results didn't show much improvement than the results without augmentation, so I commented the augmentation to make the training faster. However fell free to uncomment the Data Augmentation lines in the following cell and play a bit with it.","3ef795de":"Great, the accuracy is well over 90% !! (it varies from one run to another due to the random shuffling but is between 94% and 96%) \n\nBut let's have a look on the F1 score for each of the categories. For that we will be using the classification_report from the sklearn package.","9c8cae75":"# Import Required Libraries","7109e655":"# Define Constants","dcb3354b":"We want to create a data frame that has in one column the filenames of all our images and in the other column the corresponding category. \nWe Open the directories in the dataset one by one, save the filenames in the filenames_list and add the corresponding category in the categories_list","2ed9880d":"# Garbage Classification using keras and transfer learning","34bf85a8":"The steps are:\n1. Create an xception model without the last layer and load the ImageNet pretrained weights\n2. Add a pre-processing layer\n3. Add a pooling layer followed by a softmax layer at the end","3eec1b98":"# Create DataFrame","4c39ee1f":"We split the training set into three separate sets:\n\n1. **The training set:** used to train our model.\n1. **The validation set**: used to double check that our model is not overfitting the training set, i.e. it can also generalise to other data other than the train data\n1. **The Test set:** Used to estimate the accuracy of the model on new data other than the ones the model used for training\nFor a competition  or for some other cases, you can split the data only to training and validation sets in order to achieve the highest  possible accuracy, without the need to properly estimate how accurate the model really is.\n\nWe split the data set as follows: 80% train set, 10% cross_validation set, and 10% test set","9ea30ef6":"# Viusalize the Categories Distribution","ae95f324":"# Evaluate the test","f47a9e4c":"# Create the model","5877b987":"This kernel shows how to classify Garbage images into 12 different classes using transfer learning. I also created a webapp that can classify garbage images based on the model trained here, fell free to play a bit with it! https:\/\/mostafa-portfolio.azurewebsites.net\/ .If you find this kernel useful please upvote it!\n\nTransfer learning means that instead of your model learning everything from scratch, it uses another model that was trained on a similar problem, so that you can \"transfer\" the learned \"knowledge\" of the pretrained model to your model, and then learn some new features.\n\nThe ImageNet Data set is huge data set consisting of more than 14 million images from more than 22,000 different categories, here we are using a smaller version of it which has 1000 different categories.\n\nIn this kernel we use an xception model which is pretrained on the ImageNet dataset and then build some layers on top of it to be able to classify the garbage images.\n\nTransfer learning makes sense here because the ImageNet data set has a much larger number of images (14 million) than the Garbage Classification data set (around 15,500 image). This increases the speed of training for our model and the accuracy of our predictions."}}