{"cell_type":{"aa32fe2b":"code","6b8b0fa2":"code","8b4e43da":"code","e90abc24":"code","587d6d63":"code","f5936691":"code","1108a960":"code","0e1af28f":"code","21e9a0fd":"code","d8708ada":"code","d984f151":"code","5b7f14e3":"code","f4187bc5":"code","91e05517":"code","47a38cbe":"code","1a6d6b87":"code","3e562863":"code","010a8104":"code","9269e990":"code","952022e8":"code","82e55465":"code","eb6bcf32":"code","9f63d9be":"code","a5430cac":"code","60637f54":"code","9d6d78c8":"code","d78d2a42":"code","80c618b4":"code","d405358c":"code","a9a44121":"code","ff791eb3":"markdown","ae0d8049":"markdown","e6141315":"markdown","6dff2902":"markdown","e1eeeeae":"markdown","6ad09a9d":"markdown","2e131be8":"markdown","92b77f9b":"markdown","f37d27a3":"markdown","b16de134":"markdown","4db1924f":"markdown","32b6b855":"markdown","489cdffc":"markdown","a652a1d0":"markdown","8ccaf373":"markdown","2fcf48ef":"markdown","35a42bb7":"markdown","f39e21eb":"markdown","a3fb5ccb":"markdown","f36d6580":"markdown","66caaae4":"markdown","cff267d1":"markdown","8e0d1cad":"markdown","32bc104f":"markdown","f8e56181":"markdown","8c5e18d6":"markdown"},"source":{"aa32fe2b":"import torch \nimport numpy as np\nimport pandas as pd\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","6b8b0fa2":"dataset=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","8b4e43da":"dataset","e90abc24":"test_data=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","587d6d63":"targets_numpy = dataset.label.values","f5936691":"feature_numpy=dataset.loc[:,dataset.columns != \"label\"].values\/255","1108a960":"X_train, X_test, y_train, y_test = train_test_split(feature_numpy, targets_numpy, test_size=0.2, random_state=42)","0e1af28f":"featuresTrain=torch.from_numpy(X_train)\ntargetsTrain=torch.from_numpy(y_train).type(torch.LongTensor)","21e9a0fd":"featuresTest=torch.from_numpy(X_test)\ntargetsTest=torch.from_numpy(y_test).type(torch.LongTensor)","d8708ada":"# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters \/ (len(X_train) \/ batch_size)\nnum_epochs = int(num_epochs)","d984f151":"train=torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest=torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n\n#data loader\ntrainloader=torch.utils.data.DataLoader(train,batch_size=batch_size,shuffle=False)\ntestloader=torch.utils.data.DataLoader(test,batch_size=batch_size,shuffle=False)","5b7f14e3":"plt.imshow(feature_numpy[10].reshape(28,28))\nplt.axis(\"off\")\nplt.title(targets_numpy[10])\nplt.show()","f4187bc5":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Create Logistic Regression Model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        hidden_1=512\n        hidden_2=512\n        \n        self.fc1=nn.Linear(28*28,hidden_1)\n        self.fc2=nn.Linear(hidden_1,hidden_2)\n        self.fc3=nn.Linear(hidden_2,10)\n        self.dropout=nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        \n        x = self.dropout(x)\n        \n        x = F.relu(self.fc2(x))\n        \n        x = self.dropout(x)\n        \n        x = self.fc3(x)\n        \n        return x\n# Instantiate Model Class\ninput_dim = 28*28 # size of image px*px\noutput_dim = 10  # labels 0,1,2,3,4,5,6,7,8,9\n\n# create logistic regression model\nmodel = Net()","91e05517":"if torch.cuda.is_available():\n    model.cuda()\n    print(\"cuda is available\")","47a38cbe":"error =nn.CrossEntropyLoss()\n\noptimizer=torch.optim.SGD(model.parameters(),lr=0.01)","1a6d6b87":"for i,(images,label) in enumerate(trainloader):\n    train=Variable(images.view(-1,28*28))\n    print(train.float())\n    print(train.shape)\n    break","3e562863":"n_epochs = 50","010a8104":"count = 0\nstep=0\nloss_list = []\niteration_list = []\n\nfor epoch in range(n_epochs):\n    train_loss=0.0\n    model.train()\n    for i,(images,labels) in enumerate(trainloader):\n        if torch.cuda.is_available():\n            images,labels=images.cuda(),labels.cuda()\n        \n        train=Variable(images.view(-1,28*28))\n        labels=Variable(labels)\n        \n        \n        optimizer.zero_grad()\n        \n        output=model(train.float())\n        \n        loss=error(output,labels)\n        loss.backward()\n        \n        optimizer.step()\n        \n        count+=1\n            \n        train_loss +=loss.item()*images.size(0)\n\n        if count% 50==0:\n            #calculate accuracy\n            correct=0\n            total=0\n            for images,labels in testloader:\n                if torch.cuda.is_available():\n                    images,labels=images.cuda(),labels.cuda()\n                test=Variable(images.view(-1,28*28))\n                outputs = model(test.float())\n                \n                predicted = torch.max(outputs.data, 1)[1]\n                \n                total +=len(labels)\n                \n                correct +=(predicted==labels).sum()\n            accuracy =100 *correct\/float(total)\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n        if count % 500 == 0:\n            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n","9269e990":"#loss:4414.322540 acc:95%\nfor i,(images,labels) in enumerate(trainloader):\n    images=images.numpy()\n    print(images.shape)\n    break","952022e8":"# visualization\nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Logistic Regression: Loss vs Number of iteration\")\nplt.show()","82e55465":"torch.save(model.state_dict(),\"..\/working\/model.pt\")","eb6bcf32":"model1 = Net()\nmodel1.load_state_dict(torch.load(\"..\/working\/model.pt\"))","9f63d9be":"batch_size=100\nfeatures_numpy_final= test_data.values\/255\n\nfinaltest=torch.from_numpy(features_numpy_final)\n\nfinal_test=torch.utils.data.TensorDataset(finaltest)\nfinal_loader=torch.utils.data.DataLoader(finaltest,batch_size=batch_size,shuffle=False)","a5430cac":"plt.imshow(features_numpy_final[3].reshape(28,28))\nplt.axis(\"off\")\nplt.savefig('..\/working\/graph.png')\nplt.show()","60637f54":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nlist_predict_to_append=[]\nlist_of_number=[]\nfor i,(images) in enumerate(final_loader,start=1):\n    images = images.to(device)\n    testoutput=Variable(images.view(-1,28*28))\n    if torch.cuda.is_available():\n        outputs = model1(testoutput.cuda().float().cpu())\n    else:\n        outputs = model1(testoutput.float())\n    predicted =torch.max(outputs.data,1)[1]\n    list_predict_to_append.extend(predicted.tolist())\n    list_of_number.append(i)","9d6d78c8":"len(list_predict_to_append)","d78d2a42":"list_of_number=np.arange(1,28001).tolist()\nprint(len(list_of_number))","80c618b4":"data={'ImageId':list_of_number,'Label':list_predict_to_append}","d405358c":"new_prediction=pd.DataFrame(data,columns=['ImageId','Label'])","a9a44121":"new_prediction","ff791eb3":"# Introduction To pytorch and MNIST dataset\nAfter reading this notebook you will develop basic understanding to build model in pytorch\nThe process will be broken down into the following steps:\n>1. Load and visualize the data\n2. Define a neural network\n3. Train the model\n4. Evaluate the performance of our trained model on a test dataset!","ae0d8049":"Load the model","e6141315":"# 1. Load and visulalize the data\n#### load data in dataset using pandas \n<code>pd.read_csv<\/code>","6dff2902":"## Train the Network\n\nThe steps for training\/learning from a batch of data are described in the comments below:\n1. Clear the gradients of all optimized variables\n2. Forward pass: compute predicted outputs by passing inputs to the model\n3. Calculate the loss\n4. Backward pass: compute gradient of the loss with respect to model parameters\n5. Perform a single optimization step (parameter update)\n6. Update average training loss\n\nThe following loop trains for 50 epochs; take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data.","e1eeeeae":"#### Now we create a targetList which contain labels of each image\n","6ad09a9d":"### Split dataset in train and test\nIt is very important step to split dataset into training and testing dataset yo can easy split data using sklearn <br>\nimport the model by <code>from sklearn.model_selection import train_test_split<\/code>\nand parameters are \n- features\n- targetList\n- <code>test_size=0.2<\/code> this parameter will split dataset into testing data 20% and training data 80%\n- <code>random_state=42<\/code> random_state is the seed used by the random number generator. means if you use the same number other time you will get the exactly same train and test data","2e131be8":"## Loading numpy data to torch  \nthis is important part to load the dataset to torch so that you can use torch function ","92b77f9b":"before converting torch value to Tensor we first have to create batch_size to train a single batch in single iterations ","f37d27a3":"# Evaluate the performance of our trained model on a test dataset!\n#### Plotting graph to understand the training \nhere we can see during the training the loss value decrease every iteration ","b16de134":"<code> All keys matched successfully <\/code> this is the sign that indicate, you have successfully loaded the model","4db1924f":"##### Declaring the epochs to train data for that many time you can change the value to higher value if you want to","32b6b855":"## If your pc have gpu and want to use it for training install cuda \nvideo [link](https:\/\/youtu.be\/io6Ajf5XkaM) to install cuda,\nIf you have install CUDA install in your pc then run this code","489cdffc":"here we check the shape of trainloader we can see that the ouput is <code> (100,784)<\/code> where the 100 is the batch_size and 784 is the <code> height X width <\/code> of each image","a652a1d0":"#### Visualize the data","8ccaf373":"My first kernal hope you like it \nplz leave your comment and doubt ","2fcf48ef":"#### define loss function and optimizer for the neural network\nHere we have declare <code>CrossEntropyLoss()<\/code> for loss function <br>\nand optimizer as \"stochastic gradient descent\" <code>SGD<\/code>","35a42bb7":"- first import torch and other tools ","f39e21eb":"# Define the Network [Architecture](http:\/\/pytorch.org\/docs\/stable\/nn.html)\n\nThe architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting.","a3fb5ccb":"### preprocess the test data for prediction","f36d6580":"### Important step to normilze the features \nHere every pixel have values which lies between 0 to 255,<br>\nso we convert all pixel values to lie between 0 to 1 by dividing every pixel by 255.<br>\n- here we will select all columns except the label column and divide it by 255.","66caaae4":"#### Converting features and target torch to Tensordataset to minize the computation time \nusing <code>torch.utils.data.TensorDataset<\/code><br>\nafter converting to tensor we have to create a dataLoader object using <code>torch.utils.data.DataLoader<\/code>","cff267d1":"### understanding the dataset\n\n- loading training dataset \n\nSo in the dataset we have given every pixel value of a image, there are total <code>28 x 28 = 784 pixels<\/code >","8e0d1cad":"- loading test dataset for final prediction","32bc104f":"Checking the size of tainloader and converting it to the shape of the input size of the Neural Network","f8e56181":"#### save model and model architecture to model.pth","8c5e18d6":"Using the new model to predict the number "}}