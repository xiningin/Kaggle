{"cell_type":{"b1843ba0":"code","77e88df2":"code","57e58f33":"code","521471eb":"code","6f89ceb3":"code","82260fb0":"code","ca03b48e":"code","b29becde":"code","c570543f":"markdown","f3800259":"markdown","25e3d884":"markdown","c7c7db5b":"markdown","1f4dfbb6":"markdown"},"source":{"b1843ba0":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport glob\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision.transforms import functional as F\n\nimport matplotlib.pyplot as plt","77e88df2":"def get_profile_path(category):\n\n    data = []\n\n    for path in sorted(glob.glob('..\/input\/%s_images\/*-1.jpg' % category)):\n\n        data.append({\n            'PetID': path.split('\/')[-1].split('-')[0],\n            'path': path,\n        })\n            \n    return pd.DataFrame(data)\n\ntrain = get_profile_path('train')\ntest = get_profile_path('test')","57e58f33":"def resize_to_square(image, size):\n    h, w, d = image.shape\n    ratio = size \/ max(h, w)\n    resized_image = cv2.resize(image, (int(w*ratio), int(h*ratio)), cv2.INTER_AREA)\n    return resized_image\n\ndef image_to_tensor(image, normalize=None):\n    tensor = torch.from_numpy(np.moveaxis(image \/ (255. if image.dtype == np.uint8 else 1), -1, 0).astype(np.float32))\n    if normalize is not None:\n        return F.normalize(tensor, **normalize)\n    return tensor\n\ndef pad(image, min_height, min_width):\n    h,w,d = image.shape\n\n    if h < min_height:\n        h_pad_top = int((min_height - h) \/ 2.0)\n        h_pad_bottom = min_height - h - h_pad_top\n    else:\n        h_pad_top = 0\n        h_pad_bottom = 0\n\n    if w < min_width:\n        w_pad_left = int((min_width - w) \/ 2.0)\n        w_pad_right = min_width - w - w_pad_left\n    else:\n        w_pad_left = 0\n        w_pad_right = 0\n\n    return cv2.copyMakeBorder(image, h_pad_top, h_pad_bottom, w_pad_left, w_pad_right, cv2.BORDER_CONSTANT, value=(0,0,0))\n\n\nclass Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, df, size):\n        self.df = df\n        self.size = size\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n\n        row = self.df.iloc[idx]\n\n        image = cv2.imread(row.path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = resize_to_square(image, self.size)\n        image = pad(image, self.size, self.size)\n        tensor = image_to_tensor(image, normalize={'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]})\n            \n        return tensor","521471eb":"random.seed(70)","6f89ceb3":"size = 224\n\ndef show_image_pair(image1, image2):\n    fig = plt.figure(figsize=(10, 20))\n    fig.add_subplot(1,2,1)\n    plt.imshow(image1)\n    fig.add_subplot(1,2, 2)\n    plt.imshow(image2)\n    plt.show()\n\ndef test_dataset(idx=0):\n\n    dataset = Dataset(train, size)\n\n    image1 = cv2.imread(dataset.df.iloc[idx].path)\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n\n    tensor = dataset[idx]\n    image2 = np.transpose(tensor.numpy(), (1,2,0))\n\n    show_image_pair(image1, image2)\n\nfor idx in [random.choice(range(1000)) for i in range(3)]:\n    test_dataset(idx)","82260fb0":"model_name = 'densenet121'\nlayer_name = 'features'\n\n# If you want to use other models such as resnet18, uncomment lines below\n#model_name = 'resnet18'\n#layer_name = 'avgpool'\n\nget_model = getattr(torchvision.models, model_name)\n\ndef extract_features(df):\n\n    model = get_model(pretrained=True)\n    model = model.cuda()\n    model.eval()\n\n    # register hook to access to features in forward pass\n    features = []\n    def hook(module, input, output):\n        N,C,H,W = output.shape\n        output = output.reshape(N,C,-1)\n        features.append(output.mean(dim=2).cpu().detach().numpy())\n    handle = model._modules.get(layer_name).register_forward_hook(hook)\n\n    dataset = Dataset(df, size)\n    loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n\n    for i_batch, inputs in tqdm(enumerate(loader), total=len(loader)):\n        _ = model(inputs.cuda())\n\n    features = np.concatenate(features)\n\n    features = pd.DataFrame(features)\n    features = features.add_prefix('IMAGE_')\n    features.loc[:,'PetID'] = df['PetID']\n    \n    handle.remove()\n    del model\n\n    return features","ca03b48e":"features_train = extract_features(train)\nfeatures_test = extract_features(test)","b29becde":"features_train.to_csv('%s_size%d_train.csv' % (model_name, size), index=False)\nfeatures_test.to_csv('%s_size%d_test.csv' % (model_name, size), index=False)","c570543f":"I originally implemented these image transforms using albumentations but the library was not included in kaggle kernel and had to adopt some functionalities. https:\/\/github.com\/albu\/albumentations","f3800259":"## Let's check how images are transformed.","25e3d884":"## Prepare dataset for feature extraction","c7c7db5b":"This kernel extracts features from pet image. \n\n- Pytorch implementation.\n- Resize image to square while keeping its aspect ratio.\n- Profile image is used.\n- Pretrained densenet121 is used but you can use resnet or other architectures by replacing a few lines of code.\n\nThe kernel is inspired by dieter's great kernel https:\/\/www.kaggle.com\/christofhenkel\/extract-image-features-from-pretrained-nn\nPlease check his kernel too if you haven't.","1f4dfbb6":"## Extract features\n\nYou can use register_forward_hook to extract features without modifying the forward pass. https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/nn\/modules\/module.html#Module.register_forward_hook\n\nOfficial pytorch pretrained models can be found here. https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html"}}