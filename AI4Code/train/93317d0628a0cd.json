{"cell_type":{"f87d2a3e":"code","2f0e25a1":"code","46621816":"code","21f9768a":"code","f8f1a612":"code","e6b8a2d2":"code","b12e1c4f":"code","e2586bde":"code","e36aca28":"code","3894bab4":"code","69f09164":"code","aeb23a12":"code","e7adc0a6":"code","e0e54657":"code","28e8ac95":"code","2c574c16":"code","06c5c0f5":"code","a68ab612":"code","e70c1c78":"code","2b82d833":"code","6078151a":"markdown","dc1f86c2":"markdown","5366539d":"markdown","f75c4cba":"markdown","2c69bce3":"markdown","44d72bc8":"markdown","b65abcc0":"markdown","8fbb431d":"markdown","4fe0ba7e":"markdown","a5655bc5":"markdown","4c38d6a4":"markdown","7ca8b3b4":"markdown","cbef6b31":"markdown","9b2d7861":"markdown","a46463e5":"markdown","7c3309e7":"markdown","d1c3732e":"markdown","36b3d91f":"markdown","46fc6908":"markdown","e460cc4c":"markdown","015ae5a3":"markdown"},"source":{"f87d2a3e":"# import packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport seaborn as sns\nfrom itertools import chain\nfrom fuzzywuzzy import fuzz\nimport math\n\n%matplotlib inline\nsns.set()\n\n# setting some global styles for matplotlib & pandas\nplt.rcParams['font.family'] = 'monospace'\nsns.set_style({\"axes.facecolor\": \"1.0\", 'grid.linestyle': '--', 'grid.color': '.8'})\ncolors = [\"#fcd74e\", \"#0b84a5\"]\npd.set_option(\"display.max_columns\", 300)\npd.set_option('display.max_colwidth', -1)\n\n# dev vs prod settings\ndev = False\n\nif dev == True:\n    import os   \n    # Print input files\n    for dirname, _, filenames in os.walk('\/kaggle\/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\nelse:            \n    import warnings \n    warnings.filterwarnings('ignore')\n            \n# import data\nmult_choice_responses = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\nother_responses       = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/other_text_responses.csv')","2f0e25a1":"###############################################################################################\n# replace mult_choice OTHER columns with their actual text responses (from other_responses)\nOTHERS_to_replace = ['Q9_OTHER_TEXT', 'Q14_Part_1_TEXT', 'Q14_Part_2_TEXT', 'Q14_Part_3_TEXT',\n                     'Q14_Part_4_TEXT', 'Q14_Part_5_TEXT', 'Q18_OTHER_TEXT', 'Q19_OTHER_TEXT',\n                     'Q20_OTHER_TEXT', 'Q24_OTHER_TEXT', 'Q27_OTHER_TEXT', 'Q28_OTHER_TEXT', \n                     'Q34_OTHER_TEXT']\n\nfor col in OTHERS_to_replace:\n    mult_choice_responses[col] = other_responses[col]\n###############################################################################################\n\n###############################################################################################\n# rename columns for easier access\nname_mapping = {\n    # demographics\n    'Q1': 'Age',\n    'Q2': 'Gender',\n    'Q3': 'Country',\n    # professional\n    'Q4': 'Education',\n    'Q5': 'Title',\n    'Q10': 'Annual Compensation',\n    'Q15': 'Years_Exp_Data',\n    'Q23': 'Years_Exp_ML',\n    # day-to-day work roles\n    'Q9_Part_1': 'Analyze data to influence biz decisions',\n    'Q9_Part_2': 'Build\/run data infrastructure',\n    'Q9_Part_3': 'Prototype ML applications',\n    'Q9_Part_4': 'Build\/run an internal ML service',\n    'Q9_Part_5': 'Improve existing ML models',\n    'Q9_Part_6': 'Research state-of-the-art ML',\n    'Q9_Part_7': 'None of these',\n    'Q9_Part_8': 'Other',\n    # tools used\n    'Q14_Part_1_TEXT': 'Basic_stats_software',\n    'Q14_Part_2_TEXT': 'Advanced_stats_software',\n    'Q14_Part_3_TEXT': 'BI_software',\n    'Q14_Part_4_TEXT': 'Local_envs',\n    'Q14_Part_5_TEXT': 'Cloud_software'}\n\nmult_choice_responses = mult_choice_responses.rename(columns = name_mapping)\n###############################################################################################\n\n###############################################################################################\n# aggregate multi-column questions for plotting ease\ntext_question_cols = {\n    'work_roles':    ['Analyze data to influence biz decisions', 'Build\/run data infrastructure', \n                      'Prototype ML applications', 'Build\/run an internal ML service',\n                      'Improve existing ML models', 'Research state-of-the-art ML',\n                      'None of these', 'Other'],\n    'Programming Language':     list(mult_choice_responses.filter(like='Q18').columns), \n    'beginner_lang': list(mult_choice_responses.filter(like='Q19').columns),\n    'Visualization Tools':      list(mult_choice_responses.filter(like='Q20').columns),\n    'Algorithms':    list(mult_choice_responses.filter(like='Q24').columns),\n    'NLP Tools':     list(mult_choice_responses.filter(like='Q27').columns),\n    'ML Frameworks': list(mult_choice_responses.filter(like='Q28').columns),\n    'Relational DB Tools':  list(mult_choice_responses.filter(like='Q34').columns)}\n###############################################################################################\n\n###############################################################################################\n# renaming tool\ndef renamer(col, old_name, new_name):\n    mult_choice_responses[col] = mult_choice_responses[col].replace(regex=old_name, value=new_name)\n\nrenamer(col='Country', \n        new_name='United Kingdom', \n        old_name='United Kingdom of Great Britain and Northern Ireland')    \nrenamer(col='Education', \n        new_name='Some college', \n        old_name='Some college\/university study without earning a bachelor\u2019s degree')\nrenamer(col='Education', \n        new_name='High school', \n        old_name='No formal education past high school')\nrenamer(col='Education', \n        new_name='Never', \n        old_name='I have never written code')\nrenamer(col='Analyze data to influence biz decisions', \n        new_name='Analyze data to influence biz decisions', \n        old_name='Analyze and understand data to influence product or business decisions')\nrenamer(col='Build\/run data infrastructure', \n        new_name='Build\/run data infrastructure', \n        old_name='Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data')\nrenamer(col='Prototype ML applications', \n        new_name='Prototype ML applications', \n        old_name='Build prototypes to explore applying machine learning to new areas')\nrenamer(col='Build\/run an internal ML service', \n        new_name='Build\/run an internal ML service', \n        old_name='Build and\/or run a machine learning service that operationally improves my product or workflows')\nrenamer(col='Improve existing ML models', \n        new_name='Improve existing ML models', \n        old_name='Experimentation and iteration to improve existing ML models')\nrenamer(col='Research state-of-the-art ML', \n        new_name='Research state-of-the-art ML', \n        old_name='Do research that advances the state of the art of machine learning')\nrenamer(col='None of these', \n        new_name='None of these', \n        old_name='None of these activities are an important part of my role at work')\n###############################################################################################\n\n###############################################################################################\n# bucket compensation col\ncompensation_replace_dict = {\n    '$0-999': '< 10,000','1,000-1,999': '< 10,000','2,000-2,999': '< 10,000','3,000-3,999': '< 10,000',\n    '4,000-4,999': '< 10,000','5,000-7,499': '< 10,000','7,500-9,999': '< 10,000','10,000-14,999': '10,000 - 50,000',\n    '15,000-19,999': '10,000 - 50,000','20,000-24,999': '10,000 - 50,000','25,000-29,999': '10,000 - 50,000',\n    '30,000-39,999': '10,000 - 50,000','40,000-49,999': '10,000 - 50,000','50,000-59,999': '50,000 - 99,000',\n    '60,000-69,999': '50,000 - 99,000','70,000-79,999': '50,000 - 99,000','80,000-89,999': '50,000 - 99,000',\n    '90,000-99,999': '50,000 - 99,000','100,000-124,999': '> 100,000','125,000-149,999': '> 100,000',\n    '150,000-199,999': '> 100,000','200,000-249,999': '> 100,000','250,000-299,999': '> 100,000',\n    '300,000-500,000': '> 100,000','> $500,000': '> 100,000'}\n\nmult_choice_responses['Annual Compensation'] = mult_choice_responses['Annual Compensation'].replace(compensation_replace_dict)\n###############################################################################################\n\n###############################################################################################\n# preprocess the responses to \"tools used\"\nfor col in ['Basic_stats_software', 'Advanced_stats_software', 'BI_software', 'Local_envs', 'Cloud_software']:\n    mult_choice_responses[col] = mult_choice_responses[col].str.strip().str.lower().fillna('')\n###############################################################################################\n\n###############################################################################################\n# only keep necessary columns for profiling\nnon_text_cols = list(name_mapping.values())\ntext_cols     = list(chain(*text_question_cols.values()))\n# list + set to remove duplicate work_roles\nkeep          = list(set(non_text_cols + text_cols))\n\nmult_choice_responses = mult_choice_responses[keep]\n###############################################################################################","46621816":"# Looking @ just Data Scientists, Data Analysts\ndata_jobs = mult_choice_responses[mult_choice_responses['Title'].isin(['Data Scientist', 'Data Analyst'])]\n\nnum_analysts = len(data_jobs[data_jobs['Title'] == 'Data Analyst'])\nnum_scientists = len(data_jobs[data_jobs['Title'] == 'Data Scientist'])","21f9768a":"tools_lookup_dict = {\n    'Basic_stats_software':    ['excel', 'python', 'sheets', 'r', 'power bi', 'sql', 'libra', 'tableau', 'weka'],\n    'Advanced_stats_software': ['sas', 'spss', 'python', 'r', 'matlab', 'sap'],\n    'BI_software':             ['tableau', 'power bi', 'qlik'], \n    'Local_envs':              ['jupyter', 'rstudio', 'pycharm', 'spyder', 'visual studio', 'vscode', 'anaconda'],\n    'Cloud_software':          ['aws', 'amazon', 'azure', 'gcp', 'bigquery', 'colab', 'watson', 'ibm', \n                                'databricks', 'paperspace', 'sagemaker']}\n\ntools_rename_dict = {\n    'Basic_stats_software':    {'excel': 'Excel', 'python': 'Python', 'sheets': 'Sheets', 'r': 'R', 'power bi': 'Power BI', \n                                'sql': 'SQL', 'libra': 'Libra', 'tableau': 'Tableau', 'weka': 'Weka'},\n    \n    'Advanced_stats_software': {'sas': 'SAS', 'spss': 'SPSS', 'python': 'Python', 'r': 'R', 'matlab': 'Matlab', 'sap': 'SAP'},\n    \n    'BI_software':             {'tableau': 'Tableau', 'power bi': 'Power BI', 'qlik': 'Qlik'}, \n    \n    'Local_envs':              {'jupyter': 'Jupyter', 'rstudio': 'RStudio', 'pycharm': 'PyCharm', 'spyder': 'Spyder', \n                                'visual studio': 'Visual Studio', 'vscode': 'Visual Studio', 'anaconda': 'Anaconda'},\n    \n    'Cloud_software':          {'aws': 'AWS', 'amazon': 'AWS', 'azure': 'Azure', 'gcp': 'GCP', 'bigquery': 'GCP', \n                                'colab': 'Colab', 'watson': 'IBM Watson', 'ibm': 'IBM Watson', 'databricks': 'Databricks',\n                                'paperspace': 'Paperspace', 'sagemaker': 'Sagemaker'}}\n\ndef fuzzy_match(row, tool_category, match):\n    '''function to fuzzy match values via the dict above'''\n    name = row[tool_category]\n    return fuzz.partial_ratio(name, match)\n\ndef create_tool_df(tool_category):\n    '''creates a DataFrame of a certain tool category'''\n    \n    dataframe = pd.DataFrame()\n    \n    for tool in tools_lookup_dict[tool_category]:\n        if tool != 'r':\n            # fuzzy match cell values (threshold = > 70)\n            temp = data_jobs[data_jobs.apply(fuzzy_match, tool_category=tool_category, match=tool, axis=1) > 70]\n        else:\n            # no good way to fuzzy match r\n            temp = data_jobs[data_jobs[tool_category] == 'r']\n            \n        # narrow down columns\n        temp = temp[['Title', tool_category]]\n        # rename columns to their appropriate tool\n        temp[tool_category] = tool\n        # append to dataframe\n        dataframe = dataframe.append(temp)\n        \n    # rename    \n    dataframe[tool_category] = dataframe[tool_category].replace(tools_rename_dict[tool_category])\n        \n    return dataframe\n\nBasic_stats_software = create_tool_df('Basic_stats_software')\nAdvanced_stats_software = create_tool_df('Advanced_stats_software')\nBI_software = create_tool_df('BI_software')\nLocal_envs = create_tool_df('Local_envs')\nCloud_software = create_tool_df('Cloud_software')","f8f1a612":"def get_single_col_freq_percents(dataframe, col):\n    '''Get the % of responses per value (single column of df)'''\n    # get counts by job title\n    count_per_col = dataframe.groupby(['Title', col]).size()\n    \n    # get frequency percentage via the counts\n    col_freq_percents = pd.DataFrame(count_per_col.groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())))\n    \n    # reset and rename index\n    col_freq_percents.reset_index(inplace=True)\n    col_freq_percents = col_freq_percents.rename(columns={0: '% of Responses'})\n    \n    # sort DataFrame\n    order = {\n        'Education': ['High school', 'Some college', 'Professional degree', \n                      'Bachelor\u2019s degree', 'Master\u2019s degree',  'Doctoral degree'],\n        'Years_Exp_Data': ['< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'],\n        'Years_Exp_ML': ['< 1 years', '1-2 years', '2-3 years', '3-4 years', \n                         '4-5 years', '5-10 years', '10-15 years', '20+ years'],\n        'Gender': ['Female', 'Male'],\n        'Annual Compensation': ['< 10,000', '10,000 - 50,000', '50,000 - 99,000', '> 100,000']}\n    \n    if col in list(order.keys()):\n        col_freq_percents[col] = pd.Categorical(col_freq_percents[col], order[col])\n        col_freq_percents.sort_values(col)\n    \n    return col_freq_percents\n\n\ndef get_multicol_freq_percents(question_list):\n    '''Get frequency % of responses (over multiple columns)'''\n    \n    # get counts for Data Scientists and Data Analysts\n    DA = data_jobs[data_jobs.Title == 'Data Analyst'][question_list].fillna('').stack().value_counts()\n    DS = data_jobs[data_jobs.Title == 'Data Scientist'][question_list].fillna('').stack().value_counts()\n    \n    # calculate frequency percents\n    DA = DA.apply(lambda x: (x \/ num_analysts) * 100)\n    DS = DS.apply(lambda x: (x \/ num_scientists) * 100)\n    \n    # combine titles\n    df = pd.DataFrame({'Data Analyst': DA, 'Data Scientist': DS}).drop(labels='')\n    \n    # select top 10 responses\n    top10_idx = df.sum(axis=1).sort_values(ascending=False).head(10).index\n    df = df.loc[top10_idx]\n    \n    return df\n\ndef single_col_bar_plotter(category, plot_size=(6,5), axis_limit=5.0, legend_loc='lower right', axes=None):\n    '''plot a single column response'''\n    \n    #plt.figure(figsize=plot_size)\n    if category == 'Country':\n        df = get_single_col_freq_percents(data_jobs, 'Country')\n        temp = df[df['Country'] != 'Other'] # Remove 'Others'\n        temp = temp.groupby(['Country']).sum() # sum by % of respondants\n        temp = temp.reset_index().sort_values('% of Responses', ascending=False).head(10) # top 10\n        top_10_countries = list(temp['Country'])\n\n        df = df[df['Country'].isin(top_10_countries)]\n        ax = sns.barplot(x='% of Responses', y=category, data=df, \n                         hue='Title', palette=sns.color_palette(colors), edgecolor='.2', ax=axes)\n        \n    elif category in ['Basic_stats_software','Advanced_stats_software','BI_software','Local_envs','Cloud_software']:\n        ax = sns.barplot(x='% of Responses', y=category, data=get_single_col_freq_percents(globals()[category], category),\n                         hue='Title', palette=sns.color_palette(colors), edgecolor='.2', ax=axes)\n        \n    else:\n        ax = sns.barplot(x='% of Responses', y=category, data=get_single_col_freq_percents(data_jobs, category),\n                         hue='Title', palette=sns.color_palette(colors), edgecolor='.2', ax=axes)\n  \n    # title formatting\n    if category == 'Country':\n        ax.set_title('Top 10 Responding Countries\\n', fontsize=14)\n    elif category == 'Years_Exp_Data':\n        ax.set_title('Years Using Code to Analyze Data\\n', fontsize=14)\n    elif category == 'Years_Exp_ML':\n        ax.set_title('Years Using Machine Learning Methods\\n', fontsize=14)\n    elif category == 'Annual Compensation':\n        ax.set_title(category + ' (US$) of Respondents \\n', fontsize=14)\n    elif category == 'Basic_stats_software':\n        ax.set_title('Basic Statistical Software Used by Respondents\\n', fontsize=14)\n    elif category == 'Advanced_stats_software':\n        ax.set_title('Advanced Statistical Software Used by Respondents\\n', fontsize=14)        \n    elif category == 'BI_software':\n        ax.set_title('Business Intelligence Software Used by Respondents\\n', fontsize=14)\n    elif category == 'Local_envs':\n        ax.set_title('Local Environments Used by Respondents\\n', fontsize=14)    \n    elif category == 'Cloud_software':\n        ax.set_title('Cloud Software Used by Respondents\\n', fontsize=14)          \n    else:\n        ax.set_title(category + ' of Respondents \\n', fontsize=14)\n\n    # legend formatting\n    legend = plt.legend(frameon=True)\n    legend_frame = legend.get_frame()\n    legend_frame.set_facecolor('white')\n    legend_frame.set_edgecolor('black')\n    plt.legend(loc=legend_loc)\n    \n    # axis formatting\n    ax.yaxis.label.set_visible(False)\n    ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n    x_ax_lim = int(math.ceil(ax.get_xlim()[1] \/ axis_limit) * axis_limit) # end at a 5.0%\n    ax.set(xlim=(0.0, x_ax_lim))\n    \n    return ax\n\ndef multi_col_bar_plotter(category, plot_size=(6,5), axis_limit=5.0, axes=None):\n    '''plots multi column responses'''\n    \n    #plt.figure(figsize=plot_size)\n    \n    # get frequency percents\n    df = get_multicol_freq_percents(text_question_cols[category])\n    \n    # melt multiple columns\n    df = df.reset_index()\n    df = pd.melt(df,\n                 id_vars=['index'], var_name='Title',\n                 value_vars=['Data Analyst', 'Data Scientist'], value_name='% of Responses')\n    \n    ax = sns.barplot(x='% of Responses', y='index', data=df, hue='Title', \n                 palette=sns.color_palette(colors), edgecolor=\".2\", ax=axes)\n\n    # title formatting\n    if category == 'beginner_lang':\n        ax.set_title('Respondents\\' suggested programming language for beginners\\n', fontsize=14)\n    elif category == 'work_roles':\n        ax.set_title('Respondents\\' roles at work \\n', fontsize=14)\n    else:\n        ax.set_title(category + ' used by Respondents \\n', fontsize=14)\n    \n    # legend formatting\n    ax.legend(loc='lower right')\n    \n    # axis formatting\n    ax.yaxis.label.set_visible(False)\n    ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n    x_ax_lim = int(math.ceil(ax.get_xlim()[1] \/ axis_limit) * axis_limit) # end at a 5.0%\n    ax.set(xlim=(0.0, x_ax_lim))\n    \n    return ax","e6b8a2d2":"ax = sns.countplot(x='Title', data=data_jobs, order=['Data Analyst', 'Data Scientist'],\n              palette=sns.color_palette(colors), edgecolor='.2')\n\nax.set_title('Number of Respondents by Title\\n')\nax.set_ylabel('')\nax.set_xlabel('')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height()), (p.get_x() + p.get_width() \/ 2.,p.get_height()), \n                ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","b12e1c4f":"fig, axarr = plt.subplots(1, 2, figsize=(20, 6))\nplt.subplots_adjust(wspace=0.4)\nsingle_col_bar_plotter('Age', legend_loc='upper right', axes=axarr[0])\nsingle_col_bar_plotter('Gender', legend_loc='upper right', axes=axarr[1]);","e2586bde":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nsingle_col_bar_plotter('Country', legend_loc='upper right');","e36aca28":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nsingle_col_bar_plotter('Education', legend_loc='upper right');","3894bab4":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nsingle_col_bar_plotter('Annual Compensation', legend_loc='lower right');","69f09164":"fig, axarr = plt.subplots(1, 2, figsize=(20, 6))\nplt.subplots_adjust(wspace=0.4)\nsingle_col_bar_plotter('Years_Exp_Data', axes=axarr[0])\nsingle_col_bar_plotter('Years_Exp_ML', legend_loc='lower right', axes=axarr[1]);","aeb23a12":"fig, axarr = plt.subplots(1, figsize=(12, 6))\nmulti_col_bar_plotter('work_roles');","e7adc0a6":"fig, axarr = plt.subplots(1, 2, figsize=(20, 6))\nplt.subplots_adjust(wspace=0.4)\nmulti_col_bar_plotter('Programming Language', axes=axarr[0])\nmulti_col_bar_plotter('beginner_lang', axes=axarr[1]);","e0e54657":"fig, axarr = plt.subplots(2, 2, figsize=(20, 10))\nplt.subplots_adjust(wspace=0.4, hspace=0.6)\nsingle_col_bar_plotter('BI_software', axes=axarr[0][0])\nsingle_col_bar_plotter('Cloud_software', axes=axarr[0][1], legend_loc='lower right')\nsingle_col_bar_plotter('Basic_stats_software', axes=axarr[1][0])\nsingle_col_bar_plotter('Advanced_stats_software', axes=axarr[1][1], legend_loc='upper right');","28e8ac95":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nsingle_col_bar_plotter('Local_envs', legend_loc='lower right');","2c574c16":"fig, axarr = plt.subplots(1, figsize=(10, 8))\nmulti_col_bar_plotter('Algorithms');","06c5c0f5":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nmulti_col_bar_plotter('ML Frameworks');","a68ab612":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nmulti_col_bar_plotter('Visualization Tools');","e70c1c78":"fig, axarr = plt.subplots(1, figsize=(10, 4))\nmulti_col_bar_plotter('Relational DB Tools');","2b82d833":"fig, axarr = plt.subplots(1, figsize=(10, 8))\nmulti_col_bar_plotter('NLP Tools');","6078151a":"**Annual Compensation**\n\nTwo differences clearly stand out here:\n1. Many more Data Analysts make < \\$10,000 than Data Scientists\n2. Many more Data Scientists make > \\$100,000 than Data Analysts\n\n> **Get that Scientist title if you want the dough**\n\nOtherwise the biggest surprise to me as an American in this industry is the number of respondents making \\$0 - \\$50,000. PayScale.com's salary information has the average US salary for [Data Analysts](https:\/\/www.payscale.com\/research\/US\/Job=Data_Analyst\/Salary) at \\$59,732 while [Data Scientists](https:\/\/www.payscale.com\/research\/US\/Job=Data_Scientist%2C_IT\/Salary) sit at a cool \\$91,260. I know my surprise here might expose some global ignorance but it just goes to show how diverse the crowd here at Kaggle is.","dc1f86c2":"**Education**\n* Data Analysts tend to have completed a lower level of schooling as compared to Data Scientists. A vast majority of Data Scientists have at least a Bachelor's degree or higher.\n* Interestingly enough, individuals with Master's degrees tend to make up the largest portion of both job titles.\n* Doctorate holders are about two times more likely to be Data Scientists.","5366539d":"**Age**\n\nThe difference here is subtle, but it looks like Data Analysts tend to be a bit younger on average and conversely, Data Scientists seem to be a bit older.\n\nThe shift between professions seems to occur between age 29 & 30, where Data Scientists begin to outweigh Analysts in every succeeding bin.\n\n**Gender**\n\nOther than the stark difference in overall gender response sizes which has been covered in a number of other kernels; we can see that there is an almost equal 5-7% shift in titles between genders. That shift being, more Data Analyst females and more Data Scientist males.","f75c4cba":"#### Wrangling contd.","2c69bce3":"**Work Roles** \n\nWhenever I've read or partaken in discussions around the difference between these two titles, work roles has always seemed to be a differentiator. Without imparting my opinion on the matter, I'll talk about what the data above shows:\n* **Far and away the largest response for Data Analysts is \"Analyzing Data to influence business decisions\"**. This is self explanatory given the name \"Analyst\" in their job title. This is still an important part of a Data Scientists work though!\n* Another interesting category in which Data Analysts overindex is in the \"Build\/run data infrastructure\". I'd typically assume this role to be in the wheelhouse of Data Engineers or DBAs, so I think a good deep dive would be to see this broken out by company size. Maybe Analysts in smaller orgs are taking on more responsibilities?\n* **Where Data Scientists 'take the lead' per say, is any role that involves machine learning**. \"Prototype ML applications\", \"Improve existing ML models\", \"Build\/run internal ML service\", and \"Research state-of-the-art ML\" are all a bigger part of the Data Scientist respondents work roles vs. Data Analysts\n\n<u><font size=\"1\">Note: I renamed these roles from their true text strings.<\/font><\/u>\n\n## Tooling Used\nI'm not so sure these are a great indicator of the difference between titles but it will be interesting to see who is using what.","44d72bc8":"#### Creating helper functions for plotting & getting frequency %s","b65abcc0":"Interesting. My assumption would have been that we'd see more Analyst than Scientists, as the Data Scientist title is often more sought after & more of a specialization. This *is* a Kaggle survey, you know, \"Your Home for Data Science\".\n\nBack to the numbers, we're looking at about 8% of respondents being Data Analysts and 21% being Data Scientists.\n\n*Note: for all of the following plots, I'll be using frequency percents (i.e., # of responses per group\/# of total responses).*\n* For example, # who answered Age = 18-21\/total # of respondents to the Age question\n* Total #s are within their respective profession\n\n**Now for the meat of this exploration.**\n## Demographics","8fbb431d":"**Local Environments**\n\nEach title about mimicked the other. They both love Jupyter though.","4fe0ba7e":"**Software Used**\nI chose to drop 4 different categories here because they're a tinge related and honestly - there are no huge differences between the two titles. \n\nWhat I will highlight is what is used most by these professions, together:\n* **BI Software**: Tableau has a firm hold here. I guess that's why [Salesforce bought it](https:\/\/techcrunch.com\/2019\/06\/10\/salesforces-tableau-acquisition-is-huge-but-not-the-hugest\/) for \\$15.7 billion USD.\n* **Cloud Software**: AWS, GCP, and Azure round out the top 3 here with AWS having a firm lead. Interestingly, Data Scientists seem to use Colab a fair bit more than Data Analysts \n* **Basic Statistical Software**: Excel and Google Sheets. That's it.\n* **Advanced Statistical Software**: SAS and SPSS!! The classics. I know they don't get much love today but there's no doubting that they're used in legacy software.","a5655bc5":"### The Landscape\nThe survey's \"job title\" question had 12 possible options (not including 'Other' or non-responses). Let's take a look at how many of the 19,717 respondents identified themselves as either a Data Scientist or Data Analyst:","4c38d6a4":"## Conclusion\n\nWell - did we settle the debate? What do you think? Leave a comment below if you learned anything from this.\n\nIn my eyes, there was a clear line of separation between Data Analysts and Data Scientists when it came to years of experience, education level, and day-to-day work responsibilities. I hope some of the other data points I highlighted provided some illumination to the reader.\n\nI ommitted decent number of questions that in my opinion, didn't add to the dialogue. If there are any you would want me to add, please do.\n\nLastly, if you'd like to fork this and look at some other professions - please change the 'Data Scientist' and 'Data Analyst' strings in cells 4, 6, 8.\n\nThanks for reading!","7ca8b3b4":"**Country**\n\nLooking at the top 10 responding countries, we can see see a few insights:\n* The number one responder, India, overindexes in Data Analysts.\n* Number two, the United States, has an even mix but a *slightly* larger Data Scientist population.\n* Germany and France have quite a few more Data Scientists than Data Analysts - the largest title-by-title disparities on the plot.\n\nOtherwise, no surprises with regards to who showed up here - all of these countries are large. The smallest of the bunch is Canada which according to the United Nation's [Population Estimates](http:\/\/data.un.org\/Data.aspx?d=PopDiv&f=variableID%3a12%3btimeID%3a83%2c84%3bvarID%3a2&c=2,4,6,7&s=_crEngNameOrderBy:asc,_timeEngNameOrderBy:desc,_varEngNameOrderBy:asc&v=1), ranks 39th worldwide in population.\n\n## Career & Education","cbef6b31":"**Relational Database Tools**\n\nMySQL, PostgresSQL, and SQL Server are the favorites here. I'm interested in why **so many more Data Scientists use PostgresSQL vs. Data Analysts**.","9b2d7861":"**Machine Learning Frameworks**\n* The only thing that stands out for Analysts is the number that replied \"None\". This does reinforce what we saw before in the work roles section though.\n* Data Scientists overindex in all of these frameworks, also reinforcing their response about using ML at work.\n* Oh, and Scikit-learn rules the game.","a46463e5":"**Algorithms**\n\nThere's something to this one. \n* Both Data Scientists and Data Analysts *more often than not* use Linear\/Logistic Regression or Decision Trees\/Random Forests. **These are the clear favorite for Data Analysts** - makes sense given that they're accessible, classic techniques.\n* More advanced, Deep Learning algorithms, like **Dense Neural Nets, CNNs, and Recurrent Neural Nets, are used more often by Data Scientists.** \n* Gradient Boosted Machines being chosen by > 50% of Data Scientists is an interesting result to me personally. I wonder if this is due to their extreme popularity in the Kaggle community.","7c3309e7":"**Years of Experience Using Code to Analyze Data & Using ML Methods**\n\nNothing here comes as too much of a surprise. \n* Most Data Analysts have been **using code to analyze data for < 5 years** and have only been **using machine learning methods for 0-2 years**.\n* On the flip side, it looks like Data Scientists have been **using code to analyze data for 3-10 years** and have been **using machine learning methods for 2-10 years**.\n\nThis really reinforces what I'd assume after seeing the Educational breakdown - Data Scientists are simply more experienced. \n\nLastly, one thing that stuck out to me was the sharp dropoff in response percentage by Data Scientists after the 5-10 year bin. Dropping the term \"machine learning on [Google Trends](https:\/\/trends.google.com\/trends\/explore?date=all&q=machine%20learning) produced the following graph:\n![ml_trends_over_time](https:\/\/i.imgur.com\/Fqr8yvA.png)\n\nThis graph really shows the growth in this industry kicked off around 2013 which lines up well with these responses.","d1c3732e":"**Programming Language**\n* You know those toothpaste commericials that say [4 out of 5 dentists recommend](https:\/\/www.youtube.com\/watch?v=tXqAyMhgc7I)? \n    * Yeah well, **~6 out of 10 Data Scientists and ~5 out of 10 Data Analysts suggest that if you're a beginner, learn Python**. \n* As far as the languages used by these professionals, Python, R and SQL being the top 3 come as no surprise.\n* What does interest me is the slight uptick in Bash usage by Data Scientists - I'm going to guess this is a byproduct of some more heavy duty coding & model building. ","36b3d91f":"**NLP Tools**\n\nBasically, Data Scientists are working on Natural Language Processing much more often than Data Analysts - we can see this in the poor response rate of these tools by Data Analysts.","46fc6908":"#### Data Wrangling","e460cc4c":"# What's the difference between a Data Scientist and a Data Analyst?\n\nThis is a question that has been asked many times by many people. Answers are typically contested and convoluted and the truth is, there's a bit of a blurred line between the two.\n\nIn this notebook, I explore [Kaggle's 2019 ML & DS Survey](https:\/\/www.kaggle.com\/c\/kaggle-survey-2019) - specifically focusing on the answers by those who identified themselves as either a **Data Scientist** or **Data Analyst**. My goal is to provide a data-driven example to this discussion by identifying trends or tangible differences between the responses of the two groups. \n\nMy exploration will cover three main pillars: \n1. Demographics (Age, Gender, Geographic Location)\n2. Professional\/Career Identifiers (Education Level, Income, Work Responsibilities, Years of Experience)\n3. Tooling Used (Programming Language, ML Frameworks, Visualization Libraries, Algorithms Used)\n\n#### Importing Packages & Data","015ae5a3":"**Visualization Tools**\n\nNo tangible differences here, minus the slight % of Data Analysts who don't use visualization tools. One could say that Data Scientists use visualization tools more often.\n\nMatplotlib\/seaborn dominate the Python ecosystem, ggplot\/ggplot2 dominate R."}}