{"cell_type":{"0db64239":"code","0ac4f556":"code","f8f80ef9":"code","af31f60d":"code","8f91838b":"code","8b0564be":"code","5d8e58c5":"code","5166ef0c":"code","79302ac8":"code","3e109357":"code","d55a9605":"code","f56b730c":"code","d6abbc41":"code","8739cbd5":"code","fbca5456":"code","9062b32b":"code","0076ec64":"code","f61b579a":"code","d0c59e38":"code","f587ee05":"code","79de3f1c":"code","94036128":"code","08a415c1":"code","5848ebbf":"code","e7c3579c":"code","43490f79":"code","181ca2ce":"code","b72dd3f0":"code","d6c972e4":"code","b8c29c61":"code","e45214cb":"code","cab8fd3c":"code","9e57ece2":"code","4dcc1dc5":"code","3a770a5e":"code","879cd019":"code","d37f0e62":"code","78642452":"code","7f7f63ab":"code","c8e5f232":"markdown","58b3e53e":"markdown","f7df0809":"markdown","7a235162":"markdown","8138e712":"markdown","2dec96be":"markdown","9f019663":"markdown","974fc4dd":"markdown","1a26e846":"markdown","dc05577d":"markdown","36c175af":"markdown"},"source":{"0db64239":"import numpy as np\nfrom re import sub\nimport tensorflow as tf\nfrom tensorflow.keras import metrics\n\nimport matplotlib.colors as mcolors\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image\n\n\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import models\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\nprint(\"Done importing packages!\")","0ac4f556":"BATCH_SIZE = 32\nIMG_SIZE = (240, 240)","f8f80ef9":"data_dir = \"..\/input\/plantvillage-dataset\/color\"\ntrain_dataset = image_dataset_from_directory(data_dir,\n                                             shuffle=True,\n                                             label_mode = 'categorical',\n                                             validation_split = 0.2,\n                                             batch_size=BATCH_SIZE,\n                                             seed = 42,\n                                             subset = \"training\",\n                                             image_size=IMG_SIZE)\n\nvalidation_dataset = image_dataset_from_directory(data_dir,\n                                             shuffle=True,\n                                             label_mode = 'categorical',\n                                             validation_split = 0.2,\n                                             batch_size=BATCH_SIZE,\n                                             seed = 42,\n                                             subset = \"validation\",\n                                             image_size=IMG_SIZE)","af31f60d":"class_names = train_dataset.class_names\nnum_classes = len(class_names)\nfor i in range(1, num_classes + 1):\n    print(str(i) + \". \", class_names[i - 1])","8f91838b":"fig = plt.figure(figsize=(10, 10), constrained_layout=True)\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        title = sub(r\"[_]+\",\"_\",class_names[np.argmax(labels[i])])\n        plt.title(title)\n        plt.axis(\"off\")","8b0564be":"plt.figure(figsize=(10, 10), constrained_layout=True)\nfor images, labels in validation_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        title = sub(r\"[_]+\",\"_\",class_names[np.argmax(labels[i])])\n        plt.title(title)\n        plt.axis(\"off\")","5d8e58c5":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches \/\/ 5)\nvalidation_dataset = validation_dataset.skip(val_batches \/\/ 5)\n\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","5166ef0c":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","79302ac8":"# add more augmentations\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","3e109357":"for image, _ in train_dataset.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] \/ 255)\n    plt.axis('off')","d55a9605":"def plot_metrics(history):\n  colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n  metrics = ['loss', 'auc', 'precision', 'recall']\n  plt.figure(figsize=(20,10))\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()","f56b730c":"METRICS = [\n      metrics.TruePositives(name='tp'),\n      metrics.FalsePositives(name='fp'),\n      metrics.TrueNegatives(name='tn'),\n      metrics.FalseNegatives(name='fn'), \n      metrics.CategoricalAccuracy(name='accuracy'),\n      metrics.Precision(name='precision'),\n      metrics.Recall(name='recall'),\n      metrics.AUC(name='auc')\n]","d6abbc41":"IMG_SHAPE = IMG_SIZE + (3,)","8739cbd5":"preprocess_input = tf.keras.applications.inception_resnet_v2.preprocess_input","fbca5456":"# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n#                                                include_top=False,\n#                                                weights='imagenet')\nbase_model = tf.keras.applications.InceptionResNetV2(\n                                include_top=False,\n                                weights=\"imagenet\",\n                                input_shape=IMG_SHAPE,\n                            )","9062b32b":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","0076ec64":"base_model.trainable = False","f61b579a":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\n\nprint(feature_batch_average.shape)","d0c59e38":"prediction_layer = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","f587ee05":"inputs = tf.keras.Input(shape=(240, 240, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","79de3f1c":"base_learning_rate = 0.001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=METRICS)","94036128":"model.summary()","08a415c1":"len(model.trainable_variables)","5848ebbf":"initial_epochs = 10","e7c3579c":"history = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data=validation_dataset)","43490f79":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","181ca2ce":"plot_metrics(history)","b72dd3f0":"base_model.trainable = True","d6c972e4":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 700\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","b8c29c61":"fine_tuning_learning_rate = 1e-5\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=fine_tuning_learning_rate),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=METRICS)","e45214cb":"model.summary()","cab8fd3c":"len(model.trainable_variables)","9e57ece2":"fine_tune_epochs = 15\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)","4dcc1dc5":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n\n\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.ylabel('Cross Entropy')\nplt.show()","3a770a5e":"plot_metrics(history_fine)","879cd019":"result = model.evaluate(test_dataset)","d37f0e62":"metrics = [\"loss\", \"tp\", \"fp\", \"tn\", \"fn\", \"accuracy\", \"precision\", \"recall\", \"auc\"]\nfor i in range(len(result)):\n    print(\"{} : {}\".format(metrics[i],round(result[i], 3)))","78642452":"#Retrieve a batch of images from the test set\nimage_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch)\n\npredictions = tf.nn.softmax(predictions)\npredictions = list(np.argmax(x) for x in predictions.numpy())\n\nprint('Predictions:\\n', predictions)\nprint('Labels:\\n', list(np.argmax(x) for x in label_batch))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].astype(\"uint8\"))\n  plt.title(class_names[predictions[i]])\n  plt.axis(\"off\")","7f7f63ab":"models.save_model(model, \".\/inception_v3\")","c8e5f232":"## 2. Load data","58b3e53e":"# Transfer learning and fine tuning\n\nTop 5 models we are going to train : \n1. inception_v3\n2. mobilenet_v2\n3. vgg19\n4. xception\n5. inception_resnet_v2","f7df0809":"### 6.1 Before tuning","7a235162":"## 5. Load and compile model","8138e712":"### 6.2 After Tuning","2dec96be":"## 1. Import required modules","9f019663":"# Steps to create a Machine Learning Model:\n\n1. Import required modules\n2. Load data\n3. Apply data augmentation and preprocessing\n4. Create metrics for model performance\n5. Write functions to plot graphs\n6. Load and compile model\n7. Train, validate and test\n8. Save trained model","974fc4dd":"## 4. Metrics and Plotting functions","1a26e846":"## 6. Training, Validation and Testing","dc05577d":"## 7. Save model","36c175af":"## 3. Data Augmentation and preprocessing"}}