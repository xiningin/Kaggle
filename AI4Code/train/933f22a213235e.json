{"cell_type":{"13042fee":"code","51173895":"code","15bf3306":"code","9f825393":"code","75d9b13a":"code","be947693":"code","345432af":"code","55314ec4":"code","0068d4a1":"code","edb6e429":"code","3627c6a2":"code","792be8c0":"code","e8961bfc":"code","d6f615f5":"code","9e8aab0d":"code","3c4e6265":"code","84f8c2d0":"code","2d1b2f01":"code","64641e19":"code","299c216d":"code","5b506d3a":"code","08b577b9":"code","28526a92":"code","5097fa3f":"code","dff1ed7b":"code","1937fb43":"code","09c78009":"code","efc5565b":"code","a0dde009":"code","47ea094f":"code","403a9815":"code","77866725":"code","9aeaff70":"code","01954fa7":"code","53552bfe":"code","3fe5bc56":"code","af97c8da":"code","02376bfe":"code","76686922":"code","fead24a2":"code","698b8cb3":"code","3c2d83c6":"code","cb1585ed":"code","bfe47115":"code","24bff4d6":"code","267a8f40":"code","958732be":"code","9754ebee":"code","e4faf8a5":"code","f58551ae":"code","ecbd5f77":"code","8f24acee":"code","6342fb16":"code","ad62d375":"code","181d1b66":"code","49f2a91e":"code","9d9ce1a0":"code","03630fb4":"code","7cf972f3":"code","623a6275":"code","cd8b197c":"code","464370cb":"code","d6c2e008":"code","da543d4d":"code","5d016c32":"code","e1b38415":"code","0009d963":"code","881eff14":"code","276590c7":"code","29a829f7":"code","63a93c30":"code","fe58f5e3":"code","9a07d0cf":"code","db78fb9c":"code","d44f9c39":"code","d412b94d":"code","2d8caf6e":"code","c19d629a":"code","5db43972":"code","6cf69bf8":"code","af74acf4":"code","15a0c70e":"code","27b37bc7":"code","eb00318f":"code","b01e83c4":"code","e5f3ae5f":"code","723e04eb":"code","c26c794e":"code","e50c8dc7":"code","b40c4046":"code","58e79923":"code","2d9b9bef":"code","c8a44736":"code","44cbb645":"code","9a039d57":"code","c1c68658":"code","8b9026d4":"code","e34ae246":"code","78266035":"code","eb7e3f60":"code","9cd83bc8":"code","b22afabd":"code","d1966e99":"code","8b5d8eb6":"code","9c3082cc":"code","11926124":"code","00d2cc10":"code","3bfd6a03":"code","6ca86462":"code","02d6e7df":"code","adcca04b":"code","d3b6b5a9":"code","1f167068":"code","4fad7c4b":"code","719cd5f2":"code","065f93b5":"code","c268cc6a":"code","8139c4c3":"code","742762c1":"code","e0a0a681":"code","2bf6f36b":"code","14a8ce97":"code","2e90e2f2":"code","791ab433":"code","eeec957c":"code","003368f8":"code","38806ae0":"code","9b83b314":"code","74ab025f":"code","18a1ba49":"code","1f8acec9":"code","f4f4504e":"code","c505bdf0":"code","ed1422c5":"code","f1fe7278":"code","d355c129":"code","1478d556":"code","f1a04c62":"code","2cd5de6c":"code","be2aded2":"code","8f4e4632":"code","c2c02c6c":"code","72a9d2ca":"code","5907afed":"code","8c967c18":"code","1e14e2f7":"code","f056c9cb":"code","a3d5f58c":"code","07203a93":"code","85b342bd":"code","fd4151cb":"code","ddefb256":"code","ea6832a7":"code","2271e371":"code","25c6461d":"code","af09f9ee":"code","1500f967":"code","bbab0f28":"code","f1d868b1":"code","4be05be4":"code","0677fbb2":"code","a803fdbd":"code","863ebf68":"code","ddbc6685":"code","a968f9a8":"code","640218ef":"code","b58168f5":"code","48c505cd":"code","194ba959":"code","cbc62759":"code","0d350023":"code","6c2334aa":"code","6abb5ae7":"code","53a61aff":"code","7c267609":"code","f3187008":"code","97340dc3":"code","536004c3":"code","a8a532d0":"code","21e965c3":"code","34e96f2c":"code","f7b99f5c":"code","752d6e2b":"code","cba3cec1":"code","41c6d139":"code","0fb526ca":"code","78c7f48a":"code","abe6b6df":"code","13ebc93a":"code","ddaabb8b":"code","6cbf1a10":"code","9286f040":"code","26c487ce":"code","b24b6e49":"code","8a18a44f":"code","b4505fa1":"code","3f21b4d6":"code","e2fc4bf8":"code","9b71de05":"code","67106027":"code","c056224f":"code","c05b0726":"code","535a2479":"code","dd23956a":"code","5c4ba788":"code","cae9e959":"code","ced31416":"code","c4efaff0":"code","79c9371b":"code","3830c53f":"code","c851d266":"code","59a97d6a":"code","4c854e38":"code","8df23de8":"code","7c0e091f":"code","538f10a7":"code","3a7d53cb":"code","33de2edd":"code","488680eb":"code","89230291":"code","150932b1":"code","0b2a1e9d":"code","0eab2a4e":"code","7d0e8386":"code","1579ce00":"code","d9aa2cb3":"code","39a2552b":"markdown","301d7b02":"markdown"},"source":{"13042fee":"%%HTML\n<h1>BASIC PROJECT DATA CLEANING, VISUALIZATION TILL PREDICTION<\/h1>\n<h3>Created by : Yonela Nuba using several kennels<\/h3>","51173895":"%%HTML\n\n<h3>Links to associated Kernels <\/h3>","15bf3306":"%%HTML\n<h1> Kernel still under Construction <\/h1>","9f825393":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport missingno as msno\nsns.set_style('darkgrid')\ncolor = sns.color_palette()\nimport matplotlib.mlab as mlab\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","75d9b13a":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\ntrain = train_data.copy()\ntest = test_data.copy()","be947693":"train.select_dtypes(include = [np.number]).columns","345432af":"train.select_dtypes(include = [np.object]).columns","55314ec4":"numerical_features = train.dtypes[train.dtypes != 'object'].index\nprint('Total Numerical Features: {}'.format(len(numerical_features)))\n\ncategorical_features = train.dtypes[train.dtypes == 'object'].index\nprint('Total Categorical features: {}'.format(len(categorical_features)))\n\nprint('Total number of features: {}'.format(len(numerical_features) + len(categorical_features)))","0068d4a1":"train.describe()","edb6e429":"train.head()","3627c6a2":"test.head()","792be8c0":"%%HTML\n<h1>Lets see how are the features correlated to the target value <\/h1>","e8961bfc":"correlation = train.select_dtypes(include = [np.number]).corr()\nprint(correlation['SalePrice'].sort_values(ascending = False))","d6f615f5":"f , ax = plt.subplots(figsize = (14,12))\nplt.title('Correlation of numeric features',size=15)\nsns.heatmap(correlation,square = True,  vmax=0.8, cmap = 'viridis')","9e8aab0d":"highCorrelation = correlation.loc[['SalePrice','GrLivArea','TotalBsmtSF','OverallQual',\n                                     'FullBath','TotRmsAbvGrd','YearBuilt','1stFlrSF','GarageYrBlt',\n                                     'GarageCars','GarageArea'],\n                                    ['SalePrice','GrLivArea','TotalBsmtSF','OverallQual','FullBath',\n                                     'TotRmsAbvGrd','YearBuilt','1stFlrSF','GarageYrBlt','GarageCars','GarageArea']]\nf , ax = plt.subplots(figsize = (14,12))\nplt.title('Correlation of numeric features',size=15)\nsns.heatmap(highCorrelation, square = True, linewidths=0.01, vmax=0.8, annot=True,cmap='viridis', linecolor=\"black\", annot_kws = {'size':12})","3c4e6265":"sns.set()\ncols = ['SalePrice','GrLivArea','TotalBsmtSF','OverallQual','FullBath',\n        'TotRmsAbvGrd','YearBuilt','1stFlrSF','GarageYrBlt','GarageCars','GarageArea']\nsns.pairplot(train[cols], kind = 'scatter', size = 2, diag_kind='kde')\nplt.show()","84f8c2d0":"plt.figure(figsize = (7,5))\nplt.scatter(x = train.TotalBsmtSF, y = train.SalePrice)\nplt.title('TotalBsmtSF', size = 15)\n\nplt.figure(figsize = (7,5))\nplt.scatter(x = train['1stFlrSF'], y = train.SalePrice)\nplt.title('1stFlrSF', size = 15)\n\nplt.figure(figsize = (7,5))\nplt.scatter(x = train.GrLivArea, y = train.SalePrice)\nplt.title('GrLivArea', size = 15)","2d1b2f01":"%%HTML\n<h1> Removing outliers <\/h1>","64641e19":"train.drop(train[train['TotalBsmtSF'] > 5000].index, inplace = True)\ntrain.drop(train[train['1stFlrSF'] > 4000].index, inplace = True)\ntrain.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 3000)].index, inplace = True)","299c216d":"train.drop('Id', axis = 1, inplace = True)","5b506d3a":"y_train = train.SalePrice","08b577b9":"train.shape, y_train.shape, test.shape","28526a92":"%%HTML\n<h1> Visualising missing values <\/h1>","5097fa3f":"def missing_values(df):\n    total = df.isnull().sum() # Total Missing values\n    percent = 100 * total\/len(df) # The percentage of missing values\n    missingValue_table = pd.concat([total, percent], axis = 1)\n    ren_table = missingValue_table.rename(columns = {0: 'Total Missing values', 1: '% of missing values'})\n    ren_table = ren_table[ren_table.iloc[:,1]!=0].sort_values('% of missing values', ascending = False).round(2)\n    \n    print('Your dataset contains: {}'.format(df.shape[1]) + ' columns and there are: {}'.format(ren_table.shape[0]) + ' Columns that contains missing values')\n    \n    return ren_table","dff1ed7b":"#Visualising numerical missing values in all numerical columns\nmsno.matrix(train.select_dtypes(include = [np.number]).sample(200))","1937fb43":"#Visualising categorical missing values in categorical features\nmsno.matrix(train.select_dtypes(include = [np.object]).sample(200))","09c78009":"missing_values(train.select_dtypes(include = [np.number]))","efc5565b":"missing_values(train.select_dtypes(include = [np.object]))","a0dde009":"#Lets see a bar graph of missing values in the entire dataframe\nmsno.bar((train.select_dtypes(include = [np.number]).sample(1000)))","47ea094f":"msno.bar((train.select_dtypes(include = [np.object]).sample(1000)))","403a9815":"msno.bar(train.sample(1000))","77866725":"%%HTML\n<h1> Lets Deal with Null values <\/h1>\n\n<p> Some Columns in the training data with null values actually has no null values but the null value means that, that feature is not present in that house <\/p>\n<p> Columns such as: <h3>'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu', 'GarageQual', 'GarageCond', 'GarageFinish', 'GarageType', 'Electrical',<br \/>\n                    'KitchenQual', 'SaleType', 'Functional', 'Exterior2nd', 'Exterior1st', 'BsmtExposure', 'BsmtCond', 'BsmtQual', 'BsmtFinType1', 'BsmtFinType2',<br \/>\n                     'MSZoning', 'Utilities'<\/h3> <\/p>\n            \n<p>These columns actually have a meeaning and we will have to fill the nulls with 'none' <\/p>","9aeaff70":"cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu', 'GarageQual', 'GarageCond', 'GarageFinish',\n        'GarageType', 'Electrical','KitchenQual', 'SaleType', 'Functional', 'Exterior2nd', 'Exterior1st', 'BsmtExposure','BsmtCond',\n        'BsmtQual', 'BsmtFinType1', 'BsmtFinType2','MSZoning', 'Utilities']\n\nfor col in cols:\n    train[col].fillna('None', inplace = True)\n    test[col].fillna('None', inplace = True)","01954fa7":"missing_values(train.select_dtypes(include = [np.object]))","53552bfe":"missing_values(train.select_dtypes(include = [np.number]))","3fe5bc56":"train.fillna(train.mean(), inplace = True)\ntest.fillna(test.mean(), inplace = True)","af97c8da":"missing_values(train)","02376bfe":"train.head()","76686922":"%%HTML\n<h1>LETS GENERATE OUR OWN FEATURES FROM THE EXISTING FEATURES <\/h1>","fead24a2":"train['FullHouseSF'] = train['1stFlrSF'] + train['2ndFlrSF'] + train['TotalBsmtSF']\ntest['FullHouseSF'] = test['1stFlrSF'] + test['2ndFlrSF'] + test['TotalBsmtSF']\ntrain['PorchSF'] = train['OpenPorchSF'] + train['EnclosedPorch'] + train['3SsnPorch'] + train['ScreenPorch']\ntest['PorchSF'] = test['OpenPorchSF'] + test['EnclosedPorch'] + test['3SsnPorch'] + test['ScreenPorch']\ntrain['TotalSF'] = train['FullHouseSF'] + train['PorchSF'] + train['GarageArea']\ntest['TotalSF'] = test['FullHouseSF'] + test['PorchSF'] + test['GarageArea']\n\ntest.shape, train.shape","698b8cb3":"train.head()","3c2d83c6":"%%HTML\n<h2> Now lets deal with categorical features <\/h2>","cb1585ed":"catcols = train.select_dtypes(['object'])\nfor cat in catcols:\n    print(cat)\n    print(train[cat].value_counts())\n    print('--'*20)","bfe47115":"train['MSZoning'] = train['MSZoning'].map({'RL':0, 'RM':1, 'FV':2, 'RH':3, 'C (all)':4})\ntrain['Street'] = train['Street'].map({'Pave':0, 'Grvl':1})\ntrain['Alley'] = train['Alley'].map({'None':0, 'Grvl':1, 'Pave':2})\ntrain['LotShape'] = train['LotShape'].map({'Reg':0, 'IR1':1, 'IR2':2, 'IR3':3})\ntrain['LandContour'] = train['LandContour'].map({'Lvl':0, 'Bnk':1, 'HLS':2, 'Low':3})\ntrain['Utilities'] = train['Utilities'].map({'AllPub':0, 'NoSeWa':1})\ntrain['LotConfig'] = train['LotConfig'].map({'Inside':0, 'Corner':1, 'CulDSac':2, 'FR2':3, 'FR3':4})\ntrain['LandSlope'] = train['LandSlope'].map({'Gtl':0, 'Mod':1, 'Sev':2})\ntrain['Neighborhood'] = train['Neighborhood'].map({'NAmes':0, 'CollgCr':1, 'OldTown':2, 'Edwards':3, 'Somerst':4, 'Gilbert':5,\n                                                  'NridgHt':6, 'Sawyer':7, 'NWAmes':8, 'SawyerW':9, 'BrkSide':10, 'Crawfor':11,\n                                                  'Mitchel':12, 'NoRidge':13, 'Timber':14, 'IDOTRR':15, 'ClearCr':16, 'SWISU':17,\n                                                  'StoneBr':18, 'Blmngtn':19, 'MeadowV':20, 'BrDale':21, 'Veenker':22, 'NPkVill':23, 'Blueste':24})\ntrain['Condition1'] = train['Condition1'].map({'Norm':0, 'Feedr':1, 'Artery':2, 'RRAn':3, 'PosN':4, 'RRAe':5, 'PosA':6,\n                                              'RRNn':7, 'RRNe':8})\ntrain['Condition2'] = train['Condition2'].map({'Norm':0, 'Feedr':1, 'Artery':2, 'RRNn':3, 'PosN':4, 'RRAe':5, 'PosA':6, 'RRAn':7})\ntrain['BldgType'] = train['BldgType'].map({'1Fam':0, 'TwnhsE':1, 'Duplex':2, 'Twnhs':3, '2fmCon':4})\ntrain['HouseStyle'] = train['HouseStyle'].map({'1Story':0, '2Story':1, '1.5Fin':2, 'SLvl':3, 'SFoyer':4, '1.5Unf':5,\n                                              '2.5Unf':6, '2.5Fin':7})\ntrain['RoofStyle'] = train['RoofStyle'].map({'Gable':0, 'Hip':1, 'Flat':2, 'Gambrel':3, 'Mansard':4, 'Shed':5})\ntrain['RoofMatl'] = train['RoofMatl'].map({'CompShg':0, 'Tar&Grv':1, 'WdShngl':2, 'WdShake':3, 'Roll':4, 'Membran':5, 'Metal':6})\ntrain['Exterior1st'] = train['Exterior1st'].map({'VinylSd':0, 'HdBoard':1, 'MetalSd':2, 'Wd Sdng':3, 'Plywood':4, 'CemntBd':5, 'BrkFace':6, 'WdShing':7,\n                                                'Stucco':8, 'AsbShng':9, 'Stone':10, 'BrkComm':11, 'CBlock':12, 'ImStucc':13, 'AsphShn':14})\ntrain['Exterior2nd'] = train['Exterior2nd'].map({'VinylSd':0, 'MetalSd':1, 'HdBoard':2, 'Wd Sdng':3, 'Plwood':4, 'CmentBd':5, 'Wd Shng':6, 'Stucco':7,\n                                                'BrkFace':8, 'AsbShng':9, 'ImStucc':10, 'Brk Cmn':11, 'Stone':12, 'AsphShn':13, 'Other':14, 'CBlock':15})\ntrain['MasVnrType'] = train['MasVnrType'].map({'None':0, 'BrkFace':1, 'Stone':2, 'BrkCmn':3})\ntrain['ExterQual'] = train['ExterQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'Fa':3, 'Po':4})\ntrain['ExterCond'] = train['ExterCond'].map({'TA':0, 'Gd':1, 'Fa':3, 'Ex':2, 'Po':4})\ntrain['Foundation'] = train['Foundation'].map({'PConc':0, 'CBlock':1, 'BrkTil':2, 'Slab':3, 'Stone':4, 'Wood':5})\ntrain['BsmtQual'] = train['BsmtQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'None':3, 'Fa':4})\ntrain['BsmtCond'] = train['BsmtCond'].map({'TA':0, 'Gd':1, 'Fa':2, 'None':3, 'Po':4})\ntrain['BsmtExposure'] = train['BsmtExposure'].map({'No':0, 'Av':1, 'Gd':2, 'Mn':3, 'None':4})\ntrain['BsmtFinType1'] = train['BsmtFinType1'].map({'Unf':0, 'GLQ':1, 'ALQ':2, 'BLQ':3, 'Rec':4, 'LwQ':5, 'None':6})\ntrain['BsmtFinType2'] = train['BsmtFinType2'].map({'Unf':0, 'Rec':1, 'LwQ':2, 'None':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\ntrain['Heating'] = train['Heating'].map({'GasA':0, 'GasW':1, 'Grav':2, 'Wall':3, 'OthW':4, 'Floor':5})\ntrain['HeatingQC'] = train['HeatingQC'].map({'Ex':0, 'TA':1, 'Gd':2, 'Fa':3, 'Po':4})\ntrain['CentralAir'] = train['CentralAir'].map({'Y':1, 'N':0})\ntrain['Electrical'] = train['Electrical'].map({'SBrkr':0, 'FuseA':1, 'FuseF':2, 'FuseP':3, 'Mix':4, 'None':5})\ntrain['KitchenQual'] = train['KitchenQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'Fa':3})\ntrain['Functional'] = train['Functional'].map({'Typ':0, 'Min2':1, 'Min1':2, 'Mod':3, 'Maj1':4, 'Maj2':5, 'Sev':6})\ntrain['FireplaceQu'] = train['FireplaceQu'].map({'None':0, 'Gd':1, 'TA':2, 'Fa':3, 'Ex':4, 'Po':5})\ntrain['GarageType'] = train['GarageType'].map({'Attchd':0, 'Detchd':1, 'BuiltIn':2, 'None':3, 'Basement':4, 'CarPort':5, '2Types':6})\ntrain['GarageFinish'] = train['GarageFinish'].map({'Unf':0, 'RFn':1, 'Fin':2, 'None':3})\ntrain['GarageQual'] = train['GarageQual'].map({'TA':0, 'None':1, 'Fa':2, 'Gd':3, 'Ex':4, 'Po':5})\ntrain['GarageCond'] = train['GarageCond'].map({'TA':0, 'None':1, 'Fa':2, 'Gd':3, 'Po':4, 'Ex':5})\ntrain['PavedDrive'] = train['PavedDrive'].map({'Y':0, 'N':1, 'P':2})\ntrain['PoolQC'] = train['PoolQC'].map({'None':0, 'Ex':1, 'Gd':2, 'Fa':3})\ntrain['Fence'] = train['Fence'].map({'None':0, 'MnPrv':1, 'GdPrv':2, 'GdWo':3, 'MnWw':4})\ntrain['MiscFeature'] = train['MiscFeature'].map({'None':0, 'Shed':1, 'Othr':2, 'Gar2':3, 'TenC':4})\ntrain['SaleType'] = train['SaleType'].map({'New':1, 'COD':2, 'ConLD':3, 'ConLI':4, 'CWD':5, 'Oth':6, 'Con':7, 'WD':0})\ntrain['SaleCondition'] = train['SaleCondition'].map({'Normal':0, 'Partial':1, 'Abnorml':2, 'Family':3, 'Alloca':4, 'AdjLand':5})","24bff4d6":"train.head()","267a8f40":"train_app = train.copy()\ntrain_app.shape","958732be":"test.head()","9754ebee":"len(test.select_dtypes(['object']).columns)","e4faf8a5":"catcols = test.select_dtypes(['object'])\nfor cat in catcols:\n    print(cat)\n    print(test[cat].value_counts())\n    print('--'*20)","f58551ae":"test.select_dtypes(['object']).columns","ecbd5f77":"test['MSZoning'] = test['MSZoning'].map({'RL':0, 'RM':1, 'FV':2, 'RH':3, 'C (all)':4})\ntest['Street'] = test['Street'].map({'Pave':0, 'Grvl':1})\ntest['Alley'] = test['Alley'].map({'None':0, 'Grvl':1, 'Pave':2})\ntest['LotShape'] = test['LotShape'].map({'Reg':0, 'IR1':1, 'IR2':2, 'IR3':3})\ntest['LandContour'] = test['LandContour'].map({'Lvl':0, 'Bnk':1, 'HLS':2, 'Low':3})\ntest['Utilities'] = test['Utilities'].map({'AllPub':0, 'NoSeWa':1})\ntest['LotConfig'] = test['LotConfig'].map({'Inside':0, 'Corner':1, 'CulDSac':2, 'FR2':3, 'FR3':4})\ntest['LandSlope'] = test['LandSlope'].map({'Gtl':0, 'Mod':1, 'Sev':2})\ntest['Neighborhood'] = test['Neighborhood'].map({'NAmes':0, 'CollgCr':1, 'OldTown':2, 'Edwards':3, 'Somerst':4, 'Gilbert':5,\n                                                  'NridgHt':6, 'Sawyer':7, 'NWAmes':8, 'SawyerW':9, 'BrkSide':10, 'Crawfor':11,\n                                                  'Mitchel':12, 'NoRidge':13, 'Timber':14, 'IDOTRR':15, 'ClearCr':16, 'SWISU':17,\n                                                  'StoneBr':18, 'Blmngtn':19, 'MeadowV':20, 'BrDale':21, 'Veenker':22, 'NPkVill':23, 'Blueste':24})\ntest['Condition1'] = test['Condition1'].map({'Norm':0, 'Feedr':1, 'Artery':2, 'RRAn':3, 'PosN':4, 'RRAe':5, 'PosA':6,\n                                              'RRNn':7, 'RRNe':8})\ntest['Condition2'] = test['Condition2'].map({'Norm':0, 'Feedr':1, 'Artery':2, 'RRNn':3, 'PosN':4, 'RRAe':5, 'PosA':6, 'RRAn':7})\ntest['BldgType'] = test['BldgType'].map({'1Fam':0, 'TwnhsE':1, 'Duplex':2, 'Twnhs':3, '2fmCon':4})\ntest['HouseStyle'] = test['HouseStyle'].map({'1Story':0, '2Story':1, '1.5Fin':2, 'SLvl':3, 'SFoyer':4, '1.5Unf':5,\n                                              '2.5Unf':6, '2.5Fin':7})\ntest['RoofStyle'] = test['RoofStyle'].map({'Gable':0, 'Hip':1, 'Flat':2, 'Gambrel':3, 'Mansard':4, 'Shed':5})\ntest['RoofMatl'] = test['RoofMatl'].map({'CompShg':0, 'Tar&Grv':1, 'WdShngl':2, 'WdShake':3, 'Roll':4, 'Membran':5, 'Metal':6})\ntest['Exterior1st'] = test['Exterior1st'].map({'VinylSd':0, 'HdBoard':1, 'MetalSd':2, 'Wd Sdng':3, 'Plywood':4, 'CemntBd':5, 'BrkFace':6, 'WdShing':7,\n                                                'Stucco':8, 'AsbShng':9, 'Stone':10, 'BrkComm':11, 'CBlock':12, 'ImStucc':13, 'AsphShn':14})\ntest['Exterior2nd'] = test['Exterior2nd'].map({'VinylSd':0, 'MetalSd':1, 'HdBoard':2, 'Wd Sdng':3, 'Plwood':4, 'CmentBd':5, 'Wd Shng':6, 'Stucco':7,\n                                                'BrkFace':8, 'AsbShng':9, 'ImStucc':10, 'Brk Cmn':11, 'Stone':12, 'AsphShn':13, 'Other':14, 'CBlock':15})\ntest['MasVnrType'] = test['MasVnrType'].map({'None':0, 'BrkFace':1, 'Stone':2, 'BrkCmn':3})\ntest['ExterQual'] = test['ExterQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'Fa':3, 'Po':4})\ntest['ExterCond'] = test['ExterCond'].map({'TA':0, 'Gd':1, 'Fa':3, 'Ex':2, 'Po':4})\ntest['Foundation'] = test['Foundation'].map({'PConc':0, 'CBlock':1, 'BrkTil':2, 'Slab':3, 'Stone':4, 'Wood':5})\ntest['BsmtQual'] = test['BsmtQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'None':3, 'Fa':4})\ntest['BsmtCond'] = test['BsmtCond'].map({'TA':0, 'Gd':1, 'Fa':2, 'None':3, 'Po':4})\ntest['BsmtExposure'] = test['BsmtExposure'].map({'No':0, 'Av':1, 'Gd':2, 'Mn':3, 'None':4})\ntest['BsmtFinType1'] = test['BsmtFinType1'].map({'Unf':0, 'GLQ':1, 'ALQ':2, 'BLQ':3, 'Rec':4, 'LwQ':5, 'None':6})\ntest['BsmtFinType2'] = test['BsmtFinType2'].map({'Unf':0, 'Rec':1, 'LwQ':2, 'None':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\ntest['Heating'] = test['Heating'].map({'GasA':0, 'GasW':1, 'Grav':2, 'Wall':3, 'OthW':4, 'Floor':5})\ntest['HeatingQC'] = test['HeatingQC'].map({'Ex':0, 'TA':1, 'Gd':2, 'Fa':3, 'Po':4})\ntest['CentralAir'] = test['CentralAir'].map({'Y':1, 'N':0})\ntest['Electrical'] = test['Electrical'].map({'SBrkr':0, 'FuseA':1, 'FuseF':2, 'FuseP':3, 'Mix':4, 'None':5})\ntest['KitchenQual'] = test['KitchenQual'].map({'TA':0, 'Gd':1, 'Ex':2, 'Fa':3})\ntest['Functional'] = test['Functional'].map({'Typ':0, 'Min2':1, 'Min1':2, 'Mod':3, 'Maj1':4, 'Maj2':5, 'Sev':6})\ntest['FireplaceQu'] = test['FireplaceQu'].map({'None':0, 'Gd':1, 'TA':2, 'Fa':3, 'Ex':4, 'Po':5})\ntest['GarageType'] = test['GarageType'].map({'Attchd':0, 'Detchd':1, 'BuiltIn':2, 'None':3, 'Basement':4, 'CarPort':5, '2Types':6})\ntest['GarageFinish'] = test['GarageFinish'].map({'Unf':0, 'RFn':1, 'Fin':2, 'None':3})\ntest['GarageQual'] = test['GarageQual'].map({'TA':0, 'None':1, 'Fa':2, 'Gd':3, 'Ex':4, 'Po':5})\ntest['GarageCond'] = test['GarageCond'].map({'TA':0, 'None':1, 'Fa':2, 'Gd':3, 'Po':4, 'Ex':5})\ntest['PavedDrive'] = test['PavedDrive'].map({'Y':0, 'N':1, 'P':2})\ntest['PoolQC'] = test['PoolQC'].map({'None':0, 'Ex':1, 'Gd':2, 'Fa':3})\ntest['Fence'] = test['Fence'].map({'None':0, 'MnPrv':1, 'GdPrv':2, 'GdWo':3, 'MnWw':4})\ntest['MiscFeature'] = test['MiscFeature'].map({'None':0, 'Shed':1, 'Othr':2, 'Gar2':3, 'TenC':4})\ntest['SaleType'] = test['SaleType'].map({'New':1, 'COD':2, 'ConLD':3, 'ConLI':4, 'CWD':5, 'Oth':6, 'Con':7, 'WD':0})\ntest['SaleCondition'] = test['SaleCondition'].map({'Normal':0, 'Partial':1, 'Abnorml':2, 'Family':3, 'Alloca':4, 'AdjLand':5})\n\ntest.head()","8f24acee":"missing_values(test.select_dtypes([np.number]))","6342fb16":"train.fillna(train.mean(), inplace = True)\ntest.fillna(test.mean(), inplace = True)\ntrain.fillna(train.mode(), inplace = True)\ntest.fillna(test.mode(), inplace = True)","ad62d375":"missing_values(test)","181d1b66":"%%HTML\n<h2> Now lets create our model <\/h2>","49f2a91e":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor","9d9ce1a0":"y = train['SalePrice'].copy()\nX = train.drop(columns = 'SalePrice', inplace = True)","03630fb4":"tree = DecisionTreeClassifier(random_state=101)\ntrain = train.astype(float)","7cf972f3":"X = train","623a6275":"X.head()","cd8b197c":"treeReg = DecisionTreeRegressor(random_state=0, max_depth=5)\nmodelRegTree = treeReg.fit(X,y)\nprint(f'Decision tree has {treeReg.tree_.node_count} nodes with maximum depth {treeReg.tree_.max_depth}.')\nprint('*'*40)\nprint(f'Model Accuracy: {treeReg.score(X, y)}')","464370cb":"tree.fit(X,y)","d6c2e008":"print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')","da543d4d":"print(f'Model Accuracy: {tree.score(X, y)}')","5d016c32":"test = test.astype(float)","e1b38415":"test_app = test['Id'].copy().astype(int).round()\ntest.drop(columns = 'Id', inplace = True)","0009d963":"y_pred = tree.predict(test)","881eff14":"y_pred_prob = tree.predict_proba(test)","276590c7":"features = list(train.columns)\nfi = pd.DataFrame({'Feature': features, 'importance':tree.feature_importances_}).sort_values('importance', ascending = False)","29a829f7":"fi.head()","63a93c30":"print('SalePrice skewness: {}'.format(y_train.skew()))","fe58f5e3":"mu = y_train.mean()\nsigma = y_train.std()\n\nnum_bins = 40\n\nplt.figure(figsize = (14,7))\n\nn,bins,patches = plt.hist(y_train, num_bins, normed = 1, edgecolor = 'black', lw = 1, alpha = .40)\ny = mlab.normpdf(bins, mu, sigma)\nplt.plot(bins, y, 'r--', linewidth = 2)\nplt.xlabel('SalePrice')\nplt.ylabel('Probability density')\nplt.title(r'$\\mathrm {Histogram\\ of\\ SalePrice:}\\ \\mu=%.3f, \\ \\sigma = %.3f$'%(mu, sigma))\nplt.grid(True)\nplt.show()","9a07d0cf":"salePrice_normal = np.log1p(y_train)\nmu = salePrice_normal.mean()\nsigma = salePrice_normal.std()\n\nnum_bins = 40\n\nplt.figure(figsize = (14,7))\n\nn,bins,patches = plt.hist(salePrice_normal, num_bins, normed = 1, edgecolor = 'black', lw = 1, alpha = .40)\ny = mlab.normpdf(bins, mu, sigma)\nplt.plot(bins, y, 'r--', linewidth = 2)\nplt.xlabel('SalePrice')\nplt.ylabel('Probability density')\nplt.title(r'$\\mathrm {Histogram\\ of\\ SalePrice:}\\ \\mu=%.3f, \\ \\sigma = %.3f$'%(mu, sigma))\nplt.grid(True)\nplt.show()","db78fb9c":"target = salePrice_normal.astype(float)","d44f9c39":"from sklearn import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import utils","d412b94d":"label = preprocessing.LabelEncoder()\ntarget_encoded = label.fit_transform(y_train)\nprint(target_encoded)\nprint(utils.multiclass.type_of_target(y_train))\nprint(utils.multiclass.type_of_target(y_train.astype('int')))\nprint(utils.multiclass.type_of_target(target_encoded))","2d8caf6e":"model = tree.fit(X, target_encoded)","c19d629a":"pred = model.predict(test)","5db43972":"submit = pd.DataFrame(data = {'Id':test_app, 'SalePrice':pred})","6cf69bf8":"pred","af74acf4":"submit.head()","15a0c70e":"submit.to_csv('FirstSubmission.csv', index = False)","27b37bc7":"submit2 = pd.DataFrame(data = {'ID':test_app, 'SalePrice':y_pred})","eb00318f":"submit2.to_csv('SecondSubmission.csv', index = False)","b01e83c4":"model13 = modelRegTree.predict(test)\nmodel13","e5f3ae5f":"submit13 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':model13})\nsubmit13.to_csv('ThirteenSub.csv', index = False)\nsubmit13.head()","723e04eb":"logic = LogisticRegression(random_state = 101, C=0.5, solver='lbfgs', verbose=1)","c26c794e":"mod = logic.fit(X, y_train)","e50c8dc7":"predic = mod.predict(test)\npredic","b40c4046":"submit3 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':predic})\nsubmit3.to_csv('Submission3.csv', index = False)","58e79923":"submit3.head()","2d9b9bef":"logics = LogisticRegression(random_state = 0, C = 1.0, solver='lbfgs', verbose=1)\nmods = logics.fit(X, y_train)\nprediss = mods.predict(test)\nsubmit5 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediss})\nsubmit5.to_csv('Submission5.csv', index = False)","c8a44736":"submit5.head()","44cbb645":"log = LogisticRegression()\nlogis = log.fit(X, y_train)\npredi = logis.predict(test)\npredi","9a039d57":"submit4 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':predi})\nsubmit4.to_csv('Submission4.csv', index = False)","c1c68658":"from xgboost import XGBClassifier\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import accuracy_score","8b9026d4":"model1 = XGBClassifier()\nmodel2 = XGBRegressor()","e34ae246":"classifier = model1.fit(X, y_train)\nregressor = model2.fit(X, y_train)","78266035":"y_prediction = classifier.predict(test)\ny_prediction2 = regressor.predict(test)","eb7e3f60":"y_prediction","9cd83bc8":"y_prediction2","b22afabd":"submit6 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':y_prediction})\nsubmit6.to_csv('sixthSubmision.csv', index = False)","d1966e99":"submit7 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':y_prediction2})\nsubmit7.to_csv('SeventhSubmision.csv', index = False)","8b5d8eb6":"submit6.head()","9c3082cc":"submit7.head()","11926124":"%%HTML\n<h2> Since XGBRegressor gives us a good score we need to work on our parameters <\/h2>","00d2cc10":"params = {\n    'booster':'gblinear',\n    'objective':'reg:linear',\n    'silent':1,\n    'eta':1,\n    'learning_rate':0.05,\n    'n_estimators':50,\n    'max_depth':5,\n    'min_child_weight':1,\n    'gamma':0,\n    'subsample':0.8,\n    'nthread':1\n}\nnum_rounds = 15","3bfd6a03":"from xgboost.sklearn import XGBRegressor\nimport xgboost as xgb\n# from sklearn import cross_validation, metrics\n# from sklearn.grid_search import GridSearchCV","6ca86462":"regre = XGBRegressor(booster='gblinear', objective='reg:linear', silent = 1, eta = 1, learning_rate = 0.05,\n    n_estimators = 50, max_depth = 5, min_child_weight = 1, gamma = 0, subsample = 0.8)","02d6e7df":"last = regre.fit(X, y_train)\nless = last.predict(test)\nless","adcca04b":"submit8 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':less})\nsubmit8.to_csv('EigthSubmission.csv', index = False)\nsubmit8.head()","d3b6b5a9":"regres = XGBRegressor(booster='gblinear', objective='reg:linear', silent = 1, eta = 0.3, learning_rate = 0.05,\n    n_estimators = 50, max_depth = 5, min_child_weight = 1, gamma = 0, subsample = 0.8, colsample_bytree = 0.7)","1f167068":"model8= regres.fit(X, y_train)\nmodel = model8.predict(test)\nmodel","4fad7c4b":"submit9 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':model})\nsubmit9.to_csv('Nineth.csv', index = False)\nsubmit9.head()","719cd5f2":"regres10 = XGBRegressor(booster='gblinear', objective='reg:linear', silent = 1, eta = 1, learning_rate = 0.1,\n    n_estimators = 500, max_depth = 6, min_child_weight = 1, gamma = 0.1, subsample = 0.8, colsample_bytree = 0.8, scale_pos_weight = 1, nthread=4, seed = 27, alpha = 10)","065f93b5":"model10= regres10.fit(X, y_train)\nmodel10 = model10.predict(test)\nmodel10","c268cc6a":"submit10 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':model10})\nsubmit10.to_csv('Ten.csv', index = False)\nsubmit10.head()","8139c4c3":"regres11 = XGBRegressor(booster='gblinear', objective='reg:linear', silent = 1, eta = 1, learning_rate = 0.3,\n                        n_estimators = 100, max_depth = 8, min_child_weight = 1, gamma = 0.1, subsample = 0.8,\n                        colsample_bytree = 0.3, scale_pos_weight = 1,nthread=4, seed = 50, early_stopping_rounds=50\n                       )","742762c1":"model11= regres11.fit(X, y_train)\nmodel11 = model11.predict(test)\nmodel11","e0a0a681":"submit11 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':model11})\nsubmit11.to_csv('Eleven.csv', index = False)\nsubmit11.head()","2bf6f36b":"regres12 = XGBRegressor(booster='gblinear', objective='reg:linear', silent = 1, eta = 1, learning_rate = 0.3,\n                        n_estimators = 1500, max_depth = 8, min_child_weight = 1, gamma = 0.1, subsample = 0.8,\n                        colsample_bytree = 0.8, scale_pos_weight = 1,nthread=4, seed = 50, early_stopping_rounds=50\n                       )\nmodel12= regres12.fit(X, y_train)\nmodel12 = model12.predict(test)\nmodel12","14a8ce97":"submit12 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':model12})\nsubmit12.to_csv('Twelve.csv', index = False)\nsubmit12.head()","2e90e2f2":"from xgboost.sklearn import XGBRegressor  \nimport scipy.stats as st\nfrom scipy.stats import randint\n\none_to_left = st.beta(10, 1)  \nfrom_zero_positive = st.expon(0, 50)\n\nparams = {  \n    \"n_estimators\": st.randint(3, 40),\n    \"max_depth\": st.randint(3, 40),\n    \"learning_rate\": st.uniform(0.05, 0.4),\n    \"colsample_bytree\": one_to_left,\n    \"subsample\": one_to_left,\n    \"gamma\": st.uniform(0, 10),\n    'reg_alpha': from_zero_positive,\n    \"min_child_weight\": from_zero_positive,\n}\n\nxgbreg = XGBRegressor(nthreads=-1)","791ab433":"from sklearn.model_selection import RandomizedSearchCV\n\ngs = RandomizedSearchCV(xgbreg, params, n_jobs=1,random_state=100)  \ngs.fit(X, y_train)  \nprediction14 = gs.predict(test)","eeec957c":"submission14 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction14})\nsubmission14.head()","003368f8":"gs1 = RandomizedSearchCV(xgbreg, params, n_jobs=1)  \ngs1.fit(X, y_train)  \nprediction15 = gs1.predict(test)\nsubmission15 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction15})\nsubmission15.head()","38806ae0":"gs2 = RandomizedSearchCV(xgbreg, params, n_jobs=1)  \ngs2.fit(X, y_train)  \nprediction16 = gs2.predict(test)\nsubmission16 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction16})\nsubmission16.head()","9b83b314":"submission15.to_csv('FifteenSub.csv', index = False)\nsubmission16.to_csv('Sixteen.csv', index = False)","74ab025f":"submission14.to_csv('FouteenSub.csv', index = False)","18a1ba49":"gs3 = RandomizedSearchCV(model2, params, n_jobs=1)  \ngs3.fit(X, y_train)  \nprediction17 = gs3.predict(test)\nsubmission17 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction17})\nsubmission17.head()","1f8acec9":"gs4 = RandomizedSearchCV(xgbreg, params, n_jobs=1)  \ngs4.fit(X, y_train)  \nprediction18 = gs4.predict(test)\nsubmission18 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction18})\nsubmission18.head()","f4f4504e":"gs5 = RandomizedSearchCV(model2, params, n_jobs=1)  \ngs5.fit(X, y_train)  \nprediction19 = gs5.predict(test)\nsubmission19 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction19})\nsubmission19.head()","c505bdf0":"gs6 = RandomizedSearchCV(model2, params, n_jobs=1)  \ngs6.fit(X, y_train)  \nprediction20 = gs6.predict(test)\nsubmission20 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction20})\nsubmission20.head()","ed1422c5":"submission17.to_csv('SeventeenSub.csv', index = False)\nsubmission18.to_csv('EighteenSub.csv', index = False)\nsubmission19.to_csv('NineteenSub.csv', index = False)\nsubmission20.to_csv('TwentySub.csv', index = False)","f1fe7278":"gs7 = RandomizedSearchCV(model1, params, n_jobs=1)  \ngs7.fit(X, y_train)  \nprediction21 = gs7.predict(test)\nsubmission21 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction21})\nsubmission21.head()","d355c129":"gs8 = RandomizedSearchCV(xgbreg, params, n_jobs=1, random_state= 0)  \ngs8.fit(X, y_train)  \nprediction22 = gs8.predict(test)\nsubmission22 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction22})\nsubmission22.head()","1478d556":"gs9 = RandomizedSearchCV(xgbreg, params, n_jobs=1, random_state = 101)  \ngs9.fit(X, y_train)  \nprediction23 = gs9.predict(test)\nsubmission23 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction23})\nsubmission23.head()","f1a04c62":"submission21.to_csv('TwentyOneSub.csv', index = False)\nsubmission22.to_csv('TwentyTwoSub.csv', index = False)\nsubmission23.to_csv('TentyThreeSub.csv', index = False)","2cd5de6c":"gs10 = RandomizedSearchCV(model2, params, n_jobs=1, random_state = 50)  \ngs10.fit(X, y_train)  \nprediction24 = gs10.predict(test)\nsubmission24 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':prediction24})\nsubmission24.head()","be2aded2":"submission24.to_csv('TwentyFourSubmission.csv', index = False)","8f4e4632":"%%HTML \n<h2>SO THE SCORE OF OUR PREDICTION DOES NOT IMPROVE WHEN TRYING TO MANIPULATE THE PARAMETORS (PARAMETOR TUNING)<\/h2> <br \/>\n\nSometimes its best to use lets features than all of our features.Lets look at our data again.","c2c02c6c":"train.head()","72a9d2ca":"import lightgbm as lgb","5907afed":"model_lgb = lgb.LGBMRegressor(objective='regression',\n                              num_leaves=4,\n                              learning_rate=0.05, \n                              n_estimators=1050,\n                              max_bin=75, \n                              bagging_fraction=0.8,\n                              bagging_freq=5, \n                              feature_fraction=0.2319,\n                              feature_fraction_seed=9, \n                              bagging_seed=9,\n                              min_data_in_leaf=6, \n                              min_sum_hessian_in_leaf=11)","8c967c18":"model_lgb.fit(X, y_train)\nlgb_pred = np.expm1(model_lgb.predict(test))","1e14e2f7":"submission25 = pd.DataFrame(data = {'Id':test_app, 'SalePrice':lgb_pred})\nsubmission25.head()","f056c9cb":"%%HTML\n\n<h1> To be Continued<\/h1>\n\n<p>Now that we have tried to manipulate our data and even worked with parametors but still our model does not improve <\/p>\n<p> Lets try to work with our data again start cleaning it and use few features than we were using before. We will remove some features that are least corellated to the target feature and also remove some features that are some sort of duplicates. <\/p>","a3d5f58c":"train_app = train_data.copy()\ntest_app = test_data.copy()","07203a93":"train_ID = train_app['Id']\ntest_ID = test_app['Id']\ntrain_app = train_app.drop('Id', axis = 1)\ntest_app = test_app.drop('Id', axis = 1)","85b342bd":"train_app.shape, test_app.shape","fd4151cb":"train_app.head()","ddefb256":"test_app.head()","ea6832a7":"missing_values(train_app)","2271e371":"missing_values(test_app)","25c6461d":"train_app.select_dtypes(include = [np.object]).columns","af09f9ee":"missing_values(train_app.select_dtypes(include = [np.object]))","1500f967":"# train_app.select_dtypes('object').apply(pd.Series.unique, axis = 0)\nfrom scipy.stats import norm","bbab0f28":"sns.distplot(train_app['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_app['SalePrice'], plot=plt)","f1d868b1":"train_app['SalePrice'] = np.log(train_app['SalePrice'])\nsns.distplot(train_app['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(train_app['SalePrice'], plot=plt)","4be05be4":"plt.figure(figsize=(7,5))\nplt.scatter(x = train_app.TotalBsmtSF,y = train_app.SalePrice)\nplt.title('TotalBsmtSF', size = 15)\nplt.figure(figsize=(7,5))\nplt.scatter(x = train_app['1stFlrSF'],y = train_app.SalePrice)\nplt.title('1stFlrSF', size = 15)\nplt.figure(figsize=(7,5))\nplt.scatter(x = train_app.GrLivArea,y = train_app.SalePrice)\nplt.title('GrLivArea', size = 15)","0677fbb2":"train_app.drop(train_app[train_app['TotalBsmtSF'] > 5000].index,inplace = True)\ntrain_app.drop(train_app[train_app['1stFlrSF'] > 4000].index,inplace = True)\ntrain_app.drop(train_app[(train_app['GrLivArea'] > 4000) & (train_app['SalePrice']<300000)].index,inplace = True)\ntrain_app.shape","a803fdbd":"train_numerical_features = train_app.dtypes[train_app.dtypes != 'object'].index\ntrain_cat_features = train_app.dtypes[train_app.dtypes == 'object'].index\nprint('Train Numerical Features: {}'.format(len(train_numerical_features)))\nprint('Train Categorical Features: {}'.format(len(train_cat_features)))","863ebf68":"cols_fillna = ['PoolQC','MiscFeature','Alley','Fence','MasVnrType','FireplaceQu',\n               'GarageQual','GarageCond','GarageFinish','GarageType', 'Electrical',\n               'KitchenQual', 'SaleType', 'Functional', 'Exterior2nd', 'Exterior1st',\n               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2',\n               'MSZoning', 'Utilities']\nfor col in cols_fillna:\n    train_app[col].fillna('None',inplace=True)\n    test_app[col].fillna('None',inplace=True)","ddbc6685":"missing_values(train_app)","a968f9a8":"train_app.fillna(train_app.mean(), inplace = True)\ntest_app.fillna(test_app.mean(), inplace = True)\ntrain_app.fillna(train_app.mode(), inplace = True)\ntest_app.fillna(test_app.mode(), inplace = True)","640218ef":"missing_values(test_app)","b58168f5":"for cols in train_numerical_features:\n    print(cols)\n    print('Skewness: {}'.format(train_app[cols].skew()))\n    print('Kurtosis: {}'.format(train_app[cols].kurt()))\n    print('**'*30)","48c505cd":"for data in [train_app, test_app]:\n    data['GrLivArea_Log'] = np.log(data['GrLivArea'])\n    data.drop('GrLivArea', axis = 1, inplace = True)","194ba959":"for data in [train_app, test_app]:\n    data['LotArea_log'] = np.log(data['LotArea'])\n    data.drop('LotArea', axis = 1, inplace = True)\n","cbc62759":"train_numerical_features = train_app.dtypes[train_app.dtypes != 'object'].index","0d350023":"train_app['SalePrice_Log'] = np.log1p(train_app['SalePrice'])","6c2334aa":"train_app.drop('SalePrice_Log', axis = 1, inplace = True)","6abb5ae7":"# target = train_app.SalePrice\ntarget = 'SalePrice'","53a61aff":"nr_Cv = 5\nuse_lgvals = 1\nmin_val_corr = 0.4\ndrop_similar = 1","7c267609":"corr = train_app.corr()\ncorr_abs = corr.abs()\n\nnr_num_cols = len(train_numerical_features)\nser_corr = corr_abs.nlargest(nr_num_cols, target)[target]\n\ncols_abv_limit = list(ser_corr[ser_corr.values > min_val_corr].index)\ncols_bel_limit = list(ser_corr[ser_corr.values <= min_val_corr].index)","f3187008":"print(ser_corr)\nprint('**'*50)\nprint('Columns With correlation above limit:')\nprint('=='*25)\nprint(cols_abv_limit)\nprint('**'*50)\nprint('Columns with correlation below limit:')\nprint('=='*25)\nprint(cols_bel_limit)","97340dc3":"for col in list(train_cat_features):\n    print(col)\n    print(train_app[col].value_counts())\n    print('==='*15)","536004c3":"catg_strong_corr = [ 'MSZoning', 'Neighborhood', 'Condition2', 'MasVnrType', 'ExterQual', \n                     'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType']\n\ncatg_weak_corr = ['Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', \n                  'LandSlope', 'Condition1',  'BldgType', 'HouseStyle', 'RoofStyle', \n                  'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterCond', 'Foundation', \n                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n                  'HeatingQC', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', \n                  'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n                  'SaleCondition' ]","a8a532d0":"def plot_corr_matrix(df, nr_c, targ) :\n    \n    corr = df.corr()\n    corr_abs = corr.abs()\n    cols = corr_abs.nlargest(nr_c, targ)[targ].index\n    cm = np.corrcoef(df[cols].values.T)\n\n    plt.figure(figsize=(nr_c\/1.5, nr_c\/1.5))\n    sns.set(font_scale=1.25)\n    sns.heatmap(cm, linewidths=1.5, annot=True, square=True, \n                fmt='.2f', annot_kws={'size': 10}, \n                yticklabels=cols.values, xticklabels=cols.values\n               )\n    plt.show()","21e965c3":"nr_feats = len(cols_abv_limit)\nplot_corr_matrix(train_app, nr_feats, target)","34e96f2c":"to_drop_num = cols_bel_limit\nto_drop_catg = catg_weak_corr\ncols_to_drop = to_drop_num + to_drop_catg\n\nfor df in [train_app, test_app]:\n    df.drop(cols_to_drop, axis = 1, inplace = True)","f7b99f5c":"catg_list = catg_strong_corr.copy()\ncatg_list.remove('Neighborhood')\n\nfor catg in catg_list:\n    sns.violinplot(x = catg, y = target, data = train_app)\n    plt.show()","752d6e2b":"fig, ax = plt.subplots()\nfig.set_size_inches(16,5)\nsns.violinplot(x = 'Neighborhood', y = target, data = train_app, ax = ax)\nplt.xticks(rotation = 45)\nplt.show()","cba3cec1":"for catg in catg_list:\n    categ = train_app.groupby(catg)[target].mean()\n    print(categ)\n    print('=='*15)","41c6d139":"# 'MSZoning'\nmsz_catg2 = ['RM', 'RH']\nmsz_catg3 = ['RL', 'FV'] \n\n\n# Neighborhood\nnbhd_catg2 = ['Blmngtn', 'ClearCr', 'CollgCr', 'Crawfor', 'Gilbert', 'NWAmes', 'Somerst', 'Timber', 'Veenker']\nnbhd_catg3 = ['NoRidge', 'NridgHt', 'StoneBr']\n\n# Condition2\ncond2_catg2 = ['Norm', 'RRAe']\ncond2_catg3 = ['PosA', 'PosN'] \n\n# SaleType\nSlTy_catg1 = ['Oth']\nSlTy_catg3 = ['CWD']\nSlTy_catg4 = ['New', 'Con']","0fb526ca":"for df in [train_app, test_app]:\n    \n    df['MSZ_num'] = 1  \n    df.loc[(df['MSZoning'].isin(msz_catg2) ), 'MSZ_num'] = 2    \n    df.loc[(df['MSZoning'].isin(msz_catg3) ), 'MSZ_num'] = 3        \n    \n    df['NbHd_num'] = 1       \n    df.loc[(df['Neighborhood'].isin(nbhd_catg2) ), 'NbHd_num'] = 2    \n    df.loc[(df['Neighborhood'].isin(nbhd_catg3) ), 'NbHd_num'] = 3    \n\n    df['Cond2_num'] = 1       \n    df.loc[(df['Condition2'].isin(cond2_catg2) ), 'Cond2_num'] = 2    \n    df.loc[(df['Condition2'].isin(cond2_catg3) ), 'Cond2_num'] = 3    \n    \n    df['Mas_num'] = 1       \n    df.loc[(df['MasVnrType'] == 'Stone' ), 'Mas_num'] = 2 \n    \n    df['ExtQ_num'] = 1       \n    df.loc[(df['ExterQual'] == 'TA' ), 'ExtQ_num'] = 2     \n    df.loc[(df['ExterQual'] == 'Gd' ), 'ExtQ_num'] = 3     \n    df.loc[(df['ExterQual'] == 'Ex' ), 'ExtQ_num'] = 4     \n   \n    df['BsQ_num'] = 1          \n    df.loc[(df['BsmtQual'] == 'Gd' ), 'BsQ_num'] = 2     \n    df.loc[(df['BsmtQual'] == 'Ex' ), 'BsQ_num'] = 3     \n \n    df['CA_num'] = 0          \n    df.loc[(df['CentralAir'] == 'Y' ), 'CA_num'] = 1    \n\n    df['Elc_num'] = 1       \n    df.loc[(df['Electrical'] == 'SBrkr' ), 'Elc_num'] = 2 \n\n\n    df['KiQ_num'] = 1       \n    df.loc[(df['KitchenQual'] == 'TA' ), 'KiQ_num'] = 2     \n    df.loc[(df['KitchenQual'] == 'Gd' ), 'KiQ_num'] = 3     \n    df.loc[(df['KitchenQual'] == 'Ex' ), 'KiQ_num'] = 4      \n    \n    df['SlTy_num'] = 2       \n    df.loc[(df['SaleType'].isin(SlTy_catg1) ), 'SlTy_num'] = 1  \n    df.loc[(df['SaleType'].isin(SlTy_catg3) ), 'SlTy_num'] = 3  \n    df.loc[(df['SaleType'].isin(SlTy_catg4) ), 'SlTy_num'] = 4  ","78c7f48a":"catg_cols_to_drop = ['Neighborhood' , 'Condition2', 'MasVnrType', 'ExterQual', 'BsmtQual',\n                     'CentralAir', 'Electrical', 'KitchenQual', 'SaleType']","abe6b6df":"corr1 = train_app.corr()\ncorr_abs = corr1.abs()\n\nnr_all_cols = len(train_app)\nser_all_1 = corr_abs.nlargest(nr_all_cols, target)[target]\nprint(ser_all_1)\ncols_bel_corr_limit_1 = list(ser_all_1[ser_all_1.values <= min_val_corr].index)\n\nfor df in [train_app, test_app]:\n    df.drop(catg_cols_to_drop, axis = 1, inplace = True)\n    df.drop(cols_bel_corr_limit_1, axis = 1, inplace = True)","13ebc93a":"corr2 = train_app.corr()\ncorr_abs_2 = corr2.abs()\nnr_all_cols = len(train_app)\nser_corr_2 = corr_abs_2.nlargest(nr_all_cols, target)[target]\nprint(ser_corr_2)","ddaabb8b":"train_app.head()","6cbf1a10":"corr3 = train_app.corr()\ncorr_abs_3 = corr3.abs()\nnr_all_cols_3 = len(train_app)\nprint(corr_abs_3.nlargest(nr_all_cols, target)[target])","9286f040":"nr_features = len(train_app.columns)\nplot_corr_matrix(train_app, nr_features, target)","26c487ce":"cols = corr_abs_3.nlargest(nr_all_cols_3, target)[target].index\n\ncols = list(cols)\nif drop_similar == 1:\n    for col in ['GarageArea','1stFlrSF','TotRmsAbvGrd','GarageYrBlt']:\n        if col in cols:\n            cols.remove(col)\n            \n            \ncols = list(cols)\nprint(cols)","b24b6e49":"feats = cols.copy()\nfeats.remove('SalePrice')\nprint(feats)","8a18a44f":"train_ml = train_app[cols].copy()\ntest_ml = test_app[feats].copy()","b4505fa1":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\ntrain_ml_sc = sc.fit_transform(train_ml.drop(target, axis=1))\ntest_ml_sc = sc.transform(test_ml)","3f21b4d6":"train_ml_sc = pd.DataFrame(train_ml_sc)\ntrain_ml_sc.head()","e2fc4bf8":"X = train_ml.drop([target], axis = 1)\ny = train_ml[target]\nX_test = test_ml.copy()\n\nX_sc = train_ml_sc.copy()\ny_sc  =train_ml[target]\nX_test_sc = test_ml_sc.copy()","9b71de05":"def get_best_score(grid):\n    \n    best_score = np.sqrt(-grid.best_score_)\n    print(best_score)    \n    print(grid.best_params_)\n    print(grid.best_estimator_)\n    \n    return best_score","67106027":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\n\nscore_calc = 'neg_mean_squared_error'\nlinreg = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\ngrid_linear = GridSearchCV(linreg, parameters, cv = nr_Cv, verbose=1 , scoring = score_calc)\ngrid_linear.fit(X, y)\n\nsc_linear = get_best_score(grid_linear)","c056224f":"linregr_all = LinearRegression()\n#linregr_all.fit(X_train_all, y_train_all)\nlinregr_all.fit(X, y)\npred_linreg_all = linregr_all.predict(X_test)\npred_linreg_all[pred_linreg_all < 0] = pred_linreg_all.mean()","c05b0726":"sub_linreg = pd.DataFrame()\nsub_linreg['Id'] = test_ID\nsub_linreg['SalePrice'] = pred_linreg_all\nsub_linreg.tail()\nsub_linreg.to_csv('linreg.csv',index=False)","535a2479":"from sklearn.linear_model import Ridge\n\nridge = Ridge()\nparameters = {'alpha':[0.001,0.005,0.01,0.1,0.5,1], 'normalize':[True,False], 'tol':[1e-06,5e-06,1e-05,5e-05]}\ngrid_ridge = GridSearchCV(ridge, parameters, cv=nr_Cv, verbose=1, scoring = score_calc)\ngrid_ridge.fit(X, y)\n\nsc_ridge = get_best_score(grid_ridge)","dd23956a":"pred_ridge_all = grid_ridge.predict(X_test)","5c4ba788":"pred_ridge_all","cae9e959":"grid_regressor = XGBRegressor()","ced31416":"y_train,y = y_train.align(y, join = 'inner', axis = 0)","c4efaff0":"grid_regressor.fit(X, y_train)","79c9371b":"pred_regressor = grid_regressor.predict(X_test)","3830c53f":"pred_regressor","c851d266":"y_train.shape, y.shape","59a97d6a":"submition_dont = pd.DataFrame()\nsubmition_dont['Id'] = test_ID\nsubmition_dont['SalePrice'] = pred_regressor\n\nsubmition_dont.head()","4c854e38":"submition_dont.to_csv('Submision_TwentyFour.csv', index = False)","8df23de8":"submit30 = pd.DataFrame(data = {'Id':test_ID, 'SalePrice':pred_regressor})\n# submit30.to_csv('TwentyFive.csv', index = False)\nsubmit30.head()","7c0e091f":"submit30.to_csv('TwentyFive.csv', index = False)","538f10a7":"from sklearn.linear_model import Lasso\n\nlasso = Lasso()\nparameters = {'alpha':[1e-03,0.01,0.1,0.5,0.8,1], 'normalize':[True,False], 'tol':[1e-06,1e-05,5e-05,1e-04,5e-04,1e-03]}\ngrid_lasso = GridSearchCV(lasso, parameters, cv=nr_Cv, verbose=1, scoring = score_calc)\ngrid_lasso.fit(X, y_train)\n\nsc_lasso = get_best_score(grid_lasso)\n\npred_lasso = grid_lasso.predict(X_test)","3a7d53cb":"submitLaso = pd.DataFrame(data = {'Id': test_ID, 'SalePrice': pred_lasso})\nsubmitLaso.head()","33de2edd":"submitLaso.to_csv('LassoSubmit.csv', index = False)","488680eb":"from sklearn.linear_model import SGDRegressor\n\nsgd = SGDRegressor()\nparameters = {'max_iter' :[10000], 'alpha':[1e-05], 'epsilon':[1e-02], 'fit_intercept' : [True]  }\ngrid_sgd = GridSearchCV(sgd, parameters, cv=nr_Cv, verbose=1, scoring = score_calc)\ngrid_sgd.fit(X_sc, y_train)\n\nsc_sgd = get_best_score(grid_sgd)\n\npred_sgd = grid_sgd.predict(X_test_sc)","89230291":"submitsgd = pd.DataFrame(data = {'Id': test_ID, 'SalePrice': pred_sgd})\nsubmitsgd.head()\nsubmitsgd.to_csv('sgdSubmit.csv', index = False)","150932b1":"from sklearn.tree import DecisionTreeRegressor\n\nparam_grid = { 'max_depth' : [7,8,9,10] , 'max_features' : [11,12,13,14] ,\n               'max_leaf_nodes' : [None, 12,15,18,20] ,'min_samples_split' : [20,25,30],\n                'presort': [False,True] , 'random_state': [5] }\n            \ngrid_dtree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=nr_Cv, refit=True, verbose=1, scoring = score_calc)\ngrid_dtree.fit(X, y_train)\n\nsc_dtree = get_best_score(grid_dtree)\n\npred_dtree = grid_dtree.predict(X_test)","0b2a1e9d":"submitdtree = pd.DataFrame(data = {'Id': test_ID, 'SalePrice': pred_dtree})\nsubmitdtree.head()\nsubmitdtree.to_csv('dtreeSubmit.csv', index = False)","0eab2a4e":"from sklearn.ensemble import RandomForestRegressor\n\nparam_grid = {'min_samples_split' : [3,4,6,10], 'n_estimators' : [70,100], 'random_state': [5] }\ngrid_rf = GridSearchCV(RandomForestRegressor(), param_grid, cv=nr_Cv, refit=True, verbose=1, scoring = score_calc)\ngrid_rf.fit(X, y_train)\n\nsc_rf = get_best_score(grid_rf)\npred_rf = grid_rf.predict(X_test)","7d0e8386":"submitrf = pd.DataFrame(data = {'Id': test_ID, 'SalePrice': pred_rf})\nsubmitrf.to_csv('RfSubmit.csv', index = False)","1579ce00":"tree.fit(X, y_train)\ntree_pred = tree.predict(X_test)","d9aa2cb3":"submittree = pd.DataFrame(data = {'Id': test_ID, 'SalePrice':tree_pred})\nsubmittree.to_csv('Tree_submision.csv', index = False)\nsubmittree.head()","39a2552b":"** This is what we will do on this section**\n\n* Load Data\n* Pickout Features (ID) that I will use when I am done with the prediction\n* Filling in missing values (both objects and numeric values)\n* Change data to correct data type \n* Remove outliers\n* LabelEncode categorical features\n* Generate features\n* Skew numeric features","301d7b02":"**Link One:**\n[https:\/\/www.kaggle.com\/stephaniestallworth\/housing-feature-engineering-regression](https:\/\/www.kaggle.com\/stephaniestallworth\/housing-feature-engineering-regression) <br \/>\n**Link Two:** "}}