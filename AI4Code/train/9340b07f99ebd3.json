{"cell_type":{"326d6c1d":"code","b87d039e":"code","347720d2":"code","dbe5a4a5":"code","c0464133":"code","5265621c":"code","cd2ea5d4":"code","4eac1951":"code","5b0d6ae3":"code","bdca41ee":"code","1b2c4623":"code","ce5ebb09":"code","0f53d1eb":"code","a63520ce":"code","ebebe466":"code","ebbb0802":"code","4a14d6b7":"code","29024b8b":"code","bbaa3403":"markdown","b2dde692":"markdown","acb242ae":"markdown"},"source":{"326d6c1d":"!pip install -q efficientnet","b87d039e":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os, cv2, re, random, time, zipfile, gc\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras import layers, models, optimizers\n#from keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nimport efficientnet.tfkeras as efn","347720d2":"PATH = '\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/'\ntrain_image_path = os.path.join(PATH, 'train.zip')\ntest_image_path = os.path.join(PATH, 'test.zip')\n\nwith zipfile.ZipFile(train_image_path,\"r\") as z:\n    z.extractall(\".\/data\") # target dir\n    z.close()\n    \nwith zipfile.ZipFile(test_image_path,\"r\") as z:\n    z.extractall(\".\/data\")\n    z.close()","dbe5a4a5":"start = time.time() \n\nTRAIN_DIR = '.\/data\/train\/'\nTEST_DIR = '.\/data\/test\/'\n\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntest_images = [TEST_DIR+i for i in os.listdir(TEST_DIR)]","c0464133":"def txt_dig(text):\n    '''Input string, if it is a number, output the number, \n       if not, output the original string'''\n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n    '''Enter a string, separate the number from the text, \n       and convert the number string to int'''\n    return [ txt_dig(c) for c in re.split('(\\d+)', text) ]","5265621c":"train_images.sort(key=natural_keys) # \u4f9d\u636e\u7f16\u53f7\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\ntest_images.sort(key=natural_keys)\n\ntrain_images = train_images[0:7500] +  train_images[17500:25000]  #\u62bd\u6837\nrandom.seed(558)\nrandom.shuffle(train_images)","cd2ea5d4":"IMG_WIDTH = 128\nIMG_HEIGHT = 128\nx = []\nfor img in train_images:\n    x.append(cv2.resize(cv2.imread(img), \n                        (IMG_WIDTH, IMG_HEIGHT), \n                        interpolation=cv2.INTER_CUBIC))\n    \ntest = []\nfor img in test_images:\n    test.append(cv2.resize(cv2.imread(img), \n                        (IMG_WIDTH, IMG_HEIGHT), \n                        interpolation=cv2.INTER_CUBIC))\n    \nprint('The shape of train data is {}'.format(np.array(x).shape))\nprint('The shape of test data is {}'.format(np.array(test).shape))\n\n# extract label vector\nplt.rcParams['figure.facecolor'] = 'white'\ny = []\nfor i in train_images:\n    if 'dog' in i:\n        y.append(1)\n    elif 'cat' in i:\n        y.append(0)\nlen(y)\n\nx = np.array(x)\ny = np.array(y)\ntest = np.array(test)\nsns.countplot(y)","4eac1951":"random.seed(558)\nplt.subplots(facecolor='white',figsize=(10,20))\nsample = random.choice(train_images)\nimage = load_img(sample)\nplt.subplot(131)\nplt.imshow(image)\n\nsample = random.choice(train_images)\nimage = load_img(sample)\nplt.subplot(132)\nplt.imshow(image)\n\nsample = random.choice(train_images)\nimage = load_img(sample)\nplt.subplot(133)\nplt.imshow(image)","5b0d6ae3":"plt.subplots(facecolor='white',figsize=(10,20))\nplt.subplot(131)\nplt.imshow(cv2.cvtColor(x[1024,:,:,:], cv2.COLOR_BGR2RGB))\nplt.subplot(132)\nplt.imshow(cv2.cvtColor(x[546,:,:,:], cv2.COLOR_BGR2RGB))\nplt.subplot(133)\nplt.imshow(cv2.cvtColor(x[742,:,:,:], cv2.COLOR_BGR2RGB))","bdca41ee":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=2020)","1b2c4623":"model = models.Sequential()\n\n\nefnModel = efn.EfficientNetB7(weights = 'imagenet', \n                       input_shape = (IMG_WIDTH, IMG_HEIGHT,3), \n                       include_top = False)\nmodel.add(efnModel)\nmodel.add(layers.GlobalAveragePooling2D())\n#model.add(layers.Dense(512, activation= 'relu'))\n#model.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# decay is included for backward compatibility to allow time inverse decay of lr\nopt1 = RMSprop(lr=1e-5, decay=1e-6)\nopt2 = Adam(lr=8e-5) \n\nmodel.compile(loss='binary_crossentropy',\n              optimizer = opt2, \n              metrics = ['accuracy'])\n\nmodel.summary()","ce5ebb09":"datagen = ImageDataGenerator(\n            rescale=1. \/ 255,            # \u5c06\u6570\u636e\u653e\u7f29\u52300-1\u8303\u56f4\u5185\n            rotation_range=40,           # \u56fe\u50cf\u968f\u673a\u65cb\u8f6c\u7684\u89d2\u5ea6\u8303\u56f4\n            width_shift_range=0.2,       # \u56fe\u50cf\u5728\u6c34\u5e73\u65b9\u5411\u4e0a\u5e73\u79fb\u7684\u8303\u56f4\n            height_shift_range=0.2,      # \u56fe\u50cf\u5728\u5782\u76f4\u65b9\u5411\u4e0a\u5e73\u79fb\u7684\u8303\u56f4\n            shear_range=0.2,             # \u968f\u673a\u9519\u5207\u53d8\u6362\u7684\u89d2\u5ea6\n            zoom_range=0.2,              # \u56fe\u50cf\u968f\u673a\u7f29\u653e\u7684\u8303\u56f4\n            horizontal_flip=True,        # \u968f\u673a\u5c06\u4e00\u534a\u56fe\u50cf\u6c34\u5e73\u7ffb\u8f6c\n            fill_mode='nearest')         # \u586b\u5145\u65b0\u521b\u5efa\u50cf\u7d20\u7684\u65b9\u6cd5\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","0f53d1eb":"def plot_gened(train_images,seed=320):\n    '''plot pictures after processing\n    '''\n    df = pd.DataFrame({'filename': train_images})\n    np.random.seed(seed)\n    vis_df = df.sample(n=1).reset_index(drop=True)\n    vis_df['category'] = '0'\n#vis_df\n    vis_gen = ImageDataGenerator(\n            rescale=1. \/ 255,             # Scale data to 0-1 range\n            rotation_range=40,            # The angle range of the image randomly rotated\n            width_shift_range=0.2,        # The range of image translation in the horizontal direction\n            height_shift_range=0.2,       # The range of image translation in the vertical direction\n            shear_range=0.2,              # Random staggered transformation angle\n            zoom_range=0.2,               # Random image zoom range\n            horizontal_flip=True,         # Randomly flip half of the image horizontally\n            fill_mode='nearest')          # How to fill in newly created pixels\n\n    vis_gen0 = vis_gen.flow_from_dataframe(vis_df,\n                                       x_col='filename',\n                                       y_col='category',\n                                       target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                       batch_size = 16)\n    plt.rcParams['figure.facecolor'] = 'white'\n    plt.figure(figsize=(8, 8))\n    for i in range(0, 9):\n        plt.subplot(3, 3, i+1)\n        for X_batch, Y_batch in vis_gen0:\n            image = X_batch[0]\n            plt.imshow(image)\n            break\n    plt.tight_layout()\n    plt.show()\n    \nplot_gened(train_images)    ","a63520ce":"BATCH_SIZE = 16\ndatagen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\nval_datagen = val_datagen.flow(x_val, y_val, batch_size=BATCH_SIZE)\n\nearlystop1 = EarlyStopping(patience=5)\nearlystop2 = ReduceLROnPlateau(monitor = 'val_accuracy', min_lr = 0.001, \n                               patience = 5, mode = 'min', \n                               verbose = 1)\n\nhistory = model.fit(datagen, \n                    steps_per_epoch=45,\n                    epochs=20,\n                    validation_data=val_datagen,\n                    callbacks=[earlystop1, earlystop2],\n                    validation_steps=25)\n#model.save('dogs_cats_efficientnetb7.h5')","ebebe466":"plt.rcParams['figure.facecolor'] = 'white'\nmodel_loss = pd.DataFrame(history.history)\nmodel_loss.head()\nmodel_loss[['accuracy','val_accuracy']].plot(ylim=[0,1]);\nmodel_loss[['loss','val_loss']].plot(ylim=[0,1]);","ebbb0802":"x_val = x_val.astype('float32') \/ 255\nval_preds = model.predict(x_val)\nprint(val_preds.ravel().dtype)\nval_preds_class = np.where(val_preds.ravel() > 0.5, 1, 0) \n\nprint('Out of Fold Accuracy is {:.5}'.format(accuracy_score(y_val, val_preds_class)))\nprint('Out of Fold log loss is {:.5}'.format(log_loss(y_val, val_preds.ravel() \\\n                                                      .astype('float64'))))","4a14d6b7":"test = test.astype('float32') \/ 255\ntest_pred = model.predict(test)\nsubmission = pd.DataFrame({'id': range(1, len(test_images) + 1), 'label': test_pred.ravel()})\nsubmission.to_csv('submission.csv', index = False)\nprint('This program costs {:.2f} seconds'.format(time.time()-start))\nsubmission","29024b8b":"# remove all imgs unzipped at \/data folder\n!rm -rf \/kaggle\/working\/data\/ ","bbaa3403":"[why log loss is nan?](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge\/discussion\/48701)","b2dde692":"<!---\n```\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1, len(train_acc) + 1)\n\n# train and val acc\nplt.plot(epochs, train_acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Val acc')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nepochs = range(1, len(train_loss) + 1)\n\n# train and val loss\nplt.figure()\nplt.plot(epochs, train_loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Val loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()\n```\n--->","acb242ae":"\n$$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right]$$   \n\n\nreferences\uff1a\nhttps:\/\/www.kaggle.com\/aravrs\/siim-isic-melanoma-classification-ext-cv\n\na discussion on how to hidden output visualizations:   \nhttps:\/\/www.kaggle.com\/product-feedback\/181116#1002307"}}