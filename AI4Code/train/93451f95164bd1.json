{"cell_type":{"1ec11b87":"code","705c407c":"code","92664f41":"code","d692cb6f":"code","fbf6d8bb":"code","d7c338d4":"code","1853b151":"code","d27b1022":"code","d65f7537":"code","5ee7ad66":"code","5c7a4a33":"code","adb2e27a":"code","aea12d81":"code","31d76711":"code","021d14e2":"code","88da161a":"markdown","109471a5":"markdown","941c2d87":"markdown","4749d80a":"markdown","e9b82cd3":"markdown","e7ed0526":"markdown","5029f7f6":"markdown","07dd4f9f":"markdown","59985044":"markdown","bf46c143":"markdown","b7188df8":"markdown"},"source":{"1ec11b87":"!pip install -r \/kaggle\/input\/pre-summy\/PreSumm\/requirements.txt","705c407c":"import pandas as pd \nsummary_df = pd.read_csv('\/kaggle\/input\/news-summary\/news_summary_more.csv')\nsummary_df","92664f41":"import pandas as pd\nfrom nltk.tokenize import sent_tokenize\n\nnews_df = pd.read_csv('\/kaggle\/input\/news-summary\/news_summary_more.csv')\nnews_txt = news_df['text']\n\n\nwith open('\/kaggle\/working\/temp_news_text.txt', 'w') as save_txt:\n    for i in range(50):\n        save_txt.write(news_txt[i].strip() + '\\n')","d692cb6f":"with open('\/kaggle\/working\/temp_news_text.txt', 'r') as save_txt:\n    f= save_txt.readlines()","fbf6d8bb":"print(f[0])","d7c338d4":"print(f[1])","1853b151":"!mkdir logs\n!mkdir temp\n!mkdir models\n!mkdir result","d27b1022":"import os\nos.chdir('\/kaggle\/input\/pre-summy\/PreSumm\/src\/')","d65f7537":"!python train.py -task abs -mode test_text -text_src \/kaggle\/working\/temp_news_text.txt -test_from \/kaggle\/input\/absbert-weights\/model_step_148000.pt -model_path \/kaggle\/working\/models -visible_gpus -1 -alpha 0.2 -result_path \/kaggle\/working\/result\/news -temp_dir \/kaggle\/working\/temp -log_file \/kaggle\/working\/logs\/cnndm.log","5ee7ad66":"import os\nos.chdir('\/kaggle\/working\/result\/')","5c7a4a33":"with open('news.-1.candidate', 'r') as save_txt:\n    s= save_txt.readlines()\n    ","adb2e27a":"print(s[0])","aea12d81":"print(s[1])","31d76711":"import os\nos.chdir('\/kaggle\/working\/')","021d14e2":"!rm -r logs\n!rm -r temp\n!rm -r models\n!rm -r result","88da161a":"# Introduction","109471a5":"This kernel demonstrates how to use the open source code [PreSumm](http:\/\/github.com\/nlpyang\/PreSumm) released by **yang liu** and to conduct text summarization task on your own dataset. It covers the following contents\n\n- Evaluation on your own text files to generate summary\n\n***Notice that:** The Presumm code used here has been modified to run in kaggle and process the customized data.*","941c2d87":"## Take a glimpse on the prediction summary","4749d80a":"# Read the raw description and summary data","e9b82cd3":"# Setup \nInstall the required package from **requirements.txt** in presummy folder","e7ed0526":"# Data Preprocess","5029f7f6":"# Model Inference","07dd4f9f":"# Remove generate data to save commit time","59985044":"The inference support summarizing raw text input. The example data format are in the [raw_data directory ](https:\/\/github.com\/nlpyang\/PreSumm\/tree\/dev\/raw_data)Each line in the text document should be a source text to be summarized.  \nHence, at first we should convert our raw data from *.csv *format to *.txt* format.(*We only process 50 samples here to save kernel commit time*)\n\n\n","bf46c143":"Glimpse on our News summary data released by **Kondalarao Vonteru** in [here](https:\/\/www.kaggle.com\/sunnysai12345\/news-summary#news_summary_more.csv)","b7188df8":"## Take a glimpse on few sample"}}