{"cell_type":{"9a7638a8":"code","535e6f75":"code","c439f961":"code","fc910bc7":"code","b25d9e79":"code","3a905569":"code","1183b327":"code","c6451397":"code","6db00cee":"code","e7e25f75":"code","34c8f6c6":"code","6f955b6a":"code","6383f8bc":"code","13824c6d":"code","ef5440df":"code","97235395":"code","625d6706":"code","947ab1d3":"code","f02ee8af":"code","023756e6":"code","682a2c94":"markdown","4d8bf919":"markdown","a43bad26":"markdown","398e8cd9":"markdown","b1099f4b":"markdown","8f7e3d5c":"markdown","60b61fe5":"markdown","51ca70df":"markdown","647c4c81":"markdown","47158f56":"markdown","9310fea6":"markdown","0573bd66":"markdown","430b723a":"markdown","6373df60":"markdown"},"source":{"9a7638a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","535e6f75":"dataset = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","c439f961":"dataset.head()","fc910bc7":"dataset.info()","b25d9e79":"dataset = dataset.drop([\"id\"], axis = 1)","3a905569":"dataset = dataset.drop([\"Unnamed: 32\"], axis = 1)","1183b327":"dataset.head(3)","c6451397":"M = dataset[dataset.diagnosis == \"M\"]","6db00cee":"M.head(5)","e7e25f75":"B = dataset[dataset.diagnosis == \"B\"]","34c8f6c6":"B.head(5)","6f955b6a":"plt.title(\"Malignant vs Benign Tumor\")\nplt.xlabel(\"Radius Mean\")\nplt.ylabel(\"Texture Mean\")\nplt.scatter(M.radius_mean, M.texture_mean, color = \"red\", label = \"Malignant\", alpha = 0.3)\nplt.scatter(B.radius_mean, B.texture_mean, color = \"lime\", label = \"Benign\", alpha = 0.3)\nplt.legend()\nplt.show()","6383f8bc":"dataset.diagnosis = [1 if i == \"M\" else 0 for i in dataset.diagnosis]","13824c6d":"x = dataset.drop([\"diagnosis\"], axis = 1)\ny = dataset.diagnosis.values","ef5440df":"# Normalization:\nx = (x - np.min(x)) \/ (np.max(x) - np.min(x))","97235395":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","625d6706":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 4)  # n_neighbors = k\nknn.fit(x_train, y_train)\n\nprediction = knn.predict(x_test)","947ab1d3":"prediction","f02ee8af":"print(\"KNN score: \", knn.score(x_test, y_test))","023756e6":"scores = []\nfor i in range(1,15):\n    knn_ = KNeighborsClassifier(n_neighbors = i)\n    knn_.fit(x_train, y_train)\n    scores.append(knn_.score(x_test, y_test))\n    \nplt.plot(range(1,15), scores)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","682a2c94":"## Content:\n\n1. [Importing Dataset](#1)\n1. [Getting Info About Dataset](#2)\n1. [Dataset Visualization](#3)\n1. [Meaning Of KNN Algorithm](#4)\n1. [KNN with Sklearn](#5)\n1. [Conclusion](#6)","4d8bf919":"<a id = \"6\"><\/a>\n# 6. Conclusion","a43bad26":"<a id = \"4\"><\/a>\n# 4. Meaning Of KNN Algorithm","398e8cd9":"> <a id = \"2\"><\/a>\n# 2. Getting Info About Dataset","b1099f4b":"If our k value equals to 4, it gives best result.","8f7e3d5c":"Column names and meanings:\n* id: ID number\n* diagnosis: The diagnosis of breast tissues (M = malignant, B = benign)\n* radius_mean: mean of distances from center to points on the perimeter\n* texture_mean: standard deviation of gray-scale values\n* perimeter_mean: mean size of the core tumor\n* area_mean: area of the tumor\n* smoothness_mean: mean of local variation in radius lengths\n* compactness_mean: mean of perimeter^2 \/ area - 1.0\n* concavity_mean: mean of severity of concave portions of the contour\n* concave_points_mean: mean for number of concave portions of the contour\n* symmetry_mean\n* fractal_dimension_mean: mean for \"coastline approximation\" - 1\n* radius_se: standard error for the mean of distances from center to points on the perimeter\n* texture_se: standard error for standard deviation of gray-scale values\n* perimeter_se\n* area_se\n* smoothness_se: standard error for local variation in radius lengths\n* compactness_se: standard error for perimeter^2 \/ area - 1.0\n* concavity_se: standard error for severity of concave portions of the contour\n* concave_points_se: standard error for number of concave portions of the contour\n* symmetry_se\n* fractal_dimension_se: standard error for \"coastline approximation\" - 1\n* radius_worst: \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n* texture_worst: \"worst\" or largest mean value for standard deviation of gray-scale values\n* perimeter_worst\n* area_worst\n* smoothness_worst: \"worst\" or largest mean value for local variation in radius lengths\n* compactness_worst: \"worst\" or largest mean value for perimeter^2 \/ area - 1.0\n* concavity_worst: \"worst\" or largest mean value for severity of concave portions of the contour\n* concave_points_worst: \"worst\" or largest mean value for number of concave portions of the contour\n* symmetry_worst\n* fractal_dimension_worst: \"worst\" or largest mean value for \"coastline approximation\" - 1","60b61fe5":"1. Choose k value.\n2. Find k points closest to the specified point.\n3. Determine how mant of the class among the 3 closest points to the specified point.\n4. Determine which class the point being tested belongs to.","51ca70df":"<a id = \"1\"><\/a>\n\n## 1. Importing Dataset:","647c4c81":"Now, let's get rid of \"id\" and \"Unnamed: 32\" features because we don't need to use them while diagnosing whether the patient has a cancer or not. ","47158f56":"Dataset information:\n\n* Dataset Characteristics: Multivariate\n* Attribute Characteristics: Real\n* Attribute Characteristics: Classification\n* Number of Instances: 569\n* Number of Attributes: 32\n* Missing Values: No","9310fea6":"<a id = \"5\"><\/a>\n# 5. KNN with Sklearn","0573bd66":"For example:\n\nOur point is x = 20, y = 30.\n\n1. k = 3\n2. We found 3 nearest neighbour.\n3. 3 Malignant dots, 0 Benign dots.\n4. Conclusion: our point belongs to the Malignant class.","430b723a":"<a id = \"3\"><\/a>\n# 3. Dataset Visualization ","6373df60":"# KNN (K Neirest Neighbour) Algorithm Implementation on Cancer Dataset"}}