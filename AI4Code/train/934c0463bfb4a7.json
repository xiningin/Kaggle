{"cell_type":{"0093a5a3":"code","5b2ac843":"code","7391a06b":"code","03314526":"code","6dabea54":"code","e02e547b":"code","f44c599a":"code","18ab740c":"code","389c3e5a":"code","d2438bb3":"code","ff410116":"code","18f727d1":"code","2fdc3537":"code","b631559a":"code","6e6e3bd3":"code","40957439":"code","472fa041":"code","946c04e8":"code","1dd23fb0":"code","e5268960":"code","948f691b":"code","6ea3aa8e":"code","fb21955e":"code","fb785362":"code","7b141ea9":"code","4d03d1bb":"code","e5d11665":"code","a4706da3":"code","2baad33d":"code","4824db45":"code","a5cb4660":"code","5bcb7f97":"code","a2759770":"code","3855b711":"markdown","e270941a":"markdown","a2a9e0ca":"markdown","8b83c827":"markdown","8e93d0ec":"markdown","32220575":"markdown","2e765d7f":"markdown","8d06dd7b":"markdown","feff96af":"markdown","9e4a4798":"markdown","236c71b2":"markdown","ccb586d9":"markdown","e72795cc":"markdown","62327929":"markdown","daeb691d":"markdown","c86b859f":"markdown","e782a3f0":"markdown","2eae342c":"markdown","9a02bf31":"markdown","f55655ec":"markdown","a4ab8011":"markdown","e1178d9b":"markdown","d94db172":"markdown","bfdd1713":"markdown","d1fbdaee":"markdown"},"source":{"0093a5a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom pandas.tools.plotting import scatter_matrix\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom matplotlib import colors\nfrom matplotlib.ticker import PercentFormatter\nfrom sklearn.tree import export_graphviz\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\n# auxiliary function\nfrom sklearn.preprocessing import LabelEncoder\ndef random_colors(number_of_colors):\n    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n                 for i in range(number_of_colors)]\n    return color\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5b2ac843":"##loading the data\niris = pd.read_csv(\"..\/input\/Iris.csv\") \n##Getting a gist of the dataset in hand\niris.describe()\n","7391a06b":"#Glancing features\niris.info()","03314526":"#First few observations\niris.head(20)","6dabea54":"iris.isnull()","e02e547b":"#One more way to quickly check if your assumption about the widths and lengths of Sepal and Petal \n#differs for different species\nPivot = iris.pivot(\"Species\",\"Id\")\nprint(Pivot)\nsns.heatmap(Pivot,cbar = True)","f44c599a":"iris.hist()\nplt.show()\n","18ab740c":"##scatter plot\n\nscatter_matrix(iris)\nplt.show()","389c3e5a":"iris.Species.value_counts().plot(kind='pie')\n#Pie chart shows that all 3 species are distributed equally.","d2438bb3":"iris['Species']=iris['Species'].astype('category')\niris.dtypes","ff410116":"plt.figure()\nfig,ax=plt.subplots(1,2,figsize=(17, 19))##\niris.plot(x=\"SepalLengthCm\",y=\"SepalWidthCm\",kind=\"scatter\",ax=ax[0],sharex=False,sharey=False,label=\"sepal\",color='g')\niris.plot(x=\"PetalLengthCm\",y=\"PetalWidthCm\",kind=\"scatter\",ax=ax[1],sharex=False,sharey=False,label=\"petal\",color='y')\nax[0].set(title='Sepal comparasion ', ylabel='sepal-width')\nax[1].set(title='Petal Comparasion',  ylabel='petal-width')\nax[0].legend()\nax[1].legend()\n##Sepal comparison shows that the range of the sepal width is between 2 to 4.5,most of the data points are between 2.5 to 3.5.\n#Petal Comparision shows that the range of the petal width is between 0.5 to 2.5,intersting observation here is that there are no points in the scatterplot between 0.5 & 1.\n#There is a gradual increase in the petal length from 1 to 2.5\n#From this we can conclude that there is a finite pattern in the sepal and petal widths,lengths.","18f727d1":"##I don't recommend this part of the code for beginners\nsetosa=iris[iris['Species']=='Iris-setosa']\nversicolor =iris[iris['Species']=='Iris-versicolor']\nvirginica =iris[iris['Species']=='Iris-virginica']\n\nprint(setosa.describe())\nprint(versicolor.describe())\nprint(virginica.describe())\n\n##using the data frame to plot a scatter plot for comparing different species\n##Thanks Abhishek Gupta for this method:)\n\n\n\nplt.figure()\nfig,ax=plt.subplots(1,2,figsize=(21, 10))##1,2 indicates the visual will be fitted in a row and 2 columns.\n\nsetosa.plot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", kind=\"scatter\",ax=ax[0],label='Setosa',color='r')\nvirginica.plot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", kind=\"scatter\",ax=ax[0],label='Virginica',color='g')\nversicolor.plot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", kind=\"scatter\",ax=ax[0],label='Versicolor',color='b')\n\nsetosa.plot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", kind=\"scatter\",ax=ax[1],label='Setosa',color='r')\nversicolor.plot(x=\"PetalLengthCm\",y=\"PetalWidthCm\",kind=\"scatter\",ax=ax[1],label='Versicolor',color='b')\nvirginica.plot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", kind=\"scatter\", ax=ax[1], label='Virginica', color='g')\n\nax[0].set(title='Sepal comparasion ', ylabel='sepal-width')\nax[1].set(title='Petal Comparasion',  ylabel='petal-width')\nax[0].legend()\nax[1].legend()\n#As we have seen in the previous scatterplot,this one confirms it.","2fdc3537":"iris_1=iris.drop(['Id'],axis=1)\niris_1.head()\niris_1.corr()","b631559a":"iris.plot(kind = \"scatter\",x = \"SepalLengthCm\",y = \"SepalWidthCm\")","6e6e3bd3":"\npd.crosstab(iris.SepalLengthCm,iris.Species).plot(kind='bar')\nplt.title('Sepal Length vs Species')\nplt.xlabel('Species')\nplt.ylabel('Sepal Length')\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)\n\npd.crosstab(iris.SepalWidthCm,iris.Species).plot(kind = 'bar')\nplt.title('Sepal Width vs Species')\nplt.xlabel('Species')\nplt.ylabel('Sepal Width')\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)\n","40957439":"\npd.crosstab(iris.PetalLengthCm,iris.Species).plot(kind='bar')\nplt.title('Petal Length vs Species')\nplt.xlabel('Species')\nplt.ylabel('Petal Length')\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)\n\npd.crosstab(iris.PetalWidthCm,iris.Species).plot(kind = 'bar')\nplt.title('Petal Width vs Species')\nplt.xlabel('Species')\nplt.ylabel('Petal Width')\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)\n","472fa041":"sns.boxplot(x = \"Species\",y = \"SepalLengthCm\",data = iris)","946c04e8":" sns.pairplot(iris, hue='Species', size=2.5)\n#The pair plot also shows some overlap.","1dd23fb0":"x = iris.PetalLengthCm\ny = iris.PetalWidthCm\nplt.scatter(x, y ,s = 10*x,data = iris,cmap = \"plasma\",c = iris.PetalLengthCm)\nplt.xlabel(\"PetalLengthCm\")\nplt.ylabel(\"PetalWidthCm\")\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)","e5268960":"x =iris.SepalLengthCm\ny =iris.SepalWidthCm\nplt.scatter(x,y,s = 10*x,data = iris,cmap = \"plasma\",c = iris.SepalLengthCm)\nplt.xlabel(\"SepalLength\")\nplt.ylabel(\"SepalWidth\")\nplt.subplots_adjust(bottom=0.1, right=1.9, top=1.5)","948f691b":"##Learned this encoding technique from Ranjeet Jain's Iris notebook\nx = iris[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ny = iris['Species']\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 101)\n","6ea3aa8e":"lr_model = LogisticRegression()\nlr_model.fit(x_train,y_train)\nlr_predict = lr_model.predict(x_test)\nprint('Logistic Regression - ',accuracy_score(lr_predict,y_test))","fb21955e":"print(\"Confusion Matrix\",confusion_matrix(y_test,lr_predict))\n\n","fb785362":"print(\"Accuracy :\" ,accuracy_score(y_test,lr_predict)*100)","7b141ea9":"print(\"Report :\" ,classification_report(y_test,lr_predict))\n","4d03d1bb":"d_tree = DecisionTreeClassifier(max_depth = 4)\nd_tree_fit = d_tree.fit(x_train,y_train)\nd_tree_pred = d_tree.predict(x_test)\nprint(\"Decision Tree Accuracy\",accuracy_score(d_tree_pred,y_test))","e5d11665":"print(\"Confusion Matrix: \", \n        confusion_matrix(y_test, d_tree_pred)) \n      \nprint (\"Accuracy : \", \n    accuracy_score(y_test,d_tree_pred)*100) \n      \nprint(\"Report : \", \n    classification_report(y_test, d_tree_pred))","a4706da3":"rf_model = RandomForestClassifier(max_depth = 3)\nrf_fit = rf_model.fit(x_train,y_train)\nfr_tree_pred = rf_fit.predict(x_test)\n","2baad33d":"print(\"Confusion Matrix:\",confusion_matrix(y_test,fr_tree_pred))","4824db45":"print(\"Accuracy Score:\",accuracy_score(y_test,fr_tree_pred)*100)","a5cb4660":"print(\"EvaluationReport : \",classification_report(y_test,fr_tree_pred))","5bcb7f97":"from sklearn.cluster import KMeans\n# Number of clusters\nkmeans = KMeans(n_clusters=3)\n# Fitting the input data\nkmeans = kmeans.fit(x_train,y_train)\n# Getting the cluster labels\nlabels = kmeans.predict(x_test,y_test)\n# Centroid values\ncentroids = kmeans.cluster_centers_\nprint(centroids)","a2759770":"colormap = np.array(['purple', 'black', 'yellow'])\nplt.subplot(1, 2, 1)\nplt.subplots_adjust(right = 2,left = 0.3)\nplt.scatter(x_test.PetalLengthCm, x_test.PetalWidthCm, c=colormap[y_test], s=40)\nplt.title('K Mean Classification Test Data')\nplt.subplot(1, 2, 2)\nplt.scatter(x_train.PetalLengthCm, x_train.PetalWidthCm, c=colormap[y_train], s=40)\nplt.title('K Mean Classification on Train Data')\n\n","3855b711":"The visual above shows that all the three categories of species are of the same proportion.","e270941a":"Which is the best model?","a2a9e0ca":"We could see that the dataset has 1 Identifier,4 numerical variables & 1 Categorical Variable.\nOur task is to predict the Species with the help of all other dependent variables.\nTherefore,our assumption here is that Species is the dependent variable or the variable to be predicted.\nAll other varaibles ID,SepalLengthCm,SepalWidthCm,PetalLengthCm & PetalWidthCm are Independent  variables.\n\n","8b83c827":"Model Building","8e93d0ec":"Petal Length and Petal Width also shows uniqueness for different species.\nIris Setosa and Iris Virginica have clear distinction of Petal Lengths and Widths.\nSome of them have overlapping features.","32220575":"The diagonal grouping of the variables suggests that there is a relationship between the objects.This is also called as correlation of the varaibles.High correlation indicates high predictability with fewer features.We will talk about prediction later.","2e765d7f":"The data that we see in the real world contains noise and are generally not ready for instant analysis.Therefore we need to cleanse them for making it usable.","8d06dd7b":"Machine learning  to predict the type of Iris flower based on other parameters.\nSince this is a classification problem we will explore related algorithms.\n","feff96af":"                    **General Introduction**\n\nIn any form of analysis involving data,the main goal of it will be to solve a problem,therefore there is a pipeline to reach the goal.The starting point being gathering required data ,cleaning,visualising and so on.\n\nLast step being building machine learning models and validating them.\nHave a look at this article,\nhttps:\/\/towardsdatascience.com\/a-beginners-guide-to-the-data-science-pipeline-a4904b2d8ad3\n","9e4a4798":"Above visual shows the max and min values of Sepal Length for different Species and some more interesting things.","236c71b2":"**Correlation Coefficients\n**I have already mentioned that there is a high level of predictability with the available variables.One needs to examine the correlation between the variables.\nCorrelation is applicable only for numerical data.","ccb586d9":"Inorder to decide which model is the best model,we can consider the accuracy scores.\nYou can see that the Accuracy score for Random Forest is higher compared to all other models.\nOne more observation with respect to confusion matrix here is ,Random forest had 0 mis- calssification.All other models had misclassification to some degree.\n","e72795cc":"![image.png](attachment:image.png)\n\nThe heatmap above has grouped the species and indicates that our assumption about the Sepal and Petal lengths,widths are true.They all vary significantly for every speices.\nIris - Setosa has **smaller** length & width for both Petal and Sepal.\nIris - Versicolor has **Mediocre** length & width for both Petal and Sepal.\nIris - Virginica has **bigger** length & width for both Petal and Sepal.","62327929":"**                                                                                      Decision Tree**","daeb691d":"**Problem statement**\n\n**To predict the type of Iris species based on other features in the dataset pertaining to sepal length,width,petal length and width.\n\nHaving said that we need to know that there are different class of machine learning problems\n1.Supervised - Those which has a pre defined target variable.For every row in the dataset there is a labeled outcome which would be used as a reference to train the model.\n2.Unsupervised Learning - There is no pre defined target variable. There are no prior labellings but we have to predict,group and collate the features,so that they are meaningful.\n\nOur dataset here has a pre defined target variable Species,which qualifies this one to be a supervised learning problem.\n\nMore over our target to be predicted is categorical and hence this is a classification problem.\n**\"Be kind,fork and upvote the kernel,if you find it useful\"**","c86b859f":"                                                                              **Logistic Regression **                     ","e782a3f0":"Looks like an illusion that we do not have any null values!Great,time saver!\nShould check though.","2eae342c":"Now some visualisations,basic ones.","9a02bf31":"#This is another way\n#train=iris.sample(frac=0.8,random_state=200)\n#test=iris.drop(train.index)\n\ntrain,test = train_test_split(iris,test_size = 0.2)\ntrain.info();test.info()","f55655ec":"From this histogram we could see that there are few observations where the Sepal lengths are almost the same.\nWe coudld also see that the extreme points have distinct species captured.\nWe can confirm that there is a distinction between the Species with respect to Sepal Lengths & Widths.\n\n\n","a4ab8011":"**                                                                               Randomforest Model**","e1178d9b":"Interpreting the correlation matrix,\n1.SepalLengthCm - PetalLengthCm,PetalWidthCm are highly correlated positively.\n2.SepalWidthCm - Has negative relationship with all the other varaibles.\n3.PetalLengthCm - SepalLengthCm & PetalWidthCm are highly correlated.\n4.PetalWidthCm - SepalLengthCm & PetalWidthCm are highly correlated.","d94db172":"In the code above,the Species is converted to Categorical data type.","bfdd1713":"**    Analysis of the Iris Data Set**\n\nIris is the name of a flower.It is located in the Northern hemisphere zones, from Europe to Asia and across North America.The dataset that we have covers 3 types of Iris species,\nIris Setosa\nIris Virginica\nIris Versicolor\nThe dataset has an intersting history,I was able to learn about this from wiki page,\nhttps:\/\/en.wikipedia.org\/wiki\/Iris_flower_data_set\n\nThe Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis\".\nIt is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.\n\n","d1fbdaee":"The scatter plot depicts the Species of Iris.There are no miss classifications in the dataset.We can be assured of this as there are no overlapping dots in the graph for test set."}}