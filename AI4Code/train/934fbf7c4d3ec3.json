{"cell_type":{"3f190e42":"code","caf59e6e":"code","04903c0d":"code","d2832699":"code","6b549417":"code","fb924f35":"code","0db40b79":"code","bd12e80a":"code","450acbf7":"code","9af11de7":"code","8d6a926f":"code","8cbba3b0":"code","47075c20":"code","3ef60125":"code","51595b27":"code","7a9dfe83":"code","fec5108e":"code","d5e132fd":"code","f630254f":"code","834adf58":"code","edd408e4":"code","5f9367a0":"code","e42b7ef0":"code","e262cb20":"markdown","1d72c543":"markdown","50735c7c":"markdown","8024cd6c":"markdown","aeb73031":"markdown","14c09a7c":"markdown","1607d49a":"markdown","755c1b70":"markdown","80514a7b":"markdown","bc92aeaa":"markdown","68efa77d":"markdown","19282653":"markdown","af582006":"markdown","b1c117ab":"markdown","db4a3cfa":"markdown","74e2b5e2":"markdown"},"source":{"3f190e42":"import numpy as np\nimport pandas as pd\nimport warnings\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport time\n\nrandom_state = 6\nnp.random.seed(random_state)\nwarnings.filterwarnings('ignore')","caf59e6e":"%matplotlib inline\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n# latex parameter\nfont = {\n    'family': 'serif', \n    'serif': ['Computer Modern Roman'],\n    'weight' : 'regular',\n    'size'   : 18\n    }\n\nplt.rc('font', **font)\nplt.rc('text', usetex=False)\n# plt.style.use('classic')\n\ncolor_map = 'viridis'","04903c0d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","d2832699":"df_train = pd.read_csv('\/kaggle\/input\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/test.csv')","6b549417":"print('Training data shape: {}'.format(df_train.shape))\nprint('Training data shape: {}'.format(df_test.shape))","fb924f35":"print('Is null on train: {}'.format(df_train.isnull().any().any()))\nprint('Is null on test: {}'.format(df_test.isnull().any().any()))","0db40b79":"df_train.describe()","bd12e80a":"import seaborn as sns\ncor = df_train.corr()\nplt.figure(figsize=(16,10))\nsns.heatmap(cor)","450acbf7":"col_to_drop = list(df_train.columns[df_train.columns.str.startswith('ps_calc_')])\ndf_train = df_train.drop(col_to_drop, axis=1)  \ndf_test = df_test.drop(col_to_drop, axis=1)","9af11de7":"def get_missing_features(df):\n    missings = pd.DataFrame([], columns=['feature', 'no_recoreds', 'percentage'])\n    total_rows = df.shape[0]\n    index = 0\n    for feature in list(df):\n        total_nulls = df[feature].isnull().sum()\n        if total_nulls > 0:\n            missings_perc = total_nulls \/ total_rows\n            missings.loc[index] = [feature, total_nulls, missings_perc]\n            index += 1\n    missings = missings.sort_values('no_recoreds', ascending=False)\n    return missings","8d6a926f":"df_missings = get_missing_features(df_train)\nprint(df_missings)","8cbba3b0":"#df_missings.plot(x='feature', y='no_recoreds', kind='bar', )","47075c20":"for i, feature in enumerate(list(df_train.drop(['id'], axis=1))):\n    if df_train[feature].isnull().sum() > 0:\n        df_train[feature].fillna(df_train[feature].mode()[0],inplace=True)\n\nfor i, feature in enumerate(list(df_test.drop(['id'], axis=1))):\n    if df_test[feature].isnull().sum() > 0:\n        df_test[feature].fillna(df_test[feature].mode()[0],inplace=True)","3ef60125":"get_missing_features(df_train)\nget_missing_features(df_test)","51595b27":"cat_cols = [col for col in df_train.columns if '_cat' in col]\ndummed_cols = []\n\nfor cat_col in cat_cols:\n    unique_values = len(np.unique(df_train[cat_col]))\n    if unique_values < 50:\n        dummed_cols.append(cat_col)\n    print('{} has {} unique values'.format(cat_col, unique_values))","7a9dfe83":"id_test = df_test['id'].values\ny = df_train['target'].values\n\ndf_train = df_train.drop(['target','id'], axis = 1)\ndf_test = df_test.drop(['id'], axis = 1)\n\ncat_features = [a for a in df_train.columns if a.endswith('cat')]\n\nfor column in cat_features:\n    temp = pd.get_dummies(pd.Series(df_train[column]))\n    df_train = pd.concat([df_train,temp],axis=1)\n    df_train = df_train.drop([column],axis=1)\n    \nfor column in cat_features:\n    temp = pd.get_dummies(pd.Series(df_test[column]))\n    df_test = pd.concat([df_test,temp],axis=1)\n    df_test = df_test.drop([column],axis=1)\n\nprint(df_train.values.shape, df_test.values.shape)","fec5108e":"# Distribution of target variable\ndef plot_class_balace(train, val):\n    train_aa = dict(Counter(train))\n    val_aa = dict(Counter(val))\n    \n    plt.figure(figsize=(10, 4))\n    plt.subplot(121)\n    plt.bar([0, 1], height= [train_aa[0],train_aa[1]])\n    plt.xticks([0, 1]);\n    plt.xlabel('Class')\n    plt.ylabel('Number of data points')\n    plt.title('Train positive class {}%\\n:'.format(round(train_aa[1]*100\/train_aa[0], 2)))\n    \n    plt.subplot(122)\n    plt.bar([0, 1], height= [val_aa[0],val_aa[1]])\n    plt.xticks([0, 1]);\n    plt.xlabel('Class')\n    plt.title('Valid pos class {}%\\n:'.format(round(val_aa[1]*100\/val_aa[0], 2)))\n    plt.tight_layout()\n    plt.show()\n\nplot_class_balace(y_train_im, y_val_im)","d5e132fd":"# from https:\/\/www.kaggle.com\/mashavasilenko\/\n# porto-seguro-xgb-modeling-and-parameters-tuning\ndef eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini \/ (ntrue * (n - ntrue))\n    return gini\n\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = -eval_gini(labels, preds)\n    return [('gini', gini_score)]\n\ndef gini_normalized(a, p):\n    return gini(a, p) \/ gini(a, a)","f630254f":"from sklearn.model_selection import StratifiedKFold\n\nclass Create_ensemble(object):\n    def __init__(self, n_splits, base_models):\n        self.n_splits = n_splits\n        self.base_models = base_models\n\n    def predict(self, X, y, T):\n        X = np.array(X)\n        y = np.array(y)\n        T = np.array(T)\n\n        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n\n        S_train = np.zeros((X.shape[0], len(self.base_models)))\n        S_test = np.zeros((T.shape[0], len(self.base_models)))\n        \n        for i, clf in enumerate(self.base_models):\n            S_test_i = np.zeros((T.shape[0], self.n_splits))\n\n            for j, (train_idx, valid_idx) in enumerate(folds):\n                X_train = X[train_idx]\n                y_train = y[train_idx]\n                X_valid = X[valid_idx]\n                y_valid = y[valid_idx]\n                \n                clf.fit(X_train, y_train)\n                valid_pred = clf.predict_proba(X_valid)[:,1]\n                S_train[valid_idx, i] = valid_pred\n                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n            \n            print( \"\\nTraining Gini for model {} : {}\".format(i, eval_gini(y, S_train[:,i])))\n            S_test[:, i] = S_test_i.mean(axis=1)\n            \n        return S_train, S_test","834adf58":"# LightGBM params\nlgb_params = {}\nlgb_params['learning_rate'] = 0.02\nlgb_params['n_estimators'] = 700\nlgb_params['max_bin'] = 15\nlgb_params['subsample'] = 0.8\nlgb_params['subsample_freq'] = 10\nlgb_params['colsample_bytree'] = 0.8   \nlgb_params['min_child_samples'] = 800\nlgb_params['random_state'] = 99\nlgb_params['scale_pos_weight'] = 3\n\nlgb_params2 = {}\nlgb_params2['learning_rate'] = 0.02\nlgb_params2['n_estimators'] = 900\nlgb_params2['max_bin'] = 20\nlgb_params2['subsample'] = 0.8\nlgb_params2['subsample_freq'] = 10\nlgb_params2['colsample_bytree'] = 0.8   \nlgb_params2['min_child_samples'] = 600\nlgb_params2['random_state'] = 99\nlgb_params2['scale_pos_weight'] = 3\n\nlgb_model = LGBMClassifier(**lgb_params)\nlgb_model2 = LGBMClassifier(**lgb_params2)","edd408e4":"lgb_stack = Create_ensemble(n_splits = 5, base_models = [lgb_model, lgb_model2])        \nX = df_train\nY = y\nT = df_test\nlgb_train_pred, lgb_test_pred = lgb_stack.predict(X, Y, T)","5f9367a0":"# Create submission file\nsub = pd.DataFrame()\nsub['id'] = id_test\nsub['target'] = lgb_test_pred.mean(axis=1)\nsub.to_csv('submission.csv', float_format='%.6f', index=False)","e42b7ef0":"import seaborn as sns\ntest_pred_df = pd.DataFrame(data = lgb_test_pred)\ncor = test_pred_df.corr()\nplt.figure(figsize=(16,10))\nsns.heatmap(cor)","e262cb20":"### Descriptive statistics","1d72c543":"### Plot class ratio","50735c7c":"### Heatmap ","8024cd6c":"## Transform category features to dummies","aeb73031":"#### Since 'ps_calc' features do not show any have zero relationship with other features\n#### We can delete them.","14c09a7c":"## Check category features of the dataset","1607d49a":"## Lightbm model","755c1b70":"### Treat missing values by mean of the column","80514a7b":"### Check if there are any missing values","bc92aeaa":"### Check if both test and train have the same shape","68efa77d":"### Gini coeficient ","19282653":"### Ensembling","af582006":"## correlation among the models","b1c117ab":"## Work with missing values","db4a3cfa":"### Check if there are any missing values","74e2b5e2":"### Bar plot of missing features"}}