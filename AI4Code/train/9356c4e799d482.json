{"cell_type":{"5501a8a3":"code","902b18b9":"code","02481b3a":"code","dad832c2":"code","5d3daff7":"code","ce74d306":"code","834180d3":"code","12e07cf8":"code","1a1499c0":"code","6025d0a5":"code","802944ec":"code","89dd4211":"code","ed8269a5":"code","f0ff4903":"code","a49ab57f":"code","f29f05f2":"code","8bd3bf9c":"code","73322c58":"code","632f20b0":"code","1a3a870e":"code","c6f2717b":"code","0c7f6d54":"code","a5947e16":"code","5b5f0bd9":"code","c2bfbad6":"code","d6ae1f6a":"code","317ddb04":"code","709e8f86":"code","47927bcc":"markdown","a9d2c68e":"markdown","3910b97c":"markdown","f1f94631":"markdown","5abcb855":"markdown","8d1a5e0e":"markdown","c3e14da8":"markdown","4e1b9e2b":"markdown","53a9de4d":"markdown","bb33f637":"markdown"},"source":{"5501a8a3":"import numpy as np\nimport pandas as pd\n\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","902b18b9":"data = pd.read_csv('..\/input\/nutrition-facts\/menu.csv')","02481b3a":"data","dad832c2":"data.info()","5d3daff7":"data['Category'].unique()","ce74d306":"label_encoder = LabelEncoder()\n\ndata['Category'] = label_encoder.fit_transform(data['Category'])\n\nlabel_mappings = dict(enumerate(label_encoder.classes_))\nlabel_mappings","834180d3":"data","12e07cf8":"names = data['Item'].copy()\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(names)\n\nnames = tokenizer.texts_to_sequences(names)","1a1499c0":"vocab_length = len(tokenizer.word_index) + 1\n\nmax_seq_length = np.max(list(map(lambda x: len(x), names)))\n\nprint(\"Vocabulary length:\", vocab_length)\nprint(\"Max sequence length:\", max_seq_length)","6025d0a5":"names = pad_sequences(names, maxlen=max_seq_length, padding='post')\nnames","802944ec":"data = data.drop('Item', axis=1)","89dd4211":"data","ed8269a5":"data['Serving Size']","f0ff4903":"data['Serving Size'].unique()","a49ab57f":"units = []\n\ndef get_grams(serving):\n    units.append(0)\n    return np.float(re.search(r'(?<=\\()[\\d]+', serving).group(0))\n\ndef get_ml(serving):\n    units.append(1)\n    return np.float(re.search(r'(?<=\\()[\\d]+', serving).group(0))\n\ndef get_fl_oz(serving):\n    units.append(2)\n    return np.float(re.search(r'^[\\d.]+', serving).group(0))","f29f05f2":"def get_units(serving):\n    if ' g)' in serving:\n        return get_grams(serving)\n    \n    elif ' ml)' in serving:\n        return get_ml(serving)\n    \n    else:\n        return get_fl_oz(serving)","8bd3bf9c":"data['Serving Size'] = data['Serving Size'].apply(get_units)\ndata['Serving Units'] = units","73322c58":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","632f20b0":"data = onehot_encode(data, 'Serving Units', 'units')","1a3a870e":"data","c6f2717b":"y = data['Category'].copy()\nX = data.drop('Category', axis=1).copy()","0c7f6d54":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","a5947e16":"names_train, names_test, X_train, X_test, y_train, y_test = train_test_split(names, X, y, train_size=0.7)","5b5f0bd9":"num_classes = len(y.unique())\nprint(\"Number of classes:\", num_classes)\n\nname_feature_length = names.shape[1]\nprint(\"Name feature length:\", name_feature_length)\n\nother_feature_length = X.shape[1]\nprint(\"Other feature length:\", other_feature_length)","c2bfbad6":"# Name features\nname_input = tf.keras.Input(shape=(name_feature_length,), name=\"name_input\")\n\nname_embedding = tf.keras.layers.Embedding(\n    input_dim=vocab_length,\n    output_dim=64,\n    input_length=name_feature_length,\n    name=\"name_embedding\"\n)(name_input)\n\nname_flatten = tf.keras.layers.Flatten(name=\"name_flatten\")(name_embedding)\n\n\n# Other features\nother_input = tf.keras.Input(shape=(other_feature_length,), name=\"other_input\")\n\ndense_1 = tf.keras.layers.Dense(64, activation='relu', name=\"dense_1\")(other_input)\ndense_2 = tf.keras.layers.Dense(64, activation='relu', name=\"dense_2\")(dense_1)\n\n\n# Combined\nconcat = tf.keras.layers.concatenate([name_flatten, dense_2], name=\"concatenate\")\n\noutputs = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(concat)\n\n\n# Create model\nmodel = tf.keras.Model(inputs=[name_input, other_input], outputs=outputs)","d6ae1f6a":"print(model.summary())\ntf.keras.utils.plot_model(model)","317ddb04":"batch_size = 32\nepochs = 100\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    [names_train, X_train],\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","709e8f86":"results = model.evaluate([names_test, X_test], y_test, verbose=0)\n\nprint(\"Model Accuracy:\", results[1])","47927bcc":"# Encoding Item Column","a9d2c68e":"# Modeling","3910b97c":"# Cleaning Serving Size Feature","f1f94631":"# Task for Today  \n\n***\n\n## McDonald's Menu Item Type Prediction  \n\nGiven *data about McDonald's menu items*, let's try to predict the **type** of a given item.  \n  \nWe will use a TensorFlow ANN with two inputs to make our predictions.","5abcb855":"# Training","8d1a5e0e":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/YFvFoTZLKlA","c3e14da8":"# Splitting\/Scaling","4e1b9e2b":"# Results","53a9de4d":"# Encoding Label Column","bb33f637":"# Getting Started"}}