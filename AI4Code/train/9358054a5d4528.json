{"cell_type":{"c3530432":"code","b94e421d":"code","5d582def":"code","e38b3a42":"code","44ba03ae":"code","085c89db":"code","6959fee7":"code","645f1cd6":"code","ad3065fd":"code","f2355838":"code","305584cd":"code","221c579a":"code","26f0a320":"code","521b13a1":"code","39fcd0a6":"code","73fad247":"code","c0408996":"code","5c271657":"code","deac6dd2":"code","4553734d":"code","2d5224be":"code","78ad9688":"markdown","6bd9f897":"markdown","5d1d27be":"markdown","557d04ac":"markdown","b6f9fc46":"markdown","344a5bd9":"markdown","8a63ca0f":"markdown","06a67622":"markdown","eaefc7a3":"markdown","a255fa10":"markdown","8f7564bc":"markdown","13cf411f":"markdown","c10a44cd":"markdown","573b8d55":"markdown","e1c509f3":"markdown","08352e15":"markdown","72fd6fa3":"markdown","ade2d466":"markdown","ec61fc29":"markdown","ae13cfbb":"markdown","ea3ba64b":"markdown","b2f168fb":"markdown","73bc40ec":"markdown","c32a8104":"markdown","c172f781":"markdown","a1601b47":"markdown"},"source":{"c3530432":"# Import helper libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport requests\nfrom io import BytesIO # Use When expecting bytes-like objects\nimport pickle\nfrom collections import OrderedDict\nimport os\nfrom os import path\nimport ast\nimport random\n\n# import matplotlib for visualization\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\n\n# import PIL for image manipulation\nfrom PIL import Image, ImageDraw, ImageOps\n\n# import machine learning libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# import pytorch\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms","b94e421d":"# define 10 classes to load the data for\ncategories = ['cannon','eye', 'face', 'nail', 'pear','piano','radio','spider','star','sword']\nlabel_dict = {0:'cannon',1:'eye', 2:'face', 3:'nail', 4:'pear',\n                      5:'piano',6:'radio', 7:'spider', 8:'star', 9:'sword'}\n\n# load data for each category\nclasses = {}\nfor category in categories:\n    data = pd.read_csv(\"..\/input\/train_simplified\/\" + category + \".csv\")\n    classes[category] = data","5d582def":"# Image manipulation utilities: \n\ndef convert_to_PIL(drawing, width = 256, height = 256):\n    \"\"\"\n    Function to convert from drawing to PIL image.\n    INPUT:\n        drawing - drawing from 'drawing' column\n        width - width of the initial image\n        height - height of the initial image\n    OUTPUT:\n        pil_img - (PIL Image) image\n    \"\"\"\n    \n    # initialize empty (white) PIL image\n    pil_img = Image.new('RGB', (width, height), 'white')\n    pixels = pil_img.load()\n            \n    draw = ImageDraw.Draw(pil_img)\n    \n    # draw strokes as lines\n    for x,y in drawing:\n        for i in range(1, len(x)):\n            draw.line((x[i-1], y[i-1], x[i], y[i]), fill=0)\n        \n    return pil_img\n\ndef convert_to_np_raw(drawing, width = 256, height = 256):\n    \"\"\"\n    INPUT:\n        drawing - drawing in initial format\n        width - width of the initial image\n        height - height of the initial image\n    OUTPUT:\n        img - drawing converted to the numpy array (28 X 28)\n    \"\"\"\n    # initialize empty numpy array\n    img = np.zeros((28, 28))\n    \n    # create a PIL image out of drawing\n    pil_img = convert_to_PIL(drawing)\n    \n    #resize to 28,28\n    pil_img.thumbnail((28,28), Image.ANTIALIAS)\n    \n    pil_img = pil_img.convert('RGB')\n    pixels = pil_img.load()\n    \n    # fill in numpy array with pixel values\n    for i in range(0, 28):\n        for j in range(0, 28):\n            img[i, j] = 1 - pixels[j, i][0] \/ 255\n    \n    return img\n\ndef convert_to_np(pil_img, width = 256, height = 256):\n    \"\"\"\n    Function to convert PIL Image to numpy array.\n    INPUT:\n        pil_img - (PIL Image) image to be converted\n    OUTPUT:\n        img - (numpy array) converted image with shape (width, height)\n    \"\"\"\n    pil_img = pil_img.convert('RGB')\n\n    img = np.zeros((width, height))\n    pixels = pil_img.load()\n\n    for i in range(0, width):\n        for j in range(0, height):\n            img[i, j] = 1 - pixels[j, i][0] \/ 255\n\n    return img\n\ndef view_image(img, width = 256, height = 256):\n    \"\"\"\n    Function to view numpy image with matplotlib.\n    The function saves the image as png.\n    INPUT:\n        img - (numpy array) image from train dataset with size (1, 784)\n    OUTPUT:\n        None\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(6,9))\n    ax.imshow(img.reshape(width, height).squeeze())\n    ax.axis('off')\n\n    plt.show()\n    \ndef crop_image(image):\n    \"\"\"\n    Crops image (crops out white spaces).\n    INPUT:\n        image - PIL image of original size to be cropped\n    OUTPUT:\n        cropped_image - PIL image cropped to the center  and resized to (28, 28)\n    \"\"\"\n    cropped_image = image\n\n    # get image size\n    width, height = cropped_image.size\n\n    # get image pixels\n    pixels = cropped_image.load()\n\n    image_strokes_rows = []\n    image_strokes_cols = []\n\n    # run through the image\n    for i in range(0, width):\n        for j in range(0, height):\n            # save coordinates of the image\n            if (pixels[i,j][0] > 0):\n                image_strokes_cols.append(i)\n                image_strokes_rows.append(j)\n\n    # if image is not empty then crop to contents of the image\n    if (len(image_strokes_rows)) > 0:\n        # find the box for image\n        row_min = np.array(image_strokes_rows).min()\n        row_max = np.array(image_strokes_rows).max()\n        col_min = np.array(image_strokes_cols).min()\n        col_max = np.array(image_strokes_cols).max()\n\n        # find the box for cropping\n        margin = min(row_min, height - row_max, col_min, width - col_max)\n\n        # crop image\n        border = (col_min, row_min, width - col_max, height - row_max)\n        cropped_image = ImageOps.crop(cropped_image, border)\n\n    # get cropped image size\n    width_cropped, height_cropped = cropped_image.size\n\n    # create square resulting image to paste cropped image into the center\n    dst_im = Image.new(\"RGBA\", (max(width_cropped, height_cropped), max(width_cropped, height_cropped)), \"white\")\n    offset = ((max(width_cropped, height_cropped) - width_cropped) \/\/ 2, (max(width_cropped, height_cropped) - height_cropped) \/\/ 2)\n    # paste to the center of a resulting image\n    dst_im.paste(cropped_image, offset)\n\n    #resize to 28,28\n    dst_im.thumbnail((28,28), Image.ANTIALIAS)\n\n    return dst_im\n\ndef normalize(arr):\n    \"\"\"\n    Function performs the linear normalizarion of the array.\n    https:\/\/stackoverflow.com\/questions\/7422204\/intensity-normalization-of-image-using-pythonpil-speed-issues\n    http:\/\/en.wikipedia.org\/wiki\/Normalization_%28image_processing%29\n    INPUT:\n        arr - orginal numpy array\n    OUTPUT:\n        arr - normalized numpy array\n    \"\"\"\n    arr = arr.astype('float')\n    # Do not touch the alpha channel\n    for i in range(3):\n        minval = arr[...,i].min()\n        maxval = arr[...,i].max()\n        if minval != maxval:\n            arr[...,i] -= minval\n            arr[...,i] *= (255.0\/(maxval-minval))\n    return arr\n\ndef normalize_image(image):\n    \"\"\"\n    Function performs the normalization of the image.\n    https:\/\/stackoverflow.com\/questions\/7422204\/intensity-normalization-of-image-using-pythonpil-speed-issues\n    INPUT:\n        image - PIL image to be normalized\n    OUTPUT:\n        new_img - PIL image normalized\n    \"\"\"\n    arr = np.array(image)\n    new_img = Image.fromarray(normalize(arr).astype('uint8'),'RGBA')\n    return new_img\n\ndef rotate_image(src_im, angle = 45, size = (28,28)):\n    \"\"\"\n    Function to rotate PIL Image file\n    INPUT:\n        src_im - (PIL Image) 28x28 image to be rotated\n        angle - angle to rotate the image\n        size - (tuple) size of the output image\n    OUTPUT:\n        dst_im - (PIL Image) rotated image\n    \"\"\"\n    dst_im = Image.new(\"RGBA\", size, \"white\")\n    src_im = src_im.convert('RGBA')\n\n    rot = src_im.rotate(angle)\n    dst_im.paste(rot, (0, 0), rot)\n\n    return dst_im\n\ndef flip_image(src_im):\n    \"\"\"\n    Function to flip a PIL Image file.\n    INPUT:\n        scr_im - (PIL Image) image to be flipped\n    OUTPUT:\n        dst_im - (PIL Image) flipped image\n    \"\"\"\n    dst_im = src_im.transpose(Image.FLIP_LEFT_RIGHT)\n    return dst_im","e38b3a42":"# shrinking the images\n\n# create the dictionary containing classes names as keys and images as values\nvalues_dict = {}\nfor category in categories:\n    data = classes[category][:3000]\n    values = [convert_to_np_raw(ast.literal_eval(img)).reshape(1, 784) for img in data['drawing'].values]\n    values_dict[category] = values\n    \n# concatenate to create X (values) and y (labels) datasets\nX = []\ny = []\n\nfor key, value in label_dict.items():\n    data_i = values_dict[value]\n    Xi = np.concatenate(data_i, axis = 0)\n    yi = np.full((len(Xi), 1), key).ravel()\n    \n    X.append(Xi)\n    y.append(yi)\n    \nX = np.concatenate(X, axis = 0)\ny = np.concatenate(y, axis = 0)","44ba03ae":"def view_images_grid(X, y):\n    \"\"\"\n    Function to plot grid with several examples of images.\n    INPUT:\n        X - (numpy array) images dataset\n        y - (numpy array) labels for images from X dataset\n\n    OUTPUT: None\n    \"\"\"\n    fig, axs = plt.subplots(5, 10, figsize=(20,10))\n    \n    for label_num in range(0,50):\n        r_label = random.randint(0, len(X) - 1)\n        image = X[r_label].reshape(28,28)  #reshape images\n        i = label_num \/\/ 10\n        j = label_num % 10\n        axs[i,j].imshow(image) #plot the data\n        axs[i,j].axis('off')\n        axs[i,j].set_title(label_dict[y[r_label]])\n\n    plt.show()","085c89db":"view_images_grid(X, y)","6959fee7":"def get_label_heatmap(X, y, label, label_name):\n    \"\"\"\n    Function to plot the heatmap for images with same label.\n    INPUT:\n        X - (numpy array) dataset\n        y - (numpy array) labels for X dataset\n        label - (int) label for images\n        label_name - (str) name for images label\n\n    OUTPUT: None\n    \"\"\"\n    # filter X_train to remove all other images\n    label_filter = y == label\n    X = pd.DataFrame(X)\n    X_labeled = X[label_filter]\n\n    # find mean value for pixels\n    X_mean = np.sum(X_labeled, axis = 0).values\n\n    return X_mean","645f1cd6":"fig, axs = plt.subplots(2,5, figsize=(10,5))\n\nfor key, value in label_dict.items():\n    # get heatmap\n    heatmap = get_label_heatmap(X, y, key, value)\n    \n    i = key \/\/ 5\n    j = key % 5\n    \n    # plot image\n    axs[i,j].set_title(value)\n    axs[i,j].imshow(heatmap.reshape(28, 28).squeeze())\n    axs[i,j].axis('off')\n    \nplt.show()","ad3065fd":"def build_model(input_size, output_size, hidden_sizes, dropout = 0.0):\n    '''\n    Function creates deep learning model based on parameters passed.\n\n    INPUT:\n        input_size, output_size, hidden_sizes - layer sizes\n        dropout - dropout (probability of keeping a node)\n\n    OUTPUT:\n        model - deep learning model\n    '''\n\n    # Build a feed-forward network\n    model = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n                          ('relu1', nn.ReLU()),\n                          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n                          ('bn2', nn.BatchNorm1d(num_features=hidden_sizes[1])),\n                          ('relu2', nn.ReLU()),\n                          ('dropout', nn.Dropout(dropout)),\n                          ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n                          ('bn3', nn.BatchNorm1d(num_features=hidden_sizes[2])),\n                          ('relu3', nn.ReLU()),\n                          ('logits', nn.Linear(hidden_sizes[2], output_size))]))\n\n    return model\n\ndef shuffle(X_train, y_train):\n    \"\"\"\n    Function which shuffles training dataset.\n    INPUT:\n        X_train - (tensor) training set\n        y_train - (tensor) labels for training set\n\n    OUTPUT:\n        X_train_shuffled - (tensor) shuffled training set\n        y_train_shuffled - (tensor) shuffled labels for training set\n    \"\"\"\n    X_train_shuffled = X_train.numpy()\n    y_train_shuffled = y_train.numpy().reshape((X_train.shape[0], 1))\n\n    permutation = list(np.random.permutation(X_train.shape[0]))\n    X_train_shuffled = X_train_shuffled[permutation, :]\n    y_train_shuffled = y_train_shuffled[permutation, :].reshape((X_train.shape[0], 1))\n\n    X_train_shuffled = torch.from_numpy(X_train_shuffled).float()\n    y_train_shuffled = torch.from_numpy(y_train_shuffled).long()\n\n    return X_train_shuffled, y_train_shuffled\n\ndef fit_model(model, X_train, y_train, epochs = 100, n_chunks = 1000, learning_rate = 0.003, weight_decay = 0, optimizer = 'SGD'):\n    \"\"\"\n    Function which fits the model.\n\n    INPUT:\n        model - pytorch model to fit\n        X_train - (tensor) train dataset\n        y_train - (tensor) train dataset labels\n        epochs - number of epochs\n        n_chunks - number of chunks to cplit the dataset\n        learning_rate - learning rate value\n\n    OUTPUT: None\n    \"\"\"\n\n    print(\"Fitting model with epochs = {epochs}, learning rate = {lr}\\n\"\\\n    .format(epochs = epochs, lr = learning_rate))\n\n    criterion = nn.CrossEntropyLoss()\n\n    if (optimizer == 'SGD'):\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n    else:\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n\n    print_every = 10\n\n    steps = 0\n\n    for e in range(epochs):\n        running_loss = 0\n\n        X_train, y_train = shuffle(X_train, y_train)\n\n        images = torch.chunk(X_train, n_chunks)\n        labels = torch.chunk(y_train, n_chunks)\n\n        for i in range(n_chunks):\n            steps += 1\n\n            optimizer.zero_grad()\n\n            # Forward and backward passes\n            output = model.forward(images[i])\n            loss = criterion(output, labels[i].squeeze())\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n        \n        if epochs % print_every == 0:\n            print(\"Epoch: {}\/{}... \".format(e+1, epochs),\n                  \"Loss: {:.4f}\".format(running_loss\/print_every))\n\n            running_loss = 0\n                \n                \ndef view_classify(img, ps):\n    \"\"\"\n    Function for viewing an image and it's predicted classes\n    with matplotlib.\n\n    INPUT:\n        img - (tensor) image file\n        ps - (tensor) predicted probabilities for each class\n    \"\"\"\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(['cannon','eye', 'face', 'nail', 'pear','piano','radio','spider','star','sword'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n    plt.show()\n    \ndef test_model(model, img):\n    \"\"\"\n    Function creates test view of the model's prediction for image.\n\n    INPUT:\n        model - pytorch model\n        img - (tensor) image from the dataset\n\n    OUTPUT: None\n    \"\"\"\n\n    # Convert 2D image to 1D vector\n    img = img.resize_(1, 784)\n\n    ps = get_preds(model, img)\n    view_classify(img.resize_(1, 28, 28), ps)\n\ndef get_preds(model, input):\n    \"\"\"\n    Function to get predicted probabilities from the model for each class.\n\n    INPUT:\n        model - pytorch model\n        input - (tensor) input vector\n\n    OUTPUT:\n        ps - (tensor) vector of predictions\n    \"\"\"\n\n    # Turn off gradients to speed up this part\n    with torch.no_grad():\n        logits = model.forward(input)\n    ps = F.softmax(logits, dim=1)\n    return ps\n\ndef get_labels(pred):\n    \"\"\"\n        Function to get the vector of predicted labels for the images in\n        the dataset.\n\n        INPUT:\n            pred - (tensor) vector of predictions (probabilities for each class)\n        OUTPUT:\n            pred_labels - (numpy) array of predicted classes for each vector\n    \"\"\"\n\n    pred_np = pred.numpy()\n    pred_values = np.amax(pred_np, axis=1, keepdims=True)\n    pred_labels = np.array([np.where(pred_np[i, :] == pred_values[i, :])[0] for i in range(pred_np.shape[0])])\n    pred_labels = pred_labels.reshape(len(pred_np), 1)\n\n    return pred_labels\n\ndef evaluate_model(model, train, y_train, test, y_test):\n    \"\"\"\n    Function to print out train and test accuracy of the model.\n\n    INPUT:\n        model - pytorch model\n        train - (tensor) train dataset\n        y_train - (numpy) labels for train dataset\n        test - (tensor) test dataset\n        y_test - (numpy) labels for test dataset\n\n    OUTPUT:\n        accuracy_train - accuracy on train dataset\n        accuracy_test - accuracy on test dataset\n    \"\"\"\n    train_pred = get_preds(model, train)\n    train_pred_labels = get_labels(train_pred)\n\n    test_pred = get_preds(model, test)\n    test_pred_labels = get_labels(test_pred)\n\n    accuracy_train = accuracy_score(y_train, train_pred_labels)\n    accuracy_test = accuracy_score(y_test, test_pred_labels)\n\n    print(\"Accuracy score for train set is {} \\n\".format(accuracy_train))\n    print(\"Accuracy score for test set is {} \\n\".format(accuracy_test))\n\n    return accuracy_train, accuracy_test\n\ndef plot_learning_curve(input_size, output_size, hidden_sizes, train, labels, y_train, test, y_test, learning_rate = 0.003, weight_decay = 0.0, dropout = 0.0, n_chunks = 1000, optimizer = 'SGD'):\n    \"\"\"\n    Function to plot learning curve depending on the number of epochs.\n\n    INPUT:\n        input_size, output_size, hidden_sizes - model parameters\n        train - (tensor) train dataset\n        labels - (tensor) labels for train dataset\n        y_train - (numpy) labels for train dataset\n        test - (tensor) test dataset\n        y_test - (numpy) labels for test dataset\n        learning_rate - learning rate hyperparameter\n        weight_decay - weight decay (regularization)\n        dropout - dropout for hidden layer\n        n_chunks - the number of minibatches to train the model\n        optimizer - optimizer to be used for training (SGD or Adam)\n\n    OUTPUT: None\n    \"\"\"\n    train_acc = []\n    test_acc = []\n\n    for epochs in np.arange(10, 60, 10):\n        # create model\n        model = build_model(input_size, output_size, hidden_sizes, dropout = dropout)\n\n        # fit model\n        fit_model(model, train, labels, epochs = epochs, n_chunks = n_chunks, learning_rate = learning_rate, weight_decay = weight_decay, optimizer = 'SGD')\n        # get accuracy\n        accuracy_train, accuracy_test = evaluate_model(model, train, y_train, test, y_test)\n\n        train_acc.append(accuracy_train)\n        test_acc.append(accuracy_test)\n    \n    return train_acc, test_acc","f2355838":"# Split dataset into train\/test splits\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)","305584cd":"# Convert to tensors\ntrain = torch.from_numpy(X_train).float()\nlabels = torch.from_numpy(y_train).long()\ntest = torch.from_numpy(X_test).float()\ntest_labels = torch.from_numpy(y_test).long()\n\n# Set hyperparameters for our network\ninput_size = 784\nhidden_sizes = [128, 100, 64]\noutput_size = 10\n\ndropout = 0.0\nweight_decay = 0.0\nn_chunks = 700\nlearning_rate = 0.03\noptimizer = 'SGD'","221c579a":"# Build model\nmodel = build_model(input_size, output_size, hidden_sizes, dropout = dropout)\n\n# Fit model\ntrain_acc, test_acc = plot_learning_curve(input_size, output_size, hidden_sizes, train, labels, y_train, test, y_test, learning_rate = learning_rate, dropout = dropout, weight_decay = weight_decay, n_chunks = n_chunks, optimizer = optimizer)","26f0a320":"# Plot curve\nx = np.arange(10, 10 * (len(train_acc) + 1), 10)\nplt.plot(x, train_acc)\nplt.plot(x, test_acc)\nplt.legend(['train', 'test'], loc='upper left')\nplt.title('Accuracy, learning_rate = ' + str(learning_rate), fontsize=14)\nplt.xlabel('Number of epochs', fontsize=11)\nplt.ylabel('Accuracy', fontsize=11)\nplt.show()","521b13a1":"def convert_to_PIL_from_np(img):\n    \"\"\"\n    Function to convert numpy (1, 784) image to PIL image.\n    INPUT:\n        img - (numpy array) image from train dataset with size (1, 784)\n    OUTPUT:\n        pil_img - (PIL Image) 28x28 image\n    \"\"\"\n    img_r = img.reshape(28,28)\n\n    pil_img = Image.new('RGB', (28, 28), 'white')\n    pixels = pil_img.load()\n\n    for i in range(0, 28):\n        for j in range(0, 28):\n            if img_r[i, j] > 0:\n                pixels[j, i] = (255 - int(img_r[i, j] * 255), 255 - int(img_r[i, j] * 255), 255 - int(img_r[i, j] * 255))\n\n    return pil_img\n\ndef add_flipped_and_rotated_images(X_train, y_train):\n    \"\"\"\n    Function which adds flipped and rotated images to the original dataset.\n    INPUT:\n        X_train - (numpy array) the original training set\n        y_train - (numpy array) original labels dataset\n    OUTPUT:\n        X_Train_new - (numpy array) the dataset with added flipped and rotated\n        images\n        y_train_new - (numpy array) labels for the new training dataset\n    \"\"\"\n    print(\"Adding flipped and rotated images to the training set. \\n\")\n\n    X_train_new = X_train.copy()\n    y_train_new = y_train.copy().reshape(y_train.shape[0], 1)\n\n    for i in range(0, X_train.shape[0], 10): # I will skip some images just to run this faster \n        # get image to rotate and flip\n        img = X_train[i]\n        pil_img = convert_to_PIL_from_np(img)\n\n        # get random angle\n        angle = random.randint(5, 10)\n\n        # rotate and flip\n        rotated = convert_to_np(rotate_image(pil_img, angle), 28, 28)\n        flipped = convert_to_np(flip_image(pil_img), 28, 28)\n\n        # add to the original dataset\n        X_train_new = np.append(X_train_new, rotated.reshape(1, 784), axis = 0)\n        X_train_new = np.append(X_train_new, flipped.reshape(1, 784), axis = 0)\n        y_train_new = np.append(y_train_new, y_train[i].reshape(1,1), axis = 0)\n        y_train_new = np.append(y_train_new, y_train[i].reshape(1,1), axis = 0)\n\n        # print out progress\n        if i % 1000 == 0:\n            print(\"Processed {i} files out of {total}.\".format(i= i, total = X_train.shape[0]))\n\n    return X_train_new, y_train_new","39fcd0a6":"# examples of flipped and rotated images\nfig, axs = plt.subplots(1,3, figsize=(6,3))\n\nnp_img = X[0]\nnp_img_flipped = convert_to_np(flip_image(convert_to_PIL_from_np(np_img)), 28, 28)\nnp_img_rotated = convert_to_np(rotate_image(convert_to_PIL_from_np(np_img)), 28, 28)\n\n# plot the original image\naxs[0].set_title('original image')\naxs[0].imshow(np_img.reshape(28, 28).squeeze())\naxs[0].axis('off')\n\n# plot the flipped image\naxs[1].set_title('flipped image')\naxs[1].imshow(np_img_flipped.reshape(28, 28).squeeze())\naxs[1].axis('off')\n\n# plot the rotated image\naxs[2].set_title('rotated image')\naxs[2].imshow(np_img_rotated.reshape(28, 28).squeeze())\naxs[2].axis('off')","73fad247":"X_train, y_train = add_flipped_and_rotated_images(X_train, y_train)","c0408996":"train = torch.from_numpy(X_train).float()\nlabels = torch.from_numpy(y_train).long()\n\n# Fit model\ntrain_acc, test_acc = plot_learning_curve(input_size, output_size, hidden_sizes, train, labels, y_train, test, y_test, learning_rate = learning_rate, dropout = dropout, weight_decay = weight_decay, n_chunks = 400, optimizer = optimizer)","5c271657":"# Plot curve\nx = np.arange(10, 10 * (len(train_acc) + 1), 10)\nplt.plot(x, train_acc)\nplt.plot(x, test_acc)\nplt.legend(['train', 'test'], loc='upper left')\nplt.title('Accuracy, learning_rate = ' + str(learning_rate), fontsize=14)\nplt.xlabel('Number of epochs', fontsize=11)\nplt.ylabel('Accuracy', fontsize=11)\nplt.show()","deac6dd2":"# Fit model\ntrain_acc, test_acc = plot_learning_curve(input_size, output_size, hidden_sizes, train, labels, y_train, test, y_test, learning_rate = learning_rate, dropout = 0.2, weight_decay = weight_decay, n_chunks = 400, \\\n                                          optimizer = 'Adam')","4553734d":"# Plot curve\nx = np.arange(10, 10 * (len(train_acc) + 1), 10)\nplt.plot(x, train_acc)\nplt.plot(x, test_acc)\nplt.legend(['train', 'test'], loc='upper left')\nplt.title('Accuracy, learning_rate = ' + str(learning_rate), fontsize=14)\nplt.xlabel('Number of epochs', fontsize=11)\nplt.ylabel('Accuracy', fontsize=11)\nplt.show()","2d5224be":"# turn off batch normalization\nmodel.eval()\n\n# get prediction for the image from the test dataset\ntest_model(model, test[45])","78ad9688":"## MODELLING","6bd9f897":"I am going to load the simplified data for 10 classes:","5d1d27be":"The heatmaps demonstrated on visualizations above, in fact, represent the generalized idea of each class. Looking at the heatmaps, we can make a lot of interesting observations:\n* People who play the game give the star a five-pointed representation.\n* People who play the game represent nail as a metal spike (not as a body part).\n* Game players generally draw the sword pointed upwards.","557d04ac":"## DEFINITION\n\n### Overview\nThe [Quick Draw](https:\/\/github.com\/googlecreativelab\/quickdraw-dataset) Dataset is a collection of 50 million drawings across 345 categories, contributed by players of the game [Quick, Draw!](https:\/\/quickdraw.withgoogle.com\/). The player starts with an object to draw (for example it may say \"Draw a chair in under 20 seconds\"). Then the player has twenty seconds to draw that object. Based on what they draw, the AI guesses what they are drawing.\nResearch in recognition of images drawn by humans can improve pattern recognition solutions more broadly. Improving pattern recognition has an impact on handwriting recognition and its robust applications in areas including OCR (Optical Character Recognition), ASR (Automatic Speech Recognition) & NLP (Natural Language Processing).\n__In this kernel I analyzed the drawings and tried to build a deep learning application to classify those drawings__ (in this [GitHub repository](https:\/\/github.com\/Lexie88rus\/quick-draw-image-recognition) you can find the code for the resulting web application to play around with the model).\n\n### Problem Statement\n\nRecognition of a drawing is a classification problem. I have to build a solution, which classifies input images. I split the whole problem of recognition of drawings into the following tasks:\n* Input data analysis and preprocessing;\n* Building a model to classify drawings;\n* Evaluation of the model concerning chosen metrics;\n* Building a web-application to demonstrate the results.\n\nI am new to deep learning, so I simplified this task to only ten classes from the dataset. I will also shrink the input images to 28x28 pixels in order to be able to use simple fully connected network to classify the images.\n\n### Metrics\n\nI chose accuracy as a metric to evaluate the results. Because of the rules of the game, we mostly care about how many times did the AI recognize the drawing correctly, and this is just the accuracy of the model.","b6f9fc46":"### Explore and Preprocess Data","344a5bd9":"The example of the output from the resulting model:","8a63ca0f":"Let's plot the accuracy with respect to the number of epochs:","06a67622":"I want to work with a simplified representation of images. I will shrink initial images to 28x28 grayscale images. For image manipulation I am going to use utility functions described below. ","eaefc7a3":"Let's try to fit the model using new dataset with generated images:","a255fa10":"We see that introducing dropout to the model actually helped to reduce the gap between train and test accuracy scores. But we still have to work on the regularization of the model, because we have poor test accuracy. The easiest thing, which I didn't do in this tutorial (to reduce the computation time) is to add more data to the training set (images from the original dataset or some generated data), and to make more training epochs.","8f7564bc":"### Load Data","13cf411f":"Let's try out the model:","c10a44cd":"Since there is a lot of data, and I can even generate additional data by flipping and rotating the images, I decided to use deep learning approaches to classify drawings.\n<br>I started with a simple fully connected neural network with two hidden layers built with the PyTorch library.\nThe sizes of the layers are as follows:\n* Input layer: 784 (for 28 x 28 images),\n* Hidden layer 1: 128,\n* Hidden layer 2: 100,\n* Output layer: 10 (the number of classes).\n\nFor each hidden layer there is:\n* ReLU activation function,\n* Batch normalization.\n\nThe resulting model has hyperparameters as follows:\n* Learning rate,\n* Dropout for hidden layers,\n* Weight decay (L2 regularization),\n* Optimizer: Adam or SGD.","573b8d55":"## INPUT DATA","e1c509f3":"The plot above shows us that even adding generated data can help to reduce bias and variance.","08352e15":"Looking at the plot above we can say that we have model variance problem. On the training set we achieved 99% accuracy, which means that we fitted the training set quite well. But there is also a huge gap between training and test accuracy, which means that there is a variance problem, and we actually overfitted for the training dataset and fail to predict on the test set.\n<br>Variance problem can be addressed by increasing the training set. We have two options: get more images from the original dataset or generate more images from existing ones by flipping and rotating.\n<br>I will try the second option just to demonstrate how generation more data out of the existing works.","72fd6fa3":"# Getting Started with Deep Learning and PyTorch for Quick, Draw! Doodles Recognition","ade2d466":"![header image](https:\/\/github.com\/Lexie88rus\/quick-draw-image-recognition\/blob\/master\/app\/static\/jumbotron.png?raw=true)","ec61fc29":"### Improvement\nThe model performs quite well on ten image classes from the simplified dataset, but there is a lot to improve:\n* Add more drawing classes;\n* Try other architectures, such as convolutional neural networks;\n* Try the full dataset, which contains images with higher resolution and additional information (country, strokes and so on).","ae13cfbb":"## CONCLUSION","ea3ba64b":"I will demonstrate example of flipped and rotated images:","b2f168fb":"I still see huge gap between train and test accuracy scores. It means that we have to implement some regularizations techniques to reduce the variance. In current case it turns out that L2 regularization (weight decay) doesn't work out. But adding dropout to each hidden layer will help a little. I also added Adam optimizer to speed up the calculations.","73bc40ec":"Preview some random examples of the images from the dataset:","c32a8104":"Shrink the images and create datasets with images and labels:","c172f781":"In this kernel I demonstrated an example how to build simple fully connected neural network to classify simple images. While building the solution we used the original data and artificially generated data and introduced regularization techniques such as dropout to reduce variance of the model. The final model has the accuracy about 80% (this can be improved by adding more data and using more epochs while training, I didn't do that to reduce the running time of the kernel).","a1601b47":"It is also interesting to view the \"heatmaps\" for images for one category. The \"heatmaps\" are generalized representations of images coming from one category. \"Heatmaps\" are created out of mean values for pixels for all images from one category:"}}