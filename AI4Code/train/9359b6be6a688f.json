{"cell_type":{"25042463":"code","c8834f58":"code","d500c74f":"code","6866f513":"code","278c68ff":"code","e0a7451c":"code","14df227a":"code","063aac68":"code","56c9c803":"code","829a918f":"code","85033fdf":"code","ac036f57":"code","bf82a271":"code","de981f15":"code","44ebb851":"code","40cfd4e6":"code","f5dba855":"code","1f60ac4f":"code","7e6d6872":"code","f7915d35":"code","95a7e119":"code","0e84dfee":"code","695a783e":"code","7d75c9b4":"code","be31216c":"code","e6c73880":"code","7a5b7e6e":"code","efb08c1d":"code","49376759":"code","6a54c8f5":"code","0f353f41":"code","29ab8cbd":"code","dca01f5d":"code","da2ed311":"code","a114f37f":"code","a7db4166":"code","5ef18e2e":"code","95df668d":"code","8202f90a":"code","86f56205":"code","334076db":"markdown","0e240e98":"markdown","f9607c54":"markdown","b5e44869":"markdown","ce3f039f":"markdown","a1ed324e":"markdown","6ec0a3f4":"markdown","612fa6f5":"markdown","ad779fb5":"markdown","d181ff94":"markdown","0891cd28":"markdown","4011c290":"markdown","b6896fdd":"markdown","fb5ca2b3":"markdown","c8fe5a0f":"markdown","33bc3373":"markdown","fa2112b1":"markdown","6fb7118e":"markdown","d7edb47f":"markdown","f8b88cc3":"markdown","1777bc40":"markdown","b543b461":"markdown","b76854e1":"markdown","c417c1f8":"markdown","78620724":"markdown","9df6a8c5":"markdown","785bf227":"markdown","a9864681":"markdown","bb443fa2":"markdown","50123416":"markdown","7864810b":"markdown","168d45ef":"markdown","e10a4849":"markdown","1f695026":"markdown","58ec0eda":"markdown","6131610d":"markdown","b7b5cb6a":"markdown","e8068515":"markdown","91e0e7f8":"markdown","b25b8c7c":"markdown","606c8d8e":"markdown","d43fa966":"markdown","894f9897":"markdown","860b2261":"markdown","27111a13":"markdown","b562916c":"markdown"},"source":{"25042463":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline","c8834f58":"wine = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","d500c74f":"#Let's check how the data is distributed\nwine.head()","6866f513":"wine.info()","278c68ff":"sns.countplot(x='quality',data=wine)","e0a7451c":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='fixed acidity', data=wine)","14df227a":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='volatile acidity', data=wine)","063aac68":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='citric acid', data=wine)","56c9c803":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='residual sugar', data=wine)","829a918f":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='chlorides', data=wine)","85033fdf":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='free sulfur dioxide', data=wine)","ac036f57":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='total sulfur dioxide', data=wine)","bf82a271":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='sulphates', data=wine)","de981f15":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='alcohol', data=wine)","44ebb851":"reviews = []\nfor i in wine['quality']:\n    if i >= 1 and i <= 3:\n        reviews.append('1')\n    elif i >= 4 and i <= 7:\n        reviews.append('2')\n    elif i >= 8 and i <= 10:\n        reviews.append('3')\nwine['Reviews'] = reviews","40cfd4e6":"wine.columns","f5dba855":"wine['Reviews'].unique()","1f60ac4f":"Counter(wine['Reviews'])","7e6d6872":"X = wine.iloc[:,:11]\ny = wine['Reviews']","f7915d35":"X.head()","95a7e119":"y.head()","0e84dfee":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","695a783e":"print(X)","7d75c9b4":"from sklearn.decomposition import PCA\npca = PCA()\nX_pca = pca.fit_transform(X)","be31216c":"plt.figure(figsize=(5,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\nplt.grid()","e6c73880":"#As per the graph, we can see that 8 principal components attribute for 90% of variation in the data. \n#we shall pick the first 8 components for our prediction.\npca_new = PCA(n_components=8)\nX_new = pca_new.fit_transform(X)","7a5b7e6e":"print(X_new)","efb08c1d":"X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25)","49376759":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","6a54c8f5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)","0f353f41":"# print confusion matrix and accuracy score\nlr_confusion_matrix = confusion_matrix(y_test, lr_predict)\nlr_accuracy_score = accuracy_score(y_test, lr_predict)\nprint(lr_confusion_matrix)\nprint(lr_accuracy_score*100)","29ab8cbd":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ndt_predict = dt.predict(X_test)","dca01f5d":"#print confusion matrix and accuracy score\ndt_confusion_matrix = confusion_matrix(y_test, dt_predict)\ndt_accuracy_score = accuracy_score(y_test, dt_predict)\nprint(dt_confusion_matrix)\nprint(dt_accuracy_score*100)","da2ed311":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nnb_predict = nb.predict(X_test)","a114f37f":"#print confusion matrix and accuracy score\nnb_confusion_matrix = confusion_matrix(y_test, nb_predict)\nnb_accuracy_score = accuracy_score(y_test, nb_predict)\nprint(nb_confusion_matrix)\nprint(nb_accuracy_score*100)","a7db4166":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_predict = rf.predict(X_test)","5ef18e2e":"# print confusion matrix and accuracy score\nrf_confusion_matrix = confusion_matrix(y_test, rf_predict)\nrf_accuracy_score = accuracy_score(y_test, rf_predict)\nprint(rf_confusion_matrix)\nprint(rf_accuracy_score*100)","95df668d":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nsvc_predict = svc.predict(X_test)","8202f90a":"#print confusion matrix and accuracy score\nsvc_confusion_matrix = confusion_matrix(y_test, rf_predict)\nsvc_accuracy_score = accuracy_score(y_test, rf_predict)\nprint(svc_confusion_matrix)\nprint(svc_accuracy_score*100)","86f56205":"wine1 = [[7.8, 0.760, 0.04, 2.3, 0.092, 15.0, 54.0, 0.99700]]\nprint(\"Decision Tree : \",dt.predict(wine1))\nprint(\"Logistic Regression : \",lr.predict(wine1))\nprint(\"Naive Bayes : \",nb.predict(wine1))\nprint(\"Random forest : \",rf.predict(wine1))\nprint(\"SVM : \",svc.predict(wine1))","334076db":"Here, we see that `fixed acidity` does not give any specification to classify the `quality`.","0e240e98":"**Problem Statement : ** Predicting red wine quality using various features of red wine.\n\n**Solution to the problem : **\n\n1. [Import Libraries](#1)\n2. [Load Data](#2)\n    * [Checking the information about each data column](#3)     \n3. [Data Visualuzation](#4)\n    * [Barplot between `quality` and `fixed acidity`](#5)\n    * [Barplot between `quality` and `volatile acidity`](#6)\n    * [Barpolt between `quality` and `citric acid`](#7)\n    * [Barplot between `quality` and `residual sugar`](#8)\n    * [Barplot between `quality` and `chlorides`](#9)\n    * [Barplot between `quality` and `free sulfur dioxide`](#10)\n    * [Barplot between `quality` and `total sulfur dioxide`](#11)\n    * [Barplot between `quality` and `sulphates`](#12)\n    * [Barplot between `quality` and `alcohol`](#13)\n    * [Conclusion by visualization](#14)\n4. [Data Preprocessing](#15)\n    * [Creating new column `review`](#16)\n    * [Checking unique values for column `review`](#17)\n    * [Scaling the data using StandardScaler for PCA](#18)\n    * [Viewing the data using StandardScaler](#19)\n    * [Proceed to perform PCA](#20)\n    * [Ploting the graph to find the principal components](#21)\n5. [Splitting data into Train and Test](#22)\n    * [Checking for shape of splitted data](#23)\n6. [Data Modelling](#24)\n    * [Logistic Regression](#25)\n    * [Decision Trees](#26)\n    * [Naive Bayes](#27)\n    * [Random Forests](#28)\n    * [SVM](#29) \n    * [Accuracy for different algorithms](#30)","f9607c54":"Here, we see the increasing trend of `citric acid`. That is, as we go higher in `quality` of wine the composition of `citric acid` in wine also increases.","b5e44869":"### Naive Bayes<a id=\"27\"><\/a>","ce3f039f":"## 3. Data Visualization<a id=\"4\"><\/a>\nNow, I am going to visualize this data to see how the data is distributed.","a1ed324e":"## 1. Import Libraries<a id=\"1\"><\/a>","6ec0a3f4":"Here, we see that it's quite a downing trend in the `volatile acidity` as we go higher the `quality`.","612fa6f5":"## 6. Data Modelling<a id=\"24\"><\/a>\nWe will use the following algorithms ==>\n1. Logistic Regression\n2. Decision Trees\n3. Naive Bayes\n4. Random Forests\n5. SVM","ad779fb5":"### Barplot between `quality` and `chlorides`<a id=\"9\"><\/a>","d181ff94":"### Barplot between `quality` and `fixed acidity`<a id=\"5\"><\/a>","0891cd28":"### Barpolt between `quality` and `citric acid`<a id=\"7\"><\/a>","4011c290":"### Barplot between `quality` and `residual sugar`<a id=\"8\"><\/a>","b6896fdd":"Both the `free sulphur dioxide` and `total sulphur dioxide` are comparatively more in the 5th and 6th `quality` wine.","fb5ca2b3":"# Let's check your red wine quality...\nWe have given various features (like fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol) which will help us in predicting the quality of wine.\n\n<img src = \"https:\/\/www.calaiswine.co.uk\/wp\/wp-content\/uploads\/2015\/12\/wine-gif-2.gif\" width=500px >","c8fe5a0f":"Well, there is no significant effect of `residual sugar` on `quality` of wine.","33bc3373":"Ohh yeah, here we the the increasing trend of `sulphates` as we go higher in `quality` of wine.","fa2112b1":"### Barplot between `quality` and `total sulfur dioxide`<a id=\"11\"><\/a>","6fb7118e":"### Barplot between `quality` and `volatile acidity`<a id=\"6\"><\/a>","d7edb47f":"Here, is also a increasing trend found between `quality` and `alcohol`.","f8b88cc3":"97.75% accuracy with Naive Bayes.","1777bc40":"### Checking unique values for column `review`<a id=\"17\"><\/a>","b543b461":"### Support Vector Machine (SVM)<a id=\"29\"><\/a>","b76854e1":"### Decision Tree<a id=\"26\"><\/a>","c417c1f8":"#### Accuracy for different algorithms:<a id=\"30\"><\/a>\n\n* Logistic Regression = 98.5% accuracy  \n* Decision Trees = 97% accuracy\n* Naive Bayes = 97.75% accuracy\n* Random Forest = 98.25% accuracy\n* SVM = 98.25% accuracy","78620724":"98.5% accuracy with Logistic Regression! Let's see of Decision Trees give us a better accuracy.","9df6a8c5":"### Proceed to perform PCA<a id=\"20\"><\/a>","785bf227":"### Checking for shape of splitted data<a id=\"23\"><\/a>","a9864681":"97% accuracy with Decision Tree! Let's use NaiveBayes","bb443fa2":"98.25% accuracy with Random forest.","50123416":"### Barplot between `quality` and `free sulfur dioxide`<a id=\"10\"><\/a>","7864810b":"### Checking the information about each data column<a id=\"3\"><\/a>","168d45ef":"## 4. Data Preprocessing<a id=\"15\"><\/a>","e10a4849":">Now, we will create a new column called review. This column will contain the values of 1, 2 and 3 and will be split in the following way.\n* review ==> quality ==> meaning\n* 1 ==> 1, 2, 3 ==>Bad\n* 2 ==> 4, 5, 6, 7 ==> Average\n* 3 ==> 8, 9, 10 ==> Excellent","1f695026":"### Scaling the data using StandardScaler for PCA<a id=\"18\"><\/a>","58ec0eda":"### Ploting the graph to find the principal components<a id=\"21\"><\/a>","6131610d":"### Viewing the data using StandardScaler<a id=\"19\"><\/a>","b7b5cb6a":"## 2. Load Data <a id=\"2\"><\/a>","e8068515":"### Barplot between `quality` and `alcohol`<a id=\"13\"><\/a>","91e0e7f8":"### Barplot between `quality` and `sulphates`<a id=\"12\"><\/a>","b25b8c7c":"### Overall conclusion by examining data.<a id=\"14\"><\/a>\nSome features have great impact on `quality` of wine and some does not have any sigificant effect in the `quality`.\n\n**Trends**\n1. fixed acidity : No significant effect\n2. volatile acidity : Decreasing\n3. citric acid : Increasing\n4. residual sugar : No significant effect\n5. chlorides : Decreasing\n6. free sulphur dioxide : No significant effect\n7. total sulphur dioxide : No significant effect\n8. sulphates : Increasing\n9. alcohol : Increasing","606c8d8e":"Well, Naive Bayes did wrong prediction! Therefore, in this way we can predict the quality of red wine using **Logistic regression** because it gives highest accuracy.","d43fa966":"Here, we see the decreasing trend of `chlorides` with the increase in the `quality` of wine.","894f9897":"### Logistic Regression<a id=\"25\"><\/a>","860b2261":"### Random Forest Classifier<a id=\"28\"><\/a>","27111a13":"## 5. Splitting the dataset into train and test data.<a id=\"22\"><\/a>","b562916c":"### Creating new column `review`<a id=\"16\"><\/a>"}}