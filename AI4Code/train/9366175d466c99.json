{"cell_type":{"592a0c94":"code","7638600f":"code","bafba33c":"code","6b14badc":"code","8a170361":"code","3112d4c4":"code","c257f430":"code","54e761bf":"code","4289c91c":"code","bd95afc8":"code","5aeca7cf":"code","7ca5a323":"code","dadbde21":"code","66b0e907":"code","e326a78e":"code","ea8078fe":"code","faeaacdf":"code","4b5179c6":"code","10cf5c0a":"code","ec0b69ff":"code","4669eca8":"code","2ddf26de":"code","7b751d67":"code","a7827640":"code","03939ad7":"code","8ef917e1":"code","5f362fd2":"code","32ee852c":"code","3ae4d4b7":"code","20dc2cd2":"code","0c9c8cdc":"markdown","c9bb60ab":"markdown","23dfc7f2":"markdown","976db06b":"markdown","719a8f52":"markdown","1f23e81e":"markdown","f5f4fbf4":"markdown","16e6d99d":"markdown","f49428ba":"markdown","72abef90":"markdown","049b8d93":"markdown","d79dcc50":"markdown","e6dcd686":"markdown","e637d6ac":"markdown","50f1d1d1":"markdown","1d0d154d":"markdown","26f38556":"markdown","22588354":"markdown","520f0068":"markdown","5247715e":"markdown","9edcc165":"markdown","548f7204":"markdown","63f9c592":"markdown","44c9d121":"markdown","b79a14d8":"markdown","1947ee65":"markdown","e1db4540":"markdown","ed244c21":"markdown"},"source":{"592a0c94":"seed_random = 42\nwindow_sizes = [10, 50]","7638600f":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression, Ridge, SGDRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, f1_score, mean_absolute_error, make_scorer\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom pykalman import KalmanFilter\nfrom functools import partial\nimport scipy as sp\nimport time\nimport datetime\nimport gc\nfrom sklearn.tree import DecisionTreeClassifier\nimport shap","bafba33c":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        if col != 'time':\n            col_type = df[col].dtypes\n            if col_type in numerics:\n                c_min = df[col].min()\n                c_max = df[col].max()\n                if str(col_type)[:3] == 'int':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)  \n                else:\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        df[col] = df[col].astype(np.float16)\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","6b14badc":"train = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/test.csv')\n","8a170361":"%%time\nfor window in window_sizes:\n    train[\"rolling_mean_\" + str(window)] = train['signal'].rolling(window=window).mean()\n    train[\"rolling_std_\" + str(window)] = train['signal'].rolling(window=window).std()\n    train[\"rolling_var_\" + str(window)] = train['signal'].rolling(window=window).var()\n    train[\"rolling_min_\" + str(window)] = train['signal'].rolling(window=window).min()\n    train[\"rolling_max_\" + str(window)] = train['signal'].rolling(window=window).max()\n    \n    #train[\"rolling_min_max_ratio_\" + str(window)] = train[\"rolling_min_\" + str(window)] \/ train[\"rolling_max_\" + str(window)]\n    #train[\"rolling_min_max_diff_\" + str(window)] = train[\"rolling_max_\" + str(window)] - train[\"rolling_min_\" + str(window)]\n    \n    a = (train['signal'] - train['rolling_min_' + str(window)]) \/ (train['rolling_max_' + str(window)] - train['rolling_min_' + str(window)])\n    train[\"norm_\" + str(window)] = a * (np.floor(train['rolling_max_' + str(window)]) - np.ceil(train['rolling_min_' + str(window)]))\n    \ntrain = train.replace([np.inf, -np.inf], np.nan)    \ntrain.fillna(0, inplace=True)","3112d4c4":"%%time\nfor window in window_sizes:\n    test[\"rolling_mean_\" + str(window)] = test['signal'].rolling(window=window).mean()\n    test[\"rolling_std_\" + str(window)] = test['signal'].rolling(window=window).std()\n    test[\"rolling_var_\" + str(window)] = test['signal'].rolling(window=window).var()\n    test[\"rolling_min_\" + str(window)] = test['signal'].rolling(window=window).min()\n    test[\"rolling_max_\" + str(window)] = test['signal'].rolling(window=window).max()\n    \n    #test[\"rolling_min_max_ratio_\" + str(window)] = test[\"rolling_min_\" + str(window)] \/ test[\"rolling_max_\" + str(window)]\n    #test[\"rolling_min_max_diff_\" + str(window)] = test[\"rolling_max_\" + str(window)] - test[\"rolling_min_\" + str(window)]\n\n    \n    a = (test['signal'] - test['rolling_min_' + str(window)]) \/ (test['rolling_max_' + str(window)] - test['rolling_min_' + str(window)])\n    test[\"norm_\" + str(window)] = a * (np.floor(test['rolling_max_' + str(window)]) - np.ceil(test['rolling_min_' + str(window)]))\n\ntest = test.replace([np.inf, -np.inf], np.nan)    \ntest.fillna(0, inplace=True)","c257f430":"%%time\ndef features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index \/\/ 25_000\n    df['batch_index'] = df.index  - (df.batch * 25_000)\n    df['batch_slices'] = df['batch_index']  \/\/ 2500\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['median'+c] = df.groupby([c])['signal'].median()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        d['range'+c] = d['max'+c] - d['min'+c]\n        d['maxtomin'+c] = d['max'+c] \/ d['min'+c]\n        d['abs_avg'+c] = (d['abs_min'+c] + d['abs_max'+c]) \/ 2\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n\n    \n    # add shifts_1\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n    \n    # add shifts_2 - my upgrade\n    df['signal_shift_+2'] = [0,] + [1,] + list(df['signal'].values[:-2])\n    df['signal_shift_-2'] = list(df['signal'].values[2:]) + [0] + [1]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+2'][i] = np.nan\n    for i in df[df['batch_index']==1].index:\n        df['signal_shift_+2'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-2'][i] = np.nan\n    for i in df[df['batch_index']==49998].index:\n        df['signal_shift_-2'][i] = np.nan\n    \n    df = df.drop(columns=['batch', 'batch_index', 'batch_slices', 'batch_slices2'])\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n    gc.collect()\n    return df\n\ntrain = features(train)\ntest = features(test)","54e761bf":"train = reduce_mem_usage(train)","4289c91c":"test = reduce_mem_usage(test)","bd95afc8":"y = train['open_channels']\ncol = [c for c in train.columns if c not in ['time', 'open_channels', 'group', 'medianbatch', 'abs_avgbatch', 'abs_maxbatch']]","5aeca7cf":"train.head()","7ca5a323":"# Thanks to https:\/\/www.kaggle.com\/siavrez\/simple-eda-model\ndef MacroF1Metric(preds, dtrain):\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average = 'macro')\n    return ('MacroF1Metric', score, True)","dadbde21":"%%time\n# Thanks to https:\/\/www.kaggle.com\/jazivxt\/physically-possible with tuning from https:\/\/www.kaggle.com\/siavrez\/simple-eda-model and my tuning\nX_train, X_valid, y_train, y_valid = train_test_split(train[col], y, test_size=0.01, random_state=seed_random)\n\nmodel=lgb.LGBMClassifier(n_estimators=10)\nmodel.fit(X_train,y_train)","66b0e907":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(model,ax = axes,height = 0.5,importance_type='split')\nplt.show();plt.close()\ngc.collect()","e326a78e":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(model,ax = axes,height = 0.5,importance_type='gain')\nplt.show();plt.close()\ngc.collect()","ea8078fe":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model, random_state=1).fit(X_valid, y_valid)\n\n","faeaacdf":"eli5.show_weights(perm, feature_names = X_valid.columns.tolist(), top=150)\n","4b5179c6":"features=X_valid.columns.tolist()\ntree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(X_train, y_train)\n","10cf5c0a":"from sklearn import tree\nimport graphviz\ntree_graph = tree.export_graphviz(tree_model, out_file=None, feature_names=features)\n","ec0b69ff":"graphviz.Source(tree_graph)","4669eca8":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\n# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=tree_model, dataset=X_valid.iloc[:10000], model_features=features, feature='minbatch_msignal')\n\n# plot it\npdp.pdp_plot(pdp_goals, 'minbatch_msignal')\nplt.show()","2ddf26de":"pdp.pdp_plot(pdp_goals, 'stdbatch')\nplt.show()","7b751d67":"features_to_plot = ['minbatch_msignal', 'stdbatch']\ninter1  =  pdp.pdp_interact(model=tree_model, dataset=X_valid.iloc[:10000], model_features=features, features=features_to_plot,)\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour',which_classes=[0,1])\nplt.show()\n","a7827640":"\nexplainer = shap.TreeExplainer(model)\nshap_values=explainer.shap_values(X_valid)\n","03939ad7":"shap.summary_plot(shap_values, X_valid)","8ef917e1":"row_to_show = 1\ndata_for_prediction = X_valid.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\n","5f362fd2":"shap_values = explainer.shap_values(data_for_prediction_array)\n","32ee852c":"shap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[1], data_for_prediction)\n","3ae4d4b7":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)\n","20dc2cd2":"shap_values=explainer.shap_values(X_valid)\nfor name in ['minbatch_msignal',\"stdbatch\",\"rangebatch\"]:\n    shap.dependence_plot(name,shap_values[1],X_valid)","0c9c8cdc":"## Individual SHAP Value Plot \u2014 Local Interpretability\n You can visualize feature attributions such as Shapley values as \u201cforces\u201d. Each feature value is a force that either increases or decreases the prediction. The prediction starts from the baseline. The baseline for Shapley values is the average of all predictions. In the plot, each Shapley value is an arrow that pushes to increase (positive value) or decrease (negative value) the prediction. These forces balance each other out at the actual prediction of the data instance.","c9bb60ab":"## SHAP Summary Plot\nThe summary plot combines feature importance with feature effects. Each point on the summary plot is a Shapley value for a feature and an instance. The position on the y-axis is determined by the feature and on the x-axis by the Shapley value. The color represents the value of the feature from low to high. Overlapping points are jittered in y-axis direction, so we get a sense of the distribution of the Shapley values per feature. The features are ordered according to their importance","23dfc7f2":"## <font size='3' color='red'>SHAP dependence plot<\/font>","976db06b":"Here you can see that how each feature has affected the prediction of each class.","719a8f52":"We will plot this for some of the important features","1f23e81e":"<font size='5' color='red'>If you like this notebook,please consider leaving an upvote \u2b06\ufe0f <font size='3' color='blue'>Thank you<\/font> ","f5f4fbf4":"Before we get into using external packages for interpreting our model,we can first take a look into `feature importances`.\nBut we always do a mistake using default feature_importance function.We only consider the default importace_type and judge the model.There are 2 importance_type for lgb tree models.\n- `split`: Number of times a feature was used to split nodes in the tree.\n- `gain` : The information gain from the feature.\n\nfirst we will check split importance_type","16e6d99d":"For class 1","f49428ba":"### FE-2 - thanks to the kernels:\n* https:\/\/www.kaggle.com\/teejmahal20\/regression-with-optimized-rounder\n* https:\/\/www.kaggle.com\/pestipeti\/eda-ion-switching","72abef90":"### FE-3 - thanks to \n* https:\/\/www.kaggle.com\/jazivxt\/physically-possible\n* https:\/\/www.kaggle.com\/siavrez\/simple-eda-model","049b8d93":"## <font size='3' color='blue'> Loading required packages<\/font>","d79dcc50":"\n\nAs guidance to read the tree:\n\n   - Leaves with children show their splitting criterion on the top\n   - The pair of values at the bottom show the count of False values and True values for the target respectively, of data points in that node of the tree.\n\nNext,we will plot the partial dependency plot.\nUsing PD we can answer **how a selected variable affects the prediction?**","e6dcd686":"Here you can see how these variables interact and affects the prediction.\n\n\n\n\n## <font size='4' color='green'>SHAP Values<\/font>\n\nSHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations (see the SHAP NIPS paper for details).\n\n![](https:\/\/raw.githubusercontent.com\/slundberg\/shap\/master\/docs\/artwork\/shap_diagram.png)\n\nBy using shapely we can understand **how model works for individual predictions?**","e637d6ac":"Let's check the PD plot of `stdbatch` feature","50f1d1d1":"## <font size='5' color='blue'>Introduction<\/font>\n\n![](https:\/\/blogs.sas.com\/content\/subconsciousmusings\/files\/2018\/06\/blackboxmodels.png)\n\n\nThrough this notebook I want to explore the and extract insights from models and try to answer some of the below questions\n1. Which are the common approches and tools used for Interpreting ML models?\n2. Which are the most important features that affect our prediction?\n3. How these features affect the target?\n4. What insights can we extract  from models?\n5. How to interpret predictions of single sample?","1d0d154d":"## <font size='4' color='blue'>Feature Engineering<\/font>\nBelow I have  the most common features used in some of the kernels by excellent kagglers.I really appreciate their efforts and thank them for making it public.","26f38556":"## <font size='4' color='brown'>Partial dependancy plots.<\/font>\n\n\nA partial dependence (PD) plot depicts the functional relationship between a small number of input variables and predictions. They show how the predictions partially depend on values of the input variables of interest.","22588354":"##  <font size='4' color='blue'>Two variable interaction plot<\/font>\n\nPD plots look at the variable of interest across a specified range. At each value of the variable, the model is evaluated for all observations of the other model inputs, and the output is then averaged. Thus, the relationship they depict is only valid if the variable of interest does not interact strongly with other model inputs.\n\nSince variable interactions are common in actual practice, you can use higher-order (such as two-way) partial dependence plots to check for interactions among specific model variables.\n\nNow we will check the interaction between the variables `miibatch_msignal` and `stdbatch`.\n\nUsing intercation plot can help us find our **how interaction between these variables affects the prediction?**","520f0068":"\n\nA few items are worth pointing out as you interpret this plot\n\n- The y axis is interpreted as change in the prediction from what it would be predicted at the baseline or leftmost value.\n- A blue shaded area indicates level of confidence\n \n \nFrom this particular graph,the first image shows that the probability of predicting the sample to class 0 increasing as the `minbatch_msginal` increases from -4 to 0.","5247715e":"Here the features on the left (red) moves the prediction away from the average and the features on the right (blue) moves the prediction towards the average.","9edcc165":"##  <font size='4' color='red'> Permutation Importance<\/font>\n\nIn this section we will answer following question:\n\n1. What features have the biggest impact on predictions?\n2. how to extract insights from models?\n","548f7204":"SHAP dependence plots show the effect of a single feature across the whole dataset. They plot a feature's value vs. the SHAP value of that feature across many samples. SHAP dependence plots are similar to partial dependence plots, but account for the interaction effects present in the features, and are only defined in regions of the input space supported by data. The vertical dispersion of SHAP values at a single feature value is driven by interaction effects, and another feature is chosen for coloring to highlight possible interaction","63f9c592":"<font size='5' color='red'>If you like this notebook,please consider leaving an upvote \u2b06\ufe0f<\/font>","44c9d121":"## <font size='4' color='green'> Feature importances<\/font>","b79a14d8":"We can see that the feature `minibatch_msignal` is the most used feature inorder to split the nodes in the tree.We will do further inspection about this feature later.Next we will plot the `gain` from each feature.","1947ee65":"For class 0","e1db4540":"## <font size='4' color='blue'> Build Model<\/font>\n\nRemember building a fine model is not our focus in this notebook,so we will use the default settings and make a LGB Classifier model.\n","ed244c21":" What can be inferred from the above?\n\n 1. As you move down the top of the graph, the importance of the feature decreases.\n 2. The features that are shown in green indicate that they have a positive impact on our prediction\n 3. The features that are shown in white indicate that they have no effect on our prediction\n 4. The features shown in red indicate that they have a negative impact on our prediction\n 5. The most important feature was `minibatch_msignal`.\n"}}