{"cell_type":{"4dfa3565":"code","ca597d4f":"code","208cedad":"code","64e6bd29":"code","b383372a":"code","14032d99":"code","376502d1":"code","1d2244d5":"code","0394edbd":"code","68c2c898":"code","60f80695":"code","31f1c235":"code","d0f69576":"code","6c31039a":"code","b431047c":"code","5942b815":"code","3880489f":"code","a9b9b7a8":"code","29af6f47":"code","683432f3":"code","ad467058":"code","74c65dd4":"code","17ea4e28":"code","cbf601bb":"code","3656e479":"code","727fb1aa":"code","6a987b79":"code","acaeaf2c":"code","e5f8b5e0":"code","42f72a5c":"code","8a60f7b7":"code","5c1abffe":"code","5390a1ca":"code","e3b59988":"code","e0bf7139":"code","8cb78051":"code","b4b6a03e":"code","13696e70":"code","2b881ca4":"code","b9e708e8":"code","1eb85e15":"code","766a0a62":"code","018cb4ac":"code","db1af2e9":"code","1cd5a0ce":"code","b389fedc":"code","2c83296b":"code","51fde915":"code","0114091e":"code","1e9741d4":"code","628475b9":"code","07090492":"code","45edb272":"code","041f82db":"code","24fc16fe":"code","83ed2d4d":"code","55ddd083":"code","762f7cbf":"markdown","cb529340":"markdown","26086955":"markdown","020b8cf4":"markdown","2dd58a78":"markdown","91594ec7":"markdown","832e5d06":"markdown"},"source":{"4dfa3565":"import pandas as pd\nimport numpy as np \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = 'svg'\n%matplotlib inline\nimport warnings\nfrom sklearn.model_selection import train_test_split\nwarnings.filterwarnings('ignore')\n","ca597d4f":"#\u0421\u043d\u0430\u0447\u0430\u043b\u0430 \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u043c\u043e\u0434\u0443\u043b\u0438 \u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b #\u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445:\n# \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u043c\u043e\u0434\u0443\u043b\u0435\u0439 \u0438 \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u043e\u0432\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\nfrom catboost import CatBoostClassifier, CatBoostRegressor, Pool\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.metrics import classification_report\nfrom matplotlib import pyplot","208cedad":"TRAIN_DATASET_PATH = (\"\/kaggle\/input\/credit-default-prediction-ai-big-data\/train.csv\")\nTEST_DATASET_PATH = (\"\/kaggle\/input\/credit-default-prediction-ai-big-data\/test.csv\")","64e6bd29":"def show_distplot(feature, data, title, figsize):\n    \"\"\"\u0414\u0438\u0430\u0433\u0440\u0430\u043c\u043c\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0441\u043e \u0441\u0440\u0435\u0434\u043d\u0435\u0439, \u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439 \u0438 \u043c\u043e\u0434\u043e\u0439\"\"\"\n    \n    target_mean = round(data[feature].mean(), 2)\n    target_median = data[feature].median()\n    target_mode = data[feature].mode()[0]\n\n    plt.figure(figsize = figsize)\n\n    sns.distplot(data[feature], bins=70)\n\n    plt.axvline(x=[target_mean], label='target_mean', linestyle=':',linewidth=4, color='red')\n    plt.axvline(x=[target_median], label='target_median', linestyle='--', linewidth=4, color='green')\n    plt.axvline(x=[target_mode], label='target_mode', linestyle='-.', linewidth=4, color='orange')\n    plt.title(title)\n    plt.legend()","b383372a":"df = pd.read_csv(TRAIN_DATASET_PATH, sep=',')\ndf","14032d99":"df.loc[(df['Credit Score'] > 1000)]\n","376502d1":"class Data:\n    def __init__(self):\n        self.medians=None\n        self.mode=None\n        self.model_regr_CrSc = None\n        self.model_regr_AnIn = None\n        self.int_feature = None\n    \n    def fit(self, x):\n\n        self.medians = x[['Current Loan Amount', 'Annual Income', 'Credit Score' ]].median()\n        self.mode = x['Bankruptcies'].mode()\n    \n    def transform(self, df):\n        df['Years in current job'] = df['Years in current job'].fillna('0 years')\n        df['Months since last delinquent'] = df['Months since last delinquent'].fillna(0)\n        df['Bankruptcies'] = df.Bankruptcies.fillna(self.mode[0])\n        df.loc[df['Current Loan Amount'] == 99999999, 'Current Loan Amount'] = self.medians['Current Loan Amount']\n        \n                # \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 Annual Income \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0435\u0439\n        df['Annual_Income_isnan'] = 0\n        df.loc[df['Annual Income'].isna(), 'Annual_Income_isnan'] = 1\n        df['Annual Income'].fillna(self.medians['Annual Income'], inplace=True)\n        \n        # \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 Credit Score \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0435\u0439 \n        df['Credit_Score_isnan'] = 0\n        df.loc[df['Credit Score'].isna(), 'Credit_Score_isnan'] = 1\n        df['Credit Score'].fillna(self.medians['Credit Score'], inplace=True)\n        \n        return df\n    def fit_regr_Credit_Score(self, df):\n       #\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u043f\u043e Credit Score, \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\n        \n        df_regr = df.copy()\n        df_regr = df_regr[df_regr['Credit_Score_isnan'] == 0]\n        df_regr = df_regr.drop(['Credit Default', 'Credit_Score_isnan'], axis=1)\n        target_name_regr = 'Credit Score'\n        feature_names_regr = df_regr.columns.drop(target_name_regr).tolist()\n        feature_names_cat_regr = df_regr.select_dtypes(include=['int64', 'object']).columns.tolist()\n        \n        Xc = df_regr[feature_names_regr]\n        yc = df_regr[target_name_regr]\n\n        Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n            Xc,\n            yc,\n            shuffle=True,\n            test_size=0.3,\n            random_state=42\n        )\n        \n        train_pool = Pool(Xc_train, yc_train, cat_features=feature_names_cat_regr)\n        test_pool = Pool(Xc_test, yc_test, cat_features=feature_names_cat_regr)\n        \n        self.model_regr_CrSc = CatBoostRegressor(\n            eval_metric='R2',\n            silent=True,\n            one_hot_max_size=20,\n            early_stopping_rounds=40,\n            boosting_type='Ordered',\n            allow_writing_files=False,\n            depth=4,\n            iterations=400,\n            learning_rate=0.05,\n            l2_leaf_reg=2\n        )\n\n        self.model_regr_CrSc.fit(\n            Pool(Xc_train, yc_train, cat_features=feature_names_cat_regr),\n            eval_set=Pool(Xc_test, yc_test, cat_features=feature_names_cat_regr)\n        )\n\n        print(f'Credit Score R2: {self.model_regr_CrSc.get_best_score()}')\n        del df_regr\n        \n    def fit_regr_Annual_Income(self, df):\n        #\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u043f\u043e Annual Income, \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\n        \n        df_regr = df.copy()\n        df_regr = df_regr[df_regr['Annual_Income_isnan'] == 0]\n        df_regr = df_regr.drop(['Credit Default', 'Annual_Income_isnan'], axis=1)\n        target_name_regr = 'Annual Income'\n        feature_names_regr = df_regr.columns.drop(target_name_regr).tolist()\n        feature_names_cat_regr = df_regr.select_dtypes(include=['int64', 'object']).columns.tolist()\n        \n        Xc = df_regr[feature_names_regr]\n        yc = df_regr[target_name_regr]\n\n        Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n            Xc,\n            yc,\n            shuffle=True,\n            test_size=0.3,\n            random_state=42\n        )\n        \n        train_pool = Pool(Xc_train, yc_train, cat_features=feature_names_cat_regr)\n        test_pool = Pool(Xc_test, yc_test, cat_features=feature_names_cat_regr)\n        \n        self.model_regr_AnIn = CatBoostRegressor(\n            eval_metric='R2',\n            silent=True,\n            one_hot_max_size=20,\n            early_stopping_rounds=40,\n            boosting_type='Ordered',\n            allow_writing_files=False,\n            depth=6,\n            iterations=500,\n            learning_rate=0.4,\n            l2_leaf_reg=3.5\n        )\n\n        self.model_regr_AnIn.fit(\n            Pool(Xc_train, yc_train, cat_features=feature_names_cat_regr),\n            eval_set=Pool(Xc_test, yc_test, cat_features=feature_names_cat_regr)\n        )\n        \n        print(f'Annual Income R2: {self.model_regr_AnIn.get_best_score()}')\n        del df_regr\n    \n    def apply_regr_Credit_Score(self, df):\n        #\u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 Credit Score\n        \n        cond = (df['Credit_Score_isnan'] == 1)\n        Xc = df[cond].drop(['Credit Score', 'Credit Default', 'Credit_Score_isnan'], axis=1, errors='ignore')\n        df.loc[cond, 'Credit Score'] = self.model_regr_CrSc.predict(Xc)\n        df = df.drop(['Credit_Score_isnan'], axis=1)\n        return df\n\n    def apply_regr_Annual_Income(self, df):\n        #\u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 Annual Income\n        \n        cond = (df['Annual_Income_isnan'] == 1)\n        Xc = df[cond].drop(['Annual Income', 'Credit Default', 'Annual_Income_isnan'], axis=1, errors='ignore')\n        df.loc[cond, 'Annual Income'] = self.model_regr_AnIn.predict(Xc)\n        df = df.drop(['Annual_Income_isnan'], axis=1)\n        return df\n    \n    def features(self, df):\n        \n        # \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043f\u043e\u0434\u043e\u0437\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439\n        df = self.feature_isErrors(df)\n        # \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0430\u0433\u0435\u043d\u0435\u0440\u0435\u043d\u044b\u0435 \u0444\u0438\u0447\u0438\n        df = self.uncovered_debt(df)\n        df = self.money_for_living(df)\n        df = self.division(df)\n        df = self.division_2(df)\n        \n        df = self.money_for_living_to_year(df)\n        \n        \n        columns_to_int = ['Tax Liens', 'Bankruptcies', 'Number of Credit Problems']\n        df[columns_to_int] = df[columns_to_int].astype(int)\n        \n        return df\n\n    @staticmethod\n    def feature_isErrors(df):\n        df['isErrors'] = 0\n        df.loc[df['Years of Credit History'] > 55, 'isErrors'] = 1\n        df.loc[df['Credit Score'] > 1000, 'isErrors'] = 1\n        \n        return df\n    @staticmethod\n    def uncovered_debt(df):\n        df['uncovered debt'] = 0\n        df['uncovered debt'] = abs(df['Current Loan Amount'] - df['Current Credit Balance'])\n        return df\n    @staticmethod\n    def money_for_living(df):\n        df['money for living'] = 0\n        df['money for living'] = ((df['Annual Income'] \/ 12) - df['Monthly Debt'])\n        return df\n    @staticmethod\n    def division(df):\n        df['division_loan_to_number'] = 0\n        df['division_loan_to_number'] = df['Current Loan Amount'] \/ df['Number of Open Accounts']\n        return df\n    @staticmethod\n    def division_2(df):\n        df['division_loan_to_score'] = 0\n        df['division_loan_to_score'] = df['Current Loan Amount'] \/ df['Credit Score']\n        return df\n    @staticmethod\n    def money_for_living_to_year (df):\n        df['cout_cash'] = 0\n        df['cout_cash'] = df['Current Credit Balance'] + (df['money for living'] * 10)\n        return df\n","1d2244d5":"# TRAIN_DATASET_PATH = 'course_project_train.csv'\n# TEST_DATASET_PATH = 'course_project_test.csv'","0394edbd":"df_train_base = pd.read_csv(TRAIN_DATASET_PATH)\ndf_test_base = pd.read_csv(TEST_DATASET_PATH)","68c2c898":"df_test_base","60f80695":"\n\ndata_inst = Data()\n\n# \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\ndata_inst.fit(df_train_base)\ndf_train = data_inst.transform(df_train_base)\ndf_train = data_inst.features(df_train)\n\n# \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f Credit Score\ndata_inst.fit_regr_Credit_Score(df_train_base)\ndf_train = data_inst.apply_regr_Credit_Score(df_train_base)\n\n# \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f Annual Income\ndata_inst.fit_regr_Annual_Income(df_train_base)\ndf_train = data_inst.apply_regr_Annual_Income(df_train_base)\n\n# \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\ndf_test = data_inst.transform(df_test_base)\ndf_test = data_inst.features(df_test_base)\ndf_test = data_inst.apply_regr_Credit_Score(df_test_base)\ndf_test = data_inst.apply_regr_Annual_Income(df_test_base)\n\ntarget_name = 'Credit Default'\nfeature_names = df_train.columns.drop(target_name).tolist()\nfeature_names_num = df_train.select_dtypes(include='float64').columns.tolist()\nfeature_names_cat = df_train.select_dtypes(include=['int64', 'object']).columns.drop(target_name).tolist()","31f1c235":"from scipy.stats import shapiro, probplot, mannwhitneyu","d0f69576":"df_train.columns.drop(target_name).tolist()","6c31039a":"corr_with_target = df_train[feature_names + [target_name]].corr().iloc[:-1, -1].sort_values(ascending=False)\n\nplt.figure(figsize=(10, 8))\n\nsns.barplot(x=corr_with_target.values, y=corr_with_target.index)\n\nplt.title('Correlation with target variable')","b431047c":"credit_score_with_target = df_train[df_train['Credit Score'] < 1000][['Credit Score', target_name]]\ncredit_score = credit_score_with_target['Credit Score']\ncredit_score_target_0 = credit_score[credit_score_with_target[target_name] == 0]\ncredit_score_target_1 = credit_score[credit_score_with_target[target_name] == 1]\n\nplt.figure(figsize=(25, 3))\n\nsns.kdeplot(credit_score_target_0, shade=True, label='class 0', color='g')\nsns.kdeplot(credit_score_target_1, shade=True, label='class 1', color='r')\n\nplt.xlabel('Credit Score')\nplt.title('Credit Score grouped by target variable')","5942b815":"shapiro(credit_score)","3880489f":"plt.figure(figsize=(25, 3))\n\nax1 = plt.subplot(121)\nax1.set_xlabel('Credit Score')\nax1.set_ylabel('Count')\nax1.set_title('Credit Score distribution')\ncredit_score.hist()\n\nplt.subplot(122)\nprobplot(credit_score, dist='norm', plot=plt)","a9b9b7a8":"mannwhitneyu(credit_score_target_0, credit_score_target_1)","29af6f47":"plt.figure(figsize=(25, 5))\n\nsns.pointplot(x=target_name, y='Credit Score', data=credit_score_with_target, capsize=.1)\n\nplt.title('Confidence intervals (95 %) for Credit Score')","683432f3":"col_obj = df_train.select_dtypes(include='object').columns.to_list()\ncol_obj","ad467058":"\ncorr_matrix = df_train.corr()  # \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\ncorr_matrix = np.round(corr_matrix, 2) # \u043e\u043a\u0440\u0443\u0433\u043b\u044f\u0435\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u0434\u043e 2 \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 \u043f\u043e\u0441\u043b\u0435 \u0437\u0430\u043f\u044f\u0442\u043e\u0439\ncorr_matrix[np.abs(corr_matrix) < 0.2] = 0  # \u0437\u0430\u043d\u0443\u043b\u044f\u0435\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u043c\u0435\u043d\u044c\u0448\u0435 0,3\nsns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap='coolwarm')# annot=True - \u043f\u0440\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0438 False  \u043d\u0435 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0435\u0442 \u0446\u0438\u0444\u0440\u044b #\u0432 \u043a\u043b\u0435\u0442\u043e\u0447\u043a\u0430\u0445. cmap='coolwarm' - \u0441\u0442\u0438\u043b\u044c \u0446\u0432\u0435\u0442\u043e\u0432 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438\n\nplt.title('Correlation matrix')\nplt.show()","74c65dd4":"X = df_train[feature_names]\ny = df_train[target_name]\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X,\n    y,\n    test_size=0.25,\n    random_state=42,\n    stratify=y\n)","17ea4e28":"from sklearn.ensemble import IsolationForest\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.neighbors import LocalOutlierFactor","cbf601bb":"# outliers = LocalOutlierFactor(novelty=False, n_neighbors=10).fit_predict(X_train)\n# outliers = (outliers+1)\/\/2  #  \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u0430\u0441\u043a\u0443 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\n\n# print('% of outliers on Local Oulier Factor:', 1 - (np.sum(outliers) \/ X_train.shape[0]))  ","3656e479":"# X_train = X_train.loc[np.array(X_train.index)[outliers == 1]] # \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u043d\u0430\u0448\u0443 \u043c\u0430\u0441\u043a\u0443\n# y_train = y_train.loc[np.array(y_train.index)[outliers == 1]]","727fb1aa":"# from sklearn.linear_model import LinearRegression\n# import statsmodels.api as sm\n# from scipy import stats","6a987b79":"# est = sm.OLS(y_train, sm.add_constant(X_train))\n# est2 = est.fit()\n# print(est2.summary())","acaeaf2c":"# \u043d\u0435\u0445\u0438\u0442\u0440\u044b\u0439 \u043a\u043e\u0434 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u0434\u043b\u044f baseline, \u0432\u043e\u0437\u044c\u043c\u0438\u0442\u0435 \u0441\u0435\u0431\u0435 \u043d\u0430 \u0437\u0430\u043c\u0435\u0442\u043a\u0443!","e5f8b5e0":"# # \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u043d\u0438\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\n# num_folds = 10\n# n_estimators = 100\n# scoring = 'accuracy'","42f72a5c":"# models = []\n# models.append(('LR', LogisticRegression()))\n# models.append(('LDA', LinearDiscriminantAnalysis()))\n# models.append(('KNN', KNeighborsClassifier()))\n# models.append(('CART', DecisionTreeClassifier()))\n# models.append(('NB', GaussianNB()))\n# models.append(('LSVC', LinearSVC()))\n# models.append(('SVC', SVC()))\n# models.append(('MLP', MLPClassifier()))\n# models.append(('BG', BaggingClassifier(base_estimator = RandomForestClassifier(),n_estimators=n_estimators)))\n# models.append(('RF', RandomForestClassifier(n_estimators=n_estimators)))\n# models.append(('ET', ExtraTreesClassifier(n_estimators=n_estimators)))\n# models.append(('AB', AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME')))\n# models.append(('GB', GradientBoostingClassifier(n_estimators=n_estimators)))\n# models.append(('Cat', CatBoostClassifier(n_estimators=n_estimators)))\n\n\n\n# # \u041e\u0446\u0435\u043d\u0438\u0432\u0430\u043d\u0438\u0435 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\n# scores = []\n# names = []\n# results = []\n# predictions = []\n# msg_row = []\n# for name, model in models:\n#     kfold = KFold(n_splits=num_folds, shuffle=True)\n#     cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n#     names.append(name)\n#     results.append(cv_results)\n#     m_fit = model.fit(X_train, y_train)\n#     m_predict = model.predict(X_test)\n#     predictions.append(m_predict)\n#     m_score = model.score(X_test, y_test)\n#     scores.append(m_score)\n#     msg = \"%s: train = %.3f (%.3f) \/ test = %.3f\" % (name, cv_results.mean(), cv_results.std(), m_score)\n#     msg_row.append(msg)\n#     print(msg)","8a60f7b7":"# scores = []\n# names = []\n# results = []\n# predictions = []\n# msg_row = []","5c1abffe":"# from sklearn.preprocessing import StandardScaler","5390a1ca":"# scaler = StandardScaler()","e3b59988":"# X_train_scaled = X_train.drop(col_obj, axis=1)\n# X_valid_scaled = X_valid.drop(col_obj, axis=1)\n# x_test_scaled = df_test.drop(col_obj, axis=1)","e0bf7139":"# X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_scaled), columns=X_train_scaled.columns)\n# X_valid_scaled = pd.DataFrame(scaler.transform(X_valid_scaled), columns=X_valid_scaled.columns)\n# x_test_scaled = pd.DataFrame(scaler.transform(x_test_scaled), columns=x_test_scaled.columns)","8cb78051":"# from sklearn.manifold import TSNE","b4b6a03e":"# tsne = TSNE(n_components=3, learning_rate=250, random_state=42)\n# X_train_tsne = tsne.fit_transform(X_train_scaled)","13696e70":"# plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1])\n# plt.show()","2b881ca4":"# from sklearn.cluster import KMeans","b9e708e8":"# model = KMeans(n_clusters=2, random_state=42, max_iter=200)\n# model_kmeans = model.fit_predict(X_train_scaled)\n# fig = plt.figure()\n# fig = plt.figure(figsize=(10,10))\n# ax = fig.add_subplot(111, projection = '3d')\n\n# x = X_train_tsne[:, 0]\n# y = X_train_tsne[:, 1]\n# z = X_train_tsne[:, 2]\n\n# ax.scatter(x, y, z, c=model_kmeans)\n\n# plt.show()","1eb85e15":"# model_kmeans_valid = model.predict(X_valid_scaled)\n# model_kmeans_test_final = model.predict(x_test_scaled)\n# X_train['klaster'] = model_kmeans\n# X_valid['klaster'] = model_kmeans_valid\n# df_test['klaster'] = model_kmeans_test_final","766a0a62":"# X_train_scaled['klaster'] = model_kmeans\n# X_valid_scaled['klaster'] = model_kmeans_valid\n# x_test_scaled['klaster'] = model_kmeans_test_final","018cb4ac":"from catboost import CatBoostClassifier, CatBoostRegressor, Pool","db1af2e9":"train_pool = Pool(\n    X_train,\n    y_train,\n    cat_features=col_obj\n)\n\ntest_pool = Pool(\n    X_valid,\n    y_valid,\n    cat_features=col_obj\n) \n\nparams_model = {\n    'eval_metric': 'F1',\n    'auto_class_weights': 'Balanced',\n    'silent': True,\n    'one_hot_max_size': 20,\n    'early_stopping_rounds': 50,\n    'boosting_type': 'Ordered', #Ordered\n    'allow_writing_files': False\n}","1cd5a0ce":"\n%%time\n    cbr_model = CatBoostClassifier(**params_model)\n\n    params_grid = {\n        'depth': [4, 5, 6, 7,  8],\n        'learning_rate': [0.03, 0.1, 0,16, 0.2],\n        'iterations': [100, 200, 400],\n        'l2_leaf_reg': [0.5, 1, 2, 2.5, 3, 3.5, 4, 5, 6, 7 , 8, 9, 10],\n        'bagging_temperature': [1, 1.5, 2]\n    }\n\n#     gs = cbr_model.randomized_search(\n#         params_grid,\n#         train_pool,\n#         n_iter=50,\n#         shuffle=True,\n#         stratified=True,\n#         partition_random_seed=42,\n#         cv=5\n#     )\n\n#     pd.DataFrame(gs['cv_results']).sort_values('test-F1-mean', ascending=False).head()","b389fedc":"# gs['params']\n# {'depth': 8,\n#  'iterations': 400,\n#  'bagging_temperature': 1.5,\n#  'learning_rate': 0.1,\n#  'l2_leaf_reg': 3.5}","2c83296b":"# {'bagging_temperature': 1,\n#  'depth': 4,\n#  'iterations': 200,\n#  'learning_rate': 0.2,\n#  'l2_leaf_reg': 2.5}      #ordered","51fde915":"# gs['params']","0114091e":"%%time\n\ncat_model = CatBoostClassifier(\n    **params_model,\n    depth=6,\n    iterations=400,\n    learning_rate=0.2,\n    l2_leaf_reg=8.5,\n    bagging_temperature=1,\n    random_state=42\n)\n\ncat_model.fit(train_pool, eval_set=test_pool)","1e9741d4":"def get_classification_report(y_train_true, y_train_pred, y_valid_true, y_valid_pred):\n    \"\"\"\u041e\u0442\u0447\u0435\u0442 \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438 \u043c\u043e\u0434\u0435\u043b\u0438\"\"\"\n    \n    print('Train\\n\\n' + classification_report(y_train_true, y_train_pred))\n    print('Test\\n\\n' + classification_report(y_valid_true, y_valid_pred))\n    print('Confusion Matrix\\n')\n    print(pd.crosstab(y_valid_true, y_valid_pred))","628475b9":"def evaluate_preds(model, y_train, y_valid, train_pool, test_pool):\n    \"\"\"\u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438, \u0432\u044b\u0432\u043e\u0434 \u043e\u0442\u0447\u0435\u0442\u043e\u0432\"\"\"\n    \n    y_train_pred = model.predict(train_pool)\n    y_valid_pred = model.predict(test_pool)\n    \n    get_classification_report(y_train, y_train_pred, y_valid, y_valid_pred)","07090492":"evaluate_preds(cat_model, y_train, y_valid, X_train, X_valid)","45edb272":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_valid, cat_model.predict(X_valid))\nfpr, tpr, thresholds = roc_curve(y_valid, cat_model.predict_proba(X_valid)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='CatBoostClassifier (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","041f82db":"feature_importances = pd.DataFrame(\n    zip(X_train.columns, cat_model.get_feature_importance()),\n    columns=['feature_name', 'importance']\n)\n\nfeature_importances.sort_values(by='importance', ascending=False, inplace=True)\nfeature_importances.head(40)","24fc16fe":"y_pred_test = cat_model.predict(df_test)\ny_pred_test\nsubmit = pd.DataFrame(y_pred_test, columns=['Credit Default'])\n","83ed2d4d":"final_submit = pd.read_csv(\"\/kaggle\/input\/credit-default-prediction-ai-big-data\/sampleSubmission.csv\")\n","55ddd083":"final_submit['Credit Default'] = submit\nfinal_submit.to_csv('.\/predictions.csv', index=False, encoding='utf-8', sep=',')\nfinal_submit.head(10)","762f7cbf":"**\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430**\n\n* **Home Ownership** - \u0434\u043e\u043c\u043e\u0432\u043b\u0430\u0434\u0435\u043d\u0438\u0435\n* **Annual Income** - \u0433\u043e\u0434\u043e\u0432\u043e\u0439 \u0434\u043e\u0445\u043e\u0434\n* **Years in current job** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0435\u0442 \u043d\u0430 \u0442\u0435\u043a\u0443\u0449\u0435\u043c \u043c\u0435\u0441\u0442\u0435 \u0440\u0430\u0431\u043e\u0442\u044b\n* **Tax Liens** - \u043d\u0430\u043b\u043e\u0433\u043e\u0432\u044b\u0435 \u043e\u0431\u0440\u0435\u043c\u0435\u043d\u0435\u043d\u0438\u044f\n* **Number of Open Accounts** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0445 \u0441\u0447\u0435\u0442\u043e\u0432\n* **Years of Credit History** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0435\u0442 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u043e\u0439 \u0438\u0441\u0442\u043e\u0440\u0438\u0438\n* **Maximum Open Credit** - \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0438\u0439 \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0439 \u043a\u0440\u0435\u0434\u0438\u0442\n* **Number of Credit Problems** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0431\u043b\u0435\u043c \u0441 \u043a\u0440\u0435\u0434\u0438\u0442\u043e\u043c\n* **Months since last delinquent** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u043f\u0440\u043e\u0441\u0440\u043e\u0447\u043a\u0438 \u043f\u043b\u0430\u0442\u0435\u0436\u0430\n* **Bankruptcies** - \u0431\u0430\u043d\u043a\u0440\u043e\u0442\u0441\u0442\u0432\u0430\n* **Purpose** - \u0446\u0435\u043b\u044c \u043a\u0440\u0435\u0434\u0438\u0442\u0430\n* **Term** - \u0441\u0440\u043e\u043a \u043a\u0440\u0435\u0434\u0438\u0442\u0430\n* **Current Loan Amount** - \u0442\u0435\u043a\u0443\u0449\u0430\u044f \u0441\u0443\u043c\u043c\u0430 \u043a\u0440\u0435\u0434\u0438\u0442\u0430\n* **Current Credit Balance** - \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0439 \u0431\u0430\u043b\u0430\u043d\u0441\n* **Monthly Debt** - \u0435\u0436\u0435\u043c\u0435\u0441\u044f\u0447\u043d\u044b\u0439 \u0434\u043e\u043b\u0433\n* **Credit Default** - \u0444\u0430\u043a\u0442 \u043d\u0435\u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u044b\u0445 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432 (0 - \u043f\u043e\u0433\u0430\u0448\u0435\u043d \u0432\u043e\u0432\u0440\u0435\u043c\u044f, 1 - \u043f\u0440\u043e\u0441\u0440\u043e\u0447\u043a\u0430)","cb529340":"### \u0422\u0435\u043f\u0435\u0440\u044c \u0435\u0441\u0442\u044c \u0438\u0434\u0435\u044f \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0444\u0438\u0447\u0443 \u0434\u043b\u044f \u0438 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u043e\u0432\u0430\u0442\u044c \u043d\u0430\u0448 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445. \u0411\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u044d\u0442\u043e \u043d\u0435 \u043f\u0440\u0438\u043d\u0435\u0441\u043b\u043e, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043a\u043e\u0434 \u0441\u043f\u0440\u044f\u0442\u0430\u043d, \u043a\u043e\u043c\u0443 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c","26086955":"# \u0418\u0442\u0430\u043a, \u043b\u0438\u0447\u043d\u043e \u043c\u043e\u0438\u043c \u0447\u0435\u043c\u043f\u043e\u043c \u043e\u043a\u0430\u0437\u0430\u043b\u0441\u044f catboost","020b8cf4":"\u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c 2 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u0438\u0432\u043d\u044b\u0445 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0434\u043b\u044f 2 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 (credit_score, Annual Income),\u043e\u0444\u043e\u0440\u043c\u0438\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u0438, \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u0443","2dd58a78":"\u0412\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0440\u0430\u0432\u0435\u043d\u0441\u0442\u0432\u0430 \u043c\u0430\u0442. \u043e\u0436\u0438\u0434\u0430\u043d\u0438\u044f \u043e\u0442\u0432\u0435\u0440\u0433\u0430\u0435\u0442\u0441\u044f","91594ec7":"## \u0412 \u0441\u043b\u0443\u0447\u0430\u0435, \u0435\u0441\u043b\u0438 \u043c\u044b \u0437\u0430\u0445\u043e\u0442\u0438\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u0440\u0443\u0433\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438, \u043d\u0438\u0436\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043a\u043e\u0434 (\u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0438\u043c, \u0447\u0442\u043e \u043c\u044b \u043f\u0435\u0440\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043b\u0438 \u043d\u0430\u0448\u0438 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0445\u043e\u0442\u0438\u043c \u0435\u0449\u0435 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u043e\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u043d\u0430\u0434 \u0432\u044b\u0431\u0440\u043e\u0441\u0430\u043c\u0438)","832e5d06":"\u0412 \u0441\u043e\u043e\u0441\u0442\u0432\u0435\u0442\u0441\u0432\u0438\u0438 \u0441 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0435\u043c \u0428\u0430\u043f\u0438\u0440\u043e-\u0423\u0438\u043b\u043a\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043e\u0442\u043b\u0438\u0447\u043d\u043e \u043e\u0442 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e"}}