{"cell_type":{"9006dfa1":"code","69a991cf":"code","4892b4ab":"code","4b34100e":"code","3352e30e":"code","fbb1e84e":"code","9925cac0":"code","3ef41b9a":"code","89e8bdc6":"code","67cb8ca6":"code","35b0530f":"code","c5a3780a":"code","cecda447":"code","98714c3c":"code","b56e3ef6":"code","594b8566":"code","5e6d677a":"code","c0f25165":"code","65d0ebc1":"code","2c62d6ee":"code","ee04febf":"code","26235750":"code","e18aa000":"code","6ef18a2e":"code","112babb1":"code","e55b394a":"code","efe3e0e2":"code","55991854":"code","28cd0330":"code","e92682ac":"code","c1e9ba8f":"code","7564d2b0":"code","3d331a31":"code","640c809a":"code","6ece6e1a":"code","baa33a70":"code","304ba151":"code","f2244663":"code","e45bc0bd":"code","69c89e4b":"code","507b5ba6":"code","a043f02f":"code","7bed60d6":"code","2d2dd4ef":"code","e456e4ba":"code","bf53e619":"code","2e9e43de":"code","504628b2":"code","9e46710b":"code","4d3be040":"markdown","b2d6d49a":"markdown","82dfad78":"markdown","b8f03aa5":"markdown","6d943df3":"markdown","540b065e":"markdown","bda9497d":"markdown","2c68521b":"markdown","c842c607":"markdown","3ac6f4c7":"markdown","e4f9c908":"markdown","e7d35992":"markdown","4d70dfee":"markdown","c1903a48":"markdown","21f889df":"markdown","9eb08859":"markdown","2d35d8de":"markdown","cb3f6b6a":"markdown","c5219386":"markdown","1efc6a7e":"markdown","87f06683":"markdown","47637f64":"markdown","86682388":"markdown","3417174b":"markdown","a9a470f8":"markdown","57dd0276":"markdown","c1bcf81f":"markdown","be9095c3":"markdown","0b425e0d":"markdown","d8a3dbc2":"markdown","ca2f39bb":"markdown","3a44289c":"markdown","b14abd98":"markdown"},"source":{"9006dfa1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\nsns.set_context(\"talk\", font_scale=1.2)\nimport plotly.express as px\nimport numpy as np","69a991cf":"from sklearn.metrics import mean_squared_log_error","4892b4ab":"mean_squared_log_error?","4b34100e":"def RMSLE(y_true:np.ndarray, y_pred:np.ndarray) -> np.float64:\n    \"\"\"\n        The Root Mean Squared Log Error (RMSLE) metric \n        \n        :param y_true: The ground truth labels given in the dataset\n        :param y_pred: Our predictions\n        :return: The RMSLE score\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))","3352e30e":"import tensorflow as tf","fbb1e84e":"def RMSLETF(y_pred:tf.Tensor, y_true:tf.Tensor) -> tf.float64:\n    '''\n        The Root Mean Squared Log Error (RMSLE) metric for TensorFlow \/ Keras\n        \n        :param y_true: The ground truth labels given in the dataset\n        :param y_pred: Predicted values\n        :return: The RMSLE score\n    '''\n    y_pred = tf.cast(y_pred, tf.float64)\n    y_true = tf.cast(y_true, tf.float64) \n    y_pred = tf.nn.relu(y_pred) \n    return tf.sqrt(tf.reduce_mean(tf.squared_difference(tf.log1p(y_pred), tf.log1p(y_true))))","9925cac0":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\",\n                   keep_default_na=False, na_values=[\"\"])\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\",\n                  keep_default_na=False, na_values=[\"\"])","3ef41b9a":"with open(\"..\/input\/house-prices-advanced-regression-techniques\/data_description.txt\") as f:\n    features = {}\n    features_descr = {}\n    for line in f.readlines():\n        # feature name\n        if line[0].isalnum():\n            #print(\"feature\")\n            #print(line)\n            feature_name = line.split(\":\")[0]\n            feature_descr = line.split(\":\")[1]\n            features[feature_name] = {}\n            features_descr[feature_name] = feature_descr\n        elif len(line.strip()) > 2:\n            #print(\"feature val\")\n            #print(\"line: \", line, len(line))\n            feature_vals = [val.strip() for val in line.split('\\t')]\n            #print(feature_vals)\n            features[feature_name][feature_vals[0]] = feature_vals[1]\n            #features[]\n            \n            \n        ","89e8bdc6":"for feature in features_descr:\n    print(f\"############################# {feature}\")\n    print(features_descr[feature])\n    print(features[feature])","67cb8ca6":"print(train.shape, test.shape)","35b0530f":"train.head()","c5a3780a":"train.sample(10, random_state=42)","cecda447":"num_cols = ['SalePrice', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd','MasVnrArea', 'BsmtFinSF1',\n               'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n               'LowQualFinSF', 'GrLivArea', \n               'BsmtFullBath', 'BsmtHalfBath', 'FullBath', # check the values, expect discrete numeric\n               'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n               'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n               'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n               'MiscVal', 'MoSold', 'YrSold', 'OverallCond', 'OverallQual']\n\n\ncat_cols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n               'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n               'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n               'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n               'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n               'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu',\n               'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', \n                'PoolQC', 'Fence', 'SaleType', 'SaleCondition', 'MiscFeature']","98714c3c":"ordinal_cat = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n                  'BsmtExposure', # could be treated as ordinal except maybe one category\n                  'BsmtFinType1',\n                  'BsmtFinType2', # likely good choice of ordernal\n                  'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu',\n                  'GarageFinish', 'GarageQual', 'GarageCond',\n                  'PoolQC',\n                  'Fence', # except no fence which does not fit in the order\n                  ] #","b56e3ef6":"mapping_features = {\"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                       \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                       \"BsmtQual\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"BsmtCond\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"BsmtExposure\": {\"NA\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n                        \"BsmtFinType1\": {\"NA\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6},\n                        \"BsmtFinType2\" : {\"NA\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6},\n                        \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                        \"KitchenQual\" :  {\"Po\": 0, \"Fa\": 1, \"TA\": \"2\", \"Gd\": 3, \"Ex\": 4},\n                        \"Functional\": {\"Sal\": 0, \"Sev\": 1, \"Maj2\": 2, \"Maj1\": 3, \"Mod\": 4, \"Min2\": 5, \"Min1\": 6, \"Typ\": 7},\n                        \"FireplaceQu\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"GarageFinish\": {\"NA\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n                        \"GarageQual\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"GarageCond\": {\"NA\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"PoolQC\": {\"NA\": 0, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                        \"Fence\": {\"NA\": 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\":3 , \"GdPrv\":4}}","594b8566":"num_cols_num = 0\ncat_cols_num = 0\n\nfor feat in features.keys():\n    if feat in num_cols:\n        num_cols_num += 1\n    elif feat in cat_cols:\n        cat_cols_num +=1\n    else:\n        print(f\"feature {feat} missed\")\nprint(f\" {len(num_cols)}, {num_cols_num}\")\nprint(f\" {len(cat_cols)}, {cat_cols_num}\")","5e6d677a":"train[num_cols].dtypes","c0f25165":"train['LotFrontage'].value_counts().head()","65d0ebc1":"train['LotFrontage'] = train['LotFrontage'].replace(\"NA\", np.nan).astype(float)","2c62d6ee":"train['MasVnrArea'].value_counts().head()","ee04febf":"train['MasVnrArea'] = train['MasVnrArea'].replace(\"NA\", np.nan).astype(float)","26235750":"train['GarageYrBlt'].value_counts().head()","e18aa000":"train['GarageYrBlt'] = train['GarageYrBlt'].replace(\"NA\", np.nan).astype(float)","6ef18a2e":"train[num_cols].dtypes.value_counts()","112babb1":"train[cat_cols].dtypes","e55b394a":"train['MSSubClass'] = train['MSSubClass'].astype(str)","efe3e0e2":"for feat in features.keys():\n    print(feat)\n    #print(feat, train.dtypes.to_dict()[feat], list(features[feat].keys()))\n    print(feat, list(features[feat].keys()))\n    ","55991854":"train.nunique().sort_values()","28cd0330":"import missingno as msno","e92682ac":"train.isna().sum().sort_values(ascending=False).head(20)","c1e9ba8f":"train.isna().sum().sort_values(ascending=False).div(train.shape[0]).head(20)","7564d2b0":"with sns.plotting_context(\"talk\", font_scale=0.4):\n    msno.matrix(train, labels=True)","3d331a31":"train.duplicated().sum()","640c809a":"train[num_cols].describe().T","6ece6e1a":"train[cat_cols].describe()","baa33a70":"train['Id'].nunique()","304ba151":"for i, col in enumerate(num_cols):\n    print(col)\n    with sns.plotting_context(\"talk\", font_scale=0.4):\n        fig, axes = plt.subplots(2,1, figsize=(16,4)) # create figure and axes\n        train[col].hist(bins=50, grid=False, ax=axes[0])\n        sns.boxplot(x=train[col], ax=axes[1])\n        plt.show()","f2244663":"for col in cat_cols:\n    print(\"#\"*20, col, \"#\"*20)\n    print(pd.merge(train[col].value_counts(dropna=False), train[col].value_counts(dropna=False, normalize=True), \n                   left_index=True, right_index=True))","e45bc0bd":"with sns.plotting_context(\"talk\", font_scale=0.4):\n    plt.figure(figsize=(14,14))\n    sns.heatmap(train[num_cols].corr(), annot = True, cmap=\"YlGnBu\")","69c89e4b":"def get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(train[num_cols], 5))","507b5ba6":"for col in cat_cols:\n    fig=plt.figure(figsize=(14, 4))\n    sns.boxplot(x=col, y='SalePrice', data=train);","a043f02f":"for col in num_cols:\n    fig=plt.figure(figsize=(14, 4))\n    sns.scatterplot(x=col, y='SalePrice', data=train);","7bed60d6":"train.head()","2d2dd4ef":"sns.scatterplot(data=train, x='YrSold', y='SalePrice')","e456e4ba":"train.groupby(\"YrSold\")['SalePrice'].mean()","bf53e619":"train.groupby(\"YrSold\")['SalePrice'].plot(kind='hist', figsize=(16,4), alpha=0.6)\nplt.legend()","2e9e43de":"fig, ax= plt.subplots(figsize=(16,4))\nsns.histplot(data=train, x='SalePrice', hue='YrSold', ax=ax)\n","504628b2":"train.groupby(\"YrSold\")['SalePrice'].mean()","9e46710b":"train.groupby(\"YrSold\")['SalePrice'].median()","4d3be040":"> There is clear structure in missingness. Some variables have missingness correlated.","b2d6d49a":"# IV. Multivariate Analysis","82dfad78":"# I. Goals","b8f03aa5":"> Sales price target variable is highly skewed to the right. Log transformation could be an option or winzorisation.\n\n* Some features might be benefitial to transform similarlity, such as the SF features.","6d943df3":"There are different types of missing values, depending on the definition. I count values as truly missing if they are not a valid categoryical variable (e.g. not having a pool).","540b065e":"> Logarithm of SalesPrice also indicates little difference over the years (Metrics).","bda9497d":"> Significant correlation between some variables, e.g. garage cars and garage areas as expected. Could drop later.","2c68521b":"### Numerical Feature Distributions","c842c607":"### id\n","3ac6f4c7":"* Predict the final price of home based on characteristic features of the house. This is a regression problem where we predict the actual house value.\n* The whole population which could be the houses worldwide are not well represented in the dataset. Only *residential* homes in Ames, Iowa are included of the dataset.\n* Performance Measure\n    * Root-Mean-Squared-Error (RMSE) between the ***logarithm of the predicted value*** and the logarithm of the observed sales price. This allows for high and low prices to fairly equally contribute to the overall error.\n    * metric Properties:\n        * If prediction is 0 the log is undefined\n        * Assymetric penalizatin: Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate. This is beneficial if I sell the house as I don't want at all cost to sell below the actual value as I would loose money. But if I want to buy the house the metric might not be the right choice\n        * similar to the  Root Mean Squared Log Error (RMSLE) metric which contains additional value of 1 in prediction and ground truth to deal with 0 values\n        * I aim to optimize RMSLE as it has desirable properties and is only slight variation from the pure log minus log approach\n    ","e4f9c908":"# II. Gather the Data\n\n* The data is provided by kaggle and already split in train and validation. We do not know how this split was performed, maybe randomly or based on stratified sampling. Paper could give more info?\n* The dataset is published in a paper: http:\/\/jse.amstat.org\/v19n3\/decock.pdf\n* \n\n","e7d35992":" Root Mean Squared Log Error (RMSLE) metric:","4d70dfee":"* `CentralAir` is a clear indicator of ihgher sales price\n* `MiscFeature` is also for Gar2 ...","c1903a48":"> ","21f889df":"## Data Types\n\nAssure that features are correctly represented by types.\n\n* LotArea: in int but could be float instead\n* YearBuilt, YearRemodAdd: in int but could use potentially other dtype, datetime, or age?\n* BsmtFinSF2, BsmtUnfSF, TotalBsmtSF all in int but are quare feet so non-int are valid.\n\nCould be improved\n\n1stFlrSF int64 []\n2ndFlrSF int64 []\nLowQualFinSF int64 []\nGrLivArea int64 []\n","9eb08859":"Also agreement, after correction, all object type.","2d35d8de":"* `salesprice` spans wide range.\n* `LotArea` differs greatly in range, skewed with very high values\n* Most recent year `2010` build, indicate time creation of dataset. Extremely old house with year `1872`\n* houses sold between year 2007 and 2010. narrow range.\n* OverallCond and OverallQual include all values available. So large variaty of houses leading to different house prices.","cb3f6b6a":"Ensure no features are missed","c5219386":"Investigation the data description to understand the variables.","1efc6a7e":"# III. Prepare the data\n","87f06683":"## Duplicates\n\nNo duplicate rows.","47637f64":"### Sales Price vs Year of Sale\n\nOften house values increase over the years so I test if there is a difference between the sales prices of the 5 years of data:","86682388":"### Zero-Variance Features?\n\nNo zero-variance features which would be worth dropping.","3417174b":"all 3 features below do not have as a valid value NA, hence treat as truely missing.","a9a470f8":"> data description file inconsistency in naming: Bedroom == ","57dd0276":"# V. Univariate Analysis\n\n* id: simple identifier\n\n","c1bcf81f":"Ok, as names differ.","be9095c3":"Now all numeric columns have numeric data types.","0b425e0d":"## Missingness\n\nAre there indications that missigness is encoded in a different way and not recognized by pandas as missing?\nearlier inspection did not indicate that.\n\n* `Alley`, `PoolQC`, `Fence` are categorical variables which have NA as valid category, no missingnesss!\n* `BsmtQual` has valid cateogry NA. There are one or two other variables. with thte same characteristic.\n\n> All truely missing values where identified through pandas nan.\n","d8a3dbc2":"* some variables have a dominant category, and hence might not be useful:\n    * `Street` not very useful, only 6 values are not belong to the major category\n    * `Utilities` also not useful, due to almost all one category. Drop from analysis\n    * `Condition2` maybe drop due to main category. 15 datapoints of other category.\n    * `RoofMatl` similarly, only 26 data points from other category, not main\n\n* ","ca2f39bb":"> 3 features have high missigness as detected through empty string \"\".","3a44289c":"# EDA of the House Prices - Advanced Regression Competition","b14abd98":"# IV. Meet & Greet the data\n\n* Train and test set have similar size.\n\nAssumptions\n\n* `id`: unique id\n* \n"}}