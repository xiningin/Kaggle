{"cell_type":{"50d9b845":"code","f48e0b08":"code","d65ec225":"code","48cb0537":"code","461b582c":"code","c4a826f5":"code","1139bdfa":"code","8e111260":"code","d5667f1e":"code","75b9312d":"code","148bac2d":"code","c4e4237f":"code","b9944d4e":"code","619fb0df":"code","ef30eb59":"code","bb0cfd29":"code","afc7980e":"code","db5db17e":"code","5240f4b6":"code","27c464af":"code","f53b8e0a":"code","5c374dcf":"code","bb61832a":"code","6df1128b":"code","30527e8c":"code","a2132380":"code","6348edeb":"code","ab166790":"code","946a28e3":"code","16d8b815":"code","64ef4fbf":"code","1e1e7004":"code","e0db388d":"code","e062ff07":"code","e0ea3e57":"code","d886da1b":"code","ef5945d5":"code","ae334105":"code","67b17e36":"code","2b6088b0":"code","eab60a4d":"code","acbc889d":"code","7da0f8c0":"code","65d540cb":"code","69eeb017":"code","0a0ceb27":"code","75770954":"code","704de680":"code","7e54eb45":"code","d09943fe":"code","44ccc47a":"code","ae990760":"code","3c110499":"code","3cc4f435":"code","5587732f":"code","48620f94":"code","ae8fdb25":"code","a3991fd4":"markdown","1fd34571":"markdown","9102121b":"markdown","b6fc295d":"markdown","6c117ac4":"markdown"},"source":{"50d9b845":"### Import Libraries \nimport numpy as np \nimport xgboost as xgb\nimport numpy as np\nfrom collections import OrderedDict\nimport gc\nfrom glob import glob\nimport os\nimport pandas as pd\nfrom copy import copy\nfrom time import time\nfrom sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score,classification_report,roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom timeit import default_timer\nimport matplotlib.pyplot as plt\nimport pickle\nimport seaborn as sns\n%matplotlib inline\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f48e0b08":"### Display all the columns of dataframe\npd.set_option('display.max_columns', None)","d65ec225":"train_set = pd.read_csv('..\/input\/train.csv')\ntest_set = pd.read_csv('..\/input\/test.csv')\nvalidation_sample = pd.read_csv('..\/input\/gender_submission.csv')\n#print(train_set.head())\nprint(len(train_set))\nprint(len(test_set))\nprint(len(validation_sample))","48cb0537":"print (train_set.columns)\nprint(validation_sample.columns)","461b582c":"### Check the rows for each class\npd.DataFrame(train_set['Survived'].value_counts())","c4a826f5":"train_set.describe()","1139bdfa":"train_set.columns","8e111260":"train_set.dtypes","d5667f1e":"train_set.head()","75b9312d":"pd.DataFrame(train_set['Parch'].value_counts())","148bac2d":"pd.DataFrame(train_set['SibSp'].value_counts())","c4e4237f":"train_set[\"Age\"]=train_set[\"Age\"].fillna(train_set[\"Age\"].median())\ntrain_set[\"Fare\"]=train_set[\"Fare\"].fillna(train_set[\"Fare\"].median())\ntrain_set[\"Embarked\"]=train_set[\"Embarked\"].fillna(train_set[\"Embarked\"].mode()[0])","b9944d4e":"#train_set[\"Child\"]=train_set[\"Age\"].apply(lambda x : 1 if x<15 else 0 )\n#train_set[\"Teenager\"]=train_set[\"Age\"].apply(lambda x : 1 if (x>=15) and (x<25) else 0 )\n#train_set[\"Adult\"]=train_set[\"Age\"].apply(lambda x : 1 if (x>=25) & (x<65) else 0 )\n#train_set[\"Old\"]=train_set[\"Age\"].apply(lambda x : 1 if x>=65 else 0 )","619fb0df":"train_set['Age_new'] = np.log(1+train_set.Age) \n#train_set['Fare_new'] = np.log(1+train_set.Fare) ","ef30eb59":"train_set['Age_new'].value_counts()","bb0cfd29":"pd.DataFrame(train_set.isnull().sum())","afc7980e":"### One hot encoding for the categorical data\ncat_vars = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\n# find unique labels for each category\ncat_data = pd.get_dummies(train_set[cat_vars])\n\n# check that the categorical variables were created correctly\ncat_data.head()","db5db17e":"numeric_vars = list(set(train_set.columns.values.tolist())- set(cat_vars))\nnumeric_vars","5240f4b6":"numeric_vars = list(set(train_set.columns.values.tolist()) - set(cat_vars))\nnumeric_vars.remove('Survived')\nnumeric_vars.remove('PassengerId')\nnumeric_vars.remove('Name')\nnumeric_vars.remove('Ticket')\nnumeric_vars.remove('Cabin')\nnumeric_vars.remove('Age')\nnumeric_data = train_set[numeric_vars].copy()\n# check that the numeric data has been captured accurately\nnumeric_data.head()","27c464af":"# concat numeric and the encoded categorical variables\nnumeric_cat_data = pd.concat([numeric_data, cat_data], axis=1)\n\n# check that the data has been concatenated correctly by checking the dimension of the vectors\nprint(cat_data.shape)\nprint(numeric_data.shape)\nprint(numeric_cat_data.shape)","f53b8e0a":"numeric_cat_data.head()","5c374dcf":"# capture the labels\nlabels = train_set['Survived'].copy()\n# split data into test and train\nx_train, x_test, y_train, y_test = train_test_split(numeric_cat_data,\n                                                    labels,\n                                                    test_size=.30, \n                                                    random_state=2046)","bb61832a":"# check that the dimensions of our train and test sets are okay\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","6df1128b":"x_train.head()","30527e8c":"pd.DataFrame(y_train[0:10])","a2132380":"### Hyper Parameter Tuning: \nparams = {\n    'num_rounds':       10,\n    'max_depth':         4,\n    'max_leaves':        2**4,\n    'alpha':             0.9,\n    'eta':               0.1,\n    'gamma':             0.1,\n    'learning_rate':     0.11115,\n    'subsample':         1,\n    'reg_lambda':        1,\n    'scale_pos_weight':  2,\n    'objective':         'binary:logistic',\n    'verbose':           True\n}","6348edeb":"%%time \ndtrain = xgb.DMatrix(x_train, label=y_train)\ndtest = xgb.DMatrix(x_test, label= y_test)\nevals = [(dtest, 'test',), (dtrain, 'train')]\n\nnum_rounds = params['num_rounds']\nmodel = xgb.train(params, dtrain, num_rounds, evals=evals)","ab166790":"threshold = .5\ntrue_labels = y_test.astype(int)\ntrue_labels.sum()\n\n# make predictions on the test set using our trained model\npreds = model.predict(dtest)\nprint(preds)","946a28e3":"pred_labels = (preds > threshold).astype(int)\nprint(pred_labels)","16d8b815":"pred_labels.sum()","64ef4fbf":"# compute the auc\nauc = roc_auc_score(true_labels, pred_labels)\nprint(auc)","1e1e7004":"print ('Accuracy:', accuracy_score(true_labels, pred_labels))","e0db388d":"results = confusion_matrix(true_labels, pred_labels) \n\nprint ('Confusion Matrix :')\n\ndef plot_confusion_matrix(cm, target_names, title='Confusion Matrix', cmap=plt.cm.Greens):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(target_names))\n    plt.xticks(tick_marks, target_names, rotation=45)\n    plt.yticks(tick_marks, target_names)\n    plt.tight_layout()\n\n    width, height = cm.shape\n\n    for x in range(width):\n        for y in range(height):\n            plt.annotate(str(cm[x][y]), xy=(y, x), \n                        horizontalalignment='center',\n                        verticalalignment='center')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n\n\nplot_confusion_matrix(results, ['0','1'])","e062ff07":"### AUC\nfpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\nroc_auc = roc_auc_score(true_labels, pred_labels)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('AUC Plot')\nplt.legend(loc=\"lower right\")\nplt.show()","e0ea3e57":"### Model Inspection \nxgb.plot_importance(model)","d886da1b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nrfc = RandomForestClassifier(n_estimators=1000, random_state=0)\nrfc.fit(x_train, y_train)\ny_pred = rfc.predict(x_test)","ef5945d5":"Accuracy_rfc = accuracy_score(y_test, y_pred)\nprint(\"The Random Forest Classifier Model has an accuracy of : %.5f%%\" % (Accuracy_rfc * 100.0))","ae334105":"# grid_param dictionary\ngrid_param = {  \n    'n_estimators': [10,20,30,60,100],\n    'criterion': ['gini', 'entropy'],\n    'bootstrap': [True, False]\n}","67b17e36":"# instance of the GridSearchCV class\ngds_rfc = GridSearchCV(estimator=rfc,     \n                     param_grid=grid_param,    \n                     scoring='accuracy',       \n                     cv=5,                     \n                     n_jobs=-1) ","2b6088b0":"gds_rfc.fit(x_train, y_train)","eab60a4d":"# Optimal hyperparameters: best_params_\ngds_rfc.best_params_","acbc889d":"# Best score found (mean score on all folds used as validation set): best_score_\nAcc_gds_rfc=gds_rfc.best_score_","7da0f8c0":"print(\"Random Forest Classifier-Hyperparameters Model has an accuracy of : %.2f%%\" % (Acc_gds_rfc * 100.0))","65d540cb":"### Support Vector Machine:\nfrom sklearn.svm import SVC","69eeb017":"svc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)","0a0ceb27":"Acc_svc = accuracy_score(y_test, y_pred)\nprint(\"The Naive Bayes Model has an accuracy of : %.2f%%\" % (Acc_svc * 100.0))","75770954":"test_set[\"Age\"]=test_set[\"Age\"].fillna(test_set[\"Age\"].median())\ntest_set[\"Fare\"]=test_set[\"Fare\"].fillna(test_set[\"Fare\"].median())\ntest_set[\"Embarked\"]=test_set[\"Embarked\"].fillna(test_set[\"Embarked\"].mode()[0])","704de680":"pd.DataFrame(test_set.isnull().sum())","7e54eb45":"test_set['Age_new'] = np.log(1+test_set.Age) \n#test_set['Fare_new'] = np.log(1+test_set.Fare) ","d09943fe":"\n### One hot encoding for the categorical data\ncat_vars_test = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\n# find unique labels for each category\ncat_data_test = pd.get_dummies(test_set[cat_vars_test])\n\n# check that the categorical variables were created correctly\ncat_data_test.head()\n\nnumeric_vars_test = list(set(test_set.columns.values.tolist())- set(cat_vars_test))\nnumeric_vars_test\n\nnumeric_vars_test = list(set(test_set.columns.values.tolist()) - set(cat_vars_test))\nnumeric_vars_test.remove('PassengerId')\nnumeric_vars_test.remove('Name')\nnumeric_vars_test.remove('Ticket')\nnumeric_vars_test.remove('Cabin')\nnumeric_vars_test.remove('Age')\n#numeric_vars_test.remove('Fare')\nnumeric_data_test = test_set[numeric_vars_test].copy()\n# check that the numeric data has been captured accurately\nnumeric_data_test.head()\n\n# concat numeric and the encoded categorical variables\nnumeric_cat_data_test = pd.concat([numeric_data_test, cat_data_test], axis=1)\n\n# check that the data has been concatenated correctly by checking the dimension of the vectors\nprint(cat_data_test.shape)\nprint(numeric_data_test.shape)\nprint(numeric_cat_data_test.shape)","44ccc47a":"dtest = xgb.DMatrix(numeric_cat_data_test)\n# make predictions on the test set using our trained model\npreds = model.predict(dtest)\nprint(preds)","ae990760":"pred_labels = (preds > threshold).astype(int)\nprint(pred_labels)\nprint (len(pred_labels))","3c110499":"test_set['Survived'] = pred_labels\nsubmission = test_set[['PassengerId', 'Survived']]\nsubmission.to_csv('submission_xgboost3.csv', index=False)","3cc4f435":"submission.head()","5587732f":"preds_rfc = rfc.predict(numeric_cat_data_test)\nprint(preds_rfc)","48620f94":"test_set['Survived'] = preds_rfc\nsubmission = test_set[['PassengerId', 'Survived']]\nsubmission.to_csv('submission_rfc.csv', index=False)","ae8fdb25":"len(test_set)","a3991fd4":"###  Exploratory Data Anlysis:","1fd34571":"### RFC Prediction:","9102121b":"### Random Forest:","b6fc295d":"### Apply in Test Data Set:","6c117ac4":"> ### Support Vector Classifier:"}}