{"cell_type":{"d0459984":"code","68788df5":"code","01389ed7":"code","3cc93b29":"code","413660b9":"code","788b5062":"code","7343f8c8":"code","3541d09e":"code","45bdd067":"code","3f9f85e3":"code","b30b6676":"code","fa9a2dd7":"code","d3a8168a":"code","49d3cd0d":"code","01032753":"code","213949c2":"code","45266d0e":"code","d63cbdb6":"code","a410bf07":"code","8431b34d":"code","c0d277dd":"code","e40416d3":"markdown","c266957f":"markdown","9e3cf424":"markdown","117fdd92":"markdown","dc2bb1d8":"markdown","2784d786":"markdown","be0ca580":"markdown"},"source":{"d0459984":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68788df5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling as pp\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split","01389ed7":"df=pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","3cc93b29":"df.head()","413660b9":"print(\"*! Shape of the dataset is !*\")\ndf.shape","788b5062":"print(\"*! We can see their are no null values in any of the column !*\")\ndf.isna().any()","7343f8c8":"print(\"*! Description of the dataset !*\")\ndf.describe()","3541d09e":"print(\"*! Types of Dataset !*\")\ndf.dtypes","45bdd067":"pp.ProfileReport(df)","3f9f85e3":"nums = {\"test preparation course\": {\"none\":0, \"completed\":1}}\ndf = df.replace(nums)\ndf.head()","b30b6676":"fig, axes = plt.subplots(figsize=(12,6))\nsns.countplot(data=df, x=\"parental level of education\", hue=\"test preparation course\", palette=['#F3CEE8','#B7D1F8'])\nsns.set(style=\"whitegrid\")\naxes.legend(loc='upper right',frameon=True)\naxes.set_ylim(0, 160)\nplt.title(\"*! Test preparation according to parental level of education !*\")\nplt.show()\nprint(\"*! On the basis of the plot we can state that the high school pass out parent's students have shown the better results. !*\")","fa9a2dd7":"sns.catplot(x=\"lunch\", y=\"math score\", hue=\"gender\", kind=\"point\", data=df, palette=\"ch:s=-.2,r=.6\")\nplt.show()","d3a8168a":"a = df['math score'].sum()\nb = df['reading score'].sum()\nc = df['writing score'].sum()\n\n# Data to plot\nfig, axes = plt.subplots(figsize=(12,6))\nlabels = 'math score', 'reading score', 'writing score'\nsizes = a,b,c\ncolors = ['gold', 'yellowgreen', 'lightcoral']\nexplode = (0.1, 0, 0) \n\n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n\nplt.axis('equal')\nplt.show()","49d3cd0d":"sns.violinplot(x=df.gender, y=df['reading score'], palette=\"viridis\", inner=\"stick\")\nplt.show()","01032753":"sns.pairplot(df, hue = \"race\/ethnicity\", palette=\"Spectral\")\nplt.show()","213949c2":"X, Y = make_classification(n_samples=1000, n_features=14, n_informative=9, n_redundant=5, random_state=3)\nprint(X.shape)\nprint(Y.shape)","45266d0e":"# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)","d63cbdb6":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","a410bf07":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred)*100,2),\"%\")","8431b34d":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)","c0d277dd":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred)*100,2),\"%\")","e40416d3":"# Exploratory Data Analysis \ud83d\udcc8","c266957f":"## Support Vector Machines ","9e3cf424":"# Dataset Profile Report","117fdd92":"## Random Forest ","dc2bb1d8":"![image](https:\/\/www.teacherready.org\/wp-content\/uploads\/2017\/02\/bigstock-education-elementary-school-83201570.jpg)","2784d786":"# Student Performance Analysis\ud83d\udc69\ud83c\udffb\u200d\ud83c\udf93","be0ca580":"# Modelling \ud83d\udcca\ud83d\udc68\u200d\ud83d\udcbb\ud83d\udcc9"}}