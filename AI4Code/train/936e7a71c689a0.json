{"cell_type":{"8b455c15":"code","d3a3ab8e":"code","266b880e":"code","c08b9315":"code","2ca9a31f":"code","97155f53":"code","5370b13c":"code","81b7d8ba":"code","ed9b66b0":"code","9540ac75":"code","7dcd31fa":"code","ab78bad7":"code","47821831":"code","98169880":"markdown","d9830a6a":"markdown","05dd3c6f":"markdown","bfa394b4":"markdown","81ae0d6a":"markdown","99ca7368":"markdown","9a76ea60":"markdown","bf5f2889":"markdown","22b763dd":"markdown","40407149":"markdown","58e6508b":"markdown","ca9f595c":"markdown","b66bccb7":"markdown"},"source":{"8b455c15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3a3ab8e":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nfrom PIL import Image\nnp.random.seed(123)\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import confusion_matrix","266b880e":"data = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')","c08b9315":"data.head()","2ca9a31f":"data.isnull().sum().sum()","97155f53":"data['Type'] = 0\ncol1 = data['diagnosis']\ncol2 = data['Type']\nfor i in range(len(data)):\n    if(col1[i] == 'M'):\n        col2[i] = 1\n    elif(col1[i] == 'B'):\n        col2[i] = 0","5370b13c":"data.drop(['Unnamed: 32'], axis=1, inplace=True)\nfeatures = data.drop(columns = ['id','Type', 'diagnosis'])\ntarget = data['Type']","81b7d8ba":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.20)\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","ed9b66b0":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 2)\ny_test = to_categorical(y_test, num_classes = 2)","9540ac75":"from sklearn import neighbors\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\nrmse_val = []\nfor K in range(20):\n    K = K+1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(x_train, y_train)  #fit the model\n    pred=model.predict(x_test) #make prediction on test set\n    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n    rmse_val.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)","7dcd31fa":"curve = pd.DataFrame(rmse_val) #elbow curve \ncurve.plot()","ab78bad7":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.metrics import classification_report\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\n#    print(name)\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","47821831":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n\n \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2)) ","98169880":"**Counting Number Of Null Elements**","d9830a6a":"**K Nearest Neighbour Classifier with best value of K (i.e. 3)**","05dd3c6f":"* **Deleting Unnamed 32 and declaring features and target for splitting **","bfa394b4":"**Declaring classifier (Knn) and checking best value for K**","81ae0d6a":"**Declaring Type In Binary i.e. 0 and 1 **","99ca7368":"**Reading CSV File**","9a76ea60":"**Import Libraries**","bf5f2889":"**Splitting Data**","22b763dd":"Confusion Matrix","40407149":"**Converting labels to one-hot-encoding**","58e6508b":"**Best Value of K graph**","ca9f595c":"**Accuracy : 0.99**","b66bccb7":"**Data Head**"}}