{"cell_type":{"7b069adc":"code","f6ea3230":"code","f37b3dda":"code","77ae70b5":"code","e1b3f2a9":"code","7ffbd739":"code","b7a4157c":"code","876e3860":"code","09cad35c":"code","70a19a33":"code","8f40596e":"code","18ede700":"code","ec235978":"code","6b36aedb":"code","696d7887":"code","c4ffd297":"code","aa0bc19a":"code","c0a14eef":"code","e5b5922b":"code","ab7b0206":"code","cfa3d952":"code","11afbb8f":"code","61f08bb6":"code","aa3b5e5f":"code","c26dd812":"code","c5cbf643":"code","08e832b3":"code","631e67d9":"code","83b590fb":"code","8fc21461":"code","124fa632":"code","db392c5d":"code","9823995b":"code","887f5ef9":"code","23246b03":"code","8453aabf":"code","8d9d7fbf":"code","45bbebfd":"code","0980f0cf":"code","dd4d4161":"code","2fc45187":"code","18fb8f54":"code","5ca74e7b":"code","60becbe2":"code","305f7fd4":"code","582272a4":"code","628ac205":"code","7de44ab4":"code","f5e3d5b7":"code","35edd0b3":"code","cc0caacb":"code","d7fb1bbb":"code","425a47b8":"code","007e9073":"code","9a1e3c3f":"code","d6016b52":"code","5d19d63a":"code","1422e5a7":"code","b96b5f1c":"code","9a3d2a86":"code","fcfbdf00":"code","45d0c25c":"code","133427a2":"code","614c2d0c":"code","b6a4e0ff":"code","7faba6f1":"code","2ebaa1f0":"code","78875c24":"code","4c05ff27":"code","6780633c":"code","b825f47f":"code","1761e302":"code","62205184":"code","90f839bb":"markdown","b89d7795":"markdown","7c3c6ac3":"markdown","a3b8cb76":"markdown","78bbca6e":"markdown","69cf9d3e":"markdown","44adbd66":"markdown","eca8b6c8":"markdown","d5a62c1f":"markdown","92f8805e":"markdown","3a2f857a":"markdown","ebff628e":"markdown"},"source":{"7b069adc":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\nimport optuna\nimport gc\nimport sys\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom category_encoders import OrdinalEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nimport lightgbm as lgb\n\n!pip install optuna\nimport optuna","f6ea3230":"filepath1 = \"\/kaggle\/input\/aiacademy-pickled-datasets\/\"\nfilepath2 = \"..\/input\/homework-for-students2\/\"\n\n# filepath1 = \"\"\n# filepath2 = \"..\/input\/\"","f37b3dda":"# \u30c6\u30fc\u30d6\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\ndf_train = pd.read_csv(filepath2+\"train.csv\",parse_dates = [\"issue_d\",\"earliest_cr_line\"])\ndf_test = pd.read_csv(filepath2+\"test.csv\",parse_dates = [\"issue_d\",\"earliest_cr_line\"])","77ae70b5":"# \u305d\u306e\u4ed6\u8a2d\u5b9a\nSEED = 139\nTARGET = \"loan_condition\"","e1b3f2a9":"# zip_code\u3068state\u306e\u30ab\u30c6\u30b4\u30ea\u3092\u4f5c\u6210\ndf_train[\"state_zip_code\"] = df_train[\"zip_code\"].astype(str)+\"_\"+df_train[\"addr_state\"].astype(str)\ndf_test[\"state_zip_code\"] = df_test[\"zip_code\"].astype(str)+\"_\"+df_test[\"addr_state\"].astype(str)\n\n# zip_code\u3092\u6570\u5024\u5316\ndf_test[\"zip_code\"] = df_test[\"zip_code\"].str[0:3].astype(int)\ndf_train[\"zip_code\"] = df_train[\"zip_code\"].str[0:3].astype(int)\n\n# \u6642\u9593\u3092\u4fdd\u5b58\ndf_train[\"issue_year\"]=df_train.issue_d.dt.year\ndf_train[\"issue_month\"]=df_train.issue_d.dt.month\ndf_train[\"earliest_cr_line_year\"]=df_train.earliest_cr_line.dt.year\ndf_train[\"earliest_cr_line_month\"]=df_train.earliest_cr_line.dt.month\ndf_test[\"issue_year\"]=df_test.issue_d.dt.year\ndf_test[\"issue_month\"]=df_test.issue_d.dt.month\ndf_test[\"earliest_cr_line_year\"]=df_test.earliest_cr_line.dt.year\ndf_test[\"earliest_cr_line_month\"]=df_test.earliest_cr_line.dt.month\n\n# \u30c0\u30df\u30fc\u30ab\u30e9\u30e0\u3092\u8ffd\u52a0\ndf_train[\"dummy\"] = 0\ndf_test[\"dummy\"] = 0\n\n# \u30c8\u30ec\u30a4\u30f3\u3068\u30c6\u30b9\u30c8\u3092\u533a\u5225\ndf_train[\"istest\"] = 0\ndf_test[\"istest\"] = 1","7ffbd739":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u4fdd\u5b58\ndf_train_base = df_train.copy()\ndf_test_base = df_test.copy()","b7a4157c":"# \u30c6\u30ad\u30b9\u30c8\u30ab\u30e9\u30e0\u3092\u4fdd\u5b58\ntxt_col = ['emp_title',\"title\"]\n\n# \u30ab\u30c6\u30b4\u30ea\u30ab\u30e9\u30e0\u306e\u62bd\u51fa\ncat = []\nfor col in df_train.columns:\n    if (df_train[col].dtype == \"object\") and (col not in txt_col ):\n        cat.append(col)\n\n# \u5229\u7528\u4e88\u5b9a\u306e\u30ab\u30e9\u30e0\nf_col = []\n        \n# \u524a\u9664\u30ab\u30e9\u30e0\ndel_col = []\n\n# \u4e0d\u8981\u306a\u30ab\u30e9\u30e0\u306b\u8ffd\u52a0\ndel_col.extend([\"ID\",\"issue_d\",\"earliest_cr_line\",'emp_title',\"title\",\"loan_condition\",\"istest\",\"dummy\"])","876e3860":"f_col = ['loan_amnt',\n 'installment',\n 'grade',\n 'sub_grade',\n 'home_ownership',\n 'annual_inc',\n 'purpose',\n 'zip_code',\n 'addr_state',\n 'dti',\n 'delinq_2yrs',\n 'inq_last_6mths',\n 'mths_since_last_delinq',\n 'mths_since_last_record',\n 'open_acc',\n 'pub_rec',\n 'revol_bal',\n 'revol_util',\n 'total_acc',\n 'collections_12_mths_ex_med',\n 'mths_since_last_major_derog',\n 'acc_now_delinq',\n 'tot_coll_amt',\n 'tot_cur_bal',\n 'state_zip_code',\n 'earliest_cr_line_year']","09cad35c":"del_col = ['ID',\n 'issue_d',\n 'earliest_cr_line',\n 'emp_title',\n 'title',\n 'loan_condition',\n 'istest',\n 'dummy',\n 'initial_list_status',\n 'application_type',\n 'issue_year',\n 'issue_month',\n 'earliest_cr_line_month']","70a19a33":"# numpy\u3068\u3057\u3066\u4fdd\u5b58\n\n# \u30ab\u30c6\u30b4\u30ea\u306f\u5909\u63db\u3057\u3066\u304a\u304f\nfor col in f_col:\n    if col in cat:\n        le = OrdinalEncoder()\n        le.fit(df_train[col].sort_values())    \n        df_train[col] = le.fit_transform(df_train[col])    \n        df_test[col] = le.transform(df_test[col])    \n        print(le.mapping)\n\nX_final_train = df_train.loc[:,f_col].values.astype(float)\ny_final_train = df_train[TARGET].values.astype(int)\nX_final_test = df_test.loc[:,f_col].values.astype(float)","8f40596e":"train_idx = df_train[(df_train.issue_year<2015) | (df_train.issue_month < 7)].index.tolist()\nval_idx = df_train[(df_train.issue_year == 2015) & (df_train.issue_month>=7)].index.tolist()","18ede700":"# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx","ec235978":"del df_train,df_test","6b36aedb":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u8aad\u307f\u8fbc\u307f\ndf_train = df_train_base.copy()\ndf_test = df_test_base.copy()","696d7887":"# emp_length\u3092\u6574\u7406\ndf_train.loc[df_train[\"emp_length\"] == '< 1 year',\"emp_length_year\"] = 0\ndf_train.loc[df_train[\"emp_length\"] == '1 year',\"emp_length_year\"] = 1\ndf_train.loc[df_train[\"emp_length\"] == '2 years',\"emp_length_year\"] = 2\ndf_train.loc[df_train[\"emp_length\"] == '3 years',\"emp_length_year\"] = 3\ndf_train.loc[df_train[\"emp_length\"] == '4 years',\"emp_length_year\"] = 4\ndf_train.loc[df_train[\"emp_length\"] == '5 years',\"emp_length_year\"] = 5\ndf_train.loc[df_train[\"emp_length\"] == '6 years',\"emp_length_year\"] = 6\ndf_train.loc[df_train[\"emp_length\"] == '7 years',\"emp_length_year\"] = 7\ndf_train.loc[df_train[\"emp_length\"] == '8 years',\"emp_length_year\"] = 8\ndf_train.loc[df_train[\"emp_length\"] == '9 years',\"emp_length_year\"] = 9\ndf_train.loc[df_train[\"emp_length\"] == '10+ years',\"emp_length_year\"] = 10\ndf_train.loc[df_train[\"emp_length\"] == '10+ years',\"over_10_year\"] = 1\ndf_train.loc[df_train[\"emp_length\"] != '10+ years',\"over_10_year\"] = 0\ndf_train.loc[df_train[\"emp_length\"] == '< 1 year',\"under_1_year\"] = 1\ndf_train.loc[df_train[\"emp_length\"] != '< 1 year',\"under_1_year\"] = 0\ndf_train[\"isnull_emp_length\"] = df_train[\"emp_length\"].isnull()*1\n\ndf_test.loc[df_test[\"emp_length\"] == '< 1 year',\"emp_length_year\"] = 0\ndf_test.loc[df_test[\"emp_length\"] == '1 year',\"emp_length_year\"] = 1\ndf_test.loc[df_test[\"emp_length\"] == '2 years',\"emp_length_year\"] = 2\ndf_test.loc[df_test[\"emp_length\"] == '3 years',\"emp_length_year\"] = 3\ndf_test.loc[df_test[\"emp_length\"] == '4 years',\"emp_length_year\"] = 4\ndf_test.loc[df_test[\"emp_length\"] == '5 years',\"emp_length_year\"] = 5\ndf_test.loc[df_test[\"emp_length\"] == '6 years',\"emp_length_year\"] = 6\ndf_test.loc[df_test[\"emp_length\"] == '7 years',\"emp_length_year\"] = 7\ndf_test.loc[df_test[\"emp_length\"] == '8 years',\"emp_length_year\"] = 8\ndf_test.loc[df_test[\"emp_length\"] == '9 years',\"emp_length_year\"] = 9\ndf_test.loc[df_test[\"emp_length\"] == '10+ years',\"emp_length_year\"] = 10\ndf_test.loc[df_test[\"emp_length\"] == '10+ years',\"over_10_year\"] = 1\ndf_test.loc[df_test[\"emp_length\"] != '10+ years',\"over_10_year\"] = 0\ndf_test.loc[df_test[\"emp_length\"] == '< 1 year',\"under_1_year\"] = 1\ndf_test.loc[df_test[\"emp_length\"] != '< 1 year',\"under_1_year\"] = 0\ndf_test[\"isnull_emp_length\"] = df_test[\"emp_length\"].isnull()*1\n\ndel_col.append(\"emp_length\")","c4ffd297":"# ISNULL\u30ab\u30e9\u30e0\u4f5c\u6210\ndf_train[\"isnull_annual_inc\"] = df_train[\"annual_inc\"].isnull()*1\ndf_train[\"isnull_delinq_2yrs\"] = df_train[\"delinq_2yrs\"].isnull()*1\ndf_train[\"isnull_mths_since_last_delinq\"] = df_train[\"mths_since_last_delinq\"].isnull()*1\ndf_train[\"isnull_mths_since_last_record\"] = df_train[\"mths_since_last_record\"].isnull()*1\ndf_train[\"isnull_mths_since_last_major_derog\"] = df_train[\"mths_since_last_major_derog\"].isnull()*1\ndf_train[\"isnull_emp_length\"] = df_train[\"emp_length\"].isnull()*1\ndf_train[\"isnull_emp_title\"] = df_train[\"emp_title\"].isnull()*1\ndf_train[\"isnull_inq_last_6mths\"] = df_train[\"inq_last_6mths\"].isnull()*1\ndf_train[\"isnull_collections_12_mths_ex_med\"] = df_train[\"collections_12_mths_ex_med\"].isnull()*1\ndf_train[\"isnull_pub_rec\"] = df_train[\"pub_rec\"].isnull()*1\n\ndf_test[\"isnull_annual_inc\"] = df_test[\"annual_inc\"].isnull()*1\ndf_test[\"isnull_delinq_2yrs\"] = df_test[\"delinq_2yrs\"].isnull()*1\ndf_test[\"isnull_mths_since_last_delinq\"] = df_test[\"mths_since_last_delinq\"].isnull()*1\ndf_test[\"isnull_mths_since_last_record\"] = df_test[\"mths_since_last_record\"].isnull()*1\ndf_test[\"isnull_mths_since_last_major_derog\"] = df_test[\"mths_since_last_major_derog\"].isnull()*1\ndf_test[\"isnull_emp_length\"] = df_test[\"emp_length\"].isnull()*1\ndf_test[\"isnull_emp_title\"] = df_test[\"emp_title\"].isnull()*1\ndf_test[\"isnull_inq_last_6mths\"] = df_test[\"inq_last_6mths\"].isnull()*1\ndf_test[\"isnull_collections_12_mths_ex_med\"] = df_test[\"collections_12_mths_ex_med\"].isnull()*1\ndf_test[\"isnull_pub_rec\"] = df_test[\"pub_rec\"].isnull()*1","aa0bc19a":"# \u30ea\u30dc\u6255\u3044\u306e\u6709\u7121\ndf_train[\"isnull_revol_util\"] = df_train[\"revol_util\"].isnull()*1\ndf_train[\"isnull_revol_bal\"] = df_train[\"revol_bal\"].isnull()*1\ndf_train[\"iszero_revol_util\"] = (df_train[\"revol_util\"] <= 0)*1\ndf_train[\"iszero_revol_bal\"] = (df_train[\"revol_bal\"] <= 0)*1\n\ndf_test[\"isnull_revol_util\"] = df_test[\"revol_util\"].isnull()*1\ndf_test[\"isnull_revol_bal\"] = df_test[\"revol_bal\"].isnull()*1\ndf_test[\"iszero_revol_util\"] = (df_test[\"revol_util\"] <= 0)*1\ndf_test[\"iszero_revol_bal\"] = (df_test[\"revol_bal\"] <= 0)*1","c0a14eef":"# Subgrade\u306e\u5206\u96e2\ndf_train[\"sub_grade_num\"] = df_train[\"sub_grade\"].str[1].astype(int)\ndf_test[\"sub_grade_num\"] = df_test[\"sub_grade\"].str[1].astype(int)","e5b5922b":"# \u5916\u90e8\u30c7\u30fc\u30bf\u306eGDP\u30ed\u30fc\u30c9\ndf_GDP = pd.read_csv(filepath2+\"US_GDP_by_State.csv\").rename(columns={\"State\":\"City\"})\ndf_GDP[\"SLS\/PM\"] = df_GDP[\"State & Local Spending\"]\/df_GDP[\"Population (million)\"]\ndf_GDP[\"GSP\/PM\"] = df_GDP[\"Gross State Product\"]\/df_GDP[\"Population (million)\"]\ndf_GDP[\"RSG\/PM\"] = df_GDP[\"Real State Growth %\"]\/df_GDP[\"Population (million)\"]\ndf_GDP[\"SLS\/GSP\"] = df_GDP[\"State & Local Spending\"]\/df_GDP[\"Gross State Product\"]\ndf_GDP[\"RSG\/SLS\"] = df_GDP[\"Real State Growth %\"]\/df_GDP[\"State & Local Spending\"]\ndf_GDP[\"GSP\/RSG\"] = df_GDP[\"Gross State Product\"]\/df_GDP[\"Real State Growth %\"]\n\ndf_GDP_2013 = df_GDP[df_GDP[\"year\"]==2013].drop(\"year\",axis=1)\ndf_GDP_2014 = df_GDP[df_GDP[\"year\"]==2014].drop(\"year\",axis=1)\ndf_GDP_2015 = df_GDP[df_GDP[\"year\"]==2015].drop(\"year\",axis=1)\n\ndf_GDP_2013.columns = df_GDP_2013.columns.map(lambda x:\"2013_\"+x if x != \"City\" else x)\ndf_GDP_2014.columns = df_GDP_2014.columns.map(lambda x:\"2014_\"+x if x != \"City\" else x)\ndf_GDP_2015.columns = df_GDP_2015.columns.map(lambda x:\"2015_\"+x if x != \"City\" else x)\n\ndf_GDP_year = pd.merge(pd.merge(df_GDP_2013,df_GDP_2014,on=\"City\",how=\"left\"),df_GDP_2015,on=\"City\",how=\"left\")","ab7b0206":"df_GDP_year[\"diff_SLS_14-13\"] = df_GDP_year[\"2014_State & Local Spending\"] - df_GDP_year[\"2013_State & Local Spending\"]\ndf_GDP_year[\"diff_SLS_15-14\"] = df_GDP_year[\"2015_State & Local Spending\"] - df_GDP_year[\"2014_State & Local Spending\"]\ndf_GDP_year[\"diff_SLS_15-13\"] = df_GDP_year[\"2015_State & Local Spending\"] - df_GDP_year[\"2013_State & Local Spending\"]\n\ndf_GDP_year[\"diff_GSP_14-13\"] = df_GDP_year[\"2014_Gross State Product\"] - df_GDP_year[\"2013_Gross State Product\"]\ndf_GDP_year[\"diff_GSP_15-14\"] = df_GDP_year[\"2015_Gross State Product\"] - df_GDP_year[\"2014_Gross State Product\"]\ndf_GDP_year[\"diff_GSP_15-13\"] = df_GDP_year[\"2015_Gross State Product\"] - df_GDP_year[\"2013_Gross State Product\"]\n\ndf_GDP_year[\"diff_RSG_14-13\"] = df_GDP_year[\"2014_Real State Growth %\"] - df_GDP_year[\"2013_Real State Growth %\"]\ndf_GDP_year[\"diff_RSG_15-14\"] = df_GDP_year[\"2015_Real State Growth %\"] - df_GDP_year[\"2014_Real State Growth %\"]\ndf_GDP_year[\"diff_RSG_15-13\"] = df_GDP_year[\"2015_Real State Growth %\"] - df_GDP_year[\"2013_Real State Growth %\"]\n\ndf_GDP_year[\"diff_PM_14-13\"] = df_GDP_year[\"2014_Population (million)\"] - df_GDP_year[\"2013_Population (million)\"]\ndf_GDP_year[\"diff_PM_15-14\"] = df_GDP_year[\"2015_Population (million)\"] - df_GDP_year[\"2014_Population (million)\"]\ndf_GDP_year[\"diff_PM_15-13\"] = df_GDP_year[\"2015_Population (million)\"] - df_GDP_year[\"2013_Population (million)\"]","cfa3d952":"df_state = pd.read_csv(filepath2+\"statelatlong.csv\")\nstate_GDP = pd.merge(df_state,df_GDP_year,on=\"City\",how=\"left\").drop(\"City\",axis=1)\nstate_GDP = state_GDP.rename(columns={\"State\":\"addr_state\"})","11afbb8f":"# \u5916\u90e8\u30c7\u30fc\u30bf\u306efree-zipcode-database.csv\u30ed\u30fc\u30c9\ndf_zip = pd.read_csv(filepath2+\"free-zipcode-database.csv\").rename(columns = {\"State\":\"addr_state\"})\ndf_zip[\"zip_code\"] = df_zip[\"Zipcode\"].astype(str).str[0:3].astype(int)\n\ndf_zip = df_zip[(~df_zip[\"TaxReturnsFiled\"].isnull()) |(~df_zip[\"EstimatedPopulation\"].isnull()) |(~df_zip[\"TotalWages\"].isnull())]\n\ndf_zip_min = df_zip.groupby([\"addr_state\",\"zip_code\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].min()\ndf_zip_min.columns = [\"addr_state\",\"zip_code\",\"min_TaxReturnsFiled\",\"min_EstimatedPopulation\",\"min_TotalWages\"]\ndf_zip_mean = df_zip.groupby([\"addr_state\",\"zip_code\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].mean()\ndf_zip_mean.columns = [\"addr_state\",\"zip_code\",\"mean_TaxReturnsFiled\",\"mean_EstimatedPopulation\",\"mean_TotalWages\"]\ndf_zip_max = df_zip.groupby([\"addr_state\",\"zip_code\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].max()\ndf_zip_max.columns = [\"addr_state\",\"zip_code\",\"max_TaxReturnsFiled\",\"max_EstimatedPopulation\",\"max_TotalWages\"]\n\ndf_zip_state_min = df_zip.groupby([\"addr_state\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].min()\ndf_zip_state_min.columns = [\"addr_state\",\"min_TaxReturnsFiled_state\",\"min_EstimatedPopulation_state\",\"min_TotalWages_state\"]\ndf_zip_state_mean = df_zip.groupby([\"addr_state\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].mean()\ndf_zip_state_mean.columns = [\"addr_state\",\"mean_TaxReturnsFiled_state\",\"mean_EstimatedPopulation_state_state\",\"mean_TotalWages_state\"]\ndf_zip_state_max = df_zip.groupby([\"addr_state\"],as_index=False)[\"TaxReturnsFiled\",\"EstimatedPopulation\",\"TotalWages\"].max()\ndf_zip_state_max.columns = [\"addr_state\",\"max_TaxReturnsFiled_state\",\"max_EstimatedPopulation_state\",\"max_TotalWages_state\"]","61f08bb6":"df_zip_zip = pd.merge(df_zip_max,pd.merge(df_zip_min,df_zip_mean,on=[\"addr_state\",\"zip_code\"],how=\"left\"),on=[\"addr_state\",\"zip_code\"],how=\"left\")\ndf_zip_state = pd.merge(df_zip_state_max,pd.merge(df_zip_state_min,df_zip_state_mean,on=[\"addr_state\"],how=\"left\"),on=[\"addr_state\"],how=\"left\")","aa3b5e5f":"# Train\/Test\u306b\u30de\u30fc\u30b8\ndf_train = pd.merge(df_train,state_GDP,on=\"addr_state\",how=\"left\")\ndf_test = pd.merge(df_test,state_GDP,on=\"addr_state\",how=\"left\")\ndel df_GDP,df_GDP_2013,df_GDP_2014,df_GDP_2015,df_GDP_year,state_GDP","c26dd812":"# \u305d\u308c\u305e\u308c\u3092Train\u306b\u30de\u30fc\u30b8\ndf_train = pd.merge(df_train,df_zip_zip,on=[\"addr_state\",\"zip_code\"],how=\"left\")\ndf_train = pd.merge(df_train,df_zip_state,on=[\"addr_state\"],how=\"left\")\n\ndf_test = pd.merge(df_test,df_zip_zip,on=[\"addr_state\",\"zip_code\"],how=\"left\")\ndf_test = pd.merge(df_test,df_zip_state,on=[\"addr_state\"],how=\"left\")\ndel df_zip,df_zip_zip,df_zip_state,df_zip_max,df_zip_mean,df_zip_min","c5cbf643":"# \u30bf\u30a4\u30c8\u30eb\u3092\u96c6\u8a08\ndf_train[\"title\"] = df_train[\"title\"].str.lower().str.strip()\ndf_train[\"len_title\"] = df_train[\"title\"].str.len()\ndf_train[\"len_title\"] = df_train[\"len_title\"].astype(float)\n\ndf_test[\"title\"] = df_test[\"title\"].str.lower().str.strip()\ndf_test[\"len_title\"] = df_test[\"title\"].str.len()\ndf_test[\"len_title\"] = df_test[\"len_title\"].astype(float)\n\ndf_train[\"num_of_words_title\"] = df_train[\"title\"].astype(str).str.split(\" \").apply(lambda x:len(x))\ndf_test[\"num_of_words_title\"] = df_test[\"title\"].astype(str).str.split(\" \").apply(lambda x:len(x))","08e832b3":"# \u8077\u696d\u3092\u96c6\u8a08\ndf_train[\"emp_title\"] = df_train[\"emp_title\"].str.lower().str.strip()\ndf_train[\"len_emp_title\"] = df_train[\"emp_title\"].str.len()\ndf_test[\"emp_title\"] = df_test[\"emp_title\"].str.lower().str.strip()\ndf_test[\"len_emp_title\"] = df_test[\"emp_title\"].str.len()\ndf_train[\"num_of_words_emp_title\"] = df_train[\"emp_title\"].astype(str).str.split(\" \").apply(lambda x:len(x))\ndf_test[\"num_of_words_emp_title\"] = df_test[\"emp_title\"].astype(str).str.split(\" \").apply(lambda x:len(x))\n\n# TOP30\u4ee5\u5916\u3092other\u3068\u3057\u3066\u3067\u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\ntmp = df_train[\"emp_title\"] .value_counts()\ndf_train[\"emp_title_label\"] = df_train[\"emp_title\"]\ndf_train.loc[~df_train[\"emp_title_label\"].isin(tmp[0:30].index),\"emp_title_label\"]  = \"others\"\ndf_test[\"emp_title_label\"] = df_test[\"emp_title\"]\ndf_test.loc[~df_test[\"emp_title_label\"].isin(tmp[0:30].index),\"emp_title_label\"]  = \"others\"\n\ncat.append(\"emp_title_label\")","631e67d9":"new_col = ['emp_length_year',\n 'over_10_year',\n 'under_1_year',\n 'isnull_emp_length',\n 'isnull_mths_since_last_delinq',\n 'isnull_mths_since_last_record',\n 'isnull_mths_since_last_major_derog',\n 'isnull_emp_title',\n 'iszero_revol_util',\n 'iszero_revol_bal',\n 'sub_grade_num',\n 'Latitude',\n 'Longitude',\n '2013_State & Local Spending',\n '2013_Gross State Product',\n '2013_Real State Growth %',\n '2013_Population (million)',\n '2013_SLS\/PM',\n '2013_GSP\/PM',\n '2013_RSG\/PM',\n '2013_SLS\/GSP',\n '2013_RSG\/SLS',\n '2013_GSP\/RSG',\n '2014_State & Local Spending',\n '2014_Gross State Product',\n '2014_Real State Growth %',\n '2014_Population (million)',\n '2014_SLS\/PM',\n '2014_GSP\/PM',\n '2014_RSG\/PM',\n '2014_SLS\/GSP',\n '2014_RSG\/SLS',\n '2014_GSP\/RSG',\n '2015_State & Local Spending',\n '2015_Gross State Product',\n '2015_Real State Growth %',\n '2015_Population (million)',\n '2015_SLS\/PM',\n '2015_GSP\/PM',\n '2015_RSG\/PM',\n '2015_SLS\/GSP',\n '2015_RSG\/SLS',\n '2015_GSP\/RSG',\n 'diff_SLS_14-13',\n 'diff_SLS_15-14',\n 'diff_SLS_15-13',\n 'diff_GSP_14-13',\n 'diff_GSP_15-14',\n 'diff_GSP_15-13',\n 'diff_RSG_14-13',\n 'diff_RSG_15-14',\n 'diff_RSG_15-13',\n 'diff_PM_14-13',\n 'diff_PM_15-14',\n 'diff_PM_15-13',\n 'max_TaxReturnsFiled',\n 'max_EstimatedPopulation',\n 'max_TotalWages',\n 'min_TaxReturnsFiled',\n 'min_EstimatedPopulation',\n 'min_TotalWages',\n 'mean_TaxReturnsFiled',\n 'mean_EstimatedPopulation',\n 'mean_TotalWages',\n 'max_TaxReturnsFiled_state',\n 'max_EstimatedPopulation_state',\n 'max_TotalWages_state',\n 'min_TaxReturnsFiled_state',\n 'min_EstimatedPopulation_state',\n 'min_TotalWages_state',\n 'mean_TaxReturnsFiled_state',\n 'mean_EstimatedPopulation_state_state',\n 'mean_TotalWages_state',\n 'len_title',\n 'num_of_words_title',\n 'len_emp_title',\n 'num_of_words_emp_title',\n 'emp_title_label']","83b590fb":"f_col.extend(new_col)\n\n# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx","8fc21461":"# \u30ab\u30c6\u30b4\u30ea\u306f\u5909\u63db\u3057\u3066\u304a\u304f\nfor col in new_col:\n    if col in cat:\n        le = OrdinalEncoder()\n        le.fit(df_train[col].sort_values())    \n        df_train[col] = le.fit_transform(df_train[col])    \n        df_test[col] = le.transform(df_test[col])    \n        print(le.mapping)\n\n# numpy\u3068\u3057\u3066\u4fdd\u5b58\nX_train_new = df_train.loc[:,new_col].values.astype(float)\nX_test_new = df_test.loc[:,new_col].values.astype(float)\nX_final_train = np.hstack([X_final_train, X_train_new])\nX_final_test = np.hstack([X_final_test, X_test_new])","124fa632":"# \u30e1\u30e2\u30ea\u78ba\u4fdd\ndel df_train,df_test,X_train_new,X_test_new,tmp\ngc.collect()","db392c5d":"# \u4e0b\u6e96\u5099\nisTest_train = np.zeros(X_final_train.shape[0]).reshape(X_final_train.shape[0],-1)\nisTest_test = np.ones(X_final_test.shape[0]).reshape(X_final_test.shape[0],-1)\n\ny = np.vstack([isTest_train,isTest_test])\ny = y.flatten()\nX = np.vstack([X_final_train,X_final_test])\ndel isTest_test,isTest_train\n\nleak_name = [\"title\",\"issue_d\",\"issue_year\",\"issue_month\",\"earliest_cr_line_year\",\"earliest_cr_line_month\",\"issue_earliest_cr_line_diff\"]\n\nleak_col = []\nfor leak in leak_name:\n    leak_col.extend([s for s in f_col if leak in s])\nleak_col = list(set(leak_col))\n\ninc_col = []\ninc_col_idx = []\nfor col in f_col :\n    if col not in leak_col:\n        inc_col_idx.append(f_col_num[col])\n        inc_col.append(col)\n        \nX = X[:,inc_col_idx]","9823995b":"skf=StratifiedKFold(n_splits=5, shuffle=True,random_state=SEED)\n\ny_oof = np.zeros(len(y))\nfeature_imortance = np.zeros(len(inc_col))\n\nparams = {\n    'objective': 'binary',\n    'metric':\"auc\",\n    'n_estimators': 2000\n}\n\nfor train_ix, test_ix in tqdm(skf.split(X, y)):\n    X_train, y_train = X[train_ix], y[train_ix]\n    X_val, y_val = X[test_ix], y[test_ix]\n\n    clf =  lgb.LGBMClassifier(**params)\n    clf.fit(X_train, y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=200, verbose=200)\n    \n    y_oof[test_ix] = clf.predict_proba(X_val)[:,1]\n    feature_imortance += clf.feature_importances_\/5\n    del X_train, y_train,X_val, y_val\n\nfeature_imp = pd.DataFrame(feature_imortance,index = inc_col,columns =[\"feature_imortance\"]).sort_values(\"feature_imortance\")\nfig, ax = plt.subplots(1, 1, figsize=(12, 12))\nfeature_imp[-50:].plot(kind=\"barh\",ax=ax,color=\"b\")\n    \nscore = pd.DataFrame(y_oof[:X_final_train.shape[0]],columns=[\"Score\"])\nscore.to_csv(\"Av_Score.csv\")","887f5ef9":"# \u4e0b\u4f4d20%\u3092\u9664\u53bb\nav_idx = score[score[\"Score\"]>0.2].index.tolist()","23246b03":"# #\u30e1\u30e2\u30ea\u306e\u8868\u793a\n# print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n# print(\" ------------------------------------ \")\n# for var_name in dir():\n#     if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #\u3053\u3053\u3060\u3051\u30a2\u30ec\u30f3\u30b8\n#         print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","8453aabf":"# \u30e1\u30e2\u30ea\u78ba\u4fdd\ndel X,y,feature_imp,idx,y_oof,test_ix,train_ix\ngc.collect()","8d9d7fbf":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u8aad\u307f\u8fbc\u307f\ndf_train = df_train_base.copy()\ndf_test = df_test_base.copy()","45bbebfd":"# \u7533\u544a\u5e74\u53ce\u306b\u5bfe\u3059\u308b\u4ea4\u4e92\u4f5c\u7528\ndf_train[\"loan_amnt_div_annual_inc\"]=df_train[\"loan_amnt\"]\/(df_train[\"annual_inc\"]+1e6)\ndf_train[\"installment_div_annual_inc\"]=df_train[\"installment\"]\/(df_train[\"annual_inc\"]+1e6)\ndf_train[\"tot_cur_bal_div_annual_inc\"]=df_train[\"tot_cur_bal\"]\/(df_train[\"annual_inc\"]+1e6)\ndf_train[\"revol_bal_div_annual_inc\"]=df_train[\"revol_bal\"]\/(df_train[\"annual_inc\"]+1e6)\ndf_train[\"tot_coll_amt_div_annual_inc\"]=df_train[\"tot_coll_amt\"]\/(df_train[\"annual_inc\"]+1e6)\n\n# \u56de\u53ce\u7387\ndf_train[\"tot_coll_amt_div_tot_cur_bal\"]=df_train[\"tot_coll_amt\"]\/(df_train[\"tot_cur_bal\"]+1e6)\ndf_train[\"tot_coll_amt_div_loan_amnt\"]=df_train[\"tot_coll_amt\"]\/(df_train[\"loan_amnt\"]+1e6)\ndf_train[\"tot_cur_bal_div_loan_amnt\"]=df_train[\"tot_cur_bal\"]\/(df_train[\"loan_amnt\"]+1e6)\n\n# \u30ed\u30fc\u30f3\u984d\/\u53e3\u5ea7\u958b\u8a2d\u6570\ndf_train[\"loan_amnt_div_open_acc\"]=df_train[\"loan_amnt\"]\/(df_train[\"open_acc\"]+1e6)\ndf_train[\"installment_div_open_acc\"]=df_train[\"installment\"]\/(df_train[\"open_acc\"]+1e6)\ndf_train[\"tot_cur_bal_div_open_acc\"]=df_train[\"tot_cur_bal\"]\/(df_train[\"open_acc\"]+1e6)\n\n# \u30ea\u30dc\u6255\u3044\u306e\u4ea4\u4e92\u4f5c\u7528\ndf_train[\"revol_bal_div_revol_util\"]=df_train[\"revol_bal\"]\/(df_train[\"revol_util\"]+1e6)\ndf_train[\"revol_bal_div_tot_cur_bal\"]=df_train[\"revol_bal\"]\/(df_train[\"tot_cur_bal\"]+1e6)\ndf_train[\"revol_bal_div_installment\"]=df_train[\"revol_bal\"]\/(df_train[\"installment\"]+1e6)\ndf_train[\"revol_bal_div_revol_util\"]=df_train[\"installment\"]*df_train[\"revol_util\"]","0980f0cf":"# \u7533\u544a\u5e74\u53ce\u306b\u5bfe\u3059\u308b\u4ea4\u4e92\u4f5c\u7528\ndf_test[\"loan_amnt_div_annual_inc\"]=df_test[\"loan_amnt\"]\/(df_test[\"annual_inc\"]+1e6)\ndf_test[\"installment_div_annual_inc\"]=df_test[\"installment\"]\/(df_test[\"annual_inc\"]+1e6)\ndf_test[\"tot_cur_bal_div_annual_inc\"]=df_test[\"tot_cur_bal\"]\/(df_test[\"annual_inc\"]+1e6)\ndf_test[\"revol_bal_div_annual_inc\"]=df_test[\"revol_bal\"]\/(df_test[\"annual_inc\"]+1e6)\ndf_test[\"tot_coll_amt_div_annual_inc\"]=df_test[\"tot_coll_amt\"]\/(df_test[\"annual_inc\"]+1e6)\n\n# \u56de\u53ce\u7387\ndf_test[\"tot_coll_amt_div_tot_cur_bal\"]=df_test[\"tot_coll_amt\"]\/(df_test[\"tot_cur_bal\"]+1e6)\ndf_test[\"tot_coll_amt_div_loan_amnt\"]=df_test[\"tot_coll_amt\"]\/(df_test[\"loan_amnt\"]+1e6)\ndf_test[\"tot_cur_bal_div_loan_amnt\"]=df_test[\"tot_cur_bal\"]\/(df_test[\"loan_amnt\"]+1e6)\n\n# \u30ed\u30fc\u30f3\u984d\/\u53e3\u5ea7\u958b\u8a2d\u6570\ndf_test[\"loan_amnt_div_open_acc\"]=df_test[\"loan_amnt\"]\/(df_test[\"open_acc\"]+1e6)\ndf_test[\"installment_div_open_acc\"]=df_test[\"installment\"]\/(df_test[\"open_acc\"]+1e6)\ndf_test[\"tot_cur_bal_div_open_acc\"]=df_test[\"tot_cur_bal\"]\/(df_test[\"open_acc\"]+1e6)\n\n# \u30ea\u30dc\u6255\u3044\u306e\u4ea4\u4e92\u4f5c\u7528\ndf_test[\"revol_bal_div_revol_util\"]=df_test[\"revol_bal\"]\/(df_test[\"revol_util\"]+1e6)\ndf_test[\"revol_bal_div_tot_cur_bal\"]=df_test[\"revol_bal\"]\/(df_test[\"tot_cur_bal\"]+1e6)\ndf_test[\"revol_bal_div_installment\"]=df_test[\"revol_bal\"]\/(df_test[\"installment\"]+1e6)\ndf_test[\"revol_bal_div_revol_util\"]=df_test[\"installment\"]*df_test[\"revol_util\"]","dd4d4161":"# \u6700\u65b0\u65e5\u3068\u306e\u5dee\u5206\ndf_train[\"issue_d_diff\"] = (df_test[\"issue_d\"].max()-df_train[\"issue_d\"]).astype(int)\ndf_test[\"issue_d_diff\"] = (df_test[\"issue_d\"].max()-df_test[\"issue_d\"]).astype(int)\n\n# earliest_cr_line\u3068\u306e\u5dee\u5206\ndf_train[\"issue_earliest_cr_line_diff\"] = (df_train[\"earliest_cr_line\"]-df_train[\"issue_d\"]).astype(int)\ndf_test[\"issue_earliest_cr_line_diff\"] = (df_test[\"earliest_cr_line\"]-df_test[\"issue_d\"]).astype(int)","2fc45187":"# \u96c6\u8a08\u7528\u306bTrain\/Test\u3092\u30de\u30fc\u30b8\ndf_merge = pd.concat([df_train.drop(TARGET,axis=1),df_test])\n\n# \u30b0\u30ec\u30fc\u30c9\u6bce\u306e\u96c6\u8a08\u3001\u30b5\u30d6\u30b0\u30ec\u30fc\u30c9\u6bce\u306e\u96c6\u8a08\u3001\u5bb6\u6301\u3061\u3054\u3068\u306e\u96c6\u8a08\nparents_col = [\"grade\",\"sub_grade\",\"home_ownership\",\"purpose\",\"zip_code\",\"addr_state\",\"state_zip_code\"]\nagg_cat = [\"annual_inc\",\"installment\",\"tot_cur_bal\",\"revol_bal\",\"open_acc\",\"tot_coll_amt\",\"dti\"]\n\nfor pcol in tqdm(parents_col):\n    df_agg = df_merge.groupby(pcol,as_index=False)[\"issue_d\"].count().rename(columns={\"issue_d\":f\"{pcol}_count\"})\n    for col in agg_cat:\n        df_agg = pd.merge(df_agg,df_merge.groupby(pcol,as_index=False)[col].max().rename(columns={col:f\"{pcol}_{col}_max\"}),on = pcol,how=\"left\")\n        df_agg = pd.merge(df_agg,df_merge.groupby(pcol,as_index=False)[col].min().rename(columns={col:f\"{pcol}_{col}_min\"}),on = pcol,how=\"left\")\n        df_agg = pd.merge(df_agg,df_merge.groupby(pcol,as_index=False)[col].mean().rename(columns={col:f\"{pcol}_{col}_mean\"}),on = pcol,how=\"left\")\n        df_agg = pd.merge(df_agg,df_merge.groupby(pcol)[col].std().reset_index().rename(columns={col:f\"{pcol}_{col}_std\"}),on = pcol,how=\"left\")\n    df_train = pd.merge(df_train,df_agg,on=pcol,how=\"left\")\n    df_test = pd.merge(df_test,df_agg,on=pcol,how=\"left\")\n    del df_agg\ndel df_merge\ngc.collect()\n\n# \u5e73\u5747\u3068\u306e\u5dee\u5206\u3068DIV\n# \u30b0\u30ec\u30fc\u30c9\u6bce\u306e\u96c6\u8a08\u3001\u30b5\u30d6\u30b0\u30ec\u30fc\u30c9\u6bce\u306e\u96c6\u8a08\u3001\u5bb6\u6301\u3061\u3054\u3068\u306e\u96c6\u8a08\nparents_col = [\"grade\",\"sub_grade\",\"home_ownership\",\"purpose\",\"zip_code\",\"addr_state\",\"state_zip_code\"]\nagg_cat = [\"annual_inc\",\"installment\",\"tot_cur_bal\",\"revol_bal\",\"open_acc\",\"tot_coll_amt\",\"dti\"]\n\nfor pcol in tqdm(parents_col):\n    for col in agg_cat:\n        df_train[f\"{pcol}_{col}_diff\"] = df_train[col] - df_train[f\"{pcol}_{col}_mean\"]\n        df_train[f\"{pcol}_{col}_div\"] = df_train[col] \/( df_train[f\"{pcol}_{col}_mean\"]+1e6)\n        df_test[f\"{pcol}_{col}_diff\"] = df_test[col] - df_test[f\"{pcol}_{col}_mean\"]\n        df_test[f\"{pcol}_{col}_div\"] = df_test[col] \/( df_test[f\"{pcol}_{col}_mean\"]+1e6)\n\nnew_col = ['loan_amnt_div_annual_inc',\n 'installment_div_annual_inc',\n 'tot_cur_bal_div_annual_inc',\n 'revol_bal_div_annual_inc',\n 'tot_coll_amt_div_annual_inc',\n 'tot_coll_amt_div_tot_cur_bal',\n 'tot_coll_amt_div_loan_amnt',\n 'tot_cur_bal_div_loan_amnt',\n 'loan_amnt_div_open_acc',\n 'installment_div_open_acc',\n 'tot_cur_bal_div_open_acc',\n 'revol_bal_div_revol_util',\n 'revol_bal_div_tot_cur_bal',\n 'revol_bal_div_installment',\n 'issue_earliest_cr_line_diff',\n 'grade_count',\n 'grade_annual_inc_max',\n 'grade_annual_inc_mean',\n 'grade_annual_inc_std',\n 'grade_installment_max',\n 'grade_installment_min',\n 'grade_installment_mean',\n 'grade_installment_std',\n 'grade_tot_cur_bal_max',\n 'grade_tot_cur_bal_mean',\n 'grade_tot_cur_bal_std',\n 'grade_revol_bal_max',\n 'grade_revol_bal_mean',\n 'grade_revol_bal_std',\n 'grade_open_acc_max',\n 'grade_open_acc_min',\n 'grade_open_acc_mean',\n 'grade_open_acc_std',\n 'grade_tot_coll_amt_max',\n 'grade_tot_coll_amt_mean',\n 'grade_tot_coll_amt_std',\n 'grade_dti_max',\n 'grade_dti_min',\n 'grade_dti_mean',\n 'grade_dti_std',\n 'sub_grade_count',\n 'sub_grade_annual_inc_max',\n 'sub_grade_annual_inc_min',\n 'sub_grade_annual_inc_mean',\n 'sub_grade_annual_inc_std',\n 'sub_grade_installment_max',\n 'sub_grade_installment_min',\n 'sub_grade_installment_mean',\n 'sub_grade_installment_std',\n 'sub_grade_tot_cur_bal_max',\n 'sub_grade_tot_cur_bal_min',\n 'sub_grade_tot_cur_bal_mean',\n 'sub_grade_tot_cur_bal_std',\n 'sub_grade_revol_bal_max',\n 'sub_grade_revol_bal_mean',\n 'sub_grade_revol_bal_std',\n 'sub_grade_open_acc_max',\n 'sub_grade_open_acc_min',\n 'sub_grade_open_acc_mean',\n 'sub_grade_open_acc_std',\n 'sub_grade_tot_coll_amt_max',\n 'sub_grade_tot_coll_amt_mean',\n 'sub_grade_tot_coll_amt_std',\n 'sub_grade_dti_max',\n 'sub_grade_dti_min',\n 'sub_grade_dti_mean',\n 'sub_grade_dti_std',\n 'home_ownership_count',\n 'home_ownership_annual_inc_max',\n 'home_ownership_annual_inc_mean',\n 'home_ownership_annual_inc_std',\n 'home_ownership_installment_max',\n 'home_ownership_installment_min',\n 'home_ownership_installment_mean',\n 'home_ownership_installment_std',\n 'home_ownership_tot_cur_bal_max',\n 'home_ownership_tot_cur_bal_mean',\n 'home_ownership_tot_cur_bal_std',\n 'home_ownership_revol_bal_max',\n 'home_ownership_revol_bal_mean',\n 'home_ownership_revol_bal_std',\n 'home_ownership_open_acc_max',\n 'home_ownership_open_acc_min',\n 'home_ownership_open_acc_mean',\n 'home_ownership_open_acc_std',\n 'home_ownership_tot_coll_amt_max',\n 'home_ownership_tot_coll_amt_mean',\n 'home_ownership_tot_coll_amt_std',\n 'home_ownership_dti_max',\n 'home_ownership_dti_min',\n 'home_ownership_dti_mean',\n 'home_ownership_dti_std',\n 'purpose_count',\n 'purpose_annual_inc_max',\n 'purpose_annual_inc_min',\n 'purpose_annual_inc_mean',\n 'purpose_annual_inc_std',\n 'purpose_installment_max',\n 'purpose_installment_min',\n 'purpose_installment_mean',\n 'purpose_installment_std',\n 'purpose_tot_cur_bal_max',\n 'purpose_tot_cur_bal_min',\n 'purpose_tot_cur_bal_mean',\n 'purpose_tot_cur_bal_std',\n 'purpose_revol_bal_max',\n 'purpose_revol_bal_mean',\n 'purpose_revol_bal_std',\n 'purpose_open_acc_max',\n 'purpose_open_acc_min',\n 'purpose_open_acc_mean',\n 'purpose_open_acc_std',\n 'purpose_tot_coll_amt_max',\n 'purpose_tot_coll_amt_mean',\n 'purpose_tot_coll_amt_std',\n 'purpose_dti_max',\n 'purpose_dti_min',\n 'purpose_dti_mean',\n 'purpose_dti_std',\n 'zip_code_count',\n 'zip_code_annual_inc_max',\n 'zip_code_annual_inc_min',\n 'zip_code_annual_inc_mean',\n 'zip_code_annual_inc_std',\n 'zip_code_installment_max',\n 'zip_code_installment_min',\n 'zip_code_installment_mean',\n 'zip_code_installment_std',\n 'zip_code_tot_cur_bal_max',\n 'zip_code_tot_cur_bal_min',\n 'zip_code_tot_cur_bal_mean',\n 'zip_code_tot_cur_bal_std',\n 'zip_code_revol_bal_max',\n 'zip_code_revol_bal_min',\n 'zip_code_revol_bal_mean',\n 'zip_code_revol_bal_std',\n 'zip_code_open_acc_max',\n 'zip_code_open_acc_min',\n 'zip_code_open_acc_mean',\n 'zip_code_open_acc_std',\n 'zip_code_tot_coll_amt_max',\n 'zip_code_tot_coll_amt_mean',\n 'zip_code_tot_coll_amt_std',\n 'zip_code_dti_max',\n 'zip_code_dti_min',\n 'zip_code_dti_mean',\n 'zip_code_dti_std',\n 'addr_state_count',\n 'addr_state_annual_inc_max',\n 'addr_state_annual_inc_min',\n 'addr_state_annual_inc_mean',\n 'addr_state_annual_inc_std',\n 'addr_state_installment_max',\n 'addr_state_installment_min',\n 'addr_state_installment_mean',\n 'addr_state_installment_std',\n 'addr_state_tot_cur_bal_max',\n 'addr_state_tot_cur_bal_min',\n 'addr_state_tot_cur_bal_mean',\n 'addr_state_tot_cur_bal_std',\n 'addr_state_revol_bal_max',\n 'addr_state_revol_bal_mean',\n 'addr_state_revol_bal_std',\n 'addr_state_open_acc_max',\n 'addr_state_open_acc_min',\n 'addr_state_open_acc_mean',\n 'addr_state_open_acc_std',\n 'addr_state_tot_coll_amt_max',\n 'addr_state_tot_coll_amt_mean',\n 'addr_state_tot_coll_amt_std',\n 'addr_state_dti_max',\n 'addr_state_dti_min',\n 'addr_state_dti_mean',\n 'addr_state_dti_std',\n 'state_zip_code_count',\n 'state_zip_code_annual_inc_max',\n 'state_zip_code_annual_inc_min',\n 'state_zip_code_annual_inc_mean',\n 'state_zip_code_annual_inc_std',\n 'state_zip_code_installment_max',\n 'state_zip_code_installment_min',\n 'state_zip_code_installment_mean',\n 'state_zip_code_installment_std',\n 'state_zip_code_tot_cur_bal_max',\n 'state_zip_code_tot_cur_bal_min',\n 'state_zip_code_tot_cur_bal_mean',\n 'state_zip_code_tot_cur_bal_std',\n 'state_zip_code_revol_bal_max',\n 'state_zip_code_revol_bal_min',\n 'state_zip_code_revol_bal_mean',\n 'state_zip_code_revol_bal_std',\n 'state_zip_code_open_acc_max',\n 'state_zip_code_open_acc_min',\n 'state_zip_code_open_acc_mean',\n 'state_zip_code_open_acc_std',\n 'state_zip_code_tot_coll_amt_max',\n 'state_zip_code_tot_coll_amt_mean',\n 'state_zip_code_tot_coll_amt_std',\n 'state_zip_code_dti_max',\n 'state_zip_code_dti_min',\n 'state_zip_code_dti_mean',\n 'state_zip_code_dti_std',\n 'grade_annual_inc_diff',\n 'grade_annual_inc_div',\n 'grade_installment_diff',\n 'grade_installment_div',\n 'grade_tot_cur_bal_diff',\n 'grade_tot_cur_bal_div',\n 'grade_revol_bal_diff',\n 'grade_revol_bal_div',\n 'grade_open_acc_diff',\n 'grade_open_acc_div',\n 'grade_tot_coll_amt_diff',\n 'grade_tot_coll_amt_div',\n 'grade_dti_diff',\n 'grade_dti_div',\n 'sub_grade_annual_inc_diff',\n 'sub_grade_annual_inc_div',\n 'sub_grade_installment_diff',\n 'sub_grade_installment_div',\n 'sub_grade_tot_cur_bal_diff',\n 'sub_grade_tot_cur_bal_div',\n 'sub_grade_revol_bal_diff',\n 'sub_grade_revol_bal_div',\n 'sub_grade_open_acc_diff',\n 'sub_grade_open_acc_div',\n 'sub_grade_tot_coll_amt_diff',\n 'sub_grade_tot_coll_amt_div',\n 'sub_grade_dti_diff',\n 'sub_grade_dti_div',\n 'home_ownership_annual_inc_diff',\n 'home_ownership_annual_inc_div',\n 'home_ownership_installment_diff',\n 'home_ownership_installment_div',\n 'home_ownership_tot_cur_bal_diff',\n 'home_ownership_tot_cur_bal_div',\n 'home_ownership_revol_bal_diff',\n 'home_ownership_revol_bal_div',\n 'home_ownership_open_acc_diff',\n 'home_ownership_open_acc_div',\n 'home_ownership_tot_coll_amt_diff',\n 'home_ownership_tot_coll_amt_div',\n 'home_ownership_dti_diff',\n 'home_ownership_dti_div',\n 'purpose_annual_inc_diff',\n 'purpose_annual_inc_div',\n 'purpose_installment_diff',\n 'purpose_installment_div',\n 'purpose_tot_cur_bal_diff',\n 'purpose_tot_cur_bal_div',\n 'purpose_revol_bal_diff',\n 'purpose_revol_bal_div',\n 'purpose_open_acc_diff',\n 'purpose_open_acc_div',\n 'purpose_tot_coll_amt_diff',\n 'purpose_tot_coll_amt_div',\n 'purpose_dti_diff',\n 'purpose_dti_div',\n 'zip_code_annual_inc_diff',\n 'zip_code_annual_inc_div',\n 'zip_code_installment_diff',\n 'zip_code_installment_div',\n 'zip_code_tot_cur_bal_diff',\n 'zip_code_tot_cur_bal_div',\n 'zip_code_revol_bal_diff',\n 'zip_code_revol_bal_div',\n 'zip_code_open_acc_diff',\n 'zip_code_open_acc_div',\n 'zip_code_tot_coll_amt_diff',\n 'zip_code_tot_coll_amt_div',\n 'zip_code_dti_diff',\n 'zip_code_dti_div',\n 'addr_state_annual_inc_diff',\n 'addr_state_annual_inc_div',\n 'addr_state_installment_diff',\n 'addr_state_installment_div',\n 'addr_state_tot_cur_bal_diff',\n 'addr_state_tot_cur_bal_div',\n 'addr_state_revol_bal_diff',\n 'addr_state_revol_bal_div',\n 'addr_state_open_acc_diff',\n 'addr_state_open_acc_div',\n 'addr_state_tot_coll_amt_diff',\n 'addr_state_tot_coll_amt_div',\n 'addr_state_dti_diff',\n 'addr_state_dti_div',\n 'state_zip_code_annual_inc_diff',\n 'state_zip_code_annual_inc_div',\n 'state_zip_code_installment_diff',\n 'state_zip_code_installment_div',\n 'state_zip_code_tot_cur_bal_diff',\n 'state_zip_code_tot_cur_bal_div',\n 'state_zip_code_revol_bal_diff',\n 'state_zip_code_revol_bal_div',\n 'state_zip_code_open_acc_diff',\n 'state_zip_code_open_acc_div',\n 'state_zip_code_tot_coll_amt_diff',\n 'state_zip_code_tot_coll_amt_div',\n 'state_zip_code_dti_diff',\n 'state_zip_code_dti_div']\n\n# 0.501\u4ee5\u4e0a\u306e\u3082\u306e\u306e\u307f\u3092\u5229\u7528    \nf_col.extend(new_col)\n# del_candidate = [s for s in base_cols if s not in f_col]\n# del_col.extend(del_candidate)\n\n# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx\n\n# \u30ab\u30c6\u30b4\u30ea\u306f\u5909\u63db\u3057\u3066\u304a\u304f\nfor col in new_col:\n    if col in cat:\n        le = OrdinalEncoder()\n        le.fit(df_train[col].sort_values())    \n        df_train[col] = le.fit_transform(df_train[col])    \n        df_test[col] = le.transform(df_test[col])    \n        print(le.mapping)\n\n# numpy\u3068\u3057\u3066\u4fdd\u5b58\nX_train_new = df_train.loc[:,new_col].values.astype(float)\nX_test_new = df_test.loc[:,new_col].values.astype(float)\n","18fb8f54":"X_final_train = np.hstack([X_final_train, X_train_new])\nX_final_test = np.hstack([X_final_test, X_test_new])\n\n# \u30e1\u30e2\u30ea\u78ba\u4fdd\ndel df_train,df_test,X_test_new,X_train_new\ngc.collect()","5ca74e7b":"# \u4e0b\u6e96\u5099\nleak_name = [\"annual_inc\",\"loan_amnt\",\"installment\",\"dti\",\"revol_util\",\"tot_coll_amt\",\"tot_cur_bal\",\"revol_bal\"]\n\nleak_col = []\nfor leak in leak_name:\n    leak_col.extend([s for s in f_col if leak in s])\nleak_col = list(set(leak_col))\n\ninc_col = []\ninc_col_idx = []\nfor col in f_col :\n    if col not in leak_col:\n        inc_col_idx.append(f_col_num[col])\n        inc_col.append(col)\n        \nTARGET_inc = \"loan_amnt\"\nTARGET_inc_idx = f_col_num[TARGET_inc]","60becbe2":"X_base = np.vstack([X_final_train,X_final_test])\nX = X_base[:,inc_col_idx]\ny = X_base[:,TARGET_inc_idx]\ndel X_base\ny = y.flatten()\n\nkf=KFold(n_splits=5, shuffle=True,random_state=SEED)\ny_oof = np.zeros(y.shape[0])\n\nfeature_imp = np.zeros(len(inc_col))\n\nparams = {\n    'n_estimators': 2000\n}\n\nfor train_ix, test_ix in tqdm(kf.split(X, y)):\n    X_train, y_train = X[train_ix], y[train_ix]\n    X_val, y_val = X[test_ix], y[test_ix]\n\n    clf =  lgb.LGBMRegressor(**params)\n    clf.fit(X_train, y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=200, verbose=200)\n\n    y_oof[test_ix] += clf.predict(X_val)\n    feature_imp += clf.feature_importances_\/5\n    del X_train, y_train,X_val, y_val,test_ix,train_ix\ndel X,y\n\nfeature_imp = pd.DataFrame(feature_imp,index = inc_col,columns =[\"feature_imortance\"]).sort_values(\"feature_imortance\")\nfig, ax = plt.subplots(1, 1, figsize=(12, 12))\nfeature_imp[-50:].plot(kind=\"barh\",ax=ax,color=\"b\")","305f7fd4":"np.savetxt('loam_amt_pred.txt', y_oof)\n# y_oof = np.loadtxt('..\/input\/subset\/loam_amt_pred.txt')","582272a4":"y_oof_train = y_oof[0:X_final_train.shape[0]]\ny_oof_test = y_oof[X_final_train.shape[0]:]\ny_oof_train = y_oof_train.reshape(len(y_oof_train),-1)\ny_oof_test =y_oof_test.reshape(len(y_oof_test),-1)","628ac205":"X_final_train = np.hstack([X_final_train,y_oof_train])\nX_final_test = np.hstack([X_final_test,y_oof_test])\nf_col.append(f\"pred_{TARGET_inc}\")\n\n# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx","7de44ab4":"# #\u30e1\u30e2\u30ea\u306e\u8868\u793a\n# print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n# print(\" ------------------------------------ \")\n# for var_name in dir():\n#     if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: \n#         print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","f5e3d5b7":"del feature_imp,y_oof","35edd0b3":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u8aad\u307f\u8fbc\u307f\ndf_train = df_train_base.copy()\ndf_test = df_test_base.copy()","cc0caacb":"# revol_util\u3092BIN\u5316\ndf_train[\"revol_util_bin\"] = 0\ndf_train.loc[df_train[\"revol_util\"].isna(),\"revol_util_bin\"] = 0\ndf_train.loc[(df_train[\"revol_util\"]>0)&(df_train[\"revol_util\"]<=10),\"revol_util_bin\"] = 10\ndf_train.loc[(df_train[\"revol_util\"]>10)&(df_train[\"revol_util\"]<=20),\"revol_util_bin\"] = 20\ndf_train.loc[(df_train[\"revol_util\"]>20)&(df_train[\"revol_util\"]<=30),\"revol_util_bin\"] = 30\ndf_train.loc[(df_train[\"revol_util\"]>30)&(df_train[\"revol_util\"]<=40),\"revol_util_bin\"] = 40\ndf_train.loc[(df_train[\"revol_util\"]>40)&(df_train[\"revol_util\"]<=50),\"revol_util_bin\"] = 50\ndf_train.loc[(df_train[\"revol_util\"]>50)&(df_train[\"revol_util\"]<=60),\"revol_util_bin\"] = 60\ndf_train.loc[(df_train[\"revol_util\"]>60)&(df_train[\"revol_util\"]<=70),\"revol_util_bin\"] = 70\ndf_train.loc[(df_train[\"revol_util\"]>70)&(df_train[\"revol_util\"]<=80),\"revol_util_bin\"] = 80\ndf_train.loc[(df_train[\"revol_util\"]>80)&(df_train[\"revol_util\"]<=90),\"revol_util_bin\"] = 90\ndf_train.loc[(df_train[\"revol_util\"]>90)&(df_train[\"revol_util\"]<=100),\"revol_util_bin\"] = 100\ndf_train.loc[(df_train[\"revol_util\"]>100),\"revol_util_bin\"] = 200\n\n# revol_util\u3092BIN\u5316\ndf_test[\"revol_util_bin\"] = 0\ndf_test.loc[df_test[\"revol_util\"].isna(),\"revol_util_bin\"] = 0\ndf_test.loc[(df_test[\"revol_util\"]>0)&(df_test[\"revol_util\"]<=10),\"revol_util_bin\"] = 10\ndf_test.loc[(df_test[\"revol_util\"]>10)&(df_test[\"revol_util\"]<=20),\"revol_util_bin\"] = 20\ndf_test.loc[(df_test[\"revol_util\"]>20)&(df_test[\"revol_util\"]<=30),\"revol_util_bin\"] = 30\ndf_test.loc[(df_test[\"revol_util\"]>30)&(df_test[\"revol_util\"]<=40),\"revol_util_bin\"] = 40\ndf_test.loc[(df_test[\"revol_util\"]>40)&(df_test[\"revol_util\"]<=50),\"revol_util_bin\"] = 50\ndf_test.loc[(df_test[\"revol_util\"]>50)&(df_test[\"revol_util\"]<=60),\"revol_util_bin\"] = 60\ndf_test.loc[(df_test[\"revol_util\"]>60)&(df_test[\"revol_util\"]<=70),\"revol_util_bin\"] = 70\ndf_test.loc[(df_test[\"revol_util\"]>70)&(df_test[\"revol_util\"]<=80),\"revol_util_bin\"] = 80\ndf_test.loc[(df_test[\"revol_util\"]>80)&(df_test[\"revol_util\"]<=90),\"revol_util_bin\"] = 90\ndf_test.loc[(df_test[\"revol_util\"]>90)&(df_test[\"revol_util\"]<=100),\"revol_util_bin\"] = 100\ndf_test.loc[(df_test[\"revol_util\"]>100),\"revol_util_bin\"] = 200","d7fb1bbb":"# dti\u30925\u6bce\u3067\u30ab\u30c6\u30b4\u30ea\u5206\u3051\ndf_train[\"dti_cat\"] = df_train[\"dti\"]\ndf_train.loc[df_train[\"dti_cat\"]<0,\"dti_cat\"] = 0\ndf_train.loc[(df_train[\"dti_cat\"]>=0) & (df_train[\"dti_cat\"]<5 ),\"dti_cat\"]= 0\ndf_train.loc[(df_train[\"dti_cat\"]>=5) & (df_train[\"dti_cat\"]<10 ),\"dti_cat\"] = 5\ndf_train.loc[(df_train[\"dti_cat\"]>=10) & (df_train[\"dti_cat\"]<15 ),\"dti_cat\"] = 10\ndf_train.loc[(df_train[\"dti_cat\"]>=15) & (df_train[\"dti_cat\"]<20 ),\"dti_cat\"]= 15\ndf_train.loc[(df_train[\"dti_cat\"]>=20) & (df_train[\"dti_cat\"]<25 ),\"dti_cat\"] = 20\ndf_train.loc[(df_train[\"dti_cat\"]>=25) & (df_train[\"dti_cat\"]<30 ),\"dti_cat\"] = 25\ndf_train.loc[(df_train[\"dti_cat\"]>=30) & (df_train[\"dti_cat\"]<35 ),\"dti_cat\"]= 30\ndf_train.loc[(df_train[\"dti_cat\"]>=35) & (df_train[\"dti_cat\"]<40 ),\"dti_cat\"] = 35\ndf_train.loc[(df_train[\"dti_cat\"]>40 ),\"dti_cat\"]= 40\n\ndf_test[\"dti_cat\"] = df_test[\"dti\"]\ndf_test.loc[df_test[\"dti_cat\"]<0,\"dti_cat\"] = 0\ndf_test.loc[(df_test[\"dti_cat\"]>=0) & (df_test[\"dti_cat\"]<5 ),\"dti_cat\"]= 0\ndf_test.loc[(df_test[\"dti_cat\"]>=5) & (df_test[\"dti_cat\"]<10 ),\"dti_cat\"] = 5\ndf_test.loc[(df_test[\"dti_cat\"]>=10) & (df_test[\"dti_cat\"]<15 ),\"dti_cat\"] = 10\ndf_test.loc[(df_test[\"dti_cat\"]>=15) & (df_test[\"dti_cat\"]<20 ),\"dti_cat\"]= 15\ndf_test.loc[(df_test[\"dti_cat\"]>=20) & (df_test[\"dti_cat\"]<25 ),\"dti_cat\"] = 20\ndf_test.loc[(df_test[\"dti_cat\"]>=25) & (df_test[\"dti_cat\"]<30 ),\"dti_cat\"] = 25\ndf_test.loc[(df_test[\"dti_cat\"]>=30) & (df_test[\"dti_cat\"]<35 ),\"dti_cat\"]= 30\ndf_test.loc[(df_test[\"dti_cat\"]>=35) & (df_test[\"dti_cat\"]<40 ),\"dti_cat\"] = 35\ndf_test.loc[(df_test[\"dti_cat\"]>40 ),\"dti_cat\"]= 40","425a47b8":"# 1\u5e74\u6bce\u306b\u30bf\u30fc\u30b2\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3001\u521d\u5e74\u5ea6\u306fNULL\nt_cols =  [\"sub_grade\",\"grade\",\"inq_last_6mths\",\"addr_state\",\"state_zip_code\",\"dti_cat\",\"revol_util_bin\"] \nfor col in t_cols:\n    te_year = df_train.groupby([\"issue_year\",col],as_index=False)[TARGET].mean().rename(columns={TARGET:f\"te_{col}\"})\n    te_year[\"issue_year\"] += 1\n    df_train = pd.merge(df_train,te_year,on=[\"issue_year\",col],how=\"left\")\n    df_test = pd.merge(df_test,te_year,on=[\"issue_year\",col],how=\"left\")","007e9073":"new_col = [ 'revol_util_bin',\n 'dti_cat',\n 'te_sub_grade',\n 'te_grade',\n 'te_inq_last_6mths',\n 'te_addr_state',\n 'te_state_zip_code',\n 'te_dti_cat',\n 'te_revol_util_bin']","9a1e3c3f":"# 0.501\u4ee5\u4e0a\u306e\u3082\u306e\u306e\u307f\u3092\u5229\u7528    \nf_col.extend(new_col)\n# del_candidate = [s for s in base_cols if s not in f_col]\n# del_col.extend(del_candidate)","d6016b52":"# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx","5d19d63a":"# numpy\u3068\u3057\u3066\u4fdd\u5b58\nX_train_new = df_train.loc[:,new_col].values.astype(float)\nX_test_new = df_test.loc[:,new_col].values.astype(float)\nX_final_train = np.hstack([X_final_train, X_train_new])\nX_final_test = np.hstack([X_final_test, X_test_new])","1422e5a7":"# \u30e1\u30e2\u30ea\u78ba\u4fdd\ndel df_train,df_test,X_train_new,X_test_new\ngc.collect()","b96b5f1c":"# #\u30e1\u30e2\u30ea\u306e\u8868\u793a\n# print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n# print(\" ------------------------------------ \")\n# for var_name in dir():\n#     if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #\u3053\u3053\u3060\u3051\u30a2\u30ec\u30f3\u30b8\n#         print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","9a3d2a86":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u8aad\u307f\u8fbc\u307f\ndf_train = df_train_base.copy()\ndf_test = df_test_base.copy()\n\nlen_df_train = len(df_train)\n\n# \u30c6\u30fc\u30d6\u30eb\u30de\u30fc\u30b8\ndf_merge = pd.concat([df_train.drop(TARGET,axis=1),df_test])\n\n# \u5bfe\u8c61\u30ab\u30e9\u30e0\ncol = \"emp_title\"\n\n# \u30c6\u30ad\u30b9\u30c8\u3068\u305d\u308c\u4ee5\u5916\u306b\u5206\u5272\nTXT = df_merge[col].copy()\ndel df_merge,df_train,df_test","fcfbdf00":"many_words = ['design',\n 'creative',\n 'respiratory',\n 'agency',\n 'svp',\n 'kaiser',\n 'teller',\n 'direct',\n 'developer',\n 'cna',\n 'rehab',\n 'regional',\n 'fire',\n 'lieutenant',\n 'cpa',\n 'solutions',\n 'agent',\n 'owner',\n 'buyer',\n 'investigator',\n 'pharmacist',\n 'home',\n 'company',\n 'operations',\n 'power',\n 'administration',\n 'healthcare',\n 'information',\n 'network',\n 'laborer',\n 'man',\n 'psychologist',\n 'water',\n 'patient',\n 'collector',\n 'inside',\n 'asst',\n 'budget',\n 'education',\n 'welder',\n 'support',\n 'writer',\n 'applications',\n 'escrow',\n 'csr',\n 'vice',\n 'scientist',\n 'music',\n 'cashier',\n 'technical',\n 'capital',\n 'producer',\n 'cook',\n 'mechanic',\n 'global',\n 'president',\n 'planner',\n 'research',\n 'gas',\n 'accountant',\n 'morgan',\n 'store',\n 'programmer',\n 'clinic',\n 'dispatcher',\n 'international',\n 'public',\n 'registered',\n 'pilot',\n 'auto',\n 'firefighter',\n 'insurance',\n 'executive',\n 'superintendent',\n 'development',\n 'physical',\n 'practitioner',\n 'partner',\n 'certified',\n 'trust',\n 'office',\n 'dept',\n 'coordinator',\n 'counsel',\n 'carrier',\n 'texas',\n 'corrections',\n 'account',\n 'controller',\n 'federal',\n 'co',\n 'san',\n 'consulting',\n 'isd',\n 'corporation',\n 'business',\n 'program',\n 'national',\n 'cfo',\n 'dealer',\n 'server',\n 'group',\n 'corporate',\n 'principal',\n 'police',\n 'technologies',\n 'church',\n 'social',\n 'chief',\n 'accounting',\n 'aide',\n 'officer',\n 'district',\n 'state',\n 'engineering',\n 'hospital',\n 'college',\n 'llp',\n 'services',\n 'product',\n 'security',\n 'bank',\n 'operator',\n 'it',\n 'llc',\n 'customer',\n 'professor',\n 'supervisor',\n 'department',\n 'school',\n 'architect',\n 'teacher',\n 'management',\n 'center',\n 'lead',\n 'assistant',\n 'pastor',\n 'engineer',\n 'and',\n 'physician',\n 'attorney',\n 'project',\n 'associate',\n 'county',\n 'driver',\n 'sr',\n 'vp',\n 'specialist',\n 'administrator',\n 'clerk',\n 'new',\n 'medical',\n 'service',\n 'university',\n 'software',\n 'tech',\n 'care',\n 'city',\n 'health',\n 'sales',\n 'analyst',\n 'financial',\n 'systems',\n 'director',\n 'senior',\n 'inc',\n 'manager']","45d0c25c":"# \u30c6\u30ad\u30b9\u30c8\u306e\u51fa\u73fe\u6570\u3092\u30ab\u30a6\u30f3\u30c8\ncv = CountVectorizer()\ncv.fit(many_words)\nTXT_cv = cv.transform(TXT.fillna('#'))\n\ncols_cv = cv.get_feature_names()\nfor idx,_ in enumerate(cols_cv):\n    cols_cv[idx] = col+\"_\"+cols_cv[idx]+\"_cv\"\n\nTXT_cv_train = TXT_cv[0:len_df_train,:]\nTXT_cv_test = TXT_cv[len_df_train:,:]","133427a2":"TXT_cv_train = TXT_cv_train.toarray()\nTXT_cv_test = TXT_cv_test.toarray()","614c2d0c":"X_final_train = np.hstack([X_final_train,TXT_cv_train])\nX_final_test = np.hstack([X_final_test,TXT_cv_test])","b6a4e0ff":"f_col.extend(cols_cv)\n\n# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx\n\n# #\u30e1\u30e2\u30ea\u306e\u8868\u793a\n# print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n# print(\" ------------------------------------ \")\n# for var_name in dir():\n#     if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #\u3053\u3053\u3060\u3051\u30a2\u30ec\u30f3\u30b8\n#         print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))\n\ndel TXT,TXT_cv,TXT_cv_train,TXT_cv_test","7faba6f1":"# \u30aa\u30ea\u30b8\u30ca\u30eb\u3092\u8aad\u307f\u8fbc\u307f\ndf_train = df_train_base.copy()\ndf_test = df_test_base.copy()\n\nlen_df_train = len(df_train)\n\n# \u30c6\u30fc\u30d6\u30eb\u30de\u30fc\u30b8\ndf_merge = pd.concat([df_train.drop(TARGET,axis=1),df_test])\n\n# \u30c6\u30fc\u30d6\u30eb\u30de\u30fc\u30b8\ncol = \"title\"\n\n# \u30c6\u30ad\u30b9\u30c8\u3068\u305d\u308c\u4ee5\u5916\u306b\u5206\u5272\nTXT = df_merge[col].copy()\ndel df_merge,df_train,df_test","2ebaa1f0":"many_words = ['lower',\n 'down',\n 'help',\n 'high',\n 'on',\n 'get',\n 'car',\n 'payoff',\n 'new',\n 'refinance',\n 'free',\n 'bills',\n 'improvement',\n 'rate',\n 'cc',\n 'consolidate',\n 'home',\n 'interest',\n 'cards',\n 'off',\n 'pay',\n 'card',\n 'and',\n 'my',\n 'for',\n 'to',\n 'consolidation',\n 'credit',\n 'debt',\n 'loan']","78875c24":"# \u30c6\u30ad\u30b9\u30c8\u306e\u51fa\u73fe\u6570\u3092\u30ab\u30a6\u30f3\u30c8\ncv = CountVectorizer()\ncv.fit(many_words)\nTXT_cv = cv.transform(TXT.fillna('#'))\n\ncols_cv = cv.get_feature_names()\nfor idx,_ in enumerate(cols_cv):\n    cols_cv[idx] = col+\"_\"+cols_cv[idx]+\"_cv\"\n\nTXT_cv_train = TXT_cv[0:len_df_train,:]\nTXT_cv_test = TXT_cv[len_df_train:,:]\n\nTXT_cv_train = TXT_cv_train.toarray()\nTXT_cv_test = TXT_cv_test.toarray()\n\nX_final_train = np.hstack([X_final_train,TXT_cv_train])\nX_final_test = np.hstack([X_final_test,TXT_cv_test])\n\nf_col.extend(cols_cv)\n\n# \u30ab\u30e9\u30e0\u756a\u53f7\u3092\u4fdd\u5b58\nf_col_num = {}\nfor idx, col in enumerate(f_col):\n    f_col_num[col] = idx\n    \ndel TXT,TXT_cv,TXT_cv_train,TXT_cv_test","4c05ff27":"X_final_train = X_final_train[av_idx,:]\ny_final_train = y_final_train[av_idx]\ndf_train_base = df_train_base.iloc[av_idx,:].reset_index()","6780633c":"# \u691c\u8a3c\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u4f5c\u6210\ntrain_idx = df_train_base[(df_train_base.issue_year<2015) | (df_train_base.issue_month < 7)].index.tolist()\nval_idx = df_train_base[(df_train_base.issue_year == 2015) & (df_train_base.issue_month>=7)].index.tolist()\n\nlen_train = len(train_idx)\nidx_all   = np.random.choice(train_idx, len_train, replace=False)\ntrain_idx_1 = idx_all[0:round(len_train\/3)]\ntrain_idx_2 = idx_all[round(len_train\/3):round(len_train\/3)*2]\ntrain_idx_3 = idx_all[round(len_train\/3)*2:]\n\nlen_val = len(val_idx)\nidx_all   = np.random.choice(val_idx, len_val, replace=False)\nval_idx_1 = idx_all[0:round(len_val\/3)]\nval_idx_2 = idx_all[round(len_val\/3):round(len_val\/3)*2]\nval_idx_3 = idx_all[round(len_val\/3)*2:]","b825f47f":"def objective(trial):\n        \n    feature_fraction = trial.suggest_uniform('feature_fraction', 0, 1.0)\n    learning_rate = trial.suggest_uniform('learning_rate', 0, 1.0)\n#     subsample = trial.suggest_uniform('subsample', 0.8, 1.0)\n    num_leaves = trial.suggest_int('num_leaves', 5, 1000)\n    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 10000)\n    reg_alpha = trial.suggest_uniform('reg_alpha', 0, 1.0)\n    reg_lambda = trial.suggest_uniform('reg_lambda', 0, 1.0)\n\n    params = {\"objective\": \"binary\",\n              \"boosting_type\": \"gbdt\",\n              'metric':\"auc\",\n              \"max_depth\":-1,\n              \"learning_rate\": learning_rate,\n              \"num_leaves\": num_leaves,\n              \"feature_fraction\": feature_fraction,\n              \"verbosity\": 1,\n              \"min_split_gain\": 0,\n              \"min_data_in_leaf\": min_data_in_leaf,\n              \"subsample\": 1,\n              \"reg_alpha\":reg_alpha,\n              \"reg_lambda\":reg_lambda\n              }\n    \n    scores = []\n    \n    for train_idx,val_idx in [(train_idx_1,val_idx_1),(train_idx_2,val_idx_2),(train_idx_3,val_idx_3)]:    \n        X_train = X_final_train[train_idx]\n        X_val = X_final_train[val_idx]\n        y_train = y_final_train[train_idx]\n        y_val =  y_final_train[val_idx]\n    \n        clf =  lgb.LGBMClassifier(**params,n_estimators=2000)\n        clf.fit(X_train, y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=200, verbose=200)\n        score = clf.best_score_[\"valid_0\"][\"auc\"]\n        scores.append(score)\n        del X_train,X_val,y_train,y_val\n    #     AUC\u3092\u6700\u5c0f\u5316\u3055\u305b\u308b\n    return (1 - sum(scores)\/3)\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=30)\nstudy.best_params","1761e302":"params = {\"objective\": \"binary\",\n          \"boosting_type\": \"gbdt\",\n          'metric':\"auc\",\n          \"max_depth\":-1,\n          \"learning_rate\": study.best_params[\"learning_rate\"],\n          \"num_leaves\": study.best_params[\"num_leaves\"],\n          \"feature_fraction\": study.best_params[\"feature_fraction\"],\n          \"verbosity\": 1,\n          \"min_split_gain\": 0,\n          \"min_data_in_leaf\": study.best_params[\"min_data_in_leaf\"],\n          \"subsample\": 1,\n          \"reg_alpha\":study.best_params[\"reg_alpha\"],\n          \"reg_lambda\":study.best_params[\"reg_lambda\"]\n          }\n\nopt_params = study.best_params\n\nclf =  lgb.LGBMClassifier(**params,n_estimators=2000)\nclf.fit(X_final_train, y_final_train,eval_set=[(X_final_train,y_final_train)],early_stopping_rounds=200, verbose=100)\n\ny_pred = clf.predict_proba(X_final_test)[:,1]","62205184":"# submission\u306b\u30de\u30fc\u30b8\nsubmission = pd.read_csv(filepath2+'sample_submission.csv',index_col=0)\nsubmission.loan_condition = y_pred\nsubmission.to_csv('submission.csv')","90f839bb":"## \u5916\u90e8\u30c7\u30fc\u30bf\u306e\u5229\u7528","b89d7795":"## =====\u30d9\u30fc\u30b9\u306e\u4ea4\u4e92\u4f5c\u7528======","7c3c6ac3":"# Feature Enginnering","a3b8cb76":"## =====\u30bf\u30fc\u30b2\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0=====","78bbca6e":"# =============== \u4e88\u6e2c\u306e\u5b9f\u884c","69cf9d3e":"# =============== Optuna","44adbd66":"### =======\u6587\u5b57\u5217\u3092\u4e00\u90e8=======","eca8b6c8":"# \u30c6\u30ad\u30b9\u30c8\u30ab\u30e9\u30e0\u306e\u51e6\u7406(count_vec)","d5a62c1f":"## =====\u30ed\u30fc\u30f3\u984d\u306e\u4e88\u6e2c","92f8805e":"## =====\u96c6\u8a08\u7279\u5fb4\u91cf=====","3a2f857a":"# Preparation","ebff628e":"## =====Adversarial Validation=====\n"}}