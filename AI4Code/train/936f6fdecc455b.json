{"cell_type":{"3aa1db5d":"code","6796c97e":"code","838e4b43":"code","c3f50df1":"code","ff8d904c":"code","79dbfe0d":"code","c300ce64":"code","8b1e6131":"code","90f69e95":"code","3062c433":"code","56eb7c31":"code","6eb587a1":"code","4cda2b3b":"code","f13ae464":"code","c6966569":"code","0146af33":"markdown","fa0092af":"markdown","6ddde8ee":"markdown","6ecf2572":"markdown","ca0dc04b":"markdown","f79ac046":"markdown","5a96277f":"markdown","74729150":"markdown","d4f009a1":"markdown","c9d46c08":"markdown","8318623e":"markdown"},"source":{"3aa1db5d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))","6796c97e":"data = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')","838e4b43":"data.info()","c3f50df1":"data.head(10)","ff8d904c":"data.describe()","79dbfe0d":"data.corr()","c300ce64":"f,ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(data.corr(), annot=True, linewidths=0.5,linecolor=\"white\", fmt= '.1f',ax=ax)\nplt.show()","8b1e6131":"f,ax = plt.subplots(figsize=(15, 5))\nsns.countplot(data['GRE Score'])\nplt.xticks(rotation= 70)\nplt.show()\n\nf,ax = plt.subplots(figsize=(15, 5))\nsns.countplot(data['TOEFL Score'])\nplt.xticks(rotation= 70)\nplt.show()","90f69e95":"from sklearn.linear_model import LinearRegression #add linear regression library\nreg = LinearRegression()\nx = data.iloc[:,1].values.reshape(-1,1)\ny = data.iloc[:,8].values.reshape(-1,1)\nreg.fit(x,y) #create line\ny_head = reg.predict(x) #predict chance of admit\nb0 = reg.intercept_ \nb1 = reg.coef_\nprint(\"B0 :\",b0)\nprint(\"B1 :\",b1)\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Values :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good. \n\n#visualization\nf,ax = plt.subplots(figsize=(10, 10))\nplt.scatter(data['GRE Score'],data.iloc[:,-1], color=\"red\")\nplt.plot(x,y_head, color=\"blue\")\nplt.show()","3062c433":"from sklearn.linear_model import LinearRegression #add linear regression library\nreg = LinearRegression()\nx = data.iloc[:,2].values.reshape(-1,1)\ny = data.iloc[:,8].values.reshape(-1,1)\nreg.fit(x,y) #create line\ny_head = reg.predict(x) #predict chance of admit\nb0 = reg.intercept_\nb1 = reg.coef_\nprint(\"B0 :\",b0)\nprint(\"B1 :\",b1)\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good. \n\n#visualization\nf,ax = plt.subplots(figsize=(10, 10))\nplt.scatter(data['TOEFL Score'],data.iloc[:,-1], color=\"red\")\nplt.plot(x,y_head)\nplt.show()","56eb7c31":"from sklearn.linear_model import LinearRegression #add linear regression library\nreg = LinearRegression()\nx = data.iloc[:,6].values.reshape(-1,1)\ny = data.iloc[:,8].values.reshape(-1,1)\nreg.fit(x,y)#create line\ny_head = reg.predict(x) #predict chance of admit\nb0 = reg.intercept_\nb1 = reg.coef_ \nprint(\"B0 :\",b0)\nprint(\"B1 :\",b1)\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good. \n\n#visualization\nf,ax = plt.subplots(figsize=(10,10))\nplt.scatter(data['CGPA'],data.iloc[:,-1], color=\"red\")\nplt.plot(x,y_head, color=\"blue\")\nplt.show()","6eb587a1":"from sklearn.linear_model import LinearRegression #add linear regression library\nreg = LinearRegression()\nx = data.iloc[:,[1,2,6]].values\ny = data.iloc[:,8].values.reshape(-1,1)\nreg.fit(x,y) #create line\ny_head = reg.predict(x) #predict chance of admit\nprint(\"B0 :\",reg.intercept_)\nprint(\"B1,B2 and B3 :\",reg.coef_)\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good.","4cda2b3b":"from sklearn.preprocessing import PolynomialFeatures # add Polynomial and Linear Regression library\nfrom sklearn.linear_model import LinearRegression\npolynomial_reg = PolynomialFeatures(degree=4) #set degree\nreg = LinearRegression()\nx = data.iloc[:,6].values.reshape(-1,1)\ny = data.iloc[:,8].values.reshape(-1,1)\nx_polynomial = polynomial_reg.fit_transform(x) # Get the degree and add\nreg.fit(x_polynomial,y) #create line \ny_head = reg.predict(x_polynomial) # predict chance of admit\nprint(\"B0 :\",reg.intercept_)\nprint(\"B1,B2,B3,B4 and B5 :\",reg.coef_)\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good.\n\n#visualization\nf,ax = plt.subplots(figsize=(10,10))\nplt.scatter(data['CGPA'],data.iloc[:,-1], color=\"red\")\nplt.plot(x,y_head, color=\"blue\")\nplt.show()","f13ae464":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\nx = data.iloc[:,1].values.reshape(-1,1)\ny = data.iloc[:,8].values.reshape(-1,1)\ntree_reg.fit(x,y) # create model\n\nmin_x = min(data.iloc[:,1].values)\nmax_x = max(data.iloc[:,1].values)\narray = np.arange(min_x,max_x,0.1).reshape(-1,1)\ny_head = tree_reg.predict(array) # predict chance of admit\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(y,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good.\n\n#visualization\nf,ax = plt.subplots(figsize=(15,10))\nplt.scatter(x,y,color=\"red\",alpha=0.4)\nplt.plot(array,y_head,color=\"green\")\nplt.show()","c6966569":"from sklearn.ensemble import RandomForestRegressor # add Random Forest Regression library\ndata_drop = data.drop(['Chance of Admit '],axis=1)\ndata_change_of_admit = data.iloc[:,-1].values.reshape(-1,1)\n\nreg = RandomForestRegressor(n_estimators=100, random_state = 42) # determine tree count and random data count\nreg.fit(data_drop,data_change_of_admit) # create model\ny_head = reg.predict(data_drop) # predict chance of admit\n\n#Evalutaion Regression Model\nfrom sklearn.metrics import r2_score\nprint(\"R Square Value :\",r2_score(data_change_of_admit,y_head)) #Evaluation algorithm, If it is close to 1, Model is so good.\n\n\n","0146af33":"Hi everybody, I'm preparing a tutorial related to Regression Algorithms. In this tutorial, I used python programming language. There is a lot of ML library in python. It is quite easy to code program. But, if you want to use another programming language, you can use R, SQLite or Julia. I hope it is benefit to you. Let's get to know your dataset.\n\n[1.INTRODUCTION DATA](#1) <br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[What is the correlation?](#2)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Why are we using correlation?](#3)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Visualization](#4) <br\/>\n[2. REGRESSION ALGORITHM ](#5)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Linear Regression](#6)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Multiple Linear Regression](#7)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Polynomial Linear Regression](#8)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Decision Tree Regression](#9)<br\/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Random Forest Regression](#10)<br\/>\n[3. CONCLUSION](#11)<br\/>\n    ","fa0092af":"<a id=\"7\"><\/a>\n## Multiple Linear Regression\n\nIt's same definition with Linear Regression. This algorithm is used more from one feature. \n\n* y = : b0 + b1x1 + b2x2 + b3x3 +.... <br\/>\ny   : predicted value - dependant variable <br\/>\nx1,x2,x3....   : our value - independant value <br\/>\nb1,b2,b3...    : multiple of x <br\/>\nb0 : The point that cuts y axis. <br\/>\n\n## How can we draw true line?\n\n* Find the nearest point to all points. How?\n\nredisual = y-y_head   y_head is predict values. <br\/>\nMSE= sum(redisual^2)\/sample value \n\nMSE is meaning \"Mean Square Error\"  It is mean of errors. **Why are we getting square of redisual?**  Because, some redisual points can be negative value. So, we are getting square of redisual points to find error values. Actually, programming language of our using solve this. But, I think, You must know math of algorithm. :)\n\n## NOTE: If a true line is drawn, true prediction can be made. ","6ddde8ee":"I used a dataset that there are feaures influencing university admission of students. According to that features, We are gonna work predicting chance of admit of students.  There are totally 5 int64 type features and 4 float64 type features. We let to look correlation of our dataset and we let to set our algorithm according to correlation of our dataset. :)","6ecf2572":"<a id=\"10\"><\/a>\n## Random Forest Regression\n\nRandom Forest Regression Algorithm is a model that provide that we make better our predictions as using n times the decision tree algorithm. It is a member of Ensemble Learning. \n\n### What is the Ensemble Learning? \n\nEnsemble Learning is a method learning as using n times of machine learning algorithms. ","ca0dc04b":"<a id=\"8\"><\/a>\n## Polynomial Linear Regression\n\nThis algorithm is used if there is polynomial increasing.\n\n* y = : b0 + b1x1 + b2x2^2 + b3x3^3 +.... + bnxn^n <br\/>\ny   : predicted value - dependant variable <br\/>\nx1,x2,x3....xn    : our value - independant value <br\/>\nb1,b2,b3... bn   : multiple of x <br\/>\nb0 : The point that cuts y axis. <br\/>\n\n## How can we draw true line?\n\n* Find the nearest point to all points. How?\n\nredisual = y-y_head   y_head is predict values. <br\/>\nMSE= sum(redisual^2)\/sample value \n\nMSE is meaning \"Mean Square Error\"  It is mean of errors. **Why are we getting square of redisual?**  Because, some redisual points can be negative value. So, we are getting square of redisual points to find error values. Actually, programming language of our using solve this. But, I think, You must know math of algorithm. :)\n\n## NOTE: If a true line is drawn, true prediction can be made. ","f79ac046":"<a id=\"9\"><\/a>\n## Decision Tree Regression\n\nDecision tree splits to two as classification and regression. We can define decision regression so:\n\nDecision tree creates decision nodes and leaf nodes according to feature. It predict according to mean of terminal leaf node. <br\/> <br\/>\n\n![image.png](attachment:image.png)","5a96277f":"<a id=\"1\"><\/a>\n# 1.INTRODUCTION TO DATA\n","74729150":"<a id=\"5\"><\/a>\n# 2. Regression Algorithms\n\n* Regression Algorithm is one of supervised learning methods. \n\n* It is used for situations which is generated from figures that output is generated. For example, If you want to create a numerical efficiency score according to the number of days an employee comes to work and the number of products produced during the day, you can use regression algorithms. \n\n* Regression algorithms can be used in both supervised and unattended learning methods such as anomaly detection and anomaly detection.\n\n<a id=\"6\"><\/a>\n## Linear Regression\n\n* Linear regression not only shows the functional form of the linear relationship between two variables, one of which is dependent and the other as a true equation as an independent variable.\n\n* According to GRE, TOEFL Score and CGPA I examined Chance of Admit.\n\n*  y = : b0+b1*x  <br\/>\ny   : predicted value - dependant variable <br\/>\nx   : our value - independant value <br\/>\nb1 : multiple of x <br\/>\nb0 : The point that cuts y axis. <br\/>\n\n## How can we draw true line?\n\n* Find the nearest point to all points. How?\n\nredisual = y-y_head   y_head is predict values. <br\/>\nMSE= sum(redisual^2)\/sample value \n\nMSE is meaning \"Mean Square Error\"  It is mean of errors. **Why are we getting square of redisual?**  Because, some redisual points can be negative value. So, we are getting square of redisual points to find error values. Actually, programming language of our using solve this. But, I think, You must know math of algorithm. :)\n\n## NOTE: If a true line is drawn, true prediction can be made. \n","d4f009a1":"<a id=\"11\"><\/a>\n# 3. Conclusion\n\nWe can determine most suitable algorithm according to our data. R Square Value helps us about our selection. I had worked talking regression algorithms as best I can. I hope It's benefit to you this kernel. don't forget vote up. :) You may ask your questions from comments. I'm gonna work answering. \n\n### Good Work :)","c9d46c08":"<a id=\"2\"><\/a>\n## What is the correlation?\n\nCorrelation shows related to between two or more variable. As a result of correlation analysis, if It have one related to between variables, degree of relationship calculates with correlation coefficient. Correlation coefficient shows with \"r\". It has got values between +1 and -1. \n\n* r = 1  there is positive linear relationship.\n* r = 0  there is not relationship\n* r = -1 there is negative linear relationship.\n\nIf there is relationship 0 and 1:\n\n* r = 0.00 no relationship\n* r between 0.01 \u2013 0.29 low level relationship\n* r between 0.30 \u2013 0.70 medium level relationship\n* r between 0.71 \u2013 0.99 high level relationship\n* r = 1.00 excellent relationship\n\n<a id=\"3\"><\/a>\n## Why are we using correlation?\n\nWe can set our algorithm by analyzing this relationship. If relationship level increases, Our probability to predict increase. So correlation is important.  :)","8318623e":"<a id=\"4\"><\/a>\n## Visualization"}}