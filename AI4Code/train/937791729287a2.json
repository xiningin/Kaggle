{"cell_type":{"fa800241":"code","4167d5f9":"code","43108fc1":"code","e173d78a":"code","aba098b7":"code","ca3fe98b":"code","f1bd7be0":"code","6c15b457":"code","7cb5d81b":"code","abeeda6f":"code","455c7c3b":"code","e570d711":"code","0bd632bd":"code","00c4eca3":"code","ba86a31b":"code","21f9007a":"code","befdcfb3":"markdown","90d05711":"markdown","65fc79f7":"markdown","2e6d4f25":"markdown","7f71f4cb":"markdown","b3fc1e8f":"markdown","0907a675":"markdown","b7d2d9ee":"markdown","488b10b7":"markdown","9efe0108":"markdown","9029d3f1":"markdown","c24187a7":"markdown","c20cda64":"markdown","36f9b6c5":"markdown","6dcb99cb":"markdown","eb00cb4d":"markdown","26f94962":"markdown"},"source":{"fa800241":"import numpy as np \nimport pandas as pd \nimport missingno as msno\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\nfrom pandas_profiling import ProfileReport\n\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport os\nimport glob\nimport shutil\nimport sys\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\n# %matplotlib inline\nimport random\nfrom tensorflow.keras.applications import EfficientNetB2\n\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","4167d5f9":"summary = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_dataset_Summary.csv')\nmetadata = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\nsummary_profile = ProfileReport(summary, title=\"Summary DataFrame Profiling Report\")\nmetadata_profile = ProfileReport(metadata, title=\"MetaData DataFrame Profiling Report\")","43108fc1":"metadata_profile","e173d78a":"test_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TEST') & (~metadata['Label_1_Virus_category'].isnull())])\ntrain_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TRAIN') & (~metadata['Label_1_Virus_category'].isnull())])\n\ntrain_virus_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TRAIN') &  (metadata['Label_1_Virus_category'] == 'Virus')])\ntrain_bacteria_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TRAIN') &  (metadata['Label_1_Virus_category'] == 'bacteria')])\n\n\ntest_virus_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TEST') &  (metadata['Label_1_Virus_category'] == 'Virus')])\ntest_bacteria_images = list(metadata['X_ray_image_name'].loc[(metadata['Dataset_type'] == 'TEST') &  (metadata['Label_1_Virus_category'] == 'bacteria')])\n\n\nprint(f'No. of training images: {len(train_images)}')\nprint(f'No. of test images: {len(test_images)}')\n\nprint(f'No. of bacteria train images: {len(train_bacteria_images)}')\nprint(f'No. of virus train images: {len(train_virus_images)}')\n\nprint(f'No. of bacteria test images: {len(test_bacteria_images)}')\nprint(f'No. of virus test images: {len(test_virus_images)}')\n\n#shuffle the data\ntrain_bacteria_length = list(random.sample(range(0,2535),2535))\n\ntrain_bacteria_paths = []\nvalidation_bacteria_paths = []\nfor i,ele in enumerate(train_bacteria_length):\n    if i<1267:\n        train_bacteria_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train\/{train_bacteria_images[ele]}')\n    else:\n        validation_bacteria_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train\/{train_bacteria_images[ele]}')\n\n#shuffle the data\ntrain_virus_length = list(random.sample(range(0,1407),1407))\n\ntrain_virus_paths = []\nvalidation_virus_paths = []\nfor i,ele in enumerate(train_virus_length):\n    if i<=703:\n        train_virus_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train\/{train_virus_images[ele]}')\n    else:\n        validation_virus_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train\/{train_virus_images[ele]}')\n\ntest_virus_paths = []\ntest_bacteria_paths = []\n\nfor ele in test_virus_images:\n    test_virus_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test\/{ele}')\n    \nfor ele in test_bacteria_images:\n    test_bacteria_paths.append(f'..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test\/{ele}')\n    ","aba098b7":"model = EfficientNetB2(weights='imagenet')\nIMG_SIZE = 260\nbatch_size = 32\nwidth = 260\nheight = 260\nepochs = 10\ndropout_rate = 0.2\ninput_shape = (height, width, 3)","ca3fe98b":"# !git clone https:\/\/github.com\/Tony607\/efficientnet_keras_transfer_learning\n%cd '\/kaggle\/input\/efficientnetkeras\/efficientnet_keras_transfer_learning'","f1bd7be0":"from efficientnet import EfficientNetB2 as Net\nfrom efficientnet import center_crop_and_resize, preprocess_input\n\nconv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.GlobalMaxPooling2D(name=\"gap\"))\nif dropout_rate > 0:\n    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\nmodel.add(layers.Dense(2, activation=\"softmax\", name=\"fc_out\"))","6c15b457":"%cd '\/kaggle\/input\/bacteriavsvirus-trainvaltest-split\/bacteria_vs_virus'","7cb5d81b":"train_dir= '\/kaggle\/input\/bacteriavsvirus-trainvaltest-split\/bacteria_vs_virus\/train\/'\nvalidation_dir= '\/kaggle\/input\/bacteriavsvirus-trainvaltest-split\/bacteria_vs_virus\/validation\/'\ntest_dir = '\/kaggle\/input\/bacteriavsvirus-trainvaltest-split\/bacteria_vs_virus\/test\/'\nNUM_TRAIN= 3942\nNUM_TEST= 390","abeeda6f":"train_datagen = ImageDataGenerator(\n    rescale=1.0 \/ 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.0 \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n)","455c7c3b":"def unfreeze_model(model):\n    for layer in model.layers[-10:]:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","e570d711":"# # Include the epoch in the file name (uses `str.format`)\n# checkpoint_path = \"\/kaggle\/working\/training_checkpoints\/cp-{epoch:04d}.ckpt\"\n# checkpoint_dir = os.path.dirname(checkpoint_path)\n\n# # Create a callback that saves the model's weights every 5 epochs\n# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n#     filepath=checkpoint_path, \n#     verbose=1, \n#     save_weights_only=True,\n#     save_freq=10*batch_size)\n\n\n# # Save the weights using the `checkpoint_path` format\n# model.save_weights(checkpoint_path.format(epoch=0))\n\n\n# unfreeze_model(model)\n\n# history = model.fit_generator(\n#     train_generator,\n#     steps_per_epoch=NUM_TRAIN \/\/ batch_size,\n#     epochs=epochs,\n#     validation_data=validation_generator,\n#     validation_steps=NUM_TEST \/\/ batch_size,\n#     verbose=1,\n#     use_multiprocessing=True,\n#     workers=4,\n#     callbacks=[cp_callback]\n# )","0bd632bd":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg = mpimg.imread('\/kaggle\/input\/coronohack-checkpoints\/training_checkpoints\/training_validation_acc.png')\nimgplot = plt.imshow(img)\nplt.axis('off')\nplt.show()\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg = mpimg.imread('\/kaggle\/input\/coronohack-checkpoints\/training_checkpoints\/\/training_validation_loss.png')\nimgplot = plt.imshow(img)\nplt.axis('off')\nplt.show()","00c4eca3":"conv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.GlobalMaxPooling2D(name=\"gap\"))\nif dropout_rate > 0:\n    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\nmodel.add(layers.Dense(2, activation=\"softmax\", name=\"fc_out\"))\nlatest = tf.train.latest_checkpoint('\/kaggle\/input\/coronohack-checkpoints\/training_checkpoints')\nmodel.load_weights(latest)","ba86a31b":"test_generator = test_datagen.flow_from_directory(\n        '\/kaggle\/input\/bacteriavsvirus-trainvaltest-split\/bacteria_vs_virus\/test',\n         target_size=(height, width),\n         batch_size=batch_size,\n         classes=['bacteria','virus'],\n         class_mode='categorical',  \n         shuffle=False)  \n\nprobabilities = model.predict_generator(test_generator)","21f9007a":"from sklearn.metrics import confusion_matrix,classification_report\n\ny_pred = np.argmax(probabilities, axis=1)\n\ntrue_classes = test_generator.classes\n\nclass_labels = list(test_generator.class_indices.keys())   \n\n\nreport = classification_report(true_classes, y_pred, target_names=class_labels)\nprint(report)","befdcfb3":"<center><h2><b>Thanks for reading. Please write your comments below.<\/b><\/h2><\/center>","90d05711":"> **Train Validation Test split:**","65fc79f7":"The folder structure is created to load it into keras image data generator, here the classes are bacteria and virus.It is uploaded as bacteriavsvirus-trainvaltest-split zip folder. Classification is not possible at label 2 virus cateogry level due to less data (i.e less images with 2 virus cateogry label).","2e6d4f25":"<center><b>My References:<\/b> <a href=\"https:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/\">https:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/<\/a> <br>\n&emsp;&ensp;<a href=\"https:\/\/www.dlology.com\/blog\/transfer-learning-with-efficientnet\/\">https:\/\/www.dlology.com\/blog\/transfer-learning-with-efficientnet\/<\/a>\n<\/center>","7f71f4cb":"**Clone and import efficientNet** \n\n> Due to some error with tensorflow v2 , i corrected and imported the package seperately.","b3fc1e8f":"<center><h2><b>Following notebook classifies X-ray scans into Bacteria and Virus.<\/b><\/h2><\/center>","0907a675":"<center><img src = \"https:\/\/www.nsmedicaldevices.com\/wp-content\/uploads\/sites\/2\/2020\/03\/599px-2019-nCoV-CDC-23312_without_background.png\" width=\"550\"><\/center>","b7d2d9ee":"<h2> EfficientNet <\/h2>\nEfficientNet, first introduced in Tan and Le, 2019 is among the most efficient models (i.e. requiring least FLOPS for inference) that reaches State-of-the-Art accuracy on both imagenet and common image classification transfer learning tasks.\n\n<p>Compared to other models achieving similar ImageNet accuracy, EfficientNet is much smaller. For example, the ResNet50 model as you can see in Keras application has 23,534,592 parameters in total, and even though, it still underperforms the smallest EfficientNet, which only takes 5,330,564 parameters in total.<\/p>","488b10b7":"> From above graphs we can see that the model is starting to go into overfitting for higher epochs. ","9efe0108":"Here instead of freezing all layers and training with only top layer, i have unfreezed top 10 layers except batchnorm layers with smaller learning rate.","9029d3f1":"> **Hyperparameters:**","c24187a7":"The EfficientNet is built for ImageNet classification contains 1000 classes labels. For our dataset, we only have 2. Which means the last few layers for classification is not useful for us. They can be excluded while loading the model by specifying the include_top argument to False, and this applies to other ImageNet models made available in Keras applications as well.","c20cda64":"**General Trivia:**\n1. Chest X-Ray (CXR) is one of the important, non-invasive clinical adjuncts that play an essential role in the detection of visual responses associated with SARS-COV-2 infection.\n2. Limited availability of expert radiologists to interpret the CXR images and subtle appearance of disease radiographic responses remains the biggest bottlenecks in manual diagnosis.\n3. An automated solution if can be achieved will be of great help in tracing the cases.","36f9b6c5":"<center><h2><b>F1 score achieved after 20 epochs and trying different hyperparameters is 82% <\/b><h2><\/center>","6dcb99cb":"Lets find the latest checkpoint and load it into model. we will find the F-score on test data by finding probabilites using predict generator. ","eb00cb4d":"uncomment the following code to run training. I have uploaded the final checkpoint files in input after 20 epochs. Lets plot train vs validation accuracy and train vs validation loss.","26f94962":"From metadata dataframe profile we can see there are 98.8% of labels missing for label_2_virus_cateogery, so we will implement classification on label_1_virus category i.e. bacteria vs virus. "}}