{"cell_type":{"278389f4":"code","6bc25295":"code","2de98a68":"code","c8c73bf5":"code","31e718cd":"code","b0b37b08":"code","4b01ba0b":"code","7e835638":"code","1f624395":"code","1b0f2e14":"code","84172428":"code","04bbc50f":"code","7dc1d4c8":"code","73703045":"code","de4dbc99":"code","e49260ab":"code","df8d0d30":"code","e45feb75":"code","8fa2866e":"code","3978c409":"code","2e69393d":"code","2d30b2d1":"code","1fa89253":"code","3fc2e026":"code","e73d2fee":"markdown","12e3e841":"markdown","45a12db6":"markdown","35b1b0da":"markdown","15d14082":"markdown","c66682c9":"markdown","f01bf52f":"markdown","d0d0204c":"markdown","023de9f9":"markdown","c00a3421":"markdown"},"source":{"278389f4":"# Libraries\n\nimport numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Input,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization,Dense\nfrom keras.preprocessing.image import ImageDataGenerator as Imgen\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\n\nfrom sklearn.metrics import confusion_matrix,classification_report","6bc25295":"# reading the data\ndata = pd.read_csv(\"..\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/icml_face_data.csv\")\ndata.head()","2de98a68":"cols = [\"emotion\",\"subset\",\"pixels\"]\ndata.columns = cols\ndata.columns\n\nemotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","c8c73bf5":"print(data.subset.value_counts())\nprint(data.emotion.value_counts())","31e718cd":"# Splitting into train test and validate\n\ntrain_data = data[data[\"subset\"]==\"Training\"]\nval_data = data[data[\"subset\"]==\"PublicTest\"]\ntest_data = data[data[\"subset\"]==\"PrivateTest\"]\n\nprint(train_data.shape,test_data.shape,val_data.shape)","b0b37b08":"# to extract image data from pixel column\n\ndef toPixels(pixels):\n\n    arr = np.array(pixels.split(),\"float64\")\n    return arr\n\ndef reshapetoImage(data):\n\n    Images = np.reshape(data[\"pixels\"].to_list(),(data.shape[0],48,48,1))\n\n    return Images","4b01ba0b":"train_data[\"pixels\"] = train_data[\"pixels\"].apply(toPixels)\nval_data[\"pixels\"] = val_data[\"pixels\"].apply(toPixels)\ntest_data[\"pixels\"] = test_data[\"pixels\"].apply(toPixels)","7e835638":"# images and labels\n\ntrain_images = reshapetoImage(train_data)\nval_images = reshapetoImage(val_data)\ntest_images = reshapetoImage(test_data)\n\ntrain_labels = train_data[\"emotion\"]\nval_labels = val_data[\"emotion\"]\ntest_labels = test_data[\"emotion\"]","1f624395":"def plotImages(x,y):\n    plt.figure(figsize=[20,12])\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.imshow(x[i],cmap=\"gray\")\n        plt.title(emotions[y[i]])\n        plt.axis(\"off\")\n    plt.show()","1b0f2e14":"plotImages(train_images,train_labels)","84172428":"trainGen = Imgen(rescale=1.\/255,\n                 zoom_range=0.2,\n                 shear_range=0.2,\n                 horizontal_flip=True\n                 )\nvalGen = Imgen(rescale=1.\/255,\n                 zoom_range=0.2,\n                 shear_range=0.2,\n                 horizontal_flip=True\n               )\ntestGen = Imgen(rescale=1.\/255)","04bbc50f":"trainds = trainGen.flow(train_images,train_labels,\n                   batch_size = 32\n                   )\n\nvalds = valGen.flow(val_images,val_labels,\n               batch_size = 32\n               )\n\ntestds = testGen.flow(test_images,test_labels,\n                      batch_size=32,\n                      shuffle=False)","7dc1d4c8":"# one batch\nx,y = next(trainds)\n\n# see \nplotImages(x,y)","73703045":"# Model\nimage_input = Input(shape=(48,48,1))\n\nx = Conv2D(64,(3,3), activation=\"relu\")(image_input)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2,2))(x)\nx = Dropout(0.3)(x)\n\nx = Conv2D(128,(3,3),activation=\"relu\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2,2))(x)\nx = Dropout(0.3)(x)\n\nx = Conv2D(512,(3,3),activation=\"relu\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2,2))(x)\nx = Dropout(0.3)(x)\n\nx = Conv2D(512,(3,3),activation=\"relu\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2,2))(x)\nx = Dropout(0.3)(x)\n\nx = Flatten()(x)\n\nx = Dense(512,activation=\"relu\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Dense(256,activation=\"relu\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nimage_output = Dense(7,activation=\"softmax\")(x)\n\nmodel = Model(image_input,image_output)\n\nprint(model.summary())","de4dbc99":"# Compile the model\nprint(\"Compiling the Model....\")\nmodel.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nprint(\"Model Compiled!\")","e49260ab":"# Defining callbacks\nmy_calls = [EarlyStopping(monitor='val_accuracy',patience=5),\n            ModelCheckpoint(\"Model_ethnicity.h5\",verbose=1,save_best_only=True)]","df8d0d30":"hist = model.fit(trainds, epochs=40, validation_data=valds, callbacks=my_calls)","e45feb75":"model.evaluate(testds)","8fa2866e":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nplt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(hist.epoch,hist.history['loss'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n\nplt.title(\"Loss\")\nplt.legend()\nplt.show()\n","3978c409":"pred = model.predict(testds)","2e69393d":"pred = [np.argmax(i) for i in pred]","2d30b2d1":"y_test = np.array(test_labels)","1fa89253":"print(classification_report(y_test,pred))","3fc2e026":"plt.figure(figsize=[20,14])\nsns.heatmap(confusion_matrix(y_test,pred),annot = True, fmt= \"d\", cmap = \"Blues\");","e73d2fee":"## **Reading and Organiing Data**","12e3e841":"## **Model**","45a12db6":"# **Facial Expression Recognition**","35b1b0da":"**Train**","15d14082":"## **Predictions**","c66682c9":"**Graph**","f01bf52f":"## **Image Data Generator**","d0d0204c":"**Test**","023de9f9":"### **Visualaizing some Images**","c00a3421":"**One batch**"}}