{"cell_type":{"fc224c09":"code","f9c92eba":"code","3beba2cd":"code","410e15e5":"code","066ac67c":"code","868431a4":"code","c804f34b":"code","374bf473":"code","02df7b27":"code","155f5b04":"code","d8b39d0d":"code","3e365513":"markdown","c4410588":"markdown","8b6d5eda":"markdown"},"source":{"fc224c09":"import pandas as pd\nimport optuna","f9c92eba":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntrain.head()","3beba2cd":"X = train.drop(['id', 'claim'], axis = 1)\ny = train['claim'].values","410e15e5":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass AddFeature(BaseEstimator,TransformerMixin ):\n    def __init__(self):\n        pass\n    def fit(self, X, y = None):\n        self.greater1e10 = []\n        self.greater1e5 = []\n        self.greater1e2 = []\n        self.lessthan1e2 = []\n        for col in X.columns:\n            if (X[col].mean() > 1e10):\n                self.greater1e10.append(col)\n            elif (X[col].mean() > 1e5):\n                self.greater1e5.append(col)\n            elif (X[col].mean() > 1e2):\n                self.greater1e2.append(col)\n            else:\n                self.lessthan1e2.append(col)\n        return self\n    def transform(self, X, y = None):\n        df = X.copy()\n        df['std'] = df.std(axis = 1)\n        df['mean'] = df.mean(axis = 1)\n        df['missing counts'] = df.isna().sum(axis = 1)\n        df['mean1'] = df[self.greater1e10].mean(axis =1 )\n        df['mean2'] = df[self.greater1e5].mean(axis =1 )\n        df['mean3'] = df[self.greater1e2].mean(axis =1 )\n        df['mean4'] = df[self.lessthan1e2].mean(axis =1 )\n        return df","066ac67c":"pipeline = make_pipeline(\n    #(SimpleImputer(strategy='mean')),\n    (AddFeature()),\n    (RobustScaler())\n)\nX = pipeline.fit_transform(X)\nX","868431a4":"import xgboost\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\ndef objective_xgb(trial):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2021)\n    params = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'booster':'gbtree',\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 1e4),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1e4),\n        'n_estimators' : 6000,\n        'use_label_encoder' : False,\n        'tree_method' : 'gpu_hist',\n        'predictor' : 'gpu_predictor',\n        'gpu_id' : 0,\n        'max_depth' : trial.suggest_int('max_depth', 0, 15),\n        'eta' : trial.suggest_loguniform('eta', 1e-5, 0.2),\n        'gamma' : trial.suggest_loguniform('gamma', 1e-8, 1.0),\n        'grow_policy' : trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n        'subsample' : trial.suggest_float('subsample', 1e-8,1),\n        'max_bin' : trial.suggest_int('max_bin',256, 2048, step = 32),\n        'max_leaves' : trial.suggest_int('max_leaves', 0,20),\n        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 32)\n    }\n    eval_set = [(X_test, y_test)]\n    xgb = XGBClassifier().set_params(**params)\n    xgb.fit(X_train, y_train, early_stopping_rounds = 250, eval_set = eval_set, verbose = 500)\n    y_pred = xgb.predict_proba(X_test)\n    roc = roc_auc_score(pd.get_dummies(y_test), y_pred)\n    return roc","c804f34b":"print('gbtree: ')\nstudy_xgb = optuna.create_study(study_name='xgboosting classifier using optuna', direction= 'maximize')\nstudy_xgb.optimize(objective_xgb, n_trials = 60)","374bf473":"study_xgb.best_trial.params","02df7b27":"test = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv', index_col = 0)\ntest = pipeline.transform(test)\ntest","155f5b04":"lgb = XGBClassifier(        \n    objective = 'binary:logistic',\n    eval_metric = 'auc',\n    booster ='gbtree',\n    n_estimators  = 10000,\n    use_label_encoder = False,\n    tree_method = 'gpu_hist',\n    predictor = 'gpu_predictor',\n    gpu_id = 0,\n    **study_xgb.best_trial.params)\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\ntest_preds = []\nkf = KFold(n_splits= 10, shuffle = True, random_state = 42)\ni = 0\nfor train_index, valid_index in kf.split(X):\n    X_train, X_valid = X[train_index], X[valid_index]\n    y_train, y_valid = y[train_index], y[valid_index]\n    eval_set = [(X_valid, y_valid)]\n    lgb.fit(X_train, y_train, eval_set = eval_set, eval_metric = 'auc', early_stopping_rounds= 250, verbose = 1000)\n    y_pred = lgb.predict_proba(X_valid)\n    valid_score = roc_auc_score(pd.get_dummies(y_valid), y_pred)\n    print('Split {} : {}'.format(i, valid_score))\n    i+=1\n    test_pred = lgb.predict_proba(test)[:,1]\n    test_preds.append(test_pred)","d8b39d0d":"import numpy as np\nsubmiss = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv', index_col = 0)\nsubmiss['claim'] = np.array(test_preds).mean(axis = 0)\nsubmiss.to_csv('.\/xgb_gbtree.csv')","3e365513":"See my EDA [here](https:\/\/www.kaggle.com\/truongdang1311\/tabular-sep-2021-automl)","c4410588":"## xgboosting with optuna ","8b6d5eda":"#### Try with booster: gbtree"}}