{"cell_type":{"c15fa889":"code","350f7eeb":"code","32f143d5":"code","10e9ecf4":"code","04249c3f":"code","0ed06c9c":"code","e9def9d0":"code","9e5f800c":"code","918c07d3":"code","0447bc4d":"markdown","7cf23fe8":"markdown","b2792522":"markdown","b5775dc8":"markdown"},"source":{"c15fa889":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","350f7eeb":"BASE_DIR = '\/kaggle\/input\/vegetable-image-dataset\/Vegetable Images\/'","32f143d5":"train_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_datagen_flow = train_datagen.flow_from_directory(BASE_DIR + 'train', target_size=(150,150), batch_size=64, seed=42, class_mode='categorical')","10e9ecf4":"valid_datagen = ImageDataGenerator(rescale=1.\/255)\nvalid_datagen_flow = valid_datagen.flow_from_directory(BASE_DIR + 'validation', target_size=(150,150), batch_size=64, seed=42, class_mode='categorical')","04249c3f":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen_flow = test_datagen.flow_from_directory(BASE_DIR + 'test', target_size=(150,150), batch_size=64, seed=42, class_mode='categorical')","0ed06c9c":"model = Sequential()\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(150,150, 3)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(15, activation='softmax'))","e9def9d0":"model.compile(loss='categorical_crossentropy', metrics=['acc', 'AUC'], optimizer='adam')\nmodel.fit(train_datagen_flow, validation_data=valid_datagen_flow, steps_per_epoch=len(train_datagen_flow), \n          validation_steps=len(valid_datagen_flow), epochs=15, verbose=2)","9e5f800c":"_, axes = plt.subplots(1, 3, figsize=(24, 4))\nsns.lineplot(data=model.history.history['acc'], ax=axes[0], label='train_acc')\nsns.lineplot(data=model.history.history['val_acc'], ax=axes[0], label='valid_acc')\nsns.lineplot(data=model.history.history['loss'], ax=axes[1], label='train_loss')\nsns.lineplot(data=model.history.history['val_loss'], ax=axes[1], label='valid_loss')\nsns.lineplot(data=model.history.history['auc'], ax=axes[2], label='train_auc')\nsns.lineplot(data=model.history.history['val_auc'], ax=axes[2], label='valid_auc')\nplt.legend();","918c07d3":"model","0447bc4d":"# Configure and train model","7cf23fe8":"# Model metrics","b2792522":"# Preprocess data","b5775dc8":"# Design net"}}