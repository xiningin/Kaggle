{"cell_type":{"1d7d9499":"code","6df43602":"code","bfd899b4":"code","d4e7bd76":"code","edc2fade":"code","dedb60e0":"code","e5ff4235":"code","1b7ddffe":"code","898c58dd":"code","12f1de35":"code","5aaa9a77":"code","693ba6ce":"code","f77d9da8":"code","383c3ce8":"code","9739be2a":"code","6e10a698":"code","501c9166":"code","9720ae50":"code","8342112a":"code","96d6bd40":"code","b5cb3638":"code","801446da":"code","16706c23":"code","cff533fe":"code","469c4ba3":"code","4f7e859c":"code","21a9124a":"code","08799481":"code","9578f565":"markdown","59b949a3":"markdown","68d5cf57":"markdown","be7bb699":"markdown","d8737731":"markdown","5ad6e85c":"markdown","49768ab1":"markdown","40bae458":"markdown","f19ba126":"markdown","6bfa1a83":"markdown","5a739f2f":"markdown","5d2b645e":"markdown","1b9e9824":"markdown","8e391789":"markdown","42874dc1":"markdown","9a275f1c":"markdown","9800834f":"markdown","d482745d":"markdown","754e6861":"markdown"},"source":{"1d7d9499":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6df43602":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom wordcloud import WordCloud\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import Word, TextBlob\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom warnings import filterwarnings\n\nfilterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.2f' % x)\npd.set_option('display.width', 200)\npd.set_option(\"display.max_colwidth\", -1)","bfd899b4":"train=pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\",encoding='latin1')\ntest=pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\",encoding='latin1')\ndf = test.append(train).reset_index(drop=True)","d4e7bd76":"df.head()","edc2fade":"df['Sentiment'].value_counts()","dedb60e0":"df_ = df[[\"OriginalTweet\", \"Sentiment\"]]\ndf_.head()","e5ff4235":"df_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndf_.head()","1b7ddffe":"df_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].str.replace('[^\\w\\s]', '')\ndf_.head()","898c58dd":"df_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].str.replace('\\d', '')\ndf_.head()","12f1de35":"sw=stopwords.words('english')\ndf_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\ndf_.head()","5aaa9a77":"dropping=pd.Series(' '.join(df_['OriginalTweet']).split()).value_counts()[-1000:]\ndf_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in dropping))","693ba6ce":"df_[\"OriginalTweet\"]=df_[\"OriginalTweet\"].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\ndf_.head()","f77d9da8":"text = \" \".join(i for i in df_.OriginalTweet)\nwordcloud = WordCloud(max_font_size=50,\n                      max_words=300,\n                      background_color=\"white\",\n                     width=1600, height=800).generate(text)\nplt.figure(figsize=(20,10),facecolor='k')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","383c3ce8":"sia = SentimentIntensityAnalyzer()\ndf_[\"sentiment_label\"] = df_[\"OriginalTweet\"].apply(lambda x: \"pos\" if sia.polarity_scores(x)[\"compound\"] > 0 else \"neg\")\ndf_.head(15)","9739be2a":"train_x, test_x, train_y, test_y = train_test_split(df_[\"OriginalTweet\"],\n                                                    df_[\"sentiment_label\"],\n                                                    random_state=17)","6e10a698":"train_x.shape","501c9166":"test_x.shape","9720ae50":"encoder = preprocessing.LabelEncoder()\ntrain_y = encoder.fit_transform(train_y)\ntest_y = encoder.fit_transform(test_y)","8342112a":"vectorizer = CountVectorizer()\nvectorizer.fit(train_x)\nx_train_count = vectorizer.transform(train_x)\nx_test_count = vectorizer.transform(test_x)","96d6bd40":"tf_idf_word_vectorizer = TfidfVectorizer().fit(train_x)\nx_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\nx_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)","b5cb3638":"tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range=(2, 3)).fit(train_x)\nx_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\nx_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)","801446da":"tf_idf_chars_vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(2, 3)).fit(train_x)\nx_train_tf_idf_chars = tf_idf_chars_vectorizer.transform(train_x)\nx_test_tf_idf_chars = tf_idf_chars_vectorizer.transform(test_x)","16706c23":"# TF-IDF Word-Level\nrf_model = RandomForestClassifier().fit(x_train_tf_idf_word, train_y)\ncross_val_score(rf_model, x_test_tf_idf_word, test_y, cv=5, n_jobs=-1).mean()","cff533fe":"# TF-IDF N-GRAM\nrf_model = RandomForestClassifier().fit(x_train_tf_idf_ngram, train_y)\ncross_val_score(rf_model, x_test_tf_idf_ngram, test_y, cv=5, n_jobs=-1).mean()","469c4ba3":"# TF-IDF CHARLEVEL\nrf_model = RandomForestClassifier().fit(x_train_tf_idf_chars, train_y)\ncross_val_score(rf_model, x_test_tf_idf_chars, test_y, cv=5, n_jobs=-1).mean()","4f7e859c":"# Count Vectors\nrf_model = RandomForestClassifier().fit(x_train_count, train_y)\ncross_val_score(rf_model, x_test_count, test_y, cv=5).mean()","21a9124a":"new_comment = pd.Series(\"I really need toilet paper\")\nnew_comment = CountVectorizer().fit(train_x).transform(new_comment)\n\nrf_model.predict(new_comment)","08799481":"new_comment = pd.Series(\"Good\")\nnew_comment = CountVectorizer().fit(train_x).transform(new_comment)\n\nrf_model.predict(new_comment)","9578f565":"### 2. DATA VISUALIZATION","59b949a3":"### 3. SENTIMENT ANALYSIS","68d5cf57":"Word Cloud","be7bb699":"### TF-IDF N-Gram Level","d8737731":"Rare Words","5ad6e85c":"Dropping numbers","49768ab1":"### Count Vectors","40bae458":"Dropping punctuation marks","f19ba126":"Stopwords","6bfa1a83":"Lemmatization","5a739f2f":"# RandomForestClassifier","5d2b645e":"### FEATURE ENGINEERING","1b9e9824":"### TF-IDF Characters Level","8e391789":"Lower - upper case","42874dc1":"### 1. DATA PREPROCESSING","9a275f1c":"#### 1.1 Text Preprocesing","9800834f":"### Example","d482745d":"* Count Vectors\n* TF - IDF Vectors (words, characters, n-grams)\n* Word Embeddings","754e6861":"### TF-IDF Word Level"}}