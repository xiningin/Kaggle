{"cell_type":{"5e0445ee":"code","234c3742":"code","69de9d64":"code","fa0c9601":"code","240ca04e":"code","ccdf90fe":"code","b35a472e":"code","1f5bc5f2":"code","89ea958c":"code","44920a3f":"code","33ab9c21":"code","987a3ef4":"code","1ec38cec":"code","a201f53d":"code","e6d7524c":"code","f73ae39d":"code","de3503d6":"code","2ac855bf":"code","82a720c5":"code","1bb33730":"code","b6204c6c":"code","2d6da993":"code","619cffdd":"code","b509a5b9":"markdown","3ea99ffb":"markdown"},"source":{"5e0445ee":"#%matplotlib notebook\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pandas as pd\nfrom collections import Counter\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\npd.set_option('precision', 3)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport xgboost as xgb","234c3742":"titanic_train = pd.read_csv(\"..\/input\/titanic\/train.csv\", header=0, delimiter=',')\ntitanic_train.head()","69de9d64":"titanic_test = pd.read_csv(\"..\/input\/titanic\/test.csv\", header=0, delimiter=',')\ntitanic_test.head()","fa0c9601":"titanic_train.describe()","240ca04e":"titanic_train[\"Survived\"].value_counts()","ccdf90fe":"titanic_train.isna().sum()\ntitanic_test.isna().sum()","b35a472e":"titanic_train = titanic_train.drop(titanic_train[titanic_train.Embarked.isna()].index) #Nos cargamos los que no se sabe si embarcaron","1f5bc5f2":"titanic_test.Fare.fillna(value = titanic_test.Fare.median(),inplace=True) #a\u00f1adimos el valor que falta","89ea958c":"titanic_train = titanic_train.drop(columns = [\"Cabin\"])\ntitanic_test = titanic_test.drop(columns = [\"Cabin\"])","44920a3f":"#titanic_train = titanic_train.fillna(titanic_train.mean()) #rellenamos age con la media\n#titanic_test = titanic_test.fillna(titanic_test.mean())","33ab9c21":"titanic_train[\"Age\"] = titanic_train.groupby([\"Pclass\", \"Sex\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\ntitanic_test[\"Age\"] = titanic_test.groupby([\"Pclass\", \"Sex\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\n#We fill age with the median of the group the person belongs to","987a3ef4":"titanic_train.count()\ntitanic_test.count()","1ec38cec":"titanic_train.boxplot(column='Fare'); #outlier probable, pero lo dejaremos estar (quiza iba en la suite presidencial o algo)","a201f53d":"titanic_test.boxplot(column='Fare');#lo mismo","e6d7524c":"titanic_train.dtypes #Sex y Embarked son categorical, les haremos OH encoding","f73ae39d":"cat_cols = [\"Sex\", \"Embarked\"]\nOH_cols = pd.get_dummies(titanic_train[cat_cols])\nOH_cols_test = pd.get_dummies(titanic_test[cat_cols])\n#OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n#OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(titanic_train[cat_cols]))\n#OH_cols_train.index = titanic_train.index\n#OH_cols_train.head()\ntitanic_train = titanic_train.drop(cat_cols, axis=1)\ntitanic_train = pd.concat([titanic_train, OH_cols], axis=1)\ntitanic_train.head() #fet\ntitanic_test = titanic_test.drop(cat_cols, axis=1)\ntitanic_test = pd.concat([titanic_test, OH_cols_test], axis=1)\ntitanic_test.head() #fet","de3503d6":"titanic_train[['Age','Fare', 'SibSp', 'Parch']].hist(figsize=(14,4), layout=(1,4)) #correcte","2ac855bf":"titanic_test[['Age','Fare', 'SibSp', 'Parch']].hist(figsize=(14,4), layout=(1,4)) #correcte","82a720c5":"X = titanic_train.drop(\"Survived\", axis=1)\nY = titanic_train[\"Survived\"]\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state=42)\nx_train = x_train.drop(columns = [\"Name\", \"Ticket\"])\ny_train = y_train.drop(columns = [\"Name\", \"Ticket\"])\nx_test = x_test.drop(columns = [\"Name\", \"Ticket\"])\ny_test = y_test.drop(columns = [\"Name\", \"Ticket\"])","1bb33730":"rf = RandomForestClassifier(n_estimators = 300, random_state=0)\ncvrf = cross_val_score(rf, x_train, y_train, cv = 5)\nprint(cvrf)\nprint(cvrf.mean())","b6204c6c":"logreg = LogisticRegression(max_iter = 1000)\ncvlr = cross_val_score(logreg, x_train, y_train, cv = 5)\nprint(cvlr)\nprint(cvlr.mean())","2d6da993":"xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 50, learning_rate = 0.2)\ncvxgb = cross_val_score(xgb_model, x_train, y_train, cv = 5)\nprint(cvxgb)\nprint(cvxgb.mean())","619cffdd":"#submit\nX_fin = titanic_train.drop([\"Name\", \"Ticket\", \"Survived\"], axis = 1)\nY_fin = titanic_train[\"Survived\"]\nrf.fit(X_fin, Y_fin)\ntitanic_test = titanic_test.drop(columns = [\"Name\", \"Ticket\"], axis = 1)\nX_fin.shape\nY_fin.shape\ntitanic_test.shape\nY_pred = rf.predict(titanic_test)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","b509a5b9":"**Top 3% in leadorboards**","3ea99ffb":"### Ejercicio de pre-processing\n\nIn this exercise you need to pre-prcess the train and test data of the titanic dataset. The output of this pre-processing needs to be compatible with using the model LogisticRegression to classify if the patient survived or died.\n\n\nThe pre-processing needs to have the next parts: \n- [ ] Basic inspection of the data. \n- [ ] Dealing with missing values (you can choose what to do with them in each case). \n- [ ] Finding outliers and decide what to do with them. \n- [ ] Extract new variables. \n- [ ] Transform all categorical variables into one-hot-encoding variables. \n- [ ] Transform the numerical variables using one method that makes sense with the LogisticRegression. You can use MinMAx, Standarization, boxcox or any other transformation that makes sense. \n"}}