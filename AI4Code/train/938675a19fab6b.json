{"cell_type":{"1a6557b4":"code","d6335c05":"code","122d1ccb":"code","abd766bc":"code","20708bac":"code","8084bbdd":"code","7c3d594f":"code","6d9970aa":"code","06301818":"code","df545b67":"code","adb20f44":"code","40fb9ace":"code","e59e1cbc":"code","9fb6c54e":"code","8d7aa416":"code","dddf147d":"code","da0cc331":"code","5659e958":"code","900fe9e7":"code","221c9063":"code","b6cccd75":"code","530c5628":"code","a7ad28b1":"code","1e9dc489":"code","7c0a742f":"code","9c86280e":"markdown","4126ecb7":"markdown","8c688a25":"markdown","313eab68":"markdown","13fa3aa1":"markdown","7426bcef":"markdown","06700e4d":"markdown","db55cc8a":"markdown","9aa08c58":"markdown","3473f46f":"markdown"},"source":{"1a6557b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom tensorflow.python.framework import ops\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\nimport time\nimport tensorflow as tf\nimport datetime\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d6335c05":"seed = 7\nnp.random.seed(seed)","122d1ccb":"train_file_name = '..\/input\/train.csv'\ntrain = pd.read_csv(train_file_name)","abd766bc":"print(train.head(5))","20708bac":"test_file_name = '..\/input\/test.csv'\ntest = pd.read_csv(test_file_name)","8084bbdd":"print(test.head(5))","7c3d594f":"X_tr = train\n","6d9970aa":"y = train['target']","06301818":"X_tr = X_tr.drop(columns=['target'])","df545b67":"scaler = StandardScaler()","adb20f44":"data = X_tr.iloc[:, 1:]\nscaler.fit(data)\nStandardScaler(copy=True, with_mean=True, with_std=True)\nX_tr.iloc[:, 1:] = scaler.transform(data)","40fb9ace":"X_test = test\ndata = X_test.iloc[:, 1:]\nscaler.fit(data)\nStandardScaler(copy=True, with_mean=True, with_std=True)\nX_test.iloc[:, 1:] = scaler.transform(data)","e59e1cbc":"print(X_tr.head(5))","9fb6c54e":"print(X_test.head(5))","8d7aa416":"print(X_tr.head(5))","dddf147d":"X = X_tr.iloc[:, 1:]","da0cc331":"# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\nencoded_Y = encoder.transform(y)","5659e958":"def create_baseline():\n\t# create model\n\tmodel = Sequential()\n\tmodel.add(Dense(60, input_dim=200, kernel_initializer='normal', activation='relu'))\n\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n\t# Compile model\n\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model","900fe9e7":"# larger model\ndef create_larger():\n\t# create model\n\tmodel = Sequential()\n\tmodel.add(Dense(60, input_dim=200, kernel_initializer='normal', activation='relu'))\n\tmodel.add(Dense(30, kernel_initializer='normal', activation='relu'))\n\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n\t# Compile model\n\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=500, batch_size=32, verbose=3)))\npipeline = Pipeline(estimators)\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\npipeline.fit(X,y)\n#results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n#print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","221c9063":"y_test = pipeline.predict(X_test.iloc[:, 1:])\n","b6cccd75":"y_test","530c5628":"df = pd.DataFrame()#(y_test, columns = ['Target'])\ndf['ID_code'] = X_test['ID_code']\ndf1 = pd.DataFrame(y_test, columns = ['Target'])\ndf['Target'] = df1['Target']\ndf","a7ad28b1":"id_code = X_test['ID_code']","1e9dc489":"submission = df\n\nsubmission.to_csv('Santander Prediction.csv', index=False)","7c0a742f":"submission","9c86280e":"**Preview of Test data after applying standard scaler**","4126ecb7":"**Importing the required libraries**","8c688a25":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf2 = pd.DataFrame(df)#, columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(df2)\n\n# \u2193 \u2193 \u2193  Yay, download link! \u2193 \u2193 \u2193 ","313eab68":"**Preview of Test Data**","13fa3aa1":"**Preview of train data**","7426bcef":"**Preview of train data after applying Standard Scaler**","06700e4d":"**Standard Scaler for X_test**","db55cc8a":"**Train Data**","9aa08c58":"**Standard Scaler conversion for X_tr**","3473f46f":"**Test Data**"}}