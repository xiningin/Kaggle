{"cell_type":{"69faaafb":"code","83765192":"code","1969fe52":"code","65b86805":"code","30b3bbfb":"code","f4caf772":"code","0917bc3a":"code","62aafe5f":"code","5cbb32e7":"code","dbb5a2d8":"code","b044f1ea":"code","a95d286b":"code","7de6c818":"code","baf0df75":"code","c368e922":"code","2b56b576":"code","09a87bb6":"code","e81f6e33":"code","ba20cd63":"code","9bfaca66":"code","c3965812":"code","35cfcd58":"code","1adedafe":"code","a63d6dce":"code","9822c856":"code","a4e1ca82":"code","a3ba10b4":"code","d84936b0":"code","2e48deab":"code","cf679fe3":"code","efcf8afa":"code","afbe8ea7":"code","9a9ed898":"code","28a4ddd4":"code","6a287bec":"code","87461c3d":"code","0025c584":"code","375e1023":"code","2c7913a6":"code","42e91059":"code","a3f691ef":"code","4f4257b6":"code","ec927781":"code","41d81ed7":"code","29ce6578":"code","498e9d14":"markdown","e2ebcd28":"markdown","8c20cdc5":"markdown","0114a028":"markdown","be59571d":"markdown","6607abc8":"markdown","1919e2b9":"markdown","514ee7fc":"markdown","c87ea990":"markdown","c11cdc71":"markdown","e6150832":"markdown","d33e712c":"markdown","06df1560":"markdown","500e5820":"markdown","b1923047":"markdown","09c9b3c4":"markdown","b0328418":"markdown","cf0ffe96":"markdown","fa9067bd":"markdown","d2fdf763":"markdown","88020229":"markdown","2f28f26b":"markdown","8eefa957":"markdown","27ef5ade":"markdown","b579d0c1":"markdown"},"source":{"69faaafb":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","83765192":"df = pd.DataFrame({'bmi' : [4.0,5.5,6.8,7.2,7.8,9.8,9.7,8.8,11.0,13.0],\n                'glucose' :[60,135,90,175,240,220,300,370,360,365]})","1969fe52":"df","65b86805":"sns.scatterplot(df['bmi'],df['glucose'])\nplt.plot([4,15],[300,550],color = 'r',linestyle = 'dashed')\nplt.plot([4,16],[10,300],color = 'r',linestyle = 'dotted')","30b3bbfb":"n_bmi = len(df['bmi'])\nn_glucose = len(df['glucose'])","f4caf772":"cov_bmi_glu = np.sum((df['bmi'] - np.mean(df['bmi']))*(df['glucose'] - np.mean(df['glucose'])))\/(n_bmi-1)","0917bc3a":"var_bmi = np.sum((df['bmi'] - np.mean(df['bmi']))**2)\/(n_glucose-1)","62aafe5f":"beta1 = cov_bmi_glu\/var_bmi","5cbb32e7":"beta1","dbb5a2d8":"ybar = np.mean(df['glucose'])\nXbar = np.mean(df['bmi'])","b044f1ea":"beta0 = ybar - beta1 * Xbar","a95d286b":"beta0","7de6c818":"glu_predict = beta0 + beta1 * df['bmi']","baf0df75":"glu_predict","c368e922":"sns.scatterplot(df['bmi'],df['glucose'])\nsns.lineplot(df['bmi'],glu_predict,color = 'g')","2b56b576":"sse = np.sum((df['glucose'] - glu_predict)**2)\nmse = sse\/df.count()[0]\nrmse = np.sqrt(mse)","09a87bb6":"rmse","e81f6e33":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","ba20cd63":"lr.fit(df[['bmi']],df['glucose'])","9bfaca66":"lr.coef_","c3965812":"lr.intercept_","35cfcd58":"lr.predict(df[['bmi']])","1adedafe":"r = np.corrcoef(df['glucose'],glu_predict)[0][1]\nr","a63d6dce":"sns.scatterplot(df['glucose'],glu_predict)\nplt.ylabel('predicted glucose values')\nplt.xlabel('actual glucose values')","9822c856":"r_square = r**2\nr_square","a4e1ca82":"lr.score(df[['bmi']],df['glucose'])","a3ba10b4":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols","d84936b0":"df_mtcars = pd.read_csv('..\/input\/mtcars.csv')","2e48deab":"df_mtcars.head()","cf679fe3":"df_mtcars['cyl'].value_counts()","efcf8afa":"df_mtcars.corr()","afbe8ea7":"df_mtcars.columns","9a9ed898":"model = ols('mpg~cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb',df_mtcars).fit()","28a4ddd4":"model.params","6a287bec":"model.summary()","87461c3d":"model = ols('mpg~hp+wt',df_mtcars).fit()","0025c584":"model.params","375e1023":"model.summary()","2c7913a6":"mpg_pred = model.predict(df_mtcars[['hp','wt']])","42e91059":"rmse = np.sqrt(np.sum(((df_mtcars['mpg'] - mpg_pred)**2))\/len(df_mtcars['mpg']))\nrmse","a3f691ef":"import statsmodels.api as sm\nsm.stats.diagnostic.linear_rainbow(model)","4f4257b6":"import statsmodels.stats.api as smi\nsmi.het_goldfeldquandt(model.resid,model.model.exog)","ec927781":"df_mtcars['cyl'].value_counts()","41d81ed7":"mpg_cyl_4 = df_mtcars[df_mtcars['cyl'] == 4]['mpg']\nmpg_cyl_8 = df_mtcars[df_mtcars['cyl'] == 8]['mpg']\nmpg_cyl_6 = df_mtcars[df_mtcars['cyl'] == 6]['mpg']","29ce6578":"from scipy.stats import f_oneway\nf_oneway(mpg_cyl_4,mpg_cyl_6,mpg_cyl_8)","498e9d14":"For dashed line, all residuals will be negative.\n\nFor dotted line, all residuals will be positive.\n\nSSE (sum of squared errors) = sum((residual of each point)**2)\n\nMSE (Mean squared error) = SSE\/total num of data points\n\nRMSE (Root mean squared error) = sqrt(MSE)\n\nCost function = min(MSE)\n\nOur intention\/objective is to minimize our cost function. The line which gives the minimum cost is our best fit line.\n\nbeta1 = covariance of X and y divided by variance of X\n\nbeta1 = cov(X,y)\/var(X)\n\ncov(X,y) = sum_1_to_n((X-Xbar)(y-ybar))\/n-1\n\nvar(X) = sum_1_to_n((X-Xbar)**2)\/n-1\n\nbeta0 = ybar - beta1 * Xbar","e2ebcd28":"### Observations on bivariate linear regression model\n1. For a perfect linear reg model, there should not be any autocorrelation effect. Durbin Watson score = 2 (No Autocorrelation effect). But, our model has a slight positive autocorrelation effect, which inmplies there is certain redundency in the data(multicollinear effect).\n2. pvalue of JB score fails to reject the H0, which implies residuals are normally distributed.\n3. Check the scatterplot of y and y_pred. The pattern should be linear. Statistically use rainbow test. The rainbow test confirms that our model is linear.\n4. Check Goldfeld Quantile Distribution test. Our model shows that the pvalue is very less than 0.05 so we reject the null hypothesis that the data is homoskedstic","8c20cdc5":"r-square => 1 - ( sum((actual_y - predicted_y)** 2) \/ sum((actual_y - ybar)** 2) )","0114a028":"##### So having the actual spread of X how well we can predict y is what rsquare tells us.\n##### Higher the rsquare, better the model. Similarly, lower the RMSE, better the model.","be59571d":"glucose = beta0 + beta1 * bmi","6607abc8":"y -> actual points \n\ny' -> predicted points on the line","1919e2b9":"None of the variables are significant. So we will consider different combinations of variables and try to find the best possible features using rmse score.","514ee7fc":"## R-squared\n\nIt tells how close our predicted y is from our actual y.","c87ea990":"#### Base line Estimator\nIf predicted_y = ybar\n\nr-square -> 0\n\nIf our data is scattered like below:\n<img src=\"img_scatterplot.png\" style=\"width:200px;height;200px\">\n\nSo slope(beta1) will be 0.\n\nSo predicted_y = beta0 + beta1 * X, will become predicted_y = beta0\n\nAs we know beta0 = ybar - beta1 * Xbar, so,\n##### predicted_y = y_bar as beta1 is 0.\n\nSo rsquare = 0, using the above formula","c11cdc71":"##### To check whether 'cyl' feature affects the 'mpg' or not...","e6150832":"For feature selection, correlation matrix will just give us how strongly the variables are correlated with each other, but the final decision whether to keep a variable or drop a variable should be taken by p-value in the ols summary.","d33e712c":"residual = y - y'\n\nThe difference between actual(y) and the predicted(y') is called a residual","06df1560":"***Please UpVote if you like the work!!!***","500e5820":"# Multivariate Regression","b1923047":"***Please UpVote if you like the work!!!***","09c9b3c4":"Consider variable 'am':\n\n1 - Automatic transmission\n0 - Manual transmission\n\nEven if one of the 2 variables in the statistical test is continous, we'll do TEST OF MEAN.\n\nSo for 'am', we'll do a 2 sample independent t-test for automatic vs manual transmission to check if there is significant difference in 'mpg' wrt auto vs manual transmission.","b0328418":"## For multivariate the formulas for betas differ.\n\n(beta1) cyl   =>       -0.111440\n\n(beta2) disp   =>       0.013335\n\n(beta3) hp    =>       -0.021482\n\n(beta4) drat    =>      0.787111\n\n(beta5) wt    =>       -3.715304\n\n(beta6) qsec    =>      0.821041\n\n(beta7) vs    =>        0.317763\n\n(beta8) am   =>         2.520227\n\n(beta9) gear   =>       0.655413\n\n(beta10)carb   =>      -0.199419\n\nIntercept(beta0) = mean(mpg) - beta1 * mean(cyl) - beta2 * mean(disp) - beta3 * mean(hp) - beta4 * mean(drat) - beta5 * mean(wt) - beta6 * mean(qsec) - beta7 * mean(vs) - beta8 * mean(am) - beta9 * mean(gear) - beta10 * mean(carb)","cf0ffe96":"### Verification using the sklearn model","fa9067bd":"This tells how close our predicted y is from the actual y","d2fdf763":"# Univariate Analysis","88020229":"On an average my model predicts the blood glucose level plus or minus 54.88 miligrams\/decilitres","2f28f26b":"## Hypothesis for Regression\n#### H0 : beta1 = 0\n#### H1 : beta1 != 0","8eefa957":"For Regreesion model, we calculate the measures like rmse, r-squared and adjusted rsquared.\n\nFor binary classification, we calculate accuracy,confusion matrix,classification report and ROC AUC curve.\n\nFor multiclass classification, we calculate accuracy,confusion matrix,classification report and f1-score.","27ef5ade":"#### Without independent variable if our model is trying to predict something, it will end up with poor performance and the worst model.","b579d0c1":"##### We will be working on differnt models for regression and classification, but we need to choose the best model for our clients. \n\n##### So for final performance validation, for regression we use RMSE.\n\n##### For binary classification we use AUC and for multiclass classification we use F1-SCORE"}}