{"cell_type":{"129c2776":"code","593a9b6c":"code","1c485857":"code","29729903":"code","a2d797d7":"code","cd9038c7":"code","3fb68eee":"code","9f7cfd1a":"code","73879683":"code","04c18bf2":"code","bd0e2a2b":"code","6a096880":"code","2ebc1669":"code","3a2bd39f":"code","fcd314bf":"code","bf1b187a":"code","79dfa391":"code","4b7a4e52":"code","dffa5298":"code","18864483":"code","109abab3":"code","ced93e42":"code","207f9941":"code","2e7c3771":"code","fe6c3dd4":"code","b0dcd494":"code","4048ab52":"code","52a108e7":"code","ae23f6bc":"code","2c75b93d":"code","fe56f4d7":"code","f0ac5071":"code","6b2e5e98":"code","5b60e2e8":"code","b367ceb6":"code","de34d267":"code","1a7eed07":"markdown","307cb644":"markdown","b3efccef":"markdown","40c56e46":"markdown","48be3b92":"markdown","b8784b6a":"markdown"},"source":{"129c2776":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nfrom seaborn import countplot,lineplot, barplot\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\nfrom fastai import *\nfrom fastai.tabular import *\nfrom fastai.basic_data import DataBunch\nfrom tqdm import tqdm_notebook\n\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb","593a9b6c":"tr = pd.read_csv('..\/input\/X_train.csv')\nte = pd.read_csv('..\/input\/X_test.csv')\ntarget = pd.read_csv('..\/input\/y_train.csv')\nss = pd.read_csv('..\/input\/sample_submission.csv')","1c485857":"tr.head()","29729903":"tr.shape, te.shape","a2d797d7":"countplot(y = 'surface', data = target)\nplt.show()","cd9038c7":"len(tr.measurement_number.value_counts())","3fb68eee":"tr.shape[0] \/ 128, te.shape[0] \/ 128","9f7cfd1a":"def quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z","73879683":"def fe_step0 (actual):\n    \n    # https:\/\/www.mathworks.com\/help\/aeroblks\/quaternionnorm.html\n    # https:\/\/www.mathworks.com\/help\/aeroblks\/quaternionmodulus.html\n    # https:\/\/www.mathworks.com\/help\/aeroblks\/quaternionnormalize.html\n        \n    actual['norm_quat'] = (actual['orientation_X']**2 + actual['orientation_Y']**2 + actual['orientation_Z']**2 + actual['orientation_W']**2)\n    actual['mod_quat'] = (actual['norm_quat'])**0.5\n    actual['norm_X'] = actual['orientation_X'] \/ actual['mod_quat']\n    actual['norm_Y'] = actual['orientation_Y'] \/ actual['mod_quat']\n    actual['norm_Z'] = actual['orientation_Z'] \/ actual['mod_quat']\n    actual['norm_W'] = actual['orientation_W'] \/ actual['mod_quat']\n    \n    return actual\n\ndef fe_step1 (actual):\n    \"\"\"Quaternions to Euler Angles\"\"\"\n    \n    x, y, z, w = actual['norm_X'].tolist(), actual['norm_Y'].tolist(), actual['norm_Z'].tolist(), actual['norm_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    return actual","04c18bf2":"%%time\ntr = fe_step0(tr)\nte = fe_step0(te)\n\ntr = fe_step1(tr)\nte = fe_step1(te)","bd0e2a2b":"def fe(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 +\n                             data['angular_velocity_Z'])** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 +\n                             data['linear_acceleration_Z'])**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 +\n                             data['orientation_Z'])**0.5\n   \n    data['acc_vs_vel'] = data['totl_linr_acc'] \/ data['totl_anglr_vel']\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number', 'group_id']:\n            continue\n        if col in ['surface']:\n            df[col] = data\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] \/ df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])\/2\n    return df","6a096880":"%%time\ntr = fe(tr)\nte = fe(te)\ntr.head()","2ebc1669":"tr.shape, te.shape","3a2bd39f":"tr.head()","fcd314bf":"tr = tr.merge(target, on='series_id', how='inner')\ntr = tr.drop(['group_id', 'series_id'], axis=1)\ntr.shape, te.shape","bf1b187a":"le = LabelEncoder()\ntr['surface'] = le.fit_transform(tr['surface'])","79dfa391":"tr.fillna(0, inplace = True)\nte.fillna(0, inplace = True)","4b7a4e52":"tr.replace(-np.inf, 0, inplace = True)\ntr.replace(np.inf, 0, inplace = True)\nte.replace(-np.inf, 0, inplace = True)\nte.replace(np.inf, 0, inplace = True)","dffa5298":"tr.head()","18864483":"features = tr.drop('surface', axis=1).columns.values","109abab3":"BATCH_SIZE = 64\nrandom.seed(2019)\nvalid_idx = random.sample(list(tr.index.values), int(len(tr)*0.05))","ced93e42":"def get_data_learner(train_df, train_features, valid_idx, \n                     lr=0.02, epochs=1, layers=[512, 512, 256], ps=[0.2, 0.2, 0.2], name='learner'):\n    data = TabularDataBunch.from_df(path='.', df=train_df, \n                                    dep_var='surface', \n                                    valid_idx=valid_idx, \n                                    cat_names=[], \n                                    cont_names=train_features, \n                                    bs=BATCH_SIZE,\n                                    procs=[Normalize],\n                                    test_df=te)\n    learner = tabular_learner(data, layers=layers, ps=ps, metrics=[accuracy], use_bn=True)\n    return learner, data","207f9941":"learner, data = get_data_learner(tr, features, np.array(valid_idx))","2e7c3771":"learner.fit_one_cycle(5, 1e-2)","fe6c3dd4":"learner.lr_find()\nlearner.recorder.plot()","b0dcd494":"learner.fit_one_cycle(5, 1e-3)","4048ab52":"learner.lr_find()\nlearner.recorder.plot()","52a108e7":"learner.fit_one_cycle(5, 1e-4)","ae23f6bc":"learner.lr_find()\nlearner.recorder.plot()","2c75b93d":"learner.fit_one_cycle(5, 5e-5)","fe56f4d7":"val_predictions = np.squeeze(to_np(learner.get_preds(DatasetType.Valid)[0])).argmax(axis=1)","f0ac5071":"predictions = np.squeeze(to_np(learner.get_preds(DatasetType.Test)[0])).argmax(axis=1)\nte['surface'] = predictions\nte['surface'] = le.inverse_transform(predictions.round().astype(np.int32))","6b2e5e98":"te[['surface']].to_csv(f'submission_fastai.csv')\nte[['surface']].head()","5b60e2e8":"te['surface'].value_counts()","b367ceb6":"import itertools\n\ndef plot_confusion_matrix(truth, pred, classes, normalize=False, title=''):\n    cm = confusion_matrix(truth, pred)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion matrix', size=15)\n    plt.colorbar(fraction=0.046, pad=0.04)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(False)\n    plt.tight_layout()","de34d267":"plot_confusion_matrix(tr['surface'].iloc[valid_idx], val_predictions, le.classes_)","1a7eed07":"## Feature Engineering","307cb644":"So, we have 3810 train series, and 3816 test series.\nLet's engineer some features!","b3efccef":"## Confusion matrix","40c56e46":"What's that?\nEach series has 128 measurements. ","48be3b92":"## fastai model","b8784b6a":"We need to classify on which surface our robot is standing.\n\nSo, its a simple classification task. Multi-class to be specific."}}