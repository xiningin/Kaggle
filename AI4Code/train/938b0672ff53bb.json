{"cell_type":{"1e7dd430":"code","deb93666":"code","33813140":"code","a2744c46":"code","007a36a9":"code","cf14bc8e":"code","251ca794":"code","e5800071":"code","c7bb2fde":"code","5d8ca153":"code","31e5b3ac":"code","5e46aa6f":"code","169035c4":"markdown","430362ed":"markdown","ca8d4298":"markdown","df55026a":"markdown","1c9cce7c":"markdown","8aa76a21":"markdown","06460527":"markdown","4acbd87a":"markdown","da28efc6":"markdown","9a6e6312":"markdown","c09ad3e2":"markdown","1c29d58c":"markdown","77f97c7d":"markdown"},"source":{"1e7dd430":"import os","deb93666":"from IPython.display import Image\nimport matplotlib.pyplot as plt\nimport sys\nimport pickle\nfrom sklearn import preprocessing\nfrom time import time\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nsys.path.append(\"..\/input\/\")\n\n\nfrom feature_format import featureFormat\nfrom feature_format import targetFeatureSplit\n\n### features_list is a list of strings, each of which is a feature name\n### first feature must be \"poi\", as this will be singled out as the label\nfeatures_list = [\"poi\"]\n\n### load the dictionary containing the dataset\noriginal = \"..\/input\/final_project_dataset.pkl\"\ndestination = \"final_dataset.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))\n        \ndata_dict = pickle.load(open(\"final_dataset.pkl\", \"rb\") )","33813140":"print (\"There are \", len(data_dict.keys()), \" executives in Enron Dataset.\")","a2744c46":"print( data_dict.keys())","007a36a9":"print (data_dict['BUY RICHARD B'])","cf14bc8e":"features = [\"salary\", \"bonus\"]\n#data_dict.pop('TOTAL', 0)\ndata = featureFormat(data_dict, features)\n### plot features\nfor point in data:\n    salary = point[0]\n    bonus = point[1]\n    plt.scatter( salary, bonus )\n\nplt.xlabel(\"salary\")\nplt.ylabel(\"bonus\")\nplt.show()","251ca794":"### remove any outliers before proceeding further\nfeatures = [\"salary\", \"bonus\"]\ndata_dict.pop('TOTAL', 0)\ndata = featureFormat(data_dict, features)\n\n### remove NAN's from dataset\noutliers = []\nfor key in data_dict:\n    val = data_dict[key]['salary']\n    if val == 'NaN':\n        continue\n    outliers.append((key, int(val)))\n\noutliers_final = (sorted(outliers,key=lambda x:x[1],reverse=True)[:4])\n### print top 4 salaries\nprint (outliers_final)","e5800071":"### create new features\n### new features are: fraction_to_poi_email,fraction_from_poi_email\n\ndef dict_to_list(key,normalizer):\n    new_list=[]\n\n    for i in data_dict:\n        if data_dict[i][key]==\"NaN\" or data_dict[i][normalizer]==\"NaN\":\n            new_list.append(0.)\n        elif data_dict[i][key]>=0:\n            new_list.append(float(data_dict[i][key])\/float(data_dict[i][normalizer]))\n    return new_list\n\n### create two lists of new features\nfraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\nfraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\n\n### insert new features into data_dict\ncount=0\nfor i in data_dict:\n    data_dict[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[count]\n    data_dict[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[count]\n    count +=1\n\n    \nfeatures_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\"]    \n    ### store to my_dataset for easy export below\nmy_dataset = data_dict\n\n\n### these two lines extract the features specified in features_list\n### and extract them from data_dict, returning a numpy array\ndata = featureFormat(my_dataset, features_list)\n\n### plot new features\nfor point in data:\n    from_poi = point[1]\n    to_poi = point[2]\n    plt.scatter( from_poi, to_poi )\n    if point[0] == 1:\n        plt.scatter(from_poi, to_poi, color=\"r\", marker=\"*\")\nplt.xlabel(\"fraction of emails this person gets from poi\")\nplt.show()","c7bb2fde":"features_list = [\"poi\", \"salary\", \"bonus\", \"fraction_from_poi_email\", \"fraction_to_poi_email\",\n                 'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\ndata = featureFormat(my_dataset, features_list)\n\n### split into labels and features (this line assumes that the first\n### feature in the array is the label, which is why \"poi\" must always\n### be first in features_list\nlabels, features = targetFeatureSplit(data)\n\n### split data into training and testing datasets\nfrom sklearn.model_selection import train_test_split\nfeatures_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nt0 = time()\n\nclf = DecisionTreeClassifier()\nclf.fit(features_train,labels_train)\nscore = clf.score(features_test,labels_test)\npred= clf.predict(features_test)\nprint ('accuracy', score)\n\nprint (\"Decision tree algorithm time:\", round(time()-t0, 3), \"s\")\n\n\n\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)[::-1]\nprint ('Feature Ranking: ')\nfor i in range(16):\n    print (\"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]]))","5d8ca153":"features_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", \"shared_receipt_with_poi\"]\n\n### try Naive Bayes for prediction\nt0 = time()\n\nclf = GaussianNB()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\naccuracy = accuracy_score(pred,labels_test)\nprint (\"Gaussian NB Accuracy : \",accuracy)\n\nprint (\"NB algorithm time:\", round(time()-t0, 3), \"s\")\n\nfrom sklearn.ensemble import RandomForestClassifier\nt0 = time()\nclf3 = RandomForestClassifier(n_estimators=10)\nclf3.fit(features_train, labels_train)\npred = clf3.predict(features_test)\nrf_score = clf3.score(features_test, labels_test)\n\nrf_acc = accuracy_score(labels_test, pred)\nprint (\"RF accuracy: \", rf_acc)\nprint (\"RF algorithm time:\", round(time()-t0, 3), \"s\")","31e5b3ac":"### use manual tuning parameter min_samples_split\nclf = DecisionTreeClassifier(min_samples_split=5)","5e46aa6f":"### features_list is a list of strings, each of which is a feature name\n### first feature must be \"poi\", as this will be singled out as the label\nfeatures_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", 'shared_receipt_with_poi']\n\n\n### store to my_dataset for easy export below\nmy_dataset = data_dict\n\n\n### these two lines extract the features specified in features_list\n### and extract them from data_dict, returning a numpy array\ndata = featureFormat(my_dataset, features_list)\n\n\n### split into labels and features (this line assumes that the first\n### feature in the array is the label, which is why \"poi\" must always\n### be first in features_list\nlabels, features = targetFeatureSplit(data)\n\n\n### machine learning goes here!\n### please name your classifier clf for easy export below\n\n### deploying feature selection\nfrom sklearn.model_selection import train_test_split\nfeatures_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n### use manual tuning parameter min_samples_split\nt0 = time()\nclf = DecisionTreeClassifier(min_samples_split=5)\nclf = clf.fit(features_train,labels_train)\npred= clf.predict(features_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nacc=accuracy_score(labels_test, pred)\n\nprint (\"accuracy after tuning = \", acc)\n\n\n### dump my classifier, dataset and features_list so\n### anyone can run\/check your results\npickle.dump(clf, open(\"my_classifier.pkl\", \"wb\") )\npickle.dump(data_dict, open(\"my_dataset.pkl\", \"wb\") )\npickle.dump(features_list, open(\"my_feature_list.pkl\", \"wb\") )","169035c4":"In order to find the most effective features for classification, feature selection using \u201cDecision Tree\u201d  was deployed to rank the features. Selection features was half manual iterative process. First I put all the possible features into features_list and then started deleting them one by one using score value and human intuition.","430362ed":"First of all I\u2019d like to have a look at my data and check it for outliers. I plot salaries and bonuses on Enron employees and see an outlier in the data.","ca8d4298":"Finally I picked the following features:\n**[\"fraction_from_poi_email\", \"fraction_to_poi_email\", \u201cshared_receipt_with_poi\u201d]**","df55026a":"There are four major steps in my project:  \n1. Enron dataset\n2. Feature processing\n3. Algorithm\n4. Validation","1c9cce7c":"Firstly let's look how data is structured.","8aa76a21":"## Analysis Validation and Performance","06460527":"## Algorithm Selection and Tuning","4acbd87a":"## Feature processing","da28efc6":"After cleaning the data from outliers I had to pick the most sensible features to use. First I picked 'from_poi_to_this_person' and  'from_this_person_to_poi' but there is was no strong pattern when I plotted the data so I used fractions for both features of \u201cfrom\/to poi messages\u201d and \u201ctotal from\/to messages\u201d.","9a6e6312":"## Project Overview","c09ad3e2":"When I check it I see this is a number for total salary and bonus. As this is not sensible information for our analysis I remove it manually. Two more outliers (SKILLING JEFFREY and LAY KENNETH) I keep in dataset as these values real and actually they are already a sign of these two managers being involved in the fraud. Now dataset look like this:","1c29d58c":"## The Enron Data","77f97c7d":"Finally I picked 10 features which are:\n```\n[\"salary\", \"bonus\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", 'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value']\n```\n\n"}}