{"cell_type":{"9f960c64":"code","b8e01874":"code","22a12da6":"code","4df4857b":"code","44ac0615":"code","4bf23bcc":"code","a96d6f97":"code","9c8fb714":"code","30fcbb9d":"code","8bf2f0f7":"code","9e5ff168":"code","fa0593a7":"code","82236883":"code","8acb79d3":"code","5c91d93c":"code","c16061c1":"code","76f06b50":"code","5a26fdc0":"code","20daf00b":"code","b9de46b0":"code","5fc37143":"code","a88d1a9b":"code","5b750f50":"code","4f0df8a2":"code","e1a9baa9":"code","35f0d5c3":"code","bc6dfcb6":"code","3dcc60f7":"markdown","0905d787":"markdown","dd598463":"markdown","cae7c667":"markdown","609fd148":"markdown","a9e7498f":"markdown","6bd94bb1":"markdown","9bf01be8":"markdown","a3d4aacc":"markdown"},"source":{"9f960c64":"!pip install keras==2.2.4","b8e01874":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport shutil\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","22a12da6":"from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nbatch_size = 256\ninput_shape = (128, 128)\ninput_shape_2 = (128, 128, 3)","4df4857b":"train_df = pd.read_csv(\"..\/input\/humpback-whale-identification\/train.csv\")\ntrain_df.head()","44ac0615":"bbox = pd.read_csv('..\/input\/generating-whale-bounding-boxes\/bounding_boxes.csv')\nbbox.head()","4bf23bcc":"from PIL import Image as pimg\nfrom scipy.misc import imresize\n\nimage_name = '72c3ce75c.jpg'\nimg = image.load_img(\"..\/input\/humpback-whale-identification\/train\/\"+image_name)\nx = image.img_to_array(img)\nx = np.uint8(x)\ndetails = bbox[bbox['Image']==image_name]\nnew_x = x[int(details.x0):int(details.x1), int(details.y0):int(details.y1)]\n\nplt.figure(1)\nplt.imshow(x)\nplt.figure(2)\nplt.imshow(new_x)\n\nnewnew = imresize(new_x, size=input_shape_2)\nplt.figure(3)\nplt.imshow(newnew)","a96d6f97":"def prepareImages_bbox(data, bbox, m, dataset, preprocess=False):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, 128, 128, 3))\n    count = 0\n    \n    for fig in data['Image']:\n        # Load images into images of size 100x100x3\n#         if not preprocess:\n#             img = image.load_img(\"..\/input\/humpback-whale-identification\/\"+dataset+\"\/\"+fig)\n#             x = image.img_to_array(img)\n#             x0 = int(bbox[bbox['Image']==fig].x0)\n#             x1 = int(bbox[bbox['Image']==fig].x1)\n#             y0 = int(bbox[bbox['Image']==fig].y0)\n#             y1 = int(bbox[bbox['Image']==fig].y1)\n#             if not (x0 >= x1 or y0 >= y1):\n#                 x = x[y0:y1, x0:x1,:]\n#             else :\n#                 x = x[x0:x1, y0:y1, :]\n#             try:\n#                 x = imresize(x, size=(128, 128, 3))\n#             except:\n#                 print(x.shape)\n#                 break\n#         else:\n        img = image.load_img(\"..\/input\/humpback-whale-identification\/\"+dataset+\"\/\"+fig, target_size=(128,128,3))\n        x = image.img_to_array(img)\n        if preprocess == True:\n            x = preprocess_input(x)\n\n        X_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return X_train","9c8fb714":"from keras.preprocessing.image import ImageDataGenerator\n\n# dtypes = {\n#     'Image' : 'str',\n#    'Id' : 'str',\n# }\n\n# train_dir = \"..\/input\/humpback-whale-identification\/train\"\n# test_dir = \"..\/input\/humpback-whale-identification\/test\"\n\n# df = pd.read_csv('..\/input\/humpback-whale-identification\/train.csv', dtype = dtypes)\n# df = df[df['Id'] != 'new_whale']\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input,\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     horizontal_flip=True)\n\n# train_generator = datagen.flow_from_dataframe(\n#     dataframe = df,\n#     directory = train_dir,\n#     x_col = \"Image\",\n#     y_col = \"Id\",\n#     has_ext = True,\n#     classes = np.unique(df.Id.values).tolist(),\n#     class_mode = \"categorical\",\n#     target_size = input_shape,\n#     batch_size = batch_size\n# )","30fcbb9d":"def prepare_labels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n    # print(integer_encoded)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n    # print(onehot_encoded)\n\n    y = onehot_encoded\n    # print(y.shape)\n    return y, label_encoder","8bf2f0f7":"'''\nLet's remove the new_whale class and see the results now\n'''\nnew_whale_excluded = train_df[train_df['Id'] != 'new_whale']\n\nnew_whale_excluded = (new_whale_excluded.reset_index()).drop(columns='index')","9e5ff168":"X_val = prepareImages_bbox((new_whale_excluded[int(len(new_whale_excluded)*0.9):]).reset_index(), bbox, len((new_whale_excluded[int(len(new_whale_excluded)*0.9):])), \"train\")\nX = prepareImages_bbox((new_whale_excluded[:int(len(new_whale_excluded)*0.9)]).reset_index(), bbox, len((new_whale_excluded[:int(len(new_whale_excluded)*0.9)])), \"train\")","fa0593a7":"y, label_encoder = prepare_labels(new_whale_excluded['Id'])\ny_val = y[int(len(new_whale_excluded)*0.9):]\ny = y[:int(len(new_whale_excluded)*0.9)]","82236883":"from keras.preprocessing.image import ImageDataGenerator\n\n'''\nAdditional parameters if you want to use \nrotation_range=20,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nzoom_range=0.2,\n'''\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=60,\n    width_shift_range=0.2,\n    shear_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n\ndatagen.fit(X)","8acb79d3":"from keras.applications.resnet50 import ResNet50\n\nconv_base = ResNet50(include_top = False,\n                    weights = 'imagenet',\n                    input_shape = (input_shape_2))\n\nset_trainable = False\n\nfor layer in conv_base.layers:\n    if layer.name == 'res5b_branch2a':\n        set_trainable = True\n        print('Got here')\n    if set_trainable:\n        layer.trainable = True\n    else :\n        layer.trainable = False\n        \nconv_base.summary()\n\n","5c91d93c":"def top_5_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=5)","c16061c1":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_accuracy, categorical_crossentropy, top_k_categorical_accuracy\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.layers import Lambda\n\n\n'''\nBuild_model() function to generate a generic model \n'''\n\ndef build_model(conv_base):\n    model = Sequential()\n    model.add(Lambda(preprocess_input, name='preprocessing', input_shape=(128, 128, 3)))\n    model.add(conv_base)\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu')) \n    model.add(Dropout(0.5))\n    model.add(Dense(5004, activation='softmax')) # 5005 classes\n    \n    model.compile(optimizer=Adam(lr=0.001, decay=1e-6),\n                 loss='categorical_crossentropy',\n                 metrics=[categorical_crossentropy, categorical_accuracy, top_5_accuracy])\n    \n    model.summary()\n    \n    return model","76f06b50":"model = build_model(conv_base)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_top_5_accuracy', factor=0.2,\n                              patience=5, min_lr=0.0005)\n\nearly = EarlyStopping(monitor='val_top_5_accuracy', mode='max', patience=5)\n\nhistory = model.fit_generator(datagen.flow(X, y, batch_size=batch_size), validation_data=(X_val, y_val), epochs=50, verbose=1, callbacks=[reduce_lr, early])","5a26fdc0":"# model = build_model(conv_base)\n\n# train_samples = train_generator.filenames\n# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n#                               patience=1, min_lr=0.0005)\n\n# history = model.fit_generator(\n#     train_generator,\n#     steps_per_epoch=len(train_samples)\/batch_size,\n#     epochs=50,\n#     callbacks=[reduce_lr]\n# )","20daf00b":"'''\nPlotting loss and accuracy\n'''\n\nimport matplotlib.pyplot as plt\nacc = history.history['categorical_accuracy']\ntop5_acc = history.history['top_5_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nval_top5_acc = history.history['val_top_5_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.figure(1)\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure(2)\n\nplt.plot(epochs, top5_acc, 'bo', label='Training top_5_accuracy')\nplt.plot(epochs, val_top5_acc, 'b', label='Validation top_5_accuracy')\nplt.title('Training and validation top5_accuracy')\nplt.legend()\n\nplt.figure(3)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","b9de46b0":"# model.save('resnet-v3.h5')","5fc37143":"sample_sub = pd.read_csv(\"..\/input\/humpback-whale-identification\/sample_submission.csv\")\ntest = list(sample_sub.Image)\nprint(len(test))\n\ncol = ['Image']\ntest_df = pd.DataFrame(test, columns=col)\ntest_df['Id'] = ''","a88d1a9b":"from keras.preprocessing.image import ImageDataGenerator\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n)\n\ntest_dir = \"..\/input\/humpback-whale-identification\/test\"\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_df,\n    directory = test_dir,\n    x_col = \"Image\",\n    y_col = \"Id\",\n    has_ext = True,\n    class_mode = None,\n    target_size = input_shape,\n    batch_size = batch_size\n)","5b750f50":"# X = prepareImages_bbox(test_df, bbox, test_df.shape[0], \"test\", preprocess=True)\nunique_labels = np.unique(new_whale_excluded['Id'].values)\n\nlabels_dict = dict()\nlabels_list = []\nfor i in range(len(unique_labels)):\n    labels_dict[unique_labels[i]] = i\n    labels_list.append(unique_labels[i])","4f0df8a2":"test_samples = test_generator.filenames\nprint(len(test_samples))\n\ntest_generator.reset()\npredictions = model.predict_generator(\n    test_generator,\n    steps=len(test_samples)\/batch_size,\n    verbose=1\n)","e1a9baa9":"print(len(labels_list))","35f0d5c3":"best_th = 0.38\n\npreds_t = np.concatenate([np.zeros((predictions.shape[0],1))+best_th, predictions],axis=1)\nnp.save(\"preds.npy\",preds_t)","bc6dfcb6":"sample_df = pd.read_csv(\"..\/input\/humpback-whale-identification\/sample_submission.csv\")\nsample_list = list(sample_df.Image)\nlabels_list = [\"new_whale\"]+labels_list\npred_list = [[labels_list[i] for i in p.argsort()[-5:][::-1]] for p in preds_t]\npred_dic = dict((key, value) for (key, value) in zip(test_samples,pred_list))\npred_list_cor = [' '.join(pred_dic[id]) for id in sample_list]\ndf = pd.DataFrame({'Image':sample_list,'Id': pred_list_cor})\ndf.to_csv('submission.csv', header=True, index=False)\ndf.head()","3dcc60f7":"### Save model","0905d787":"\n### Fitting the model","dd598463":"### Importing train.csv","cae7c667":"### Convert predictions back to their original name","609fd148":"\n### Define the model","a9e7498f":"### Create test directory","6bd94bb1":"## Building the network (ResNet50)","9bf01be8":"## Add the Fully connected layers on top of the conv_base","a3d4aacc":"## Preprocessing input"}}