{"cell_type":{"fd9dc472":"code","ad90dc19":"code","06acbfd6":"code","2e09392b":"code","cfe6dc43":"code","44f65447":"code","6bb927a7":"code","ffff8a95":"code","91d59b0c":"code","7abf52e2":"code","39b0a3a8":"code","5af33787":"code","0785d850":"code","bb314657":"code","047fc144":"code","e4507429":"code","02dcd626":"code","832930bf":"code","8cb49179":"code","a5934d46":"code","e918c6e2":"code","c76661b2":"code","931776af":"code","8a9fcc3d":"code","60aeda79":"code","f6dde8c9":"code","80ccde62":"code","9fd5bbdf":"code","748b5a26":"code","0465ba48":"code","f6358875":"code","7860cc3a":"code","7c335a53":"code","58cab3d4":"code","d25fb1d7":"code","25291edb":"code","af23b02a":"code","597c30d3":"code","d1b5b0ba":"code","19a6b323":"code","0634c82c":"code","0f030c9e":"code","b5d56eeb":"code","c4176b1e":"markdown","64f73075":"markdown"},"source":{"fd9dc472":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\nimport matplotlib.pyplot as plt\n%matplotlib inline","ad90dc19":"data_dir = '..\/input\/animal-images-dataset\/animal_images'","06acbfd6":"labels=pd.read_csv('..\/input\/animal-images-dataset\/animal_data_img.csv')\nlabels","2e09392b":"Name = labels['Animal_Type'].unique().tolist()\nprint(Name)\nprint(len(Name))","cfe6dc43":"N=list(range(len(Name)))    \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","44f65447":"labels['label']=labels['Animal_Type'].map(normal_mapping)\nfiles = labels['Image_File'].unique().tolist()\nprint(files[0:10])\nprint(len(files))","6bb927a7":"dataset=[]\nfor i in tqdm(range(len(labels))):\n    labeli=labels.loc[i,'label']\n    filei=labels.loc[i,'Image_File']\n    path=os.path.join(data_dir,filei)\n    img1=cv2.imread(path)\n    img2=cv2.resize(img1,dsize=(40,40),interpolation=cv2.INTER_CUBIC)\n    img3=img2.astype(np.float32)\n    image=torch.from_numpy(img3).permute(2,0,1) ###\n    dataset+=[[image,labeli]]","ffff8a95":"dataset[100]","91d59b0c":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(img.shape)\nprint(label)","7abf52e2":"def show_image(img,label):\n    plt.imshow(img.permute(1,2,0).numpy().astype(int))","39b0a3a8":"show_image(*dataset[20])","5af33787":"torch.manual_seed(20)\nval_size = len(dataset)\/\/10\ntest_size = len(dataset)\/\/5\ntrain_size = len(dataset) - val_size - test_size","0785d850":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds) ","bb314657":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)","047fc144":"m=len(dataset)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","e4507429":"dataset[0][0]","02dcd626":"fig, axs = plt.subplots(4,4,figsize=(15,15))\nfor i in range(16):\n    r=i\/\/4\n    c=i%4\n    img, label = dataset[M[i]]\n    ax=axs[r][c].axis(\"off\")\n    ax=axs[r][c].set_title(reverse_mapping[label])\n    ax=axs[r][c].imshow(img.permute(1,2,0).numpy().astype(int))\nplt.show()","832930bf":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","8cb49179":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","a5934d46":"torch.cuda.is_available()","e918c6e2":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","c76661b2":"device = get_default_device()\ndevice","931776af":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","8a9fcc3d":"m=len(dataset)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","60aeda79":"input_size = 3*40*40\noutput_size = len(Name)","f6dde8c9":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                   # Generate predictions\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","80ccde62":"class CnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 100, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(100, 150, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(150, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(200, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(200, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(250, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Flatten(), \n            nn.Linear(6250, 64),  \n            nn.ReLU(),            \n            nn.Linear(64, 32),  \n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(32, output_size))\n        \n    def forward(self, xb):\n        return self.network(xb)","9fd5bbdf":"model = CnnModel()\n#model.cuda()","748b5a26":"model","0465ba48":"for images, labels in train_loader:\n    print('images.shape:', images.shape)    \n    out = model(images)      \n    print('out.shape:', out.shape)\n    break","f6358875":"device = get_default_device()\ndevice","7860cc3a":"train_dl = DeviceDataLoader(train_loader, device)\nval_dl = DeviceDataLoader(val_loader, device)\nto_device(model, device)","7c335a53":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","58cab3d4":"model = to_device(CnnModel(), device)","d25fb1d7":"history=[evaluate(model, val_loader)]\nhistory","25291edb":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.01","af23b02a":"history+= fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","597c30d3":"history+= fit(num_epochs, lr\/10, model, train_dl, val_dl, opt_func)","d1b5b0ba":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","19a6b323":"plot_accuracies(history)","0634c82c":"plot_losses(history)","0f030c9e":"evaluate(model, test_loader)","b5d56eeb":"from sklearn.metrics import classification_report\n\npred = []\nY = []\nfor i, (x,y) in enumerate(test_loader):\n    with torch.no_grad():\n        outputs = model(x)\n    pred += [int(op.argmax()) for op in outputs]\n    Y += [int(yi) for yi in y]\n\nprint(classification_report(Y, pred))\n","c4176b1e":"# Conv2d Model","64f73075":"# Animal Images Classify Torch Conv2d"}}