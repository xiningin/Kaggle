{"cell_type":{"69612326":"code","7568f1c1":"code","fc094028":"code","12491f3b":"code","7bd33e27":"code","e0d212fe":"code","8d796c62":"code","ca767192":"code","1b2e898b":"code","29e99674":"code","93f93d5b":"code","cf874d88":"code","9b3b0bce":"code","2c0f13e1":"code","da570551":"code","9b4d74a5":"code","cb46d4aa":"code","06e87210":"code","7e3dec6f":"code","aaa35420":"code","a2d13efa":"code","67550f6e":"code","ee12d2eb":"code","2c73f21e":"code","7773138d":"code","2639565b":"code","413858fc":"code","ec58502e":"code","bdef2c17":"code","ece3c563":"code","ebbc3ea1":"code","58053781":"code","eed9a1e2":"code","aa743ed0":"code","42aefbbf":"code","71f9f4ac":"code","c61a201a":"code","dd338feb":"code","5f92340f":"code","7123272a":"code","0d46a31e":"code","b4dd38d4":"code","df587b09":"markdown","27f0d716":"markdown","09eb4cb7":"markdown","98c8a3d3":"markdown","8e2e9f62":"markdown","53d53c56":"markdown"},"source":{"69612326":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7568f1c1":"import bz2\nimport pandas as pd\nimport re \nimport numpy as np","fc094028":"#Import Dataset\ntrain_file = bz2.BZ2File('..\/input\/amazonreviews\/train.ft.txt.bz2')\ntest_file = bz2.BZ2File('..\/input\/amazonreviews\/test.ft.txt.bz2')","12491f3b":"#Reading Data set\ntrain_file = train_file.readlines()\ntest_file = test_file.readlines()\n","7bd33e27":"print(\"Number of training reivews: \" + str(len(train_file)))\nprint(\"Number of test reviews: \" + str(len(test_file)))","e0d212fe":"#training on the first 10000 reviews in the  dataset\nnum_train = 100000\n#Using 2000 reviews from test set\nnum_test = 20000#Using 200,000 reviews from test set\n\ntrain_file = [x.decode('utf-8') for x in train_file[:num_train]]\ntest_file = [x.decode('utf-8') for x in test_file[:num_test]]","8d796c62":"#Extracing Labels and Review from traing Dataset\ntrain_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\ntrain_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]","ca767192":"#Extracing Labels and Review from test Dataset\ntest_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\ntest_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]","1b2e898b":"train = pd.DataFrame({'text':train_sentences,'label':train_labels})\ntest=pd.DataFrame({'text':test_sentences,'label':test_labels})","29e99674":"train.head()","93f93d5b":"train.describe()","cf874d88":"train['number_of_words'] = train['text'].str.lower().str.split().apply(len)\ntrain.head()","9b3b0bce":"test['number_of_words'] = test['text'].str.lower().str.split().apply(len)\ntest.head()","2c0f13e1":"import seaborn as sns\nsns.set(style=\"darkgrid\")\nsns.countplot(x=\"label\", data=train)","da570551":"train['number_of_words'].plot(bins=50, kind='hist',figsize = (10,8)) ","9b4d74a5":"train.hist(column='number_of_words', by='label',\n           bins=50,figsize=(14,6))","cb46d4aa":"import re\n\nimport nltk\n\ndef remove_url(text):\n     url=re.compile(r\"https?:\/\/\\S+|www\\.\\S+\")\n     return url.sub(r\" \",text)\n\ndef remove_html(text):\n  cleanr = re.compile('<.*?>')\n  return cleanr.sub(r\" \",text)\n\n\n\ndef remove_num(texts):\n   output = re.sub(r'\\d+', '', texts)\n   return output\n\n\nimport string\ndef remove_punc(text):\n   table=str.maketrans(' ',' ',string.punctuation)\n   return text.translate(table)\n\n\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words(\"english\"))\n \ndef remove_stopword(text):\n   text=[word.lower() for word in text.split() if word.lower() not in stop]\n   return \" \".join(text)","06e87210":"train['text']=train.text.map(lambda x:remove_url(x))\ntrain['text']=train.text.map(lambda x:remove_html(x))\ntrain['text']=train.text.map(lambda x:remove_punc(x))\ntrain['text']=train['text'].map(remove_num)\ntrain['text']=train['text'].map(remove_stopword)","7e3dec6f":"test['text']=test.text.map(lambda x:remove_url(x))\ntest['text']=test.text.map(lambda x:remove_html(x))\ntest['text']=test.text.map(lambda x:remove_punc(x))\ntest['text']=test['text'].map(remove_num)\ntest['text']=test['text'].map(remove_stopword)","aaa35420":"\nimport nltk\n\ndef Stemming(text):\n   stem=[]\n   from nltk.corpus import stopwords\n   from nltk.stem import SnowballStemmer\n  #is based on The Porter Stemming Algorithm\n   stopword = stopwords.words('english')\n   snowball_stemmer = SnowballStemmer('english')\n   word_tokens = nltk.word_tokenize(text)\n   stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n   stem=' '.join(stemmed_word)\n   return stem","a2d13efa":"\ntrain['text']=train['text'].map(Stemming)","67550f6e":"\ntest['text']=test['text'].map(Stemming)","ee12d2eb":"import tensorflow as tf\n","2c73f21e":"max_length=100\nvocab_size=12000\nembedding_dim=64\ntrunc_type=\"post\"\noov_tok=\"<OOV>\"\npadding_type=\"post\"\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","7773138d":"tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok)\ntokenizer.fit_on_texts(train['text'])\n\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(train['text'])\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_sequences = tokenizer.texts_to_sequences(test['text'])\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","2639565b":"training_padded[1]","413858fc":"print(training_sequences[0])","ec58502e":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM,GRU\nfrom keras.preprocessing import sequence\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score    \nfrom tensorflow.python.keras import models, layers, optimizers   \nfrom keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, SpatialDropout1D\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping","bdef2c17":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(Bidirectional(LSTM(256, dropout=0.2)))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\nmodel.summary()\n\n\n","ece3c563":"adam=Adam(lr=0.0001)","ebbc3ea1":"\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'] )","58053781":"\nhistory=model.fit(training_padded,train['label'], epochs=15, batch_size=256,verbose = 1,callbacks = [EarlyStopping(monitor='val_accuracy', patience=2)],validation_data=(testing_padded,test['label']))","eed9a1e2":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","aa743ed0":"def Review(sentence):\n   sequences = tokenizer.texts_to_sequences(sentence)\n   padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\n   prob=model.predict(padded)\n   if prob>=0.8:\n     print(5)\n   elif prob>=0.6:\n     print(4)\n   elif prob>=0.4:\n     print(3) \n   elif prob>=0.2:\n     print(2)   \n   else:\n       print(1)","42aefbbf":"sentence=['Good Product + exactly in size']\nReview(sentence)","71f9f4ac":"sentence=['this is worst thing donot buy it']\nReview(sentence)","c61a201a":"# Predicting the Test set results\ny_pred = model.predict(testing_padded)\ny_pred = (y_pred > 0.5)\nX_test=testing_padded\ny_test=test['label']","dd338feb":"from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix","5f92340f":"accuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy: %f' % accuracy)\n\nprecision = precision_score(y_test, y_pred)\nprint('Precision: %f' % precision)\n\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %f' % recall)\n\nf1 = f1_score(y_test, y_pred)\nprint('F1 score: %f' % f1)\n \n# ROC AUC\nauc = roc_auc_score(y_test, y_pred)\nprint('ROC AUC: %f' % auc)\n# confusion matrix\nmatrix = confusion_matrix(y_test, y_pred)\nprint(matrix)","7123272a":"#Report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","0d46a31e":"#Confusion Matrix\nimport seaborn as sns\nsns.heatmap(matrix,annot=True,fmt='')","b4dd38d4":"#ROC Curve\n\nfrom sklearn.metrics import roc_curve\ny_pred_keras = model.predict(X_test).ravel()\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n# Zoom in view of the upper left corner.\nplt.figure(2)\nplt.xlim(0, 0.2)\nplt.ylim(0.8, 1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve (zoomed in at top left)')\nplt.legend(loc='best')\nplt.show()","df587b09":"# ***Creating Data Frame***","27f0d716":"# *Data Visulaization*","09eb4cb7":"# ***Reading Dataset***","98c8a3d3":"#  ***Word Embedding***","8e2e9f62":"# *Bidirectional LSTM Model*","53d53c56":"# *Data Preprocessing*"}}