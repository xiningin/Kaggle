{"cell_type":{"afe827e0":"code","1c1f3b3f":"code","b1b769dc":"code","56a8e4a6":"code","f11af7ed":"code","1fe9e6c2":"code","a19c9186":"code","bdecc8cf":"code","e7b3b3f0":"code","1c6078da":"code","1748c70a":"code","217ac423":"code","fba5cf13":"code","d9350875":"code","27baed36":"markdown","504e7491":"markdown","a97d3e95":"markdown","4a2b620d":"markdown","05bc9da2":"markdown","72c58f4e":"markdown","b513bf32":"markdown","b6d88f87":"markdown","47c409a6":"markdown","bbcf5e7d":"markdown","6a50a7b0":"markdown"},"source":{"afe827e0":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport random\nimport time\nfrom keras.layers import *\nfrom keras.models import Input, Model\nfrom keras.utils import to_categorical\nfrom keras.callbacks import callbacks\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix, f1_score, roc_auc_score","1c1f3b3f":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","b1b769dc":"numberOfNormal = len(os.listdir('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia\/train\/NORMAL')) + len(os.listdir('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia2\/train\/NORMAL'))\nnumberOfPneumonia = len(os.listdir('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia\/train\/PNEUMONIA')) + len(os.listdir('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia2\/train\/PNEUMONIA'))\n\nprint('number of normal samples is {0} and number of pneumonia samples is {1}'.format(numberOfNormal, numberOfPneumonia))\nprint('Ratio of Normal samples over pneumonia samples is ', numberOfNormal \/ numberOfPneumonia)","56a8e4a6":"X_train, y_train= [], []\nX_test, y_test = [], []\nX_validation, y_validation = [], []\ndef prepareData(mainPath) : \n  global X_train, y_train, X_test, y_test, X_validation, y_validation\n  for dirname, _, filenames in os.walk(mainPath):\n      for filename in filenames:\n          path = os.path.join(dirname, filename)\n          img = cv2.imread(path, 0) #read each image in dataset\n          img = cv2.resize(img, (480, 360))  \n            \n          if path.find('\/NORMAL\/') != -1:\n              classification = 0\n          elif path.find('\/PNEUMONIA\/') != -1:\n              classification = 1\n          if path.find('train') != -1:\n              X_train.append(img)              \n              y_train.append(classification)\n            \n              if classification == 0:\n                  # data augmentation for normal classes\n                \n                  #Rotation \n                  rows, cols = img.shape\n                  Matrix = cv2.getRotationMatrix2D((int(cols\/2), int(rows\/2)), random.randint(-10, 10) , 1)\n                  img_1 = cv2.warpAffine(img,Matrix,(cols,rows))\n                  X_train.append(img_1)\n                  y_train.append(classification)\n                  # shifting in x and y axis\n                  Matrix = np.float32([[1,0,random.randint(10, 20)],[0,1,random.randint(10, 20)]])\n                  img_2 = cv2.warpAffine(img,Matrix,(cols,rows))\n\n                  X_train.append(img_2)\n                  y_train.append(classification)\n          elif path.find('test') != -1:\n              X_test.append(img)\n              y_test.append(classification)\n          elif path.find('validation') != -1:\n              X_validation.append(img)\n              y_validation.append(classification)\n\ndef shuffle_data(x, y):\n  tmp = list(zip(x, y)) \n  random.shuffle(tmp)\n  x, y = zip(*tmp)\n  x, y = list(x), list(y)\n  del(tmp)\n  return x, y\n\n","f11af7ed":"# append data into X_train, y_train, X_test, y_test, X_validation and y_validation lists.\n\nprepareData('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia')\nprepareData('\/kaggle\/input\/chest-xray-images-for-classification-pneumonia\/pneumonia2')\n# Shuffle training dataset\nX_train, y_train = shuffle_data(X_train, y_train)\n\nX_train = np.array(X_train).astype('float32')\/255\nX_test = np.array(X_test).astype('float32')\/255\nX_validation = np.array(X_validation).astype('float32')\/255\n\ny_train = np.array(y_train)\ny_test = np.array(y_test)\ny_validation = np.array(y_validation)\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_validation = to_categorical(y_validation)\n\nX_train = X_train[:, :, :, np.newaxis]\nX_test = X_test[:, :, :, np.newaxis]\nX_validation = X_validation[:, :, :, np.newaxis]\n\n#concatenate validation to testing data\nX_test = np.concatenate((X_test, X_validation))\ndel(X_validation)\ny_test = np.concatenate((y_test, y_validation))\ndel(y_validation)","1fe9e6c2":"numberofZeroClassified = np.count_nonzero(y_train, axis=0)[0]\nnumberofOneClassified = np.count_nonzero(y_train, axis=0)[1]\nprint('number of normal samples is {0} and number of pneumonia samples is {1}'.format(numberofZeroClassified, numberofOneClassified))\nprint('Ratio of Normal samples over pneumonia samples is ', numberofZeroClassified\/ numberofOneClassified)","a19c9186":"for i, sample in enumerate(X_train[:4]):\n    plt.subplot(2, 2, i+1)\n\n    plt.imshow(cv2.resize(sample, (48, 36)), cmap='gray', interpolation='none')\n    plt.title('Class '+ str(y_train[i][0]))\n","bdecc8cf":"with strategy.scope():\n    filters = [32, 64, 128]\n\n    input_layer = Input(shape=(360, 480, 1), name='Input_Layer')\n    layer = input_layer\n\n    for filter_size in filters:\n        layer = Conv2D(filter_size, kernel_size = 3,strides = 2, activation='relu')(layer)\n        layer = BatchNormalization()(layer)\n        layer = MaxPool2D()(layer)\n        layer = Dropout(.25)(layer)\n    layer = Flatten()(layer)\n    layer = Dense(512, activation='relu')(layer)\n    layer = Dropout(.4)(layer)\n    output_layer = Dense(2, activation='softmax')(layer)\n\n    model = Model(input_layer, output_layer)\n    model.summary()\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","e7b3b3f0":"epochs_number = 30\n# check point to save model which has best accuracy\nbest_accuracy = ModelCheckpoint('best_accuracy.hdf5',monitor='val_accuracy', verbose=0, save_best_only=True ) \n# check point to save model which has best loss  (Lowest loss value)\nbest_loss = ModelCheckpoint('best_loss.hdf5',monitor='val_loss', verbose=0, save_best_only=True )\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=epochs_number, validation_data=(X_test, y_test), callbacks=[best_accuracy, best_loss])","1c6078da":"plt.style.use('ggplot')\nplt.plot(range(epochs_number),history.history['val_loss'], c='b' ,label='Validation Loss')\nplt.plot(range(epochs_number),history.history['loss'], c='r' ,label='Training Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","1748c70a":"plt.style.use('ggplot')\nplt.plot(range(epochs_number),history.history['val_accuracy'], 'b' ,label='Validation Accuracy')\nplt.plot(range(epochs_number),history.history['accuracy'], 'r' ,label='Training Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('Acurracy')\nplt.legend()\nplt.show()","217ac423":"best_lossModel = load_model('best_accuracy.hdf5')\nbest_accuracyModel = load_model('best_loss.hdf5')","fba5cf13":"y = np.argmax(y_test, axis=1) #original test data \n'''\noutput for softmax is a probaility for which class the input belog to for example\nif output is [.2 .8]\n.2 for zero class\nand .8 for 1 class\n\nnp.argmax will return 1 because .8 has index 1\nso we can use thic concept to do the inverse operation of categorization\n'''\ny_best_lossModel = best_lossModel.predict(X_test)\ny_best_lossModel = np.argmax(y_best_lossModel, axis=1) \ny_best_accuracyModel = best_accuracyModel.predict(X_test)\ny_best_accuracyModel = np.argmax(y_best_accuracyModel, axis=1)","d9350875":"print(\"Best Loss model confusion Matrix \")\nconf_mat_Loss = confusion_matrix(y, y_best_lossModel)\nprint(conf_mat_Loss)\nprint(\"Best Accuracy model confusion Matrix \")\nconf_mat_accuracy = confusion_matrix(y, y_best_accuracyModel)\nprint(conf_mat_accuracy)\n\nprint(\"ROC AUC best accuracy model Score --> \", roc_auc_score(y, y_best_accuracyModel))\nprint(\"ROC AUC best less model Score --> \", roc_auc_score(y, y_best_lossModel))\n\nprint(\"F1 Score best accuracy model Score --> \", f1_score(y, y_best_accuracyModel))\nprint(\"F1 Score best loss model Score --> \", f1_score(y, y_best_lossModel))","27baed36":"* ****Inverse of categorical","504e7491":"* Plotting loss over each training epoch for training dataset and validation dataset .","a97d3e95":"* **Loading saved models**\n\nkeras model checkpoint saved two models one of them is the best accuracy model while training ang the another the lowest loss value model while training.","4a2b620d":"* **Performance measurement**","05bc9da2":"* **Checking for unbalanced dataset after data augmentation **","72c58f4e":"![image.png](attachment:image.png)","b513bf32":"**TPU or GPU detection**","b6d88f87":"* **Preparing dataset**\nAs mentioned above, normal samples should be augmented.\naugmentaion was done by openCV library. Transition and rotation were applied.","47c409a6":"* Data visualization for training data.","bbcf5e7d":"* Plotting loss over each training epoch for training dataset and validation dataset .","6a50a7b0":"* **Checking for unbalanced dataset**\n\nMost of dataset samples are pneumonia, so while preparing dataset normal samples were augmented to improve the ratio of number of normal samples over number of pneumonia samples samples.\n\nGenerally, This ratio shoud be about .8 and 1.2 ."}}