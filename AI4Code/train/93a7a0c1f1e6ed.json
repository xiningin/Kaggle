{"cell_type":{"d675569d":"code","f1669692":"code","5fe22bef":"code","27be322a":"code","631ac8dd":"code","2fe1b3f6":"code","2cd6865c":"code","4b352c78":"code","a6d3544f":"code","0781b8dc":"code","2037211a":"code","8ec2e30a":"markdown","7958aa02":"markdown"},"source":{"d675569d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1669692":"insurance = pd.read_csv('https:\/\/raw.githubusercontent.com\/skathirmani\/datasets\/main\/insurance.csv')\ninsurance.head()","5fe22bef":"target_col_name = 'expenses'\n","27be322a":"insurance.corr()","631ac8dd":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler","2fe1b3f6":"dummies = pd.get_dummies(insurance, drop_first=True)\n#insurance.shape, dummies.shape\n#dummies.head()","2cd6865c":"target_col_name = 'expenses'\ninput_cols_names = dummies.columns.drop(target_col_name)\ntrain_x, test_x, train_y, test_y = train_test_split(dummies[input_cols_names],\n                                                   dummies[target_col_name],\n                                                   test_size=0.2,\n                                                   random_state=1)","4b352c78":"scaler = StandardScaler().fit(train_x)\ntrain_x_scaled = scaler.transform(train_x)\ntest_x_scaled = scaler.transform(test_x)\ndf_train_x_scaled = pd.DataFrame(train_x_scaled,\n                                 index=train_x.index,\n                                 columns=train_x.columns)\n\ndf_test_x_scaled = pd.DataFrame(test_x_scaled,\n                                index=test_x.index,\n                               columns=test_x.columns)","a6d3544f":"import statsmodels.api as sm\ntrain_x_with_constant = sm.add_constant(df_train_x_scaled)\ntest_x_with_constant = sm.add_constant(df_test_x_scaled)\n\nmodel = sm.OLS(train_y, train_x_with_constant).fit()\nmodel.summary()","0781b8dc":"#df = pd.DataFrame({\n#    'gender': ['f', 'm', 'm', 'f'],\n#    'status': ['married', 'single', 'divorced', 'married'],\n#    'age': [1,2,3,4]\n#})","2037211a":"#dummies = pd.get_dummies(df, drop_first=True)\n#dummies.corr()","8ec2e30a":"### Steps in Multiple Linear Regression","7958aa02":"- No missing values\n- No outliers\n- Inputs should be numeric\n- Divide the data in training and testing\n- Standardize the input variables"}}