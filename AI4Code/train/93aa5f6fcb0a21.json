{"cell_type":{"0708b4fb":"code","d794e6d9":"code","a6dbfe53":"code","3f58627b":"code","672d5df5":"code","7bcacad1":"code","d2f23618":"code","aeabaae3":"code","354139dd":"code","ecc02c26":"code","4bb19fd6":"code","1fc7e2ca":"code","df5992b1":"code","3924d480":"code","1f34673a":"code","8166e9e9":"code","2c8fb1a5":"code","a8c97e53":"code","5ebefe7f":"code","b42e7fe7":"markdown","77803fc6":"markdown","0ab2ab15":"markdown","66536521":"markdown","aa0a7d6e":"markdown","55098160":"markdown","66198e1f":"markdown","45143e04":"markdown","19e7a1d8":"markdown","1deefd97":"markdown","19c178f1":"markdown","ec94fff5":"markdown","ea792c8a":"markdown","16d04a88":"markdown","c82e2182":"markdown","a79903a6":"markdown","3d4040ed":"markdown","ac44fcb9":"markdown","6dc94a35":"markdown"},"source":{"0708b4fb":"from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\n%matplotlib inline\n","d794e6d9":"batch_size = 32  # The default batch size of keras.\nnum_classes = 10  # Number of class for the dataset\nepochs = 100\ndata_augmentation = False","a6dbfe53":"# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n","3f58627b":"fig, axs = plt.subplots(1,2,figsize=(15,5)) \n# Count plot for training set\nsns.countplot(y_train.ravel(), ax=axs[0])\naxs[0].set_title('Distribution of training data')\naxs[0].set_xlabel('Classes')\n# Count plot for testing set\nsns.countplot(y_test.ravel(), ax=axs[1])\naxs[1].set_title('Distribution of Testing data')\naxs[1].set_xlabel('Classes')\nplt.show()","672d5df5":"# Normalize the data. Before we need to connvert data type to float for computation.\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\n# Convert class vectors to binary class matrices. This is called one hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","7bcacad1":"#define the convnet\nmodel = Sequential()\n# CONV => RELU => CONV => RELU => POOL => DROPOUT\nmodel.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# CONV => RELU => CONV => RELU => POOL => DROPOUT\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# FLATTERN => DENSE => RELU => DROPOUT\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n# a softmax classifier\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","d2f23618":"# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])","aeabaae3":"history = None  # For recording the history of trainning process.\nif not data_augmentation:\n    print('Not using data augmentation.')\n    history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        # randomly shift images horizontally (fraction of total width)\n        width_shift_range=0.1,\n        # randomly shift images vertically (fraction of total height)\n        height_shift_range=0.1,\n        shear_range=0.,  # set range for random shear\n        zoom_range=0.,  # set range for random zoom\n        channel_shift_range=0.,  # set range for random channel shifts\n        # set mode for filling points outside the input boundaries\n        fill_mode='nearest',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either \"channels_first\" or \"channels_last\"\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    history = model.fit_generator(datagen.flow(x_train, y_train,\n                                    batch_size=batch_size),\n                                    epochs=epochs,\n                                    validation_data=(x_test, y_test),\n                                    workers=4)","354139dd":"def plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n# list all data in history\nprint(history.history.keys())\n\nplotmodelhistory(history)\n","ecc02c26":"# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n\n# make prediction.\npred = model.predict(x_test)","4bb19fd6":"def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n    \"\"\"\n    Create a heatmap from a numpy array and two lists of labels.\n    \"\"\"\n    if not ax:\n        ax = plt.gca()\n\n    # Plot the heatmap\n    im = ax.imshow(data, **kwargs)\n\n    # Create colorbar\n    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n\n    # Let the horizontal axes labeling appear on top.\n    ax.tick_params(top=True, bottom=False,\n                   labeltop=True, labelbottom=False)\n    # We want to show all ticks...\n    ax.set_xticks(np.arange(data.shape[1]))\n    ax.set_yticks(np.arange(data.shape[0]))\n    # ... and label them with the respective list entries.\n    ax.set_xticklabels(col_labels)\n    ax.set_yticklabels(row_labels)\n    \n    ax.set_xlabel('Predicted Label') \n    ax.set_ylabel('True Label')\n    \n    return im, cbar\n\ndef annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n    \"\"\"\n    A function to annotate a heatmap.\n    \"\"\"\n    # Change the text's color depending on the data.\n    texts = []\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n                                 color=\"white\" if data[i, j] > thresh else \"black\")\n            texts.append(text)\n\n    return texts","1fc7e2ca":"labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test, axis=1)\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = pred[errors]\nY_true_errors = Y_true[errors]\nX_test_errors = x_test[errors]\n\ncm = confusion_matrix(Y_true, Y_pred_classes) \nthresh = cm.max() \/ 2.\n\nfig, ax = plt.subplots(figsize=(12,12))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","df5992b1":"print(classification_report(Y_true, Y_pred_classes))","3924d480":"R = 5\nC = 5\nfig, axes = plt.subplots(R, C, figsize=(12,12))\naxes = axes.ravel()\n\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[i])\n    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)\n","1f34673a":"R = 3\nC = 5\nfig, axes = plt.subplots(R, C, figsize=(12,8))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(Y_pred_classes != Y_true)[0]\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]], \n                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)\n","8166e9e9":"def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 5\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True, figsize=(12,6))\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((32,32,3)))\n            ax[row,col].set_title(\"Predicted:{}\\nTrue:{}\".\n                                  format(labels[pred_errors[error]],labels[obs_errors[error]]))\n            n += 1\n            ax[row,col].axis('off')\n            plt.subplots_adjust(wspace=1)\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 10 errors \nmost_important_errors = sorted_dela_errors[-10:]\n\n# Show the top 10 errors\ndisplay_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors)","2c8fb1a5":"def show_test(number):\n    fig = plt.figure(figsize = (3,3))\n    test_image = np.expand_dims(x_test[number], axis=0)\n    test_result = model.predict_classes(test_image)\n    plt.imshow(x_test[number])\n    dict_key = test_result[0]\n    plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key],\n                                                      labels[Y_true[number]]))","a8c97e53":"show_test(20)","5ebefe7f":"save_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'keras_cifar10_trained_model.h5'\n\n# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n","b42e7fe7":"\n\n### Hope that you found this notebook helpful for you. More to come.\n\n### Thanks for sharing it and for your suggestions.\n","77803fc6":"## 3. Defining the model architecture Using ConVnets\n\nNow Let us define a suitable deep net.\n\n* In the first stage, Our net will learn **32 convolutional filters**, each of which with a **3 x 3 size**. The output dimension is the same one of the input shape, so it will be **32 x 32** and activation is `relu`, which is a simple way of introducing non-linearity; folowed by another **32 convolutional filters**, each of which with a **3 x 3 size** and activation is also `relu`. After that we have a **max-pooling** operation with `pool size` **2 x 2** and a `dropout` at **25%.**\n* In the next stage in the deep pipeline, Our net will learn **64 convolutional filters**, each of which with a **3 x 3 size**. The output dimension is the same one of the input shape and activation is `relu`; folowed by another **64 convolutional filters**, each of which with a **3 x 3 size** and activation is also `relu`. After that we have a **max-pooling** operation with `pool size` **2 x 2** and a `dropout` at **25%.**\n* And the Final stage in the deep pipeline is a dense network with **512 units** and `relu` activation followed by a `dropout` at **50%** and by a `softmax` layer with **10 classes as output**, one for each category.\n\nNow let us look at the code review for our architecture.","0ab2ab15":"## 5. Evaluate the model.\n\n### 5.1 Training and validation curves.\nLet's see the training and validation process by the visualization of history of fitting. This allow us to quickly know if how our model fit our data **(overfitting, underfitting, model convergence, etc...)**","66536521":"And now, let us train the model.\n\n## 4. Model training\n\nBefore making network ready for training we have to make sure to add below things:\n*   **A loss function:** to measure how good the network is\n*   **An optimizer:** to update network as it sees more data and reduce loss value\n*   **Metrics:** to monitor performance of network\n\n**Also note that for data augmentation:**\n* One of the most commun tehnique to avoid overfitting is data augmentation. And We know that overfitting is generaly occur when we don't have enought data for training the model. To avoid this overfitting problem, we need to expand artificially our dataset. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit. \n\n* Different data aumentation techniques are as follows: Cropping, Rotating, Scaling, Translating, Flipping, Adding Gaussian noise to input images, etc...\n","aa0a7d6e":"Let's setting the models hyperparameters and others global parameters.","55098160":"## 6. Save model and weights\n\nNote that we need to firstly indicate the directory to save the model and the name of our model. ","66198e1f":"### 5.4 Classification report\n\nThis will allow us to evaluate the model with other metrics **(Precision, Recall, F1 score, etc...)**","45143e04":"# An experimentation of computer vision challenge for beginer(75% val_accuracy in 25 epochs, and 79% after 50 epochs without data augmentation). \n\nThe codes of this notebook are taken on keras documentation. I am just crying to give some explaination for that code.\nI hope that this migth be helpful for you.\n\n### Table of interest:\n1. Introduction\n2. Import and Preprocess the data\n + 2.1 Import all required libraries\n + 2.2 Import and preproces of data\n + 2.3 Distribution of data.\n3. Defining the model architecture Using ConVnets\n4. Model training\n5. Evaluate the model\n + 5.1 Training and validations cuvre\n + 5.2 Score trained model and prediction.\n + 5.3 Confusion matrix.\n + 5.4 Classification report.\n + 5.5 Check for the predictions.\n6. Save model and weights","19e7a1d8":"#### - Check the wrong predictions.","1deefd97":"## 2. Import and Preprocess the data\n\n### 2.1 Import all required libraries","19c178f1":"As we can see, after 60 epochs, the accuracy of our model doesn't really increase. But our model doesn't overffit.\n### 5.2 Score trained model and prediction.","ec94fff5":"Now Let's investigate for errors.\n### 5.3 Confusion matrix.\nConfusion matrix can be very helpfull to see your model drawbacks.\nWe plot the confusion matrix of the validation results.\nFor good vizualization of our confusion matrix, we have to define to fonction.","ea792c8a":"## 1. Introduction.\nThe CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\nclasses. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\nprovides 10,000 images. This image taken from the CIFAR repository ( <a href = \"https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\">https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html <\/a>). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset. \n\n![cifar10.png](attachment:cifar10.png)\n\n\nThe challenge is to recognize previously unseen images and assign them to one of the 10 classes.\n\nOk Let's get started.","16d04a88":"### 5.5 Check the predictions.","c82e2182":"#### - Testing the model with the test images in the test set.\nNow we can play with our model for some fun.","a79903a6":"#### - Check the most important errors.","3d4040ed":"### 2.3 Distribution of data.","ac44fcb9":"### 2.2 Import and preproces of data \nWe load the data and split it between train and test sets\n","6dc94a35":"As we can see, each classe contain exacly 6000 examples( 5000 for training and 1000 for test).\n\nThe graph above is very important for the training, for example if we had just 1000 samples of label 1 that will be a problem , the model will find difficulties to detect label 1\"less accuracy \", so that's not going to happend everything look fine. It's important to know the distribution of dataset behind different classes because the goodness of our model depend on it.\n\nNow let's doing some preprocessing.\n\nThe output variable have 10 posible values. This is a multiclass classification problem. We need to encode these lables to one hot vectors (ex : \"bird\" -> [0,0,1,0,0,0,0,0,0,0]). "}}