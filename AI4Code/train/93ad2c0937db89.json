{"cell_type":{"6e1dda57":"code","a0fd0062":"code","08c1fc1c":"code","d63454fb":"code","bdaffec1":"code","4fda5917":"code","e65592de":"code","78ed47b3":"code","924ac21d":"code","e1a1e995":"code","8d65ba29":"code","d9b683f5":"code","9299c03f":"code","072df3cb":"code","81f32703":"code","50c463ea":"code","6261cc30":"code","5a09cb1d":"code","f88bc7d6":"code","d15476c3":"code","f79a8ce0":"code","4dc00b87":"code","ad8a92f3":"markdown"},"source":{"6e1dda57":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras as ks # neural network models\n\n# For working with images\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tqdm\n\n# Potentially useful tools - you do not have to use these\nfrom keras.models import Sequential, Model, Input\nfrom keras.layers import Activation, Flatten, Dense, Dropout, ZeroPadding2D, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, Average\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nimport os\nimport math\n\n# Input data files are available in the \"..\/input\/\" directory.\n# Any results you write to the current directory are saved as output.","a0fd0062":"# CONSTANTS\n# You may not need all of these, and you may find it useful to set some extras\n\nCATEGORIES = ['airplane','car','cat','dog','flower','fruit','motorbike','person']\n\nIMG_WIDTH = 100\nIMG_HEIGHT = 100\nTRAIN_PATH = '..\/input\/natural_images\/natural_images\/'\nTEST_PATH = '..\/input\/evaluate\/evaluate\/'","08c1fc1c":"# To find data:\nfolders = os.listdir(TRAIN_PATH)\n\nimages = []\n\nfor folder in folders:\n    files = os.listdir(TRAIN_PATH + folder)\n    images += [(folder, file, folder + '\/' + file) for file in files]\n\nimage_locs = pd.DataFrame(images, columns=('class','filename','file_loc'))\n\n# data structure is three-column table\n# first column is class, second column is filename, third column is image address relative to TRAIN_PATH\ndisplay(image_locs.head(10))\ndisplay(image_locs.shape)","d63454fb":"# Shuffle the image_locs dataframe\nimage_locs_shuffled = image_locs.sample(frac=1)\ndisplay(image_locs_shuffled.head())","bdaffec1":"row_count = len(image_locs_shuffled.index)\nval_split = 0.1\ntrain_split = 1 - val_split\n\n# Split the shuffled image_locs into training and validation dataframes by the proportion given by val_split\ntrain_image_locs = image_locs_shuffled[:math.floor(train_split * row_count)]\nval_image_locs = image_locs_shuffled[-math.ceil(val_split * row_count):]\ndisplay(train_image_locs.shape)\ndisplay(val_image_locs.shape)","4fda5917":"# Training data generator with scaling and data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n#     rotation_range=10,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n# Validation\/Test data generator with only scaling\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255\n)","e65592de":"# train_generator = train_datagen.flow_from_directory(\n#     directory=TRAIN_PATH,\n#     target_size=(IMG_WIDTH, IMG_HEIGHT)\n# )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_image_locs,\n    directory=TRAIN_PATH,\n    x_col='file_loc',\n    target_size=(IMG_WIDTH, IMG_HEIGHT)\n)\n\n# val_generator = test_datagen.flow_from_directory(\n#     directory=TRAIN_PATH,\n#     target_size=(IMG_WIDTH, IMG_HEIGHT)\n# )\n\nval_generator = test_datagen.flow_from_dataframe(\n    val_image_locs,\n    directory=TRAIN_PATH,\n    x_col='file_loc',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    shuffle=False\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory='..\/input\/evaluate\/',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    class_mode=None,\n    batch_size=1,\n    shuffle=False\n)","78ed47b3":"def build_model(weights_path=None):\n    model = Sequential()\n    \n    # First Convolution layer\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n    model.add(Conv2D(32, (3,3), activation ='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n#     model.add(Dropout(0.1))\n\n    # Second Convolution layer\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n    model.add(Conv2D(64, (3,3), activation ='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n#     model.add(Dropout(0.1))\n\n    # Fully-connected layers\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    # Output layer\n    model.add(Dense(len(CATEGORIES), activation='softmax'))\n    \n    # Load weights if provided (used in final model)\n    if weights_path is not None:\n        model.load_weights(weights_path)\n\n    # Compile using Adam optimizer\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n    return model","924ac21d":"def build_model_2(weights_path=None):\n    model = Sequential()\n    \n    # First Convolution layer\n    model.add(Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n    model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Second Convolution layer\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Third Convolution layer\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Output layers\n    model.add(Conv2D(len(CATEGORIES), (1, 1)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Activation('softmax'))\n    \n    # Load weights if provided (used in final model)\n    if weights_path is not None:\n        model.load_weights(weights_path)\n\n    # Compile using Adam optimizer\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n    return model","e1a1e995":"def build_model_3(weights_path=None):\n    model = Sequential()\n    \n    # First Convolution layer\n    model.add(Conv2D(8, (3,3), activation='relu', padding='same', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Second Convolution layer\n    model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Third Convolution layer\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Dropout(0.1))\n    \n    # Fully-connected layers\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    # Output layer\n    model.add(Dense(len(CATEGORIES), activation='softmax'))\n    \n    # Load weights if provided (used in final model)\n    if weights_path is not None:\n        model.load_weights(weights_path)\n\n    # Compile using Adam optimizer\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n    return model","8d65ba29":"ensemble_builders = [\n    build_model,\n    build_model_2,\n    build_model_3\n]\n\nensemble_models = []\nfor i, (build) in enumerate(ensemble_builders):\n    m = build()\n    display(m.summary())\n    ensemble_models.append((i, m))\ndisplay(ensemble_models)","d9b683f5":"model = build_model()\nmodel.summary()","9299c03f":"val_split = 0.2\ntrain_steps = train_generator.n \/\/ train_generator.batch_size\nval_steps = train_steps * val_split\n# val_steps = val_generator.n \/\/ val_generator.batch_size\n\n# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n\nweights_path = 'best_weights.h5'\nmc = ModelCheckpoint(weights_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\n# history = model.fit_generator(\n#     train_generator,\n#     steps_per_epoch=train_steps,\n#     validation_data=val_generator,\n#     validation_steps=val_steps,\n#     epochs=25,\n# #     callbacks=[es, mc]\n#     callbacks=[mc]\n# )\n\nensemble_histories = []\n\nfor (i, m) in ensemble_models:\n    mc = mc = ModelCheckpoint('{}_{}'.format(i, weights_path), monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    h = m.fit_generator(\n        train_generator,\n        steps_per_epoch=train_steps,\n        validation_data=val_generator,\n        validation_steps=val_steps,\n        epochs=20,\n        callbacks=[mc]\n    )\n    ensemble_histories.append((i, h))","072df3cb":"# # Plot the training and validation losses over time during model training\n# plt.plot(history.history['loss'], label='train')\n# plt.plot(history.history['val_loss'], label='validation')\n# plt.legend()\n# plt.show()\n\nfor (i, h) in ensemble_histories:\n    plt.plot(h.history['loss'], label='train')\n    plt.plot(h.history['val_loss'], label='validation')\n    plt.legend()\n    plt.show()","81f32703":"# # Load the checkpointed \"best\" weights into new model\n# final_model = build_model(weights_path)\n\nensemble_final_models = []\nfor i, (build) in enumerate(ensemble_builders):\n    m = build('{}_{}'.format(i, weights_path))\n    ensemble_final_models.append((i, m))","50c463ea":"# display(final_model.evaluate_generator(generator=val_generator, steps=val_steps))\n\nfor (i, final_model) in ensemble_final_models:\n    display(final_model.evaluate_generator(generator=val_generator, steps=val_steps))","6261cc30":"# val_generator.reset()\n\n# val_predictions = final_model.predict_generator(\n#     val_generator,\n#     steps=val_steps,\n#     verbose=1\n# )\n# display(val_predictions.shape)\n\n# val_predictions_labels = np.argmax(val_predictions, axis=1)\n\n# val_true_labels = val_generator.classes[:val_predictions.shape[0]]\n\n# display(confusion_matrix(val_true_labels, val_predictions_labels))\n\nfor (i, final_model) in ensemble_final_models:\n    val_generator.reset()\n\n    val_predictions = final_model.predict_generator(\n        val_generator,\n        steps=val_steps,\n        verbose=1\n    )\n    display(val_predictions.shape)\n\n    val_predictions_labels = np.argmax(val_predictions, axis=1)\n\n    val_true_labels = val_generator.classes[:val_predictions.shape[0]]\n\n    display(confusion_matrix(val_true_labels, val_predictions_labels))","5a09cb1d":"model_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n# ensemble_outputs = [m.outputs[0] for i, m in ensemble_final_models]\nyModels=[m(model_input) for i, m in ensemble_final_models] \noverall_model = Model(\n    model_input,\n    Average()(yModels),\n    name='ensemble'\n)","f88bc7d6":"# test_generator.reset()\n\n# predictions = final_model.predict_generator(\n#     test_generator,\n#     steps=test_generator.n,\n#     verbose=1\n# )\n\n# predicted_class_indices = np.argmax(predictions, axis=1)\n# display(predicted_class_indices)\n\ntest_generator.reset()\n\npredictions = overall_model.predict_generator(\n    test_generator,\n    steps=test_generator.n,\n    verbose=1\n)\n\npredicted_class_indices = np.argmax(predictions, axis=1)\ndisplay(predicted_class_indices)","d15476c3":"labels = train_generator.class_indices\nlabels = dict((v,k) for k,v in labels.items())\ndisplay(labels)","f79a8ce0":"filenames = [fn.split('\/')[1] for fn in test_generator.filenames]\npredictions = [labels[k] for k in predicted_class_indices]\n\ndisplay(filenames[:10])\ndisplay(predictions[:10])","4dc00b87":"# Save results\n\n# results go in dataframe: first column is image filename, second column is category name\n# category names are: airplane, car, cat, dog, flower, fruit, motorbike, person\ndf = pd.DataFrame()\ndf['filename'] = filenames\ndf['label'] = predictions\ndf = df.sort_values(by='filename')\n\ndf.to_csv('results.csv', header=True, index=False)","ad8a92f3":"### Over to you\n\nNow you must create your own solution to the problem. To get the file containing your results, you have to `commit` the kernel and then navigate to [kaggle.com\/kernels](https:\/\/www.kaggle.com\/kernels\/), and the 'Your Work' tab, where you will find a list of your notebooks. Click on it and scroll down to the `Output` section."}}