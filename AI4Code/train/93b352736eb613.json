{"cell_type":{"0a02b619":"code","8941ae74":"code","535a8f7d":"code","3556bdc5":"code","f063f37a":"code","e34f8191":"code","1efc6e39":"code","ec1b0810":"code","e310273c":"code","a66495b7":"code","2d5381b5":"code","002e8098":"code","a161714d":"code","2dd0e7d3":"code","fcfa2c03":"code","292f71bb":"markdown","b90b4b46":"markdown","c7f64084":"markdown","1bf8c17b":"markdown","8c674b58":"markdown","53c5e00f":"markdown","2d355363":"markdown","e8b2f877":"markdown","ec8cf8e8":"markdown","9dc8715a":"markdown","3f46f717":"markdown","18d66fce":"markdown","da11ba02":"markdown","5266190a":"markdown","44b8410c":"markdown","f750e44b":"markdown"},"source":{"0a02b619":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8941ae74":"data=pd.read_csv(\"..\/input\/weatherAUS.csv\")","535a8f7d":"data.head()","3556bdc5":"data = data.drop(columns=['RISK_MM'],axis=1)","f063f37a":"from sklearn.preprocessing import Imputer\nimputer=Imputer(missing_values='NaN',strategy='mean',axis=0)","e34f8191":"df_num_col = [\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Evaporation\",\"Sunshine\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"Cloud9am\",\"Cloud3pm\",\"Temp9am\",\"Temp3pm\"]\ndata_num=data[df_num_col]\nimputer=imputer.fit(data_num)\ndata[df_num_col]=imputer.transform(data_num)","1efc6e39":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\ndf_cat_col = [\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\",\"RainToday\",\"RainTomorrow\",\"Date\",\"Location\"]","ec1b0810":"data_cat=data[df_cat_col].fillna('NA')","e310273c":"for i in range(len(data_cat.columns)):\n  data_cat.iloc[:,i] = labelencoder.fit_transform(data_cat.iloc[:,i])\n  \ndata[df_cat_col]=data_cat","a66495b7":"x=data.iloc[:,0:22].values\ny=data.iloc[:,22].values","2d5381b5":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)","002e8098":"from sklearn.preprocessing import StandardScaler\nsc_x=StandardScaler()\nx_train=sc_x.fit_transform(x_train)\nx_test=sc_x.fit_transform(x_test)","a161714d":"from sklearn.linear_model import LogisticRegression\nimport time\nfrom sklearn.metrics import accuracy_score\nt0=time.time()\nlogreg=LogisticRegression(random_state=0)\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)\nscore = accuracy_score(y_test,y_pred)\nprint('Logistic Regression Accuracy :',score)\nprint('Logistic Regression Time taken :' , time.time()-t0)","2dd0e7d3":"from sklearn.tree import DecisionTreeClassifier\nt0=time.time()\ndestree=DecisionTreeClassifier(random_state=0)\ndestree.fit(x_train,y_train)\ny_pred=destree.predict(x_test)\nscore = accuracy_score(y_test,y_pred)\nprint('Decision Tree Accuracy :',score)\nprint('Decision Tree Time taken :' , time.time()-t0)","fcfa2c03":"from sklearn.ensemble import RandomForestClassifier\nt0=time.time()\nrantree=RandomForestClassifier(random_state=0)\nrantree.fit(x_train,y_train)\ny_pred=rantree.predict(x_test)\nscore = accuracy_score(y_test,y_pred)\nprint('Random Tree Accuracy :',score)\nprint('Random Tree Time taken :' , time.time()-t0)","292f71bb":"#Random Forest Classifier\n","b90b4b46":"#Split data set into train and test set","c7f64084":"# Feature Scaling","1bf8c17b":"Import Dataset","8c674b58":"# We need to remove RISK_MM because we want to predict 'RainTomorrow' and RISK_MM can leak some info to our model\n\n","53c5e00f":"Analysis shows both Logical regressor and Random forest regressor have accuracy of 84%.\nBut performance wise Logical regressor is better since it took only 1.5 Seconds.","2d355363":"Get dependent and independent variable from dataset","e8b2f877":"#Loop through each categorical variable and update values using LabelEncoder","ec8cf8e8":"#Use encoder for categorical variables","9dc8715a":"Apply different classification models on the data","3f46f717":"#Impute missing values for numerical varibales","18d66fce":"#Logistic Regression","da11ba02":"Have a look at the sample data","5266190a":"# Taking care of missing data","44b8410c":"#Decision Tree\n\n","f750e44b":"#Update NaN values by NA"}}