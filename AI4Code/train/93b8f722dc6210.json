{"cell_type":{"1a9168ce":"code","8837883e":"code","4fe000d8":"code","e2428894":"code","cd6176c9":"code","5550f5b1":"code","48a5c519":"code","a75ba42f":"code","a7e2645a":"code","2b7f2550":"code","9eaed30b":"code","16cfde6a":"code","f3667647":"code","1fe9253e":"code","ce5ad680":"code","cd49bb58":"code","a7fb6499":"code","71327bcb":"code","d86dab43":"code","20003fe8":"code","274d3d07":"code","70202d7a":"code","bad130f8":"code","c790f41f":"code","eb21efb8":"code","4be030f5":"code","7724f2ce":"code","b61e3ef5":"code","4dee4082":"code","cb5af977":"code","16f4d71a":"code","4f862492":"code","ca22ff64":"code","396b6c3d":"code","5642a366":"code","433a09af":"code","eefe658d":"code","c01d5176":"code","8ca4815d":"code","bda5c7ae":"code","ce745762":"code","82db7fe4":"markdown","613cd32d":"markdown","59ad3f67":"markdown","485277d3":"markdown","62b4eb48":"markdown","a0fb245c":"markdown"},"source":{"1a9168ce":"# Essential Imports\nimport numpy as np \nimport pandas as pd \n\n\n# Visualisations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Statistics\nfrom scipy.stats import skew,boxcox_normmax\nfrom scipy.special import boxcox1p\n\n# Misc\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\n\n# Models\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.cluster import KMeans,AgglomerativeClustering\n\n# For warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n\n","8837883e":"# Read in train and test set and set our seaborn plot style\ntrain = pd.read_csv('\/kaggle\/input\/nmlo-contest-3\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nmlo-contest-3\/test.csv')\n\nsns.set_style('darkgrid')","4fe000d8":"# Get shapes of data\nprint('Train Shape:' + str(train.shape))\nprint('Test Shape:' + str(test.shape))","e2428894":"# Get the head of our training set to see what our features look like\ntrain.head()","cd6176c9":"# Some info on our data\ntrain.info()","5550f5b1":"# Describe our data to get some basic statistics about it\ntrain.describe()","48a5c519":"# Get skewness and kurtosis of data\nprint('Median Income skew in train set: ' + str(skew(train['inc'])))\nprint('Median Income kurtosis in train set: ' + str((train['inc'].kurt())))\nprint('')\nprint('Population skew in train set: ' + str(skew(train['pop'])))\nprint('Population kurtosis in train set: ' + str((train['pop'].kurt())))\nprint('')\nprint('Target feature skew in train set: ' + str(skew(train['cases'])))\nprint('Target feature kurtosis in train set: ' + str((train['cases'].kurt())))\nprint('')\nprint('Education feature skew in train set: ' + str(skew(train['ed'])))\nprint('Education feature kurtosis in train set: ' + str((train['ed'].kurt())))","a75ba42f":"# Box plot of the cases log transformed \nsns.boxplot(np.log1p(train['cases']))\nplt.title('Box Plot of cases in the train set')\nplt.show()","a7e2645a":"# Histogram of the cases log transformed \nsns.distplot(np.log1p(train['cases']))\nplt.title('Distribution Plot of cases in the train set')\nplt.show()","2b7f2550":"# Box plot of the population log transformed \nsns.boxplot(np.log1p(train['pop']))\nplt.title('Box Plot of population in the train set')\nplt.show()","9eaed30b":"# Histogram of the population log transformed \nsns.distplot(np.log1p(train['pop']))\nplt.title('Distribution Plot of population in the train set')\nplt.show()","16cfde6a":"# Box plot of the eduction feature\nsns.boxplot(train['ed'])\nplt.title('Box Plot of education levels in the train set')\nplt.show()","f3667647":"# Box plot of the eduction feature\nsns.distplot(train['ed'])\nplt.title('Distribtion Plot of education levels in the train set')\nplt.show()","1fe9253e":"# Box plot of the income feature\nsns.boxplot(np.log1p(train['inc']))\nplt.title('Box Plot of income levels in the train set')\nplt.show()","ce5ad680":"# Box plot of the income feature\nsns.distplot((train['inc']))\nplt.title('Distribution Plot of income levels in the train set')\nplt.show()","cd49bb58":"# Pairplot of all training features\nsns.pairplot(np.log1p(train))\nplt.show()","a7fb6499":"# Linear Model plot of cases and population\nsns.lmplot('pop','cases',np.log1p(train),line_kws={'color': 'red'})\nplt.title('Linear model plot of cases vs population')\nplt.show()","71327bcb":"# Scatter plot of inc vs population split by number of cases\nplt.scatter('pop','inc',data=np.log1p(train),c='cases',alpha=0.3,cmap='coolwarm')\nplt.title('Population vs income split by cases on train set')\nplt.show()","d86dab43":"# Correlation heatmap\nplt.figure(figsize=(10,10))\nsns.heatmap(train.corr(),annot=True,cmap='coolwarm')\nplt.show()","20003fe8":"# Check if there are any rows where amount of cases is more that the population)\ntrain.iloc[np.where(train['cases'] > train['pop'])[0]]","274d3d07":"# Remove that example and then drop the id columns completey\ntrain = train[train['id'] != 724]\ntrain.drop('id',axis=1,inplace=True)","70202d7a":"# See if there is any education feature that is zero\ntest[test['ed'] == 0]","bad130f8":"# Replace the outlier values with the 25% percentile of the education feature \ntest['ed'] = test['ed'].replace(0.0,test['ed'].quantile([0.25][0]))","c790f41f":"# Log transform cases so they follow normal distribution\ntrain['cases'] = np.log1p(train['cases'])","eb21efb8":"# Remove all examples with target value greater than 11\ntrain = train[(train['cases'] < 11)]\n\n# Remove all income values with a value greater than 110000\ntrain = train[(train['inc'] < 110000)]\n\n# Remove all population values with a population greater than 4000000\ntrain = train[(train['pop'] < 4000000)]","4be030f5":"# Select labels and features and merge train and test data together\ntrain_features = train.drop('cases',axis=1)\ntest_features = test\ny = train.cases\n\ncombined = pd.concat([train_features,test_features],axis=0).reset_index(drop=True)\ncombined.shape","7724f2ce":"skewed_features = combined.apply(lambda x:skew(x)).sort_values(ascending=False)\n\nhigh_skew = skewed_features[skewed_features > 0.5]\nskew_index = high_skew.index\nskewness = pd.DataFrame({'Skew' :high_skew})\nskewness.head()","b61e3ef5":"for i in skew_index:\n    combined[i] = boxcox1p(combined[i],boxcox_normmax(combined[i] + 1))","4dee4082":"from sklearn.preprocessing import normalize","cb5af977":"# Fuction to create a new feature that clusters similiar examples together using Hierarchical Clustering\ndef hierarchical_cluster_feature():\n    data_scaled = normalize(combined)\n    data_scaled = pd.DataFrame(data_scaled,columns=combined.columns)\n    cluster = AgglomerativeClustering(n_clusters=2,affinity='euclidean',linkage='ward')\n    cluster.fit(data_scaled)\n    combined['hierarchical_cluster_feature'] = cluster.labels_\n    \nhierarchical_cluster_feature()","16f4d71a":"# Fuction to create a new feature that clusters similiar examples together using KMeans Clustering\ndef generate_cluster_feature():\n    scaler = StandardScaler()\n    combined_scaled = scaler.fit_transform(combined.drop('hierarchical_cluster_feature',axis=1))\n    pca = PCA(n_components=2)\n    combined_pca = pca.fit_transform(combined_scaled)\n    kmeans = KMeans(n_clusters=2,max_iter=400,random_state=42)\n    kmeans.fit(combined_pca)\n    combined['cluster_feature'] = kmeans.labels_\n\n# Call the function to generate clusters\ngenerate_cluster_feature()","4f862492":"# Divide income by population\ncombined['inc_over_pop'] = combined['inc'] \/ combined['pop']\n# Divide education over population\ncombined['ed_over_pop'] = combined['ed'] \/ combined['pop']\n# Divide education over income\ncombined['inc_over_ed'] = combined['inc'] \/ combined['ed']","ca22ff64":"# Function to calculate log transformation of features\ndef logs(res, ls):\n    m = res.shape[1]\n    for l in ls:\n        res = res.assign(newcol=pd.Series(np.log(1.01+res[l])).values)   \n        res.columns.values[m] = l + '_log'\n        m += 1\n    return res\n\n# Call the function\ncombined = logs(combined, ['ed','pop','ed_over_pop'])\n\n# Function to calculate square transformation of features\ndef squares(res, ls):\n    m = res.shape[1]\n    for l in ls:\n        res = res.assign(newcol=pd.Series(res[l]*res[l]).values)   \n        res.columns.values[m] = l + '_sq'\n        m += 1\n    return res \n\n# Call the function\ncombined = squares(combined, ['ed','pop','ed_log','pop_log','ed_over_pop_log','ed_over_pop'])","396b6c3d":"X = combined.iloc[:len(train),:]\nX_test = combined.iloc[len(train):,:]\n\nX.shape,X_test.shape","5642a366":"X","433a09af":"# Setup cross validation KFolds\nkf = KFold(n_splits=12,random_state=42,shuffle=True)","eefe658d":"# Split data into train and validation set\nfor train_index,val_index in kf.split(X):\n    X_train,X_val = X.iloc[train_index],X.iloc[val_index],\n    y_train,y_val = y.iloc[train_index],y.iloc[val_index]","c01d5176":"# Initialize SGD Model and fit to training set\nsgd = make_pipeline(StandardScaler(),SGDRegressor(random_state=42,n_iter_no_change=33))\nsgd.fit(X_train,y_train)\nnp.sqrt(mean_squared_error(y_val,sgd.predict(X_val)))","8ca4815d":"# Read in sample_submission dataframe\nsubmission = pd.read_csv(\"..\/input\/nmlo-contest-3\/sample.csv\")\nsubmission.shape","bda5c7ae":"# Append predictions from sgd model\nsubmission.iloc[:,1] = np.floor(np.expm1(sgd.predict(X_test)))","ce745762":"# Scale predictions\nsubmission['cases'] *= 1.001619\nsubmission.to_csv(\"submission_sgd.csv\", index=False)","82db7fe4":"<h1 align='center'> Recreate train and test sets <\/h1>","613cd32d":"<h1 align='center'> Modelling <\/h1>","59ad3f67":"<h1 align='center'> Fixed Skewed Features <\/h1>","485277d3":"<h1 align='center'> Feature Creation <\/h1>","62b4eb48":"<h1 align='center'> Exploratory Data Analysis <\/h1>","a0fb245c":"<h1 align='center'> Outlier Removal <\/h1>"}}