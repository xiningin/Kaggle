{"cell_type":{"bd0a6ab2":"code","8a405b4f":"code","ed4d2cdd":"code","b6afb6e5":"code","847b4100":"code","eb665ada":"code","62187688":"code","f86d79f5":"code","f8d3a302":"markdown","090da016":"markdown","8e1be497":"markdown","c3a4c32f":"markdown","30530dbe":"markdown"},"source":{"bd0a6ab2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import date, datetime\nfrom scipy import stats\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8a405b4f":"data = pd.read_csv('..\/input\/nba2k20-player-dataset\/nba2k20-full.csv')\ndata.head(5)","ed4d2cdd":"data.info()","b6afb6e5":"def prepare_data(data: pd.DataFrame):\n    '''\n        Preprocesses data\n    '''\n    def calculateAge(birthDate: str):\n        '''\n        calculates age of person, on given birth day\n        '''\n        datetime_object = datetime.strptime(birthDate, '%m\/%d\/%y')\n        today = date.today() \n        age = today.year - datetime_object.year -  ((today.month, today.day) < (datetime_object.month, datetime_object.day)) \n        return age \n    \n    data['jersey'] = data['jersey'].apply(lambda x: int(x[1:]))\n    data['age'] = data['b_day'].apply(calculateAge)\n    data['height'] = data['height'].apply(lambda x: float(x.split('\/')[1]))\n    data['weight'] = data['weight'].apply(lambda x: float(x.split('\/')[1].split(' ')[1]))\n    data['salary'] = data['salary'].apply(lambda x: float(x[1:]))\n    data['draft_round'].replace('Undrafted', 0, inplace = True)\n    data['draft_round'] = data['draft_round'].apply(int)\n    data['team'] = data['team'].fillna('No team')\n    data['college'] = data['college'].fillna('No education')\n    data.drop(['b_day', 'draft_peak'], axis = 1, inplace = True)","847b4100":"\ndata = pd.read_csv('..\/input\/nba2k20-player-dataset\/nba2k20-full.csv')\nprepare_data(data)\n\n#creating categories to teams by mean salary\nsalary = data[['salary', 'team']]\nnew_sal = salary.groupby('team').mean().reset_index()\nboundaries = [np.NINF, 7E+6, 7.6E+6, 8.1E+6, 9E+6, 9.5E+6, np.Inf]\nnew_sal['team_salary'] = pd.cut(salary.groupby('team').mean().\\\n                                reset_index()['salary'], bins=boundaries)\nnew_sal.drop(['salary'], axis = 1, inplace = True)\n#merging this categories to data\ndata = data.merge(new_sal, on = 'team', how = 'left')\n\n#removing imbalanced data\ndata.loc[data['country'] != 'USA', 'country'] = 'not USA'\ndata.loc[data['position'] == 'C-F', 'position'] = 'F-C'\ndata.loc[data['position'] == 'F-G', 'position'] = 'F'\ndata.loc[data['position'] == 'G-F', 'position'] = 'F'\n\n# we should drop full_name because it doesn't have anything meaning for this type of model\n# we should drop jersey because it doesn't have high correlation\n# we should drop team because we have already preprocessed it\n# For now we should drop college because there is too much colleges with just 5 or less occurances\ndata = data.drop(['full_name', 'jersey',  'team', 'college'], axis = 1)\n\n# converting categorical data to one-hot encoding\ndata = pd.get_dummies(data, \n                      columns = ['team_salary', 'position', 'country', 'draft_round'],\n                      drop_first = True)\n\nX, y = data.drop(['salary'], axis = 1), data['salary']\n#normalizing input features\nnormalizer = preprocessing.Normalizer().fit(X)\nX = normalizer.transform(X)","eb665ada":"print(X.shape)","62187688":"data.head()","f86d79f5":"X","f8d3a302":"So we can see, that we get 16 feature columns","090da016":"Let's take a look on data types","8e1be497":"Also we can try to look at X variable, but as we normalized data, it doesn't have sense.","c3a4c32f":"As we can see, we have only 2 int columns, but we have data, that we can preprocess to get numerical data","30530dbe":"And we can look at our data. We can see, that we converted categorical data to one-hot encoding."}}