{"cell_type":{"59b65bc7":"code","13467f0d":"code","8f7e4a45":"code","775b7a15":"code","20e8786e":"code","9b688f70":"code","a3ba1bcd":"code","14341ba3":"code","7edfab80":"code","c0b89de9":"code","8895182a":"code","39e57ed3":"code","492438a9":"code","7f3b5d40":"code","f567a11d":"code","8c73f166":"code","1b521f93":"code","ca51681d":"code","7f484df8":"code","ce86f6c1":"code","b025fd4f":"code","288cfaf0":"code","0742ad5f":"markdown","a4756b6c":"markdown","b77d32c8":"markdown","4b2020ab":"markdown","9e99bfb8":"markdown","70686710":"markdown","e27b8be0":"markdown","766f676b":"markdown","3257d954":"markdown","b10fb7ec":"markdown","a6d2ddea":"markdown","947bbf86":"markdown","49dbd9b7":"markdown","cb547cb8":"markdown"},"source":{"59b65bc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13467f0d":"!pip install pyforest\nfrom pyforest import *  #this will import all necessary data science libraries and modules at once","8f7e4a45":"df=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')  #reading train dataset\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf.head()   #top 5 rows of dataset","775b7a15":"df.isnull().value_counts()   #counting null values ","20e8786e":"df.info()  #this will give datatype of each column and null value information","9b688f70":"df.fillna(0,inplace=True)  #filling null values with 0\ntest.fillna(0,inplace=True)","a3ba1bcd":"df.shape,test.shape","14341ba3":"sns.barplot(data=df,y='Fare',x='Sex',hue='Survived') #counting fare of male and female and specifying which of them survived","7edfab80":"matrix=df.corr()\nsns.heatmap(matrix) ","c0b89de9":"df['Embarked'].value_counts()  ","8895182a":"df1=pd.get_dummies(df['Sex'])  #get dummy variables from string categorical data because model can't process string data\ndf2=pd.get_dummies(test['Sex'])\ndf3=pd.get_dummies(df['Embarked'])  #get dummy variables from string categorical data because model can't process string data\ndf4=pd.get_dummies(test['Embarked'])","39e57ed3":"\ndf1.drop('male',axis=1,inplace=True) \ndf2.drop('male',axis=1,inplace=True)\n\ndf3.drop(['Q',0],axis=1,inplace=True) \ndf4.drop('Q',axis=1,inplace=True)","492438a9":"res_df=pd.concat([df1,df,df3],axis=1)\nres_test=pd.concat([df2,test,df4],axis=1)","7f3b5d40":"res_df.drop(['Name','Sex','Embarked','Cabin','Ticket'],axis=1,inplace=True)  #drop unnecessary columns\nres_test.drop(['Name','Sex','Embarked','Cabin','Ticket'],axis=1,inplace=True)","f567a11d":"res_df.info() #check if dataframe has all int and float type values","8c73f166":"res_df.shape,res_test.shape","1b521f93":"x=res_df.drop('Survived',axis=1)\ny=res_df['Survived']  #make survived as target variable","ca51681d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)","7f484df8":"from xgboost import XGBClassifier #using xgboost classifier\nclf = XGBClassifier(max_depth=2, random_state=0)\nclf.fit(x_train,y_train)\n","ce86f6c1":"y_pred=clf.predict(x_test)\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nprint(accuracy_score(y_test,y_pred)*100)\nconfusion_matrix(y_test,y_pred)","b025fd4f":"preds=clf.predict(res_test)","288cfaf0":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('submission_latest.csv', index=False)\n","0742ad5f":"Plotting covariance matrix to check which variable depends(or not) on whom. +ve covariance means a variable is directly proportional to other, -ve means they are inversely proportional and 0 means they do not depend on each other. Independant variables should depend on dependant variable while independant variables should not depend on each other. ","a4756b6c":"<h1>Data Preprocessing ends here<\/h1>","b77d32c8":"Bar plot is bivariate plotting tool that I am using to plot fare of both male and female people and hue helps to analyze which of them survived.","4b2020ab":"Drop unnecessary columns and string variables","9e99bfb8":"Analyzing performance of model using sklearn metrics. Confusion matrix is 2 by 2 matrix (in this case) that is storing True positive (correctly predicted positive class), True negatives (correctly predicted negative class), False positives and False negatives. ","70686710":"Drop some dummy variables to avoid multicolliniarity or dummy variable trap. Inplace means perform changes on same dataset instead of creating copies.","e27b8be0":"Strings features can be framed into dummy columns if they are categorical and we can drop that string column afterwards.","766f676b":"<h1>Saving the output for submission<\/h1>","3257d954":"**<h1>Data Preprocessing and analysis starts here<h1>**","b10fb7ec":"Concatinating dummy variables and original dataframe","a6d2ddea":"Split the data into test and train. Train data is used to train the model while test data will be used to check accuracy of model on unseen data. I am taking 20% of data as test. This depends on how much data you have. ","947bbf86":"<h1>Model Building <\/h1>","49dbd9b7":"Null values contribute in decreasing the accuracy of the model. One way to handle them is to remove that row completely but this is not preferred in small size dataset. We can replace that null value with some central tendency or zero. ","cb547cb8":"Here, I am filling the nan values with 0."}}