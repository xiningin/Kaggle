{"cell_type":{"769c979e":"code","caf8064c":"code","19a4f567":"code","745e54d7":"code","47fc61c0":"code","37d61fcd":"code","932ad71b":"code","ff10830d":"code","7ae51198":"code","9a0ac564":"code","080440f1":"code","369452b8":"code","f5d98999":"code","167c87cb":"code","4ffcb270":"code","92b8e0ae":"code","eb34e6a2":"code","bf0e74f9":"code","71c1f582":"code","d93e9721":"code","eeb43dce":"code","482e765e":"code","8924d1c3":"code","e25fda09":"markdown"},"source":{"769c979e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","caf8064c":"import numpy as np \n#import xlearn as xl","19a4f567":"import pandas as pd\n\ntrain = pd.read_csv(\"..\/input\/avazu-ctr-train\/train.csv\", nrows = 20000000)","745e54d7":"#\u65e0\u7f3a\u5931\u503c\ntrain.info()","47fc61c0":"pd.set_option('display.max_columns',None)\ntrain.head()","37d61fcd":"#\u67e5\u770b\u6570\u636e\u578b\u7279\u5f81\u548c\u7c7b\u522b\u578b\u7279\u5f81\ntrain.describe()","932ad71b":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nparams = {'legend.fontsize':'x-large',\n         'figure.figsize':(30,30),\n         'axes.labelsize':'x-large',\n         'axes.titlesize':'x-large',\n         'xtick.labelsize':'x-large',\n         'ytick.labelsize':'x-large'}\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\n\nplt.rcParams.update(params)\npd.options.display.max_colwidth = 600","ff10830d":"numerical_features =['hour','C1','C14','C15','C16','C17','C18','C19','C20','C21','click']\ntrain[numerical_features].hist()","7ae51198":"corrMatt = train[['C1','C14','C15','C16','C17','C18','C19','C20','C21','click','banner_pos','hour']].corr()\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(corrMatt,mask=mask,vmax=.8,square=True,annot=True)","9a0ac564":"train_data = pd.DataFrame(columns = [\"id\",\"click\",\"hour\", \"banner_pos\", \"site_id\", \"site_domain\", \"site_category\",\"app_id\", \"app_domain\", \"app_category\",\n                             \"device_id\",\"device_ip\",\"device_model\",\"device_type\",\"device_conn_type\",\"C14\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"])\n\n#train_data\nhour_index = 14102200\n\nwhile(hour_index < 14102224):\n    data = train.loc[train['hour'] == hour_index]\n    train_data = pd.concat([train_data,data])\n    hour_index = hour_index + 1\n    \ndel hour_index","080440f1":"sns.stripplot(x=\"banner_pos\",y=\"click\",data=train_data)\nplt.title(\"2014\u5e7410\u670822\u65e524\u4e2a\u65f6\u6bb5\u6563\u70b9\u56fe\")\nplt.show()","369452b8":"item = train_data['hour'].value_counts()\nitem.index","f5d98999":"# for hour_index in item.index:\n#     data = train_data.loc[train_data['hour'] == hour_index]\n#     sns.stripplot(x=\"banner_pos\",y=\"click\",data=data)\n#     plt.title(hour_index)\n#     plt.show()","167c87cb":"#train['day']=np.round(train,hour%10000\/100)\n#train['day'].value_counts()","4ffcb270":"#train['week']=np.round(train,\uff08hour%10000\/100+4\uff09%7)\n#train['week'].value_counts()","92b8e0ae":"# train['hour']=np.round(train,hour%100)\n# train['hour'].value_counts()","eb34e6a2":"# sns.countplot(x=\"hour1\", hue=\"click\",data=train);","bf0e74f9":"# sns.countplot(x=\"day\", hue=\"click\",data=train);","71c1f582":"train[\"time\"]=train[\"hour\"]%100\ntrain[\"week\"]=np.int64(((train[\"hour\"]%10000)\/100+4)%7)\ntrain[\"day\"]=np.int64((train[\"hour\"]\/100)%100)\nprint(\"\u65b0\u5efa\u7279\u5f81time week day\u5b8c\u6bd5\")\ntrain['size']=train['C15'].astype('str')+'_'+train['C16'].astype('str')\nprint(\"\u65b0\u5efa\u7279\u5f81size\u5b8c\u6bd5\")","d93e9721":"#\u521b\u5efa\u8ba1\u6570\u7279\u5f81\nfor feature in ['device_ip','device_id']:\n    grp1 = train.groupby(data[feature])\n    cnt1 = grp1[feature].aggregate(np.size)\n    _cnt = cnt1[train[feature]].values\n#    _cnt[np.isnan(_cnt)]=False\n    new_name=feature+'_count'\n    train[new_name]=_cnt\nprint(\"\u65b0\u5efa\u7279\u5f81\u8ba1\u6570\u7279\u5f81\u5b8c\u6bd5\")","eeb43dce":"import hashlib\n#garbage collector\nimport gc\nimport time\nfrom sklearn.preprocessing import StandardScaler\n\nNR_BINS = 1000000\n\ndef hashstr(input):\n    return str(int(hashlib.md5(input.encode('utf8')).hexdigest(), 16)%(NR_BINS-1)+1)","482e765e":"\n#\u7528\u6237\u7684\u5386\u53f2\u70b9\u51fb\u7387\u7279\u5f81\ndata1=train.groupby(by='device_ip').click.mean()\n_data=data1[train['device_ip']].values\ntrain['click_rate']=_data\n    \nprint(\"\u5f00\u59cb\u54c8\u5e0c\u7f16\u7801\")\n# ## \u54c8\u5e0c\u7f16\u7801 \nhash_list=['site_id', 'site_domain', 'app_id', 'app_domain', 'device_id', 'device_ip',\n            'device_model']\nfor item in hash_list:\n    feats = []\n    for row in train[item]:\n        feats.append(hashstr(row))\n    newname =item +'_hashed'\n    train[newname]=feats\n    #del feats\n    #data.drop([row],inplace=True,axis=1)\ntrain.drop(hash_list,inplace = True, axis = 1)\nprint(\"\u54c8\u5e0c\u7f16\u7801\u5b8c\u6210\")\n\nx_3 = train['click']","8924d1c3":"#One_hot\u7f16\u7801\nprint(\"\u5f00\u59cbonehot\u7f16\u7801\")\ncategorical_features=['week','C1','banner_pos','site_category','app_category','device_type','device_conn_type','C18','C19','C21','size']\nx_1 = train[categorical_features]\n#\u66f4\u6539\u6570\u636e\u7c7b\u578b\nx_1 = pd.DataFrame(data=x_1, dtype='object')\n#get_dummies\u8fdb\u884c\u7f16\u7801\nx_1 = pd.get_dummies(x_1)\nprint(\"onehot\u7f16\u7801\u5b8c\u6210\")\n\n#\u4e22\u5f03\u7279\u5f81\ndrop_feats=['click','week','C1','banner_pos','site_category','app_category','device_type','device_conn_type','C15','C16','C18','C19','C21','size']\ntrain.drop(drop_feats, inplace = True, axis = 1)\n#\u6807\u51c6\u5316    \n# \u521d\u59cb\u5316\u7279\u5f81\u7684\u6807\u51c6\u5316\u5668\nss_X = StandardScaler()\n# \u5206\u522b\u5bf9\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u7279\u5f81\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\nx_2 = ss_X.fit_transform(train)\nx_2 = pd.DataFrame(x_2)\nprint(\"\u6807\u51c6\u5316\u5904\u7406\")\n\n#\u5c06\u6570\u636e\u8fde\u63a5\u5728\u4e00\u8d77\ndata_final = pd.concat([x_3,x_2,x_1], axis = 1)\ndel x_1,x_2,x_3,data\nsavename = \"fe_train.csv\"\nsavenameI = \"fe_test.csv\"\nsavenameII = \"fe_names.csv\"\nsavenameIII = \"fe_validation.csv\"\n    \ndata_final_I  = data_final.iloc[0:40428967]\n    \n#\u6253\u4e71\u987a\u5e8f\ndata_final_I.sample(frac=1, replace=True)\n    \ndata_train_  = data_final_I.iloc[0:36000000]\n\ndata_validation_ = data_final_I.iloc[36000000:40428967]\n        \ndata_test_ = data_final.iloc[-4577464:]\ncolumn_names = data_final.iloc[0:10]\n    \nprint(\"data_final shape\",data_final.shape)\nprint(\"data_train shape\",data_train_.shape)\nprint(\"data_validation shape\",data_validation_.shape)\nprint(\"data_test shape\",data_test_.shape)\n   \n    \ncolumn_names.to_csv(savenameII,index=False)\ndata_train_.to_csv(savename,sep=' ',index=False,header=False)\ndata_test_.to_csv(savenameI,sep=' ',index=False,header=False)\ndata_validation_.to_csv(savenameIII,sep=' ',index=False,header=False)\ndel data_final,data_final_I,data_train_,data_test_,data_validation_,column_names\ngc.collect()\n    \nprint(\"The times finish\")","e25fda09":"\u4e3b\u8981\u76f8\u5173\u6027\u7279\u5f81\nC14\u548cC17:0.98\nC17 C21:0.44\nC14 C21:0.42\nC18 C21:-0.57\nC19\u548cC14 C17:-0.31\nC19 C21:-0.26\nC18\u548cC14 C17:-0.24 -0.25"}}