{"cell_type":{"274230d2":"code","8fe1e110":"code","39c7f77c":"code","39b94b4d":"code","a95ddd91":"code","80d785ef":"code","8574348c":"code","ac662bbd":"code","6e87f906":"code","0737412d":"code","a8bc28e2":"code","4c4eee90":"code","3b894e66":"code","c42d7a17":"code","4e97a1aa":"code","49096279":"code","777d0844":"code","4e6a9c2a":"code","7893f6fd":"code","db8187c7":"code","d4cfd030":"code","c248022c":"code","95132d57":"code","17606b27":"code","d92a398e":"markdown","69893c40":"markdown","75f47ada":"markdown","c8da2ad1":"markdown","4ebcbb9d":"markdown","bf98e2e9":"markdown","f9e3ab55":"markdown","73947ed0":"markdown","c7c9fe30":"markdown","f13051d6":"markdown","722050b5":"markdown","108513cb":"markdown","69a97ac0":"markdown","f052db43":"markdown","02c84a77":"markdown","69dda7cb":"markdown"},"source":{"274230d2":"# System\nimport sys\nimport os\nimport argparse\nimport itertools\n\n# Time\nimport time\nimport datetime\n\n# Numerical Data\nimport random\nimport numpy as np \nimport pandas as pd\n\n# Tools\nimport shutil\nfrom glob import glob\nfrom tqdm import tqdm\nimport gc\n\n# NLP\nimport re\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.utils import shuffle\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# Machine Learning Models\nfrom sklearn import svm\nfrom sklearn.svm import LinearSVC, SVC\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score\n\n\n# Deep Learning - Keras -  Preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Deep Learning - Keras - Model\nimport keras\nfrom keras import models\nfrom keras.models import Model\nfrom keras.models import load_model\nfrom keras.models import Sequential\n\n# Deep Learning - Keras - Layers\nfrom keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\nfrom keras.layers import Dense, Input, Dropout, MaxPool2D, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\nfrom keras.layers.pooling import _GlobalPooling1D\n\nfrom keras.regularizers import l2\n\n# Deep Learning - Keras - Pretrained Models\nfrom keras.applications.xception import Xception\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.densenet import DenseNet201\nfrom keras.applications.nasnet import NASNetMobile, NASNetLarge\n\nfrom keras.applications.nasnet import preprocess_input\n\n# Deep Learning - Keras - Model Parameters and Evaluation Metrics\nfrom keras import optimizers\nfrom keras.optimizers import Adam, SGD , RMSprop\nfrom keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n\n# Deep Learning - Keras - Visualisation\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau, LearningRateScheduler\n# from keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import backend as K\n\n# Deep Learning - TensorFlow\nimport tensorflow as tf\n\n# Graph\/ Visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# Image\nimport cv2\nfrom PIL import Image\nfrom IPython.display import display\n\n# np.random.seed(42)\n\n%matplotlib inline\n\n# Input data\nprint(os.listdir(\"..\/input\/\"))","8fe1e110":"def date_time(x):\n    if x==1:\n        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==2:    \n        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==3:  \n        return 'Date now: %s' % datetime.datetime.now()\n    if x==4:  \n        return 'Date today: %s' % datetime.date.today()  ","39c7f77c":"input_directory = r\"..\/input\/Kannada-MNIST\/\"\noutput_directory = r\"..\/output\/\"\n\ntraining_dir = input_directory + \"train_images\"\ntesting_dir = input_directory + r\"test_images\"\n\nif not os.path.exists(output_directory):\n    os.mkdir(output_directory)\n    \nfigure_directory = \"..\/output\/figures\"\nif not os.path.exists(figure_directory):\n    os.mkdir(figure_directory)\n\n# model_input_directory = \"..\/input\/models\/\"\n# if not os.path.exists(model_input_directory):\n#     os.mkdir(model_input_directory)\n\nmodel_output_directory = \"..\/output\/models\/\"\nif not os.path.exists(model_output_directory):\n    os.mkdir(model_output_directory)\n\n\n    \nfile_name_pred_batch = figure_directory+r\"\/result\"\nfile_name_pred_sample = figure_directory+r\"\/sample\"","39b94b4d":"train_df = pd.read_csv(input_directory + \"train.csv\")\ntrain_df.rename(index=str, columns={\"label\": \"target\"}, inplace=True)\ntrain_df.head()","a95ddd91":"test_df = pd.read_csv(input_directory + \"test.csv\")\ntest_df.rename(index=str, columns={\"label\": \"target\"}, inplace=True)\ntest_df.head()","80d785ef":"ticksize = 18\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nfigsize = (18, 5)\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol = \"target\"\nxlabel = \"Label\"\nylabel = \"Count\"\n\nsns.countplot(x=train_df[col])\nplt.title(\"Label Count\")\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.show()","8574348c":"def get_data(train_X=None, train_Y=None, test_X=None, batch_size=32):\n    print(\"Preprocessing and Generating Data Batches.......\\n\")\n    \n    rescale = 1.0\/255\n\n    train_batch_size = batch_size\n    validation_batch_size = batch_size*5\n    test_batch_size = batch_size*5\n    \n    train_shuffle = True\n    val_shuffle = True\n    test_shuffle = False\n    \n    train_datagen = ImageDataGenerator(\n        horizontal_flip=False,\n        vertical_flip=False,\n        rotation_range=10,\n#         shear_range=15,\n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,\n        rescale=rescale,\n        validation_split=0.25)\n\n    \n    train_generator = train_datagen.flow(\n        x=train_X, \n        y=train_Y, \n        batch_size=batch_size,\n        shuffle=True, \n        sample_weight=None, \n        seed=42, \n        save_to_dir=None, \n        save_prefix='', \n        save_format='png', \n        subset='training')\n    \n    \n    validation_generator = train_datagen.flow(\n        x=train_X, \n        y=train_Y, \n        batch_size=validation_batch_size,\n        shuffle=True, \n        sample_weight=None, \n        seed=42, \n        save_to_dir=None, \n        save_prefix='', \n        save_format='png', \n        subset='validation')\n    \n    test_datagen = ImageDataGenerator(rescale=rescale)\n    \n    test_generator = test_datagen.flow(\n        x=test_X, \n        y=None,  \n        batch_size=test_batch_size,\n        shuffle=False, \n        sample_weight=None, \n        seed=42, \n        save_to_dir=None, \n        save_prefix='', \n        save_format='png')\n    \n    class_weights = get_weight(np.argmax(train_Y, axis=1))\n    \n    steps_per_epoch = len(train_generator)\n    validation_steps = len(validation_generator)\n    \n    print(\"\\nPreprocessing and Data Batch Generation Completed.\\n\")\n    \n    \n    return train_generator, validation_generator, test_generator, class_weights, steps_per_epoch, validation_steps\n            \n# Calculate Class Weights\ndef get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current","ac662bbd":"def get_model(model_name, input_shape=(96, 96, 3), num_class=2, weights='imagenet', dense_units=1024, internet=False):\n    inputs = Input(input_shape)\n    \n    if model_name == \"Xception\":\n        base_model = Xception(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet50\":\n        base_model = ResNet50(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet101\":\n        base_model = keras.applications.resnet.ResNet101(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet152\":\n        base_model = keras.applications.resnet.ResNet152(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet50V2\":\n        base_model = resnet_v2.ResNet50V2(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet101V2\":\n        base_model = resnet_v2.ResNet101V2(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNet152V2\":\n        base_model = resnet_v2.ResNet152V2(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNeXt50\":\n        base_model = resnext.ResNeXt50(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"ResNeXt101\":\n        base_model = resnext.ResNeXt101(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"InceptionV3\":\n        base_model = InceptionV3(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"InceptionResNetV2\":\n        base_model = InceptionResNetV2(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"DenseNet201\":\n        base_model = DenseNet201(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"NASNetMobile\":\n        base_model = NASNetMobile(include_top=False, weights=weights, input_shape=input_shape)\n    elif model_name == \"NASNetLarge\":\n        base_model = NASNetLarge(include_top=False, weights=weights, input_shape=input_shape)\n        \n        \n#     x = base_model(inputs)\n#     x = Dropout(0.5)(x)\n    \n#     out1 = GlobalMaxPooling2D()(x)\n#     out2 = GlobalAveragePooling2D()(x)\n#     out3 = Flatten()(x)\n    \n#     out = Concatenate(axis=-1)([out1, out2, out3])\n    \n#     out = Dropout(0.6)(out)\n#     out = BatchNormalization()(out)\n#     out = Dropout(0.5)(out)\n    \n#     if num_class>1:\n#         out = Dense(num_class, activation=\"softmax\", name=\"3_\")(out)\n#     else:\n#         out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n        \n#     model = Model(inputs, out)\n#     model = Model(inputs=base_model.input, outputs=outputs)\n\n    \n    x = base_model.output\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(dense_units)(x)\n    x = BatchNormalization()(x)\n    x = Activation(activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    if num_class>1:\n        outputs = Dense(num_class, activation=\"softmax\")(x)\n    else:\n        outputs = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model(inputs=base_model.input, outputs=outputs)\n    \n    model.summary()\n    \n    \n    return model\n\n\ndef get_conv_model(num_class=2, input_shape=None, dense_units=256):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', input_shape = input_shape))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n    \n    model.add(Flatten())\n    model.add(Dense(dense_units, activation = \"relu\"))\n    model.add(Dropout(0.5))\n\n    \n#     model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4), input_shape = input_shape))\n#     model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    \n#     model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n#     model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    \n#     model.add(MaxPool2D())\n#     model.add(Dropout(0.5))\n\n    \n#     model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n#     model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    \n#     model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n#     model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n    \n#     model.add(MaxPool2D())\n#     model.add(Dropout(0.5))\n    \n    \n#     model.add(GlobalAveragePooling2D())\n    \n    \n    if num_class>1:\n        model.add(Dense(num_class, activation='softmax'))\n    else:\n        model.add(Dense(num_class, activation='sigmoid'))\n    \n    print(model.summary())\n\n    return model","6e87f906":"def plot_performance(history=None, figure_directory=None):\n    xlabel = 'Epoch'\n    legends = ['Training', 'Validation']\n\n    ylim_pad = [0.005, 0.005]\n    ylim_pad = [0, 0]\n\n\n    plt.figure(figsize=(20, 5))\n\n    # Plot training & validation Accuracy values\n\n    y1 = history.history['accuracy']\n    y2 = history.history['val_accuracy']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[0]\n    max_y = max(max(y1), max(y2))+ylim_pad[0]\n    \n#     min_y = .96\n#     max_y = 1\n\n\n    plt.subplot(121)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Accuracy\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Accuracy', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n\n\n    # Plot training & validation loss values\n\n    y1 = history.history['loss']\n    y2 = history.history['val_loss']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[1]\n    max_y = max(max(y1), max(y2))+ylim_pad[1]\n\n#     min_y = .1\n#     max_y = 0\n\n    plt.subplot(122)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Loss\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Loss', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n    if figure_directory:\n        plt.savefig(figure_directory+\"\/history\")\n\n    plt.show()","0737412d":"main_model_dir = output_directory + r\"models_output\/\"\nmain_log_dir = output_directory + r\"logs\/\"\n\ntry:\n    os.mkdir(main_model_dir)\nexcept:\n    print(\"Could not create main model directory\")\n    \ntry:\n    os.mkdir(main_log_dir)\nexcept:\n    print(\"Could not create main log directory\")\n\n\n\nmodel_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"\/\"\nlog_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n\n\ntry:\n    os.mkdir(model_dir)\nexcept:\n    print(\"Could not create model directory\")\n    \ntry:\n    os.mkdir(log_dir)\nexcept:\n    print(\"Could not create log directory\")\n    \nmodel_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"","a8bc28e2":"print(\"Settting Callbacks\")\n\ndef step_decay(epoch, lr):\n    # initial_lrate = 1.0 # no longer needed\n    lrate = lr\n    if epoch==2:\n        lrate = 0.0001  \n#     lrate = lr * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n    return lrate\n\n\ncheckpoint = ModelCheckpoint(\n    model_file, \n    monitor='val_acc', \n    save_best_only=True)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    verbose=1,\n    restore_best_weights=True)\n\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.6,\n    patience=2,\n    min_lr=0.0000001,\n    verbose=1)\n\nlearning_rate_scheduler = LearningRateScheduler(step_decay, verbose=1)\n# f1_metrics = Metrics()\n\n\ncallbacks = [reduce_lr, early_stopping]\n# callbacks = [checkpoint, reduce_lr, early_stopping]\n# callbacks = [reduce_lr, early_stopping, f1_metrics]\n\nprint(\"Set Callbacks at \", date_time(1))","4c4eee90":"print(\"Getting Base Model\", date_time(1))\n\n# model_name=\"InceptionV3\"\n# model_name=\"NASNetMobile\"\n\ndim = 28\n\ninput_shape = (dim, dim, 1)\n\n\nnum_class = len(set(train_df[\"target\"].values))\n\nweights = 'imagenet'\ndense_units = 256\n\ninternet = True\n\n# model = get_model(model_name=model_name, \n#                   input_shape=input_shape, \n#                   num_class=num_class, \n#                   weights=weights, \n#                   dense_units=dense_units, \n#                   internet=internet)\n\nmodel = get_conv_model(num_class=num_class, input_shape=input_shape, dense_units=dense_units)\nprint(\"Loaded Base Model\", date_time(1))","3b894e66":"loss = 'categorical_crossentropy'\n# loss = 'binary_crossentropy'\nmetrics = ['accuracy']\n# metrics = [auroc]","c42d7a17":"# train_X = train_df.drop(columns=[\"target\"]).values\n# train_Y = train_df[\"target\"].values\n\n\n# clf = svm.SVC()\n\n# cross_val_score(clf, train_X, train_Y, cv=10, n_jobs=-1, verbose=2)","4e97a1aa":"train_X = train_df.drop(columns=[\"target\"]).values\ntrain_X = train_X.reshape(train_X.shape[0], dim, dim,1)\n\ntrain_Y = train_df[\"target\"].values\ntrain_Y = keras.utils.to_categorical(train_Y, 10) \n\ntest_X = test_df.drop(columns=[\"id\"]).values\ntest_X = test_X.reshape(test_X.shape[0], dim, dim,1)","49096279":"batch_size = 128\n\n# class_mode = \"categorical\"\n# class_mode = \"binary\"\n\n# target_size = (dim, dim)\n\ntrain_generator, validation_generator, test_generator, class_weights, steps_per_epoch, validation_steps = get_data(train_X=train_X, train_Y=train_Y, test_X=test_X, batch_size=batch_size)\n","777d0844":"print(\"Starting Trainning ...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\n# batch_size = 32\n# train_generator, validation_generator, test_generator, class_weights, steps_per_epoch, validation_steps = get_data(batch_size=batch_size)\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nsteps_per_epoch = len(train_generator)\nvalidation_steps = len(validation_generator)\n\nverbose = 1\nepochs = 100\n\nprint(\"Trainning Model ...\\n\")\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_data=validation_generator,\n    validation_steps=validation_steps, \n    class_weight=class_weights)\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","4e6a9c2a":"plot_performance(history=history)","7893f6fd":"ypreds = model.predict_generator(generator=test_generator, steps = len(test_generator),  verbose=1)\n# ypreds","db8187c7":"# ypred = ypreds[:,1]#\nypred = np.argmax(ypreds, axis=1)","d4cfd030":"sample_df = pd.read_csv(input_directory+\"sample_submission.csv\")\nsample_df.head()","c248022c":"test_gen_id = test_generator.index_array\nsample_submission_id = sample_df[\"id\"]\n\nlen(test_gen_id), len(sample_submission_id)","95132d57":"sample_list = list(sample_df.id)\n\npred_dict = dict((key, value) for (key, value) in zip(test_generator.index_array, ypred))\n\npred_list_new = [pred_dict[f] for f in sample_list]\n\ntest_df = pd.DataFrame({'id': sample_list,'label': pred_list_new})\n\ntest_df.to_csv('submission.csv', header=True, index=False)","17606b27":"test_df.head()","d92a398e":"# 7. Model","69893c40":"# 9. Training","75f47ada":"![]()","c8da2ad1":"# 4. Visualization","4ebcbb9d":"# 5. Preprocess","bf98e2e9":"![](data:image\/png;base64,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)","f9e3ab55":"# 1. Import ","73947ed0":"## 6.2 Call Back Configuration","c7c9fe30":"# 6. Output Configuration","f13051d6":"# 8. Data","722050b5":"# Kannada MNIST","108513cb":"# 10. Model Performance \nModel Performance  Visualization over the Epochs","69a97ac0":"# 3. Input Configuration","f052db43":"# 2. Functions","02c84a77":"# 5. Model Function","69dda7cb":"## Visualization"}}