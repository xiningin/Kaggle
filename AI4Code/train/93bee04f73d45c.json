{"cell_type":{"7d9c70a7":"code","51087a31":"code","90e178ae":"code","e75de76a":"code","94f19a1f":"code","59f72795":"code","cb694ff5":"code","759d4d99":"code","ea7f4685":"code","3cc44954":"code","853dbb49":"code","b86c6e83":"code","eb0cde36":"code","4053bf08":"code","5c47ee56":"code","28290b75":"code","2aff6f95":"code","29c10a53":"code","32de8918":"code","b3c8e82b":"code","da5d6c19":"code","f957c1ac":"code","27e42ea1":"code","b6d89957":"code","9bfc2a63":"code","fc87335e":"markdown","ace83dcc":"markdown","51f15714":"markdown","1a443184":"markdown","095abfdc":"markdown","5e8f9160":"markdown","658600a4":"markdown","a346fff8":"markdown","e498a2eb":"markdown","4c55ffa1":"markdown","c1c79e05":"markdown","01193714":"markdown","8a824e94":"markdown","c52ebdc1":"markdown","94a0f799":"markdown","81b659ab":"markdown","ecb3f910":"markdown","ec8ad4f2":"markdown"},"source":{"7d9c70a7":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.utils.data as utils\nfrom torchvision import transforms\nimport torch.nn.functional as F","51087a31":"path = '..\/input\/severstal-steel-defect-detection\/'","90e178ae":"tr = pd.read_csv(path + 'train.csv')\nprint(len(tr))\ntr.head(6)","e75de76a":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\ndf_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","94f19a1f":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","59f72795":"columns = 1\nrows = 4\nfig = plt.figure(figsize=(20,columns*rows+6))\nfor i in range(1,columns*rows+1):\n    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n    fig.add_subplot(rows, columns, i).set_title(fn)\n    img = cv2.imread( path + 'train_images\/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n    img[mask==1,0] = 255\n    plt.imshow(img)\nplt.show()","cb694ff5":"class ImageData(Dataset):\n    def __init__(self, df, transform, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.subset = subset\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images\/'\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):                      \n        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n        img = Image.open(self.data_path + fn)\n        img = self.transform(img)\n\n        if self.subset == 'train': \n            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n            mask = transforms.ToPILImage()(mask)            \n            mask = self.transform(mask)\n            return img, mask\n        else: \n            mask = None\n            return img       ","759d4d99":"data_transf = transforms.Compose([\n                                  transforms.Scale((256, 256)),\n                                  transforms.ToTensor()])\ntrain_data = ImageData(df = df_train, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size=4)","ea7f4685":"plt.imshow(train_data[3][0].permute(1, 2, 0))","3cc44954":"plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))","853dbb49":"def convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n# copied from 682\n# model = nn.Sequential(\n#     nn.Conv2d(3, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.Conv2d(64, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.MaxPool2d(2), #32\/2\n        nn.ReLU(inplace=True),\n    )\n\nclass UNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        \n        self.base_model = models.resnet18()\n        self.base_model.load_state_dict(torch.load(\"..\/input\/resnet18\/resnet18.pth\"))\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3])\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","b86c6e83":"model = UNet(n_class=1).cuda()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), weight_decay=1e-4, lr = 0.001, momentum=0.9)","eb0cde36":"%%time\nfor epoch in range(5):      \n    model.train()         \n    for ii, (data, target) in enumerate(train_loader):                         \n        data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)  \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()          \n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))","4053bf08":"plt.imshow(train_data[6][0].permute(1, 2, 0))","5c47ee56":"x = train_data[6][0].unsqueeze(0)\no = model(x.cuda())  \no = o.cpu().detach().numpy() * (-1)\ntmp = np.copy(o)\nmn = np.mean(o)*1.2\ntmp[tmp<mn] = 0\ntmp[tmp>mn] = 1\nplt.imshow(np.squeeze(tmp))","28290b75":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))\nsub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\nprint(len(sub4))\nsub4.head()","2aff6f95":"test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","29c10a53":"%%time\npredict = []\nmodel.eval()\nfor data in test_loader:\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy() * (-1)    \n    predict.append(abs(output[0]))","32de8918":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","b3c8e82b":"%%time\npred_rle = []\n  \nfor p in predict:        \n    img = np.copy(p)\n    mn = np.mean(img)*1.2\n    img[img<=mn] = 0\n    img[img>mn] = 1\n    img = cv2.resize(img[0], (1600, 256))\n    \n    pred_rle.append(mask2rle(img))","da5d6c19":"submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\nsubmit.head()","f957c1ac":"img_s = cv2.imread( path + 'test_images\/'+ submit['ImageId_ClassId'][47].split('_')[0])\nplt.imshow(img_s)","27e42ea1":"mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\nplt.imshow(mask_s)","b6d89957":"submit.head(10)","9bfc2a63":"submit.to_csv('submission.csv', index=False)","fc87335e":"#### To simplify and speed up process, n this kernel I use only images with ClassId=4","ace83dcc":"### Training","51f15714":"### Display some images","1a443184":"### Read submit file","095abfdc":"### Create test Dataset and DataLoader","5e8f9160":"Architecture of Model is U-Net with pretrained encoder. In our case it ResNet18.\n\n![](https:\/\/github.com\/ushur\/Severstal-Steel-Defect-Detection\/blob\/master\/unet.jpg?raw=true)","658600a4":"### Decode mask","a346fff8":"### Import necessary libraries","e498a2eb":"### Show prediction on image from train dataset","4c55ffa1":"### Read train dataframe","c1c79e05":"### Resize images","01193714":"### Prepare submission file","8a824e94":"### Prediction","c52ebdc1":"### Create train Dataset and DataLoader","94a0f799":"### Encode mask ","81b659ab":"### Show some image and mask","ecb3f910":"### Steel Defect Detection \n\nThis is basic kernel to start participating in this competition.\nIt shows how to use PyTorch for solving the segmentation problem.\nIf you prefer to use Keras, I also created others basic Kernels: \n1. https:\/\/www.kaggle.com\/ateplyuk\/keras-starter-segmentation\n1. https:\/\/www.kaggle.com\/ateplyuk\/keras-starter-u-net","ec8ad4f2":"### Create U-Net Model"}}