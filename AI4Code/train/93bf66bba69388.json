{"cell_type":{"197c50ae":"code","516bc54b":"code","89f9b0e7":"code","78b36908":"code","0e765c91":"code","f472c814":"code","09d07b78":"code","e2d2bef9":"code","b658d7db":"code","13b76b96":"markdown","e9326f9e":"markdown","09a07e90":"markdown","3d5167db":"markdown","91c8e4ee":"markdown","11ef09e8":"markdown","7973fba8":"markdown"},"source":{"197c50ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","516bc54b":"#this list was arrived at in the following way:\n#ran cesium features + metadata through lgbm with trouble classes only\n#csFeatsToAdd=importances[importances['fold']==5].nlargest(40,'mean_gain').loc[:,'feature'].unique()\n#will try to remove redundancies\n#it turns out that 32 are not redundant (although possible collinearities where same basic feature has different name)\n\ncesiumFeaturesToConsider=['mjd_diff_det', 'distmod',\n       'flux_by_flux_ratio_sq__longest_strike_above_mean',\n       '__max_slope___2_', '__skew___4_',\n       'flux__longest_strike_above_mean',\n       '__median_absolute_deviation___2_', '__max_slope___3_',\n       '__freq_varrat___3_', '__percent_amplitude___3_',\n       '__percent_difference_flux_percentile___5_', '__std___5_',\n       '__percent_amplitude___5_', '__median_absolute_deviation___1_',\n       '__freq2_rel_phase2___2_', 'hostgal_photoz',\n       '__freq_y_offset___0_', 'hostgal_photoz_certain',\n       '__stetson_j___5_', '__freq_varrat___1_',\n       '__qso_log_chi2_qsonu___0_', '__amplitude___2_',\n       '__percent_difference_flux_percentile___2_', '__amplitude___0_',\n       '__freq_varrat___5_', '__skew___5_', '__freq_varrat___2_',\n       '__freq3_freq___2_', '__freq1_rel_phase4___5_',\n       'flux__mean_change', '__flux_percentile_ratio_mid80___5_',\n       '__percent_amplitude___2_', '__amplitude___5_',\n       '__median_absolute_deviation___5_', '__freq3_freq___3_',\n       '__qso_log_chi2_qsonu___5_', 'hostgal_photoz_err',\n       '__freq1_rel_phase3___5_', '__freq2_rel_phase2___4_',\n       '__freq2_rel_phase3___4_','object_id']","89f9b0e7":"def convertNames(testName):\n    trainName=\"\"\n    \n    lenTest=len(testName)\n    for charindex in range(lenTest):\n        char=testName[charindex]\n        #print(char)\n        if char in [')','(', ' ',',',\"'\"]:\n            trainName=trainName + '_'\n            #print('changed')\n        else:\n            trainName+=char\n            \n    return trainName\n\n            \ntestName=\"('percent_amplitude', 0)\"\ntrainName=convertNames(testName)\nprint(trainName)","78b36908":"#for chunk in pd.read_csv(fn, chunksize=10)\nfn='..\/input\/plasticc-features\/single_output_test_ts_features.csv'\nfor chunk in pd.read_csv(fn, chunksize=10):\n    testCols=chunk.columns\n    break","0e765c91":"nameDict={}\ncolsToGrab=[]\nfor testCol in testCols:\n    trainName=convertNames(testCol)\n    if trainName in cesiumFeaturesToConsider:\n        colsToGrab.append(testCol)\n        nameDict[testCol]=trainName\n        \n#colsToGrab\n    ","f472c814":"testCesiumDf = pd.read_csv(fn, skipinitialspace=True, usecols=colsToGrab)","09d07b78":"testCesiumDf.shape","e2d2bef9":"#df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\ntestCesiumDf = testCesiumDf.rename(columns=nameDict)","b658d7db":"testCesiumDf.to_csv('reducedCesiumTestRevB.csv', index=False)","13b76b96":"## Get the column list and a dictionary for translating to the training names","e9326f9e":"## Open the selected columns of the dataFrame","09a07e90":"## Rename the columns so they'll match the training data","3d5167db":"## I wanted to use some of Mithrillion's features\n- in concert with my custom features and with the featureset passed down via Chai-ta Tsai, Iprapas, and others\n- I kept crashing my kernel\n- So I needed to pare it down BEFORE bringing it into my main kernel","91c8e4ee":"## First challenge - column names don't match in training and test\n- Features were chosen based on CV importances on training data\n- Opening the whole file crashed kernel\n- Trying to open with above column names weren't recognized\n- It is easier to go from testName --> trainingName using method below","11ef09e8":"## Open the first 10 rows just to get the test column names\n","7973fba8":"## Save the file for pulling into featureMergingKernel"}}