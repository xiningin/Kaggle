{"cell_type":{"11121b72":"code","b565ad19":"code","d86947d7":"code","98496f30":"code","03253e16":"code","e5f480c2":"code","a1a881aa":"code","85bc9ca0":"code","227eacd6":"code","a23c5b3b":"code","5d55bf15":"code","e320da68":"code","3735c7ad":"code","eb6a4629":"code","cfc4af58":"code","221e168d":"code","c19c26f3":"code","63726876":"code","d1798761":"code","1e3d53c5":"code","ef42d853":"code","312d4d48":"code","34841f66":"code","be602c73":"code","547df1c4":"code","9fa19142":"code","3bcd0399":"code","110dce44":"code","5d0f917f":"code","9bf3b343":"code","876239f8":"code","21a46e91":"code","22453b4d":"code","7ae8187a":"code","2b9c8b40":"code","cad4adb2":"code","e8d5a111":"code","f1682aa7":"code","fafa3930":"code","f39f63d3":"code","790635cf":"code","fc7ead53":"code","08a97ded":"code","e6b38014":"code","60f4663c":"code","efa43515":"code","30ba55a1":"code","f24c76c5":"code","f6618048":"code","9a1ffa51":"code","586679e1":"code","14a23720":"code","65a51065":"code","0bb44f23":"code","5f39f8cc":"code","84ec1256":"code","a9851b33":"markdown"},"source":{"11121b72":"#\u0438\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\nfrom datetime import datetime\nfrom dateutil.parser import parse\n#!pip install category_encoders\nimport category_encoders as ce\nfrom sklearn.linear_model import LinearRegression\n\n\n#\u0438\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\n\n\n\nfrom sklearn.metrics import precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom tqdm import tqdm\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold ","b565ad19":"zf = zipfile.ZipFile('..\/input\/sberbank-russian-housing-market\/train.csv.zip') \ndf = pd.read_csv(zf.open('train.csv'), index_col = 'id')","d86947d7":"df.describe()","98496f30":"df.timestamp = df.timestamp.apply(lambda x: parse(x))   # \u0441\u043f\u0430\u0440\u0441\u0438\u043b\u0438 \u0434\u0430\u0442\u0443\ndf.reset_index(drop = True, inplace = True)\ndf.set_index(['timestamp'], inplace = True)         # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438 \u0434\u0430\u0442\u0443 \u043a\u0430\u043a \u0438\u043d\u0434\u0435\u043a\u0441","03253e16":"df_obj = df[df.dtypes[df.dtypes == object].index]   #\u0440\u0430\u0431\u043e\u0442\u0430 \u0441 object\nencoder = ce.OneHotEncoder(cols = df_obj.columns, use_cat_names = True)\nencoder.fit(df)\ndf = encoder.transform(df)        #\u0432\u0441\u0435 object-\u044b \u0434\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043b\u0438 , \u043f\u043e\u043b\u043e\u0436\u0438\u043b\u0438 \u0441\u044e\u0434\u0430","e5f480c2":"# \u0442\u0435\u043f\u0435\u0440\u044c \u0440\u0430\u0437\u0431\u0435\u0440\u0435\u043c\u0441\u044f \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438\ndf_nan = df.isnull().sum().reset_index()\ndf_nan.columns = ['col_name', 'quant']\ncolumn_nan = df_nan[df_nan.quant > 0].reset_index(drop = True)\ncolumn_nan.quant = column_nan.quant.apply(lambda x: round((x*100)\/30471, 1))\nprint(\"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0441 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438: {}\".format(column_nan.shape[0]))\nprint(\"\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(column_nan.quant.max()))\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(column_nan.quant.min()))\nprint(\"\u041c\u0435\u0434\u0438\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(round(column_nan.quant.median(),1)))","a1a881aa":"# \u0442\u0430\u043c, \u0433\u0434\u0435 \u043c\u0430\u043b\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0437\u0430\u043c\u0435\u043d\u0438\u043b\u0438 \u043d\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0435\ndf.floor = df[['floor']].fillna(df[['floor']].mean())\ndf.metro_min_walk = df[['metro_min_walk']].fillna(df[['metro_min_walk']].mean())\ndf.metro_km_walk = df[['metro_km_walk']].fillna(df[['metro_km_walk']].mean())\ndf.railroad_station_walk_km = df[['railroad_station_walk_km']].fillna(df[['railroad_station_walk_km']].mean())\ndf.railroad_station_walk_min = df[['railroad_station_walk_min']].fillna(df[['railroad_station_walk_min']].mean())\ndf.prom_part_5000 = df[['prom_part_5000']].fillna(df[['prom_part_5000']].mean())\ndf.cafe_avg_price_5000 = df[['cafe_avg_price_5000']].fillna(df[['cafe_avg_price_5000']].mean())\ndf.cafe_sum_5000_max_price_avg = df[['cafe_sum_5000_max_price_avg']].fillna(df[['cafe_sum_5000_max_price_avg']].mean())\ndf.cafe_sum_5000_min_price_avg = df[['cafe_sum_5000_min_price_avg']].fillna(df[['cafe_sum_5000_min_price_avg']].mean())\ndf.ID_railroad_station_walk = df[['ID_railroad_station_walk']].fillna(df[['ID_railroad_station_walk']].mean())","85bc9ca0":"def predict_value(y, x):\n    x.append(y)\n    df_predict = df[x]\n    df_replacena_train=df_predict.loc[df[y].notna()]\n    df_linear=df_replacena_train.drop(columns = [y],axis=1)\n    df_linear_y=df_replacena_train[y].tolist()\n    reg=LinearRegression()\n    reg.fit(df_linear,df_linear_y)\n\n    df_na=df_predict.loc[df_predict[y].isna()]\n    df_linear_pred = df_na.drop(columns = [y])\n\n    list_pred=reg.predict(df_linear_pred )\n    list_pred_rounded=[]\n    for i in list_pred:\n        list_pred_rounded.append(i)\n\n    \n    df_na[y]=list_pred_rounded\n\n    df_predict =pd.concat([df_na,df_replacena_train])\n    df[y] = df_predict[y].values","227eacd6":"y = 'life_sq'\nx = ['full_sq']\npredict_value(y,x)\n\ny = 'num_room'\nx = ['full_sq']\npredict_value(y,x)\n\n\ny = 'kitch_sq'\nx = ['full_sq']\npredict_value(y,x)","a23c5b3b":"x = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\ny = 'cafe_sum_500_min_price_avg'\npredict_value(y,x)\n\ny = 'cafe_sum_1500_max_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_avg_price_1500'\nx = [ 'cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_2000_min_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_2000_max_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_3000_min_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_3000_max_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_500_max_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_avg_price_500'\nx = [ 'cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_1000_min_price_avg'\nx = [ 'cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_1000_max_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_avg_price_1000'\nx = [ 'cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_sum_1500_min_price_avg'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\n\ny = 'cafe_avg_price_2000'\nx = ['cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)\n\ny = 'cafe_avg_price_3000'\nx = [ 'cafe_avg_price_5000', 'cafe_count_5000_na_price', 'cafe_count_5000_price_500', 'cafe_count_5000_price_1000', 'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500' , 'cafe_count_5000_price_4000', 'cafe_count_5000_price_high' ]\npredict_value(y,x)","5d55bf15":"df[df.floor > df.max_floor].max_floor = df[df.floor > df.max_floor].floor #\u0437\u0430\u043c\u0435\u043d\u0438\u043b\u0430 max_floor \u043d\u0430 floor\ndf.max_floor = df[['max_floor']].fillna(df[['max_floor']].mean())","e320da68":"replace_state = df[df.state > 4]['state'].unique()\ndf['state'].replace(replace_state.tolist(),df[df.state < 5][['state']].mode().values[0][0], inplace = True)","3735c7ad":"df.state = df[['state']].fillna(df[df.state < 5][['state']].mode().values[0][0])","eb6a4629":"replace_year = df[df.build_year < 1691.0]['build_year'].unique()\ndf['build_year'].replace(replace_year.tolist(),df[df.build_year > 1691.0][['build_year']].mode().values[0][0], inplace = True)\nreplace_year = df[df.build_year > 2018.0]['build_year'].unique()\ndf['build_year'].replace(replace_year.tolist(),df[df.build_year > 1691.0][['build_year']].mode().values[0][0], inplace = True)","cfc4af58":"for i in column_nan.col_name.values:\n    df[i] = df[i].fillna(df[i].mean())","221e168d":"# \u0442\u0435\u043f\u0435\u0440\u044c \u0440\u0430\u0437\u0431\u0435\u0440\u0435\u043c\u0441\u044f \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438\ndf_nan = df.isnull().sum().reset_index()\ndf_nan.columns = ['col_name', 'quant']\ncolumn_nan = df_nan[df_nan.quant > 0].reset_index(drop = True)\ncolumn_nan.quant = column_nan.quant.apply(lambda x: round((x*100)\/30471, 1))\nprint(\"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0441 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438: {}\".format(column_nan.shape[0]))\nprint(\"\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(column_nan.quant.max()))\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(column_nan.quant.min()))\nprint(\"\u041c\u0435\u0434\u0438\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c: {}%\".format(round(column_nan.quant.median(),1)))","c19c26f3":"#\u0431\u043b\u043e\u043a \u0441\u043b\u0438\u044f\u043d\u0438\u044f \u0441 \u043c\u0430\u043a\u0440\u043e \nzf = zipfile.ZipFile('..\/input\/sberbank-russian-housing-market\/macro.csv.zip') \nmacro = pd.read_csv(zf.open('macro.csv'))\ndf.sort_index(inplace = True)\ndf.reset_index(inplace = True)\nmacro.timestamp = macro.timestamp.apply(lambda x: parse(x))   # \u0441\u043f\u0430\u0440\u0441\u0438\u043b\u0438 \u0434\u0430\u0442\u0443\nmacro.reset_index(drop = True, inplace = True)    \ndf_macro = df.merge(macro, how = 'left', on = 'timestamp' )","63726876":"df_macro","d1798761":"y = df['price_doc']                      #timestamp \u0442\u043e\u0436\u0435 \u0443\u0434\u0430\u043b\u0438\u0442\u044c \u043d\u0430\u0434\u043e\nx = df.drop(['price_doc'], axis = 1)","1e3d53c5":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)","ef42d853":"%%time\ncv = ShuffleSplit(n_splits=5,  random_state=42)\n\npipe = Pipeline([('regresion', RandomForestRegressor())])\n\n\nparam_grid =[\n    {'regresion': [RandomForestRegressor(random_state = 42, n_jobs =-1)],\n     'regresion__n_estimators': [int(x) for x in np.linspace(start = 25, stop = 30, num = 5)],\n     'regresion__max_depth': [int(x) for x in np.linspace(start = 25, stop = 30, num = 5)] ,\n    }\n]\n\ngrid = GridSearchCV(pipe, param_grid, cv=cv, return_train_score=True)\ngrid.fit(X_train,y_train)\n\nprint(\"----------------- \u041e\u0431\u0443\u0447\u0438\u043b\u0438 \u0438 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043b\u0438 -------------------\")\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b:\\n{}\\n\".format(grid.best_params_))\nprint(\"\u0421\u0440\u0435\u0434\u043d\u044f\u044f \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0434\u043b\u044f \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043a\u0440\u043e\u0441\u0441\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u043d\u0430\u0431\u043e\u0440\u0430\u0445: {:.6f}\\n\".format(grid.best_score_)) \nprint(\"\u0421\u0440\u0435\u0434\u043d\u044f\u044f \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0434\u043b\u044f \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435: {:.6f}\\n\".format(grid.score(X_test, y_test)))\ngridresults = pd.DataFrame(grid.cv_results_)\ndisplay(gridresults.sort_values([\"rank_test_score\"]).T)","312d4d48":"y=df.price_doc.tolist()","34841f66":"df_corr=df.corr()","be602c73":"df10=df_corr.nlargest(11, 'price_doc')","547df1c4":"df10['price_doc'].index","9fa19142":"from sklearn.ensemble import RandomForestRegressor","3bcd0399":"import matplotlib.pyplot as plt\n","110dce44":"for i in df20['price_doc'].index.tolist():\n    print(sum(df['%s'%i].isna()),i)","5d0f917f":"df['num_room']","9bf3b343":"df_rooms=df.corr().nlargest(21, 'num_room')","876239f8":"df_rooms['num_room']","21a46e91":"from sklearn.linear_model import LinearRegression\ndf_replacena_train=df.loc[df['num_room'].notna()]","22453b4d":"df_replacena_train[['full_sq','num_room','life_sq']]","7ae8187a":"df_linear=df_replacena_train[['full_sq','num_room']]","2b9c8b40":"df_linear_y=df_linear['num_room'].tolist()","cad4adb2":"df_linear=df_linear.drop('num_room',axis=1)","e8d5a111":"reg=LinearRegression()\nreg.fit(df_linear,df_linear_y)","f1682aa7":"df_na=df.loc[df['num_room'].isna()]","fafa3930":"df_linear_pred=df_na[['full_sq']]","f39f63d3":"list_pred=reg.predict(df_linear_pred)\nlist_pred_rounded=[]\nfor i in list_pred:\n    list_pred_rounded.append(round(i))\n","790635cf":"df_na['num_room']=list_pred_rounded","fc7ead53":"df_filled=pd.concat([df_na,df_replacena_train])","08a97ded":"df_filled","e6b38014":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"num_room\", data=df_filled)\nplt.ylabel('count')\nplt.xlabel('num_room')\nplt.xticks(rotation='vertical')\nplt.show()","60f4663c":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"timestamp\", data=df_filled)\nplt.ylabel('count')\nplt.xlabel('timestamp')\nplt.xticks(rotation='vertical')\nplt.show()","efa43515":"df_filled['month'] = pd.DatetimeIndex(df_filled['timestamp']).month","30ba55a1":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"month\", data=df_filled)\nplt.ylabel('count')\nplt.xlabel('month')\nplt.xticks(rotation='vertical')\nplt.show()","f24c76c5":"zf = zipfile.ZipFile('..\/input\/sberbank-russian-housing-market\/test.csv.zip') \ndf_test = pd.read_csv(zf.open('test.csv'))","f6618048":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"num_room\", data=df_test)\nplt.ylabel('count')\nplt.xlabel('num_room')\nplt.xticks(rotation='vertical')\nplt.show()","9a1ffa51":"df_test['month'] = pd.DatetimeIndex(df_test['timestamp']).month","586679e1":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"month\", data=df_test)\nplt.ylabel('count')\nplt.xlabel('month')\nplt.xticks(rotation='vertical')\nplt.show()","14a23720":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"month\", data=df_filled)\nplt.ylabel('count')\nplt.xlabel('month')\nplt.xticks(rotation='vertical')\nplt.show()","65a51065":"df_filled['YearMonth'] = pd.DatetimeIndex(df_filled['timestamp']).map(lambda x: 100*x.year + x.month)","0bb44f23":"df_test['YearMonth'] = pd.DatetimeIndex(df_test['timestamp']).map(lambda x: 100*x.year + x.month)","5f39f8cc":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"YearMonth\", data=df_filled)\nplt.ylabel('count')\nplt.xlabel('month')\nplt.xticks(rotation='vertical')\nplt.show()","84ec1256":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"YearMonth\", data=df_test)\nplt.ylabel('count')\nplt.xlabel('month')\nplt.show()","a9851b33":"### \u0414\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u0447\u0438\u0441\u0442\u0438\u043b\u0438"}}