{"cell_type":{"462eb45c":"code","80c5ca31":"code","733d5279":"code","94d99b9c":"code","48f684f6":"code","f3d30b49":"code","548e8fcf":"code","9a0a4b4c":"code","db55671f":"code","86eb5e53":"code","b29c52bc":"code","feb416c8":"code","ae203ded":"markdown","574fb74d":"markdown","4186b5d9":"markdown","2f4db58d":"markdown"},"source":{"462eb45c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","80c5ca31":"fb_df = pd.read_csv('\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/FB_data.csv', index_col='date', parse_dates=True)\nfb_df.head()","733d5279":"from sklearn.preprocessing import MinMaxScaler\n\nprice_scaler, volume_scaler = MinMaxScaler(), MinMaxScaler()\n\nprice_scaler.fit(np.array(fb_df['close']).reshape(-1, 1))\nfb_df[['open','high','low','close']] = price_scaler.transform(fb_df[['open','high','low','close']])\nfb_df['volume'] = volume_scaler.fit_transform(np.array(fb_df['volume']).reshape(-1, 1))\nfb_df","94d99b9c":"figure = plt.figure(figsize=(16,8))\nplt.xlabel('Date')\nplt.ylabel('Price per Share')\nplt.title('Opening and closing prices of Facebook common stock')\n\nplt.plot(fb_df['open'], label='Open')\nplt.plot(fb_df['close'], label='Close')\nplt.legend()","48f684f6":"from sklearn.utils import shuffle\n\ndef process_data(data, days_back):\n    X,Y = [],[]\n    for i in range(len(data)-days_back-1):\n        X.append(np.array(data[i:(i+days_back)][['close','open','high','low','volume']]))\n        Y.append(np.array(data.iloc[(i+days_back)][['close']]).astype('float32'))\n    X, y = shuffle(np.array(X),np.array(Y))\n    return X, y\n\ndays_back = 45\nX,y = process_data(fb_df ,days_back)\nX_train,X_val,X_test = X[:int(X.shape[0]*0.70)], X[int(X.shape[0]*0.70):int(X.shape[0]*0.90)], X[int(X.shape[0]*0.90):]\ny_train,y_val,y_test = y[:int(y.shape[0]*0.70)], y[int(y.shape[0]*0.70):int(y.shape[0]*0.90)], y[int(y.shape[0]*0.90):]\n\nprint(X_train.shape)\nprint(X_train)","f3d30b49":"X_train_tensor = tf.convert_to_tensor(X_train)\ny_train_tensor = tf.convert_to_tensor(y_train)\nX_val_tensor = tf.convert_to_tensor(X_val)\ny_val_tensor = tf.convert_to_tensor(y_val)\nX_test_tensor = tf.convert_to_tensor(X_test)\ny_test_tensor = tf.convert_to_tensor(y_test)","548e8fcf":"class RNN:\n    \n    # Initialization of our class\n    def __init__(self, NUM_INPUTS, NUM_OUTPUTS, SEQ_LENGTH, TYPE_RNN):\n        self.NUM_INPUTS = NUM_INPUTS\n        self.NUM_OUTPUTS = NUM_OUTPUTS\n        self.SEQ_LENGTH = SEQ_LENGTH\n        self.TYPE_RNN = TYPE_RNN\n        self.MODEL = self.create_model()\n        \n    def create_model(self):\n        model = tf.keras.Sequential()\n        \n        # Input\n        model.add(layer=tf.keras.Input(shape=(self.SEQ_LENGTH,self.NUM_INPUTS)))\n        \n        # RNN Layer\n        if (self.TYPE_RNN == 'RNN'):  \n            model.add(layer=tf.keras.layers.SimpleRNN(256))\n            \n        elif (self.TYPE_RNN == 'LSTM'):\n            model.add(layer=tf.keras.layers.LSTM(256))\n            \n        elif (self.TYPE_RNN == 'GRU'):\n            model.add(layer=tf.keras.layers.GRU(256))\n        \n        # Output to one value\n        model.add(layer=tf.keras.layers.Dense(self.NUM_OUTPUTS))\n        model.compile(optimizer='adam', loss='mse')\n        \n        return model\n    \n    \n    def train_model(self, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor):\n        self.MODEL.fit(X_train_tensor,y_train_tensor,epochs=50,validation_data=(X_val_tensor,y_val_tensor))\n        \nnum_inputs=5\nnum_outputs=1\nseq_length=days_back","9a0a4b4c":"RNN_lstm = RNN(num_inputs, num_outputs, seq_length, 'LSTM')\nRNN_lstm.train_model(X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)  ","db55671f":"RNN_rnn = RNN(num_inputs, num_outputs, seq_length, 'RNN')\nRNN_rnn.train_model(X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)  ","86eb5e53":"RNN_gru = RNN(num_inputs, num_outputs, seq_length, 'GRU')\nRNN_gru.train_model(X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)  ","b29c52bc":"fig = plt.figure(figsize=(10,8))\nplt.title('Testing Accuracy')\n\nplt.bar(x='LSTM', height=RNN_lstm.MODEL.evaluate(X_test_tensor, y_test_tensor))\nplt.bar(x='RNN', height=RNN_rnn.MODEL.evaluate(X_test_tensor, y_test_tensor))\nplt.bar(x='GRU', height=RNN_gru.MODEL.evaluate(X_test_tensor, y_test_tensor))","feb416c8":"fig = plt.figure(figsize=(16,8))\ni = np.random.randint(30)\nlstm_pred = RNN_lstm.MODEL(tf.reshape(X_test[i], shape=(1,days_back,5)))\nrnn_pred = RNN_rnn.MODEL(tf.reshape(X_test[i], shape=(1,days_back,5)))\ngru_pred = RNN_gru.MODEL(tf.reshape(X_test[i], shape=(1,days_back,5)))\n                         \nplt.plot(price_scaler.inverse_transform(np.reshape(X_test[i,:,0], newshape=(-1,1))), label='Previous {} days'.format(days_back))\nplt.scatter(x=days_back, y=price_scaler.inverse_transform(np.reshape(lstm_pred, newshape=(1,1))), label='LSTM', marker='.')\nplt.scatter(x=days_back, y=price_scaler.inverse_transform(np.reshape(rnn_pred, newshape=(1,1))), label='RNN', marker='s')\nplt.scatter(x=days_back, y=price_scaler.inverse_transform(np.reshape(gru_pred, newshape=(1,1))), label='GRU', marker ='o')\nplt.scatter(x=days_back, y=price_scaler.inverse_transform(np.reshape(y_test[i], newshape=(1,1))), label='True', marker='x')\nplt.legend()","ae203ded":"1. Understand our data\n\nHere we will attempt to predict the closing price of the next day given: open, high, low, close, volume (of previous 7-day window).","574fb74d":"Find testing accuracy","4186b5d9":"2. Design our Neural Network","2f4db58d":"### Let's train a model using the Recurrent Neural Network architecture to predict future close\/open prices!\n\n#### Process of training an RNN\n1. Understand our data\n    * What are we trying to predict\n    * What data will we use to predict it\n2. Prepare data for model \n    * Make sure the dimensions are correct, and turn dataframes into tensors   \n3. Design our Neural Network\n    * We will be using variations of RNN layers\n4. Train our neural network\n5. Validate its accuracy"}}