{"cell_type":{"c633ed3d":"code","87cc8c2b":"code","dfeda98c":"code","74459714":"code","485f2b9d":"code","8571e455":"code","9250ff37":"code","436cccab":"code","df576e35":"code","6499175b":"code","1e7a31f2":"code","5e54f5c6":"code","67ef0fcd":"code","e92ba1bf":"code","503e0ece":"code","f7da5c00":"code","d0b65e28":"code","d2215af7":"code","f67e4ac6":"code","726ab57b":"code","9032a54b":"code","e357e73c":"code","d45339c0":"code","96b9d6f6":"code","f60c6864":"code","9b5576de":"code","44586622":"code","6f94f934":"markdown"},"source":{"c633ed3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87cc8c2b":"import matplotlib.pyplot as plt","dfeda98c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report","74459714":"data = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\nprint(data.info())","485f2b9d":"data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1,1))\nprint(data.info())","8571e455":"data = data.drop(['Time', 'Amount'], axis = 1)\nprint(data.info())","9250ff37":"data['Class'].value_counts()","436cccab":"from sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_multilabel_classification","df576e35":"X=np.array(data.drop(['Class'],1))\ny=np.array(data['Class'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","6499175b":"lr = LogisticRegression()","1e7a31f2":"lr.fit(X_train, y_train.ravel())","5e54f5c6":"predictions = lr.predict(X_test)","67ef0fcd":"print(classification_report(y_test, predictions))","e92ba1bf":"print(\"Before Oversampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))","503e0ece":"from imblearn.over_sampling import SMOTE","f7da5c00":"sm = SMOTE(random_state = 2)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())","d0b65e28":"print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))","d2215af7":"print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))","f67e4ac6":"lr1 = LogisticRegression()\nlr1.fit(X_train_res, y_train_res.ravel())\npredictions = lr1.predict(X_test)","726ab57b":"print(classification_report(y_test, predictions))","9032a54b":"from imblearn.under_sampling import NearMiss\nnr = NearMiss()","e357e73c":"print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))","d45339c0":"X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel())","96b9d6f6":"print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape))\nprint('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape))","f60c6864":"print(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1)))\nprint(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0)))","9b5576de":"lr2 = LogisticRegression()\nlr2.fit(X_train_miss, y_train_miss.ravel())\npredictions = lr2.predict(X_test)","44586622":"print(classification_report(y_test, predictions))","6f94f934":"- According to the SMOTE method, the recall value of minority class is 0.92 and that of majority class is 0.98.\n- According to NearMiss method, the recall value of minority class is 0.95 and that of majority class is 0.55.\n\nThus, here we choose the SMOTE model."}}