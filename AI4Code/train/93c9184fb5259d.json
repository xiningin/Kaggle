{"cell_type":{"78d111e4":"code","ba46ffcc":"code","45571a7d":"code","685b0fe7":"code","1d6d8ee3":"code","808596b1":"code","4708ae79":"code","6675fdcc":"code","9613e1e0":"code","fd21e893":"code","955279f5":"code","95526dbc":"code","c365c788":"code","31d45748":"code","8019d500":"code","9925a2e7":"code","15ca9f3a":"code","80798acb":"code","0023159c":"code","3b99c5b1":"code","c1e3137c":"code","2b2e90a1":"code","de6db55c":"code","e682653a":"code","c250ba35":"code","e6e63a41":"code","8c3932e2":"code","fb509c10":"code","a043cdcc":"code","14bb62ad":"code","6063f900":"code","7440ac85":"code","dbcfcbdf":"code","1cb3bd95":"code","b7deba60":"code","f82f3984":"code","6165a530":"code","0b388338":"markdown","8e06a866":"markdown","0302b378":"markdown","b26b85c9":"markdown","49a98401":"markdown","718d4fb3":"markdown","62200887":"markdown","b071dbcf":"markdown","058e909c":"markdown","dfdc5513":"markdown","39a2eee2":"markdown","89d81778":"markdown","779d29b9":"markdown","ad194170":"markdown","3a5fa037":"markdown","8c3c5f24":"markdown","635c7094":"markdown","ec7d8224":"markdown","90b520c0":"markdown","e58debb5":"markdown","bcc769ce":"markdown","ec541c83":"markdown","e0e7064d":"markdown","7e906194":"markdown","b01681e3":"markdown","9a43a848":"markdown","a03171f2":"markdown","7f6ea4e2":"markdown","5060c0b0":"markdown"},"source":{"78d111e4":"#!pip install pycountry\n#!pip install catboost\n#!pip install xgboost\n#!pip install eli5\n#!pip install category_encoders\n#!pip install scikit-learn","ba46ffcc":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport pycountry as pc\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier \nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n#from pdpbox import pdp\npd.options.display.max_columns = None","45571a7d":"## Data Loading\ndata = pd.read_csv('..\/input\/hotel-booking-demand\/hotel_bookings.csv')","685b0fe7":"## Data Check\ndata.head()","1d6d8ee3":"## Data Copy for Pre-Processing\ndf = data.copy()","808596b1":"## number of null checking\ndf.isnull().sum().sort_values(ascending=False)[:10]","4708ae79":"## if the value of agent, company column is null replace to 0\ndf[['agent','company']] = df[['agent','company']].fillna(0.0)\n\n## if the value of country column is null replace to mode value.\ndf['country'].fillna(data.country.mode().to_string(), inplace=True)","6675fdcc":"## if the value of children column is null replace to 0\ndf['children']=df['children'].fillna(0.0)\n\n## if the sum of adult, baby , child is 0 drop row.\ndf = df.drop(df[(df.adults+df.babies+df.children)==0].index)","9613e1e0":"## transfrom the datatype into int.\ndf[['children', 'company', 'agent']] = df[['children', 'company', 'agent']].astype('int64')","fd21e893":"## The number of total staying night is smaller than 1 drop row.\n## Create New Column.\ndf['total_staying_nights'] = df['stays_in_week_nights'] + df['stays_in_weekend_nights']\n\ndf = df[ df['total_staying_nights'] >= 1 ]\ndf = df.reset_index(drop=True)","955279f5":"## only for adr > 0 \ndf = df[ df['adr'] > 0 ].copy()","95526dbc":"## Data Copy for new columns.\ndf_subset = df.copy()","c365c788":"df_subset = df_subset.drop(['reservation_status'], axis=1)\n\n## Create [Room] column \n## if assigned room is same 1, if not0\ndf_subset['Room'] = 0\ndf_subset.loc[ df_subset['reserved_room_type'] == df_subset['assigned_room_type'] , 'Room'] = 1\n\n## Create [more_canceled] column\n## if the cancellation rate is higher  1, if not 0\ndf_subset['more_canceled'] = 0\ndf_subset.loc[ df_subset['previous_cancellations'] > df_subset['previous_bookings_not_canceled'] , 'not_canceled'] = 1\n\n## Seperate year\/month\/date from reservation_status_date column\ndf_subset['reservation_status_date'] = pd.to_datetime(df_subset['reservation_status_date'])\n\ndf_subset['reservation_year'] = df_subset['reservation_status_date'].dt.year\ndf_subset['reservation_month'] = df_subset['reservation_status_date'].dt.month\ndf_subset['reservation_day'] = df_subset['reservation_status_date'].dt.day\n\n## remove the leftover columns. \ndf_subset = df_subset.drop(['booking_changes','assigned_room_type','reservation_status_date','distribution_channel'],axis=1)","31d45748":"def transform(dataframe):\n\n    ## LabelEncoder import\n    from sklearn.preprocessing import LabelEncoder\n    \n    le = LabelEncoder()\n    categorical_features = list(dataframe.columns[dataframe.dtypes == object])\n    dataframe[categorical_features]=dataframe[categorical_features].apply(lambda x: le.fit_transform(x))\n    return dataframe\n\n\ndf_subset = transform(df_subset)","8019d500":"## Checking the variance\ndf_subset.var()","9925a2e7":"df_subset['lead_time']=np.log(df_subset['lead_time']+1)\ndf_subset['agent'] = np.log(df_subset['agent'] + 1)\ndf_subset['company'] = np.log(df_subset['company'] + 1)\ndf_subset['adr'] = np.log(df_subset['adr'] + 1)\ndf_subset['country'] = np.log(df_subset['country'] + 1)\ndf_subset['days_in_waiting_list'] = np.log(df_subset['days_in_waiting_list'] + 1)\ndf_subset['reservation_month'] = np.log(df_subset['reservation_month'] + 1)\ndf_subset['reservation_day'] = np.log(df_subset['reservation_day'] + 1)\ndf_subset['arrival_date_week_number'] = np.log(df_subset['arrival_date_week_number'] + 1)\ndf_subset['arrival_date_day_of_month'] = np.log(df_subset['arrival_date_day_of_month'] + 1)\ndf_subset['arrival_date_month'] = np.log(df_subset['arrival_date_month'] + 1)\n\ndf_subset = df_subset.drop([])","15ca9f3a":"## Checking the variance \ndf_subset.var()","80798acb":"def data_split(df, label):\n    \n    from sklearn.model_selection import train_test_split\n\n    X = df.drop(label, axis=1)\n    Y = df[label]\n\n    x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.30)\n    \n    return x_train, x_test, y_train, y_test\n\n\nx_train, x_test, y_train, y_test = data_split(df_subset, 'is_canceled')\n\nfrom sklearn.impute import SimpleImputer\n\n## default, imputing 'mean' value\nimputer = SimpleImputer()\n# make X_train for PDP\nX_train = x_train\n# feature list\nfeature_names = x_train.columns\nx_train = imputer.fit_transform(x_train)\nx_test = imputer.transform(x_test)","0023159c":"## decision tree\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(x_train,y_train)","3b99c5b1":"## XGBoost\nxgb = XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 500)\nxgb.fit(x_train, y_train)","c1e3137c":"## Gradient Boosting\ngb = GradientBoostingClassifier()\ngb.fit(x_train, y_train)","2b2e90a1":"## AdaBoost\nada = AdaBoostClassifier(base_estimator = clf)\nada.fit(x_train, y_train)","de6db55c":"## RandomForest\nrd_clf = RandomForestClassifier(n_estimators=300)\nrd_clf.fit(x_train, y_train)    ","e682653a":"## LogisticRegression\n#lr = LogisticRegression()\n#lr.fit(x_train, y_train)","c250ba35":"## CatBoost\ncat = CatBoostClassifier(iterations=300)\ncat.fit(x_train, y_train, verbose = 100)","e6e63a41":"##LGBM\nlgbm = LGBMClassifier(learning_rate = 1)\nlgbm.fit(x_train, y_train)","8c3932e2":"##ExtraTreesClassifier\netc = ExtraTreesClassifier()\netc.fit(x_train, y_train)","fb509c10":"##HistGradientBoostingClasifier\nhgbc = HistGradientBoostingClassifier(random_state=0)\nhgbc.fit(x_train,y_train)","a043cdcc":"models = pd.DataFrame({\n    'Model' : ['Decision Tree Classifier', 'Random Forest Classifier', \n               'XgBoost',  'Cat Boost', 'Gradient Boosting Classifier','Ada Boost Classifier',\"LightGBMClassifier\",\"ExtraTreesClassifier\",\"HistGradientBoostingClassifier\"],\n\n    'Score' : [clf.score(x_test,y_test),rd_clf.score(x_test,y_test), xgb.score(x_test,y_test), cat.score(x_test,y_test) , gb.score(x_test,y_test) , ada.score(x_test,y_test) ,lgbm.score(x_test,y_test),etc.score(x_test,y_test),hgbc.score(x_test,y_test)]\n})\n\nmodels.sort_values(by = 'Score', ascending = False)","14bb62ad":"import plotly.express as px\npx.bar(data_frame = models, x = 'Score', y = 'Model', orientation='h', color = 'Score', template = 'plotly_dark', title = 'Models Comparison')","6063f900":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\ntrain_score = xgb.score(x_train,y_train)\ntest_score = xgb.score(x_test,y_test)\n\ny_pred = xgb.predict(x_test)\ny_pred_proba_test = xgb.predict_proba(x_test)[:,1]\nacc = accuracy_score(y_test, y_pred)\nconf = confusion_matrix(y_test, y_pred)\nfinal_model_report = classification_report(y_test, y_pred)\n\n# ROC curve\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_test)\nroc = pd.DataFrame({\n    'FPR(Fall-out)': fpr, \n    'TPRate(Recall)': tpr, \n    'Threshold': thresholds\n})\n\n# \uc2dc\uac01\ud654\nplt.scatter(fpr, tpr)\nplt.title(\"ROC curve\")\nplt.xlabel(\"FPR(Fall-out)\")\nplt.ylabel(\"TPR(Recall)\");","7440ac85":"# AUC score \uad6c\ud558\uae30\nauc_score = roc_auc_score(y_test, y_pred_proba_test)\nprint('AUC score:', auc_score)","dbcfcbdf":"feature_impt = pd.Series(xgb.feature_importances_, feature_names).sort_values(ascending=False)\n\nprint(feature_impt)\n\n# Visualization \nfeature_impt.sort_values(ascending=True)[-10:].plot.barh();","1cb3bd95":"from sklearn.pipeline import make_pipeline\nfrom category_encoders import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom pdpbox import pdp\n\nmodel = make_pipeline(\n    OrdinalEncoder(), \n    SimpleImputer(),\n    XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 500)\n)\nmodel.fit(x_train,y_train)","b7deba60":"feature = 'deposit_type'\nfeatures = feature_names\npdp_dist = pdp.pdp_isolate(model=model, dataset=X_train, model_features=features, feature=feature)\npdp.pdp_plot(pdp_dist, feature);","f82f3984":"feature = 'required_car_parking_spaces'\npdp_dist = pdp.pdp_isolate(model=model, dataset=X_train, model_features=features, feature=feature, num_grid_points=10000)\npdp.pdp_plot(pdp_dist, feature);","6165a530":"feature = 'previous_cancellations'\npdp_dist = pdp.pdp_isolate(model=model, dataset=X_train, model_features=features, feature=feature, num_grid_points=1000)\npdp.pdp_plot(pdp_dist, feature);","0b388338":"<br\/><\/br>\n\n### 2-4) Encoding the  Categorical variables","8e06a866":"-----------\n## 1. Packages Import\n","0302b378":"#### CatBoost","b26b85c9":"#### deposit_type","49a98401":"\n\n### 3-1) data split","718d4fb3":"<br\/><\/br>\n\n### 2-1) Dealing with Missing Value.","62200887":"#### Decision Tree","b071dbcf":"<br\/><\/br>\n\n### 2-5) Normalization","058e909c":"#### LGBMClassifier","dfdc5513":"#### required_car_parking_spaces","39a2eee2":"#### RandomForest","89d81778":"<br\/><\/br>\n\n### 2-3) Feature Creation","779d29b9":"#### previous_cancellations","ad194170":"hotel booking demand\n====================\n#### https:\/\/www.kaggle.com\/jessemostipak\/hotel-booking-demand   \n   \n+ Find a problem\n+ Analyze previous approaches\n+ Modeling your methodolody\n+ Analyzing data\n+ Visualization\n+ Collaborative Evaluation  \n<br\/>\n\n\n\n<\/br>\n\n-----------------","3a5fa037":"\n### 3-5) Feature Importance","8c3c5f24":"<br\/><\/br>\n\n### 3-3) Model Comparison","635c7094":"### 3-6) Top3 Feature PDP","ec7d8224":"<br\/><\/br>\n\n### 2-6) Select the column for normalization","90b520c0":"#### AdaBoost","e58debb5":"#### ExtraTreesClassifier","bcc769ce":"####XGBoost","ec541c83":"#### LogisticRegression","e0e7064d":"<br\/><\/br>\n\n### 3-2) model train\n+ decision tree\n+ XGBoost\n+ Gradient Boosting\n+ AdaBoost\n+ RandomForest\n+ LogisticRegression\n+ CatBoost\n+ LGBMClassifier\n+ ExtraTreesClssifier\n+ HistGradientBoostingClassfier","7e906194":"<br\/><\/br>\n\n\n--------------\n## 3. Modeling","b01681e3":"#### HistGradientBoostingClassfier","9a43a848":"#### Gradient Boosting","a03171f2":"<br\/><\/br>\n\n### 3-4) ROC Curve","7f6ea4e2":"<br\/><\/br>\n\n### 2-2)Removing Outliers.","5060c0b0":"<br\/><\/br>\n\n\n--------------\n## 2. Data Pre-Processing"}}