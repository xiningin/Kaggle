{"cell_type":{"af94695b":"code","96252134":"code","bb3f26fc":"code","e0b1cb70":"code","1d520442":"code","77ce1c6e":"code","5e99bee8":"code","8245b510":"code","bb83d783":"code","8c2b6f21":"code","498397f5":"code","036c0b08":"code","af34a76b":"code","ad9f2122":"code","8af7e683":"code","e36590ac":"code","0ee24b27":"code","691394b0":"code","de109c6c":"code","014ecce6":"code","4ad1f7cb":"code","ae7a908c":"code","6e6fb61f":"code","7509ec0e":"code","46ab669b":"code","3c6ec699":"code","cb7351b4":"code","e6af05e6":"code","157df13b":"code","b144d3c2":"code","fc79da95":"code","eac09dc3":"code","27c1af13":"code","3b978078":"code","a487b1fe":"code","b8deeae2":"code","a7c30e2f":"code","e9d7e148":"code","148d6a36":"code","afa587f4":"code","d11ec535":"code","ebf85148":"code","f25f9e34":"code","ad708074":"code","6fa80cce":"code","4fc8bc7a":"code","fbf26626":"code","a79fee03":"code","7913ee6d":"code","e186f465":"code","78f2f898":"code","a71c409f":"code","d22b4796":"code","9e9a0f8d":"code","0887e7c4":"code","7567de06":"code","76f8cadb":"code","1b4b22c2":"code","1b4910e5":"code","998beac7":"code","dd05d774":"code","b300206a":"code","a4573d31":"code","3ef359ff":"code","355a4a81":"code","439baec5":"code","296009e0":"code","0f7be515":"code","4142ab22":"code","e3d2db84":"markdown","e643b153":"markdown","d9b10e8b":"markdown","bb6f6f97":"markdown","037202e0":"markdown","cb96c777":"markdown","ca10a91b":"markdown","8b9d2920":"markdown","9be28641":"markdown","163b7bb9":"markdown","79a86483":"markdown","198d0811":"markdown","8e2bc689":"markdown","e676029c":"markdown","06185d14":"markdown","6008ce9d":"markdown","c3caeb21":"markdown","b8ef5ea5":"markdown","23feae88":"markdown","7e4d7071":"markdown","1b38d908":"markdown","c84acd5b":"markdown","922f16c2":"markdown","855df694":"markdown","8b5259a0":"markdown","169071c7":"markdown","81f012c8":"markdown","e77f688e":"markdown","8bc58637":"markdown","9ee29723":"markdown","3e96ba98":"markdown","92e26c56":"markdown","92d506b3":"markdown","295f02f9":"markdown","bee4683c":"markdown","c01f9982":"markdown","e07687e5":"markdown","21c7db28":"markdown"},"source":{"af94695b":"# \u00d6ncelikle k\u00fct\u00fcphanelerimizi \u00e7a\u011f\u0131r\u0131yoruz.\nimport pandas as pd # Verimizi okumak ve grupland\u0131rmak i\u00e7in: pandas\nimport numpy as np  # Verimiz \u00fczerinde say\u0131sal i\u015flemler yapmak i\u00e7in: numpy\n# Verimizi g\u00f6rselle\u015ftirmek i\u00e7in: matplot ve seaborn\nimport matplotlib.pyplot as plt \nimport seaborn as sns","96252134":"# Kullanaca\u011f\u0131m\u0131z verimizi okuyoruz.\ndf = pd.read_csv(\"..\/input\/who_suicide_statistics.csv\")","bb3f26fc":"# Veri setimizin ilk 10 de\u011ferini inceliyoruz\ndf.head(10)","e0b1cb70":"# Veri setimizin son 5 de\u011ferini inceliyoruz\ndf.tail()","1d520442":"# Veri setimizin sat\u0131r say\u0131s\u0131na ve \u00f6z nitelik adedine bak\u0131yoruz.\ndf.shape","77ce1c6e":"# Kolonlar\u0131m\u0131z\u0131 ve veri tiplerimizi g\u00f6zlemliyoruz.\ndf.info()","5e99bee8":"# Say\u0131sal de\u011ferlerimize bak\u0131yoruz.\ndf.describe() ","8245b510":"# Verimizin korelasyon durumunu g\u00f6zlemliyoruz. \nsns.heatmap(df.corr())","bb83d783":"# Verimizdeki toplam bo\u015f de\u011fer say\u0131s\u0131n\u0131 kontrol ediyoruz.\ndf.isnull().sum()","8c2b6f21":"# Pop\u00fclasyon kolonumuzu kald\u0131r\u0131yoruz. Gerekti\u011fi g\u00f6rselle\u015ftirme k\u0131s\u0131mlar\u0131nda geri \u00e7a\u011f\u0131raca\u011f\u0131z.\ndf.drop([\"population\"], axis=1, inplace=True)","498397f5":"# Herhangi bir \u00f6zniteli\u011fi bo\u015f olan verileri temizliyoruz\ndf = df.dropna(axis=0, how=\"any\")","036c0b08":"# Bo\u015f de\u011ferlerimizin kal\u0131p kalmad\u0131\u011f\u0131n\u0131 g\u00f6zlemleyelim\ndf.isnull().sum()","af34a76b":"# Kullanaca\u011f\u0131m\u0131z kolonlar\u0131 ay\u0131r\u0131yoruz.\nyears = df.iloc[:, 1].values.reshape(-1,1)\nsuicides = df.iloc[:, 4].values.reshape(-1,1)","ad9f2122":"# Histogram (frekans grafi\u011fi) ile intihar olay\u0131n\u0131n en \u00e7ok tekrar etti\u011fi y\u0131llar\u0131 g\u00f6rebiliriz.\nplt.figure(figsize=(20,10))\nplt.hist(years, bins=50)\nplt.xlabel(\"Y\u0131llar\")\nplt.ylabel(\"\u0130ntihar S\u0131kl\u0131\u011f\u0131\")","8af7e683":"# B\u00fct\u00fcn \u00fclkeleri intihar say\u0131lar\u0131na g\u00f6re grupland\u0131r\u0131yoruz ve dataframe'imizi d\u00fczenliyoruz\ncountry_suicides = pd.DataFrame(df.groupby(\"country\")[\"suicides_no\"].sum())\ncountry_suicides['country'] = country_suicides.index\ncountry_suicides = country_suicides.reset_index(drop = True)\n\ncountry_suicides.head()","e36590ac":"# \u00dclkeleri intihar say\u0131lar\u0131na g\u00f6re d\u00fczenleyip en \u00e7ok ilk 50 \u00fclkemizi ay\u0131r\u0131yoruz\nsorted_data = country_suicides.sort_values(\"suicides_no\", ascending=False)\nsorted_data = sorted_data.iloc[:50,:]","0ee24b27":"# G\u00f6rselimizi olu\u015fturuyoruz\nplt.figure(figsize=(20,10))\nsns.barplot(x=sorted_data.country, y=sorted_data.suicides_no)\nplt.xticks(rotation= 90)\nplt.xlabel('\u00dclkeler')\nplt.ylabel('Toplam \u0130ntihar Say\u0131s\u0131')\nplt.title('\u0130NT\u0130HARLAR')","691394b0":"# \u00dclkeleri isim olarak ay\u0131r\u0131yoruz\nunique = pd.DataFrame(df.country.unique(), columns = [\"countries\"])\nunique.sample(10)","de109c6c":"# Toplayaca\u011f\u0131m\u0131z verileri saklayaca\u011f\u0131m\u0131z veri tablosunu olu\u015fturuyoruz.\nsuicides_by_gender = pd.DataFrame(columns=['country', # \u00fclke\n                                           'total s', # total suicide:  toplam intihar say\u0131s\u0131\n                                           'per f',   # percent female: kad\u0131n intiharlar\u0131 y\u00fczdesi\n                                           'per m',]) # percent male:   erkek intiharlar\u0131 y\u00fczdesi","014ecce6":"for index, rows in unique.iterrows():\n   test_df = df[df[\"country\"] == rows[\"countries\"]]\n   suicides_by_gender = suicides_by_gender.append({'country': rows[\"countries\"],\n        'total s' : df[df[\"country\"] == rows[\"countries\"]].suicides_no.sum(),\n        'per f': test_df[test_df[\"sex\"] == \"female\"].suicides_no.sum()\/df[df[\"country\"] == rows[\"countries\"]].suicides_no.sum()*100,\n        'per m': test_df[test_df[\"sex\"] == \"male\"].suicides_no.sum()\/df[df[\"country\"] == rows[\"countries\"]].suicides_no.sum()*100}, ignore_index=True)","4ad1f7cb":"# Verimizdeki intihar say\u0131s\u0131 baz al\u0131narak ayk\u0131r\u0131 verileri temizliyoruz.\nP = np.percentile(suicides_by_gender['total s'], [10, 100])\nsuicides_by_gender = suicides_by_gender[(suicides_by_gender['total s'] > P[0]) & (suicides_by_gender['total s'] <= P[1])]","ae7a908c":"# Olu\u015fan veri tablomuzu inceleyelim\nsuicides_by_gender.head()","6e6fb61f":"# Verimizi kad\u0131n intiharlar\u0131 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_gender = suicides_by_gender.sort_values(\"per f\", ascending=False)\nsuicides_by_gender.head(10)","7509ec0e":"# Verimizi erkek intihar y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_gender = suicides_by_gender.sort_values(\"per m\", ascending=False)\nsuicides_by_gender.head(10)","46ab669b":"# \u00dclke isimlerini \"unique\" i\u00e7erisinde daha \u00f6nceden kaydetmi\u015ftik.\n# Toplayaca\u011f\u0131m\u0131z verileri saklayaca\u011f\u0131m\u0131z veri tablosunu olu\u015fturuyoruz.\nsuicides_by_age = pd.DataFrame(columns=[\n    'country',   # \u00fclke\n    'total s',   # total suicide: toplam intihar say\u0131s\u0131\n    'per 5-14',  # 5 ve 14 ya\u015f aras\u0131 kad\u0131n ve erkeklerin toplam y\u00fczdesi\n    'per 15-24', # 15 ve 24 ya\u015f aras\u0131 kad\u0131n ve erkeklerin toplam y\u00fczdesi\n    'per 25-34', # 25 ve 34 ya\u015f aras\u0131 kad\u0131n ve erkeklerin toplam y\u00fczdesi\n    'per 35-54', # 35 ve 54 ya\u015f aras\u0131 kad\u0131n ve erkeklerin toplam y\u00fczdesi\n    'per 55-74', # 55 ve 74 ya\u015f aras\u0131 kad\u0131n ve erkeklerin toplam y\u00fczdesi\n    'per 75+'])  # 75 ya\u015f ve \u00fczeri kad\u0131n ve erkeklerin toplam y\u00fczdesi","3c6ec699":"# D\u00f6ng\u00fcm\u00fczle ana veri tablomuzdan e\u015fle\u015fen \u00fclkelerin ya\u015f aral\u0131klar\u0131ndaki intiharlar d\u00fczenleniyor.\nfor index, rows in unique.iterrows():\n   test_df = df[df[\"country\"] == rows[\"countries\"]]\n   s = df[df[\"country\"] == rows[\"countries\"]].suicides_no.sum()\n   suicides_by_age = suicides_by_age.append({'country': rows[\"countries\"],\n        'total s': df[df[\"country\"] == rows[\"countries\"]].suicides_no.sum(),\n        'per 5-14': test_df[test_df[\"age\"] == \"5-14 years\"].suicides_no.sum()\/s *100, \n        'per 15-24': test_df[test_df[\"age\"] == \"15-24 years\"].suicides_no.sum()\/s*100, \n        'per 25-34': test_df[test_df[\"age\"] == \"25-34 years\"].suicides_no.sum()\/s*100, \n        'per 35-54': test_df[test_df[\"age\"] == \"35-54 years\"].suicides_no.sum()\/s*100, \n        'per 55-74': test_df[test_df[\"age\"] == \"55-74 years\"].suicides_no.sum()\/s*100,\n        'per 75+': test_df[test_df[\"age\"] == \"75+ years\"].suicides_no.sum()\/s*100}, ignore_index=True)","cb7351b4":"# Verimizdeki intihar say\u0131s\u0131n\u0131 g\u00f6z \u00f6n\u00fcnde bulundurarak ayk\u0131r\u0131 verileri temizliyoruz.\nP = np.percentile(suicides_by_age['total s'], [10, 100])\nsuicides_by_age = suicides_by_age[(suicides_by_age['total s'] > P[0]) & (suicides_by_age['total s'] <= P[1])]","e6af05e6":"# Olu\u015fan veri tablomuzu inceleyelim\nsuicides_by_age.head()","157df13b":"# Verimizi 5-14 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 5-14\", ascending=False)\nsuicides_by_age.head(10)","b144d3c2":"# Verimizi 15-24 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 15-24\", ascending=False)\nsuicides_by_age.head(10)\n","fc79da95":"# Verimizi 25-34 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 25-34\", ascending=False)\nsuicides_by_age.head(10)","eac09dc3":"# Verimizi 35-54 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 35-54\", ascending=False)\nsuicides_by_age.head(10)","27c1af13":"# Verimizi 55-74 y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 55-74\", ascending=False)\nsuicides_by_age.head(10)","3b978078":"# Verimizi 75+ y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_age = suicides_by_age.sort_values(\"per 75+\", ascending=False)\nsuicides_by_age.head(10)","a487b1fe":"df2 = pd.read_csv(\"..\/input\/who_suicide_statistics.csv\")\ndf2 = df2.dropna(axis=0, how=\"any\")\ndf2.isnull().sum()","b8deeae2":"unique = pd.DataFrame(df2.country.unique(), columns = [\"countries\"])\nunique.sample(10)","a7c30e2f":"# Toplayaca\u011f\u0131m\u0131z verileri saklayaca\u011f\u0131m\u0131z veri tablosunu olu\u015fturuyoruz.\nsuicides_by_pop = pd.DataFrame(columns=['country', \n                                           'total s', \n                                           'mean pop',\n                                           'per s'])","e9d7e148":"# Her bir \u00fclkeyi gezip intiharlar\u0131n toplam\u0131n\u0131 pop\u00fclasyonun ortalamas\u0131n\u0131 al\u0131yor, olu\u015fturdu\u011fumuz dataframe'e ekliyoruz.\nfor index, rows in unique.iterrows():\n   test_df = df2[df2[\"country\"] == rows[\"countries\"]]\n   suicides_by_pop = suicides_by_pop.append({\n        'country': rows[\"countries\"],\n        'total s' : test_df.suicides_no.sum(),\n        'mean pop': test_df.population.mean(),\n        'per s': test_df.suicides_no.sum()\/test_df.population.mean()*100}, \n            ignore_index=True)","148d6a36":"# Ayk\u0131r\u0131 verileri temizliyoruz.\nP = np.percentile(suicides_by_pop['per s'], [10, 100])\nsuicides_by_pop = suicides_by_pop[(suicides_by_pop['per s'] > P[0]) & (suicides_by_pop['per s'] <= P[1])]","afa587f4":"# Olu\u015fan veri tablomuzu inceleyelim\nsuicides_by_pop.head()","d11ec535":"# Verimizi intihar\/pop\u00fclasyon oran y\u00fczdesine g\u00f6re s\u0131ralayal\u0131m.\nsuicides_by_pop = suicides_by_pop.sort_values(\"per s\", ascending=False)\nsuicides_by_pop.head(10)","ebf85148":"# Regresyon modellerimizin ba\u015far\u0131s\u0131n\u0131 \u00f6l\u00e7mek i\u00e7in r2 score fonksiyonunu kullanaca\u011f\u0131z.\n# De\u011fer ne kadar 1'e yak\u0131nsa o kadar iyi sonu\u00e7 al\u0131nm\u0131\u015ft\u0131r demektir.\nfrom sklearn.metrics import r2_score","f25f9e34":"# Y\u0131llara g\u00f6re intihar say\u0131lar\u0131n\u0131n toplam\u0131n\u0131 grupluyoruz.\nanalyze_df = pd.DataFrame(df.groupby(\"year\")[\"suicides_no\"].sum())","ad708074":"analyze_df.head()","6fa80cce":"analyze_df.tail()","4fc8bc7a":"# Girdi de\u011ferlerine y\u0131llar\u0131, \u00e7\u0131kt\u0131 de\u011ferlerine intiharlar\u0131 at\u0131yoruz. \nx = pd.DataFrame(analyze_df.index)\ny = analyze_df.iloc[:, 0]\n\n# 2016 y\u0131l\u0131n\u0131 ve intihar de\u011ferini temizliyoruz.\nx = x.iloc[:-1, :].values.reshape(-1,1)\ny = analyze_df.iloc[:-1, 0].values.reshape(-1,1)","fbf26626":"# Gerekli k\u00fct\u00fcphaneleri \u00e7a\u011f\u0131r\u0131yoruz.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Modellerimizi olu\u015fturuyoruz.\nlr = LinearRegression()\n\n# 4. dereceden bir fonksiyon kullanaca\u011f\u0131z.\npf = PolynomialFeatures(degree=4)","a79fee03":"# \u00d6ncelikle girdi de\u011ferlerimizi polinomal forma \u00e7eviriyoruz. \u00c7\u00fcnk\u00fc polinomal bir fonksiyon olu\u015fturduysak o dereceden girdiler sa\u011flamal\u0131y\u0131z.\nx_pol = pf.fit_transform(x)","7913ee6d":"# Modelimizi e\u011fitiyoruz\nlr.fit(x_pol, y)","e186f465":"# Modelimizi e\u011fittik, \u015fimdi ise test edece\u011fiz. \u00d6ncelikle test datam\u0131z\u0131 polinomal hale getiriyoruz.\nx_pol2 = pf.fit_transform(x)","78f2f898":"# \u00c7evirdi\u011fimiz test verisini modele g\u00f6nderip tahmin edilen de\u011ferlerimizi g\u00f6rece\u011fiz.\ny_pred = lr.predict(x_pol2)","a71c409f":"# Orijinal de\u011ferler ile fonksiyonumuzun t\u00fcretti\u011fi verileri k\u0131yaslamak i\u00e7in g\u00f6rselle\u015ftirelim.\nplt.figure(figsize=(20,10))\nplt.scatter(x, y)\nplt.plot(x, y_pred, color=\"red\")\nplt.xlabel(\"Y\u0131llar\")\nplt.ylabel(\"\u0130ntihar Say\u0131lar\u0131\")","d22b4796":"# Regresyon score de\u011ferini g\u00f6zlemleyelim\nr2_score(y, y_pred)","9e9a0f8d":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","0887e7c4":"# Kullanaca\u011f\u0131m\u0131z modellerde girdi de\u011ferlerimize normalizasyon uygulamal\u0131y\u0131z. Bunun i\u00e7in gerekli k\u00fct\u00fcphaneleri \u00e7a\u011f\u0131r\u0131yoruz.\nfrom sklearn.preprocessing import StandardScaler\n# Girdi \u00e7\u0131kt\u0131 de\u011ferleri i\u00e7in ayr\u0131 birer scale modeli \u00fcretmeliyiz, \u00e7a\u011f\u0131r\u0131lan her model ancak normalize etti\u011fi veri \u00f6l\u00e7\u00fct\u00fcn\u00fc de-normalize edebilir.\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nx_train = sc_x.fit_transform(x_train)\ny_train = sc_y.fit_transform(y_train)\n\n# Test edece\u011fimiz girdi de\u011ferlerini de normalize etmeliyiz.\nx_test = sc_x.transform(x_test)","7567de06":"# SVR i\u00e7in gerekli k\u00fct\u00fcphanemizi \u00e7a\u011f\u0131r\u0131yoruz\nfrom sklearn.svm import SVR","76f8cadb":"# rbf\nmodel = SVR(kernel=\"rbf\")\nmodel.fit(x_train, y_train)\ny_pred_rbf = model.predict(x_test)\n# Normalize ederek e\u011fitti\u011fimiz veriler bize normalize edilmi\u015f bir halde d\u00f6necektir. \n# Ger\u00e7ek de\u011ferlerini g\u00f6rmek i\u00e7in de-normalize (inverse transform) etmemiz gerekmekte.\ny_pred_rbf = sc_y.inverse_transform(y_pred_rbf)","1b4b22c2":"# linear\nmodel = SVR(kernel=\"linear\")\nmodel.fit(x_train, y_train)\ny_pred_linear =  sc_y.inverse_transform(model.predict(x_test))","1b4910e5":"# poly\nmodel = SVR(kernel=\"poly\")\nmodel.fit(x_train, y_train)\ny_pred_poly =  sc_y.inverse_transform(model.predict(x_test))","998beac7":"# sigmoid\nmodel = SVR(kernel=\"sigmoid\")\nmodel.fit(x_train, y_train)\ny_pred_sgm =  sc_y.inverse_transform(model.predict(x_test))","dd05d774":"print(r2_score(y_test, y_pred_rbf))\nprint(r2_score(y_test, y_pred_linear))\nprint(r2_score(y_test, y_pred_poly)) \nprint(r2_score(y_test, y_pred_sgm)) ","b300206a":"from sklearn.tree import DecisionTreeRegressor\n# A\u011fac\u0131m\u0131z\u0131n derinli\u011fini 100 birim belirledik.\nmodel = DecisionTreeRegressor(max_depth = 100, random_state=0)\nmodel.fit(x_train, y_train)\ny_pred = sc_y.inverse_transform(model.predict(x_test))","a4573d31":"# Model score'umuzu kontrol ediyoruz.\nr2_score(y_test, y_pred)","3ef359ff":"score=[]\nfor i in range(1, 15):\n    model = DecisionTreeRegressor(max_depth = i, random_state=0)\n    model.fit(x_train, y_train)\n    y_pred = sc_y.inverse_transform(model.predict(x_test))\n    score.append(r2_score(y_test, y_pred))","355a4a81":"# Score \u00e7\u0131kt\u0131lar\u0131m\u0131z\u0131 grafik \u00fczerinde inceleyelim\nplt.figure(figsize=(20,10))\nplt.plot(range(1,15), score)\nplt.xlabel(\"Derinlik\")\nplt.ylabel(\"R2 Score\")","439baec5":"from sklearn.ensemble import RandomForestRegressor\n\n# Desicion Tree y\u00f6ntemimizde oldu\u011fu gibi en uygun dallanma say\u0131s\u0131n\u0131 g\u00f6rmek i\u00e7in d\u00f6ng\u00fc kural\u0131m.\nscore = []\nfor i in range(1, 50):\n    model = RandomForestRegressor(n_estimators = i, random_state = 0)\n    model.fit(x_train, y_train)    \n    y_pred = sc_y.inverse_transform(model.predict(x_test))    \n    score.append(r2_score(y_test, y_pred))","296009e0":"# Score \u00e7\u0131kt\u0131lar\u0131m\u0131z\u0131 grafik \u00fczerinde inceleyelim\nplt.figure(figsize=(20,10))\nplt.plot(range(1, 50), score)\nplt.xlabel(\"Dallanma Say\u0131s\u0131\")\nplt.ylabel(\"R2 Score\")\nplt.show()","0f7be515":"from sklearn.neighbors import KNeighborsRegressor\n\n# Kom\u015fu say\u0131m\u0131z\u0131 bir d\u00f6ng\u00fc ile belirleyip score de\u011ferini grafik \u00fczerinde g\u00f6zlemleyebiliriz\nscore = []\nfor i in range(1, 27):\n    model = KNeighborsRegressor(n_neighbors = i) # n_neighbors = k\n    model.fit(x_train,y_train)\n    y_pred = sc_y.inverse_transform(model.predict(x_test))    \n    score.append(r2_score(y_test, y_pred))","4142ab22":"plt.figure(figsize=(20,10))\nplt.plot(range(1, 27), score)\nplt.xlabel(\"Kom\u015fuluk Say\u0131s\u0131\")\nplt.ylabel(\"R2 Score\")","e3d2db84":"**En y\u00fcksek perfonmas\u0131 g\u00f6steren kernel RBF oluyor.**\n<br>**0.8887428684867584**\n","e643b153":"**E\u011fitim ve test verisinde kullanaca\u011f\u0131m\u0131z verilerimizi haz\u0131rl\u0131yoruz.**","d9b10e8b":"* **Y\u0131llara g\u00f6re d\u00fcnyadaki intihar olay s\u0131kl\u0131\u011f\u0131n\u0131 g\u00f6zlemleyelim.**","bb6f6f97":"### E\u011fitim ve test de\u011ferlerimiz haz\u0131r.","037202e0":">  ## **K-NEAREST NEIGHBOR REGRESSION**","cb96c777":"### Regresyon modellerini olu\u015fturmaya haz\u0131r\u0131z.","ca10a91b":"**Elimizdekilere g\u00f6re inceledi\u011fimiz veri setine en uygun regresyon modelimiz 2 kom\u015fuluk de\u011feri ile K-Nearest Neighbor regresyon modeli oluyor.**\n\n*  Linear Reg. : 0.8467048048511636 \n*  Support Vector Reg.: 0.8887428684867584\n*  Desicion Tree Reg.: 0.9200627081915808\n*  Random Forest Reg.: 0.9238047137712131\n*  K-Nearest Neighbor Reg.: **0.9327148635745971**","8b9d2920":"**Uygulayaca\u011f\u0131m\u0131z di\u011fer modellerde datam\u0131z\u0131 train test olarak b\u00f6lebiliriz.**","9be28641":"**\u0130ntihar say\u0131s\u0131n\u0131n en y\u00fcksek oldu\u011fu ba\u015fl\u0131ca \u00fclkelerin Rusya, Amerika, Japonya ve Fransa gibi pop\u00fclasyonun da y\u00fcksek oldu\u011fu \u00fclkeler oldu\u011funu g\u00f6zlemliyoruz. Fakat bu veri intihar\/pop\u00fclasyon oran\u0131ndan ziyade kalabal\u0131k \u00fclkelerin (do\u011fal olarak) intihar say\u0131s\u0131n\u0131n da y\u00fcksek olaca\u011f\u0131ndan dominant bir veri da\u011f\u0131l\u0131m\u0131na sebep olmaktad\u0131r.**\n<br>\n<br>**\u0130lerleyen safhalarda intihar\/pop\u00fclasyon oran\u0131n\u0131 da inceleyece\u011fiz**","163b7bb9":"**G\u00f6zle g\u00f6r\u00fcn\u00fcr oranda 2000'li y\u0131llardan sonra intihar olaylar\u0131n\u0131n s\u0131kla\u015ft\u0131\u011f\u0131n\u0131 s\u00f6yleyebiliriz.**","79a86483":"*(Toplamda 141 \u00fclkemiz mevcut ve bu g\u00f6rselle\u015ftirmek i\u00e7in \u00e7ok fazla)*","198d0811":"Burada yukar\u0131da ay\u0131rd\u0131\u011f\u0131m\u0131z \u00fclke isimlerini bir d\u00f6ng\u00fcde dond\u00fcrecek ve ana veri setimizde e\u015fle\u015fen \u00fclkelerin her intihar say\u0131lar\u0131n\u0131 kad\u0131n erkek olarak ay\u0131racak ve y\u00fczdelerini hesaplayaca\u011f\u0131z.\n","8e2bc689":"* **\u00dclkelerin intihar say\u0131lar\u0131n\u0131 ya\u015f aral\u0131klar\u0131na g\u00f6re grupland\u0131ral\u0131m**","e676029c":"Veri setimizi inceledi\u011fimizde kay\u0131p verilerimizin belirli \u00fclkelere, belirli y\u0131llara g\u00f6re da\u011f\u0131l\u0131ml\u0131 oldu\u011funu g\u00f6r\u00fcyoruz.\n<br>\u00d6rne\u011fin Bolivya ya da Tunus \u00fclkesine ait hi\u00e7 bir pop\u00fclasyon verisi mevcut de\u011fil, haliyle bu verileri elden girmek *(pop\u00fclasyonun ortalama verisini ya da mod verisini girmek)* yan\u0131lt\u0131c\u0131 olacakt\u0131r.\n<br>Ayn\u0131 \u015fekilde intihar say\u0131s\u0131 niteli\u011fi \u00e7o\u011funlukla y\u0131llara g\u00f6re gruplanm\u0131\u015f durumda. \u00d6rne\u011fin Uruguay'\u0131n 1979 y\u0131l\u0131na, Ukrayna'n\u0131n 1983 y\u0131l\u0131na, Arnavutluk'un 1985-86, 1990-91 ve 2011-15 y\u0131llar\u0131 aras\u0131na ait intihar verileri kay\u0131p durumda. Bundan \u00f6t\u00fcr\u00fc di\u011fer y\u0131llara ait intihar verilerini girmek de veri b\u00fct\u00fcnl\u00fc\u011f\u00fcn\u00fc bozacakt\u0131r. \n <br>**Sonu\u00e7 itibariyle kay\u0131p verileri toptan temizlemek toplam veri adedine k\u0131yasla \u00e7ok b\u00fcy\u00fck bir kay\u0131p olmayaca\u011f\u0131ndan en mant\u0131kl\u0131 \u00e7\u00f6z\u00fcm olacakt\u0131r.**\n\n\u015eu anl\u0131k yapaca\u011f\u0131m\u0131z g\u00f6rselle\u015ftirmelerde pop\u00fclasyon kolonunu dahil etmeyece\u011fiz ve pop\u00fclasyonun kay\u0131p veri say\u0131s\u0131 5460 iken intihar say\u0131s\u0131 kolonunun kay\u0131p veri say\u0131s\u0131 2256.\n<br>Haliyle \u00f6ncelikle pop\u00fclasyon kolonunu \u00e7\u0131kart\u0131p daha sonra kay\u0131p veri temizli\u011fi yaparsak \u00e7ok daha az verimiz silinecektir.\n","06185d14":" \u0130lk olarak **Polynomial Linear Regression** modelini uygulayaca\u011f\u0131z.\n <br>Bu modelde olu\u015fturulacak fonksiyonu g\u00f6rselle\u015ftirmek i\u00e7in datay\u0131 train-test olarak b\u00f6lmeyece\u011fiz.\n<br>** (B\u00f6ld\u00fc\u011f\u00fcm\u00fcz taktirde fonksiyon e\u011frisini \u00e7izemeyecektir.)**","6008ce9d":"Bu b\u00f6l\u00fcm\u00fcm\u00fczde regresyon modelleri olu\u015fturarak veri setimizde e\u011fitimler uygulayacak ve belirledi\u011fimiz \u00f6z niteliklere g\u00f6re en iyi sonucu veren regresyon modelini saptayaca\u011f\u0131z.","c3caeb21":"**\u00c7\u0131kt\u0131 de\u011ferlerini g\u00f6zlemliyoruz.**","b8ef5ea5":">  ## **DESICION TREE REGRESSION**","23feae88":"**Verimizin korelasyon durumundan \u015fu an ki haliyle fikir edinemiyoruz. \u00c7\u00fcnk\u00fc say\u0131sal kolonlar iki adet ve net bir bilgi d\u00f6nd\u00fcrmemekte.**\n","7e4d7071":">  ## **SUPPORT VECTOR REGRESSION**","1b38d908":">  ## **LINEAR REGRESSION**","c84acd5b":"**Fakat veri setimiz \u00e7ok b\u00fcy\u00fck de\u011fil ve 100'den \u00e7ok daha az bir de\u011fer de belki \u00e7ok daha fazla perfonmans g\u00f6sterebilir.\n<br>Hangi de\u011ferin daha uygun oldu\u011funu bulmak i\u00e7in farkl\u0131 bir y\u00f6ntem deneyelim.**\n<br><br>**D\u00f6ng\u00fcm\u00fcz a\u011fa\u00e7 derinli\u011fimizi 1'den 15'e kadar indirecek ve r2 score de\u011feri score listemize eklenecek, b\u00f6ylelikle en uygun de\u011feri saptayabilece\u011fiz.**\n","922f16c2":"> # **VER\u0130 MODEL\u0130 \u0130\u015eLEME**","855df694":"* **\u00dclkelerin toplam intihar say\u0131s\u0131n\u0131 ve kad\u0131n erkek y\u00fczdesini hesaplayal\u0131m**","8b5259a0":"> # **VER\u0130 G\u00d6RSELLE\u015eT\u0130RME**","169071c7":"> # **VER\u0130 \u00d6N \u0130\u015eLEME**","81f012c8":">  ## **RANDOM FOREST REGRESSION**","e77f688e":"Deneyece\u011fimiz modellerin y\u0131llara g\u00f6re intihar say\u0131s\u0131n\u0131 tahmin etmesini bekleyece\u011fiz.\n\n* Linear Regression\n* Support Vector Regression\n* Desicion Tree Regression\n* Random Forest Regression\n* K-Nearest Neighbor Regression","8bc58637":"**SVR modeli i\u00e7in bir \u00e7ok kernel se\u00e7ene\u011fimiz mevcut. S\u0131ras\u0131yla 'rbf', 'linear', 'poly' ve 'sigmoid' kernellerini deneyip, r2_score de\u011ferlerini g\u00f6zlemleyece\u011fiz.\n**","9ee29723":"* **\u00dclkelerin toplam intihar say\u0131lar\u0131n\u0131 g\u00f6zlemleyelim.**","3e96ba98":"***\u00dclke isimlerini \"unique\" i\u00e7erisinde daha \u00f6nceden kaydetmi\u015ftik fakat veri setimizden \u00f6nceki veri setine k\u0131yasla daha farkl\u0131 ve daha fazla veri sildik. Bundan \u00f6t\u00fcr\u00fc tekrar \u00fclke isimlerini \u00e7ekmemiz gerek***","92e26c56":"*  **\u00dclkelerin intihar \/ pop\u00fclasyon oranlar\u0131n\u0131 hesaplayal\u0131m.**\n<br>\n <br>**Bunun i\u00e7in \u00fclkelerin toplam intihar say\u0131s\u0131n\u0131 pop\u00fclasyonlar\u0131n\u0131n ortalamas\u0131na b\u00f6l\u00fcp y\u00fczdesini hesaplayaca\u011f\u0131z.**\n <br>(*\u00d6nceki verimizde veri kayb\u0131n\u0131n y\u00fcksek olmamas\u0131 i\u00e7in pop\u00fclasyon \u00f6z niteli\u011fini \u00e7\u0131kartm\u0131\u015ft\u0131k. Tekrar \u00e7a\u011f\u0131r\u0131p eksik verilerimizi temizliyoruz.*)\n","92d506b3":"**Grafi\u011fimizden de g\u00f6r\u00fclece\u011fi \u00fczere en uygun dallanma seviyesi 12 ve r2_score de\u011feri; <br> 0.9238047137712131**\n","295f02f9":"**Verileri inceledi\u011fimizde 2016 y\u0131l\u0131n\u0131n verisi hatal\u0131 oldu\u011fu i\u00e7in o y\u0131l\u0131 elimine ediyoruz.**","bee4683c":"**Sonu\u00e7lar\u0131m\u0131za bakt\u0131\u011f\u0131m\u0131zda en uygun kom\u015fuluk de\u011ferinin 2 oldu\u011funu ve r2_score de\u011ferinin; <br>0.9327148635745971 oldu\u011funu g\u00f6r\u00fcyoruz.**\n","c01f9982":"Kullanaca\u011f\u0131m\u0131z di\u011fer regresyon modellerinde girdi ve \u00e7\u0131kt\u0131 de\u011ferlerinin normalize edilmesi gerekmektedir. Bunun nedeni ise girdi ve \u00e7\u0131kt\u0131 de\u011ferlerinin say\u0131sal fark\u0131n\u0131n \u00e7ok y\u00fcksek olma durumunda algoritman\u0131n yan\u0131lmas\u0131na sebep olmas\u0131n\u0131 \u00f6nlemektir.\n<br>**\u00d6rne\u011fin;** KNN modeli herhangi bir girdi de\u011ferinin sonucunu onun kom\u015fuluklar\u0131n\u0131 baz alarak belirler. Kom\u015fuluk hesaplamalar\u0131nda ise Pisagor denklemini kullan\u0131r.\n<br>Karesi al\u0131nacak kenarlar\u0131n herhangi birinin de\u011feri 0-1 aras\u0131nda bir de\u011fer ise *(\u00f6rne\u011fin x = 0.1, 0.3, 0.05 gibi de\u011ferlere sahipse)*, bu say\u0131 karesi al\u0131nd\u0131k\u00e7a k\u00fc\u00e7\u00fclecek, di\u011fer kenar 1'den b\u00fcy\u00fckse de *(\u00f6rne\u011fin y = 1000, 2200, 50 000 gibi de\u011ferlere sahipse)*, karesi al\u0131nd\u0131k\u00e7a b\u00fcy\u00fcyecektir ve 1'den b\u00fcy\u00fck kenar form\u00fcl hesaplanmas\u0131nda bask\u0131nl\u0131k yaratacak dolay\u0131s\u0131yla da algoritman\u0131n yanl\u0131\u015f \u00e7al\u0131\u015fmas\u0131na sebep olacakt\u0131r. B\u00f6yle bir durumu \u00f6nlemek i\u00e7in de\u011ferlere normalizasyon i\u015flemi uygulan\u0131r.","e07687e5":"# **D\u00dcNYA \u0130NT\u0130HAR \u0130STAT\u0130ST\u0130\u011e\u0130 VER\u0130 ANAL\u0130Z\u0130**\n\u0130nceleyece\u011fimiz veri seti 141 \u00fclkede 1979-2015 y\u0131llar\u0131 aras\u0131 intihar eden ki\u015fi say\u0131s\u0131n\u0131 cinsiyete ve ya\u015f gruplar\u0131na g\u00f6re da\u011f\u0131tarak olu\u015fturulmu\u015ftur.\nAmac\u0131m\u0131z \u00f6ncelikle bu veri setini g\u00f6rselle\u015ftirerek veri analizi yapmak ve makine \u00f6\u011frenmesi algoritmalar\u0131n\u0131 kullanarak gelecek y\u0131llardaki intihar say\u0131s\u0131n\u0131n tahminidir.","21c7db28":"**Tablomuzdan da g\u00f6r\u00fclece\u011fi \u00fczere en uygun derinlik seviyesi 4 ve r2_score de\u011feri;<br>0.9200627081915808**"}}