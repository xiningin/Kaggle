{"cell_type":{"450f1ab0":"code","ff7d1be8":"code","093d84ff":"code","a3777866":"code","ea4f9cf8":"code","c609db7e":"code","248a4783":"code","954d9274":"code","0fbe4b51":"code","a47ca7fa":"code","d68fdf52":"code","a2e63308":"code","90a6b995":"code","a2056492":"code","33cd7320":"code","94750da6":"code","a4c70bb2":"code","b3eef0b2":"code","26344a48":"code","ac52f1a0":"code","f4016600":"code","b6201d4f":"code","ebc6c72a":"code","f6f4de78":"code","4c8d0c34":"code","5d68e91e":"code","646e4357":"code","8bc7aced":"code","0a611c75":"code","1ad3c684":"code","f50adb89":"code","9dfc3e08":"code","2ef38c95":"code","b1bfa3d2":"code","fc53f5c6":"code","f0db7680":"code","00b479ee":"code","75c9b6c1":"code","83c8f0f0":"code","18224458":"code","f451c985":"code","a995da9a":"code","14956b54":"code","8a61e817":"code","0eb64202":"code","21f28718":"code","05ce0636":"code","51427f5c":"code","54352dfe":"code","2c4563e2":"code","0886d91c":"code","40a32d78":"code","294e1ed7":"code","3c0e1dc3":"code","b03a4083":"code","8345a39d":"code","a3a7f571":"code","c43187e8":"code","46aad64f":"code","da121563":"code","022f6287":"code","7406681f":"code","97b9efe6":"code","c07c29c1":"code","9fb45f7f":"code","c881141b":"code","f7de7710":"code","aca670c8":"code","770983b7":"code","cfb98bd7":"code","24307cd8":"code","c20e5e97":"code","e998e931":"code","724e9c3c":"code","c8be9d9d":"code","9cb8a726":"code","fa86e537":"code","829c98c2":"code","eb8c5bb0":"code","f243072e":"code","f4aa6ad5":"code","3a6edb80":"code","49c80090":"code","4210568e":"code","19d01ac9":"code","2c2b8f90":"code","fe88e2e3":"code","75935230":"code","a8c29c56":"code","9f7a0905":"code","f363c9eb":"markdown","bc1655cb":"markdown","70138913":"markdown","98495d6a":"markdown","56684091":"markdown","cee252ef":"markdown","47a6859f":"markdown","ee9186a1":"markdown","ea2bbf5a":"markdown","82ad3295":"markdown","86950383":"markdown","075f1008":"markdown","58c83b30":"markdown"},"source":{"450f1ab0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff7d1be8":"state_wise = pd.read_csv(\"\/kaggle\/input\/totalcases\/state_wise_daily.csv\")","093d84ff":"state_wise.tail()","a3777866":"tamil_nadu = state_wise[state_wise.columns[:3]]","ea4f9cf8":"tamil_nadu.head()","c609db7e":"df = tamil_nadu.pivot_table('TT', ['Date'], 'Status')","248a4783":"df.columns","954d9274":"df[\"Dates\"] = df.index","0fbe4b51":"df[\"Dates\"] = pd.to_datetime(df[\"Dates\"])\ndf = df.sort_values(by=\"Dates\")\n","a47ca7fa":"df_tn = df","d68fdf52":"df_tn.head()","a2e63308":"df = state_wise[state_wise.columns[:2]]\ndf[\"MH\"] = state_wise[\"MH\"]\nmaha_rastra = df.pivot_table('MH', ['Date'], 'Status')\nmaha_rastra[\"Dates\"] = maha_rastra.index\nmaha_rastra[\"Dates\"] = pd.to_datetime(maha_rastra[\"Dates\"])\nmaha_rastra = maha_rastra.sort_values(by=\"Dates\")\ndf_mh = maha_rastra","90a6b995":"df_mh.head()","a2056492":"df = state_wise[state_wise.columns[:2]]\ndf[\"TN\"] = state_wise[\"TN\"]\ntamil_nadu = df.pivot_table('TN', ['Date'], 'Status')\ntamil_nadu[\"Dates\"] = tamil_nadu.index\ntamil_nadu[\"Dates\"] = pd.to_datetime(tamil_nadu[\"Dates\"])\ntamil_nadu = tamil_nadu.sort_values(by=\"Dates\")\ndf_tn = tamil_nadu","33cd7320":"df_tn.head()","94750da6":"df = state_wise[state_wise.columns[:2]]\ndf[\"GJ\"] = state_wise[\"GJ\"]\nguja_rat = df.pivot_table('GJ', ['Date'], 'Status')\nguja_rat[\"Dates\"] = guja_rat.index\nguja_rat[\"Dates\"] = pd.to_datetime(guja_rat[\"Dates\"])\nguja_rat = guja_rat.sort_values(by=\"Dates\")\ndf_gj = guja_rat","a4c70bb2":"df_gj.head()","b3eef0b2":"df = state_wise[state_wise.columns[:2]]\ndf[\"DL\"] = state_wise[\"DL\"]\ndelhi = df.pivot_table('DL', ['Date'], 'Status')\ndelhi[\"Dates\"] = delhi.index\ndelhi[\"Dates\"] = pd.to_datetime(delhi[\"Dates\"])\ndelhi = delhi.sort_values(by=\"Dates\")\ndf_dl = delhi","26344a48":"df_dl.head()","ac52f1a0":"df = state_wise[state_wise.columns[:2]]\ndf[\"RJ\"] = state_wise[\"RJ\"]\nrajas_than = df.pivot_table('RJ', ['Date'], 'Status')\nrajas_than[\"Dates\"] = rajas_than.index\nrajas_than[\"Dates\"] = pd.to_datetime(rajas_than[\"Dates\"])\nrajas_than = rajas_than.sort_values(by=\"Dates\")\ndf_rj = rajas_than","f4016600":"df_rj.head()","b6201d4f":"df = state_wise[state_wise.columns[:2]]\ndf[\"UP\"] = state_wise[\"UP\"]\nuttar_pradesh = df.pivot_table('UP', ['Date'], 'Status')\nuttar_pradesh[\"Dates\"] = uttar_pradesh.index\nuttar_pradesh[\"Dates\"] = pd.to_datetime(uttar_pradesh[\"Dates\"])\nuttar_pradesh = uttar_pradesh.sort_values(by=\"Dates\")\ndf_up = uttar_pradesh","ebc6c72a":"df_up.head()","f6f4de78":"df = state_wise[state_wise.columns[:2]]\ndf[\"MP\"] = state_wise[\"MP\"]\nmadhya_pradesh = df.pivot_table('MP', ['Date'], 'Status')\nmadhya_pradesh[\"Dates\"] = madhya_pradesh.index\nmadhya_pradesh[\"Dates\"] = pd.to_datetime(madhya_pradesh[\"Dates\"])\nmadhya_pradesh = madhya_pradesh.sort_values(by=\"Dates\")\ndf_mp = madhya_pradesh","4c8d0c34":"df_mp.head()","5d68e91e":"df = state_wise[state_wise.columns[:2]]\ndf[\"WB\"] = state_wise[\"WB\"]\nwest_bengal = df.pivot_table('WB', ['Date'], 'Status')\nwest_bengal[\"Dates\"] = west_bengal.index\nwest_bengal[\"Dates\"] = pd.to_datetime(west_bengal[\"Dates\"])\nwest_bengal = west_bengal.sort_values(by=\"Dates\")\ndf_wb = west_bengal","646e4357":"df_wb.head()","8bc7aced":"df_mh.reset_index(drop=True, inplace=True)\ndf_tn.reset_index(drop=True, inplace=True)\ndf_gj.reset_index(drop=True, inplace=True)\ndf_rj.reset_index(drop=True, inplace=True)\ndf_up.reset_index(drop=True, inplace=True)\ndf_dl.reset_index(drop=True, inplace=True)\ndf_mp.reset_index(drop=True, inplace=True)\ndf_wb.reset_index(drop=True, inplace=True)","0a611c75":"df_mh.reset_index(drop = True,inplace = True)\ndf_mh.set_index(\"Dates\",inplace = True)\ndf_tn.reset_index(drop = True,inplace = True)\ndf_tn.set_index(\"Dates\",inplace = True)\ndf_gj.reset_index(drop = True,inplace = True)\ndf_gj.set_index(\"Dates\",inplace = True)\ndf_rj.reset_index(drop = True,inplace = True)\ndf_rj.set_index(\"Dates\",inplace = True)\ndf_up.reset_index(drop = True,inplace = True)\ndf_up.set_index(\"Dates\",inplace = True)\ndf_dl.reset_index(drop = True,inplace = True)\ndf_dl.set_index(\"Dates\",inplace = True)\ndf_mp.reset_index(drop = True,inplace = True)\ndf_mp.set_index(\"Dates\",inplace = True)\ndf_wb.reset_index(drop = True,inplace = True)\ndf_wb.set_index(\"Dates\",inplace = True)","1ad3c684":"df_dl.head()","f50adb89":"df_mh.head()","9dfc3e08":"df_mh[\"Active\"] = df_mh[\"Confirmed\"] - df_mh[\"Deceased\"] - df_mh[\"Recovered\"]\ndf_tn[\"Active\"] = df_tn[\"Confirmed\"] - df_tn[\"Deceased\"] - df_tn[\"Recovered\"]\ndf_gj[\"Active\"] = df_gj[\"Confirmed\"] - df_gj[\"Deceased\"] - df_gj[\"Recovered\"]\ndf_dl[\"Active\"] = df_dl[\"Confirmed\"] - df_dl[\"Deceased\"] - df_dl[\"Recovered\"]\ndf_rj[\"Active\"] = df_rj[\"Confirmed\"] - df_rj[\"Deceased\"] - df_rj[\"Recovered\"]\ndf_up[\"Active\"] = df_up[\"Confirmed\"] - df_up[\"Deceased\"] - df_up[\"Recovered\"]\ndf_mp[\"Active\"] = df_mp[\"Confirmed\"] - df_mp[\"Deceased\"] - df_mp[\"Recovered\"]\ndf_wb[\"Active\"] = df_wb[\"Confirmed\"] - df_wb[\"Deceased\"] - df_wb[\"Recovered\"]","2ef38c95":"df_mh.head()","b1bfa3d2":"def active(df):\n    df[\"Total_Active\"] = 0\n    for i in range(len(df)):\n        df[\"Total_Active\"][0] = df[\"Active\"][0]\n        if i>0:\n            df[\"Total_Active\"][i] = df[\"Total_Active\"][i-1]+df[\"Active\"][i] ","fc53f5c6":"active(df_mh)\nactive(df_gj)\nactive(df_tn)\nactive(df_dl)\nactive(df_rj)\nactive(df_up)\nactive(df_mp)\nactive(df_wb)","f0db7680":"df_mh.head()","00b479ee":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\nimport math\n# contrived dataset\ndata = list(df_mh[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_mh = model_fit.predict(len(data), len(data)+60)\nyhat_auto_mh =  [math.floor(i) for i in yhat_auto_mh]\nprint(yhat_auto_mh)","75c9b6c1":"data[-5:]","83c8f0f0":"project = pd.DataFrame()","18224458":"project[\"Auto_Maharatra\"] = yhat_auto_mh ","f451c985":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_gj[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_gj = model_fit.predict(len(data), len(data)+60)\nyhat_auto_gj =  [math.floor(i) for i in yhat_auto_gj]\n\nprint(yhat_auto_gj)\nproject[\"Auto_Gujarat\"] = yhat_auto_gj ","a995da9a":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_tn[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_tn = model_fit.predict(len(data), len(data)+60)\nyhat_auto_tn =  [math.floor(i) for i in yhat_auto_tn]\n\nprint(yhat_auto_tn)\nproject[\"Auto_TamilNadu\"] = yhat_auto_tn ","14956b54":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_dl[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_dl = model_fit.predict(len(data), len(data)+60)\nyhat_auto_dl =  [math.floor(i) for i in yhat_auto_dl]\n\nprint(yhat_auto_dl)\nproject[\"Auto_Delhi\"] = yhat_auto_dl ","8a61e817":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_rj[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_rj = model_fit.predict(len(data), len(data)+60)\nyhat_auto_rj =  [math.floor(i) for i in yhat_auto_rj]\n\nprint(yhat_auto_rj)\nproject[\"Auto_Rajasthan\"] = yhat_auto_rj ","0eb64202":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_up[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_up = model_fit.predict(len(data), len(data)+60)\nyhat_auto_up =  [math.floor(i) for i in yhat_auto_up]\n\nprint(yhat_auto_up)\nproject[\"Auto_UttarPradesh\"] = yhat_auto_up ","21f28718":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_mp[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_mp = model_fit.predict(len(data), len(data)+60)\nyhat_auto_mp =  [math.floor(i) for i in yhat_auto_mp]\n\nprint(yhat_auto_mp)\nproject[\"Auto_MadhyaPradesh\"] = yhat_auto_mp ","05ce0636":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n# contrived dataset\ndata = list(df_wb[\"Total_Active\"][:])\n# fit model\nmodel = AutoReg(data, lags=1)\nmodel_fit = model.fit()\n# make prediction\nyhat_auto_wb = model_fit.predict(len(data), len(data)+60)\nyhat_auto_wb =  [math.floor(i) for i in yhat_auto_wb]\n\nprint(yhat_auto_wb)\nproject[\"Auto_WestBengal\"] = yhat_auto_wb","51427f5c":"project.head()","54352dfe":"list(df_mh[\"Total_Active\"][-5:])","2c4563e2":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_mh[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_mh[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)","0886d91c":"#predicting next forty days\ndef lstm_pred(list_a):\n    yhat_lstm = []\n    x_input = array(list_a)\n    for i in range(6):\n        x_input = x_input.reshape((1, n_steps, n_features))\n        yhat = model.predict(x_input,verbose = 2)\n        yhat_lstm = yhat_lstm + list(yhat[0])\n        x_input = array(yhat_lstm[-5:])\n    return (yhat_lstm)\nyhat_lstm_mh = lstm_pred(list(df_mh[\"Total_Active\"][-5:]))","40a32d78":"yhat_lstm_mh = [math.floor(i) for i in yhat_lstm_mh]\n","294e1ed7":"project_lstm = pd.DataFrame()","3c0e1dc3":"project_lstm[\"Lstm_Maharatra\"] = yhat_lstm_mh","b03a4083":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_tn[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_tn[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_tn = lstm_pred(list(df_tn[\"Total_Active\"][-5:]))\nyhat_lstm_tn = [math.floor(i) for i in yhat_lstm_tn]\nproject_lstm[\"Lstm_TamilNadu\"] = yhat_lstm_tn","8345a39d":"project_lstm","a3a7f571":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_gj[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_gj[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_gj = lstm_pred(list(df_gj[\"Total_Active\"][-5:]))\nyhat_lstm_gj = [math.floor(i) for i in yhat_lstm_gj]\nproject_lstm[\"Lstm_Gujarat\"] = yhat_lstm_gj","c43187e8":"project_lstm","46aad64f":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_dl[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_dl[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_dl = lstm_pred(list(df_dl[\"Total_Active\"][-5:]))\nyhat_lstm_dl = [math.floor(i) for i in yhat_lstm_dl]\nproject_lstm[\"Lstm_Delhi\"] = yhat_lstm_dl","da121563":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_up[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_up[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_up = lstm_pred(list(df_up[\"Total_Active\"][-5:]))\nyhat_lstm_up = [math.floor(i) for i in yhat_lstm_up]\nproject_lstm[\"Lstm_UttarPradesh\"] = yhat_lstm_up","022f6287":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_mp[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_mp[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_mp = lstm_pred(list(df_mp[\"Total_Active\"][-5:]))\nyhat_lstm_mp = [math.floor(i) for i in yhat_lstm_mp]\nproject_lstm[\"Lstm_Madhya Pradesh\"] = yhat_lstm_mp","7406681f":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_rj[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_rj[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_rj = lstm_pred(list(df_rj[\"Total_Active\"][-5:]))\nyhat_lstm_rj = [math.floor(i) for i in yhat_lstm_rj]\nproject_lstm[\"Lstm_Rajasthan\"] = yhat_lstm_rj","97b9efe6":"#Example\n# univariate lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n \n# define input sequence\nraw_seq = list(df_wb[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=5, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_wb[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)\nyhat_lstm_wb = lstm_pred(list(df_wb[\"Total_Active\"][-5:]))\nyhat_lstm_wb = [math.floor(i) for i in yhat_lstm_wb]\nproject_lstm[\"Lstm_WestBengal\"] = yhat_lstm_wb","c07c29c1":"project_lstm.head()","9fb45f7f":"# univariate bidirectional lstm example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_mh[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_mh[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat = model.predict(x_input, verbose=0)\nprint(yhat)","c881141b":"\ndef bilstm_pred(list_a):\n    yhat_bilstm = []\n    x_input = array(list_a)\n    for i in range(6):\n        x_input = x_input.reshape((1, n_steps, n_features))\n        yhat = model.predict(x_input,verbose = 2)\n        yhat_bilstm = yhat_bilstm + list(yhat[0])\n        x_input = array(yhat_bilstm[-5:])\n    return yhat_bilstm    ","f7de7710":"yhat_bilstm_mh = bilstm_pred(list(df_mh[\"Total_Active\"][-5:]))\nyhat_bilstm_mh = [math.floor(i) for i in yhat_bilstm_mh]\nproject_bilstm = pd.DataFrame()\nproject_bilstm[\"BILSTM_MH\"] = yhat_bilstm_mh","aca670c8":"project_bilstm.head()","770983b7":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_tn[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_tn[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_tn = bilstm_pred(list(df_tn[\"Total_Active\"][-5:]))\nyhat_bilstm_tn = [math.floor(i) for i in yhat_bilstm_tn]\nproject_bilstm[\"BILSTM_TN\"] = yhat_bilstm_tn","cfb98bd7":"project_bilstm.head()","24307cd8":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_gj[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_gj[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_gj = bilstm_pred(list(df_gj[\"Total_Active\"][-5:]))\nyhat_bilstm_gj = [math.floor(i) for i in yhat_bilstm_gj]\nproject_bilstm[\"BILSTM_GJ\"] = yhat_bilstm_gj","c20e5e97":"project_bilstm.head()","e998e931":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_dl[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_dl[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_dl = bilstm_pred(list(df_dl[\"Total_Active\"][-5:]))\nyhat_bilstm_dl = [math.floor(i) for i in yhat_bilstm_dl]\nproject_bilstm[\"BILSTM_DL\"] = yhat_bilstm_dl","724e9c3c":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_up[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_up[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_up = bilstm_pred(list(df_up[\"Total_Active\"][-5:]))\nyhat_bilstm_up = [math.floor(i) for i in yhat_bilstm_up]\nproject_bilstm[\"BILSTM_UP\"] = yhat_bilstm_up","c8be9d9d":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_mp[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_mp[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_mp = bilstm_pred(list(df_mp[\"Total_Active\"][-5:]))\nyhat_bilstm_mp = [math.floor(i) for i in yhat_bilstm_mp]\nproject_bilstm[\"BILSTM_MP\"] = yhat_bilstm_mp","9cb8a726":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_rj[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_rj[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_rj = bilstm_pred(list(df_rj[\"Total_Active\"][-5:]))\nyhat_bilstm_rj = [math.floor(i) for i in yhat_bilstm_rj]\nproject_bilstm[\"BILSTM_RJ\"] = yhat_bilstm_rj","fa86e537":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\n\n# split a univariate sequence\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix+10 > len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n# define input sequence\nraw_seq = list(df_wb[\"Total_Active\"][:])\n# choose a number of time steps\nn_steps = 5\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\n# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\nmodel.add(Dense(10))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\ncallback = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X, y, epochs=10000, verbose=0, batch_size=10, callbacks=[callback])\n# demonstrate prediction\nx_input = array(list(df_wb[\"Total_Active\"][-5:]))\nx_input = x_input.reshape((1, n_steps, n_features))\nyhat_bilstm_wb = bilstm_pred(list(df_wb[\"Total_Active\"][-5:]))\nyhat_bilstm_wb = [math.floor(i) for i in yhat_bilstm_wb]\nproject_bilstm[\"BILSTM_WB\"] = yhat_bilstm_wb","829c98c2":"project_bilstm.head()","eb8c5bb0":"project.head()","f243072e":"project['Date'] = pd.date_range(start='6\/26\/2020', periods=len(project), freq='D')","f4aa6ad5":"project.head()","3a6edb80":"project.set_index(\"Date\",inplace = True)","49c80090":"project_lstm['Date'] = pd.date_range(start='6\/26\/2020', periods=len(project_lstm), freq='D')\nproject_lstm.set_index(\"Date\",inplace = True)","4210568e":"project_bilstm['Date'] = pd.date_range(start='6\/26\/2020', periods=len(project_bilstm), freq='D')\nproject_bilstm.set_index(\"Date\",inplace = True)","19d01ac9":"project.head()","2c2b8f90":"project.to_csv(\"autoregtotalactive_states.csv\")","fe88e2e3":"project_lstm.head()","75935230":"project_lstm.to_csv(\"lstmtotalactive.csv\")\n","a8c29c56":"project_bilstm.head()","9f7a0905":"# project.to_csv(\"autoreg.csv\")\n# project_lstm.to_csv(\"lstm.csv\")\n\nproject_bilstm.to_csv(\"bilstmtotalactive.csv\")","f363c9eb":"# Applying Autoregression","bc1655cb":"Maharastra,Tamil Nadu,Delhi,Gujarat,Rajasthan,Uttar Pradesh,Madhya Pradesh\n\n42224,12697,15311,4918,2525,3828,2734 active cases respectively.\n\nThis is 70 % of total active cases in India.","70138913":"# Tamil Nadu","98495d6a":"# BI_LSTM","56684091":"# Maharastra","cee252ef":"# West Bengal","47a6859f":"We would analyse top 6 states and 1 UN for covid19 india according to 5 June 2020.","ee9186a1":"# Uttar Pradesh","ea2bbf5a":"# Gujarat","82ad3295":"# LSTM","86950383":"# Rajasthan","075f1008":"# Madhya Pradesh","58c83b30":"# Delhi"}}