{"cell_type":{"865c00dc":"code","15ea9ec3":"code","e21b8b7c":"code","f5e9201e":"code","1e1b25ce":"code","23098fb3":"code","8dfcce93":"code","e79a6f3e":"code","6631a2e2":"code","8e85ef72":"code","ab2006fc":"code","401c9662":"code","4dbc69e5":"code","49d516f9":"code","e93549ef":"code","4e1dda31":"code","7a0d3a62":"code","33e96d0e":"code","8b783292":"code","e76fd24c":"code","4c263a3f":"code","b56ccda7":"code","13979c2d":"code","68e56daa":"code","2f08f327":"markdown"},"source":{"865c00dc":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","15ea9ec3":"%%time\ntrain = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/train.csv')\ntest = pd.read_csv('..\/input\/resolving-citizens-grievances-v1\/dataset\/test.csv')\ntrain.head()\n","e21b8b7c":"train.shape, test.shape","f5e9201e":"# combining test and train to do feature engineering.\ntest['importance']=-1\ntrain['label'] = 'train'\ntest['label'] = 'test'\ncombined = pd.concat([train,test],axis=0)\ncombined.shape","1e1b25ce":"for col in combined.columns:\n    print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum())\n\n#     a lot of features have multiple empty values and single constant value.","23098fb3":"def combine_issues(df):\n#     combining all the issues columns to form one issue column\n    issue_columns = [\n        'issue.0', 'issue.1', 'issue.2', 'issue.3', 'issue.4', 'issue.5', 'issue.6', 'issue.7', 'issue.8', \n        'issue.9', 'issue.10', 'issue.11', 'issue.12', 'issue.13', 'issue.14', 'issue.15', 'issue.16', \n        'issue.17', 'issue.18', 'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23']\n    issue_df = combined[issue_columns]\n    issue_df.fillna('',inplace=True)\n    issue_df['issues'] = issue_df[issue_columns].apply(lambda x: '. '.join([val for val in x if val != '']), axis=1)\n    df.drop(issue_columns, axis=1, inplace=True)\n    issue_df.drop(issue_columns, axis=1, inplace=True)\n    df = pd.concat([df, issue_df], axis=1)\n    return df\n\n\ndef lowercase_texts(df):\n    print('converting all text columns in lowercase.',)\n    for col in combined.columns:\n        if combined[col].dtype=='object':\n            combined[col] = combined[col].str.lower()\n    return df\n\n\ndef universalize_countries(df):\n#     converting all the countries to single symbolic numerical value.(eg - Albania, albania, abl, ab -> 1)\n    country_dict_A = df[['respondentOrderEng','country.name']].set_index('country.name').T.to_dict('list')\n    country_dict_C = df[['respondentOrderEng','respondent.0']].set_index('respondent.0').T.to_dict('list')    \n    country_dict = {}\n    for d in (country_dict_A, country_dict_C):#, country_dict_C): #, country_dict_D, country_dict_E, country_dict_F): \n        country_dict.update(d)\n        \n    country_dict = {k: v for k, v in country_dict.items() if pd.notna(k)}\n    df['respondent.0'] = df['respondent.0'].apply(lambda x: country_dict[x][0])\n    df['respondent.1'] = df['respondent.1'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.2'] = df['respondent.2'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.3'] = df['respondent.3'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.4'] = df['respondent.4'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    del df['respondentOrderEng']\n    return df\n\ndef remove_constant_values(df):\n#     this function removes redundant constant features.\n    print('Removing constant columns -> ',)\n    for col in df.columns:\n        if df[col].nunique()==1:\n            print(col,end=', ' )\n            del df[col]\n    return df\n\ndef remove_unwanted_features(df):\n#     these features dont add any valueable signal to the data.\n    remove_cols =['parties.0', 'country.alpha2', 'parties.1', 'country.name', 'docname', 'appno', 'ecli', 'kpdate', 'originatingbody_name']\n    for col in remove_cols:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df\n\n  \ndef featurize_columns(df):\n#     making new columns.\n    df['itemid'] = df['itemid'].apply(lambda x: x[4:7])\n    df['sharepointid'] = df['sharepointid'].apply(lambda x: str(x)[:3])\n    df['total_respondents'] = 5- df[['respondent.0','respondent.1','respondent.2','respondent.3','respondent.4']].isna().sum(axis=1)\n\n    return df\n\ndef featurize_date_columns(df):\n    #     making new columns based on dates.\n    df['daysbetween_intro_decision'] = (pd.to_datetime(df['decisiondate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_intro_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_decision_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['decisiondate'])).dt.days\n    df.drop(['decisiondate','introductiondate','judgementdate'], axis=1, inplace=True)\n    return df\n\ndef encoding(df):\n    df['doctypebranch'] = le.fit_transform(df['doctypebranch'])\n    df['separateopinion'] = le.fit_transform(df['separateopinion'])\n    df['typedescription'] = le.fit_transform(df['typedescription'])\n    return df\n\ndef fill_missing(df):\n    for col in df.columns:\n        if col not in ['label', 'issues']:\n            df[col].fillna(0,inplace=True)\n            df[col] = df[col].astype('int')\n    return df","8dfcce93":"combined.head()","e79a6f3e":"# pd.set_option('display.max_colwidth', -1)\n# combined[['issues']]","6631a2e2":"combined = combine_issues(combined)\nprint('combined shape after combining issues ->', combined.shape)\ncombined = lowercase_texts(combined)\ncombined = universalize_countries(combined)\ncombined = featurize_columns(combined)\ncombined = featurize_date_columns(combined)\ncombined = encoding(combined)\ncombined = remove_constant_values(combined)\nprint('\\ncombined shape after removing constant features->', combined.shape)\ncombined = remove_unwanted_features(combined)\ncombined = fill_missing(combined)","8e85ef72":"combined.head()","ab2006fc":"combined.to_csv('combined_inbetween.csv',index=False)\n","401c9662":"# for col in combined.columns:\n#     print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum(), 'type-> ',combined[col].dtype)","4dbc69e5":"# before making the model, delete label column, delete issues column.\n# separate test and train, delete output of test.\n# explore blackstone - https:\/\/spacy.io\/universe\/project\/blackstone for making new features from issues.\n# test filling missing values using different stratergies.","49d516f9":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score","e93549ef":"target_col = 'importance'\ncombined.shape","4e1dda31":"combined_train = combined.query('label == \"train\"').drop(['issues', 'label'] , axis=1)\ncombined_train.shape","7a0d3a62":"# split test and train\nX_train, X_test, Y_train, Y_test = \\\n    train_test_split(combined_train.drop([target_col], axis=1), \n                     combined_train[target_col], \n                     test_size=0.2, \n                     stratify=combined_train[target_col])\nprint(len(X_train),' samples in training data\\n',\n      len(X_test),' samples in test data\\n', )","33e96d0e":"# choosing different hyperparameters and select the best one\nclf_dict = {\"LGBM Classifier\": \n            {'classifier': LGBMClassifier(),\n                 'params': [\n                            {\n                             'learning_rate': [0.01, 0.1, 1.0],\n                             'n_estimators' :[10, 50, 500, 1000],\n                             'max_depth':[5, 3,7],\n                             'max_features' : [3, 5, 7, 11]\n                            }\n                           ]\n            },\n           }","8b783292":"res_df  = pd.DataFrame()\nnum_clf = len(clf_dict.keys())\nres_df = pd.DataFrame(\n    data=np.zeros(shape=(num_clf, 3)),\n    columns = ['classifier',\n                   'train_score', \n                   'test_score',\n            ]\n)","e76fd24c":"%%time\ncount = 0\n#training the model\nfor key, clf in clf_dict.items():\n    print(key, clf)\n\n    grid = GridSearchCV(clf[\"classifier\"],\n                        clf[\"params\"],\n                        refit=True,\n                        cv=10,\n                        scoring = 'accuracy',\n                        n_jobs = -1,\n                        verbose=0\n                        \n                       )\n    estimator = grid.fit( X_train,Y_train)\n    \n    train_score = estimator.score(X_train,Y_train)\n    \n    test_score = estimator.score(X_test,Y_test)\n    \n    count+=1\n    \n    res_df.loc[count,'classifier'] = key\n    res_df.loc[count,'train_score'] = train_score\n    res_df.loc[count,'test_score'] = test_score\n    print(f\"{key} best params: {grid.best_params_}\")\n    \nres_df.iloc[1:, :]","4c263a3f":"#Light Gradient Boosting Machine ensemble machine learning algorithm\nxgbm = LGBMClassifier(max_depth=6, learning_rate=0.1, n_estimators=500,\n                         min_child_weight=100, subsample=1.0, \n                         colsample_bytree=0.8, colsample_bylevel=0.8,\n                         random_state=42, n_jobs=-1)\n\n\nprint(\"Cross Validating...\")\noof_preds = cross_val_predict(xgbm, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)","b56ccda7":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\n#prediction\npreds = pred.predict(tst)\npreds","13979c2d":"sub = pd.DataFrame(columns=[\"appno\",\"importance\"])\nsub[\"appno\"] = test.appno\nsub[\"importance\"] = preds\n","68e56daa":"sub.to_csv(\"submission2.csv\", index=False)","2f08f327":"- Problem description: https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-machine-learning-challenge-predict-grievance-importance\/"}}