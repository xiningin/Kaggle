{"cell_type":{"abdf9da8":"code","ddb5c0f5":"code","e1c9e3b9":"code","b6e1cda4":"code","f0e5e928":"code","b0b147bb":"code","7b50b40d":"code","30e1e21f":"code","65a9a41f":"code","56815928":"code","fea21e9c":"code","277bee7f":"code","e846177e":"code","ec6d7902":"code","39a53b70":"code","34b7842d":"code","5f99e095":"code","b14edb2a":"code","4220425e":"code","9579defc":"code","c0f7e274":"code","ff5b1b77":"code","2f964b1b":"code","8cc063ba":"code","bc3a9821":"code","a54aff48":"code","96c82c71":"code","580e7645":"markdown","8190316f":"markdown","beb53bae":"markdown","752107f6":"markdown","8c0ec59b":"markdown","534578c1":"markdown","36876cf5":"markdown","9886abe1":"markdown","9cfbff44":"markdown","1051697a":"markdown","6f9126c2":"markdown","00356168":"markdown","401fe8b8":"markdown","37801582":"markdown"},"source":{"abdf9da8":"import os\nprint(os.listdir(\"..\/input\"))","ddb5c0f5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\n\n# I don't like SettingWithCopyWarnings ...\nwarnings.simplefilter('error', SettingWithCopyWarning)\ngc.enable()\n%matplotlib inline","e1c9e3b9":"train = pd.read_csv('..\/input\/create-extracted-json-fields-dataset\/extracted_fields_train.gz', \n                    dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntest = pd.read_csv('..\/input\/create-extracted-json-fields-dataset\/extracted_fields_test.gz', \n                   dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntrain.shape, test.shape","b6e1cda4":"def get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['fullVisitorId'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['fullVisitorId'].isin(unique_vis[trn_vis])],\n                ids[df['fullVisitorId'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids","f0e5e928":"y_reg = train['totals.transactionRevenue'].fillna(0)\ndel train['totals.transactionRevenue']\n\nif 'totals.transactionRevenue' in test.columns:\n    del test['totals.transactionRevenue']","b0b147bb":"train.columns","7b50b40d":"for df in [train, test]:\n    df['date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n    df['sess_date_dow'] = df['date'].dt.dayofweek\n    df['sess_date_hours'] = df['date'].dt.hour\n    df['sess_date_dom'] = df['date'].dt.day","30e1e21f":"excluded_features = [\n    'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', \n    'visitId', 'visitStartTime'\n]\n\ncategorical_features = [\n    _f for _f in train.columns\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')\n]","65a9a41f":"for f in categorical_features:\n    train[f], indexer = pd.factorize(train[f])\n    test[f] = indexer.get_indexer(test[f])","56815928":"folds = get_folds(df=train, n_splits=5)\n\ntrain_features = [_f for _f in train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(train.shape[0])\nsub_reg_preds = np.zeros(test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.03,\n        n_estimators=1000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","fea21e9c":"import warnings\nwarnings.simplefilter('ignore', FutureWarning)\n\nimportances['gain_log'] = np.log1p(importances['gain'])\nmean_gain = importances[['gain', 'feature']].groupby('feature').mean()\nimportances['mean_gain'] = importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 12))\nsns.barplot(x='gain_log', y='feature', data=importances.sort_values('mean_gain', ascending=False))","277bee7f":"train['predictions'] = np.expm1(oof_reg_preds)\ntest['predictions'] = sub_reg_preds","e846177e":"# Aggregate data at User level\ntrn_data = train[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()","ec6d7902":"%%time\n# Create a list of predictions for each Visitor\ntrn_pred_list = train[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})","39a53b70":"# Create a DataFrame with VisitorId as index\n# trn_pred_list contains dict \n# so creating a dataframe from it will expand dict values into columns\ntrn_all_predictions = pd.DataFrame(list(trn_pred_list.values), index=trn_data.index)\ntrn_feats = trn_all_predictions.columns\ntrn_all_predictions['t_mean'] = np.log1p(trn_all_predictions[trn_feats].mean(axis=1))\ntrn_all_predictions['t_median'] = np.log1p(trn_all_predictions[trn_feats].median(axis=1))\ntrn_all_predictions['t_sum_log'] = np.log1p(trn_all_predictions[trn_feats]).sum(axis=1)\ntrn_all_predictions['t_sum_act'] = np.log1p(trn_all_predictions[trn_feats].fillna(0).sum(axis=1))\ntrn_all_predictions['t_nb_sess'] = trn_all_predictions[trn_feats].isnull().sum(axis=1)\nfull_data = pd.concat([trn_data, trn_all_predictions], axis=1)\ndel trn_data, trn_all_predictions\ngc.collect()\nfull_data.shape","34b7842d":"%%time\nsub_pred_list = test[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})","5f99e095":"sub_data = test[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()\nsub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)\nfor f in trn_feats:\n    if f not in sub_all_predictions.columns:\n        sub_all_predictions[f] = np.nan\nsub_all_predictions['t_mean'] = np.log1p(sub_all_predictions[trn_feats].mean(axis=1))\nsub_all_predictions['t_median'] = np.log1p(sub_all_predictions[trn_feats].median(axis=1))\nsub_all_predictions['t_sum_log'] = np.log1p(sub_all_predictions[trn_feats]).sum(axis=1)\nsub_all_predictions['t_sum_act'] = np.log1p(sub_all_predictions[trn_feats].fillna(0).sum(axis=1))\nsub_all_predictions['t_nb_sess'] = sub_all_predictions[trn_feats].isnull().sum(axis=1)\nsub_full_data = pd.concat([sub_data, sub_all_predictions], axis=1)\ndel sub_data, sub_all_predictions\ngc.collect()\nsub_full_data.shape","b14edb2a":"train['target'] = y_reg\ntrn_user_target = train[['fullVisitorId', 'target']].groupby('fullVisitorId').sum()","4220425e":"df = pd.concat([full_data,sub_full_data],sort=False)\ndf = df.reset_index(drop=False)\nfor c in df.columns[1:]:\n    if((df[c].min()>=0)&(df[c].max()>=10)):\n        df[c] = np.log1p(df[c])\n    elif((df[c].min()<0)&((df[c].max()-df[c].min())>=10)):\n        df.loc[df[c]!=0,c] = np.sign(df.loc[df[c]!=0,c])*np.log(np.abs(df.loc[df[c]!=0,c]))\nfrom sklearn.preprocessing import StandardScaler\nfor c in df.columns[1:]:\n    ss = StandardScaler()\n    df.loc[~np.isfinite(df[c]),c] = np.nan\n    df.loc[~df[c].isnull(),c] = ss.fit_transform(df.loc[~df[c].isnull(),c].values.reshape(-1,1))\ndf.fillna(-99999,inplace=True)\ngp_trn_users = df[:full_data.shape[0]].copy().set_index('fullVisitorId')\ngp_trn_users['target'] = np.log1p(trn_user_target['target'].values)\ngp_trn_users.target \/= gp_trn_users.target.max()\ngp_sub_users = df[full_data.shape[0]:].copy().set_index('fullVisitorId')\nnewcols =  [x.replace('.','_') for x in gp_trn_users.columns]\ngp_trn_users.columns = newcols\nnewcols =  [x.replace('.','_') for x in gp_sub_users.columns]\ngp_sub_users.columns = newcols","9579defc":"def GP1(data):\n    return ((((data[\"t_mean\"]) + (data[\"totals_hits\"]))) +\n            (np.maximum((((((data[\"pred_2\"]) + (data[\"pred_2\"]))\/2.0))), ((-3.0)))) +\n            (np.maximum(((data[\"t_mean\"])), ((-1.0)))) +\n            (np.minimum(((1.0)), (((4.81583929061889648))))) +\n            (np.maximum(((-2.0)), ((data[\"t_sum_act\"])))) +\n            (((1.0) * (data[\"geoNetwork_metro\"]))) +\n            (np.maximum((((((data[\"pred_0\"]) + ((((data[\"t_median\"]) + (np.maximum(((np.maximum(((data[\"t_sum_log\"])), ((data[\"pred_0\"]))))), ((data[\"t_mean\"])))))\/2.0)))\/2.0))), ((data[\"t_sum_log\"])))) +\n            (((data[\"t_sum_log\"]) + (np.minimum(((data[\"t_mean\"])), ((data[\"t_sum_log\"])))))) +\n            ((((((-1.0) - (-2.0))) + (data[\"t_sum_act\"]))\/2.0)) +\n            ((((0.0) > ((((data[\"trafficSource_referralPath\"]) < (data[\"trafficSource_referralPath\"]))*1.)))*1.)) +\n            (((data[\"t_mean\"]) + (1.0))) +\n            (((data[\"t_sum_log\"]) + (data[\"t_median\"]))) +\n            (((data[\"t_sum_act\"]) - (0.0))) +\n            (np.maximum(((data[\"pred_3\"])), ((((3.0) * (data[\"pred_0\"])))))) +\n            ((((data[\"pred_2\"]) + (-2.0))\/2.0)) +\n            (((data[\"t_sum_log\"]) * (data[\"t_mean\"]))) +\n            (((data[\"t_sum_act\"]) + (data[\"t_sum_log\"]))) +\n            ((((((data[\"totals_hits\"]) - (3.0))) > (data[\"geoNetwork_metro\"]))*1.)) +\n            (((3.0) * (data[\"t_sum_log\"]))) +\n            ((((data[\"geoNetwork_continent\"]) > (-1.0))*1.)) +\n            ((((data[\"geoNetwork_subContinent\"]) < (((data[\"device_browser\"]) + (-2.0))))*1.)) +\n            (np.minimum(((np.minimum(((2.0)), ((data[\"geoNetwork_metro\"]))))), ((data[\"geoNetwork_metro\"])))) +\n            (np.minimum(((1.0)), ((np.tanh((((2.0) * 2.0))))))) +\n            ((((data[\"geoNetwork_subContinent\"]) > (-3.0))*1.)) +\n            (((data[\"t_sum_log\"]) - (-1.0))) +\n            (np.minimum(((-2.0)), ((data[\"trafficSource_referralPath\"])))) +\n            (np.maximum(((data[\"t_sum_log\"])), ((-3.0)))) +\n            (np.minimum(((np.where((((data[\"pred_0\"]) > (data[\"trafficSource_referralPath\"]))*1.)<0, data[\"totals_hits\"], -3.0 ))), ((((data[\"geoNetwork_subContinent\"]) \/ 2.0))))) +\n            ((((2.0) + (data[\"pred_1\"]))\/2.0)) +\n            (np.tanh((np.tanh((2.0))))) +\n            (np.tanh(((-1.0*((-3.0)))))) +\n            (((-2.0) + (data[\"t_sum_log\"]))) +\n            ((((data[\"geoNetwork_country\"]) < (data[\"geoNetwork_metro\"]))*1.)) +\n            ((((3.0) + ((-1.0*((-2.0)))))\/2.0)) +\n            (((((((data[\"t_sum_log\"]) * (data[\"geoNetwork_continent\"]))) * (((data[\"t_sum_log\"]) - (data[\"visitNumber\"]))))) * (np.minimum(((data[\"t_sum_act\"])), ((data[\"t_sum_log\"])))))) +\n            ((((((data[\"totals_hits\"]) \/ 2.0)) + (data[\"t_sum_log\"]))\/2.0)) +\n            (((((np.tanh((data[\"pred_1\"]))) + (data[\"t_sum_act\"]))) + (((data[\"t_sum_act\"]) + (((data[\"t_sum_log\"]) + (-2.0))))))) +\n            (((2.0) - (np.where(data[\"t_mean\"]>0, data[\"t_nb_sess\"], (((data[\"t_mean\"]) < (data[\"geoNetwork_continent\"]))*1.) )))) +\n            (np.where(data[\"t_mean\"]>0, data[\"t_sum_log\"], -2.0 )) +\n            ((((data[\"t_mean\"]) + ((((data[\"geoNetwork_subContinent\"]) + (((np.tanh(((12.19428730010986328)))) * 2.0)))\/2.0)))\/2.0)) +\n            (np.where(((((((data[\"pred_0\"]) * 2.0)) + (data[\"visitNumber\"]))) \/ 2.0) < -99998, (((-1.0) > (2.0))*1.), np.tanh((data[\"totals_hits\"])) )) +\n            (np.where((((-1.0) > (1.0))*1.)<0, ((((1.0)) + (-1.0))\/2.0), data[\"t_sum_act\"] )) +\n            ((((-1.0*((((((((((data[\"t_median\"]) + (((data[\"t_sum_log\"]) + (data[\"t_nb_sess\"]))))\/2.0)) + (data[\"geoNetwork_continent\"]))\/2.0)) + (data[\"t_sum_log\"])))))) \/ 2.0)) +\n            (np.minimum(((np.minimum(((np.where(data[\"trafficSource_referralPath\"]<0, (((data[\"trafficSource_referralPath\"]) + (np.tanh((data[\"t_sum_log\"]))))\/2.0), -3.0 ))), ((data[\"geoNetwork_country\"]))))), ((data[\"t_sum_log\"])))) +\n            ((((((data[\"t_sum_log\"]) + (np.where(data[\"visitNumber\"]<0, -2.0, data[\"pred_1\"] )))\/2.0)) + (data[\"t_sum_act\"]))) +\n            (((((np.where(data[\"geoNetwork_country\"]>0, data[\"t_sum_act\"], data[\"geoNetwork_country\"] )) + (((data[\"geoNetwork_country\"]) \/ 2.0)))) + (-1.0))) +\n            (np.where(data[\"t_mean\"]<0, -2.0, np.where(((data[\"geoNetwork_metro\"]) + (data[\"geoNetwork_continent\"]))<0, -2.0, ((data[\"geoNetwork_continent\"]) + (data[\"geoNetwork_continent\"])) ) )) +\n            ((((((data[\"geoNetwork_continent\"]) < (data[\"t_sum_act\"]))*1.)) + (((np.minimum(((((((data[\"totals_hits\"]) \/ 2.0)) \/ 2.0))), ((data[\"pred_0\"])))) + (data[\"t_sum_log\"]))))) +\n            (((data[\"t_sum_act\"]) + (((-2.0) - (np.minimum(((data[\"geoNetwork_metro\"])), ((((data[\"geoNetwork_metro\"]) * (np.minimum(((data[\"t_sum_act\"])), ((data[\"t_mean\"]))))))))))))) +\n            (np.where(-3.0<0, ((np.where(2.0 < -99998, data[\"t_sum_log\"], (((0.0) < (data[\"totals_pageviews\"]))*1.) )) * 2.0), (6.0) )) +\n            ((((data[\"t_sum_log\"]) + ((((((-1.0) - (((data[\"visitNumber\"]) + (data[\"t_mean\"]))))) + (np.tanh((data[\"t_sum_log\"]))))\/2.0)))\/2.0)) +\n            ((((((4.0)) * (np.where((((data[\"totals_pageviews\"]) > (data[\"totals_hits\"]))*1.)>0, data[\"t_sum_act\"], -3.0 )))) * 2.0)) +\n            (np.minimum(((((data[\"t_sum_log\"]) + ((-1.0*((data[\"t_nb_sess\"]))))))), ((np.where(np.tanh((data[\"t_mean\"]))>0, (-1.0*((data[\"t_nb_sess\"]))), -3.0 ))))) +\n            (((((((-3.0) + ((((11.04013633728027344)) * (data[\"t_sum_log\"]))))) + ((((-3.0) + (data[\"t_sum_log\"]))\/2.0)))) * 2.0)) +\n            (np.minimum(((np.tanh((np.tanh((data[\"totals_hits\"])))))), ((data[\"pred_1\"])))) +\n            ((((np.minimum(((np.tanh((((((data[\"pred_0\"]) * 2.0)) \/ 2.0))))), (((4.91354322433471680))))) + (-2.0))\/2.0)) +\n            (((-3.0) + (((data[\"t_sum_act\"]) * ((((13.85095119476318359)) - (-2.0))))))) +\n            (((((((((data[\"t_sum_log\"]) * 2.0)) * 2.0)) * 2.0)) * 2.0)) +\n            ((((((np.maximum(((np.minimum(((data[\"t_median\"])), ((data[\"geoNetwork_metro\"]))))), (((((data[\"t_mean\"]) > (data[\"t_sum_log\"]))*1.))))) + (-3.0))\/2.0)) + (data[\"t_mean\"]))) +\n            (np.minimum(((((1.0) * 2.0))), (((((-2.0) + (((0.0) + (data[\"trafficSource_referralPath\"]))))\/2.0))))) +\n            (((np.minimum(((data[\"t_sum_log\"])), ((0.0)))) + (np.minimum((((((data[\"t_mean\"]) + (data[\"totals_pageviews\"]))\/2.0))), ((data[\"t_mean\"])))))) +\n            ((((3.0) > (data[\"t_sum_act\"]))*1.)) +\n            ((((data[\"trafficSource_referralPath\"]) < (3.0))*1.)) +\n            (((0.0) + (-1.0))) +\n            (np.minimum(((data[\"geoNetwork_metro\"])), (((13.91542816162109375))))) +\n            (((data[\"t_sum_act\"]) + (((-3.0) + (((data[\"t_nb_sess\"]) + (((data[\"t_sum_act\"]) + (data[\"t_sum_act\"]))))))))) +\n            ((-1.0*(((((data[\"t_nb_sess\"]) + (((((data[\"pred_1\"]) * (((((((data[\"t_mean\"]) > (data[\"t_sum_log\"]))*1.)) < (-1.0))*1.)))) * 2.0)))\/2.0))))) +\n            (((data[\"t_median\"]) + (((((((data[\"t_median\"]) + (((data[\"totals_pageviews\"]) + (-1.0))))) - (data[\"trafficSource_referralPath\"]))) + (-1.0))))) +\n            (((((0.0) + (((((((data[\"t_mean\"]) < (data[\"trafficSource_referralPath\"]))*1.)) > (1.0))*1.)))) * (-3.0))) +\n            (((data[\"totals_pageviews\"]) - ((((data[\"visitNumber\"]) + (((((data[\"totals_hits\"]) - ((-1.0*((data[\"t_nb_sess\"])))))) * 2.0)))\/2.0)))) +\n            (((((((data[\"geoNetwork_metro\"]) - (((((10.93749332427978516)) > (((data[\"t_sum_log\"]) * 2.0)))*1.)))) - (np.tanh((data[\"geoNetwork_metro\"]))))) * (data[\"geoNetwork_metro\"]))) +\n            (((data[\"t_nb_sess\"]) * (data[\"channelGrouping\"]))) +\n            (((-2.0) + (0.0))) +\n            ((((-1.0) > (1.0))*1.)) +\n            (((((-3.0) + (0.0))) + (-3.0))) +\n            (((((data[\"totals_hits\"]) - (np.where(data[\"pred_1\"] < -99998, 1.0, data[\"totals_pageviews\"] )))) + (((data[\"totals_hits\"]) - (data[\"totals_pageviews\"]))))) +\n            (((((data[\"t_mean\"]) * ((((data[\"geoNetwork_continent\"]) + ((-1.0*((data[\"geoNetwork_subContinent\"])))))\/2.0)))) * (2.0))) +\n            (np.maximum(((data[\"t_sum_act\"])), ((data[\"visitNumber\"])))) +\n            ((((data[\"totals_hits\"]) < (3.0))*1.)) +\n            (np.minimum((((((data[\"t_median\"]) + (data[\"visitNumber\"]))\/2.0))), ((np.minimum(((data[\"t_sum_act\"])), ((data[\"totals_hits\"]))))))) +\n            (np.maximum(((data[\"totals_hits\"])), ((((data[\"geoNetwork_continent\"]) \/ 2.0))))) +\n            (np.maximum(((-3.0)), ((np.maximum(((data[\"geoNetwork_continent\"])), ((data[\"t_nb_sess\"]))))))) +\n            ((((2.0) > (data[\"visitNumber\"]))*1.)) +\n            ((((((data[\"channelGrouping\"]) + (data[\"geoNetwork_continent\"]))) < ((((data[\"geoNetwork_continent\"]) > (((data[\"t_nb_sess\"]) - (data[\"channelGrouping\"]))))*1.)))*1.)) +\n            ((((-2.0) > (np.maximum(((((data[\"t_sum_log\"]) - ((2.97587943077087402))))), (((((data[\"pred_0\"]) + ((3.84451842308044434)))\/2.0))))))*1.)) +\n            (np.minimum(((np.minimum(((data[\"geoNetwork_country\"])), ((((((((1.0)) - (data[\"geoNetwork_country\"]))) + ((((1.0)) - (data[\"geoNetwork_subContinent\"]))))\/2.0)))))), ((data[\"t_sum_act\"])))) +\n            (((((((10.0)) * (data[\"t_nb_sess\"]))) > (np.minimum((((3.0))), ((((data[\"geoNetwork_continent\"]) * ((0.13566258549690247))))))))*1.)) +\n            ((((data[\"geoNetwork_continent\"]) > ((3.89537310600280762)))*1.)) +\n            (np.minimum(((data[\"t_mean\"])), ((2.0)))) +\n            (np.minimum(((np.minimum(((-3.0)), ((((data[\"t_sum_log\"]) - (data[\"t_median\"]))))))), ((((data[\"t_sum_log\"]) + (data[\"t_sum_act\"])))))) +\n            (((data[\"totals_pageviews\"]) - (data[\"t_mean\"]))) +\n            (np.maximum(((1.0)), ((data[\"t_sum_act\"])))) +\n            (np.where(0.0<0, data[\"geoNetwork_metro\"], data[\"visitNumber\"] )) +\n            (((data[\"visitNumber\"]) * (data[\"geoNetwork_continent\"]))) +\n            ((((0.0) < (data[\"geoNetwork_subContinent\"]))*1.)) +\n            (np.minimum((((((-3.0) + ((((data[\"t_sum_log\"]) + (data[\"geoNetwork_subContinent\"]))\/2.0)))\/2.0))), ((((data[\"t_sum_act\"]) - (np.minimum(((data[\"t_sum_log\"])), ((data[\"t_mean\"]))))))))) +\n            (np.minimum(((3.0)), ((data[\"geoNetwork_metro\"])))) +\n            (((-3.0) * (((data[\"t_median\"]) * (-1.0))))) +\n            (((2.0) * ((((9.0)) * ((9.0)))))) +\n            (np.minimum(((np.minimum(((data[\"t_median\"])), ((data[\"t_sum_log\"]))))), (((((((data[\"totals_hits\"]) - (data[\"visitNumber\"]))) + (((data[\"totals_hits\"]) + (data[\"totals_hits\"]))))\/2.0))))))\n\ndef GP2(data):\n    return ((((((np.tanh((data[\"totals_hits\"]))) + (data[\"pred_1\"]))) * 2.0)) +\n            ((((8.08461284637451172)) - (data[\"t_sum_log\"]))) +\n            ((((np.tanh((data[\"t_sum_log\"]))) + (((data[\"t_sum_log\"]) + (data[\"t_mean\"]))))\/2.0)) +\n            (((((data[\"t_sum_log\"]) + (0.0))) + (data[\"t_sum_act\"]))) +\n            (np.minimum(((data[\"t_nb_sess\"])), (((((-2.0) + (3.0))\/2.0))))) +\n            (((data[\"geoNetwork_continent\"]) + (data[\"t_sum_log\"]))) +\n            (np.minimum(((data[\"t_sum_act\"])), ((np.maximum((((5.0))), ((data[\"t_sum_act\"]))))))) +\n            (((data[\"totals_hits\"]) * (((data[\"t_sum_act\"]) - ((8.14568805694580078)))))) +\n            (((data[\"t_sum_act\"]) + (data[\"pred_3\"]))) +\n            ((-1.0*(((-1.0*((data[\"t_sum_act\"]))))))) +\n            (np.maximum(((((3.0) - (-2.0)))), ((3.0)))) +\n            (np.maximum(((-2.0)), ((data[\"t_sum_log\"])))) +\n            (((((data[\"t_sum_act\"]) * 2.0)) * ((1.0)))) +\n            (((data[\"t_sum_log\"]) + (data[\"t_sum_log\"]))) +\n            (((data[\"pred_1\"]) - ((5.53632402420043945)))) +\n            ((((data[\"t_sum_log\"]) < (data[\"geoNetwork_metro\"]))*1.)) +\n            (((data[\"pred_1\"]) * (1.0))) +\n            (np.maximum(((data[\"totals_pageviews\"])), (((-1.0*((np.tanh((0.0))))))))) +\n            (((((((0.0)) * (-3.0))) > (-1.0))*1.)) +\n            (np.maximum(((data[\"totals_pageviews\"])), ((-2.0)))) +\n            (((data[\"t_sum_log\"]) * (data[\"t_sum_log\"]))) +\n            (np.minimum(((3.0)), ((data[\"t_sum_log\"])))) +\n            (((np.maximum(((data[\"visitNumber\"])), ((3.0)))) - (data[\"t_mean\"]))) +\n            (((data[\"t_sum_log\"]) - ((14.92182254791259766)))) +\n            (np.maximum(((data[\"t_median\"])), ((3.0)))) +\n            ((((3.0) > (data[\"t_mean\"]))*1.)) +\n            (((((data[\"geoNetwork_subContinent\"]) * 2.0)) * 2.0)) +\n            (((np.where(1.0<0, np.tanh((data[\"pred_1\"])), data[\"t_nb_sess\"] )) * (((data[\"t_sum_act\"]) * 2.0)))) +\n            (((data[\"t_sum_act\"]) * (data[\"t_sum_act\"]))) +\n            (((-3.0) + (data[\"t_sum_log\"]))) +\n            ((((9.0)) * (((-2.0) + (data[\"t_sum_act\"]))))) +\n            (((((((7.23600816726684570)) * (data[\"geoNetwork_continent\"]))) > ((1.63156664371490479)))*1.)) +\n            ((((data[\"t_sum_log\"]) < (1.0))*1.)) +\n            (((data[\"t_sum_act\"]) * ((((((((7.0)) - (data[\"t_sum_act\"]))) * (((((7.0)) > (data[\"t_sum_act\"]))*1.)))) * (data[\"t_sum_act\"]))))) +\n            (((((((3.0) > (data[\"pred_0\"]))*1.)) > (((np.maximum(((np.minimum(((2.0)), ((data[\"visitNumber\"]))))), ((((data[\"t_median\"]) * 2.0))))) \/ 2.0)))*1.)) +\n            (((((2.0) * (data[\"geoNetwork_subContinent\"]))) + (((((data[\"t_sum_act\"]) + (((data[\"t_sum_act\"]) - (data[\"pred_0\"]))))) * (data[\"t_sum_act\"]))))) +\n            (np.minimum((((((data[\"t_sum_act\"]) < (data[\"pred_1\"]))*1.))), ((data[\"geoNetwork_metro\"])))) +\n            (((data[\"geoNetwork_continent\"]) + (data[\"t_mean\"]))) +\n            (np.maximum((((((((data[\"totals_hits\"]) * 2.0)) + (-2.0))\/2.0))), ((((data[\"visitNumber\"]) + (1.0)))))) +\n            ((((((data[\"t_sum_act\"]) + ((((data[\"t_mean\"]) + (data[\"pred_1\"]))\/2.0)))\/2.0)) + ((((((data[\"pred_1\"]) + (data[\"t_sum_act\"]))\/2.0)) - (data[\"visitNumber\"]))))) +\n            (np.minimum((((((10.0)) - (data[\"t_sum_log\"])))), ((((((((data[\"geoNetwork_continent\"]) * 2.0)) * (data[\"t_sum_act\"]))) * (data[\"geoNetwork_continent\"])))))) +\n            (np.minimum(((data[\"geoNetwork_subContinent\"])), (((((((((data[\"geoNetwork_subContinent\"]) + (-3.0))) - (2.0))) + (data[\"t_sum_log\"]))\/2.0))))) +\n            (((((((data[\"t_sum_log\"]) \/ 2.0)) + (data[\"t_nb_sess\"]))) + (((((-3.0) + (data[\"t_sum_act\"]))) + (data[\"t_sum_act\"]))))) +\n            ((((np.tanh((((((np.tanh((np.tanh((np.minimum(((data[\"geoNetwork_country\"])), ((data[\"geoNetwork_country\"])))))))) * 2.0)) * 2.0)))) + ((7.0)))\/2.0)) +\n            (np.where(np.minimum(((2.0)), (((((-1.0) > (-2.0))*1.))))>0, data[\"geoNetwork_subContinent\"], (-1.0*(((5.0)))) )) +\n            (((data[\"geoNetwork_metro\"]) + (np.where(data[\"geoNetwork_metro\"]>0, data[\"geoNetwork_metro\"], data[\"t_sum_act\"] )))) +\n            ((((((6.0)) \/ 2.0)) - ((((((-3.0) + (data[\"visitNumber\"]))) < (np.tanh((data[\"totals_pageviews\"]))))*1.)))) +\n            (((data[\"t_nb_sess\"]) + (((data[\"t_sum_log\"]) + (((np.where(data[\"t_sum_log\"] < -99998, data[\"t_mean\"], data[\"t_sum_log\"] )) - (3.0))))))) +\n            ((((data[\"t_median\"]) + (((np.maximum((((((data[\"geoNetwork_metro\"]) + (-1.0))\/2.0))), ((-2.0)))) * (data[\"t_sum_act\"]))))\/2.0)) +\n            ((((((data[\"t_median\"]) * (data[\"t_sum_act\"]))) + (np.tanh((((np.minimum(((-1.0)), ((2.0)))) + (data[\"t_sum_act\"]))))))\/2.0)) +\n            (np.maximum(((data[\"visitNumber\"])), ((np.minimum(((data[\"totals_hits\"])), ((data[\"t_mean\"]))))))) +\n            (np.where(data[\"t_median\"]<0, ((data[\"t_median\"]) * 2.0), ((data[\"t_sum_act\"]) * 2.0) )) +\n            ((((((np.minimum(((np.minimum(((3.0)), ((data[\"totals_pageviews\"]))))), ((data[\"t_mean\"])))) + (data[\"totals_pageviews\"]))\/2.0)) * 2.0)) +\n            (np.maximum(((data[\"totals_hits\"])), ((np.maximum((((((((data[\"totals_pageviews\"]) + (data[\"t_mean\"]))) + (data[\"t_sum_log\"]))\/2.0))), ((data[\"t_sum_act\"]))))))) +\n            (((((np.where(data[\"t_sum_log\"]<0, data[\"pred_1\"], data[\"geoNetwork_metro\"] )) + (np.tanh((np.tanh((data[\"t_sum_log\"]))))))) * 2.0)) +\n            (((np.minimum(((((data[\"geoNetwork_metro\"]) - (data[\"channelGrouping\"])))), (((((13.51332950592041016)) * (data[\"t_sum_log\"])))))) * 2.0)) +\n            ((((-1.0*((data[\"geoNetwork_country\"])))) \/ 2.0)) +\n            ((((np.tanh((((data[\"pred_1\"]) + ((((1.0) > (data[\"channelGrouping\"]))*1.)))))) > ((((data[\"t_sum_act\"]) + (data[\"t_nb_sess\"]))\/2.0)))*1.)) +\n            (((data[\"t_sum_log\"]) + (((data[\"t_sum_log\"]) + (((data[\"t_sum_log\"]) + (((data[\"t_sum_act\"]) + (data[\"t_sum_act\"]))))))))) +\n            (((((data[\"totals_pageviews\"]) + (((data[\"totals_pageviews\"]) - (3.0))))) + (((data[\"t_sum_log\"]) - (data[\"t_sum_act\"]))))) +\n            (((data[\"trafficSource_referralPath\"]) - (np.maximum((((2.04302835464477539))), ((0.0)))))) +\n            ((((data[\"geoNetwork_continent\"]) + (data[\"totals_pageviews\"]))\/2.0)) +\n            (np.minimum((((12.72106933593750000))), ((((data[\"geoNetwork_continent\"]) - (data[\"device_browser\"])))))) +\n            (((np.minimum(((((data[\"t_sum_log\"]) * ((4.04873085021972656))))), ((((data[\"totals_pageviews\"]) - (np.minimum(((data[\"totals_hits\"])), ((data[\"totals_hits\"]))))))))) * ((4.04873085021972656)))) +\n            (((3.0) + (data[\"geoNetwork_metro\"]))) +\n            ((((-2.0) < (np.minimum((((4.73788738250732422))), ((data[\"t_median\"])))))*1.)) +\n            (np.minimum(((-1.0)), ((np.minimum(((0.0)), ((3.0))))))) +\n            (((np.maximum((((0.0))), ((-3.0)))) * (((((((2.0) > (data[\"t_median\"]))*1.)) > (0.0))*1.)))) +\n            (np.minimum((((((data[\"geoNetwork_metro\"]) > ((4.0)))*1.))), ((np.minimum(((data[\"t_mean\"])), ((data[\"t_sum_log\"]))))))) +\n            (((np.minimum((((((6.11185455322265625)) * (((np.tanh((data[\"t_median\"]))) - ((-1.0*((data[\"t_sum_act\"]))))))))), ((data[\"t_sum_log\"])))) + (data[\"totals_hits\"]))) +\n            ((((np.minimum(((data[\"t_nb_sess\"])), ((-3.0)))) > (1.0))*1.)) +\n            (((((((np.tanh(((-1.0*((data[\"pred_1\"])))))) + (data[\"trafficSource_referralPath\"]))\/2.0)) < (0.0))*1.)) +\n            (((data[\"t_sum_act\"]) * ((((data[\"t_sum_act\"]) < ((7.0)))*1.)))) +\n            (((data[\"t_sum_log\"]) + (np.minimum(((data[\"t_mean\"])), ((((data[\"channelGrouping\"]) * (data[\"t_mean\"])))))))) +\n            (np.maximum((((((data[\"totals_hits\"]) > (0.0))*1.))), ((data[\"totals_pageviews\"])))) +\n            ((((data[\"geoNetwork_continent\"]) > (((data[\"device_browser\"]) + (((data[\"trafficSource_referralPath\"]) * ((((data[\"pred_0\"]) > (data[\"t_nb_sess\"]))*1.)))))))*1.)) +\n            (np.where(data[\"t_mean\"]<0, data[\"totals_pageviews\"], data[\"geoNetwork_metro\"] )) +\n            (((data[\"totals_pageviews\"]) - (np.maximum(((-1.0)), ((data[\"totals_hits\"])))))) +\n            ((((data[\"t_mean\"]) < (data[\"totals_pageviews\"]))*1.)) +\n            ((((1.0)) + ((((data[\"t_median\"]) + (1.0))\/2.0)))) +\n            ((((np.minimum(((((data[\"pred_0\"]) * (((np.minimum(((data[\"t_median\"])), (((-1.0*((data[\"device_browser\"]))))))) * 2.0))))), ((-2.0)))) + (data[\"totals_hits\"]))\/2.0)) +\n            (np.minimum(((data[\"pred_0\"])), ((data[\"t_median\"])))) +\n            (np.minimum(((((data[\"t_sum_act\"]) * (np.minimum(((((data[\"geoNetwork_subContinent\"]) - (data[\"geoNetwork_country\"])))), ((data[\"geoNetwork_subContinent\"]))))))), ((((data[\"geoNetwork_country\"]) - (data[\"trafficSource_referralPath\"])))))) +\n            (((3.0) - (data[\"geoNetwork_metro\"]))) +\n            (((np.maximum(((((data[\"pred_0\"]) * (data[\"pred_0\"])))), ((data[\"channelGrouping\"])))) * (((data[\"t_nb_sess\"]) * (data[\"t_nb_sess\"]))))) +\n            ((((-2.0) > ((((0.0) < (data[\"t_median\"]))*1.)))*1.)) +\n            (np.maximum(((np.maximum(((data[\"trafficSource_referralPath\"])), ((np.maximum(((((data[\"geoNetwork_subContinent\"]) + (((data[\"t_nb_sess\"]) + (data[\"geoNetwork_continent\"])))))), ((data[\"channelGrouping\"])))))))), ((data[\"trafficSource_referralPath\"])))) +\n            (np.minimum(((np.maximum(((data[\"trafficSource_referralPath\"])), ((data[\"t_nb_sess\"]))))), (((((((data[\"t_sum_log\"]) + (data[\"t_mean\"]))\/2.0)) + (data[\"t_sum_act\"])))))) +\n            ((((((data[\"totals_pageviews\"]) + (data[\"geoNetwork_city\"]))) < (2.0))*1.)) +\n            (np.minimum(((data[\"t_sum_act\"])), ((1.0)))) +\n            (((-1.0) - (3.0))) +\n            ((((((((((12.32176685333251953)) > ((((data[\"geoNetwork_metro\"]) + (data[\"geoNetwork_metro\"]))\/2.0)))*1.)) + (data[\"channelGrouping\"]))\/2.0)) * (np.minimum(((data[\"t_mean\"])), ((data[\"geoNetwork_metro\"])))))) +\n            (((np.minimum(((data[\"visitNumber\"])), ((data[\"trafficSource_source\"])))) * 2.0)) +\n            (((1.0) * (data[\"device_browser\"]))) +\n            ((((((-1.0*((2.0)))) + (((-2.0) + (1.0))))) \/ 2.0)) +\n            (((((((((((data[\"t_nb_sess\"]) + ((6.0)))\/2.0)) - (data[\"t_nb_sess\"]))) + (data[\"geoNetwork_subContinent\"]))\/2.0)) + (data[\"t_nb_sess\"]))) +\n            ((((((data[\"t_sum_act\"]) * (data[\"totals_pageviews\"]))) < (data[\"pred_0\"]))*1.)) +\n            (((((((data[\"t_median\"]) - (data[\"totals_hits\"]))) + (data[\"geoNetwork_subContinent\"]))) + (((data[\"geoNetwork_subContinent\"]) + (((data[\"geoNetwork_subContinent\"]) + (data[\"geoNetwork_country\"]))))))) +\n            (np.minimum(((data[\"geoNetwork_subContinent\"])), ((data[\"geoNetwork_metro\"])))) +\n            ((((np.minimum(((data[\"t_median\"])), ((data[\"t_sum_log\"])))) + (data[\"totals_hits\"]))\/2.0)))","c0f7e274":"xtrain = GP1(gp_trn_users).values\nytrain = GP2(gp_trn_users).values\nxtrain = np.sign(xtrain)*np.log1p(np.abs(xtrain))\nytrain = np.sign(ytrain)*np.log1p(np.abs(ytrain))\nxtest = GP1(gp_sub_users).values\nytest = GP2(gp_sub_users).values\nxtest = np.sign(xtest)*np.log1p(np.abs(xtest))\nytest = np.sign(ytest)*np.log1p(np.abs(ytest))\ndel gp_sub_users\ndel gp_trn_users\ngc.collect()","ff5b1b77":"cm = plt.cm.get_cmap('RdYlGn')\nfig, axes = plt.subplots(1, 1, figsize=(15, 15))\nsc = axes.scatter(xtrain,\n                  ytrain,\n                  alpha=.1,\n                  c=np.log1p(trn_user_target.values.ravel()),\n                  cmap=cm,\n                  s=30)\ncbar = fig.colorbar(sc, ax=axes)\ncbar.set_label('Target')\n_ = axes.set_title(\"Clustering colored by target\")","2f964b1b":"fig, axes = plt.subplots(1, 1, figsize=(15, 15))\nsc = axes.scatter(xtest,\n                  ytest,\n                  alpha=.1,\n                  s=30)\n_ = axes.set_title(\"Clustering test\")","8cc063ba":"full_data['gp1'] = xtrain\nfull_data['gp2'] = ytrain\nsub_full_data['gp1'] = xtest\nsub_full_data['gp2'] = ytest","bc3a9821":"folds = get_folds(df=full_data[['totals.pageviews']].reset_index(), n_splits=5)\n\noof_preds = np.zeros(full_data.shape[0])\nsub_preds = np.zeros(sub_full_data.shape[0])\nvis_importances = pd.DataFrame()\n\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = full_data.iloc[trn_], trn_user_target['target'].iloc[trn_]\n    val_x, val_y = full_data.iloc[val_], trn_user_target['target'].iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.03,\n        n_estimators=1000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(trn_x, np.log1p(trn_y)), (val_x, np.log1p(val_y))],\n        eval_names=['TRAIN', 'VALID'],\n        early_stopping_rounds=50,\n        eval_metric='rmse',\n        verbose=100\n    )\n    \n    imp_df = pd.DataFrame()\n    imp_df['feature'] = trn_x.columns\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    vis_importances = pd.concat([vis_importances, imp_df], axis=0, sort=False)\n    \n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_preds[oof_preds < 0] = 0\n    \n    # Make sure features are in the same order\n    _preds = reg.predict(sub_full_data[full_data.columns], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_preds += _preds \/ len(folds)\n    \nmean_squared_error(np.log1p(trn_user_target['target']), oof_preds) ** .5","a54aff48":"vis_importances['gain_log'] = np.log1p(vis_importances['gain'])\nmean_gain = vis_importances[['gain', 'feature']].groupby('feature').mean()\nvis_importances['mean_gain'] = vis_importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 25))\nsns.barplot(x='gain_log', y='feature', data=vis_importances.sort_values('mean_gain', ascending=False).iloc[:300])","96c82c71":"sub_full_data['PredictedLogRevenue'] = sub_preds\nsub_full_data[['PredictedLogRevenue']].to_csv('new_test.csv', index=True)","580e7645":"### Save predictions","8190316f":"### Create target at Visitor level","beb53bae":"### Predict revenues at session level","752107f6":"### Train a model at Visitor level","8c0ec59b":"### Define folding strategy","534578c1":"### Display feature importances","36876cf5":"### Add date features\n\nOnly add the one I think can ganeralize","9886abe1":"### Factorize categoricals","9cfbff44":"### Get the extracted data","1051697a":"### Create user level predictions","6f9126c2":"### Create features list","00356168":"### Get session target","401fe8b8":"### Introduction\n\nIn this kernel I demonstrate how to create predictions at Session level and then use them at User level so that LighGBM can learn how to better sum individual session prediction. \n\nIt is sort of mini stacker and to avoid leakage, we use GroupKFold strategy.\n","37801582":"### Display feature importances"}}