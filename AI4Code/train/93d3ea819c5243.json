{"cell_type":{"474869a8":"code","5ed138a9":"code","b31328a6":"code","ee377c9c":"code","2ad601ec":"code","615c3186":"code","cdd3b87e":"code","5e43adc6":"code","9e3d9fc5":"code","fc213f1f":"code","3bf8f268":"code","4d75fa2a":"code","5f89aa23":"code","2f111c23":"code","8f864ef9":"code","da8c758d":"code","48d4cd90":"code","3cc8cd28":"code","e55e6351":"code","8695aa8a":"code","844107b2":"markdown","e902ae76":"markdown","dec71ecb":"markdown","72c94eac":"markdown","cc6c373f":"markdown","50af530a":"markdown","408589dd":"markdown","471a5a4c":"markdown","7beb95d1":"markdown","f57e3f16":"markdown","2167a1e4":"markdown","a3144e6b":"markdown","bdf4c4ee":"markdown","81408d4d":"markdown"},"source":{"474869a8":"from skimage import io\nimport os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.simplefilter('ignore')","5ed138a9":"DATASET_PATH = '..\/input\/x-ray-report\/X-Ray Report\/'\n\n# There are two classes of images that we will deal with\ndisease_cls = ['effusion', 'nofinding']","b31328a6":"effusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[0])\n\nnormal_path = os.path.join(DATASET_PATH, disease_cls[1], '*')\nnormal = glob.glob(normal_path)\nnormal = io.imread(normal[0])\n\nf, axes = plt.subplots(1, 2, sharey=True)\nf.set_figwidth(10)\n    \naxes[0].imshow(effusion, cmap='gray')\naxes[1].imshow(normal, cmap='gray')\nplt.show()","ee377c9c":"effusion.shape","2ad601ec":"normal.shape","615c3186":"from skimage.transform import rescale\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    width_shift_range=0,\n    height_shift_range=0,\n    vertical_flip=False,)\n\ndef preprocess_img(img, mode):\n    img = (img - img.min())\/(img.max() - img.min())\n    img = rescale(img, 0.25, multichannel=True, mode='constant')\n    \n    if mode == 'train':\n        if np.random.randn() > 0:\n            img = datagen.random_transform(img)\n    return img","cdd3b87e":"import six\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input,\n    Activation,\n    Dense,\n    Flatten,\n    add,\n    BatchNormalization,\n    Conv2D,\n    MaxPooling2D,\n    AveragePooling2D\n)\n\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K\n\n\ndef _bn_relu(input):\n    \"\"\"Helper to build a BN -> relu block\n    \"\"\"\n    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n    return Activation(\"relu\")(norm)\n\n\ndef _conv_bn_relu(**conv_params):\n    \"\"\"Helper to build a conv -> BN -> relu block\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(input)\n        return _bn_relu(conv)\n\n    return f\n\n\ndef _bn_relu_conv(**conv_params):\n    \"\"\"Helper to build a BN -> relu -> conv block.\n    This is an improved scheme proposed in http:\/\/arxiv.org\/pdf\/1603.05027v2.pdf\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        activation = _bn_relu(input)\n        return Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(activation)\n\n    return f\n\n\ndef _shortcut(input, residual):\n    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n    \"\"\"\n    # Expand channels of shortcut to match residual.\n    # Stride appropriately to match residual (width, height)\n    # Should be int if network architecture is correctly configured.\n    input_shape = K.int_shape(input)\n    residual_shape = K.int_shape(residual)\n    stride_width = int(round(input_shape[ROW_AXIS] \/ residual_shape[ROW_AXIS]))\n    stride_height = int(round(input_shape[COL_AXIS] \/ residual_shape[COL_AXIS]))\n    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n\n    shortcut = input\n    # 1 X 1 conv if shape is different. Else identity.\n    if stride_width > 1 or stride_height > 1 or not equal_channels:\n        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n                          kernel_size=(1, 1),\n                          strides=(stride_width, stride_height),\n                          padding=\"valid\",\n                          kernel_initializer=\"he_normal\",\n                          kernel_regularizer=l2(0.0001))(input)\n\n    return add([shortcut, residual])\n\n\ndef _residual_block(block_function, filters, repetitions, is_first_layer=False):\n    \"\"\"Builds a residual block with repeating bottleneck blocks.\n    \"\"\"\n    def f(input):\n        for i in range(repetitions):\n            init_strides = (1, 1)\n            if i == 0 and not is_first_layer:\n                init_strides = (2, 2)\n            input = block_function(filters=filters, init_strides=init_strides,\n                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n        return input\n\n    return f\n\n\ndef basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n    Follows improved proposed scheme in http:\/\/arxiv.org\/pdf\/1603.05027v2.pdf\n    \"\"\"\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n                           strides=init_strides,\n                           padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=l2(1e-4))(input)\n        else:\n            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n                                  strides=init_strides)(input)\n\n        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n        return _shortcut(input, residual)\n\n    return f\n\n\ndef bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Bottleneck architecture for > 34 layer resnet.\n    Follows improved proposed scheme in http:\/\/arxiv.org\/pdf\/1603.05027v2.pdf\n    Returns:\n        A final conv layer of filters * 4\n    \"\"\"\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n                              strides=init_strides,\n                              padding=\"same\",\n                              kernel_initializer=\"he_normal\",\n                              kernel_regularizer=l2(1e-4))(input)\n        else:\n            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n                                     strides=init_strides)(input)\n\n        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n        return _shortcut(input, residual)\n\n    return f\n\n\ndef _handle_dim_ordering():\n    global ROW_AXIS\n    global COL_AXIS\n    global CHANNEL_AXIS\n    #if K.image_dim_ordering() == 'tf':\n    ROW_AXIS = 1\n    COL_AXIS = 2\n    CHANNEL_AXIS = 3\n    #else:\n    #CHANNEL_AXIS = 1\n    #ROW_AXIS = 2\n    #COL_AXIS = 3\n\n\ndef _get_block(identifier):\n    if isinstance(identifier, six.string_types):\n        res = globals().get(identifier)\n        if not res:\n            raise ValueError('Invalid {}'.format(identifier))\n        return res\n    return identifier\n\n\nclass ResnetBuilder(object):\n    @staticmethod\n    def build(input_shape, num_outputs, block_fn, repetitions):\n        \"\"\"Builds a custom ResNet like architecture.\n        Args:\n            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n            num_outputs: The number of outputs at final softmax layer\n            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n                The original paper used basic_block for layers < 50\n            repetitions: Number of repetitions of various block units.\n                At each block unit, the number of filters are doubled and the input size is halved\n        Returns:\n            The keras `Model`.\n        \"\"\"\n        _handle_dim_ordering()\n        if len(input_shape) != 3:\n            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n\n        # Permute dimension order if necessary\n        # if K.image_dim_ordering() == 'tf':\n        input_shape = (input_shape[1], input_shape[2], input_shape[0])\n\n        # Load function from str if needed.\n        block_fn = _get_block(block_fn)\n\n        input = Input(shape=input_shape)\n        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n\n        block = pool1\n        filters = 64\n        for i, r in enumerate(repetitions):\n            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n            filters *= 2\n\n        # Last activation\n        block = _bn_relu(block)\n\n        # Classifier block\n        block_shape = K.int_shape(block)\n        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n                                 strides=(1, 1))(block)\n        flatten1 = Flatten()(pool2)\n        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n                      activation=\"softmax\")(flatten1)\n\n        model = Model(inputs=input, outputs=dense)\n        return model\n\n    @staticmethod\n    def build_resnet_18(input_shape, num_outputs):\n        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n\n    @staticmethod\n    def build_resnet_34(input_shape, num_outputs):\n        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n\n    @staticmethod\n    def build_resnet_50(input_shape, num_outputs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n\n    @staticmethod\n    def build_resnet_101(input_shape, num_outputs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n\n    @staticmethod\n    def build_resnet_152(input_shape, num_outputs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])","5e43adc6":"img_channels = 1\nimg_rows = 256\nimg_cols = 256\n\nnb_classes = 2","9e3d9fc5":"import numpy as np\nimport tensorflow as tf\n\nclass AugmentedDataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, mode='train', ablation=None, disease_cls = ['nofinding', 'effusion'], \n                 batch_size=32, dim=(256, 256), n_channels=1, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = {}\n        self.list_IDs = []\n        self.mode = mode\n        \n        for i, cls in enumerate(disease_cls):\n            paths = glob.glob(os.path.join(DATASET_PATH, cls, '*'))\n            brk_point = int(len(paths)*0.8)\n            if self.mode == 'train':\n                paths = paths[:brk_point]\n            else:\n                paths = paths[brk_point:]\n            if ablation is not None:\n                paths = paths[:int(len(paths)*ablation\/100)]\n            self.list_IDs += paths\n            self.labels.update({p:i for p in paths})\n        \n            \n        self.n_channels = n_channels\n        self.n_classes = len(disease_cls)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        \n        delete_rows = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            img = io.imread(ID)\n            img = img[:, :, np.newaxis]\n            if img.shape == (1024, 1024,1):\n                img = preprocess_img(img, self.mode)\n                X[i,] = img\n                y[i] = self.labels[ID]\n            else:\n                delete_rows.append(i)\n                continue\n                \n        X = np.delete(X, delete_rows, axis=0)\n        y = np.delete(y, delete_rows, axis=0)\n        \n        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)","fc213f1f":"model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=5, validation_data=validation_generator)","3bf8f268":"model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=5, validation_data=None)","4d75fa2a":"from sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import *\n\nclass roc_callback(Callback):\n    \n    def on_train_begin(self, logs={}):\n        logs['val_auc'] = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_p = []\n        y_v = []\n        for i in range(len(validation_generator)):\n            x_val, y_val = validation_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc'] = roc_auc","5f89aa23":"model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=20)\nvalidation_generator = AugmentedDataGenerator('val', ablation=20)\n\nauc_logger = roc_callback()\n\nmodel.fit(training_generator, epochs=5, validation_data=validation_generator, callbacks=[auc_logger])","2f111c23":"from functools import partial\nimport tensorflow.keras.backend as K\nfrom itertools import product\n\ndef w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    cross_ent = K.categorical_crossentropy(y_true, y_pred, from_logits=False)\n    return cross_ent * final_mask\n\nbin_weights = np.ones((2,2))\nbin_weights[0, 1] = 5\nbin_weights[1, 0] = 5\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'","8f864ef9":"model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss=ncce, optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=1, validation_data=None)","da8c758d":"class DecayLR(tf.keras.callbacks.Callback):\n    def __init__(self, base_lr=0.01, decay_epoch=1):\n        super(DecayLR, self).__init__()\n        self.base_lr = base_lr\n        self.decay_epoch = decay_epoch \n        self.lr_history = []\n        \n    def on_train_begin(self, logs={}):\n        K.set_value(self.model.optimizer.lr, self.base_lr)\n\n    def on_epoch_end(self, epoch, logs={}):\n        new_lr = self.base_lr * (0.5 ** (epoch \/\/ self.decay_epoch))\n        self.lr_history.append(K.get_value(self.model.optimizer.lr))\n        K.set_value(self.model.optimizer.lr, new_lr)","48d4cd90":"model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\nsgd = optimizers.SGD(lr=0.005)\n\nbin_weights = np.ones((2,2))\nbin_weights[0, 1] = 5\nbin_weights[1, 0] = 5\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'\n\nmodel.compile(loss=ncce,optimizer= sgd,\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=550)\nvalidation_generator = AugmentedDataGenerator('val', ablation=550)\n\nauc_logger = roc_callback()\nfilepath = '\/best_model.hdf5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n\ndecay = DecayLR()\n\nmodel.fit(training_generator, epochs=50, validation_data=validation_generator, callbacks=[auc_logger, decay, checkpoint])","3cc8cd28":"val_model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)","e55e6351":"effusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[-8])\nplt.imshow(effusion,cmap='gray')\nplt.show()","8695aa8a":"img = preprocess_img(effusion[:, :, np.newaxis], 'validation')\nval_model.predict(img[np.newaxis,:])","844107b2":"## 5. Making a Prediction","e902ae76":"Next, we read the \"effusion\" and \"nofinding\" images.","dec71ecb":"In the previous notebook, you learnt about Ablation. Briefly, an ablation run is when you systematically modify certain parts of the input, in order to observe the equivalent change in the input.\n\nFor the following section, we'll be using the Data Generator concept that you previously worked on.","72c94eac":"## 4. Final Run","cc6c373f":"Neural networks have revolutionised image processing in several different domains. Among these is the field of medical imaging. In the following notebook, we will get some hands-on experience in working with Chest X-Ray (CXR) images.\n\nThe objective of this exercise is to identify images where an \"effusion\" is present. This is a classification problem, where we will be dealing with two classes - 'effusion' and 'nofinding'. Here, the latter represents a \"normal\" X-ray image.\n\nThis same methodology can be used to spot various other illnesses that can be detected via a chest x-ray. For the scope of this demonstration, we will specifically deal with \"effusion\".","50af530a":"## 2. Model building","408589dd":"Point a variable to the path where the data resides. Note that to use the code below you will need to move the folders effusion\/ and nofinding\/ into one common folder. You can do something like this:\n\n```\nmkdir CXR_Data\nmove effusion CXR_Data\nmove nofinding CXR_Data\n```","471a5a4c":"## 1. Data Pre-processing","7beb95d1":"### Data Augmentation ###\n\nNow that we have read the images, the next step is data augmentation. We use the concept of a \"data generator\" that you learnt in the last section.","f57e3f16":"We will be using a Resnet in this (you learnt about Resnets previously). \n\nFor this to work, the script that defines the resnet model (resnet.py) should reside in the same folder as this notebook","2167a1e4":"## 3. Ablation Run","a3144e6b":"# Analysis of Chest X-Ray images","bdf4c4ee":"After deeply examining our data and building some preliminary models, we are finally ready to build a model that will perform our prediction task.","81408d4d":"Our data is in the form of grayscale (black and white) images of chest x-rays. To perform our classification task effectively, we need to perform some pre-processing of the data.\n\nFirst, we load all the relevant libraries."}}