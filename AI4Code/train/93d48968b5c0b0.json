{"cell_type":{"24f9f67d":"code","b0ba3e9a":"code","68ec9244":"code","2d8b1795":"code","56621d2e":"code","3eee84c8":"code","7c96f476":"code","714dbb22":"code","ddfe2f8e":"code","35b98602":"code","809f4b52":"code","7b2395fa":"markdown","cbbafeaa":"markdown","766c8b31":"markdown","f29400a5":"markdown","46c7791b":"markdown","49d46ffa":"markdown"},"source":{"24f9f67d":"\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nSEED = 42\nnp.random.seed(SEED)","b0ba3e9a":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\n\nprint('Quick view of training data: ')\ntrain.head()","68ec9244":"TARGET = 'target'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\nprint(f'Training data:\\n\\t Number of rows: {train.shape[0]}, Number of columns: {train.shape[1]}')\nprint(f'Testing data:\\n\\t Number of rows: {test.shape[0]}, Number of columns: {test.shape[1]}')","2d8b1795":"print('Basic statistics of training data:')\ntrain[FEATURES+[TARGET]].describe().style.background_gradient(cmap=\"Greens\")","56621d2e":"print('Basic statistics of testing data:')\ntest[FEATURES].describe().style.background_gradient(cmap=\"Greens\")","3eee84c8":"print(f'Number of missing values in training data: {train.isna().sum().sum()}')\nprint(f'Number of missing values in testing data: {test.isna().sum().sum()}')","7c96f476":"df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)\n\ncat_features = [col for col in FEATURES if df[col].nunique() < 10]\ncont_features = [col for col in FEATURES if df[col].nunique() >= 10]\n\ndel df\n\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'categorical features: {len(cat_features)}')\nprint(f'continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#2E8B57', '#8FBC8F'],\n        textprops={'fontsize': 15},\n        autopct='%1.1f%%')\nplt.show()","714dbb22":"print(\"Feature distribution of continous features: \")\nncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(FEATURES) % ncols > 0))\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 150), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.kdeplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data')\n        sns.kdeplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\nplt.show()","ddfe2f8e":"print(\"Feature distribution of continous features: \")\nncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(FEATURES) % ncols > 0))\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 150), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.boxplot(y=train[col], ax=axes[r, c], color='#58D68D')\n        sns.boxplot(y=test[col], ax=axes[r, c], color='#DE3163')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\nplt.show()","35b98602":"print(\"Target Distribution: \")\n\ntarget = pd.DataFrame(train[TARGET].value_counts()).reset_index()\ntarget.columns = [TARGET, 'count']\n\nfig, ax = plt.subplots(1, 1, figsize=(25, 8), facecolor='#EAEAF2')\nsns.barplot(y=TARGET, x='count', data=target, palette=['#58D68D', '#DE3163'], ax=ax, orient='h')\nax.set_xlabel('Count', fontsize=16)\nax.set_ylabel('Target', fontsize=16)\nplt.show()","809f4b52":"#As a test, draw both bivariate and univariate KDEs\n\nsns.jointplot(train['target'],train['f1'],x ='target', y ='f1',color = '#ff355d', kind = \"kde\")     \nplt.show()","7b2395fa":"# **<span style=\"color:#228B22;\">Load Data<\/span>**","cbbafeaa":"# **<span style=\"color:#228B22;\">Import Module<\/span>**","766c8b31":"# **<U><span style=\"color:#F08080;\">Hope you get a basic understanding of your data with a simple EDA \ud83d\ude42<\/span><\/U>**","f29400a5":"# **<span style=\"color:#228B22;\">EDA<\/span>**","46c7791b":"<h1 style='background:#F0FFF0; border:2; color:black'><center>Simple and Easy EDA \ud83d\udc81<\/center><\/h1>","49d46ffa":"The purpose of this notebook is to quickly and easily show the EDA of this November competition.\n\n# **<span style=\"color:#228B22;\">Data<\/span>**\n\nFor this competition, you will be predicting a binary target based on 100 feature columns given in the data. All columns are continuous.\n\nThe original dataset deals with predicting identifying spam emails via various extracted features from the email. Although the features are anonymized, they have properties relating to real-world features.\n\nThe data is synthetically generated by a GAN that was trained on a real-world dataset used to identify spam emails via various extracted features from the email.\n\n**Files**\n> - ``` train.csv``` -  the training data with the target column\n> - ```test.csv``` - the test set\n> - ```sample_submission.csv``` - a sample submission file in the correct format\n\n# **<span style=\"color:#228B22;\">Evaluation Metric<\/span>**\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target."}}