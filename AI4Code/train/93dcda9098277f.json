{"cell_type":{"295257fd":"code","3e659165":"code","1a631b9c":"code","0c647471":"code","50e9886d":"code","40ed1e88":"code","d554c618":"code","f79cc929":"code","d7507140":"code","e4fc3c2f":"code","eb396fcc":"code","529d43d2":"code","13880b9a":"code","a2045ca5":"code","263a7c50":"code","8d446073":"code","a1893ce0":"code","8868d535":"code","83c69a10":"code","2a0df6c6":"code","74cfe1c8":"code","7bb38446":"code","3c19865b":"code","aa5ae51e":"code","28fb7ba1":"code","80a79a84":"code","d6f35da6":"code","01c7f6b2":"code","3f6c1348":"code","aa0dd90d":"code","09959519":"code","c98b54c4":"code","3561e03b":"code","34810dda":"markdown","dbd8623a":"markdown","95ede9b7":"markdown","b4e38aa0":"markdown","a719fec7":"markdown","4fa6b5ee":"markdown","275a1544":"markdown","41fed28b":"markdown"},"source":{"295257fd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport keras\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","3e659165":"train = pd.read_csv('..\/input\/nfl-big-data-bowl-2020\/train.csv', dtype={'WindSpeed': 'object'})\nprint(train.shape)\ntrain.head()","1a631b9c":"#https:\/\/www.kaggle.com\/rooshroosh\/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])\/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x\/15))\n    except:\n        return \"nan\"","0c647471":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four\/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","50e9886d":"%%time\ntrain = preprocess(train)","40ed1e88":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","d554c618":"pd.to_pickle(train, \"train.pkl\")","f79cc929":"def drop(train):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\"] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n    drop_cols += [\"Orientation\", \"Dir\", 'WindSpeed', \"GameClock\"]\n    train = train.drop(drop_cols, axis = 1)\n    return train","d7507140":"train = drop(train)","e4fc3c2f":"un_use_features = ['G_HomeTeamAbbr',\n 'G_PossessionTeam',\n 'G_RusherTeam',\n 'G_StadiumType',\n 'G_diffScoreBeforePlay_binary_ob',\n 'P_DefenseDB',\n 'P_DefenseDL',\n 'P_DefenseLB',\n 'P_DefenseOL',\n 'P_GameWeather_dense',\n 'P_IsRusher',\n 'P_IsRusherTeam',\n 'P_OffenseDB',\n 'P_OffenseDL',\n 'P_OffenseLB',\n 'P_OffenseOL',\n 'P_OffenseQB',\n 'P_OffenseTE',\n 'P_OffenseWR',\n 'P_PlayerAge_ob',\n 'P_Quarter',\n 'P_Week']\n\nun_use_features += ['G_Down_ob',\n 'G_FieldPosition',\n 'G_OffenseRB',\n 'G_TimeDelta',\n 'G_VisitorTeamAbbr',\n 'G_WindDirection',\n 'P_GameClock_sec',\n 'P_HomeScoreBeforePlay',\n 'P_Humidity',\n 'P_Orientation_ob',\n 'P_PlayerHeight',\n 'P_Temperature',\n 'P_VisitorScoreBeforePlay',\n 'P_WindSpeed_dense',\n 'P_diffScoreBeforePlay']\n\n## delete prefix\nun_use_features = [c[2:] for c in un_use_features]\ntrain = train.drop(un_use_features, axis = 1)","eb396fcc":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))\ndense_features.remove(\"PlayId\")\ndense_features.remove(\"Yards\")","529d43d2":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","13880b9a":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","a2045ca5":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","263a7c50":"eps = 1e-8\n## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() <= eps]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() > eps]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() <= eps]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() > eps]","8d446073":"dense_game_feature_names = [\"G_\" + cc for cc in dense_game_features]\ndense_player_feature_names = list(np.hstack([[\"P_\" + c for c in dense_player_features] for k in range(22)]))\ncat_game_feature_names = [\"G_\" + cc for cc in cat_game_features]\ncat_player_feature_names = list(np.hstack([[\"P_\" + c for c in cat_player_features] for k in range(22)]))","a1893ce0":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","8868d535":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\ntrain_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y = np.vstack(train_y_raw.apply(return_step).values)","83c69a10":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","2a0df6c6":"## concat all features\ntrain_dense_players = np.reshape(train_dense_players, (len(train_dense_players), -1))\ntrain_dense = np.hstack([train_dense_players, train_dense_game])\n\ntrain_cat_players = np.reshape(train_cat_players, (len(train_cat_players), -1))\ntrain_cat = np.hstack([train_cat_players, train_cat_game])\n\ntrain_x = np.hstack([train_dense, train_cat])","74cfe1c8":"from lightgbm import LGBMClassifier\nclass MultiLGBMClassifier():\n    def __init__(self, resolution, params):\n        ## smoothing size\n        self.resolution = resolution\n        ## initiarize models\n        self.models = [LGBMClassifier(**params) for _ in range(resolution)]\n        \n    def fit(self, x, y):\n        self.classes_list = []\n        for k in tqdm_notebook(range(self.resolution)):\n            ## train each model\n            self.models[k].fit(x, (y + k) \/\/ self.resolution)\n            ## (0,1,2,3,4,5,6,7,8,9) -> (0,0,0,0,0,1,1,1,1,1) -> (0,5)\n            classes = np.sort(list(set((y + k) \/\/ self.resolution))) * self.resolution - k\n            classes = np.append(classes, 999)\n            self.classes_list.append(classes)\n            \n    def predict(self, x):\n        pred199_list = []\n        for k in range(self.resolution):\n            preds = self.models[k].predict_proba(x)\n            classes = self.classes_list[k]\n            pred199s = self.get_pred199(preds, classes)\n            pred199_list.append(pred199s)\n        self.pred199_list = pred199_list\n        pred199_ens = np.mean(np.stack(pred199_list), axis = 0)\n        return pred199_ens\n    \n    def _get_pred199(self, p, classes):\n        ## categorical prediction -> predicted distribution whose length is 199\n        pred199 = np.zeros(199)\n        for k in range(len(p)):\n            pred199[classes[k] + 99 : classes[k+1] + 99] = p[k]\n        return pred199\n\n    def get_pred199(self, preds, classes):\n        pred199s = []\n        for p in preds:\n            pred199 = np.cumsum(self._get_pred199(p, classes))\n            pred199 = pred199\/np.max(pred199)\n            pred199s.append(pred199)\n        return np.vstack(pred199s)","7bb38446":"params = {'num_leaves': 35, 'max_depth': 5, # 2**5 = 32 - Let's set num_leaves=35\n 'subsample': 0.4, 'min_child_samples': 10,\n 'learning_rate': 0.01,\n 'num_iterations': 500, 'random_state': 12}","3c19865b":"from sklearn.model_selection import train_test_split, KFold\nlosses = []\nmodels = []\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model = MultiLGBMClassifier(resolution = 5, params = params)\n        model.fit(train_x[tr_inds], train_y_raw.values[tr_inds])\n        preds = model.predict(train_x[val_inds])\n        loss = np.mean((train_y[val_inds] - preds) ** 2)\n        models.append(model)\n        print(k_fold, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","aa5ae51e":"print(losses)\nprint(np.mean(losses))","28fb7ba1":"feature_importances = 0\nnum_model = 0\nfor model in models:\n    for m in model.models:\n        feature_importances += m.booster_.feature_importance(\"gain\")\n        num_model += 1\n\nfeature_importances \/= num_model","80a79a84":"feature_names = dense_player_feature_names + dense_game_feature_names + cat_game_feature_names + cat_player_feature_names\nfeature_importance_df = pd.DataFrame(np.vstack([feature_importances, feature_names]).T, columns = [\"importance\", \"name\"])\nfeature_importance_df[\"importance\"] = feature_importance_df[\"importance\"].astype(np.float32)\nfeature_importance_df = feature_importance_df.groupby(\"name\").agg(\"mean\").reset_index()","d6f35da6":"plt.figure(figsize = (8, 18))\nsns.barplot(data = feature_importance_df.sort_values(by = \"importance\", ascending = False).head(50), x = \"importance\", y = \"name\")\nplt.show()","01c7f6b2":"plt.figure(figsize = (8, 18))\nsns.barplot(data = feature_importance_df.sort_values(by = \"importance\", ascending = False).tail(50), x = \"importance\", y = \"name\")\nplt.show()","3f6c1348":"## bad features\nlist(feature_importance_df[feature_importance_df[\"importance\"] < np.quantile(feature_importance_df[\"importance\"], 0.3)][\"name\"])","aa0dd90d":"def make_pred(test, sample, env, model):\n    test = preprocess(test)\n    test = drop(test)\n    test = test.drop(un_use_features, axis = 1)\n    \n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n            if not ((col + \"__nan\") in categories):\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n\n    test_dense_players = np.reshape(test_dense_players, (len(test_dense_players), -1))\n    test_dense = np.hstack([test_dense_players, test_dense_game])\n    test_cat_players = np.reshape(test_cat_players, (len(test_cat_players), -1))\n    test_cat = np.hstack([test_cat_players, test_cat_game])\n    test_x = np.hstack([test_dense, test_cat])\n\n    test_inp = test_x\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)\n        pred += _pred\n    pred \/= len(models)\n    pred = np.clip(pred, 0, 1)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","09959519":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","c98b54c4":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","3561e03b":"print(losses)\nprint(np.mean(losses))","34810dda":"## Divide features into groups","dbd8623a":"## Model","95ede9b7":"My experience (for example [Titanic (0.83253) - Comparison 20 popular models](https:\/\/www.kaggle.com\/vbmokin\/titanic-0-83253-comparison-20-popular-models)) has shown that simulation using LGBMClassifier is better if you set both parameter num_leaves and parameter max_depth","b4e38aa0":"## Prediction","a719fec7":"## categorical","4fa6b5ee":"## Dense","275a1544":"## Feature engineering","41fed28b":"Many thanks to:\n* https:\/\/www.kaggle.com\/mrkmakr\/lgbm-multiple-classifier\n* https:\/\/www.kaggle.com\/mrkmakr\/neural-network-with-mae-objective-0-01381\n* https:\/\/www.kaggle.com\/rooshroosh\/fork-of-neural-networks-different-architecture"}}