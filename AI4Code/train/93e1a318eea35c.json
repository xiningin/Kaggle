{"cell_type":{"ed4fb587":"code","c4516a98":"code","39a0bf74":"code","a03b9ddf":"code","ab7f6034":"code","48f73e85":"code","c56c0a85":"code","b3375738":"code","b4752af8":"code","92b67c47":"code","038be1ce":"code","e41d2ab4":"code","ec2993d4":"code","6aee4cb0":"code","2080220e":"code","aff44a9f":"code","1bc95695":"code","0d5c5864":"code","4f745e03":"code","2377d310":"code","f3d496cb":"code","7cc63ebe":"code","095ee2f0":"code","9f8b39ab":"code","d13f15c9":"code","3c5c3cb9":"code","6af1cc0a":"code","33efb83f":"code","52f73577":"markdown","c56bc9f4":"markdown","9af7c844":"markdown","520d05ed":"markdown","5dddd07a":"markdown","d83c3777":"markdown","4fa4b548":"markdown","2ac471ac":"markdown","7452771d":"markdown","2ccf769b":"markdown","39a2010c":"markdown"},"source":{"ed4fb587":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4516a98":"train_targets_scored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_nonscored.csv\")\ntrain_features = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\")\ntest_features = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\")\nsample_submission = pd.read_csv(\"..\/input\/lish-moa\/sample_submission.csv\")","39a0bf74":"train_features.shape","a03b9ddf":"train_features","ab7f6034":"train_features['sig_id'].nunique()","48f73e85":"train_features.cp_type.value_counts()","c56c0a85":"train_features.cp_time.value_counts()","b3375738":"train_features.cp_dose.value_counts()","b4752af8":"train_targets_scored.head()","92b67c47":"train_targets_scored.sum()[1:].sort_values()","038be1ce":"train_features[:2]","e41d2ab4":"gs = train_features[:1][[col for col in train_features.columns if 'g-' in col]].values.reshape(-1, 1)","ec2993d4":"import matplotlib.pyplot as plt\nplt.plot(gs)","6aee4cb0":"plt.plot(sorted(gs))","2080220e":"train_features['c-0'].plot(kind='hist')","aff44a9f":"!pip install iterative-stratification","1bc95695":"import pandas as pd\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\ndf = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ndf.loc[:, \"kfold\"] = -1\ndf = df.sample(frac=1).reset_index(drop=True)\ntargets = df.drop('sig_id', axis=1).values","0d5c5864":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor fold_, (trn_, val_) in enumerate(mskf.split(X=df, y=targets)):\n    df.loc[val_, \"kfold\"] = fold_\n\ndf.to_csv(\"train_folds.csv\", index=False)","4f745e03":"import torch\nimport torch.nn","2377d310":"class MoaDataset:\n    def __init__(self, dataset, features):\n        self.dataset = dataset\n        self.features = features\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, item):\n        return {\n            \"x\": torch.tensor(self.dataset[item, :], dtype=torch.float),\n            \"y\": torch.tensor(self.features[item, :], dtype=torch.float)\n        }","f3d496cb":"class Engine:\n#     Model, optimizer, and device are fixed, \n#     thus, they are in the init function\n    def __init__(self, model, optimizer, device):\n        self.model = model\n        self.optimizer = optimizer\n        self.device = device\n    \n    @staticmethod\n    def loss_fn(targets, outputs):\n        return nn.BCEWithLogitsLoss()(outputs, targets)\n#     data (batches) can change, thus, data, and model..., \n#     are in different functions\n    def train(self, data_loader):\n        self.model.train()\n        final_loss = 0\n        for data in data_loader:\n            self.optimizer.zero_grad()\n            inputs = data[\"x\"].to(self.device)\n            targets = data[\"y\"].to(self.device)\n            outputs = self.model(inputs)\n            loss = self.loss_fn(targets, outputs)\n            loss.backward()\n            self.optimizer.step()\n            final_loss += loss.item()\n        return final_loss \/ len(data_loader)\n\n#     validation\n    def validate(self, data_loader):\n        self.model.eval()\n        final_loss = 0\n        for data in data_loader:\n            inputs = data[\"x\"].to(self.device)\n            targets = data[\"y\"].to(self.device)\n            outputs = self.model(inputs)\n            loss = self.loss_fn(targets, outputs)\n            final_loss += loss.item()\n        return final_loss \/ len(data_loader)","7cc63ebe":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nUSE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n    print('using device: cuda')\nelse:\n    print('using device: cpu')","095ee2f0":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(num_features, 256),\n            nn.BatchNormalization(256),\n            nn.Dropout(0.3),\n            nn.Linear(num_features, 256),\n            nn.BatchNormalization(256),\n            nn.Dropout(0.3),\n            nn.Linear(num_features, 256),\n            nn.BatchNormalization(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_targets)\n        )\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","9f8b39ab":"DEVICE = \"cuda\"\nEPOCHS = 100","d13f15c9":"def add_dummies(data, column):\n    ohe = pd.get_dummies(data[column])\n    ohe_columns = [f\"{column}_{c}\" for c in ohe.columns]\n    ohe.columns = ohe_columns\n    data = data.drop(column, axis=1)\n    data = data.join(ohe)\n    return data","3c5c3cb9":"def process_data(df):\n    df = add_dummies(df, \"cp_time\")\n    df = add_dummies(df, \"cp_dose\")\n    df = add_dummies(df, \"cp_type\")\n    return df","6af1cc0a":"def run_training(fold):\n    df = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\")\n    df = process_data(df)\n    folds = pd.read_csv(\"..\/working\/train_folds.csv\")\n    \n    targets = folds.drop([\"sig_id\", \"kfold\"], axis=1).columns\n    features = df.drop(\"sig_id\", axis=1).columns\n    \n    df = df.merge(folds, on=\"sig_id\", how=\"left\")\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    x_train = train_df[features].to_array()\n    x_valid = valid_df[features].to_array()\n                     \n    y_train = train_df[features].to_array()\n    y_valid = valid_df[targets].to_array()\n    \n    train_dataset = MoaDataset(x_train, y_train)\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=1024, num_workers=8\n    )\n                     \n    valid_dataset = MoaDataset(x_valid, y_valid)\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset, batch_size=1024, num_workers=8\n    )\n    model = utils.ModelX(\n        num_features = x_train.shape[1],\n        num_targets = y_train.shape[1],\n        num_layers = params[\"num_layers\"],\n        hidden_size = params[\"hidden_size\"],\n        dropout =  params[\"dropout\"]\n    )\n    model.to(DEVICE)\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, patience=3, threshold=0.00001, mode=\"min\", verbose=True)\n                     \n    eng = Engine(\n        model, optimizer, device=DEVICE\n    )\n    best_loss = np.inf\n    early_stopping = 10\n    early_stopping_counter = 0\n    for _ in range(EPOCHS):\n        train_loss = engine.train(train_loader)\n        valid_loss = engine.train(valid_loader)\n        scheduler.step(valid_loss)\n        print(f\"{fold}, {epoch}, {train_loss}, {valid_loss}\")\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            if save_model:\n                torch.save(model.state_dict(), f\"model{fold}.bin\")\n        else:\n            early_stopping_counter += 1\n        if early_stopping_counter > early_stopping:\n            break\n    return best_loss","33efb83f":"import optuna\nclass ModelX(nn.Module):\n    def __init__(self, num_features, num_targets, num_layers, hidden_size, dropout):\n        super().__init__()\n        layers = []\n        for _ in range(num_layers):\n            if len(layers) == 0:\n                layers.append(nn.Linear(num_features, hidden_size))\n                layers.append(nn.BatchNorm1d(hidden_size))\n                layers.append(nn.Dropout(dropout))\n                nn.ReLU()\n            else:\n                layers.append(nn.Linear(hidden_size, hidden_size))\n                layers.append(nn.BatchNorm1d(hidden_size))\n                layers.append(nn.Dropout(dropout))\n                nn.ReLU()\n        layers.append(nn.Linear(hidden_size, num_targets))\n        self.model = nn.Sequential(*layers)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","52f73577":"Submission","c56bc9f4":"3 types of time","9af7c844":"Check if number of unique Ids is equal to the row number","520d05ed":"2 types of cp_type","5dddd07a":"> Split the data\n>> It is a multi-label classification problem, thus, to choose how to split based off of that","d83c3777":"Neural Networks is chosen coz of the fact that we should predict on different targets at the same time. ","4fa4b548":"In case of the usage of any kind of different boosting algorithms like LightGBM, XGBoost, then we have to build the model for each of the >200 targets. Thus, Neural Nets","2ac471ac":"Pytorch Model","7452771d":"Check data distribution in c columns","2ccf769b":"2 types of dose","39a2010c":"Model"}}