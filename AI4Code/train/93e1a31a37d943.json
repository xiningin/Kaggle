{"cell_type":{"c13ccd00":"code","8c95b5d1":"code","d7045a25":"code","968a47d7":"code","3991f8d2":"code","090ef1db":"code","a2bfccb7":"code","9a90d6b3":"code","0ebe666a":"code","9edf68ff":"code","55c5c176":"code","dd09e3d7":"code","7db8ec4c":"code","32b1e409":"code","dc38aeba":"code","44526e55":"code","9636c683":"code","8055efd4":"code","77bae78f":"code","b9674d3e":"code","1e3f2e22":"code","6f1f1bf2":"code","8fe0b55a":"code","81831b35":"code","81e0d615":"code","c0a8d9f9":"code","b8818d33":"code","fad02ddf":"code","78b54cb0":"code","dcb8dbd7":"code","e3d8969c":"code","1e722db3":"code","0af4220a":"code","ad064722":"code","b1f0890f":"code","dc3268e6":"code","492b785a":"code","20296ce3":"code","14ed6ccd":"code","25ebc1fd":"code","41933eab":"code","ce81f9d3":"code","c3851745":"code","d9bff931":"code","8952bf3a":"code","0bcb4122":"code","0f16217a":"code","ee86c503":"code","afe167b1":"code","3fbd1577":"code","67204ed7":"code","335d6c02":"code","02c378ab":"code","c231bb89":"code","db2b3c44":"code","d4bd00e0":"code","ab1318eb":"code","9fc9cb3a":"code","8fc977aa":"code","9eef841d":"code","123b32cf":"code","cbb27c64":"markdown"},"source":{"c13ccd00":"import numpy as np\nimport pandas as pd \nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n!pip install lightgbm\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.simplefilter(action = \"ignore\") ","8c95b5d1":"import pandas as pd\ndf = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.head()","d7045a25":"df.shape","968a47d7":"df.info()","3991f8d2":"df.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T","090ef1db":"df[\"Outcome\"].value_counts()*100\/len(df)","a2bfccb7":"df.Outcome.value_counts()","9a90d6b3":"df[\"Age\"].hist(edgecolor = \"black\");\nprint(\"Max Age: \" + str(df[\"Age\"].max()) + \" Min Age: \" + str(df[\"Age\"].min()))","0ebe666a":"fig, ax = plt.subplots(4,2, figsize=(16,16))\nsns.distplot(df.Age, bins = 20, ax=ax[0,0]) \nsns.distplot(df.Pregnancies, bins = 20, ax=ax[0,1]) \nsns.distplot(df.Glucose, bins = 20, ax=ax[1,0]) \nsns.distplot(df.BloodPressure, bins = 20, ax=ax[1,1]) \nsns.distplot(df.SkinThickness, bins = 20, ax=ax[2,0])\nsns.distplot(df.Insulin, bins = 20, ax=ax[2,1])\nsns.distplot(df.DiabetesPedigreeFunction, bins = 20, ax=ax[3,0]) \nsns.distplot(df.BMI, bins = 20, ax=ax[3,1]) ","9edf68ff":"df.groupby(\"Outcome\").agg({\"Pregnancies\":\"mean\"})","55c5c176":"df.groupby(\"Outcome\").agg({\"Age\":\"mean\"})","dd09e3d7":"\n\ndf.groupby(\"Outcome\").agg({\"Age\":\"max\"})\n","7db8ec4c":"df.groupby(\"Outcome\").agg({\"Insulin\": \"mean\"})","32b1e409":"df.groupby(\"Outcome\").agg({\"Glucose\": \"mean\"})","dc38aeba":"df.groupby(\"Outcome\").agg({\"Glucose\": \"max\"})","44526e55":"df.groupby(\"Outcome\").agg({\"BMI\": \"mean\"})","9636c683":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf['Outcome'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('target')\nax[0].set_ylabel('')\nsns.countplot('Outcome',data=df,ax=ax[1])\nax[1].set_title('Outcome')\nplt.show()","8055efd4":"df.corr()","77bae78f":"f, ax = plt.subplots(figsize= [20,15])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()\n\ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","b9674d3e":"df.head()","1e3f2e22":"df.isnull().sum()","6f1f1bf2":"import missingno as msno\nmsno.bar(df);","8fe0b55a":"def median_target(var):   \n    temp = df[df[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","81831b35":"columns = df.columns\ncolumns = columns.drop(\"Outcome\")\nfor i in columns:\n    median_target(i)\n    df.loc[(df['Outcome'] == 0 ) & (df[i].isnull()), i] = median_target(i)[i][0]\n    df.loc[(df['Outcome'] == 1 ) & (df[i].isnull()), i] = median_target(i)[i][1]\n    \ndf.head()","81e0d615":"df.isnull().sum()","c0a8d9f9":"for feature in df:\n    \n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3-Q1\n    lower = Q1- 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","b8818d33":"import seaborn as sns\nsns.boxplot(x = df[\"Insulin\"]);\n\nQ1 = df.Insulin.quantile(0.25)\nQ3 = df.Insulin.quantile(0.75)\nIQR = Q3-Q1\nlower = Q1 - 1.5*IQR\nupper = Q3 + 1.5*IQR\ndf.loc[df[\"Insulin\"] > upper,\"Insulin\"] = upper","fad02ddf":"import seaborn as sns\nsns.boxplot(x = df[\"Insulin\"]);\n\n\nfrom sklearn.neighbors import LocalOutlierFactor\nlof =LocalOutlierFactor(n_neighbors= 10)\nlof.fit_predict(df)","78b54cb0":"df_scores = lof.negative_outlier_factor_\nnp.sort(df_scores)[0:30]\n\n\nthreshold = np.sort(df_scores)[7]\nthreshold\n\n\noutlier = df_scores > threshold\ndf = df[outlier]\n\n\nNewBMI = pd.Series([\"Underweight\", \"Normal\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"], dtype = \"category\")\ndf[\"NewBMI\"] = NewBMI\ndf.loc[df[\"BMI\"] < 18.5, \"NewBMI\"] = NewBMI[0]\ndf.loc[(df[\"BMI\"] > 18.5) & (df[\"BMI\"] <= 24.9), \"NewBMI\"] = NewBMI[1]\ndf.loc[(df[\"BMI\"] > 24.9) & (df[\"BMI\"] <= 29.9), \"NewBMI\"] = NewBMI[2]\ndf.loc[(df[\"BMI\"] > 29.9) & (df[\"BMI\"] <= 34.9), \"NewBMI\"] = NewBMI[3]\ndf.loc[(df[\"BMI\"] > 34.9) & (df[\"BMI\"] <= 39.9), \"NewBMI\"] = NewBMI[4]\ndf.loc[df[\"BMI\"] > 39.9 ,\"NewBMI\"] = NewBMI[5]\n\n\ndf.head()","dcb8dbd7":"def set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166:\n        return \"Normal\"\n    else:\n        return \"Abnormal\"\n\n\ndf = df.assign(NewInsulinScore=df.apply(set_insulin, axis=1))\n\ndf.head()","e3d8969c":"NewGlucose = pd.Series([\"Low\", \"Normal\", \"Overweight\", \"Secret\", \"High\"], dtype = \"category\")\ndf[\"NewGlucose\"] = NewGlucose\ndf.loc[df[\"Glucose\"] <= 70, \"NewGlucose\"] = NewGlucose[0]\ndf.loc[(df[\"Glucose\"] > 70) & (df[\"Glucose\"] <= 99), \"NewGlucose\"] = NewGlucose[1]\ndf.loc[(df[\"Glucose\"] > 99) & (df[\"Glucose\"] <= 126), \"NewGlucose\"] = NewGlucose[2]\ndf.loc[df[\"Glucose\"] > 126 ,\"NewGlucose\"] = NewGlucose[3]\n\n\ndf.head()","1e722db3":"df = pd.get_dummies(df, columns =[\"NewBMI\",\"NewInsulinScore\", \"NewGlucose\"], drop_first = True)\n\ndf.head()","0af4220a":"categorical_df = df[['NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret']]\n\ncategorical_df.head()","ad064722":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\",'NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret'], axis = 1)\ncols = X.columns\nindex = X.index\n\n\nX.head()","b1f0890f":"from sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(X)\nX = transformer.transform(X)\nX = pd.DataFrame(X, columns = cols, index = index)\n\nX.head()","dc3268e6":"X = pd.concat([X,categorical_df], axis = 1)\n\n\nX.head()\n\n\ny.head()","492b785a":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\nmodels.append(('SVM', SVC(gamma='auto', random_state = 12345)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\n\n# her modeli s\u0131rayla de\u011ferlendirin\nresults = []\nnames = []\n","20296ce3":"for name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)","14ed6ccd":"# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\nrf_params = {\"n_estimators\" :[100,200,500,1000], \n             \"max_features\": [3,5,7], \n             \"min_samples_split\": [2,5,10,30],\n            \"max_depth\": [3,5,8,None]}","25ebc1fd":"rf_model = RandomForestClassifier(random_state = 12345)","41933eab":"gs_cv = GridSearchCV(rf_model, \n                    rf_params,\n                    cv = 10,\n                    n_jobs = -1,\n                    verbose = 2).fit(X, y)\n\ngs_cv.best_params_","ce81f9d3":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)","c3851745":"rf_tuned = rf_tuned.fit(X,y)","d9bff931":"cross_val_score(rf_tuned, X, y, cv = 10).mean()","8952bf3a":"feature_imp = pd.Series(rf_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","0bcb4122":"lgbm = LGBMClassifier(random_state = 12345)","0f16217a":"lgbm_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n              \"n_estimators\": [500, 1000, 1500],\n              \"max_depth\":[3,5,8]}","ee86c503":"gs_cv = GridSearchCV(lgbm, \n                     lgbm_params, \n                     cv = 10, \n                     n_jobs = -1, \n                     verbose = 2).fit(X, y)","afe167b1":"gs_cv.best_params_","3fbd1577":"lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X,y)","67204ed7":"cross_val_score(lgbm_tuned, X, y, cv = 10).mean()","335d6c02":"feature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","02c378ab":"xgb = GradientBoostingClassifier(random_state = 12345)","c231bb89":"xgb_params = {\n    \"learning_rate\": [0.01, 0.1, 0.2, 1],\n    \"min_samples_split\": np.linspace(0.1, 0.5, 10),\n    \"max_depth\":[3,5,8],\n    \"subsample\":[0.5, 0.9, 1.0],\n    \"n_estimators\": [100,1000]}","db2b3c44":"xgb_cv_model  = GridSearchCV(xgb,xgb_params, cv = 10, n_jobs = -1, verbose = 2).fit(X, y)","d4bd00e0":"xgb_cv_model.best_params_","ab1318eb":"xgb_tuned = GradientBoostingClassifier(**xgb_cv_model.best_params_).fit(X,y)","9fc9cb3a":"cross_val_score(xgb_tuned, X, y, cv = 10).mean()","8fc977aa":"feature_imp = pd.Series(xgb_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","9eef841d":"models = []\n\nmodels.append(('RF', RandomForestClassifier(random_state = 12345, max_depth = 8, max_features = 7, min_samples_split = 2, n_estimators = 500)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345, learning_rate = 0.1, max_depth = 5, min_samples_split = 0.1, n_estimators = 100, subsample = 1.0)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345, learning_rate = 0.01,  max_depth = 3, n_estimators = 1000)))\n\n# evaluate each model in turn\nresults = []\nnames = []","123b32cf":"for name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# boxplot algorithm comparison\n\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","cbb27c64":"# Diabetes Prediction using Machine Learning\n## Diabetes, is a group of metabolic disorders in which there are high blood sugar levels over a prolonged period. Symptoms of high blood sugar include frequent urination, increased thirst, and increased hunger. If left untreated, diabetes can cause many complications. Acute complications can include diabetic ketoacidosis, hyperosmolar hyperglycemic state, or death. Serious long-term complications include cardiovascular disease, stroke, chronic kidney disease, foot ulcers, and damage to the eyes.\n\n## This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. \n# CONTEXT\n## This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n## This dataset consists several variables :\n\n## Pregnancies: Number of times pregnant\n## Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n## BloodPressure: Diastolic blood pressure (mm Hg)\n## SkinThickness: Triceps skin fold thickness (mm)\n## Insulin: 2-Hour serum insulin (mu U\/ml)\n## BMI: Body mass index (weight in kg\/(height in m)^2)\n## DiabetesPedigreeFunction: Diabetes pedigree function\n## Age: Age (years)\n## Outcome: Class variable (0 or 1)"}}