{"cell_type":{"08ae8cac":"code","b41b23be":"code","d86345c0":"code","8c26fb25":"code","ca69cd7f":"code","df25532e":"code","34ba58dc":"code","05e6a4b0":"code","116054bc":"code","b4653d5c":"code","6ef81c13":"code","e70b2fc8":"code","9db5e760":"code","cf61d7b9":"code","fd2a4b90":"code","67ae58cc":"code","dac2bb10":"code","a7fd2d9d":"code","489225d0":"code","2eeaafd4":"code","f2aeea86":"code","35509a9f":"code","62c9444c":"code","d89698c1":"code","7fb2c202":"code","d8631e8d":"code","dc83736e":"markdown","23c91658":"markdown","c5f7dd69":"markdown","4d035de2":"markdown","25299b01":"markdown","51c6a959":"markdown","c2b5efdd":"markdown","e7351001":"markdown","3c777c2d":"markdown","fe1b8892":"markdown","bce31eed":"markdown","bd5084dd":"markdown","17374464":"markdown","515f0b43":"markdown","54dade26":"markdown","71cd0eca":"markdown","860bd310":"markdown","7ac1f24b":"markdown","804d7662":"markdown","a1ccb201":"markdown","ac0b906a":"markdown"},"source":{"08ae8cac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b41b23be":"from pyspark.sql import SparkSession\nimport pyspark.sql as sparksql\nspark = SparkSession.builder.appName('stroke').getOrCreate()\ntrain = spark.read.csv('..\/input\/train_2v.csv', inferSchema=True,header=True)\ntest = spark.read.csv('..\/input\/test_2v.csv', inferSchema=True,header=True)","d86345c0":"train.printSchema()","8c26fb25":"train.dtypes","ca69cd7f":"train.head(5)","df25532e":"train.toPandas().head(5)","34ba58dc":"test.describe().show()","05e6a4b0":"train.groupBy('stroke').count().show()","116054bc":"# create DataFrame as a temporary view for SQL queries\ntrain.createOrReplaceTempView('table')","b4653d5c":"# sql query to find the number of people in specific work_type who have had stroke and not\nspark.sql(\"SELECT work_type, COUNT(work_type) as work_type_count FROM table WHERE stroke == 1 GROUP BY work_type ORDER BY COUNT(work_type) DESC\").show()\nspark.sql(\"SELECT work_type, COUNT(work_type) as work_type_count FROM table WHERE stroke == 0 GROUP BY work_type ORDER BY COUNT(work_type) DESC\").show()","6ef81c13":"spark.sql(\"SELECT gender, COUNT(gender) as gender_count, COUNT(gender)*100\/(SELECT COUNT(gender) FROM table WHERE gender == 'Male') as percentage FROM table WHERE stroke== 1 AND gender = 'Male' GROUP BY gender\").show()\nspark.sql(\"SELECT gender, COUNT(gender) as gender_count, COUNT(gender)*100\/(SELECT COUNT(gender) FROM table WHERE gender == 'Female') as percentage FROM table WHERE stroke== 1 AND gender = 'Female' GROUP BY gender\").show()","e70b2fc8":"spark.sql(\"SELECT COUNT(age)*100\/(SELECT COUNT(age) FROM table WHERE stroke ==1) as percentage FROM table WHERE stroke == 1 AND age>=50\").show()","9db5e760":"train.describe().show()","cf61d7b9":"# fill in missing values for smoking status\n# As this is categorical data, we will add one data type \"No Info\" for the missing one\ntrain_f = train.na.fill('No Info', subset=['smoking_status'])\ntest_f = test.na.fill('No Info', subset=['smoking_status'])","fd2a4b90":"# fill in miss values for bmi \n# as this is numecial data , we will simple fill the missing values with mean\nfrom pyspark.sql.functions import mean\nmean = train_f.select(mean(train_f['bmi'])).collect()\nmean_bmi = mean[0][0]\ntrain_f = train_f.na.fill(mean_bmi,['bmi'])\ntest_f = test_f.na.fill(mean_bmi,['bmi'])","67ae58cc":"train_f.describe().show()","dac2bb10":"test_f.describe().show()","a7fd2d9d":"# indexing all categorical columns in the dataset\nfrom pyspark.ml.feature import StringIndexer\nindexer1 = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\nindexer2 = StringIndexer(inputCol=\"ever_married\", outputCol=\"ever_marriedIndex\")\nindexer3 = StringIndexer(inputCol=\"work_type\", outputCol=\"work_typeIndex\")\nindexer4 = StringIndexer(inputCol=\"Residence_type\", outputCol=\"Residence_typeIndex\")\nindexer5 = StringIndexer(inputCol=\"smoking_status\", outputCol=\"smoking_statusIndex\")\n","489225d0":"# Doing one hot encoding of indexed data\nfrom pyspark.ml.feature import OneHotEncoderEstimator\nencoder = OneHotEncoderEstimator(inputCols=[\"genderIndex\",\"ever_marriedIndex\",\"work_typeIndex\",\"Residence_typeIndex\",\"smoking_statusIndex\"],\n                                 outputCols=[\"genderVec\",\"ever_marriedVec\",\"work_typeVec\",\"Residence_typeVec\",\"smoking_statusVec\"])","2eeaafd4":"from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=['genderVec',\n 'age',\n 'hypertension',\n 'heart_disease',\n 'ever_marriedVec',\n 'work_typeVec',\n 'Residence_typeVec',\n 'avg_glucose_level',\n 'bmi',\n 'smoking_statusVec'],outputCol='features')","f2aeea86":"from pyspark.ml.classification import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(labelCol='stroke',featuresCol='features')","35509a9f":"from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[indexer1, indexer2, indexer3, indexer4, indexer5, encoder, assembler, dtc])","62c9444c":"# splitting training and validation data\ntrain_data,val_data = train_f.randomSplit([0.7,0.3])\n\n# training model pipeline with data\nmodel = pipeline.fit(train_data)","d89698c1":"# making prediction on model with validation data\ndtc_predictions = model.transform(val_data)\n\n# Select example rows to display.\ndtc_predictions.select(\"prediction\",\"probability\", \"stroke\", \"features\").show(5)","7fb2c202":"from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n# Select (prediction, true label) and compute test error\nacc_evaluator = MulticlassClassificationEvaluator(labelCol=\"stroke\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndtc_acc = acc_evaluator.evaluate(dtc_predictions)\nprint('A Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))","d8631e8d":"# now predicting the labels for test data\ntest_pred = model.transform(test_f)\ntest_selected = test_pred.select(\"id\", \"features\", \"prediction\",\"probability\")\ntest_selected.limit(5).toPandas()","dc83736e":"Now there is no missing values, Lets work on categorical columns now...","23c91658":"So far we have kind of a complex task that contains bunch of stages, that need to be performed to process data. To wrap all of that Spark ML represents such a workflow as a Pipeline, which consists of a sequence of PipelineStages to be run in a specific order.","c5f7dd69":"1. Here we see that there are few missing values in *smoking_status* and *bmi* column\n2. Also there are few categorical data (*gender, ever_married, work_type, Residence_type, smoking_status* which we need to covert into one hot encoding","4d035de2":"StringIndexer -> OneHotEncoder -> VectorAssembler","25299b01":"It is mostly happening to private or self-employed person.","51c6a959":"Now we will see influence of age on stroke","c2b5efdd":"### Lets also look at test data","e7351001":"Is it related to gender !!!","3c777c2d":"Here we see that 91.5% stroke had occured for person who are more than 50 years old","fe1b8892":"### Lets look the the target distribution","bce31eed":"### Training feature analysis ","bd5084dd":"We are using Decision tree classifier for baseline model","17374464":"The next step is to create an assembler, that combines a given list of columns into a single vector column to train ML model. I will use the vector columns, that we got after one_hot_encoding.","515f0b43":"### Cleaning up training data","54dade26":"### Exploring the training data","71cd0eca":"1.68% male and almost 2% male had stroke.","860bd310":"As can be seen from this observation. This is an Imbalanced dataset, where the number of observations belonging to one class is significantly lower than those belonging to the other classes. In this case, the predictive model could be biased and inaccurate. There are different strategies to handling Imbalanced Datasets, We will look into it later.","7ac1f24b":"influence of work type on getting stroke","804d7662":"Now we will evaluate the model with validation data","a1ccb201":"The next step is to split dataset to train and test to train the model and make predictions.","ac0b906a":"### Baseline model"}}