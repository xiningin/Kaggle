{"cell_type":{"cea1494a":"code","cc61e1f5":"code","9e38638a":"code","837be9a6":"code","3427dd83":"code","33abec87":"code","d476caac":"code","e4548e9b":"code","9fc5e9b2":"code","a6fe65e3":"code","38737732":"code","d169d2d9":"markdown","299d7d83":"markdown","0611a3ce":"markdown","65057407":"markdown","c35ad321":"markdown","5bca6641":"markdown","003803ca":"markdown","b3d2d893":"markdown","b90c09e7":"markdown"},"source":{"cea1494a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\nimport tensorflow as tf\nimport os","cc61e1f5":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n    \nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'","9e38638a":"pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\ntype(pre_trained_model)","837be9a6":"# This model layers are long and complex\npre_trained_model.summary()","3427dd83":"# Freezing all layers to avoid modification of weights in pretrained model\nfor layer in pre_trained_model.layers:\n    layer.trainable = False","33abec87":"# Extract \"mixed7\" named layer\n# The name of the layer is according to the dimension (7x7) of the layer\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","d476caac":"# Making our own custom model\n\n# Flatten the output layer to 1 dimension\nx = tf.keras.layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = tf.keras.layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = tf.keras.layers.Dense(6, activation='softmax')(x)           \n\nmodel = tf.keras.Model(pre_trained_model.input, x) \n\nmodel.compile(\n    optimizer = RMSprop(lr=0.0001),\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)","e4548e9b":"training_images_path = '..\/input\/intel-image-classification\/seg_train\/seg_train'\nvalidation_images_path = '..\/input\/intel-image-classification\/seg_test\/seg_test'","9fc5e9b2":"# Defining training image generator with all the augmentation sample parameters\n# This ensures correct classification for different image in validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Defining validation image generator\n# We don't pass augmentation parameters as we model haven't seen this data earlier\nvalidation_generator = ImageDataGenerator(rescale=1\/255)\n\n# Loading training data from path\ntrain_generator = train_datagen.flow_from_directory(\n    training_images_path,\n    target_size=(150, 150),\n    batch_size=40,\n    class_mode='categorical'\n)\n\n# Loading validation data from path\nvalidation_generator = validation_generator.flow_from_directory(\n    validation_images_path,\n    target_size=(150, 150),\n    batch_size=40,\n    class_mode='categorical'\n)","a6fe65e3":"history = model.fit(\n    train_generator,\n    steps_per_epoch=350,\n    epochs=4,\n    verbose=1,\n    validation_data=validation_generator\n)","38737732":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","d169d2d9":"## Training Model","299d7d83":"## Importing Libraries","0611a3ce":"# Tensorflow Keras Tutorial - Using Pretrained Models and Multiclass Classification (Part 4)\n\n**What is Keras?** Keras is a wrapper that allows you to implement Deep Neural Network without getting into intrinsic details of the Network. It can use Tensorflow or Theano as backend. This tutorial series will cover Keras from beginner to intermediate level.\n\n\n<p style=\"color:red\">IF YOU HAVEN'T GONE THROUGH THE PART 1-3 OF THIS TUTORIAL, IT'S RECOMMENDED FOR YOU TO GO THROUGH THAT FIRST.<\/p>\n[LINK TO PART 1](https:\/\/www.kaggle.com\/akashkr\/tf-keras-tutorial-neural-network-part-1)<br>\n[LINK TO PART 2](https:\/\/www.kaggle.com\/akashkr\/tf-keras-tutorial-cnn-part-2)<br>\n[LINK TO PART 3](https:\/\/www.kaggle.com\/akashkr\/tf-keras-tutorial-binary-classification-part-3)\n","65057407":"## Loss and Accuracy\nLet's see the Loss and Accuracy graph for training and Validation Data","c35ad321":"## Defining Dataset Generator","5bca6641":"## Customizing the model\n\nTo make our custom model using the pretrained models, there are a few things that we need to take into account.\n1. Freeze the loaded model weights to ensure that the pretrained weights do not get modified while fitting our dataset\n2. Choose the appropriate layer for output\n3. Add few more layers which get trained as custom model\n4. Use dropouts in order to avoid overfitting in the model","003803ca":"**IN THE NEXT TUTORIAL WE WILL SEE APPLICATION OF NEURAL NETWORK IN NATURAL LANGUAGE PROCESSING.**\n\n> # PART 5 [Basics of NLP](https:\/\/www.kaggle.com\/akashkr\/tf-keras-tutorial-basics-of-nlp-part-5)","b3d2d893":"## Download Pre-trained Model","b90c09e7":"## Load Pretrained Model\nInceptionV3 is pretrained model on billons on image classified into thousands of classes. `InceptionV3` returns a skeleton of model and `load_weights` loads pretrained model weights into the skeleton.\n\n#### InceptionV3\n> * **input_shape** Shape of the input layer\n* **include_top** Whether to include the first dense layer in the model\n* **weights** Weight name to load"}}