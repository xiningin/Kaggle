{"cell_type":{"614921f0":"code","b18b3d4f":"code","30236b61":"code","9bd87635":"code","eb32a393":"code","309bedf2":"code","a65fe057":"code","3a6b0179":"code","393c7866":"code","1dc2316b":"code","6bb44f87":"code","d57ffefc":"code","1d4265b2":"code","24388d32":"code","6a9cd361":"code","69180e8b":"code","901e0b76":"code","e09c1c00":"code","4087a259":"code","276e6909":"code","daafff7d":"code","d8a5a831":"code","1c2a6c8b":"code","783d4701":"code","7500dd11":"code","68d060b9":"code","41460aab":"markdown","f426a33c":"markdown","5c451855":"markdown","41de4db4":"markdown","069255f9":"markdown","e1082996":"markdown","e2c7d2b8":"markdown","b1c6ca83":"markdown","920eebf1":"markdown","0a65fa7d":"markdown","49ea3a39":"markdown","af28e3ac":"markdown","9714943c":"markdown","712ceeb9":"markdown","573c4cf4":"markdown","9509675e":"markdown","20c224eb":"markdown"},"source":{"614921f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport sys\nimport shutil   \nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import History \nfrom sklearn.metrics import classification_report, confusion_matrix\nimport keras\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers import Dense\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b18b3d4f":"train = '\/kaggle\/input\/10-monkey-species\/training\/training\/'\nval = '\/kaggle\/input\/10-monkey-species\/validation\/validation\/'\nlabels = pd.read_csv(\"\/kaggle\/input\/10-monkey-species\/monkey_labels.txt\")\nlabels","30236b61":"# Total number of training images\nnum_of_train_samples = 0\nfor train_dataset in os.listdir(train):\n    in_folder = train + \"\/\" + train_dataset \n    in_folder_list = os.listdir(in_folder)\n    num_of_train_samples = num_of_train_samples + len(in_folder_list)\nprint(\"Number of Training samples   : \",num_of_train_samples)\n\n# Total number of validation images\nnum_of_validation_samples = 0\nfor validation_dataset in os.listdir(val):\n    in_folder_val = val + \"\/\" + validation_dataset\n    in_folder_val_list = os.listdir(in_folder_val)\n    num_of_validation_samples = num_of_validation_samples + len(in_folder_val_list)\nprint(\"Number of Validation samples : \", num_of_validation_samples)","9bd87635":"train_datagen = ImageDataGenerator(rescale=1. \/ 255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\nval_datagen = ImageDataGenerator(rescale=1. \/ 255)","eb32a393":"batch_size = 16\nlearning_rate = 0.0001\nepoch = 45\n\n# Defining image width and height respectively\nimg_rows = 256\nimg_cols = 256\n\ntrain_generator = train_datagen.flow_from_directory(train,\n                                                    target_size = (img_rows, img_cols),\n                                                    batch_size = batch_size,\n                                                    class_mode = 'categorical')\n\nvalidation_generator = val_datagen.flow_from_directory(val,\n                                                        target_size = (img_rows, img_cols),\n                                                        batch_size = batch_size,\n                                                        shuffle = False, class_mode='categorical')","309bedf2":"steps_per_epoch = num_of_train_samples \/\/ batch_size\nprint(\"Steps per epoch: \",steps_per_epoch)","a65fe057":"from keras.applications import ResNet50\n# The sequential API allows you to create models layer-by-layer\nresnet_model = Sequential()\nresnet_model.add(ResNet50(include_top=False, \n                   pooling='max', \n                   weights='imagenet'))\nresnet_model.add(Dense(10, activation=\"softmax\"))\n\n# Summary: to find the number of parameters\nresnet_model.layers[0].trainable=False\nresnet_model.summary()\n\nsgd = optimizers.SGD(lr=learning_rate, decay=0.00001,momentum = 0.0,nesterov=False)\nresnet_model.compile(loss=\"categorical_crossentropy\",\n              optimizer=sgd,\n              metrics=[\"accuracy\"])","3a6b0179":"# Trains the model for a given number of epochs (iterations on a dataset).\nresnet_training = resnet_model.fit_generator(train_generator,\n                               steps_per_epoch = steps_per_epoch,\n                               epochs = epoch,\n                               validation_data = validation_generator,\n                               validation_steps = num_of_validation_samples \/\/ batch_size)\n","393c7866":"training_accuracy_resnet      = resnet_training.history['accuracy'][-1]\ntraining_loss_resnet          = resnet_training.history['loss'][-1]\nvalidation_accuracy_resnet    = resnet_training.history['val_accuracy'][-1]\nvalidation_loss_resnet        = resnet_training.history['val_loss'][-1]\nprint(\"Training Accuracy ResNet   :\", training_accuracy_resnet )\nprint(\"Training Loss ResNet       :\", training_loss_resnet)\nprint(\"Validation Accuracy ResNet :\", validation_accuracy_resnet)\nprint(\"Validation Loss ResNet     :\", validation_loss_resnet)","1dc2316b":"# Generating Confusion Matrix and Classification Report\nY_pred_res = resnet_model.predict_generator(validation_generator, num_of_validation_samples \/\/ batch_size+1)\ny_pred_res = np.argmax(Y_pred_res, axis=1)\nprint('Confusion Matrix')\nconf_matrix_res = confusion_matrix(validation_generator.classes, y_pred_res)\ncm_res = np.array2string(conf_matrix_res)\nprint(conf_matrix_res)\nprint(\"=============================================================================================\")\nprint('Classification Report')\ntarget_names = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']\nclass_rep_res = classification_report(validation_generator.classes, y_pred_res, target_names=target_names)\nprint(class_rep_res)","6bb44f87":"epoch_inc = 30\nlearning_rate_inc = 0.001\nbatch_size_inc = 32\nsteps_per_epoch_inc = num_of_train_samples \/\/ batch_size_inc\nprint(\"Steps per epoch: \",steps_per_epoch_inc)","d57ffefc":"from keras.applications import InceptionV3\n# The sequential API allows us to create model layer by layer\ninc_model = Sequential()\ninc_model.add(InceptionV3(include_top=False, \n                      pooling='max',\n                      weights='imagenet'))\ninc_model.add(Dense(10, activation=\"softmax\"))\n\n# Summary: to find the number of parameters\ninc_model.layers[0].trainable=False\ninc_model.summary()\n\nadam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\ninc_model.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n              metrics=[\"accuracy\"])","1d4265b2":"# Trains the model for a given number of epochs (iterations on a dataset).\ninc_training = inc_model.fit_generator(train_generator,\n                                       steps_per_epoch = steps_per_epoch_inc,\n                                       epochs = epoch_inc,\n                                       validation_data = validation_generator,\n                                       validation_steps = num_of_validation_samples \/\/ batch_size_inc)","24388d32":"training_accuracy_inc      = inc_training.history['accuracy'][-1]\ntraining_loss_inc          = inc_training.history['loss'][-1]\nvalidation_accuracy_inc    = inc_training.history['val_accuracy'][-1]\nvalidation_loss_inc        = inc_training.history['val_loss'][-1]\nprint(\"Training Accuracy Inception   :\", training_accuracy_inc )\nprint(\"Training Loss Inception       :\", training_loss_inc)\nprint(\"Validation Accuracy Inception :\", validation_accuracy_inc)\nprint(\"Validation Loss Inception     :\", validation_loss_inc)","6a9cd361":"# Generating Confusion Matrix and Classification Report\nY_pred_inc = inc_model.predict_generator(validation_generator, num_of_validation_samples \/\/ batch_size+1)\ny_pred_inc = np.argmax(Y_pred_inc, axis=1)\nprint('Confusion Matrix')\nconf_matrix_inc = confusion_matrix(validation_generator.classes, y_pred_inc)\ncm_inc = np.array2string(conf_matrix_inc)\nprint(conf_matrix_inc)\nprint(\"=============================================================================================\")\nprint('Classification Report')\n# target_names = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']\nclass_rep_inc = classification_report(validation_generator.classes, y_pred_inc, target_names=target_names)\nprint(class_rep_inc)","69180e8b":"epoch_vgg = 60\nlearning_rate_vgg = 0.001\nbatch_size_vgg = 64\nsteps_per_epoch_vgg = num_of_train_samples \/\/ batch_size_vgg\nprint(\"Steps per epoch: \",steps_per_epoch_vgg)","901e0b76":"from keras.applications import vgg16\n    # The sequential API allows you to create models layer-by-layer\nvgg_model=Sequential()\nvgg_model.add(vgg16.VGG16(include_top = False, pooling = 'max', weights = 'imagenet'))\nvgg_model.add(Dense(10, activation=\"softmax\"))\n\n    # Summary: to find the number of parameters\nvgg_model.layers[0].trainable=False\nvgg_model.summary() \n\nadam = optimizers.Adam(lr=learning_rate_vgg, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\nvgg_model.compile(loss=\"categorical_crossentropy\",\n                  optimizer=adam,\n                  metrics=[\"accuracy\"])","e09c1c00":"# Trains the model for a given number of epochs (iterations on a dataset).\nvgg_training = vgg_model.fit_generator(train_generator,\n                                       steps_per_epoch = steps_per_epoch_vgg,\n                                       epochs = epoch_vgg,\n                                       validation_data = validation_generator,\n                                       validation_steps = num_of_validation_samples \/\/ batch_size_vgg)","4087a259":"training_accuracy_vgg      = vgg_training.history['accuracy'][-1]\ntraining_loss_vgg          = vgg_training.history['loss'][-1]\nvalidation_accuracy_vgg    = vgg_training.history['val_accuracy'][-1]\nvalidation_loss_vgg        = vgg_training.history['val_loss'][-1]\nprint(\"Training Accuracy VGG    :\", training_accuracy_vgg )\nprint(\"Training Loss VGG        :\", training_loss_vgg)\nprint(\"Validation Accuracy VGG  :\", validation_accuracy_vgg)\nprint(\"Validation Loss VGG      :\", validation_loss_vgg)","276e6909":"# Generating Confusion Matrix and Classification Report\nY_pred_vgg = vgg_model.predict_generator(validation_generator, num_of_validation_samples \/\/ batch_size+1)\ny_pred_vgg = np.argmax(Y_pred_vgg, axis=1)\nprint('Confusion Matrix')\nconf_matrix_vgg = confusion_matrix(validation_generator.classes, y_pred_vgg)\ncm_vgg = np.array2string(conf_matrix_vgg)\nprint(conf_matrix_vgg)\nprint(\"=============================================================================================\")\nprint('Classification Report')\ntarget_names = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']\nclass_rep_vgg = classification_report(validation_generator.classes, y_pred_vgg, target_names=target_names)\nprint(class_rep_vgg)","daafff7d":"epoch_cn = 50\nlearning_rate_cn = 0.0001\nbatch_size_cn = 64\nsteps_per_epoch_cn = num_of_train_samples \/\/ batch_size_cn\nprint(\"Steps per epoch: \",steps_per_epoch_cn)","d8a5a831":"# Custom network\nmodel_cn = Sequential()\nmodel_cn.add(Conv2D(16,(3,3),input_shape=(256,256,3),padding='same'))\nmodel_cn.add(Activation('relu'))\nmodel_cn.add(BatchNormalization())\nmodel_cn.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_cn.add(Conv2D(32,(3,3),padding='same'))\nmodel_cn.add(Activation('relu'))\nmodel_cn.add(BatchNormalization())\nmodel_cn.add(MaxPooling2D(pool_size=(2,2)))\nmodel_cn.add(Dropout(0.25))\n\n\nmodel_cn.add(Conv2D(32,(3,3),padding='same'))\nmodel_cn.add(Activation('relu'))\nmodel_cn.add(BatchNormalization())\nmodel_cn.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_cn.add(Conv2D(64,(3,3),padding='same'))\nmodel_cn.add(Activation('relu'))\nmodel_cn.add(BatchNormalization())\nmodel_cn.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_cn.add(Flatten())\nmodel_cn.add(Dense(256,activation='relu'))\n#model.add(LeakyReLU(0.1))\nmodel_cn.add(Dropout(0.5))\nmodel_cn.add(Dense(10))\nmodel_cn.add(Activation(\"softmax\"))\n\nmodel_cn.summary()\n\n\nmodel_cn.compile(loss=\"categorical_crossentropy\",\n                  optimizer= 'sgd',\n                  metrics=[\"accuracy\"])","1c2a6c8b":"# Trains the model for a given number of epochs (iterations on a dataset).\ncn_training = model_cn.fit_generator(train_generator,\n                                       steps_per_epoch = steps_per_epoch_cn,\n                                       epochs = epoch_cn,\n                                       validation_data = validation_generator,\n                                       validation_steps = num_of_validation_samples \/\/ batch_size_cn)","783d4701":"training_accuracy_cn      = cn_training.history['accuracy'][-1]\ntraining_loss_cn          = cn_training.history['loss'][-1]\nvalidation_accuracy_cn    = cn_training.history['val_accuracy'][-1]\nvalidation_loss_cn        = cn_training.history['val_loss'][-1]\nprint(\"Training Accuracy CN    :\", training_accuracy_cn )\nprint(\"Training Loss CN        :\", training_loss_cn)\nprint(\"Validation Accuracy CN  :\", validation_accuracy_cn)\nprint(\"Validation Loss CN      :\", validation_loss_cn)","7500dd11":"# Generating Confusion Matrix and Classification Report\nY_pred_cn = model_cn.predict_generator(validation_generator, num_of_validation_samples \/\/ batch_size+1)\ny_pred_cn = np.argmax(Y_pred_cn, axis=1)\nprint('Confusion Matrix')\nconf_matrix_cn = confusion_matrix(validation_generator.classes, y_pred_cn)\ncm_cn = np.array2string(conf_matrix_cn)\nprint(conf_matrix_cn)\nprint(\"=============================================================================================\")\nprint('Classification Report')\n# target_names = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']\nclass_rep_cn = classification_report(validation_generator.classes, y_pred_cn, target_names=target_names)\nprint(class_rep_cn)","68d060b9":"model_comp = pd.DataFrame({\"Models\": ['ResNet50', 'Inception', 'VGG16', 'Custom Network'],\n                           \"Batch Size\":[batch_size,batch_size_inc,batch_size_vgg,batch_size_cn],\n                           \"Epochs\":[epoch,epoch_inc,epoch_vgg,epoch_cn],\n                           \"Learning Rate\": [learning_rate,learning_rate_inc,learning_rate_vgg,learning_rate_cn],\n                           \"Steps per epoch\":[68,34,17,17],\n                           \"Optimizer\":[\"sgd\",'adam', 'adam', 'sgd'],\n                           \"Image Resolution\":['256*256','256*256', '256*256', '256*256'],\n                          \"Training Accuracy\": [training_accuracy_resnet,training_accuracy_inc,training_accuracy_vgg,training_accuracy_cn],\n                          \"Training Loss\": [training_loss_resnet,training_loss_inc,training_loss_vgg,training_loss_cn],\n                          \"Validation Accuracy\": [validation_accuracy_resnet,validation_accuracy_inc,validation_accuracy_vgg,validation_accuracy_cn],\n                          \"Validation Loss\": [validation_loss_resnet,validation_loss_inc,validation_loss_vgg,validation_loss_cn],\n                          })\nmodel_comp","41460aab":"Saving the model history for Inception","f426a33c":"# Image Generator:\u00b6\n\nReal time data augmentation, the data will be looped over (in batches)","5c451855":"# Transfer Learning - Comparing losses and accuracies for different standard algorithms, Confusion Matrix and Classification Report.","41de4db4":"# Comparing Accuracies and losses for all the models","069255f9":"Saving the model history for Custom network","e1082996":"Saving the model history for ResNet - 50","e2c7d2b8":"# Inception","b1c6ca83":"Generating Confusion Matrix and Classification Report for ResNet 50","920eebf1":"Generating Confusion Matrix and Classification Report for Custom Network","0a65fa7d":"Generating Confusion Matrix and Classification Report for Inception","49ea3a39":"defining hyperparameters, image resolution and other stuffs...","af28e3ac":"Generating Confusion Matrix and Classification Report for VGG","9714943c":"**Output:** Post running the below script, output resembles as shown in the below image.\n\n![aaaaaa.png](attachment:aaaaaa.png)","712ceeb9":"# Custom Network","573c4cf4":"Saving the model history for VGG","9509675e":"class_mode = 'binary' (2 output classes) ---- if more class prefer class_mode = 'categorical'.\n\nTotal number of steps (batches of samples) before declaring one epoch finished and starting the next epoch\n\n# ResNet 50","20c224eb":"# VGG16"}}