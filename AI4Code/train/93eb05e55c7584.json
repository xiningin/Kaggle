{"cell_type":{"b84bf549":"code","3551865b":"code","16d124bb":"code","a87bec24":"code","b659df70":"markdown","b0997482":"markdown","ad8b0c33":"markdown","e3b0043a":"markdown","9a213438":"markdown","f7ed9353":"markdown","ca04ebd9":"markdown"},"source":{"b84bf549":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3551865b":"mnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images \/ 255.0\ntest_images=test_images \/ 255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(training_images, training_labels, epochs=5)\n\ntest_loss = model.evaluate(test_images, test_labels)","16d124bb":"import tensorflow as tf\nmnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)\n","a87bec24":"import matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=0\nSECOND_IMAGE=7\nTHIRD_IMAGE=26\nCONVOLUTION_NUMBER = 1\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[0,x].grid(False)\n  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[1,x].grid(False)\n  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[2,x].grid(False)","b659df70":"We have different approaches to solve same problem , what does matter is accuracy and computation time while working on NN, here I am going to share how DNN and CNN have a performance difference over same type of problem.Please turn on internet from setting panel on right bottom side for smooth execution of code.","b0997482":"For further information related to this topic please check Cousera , a very simple and comprehensive guideline to learn and code CNN using TensorFlow","ad8b0c33":"You can see the difference between CNN and DNN, the reason is that CNN works is basically more focus, as we just get more useful pixal and trained our model on it, rather calculating and considering all the pixal which may have zero impact for image recognition, ","e3b0043a":"Below is the code for visualization behaviour of CNN, ","9a213438":"This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n\nThat's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.","f7ed9353":"accuracy is probably about 89% on training and 87% on validation, now we will move to test same dataset using CNN, and will discuss the difference in behaviour at the end","ca04ebd9":"**First we go with DNN and will see the accuracy at the end after running this piece of code **"}}