{"cell_type":{"db15186b":"code","6c1ef3da":"code","24c11371":"code","f20c39d7":"code","a3ea2715":"code","c2d64f20":"code","b4ed8dfb":"code","fb65613c":"code","f7c5022c":"code","fabb5c44":"code","261042ba":"code","72b36408":"code","fa906cf7":"code","c6437b95":"code","e949e542":"code","1f088f8e":"code","680dec65":"code","30f25133":"code","6a0795fd":"code","25bd98a9":"code","b29619af":"code","9847ac54":"code","7fcce9eb":"code","62e0f48c":"code","bf9a35bc":"code","909e67bb":"code","291ced1e":"code","8780b73a":"code","0b511bc8":"code","680ac63b":"code","450708ab":"code","7334cb81":"code","fdd885ae":"code","e402336b":"code","b4bf3a74":"code","2fabe851":"code","3b71818f":"code","d6072311":"code","29b0ce88":"code","c1819c0a":"code","3af47f11":"code","5cd5224f":"code","15f087ea":"code","59254cfc":"code","60f2f689":"code","900219ac":"code","20b7faec":"code","a449e455":"code","cdddf21c":"code","5fa97565":"code","0336de14":"code","ccd33971":"code","33be33fc":"code","7e7a5c6c":"code","c6080b35":"code","8bca443c":"code","6e09b761":"code","e0b22b6b":"code","33e622ec":"code","c7931460":"code","59e6eabd":"code","154c5b54":"code","0b97deed":"code","c784700a":"code","51b31d9d":"code","591a1059":"code","ba43deb4":"code","77b42f5b":"markdown"},"source":{"db15186b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport pickle\nfrom collections import Counter","6c1ef3da":"import json\nwith open('data.json', encoding='utf-8') as fh:\n    data = json.load(fh)","24c11371":"data[0]","f20c39d7":"set_cats = set([a['category'] for a in data])","a3ea2715":"set_cats","c2d64f20":"len(data)","b4ed8dfb":"all_cats = [a['category'] for a in data]","fb65613c":"len(all_cats)","f7c5022c":"cat_cnts = []\n\nfor cat in set_cats:\n    cat_cnts.append(all_cats.count(cat))","fabb5c44":"cat_cnts","261042ba":"sorted(cat_cnts)[::-1]","72b36408":"z = zip(cat_cnts, set_cats)\nz = list(z)","fa906cf7":"z","c6437b95":"sel_cats = []\n\nfor p in z:\n    if p[0] > 8000:\n        sel_cats.append(p[1])","e949e542":"sel_cats","1f088f8e":"X_text = []\ny_label = []\n\nfor p in data:\n    if p['category'] in sel_cats:\n        y_label.append(p['category'])\n        X_text.append(p['content'])","680dec65":"len(X_text)","30f25133":"len(y_label)","6a0795fd":"X_text[0]","25bd98a9":"print(len(X_text[0]))","b29619af":"y_label[0]","9847ac54":"set(y_label)","7fcce9eb":"print(len(X_text))\nprint(len(y_label))","62e0f48c":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nclass_labels = encoder.fit_transform(y_label)","bf9a35bc":"set(class_labels)","909e67bb":"encoder.inverse_transform([[3]])","291ced1e":"class_labels.shape","8780b73a":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False)\nclass_labels = class_labels.reshape((class_labels.shape[0], 1))\ny_ohe = encoder.fit_transform(class_labels)","0b511bc8":"class_labels[0]","680ac63b":"y_ohe","450708ab":"y_ohe.shape","7334cb81":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_text)\n\nX_token = tokenizer.texts_to_sequences(X_text)\n\nvocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index","fdd885ae":"vocab_size","e402336b":"tokenizer.texts_to_sequences(['\u09a6\u09cd\u09b0\u09ac\u09cd\u09af\u09ae\u09c2\u09b2\u09cd\u09af \u09a8\u09bf\u09df\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09c7 \u0985\u09ad\u09bf\u09af\u09be\u09a8 \u09b6\u09c1\u09b0\u09c1\u09b0 \u0986\u0997\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7\u09b0 \u09a8\u09be\u09ae \u09ab\u09be\u0981\u09b8 \u09b9\u09df\u09c7 \u09af\u09be\u099a\u09cd\u099b\u09c7\u0964 \u098f\u0987 \u0985\u09ad\u09bf\u09af\u09cb\u0997 \u0989\u09a0\u09c7 \u098f\u09b8\u09c7\u099b\u09c7 \u09ac\u09be\u099c\u09be\u09b0 \u09a4\u09a6\u09be\u09b0\u0995\u09bf \u099c\u09cb\u09b0\u09a6\u09be\u09b0 \u0995\u09b0\u09be \u09a8\u09bf\u09df\u09c7 \u0986\u09df\u09cb\u099c\u09bf\u09a4 \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u09c7\u09b0 \u098f\u0995\u099f\u09bf \u09b8\u09ad\u09be\u09df\u0964 \u09b8\u09ad\u09be\u09df \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u09c7\u09b0 \u098f\u0995\u099c\u09a8 \u09af\u09c1\u0997\u09cd\u09ae \u09b8\u099a\u09bf\u09ac \u09ac\u09b2\u09c7\u09a8, \u0986\u0997\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u0985\u09ad\u09bf\u09af\u09be\u09a8\u09c7\u09b0 \u09a6\u09bf\u09a8 \u09b0\u09bf\u099c\u09be\u09b0\u09cd\u09ad \u09aa\u09c1\u09b2\u09bf\u09b6\u09c7\u09b0 \u09b8\u09a6\u09b8\u09cd\u09af\u09a6\u09c7\u09b0 \u09aa\u09be\u0993\u09df\u09be \u09af\u09c7\u09a4\u0964 \u098f\u0996\u09a8 \u09b8\u0982\u09b6\u09cd\u09b2\u09bf\u09b7\u09cd\u099f \u09a5\u09be\u09a8\u09be \u09a5\u09c7\u0995\u09c7 \u09b8\u09a6\u09b8\u09cd\u09af\u09a6\u09c7\u09b0 \u09a8\u09bf\u09df\u09c7 \u0985\u09ad\u09bf\u09af\u09be\u09a8 \u09aa\u09b0\u09bf\u099a\u09be\u09b2\u09a8\u09be \u0995\u09b0\u09a4\u09c7 \u09b9\u09df\u0964 \u098f\u09a4\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7\u09b0 \u09a8\u09be\u09ae \u0986\u0997\u09c7\u0987 \u09aa\u09cd\u09b0\u0995\u09be\u09b6 \u09b9\u09df\u09c7 \u09af\u09be\u09df\u0964  \u09ac\u09c8\u09a0\u0995\u09c7 \u0986\u0997\u09c7\u09b0 \u09ae\u09a4\u09cb \u09b0\u09bf\u099c\u09be\u09b0\u09cd\u09ad \u09aa\u09c1\u09b2\u09bf\u09b6 \u09b8\u09a6\u09b8\u09cd\u09af\u09a6\u09c7\u09b0 \u09a8\u09bf\u09df\u09c7 \u0985\u09ad\u09bf\u09af\u09be\u09a8 \u099a\u09be\u09b2\u09be\u09a8\u09cb\u09b0 \u09b8\u09bf\u09a6\u09cd\u09a7\u09be\u09a8\u09cd\u09a4 \u09b9\u09df\u0964 \u098f \u099c\u09a8\u09cd\u09af \u09aa\u09c1\u09b2\u09bf\u09b6 \u09b8\u09a6\u09b8\u09cd\u09af\u09a6\u09c7\u09b0 \u09ae\u09cb\u09a4\u09be\u09df\u09c7\u09a8\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u09a2\u09be\u0995\u09be \u09ae\u09c7\u099f\u09cd\u09b0\u09cb\u09aa\u09b2\u09bf\u099f\u09a8 \u09aa\u09c1\u09b2\u09bf\u09b6\u0995\u09c7 (\u09a1\u09bf\u098f\u09ae\u09aa\u09bf) \u0985\u09a8\u09c1\u09b0\u09cb\u09a7 \u099c\u09be\u09a8\u09be\u09a8\u09cb \u09b9\u09df\u0964 \u09b8\u0982\u09b6\u09cd\u09b2\u09bf\u09b7\u09cd\u099f \u09ac\u09cd\u09af\u0995\u09cd\u09a4\u09bf\u09b0\u09be \u09ac\u09b2\u099b\u09c7\u09a8, \u0985\u09ad\u09bf\u09af\u09be\u09a8\u09c7\u09b0 \u0986\u0997\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7\u09b0 \u09a8\u09be\u09ae \u09ab\u09be\u0981\u09b8 \u09b9\u09df\u09c7 \u0997\u09c7\u09b2\u09c7 \u09a4\u09a6\u09be\u09b0\u0995\u09bf\u09a4\u09c7 \u0995\u09cb\u09a8\u09cb \u09b2\u09be\u09ad \u09b9\u09df \u09a8\u09be\u0964 \u09ac\u09cd\u09af\u09ac\u09b8\u09be\u09df\u09c0\u09b0\u09be \u0986\u0997\u09c7 \u09a5\u09c7\u0995\u09c7\u0987 \u09b8\u09a4\u09b0\u09cd\u0995 \u09b9\u09df\u09c7 \u09af\u09be\u09a8\u0964 \u0985\u09a8\u09c7\u0995 \u09b8\u09ae\u09df \u09a6\u09c7\u0996\u09be \u09af\u09be\u09df, \u09ad\u09cd\u09b0\u09be\u09ae\u09cd\u09af\u09ae\u09be\u09a3 \u0986\u09a6\u09be\u09b2\u09a4 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u0987 \u09ac\u09c7\u09b6\u09bf\u09b0 \u09ad\u09be\u0997 \u09a6\u09cb\u0995\u09be\u09a8 \u09ac\u09a8\u09cd\u09a7 \u0995\u09b0\u09c7 \u09a6\u09c7\u0993\u09df\u09be \u09b9\u09df\u09c7\u099b\u09c7\u0964  \u09b8\u09ad\u09be\u09df \u09ac\u09be\u099c\u09be\u09b0 \u09a4\u09a6\u09be\u09b0\u0995\u09bf\u09b0 \u0995\u09cd\u09b7\u09c7\u09a4\u09cd\u09b0\u09c7 \u09a8\u09be\u09a8\u09be \u09a6\u09c1\u09b0\u09cd\u09ac\u09b2\u09a4\u09be \u0989\u09a0\u09c7 \u0986\u09b8\u09c7\u0964 \u09b8\u09ad\u09be\u09df \u098f\u0996\u09a8 \u09a5\u09c7\u0995\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u0985\u09ad\u09bf\u09af\u09be\u09a8\u09c7\u09b0 \u0995\u09cd\u09b7\u09c7\u09a4\u09cd\u09b0\u09c7 \u09b8\u0982\u09b6\u09cd\u09b2\u09bf\u09b7\u09cd\u099f \u09ac\u09cd\u09af\u09ac\u09b8\u09be\u09df\u09c0 \u09b8\u09ae\u09bf\u09a4\u09bf\u0995\u09c7 \u0986\u09b0\u0993 \u09ac\u09c7\u09b6\u09bf \u09b8\u09ae\u09cd\u09aa\u09c3\u0995\u09cd\u09a4 \u0995\u09b0\u09be\u09b0 \u09b8\u09bf\u09a6\u09cd\u09a7\u09be\u09a8\u09cd\u09a4 \u09a8\u09c7\u0993\u09df\u09be \u09b9\u09df\u0964 \u09b8\u09ad\u09be\u09b0 \u0995\u09be\u09b0\u09cd\u09af\u09ac\u09bf\u09ac\u09b0\u09a3\u09c0 \u09a5\u09c7\u0995\u09c7 \u098f\u09b8\u09ac \u09a4\u09a5\u09cd\u09af \u099c\u09be\u09a8\u09be \u0997\u09c7\u099b\u09c7\u0964  \u09ac\u09be\u099c\u09be\u09b0 \u09a4\u09a6\u09be\u09b0\u0995\u09bf \u09a6\u09b2\u09c7\u09b0 \u0995\u09be\u09b0\u09cd\u09af\u0995\u09cd\u09b0\u09ae \u099c\u09cb\u09b0\u09a6\u09be\u09b0 \u0995\u09b0\u09be\u09b0 \u09b2\u0995\u09cd\u09b7\u09cd\u09af \u09a8\u09bf\u09df\u09c7 \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u09c7 \u09b8\u09ad\u09be\u099f\u09bf \u0985\u09a8\u09c1\u09b7\u09cd\u09a0\u09bf\u09a4 \u09b9\u09df \u0997\u09a4 \u09e8\u09e9 \u099c\u09be\u09a8\u09c1\u09df\u09be\u09b0\u09bf\u0964 \u098f\u09a4\u09c7 \u09b8\u09ad\u09be\u09aa\u09a4\u09bf\u09a4\u09cd\u09ac \u0995\u09b0\u09c7\u09a8 \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af\u09b8\u099a\u09bf\u09ac \u09b6\u09c1\u09ad\u09be\u09b6\u09c0\u09b7 \u09ac\u09b8\u09c1\u0964 \u09b8\u09ad\u09be\u09df \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df, \u09b6\u09bf\u09b2\u09cd\u09aa \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df, \u0995\u09c3\u09b7\u09bf \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df, \u0996\u09be\u09a6\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df, \u099f\u09cd\u09af\u09be\u09b0\u09bf\u09ab \u0995\u09ae\u09bf\u09b6\u09a8, \u09b0\u09aa\u09cd\u09a4\u09be\u09a8\u09bf \u0989\u09a8\u09cd\u09a8\u09df\u09a8 \u09ac\u09cd\u09af\u09c1\u09b0\u09cb (\u0987\u09aa\u09bf\u09ac\u09bf) , \u099f\u09cd\u09b0\u09c7\u09a1\u09bf\u0982 \u0995\u09b0\u09aa\u09cb\u09b0\u09c7\u09b6\u09a8 \u0985\u09ac \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 (\u099f\u09bf\u09b8\u09bf\u09ac\u09bf) , \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u09b6\u09bf\u09b2\u09cd\u09aa \u0993 \u09ac\u09a3\u09bf\u0995 \u09b8\u09ae\u09bf\u09a4\u09bf \u09ab\u09c7\u09a1\u09be\u09b0\u09c7\u09b6\u09a8 (\u098f\u09ab\u09ac\u09bf\u09b8\u09bf\u09b8\u09bf\u0986\u0987) , \u09a2\u09be\u0995\u09be \u0989\u09a4\u09cd\u09a4\u09b0 \u09b8\u09bf\u099f\u09bf \u0995\u09b0\u09aa\u09cb\u09b0\u09c7\u09b6\u09a8 \u0993 \u099c\u09be\u09a4\u09c0\u09df \u09ad\u09cb\u0995\u09cd\u09a4\u09be \u0985\u09a7\u09bf\u0995\u09be\u09b0 \u09b8\u0982\u09b0\u0995\u09cd\u09b7\u09a3 \u0985\u09a7\u09bf\u09a6\u09aa\u09cd\u09a4\u09b0\u09c7\u09b0 \u09aa\u09cd\u09b0\u09a4\u09bf\u09a8\u09bf\u09a7\u09bf\u09b0\u09be \u0989\u09aa\u09b8\u09cd\u09a5\u09bf\u09a4 \u099b\u09bf\u09b2\u09c7\u09a8\u0964  \u09ac\u09be\u09a3\u09bf\u099c\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df \u09aa\u09ac\u09bf\u09a4\u09cd\u09b0 \u09b0\u09ae\u099c\u09be\u09a8 \u09ae\u09be\u09b8\u09b8\u09b9 \u09ac\u09bf\u09ad\u09bf\u09a8\u09cd\u09a8 \u09b8\u09ae\u09df\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09a4\u09a6\u09be\u09b0\u0995\u09bf \u09a6\u09b2 \u09aa\u09be\u09a0\u09bf\u09df\u09c7 \u09a5\u09be\u0995\u09c7\u0964 \u098f\u09b8\u09ac \u09a4\u09a6\u09be\u09b0\u0995\u09bf \u09a6\u09b2 \u09a8\u09be\u09a8\u09be \u0985\u09ad\u09bf\u09af\u09cb\u0997\u09c7 \u09ac\u09cd\u09af\u09ac\u09b8\u09be\u09df\u09c0\u09a6\u09c7\u09b0 \u099c\u09b0\u09bf\u09ae\u09be\u09a8\u09be \u0995\u09b0\u09c7\u0964'])","b4bf3a74":"print(X_text[2])\nprint(X_token[2])","2fabe851":"len(X_token[0])","3b71818f":"len(X_text[0])","d6072311":"from keras.preprocessing.sequence import pad_sequences\nmaxlen = 300\nX_pad = pad_sequences(X_token, padding='post', maxlen=maxlen)","29b0ce88":"from collections import Counter\n\nword_ls = []\n\nfor sen in X_text:\n    word_ls.extend(sen.split())","c1819c0a":"len(word_ls)","3af47f11":"Counter = Counter(word_ls)","5cd5224f":"most_occur = Counter.most_common(100)\nprint(most_occur)","15f087ea":"X_pad.shape","59254cfc":"vocab_size","60f2f689":"maxlen","900219ac":"y_ohe.shape","20b7faec":"X_pad[1]","a449e455":"class_labels.shape","cdddf21c":"class_labels[:,0]","5fa97565":"c_l = list(class_labels[:,0])","0336de14":"c_l = set(c_l)","ccd33971":"class_weight = {}\n\nfor c in (list(c_l)):\n    print(c)\n    c_w = len(class_labels)\/np.sum(class_labels==c)\n    print(c_w)\n    class_weight[c] = c_w","33be33fc":"from keras.models import Sequential\nfrom keras.layers import Embedding, CuDNNLSTM, Bidirectional, Dense\n\nembedding_dim = 8\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, \n                           output_dim=embedding_dim, \n                           input_length=maxlen))\nmodel.add(Bidirectional(CuDNNLSTM(128, return_sequences = True)))\nmodel.add(Bidirectional(CuDNNLSTM(128))) \nmodel.add(Dense(9, activation='softmax'))\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","7e7a5c6c":"from keras.callbacks import LearningRateScheduler, EarlyStopping\nfrom math import exp\ndef exp_decay(epoch):\n    initial_lrate = 0.1\n    k = 0.1\n    lrate = initial_lrate * exp(-k*epoch)\n    return lrate\nlrate = LearningRateScheduler(exp_decay)","c6080b35":"[exp_decay(i) for i in range(5)]","8bca443c":"import numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=0)\nsss.get_n_splits(X_pad, y_ohe)\n\n#print(sss)       \n\nfor train_index, test_index in sss.split(X_pad, y_ohe):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X_pad[train_index], X_pad[test_index]\n    y_train, y_test = y_ohe[train_index], y_ohe[test_index]","6e09b761":"class_labels","e0b22b6b":"history = model.fit(X_train, y_train,\n                    epochs=10,\n                    verbose=1,\n                    validation_split=0.2,\n                    batch_size=256,\n                    class_weight = class_weight)","33e622ec":"model.evaluate(X_test, y_test)","c7931460":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['train', 'valid'])\nplt.show()","59e6eabd":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train', 'valid'])\nplt.show()","154c5b54":"model.save('lstm_best.h5')","0b97deed":"import matplotlib.pyplot as plt\nplt.hist(y_train)\nplt.show()","c784700a":"from keras.models import load_model\n\nmodel = load_model('lstm_best.h5')","51b31d9d":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nclass_labels = encoder.fit_transform(y_label)","591a1059":"def generate_response():\n    input_sentence = input('Enter input news: ')\n    Xi_token = tokenizer.texts_to_sequences([input_sentence])\n    Xi_pad = pad_sequences(Xi_token, padding='post', maxlen=maxlen)\n    print('Model predicts')\n    preds = model.predict(Xi_pad)\n    print('Confidence :')\n    print(preds)\n    preds = preds\n    total = 0\n    for k in range(len(preds[0])):\n        print(encoder.inverse_transform([[k]]))\n        print('%f %%' %(preds[0,k]*100))\n        total += preds[0,k]*100\n    #print(total)\n    print('Predicted class: %s'%(encoder.inverse_transform(model.predict_classes(Xi_pad))))","ba43deb4":"generate_response()","77b42f5b":"**Github** [https:\/\/github.com\/zabir-nabil\/bangla-news-rnn](https:\/\/github.com\/zabir-nabil\/bangla-news-rnn)"}}