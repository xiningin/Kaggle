{"cell_type":{"40682129":"code","b5e63f89":"code","6c890575":"code","d32fab7a":"code","75c81283":"code","ea17bf32":"code","8d729ff3":"code","9cfcbb0d":"code","ca952b95":"code","4fbdd7ad":"code","ff158c34":"code","76de8b50":"code","c8cb28ee":"code","2e412146":"code","aa7bc058":"code","7327b42d":"code","d1be74a1":"code","d3079c32":"code","6f8f41e6":"code","d92442bd":"code","5884aca8":"markdown","774403ca":"markdown","ea49c3be":"markdown","d68884bc":"markdown","4e3a7d2c":"markdown","fcc5500f":"markdown","d86db6e5":"markdown","47d207b0":"markdown","36d60aef":"markdown","357e3a37":"markdown","4f9617c7":"markdown","ffdec404":"markdown"},"source":{"40682129":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM, GRU\nfrom keras.layers import Dropout\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom math import sqrt\n\nimport math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","b5e63f89":"data = pd.read_csv('..\/input\/Data\/Stocks\/gs.us.txt', sep=',', header=0).fillna(0)\ndata.head()","6c890575":"dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\ndata = pd.read_csv('..\/input\/Data\/Stocks\/gs.us.txt', sep=',', parse_dates=['Date'], index_col='Date',date_parser=dateparse)\n#data = data.loc['2012-11-10':'2017-11-10']\nplt.figure(figsize=(16,8))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Open Prices')\nplt.plot(data['Open']);","d32fab7a":"from pandas.plotting import lag_plot\nplt.figure(figsize=(12,8))\nlag_plot(data['Open'], lag=1)\nplt.title('Goldman Sachs Autocorrelation plot')\nplt.grid(True)\nplt.legend();\n\nfrom pandas import DataFrame\nfrom pandas import concat\nvalues = DataFrame(data['Open'].values)\ndataframe = concat([values.shift(120), values], axis=1)\ndataframe.columns = ['t-1', 't+1']\nresult = dataframe.corr()\nprint(result)","75c81283":"data.tail()","ea17bf32":"train_data, test_data = data[0:int(len(data)*0.9)], data[int(len(data)*0.9):]\nplt.figure(figsize=(16,8))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Open Prices')\nplt.plot(data['Open'], 'green', label='Train data')\nplt.plot(test_data['Open'], 'blue', label='Test data')\nplt.legend()","8d729ff3":"from pandas import Series\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.ar_model import AR\nfrom sklearn.metrics import mean_squared_error\n\ntrain_ar = train_data['Open']\ntest_ar = test_data['Open']\n# train autoregression\nmodel = AR(train_ar)\nmodel_fit = model.fit()\nwindow = model_fit.k_ar\ncoef = model_fit.params\n# walk forward over time steps in test\nhistory = train_ar[len(train_ar)-window:]\nhistory = [history[i] for i in range(len(history))]\npredictions = list()\nfor t in range(len(test_ar)):\n    length = len(history)\n    lag = [history[i] for i in range(length-window,length)]\n    yhat = coef[0]\n    for d in range(window):\n        yhat += coef[d+1] * lag[window-d-1]\n    obs = test_ar[t]\n    predictions.append(yhat)\n    history.append(obs)\n    \nplt.figure(figsize=(14,8))\nprint('Lag: %s' % model_fit.k_ar)\nplt.plot(data.index[-600:], data['Open'].tail(600), color='green', label='Close price')\nplt.plot(test_data.index, test_data['Open'], color='red', label='Test close price')\nplt.plot(test_data.index, predictions, color='blue', label='Predicted close price')\nplt.xticks(rotation=30)\nplt.grid(True)\nplt.legend()\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math\nmse = mean_squared_error(test_data['Open'], predictions)\nprint('MSE: '+str(mse))\nmae = mean_absolute_error(test_data['Open'], predictions)\nprint('MAE: '+str(mae))\nrmse = math.sqrt(mean_squared_error(test_data['Open'], predictions))\nprint('RMSE: '+str(rmse))\n\nplt.savefig('ar_model.pdf')\n","9cfcbb0d":"from pylab import rcParams\nrcParams['figure.figsize'] = 14, 8\ndata_arima = data['Open']\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(data_arima[-1000:], model='multiplicative', freq=30)\nplt.figure(figsize=(16,8))\nfig = result.plot()\nplt.show()","ca952b95":"train_arima = train_data['Open']\ntest_arima = test_data['Open']\n\nhistory = [x for x in train_arima]\ny = test_arima\n# make first prediction\npredictions = list()\nmodel = ARIMA(history, order=(1,1,0))\nmodel_fit = model.fit(disp=0)\nyhat = model_fit.forecast()[0]\npredictions.append(yhat)\nhistory.append(y[0])\n# rolling forecasts\nfor i in range(1, len(y)):\n    # predict\n    model = ARIMA(history, order=(1,1,0))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    # invert transformed prediction\n    predictions.append(yhat)\n    # observation\n    obs = y[i]\n    history.append(obs)\n# report performance\nmse = mean_squared_error(y, predictions)\nprint('MSE: '+str(mse))\nmae = mean_absolute_error(y, predictions)\nprint('MAE: '+str(mae))\nrmse = math.sqrt(mean_squared_error(y, predictions))\nprint('RMSE: '+str(rmse))\n","4fbdd7ad":"plt.figure(figsize=(16,8))\nplt.plot(data.index[-600:], data['Open'].tail(600), color='green', label = 'Train Stock Price')\nplt.plot(test_data.index, y, color = 'red', label = 'Real Stock Price')\nplt.plot(test_data.index, predictions, color = 'blue', label = 'Predicted Stock Price')\nplt.title('Goldman Sachs Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Goldman Sachs Stock Price')\nplt.legend()\nplt.grid(True)\nplt.savefig('arima_model.pdf')\nplt.show()\n","ff158c34":"train = train_data.iloc[:, 0:1].values # selecting open prices","76de8b50":"scaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(train) ","c8cb28ee":"timesteps = 7\nX_train = []\ny_train = []\nfor i in range(timesteps, train.shape[0]):\n    X_train.append(train_scaled[i-timesteps:i, 0]) # we take 30 previous prices\n    y_train.append(train_scaled[i, 0]) # and 60-th price as y value\nX_train, y_train = np.array(X_train), np.array(y_train)","2e412146":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nfrom numpy.random import seed\nseed(2019)","aa7bc058":"model = Sequential()\n\n# Adding the first LSTM layer \n# Here return_sequences=True means whether to return the last output in the output sequence, or the full sequence.\n# it basically tells us that there is another(or more) LSTM layer ahead in the network.\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n# Dropout regularisation for tackling overfitting\nmodel.add(Dropout(0.20))\n\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.25))\n\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.25))\n\n# Adding the output layer\nmodel.add(Dense(units = 1))\n\n# Compiling the RNN\n# RMSprop is a recommended optimizer as per keras documentation\n# check out https:\/\/keras.io\/optimizers\/ for more details\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nmodel.fit(X_train, y_train, epochs = 40, batch_size = 32)","7327b42d":"# this will be used later while comparing and visualization\nreal_stock_price = test_data.iloc[:,0:1].values # taking open price","d1be74a1":"# combine original train and test data vertically\n# as previous Open Prices are not present in test dataset\n# e.g. for predicting Open price for first date in test data, we will need stock open prices on timesteps previous dates  \ncombine = pd.concat((train_data['Open'], test_data['Open']), axis = 0)\n# our test inputs also contains stock open Prices of last timesteps dates (as described above)\ntest_inputs = combine[len(combine) - len(test_data) - timesteps:].values\ntest_inputs = test_inputs.reshape(-1,1)\ntest_inputs = scaler.transform(test_inputs)","d3079c32":"test_data.shape","6f8f41e6":"# same steps as we followed while processing training data\nX_test = []\nfor i in range(timesteps, test_data.shape[0]+timesteps):\n    X_test.append(test_inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = model.predict(X_test)\n# inverse_transform because prediction is done on scaled inputs\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)","d92442bd":"plt.figure(figsize=(16,8))\nplt.plot(data.index[-600:], data['Open'].tail(600), color='green', label = 'Train Stock Price')\nplt.plot(test_data.index, real_stock_price, color = 'red', label = 'Real Stock Price')\nplt.plot(test_data.index, predicted_stock_price, color = 'blue', label = 'Predicted Stock Price')\nplt.title('Goldman Sachs Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Goldman Sachs Stock Price')\nplt.legend()\nplt.grid(True)\nplt.savefig('lstm_30.pdf')\nplt.show()\n\nmse = mean_squared_error(real_stock_price, predicted_stock_price)\nprint('MSE: '+str(mse))\nmae = mean_absolute_error(real_stock_price, predicted_stock_price)\nprint('MAE: '+str(mae))\nrmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\nprint('RMSE: '+str(rmse))","5884aca8":"## Autoregression model","774403ca":"## Building the RNN","ea49c3be":"## Feature Scaling","d68884bc":"## Visualising the results","4e3a7d2c":"## Plotting autocorrelation","fcc5500f":"## ARIMA model","d86db6e5":"## Now we will creating a data structure with 30 timesteps and 1 output, i.e.Open Stock Price ","47d207b0":"## Now making the predictions and visualising the results","36d60aef":"## Importing the libraries.","357e3a37":"## Visualizing train data","4f9617c7":"## Reshaping\n*  Here second argument is (batch_size, time_step ,input_dim)\n* batch_size is total number of stock price from 2009-12-31 to 2016, i.e. given by X_train.shape[0]\n* time_step is total number of previous stock price we want to consider while predicting present stock price, i.e given by X_train.shape[1]\n*  third argument is input_dim-in our case it is 1, i.e.Open price, but it can be more than one. It basically includes all those factors\/indicators that can affect present stock price ","ffdec404":"## Loading APPL Stock Price train and test dataset"}}