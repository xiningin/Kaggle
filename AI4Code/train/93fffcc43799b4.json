{"cell_type":{"e3fb47a0":"code","4302a2d8":"code","b9a0e66a":"code","51ff721b":"code","556d7a01":"code","51dd37f0":"code","ff210356":"code","1a096de0":"code","e3b255a0":"code","b4a8fd94":"code","7cb366cb":"code","5d9d23b0":"code","b92aabea":"code","6cda6cfb":"code","2dbc1384":"code","86e81848":"code","f36e4484":"code","99516308":"code","21a4a2d3":"code","59985a14":"code","3bc27a56":"code","77dc878f":"code","a5460ef0":"code","4be151fa":"code","8ea67096":"code","f325a7b8":"code","56432b41":"code","be92a64a":"code","3a366b3d":"code","cb8c894b":"code","2edce32e":"code","97446746":"code","b8721d07":"code","60869109":"code","057d0612":"code","e9edbca6":"code","8da10074":"code","5d42e5b7":"code","4d553ff3":"code","2cbada54":"code","4cbcf704":"code","ca5be905":"code","29d411ff":"code","9961f9dd":"code","342fc8a9":"code","58c792bc":"code","ce795eb0":"code","d86f5e5a":"code","dda874ed":"code","d4143ead":"code","9c1b27c9":"code","a6dd021b":"code","5bd16bc1":"code","5b909a0e":"code","5e7bd2a3":"code","82466763":"code","91a42348":"code","a70a105a":"code","2004d28a":"code","21ad3b02":"code","8472b91f":"code","a0bb6c4b":"code","6df3006e":"code","bc63cce2":"code","ad9f3c44":"code","85046205":"code","e6e60290":"code","e0d2f14e":"code","55202f29":"code","6dc63f01":"code","d089093f":"code","e3dd5602":"code","104e668a":"code","bd11fb66":"code","767d3463":"code","48b5dcd1":"code","40109da9":"code","fbc38b76":"code","57129e8e":"code","6a565229":"code","4f8f408c":"code","d9907ddd":"code","a14056d6":"code","26414a08":"code","c6b5b8c2":"code","a108747c":"code","5c1e33ad":"code","7d53ff39":"code","8b2a3dbf":"code","3747b24d":"code","6b08322e":"code","2a89adeb":"code","af35803e":"code","54738a6e":"code","f4d5f118":"code","035900d2":"code","53d26fa4":"code","d6536b93":"code","b45ca81d":"code","b0580e81":"code","eadf80cc":"code","642572df":"code","cf22aaf6":"code","2d7a9ecb":"code","eba7d199":"code","b3af6dca":"code","5af155f1":"code","3612ecb4":"code","7d3e120b":"code","ce4ddca1":"code","0f3c1eca":"code","19cd714c":"code","b729ccc9":"code","8563d76d":"code","6e6160ff":"code","347c89b6":"code","83098afc":"code","dbb0c900":"code","cb2d39c1":"code","4de5d7ba":"code","99905f2a":"code","825b114a":"code","1bbc96ea":"code","387bb41d":"code","1188726a":"code","24c0626e":"code","e9de269b":"code","cf25b1ae":"code","6f146b5a":"code","3bb40811":"code","6aac6667":"code","7e89575c":"code","b9cc3703":"code","31a13887":"code","0ff56859":"code","61b032b4":"code","760bacf8":"code","a492abc4":"code","72c7fd5b":"code","dca3ecd5":"code","3cdef3ca":"code","09e9e418":"code","d009d99a":"code","a8bc78b0":"code","e8303a7e":"code","c927b90f":"code","2872c20d":"markdown","284a293b":"markdown","dfa580d3":"markdown","8eaab9e9":"markdown","1ea373a0":"markdown","32accd83":"markdown","24a2fe47":"markdown","b90b613c":"markdown","fc662a7c":"markdown","2d95aa8a":"markdown","14832202":"markdown","cba22bea":"markdown","3aeba0fd":"markdown","b4becc1c":"markdown","ec1545ab":"markdown","549bc4bf":"markdown","fb605f2f":"markdown","c5bad539":"markdown","9110d385":"markdown","fb12bff9":"markdown","57975656":"markdown","c5ee0ba1":"markdown","31b6fde4":"markdown","8e3cdfc6":"markdown","359323e9":"markdown","c00b83a7":"markdown","946300e8":"markdown","f97eebea":"markdown","e4e8dc6e":"markdown","999b836d":"markdown","01b5f2d7":"markdown","5c2ce3c0":"markdown","3f78ef41":"markdown","a2b3086c":"markdown","df8fe459":"markdown","82316d09":"markdown","b220c2a3":"markdown","7b454280":"markdown","108c5a3d":"markdown","9639b402":"markdown","b5dfa9bf":"markdown","6534cdfd":"markdown","e97d572d":"markdown","4da820e3":"markdown","9b2056b6":"markdown","23aae4fc":"markdown","8f9a45a0":"markdown","41eb1e32":"markdown","617faf73":"markdown","d8479103":"markdown","8d9255cf":"markdown","520b8041":"markdown","28fb3cea":"markdown","22eed26b":"markdown","517fab3b":"markdown","9cba884c":"markdown","074af710":"markdown","d60664b2":"markdown","badcc4e1":"markdown","6b00d99d":"markdown","b5d333d3":"markdown","a7f37682":"markdown","26258b19":"markdown","68177831":"markdown","edc85215":"markdown","13c2259c":"markdown","325005d1":"markdown","00e21aa3":"markdown","4c6c3724":"markdown","527c2a4e":"markdown","edb7ac05":"markdown","5ceb22ba":"markdown","dec2d125":"markdown","7098118e":"markdown","422d169a":"markdown","43098153":"markdown","326001d0":"markdown","9cef7668":"markdown","f421203c":"markdown","f85ccbfa":"markdown","8f83ab6f":"markdown","51b1af27":"markdown","373c53ad":"markdown","160d77db":"markdown","dfccf571":"markdown","f1e27b16":"markdown","9ad8bf8a":"markdown","da9ea956":"markdown","30ed1ba0":"markdown","8019a07e":"markdown","8c0c271e":"markdown","06665219":"markdown","d62f8628":"markdown","13332495":"markdown","b4fa0512":"markdown","40549605":"markdown","eabd855f":"markdown","3816adf3":"markdown","47f236c8":"markdown","034ea7e9":"markdown","a8e092c9":"markdown","8deea32f":"markdown","dfd20c29":"markdown","7febdd6d":"markdown","62643cc3":"markdown","66899f20":"markdown","af9d7b4f":"markdown","a7df7863":"markdown"},"source":{"e3fb47a0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport missingno as msno\nfrom sklearn.model_selection import train_test_split, cross_val_predict, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\nimport shap\nimport warnings\nwarnings.filterwarnings('ignore')","4302a2d8":"!pip install xgboost==1.0.0","b9a0e66a":"import xgboost","51ff721b":"class CreateFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n        \n    def transform(self, X, y=None):\n        X['week_of_year'] = pd.to_datetime(X.Date).dt.weekofyear\n        X['year'] = pd.to_datetime(X.Date).dt.year\n\n        X = X.merge(df_4holidays[['year', 'current_week', 'week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'current_week'])\n\n        X = X.merge(df_4holidays[['year', 'last_week', 'last_week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'last_week'])\n\n        X = X.merge(df_4holidays[['year', 'next_week', 'next_week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'next_week'])\n        \n        X['prop_to_buy'] =  ((X.Temperature * (100 - X.Unemployment) ) \/ (X.CPI * X.Fuel_Price ))\n        X['move_cost'] = X.CPI \/ X.Fuel_Price\n        X['revenue_potential'] = (100 * X.Unemployment) * X.Size\n        return X\n\nclass FeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X.Store = X.Store.astype(str)\n        X.Dept = X.Dept.astype(str)\n        X.Type = X.Type.astype(str)\n        X.week_holiday = X.week_holiday.astype(str)\n        X.last_week_holiday = X.last_week_holiday.astype(str)\n        X.next_week_holiday = X.next_week_holiday.astype(str)\n        X = pd.get_dummies(X)\n        return X[FEATURES_TO_MODEL]\n    \nclass FeatureSelector1(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X.Store = X.Store.astype(str)\n        X.Dept = X.Dept.astype(str)\n        X.Type = X.Type.astype(str)\n        X.week_holiday = X.week_holiday.astype(str)\n        X.last_week_holiday = X.last_week_holiday.astype(str)\n        X.next_week_holiday = X.next_week_holiday.astype(str)\n        X = pd.get_dummies(X)\n        return X\n\n\nclass FillNaValues(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X.MarkDown1 = X.MarkDown1.fillna(X.MarkDown1.dropna().median())\n        X.next_week_holiday.fillna('None', inplace=True)\n        X.last_week_holiday.fillna('None', inplace=True)\n        X.week_holiday.fillna('None', inplace=True)\n        X.Unemployment.fillna(X.Unemployment.dropna().median(), inplace=True)\n        X.IsHoliday.fillna(0, inplace=True)\n        X.prop_to_buy.fillna(X.prop_to_buy.dropna().median(), inplace=True)\n        X.move_cost.fillna(X.move_cost.dropna().median(), inplace=True)\n        X.revenue_potential.fillna(X.revenue_potential.dropna().median(), inplace=True)\n        return X\n\n    \ndef train_linear_regression(X_train, y_train, X_val, y_val):\n    lr = linear_model.ElasticNet(random_state=42)\n    lr.fit(X_train, y_train)\n    print('R^2 = {}'.format(r2_score(y_val, lr.predict(X_val))))\n    print('MAE = {}'.format(mean_absolute_error(y_val, lr.predict(X_val)) ))\n    print('RMSE = {}'.format(mean_squared_error(y_val, lr.predict(X_val), squared=False) ))\n    # cross_val_predict returns an array of the same size as `y` where each entry\n    # is a prediction obtained by cross validation:\n    predicted = cross_val_predict(lr, X_train, y_train, cv=5)\n    fig, ax = plt.subplots()\n    ax.scatter(y_train, predicted, edgecolors=(0, 0, 0))\n    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n    ax.set_xlabel('Measured')\n    ax.set_ylabel('Predicted')\n    plt.show()\n    return lr  \n\ndef train_xgboost_regressor(X_train, y_train, X_val, y_val):\n    xgb_model = xgboost.XGBRegressor(random_state=42, n_jobs=-1)\n    xgb_model.fit(X_train, y_train)\n    print('R^2 = {}'.format(r2_score(y_val, xgb_model.predict(X_val))))\n    print('MAE = {}'.format(mean_absolute_error(y_val, xgb_model.predict(X_val)) ))\n    print('RMSE = {}'.format(mean_squared_error(y_val, xgb_model.predict(X_val), squared=False) ))\n    predicted = cross_val_predict(xgb_model, X_train, y_train, cv=5)\n    fig, ax = plt.subplots()\n    ax.scatter(y_train, predicted, edgecolors=(0, 0, 0))\n    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n    ax.set_xlabel('Measured')\n    ax.set_ylabel('Predicted')\n    plt.show()\n    return xgb_model\n\ndef ensemble_xgb_elastic_net(model_1, model_2, X_train_1, X_train_2, y_train, X_val_1, X_val_2, y_val):\n    train_pred1 = model_1.predict(X_train_1)\n    train_pred2 = model_2.predict(X_train_2)\n    val_pred1 = model_1.predict(X_val_1)\n    val_pred2 = model_2.predict(X_val_2)\n    df_train = pd.DataFrame({'feat_model_1': train_pred1, 'feat_model_2': train_pred2})\n    df_val = pd.DataFrame({'feat_model_1': val_pred1, 'feat_model_2': val_pred2})\n    model_lr = linear_model.LinearRegression()\n    model_lr.fit(df_train, y_train)\n    print('R^2 = {}'.format(r2_score(y_val, model_lr.predict(df_val))))\n    print('MAE = {}'.format(mean_absolute_error(y_val, model_lr.predict(df_val)) ))\n    print('RMSE = {}'.format(mean_squared_error(y_val, model_lr.predict(df_val), squared=False) ))\n    return model_lr\n","556d7a01":"df_stores = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/stores.csv', sep=',')\ndf_features = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/features.csv.zip', sep=',')\ndf_train = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/train.csv.zip', sep=',')\ndf_teste = pd.read_csv('\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/test.csv.zip', sep=',')","51dd37f0":"df_stores.shape","ff210356":"df_stores.info()","1a096de0":"df_stores.head()","e3b255a0":"df_stores.Store.nunique()","b4a8fd94":"df_stores['Type'].value_counts()","7cb366cb":"ax = sns.barplot(x=sorted(df_stores.Type.unique()),y=df_stores['Type'].value_counts(),\n                 palette=\"Blues_d\")\nplt.xlabel('Store types')\nplt.ylabel(\"Quantity\")\nplt.title('Quantity analysis of store types')\nsns.despine()\nplt.show();\n","5d9d23b0":"sns.distplot(df_stores['Size']);\nsns.despine();","b92aabea":"df_stores['Size'].plot.hist(density=True);\nplt.xlabel('Store Size');\nplt.title('Analysing the Size distribution ');\nplt.show();","6cda6cfb":"for t in df_stores['Type'].unique():\n    df_stores.loc[df_stores.Type==t, 'Size'].plot.hist(density=False, label=t, alpha=0.8);\n    plt.xlabel('Store Size');\nplt.legend(title='Type of store');\nplt.title('Analysing the Size distribution by Type of Store');\nplt.show();","2dbc1384":"for t in df_stores['Type'].unique():\n    print('Analysing the Size distribution for Store Type {}'.format(t));\n    display(df_stores.loc[df_stores.Type==t, 'Size'].describe())\n    df_stores.loc[df_stores.Type==t, 'Size'].plot.hist(density=True, label=t, alpha=0.8);\n    plt.xlabel('Store Size');\n    plt.legend(title='Type of store');\n    plt.title('');\n    plt.show();","86e81848":"df_features.shape","f36e4484":"df_features.info()","99516308":"df_features.head()","21a4a2d3":"df_features.groupby(['Store']).agg({'Date':['count', 'min','max']})","59985a14":"df_features.Temperature.plot.hist(density=True, alpha=0.85);\nplt.xlabel('Temperature');\nplt.title('Temperature Distribution for the whole dataset');\nplt.show()","3bc27a56":"df_features.groupby(['Store']).agg({'Temperature': ['min','mean','max', 'std']})","77dc878f":"df_features.loc[df_features.Store==7, 'Temperature'].plot.hist(label='Store 7', density=True, alpha=.6);\ndf_features.loc[df_features.Store==33, 'Temperature'].plot.hist(label='Store 33', density=True, alpha=.6);\nplt.xlabel('Temperature');\nplt.legend();\nplt.title('Comparing the temperature of the hottest store to the coldest store');\nplt.show();","a5460ef0":"df_features.Fuel_Price.plot.hist();\nplt.xlabel('Fuel Price');\nplt.title('Fuel Price Distribution for the whole dataset');\nplt.show()","4be151fa":"for i in df_features.Store.unique():\n    df_features.loc[df_features.Store==i, 'Fuel_Price'].plot();\n    plt.title('Fuel Price through time for Store {}'.format(i));\n    plt.ylabel('Fuel Price');\n    plt.xticks([]);\n    plt.xlabel('Time {} to {}'.format(min(df_features.Date),max(df_features.Date) ));\n    plt.show();","8ea67096":"df_features.sample()","f325a7b8":"for mark in [i for i in df_features.columns if 'Mark' in i]:\n    df_features[mark].plot.hist(density=False);\n    plt.title('Distribuition of {}'.format(mark));\n    plt.show();  ","56432b41":"df_features.groupby(['Store']).agg({'MarkDown1':['min','mean', 'max']})","be92a64a":"for st in df_features.Store.unique():\n    df_features.loc[df_features.Store==st, 'MarkDown1'].plot.hist(density=True, alpha=0.8, label=st);\n    plt.xlabel('MarkDown1');\n    plt.title('MarkDown1 distribution for Store {}'.format(st));\n    plt.show();","3a366b3d":"df_features.CPI.plot.hist();","cb8c894b":"for st in df_features.Store.unique():\n    df_features.loc[df_features.Store==st, 'CPI'].plot.hist(density=True, alpha=0.8, label=st);\n    plt.xlabel('CPI value');\n    plt.title('CPI distribution for Store {}'.format(st));\n    plt.show();","2edce32e":"df_features.groupby('Store').agg({'CPI': ['min', 'mean', 'max']})","97446746":"df_features.sample()","b8721d07":"df_features.Unemployment.plot.hist();","60869109":"df_features.groupby('Store').agg({'Unemployment':['min', 'mean', 'max']})","057d0612":"df_features.IsHoliday.dtype","e9edbca6":"df_features.IsHoliday = df_features.IsHoliday.astype(int)","8da10074":"df_features.groupby(['Store']).agg({'IsHoliday':sum})","5d42e5b7":"df_features.sample()","4d553ff3":"ax = sns.scatterplot(x=\"CPI\", y=\"Fuel_Price\",hue='Store', data=df_features)","2cbada54":"ax = sns.scatterplot(x=\"CPI\", y=\"Unemployment\",hue='Store', data=df_features)","4cbcf704":"df_train.head()","ca5be905":"df_teste.head()","29d411ff":"df_stores.head()","9961f9dd":"df_features.head()","342fc8a9":"(df_train.Store.dtype == df_stores.Store.dtype, df_teste.Store.dtype == df_stores.Store.dtype )","58c792bc":"df_temp_train = df_train.merge(df_stores, how='left', on='Store')\ndf_temp_test = df_teste.merge(df_stores, how='left', on='Store')","ce795eb0":"df_temp_test.sample()","d86f5e5a":"df_temp_train.sample()","dda874ed":"(df_temp_train.Store.dtype == df_features.Store.dtype, df_temp_train.Date.dtype == df_features.Date.dtype)","d4143ead":"(df_temp_test.Store.dtype == df_features.Store.dtype, df_temp_test.Date.dtype == df_features.Date.dtype)","9c1b27c9":"df_train_full = df_temp_train.merge(df_features, how='left', on=['Store', 'Date'])","a6dd021b":"df_test_full = df_temp_test.merge(df_features, how='left', on=['Store', 'Date'])","5bd16bc1":"df_train_full.shape","5b909a0e":"df_test_full.shape","5e7bd2a3":"df_train_full.head()","82466763":"df_train_full.IsHoliday_x.astype(int).sum() == df_train_full.IsHoliday_y.sum()","91a42348":"df_train_full.drop('IsHoliday_x', axis=1,inplace=True)","a70a105a":"df_train_full.rename(columns={'IsHoliday_y':'IsHoliday'}, inplace=True)","2004d28a":"df_test_full.head()","21ad3b02":"df_test_full.IsHoliday_x.astype(int).sum() == df_test_full.IsHoliday_y.sum()","8472b91f":"df_test_full.drop('IsHoliday_x', axis=1,inplace=True)","a0bb6c4b":"df_test_full.rename(columns={'IsHoliday_y':'IsHoliday'}, inplace=True)","6df3006e":"dict_lgt_hlds ={'Super_Bowl': ['12-Feb-10', '11-Feb-11', '10-Feb-12', '8-Feb-13']\n               ,'Labor_Day': ['10-Sep-10', '9-Sep-11', '7-Sep-12', '6-Sep-13']\n                ,'Thanksgiving': ['26-Nov-10', '25-Nov-11', '23-Nov-12', '29-Nov-13']\n                ,'Christmas': ['31-Dec-10', '30-Dec-11', '28-Dec-12', '27-Dec-13']\n               }","bc63cce2":"lista = []","ad9f3c44":"for hol in dict_lgt_hlds.keys():\n    for dt in dict_lgt_hlds[hol]:\n        lista.append([hol, pd.to_datetime(dt).year, pd.to_datetime(dt).week])","85046205":"df_4holidays = pd.DataFrame(lista, columns=['week_holiday','year', 'current_week'])","e6e60290":"df_4holidays['last_week'] =df_4holidays['current_week'] +1\ndf_4holidays['next_week'] =df_4holidays['current_week'] - 1\ndf_4holidays['last_week_holiday'] = df_4holidays['week_holiday']\ndf_4holidays['next_week_holiday'] = df_4holidays['week_holiday']","e0d2f14e":"df_4holidays","55202f29":"df_train_full['week_of_year'] = pd.to_datetime(df_train_full.Date).dt.weekofyear\ndf_train_full['year'] = pd.to_datetime(df_train_full.Date).dt.year","6dc63f01":"sns.countplot(data=df_train_full, x='week_of_year');\nplt.xticks(rotation=45);","d089093f":"sns.countplot(data=df_train_full, x='year');","e3dd5602":"df_train_full_4h = df_train_full.merge(df_4holidays[['year', 'current_week', 'week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'current_week'])\n    ","104e668a":"df_train_full_4h = df_train_full_4h.merge(df_4holidays[['year', 'last_week', 'last_week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'last_week'])","bd11fb66":"df_train_full_4h = df_train_full_4h.merge(df_4holidays[['year', 'next_week', 'next_week_holiday']]\n                                       , how='left', left_on=['year', 'week_of_year'],right_on=['year', 'next_week'])","767d3463":"pd.options.display.max_columns=None","48b5dcd1":"df_train_full_4h.head()","40109da9":"data = df_train_full_4h.groupby('Store').agg({'Weekly_Sales':'mean', 'Type':'max', 'Size':'mean'}).reset_index()","fbc38b76":"data.groupby('Type').agg({'Weekly_Sales':'mean'})","57129e8e":"ax = sns.scatterplot(x=\"Store\", y=\"Weekly_Sales\",hue='Type', data=data)","6a565229":"data['sales_per_size'] = data['Weekly_Sales'] \/data['Size']","4f8f408c":"data.groupby('Type').agg({'sales_per_size':'mean'})","d9907ddd":"ax = sns.scatterplot(x=\"Store\", y=\"sales_per_size\",hue='Type', data=data)","a14056d6":"data = df_train_full_4h.groupby(['Type','Dept']).agg({'Weekly_Sales':'mean'}).reset_index()","26414a08":"ax = sns.scatterplot(x=\"Dept\", y=\"Weekly_Sales\",hue='Type' ,data=data)","c6b5b8c2":"data = df_train_full_4h.groupby(['Temperature']).agg({'Weekly_Sales':'mean'}).reset_index()","a108747c":"ax = sns.scatterplot(x=\"Temperature\", y=\"Weekly_Sales\" ,data=data)","5c1e33ad":"data['temp_bins'] = pd.cut(data.Temperature, bins=10).astype(str)","7d53ff39":"ax = sns.lineplot(x=\"temp_bins\", y=\"Weekly_Sales\" ,data=data.groupby('temp_bins').agg({'Weekly_Sales':'mean'}).reset_index())\nplt.xticks(rotation=45);","8b2a3dbf":"ax = sns.scatterplot(x=\"Temperature\", y=\"Weekly_Sales\",hue='Type' ,data=df_train_full_4h)","3747b24d":"ax = sns.scatterplot(x=\"Fuel_Price\", y=\"Weekly_Sales\",hue='Type' ,data=df_train_full_4h)","6b08322e":"ax = sns.scatterplot(x=\"MarkDown1\", y=\"Weekly_Sales\",hue='Type' ,data=df_train_full_4h)","2a89adeb":"ax = sns.scatterplot(x=\"CPI\", y=\"Weekly_Sales\",hue='Type' ,data=df_train_full_4h)","af35803e":"ax = sns.scatterplot(x=\"Unemployment\", y=\"Weekly_Sales\",hue='Type' ,data=df_train_full_4h)","54738a6e":"df_train_full_4h.groupby('IsHoliday').agg({'Weekly_Sales':'mean'})","f4d5f118":"ax = sns.lineplot(x=\"IsHoliday\", y=\"Weekly_Sales\", markers=True ,data=df_train_full_4h.groupby('IsHoliday').agg({'Weekly_Sales':'mean'}).reset_index())\nplt.xticks(rotation=45);","035900d2":"df_train_full_4h.groupby('week_holiday').agg({'Weekly_Sales':'mean'})","53d26fa4":"ax = sns.lineplot(x=\"week_holiday\", y=\"Weekly_Sales\", markers=True ,data=df_train_full_4h.groupby('week_holiday').agg({'Weekly_Sales':'mean'}).reset_index())\nplt.xticks(rotation=45);","d6536b93":"df_train_full_4h.groupby('last_week_holiday').agg({'Weekly_Sales':'mean'})","b45ca81d":"ax = sns.lineplot(x=\"last_week_holiday\", y=\"Weekly_Sales\", markers=True ,data=df_train_full_4h.groupby('last_week_holiday').agg({'Weekly_Sales':'mean'}).reset_index())\nplt.xticks(rotation=45);","b0580e81":"df_train_full_4h.groupby('next_week_holiday').agg({'Weekly_Sales':'mean'})","eadf80cc":"ax = sns.lineplot(x=\"next_week_holiday\", y=\"Weekly_Sales\", markers=True ,data=df_train_full_4h.groupby('next_week_holiday').agg({'Weekly_Sales':'mean'}).reset_index())\nplt.xticks(rotation=45);","642572df":"df_train_full_4h.describe()","cf22aaf6":"df_train_full_4h['prop_to_buy'] =  ((df_train_full_4h.Temperature * (100 - df_train_full_4h.Unemployment) ) \/ (df_train_full_4h.CPI * df_train_full_4h.Fuel_Price ))","2d7a9ecb":"ax = sns.scatterplot(x=\"prop_to_buy\", y=\"Weekly_Sales\", hue='Type' ,data=df_train_full_4h)\n#plt.xticks(rotation=45);","eba7d199":"g = sns.jointplot(x=\"prop_to_buy\", y=\"Weekly_Sales\" ,data=df_train_full_4h,\n                  kind=\"reg\", truncate=False,\n                  #xlim=(0, 60), ylim=(0, 12),\n                  color=\"m\"\n                  #, height=7\n                 )","b3af6dca":"df_train_full_4h['move_cost'] = df_train_full_4h.CPI \/ df_train_full_4h.Fuel_Price","5af155f1":"ax = sns.scatterplot(x=\"move_cost\", y=\"Weekly_Sales\", hue='Type' ,data=df_train_full_4h)\n#plt.xticks(rotation=45);","3612ecb4":"g = sns.jointplot(x=\"move_cost\", y=\"Weekly_Sales\" ,data=df_train_full_4h,\n                  kind=\"reg\", truncate=False,\n                  #xlim=(0, 60), ylim=(0, 12),\n                  color=\"m\"\n                  #, height=7\n                 )","7d3e120b":"df_train_full_4h['revenue_potential'] = (100 * df_train_full_4h.Unemployment) * df_train_full_4h.Size","ce4ddca1":"ax = sns.scatterplot(x=\"revenue_potential\", y=\"Weekly_Sales\", hue='Type' ,data=df_train_full_4h)","0f3c1eca":"g = sns.jointplot(x=\"revenue_potential\", y=\"Weekly_Sales\" ,data=df_train_full_4h,\n                  kind=\"reg\", truncate=False,\n                  #xlim=(0, 60), ylim=(0, 12),\n                  color=\"m\"\n                  #, height=7\n                 )","19cd714c":"msno.matrix(df_train_full_4h);","b729ccc9":"df_train_sel = df_train_full_4h.drop(['MarkDown2'\n                                     ,'MarkDown3'\n                                     ,'MarkDown4'\n                                     ,'MarkDown5'\n                                     ,'year'\n                                     ,'Date'\n                                     ,'current_week'\n                                      ,'last_week'\n                                      ,'next_week'\n                                      ,'week_of_year'\n                                     ], axis=1)","8563d76d":"df_train_sel.MarkDown1 = df_train_sel.MarkDown1.fillna(df_train_sel.MarkDown1.dropna().median())","6e6160ff":"df_train_sel.next_week_holiday.fillna('None', inplace=True)\ndf_train_sel.last_week_holiday.fillna('None', inplace=True)\ndf_train_sel.week_holiday.fillna('None', inplace=True)","347c89b6":"FET_TO_SCALER = [\n    'Size'\n    ,'Temperature'\n    ,'Fuel_Price'\n    ,'MarkDown1'\n    ,'CPI'\n    ,'Unemployment'\n    ,'prop_to_buy'\n    ,'move_cost'\n    ,'revenue_potential'\n]","83098afc":"scaler = StandardScaler()","dbb0c900":"df_train_sel[FET_TO_SCALER] = scaler.fit_transform(df_train_sel[FET_TO_SCALER])","cb2d39c1":"df_train_sel.describe()","4de5d7ba":"msno.matrix(df_train_sel);","99905f2a":"df_train_sel.info()","825b114a":"df_train_sel.Store = df_train_sel.Store.astype(str)\ndf_train_sel.Dept = df_train_sel.Dept.astype(str)\ndf_train_sel.Type = df_train_sel.Type.astype(str)\ndf_train_sel.week_holiday = df_train_sel.week_holiday.astype(str)\ndf_train_sel.last_week_holiday = df_train_sel.last_week_holiday.astype(str)\ndf_train_sel.next_week_holiday = df_train_sel.next_week_holiday.astype(str)","1bbc96ea":"df_train_dummies = pd.get_dummies(df_train_sel)","387bb41d":"df_train_dummies.shape","1188726a":"df_train_dummies.sample(3)","24c0626e":"list(df_train_dummies.columns)","e9de269b":"GP1 = ['Size'\n       ,'Temperature'\n       ,'Fuel_Price'\n       ,'MarkDown1'\n       ,'CPI'\n       ,'Unemployment'\n       ,'IsHoliday'\n       ,'prop_to_buy'\n       ,'move_cost'\n       ,'revenue_potential'\n    \n]\nGP2 = [\n    'week_holiday_Christmas'\n    ,'week_holiday_Labor_Day'\n    ,'week_holiday_None'\n    ,'week_holiday_Super_Bowl'\n    ,'week_holiday_Thanksgiving'\n    ,'last_week_holiday_Labor_Day'\n    ,'last_week_holiday_None'\n    ,'last_week_holiday_Super_Bowl'\n    ,'last_week_holiday_Thanksgiving'\n    ,'next_week_holiday_Christmas'\n    ,'next_week_holiday_Labor_Day'\n    ,'next_week_holiday_None'\n    ,'next_week_holiday_Super_Bowl'\n    ,'next_week_holiday_Thanksgiving'\n]\n\nGP3 = [\n    'Type_A'\n    ,'Type_B'\n    ,'Type_C'\n]","cf25b1ae":"f, ax = plt.subplots(figsize=(11, 6))\nsns.heatmap(df_train_dummies[GP1].corr(), annot=True, linewidths=.5, ax=ax);","6f146b5a":"f, ax = plt.subplots(figsize=(15, 8))\nsns.heatmap(df_train_dummies[GP2].corr(), annot=True, linewidths=.5, ax=ax);","3bb40811":"f, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(df_train_dummies[GP3].corr(), annot=True, linewidths=.5, ax=ax);","6aac6667":"FEATURES_TO_MODEL = [\n\n 'MarkDown1',\n 'Unemployment',\n 'IsHoliday',\n 'prop_to_buy',\n 'move_cost',\n 'revenue_potential',\n \n 'Store_1',\n 'Store_10',\n 'Store_11',\n 'Store_12',\n 'Store_13',\n 'Store_14',\n 'Store_15',\n 'Store_16',\n 'Store_17',\n 'Store_18',\n 'Store_19',\n 'Store_2',\n 'Store_20',\n 'Store_21',\n 'Store_22',\n 'Store_23',\n 'Store_24',\n 'Store_25',\n 'Store_26',\n 'Store_27',\n 'Store_28',\n 'Store_29',\n 'Store_3',\n 'Store_30',\n 'Store_31',\n 'Store_32',\n 'Store_33',\n 'Store_34',\n 'Store_35',\n 'Store_36',\n 'Store_37',\n 'Store_38',\n 'Store_39',\n 'Store_4',\n 'Store_40',\n 'Store_41',\n 'Store_42',\n 'Store_43',\n 'Store_44',\n 'Store_45',\n 'Store_5',\n 'Store_6',\n 'Store_7',\n 'Store_8',\n 'Store_9',\n \n 'Dept_1',\n 'Dept_10',\n 'Dept_11',\n 'Dept_12',\n 'Dept_13',\n 'Dept_14',\n 'Dept_16',\n 'Dept_17',\n 'Dept_18',\n 'Dept_19',\n 'Dept_2',\n 'Dept_20',\n 'Dept_21',\n 'Dept_22',\n 'Dept_23',\n 'Dept_24',\n 'Dept_25',\n 'Dept_26',\n 'Dept_27',\n 'Dept_28',\n 'Dept_29',\n 'Dept_3',\n 'Dept_30',\n 'Dept_31',\n 'Dept_32',\n 'Dept_33',\n 'Dept_34',\n 'Dept_35',\n 'Dept_36',\n 'Dept_37',\n 'Dept_38',\n 'Dept_39',\n 'Dept_4',\n 'Dept_40',\n 'Dept_41',\n 'Dept_42',\n 'Dept_43',\n 'Dept_44',\n 'Dept_45',\n 'Dept_46',\n 'Dept_47',\n 'Dept_48',\n 'Dept_49',\n 'Dept_5',\n 'Dept_50',\n 'Dept_51',\n 'Dept_52',\n 'Dept_54',\n 'Dept_55',\n 'Dept_56',\n 'Dept_58',\n 'Dept_59',\n 'Dept_6',\n 'Dept_60',\n 'Dept_65',\n 'Dept_67',\n 'Dept_7',\n 'Dept_71',\n 'Dept_72',\n 'Dept_74',\n 'Dept_77',\n 'Dept_78',\n 'Dept_79',\n 'Dept_8',\n 'Dept_80',\n 'Dept_81',\n 'Dept_82',\n 'Dept_83',\n 'Dept_85',\n 'Dept_87',\n 'Dept_9',\n 'Dept_90',\n 'Dept_91',\n 'Dept_92',\n 'Dept_93',\n 'Dept_94',\n 'Dept_95',\n 'Dept_96',\n 'Dept_97',\n 'Dept_98',\n 'Dept_99',\n \n 'Type_A',\n \n 'Type_C',\n \n 'week_holiday_Christmas',\n 'week_holiday_Labor_Day',\n 'week_holiday_None',\n 'week_holiday_Super_Bowl',\n 'week_holiday_Thanksgiving',\n 'last_week_holiday_Labor_Day',\n 'last_week_holiday_None',\n 'last_week_holiday_Super_Bowl',\n 'last_week_holiday_Thanksgiving',\n 'next_week_holiday_Christmas',\n 'next_week_holiday_Labor_Day',\n 'next_week_holiday_None',\n 'next_week_holiday_Super_Bowl',\n 'next_week_holiday_Thanksgiving'\n]","7e89575c":"pipeline_regression = Pipeline([\n                                ('createFeatures', CreateFeatures())                         \n                                ,('fillNaValues', FillNaValues()) \n                                ,('featureSelector', FeatureSelector())\n                                ,('scaler', StandardScaler())\n                                \n                               ])\n\npipeline_xgboost = Pipeline([\n                                ('createFeatures', CreateFeatures())\n                                ,('featureSelector', FeatureSelector1())\n                                \n                               ])","b9cc3703":"X = df_train_full.drop('Weekly_Sales', axis=1)\ny = df_train_full['Weekly_Sales']","31a13887":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=42)","0ff56859":"X_train.shape","61b032b4":"X_val.shape","760bacf8":"X_train_LR = pipeline_regression.fit_transform(X_train) ","a492abc4":"X_val_LR = pipeline_regression.transform(X_val)","72c7fd5b":"lr_model = train_linear_regression(X_train_LR, y_train, X_val_LR, y_val)","dca3ecd5":"hyperparameters = {\"max_iter\": [1, 5, 10],\n                      \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n    \n    \nscoring = {'MAE': make_scorer(mean_absolute_error), 'r2': make_scorer(r2_score)}\n\n# Create randomized search 5-fold cross validation \nrand_ser = RandomizedSearchCV(lr_model\n                         , hyperparameters\n                         , random_state=42\n                        , n_iter=100\n                         , cv=5\n                         , verbose=0\n                         , n_jobs=-1\n                         , scoring=scoring\n                         ,refit='r2'\n                         )\n\n# Fit randomized search\nbest_model_lr = rand_ser.fit(X_train_LR, y_train)\n\nprint('R^2 = {}'.format(r2_score(y_val, best_model_lr.predict(X_val_LR))))\nprint('MAE = {}'.format(mean_absolute_error(y_val, best_model_lr.predict(X_val_LR)) ))\nprint('RMSE = {}'.format(mean_squared_error(y_val, best_model_lr.predict(X_val_LR), squared=False) ))","3cdef3ca":"X_train_XG = pipeline_xgboost.fit_transform(X_train)","09e9e418":"X_val_XG = pipeline_xgboost.transform(X_val)","d009d99a":"xgb = train_xgboost_regressor(X_train_XG, y_train, X_val_XG, y_val)","a8bc78b0":"explainer = shap.TreeExplainer(xgb)","e8303a7e":"shap.initjs()\nshap_values = explainer.shap_values(X_train_XG, check_additivity=False)\nshap.summary_plot(shap_values, X_train_XG)","c927b90f":"model_xgb_elatcnet = ensemble_xgb_elastic_net(model_1=lr_model\n                         , model_2=xgb\n                         , X_train_1=X_train_LR\n                         , X_train_2=X_train_XG\n                         , y_train = y_train\n                         , X_val_1 = X_val_LR\n                         , X_val_2 = X_val_XG\n                         , y_val = y_val\n                        )","2872c20d":"we see that the store size and departments are variable with high predictive power\n","284a293b":"Training the model:\n","dfa580d3":"Transforming the training and validation dataset with the Pipeline made for regression\n","8eaab9e9":"Another nice thing about XGBOOST is that it has great interpretability of the most important variables, which is a very good thing to validate if the model is making sense, rationally speaking at the level of variables, and not just looking at performance metrics.\n","1ea373a0":"Transforming categorical variables into binary variables\n","32accd83":"# 4.2.2 - Temperature","24a2fe47":"We know that a low CPI rate, a low unemployment rate, and cheap fuel price are factors that encourage people to spend money. So we are going to create a variable with these 3 factors, which we will call propensity to buy the region\n","b90b613c":"Now, grouping by Stores, let's analyze how the temperature variable behaves","fc662a7c":"We will try to better calibrate the parameters of Elastic Net and try to obtain better performance. In this step we will use a Randomized Search.\n","2d95aa8a":"Variables selected for modeling\n","14832202":"Weeks that discriminate most: Thanksgiving week, and one week before Christmas\n","cba22bea":"In this step, we will train a Linear Regression Elastic Net that has the regularization parameters l1 and l2 combined (Lasso + Ridge). This is a simpler model computationally speaking and has low variance.\n","3aeba0fd":"# 6 - Feature Engineering","b4becc1c":"We conclude that the store and department type variables discriminate well as to the gross value sold\n","ec1545ab":"\nAt this stage, the idea is to analyze the main variables of the base with the variable response of the problem, in this case the amount of weekly sales.","549bc4bf":"First step is to understand the data of each dataset source. I am starting with \"stores.csv\"","fb605f2f":"On average, the price of fuel for all stores followed the same upward and downward trend during the period. It is worth noting that the regions of Stores 44, 41, 38, 33, 32, 28, 17, 16, 13 and 7. Perhaps these stores are in nearby regions and some other external factor may have influenced the further decline in those regions.\n","c5bad539":"# 6.1.1 - The region's propensity to buy","9110d385":"# 5.7 - Unemployment vs Sales","fb12bff9":"# 8.2 - XGBOOST Regressor","57975656":"# 5.6 - CPI vs Sales","c5ee0ba1":"We will analyze if all stores have the same number of lines (sales dates) and if the minimum and maximum dates coincide.\n","31b6fde4":"# 4.3 - Merging datasets","8e3cdfc6":"# 4.2.6 - Is Holiday","359323e9":"Nice! As expected, regions with a lower CPI have a slight tendency to spend more than regions with a higher CPI, customers who experience less price increases spend more\n","c00b83a7":"# 4.2.8 - CPI vs Unemployment","946300e8":"# 5.5 - MarkDown1 vs Sales","f97eebea":"Does cheaper gasoline influence people's propensity to go out more to buy?\n","e4e8dc6e":"Let's analyze and understand the \"MarkDown\" variable. anonymized data related to promotional markdowns that Walmart is running.\n","999b836d":"How does this promotion related variable behave?\n","01b5f2d7":"Although we don't know each type of store is, we can realize that the types \"A\" and \"B\" is at least 80% overall.","5c2ce3c0":"The \"Markdown\" column with more information (greater dispersion in the distribution) is Markdown1. Let's look at it in more detail\n","3f78ef41":"# 6.1 - Creating new features","a2b3086c":"Let\u2019s drop some variables that we found in the exploratory analysis that didn\u2019t make sense in modeling\n","df8fe459":"# 4.4 - Plug-in the Four Largest Holidays in the dataset","82316d09":"In this step we will try to train a more complex model with a greater variance, a Gradient Boosting (decision tree ensemble), in this case the XGBOOST. This model is very useful because it requires little treatment in the input dataset, accepts nulls, can work well with correlated variables, and does not need to normalize variables, as in the case of Linear Regression\n","b220c2a3":"In this step we will prepare the dataset for the training, as we intend to use a linear regression, we have to analyze the correction of the variables, fill in missings, normalize numerical variables, among other treatments\n","7b454280":"Let's go deeper in store types:","108c5a3d":"In this step we will create pipelines for handling the modeling dataset for both models we intend to use\n","9639b402":"Are there departments that sell more than others?\n","b5dfa9bf":"Let's look at the fuel price distribution\n","6534cdfd":"It worked! We achieved a minor error by joining the two models!\n","e97d572d":"# 6.2 - Feature Selection","4da820e3":"# 4.1.2 - Store Sizes","9b2056b6":"Incredible performance!\n","23aae4fc":"Here I will create a variable that I call revenue potential, which relates the size of the store to the local unemployment rate\n","8f9a45a0":"Nice! We have 182 records for each store, and the records range from 2010-02-05 to 2013-07-26\n","41eb1e32":"# 8.1.1 - Randomized Search for LR Elastic Net","617faf73":"Separating the dataset between training and validation\n","d8479103":"# 5.4 - Fuel Price vs Sales","8d9255cf":"Another hypothesis confirmed here, stores in regions with a high unemployment rate, spend less !!\n","520b8041":"# 6.1.2 - Locomotion cost\n","28fb3cea":"Interesting! Type \"A\" stores are the largest, with an average size of ~ 180kunits of measurement, followed by type \"B\", with average size of ~ 102k measurement units, and finally type C stores with average size of ~ 40k measurement units .\n","22eed26b":"# 4.1.1 - Type of Store","517fab3b":"Variables to normalize\n","9cba884c":"# 4.2.4 - MarkDown","074af710":"Marking the weeks after the holiday\n","d60664b2":"The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks:\n\n- **Super Bowl**: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n- **Labor Day**: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n- **Thanksgiving**: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n- **Christmas**: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13","badcc4e1":"\nMarking the weeks of big holidays","6b00d99d":"# 4.2.5 - CPI (The Consumer Price Index)","b5d333d3":"In this step, we will use a tool called Shapley Values. It has 3 dimensions to analyze. On the y-axis, it is the importance of the variable, from top to bottom (most important to least important). Axis x, it is the strength of the variable, if it points to the left, it contributes to a lower output value of the model, and to the right, a higher output value of the model. The other dimension is the intensity of the variable, represented by colors, a lower intensity represented by blue, and a higher intensity represented by red.\n","a7f37682":"Do places with a lower unemployment rate spend more money?\n","26258b19":"# 5.2 - Dept vs Sales","68177831":"This step, we go further! How about joining XGBOOST with Elastic Net? Although XGBOOST performed much better than regression, there must be cases where the regression shows predictions with a smaller error than XGBOOST, so we will use the prediction of the two models and train a third regression in order to obtain a smaller error . Does it work?\n","edc85215":"# 4.2 - Features dataset","13c2259c":"Below we will analyze the evolution of the fuel price over time for each Store\n","325005d1":"Stores in regions with higher unemployment rates are expected to have less sales\n","00e21aa3":"# 4.2.1 - Date","4c6c3724":"Now, let's go deeper in the store sizes","527c2a4e":"There is a bias that bigger stores will sell more, so let's weigh sales by store size and see what happens\n","edb7ac05":"Analyzing the temperature alone does not tell us much, the biggest purchases happen at the average temperature observed in the dataset, which is the average temperature for the regions analyzed\n","5ceb22ba":"This cell contains all the functions built for use in this work","dec2d125":"Wow! Type C stores are twice as efficient in their sales considering their size ... given that a larger store can generate a higher fixed cost.\n","7098118e":"# 4.1 - Stores dataset","422d169a":"# 4 - Exploratory Analysis","43098153":"Importing all the libraries used in this work","326001d0":"# 6.1.3 - Revenue potential","9cef7668":"In this step we will try to explore and understand the data provided ... it is a step to be comfortable with the dataset that we will use in the modeling, and to obtain \"insights\" from the data","f421203c":"Let's understand how the temperature distribution of the base is based on the dates\n","f85ccbfa":"Transforming the dataset for week view of the year:\n","8f83ab6f":"# 8 - Modeling","51b1af27":"Certainly these special holidays drive people to spend more, shall we check?\n","373c53ad":"# 3 - Loading the database","160d77db":"The table above also shows that the hottest store is 33! Let's compare the temperature distribution of the warmest store with the coldest store.\n","dfccf571":"# 4.2.7 - CPI vs Fuel Price","f1e27b16":"Most stores have an average temperature between 50-70. What draws attention is the coldest store of all (Store 7) ... with an average temperature of ~ 37, and a minimum of -7! Is there a relationship between the temperature of the place and the amount of sales? In warmer places do people buy more? We will study this soon.\n","9ad8bf8a":"# 8.2.1 - Model Interpretability - Shapley Values","da9ea956":"# 2 - Used Functions","30ed1ba0":"Now let's explore the feature dataset!","8019a07e":"# 5 - Bivariate Analysis","8c0c271e":"Here we will try to create a variable that I will call \"transportation cost\", which relates the CPI and the fuel price\n","06665219":"# 5.1 - Store x Weekly Sales","d62f8628":"marking the weeks before the big holidays\n","13332495":"Our hypothesis here is that the sales weeks before and after the big holidays are also affected! So we are going to mark these weeks on the bases.\n","b4fa0512":"Apparently MarkDown1 has a slightly negative relationship to sales ... lower MarkDown, higher sales?\n","40549605":"# 5.3 - Temperature vs Sales","eabd855f":"# 7 - Pipeline to models","3816adf3":"# 4.2.5 - Unemployment","47f236c8":"Let's look at the correlation of the variables. The idea here is to eliminate variables that are very correlated with each other, either positively or negatively. In my criteria I will remove variables that have a correlation module> 0.6","034ea7e9":"# 5.8 - Holiday\tvs Sales","a8e092c9":"# 1 - Importing used Libraries","8deea32f":"Do regions with a lower CPI have a propensity to spend more?","dfd20c29":"# 4.2.3 - Fuel Price","7febdd6d":"Another variable that alone doesn't tell us much, later we will try to create new variables using the fuel price \n","62643cc3":"Does temperature influence people's propensity to spend more money?\n","66899f20":"# 8.3 - Ensemble XGBOOST + ELastic Net","af9d7b4f":"# 8.1 - Linear Regression (Elastic Net)","a7df7863":"In this step I am loading all data source given for this problem"}}