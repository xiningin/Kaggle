{"cell_type":{"43cffd71":"code","dc44e8bc":"code","c4c65e7e":"code","bd3596d5":"code","d721d10f":"code","7abc654f":"code","184deaaf":"code","de0e514c":"code","3b6c3ec8":"code","d02617d3":"markdown","39d2d74e":"markdown","c49a3e1d":"markdown","1d6174ac":"markdown","16804855":"markdown"},"source":{"43cffd71":"!pip install tensorflow","dc44e8bc":"!git clone https:\/\/github.com\/jmvalenciae\/U-Net.git","c4c65e7e":"%mv U-Net\/* .\/\n%rm -r U-Net\/","bd3596d5":"!mkdir tfrecords weights","d721d10f":"!python3 make_TFrecords.py --img_path=..\/input\/tomato-seeds\/seeds_data\/JPEGImages\/ --mask_path=..\/input\/tomato-seeds\/seeds_data\/SegmentationClass\/","7abc654f":"!python3 train.py --batch_size=2 --save_freq=2","184deaaf":"pip install tensorflow","de0e514c":"import tensorflow as tf \ntf.__version__","3b6c3ec8":"import matplotlib.pyplot as plt\nfrom model import get_model\nimport tensorflow as tf\nimport countR\n\nif __name__ == \"__main__\":\n    img_path = \"..\/input\/tomato-seeds\/seeds_data\/JPEGImages\/006.jpg\"\n    weights_path = \".\/weights\/cp-0010.ckpt\"\n    \n    model = get_model(output_channels=1, size=None)\n    model.load_weights(weights_path)\n    \n    X = plt.imread(img_path)\/255\n    X = tf.convert_to_tensor(X)\n    X = tf.expand_dims(X, 0)\n    \n    Y = model.predict(X)\n    \n    countR.display([X[0],Y[0]])","d02617d3":"## Instalaci\u00f3n de Librerias","39d2d74e":"## Entrenamiento","c49a3e1d":"## Initializaci\u00f3n del proyecto","1d6174ac":"## Preparaci\u00f3n del Dataset","16804855":"## Demostraci\u00f3n"}}