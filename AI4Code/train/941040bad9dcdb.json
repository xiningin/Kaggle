{"cell_type":{"9ece7d44":"code","270a4fa2":"code","5cd13cd2":"code","aad81e8e":"code","a3353da0":"code","d69a3298":"code","1deb3df1":"code","b9ab4ec8":"code","86a49e71":"code","36141d58":"code","0a0eccb5":"code","1ab6ea1c":"markdown","20cc062d":"markdown","f01a0621":"markdown","546b98f7":"markdown","c89fb363":"markdown","f182bcd7":"markdown","16668c53":"markdown","d49f6376":"markdown","d9f4a7be":"markdown"},"source":{"9ece7d44":"import matplotlib.pyplot as plt\nimport cv2\nimport PIL\nimport tensorflow as tf\nimport numpy as np\nimport os\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\nfrom keras.layers import LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, RMSprop\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\nprint(os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\"))\n\nbase_folder = \"..\/input\/fruits-360_dataset\/fruits-360\"\n","270a4fa2":"epochs=4\nbatch_size = 128\nsteps_per_epoch_train=37836\/\/128\nsteps_per_epoch_val=12709\/\/128","5cd13cd2":"datagen_train = ImageDataGenerator(\n      rescale=1.\/255,\n      vertical_flip=True,\n      horizontal_flip=True,\n      shear_range = 0.5,\n      zoom_range = 0.2,\n      rotation_range=90)\ndatagen_test = ImageDataGenerator(rescale=1.\/255)","aad81e8e":"generator_train = datagen_train.flow_from_directory(directory=base_folder+'\/Training',\n                               \n                                                    target_size=(100,100),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',shuffle=True)\n\ngenerator_test = datagen_test.flow_from_directory(directory=base_folder+'\/Test',\n                                                  target_size=(100,100),\n                                                  batch_size=batch_size,\n                                                  class_mode='categorical',\n                                                  shuffle=False)","a3353da0":"steps_test = generator_test.n \/ batch_size\nsteps_test","d69a3298":"from sklearn.utils.class_weight import compute_class_weight\ncls_train = generator_train.classes\ncls_test = generator_test.classes\nfrom collections import OrderedDict\nclasses = list(generator_train.class_indices.keys())\nnum_values = []\nunique, counts = np.unique(cls_train, return_counts=True)\nvaldict=OrderedDict(zip(unique, counts))\nfor i in range(75):\n    num_values.append(valdict[i])\nplt.figure(figsize=(30,30))\nx = np.arange(len(num_values))\nxlabel = classes\nplt.bar(x, num_values)\nplt.xticks(x, xlabel)\nplt.show()    ","1deb3df1":"class_weight = compute_class_weight(class_weight='balanced', classes=np.unique(cls_train), y=cls_train)\nclass_weight","b9ab4ec8":"learning_rate = 2.2279389932900166e-05\nnum_dense_nodes = 1731\nnum_epoch = 4","86a49e71":"model = Sequential()\n  \nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(100, 100, 3), name='conv2d_1'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\n  \nmodel.add(Conv2D(64, (3,3), padding='same', name='conv2d_2'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\nmodel.add(MaxPooling2D(pool_size=2, padding='same', name='maxpool_1'))\n  \n  \nmodel.add(Conv2D(128, (3,3), padding='same', name='conv2d_3'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\n  \nmodel.add(Conv2D(128, (3,3), padding='same', name='conv2d_4'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\nmodel.add(MaxPooling2D(pool_size=2, padding='same', name='maxpool_2'))\n  \nmodel.add(Conv2D(256, (3,3), padding='same', name='conv2d_5'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\n  \nmodel.add(Conv2D(256, (3,3), padding='same', name='conv2d_6'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\n  \nmodel.add(Conv2D(256, (3,3), padding='same', name='conv2d_7'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\nmodel.add(MaxPooling2D(pool_size=2, padding='valid', name='maxpool_3'))\n  \nmodel.add(Flatten(name='flatten_1'))\nmodel.add(Dense(num_dense_nodes))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.5))\nmodel.add(Dropout(0.5, name='dropout_1'))\nmodel.add(Dense(75, activation='softmax'))\noptimizer=Adam(lr=learning_rate)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","36141d58":"model.summary()","0a0eccb5":"model_train = model.fit_generator(generator=generator_train,\n                                  epochs=num_epoch,\n                                  steps_per_epoch=steps_per_epoch_train,\n                                  class_weight=class_weight,\n                                  validation_data=generator_test,\n                                  validation_steps=steps_per_epoch_val)","1ab6ea1c":"## Plot the model architecture","20cc062d":"## Define epochs, batch_size, steps_per_epoch_train, steps_per_epoch_val","f01a0621":"## Set augmentations for each image","546b98f7":"## Make 3 x 3 overlapping kernel CNN\n### we can get an effect of lowering computational cost\n### && acquiring non-linearities well","c89fb363":"# Fruit 360 Analysis by Gerard Kim\n\n## Import libraries","f182bcd7":"## Train a model and get an accuracy","16668c53":"## Make generators for each training and test datasets","d49f6376":"## Set Hyperparameters\n### these values had been calculated by Bayesian optimization ","d9f4a7be":"## Compute class weight and plot it\n### It needs to be considered for backpropagation"}}