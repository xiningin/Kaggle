{"cell_type":{"c531eb4a":"code","49fdd9bd":"code","bff21c59":"code","31213d64":"code","28f846d3":"code","9c71b351":"code","261474c5":"code","66dfb069":"code","e1c84542":"code","755f695a":"code","877bcf3e":"code","1f918b22":"code","cca211d6":"code","5701ce46":"code","9ac39956":"code","f0046b72":"code","75e3f138":"code","ba903708":"code","834d1773":"code","b1351fa6":"code","82d6ec92":"code","fec5ea4a":"code","6870da6e":"code","09a78f8f":"code","1310d0ab":"code","5ffeba1f":"code","f0c326b7":"code","7e9c8c2b":"code","07f333e8":"code","e618cecd":"code","9d061b7c":"code","1ae4dece":"code","cef30f62":"code","a1f855fe":"code","44efe170":"code","08d2b477":"code","ea3c89ea":"code","7d5d66f3":"code","313b9307":"code","a7bb0959":"code","4db391b3":"code","e6572eaa":"code","d0099913":"code","00956575":"code","59ec4865":"code","fb6249a5":"code","187a68fb":"code","b72fb2c5":"code","3aa86ec3":"code","42d1a932":"code","3b7b9e5a":"code","c89406f0":"code","0371f294":"code","8e99a408":"code","8b5a3619":"code","66b474a0":"code","a6da8bbc":"code","09e1b162":"code","9cb50a92":"code","cf82f000":"code","7b1815a3":"code","4f762e1b":"code","32b95b5e":"code","757b3d69":"code","897a3a8c":"code","64bd246e":"code","73dedef9":"code","c39a17ff":"code","dd59a3ee":"markdown","47dd5785":"markdown","11b94c50":"markdown","4e682962":"markdown","9ad1d63c":"markdown","117ab750":"markdown","4dd16fae":"markdown","e4eeb02b":"markdown","a9d3827d":"markdown","216f7fbe":"markdown","4a5cdb8a":"markdown","b3e75d2e":"markdown","be3dcb73":"markdown","19b66a67":"markdown","ed08bbae":"markdown","84e701b1":"markdown","3ad2fe90":"markdown","73d7708c":"markdown","4b209e52":"markdown","c725653e":"markdown","2cc55964":"markdown","04d3d0d5":"markdown","412f890c":"markdown","07b9c0c5":"markdown","801df44b":"markdown","9319fd18":"markdown","435992f4":"markdown","5f0e5afe":"markdown","0030f2df":"markdown","2a953798":"markdown","49138c9d":"markdown","51bf108a":"markdown","e1fab00f":"markdown","a6fddf0a":"markdown","2a7c8feb":"markdown","5667a815":"markdown","2a15ac08":"markdown","daf1bb18":"markdown","122f3d3b":"markdown","a7901c51":"markdown","5994f476":"markdown","43492143":"markdown","bfa71c2b":"markdown","3bdc9e7a":"markdown","00cc7924":"markdown","2f615e9c":"markdown","757ba020":"markdown","79d2cfb9":"markdown","f72831ad":"markdown","316930d7":"markdown","261bbd7c":"markdown","94683d73":"markdown","c9503d20":"markdown","bf35e0ed":"markdown","cc9d68e6":"markdown","45880919":"markdown","51f6e03e":"markdown","10367966":"markdown","0011c8d5":"markdown","f3824c3b":"markdown","d5da46b3":"markdown","dfe2a1ca":"markdown","5e0dee5a":"markdown","3d4cc887":"markdown","06c65654":"markdown","0d71cfd3":"markdown","917c0f8f":"markdown","8982549f":"markdown","16aa1081":"markdown","dd112f2a":"markdown","3769beca":"markdown","0039dbc6":"markdown","3f3b28d0":"markdown","dc456111":"markdown","113ac1a4":"markdown","8e12141f":"markdown","39d4abf9":"markdown","1e9f36b8":"markdown","82beef1b":"markdown","58e16d89":"markdown","1922d4e7":"markdown","41b447eb":"markdown","5eef4e16":"markdown","61e687e5":"markdown","d162f1a2":"markdown","487dbf7a":"markdown","f604b139":"markdown","ac9d057a":"markdown","1a62aa6e":"markdown","2c2a72a1":"markdown","daa9132e":"markdown","28ce659e":"markdown","45f83848":"markdown"},"source":{"c531eb4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49fdd9bd":"!cat \/kaggle\/input\/amazon-fine-food-reviews\/hashes.txt","bff21c59":"!head -n 2 \/kaggle\/input\/amazon-fine-food-reviews\/Reviews.csv","31213d64":"%%time\ndf = pd.read_csv(\"\/kaggle\/input\/amazon-fine-food-reviews\/Reviews.csv\")","28f846d3":"df.info()","9c71b351":"df.head(2)","261474c5":"import sqlite3\n\nconn = sqlite3.connect(\"\/kaggle\/input\/amazon-fine-food-reviews\/database.sqlite\")\ncur = conn.cursor()","66dfb069":"cur.execute(\"\"\"\nSELECT * FROM Reviews limit 1;\n\"\"\")\ncur.fetchone()","e1c84542":"sql_data_5_samples = pd.read_sql_query(\"\"\"\nSELECT * FROM Reviews limit 5\n\"\"\", conn)\nsql_data_5_samples.head()","755f695a":"%%time\ncur.execute(\"\"\"\nSELECT count(*) FROM Reviews;\n\"\"\")\ncur.fetchone()","877bcf3e":"from prettytable import PrettyTable\nimport time\n\nx = PrettyTable()\nx.field_names = [\"Attribute\",\"Claim\",\"Actual\",\"Match\"]\nx.add_rows(\n    [\n        [\"# reviews\", \"568454\",df.shape[0],\"YES\"],\n        [\"Distinct users\", \"256059\", df[\"UserId\"].nunique(), \"YES\"],\n        [\"Distinct products\", \"74258\", df[\"ProductId\"].nunique(), \"YES\"],\n        [\"Users with more than 50 reviews\", \"260\", (df.groupby(\"UserId\").size()).where(lambda x:x>50).count(), \"YES\"],\n        [\"Reviews Time Range\", \"Oct 1999 - Oct 2012\", f\"{time.strftime('%b %Y', time.localtime(df['Time'].min()))} - {time.strftime('%b %Y', time.localtime(df['Time'].max()))}\", \"YES\"]\n    ]\n)\nprint(x)","1f918b22":"with pd.option_context('display.max_colwidth', -1):\n    display(df.head())","cca211d6":"df_shape = df.shape\nprint(f\"No. of Datapoints : {df_shape[0]}\")\nprint(f\"No. of Features : {df_shape[1]}\")","5701ce46":"df.isnull().sum()","9ac39956":"with pd.option_context('display.max_colwidth', -1):\n    display(df[df[\"ProfileName\"].isnull()].head())","f0046b72":"with pd.option_context('display.max_colwidth', -1):\n    display(df[df[\"Summary\"].isnull()].head())","75e3f138":"from matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.figure(figsize=(10,5))\nsns.countplot(df['Score'], palette=sns.color_palette(\"RdYlGn\", 5))\nplt.title(\"Distribution of Ratings across the entire dataset\", fontweight='bold', fontsize=15)\nplt.xlabel(\"Ratings of Reviews\")\nplt.ylabel(\"Number of reviews corresponding to each of 5 ratings\")\nplt.show();\n\nprint(df['Score'].value_counts().sort_index());","ba903708":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = [f'{k} ({df[\"Score\"].value_counts()[k]} samples)' for k in df['Score'].value_counts().keys()]\nsizes = dict(df['Score'].value_counts()).values()\n\nfig1, ax1 = plt.subplots(figsize=(8,8))\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title(\"Distribution of ratings in reviews\",pad=40, fontweight='bold', fontsize=15)\nplt.show();","834d1773":"mask_duplicated_reviews = df.duplicated(subset=[\"UserId\",\"Time\",\"Text\"], keep='first')\ncount_duplicated_reviews = mask_duplicated_reviews.value_counts()\n\nsum_reviews = count_duplicated_reviews.sum()\nperc_duplicated_reviews = (count_duplicated_reviews\/sum_reviews) * 100\n\nx = PrettyTable()\nx.field_names = [\"\",\"Count\",\"Percentage of Total\"]\nx.add_rows([\n    [\"Duplicate Reviews\", count_duplicated_reviews[True], perc_duplicated_reviews[True]],\n    [\"Original Reviews\", count_duplicated_reviews[False], perc_duplicated_reviews[False]],\n])\nprint(x)","b1351fa6":"df = df[~mask_duplicated_reviews]\n\nprint(f\"Updated No. of Datapoints : {df.shape[0]}\")","82d6ec92":"print(f\"{df[df['Score']==3].shape[0]}\/{df.shape[0]} ({round((df[df['Score']==3].shape[0]\/df.shape[0])*100,2)}% of the total)\")","fec5ea4a":"with pd.option_context('display.max_colwidth', -1):\n    display(df[df[\"Score\"]==3].head(10))","6870da6e":"print(f\"No. of Datapoints BEFORE discarding : {df.shape[0]}\")\n\ndf = df[df[\"Score\"]!=3]\n\nprint(f\"No. of Datapoints AFTER discarding : {df.shape[0]}\")\n","09a78f8f":"df[df[\"HelpfulnessNumerator\"] > df[\"HelpfulnessDenominator\"]]","1310d0ab":"print(f\"No. of Datapoints BEFORE discarding : {df.shape[0]}\")\n\ndf = df[df[\"HelpfulnessNumerator\"] <= df[\"HelpfulnessDenominator\"]]\n\nprint(f\"No. of Datapoints AFTER discarding : {df.shape[0]}\")\n","5ffeba1f":"df.head()","f0c326b7":"%%time\ndf[\"Helpfulness_Perc\"] = df[[\"HelpfulnessNumerator\",\"HelpfulnessDenominator\"]].apply(lambda x: ((x[0]\/x[1])*100.0) if x[1] else 0.0, axis=1)\ndf = df.drop([\"HelpfulnessNumerator\",\"HelpfulnessDenominator\"], axis=1)\ndf.head()","7e9c8c2b":"plt.figure(figsize=(18,7))\nsns.histplot(data=df[\"Helpfulness_Perc\"], bins=50)\nplt.title(\"Distribution of Helpfulness_Perc\",fontweight='bold', fontsize=15)\nplt.xticks(range(0,100,2), rotation=45)\nplt.show();","07f333e8":"x = PrettyTable()\nx.field_names = [\"Condition\", \"Class\"]\nx.add_rows([\n    [\"Helpfulness_Perc >= 75\", \"Useful\"],\n    [\"40 < Helpfulness_Perc < 75\",\"Intermediate\"],\n    [\"0 < Helpfulness_Perc <= 40\",\"Not Useful\"],\n    [\"Helpfulness_Perc = 0\",\"Not Available\"],\n])\nprint(x)","e618cecd":"# Assigning Helpfulness indicator\ndf.loc[df[\"Helpfulness_Perc\"] >= 75, 'Helpfulness_indicator'] = 'Useful'\ndf.loc[(df[\"Helpfulness_Perc\"] > 40) & (df[\"Helpfulness_Perc\"] < 75), 'Helpfulness_indicator'] = 'Intermediate'\ndf.loc[(df[\"Helpfulness_Perc\"] > 0) & (df[\"Helpfulness_Perc\"] <= 40), 'Helpfulness_indicator'] = 'Not Useful'\ndf.loc[df[\"Helpfulness_Perc\"] == 0, 'Helpfulness_indicator'] = 'Not Available'\n\ndf = df.drop([\"Helpfulness_Perc\"], axis=1)\n\ndf.head()","9d061b7c":"plt.figure(figsize=(12,7))\nsns.countplot(df['Helpfulness_indicator'], palette=sns.color_palette(\"RdYlGn\", 4), order=[\"Not Available\",\"Not Useful\",\"Intermediate\",\"Useful\"])\nplt.title(\"Distribution of Helpfulness_indicator\",fontweight='bold', fontsize=15)\nplt.xlabel(\"Helpfulness_indicator\")\nplt.ylabel(\"Number of reviews corresponding to each of 4 Helpfulness_indicator\")\nplt.show();\n\nprint(df['Helpfulness_indicator'].value_counts()[[0,3,2,1]]);","1ae4dece":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = [f'{k} ({df[\"Helpfulness_indicator\"].value_counts()[k]} samples)' for k in df['Helpfulness_indicator'].value_counts().keys()]\nsizes = dict(df['Helpfulness_indicator'].value_counts()).values()\n\nfig1, ax1 = plt.subplots(figsize=(10,10));\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title(\"All Samples\", pad=40,fontweight='bold', fontsize=15)\nplt.show();","cef30f62":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = [f'{k} ({df[\"Helpfulness_indicator\"].value_counts()[k]} samples)' for k in ['Useful','Not Useful']]\nsizes = dict(df['Helpfulness_indicator'].value_counts())\nsizes.pop('Not Available')\nsizes.pop('Intermediate')\nsizes = sizes.values()\n\nfig1, ax1 = plt.subplots(figsize=(10,10));\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title(\"Excluding 'Not Available' and 'Intermediate' Samples\", pad=40, fontweight='bold', fontsize=15)\nplt.show();","a1f855fe":"df.loc[df[\"Score\"] > 3, 'Sentiment_Class'] = 'Positive'\ndf.loc[df[\"Score\"] < 3, 'Sentiment_Class'] = 'Negative'","44efe170":"with pd.option_context('display.max_colwidth', -1):\n    display(df.head(2))","08d2b477":"# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = [f'{k} ({df[\"Sentiment_Class\"].value_counts()[k]} samples)' for k in df['Sentiment_Class'].value_counts().keys()]\nsizes = dict(df['Sentiment_Class'].value_counts())\nsizes = sizes.values()\n\nfig1, ax1 = plt.subplots(figsize=(10,10));\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title(\"Count of 'Positive' and 'Negative' Samples\", pad=40, fontweight='bold', fontsize=15)\nplt.show();","ea3c89ea":"%%time\ndf[\"Review_Word_Count\"] = df[\"Text\"].apply(lambda x: len(x.split()))\nwith pd.option_context('display.max_colwidth', -1):\n    display(df.head(1))","7d5d66f3":"df_temp = df[(df[\"Helpfulness_indicator\"]!= \"Not Available\") & (df[\"Helpfulness_indicator\"]!= \"Intermediate\")]\ndf_temp_1 = df_temp[\"Helpfulness_indicator\"].groupby(df_temp[\"Sentiment_Class\"]).value_counts(normalize=True)\ndf_temp_1 = df_temp_1*100\ndf_temp_1 = df_temp_1.rename(\"Percentage\").reset_index()\n\nplt.figure(figsize=(10,6))\nsns.barplot(data=df_temp_1, x=\"Sentiment_Class\", y=\"Percentage\", hue=\"Helpfulness_indicator\", hue_order=[\"Not Useful\",\"Useful\"], palette=sns.color_palette(\"RdYlGn\", 2));\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\nplt.show()\ndf_temp_1","313b9307":"df_temp = df[(df[\"Helpfulness_indicator\"]!= \"Not Available\") & (df[\"Helpfulness_indicator\"]!= \"Intermediate\")]\ndf_temp_1 = df_temp[\"Sentiment_Class\"].groupby(df_temp[\"Helpfulness_indicator\"]).value_counts(normalize=True)\ndf_temp_1 = df_temp_1*100 \ndf_temp_1 = df_temp_1.rename(\"Percentage\").reset_index()\n\nplt.figure(figsize=(10,6))\nsns.barplot(data=df_temp_1, x=\"Helpfulness_indicator\", y=\"Percentage\", hue=\"Sentiment_Class\", hue_order=[\"Negative\",\"Positive\"], palette=sns.color_palette(\"RdYlGn\", 2));\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\nplt.show()\ndf_temp_1","a7bb0959":"temp_df_useful_nonuseful = df[(df[\"Helpfulness_indicator\"]!= \"Not Available\") & (df[\"Helpfulness_indicator\"]!= \"Intermediate\")]\nplt.figure(figsize=(20,8))\nsns.violinplot(x='Review_Word_Count', y='Helpfulness_indicator', data=temp_df_useful_nonuseful);","4db391b3":"temp_df_useful_nonuseful_500wc = df[(df[\"Helpfulness_indicator\"]!= \"Not Available\") & (df[\"Helpfulness_indicator\"]!= \"Intermediate\") & (df[\"Review_Word_Count\"]<500)]\nplt.figure(figsize=(20,8))\nsns.violinplot(x='Review_Word_Count', y='Helpfulness_indicator', data=temp_df_useful_nonuseful_500wc, orient=\"h\")\nplt.xticks(range(0,500,10), rotation=45)\nplt.show()\ntemp_df_useful_nonuseful_500wc[\"Review_Word_Count\"].groupby(temp_df_useful_nonuseful_500wc[\"Helpfulness_indicator\"]).describe()","e6572eaa":"plt.figure(figsize=(20,8))\nsns.violinplot(x='Review_Word_Count', y='Sentiment_Class', data=temp_df_useful_nonuseful);","d0099913":"plt.figure(figsize=(20,8))\nsns.violinplot(x='Review_Word_Count', y='Sentiment_Class', data=temp_df_useful_nonuseful_500wc, orient=\"h\")\nplt.xticks(range(0,500,10), rotation=45)\nplt.show()\ntemp_df_useful_nonuseful_500wc[\"Review_Word_Count\"].groupby(temp_df_useful_nonuseful_500wc[\"Sentiment_Class\"]).describe()","00956575":"%%time\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n\ntext = \" \".join(review for review in df[\"Text\"])\nprint (\"There are {} words in the combination of all review.\".format(len(text)))\n\n# Create stopword list:\ndefault_stopwords=set(stopwords.words('english'))\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=default_stopwords, background_color=\"white\", width=1200, height=600).generate(text)\n\n# Display the generated image:\nplt.figure(figsize=(30,12))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","59ec4865":"%%time\ndf_positive = df[df[\"Sentiment_Class\"] == \"Positive\"]\ntext = \" \".join(review for review in df_positive[\"Text\"])\nprint (\"There are {} words in the combination of all positive reviews.\".format(len(text)))\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=default_stopwords, background_color=\"white\", width=1200, height=600).generate(text)\n\n# Display the generated image:\nplt.figure(figsize=(30,12))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","fb6249a5":"%%time\ndf_negative = df[df[\"Sentiment_Class\"] == \"Negative\"]\ntext = \" \".join(review for review in df_negative[\"Text\"])\nprint (\"There are {} words in the combination of all negative reviews.\".format(len(text)))\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=default_stopwords, background_color=\"white\", width=1200, height=600).generate(text)\n\n# Display the generated image:\nplt.figure(figsize=(30,12))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","187a68fb":"import re\n\n# Ref: https:\/\/stackoverflow.com\/a\/12982689\ndef remove_html_tags(sentence):\n    pattern = re.compile(\"<.*?>\") # Match any text wrapped with < and > along with the < and >\n    cleaned_sentence = re.sub(pattern,'',sentence).strip()\n    return cleaned_sentence\n\nsentence = \"<a href='sample.com'> <b> Click <\/b> here <br\/> <\/a>\"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {remove_html_tags(sentence)}\")","b72fb2c5":"# Ref: https:\/\/stackoverflow.com\/a\/12982689\ndef remove_urls(sentence):\n    http_pattern = re.compile(r\"http\\S+\") # Matches all words starting with 'http' and followed by 1 or more occurance of non-whitespace characters\n    cleaned_sentence = re.sub(http_pattern,'',sentence).strip()\n    www_pattern = re.compile(r\"www\\S+\") # Matches all words starting with 'www' and followed by 1 or more occurance of non-whitespace characters\n    cleaned_sentence = re.sub(www_pattern,'',cleaned_sentence)\n    return cleaned_sentence\n\nsentence = \"\"\"url starting with http s : https:\/\/www.google.com\/search?client=ubuntu&channel=fs&q=google+drive+storage+plans&ie=utf-8&oe=utf-8\nurl starting with http : http:\/\/google.com\nurl starting with www : www.google.co.in\"\"\"\nprint(\"Sample\\n\")\nprint(f\"Before:\\n {sentence}\\n\")\nprint(f\"After:\\n {remove_urls(sentence)}\")","3aa86ec3":"# Ref: https:\/\/www.w3schools.com\/html\/html_entities.asp\n# Ref: https:\/\/stackoverflow.com\/a\/12982689\ndef remove_html_entities(sentence):\n    pattern = re.compile(\"&[a-z0-9]+|&#[0-9]{1,6}|&#x[0-9a-f]{1,6}\")\n    cleaned_sentence = re.sub(pattern,'',sentence).strip()\n    return cleaned_sentence\n\nsentence = \"&nbsp, &#60, a&#771\"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {remove_html_entities(sentence)}\")","42d1a932":"# Ref: https:\/\/stackoverflow.com\/a\/18082370\/4084039\ndef remove_words_with_numbers(sentence):\n    pattern = re.compile(\"\\S*\\d\\S*\") # Match a word starting with 0 or more occurances of a non whitespace character, then a digit followed by 0 or more occurances of a non whitespace character\n    cleaned_text = re.sub(pattern,\"\", sentence).strip()\n    return cleaned_text\n\nsentence = \"  The5 number is removed removed55 \"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {remove_words_with_numbers(sentence)}\")","3b7b9e5a":"# Ref : https:\/\/stackoverflow.com\/a\/37013006\ndef remove_words_with_repeated_characters(sentence): \n    pattern = re.compile(\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\")\n    cleaned_text  = re.sub(pattern,' ',sentence)\n    return (cleaned_text)\n\nsentence = \"This looks soooooooo good! I am so happpyyy aa aaa aaaa\"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {remove_words_with_repeated_characters(sentence)}\")","c89406f0":"# Ref : https:\/\/stackoverflow.com\/a\/47091490\ndef expand_eng_contradictions(phrase):\n    # specific\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase\n\nsentence = \"Hey I'm Yann, how're you and how's it going ? That's interesting: I'd love to hear more about it.\"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {expand_eng_contradictions(sentence)}\")","0371f294":"# Ref: https:\/\/stackoverflow.com\/a\/5843547\/4084039\ndef remove_special_characters_punctuations(sentence):\n    pattern = re.compile(\"[^a-zA-Z]+\") # match a single character not present in the set (basically anything other than a-z and A-Z)\n    cleaned_text  = re.sub(pattern,' ',sentence).strip()\n    return cleaned_text\n\nsentence = \"fsd*?~,,,( garr1rgggv.)#! a\"\nprint(\"Sample\")\nprint(f\"Before: {sentence}\")\nprint(f\"After: {remove_special_characters_punctuations(sentence)}\")","8e99a408":"from nltk.stem.porter import PorterStemmer\n\nporter = PorterStemmer()\nprint(f\"was -> {porter.stem('was')}\")\nprint(f\"flying -> {porter.stem('flying')}\")\nprint(f\"delicious -> {porter.stem('delicious')}\")\nprint(f\"caring -> {porter.stem('caring')}\")\nprint(f\"bought -> {porter.stem('bought')}\")","8b5a3619":"from nltk.stem.snowball import SnowballStemmer\n\nsnowball = SnowballStemmer('english')\nprint(f\"was -> {snowball.stem('was')}\")\nprint(f\"flying -> {snowball.stem('flying')}\")\nprint(f\"delicious -> {snowball.stem('delicious')}\")\nprint(f\"caring -> {snowball.stem('caring')}\")\nprint(f\"bought -> {snowball.stem('bought')}\")","66b474a0":"from nltk.stem.lancaster import LancasterStemmer\n\nlancaster = LancasterStemmer()\nprint(f\"was -> {lancaster.stem('was')}\")\nprint(f\"flying -> {lancaster.stem('flying')}\")\nprint(f\"delicious -> {lancaster.stem('delicious')}\")\nprint(f\"caring -> {lancaster.stem('caring')}\")\nprint(f\"bought -> {lancaster.stem('bought')}\")","a6da8bbc":"from nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer \n\nlemmatizer = WordNetLemmatizer()\n\nsentence = \"the boy's cars are different colors, best go went gone going run runs ran and running\"\n\nword_list = word_tokenize(sentence)\nlemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n# print(sentence)\n# print(lemmatized_output)\nprint(f\"Sample Sentence: {sentence}\")\nprint(f\"After Stemming: {lemmatized_output}\")","09e1b162":"import spacy\n\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n\nsentence = \"the boy's cars are different colors, best go went gone going run runs ran and running\"\n\ndoc = nlp(sentence)\n\nprint(f\"Sample Sentence: {sentence}\")\nprint(f\"After Lemmatization: {' '.join([token.lemma_.lower() if token.lemma_ != '-PRON-' else token.lower_ for token in doc])}\")","9cb50a92":"def only_stem_print(word):\n    stem=snowball.stem(word)\n    print(f\"{word} -> {stem}\")\n\nonly_stem_print('was')\nonly_stem_print('flying')\nonly_stem_print('flew')\nonly_stem_print('flown')\nonly_stem_print('delicious')\nonly_stem_print('delicacy')\nonly_stem_print('caring')\nonly_stem_print('bought')\nonly_stem_print('tasty')\nonly_stem_print('taste')\nonly_stem_print('cry')\nonly_stem_print('crying')\n\ndef only_stem(word):\n    return snowball.stem(word)","cf82f000":"def only_lemmatize_print(word):\n    lemma=nlp(word)[0].lemma_\n    lemma = lemma.lower() if lemma != '-PRON-' else word.lower()\n    print(f\"{word} -> {lemma}\")\n\nonly_lemmatize_print('was')\nonly_lemmatize_print('flying')\nonly_lemmatize_print('flew')\nonly_lemmatize_print('flown')\nonly_lemmatize_print('delicious')\nonly_lemmatize_print('delicacy')\nonly_lemmatize_print('caring')\nonly_lemmatize_print('bought')\nonly_lemmatize_print('tasty')\nonly_lemmatize_print('taste')\nonly_lemmatize_print('cry')\nonly_lemmatize_print('crying')\nonly_lemmatize_print('she')\n\ndef only_lemmatize(word):\n    lemma = nlp(word)[0].lemma_\n    lemma = lemma.lower() if lemma != '-PRON-' else word.lower()\n    return lemma","7b1815a3":"def lemmatize_then_stem_print(word):\n    lemma=nlp(word)[0].lemma_\n    stem=snowball.stem(lemma)\n    print(f\"{word} -> {lemma} -> {stem}\")\n\n\nlemmatize_then_stem_print('was')\nlemmatize_then_stem_print('flying')\nlemmatize_then_stem_print('flew')\nlemmatize_then_stem_print('flown')\nlemmatize_then_stem_print('delicious')\nlemmatize_then_stem_print('delicacy')\nlemmatize_then_stem_print('caring')\nlemmatize_then_stem_print('bought')\nlemmatize_then_stem_print('tasty')\nlemmatize_then_stem_print('taste')\nlemmatize_then_stem_print('cry')\nlemmatize_then_stem_print('crying')\n\ndef lemmatize_then_stem(word):\n    lemma=nlp(word)[0].lemma_\n    stem=snowball.stem(lemma)\n    return stem","4f762e1b":"df = df.reset_index(drop=True)","32b95b5e":"%%time\nfrom tqdm.contrib.concurrent import process_map\nfrom nltk.corpus import stopwords\n\ndefault_stopwords=set(stopwords.words('english'))\n\npreprocessed_reviews=[] # store all the preprocessed reviews\n\ndef process_review(idx, remove_stopwords=False):\n    review = df.at[idx, 'Text']\n    \n    filtered_sentence=[]\n    \n    review=remove_html_tags(review)\n    review=remove_urls(review)\n    review=remove_html_entities(review)\n    review=remove_words_with_numbers(review)\n    review=remove_words_with_repeated_characters(review)\n    review=expand_eng_contradictions(review)\n    review=remove_special_characters_punctuations(review)\n    \n    for word in review.split(): # Tokenizing a text or review\n        \n        if((word.isalpha()) and (len(word)> 2)):\n            word_lower = word.lower()\n            \n            # Removing Stopwords\n            if((not remove_stopwords) or ((remove_stopwords) and (word_lower not in default_stopwords))):\n                filtered_sentence.append(word_lower)\n                \n    str1 = \" \".join(filtered_sentence) #final string of cleaned words\n    return idx, str1.strip()\n\n\nfor idx, processed_review in process_map(process_review, df.index, max_workers=4):\n    preprocessed_reviews.append(processed_review)\n    \n\npreprocessed_reviews_words = []\nfor review in preprocessed_reviews:\n    for word in review.split():\n        preprocessed_reviews_words.append(word)\nprint(f\"Count of Distinct words in corpus without stemming:{len(set(preprocessed_reviews_words))}\");","757b3d69":"%%time\npreprocessed_reviews=[] # store all the preprocessed reviews\n\ndef process_review(idx, remove_stopwords=False):\n    review = df.at[idx, 'Text']\n    \n    filtered_sentence=[]\n    \n    review=remove_html_tags(review)\n    review=remove_urls(review)\n    review=remove_html_entities(review)\n    review=remove_words_with_numbers(review)\n    review=remove_words_with_repeated_characters(review)\n    review=expand_eng_contradictions(review)\n    review=remove_special_characters_punctuations(review)\n    \n    for word in review.split(): # Tokenizing a text or review\n        \n        if((word.isalpha()) and (len(word)> 2)):\n            word_lower = word.lower()\n            \n            # Removing Stopwords\n            if((not remove_stopwords) or ((remove_stopwords) and (word_lower not in default_stopwords))):\n                s=(only_stem(word_lower)) #Stemming the word using SnowBall Stemmer\n                filtered_sentence.append(s)\n                \n    str1 = \" \".join(filtered_sentence) #final string of cleaned words\n    return idx, str1.strip()\n\n\nfor idx, processed_review in process_map(process_review, df.index, max_workers=4):\n    preprocessed_reviews.append(processed_review)\n#     df.at[idx, 'CleanedText'] = processed_review\n    \n\npreprocessed_reviews_words = []\nfor review in preprocessed_reviews:\n    for word in review.split():\n        preprocessed_reviews_words.append(word)\nprint(f\"Count of Distinct words in corpus with Stemming:{len(set(preprocessed_reviews_words))}\");","897a3a8c":"%%time\npreprocessed_reviews=[] # store all the preprocessed reviews\n\ndef process_review(idx, remove_stopwords=False):\n    review = df.at[idx, 'Text']\n    \n    filtered_sentence=[]\n    \n    review=remove_html_tags(review)\n    review=remove_urls(review)\n    review=remove_html_entities(review)\n    review=remove_words_with_numbers(review)\n    review=remove_words_with_repeated_characters(review)\n    review=expand_eng_contradictions(review)\n    review=remove_special_characters_punctuations(review)\n    \n    for word in review.split(): # Tokenizing a text or review\n        \n        if((word.isalpha()) and (len(word)> 2)):\n            word_lower = word.lower()\n            \n            # Removing Stopwords\n            if((not remove_stopwords) or ((remove_stopwords) and (word_lower not in default_stopwords))):\n                s=(only_lemmatize(word.lower()))\n                filtered_sentence.append(s)\n                \n    str1 = \" \".join(filtered_sentence) #final string of cleaned words\n    return idx, str1.strip()\n\n\nfor idx, processed_review in process_map(process_review, df.index, max_workers=4):\n    preprocessed_reviews.append(processed_review)\n    df.at[idx, 'CleanedText'] = processed_review\n    \n\npreprocessed_reviews_words = []\nfor review in preprocessed_reviews:\n    for word in review.split():\n        preprocessed_reviews_words.append(word)\nprint(f\"Count of Distinct words in corpus with Stemming:{len(set(preprocessed_reviews_words))}\");","64bd246e":"with pd.option_context('display.max_colwidth', -1):\n    display(df.head())","73dedef9":"%%time\ndf.to_csv(\".\/cleaned_df_amazon_fine_food_reviews.csv\")","c39a17ff":"%%time\ndf.to_pickle(\".\/cleaned_df_amazon_fine_food_reviews.pkl\")","dd59a3ee":"### Observations:\n* There are 16 datapoints having 'ProfileName' as Null.  \n* There are 27 datapoints having 'Summary' as Null.  ","47dd5785":"## Check and Remove 3 Star(Neutral) Reviews","11b94c50":"### Observation\n* The sample reviews above dont have a summary\/title. But nothing to be concerned about since the 'text' corresponding to it is present, which may provide much more info about the review context\/message.\n* On a closer look, their text(review) attribute are all duplicated.  \n* Everything except the 'ProductId' are same; Even TIME!\n* So, we may safely presume that when a product has different variants(stock-keeping unit (SKU)), review written for any one of the variant gets replicated for all the other variants. And Each Product-Variant Combo gets assigned a different ProductId.\n* We may delete the duplicated data in further steps","4e682962":"## Stemming Conclusion\n* Out of the 3 stemmers that we have seen, snowball stemmer seems to be the good one to go ahead with in our usecase","9ad1d63c":"Observation:  \n1. **~78 percent** of the reviews in the dataset are **positive reviews** having ratings >3 (4 and 5)  \n2. **~14 percent** of the reviews in the dataset are **negative reviews** having ratings <3 (1 and 2)  \n3. Remaining **~8 percent** reviews have a rating of 3.\n4. Since a major portion of the reviews are positive, we can say that most of the users have a good experience with their purchases.","117ab750":"## EDA Observations (Consolidated):\n1. Positive reviews are more common than negative reviews.\n2. If we just look at Negative Reviews, a little more than quarter of the customers finding them non-useful(~27%)\n3. If we just look at Positive Reviews, there are very very few customers finding them non-useful(~2%)\n4. Most of the Customers find both Negative and Positive reviews useful (>94%) (presumably to make their purchase decisions).\n5. negative reviews are less helpful\n6. positive reviews are more helpful\n7. Helpful reviews are longer\n8. Positive Reviews are shorter\n\n## EDA Conclusion:\n* Positive reviews are common\n* Positive reviews are shorter (in terms of word count)\n* Helpful reviews are longer.\n* Despite being shorter, Positive reviews are found to be more helpful.\n","4dd16fae":"### Assigning 'Sentiment_Class' Feature\n\nScore > 3 (4,5) -> Positive  \nScore < 3 (1,2) -> Negative  ","e4eeb02b":"### Observations:\n* We can see the presence of words with positive sentiments such as:  \n    * excellent\n    * perfect\n    * good\n    * wonderful\n    * amazing\n    * best\n    * love\n    * tasty","a9d3827d":"### Peak the datapoints having a 'Score' of 3","216f7fbe":"### Porter Stemmer\n* This is one of the most common and gentle stemmer, Its fast but not very precise.  ","4a5cdb8a":"### Plotting word cloud to understand the top words that have occured most frequently in the NEGATIVE reviews.","b3e75d2e":"### Count of reviews in sqllite db","be3dcb73":"### Observation:\n* Since many outliers are there i.e. reviews with too many words are present, so in order to capture better co-relation between review length and ratings, we can consider reviews with 500 words or less.","19b66a67":"### Observations\n* **If we just look at Negative Reviews, a little more than quarter of the customers finding them non-useful(~27%)**.\n    1. Some cases of Negative Reviews being non-helpful : This could be for reviews which talks about some situational things which the customers who are reading them may not be concerned about. (for eg. a review which talks about how pricey the product is (this review will be negative since the rating given was less than 3). But the customer reading them is willing to pay a premium for good quality, taste. So in such cases, they find it not useful.)\n    2. Here, as we have seen earlier also reviews belonging to such cases are prevalent in our dataset.\n* **If we just look at Positive Reviews, there are very very few customers finding them non-useful(~2%)**. \n    1. Some cases of Positive Reviews being non-helpful : This could be for reviews which doesn't explain in length\/detail as to why the product is good(for example - \"good\", \"best\"). Or some reviews which may have been paid for by the brand itself, as we call paid reviews, which the customers prompty recognized by the tone of it.\n    2. So we can safely say that our dataset doesn't have much - such kind of reviews.\n* **So if we look at the above graph collectively, Most of the Customers find both Negative and Positive reviews useful (>94%) (presumably to make their purchase decisions).**","ed08bbae":"## Text Preprocessing","84e701b1":"### Remove URLs (starting with 'http' as well as 'www')","3ad2fe90":"### Assigning 'Review_Word_Count' Feature\n","73d7708c":"### Removing HTML Entities like &nbsp, &#60, a&#771('a' with a bar on top), etc.","4b209e52":"### Observations:\n* For reviews with index 83 and 84, it talks about how the dog food is great and liked by the dog, but it has a side effect of itching with it. Now this may be not be observed by all the users and here in this case we may conclude that the dog may be allergic with an ingredient that goes into the product. Type - **Case Specific**\n* For review with index 78, the customer talks about how the product doesnt taste great in hot weather. Type - **Situational**\n* For reviews with index 60 and 68, the main concern is about the price of the product which is kind of a secondary aspect about the product. Type - **Price Concern**\n* For reviews with index 45, 47, 106, there is something wrong with respect to the product which may be termed as a negative review. Type - **Negative Review**\n* For reviews with index 49, 53, Expectation of the user with respect to taste, health, quality were not met by the product which again may be termed as a negative review. Type - **Negative Review**\n\n> * Since we have a mix of Negative Reviews as well as Neutral Reviews, we can't assign them to 'Negative' Class. That leaves us with the option of discarding all the reviews having a Score of 3.\n","c725653e":"* Aggression can be observed by \u201cCaring\u201d input, It was converted to \u201ccar\u201d which is altogether a different word in English dictionary.","2cc55964":"## What is the distribution of Positive and Negative Reviews in each of the set of useful and non-useful reviews","04d3d0d5":"### Lets replace HelpfulnessNumerator and HelpfulnessDenominator Feature into one feature indicating the HelpfulnessPercentage","412f890c":"### Snowball Stemmer\n* There were some improvements done on Porter Stemmer which made it more precise over large data-sets.  \n* There is an impotant feature added to this algorithm which was excluding Stop Word Stemming.  ","07b9c0c5":"## Explore the files\n### 1. hashes.txt","801df44b":"### Observations:\n* If we just look at the reviews which are **non-useful**, we can see that the share of **negative** reviews are far more than the positive reviews. So, Users find the ***negative reviews to be less helpful*** in general.\n* If we just look at the reviews which are **useful**, we can see that the share of **positive** reviews are far more than the negative reviews. So, Users find the ***positive reviews to be more helpful*** in general.","9319fd18":"### Remove words with numbers ","435992f4":"### Peak the datapoints having 'Summary' Feature as Null","5f0e5afe":"## Stemming\n**Stemming is basically removing the suffix from a word and reduce it to its root word.**\n\nExample 1: \u201cFlying\u201d is a word and its suffix is \u201cing\u201d, if we remove \u201cing\u201d from \u201cFlying\u201d then we will get base word or root word which is \u201cFly\u201d.  \nExample 2: \"Tradition\" and \"Traditional\" have the same stem word - \"tradit\"\n\n[Ref](https:\/\/medium.com\/@tusharsri\/nlp-a-quick-guide-to-stemming-60f1ca5db49e#:~:text=Stemming%20is%20basically%20removing%20the%20suffix%20from%20a%20word,it%20to%20its%20root%20word.&text=We%20uses%20these%20suffix%20to,to%20all%20its%20inflected%20variants.)","0030f2df":"# EDA 1","2a953798":"### Observations:\n1. Cars was converted to root form(singular) : car\n2. Colors was converted to root form(singular) : color\n3. Best was converted to root form : good\n4. go, went, gone, going were not converted to their root form : go\n5. run, runs, ran, running came into same root word : run\n\n### Conclusion:\nShortcomings of wordnet lemmatizer were taken care by spacy.","49138c9d":"# Table of Content\n\n<center> <div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" style=\"background-color:purple; color:white\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content<\/h3><\/div><\/center>\n<left>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Understanding-Dataset\" role=\"tab\" aria-controls=\"profile\" style=\"color:purple\"><b>1. Understanding Dataset<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Context\" role=\"tab\" aria-controls=\"profile\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;1.1 Context<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Content\" role=\"tab\" aria-controls=\"profile\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;1.2 Content<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Explore-the-files\" role=\"tab\" aria-controls=\"profile\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;1.3 Explore the files<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Dataset-Claims\" role=\"tab\" aria-controls=\"messages\" style=\"color:purple\"><b>2. Dataset Claims<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Attribute-Information\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>3. Attribute Information<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Peak-at-5-Samples-of-the-Dataset\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>4. Peak at 5 Samples of the Dataset<\/b><\/a> \n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#EDA-1\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>5. EDA 1<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Datapoints-with-Missing\/Null-Features\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;5.1 Datapoints with Missing\/Null Features<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Peak-the-datapoints-having-'ProfileName'-Feature-as-Null\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.1.1 Peak the datapoints having 'ProfileName' Feature as Null<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Peak-the-datapoints-having-'Summary'-Feature-as-Null\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.1.2 Peak the datapoints having 'Summary' Feature as Null<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Distribution-of-Ratings(Scores)-across-the-entire-dataset\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;5.2 Distribution of Ratings(Scores) across the entire dataset<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Data-Cleaning\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>6. Data Cleaning<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Check-and-Delete-Duplicate-Reviews\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;6.1 Check and Delete Duplicate Reviews<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Update-dataframe-to-include-only-original(non-duplicated)-reviews-(Discarding-Duplicated-Reviews)\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.1.1 Update dataframe to include only original(non-duplicated) reviews (Discarding Duplicated Reviews)<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Check-and-Remove-3-Star(Neutral)-Reviews\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;6.2 Check and Remove 3 Star(Neutral) Reviews<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Count-and-Proportion-of-3-star-reviews\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2.1 Count and Proportion of 3 star reviews<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Peak-the-datapoints-having-a-'Score'-of-3\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2.2 Peak the datapoints having a 'Score' of 3<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Discard-all-reviews-having-a-Score-of-3\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2.3 Discard all reviews having a Score of 3<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Discarding-reviews-having-inconsistencies\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;6.3 Discarding reviews having inconsistencies<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Helpfulness-numerator-should-not-exceed-Helpfulness-denominator\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.3.1 Helpfulness numerator should not exceed Helpfulness denominator<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Feature-Engineering-1\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>7. Feature Engineering 1<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lets-replace-HelpfulnessNumerator-and-HelpfulnessDenominator-Feature-into-one-feature-indicating-the-HelpfulnessPercentage\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;7.1 Lets replace HelpfulnessNumerator and HelpfulnessDenominator Feature into one feature indicating the HelpfulnessPercentage<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lets-create-a-new-feature-off-of-'Helpfulness_Perc'-which-will-be-an-indicator-of-helpfulness-basis-the-helpfulness-percentage.-This-will-be-a-4-class-feature.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;7.2 Lets create a new feature off of 'Helpfulness_Perc' which will be an indicator of helpfulness basis the helpfulness percentage. This will be a 4-class feature.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Assigning-'Sentiment_Class'-Feature\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;7.4 Assigning 'Sentiment_Class' Feature<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Assigning-'Review_Word_Count'-Feature\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;7.5 Assigning 'Review_Word_Count' Feature<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#EDA-2-(After-Data-Cleaning,-FE1)\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>8. EDA 2 (After Data Cleaning, FE1)<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#What-is-the-distribution-of-useful-and-non-useful-reviews-in-each-of-the-set-of-Positive-and-Negative-Reviews.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.1 What is the distribution of useful and non-useful reviews in each of the set of Positive and Negative Reviews.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#What-is-the-distribution-of-Positive-and-Negative-Reviews-in-each-of-the-set-of-useful-and-non-useful-reviews\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.2 What is the distribution of Positive and Negative Reviews in each of the set of useful and non-useful reviews<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Review-Length-vs.-Review-Usefulness\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.3 Review Length vs. Review Usefulness<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Review-Length-vs.-Review-Sentiment\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.4 Review Length vs. Review Sentiment<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Wordcloud-for-Reviews.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.5 Wordcloud for Reviews.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Plotting-word-cloud-to-understand-the-top-words-that-have-occured-most-frequently-in-the-reviews.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.5.1 Plotting word cloud to understand the top words that have occured most frequently in the reviews.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Plotting-word-cloud-to-understand-the-top-words-that-have-occured-most-frequently-in-the-POSITIVE-reviews.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.5.2 Plotting word cloud to understand the top words that have occured most frequently in the POSITIVE reviews.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Plotting-word-cloud-to-understand-the-top-words-that-have-occured-most-frequently-in-the-NEGATIVE-reviews.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.5.3 Plotting word cloud to understand the top words that have occured most frequently in the NEGATIVE reviews.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#EDA-Observations-(Consolidated):\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.6 EDA Observations (Consolidated):<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#EDA-Conclusion:\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;8.7 EDA Conclusion:<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Data-Preprocessing\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>9. Data Preprocessing<\/b><\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Preprocessing\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.1 Text Preprocessing<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Remove-html-tags\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.1 Remove html tags<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Remove-URLs-(starting-with-'http'-as-well-as 'www')\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.2 Remove URLs (starting with 'http' as well as 'www')<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Removing-HTML-Entities-like-&nbsp,-&#60,-a&#771('a'-with-a-bar-on-top),-etc.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.3 Removing HTML Entities like &nbsp, &#60, a&#771('a' with a bar on top), etc.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Remove-words-with-numbers\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.4 Remove words with numbers<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Remove-words-with-3-or-more-repeated-characters-(words-like-'happpyyy')\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.5 Remove words with 3 or more repeated characters (words like 'happpyyy')<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Expand-the-common-english-contradictions\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.6 Expand the common english contradictions<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Remove-Special-Characters-and-Punctuations\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.1.7 Remove Special Characters and Punctuations<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Stemming\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.2 Stemming<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Porter-Stemmer\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.2.1 Porter Stemmer<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Snowball-Stemmer\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.2.2 Snowball Stemmer<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lancaster-Stemmmer\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.2.3 Lancaster Stemmmer<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Stemming-Conclusion\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.2.4 Stemming Conclusion<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lemmatization\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.3 Lemmatization<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lemmatization-using-NLTK's-Wordnet-Lemmatizer\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.3.1 Lemmatization using NLTK's Wordnet Lemmatizer<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Lemmatization-using-Spacy\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.3.2 Lemmatization using Spacy<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Check-if-stemming-followed-by-lemmatization-yields-better-results-for-some-test-words-compared-to-just-stemming\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.4 Check if stemming followed by lemmatization yields better results for some test words compared to just stemming<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#just-stemming\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.4.1 just stemming<\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#just-lemmatization\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.4.2 just lemmatization<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#stemming-followed-by-lemmatization\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.4.3 stemming followed by lemmatization<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Applying-all-the-Text-Preprocessing-steps-on-the-review-data-without-stemming.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.5 Applying all the Text Preprocessing steps on the review data without stemming.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Applying-all-the-Text-Preprocessing-steps-on-the-review-data-with-stemming.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.6 Applying all the Text Preprocessing steps on the review data with stemming.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Applying-all-the-Text-Preprocessing-steps-on-the-review-data-with-only-lemmatization.\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\">&nbsp;&nbsp;&nbsp;9.7 Applying all the Text Preprocessing steps on the review data with only lemmatization.<\/a>\n<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Serialize-the-dataframe-to-a-file\" role=\"tab\" aria-controls=\"settings\" style=\"color:purple\"><b>10. Serialize the dataframe to a file<\/b><\/a><\/left>","51bf108a":"# Data Preprocessing","e1fab00f":"## Context\nThis dataset consists of reviews of fine foods from amazon. The **data span** a period of more than **10 years**, including all **~500,000 reviews** up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n## Contents\nReviews.csv: Pulled from the corresponding SQLite table named Reviews in database.sqlite  \ndatabase.sqlite: Contains the table 'Reviews'\n","a6fddf0a":"## Applying all the Text Preprocessing steps on the review data without stemming.","2a7c8feb":"## Lemmatization\n\n[Ref](https:\/\/medium.com\/@tusharsri\/lemmatization-af85aa3e5a86)\n\n**Inflection** is a process of word formation, in which a word is modified to express different grammatical categories such as tense, case, voice, aspect, person, number, gender, mood, animacy, and definiteness.  \n\n* Lemmatisation in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word\u2019s lemma, or dictionary form.  \n* for example, run, runs, ran and running are forms of the same set of words that are related through inflection, with run as the lemma.  \n\nWhat is the different between Stemming and Lemmatization?  \n* Unlike Stemming, Lemmatisation depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.  \n\nWhy should we need Lemmatization when we have Stemming?  \n1. The purpose of both stemming and lemmatization is to reduce morphological variation or to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.  \n2. A Stemmer will return the stem of a word, which needn't be identical to the morphological root of the word. It usually sufficient that related words map to the same stem,even if the stem is not in itself a valid root, while in lemmatisation, it will return the dictionary form of a word, which must be a valid word.  \n3. In lemmatisation, the part of speech of a word should be first determined and the normalisation rules will be different for different part of speech, while the stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech.  \n","5667a815":"### Lemmatization using NLTK's Wordnet Lemmatizer","2a15ac08":"### Count and Proportion of 3 star reviews","daf1bb18":"### Remove words with 3 or more repeated characters (words like 'happpyyy')","122f3d3b":"### stemming followed by lemmatization","a7901c51":"## Peak at 5 Samples of the Dataset","5994f476":"### just stemming","43492143":"## Applying all the Text Preprocessing steps on the review data with only lemmatization.","bfa71c2b":"#### sqlite table to pandas dataframe","3bdc9e7a":"#### Columns and its data types","00cc7924":"### Plotting word cloud to understand the top words that have occured most frequently in the POSITIVE reviews.","2f615e9c":"### Lets create a new feature off of 'Helpfulness_Perc' which will be an indicator of helpfulness basis the helpfulness percentage. This will be a 4-class feature.  ","757ba020":"# Feature Engineering 1","79d2cfb9":"## Attribute Information\n\n1. **Id** - Row Id\n2. **ProductId** - Unique identifier for the product\n3. **UserId** - Unqiue identifier for the user\n4. **ProfileName** - Profile name of the user\n5. **HelpfulnessNumerator** - Number of users who found the review helpful\n6. **HelpfulnessDenominator** - Number of users who indicated whether they found the review helpful or not\n7. **Score** - Rating between 1 and 5\n8. **Time** - Timestamp for the review\n9. **Summary** - Brief summary of the review\n10. **Text** - Text of the review  \n\n<img src=\"https:\/\/nycdsa-blog-files.s3.us-east-2.amazonaws.com\/2016\/04\/AmazonReview-300x189.png\" width=\"600\" height=\"400\">","f72831ad":"### just lemmatization","316930d7":"## Review Length vs. Review Usefulness","261bbd7c":"### Update dataframe to include only original(non-duplicated) reviews (Discarding Duplicated Reviews)","94683d73":"* Look at the input and you can see we are passing \u201cwas\u201d and getting \u201cwa\u201d as output. This is something which should be considered under less precise algorithm. To increase the precision another algorithm came which was SnowBall Stemmer.","c9503d20":"## Distribution of Ratings(Scores) across the entire dataset","bf35e0ed":"### Observation:\n* Since many outliers are there i.e. reviews with too many words are present, so in order to capture better co-relation between review length and ratings, we can consider reviews with 500 words or less.\n* The max length of a Positive review is much higher(\\~2500)  as compared to Negative Review(\\~1600)","cc9d68e6":"#### Few sample rows","45880919":"## Applying all the Text Preprocessing steps on the review data with stemming.","51f6e03e":"### Observation:\n* Negative reviews are generally lengthier than Positive reviews in terms of mean, 25th percentile, median(50th percentile), 75th percentile, etc. (**Positive Reviews are shorter**)\n* The standard deviation is higher in case of Positive Reviews.","10367966":"### 3. database.sqlite","0011c8d5":"### Observations:\n* There are two datapoints matching this criteria, discarding them.","f3824c3b":"### Observations:\n* We can see the presence of words with negative sentiments such as:  \n    * Unfortunately\n    * stale\n    * horrible\n    * disappointed\n    * terrible\n    * bad","d5da46b3":"# EDA 2 (After Data Cleaning, FE1)","dfe2a1ca":"### Expand the common english contradictions","5e0dee5a":"### Observations:\n1. Cars was converted to root form(singular) : car\n2. Colors was converted to root form(singular) : color\n3. **Best was not converted to root form : good**\n4. **go, went, gone, going were not converted to their root form : go**\n5. run and runs came into same root word but **ran and running didnt**\n\n### Conclusion:  \nWordNet was only able to remove the suffix in cases applicable","3d4cc887":"### Observations:\n* **Positive reviews are more common than negative reviews.**","06c65654":"## Discarding reviews having inconsistencies","0d71cfd3":"## Wordcloud for Reviews.\n### Plotting word cloud to understand the top words that have occured most frequently in the reviews.","917c0f8f":"#### Read csv into a dataframe","8982549f":"> **Recall we have the task of buiding a model which will tag an unseen review as positive or negative. If the scores were between 1 and 10(inclusive), we could have assigned the class label as 'Negative' for reviews with scores [1,2,3,4,5] and 'Positive' for reviews with scores [6,7,8,9,10]. But here since we have scores between 1 and 5(inclusive), we don't have an option to divide the scores in two equal classes. If we were to do that either all the reviews with score of 3 had to be discarded(then reviews with scores [1,2] would fall in 'Negative' class and [4,5] would fall in 'Positive' class) or we could take a decision to either include score '3' reviews in either 'Negative' or 'Positive' Class. Or we could make this a Multiclass Classification Problem (Negative, Neutral and Positive) instead of the current Binary Classification Problem (not expected).**","16aa1081":"### Observations:\n* Ignoring 'Not Available' and 'Intermediate'(Since we want to be sure of the fact that it is useful\/non-useful) Datapoints, if we look at the count of 'Useful' and 'Not Useful' we can see that **94.3%** of reviews are Useful and **5.7%** are Not Useful","dd112f2a":"### Discard all reviews having a Score of 3","3769beca":"#### SQL row in tuple form","0039dbc6":"### Observations:\n* sqlite database and csv has equal no. of data.  \n* using either one of them is fine.  \n* In dataset description also, its mentioned that csv was created using the sqlite database.","3f3b28d0":"### Observation:\n* Nothing extraordinary here! ProfileName is missing, but Corresponding 'UserId' is present which is sufficient to uniquely identify a user who has written the review.","dc456111":"# Understanding Dataset","113ac1a4":"### Lancaster Stemmmer\n* It is very aggressive algorithm.  \n* It will hugely trim down your working set, this statement itself has pros and cons, sometime you many want this in your datasets but maximum time you will be avoiding it.","8e12141f":"### Remove Special Characters and Punctuations","39d4abf9":"### Observation:\n* Useful reviews are generally lengthier than non-useful reviews in terms of mean, median(50%), max, etc. (**Helpful reviews are longer**)\n* Helpful reviews have a higher median word count(63 words) as compared to non-helpful's (56 words)\n* There is a high concentration of reviews which are having a word count in the neighbourhood of 30.\n* Distribution of both useful and non-useful reviews are more or less the same; follows the log-normal distribution which is inline with most human behaviours.","1e9f36b8":"### Remove html tags","82beef1b":"### Peak the datapoints having 'ProfileName' Feature as Null","58e16d89":"### Lemmatization using Spacy","1922d4e7":"## Review Length vs. Review Sentiment","41b447eb":"<center> <h1 style=\"background-color:purple; color:white\">Amazon Fine Food Reviews - EDA,<br> Data Cleaning, Data Preprocessing, Feature Engineering<\/h1>","5eef4e16":"## Serialize the dataframe to a file","61e687e5":"## Dataset Claims\n\n568,454 reviews  \n256,059 users  \n74,258 products  \n260 users with > 50 reviews  \nReviews from Oct 1999 - Oct 2012  \n ","d162f1a2":"### 2. Reviews.csv","487dbf7a":"### Observations:\n* There is a high frequency(big size among the word counts) of occurance of the word \"br\" in the reviews. Since it occurs in the html tags indicating breaks : ```<br> <\/br>```, we can presume the presence of other html tags as well. So in the text preprocessing step, we need to remove all the html related text\/tags.","f604b139":"### Check if stemming followed by lemmatization yields better results for some test words compared to just stemming","ac9d057a":"### Helpfulness numerator should not exceed Helpfulness denominator","1a62aa6e":"## Datapoints with Missing\/Null Features","2c2a72a1":"### Observation:\n* We have about 1.75 lakh reviews(~30% of total reviews) which are duplicated across product variants. Basically reviews by the same user at the same time with same review text.","daa9132e":"## What is the distribution of useful and non-useful reviews in each of the set of Positive and Negative Reviews.","28ce659e":"Due to this feature we observed difference in \u201cwas\u201d input.  ","45f83848":"# Data Cleaning\n## Check and Delete Duplicate Reviews"}}