{"cell_type":{"b092fdd8":"code","a59880ed":"code","711f4a27":"code","aa6f2302":"code","2b07a6bd":"code","5d2290f7":"code","357917ae":"code","84d3f4a5":"code","089dc033":"code","ac7ce826":"code","11bbf14c":"markdown","c9c05f13":"markdown","a5ce8604":"markdown","24766a66":"markdown","3175f627":"markdown"},"source":{"b092fdd8":"import pandas as pd\nimport os","a59880ed":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","711f4a27":"CD = '..\/input\/paralel-translation-corpus-in-22-languages\/' #initially there were 22 languages, two more added afterwards :)","aa6f2302":"SL = 'EN' #this is a constant and should not be changed, i.e. Source Language is always English","2b07a6bd":"TL = 'DE' #depending on the desired Target Language, this could be set, available abbr. choices are written in the introduction paragraph","5d2290f7":"pd.read_csv(CD+SL+'-'+TL+'\/'+SL+'-'+TL+'.txt', sep='\\t', header = None)[[0,1]].rename(columns = {0:SL, 1:TL})","357917ae":"import pandas as pd\nfrom xml.dom import minidom","84d3f4a5":"def process_tuv(tuv):\n    lang = tuv.getAttribute(\"lang\")\n    if lang == '':\n        lang = tuv.getAttribute(\"xml:lang\")\n    seg = tuv.getElementsByTagName('seg')[0]\n    txt = seg.childNodes[0].data\n    return lang, txt\n\ndef read_tmx_files(path):\n\n    \"\"\"Read function takes in a path to TMX translation file and outputs the metadata and a pandas dataframe.\n\n    Args:\n        param1 (str): The path to the TMX translation file\n\n    Returns:\n        dict: The header of the TMX file, which contains metadata\n        DataFrame: A Pandas Dataframe. Each line item consists of source_language, source_sentence, target_language, target_sentence\n\n    \"\"\"\n    # parse an xml file by name\n    tmx = minidom.parse(path)\n\n    # Get metadata\n    metadata = {}\n    header = tmx.getElementsByTagName('header')[0]\n    for key in header.attributes.keys():\n        metadata[key] = header.attributes[key].value\n        \n    srclang = metadata['srclang']\n\n    # Get translation sentences\n    body = tmx.getElementsByTagName('body')[0]\n    translation_units = body.getElementsByTagName('tu')\n    items = []\n    count_unpaired = 0\n    for tu in translation_units:\n        if len(tu.getElementsByTagName('tuv')) < 2:\n            print(\"Unpaired translation. Ignoring...\")\n            count_unpaired = count_unpaired + 1\n        else:\n            srclang, srcsentence = process_tuv(tu.getElementsByTagName('tuv')[0])\n            targetlang, targetsentence = process_tuv(tu.getElementsByTagName('tuv')[1])\n            item = {\n                'source_language': srclang,\n                'source_sentence': srcsentence,\n                'target_language': targetlang,\n                'target_sentence': targetsentence\n            }\n            items.append(item)\n\n    df = pd.DataFrame(items)\n    if count_unpaired > 0:\n       print(\"The data contained %d unpaired translations which were ignored\" % (count_unpaired))\n    return metadata, df","089dc033":"metadata, df = read_tmx_files('..\/input\/paralel-translation-corpus-in-22-languages\/Sample TMX file (EN-GA)\/EN-GA.tmx')","ac7ce826":"df.head()","11bbf14c":"[](http:\/\/)The translation memory was preprocessed  to reduce the number of entries of low value for the translators (short sentences, long sentences, obvious mismatches, etc.). There are approximately more than 5.5M senteces in each \"Source (English) to target langage\" parallel corpus in each txt file (tab-delimated) provided for the associated target language.\n\nThere are total number of 24 languages available: English(Source), Bulgarian (BR), Croatian (CR), Czech (CS), Danish (DA), Dutch (NL), Estonian (ET), German (DE), Greek (EL), Finnish (FI), French (FR), Irish (GA), Hungarian (HU), Italian (IT), Latvian (LV), Lithuanian (LT), Maltese (MT), Polish (PL), Portuguese (PT), Romanian (RO), Slovak (SK), Slovene (SL), Spanish (ES) and Swedish (SV).\n\nTo read a single txt file the following single line of code will suffice:","c9c05f13":"## Reading TMX Extension Directly","a5ce8604":"# Reading the Translation Memory Data","24766a66":"I hope this notebook helps answering potential questions regarding reading the parallel translation text corpus, if you have further questions please do not hesitate to ask!","3175f627":"In most cases, the professionally translated corpus is stored in the TMX (Translation Memory Exchange) file format, an open XML standard used for exchanging translation memory. I have tried to read from this format directly in Python, I found several libraries and the most promising one seemed to be [tmx2dataframe](https:\/\/pypi.org\/project\/tmx2dataframe\/). However, for some reason, this library did not work in any environment I tried and I decided to utilize its source code corresponding to this reading of the TMX file and it worked, here is how it did:"}}