{"cell_type":{"4b2322db":"code","5d47eb9d":"code","9add0cd5":"code","b04be809":"code","8facee7a":"code","4ca9b99b":"code","23fc0fe1":"code","f3ac2baf":"code","257ab980":"code","7cf52e76":"code","f7c790f1":"code","35d214b0":"code","5e013257":"code","627fe0df":"code","f598e612":"code","397f4792":"code","213ff20e":"code","b28af65f":"code","636538ef":"code","fcc1d4f9":"code","dff1a718":"code","e1c096db":"code","4cf3e9b3":"code","a942ba5b":"code","b5827e5b":"code","6b8a8dd8":"code","6f83dcca":"code","e626d76c":"code","47b6c1ac":"code","e30c9776":"code","68d2e480":"code","55bc8432":"code","4206e548":"code","af4945e8":"code","b2b4078e":"code","cdb47301":"code","c992aa27":"code","9a954cc8":"code","aa5eca82":"code","dfd9fc23":"code","20ec5275":"code","5e2a88ec":"code","a84e862e":"code","3fa91d73":"code","66e3a880":"code","a61d8fbd":"code","660d0d16":"code","9ab76093":"code","60960634":"code","f5744693":"code","dbfc8da9":"code","be8a2bcc":"code","0e5a33ce":"code","0c95c39e":"code","fede3e44":"code","2b83b9b4":"code","4c53027a":"code","977eca4c":"code","126d37d1":"code","4d05393d":"code","be2c9629":"code","17a4bb56":"code","a83b4a13":"code","b9c90d43":"code","2ab6c448":"code","a10a547a":"code","1c49ce82":"code","92de2f2b":"code","01c9e98d":"code","6b8e0fea":"code","81d83b45":"code","226df704":"code","190aa3b6":"code","3f38d838":"code","471b78d9":"code","20df4e14":"code","83958d0a":"code","f698b5da":"code","c74de321":"code","181a66f7":"code","7b5fc60e":"code","4389fa01":"code","d435f976":"code","10af0330":"code","3b71babd":"code","d2332436":"code","fe4fdf53":"code","4e6e8a18":"code","a6e2a571":"code","70fac4e0":"code","bde24cae":"code","f3af90c8":"code","4ed778ab":"code","24adb8cc":"code","75139e84":"code","03cf4361":"code","77626fc3":"code","bc3bf064":"code","afdba9f4":"code","162f259f":"code","1d9d76e9":"code","d1b0fda9":"code","6b8f8f88":"code","31ad94dc":"code","cba1935f":"code","c444d532":"code","884ce94d":"code","975e4f66":"code","c8feb7ea":"code","b72ddc19":"code","c1bfba43":"code","549b79a0":"code","499078f5":"code","65561063":"code","ea83adff":"code","e6e1a9a2":"markdown","3ca34f47":"markdown","e972ee6e":"markdown","4365a3fe":"markdown","5a351810":"markdown","89d56e54":"markdown","f0b050f7":"markdown","ca300c78":"markdown","6a986be0":"markdown","77d64c4a":"markdown","cc6480e2":"markdown","f161609a":"markdown","79859789":"markdown","7902f5bd":"markdown","7e55db7b":"markdown","371f45fd":"markdown","b062e299":"markdown","17423237":"markdown","55ab628f":"markdown","1674481d":"markdown","93203c33":"markdown"},"source":{"4b2322db":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","5d47eb9d":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","9add0cd5":"train.head()","b04be809":"train.shape","8facee7a":"test.head()","4ca9b99b":"test.shape","23fc0fe1":"dfcombine = pd.concat([train, test],ignore_index=True,sort=True)\ndfcombine.head()","f3ac2baf":"dfcombine.info()","257ab980":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"http:\/\/visualoop.com\/media\/2015\/04\/TITANIC.jpg\")","7cf52e76":"#analyze the unique value of Cabin\ndfcombine['Cabin'].unique()","f7c790f1":"#get 186 non null Cabin features \ndfcombine['Cabin'].value_counts()","35d214b0":"#find Cabin which contain space. \ndfcombine[['Cabin','Pclass','Fare','SibSp','Parch']][dfcombine['Cabin'].str.find(' ')>0]","5e013257":"#insert new column (CabinLetter and CabinNumber)\ndfcombine['CabinLetter'] = pd.Series([], dtype='str')\ndfcombine['CabinNumber'] = pd.Series([], dtype='float')","627fe0df":"for idx,cabin in dfcombine['Cabin'].iteritems():\n    if type(cabin)==float:\n        dfcombine.loc[idx,'CabinLetter'] = np.nan\n        dfcombine.loc[idx,'CabinNumber'] = np.nan\n    else:\n        if len(cabin.rsplit(' ',1))>1:\n            tempText = cabin.rsplit(' ',1)[1]\n            tempLetter = tempText[0:1]\n            tempNumber = tempText[1:]\n        else:\n            tempLetter = cabin[0:1]\n            tempNumber = cabin[1:]\n        dfcombine.loc[idx,'CabinLetter'] = tempLetter\n        if len(tempNumber):\n            dfcombine.loc[idx,'CabinNumber'] = float(tempNumber)\n        else:\n            dfcombine.loc[idx,'CabinNumber'] = 0","f598e612":"dfcombine.head()","397f4792":"dfcombine['CabinLetter'].dropna().unique()","213ff20e":"TempCabinClass = dfcombine[['Pclass','CabinLetter']].dropna().drop_duplicates(['Pclass','CabinLetter']).copy()","b28af65f":"TempCabinClass","636538ef":"import networkx as nx","fcc1d4f9":"G=nx.DiGraph()","dff1a718":"#add node\nfor index, row in TempCabinClass[['Pclass','CabinLetter']].iterrows():\n    G.add_node(row['Pclass'])\n    G.add_node(row['CabinLetter'])\n    \n#add edge\nfor index, row in TempCabinClass[['Pclass','CabinLetter']].iterrows():\n    G.add_edge(row['Pclass'],row['CabinLetter'])","e1c096db":"Row_list1 = []\nfor index,rows in TempCabinClass[['Pclass']].drop_duplicates(['Pclass']).iterrows():\n    my_list = rows['Pclass']\n    Row_list1.append(my_list)","4cf3e9b3":"Row_list2 = []\nfor index,rows in TempCabinClass[['CabinLetter']].dropna().drop_duplicates(['CabinLetter']).iterrows():\n    my_list = rows['CabinLetter']\n    Row_list2.append(my_list)","a942ba5b":"edge_list = []\nfor index,rows in TempCabinClass[['CabinLetter','Pclass']].drop_duplicates(['CabinLetter','Pclass']).iterrows():\n    my_list = [rows['Pclass'],rows['CabinLetter']]\n    edge_list.append(my_list)","b5827e5b":"dic = {\n    \"A\":\"Deck A\",\n    \"B\":\"Deck B\",\n    \"C\":\"Deck C\",\n    \"D\":\"Deck D\",\n    \"E\":\"Deck E\",\n    \"F\":\"Deck F\",\n    \"G\":\"Deck G\",\n    \"T\":\"Deck A\", #T is only one row and only in first class, convert to Deck A\n    1:\"First Class\",\n    2:\"Second Class\",\n    3:\"Third Class\"\n}","6b8a8dd8":"pos=nx.bipartite_layout(G,Row_list1)\nnx.draw_networkx_nodes(G,pos,\n                       node_color='yellow',\n                       nodelist=Row_list1,\n                       node_size=500,\n                       alpha=0.8)\nnx.draw_networkx_nodes(G,pos,\n                       node_color='lightblue',\n                       nodelist=Row_list2,\n                       alpha=0.8)\nnx.draw_networkx_labels(G,pos,labels=dic,font_size=14)\nnx.draw_networkx_edges(G,pos,\n                       edgelist=edge_list,\n                       width=2,alpha=0.5,edge_color='r')\nplt.show()","6f83dcca":"dfcombine.head(100)","e626d76c":"dfcombine['Cabin'].str[:1].value_counts()","47b6c1ac":"dfcombine['Pclass'] = dfcombine['Pclass'].astype(float)","e30c9776":"dfcombine.groupby(['Pclass','CabinLetter'])['CabinNumber'].count()","68d2e480":"dic_embarked = {\n    \"S\":101,\n    \"C\":102,\n    \"Q\":103\n}","55bc8432":"dfcombine['Embarked_num'] = dfcombine['Embarked'].map(dic_embarked)","4206e548":"#mapping cabin letter with numeric value\ndic_cabinbetter = {\n    \"A\":10,\n    \"B\":20,\n    \"C\":30,\n    \"D\":40,\n    \"E\":50,\n    \"F\":60,\n    \"G\":70,\n    \"T\":10 #T to A deck, maybe outliar\n}\n\n#create new column for cabin letter numeric value\ndfcombine['CabinLetter_num'] = dfcombine['CabinLetter'].map(dic_cabinbetter)","af4945e8":"dfcombine[['Embarked_num','Pclass','CabinLetter_num']].groupby(['Embarked_num','Pclass'])['CabinLetter_num'].value_counts()","b2b4078e":"dfcombine[['Pclass', 'Survived']][dfcombine['Survived'].notnull()].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","cdb47301":"dfcombine[['CabinLetter_num', 'Survived']][dfcombine['Survived'].notnull()].groupby('CabinLetter_num').agg({'Survived':['count','mean']}).sort_values([('Survived','mean')], ascending=False) #name=('Survived','mean'))","c992aa27":"dic_cabinbetter_rev = {\n    10:\"A\",\n    20:\"B\",\n    30:\"C\",\n    40:\"D\",\n    50:\"E\",\n    60:\"F\",\n    70:\"G\",\n    80:\"A\"\n}\nprob_cabin = dfcombine[['CabinLetter_num', 'Survived']][dfcombine['Survived'].notnull()].groupby('CabinLetter_num',as_index=False).agg('mean') #.sort_values('mean', ascending=False)\nprob_cabin['CabinLetter_num'] = prob_cabin['CabinLetter_num'].map(dic_cabinbetter_rev)\nprint(prob_cabin)","9a954cc8":"prob_cabin_withnan = dfcombine[['CabinLetter', 'Survived']].groupby('CabinLetter',as_index=False).agg('mean') #.sort_values('mean', ascending=False)","aa5eca82":"plt.plot(prob_cabin['CabinLetter_num'],prob_cabin['Survived'],label='Cabin w\/o Null Values')\nplt.plot(prob_cabin_withnan['CabinLetter'],prob_cabin_withnan['Survived'],label='Cabin with Null Values')\nplt.title(\"Cabin Survival Probability null vs not null\")\nplt.legend()\nplt.show()","dfd9fc23":"prob_pclass = dfcombine[['Pclass', 'Survived']][dfcombine['Survived'].notnull()].groupby('Pclass',as_index=False).agg('mean')\nprob_pclass","20ec5275":"y = prob_pclass['Survived']\nx1 = prob_pclass['Pclass']","5e2a88ec":"import statsmodels.api as sm","a84e862e":"prob_pclass.describe()","3fa91d73":"y = prob_pclass['Survived']\nx1 = prob_pclass['Pclass']","66e3a880":"plt.scatter(x1,y)\nplt.xlabel('Class',fontsize=20)\nplt.ylabel('Probability of Survive',fontsize=20)\nplt.show()","a61d8fbd":"x = sm.add_constant(x1)\nresults = sm.OLS(y,x).fit()\nresults.summary()","660d0d16":"plt.scatter(x1,y)\nyhat = -0.1936*x1+0.8355\nfig = plt.plot(x1,yhat,lw=3,c='orange',label='Regression Line')\nplt.xlabel('Class',fontsize=20)\nplt.ylabel('Probability of Survive',fontsize=20)\nplt.show()","9ab76093":"dfcombine['Survived']","60960634":"dfcombine.info()","f5744693":"class_order = dfcombine[['PassengerId','Pclass','Sex','Survived']].sort_values(by=['Pclass','Sex'],ascending=['True','False'])\nclass_order.head(10)\n\n","dbfc8da9":"class_order['Pclass'].value_counts()","be8a2bcc":"dfcombine.head(50)","0e5a33ce":"import random","0c95c39e":"# First Class has 323 Passenger separated with 5 deck (A to E). So we distribute the probability every passager from A to E. Which A is most likely to survive\n\nfor pclass_num,passanger_perclass in class_order['Pclass'].value_counts().items():\n    randNumber = random.sample(range(passanger_perclass), passanger_perclass)\n    original_loop = 0\n    for idx,data in class_order[['Pclass','Sex','Survived']][class_order['Pclass']==pclass_num].iterrows():\n        Pclass_relative = pclass_num+randNumber[original_loop]\/passanger_perclass\n        original_loop = original_loop + 1\n        #print(class_order.loc[idx,'Survived'])\n        class_order.loc[idx,'Pclass_rel'] =  Pclass_relative\n        class_order.loc[idx,'Cabin_score'] = float(round(-0.1936*Pclass_relative+0.8355,4))\n        #print(cabin_score)","fede3e44":"class_order['Cabin_score'] = class_order['Cabin_score'].astype(float)","2b83b9b4":"class_order['Pclass_rel']","4c53027a":"class_order.head()","977eca4c":"class_order.describe()","126d37d1":"class_order[class_order['Pclass']==3].describe()","4d05393d":"cabin_range  = 0.6419\/7\ncabin_range_initial = 0\nfor i in range(7):\n    print(round(cabin_range_initial,4))\n    cabin_range_initial = round((cabin_range_initial)+cabin_range,4)","be2c9629":"class_order['Cabin_score_convert'] = np.nan","17a4bb56":"class_order","a83b4a13":"#binning\nfor i_class in [1.0,2.0,3.0]:\n    for idx in class_order[class_order['Pclass']==i_class].index:\n        if class_order.loc[idx,'Cabin_score'] >= 0.5502:\n            class_order.loc[idx,'Cabin_score_convert'] = 10\n        elif class_order.loc[idx,'Cabin_score'] >= 0.4585 and class_order.loc[idx,'Cabin_score']<0.5502:\n            class_order.loc[idx,'Cabin_score_convert'] = 20\n        elif class_order.loc[idx,'Cabin_score'] >= 0.3668 and class_order.loc[idx,'Cabin_score']<0.4585:\n            class_order.loc[idx,'Cabin_score_convert'] = 30\n        elif class_order.loc[idx,'Cabin_score'] >= 0.2751 and class_order.loc[idx,'Cabin_score']<0.3668:\n            class_order.loc[idx,'Cabin_score_convert'] = 40\n        elif class_order.loc[idx,'Cabin_score'] >= 0.1834 and class_order.loc[idx,'Cabin_score']<0.2751:\n            class_order.loc[idx,'Cabin_score_convert'] = 50\n        elif class_order.loc[idx,'Cabin_score'] >= 0.0917 and class_order.loc[idx,'Cabin_score']<0.1834:\n            class_order.loc[idx,'Cabin_score_convert'] = 60\n        elif class_order.loc[idx,'Cabin_score'] >= 0 and class_order.loc[idx,'Cabin_score'] < 0.0917:\n            class_order.loc[idx,'Cabin_score_convert'] = 70\n            \n        #class_order.loc[ class_order['Cabin_score'] >= 0.5502, 'Cabin_score_convert'] = 10,\n        #class_order.loc[(class_order['Cabin_score'] >= 0.4585) & (class_order['Cabin_score'] < 0.5502), 'Cabin_score_convert'] = 20,\n        #class_order.loc[(class_order['Cabin_score'] >= 0.3668) & (class_order['Cabin_score'] < 0.4585), 'Cabin_score_convert'] = 30,\n        #class_order.loc[(class_order['Cabin_score'] >= 0.2751) & (class_order['Cabin_score'] < 0.3668), 'Cabin_score_convert'] = 40,\n        #class_order.loc[(class_order['Cabin_score'] >= 0.1834) & (class_order['Cabin_score'] < 0.2751), 'Cabin_score_convert'] = 50,\n        #class_order.loc[(class_order['Cabin_score'] >= 0.0917) & (class_order['Cabin_score'] < 0.1834), 'Cabin_score_convert'] = 60,\n        #class_order.loc[(class_order['Cabin_score'] >= 0) & (class_order['Cabin_score'] < 0.0917), 'Cabin_score_convert'] = 70","b9c90d43":"class_order.head()","2ab6c448":"sns.catplot(x='CabinLetter_num',col='Survived',data=dfcombine,kind='count')","a10a547a":"sns.catplot(x='Cabin_score_convert',col='Survived',data=class_order,kind='count')","1c49ce82":"dfcombine=pd.merge(dfcombine,class_order[['PassengerId','Cabin_score_convert']],on='PassengerId',how='inner')","92de2f2b":"dfcombine.head()","01c9e98d":"dfcombine[['CabinLetter_num','Cabin_score_convert']][dfcombine['CabinLetter_num'].notnull()].count()","6b8e0fea":"dfcombine[['CabinLetter_num','Cabin_score_convert']][dfcombine['CabinLetter_num']==dfcombine['Cabin_score_convert']].count()","81d83b45":"for idx in dfcombine['CabinLetter_num'][dfcombine['CabinLetter_num'].isnull()].index:\n    dfcombine.loc[idx,'CabinLetter_num']=dfcombine['Cabin_score_convert'][idx]\n    ","226df704":"dfcombine['Embarked'].isnull().sum()","190aa3b6":"dfcombine[['Embarked_num']].groupby(['Embarked_num'])['Embarked_num'].count()","3f38d838":"dfcombine[['Embarked']].groupby(['Embarked'])['Embarked'].count()","471b78d9":"for idx in dfcombine['Embarked'][dfcombine['Embarked'].isnull()].index:\n    dfcombine.loc[idx,'Embarked'] = 'S'\n    dfcombine.loc[idx,'Embarked_num'] = 101.0","20df4e14":"dfcombine[['Embarked']].groupby(['Embarked'])['Embarked'].count()","83958d0a":"dfcombine[['Embarked_num']].groupby(['Embarked_num'])['Embarked_num'].count()","f698b5da":"dfcombine.isnull().sum()","c74de321":"dfcombine['Fare'].isnull().sum()","181a66f7":"dfcombine[['Pclass','Fare']].groupby(['Pclass','Fare'])['Pclass'].count()","7b5fc60e":"dfcombine[['Pclass','Fare']].groupby(['Pclass'])['Fare'].count()","4389fa01":"dfcombine.info()","d435f976":"dfcombine['Fare'].isnull().sum()","10af0330":"idx = dfcombine[dfcombine['Fare'].isnull()].index[0]\ndfcombine.loc[idx,'Fare'] = dfcombine['Fare'][dfcombine['Pclass']==dfcombine['Pclass'][idx]].median(skipna=True)","3b71babd":"dfcombine['Fare'].isnull().sum()","d2332436":"dfcombine.info()","fe4fdf53":"dfcombine['NumberOfFamily'] = dfcombine['SibSp'] = dfcombine['Parch'] + 1","4e6e8a18":"dfcombine.info()","a6e2a571":"dfcombine[\"Age\"].isnull().sum()","70fac4e0":"dfcombine[\"Title\"]=\"\"\nfor index,row in dfcombine.iterrows():\n    idx1 = row['Name'].find('. ')\n    tempText = row['Name'][:idx1].split(' ')\n    tempText = tempText[len(tempText)-1]\n    dfcombine.loc[index,'Title']=tempText","bde24cae":"print(dfcombine[['Name','Title']])","f3af90c8":"dfcombine['Title'].unique()","4ed778ab":"dfcombine['Title'].value_counts()","24adb8cc":"arrAgeNull = dfcombine['Age'][dfcombine['Age'].isnull()].index","75139e84":"dfcombine\ntitlemapping = {\n    'Mr':101,\n    'Mrs':102,\n    'Miss':103,\n    'Master':104,\n    'Rev':105,\n    'Dr':105,\n    'Col':105,\n    'Major':105,\n    'Ms':105,\n    'Mlle':105,\n    'Lady':105,\n    'Mme':105,\n    'Dona':105,\n    'Countess':105,\n    'Sir':105,\n    'Jonkheer':105,\n    'Capt':105,\n    'Don':105\n}\ndfcombine['Title_num'] = dfcombine['Title'].map(titlemapping)","03cf4361":"for nx in arrAgeNull:\n    dfcombine.loc[nx,'Age'] = int(dfcombine['Age'][dfcombine['Title']==dfcombine['Title'][nx]].median(skipna=True))","77626fc3":"dfcombine[\"Age\"].isnull().sum()","bc3bf064":"dfcombine.info()","afdba9f4":"dfcombine['Sex'].unique()","162f259f":"dfcombine['Sex_num'] = dfcombine['Sex'].map({'male':0.0,'female':1.0})","1d9d76e9":"dfcombine.info()","d1b0fda9":"newdfcombine = dfcombine[dfcombine['Survived'].notnull()].drop(columns=['Cabin','Embarked','Name','Sex','Ticket','CabinLetter','Title','PassengerId']).copy()","6b8f8f88":"newdfcombine.info()","31ad94dc":"newdfcombine.corr()","cba1935f":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(newdfcombine.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nbottom, top = heatmap.get_ylim()\nheatmap.set_ylim(bottom + 0.5, top - 0.5)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);\n# save heatmap as .png file\n# dpi - sets the resolution of the saved image in dots\/inches\n# bbox_inches - when set to 'tight' - does not allow the labels to be cropped\n#plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')","c444d532":"noneed=['Cabin','Embarked','Name','Sex','Ticket','CabinLetter','Title','PassengerId','Cabin_score_convert','CabinNumber']\n#noneed=['Cabin','Embarked','Name','Sex','Ticket','CabinLetter','Title','PassengerId','Embarked_num']\n\nX_train = dfcombine[dfcombine['Survived'].notnull()].drop(columns=noneed).copy()\ny_train = X_train['Survived']\nX_train = X_train.drop(['Survived'],axis=1)\nX_train = X_train.reset_index(drop=True)\nX_test = dfcombine[dfcombine['Survived'].isnull()].drop(columns=noneed).copy()\nX_test = X_test.drop(['Survived'],axis=1)\nX_test = X_test.reset_index(drop=True)\n","884ce94d":"X_train.info()\nprint('------------------------')\nX_test.info()","975e4f66":"# machine learning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier","c8feb7ea":"# train Random Forest\nforest = RandomForestClassifier(n_estimators=153, max_depth=5, random_state=1)\nforest.fit(X_train, y_train)\n\n# predict\ny_pred = forest.predict(X_train)\n\n# evaluate\nprint('Accuracy Score: ', forest.score(X_train, y_train))\nprint('\\nConfusion Matric: ', confusion_matrix(y_train, y_pred))\nprint('\\nClassification Report: ', classification_report(y_train, y_pred))","b72ddc19":"# obtain importance value of each feature\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\nindices = np.argsort(importances)[::-1]\nfeature_df = pd.DataFrame(X_train.columns)\nfeature_df.columns = ['Importance']\n\n# print feature ranking\nfeature_df['Feature'] = pd.Series(importances)\nfeature_df.sort_values(by='Feature', ascending=False, inplace=True)\nprint(feature_df)","c1bfba43":"# final prediction\npredict = forest.predict(X_test)\n\n# report\nreport = pd.DataFrame({'PassengerId': dfcombine['PassengerId'][dfcombine['Survived'].isnull()], 'Survived': predict})\n","549b79a0":"test[test['PassengerId']==1150]","499078f5":"report['Survived'] = report['Survived'].astype(int)","65561063":"report.head(10)","ea83adff":"report.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e6e1a9a2":"#### Summary of Cabin\nCabin has so many missing values. We tried to replace the missing values with median of some of clustered features like Pclass. Hopefully we filled missing value of cabin with good accuracy.\n\nWhile we were filling missing values of cabin, we changed the Embarked and Pclass data features to numeric for compatibilities of group by function and median method  ","3ca34f47":"#### 2.1 Cabin\n##### The Cabin fetures have more null value than the other. Lets take a look the Cabin data, and find out if there are any correlations to another data\/features","e972ee6e":"##### from the diagram picture of the Titanic, we can find out the correlation between Deck and Class","4365a3fe":"### 1. Load Data","5a351810":"#### RMS Titanic sank in the early morning hours of 15 April 1912 in the North Atlantic Ocean, four days into her maiden voyage from Southampton to New York City. The largest ocean liner in service at the time, Titanic had an estimated 2,224 people on board when she struck an iceberg at around 23:40 (ship's time) on Sunday, 14 April 1912. Her sinking two hours and forty minutes later at 02:20 (ship's time; 05:18 GMT) on Monday, 15 April, resulted in the deaths of more than 1,500 people, making it one of the deadliest peacetime maritime disasters in history.\n\n![titanicpic.jpg](attachment:titanicpic.jpg)","89d56e54":"#### 2.4 Age\nSo many missing value in Age. But we can user name and get the title of the person","f0b050f7":"1. Load Data\n2. Analysis\n3. Modeling\n4. Evaluate Results","ca300c78":"#### 2.2 Embarked\nBefore a maiden voyage to New York and after leaving Southampton as its origin embarkation, the Titanic has transit in Cherbourg and Queenstown to pick up some passenger. Based on Embark feature, we have 3 varian values of capital letter: S, C and Q. So we can say the meaning of the letter S for Southmapton, C for Cherbourg and Q for Queenstown","6a986be0":"## Table of Content","77d64c4a":"#### 2.5 Sex\nOnly convert string of sex column into float","cc6480e2":"##### The first class is only in deck (Cabin) A to E while deck F and G can be found for SECOND and THIRD class.","f161609a":"report","79859789":"#### combine test n train","7902f5bd":"#### 2.3 Fare","7e55db7b":"##### From the picture above, we can see that the cabin is repreasent as decks which contains capital letter from A to G plus T ","371f45fd":"#### 2.3 SibSp and Parch\n\nSibSp is the number of sibbling or spouse abroad the Titanic, while Parch is number of parent or children abroad the Titanic. So if SibSp and Parch is zero, it means she or he abroad the Titanic alone which we can add new feature called \"NumberOfFamily\" with minimum value of 1 represent the passenger itself or alone.","b062e299":"# Titanic Survival Prediction","17423237":"#### get the last index of space split.  ","55ab628f":"### 2. Analysis\n\n#### Analyze the data","1674481d":"#### Conclusion: \n\nA, B and C Deck is at the top level of the ship. While D until G is at the low level of the ship. So when the Titanic hit the ice berg, maybe the passenger at the top level would be the first to know and take survival action. Based that argument, why A Dec has least probability than B n C deck??? This is interesting to test. Linear Regresion using pclass?","93203c33":"##### now we fill the missing value of CabinLetter and CabinNumber with median"}}