{"cell_type":{"dd151a24":"code","2cacfa90":"code","3676a93a":"code","c6a59fa1":"code","52823582":"code","c4a84db4":"code","fb079c83":"code","9b501646":"code","4f7d3116":"code","cd375d3b":"code","f0047979":"code","b1db86a4":"code","fe8340fa":"code","9032f751":"code","0a200b59":"code","8590d73c":"code","15115b83":"code","a24982cb":"code","fcc8f86a":"code","b5d507e8":"code","cf4221a1":"code","badca784":"code","b121e981":"code","c3c201d8":"code","b60a85cb":"code","f63c17a1":"code","0aab716b":"code","60f9eb02":"code","9db6b07e":"code","5991c17c":"code","f95b6cbf":"code","c810d37e":"code","d1243fbb":"code","10e9986b":"code","f5e929b8":"code","670aed10":"code","cdbe841c":"code","68bb14c7":"code","8cfdb559":"code","b72c47b1":"code","ed9cc327":"code","55c19d69":"code","59aef4d9":"code","6bcaab27":"code","ac1fd428":"code","1315f990":"code","29528133":"code","dce7260b":"code","4b0f9594":"code","75df220b":"code","7e9753ef":"code","58439757":"code","0055501e":"code","2a70e9b0":"code","afb9b185":"code","c0135fe9":"markdown","85105438":"markdown","22e85979":"markdown","8e9e0451":"markdown","ae90f8c8":"markdown","a968af75":"markdown","84d81ac5":"markdown","e89899e4":"markdown","8b10ff64":"markdown","31d4193b":"markdown","64a48111":"markdown","75f15bcc":"markdown","6d0ae908":"markdown","53fa6af6":"markdown","e5e4380b":"markdown","dc15c2af":"markdown","22497392":"markdown","21e37d65":"markdown"},"source":{"dd151a24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cacfa90":"import pandas as pd\nimport numpy as np\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","3676a93a":"import missingno as msno","c6a59fa1":"file ='\/kaggle\/input\/customer-segmentation-51k-records\/Customer Segmentation.csv'\ndf = pd.read_csv(file)","52823582":"df.head()","c4a84db4":"df.tail()","fb079c83":"df.shape","9b501646":"df.info()","4f7d3116":"df.columns","cd375d3b":"data = df[['first_name', 'last_name','gender', 'email','city',\n       'country','time_zone', 'company_name', 'department', 'job_title', 'language',\n       'university', 'linkedin_skill']]","f0047979":"data.head()","b1db86a4":"data.isnull().sum()","fe8340fa":"msno.bar(data)#checking missing value","9032f751":"data.dtypes.value_counts()#checking various type of category in dataset.","0a200b59":"data.info()# further inspecting each feature dtype correctly assign or not","8590d73c":"data = data.astype({\"gender\":'category',\"department\":'category',\"job_title\":'category',\"language\":'category',\"linkedin_skill\":'category'})","15115b83":"data.info()","a24982cb":"data['name']=data['first_name'].str.cat(data['last_name'],sep=\" \") # merging first and last name , no need of two seprate column for this.","fcc8f86a":"s = data['time_zone'].str.split('\/') # spliting time_zone into continent and time_zone.\ndata = data.assign(continent=s.str[0], timezone=s.str[1])","b5d507e8":"data = data.drop(['first_name', 'last_name','time_zone', 'timezone'],axis=1)","cf4221a1":"data = data.rename(columns={'company_name': 'company', 'job_title': 'job','linkedin_skill':'skill'})","badca784":"data.describe()","b121e981":"data.nunique()","c3c201d8":"plt.figure(figsize=(12, 6))\ndepartment = data['department']\nax=sns.countplot(y= department ,data =data,orient='h',order=department.value_counts().sort_values().index)\nplt.title('various type of department', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('department', fontsize=16)\n","b60a85cb":"plt.figure(figsize=(12, 6))\nsex = data['gender']\nax=sns.countplot(x= sex ,data =data,orient='v',order=sex.value_counts().sort_values().index)\nplt.title('Distribution of Gender', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('Gender', fontsize=16)","f63c17a1":"plt.figure(figsize=(12, 6))\ncontinent = data['continent']\nax=sns.countplot(x= continent ,data =data,orient='v',order=continent.value_counts().sort_values().index)\nplt.title('Continent', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('continent', fontsize=16)","0aab716b":"import squarify # pip install squarify","60f9eb02":"plt.figure(figsize=(20, 10))\nsizes = data['country'].value_counts()[:40]\nsquarify.plot(sizes=sizes, label=data['country'], alpha=0.6)\nplt.title('Proporton of Top 40 countries', fontsize=18)\nplt.axis('off')\nplt.show()\n","9db6b07e":"plt.figure(figsize=(30, 20))\nsizes = data['university'].value_counts()[:50]\nsquarify.plot(sizes=sizes, label=data['university'], alpha=0.6)\nplt.title('Proporton of Top 40 university', fontsize=18)\nplt.axis('off')\nplt.show()","5991c17c":"data.nunique()","f95b6cbf":"data.columns","c810d37e":"data.groupby('continent')['job'].count()\n","d1243fbb":"data.groupby('gender')['continent'].max()","10e9986b":"india = data[data.continent == 'Indian']","f5e929b8":"ind = data[data.country == 'India']","670aed10":"china = data[data.country == 'China']","cdbe841c":"china.info()","68bb14c7":"india.head(10)","8cfdb559":"india.info()","b72c47b1":"india.nunique()","ed9cc327":"plt.figure(figsize=(20, 15))\ncountry = india['country']\nax=sns.countplot(x= country ,data =india,orient='v',order=country.value_counts().sort_values().index)\nplt.title('country', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('country', fontsize=16)","55c19d69":"plt.figure(figsize=(12, 6))\nsex1 = india['gender']\nax=sns.countplot(x= sex1 ,data =india,orient='v',order=sex1.value_counts().sort_values().index)\nplt.title('Distribution of Gender in India', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('Gender', fontsize=16)","59aef4d9":"plt.figure(figsize=(12, 6))\ndepartment1 = india['department']\nax=sns.countplot(y= department1 ,data =india,orient='h',order=department1.value_counts().sort_values().index)\nplt.title('various type of department in India', fontsize=18)\nax.bar_label(ax.containers[0])\nplt.ylabel('Count', fontsize=16)\nplt.ylabel('department', fontsize=16)\n","6bcaab27":"job_grp['gender','country', 'company', 'department', 'job',\n       'language', 'skill', 'continent']","ac1fd428":"india['skill'].value_counts()","1315f990":"india['skill'].nunique()","29528133":"ind.info()","dce7260b":"china.info()","4b0f9594":"china['company'].value_counts().head(30)","75df220b":"china['job'].value_counts().head(30)","7e9753ef":"china['gender'].value_counts(normalize=True).head(10).plot(kind='bar')","58439757":"plt.figure(figsize=(20, 10))\nsizes1 = china['university'].value_counts()[:20]\nsquarify.plot(sizes=sizes1, label=china['university'], alpha=0.6)\nplt.title('Proporton of Top 15 university in China', fontsize=18)\nplt.axis('off')\nplt.show()","0055501e":"language= data['language']\nplt.figure(figsize=(25, 15))\nsns.countplot(x=data['language'][:10],order=language.value_counts().sort_values().index)\nplt.xticks(rotation=90)\nplt.show()","2a70e9b0":"from wordcloud import WordCloud, STOPWORDS","afb9b185":"comment_words = ''\nstopwords = set(STOPWORDS)\n \n# iterate through the csv file\nfor val in china.job:\n     \n    # typecaste each val to string\n    val = str(val)\n \n    # split the value\n    tokens = val.split()\n     \n    # Converts each token into lowercase\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n     \n    comment_words += \" \".join(tokens)+\" \"\n \nwordcloud = WordCloud(width = 1200, height = 1200,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 10).generate(comment_words)\n                     \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()\n","c0135fe9":"### Inspecting each varriable","85105438":"Shape of dataset","22e85979":"Observation\n-------------------------------------------------\n\n1. Asia is dominating.\n2. India as sub_continent. ","8e9e0451":"### Changing dtype","ae90f8c8":"### China","a968af75":"Checking it properly load or not.","84d81ac5":"Observation\n\n-----------------------------------------------------------\n\n1. Male and Female gender is more in number.\n2. proprtion of male and female is appreox same.\n3. Show diversity in our dataset.","e89899e4":"Observation\n\n-----------------------------------------\n\n1. There is no numarical type of data in our dataset.","8b10ff64":"### Importing Related Resources","31d4193b":"## Expolaratory Data Analysis","64a48111":"## Information about the schema","75f15bcc":"extracting useful features from existing dataframe","6d0ae908":"### Removing unnecessary column","53fa6af6":"Observation\n\n-----------------------------------------\n\n\nThere is no missing value in dataset.","e5e4380b":"### Making new features","dc15c2af":"### Renaming some column","22497392":"Observation\n\n-----------------------------------------------------------\n\n1. Proportion of every department is somewhat simmilar in dataset.","21e37d65":"Uploading and Reading Dataset "}}