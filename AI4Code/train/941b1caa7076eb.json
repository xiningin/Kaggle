{"cell_type":{"021c4359":"code","ce3c3b26":"code","7b633f92":"code","173374ff":"code","a9f5c722":"code","a373b46c":"code","e3d756a6":"code","fe492c01":"code","322dcd8f":"code","c4b51f09":"code","47186d09":"code","e96a9c66":"code","79514e4c":"code","3f5d5e73":"code","7ef36657":"code","b9987d26":"code","e38ea1b2":"code","ea80e6aa":"code","bc6911f2":"code","c19a77e5":"code","3d6cef93":"code","eb1f90c3":"code","3e24de71":"code","fb78b6ba":"code","4a05e404":"code","54146c62":"code","f2849241":"code","e6797a11":"code","7c585177":"code","3b180694":"code","cdd51a29":"code","c895bbb7":"code","a071ee9b":"code","1ff73f52":"code","98bcd95e":"code","929021bc":"code","5bfd4acd":"code","58c506c0":"code","e9afe520":"code","1c413ec4":"code","ded503e6":"code","89bc5105":"code","b23a0e86":"code","2b998dbc":"code","9481bf10":"code","d9f746a7":"code","fe9fd428":"code","cdd59104":"code","020def43":"code","8eb2c1d8":"code","9544f566":"code","6c3ab7bb":"code","60860297":"code","3ccc15d6":"code","20555479":"code","dfd7d169":"code","03e2b82e":"markdown","4cc1adfd":"markdown","45f96849":"markdown","8c0dacfa":"markdown","47f15f96":"markdown","ef0f9775":"markdown","a6b48258":"markdown","efa22737":"markdown"},"source":{"021c4359":"import numpy as np# linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport sklearn\nimport warnings\nimport io\nimport requests\nimport re\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nsns.set()\nimport xgboost as xgb\nfrom sklearn.metrics import r2_score\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ce3c3b26":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv')\nsample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')","7b633f92":"train.head()","173374ff":"print(f'Number of rows: {train.shape[0]};  Number of columns: {train.shape[1]}; No of missing values: {sum(train.isna().sum())}')","a9f5c722":"print(f'Number of rows: {test.shape[0]};  Number of columns: {test.shape[1]}; No of missing values: {sum(test.isna().sum())}')","a373b46c":"test.head()","e3d756a6":"train.info()","fe492c01":"train.describe().T","322dcd8f":"train['year'] = pd.DatetimeIndex(train['date']).year\ntrain['month'] = pd.DatetimeIndex(train['date']).month\ntrain['day']= pd.DatetimeIndex(train['date']).day","c4b51f09":"print(f'train years  {train.year.unique()}  months : {train.month.unique()}    days: {train.day.unique()} ')","47186d09":"test['year'] = pd.DatetimeIndex(test['date']).year\ntest['month'] = pd.DatetimeIndex(test['date']).month\ntest['day']= pd.DatetimeIndex(test['date']).day","e96a9c66":"print(f'test years  {test.year.unique()}  months : {test.month.unique()}    days: {test.day.unique()} ')","79514e4c":"sns.countplot(x='product', data=train, palette='tab10')","3f5d5e73":"sns.countplot(x='country', data=train, palette='tab10')","7ef36657":"sns.countplot(x='store', data=train, palette='tab10')","b9987d26":"#histogram\nsns.histplot(train['num_sold'],color=\"red\", label=\"100% Equities\", kde=True, stat=\"density\", linewidth=0)","e38ea1b2":"print (\"Skew is:\", train.num_sold.skew())\nplt.hist(train.num_sold, color='red')\nplt.show()","ea80e6aa":"import matplotlib.pyplot as plt\nplt.plot(train['date'], train['num_sold'], label='num_sold') #The parameter label is to indicate the legend. This doesn't mean that it will be shown, we'll have to use another command that I'll explain later.","bc6911f2":"target = np.log(train.num_sold)\nprint (\"Skew is:\", target.skew())\nplt.hist(target, color='blue')\nplt.show()","c19a77e5":"plt.plot(train['date'], train['num_sold'], label='num_sold')\nplt.xlabel('Date')\nplt.ylabel('Popularity')\nplt.title('Popularity of AI terms by date')\nplt.grid(True)\nplt.legend()","3d6cef93":"num_sold_by_country = train.groupby(['country'])[['num_sold']].mean()\nnum_sold_by_country ","eb1f90c3":"colors_4 = ['magenta','yellow','orange','red']\ncolors_3 = ['green', 'blue','cyan']","3e24de71":"num_sold_by_country.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_country.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()","fb78b6ba":"num_sold_by_store = train.groupby(['store'])[['num_sold']].mean()\nnum_sold_by_store.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_store.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()\n","4a05e404":"num_sold_by_product = train.groupby(['product'])[['num_sold']].mean()\nnum_sold_by_product.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_product.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()","54146c62":"num_sold_by_year= train.groupby(['year'])[['num_sold']].mean()\nnum_sold_by_year.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_year.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()","f2849241":"num_sold_by_month= train.groupby(['month'])[['num_sold']].mean()\nnum_sold_by_month.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_month.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()","e6797a11":"num_sold_by_day= train.groupby(['day'])[['num_sold']].mean()\nnum_sold_by_day.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_day.index,autopct='%1.1f%%', colors=colors_4)\nplt.show()","7c585177":"def select_date(date1,date2,train):\n\n \n df = train[(train['date'] >= date1) & (train['date'] <= date2)]\n return df","3b180694":"date1='2015-01-01'\ndate2='2015-12-30'\ndf=select_date(date1,date2,train)","cdd51a29":"df.head()","c895bbb7":"def plt_sns(train):\n sns.countplot(x='product', data=train, palette='tab10')\n sns.countplot(x='country', data=train, palette='tab10')\n sns.countplot(x='store', data=train, palette='tab10')\n\n\ndef plt_his(train):\n  sns.histplot(train['num_sold'],color=\"red\", label=\"100% Equities\", kde=True, stat=\"density\", linewidth=0)\n  print (\"Skew is:\", train.num_sold.skew())\n  plt.hist(train.num_sold, color='red')\n  plt.show()\n  plt.plot(train['date'], train['num_sold'], label='num_sold') #The parameter label is to indicate the legend. This doesn't mean that it will be shown, we'll have to use another command that I'll explain later.\n  target = np.log(train.num_sold)\n  print (\"Skew is:\", target.skew())\n  plt.hist(target, color='blue')\n  plt.show()\n  plt.plot(train['date'], train['num_sold'], label='num_sold')\n  plt.xlabel('Date')\n  plt.ylabel('Popularity')\n  plt.title('Popularity of AI terms by date')\n  plt.grid(True)\n  plt.legend()\n\n\n\ncolors_4 = ['magenta','yellow','orange','red']\ncolors_3 = ['green', 'blue','cyan']\n\ndef num_sold_by_country_pie(train):\n  num_sold_by_country = train.groupby(['country'])[['num_sold']].mean()\n  num_sold_by_country.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_country.index,autopct='%1.1f%%', colors=colors_4)\n  plt.show()\n\ndef num_sold_by_store_pie(train):\n    num_sold_by_store = train.groupby(['store'])[['num_sold']].mean()\n    num_sold_by_store.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_store.index,autopct='%1.1f%%', colors=colors_4)\n    plt.show()\n    \ndef num_sold_by_product_pie(train):\n  num_sold_by_product = train.groupby(['product'])[['num_sold']].mean()\n  num_sold_by_product.plot.pie(subplots=True, figsize=(20,10), labels=num_sold_by_product.index,autopct='%1.1f%%', colors=colors_4)\n  plt.show()","a071ee9b":"num_sold_by_product_pie(df)","1ff73f52":"plt_his(df)","98bcd95e":"num_sold_by_country_pie(df)","929021bc":"num_sold_by_store_pie(df)","5bfd4acd":"num_sold_by_product_pie(df)","58c506c0":"y     = train[['row_id','num_sold']]\n\ntrain.drop(['date','num_sold'] , axis = 1 , inplace = True)\ntest.drop('date' , axis = 1 , inplace = True)\n","e9afe520":"labelencoder=LabelEncoder()\nall_df = [train, test]\nall_df = pd.concat(all_df).reset_index(drop=True)\nall_df['country']      = labelencoder.fit_transform(all_df['country'])\nall_df['store']   = labelencoder.fit_transform(all_df['store'].astype(str))\nall_df['product']   = labelencoder.fit_transform(all_df['product'].astype(str))","1c413ec4":"X = pd.DataFrame(all_df[:26298])\ntest  = pd.DataFrame(all_df[26298:32868])","ded503e6":"sns.heatmap(X.corr(), annot=True, fmt='.2f')","89bc5105":"sns.pairplot(X)","b23a0e86":"sns.jointplot(x='store', y='country', data=X)","2b998dbc":"# explore lightgbm number of trees effect on performance\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(X, y['num_sold'], test_size=0.2, random_state=42)\n","9481bf10":"from xgboost import XGBRegressor\nXGB = XGBRegressor(max_depth=2,learning_rate=0.1,n_estimators=1000,reg_alpha=0.001,reg_lambda=0.000001,n_jobs=-1,min_child_weight=3)\nXGB.fit(X_train,y_train)","d9f746a7":"from lightgbm import LGBMRegressor\nLGBM = LGBMRegressor(n_estimators = 1000)\nLGBM.fit(X_train,y_train)","fe9fd428":"print (\"Training score:\",XGB.score(X_train,y_train), \"Test Score:\",XGB.score(X_test,y_test))\nprint (\"Training score:\",LGBM.score(X_train,y_train),\"Test Score:\",LGBM.score(X_test,y_test))","cdd59104":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\nclf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train,y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","020def43":"# decision tree Score\nround(np.mean(score)*100, 2)","8eb2c1d8":"clf.fit(X_train,y_train)","9544f566":"# calculate manually\ndef my_function(y,y_preds):\n  from sklearn.metrics import r2_score\n  from sklearn.metrics import mean_squared_error\n  from sklearn.metrics import mean_absolute_error  \n\n  m1=mean_absolute_error(y,y_preds)\n  m2 = mean_squared_error(y,y_preds)\n  r2 = r2_score(y, y_preds)\n\n  print(\"Results by manual calculation:\")\n  print(\"mean_absolute_error:\",m1)\n  print(\"mean_squared_error:\", m2)\n  print('r2 score for a worse model is', r2)","6c3ab7bb":"y_preds_lgbm = LGBM.predict(test)\nmy_function(sample.num_sold,y_preds_lgbm)","60860297":"y_XGB = XGB.predict(test )\nmy_function(sample.num_sold,y_XGB)","3ccc15d6":"nn_preds = clf.predict(test )\nmy_function(sample.num_sold,nn_preds)","20555479":"test.head()","dfd7d169":"my_submission = pd.DataFrame({'row_id': test.row_id, 'num_sold': y_preds_lgbm})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_ran.csv', index=False)\nmy_submission.head()","03e2b82e":"The dimension and number of missing values in the train dataset is as below:","4cc1adfd":"Load and check data","45f96849":"let create day , months and years variables","8c0dacfa":"Below is the first 5 rows of test dataset:","47f15f96":"function select_date is function give you data between two dates ","ef0f9775":"Infos","a6b48258":"Summarie and statistics\u00b6","efa22737":"data train between 2015-01-01 and 2015-12-30"}}