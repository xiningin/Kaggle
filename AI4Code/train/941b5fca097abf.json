{"cell_type":{"5382cf02":"code","5a6a8aff":"code","f2f9e63e":"code","2e61eb0d":"code","7ef8ff0c":"code","ad19edc7":"code","6be971b2":"code","e73a4de2":"code","0e65b8a7":"code","2c791d0d":"code","12053789":"code","8ada6e64":"code","1b706b30":"code","57aeb475":"code","22d01eac":"code","f478d0ca":"code","a23834bf":"code","849d3442":"code","0d814a59":"code","f5c7995b":"code","fe6d2b57":"code","4019c06f":"markdown","934a49b5":"markdown","8b87031d":"markdown","6b8a5027":"markdown","d6aad0bc":"markdown","5bcda27f":"markdown","541bc61f":"markdown","f2651743":"markdown"},"source":{"5382cf02":"!pip install xmltodict --upgrade\n","5a6a8aff":"from tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import datasets, layers, models\n\nimport keras_tuner\nfrom keras_tuner.engine.hyperparameters import HyperParameter\nfrom keras_tuner import RandomSearch\n\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle\n\nimport seaborn as sns\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport collections\nimport xmltodict\nimport cv2\nimport os","f2f9e63e":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # Sync TPU version\n    from cloud_tpu_client import Client\n    c = Client()\n    c.configure_tpu_version(tf.__version__, restart_type='ifNeeded')\n    \n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError as v:\n    tpu = None\n    print(v)\n    \n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","2e61eb0d":"def face_exctraction(directory_load_image,directory_load_notation,directory_save_train,directory_save_test):\n    y_train = []\n    y_test = []\n    i=1\n    \n    if not os.path.exists(\".\/\"+directory_save_train):\n        os.makedirs(\".\/\"+directory_save_train)\n    if not os.path.exists(\".\/\"+directory_save_test):\n        os.makedirs('.\/'+directory_save_test)\n    \n    for file in os.listdir(directory_load_notation):\n        with open(os.path.join(directory_load_notation, file), 'r') as f:\n            data = f.read()\n\n\n            #getting data\n            ann_dict=xmltodict.parse(data)[\"annotation\"]\n            object_list = ann_dict[\"object\"]\n\n\n            #opening image\n            image_name = file.replace(\"xml\",\"png\")\n            im = Image.open(directory_load_image+image_name)\n\n            #checking if there are more than 1 face in this image\n            if isinstance(object_list, list): #if yes: itrating through them \n                 for object_ in object_list:\n                        #getting face boundaries\n                        xmin = int(object_[\"bndbox\"][\"xmin\"])\n                        xmax = int(object_[\"bndbox\"][\"xmax\"])\n                        ymin = int(object_[\"bndbox\"][\"ymin\"])\n                        ymax = int(object_[\"bndbox\"][\"ymax\"])\n                        \n                        #cropping the face and saving it\n                        crop_rectangle = (xmin, ymin, xmax , ymax)\n                        cropped_im = im.crop(crop_rectangle)\n                        resized_im = cropped_im.resize((32, 32), Image.ANTIALIAS)\n                        \n                        #this part is for sperating train set from test set\n                        if i<3600:\n                            resized_im.save(directory_save_train+str(i)+\".png\")\n                            y_train.append(object_[\"name\"])\n                        else:\n                            resized_im.save(directory_save_test+str(i-3599)+\".png\")\n                            y_test.append(object_[\"name\"])\n\n                        i+=1\n            else:\n                #same thing on images with one face in them\n                object_ = object_list\n                xmin = int(object_[\"bndbox\"][\"xmin\"])\n                xmax = int(object_[\"bndbox\"][\"xmax\"])\n                ymin = int(object_[\"bndbox\"][\"ymin\"])\n                ymax = int(object_[\"bndbox\"][\"ymax\"])\n\n                crop_rectangle = (xmin, ymin, xmax , ymax)\n                cropped_im = im.crop(crop_rectangle)\n                resized_im = cropped_im.resize((32, 32), Image.ANTIALIAS)\n                if i<3600:\n                    resized_im.save(directory_save_train+str(i)+\".png\")\n                    y_train.append(object_[\"name\"])\n                else:\n                    resized_im.save(directory_save_test+str(i-3599)+\".png\")\n                    y_test.append(object_[\"name\"])\n\n                i+=1\n    y_train = np.asarray(y_train)\n    y_test = np.asarray(y_test)\n    return y_train,y_test\n\n                    \n            \n        \n            \n    \n        ","7ef8ff0c":"def images_to_array(directory,num_img):\n    X_nn=[]\n    #iterating through directory and turning 32x32 images to an array with shape of (32,32,3) and stacking them inside a dataset.\n    for i in range(1,num_img+1):\n        im = Image.open(directory+str(i)+\".png\")\n        rgb_im = im.convert('RGB')\n        im = np.asarray(rgb_im,dtype=\"int\")\n        X_nn.append(im)\n    return np.asarray(X_nn)","ad19edc7":"def add_data_aug (directory_save_inc , directory_save_no , num_inc , num_no , X_train , y_train):\n    \n    if not os.path.exists(\".\/\"+directory_save_inc):\n        os.makedirs(\".\/\"+directory_save_inc)\n    if not os.path.exists(\".\/\"+directory_save_no):\n        os.makedirs('.\/'+directory_save_no)\n    \n    \n    #the image generator ranges.\n    datagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True,\n        fill_mode = \"nearest\"\n    )\n    \n    #we are trying to upsmaple \"without_mask\" images and \"mask_weared_incorrect\" so we select them\n    without_mask = X_train[y_train==\"without_mask\"]\n    mask_weared_incorrect = X_train[y_train==\"mask_weared_incorrect\"]\n    \n    #creating the desired number of images\n    j=0\n    for batch in datagen.flow(without_mask,batch_size=1,save_to_dir=directory_save_no,save_prefix=\"wo\",save_format='png'):\n        j+=1\n        #if j> 2175:\n        if j>num_no:\n            break\n    j=0\n    for batch in datagen.flow(mask_weared_incorrect,batch_size=1,save_to_dir=directory_save_inc,save_prefix=\"wi\",save_format='png'):\n        j+=1\n        #if j> 2722:\n        if j>num_inc:\n            break\n    X_nn=[]\n    \n    #adding newly made images to trainign set\n    for file in os.listdir(directory_save_no):\n        im = Image.open(os.path.join(directory_save_no, file))\n        rgb_im = im.convert('RGB')\n        im = np.asarray(rgb_im,dtype=\"int\")\n        X_nn.append(im)\n        y_train=np.append(y_train,'without_mask')\n    \n    \n    for file in os.listdir(directory_save_inc):\n        im = Image.open(os.path.join(directory_save_inc, file))\n        rgb_im = im.convert('RGB')\n        im = np.asarray(rgb_im,dtype=\"int\")\n        X_nn.append(im)\n        y_train = np.append(y_train,\"mask_weared_incorrect\")\n        \n    X_train_augmented = np.asarray(X_nn)\n    \n    X_train = np.concatenate((X_train,X_train_augmented  ))\n    \n    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n    \n    return X_train,y_train","6be971b2":"def preproccesing(X_train,X_test,y_train,y_test):\n    #nomalizing color values\n    X_train = X_train \/ 255\n    X_test = X_test \/ 255\n    \n    #categorical to numerical values for labels.\n    conditions = [\n                    (y_train == \"without_mask\"),\n                    y_train == (\"mask_weared_incorrect\"),\n                    (y_train == \"with_mask\")]\n    choices = [0, 1, 2]\n    y_train = np.select(conditions, choices)\n    conditions = [\n                    (y_test == \"without_mask\"),\n                    y_test == (\"mask_weared_incorrect\"),\n                    (y_test == \"with_mask\")]\n    choices = [0, 1, 2]\n    y_test = np.select(conditions, choices)\n    return X_train,X_test,y_train,y_test","e73a4de2":"def build_model(hp):  \n    #model structure\n    model = keras.Sequential()\n        \n    model.add(layers.Conv2D(\n        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n        activation='relu',\n        input_shape=(32,32,3)\n    )),\n\n    model.add(layers.MaxPooling2D((2, 2))),\n\n    model.add(layers.Conv2D(\n        filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=16),\n        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n        activation='relu',\n        \n    )),\n    model.add(layers.MaxPooling2D((2, 2))),\n\n    model.add(layers.Conv2D(\n        filters=hp.Int('conv_3_filter', min_value=32, max_value=128, step=16),\n        kernel_size=hp.Choice('conv_3_kernel', values = [3,5]),\n        activation='relu',\n        \n    )),\n\n    model.add(layers.Flatten()),\n\n    model.add(layers.Dense(\n        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n        activation='relu'\n    )),\n\n    model.add(layers.Dense(3, activation='softmax'))\n\n  \n  \n    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3])),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n  \n    return model","0e65b8a7":"def model_training (X_train,y_train):\n    tuner_search = RandomSearch(build_model,objective=keras_tuner.Objective(\"val_accuracy\", direction=\"max\"),max_trials=50,distribution_strategy=strategy,directory=\"output\")\n    tuner_search.search(X_train,y_train,epochs=30,validation_split=0.1)\n    return tuner_search.get_best_models(num_models=1)[0]","2c791d0d":"def evaluatuion (model,X_test,y_test):\n    #getting models predcitons on test set\n    y_pred = []\n    y_prob = model.predict(X_test)\n    for i in y_prob:\n        y_pred.append(np.argmax(i))\n        \n                \n    confusion_matrix_array = confusion_matrix(y_test,y_pred)\n    \n    print(\"Report:\")\n    print(classification_report(y_test, y_pred,\n\ttarget_names=[\"without mask\",\"wask weared incorrectly\",\"with mask\"]))\n    \n    \n    print(\"Confusion Matrix:\")\n    confusion_matrix_array = confusion_matrix(y_test,y_pred,normalize='true')\n    \n    g= sns.heatmap(confusion_matrix_array, annot=True,yticklabels=[\"Act No Mask\",\"Act Wrong\",\"Act Correct\"],xticklabels=[\"Pred No Mask\",\"Pred Wrong\",\"Pred Correct\"])\n    g.set_yticklabels(g.get_yticklabels(), rotation = 0)\n    \n\n\n    \n    return y_pred\n    ","12053789":"def show_example(X_test,y_test,y_pred,index):\n    plt.imshow(X_test[index])\n    print (\"Actual:\")\n    \n    if y_test[index] == 0 :\n        print (\"with out mask\")\n    if y_test[index] == 1 :\n        print (\"mask worn incorrectly\")\n    if y_test[index] == 2 :\n        print (\"mask worn correctly\")\n        \n    print(\"Prediction:\")    \n        \n    if y_pred[index] == 0 :\n        print (\"with out mask\")\n    if y_pred[index] == 1 :\n        print (\"mask worn incorrectly\")\n    if y_pred[index] == 2 :\n        print (\"mask worn correctly\")","8ada6e64":"y_train,y_test = face_exctraction(\"..\/input\/face-mask-detection\/images\/\",\"..\/input\/face-mask-detection\/annotations\/\",\"train_images\/\",\"test_images\/\")","1b706b30":"collections.Counter(y_train)","57aeb475":"X_train = images_to_array(\".\/train_images\/\",3599)\nX_test = images_to_array(\".\/test_images\/\",473)","22d01eac":"X_train.shape","f478d0ca":"X_train,y_train = add_data_aug (\"Augmented_incorrect\/\" , \"Augmented_without\/\", 2722 , 2175 , X_train , y_train)","a23834bf":"collections.Counter(y_train)","849d3442":"X_train,X_test,y_train,y_test = preproccesing(X_train,X_test,y_train,y_test)","0d814a59":"model= model_training (X_train,y_train)","f5c7995b":"y_pred = evaluatuion (model,X_test,y_test,)","fe6d2b57":"show_example(X_test,y_test,y_pred,2)","4019c06f":"# Summary\n**1.Exctarcting faces and saving them** <br>\n**2.Turning the face images to numpy array and creating train,test sets**<br>\n**3.Generating new images to solve skewed data problem**<br>\n**4.Preproccesing the data** <br>\n**5.Training the model with keras_tuner**<br>\n**6.Evaluating the model** <br>\n","934a49b5":"**An example**","8b87031d":"# 1.Extracting the face\n**First we iterate through all images the found faces in specified box, extarcting and saving it (as train or test set) and also adding label of the image while we are saving it**","6b8a5027":"# 3.Generating new images\n**With the help of built in keras modules, with generate new images with transforming current images to solve the skeweness problem. we only do this for training data set**","d6aad0bc":"# 4.Preproccesing","5bcda27f":"# 2.Creating train,test sets.\n**First we load the saved images and turn them into datasets**","541bc61f":"# 5.Training the model\n**We use keras_tuner library for hyperparameter tuning, it uses a RandomSearch to find the best parameters. the metric the tuner is trying to maximize is the validation set accuracy(validation is chosen from traning data set). accuracy is a good measurement since the training set is balanced**","f2651743":"# 6.Evaluation"}}