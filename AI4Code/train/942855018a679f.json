{"cell_type":{"360ee7ad":"code","aaec05fb":"code","b1be4ed7":"code","353087d3":"code","ea41d518":"code","91d08f4c":"code","b6840f14":"code","7904a76a":"code","bfdefda1":"code","7a80555a":"code","3d5d1f5b":"code","a103cbd6":"code","243f0686":"code","bdbb0759":"code","82967c0a":"markdown","96ef397d":"markdown","3884293c":"markdown","de33ba8d":"markdown","99019a35":"markdown","dfa96e66":"markdown","f0f27e1c":"markdown"},"source":{"360ee7ad":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom PIL import Image\n\nnp.random.seed(42)\ntorch.manual_seed(42)","aaec05fb":"TARGET_COLUMNS = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n                 'Swan Ganz Catheter Present']\n\nDEBUG = False\n\nif DEBUG is False:\n    BATCH_SIZE = 32\n    EPOCHS = 10\n    AVERAGING_SIZE = 100\nelse:\n    BATCH_SIZE = 4\n    EPOCHS = 2\n    AVERAGING_SIZE = 20\n\nROOT_DIR = '\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/test'\nOUTPUT_DIR = '.\/'\nMODEL_PATH = '..\/input\/densenet121-adam-finetuning\/densenet121_epoch_2_loss_0.1807_roc_0.8640.pth'\nIMG_SIZE = 256\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","b1be4ed7":"imgs = []\nfor dirname, _, filenames in os.walk('..\/input\/ranzcr-clip-catheter-line-classification\/test'):\n    for filename in filenames:\n        imgs.append(filename)\n\n# Load DF with labels \ncols = {\"StudyInstanceUID\": imgs}\nfor col in TARGET_COLUMNS:\n    cols[col] = [0 for i in range(len(imgs))]\ntest_set_df = pd.DataFrame(cols)\nprint(test_set_df.columns)\n\nif DEBUG is True:\n    test_set_df = test_set_df.sample(200)\nelse:\n    test_set_df = test_set_df\n\n\ntest_set_df.shape","353087d3":"class RanzcrClipTestDataset(torch.utils.data.Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, labels_df, transform=None):\n        \"\"\"\n        Args:\n            labels_df (string): DataFrame with mapping of images to target\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.file_paths = [os.path.join(ROOT_DIR, uid) for uid in labels_df[\"StudyInstanceUID\"].values]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n\n        # Read image as PIL\n        sample = Image.open(self.file_paths[idx]).convert('RGB')\n\n        # Run all given transformations on image\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample","ea41d518":"test_transforms = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])","91d08f4c":"test_set = RanzcrClipTestDataset(labels_df=test_set_df, transform=test_transforms)\n\nprint(f'Test size: {len(test_set)}')\n\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)","b6840f14":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs = next(iter(test_loader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)\n","7904a76a":"def inference(net):\n    \n    y_pred = []\n    y_prob = []\n    \n    # switch to evaluation mode\n    net.eval()\n    \n    start_time = time.time()\n    \n    with torch.no_grad():\n        for i, inputs in enumerate(test_loader, 0):\n\n            inputs = inputs.to(device)\n      \n            outputs = net(inputs)\n            \n            probs = outputs.sigmoid()\n            \n            for i in range(len(outputs)):\n                y_pred.append(np.round(probs[i].cpu().detach().numpy()))\n                y_prob.append(probs[i].cpu().detach().numpy())\n\n        y_pred = np.vstack(y_pred)\n        y_prob = np.vstack(y_prob)\n        \n        del inputs\n        torch.cuda.empty_cache()\n        \n        end_time = time.time()\n        print(f'[{i}] Elapsed {(end_time - start_time):.4f} ') \n        \n        return y_pred, y_prob\n","bfdefda1":"class CustomPretrainedmModel(nn.Module):\n    def __init__(self, pretrained=False):\n        super().__init__()\n        self.model = torchvision.models.densenet121(pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, len(TARGET_COLUMNS))\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","7a80555a":"checkpoint = torch.load(MODEL_PATH, map_location=device)\nmodel = CustomPretrainedmModel()\nmodel.to(device)\nmodel.load_state_dict(checkpoint['model'])\ny_pred, y_prob = inference(model)","3d5d1f5b":"test_set_df.iloc[:, 1:] = y_prob\n\ntest_set_df[\"StudyInstanceUID\"] = test_set_df.StudyInstanceUID.str.replace('.jpg', '')","a103cbd6":"# dtypes = {col: 'int' for col in TARGET_COLUMNS}\n# test_set_df = test_set_df.astype(dtypes)","243f0686":"test_set_df.sample(20)","bdbb0759":"test_set_df.to_csv('.\/submission.csv', index=False)","82967c0a":"### Load DataFrame with labels of images","96ef397d":"### Split test dataset into train and test","3884293c":"# Training Code","de33ba8d":"## Visualize some images","99019a35":"# Load and configure data ","dfa96e66":"### Transforms","f0f27e1c":"### Create custom PyTorch dataset\n\nWe do this instead of using ImageFolder as we don't want to reorganize the input folder as it is given from Kaggle already loaded without any nesting, and we have more than one class for each image so we need custom dataset"}}