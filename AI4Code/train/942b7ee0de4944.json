{"cell_type":{"0092cef9":"code","7ed41444":"code","a5ea1f3a":"code","3b1384eb":"code","f024a482":"code","bd9c3245":"code","7fbbd359":"code","8a408829":"code","c1872bcd":"code","be020076":"code","cb481d31":"code","a3ce8934":"code","b2409b67":"code","72f2b6ad":"code","9b72994f":"code","9df62047":"code","9efaf688":"code","326be973":"code","3f204890":"markdown","c456ee4c":"markdown","ba2263d2":"markdown","01c35199":"markdown","a594c41d":"markdown","42b86862":"markdown","35eca635":"markdown","82398368":"markdown","008ae43c":"markdown","957094f0":"markdown","53de8b02":"markdown","1e4f3a41":"markdown","4ebf7bf6":"markdown","d4e4ed67":"markdown","acf2e243":"markdown"},"source":{"0092cef9":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nsns.set_style(\"whitegrid\")\n%matplotlib inline\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import make_scorer, accuracy_score \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import GridSearchCV\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os","7ed41444":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","a5ea1f3a":"train.head()","3b1384eb":"test.head()","f024a482":"print(\"These are all the columns for the data: \", train.columns)\nprint(\"There are \" + str(len(train.columns)) + \" columns.\")","bd9c3245":"train.describe()","7fbbd359":"train.corr()","8a408829":"train.isnull().sum()","c1872bcd":"test.isnull().sum()","be020076":"# Drop useless features from data\ntrain = train.drop([\"id\", \"name\", \"favorite_color\"], axis=1)\ntesting = test.drop([\"id\", \"name\", \"favorite_color\"], axis=1)","cb481d31":"le = LabelEncoder()\nle.fit(train[\"city\"])\n\ntrain[\"city\"] = le.transform(train[\"city\"])\ntesting[\"city\"] = le.transform(testing[\"city\"])","a3ce8934":"def one_hot(data, col):\n    for value in set(data[col]):\n        encode = (data[col] == value).astype(\"int\")\n        data[value] = encode\n    return data.drop([col], axis=1)\n        \ntrain = one_hot(train, \"city\")\ntesting = one_hot(testing, \"city\")","b2409b67":"def scale(data, method=\"standard\"):\n    \"\"\"\n    Scales the inputted data by standardizing its values.\n  \n    :param data: data to be scaled\n    :param method: how to scale data\n    :return: standardized version of the data\n    \"\"\"\n    scaler = StandardScaler() if method==\"standard\" else MinMaxScaler()\n    arr = np.array(data).reshape(-1, 1)\n    return scaler.fit_transform(arr)\n\n\ncolumns = [\"age\", \"salary\"]\n\nfor column in columns:\n    train[column] = scale(train[column])\n    testing[column] = scale(testing[column])","72f2b6ad":"train.head()","9b72994f":"def prepare_data(df, valid_split=0.2):\n    \"\"\"\n    Splits and returns the training and validation sets for the data. \n\n    :param df: preprocessed dataset\n    :returns: training sets and validation sets\n    \"\"\"\n    X_train = df.drop(\"surf\", axis=1) # define training features set\n    y_train = df[\"surf\"] # define training label set\n    # we will use 20% of the trainig data as validation data\n    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_split, random_state=0) # X_valid and y_valid are the validation sets\n    return X_train, X_valid, y_train, y_valid\n\n\nX_train, X_valid, y_train, y_valid = prepare_data(train)","9df62047":"def train_and_evaluate(model, parameters, train_X, train_y, valid_X, valid_y):\n    \"\"\"\n    Trains and evalutaes a model based on training\/validation data.\n  \n    :param model: model to fit\n    :param parameters: model parameters\n    :param train_X: training features\n    :param train_y: training label\n    :param valid_X: validation features\n    :param valid_y: validation label\n    :return: accuracy of model on validation set\n    \"\"\"\n    grid_search = GridSearchCV(model, parameters, scoring=make_scorer(accuracy_score))\n    grid_search.fit(train_X, train_y)\n    model = grid_search.best_estimator_\n    model.fit(train_X, train_y)\n    \n    predictions = model.predict(valid_X)\n    return model, accuracy_score(valid_y, predictions)\n\n\nknn_params = {\"n_neighbors\": [3, 5, 10, 15], \"weights\": [\"uniform\", \"distance\"], \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n              \"leaf_size\": [20, 30, 50]}\nknn, knn_acc = train_and_evaluate(KNeighborsClassifier(), knn_params, X_train, y_train, X_valid, y_valid)\n\ngnb_params = {}\ngnb, gnaivebayes_acc = train_and_evaluate(GaussianNB(), gnb_params, X_train, y_train, X_valid, y_valid)\n\nbnb_params = {}\nbnb, bnaivebayes_acc = train_and_evaluate(BernoulliNB(), bnb_params, X_train, y_train, X_valid, y_valid)","9efaf688":"model_performances = pd.DataFrame({\n    \"Model\": [\"K Nearest Neighbors\", \"Gaussian Naive Bayes\", \"Bernoulli Naive Bayes\"],\n    \"Accuracy\": [knn_acc, gnaivebayes_acc, bnaivebayes_acc]\n})\n\nmodel_performances.sort_values(by=\"Accuracy\", ascending=False)","326be973":"model = gnb.fit(train.drop([\"surf\"], axis=1), train[\"surf\"])\npreds = model.predict(testing)\n\npredictions = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"surf\": preds\n    })\n    \npredictions.to_csv(\"predictions.csv\", index=False)\npredictions","3f204890":"Here are the model performances on the validation set. ","c456ee4c":"## Importing Packages\nThese are all the packages that we will use in the notebook, including preprocessing and modeling the data.","ba2263d2":"### Scaling\nThere are many numerical features in the data with a large range of values. This potentially has an affect on modeling, as larger values tend to impact model weights more. In this case, we can use a standard scaler by standardizing each value in each column. Each value is transformed accordingly: z = (x - u) \/ s where u is the mean and s is the standard deviation.","01c35199":"# Model Description\nI implemented a Gaussian Naive Bayes model to make classifications on the data of whether a person surfs or not. This model uses Gaussian distributions in order to estimate conditional probabilities of the labels given the feature vector of the data. It performed generally well on unseen validation data, with a consistent accuracy above 80%. ","a594c41d":"## Loading and Viewing Data\nWe already have the training and testing sets made, so we will load and inspect them.","42b86862":"## Selecting Model and Making Predictions\nThe last step is to choose the best performing model and use it to make predictions on the test set we are provided. We are confident that this model will be the best selection since it performed the best on the validation set, which it hasn't been exposed to during training. This means that the risk of overfitting is reduced. \n\nWe will now generate a new csv table containing the test data and the predictions made by the model.","35eca635":"### Training and Validation Sets\nNow that our data is preprocessed, we can create the inputs that the model will take in. We will also introduce a validation set generated by randomly sampling rows from the training set. \n\nA validation set is important to mitigate overfitting by the models by evaluating the model performance on data it hasn't been exposed to. By doing so, we can be more confident that the model isn't overfitting to the training and will perform just as well on the testing set we have.","82398368":"## Preprocessing\nBefore modeling, we need to preprocess the data by setting it up in the correct format to make accurate predictions. This includes imputing, label encoding, scaling, and creating training\/validation sets.\n","008ae43c":"## Model Fitting, Evaluation, Optimization, and Prediction\nWe are now ready to start modeling the data. We will use the training and validation sets to fit and evaluate different types of classification models through metrics like accuracy of its predictions. Then we will compare and decide the most appropriate model to use for our data.","957094f0":"### Label Encoding\nMost of the data is already well prepared. The columns, **Race**, **Sex**, and **Renal Disease Indicator** have string values that must be encoded to a numerical value. We can do a simple encoding by assigning a numerical value to each category that aappears.","53de8b02":"We now have the data in the format we need to start modeling.","1e4f3a41":"### Missingness\n\nWe should also inspect the number of missing values in both the training and testing datasets.","4ebf7bf6":"## EDA\nIn this section, we will explore the dataset and its features. We will visualize the associations between certain attributes and the outcome of AdverseOpioidEvent.","d4e4ed67":"Great! Now we can inspect the current data we have to see if it looks ready.","acf2e243":"Here is a summary of the statistics for each quantitative column. Looking at the values below, there are many nominal data types represented as numerical values."}}