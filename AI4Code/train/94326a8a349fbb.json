{"cell_type":{"7ef79ee3":"code","4dcea431":"code","1700834b":"code","c53e72c2":"code","1482be51":"code","a8b95dd7":"code","d30900ac":"code","c25bcf29":"code","5cf95829":"code","23e3bae7":"code","c5a32f44":"code","8420271a":"code","a3e10f54":"code","22fa3b89":"code","7cd770ae":"code","4411a0a9":"code","1c61664d":"code","39de7d10":"code","de9bf03a":"code","1e3d949e":"code","e6a9e762":"code","373534f6":"code","51ad4ae1":"code","6e30a53a":"code","b0110706":"code","28ba7a95":"code","d75bd127":"code","6e9a1821":"code","3edd7fee":"markdown","a9bf7f7b":"markdown","bc0b3aae":"markdown","6a3f4f8a":"markdown","3f5aa114":"markdown","be1725ce":"markdown","49deb94a":"markdown","02ada98f":"markdown","bf12b463":"markdown","3ebdc8ca":"markdown"},"source":{"7ef79ee3":"#IMPORTING LIBRARIES\nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","4dcea431":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","1700834b":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","c53e72c2":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","1482be51":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","a8b95dd7":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","d30900ac":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","c25bcf29":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","5cf95829":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","23e3bae7":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","c5a32f44":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","8420271a":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","a3e10f54":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","22fa3b89":"cnn.save('catdog_cnn_model.h5')","7cd770ae":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","4411a0a9":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","1c61664d":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')","39de7d10":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","de9bf03a":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')","1e3d949e":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","e6a9e762":"image.load_img('..\/input\/cat-11\/WhatsApp Image 2021-07-10 at 22.07.03.jpeg')","373534f6":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","51ad4ae1":"image.load_img('..\/input\/dog-12\/WhatsApp Image 2021-07-10 at 22.07.03 (3).jpeg')","6e30a53a":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","b0110706":"image.load_img('..\/input\/cat-13\/WhatsApp Image 2021-07-10 at 22.07.03 (1).jpeg')","28ba7a95":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","d75bd127":"image.load_img('..\/input\/dog-13\/WhatsApp Image 2021-07-10 at 22.07.03 (2).jpeg')","6e9a1821":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","3edd7fee":"# **PREDICTING VALUES**","a9bf7f7b":"**STEP - 2) APPLYING MAX POOLING**","bc0b3aae":"**STEP -3 ) FLATTENING**","6a3f4f8a":"**STEP - 4 ) FULL CONNECTION**","3f5aa114":"**0 MEANS CATS AND 1 MEANS DOGS**","be1725ce":"**CLASSIYING WHETHER THEIR IS A DOG OR A CAT IN A PICTURE USING CNN.**\n","49deb94a":"**IT'S A CAT**","02ada98f":"**IT'S A DOG**","bf12b463":"**STEP - 1) ADDING CONVOLUTIONAL LAYER**","3ebdc8ca":"# HERE CNN IS DIVIDED INTO 4 STEPS\n**1. CONVOLUTION**\n\n**2. POOLING**\n\n**3. FLATTENING**\n\n**4. FULL CONNECTION**"}}