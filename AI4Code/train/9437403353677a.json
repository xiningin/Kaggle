{"cell_type":{"fd16421f":"code","ac19fb9e":"code","895e9998":"code","d98cdc93":"code","47bd2c63":"code","695aaeea":"code","e7e01df5":"code","c07c15e6":"code","13e36b79":"code","c05ed15e":"code","a9998cb4":"code","82805f96":"code","5e5764e6":"code","b30a1fe6":"code","0bbe4e0c":"code","45da234f":"code","cda0a1d1":"code","cccad39a":"code","63cf0757":"code","06516b08":"code","d97c19cf":"code","b9701a6b":"code","ffee0c25":"code","5e6ff8cc":"code","3a112931":"code","013bba04":"markdown","f644adaa":"markdown","2b1a68d3":"markdown","2e9297c2":"markdown","e3ef7adc":"markdown","a35d27a4":"markdown","c9399da2":"markdown","bc42c45f":"markdown","2a3dd4c4":"markdown","591e9ea0":"markdown","f36a321c":"markdown","236a89d8":"markdown","65378cd9":"markdown","730dfcb1":"markdown","05a9173f":"markdown","140ece00":"markdown","2bc36317":"markdown","7274562d":"markdown","fb456045":"markdown","4b123a5f":"markdown","48c98a3f":"markdown","feb26aab":"markdown","a0b7ecbd":"markdown","8878409a":"markdown","87000a09":"markdown","d6510cfb":"markdown","771d84c4":"markdown","9025b051":"markdown","05627f1d":"markdown","d6af5e98":"markdown","7d8cb95d":"markdown","55f1d606":"markdown","d9e94e18":"markdown"},"source":{"fd16421f":"# Installed this library for this needed later to show model summary \n!pip install torchsummary","ac19fb9e":"import gc, os, cv2, PIL, torch\nimport torchvision as tv\nimport torch.nn as nn\nimport torchsummary as ts\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","895e9998":"labels_df = pd.read_csv('..\/input\/traffic-signs-classification\/labels.csv')\nlabels_df","d98cdc93":"%%time \n# %%time used to calculate total time taken to execute the cell\nx , y = [] , []  # X to store images and y to store respective labels  \ndata_dir = '..\/input\/traffic-signs-classification\/myData'\nfor folder in range(43):\n    folder_path = os.path.join(data_dir,str(folder)) # os.path.join just join both string \n    for i,img in enumerate(os.listdir(folder_path)):\n        img_path = os.path.join(folder_path,img)\n        # PIL load the image as PIL object and ToTensor() convert this to a Tensor\n        img_tensor = tv.transforms.ToTensor()(PIL.Image.open(img_path))\n        x.append(img_tensor.tolist()) # convert the tensor to list of list and append\n        y.append(folder)\n    print('folder of label',folder,'images loaded. Number of samples :',i+1)\nx = np.array(x)\ny = np.array(y)","47bd2c63":"# np.unique returns all the labels as one array and \n#number of samples available respect to that label as another array.\nnp.unique(y,return_counts=True)","695aaeea":"x = x.reshape(x.shape[0],3*32*32) # flatten x as RandomOverSampler only accepts 2-D matrix\n# RandomOverSampler method duplicates samples in the minority class to balance dataset\nx,y = RandomOverSampler().fit_resample(x,y)\nx = x.reshape(x.shape[0],3,32,32) # reshaped again as it was\nx.shape, y.shape","e7e01df5":"np.unique(y,return_counts=True)","c07c15e6":"# Stratified split on the dataset \nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,stratify=y)\ndel x,y\ngc.collect() # delete x,y and free the memory \nxtrain.shape, xtest.shape, ytrain.shape, ytest.shape # splited data shapes","13e36b79":"plt.figure(figsize=(20,20)) \n# make_grid creates a grid of 100 images and show it\nplt.imshow(tv.utils.make_grid(torch.tensor(xtrain[:100]),nrow=10).permute(1,2,0))\nplt.axis('off') # To remove xticks and yticks\nplt.show()\nprint('\\n\\nLabels of the above images :\\n')\nytrain[:100]","c05ed15e":"xtrain = torch.from_numpy(xtrain) \nytrain = torch.from_numpy(ytrain)\nxtest = torch.from_numpy(xtest)\nytest = torch.from_numpy(ytest)","a9998cb4":"model = nn.Sequential(\n                        # 1st convolutional network Layers\n                        nn.Conv2d(3,16,(2,2),(1,1),'same'),   # Convolution\n                        nn.BatchNorm2d(16),                   # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n    \n                        # 2nd convolutional network Layers\n                        nn.Conv2d(16,32,(2,2),(1,1),'same'),  # Convolution\n                        nn.BatchNorm2d(32),                  # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n    \n                        # 3rd convolutional network Layers\n                        nn.Conv2d(32,64,(2,2),(1,1),'same'), # Convolution\n                        nn.BatchNorm2d(64),                  # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n\n                        # Flatten Data\n                        nn.Flatten(),                        # Flatten\n    \n                        # feed forward Layers\n                        nn.Linear(1024,256),                  # Linear \n                        nn.ReLU(True),                       # Activation\n                        nn.Linear(256,43)                    # Linear \n                    )\n\n# Send model to Cuda Memory\nmodel = model.to(torch.device('cuda'),non_blocking=True)\n# For Model Summary\nts.summary(model,(3,32,32))","82805f96":"def evaluate(model, data, target):\n    # sending data and target to cuda memory\n    data = data.to(torch.device('cuda'),non_blocking=True)\n    target = target.to(torch.device('cuda'),non_blocking=True)\n    length = len(target)\n    yhat = model(data) # predict on data\n    ypred = yhat.argmax(axis=1) # claculate the prediction labels from yhat\n    loss = float(nn.functional.cross_entropy(yhat, target)) # calculate the loss\n    acc = float((ypred == target).sum() \/ length) # Calculate accuracy\n    print('Loss :',round(loss,4),'- Accuracy :',round(acc,4)) # Print loss and Accuracy\n    del data,target,yhat,ypred # delete the used variables\n    torch.cuda.empty_cache() # Free the Cuda memory","5e5764e6":"print('\\nInitial Loss and Accuracy on Test Dataset :')\nevaluate(model,xtest.float(),ytest)","b30a1fe6":"def train_model(model=model,optimizer=torch.optim.Adam,epochs=5,batch_size=200,steps_per_epochs=200,l2_reg=0,max_lr=0.01,grad_clip=0.5):\n    \n    hist = [[],[],[],[]] # hist will stores train and test data losses and accuracy of every epochs\n    \n    train_ds = [(x,y) for x,y in zip(xtrain,ytrain)] # Prepare training dataset for Data Loader\n    training_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size) # Data Loader used to train model \n    train_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size * steps_per_epochs) \n                                    # Data Loader for epoch end evaluation on train data\n    del train_ds \n    gc.collect() # Delete the used variable and free up memory\n    \n    # Initialized the Optimizer to update weights and bias of model parameters\n    optimizer = optimizer(model.parameters(),weight_decay=l2_reg)\n    \n    # Initialized the Schedular to update learning rate as per one cycle poicy  \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs, steps_per_epoch=int(steps_per_epochs * 1.01))\n        \n    # Training Started\n    for i in range(epochs):\n                 \n        print('\\nEpoch' , i+1 , ': [',end=\"\")\n        \n        # Load Batches of training data loader\n        for j,(xb,yb) in enumerate(training_dl):\n            \n            # move the training batch data to cuda memory for faster processing\n            xb = xb.to(torch.device('cuda'),non_blocking=True)\n            yb = yb.to(torch.device('cuda'),non_blocking=True)\n            \n            # Calculate Losses and gradients\n            yhat = model(xb.float())\n            loss = nn.functional.cross_entropy(yhat, yb)\n            loss.backward()\n            \n            # Clip the outlier like gradients\n            nn.utils.clip_grad_value_(model.parameters(),grad_clip)\n            \n            # Update Weights and bias\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Update Learning Rate\n            sched.step()\n            \n            del xb,yb,yhat\n            torch.cuda.empty_cache()\n            # delete the used data and free up space\n            \n            # print the training epochs progress\n            if j % int(steps_per_epochs \/ 20) == 0:\n                print('.',end='')\n                \n            # break the loop when all steps of an epoch completed. \n            if steps_per_epochs == j :\n                break\n                             \n           \n        # Epochs end evaluation \n        \n        device = torch.device('cuda') # initialized cuda to device\n        \n        # load training data batches from train data loader\n        for xtrainb,ytrainb in train_dl:\n            break\n        \n        # move train data to cuda\n        xtrain_cuda = xtrainb.to(device,non_blocking=True)\n        ytrain_cuda = ytrainb.to(device,non_blocking=True)\n        del xtrainb, ytrainb\n        gc.collect()\n        # delete used variables and free up space\n        \n        # Calculate train loss and accuracy\n        yhat = model(xtrain_cuda.float())\n        ypred = yhat.argmax(axis=1)\n        train_loss = float(nn.functional.cross_entropy(yhat, ytrain_cuda))\n        train_acc = float((ypred == ytrain_cuda).sum() \/ len(ytrain_cuda))\n        \n        del xtrain_cuda, ytrain_cuda, yhat, ypred\n        torch.cuda.empty_cache()\n        # delete used variables and free up space\n        \n        # move test data to cuda\n        xtest_cuda = xtest.to(device,non_blocking=True)\n        ytest_cuda = ytest.to(device,non_blocking=True)\n        \n        # Calculate test loss and accuracy\n        yhat = model(xtest_cuda.float())\n        ypred = yhat.argmax(axis=1)\n        val_loss = float(nn.functional.cross_entropy(yhat, ytest_cuda))\n        val_acc = float((ypred == ytest_cuda).sum() \/ len(ytest_cuda))\n        \n        del xtest_cuda, ytest_cuda, yhat, ypred\n        torch.cuda.empty_cache()\n        # delete used variables and free up space\n        \n        # print the captured train and test loss and accuracy at the end of every epochs\n        print('] - Train Loss :',round(train_loss,4),'- Train Accuracy :',round(train_acc,4),\n              '- Val Loss :',round(val_loss,4), '- Val Accuracy :',round(val_acc,4))\n        \n        # store that data into the previously blank initialized hist list \n        hist[0].append(train_loss)\n        hist[1].append(val_loss)\n        hist[2].append(train_acc)\n        hist[3].append(val_acc)\n        \n    # Initialized all the evaluation history of all epochs to a dict\n    history = {'Train Loss':hist[0],'Val Loss':hist[1],'Train Accuracy':hist[2], 'Val Accuracy':hist[3]}\n    \n    # return the history as pandas dataframe\n    return pd.DataFrame(history)","0bbe4e0c":"%%time\nhistory = train_model(model,optimizer=torch.optim.Adam,epochs=25,steps_per_epochs=200,l2_reg=0,max_lr=0.015,grad_clip=0.5)","45da234f":"history","cda0a1d1":"# used plotly for interactive plotting\nfig = px.line(history.iloc[:,:2],title='Loss Per Epochs',labels={'value':'Loss','index':'Epochs'})\nfig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show()\nfig = px.line(history.iloc[:,2:],title='Accuracy Per Epochs',labels={'value':'Accuracy','index':'Epochs'})\nfig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show() ","cccad39a":"# move to cuda \nxtest =  xtest.to(torch.device('cuda'),non_blocking=True)\n# generate predictions\nypred = model(xtest.float()).argmax(axis=1)\n# again move back xtest , ypred to cpu\nxtest = xtest.to(torch.device('cpu'),non_blocking=True)\nypred = ypred.to(torch.device('cpu'),non_blocking=True)\n# calculate the classification metrices and print result \nprint(classification_report(ytest,ypred))","63cf0757":"def prediction(img):\n    if type(img) == str:\n        # PIL load the image as PIL object and ToTensor() convert this to a Tensor\n        img = tv.transforms.ToTensor()(PIL.Image.open(img))\n    # resize image to 32X32 as model supports this\n    img = cv2.resize(img.permute(1,2,0).numpy(),(32,32))\n    img = torch.from_numpy(img).permute(2,0,1)\n    # unsqueezed img as inside a tensor and move to cuda\n    img_tensor = img.unsqueeze(0).to(torch.device('cuda'))\n    # Predict the label\n    pred = int(model(img_tensor).argmax(axis=1)[0])\n    # Find the traffic sign name for label from labels_df \n    # that initialize at the begining of the notebook\n    pred_str = labels_df[labels_df['ClassId'] == pred]['Name'][pred]\n    # Show the image using matplotlib\n    plt.figure(figsize=(5,5))\n    plt.imshow(cv2.resize(img.permute(1,2,0).numpy(),(1000,1000)))\n    plt.axis('off')\n    # Print traffic sign that recognized\n    print('\\nRecognized Traffic Sign :',pred_str,'\\n')","06516b08":"prediction('..\/input\/traffic-signs-classification\/myData\/17\/00000_00004.jpg')","d97c19cf":"prediction('..\/input\/traffic-signs-classification\/myData\/2\/00000_00017.jpg')","b9701a6b":"prediction('..\/input\/traffic-signs-classification\/myData\/29\/00000_00029.jpg')","ffee0c25":"prediction('..\/input\/traffic-signs-classification\/myData\/7\/00000_00025.jpg')","5e6ff8cc":"prediction('..\/input\/traffic-signs-classification\/myData\/14\/00000_00019.jpg')","3a112931":"torch.save(model,'traffic_sign_recognition.pt')","013bba04":"#### Install Libraries and APIs that are not available but required","f644adaa":"##### Example 3","2b1a68d3":"#### Define Train Model Function to train the model","2e9297c2":"#### Show 100 Images from train samples as a Grid using matplotlib","e3ef7adc":"#### Read the labels.csv file that contains metadata on traffic sign labels ","a35d27a4":"### Initialized the Neural Network Model \n![image.png](attachment:16dc970a-fdee-4e4f-9f8a-c7a52e45ffb4.png)","c9399da2":"<div align='center'><img src=\"https:\/\/i.ytimg.com\/vi\/U-SBY9eJ-xc\/maxresdefault.jpg\" width=900><\/div>","bc42c45f":"#### Save the Model","2a3dd4c4":"#### Model Classification Report on Test Data","591e9ea0":"#### Train the Model","f36a321c":"#### Some Examples of the above Prediction Function","236a89d8":"##### Example 5","65378cd9":"So as per the above result , the dataset is very imbalanced and needed to be balanced.\n\n##### Apply Over Sampling to balance the dataset","730dfcb1":"#### Import the dataset of Images along with the labels that are needed to train and test the model","05a9173f":"#### Import Libraries and APIs","140ece00":"#### Convert train and test data from numpy array to tensor for further computations","2bc36317":"# **Project Title : Traffic Sign Recognition System**\n\n##### **AIM :** To build and train a State of the art Neural Network model using Pytorch API that can recognize different Traffic Signs by just processing the images.\n\n","7274562d":"## Introduction\nIn recent years, the technology world is eagerly moving towards Artificial intelligence (AI). AI has many applications and one of these applications is autonomous or driverless vehicles. With the enhanced technology, multinational companies like Google, Tesla, Uber, Ford, Audi, Toyota, Mercedes-Benz, and many more are working on automating vehicles. There are so many algorithms to automate vehicles and too much research happens on daily basis. But before we think about these self-driving cars, we must wonder about how these cars automatically recognized objects like other cars, humans, animals, roads, and also the traffic signs on the roadsides like turn left or right, speed limits, no passing of heavy vehicles, no entry, children crossing, etc. and take the necessary step accordingly. Well, to recognize these objects like different traffic signs, we can develop an AI that is capable to do this kind of task. <br>\nThrough this project, we will develop that AI which is a Traffic Sign Recognition Neural Network Model. This model will take images of the traffic symbols and returns the recognized labels of that traffic sign. The model will be a Convolutional Neural Network model that is designed and trained totally using Pytorch Library. \n##### Why CNN?\nIn machine learning, Convolutional Neural Networks (CNN or Conv2D) are complex neural networks. CNNs are used for image classification and recognition because of its high accuracy. \n##### Why Pytorch?\nPyTorch is an optimized tensor processing library primarily used for Deep Learning applications using GPUs and CPUs. It is an open-source machine learning library for Python, mainly developed by the Facebook AI Research team. It is one of the widely used Machine learning libraries, like TensorFlow and Keras.","fb456045":"#### Visualize the Training History","4b123a5f":"#### Evaluate the Model on test data before training","48c98a3f":"So now the dataset is balanced. Now split the dataset for training and testing \n\n#### Split dataset for training and testing","feb26aab":"##### Check - dataset is balanced or not","a0b7ecbd":"##### Check again - dataset is balanced or not","8878409a":"#### Model History","87000a09":"##### Example 4","d6510cfb":"##### Example 2","771d84c4":"##### Example 1","9025b051":"# <center>**Thank You**","05627f1d":"#### Handling Imbalanced Dataset","d6af5e98":"### Conclusion and Summerization \n\nThrough this entire project, we have build and trained a Convolution Neural Network Model that can recognized traffic signs by processing the images that contains traffic signs. <br>  \nThe architecture of this model : <br>\n3 Convolution layers of 16,32 and 64 number of output channels respectively along with Batch Normalization, Relu Activation and Max Pooling.\nThen a flatten layer to flatten the output of last layer into 2-D and apply 2 linear layers with a Relu at the middle where 256 and 43 are the output size respectively. <br><br>\nThe complete notebook from begining to end follows a Pipeline like import libraries, load dataset, balanced the dataset, split dataset for training and testing, showed 100 of training images as grid, create the model, evaluate the model before training ( to just compare from where to where model improved ), created a train_model function and trained the model with 25 epochs and 200 steps per epochs that takes only 2 - 3 minutes with almost 100% test accuracy. \nIn this model training , we also used learning rate one cycle policy scheduling technique to update the learning rate and gradient cliping to limit gradient values.<br>\nAfter the model training, visualize the training history, show the classification report and lastly create a prediction function and predict on some random choosed images.","7d8cb95d":"#### Define the Evaluate Function for model loss and accuracy evaluation and Train Model Function to train the model","55f1d606":">","d9e94e18":"#### Create the Prediction Function"}}