{"cell_type":{"ef1a8eab":"code","7719b714":"code","8f7b315e":"code","3380714f":"code","a9aae983":"code","82df2b75":"code","519f387c":"code","a25ff7f7":"code","6f40b7cd":"code","b21bf7b5":"code","9a2e0c3a":"code","eeceb22a":"code","ab890373":"code","03b37cf7":"code","3f0905e2":"code","6c4211e1":"code","ef1a6762":"code","f6a470c9":"code","0353d287":"code","0578c0e5":"code","e61a771a":"code","e333a62b":"code","b9658e0d":"code","174aa08f":"code","46a423aa":"code","ca6378ce":"code","47e75c6f":"code","ee5e9add":"code","10f8df5e":"code","bddcb1aa":"code","33c32637":"code","2a48dffa":"code","22f7c22c":"code","ad8fe806":"code","5f8cd152":"code","67f9e5da":"code","6c1592d6":"code","28e8d989":"code","d7bc26e4":"code","cbb1be84":"code","4db58f21":"code","0da46615":"code","086bb9bd":"code","d36468a3":"code","912dbd55":"code","0e01f0bb":"code","465a0af1":"code","37d7464c":"code","fb84520c":"code","79929dad":"markdown","78f0ec09":"markdown","658ec99c":"markdown","50d801b0":"markdown","bb1c70c3":"markdown","353e45e1":"markdown","a4dc9079":"markdown","ade02c1e":"markdown","4440bd02":"markdown","8af89100":"markdown","30060c51":"markdown","a3f4af7c":"markdown","2bbcdf06":"markdown","e1673856":"markdown","a2b2619f":"markdown","eb6db7b9":"markdown","732d0cb1":"markdown","67f21103":"markdown","6b387b46":"markdown","8695bafa":"markdown","3bc52317":"markdown","472f3e07":"markdown"},"source":{"ef1a8eab":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport nltk\nimport re\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nnltk.download('wordnet')","7719b714":"df= pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","8f7b315e":"df.head()","3380714f":"df.info()","a9aae983":"df.shape","82df2b75":"df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['red','green'])","519f387c":"df['Total_words']=[len(x.split())for  x in df['review']]","a25ff7f7":"df","6f40b7cd":"df['word_counts']= df['review'].apply(lambda x: len(x.split(' ') ))","b21bf7b5":"df.head()","9a2e0c3a":"df['character_count'] = [len(x) for x in df['review']]","eeceb22a":"df.head()","ab890373":"df['character_count2'] = [len(''.join(x.split())) for x in df['review']]","03b37cf7":"#Using Lambda function","3f0905e2":"df['character_count3']= df['review'].apply(lambda x: len(''.join(x.split()) ))","6c4211e1":"df.head()","ef1a6762":"df['Upper_Case'] = df['review'].apply( lambda x : len([x for x in x.split() if x.isupper()]))","f6a470c9":"df.head()","0353d287":"df['Lower_Case'] = df['review'].apply( lambda x : len([x for x in x.split() if x.islower()]))","0578c0e5":"df.head()","e61a771a":"df['Digit_count'] = df['review'].apply( lambda x : len([x for x in x.split() if x.isdigit()]))","e333a62b":"df.head()","b9658e0d":"df['average_word'] = df['character_count2']\/df['word_counts']","174aa08f":"df.head()","46a423aa":"from nltk.corpus import stopwords\nstop=stopwords.words('english')\ndf['stopwords'] = df['review'].apply(lambda x: len([x for x in x.split() if x in stop]))","ca6378ce":"df.head()","47e75c6f":"df['review'] = df['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))","ee5e9add":"df.head()","10f8df5e":"def remove_special_characters(text, remove_digits=True):\n    pattern=r'[^a-zA-Z0-9]'\n    text=re.sub(pattern,' ',text)\n    return text\n#Apply function on review column\ndf['review']=df['review'].apply(remove_special_characters)","bddcb1aa":"df['review'] = df['review'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop))","33c32637":"from nltk.stem import WordNetLemmatizer\n\nlmtzr = WordNetLemmatizer()\n\ndf['review'] = df['review'].apply(lambda x: \" \".join(lmtzr.lemmatize(x) for x in x.split()))\n\ndf['review'].head()","2a48dffa":"df.head()","22f7c22c":"all_Words=[x for x in pd.Series(' '.join(df['review']).split())] ","ad8fe806":"nltk.FreqDist(all_Words).most_common(10)","5f8cd152":"freq = pd.Series(' '.join(df['review']).split()).value_counts()[:50]\nfreq","67f9e5da":"freq =['br','movie','film','one','get','would','make','see','much','first','way','could','go','know','two','like','even','say','ever','little','go','way','know','also','seem']","6c1592d6":"df['review'] = df['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\ndf['review'].head()","28e8d989":"from wordcloud import WordCloud,STOPWORDS\nnew_df=df[df['sentiment']=='negative']\nwords = ' '.join(new_df['review'])\n\nwordcloud = WordCloud(stopwords=stop,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(words)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","d7bc26e4":"from wordcloud import WordCloud,STOPWORDS\nnew_df=df[df['sentiment']=='positive']\nwords = ' '.join(new_df['review'])\n\nwordcloud = WordCloud(stopwords=stop,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(words)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","cbb1be84":"processed_features = df.iloc[:,0].values\nlabels = df.iloc[:, 1].values","4db58f21":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer (max_features=2500, min_df = 100, max_df = 1000)#(min_df = 0.2,max_df = 0.8)\nprocessed_features = vectorizer.fit_transform(processed_features).toarray() ","0da46615":"processed_features","086bb9bd":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)","d36468a3":"from sklearn.tree import DecisionTreeClassifier\nDT_model = DecisionTreeClassifier()\nDT_model.fit(X_train, y_train)","912dbd55":"## Performance Matrix on train data set\nfrom sklearn import metrics\ny_train_predict = DT_model.predict(X_train)\nmodel_score = DT_model.score(X_train, y_train)\nprint(model_score)\nprint(metrics.confusion_matrix(y_train, y_train_predict))\nprint(metrics.classification_report(y_train, y_train_predict))","0e01f0bb":"## Performance Matrix on test data set\ny_test_predict = DT_model.predict(X_test)\nmodel_score = DT_model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_test_predict))\nprint(metrics.classification_report(y_test, y_test_predict))","465a0af1":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nLDA_model= LinearDiscriminantAnalysis()\nLDA_model.fit(X_train, y_train)","37d7464c":"## Performance Matrix on train data set\ny_train_predict = LDA_model.predict(X_train)\nmodel_score = LDA_model.score(X_train, y_train)\nprint(model_score)\nprint(metrics.confusion_matrix(y_train, y_train_predict))\nprint(metrics.classification_report(y_train, y_train_predict))","fb84520c":"## Performance Matrix on test data set\ny_test_predict = LDA_model.predict(X_test)\nmodel_score = LDA_model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_test_predict))\nprint(metrics.classification_report(y_test, y_test_predict))","79929dad":"#### Removal of StopWords","78f0ec09":"### Looking at the distribution of Sentiment","658ec99c":"#### Stemming the text","50d801b0":"#### Conting the Upper case words","bb1c70c3":"### Word CLoud","353e45e1":"#### Define function for removing special characters","a4dc9079":"### TF-IDF","ade02c1e":"#### Lower Case conversion","4440bd02":"#### Using lambda function","8af89100":"#### Bag of Words","30060c51":"#### character count excluding spaces","a3f4af7c":"#### Number of stop Words","2bbcdf06":"### Linear DIscriminant Analysis","e1673856":"#### Number of numerics:","a2b2619f":"### Decision Tree Classifier","eb6db7b9":"#### Basic Pre-Processing","732d0cb1":"### Pre Processing","67f21103":"### Extracting the Data","6b387b46":"#### Average word count","8695bafa":"#### Total Word Counts in each sentiment","3bc52317":"#### Conting the Upper case words","472f3e07":"#### Character count including spaces"}}