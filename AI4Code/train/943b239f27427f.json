{"cell_type":{"f884c2be":"code","0d500f2b":"code","f63d4e0c":"code","fa822670":"code","ee0019e8":"code","a111c8d6":"code","8399f19c":"code","2d525348":"code","a42b0634":"code","e2f299ed":"code","6be4076a":"code","e0c9e45e":"code","87ae7404":"code","e6f945ee":"code","97bb3457":"code","6b68fbf3":"code","7e683697":"code","008ca43e":"code","e500674c":"code","0b7bc7a1":"code","9372c1a6":"code","568f0a57":"code","790aa757":"code","dcb13eb8":"code","f11222c4":"code","3c03eead":"code","e081eb51":"code","d955b707":"code","50709561":"code","f1b7c808":"code","a1bbdb47":"code","b1cf50a5":"code","7060383b":"code","e4d6b3a9":"code","fbd64057":"code","229d50a8":"code","1653b177":"code","35d8c4d7":"code","57985a17":"code","56b417df":"code","28be708e":"code","8b1c67a2":"code","43c3a1a0":"code","bb7aa641":"markdown","bdf266a0":"markdown","ac6fe143":"markdown","b7fdabf5":"markdown","cd833d6b":"markdown","f4ee4906":"markdown"},"source":{"f884c2be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d500f2b":"data = pd.read_csv(\"\/kaggle\/input\/mrf-stock-price-history\/MRF.NS.csv\")","f63d4e0c":"data.head()","fa822670":"from pandas_profiling import ProfileReport","ee0019e8":"report = ProfileReport(data)","a111c8d6":"report","8399f19c":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\nimport plotly.express as px \n\nimport warnings\nwarnings.filterwarnings('ignore')","2d525348":"data = data.set_index('Date')\ndata.tail()","a42b0634":"data.describe()","e2f299ed":"data.info()","6be4076a":"# Let's see a historical view of the closing price\n\nplt.figure(figsize=(15, 6))\n\ndata['Adj Close'].plot()\nplt.ylabel('Adj Close')\nplt.xlabel(None)\nplt.title(f\"Closing Price of MRF\")\n\nplt.tight_layout()","e0c9e45e":"# Now let's plot the total volume of stock being traded each day\nplt.figure(figsize=(15, 7))\n\ndata['Volume'].plot()\nplt.ylabel('Volume')\nplt.xlabel(None)\nplt.title(f\"Sales Volume for MRF\")\n\nplt.tight_layout()","87ae7404":"ma_day = [10, 20, 50]\n\nfor ma in ma_day:\n    column_name = f\"MA for {ma} days\"\n    data[column_name] = data['Adj Close'].rolling(ma).mean()","e6f945ee":"plt.rcParams[\"figure.figsize\"] = (15,8)\n\ndata[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot()\nplt.title('MRF')","97bb3457":"# We'll use pct_change to find the percent change for each day\n\ndata['Daily Return'] = data['Adj Close'].pct_change()","6b68fbf3":"plt.rcParams[\"figure.figsize\"] = (15,8)\n\ndata['Daily Return'].plot(legend=True, linestyle='--', marker='o')\nplt.title(f'MRF')","7e683697":"sns.displot(data['Daily Return'].dropna(), bins=50, color='purple')\nplt.ylabel('Daily Return')\nplt.title(\"MRF\")\n\nplt.tight_layout()","008ca43e":"fig = px.line(data, x=data.index, y=\"Close\", title='Close Price Rupee')\nfig.show()","e500674c":"# Create a new dataframe with only the 'Close column \ndata_close = data.filter(['Close'])\n\n# Convert the dataframe to a numpy array\ndataset = data_close.values\n\n# Get the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * .90 ))\n\ntraining_data_len","0b7bc7a1":"# Scale the data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","9372c1a6":"#create the training dataset\n#create the scaled training dataset\n\ntrain_data = scaled_data[0:training_data_len, :]\n#Split the data into x_train, y_train datasets\nx_train = []\ny_train = []\nfor i in range(60,len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i,0])\n    if i<=60:\n        print(x_train)\n        print(y_train)\n        print()","568f0a57":"#convert the x_train and y_train  to numppy array\nx_train,y_train = np.array(x_train), np.array(y_train)","790aa757":"#reshape the data\nx_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\nx_train.shape","dcb13eb8":"#Buil the LSTM model\nmodel =Sequential()\nmodel.add(LSTM(64,return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(LSTM(64, return_sequences= False))\nmodel.add(Dense(32))\nmodel.add(Dense(1))","f11222c4":"#Complie the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')","3c03eead":"#Train the model\nmodel.fit(x_train,y_train, batch_size=1, epochs=10)","e081eb51":"#create the testing data sets\n#create a new array containing scale values from index 1543 to 2003\ntest_data= scaled_data[training_data_len-60:, :]\n\n#create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:,:]\nfor i in range(60,len(test_data)):\n    x_test.append(test_data[i-60:i,0])","d955b707":"#convert the data to a numpy array\nx_test = np.array(x_test)","50709561":"#reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\nx_test.shape","f1b7c808":"#predicting the data\npredictions = model.predict(x_test)","a1bbdb47":"predictions = scaler.inverse_transform(predictions)","b1cf50a5":"from fbprophet import Prophet","7060383b":"data.reset_index(inplace=True)","e4d6b3a9":"data[\"Date\"] = pd.to_datetime(data[\"Date\"], infer_datetime_format=True)","fbd64057":"prophet_df = data.iloc[:,[0,1]]\nprophet_df.head()","229d50a8":"prophet_df = prophet_df.rename(columns={'Date':'ds', 'Open':'y'})\nprophet_df.tail(10)","1653b177":"prophet_df.dtypes","35d8c4d7":"# Create Model\nmodel = Prophet()\nmodel.fit(prophet_df)","57985a17":"# Forcasting into the future\nfuture = model.make_future_dataframe(periods=730)\nfuture.tail(10)","56b417df":"forecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","28be708e":"# You can plot the forecast\nfigure1 = model.plot(forecast, xlabel='Date', ylabel='Price')","8b1c67a2":"# If you want to see the forecast components\nfigure2 = model.plot_components(forecast)","43c3a1a0":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(model, forecast)  # This returns a plotly Figure\npy.iplot(fig)","bb7aa641":"Now that we've seen the visualizations for the closing price and the volume traded each day, let's go ahead and caculate the moving average for the stock.","bdf266a0":"Using **Facebook Prophet**","ac6fe143":"**Import Libraries**","b7fdabf5":"Don't forget to upvote if you like the work","cd833d6b":"# Predicting the closing price","f4ee4906":"In this notebook we will be looking at data from the stock market, particularly MRF Stock. We will learn how to use pandas to get stock information, visualize different aspects of it, and finally we will look at a few ways of analyzing the risk of a stock, based on its previous performance history. We will also be predicting future stock prices through a Long Short Term Memory (LSTM) method!"}}