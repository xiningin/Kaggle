{"cell_type":{"84c5b7ef":"code","37f06810":"code","9c543fc5":"code","9a68351e":"code","1328064f":"code","fd26f2c9":"code","7981269c":"code","b878ca4a":"code","2105461e":"code","4ef96e0f":"code","51a2b0ed":"code","1904f5d9":"code","991ed15d":"code","57c6df78":"code","7157feb9":"code","4b302be0":"code","8dbe6b24":"code","23a8156f":"code","aab3d6eb":"code","fcc9fb23":"code","64e5d1b0":"code","5c913c03":"code","986b26fd":"code","e2162e47":"code","396b1060":"code","edb74324":"code","620d76cb":"code","3942ba98":"code","0c7f4f4a":"code","0de2b8be":"markdown","42c145bc":"markdown","1327f4bc":"markdown","0e7b6ad9":"markdown","c9b16aa9":"markdown","e89188c2":"markdown","94381313":"markdown","a6346953":"markdown","15e00b2b":"markdown","2ec254c4":"markdown","c6c4f84c":"markdown","a1b8e42b":"markdown"},"source":{"84c5b7ef":"import pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler\npd.set_option('display.max_columns',None)","37f06810":"data = pd.read_csv('\/kaggle\/input\/automobile-dataset\/Automobile_data.csv',na_values=['?'])\ndata","9c543fc5":"data.info()","9a68351e":"nulls = data.columns[data.isnull().all()]\nnulls","1328064f":"(data == data.iloc[0]).all()","fd26f2c9":"# categorical features\ncat_features = [feat for feat in data.columns if data[feat].dtype == 'object']\ncat_features","7981269c":"#discrete features\ndiscrete_features = [feat for feat in data.columns if len(data[feat].unique())<10 and feat not in cat_features]\ndiscrete_features","b878ca4a":"#continuous features\ncon_features = [feat for feat in data.columns if feat not in discrete_features and feat not in cat_features]\ncon_features","2105461e":"#filling categorical features with first most frequently occuring value\nfor feat in cat_features:\n    data[feat].fillna(data[feat].mode()[0],inplace=True)\ndata.info()","4ef96e0f":"for feat in con_features:\n    plt.hist(data[feat])\n    plt.title(feat)\n    plt.show()","51a2b0ed":"#filling continuous features with mean the the column \nfor feat in con_features:\n    data[feat].fillna(data[feat].mean(),inplace=True)\ndata.info()","1904f5d9":"for feat in cat_features:\n    print(feat,'\\n',data[feat].unique(),'\\n')","991ed15d":"data['make'] = data['make'].map(data['make'].value_counts().to_dict())\ndata['fuel-system'] = data['fuel-system'].map(data['fuel-system'].value_counts().to_dict())\ndata.head()","57c6df78":"label = LabelEncoder()\ndata[['num-of-doors','num-of-cylinders']] = data[['num-of-doors','num-of-cylinders']].apply(label.fit_transform)\ndata","7157feb9":"data = pd.get_dummies(data,drop_first=True)\ndata","4b302be0":"# changing the distributon of continuous features to log normal distribution\nfor feat in con_features:\n    data[feat] = np.log(data[feat]+1)","8dbe6b24":"sns.heatmap(data.corr())","23a8156f":"label = data['price']\ndata.drop('price',inplace=True,axis=1)\ncolnames=data.columns","aab3d6eb":"scaler=StandardScaler()\nscaler.fit(data)\ndata = scaler.transform(data)","fcc9fb23":"X_train,X_test,y_train,y_test=train_test_split(data,label,test_size=0.2)\n\nclf=svm.SVR()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint('svm', acc)\n\nclf=LinearRegression()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint('linear regression', acc)\n\nclf=Ridge()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint('ridge regression', acc)\n\n\n\n","64e5d1b0":"X_train = pd.DataFrame(X_train)\nX_train.columns = colnames\nX_test = pd.DataFrame(X_test)\nX_test.columns = colnames","5c913c03":"feature_sel_model = SelectFromModel(Lasso(alpha=0.006, random_state=0)) # remember to set the seed, the random state in this function\nfeature_sel_model.fit(X_train, y_train)","986b26fd":"feature_sel_model.get_support()","e2162e47":"# this is how we can make a list of the selected features\nselected_feat = X_train.columns[feature_sel_model.get_support()]\n\nX_train = X_train[selected_feat]\nX_test = X_test[selected_feat]","396b1060":"print(X_train.shape)\nX_train.head()","edb74324":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","620d76cb":"clf=svm.SVR()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint(acc)","3942ba98":"clf=LinearRegression()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint(acc)","0c7f4f4a":"clf=Ridge()\nclf.fit(X_train,y_train)\nacc=clf.score(X_test,y_test)\nprint(acc)","0de2b8be":"## Encoding","42c145bc":"Check for the columns which havve all null values","1327f4bc":"We can do frequency encoding for fuel system and make columns. As they are nominal features and have too many categories. \nIf we do one hot encoding it will increase the dimensions a lot.","0e7b6ad9":"Try different alpha values for feature selection. For this problem 0.006 gave a good accuracy.","c9b16aa9":"Linear Regression","e89188c2":"Ridge Regression","94381313":"Support Vector Regression","a6346953":"#  Filling Null Values","15e00b2b":"For ordinal features we will be doing label encoding.\n\nWe can explicitly define a dictionary for each column and use map function or we can use LabelEncoder class.","2ec254c4":"For other nominal features we will be doing one hot encoding. One hot encoding can be done using pd.got_dummies function and OneHotEncoder class.","c6c4f84c":"Check for columns which have same records","a1b8e42b":"## Feature Selection"}}