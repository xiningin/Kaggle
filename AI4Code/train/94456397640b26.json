{"cell_type":{"ce8dcc2c":"code","0bf2d9ca":"code","064a1be1":"code","aa1bffa7":"code","31265888":"code","e3ce2584":"code","e93b4be3":"code","a271d9c2":"code","af9ac9cb":"code","c5016fd2":"code","39cf0350":"code","fd73be3b":"code","e4bb1069":"code","8bdefc05":"code","12d5aa12":"code","438bd3ad":"code","6a60fd01":"code","5cdb6730":"code","5e179742":"code","7a29206b":"code","48cd62bd":"code","36fc357e":"code","fc4d83d6":"code","7a1150ee":"code","09b04923":"code","d56eb6e8":"code","504fdbcc":"code","8b809215":"code","9786a3b4":"code","f8ed2e1d":"code","9618567c":"code","909a1ab2":"code","b4b200aa":"code","17ad54c0":"markdown","6ee40416":"markdown","4d0002cd":"markdown","856c68fa":"markdown","43a5bd8a":"markdown","d3cf0a9e":"markdown","120c06b0":"markdown","ca06e7da":"markdown","9b085d92":"markdown","cc0e385a":"markdown","7363f8f7":"markdown","ccd506a3":"markdown","6cc47856":"markdown","82346cb6":"markdown","fd302d7d":"markdown","df93ba60":"markdown","10f3beb0":"markdown","d7e99493":"markdown","897ced67":"markdown","3dc43afc":"markdown","52c0af26":"markdown","5ad66ca2":"markdown","8b893454":"markdown","66b091c3":"markdown","f92faa83":"markdown","f3434284":"markdown","f3a40932":"markdown","f86e74bb":"markdown","ba37a8df":"markdown","1ef9bfd0":"markdown","0f0b606f":"markdown","6ec310ed":"markdown","d8afbdfe":"markdown","56f1c98a":"markdown","a7639562":"markdown","4c48376a":"markdown","aee13d7f":"markdown","be8106ed":"markdown"},"source":{"ce8dcc2c":"!pip install etna==1.3.3 --ignore-installed -q 2> \/dev\/null","0bf2d9ca":"import pathlib\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom IPython.display import display\n\n\nsns.set(font_scale=1.3)","064a1be1":"DATA_PREFIX = pathlib.PurePath(\"\/kaggle\/input\/store-sales-time-series-forecasting\")\nHORIZON = 16\nNUM_DAYS_TRAIN = 200","aa1bffa7":"train = pd.read_csv(\n    DATA_PREFIX.joinpath(\"train.csv\"), \n    parse_dates=[\"date\"], \n    infer_datetime_format=True,\n)\ntrain.head()","31265888":"test = pd.read_csv(\n    DATA_PREFIX.joinpath(\"test.csv\"), \n    parse_dates=[\"date\"], \n    infer_datetime_format=True,\n)\ntest.head()","e3ce2584":"stores = pd.read_csv(DATA_PREFIX.joinpath(\"stores.csv\"))\nstores.head()","e93b4be3":"transactions = pd.read_csv(DATA_PREFIX.joinpath(\"transactions.csv\"))\ntransactions.head()","a271d9c2":"start_date = train[\"date\"].max() - pd.Timedelta(NUM_DAYS_TRAIN, \"D\")","af9ac9cb":"def prepare_df(df, start_date=None, num_segments=None):\n    df = df.drop(columns=[\"onpromotion\", \"id\"])\n    df[\"segment\"] = [f\"{x}::{y}\" for x, y in zip(df[\"store_nbr\"], df[\"family\"])]\n    df.rename(columns={\n        \"date\": \"timestamp\", \n        \"sales\": \"target\", \n    }, inplace=True)\n    \n    if start_date is not None:\n        df = df[df[\"timestamp\"] >= start_date]\n        \n    if num_segments is not None:\n        segments = df[\"segment\"].unique()[:num_segments]\n        df = df[df[\"segment\"].isin(segments)]\n    \n    df = df[[\"timestamp\", \"segment\", \"target\"]]\n    df[\"target\"] = np.log1p(df[\"target\"])\n    \n    start_date = df[\"timestamp\"].min()\n    end_date = df[\"timestamp\"].max() + pd.Timedelta(HORIZON, \"D\")\n    timestamp = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n    df_exog_list = []\n    df_exog_segment_template = pd.DataFrame({\"timestamp\": timestamp})\n    for segment in tqdm(df[\"segment\"].unique()):\n        df_exog_segment = df_exog_segment_template.copy()\n        df_exog_segment[\"segment\"] = segment\n        df_exog_segment[\"regressor_store_nbr\"] = segment.split(\"::\")[0]\n        df_exog_segment[\"regressor_family\"] = segment.split(\"::\")[1]\n        df_exog_list.append(df_exog_segment)\n    \n    df_exog = pd.concat(df_exog_list, ignore_index=True)\n    df_exog[\"regressor_store_nbr\"] = df_exog[\"regressor_store_nbr\"].astype(\"category\")\n    df_exog[\"regressor_family\"] = df_exog[\"regressor_family\"].astype(\"category\")\n    \n    return df, df_exog","c5016fd2":"train, train_exog = prepare_df(train, start_date=start_date)","39cf0350":"train.head()","fd73be3b":"train_exog.head()","e4bb1069":"from etna.datasets import TSDataset\n\nts = TSDataset(\n    df=TSDataset.to_dataset(train), \n    df_exog=TSDataset.to_dataset(train_exog), \n    freq=\"D\"\n)","8bdefc05":"ts.segments[:10]","12d5aa12":"ts.regressors","438bd3ad":"ts.plot(segments=[\"10::DAIRY\", \"8::BOOKS\", \"6::CLEANING\", \"4::MEATS\"])","6a60fd01":"from etna.transforms import LagTransform, DateFlagsTransform, SegmentEncoderTransform\n\nnum_lags = 10\n\ntransforms = [\n    SegmentEncoderTransform(),\n    LagTransform(in_column=\"target\", lags=[HORIZON + i for i in range(num_lags)]),\n    DateFlagsTransform(day_number_in_week=True, day_number_in_month=True, is_weekend=True),\n]","5cdb6730":"from etna.models import CatBoostModelMultiSegment\nfrom etna.pipeline import Pipeline\nfrom etna.metrics import MSE\n\nmodel = CatBoostModelMultiSegment(logging_level=\"Silent\")\npipeline = Pipeline(model=model, horizon=HORIZON, transforms=transforms)","5e179742":"metrics_df, forecast_df, fold_info_df = pipeline.backtest(\n    ts=ts, metrics=[MSE()], n_folds=3\n)","7a29206b":"metrics_df.head()","48cd62bd":"metric = metrics_df[\"MSE\"].mean()**(1\/2)\nprint(f\"RMSLE: {metric:.4f}\")","36fc357e":"from etna.loggers import tslogger, ConsoleLogger\n\ntslogger.add(ConsoleLogger())","fc4d83d6":"tslogger.log(\"Hello\")","7a1150ee":"num_lags = 10\n\ntransforms = [\n    SegmentEncoderTransform(),\n    LagTransform(in_column=\"target\", lags=[HORIZON + i for i in range(num_lags)]),\n    DateFlagsTransform(day_number_in_week=True, day_number_in_month=True, is_weekend=True),\n]","09b04923":"model = CatBoostModelMultiSegment(logging_level=\"Silent\")\npipeline = Pipeline(model=model, horizon=HORIZON, transforms=transforms)","d56eb6e8":"pipeline.fit(ts=ts)","504fdbcc":"forecasted = pipeline.forecast()","8b809215":"sample_submission = pd.read_csv(DATA_PREFIX.joinpath(\"sample_submission.csv\"))\nsample_submission.head()","9786a3b4":"test.head()","f8ed2e1d":"forecasted_target = forecasted[:, :, \"target\"]\n\nsales = sample_submission[\"sales\"].copy()\nfor i, row in tqdm(test.iterrows(), total=test.shape[0]):\n    date = row[\"date\"]\n    segment = f\"{row['store_nbr']}::{row['family']}\"\n    try:\n        target = forecasted_target.loc[date, segment].item()\n        sales.iloc[i] = target\n    except IndexError:\n        pass","9618567c":"sales.describe()","909a1ab2":"sample_submission[\"sales\"] = np.expm1(np.maximum(sales, 0))","b4b200aa":"sample_submission.to_csv(\"submission.csv\", index=False)","17ad54c0":"This section is dedicated to validation different model with different parameters.","6ee40416":"![backtest.png](attachment:backtest.png)","4d0002cd":"Here let's create some transforms to the dataset:\n1. `SegmentEncoderTransform`: makes regressors out of segments.\n2. `LagTransform`: creates lag features. Our model won't use lags less than `HORIZON` to make forecasting in regression fashion.\n3. `DateFlagsTransform`: creates features related to datetime.","856c68fa":"<a href=\"https:\/\/github.com\/tinkoff-ai\/etna\">\n    <img src=\"https:\/\/img.shields.io\/badge\/GitHub-100000?style=for-the-badge&logo=github&logoColor=white\"  align='left'>\n<\/a>","43a5bd8a":"We are going to use `Pipeline` here as well.","d3cf0a9e":"In this competition there are segments on test, that are absent on train. We are going to predict these segments as 0.","120c06b0":"## Selecting transformers","ca06e7da":"Finally, make a forecast.","9b085d92":"## Fitting the model","cc0e385a":"We can modify it to get metric used in competition.","7363f8f7":"We can look at all segments in dataset.","ccd506a3":"Let's create a `Pipeline`. It takes in a model, horizon and list of transforms. We are going to use a `CatBoostModelMultiSegment`: CatBoost regression model that fits on all segments simultaneously.","6cc47856":"In this notebook we will make predictions for [Store Sales - Time Series Forecasting competition](https:\/\/www.kaggle.com\/c\/store-sales-time-series-forecasting) with [etna time series library](https:\/\/github.com\/tinkoff-ai\/etna\/).","82346cb6":"Let's load all relevant datasets.","fd302d7d":"As a result, we have a validation procedure to adjust our hyperparameters. A custom script with [Optuna](https:\/\/optuna.org\/) can be written to do this.","df93ba60":"Get list of all regressors.","10f3beb0":"Let's make some processing:\n1. Drop `id` and `onpromotion`, because they seem to be not very useful.\n2. Create such column as `segment`. It indicates different time series within dataset. In our case segment is determined by store and family of product.\n3. Rename columns. Library requires that column with time should be named as `timestamp` and column with variable to predict as `target`.\n4. Apply `np.log1p` function to `target`, because we calculate metric based on them.\n4. Create regressors. These are exogenous factors that will be known in future. In our case it is `store_nbr` and `family`.","d7e99493":"To work with etna library we should create a `TSDataset`. This is a special structure that holds many time series.","897ced67":"Now let's create an instance of `TSDataset`.","3dc43afc":"# Dataset","52c0af26":"We are going to use not all data, but only last `NUM_DAYS_TRAIN` days.","5ad66ca2":"# Training","8b893454":"## Backtest","66b091c3":"## Creating `TSDataset`","f92faa83":"Visualize some segments.","f3434284":"The submission can be sent now.","f3a40932":"# Submission","f86e74bb":"Save selected transforms.","ba37a8df":"In this section we will construct the submission.","1ef9bfd0":"In this section we will work with competition datasets.","0f0b606f":"## Loading data","6ec310ed":"First, let's create a logger object to monitor the process.","d8afbdfe":"We are going to run a backtest. This is a special cross validation for time series that takes into account ordering by timestamp. The base idea is simple: don't validate on the past.\n\nIn our backtest each split's size is equal to the horizon and we validate on the latest `n_folds` splits. You can take or not take the whole history depending on `mode` parameter.","56f1c98a":"# Store sales prediction with `etna` libarary \ud83c\udf0b","a7639562":"If you want to know more about the etna library welcome to [our github page](https:\/\/github.com\/tinkoff-ai\/etna) there you can see examples and link to documentation.","4c48376a":"# Validation","aee13d7f":"As se can see, there are some abnormal values less than zero. Let's get rid of this and apply inverse transformation to our target.","be8106ed":"We are interested only in `metrics_df`, it contains metric for each segment and each fold."}}