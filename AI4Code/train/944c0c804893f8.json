{"cell_type":{"f2f262ac":"code","af6a2040":"code","ded21963":"code","6a3dd6f6":"code","6d228815":"code","80563972":"code","ebef8e2f":"code","1c0b8adc":"code","bd714e3b":"code","f16bee09":"code","c5028212":"code","9e799c2a":"markdown","e7bbc35a":"markdown","568f69f6":"markdown","e202896f":"markdown","d0ea804e":"markdown"},"source":{"f2f262ac":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_palette('husl')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('..\/input\/Iris.csv')","af6a2040":"data.head()","ded21963":"data.info()","6a3dd6f6":"data.describe()","6d228815":"data['Species'].value_counts()","80563972":"tmp = data.drop('Id', axis=1)\ng = sns.pairplot(tmp, hue='Species', markers='+')\nplt.show()","ebef8e2f":"g = sns.violinplot(y='Species', x='SepalLengthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='SepalWidthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='PetalLengthCm', data=data, inner='quartile')\nplt.show()\ng = sns.violinplot(y='Species', x='PetalWidthCm', data=data, inner='quartile')\nplt.show()","1c0b8adc":"X = data.drop(['Id', 'Species'], axis=1)\ny = data['Species']\n# print(X.head())\nprint(X.shape)\n# print(y.head())\nprint(y.shape)","bd714e3b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","f16bee09":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nprint(metrics.accuracy_score(y_test, y_pred))","c5028212":"print(y_pred)","9e799c2a":"# Modeling with scikit-learn","e7bbc35a":"# Data Visualization\n- After graphing the features in a pair plot, it is clear that the relationship between pairs of features of a iris-setosa (in pink) is distinctly different from those of the other two species.\n- There is some overlap in the pairwise relationships of the other two species, iris-versicolor (brown) and iris-virginica (green).\n","568f69f6":"## Split the dataset into a training set and a testing set\n\n### Advantages\n- By splitting the dataset pseudo-randomly into a two separate sets, we can train using one set and test using another.\n- This ensures that we won't use the same observations in both sets.\n- More flexible and faster than creating a model using all of the dataset for training.\n\n### Disadvantages\n- The accuracy scores for the testing set can vary depending on what observations are in the set. \n- This disadvantage can be countered using k-fold cross-validation.\n\n### Notes\n- The accuracy score of the models depends on the observations in the testing set, which is determined by the seed of the pseudo-random number generator (random_state parameter).\n- As a model's complexity increases, the training accuracy (accuracy you get when you train and test the model on the same data) increases.\n- If a model is too complex or not complex enough, the testing accuracy is lower.","e202896f":"## Logistic Regression\n\nDespite having \u201cregression\u201d in its name, a logistic regression is actually a widely used binary classifier (i.e. the target vector can only take two values).\n\nOk now that we have our train\/test set we\u2019re all ready to train our Logistic Regression model. Let\u2019s use Sklearn\u2019s implementation and see what we come up with.","d0ea804e":"# Preview of Data\n- There are 150 observations with 4 features each (sepal length, sepal width, petal length, petal width).\n- There are no null values, so we don't have to worry about that.\n- There are 50 observations of each species (setosa, versicolor, virginica)."}}