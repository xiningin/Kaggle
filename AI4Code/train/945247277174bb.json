{"cell_type":{"09e29959":"code","9ff38612":"code","498df664":"code","6db8343c":"code","2cccc140":"code","903b6c1d":"code","0f116ce7":"code","491799ea":"code","5ef9209a":"code","71ac8fee":"code","478070cb":"code","cefd36c7":"code","02f32533":"code","21b68121":"code","c4c559a1":"markdown","b8054027":"markdown","a562ddc1":"markdown","ba5e9172":"markdown","2fff3c73":"markdown","e9e0544a":"markdown","a280758c":"markdown","53d6e575":"markdown","42f496ad":"markdown","cd6430b5":"markdown","3e974443":"markdown","f825e6b9":"markdown","eca6e495":"markdown","95bb59ce":"markdown","660c7650":"markdown"},"source":{"09e29959":"# Para usarlo desde el colab.\n\n#from google.colab import drive\n#from pathlib import Path\n#import matplotlib.pyplot as plt\n\n#drive.mount('\/content\/gdrive')\n#PATH = Path('\/content\/gdrive\/My Drive\/datitos-data')\n#df_fifa2021_o = pd.read_csv(PATH \/ 'fifa2021_training.csv')\n#df_infer = pd.read_csv(PATH \/ 'fifa2021_test.csv')","9ff38612":"import pandas as pd\nimport numpy as np\nimport os \n\n#print(os.listdir(\"\/kaggle\/input\/tp-n2-aprendizaje-profundo-2021-by-datitos-v2\"))\n\nROOT_DIR = \"\/kaggle\/input\/tp-n2-aprendizaje-profundo-2021-by-datitos-v2\"\n\ndf_fifa2021_o = pd.read_csv(os.path.join(ROOT_DIR,'fifa2021_training.csv'))\ndf_infer = pd.read_csv(os.path.join(ROOT_DIR, 'fifa2021_test.csv'))","498df664":"def Preprocesar(data):\n  # Eliminar las caracteristicas que est\u00e1n completas solo por los hombres: \n  #\"Value\", \"Wage\", \"Club\", \"Club_KitNumber\", \"Club_JoinedClub\", \"Club_ContractLength\".\n  # Adem\u00e1s \"Name\", \"Natinality\",\"BirthDate\".\n\n  df_r = pd.DataFrame()\n  df_r = data.drop([\"ID\",\"Name\", \"Natinality\",\"BirthDate\", \"Value\", \"Wage\", \"Club\", \"Club_KitNumber\", \"Club_JoinedClub\", \"Club_ContractLength\"], axis = 1)    \n    \n  #Dummies de categ\u00f3ricas\n  col_sex = pd.get_dummies(df_r[\"Sex\"],prefix=\"Sex\",drop_first=False)\n\n  col_preferredFoot = pd.get_dummies(df_r[\"PreferredFoot\"],prefix=\"PreferredFoot\",drop_first=False)\n  \n  col_playerWorkRate= pd.get_dummies(df_r[\"PlayerWorkRate\"],prefix=\"WorkRate\", drop_first= False)\n \n  df_r = df_r.drop([\"Sex\", \"PreferredFoot\",\"PlayerWorkRate\"], axis=1)\n  \n  df_r = pd.concat([df_r, col_sex, col_playerWorkRate,col_preferredFoot], axis=1)\n\n  #Escalamiento de num\u00e9ricas\n  numeric_features = df_r.dtypes[df_r.dtypes != 'object'].index\n  \n  df_r[numeric_features] = df_r[numeric_features].apply(lambda x: (x - x.mean()) \/ (x.std()))\n\n  return df_r","6db8343c":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df_fifa2021_o, stratify=df_fifa2021_o.Position, train_size=0.9, random_state=42)","2cccc140":"# Training\ndf_train = Preprocesar(df_train)\n\n# Test\ndf_test = Preprocesar(df_test)\n\n#Kraggle\ncolumn_id = df_infer[\"ID\"]\ndf_infer_id = Preprocesar(df_infer)\ndf_infer_id[\"ID\"] = column_id\ndf_infer = df_infer_id.drop([\"ID\"], axis=1)  ","903b6c1d":"# Lleva \"Position\" a tipo num\u00e9rico. \nfrom sklearn.preprocessing import LabelEncoder\n\ntransformador_etiquetas = LabelEncoder()\ntransformador_etiquetas.fit(df_train.Position)\n\ny_train = transformador_etiquetas.transform(df_train.Position) #numpy.ndarray\n\ny_test = transformador_etiquetas.transform(df_test.Position)\n\ndf_train = df_train.drop([\"Position\"], axis=1)\n\ndf_test = df_test.drop([\"Position\"], axis=1)\n","0f116ce7":"import torch\n# Se convierten los dataframes para pasarselos a pytorch\n\n#Training.\nX_train = torch.tensor(df_train.values, dtype=torch.float32)\ny_train = torch.tensor(y_train) \n\n#Test.\nX_test = torch.tensor(df_test.values, dtype=torch.float32)\ny_test = torch.tensor(y_test) \n\n#kraggle\nX_infer = torch.tensor(df_infer.values,dtype=torch.float32)","491799ea":"from torch.utils.data import Dataset\n\nclass Tabular(Dataset):\n    def __init__(self, X, y=None):\n        #self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n        self.X = X\n        self.y = y \n\n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, item):\n        if self.y is None:\n            return self.X[item]\n        else:\n            return self.X[item], self.y[item]\n        \nds_train = Tabular(X_train, y_train)","5ef9209a":"from torch.utils.data import DataLoader\n\ndl_train = DataLoader(ds_train, batch_size=32, shuffle=True)","71ac8fee":"import torch\nimport torch.nn as nn\n\nIN  = X_train.shape[1] # 52 variables\/columnas\nOUT = len(transformador_etiquetas.classes_) # 4 clases resultado.\n\ndropout1 = 0.3\ndropout2 = 0.5\ndropout3 = 0.1\n\nmodelo = nn.Sequential(\n    nn.Linear(IN,  24), \n    nn.ReLU(),\n#    nn.Dropout(dropout1),\n    nn.Linear( 24, 128), nn.ReLU(),\n#    nn.Dropout(dropout2),\n    nn.Linear(128, 16), nn.ReLU(),\n #   nn.Dropout(dropout3),\n    nn.Linear(16, OUT)\n)","478070cb":"#Balanceo de datasets.\n\n#MID    4056 ;DEF    3668; FWD    2172; GK     1240\n#transformador_etiquetas.classes_ : array(['DEF', 'FWD', 'GK', 'MID'], dtype=object)\npesos = torch.FloatTensor ([0.61,1.03, 1.8, 0.55])\n\ncriterio = nn.CrossEntropyLoss(weight= pesos)\noptimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)","cefd36c7":"from sklearn.metrics import balanced_accuracy_score\n\nEPOCAS = 20\n\nfor epoca in range(EPOCAS):\n    modelo.train()\n\n    perdidas_train = []\n    \n    for X_lote, y_lote in dl_train:\n        optimizador.zero_grad()\n\n        predicciones = modelo(X_lote)\n        perdida = criterio(predicciones, y_lote)\n\n        perdida.backward()\n        optimizador.step()\n        \n        perdidas_train.append(perdida.item())\n    \n    modelo.eval()\n    \n    with torch.no_grad():\n        predicciones = modelo(X_test)\n        perdida = criterio(predicciones, y_test)\n        \n        y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n        \n        efectividad = balanced_accuracy_score(y_test, y_pred)\n    \n    \n    print(f'{epoca:3d}  |  Train loss: {np.mean(perdidas_train):.3f}    Valid loss: {perdida:.3f}    Valid accuracy: {efectividad:.2f}')","02f32533":"with torch.no_grad():\n    y_infer = modelo(X_infer).argmax(dim=1)\n\ndf_infer_id['Position'] = transformador_etiquetas.inverse_transform(y_infer)\n\n(\n    df_infer_id[['ID', 'Position']]\n    .rename(columns={'ID':'Id', 'Position':'Category'})\n    .to_csv('submit.csv', index=False)\n)","21b68121":"#os.listdir(\"\/kaggle\/working\")","c4c559a1":"OPCI\u00d3N 1)\n\n(0): Linear(in_features=52, out_features=8, bias=True) (1): Linear(in_features=8, out_features=64, bias=True) (2): ReLU() (3): Linear(in_features=64, out_features=32, bias=True) (4): ReLU() (5): Linear(in_features=32, out_features=4, bias=True)\n\n9 | Train loss: 0.273 Valid loss: 0.274 Valid accuracy: 0.89 Nota: agregando m\u00e1s EPOCS no mejora el \"Valid accuracy\"","b8054027":"OPCI\u00d3N 6) Cambio los pesos del balanceo: [0.61,1.03, 1.8, 0.55] y epocs\n\n5 | Train loss: 0.230 Valid loss: 0.217 Valid accuracy: 0.90","a562ddc1":"OPCI\u00d3N 2) Idem 1 pero agrego una capa de ReLU.\n\n(0): Linear(in_features=52, out_features=8, bias=True) (1): ReLU() (2): Linear(in_features=8, out_features=64, bias=True) (3): ReLU() (4): Linear(in_features=64, out_features=32, bias=True) (5): ReLU() (6): Linear(in_features=32, out_features=4, bias=True)\n\n14 | Train loss: 0.236 Valid loss: 0.249 Valid accuracy: 0.90","ba5e9172":"OPCI\u00d3N 3) Agrego dropout a 2 capas.\n\n(0): Linear(in_features=52, out_features=24, bias=True) (1): ReLU() (2): Dropout(p=0.2, inplace=False) (3): Linear(in_features=24, out_features=64, bias=True) (4): ReLU() (5): Dropout(p=0.4, inplace=False) (6): Linear(in_features=64, out_features=32, bias=True) (7): ReLU() (8): Linear(in_features=32, out_features=4, bias=True)\n\n13 | Train loss: 0.302 Valid loss: 0.265 Valid accuracy: 0.90","2fff3c73":"**Entrenar Modelo**","e9e0544a":"**Transformar variable objetivo**","a280758c":"**Modelo**","53d6e575":"**Separaci\u00f3n en Training y Test**","42f496ad":"OPCI\u00d3N 4): Cambio el learning rate a = 0.001 (LLega m\u00e1s rapido al valor 0.90)\n\n3 | Train loss: 0.273 Valid loss: 0.251 Valid accuracy: 0.90","cd6430b5":"OPCI\u00d3N 5) Agrego pesos para balancear el dataset: [0.9,1.0, 1.7, 0.55]\n\n(0): Linear(in_features=52, out_features=24, bias=True) (1): ReLU() (2): Dropout(p=0.2, inplace=False) (3): Linear(in_features=24, out_features=64, bias=True) (4): ReLU() (5): Dropout(p=0.4, inplace=False) (6): Linear(in_features=64, out_features=32, bias=True) (7): ReLU() (8): Linear(in_features=32, out_features=4, bias=True)\n\n14 | Train loss: 0.257 Valid loss: 0.224 Valid accuracy: 0.89","3e974443":"**Preprocessing**","f825e6b9":"**Inferir datos de prueba**","eca6e495":"**Selecci\u00f3n de modelos:**","95bb59ce":"**Transformar datasets**","660c7650":"**Instanciar Modelo**"}}