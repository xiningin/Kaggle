{"cell_type":{"284e2d43":"code","299edbf8":"code","a0dc32b0":"code","9350c087":"code","64b3ca35":"code","8220301b":"code","537cb978":"code","92378855":"code","9262f705":"code","53542d2d":"code","79145060":"code","9da48f4d":"code","316becae":"code","38cfde4c":"code","3abec778":"code","5e8797e3":"code","9237ae04":"code","9b25e5f9":"code","84842ef2":"code","8b4c9506":"code","0d1d0880":"code","7ff188d8":"markdown","ff759c83":"markdown","1ffa90fd":"markdown","4523f432":"markdown","b0d04e98":"markdown","28adc219":"markdown","98325b49":"markdown","6113a2b6":"markdown","50e786b0":"markdown","630195a6":"markdown","011d2a19":"markdown","c74dd70d":"markdown"},"source":{"284e2d43":"# For CSV handling and numeric operations\nimport numpy as np\nimport pandas as pd\n\n# For ML Model\nimport tensorflow as tf\nimport keras\n\n# For splitting data for training and testing\nfrom sklearn.model_selection import train_test_split\n\n# For plotting graphs and images\nimport matplotlib.pyplot as plt\n\n# For preprocessing images\nfrom sklearn.preprocessing import MinMaxScaler","299edbf8":"dataset = pd.read_csv('..\/input\/az-handwritten-alphabets-in-csv-format\/A_Z Handwritten Data\/A_Z Handwritten Data.csv')\ndataset.rename(columns={'0':'labels'}, inplace=True)","a0dc32b0":"labels = dataset['labels']\nlabels = labels.to_numpy()\n\nimages = dataset.drop('labels', axis=1)\nimages = images.to_numpy()","9350c087":"print('Labels data shape', labels.shape)\nprint('Images data shape', images.shape)","64b3ca35":"def alpha_mapper(int_arr):\n    map_dict = {\n    0:'A',1:'B',2:'C',3:'D',4:'E',\n    5:'F',6:'G',7:'H',8:'I',9:'J',\n    10:'K',11:'L',12:'M',13:'N',14:'O',\n    15:'P',16:'Q',17:'R',18:'S',19:'T',\n    20:'U',21:'V',22:'W',23:'X',24:'Y',\n    25:'Z'}\n    result = np.vectorize(map_dict.get)(int_arr)\n    return result","8220301b":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2)","537cb978":"selected = np.random.randint(x_test.shape[0], size=100)","92378855":"fig, axes = plt.subplots(10, 10, figsize=(10, 10))\nfig.subplots_adjust(wspace=0)\nfor a, image, true_label in zip(\n        axes.flatten(), x_test[selected],\n        alpha_mapper(y_test[selected])):\n    a.imshow(image.reshape(28, 28), cmap='gray_r')\n    a.text(0, 10, str(true_label), color=\"black\", size=15)\n\n    a.set_xticks(())\n    a.set_yticks(())\n\nplt.show()","9262f705":"preprocessor = MinMaxScaler()\npreprocessor.fit(x_train)\n\nx_train = preprocessor.transform(x_train)\nx_test = preprocessor.transform(x_test)","53542d2d":"fig, axes = plt.subplots(10, 10, figsize=(10, 10))\nfig.subplots_adjust(wspace=0)\nfor a, image, true_label in zip(\n        axes.flatten(), x_test[selected],\n        alpha_mapper(y_test[selected])):\n    a.imshow(image.reshape(28, 28), cmap='gray_r')\n    a.text(0, 10, str(true_label), color=\"black\", size=15)\n\n    a.set_xticks(())\n    a.set_yticks(())\n\nplt.show()","79145060":"x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32')\nx_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32')","9da48f4d":"print(x_train[0].shape)","316becae":"model = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5), input_shape=(28, 28, 1), activation = 'relu'))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\nmodel.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5), input_shape=(28, 28, 1), activation = 'relu'))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(keras.layers.Flatten())\n\nprint('Shape after CNN :', model.output_shape)\n\nmodel.add(keras.layers.Dense(1000, activation = 'relu'))\nmodel.add(keras.layers.Dense(300, activation = 'sigmoid'))\nmodel.add(keras.layers.Dense(100, activation = 'relu'))\nmodel.add(keras.layers.Dense(26, activation = 'softmax'))\n\nprint('Final Output Shape :', model.output_shape)\nassert model.output_shape[1] == 26","38cfde4c":"model.summary()","3abec778":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","5e8797e3":"fitting = model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 100, epochs = 25, verbose = 2)","9237ae04":"!mkdir -p saved_model\nmodel.save('saved_model\/handwriting_recognizer')\nmodel.save('handwriting_recognizer.h5')","9b25e5f9":"preds_trained = model.predict(x_test[selected])\n\nfig, axes = plt.subplots(10, 10, figsize=(10, 10))\nfig.subplots_adjust(wspace=0)\nfor a, image, true_label, pred_trained in zip(\n        axes.flatten(), x_test[selected],\n        alpha_mapper(y_test[selected]),\n        alpha_mapper(np.argmax(preds_trained, axis=1))):\n    a.imshow(image.reshape(28, 28), cmap='gray_r')\n    a.text(0, 10, str(true_label), color=\"black\", size=15)\n    a.text(20, 26, str(pred_trained), color=\"blue\", size=15)\n\n    a.set_xticks(())\n    a.set_yticks(())\n\nplt.show()","84842ef2":"print(preds_trained[0])\nprint(np.argmax(preds_trained[0]))","8b4c9506":"plt.plot(fitting.history['loss'])\nplt.plot(fitting.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","0d1d0880":"plt.plot(fitting.history['accuracy'])\nplt.plot(fitting.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","7ff188d8":"## Loading and Preprocessing Dataseet","ff759c83":"## Building CNN Model","1ffa90fd":"### Potting Loss","4523f432":"### Plotting Accuracy","b0d04e98":"### Images with True Labels (Black) and Predicted Labels (Blue)","28adc219":"* #### Using ADAM Optimizer","98325b49":"#### Model Fitting Step\n* batch_size = 100\n* epochs = 25","6113a2b6":"### Mapper Function\n* input: array of integers in 0 to 25\n* output: array mapped to int -> corresponding char","50e786b0":"### Preprocessing Step","630195a6":"### Images after preprocessing step\nImages may look same but their values are now scaled from a(min) -> b(max) to 0 -> 1 for better performance.","011d2a19":"### Images and their Labels","c74dd70d":"### Preparing Dataset for Training and Testing"}}