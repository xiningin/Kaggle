{"cell_type":{"61fe4195":"code","91468d74":"code","f9f9bbc1":"code","c0150657":"code","2fa90a3f":"code","f6beacb0":"code","abd9bf7e":"code","596ce2b4":"code","f92b3c74":"code","e8a590cb":"code","c8de45c1":"code","92d91c9a":"code","08687893":"code","5536db14":"code","508b358f":"code","d23db190":"code","96ec216d":"code","21f40cda":"code","6e891cd7":"code","d1cb90fa":"code","c8c99003":"code","ac52c58c":"code","6857347e":"code","9b46dfd3":"code","66967946":"code","3dfbf69b":"code","b0fd0638":"code","81a469b7":"markdown","56c7137d":"markdown","39a2fda1":"markdown"},"source":{"61fe4195":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\npd.set_option('display.max_columns', 110)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91468d74":"df_train = pd.read_csv('..\/input\/minor-project-2021\/train.csv')\ndf_train.head()","f9f9bbc1":"abs(df_train.corr()['Result']).sort_values(ascending=False)[:50].index[1:].values","c0150657":"df_mod = df_train[abs(df_train.corr()['Result']).sort_values(ascending=False)[:50].index[1:].values]\ndf_mod.shape","2fa90a3f":"#correlation matrix\ncorrmat = df_mod.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=1, square=True, cmap='coolwarm')","f6beacb0":"df_train.shape","abd9bf7e":"total = df_mod.isnull().sum().sort_values(ascending=False)\npercent = (df_mod.isnull().sum()\/df_mod.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.Total.values","596ce2b4":"df_train = df_train.drop('f_1', axis = 1)\ndf_train = df_train.drop('f_3', axis = 1)\ndf_train = df_train.drop('f_10', axis = 1)\ndf_train = df_train.drop('f_11', axis = 1)\ndf_train = df_train.drop('f_12', axis = 1)\ndf_train = df_train.drop('f_18', axis = 1)\ndf_train = df_train.drop('f_19', axis = 1)\ndf_train = df_train.drop('f_20', axis = 1)\ndf_train = df_train.drop('f_61', axis = 1)\ndf_train = df_train.drop('f_69', axis = 1)\ndf_train = df_train.drop('f_70', axis = 1)\ndf_train.shape","f92b3c74":"df_train = df_train.dropna()","e8a590cb":"# #correlation matrix\n# corrmat = df_train.corr()\n# f, ax = plt.subplots(figsize=(12, 9))\n# sns.heatmap(corrmat, vmax=1, square=True, cmap='coolwarm')","c8de45c1":"# df_mod = df_mod.fillna(df_train.median())\n# df_mod.describe()","92d91c9a":"# df_mod.info()","08687893":"df_train.columns","5536db14":"X_train, X_test, y_train, y_test = train_test_split(df_train[df_train.columns[:-2]], df_train['Result'], test_size = 0.2, random_state = 42, stratify = df_train['Result'])","508b358f":"scalar = StandardScaler()\nscalar.fit(X_train)\nX_train = scalar.transform(X_train)\nX_test = scalar.transform(X_test)","d23db190":"# classifier = LogisticRegression(class_weight = 'balanced', max_iter = 10000, n_jobs = -1)\n# parameters = {'C':[0.005, 0.01, 0.02, 0.04]}\n# gridsearch = GridSearchCV(classifier, parameters)\n# gridsearch.fit(X_train, y_train)","96ec216d":"# gridsearch.cv_results_","21f40cda":"classifier = LogisticRegression(C = 0.005, max_iter = 10000, n_jobs = -1)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(f1_score(y_test, y_pred))","6e891cd7":"# clf_rf_gs = RandomForestClassifier(oob_score=True, n_jobs = -1, random_state = 42,  class_weight = 'balanced_subsample')\n# parameters = {'n_estimators':[100, 250, 400], 'max_depth':[12, 14, 16]}\n# gridsearch = GridSearchCV(clf_rf, parameters)\n# gridsearch.fit(X_train, y_train)","d1cb90fa":"# gridsearch.best_estimator_","c8c99003":"# gridsearch.cv_results_","ac52c58c":"# clf_rf = RandomForestClassifier(oob_score=True, n_jobs = -1, random_state = 42, n_estimators = 100, class_weight = 'balanced_subsample', criterion='gini')\n# clf_rf.fit(X_train, y_train)\n# y_pred_rf = clf_rf.predict(X_test)\n# print(f1_score(y_test, y_pred_rf))","6857347e":"df_test = pd.read_csv('..\/input\/minor-project-2021\/test.csv')\ndf_test = df_test.fillna(df_test.median())\ndf_test.shape","9b46dfd3":"df_test = df_test.drop('f_1', axis = 1)\ndf_test = df_test.drop('f_3', axis = 1)\ndf_test = df_test.drop('f_10', axis = 1)\ndf_test = df_test.drop('f_11', axis = 1)\ndf_test = df_test.drop('f_12', axis = 1)\ndf_test = df_test.drop('f_18', axis = 1)\ndf_test = df_test.drop('f_19', axis = 1)\ndf_test = df_test.drop('f_20', axis = 1)\ndf_test = df_test.drop('f_61', axis = 1)\ndf_test = df_test.drop('f_69', axis = 1)\ndf_test = df_test.drop('f_70', axis = 1)","66967946":"df_train.columns","3dfbf69b":"sub = pd.read_csv('..\/input\/minor-project-2021\/sample_submission.csv')\ndf_test = df_test[df_train.columns[:-2]]\ndf_test = scalar.transform(df_test)\ny_pred = classifier.predict(df_test)\nsub.Expected = y_pred.astype(int)\nsub.to_csv('Submission.csv', index=False)","b0fd0638":"# sub_csv = pd.read_csv('.\/Submission.csv')\n# sub_csv.info()","81a469b7":"# **Actual Predictions on test data**","56c7137d":"# **Random Forest Classifier**","39a2fda1":"# **Logistic regression**"}}