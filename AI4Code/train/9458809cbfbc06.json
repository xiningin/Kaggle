{"cell_type":{"3d2c16b4":"code","f7ec2c27":"code","87bf87b1":"code","885b74bb":"code","cd595994":"code","6b6a5d39":"code","7f4f798d":"code","17c1bf66":"code","e79729d9":"code","da1a5bf5":"code","542c462d":"code","26b0a054":"code","aba25a57":"code","c7458a63":"code","7528a94b":"code","e6b34717":"code","31c54afe":"code","00646dc0":"code","c0c228b0":"code","c1782196":"code","11f67b0b":"code","25a8fe66":"markdown","43e518e3":"markdown","df65644b":"markdown","166fbb9d":"markdown","66771969":"markdown","29f6aaba":"markdown","a3e024f6":"markdown","677daa80":"markdown","cf301565":"markdown","bb2c2c2f":"markdown","cbc330cf":"markdown","860298ac":"markdown","bfd2ae1c":"markdown","f1cbbd7e":"markdown","33afb9de":"markdown","5f495e03":"markdown","33aa8491":"markdown"},"source":{"3d2c16b4":"import logging\nimport time\nimport warnings\n\nimport catboost as cb\nimport datatable as dt\nimport joblib\nimport lightgbm as lgbm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport optuna\nimport pandas as pd\nimport seaborn as sns\nimport shap\nimport xgboost as xgb\nfrom optuna.samplers import TPESampler\nfrom sklearn.compose import (\n    ColumnTransformer,\n    make_column_selector,\n    make_column_transformer,\n)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import log_loss, mean_squared_error\nfrom sklearn.model_selection import (\n    KFold,\n    StratifiedKFold,\n    cross_validate,\n    train_test_split,\n)\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\nlogging.basicConfig(\n    format=\"%(asctime)s - %(message)s\", datefmt=\"%d-%b-%y %H:%M:%S\", level=logging.INFO\n)\noptuna.logging.set_verbosity(optuna.logging.WARNING)\nwarnings.filterwarnings(\"ignore\")\npd.set_option(\"float_format\", \"{:.5f}\".format)","f7ec2c27":"train = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/test.csv\")","87bf87b1":"train.columns","885b74bb":"train.head(10)","cd595994":"print(train.shape)\nprint(test.shape)","6b6a5d39":"print(train.isnull().values.any())\nprint(test.isnull().values.any())","7f4f798d":"train.groupby('target').mean()","17c1bf66":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nX = train.iloc[0:10000,:-1]\nfeatures = [i for i in X.columns if i not in ['row_id', 'target']]\nlb = LabelEncoder()\ny = lb.fit_transform(train['target'])\ny = y[0:10000]\nX_train, X_valid, y_train, y_valid = train_test_split(X[features], y, random_state=1)\n#my_model = RandomForestClassifier(n_estimators=100,\n #                                 random_state=0).fit(train_X, train_y)\ndel train,test","e79729d9":"#import eli5\n#from eli5.sklearn import PermutationImportance\n\n#perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n#eli5.show_weights(perm, feature_names = val_X.columns.tolist())","da1a5bf5":"model = xgb.XGBRegressor(n_estimators=1000, tree_method=\"gpu_hist\").fit(\n    X_train, y_train\n)","542c462d":"# Create a tree explainer\nxgb_explainer = shap.TreeExplainer(\n    model, X_train, feature_names=X_train.columns.tolist()\n)","26b0a054":"xgb_explainer","aba25a57":"%%time\n\n# Shap values with tree explainer\nshap_values = xgb_explainer.shap_values(X_train, y_train)","c7458a63":"%%time\n\n# Shap values with XGBoost core model\nbooster_xgb = model.get_booster()\nshap_values_xgb = booster_xgb.predict(xgb.DMatrix(X_train, y_train), pred_contribs=True)","7528a94b":"shap_values_xgb = shap_values_xgb[:, :-1]\n\npd.DataFrame(shap_values_xgb, columns=X_train.columns.tolist()).head()","e6b34717":"shap.summary_plot(\n    shap_values_xgb, X_train, feature_names=X_train.columns, plot_type=\"bar\"\n)","31c54afe":"shap.summary_plot(shap_values_xgb, X_train, feature_names=X_train.columns);","00646dc0":"%%time\n\n# SHAP interactions with XGB\ninteractions_xgb = booster_xgb.predict(\n    xgb.DMatrix(X_train, y_train), pred_interactions=True\n)","c0c228b0":"interactions_xgb.shape","c1782196":"def get_top_k_interactions(feature_names, shap_interactions, k):\n    # Get the mean absolute contribution for each feature interaction\n    aggregate_interactions = np.mean(np.abs(shap_interactions[:, :-1, :-1]), axis=0)\n    interactions = []\n    for i in range(aggregate_interactions.shape[0]):\n        for j in range(aggregate_interactions.shape[1]):\n            if j < i:\n                interactions.append(\n                    (\n                        feature_names[i] + \"-\" + feature_names[j],\n                        aggregate_interactions[i][j] * 2,\n                    )\n                )\n    # sort by magnitude\n    interactions.sort(key=lambda x: x[1], reverse=True)\n    interaction_features, interaction_values = map(tuple, zip(*interactions))\n\n    return interaction_features[:k], interaction_values[:k]\n\n\ntop_10_inter_feats, top_10_inter_vals = get_top_k_interactions(\n    X_train.columns, interactions_xgb, 10\n)","11f67b0b":"top_10_inter_feats","25a8fe66":"One of the most fantastic attributes of SHAP and Shapley values is their ability to find relationships between features accurately.","43e518e3":"<h2>Upvote, If you find this notebook helpful!<\/h2>","df65644b":"<h1>Permutation Importance<\/h1>","166fbb9d":"In the previous version of this notebook we could see A2T1G3C4 & A1T1G4C4 have the highest importance.","66771969":"<h3>Loading Data<\/h3>","29f6aaba":"By setting pred_interactions to True, we get SHAP interaction values in only 10 seconds. It is a 3D array, with the last column axes being the bias terms:","a3e024f6":"<h1>Work in progress...<\/h1>","677daa80":"<h1>Feature Importances with SHAP<\/h1>","cf301565":"A4T2G0C4 & A3T3G2C2 stands out as the driving factor for the dataset.","bb2c2c2f":"<b>Now, top_10_inter_feats contains 10 of the strongest interactions between all possible pairs of features:<b>","cbc330cf":"<h1>Machine Learning Explainability - kaggle tutorial<\/h1>\nThis notebook is inspired and heavily influenced by the excellent notebook of BEXGBoost, here is the notebook link\n<a href=https:\/\/www.kaggle.com\/bextuychiev\/model-explainability-with-shap-only-guide-u-need>Model Explainability with SHAP only guide u need<\/a>","860298ac":" Interpretation of the above plot:\n\n1)The left vertical axis denotes feature names, ordered based on importance from top to bottom.\n\n2)The horizontal axis represents the magnitude of the SHAP values for predictions.\n\n3)The vertical right axis represents the actual magnitude of a feature as it appears in the dataset and colors the points.\n\nWe see that as A3T3G2C2 increases, its effect on the model is more positive. The same is true for A3T3G3C1 feature. The A4T2G0C4 feature is a bit tricky with a cluster of mixed points around the center, as well as a mixed sign as it increases.","bfd2ae1c":"<h1> Shap Values<\/h1>","f1cbbd7e":"<h2>Hope you find this helpful!<\/h2>","33afb9de":"<h1>Feature Interactions with Shapley values - Part 2<\/h1>","5f495e03":"Checking for null values.","33aa8491":"Shape of Train & Test"}}