{"cell_type":{"ab0637d9":"code","601942ba":"code","638275bb":"code","21b375bc":"code","d112d534":"code","6cfdf3b7":"code","0789d882":"code","b1f977b4":"code","5756ad02":"code","8e9282df":"code","1947619d":"code","94386066":"code","b2dfa108":"code","92cd93a6":"code","9ccc61eb":"code","5acb2de0":"code","4a809981":"code","0427f6d7":"code","40a20432":"code","0e448518":"code","375f6194":"code","8350c03c":"code","6279542a":"code","86335577":"markdown","b7a6de42":"markdown"},"source":{"ab0637d9":"!pip install -U albumentations","601942ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport PIL\n%matplotlib inline\n\n# https:\/\/github.com\/fastai\/fastai\n# https:\/\/docs.fast.ai\/\nfrom fastai.vision.all import *\nimport albumentations\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","638275bb":"sub = pd.read_csv(\"\/kaggle\/input\/expertclass\/Sample_Solutions.csv\")\nsub.head()","21b375bc":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)","d112d534":"def get_train_aug(): return albumentations.Compose([\n            albumentations.Transpose(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.3, \n                sat_shift_limit=0.3, \n                val_shift_limit=0.3, \n                p=0.5),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)\n])\n\ndef get_valid_aug(): return albumentations.Compose([\n#     albumentations.CenterCrop(224,224, p=1.),\n    albumentations.Resize(224, 224)\n], p=1.)\n\nitem_tfms = [Resize(224), AlbumentationsTransform(get_train_aug(), get_valid_aug())]","6cfdf3b7":"block = DataBlock(blocks=(ImageBlock, CategoryBlock),\n   get_items=get_image_files,\n   get_y=parent_label,\n   splitter=GrandparentSplitter(train_name='Trainset', valid_name='Testset'),\n   item_tfms=item_tfms,\n#    batch_tfms=aug_transforms() # Optional Already using Albumentations above \n)","0789d882":"dls = block.dataloaders('\/kaggle\/input\/expertclass\/', bs=32)","b1f977b4":"dls.train.show_batch(max_n=9)","5756ad02":"dls.valid.show_batch(max_n=9)","8e9282df":"learn = cnn_learner(dls, resnet34, metrics=[\n#     F1Score(average=None), # f1 score per class\n#     F1Score(average='micro'), # this is the same as accuracy\n#     F1Score(average='macro'), # This does not take label imbalance into account.\n    F1Score(average='weighted') # Used in this competition\n                                # it can result in an F-score that is not between precision and recall.\n])\nlearn.model","1947619d":"lr_min, lr_steep = learn.lr_find(num_it=200)","94386066":"lr_min, lr_steep","b2dfa108":"learn.fine_tune(5, lr_min)","92cd93a6":"learn.save(\"resnet-34-stage-1\")","9ccc61eb":"learn.show_results()","5acb2de0":"interp = Interpretation.from_learner(learn)","4a809981":"inter_class = ClassificationInterpretation.from_learner(learn)","0427f6d7":"inter_class.plot_confusion_matrix()","40a20432":"inter_class.print_classification_report()","0e448518":"interp.plot_top_losses(12, figsize=(15,10))","375f6194":"PREDICTION_DIR = '\/kaggle\/input\/expertclass\/Prediction\/Prediction\/'\nPREDICTION_LEN = (len([name for name in os.listdir(PREDICTION_DIR) if os.path.isfile(os.path.join(PREDICTION_DIR, name))]))\nPREDICTION_LEN","8350c03c":"dict_target = {\n    'Budweiser' : 0,\n    'Hoegaarden' : 1,\n    'Leffe' : 2,\n    'Stella' : 3,\n    'Others' : 4\n}\n\nimages = []\npreds = []\nfor img_path in glob.glob(PREDICTION_DIR+'\/*.png'):\n    pr1,_,pr2 = learn.predict(img_path)\n#     print(img_path.split(\"\/\")[-1].split('.')[0], pr1, _, pr2)\n    images.append(int(img_path.split(\"\/\")[-1].split('.')[0]))\n    preds.append(dict_target[pr1])\n    \nsubmission = pd.DataFrame({\n    'ID' : images,\n    'Class' : preds\n})\nsubmission\n# plt.figure(figsize=(20,10))\n# columns = 4\n\n# plt.rcParams[\"figure.figsize\"] = (20,3)\n# for i, image in enumerate(images):\n#     x = sub.at[i,'ID']\n#     image_name = \"\/kaggle\/input\/expertclass\/Prediction\/Prediction\/\" + str(x) + \".png\"\n#     plt.subplot(len(images) \/ columns + 1, columns, i + 1)\n#     pr1,_,pr2 = learn.predict(test_image)\n#     plt.title(pr1+'\\t-\\t'+str(x)+'.png')\n#     plt.imshow(image)\n#     sub.at[i,'Class'] = dict_target[pr1]","6279542a":"submission.to_csv('submission.csv', index=False)","86335577":"**Team**\n* Maycown Miranda - maycown.miranda@ambev.com.br\n* Fabricio Talarico - 99814747@ambev.com.br\n* Lucas Nakadaira - 99816022@ambev.com.br\n* Rafael Grimaldi - 99821224@ambev.com.br","b7a6de42":"Creating transformations for Data Augmentation using `Albumentation` lib"}}