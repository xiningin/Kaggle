{"cell_type":{"0bca3291":"code","fc3af395":"code","f5d10f13":"code","e93d7558":"code","2e112644":"code","f2fc97a7":"code","f38f02ca":"code","eb4b4a9a":"code","889fb67c":"code","80f17ab1":"code","ad3eb755":"code","74f8036e":"code","86f2d54c":"code","e09621d1":"code","b5a1403a":"code","3ef2d1fb":"code","ea70c5fa":"code","ed4f6e47":"code","ca454c94":"code","2e5ce598":"code","1d7d7c76":"code","2a4afc22":"code","3ac45333":"code","ae148076":"code","623ed365":"code","313b563d":"code","51353ff1":"code","2ee1b575":"code","6c0f6850":"code","dd4abf2f":"code","1ddfff65":"code","8065542c":"code","00fa6e27":"code","82b2ade8":"code","90a25bd0":"code","06ae1a26":"code","90d3bc0d":"code","232a88d2":"code","12ec43b3":"code","da84513a":"code","dd106669":"code","de5e4838":"code","11de9db7":"code","20f0cfb6":"code","a109cbd5":"markdown","cde16517":"markdown","b32eec7d":"markdown","0bcfc96a":"markdown","e27c313b":"markdown","282ac18d":"markdown","397b2922":"markdown","eecf7f4d":"markdown","de29d46f":"markdown","f251b056":"markdown","f665c778":"markdown","5c282a37":"markdown","36714fe6":"markdown"},"source":{"0bca3291":"from IPython.display import Image\nImage(\"..\/input\/1.png\")","fc3af395":"Image(\"..\/input\/2.PNG\")","f5d10f13":"Image(\"..\/input\/3.PNG\")","e93d7558":"Image(\"..\/input\/4.PNG\")","2e112644":"Image(\"..\/input\/5.PNG\")","f2fc97a7":"Image(\"..\/input\/6.PNG\")","f38f02ca":"Image(\"..\/input\/7.PNG\")","eb4b4a9a":"Image(\"..\/input\/8.PNG\")","889fb67c":"Image(\"..\/input\/9.PNG\")","80f17ab1":"Image(\"..\/input\/10.PNG\")","ad3eb755":"Image(\"..\/input\/11.PNG\")","74f8036e":"Image(\"..\/input\/121.PNG\")","86f2d54c":"Image(\"..\/input\/13.PNG\")","e09621d1":"## lets first create an utility method that would compare two matrices element by element\n## this is required since we would be comparing our custom method with industry accepted methods\n\n#### NOTE: we could very well have used (A==B).all(). however this only works if A,B are numpy arrays\n\ndef compare(m1,m2):\n\n    flag = False\n\n    if m1.shape == m2.shape:\n\n        for i,j in enumerate(m1):\n            \n            check_all = list(set(filter(lambda x :True if x else False,[i==k for i,k in zip(j,m2[i])])))\n\n            if check_all and len(check_all)==1 and check_all[0]:\n\n                continue\n            \n            else:\n                return flag\n\n        flag = True\n    \n    return flag","b5a1403a":"## we will first flip horizontally and then vertically\nimport numpy as np\n\nm = np.array([\n\n    [5, 2, 3],\n    [1, 1, 11],\n    [3, 4, 55]\n\n])\n\nm","3ef2d1fb":"\ndef flip_horizontally(matrix):\n    return matrix[:, ::-1]\n\n##lets test\n\nflip_horizontally(m)","ea70c5fa":"## lets assert using industry level method to achieve the same\n\ncompare(flip_horizontally(m),np.fliplr(m))","ed4f6e47":"def flip_vertically(matrix):\n    return matrix[::-1]\n\n## lets test\n\ncompare(flip_vertically(m),np.flipud(m))\n\n## we can see that they are the same","ca454c94":"## lets bring this all together.\ncompare(flip_vertically(flip_horizontally(m)), np.flipud(np.fliplr(m)))\n","2e5ce598":"## lets first see how we can get weighted sum of two matrix\n\na = np.array([[1,2,3],[4,5,6]])\n\nk = np.array([[10,10,10],[10,10,10]])\n\n## we are expecting a value of 1*10+2*10+3*10+4*10+5*10+6*10\nsum = 0\nfor i, j in enumerate(a):\n    \n    for a, b in zip(j, k[i]):\n        sum = sum + a*b\n        \nprint(sum)\n\ndef weighted_sum(matrix_one, matrix_two):\n    sum = 0\n    \n    for i, j in enumerate(matrix_one):    \n        for a, b in zip(j, matrix_two[i]):\n            sum = sum + a*b\n            \n    return sum\n        \n    ","1d7d7c76":"## lets create a method for padding\n\ndef pad_zeros(matrix, pad_dim):\n    \"\"\"\n    pad_dim needs to be a sequence of two length. \n    \n    \"\"\"\n    \n    existing_dim =  matrix.shape\n    \n    new_dim = (pad_dim[0]*2 + existing_dim[0], pad_dim[1]*2 + existing_dim[1])\n    \n    new_matrix = np.zeros(new_dim)\n    \n    new_matrix[pad_dim[0]: pad_dim[0]+ existing_dim[0], pad_dim[1]: pad_dim[1]+ existing_dim[1]] = matrix\n    \n    return new_matrix\n\n\n## lets test\n\nt1 = np.array([[2,1,2],[5,0,1],[1,7,3]])\nt2 = np.array([[0.5,0.7, 0.4],[0.3,0.4, 0.1],[0.5, 1, 0.5]])\nt3 = np.array([[1,2,3,4], [11,22,33,44]])\n\nprint(t1, '\\n padded: \\n',pad_zeros(t1, (1,1)))\n\nprint(t2, '\\n padded: \\n',pad_zeros(t2, (1,1)))\n\nprint(t2, '\\n padded: \\n',pad_zeros(t2, (2,2)))\n\nprint(t3, '\\n padded: \\n',pad_zeros(t3, (1,1)))","2a4afc22":"from math import ceil\n\nm = np.array([[2,1,2],[5,0,1],[1,7,3]])\nw = np.array([[0.5,0.7, 0.4],[0.3,0.4, 0.1],[0.5, 1, 0.5]])\nw = flip_vertically(flip_horizontally(w))\nprint(m,w)\n\ndim_image = m.shape\ndim_kernel = w.shape\nstride = 1\n\nfrom math import floor \n\ndim_kernel_center = (floor((dim_kernel[0]- 1 )\/2),floor((dim_kernel[1]- 1 )\/2))\n\npadding_dim = dim_kernel_center\n\n## we find the dimensions of the padded matrix\nnew_dim = (padding_dim[0]*2 + dim_image[0], padding_dim[1]*2 + dim_image[1])\n\nnumber_of_movements_column_wise = ceil(dim_kernel[1]\/stride)\nnumber_of_movements_row_wise = ceil(dim_kernel[0]\/stride)\n\ndim_output_matrix = (floor((dim_image[0] + 2* padding_dim[0] - dim_kernel[0])\/stride) +1, \\\n                        floor((dim_image[1] + 2* padding_dim[1] - dim_kernel[1])\/stride)+1)\n\n\noutput_matrix = np.zeros(dim_output_matrix)\npadded_matrix = pad_zeros(m, padding_dim)\nprint(number_of_movements_column_wise, number_of_movements_row_wise, dim_output_matrix)\n\n\nfor r in range(dim_output_matrix[0]):\n    \n    for c in range(dim_output_matrix[1]):\n        \n        for s in range(stride):\n            output_matrix[r,c] = weighted_sum(m[r:dim_kernel[0], c + s: dim_kernel[1] + s], w)\n        \n\noutput_matrix\n        \n        ","3ac45333":"def convolution(image, kernel, stride = 1):\n    \n    w = flip_vertically(flip_horizontally(kernel))\n\n    dim_image = image.shape\n    dim_kernel = w.shape\n    stride = 1\n\n    dim_kernel_center = (floor((dim_kernel[0]- 1 )\/2),floor((dim_kernel[1]- 1 )\/2))\n\n    padding_dim = dim_kernel_center\n\n    ## we find the dimensions of the padded matrix\n    new_dim = (padding_dim[0]*2 + dim_image[0], padding_dim[1]*2 + dim_image[1])\n\n    dim_output_matrix = (floor((dim_image[0] + 2* padding_dim[0] - dim_kernel[0])\/stride) +1, \\\n                            floor((dim_image[1] + 2* padding_dim[1] - dim_kernel[1])\/stride)+1)\n\n\n    output_matrix = np.zeros(dim_output_matrix) \n    padded_matrix = pad_zeros(image, padding_dim)\n\n    rstep = 0\n    for r in range(dim_output_matrix[0]):\n\n        step = 0\n        for c in range(dim_output_matrix[1]):\n\n            output_matrix[r,c] = weighted_sum(padded_matrix[ rstep:dim_kernel[0]+ rstep , step : dim_kernel[1] + step ], w)\n            step = step+stride\n\n        rstep = rstep + stride\n\n    return output_matrix\n\nm = np.array([[2,1,2],[5, 0, 1],[1,7,3]])\nw = np.array([[0.5, 0.7, 0.4],[0.3,0.4,0.1],[0.5,1,0.5]])\n\nconvolution(m, w)\n","ae148076":"\n##lets this our method out against scipy.signal convolve methods\nfrom scipy.signal import convolve2d\n\nm = np.array([[1,1,1],[2,2,2],[3,3,3]])\nw = np.array([[-1,2,-1],[-1,2,-1],[-1,2,-1]])\nprint(compare(convolution(m, w), convolve2d(m,w,mode='same')))\n\n\nm = np.array([[0.5,0.3,0.2],[2,2,2],[-3,0.2,1.2]])\nw = np.array([[-1,2,-1],[-1,2,-1],[-1,2,-1]])\nprint(compare(convolution(m, w), convolve2d(m,w,mode='same')))\n\n\nm = np.random.rand(10,10)\nw = np.array([[0,-1,2,-1,0],[0,-1,2,-1,0],[0,-1,2,-1,0],[0,-1,2,-1,0],[0,-1,2,-1,0]])\n\nprint(compare(convolution(m, w),convolve2d(m,w,mode='same')))\n\n## we can see that our values are the same across all. hence we have succesfully convolved","623ed365":"Image(\"..\/input\/14.PNG\")","313b563d":"Image(\"..\/input\/15.PNG\")","51353ff1":"Image(\"..\/input\/16.PNG\")","2ee1b575":"Image(\"..\/input\/17.PNG\")","6c0f6850":"Image(\"..\/input\/18.PNG\")","dd4abf2f":"Image(\"..\/input\/19.PNG\")","1ddfff65":"Image(\"..\/input\/20.PNG\")","8065542c":"Image(\"..\/input\/21.PNG\")","00fa6e27":"Image(\"..\/input\/22.PNG\")","82b2ade8":"Image(\"..\/input\/23.PNG\")","90a25bd0":"Image(\"..\/input\/24.PNG\")","06ae1a26":"Image(\"..\/input\/25.PNG\")","90d3bc0d":"Image(\"..\/input\/26.PNG\")","232a88d2":"from skimage import io, viewer\n\nimport numpy as np\nfrom matplotlib import pyplot as plot\nfrom scipy.signal import convolve2d\n","12ec43b3":"## lets draw a rough square 256*256 pixel\n\nsquare = np.zeros((256,256))\n##this square is completely dark box\nsquare[50:200, 50:200] = 1\n\n\nplot.imshow(square, cmap = plot.cm.gray)","da84513a":"## lets define our kernels one by one \n\n\nblur_kernel = np.array([[1\/9,1\/9,1\/9],[1\/9,1\/9,1\/9],[1\/9,1\/9,1\/9]])\n\nplot.imshow(convolve2d(square, blur_kernel, mode='same'), cmap = plot.cm.gray)\n\n## since this is a white nd black image, impact of blurring may not be clear immediately\n\n\n## however take a look at the bottom right edges. it is clear that color white is bleeding into the black background\n## whereas in our original image, the boundaries where very clearly defined\n","dd106669":"## as promised, lets see what happens when we take weird combinations of the kernel. where the weights are not\n## proportionately distributed \nimg = io.imread('..\/\/input\/\/cat_black_nd_white.jpg', as_grey=True)\n\nplot.imshow(img, cmap = plot.cm.gray)\n\n","de5e4838":"blur_kernel_weights = (1\/9) * np.array([[1,1,1],[1,1,1],[1,1,1]])\n\nfig, ax = plot.subplots(1,2, figsize= (25,45))\nax[0].imshow(img, cmap = plot.cm.gray)\nax[1].imshow(convolve2d(img, blur_kernel_weights, mode = 'same'), cmap = plot.cm.gray)\nax[0].set_title('Original Image')\nax[1].set_title('Blurred Image')","11de9db7":"\n## lets work on vertical edge detectors\n\nimg = io.imread('..\/\/input\/\/small_t.jpg', as_grey=True)\n\nplot.imshow(img,cmap=plot.cm.gray)\n","20f0cfb6":"vertical_edge_kernel = np.array([[-4,8,-4],[-4,8,-4],[-4,8,-4]])\n\n## could be same as [-1,2,-1] or any multiples there of\n\nfig , ax = plot.subplots(1,2)\n\nax[0].imshow(img, cmap=plot.cm.gray)\nax[1].imshow(convolve2d(img, vertical_edge_kernel), cmap=plot.cm.gray)\nax[0].set_title('Original Image')\nax[1].set_title('Vertical Edge Detected')","a109cbd5":"#### Before we proceed further lets reiterate our custom functions vs industry accepted methods for convolution operations","cde16517":"##### Lets create a method to apply convolution on a pixel representation of an image\n\n###### input would be the original image matrix, kernel matrix , stride value","b32eec7d":"#### Steps \n\n###### demonstrate in illustration how convolution is done\n###### show the python code for each operation\n###### develop an intuition for convolutions so as to come up with kernels on own\n###### references i have used ","0bcfc96a":"<br><br>","e27c313b":"<br><br>","282ac18d":"\n\nI am a beginner to deep learning and CNN. <br>\nLike any other beginners to deep learning, i started with the classic example of using an artificial neural network on MNIST database. While this particular use case had challenges of its own, i found nothing more excruciating than the use case of image classification using Convolutional Neural Network.<br>\n\nMost blogs\/papers\/youtube videos\/paid tutorials would simply explain what is a convolution, how convolution is performed and its impact or worse, extreme mathematical terms (i went down a rabbit hole of maths upto fourier transform :( ). <br>\n\nI could not, for the life of me, understand the intuition behind convolution in image processing. BY that i mean, how is it that the matrix for edge detectors actually detect edge. Why do they detect edges and nothing else? <br>\n\nAnd a direct impact of the above confusion was i could not come up with the kernels for operations such as blur,sharpen on my own. <br>\n\nAfter week of searching intensely, reading intensely i came up with an understanding of convolution in image processing. I am hoping this will come in handy for others as well. And heck, will serve as a reference guide for me too when needed in the future","397b2922":"# Intuition behind Convolution in Image Processing\n\n## - No Maths\n## - All illustrations\n## - Python code for each operation\n## - Corresponding vendor code also shown (eg numpy packages, scipy packages,etc)","eecf7f4d":"<br><br>\n\n\n\n##### I hope you found this useful. I cannot end without acknowledging help i got from many folks and their blogs. All of them are listed below\n\n\n\n### http:\/\/machinelearninguru.com\/computer_vision\/basics\/convolution\/image_convolution_1.html\n\n### https:\/\/cs.stackexchange.com\/questions\/3215\/intuition-for-convolution-in-image-processing?rq=1\n\n### http:\/\/www.aishack.in\/tutorials\/image-convolution-examples\/\n\n### https:\/\/www.youtube.com\/watch?v=C_zFhWdM4ic&t=278s\n\n\n\n### best playground : http:\/\/setosa.io\/ev\/image-kernels\/","de29d46f":"\n\n\n\nTo reiterate the steps in performing an image convolution\n\n1. take the pixel representation of the original image\n\n2. decide on a kernel matrix and flip it horizontally as well as vertically\n\n3. perform padding on the original matrix.\n\n4. decide on a slide\n\n5. calculate the output image matrix based on the dimensions in 1,2,3 and 4.\n\n6. slide the kernel on the original image and calculate the weighted sum to get the output image\n\n\n<br>\n\n###### We will now take a look at the python code for each of these operations. We would compare our python code with the already available methods in industry accepted packages such as numpy , scipy, etc","f251b056":"#### Lets see if we can develop the intuition for convolution on image processing","f665c778":"<br><br>","5c282a37":"### Lets write python code for the above operations and proof our conclusions","36714fe6":"<br>"}}