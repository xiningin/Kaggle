{"cell_type":{"19d6dd50":"code","9d9b86d9":"code","d901620f":"code","278bb66a":"code","b3216ffe":"code","74fc9bd2":"code","c5893b10":"code","654949dc":"code","aec01b2c":"code","77ea1214":"code","9c8f7319":"code","ade74c6f":"code","ab3c7eb3":"code","1c3f8f8c":"code","ffa0dfe6":"code","0e0ea228":"code","29231bab":"code","87cc17b0":"code","c336cd67":"code","97a5160e":"code","936068e4":"code","cec600ad":"code","f9b287e1":"code","de8f5b2a":"code","caf5d175":"code","be168ae1":"code","2788b630":"code","541f4a59":"code","280d17f8":"code","3dd8ab61":"code","fde46765":"code","e995993e":"code","9bbb1717":"markdown","0004811d":"markdown","e3d58b69":"markdown","21d777be":"markdown","4e6b0cb8":"markdown","7c70fb32":"markdown","64c29f3d":"markdown","c181d4a2":"markdown","8485db0b":"markdown","28e4f241":"markdown","30bcfab6":"markdown","570ef28a":"markdown","bd86abbd":"markdown","602e1018":"markdown","c8c037d6":"markdown","b6d18138":"markdown","57dedb77":"markdown","8d98ac82":"markdown","22993783":"markdown","1344c2a7":"markdown","60bb2e1e":"markdown","68cd9f59":"markdown","e7d1d20b":"markdown","08d1f1a4":"markdown","26a12954":"markdown","ad187a38":"markdown","9678790e":"markdown","346e989c":"markdown","b3e48205":"markdown","bd429d58":"markdown","36381939":"markdown","2383202e":"markdown","40e048f7":"markdown","2278a455":"markdown","dbab1048":"markdown"},"source":{"19d6dd50":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \nfrom PIL import Image\nfrom PIL.ExifTags import TAGS, GPSTAGS\nfrom urllib import request\nfrom io import BytesIO\n%matplotlib inline ","9d9b86d9":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')","d901620f":"print(\"Train data shape -  rows:\",train_df.shape[0],\" columns:\", train_df.shape[1])\nprint(\"Test data size -  rows:\",test_df.shape[0],\" columns:\", test_df.shape[1])","278bb66a":"train_df.head()","b3216ffe":"test_df.head()","74fc9bd2":"submission.head()","c5893b10":"# missing data in training data set\nmissing = train_df.isnull().sum()\nall_val = train_df.count()\n\nmissing_train_df = pd.concat([missing, all_val], axis=1, keys=['Missing', 'All'])\nmissing_train_df","654949dc":"# missing data in training data set\nmissing = test_df.isnull().sum()\nall_val = test_df.count()\n\nmissing_test_df = pd.concat([missing, all_val], axis=1, keys=['Missing', 'All'])\nmissing_test_df","aec01b2c":"train_df.nunique()","77ea1214":"test_df.nunique()","9c8f7319":"# concatenate train and test datasets\nconcatenated = pd.concat([train_df, test_df])\n# print the shape of the resulted data.frame\nconcatenated.shape","ade74c6f":"concatenated.nunique()","ab3c7eb3":"plt.figure(figsize = (8, 8))\nplt.title('Landmark id density plot')\nsns.kdeplot(train_df['landmark_id'], color=\"tomato\", shade=True)\nplt.show()","1c3f8f8c":"plt.figure(figsize = (8, 8))\nplt.title('Landmark id distribuition and density plot')\nsns.distplot(train_df['landmark_id'],color='green', kde=True,bins=100)\nplt.show()","ffa0dfe6":"th10 = pd.DataFrame(train_df.landmark_id.value_counts().head(10))\nth10.reset_index(level=0, inplace=True)\nth10.columns = ['landmark_id','count']\nth10","0e0ea228":"# Plot the most frequent landmark occurences\nplt.figure(figsize = (6, 6))\nplt.title('Most frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=th10,\n            label=\"Count\", color=\"darkgreen\")\nplt.show()","29231bab":"tb10 = pd.DataFrame(train_df.landmark_id.value_counts().tail(10))\ntb10.reset_index(level=0, inplace=True)\ntb10.columns = ['landmark_id','count']\ntb10","87cc17b0":"# Plot the least frequent landmark occurences\nplt.figure(figsize = (6,6))\nplt.title('Least frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=tb10,\n            label=\"Count\", color=\"orange\")\nplt.show()","c336cd67":"# Extract repositories names for train data\nll = list()\nfor path in train_df['url']:\n    ll.append((path.split('\/\/', 1)[1]).split('\/', 1)[0])\ntrain_df['site'] = ll\n# Extract repositories names for test data\nll = list()\nfor path in test_df['url']:\n    ll.append((path.split('\/\/', 1)[1]).split('\/', 1)[0])\ntest_df['site'] = ll","97a5160e":"print(\"Train data shape -  rows:\",train_df.shape[0],\" columns:\", train_df.shape[1])\nprint(\"Test data size -  rows:\",test_df.shape[0],\" columns:\", test_df.shape[1])","936068e4":"train_df.head()","cec600ad":"test_df.head()","f9b287e1":"train_site = pd.DataFrame(train_df.site.value_counts())\ntest_site = pd.DataFrame(test_df.site.value_counts())","de8f5b2a":"train_site","caf5d175":"# Plot the site occurences in the train dataset\ntrsite = pd.DataFrame(list(train_site.index),train_site['site'])\ntrsite.reset_index(level=0, inplace=True)\ntrsite.columns = ['Count','Site']\nplt.figure(figsize = (6,6))\nplt.title('Sites storing images - train dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x = 'Site', y=\"Count\", data=trsite, color=\"blue\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","be168ae1":"test_site","2788b630":"# Plot the site occurences in the test dataset\ntesite = pd.DataFrame(list(test_site.index),test_site['site'])\ntesite.reset_index(level=0, inplace=True)\ntesite.columns = ['Count','Site']\nplt.figure(figsize = (6,6))\nplt.title('Sites storing images - test dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x = 'Site', y=\"Count\", data=tesite, color=\"magenta\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","541f4a59":"def displayLandmarkImages(urls):\n    \n    imageStyle = \"height: 60px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' \/>\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))\n    \n    \ndef displayLandmarkImagesLarge(urls):\n    \n    imageStyle = \"height: 100px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' \/>\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))","280d17f8":"IMAGES_NUMBER = 50\nlandmarkId = train_df['landmark_id'].value_counts().keys()[5]\nurls = train_df[train_df['landmark_id'] == landmarkId]['url'].head(IMAGES_NUMBER)\ndisplayLandmarkImages(urls)","3dd8ab61":"LANDMARK_NUMBER = 5\nIMAGES_NUMBER = 5\nlandMarkIDs = pd.Series(train_df['landmark_id'].value_counts().keys())[1:LANDMARK_NUMBER+1]\nfor landMarkID in landMarkIDs:\n    url = train_df[train_df['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n    displayLandmarkImagesLarge(url)\n","fde46765":"\nclass ImageMetaData(object):\n    '''\n    Extract the exif data from any image. Data includes GPS coordinates, \n    Focal Length, Manufacture, and more.\n    '''\n    exif_data = None\n    image = None\n\n    def __init__(self, img_path):\n        \n        response = request.urlopen(url)\n        image_data = response.read()\n        self.image = Image.open(BytesIO(image_data))\n        self.get_exif_data()\n        super(ImageMetaData, self).__init__()\n\n    def get_exif_data(self):\n        \"\"\"Returns a dictionary from the exif data of an PIL Image item. Also converts the GPS Tags\"\"\"\n        exif_data = {}\n        info = self.image._getexif()\n        if info:\n            for tag, value in info.items():\n                decoded = TAGS.get(tag, tag)\n                if decoded == \"GPSInfo\":\n                    gps_data = {}\n                    for t in value:\n                        sub_decoded = GPSTAGS.get(t, t)\n                        gps_data[sub_decoded] = value[t]\n\n                    exif_data[decoded] = gps_data\n                else:\n                    exif_data[decoded] = value\n        self.exif_data = exif_data\n        return exif_data\n\n    def get_if_exist(self, data, key):\n        if key in data:\n            return data[key]\n        return None\n\n    def convert_to_degress(self, value):\n\n        \"\"\"Helper function to convert the GPS coordinates \n        stored in the EXIF to degress in float format\"\"\"\n        d0 = value[0][0]\n        d1 = value[0][1]\n        d = float(d0) \/ float(d1)\n\n        m0 = value[1][0]\n        m1 = value[1][1]\n        m = float(m0) \/ float(m1)\n\n        s0 = value[2][0]\n        s1 = value[2][1]\n        s = float(s0) \/ float(s1)\n\n        return d + (m \/ 60.0) + (s \/ 3600.0)\n\n    def get_lat_lng(self):\n        \"\"\"Returns the latitude and longitude, if available, from the provided exif_data (obtained through get_exif_data above)\"\"\"\n        lat = None\n        lng = None\n        exif_data = self.get_exif_data()\n        #print(exif_data)\n        if \"GPSInfo\" in exif_data:      \n            gps_info = exif_data[\"GPSInfo\"]\n            gps_latitude = self.get_if_exist(gps_info, \"GPSLatitude\")\n            gps_latitude_ref = self.get_if_exist(gps_info, 'GPSLatitudeRef')\n            gps_longitude = self.get_if_exist(gps_info, 'GPSLongitude')\n            gps_longitude_ref = self.get_if_exist(gps_info, 'GPSLongitudeRef')\n            if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n                lat = self.convert_to_degress(gps_latitude)\n                if gps_latitude_ref != \"N\":                     \n                    lat = 0 - lat\n                lng = self.convert_to_degress(gps_longitude)\n                if gps_longitude_ref != \"E\":\n                    lng = 0 - lng\n        return lat, lng\n    \n    \n","e995993e":"# take the most frequent label\nfreq_label = train_df['landmark_id'].value_counts()\/train_df['landmark_id'].value_counts().sum()\n\n# submit the most freq label\nsubmission['landmarks'] = '%d %2.2f' % (freq_label.index[0], freq_label.values[0])\nsubmission.to_csv('submission.csv', index=False)\n\nnp.random.seed(2018)\nr_idx = lambda : np.random.choice(freq_label.index, p = freq_label.values)\n\nr_score = lambda idx: '%d %2.4f' % (freq_label.index[idx], freq_label.values[idx])\nsubmission['landmarks'] = submission.id.map(lambda _: r_score(r_idx()))\nsubmission.to_csv('rand_submission.csv', index=False)","9bbb1717":"#  <a id=\"9\">References<\/a>\n\n\n[1] Max Diebold, Simple exploration of Google Recognition,  https:\/\/www.kaggle.com\/mxdbld\/simple-exploration-of-google-recognition  \n[2] Ashok LathwalI, Introduction and overview,   https:\/\/www.kaggle.com\/codename007\/introduction-and-overview   \n[3] Extract GPS & Exif Data from Images using Python, https:\/\/www.codingforentrepreneurs.com\/blog\/extract-gps-exif-images-python\/  \n[4] Python3 Dataset Downloader with progress bar, https:\/\/www.kaggle.com\/anokas\/python3-dataset-downloader-with-progress-bar  \n[5] Kevin Mader, Baseline Landmark Model, https:\/\/www.kaggle.com\/kmader\/baseline-landmark-model  \n\n","0004811d":"We can observe that most of the images in the test dataset are stored on one site, *lh3.googleusercontent.com*, which is also the one with most content stored for train dataset.\nLet's look now to the images.","e3d58b69":"# <a id=\"2\">Load packages<\/a>","21d777be":"# <a id=\"3\">Read the data <\/a>","4e6b0cb8":"Let's look now to the most frequent landmarks in the train set and also to the least frequent landmarks.","7c70fb32":"Test set has two columns, first being an id for the image, the second being an url for the image.","64c29f3d":"# <a id=\"6\">Image thumbnails<\/a>\n\nLet's inspect also the images. We create a function to display a certain number of images, giving a list of images urls. We show here a number of `50` images of the `Petronas Twin Towers` in Kuala Lumpur, which is the 5th ranged landmark in the selection of landmarks, based on number of occurences.\n\nWe will define two functions to display landmarks.\n","c181d4a2":"Least frequent landmarks have only one occurence in the train dataset.","8485db0b":"## Glimpse the data\n\nLet's inspect the train and test sets","28e4f241":"# <a id=\"7\">Extracting Exif data and GPS data<\/a>\n\nWe will not be able to use the following code with this Kernel (feel free to download it) because there are some missing libraries support. It is not actually allowed to stream image data (we are allowed to display images, thought) on Kaggle so two libraries that will help us to do this are missing. The original code is from Reference [3] with a small correction for the way the image data taken from [Anokas](https:\/\/www.kaggle.com\/anokas)'s Kernel (Reference [4]).","30bcfab6":"#  <a id=\"8\">Baseline submission<\/a>\n\nWe are using a random guess, normalized by the frequency in the training set to prepare a submission file. The solution is picked up from Kevin Mader's Kernel, [Baseline Landmark Model](ttps:\/\/www.kaggle.com\/kmader\/baseline-landmark-model).\n","570ef28a":"Let's see now the expected format for the submission file","bd86abbd":"Submission has two columns, first being an id for the image, the second being the landmark. This has two elements: an landmark id that is associated with the image and its corresponding confidence score. Some query images may contain no landmarks. For these, one can submit no landmark id (and no confidence score).","602e1018":"The sites in train data are:","c8c037d6":"We can see that we do not have any missing values (null values) in the test data\n\n\n## Unique values\n\nLet's inspect the train and test data to check now many unique values are\n","b6d18138":"# <a id=\"4\">Inspect the data<\/a>","57dedb77":"Let's visualize now 5 images for each of the first 5 landmarks, ordered by the number of occurences.","8d98ac82":"Let's check the shape again for train and test datasets.","22993783":"# <a id=\"5\">Image paths<\/a>\n\nLet's check the image paths. When we first analyzed the images, we noticed that there are just few main repositories used. Let's try now to find the names of these repositories.","1344c2a7":"We see that we do not have any missing values (null values) in the training data\n\n### Test data quality\n\nLet's see if we do have missing values in the test set","60bb2e1e":"Let's represent the same data as a density plot","68cd9f59":"# <a id=\"1\">Introduction<\/a>\n\nThis Kernel explore the **train** and **test** datasets from [Google Landmark Recognition Challenge](https:\/\/www.kaggle.com\/c\/landmark-recognition-challenge). References [1-2] were used as a starting point for this Kernel. As the images in the datasets will have to be downloaded in order to conduct an analysis on the images itselfs, the Kernel is not covering the image analysis part. We include code (from Reference [3]) that will allow one competitor to retrieve tags informations from the url images.   \n\nPlease feel free to **fork and further develop** this Kernel.   \n\n<img src=\"http:\/\/lh4.ggpht.com\/-Szw4nwa8izg\/StLpb6miB4I\/AAAAAAAAAJk\/cDTWbVgI4Lg\/s1600\/\" width=800><\/img>\n","e7d1d20b":"We added to train and test data sets one more column, `site`, storing the name of the image repository. Let's also glimpse the train and test again, to check on the new column values.","08d1f1a4":"Let's group now on `site` name. We process both the train and test data.","26a12954":"All id's and url's are unique in the test data as well. Let's now check if we do have any id's or url's that are in both train and test set. ","ad187a38":"## Retrieve metadata example\n\nHere is an example of usage of the ImageMetaData function.\n\n> meta_data =  ImageMetaData(urls.head(1))  \n> latlng =meta_data.get_lat_lng()  \n> print(latlng)  \n> exif_data = meta_data.get_exif_data()  \n> print(exif_data)  \n","9678790e":"We can observe that most of the images in the train dataset are stored on 4 sites, *lh3.googleusercontent.com*, *lh4.googleusercontent.com*, *lh5.googleusercontent.com* and *lh6.googleusercontent.com*.\n\nThe sites in test dataset are:","346e989c":"Most frequent landmark has 50337 apparitions in train dataset.","b3e48205":"In the train dataset, there are only 14951 unique landmark_id data. All id's and url's are unique. \n\nLet's see now the test data to check now many unique values are","bd429d58":"<h1><center><font size=\"6\">Google Landmark Recogn. Challenge Data Exploration<\/font><\/center><\/h1>\n\n\n<img src=\"https:\/\/kaggle2.blob.core.windows.net\/competitions\/kaggle\/7456\/logos\/thumb76_76.png\" width=\"600\"><\/img>\n\n<a id='0'>Content<\/a>\n- <a href='#1'>Introduction<\/a>\n- <a href='#2'>Load packages<\/a>\n- <a href='#3'>Read the data<\/a>\n- <a href='#4'>Inspect the data<\/a>\n- <a href='#5'>Image paths<\/a>\n- <a href='#6'>Image thumbnails<\/a>\n- <a href='#7'>Extracting Exif data and GPS data<\/a>\n- <a href='#8'>Baseline submission<\/a>\n- <a href='#9'>References<\/a>","36381939":"Train set has three columns, first being an id for the image, the second being an url for the image and the third the id of the landmark associated with the image.","2383202e":"## Landmarks\n\nWe already know how many distincts landmarks there are in the train set. Let's inspect now how many occurences are for these landscapes in the train set.","40e048f7":"## Data quality\n\nLet's look into more details to the data quality\n\n\n### Train data quality\n\nLet's see if we do have missing values in the training set","2278a455":"## Data shape","dbab1048":"All id's and url's are unique for the concatenated data. That means we do not have any id's or url's from train dataset leaked in the test data set as well."}}