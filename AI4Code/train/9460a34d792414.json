{"cell_type":{"7cdd0973":"code","92a0bd9b":"code","77990f58":"code","216ea83c":"code","92bd8fed":"code","f0b0c24c":"code","3f919fab":"code","ac12277c":"code","acb4d489":"markdown","1800f155":"markdown"},"source":{"7cdd0973":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92a0bd9b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport argparse\nimport xml.etree.ElementTree as et\nimport re\nimport glob\nimport cv2\nimport random as rand","77990f58":"#parsing data in a csv format\n\ndic = {\"image\": [],\"Dimensions\": []}\nfor i in range(1,116):\n    dic[f'Object {i}']=[]\n\nfor file in os.listdir(\"\/kaggle\/input\/face-mask-detection\/annotations\"):\n    row = []\n    xml = et.parse(\"\/kaggle\/input\/face-mask-detection\/annotations\/\"+ file) \n    root = xml.getroot()\n    img = root[1].text\n    row.append(img)\n    h,w = root[2][0].text,root[2][1].text\n    row.append([h,w])\n\n    for i in range(4,len(root)):\n        temp = []\n        temp.append(root[i][0].text)\n        for point in root[i][5]:\n            temp.append(point.text)\n        row.append(temp)\n        \n    for i in range(len(row),119):\n        row.append(0)\n        \n    for i,each in enumerate(dic):\n        dic[each].append(row[i])\n        \ndf = pd.DataFrame(dic)\ndf.head()","216ea83c":"image_directories = sorted(glob.glob(os.path.join(\"\/kaggle\/input\/face-mask-detection\/images\",\"*.png\")))\nj=0\nclasses = [\"without_mask\",\"mask_weared_incorrect\",\"with_mask\"]\nlabels = []\ndata = []\n\nfor idx,image in enumerate(image_directories):\n    img  = cv2.imread(image)\n    #scale to dimension\n    X,Y = df[\"Dimensions\"][idx]\n    cv2.resize(img,(int(X),int(Y)))\n    #find the face in each object\n    for obj in df.columns[3:]:\n        info = df[obj][idx]\n        if info!=0:\n            label = info[0]\n            info[0] = info[0].replace(str(label), str(classes.index(label)))\n            info=[int(each) for each in info]\n            face = img[info[2]:info[4],info[1]:info[3]]\n            if((info[3]-info[1])>40 and (info[4]-info[2])>40):\n                try:\n                    face = cv2.resize(face, (224, 224))\n                    face = img_to_array(face)\n                    face = preprocess_input(face)\n                    data.append(face)\n                    labels.append(label)\n                    if(label==\"mask_weared_incorrect\"):\n                        data.append(face)\n                        labels.append(label)\n\n                except:\n                    pass\n                \ndata = np.array(data, dtype=\"float32\")\nlabels = np.array(labels)\n","92bd8fed":"#one-hot encoding on the labels\nlb = LabelEncoder()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n\n#train-test split\n(trainX, testX, trainY, testY) = train_test_split(data, labels,\n    test_size=0.25, stratify=labels, random_state=42)\n\n#hyperparameters\nilr = 1e-4\nep = 40\nbs = 32\n\n#training image gen for augmentation\naug = ImageDataGenerator(\n    zoom_range=0.2,\n    rotation_range=25,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n    )\n\n","f0b0c24c":"#loading MobileNetV2 network for fine-tuning\nbaseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n    input_tensor=Input(shape=(224, 224, 3)))\n\n#contruct headModel that will be on top of the baseModel\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(3, activation=\"softmax\")(headModel)\n\n#consruct the actual trainable model\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n#loop base layers to freeze them (they won't be updated during the initial training process)\nfor layer in baseModel.layers:\n    layer.trainable = False","3f919fab":"# compile model\nopt = Adam(lr = ilr, decay = ilr \/ ep)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n\n# train the head of the network\nH = model.fit(\n    aug.flow(trainX, trainY, batch_size=bs),\n    steps_per_epoch=len(trainX) \/\/ bs,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ bs,\n    epochs=ep)","ac12277c":"predIdxs = model.predict(testX, batch_size = bs)\npredIdxs = np.argmax(predIdxs, axis = 1)\n\n#classification report\nprint(classification_report(testY.argmax(axis = 1), predIdxs,\n    target_names = lb.classes_))\n\n#plot\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, ep), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, ep), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, ep), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, ep), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss & Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower right\")\nplt.savefig(args[\"plot\"])","acb4d489":"At first, we import the necessary modules so that we can train a mask detector. ","1800f155":"We initialize some initial hyperparameters."}}