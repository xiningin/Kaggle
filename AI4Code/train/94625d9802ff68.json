{"cell_type":{"526e14a6":"code","b61279b3":"code","b1ff9086":"code","520ab7b7":"code","b0d4bc9e":"code","9b0cc262":"code","e002fe30":"code","46fc7c1a":"code","aa2101d3":"code","88c982cc":"code","4bc60b0b":"code","ef3cb21d":"code","de59dc49":"code","aab4175c":"code","ed2f5f93":"code","f5dc0856":"code","b9350742":"code","01619d35":"code","491111e3":"code","1603fe36":"code","5483e890":"code","65f8f6c4":"code","0c126a33":"code","8b0f63d1":"code","2452113f":"markdown","6db693f3":"markdown","289005d6":"markdown","2bbc802f":"markdown","39bba991":"markdown","da31ce11":"markdown","15c971e9":"markdown","d828659e":"markdown","ffdb6dd0":"markdown","27025202":"markdown","cc34ff51":"markdown","b1ac3454":"markdown","ae3c0ff4":"markdown","c786156d":"markdown","f24d2774":"markdown"},"source":{"526e14a6":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing","b61279b3":"housing = pd.read_csv('..\/input\/housing.csv')\n\ntrain,test = train_test_split(housing,test_size=0.20,random_state=42)","b1ff9086":"train.head()","520ab7b7":"train = train.drop('ocean_proximity',axis=1)\ntest = test.drop('ocean_proximity',axis=1)\n\ntrain.head()","b0d4bc9e":"x_train = train.drop('median_house_value',axis=1)","9b0cc262":"y_train = train.median_house_value","e002fe30":"x_train.head()","46fc7c1a":"y_train.head()","aa2101d3":"# first import the function from scikit-learn\nfrom sklearn.linear_model import LinearRegression","88c982cc":"# create a new object of Linear Regression class\nmodel = LinearRegression()","4bc60b0b":"# fitting the model = finding the perfect line with minimum error\nmodel.fit(x_train,y_train)","ef3cb21d":"model.score(x_train,y_train)","de59dc49":"x_test = test.drop('median_house_value',axis=1)","aab4175c":"print(x_test.isnull().sum())","ed2f5f93":"x_test['total_bedrooms'] = x_test['total_bedrooms'].fillna(x_test['total_bedrooms'].mean())\n\nprint(x_test.isnull().sum())","f5dc0856":"model.predict(x_test)","b9350742":"model.score(x_test,test.median_house_value)","01619d35":"from sklearn.ensemble import RandomForestRegressor","491111e3":"my_new_model = RandomForestRegressor()","1603fe36":"my_new_model.fit(x_train,y_train)","5483e890":"my_new_model.score(x_train,y_train)","65f8f6c4":"output = my_new_model.predict(x_test)","0c126a33":"my_new_model.score(x_test,test.median_house_value)","8b0f63d1":"# output_csv = pd.DataFrame({'Label':output})\n\n# output_csv.to_csv('output.csv',index=False)","2452113f":"# Linear Regression on California Housing Dataset.\nLets do linear regression on an actual dataset.","6db693f3":"Now we have two dataset, train and test. We always need to split our data into train and test. We will train the model with the train dataset and then test its accuracy with the test dataset.","289005d6":"## Our model have 64% training accuracy and 61% testing accuracy.","2bbc802f":"And with that, we trained out first machine learning model!","39bba991":"We are going to use a library known as scikit-learn. It is a high level library where many popular machine learning algorithms are available as off the shelf functions. This makes it more easier to use than standard frameworks like TensorFlow or Keras. ","da31ce11":"### But how can we increase the accuracy of the model? There are several methods, known as Hyperparameter Tuning, which can go deep into later on. For now, we can try using another technique than just simple Linear Regression. Let's try using an algorithm called 'Random Forest Regression'","15c971e9":"### Now we can go on to train our model with x_train and y_train\n\n\n","d828659e":"Here you can see the first 5 samples of the data. We need to predict the 'mean house price' with the help of all other attributes. So here, our x will be all the attributes and y will be the price. So we are now gonna split the train dataset into x_train and y_train","ffdb6dd0":"### Here we are creating an ML model to predict the prices of houses at California.\nAs the california housing prices dataset are already availlable in colab as default, we can simply use them","27025202":"Now we import the datasets which are given in the sample_data folder. (Check the left menu for folders)","cc34ff51":"And that's 96% accuracy of the model's values with the actual values. This means that the model passes through 96% of the actual data points!!","b1ac3454":"But it has only an accuracy of 64% But what does this really mean?\nIf we inspect the test dataset, we can see that it includes the median_house_value that we need to predict. So we can split the dataset into only its attributes, put it into our model to predict the values and then compare the original median house price with what our model predicted. This will be 64% accurate.","ae3c0ff4":"First we import the basic matheatical and statistical packages","c786156d":"These are the house prices that our model predicted. Now lets look at the actual prices which were given in the dataset.","f24d2774":"As you might have noticed, the .head( ) function displays the first 5 elements in a DataFrame. A DataFrame is a table in pandas. Here as we read train and test with **pd.read_csv( )** function, they are pandas DataFrames. Its much similar to saying that they are Excel spreadsheets."}}