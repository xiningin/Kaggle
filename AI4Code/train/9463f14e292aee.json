{"cell_type":{"e960fbc5":"code","35df170a":"code","4a152896":"code","7edb7ad4":"code","996af3f4":"code","fafc99e0":"code","96d4664e":"code","451f1ab8":"code","580078d7":"code","4830dd82":"code","38644014":"code","7bb5cf6f":"markdown","136e3fda":"markdown","928c7d38":"markdown","4990e606":"markdown","6dba8e36":"markdown","f08317a6":"markdown","1be6f765":"markdown","3ea198d1":"markdown","88525a4d":"markdown","912f6666":"markdown","c54e7b25":"markdown","e206c965":"markdown","e094303d":"markdown","3d83715b":"markdown"},"source":{"e960fbc5":"import nltk\n\nimport warnings\nwarnings.filterwarnings('ignore')","35df170a":"from nltk.corpus import reuters\ntrain_documents, train_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training\/')])\ntest_documents, test_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test\/')])","4a152896":"from nltk.stem.porter import PorterStemmer\ndef tokenize(text):\n    tokens = nltk.word_tokenize(text)\n    stems = []\n    for item in tokens:\n        stems.append(PorterStemmer().stem(item))\n    return stems","7edb7ad4":"%%time\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(tokenizer = tokenize, stop_words = 'english')\n\nvectorised_train_documents = vectorizer.fit_transform(train_documents)\nvectorised_test_documents = vectorizer.transform(test_documents)","996af3f4":"from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ntrain_labels = mlb.fit_transform(train_categories)\ntest_labels = mlb.transform(test_categories)","fafc99e0":"%%time\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\n\nclassifier = OneVsRestClassifier(LinearSVC())\nclassifier.fit(vectorised_train_documents, train_labels)","96d4664e":"%%time\nfrom sklearn.model_selection import KFold, cross_val_score\n\nkf = KFold(n_splits=10, random_state = 42, shuffle = True)\nscores = cross_val_score(classifier, vectorised_train_documents, train_labels, cv = kf)","451f1ab8":"print('Cross-validation scores:', scores)\nprint('Cross-validation accuracy: {:.4f} (+\/- {:.4f})'.format(scores.mean(), scores.std() * 2))","580078d7":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\npredictions = classifier.predict(vectorised_test_documents)\n\naccuracy = accuracy_score(test_labels, predictions)\n\nmacro_precision = precision_score(test_labels, predictions, average='macro')\nmacro_recall = recall_score(test_labels, predictions, average='macro')\nmacro_f1 = f1_score(test_labels, predictions, average='macro')\n\nmicro_precision = precision_score(test_labels, predictions, average='micro')\nmicro_recall = recall_score(test_labels, predictions, average='micro')\nmicro_f1 = f1_score(test_labels, predictions, average='micro')\n\ncm = confusion_matrix(test_labels.argmax(axis = 1), predictions.argmax(axis = 1))","4830dd82":"print(\"Accuracy: {:.4f}\\nPrecision:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nRecall:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nF1-measure:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\".format(accuracy, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))","38644014":"import matplotlib.pyplot as plt\nimport seaborn as sb\nimport pandas as pd\n\ncm_plt = pd.DataFrame(cm[:73])\n\nplt.figure(figsize = (25, 25))\nax = plt.axes()\n\nsb.heatmap(cm_plt, annot=True)\n\nax.xaxis.set_ticks_position('top')\n\nplt.show()","7bb5cf6f":"To begin, I first used TF-IDF for feature selection on both train as well as test data using `TfidfVectorizer`.\n\nBut first, What `TfidfVectorizer` actually does?\n- `TfidfVectorizer` converts a collection of raw documents to a matrix of **TF-IDF** features.\n\n**TF-IDF**?\n- TFIDF (abbreviation of the term *frequency\u2013inverse document frequency*) is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. [tf\u2013idf](https:\/\/en.wikipedia.org\/wiki\/Tf%E2%80%93idf)\n\n**Why `TfidfVectorizer`**?\n- `TfidfVectorizer` scale down the impact of tokens that occur very frequently (e.g., \u201ca\u201d, \u201cthe\u201d, and \u201cof\u201d) in a given corpus. [Feature Extraction and Transformation](https:\/\/spark.apache.org\/docs\/latest\/mllib-feature-extraction.html#tf-idf)\n\nI gave following two arguments to `TfidfVectorizer`:\n- tokenizer: `tokenize` function\n- stop_words\n\nThen I used `fit_transform` and `transform` on the train and test documents repectively.\n\n**Why `fit_transform` for training data while `transform` for test data**?\n\nTo avoid data leakage during cross-validation, imputer computes the statistic on the train data during the `fit`, **stores it** and uses the same on the test data, during the `transform`. This also prevents the test data from appearing in `fit` operation.","136e3fda":"Now, To **train** the classifier, I used `LinearSVC` in combination with the `OneVsRestClassifier` function in the scikit-learn package.\n\nThe strategy of `OneVsRestClassifier` is of **fitting one classifier per label** and the `OneVsRestClassifier` can efficiently do this task and also outputs are easy to interpret. Since each label is represented by **one and only one classifier**, it is possible to gain knowledge about the label by inspecting its corresponding classifier. [OneVsRestClassifier](http:\/\/scikit-learn.org\/stable\/modules\/multiclass.html#one-vs-the-rest)\n\nThe reason I combined `LinearSVC` with `OneVsRestClassifier` is because `LinearSVC` supports **Multi-class**, while we want to perform **Multi-label** classification.","928c7d38":"# Training the model","4990e606":"# Evaluation","6dba8e36":"# MultiLabelBinarizer","f08317a6":"After fitting the classifier, I decided to use `cross_val_score` to **measure score** of the classifier by **cross validation** on the training data. But the only problem was, I wanted to **shuffle** data to use with `cross_val_score`, but it does not support shuffle argument.\n\nSo, I decided to use `KFold` with `cross_val_score` as `KFold` supports shuffling the data.\n\nI also enabled `random_state`, because `random_state` will guarantee the same output in each run. By setting the `random_state`, it is guaranteed that the pseudorandom number generator will generate the same sequence of random integers each time, which in turn will affect the split.\n\nWhy **42**?\n- [Why '42' is the preferred number when indicating something random?](https:\/\/softwareengineering.stackexchange.com\/questions\/507\/why-42-is-the-preferred-number-when-indicating-something-random)","1be6f765":"# TF-IDF","3ea198d1":"For the **efficient implementation** of machine learning algorithms, many machine learning algorithms **requires all input variables and output variables to be numeric**. This means that categorical data must be converted to a numerical form.\n\nFor this purpose, I used `MultiLabelBinarizer` from `sklearn.preprocessing`.","88525a4d":"# Setting up train\/test data","912f6666":"# Confusion Matrix","c54e7b25":"The following cell defines a function **tokenize** that performs following actions:\n- Receive a document as an argument to the function\n- Tokenize the document using `nltk.word_tokenize()`\n- Use `PorterStemmer` provided by the `nltk` to remove morphological affixes from each token\n- Append stemmed token to an already defined list `stems`\n- Return the list `stems`","e206c965":"In the end, I used different methods (`accuracy_score`, `precision_score`, `recall_score`, `f1_score` and `confusion_matrix`) provided by scikit-learn **to evaluate** the classifier. (both *Macro-* and *Micro-averages*)","e094303d":"In below cell, I used `matplotlib.pyplot` to **plot the confusion matrix** (of first *few results only* to keep the readings readable) using `heatmap` of `seaborn`.","3d83715b":"# Cross-Validation"}}