{"cell_type":{"a2c0de0e":"code","de896268":"code","965a5ea1":"code","11118826":"code","77a0d765":"code","ab77d40f":"code","a69ced7b":"code","5efc3b4a":"code","006788ac":"code","3e188efe":"code","213ea9a9":"code","fcbedc14":"code","f94a32e4":"code","41d0905e":"code","c1af5e40":"code","f596a88c":"code","72dd8550":"code","ddbc1998":"code","d2fd6b32":"markdown","e7748d9f":"markdown"},"source":{"a2c0de0e":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport cv2\nfrom os import listdir\nfrom os.path import isfile, join\nimport yaml","de896268":"import torch\nfrom IPython.display import Image, clear_output","965a5ea1":"# shutil.copytree, essential but can run only once\nif  'yolov5' in os.listdir('\/kaggle\/working\/'):\n    print('WOW')\nelse:\n    shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5') ","11118826":"os.chdir('\/kaggle\/working\/yolov5')\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","77a0d765":"os.listdir('\/kaggle\/working\/')","ab77d40f":"# shutil.copytree, essential but can run only once\nif 'sample1' in os.listdir('\/kaggle\/working\/'):\n    print('exist1')\nelse:\n    shutil.copytree('\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/0001', '\/kaggle\/working\/sample1')","a69ced7b":"if 'sample2' in os.listdir('\/kaggle\/working\/'):\n    print('exist2')\nelse:    \n    shutil.copytree('\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/0002', '\/kaggle\/working\/sample2')","5efc3b4a":"if 'sample3' in os.listdir('\/kaggle\/working\/'):\n    print('exist3')\nelse:    \n    shutil.copytree('\/kaggle\/input\/cat-individuals\/cat_individuals_dataset\/0003','\/kaggle\/working\/sample3')","006788ac":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ..\/sample1\/\n!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ..\/sample2\/\n!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ..\/sample3\/","3e188efe":"from matplotlib import animation, rc\nrc('animation', html='jshtml')","213ea9a9":"def create_animation(ims):\n    fig=plt.figure(figsize=(10,10))\n    plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[0],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000\/\/2)","fcbedc14":"imgdir1 ='\/kaggle\/working\/yolov5\/runs\/detect\/exp\/' \nimgdir2 ='\/kaggle\/working\/yolov5\/runs\/detect\/exp2\/' \nimgdir3 ='\/kaggle\/working\/yolov5\/runs\/detect\/exp3\/' ","f94a32e4":"paths0=[]\nfor dirname, _, filenames in os.walk(imgdir1):\n    for filename in filenames:\n        paths0+=[os.path.join(dirname, filename)]\nfor dirname, _, filenames in os.walk(imgdir2):\n    for filename in filenames:\n        paths0+=[os.path.join(dirname, filename)]        \nfor dirname, _, filenames in os.walk(imgdir3):\n    for filename in filenames:\n        paths0+=[os.path.join(dirname, filename)]            \npaths0","41d0905e":"paths1=[]\nfor item in paths0:\n    if item[-4:]=='.JPG':\n        paths1+=[item]\npaths1[0:5]","c1af5e40":"order=[]\nfor item in paths1:\n    order+=[(item[0:-4].split('\/')[-1])]\npaths2=pd.DataFrame(paths1)\npaths2[1]=order\npaths2.columns=['path','int']\npaths2=paths2.sort_values('int')\npaths3=paths2['path'].tolist()\npaths3","f596a88c":"images0=[]\nfor i in tqdm(range(0,len(paths3),1)):\n    images0+=[cv2.imread(paths3[i])]","72dd8550":"print(len(images0))","ddbc1998":"create_animation(np.array(images0))","d2fd6b32":"# YOLOv5","e7748d9f":"# Create animation"}}