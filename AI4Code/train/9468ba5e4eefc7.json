{"cell_type":{"b5a6c4b0":"code","d5dc8e88":"code","0cdbad8c":"code","38a3acac":"code","967f5d02":"code","83fd4880":"code","e1c682c6":"code","ee1c6cc2":"code","a492dd5d":"code","7495cdcc":"code","0a3e42e1":"code","3d28a1ea":"code","ed455ab8":"code","1fc8bac5":"code","3c01141b":"code","d7622073":"markdown","dafaef65":"markdown"},"source":{"b5a6c4b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nr = plt.imread\ndef p(x):plt.imshow(x);plt.show()\n    \nimport math\ndef subplotter(img_list,ncols=6,figsize=14,names=None):\n    nrows= math.ceil(len(img_list)\/ncols)\n    \n    plt.figure(figsize=(figsize,figsize))\n    for i,img in enumerate(img_list):\n        plt.subplot(nrows,ncols,i+1)\n        plt.imshow(img)\n        if names:plt.title(names[i])\n    plt.show()\n    \nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5dc8e88":"df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.head()","0cdbad8c":"df['label'].value_counts()","38a3acac":"df['label'].unique()","967f5d02":"img_dir='\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/'\nnum_imgs=42\n\nfor e in df['label'].unique():\n    print(e)\n    small_df=df[df.label==e].sample(frac=1)\n    img_list=[];name_list=[]\n    for i in range(num_imgs):\n        img_name=small_df.iloc[i]['image_id']\n        img_list.append(r(img_dir+img_name))\n        name_list.append(img_name.split('.')[0])\n    subplotter(img_list,names=name_list,figsize=28)\n        \n        ","83fd4880":"!pip install timm\n!pip install pytorch-lightning\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torch, timm\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom pytorch_lightning.loggers import TensorBoardLogger\n","e1c682c6":"class PlantLoader(Dataset):\n    def __init__(self, img_names,targets, transform=None):\n        self.img_names=img_names\n        self.targets=targets\n        self.transform=transform\n        self.img_dir='\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/'\n    def __len__(self):\n        return len(self.img_names)\n    def __getitem__(self, idx):\n        \n        img_name=self.img_names[idx]\n        label=int(self.targets[idx])\n        \n        image=r(img_dir+img_name)\n        \n        if self.transform: image = self.transform(image)\n            \n        return image,label\n","ee1c6cc2":"np.shape(df[df.label==2].iloc[1:200] )","a492dd5d":"from sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nnum_samples=2600 ; df_balanced=None\n\nfor e in df['label'].unique():\n    df_class = df[df.label==e].iloc[:num_samples]\n    \n    df_upsampled = resample(df_class, \n                                 replace=True,     # sample with replacement\n                                 n_samples=num_samples,    # to match majority class\n                                 random_state=123) # reproducible results\n \n\n    if df_balanced is None: df_balanced = df_upsampled\n    else: df_balanced = pd.concat([df_balanced, df_upsampled])\n \n\nprint(df_balanced['label'].value_counts() )\n\nX_train, X_test, y_train, y_test = train_test_split( df_balanced.image_id, df_balanced.label, test_size=0.2, random_state=42)\n\nprint(y_train.value_counts() )\nprint(y_test.value_counts() )\n","7495cdcc":"batch_size=32\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\ntrain_augs=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize ])\n\nval_augs=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.ToTensor(),\n            normalize ])\n\n\ndataset = PlantLoader(list(X_train),list(y_train),train_augs)\ntrain_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n\n\ndataset = PlantLoader(list(X_test),list(y_test),val_augs)\nval_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n","0a3e42e1":"for i, (images, target) in enumerate(train_dataloader):\n    print(torch.min(images),torch.max(images),target)\n    break","3d28a1ea":"class PlantModel(pl.LightningModule):\n\n    def __init__(self):\n        super(PlantModel, self).__init__()\n        self.model = timm.create_model('resnest26d', pretrained=True)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        loss = F.cross_entropy(self(x), y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n\n        # validation metrics\n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy(preds, y)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n        return loss\n    \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-3)","ed455ab8":"# lr finder\nplant_model = PlantModel()\ntrainer = pl.Trainer(gpus=1)\n\nlr_finder = trainer.tuner.lr_find(plant_model,train_dataloader=train_dataloader)\n\nfig = lr_finder.plot(suggest=True)\nfig.show()\n\n\nprint(lr_finder.suggestion())\n\n","1fc8bac5":"%load_ext tensorboard\n%tensorboard --logdir logs","3c01141b":"plant_model = PlantModel()\nlogger = TensorBoardLogger('tb_logs', name='my_model')\n\n\ntrainer = pl.Trainer(gpus=1, max_epochs=3, progress_bar_refresh_rate=20,logger=logger)\n\ntrainer.fit(plant_model, train_dataloader,val_dataloader)","d7622073":"# Trainer","dafaef65":"Images clicked in wide variety of lighting,angle,,number and position distribution. Differences betweeen classes is quite noticible"}}