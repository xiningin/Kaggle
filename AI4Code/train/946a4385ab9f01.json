{"cell_type":{"9effd3d8":"code","bd081326":"code","6f3eaa99":"code","ddbe3463":"code","ee46c6b3":"code","6a57b657":"code","51545014":"code","4cc1fb15":"code","bb2efc05":"code","e875933b":"code","0f2f1d2c":"code","76b333ab":"code","75b1989a":"code","71bda3d9":"code","684b2e3f":"code","894245f2":"code","ec0068fa":"code","effc7574":"code","89578d79":"code","d3e62ed4":"code","dd870ee7":"code","be3ec0d8":"code","37bd9455":"code","06ba3bea":"code","9174686e":"code","29548707":"code","049593c0":"code","6249e3e3":"code","406aea0a":"code","71b83c35":"code","e1344561":"code","43d387dd":"markdown","abbaf3ec":"markdown","5a81554b":"markdown","b5114902":"markdown","dc4c7d81":"markdown","d0a7c0d1":"markdown","5c1575fa":"markdown","29a1921e":"markdown","f239ac9e":"markdown","c7478cba":"markdown","5882e80c":"markdown"},"source":{"9effd3d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd081326":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom scipy.stats import norm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n","6f3eaa99":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ny_true = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","ddbe3463":"train_df.head(10)","ee46c6b3":"test_df.head(10)","6a57b657":"train_df.info()","51545014":"train_df['Sex'].replace({'male':0,'female':1},inplace=True)\ntrain_df['Embarked'].replace({'S':1,'C':2,'Q':3},inplace=True)\ntest_df['Sex'].replace({'male':0,'female':1},inplace=True)\ntest_df['Embarked'].replace({'S':1,'C':2,'Q':3},inplace=True)","4cc1fb15":"train_df['family']=train_df['SibSp']+train_df['Parch']+1\ndef family(size):\n    a=''\n    if(size<=1):\n        a=1    \n    elif(size<=2):\n        a=2    \n    elif(size<=4):\n        a=3    \n    elif(size<=6):\n        a=4   \n    else:\n        a=5   \n    return a\ntrain_df['family']=train_df['family'].map(family)","bb2efc05":"test_df['family']=test_df['SibSp']+test_df['Parch']+1\ndef family(size):\n    a=''\n    if(size<=1):\n        a=1    \n    elif(size<=2):\n        a=2    \n    elif(size<=4):\n        a=3    \n    elif(size<=6):\n        a=4   \n    else:\n        a=5   \n    return a\ntest_df['family']=test_df['family'].map(family)","e875933b":"train_df.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin'],axis=1,inplace=True)\n\ntest_df.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin'],axis=1,inplace=True)","0f2f1d2c":"train_df.isna().sum()","76b333ab":"# there are just two of missing values in this column, we can drop them.\n\ntrain_df.dropna(subset=['Embarked'], inplace=True)","75b1989a":"# replacing NaNs in age column by mean value of this column\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain_df[['Age']] = imputer.fit(train_df[['Age']]).transform(train_df[['Age']])","71bda3d9":"test_df.isna().sum()","684b2e3f":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntest_df[['Age']] = imputer.fit(test_df[['Age']]).transform(test_df[['Age']])","894245f2":"\nx_test[['Fare']] = imputer.fit(x_test[['Fare']]).transform(x_test[['Fare']])","ec0068fa":"train_df.hist(figsize=(12,8))\nplt.show()","effc7574":"fig,ax=plt.subplots(3,1,figsize=(15,13))\nsns.heatmap(train_df.corr('spearman'),cmap='Greys',annot=True,ax=ax[0],label='spearman')     \nsns.heatmap(train_df.corr('kendall'),cmap='Greys',annot=True,ax=ax[1],label='kendall')      \nsns.heatmap(train_df.corr('pearson'),cmap='Greys',annot=True,ax=ax[2],label='pearson')       ","89578d79":"sns.countplot(x='family',data=train_df,hue='Survived')  ","d3e62ed4":"sns.ecdfplot(x='Age',data=train_df,hue='Survived')\nplt.show()","dd870ee7":"# splitting x and y from train set\nx_train = train_df.drop('Survived', axis=1)\ny_train = train_df['Survived']","be3ec0d8":"x_test = test_df.copy()\n","37bd9455":"le = LabelEncoder()\nfor col in ['Embarked', 'Sex']:\n    x_test[col] = le.fit_transform(x_test[col])","06ba3bea":"def accuracy(y_true, y_pred):\n    acc = 0\n    acc = accuracy_score(y_true['Survived'], y_pred)\n    return acc","9174686e":"classifier = DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\nprint(accuracy(y_true, y_pred))","29548707":"classifier = LogisticRegression()\nclassifier.fit(x_train, y_train)\nchosen_y_pred = classifier.predict(x_test)\nprint(accuracy(y_true, chosen_y_pred))","049593c0":"classifier = RandomForestClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\nprint(accuracy(y_true, y_pred))","6249e3e3":"classifier = KNeighborsClassifier(n_neighbors=7)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\nprint(accuracy(y_true, y_pred))","406aea0a":"# classification report of logistic regression model\n\nprint(classification_report(y_true['Survived'], chosen_y_pred))","71b83c35":"output = pd.DataFrame({'PassengerId': y_true.PassengerId, 'Survived': chosen_y_pred})\noutput.to_csv('submission.csv', index=False)","e1344561":"output\n","43d387dd":"## Classification report","abbaf3ec":"### Random Forest","5a81554b":"## Classifiers","b5114902":"## DecisionTreeClassifier","dc4c7d81":"## visualization","d0a7c0d1":"## KNN","5c1575fa":"## LogisticRegression","29a1921e":"young children have high survival rate, and at age 30 stright line come due to data correction ","f239ac9e":"# Model prepration","c7478cba":"# Loading datasets","5882e80c":"# # improving train and test dataset"}}