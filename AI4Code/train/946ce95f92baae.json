{"cell_type":{"70d5d025":"code","094bcc79":"code","fc60ff85":"code","29bf605a":"code","4ec9a417":"code","54b04403":"code","7eb4f0c6":"code","37f943a6":"code","16ea57ba":"code","5d0d15a4":"code","bfd1e2c5":"code","63d2ca82":"code","f269bff5":"markdown","3aab471b":"markdown","779df939":"markdown","ac14eae7":"markdown","89610782":"markdown"},"source":{"70d5d025":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","094bcc79":"from PIL import Image\n\nimage = Image.open(\"..\/input\/cusersmarildownloads2oshltavtnq51jpg\/2oshltavtnq51.jpg\")\nimage","fc60ff85":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","29bf605a":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","4ec9a417":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/cusersmarildownloads2oshltavtnq51jpg\/2oshltavtnq51.jpg', loader_transform)","54b04403":"#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","7eb4f0c6":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('..\/input\/cusersmarildownloads2oshltavtnq51jpg\/2oshltavtnq51.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","37f943a6":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *","16ea57ba":"_,axs = subplots(1,2)\nshow_image(image, ctx=axs[0], title='original')\nshow_image(image.flip_lr(), ctx=axs[1], title='flipped');","5d0d15a4":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(image.crop_pad(sz), ctx=ax, title=f'Size {sz}');","bfd1e2c5":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,mode in zip(axs.flatten(), [PadMode.Zeros, PadMode.Border, PadMode.Reflection]):\n    show_image(image.crop_pad((600,700), pad_mode=mode), ctx=ax, title=mode);","63d2ca82":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml(\"Wearing a Mask Properly is a Sign of Respect. @mpwolke\" )","f269bff5":"<iframe width=\"857\" height=\"482\" src=\"https:\/\/www.youtube.com\/embed\/8ttH9s6cFG8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","3aab471b":"#Codes from docs.fastai","779df939":"#Well it's really not a mask if you wear it down around your chin, that's a CHIN DIAPER!","ac14eae7":"#Codes by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques","89610782":"<iframe width=\"857\" height=\"482\" src=\"https:\/\/www.youtube.com\/embed\/URF6c-JsygU\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>"}}