{"cell_type":{"05f656ef":"code","bef30201":"code","3b1b0f49":"code","94cbf119":"code","b6b606b0":"code","8bd3ce88":"code","a6ad62a5":"code","77c451c7":"code","cd6b48e9":"code","0ccf4b57":"code","4a3223e0":"code","6da173c3":"code","20383ccf":"code","772e2e6c":"code","77984d12":"code","a97d6b1b":"code","f42efc31":"code","e1cb931d":"code","61b71ae1":"code","5183139f":"code","90055201":"code","8b5e2216":"code","05beb616":"code","66e62677":"code","c9f2e974":"code","12e7e82a":"code","b7bfb028":"code","3ffc7f82":"code","52f035d0":"code","fb8530a5":"code","48d5cd0b":"code","d23b2382":"code","a9cd3400":"code","534fcf5a":"code","7e74d106":"code","0a77ef04":"code","058b6144":"code","b7c49d38":"code","c0704349":"code","67fae8ac":"code","8bf0fca1":"code","61f92494":"code","1fa98da6":"code","b7a6b16f":"code","e6b637ec":"code","628e1af3":"code","8c64a9af":"code","764cc480":"code","cec1a498":"code","43ba7a71":"code","dbdac351":"code","9e8051c6":"code","aeafae7b":"code","d647829f":"code","da25a911":"markdown","a466b408":"markdown","c92d5e3a":"markdown","686e70a0":"markdown","f8a2852b":"markdown","32b6645e":"markdown","7df09688":"markdown","652e25d7":"markdown","ba1f0514":"markdown","a2515346":"markdown"},"source":{"05f656ef":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","bef30201":"df = pd.read_csv('..\/input\/cancer-prediction\/Cancer_Dataset.csv')\ndf.head(10)","3b1b0f49":"df.shape","94cbf119":"df.columns","b6b606b0":"df.describe().T","8bd3ce88":"df_copy = df.copy(deep = True)\ndf_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(df_copy.isnull().sum())","a6ad62a5":"df_copy['BMI'].fillna(df_copy['BMI'].median(), inplace=True)\n\nprint(df_copy.isnull().sum())","77c451c7":"p = df.hist(figsize = (20,20))","cd6b48e9":"df_copy['Glucose'].fillna(df_copy['Glucose'].mean(), inplace = True)\ndf_copy['BloodPressure'].fillna(df_copy['BloodPressure'].mean(), inplace = True)\ndf_copy['SkinThickness'].fillna(df_copy['SkinThickness'].median(), inplace = True)\ndf_copy['Insulin'].fillna(df_copy['Insulin'].median(), inplace = True)","0ccf4b57":"p = df_copy.hist(figsize = (20,20))","4a3223e0":"df_copy.head(10)","6da173c3":"for i in df_copy: \n    print(\"column:\",i,\"missing values\",df_copy.loc[df_copy[i] ==\"NaN\",i].size)","20383ccf":"from pandas_profiling import ProfileReport\nfrom matplotlib.animation import FuncAnimation","772e2e6c":"df_copy.dtypes","77984d12":"# initiates profilereport to perform eda on data\nprofile = ProfileReport(df_copy,title=\"CBD Dataset EDA Report\",html={'style':{'full_width':True}}, sort=\"None\")\nprofile.to_widgets() #converts the analysis to a widget","a97d6b1b":"import seaborn as sns\n\np=sns.pairplot(df_copy, hue = 'Outcome')","f42efc31":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(df.corr(), annot=True)  # seaborn has very simple solution for heatmap","e1cb931d":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(df_copy.corr(), annot=True)  # seaborn has very simple solution for heatmap","61b71ae1":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(df_copy.drop([\"Outcome\"],axis = 1),),\n        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])","5183139f":"X.head()","90055201":"y = df_copy['Outcome'].values","8b5e2216":"#importing train_test_split\nfrom sklearn.model_selection import train_test_split","05beb616":"#the proportion of labels should remain same in the splits, so we use \"stratify\"\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42, stratify=y)","66e62677":"from sklearn.neighbors import KNeighborsClassifier\n\nneighbors = np.arange(1,20)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    knn.fit(X_train,y_train)\n    \n    train_accuracy[i] = knn.score(X_train,y_train)\n    #print(\"Training accuracy for\",i,\"is\",train_accuracy[i])\n    \n    test_accuracy[i] = knn.score(X_test,y_test)\n    print(\"Test accuracy for\",i+1,\"is\",test_accuracy[i])\n","c9f2e974":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","12e7e82a":"max_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","b7bfb028":"plt.title('KNN varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label = \"Testing Accuracy\")\nplt.plot(neighbors, train_accuracy, label = \"Training Accuracy\")\nplt.xticks(range(12,5))\nplt.legend()\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Accuracy\")\nplt.show","3ffc7f82":"#Setup a knn classifier with k neighbors\nknn = KNeighborsClassifier(8)\n\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","52f035d0":"knn.score(X_train,y_train)","fb8530a5":"knn.score(X_test,y_test)","48d5cd0b":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression","d23b2382":"#import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n#let us get the predictions using the classifier we had fit above\ny_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","a9cd3400":"tp, fn, fp, tn = confusion_matrix(y_test, y_pred, labels=(1,0)).ravel()\nprint(tp,tn,fp,fn)","534fcf5a":"pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","7e74d106":"matrix = classification_report(y_test,y_pred,labels=[0,1])\nprint('Classification report : \\n',matrix)","0a77ef04":"precision = tp\/(tp+fp)","058b6144":"precision","b7c49d38":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score","c0704349":"accuracy_score(y_test,y_pred)","67fae8ac":"precision_score(y_test,y_pred)","8bf0fca1":"recall_score(y_test,y_pred)","61f92494":"f1_score(y_test,y_pred)","1fa98da6":"fbeta_score(y_test,y_pred,beta=0.5)","b7a6b16f":"fbeta_score(y_test,y_pred,beta=2)","e6b637ec":"probs = knn.predict_proba(X_test)[:,1]\ny_predict = knn.predict(X_test)\n\nfrom sklearn.metrics import roc_curve\nfpr,tpr,thresholds = roc_curve(y_test,probs)","628e1af3":"probs","8c64a9af":"from sklearn.metrics import roc_curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)","764cc480":"plt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=8) ROC curve')\nplt.show()","cec1a498":"#Area under ROC curve\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","43ba7a71":"param_grid = {'n-neighbors':np.arange(1,50)}","dbdac351":"#knn_cv.get_params().keys()","9e8051c6":"#a = knn_cv.iid\n#print(a)","aeafae7b":"#b = knn_cv.error_score\n#print(b)","d647829f":"#import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n#In case of classifier like knn the parameter to be tuned is n_neighbors\nparam_grid = {'n_neighbors':np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv= GridSearchCV(knn,param_grid,cv=5)\nknn_cv.fit(X,y)\n\nprint(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_))","da25a911":"Heat Map for unclean data","a466b408":"### Model performance Analysis","c92d5e3a":"Heat Map for clean data i.e after removal of 'NaN'","686e70a0":"Scaling the data - ","f8a2852b":"#### Confusion Matrix","32b6645e":"### Exploratory Data Analysis ","7df09688":"### Building the KNN classifier","652e25d7":"Ploting after removal of NaN","ba1f0514":"## Business Understanding\n\n\nAIMD hospital is a medical facility that has just hired an intern in the Machine Learning space due to the vast advancements of ML in the medical field. \n\nThis facility has given the intern the data of 769 patients who have cancer and who don\u2019t have cancer. \nThese patients have other conditions as well like past pregnancies, diabetes, insulin intake, etc. \nThe doctors are hoping these attributes will help the intern learn & build a model to predict whether a patient is likely to have cancer or not based on certain attributes.","a2515346":"On these columns, a value of zero does not make sense and thus indicates missing value.\n\nFollowing columns or variables have an invalid zero value:\n1. Glucose\n2. BloodPressure\n3. SkinThickness\n4. Insulin\n5. BMI"}}