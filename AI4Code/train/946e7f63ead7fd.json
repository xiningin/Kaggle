{"cell_type":{"5b1a651c":"code","45c31a43":"code","cef3ea03":"code","3c6a015f":"code","a879a1f7":"code","ad6eb132":"code","58f4834e":"code","13273500":"code","5fae4032":"code","39903913":"code","e90a6d4e":"code","2a45d7bb":"code","82188c48":"code","0b71d578":"code","fcaf8805":"code","9f1814f5":"code","fcd0ae84":"code","b3314f98":"code","3996c45c":"code","da3191a5":"code","899fcfeb":"code","36f5c277":"code","8aff2515":"markdown","7a66d2fb":"markdown","8958a827":"markdown","67f48ff1":"markdown","24f3ec84":"markdown","5693c2be":"markdown","a623c3be":"markdown","c7f08bd6":"markdown","3a8f2142":"markdown","6120b627":"markdown","c8e1f7e5":"markdown","eccb9c02":"markdown","42d0dab2":"markdown","f603ae50":"markdown","0712655c":"markdown","b76e0181":"markdown","39a43dfe":"markdown"},"source":{"5b1a651c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ncnt=1\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if(cnt==2):\n            break;\n        print(os.path.join(dirname, filename))\n        cnt+=1\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","45c31a43":"#importing libraries\nimport matplotlib.pyplot as plt\nfrom keras import Model\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, concatenate\nfrom tensorflow.keras import Input","cef3ea03":"df=pd.read_csv('\/kaggle\/input\/house-prices-and-images-socal\/socal2.csv')\nprint(df.head())","3c6a015f":"X_house_attributes=df[['n_citi','bed','bath','sqft','price']]\n\n\nprint(X_house_attributes)\nprint(X_house_attributes.shape)","a879a1f7":"\n'''\ncolumns:\nn_citi : can be label encoded\nbed : there are either 1,2,3,4,5 beds. can be label encoded\nsqft : need to use minmax scaler\nbath : use minmax scaler\nprice : also minmax scaler can be applied\n'''","ad6eb132":"bm=max(X_house_attributes['bed'])\nsqftm=max(X_house_attributes['sqft'])\npricem=max(X_house_attributes['price'])\nbathm=max(X_house_attributes['bath'])\ncitim=max(X_house_attributes['n_citi'])\nX_house_attributes['n_citi']=X_house_attributes['n_citi']\/citim\nX_house_attributes['bed']=X_house_attributes['bed']\/bm\nX_house_attributes['sqft']=X_house_attributes['sqft']\/sqftm\nX_house_attributes['bath']=X_house_attributes['bath']\/bathm\nX_house_attributes['price']=X_house_attributes['price']\/pricem","58f4834e":"import cv2\nsample=cv2.imread('\/kaggle\/input\/house-prices-and-images-socal\/socal2\/socal_pics\/1.jpg')\nplt.imshow(sample)","13273500":"sample_resized=cv2.resize(sample,(64,64))\nplt.imshow(sample_resized)","5fae4032":"import os\nimport cv2\ncnt=0\nimages_path='..\/input\/house-prices-and-images-socal\/socal2\/socal_pics'\nX_house_images=np.zeros((15474,64,64,3),dtype='uint32')\nfor i in range(15474):\n\n    sample=cv2.imread(images_path+'\/'+str(i)+'.jpg')\n    imgs=cv2.resize(sample,(64,64))\n    X_house_images[cnt]=imgs\n    cnt+=1\n\nprint(\"No. of images: \",cnt)","39903913":"X_house_images=X_house_images\/255.0","e90a6d4e":"def create_ann(dim, regress=False):\n    # define our MLP network\n    model = Sequential()\n    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n    model.add(Dense(4, activation=\"relu\"))\n    # check to see if the regression node should be added\n    # return our model\n    return model","2a45d7bb":"def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n    # initialize the input shape and channel dimension, assuming\n    # TensorFlow\/channels-last ordering\n    #inpute shape: (64,64,3)\n    inputShape = (height, width, depth)\n    chanDim = -1\n    # define the model input\n    inputs = Input(shape=inputShape)\n    # flatten the volume, then FC => RELU => BN => DROPOUT\n    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(axis=chanDim)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(axis=chanDim)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(axis=chanDim)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = Flatten()(x)\n    x = Dense(16)(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(axis=chanDim)(x)\n    x = Dropout(0.5)(x)\n\n    x = Dense(4)(x)\n    x = Activation(\"relu\")(x)\n    # construct the CNN\n    model = Model(inputs, x)\n    # return the CNN\n    return model","82188c48":"# X_house_attributes -> continuous variables and price (output variable)\n# X_house_images -> images\nfrom sklearn.model_selection import train_test_split\nsplit = train_test_split(X_house_attributes, X_house_images, test_size=0.25, random_state=42)\n(Xatt_train,Xatt_test,Ximage_train,Ximage_test) = split\n\ny_train , y_test = Xatt_train['price'].values , Xatt_test['price'].values\n\nX1_train=Xatt_train[['n_citi','bed','bath','sqft']].values\nX2_train=Ximage_train\nX1_test=Xatt_test[['n_citi','bed','bath','sqft']].values\nX2_test=Ximage_test\n\nprint(X1_train.shape)\nprint(X1_test.shape)\nprint(X2_train.shape)\nprint(X2_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","0b71d578":"# create the MLP and CNN models\nmlp = create_ann(X1_train.shape[1], regress=False)\ncnn = create_cnn(64, 64, 3, regress=False)\n# create the input to our final set of layers as the *output* of both\n# the MLP and CNN\ncombinedInput = concatenate([mlp.output, cnn.output])\n# our final FC layer head will have two dense layers, the final one\n# being our regression head\nx = Dense(4, activation=\"relu\")(combinedInput)\nx = Dense(1, activation=\"linear\")(x)\n# our final model will accept categorical\/numerical data on the MLP\n# input and images on the CNN input, outputting a single value (the\n# predicted price of the house)\n","fcaf8805":"from keras.optimizers import Adam\nmodel = Model(inputs=[mlp.input, cnn.input], outputs=x)\nopt = Adam(lr=1e-3, decay=1e-3 \/ 200)\nmodel.compile(loss=\"mse\", optimizer=opt)\n# train the model\nprint(\"[INFO] training model...\")\n\nmodel.fit(x=[X1_train,X2_train], y=y_train,validation_data=([X1_test, X2_test], y_test),epochs=50, batch_size=64)\n","9f1814f5":"attr_sample=df.loc[df['image_id'] == 4]\nprint(attr_sample)","fcd0ae84":"image_sample=cv2.imread('\/kaggle\/input\/house-prices-and-images-socal\/socal2\/socal_pics\/4.jpg')\nsample_resized=cv2.resize(image_sample,(64,64))\nplt.imshow(sample_resized)","b3314f98":"X1_final=np.zeros(4,dtype='float32')\nX1_final[0]=attr_sample['n_citi']\/citim\nX1_final[1]=attr_sample['bed']\/bm\nX1_final[2]=attr_sample['bath']\/bathm\nX1_final[3]=attr_sample['sqft']\/sqftm\ny_ground_truth=attr_sample['price']","3996c45c":"X2_final=sample_resized\/255.0","da3191a5":"print(X1_final.shape,\" \",X2_final.shape)","899fcfeb":"y_pred=model.predict([np.reshape(X1_final,(1,4)),np.reshape(X2_final,(1,64,64,3))])","36f5c277":"print(\"Actual price: \",attr_sample['price'].values)\nprint(\"Predicted price: \",y_pred*pricem)","8aff2515":"**Reading images sequentially**","7a66d2fb":"## Data pre-processing","8958a827":"**We also have a dataset of images where each image corresponds to one house.**","67f48ff1":"**Given below is the architecture of the model**\n\n![Architecture of our model](https:\/\/drive.google.com\/uc?export=view&id=1JWPszu8ZgxTdxCIJvtNbklkNIrfhqxFD)","24f3ec84":"**We use the House Price dataset (socal) from kaggle for this problem.** \n\n**The csv file socal2.csv contains informations about a particular house like no. of bedrooms , bathrooms, kitchens, city code , square feet and price column.**\n\n**We will drop the price column from the input data and this will act as the label value which we will predict finally from our model.**\n\n","5693c2be":"## Defining the model","a623c3be":"## Splitting into training and test set","c7f08bd6":"## Prediction on a test data","3a8f2142":"\n**We will give the X1_train as input to ANN, which has continous variables\nand images (X2_train) to CNN.**\n\n**Similarly for validation set**","6120b627":"**Taking image id 4 data**","c8e1f7e5":"**X_house_attributes : contains the continous values**","eccb9c02":"## *The motivation in solving this problem comes from the fact that in real world, you do get mixed data and there is need of a model which would take the features from it and approximate a value*","42d0dab2":"**The size of images vary, so we will resize each image to a fixed size of 64X64**","f603ae50":"Preprocessing the data so that the trained model can predict","0712655c":"## Dataset","b76e0181":"**We will define 3 models.**\n\n* **The ANN model will take the continous data and return vector of dimension 4 which will indicate features**\n\n* **The CNN model will take images and return vector of dimension 4 which will indicate features**\n\n* **Finally our final ANN model will take all these features and predict the final price.**","39a43dfe":"## Importing libraries"}}