{"cell_type":{"16af7a4a":"code","ec6e19e6":"code","2e328e02":"code","9aadb671":"code","44720179":"code","f2efe6a1":"code","a62c28ab":"code","21d0ca4a":"code","5e537e5b":"code","c04a5ae5":"code","9eaa2cd8":"code","45b9da6b":"code","1f8ca8e0":"code","bc6667b8":"code","bd5571a4":"code","63e2f9b9":"code","e847cd34":"code","34df21ed":"markdown","18bd0060":"markdown"},"source":{"16af7a4a":"import numpy as np # We'll be storing our data as numpy arrays\nimport os # For handling directories\nfrom PIL import Image # For handling the images\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg # Plotting\n","ec6e19e6":"print(os.listdir('..\/input'))","2e328e02":"data_dir = \"..\/input\/depthgestrecog\/depthGestRecog\/\"   ","9aadb671":"label_dict = {}\n# get the class num\nfor label in os.listdir(data_dir):\n   for sub_dir in os.listdir(os.path.join(data_dir,label)):\n       class_num = int((os.listdir(os.path.join(data_dir,label,sub_dir)))[:][0][5:7])\n   label_dict[class_num] = label","44720179":"x = []\ny = []\nfor root, _, files in os.walk(data_dir):\n    for i in range(len(files)):\n        x.append((plt.imread((os.path.join(root,files[i])))))\n        y.append((int(files[i][5:7])))\n\nx = np.asarray(x, dtype=np.float32)\ny = np.asarray(y)","f2efe6a1":"y","a62c28ab":"y_ohev = []\n\nfor j in y:\n    ohev = np.zeros(11)  # 11 classes ( replace by no of classes)\n    ohev[j - 1] = 1\n    y_ohev.append(ohev)","21d0ca4a":"y_ohev","5e537e5b":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y_ohev,test_size = 0.2)\n","c04a5ae5":"fig = plt.figure(figsize=(10, 10))\ncolumns = 4\nrows = 3\n\nfor i in range(1, columns * rows + 1):\n    gest = \"\"\n    ind = np.random.randint(len(x_train))\n    fig.add_subplot(rows, columns, i)\n    for key, value in label_dict.items():\n        if value == (np.argmax(y_train[ind]) + 1):\n            gest = key\n    plt.title(gest)\n    plt.imshow(x_train[ind])\n\nplt.show()","9eaa2cd8":"x_train = np.array(x_train)\nx_train[x_train > 0] = 1\nx_test = np.array(x_test)\nx_test[x_test > 0] = 1\n\ny_test = np.array(y_test)\ny_train = np.array(y_train)\n","45b9da6b":"from keras import backend as K\nnum_classes = 11\nimg_rows = 100\nimg_cols = 100\n# input shape (100, 100, 1)\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)","1f8ca8e0":"from keras import layers\nfrom keras import models","bc6667b8":"model=models.Sequential()\nmodel.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=input_shape)) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu')) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(num_classes, activation='softmax'))","bd5571a4":"model.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nhistory = model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_test, y_test))","63e2f9b9":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# plot for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e847cd34":"[loss, acc] = model.evaluate(x_test,y_test,verbose=0)\nprint(\"Accuracy:\" + str(acc))","34df21ed":"Finally, we fit the model.","18bd0060":"Now it's time to build our network. We'll use keras."}}