{"cell_type":{"5ac7879e":"code","087d0745":"code","b01ca056":"code","f03194ff":"code","26f38f51":"code","05e74448":"code","888c2c30":"code","ac0a04ac":"code","87268abd":"code","b450a511":"code","ed758f54":"markdown","fbfde130":"markdown","13a98f86":"markdown","06244d15":"markdown","f35e3d45":"markdown","4cd9d116":"markdown","4bde0582":"markdown"},"source":{"5ac7879e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        df = pd.read_csv(os.path.join(dirname, filename))\n        break\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","087d0745":"df.head()","b01ca056":"df.describe()\ndf.info()\ndf.columns","f03194ff":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\ncols_interest= ['GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n       'LOR ', 'CGPA', 'Research', 'Chance of Admit ']\n\n#df = pd.DataFrame(np.random.randn(50, 7), columns=list('ABCDEFG'))\n\n# initiate empty dataframe\ncorr = pd.DataFrame()\nfor a in cols_interest:\n    for b in cols_interest:\n        corr.loc[a, b] = df.corr().loc[a, b]\n\ncorr\n\nsns.heatmap(corr)","26f38f51":"df=df[cols_interest]\n\nfig = plt.figure(figsize=(10,10))\nfig.tight_layout(pad = 3.0)\nax1 = fig.add_subplot(421)\nax2 = fig.add_subplot(422)\nax3 = fig.add_subplot(423)\nax4 = fig.add_subplot(424)\nax5 = fig.add_subplot(425)\nax6 = fig.add_subplot(426)\nax7 = fig.add_subplot(427)\n\nax1.scatter(df['Chance of Admit '], df['GRE Score'], color='red')\n#ax1.title.set_text('Chance of Admit Vs Gre Score')\nax1.set_xlabel('COA')\nax1.set_ylabel('GRE')\n\nax2.scatter(df['Chance of Admit '], df['TOEFL Score'], color='red')\n#ax2.title.set_text('Chance of Admit Vs TOEFL')\nax2.set_xlabel('COA')\nax2.set_ylabel('Toefl')\n\nax3.scatter(df['Chance of Admit '], df['University Rating'], color='red')\n#ax3.title.set_text('Chance of Admit Vs Ranking')\nax3.set_xlabel('COA')\nax3.set_ylabel('ranking')\n\nax4.scatter(df['Chance of Admit '], df['SOP'], color='red')\n#ax4.title.set_text('Chance of Admit Vs SOP')\nax4.set_xlabel('COA')\nax4.set_ylabel('sop')\n\nax5.scatter(df['Chance of Admit '], df['LOR '], color='red')\n#ax5.title.set_text('Chance of Admit Vs LOR')\nax5.set_xlabel('COA')\nax5.set_ylabel('lor')\n\nax6.scatter(df['Chance of Admit '], df['CGPA'], color='red')\n#ax6.title.set_text('Chance of Admit Vs CGPA')\nax6.set_xlabel('COA')\nax6.set_ylabel('cgpa')\n\nax7.scatter(df['Chance of Admit '], df['Research'], color='red')\n#ax7.title.set_text('Chance of Admit Vs Research')\nax7.set_xlabel('COA')\nax7.set_ylabel('research')\n\nfig.subplots_adjust(top=0.92, bottom=0.04, left=0.10, right=0.95, hspace=0.25,\n                    wspace=0.35)","05e74448":"\nX = df[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n       'LOR ', 'CGPA', 'Research']]\nY = df[\"Chance of Admit \"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test , Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=0)\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,Y_train)\n\nY_pred= regressor.predict(X_test)\n\nprint('Intercept: \\n', regressor.intercept_)\n#print('Coefficients: \\n', regressor.coef_)\nprint(\"Coeffecients:\")\nprint(list(zip(X.columns,regressor.coef_ )))\n","888c2c30":"from sklearn import metrics\nprint(np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))","ac0a04ac":"#Removing SOP as it has the lowest coeffecient and building the model again\ncols_interest = ['GRE Score',  \n       'LOR ', 'CGPA', 'Research']\nX = df[['GRE Score',  \n       'LOR ', 'CGPA', 'Research']]\nY = df[\"Chance of Admit \"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test , Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=0)\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,Y_train)\n\nY_pred= regressor.predict(X_test)\n\nprint('Intercept: \\n', regressor.intercept_)\n#print('Coefficients: \\n', regressor.coef_)\nprint(\"Coeffecients:\")\nprint(list(zip(cols_interest,regressor.coef_ )))\n\nfrom sklearn import metrics\nprint(\"\")\nprint(np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n","87268abd":"# The above RMSE scores shows a decrease due to the removal of SOP variable from the list of columns, so we will not remove it and since RMSE is 0.063 which is low \n# I will consider this as my final model.\n#But I will apply statsmodel on the data to see if my model is making the right predictions\n\n# with statsmodels\n\nimport statsmodels.api as sm\nX_train = sm.add_constant(X_train) # adding a constant\n \nmodel = sm.OLS(Y_train, X_train).fit()\npredictions = model.predict(X_train) \n \nprint_model = model.summary()\nprint(print_model)\n","b450a511":"\nGRE_Score = 325\nToefl = 115\nRanking = 10\nSOP=4.0\nLOR= 4.0 \nCGPA =8.5\nResearch=1\n\n\nprint ('Predicted Stock Index Price: \\n', regressor.predict([[GRE_Score ,Toefl,Ranking,SOP,LOR,CGPA,Research]])[0]*100)\n","ed758f54":"# **Finding the correlations between chance of admit and other metrics**","fbfde130":"# **create a OLS model to verify the result with sklearn (and it looks good )**","13a98f86":"# **Time to do some predictions**","06244d15":"# **Removing SOP to see if there is any improvement in RMSE**\n-> there is no improvement so we will keep the previous model","f35e3d45":"# **Evaluate using RMSE**","4cd9d116":"# **Build the Multiple Linear Regression Model **","4bde0582":"# **Evaluating linear relationships among different factors**"}}