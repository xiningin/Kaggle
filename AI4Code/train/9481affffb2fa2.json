{"cell_type":{"2df25552":"code","0a6312cd":"code","883436ba":"code","c13d3bd1":"code","904e7156":"code","8c988159":"code","216c696e":"code","1f39a443":"code","b1a23082":"code","ee744882":"code","6090ac58":"code","8c69f4c1":"code","c7dedc4d":"code","b13c0152":"code","03a411ac":"code","d6e764fc":"code","10fc7a69":"code","3a7e2e09":"code","8b92cbc5":"code","9dc9050a":"code","54847fd4":"code","3f48882c":"markdown"},"source":{"2df25552":"import cv2\nimg = cv2.imread(\"..\/input\/car-damage-detection\/data1a\/training\/00-damage\/0001.JPEG\")\nimg.shape","0a6312cd":"!pip install timm","883436ba":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nimport random\nimport timm\nimport torchvision\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport os\nfrom torchvision.datasets import ImageFolder\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations\nimport pickle\n\n\nfrom sklearn.metrics import accuracy_score\n\n\nwarnings.filterwarnings(\"ignore\")","c13d3bd1":"seed = 1000\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\nseed_everything(seed)","904e7156":"train_val_path = \"..\/input\/car-damage-detection\/data1a\/training\"\ntransform=transforms.Compose([\n                                  transforms.Resize([128,128]),\n                                  transforms.RandomHorizontalFlip(p=0.5),\n                                  transforms.RandomVerticalFlip(p=0.5),\n                                  transforms.ToTensor()\n])","8c988159":"dataset=ImageFolder(train_val_path,transform=transform)","216c696e":"img0,label0 = dataset[6]\nprint(img0.shape,label0)\nimg10,label10 = dataset[10]\nprint(img10.shape,label10)\nprint(dataset.classes)","1f39a443":"def show_img_with_label(img,label):\n    print(\"label:\" ,label)\n    plt.imshow(img.permute(1,2,0))\n    \nshow_img_with_label(img0,label0)","b1a23082":"print(dataset.classes[0])\nprint(dataset.classes[1])\nprint(len(dataset))","ee744882":"val_num= int(len(dataset)*0.3)\nindex = np.random.permutation(len(dataset))\nval_idx = index[:val_num]\ntrain_idx = index[val_num:]\nprint(val_idx[:5])","6090ac58":"batch_size = 16\n\ntrain_sampler = SubsetRandomSampler(train_idx)\ntrain_df = DataLoader(dataset,batch_size = batch_size,sampler = train_sampler)\n\nval_sampler = SubsetRandomSampler(val_idx)\nval_df = DataLoader(dataset,batch_size=batch_size,sampler = val_sampler)","8c69f4c1":"class Model(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, 2)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \nmodel = Model()","c7dedc4d":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n\nmodel.to(device)","b13c0152":"loss_type = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)","03a411ac":"loss_val = []\nfor epoch in range(130):\n    \n    print(\"epoch: \" , epoch+1)\n    running_loss = 0\n    for(i,data) in enumerate(train_df):\n        img,label = data\n        img,label = img.to(device),label.to(device)\n        \n        optimizer.zero_grad()\n        \n        output_label = model(img)\n        \n        loss = loss_type(output_label,label)\n        \n        loss.backward()\n        \n        optimizer.step()\n        running_loss = running_loss + loss.item()*img.size(0)\n    \n    loss_val.append(running_loss\/len(train_df))\n    \n    print(running_loss)\n\nplt.plot(loss_val,label=\"loss\")\nplt.legend()","d6e764fc":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data in val_df:\n        img,label = data\n        img,label = img.to(device),label.to(device)\n        \n        output = model(img)\n        _,predicted = torch.max(output,dim=1)\n        \n        \n        preds.extend(predicted.cpu().detach().numpy())\n        labels.extend(label.cpu().detach().numpy())\n    \nprint(\"Accuracy: {}\".format(accuracy_score(labels,preds)) )","10fc7a69":"model_path = \"Resnext_model.pkl\"\nwith open(model_path,'wb') as f:\n    pickle.dump(model,f)","3a7e2e09":"with open(model_path,'rb') as f:\n    model = pickle.load(f)","8b92cbc5":"test_dir = \"..\/input\/car-damage-detection\/data1a\/validation\"\n\ntransform=transforms.Compose([\n                              transforms.Resize([128,128]),\n                              transforms.RandomHorizontalFlip(p=0.5),\n                              transforms.RandomVerticalFlip(p=0.5),\n                              transforms.ToTensor()\n])\ntest_data = ImageFolder(test_dir,transform = transform)","9dc9050a":"batch_size = 32\n\ntest_df = DataLoader(test_data,batch_size)","54847fd4":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data in test_df:\n        img,label = data\n        img,label = img.to(device),label.to(device)\n        output = model(img)\n        _,predicted = torch.max(output,dim=1)\n        \n        preds.extend(predicted.cpu().detach().numpy())\n        labels.extend(label.cpu().detach().numpy())\n        \nprint(f\"Accuracy for test data : {accuracy_score(preds,labels)}\")","3f48882c":"# Building Damage Classifier\n\n### Approach \n\nSince, i have not given a csv or json file with labels so i have to generate them. Now all the given images have different sizes i have to augment then into a specific size. As for model , i use diffenent model and choose the one with better accuracy. I choose Resnext50 model by changing its classifier.\nI use hit and trial method for choosing number of epochs. And for validation data, random indexes were generated. After training , i saved the model weights in a  pickle file.\n\n### Augmentation Policy \n\nFor augmentation i used,\n\n`->` Resize - As images are of different size, i fixed their size to (128,128) pixels.\n\n`->` I have used random horizontal flip and random vertical flip to flip images\n\n`->` And finally , i converted images to tensors.\n\n### Evaluation Metrics\n\nI used accuracy as my evaluation metrics, since it describes how good the model is doing on validation and test data much better and it is easy to use and easy to understand."}}