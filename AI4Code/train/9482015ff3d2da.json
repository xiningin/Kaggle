{"cell_type":{"3e146904":"code","b040c717":"code","3d3188fe":"code","0486b4f7":"code","046c057b":"code","b4a97fdf":"code","97d055d6":"code","a4e78123":"code","66555167":"code","1dfde67a":"code","1b31d688":"code","ace461b1":"code","85c8d89c":"code","0f3aae1d":"code","9fb54bbe":"code","c993b33d":"code","3ad236f1":"code","caf83bb0":"code","43528918":"code","1ce09feb":"code","c4d827e5":"code","88057cdd":"code","ffb24e87":"code","9975a22d":"markdown","ec755056":"markdown","9cce796e":"markdown","314ea8ee":"markdown","ccef3617":"markdown","338c3c84":"markdown"},"source":{"3e146904":"!pip install opencv-torchvision-transforms-yuzhiyang\n!rm -rf torch_collections\/","b040c717":"import numpy as np \nimport pandas as pd \nimport os\nimport cv2\nimport json\nimport torch\nimport torchvision\nfrom cvtorchvision import cvtransforms\nimport matplotlib.pyplot as plt\nimport tqdm\nimport shutil\nimport pickle\nshutil.copytree(\"..\/input\/torch-collections-5\/torch_collections\/\",'.\/torch_collections')\nfrom torch_collections import RetinaNet\nfrom IPython.display import FileLink","3d3188fe":"images_dir = '..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/'\nannot_dir = '..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/annotations\/'\nannot_csv = '..\/input\/face-mask-detection-dataset\/train.csv'\n\nshape = (768,768)","0486b4f7":"def json_open(path):\n    with open(path) as f:\n        file = json.load(f)\n    return file\n\ndef img_read(path):\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    res_img = cv2.resize(img,shape)\n    return res_img,img.shape\n\ndef img_to_annot(annot_df):\n    data_dict = {}\n    for index,row in annot_df.iterrows():\n        key = str(row['name'])\n        box = [int(row['x1']),int(row['y1']),int(row['x2']),int(row['y2']),int(row['class'])]\n        if key in data_dict:\n            data_dict[key].append(box)\n        else:\n            data_dict[key] = [box]\n#         print(data_dict)\n#         break\n        \n    for image_name in data_dict:\n        img_path = images_dir + image_name \n        print(img_path)\n        img,org_s = img_read(img_path)\n        for box in data_dict[image_name]:\n            box[0] = shape[1]*box[0]\/\/org_s[1] #x1\n            box[1] = shape[0]*box[1]\/\/org_s[0] #y1\n            box[2] = shape[1]*box[2]\/\/org_s[1] #x2\n            box[3] = shape[0]*box[3]\/\/org_s[0] #y2\n    return data_dict\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self,data_dict):\n        self.data_dict = data_dict\n        self.image_files = list(data_dict.keys())\n        self.image_to_tensor = cvtransforms.Compose([cvtransforms.ToTensor(),\n                               cvtransforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n    \n    def __len__(self):\n        return len(self.data_dict)\n\n    def __getitem__(self, idx):\n        image_file = self.image_files[idx]\n        image,_ = img_read(images_dir + image_file)\n        image = self.image_to_tensor(image)\n        annots = self.data_dict[image_file]\n        annots = torch.from_numpy(np.array(annots,dtype=np.float32))\n        return image,annots       ","046c057b":"images = os.listdir(images_dir)\n# annots = os.listdir(annot_dir)\n# annots_df = pd.read_csv(annot_csv)\n# images.sort()\n# # annots.sort()\n# print(len(images))\n# # print(len(annots))\n# print(len(set(annots_df['name'])))\n\n# print(images[1697])\n# # print(annots[-1])\n# print(list(set(annots_df['name']))[-1])\n# print(annots_df.head)\n# j = json_open(annot_dir + '1802.jpg.json')\n# print(j)\ntest_images = images[:1698]\ndel images\n# del annots","b4a97fdf":"def modify_annots(annots_df):\n    annots_df = annots_df.sort_values(by='name')\n    annots_df.replace(['face_other_covering','helmet','hijab_niqab',\n                                       'balaclava_ski_mask','gas_mask','other'],'face_no_mask',inplace=True)\n    annots_df.replace(['face_with_mask','face_no_mask'],[1,0],inplace=True)\n    annots_df = annots_df.loc[annots_df['classname'].isin([0,1])]\n    annots_df.columns = ['name','x1','y1','x2','y2','class']\n    annots_df.reset_index(drop=True,inplace=True)\n    return annots_df\n\n# annots_df = modify_annots(annots_df)\n# class_count = annots_df['class'].value_counts()\n# print(class_count)\n# print(annots_df.head(20))","97d055d6":"try:\n    with open('..\/input\/data-dict\/data_dict.p','rb') as f:\n        data_dict = pickle.load(f)\n        print('loaded data dict file !')\nexcept:       \n    data_dict = img_to_annot(annots_df)\n    with open('data_dict.p','wb') as f:\n        pickle.dump(data_dict,f)\n\n# with open('data_dict.p','rb') as f:\n#     data_dict = pickle.load(f)\n\n# classes = set(annots_df['classname'])\n# print(classes,len(classes))\n# d = annots_df[annots_df['classname'] == 'balaclava_ski_mask']\n# print(d[['name','classname']])\n# class_count = annots_df['classname'].value_counts()\n# print(class_count)","a4e78123":"dataset = Dataset(data_dict)\ndel data_dict\n# dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=2, pin_memory=True)","66555167":"# for batch in dataset_loader:\n#     break\n# print(batch[0].shape,batch[1].shape)","1dfde67a":"# print(data_dict['1812.jpg'][5])\n# print(len(data_dict))\n# # print(data_dict.keys())","1b31d688":"# !rm -rf torch_collections\/\n# !wget -q 'https:\/\/github.com\/mingruimingrui\/torch-collections\/archive\/0.4b.zip' -O torch-collections.zip\n# !unzip -oq torch-collections.zip\n# !mv torch-collections-0.4b\/torch_collections .\n# !rm -rf torch-collections-0.4b\/  torch-collections.zip","ace461b1":"value = [0,0]\nindex = value[0]\nsub_df = pd.DataFrame(columns=['name','x1','x2','y1','y2','classname'])\ntry:\n    sub_df = pd.read_csv('\/kaggle\/input\/submission-v-5\/wobot submission\/submission.csv')\n    sub_df = sub_df.drop('Unnamed: 0',axis=1)\n    print('loaded sub df !')\nexcept:\n    pass\ntry:\n    with open('\/kaggle\/input\/submission-v-5\/wobot submission\/value_file.p','rb') as f:\n        value = pickle.load(f)\n        index = value[0]\n        print('loaded value file !')\nexcept:\n    pass\n  \ndef gen_sub_csv(name,boxes,labels):\n    global index\n    global sub_df\n    for i in range(len(boxes)):\n        anno = []\n        anno.append(name)\n        anno.append(boxes[i][0])\n        anno.append(boxes[i][2])\n        anno.append(boxes[i][1])\n        anno.append(boxes[i][3])\n        anno.append(labels[i])\n        sub_df.loc[index] = anno\n        del anno\n        index += 1","85c8d89c":"sub_df.head()","0f3aae1d":"def test_model(test_images,thresh=0.7): \n    global value\n    global sub_df\n    global index\n    for file_no in range(len(test_images)):\n        file_no = value[1]\n        name = test_images[file_no]\n        test_image,_ = img_read(images_dir + name)\n#         test_image = cv2.cvtColor(test_image,cv2.COLOR_BGR2RGB)\n        test_tensor = dataset.image_to_tensor(test_image)\n        test_tensor = test_tensor.unsqueeze(0)\n        test_tensor = test_tensor.cuda()\n        dets = model(test_tensor)[0]\n        del test_image\n        del test_tensor\n#         torch.cuda.empty_cache()\n        scores = dets['scores'].cpu().data.numpy()\n        boxes = dets['boxes'].cpu().data.numpy()[scores > thresh]\n        labels = dets['labels'].cpu().data.numpy()[scores > thresh]\n#         print(boxes,labels,scores)\n        if len(boxes) > 0:\n            boxes = boxes.round()\n        gen_sub_csv(name,boxes,labels)\n        del name\n        del scores\n        del boxes\n        del labels\n        if file_no%100 == 0 or file_no == 1697:\n            value = [index,file_no+1]\n            with open('.\/value_file.p','wb') as f:\n                pickle.dump(value,f)\n            sub_df.to_csv('.\/submission.csv')\n            print('Generated submission.csv file and index :',file_no,' ',index-1)\n        value[1] = file_no + 1\n    print('file generation completed')\n#         for box in boxes:\n#             cv2.rectangle(test_image,box,(0,255,0),3)\n#     plt.imshow(test_image)\n#     plt.show()","9fb54bbe":"# dc = 0\n# for annot in data_dict.values():\n#     box = len(annot)\n#     dc += box\n# print(dc)","c993b33d":"model = RetinaNet(2).cuda()\nmodel.load_state_dict(torch.load('\/kaggle\/input\/mask-detector-model-1\/mask_detector_model.pt'))\nmodel.eval()\n                      \n# model = RetinaNet(2).train().cuda()\n# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001)","3ad236f1":"def train_model(epochs=20):\n    max_count = 4270\n    for epoch in range(epochs):\n        pbar = tqdm.tqdm(total=max_count, desc='training model')\n        epoch_loss = 0\n        for batch in dataset_loader:\n            pbar.update(1)\n            optimizer.zero_grad()\n            batch_image = batch[0].cuda()\n            batch_annotations = batch[1].cuda()\n            loss = model(batch_image, batch_annotations)\n            if loss is not None:\n                epoch_loss += loss\n                # loss can be none when no valid anchors are available\n                loss.backward()\n                optimizer.step()\n\n            del batch_image\n            del batch_annotations\n            del batch\n        try:\n            os.remove('.\/mask_detector_model.pt')\n        except:\n            pass\n        torch.save(model.state_dict(),'.\/mask_detector_model.pt')\n        print('model saved at epoch :',epoch)\n        print('Epoch ',epoch,' loss :',epoch_loss)\n        pbar.close()        \n    print('Training completed !')    \n    ","caf83bb0":"# train_model()","43528918":"# test_model(test_images)","1ce09feb":"sub_df = sub_df.sort_values(by='name')\nsub_df['classname'].replace([1,0],['face_with_mask','face_no_mask'],inplace=True)\nsub_df.reset_index(drop=True,inplace=True)","c4d827e5":"print(sub_df.head())\nclass_count = sub_df['classname'].value_counts()\nprint(class_count)\nsub_df.to_csv('.\/submission.csv')","88057cdd":"t_im,_ = img_read(images_dir + '0003.jpg')\ncv2.rectangle(t_im,[315,0,683,653],(0,255,0),3)\nplt.imshow(t_im)\nplt.show()","ffb24e87":"t_im,_ = img_read(images_dir + '0009.jpg')\ncv2.rectangle(t_im,[394,117,437,211],(0,255,0),3)\ncv2.rectangle(t_im,[394,118,438,219],(0,255,0),3)\ncv2.rectangle(t_im,[199,186,278,355],(0,255,0),3)\nplt.imshow(t_im)\nplt.show()","9975a22d":"**Some utility functions**","ec755056":"**Combining face_no_mask,face_other_covering,helmet,hijab_niqab,balaclava_ski_mask,gas_mask and other ---> as these classes describe whether the person is wearing a mask or not. Other classes like sunglasses etc are not considered here because they are not related to masks**","9cce796e":"**As we can see the model is able to detect successfully upto some extent. The boxes would be more precise if the no of epochs is higher. I am limited by GPU run time and CUDA memory on Kaggle**","314ea8ee":"**Training Done**","ccef3617":"# Face Mask Detector using RetinaNet for 2 classes by Shanmukha","338c3c84":"**Visualizing boxes generated from Test Set**"}}