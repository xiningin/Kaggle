{"cell_type":{"5b19762f":"code","b7fb3cfa":"code","decac489":"code","3c163199":"code","ef03e3bd":"code","f6adaa9c":"code","2a60dacc":"code","b10514c1":"code","984b6882":"code","061be358":"code","4765c5d8":"code","a2743c04":"code","34bf7fc5":"code","e4664585":"code","995a6fd5":"code","8369f9a5":"code","69c27aa5":"code","923b1423":"code","6748ef2c":"code","a6976f97":"code","801fbb7f":"code","12a7c90f":"code","aa66997d":"code","39ee738d":"code","78a6c94f":"code","5a32e035":"code","5caa3894":"code","13945d2f":"code","b81ae99f":"code","082d7f30":"code","c056a07d":"code","3b124aa1":"code","53337cea":"code","f53a569c":"code","f2ca2f2f":"code","7c320141":"code","38cab095":"code","63e0cfb0":"code","07c9fa56":"code","809fc0b2":"code","f9c1b1d1":"code","86163dbe":"code","7fb17bed":"code","a8187d21":"code","6b6536a7":"code","2d043ff9":"code","152cd283":"code","9b3e8480":"code","3eee84a0":"code","4557dfd0":"code","7205e977":"code","757db482":"code","50aaead7":"code","31bc02c8":"code","e0123e3f":"code","3ddff919":"code","0fc68ff4":"code","7ec41e9b":"code","e8f9d96a":"markdown","211ccc6c":"markdown","e0edfbb4":"markdown","b262f2ed":"markdown","523df0c8":"markdown","abeea878":"markdown","f09ec4df":"markdown","be499413":"markdown"},"source":{"5b19762f":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.ensemble import RandomForestClassifier","b7fb3cfa":"#Load the Data\ntrain = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/train.csv')","decac489":"train.head()","3c163199":"print(f'Number of rows: {train.shape[0]};  Number of columns: {train.shape[1]}; No of missing values: {sum(train.isna().sum())}')","ef03e3bd":"train.info()","f6adaa9c":"train.describe().T","2a60dacc":"target_count = train['target'].value_counts().sort_index()\ntarget_count_df = pd.DataFrame(target_count)\n#pd.options.display.float_format = '{:,.2f}%'.format\ntarget_count_df['target(%)'] = (target_count_df\/target_count.sum()*100)\ntarget_count_df.sort_values('target(%)', ascending=False, inplace=True)\ndisplay(target_count_df)","b10514c1":"fig, ax = plt.subplots(1, 1, figsize=(17, 8))\n\ntarget_count = train['target'].value_counts().sort_index()\n\nax.bar(target_count.index, target_count, color=['#1520E6' if i%2==0 else '#93D1FF' for i in range(9)],\n       width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.margins(0.02, 0.05)\n\nfor i in range(1,2):\n    ax.annotate(f'{target_count[i]\/len(train)*100:.3}', xy=(i, target_count[i]+1000),\n                   va='center', ha='center',\n               )\n#Annotate the point xy with text text.\n\n#In the simplest form, the text is placed at xy.\n\nax.set_title('target Distribution', weight='bold', fontsize=15)\nax.grid(axis='y', linestyle='-', alpha=0.4)\n\nfig.tight_layout()\nplt.show()","984b6882":"import seaborn as sns\nfrom matplotlib import pyplot as plt\ntrain.isnull().sum()\nsns.heatmap(train.isnull(), cbar = True).set_title(\"Missing values heatmap\")\nplt.gcf().set_size_inches(16,6)","061be358":"train.nunique()","4765c5d8":"# Check the data\ntrain.isnull().any().describe()","a2743c04":"train.dtypes","34bf7fc5":"y=train['target']\nX=train.drop(labels=['target','ID_code'], axis=1)","e4664585":"# explore lightgbm number of trees effect on performance\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","995a6fd5":"import lightgbm\nfrom sklearn.metrics import roc_auc_score\n#Step2: Create a simple Light GBM Model and evaluate performance\n#LightGBM has function Dataset to read the data. This is required for using LightGBM\ntrain_data = lightgbm.Dataset(X_train, label=y_train)\nvalid_data = lightgbm.Dataset(X_valid, label=y_valid)\n# to record eval results for plotting\nevals_result = {} \nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'l2'},\n    'num_leaves': 20,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'min_data_in_leaf':4,\n     #'min_sum_hessian_in_leaf': 5,\n    'verbose':10\n}\n\nmodel_lgbm = lightgbm.train(params,\n                            train_data,\n                            valid_sets=valid_data,\n                            evals_result=evals_result,\n                            num_boost_round=5000,\n                            early_stopping_rounds=50)\ny_train_pred = model_lgbm.predict(X_train)\ny_valid_pred = model_lgbm.predict(X_valid)\n\nprint(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n                                                    roc_auc_score(y_valid, y_valid_pred)))\n","8369f9a5":"print('Plot metrics during training...')\nax = lightgbm.plot_metric(evals_result)\nplt.show()","69c27aa5":"print('Plot feature importances...')\nax = lightgbm.plot_importance(model_lgbm, max_num_features=10)\nplt.show()","923b1423":"def pie(df,var):\n# Creating dataset\n labels = ['0', '1']\n\n\n# Creating explode data\n explode = (0.1, 0.0)\n\n# Creating color parameters\n colors = ( \"orange\", \"cyan\", \"brown\",\n\t\t\"grey\", \"indigo\", \"beige\")\n\n# Wedge properties\n wp = { 'linewidth' : 1, 'edgecolor' : \"green\" }\n\n# Creating autocpt arguments\n def func(pct, allvalues):\n\t absolute = int(pct \/ 100.*np.sum(allvalues))\n\t return \"{:.1f}%\\n({:d} g)\".format(pct, absolute)\n\n# Creating plot\n fig, ax = plt.subplots(figsize =(10, 7))\n wedges, texts, autotexts = ax.pie(df,\n\t\t\t\t\t\t\t\tautopct = lambda pct: func(pct, df),\n\t\t\t\t\t\t\t\texplode = explode,\n\t\t\t\t\t\t\t\tlabels = labels,\n\t\t\t\t\t\t\t\tshadow = True,\n\t\t\t\t\t\t\t\tcolors = colors,\n\t\t\t\t\t\t\t\tstartangle = 90,\n\t\t\t\t\t\t\t\twedgeprops = wp,\n\t\t\t\t\t\t\t\ttextprops = dict(color =\"magenta\"))\n\n# Adding legend\n ax.legend(wedges, labels,\n\t\ttitle =\"target\",\n\t\tloc =\"center left\",\n\t\tbbox_to_anchor =(1, 0, 0.5, 1))\n\n plt.setp(autotexts, size = 8, weight =\"bold\")\n ax.set_title(f\"Customizing pie chart for {var}\")\n\n# show plot\n plt.show()","6748ef2c":"data=train.iloc[:,[1,83]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_81')","a6976f97":"data=train.iloc[:,[1,141]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_139')","801fbb7f":"data=train.iloc[:,[1,14]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_12')","12a7c90f":"data=train.iloc[:,[1,55]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_53')","aa66997d":"data=train.iloc[:,[1,168]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\n\npie(df,'var_166')","39ee738d":"data=train.iloc[:,[1,8]]\ndata.head()\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\n#df\npie(df,'var_6')","78a6c94f":"data=train.iloc[:,[1,176]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_174')","5a32e035":"data=train.iloc[:,[1,24]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_22')","5caa3894":"data=train.iloc[:,[1,23]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_21')","13945d2f":"data=train.iloc[:,[1,112]]\n\n#data1.sort_values(by=['target'])\ndf=data['target'].value_counts()\npie(df,'var_110')","b81ae99f":"def plt_Density(data1,data0,var):\n  fig, ax = plt.subplots(1,1)\n\n\n  sns.distplot(data1, color='red',\n             hist_kws={\"edgecolor\": 'white'}, label='taeget 1')\n\n  sns.distplot(data0, color='blue',\n             hist_kws={\"edgecolor\": 'black'}, label='target 0')\n  # visualizing plot using matplotlib.pyplot library\n  # Plot formatting\n  plt.legend(prop={'size': 16}, title = 'var')\n  plt.title(f'Density Plot of {var}  with Multiple target 0 and target 1')\n  plt.xlabel('Delay (min)')\n  plt.ylabel('Density')\n  plt.show()","082d7f30":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,83]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_81,data0.var_81,'var_81')","c056a07d":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,83]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_81,data0.var_81,'var_81')","3b124aa1":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,141]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_139,data0.var_139,'var_139')","53337cea":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,14]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_12,data0.var_12,'var_12')","f53a569c":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,55]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_53,data0.var_53,'var_53')","f2ca2f2f":"data=train.iloc[:,[1,168]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_166,data0.var_166,'var_166')","7c320141":"data=train.iloc[:,[1,8]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_6,data0.var_6,'var_6')","38cab095":"#select_price = df.loc[data['target'] == 0]\n\ndata=train.iloc[:,[1,176]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_174,data0.var_174,'var_174')","63e0cfb0":"data=train.iloc[:,[1,24]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_22,data0.var_22,'var_22')","07c9fa56":"data=train.iloc[:,[1,23]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_21,data0.var_21,'var_21')","809fc0b2":"data=train.iloc[:,[1,112]]\ndata0 = data.loc[data['target'] == 0]\ndata1 = data.loc[data['target'] == 1]\nplt_Density(data1.var_110,data0.var_110,'var_110')","f9c1b1d1":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import colors\nfrom matplotlib.ticker import PercentFormatter\n\ndef hst(data):\n\n\n# Creating distribution\n  n_bins = 20\n  legend = ['distribution']\n\n# Creating histogram\n  fig, axs = plt.subplots(1, 1,\n\t\t\t\t\t\tfigsize =(10, 7),\n\t\t\t\t\t\ttight_layout = True)\n\n\n# Remove axes splines\n  for s in ['top', 'bottom', 'left', 'right']:\n\t  axs.spines[s].set_visible(False)\n\n# Remove x, y ticks\n  axs.xaxis.set_ticks_position('none')\n  axs.yaxis.set_ticks_position('none')\n\n# Add padding between axes and labels\n  axs.xaxis.set_tick_params(pad = 5)\n  axs.yaxis.set_tick_params(pad = 10)\n\n# Add x, y gridlines\n  axs.grid(b = True, color ='grey',\n\t\tlinestyle ='-.', linewidth = 0.5,\n\t\talpha = 0.6)\n\n# Add Text watermark\n  fig.text(0.9, 0.15, '',\n\t\tfontsize = 12,\n\t\tcolor ='red',\n\t\tha ='right',\n\t\tva ='bottom',\n\t\talpha = 0.7)\n\n# Creating histogram\n  N, bins, patches = axs.hist(data, bins = n_bins)\n\n# Setting color\n  fracs = ((N**(1 \/ 5)) \/ N.max())\n  norm = colors.Normalize(fracs.min(), fracs.max())\n\n  for thisfrac, thispatch in zip(fracs, patches):\n\t  color = plt.cm.viridis(norm(thisfrac))\n\t  thispatch.set_facecolor(color)\n\n# Adding extra features\n  plt.xlabel(\"X-axis\")\n  plt.ylabel(\"y-axis\")\n  plt.legend(legend)\n  plt.title('Customized histogram')\n\n# Show plot\n  plt.show()\n","86163dbe":"data=train.iloc[:,[1,83]]\nhst(data.var_81)","7fb17bed":"data=train.iloc[:,[1,141]]\nhst(data.var_139)\n","a8187d21":"data=train.iloc[:,[1,14]]\nhst(data.var_12)\n","6b6536a7":"data=train.iloc[:,[1,55]]\nhst(data.var_53)","2d043ff9":"data=train.iloc[:,[1,168]]\nhst(data.var_166)","152cd283":"data=train.iloc[:,[1,8]]\nhst(data.var_6)","9b3e8480":"data=train.iloc[:,[1,176]]\nhst(data.var_174)","3eee84a0":"data=train.iloc[:,[1,24]]\nhst(data.var_22)","4557dfd0":"data=train.iloc[:,[1,23]]\nhst(data.var_21)","7205e977":"data=train.iloc[:,[1,112]]\nhst(data.var_110)","757db482":"data=train.iloc[:,[1,8,14,23,24,55,83,112,141,168,176]]\ndata.head(4)","50aaead7":"import seaborn as sns","31bc02c8":"sns.relplot(x='var_6', y='var_12', hue='var_21', size='var_22', col='target', data=data)","e0123e3f":"sns.heatmap(data.corr(), annot=True, fmt='.2f')\n","3ddff919":"sns.pairplot(data)","0fc68ff4":"sns.pairplot(data, hue='target')","7ec41e9b":"sns.jointplot(x='var_21', y='var_22', data=data)","e8f9d96a":"Load and check data\n\n","211ccc6c":"Now let\u2019s do the pairplot showing the charts segmented according to the values of the categorical variable","e0edfbb4":"Another interesting graphic is the ViolinPlot:","b262f2ed":"Summarie and statistics","523df0c8":"Below is the first 5 rows of test dataset:","abeea878":"Infos","f09ec4df":"The dimension and number of missing values in the train dataset is as below:","be499413":"#so  get 10 feature importance var_81 var_139 var_12 var_53 var_166 var_6 var_174 var_22 var_21 var_110"}}