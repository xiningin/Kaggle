{"cell_type":{"c8d5424f":"code","b13c618b":"code","690e6268":"code","7bb1ae8e":"code","d6461fa9":"code","06cee471":"code","705182af":"code","c7b05362":"code","0394645e":"code","6dbfa81c":"code","7c07c85d":"code","ab3b8c06":"code","d9672fa8":"code","5330b983":"code","535b5609":"code","7160db44":"code","0d6d0db2":"code","157b9cdc":"code","ad0fd8a6":"code","437207bf":"markdown","e83d3ad9":"markdown","22e196a9":"markdown","d298aef9":"markdown","864ff5ca":"markdown","b0b97869":"markdown","dcc712da":"markdown"},"source":{"c8d5424f":"#firts mini proyect on Generative Adversarial Neural Networks\nimport tensorflow as tf\nimport pandas as pd \nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom random import random\nimport random\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import Dense, Flatten,Dropout, Conv2DTranspose, Reshape,BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, LeakyReLU\nfrom tensorflow.keras import Input, Model\nfrom tqdm import tqdm # progress bar small tool","b13c618b":"# setting all seeds for repruducibilty\n\nseed = 789\n\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)","690e6268":"# loading the MNIST dataset\n\n(train_imgs, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","7bb1ae8e":"print(\"The train images shape is:\" + str(train_imgs.shape))\nprint(\"The train labels shape is:\" + str(train_labels.shape))","d6461fa9":"_ = plt.figure(figsize= (15,15))\n\n\nfor i in range(10):\n    \n    indexes = np.where(train_labels == i)[0][:5]\n    \n    for j,index in enumerate(indexes):\n        \n        plt.subplot(10, 5, i*5+j+1)\n        \n        plt.imshow(train_imgs[index], cmap = 'gray')   ","06cee471":"sns.countplot(train_labels)\nplt.title('Ocurrence of label')","705182af":"buffersize = train_imgs.shape[0] #buffer size is used to shuffle the dataset on every epoch, the buffer size must be at least the size of the dataset\nbatchsize = 128\n\ndef get_train_ds(train_imgs):\n    #adding 3rd dimension to be acceptable for training\n    train_imgs = np.expand_dims(train_imgs, axis = 3)\n\n    # creating the dataset for training\n    train_ds = tf.data.Dataset.from_tensor_slices(train_imgs)\n    train_ds = train_ds.shuffle(buffersize)\n    train_ds = train_ds.batch(batchsize)\n    \n    return train_ds\n\ntrain_ds = get_train_ds(train_imgs)","c7b05362":"#model for the generator\n\ndef create_generator_model():\n     \n    \n    inputs = Input(shape = (100,)) #this is a randomly generated vector\n    out_med = Dense(7*7*256, use_bias = False)(inputs)\n    out_med = BatchNormalization()(out_med)\n    out_med = tf.keras.layers.LeakyReLU()(out_med)\n    \n    out_med = Reshape((7,7,256))(out_med) \n    \n    # the following layer does the opossite of a Convolutional layer, and the strides control the output size\n    out_med = Conv2DTranspose(128, (5,5), strides = (1,1), use_bias = False, padding = \"same\")(out_med)\n    out_med = BatchNormalization()(out_med)\n    out_med = tf.keras.layers.LeakyReLU()(out_med)\n    \n    out_med = Conv2DTranspose(64, (5,5), strides = (2,2), use_bias = False, padding = \"same\")(out_med)\n    out_med = BatchNormalization()(out_med)\n    out_med = tf.keras.layers.LeakyReLU()(out_med)\n    \n    outputs = Conv2DTranspose(1, (5,5), strides = (2,2), use_bias = False, padding = \"same\", activation = 'sigmoid')(out_med)\n    \n    model = Model(inputs = inputs, outputs = outputs)\n    \n    model.summary()\n    \n    return model\n\ngenerator  = create_generator_model()","0394645e":"# generating some outputs from the untrained model with random weights \n_ = plt.figure(figsize=(20,10))\nfor i in range(5):\n    noise = tf.random.normal([1,100]) #generates random gaussian noise in shape (1,100)    \n    img = generator(noise)\n    plt.subplot(1,5,i+1)\n    plt.imshow(img[0,:,:,0]*255, cmap = 'gray') #it is multiplied by 255 because the output of the generator goes from 0 to 1\n    plt.title('Random image Generated')","6dbfa81c":"# model for the discriminator\n\ndef create_discriminator():\n    \n    inputs = Input(shape = (28,28,1,))\n    mid_out = Conv2D(64, (5,5), strides = (2,2), padding = 'same')(inputs)\n    mid_out = LeakyReLU()(mid_out)\n    mid_out = Dropout(0.3)(mid_out)\n    \n    mid_out = Conv2D(128, (5,5), strides = (2,2), padding = 'same')(mid_out)\n    mid_out = LeakyReLU()(mid_out)\n    mid_out = Dropout(0.3)(mid_out)\n    \n    mid_out = Flatten()(mid_out)\n    outputs = Dense(1, activation = 'sigmoid')(mid_out)\n    \n    model = Model(inputs = inputs, outputs = outputs)\n    \n    model.summary()\n    \n    return model\n\ndiscriminator = create_discriminator()","7c07c85d":"random_generated_img = generator(tf.random.normal([1,100]))\npredic = discriminator(random_generated_img)\nprint(predic)","ab3b8c06":"bin_crossentropy = tf.keras.losses.BinaryCrossentropy() #loss to be used","d9672fa8":"# defining the discriminator's loss\n\ndef disc_loss(real_out, fake_out):\n    real_loss = bin_crossentropy(tf.ones_like(real_out), real_out) #loss for real images\n    fake_loss = bin_crossentropy(tf.zeros_like(fake_out), fake_out) #loss for generated images\n    total_loss = real_loss + fake_loss\n    return total_loss\n\n# defining the generator's loss\n\ndef gen_loss(fake_out):\n    return bin_crossentropy(tf.ones_like(fake_out), fake_out) #the worst the discriminator does the better the generator does","5330b983":"# optimizers need to be separated becahse the models will be trained separately\n\ngen_opt = tf.keras.optimizers.Adam(1e-4)\ndisc_opt = tf.keras.optimizers.Adam(1e-4)","535b5609":"epochs = 50\nsamples = 15\n\nog_seed = tf.random.normal([samples, 100]) #seed used to visualize data while training and see the progess\n\n\ndef check_gen(og_seed, samples):\n    \n    \"\"\"\n    helper function to print 15 samples after each epoch to see how the generator is \n    doing\n    \"\"\"\n    \n    gen_images = generator(og_seed, training = False)\n    \n    _ = plt.figure(figsize=(8,8))\n\n    for i in range(samples):\n        \n        plt.subplot(3,5, i+1)\n        plt.imshow(gen_images[i,:,:,0]*255, cmap = 'gray') #it is multiplied by 255 because the output of the generator goes from 0 to 1\n       ","7160db44":"@tf.function #this line improves the performance\ndef train_step(images):\n    \n    noise = tf.random.normal([batchsize, 100])\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n\n        \n        generated_images = generator(noise, training = True) * 255 #it is multiplied by 255 because the output of the generator goes from 0 to 1\n        \n        real_out = discriminator(images, training = True)\n        fake_out = discriminator(generated_images, training = True)\n        \n        gene_loss = gen_loss(fake_out)\n        discr_loss = disc_loss(real_out, fake_out)\n        \n    gradients_of_generator = gen_tape.gradient(gene_loss, generator.trainable_variables) #obtain the gradient\n    gradients_of_discriminator = disc_tape.gradient(discr_loss, discriminator.trainable_variables)\n    \n    gen_opt.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) #apply the gradient to the models\n    disc_opt.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    ","0d6d0db2":"def train(dataset, epochs): # function to train the model\n    \n    for epoch in range(epochs):\n        \n        for image_batch in tqdm(dataset):\n            \n            train_step(image_batch)\n            \n        check_gen(og_seed, samples)","157b9cdc":"train(train_ds, 50)","ad0fd8a6":"for i in range(5):\n\n    og_seed = tf.random.normal([samples, 100])\n\n    check_gen(og_seed, samples)","437207bf":"Here is a predictor of the discriminator for a randomly generated image","e83d3ad9":"Here are some images created by the Generator without any training, they should seem as noise","22e196a9":"creating the dataset","d298aef9":"Simple Generative Adversarial Neural Networks using the Mnist dataset to generate decimal digits pictures. I based my project highly on this tutorial from Tensorflow https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan I just added small detail from me and my notes. Upvote if it helped you.","864ff5ca":"Small block to plot several samples from the dataset","b0b97869":"The discriminator is a very simple image classifier, the closer to 1 the more real the image seems.","dcc712da":"The countplot will help to see if the items are varied"}}