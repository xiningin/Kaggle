{"cell_type":{"469d90c4":"code","670894ce":"code","6991f9b3":"code","c2044d06":"code","5d9b0caa":"code","01a4ee06":"code","8ea72bcd":"code","17903995":"code","3513d1d0":"code","bbc91389":"code","e0a3765f":"code","dc7dfbd6":"code","c919087e":"code","9a8bde6a":"code","5a617f86":"code","68be86a6":"code","49a6a23f":"code","553984df":"code","b8b73cb8":"code","a282059c":"code","57f39181":"code","e525bd77":"code","763b5ecb":"code","a5ba73bd":"code","5231864c":"code","64ae1014":"code","23bd5fd7":"code","193d54c6":"code","81fe066c":"code","6a8212bc":"code","8536f4fa":"code","40d265dd":"code","0e9a8ee3":"code","31fe3312":"code","5b5ac7ed":"code","6f592895":"code","5fb1d417":"code","fa11b4cc":"code","391a0033":"code","13a19e8e":"code","455ca970":"code","318562c7":"code","4afe3686":"code","d4bef1b0":"code","e54bb17d":"code","a2afa7bc":"code","0a6d3141":"code","04324a11":"code","770c0225":"code","b5ba06d5":"code","493f187e":"code","f1ec9741":"code","8a277845":"code","654eda95":"code","37a3e0e3":"code","7e8c14ca":"code","73180fbf":"code","871d1d12":"code","e4d8e20d":"code","da7ed932":"code","33fe2f61":"code","0b91d97d":"code","dfdcbfa5":"code","1a95daac":"code","3c68d11a":"code","5b6965b9":"code","091595b5":"code","02cf54e1":"code","7e71ead9":"code","21e64ea1":"code","fd273a3b":"code","1866cf36":"code","7d7d1436":"code","1554ab8a":"markdown","361c1a83":"markdown","ec17f8e1":"markdown","2e3d7037":"markdown","2a78cc91":"markdown","63b2dae0":"markdown","6752d6aa":"markdown","f29567d1":"markdown","786d28df":"markdown","210e25b7":"markdown","d7360bb5":"markdown","67a3e205":"markdown","351eacf6":"markdown","604dee59":"markdown","6fd8cb92":"markdown","83be1d7f":"markdown","12082c71":"markdown","5c985b98":"markdown","c4562994":"markdown","55bd1244":"markdown","a6f1cb5c":"markdown","28339c2e":"markdown","2a456512":"markdown","29de4881":"markdown","49f754d5":"markdown","1a8bda93":"markdown"},"source":{"469d90c4":"2+2","670894ce":"print('He killed the man with fire') ","6991f9b3":"# importing spacy \nimport spacy\nfrom spacy import displacy\nnlp = spacy.load('en')","c2044d06":"# review text\n\ntext=\"This is one of the greatest films ever made. Brilliant acting by George C. Scott and Diane Riggs. This movie is both disturbing and extremely deep. Don't be fooled into believing this is just a comedy. It is a brilliant satire about the medical profession. It is not a pretty picture. Healthy patients are killed by incompetent surgeons, who spend all their time making money outside the hospital. And yet, you really believe that this is a hospital. The producers were very careful to include real medical terminology and real medical cases. This movie really reveals how difficult in is to run a hospital, and how badly things already were in 1971. I loved this movie.\"\nprint(text)","5d9b0caa":"# instantiate the document text\ndoc = nlp(text)  #disable=['parser','tagger','ner'])\n# which the SpaCy document methods and attributes\nprint(dir(doc))","01a4ee06":"from IPython.core.display import display, HTML\n# SpaCy pipeline\nspacy_url = 'https:\/\/spacy.io\/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg'\niframe = '<iframe src={} width=1000 height=200><\/iframe>'.format(spacy_url)\nHTML(iframe)","8ea72bcd":"# SpaCy pipeline\nspacy_url = 'https:\/\/spacy.io\/tokenization-57e618bd79d933c4ccd308b5739062d6.svg'\niframe = '<iframe src={} width=1500 height=200><\/iframe>'.format(spacy_url)\nHTML(iframe)","17903995":"# \n[ token.text for token in nlp(\" let's go to N.Y.!\")],\" let's go to N.Y.!\".split()","3513d1d0":"tok_doc=nlp(\"Some\\nspaces  and\\ttab characters\") # Let's go to N.Y.!'\n# tok_doc=nlp(\"Let's go to N.Y.!\")\ntokens_text = [t.text for t in tok_doc]\ntokens_text","bbc91389":"# import a list of stop words from SpaCy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\nprint('Example stop words: {}'.format(list(STOP_WORDS)[0:10]))","e0a3765f":"# word_list = ['feet', 'foot', 'foots', 'footing']\nword_list=['organize', 'organizes', 'organizing']","dc7dfbd6":"from nltk import stem\nwnl = stem.WordNetLemmatizer()\nporter = stem.porter.PorterStemmer()","c919087e":"[porter.stem(word) for word in word_list]","9a8bde6a":"# Lemmatization using nltk\n[wnl.lemmatize(word) for word in word_list]","5a617f86":"# Lemmatization using spacy\nfor token in nlp(\" \".join(word_list)):\n    print(token.text, token.lemma_)","68be86a6":"# review document\ndoc","49a6a23f":"# check if POS tags were added to the doc in the NLP pipeline\ndoc.is_tagged","553984df":"# print column headers\nprint('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | '.format(\n    'TEXT','LEMMA_','POS_','TAG_','DEP_','SHAPE_','IS_ALPHA','IS_STOP'))\n\n# print various SpaCy POS attributes\nfor token in doc:\n    print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} |'.format(\n          token.text, token.lemma_, token.pos_, token.tag_, token.dep_\n        , token.shape_, token.is_alpha, token.is_stop))","b8b73cb8":"spacy.explain('JJ')","a282059c":"previous_token = doc[0]  # set first token\n\nfor token in doc[1:]:    \n    # identify adjective noun pairs\n    if previous_token.pos_ == 'ADJ' and token.pos_ == 'NOUN':\n        print(f'{previous_token.text}_{token.text}')\n    \n    previous_token = token","57f39181":"for token in doc[0:20]:\n    print(f'{token.text}_{token.pos_}')","e525bd77":"spacy.explain('CARDINAL')","763b5ecb":"ner_text = \"When I told John that I wanted to move to Alaska, he warned me that I'd have trouble finding a Starbucks there.\"\nner_doc = nlp(ner_text)","a5ba73bd":"print('{:10} | {:15}'.format('LABEL','ENTITY'))\n\nfor ent in ner_doc.ents[0:20]:\n    print('{:10} | {:50}'.format(ent.label_, ent.text))","5231864c":"# ent methods and attributes\nprint(dir(ent))","64ae1014":"displacy.render(docs=ner_doc, style='ent', jupyter=True)","23bd5fd7":"spacy.explain('GPE')","193d54c6":"doc1 = nlp(\"Larry Page founded Google\") #\"Apple is looking at buying U.K. startup for $1 billion\"\ndisplacy.render(doc1, style=\"ent\")","81fe066c":"# dependency visualization\n\n# show visualization in Jupyter Notebook\ndisplacy.render(docs=doc, style='ent', jupyter=True)","6a8212bc":"\"This is a sentence. This is another sentence. let's go to N.Y.!\".split('.')","8536f4fa":"doc = nlp(\"This is a sentence. This is another sentence. let's go to N.Y.!\") \n\nfor sent in doc.sents:\n    print(sent.text)","40d265dd":"tokens = ['i', 'want', 'to', 'go', 'to', 'school'] # \"i_want\", want_to","0e9a8ee3":"def ngrams(tokens, n):\n    length = len(tokens)\n    grams = []\n    for i in range(length - n + 1):\n        grams.append(\"_\".join(tokens[i:i+n]))\n    return grams","31fe3312":"spacy.load('en')","5b5ac7ed":"print(ngrams(tokens, 2))","6f592895":"from collections import defaultdict,Counter","5fb1d417":"review = \"\"\"This is one of the greatest films ever made. Brilliant acting by George C. Scott and Diane Riggs.\nThis movie is both disturbing and extremely deep. Don't be fooled into believing this is just a comedy. \nIt is a brilliant satire about the medical profession. It is not a pretty picture. Healthy patients are killed by incompetent surgeons, who spend all their time making money outside the hospital. And yet, you really believe that this is a hospital. The producers were very careful to include real medical terminology and real medical cases.\nThis movie really reveals how difficult in is to run a hospital, and how badly things already were in 1971. I loved this movie.\"\"\".strip()\n\nexample_doc = nlp(review)","fa11b4cc":"# WRONG APPROACH - KeyError!\n\n# try to create a word count dict with new keys\nvocab = {}\nfor word in example_doc:\n    try:\n        vocab[word.text] += 1\n    except:\n        vocab[word.text] = 1\n    \nprint(vocab)","391a0033":"??defaultdict","13a19e8e":"d = defaultdict(int)  # define the type of data the dict stores\n\nfor word in example_doc:\n    d[word.text] += 1  # can add to unassigned keys\n\nprint(d)","455ca970":"somedict = {'a':2}\nprint(somedict[3]) # KeyError\n\n","318562c7":"someddict = defaultdict(int)\nprint(someddict[3]) # print int(), thus 0","4afe3686":"# count the number of times each CARDINAL appears\nprint(Counter(d))","d4bef1b0":"most_common=Counter(d).most_common(10)\nmost_common","e54bb17d":"most_common=Counter(review.split()).most_common(4)\nmost_common","a2afa7bc":"elems = [1, 2, 3, 4]\na, b, c, d = elems\nprint(a, b, c, d)","0a6d3141":"a, *new_elems, d = elems\nprint(a)\nprint(new_elems)\nprint(d)","04324a11":"elems = list(range(10))\nprint(elems)","770c0225":"print(elems[::-1]) # 9 8 76","b5ba06d5":"elems[::2],elems[-2::-2]","493f187e":"nums = [1,2,3,4,5]\nnums_squared = [num * num for num in nums if num %2==0]\nprint(nums_squared)","f1ec9741":"nums_squared=[]\nfor num in nums:\n    nums_squared.append(num)\n\nnums_squared","8a277845":"def square_fn(x):\n    return x * x\n\nsquare_ld = lambda x: x * x","654eda95":"# square_fn(5)\nsquare_ld(5)","37a3e0e3":"nums","7e8c14ca":"nums_squared_1 = map(square_fn, nums)\nnums_squared_2 = map(lambda x: x * x, nums)\nprint(list(nums_squared_1))\n","73180fbf":"filtered_Values = filter(lambda x: x > 10, nums)\nprint(list(filtered_Values))","871d1d12":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e4d8e20d":"data= pd.read_csv('\/kaggle\/input\/usinlppracticum\/imdb_train.csv')\ndata.head()","da7ed932":"data.iloc[1,0]","33fe2f61":"# create a small dataframe with example data\nexample_data = {'col1':range(0,3),'col2':range(3,6)}\ntest_df = pd.DataFrame(example_data)\ntest_df","0b91d97d":"# apply a built-in function to each element in a column\ntest_df['col1'].apply(float)","dfdcbfa5":"# apply a custom function to every element in a column\ndef add_five(row):\n    return row + 5\n\ntest_df['col1'].apply(add_five)","1a95daac":"test_df['col1'].apply(lambda x: x+5)","3c68d11a":"# apply an annonomous function to every element in a column\ntest_df['col1'].apply(lambda x: x+5)","5b6965b9":"articles =[('article2', 3, 'za'),('article3', 2, 'yb'),('article1', 1, 'xc')]","091595b5":"sorted(articles)","02cf54e1":"sorted(articles, key=lambda x: x[1])","7e71ead9":"# sort based on the last term\nsorted(articles, key=lambda x: x[2][1])","21e64ea1":"imdb_sample=data.sample(1000).reset_index(drop=True)","fd273a3b":"from tqdm import tqdm\ntqdm.pandas()","1866cf36":"def clean_review(x):\n    doc = nlp(x) #test_df['col1'].apply(add_five)\n    narrative = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-'] \n    narrative = [i for i in narrative if i not in STOP_WORDS]#  removing # list comprehension\n    return \" \".join(narrative)","7d7d1436":"%%time\nimdb_sample['clean']=imdb_sample['review'].apply(lambda x:clean_review(x)) #progress_","1554ab8a":"# Text Preprocessing \n\n##### Author: Alex Sherman | alsherman@deloitte.com, Vikas Kumar | vikkumar@deloitte.com","361c1a83":"### Tokenization\n\nSpaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off \u2013 whereas \"U.K.\" should remain one token. ","ec17f8e1":"##### STOPWORDS","2e3d7037":"##### Sorted\n\nsorted(iterable, key=None, reverse=False)\n\n- Return a new sorted list from the items in iterable.\n- Has two optional arguments which must be specified as keyword arguments.\n- key specifies a function of one argument that is used to extract a comparison key from each list element: key=str.lower. The default value is None (compare the elements directly).\n- reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed.\n\nSOURCE: https:\/\/docs.python.org\/3\/library\/functions.html#sorted","2a78cc91":"##### word sense disambiguation via part of speech tags","63b2dae0":"**What is NLP?**\n\nWhat can we do with NLP?\n\n* `information extraction`\n* `Text classification`\n   - Bag of words (tf-idf)\n   - deep learning (RNN\/LSTM\/Transformer)\n* `Language modeling\/ Natural Text Generation`\n* `Text Similairty`\n> * `Topic modeling`\n* Translation\n* Chat bot\n* Question answering\n* Text-to-speech and Speech-to-text","6752d6aa":"##### Pandas Apply\n\napply is an efficient and fast approach to 'apply' a function to every element in a row. applymap does the same to every element in the entire dataframe (e.g. convert all ints to floats)\n\nExample: https:\/\/chrisalbon.com\/python\/data_wrangling\/pandas_apply_operations_to_dataframes\/","f29567d1":"The general workflow for any Natural Language Processing Project","786d28df":" #### Lambda, map, filter, reduce","210e25b7":"* NLP\n* Intro to Kaggle Kernels \/ Jupyter Notebook\n* SpaCy- Text Tokenization, POS Tagging, Parsing, NER\n* Python Fundamentals: Collections, list comprehensions, sorted, apply","d7360bb5":"#### List Comprehension","67a3e205":"#### Stemming and lemmatization\n\nfrom [Information Retrieval](https:\/\/nlp.stanford.edu\/IR-book\/html\/htmledition\/stemming-and-lemmatization-1.html) textbook:\n\nAre the below words the same?\n\n`organize, organizes, and organizing`\n\n`democracy, democratic, and democratization`\n\nStemming and Lemmatization both generate the root form of the words.\n\nLemmatization uses the rules about a language. The resulting tokens are all actual words\n\n`\"Stemming is the poor-man\u2019s lemmatization.\" (Noah Smith, 2011) Stemming is a crude heuristic that chops the ends off of words. \nThe resulting tokens may not be actual words. Stemming is faster.`","351eacf6":"### Part-of-speech (POS) Tagging\n\nAfter tokenization, spaCy can parse and tag a given Doc. This is where the statistical model comes in, which enables spaCy to make a prediction of which tag or label most likely applies in this context. A model consists of binary data and is produced by showing a system enough examples for it to make predictions that generalize across the language \u2013 for example, a word following \"the\" in English is most likely a noun.\n\nAnnotation | Description\n:----- |:------|\nText |The original word text|\nLemma |The base form of the word.|\nPOS |The simple part-of-speech tag.|\nTag |The detailed part-of-speech tag.|\nDep |Syntactic dependency, i.e. the relation between tokens.|\nShape |The word shape \u2013 capitalisation, punctuation, digits.|\nIs Alpha |Is the token an alpha character?|\nIs Stop |Is the token part of a stop list, i.e. the most common words of the language?|","604dee59":"### References:\n* https:\/\/spacy.io\/api\/language\n* https:\/\/www.fast.ai\/2019\/07\/08\/fastai-nlp\/\n\n","6fd8cb92":"**Spacy Lemmatization example**\n* Adjectives: happier, happiest \u2192 happy\n* Adverbs: worse, worst \u2192 badly\n* Nouns: dogs, children \u2192 dog, child\n* Verbs: writes, writing, wrote, written \u2192 write","83be1d7f":"#### **LIST ** ****\nunpacking, slicing, ","12082c71":"### NLP Pipeline\n\nWhen you read the text into spaCy, e.g. doc = nlp(text), you are applying a pipeline of nlp processes to the text.\nby default spaCy applies a tagger, parser, and ner, but you can choose to add, replace, or remove these steps.\nNote: Removing unnecessary steps for a given nlp can lead to substantial descreses in processing time.","5c985b98":"### Fast Sentence Boundary Detection (SBD)","c4562994":"imdb - apply (len, tokenize )\nvalue_counts,\n","55bd1244":"### Named Entity Recognition (NER)\n\nA named entity is a \"real-world object\" that's assigned a name \u2013 for example, a person, a country, a product, or a book title. spaCy can recognise various types of named entities in a document, by asking the model for a prediction. ","a6f1cb5c":"'He killed the man with **fire**'","28339c2e":"### Python Fundamentals\nA brief overview of some advanced Python which will be used in future lessons","2a456512":"## SpaCy\n\n\"SpaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n\nIf you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other?\n\nSpaCy is designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n\nSpaCy is not research software. It's built on the latest research, but it's designed to get things done. This leads to fairly different design decisions than NLTK or CoreNLP, which were created as platforms for teaching and research. The main difference is that SpaCy is integrated and opinionated. SpaCy tries to avoid asking the user to choose between multiple algorithms that deliver equivalent functionality. Keeping the menu small lets SpaCy deliver generally better performance and developer experience.\"\n\n### SpaCy Features \n\nNAME |\tDESCRIPTION |\n:----- |:------|\nTokenization|Segmenting text into words, punctuations marks etc.|\nPart-of-speech (POS) Tagging|Assigning word types to tokens, like verb or noun.|\nDependency Parsing|\tAssigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.|\nLemmatization|\tAssigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".|\nSentence Boundary Detection (SBD)|\tFinding and segmenting individual sentences.|\nNamed Entity Recognition (NER)|\tLabelling named \"real-world\" objects, like persons, companies or locations.|\nSimilarity|\tComparing words, text spans and documents and how similar they are to each other.|\nText Classification|\tAssigning categories or labels to a whole document, or parts of a document.|\nRule-based Matching|\tFinding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.|\nTraining|\tUpdating and improving a statistical model's predictions.|\nSerialization|\tSaving objects to files or byte strings.|\n\nSOURCE: https:\/\/spacy.io\/usage\/spacy-101****","29de4881":"![nlp_pract.PNG](attachment:nlp_pract.PNG)","49f754d5":"**Next Lesson**\n* Text Vectorization\n* [Regex cheatsheet](https:\/\/www.cheatography.com\/davechild\/cheat-sheets\/regular-expressions\/)\n","1a8bda93":"#### IMDB REVIEW DATA EXPLORATION "}}