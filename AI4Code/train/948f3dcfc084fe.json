{"cell_type":{"35144f90":"code","6ffb05b9":"code","e29f6b89":"code","5caa66e0":"code","de27dd39":"code","02098cdf":"code","a56da820":"code","0faaf66f":"code","e4973e84":"code","68d2e4a5":"code","de347e5f":"code","47098b9c":"code","3804e831":"code","41f447c1":"code","cc49c70d":"markdown"},"source":{"35144f90":"import joblib\nimport warnings\n\nimport numpy\nimport pandas\nimport sklearn\n\nfrom matplotlib import pyplot\n\nfrom numpy import log, exp\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold","6ffb05b9":"class data_container:\n    pass\n\n\ndef data_load(data):\n    \"\"\" Load data from disk and store our target statistics. \"\"\"\n    train_features = pandas.read_csv('..\/input\/lish-moa\/train_features.csv')\n    test_features = pandas.read_csv('..\/input\/lish-moa\/test_features.csv')\n    train_targets = pandas.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\n    sample_submission = pandas.read_csv('..\/input\/lish-moa\/sample_submission.csv')\n\n    test_control = (test_features.cp_type == \"ctl_vehicle\")\n\n    def drop_useless(df):\n        not_used = [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]\n        df = df.drop(not_used, axis=1)\n        return df\n\n    train_features = drop_useless(train_features)\n    test_features = drop_useless(test_features)\n    train_targets = train_targets.drop(\"sig_id\", axis=1)\n\n    # whiten\n    mean = train_features.values.mean()\n    train_features -= mean\n    test_features -= mean\n\n    # store\n    data.train_features = train_features\n    data.train_targets = train_targets\n    data.test_features = test_features\n    data.test_control = test_control\n    data.submission = sample_submission\n\n\ndef data_fold(data, target_column_name, k=2, seed=None):\n    \"\"\" Iterate over k folds of the training data \"\"\"\n    kfold = StratifiedKFold(k, shuffle=(seed != None), random_state=seed)\n    features = data.train_features\n    targets = data.train_targets[target_column_name]\n    for itrain, itest in kfold.split(features, targets):\n        X_train, X_test = features.iloc[itrain], features.iloc[itest]\n        y_train, y_test = targets.iloc[itrain], targets.iloc[itest]\n        yield X_train, X_test, y_train, y_test\n\n\ndef data_sumbission(data, test_predictions, filename=\"submission.csv\"):\n    \"\"\" Write our submission \"\"\"\n    data.submission.iloc[:, 1:] = test_predictions\n    data.submission.iloc[data.test_control, 1:] = 0.0\n    data.submission.to_csv(filename, index=False)","e29f6b89":"data = data_container()\ndata_load(data)","5caa66e0":"def get_hitcount(data):\n    \"\"\" Return dict of MoA names to number of positive training examples. \"\"\"\n    return dict(data.train_targets.sum(0).sort_values(ascending=False))\n\ndef print_hitcount(data):\n    \"\"\" Print results of get_hitcount. \"\"\"\n    for i, (column_name, count) in enumerate(get_hitcount(data).items()):\n        print(\"%3d %-47s %d\" % (i, column_name, count))\n\n# print_hitcount(data) # Commented to shorten public notebook","de27dd39":"def log_likelihood(model, X_test, y_test):\n    \"\"\" Return log prob(y_test | X_test, model). \"\"\"\n    y_pred = model.predict_proba(X_test)\n    return -sklearn.metrics.log_loss(y_test, y_pred, normalize=False)","02098cdf":"def logistic(**kwargs):\n    \"\"\" Return a default logistic regression model. \"\"\"\n    config = dict(\n        C=1e-2,\n        max_iter=200,\n        intercept_scaling=1e3,\n    )\n    config.update(kwargs)\n    return LogisticRegression(**config)\n\n\ndef make_base_models():\n    \"\"\" Return a list of linear models to combine. \"\"\"\n    models = []\n    models.extend(\n        logistic(penalty=\"l1\", solver=\"liblinear\", C=C)\n        for C in (1e-4, 2e-4, 5e-4,\n                  1e-3, 2e-3, 5e-3,\n                  1e-2, 2e-2, 5e-2,\n                  1e-1, 2e-1, 5e-1)\n    )\n    models.extend(\n        logistic(C=C)\n        for C in (1e-6, 1e-5,\n                  1e-4, 2e-4, 5e-4,\n                  1e-3, 2e-3, 5e-3,\n                  1e-2, 2e-2, 5e-2,\n                  1e-1, 2e-1, 5e-1,\n                  1e0, 1e3)\n    )\n    return models","a56da820":"# Linear combination structures\nclass mixture:\n    def __init__(self, models, weights=None):\n        \"\"\" Initialize with fitted and their relative weights. \"\"\"\n        models = tuple(models)\n        \n        if weights is None:\n            weights = numpy.ones(len(models))\n\n        weights = numpy.asanyarray(weights)\n        weights \/= weights.sum()\n\n        assert len(models) == len(weights)\n        \n        self.models = models\n        self.weights = weights\n\n    def predict_proba(self, X):\n        \"\"\" Return the weighted sum of model results. \"\"\"\n        y_pred = numpy.array([\n            model.predict_proba(X)*weight\n            for model, weight in zip(self.models, self.weights)\n        ])\n        return y_pred.sum(axis=0)\n           \n    def prune(self, threshold):\n        \"\"\" Remove models with weight below threshold. \"\"\"\n        models = []\n        weights = []\n        for model, weight in zip(self.models, self.weights):\n            if weight < threshold:\n                continue\n            models.append(model)\n            weights.append(weight)\n            \n        models = tuple(models)\n        weights = numpy.array(weights)\n        weights \/= weights.sum()\n        \n        self.models = models\n        self.weights = weights\n\n\nclass kfoldmixture:\n    def __init__(self, base_models, prior=None):\n        \"\"\" Initialize with models to fit and their relative weihgts. \"\"\"\n        base_models = tuple(base_models)\n        \n        if prior is None:\n            prior = numpy.ones(len(base_models))\n\n        prior = numpy.asanyarray(prior)\n        prior \/= prior.sum()\n\n        assert len(base_models) == len(prior)\n        \n        self.base_models = base_models\n        self.prior = prior\n        \n        # mixture over folds, then over base models\n        self.model = None\n\n    def fit(self, fold_iter, verbose=False):\n        \"\"\" Fit models to the k-folded data generated. \"\"\"\n        chars = str(len(str(len(self.base_models))))\n        print_string = \"\\rfold %d, model %\" + chars + \"d\/%d\"\n        fold_models = []\n        for i, (X_train, X_test, y_train, y_test) in enumerate(fold_iter):\n            models = []\n            log_likelihoods = []\n            for j, model in enumerate(self.base_models):\n                if verbose:\n                    print(print_string % (i, j, len(self.base_models)), end='')\n                model = sklearn.base.clone(model)\n                model.fit(X_train, y_train)\n                models.append(model)\n                log_prob = log_likelihood(model, X_test, y_test)\n                log_likelihoods.append(log_prob)\n\n            if verbose:\n                print(print_string % (i, len(self.base_models), len(self.base_models)))\n\n            log_prod = log_likelihoods + log(self.prior)\n            weights = exp(log_prod - log_prod.max())\n            \n            fold_model = mixture(models, weights)\n            fold_models.append(fold_model)\n\n        self.model = mixture(fold_models)\n\n    def prune(self, threshold):\n        \"\"\" Remove components with weight below threshold. \"\"\"\n        for mixture in self.model.models:\n            mixture.prune(threshold)\n\n    def predict_proba(self, X):\n        \"\"\" Predict labels of new data X. \"\"\"\n        return self.model.predict_proba(X)\n\n    def log_loss(self, fold_iter):\n        \"\"\" Calculate log loss on the k-folded data generated. \"\"\"\n        log_loss = 0.0\n        n_total = 0\n\n        zipiter = zip(fold_iter, self.model.models)\n        for (X_train, X_test, y_train, y_test), model in zipiter:\n            log_loss -= log_likelihood(model, X_test, y_test)\n            n_total += len(y_test)\n\n        return log_loss\/n_total","0faaf66f":"def fit_target(data, column_name, k=2, seed=None, verbose=True):\n    \"\"\" Fit a linear combination of linear models to the given target column. \"\"\"\n\n    def fold_iter():\n        return data_fold(data, column_name, k=k, seed=seed)\n\n    mixture = kfoldmixture(make_base_models())\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore', category=sklearn.exceptions.ConvergenceWarning)\n        mixture.fit(fold_iter(), verbose=verbose)\n    mixture.prune(1e-15)\n    log_loss = mixture.log_loss(fold_iter())\n    return mixture, log_loss\n\n\ndef fit_target_sparse(data, column_name):\n    \"\"\" Hack to fit columns with almost-empty training data. \n\n        Hand tuned. No cross-validation here.\n    \"\"\"\n    X_train, y_train = data.train_features, data.train_targets[column_name]\n    \n    # l1 for sparsity, C tuned by hand to get ~a dozen columns in play\n    model = logistic(penalty=\"l1\", solver=\"liblinear\", C=0.8)\n    model.fit(X_train, y_train)\n    return model","e4973e84":"def fit_all(data, k=2, seed=None):\n    \"\"\" Run all our fitting and return fitted models. \"\"\"\n    hitcount = get_hitcount(data)\n\n    usual = tuple(\n        column_name\n        for column_name, count in hitcount.items()\n        if count >= k\n    )\n    \n    sparse = tuple(\n        column_name\n        for column_name, count in hitcount.items()\n        if not (count >= k)\n    )\n\n    model_loss = joblib.Parallel(3, verbose=10)(\n        joblib.delayed(fit_target)(data, column_name, k=k, seed=seed, verbose=True)\n        for column_name in usual\n    )\n    \n    log_loss = 0.0\n    column_models = {}\n    for i, (model, column_log_loss) in enumerate(model_loss):\n        column_name = usual[i]\n        log_loss += column_log_loss\n        column_models[column_name] = model\n        print(\"%3d\/%d %-47s logloss: %.6f, mean %.6f\" % \n              (i + 1, len(usual), column_name, column_log_loss, log_loss\/(i + 1)))\n\n    for i, column_name in enumerate(sparse):\n        print(\"%d\/%d %-47s (sum(y) == 1)\" % (i + 1, len(sparse), column_name))\n        model = fit_target_sparse(data, column_name)\n        column_models[column_name] = model\n\n    log_loss \/= len(usual)\n    print(\"log loss: %.6f\" % log_loss)\n    return column_models","68d2e4a5":"all_fitted = fit_all(data, k=3)","de347e5f":"def all_predict(data, all_fitted):\n    \"\"\" Return a DataFrame of predictions of test targets. \"\"\"\n    results = {}\n    test_features = data.test_features\n    for column_name, model in all_fitted.items():\n        y_pred = model.predict_proba(test_features)\n        y_pred = y_pred[:, 1]\n        results[column_name] = y_pred\n    return pandas.DataFrame(results)","47098b9c":"predictions = all_predict(data, all_fitted)","3804e831":"data_sumbission(data, predictions)","41f447c1":"joblib.dump(all_fitted, \"all_fitted.joblib\")","cc49c70d":"# Linear combinations of linear models\n\n**Heavily regularised logistic models** work surprisingly well.\n\n---\n**Description**\n\nList various plausible penalty parameters (l1, l2, varied C).\n\nIn each of *k* folds, fit logistic regression models for each penalty, for each MoA label.\n\nModels' predictions are weighted by the probability they assign to the test split (the non-normalised negative non-log loss).\n\nResults are not competitive, but pleasingly good for the model simplicity.\n\n---\n**Details**\n\nTwo MoAs have only one positive label in the training data:\n`erbb2_inhibitor` and\n`atp-sensitive_potassium_channel_antagonist`.\n\nSince that entry cannot be in both folds, these are simple fitted one l1 regularized model, tuned to use just a few features.\n\n\n---\n**Lessons**\n\nNon-linear variable transforms hurt; all I have tried performed worse. The data are already whitened and appear to have meaningful linearity.\n\nCategorical features hurt here. Tried one-hot encoding, but found worse results. Perhaps the risk of overfitting outweighs their information.\n"}}