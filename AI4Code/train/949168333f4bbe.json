{"cell_type":{"1a23f56c":"code","a01c1f4b":"code","09982cc6":"code","ae069f90":"code","041ba2ad":"code","c2c8e0e2":"code","79d58362":"code","9b7efa23":"code","1a71f4b0":"code","8fd2b795":"code","729a3330":"code","57b1e1ff":"code","4fa393eb":"code","04607397":"code","8e09c0e2":"code","413355c6":"code","8668341f":"code","8c33a8e7":"code","828d6d62":"code","fceb307f":"code","72ff9a09":"code","e05faa6e":"code","ffb06249":"code","9b9264a3":"code","724db08b":"code","1ca5db23":"code","87258d6e":"code","0a16f918":"code","1119bebd":"code","08962a17":"code","b935b4a5":"code","283f9dad":"code","509a5e39":"code","79fff08d":"code","7a66eea2":"code","58c6f71c":"code","530e9d44":"code","807d69e9":"code","c683311a":"code","006c215a":"code","38d75cd2":"code","d77b6a46":"code","5ed97200":"code","a37f7cb3":"code","abd78f48":"code","1fb9b731":"markdown","003a524f":"markdown","0acb9cdc":"markdown","1bc9d4aa":"markdown","788b64f6":"markdown","b9b79c49":"markdown","d62406e1":"markdown","06768a5e":"markdown","8aec00bd":"markdown","4bb8f857":"markdown","ccef77aa":"markdown","44ff648c":"markdown","15d74f21":"markdown","d0eabeb2":"markdown","d0a98a35":"markdown","535cbcbf":"markdown","1dc029b0":"markdown","40bdfbe3":"markdown","5f2e64b5":"markdown","61844dbc":"markdown","3914a14d":"markdown","1b344def":"markdown","87dcdcf0":"markdown","5f93585f":"markdown","d852c7b0":"markdown","2edeb663":"markdown","aca19161":"markdown","66bce4a0":"markdown","4ca0dab0":"markdown","4eb4012a":"markdown","5c3497ad":"markdown","acfd7e8f":"markdown"},"source":{"1a23f56c":"# Cargando librerias\nimport gc\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport datetime\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom itertools import product\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n","a01c1f4b":"# Cargando Datos\nroute = \"..\/input\/competitive-data-science-predict-future-sales\/\"\ncategorias = pd.read_csv(route + \"item_categories.csv\")\nitems = pd.read_csv(route + \"items.csv\")\nventas = pd.read_csv(route + \"sales_train.csv\")\ntiendas = pd.read_csv(route + \"shops.csv\")\ntest = pd.read_csv(route + \"test.csv\")\n\ndatos = {\"categorias\": categorias, \n         \"items\": items,\n         \"ventas\": ventas,\n         \"tiendas\": tiendas,\n         \"test\": test}","09982cc6":"# Revisando informacion basica de los datos\nfor nombre, dato in datos.items():\n    print(\"Informacion sobre: \" + nombre)\n    dato.info()\n    print(\"_\"*50)\n    print(\" \")\n    dato.isnull().sum()\n    print(\"_\"*50)\n    print(\" \")","ae069f90":"# Transformando a formato fecha\nventas[\"date\"] = ventas.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# Creando variables de mes y dia para considerar en el modelo\nventas[\"month\"] = ventas[\"date\"].dt.month\nventas[\"days\"] = ventas[\"date\"].dt.day","041ba2ad":"ventas.describe().apply(lambda s: s.apply('{0:.5f}'.format))","c2c8e0e2":"# Corrigiendo valores negativos - Precio\nneg_price = ventas.loc[ventas[\"item_price\"] < 0]\nmean_price_neg = ventas.loc[(ventas[\"shop_id\"].isin(neg_price[\"shop_id\"])) &\n                            (ventas[\"item_id\"].isin(neg_price[\"item_id\"])),\"item_price\"].mean()\nventas.loc[ventas[\"item_price\"] < 0, \"item_price\"] = mean_price_neg","79d58362":"# Corrigiendo valores negativos - Numero de items\nneg_items_cnt = ventas.loc[ventas[\"item_cnt_day\"] < 0]\nneg_items_cnt.shop_id.value_counts()","9b7efa23":"ventas = ventas.loc[ventas[\"item_cnt_day\"] >= 0]","1a71f4b0":"fig, ax = plt.subplots(2,1, figsize=(12,8))\nsns.boxplot(ventas[\"item_price\"], ax=ax[0])\nsns.boxplot(ventas[\"item_cnt_day\"], ax=ax[1])","8fd2b795":"ventas.loc[ventas[\"item_price\"] > 50000]","729a3330":"ventas.loc[ventas[\"item_cnt_day\"] > 500]","57b1e1ff":"ventas = ventas.loc[ventas[\"item_price\"] <= 50000]\nventas = ventas.loc[ventas[\"item_cnt_day\"] <= 500]\nprint(\"Conjunto de datos de ventas corregidos\")\nventas.describe().apply(lambda s: s.apply('{0:.5f}'.format))","4fa393eb":"ventas_tiempo = ventas.copy()\nventas_tiempo = ventas_tiempo.set_index('date')\ntotal_items_por_mes = ventas_tiempo.item_cnt_day.resample('M').sum()\n\nfig, ax = plt.subplots(figsize=(12,8))\nsns.lineplot(data=total_items_por_mes, ax=ax)","04607397":"ventas_tienda = ventas.groupby([\"shop_id\"])[\"item_cnt_day\"].sum()\nventas_tienda.sort_values(ascending=False, inplace=True)\nventas_tienda = ventas_tienda[0:10].reset_index()\nsns.barplot(y=\"item_cnt_day\", x=\"shop_id\", data=ventas_tienda, order=ventas_tienda.sort_values('item_cnt_day', ascending=False)[\"shop_id\"])","8e09c0e2":"ventas_tienda_item = ventas.groupby([\"shop_id\",\"item_id\"])[\"item_cnt_day\"].sum().reset_index()\n\nfor tienda in ventas_tienda_item.shop_id.unique():\n    agg_ventas_tienda = ventas_tienda_item.loc[ventas_tienda_item[\"shop_id\"] == tienda]\n    item_tienda_sort = agg_ventas_tienda.sort_values([\"item_cnt_day\"], ascending=False)\n    print(item_tienda_sort.max())\n    ","413355c6":"items.iloc[22167].item_name","8668341f":"ventas[\"revenue\"] = ventas[\"item_cnt_day\"] * ventas[\"item_price\"] \nventas_tienda = ventas.groupby([\"shop_id\"])[\"revenue\"].sum()\nventas_tienda.sort_values(ascending=False, inplace=True)\nventas_tienda = ventas_tienda[0:10].reset_index()\nsns.barplot(y=\"revenue\", x=\"shop_id\", data=ventas_tienda, order=ventas_tienda.sort_values('revenue', ascending=False)[\"shop_id\"])","8c33a8e7":"nov_ventas = ventas.loc[ventas[\"month\"] == 11]\ngroup_nov_ventas = nov_ventas.groupby([\"shop_id\", \"item_id\"])[\"item_cnt_day\"].sum().reset_index()\ntop20_nov_items = group_nov_ventas.sort_values([\"item_cnt_day\"], ascending=False)[0:20]\n\nsns.barplot(y=\"item_cnt_day\", x=\"shop_id\", data=top20_nov_items, \n            order=top20_nov_items.sort_values('item_cnt_day', ascending=False)[\"shop_id\"],\n            hue=\"item_id\")","828d6d62":"items.iloc[20949].item_name","fceb307f":"list_tiendas = tiendas.shop_name.str.split(\" \")\ntiendas[\"city\"] = [tienda[0] for tienda in list_tiendas]\ntiendas[\"shop_type\"] = [tienda[1] for tienda in list_tiendas]","72ff9a09":"#Corrigiendo los nombres de ciudades\ntiendas.loc[tiendas[\"city\"] == \"!\u042f\u043a\u0443\u0442\u0441\u043a\", \"city\"] = \"\u042f\u043a\u0443\u0442\u0441\u043a\"\ntiendas.loc[tiendas[\"city\"] == \"\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d\", \"city\"] = \"NA\"\ntiendas['city_id'] = LabelEncoder().fit_transform(tiendas['city'])\n#Corrigiendo los tipos de tiendas\ntiendas.loc[tiendas[\"shop_type\"] == \"\u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435,\", \"shop_type\"] = \"\u0434\u043e\u043c\u0435\"\ntiendas.loc[tiendas[\"shop_type\"] == \"(\u041f\u043b\u0435\u0445\u0430\u043d\u043e\u0432\u0441\u043a\u0430\u044f,\", \"shop_type\"] = \"\u0434\u043e\u043c\u0435\"\ntiendas.loc[tiendas[\"shop_type\"] == '\"\u0420\u0430\u0441\u043f\u0440\u043e\u0434\u0430\u0436\u0430\"', \"shop_type\"] = \"\u041c\u0422\u0420\u0426\"\ntiendas.loc[tiendas[\"shop_type\"] == '\u041f\u043e\u0441\u0430\u0434', \"shop_type\"] = \"\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d\"\ntiendas.loc[tiendas[\"shop_type\"] == '\u0427\u0421', \"shop_type\"] = \"\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d\"\ntiendas['shop_type_id'] = LabelEncoder().fit_transform(tiendas['shop_type'])\ntiendas","e05faa6e":"#Corrigiendo duplicacion de nombre de tiendas.\n# 0 - !\u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56 \u0444\u0440\u0430\u043d\n# 57 - \u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56\nventas.loc[ventas.shop_id == 57, \"shop_id\"] = 0\ntest.loc[test.shop_id == 57, \"shop_id\"] = 0\n\n# 1 - !\u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\" \u0444\u0440\u0430\u043d\n# 58 - \u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\"\nventas.loc[ventas.shop_id == 58, \"shop_id\"] = 1\ntest.loc[test.shop_id == 58, \"shop_id\"] = 1\n\n# 39 - \u0420\u043e\u0441\u0442\u043e\u0432\u041d\u0430\u0414\u043e\u043d\u0443 \u0422\u0420\u041a \"\u041c\u0435\u0433\u0430\u0446\u0435\u043d\u0442\u0440 \u0413\u043e\u0440\u0438\u0437\u043e\u043d\u0442\"\n# 40 - \u0420\u043e\u0441\u0442\u043e\u0432\u041d\u0430\u0414\u043e\u043d\u0443 \u0422\u0420\u041a \"\u041c\u0435\u0433\u0430\u0446\u0435\u043d\u0442\u0440 \u0413\u043e\u0440\u0438\u0437\u043e\u043d\u0442\" \u041e\u0441\u0442\u0440\u043e\u0432\u043d\u043e\u0439\nventas.loc[ventas.shop_id == 40, \"shop_id\"] = 39\ntest.loc[test.shop_id == 40, \"shop_id\"] = 39\n\n# 10 - \u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c?\n# 11 - \u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\u00b2\nventas.loc[ventas.shop_id == 11, \"shop_id\"] = 10\ntest.loc[test.shop_id == 11, \"shop_id\"] = 10\ntiendas.drop([57, 58, 40, 11])","ffb06249":"list_categorias = categorias.item_category_name.str.split(\" - \")\ncategorias[\"cat\"] = [cat[0] for cat in list_categorias]\n\nsubcat = []\nfor cat in list_categorias: \n    if len(cat) > 1:\n        subcat.append(cat[1])\n    else:\n        subcat.append(\"NA\")\n\ncategorias[\"subcat\"] = subcat\ncategorias[\"cat_id\"] = LabelEncoder().fit_transform(categorias[\"cat\"])\ncategorias[\"subcat_id\"] = LabelEncoder().fit_transform(categorias[\"subcat\"])\ncategorias.drop(\"item_category_name\", axis=1)","9b9264a3":"tiendas_ventas = set(ventas.shop_id.unique())\ntiendas_test = set(test.shop_id.unique())\n\nprint(\"Todas los tiendas del conjunto de prueba estan en los datos de entrenamiento?\")\nprint(tiendas_test.issubset(tiendas_ventas))","724db08b":"items_ventas = set(ventas.item_id.unique())\nitems_test = set(test.item_id.unique())\n\nprint(\"Todos los items del conjunto de prueba estan en los datos de entrenamiento?\")\nprint(items_test.issubset(items_ventas))\n\nprint(\"Items que estan en el base de datos de prueba pero no los datos de entrenamiento\")\nprint(\"Numero de items faltantes: \" + str(len(items_test - items_ventas)))\n","1ca5db23":"## Agrupando informacion de ventas por mes \n# La columna date_block_num representa los meses de forma consecutiva\ntotal_ventas_mes = ventas.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_cnt_day\"].sum().reset_index()\ntotal_ventas_mes = total_ventas_mes.fillna(0.0)\ntotal_ventas_mes","87258d6e":"formato_ventas = []\n\n# Generando todos los pares tienda-producto \nfor date_block in ventas[\"date_block_num\"].unique():\n    ventas_mes = ventas.loc[ventas[\"date_block_num\"] == date_block]\n    \n    tiendas_unicas = ventas.loc[ventas['date_block_num'] == date_block, 'shop_id'].unique()\n    items_unicos = ventas.loc[ventas['date_block_num'] == date_block, 'item_id'].unique()\n    formato_ventas.append(np.array(list(product([date_block], \n                                        tiendas_unicas, \n                                        items_unicos)), \n                                        dtype='int16'))\n\n# Cambiando formato de lista a DataFrame \nformato_ventas = pd.DataFrame(np.vstack(formato_ventas), columns=[\"date_block_num\", \"shop_id\", \"item_id\"]).reset_index()\nformato_ventas.sort_values(\"date_block_num\",inplace=True)\n\n#Combinando formato con ventas por mes\ntotal_ventas = pd.merge(formato_ventas, total_ventas_mes, on=[\"date_block_num\", \"shop_id\", \"item_id\"], how='left')\ntotal_ventas = total_ventas.fillna(0)\ntotal_ventas = total_ventas.drop(\"index\", axis=1)\ntotal_ventas[\"item_cnt_day\"] = total_ventas[\"item_cnt_day\"].astype(\"float16\")\n\n","0a16f918":"# Limpiando memoria para liberar espacio\ndel formato_ventas\ndel total_ventas_mes\ndel ventas_tiempo\ndel ventas_tienda_item\ndel ventas_mes\ndel top20_nov_items\ndel group_nov_ventas\ndel item_tienda_sort\ndel neg_items_cnt      \ndel total_items_por_mes\ndel agg_ventas_tienda\ndel fig, ax\ngc.collect()","1119bebd":"# Entrenamiento + Prueba\ntest.drop([\"ID\"], axis=1, inplace=True)\ntest[\"date_block_num\"] = 34\ntotal_ventas = pd.concat([total_ventas, test], ignore_index=True, \n                          sort=False, keys=[\"date_block_num\", \"shop_id\", \"item_id\"])\ntotal_ventas.fillna(0, inplace=True) \ntotal_ventas[\"date_block_num\"] = total_ventas[\"date_block_num\"].astype(\"int16\")\ntotal_ventas[\"shop_id\"] = total_ventas[\"shop_id\"].astype(\"int16\")\ntotal_ventas[\"item_id\"] = total_ventas[\"item_id\"].astype(\"int16\")\n","08962a17":"# Categoria y subcategorias de los items\nitems_cat = pd.merge(items,categorias,on=\"item_category_id\", how=\"left\")\nitems_cat.drop([\"item_name\",\"item_category_name\", \"item_category_id\",\"cat\",\"subcat\"], axis=1, inplace=True)\ntotal_ventas = pd.merge(total_ventas, items_cat, on=\"item_id\", how='left')\ntotal_ventas[\"cat_id\"] = total_ventas[\"cat_id\"].astype(\"int16\")\ntotal_ventas[\"subcat_id\"] = total_ventas[\"subcat_id\"].astype(\"int16\")\ndel items_cat","b935b4a5":"# Ciudad y tipo de tiendas\ntiendas_var = tiendas.drop([\"shop_name\",\"shop_type\",\"city\"],axis=1)\ntotal_ventas = pd.merge(total_ventas, tiendas_var, on=\"shop_id\", how='left')\ntotal_ventas[\"city_id\"] = total_ventas[\"city_id\"].astype(\"int16\")\ntotal_ventas[\"shop_type_id\"] = total_ventas[\"shop_type_id\"].astype(\"int16\")\ndel tiendas_var","283f9dad":"#mes\ntotal_ventas[\"month\"] = total_ventas[\"date_block_num\"] % 12 + 1","509a5e39":"# Retrasos(lags)\ndef lags_vars(target_df, target_cols, lags=[1,6,12]):\n    std_cols = ['date_block_num','shop_id','item_id'] # columnas estandar\n    \n    for col in target_cols:\n        std_cols.append(col)\n    \n    original = target_df.loc[:,std_cols]\n    \n    for lag in lags:\n        for col in target_cols:\n            shift = original.copy()\n            colname = \"lag_\"+str(lag)+\"_\"+col\n            shift.rename(columns={col: colname}, inplace=True)\n            \n        shift.loc[:,'date_block_num'] = shift.loc[:,'date_block_num'] + lag\n        target_df = pd.merge(target_df, shift, \n                             on=['date_block_num','shop_id','item_id'], \n                             how='left')\n    \n        \n    return target_df\n        ","79fff08d":"total_ventas = lags_vars(total_ventas, [\"item_cnt_day\"]).fillna(0)","7a66eea2":"#Funcion para generar datos agregados\ndef aggregate_data(data_df, target_df, cols, fun, name, target=\"item_cnt_day\"):\n    agg_values = data_df.groupby(cols)[target].apply(lambda x: fun(x)).reset_index()\n    agg_values = agg_values.rename({target: name}, axis=1)\n    target_df = pd.merge(target_df,agg_values, on=cols, how='left').fillna(0)\n    target_df[name] = target_df[name].astype(\"float16\")\n    return target_df","58c6f71c":"# Valores agregados\n# Promedio de numero de ventas por mes para cada tienda\ntotal_ventas = aggregate_data(data_df=ventas, target_df=total_ventas, \n                              cols=[\"date_block_num\", \"shop_id\"], \n                              fun=np.mean, \n                              name=\"mean_shop_block\")\n# Promedio de numero de ventas por mes para cada item\ntotal_ventas = aggregate_data(data_df=ventas, target_df=total_ventas, \n                              cols=[\"date_block_num\", \"item_id\"], \n                              fun=np.mean, \n                              name=\"mean_item_block\")\n# Promedio de numero de ventas por mes por cada categoria\nitems_cat = pd.merge(items,categorias,on=\"item_category_id\", how=\"left\")\nitems_cat.drop([\"item_name\",\"item_category_name\", \"item_category_id\",\"cat\",\"subcat\"], axis=1, inplace=True)\nventas_cat = pd.merge(ventas, items_cat, on=\"item_id\", how=\"left\")\n\ntotal_ventas = aggregate_data(data_df=ventas_cat, target_df=total_ventas, \n                              cols=[\"date_block_num\", \"cat_id\"], \n                              fun=np.mean, \n                              name=\"mean_cat_block\")\n\ntotal_ventas = aggregate_data(data_df=ventas, target_df=total_ventas, \n                              target=\"item_price\",\n                              cols=[\"date_block_num\", \"item_id\"], \n                              fun=np.mean, \n                              name=\"mean_item_price\")\n\ntotal_ventas","530e9d44":"total_ventas = lags_vars(total_ventas, [\"mean_shop_block\"]).fillna(0)\ntotal_ventas = lags_vars(total_ventas, [\"mean_item_block\"]).fillna(0)\ntotal_ventas = lags_vars(total_ventas, [\"mean_cat_block\"]).fillna(0)\ntotal_ventas = lags_vars(total_ventas, [\"mean_item_price\"]).fillna(0)","807d69e9":"total_ventas.columns","c683311a":"total_ventas.to_pickle('datos_final.pkl')","006c215a":"del ventas\ndel items\ndel categorias\ndel tiendas\ndel dato\ndel total_ventas\ndel ventas_cat\ndel aggregate_data\ndel neg_price","38d75cd2":"%whos","d77b6a46":"final_data = pd.read_pickle('datos_final.pkl')","5ed97200":"train_set = final_data.loc[final_data[\"date_block_num\"] < 33]\nx_train = train_set.drop('item_cnt_day', axis=1)\ny_train = train_set['item_cnt_day']\n                             \nval_set = final_data.loc[final_data[\"date_block_num\"] == 33]\nx_val = val_set.drop('item_cnt_day', axis=1)\ny_val = val_set['item_cnt_day']\n\ntest_set = final_data.loc[final_data[\"date_block_num\"] == 34]\nx_test = test_set.drop('item_cnt_day', axis=1)\ny_test = test_set['item_cnt_day']\n                        \ndel train_set \ndel val_set\ndel test_set","a37f7cb3":"model = XGBRegressor(max_depth=10, n_estimators=1000, min_child_weight=100, \n                     colsample_bytree=0.8, subsample=1, eta=0.2)\n\nmodel.fit(x_train, y_train, eval_metric=\"rmse\", \n          eval_set=[(x_train, y_train), (x_val, y_val)], \n          verbose=True, \n          early_stopping_rounds = 20)\n","abd78f48":"# Se usa el modelo para predecir el numero de ventas\ny_test = model.predict(x_test).clip(0, 20)\n\nfinal = pd.DataFrame({\"ID\": test.index, \"item_cnt_month\": y_test})\n\nfinal.to_csv('gb_results.csv', index=False)","1fb9b731":"# Limpieza de los datos y Feature Engineering","003a524f":"Se identifica cuantos registros por tienda presentan errores sobre el numero de productos vendidos. Debido a que no tiene sentido contar con un numero negativo de ventas, se asume que es un error de sistema y se eliminan estos registros del analisis.","0acb9cdc":"* El 75% de los precios se concentra en valores menores a 999, los precios mas extremos se observan en muy baja cantidad. Hay un item con un precio por encima de los 300K y 2 por encima de los 50K.  \n* El 75% de los items vendidos es de una unidad por dia, se observan solo dos articulos con valores por encima de las 1000 unidades vendidas por dia y solo 12 articulos con valores encima de las 500 unidades.\n* Con base en lo anterior se opta por filtrar los items con precios menores a 50K y cantidad de items vendida por debajo de las 500 unidades por dia.","1bc9d4aa":"Se analiza la distribucion del precio por item y el numero de items vendidos por dia mediante diagramas de box. ","788b64f6":"\u00bfCu\u00e1l es el item mas popular en cada tienda?","b9b79c49":"# Modelamiento\n\nUsaremos el modelo de Gradient Boosting para predecir el numero de productos vendidos. ","d62406e1":"Hay items en los datos de prueba que no estan en los datos de entrenamiento. Debido a que no se cuenta con informacion sobre estos productos, es de esperar que la prediccion del modelo sobre la venta de estos nuevos productos sea 0.  ","06768a5e":"# Categorias\n\nAl traducir las categorias se observa que tienen una categoria y una subcategoria. Por ejemplo \u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b - PS2 es Accesorios - PS2. Esto crea variables adicionales que pueden ser consideradas en el modelo.","8aec00bd":"# Autocorrelacion y Retrasos\n\nEn problemas con series de tiempo es usual que se analize si la serie de datos presenta autocorrelaciones, es decir que existen correlaciones entre datos en diferentes periodos de tiempo. Por ejemplo cuando se estudia los cambios de temperatura en diferentes dias, la temperatura tiende a ser mas alta a mediodia y baja a medianoche, independiente del dia. Esto causa una correlacion entre temperaturas tomadas en horas similares.\n\nEn este caso al analizar el numero de ventas a traves del tiempo vemos que se repiten picos de venta en Noviembre y posterior descenso del numero de ventas en Enero y Febrero, asi como repuntes en Junio-Julio. Lo que nos lleva a pensar que hay autocorrelacion en los datos. Con el fin de capturar esta informacion se a\u00f1aden retrasos (lags) como predictores. Para mas informacion sobre autocorrelacion y el uso de retrasos consulte el libro *Algoritmos para ciencia de datos* de Steele, Chandler y Reddy:\n\nSteele, B., Chandler, J., & Reddy, S. (2016). Forecasting. In B. Steele, J. Chandler, & S. Reddy, Algorithms for Data Science (pp. 343-375). Missoula, MT: Springer International Publishing.","4bb8f857":"# Prediccion de futuras ventas (predict future sales) \nEn este cuaderno se realiza una exploraci\u00f3n de analisis de datos y modelamiento predictivo de las futuras ventas mensuales para la compa\u00f1ia 1C Company. El objetivo principal es predecir las ventas totales de cada producto y tienda para el proximo mes. \n\n**\u00bfQui\u00e9n es 1C Company?**\n\nEsta compa\u00f1ia rusa se dedica a manufacturar, licenciar, vender y dar soporte a software, videojuegos y servicios adicionales. Varios de sus productos se enfocan en soluciones para el negocio incluyendo soluciones ERP, contabilidad, financias y gerencia. Tiene una posici\u00f3n lider en el mercado de software comercial ruso. \n","ccef77aa":"Analizando el top 20 de los productos mas vendidos en los meses de Noviembre, se observa que el item 20949 (\u0424\u0438\u0440\u043c\u0435\u043d\u043d\u044b\u0439 \u043f\u0430\u043a\u0435\u0442 \u043c\u0430\u0439\u043a\u0430 1\u0421 \u0418\u043d\u0442\u0435\u0440\u0435\u0441 \u0431\u0435\u043b\u044b\u0439 (34*42*) 45 \u043c\u043a\u043c) es el mas popular es varias tiendas. Este producto es una camisa con el logo de 1C company. Esto lleva a sospechar que hay un evento o festividad que realiza la compa\u00f1ia para promocionarse durante este mes, que incluye ofertas por este producto.    ","44ff648c":"\u00bfCu\u00e1l tienda produce mayores ganancias?","15d74f21":"La gran mayoria de la informaci\u00f3n se encuentra en el .csv de **ventas** con 2935848 datos. Este conjunto de datos contiene las ventas diarias generadas desde Enero 2013 hasta Octubre 2015. Este set de datos presenta 6 variables:  \t\n\n*date:* fecha en formato dd\/mm\/yyyy.  \t<br>\n*date_block_num:* numeracion consecutiva por mes, donde Enero 2013 es 0, Febrero 2013 es 1 y asi hasta Octubre 2015 que es 33. <br>\n*shop_id*: Identificador unico de la tienda. <br>\n*item_id*: Identificador unico del item. <br>\n*item_price*: Precio actual del item. <br>\n*item_cnt_day*: Numero de Unidades Vendidas. Variable que se busca predecir (en tama\u00f1o por meses). <br>\n\nEl segundo conjunto de datos mas grande es **test** que contiene la informacion de las ventas que se buscan predecir para Noviembre 2015. Tiene 214199 datos y presenta 3 variables.\n\n*ID*: tuple que representa la tienda y el item. <br>\n*shop_id*: Identificador unico de la tienda. <br>\n*item_id*: Identificador unico del item. <br>\n\nEl resto de los datos son variables auxiliares que sirven para identificar los items, categorias y tiendas.\n\nNo se observan datos faltantes","d0eabeb2":"# Importando librerias y datos","d0a98a35":"* Picos de ventas en Noviembre. - seasonality\n* Incremento de ventas para el mes de Junio. - Julio \n* Numero de items vendidos decrece con el tiempo.","535cbcbf":"# Descripcion de los datos","1dc029b0":"# Integrando Datos\n\nSe combinan los set de datos de entrenamiento y prueba para poder a\u00f1adir variables adicionales como Categorias, Ciudad de la Tienda, Tipo de Tienda y valores promedio al conjunto de datos, posteriormente se realiza la separacion durante el modelamiento.","40bdfbe3":"# Media movil (Mobile Average)\n\nOtra metrica muy utilizada en analisis de series es la media movil. La idea detras de esta metrica es crear una serie de promedio de diferentes subconjuntos del set de datos. Esto permite reducir el efecto de fluctuaciones cortas en el tiempo y concentrarse en patrones de mayor duracion. \n\nEn este caso se toman los promedios del numero de venta por cada mes bajo diferentes agrupaciones. En particular tomaremos 3 promedios:\n\n* Numero de ventas por mes por cada tienda. \n* Numero promedio de ventas por mes por cada articulo.\n* Numero promedio de ventas por mes por cada categoria.\n\nAdicionalmente se realiza un retraso para estas promedios para incluir este efecto en el modelo.","5f2e64b5":"Como se puede observar, hay valores extra\u00f1os en el precio y el numero de items vendidos por dia. Al analizar el precio se observa que hay items con valores negativos y items con precios exorbitantes. En el conteo por day vemos que hay un numero negativo de items vendidos, lo cual no tiene mucho sentido, asi como uno o mas items con gran cantidad de ventas por dia (2169). ","61844dbc":"El trend de tiempo muestra picos claramente definidos para los meses de Noviembre 2013 y 2014, asi que resulta de interes saber que tiendas y items se venden durante estos meses en particular.","3914a14d":"La tienda con mayor volumen de ventas total es la 31, seguida de la 25 y la 54. Examinando las tiendas se observa que 4 de las tiendas con mayor volumen de ventas quedan en Moscu. Ademas, la gran mayoria de las ventas se obtienen en centro comerciales (\u0422\u0426 o \u0422\u0420\u041a). A pesar de ser un negocio de software, gran parte de las ventas no se realiza online, se realiza por medios tradicionales.","1b344def":"# Guardar datos final\n\nSe guarda los datos finales como archivo .pkl para poder cargar posteriormente en el modelo. Debido a que el cuaderno esta en Kaggle, la ruta donde se encuentra el archivo es *\/kaggle\/working*. Esta carpeta es temporal y solo aplica cuando se corre el cuaderno. Posteriomente es borrada automaticamente en el servidor","87dcdcf0":"Como se esperaba, las tiendas 31 y 25 con el mayor volumen de ventas son las tiendas mas rentables de todas. Sin embargo algunas tiendas con menor volumen de ventas son mas rentables que otras con mayor volumen. Por ejemplo la tienda 28 es mas rentable que la tienda 57 a pesar que la tienda 57 vende mas productos. Incluso las tiendas 6 y 12 que no aparecen en el top 10 de mayor volumen de ventas si aparecen en el Top 10 de tiendas rentables. Seria interesante revisar que tipo de productos se venden en esas tiendas. ","5f93585f":"# Datos de Prueba\n\nSe analiza si todos las tiendas y todos los items en el conjunto de entrenamiento estan en los datos de prueba. ","d852c7b0":"# Tiendas\n\nDespues de traducir los nombres de las tiendas mediante DeepL https:\/\/www.deepl.com\/translator, se observan tres puntos importantes:\n\n1. Muchas tiendas empiezan con el nombre de la cuidad.\n2. Algunas tiendas tienen el tipo de local (Centro Comercial, tienda, etc.) \n3. Hay nombres de tienda repetidos. ","2edeb663":"No todas las tiendas venden todos los productos, por lo cual hay vacios entre los pares de tiendas-productos en este set de datos. Por otro lado, el formato de los datos de prueba muestra los mismos productos para todas las tiendas. Con el fin de mantener el mismo formato para ambos set de datos resulta mas conveniente crear un formato con todos los pares de tienda producto y colocar 0 en el numero de ventas cuando la tienda no venda ese producto.","aca19161":"\u00bfCu\u00e1l tienda tiene un mayor volumen de ventas?","66bce4a0":"# Cambiar formato de los datos\n\nDebido a que el objetivo es predecir el numero de ventas de cada tienda e item en un mes. Es necesario organizar la informacion por meses. Para ello la variable *date_block_num* es muy util ya que nos permite organizar la informacion por meses de manera ascendente. ","4ca0dab0":"Se observa que el item 22167 (\u042f\u0437\u044b\u043a \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 1\u0421:\u041f\u0440\u0435\u0434\u043f\u0440\u0438\u044f\u0442\u0438\u044f 8 (+CD). \u0425\u0440\u0443\u0441\u0442\u0430\u043b\u0435\u0432\u0430 \u0415.\u042e.') es bastante popular en muchas de las tiendas. Este item es un libro de consulta de 1C Company. Para todos los casos, los items en el catalogo presentan un alto valor de id, seria necesario revisar a que categoria pertenecen estos articulos.  ","4eb4012a":"# Exploracion inicial de los datos\n# Ventas\n\n","5c3497ad":"# Analisis exploratorio de los datos","acfd7e8f":"\u00bfC\u00faantos items fueron vendidos por mes?"}}