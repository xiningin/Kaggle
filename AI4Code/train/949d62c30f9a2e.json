{"cell_type":{"5996e153":"code","c3d291e6":"code","98bb59b2":"code","0d21e6a3":"code","1a1009f1":"code","bb83adf0":"code","dbdab1df":"code","e068e2bf":"code","36c1403e":"code","80ba76be":"code","69445da3":"code","dae8f78b":"code","ff914066":"code","7984702c":"code","e35a5fd3":"code","df4f327a":"code","7ec0b091":"code","fac42ddc":"code","083ddd8d":"code","c6846079":"code","230a410a":"code","9444e6b6":"code","dc9deee2":"code","450ef662":"code","87f062c3":"code","5500277d":"code","6e039ae4":"code","7c61a796":"code","71de1f41":"code","bee57d92":"code","2f1e93b2":"markdown","b551f8d8":"markdown","bc5ad2ce":"markdown","6c2362db":"markdown","89359a6e":"markdown","026fd435":"markdown","d51aa667":"markdown","58ff1d8a":"markdown","3921d25e":"markdown","224a22d1":"markdown","cf692c94":"markdown","de9dd39f":"markdown","3a0f2f89":"markdown","76476f01":"markdown","9d510958":"markdown","e6843460":"markdown"},"source":{"5996e153":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_palette(\"husl\")\nimport os\nprint(os.listdir(\"..\/input\/\"))\nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\nfrom pathlib import Path\nfrom PIL import Image\nfrom IPython.display import clear_output\nfrom tqdm import tqdm_notebook as tqdm","c3d291e6":"labels_df = pd.read_csv(\"..\/input\/labels.csv\")","98bb59b2":"labels_df.head()","0d21e6a3":"labels_df.tail()","1a1009f1":"print(f\"labels.csv have {labels_df.shape[0]} attributes_name.\")","bb83adf0":"kind_dict = {}\nfor i in range(len(labels_df)):\n    kind, name = labels_df.attribute_name[i].split(\"::\")\n    if(kind in kind_dict.keys()):\n        kind_dict[kind] += 1\n    else:\n        kind_dict[kind] = 1\nfor key, val in kind_dict.items():\n    print(\"The number of {} is {}({:.2%})\".format(key, val, val\/len(labels_df)))","dbdab1df":"label_dict = labels_df.attribute_name.to_dict()","e068e2bf":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntrain_df.head()","36c1403e":"test_path = Path(\"..\/input\/test\/\")\ntest_num = len(list(test_path.glob(\"*.png\")))\ntrain_num = len(train_df)\nfig, ax = plt.subplots()\nsns.barplot(y=[\"train\", \"test\"], x=[train_num, test_num])\nax.set_title(\"The amount of data\")\nclear_output()","80ba76be":"id_len_dict = {}\nid_num_dict = {}\nfor i in range(train_df.shape[0]):\n    ids = list(map(int, train_df.attribute_ids[i].split()))\n    id_len = len(ids)\n    if(id_len in id_len_dict.keys()):\n        id_len_dict[id_len] += 1\n    else:\n        id_len_dict[id_len] = 1\n    for num in ids:\n        if(num in id_num_dict.keys()):\n            id_num_dict[num] += 1\n        else:\n            id_num_dict[num] = 1","69445da3":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\nsns.barplot(x=list(id_len_dict.keys()), y=list(id_len_dict.values()), ax=ax1)\nax1.set_title(\"The number of attribute_id per image\")\nax2.bar(list(id_num_dict.keys()), list(id_num_dict.values()))\nax2.set_title(\"Appearance frequency of attribute\")\nax2.set_xticks(np.linspace(0, max(id_num_dict.keys()), 10, dtype='int'))\nclear_output()","dae8f78b":"id_len_list = sorted(id_len_dict.items(), key=lambda x: -x[1])\nprint(\"The number of attribute_id per image\\n\")\nprint(\"{0:9s}{1:20s}\".format(\"label num\".rjust(9), \"amount\".rjust(20)))\nfor i in id_len_list:\n    print(\"{0:9d}{1:20d}\".format(i[0], i[1]))","ff914066":"id_num_list = sorted(id_num_dict.items(), key=lambda x: -x[1])\nprint(\"Top 10 high appearance frequency attitude\\n\")\nprint(\"{0:4s}{1:15s}{2:30s}\".format(\"rank\".rjust(4), \"num\".rjust(15), \"attitude_name\".rjust(30)))\nfor i in range(10):\n    print(\"{0:3d}.{1:15d}{2:30s}\".format(i+1, id_num_list[i][1], (label_dict[id_num_list[i][0]]).rjust(30)))","7984702c":"id_num_list = sorted(id_num_dict.items(), key=lambda x: x[1])\nprint(\"Top 16 low appearance frequency attitude\\n\")\nprint(\"{0:4s}{1:15s}{2:30s}\".format(\"rank\".rjust(4), \"num\".rjust(15), \"attitude_name\".rjust(50)))\nfor i in range(16):\n    print(\"{0:3d}.{1:15d}{2:50s}\".format(i+1, id_num_list[i][1], (label_dict[id_num_list[i][0]]).rjust(50)))","e35a5fd3":"train_path = Path(\"..\/input\/train\/\")\nfig, ax = plt.subplots(3, figsize=(10, 20))\nfor i, index in enumerate(np.random.randint(0, len(train_df), 3)):\n    path = (train_path \/ (train_df.id[index] + \".png\"))\n    img = np.asarray(Image.open(str(path)))\n    ax[i].imshow(img)\n    ids = list(map(int, train_df.attribute_ids[index].split()))\n    for num, attribute_id in enumerate(ids):\n        x_pos = img.shape[1] + 100\n        y_pos = (img.shape[0] - 100) \/ len(ids) * num + 100\n        ax[i].text(x_pos, y_pos, label_dict[attribute_id], fontsize=20)","df4f327a":"test_path = Path(\"..\/input\/test\/\")\ntest_img_paths = list(test_path.glob(\"*.png\"))\nfig, ax = plt.subplots(3, figsize=(10, 20))\nfor i, path in enumerate(np.random.choice(test_img_paths, 3)):\n    img = np.asarray(Image.open(str(path)))\n    ax[i].imshow(img)","7ec0b091":"def check_area_size(folder_path):\n    area_list = []\n    max_width = None\n    min_width = None\n    max_height = None\n    min_height = None\n    img_paths = list(folder_path.glob(\"*.png\"))\n    for path in tqdm(img_paths):\n        img = np.asarray(Image.open(str(path)))\n        shape = img.shape\n        area_list.append(shape[0]*shape[1])\n        if(max_width is None):\n            max_width = (shape[1], path)\n            min_width = (shape[1], path)\n            max_height = (shape[0], path)\n            min_height = (shape[0], path)\n        else:\n            if(max_width[0] < shape[1]):\n                max_width = (shape[1], path)\n            elif(min_width[0] > shape[1]):\n                min_width = (shape[1], path)\n            if(max_height[0] < shape[0]):\n                max_height = (shape[0], path)\n            elif(min_height[0] > shape[0]):\n                min_height = (shape[0], path)\n    return area_list, max_width, min_width, max_height, min_height","fac42ddc":"train_area_list, train_max_width, train_min_width, train_max_height, train_min_height\\\n    = check_area_size(train_path)\nclear_output()","083ddd8d":"print(\"test max area size is {}\".format(max(train_area_list)))\nprint(\"test min area size is {}\".format(min(train_area_list)))\nprint(\"Max area is {:.2f} times min area\".format(max(train_area_list)\/ min(train_area_list)))","c6846079":"print(f\"max train image width is {train_max_width[0]}\")\nimg = np.asarray(Image.open(str(train_max_width[1])))\nplt.imshow(img)\nplt.show()","230a410a":"print(f\"min train image width is {train_min_width[0]}\")\nimg = np.asarray(Image.open(str(train_min_width[1])))\nplt.imshow(img)\nplt.show()","9444e6b6":"print(f\"max train image height is {train_max_height[0]}\")\nimg = np.asarray(Image.open(str(train_max_height[1])))\nplt.imshow(img)\nplt.show()","dc9deee2":"print(f\"min train image height is {train_min_height[0]}\")\nimg = np.asarray(Image.open(str(train_min_height[1])))\nplt.imshow(img)\nplt.show()","450ef662":"test_area_list, test_max_width, test_min_width, test_max_height, test_min_height\\\n    = check_area_size(test_path)\nclear_output()","87f062c3":"print(\"test max area size is {}\".format(max(test_area_list)))\nprint(\"test min area size is {}\".format(min(test_area_list)))\nprint(\"Max area is {:.2f} times min area\".format(max(test_area_list)\/ min(test_area_list)))","5500277d":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharex=True)\nsns.distplot(train_area_list, kde=False, ax=ax1)\nax1.set_title(\"Distribution of the train image area\")\nsns.distplot(test_area_list, kde=False, ax=ax2)\nax2.set_title(\"Distribution of the test image area\")\nplt.show()","6e039ae4":"print(f\"max test image width is {test_max_width[0]}\")\nimg = np.asarray(Image.open(str(test_max_width[1])))\nplt.imshow(img)\nplt.show()","7c61a796":"print(f\"min train image width is {test_min_width[0]}\")\nimg = np.asarray(Image.open(str(test_min_width[1])))\nplt.imshow(img)\nplt.show()","71de1f41":"print(f\"max train image height is {test_max_height[0]}\")\nimg = np.asarray(Image.open(str(test_max_height[1])))\nplt.imshow(img)\nplt.show()","bee57d92":"print(f\"min train image height is {test_min_height[0]}\")\nimg = np.asarray(Image.open(str(test_min_height[1])))\nplt.imshow(img)\nplt.show()","2f1e93b2":"Check the amount of train\/test data!","b551f8d8":"Dataset images have big difference in size(10 times over).  \nAnd image that have big difference between width and height(like about 280\\*5314) is exist in dataset.  \nI think we need care that adjust the size.","bc5ad2ce":"# Let's recognize artwork attributes from The Metropolitan Museum of Art","6c2362db":"## labels.csv\n* labels.csv provides descriptions of the attributes","89359a6e":"Test data is small.  \nBecause this competition is 2-stage.  \nWe can see the**The second-stage test set is approximately five times the size of the first.** in [Data Description](https:\/\/www.kaggle.com\/c\/imet-2019-fgvc6\/data).  \nSo please care your memory usage in kernel!","026fd435":"# Thank you for watching!\nI hope this will help.  \nPlease tell me if i make mistake.  ","d51aa667":"## Note\nThis is a Kernels-only competition  \nSubmissions to this competition must be made through Kernels. In order for the \"Submit to Competition\" button to be active after a commit, the following conditions must be met:  \n\n* 9 hour runtime limit (including GPU Kernels)  \n* No internet access enabled  \n* Only whitelisted data is allowed  \n* No custom packages  \n* Submission file must be named \"submission.csv\"  \nPlease see the [Kernels-only](https:\/\/www.kaggle.com\/docs\/competitions#kernels-only-FAQ) FAQ for more information on how to submit.","58ff1d8a":"Let's check the number of culture and tag.","3921d25e":"WTF!? what is this...","224a22d1":"Check the number of attribute_id per image and appearance frequency of attribute!","cf692c94":"* The number of attribute_id per image  \nMost data have 1-6 labels.  \nBut few data have 7-11 labels.  \nThe data that have 11 labels is only one!!!\n\n\n* Appearance frequency of attribute  \nTop2 high appearance frequency tag is \"men\" and \"women\".  \nTop3 high appearance frequency culture is \"french\", \"italian\" and \"american\".  \nLow appearance frequency attitude is too many.  \nI think we need care this low attitudes.  ","de9dd39f":"## train\/test images\nLet's show training images.","3a0f2f89":"## train.csv\n* train.csv gives the attribute_ids for the train images in \/train  ","76476f01":"Let's show test images.","9d510958":"Check train\/test image area and size.","e6843460":"## Files\nThe filename of each image is its id.  \n* **train.csv** gives the attribute_ids for the train images in **\/train**\n* **\/test** contains the test images. You must predict the attribute_ids for these images.\n* **sample_submission.csv** contains a submission in the correct format\n* **labels.csv** provides descriptions of the attributes"}}