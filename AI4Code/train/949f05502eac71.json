{"cell_type":{"ce3eb296":"code","3f3dde85":"code","d197f59b":"code","36a3ddd8":"code","d59db0fc":"code","3cdf9d2f":"code","8db1e5c8":"code","cbd1f19c":"code","149e7bcf":"code","2e440841":"code","c1695027":"code","9c2c55e7":"code","1c96458d":"code","0f5948d0":"code","52f11408":"code","ec061f95":"code","56f5f3a0":"code","1d5cb210":"code","73f3cd3c":"code","6228a74e":"code","cacc92c2":"code","3cfaf492":"code","f75da51f":"code","a0949202":"code","daa0d870":"code","06d42d6e":"code","09b270b4":"code","0bfe3296":"code","fac1e439":"code","3ce62243":"code","2dce72fd":"code","bba4bfee":"code","dbe8a7cb":"code","e4d78f0b":"code","51b6fe11":"code","cde0f2f8":"code","98f4bb3d":"code","88c0958b":"code","5a282cb0":"code","591d11fb":"code","6be700d3":"code","1412a471":"code","f4cc30f9":"code","529bd14c":"code","7b78c25e":"code","5e04f478":"code","272087ab":"code","03e7fdb0":"code","661913e1":"code","b5d5f434":"code","0506ff04":"code","5d998156":"code","6bfb2ef5":"code","d0f969ff":"code","e156a2af":"code","0f3ddddf":"code","6ce27756":"code","6d4004b3":"code","aadf7416":"code","c8c26fec":"code","e240e2f1":"code","b9eb014d":"code","da494d35":"code","75f9dbb4":"code","b5389f38":"code","dc4a8e1f":"code","f364695e":"code","4fcf08cc":"code","85880d9c":"code","8f283dfb":"code","7dccd9b8":"code","0051765b":"code","61690af9":"code","f8e66e7f":"code","f7e75209":"code","b4ca3758":"code","6841cd32":"code","c0e59dad":"code","bc003144":"code","662fdab0":"code","9a89094b":"code","daa271d9":"code","c9719585":"code","601e7098":"code","89604553":"code","f2a930d0":"code","80af4ab6":"code","358170ee":"code","c4025f7f":"code","5c7935af":"code","505bf054":"code","4bcf3bc4":"code","d6a331c0":"code","6b3b826f":"code","10d292e4":"code","78c23e3d":"code","1c3bc661":"code","fd5b4686":"code","e45e1f14":"code","fac11b42":"code","79fa9723":"code","dab799a1":"code","0bd2a809":"code","543f4b08":"code","8b96ad2f":"code","bd289f8d":"code","662586c0":"code","360a24a1":"code","7ed696ab":"code","edb6e2ea":"code","8ab423d7":"markdown","f43bab32":"markdown","0bfe674a":"markdown","c17dd905":"markdown"},"source":{"ce3eb296":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,accuracy_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline","3f3dde85":"#DATASET VIEW\npath1=\"..\/input\/\"\ndata_files=list(os.listdir(path1))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path1+x).st_size\/(1024*1024),2))\ndf_files","d197f59b":"#ALL FUNCTIONS\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Median','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Median']=df_fa[col].median()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))\n\n#FUNCTION TO IDENTIFY HIGHLY CORRELATED FEATURES\ndef drop_corr_col(df_corr):\n    upper = df_corr.where(np.triu(np.ones(df_corr.shape),\n                          k=1).astype(np.bool))\n    # Find index of feature columns with correlation greater than 0.97\n    to_drop = [column for column in upper.columns if any(upper[column] > 0.999)]\n    return(to_drop)\n\n#FUNCTION USED FOR GROUPING DATA AND COUNTING UNIQUE VALUES\n#USED WITH GROUP BY\ndef cnt_unique(df):\n    return(len(df.unique()))","36a3ddd8":"%%time\n#READING TRAINGING DATA\ntrain=pd.read_csv(path1+'application_train.csv')\n#READING TEST DATA\ntest=pd.read_csv(path1+'application_test.csv')","d59db0fc":"#TRAINING DATA VEIW\ntrain.head()","3cdf9d2f":"#TESTING DATA VIEW\ntest.head()","8db1e5c8":"#COMBINING TRAIN AND TEST DATA\nprint('Train shape:',train.shape,'Test shape:',test.shape)\ndf_comb=pd.concat([train.drop(['TARGET'],axis=1),test],ignore_index=True)\ndf_comb_fs=feature_summary(df_comb)\n\n#IDENTIFYING CATEGORICAL FEATURES\ncat_features=df_comb_fs[df_comb_fs.Data_type=='object'].index\n\n#REPLACING SPACE WITH UNDERSCORE IN CATEGORICAL VALUES\n#AS CATEGORICAL VALUES WILL APPEAR IN COLUMN NAMES WHEN CONVERTED TO DUMMIES\nfor col in cat_features:\n    df_comb[col]=df_comb[col].apply(lambda x: str(x).replace(\" \",\"_\"))\n\nprint('categorical features',len(cat_features))","cbd1f19c":"#CREATING DUMMIES\n#NAN VALUES WILL BE TREATED AS A CATEGORY\ncat_train=pd.DataFrame()\nfor col in cat_features:\n    dummy=pd.get_dummies(df_comb[col],prefix='DUM_'+col)\n    cat_train=pd.concat([cat_train,dummy],axis=1)\ndisplay(cat_train.head())\nprint('Newly created dummy columns:',cat_train.shape)","149e7bcf":"#REMOVING COLUMNS WILL VERY FEW VALUES OR HIGHLY CORRELATED\ncat_train.drop(['DUM_CODE_GENDER_XNA','DUM_NAME_INCOME_TYPE_Businessman','DUM_NAME_INCOME_TYPE_Maternity_leave','DUM_NAME_INCOME_TYPE_Student',\n                'DUM_NAME_INCOME_TYPE_Unemployed','DUM_NAME_FAMILY_STATUS_Unknown','DUM_OCCUPATION_TYPE_Security_staff','DUM_FONDKAPREMONT_MODE_nan',\n                'DUM_OCCUPATION_TYPE_IT_staff','DUM_ORGANIZATION_TYPE_Police','DUM_ORGANIZATION_TYPE_Telecom','DUM_ORGANIZATION_TYPE_Business_Entity_Type_1'],\n               axis=1,inplace=True)\nprint('Categorical feature count after dropping irrelevant features',cat_train.shape)","2e440841":"#COMBINING DUMMIES WITH NON CATEGORICAL FEATURES\ndf_final=pd.concat([df_comb.drop(cat_features,axis=1),cat_train],axis=1)\nprint('Final shape:',df_final.shape)\ndisplay(df_final.head())","c1695027":"#MANUAL FEATURE ENGINEERING ON APPLICATION DATA\ndf_final['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n\ndf_final['CALC_PERC_DAYS_EMPLOYED'] = df_final['DAYS_EMPLOYED'] \/ df_final['DAYS_BIRTH']\ndf_final['CALC_PERC_INCOME_CREDIT'] = df_final['AMT_INCOME_TOTAL'] \/df_final['AMT_CREDIT']\ndf_final['CALC_INCOME_PER_PERSON'] = df_final['AMT_INCOME_TOTAL'] \/ df_final['CNT_FAM_MEMBERS']\ndf_final['CALC_ANNUITY_INCOME_PERC'] = df_final['AMT_ANNUITY'] \/ df_final['AMT_INCOME_TOTAL']\ndf_final['CALC_PAYMENT_RATE'] = df_final['AMT_ANNUITY'] \/ df_final['AMT_CREDIT']\ndf_final['CALC_GOODS_PRICE_PER']=df_final['AMT_GOODS_PRICE']\/df_final['AMT_CREDIT']\ndf_final['CALC_PERC_CHILDREN']=df_final['CNT_CHILDREN']\/df_final['CNT_FAM_MEMBERS']\ndf_final['CALC_RATIO_CAR_TO_BRITH']=df_final['OWN_CAR_AGE'] \/ df_final['DAYS_BIRTH']\ndf_final['CALC_RATIO_CAR_TO_EMPLOY'] = df_final['OWN_CAR_AGE'] \/ df_final['DAYS_EMPLOYED']\ndf_final['CALC_INCOME_PER_CHILD'] = df_final['AMT_INCOME_TOTAL'] \/ (1 + df_final['CNT_CHILDREN'])\ndf_final['CALC_INCOME_PER_PERSON'] = df_final['AMT_INCOME_TOTAL'] \/ df_final['CNT_FAM_MEMBERS']\ndf_final['CALC_RATIO_PHONE_TO_BIRTH'] = df_final['DAYS_LAST_PHONE_CHANGE'] \/ df_final['DAYS_BIRTH']\ndf_final['CALC_RATIO_PHONE_TO_EMPLOY'] = df_final['DAYS_LAST_PHONE_CHANGE'] \/ df_final['DAYS_EMPLOYED']","9c2c55e7":"#DROPING IRRELEVANT CONTINUOUS FEATURES\ndf_final.drop(['FLAG_MOBIL','FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12'],axis=1,inplace=True)","1c96458d":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel dummy\ngc.collect()","0f5948d0":"%%time\n#READING BUREAU DATA\nbur=pd.read_csv(path1+'bureau.csv')\nprint('bureau set reading complete...')\n#READING BUREAU BALANCE DATA\nbur_bal=pd.read_csv(path1+'bureau_balance.csv')\nprint('bureau balance set reading complete...')","52f11408":"%%time\n#CONVERTING CATEGORICAL FEATURES IN BUREAU DATA TO DUMMIES\nfor col in ['CREDIT_CURRENCY','CREDIT_TYPE','CREDIT_ACTIVE']:\n    bur[col]=bur[col].apply(lambda x: str(x).replace(\" \",\"_\")) \n\ndummy=pd.DataFrame()\nfor col in ['CREDIT_CURRENCY','CREDIT_TYPE','CREDIT_ACTIVE']:\n    dummy=pd.concat([dummy,pd.get_dummies(bur[col],prefix='DUM_'+col)],axis=1)","ec061f95":"#COMBINING DUMMIES WITH CONTINUOUS BUREAU FEATURES\nbur_f=pd.concat([bur.drop(['CREDIT_CURRENCY','CREDIT_TYPE','CREDIT_ACTIVE'],axis=1),dummy],axis=1)","56f5f3a0":"#MANUAL FEATURE ENGINEERING WITH BUREAU DATA\nbur_f['CALC_PER_CREDIT_MAX_OVERDUE']=bur_f['AMT_CREDIT_MAX_OVERDUE']\/bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_PER_CREDIT_SUM_DEBT']=bur_f['AMT_CREDIT_SUM_DEBT']\/bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_PER_CREDIT_SUM_LIMIT']=bur_f['AMT_CREDIT_SUM_LIMIT']\/bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_PER_CREDIT_SUM_OVERDUE']=bur_f['AMT_CREDIT_SUM_OVERDUE']\/bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_PER_ANNUITY']=bur_f['AMT_ANNUITY']\/bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_CREDIT_LIMIT_CROSSED']=bur_f['AMT_CREDIT_SUM_LIMIT']-bur_f['AMT_CREDIT_SUM']\nbur_f['CALC_CREDIT_PER_DAY']=bur_f['AMT_CREDIT_SUM']\/bur_f['DAYS_CREDIT_ENDDATE'].abs()\nbur_f['CALC_CREDIT_CLOSED']=(bur_f['DAYS_ENDDATE_FACT'] < 0).astype(int)","1d5cb210":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel bur,dummy\ngc.collect()","73f3cd3c":"#CONVERTING MONTHS_BALANCE TO ITS ABSOLUTE VALUE\n#FOR MONTHS BALANCE ABSOLUTE VALUE IS GIVING BETTER RESULTS\nbur_bal['MONTHS_BALANCE']=bur_bal.MONTHS_BALANCE.abs()","6228a74e":"%%time\n#AGGREGATING BUREAU_BALANCE ON 'SK_ID_BUREAU','STATUS'\n#THIS HELPS IN REDUCING NUMBER OF OBSERVATION AND WE HAVE TO JOIN BUREAU_BALANCE WITH BUREAU TABLE\nbur_bal_f=bur_bal.groupby(['SK_ID_BUREAU','STATUS']).aggregate({'STATUS':['count'],'MONTHS_BALANCE':['max','min']})\nbur_bal_f.reset_index(inplace=True)\nbur_bal_f.columns=['SK_ID_BUREAU','STATUS','STATUS_count','MONTHS_BALANCE_max','MONTHS_BALANCE_min']","cacc92c2":"#CONVERTING STATUS INTO DUMMIES\ndummy=pd.get_dummies(bur_bal_f['STATUS'],prefix='DUM_STATUS')","3cfaf492":"#CONCATENATING STATUS DUMMIES WITH OTHER FEATURES\nbur_bal_ff=pd.concat([bur_bal_f.drop(['STATUS'],axis=1),dummy],axis=1)","f75da51f":"%%time\n#DISTRIBUTING STATUS COUNT ON STATUS TYPE FEATURES\ndummy_col=[x for x in bur_bal_ff.columns if 'DUM_' in x]\nfor col in dummy_col:\n    bur_bal_ff[col]=bur_bal_ff.apply(lambda x: x.STATUS_count if x[col]==1 else 0,axis=1)","a0949202":"bur_bal_ff.head(10)","daa0d870":"#DROPPING STATUS_count FEATURE\nbur_bal_ff.drop('STATUS_count',axis=1,inplace=True)","06d42d6e":"#DEFINING AGGREGATION RULES FOR GROUPING BUREAU_BALANCE DATA ON 'SK_ID_BUREAU'\nbur_bal_cols=[x for x in list(bur_bal_ff.columns) if x not in ['SK_ID_BUREAU']]\nbur_bal_agg={}\nbur_bal_name=['SK_ID_BUREAU']\nfor col in bur_bal_cols:\n    if 'DUM_' in col:\n        bur_bal_agg[col]=['sum']\n        bur_bal_name.append(col)\n    elif '_max' in col:\n        bur_bal_agg[col]=['max']\n        bur_bal_name.append(col)\n    elif '_min' in col:\n        bur_bal_agg[col]=['min']\n        bur_bal_name.append(col)\n    else:\n        bur_bal_agg[col]=['sum','mean']\n        bur_bal_name.append(col+'_'+'sum')\n        bur_bal_name.append(col+'_'+'mean')","09b270b4":"%%time\n#GROUPING BUREAU_BALANCE DATA ON 'SK_ID_BUREAU'\nbur_bal_fg=bur_bal_ff.groupby('SK_ID_BUREAU').aggregate(bur_bal_agg)\nbur_bal_fg.reset_index(inplace=True)\nbur_bal_fg.columns=bur_bal_name","0bfe3296":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel bur_bal,bur_bal_f,bur_bal_ff\ngc.collect()","fac1e439":"#JOINING BUREAU AND BUREAU_BALANCE TABLES ON 'SK_ID_BUREAU'\nbur_combi=bur_f.join(bur_bal_fg.set_index('SK_ID_BUREAU'),on='SK_ID_BUREAU',lsuffix='_BU', rsuffix='_BUB')","3ce62243":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel bur_bal_fg\ngc.collect()","2dce72fd":"#DEFINING AGGREGATION RULES FOR BUREAU COMBINED DATA TO GROUP ON 'SK_ID_CURR','SK_ID_BUREAU'\nbur_combi_cols=[x for x in list(bur_combi.columns) if x not in ['SK_ID_CURR','SK_ID_BUREAU']]\nbur_combi_agg={}\nbur_combi_name=['SK_ID_CURR','SK_ID_BUREAU']\nfor col in bur_combi_cols:\n    if 'DUM_' in col:\n        bur_combi_agg[col]=['sum']\n        bur_combi_name.append(col+'_'+'sum')\n    elif 'AMT_' in col:\n        bur_combi_agg[col]=['sum','mean','max','min','var','std']\n        bur_combi_name.append(col+'_'+'sum')\n        bur_combi_name.append(col+'_'+'mean')\n        bur_combi_name.append(col+'_'+'max')\n        bur_combi_name.append(col+'_'+'min')\n        bur_combi_name.append(col+'_'+'var')\n        bur_combi_name.append(col+'_'+'std')\n    elif 'CNT_' in col:\n        bur_combi_agg[col]=['sum','max','min','count']\n        bur_combi_name.append(col+'_'+'sum')\n        bur_combi_name.append(col+'_'+'max')\n        bur_combi_name.append(col+'_'+'min')\n        bur_combi_name.append(col+'_'+'count')\n    elif 'DAYS_' in col:\n        bur_combi_agg[col]=['sum','max','min']\n        bur_combi_name.append(col+'_'+'sum')\n        bur_combi_name.append(col+'_'+'max')\n        bur_combi_name.append(col+'_'+'min')\n    elif 'CALC_' in col:\n        bur_combi_agg[col]=['mean']\n        bur_combi_name.append(col+'_'+'mean')\n    else:\n        bur_combi_agg[col]=['sum']\n        bur_combi_name.append(col+'_'+'sum')\n       \n","bba4bfee":"%%time\n#GROUPING BUREAU COMBINED DATA ON 'SK_ID_CURR','SK_ID_BUREAU'\nbur_combi_f=bur_combi.groupby(['SK_ID_CURR','SK_ID_BUREAU']).aggregate(bur_combi_agg)                 \nbur_combi_f.reset_index(inplace=True)\nbur_combi_f.columns=bur_combi_name","dbe8a7cb":"#DEFINING AGGREGATION RULES FOR BUREAU COMBINED DATA TO GROUP ON 'SK_ID_CURR'\nbur_combi_cols=list(bur_combi_f.columns)\nbur_combi_agg={}\nbur_combi_name=['SK_ID_CURR']\nfor col in bur_combi_cols:\n    if 'SK_ID_CURR'==col:\n        bur_combi_agg[col]=['count']\n        bur_combi_name.append('SK_ID_BUREAU_count')\n    elif '_sum'==col:\n        bur_combi_agg[col]=['sum']\n        bur_combi_name.append(col)\n    elif '_mean' in col:\n        bur_combi_agg[col]=['mean']\n        bur_combi_name.append(col)\n    elif '_max' in col:\n        bur_combi_agg[col]=['max']\n        bur_combi_name.append(col)\n    elif '_min' in col:\n        bur_combi_agg[col]=['min']\n        bur_combi_name.append(col)\n    elif '_count' in col:\n        bur_combi_agg[col]=['sum']\n        bur_combi_name.append(col)\n    elif '_var' in col:\n        bur_combi_agg[col]=['mean']\n        bur_combi_name.append(col)\n    elif '_std' in col:\n        bur_combi_agg[col]=['mean']\n        bur_combi_name.append(col)\n    else:\n        bur_combi_agg[col]=['sum']\n        bur_combi_name.append(col)","e4d78f0b":"%%time\n#GROUPING BUREAU COMBINED DATA ON 'SK_ID_CURR'\nbur_combi_fg=bur_combi_f.groupby(['SK_ID_CURR']).aggregate(bur_combi_agg)                 \nbur_combi_fg.reset_index(inplace=True)\nbur_combi_fg.columns=bur_combi_name","51b6fe11":"#DROPPING IRRELEVANT FEATURES\nbur_combi_fg.drop(['DUM_CREDIT_TYPE_Car_loan_sum', 'DUM_CREDIT_CURRENCY_currency_2_sum', 'AMT_CREDIT_SUM_OVERDUE_var'],axis=1,inplace=True)","cde0f2f8":"#COMBINING BUREAUE COMBINED DATA WITH APPLICATION DATA\ndf_final=df_final.join(bur_combi_fg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_BU')","98f4bb3d":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel bur_combi,bur_combi_f,bur_combi_fg\ngc.collect()","88c0958b":"%%time\n#READING PREVIOUS APPLICATION DATA\nprev_appl=pd.read_csv(path1+'previous_application.csv')\nprint('previous_application set reading complete...')","5a282cb0":"#ENCODING CATEGORICAL FEATURES\nprev_appl_encoding={'NAME_YIELD_GROUP':{'middle':3,'low_action':1,'high':4,'low_normal':1,'XNA':0},\n                   'WEEKDAY_APPR_PROCESS_START':{'MONDAY':1,'TUESDAY':2,'WEDNESDAY':3,'THURSDAY':4,'FRIDAY':5,'SATURDAY':6,'SUNDAY':7},\n                   'FLAG_LAST_APPL_PER_CONTRACT':{'Y':1,'N':0}}\nprev_appl.replace(prev_appl_encoding,inplace=True)","591d11fb":"%%time\n#REPLACING 365243 IN DAYS_ FEATURES WITH NAN\ndays_col=[x for x in prev_appl.columns if 'DAYS_' in x]\nfor col in days_col:\n    prev_appl.replace(365243,np.nan,inplace= True)","6be700d3":"#CREAGING FEATURE SUMMARY\nprev_appl_fs=feature_summary(prev_appl)","1412a471":"#CATEGORICAL FEATURES\nprev_appl_fs[prev_appl_fs.Data_type=='object']","f4cc30f9":"%%time\n#CONVERTING CATEGORICAL FEATURES INTO DUMMIES\nprev_appl_cf=list(prev_appl_fs[prev_appl_fs.Data_type=='object'].index)\n\nfor col in prev_appl_cf:\n    prev_appl[col]=prev_appl[col].apply(lambda x: str(x).replace(\" \",\"_\"))    \n    \nprint('previous application categorical features',len(prev_appl_cf))\nprev_appl_cf.remove('NAME_CONTRACT_STATUS')\n\nprev_appl_cat=pd.DataFrame()\nfor col in prev_appl_cf:\n    dummy=pd.get_dummies(prev_appl[col],prefix='DUM_'+col)\n    prev_appl_cat=pd.concat([prev_appl_cat,dummy],axis=1)\ndisplay(prev_appl_cat.head())","529bd14c":"#DROPPING IRRELEVANT FEATURES\nprev_appl_cat.drop(['DUM_NAME_CASH_LOAN_PURPOSE_XAP', 'DUM_PRODUCT_COMBINATION_nan'],axis=1,inplace=True)","7b78c25e":"print('Newly created Dummy features:',len(prev_appl_cat.columns))","5e04f478":"#COMBINING DUMMIES WITH OTHER CONTINUOUS FEATURES\nprev_appl_f=pd.concat([prev_appl.drop(prev_appl_cf,axis=1),prev_appl_cat],axis=1)\n# with pd.option_context('display.max_columns',prev_appl_f.shape[1]):\n#     display(prev_appl_f.head(10))","272087ab":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel prev_appl,prev_appl_cat,prev_appl_fs\ngc.collect()","03e7fdb0":"%%time\n#MANUAL FEATURE ENGINEERING ON PREVIOUS_APPLICATION DATA\nprev_appl_f['CALC_PERC_ANNUITY']=prev_appl_f['AMT_ANNUITY']\/prev_appl_f['AMT_CREDIT']\nprev_appl_f['CALC_PERC_AMT_APPLICATION']=prev_appl_f['AMT_APPLICATION']\/prev_appl_f['AMT_CREDIT']\nprev_appl_f['CALC_PERC_DOWN_PAYMENT']=prev_appl_f['AMT_DOWN_PAYMENT']\/prev_appl_f['AMT_CREDIT']\nprev_appl_f['CALC_PERC_APPL_DOWN_PAYMENT']=prev_appl_f['AMT_DOWN_PAYMENT']\/prev_appl_f['AMT_APPLICATION']\nprev_appl_f['CALC_PERC_GOODS_PRICE']=prev_appl_f['AMT_GOODS_PRICE']\/prev_appl_f['AMT_CREDIT']\nprev_appl_f['CALC_FLAG_PRIVILEGED_CUSTOMER']=(prev_appl_f['RATE_INTEREST_PRIVILEGED']>0).astype(int)\nprev_appl_f['CALC_TERMINATED']=(prev_appl_f['DAYS_TERMINATION']<0).astype(int)\nprev_appl_f['CALC_AMT_ANNUITY_PER_PAY']=prev_appl_f['AMT_ANNUITY']\/prev_appl_f['CNT_PAYMENT']\nprev_appl_f['CALC_AMT_APPLICATION_PER_PAY']=prev_appl_f['AMT_APPLICATION']\/prev_appl_f['CNT_PAYMENT']\nprev_appl_f['CALC_AMT_DOWN_PAYMENT_PER_PAY']=prev_appl_f['AMT_DOWN_PAYMENT']\/prev_appl_f['CNT_PAYMENT']\nprev_appl_f['CALC_AMT_APPL_DOWN_PAYMENT_PER_PAY']=prev_appl_f['AMT_DOWN_PAYMENT']\/prev_appl_f['CNT_PAYMENT']\nprev_appl_f['CALC_AMT_GOODS_PRICE_PER_PAY']=prev_appl_f['AMT_GOODS_PRICE']\/prev_appl_f['CNT_PAYMENT']\nprev_appl_f['CALC_AMT_CREDIT_APP_DIFF']=prev_appl_f['AMT_CREDIT']-prev_appl_f['AMT_APPLICATION']\nprev_appl_f['CALC_LAST_DUE_AFTER_APPL']=(prev_appl_f['DAYS_LAST_DUE_1ST_VERSION']>0).astype(int)","661913e1":"print('Previoun application data shape:',prev_appl_f.shape)","b5d5f434":"#DEFINING AGGREGATION RULES FOR GROUPING PREVIOUS APPLICATION DATA ON 'SK_ID_CURR','SK_ID_PREV','NAME_CONTRACT_STATUS'\nprev_cols=[x for x in list(prev_appl_f.columns) if x not in ['SK_ID_CURR','SK_ID_PREV','NAME_CONTRACT_STATUS']]\nprev_agg={}\nprev_name=['SK_ID_CURR','SK_ID_PREV','NAME_CONTRACT_STATUS']\nfor col in prev_cols:\n    if 'DUM_' in col:\n        prev_agg[col]=['sum','mean','std']\n        prev_name.append(col+'_'+'sum')\n        prev_name.append(col+'_'+'mean')\n        prev_name.append(col+'_'+'std')\n    elif 'AMT_' in col:\n        prev_agg[col]=['sum','mean','max','min','var','std']\n        prev_name.append(col+'_'+'sum')\n        prev_name.append(col+'_'+'mean')\n        prev_name.append(col+'_'+'max')\n        prev_name.append(col+'_'+'min')\n        prev_name.append(col+'_'+'var')\n        prev_name.append(col+'_'+'std')\n    elif 'CNT_' in col:\n        prev_agg[col]=['sum','max','min','size','count']\n        prev_name.append(col+'_'+'sum')\n        prev_name.append(col+'_'+'max')\n        prev_name.append(col+'_'+'min')\n        prev_name.append(col+'_'+'size')\n        prev_name.append(col+'_'+'count')\n    elif 'DAYS_' in col:\n        prev_agg[col]=['sum','max','min']\n        prev_name.append(col+'_'+'sum')\n        prev_name.append(col+'_'+'max')\n        prev_name.append(col+'_'+'min')\n    elif 'CALC_FLAG_' in col:\n        prev_agg[col]=['sum']\n        prev_name.append(col+'_'+'sum')\n    elif 'CALC_' in col:\n        prev_agg[col]=['mean']\n        prev_name.append(col+'_'+'mean')\n    else:\n        prev_agg[col]=['sum','mean']\n        prev_name.append(col+'_'+'sum')\n        prev_name.append(col+'_'+'mean')\n","0506ff04":"%%time\n#GROUPING PREVIOUS APPLICATION DATA ON 'SK_ID_CURR','SK_ID_PREV','NAME_CONTRACT_STATUS'\nprev_appl_ff=prev_appl_f.groupby(['SK_ID_CURR','SK_ID_PREV','NAME_CONTRACT_STATUS']).aggregate(prev_agg)\nprev_appl_ff.reset_index(inplace=True)\nprev_appl_ff.columns=prev_name","5d998156":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel prev_appl_f\ngc.collect()","6bfb2ef5":"#CONVERTING 'NAME_CONTRACT_STATUS' TO DUMMIES\ndummy=pd.get_dummies(prev_appl_ff['NAME_CONTRACT_STATUS'],prefix='DUM_'+'NAME_CONTRACT_STATUS')","d0f969ff":"#COMBINING DUMMIES WITH OTHER CONTINUOUS FEATURES \nprev_appl_fg=pd.concat([prev_appl_ff.iloc[:,:1],dummy,prev_appl_ff.iloc[:,3:]],axis=1)","e156a2af":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel prev_appl_ff,dummy\ngc.collect()","0f3ddddf":"#DEFINING AGGREGATION RULES FOR GROUPING PREVIOUS APPLICATION DATA ON 'SK_ID_CURR'\nprev_cols=list(prev_appl_fg.columns)\nprev_agg={}\nprev_name=['SK_ID_CURR']\nfor col in prev_cols:\n    if 'SK_ID_CURR'==col:\n        prev_agg[col]=['count']\n        prev_name.append('SK_ID_PREV_count')\n    elif '_sum' in col:\n        prev_agg[col]=['sum']\n        prev_name.append(col)\n    elif '_mean' in col:\n        prev_agg[col]=['mean']\n        prev_name.append(col)\n    elif '_max' in col:\n        prev_agg[col]=['max']\n        prev_name.append(col)\n    elif '_min' in col:\n        prev_agg[col]=['min']\n        prev_name.append(col)\n    elif '_var' in col:\n        prev_agg[col]=['mean']\n        prev_name.append(col)\n    elif '_std' in col:\n        prev_agg[col]=['mean']\n        prev_name.append(col)\n    elif '_size' in col:\n        prev_agg[col]=['mean']\n        prev_name.append(col)\n    elif '_count' in col:\n        prev_agg[col]=['sum']\n        prev_name.append(col)\n    else:\n        prev_agg[col]=['sum']\n        prev_name.append(col)\n       ","6ce27756":"%%time\n#GROUPING PREVIOUS APPLICATION DATA ON 'SK_ID_CURR'\nprev_appl_fgg=prev_appl_fg.groupby(['SK_ID_CURR']).aggregate(prev_agg)\nprev_appl_fgg.reset_index(inplace=True)\nprev_appl_fgg.columns=prev_name","6d4004b3":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel prev_appl_fg\ngc.collect()","aadf7416":"#JOINING PREVIOUS APPLICATION DATA WITH FINAL TABLE (CONTAINING APPLICATION AND BUREAU DATA)\ndf_final=df_final.join(prev_appl_fgg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_PV')","c8c26fec":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel prev_appl_fgg\ngc.collect()","e240e2f1":"%%time\n#READING INSTALLMENTS_PAYMENTS DATA\ninst_pay=pd.read_csv(path1+'installments_payments.csv')\nprint('installments_payments set reading complete...')","b9eb014d":"#TAKING ABSOLUTE VALUE FOR DAYS_ FEATURES\nfor col in inst_pay.columns:\n    if 'DAYS_' in col:\n        inst_pay[col]=inst_pay[col].abs()","da494d35":"%%time\n#MANUAL FEATURE ENGINEERING\n\ninst_pay['CALC_DAYS_LATE_PAYMENT']=inst_pay['DAYS_ENTRY_PAYMENT']-inst_pay['DAYS_INSTALMENT']\ninst_pay['CALC_PERC_LESS_PAYMENT']=inst_pay['AMT_PAYMENT']\/inst_pay['AMT_INSTALMENT']\ninst_pay['CALC_PERC_LESS_PAYMENT'].replace(np.inf,0,inplace=True)\ninst_pay['CALC_DIFF_INSTALMENT']=inst_pay['AMT_INSTALMENT']-inst_pay['AMT_PAYMENT']\ninst_pay['CALC_PERC_DIFF_INSTALMENT']=np.abs(inst_pay['CALC_DIFF_INSTALMENT'])\/inst_pay['AMT_INSTALMENT']\ninst_pay['CALC_PERC_DIFF_INSTALMENT'].replace(np.inf,0,inplace=True)\ninst_pay['CALC_INSTAL_PAID_LATE'] = (inst_pay['CALC_DAYS_LATE_PAYMENT'] > 0).astype(int)\ninst_pay['CALC_OVERPAID']= (inst_pay['CALC_DIFF_INSTALMENT'] < 0).astype(int)","75f9dbb4":"#DEFINING AGGREGATION RULES AND CREATING LIST OF NEW FEATURES\ninst_pay_cols=[x for x in list(inst_pay.columns) if x not in ['SK_ID_CURR','SK_ID_PREV']]\ninst_pay_agg={}\ninst_pay_name=['SK_ID_CURR','SK_ID_PREV']\nfor col in inst_pay_cols:\n    if 'NUM_INSTALMENT_VERSION'==col:\n        inst_pay_agg[col]=[cnt_unique]#CUSTOM FUNCTION FOR COUNTING UNIQUE INSTALMENT_VERSION\n        inst_pay_name.append(col+'_'+'unique')\n    elif 'NUM_INSTALMENT_NUMBER'==col:\n        inst_pay_agg[col]=['max','count']\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'count')\n    elif 'AMT_' in col:\n        inst_pay_agg[col]=['sum','mean','max','min','var','std']\n        inst_pay_name.append(col+'_'+'sum')\n        inst_pay_name.append(col+'_'+'mean')\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'min')\n        inst_pay_name.append(col+'_'+'var')\n        inst_pay_name.append(col+'_'+'std')\n    elif 'CALC_DAYS_' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col+'_'+'sum')\n    elif 'DAYS_' in col:\n        inst_pay_agg[col]=['sum','max','min']\n        inst_pay_name.append(col+'_'+'sum')\n        inst_pay_name.append(col+'_'+'max')\n        inst_pay_name.append(col+'_'+'min')\n    else:\n        inst_pay_agg[col]=['mean']\n        inst_pay_name.append(col+'_'+'mean')","b5389f38":"%%time\n#AGGREGATING DATA ON SK_ID_CURR,SK_ID_PREV USING RULES CREATED IN PREVIOUS STEP\ninst_pay_f=inst_pay.groupby(['SK_ID_CURR','SK_ID_PREV']).aggregate(inst_pay_agg)\ninst_pay_f.reset_index(inplace=True)\ninst_pay_f.columns=inst_pay_name","dc4a8e1f":"#NUMBER OF MISSED INATALLMENTS\ninst_pay_f['CALC_NUM_INSTALMENT_MISSED']=inst_pay_f['NUM_INSTALMENT_NUMBER_max']-inst_pay_f['NUM_INSTALMENT_NUMBER_count']","f364695e":"#DEFINING RULES FOR SECOND AGGREGATION ON SK_ID_CURR\ninst_pay_cols=[x for x in list(inst_pay_f.columns) if x not in ['SK_ID_PREV']]\ninst_pay_agg={}\ninst_pay_name=['SK_ID_CURR']\nfor col in inst_pay_cols:\n    if 'SK_ID_CURR'==col:\n        inst_pay_agg[col]=['count']\n        inst_pay_name.append('SK_ID_PREV_count')\n    elif '_unique' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)\n    elif '_mean' in col:\n        inst_pay_agg[col]=['mean']\n        inst_pay_name.append(col)\n    elif '_max' in col:\n        inst_pay_agg[col]=['max']\n        inst_pay_name.append(col)\n    elif '_min' in col:\n        inst_pay_agg[col]=['min']\n        inst_pay_name.append(col)\n    elif '_count' in col:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)\n    else:\n        inst_pay_agg[col]=['sum']\n        inst_pay_name.append(col)","4fcf08cc":"%%time\n#AGGREGATING DATA ON SK_ID_CURR\ninst_pay_f.drop(['SK_ID_PREV'],axis=1,inplace=True)\ninst_pay_fg=inst_pay_f.groupby(['SK_ID_CURR']).aggregate(inst_pay_agg)\ninst_pay_fg.reset_index(inplace=True)\ninst_pay_fg.columns=inst_pay_name","85880d9c":"#INSTALMENT_VERSION CHANGE\ninst_pay_fg['CALC_CNT_INSTALMENT_VERSION_CHG']=inst_pay_fg['NUM_INSTALMENT_VERSION_unique']-inst_pay_fg['SK_ID_PREV_count']","8f283dfb":"#DROPING IRRELEVANT FEATURES\ninst_pay_fg.drop(['DAYS_ENTRY_PAYMENT_max', 'AMT_PAYMENT_var', 'DAYS_INSTALMENT_sum'],axis=1,inplace=True)","7dccd9b8":"#JOINING INSTALLMENT DATA WITH FINAL TABLE\n#FINAL TABLE ALREADY CONTAINS APPLICATION, BUREAU AND PREVIOUS APPLICATION DATA\ndf_final=df_final.join(inst_pay_fg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_INP')","0051765b":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel inst_pay,inst_pay_f,inst_pay_fg\ngc.collect()","61690af9":"%%time\n#READING POS_CASH_balance DATA\npos_cash=pd.read_csv(path1+'POS_CASH_balance.csv')\nprint('POS_CASH_balance set reading complete...')","f8e66e7f":"#CONVERTING MONTHS_BALANCE TO ITS ABSOLUTE VALUE\n#FOR MONTHS BALANCE ABSOLUTE VALUE IS GIVING BETTER RESULTS\npos_cash['MONTHS_BALANCE']=pos_cash['MONTHS_BALANCE'].abs()","f7e75209":"#MANUAL FEATURE ENGINEERING ON POS_CASH_BALANCE DATA\npos_cash['CALC_PERC_REMAINING_INSTAL']=pos_cash['CNT_INSTALMENT_FUTURE']\/pos_cash['CNT_INSTALMENT']\npos_cash['CALC_CNT_REMAINING_INSTAL']=pos_cash['CNT_INSTALMENT']-pos_cash['CNT_INSTALMENT_FUTURE']\npos_cash['CALC_DAYS_WITHOUT_TOLERANCE']=pos_cash['SK_DPD']-pos_cash['SK_DPD_DEF']","b4ca3758":"#CONVERTING 'NAME_CONTRACT_STATUS' TO DUMMIES\npos_cash['NAME_CONTRACT_STATUS']=pos_cash['NAME_CONTRACT_STATUS'].apply(lambda x: str(x).replace(\" \",\"_\")) \ndummy=pd.get_dummies(pos_cash['NAME_CONTRACT_STATUS'],prefix='DUM_NAME_CONTRACT_STATUS')","6841cd32":"#COMBINING DUMMIES WITH OTHER CONTINUOUS FEATURES\npos_cash_f=pd.concat([pos_cash.drop(['NAME_CONTRACT_STATUS'],axis=1),dummy],axis=1)","c0e59dad":"#DEFINING AGGREGATION RULES AND CREATING LIST OF NEW FEATURES\npos_cash_cols=[x for x in list(pos_cash_f.columns) if x not in ['SK_ID_CURR']]\npos_cash_agg={}\npos_cash_name=['SK_ID_CURR','SK_ID_PREV']\nfor col in pos_cash_cols:\n    if 'SK_ID_PREV'==col:\n        pos_cash_agg[col]=['count']\n        pos_cash_name.append(col+'_'+'count')\n    elif 'MONTHS_BALANCE'==col:\n        pos_cash_agg[col]=['max','min','count']\n        pos_cash_name.append(col+'_'+'max')\n        pos_cash_name.append(col+'_'+'min')\n        pos_cash_name.append(col+'_'+'count')\n    elif 'DUM_' in col:\n        pos_cash_agg[col]=['sum','mean','max','min']\n        pos_cash_name.append(col+'_'+'sum')\n        pos_cash_name.append(col+'_'+'mean')\n        pos_cash_name.append(col+'_'+'max')\n        pos_cash_name.append(col+'_'+'min')\n    elif 'CNT_' in col:\n        pos_cash_agg[col]=['max','min','sum','count']\n        pos_cash_name.append(col+'_'+'max')\n        pos_cash_name.append(col+'_'+'min')\n        pos_cash_name.append(col+'_'+'sum')\n        pos_cash_name.append(col+'_'+'count')\n    else:\n        pos_cash_agg[col]=['sum','mean']\n        pos_cash_name.append(col+'_'+'sum')\n        pos_cash_name.append(col+'_'+'mean')","bc003144":"%%time\n#AGGREGATING DATA ON SK_ID_CURR,SK_ID_PREV USING RULES CREATED IN PREVIOUS STEP\npos_cash_ff=pos_cash_f.groupby(['SK_ID_CURR','SK_ID_PREV']).aggregate(pos_cash_agg)\npos_cash_ff.reset_index(inplace=True)\npos_cash_ff.columns=pos_cash_name","662fdab0":"#DEFINING RULES FOR SECOND AGGREGATION ON SK_ID_CURR\npos_cash_cols=[x for x in list(pos_cash_ff.columns) if x not in ['SK_ID_CURR','SK_ID_PREV']]\npos_cash_agg={}\npos_cash_name=['SK_ID_CURR']\nfor col in pos_cash_cols:\n    if '_sum'==col:\n        pos_cash_agg[col]=['sum']\n        pos_cash_name.append(col)\n    elif '_mean' in col:\n        pos_cash_agg[col]=['mean']\n        pos_cash_name.append(col)\n    elif '_max' in col:\n        pos_cash_agg[col]=['max']\n        pos_cash_name.append(col)\n    elif '_min' in col:\n        pos_cash_agg[col]=['min']\n        pos_cash_name.append(col)\n    elif '_count' in col:\n        pos_cash_agg[col]=['sum']\n        pos_cash_name.append(col)\n    else:\n        pos_cash_agg[col]=['sum']\n        pos_cash_name.append(col)","9a89094b":"%%time\n#AGGREGATING DATA ON SK_ID_CURR,SK_ID_PREV USING RULES CREATED IN PREVIOUS STEP\npos_cash_fg=pos_cash_ff.groupby(['SK_ID_CURR']).aggregate(pos_cash_agg)\npos_cash_fg.reset_index(inplace=True)\npos_cash_fg.columns=pos_cash_name","daa271d9":"#JOINING POS_CASH DATA WITH FINAL TABLE\n#FINAL TABLE ALREADY CONTAINS APPLICATION,BUREAU,PREVIOUS APPLICATION DATA AND INSTALLMENT DATA\ndf_final=df_final.join(pos_cash_fg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_PC')","c9719585":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel pos_cash_fg,pos_cash,pos_cash_f,pos_cash_ff\ngc.collect()","601e7098":"%%time\n#READING CREDIT CARD BALANCE DATA\ncc_bal=pd.read_csv(path1+'credit_card_balance.csv')\nprint('credit_card_balance set reading complete...')","89604553":"#CONVERTING MONTHS_BALANCE TO ITS ABSOLUTE VALUE\n#FOR MONTHS BALANCE ABSOLUTE VALUE IS GIVING BETTER RESULTS\ncc_bal['MONTHS_BALANCE']=cc_bal['MONTHS_BALANCE'].abs()","f2a930d0":"#MANUAL FEATURE ENGINEERING\ncc_bal['CALC_PERC_BALANCE']=cc_bal['AMT_BALANCE']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_DRAWINGS_ATM_CURRENT']=cc_bal['AMT_DRAWINGS_ATM_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_DRAWINGS_CURRENT']=cc_bal['AMT_DRAWINGS_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_DRAWINGS_OTHER_CURRENT']=cc_bal['AMT_DRAWINGS_OTHER_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_DRAWINGS_POS_CURRENT']=cc_bal['AMT_DRAWINGS_POS_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_INST_MIN_REGULARITY']=cc_bal['AMT_INST_MIN_REGULARITY']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_PAYMENT_CURRENT']=cc_bal['AMT_PAYMENT_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_PAYMENT_TOTAL_CURRENT']=cc_bal['AMT_PAYMENT_TOTAL_CURRENT']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_RECEIVABLE_PRINCIPAL']=cc_bal['AMT_RECEIVABLE_PRINCIPAL']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_PERC_RECIVABLE']=cc_bal['AMT_RECIVABLE']\/cc_bal['AMT_CREDIT_LIMIT_ACTUAL']\ncc_bal['CALC_DAYS_WITHOUT_TOLERANCE']=cc_bal['SK_DPD']-cc_bal['SK_DPD_DEF']\n\nCNT_DRAWING_LIST=['CNT_DRAWINGS_ATM_CURRENT','CNT_DRAWINGS_CURRENT','CNT_DRAWINGS_OTHER_CURRENT','CNT_DRAWINGS_POS_CURRENT']\ncc_bal['CALC_CNT_DRAWINGS_TOTAL']=cc_bal[CNT_DRAWING_LIST].sum(axis=1)","80af4ab6":"#CONVERTING 'NAME_CONTRACT_STATUS' TO DUMMIES\ncc_bal['NAME_CONTRACT_STATUS']=cc_bal['NAME_CONTRACT_STATUS'].apply(lambda x: str(x).replace(\" \",\"_\")) \ndummy=pd.get_dummies(cc_bal['NAME_CONTRACT_STATUS'],prefix='DUM_NAME_CONTRACT_STATUS')","358170ee":"#COMBINING DUMMIES WITH OTHER CONTINUOUS FEATURES\ncc_bal_f=pd.concat([cc_bal.drop(['NAME_CONTRACT_STATUS'],axis=1),dummy],axis=1)","c4025f7f":"#DEFINING AGGREGATION RULES AND CREATING LIST OF NEW FEATURES\ncc_bal_cols=[x for x in list(cc_bal_f.columns) if x not in ['SK_ID_CURR']]\ncc_bal_agg={}\ncc_bal_name=['SK_ID_CURR','SK_ID_PREV']\nfor col in cc_bal_cols:\n    if 'SK_ID_PREV'==col:\n        cc_bal_agg[col]=['count']\n        cc_bal_name.append(col+'_'+'count')\n    elif 'MONTHS_BALANCE'==col:\n        cc_bal_agg[col]=['max','min','count']\n        cc_bal_name.append(col+'_'+'max')\n        cc_bal_name.append(col+'_'+'min')\n        cc_bal_name.append(col+'_'+'count')\n    elif 'AMT_' in col:\n        cc_bal_agg[col]=['sum','mean','max','min','var','std']\n        cc_bal_name.append(col+'_'+'sum')\n        cc_bal_name.append(col+'_'+'mean')\n        cc_bal_name.append(col+'_'+'max')\n        cc_bal_name.append(col+'_'+'min')\n        cc_bal_name.append(col+'_'+'var')\n        cc_bal_name.append(col+'_'+'std')\n    elif 'CNT_' in col:\n        cc_bal_agg[col]=['max','min','sum','count']\n        cc_bal_name.append(col+'_'+'max')\n        cc_bal_name.append(col+'_'+'min')\n        cc_bal_name.append(col+'_'+'sum')\n        cc_bal_name.append(col+'_'+'count')\n    else:\n        cc_bal_agg[col]=['mean']\n        cc_bal_name.append(col+'_'+'mean')","5c7935af":"%%time\n#AGGREGATING DATA ON SK_ID_CURR,SK_ID_PREV USING RULES CREATED IN PREVIOUS STEP\ncc_bal_ff=cc_bal_f.groupby(['SK_ID_CURR','SK_ID_PREV']).aggregate(cc_bal_agg)\ncc_bal_ff.reset_index(inplace=True)\ncc_bal_ff.columns=cc_bal_name","505bf054":"#DEFINING RULES FOR SECOND AGGREGATION ON SK_ID_CURR\ncc_bal_cols=[x for x in list(cc_bal_ff.columns) if x not in ['SK_ID_CURR','SK_ID_PREV']]\ncc_bal_agg={}\ncc_bal_name=['SK_ID_CURR']\nfor col in cc_bal_cols:\n    if '_sum'==col:\n        cc_bal_agg[col]=['sum']\n        cc_bal_name.append(col)\n    elif '_var' in col:\n        cc_bal_agg[col]=['mean']\n        cc_bal_name.append(col)\n    elif '_std' in col:\n        cc_bal_agg[col]=['mean']\n        cc_bal_name.append(col)\n    elif '_mean' in col:\n        cc_bal_agg[col]=['mean']\n        cc_bal_name.append(col)\n    elif '_max' in col:\n        cc_bal_agg[col]=['max']\n        cc_bal_name.append(col)\n    elif '_min' in col:\n        cc_bal_agg[col]=['min']\n        cc_bal_name.append(col)\n    elif '_count' in col:\n        cc_bal_agg[col]=['sum']\n        cc_bal_name.append(col)\n    else:\n        cc_bal_agg[col]=['sum']\n        cc_bal_name.append(col)","4bcf3bc4":"%%time\n#AGGREGATING DATA ON SK_ID_CURR USING RULES CREATED IN PREVIOUS STEP\ncc_bal_fg=cc_bal_ff.groupby(['SK_ID_CURR']).aggregate(cc_bal_agg)\ncc_bal_fg.reset_index(inplace=True)\ncc_bal_fg.columns=cc_bal_name","d6a331c0":"#JOINING CREDIT_CARD DATA WITH FINAL TABLE\n#FINAL TABLE ALREADY CONTAINS APPLICATION,BUREAU,PREVIOUS APPLICATION DATA, INSTALLMENTS AND POS_CASH DATA\ndf_final=df_final.join(cc_bal_fg.set_index('SK_ID_CURR'),on='SK_ID_CURR',lsuffix='_AP', rsuffix='_CB')","6b3b826f":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel cc_bal_fg,cc_bal,cc_bal_f,cc_bal_ff\ngc.collect()","10d292e4":"print('Final shape:',df_final.shape)","78c23e3d":"#DROPPING 'SK_ID_CURR'\ndf_final.drop(['SK_ID_CURR'],axis=1,inplace=True)","1c3bc661":"%%time\n#IDENTIFYING HIGHLY CORRELATED FEATURES\ncorr=df_final.corr().abs()\ndrop_col=drop_corr_col(corr)\n\nprint(len(drop_col))","fd5b4686":"print('List of highly correlated columns:\\n')\ndrop_col","e45e1f14":"#DROPING HIGHLY CORRELATED FEATURES\ndf_final.drop(drop_col,axis=1,inplace=True)","fac11b42":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel corr\ngc.collect()","79fa9723":"%%time\n#ADDING FEW PURE STATISTICAL FEATURES\n#THIS HELPS IN IMPROVING SCORE\ndf_final['the_mean'] = df_final.mean(axis=1)\nprint('the_mean calculated...')\ndf_final['the_sum'] =df_final.sum(axis=1)\nprint('the_sum calculated...')\ndf_final['the_std'] = df_final.std(axis=1)\nprint('the_std calculated...')","dab799a1":"#CREATING FINAL X, y and test SETS\nX=df_final.iloc[:len(train),:]\ny=train['TARGET']\ntest=df_final.iloc[len(train):,:]","0bd2a809":"print('Shape of X:',X.shape,'Shape of y:',y.shape,'Shape of test:',test.shape)","543f4b08":"#RELEASING MEMORY \/ GARBAGE COLLECTION\ndel df_final\ngc.collect()","8b96ad2f":"%%time\n#CREATING FINAL MODEL WITH STRATIFIED KFOLDS\n#FOLD COUNT 10\n#TRIED XGBClassifier, LGBMClassifier, CatBoostClassifier\n#BEST SCORE ACHIEVED BY CatBoostClassifier\n\nmodel=CatBoostClassifier(iterations=1000,\n                              learning_rate=0.05,\n                              depth=7,\n                              l2_leaf_reg=40,\n                              bootstrap_type='Bernoulli',\n                              subsample=0.7,\n                              scale_pos_weight=5,\n                              eval_metric='AUC',\n                              metric_period=50,\n                              od_type='Iter',\n                              od_wait=45,\n                              random_seed=17,\n                              allow_writing_files=False)\n\n#DATAFRAMES FOR STORING PREDICTIONS ON TRAIN DATA AS WELL AS TEST DATA\n#CAN BE USED FOR ENSEMBLE \ndf_preds=pd.DataFrame()\ndf_preds_x=pd.DataFrame()\nk=1\nsplits=10\navg_score=0\n\n#CREATING STRATIFIED FOLDS\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\nprint('\\nStarting KFold iterations...')\nfor train_index,test_index in skf.split(X,y):\n    df_X=X.iloc[train_index,:]\n    df_y=y.iloc[train_index]\n    val_X=X.iloc[test_index,:]\n    val_y=y.iloc[test_index]\n\n#FITTING MODEL\n    model.fit(df_X,df_y)\n\n#PREDICTING ON VALIDATION DATA\n    col_name='cat_predsx_'+str(k)\n    preds_x=pd.Series(model.predict_proba(val_X)[:,1])\n    df_preds_x[col_name]=pd.Series(model.predict_proba(X)[:,1])\n\n#CALCULATING ACCURACY\n    acc=roc_auc_score(val_y,preds_x)\n    print('Iteration:',k,'  roc_auc_score:',acc)\n    if k==1:\n        score=acc\n        model1=model\n        preds=pd.Series(model.predict_proba(test)[:,1])\n        col_name='cat_preds_'+str(k)\n        df_preds[col_name]=preds\n    else:\n        preds1=pd.Series(model.predict_proba(test)[:,1])\n        preds=preds+preds1\n        col_name='cat_preds_'+str(k)\n        df_preds[col_name]=preds1\n        if score<acc:\n            score=acc\n            model1=model\n    avg_score=avg_score+acc        \n    k=k+1\nprint('\\n Best score:',score,' Avg Score:',avg_score\/splits)\n#TAKING AVERAGE OF PREDICTIONS\npreds=preds\/splits","bd289f8d":"#READING SAMPLE SUBMISSION FILE\nsample=pd.read_csv(path1+'sample_submission.csv')","662586c0":"sample['TARGET']=preds","360a24a1":"#CREATING SUMBISSION FILE\nsample.to_csv('submission.csv',index=False)","7ed696ab":"#CREATING FILES FOR ENSEMBLE\ndf_preds_x.to_csv('cat_preds_x.csv',index=False)\ndf_preds.to_csv('cat_preds.csv',index=False)","edb6e2ea":"%%time\n#ENSEMBLE MODEL\n#USING LOGISTIC REGRESSION FOR NEXT LEVEL\nsample_ens=sample.copy()\n\ndf_preds_x.columns=['cat_preds_1','cat_preds_2','cat_preds_3','cat_preds_4','cat_preds_5','cat_preds_6',\n               'cat_preds_7','cat_preds_8','cat_preds_9','cat_preds_10']\n\ndf_final_ens=pd.concat([df_preds_x,df_preds],ignore_index=True)\n\ndf_final_ens['the_mean'] = df_final_ens.mean(axis=1)\nprint('the_mean calculated...')\ndf_final_ens['the_sum'] =df_final_ens.sum(axis=1)\nprint('the_sum calculated...')\ndf_final_ens['the_std'] = df_final_ens.std(axis=1)\nprint('the_std calculated...')\ndf_final_ens['the_kur'] = df_final_ens.kurtosis(axis=1)\nprint('the_kur calculated...')\n\n\nX=df_final_ens.iloc[:len(train),:]\ny=train['TARGET']\ntest=df_final_ens.iloc[len(train):,:]\n\nmodel=LogisticRegression()\n\nk=1\nsplits=10\navg_score=0\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\nprint('\\nStarting KFold iterations...')\nfor train_index,test_index in skf.split(X,y):\n    df_X=X.iloc[train_index,:]\n    df_y=y.iloc[train_index]\n    val_X=X.iloc[test_index,:]\n    val_y=y.iloc[test_index]\n\n    model.fit(df_X,df_y)\n\n    preds_x=pd.Series(model.predict_proba(val_X)[:,1])\n\n    acc=roc_auc_score(val_y,preds_x)\n    print('Iteration:',k,'  roc_auc_score:',acc)\n    if k==1:\n        score=acc\n        model1=model\n        preds=pd.Series(model.predict_proba(test)[:,1])\n    else:\n        preds=preds+pd.Series(model.predict_proba(test)[:,1])\n        if score<acc:\n            score=acc\n            model1=model\n    avg_score=avg_score+acc        \n    k=k+1\nprint('\\n Best score:',score,' Avg Score:',avg_score\/splits)\npreds=preds\/splits\n\nsample_ens['TARGET']=preds\nsample_ens.to_csv('submission_ens.csv',index=False)","8ab423d7":"<font color='blue'><I>Please upvote if you find this Notebook useful<\/I><\/font><br><br><br>\n\n<h1>My Learnings and mistakes in this competition<\/h1>\n<h2><u>Learnings<\/u><\/h2>\nAll Learning points are covered in this notebook\n<ol>\n    <li>Handling large number of features\n        <ul>\n            <li>Had around 1000 features\n            <li>Identification of most valuable features\n            <li>Feature Engineering and Feature selection are most important aspects of Machine Learning\n            <li>Good Feature Engineering and Feature selection super seeds superior hardware\n            <li>Different set of features perform better with different algorithms. \n        <\/ul>\n    <li>Combining different tables together and preparing them for model fitting\n        <ul>\n            <li>Tables have well defined relationships for creating joins\n            <li>Data from supporting tables is grouped before joining it with final tables\n            <li>Grouping process is a very good application of <b>groupby aggregation functionality <\/b>\n        <\/ul>\n    <li>Extensive use of Groupby and aggregation on supporting table\n    <li>Manual feature engineering\n    <li>Dropping highly correlated features.\n   <li>Categorization of observations can help improving score. \n    <li>Feature selection and feature exclusion. Check following Notebooks for Feature selection and exclusion:\n        <ul>\n      <li> <a href=\"https:\/\/www.kaggle.com\/rahullalu\/hcdr-installments-table-feature-selection\">https:\/\/www.kaggle.com\/rahullalu\/hcdr-installments-table-feature-selection<\/a>\n        <li><a href=\"https:\/\/www.kaggle.com\/rahullalu\/hcdr-feature-selection-for-pos-table\">https:\/\/www.kaggle.com\/rahullalu\/hcdr-feature-selection-for-pos-table<\/a>\n       <li><a href=\"https:\/\/www.kaggle.com\/rahullalu\/home-credit-default-risk-preparing-bureau-data\">https:\/\/www.kaggle.com\/rahullalu\/home-credit-default-risk-preparing-bureau-data<\/a>\n       <li><a href=\"https:\/\/www.kaggle.com\/rahullalu\/hcdr-feature-selection-for-creditcard-table\">https:\/\/www.kaggle.com\/rahullalu\/hcdr-feature-selection-for-creditcard-table<\/a>\n        <\/ul>\n    <li> Ensembling: With Private score of 0.79134\n    \n <\/ol>\n<h2><u>Mistakes<\/u><\/h2>\nMistake of not exploring all available Boosting models. Biggest mistake :(\n<ol>\n    <li>Extensively worked with XGBoost and LGBM. But not worked extensively with CatBoost.\n    <li>Got best result with CatBoost. Realized pretty late.\n    <li>Thought LGBM is the best model. Got CV score of 0.7869.\n    <li>Realized this mistake on last day. So was not able to submit best score with CatBoost.\n    <li>Didn't worked extensively on ensemble. Ensemble techinques helped a lot in improving scores.\n    \n<\/ol>","f43bab32":"![](http:\/\/)<h2>Problem Statement<\/h2>\nThe objective of this competition is to use historical loan application data to predict whether or not an applicant will be able to repay a loan. This is a standard supervised classification task:\n\n**Supervised:** The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features<br>\n**Classification:** The label is a binary variable, 0 (will repay loan on time), 1 (will have difficulty repaying loan)","0bfe674a":"\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/home-credit\/home_credit.png\" alt=\"Count of Operation\" height=\"800\" width=\"800\"><\/img>\n","c17dd905":"<h2>Dataset with file size<\/h2>"}}