{"cell_type":{"7e0252fe":"code","53f41b38":"code","f88db30f":"code","fbb55fb5":"code","49edd65b":"code","37766fe1":"code","c3176d6a":"code","a01b7ae2":"code","c22059b8":"code","63042f39":"code","ec9bb540":"code","fa1c92c3":"code","f5f6621a":"code","9fb0b896":"code","32bbeb96":"code","eda21a97":"code","fa1a2e5e":"markdown","d5c3d102":"markdown","8bae1afa":"markdown"},"source":{"7e0252fe":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nAUTO=tf.data.AUTOTUNE\n","53f41b38":"resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)\n","f88db30f":"gcsPath=KaggleDatasets().get_gcs_path()\n","fbb55fb5":"Train=tf.data.TFRecordDataset(tf.io.gfile.glob(gcsPath+'\/tfrecords-jpeg-512x512\/train\/*'),num_parallel_reads=AUTO)\nVal=tf.data.TFRecordDataset(tf.io.gfile.glob(gcsPath+'\/tfrecords-jpeg-512x512\/val\/*'),num_parallel_reads=AUTO)\nTest=tf.data.TFRecordDataset(tf.io.gfile.glob(gcsPath+'\/tfrecords-jpeg-512x512\/test\/*'),num_parallel_reads=AUTO)\n","49edd65b":"FullTrain=Train.concatenate(Val)\n","37766fe1":"temp=[]\nfor i,data in enumerate(FullTrain):\n    temp.append(i)","c3176d6a":"def parseImage(EagerTensor):\n    FeatureMap={\n    'image':tf.io.FixedLenFeature([],tf.string),\n    }\n    Features=tf.io.parse_single_example(EagerTensor,FeatureMap)\n    return tf.reshape(tf.image.decode_jpeg(Features['image']),(512,512,3))\/255\n\ndef parseLabel(EagerTensor):\n    FeatureMap={\n    \"class\":tf.io.FixedLenFeature([], tf.int64),\n    }\n    Features=tf.io.parse_single_example(EagerTensor,FeatureMap)\n    return tf.one_hot(Features['class'],104)\n\ndef parseId(EagerTensor):\n    FeatureMap={\n    \"id\":tf.io.FixedLenFeature([], tf.string),\n    }\n    Features=tf.io.parse_single_example(EagerTensor,FeatureMap)\n    return Features['id']\n","a01b7ae2":"\nwith strategy.scope():\n    Densenet201=tf.keras.applications.DenseNet201(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(512,512,3)\n    )\n    Densenet201.trainalbe=True\n    for layer in Densenet201.layers[:100]:\n        layer.trainable=False\n\n    model=tf.keras.Sequential([\n        Densenet201,\n        layers.Dropout(0.2),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(104,activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy',tfa.metrics.F1Score(104)])\n    \nmodel.summary()","c22059b8":"BATCHSIZE=16*strategy.num_replicas_in_sync\n\nTrainImage=FullTrain.map(parseImage)\nTrainLabel=FullTrain.map(parseLabel)\n\n# ValImage=Val.map(parseImage)\n# ValLabel=Val.map(parseLabel)\n\nTrainDS=tf.data.Dataset.zip((TrainImage,TrainLabel)).repeat().batch(BATCHSIZE).prefetch(AUTO)\n# ValDS=tf.data.Dataset.zip((ValImage,ValLabel)).batch(BATCHSIZE).prefetch(AUTO)","63042f39":"ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=3,verbose=True)\n\nclass MyCallBack(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,log):\n        if log['accuracy']>0.9995:\n            self.stop_training=True\n            \nStop=MyCallBack()","ec9bb540":"Epochs=20\nHistory=model.fit(TrainDS,epochs=Epochs,steps_per_epoch=temp[-1]\/\/BATCHSIZE,callbacks=[ReduceLR,Stop],verbose=1)\n","fa1c92c3":"Loss=History.history['loss']\nAcc=History.history['accuracy']\nF1=History.history['f1_score']\n\n# ValLoss=History.history['val_loss']\n# ValAcc=History.history['val_accuracy']\n# ValF1=History.history['val_f1_score']\n","f5f6621a":"fig=make_subplots(rows=1, cols=3)\nfig.add_scatter(x=History.epoch,y=Acc,name='TrainAcc',row=1, col=1)\n# fig.add_scatter(x=History.epoch,y=ValAcc,name='ValAcc',row=1, col=1)\nfig.add_scatter(x=History.epoch,y=Loss,name='TrainLoss',row=1, col=2)\n# fig.add_scatter(x=History.epoch,y=ValLoss,name='ValLoss',row=1, col=2)\nfig.add_scatter(x=History.epoch,y=Loss,name='TrainF1',row=1, col=3)\n# fig.add_scatter(x=History.epoch,y=ValLoss,name='ValF1',row=1, col=3)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=3)\nfig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\nfig.update_yaxes(title_text=\"Loss\", row=1, col=2)\nfig.update_yaxes(title_text=\"F1 Score\", row=1, col=3)\n","9fb0b896":"TestImage=Test.map(parseImage)\nTestId=Test.map(parseId)\nTestDS=tf.data.Dataset.zip((TestImage)).batch(BATCHSIZE).prefetch(AUTO)\nresult=model.predict(TestDS)\n","32bbeb96":"Id=[]\nfor i in TestId:\n    Id.append(str(i.numpy(),encoding='utf-8'))\n    ","eda21a97":"submission=pd.read_csv(r'..\/input\/tpu-getting-started\/sample_submission.csv')\nsubmission.id=Id\nsubmission.label=np.argmax(result,axis=1)\nsubmission.to_csv(r'.\/submission.csv',index=False)\n","fa1a2e5e":"plt.imshow(next(iter(Train.map(parseImage))))","d5c3d102":"plt.imshow(next(iter(HighResolution.map(parse512Image))))","8bae1afa":"for i in FullTrain.take(1):\n    example=tf.train.Example()\n    example.ParseFromString(i.numpy())\n    print(example)\n"}}