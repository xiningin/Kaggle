{"cell_type":{"81e6051e":"code","c7a6be4b":"code","47b31ef9":"code","887fbd5f":"code","efc4ef45":"code","bbdeee5b":"code","d9ec3124":"code","50d5c8f5":"code","2e974722":"code","667bc7ba":"code","bc38c77e":"code","7299d14c":"code","e08db195":"code","af801fc9":"code","2645819e":"code","a8511e6f":"code","eb231fdf":"code","d0ad37e6":"code","8032643e":"markdown","d1cdb158":"markdown","4026efd6":"markdown","4db2a542":"markdown","f3e84773":"markdown","44f42655":"markdown"},"source":{"81e6051e":"import os\nimport keras\nimport cv2\nimport h5py\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nimport numpy as np\nimport random\nfrom   tensorflow.keras.preprocessing.image import img_to_array, load_img\nimport os\nfrom glob import glob\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.preprocessing import image","c7a6be4b":"model = tf.keras.models.Sequential([\n\ntf.keras.layers.Conv2D(16, (3,3), activation='relu',padding = 'same', input_shape=(224, 224, 3)),\n#tf.keras.layers.MaxPooling2D(2, 2),\n\ntf.keras.layers.Conv2D(32, (3,3), activation='relu'),\ntf.keras.layers.MaxPooling2D(2,2),\n\ntf.keras.layers.Conv2D(64, (3,3), activation='relu'),\ntf.keras.layers.MaxPooling2D(2,2),\n\ntf.keras.layers.Conv2D(64, (3,3), activation='relu'),\ntf.keras.layers.MaxPooling2D(2,2),\n\ntf.keras.layers.Conv2D(128, (3,3), activation='relu'),\ntf.keras.layers.MaxPooling2D(2,2),\n\ntf.keras.layers.Flatten(),\n\ntf.keras.layers.Dense(1024, activation='tanh'),\ntf.keras.layers.Dropout(0.01),\ntf.keras.layers.Dense(512, activation='tanh',kernel_regularizer=regularizers.l2(0.01)),\ntf.keras.layers.Dropout(0.01),\n#tf.keras.layers.Dense(128, activation='relu'),\ntf.keras.layers.Dense(32, activation='tanh'),\n\ntf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['accuracy'])\n\n","47b31ef9":"model.summary()","887fbd5f":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        horizontal_flip=True)\nvali_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/urecamain\/Train',\n        target_size=(224, 224),\n        batch_size=64,\n        classes = ['Fire','Non-Fire'],\n        shuffle = True,\n        \n        class_mode='binary')\nvalidation_generator = vali_datagen.flow_from_directory(\n        '..\/input\/urecamain\/Vali',\n        target_size=(224, 224),\n        batch_size=64,\n        classes = ['Fire','Non-Fire'],\n        shuffle = True,\n        class_mode='binary')\ntest_generator = test_datagen.flow_from_directory(\n        '..\/input\/urecamain\/Test',\n        target_size=(224, 224),\n        batch_size=64,\n        classes = ['Fire','Non-Fire'],\n        shuffle = True,\n        class_mode='binary')\n","efc4ef45":"file_path = \".\/Final1.h5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\n\ncurr_model_hist = model.fit(\n      train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)","bbdeee5b":"import matplotlib.pyplot as plt\ndef plot_accuracy(y):\n    if(y == True):\n        plt.plot(curr_model_hist.history['accuracy'])\n        plt.plot(curr_model_hist.history['val_accuracy'])\n        plt.legend(['train', 'validation'], loc='lower right')\n        plt.title('Accuracy plot - train vs validation')\n        plt.xlabel('epoch')\n        plt.ylabel('accuracy')\n        plt.show()\n    else:\n        pass\n    return\n\ndef plot_loss(y):\n    if(y == True):\n        plt.plot(curr_model_hist.history['loss'])\n        plt.plot(curr_model_hist.history['val_loss'])\n        plt.legend(['training', 'validation'], loc = 'upper right')\n        plt.title('Loss plot - train vs vaidation')\n        plt.xlabel('epoch')\n        plt.ylabel('loss')\n        plt.show()\n    else:\n        pass\n    return\n\n\nplot_accuracy(True)\nplot_loss(True)","d9ec3124":"lossandacc = model.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","50d5c8f5":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    base = MobileNetV2(input_shape=(224,224,3), include_top=False, \\\n                       pooling='max', weights='imagenet')\n    base.trainable = False\n    dense = Dense(1, activation='sigmoid', name='dense')(base.output)\n\n    model = Model(inputs=base.inputs, outputs=dense, name='mobilenetv2')\n    model.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['acc'])\n    return model\n\nmobilenet = get_model()\n\nfile_path = '\/mobilenet.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\nhist = mobilenet.fit(train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)","2e974722":"lossandacc = mobilenet.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","667bc7ba":"\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    base = InceptionResNetV2(input_shape=(224,224,3), include_top=False, \\\n                       pooling='max', weights='imagenet')\n    base.trainable = False\n    dense = Dense(1, activation='sigmoid', name='dense')(base.output)\n\n    model = Model(inputs=base.inputs, outputs=dense, name='InceptionResNetV2')\n    model.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['acc'])\n    return model\n\nInceptionResNetV2 = get_model()\n\nfile_path = '\/InceptionResNetV2.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\nhist = InceptionResNetV2.fit(train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)\n","bc38c77e":"lossandacc = InceptionResNetV2.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","7299d14c":"from tensorflow.keras.applications import ResNet152\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    base = ResNet152(input_shape=(224,224,3), include_top=False, \\\n                       pooling='max', weights='imagenet')\n    base.trainable = False\n    dense = Dense(1, activation='sigmoid', name='dense')(base.output)\n\n    model = Model(inputs=base.inputs, outputs=dense, name='ResNet152')\n    model.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['acc'])\n    return model\n\nResNet152 = get_model()\n\nfile_path = '\/ResNet152.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\nhist = ResNet152.fit(train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)","e08db195":"lossandacc = ResNet152.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","af801fc9":"from tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    base = VGG19(input_shape=(224,224,3), include_top=False, \\\n                       pooling='max', weights='imagenet')\n    base.trainable = False\n    dense = Dense(1, activation='sigmoid', name='dense')(base.output)\n\n    model = Model(inputs=base.inputs, outputs=dense, name='VGG19')\n    model.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['acc'])\n    return model\n\nVGG19 = get_model()\n\nfile_path = '\/VGG19.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\nhist = VGG19.fit(train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)","2645819e":"lossandacc = VGG19.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","a8511e6f":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    base = ResNet50(input_shape=(224,224,3), include_top=False, \\\n                       pooling='max', weights='imagenet')\n    base.trainable = False\n    dense = Dense(1, activation='sigmoid', name='dense')(base.output)\n\n    model = Model(inputs=base.inputs, outputs=dense, name='ResNet50')\n    model.compile(loss='binary_crossentropy',\n          optimizer=Adam(lr=0.001),\n          metrics=['acc'])\n    return model\n\nResNet50 = get_model()\n\nfile_path = '\/EfficientNetB7.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"loss\", mode=\"min\", factor=0.1, patience=5, verbose=1)\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=8)\ncallbacks_list = [ checkpoint, reduce_on_plateau, es]\nhist = ResNet50.fit(train_generator,\n      callbacks=callbacks_list,\n      epochs=100,\n      validation_data=validation_generator,\n      verbose=1)","eb231fdf":"lossandacc = ResNet50.evaluate_generator(test_generator,verbose=1)\nprint(lossandacc)","d0ad37e6":"from IPython.display import FileLink\nFileLink('.\/Final1.h5')","8032643e":"# Training using EfficientNetB7","d1cdb158":"# Initializing Model Architectures \n## Included imagenet weights ","4026efd6":"# Training using MobileNetV2","4db2a542":"# Training using InceptionResNetV2","f3e84773":"# Training using VGG19","44f42655":"# Training using ResNet152"}}