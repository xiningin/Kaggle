{"cell_type":{"8de5955e":"code","4231b4b7":"code","92e2564e":"code","04fa8f90":"code","aa3e8033":"code","d3eb1615":"code","2f517ab4":"code","a65f4099":"markdown","8ff4f460":"markdown","c2cdf16d":"markdown","1c55e8cd":"markdown","923dbebb":"markdown","e89ae1cd":"markdown","9d3359c4":"markdown","d42f8fc5":"markdown"},"source":{"8de5955e":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer","4231b4b7":"# Config\nroot_path = '..\/input\/homework4_v2\/'  # Relative path of homework data\n\n# TF-IDF\nmax_df = 0.95        # Ignore words with high df. (Similar effect to stopword filtering)\nmin_df = 5           # Ignore words with low df.\nsmooth_idf = True    # Smooth idf weights by adding 1 to df.\nsublinear_tf = True  # Replace tf with 1 + log(tf).\n\n# Rocchio (Below is a param set called Ide Dec-Hi)\nalpha = 1\nbeta = 0.75\ngamma = 0.15\nrel_count = 5   # Use top-5 relevant documents to update query vector.\nnrel_count = 1  # Use only the most non-relevant document to update query vector.\niters = 5","92e2564e":"with open(root_path + 'doc_list.txt') as file:\n    doc_list = [line.rstrip() for line in file]\n    \nwith open(root_path + 'query_list.txt') as file:\n    query_list = [line.rstrip() for line in file]","04fa8f90":"documents, queries = [], []\n\nfor doc_name in doc_list:\n    with open(root_path + 'Document\/' + doc_name) as file:\n        doc = ' '.join([word for line in file.readlines()[3:] for word in line.split()[:-1]])\n        documents.append(doc)\n\nfor query_name in query_list:\n    with open(root_path + 'Query\/' + query_name) as file:\n        query = ' '.join([word for line in file.readlines() for word in line.split()[:-1]])\n        queries.append(query)","aa3e8033":"# Build TF-IDF vectors of docs and queries\nvectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df,\n                             smooth_idf=smooth_idf, sublinear_tf=sublinear_tf)\ndoc_tfidfs = vectorizer.fit_transform(documents).toarray()\nquery_vecs = vectorizer.transform(queries).toarray()\n\n# Rank documents based on cosine similarity\ncos_sim = cosine_similarity(query_vecs, doc_tfidfs)\nrankings = np.flip(cos_sim.argsort(), axis=1)","d3eb1615":"for _ in range(iters):\n    \n    # Update query vectors with Rocchio algorithm\n    rel_vecs = doc_tfidfs[rankings[:, :rel_count]].mean(axis=1)\n    nrel_vecs = doc_tfidfs[rankings[:, -nrel_count:]].mean(axis=1)\n    query_vecs = alpha * query_vecs + beta * rel_vecs - gamma * nrel_vecs\n    \n    # Rerank documents based on cosine similarity\n    cos_sim = cosine_similarity(query_vecs, doc_tfidfs)\n    rankings = np.flip(cos_sim.argsort(axis=1), axis=1)","2f517ab4":"with open('submission.csv', mode='w') as file:\n    file.write('Query,RetrievedDocuments\\n')\n    for query_name, ranking in zip(query_list, rankings):\n        ranked_docs = ' '.join([doc_list[idx] for idx in ranking])\n        file.write('%s,%s\\n' % (query_name, ranked_docs))","a65f4099":"## \u8b80\u53d6\u6a94\u540d\u6e05\u55ae","8ff4f460":"\u5927\u5bb6\u8c6a\uff0c\u80a5\u5b85\u5076U\u4f86\u767c\u6587\u310c'_'","c2cdf16d":"## \u7528TF-IDF\u521d\u59cb\u5316query\u5411\u91cf","1c55e8cd":"## \u8d85\u53c3\u6578","923dbebb":"## The end. \u63a8\u5751\u63a8\u5751( \u0361\u00b0 \u035c\u0296 \u0361\u00b0) [**\u55b5\u55b5\u55b5\uff5e**](https:\/\/acg.gamer.com.tw\/acgDetail.php?s=95931)\n![404](https:\/\/i.imgur.com\/RcEpAN2.png)","e89ae1cd":"## \u628a\u8cc7\u6599\u8655\u7406\u6210 [str, str, ...] \u7684\u683c\u5f0f","9d3359c4":"## \u7528Rocchio\u7b97\u6cd5\u66f4\u65b0query\u5411\u91cf","d42f8fc5":"## \u5beb\u5165\u7b54\u6848"}}