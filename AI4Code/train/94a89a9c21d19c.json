{"cell_type":{"694d8c35":"code","405aaa9a":"code","4c68cc18":"code","83ce544a":"code","bbff366b":"code","26847e55":"code","9bdabaec":"code","12101e58":"code","a26347ec":"code","dea75196":"code","4c5b228e":"markdown","f5300a25":"markdown","aa7ae150":"markdown","45ad87b1":"markdown"},"source":{"694d8c35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn.preprocessing\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import GradientBoostingClassifier as gb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\n\n# Prescaler:\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","405aaa9a":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","4c68cc18":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","83ce544a":"y = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Embarked\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nX[\"Age\"] = np.nan_to_num(X[\"Age\"])\n# X[\"Age\"] = img.fit_transform(X[[\"Age\"]])","bbff366b":"img = SimpleImputer(missing_values= 0.0 , strategy='mean', fill_value=None, verbose=0, copy=True, add_indicator=False)\n\ntrain_data[\"Age\"] = np.nan_to_num(train_data[\"Age\"])\ntest_data[\"Age\"] = np.nan_to_num(test_data[\"Age\"])\n\nXinfo = pd.get_dummies(train_data[features])\nXinfo[\"Age\"] = img.fit_transform(Xinfo[[\"Age\"]])\n\nTest_info = pd.get_dummies(test_data[features])\nTest_info[\"Age\"] = img.fit_transform(Test_info[[\"Age\"]])\n\n\nxx_train, xx_test, yy_train, yy_test = train_test_split(\n    Xinfo, train_data[\"Survived\"], random_state = 0)\n\nconvert_xtrain = pd.get_dummies(xx_train)\nconvert_xtest = pd.get_dummies(xx_test)","26847e55":"# print(np.nan_to_num(X[\"Age\"]))\n# print(X.info())\n\nmodel = RandomForestClassifier(n_estimators=400, max_depth=5, random_state=1)\nmodel.fit(X, y)\n\nprint(\"{:.3f}\".format(model.score(X, y)))","9bdabaec":"model_new = gb(random_state = 0, max_depth = 2, learning_rate = 0.35)\nmodel_new.fit(convert_xtrain, yy_train)\n\n\n# grid search for the best rate\n# for j in range(1, 6):\n#     max_score = 0\n#     max_learning_rate = 0\n#     for i in range(1, 100):\n#         model_new = gb(random_state = 0, max_depth = j, learning_rate = (i \/ 100), n_estimators = 100)\n#         model_new.fit(convert_xtrain, yy_train)\n#         score = model_new.score(convert_xtest, yy_test)\n#         if (score > max_score):\n#             max_score = score\n#             max_learning_rate = i \/ 100\n#     print(\"{:.3f}, {rate}, {depth}\".format(max_score, rate = max_learning_rate, depth = j))\n    \n# print(\"---------------------------------\")\nprint(\"Last best score: {:.3f}\".format(model_new.score(convert_xtest, yy_test)))\n\n# predictions = model_new.predict(Test_info)\n\n# output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n# print(output)\n# output.to_csv('my_submission.csv', index=False)\nprint(\"---------------------------------success-----------------------------------\")\n","12101e58":"svc = SVC()\n# print(convert_xtrain.info())\n# print(convert_xtrain)\nsvc.fit(convert_xtrain, yy_train)\nprint(\"train:{:.3f}\".format(svc.score(convert_xtrain, yy_train)))\nprint(\"test:{:.3f}\".format(svc.score(convert_xtest, yy_test)))\nprint(\"---------------normal------------------------\")\n\n# robustscaler\nscaler1 = RobustScaler()\nx_train_scaler = scaler1.fit_transform(convert_xtrain)\nx_test_scaler = scaler1.fit_transform(convert_xtest)\nsvc.fit(x_train_scaler, yy_train)\nprint(\"train:{:.3f}\".format(svc.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(svc.score(x_test_scaler, yy_test)))\nprint(\"--------------robustscaler-------------------\")\n\n# minmaxscaler:\nscaler2 = MinMaxScaler()\nx_train_scaler = scaler2.fit_transform(convert_xtrain)\nx_test_scaler = scaler2.fit_transform(convert_xtest)\nsvc.fit(x_train_scaler, yy_train)\nprint(\"train:{:.3f}\".format(svc.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(svc.score(x_test_scaler, yy_test)))\nprint(\"--------------minmaxscaler-------------------\")\n\n# Normalizer:\nscaler3 = Normalizer()\nx_train_scaler = scaler3.fit_transform(convert_xtrain)\nx_test_scaler = scaler3.fit_transform(convert_xtest)\nsvc.fit(x_train_scaler, yy_train)\nprint(\"train:{:.3f}\".format(svc.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(svc.score(x_test_scaler, yy_test)))\nprint(\"--------------Normalizer---------------------\")\n\n\n# StandardScaler:\nscaler3 = StandardScaler()\nx_train_scaler = scaler3.fit_transform(convert_xtrain)\nx_test_scaler = scaler3.fit_transform(convert_xtest)\ntest_test_scaler = scaler3.fit_transform(Test_info)\n\nsvc.fit(x_train_scaler, yy_train)\nprint(\"train:{:.3f}\".format(svc.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(svc.score(x_test_scaler, yy_test)))\nprint(\"--------------StandardScaler-----------------\")","a26347ec":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n             'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n\ngrid_search = GridSearchCV(SVC(), param_grid, cv = 5)\ngrid_search.fit(x_train_scaler, yy_train)\n\nprint(\"train:{:.3f}\".format(grid_search.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(grid_search.score(x_test_scaler, yy_test)))\nprint(\"test param:{}\".format(grid_search.best_params_))\n\nresults = pd.DataFrame(grid_search.cv_results_)\ndisplay(results.head())","dea75196":"svc_best = SVC(C = 10, gamma = 0.1)\nmodel_sg = XGBClassifier()\nmodel_sg.fit(x_train_scaler, yy_train)\nsvc_best.fit(x_train_scaler, yy_train)\nprint(\"train:{:.3f}\".format(model_sg.score(x_train_scaler, yy_train)))\nprint(\"test:{:.3f}\".format(model_sg.score(x_test_scaler, yy_test)))\n# print(\"train:{:.3f}\".format(svc_best.score(x_train_scaler, yy_train)))\n# print(\"test:{:.3f}\".format(svc_best.score(x_test_scaler, yy_test)))\n\n\n# print(test_test_scaler)\n\npredictions = model_sg.predict(test_test_scaler)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\n# display(output['Survived'].value_counts())\nprint(\"-----------success----------\")","4c5b228e":"**grid search to find the best C and Gamma**","f5300a25":"**best param of svm**","aa7ae150":"**choose the best preprocessing**","45ad87b1":"**Next cell is search by grid of best param (learning_rate and depth)**\u2014\u2014\u2014\u2014\u2014\u2014GradientBoostingClassifier\n"}}