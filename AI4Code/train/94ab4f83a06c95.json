{"cell_type":{"c34e62c3":"code","396a5888":"code","a98faf66":"code","caacc97e":"code","eb99ae71":"code","6a3baf35":"code","3c8c516c":"code","beaf3687":"code","2174e6fa":"code","92779002":"code","c8df275e":"code","9204341f":"code","3a0cbeb9":"code","23d973d5":"markdown","9118ca48":"markdown","d7c19740":"markdown","4f4d47d5":"markdown","a6c642fe":"markdown","0fc17a20":"markdown","83e0286d":"markdown","302e9326":"markdown"},"source":{"c34e62c3":"import os\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom matplotlib import pyplot\nfrom sklearn.utils import shuffle\nfrom matplotlib import pyplot\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam","396a5888":"IMG_H = 256\nIMG_W = 160\nIMG_C = 3\n# w_init = tf.initializers.glorot_uniform()\nw_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)","a98faf66":"def load_image(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.io.decode_jpeg(img)\n    img = tf.image.resize(img, [IMG_H, IMG_W], preserve_aspect_ratio=False)\n    img = tf.cast(img, tf.float32)\n    img = (img - 127.5) \/ 127.5\n    return img\n\ndef tf_dataset(images_path, batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n    dataset = dataset.shuffle(buffer_size=10240)\n    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    return dataset","caacc97e":"def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n    x = Conv2DTranspose(\n        filters=num_filters,\n        kernel_size=kernel_size,\n        kernel_initializer=w_init,\n        padding=\"same\",\n        strides=strides,\n        use_bias=False\n        )(inputs)\n\n    if bn:\n        x = BatchNormalization()(x)\n        x = LeakyReLU(alpha=0.2)(x)\n    return x\n\n\ndef conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation=True):\n    x = Conv2D(\n        filters=num_filters,\n        kernel_size=kernel_size,\n        kernel_initializer=w_init,\n        padding=padding,\n        strides=strides,\n    )(inputs)\n\n    if activation:\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Dropout(0.3)(x)\n    return x","eb99ae71":"def build_generator(latent_dim):\n    f = [2**i for i in range(5)][::-1]\n    filters = 64\n    output_strides = 16\n    h_output = IMG_H \/\/ output_strides\n    w_output = IMG_W \/\/ output_strides\n\n    noise = Input(shape=(latent_dim,), name=\"generator_noise_input\")\n\n    x = Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Reshape((h_output, w_output, 16 * filters))(x)\n\n    for i in range(1, 5):\n        x = deconv_block(x,\n            num_filters=f[i] * filters,\n            kernel_size=5,\n            strides=2,\n            bn=True\n        )\n\n    x = conv_block(x,\n        num_filters=3,\n        kernel_size=5,\n        strides=1,\n        activation=False\n    )\n    fake_output = Activation(\"tanh\")(x)\n\n    return Model(noise, fake_output, name=\"generator\")","6a3baf35":"def build_discriminator():\n    f = [2**i for i in range(4)]\n    image_input = Input(shape=(IMG_H, IMG_W, IMG_C))\n    x = image_input\n    filters = 64\n    output_strides = 16\n    h_output = IMG_H \/\/ output_strides\n    w_output = IMG_W \/\/ output_strides\n\n    for i in range(0, 4):\n        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)\n\n    x = Flatten()(x)\n    x = Dense(1)(x)\n\n    return Model(image_input, x, name=\"discriminator\")","3c8c516c":"class GAN(Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, real_images):\n        batch_size = tf.shape(real_images)[0]\n\n        for _ in range(2):\n            ## Train the discriminator\n            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n            generated_images = self.generator(random_latent_vectors)\n            generated_labels = tf.zeros((batch_size, 1))\n\n            with tf.GradientTape() as ftape:\n                predictions = self.discriminator(generated_images)\n                d1_loss = self.loss_fn(generated_labels, predictions)\n            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n            ## Train the discriminator\n            labels = tf.ones((batch_size, 1))\n\n            with tf.GradientTape() as rtape:\n                predictions = self.discriminator(real_images)\n                d2_loss = self.loss_fn(labels, predictions)\n            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n        ## Train the generator\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        misleading_labels = tf.ones((batch_size, 1))\n\n        with tf.GradientTape() as gtape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss}","beaf3687":"def save_plot(examples, epoch, n):\n    examples = (examples + 1) \/ 2.0\n    for i in range(n * n):\n        pyplot.subplot(n, n, i+1)\n        pyplot.axis(\"off\")\n        pyplot.imshow(examples[i])\n    filename = f\"..\/working\/generated_plot_epoch-{epoch+1}.png\"\n    pyplot.savefig(filename)\n    pyplot.close()","2174e6fa":"batch_size = 128\nlatent_dim = 128\nnum_epochs = 100\nimages_path = glob(\"..\/input\/images\/*.jpg\")","92779002":"d_model = build_discriminator()\ng_model = build_generator(latent_dim)\ngan = GAN(d_model, g_model, latent_dim)","c8df275e":"bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\nd_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\ng_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\ngan.compile(d_optimizer, g_optimizer, bce_loss_fn)","9204341f":"images_dataset = tf_dataset(images_path, batch_size)","3a0cbeb9":"for epoch in range(num_epochs):\n    gan.fit(images_dataset, epochs=1)\n    g_model.save(\"..\/working\/g_model.h5\")\n    d_model.save(\"..\/working\/d_model.h5\")\n\n    n_samples = 16\n    noise = np.random.normal(size=(n_samples, latent_dim))\n    examples = g_model.predict(noise)\n    save_plot(examples, epoch, int(np.sqrt(n_samples)))","23d973d5":"# DISCRIMINATOR","9118ca48":"# GENERATOR","d7c19740":"# CONV & DECONV BLOCK","4f4d47d5":"# GAN Model","a6c642fe":"# SAVE IMG","0fc17a20":"# HYPERPARAMETERS","83e0286d":"# GLOBAL VARIABLES","302e9326":"# LOAD DATASET FUNCTION"}}