{"cell_type":{"9cb998b8":"code","35467fa8":"code","a861f80b":"code","5eda14f1":"code","c99d0b65":"code","2da5c38b":"code","d69633c1":"code","ee96f873":"code","14e5bd1e":"code","e1b9dad5":"code","edf0062e":"code","a4c4983c":"code","208a651a":"code","9c1ea09f":"code","5c4413d6":"code","d756e306":"code","e899a483":"code","e9566c6f":"code","c0bbda7f":"code","8265415f":"code","e75c7b37":"code","1dc70035":"code","472ef293":"code","e50835b4":"code","c4bb20a9":"code","6f84a664":"code","c13862b8":"code","bfab68c2":"code","2c9f27e6":"code","bd2e28d7":"code","dc9475dc":"code","153f590c":"code","ac823793":"code","d7e4a31f":"code","565b08e5":"code","685ce643":"code","87ce8c6d":"code","c9e90072":"code","2e07a178":"code","f060ff90":"code","a8188f8d":"markdown","f8cdbc3c":"markdown","87e0befa":"markdown","bd583e68":"markdown","86ee3af4":"markdown","796de51f":"markdown","8eb3f7cc":"markdown","b60658b5":"markdown","35a88d9a":"markdown","bd1fce94":"markdown","e478c2e9":"markdown"},"source":{"9cb998b8":"import os\nimport datetime as dt\nimport math\nimport numpy as np\nimport pandas as pd","35467fa8":"# Input data files are available in the \"..\/input\/\" directory.\ninput_dir = \"..\/input\"\n\nquestions = pd.read_csv(os.path.join(input_dir, 'questions.csv'))\nquestions['questions_date_added'] = pd.to_datetime(questions['questions_date_added'])\n\nanswers = pd.read_csv(os.path.join(input_dir, 'answers.csv'))\nanswers['answers_date_added'] = pd.to_datetime(answers['answers_date_added'])\n\ncomments = pd.read_csv(os.path.join(input_dir, 'comments.csv'))\ncomments['comments_date_added'] = pd.to_datetime(comments['comments_date_added'])","a861f80b":"questions['questions_date_added'].min()","5eda14f1":"questions.head(3)","c99d0b65":"answers.head(3)","2da5c38b":"comments.head(3)","d69633c1":"questions['questions_text'] = questions['questions_title'] + ' ' + questions['questions_body']\nquestions_text = questions[['questions_id', 'questions_text']]\nquestions_text.head(5)","ee96f873":"questions_text.to_parquet('questions_text.parquet.gzip', compression='gzip')","14e5bd1e":"test_period_start = dt.datetime(2018, 7, 1)\ntest_period_end = dt.datetime(2019, 1, 31)","e1b9dad5":"train_questions = questions[questions['questions_date_added'] < test_period_start]\ntrain_questions['text'] = train_questions['questions_title'] + ' ' + train_questions['questions_body']\ntrain_questions_by_users = train_questions.groupby('questions_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_questions_by_users = train_questions_by_users.rename(columns={'questions_author_id': 'user_id'})","edf0062e":"train_answers= answers[answers['answers_date_added'] < test_period_start]\ntrain_answers['text'] = train_answers['answers_body'].apply(str)\ntrain_answers_by_users = train_answers.groupby('answers_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_answers_by_users = train_answers_by_users.rename(columns={'answers_author_id': 'user_id'})","a4c4983c":"train_comments = comments[comments['comments_date_added'] < test_period_start]\ntrain_comments['text'] = train_comments['comments_body'].apply(str)\ntrain_comments_by_users = train_comments.groupby('comments_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_comments_by_users = train_comments_by_users.rename(columns={'comments_author_id': 'user_id'})","208a651a":"direct_user_texts = pd.concat([train_questions_by_users, train_answers_by_users, train_comments_by_users], axis=0)\ndirect_user_texts = direct_user_texts.groupby('user_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\nprint(direct_user_texts.shape)\ndirect_user_texts.head(3)\ndirect_user_texts.to_parquet('direct_user_texts.parquet.gzip', compression='gzip')","9c1ea09f":"train_questions_to_answers_by_users = train_questions.merge(\n    train_answers[['answers_question_id', 'answers_author_id']], \n    left_on='questions_id', right_on='answers_question_id', how='inner').groupby(\n    'answers_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_questions_to_answers_by_users = train_questions_to_answers_by_users.rename(columns={'answers_author_id': 'user_id'})\ntrain_questions_to_answers_by_users.shape","5c4413d6":"train_answers_to_questions_by_users = train_answers.merge(\n    train_questions[['questions_id', 'questions_author_id']], \n    left_on='answers_question_id', right_on='questions_id', how='inner').groupby(\n    'questions_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_answers_to_questions_by_users = train_answers_to_questions_by_users.rename(columns={'questions_author_id': 'user_id'})\ntrain_answers_to_questions_by_users.shape","d756e306":"train_questions_to_comments_by_users = train_questions.merge(\n    train_comments[['comments_parent_content_id', 'comments_author_id']], \n    left_on='questions_id', right_on='comments_parent_content_id', how='inner').groupby(\n    'comments_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_questions_to_comments_by_users = train_questions_to_comments_by_users.rename(columns={'comments_author_id': 'user_id'})\ntrain_questions_to_comments_by_users.shape","e899a483":"train_comments_to_questions_by_users = train_comments.merge(\n    train_questions[['questions_id', 'questions_author_id']], \n    left_on='comments_parent_content_id', right_on='questions_id', how='inner').groupby(\n    'questions_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_comments_to_questions_by_users = train_comments_to_questions_by_users.rename(columns={'questions_author_id': 'user_id'})\ntrain_comments_to_questions_by_users.shape","e9566c6f":"train_answers_to_comments_by_users = train_answers.merge(\n    train_comments[['comments_parent_content_id', 'comments_author_id']], \n    left_on='answers_id', right_on='comments_parent_content_id', how='inner').groupby(\n    'comments_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_answers_to_comments_by_users = train_answers_to_comments_by_users.rename(columns={'comments_author_id': 'user_id'})\ntrain_answers_to_comments_by_users.shape","c0bbda7f":"train_comments_to_answers_by_users = train_comments.merge(\n    train_answers[['answers_id', 'answers_author_id']], \n    left_on='comments_parent_content_id', right_on='answers_id', how='inner').groupby(\n    'answers_author_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\ntrain_comments_to_answers_by_users = train_comments_to_answers_by_users.rename(columns={'answers_author_id': 'user_id'})\ntrain_comments_to_answers_by_users.shape","8265415f":"indirect_user_texts = pd.concat(\n    [train_questions_to_answers_by_users, train_answers_to_questions_by_users,\n     train_questions_to_comments_by_users, train_comments_to_questions_by_users,\n     train_answers_to_comments_by_users, train_comments_to_answers_by_users], axis=0)\nindirect_user_texts = indirect_user_texts.groupby('user_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\nprint(indirect_user_texts.shape)\nindirect_user_texts.head(3)\nindirect_user_texts.to_parquet('indirect_user_texts.parquet.gzip', compression='gzip')","e75c7b37":"merged_user_texts = pd.concat([direct_user_texts, indirect_user_texts], axis=0)\nmerged_user_texts = merged_user_texts.groupby('user_id')['text'].apply(lambda texts: '\\n '.join(texts)).reset_index()\nprint(merged_user_texts.shape)\nmerged_user_texts.head(3)\nmerged_user_texts.to_parquet('merged_user_texts.parquet.gzip', compression='gzip')","1dc70035":"direct_user_texts['text'][0]","472ef293":"import spacy\nnlp = spacy.load('en')\nnlp.remove_pipe('parser')\nnlp.remove_pipe('ner')\n\nfrom wordcloud import WordCloud\n\nimport gensim","e50835b4":"token_pos = ['NOUN', 'VERB', 'PROPN', 'ADJ', 'INTJ', 'X']\n\ndef nlp_preprocessing(data):\n    \"\"\" Use NLP to transform the text corpus to cleaned sentences and word tokens\n    \"\"\"    \n    \n    def token_filter(token):\n        \"\"\" Keep tokens who are alphapetic, in the pos (part-of-speech) list and not in stop list\n        \"\"\"    \n        return not token.is_stop and token.is_alpha and token.pos_ in token_pos\n    \n    processed_tokens = []\n    data_pipe = nlp.pipe(data)\n    for doc in data_pipe:\n        filtered_tokens = [token.lemma_.lower() for token in doc if token_filter(token)]\n        processed_tokens.append(filtered_tokens)\n    return processed_tokens    ","c4bb20a9":"# Tokenize text\nlsi_tokens = nlp_preprocessing(direct_user_texts['text'])\n\n# Create vocabulary\nremove_terms_below_document_numbers = 10\nremove_terms_above_corpus_size = 0.5\nvocabulary_size = 10000\nlsi_dic = gensim.corpora.Dictionary(lsi_tokens)\nlsi_dic.filter_extremes(no_below=remove_terms_below_document_numbers, \n                        no_above=remove_terms_above_corpus_size, \n                        keep_n=vocabulary_size)\nlsi_dic.save('lsi_dic_size_{}.model'.format(vocabulary_size))","6f84a664":"print('Dictionary size: {}'.format(len(lsi_dic)))","c13862b8":"# Convert tokens to gensim document format\nlsi_corpus = [lsi_dic.doc2bow(doc) for doc in lsi_tokens]\n# Apply tfidf on the corpus first to remove the effect of function words (those with high document frequencies but low tf-idf scores)\nlsi_tfidf = gensim.models.TfidfModel(lsi_corpus)\nlsi_tfidf.save('lsi_corpus_voc_size_{}.model'.format(vocabulary_size))\nlsi_corpus = lsi_tfidf[lsi_corpus]","bfab68c2":"num_topics = 50\nlsi_model = gensim.models.LsiModel(lsi_corpus, id2word=lsi_dic, num_topics=num_topics)\nlsi_model.save('lsi_topics_{}.model'.format(num_topics))","2c9f27e6":"def compute_lsi_probs(doc, text_col, num_topics):\n    doc_tokens = nlp_preprocessing([doc[text_col]])[0]\n    doc_bow = lsi_tfidf[lsi_dic.doc2bow(doc_tokens)]\n    doc_lsi = lsi_model[doc_bow]\n    doc_scores = np.zeros(shape=num_topics)\n    for v,k in doc_lsi:\n        doc_scores[v] = k\n    return doc_scores\n\ndef lsi_similarity(lsi_1, lsi_2):\n    return np.dot(lsi_1,lsi_2) \/ np.sqrt(np.dot(lsi_1,lsi_1) * np.dot(lsi_2,lsi_2))","bd2e28d7":"text_col = 'text'\ndoc1_scores = compute_lsi_probs(direct_user_texts.iloc[0], text_col, num_topics)\ndoc2_scores = compute_lsi_probs(direct_user_texts.iloc[0], text_col, num_topics)\nlsi_similarity(doc1_scores, doc2_scores)","dc9475dc":"doc1_scores = compute_lsi_probs(direct_user_texts.iloc[0], text_col, num_topics)\ndoc2_scores = compute_lsi_probs(direct_user_texts.iloc[1], text_col, num_topics)\nlsi_similarity(doc1_scores, doc2_scores)","153f590c":"doc1_scores = compute_lsi_probs(direct_user_texts.iloc[0], text_col, num_topics)\ndoc2_scores = compute_lsi_probs(direct_user_texts.iloc[2], text_col, num_topics)\nlsi_similarity(doc1_scores, doc2_scores)","ac823793":"def compute_lsi_scores(doc, text_col, num_topics):\n    doc_tokens = nlp_preprocessing([doc[text_col]])[0]\n    doc_bow = lsi_tfidf[lsi_dic.doc2bow(doc_tokens)]\n    doc_lsi = lsi_model[doc_bow]\n    doc_scores = np.zeros(shape=num_topics)\n    for v,k in doc_lsi:\n        doc_scores[v] = k\n    return pd.Series(doc_scores)","d7e4a31f":"print(questions_text.shape)\nquestions_topics = questions_text.apply(compute_lsi_scores, axis=1, text_col='questions_text', num_topics=num_topics)\nprint(questions_topics.shape)","565b08e5":"questions_topics = questions_topics.set_index(questions_text['questions_id'])\nquestions_topics.tail(2)","685ce643":"questions_topics.columns = ['Topic_{}'.format(i) for i in questions_topics.columns]\nquestions_topics.to_parquet('questions_topics_vs_{}_nt_{}.parquet.gzip'.format(vocabulary_size, num_topics), compression='gzip')","87ce8c6d":"print(merged_user_texts.shape)\nmerged_user_topics = merged_user_texts.apply(compute_lsi_scores, axis=1, text_col='text', num_topics=num_topics)\nprint(merged_user_topics.shape)","c9e90072":"merged_user_topics = merged_user_topics.set_index(merged_user_texts['user_id'])\nmerged_user_topics.tail(2)","2e07a178":"merged_user_topics.columns = ['Topic_{}'.format(i) for i in merged_user_topics.columns]\nmerged_user_topics.to_parquet('merged_user_topics_vs_{}_nt_{}.parquet.gzip'.format(vocabulary_size, num_topics), compression='gzip')","f060ff90":"os.listdir()","a8188f8d":"**Direct Texts Which Are Actually Written by Users**","f8cdbc3c":"**LSI Scores for Questions**","87e0befa":"**NLP Functions**","bd583e68":"**Extract LSI Scores**","86ee3af4":"**LSI Scores for Merged User Texts**","796de51f":"**Latent Semantic Indexing**","8eb3f7cc":"**Collect Text Corpora for Training Period from September 2011 to June 2018 **","b60658b5":"**Indirect Texts Forwarded from Interactions with Other Users**","35a88d9a":"**Merged User Texts**","bd1fce94":"**Questions**","e478c2e9":"**Test LSI Scores**"}}