{"cell_type":{"580cc78f":"code","e48b826f":"code","06769e1e":"code","22e6d59d":"code","045e61bb":"code","7f1037d0":"code","e04a1472":"code","75540a38":"code","39524084":"code","6ff2b466":"code","d0c81a9b":"code","ff55bae1":"code","37287837":"code","dc47b5f9":"code","c2f8ea2d":"code","f3a99977":"code","2e0057ed":"code","e460dc09":"code","cbcedc0a":"markdown"},"source":{"580cc78f":"!pip install efficientnet","e48b826f":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport efficientnet.tfkeras as efn\nfrom keras.applications.densenet import DenseNet201\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint","06769e1e":"AUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","22e6d59d":"# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# Configuration\nEPOCHS = 40\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIM_Z = 768","045e61bb":"def format_path(st):\n    return GCS_DS_PATH + '\/images\/' + st + '.jpg'","7f1037d0":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n    train_paths, train_labels, test_size=0.1, random_state=2020)","e04a1472":"def decode_image(filename, label=None, image_size=(IM_Z, IM_Z)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n#     image = tf.image.adjust_brightness(image, delta=0.2)\n#     image = tf.image.adjust_contrast(image,2)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","75540a38":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .cache()\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","39524084":"def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n               lr_min=0.000001, lr_rampup_epochs=20, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn\n\nch_p = ModelCheckpoint(filepath=\"model_ef.h5\", monitor='val_loss', save_weights_only=True,\n                                                 verbose=1)","6ff2b466":"with strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB7(\n            input_shape=(IM_Z, IM_Z, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(train_labels.shape[1], activation='softmax')\n    ])\n        \n    model.compile(\n        optimizer='adam',\n        loss = 'categorical_crossentropy',\n        metrics=['categorical_accuracy']\n    )\n#     model.summary()","d0c81a9b":"lrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\nSTEPS_PER_EPOCH = train_labels.shape[0] \/\/ BATCH_SIZE ","ff55bae1":"history = model.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    callbacks=[lr_schedule, ch_p],\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset\n)","37287837":"with strategy.scope():\n    model1 = tf.keras.Sequential([\n        tf.keras.applications.DenseNet201(\n            input_shape=(IM_Z, IM_Z, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(train_labels.shape[1], activation='softmax')\n    ])\n        \n             \n    model1.compile(\n        optimizer='adam',\n        loss = 'categorical_crossentropy',\n        metrics=['categorical_accuracy']\n    )\n#     model.summary()","dc47b5f9":"ch_p_den = ModelCheckpoint(filepath=\"model_den.h5\", monitor='val_loss', save_weights_only=True,\n                                                 verbose=1)","c2f8ea2d":"history1 = model1.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    callbacks=[lr_schedule, ch_p_den],\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset\n)","f3a99977":"# model.load_weights(\"model_ef.h5\")\n# model.load_weights(\"model_den.h5\")","2e0057ed":"# probs = model.predict(test_dataset, verbose=1)\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))\/2","e460dc09":"sub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","cbcedc0a":"##  TPU or GPU detection"}}