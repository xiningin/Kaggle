{"cell_type":{"98fadbe0":"code","36b001ab":"code","2d7ac354":"code","45733278":"code","8789c998":"code","86733390":"code","04c73d90":"code","e47c7b86":"code","859ceaf4":"code","8515b1f0":"code","be078c38":"code","50f855e4":"code","cd03506d":"code","ffe4ce77":"code","a83d2acb":"code","47d31f1a":"code","dd6737f2":"code","34552b99":"code","64e194b5":"code","a97306f3":"code","4d60f299":"code","723de45a":"code","c52e37da":"code","c19a0aac":"markdown","f356794a":"markdown","97a17514":"markdown","3e64c5ae":"markdown","2c5a2d6d":"markdown","54a58a71":"markdown"},"source":{"98fadbe0":"import os\n\nimport numpy as np \nimport pandas as pd \nimport json\n\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\ntrain_image_path = \"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/\"\ntest_image_path = \"\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/\"","36b001ab":"traindf = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\ntraindf.head()","2d7ac354":"traindf.shape","45733278":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n\n    img = mpimg.imread(train_image_path + img_path)\n    plt.imshow(img)\n\nplt.show()","8789c998":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,1)\n    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    # Create our shapening kernel, we don't normalize since the \n  \n    kernel_sharpening = np.array([[1,2,3], \n                                  [4,-33,5], \n                                  [6,7,8]])\n\n    # applying different kernels to the input image\n    sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n    plt.imshow(sharpened)\n\nplt.show()\n\n\n","86733390":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,0)\n    \n    # Values below 100 goes to 0 (black), everything above goes to 200 (white)\n    ret,thresh1 = cv2.threshold(img, 100, 200, cv2.THRESH_BINARY)\n\n\n    plt.imshow(thresh1)\n\nplt.show()","04c73d90":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,0)\n    \n    # It's good practice to blur images as it removes noise\n    image = cv2.GaussianBlur(img, (3,3), 0)\n\n\n\n    plt.imshow(image)\n\nplt.show()","e47c7b86":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,0)\n    \n    # It's good practice to blur images as it removes noise\n    image = cv2.GaussianBlur(img, (3,3), 0)\n\n    # Using adaptiveThreshold\n    thresh = cv2.adaptiveThreshold(image, 200, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 3)\n\n    plt.imshow(thresh)\n\nplt.show()","859ceaf4":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,0)\n    \n    # It's good practice to blur images as it removes noise\n    image = cv2.GaussianBlur(img, (3,3), 0)\n\n    _, th2 = cv2.threshold(image, 0, 200, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n    plt.imshow(th2)\n\nplt.show()","8515b1f0":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = traindf['image_id'][0:12]\n\nfor i, img_path in enumerate(next_pix):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n    \n    img = cv2.imread(train_image_path + img_path,0)\n    \n    # Otsu's thresholding after Gaussian filtering\n    blur = cv2.GaussianBlur(img, (5,5), 0)\n    \n    _, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    plt.imshow(th3)\n\nplt.show()","be078c38":"f = open(\"..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json\",\"r\")\ndata = json.load(f)\ndata['0']","50f855e4":"X_data = []\nY_data = []\n\nfor i in range(0,600):\n    img = load_img(train_image_path + traindf['image_id'][i])\n    X_data.append(img_to_array(img))\n    Y_data.append(traindf['label'][i])","cd03506d":"X_data = np.array(X_data)","ffe4ce77":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0])\nY_data = to_categorical(Y_data, num_classes = 5)\nY_data.shape","a83d2acb":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size = 0.2, random_state=45)","47d31f1a":"print(X_train.shape)\nprint(X_val.shape)\nprint(Y_train.shape)\nprint(Y_val.shape)","dd6737f2":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (600,800,3)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation = \"softmax\"))","34552b99":"# Compile the model\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"acc\"])","64e194b5":"epochs = 50\nbatch_size = 8","a97306f3":"#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n#          validation_data = (X_val, Y_val), verbose = 2)","4d60f299":"datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        shear_range=0.1,\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,\n        fill_mode='nearest')  # randomly flip images\n\n\ndatagen.fit(X_train)","723de45a":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, \n                              validation_data = (X_val,Y_val),\n                              verbose = 1, \n                              steps_per_epoch=4)","c52e37da":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","c19a0aac":"Referecnce : https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python","f356794a":"# Background Removal","97a17514":"# Sharpening Image","3e64c5ae":"# Binarization ","2c5a2d6d":"# Thresholding Image","54a58a71":"# Adaptive Thresholding"}}