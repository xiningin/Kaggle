{"cell_type":{"1e093e3f":"code","08f87694":"code","b90fab17":"code","30e1ac7d":"code","301dd5d0":"code","0dd4ad09":"code","f1325fca":"code","08b6a595":"code","57f19739":"code","3a2cc533":"code","e8afd971":"code","e9228015":"code","6c625756":"code","1edaf5f1":"code","f215c6a9":"code","77d5b618":"code","a260d32a":"code","86ad4995":"code","a8525471":"code","7af94d4a":"code","6a62ac33":"code","10f3f0bd":"code","b5e862df":"code","b9e9fc5b":"markdown","c71641f6":"markdown","35ac859d":"markdown","00a7b73c":"markdown","9f457018":"markdown","d6727c65":"markdown","d0bf44ba":"markdown","ea34a76f":"markdown","08bedfed":"markdown","0e473ba7":"markdown","11f55b3c":"markdown","1bff2ac7":"markdown","af0e67ce":"markdown","b26c3956":"markdown","b1f36fdb":"markdown","53d1764e":"markdown","af268423":"markdown","fe14ed79":"markdown","36f43755":"markdown","00ae58ad":"markdown","c3866310":"markdown","26f8d586":"markdown","09f1390d":"markdown","84ea60c0":"markdown"},"source":{"1e093e3f":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option(\"display.max_rows\", 100)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 14\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nfrom pathlib import Path\nimport cv2\nfrom tqdm import tqdm","08f87694":"train_df = pd.read_csv(\"..\/input\/understanding_cloud_organization\/train.csv\")\nsample_df = pd.read_csv(\"..\/input\/understanding_cloud_organization\/sample_submission.csv\")","b90fab17":"train_df.head()","30e1ac7d":"print(f'There are {train_df.shape[0]} records in train.csv')","301dd5d0":"train_df['Image_Label'].apply(lambda x : x.split('_')[1]).value_counts().plot(kind='bar')","0dd4ad09":"len_train = len(os.listdir(\"..\/input\/understanding_cloud_organization\/train_images\"))\nlen_test = len(os.listdir(\"..\/input\/understanding_cloud_organization\/test_images\"))\nprint(f'There are {len_train} images in train dataset')\nprint(f'There are {len_test} images in test dataset')","f1325fca":"len(train_df[train_df['EncodedPixels'].isnull()])","08b6a595":"train_df.loc[train_df['EncodedPixels'].isnull(), 'Image_Label'].apply(lambda x: x.split('_')[1]).value_counts().plot(kind=\"bar\")","57f19739":"train_df.loc[train_df['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()","3a2cc533":"train_df.loc[train_df['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().value_counts().plot(kind=\"bar\")","e8afd971":"from collections import defaultdict\ntrain_size_dict = defaultdict(int)\ntrain_path = Path(\"..\/input\/understanding_cloud_organization\/train_images\/\")\n\nfor img_name in train_path.iterdir():\n    img = Image.open(img_name)\n    train_size_dict[img.size] += 1","e9228015":"train_size_dict","6c625756":"test_size_dict = defaultdict(int)\ntest_path = Path(\"..\/input\/understanding_cloud_organization\/test_images\/\")\n\nfor img_name in test_path.iterdir():\n    img = Image.open(img_name)\n    test_size_dict[img.size] += 1","1edaf5f1":"test_size_dict","f215c6a9":"palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]","77d5b618":"def name_and_mask(start_idx):\n    col = start_idx\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n\n    labels = train_df.iloc[col:col+4, 1]\n    mask = np.zeros((1400, 2100, 4), dtype=np.uint8)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            mask_label = np.zeros(2100*1400, dtype=np.uint8)\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            for pos, le in zip(positions, length):\n                mask_label[pos:(pos+le)] = 1\n            mask[:, :, idx] = mask_label.reshape(1400, 2100, order='F')\n    return img_names[0], mask","a260d32a":"def show_mask_image(col):\n    name, mask = name_and_mask(col)\n    img = cv2.imread(str(train_path \/ name))\n    fig, ax = plt.subplots(figsize=(15, 15))\n\n    for ch in range(4):\n        contours, _ = cv2.findContours(mask[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n        for i in range(0, len(contours)):\n            cv2.polylines(img, contours[i], True, palet[ch], 2)\n    ax.set_title(name)\n    ax.imshow(img)\n    plt.show()","86ad4995":"idx_no_class = []\nidx_class_1 = []\nidx_class_2 = []\nidx_class_3 = []\nidx_class_4 = []\nidx_class_multi = []\nidx_class_triple = []\n\nfor col in range(0, len(train_df), 4):\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n        \n    labels = train_df.iloc[col:col+4, 1]\n    if labels.isna().all():\n        idx_no_defect.append(col)\n    elif (labels.isna() == [False, True, True, True]).all():\n        idx_class_1.append(col)\n    elif (labels.isna() == [True, False, True, True]).all():\n        idx_class_2.append(col)\n    elif (labels.isna() == [True, True, False, True]).all():\n        idx_class_3.append(col)\n    elif (labels.isna() == [True, True, True, False]).all():\n        idx_class_4.append(col)\n    elif labels.isna().sum() == 1:\n        idx_class_triple.append(col)\n    else:\n        idx_class_multi.append(col)","a8525471":"for idx in idx_class_1[:5]:\n    show_mask_image(idx)","7af94d4a":"for idx in idx_class_2[:5]:\n    show_mask_image(idx)","6a62ac33":"for idx in idx_class_3[:5]:\n    show_mask_image(idx)","10f3f0bd":"for idx in idx_class_4[:5]:\n    show_mask_image(idx)","b5e862df":"for idx in idx_class_multi[:5]:\n    show_mask_image(idx)","b9e9fc5b":"**Please upvote if this is helpful**","c71641f6":"## Images having multiple masks","35ac859d":"**Shallow clouds play a huge role in determining the Earth's climate. They\u2019re also difficult to understand and to represent in climate models. By classifying different types of cloud organization, researchers at Max Planck hope to improve our physical understanding of these clouds, which in turn will help us build better climate models.**","00a7b73c":"## A brief history about the purpose of this competition\n\nIt all started around two years ago at a workshop where 12 cloud experts came together to discuss shallow clouds over the ocean. These clouds look benign compared to big thunderstorms but, in fact, for the Earth\u2019s climate they play a huge role. The reason is that they reflect a lot of sunlight back into space, thereby cooling our planet, while only contributing marginally to the greenhouse effect. This means that it\u2019s really important to figure out how these clouds will change as our planet warms. Current climate models, however, struggle with that. They do not even agree whether there will be more or less of these shallow clouds.\n\n\nPart of the reason is that shallow clouds aren\u2019t just the result of the global circulation of the atmosphere. Rather, they have a life of their own and arrange themselves in a variety of patterns. For many of these patterns, the basic mechanisms behind them are poorly understood. This brings us back to our group of scientists. As they were looking through hundreds of satellite images like the ones shown on this page, they noticed that some structures occur more often than others. After some discussion, they agreed on four common patterns and called them Sugar, Flower, Fish and Gravel.\n\n![](https:\/\/miro.medium.com\/max\/1050\/1*Wz8Rosw9W0VDorCwcLIxkg.png)\n\nSource: Awesome article by Stephan Rasp https:\/\/medium.com\/@raspstephan","9f457018":"Iterating through all images in Test","d6727c65":"## Figuring out the total number of images having empty masks.","d0bf44ba":"## Count of labels having mask data","ea34a76f":"# Vizualizing the masks","08bedfed":"# Images with class 2","0e473ba7":"# Images with class 1","11f55b3c":"## Label wise breakdown of empty masks.","1bff2ac7":"# Let's dive in the clouds and explore the data","af0e67ce":"# Images with class 3","b26c3956":"Check the size of each image in the dataset by iterating through all the images (in train and test).","b1f36fdb":"I devote the credits for the code of this kernel to @GoldFish kernel at [https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda](https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda)","53d1764e":"# Images with multiple classes","af268423":"**Dice Coefficient (F1 Score)**\n\nDice coefficient is a statistic used to gauge the similarity of two samples.\n\nSimply put, the Dice Coefficient is 2 * the Area of Overlap divided by the total number of pixels in both images. (See explanation of area of union in section 2).\n\n![](https:\/\/miro.medium.com\/max\/644\/1*yUd5ckecHjWZf6hGrdlwzA.png)","fe14ed79":"## All the images in train and test set have a size 2100*1400","36f43755":"We have approx 5.5k images in train dataset and they can have up to 4 masks: Fish, Flower, Gravel and Sugar.","00ae58ad":"# Images with class 4","c3866310":"## Checking image size for train and test","26f8d586":"We can see that there are significant number of images having 2 masks and also a few of them having 4 masks.","09f1390d":"![](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/MaxPlanck\/Teaser_AnimationwLabels.gif)","84ea60c0":"# Explanation of the evaluation metric"}}