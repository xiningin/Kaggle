{"cell_type":{"e1d3364a":"code","9bfdea87":"code","7d62f31b":"code","faac380a":"code","584e0142":"code","a7278559":"code","ea220246":"code","03d053ed":"code","f7d84d05":"code","8434c1c2":"code","28e875d4":"code","cc8dde52":"code","41d62907":"code","07cd548b":"code","6c686165":"code","a55d5523":"code","dc226ba6":"code","8bc6d207":"code","197e7438":"code","b760533c":"code","ba06ab7b":"code","6a3b0d69":"code","5f07b070":"code","524e8adc":"code","8daa7026":"code","f10ef26b":"code","12bc6f7d":"code","a0aefde0":"code","171affb5":"markdown","182e1902":"markdown","43f63eef":"markdown"},"source":{"e1d3364a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","9bfdea87":"USAhousing=pd.read_csv(\"..\/input\/USA_Housing.csv\")\nUSAhousing.head(5)","7d62f31b":"USAhousing.info()","faac380a":"USAhousing.describe()","584e0142":"USAhousing.columns","a7278559":"sns.heatmap(USAhousing.corr(),annot=True)\n\n#We can see that the indepedent variables 'Number of Rooms' and 'Number of Bedrooms' are highly correlated\n","ea220246":"plt.figure(figsize=(20,12))\nplt.scatter(USAhousing['Avg. Area Number of Rooms'],USAhousing['Price'])","03d053ed":"plt.figure(figsize=(20,12))\nplt.scatter(USAhousing['Avg. Area Number of Bedrooms'],USAhousing['Price'])\n","f7d84d05":"sns.pairplot(USAhousing)","8434c1c2":"\n\n#Now let us look at the distribution of the housing prices\n#We can see that every parameter has data that is almost normally distributed except for the parameter Average area number of bedrooms.\n#you can further confirm the distribution by calculating skewness and kurtosis,but I am not doing it here as I will be dropping the parameter.\nsns.distplot(USAhousing['Price'])","28e875d4":"X=USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n        'Area Population']]\ny=USAhousing['Price']","cc8dde52":"USAhousing.head()","41d62907":"from sklearn.model_selection import train_test_split\nfrom scipy.stats.mstats import zscore\ny_stdrd = pd.Series(zscore(y),index=y.index)\nX_stdrd = pd.DataFrame(data=zscore(X), index=X.index, columns=X.columns)\n\nX_train,X_test,y_train,y_test=train_test_split(X_stdrd,y_stdrd,test_size=0.4,random_state=101)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n\n\n","07cd548b":"from sklearn.linear_model import LinearRegression\nlm=LinearRegression()\nlm.fit(X_train,y_train)\nlm.intercept_","6c686165":"coeff=pd.DataFrame(lm.coef_,X.columns,columns=['coeff'])\ncoeff","a55d5523":"prediction=lm.predict(X_test)","dc226ba6":"plt.scatter(y_test,prediction)","8bc6d207":"from sklearn import metrics\n\nprint('MAE',metrics.mean_absolute_error(y_test,prediction))\nprint('MSE:', metrics.mean_squared_error(y_test, prediction))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))","197e7438":"import statsmodels.api as sm\nfrom scipy import stats","b760533c":"X=USAhousing[['Avg. Area Income', 'Avg. Area House Age', \n        'Area Population','Avg. Area Number of Rooms']]\ny=USAhousing['Price']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=101)\n\n\nX2=sm.add_constant(X_train)\nX2.head()\nest=sm.OLS(y_train,X2)\nest2=est.fit()\nprint(est2.summary())","ba06ab7b":"#out of the three models we go with the last mpdel as it has high Adj R2 ,high Fstat.\n#but the condition number seems to be very high .So we check for multi collinearity.\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\nvifs=[vif(X2.values,i) for i in range(len(X2.columns))]\npd.Series(data=vifs,index=X2.columns)","6a3b0d69":"#As Vif for all parameters is less than 5, we can say that the parameters are not correlated, and the condition number is due to not standardising the data.\n\nfrom scipy.stats.mstats import zscore\ny_stdrd = pd.Series(zscore(y),index=y.index)\nX_stdrd = pd.DataFrame(data=zscore(X), index=X.index, columns=X.columns)\n\nX_train,X_test,y_train,y_test=train_test_split(X_stdrd,y_stdrd,test_size=0.4,random_state=101)\n\n\nX2=sm.add_constant(X_train)\nX2.head()\nest=sm.OLS(y_train,X2)\nest2=est.fit()\nprint(est2.summary())","5f07b070":"#we now see that condition number has decreased to 1.04, indicating the absence of multicollinearity.\n#A condition number greater than 100 indicates the presence of multicollinearity.","524e8adc":"lm=LinearRegression()\nlm.fit(X_train,y_train)\nlm.intercept_","8daa7026":"coeff=pd.DataFrame(lm.coef_,X.columns,columns=['coeff'])\ncoeff","f10ef26b":"prediction=lm.predict(X_test)","12bc6f7d":"plt.scatter(y_test,prediction)","a0aefde0":"print('MAE',metrics.mean_absolute_error(y_test,prediction))\nprint('MSE:', metrics.mean_squared_error(y_test, prediction))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))","171affb5":"Training a Regression model.For information regarding comparision of algorithms  for linear regression,check out my blog here:https:\/\/medium.com\/@harshita.vemula\/comparison-of-algorithms-for-linear-regression-105e405a4f15","182e1902":" ******We will now visualise the data -Exploratory data analysis ****","43f63eef":"From the above two graphs, we can more or less say that the independent variable 'Number of Bedrooms' has little or no effect on Housing prices compared to the variable 'Number of rooms', which seems to be linearly associated with housing prices.\n"}}