{"cell_type":{"983f8347":"code","3fb4211f":"code","d5f998eb":"code","953bd77b":"code","2ab38c5e":"code","f0bb1893":"code","9b751506":"code","3835cb6f":"code","c1d1a315":"code","b4f7b213":"code","e2f781d1":"code","25301837":"code","6f38ad52":"code","1a4856cf":"code","a5656a41":"code","a5e32e55":"code","511f7f50":"code","4338c89b":"code","71e1ffe8":"code","42f5ff13":"code","189ffb0a":"code","6a090afd":"code","0b1e3032":"code","4b3d1dd7":"code","edfac989":"code","299241b0":"code","3a77f360":"code","05072bd6":"code","ab1a5c85":"code","4faa8aa4":"code","9ffd53ff":"code","7509cb86":"code","cf2feeb5":"code","e0b83631":"code","4409003d":"code","1c9097c0":"code","fc91fdf5":"code","16e88118":"code","7c13e304":"code","40c7bfb2":"markdown","fb6b61b3":"markdown","b5c4b269":"markdown","045c2536":"markdown","29b27fb1":"markdown","a78afe09":"markdown"},"source":{"983f8347":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom random import seed\nfrom random import randrange\nimport csv","3fb4211f":"filename = \"..\/input\/Banknotes\/data_banknote_authentication.csv\"","d5f998eb":"def loadCsv(path):\n    lines = csv.reader(open(path))\n    dataset = list(lines)\n    for i in range(len(dataset)):\n        dataset[i] = [float(x) for x in dataset[i]]\n    return dataset","953bd77b":"# Calculate the Gini impurity for a split dataset\ndef calGiniImpurity(groups, classes):\n    \"\"\"\n    gini impurity = (sum((1 - sum[(p_class_i^2) for i :=0 to (n-1)])  \n                     \/ (weight of class at split point=nInstance\/totalInstace))\n                    )\n    item_g_ij = [value, class]\n    groups = [\n        [item_g00, item_g01, ...],\n        [item_g10, item_g11, ...],\n    ]\n    classes = [class_0, class_1, ..\/]\n    \"\"\"\n    # count all samples at split point\n    nInstances = float(sum([len(group) for group in groups]))\n    # sum weighted Gini index for each group\n    gini = 0.0\n    for group in groups:\n        size = float(len(group))\n        # print(group, size)\n        # avoid divide by zero\n        if size == 0:\n            continue\n        score = 0.0\n        # score the group based on the score for each class\n        for classVal in classes:\n            # print(classVal)\n            p = [row[-1] for row in group].count(classVal) \/ size\n            score += p * p\n            # print(\"Score:\", score)\n        # weight the group score by its relative size\n        gini += (1.0 - score) * (size \/ nInstances)\n    return gini","2ab38c5e":"# test Gini values\nprint(calGiniImpurity(\n    [\n        [[1, 1], [1, 0]], # Class 0\n        [[1, 1], [1, 0]], # Class 1\n    ], \n    [0, 1])\n     )\nprint(calGiniImpurity(\n    [\n        [[1, 0], [1, 0]], # Class 0\n        [[1, 1], [1, 1]], # Class 1\n    ], \n    [0, 1])\n     )","f0bb1893":"def splitDataset(index, splitVal, dataset):\n    left, right = [], []\n    for row in dataset:\n        if row[index] < splitVal:\n            left.append(row)\n        else:\n            right.append(row)\n    return left, right","9b751506":"# Select the best split point for a dataset\ndef getBestSplit(dataset):\n    classValues = list(set(row[-1] for row in dataset))\n    bIndex, bValue, bScore, bGroups = 999, 999, 999, None\n    for index in range(len(dataset[0])-1):\n        for row in dataset:\n            groups = splitDataset(index, row[index], dataset)\n            gini = calGiniImpurity(groups, classValues)\n            # print('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n            if gini < bScore:\n                bIndex, bValue, bScore, bGroups = index, row[index], gini, groups\n    return {'index':bIndex, 'value':bValue, 'groups':bGroups}","3835cb6f":"dataset = [\n    [2.771244718,1.784783929,0],\n    [1.728571309,1.169761413,0],\n    [3.678319846,2.81281357,0],\n    [3.961043357,2.61995032,0],\n    [2.999208922,2.209014212,0],\n    [7.497545867,3.162953546,1],\n    [9.00220326,3.339047188,1],\n    [7.444542326,0.476683375,1],\n    [10.12493903,3.234550982,1],\n    [6.642287351,3.319983761,1]\n]","c1d1a315":"X0 = [c[0] for c in dataset if c[2]==0]\nY0 = [c[1] for c in dataset if c[2]==0]\nX1 = [c[0] for c in dataset if c[2]==1]\nY1 = [c[1] for c in dataset if c[2]==1]","b4f7b213":"plt.plot(X0, Y0, \"b^\", markersize = 4, alpha = .8)\nplt.plot(X1, Y1, \"ro\", markersize = 4, alpha = .8)\nxSplit = [6.64] * 100\nySplit = np.linspace(-0.5, 4, 100)\nplt.plot(xSplit, ySplit, \"-g\")\nplt.axis('equal')\nplt.show()","e2f781d1":"split = getBestSplit(dataset)\nprint('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))","25301837":"# Create a terminal node value\n# Defined by max depth and minimum samples per nodes\ndef toTerminal(group):\n    outcomes = [row[-1] for row in group]\n    return max(set(outcomes), key=outcomes.count)","6f38ad52":"# Create child splits for a node or make terminal\ndef split(node, maxDepth, minSize, depth):\n    left, right = node['groups']\n    del(node['groups'])\n    # check for a no split\n    if not left or not right:\n        node['left'] = node['right'] = toTerminal(left + right)\n        return\n    # check for max depth\n    if depth >= maxDepth:\n        node['left'], node['right'] = toTerminal(left), toTerminal(right)\n        return\n    # process left child\n    if len(left) <= minSize:\n        node['left'] = toTerminal(left)\n    else:\n        node['left'] = getBestSplit(left)\n        split(node['left'], maxDepth, minSize, depth+1)\n    # process right child\n    if len(right) <= minSize:\n        node['right'] = toTerminal(right)\n    else:\n        node['right'] = getBestSplit(right)\n        split(node['right'], maxDepth, minSize, depth+1)","1a4856cf":"# Build a decision tree\ndef buildTree(train, maxDepth, minSize):\n    root = getBestSplit(train)\n    split(root, maxDepth, minSize, 1)\n    return root","a5656a41":"# Print a decision tree\ndef printTree(node, depth=0):\n    if isinstance(node, dict):\n        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n        printTree(node['left'], depth+1)\n        printTree(node['right'], depth+1)\n    else:\n        print('%s[%s]' % ((depth*' ', node)))\n","a5e32e55":"# Make a prediction with a decision tree\ndef predict(node, row):\n    if row[node['index']] < node['value']:\n        if isinstance(node['left'], dict):\n            return predict(node['left'], row)\n        else:\n            return node['left']\n    else:\n        if isinstance(node['right'], dict):\n            return predict(node['right'], row)\n        else:\n            return node['right']","511f7f50":"#  predict with a stump\nstump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\nfor row in dataset:\n    prediction = predict(stump, row)\n    print('Expected=%d, Got=%d' % (row[-1], prediction))\n","4338c89b":"# Classification and Regression Tree Algorithm\ndef fit(train, maxDepth, minSize):\n    tree = buildTree(train, maxDepth, minSize)\n    return tree\n\ndef decisionTree(train, test, maxDepth, minSize):\n    tree = buildTree(train, maxDepth, minSize)\n    predictions = list()\n    for row in test:\n        prediction = predict(tree, row)\n        predictions.append(prediction)\n    return(predictions)\n\n# Split a dataset into k folds\ndef crossValidationSplit(dataset, nFolds):\n    datasetSplit = list()\n    datasetCopy = list(dataset)\n    foldSize = int(len(dataset) \/ nFolds)\n    for i in range(nFolds):\n        fold = list()\n        while len(fold) < foldSize:\n            index = randrange(len(datasetCopy))\n            fold.append(datasetCopy.pop(index))\n        datasetSplit.append(fold)\n    return datasetSplit\n\n# Calculate accuracy percentage\ndef accuracyMetric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i]:\n            correct += 1\n    return correct \/ float(len(actual)) * 100.0\n\n\n# Evaluate an algorithm using a cross validation split\ndef evaluateAlgorithm(dataset, algorithm, nFolds, *args):\n    folds = crossValidationSplit(dataset, nFolds)\n    scores = list()\n    for fold in folds:\n        trainSet = list(folds)\n        trainSet.remove(fold)\n        trainSet = sum(trainSet, [])\n        testSet = list()\n        for row in fold:\n            rowCopy = list(row)\n            testSet.append(rowCopy)\n            rowCopy[-1] = None\n        predicted = algorithm(trainSet, testSet, *args)\n        actual = [row[-1] for row in fold]\n        accuracy = accuracyMetric(actual, predicted)\n        scores.append(accuracy)\n    return scores","71e1ffe8":"# Test CART on Bank Note dataset\nseed(1)\n# load and prepare data\nfilename = \"..\/input\/data_banknote_authentication.csv\"\ndataset = loadCsv(filename)","42f5ff13":"# evaluate algorithm\nnFolds = 5\nmaxDepth = 5\nminSize = 10\nscores = evaluateAlgorithm(dataset, decisionTree, nFolds, maxDepth, minSize)\nprint('Scores: %s' % scores)\nprint('Mean Accuracy: %.3f%%' % (sum(scores)\/float(len(scores))))","189ffb0a":"import pandas as pd\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc","6a090afd":"import matplotlib.pyplot as plt\n%matplotlib inline","0b1e3032":"lsFt = [\"ft_%d\"%i for i in range(4)] \nlsCol = lsFt + [\"label\"]","4b3d1dd7":"filename = \"..\/input\/data_banknote_authentication.csv\"\npdfData = pd.read_csv(filename, names=lsCol)","edfac989":"pdfData.shape","299241b0":"pdfData.head()","3a77f360":"pdfData[lsFt].hist(bins=50, figsize=(15,15))\nplt.show()","05072bd6":"corrMatrix = pdfData.corr()\nprint(corrMatrix[\"label\"].sort_values(ascending=False))","ab1a5c85":"data = pdfData[lsFt].values\nlabel = pdfData[[\"label\"]].values","4faa8aa4":"X_train, X_test, y_train, y_test = train_test_split(\n    data, label, test_size=0.2, random_state=2)","9ffd53ff":"dTreeClf = DecisionTreeClassifier()","7509cb86":"# K-fold estimator, scoring=\"neg_mean_squared_error\"\nscores = cross_val_score(dTreeClf, X_train, y_train,\n                         scoring=\"roc_auc\", cv=5)\nprint(scores)","cf2feeb5":"dTreeClf.fit(X_train, y_train)","e0b83631":"predictions = dTreeClf.predict(X_test)","4409003d":"# creating a confusion matrix \ncm = confusion_matrix(y_test, predictions) \nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\n# plt.title('Confusion matrix')\nfig.colorbar(cax)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\nprint(\"-\"*30)","1c9097c0":"# Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality\ndef drawROC(trueLabel, predictions):\n    # fpr: false_positive_rate\n    # tpr: true_positive_rate \n    # thres: thresholds \n    fpr, tpr, thres = roc_curve(trueLabel, predictions)\n    aucScore = auc(fpr, tpr)\n    plt.figure()\n    lw = 2\n    # Plot the curve\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % aucScore)\n\n    # Plot the random line\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return 0","fc91fdf5":"## Draw AUC curve\ndrawROC(y_test, predictions)","16e88118":"from sklearn.tree import export_graphviz\nexport_graphviz(\n        dTreeClf,\n        out_file=\".\/banknote_tree.dot\",\n        feature_names=lsFt,\n        class_names=\"label\",\n        rounded=True,\n        filled=True\n    )","7c13e304":"!dot -Tpng banknote_tree.dot -o banknote_tree.png","40c7bfb2":"### 4. Validate by sklearn","fb6b61b3":"1. Gini Index.\n2. Create Split.\n3. Build a Tree.\n4. Make a Prediction.\n5. Banknote Case Study","b5c4b269":"# DECISION TREE","045c2536":"### 3. Test the algorithm","29b27fb1":"### 2. Build the tree","a78afe09":"### 1. Gini Impurity and split point"}}