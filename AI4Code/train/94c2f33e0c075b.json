{"cell_type":{"501d330f":"code","3053a5f8":"code","8a73a299":"code","d2080dbe":"code","2159332c":"code","33ee506a":"code","20cc3e9a":"code","35b86020":"code","cc37e4a5":"code","d1372bb9":"code","2b011ffd":"code","09b35c52":"code","30afd219":"code","7d41c05c":"code","e30d9431":"code","0d7f9b3f":"code","aaa5597a":"code","dfb000b0":"code","5f18f943":"code","dca9b7a8":"code","663b8e0d":"code","a1baabd4":"code","1e41fe6c":"code","ba9178ec":"code","6682b294":"code","52581793":"code","a2f57533":"code","db1789c4":"code","ffc7c0ad":"code","6eabe5e3":"code","5b877f47":"markdown","c05e4441":"markdown","b817db59":"markdown","6756a868":"markdown","5427bd91":"markdown","ecf26339":"markdown","6c6f765a":"markdown","cd6b9cce":"markdown","56067cc9":"markdown","aaff6bab":"markdown","5fd86271":"markdown","b5f45893":"markdown","aacbd0e3":"markdown","eec43799":"markdown","1c3c1cc5":"markdown","acdf62b2":"markdown"},"source":{"501d330f":"import requests\nfrom bs4 import BeautifulSoup as bs","3053a5f8":"#Load the web page content\nr = requests.get(\"https:\/\/keithgalli.github.io\/web-scraping\/example.html\")\n\n#Convert to a bs object\nsoup = bs(r.content)\n\nprint(soup)\n\n#Print out our HTML\nprint(soup.prettify())","8a73a299":"soup","d2080dbe":"first_header = soup.find(\"h2\")\nfirst_header\n\nheaders = soup.find_all(\"h2\")\nheaders","2159332c":"#Pass in a list of elements to look for\nfirst_header = soup.find([\"h1\", \"h2\"])\nfirst_header\n\nheaders = soup.find_all([\"h1\", \"h2\"])\nheaders","33ee506a":"#You can pass in attributes to the find\/find_all function\nparagraph = soup.find_all(\"p\")\nparagraph","20cc3e9a":"#Let's say I want the one with the id = to paragraph-id\nparagraph = soup.find_all(\"p\", attrs={\"id\": \"paragraph-id\"})\nparagraph","35b86020":"#You can nest find\/find all calls\nbody = soup.find('body')\ndiv = soup.find('div')\nh1 = soup.find('h1')\nh1","cc37e4a5":"#We can search spesif strings in our find\/find all calls\nprint(soup.prettify())\n\nparagraph = soup.find_all(\"p\", string=\"Some bold text\")\nparagraph\n\n'''But let's assume that we wanna search a specific object by entering just one word,\n    in this case I want the paragraph by typing \"Some\" '''\nparagraph_byword = soup.find_all('p', string=\"Some\")\nparagraph_byword\n\n#I GET AN EMPITY LIST! ... SO WE HAVE TO CHANGE METHOD\nimport re\nparagraphs = soup.find_all(\"p\", string=re.compile(\"Some\"))\nparagraphs","d1372bb9":"headers = soup.find_all(\"h2\", string=re.compile(\"(H|h)eader\"))\nheaders","2b011ffd":"print(soup.body.prettify())","09b35c52":"paragraph = soup.select('p')\nparagraph","30afd219":"#But i want the paragraph in the div so:\ndiv_p = soup.select('div p')\ndiv_p","7d41c05c":"#Now I want the paragraph after the h2\nafterh2_p = soup.select(\"h2 ~ p\")\nafterh2_p","e30d9431":"bold_text = soup.select(\"p#paragraph-id b\")\nbold_text","0d7f9b3f":"#use .string\nheader = soup.find('h2')\nheader.string\n\n","aaa5597a":"#If multiple child elements use get_text\ndiv = soup.find(\"div\")\nprint(div.prettify())\nprint(div.get_text())","dfb000b0":"link = soup.find(\"a\")\nlink","5f18f943":"link['href']","dca9b7a8":"paragraphs = soup.select(\"p#paragraph-id\")\nparagraphs","663b8e0d":"paragraphs[0]['id']","a1baabd4":"soup.body.div.h1.string","1e41fe6c":"#Load the web page content\nurl = \"https:\/\/keithgalli.github.io\/web-scraping\/\"\nr = requests.get(url+\"webpage.html\")\n\n#Convert to a bs object\nwebpage = bs(r.content)\n\n#Print out our HTML\nprint(webpage.prettify())","ba9178ec":"links = webpage.select('ul.socials a')\nactual_links = [link['href'] for link in links]\nactual_links\n","6682b294":"ulist = webpage.find('ul', attrs={'class':'socials'})\nlinks = ulist.find_all('a')\nactual_links = [link['href'] for link in links]\nactual_links","52581793":"links = webpage.select('li.social a')\nfinal_links = [link['href'] for link in links]\nfinal_links","a2f57533":"import pandas as pd\n\ntable = webpage.select('table.hockey-stats')[0]\ncolumns = table.find('thead').find_all('th')\ncolumn_names = [c.string for c in columns]\n\ntable_rows = table.find('tbody').find_all('tr')\nl = []\nfor tr in table_rows:\n    td = tr.find_all('td')\n    row = [tr.text.strip() for tr in td]\n    l.append(row)\n\ndf = pd.DataFrame(l, columns=column_names)\ndf","db1789c4":"import re\n\nfun_facts = webpage.select('ul.fun-facts li')\nfacts_with_is = [fact.find(string=re.compile(\"is\")) for fact in fun_facts]\nfacts_with_is = [fact.find_parent().get_text() for fact in facts_with_is if fact]\nfacts_with_is","ffc7c0ad":"img = webpage.select(\"div.row div.column img\")\nimg_url = img[2]['src']\nfull_url = url + img_url\n\nimg_data = requests.get(full_url).content\nwith open('cinque_terre.jpg', 'wb') as handler:\n    handler.write(img_data)","6eabe5e3":"files = webpage.select(\"div.block a\")\nrelative_files = [file['href'] for file in files]\n\nfor file in relative_files:\n    full_url = url + file\n    page = requests.get(full_url)\n    bs_page = bs(page.content)\n    secret_word_element = bs_page.find('p', attrs={'id':'secret-word'})\n    secret_word = secret_word_element.string\n    print(secret_word)","5b877f47":"## Get a specific property from an element","c05e4441":"## Get different proprieties of the HTML","b817db59":"# selct (CSS Selector)","6756a868":"#### Method 1 of 3 : select","5427bd91":"## Start Using BeautifulSoup to Scrape","ecf26339":"## EXERCISE 3: Grab all the fun facts that use word \"is\"","6c6f765a":"#### Method 3 of 3","cd6b9cce":"## EXERCISE 4: Download an Image","56067cc9":"## Code Navigation","aaff6bab":"paragraphs = soup.select(\"body > p\")\nprint(paragraphs)\n\nfor paragraph in paragraphs:\n    print(paragraph.select('i'))\n\n#As we can correctly see, just one paragraph is in Italicized","5fd86271":"## EXERCISE 2: Scrape the table","b5f45893":"# EXERCISES","aacbd0e3":"#### Method 2 of 3: find","eec43799":"### Do this in at least 3 different methods","1c3c1cc5":"## EXERCISE 1 : Grab all of the social links from the webpage","acdf62b2":"## EXERCISE 5: Mystery Challenge!"}}