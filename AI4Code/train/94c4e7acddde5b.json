{"cell_type":{"08d11dd3":"code","fb4e489a":"code","02b8ecda":"code","89bcb4f1":"code","c06c0951":"code","1bcb6b3c":"code","a488d81c":"code","389b27da":"code","4159c6bd":"code","05f9179e":"code","87b80e86":"code","80bfb226":"code","ad3c2ddb":"code","5db79d40":"code","e87f18ac":"code","4addc2cc":"code","66106975":"code","2f1e29a3":"code","572edc6d":"code","cfcb32e8":"markdown","40168e6d":"markdown","084fe5e2":"markdown","1b049433":"markdown","6c8e24ba":"markdown","550b85aa":"markdown","a0045ffa":"markdown","8922a5ce":"markdown","3eb95722":"markdown","77bcfec3":"markdown","4536fd4a":"markdown","18bc0635":"markdown","50e1d1a5":"markdown","96b48667":"markdown","9b69e46b":"markdown","55ff7e65":"markdown","58cad30d":"markdown","ddd3cf4f":"markdown","0f30ebeb":"markdown","3cb1c39c":"markdown","a7d986a7":"markdown","ed155ee7":"markdown"},"source":{"08d11dd3":"#import some stuff\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as st\nfrom sklearn import datasets, linear_model\n!wget \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/adult\/adult.data\" \n!wget \"http:\/\/jse.amstat.org\/v19n3\/decock\/AmesHousing.txt\"","fb4e489a":"#Get some data \nx = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) \ny = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n\n#Let's plot the data to see what it looks like\nplt.scatter(x, y, color = \"black\", \n               marker = \"o\", s = 30) \nplt.show()","02b8ecda":"#calculating the coefficients\n\n# number of observations\/points \nn = np.size(x) \n\n# mean of x and y vector \nm_x, m_y = np.mean(x), np.mean(y) \n\n# calculating cross-deviation and deviation about x \nSS_xy = np.sum(y*x - n*m_y*m_x) \nSS_xx = np.sum(x*x - n*m_x*m_x) \n\n# calculating regression coefficients \nb_1 = SS_xy \/ SS_xx \nb_0 = m_y - b_1*m_x\n\n#var to hold the coefficients\nb = (b_0, b_1)\n\n#print out the estimated coefficients\nprint(\"Estimated coefficients:\\nb_0 = {} \\nb_1 = {}\".format(b[0], b[1])) ","89bcb4f1":"#we need to reshape the array to make the sklearn gods happy\nx = x.reshape(-1,1)\ny = y.reshape(-1,1)\n\n#making the model\nregress = linear_model.LinearRegression()\nregress.fit(x, y)\ny_sk_pred = regress.predict([[6]])","c06c0951":"# plotting the actual points as scatter plot \nplt.scatter(x, y, color = \"black\", \n           marker = \"o\", s = 30) \n\n# predicted response vector \ny_pred = b[0] + b[1]*x \n\n# plotting the regression line \nplt.plot(x, y_pred, color = \"blue\") \n\n# putting labels \nplt.xlabel('x') \nplt.ylabel('y') \n\n# function to show plot \nplt.show()","1bcb6b3c":"#here we can try out any data point\nprint(regress.predict([[6]]))","a488d81c":"housing_data =  pd.read_csv(\"AmesHousing.txt\", delimiter=\"\\t\") \n\n#Mean Sales price \nmean_price = np.mean(housing_data[\"SalePrice\"])\nprint(\"Mean Price : \" + str(mean_price))\n\n#Variance of the Sales Price \nvar_price = np.var(housing_data[\"SalePrice\"], ddof=1)\nprint(\"Variance of Sales Price : \" + str(var_price))\n\n#Median of Sales Price \nmedian_price = np.median(housing_data[\"SalePrice\"])\nprint(\"Median Sales Price : \" + str(median_price))\n\n#Skew of Sales Price \nskew_price = st.skew(housing_data[\"SalePrice\"])\nprint(\"Skew of Sales Price : \" + str(skew_price))","389b27da":"plt.hist(housing_data[\"SalePrice\"])\nplt.xlabel(\"Price\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Housing Prices\")\nplt.show()","4159c6bd":"plt.boxplot(housing_data[\"SalePrice\"])\nplt.ylabel(\"Sales Price\")\nplt.show()","05f9179e":"plt.scatter(housing_data[\"Gr Liv Area\"], housing_data[\"SalePrice\"])\nplt.ylabel(\"Sales Price\")\nplt.show()","87b80e86":"#we need to reshape the array to make the sklearn gods happy\narea_reshape = housing_data[\"Gr Liv Area\"].reshape(-1,1)\nprice_reshape = housing_data[\"SalePrice\"].reshape(-1,1)\n\n#Generate the Model\nmodel = linear_model.LinearRegression(fit_intercept=True)\nmodel.fit(area_reshape, price_reshape)\nprice_prediction = model.predict(area_reshape)\n\n# plotting the actual points as scatter plot \nplt.scatter(area_reshape, price_reshape) \n\n# plotting the regression line \nplt.plot(area_reshape, price_prediction, color = \"red\") \n\n# putting labels \nplt.xlabel('Above Ground Living Area') \nplt.ylabel('Sales Price') \n\n# function to show plot \nplt.show()","80bfb226":"#we're going to need a different model, so let's import it\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","ad3c2ddb":"#read_csv allow us to easily import a whole dataset\ndata = pd.read_csv(\"adult.data\", names =[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"])\n\n#this tells us whats in it \nprint(data.info())","5db79d40":"# data.head() gives us some the the first 5 sets of the data\nprint(data.head())\n\n#this is the function that give us some quick info about continous data in the dataset\nprint(data.describe())","e87f18ac":"#put the name of the parameter you want to test\ntest = \"\"","4addc2cc":"#little baby helper function\ndef incomeFixer(x):\n  if x == \" <=50K\":\n    return 0\n  else:\n    return 1\n\n#change the income data into 0's and 1's\ndata[\"income\"] = data.apply(lambda row: incomeFixer(row['income']), axis=1)\n\n#ploting \nplt.scatter(data[test], data['income'], color= \"black\")\nplt.show()","66106975":"#but before we make our model, we need to modify our data a bit\n\n\n#get the data we are going to make the model with \nx = np.array(data[test])\ny = np.array(data[\"income\"])\n\n#again, lets make the scikitlearn gods happy\nx = x.reshape(-1,1)\n\n#Making the test-train split\nx_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=0.25, random_state=42)","2f1e29a3":"#now make data model!\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train,y_train)","572edc6d":"#now need to test the model's performance\nprint(logreg.score(x_test,y_test))","cfcb32e8":"This data set was provided by UCI's Machine Learning Repository: \n\n*  [Adult Data Set (Also know as Census Income)](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Adult)\n\nWe already downloaded the dataset at the begining of the notebook, so now let's mess around with it.\n\nBut before that, we need to read in the data, and pandas has the functions we need to do this\n","40168e6d":"The data for this example is arbitrary (we'll use real data in a bit), but there is a clear linear relationship here\n\nGraphing the data will make this relationship clear to see","084fe5e2":"<img src=\"https:\/\/ucfai.org\/\/course\/sp19\/linear-regression\/banner.jpg\">\n\n<div class=\"col-12\">\n    <a class=\"btn btn-success btn-block\" href=\"https:\/\/ucfai.org\/signup\">\n        First Attendance? Sign Up!\n    <\/a>\n<\/div>\n\n<div class=\"col-12\">\n    <h1> Starting with the Basics, Regression <\/h1>\n    <hr>\n<\/div>\n\n<div style=\"line-height: 2em;\">\n    <p>by: \n        <strong> Liam Jarvis<\/strong>\n        (<a href=\"https:\/\/github.com\/JarvisEQ\">@JarvisEQ<\/a>),\n        <strong> Steve Testa<\/strong>\n        (<a href=\"https:\/\/github.com\/causallycausal\">@causallycausal<\/a>),    \n        <strong> John Muchovej<\/strong>\n        (<a href=\"https:\/\/github.com\/ionlights\">@ionlights<\/a>)\n     on 2019-02-06<\/p>\n<\/div>","1b049433":"But, we don't need to directly program all of the maths everytime we do linear regression\n\nsklearn has built in functions that allows you to quickly do Linear Regression with just a few lines of code\n\nWe're going to use sklearn to make a model and then plot it using matplotlib\n","6c8e24ba":"###What's inside? \n\nThis \u201dnew\u201d data set contains 2930 (n=2930) observations along with 80\npredictor variables and two identification variables. \n\n[Paper linked to dataset](http:\/\/jse.amstat.org\/v19n3\/decock.pdf)\n\nAn exhaustive variable breakdown can be found\n[here](http:\/\/jse.amstat.org\/v19n3\/decock\/DataDocumentation.txt)\n\n###**Quick Summary** \n---\nOf the 80 predictor variables we have:\n> - 20 continuous variables (area dimension)\n - Garage Area, Wood Deck Area, Pool Area\n> - 14 discrete variables (items occurring)\n - Remodeling Dates, Month and Year Sold\n > - 23 nominal and 23 ordinal \n - Nominal: Condition of the Sale, Type of Heating and\nFoundation\n - Ordinal: Fireplace and Kitchen Quality, Overall\nCondition of the House\n\n\n","550b85aa":"***Question to Answer***: What is the linear relationship between sale price on above ground\nliving room area?\n\nBut first lets visually investigate what we are trying to predict. ","a0045ffa":"And now lets see what the model looks like","8922a5ce":"First thing first, we to get some packages \n\n*   matplotlib allows us to graph \n*   numpy is powerful package for data manipulation\n*   pandas is a tool for allowing us to interact with large datasets\n*   sklearn is what we'll use for making the models\n*   !wget grabs the data set we'll be using later","3eb95722":"Now we shall look at sales price on above ground living room area. ","77bcfec3":"___\n## **[Die Pr\u00e4sentation](https:\/\/docs.google.com\/presentation\/d\/12MvqRMZlKL3DwqAX1XqQMaL21UUV29hLkEcYO3liHfs\/edit?usp=sharing)**\n\n----","4536fd4a":"We shall start our analysis with summary statistics. ","18bc0635":"--------------------------------------------\n## Applied Linear Regression \n--------------------------------------------\n","50e1d1a5":"**Now here is the Qustion:**\n\n\n>*Which one of these parameters are best in figuring out if someone is going to be making more then 50k a year?*","96b48667":"###What was the original purpose of this data set? \n\nThat is, why did the Amess City Assessor's Office decide to collect this data? \n\n> - **Answer**: To update the assessment model used by the Ames\nCity Assessor\u2019s Office.\n\nNow you may ask, what is an assessment model? \n\n>- **Answer**: In short, an assessment model is used to assign dollar value to a property that reflects the true market value of that property.\n\nNow according to the Iowa Department of Revenue\u2019s website, primary beneficiaries of the revenue generated by\nproperty taxes include but are not limited to: \n> - K-12 Schools, Hospitals, Assessors, Townships, and Agricultural\nExtension Districts.\n\n**Moral of this story**: We will be using the modified Ames housing dataset to predict housing price. \n","9b69e46b":"###The Ames Housing Dataset \n> Ames is a city located in Iowa.\n> \n> - This data set consists of all property sales\ncollected by the Ames City Assessor\u2019s Office between the years\nof 2006 and 2010.\n> - Originally contained 113 variables and 3970 property sales\npertaining to the sale of stand-alone garages, condos, storage\nareas, and of course residential property.\n> - Distributed to the public as a means to replace the old Boston\nHousing 1970\u2019s data set.  \n> - [Link to Original](http:\/\/lib.stat.cmu.edu\/datasets\/boston) \n> - The \"cleaned\" version of this dataset contains 2930 observations along with 80\npredictor variables and two identification variables.\n","55ff7e65":"Ploting will help with visualising the data","58cad30d":"So now we can make predictions with new points based off our data","ddd3cf4f":"--------------------------------------------\n\n## **Applied Logistic Regression**\n\n--------------------------------------------","0f30ebeb":"Finally, lets generate our model and see how it predicts Sales Price!!","3cb1c39c":"--------------------------------------------------\n\n## **Linear Regression**\n\n--------------------------------------------------","a7d986a7":"Here's the meat of the calculations\n\nThis is using least squares estimation, which tries to minimize the squared error of the function vs. the training data\n\nSS_xy is the cross deviation about x, and SS_xx is the deviation about x\n\n[It's basically some roundabout algebra methods to optimize a function](https:\/\/www.amherst.edu\/system\/files\/media\/1287\/SLR_Leastsquares.pdf) \n\nThe concept isn't super complicated but it gets hairy when you do it by hand","ed155ee7":"Another way we can view our data is with a box and whisker plot."}}