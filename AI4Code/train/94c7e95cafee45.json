{"cell_type":{"03d40a03":"code","f9cc6f44":"code","169232ea":"code","f02ed848":"code","54e4f1cf":"code","160568fc":"code","4ea39f01":"code","17ea7360":"code","7e948f77":"code","66aec3cb":"code","0aaf38a5":"code","68bc6900":"code","dacdf71f":"code","79022076":"code","9ac66ec4":"code","354a8a85":"code","5291f642":"code","d1bc40a6":"code","01a9c524":"code","8b9e136c":"markdown","089c2bc9":"markdown","b896a73e":"markdown","64194515":"markdown","207af9ea":"markdown","d67d7f82":"markdown","f736f38f":"markdown","cb3997c3":"markdown","85215a2d":"markdown","8a7d5cda":"markdown","c8b232b6":"markdown","603e06fa":"markdown","18252434":"markdown","af0ad011":"markdown","f611586b":"markdown","71d413bf":"markdown","f2ae5ec5":"markdown"},"source":{"03d40a03":"import pandas_profiling #for EDA\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#For text proccessing\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import text_to_word_sequence\n#For network building\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n#For model evaluation\nfrom sklearn.model_selection import train_test_split","f9cc6f44":"df=pd.read_csv(\"..\/input\/winemag-data-130k-v2.csv\")","169232ea":"print(df.shape)\nprint(df.columns)","f02ed848":"pandas_profiling.ProfileReport(df)","54e4f1cf":"del df[\"Unnamed: 0\"]\ndf=df.loc[np.logical_and(df.taster_name.notna(),df.description.notna()),:]","160568fc":"df.taster_name.value_counts()","4ea39f01":"df.taster_name.value_counts().plot(kind=\"bar\")","17ea7360":"df[\"taster_name\"]=[\n    x if x in [\"Roger Voss\",\"Michael Schachner\",\"Kerin O\u2019Keefe\",\"Virginie Boone\",\"Paul Gregutt\",\"Matt Kettmann\",\"Joe Czerwinski\"]\n    else \"Other Reviewer\" \n    for x in df.taster_name\n]","7e948f77":"df.taster_name.value_counts()","66aec3cb":"for i in range(5):\n    print(df.description[i])\n    print(\"---------------------\")","0aaf38a5":"t=Tokenizer()\nt.fit_on_texts(df.description.tolist())","68bc6900":"#Had to break this up into chunks for memory purposes\nX=(t.texts_to_sequences(df.description[0:50000]))\nX.extend(t.texts_to_sequences(df.description[50000:]))","dacdf71f":"X=np.array(pad_sequences(X))","79022076":"Y=pd.get_dummies(df.taster_name)\ntarget_lables=Y.columns\nY=Y.values","9ac66ec4":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=123)","354a8a85":"max_words=len(t.word_counts)\nembed_len=100\nmem_units=100","5291f642":"model = Sequential()\nmodel.add(Embedding(max_words, embed_len, input_length=128))\nmodel.add(LSTM(mem_units))\nmodel.add(Dense(8, activation='sigmoid'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=3, batch_size=64)","d1bc40a6":"preds=model.predict_classes(X_test)\npreds=[target_lables[x] for x in preds]\nactual=[target_lables[x] for x in Y_test.argmax(axis=1)]","01a9c524":"pd.crosstab(pd.Series(preds),pd.Series(actual))","8b9e136c":"Right away we can go ahead and drop that unnamed column (looks like an id or index) and drop records that do not have a *taster_name* or *description*.","089c2bc9":"First we'll import the necessary packages and load in the csv that includes reviewer.","b896a73e":"### Evaluating the Model\n\nAt first glance it looks like this model does a great job. Lets take a peak at the confusion matrix.","64194515":"### Tokenize the reviews\n\nOur first step is to tokenize the review texts so we can feed them into keras.","207af9ea":"### Splitting Data into Train\/Test Partitions\n\nIdeally we'd utilize k-fold CV, but because our sample size isn't very large and training a LSTM NN is fairly time consuming, we'll just use a simple 80\/20 split.","d67d7f82":"# Predicting Review Author From Review Text\n\n## Table of Contents\n1. Setup\n2. EDA\n3. Building the Classifier\n","f736f38f":"## EDA","cb3997c3":"## Setup","85215a2d":"Since there are only 14 columns, I'll utilize pandas-profiling to give a quick glance at the data.","8a7d5cda":"### Exploring the target\n\nLets start by looking at the value counts for our target.","c8b232b6":"### Overview","603e06fa":"Now we'll pad the matrix so each review has the same length.","18252434":"Before we start working on the model, let's take a look at some of the reviews we'll use as the inputs.","af0ad011":"### Convert target into matrix\n","f611586b":"Given the small sample size we have for some of the reviewers, lets group everyone under 5000 into \"Other Reviewers\"","71d413bf":"## Building the Classifier\n\nIn this section we'll build our model. We'll utilize an LSTM neural network since they are able to more fully learn the sequential patterns in the review text.","f2ae5ec5":"### Building+Fitting the Network\nThere was a bit of experimenting to end up with these hyper parameters.\n"}}