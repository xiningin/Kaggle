{"cell_type":{"881f1b8f":"code","cb77552e":"code","73cac42b":"code","fd15d7d1":"code","ab5894f6":"code","f534f638":"code","07a5805b":"code","78e07e02":"code","c1d421d0":"code","364c3576":"code","8de3543e":"code","025b2aac":"code","36046583":"code","c4e7d51d":"code","6c00c764":"code","581cfe0d":"code","e32c431e":"code","5f180935":"code","214ea39d":"code","ef39c46c":"code","83090762":"code","fbe6c7f6":"code","6f56b647":"code","376a8cff":"code","a67c89a6":"code","0b2ef05b":"code","dd06518d":"code","e820821a":"code","94734108":"code","35b7f207":"code","ff985baf":"code","5cd067d3":"code","73c6cc40":"code","d55857c8":"markdown","1a9c8def":"markdown"},"source":{"881f1b8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.pandas.set_option('display.max_columns',None)\npd.pandas.set_option('display.max_rows',None)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb77552e":"train = pd.read_csv('..\/input\/jovian-pytorch-z2g\/Human protein atlas\/train.csv')\ntrain.head(10)","73cac42b":"train.shape","fd15d7d1":"train.isnull().sum()","ab5894f6":"from plotly.offline import iplot\nimport plotly as py\nimport plotly.tools as tls\nimport cufflinks as cf\n\npy.offline.init_notebook_mode(connected = True)\ncf.go_offline()","f534f638":"train['Label'].value_counts().iplot(kind='bar',theme='solar',color = [ 'gold'],title='Class distribution')","07a5805b":"def encode_label(label):\n    target = np.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target","78e07e02":"def decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","c1d421d0":"label3 = []\n\nfor i in train['Label']:\n    label3.append(encode_label(i))\n    \nlabel3 = np.array(label3)","364c3576":"label3.shape","8de3543e":"train['Label'][2]","025b2aac":"encode_label(train['Label'][2])","36046583":"import gc\ngc.collect()","c4e7d51d":"DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/train'\nimg_dir = []\n\nfor i in train['Image']:\n    img_dir.append(os.path.join(DIR,str(i))+'.png')\n    \n    \n","6c00c764":"y = label3\nx = np.array(img_dir)","581cfe0d":"SEED = 42\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_val,y_train,y_val = train_test_split(x,y,test_size = 0.2,random_state = SEED)","e32c431e":"import cv2\nimport matplotlib.pyplot as plt\n\nimg = plt.imread(img_dir[100])\nplt.imshow(img)","5f180935":"img.shape","214ea39d":"test = pd.read_csv('..\/input\/jovian-pytorch-z2g\/submission.csv')\ntest.head()","ef39c46c":"TEST_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/test'\ntest_img = []\n\nfor i in test['Image']:\n    test_img.append(os.path.join(TEST_DIR,str(i))+'.png')\n\ntest_img = np.array(test_img)","83090762":"import tensorflow as tf","fbe6c7f6":"img_size = 256\nAUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 8\nEPOCHS = 10","6f56b647":"def decode_image(filename, label=None, image_size=(img_size,img_size)) :\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.bfloat16) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label == None :\n        return image\n    else :\n        return image, label","376a8cff":"bool_random_brightness = False\nbool_random_contrast = False\nbool_random_hue = False\nbool_random_saturation = False\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if bool_random_brightness:\n        image = tf.image.random_brightness(image,0.2,seed=seed)\n    if bool_random_contrast:\n        image = tf.image.random_contrast(image,0.6,1.4, seed=seed)\n    if bool_random_hue:\n        image = tf.image.random_hue(image,0.07,seed=seed)\n    if bool_random_saturation:\n        image = tf.image.random_saturation(image,0.5,1.5,seed=seed)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","a67c89a6":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .cache()\n    .repeat()\n    .shuffle(1024)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","0b2ef05b":"test_dataset=(\n    tf.data.Dataset\n    .from_tensor_slices(test_img)\n    .map(decode_image ,num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","dd06518d":"valid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_val, y_val))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","e820821a":"def create_test_data(test_paths,aug=False):\n    test_data = (\n        tf.data.Dataset.from_tensor_slices(test_paths)\n        .map(decode_image, num_parallel_calls = AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    \n    if aug == True :\n        test_data = test_data.map(data_augment ,num_parallel_calls = AUTO)\n    return test_data","94734108":"channel = 3\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras import layers,models\n\nmodel = models.Sequential()\nmodel.add(ResNet50(weights = 'imagenet',include_top=False,input_shape=(img_size,img_size,channel))\n)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(10,activation='sigmoid'))\n\n\n","35b7f207":"model.summary()","ff985baf":"model.compile(loss=tf.keras.losses.binary_crossentropy,optimizer='adam',metrics = ['acc'])","5cd067d3":"mc = tf.keras.callbacks.ModelCheckpoint('resnet50_model.h5',monitor='val_acc',mode='max',save_best_only=True,verbose=1)\n","73c6cc40":"history = model.fit(train_dataset, \n        epochs=EPOCHS, \n        callbacks=[mc],\n        steps_per_epoch=y_train.shape[0] \/\/ BATCH_SIZE,\n        validation_data=valid_dataset,\n        validation_steps=y_val.shape[0] \/\/ BATCH_SIZE\n    )","d55857c8":"# Model Building","1a9c8def":"## Data Loading:"}}