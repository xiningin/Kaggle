{"cell_type":{"d45b5dff":"code","a0677a52":"code","338a2393":"code","bc3a25e7":"code","df0341be":"code","0a69d301":"code","4480da39":"markdown","def9667e":"markdown","57aff558":"markdown","ce15e14d":"markdown","25d1bf65":"markdown","ead7ec85":"markdown"},"source":{"d45b5dff":"def block():\n    \n    global df\n    \n    import numpy as np \n    import pandas as pd \n    pd.options.display.max_columns = None\n\n    df = pd.read_csv( '\/kaggle\/input\/creditcardfraud\/creditcard.csv' )\n    \n    df_len = len(df)\n    \n    df = df.rename(columns={'Time':'dt'})\n    df = df.rename(columns={'Amount':'vr'})\n\n    df.insert( 1, 'dt_sec', df['dt'].apply( lambda x: int(x%(60*60) ) ) )\n    df.insert( 1, 'dt_hour', df['dt'].apply( lambda x: int(x%(24*60*60)\/(60*60) ) ) )\n    df.insert( 2, 'dt_wday', ( df['dt'].apply( lambda x: int(x\/(24*60*60)%7) ) ) ) \n    df['dt'] = df['dt'].apply( lambda x: int(x\/(24*60*60)) )\n    df = df.rename(columns={'dt':'dt_day'})\n        \n    df['vr_f1'] = df['vr'].apply( lambda x: 1 if x < 10 else 0 )\n    df['vr_f2'] = df['vr'].apply( lambda x: 1 if 10 < x < 20 else 0 )\n    df['vr_f3'] = df['vr'].apply( lambda x: 1 if 20 < x < 50 else 0 )\n    df['vr_f4'] = df['vr'].apply( lambda x: 1 if 50 < x < 100 else 0 )\n    df['vr_f5'] = df['vr'].apply( lambda x: 1 if 100 < x < 200 else 0 )\n    df['vr_f6'] = df['vr'].apply( lambda x: 1 if 200 < x < 500 else 0 )\n    df['vr_f7'] = df['vr'].apply( lambda x: 1 if 500 < x < 1000 else 0 )\n    df['vr_f8'] = df['vr'].apply( lambda x: 1 if 1000 < x < 1500 else 0 )\n    df['vr_f9'] = df['vr'].apply( lambda x: 1 if 1500 < x < 2000 else 0 )\n    df['vr_f10'] = df['vr'].apply( lambda x: 1 if 2000 < x < 2500 else 0 )\n    df['vr_f11'] = df['vr'].apply( lambda x: 1 if 2500 < x < 5000 else 0 )\n    df['vr_f12'] = df['vr'].apply( lambda x: 1 if 5000 < x else 0 )\n    \n    df['vr_pad'] = ( df['vr'] - df['vr'].mean() ) \/ df['vr'].std()       \n\n    assert df_len==len(df), \"ERROR, the source dataset was unexpectedly modified\"\n    \n    return df\n      \nblock()","a0677a52":"def block():\n    \n    u = df.describe().transpose()\n    \n    u['Types'] = df.dtypes\n    u['Distinct Values'] = df.nunique()    \n    u['%Distinct Values'] = df.nunique() \/ len(df) * 100.0\n    \n    return u.transpose()\n    \nblock()","338a2393":"def block():\n\n    import matplotlib\n    import matplotlib.pyplot as plt\n    import numpy as np\n    %matplotlib inline\n        \n    fig = plt.figure(figsize=(13,4), dpi=96)\n    fig_grid = fig.add_gridspec(100,360)\n\n    ax = fig.add_subplot( fig_grid[ 0:100, 15:80 ] )\n    ax.set( title=\"Class Histogram\", \n            xlabel=\"class\", xticks=[0,1], xticklabels=['No', 'Yes'],\n            ylabel=\"qt transactions\",  yscale=\"log\" )\n    ax.hist( df['Class'] , [x for i in range(2) for x in (i-0.4,i+0.4)], color='#00800080')\n    \n    ax_cols = [x for x in range(0,24)]\n    ax = fig.add_subplot( fig_grid[ 0:100, 110:250 ] )\n    ax.set( title=\"Transaction count by hour\",\n            xlabel='hour', xticks=ax_cols, xticklabels=ax_cols, \n            ylabel='qt transactions', yscale='log' )\n    ax.hist( df['dt_hour'] , [x for i in ax_cols for x in (i-0.4,i+0.4)], color='#80800080')\n    ax.add_artist(matplotlib.offsetbox.AnchoredText(\"hora = time%(24*60*60)%(60*60)\", frameon=True, loc='lower right'))\n    \n    ax_cols = [x for x in range(0,7)]\n    ax = fig.add_subplot( fig_grid[ 0:100, 290:340 ] )\n    ax.set( title=\"Transacions by day of week\",\n            xlabel='wday', xticks=ax_cols, xticklabels=ax_cols,\n            ylabel='qt transactions', yscale='log')\n    ax.hist( df['dt_wday'] , [x for i in ax_cols for x in (i-0.4,i+0.4)], color='#80800080')\n    \n    plt.show()\n\nblock()","bc3a25e7":"def block():\n    \n    global df\n    global X_train, X_test, X_validation\n    global y_train, y_test, y_validation    \n    global df_features\n    \n    df_features = [\n         'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10',\n        'V11','V12','V13','V14','V15','V16','V17','V18','V19','V20',\n        'V21','V22','V23','V24','V25','V26','V27','V28',\n        'vr_pad'\n        #,  'vr_f1','vr_f2','vr_f3', 'vr_f4', 'vr_f5', 'vr_f6',\n        #'vr_f7','vr_f8','vr_f9','vr_f10','vr_f11','vr_f12'       \n    ]\n    \n    from sklearn.model_selection import train_test_split\n            \n    # first split (df into train and test)\n    X_train, X_test = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=564654)\n    \n    # second split (tain into test and validation)\n    #X_train, X_validation = train_test_split(X_train, test_size=0.2, stratify=X_train['Class'])\n   \n    # ballance classes    \n    X_train_fraude = X_train[ X_train['Class'] == 1 ]\n    X_train_naofraude = X_train[ X_train['Class'] == 0 ]\n    \n    for i in range( int( len(X_train_naofraude)\/len(X_train_fraude) ) ):\n        X_train = X_train.append( X_train_fraude )\n    \n    X_train = X_train.sample(frac=1).reset_index(drop=True)    \n       \n    # third split: (classes)\n    y_train = X_train.pop( 'Class' )\n    y_test = X_test.pop( 'Class' )\n    #y_validation = X_validation.pop( 'Class')\n        \n    print(f'Training shape: {X_train.shape} {y_train.shape}' )\n    #print(f'Validation shape: {X_validation.shape} {y_validation.shape}' )\n    print(f'Test shape: {X_test.shape} {y_test.shape}' )\n         \nblock()","df0341be":"def block():\n    \n    global model\n    \n    from sklearn.neural_network import MLPClassifier\n        \n    model = MLPClassifier(\n                solver='adam',            #default='adam'\n                learning_rate_init=0.001, #default=0.001 step size when updating weights\n                alpha=0.0001,             #default=0.0001 \n                hidden_layer_sizes=(16, 16), \n                random_state=564654,\n                activation='relu',        #default='relu'\n                max_iter=100,\n                early_stopping=True\n    )\n\n    model.fit( X_train[ df_features ], y_train )\n            \nblock()","0a69d301":"def block():\n    \n    import matplotlib\n    import matplotlib.pyplot as plt\n    from sklearn.metrics import confusion_matrix\n    #from sklearn.metrics import roc_curve\n    import seaborn as sns\n    import pandas as pd\n    \n    # calculate the predictions\n    y_pred = model.predict(X_test[ df_features ])\n        \n    class_names = ['Normal','Fraud']\n        \n    confusion_mtx = pd.DataFrame( \n        columns=class_names,        \n        data=confusion_matrix( y_test, y_pred )\n    )    \n    confusion_mtx['Total'] = confusion_mtx['Fraud'] + confusion_mtx['Normal']\n    confusion_mtx = confusion_mtx.append(confusion_mtx.sum(numeric_only=True), ignore_index=True)\n    confusion_mtx = confusion_mtx.rename( index={ 0:'Normal', 1:'Fraud', 2:'Total' } )\n    \n    fig = plt.figure(figsize=(8,8))    \n   # ax = fig.add_subplot( 1 , 1  )\n  \n    sns.set(font_scale=1.5)\n    \n    c = sns.heatmap([[2,1,0],[1,2,0],[0,0,0]], \n                    annot=[\n                        ['\\nTN\\n\\n(true\\nnegative)','\\nFP\\n\\n(false\\npositive)',''],\n                        ['\\nFN\\n\\n(false\\nnegative)','\\nTP\\n\\n(true\\npositive)','\\n\\n\\n(total\\nfraud)'],\n                        ['\\n\\n(not predicted)','\\n\\n(predicted)','\\n\\n(obs)']], \n                    cbar=False, \n                    fmt='',\n                    linewidths=2,\n                    linecolor='#000000',\n                    cmap=matplotlib.colors.ListedColormap(['#ffffff','#FFa0a0','#a0FFa0'])\n                   )\n    c = sns.heatmap(confusion_mtx,                     \n                    annot=True, \n                    fmt='g', \n                    cbar=False, \n                    cmap=matplotlib.colors.ListedColormap(['#ffffff00']),\n                    linewidths=2,                    \n                    linecolor='#000000'\n                   )\n    \n  \n    \n    c.set(xlabel='Predicted',ylabel='True')\n    c.set(title='Confusion Matrix')\n    c.tick_params(right=True, bottom=True, labelright=True, labeltop=True,rotation=0)\n\n\n    fp = confusion_mtx.iloc[0,1] \n    fn = confusion_mtx.iloc[1,0]\n    tn = confusion_mtx.iloc[0,0]\n    tp = confusion_mtx.iloc[1,1] \n    \n    acc       = (tp+tn)\/(tp+tn+fp+fn)\n    recall    = tp\/(tp+fn)\n    f1        = (2*acc*recall)\/(acc+recall)\n    \n    fdr  = fp\/(fp+tp)\n    fnr  = fn\/(fn+tp)\n    \n    ppv  = tp\/(fp+tp)\n    tpr = tp\/(fn+tp)\n    \n    print( f'      Accuracy={acc:05.2f}' )\n    print( f'       F Score={f1:05.2f}' )\n    print( f'   Sensitivity={tpr*100.0:05.2f}% of total fraud        [TP\/(FN+TP)]' )   \n    print( f'     Precision={ppv*100.0:05.2f}% of predicted fraud    [TP\/(FN+TP)]' )    \n    \n    \n    plt.text( s=f'Sensitivity:\\n{tpr*100.0:05.2f}% of', x=2.05, y=1.25, size='small', color='#808080' )\n    plt.text( s=f'Precision:\\n{ppv*100.0:05.2f}% of', ha='right', x=1.95, y=2.25, size='small', color='#808080' )\n    \n    \n    plt.show()\n    \nblock()","4480da39":"# 6. Final Thoughts \n\nThe results found was good, but was inferior to the one we achieved \"out of the box\" with a RandomForestClassifier. \n\nWe achieve a sensibility of ~86% with a precision of ~55%, in other words, aproximatedly one in two predicted frauds was actually a fraud and with that precision was still possible to detect 85% of the frauds of the dataset. \n\nMaybe the results can be improved by:\n* evaluating the kfold to improve the training;\n* evaluating the grid search to check the influence of the model parameters on the results;\n* evaluating the performance with a smaller sample (all fraud + random sample of the normal transactions);\n* evaluating the SMOTE to ballance the dataset;\n* change the model parameters to increase the precision (less false positives) even if this reduce the true posives, extract the false negatives and develop new specialized models on those false positives. \n\n# References\n* https:\/\/www.dataschool.io\/simple-guide-to-confusion-matrix-terminology\/\n* https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.htmlFinal Thoughts \n\n\n\n\n","def9667e":"# 2. Load and prepare dataset\n\nSimple pre-processing:\n* Added columns for wday, day(of month), hour(of day) and sec(of hour)\n* Added columns with vr broken in value slices\n* Added column with the standardized value\n\nBellow an sample of the data and some column statistics:","57aff558":"# 3. Prepare the data for the model\n\nThe following code:\n* splits the dataset in two: \n * **train** with with 80% of the records;\n * **test** with 20% of the records;\n* ballance the data on the training set so that class=0 and class=1 have more or less the same number of records\n* define the features that will be used in the model training\n\nThe best results for the neural net was found with features V1 to V28 and the standardized value. ","ce15e14d":"# 5. Evaluate the results\n\nIn the confusion matrix (bellow):\n* the green diagonal represents the correct predictions made by the model;\n* the red diagonal represent the incorrect predictions made by the model.\n\nThis kind of problem, the objective is to find the class=1 (frauds) with a minimum quantity of losses (false negatives) and the minimum error (false positives) that consume work to be revalidated. With that in mind, the best indicators appears to be:\n* **Precision (Positive Predictive Value)** = `tp \/ (tp+fp)`.\n* **Sensitivity (True Positive Rate or Recall)** = `tp \/ (tp+fn)`\n\n*Accuracy* (`(tp+tn\/tp+tn+fp+fn)` ) is not suited for this kind of problem because it scores well true class=0 predictions and will allow scores close to 100% even when the model does not find any class=0 at all. A simple tought experiment can illustrate that: if the model predicts everything to be class=0, the acuracy score will be 99,8% in a dataset like that. The *F-Score* is the harmonic average of *Acuracy* and *Recall* which inherits the distortion of the *Acuracy* for this kind of problem. Is important to notice that this limitations of these indicators is particular to this kind of problem.","25d1bf65":"# CreditCard Fraud as an example of a inbalanced dataset\n\n# 1. Introduction\n\nThis notebook is an example of a classification model training and testing on inbalanced data. \n","ead7ec85":"# 4. Setup and Train the Neural Network\n\nThis is an example of the sklearn neural network"}}