{"cell_type":{"26c5ac33":"code","739a3756":"code","9a195d4c":"code","9a22ee96":"code","69efe74b":"code","62ebf867":"code","2acf9cd8":"code","450c60fe":"markdown","fbb96e7f":"markdown","b259f702":"markdown","9c68298f":"markdown","3078d1c2":"markdown","b059428f":"markdown","2407e07c":"markdown","7207960d":"markdown","99d93d47":"markdown","667ee2f4":"markdown"},"source":{"26c5ac33":"# system imports\nimport os\nimport sys\nimport random\nimport collections\n\n# data imports\nimport numpy as np\n\n\n# tensorflow imports\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.python.keras import initializers\nfrom tensorflow.python.keras import regularizers\nfrom tensorflow.python.keras import constraints\nfrom tensorflow.python.training.tracking import data_structures","739a3756":"from tensorflow.python.keras.engine.base_layer import Layer\nfrom tensorflow.python.keras.engine.input_spec import InputSpec\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.ops import gen_cudnn_rnn_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.keras.layers.recurrent import DropoutRNNCellMixin\nfrom tensorflow.python.util import nest\nfrom tensorflow.python.keras import activations\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.keras.utils import generic_utils\nfrom tensorflow.python.keras.utils import tf_utils\n\nfrom tensorflow.python.distribute import distribution_strategy_context as ds_context\nfrom tensorflow.python.eager import context","9a195d4c":"class LSTMCell(Layer):\n    def __init__(self,units):\n        super(LSTMCell, self).__init__()\n        self.units = units\n        \n        # specify some parameters\n        self.activation = activations.get('tanh')\n        self.recurrent_activation = activations.get('hard_sigmoid')\n        self.kernel_initializer = initializers.get('glorot_uniform')\n        self.recurrent_initializer = initializers.get('orthogonal')\n        self.bias_initializer = initializers.get('zeros')\n\n        # two of the requirements to consider this layer a cell\n        self.state_size = data_structures.NoDependency([self.units, self.units])\n        self.output_size = self.units\n\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        \n        # initialize the weights .. remember I am creating four times of weights\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4), name='kernel', initializer=self.kernel_initializer)\n        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units * 4), name='recurrent_kernel', initializer=self.recurrent_initializer)\n\n\n    def call(self, inputs, states, training=None):\n        \n        # h(t-1) and c(t-1)\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        # copy the inputs four times , go to the equations, you will find xt used four times (f, i, c, o)\n        inputs_i = inputs\n        inputs_f = inputs\n        inputs_c = inputs\n        inputs_o = inputs\n        \n        # split the weights into the four neurons, go to the build function, you find I created them all together, this is time to split\n        k_i, k_f, k_c, k_o = array_ops.split(self.kernel, num_or_size_splits=4, axis=1)\n        \n        # multiple the weights by each input for each gate (f, i, c, o), in the equations above, you will find xt multiplied by each their corresponding weights(Wf, Wi, Wc, Wo).\n        x_i = K.dot(inputs_i, k_i)\n        x_f = K.dot(inputs_f, k_f)\n        x_c = K.dot(inputs_c, k_c)\n        x_o = K.dot(inputs_o, k_o)\n\n        # copy h(t-1) four times, in the above equations, h(t-1) is used four times in (f, i, c, o) equations.\n        h_tm1_i = h_tm1\n        h_tm1_f = h_tm1\n        h_tm1_c = h_tm1\n        h_tm1_o = h_tm1\n        \n        \n        # equation i\n        i = self.recurrent_activation(x_i + K.dot(h_tm1_i, self.recurrent_kernel[:, :self.units])) \n        \n        # equation f\n        f = self.recurrent_activation(x_f + K.dot(h_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]))\n        \n        # equation c\n        c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))\n        \n        # equation o\n        o = self.recurrent_activation(x_o + K.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))\n\n        \n\n        # calculate h(t) the output, h(t) will also be the memory state, and c is the carry state  (look above you will see three inputs and three outputs)\n        h = o * self.activation(c)\n        return h, [h, c]\n\n    # one of the requirements to consider this layer a cell\n    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n        return list(_generate_zero_filled_state(batch_size, self.state_size, dtype))\n\n","9a22ee96":"class RNN(Layer):\n    \n    def __init__(self,cell,return_sequences=False,return_state=False):\n        super(RNN, self).__init__()\n        self.cell = cell\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.input_spec = None \n        self.state_spec = None\n\n    def build(self, input_shape):\n        # Get the shape of the input ,many stuff to take care of any error, in the end- We will create two InputSpecs input_spec and state_spec and it will call the build of the LSTMCell which will prepare\n        # it as well by instantiating the weights , check the build() in LSTMCell above.\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        def get_input_spec(shape):\n            input_spec_shape = shape.as_list()\n            input_spec_shape[0] = None\n            input_spec_shape[1] = None\n            return InputSpec(shape=tuple(input_spec_shape))\n\n        def get_step_input_shape(shape):\n            shape = tuple(shape.as_list())\n            return (shape[0],) + shape[2:]\n\n        input_shape = tensor_shape.as_shape(input_shape)\n        if self.input_spec is not None:\n            self.input_spec[0] = get_input_spec(input_shape)\n        else:\n            self.input_spec = [get_input_spec(input_shape)]\n            \n        step_input_shape = get_step_input_shape(input_shape)\n        self.cell.build(step_input_shape)\n\n        if _is_multiple_state(self.cell.state_size):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        self.state_spec = [InputSpec(shape=[None] + tensor_shape.as_shape(dim).as_list()) for dim in state_size]\n        print(\"input_spec\", self.input_spec)\n        print(\"state_spec\", self.state_spec)\n        self.built = True\n\n    def __call__(self, inputs, initial_state=None):\n        inputs, initial_state = _standardize_args(inputs,initial_state)\n        if initial_state is None:\n            return super(RNN, self).__call__(inputs)\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            additional_inputs += initial_state\n            self.state_spec = nest.map_structure(\n              lambda s: InputSpec(shape=K.int_shape(s)), initial_state)\n            additional_specs += self.state_spec\n\n        # additional_inputs can be empty if initial_state is provided\n        # but empty (e.g. the cell is stateless).\n        flat_additional_inputs = nest.flatten(additional_inputs)\n        is_keras_tensor = K.is_keras_tensor(\n            flat_additional_inputs[0]) if flat_additional_inputs else True\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            # The original input_spec is None since there could be a nested tensor\n            # input. Update the input_spec to match the inputs.\n            full_input_spec = generic_utils.to_list(\n              nest.map_structure(lambda _: None, inputs)) + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            self.input_spec = full_input_spec\n            output = super(RNN, self).__call__(full_input)\n            # Remove the additional_specs from input spec and keep the rest. It is\n            # important to keep since the input spec was populated by build(), and\n            # will be reused in the stateful=True.\n            self.input_spec = self.input_spec[:-len(additional_specs)]\n            return output\n        else:\n            return super(RNN, self).__call__(inputs)\n\n        \n    def call(self,inputs,initial_state=None):\n        if (isinstance(inputs, collections.Sequence) and not isinstance(inputs, tuple)):\n            initial_state = inputs[1:]\n            if len(initial_state) == 0:\n                initial_state = None\n            inputs = inputs[0]\n        \n        if initial_state is None:\n            input_shape = array_ops.shape(inputs)\n            initial_state = self.cell.get_initial_state(inputs=None, batch_size=input_shape[0], dtype=inputs.dtype)\n                    \n            if not nest.is_sequence(initial_state): # Keras RNN expect the states in a list, even if it's a single state tensor.\n                initial_state = [initial_state]       \n   \n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n\n        def step(inputs, states):\n            output, new_states = self.cell.call(inputs, states)\n            if not nest.is_sequence(new_states):\n                new_states = [new_states]\n            return output, new_states\n\n        # I stopped here, .. so the loop will be done here by K.rnn (https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e5bf8de410005de06a7ff5393fafdf832ef1d4ad\/tensorflow\/python\/keras\/backend.py#L3809)\n        # to save the states and outputs..........\n        last_output, outputs, states = K.rnn(step,inputs,initial_state)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n            \n        if self.return_state:\n            return generic_utils.to_list(output) + list(states)\n        else:\n            return output","69efe74b":"# some helper functions\ndef _standardize_args(inputs, initial_state):\n    if isinstance(inputs, list):\n        assert initial_state is None\n        if len(inputs) > 1:\n            initial_state = inputs[1:]\n            inputs = inputs[:1]\n        if len(inputs) > 1:\n            inputs = tuple(inputs)\n        else:\n            inputs = inputs[0]\n\n    def to_list_or_none(x):\n        if x is None or isinstance(x, list):\n            return x\n        if isinstance(x, tuple):\n            return list(x)\n        return [x]\n\n    initial_state = to_list_or_none(initial_state)\n    return inputs, initial_state\n\n\ndef _is_multiple_state(state_size):\n    return (hasattr(state_size, '__len__') and\n          not isinstance(state_size, tensor_shape.TensorShape))\n\n\ndef _generate_zero_filled_state(batch_size_tensor, state_size, dtype):\n    def create_zeros(unnested_state_size):\n        flat_dims = tensor_shape.as_shape(unnested_state_size).as_list()\n        init_state_size = [batch_size_tensor] + flat_dims\n        return array_ops.zeros(init_state_size, dtype=dtype)\n\n    if nest.is_sequence(state_size):\n        return nest.map_structure(create_zeros, state_size)\n    else:\n        return create_zeros(state_size)","62ebf867":"input_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nnum_samples = 10000\n\nwith open('..\/input\/french-english-translation-for-seq2seq-model\/fra.txt', 'r', encoding='utf-8') as f:\n    counter = 0\n    for line in f:\n        input_text, target_text,_ = line.split('\\t')     \n        \n        target_text = '\\t' + target_text + '\\n'\n        input_texts.append(input_text)\n        \n        target_texts.append(target_text)\n        \n        for char in input_text:\n            if char not in input_characters:\n                input_characters.add(char)\n        \n        for char in target_text:\n            if char not in target_characters:\n                target_characters.add(char)\n        \n        counter = counter + 1\n        if counter == num_samples :\n            break;\n            \n#  characters and the number of them\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\n\n# maximum number of words in a sentence for both input and output\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\n# indexing i.e. for each character use a number to refer to it\ninput_token_index = {char: i for i, char in enumerate(input_characters)}\ntarget_token_index = {char: i for i, char in enumerate(target_characters)}\n\n# encoder_input_data.shape is (175623, 262, 91) i.e create an array of all the text and pad it to the maximum length\n# for both the encoder and the decoder, each sentence will be represended by 262 words and each word will be represented \n# with 91 characters. e.g. (cat is good), the first three of 262 will be filled everything else will be zero. For the first\n# (cat) only three letters of the 91 will take 1 and everything else is 0.\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n    dtype='float32')\n\n# two decoder data input and target\n\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype='float32')\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype='float32')\n\n\n\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n\nprint('Number of samples:', len(input_texts))\nprint('Number of unique input tokens:', num_encoder_tokens)\nprint('Number of unique output tokens:', num_decoder_tokens)\nprint('Max sequence length for inputs:', max_encoder_seq_length)\nprint('Max sequence length for outputs:', max_decoder_seq_length)\nprint(\"encoder_input_data shape:\",encoder_input_data.shape)\nprint(\"decoder_input_data shape:\",decoder_input_data.shape)\nprint(\"decoder_target_data shape:\",decoder_target_data.shape)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())\n\n","2acf9cd8":"latent_dim = 256\n#from tensorflow.keras.layers import RNN\n# Define an input sequence and process it.\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nprint(\"build() called for the first RNN \")\nencoder = RNN(LSTMCell(latent_dim), return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = Input(shape=(None, num_decoder_tokens)) # Set up the decoder, using `encoder_states` as initial state.\n\nprint(\"build() called for the second RNN \")\ndecoder_lstm = RNN(LSTMCell(latent_dim), return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs) # the last state will be fed to the decoder\n\noptimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001)\nmodel.compile(optimizer, loss='categorical_crossentropy')\nmodel.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n          batch_size = 64,\n          epochs = 20,\n          validation_split=0.2)\n\n\n\n\nencoder_model = Model(encoder_inputs, encoder_states)\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_outputs, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state= decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n\ndecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n\ninput_seq = encoder_input_data[2019:2020]\n# Encode the input as state vectors.\nstates_value = encoder_model.predict(input_seq)\n\n# Generate empty target sequence of length 1.\ntarget_seq = np.zeros((1, 1, num_decoder_tokens))\n# Populate the first character of target sequence with the start character.\ntarget_seq[0, 0, target_token_index['\\t']] = 1.\n\n# Sampling loop for a batch of sequences\n# (to simplify, here we assume a batch of size 1).\nstop_condition = False\ndecoded_sentence = ''\nwhile not stop_condition:\n    output_tokens, h, c = decoder_model.predict(\n        [target_seq] + states_value)\n\n    # Sample a token\n    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n    sampled_char = reverse_target_char_index[sampled_token_index]\n    decoded_sentence += sampled_char\n\n    # Exit condition: either hit max length\n    # or find stop character.\n    if (sampled_char == '\\n' or\n       len(decoded_sentence) > max_decoder_seq_length):\n        stop_condition = True\n\n    # Update the target sequence (of length 1).\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    target_seq[0, 0, sampled_token_index] = 1.\n\n    # Update states\n    states_value = [h, c]\n\nprint('-')\nprint('Input sentence:', input_texts[2019])\nprint('Decoded sentence:', decoded_sentence)","450c60fe":"![rnn.png](attachment:rnn.png)\n\n\nSo, RNN is just a for loop applied on a layer. \nFor example, a layer (function) will take input and output, I will -using rnn- map(loop) this layer on all inputs. \n\nA layer that I can loop over it must support that, and it will be called a cell. \n\nCan the Dense layer be considered a cell? No, because for a layer to be a cell must fullfil the following:\n![cell.png](attachment:cell.png)\n\n\nFor example, instead of writing LSTM(32, return_sequences=True) you can write RNN(LSTMCell(32), return_sequences=True)\nLSTM layer is a wrapper function. So, We will implement the LSTMCell and the RNN loop. [Both inherit Layer](https:\/\/www.tensorflow.org\/guide\/keras\/custom_layers_and_models)","fbb96e7f":"# Import necessary libraries","b259f702":"# Build the model","9c68298f":"# Horray, now use our own layers \u30fd(\u2022\u203f\u2022)\u30ce\nI will build on top of this [kernel](https:\/\/www.kaggle.com\/shujunge\/lstm-seq2seq-with-keras) , It's a seq to seq model for translating from French to English. Here is the running code, but maybe you read additional description there.\n\n# Read the data","3078d1c2":"# Requirements for a custom layer\n\n![call.png](attachment:call.png)\n\n\nSo, we have four methods. **\\__init__()** will inistantiate, **build** will prepare the shape,  when the layer is called as a function when defining the model code inside **\\__call__()** will run. inside it already is **call()** which will run and also it will induce the call() function of the LSTMCell\n# Additional requirements\n1. Every layer should expose (if appropriate) an input_spec attribute: a list of instances of [InputSpec](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/InputSpec) (one per input tensor). It specifies the ndim, dtype and shape of every input to a layer.  This will be done in the build method. Since we have two inputs (input and state) we will have two InputSpecs.","b059428f":"# Step1 -> Create the LSTMCell layer\n\nThe LSTMCell includes four neurons. Weights are multiplied by 4.  The four steps to build an LSTMCell are as following (Keep an eye up on the requirements to consider a layer a cell):\n\n\n\n![step1.png](attachment:step1.png)\n\n![step2.png](attachment:step2.png)\n\n![step3.png](attachment:step3.png)\n\n![step4.png](attachment:step4.png)\n\n\nI ignored bias for now\n","2407e07c":"# Motivation\nThe motivation behind this work is that LSTM is a big thing in deep learning and if I understand it correctly, and also understand the internals of tensorflow behind it, then I think I will understand the tensorflow very well.\n\n# Methodology \nIn this notebook, I am going to create a seq2seq model to translate from French to English. To create the model, I will follow a previous kernel (https:\/\/www.kaggle.com\/shujunge\/lstm-seq2seq-with-keras). But, instead of importing LSTM, I will create it myself. I will not reinvent it because  this will not be useful and why would you follow me, but rather, I will dig into the awesome tensorflow internal code, step after step, and rewrite  exactly every step that happened until I reach the cuda stuff. For example, instead of writing import LSTM , I will find get its code from github and use it instead of importing it.\n\nThe best source to learn LSTM is (https:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/). I will take\/ use it as much as possible. Follow its equations, etc. So read it with this kernel! To avoid plagiarism, all text copied from him, I will put in screenshots.\n\n","7207960d":"## Why is it slow ?\nBecause I used the implementation in tf that is cpu based, Another function is used internally if using gpu called [CuDNNLSTM](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/compat\/v1\/keras\/layers\/CuDNNLSTM). But the implementation we used is also used, in the tf code, if there is dropout or additional specifications by the user that are not implemented yet in the CuDNNLSTM, then the implementation- used in this kernel- is the one used.","99d93d47":"# Step two -> The RNN loop \n\nInstead of writing from tensorflow.keras.layers import RNN, we are going to create it.","667ee2f4":"# What is the difference between \\__call__ and call ?\n\n__call__ makes the class callable, then you use call\n\nFor example, this produces an error. befause it's Layer is not even callable\n\n    class Layer():\n        def __init__(self,x):\n            print('Init parent',x)\n\n        def call(self,z):\n            print('parent called:',z)\n\n    obj = Layer(3)\n    obj(4)\n\nThis works fine\n\n    class Layer():\n        def __init__(self,x):\n            print('Init parent',x)\n\n        def __call__(self, y):\n            print('Parent is being made callable :',y)\n            self.call(y)\n\n        def call(self,z):\n            print('parent now called as function successfuly:',z)\n\n    obj = Layer(3)\n    obj(4)\n\nSo, if \\__call__ is the right way to make a class respond as a function. Why do we use call in custom layers in keras ? Answer is because __call__ is already in the parent class Layer. because we need to load some stuff first (to make it a layer) to load that additional stuff in call() or load your custom created call()"}}