{"cell_type":{"7d0700b2":"code","7a63b6b7":"code","9abe7221":"code","6e32b3d6":"code","0a68dace":"code","6e9ae543":"code","ff5fea5c":"code","952b2bad":"code","39253dbf":"code","ad662172":"code","b80503a7":"code","051122c4":"code","cc857be8":"code","bda4c0f1":"code","b62cd206":"code","44003a14":"code","282a671c":"code","69e238e6":"code","1fafa144":"code","bfc81423":"code","29d7115f":"code","e5889509":"code","c861be91":"code","1b9f174a":"code","2e0def2f":"code","d3ec342f":"code","dbae94c1":"code","e28dc374":"markdown"},"source":{"7d0700b2":"import pandas as pd\nimport numpy as np \nimport math \nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n","7a63b6b7":"dp = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n# age.describe() #decribe column for statiscial value\nY = dp['Survived'].copy()\nX = dp[dp.columns.difference(['Survived'])].copy()","9abe7221":"dp.head()","6e32b3d6":"test.head()","0a68dace":"cols_with_missing = [col for col in dp.columns if dp[col].isnull().any()]\nprint(cols_with_missing)\ncols_with_missing2 = [col for col in test.columns if test[col].isnull().any()]\nprint(cols_with_missing2)","6e9ae543":"dp.groupby(dp['Survived']).count()","ff5fea5c":"X.describe()\n# Age has missing data. We fix it by filling missing data with mean","952b2bad":"combined_data_set = [X,test]","39253dbf":"# female is 0; male is 1\nfor data_set in combined_data_set:\n    data_set['Sex'] = data_set['Sex'].replace({'male':1,'female':0})","ad662172":"for data_set in combined_data_set:\n    #new entry for passengers embarked at S\n    data_set['S'] = np.where(data_set['Embarked'] == 'S', 1,0)\n    #new entry for passengers embarked at C\n    data_set['C'] = np.where(data_set['Embarked'] == 'C', 1,0)\n    #new entry for passengers embarked at Q\n    data_set['Q'] = np.where(data_set['Embarked'] == 'Q', 1,0)\n    #drop the remaining 'Embarked' column\n    data_set.drop('Embarked',axis = 1,inplace = True)","b80503a7":"# Embarked: S is 0; C is 1; Q is 2\n#for data_set in combined_data_set:\n    #data_set['Embarked'] = data_set['Embarked'].replace({'S':0,'C':1,'Q':2})\n    #data_set['Embarked'] = data_set['Embarked'].fillna(1)","051122c4":"# using feature extraction to convert Name into a new feature called 'Titles'\nfor data_set in combined_data_set:\n    data_set['Titles'] = data_set['Name'].str.extract(' ([A-Za-z]+)\\.', expand= False)","cc857be8":"# we created a new feature called Titles: Mr: 0; Miss: 1; Mrs: 2; Others: 3\ntitles_mapping = {'Mr': 0, 'Miss': 1, 'Mrs':2}\nfor data_set in combined_data_set:\n    data_set['Titles'] = data_set['Titles'].map(titles_mapping)\n    data_set['Titles'] = data_set['Titles'].fillna(3)","bda4c0f1":"#X.groupby('Titles')['Age'].transform('max')\n#k = pd.DataFrame({'k':[1,2,3,4,5,6], 'b': ['a','a','b','b','b','b'], 'g':[None,1,1, None,3,4]})\n#k['g'].fillna(k.groupby('b')['g'].transform('median'), inplace = True)","b62cd206":"#creating spearate entries for all titles\nfor data_set in combined_data_set:\n    #new entry for titles starts with Mr\n    data_set['Mr'] = np.where(data_set['Titles'] == 0, 1,0)\n    #new entry for titles starts with Miss\n    data_set['Miss'] = np.where(data_set['Titles'] == 1, 1,0)\n    #new entry for titles starts with Mrs\n    data_set['Mrs'] = np.where(data_set['Titles'] == 2, 1,0)\n    #new entry for other titles\n    data_set['Others'] = np.where(data_set['Titles'] == 3, 1,0)\n    #drop the remaining 'Embarked' column\n    data_set.drop('Titles',axis = 1,inplace = True)","44003a14":"IDs = test['PassengerId']\n# normalize Parch, SibSp and PassengerId\nfor data_set in combined_data_set:\n      data_Parch =(data_set['Parch']-data_set['Parch'].min())\/(data_set['Parch'].max()-data_set['Parch'].min())\n      data_set['Parch'] = data_Parch\n      data_SibSp =(data_set['SibSp']-data_set['SibSp'].min())\/(data_set['SibSp'].max()-data_set['SibSp'].min())\n      data_set['SibSp'] = data_SibSp\n      #data_PassengerId =(data_set['PassengerId']-data_set['PassengerId'].min())\/(data_set['PassengerId'].max()-data_set['PassengerId'].min())\n      #data_set['PassengerId'] = data_PassengerId","282a671c":"# fill the missing Fare based on the Passanger Class\nfor data_set in combined_data_set:\n    data_set['Fare'].fillna(data_set.groupby('Pclass')['Fare'].transform('median'), inplace = True)\nfor data_set in combined_data_set:\n    data_set.loc[data_set['Fare'] <= 17, 'Fare'] = 0    \n    data_set.loc[data_set['Fare'] > 17 & (data_set['Fare'] <= 30),'Fare'] = 1 \n    data_set.loc[data_set['Fare'] > 30 & (data_set['Fare'] <= 100),'Fare'] = 2\n    data_set.loc[data_set['Fare'] > 100 ,'Fare'] = 3\n    #new entry for Cheapest Fare\n    data_set['0_Fare'] = np.where(data_set['Fare'] == 0, 1,0)\n    #new entry for Second Cheapest Fare\n    data_set['1_Fare'] = np.where(data_set['Fare'] == 1, 1,0)\n    #new entry for Third Cheapest Fare\n    data_set['2_Fare'] = np.where(data_set['Fare'] == 2, 1,0)\n    #new entry for Forth Cheapest Fare\n    data_set['3_Fare'] = np.where(data_set['Fare'] == 3, 1,0)\n    #drop the remaining 'Embarked' column\n    data_set.drop('Fare',axis = 1,inplace = True)","69e238e6":"#new entries for Pclass\nfor data_set in combined_data_set:\n    #new entry for passengers holds 1st class\n    data_set['1_class'] = np.where(data_set['Pclass'] == 1, 1,0)\n    #new entry for passengers hold  2nd class\n    data_set['2_class'] = np.where(data_set['Pclass'] == 2, 1,0)\n    #new entry for passengers holds 3rd class\n    data_set['3_class'] = np.where(data_set['Pclass'] == 3, 1,0)\n    #drop the remaining 'Embarked' column\n    data_set.drop('Pclass',axis = 1,inplace = True)","1fafa144":"# convert Cabin to numerical data that we can use","bfc81423":"for data_set in combined_data_set:\n    data_set.drop(['Cabin','Ticket','Name','PassengerId','Age','SibSp','Parch','1_Fare','2_Fare','Q'], axis = 1, inplace = True)\n    #data_set.drop(data_set.columns.difference(['Fare','Age','Sex','Parch']), axis = 1, inplace = True)","29d7115f":"model = RandomForestClassifier(n_estimators = 100)\nmodel.fit(X,Y)","e5889509":"from sklearn.metrics import accuracy_score\n\naccuracy_score(Y, model.predict(X))","c861be91":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nGBayes_clf = GaussianNB()\nGBayes_clf.fit(X, Y)\n\nprint (GBayes_clf.score(X,Y))","1b9f174a":"from sklearn.tree import DecisionTreeClassifier\n    \ntree_clf = DecisionTreeClassifier(max_depth = 5)\ntree_clf.fit(X,Y)\n\nprint(tree_clf.score(X, Y))\n","2e0def2f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\nclf = KNeighborsClassifier(n_neighbors = 13)\nclf.fit(X,Y)\n\nprint(clf.score(X,Y))","d3ec342f":"prediction = model.predict(test)\nprediction = {'PassengerId': IDs, 'Survived': prediction}\npd.DataFrame(prediction).to_csv('prediction_3.csv', index = False)","dbae94c1":"X","e28dc374":"# fill the missing ages with median based on their title and normalize age\nfor data_set in combined_data_set:\n    data_set['Age'].fillna(data_set.groupby('Titles')['Age'].transform('median'), inplace = True)\n\n    data_set.loc[data_set['Age'] <= 7, 'Age'] = 0    \n    data_set.loc[data_set['Age'] > 7 & (data_set['Age'] <= 20),'Age'] = 1 \n    data_set.loc[data_set['Age'] > 20 & (data_set['Age'] <= 40),'Age'] = 2\n    data_set.loc[data_set['Age'] > 40 & (data_set['Age'] <= 60),'Age'] = 3\n    data_set.loc[data_set['Age'] > 60 & (data_set['Age'] <= 80),'Age'] = 4\n    data_set.loc[data_set['Age'] > 80 ,'Age'] = 5\n    \n    # separate ages into four different phrase\n    data_set['0_Age'] = np.where(data_set['Age'] == 0, 1,0)\n    data_set['1_Age'] = np.where(data_set['Age'] == 1, 1,0)\n    data_set['2_Age'] = np.where(data_set['Age'] == 2, 1,0)\n    data_set['3_Age'] = np.where(data_set['Age'] == 3, 1,0)\n    data_set['4_Age'] = np.where(data_set['Age'] == 4, 1,0)\n    data_set['5_Age'] = np.where(data_set['Age'] == 5, 1,0)\n    data_set.drop('Age',axis = 1,inplace = True)"}}