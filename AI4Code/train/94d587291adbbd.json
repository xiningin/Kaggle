{"cell_type":{"5fa4e01f":"code","fb04bf2e":"code","32cdd703":"code","18e7e103":"code","e7cf551f":"code","6cd4cf72":"code","0e2a2d77":"code","e1896d12":"code","1dc452d7":"code","67722478":"code","6621e15f":"code","efa106e1":"code","aea6171b":"code","40342056":"code","60f84b74":"code","3d80e1e8":"code","e18eafe4":"code","e8749d83":"code","63d51907":"code","12b0167a":"code","36cdda26":"markdown","93d5c4cc":"markdown","1044e916":"markdown","32f2a1e2":"markdown","a960331e":"markdown","3fe5252e":"markdown","425555a7":"markdown","3550de23":"markdown","c466f6a8":"markdown","694bef8c":"markdown","60c77059":"markdown","d6db003a":"markdown","149b789e":"markdown","d97c9c7d":"markdown","35840276":"markdown","d2e86e56":"markdown","942b8225":"markdown","68cbd861":"markdown","5b96b6f1":"markdown","67465abe":"markdown","5a7b5ee5":"markdown"},"source":{"5fa4e01f":"!pip install sweetviz\nimport numpy as np\nimport pandas as pd\nimport sweetviz as sv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","fb04bf2e":"data = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","32cdd703":"data.head()","18e7e103":"data.shape","e7cf551f":"data.isnull().sum()  # Checking the number values missing values in each feature ","6cd4cf72":"sns.heatmap(data.isnull(),cmap = 'magma' )","0e2a2d77":"eda = sv.analyze([data, \"data\"],target_feat='Churn')","e1896d12":"eda.show_html('Report.html')","1dc452d7":"data.drop('customerID', axis = 1, inplace = True)  ","67722478":"from sklearn.preprocessing import LabelEncoder                 # Converting categorical churn column into numerical\nle = LabelEncoder()\ndata['Churn'] = le.fit_transform(data.Churn)","6621e15f":"df = pd.get_dummies(data)                           ","efa106e1":"X = df.drop('Churn', axis = 1)                # Defining X and y variables\ny = df['Churn'] ","aea6171b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n","40342056":"# Splitting the data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","60f84b74":"lm = LogisticRegression()\nlm.fit(X_train, y_train)\ny_pred = lm.predict(X_test)\n\nlm_accuracy = round(lm.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', lm_accuracy)\n","3d80e1e8":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nknn_accuracy = round(knn.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', knn_accuracy)","e18eafe4":"svc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\n\nsvc_accuracy = round(svc.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', svc_accuracy)","e8749d83":"dt = DecisionTreeClassifier(max_depth = 5)\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\n\ndt_accuracy = round(dt.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', dt_accuracy)","63d51907":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nrf_accuracy = round(rf.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', rf_accuracy)","12b0167a":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\n\nxgb_accuracy = round(xgb.score(X_test, y_test) * 100, 2)\nprint('Test Accuracy: ', xgb_accuracy)","36cdda26":"**Prediction using Logistic Regression**","93d5c4cc":"![eda.PNG](attachment:eda.PNG)","1044e916":"![eda3.PNG](attachment:eda3.PNG)","32f2a1e2":"# Customer Churn Prediction","a960331e":"**Conclusion**\nFrom the prediction accuracy, Logistic Regression model serves to fit better for the given problem. \n\nThank You for reading!!","3fe5252e":"![association.PNG](attachment:association.PNG)","425555a7":"So we have successfully read the data. Now let's Check for the missing values and make our hands dirty in doing some data preprocessing. \n","3550de23":"**Prediction using Random Forest**","c466f6a8":"![eda2.PNG](attachment:eda2.PNG)","694bef8c":"**Prediction using Boosting Technique(Xgboost)**","60c77059":"Great!!!\nWe don't have missing values in any column. \nNow we can proceed further to perform EDA\nThere is a beautiful library to visualize our features and see the characteristics of each feature. ","d6db003a":"**Prediction using Decision Tree**","149b789e":"![churn.png](attachment:churn.png)","d97c9c7d":"![eda1.PNG](attachment:eda1.PNG)","35840276":"**Reading Data**","d2e86e56":"**Importing Libraries**","942b8225":"**Prediction using KNN**","68cbd861":"**Prediction using Support Vector Classifier**","5b96b6f1":"**Importing necessary libraries for Prediction**","67465abe":"**Customer churn** is a situation when subscribers or customers stop taking service from the campany. Whether a customer will switch to another service provider or not is a problem which comes under classification technique. We have various classification techniques to predict customer churn.\n\nSo lets get started!!!","5a7b5ee5":"Since CustomerID need not to be included for the prediction, so we can drop it."}}