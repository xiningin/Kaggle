{"cell_type":{"f28f5caf":"code","dbeae8c1":"code","b06d7023":"code","aa22e794":"code","72c5844b":"code","1fa063c6":"code","a465f273":"code","af5b0d33":"code","57a09e2c":"code","11c132b6":"markdown","9b676b6b":"markdown","64c4465c":"markdown","9d2eb101":"markdown","fc3b7c99":"markdown","f260a620":"markdown","cade76a0":"markdown","12f78795":"markdown","f728ad87":"markdown","497bf961":"markdown","68e90384":"markdown","a3bee545":"markdown","6969a99b":"markdown","a98aae56":"markdown","845e2db3":"markdown"},"source":{"f28f5caf":"# importing libraries\nimport numpy as np\nimport pandas as pd \nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable","dbeae8c1":"# importing dataset\nmovies = pd.read_csv('\/kaggle\/input\/movie-recommender-dataset\/ml-1m\/ml-1m\/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nusers = pd.read_csv('\/kaggle\/input\/movie-recommender-dataset\/ml-1m\/ml-1m\/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nratings = pd.read_csv('\/kaggle\/input\/movie-recommender-dataset\/ml-1m\/ml-1m\/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')","b06d7023":"# creating train and test sets\ntraining_set = pd.read_csv('\/kaggle\/input\/movie-recommender-dataset\/ml-100k\/ml-100k\/u1.base', delimiter = '\\t')\ntraining_set = np.array(training_set, dtype = 'int')\ntest_set = pd.read_csv('\/kaggle\/input\/movie-recommender-dataset\/ml-100k\/ml-100k\/u1.test', delimiter = '\\t')\ntest_set = np.array(test_set, dtype = 'int')","aa22e794":"# getting the number of users and movies\nnb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\nnb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\nprint('no of users = ' + str(nb_users))\nprint('no of movies = ' + str(nb_movies))","72c5844b":"# converting the data into an array with users as lines and movies as columns\ndef conv(data):\n    new_data = []\n    for id_user in range(1, nb_users + 1):\n        id_movies = data[:, 1][data[:, 0] == id_user]\n        id_ratings = data[:, 2][data[:, 0] == id_user]\n        ratings = np.zeros(nb_movies)\n        ratings[id_movies - 1] = id_ratings\n        new_data.append(list(ratings))\n    return new_data\n\n# converting test and train sets\ntraining_set = conv(training_set)\ntest_set = conv(test_set)","1fa063c6":"# converting the data into Torch tensors\ntraining_set = torch.FloatTensor(training_set)\ntest_set = torch.FloatTensor(test_set)","a465f273":"# creating the architecture of the Neural Network (SAE in our case is considered a directed neural network)\nclass SAE(nn.Module):\n    def __init__(self):\n        super(SAE, self).__init__()\n        self.fc1 = nn.Linear(nb_movies, 20)\n        self.fc2 = nn.Linear(20, 10)\n        self.fc3 = nn.Linear(10, 20)\n        self.fc4 = nn.Linear(20, nb_movies)\n        self.activation = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        x = self.activation(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\nsae = SAE()\ncriterion = nn.MSELoss()\noptimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)","af5b0d33":"# training the SAE\nnb_epoch = 200\nfor epoch in range(1, nb_epoch + 1):\n    train_loss = 0\n    s = 0.\n    for id_user in range(nb_users):\n        input = Variable(training_set[id_user]).unsqueeze(0)\n        target = input.clone()\n        if torch.sum(target.data > 0) > 0:\n            output = sae(input)\n            target.require_grad = False\n            output[target == 0] = 0\n            loss = criterion(output, target)\n            mean_corrector = nb_movies\/float(torch.sum(target.data > 0) + 1e-10)\n            loss.backward()\n            train_loss += np.sqrt(loss.data * mean_corrector)\n            s += 1.\n            optimizer.step()\n    print('epoch: ' + str(epoch) + ' train_loss: ' + str(train_loss \/ s))","57a09e2c":"# testing the SAE\ntest_loss = 0\ns = 0.\nfor id_user in range(nb_users):\n    input = Variable(training_set[id_user]).unsqueeze(0)\n    target = Variable(test_set[id_user])\n    if torch.sum(target.data > 0) > 0:\n        output = sae(input)\n        target.require_grad = False\n        output[(target == 0).unsqueeze(0)] = 0\n        loss = criterion(output, target)\n        mean_corrector = nb_movies \/ float(torch.sum(target.data > 0) + 1e-10)\n        test_loss += np.sqrt(loss.data * mean_corrector)\n        s += 1.\n        print('test loss: '+ str(test_loss \/ s))","11c132b6":"The final loss on the test set is ~0.95 which proves to be an incredible result for our system!","9b676b6b":"# Importing dataset","64c4465c":"*Thank you for your attention! :)*","9d2eb101":"# Creating train and test sets","fc3b7c99":"# Training the SAE","f260a620":"More information about the **torch.nn** module can be found [here](https:\/\/pytorch.org\/docs\/stable\/nn.html).","cade76a0":"# Creating the arhitecture of the SAE","12f78795":"We are going to use \n* NumPy\n* Pandas\n\nand **PyTorch** for building the SAE (Sparse AutoEncoder)\n    More information about Sparse Autoencoders can be found [here](https:\/\/web.stanford.edu\/class\/cs294a\/sparseAutoencoder.pdf).","f728ad87":"# Importing libraries","497bf961":"# Converting the data into an array with users as lines and movies as columns","68e90384":"More information about Torch tensors and how they work can be found [here](https:\/\/pytorch.org\/docs\/stable\/tensors.html).","a3bee545":" \n# This notebook comes as a helping hand to anyone interested in building or learning how to build a **movie recommender system using AutoEncoders**! Enjoy!","6969a99b":"# Getting number of users and movies","a98aae56":"# Testing the SAE","845e2db3":"# Converting the data into Torch tensors"}}