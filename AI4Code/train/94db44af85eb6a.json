{"cell_type":{"73a90796":"code","7ab66930":"code","7761bac8":"code","41bc84f5":"code","f5b450f0":"code","d735c1b8":"code","8eeeb2d2":"code","4c8cc6c6":"code","d07c92e3":"code","c85a9a30":"code","4a4ec9d4":"code","976ad683":"code","cd309b43":"code","447cce52":"code","589150bc":"code","e5d20d68":"code","ab093515":"code","ade56d36":"code","53e40fc8":"code","35832cdf":"code","7873699b":"code","3f74b7ff":"code","04d09eb6":"code","5570bcaf":"markdown"},"source":{"73a90796":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ab66930":"df_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","7761bac8":"df_train.head()","41bc84f5":"X = df_train.iloc[:, 1:].to_numpy()\ny = df_train['label']","f5b450f0":"df_test.head()","d735c1b8":"test = df_test.to_numpy()\n\n# n\u00e3o temos o target para o teste","8eeeb2d2":"X = X \/ 255\ntest = test \/ 255","4c8cc6c6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=1)","d07c92e3":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(hidden_layer_sizes=(100,), solver='lbfgs', \n                    max_iter = 2000, random_state=43)\n\nclf.fit(X_train, y_train)\n\nprint(\"Training set score: %f\" % clf.score(X_train, y_train))\nprint(\"Test set score: %f\" % clf.score(X_test, y_test))","c85a9a30":"test.shape","4a4ec9d4":"results1 = clf.predict(test)\nresults1 = pd.Series(results1, name=\"Label\")\noutput1 = pd.concat([pd.Series(range(1,28001), name = 'ImageId'), results1], axis = 1)\noutput1","976ad683":"output1.to_csv('submission.csv', index=False)","cd309b43":"mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, alpha=1e-4,\n                    solver='sgd', verbose=10, random_state=1,\n                    learning_rate_init=.1)\n\nmlp.fit(X_train, y_train)\n\nprint(\"Training set score: %f\" % mlp.score(X_train, y_train))\nprint(\"Test set score: %f\" % mlp.score(X_test, y_test))","447cce52":"import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","589150bc":"X_keras = X.reshape(X.shape[0], 28, 28, 1)\ntest_keras = test.reshape(test.shape[0], 28, 28, 1)","e5d20d68":"y_keras = keras.utils.to_categorical(y)\ny_keras","ab093515":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_keras, y_keras, test_size = 0.1, random_state=1)","ade56d36":"num_classes = 10\ninput_shape = (28, 28, 1)\n\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()","53e40fc8":"batch_size = 128\nepochs = 50\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","35832cdf":"score = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","7873699b":"results = model.predict(test_keras) ","3f74b7ff":"results = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\noutput = pd.concat([pd.Series(range(1,28001), name = 'ImageId'), results], axis = 1)\noutput","04d09eb6":"output.to_csv('submission.csv', index=False)","5570bcaf":"Vamos separar em features e target"}}