{"cell_type":{"529a952f":"code","95b57eec":"code","5a8ac5d6":"code","e779c033":"code","72af8f56":"code","a58f841c":"code","b1bb6d9f":"code","9b475cf8":"code","83b6b4de":"code","1def35d0":"code","cd9d378b":"code","1961e164":"code","ecb8440b":"code","521ec4c0":"code","7b3ce991":"code","7553c69c":"code","8d882155":"markdown","8dc6071b":"markdown","9b4c7867":"markdown","0b699bdb":"markdown","72fb79d1":"markdown","005dbbe0":"markdown","704c3762":"markdown","1f2a2a97":"markdown","16e08c82":"markdown","a85e9b0d":"markdown","aebaeff8":"markdown","1880bbdf":"markdown"},"source":{"529a952f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95b57eec":"import pandas as pd","5a8ac5d6":"df = pd.read_csv('..\/input\/titanic-machine-learning-from-disaster\/train.csv')","e779c033":"df.head()","72af8f56":"df.isnull().sum()","a58f841c":"df[df['Embarked'].isnull()]","b1bb6d9f":"import numpy as np\ndf['cabin_null'] = np.where(df['Cabin'].isnull(),1,0)\n\n## find the percentage of null values\ndf['cabin_null'].mean()","9b475cf8":"df.groupby(['Survived'])['cabin_null'].mean()","83b6b4de":"df = pd.read_csv('..\/input\/titanic-machine-learning-from-disaster\/train.csv' , usecols=['Age' , 'Fare' , 'Survived'])\ndf.head()","1def35d0":"## Lets see the percentage of missing values\n\ndf.isnull().mean()","cd9d378b":"def impute_nan(df, variable, median):\n    df[variable + \"_median\"] = df[variable].fillna(median)","1961e164":"median = df.Age.median()\nmedian","ecb8440b":"impute_nan(df , 'Age', median)\ndf.head()","521ec4c0":"print(df['Age'].std())\nprint(df['Age_median'].std())\ndf.head()","7b3ce991":"import matplotlib.pyplot as plt\n%matplotlib inline","7553c69c":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde' , ax=ax)\ndf.Age_median.plot(kind='kde', ax=ax, color='red')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","8d882155":"MEN - hide their salary\nWOMEN - hide their age\nIn a survey where there is a column of MEN , WOMEN , their AGES and SALARIES","8dc6071b":"#### Types of missing data : \n##### 1. Missing Completely at Random, MCAR:\nA variable is missing completely at random if the probability of being missing is the same for all observations. When data is MCAR, there is absolutely no relationship between the data missing and any other values, observed or missing , within the dataset. In other words, those missing data points are a random subset of the data. There is nothing systematic going on that makes some data more likely to be missing than other . \n\nIf values for observations are completely missing at random, then disregarding those cases would not bias the inferences made. ","9b4c7867":"### Continuous Data","0b699bdb":"#### 2. Missing Data not at random (MNAR) : Systematic Missing Data \nThere is absolutely a relationship between the data missing and any other values, observed or missing , within the dataset.","72fb79d1":"### Advantages and Disadvantages of Mean \/ Median \/ Imputation\n\n#### Advantages\n1. Easy to implement(Robust to outliers)\n2. Faster way to obtain the complete dataset\n\n#### Disadvantages \n\n1. Change or distortion in the original variance \n2. Impacts Correlation","005dbbe0":"Why are missing values there in data ?\n-> Suppose there is a survey - Depression Survey : While entering information sometimes people skips some quetions\/ hesitate to put down the information or they enter something wrong which inturn gets to be an error. \n\n(Note : Data Science Projects -> Dataset should be collected from multiple sources)\n\nData that will be missing :\n1. Continuous Data\n2. Categorical Data","704c3762":"## Lifecycle of a Data Science Projects\n1. Data Collection Strategy -- from company side, 3rd party API's , Surveys\n2. Feature Engineering -- Handling Missing Values (First thing to do as soon as the data is collected) ","1f2a2a97":"Embarked is a true example of MCAR !","16e08c82":"#### 3.Missing At Random(MAR):","a85e9b0d":"## Missing Values - Feature Engineering","aebaeff8":"#### Mean \/ Median \/ Mode Imputation\n\nWhen should we apply ?\nMean \/ Median imputation has the assumption that the data is missing completely at random (MCAR) .\nSolve this by replacing the most frequent occurance of the variables. ","1880bbdf":"### All the techniques of handling missing values\n\n1. Mean \/ Median \/ Mode replacement\n2. Random Sample Imputation\n3. Capturing NAN values with a new feature\n4. End of Distribution imputation\n5. Arbitrary Imputation\n6. Frequent Categories Imputation"}}