{"cell_type":{"f1ff6e4f":"code","bab71bde":"code","872a1998":"code","137cb1e7":"code","60ca6bf9":"code","c0f46dae":"code","ae8bd9cd":"code","cdb1fae2":"code","9db2331a":"code","64925910":"code","23821618":"code","b9495c17":"code","2074829c":"code","a0087f7f":"code","adcc70d9":"code","0f633b76":"code","ce611ac1":"code","6bc6305f":"code","7a0b949c":"code","32ce4126":"code","9bf6ab73":"code","401efec8":"code","08636c04":"code","9bd63ca9":"code","aabaa81c":"code","f5fa57c5":"code","0a8b3779":"code","bc540adf":"code","38a25174":"code","7fba5067":"code","a93c0df1":"code","89a45a54":"code","d9bd5705":"code","98753155":"code","04e0e67e":"code","1aa76d9d":"code","3d14a962":"code","84b718ad":"code","c06f0e96":"code","3b9b15d9":"code","a2041b0d":"code","06a07697":"code","0fb5c610":"code","8d27490b":"code","af96cac0":"code","24a8ce1d":"code","67964953":"code","7ad7afc9":"code","9fc62b61":"code","b69ac05f":"code","ca0b81f4":"code","ab5acfe3":"code","936f84b0":"code","2b9d55de":"code","09caa832":"code","0c97a4f2":"markdown","121f1701":"markdown","11af6f79":"markdown","170a4d04":"markdown","60d2af89":"markdown","baa60092":"markdown","f6503e09":"markdown","35de2b6d":"markdown","7f4256ae":"markdown","3e82d4aa":"markdown","45c345b8":"markdown","1a3a0f75":"markdown","c513485e":"markdown","e1c912ab":"markdown","29da21c7":"markdown","204318d7":"markdown","8bf34e98":"markdown","b0c2c1f4":"markdown","03924387":"markdown","38c4a6ab":"markdown","865041d8":"markdown","c7fba2f6":"markdown","e9ee568d":"markdown","9d92a9aa":"markdown","8fca874f":"markdown","2431e754":"markdown","8efe89b1":"markdown","85ef7e80":"markdown","b81c31c9":"markdown","7776f3f2":"markdown","9123594e":"markdown","2b1be04b":"markdown","8fe5d08e":"markdown","ec187517":"markdown","1d092f06":"markdown","fc8ec673":"markdown","fa5d5d78":"markdown","ebd93a55":"markdown","93723279":"markdown","198409ed":"markdown","0df2d590":"markdown"},"source":{"f1ff6e4f":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns  \n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bab71bde":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n\ntrain_data.columns","872a1998":"train_data.head()","137cb1e7":"train_data.info()","60ca6bf9":"train_data.describe()","c0f46dae":"def outlier_detect(feature, data):\n    outlier_index = []\n\n    for each in feature:\n        Q1 = np.percentile(data[each], 25)\n        Q3 = np.percentile(data[each], 75)\n        IQR = Q3 - Q1\n        min_quartile = Q1 - 1.5*IQR\n        max_quartile = Q3 + 1.5*IQR\n        outlier_list = data[(data[each] < min_quartile) | (data[each] > max_quartile)].index\n        outlier_index.extend(outlier_list)\n        \n    outlier_index = Counter(outlier_index)\n    #If there are three or more outlier data features we must delete them. (n)\n    outlier_data = list(i for i, n in outlier_index.items() if n > 3)\n    return outlier_data","ae8bd9cd":"outlier_data = outlier_detect([\"Age\",\"SibSp\",\"Parch\",\"Fare\"], train_data)\ntrain_data.loc[outlier_data]\n","cdb1fae2":"train_data = train_data.drop(outlier_data, axis=0).reset_index(drop=True)","9db2331a":"data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)","64925910":"sns.countplot('Survived',data=train_data )\n","23821618":"data.describe()","b9495c17":"data[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean()","2074829c":"sns.factorplot(x=\"Sex\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","a0087f7f":"sns.factorplot(x=\"Pclass\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","adcc70d9":"sns.factorplot(x=\"Embarked\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","0f633b76":"sns.factorplot(x=\"SibSp\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","ce611ac1":"sns.factorplot(x=\"Parch\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","6bc6305f":"g = sns.FacetGrid(data, row=\"Survived\")\ng.map(sns.distplot, \"Age\", bins=25)\nplt.show()","7a0b949c":"g = sns.FacetGrid(data, row=\"Survived\")\ng.map(sns.distplot, \"Fare\", bins=25)\nplt.show()","32ce4126":"#data[\"Sex\"] = [0 if i == \"male\" else 1 for i in data[\"Sex\"]]\ndata['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n# male: 0, famela: 1\nsns.heatmap(data[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\",\"Embarked\", \"Survived\"]].corr(), annot = True)\nplt.show()","9bf6ab73":"data.columns[data.isnull().any()]","401efec8":"data.isnull().sum()","08636c04":"data[data[\"Fare\"].isnull()]","9bd63ca9":"data[\"Fare\"] = data[\"Fare\"].fillna(np.mean(data[((data[\"Pclass\"]==3) & (data[\"Embarked\"]==0))][\"Fare\"]))\ndata[data[\"Fare\"].isnull()]","aabaa81c":"data[data[\"Embarked\"].isnull()]","f5fa57c5":"data[\"Embarked\"] = data[\"Embarked\"].fillna(1)\ndata[data[\"Embarked\"].isnull()]","0a8b3779":"data[data[\"Age\"].isnull()]","bc540adf":"data_age_nan_index = data[data[\"Age\"].isnull()].index\nfor i in data_age_nan_index:\n    mean_age = data[\"Age\"][(data[\"Pclass\"]==data.iloc[i][\"Pclass\"])].median()\n    data[\"Age\"].iloc[i] = mean_age","38a25174":"data[\"Family\"] = data[\"SibSp\"] + data[\"Parch\"]\nsns.factorplot(x=\"Family\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","7fba5067":"data[\"Alone\"] = [1 if i == 0 else 0 for i in data[\"Family\"]]\ndata[\"Family\"].replace([0,1,2,3,4,5,6,7,10], [0,1,1,1,0,2,0,2,2], inplace=True)\ndata.head()","a93c0df1":"data['Title']=data.Name.str.extract('([A-Za-z]+)\\.')","89a45a54":"sns.countplot(data[\"Title\"])\nplt.xticks(rotation = 90)\nplt.show()","d9bd5705":"data['Title'].replace(['Mme','Ms','Mlle','Lady','Countess','Dona','Dr','Major','Sir','Capt','Don','Rev','Col', 'Jonkheer'],['Miss','Miss','Miss','Mrs','Mrs','Mrs','Mr','Mr','Mr','Mr','Mr','Other','Other','Other'], inplace=True)","98753155":"sns.countplot(data[\"Title\"])\nplt.show()","04e0e67e":"sns.factorplot(x=\"Title\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","1aa76d9d":"data[\"Title\"].replace([\"Mr\",\"Mrs\",\"Miss\",\"Master\",\"Other\"], [1,2,2,3,1], inplace=True)\n","3d14a962":"data['Age_Limit']=pd.cut(data['Age'], 5)\ndata.groupby(['Age_Limit'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","84b718ad":"data['Age_Limit'] = LabelEncoder().fit_transform(data['Age_Limit'])\n","c06f0e96":"data['Fare_Limit']=pd.qcut(data['Fare'],4)\ndata.groupby(['Fare_Limit'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","3b9b15d9":"data['Fare_Limit'] = LabelEncoder().fit_transform(data['Fare_Limit'])\n","a2041b0d":"sns.factorplot(x=\"Fare_Limit\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","06a07697":"sns.heatmap(data[[\"Cabin\",\"Pclass\",\"Embarked\",\"Sex\",\"Age\",\"Age_Limit\",\"Fare_Limit\", \"Title\",\"Family\", \"Survived\"]].corr(), annot = True)\nplt.show()","0fb5c610":"data['Age']=data['Age'].astype(int)\n\ndata.drop(labels=[\"SibSp\",\"Parch\",\"Cabin\",\"Fare\",\"Age\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace = True)\ndata.head()","8d27490b":"data = pd.get_dummies(data,columns=[\"Pclass\"])\ndata = pd.get_dummies(data,columns=[\"Embarked\"])\ndata = pd.get_dummies(data,columns=[\"Family\"])\ndata = pd.get_dummies(data,columns=[\"Age_Limit\"])\ndata = pd.get_dummies(data,columns=[\"Fare_Limit\"])\ndata = pd.get_dummies(data,columns=[\"Title\"])\n\ndata.head()","af96cac0":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","24a8ce1d":"if len(data) == (len(train_data) + len(test_data)):\n    print(\"success\")","67964953":"test = data[len(train_data):]\ntest.drop(labels=\"Survived\", axis=1, inplace=True)","7ad7afc9":"train = data[:len(train_data)]\nX_train = train.drop(labels = \"Survived\", axis=1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n","9fc62b61":"log_reg = LogisticRegression(random_state=42)\nlog_reg.fit(X_train, y_train)\nprint(\"Accuracy: \", log_reg.score(X_test,y_test))","b69ac05f":"rf_reg = RandomForestClassifier(random_state=42)\nrf_reg.fit(X_train, y_train)\nprint(\"Accuracy: \", rf_reg.score(X_test,y_test))","ca0b81f4":"svm_clsf = SVC()\nsvm_clsf.fit(X_train, y_train)\nprint(\"Accuracy: \", svm_clsf.score(X_test,y_test))","ab5acfe3":"best_knn = []\nfor n in range(1,12):\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train, y_train)\n    best_knn.insert(n, knn.score(X_test,y_test))\nbest_knn\n","936f84b0":"knn_clsf = KNeighborsClassifier(n_neighbors=8)\nknn_clsf.fit(X_train, y_train)\nprint(\"Accuracy: \", knn_clsf.score(X_test,y_test))","2b9d55de":"voting_classfication = VotingClassifier(estimators = [('knn', knn_clsf),('lg', log_reg), ('rfg', rf_reg), ('svc', svm_clsf)], voting=\"hard\", n_jobs=-1)\nvoting_classfication.fit(X_train, y_train)\nprint(\"Accuracy: \", voting_classfication.score(X_test,y_test))","09caa832":"test_result = pd.Series(voting_classfication.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_data[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission.csv\", index = False)","0c97a4f2":"###\u00a0Logistic Regression","121f1701":"<a id='3'><\/a><br>\n## 2-Combining Train and Test Data\n\n\n* Train_data and test_data are combined so that data is obtained. \n","11af6f79":" ### Age - Survived","170a4d04":"<a id='10'><\/a><br>\n## 2-Fill Missing Value\n\n*\u00a0Cabin has 1007 missing value\n*\u00a0Age has 256 missing value\n*\u00a0Embarked has 2 missing value\n*\u00a0Fare has 1 missing value\n\nNot: Survived has 418 missing value (only test value)","60d2af89":"<a id='5'><\/a><br>\n# Chapter:2 Data Analysis\n\n* Feature Analysis\n* Corelation Between Features\n\n","baa60092":"<a id='6'><\/a><br>\n## 1- Feature Analysis\n\n* Sex - Survived\n* Pclass - Survived\n* Embarked - Survived\n* SibSp - Survived\n* Parch - Survived\n* Age - Survived\n* Fare - Survived","f6503e09":"<a id='9'><\/a><br>\n## 1-Find Missing Value\n\n* Age, Fare and Cabin have missing value. Therefore we are looking at the correlation matrix.\n\nCorrelation Matrix\n* Pclass is associated with Fare.\n* Embarked is not associated with any feature.\n* Pclass and SibSp are associated with Age.","35de2b6d":"<a id='18'><\/a><br>\n##\u00a02-Classificaiton Methods\n\n\n* Logistic Regression\n* Random Forest Regression\n* Support Vector Machine (SVM)\n* K-Nearest Neighbors (KNN)","7f4256ae":"### Age Limit","3e82d4aa":"<a id='12'><\/a><br>\n##\u00a01-New - Feature\n* Alone and Family\n* Title (Name)\n* Age Limit\n* Fare Limit","45c345b8":"**Outcome**    \n\n* Sex, Pclass, Fare and Embarked are associated with Survived. \n\n\n","1a3a0f75":"###\u00a0Alone and Family \n* SibSp + Parch = family","c513485e":"###\u00a0Name - Title","e1c912ab":" <a id='2'><\/a><br>\n## 1-Outlier Detection\n\n\n![oie_384549KoGQkTap.png](attachment:oie_384549KoGQkTap.png)\n\n* Q1 = 1.Quartile 25%\n* Q2 = 2.Quartile 50% (median)\n* Q3 = 3.Quartile 75%\n* IQR = Q3 - Q1\n* Outlier data = (Q1 - 1.5 IQR ) U (Q3 + 1.5 IQR)\n\n","29da21c7":"###\u00a0Fare Fill Value\n\nPclass is associated with Fare.","204318d7":"<a id='8'><\/a><br>\n# Chapter-4 Data Engineering\n\n* New Feature\n* Edit Feature\n* Drop Feature\n* Normalization","8bf34e98":"<a id='16'><\/a><br>\n#\u00a0Chapter:5 Modeling","b0c2c1f4":"###\u00a0Age Fill Value\n\nPclass and SibSp are associated with Age.","03924387":"<a id='7'><\/a><br>\n## 2-Correlation Between Features","38c4a6ab":"<a id='8'><\/a><br>\n# Chapter-3 Missing Value\n\n* Find Missing Value\n* Fill Missing Value\n","865041d8":"### Survived","c7fba2f6":"### Fare Limit","e9ee568d":"###\u00a0KNN\n\nelbow -> n:8 (the article will be updated)","9d92a9aa":"<a id='19'><\/a><br>\n##\u00a03-\u00a0Ensemble Modeling","8fca874f":"<a id='20'><\/a><br>\n## 4-Result\n\nWe choose the ensemble model because it works best.","2431e754":"###\u00a0Random Forest Regression","8efe89b1":"<a id='14'><\/a><br>\n##\u00a03 - One Hot Encoding","85ef7e80":" ### Fare - Survived","b81c31c9":"###\u00a0Embarked Fill Value\n\nEmbarked is not associated with any feature.\n\nS = 0,  C = 1 and Q = 2","7776f3f2":"### Parch - Survived","9123594e":"<a id='1'><\/a><br>\n# Chapter:1 Data Load And Check","2b1be04b":"### Correlation Matrix","8fe5d08e":"### Sex - Survived\n\nFemale are more likely to survive than male.","ec187517":"<a id='4'><\/a><br>\n## 3-Feature Analysis\n\nObject\n1. Name        : \n1. Sex         : male and female\n1. Ticket      : ticket number\n1. Cabin       : cabin category\n1. Embarked    : port C, Q and S\n\nInt64\n1. PassengerId : unique id number\n1. Survived    : 0 -> died ,1-> survived\n1. Pclasss     : 1, 2 and 3 \n1. SibSp       : number of siblings\/spouse\n1. Parch       : number of parent\/children\n\nFloat64\n1. Age         : age of passenger\n1. Fare        : price of the ticket","1d092f06":"### SibSp - Survived","fc8ec673":"<a id='13'><\/a><br>\n##\u00a02- Drop Features\n* Ticket, Cabin, Name, PassengerId and Age are deleted according to the result of the correlation matrix.","fa5d5d78":"<font color='red'>\n\n#\u00a0Titanic EDA and Classification Project  (TOP %5)\n    \n<font color='black'>\n\nContent of The Titanic Exploratory Data Analysis\n1. [Chapter-1 Data Load and Check](#1)\n    * [1-Outlier Detection](#2)\n    * [2-Joining Test and Train Data](#3)\n    * [3-Feature Check](#4)\n1. [Chapter-2 Data Analysis](#5)\n    * [1-Feature Analysis](#6)\n    * [2-Correlation Between Feature](#7)\n1. [Chapter-3 Missing Value](#8)\n    * [1-Find Missing Value](#9)\n    * [2-Fill Missing Value](#10)\n1. [Chapter-4 Data Engineering](#11)\n    * [1-New Feature](#12)\n    * [2-Drop Feature](#13)\n    * [3-One Hot Encoding](#14)\n1. [Chapter-5 Modeling](#16)\n    * [1-Train-Test Split](#17)\n    * [2-Classification Methods](#18)\n    * [3-Ensemble Modeling](#19)\n    * [4-Result](#20)\n\n\n   \n    \n    \n    \n    \n\n\n\n    \n    \n    ","ebd93a55":"### Support Vector Machine (SVM)","93723279":"<a id='17'><\/a><br>\n##\u00a01-Train Test Split","198409ed":"### Pclass - Survived","0df2d590":"### Embarked - Survived"}}