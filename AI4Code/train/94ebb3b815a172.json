{"cell_type":{"f575f48f":"code","0868360e":"code","08fe0731":"code","8533ccd7":"code","b9a89bde":"code","c1fef8e8":"code","31e3a2ee":"code","72b9a2ff":"code","82e434ac":"code","f598bade":"code","d6b74acc":"code","7211fcea":"code","a0c8e3c6":"code","2cb0488b":"code","26be1ae7":"code","ce884cbc":"markdown","fde3d8de":"markdown","8e71630e":"markdown","d22de7c8":"markdown","67b864df":"markdown","5d205cf3":"markdown","3b13e1c8":"markdown","4d793dd8":"markdown","390b377f":"markdown","bc3bf29b":"markdown","137e8ba7":"markdown","e733a4c3":"markdown","f5f7b3d7":"markdown","1e8651d3":"markdown","ba3be2e5":"markdown","a9c9a352":"markdown","07add7de":"markdown","a44e95c8":"markdown"},"source":{"f575f48f":"!pip install transforms3d","0868360e":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom transforms3d.euler import euler2mat\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nclass Joint:\n  def __init__(self, name, direction, length, axis, dof, limits):\n    \"\"\"\n    Definition of basic joint. The joint also contains the information of the\n    bone between it's parent joint and itself. Refer\n    [here](https:\/\/research.cs.wisc.edu\/graphics\/Courses\/cs-838-1999\/Jeff\/ASF-AMC.html)\n    for detailed description for asf files.\n\n    Parameter\n    ---------\n    name: Name of the joint defined in the asf file. There should always be one\n    root joint. String.\n\n    direction: Default direction of the joint(bone). The motions are all defined\n    based on this default pose.\n\n    length: Length of the bone.\n\n    axis: Axis of rotation for the bone.\n\n    dof: Degree of freedom. Specifies the number of motion channels and in what\n    order they appear in the AMC file.\n\n    limits: Limits on each of the channels in the dof specification\n\n    \"\"\"\n    self.name = name\n    self.direction = np.reshape(direction, [3, 1])\n    self.length = length\n    axis = np.deg2rad(axis)\n    self.C = euler2mat(*axis)\n    self.Cinv = np.linalg.inv(self.C)\n    self.limits = np.zeros([3, 2])\n    for lm, nm in zip(limits, dof):\n      if nm == 'rx':\n        self.limits[0] = lm\n      elif nm == 'ry':\n        self.limits[1] = lm\n      else:\n        self.limits[2] = lm\n    self.parent = None\n    self.children = []\n    self.coordinate = None\n    self.matrix = None\n\n  def set_motion(self, motion):\n    if self.name == 'root':\n      self.coordinate = np.reshape(np.array(motion['root'][:3]), [3, 1])\n      rotation = np.deg2rad(motion['root'][3:])\n      self.matrix = self.C.dot(euler2mat(*rotation)).dot(self.Cinv)\n    else:\n      idx = 0\n      rotation = np.zeros(3)\n      for axis, lm in enumerate(self.limits):\n        if not np.array_equal(lm, np.zeros(2)):\n          rotation[axis] = motion[self.name][idx]\n          idx += 1\n      rotation = np.deg2rad(rotation)\n      self.matrix = self.parent.matrix.dot(self.C).dot(euler2mat(*rotation)).dot(self.Cinv)\n      self.coordinate = self.parent.coordinate + self.length * self.matrix.dot(self.direction)\n    for child in self.children:\n      child.set_motion(motion)\n\n  def draw(self):\n    joints = self.to_dict()\n    fig = plt.figure()\n    ax = Axes3D(fig)\n\n    ax.set_xlim3d(-50, 10)\n    ax.set_ylim3d(-20, 40)\n    ax.set_zlim3d(-20, 40)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n\n    xs, ys, zs = [], [], []\n    for joint in joints.values():\n      xs.append(joint.coordinate[0, 0])\n      ys.append(joint.coordinate[1, 0])\n      zs.append(joint.coordinate[2, 0])\n    plt.plot(zs, xs, ys, 'b.')\n    #print('xs = {}\\n'.format(xs))\n    for joint in joints.values():\n      child = joint\n      if child.parent is not None:\n        parent = child.parent\n        xs = [child.coordinate[0, 0], parent.coordinate[0, 0]]\n        ys = [child.coordinate[1, 0], parent.coordinate[1, 0]]\n        zs = [child.coordinate[2, 0], parent.coordinate[2, 0]]\n        plt.plot(zs, xs, ys, 'r')\n    plt.show()\n    \n    \n  def to_dict(self):\n    ret = {self.name: self}\n    for child in self.children:\n      ret.update(child.to_dict())\n    return ret\n\n  def pretty_print(self):\n    print('===================================')\n    print('joint: %s' % self.name)\n    print('direction:')\n    print(self.direction)\n    print('limits:', self.limits)\n    print('parent:', self.parent)\n    print('children:', self.children)\n\n\ndef read_line(stream, idx):\n  if idx >= len(stream):\n    return None, idx\n  line = stream[idx].strip().split()\n  idx += 1\n  return line, idx\n\n\ndef parse_asf(file_path):\n  '''read joint data only'''\n  with open(file_path) as f:\n    content = f.read().splitlines()\n\n  for idx, line in enumerate(content):\n    # meta infomation is ignored\n    if line == ':bonedata':\n      content = content[idx+1:]\n      break\n\n  # read joints\n  joints = {'root': Joint('root', np.zeros(3), 0, np.zeros(3), [], [])}\n  idx = 0\n  while True:\n    # the order of each section is hard-coded\n\n    line, idx = read_line(content, idx)\n\n    if line[0] == ':hierarchy':\n      break\n\n    assert line[0] == 'begin'\n\n    line, idx = read_line(content, idx)\n    assert line[0] == 'id'\n\n    line, idx = read_line(content, idx)\n    assert line[0] == 'name'\n    name = line[1]\n\n    line, idx = read_line(content, idx)\n    assert line[0] == 'direction'\n    direction = np.array([float(axis) for axis in line[1:]])\n\n    # skip length\n    line, idx = read_line(content, idx)\n    assert line[0] == 'length'\n    length = float(line[1])\n\n    line, idx = read_line(content, idx)\n    assert line[0] == 'axis'\n    assert line[4] == 'XYZ'\n\n    axis = np.array([float(axis) for axis in line[1:-1]])\n\n    dof = []\n    limits = []\n\n    line, idx = read_line(content, idx)\n    if line[0] == 'dof':\n      dof = line[1:]\n      for i in range(len(dof)):\n        line, idx = read_line(content, idx)\n        if i == 0:\n          assert line[0] == 'limits'\n          line = line[1:]\n        assert len(line) == 2\n        mini = float(line[0][1:])\n        maxi = float(line[1][:-1])\n        limits.append((mini, maxi))\n\n      line, idx = read_line(content, idx)\n\n    assert line[0] == 'end'\n    joints[name] = Joint(\n      name,\n      direction,\n      length,\n      axis,\n      dof,\n      limits\n    )\n\n  # read hierarchy\n  assert line[0] == ':hierarchy'\n\n  line, idx = read_line(content, idx)\n\n  assert line[0] == 'begin'\n\n  while True:\n    line, idx = read_line(content, idx)\n    if line[0] == 'end':\n      break\n    assert len(line) >= 2\n    for joint_name in line[1:]:\n      joints[line[0]].children.append(joints[joint_name])\n    for nm in line[1:]:\n      joints[nm].parent = joints[line[0]]\n\n  return joints\n\n\ndef parse_amc(file_path):\n  with open(file_path) as f:\n    content = f.read().splitlines()\n\n  for idx, line in enumerate(content):\n    if line == ':DEGREES':\n      content = content[idx+1:]\n      break\n\n  frames = []\n  idx = 0\n  line, idx = read_line(content, idx)\n  assert line[0].isnumeric(), line\n  EOF = False\n  while not EOF:\n    joint_degree = {}\n    while True:\n      line, idx = read_line(content, idx)\n      if line is None:\n        EOF = True\n        break\n      if line[0].isnumeric():\n        break\n      joint_degree[line[0]] = [float(deg) for deg in line[1:]]\n    frames.append(joint_degree)\n  return frames\n\n\ndef test_all():\n  import os\n  lv0 = '.\/data'\n  lv1s = os.listdir(lv0)\n  for lv1 in lv1s:\n    lv2s = os.listdir('\/'.join([lv0, lv1]))\n    asf_path = '%s\/%s\/%s.asf' % (lv0, lv1, lv1)\n    print('parsing %s' % asf_path)\n    joints = parse_asf(asf_path)\n    motions = parse_amc('.\/nopose.amc')\n    joints['root'].set_motion(motions[0])\n    joints['root'].draw()\n\n    # for lv2 in lv2s:\n    #   if lv2.split('.')[-1] != 'amc':\n    #     continue\n    #   amc_path = '%s\/%s\/%s' % (lv0, lv1, lv2)\n    #   print('parsing amc %s' % amc_path)\n    #   motions = parse_amc(amc_path)\n    #   for idx, motion in enumerate(motions):\n    #     print('setting motion %d' % idx)\n    #     joints['root'].set_motion(motion)\n\n\nif __name__ == '__main__':\n  #test_all()\n  asf_path = '\/kaggle\/input\/cmu-motion-capture-walking-database\/35.asf'\n  amc_path = '\/kaggle\/input\/cmu-motion-capture-walking-database\/walk\/07_11.amc'\n  joints = parse_asf(asf_path)\n  print(joints.values())\n  motions = parse_amc(amc_path)\n  \n  frame_idx = 100\n  joints['root'].set_motion(motions[frame_idx])\n  joints['root'].draw() \n  ","08fe0731":"def combineMultipleDatas(data_names):\n   datas = data_names[0]\n   x = 0\n   for data in data_names:\n       if x == 0:\n           result = datas.append(data,ignore_index=True)\n       else:\n           result = result.append(data,ignore_index=True)\n       x = x+ 1\n   return result\ndef dataPreparer(df,df2,df3,liste,liste2,liste3):\n    a = 1\n    b = 0\n    \n    for i in liste: \n        df.iloc[b,(a%31-1)] = i\n        if a % 31 ==0:\n            b = b+1\n        #print(b,a)\n        a = a+1\n    a = 1\n    b = 0\n    for i in liste2:\n        df2.iloc[b,(a%31-1)] = i\n        if a % 31 ==0:\n            b = b+1\n        #print(b,a)\n        a = a+1\n    a = 1\n    b = 0\n    for i in liste3:\n        df3.iloc[b,(a%31-1)] = i\n        if a % 31 ==0:\n            b = b+1\n        #print(b,a)\n        a = a+1\n\n    data = pd.concat([df,df2],axis=1,ignore_index=True)\n    data = pd.concat([data,df3],axis=1,ignore_index=True)\n    return data\n\nimport pandas as pd\ndf = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,34))\ndf2 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,34))\ndf3 =pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,34))\nliste= []\nliste2 = []\nliste3 = []\nimport os","8533ccd7":"if __name__ == '__main__':\n    asf_path = '\/kaggle\/input\/cmu-motion-capture-walking-database\/35.asf'\n    path ='\/kaggle\/input\/cmu-motion-capture-walking-database\/walk_2\/'\n    for entry in sorted(os.listdir(path)):\n      if os.path.isfile(os.path.join(path, entry)):\n          joints = parse_asf(asf_path)\n          motions = parse_amc(path+entry)\n          frame_idx= 0\n          joints['root'].set_motion(motions[frame_idx])\n          #joints['root'].draw()\n          \n          for j in joints.items():\n              for k in j[1].coordinate.T:\n                  liste.append(k[0])\n                  liste2.append(k[1])\n                  liste3.append(k[2])\n    data = dataPreparer(df,df2,df3,liste,liste2,liste3)","b9a89bde":"if __name__ == '__main__':\n    asf_path = '\/kaggle\/input\/cmu-motion-capture-walking-database\/07.asf'\n    path ='\/kaggle\/input\/cmu-motion-capture-walking-database\/walk\/'\n    liste4 = []\n    liste5 = []\n    liste6 = []\n    for entry in sorted(os.listdir(path)):\n      if os.path.isfile(os.path.join(path, entry)):\n          joints = parse_asf(asf_path)\n          motions = parse_amc(path+entry)\n          frame_idx= 0\n          joints['root'].set_motion(motions[frame_idx])\n          #joints['root'].draw()\n          for js in joints.items():\n              for ks in js[1].coordinate.T:\n                  liste4.append(ks[0])\n                  liste5.append(ks[1])\n                  liste6.append(ks[2])\n    df4 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,12))\n    df5 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,12))\n    df6 =pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,12))\n    data2 = dataPreparer(df4,df5,df6,liste4,liste5,liste6)","c1fef8e8":"if __name__ == '__main__':\n    asf_path = '\/kaggle\/input\/cmu-motion-capture-walking-database\/39.asf'\n    path ='\/kaggle\/input\/cmu-motion-capture-walking-database\/walk_3\/'\n    liste7 = []\n    liste8 = []\n    liste9 = []\n    for entry in sorted(os.listdir(path)):\n      if os.path.isfile(os.path.join(path, entry)):\n          joints = parse_asf(asf_path)\n          motions = parse_amc(path+entry)\n          frame_idx= 0\n          joints['root'].set_motion(motions[frame_idx])\n          #joints['root'].draw()\n          for js in joints.items():\n              for ks in js[1].coordinate.T:\n                  liste7.append(ks[0])\n                  liste8.append(ks[1])\n                  liste9.append(ks[2])\n    df7 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,14))\n    df8 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,14))\n    df9 = pd.DataFrame(columns = np.arange(1,32),index= np.arange(0,14))\n    data4 = dataPreparer(df7,df8,df9,liste7,liste8,liste9)","31e3a2ee":"data3 = pd.concat([data,data2,data4],ignore_index=True)","72b9a2ff":"x = data3\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=31) #whitten = normalize\npca.fit(x)\n\nx_pca = pca.transform(x)\n\nprint(\"variance ratio: \",pca.explained_variance_ratio_)\n\nprint(\"sum: \",sum(pca.explained_variance_ratio_))","82e434ac":"data3[\"p1\"] = x_pca[:,0]\ndata3[\"p2\"] = x_pca[:,1]\n\ncolor = [\"red\",\"green\",\"blue\"]\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx_pca_ = pd.DataFrame(data=x_pca)\nxs = x_pca_.iloc[5,0:10]\nys = x_pca_.iloc[5,10:20]\nzs = x_pca_.iloc[5,20:30]\n\nax.scatter(xs,ys,zs)\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\nax.set_xlim3d(-50, 10)\nax.set_ylim3d(-20, 40)\nax.set_zlim3d(-20, 40)\nplt.show()","f598bade":"import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nfor ar in range(1,len(x_pca_)):\n    xs = x_pca_.iloc[ar,0:10]\n    ys = x_pca_.iloc[ar,10:20]\n    zs = x_pca_.iloc[ar,20:30]\n    ax.scatter(xs,ys,zs)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n    ax.set_xlim3d(-50, 10)\n    ax.set_ylim3d(-20, 40)\n    ax.set_zlim3d(-20, 40)\n    plt.show()\n    plt.pause(0.5)\n    ax.cla()","d6b74acc":"from keras.models import Model\nfrom keras.layers import Input, Dense\nfrom keras.datasets import fashion_mnist\nimport matplotlib.pyplot as plt\nimport json, codecs\nimport warnings \nwarnings.filterwarnings('ignore')\nx = x.drop(['p1','p2'],axis=1)","7211fcea":"input_img = Input(shape=(93,))\n\nencoded = Dense(32, activation='relu')(input_img)\n\nencoded = Dense(16, activation='relu')(encoded)\n\ndecoded = Dense(32, activation='relu')(encoded)\n\ndecoded = Dense(93, activation='relu')(decoded)\n\nautoencoder = Model(input_img,decoded)\n\nautoencoder.compile(optimizer='rmsprop',loss='binary_crossentropy')\n\nhist = autoencoder.fit(x,x,epochs=200,batch_size=256,shuffle=True,validation_data=(x,x))\n\nprint(hist.history.keys())\n","a0c8e3c6":"plt.plot(hist.history['loss'],label = 'Train loss')\nplt.plot(hist.history['val_loss'],label = 'Validationn loss')\nplt.legend()\nplt.show()","2cb0488b":"denemedix = autoencoder.predict(x)\ndenemedix = pd.DataFrame(data=denemedix)","26be1ae7":"import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nfor ar in range(1,len(denemedix)):\n    xs = denemedix.iloc[ar,0:10]\n    ys = denemedix.iloc[ar,10:20]\n    zs = denemedix.iloc[ar,20:30]\n    ax.scatter(xs,ys,zs)\n    ax.set_xlabel('X Label')\n    ax.set_ylabel('Y Label')\n    ax.set_zlabel('Z Label')\n    ax.set_xlim3d(-50, 10)\n    ax.set_ylim3d(-20, 40)\n    ax.set_zlim3d(-20, 40)\n    plt.show()\n    plt.pause(0.5)\n    ax.cla()","ce884cbc":"**Now, let's try a non-linear feature extractor.I imported necessary libraries.**","fde3d8de":"**Now, we have ability to parse amc\/asf files which is an important area for me.**","8e71630e":"**Hi,\nIn this notebook I will show you how to parse amc\/asf file which collected by Vicon Motion Capture System, then we will visualize 3D Human joints.Also, we will have a experiment of linear and non-linear feature extractor named PCA(Principal Component Analysys) and Autoencoder to see the significant features of human joints.**","d22de7c8":"**I create a dataframe with autoencoder output data(reduced point cloud).**","67b864df":"**We combine 3 dataframe in a single dataframe which we prepare previous sections.The main dataframe name is \"data3\".**","5d205cf3":"**The sum of variances are almost 1 which means the feature reducer(extractor) worked well.Let's visualize a reduced point cloud to see which region is most importont acording to PCA**","3b13e1c8":"**Let's visualize the autoencoder reduced data in a order.As a result, clearly we can understand that the point cloud direct us to region of hip and legs which is not a suprise.**","4d793dd8":"**In this section we prepare last folder named \"\/walk_3\".**","390b377f":"Then, I prepare a dataframe with second data in folder \"\/walk\".","bc3bf29b":"**Lets, import first walking data in a dataframe.The first data is in folder \"\/walk_2\".**","137e8ba7":"**I wrote some functions to prepare the data and combining multiple dataframe correctly.**","e733a4c3":"**I wrote a simple autoencoder example with keras and visualize the loss graph.**","f5f7b3d7":"**Let's try a simple Linear feature extractor named PCA.I choose component parameter 31 just because of we have 93 features and I wanted to press it in a linear reduced data points.**","1e8651d3":"**First, we have to install external library named transforms3d.**","ba3be2e5":"**The mistake that I do is the data was not much huge, in fact it was a small size data.But, I still wanted to see the important features and we show that the hip and leg region is most important in walking.**","a9c9a352":"**In this section I tried to visualize all points one by one, but kaggle api show just last visualize, It does not show us the process :) But, you can have a look it on your computer.**","07add7de":"**This is main script to parse amc\/asf files.I use [this](https:\/\/github.com\/CalciferZh\/AMCParser) repo to parse data.In fact I modify this repo a bit to make it more usefull for us.Then, I visualized the 3D human positions as you see below.**","a44e95c8":"**As you see above, the significant features in the region of hip and leg.So, it's not suprised to have this results in a walking data:)**"}}