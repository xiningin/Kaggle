{"cell_type":{"24c92169":"code","d80f0f69":"code","6641ef92":"code","bf19f8bb":"code","27c4a360":"code","706ae7f1":"code","d0bb7df1":"code","eb27f1a5":"code","68fe86b7":"code","395f7c6f":"code","4ed95404":"code","ae25ea4c":"code","04b5472d":"code","2f443310":"code","d14a0466":"code","2d19cdf9":"code","1d1e1944":"code","06e2eacb":"code","bd4be14e":"code","2abf8c28":"code","8236d911":"code","b8906d73":"code","6904a206":"code","47f3c01d":"code","245857a3":"code","a479cfa4":"code","c5434f0d":"code","711beed5":"code","a564c9b2":"code","0b693784":"code","cf8594a2":"code","a2da0d2a":"code","02c2b9ac":"code","c8330350":"code","c434ab5f":"code","9810fa37":"code","1561cdd5":"code","3195f7b5":"code","326eafad":"code","ac8ae931":"code","8bf8b2c0":"code","de39b16a":"code","e6ceaf11":"code","b769e767":"code","f07a9ea7":"code","f12fb499":"code","94ee5f31":"markdown","394fa397":"markdown","1e3b0845":"markdown","380e2952":"markdown","d925cf87":"markdown","5bfb1b1a":"markdown","9e74c100":"markdown","2e120362":"markdown","4a6f1b18":"markdown","26875f17":"markdown","8d2019c9":"markdown","1ed74fdb":"markdown","033e8d75":"markdown","0ce9111f":"markdown","ce456e47":"markdown","fd8fbd28":"markdown","9f0c4729":"markdown","a36810ba":"markdown","dd59653f":"markdown","9d3bf31c":"markdown"},"source":{"24c92169":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d80f0f69":"train=pd.read_csv(\"..\/input\/titanic\/train.csv\" )\ntrain.head()","6641ef92":"train.shape","bf19f8bb":"test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest.head()","27c4a360":"test.shape","706ae7f1":"train.columns","d0bb7df1":"train.info()","eb27f1a5":"train.dtypes","68fe86b7":"train['Name'].unique()","395f7c6f":"train['Sex'].unique()","4ed95404":"train['Ticket'].unique()","ae25ea4c":"train['Cabin'].unique()","04b5472d":"train['Embarked'].unique()","2f443310":"train.duplicated().sum()","d14a0466":"train.describe()","2d19cdf9":"train.isnull().sum()","1d1e1944":"train.skew()","06e2eacb":"train['Age'].fillna(train['Age'].median(),inplace=True)","bd4be14e":"train['Embarked'].fillna(train['Embarked'].mode(),inplace=True)","2abf8c28":"from statistics import mode\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(mode(train[\"Embarked\"]))","8236d911":"train.isnull().sum()","b8906d73":"test.isnull().sum()","6904a206":"test.skew()","47f3c01d":"test['Age'].fillna(test['Age'].median(),inplace=True)","245857a3":"test['Fare'].fillna(test['Fare'].median(),inplace=True)","a479cfa4":"from statistics import mode\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(mode(train[\"Embarked\"]))","c5434f0d":"test.isnull().sum()","711beed5":"#Analytics between numeric vrs categorical:-\n#Age vrs Survival\nplt.figure(figsize=(12,5))\nsns.distplot(train.Age[train.Survived==0],color=\"darkblue\")\nsns.distplot(train.Age[train.Survived==1],color=\"cyan\")\nplt.legend(['0','1'])\nplt.show()","a564c9b2":"#Analytics between numeric vrs categorical:-\n#Fare vrs Survival\nplt.figure(figsize=(12,5))\nsns.distplot(train.Fare[train.Survived==0],color=\"darkblue\")\nsns.distplot(train.Fare[train.Survived==1],color=\"cyan\")\nplt.legend(['0','1'])\nplt.show()","0b693784":"#categorical vrs categorical\n#sex vrs survived\nplt.figure(figsize=(6,3))\nsns.countplot(train.Sex)\nplt.show()\nsns.countplot(train.Sex[train.Survived==1])\nplt.show()","cf8594a2":"#categorical vrs categorical\n#sex vrs survived\nplt.figure(figsize=(6,3))\nsns.countplot(train.SibSp)\nplt.show()\nsns.countplot(train.SibSp[train.Survived==1])\nplt.show()","a2da0d2a":"#categorical vrs categorical\n#sex vrs survived\nplt.figure(figsize=(6,3))\nsns.countplot(train.Parch)\nplt.show()\nsns.countplot(train.Parch[train.Survived==1])\nplt.show()","02c2b9ac":"cor=train.corr()\n#Heatmap for visualisation of correlation analysis\nplt.figure(figsize=(12,10))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\n#when we write annot= True , it shows the values .\nplt.show()","c8330350":"train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\ntrain[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n\ntest[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\ntest[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n\ntrain[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n\ntest[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\ntest[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\ntest[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2","c434ab5f":"train.columns","9810fa37":"train.dtypes","1561cdd5":"xtr=train[['Sex','Age','SibSp','Parch','Fare','Embarked']]\nytr=train['Survived']\nxts=test[['Sex','Age','SibSp','Parch','Fare','Embarked']]","3195f7b5":"from sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression(max_iter = 30000)\nlogisticRegression.fit(xtr, ytr)","326eafad":"ypred = logisticRegression.predict(xts)","ac8ae931":"ypred","8bf8b2c0":"output = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived': ypred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","de39b16a":"output.head()","e6ceaf11":"from sklearn.ensemble import RandomForestClassifier\nmodel4 = RandomForestClassifier(n_estimators=50,criterion='gini',max_depth=10,min_samples_leaf=20)\nmodel4.fit(xtr,ytr)","b769e767":"ypred = model4.predict(xts)","f07a9ea7":"ypred","f12fb499":"output2 = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived': ypred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","94ee5f31":"#### To replace these null values we have to first check the skeweness","394fa397":"#### So we are having 891 columns and 12 rows in the train data","1e3b0845":"## Data Analysis","380e2952":"## Importing Libraries:","d925cf87":"## Data Wrangling","5bfb1b1a":"#### from above analysis it is clear that we are not having null values in any other columns apart from age embarked and cabin ","9e74c100":"#### First we have to import all the required library for the project Then we will start working with that","2e120362":"## Random forest Algorithm","4a6f1b18":"#### We are not having any duplicate rows ","26875f17":"## Data Visualisation","8d2019c9":"#### Here we are having 418 rows and 11 columns in the test data and here we have to predict the target column i.e the survived column","1ed74fdb":" Data Dictionary\n Variable\tDefinition\tKey\n survival\tSurvival\t0 = No, 1 = Yes\n pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n sex\tSex\t\n Age\tAge in years\t\n sibsp\t# of siblings \/ spouses aboard the Titanic\t\n parch\t# of parents \/ children aboard the Titanic\t\n ticket\tTicket number\t\n fare\tPassenger fare\t\n cabin\tCabin number\t\n embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n Variable Notes\n pclass: A proxy for socio-economic status (SES)\n 1st = Upper\n 2nd = Middle\n 3rd = Lower\n\n age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n sibsp: The dataset defines family relations in this way...\n Sibling = brother, sister, stepbrother, stepsister\n Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n parch: The dataset defines family relations in this way...\n Parent = mother, father\n Child = daughter, son, stepdaughter, stepson\n Some children travelled only with a nanny, therefore parch=0 for them.","033e8d75":"#### From the above code we can get the statistical summary of the dataset","0ce9111f":"## Applying Algorithm :","ce456e47":"### Feature Scaling","fd8fbd28":"#### Here we knew that three columns are there having some null values those are age column and the cabin column but there exist some columns whose datatype is object so we have to check for the unique value to ensure that there does nit exist any null values in the form of any symbol","9f0c4729":" - **There are four type of variables**\n  - **Numerical Features**: Age, Fare, SibSp and Parch\n  - **Categorical Features**: Sex, Embarked, Survived and Pclass\n  - **Alphanumeric Features**: Ticket and Cabin(Contains both alphabets and the numeric value)\n  - **Text Features**: Name\n\n**We really need to tweak these features so we get the desired form of input data**","a36810ba":"## Test Data","dd59653f":" We are having two dataset One is train and another is test\n training set (train.csv)\n test set (test.csv)\n \n The training set should be used to build your machine learning models. For the training set, we provide the outcome (also      known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You  can also use feature engineering to create new features.\n\n The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground   truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you    trained to predict whether or not they survived the sinking of the Titanic.\n\n We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example   of what a submission file should look like.\n","9d3bf31c":"# Titanic : Machine Learning From Disaster :-"}}