{"cell_type":{"1898e0d3":"code","defd7d34":"code","c1a0719f":"code","3f66b862":"code","36de00b5":"code","7ad69c25":"code","5920746a":"code","8d159063":"code","775e442f":"code","6bdb7f81":"code","6e267c5e":"code","66f720ef":"code","9a4c8442":"code","2351ceea":"code","ffecf024":"code","87b7a85f":"code","d70120ba":"code","c9b27a38":"code","a97e7b7f":"code","d5fad1da":"code","1937423e":"code","8b485419":"code","2fd8d423":"code","bfb25b66":"code","640a857c":"code","aac2802d":"code","d730b4dc":"code","d28a7246":"code","b1ef813c":"markdown","fc0f11e9":"markdown","5fd390e2":"markdown","7708fca5":"markdown","83e98802":"markdown","3cd4bf49":"markdown","3b929c82":"markdown","fba656a4":"markdown","1a15de4a":"markdown","2c5211fe":"markdown","8f521164":"markdown","6ed2ecf6":"markdown","c0312c4e":"markdown","c6f25b1e":"markdown"},"source":{"1898e0d3":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt \nimport seaborn as sns  \nfrom sklearn.model_selection import train_test_split, cross_val_score\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import  confusion_matrix , plot_roc_curve, classification_report","defd7d34":"df = pd.read_csv('\/kaggle\/input\/churn-for-bank-customers\/churn.csv')\ndf.head()","c1a0719f":"df.info()\n# no NAN values ","3f66b862":"# remove useless columns\ndf.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis = 1, inplace = True)\n\n# Plot histogram grid\ndf.hist(figsize=(14,14))\nplt.show()","36de00b5":"# Calculate correlations between numeric features\ncorrelations = df.corr()\n\n# sort features in order of their correlation with \"Exited\"\nsort_corr_cols = correlations.Exited.sort_values(ascending=False).keys()\nsort_corr = correlations.loc[sort_corr_cols,sort_corr_cols]\nsort_corr\n\n# Generate a mask for the upper triangle\ncorr_mask = np.zeros_like(df.corr())\ncorr_mask[np.triu_indices_from(corr_mask)] = 1\n\n# Make the figsize 9x9\nplt.figure(figsize=(9,9))\n\n# Plot heatmap of annotated correlations; change background to white\nsns.heatmap(sort_corr*100, \n                cmap='RdBu', \n                annot=True,\n                fmt='.0f',\n                mask=corr_mask,)\n\nplt.title('Correlations by Exited', fontsize=14)\nplt.yticks(rotation=0)\nplt.show()","7ad69c25":"def kdeplot(feature):\n    plt.figure(figsize=(9, 4))\n    plt.title(f\"KDE Plot for {feature}\")\n    ax0 = sns.kdeplot(df[df['Exited'] == 0][feature].dropna(), color= 'dodgerblue', label= 'Exited - 0')\n    ax1 = sns.kdeplot(df[df['Exited'] == 1][feature].dropna(), color= 'orange', label= 'Exited - 1')","5920746a":"kdeplot('Tenure')\nkdeplot('HasCrCard')\nkdeplot('EstimatedSalary')","8d159063":"outlier_plot = [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"]\nfor i in outlier_plot:\n    sns.boxplot(x = df[i])\n    plt.show()","775e442f":"# Seems like CreditScore, Age, NumOfProducts have outliers\noutliers = ['Age','CreditScore','NumOfProducts']","6bdb7f81":"def outlier_removal(df,column):\n    q1 = df[column].quantile(0.25)\n    q3 = df[column].quantile(0.75)\n    iqr = q3 - q1\n    fence_low = q1 - 1.5 * iqr\n    fence_high = q3 + 1.5 * iqr\n    cleaned_data = df.loc[(df[column] > fence_low) & (df[column] < fence_high)]\n    return cleaned_data","6e267c5e":"# clean the dataset by removing outliers\ndf_cleaned = outlier_removal(outlier_removal(outlier_removal(df,'Age'),'CreditScore'),'NumOfProducts')\n\nprint(df.shape)\nprint(df_cleaned.shape)","66f720ef":"def unique_counts(df):\n    for column in df.columns:\n        print(f'{column} :  {len(df[column].value_counts())}')\nunique_counts(df_cleaned)","9a4c8442":"# Gender and Geography need to be encoded\ndf_cleaned = pd.get_dummies(df_cleaned, columns = [\"Geography\"])\ndf_cleaned.replace({'Female': 0,'Male': 1},inplace=True)\ndf_cleaned","2351ceea":"X = df_cleaned.drop([\"Exited\"], axis=1)\nY = df_cleaned[\"Exited\"]","ffecf024":"x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)","87b7a85f":"# Helper function for confusion matric and classification report \ndef evaluate_model(classifier):\n    cf_matrix = confusion_matrix(y_test, classifier.predict(x_test))\n    sns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n                fmt='.2%', cmap='Blues')\n\n    print(classification_report(y_test, classifier.predict(x_test),zero_division=0))","d70120ba":"# Helper function for cross validation\ndef score_model(classifier):\n    print(f\"Test accurarcy {classifier.score(x_test,y_test)}\")\n    val = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n    print(f\"cross validation Mean : {val.mean()} and STD of {val.std()}\")","c9b27a38":"log_clsf = LogisticRegression(max_iter=10000)\nlog_clsf.fit(x_train,y_train)\n\nscore_model(log_clsf)","a97e7b7f":"evaluate_model(log_clsf)\n\nplot_roc_curve(log_clsf, x_test, y_test)  \nplt.show() ","d5fad1da":"rf_clsf = RandomForestClassifier(random_state = 42, max_depth = 10, n_estimators = 1000)\nrf_clsf.fit(x_train, y_train)\n\nscore_model(rf_clsf)","1937423e":"evaluate_model(rf_clsf)\n\nplot_roc_curve(rf_clsf, x_test, y_test)  \nplt.show() ","8b485419":"svm_clsf = SVC()\nsvm_clsf.fit(x_train, y_train)\n\nscore_model(svm_clsf)","2fd8d423":"evaluate_model(svm_clsf)\n\nplot_roc_curve(svm_clsf, x_test, y_test)  \nplt.show() ","bfb25b66":"best_knn = []\nerror = [] \nfor K in range(20):\n    K = K+1\n    model = KNeighborsClassifier(n_neighbors = K)\n\n    model.fit(x_train, y_train)  \n    pred=model.predict(x_test) \n    error.append(np.mean(pred != y_test))\n    best_knn.insert(K, model.score(x_test,y_test))\n\n# Get the best fitting number of neighbours \nfor i,v in enumerate(best_knn):\n    if v == max(best_knn):\n        print(f'best n_neighbours = {i}')\n        \ncurve = pd.Series(error) #elbow curve \ncurve.plot()","640a857c":"knn_clsf = KNeighborsClassifier(n_neighbors=15)\nknn_clsf.fit(x_train, y_train)\n\nscore_model(knn_clsf)","aac2802d":"evaluate_model(knn_clsf)\n\nplot_roc_curve(knn_clsf, x_test, y_test)  \nplt.show() ","d730b4dc":"voting_classfication = VotingClassifier(estimators = [('lg', log_clsf), ('rfg', rf_clsf), ('svc', svm_clsf), ('knn', knn_clsf)])\nvoting_classfication.fit(x_train, y_train)\n\nprint(\"Test accuracy: \", voting_classfication.score(x_test,y_test))","d28a7246":"evaluate_model(voting_classfication)","b1ef813c":"### Looking at Correlations between the variables","fc0f11e9":"## KNN","5fd390e2":"## Random Forest","7708fca5":"# Problem Statement:\n\nPredict churn from the bank customer dataset.\n\n### Dataset Content:\n\n\n* RowNumber\u2014corresponds to the record (row) number and has no effect on the output.\n* CustomerId\u2014contains random values and has no effect on customer leaving the bank.\n* Surname\u2014the surname of a customer has no impact on their decision to leave the bank.\n* CreditScore\u2014can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n* Geography\u2014a customer\u2019s location can affect their decision to leave the bank.\n* Gender\u2014it\u2019s interesting to explore whether gender plays a role in a customer leaving the bank.\n* Age\u2014this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n* Tenure\u2014refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n* Balance\u2014also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n* NumOfProducts\u2014refers to the number of products that a customer has purchased through the bank.\n* HasCrCard\u2014denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n* IsActiveMember\u2014active customers are less likely to leave the bank.\n* EstimatedSalary\u2014as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n* Exited\u2014whether or not the customer left the bank.\n","83e98802":"The variables with low correlation do seem so contribute to predicting the final outcome \n(the KDE plots show how different are the graphs of the features with respenct to the target feature. Thus more differences in the graph, the more the variable contributes to the target feature)","3cd4bf49":"## Logistic Regression","3b929c82":"# Modeling","fba656a4":"### Looking at Unique data for Encoding","1a15de4a":"### Remove useless columns and see distributions of the variables","2c5211fe":"### Looking at Variables with low correlation with the target variable","8f521164":"### Finding and Removing Outliers in numerical variables","6ed2ecf6":"## Support Vector Machine (SVM) ","c0312c4e":"## Voting Classification","c6f25b1e":"# Summary:\n\nThe best model amonst the ones implemented is Random Forests with an accuracy of 86.8% \nas for the other models, even though their accuracy hovers arround 80%, their AUC is pretty bad and thus shouldn't be used for a real world scenario.\n\n\n\nDo post a comment if you have any suggessions !"}}