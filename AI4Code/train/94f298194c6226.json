{"cell_type":{"9e1640df":"code","65754802":"code","e32cb4d7":"code","788ed6b8":"code","442d8779":"code","bae51bad":"code","26648451":"code","4270ffbc":"code","ab6af579":"code","34a16c1e":"code","06919392":"code","e55c927d":"code","d414e47a":"code","c3508d62":"code","edf47dd9":"code","f106924c":"code","f0dcc845":"code","fcaa9f0b":"code","ace5f227":"code","d0db8866":"code","38ae4b44":"code","657dbe10":"code","8871776d":"code","c5b949cc":"code","78ecc968":"code","8d9ac692":"code","0c804bb1":"code","4b906dea":"code","60657ab1":"code","8d9d374c":"code","e9a58aac":"code","3e09104b":"code","3147e924":"code","bb9e86bf":"code","dffa6459":"code","6e3df8b4":"code","73771880":"code","47fd032a":"code","420e245d":"code","19a62261":"code","f4635205":"code","921d045b":"code","d6fa7fd5":"code","b605f1c1":"code","43f6a34f":"code","c768540a":"code","a4decb95":"code","560fdac2":"code","9f8ae516":"code","03cf74d7":"code","a71eb898":"code","d216ad1c":"markdown","e0fbd42c":"markdown","d0ec32d5":"markdown","a0409bb8":"markdown","338aa631":"markdown","cf717ec9":"markdown","cb4fc940":"markdown","7f76a4c8":"markdown","21e03add":"markdown","41af61ef":"markdown","48d2749b":"markdown","40dfbd78":"markdown","eac65336":"markdown","69691f3d":"markdown"},"source":{"9e1640df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65754802":"#importing useful libraries.\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport plotly.express as px\nimport plotly.graph_objects as go\nsns.color_palette('bright')\nsns.set(style='darkgrid',rc = {'figure.figsize':(15,8)})\nfrom plotly.offline import iplot\nfrom sklearn.pipeline import make_pipeline \n%matplotlib inline\nprint(\"Ready,set,go....\")","e32cb4d7":"#reading data sets\ndf = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ndftest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","788ed6b8":"#checking head\ndf.head()","442d8779":"#checking info\ndf.info()","bae51bad":"#describing the data\ndf.describe()","26648451":"#checking head\ndftest.head()","4270ffbc":"#checking info\ndftest.info()","ab6af579":"#describing the data\ndftest.describe()","34a16c1e":"# checking for any NaN values\ndf.isna().any()","06919392":"# checking for any NaN values\ndftest.isna().any()","e55c927d":"#visuvalising the  null values\nplt.figure(figsize=(16,8))\nsns.heatmap(df.isnull(),cmap='coolwarm')\nplt.title('Heatmap for checking Null Values')\nplt.show()","d414e47a":"#visuvalising the  null values\nplt.figure(figsize=(16,8))\nsns.heatmap(dftest.isnull(),cmap='coolwarm')\nplt.title('Heatmap for checking Null Values')\nplt.show()","c3508d62":"#getting sum of null values\ndf.isnull().sum().sort_values(ascending=False)","edf47dd9":"#getting sum of null values\ndftest.isnull().sum().sort_values(ascending=False)","f106924c":"df['location'].describe()","f0dcc845":"dftest['location'].describe()","fcaa9f0b":"#for getting number of value_counts\ndf['location'].value_counts()","ace5f227":"#plot for locations \npx.histogram(df, x=\"location\",title=\"count of Different Locations\")","d0db8866":"#plot for locations \npx.histogram(dftest, x=\"location\",title=\"count of Different Locations\")","38ae4b44":"df['keyword'].describe()","657dbe10":"dftest['keyword'].describe()","8871776d":"#for getting number of value_counts\ndf['keyword'].value_counts()","c5b949cc":"#for getting number of value_counts\ndftest['keyword'].value_counts()","78ecc968":"#plot for keywords\npx.histogram(df, x=\"keyword\",title=\"count of Different Keywords\",template='plotly_dark')","8d9ac692":"#plot for keywords\npx.histogram(df, x=\"keyword\",title=\"count of Different Keywords\",template='plotly_dark')","0c804bb1":"df['text'].describe()","4b906dea":"dftest['text'].describe()","60657ab1":"df['target'].describe()","8d9d374c":"#for getting number of value_counts\ndf['target'].value_counts()","e9a58aac":"#plot for target\nfig = px.histogram(df, x=\"target\",title=\"count of target\",template='plotly_dark',category_orders=dict(target=[0,1]))\nfig.update_layout(bargap=0.5)\nfig.show()","3e09104b":"df.drop(['id','keyword','location'],axis=1,inplace = True)\ndftest.drop(['id','keyword','location'],axis=1,inplace = True)","3147e924":"df['count'] = df['text'].apply(len)\ndftest['count'] = dftest['text'].apply(len)","bb9e86bf":"px.histogram(data_frame=df,x='count',template='plotly_dark')","dffa6459":"px.histogram(data_frame=dftest,x='count',template='plotly_dark')","6e3df8b4":"!pip install texthero","73771880":"import texthero as hero\nfrom texthero import preprocessing as ppe\n","47fd032a":"custom_pipeline = [ppe.fillna,\n                   ppe.lowercase,\n                   ppe.remove_punctuation,\n                   ppe.remove_stopwords,\n                   ppe.remove_digits,\n                   ppe.remove_diacritics,\n                   ppe.remove_round_brackets,\n                   ppe.remove_html_tags,\n                   ppe.remove_urls,\n                   ppe.remove_whitespace,\n                   ppe.remove_brackets,\n                   ppe.remove_angle_brackets,\n                   ppe.remove_curly_brackets,\n                   ppe.remove_square_brackets,\n                   ppe.stem\n                  ]\n","420e245d":"df['clean_text'] = hero.clean(df['text'], custom_pipeline)\ndftest['clean_text'] = hero.clean(dftest['text'], custom_pipeline)","19a62261":"df.head()","f4635205":"from wordcloud import WordCloud\n#interplotaion in bilinear way\nwordcloud = WordCloud(margin=0,background_color='black',colormap='coolwarm')\nwordcloud.generate(' '.join(df[df['target']==0]['clean_text']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"word cloud for target 0\")\nplt.margins(x=0,y=0)\nplt.show()","921d045b":"#interplotaion in bilinear way\nwordcloud = WordCloud(margin=0,background_color='black',colormap='coolwarm')\nwordcloud.generate(' '.join(df[df['target']==1]['clean_text']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.margins(x=0,y=0)\nplt.title('worcloud for target 1')\nplt.show()","d6fa7fd5":"#interplotaion in bilinear way\nwordcloud = WordCloud(margin=0,background_color='black',colormap='coolwarm')\nwordcloud.generate(' '.join(dftest['clean_text']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis('off')\nplt.margins(x=0,y=0)\nplt.title('worcloud for test data')\nplt.show()","b605f1c1":"vector  = hero.CountVectorizer()\nx = vector.fit_transform(df['clean_text'])\nxtest = vector.transform(dftest['clean_text'])","43f6a34f":"y =df['target'].values","c768540a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nlr = LogisticRegression()\ncv = cross_val_score(lr,x,y,cv = 10)\ncv","a4decb95":"from sklearn.model_selection import GridSearchCV\ngd = GridSearchCV(\n    estimator=lr,\n    param_grid={'solver':['sag','saga'],\n                'C':[0.5,0.75,1.0,1.25,1.5,1.75,2.0]\n            },\n    cv = 15\n)","560fdac2":"gd.fit(x,y)\n#getting best values\nprint(\"best parameters ;{}\".format(gd.best_params_))\nprint(\"best score:{}\".format(gd.best_score_))\nprint(\"best model:{}\".format(gd.best_estimator_))","9f8ae516":"lr = LogisticRegression(C = 0.5,solver='sag')\nlr.fit(x,y)\nr = lr.predict(xtest)","03cf74d7":"sample = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')\n\nsample.head()","a71eb898":"sample['target'] = r\nsample.to_csv('submission1.csv', index=False)","d216ad1c":"<h2>Word clouds<\/h2>","e0fbd42c":"<h2>Cleaning Data<\/h2>","d0ec32d5":"<h3>Text<\/h3>","a0409bb8":"<h2>submission<\/h2>","338aa631":"<h2>Reading the given data<\/h2>","cf717ec9":"<h2>preprocessing<\/h2>","cb4fc940":"cleaning text using texthero","7f76a4c8":"<h2>Understanding Each column <\/h2>","21e03add":"<h2> Model <\/h2>","41af61ef":"checking count of words distribution","48d2749b":"<h3>Key word<\/h3>","40dfbd78":"<h3>Target Values<\/h3>","eac65336":"<h3>Location :<\/h3>","69691f3d":"https:\/\/texthero.org\/"}}