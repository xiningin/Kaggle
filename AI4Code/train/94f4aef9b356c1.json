{"cell_type":{"992f0ffb":"code","5976756d":"code","dd87284e":"code","e11f0682":"code","92d08883":"code","0a4f0d6a":"code","957e9601":"code","57983861":"code","ee1bf27d":"code","086227bb":"code","2a0494a9":"code","ad0e26da":"code","8e203164":"markdown"},"source":{"992f0ffb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5976756d":"#%% DATA IMPORT\ndataset= pd.read_csv(\"..\/input\/tiny_eeg_self_experiment_music.csv\")","dd87284e":"#%% Slicing sample data (39647 feature huge )\ndataset=dataset.iloc[0:250,:]\ndataset.head()","e11f0682":"#%% EDA\n\ndataset.info()\ndataset.columns","92d08883":"#%% CLEANING DATA\n#Drop unnecessary columns\ndataset=dataset.drop(['IndexId','Ref1','Ref2', 'Ref3', 'TS1', 'TS2'],axis=1)","0a4f0d6a":"dataset.tail()","957e9601":"#%% see on pairplot our dataset every sigle feature pair with the other and non colored like featureless\nsns.pairplot(data=dataset)\nplt.show()","57983861":"#%% KMEANS wiht sklearn \nfrom sklearn.cluster import KMeans\nwcss=[]\n#find best k value\nfor k in range(1,15):\n    kmeans=KMeans(n_clusters=k)\n    kmeans.fit(dataset)\n    wcss.append(kmeans.inertia_)\n#elbow rule on plot    \nplt.figure(figsize=(12,8))\nplt.plot(range(1,15),wcss,\"-o\")\nplt.title(\"wcss \/ number of cluster\", fontsize=18)\nplt.xlabel(\"number of k(cluster) values\")\nplt.xticks(range(1,15))\nplt.grid(True)\nplt.ylabel(\"wcss\")\nplt.tight_layout()\nplt.show()","ee1bf27d":"#%%   from elbow plot we can choose 3 or 4 i'll go with 4 cluster.\n#kmeans2=KMeans(n_clusters=2)\n#kmeans3=KMeans(n_clusters=3)\nkmeans=KMeans(n_clusters=4)\nclusters=kmeans.fit_predict(dataset)\ndataset[\"label\"]=clusters","086227bb":"#%% plot with cluster \/ center(centroid)\nplt.figure(figsize=(20,8))\nplt.scatter(dataset.Channel1[dataset.label==0],dataset.Channel2[dataset.label==0],color=\"red\",alpha= 0.8)\nplt.scatter(dataset.Channel1[dataset.label==1],dataset.Channel2[dataset.label==1],color=\"green\",alpha= 0.8)\nplt.scatter(dataset.Channel1[dataset.label==2],dataset.Channel2[dataset.label==2],color=\"blue\",alpha= 0.8)\nplt.scatter(dataset.Channel1[dataset.label==3],dataset.Channel2[dataset.label==3],color=\"black\",alpha= 0.8)\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],color=\"orange\")# cluster center(centroid)\nplt.title(\"Kmeans(k=4) Cluster\")\nplt.xlabel(\"Channel1\")\nplt.ylabel(\"Channel2\")\nplt.legend(dataset,loc='upper right')\nplt.show()","2a0494a9":"#%%   HIERARCICAL CLUSTRING\n # DENDROGRAM\ndataset2=dataset\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nmerg=linkage(dataset2,method=\"ward\")      \ndendrogram(merg,leaf_rotation=90)\nplt.xlabel(\"data points\")\nplt.ylabel(\"euclidean distanece\")\nplt.show()","ad0e26da":"#%%  HIERARCICAL CLUSTRING\n# CLUSTRING AND PLOT For n_clusters=4\nfrom sklearn.cluster import AgglomerativeClustering\n# AgglomerativeClustering    en alakal\u0131 data pointleri cluster ederek t\u00fcme var\u0131p yap\u0131p datan\u0131n tamam\u0131n\u0131 mant\u0131kl\u0131 cluster eden algoritma\nhierarcical_cluster = AgglomerativeClustering(n_clusters=4,affinity=\"euclidean\",linkage=\"ward\")\ncluster=hierarcical_cluster.fit_predict(dataset)\ndataset2[\"label2\"]=cluster\n\nplt.figure(figsize=(20,8))\nplt.xlabel(\"Channel1\")\nplt.ylabel(\"Channel2\")\nplt.scatter(dataset2.Channel1[dataset2.label2==0],dataset2.Channel2[dataset2.label2==0],color=\"red\",alpha= 0.8)\nplt.scatter(dataset2.Channel1[dataset2.label2==1],dataset2.Channel2[dataset2.label2==1],color=\"green\",alpha= 0.8)\nplt.scatter(dataset2.Channel1[dataset2.label2==2],dataset2.Channel2[dataset2.label2==2],color=\"blue\",alpha= 0.8)\nplt.scatter(dataset2.Channel1[dataset2.label2==3],dataset2.Channel2[dataset2.label2==3],color=\"black\",alpha= 0.8)\n#plt.scatter(dataset.Channel1[dataset.label==4],dataset.Channel2[dataset.label==4],color=\"black\",alpha= 0.3)\nplt.show()\n","8e203164":"# Hello,\n\n*  In this notebook i am going to study Kmeans Clustring and Hierarcical Clustting on EEG micro-experiment dataset\n* Then find best k value (n_clusters) for clustring."}}