{"cell_type":{"2b48f786":"code","1355f458":"code","397b74f3":"code","14f81f75":"code","8e3f9080":"code","37a5ee66":"code","302b1590":"code","afb6f798":"code","6049d8f7":"code","42f39636":"markdown","d0474aea":"markdown","1ce44b82":"markdown","7313278b":"markdown","71f9b60b":"markdown","eefe5799":"markdown","d29b77db":"markdown","3ff8ece0":"markdown","964ab01b":"markdown","2aaed25b":"markdown","10dc53ef":"markdown","0e588818":"markdown"},"source":{"2b48f786":"import datetime\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow_cloud as tfc\nimport tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nfrom sklearn.model_selection import train_test_split","1355f458":"# Note: Please change the Google Cloud project to your own project.\nGCP_PROJECT= 'rosbo-personal'\n\n# Note: Please change the GCS bucket to your own bucket name.\nGCS_BUCKET = 'tf-cloud-rosbo-test' # used to save models & docker images\n\n# Note: Please change the job name to reflect the work you are doing.\nJOB_NAME = 'kaggle-example'\n\nif not tfc.remote():\n    from kaggle_secrets import UserSecretsClient\n    UserSecretsClient().set_gcloud_credentials(project=GCP_PROJECT)\n\ngcs_base_path = f'gs:\/\/{GCS_BUCKET}\/{JOB_NAME}\/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n\nprint(\"Your training artifacts will be stored at:\", gcs_base_path)","397b74f3":"# These settings apply when running in this Kaggle notebook.\nNUM_EPOCHS = 1 # Train a single epoch to test the training code works.\ncallbacks = None\n\n# These settings apply when running on TensorFlow Cloud\nif tfc.remote():    \n    NUM_EPOCHS = 10 # Train more epochs on TensorFlow Cloud\n    \n    callbacks = [\n        # TensorBoard will store logs for each epoch & graph performance for us.\n        tf.keras.callbacks.TensorBoard(log_dir=f'{gcs_base_path}\/tensorboard', histogram_freq=1),\n        # ModelCheckpoint will save models after each epoch for retrieval later.\n        tf.keras.callbacks.ModelCheckpoint(gcs_base_path + '\/checkpoints\/save_at_{epoch}'),\n    ]","14f81f75":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nx_train = train.iloc[:,1:].values.astype('float32') \/ 255.0\ny_train = tf.keras.utils.to_categorical(train.iloc[:,0].astype('int32'))\nx_train = x_train.reshape(-1, 28, 28, 1)\n\nprint(\"Splitting input in train and validation sets...\")\nx_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.10)\nprint(\"Training:\", x_train.shape, y_train.shape)\nprint(\"Validation:\", x_validation.shape, y_validation.shape)","8e3f9080":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.compile(\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n\nprint(model.summary())\n\nprint(\"Training...\")\nmodel.fit(x_train, y_train, epochs=NUM_EPOCHS, batch_size=32)\nprint(\"Training complete\")","37a5ee66":"model.evaluate(x_validation, y_validation, return_dict=True)","302b1590":"if tfc.remote():\n    model.save(f'{gcs_base_path}\/model')","afb6f798":"print(\"Training on TensorFlow Cloud...\")\ntfc.run(\n    distribution_strategy='auto',\n    docker_image_bucket_name=GCS_BUCKET,\n    chief_config=tfc.MachineConfig(\n        cpu_cores=16,\n        memory=64,\n    ),\n    job_labels={\"job\": JOB_NAME},\n)","6049d8f7":"# Look at your training job logs using the link printed in the cell above to get the path to your model trained using TensorFlow Cloud.\nif tfc.remote():\n    print(\"Your model trained by TensorFlow Cloud is saved at:\")\n    print(\"MODEL_PATH =\", f'{gcs_base_path}\/model')","42f39636":"### Read & Prepare Training Data\n\nThe model will be trained to recognize handwritten digits on the Kaggle MNIST dataset used in the [Kaggle Digit Recognizer competition](https:\/\/www.kaggle.com\/c\/digit-recognizer).","d0474aea":"## Step 3: Add Your TensorFlow Training Code","1ce44b82":"## Step 1: Import Packages (including TensorFlow Cloud)","7313278b":"### Evaluate\n\nThe model is evaluated against the validation set.","71f9b60b":"### Define & Train TensorFlow Model","eefe5799":"### Specify Parameters\n\nTensorFlow Cloud will run all the cells in this notebook in the Cloud.\n\nYou can call `tfc.remote()` to check whether you are running in the Cloud or not and set different value for parameters (e.g. number of epochs). This allows you to easily debug your training code locally before sending the larger training job to the Cloud.","d29b77db":"## Next Step\n    \n- [Test & Deploy your model trained with TensorFlow Cloud to Google Cloud AI Platform](https:\/\/www.kaggle.com\/rosebv\/test-deploy-tensorflow-model-to-ai-platform)","3ff8ece0":"# Train model with TensorFlow Cloud\n\n[TensorFlow Cloud](https:\/\/github.com\/tensorflow\/cloud) is a Python package that provides APIs for seamless transition from local training to distributed training in Google Cloud.\n\nThis notebook will show you how to train your TensorFlow model from a Kaggle notebook and using a Kaggle dataset.","964ab01b":"For this example, we use a single machine with 16 cores & 64 GB of RAM. \n\nYou can use larger machines, add accelerators or add additional machines to perform the training. To learn more about this, you can read the [TensorFlow Cloud cluster & distribution strategy configuration](https:\/\/github.com\/tensorflow\/cloud#cluster-and-distribution-strategy-configuration) documentation.","2aaed25b":"## Step 4: Train model on TensorFlow Cloud","10dc53ef":"## Step 2: Setup Google Cloud credentials\n\nAdd the \"Google Cloud SDK\" addon from the \"Add-ons\" menu bar above to allow scheduling an AI training job in your Google Cloud project.\n\n**NOTICE**: TensorFlow Cloud will run the training job in your Google Cloud project. **You will be billed ($$$)** for the resources consumed by this training job.\n\n![52xZHgn3Na33F4d.png](attachment:52xZHgn3Na33F4d.png)\n","0e588818":"### Save model\n\nWe save the trained model to Cloud Storage **only when running in the Cloud**."}}