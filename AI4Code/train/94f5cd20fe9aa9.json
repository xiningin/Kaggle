{"cell_type":{"73925f08":"code","362893f9":"code","b56312a7":"code","63b67e7d":"code","1e7684f5":"code","db7bbce4":"code","2e2da01b":"code","2e86d8ce":"code","049e5804":"code","047017b1":"code","8c38ed1d":"code","a2a703fe":"code","a37b1556":"code","384f892e":"code","02b34bb5":"code","8ec04cf2":"markdown","0ab940d2":"markdown","fe1a6ba8":"markdown"},"source":{"73925f08":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","362893f9":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set some parameters\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3\nTRAIN_PATH = '..\/input\/mydata-ns2\/stage1_train\/'\nTEST_PATH = '..\/input\/mydata-ns2\/stage1_test\/'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed","b56312a7":"tf.__version__","63b67e7d":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]","1e7684f5":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n\n# Get and resize test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","db7bbce4":"X_train = X_train \/ 255\nY_train = np.array(Y_train, dtype='float32')","2e2da01b":"# Check if training data looks all right\nix = random.randint(0, len(train_ids))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\n","2e86d8ce":"# From: https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/train.py\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(K.abs(y_true * y_pred))\n    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n    jac = (intersection) \/ (sum_ - intersection)\n    return jac","049e5804":"def unet(input_size=(128, 128, 3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","047017b1":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle=False)\n\nBATCH_SIZE = 16\nEPOCHS = 100","8c38ed1d":"histories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\nfor k, (train_index, test_index) in enumerate(kf.split(X_train, Y_train)):\n    x_train = X_train[train_index]\n    y_train = Y_train[train_index]\n    x_test = X_train[test_index]\n    y_test = Y_train[test_index]\n\n    model = unet(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    \n    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[iou, dice_coef, 'binary_accuracy'])\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_nuclei_seg.hdf5', \n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit(x_train, y_train,\n                        epochs=EPOCHS, \n                        callbacks=[model_checkpoint],\n                        validation_data = (x_test, y_test),\n                        batch_size=BATCH_SIZE)\n    \n    model = load_model(str(k+1) + '_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n    \n    results = model.evaluate(x_test, y_test)\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])","a2a703fe":"print('accuracies : ', accuracies)\nprint('losses : ', losses)\nprint('dicecoefs : ', dicecoefs)\nprint('ious : ', ious)\n\nprint('-----------------------------------------------------------------------------')\nprint('-----------------------------------------------------------------------------')\n\nprint('average accuracy : ', np.mean(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)))\nprint('average dicecoefs : ', np.mean(np.array(dicecoefs)))\nprint('average ious : ', np.mean(np.array(ious)))\nprint()\n\nprint('standard deviation of accuracy : ', np.std(np.array(accuracies)))\nprint('standard deviation of loss : ', np.std(np.array(losses)))\nprint('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\nprint('standard deviation of ious : ', np.std(np.array(ious)))","a37b1556":"import pickle\n\nfor h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, len(keys)\/\/2, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[:len(keys)\/\/2]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])\n        \n    with open(str(h+1) + '_nuclei_trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","384f892e":"selector = np.argmin(abs(np.array(ious) - np.mean(ious)))\nmodel = load_model(str(selector+1) + '_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","02b34bb5":"for i in range(20):\n    index=np.random.randint(1,len(X_train))\n    pred=model.predict(X_train[index][np.newaxis, :, :, :])\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(X_train[index])\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(Y_train[index]))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Predicted mask')\n    plt.show()","8ec04cf2":"Let's see if things look all right by drawing some random images and their associated masks.","0ab940d2":"Seems good!\n\n# Create our Keras metric\n\nNow we try to define the *mean average precision at different intersection over union (IoU) thresholds* metric in Keras. TensorFlow has a mean IoU metric, but it doesn't have any native support for the mean over multiple thresholds, so I tried to implement this. **I'm by no means certain that this implementation is correct, though!** Any assistance in verifying this would be most welcome! \n\n*Update: This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. It also seems to just increase over time no matter what when you train ... *","fe1a6ba8":"# Get the data\nLet's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!"}}