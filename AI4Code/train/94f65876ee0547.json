{"cell_type":{"cfee17e3":"code","5c6e1323":"code","edc51322":"code","4e0dbbd7":"code","d8a3ea7f":"code","6a072edb":"code","6ad1cc8a":"code","ab9267c1":"code","08a4a2d9":"code","42eccb9d":"code","8f72bcc9":"code","19d52aaa":"code","fad42115":"code","bfc0900d":"code","44fa2e15":"code","379a8e01":"code","f0426fbf":"code","82d87863":"code","002297eb":"code","38263667":"code","5cd5787d":"code","eab859e5":"code","1c7d8f68":"code","b781e915":"code","5ad3d12b":"code","79f8f6f5":"markdown","54c2e1f1":"markdown","e3efe6a5":"markdown","0345eae3":"markdown","0f54b63b":"markdown","11874143":"markdown","7c395d5f":"markdown","005b1368":"markdown","b2ee5880":"markdown","d2f5ed53":"markdown","9cd54894":"markdown","7a944c77":"markdown","3294013f":"markdown"},"source":{"cfee17e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c6e1323":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras import Model, layers\nfrom keras.callbacks import *\nfrom keras.models import load_model, model_from_json","edc51322":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random images of Predator\",\"..\/input\/alien-vs-predator-images\/data\/train\/predator\/**\") ","4e0dbbd7":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random images of Alien\",\"..\/input\/alien-vs-predator-images\/data\/train\/alien\/**\") ","d8a3ea7f":"# re-size all the images to this\ntrain_input_shape = (224, 224, 3)","6a072edb":"train_path = '..\/input\/alien-vs-predator-images\/data\/train\/'\nvalid_path = '..\/input\/alien-vs-predator-images\/data\/validation\/'","6ad1cc8a":"# # Load pre-trained VGG16 model\nvgg = VGG16(weights='imagenet', include_top=False, input_shape=train_input_shape)","ab9267c1":"# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False","08a4a2d9":"# our layers - you can add more if you want\nx = vgg.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x) \npredictions = layers.Dense(2, activation='softmax')(x) # 2 since we have only 2 categories","42eccb9d":"model = Model(vgg.input, predictions)","8f72bcc9":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=predictions)\n\n# view the structure of the model\nmodel.summary()","19d52aaa":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='sparse_categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","fad42115":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   preprocessing_function=preprocess_input)\n\ntraining_generator = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_generator = test_datagen.flow_from_directory(valid_path,\n                                            target_size = (224, 224),\n                                            shuffle=False,\n                                            batch_size = 32,\n                                            class_mode = 'binary')","bfc0900d":"early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)","44fa2e15":"#Train the model\nr = model.fit_generator(\n  generator = training_generator,\n  validation_data = test_generator,\n  epochs = 25,\n  shuffle=True,\n  steps_per_epoch = 347 \/\/ 32,\n  validation_steps = 10,\n  use_multiprocessing=True,\n  callbacks = early_stop\n)","379a8e01":"#Plot train and test loss and Accuracy\nplt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(r.history['loss'], label='Training Loss')\nplt.plot(r.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(r.history['accuracy'], label='Training Accuracy')\nplt.plot(r.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Accuracy')","f0426fbf":"!mkdir models\n!mkdir models\/keras","82d87863":"# save\nmodel.save('models\/keras\/model.h5')","002297eb":"# load\nmodel = load_model('models\/keras\/model.h5')","38263667":"# save\nmodel.save_weights('models\/keras\/weights.h5')\nwith open('models\/keras\/architecture.json', 'w') as f:\n        f.write(model.to_json())","5cd5787d":"# load\nwith open('models\/keras\/architecture.json') as f:\n    model = model_from_json(f.read())\nmodel.load_weights('models\/keras\/weights.h5')\n","eab859e5":"validation_img_paths = [\"alien\/22.jpg\",\n                        \"predator\/33.jpg\",\n                       \"predator\/65.jpg\",\n                       \"alien\/60.jpg\",\n                       \"alien\/30.jpg\",\n                       \"predator\/3.jpg\"]\nimg_list = [Image.open(valid_path + img_path) for img_path in validation_img_paths]","1c7d8f68":"validation_batch = np.stack([preprocess_input(np.array(img.resize((224,224))))\n                             for img in img_list])","b781e915":"pred_probs = model.predict(validation_batch)\npred_probs","5ad3d12b":"fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\nfor i, img in enumerate(img_list):\n    ax = axs[i]\n    ax.axis('off')\n    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n                                                            100*pred_probs[i,1]))\n    ax.imshow(img)","79f8f6f5":"Display some images of Predators","54c2e1f1":"## To classify the image as Alien or Predator using Transfer Learning(VGG16)","e3efe6a5":"**Train the model**","0345eae3":"**Data Augmentation**\n\nData Augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. This technique like padding , cropping , shifting , flipping etc.\n\n**ImageDataGenerator()** the ImageDataGenerator accepts the original data, randomly transforms it, and returns only the new, transformed data.","0f54b63b":"**Tell the model what cost and optimization method to use**","11874143":"**Create a CNN network**","7c395d5f":"## Load all the required libraries","005b1368":"**Make prediction on random test images**","b2ee5880":"Display some images of Alien","d2f5ed53":"**Save and load the model**\n\nThis is for demonstration. You don't need to to so, if you intend to run predictions within this notebook.","9cd54894":"**Put early stopping criteria**","7a944c77":"Download the dataset : https:\/\/www.kaggle.com\/pmigdal\/alien-vs-predator-images","3294013f":"**Build Model**\n\nSo here in this part we are going to build model which train our data using state of the art technique like VGG16 model. I can use CNN(Convolutional Neural Network) but when I read the research paper that VGG16 network does a tremendous job on image data so let\u2019s begin this section.\n\nVGG16 model is also called identity layer why because the sole purpose of identity layer is skip-connection that means skip one layer in VGG16 model which helps reducing vanishing gradient problem\n\nThe VGG16 model is adapted to the 1000 categories of ImageNet. Our task, however, is to classify the images as alien or predator.\n\nWhat can we do? With keras, it's easy to import only the convolutional part of VGG16, by setting the include_top parameter to False :"}}