{"cell_type":{"bbd5bce7":"code","14e54d48":"code","f8f99fc2":"code","ad8da4d2":"code","39e19d56":"code","ee4aba8b":"code","3a3299f5":"code","dc13ea55":"code","cd63c3f8":"code","cfd2d62c":"code","c0ea3daf":"code","78d45cfc":"code","85d656ac":"code","d1071f51":"code","df9a6f3e":"code","412dda62":"code","ae301b58":"code","24860cca":"code","61b5ca64":"code","6848e865":"code","5f1e37ae":"code","6f115b65":"code","ccbee694":"code","a0fc91da":"markdown"},"source":{"bbd5bce7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport geopandas as gpd\nimport scipy as sp\nfrom scipy import stats\n\n\nimport folium\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\n\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\n%matplotlib inline\nmatplotlib.style.use('ggplot')\n\n\n%matplotlib inline\nrcparams = {'legend.fontsize': 'x-large',\n          'figure.figsize': (15, 5),\n         'axes.labelsize': 'x-large',\n         'axes.titlesize':'x-large',\n         'xtick.labelsize':'x-large',\n         'ytick.labelsize':'x-large'}\npylab.rcParams.update(rcparams)\nimport seaborn as sb\nsb.set_style('whitegrid')\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14e54d48":"#Input Geospatial data\ndata_fp = gpd.read_file(\"https:\/\/www.rowmaps.com\/jsons\/WO\/mutated1.json\", delimiter='|', axis=0)\ndata_fp.crs = {'init':'epsg:4326'}\ndata_br = gpd.read_file(\"https:\/\/www.rowmaps.com\/jsons\/WO\/mutated2.json\", delimiter='|', axis=0)\ndata_br.crs = {'init':'epsg:4326'}\ndata_rb = gpd.read_file(\"https:\/\/www.rowmaps.com\/jsons\/WO\/mutated3.json\", delimiter='|', axis=0)\ndata_rb.crs = {'init':'epsg:4326'}\ndata_bw = gpd.read_file(\"https:\/\/www.rowmaps.com\/jsons\/WO\/mutated4.json\", delimiter='|', axis=0)\ndata_bw.crs = {'init':'epsg:4326'}\n\n\nWorc_fp = gpd.GeoDataFrame(data_fp)\nWorc_br = gpd.GeoDataFrame(data_br)\nWorc_rb = gpd.GeoDataFrame(data_rb)\nWorc_bw = gpd.GeoDataFrame(data_bw)\n\n#import statistical data\ndf = pd.read_csv('http:\/\/www.rowmaps.com\/getcsv.php?council=WO&filename=augmented.kml&coordinates=lat-lons', sep = '|')","f8f99fc2":"#Before we look at the data in depth, let's define a function so we' don't have to keep typing our code out with other data sets.\n#The first function will allow us to quickly download and separate our data. We'll set the default to our file we're currently using\ndef sort_csv(URL):\n    df1 = pd.read_csv(URL, sep = '|')\n    print(df1)\n#We can then check it works  by inputting another link to a CSV file on rowmaps.com  \nsort_csv('http:\/\/www.rowmaps.com\/getcsv.php?council=GR&filename=augmented.kml&coordinates=lat-lons')","ad8da4d2":"#We could do this another way: descriptive statistics on the variable distance. This is measured in km\ndf_dist = pd.DataFrame(df['DISTANCE'])\nprint(\"The mean distance of all the PRoW is\", np.mean(df_dist))\nprint(\"The median distance of all the PRoW is\", np.median(df_dist))\nmode = stats.mode(df_dist)# need to get mode data from scipy\nprint(\"The modal distance of all the PRoW is {}\" \" with a count of {}\".format(mode.mode[0], mode.count[0]))\nprint(\"The variance of all the PRoW is\", np.var(df_dist))\nprint(\"The SD of all the PRoW is\", np.std(df_dist))\nprint(\"The SE of all the PRoW is\", stats.sem(df_dist))","39e19d56":"#Examine the GEOJSON and geospatial data\nWorc_fp","ee4aba8b":"#Plot the Footpaths for Worcestershire\nWorc_fp.plot()","3a3299f5":"\nWorc_fp.head()","dc13ea55":"#Map all of the RoW\nm_1 = folium.Map(location=[52.1962, -2.2749], tiles='openstreetmap', zoom_start=10)\nfolium.Choropleth(Worc_fp[Worc_fp.geometry.length>0.001],line_weight=1.5,\n    line_color='blue').add_to(m_1)\nfolium.Choropleth(Worc_br[Worc_br.geometry.length>0.001],line_weight=1.5,\n    line_color='red').add_to(m_1)\nfolium.Choropleth(Worc_rb[Worc_rb.geometry.length>0.001],line_weight=1.5,\n    line_color='orange').add_to(m_1)\nfolium.Choropleth(Worc_bw[Worc_bw.geometry.length>0.001],line_weight=1.5,\n    line_color='purple').add_to(m_1)\nm_1\n\n    ","cd63c3f8":"#define the read_geosjon function\ndef read_geojson(url_list, geog1, geog2): \n    for URL in url_list:\n        data_fp = gpd.read_file(URL, delimiter='|', axis=0)\n        data_fp.set_crs(epsg=4326)\n        data_br = gpd.read_file(URL, delimiter='|', axis=0)\n        data_br.set_crs(epsg=4326)\n        data_rb = gpd.read_file(URL, delimiter='|', axis=0)\n        data_rb.set_crs(epsg=4326)\n        data_bw = gpd.read_file(URL, delimiter='|', axis=0)\n        data_bw.set_crs(epsg=4326)\n    \n    \n    m_1 = folium.Map(location=[geog1, geog2], tiles='openstreetmap', zoom_start=10)\n    folium.Choropleth(data_fp[data_fp.geometry.length>0.001],line_weight=1.5,\n        line_color='blue').add_to(m_1)\n    folium.Choropleth(data_br[data_br.geometry.length>0.001],line_weight=1.5,\n        line_color='red').add_to(m_1)\n    folium.Choropleth(data_rb[data_rb.geometry.length>0.001],line_weight=1.5,\n        line_color='orange').add_to(m_1)\n    folium.Choropleth(data_bw[data_bw.geometry.length>0.001],line_weight=1.5,\n        line_color='purple').add_to(m_1)\nm_1\nread_geojson(['https:\/\/www.rowmaps.com\/jsons\/WO\/mutated1.json', 'https:\/\/www.rowmaps.com\/jsons\/WO\/mutated2.json','https:\/\/www.rowmaps.com\/jsons\/WO\/mutated3.json', 'https:\/\/www.rowmaps.com\/jsons\/WO\/mutated4.json'], 52.1962, -2.2749)","cfd2d62c":"# Isolate a path\npath1 =   Worc_fp.iloc[200].loc['Name']\npath1","c0ea3daf":"# print distances between two paths\nWO_Romsley_513 = Worc_fp.iloc[200]\npath1 =  Worc_fp.iloc[200].loc['Name']\npath2 =  Worc_fp.iloc[33].loc['Name']\nWO_Woverly_and_Cookley_553 = Worc_fp.iloc[33]\ndistances = WO_Romsley_513.geometry.distance(WO_Woverly_and_Cookley_553.geometry)\n\n\n\nprint(f'The distance from {path1} to {path2} is {round(distances*100)} km')\n","78d45cfc":"#let's run some code so we're only working with with a small number of datapoints just for distance.  \n#We'll then multiply that value by 100 and get the value in metres and then look at the first 10 values\n\nin_m_distance = df['DISTANCE']*100\n\nprint('Distance in Metres')\nprint(f'-'*40)\nprint(in_m_distance.head(n=10))","85d656ac":"#Lets set an index for our data. We'll use the 'UNIQUE' column since this gives each RoW a unique identifier anyway\ndf.index = df['UNIQUE']\ndf","d1071f51":"#Now let's look at some graphs of our data. First, a histogram to examine the distribution of the data. The only numeric value of interest is 'DISTANCE'\n#Let's plot this using a certain number of bars to represent our data. We'll divide it into 50 groups\ndf['DISTANCE'].hist(bins=50)\n#We can see our data is heavily skewed to shorter distances. This makes sense, footpaths tend to be dominant, but shorter, than other PRoW.","df9a6f3e":"# Now, let's look at a boxplot of the data to get a sense of which category of RoW has the largest distance\nsb.set_style(\"whitegrid\") \n  \nsb.boxplot(x = 'DISTANCE', y = 'ROW_TYPE', data = df) ","412dda62":"#on their own, they are not very useful data points! What if we look at them with other variables? \n#Let's do that by selecting ROW_TYPE and PARISH as well\ndf_path_type1 = df[['DISTANCE','ROW_TYPE', 'PARISH']]\n\nprint(df_path_type1)","ae301b58":"#now lets look at the type of right of way for each entry. We'll do the same as above and create a new variable called 'df_path_type'\ndf_path_type = df['ROW_TYPE']\npath_n = df['ROW_TYPE']\nfp_n = df[df['ROW_TYPE'] == 'Footpath']\nbw_n = df[df['ROW_TYPE'] == 'Bridleway']\nrb_n = df[df['ROW_TYPE'] == 'Restricted Byway']\nBOAT_n = df[df['ROW_TYPE'] == 'BOAT']\n\nfp_mean = fp_n['DISTANCE'].mean()*100\nbw_mean = bw_n['DISTANCE'].mean()*100\nrb_mean = rb_n['DISTANCE'].mean()*100\nBOAT_mean = BOAT_n['DISTANCE'].mean()*100\n\n#Let's now define a function that prints out the mean distance of each type of PRoW. \n#If we want to specify that we've changed the measurement to metres, we can do that with the .format() argument\n\ndef mean_metres():\n    print('the mean distance for Footpaths is {} m'.format(fp_mean))\n    print('the mean distance for Bridleways is {} m'.format(bw_mean))\n    print('the mean distance for Restricted Bridleways is {} m'.format(rb_mean))\n    print('the mean distance for BOATS {} m'.format(BOAT_mean))\n    \nmean_metres()","24860cca":"#We can group our data in different ways using Pandas .groupby function.\n#Let's use pandas to view the sum of the length of each amount of PRoW for each parish\ngrouped = df.groupby(['PARISH', 'ROW_TYPE'])['DISTANCE'].sum()\ngrouped\n#and we can count the total number of PRoW in each parish by type\ngrouped1 = df.groupby(['PARISH', 'ROW_TYPE'])['UNIQUE'].count()\ngrouped","61b5ca64":"#Now Let's examine how many PRoW are in the dataset by type and plot it\npath_by_parish = pd.DataFrame(df,columns=['PARISH', 'ROW_TYPE', 'DISTANCE'])\ntotal_row = path_by_parish.groupby('ROW_TYPE')['PARISH'].count()\ntotal_row.plot(kind='bar',)\nplt.title('Totals of PRoW in dataset')","6848e865":"#We're still interested in analysing distance. We can create a bar chart of the mean values of all of the ProW. Here, we'll create a list with the values 1-4, representing the type of PRoW. \n#Next, we'll create another list called values1 with the mean distance in metres of each footpath. \n#Finally, we'll add some details to our plot.\n\nnames = [1, 2, 3, 4]\nvalues1 = [fp_n['DISTANCE'].mean()*100,\nbw_n['DISTANCE'].mean()*100,\nrb_n['DISTANCE'].mean()*100,\nBOAT_n['DISTANCE'].mean()*100]\n\nplt.figure(figsize=(9, 3))\nplt.subplot()\nplt.ylabel('Distance m')\nplt.title('PRoW by Mean Distance in Metres')\nplt.bar(names, values1, color ='salmon', align='center', edgecolor ='blue', tick_label=['FP', 'BW', 'RB', 'BOAT',])\nplt.savefig('foo.png')","5f1e37ae":"#What if we want to select our dataframe by using a specific Parish? We can use the string match function\ndf_ABBERLEY = df[df['PARISH'].str.match('ABBERLEY')]\ndf_ABBERLEY","6f115b65":"read_geojson(['https:\/\/www.rowmaps.com\/jsons\/WO\/mutated1.json', 'https:\/\/www.rowmaps.com\/jsons\/WO\/mutated2.json','https:\/\/www.rowmaps.com\/jsons\/WO\/mutated3.json', 'https:\/\/www.rowmaps.com\/jsons\/WO\/mutated4.json'], 52.1962, -2.2749)","ccbee694":"#Isolate a single ROW\n    \npath1 =  Worc_fp.iloc[1]\npath2 =  Worc_fp.iloc[4]\nx,y = path1.geometry.coords.xy\ndf_coords = pd.DataFrame({'LAT':x,'LON':y})\ncoords2 = df_coords.iloc[0]['LAT']\ncoords1 = df_coords.iloc[0]['LON']\npath1_name =path1.loc['Name']\npath2_name = path2.loc['Name']\ndistances = path1.geometry.distance(path2.geometry)\nm_2 = folium.Map(location= [coords1, coords2], tiles='openstreetmap', zoom_start=17)\nfolium.Choropleth(path1.geometry,line_weight=1.5,\nline_color='blue').add_to(m_2)\nfolium.Choropleth(path2.geometry,line_weight=1.5,\nline_color='green').add_to(m_2)\nm_2","a0fc91da":"This is a notebook for reading, analysing and mapping public rights of way. Being able to ap Rights of Way is a useful skill but it's especially important in the UK with the [2026 deadline for Path Extinguishment](http:\/\/) fast approaching. on 1st January 2026 any Right of Way that is not properly registered will be extinguished (removed). This means that 1000s of km of paths and tracks will become illegal to walk, cycle and ride. The more we know about the distribution of Rights of Way in an area the easier it will be to identify at-risk routes and start protecting them. \n\nThis notebook takes preliminary steps towards identifying at risk routes. It does this by mapping, describing and classifying known Rights of Way.\n\nThe data used for this excercise uses offical records of Rights of Way. It is is publically available and has been collected by Barry Cornelius on www.rowmaps.com. It is,  by definition, incomplete. At-risk routes do not appear on definitive maps and statements which is where this data is sourced from. The routes we are most worried about will not be in this dataset. \n\nIf we wish to use Machine Learning to predict and locate at-risk rights of way then you will need to contact the Ramblers. They have a dataset on at-risk rights of way that has been collected by volunteers across the country. Please contact them for more information. E: DLYW@ramblers.zendesk.com\n"}}