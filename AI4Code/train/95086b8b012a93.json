{"cell_type":{"2d0b8e2f":"code","acbf8919":"code","e44cc194":"code","6832b448":"code","a5a0f8e4":"code","88513ff8":"code","890a5f91":"code","7e5bf578":"code","137fe13f":"code","2d55ba58":"code","bfb8d774":"code","41f8acec":"code","88f98d98":"code","c53aea54":"code","d68378f2":"code","edd9b8ad":"markdown","605043c8":"markdown","4abb1a5d":"markdown","2c62eccb":"markdown","8c35ce1b":"markdown","18f509e2":"markdown","f934d49d":"markdown","725b7060":"markdown","99a0f508":"markdown"},"source":{"2d0b8e2f":"!pip install tfjs-graph-converter","acbf8919":"!git clone https:\/\/github.com\/rkuo2000\/posenet-python\n%cd posenet-python","e44cc194":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom posenet.posenet_factory import load_model\nimport posenet","6832b448":"modelname = 'resnet50'  # mobilenet resnet50\nstride = 32 # 8, 16, 32 (max 16 for mobilenet, min 16 for resnet50)\nquant_bytes = 4  # float\nmultiplier = 1.0  # only for mobilenet\nnet = load_model(modelname, stride, quant_bytes, multiplier)","a5a0f8e4":"#file = '\/kaggle\/input\/input-images\/persons.jpg'\n#file = '\/kaggle\/input\/input-images\/facemask.jpg'\nfile = '\/kaggle\/input\/input-images\/facemask1.jpg'","88513ff8":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","890a5f91":"# read image\nimg = plt.imread(file)\nplt.imshow(img)\nplt.show()","7e5bf578":"# detect pose keypoints\npose_scores, keypoint_scores, keypoint_coords = net.estimate_multiple_poses(img)","137fe13f":"# read image\nimage = plt.imread(file)\n\nbboxes = []\n# find face keypoints & detect face mask\nfor pi in range(len(pose_scores)):\n    if pose_scores[pi] != 0.:\n        print('Pose #%d, score = %f' % (pi, pose_scores[pi]))       \n        keypoint_coords = keypoint_coords.astype(np.int32) # convert float to integer\n        #print(keypoint_coords[pi,:5]) # print out first 5 keypoint coords\n\n        # find bounding box\n        (y1,x1) = keypoint_coords[pi,:5].min(axis=0) # find min of x,y\n        (y2,x2) = keypoint_coords[pi,:5].max(axis=0) # find max of x,y\n        print(x1,y1,x2,y2)\n        bboxes.append([x1,y1,x2,y2])\n        # draw keypoints on image\n        for coord in keypoint_coords[pi,:5]:            \n            (y,x)=coord                                 # keypoint coordinate = [y,x]\n            cv2.circle(image, (x,y), 3, (255,255,255), 1) # draw circle on keypoints\nprint(\"--- bounding box ---\")\nprint(bboxes)","2d55ba58":"for bbox in bboxes:\n    x1,y1,x2,y2 = bbox\n    w = x2-x1\n    cv2.rectangle(image, (x1,y1-int(w\/2)), (x2,y2+int(w\/2)), (0,255,0), 2)\n\nplt.imshow(image)\nplt.show()","bfb8d774":"# load FaceMask-CNN model\nmodel = keras.models.load_model('\/kaggle\/input\/facemask-model\/facemask_cnn.h5')","41f8acec":"labels = ['With Mask', 'No Mask']","88f98d98":"img = plt.imread(file)","c53aea54":"for bbox in bboxes:\n    x1,y1,x2,y2 = bbox\n    \n    # extend y1,y2 to cover entire face\n    w = x2-x1 # face width        \n    y1 = y1 - int(w\/2) \n    y2 = y2 + int(w\/2) \n        \n    # convert roi to x_test \n    roi = img[y1:y2, x1:x2]\n    roi = cv2.resize(roi, (96,96))\n        \n    # show roi\n    plt.imshow(roi)\n    plt.show()\n        \n    # normalized data\n    x_test = roi\/255.0\n    x_test = x_test.reshape(-1,96,96,3)\n        \n    # model predict\n    preds = model.predict(x_test)\n    maxindex = int(np.argmax(preds))\n    #print(preds[0][maxindex], labels[maxindex]) # print accuracy & label\n    txt = labels[maxindex]\n    acc = str(int(preds[0][maxindex] * 100))+'%'    \n        \n    # draw box for detected face in the image\n    cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2) # draw box, thickness=2\n    cv2.putText(img, txt, (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2) # font scale=0.5, thickness=2\n    cv2.putText(img, acc, (x1,y2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2) # font scale=0.5, thickness=2\n\n        \n# save image to a file\nplt.imsave('.\/detected.jpg', img)","d68378f2":"# display detected image\nfrom IPython.display import Image\nImage('.\/detected.jpg')","edd9b8ad":"### Pose Detection","605043c8":"## Face Detection : PoseNet ","4abb1a5d":"# PoseNet Face Mask Detection","2c62eccb":"### Detect Poses","8c35ce1b":"## Mask Detection : FaceMask-CNN","18f509e2":"## Face Detection : PoseNet","f934d49d":"### find keypoint coordinates in poses","725b7060":"### Repro [Github](https:\/\/github.com\/atomicbits\/posenet-python) for TF.2x","99a0f508":"### load PoseNet model"}}