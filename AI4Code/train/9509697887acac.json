{"cell_type":{"62cddcf7":"code","bdb0aece":"code","74b6483a":"code","4e16c0d4":"code","e1e5549a":"code","82d9ead8":"code","ea6df6b9":"code","2a456c91":"code","9e54242f":"code","4854a4a5":"code","cb474e53":"code","12331bd1":"code","c7200ee8":"code","74d4a03f":"code","3aa88e00":"code","25b61b1b":"code","9f58e8bd":"code","4c9bc4bd":"code","18524150":"code","1e59c318":"code","c9eb2bbc":"code","ce6c1ea3":"code","06d9ff5e":"code","146c39c6":"code","534c46ae":"code","0530b1de":"code","1723ee9a":"code","090852e8":"code","d1c03e2d":"code","842449d4":"code","1998d697":"markdown","a3650633":"markdown","3d5cc67c":"markdown","ae3b2cfe":"markdown","c219a331":"markdown","1294ae09":"markdown","f1b52928":"markdown","849af990":"markdown","dce63584":"markdown","2415aa1a":"markdown","cb59d3bc":"markdown","da790820":"markdown","cdfeec01":"markdown","da0dfd97":"markdown","70ce95f5":"markdown","9acb3292":"markdown"},"source":{"62cddcf7":"import os\nimport librosa\nimport numpy as np\nimport json","bdb0aece":"data_covid = {}\ndata_healthy = {}","74b6483a":"read = [\"zero_crossing\", \"stft\", \"spectral_centroid\", \"spectral_bandwith\", \n               \"rms\", \"envelope\", \"mfcc13\", \"mfcc13_delta\", \"mfcc13_delta2\"]","4e16c0d4":"path = \"..\/input\/covid-dataset\"\nfor i in os.listdir(path):\n  name = \"_\".join(i.split(\"_\")[:-1]) \n  if name in read:\n    if i.split(\"_\")[-1] == \"covid.json\":\n      with open(f\"{path}\/{i}\", \"r\") as file:\n        data_covid[name] = np.array(json.load(file), dtype=np.float32)\n    else:\n      with open(f\"{path}\/{i}\", \"r\") as file:\n        data_healthy[name] = np.array(json.load(file), dtype=np.float32)","e1e5549a":"def get_data(label, data):\n  for i in range(data[read[0]].shape[0]):\n    a = data[read[0]][i]\n    for k in read:\n      a = np.vstack((a, data[k][i]))\n    size = data[read[0]][i].shape\n    if len(size) > 1:\n        size = size[0]\n    else:\n        size = 1\n    a = a[size:]\n    X.append(a)\n    y.append(label)","82d9ead8":"labels = {\"Covid\" : 0 , \"Healthy\" : 1}","ea6df6b9":"X = []\ny = []\nget_data(labels[\"Covid\"],data_covid)\nget_data(labels[\"Healthy\"],data_healthy)\nX = np.array(X, dtype=np.float32)\nX.shape","2a456c91":"y = np.array(y).reshape(-1,1)\ny.shape, X.shape","9e54242f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)","4854a4a5":"X_train, X_test = X_train[..., np.newaxis], X_test[...,np.newaxis]\nX_train.shape, X_test.shape","cb474e53":"from tensorflow.keras.utils import to_categorical\ny_train_2, y_test_2 = y_train.copy(), y_test.copy()\ny_train, y_test = to_categorical(y_train) , to_categorical(y_test)","12331bd1":"import tensorflow as tf\nfrom tensorflow import keras\nimport gc\nhistory = []\ndef get_model():\n    # CNN\n    \n    model = keras.Sequential()\n\n    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)) )\n    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(64, activation='relu'))\n    model.add(keras.layers.Dropout(0.3))\n\n    model.add(keras.layers.Dense(2, activation='softmax'))\n\n    optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n    model.compile(optimizer=optimiser,\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    return model","c7200ee8":"import matplotlib.pyplot as plt\ndef plot_history(history):\n    plt.plot(history.history['categorical_accuracy'])\n    plt.plot(history.history['val_categorical_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","74d4a03f":"model = get_model()\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=20)\ngc.collect()","3aa88e00":"plot_history(history)","25b61b1b":"def print_classification_report():\n    pred = model.predict(X_test)\n    y_pred = []\n    for i in range(pred.shape[0]):\n      index = -1\n      maxVal = 0\n      for j in range(pred.shape[1]):\n        if pred[i][j] > maxVal:\n          index = j\n          maxVal = pred[i][j]\n      y_pred.append(index)\n    from sklearn.metrics import classification_report\n    print(classification_report(y_test_2, y_pred))\nprint_classification_report()","9f58e8bd":"read = [\"mfcc13\"]\n\nX = []\ny = []\nget_data(labels[\"Covid\"],data_covid)\nget_data(labels[\"Healthy\"],data_healthy)\nX = np.array(X, dtype=np.float32)\n\ny = np.array(y).reshape(-1,1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n\nX_train, X_test = X_train[..., np.newaxis], X_test[...,np.newaxis]\n\ny_train_2, y_test_2 = y_train.copy(), y_test.copy()\ny_train, y_test = to_categorical(y_train) , to_categorical(y_test)\n\nmodel = get_model()\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=20)\n\nplot_history(history)","4c9bc4bd":"print_classification_report()","18524150":"import matplotlib.pyplot as plt\n\ncounts = [0] * len(labels)\nfor i in y_train_2:\n    counts[i[0]] += 1\n\nnames = list(labels.keys())\n\nplt.figure(figsize=(9, 3))\n\nplt.bar(names, counts)","1e59c318":"from imblearn.over_sampling import SMOTE ","c9eb2bbc":"X_train.shape","ce6c1ea3":"X_train = np.reshape(X_train, (X_train.shape[0], int(X_train.shape[1] * X_train.shape[2])))\nX_train.shape","06d9ff5e":"sm = SMOTE()\nX_train , y_train = sm.fit_resample(X_train, y_train)","146c39c6":"X_train.shape","534c46ae":"X_train = np.reshape(X_train, (X_train.shape[0],  13, 216, 1))\nX_train.shape","0530b1de":"y_train_2 = []\nfor i in range(len(y_train)):\n    y_train_2.append(y_train[i][0])","1723ee9a":"import matplotlib.pyplot as plt\n\ncounts = [0] * len(labels)\nfor i in y_train_2:\n    counts[i] += 1\n\nnames = list(labels.keys())\n\nplt.figure(figsize=(9, 3))\n\nplt.bar(names, counts)","090852e8":"y_train = to_categorical(y_train)","d1c03e2d":"model = get_model()\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=20)\n\nplot_history(history)","842449d4":"print_classification_report()","1998d697":"SMOTE does not work for 3d arrays.","a3650633":"SMOTE algorithm balanced data for train set","3d5cc67c":"F1-Scores improved with SMOTE algorithm","ae3b2cfe":"I extracted this audio features from Librosa library. You can get more information about audio features from [librosa documentation](https:\/\/librosa.org\/doc\/latest\/index.html).","c219a331":"### SMOTE Algorithm","1294ae09":"### Train Data","f1b52928":"### Plot History","849af990":"### Try with MFCC feature only","dce63584":"This results more healthy than previous results","2415aa1a":"SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem.","cb59d3bc":"### Prepare Data For Model Train","da790820":"OK, Our shape is (25998, 45, 216)\n\nShape-2 is about audio features\n\n0 : Amplitude-Envelope\n\n1 : RMS\n\n2 : Zero Crossing\n\n3 : STFT\n\n4-16 : MFCC\n\n17-29 : MFCC-Delta\n\n30-42 : MFCC-Delta-2 (Order:2)\n\n43: Spectral Centroid\n\n44: Spectral Bandwith\n","cdfeec01":"It takes some time (about 5 minutes)","da0dfd97":"### Read Jsons","70ce95f5":"As you can see our train set has unbalanced data. We try SMOTE algorithm to balance data.","9acb3292":"It takes some time. (about 4-5 minutes)"}}