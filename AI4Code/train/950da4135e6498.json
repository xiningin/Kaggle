{"cell_type":{"6a70aa56":"code","53c2ec67":"code","f0646f13":"code","14423aa4":"code","90df08cc":"code","f9b63899":"code","e26bdebd":"code","970863bd":"code","30bd6e39":"code","42f62cf8":"code","b5580597":"code","b27d9e31":"markdown","97777a4c":"markdown","39ad4897":"markdown","84c317d4":"markdown","67226732":"markdown","39b8d5f5":"markdown","58bc8249":"markdown","4281c1a6":"markdown","b7240563":"markdown"},"source":{"6a70aa56":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","53c2ec67":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import SGD","f0646f13":"train_images = pd.read_csv('..\/input\/ahcd1\/csvTrainImages 13440x1024.csv')\ntrain_label = pd.read_csv('..\/input\/ahcd1\/csvTrainLabel 13440x1.csv')\n\ntest_images = pd.read_csv('..\/input\/ahcd1\/csvTestImages 3360x1024.csv')\ntest_label = pd.read_csv('..\/input\/ahcd1\/csvTestLabel 3360x1.csv')","14423aa4":"X_train = train_images.to_numpy()\ny_train = train_label.to_numpy()\n\nX_test = test_images.to_numpy()\ny_test = test_label.to_numpy()","90df08cc":"nr_classes = len(np.unique(train_label))","f9b63899":"X_train = X_train.reshape(13439, 32, 32, 1)\ny_train = tf.keras.backend.one_hot(y_train, nr_classes)\ny_train = y_train.numpy().reshape(13439, 28)\n\nX_test = X_test.reshape(3359, 32, 32, 1)\ny_test = tf.keras.backend.one_hot(y_test, nr_classes)\ny_test = y_test.numpy().reshape(3359, 28)","e26bdebd":"# Instantiate an empty sequential model\nmodel = Sequential()\n# C1 Convolutional Layer\nmodel.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'tanh',\ninput_shape = (32,32,1), padding = 'same'))\n \n# S2 Pooling Layer\nmodel.add(AveragePooling2D(pool_size = 2, strides = 2, padding = 'valid'))\n \n# C3 Convolutional Layer\nmodel.add(Conv2D(filters = 16, kernel_size = 5, strides = 1,activation = 'tanh',\npadding = 'valid'))\n# S4 Pooling Layer\nmodel.add(AveragePooling2D(pool_size = 2, strides = 2, padding = 'valid'))\n \n# C5 Convolutional Layer\nmodel.add(Conv2D(filters = 120, kernel_size = 5, strides = 1,activation = 'tanh',\npadding = 'valid'))\n \n# Flatten the CNN output to feed it with fully connected layers\nmodel.add(Flatten())\n \n# FC6 Fully Connected Layer\nmodel.add(Dense(units = 84, activation = 'tanh'))\n \n# FC7 Output layer with softmax activation\nmodel.add(Dense(units = 28, activation = 'softmax'))\n \n# print the model summary\nmodel.summary()","970863bd":"def lr_schedule(epoch):\n    # initiate the learning rate with value = 0.0005\n    lr = 5e-4\n    # lr = 0.0005 for the first two epochs, 0.0002 for the next three epochs,\n    # 0.00005 for the next four, then 0.00001 thereafter.\n    if epoch > 2:\n        lr = 2e-4\n    elif epoch > 5:\n        lr = 5e-5\n    elif epoch > 9:\n        lr = 1e-5\n    return lr","30bd6e39":"model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=lr_schedule(0)), metrics=['accuracy'])","42f62cf8":"hist = model.fit(X_train, y_train, batch_size=124, epochs=500,\nvalidation_data=(X_test, y_test), verbose=0, shuffle=True)","b5580597":"plt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","b27d9e31":"<a id='goal'><\/a>\n# Goal\n\nThe goal of this notebook is to use LeNet-5 in order to train a model to recognize arabic handwritten characters.<br>\n<br>\n### What is LeNet ?\nLeNet is a convolutional neural network structure proposed by Yann LeCun et al. in 1998. In general, LeNet refers to lenet-5 and is a simple convolutional neural network. Convolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing.\n<br>\n### Reference\nhttps:\/\/en.wikipedia.org\/wiki\/LeNet","97777a4c":"<img align=left src=\"https:\/\/dpzbhybb2pdcj.cloudfront.net\/elgendy\/v-8\/Figures\/05-06_img_0032.png\" \/>\n<br><br><br><br><br><br><br><br><br>\nWe use the original mnist architecture but instead of numbers, we train with arabic alphabet.","39ad4897":"<a id='conclusion'><\/a>\n# Conclusion","84c317d4":"<a id='architecture'><\/a>\n# Architecture","67226732":"# CNN Arabic Handwritten using Keras and <br>LeNet-5 Architecture","39b8d5f5":"<a id='preparation'><\/a>\n# Data Preparation","58bc8249":"## **Table content**\n- [Goal](#goal)\n- [Data Preparation](#preparation)\n- [Architecture](#architecture)\n- [Implementation](#implementation)\n- [Conclusion](#conclusion)","4281c1a6":"<img align=left width=500 src='https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/5\/50\/Birmingham_Quran_manuscript.jpg\/1920px-Birmingham_Quran_manuscript.jpg'\/>","b7240563":"<a id='implementation'><\/a>\n# Implementation"}}