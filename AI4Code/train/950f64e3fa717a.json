{"cell_type":{"627de9a0":"code","7147b85d":"code","7dc74e0f":"code","b519985e":"code","1dc3e37a":"code","ba9fb176":"code","24a1e222":"code","a3ed0947":"code","c91b1277":"code","dc975162":"code","e6618dfe":"code","a6f8a55b":"code","c1b40605":"code","32066cfe":"code","5cc6d3ae":"code","c18c7922":"code","2bbdf039":"code","24ef7828":"code","910b25f0":"code","1967b1c1":"code","3b72a2ec":"code","0a66922e":"code","18c49ca4":"code","ff20e773":"code","232d5fb1":"code","2117f879":"code","e80fd4c9":"code","5ba11457":"code","7ff26425":"code","6e123262":"code","acb51730":"code","8e8eefd7":"code","260652bb":"code","722a167f":"code","bbd1e6be":"code","fbafab5e":"code","2c784515":"code","298a3077":"code","27373e84":"code","5944b282":"code","5047f179":"code","9b9662f9":"code","aa7ff690":"code","20cea5a8":"markdown","ed242e71":"markdown","d09ab605":"markdown","4e9856ff":"markdown","7d4eed46":"markdown","49a3121f":"markdown","c60bf274":"markdown","01ab42c2":"markdown","d5a02e25":"markdown","d0597f72":"markdown","2b373058":"markdown","d366ed91":"markdown","1bfa73f5":"markdown","a4b79418":"markdown","f22c70cf":"markdown","7c293d93":"markdown","754dfe14":"markdown","b25ac49b":"markdown","87b1d6bd":"markdown","5a8e4ac2":"markdown","9960f7ef":"markdown","7a431e6c":"markdown","877528d5":"markdown","5be665fc":"markdown","c987e367":"markdown","fc9ebe96":"markdown","50978905":"markdown","08dc0081":"markdown","0c3d6532":"markdown","665bca1d":"markdown","38d20c4b":"markdown","e654bec5":"markdown","2328bca5":"markdown","26c18c24":"markdown","e2bc64e0":"markdown","8a0be525":"markdown","ebbc1375":"markdown","bd250fb5":"markdown","16172480":"markdown","7a2e714c":"markdown","0d47cbfc":"markdown","1efa8986":"markdown","26045147":"markdown","779713ca":"markdown","4b36ca50":"markdown","1ab4859d":"markdown","6b5097c2":"markdown","e6b87f71":"markdown","75f5c2f8":"markdown","3be4f33c":"markdown","2472b57d":"markdown","1e539ec4":"markdown","c9581812":"markdown","149045d5":"markdown","404d197c":"markdown","0d946ee0":"markdown","041df785":"markdown","76d76cf7":"markdown","10e631ed":"markdown"},"source":{"627de9a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings as wrn\n\nwrn.filterwarnings('ignore')\nsns.set_style(\"whitegrid\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7147b85d":"data = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\n","7dc74e0f":"data.head()","b519985e":"data.info()","1dc3e37a":"data[\"Pregnancies\"].value_counts()","ba9fb176":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","24a1e222":"data[\"Glucose\"].head()","a3ed0947":"fig,ax = plt.subplots(figsize = (10,7))\nsns.distplot(data[\"Glucose\"],color=\"#FE5205\")\nplt.show()","c91b1277":"data[\"BloodPressure\"].head(10)","dc975162":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BloodPressure\"],color=\"#00B037\")\nplt.show()","e6618dfe":"data[\"SkinThickness\"].head(10)","a6f8a55b":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"SkinThickness\"],color=\"#C0F714\")\nplt.show()","c1b40605":"data[\"Insulin\"].head(10)","32066cfe":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Insulin\"],color=\"#077F8F\")\nplt.show()","5cc6d3ae":"data[\"BMI\"].head(10)","c18c7922":"plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BMI\"],color=\"#DB6A14\")\nplt.show()","2bbdf039":"data[\"DiabetesPedigreeFunction\"].head()","24ef7828":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"DiabetesPedigreeFunction\"],color=\"#8F105A\")\nplt.show()","910b25f0":"data[\"Age\"].head(10)","1967b1c1":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Age\"],color=\"#DB620D\")\nplt.show()","3b72a2ec":"data[\"Outcome\"].value_counts()","0a66922e":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Outcome\"])\nplt.show()","18c49ca4":"def outlier_dropper(dataset):\n    check_index = []\n    final_index = []\n    for feature in dataset: # Each iteration is a different feature\n        \n        Q1 = dataset[feature].describe()[\"25%\"] # Lower Quartile\n        Q3 = dataset[feature].describe()[\"75%\"] # Upper Quartile\n        \n        IQR = Q3-Q1\n        STEP = IQR*1.5\n        \n        \n        indexes = data[(data[feature]<Q1-IQR) | (data[feature]>Q3+IQR)].index.values # Taking outlier's indexes.\n        \n        for i in indexes:  \n            check_index.append(i) # Appending each index into the check_index list.\n    \n    for i in check_index:        \n        check_index.remove(i)\n        if i in check_index: # If i still exists (If there is two outliers in the i index)\n            final_index.append(i) # Append it.\n    \n    return np.unique(final_index)","ff20e773":"indexes = outlier_dropper(data)\nprint(indexes)\nprint(\"------------------------------------------------------------------------------\")\nprint(len(indexes))","232d5fb1":"data.drop(indexes,inplace=True)","2117f879":"data.info()","e80fd4c9":"fig,ax = plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True,fmt=\".2f\",linewidths=1.5)\nplt.show()","5ba11457":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Glucose\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Glucose\"],data[\"Outcome\"])\nplt.show()","7ff26425":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Outcome\"],data[\"Age\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Outcome\"],data[\"Age\"])\nplt.show()","6e123262":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"BMI\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"BMI\"],data[\"Outcome\"])\nplt.show()","acb51730":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","8e8eefd7":"pregnancies = []\n\nfor i in data[\"Pregnancies\"]:\n    \n    if i==11 or i==12 or i==13 or i==14 or i==15 or i==17:\n        pregnancies.append(11)\n    \n    else:\n        pregnancies.append(i)\n\ndata.Pregnancies = pregnancies","260652bb":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","722a167f":"data = pd.get_dummies(data,columns=[\"Pregnancies\"])\ndata.head()","bbd1e6be":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nx = data.drop(\"Outcome\",axis=1)\ny = data.Outcome\n\nx = scaler.fit_transform(x)","fbafab5e":"print(\"Shape of x\",x.shape)\ny = y.values\nprint(\"Shape of y\",y.shape)","2c784515":"y = y.reshape(-1,1)","298a3077":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=1)","27373e84":"from keras.layers import Dropout,Dense\nfrom keras.models import Sequential","5944b282":"model = Sequential()\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\",input_dim=19)) # Layer 1\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 2\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 3\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 4 \nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 5\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 6\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 7\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=1,kernel_initializer=\"uniform\",activation=\"sigmoid\")) # Output Layer\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","5047f179":"model.fit(x_train,y_train,epochs=250)","9b9662f9":"from sklearn.metrics import accuracy_score\ny_head = model.predict_classes(x_test)\n\nprint(\"The score is \",accuracy_score(y_test,y_head))","aa7ff690":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,y_head)\n\nfig,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(confusion_matrix,annot=True,fmt=\"0.1f\",cmap=\"Greens_r\",linewidths=1.5)\nplt.show()","20cea5a8":"## Examining Glucose Feature","ed242e71":"* Outcome feature is our label.\n* It is a categorical feature, so we can use count plot.","d09ab605":"# Predicting\nIn this section I will predict the values using our model and after that I will take a look at the confusion matrix and the score.","4e9856ff":"# Data Overview\nIn this section I will get a general idea about the dataset.","7d4eed46":"## Examining Pregnancies Feature","49a3121f":"## Train Test Splitting\nIn this section I will split the data into train and test. In order to do this I will use SKLearn library's train_test_split","c60bf274":"* And now let's use our function.","01ab42c2":"* Let's start with reminding the feature","d5a02e25":"* This feature is not a categorical like the Blood Pressure and Glucose","d0597f72":"* Although there are 17 unique values, most of them is 1,0 and 2. \n* We can join 11,12,13,14,15 and 17.\n","2b373058":"I've created x and y in this section, because I don't want to normalize y axis.","d366ed91":"* This is not a categorical feature as well. \n* So let's use a distplot.","1bfa73f5":"* Although most of the dataset between 0 and 1, there are values between 1 and 2.5","a4b79418":"* This is an unbalanced data.\n* Most of the values are 0 \n* They are 500 0 values and 268 1 values.","f22c70cf":"## Defining Function","7c293d93":"# Introduction\nHello people, welcome to my kernel. In this kernel I'll examine the dataset and after that, I will train a neural network using the dataset. Before the start, let's take a look at the content\n\n# Content\n1. Importing Libraries and The Data\n1. Data Overview\n1. Simple Data Analyses\n    * Examining Pragnancies Feature\n    * Examining Glucose Feature\n    * Examining Blood Pressure Feature\n    * Examining Skin Thickness Feature\n    * Examining Insulin Feature\n    * Examining BMI Feature\n    * Examining DiabetesPedigreeFunction Feature\n    * Examining Age Feature\n    * Examining Outcome Feature\n1. Outlier Detection\n    * Defining Function\n    * Dropping Outliers\n1. Detailed Data Analyses\n    * Correlation Heatmap\n    * Glucose - Outcome\n    * BMI - Outcome\n    * Age - Outcome\n1. Preprocessing\n    * Preparing Pregnancies Feature\n    * Normalization\n    * Train Test Split\n1. Modeling\n1. Predictinig\n1. Conclusion","754dfe14":"* Most of the dataset's value must be 0.","b25ac49b":"* Before the joining, let's remind the countplot of pregnancies feature.","87b1d6bd":"* When outcome is 1, glucose is bigger than 100. ","5a8e4ac2":"* Most of the values are between 70 and 130. ","9960f7ef":"* There are 9 features in the dataset.","7a431e6c":"# Importing Libraries and The Dataset\n\nIn this section I will import the libraries and the dataset. I am not going to import deep learning libraries, I am going to import them when I will need. ","877528d5":"* As we can see, glucose data is not categorical, so we should use a distplot for examining it.","5be665fc":"* Finally we are ready for modeling!","c987e367":"## Examining BMI Feature\n","fc9ebe96":"## Dropping Outliers\n","50978905":"* Model had difficulty when it predict 1 values. \n* It is a predictible result, because you will remember, the number of 1 values in the dataset is lower than 0 values.","08dc0081":"* There are 47 rows in the dataset that have outliers more than one.","0c3d6532":"# Preprocessing\nIn this section I am going to preapre the dataset for modeling. In order to prepare the dataset. I will follow these steps:\n\n* Preparing Pregnancies Feature\n    * Joinining 11,12,13,14,15,17\n    * One Hot Encoding\n* Normalization\n* Train Test Splitting","665bca1d":"## DiabetesPedigreeFunction Feature\n","38d20c4b":"* Most of the dataset between 20 and 40.","e654bec5":"## BMI - Outcome","2328bca5":"* And now I will check countplot again.","26c18c24":"* Now we have 721 entries.","e2bc64e0":"* And now I'll import the data.","8a0be525":"* Not an interesting distplot\n* Most of the values are between 20 and 50.","ebbc1375":"## Normalization (Scaling)\n\nAnd now I am going to normalize data because if we normalize the data, training time will be better.","bd250fb5":"## Glucose - Outcome","16172480":"## Examining Insulin Feature","7a2e714c":"## Age - Outcome","0d47cbfc":"* They are three strong correlation between outcome and other features\n\n* Glucose - Outcome (0.46)\n* Age - Outcome (0.24)\n* BMI - Outcome (0.29)\n\nLet's examine them using different plots.","1efa8986":"## Examining Skin Thickness Feature","26045147":"* An interesting chart. There are may 0 values in the dataset. However values that between 0 and 40 are very rare.\n* And most of the dataset is between 40 and 100 especially 60 and 80\n","779713ca":"# Conclusion\n\nThanks for your attention, if you have any questions in your mind, you can ask me in the comment section. I am waiting for your comments, questions and upvotes. \n","4b36ca50":"## Examining Outcome Feature","1ab4859d":"* The values are between 0 and 60. Most of the dataset's value is 0. ","6b5097c2":"* Okey, we are ready one hot encoding","e6b87f71":"## Examining Blood Pressure Feature","75f5c2f8":"* All of the features are numerical. 6 of them are int and the rest are float.\n* There is no missing values.\n* There are 768 rows in the dataset.","3be4f33c":"## Preparing Pregnancies Feature\n\n### Joining 11,12,13,14,15,17 ","2472b57d":"### One Hot Encoding","1e539ec4":"## Examining Age Feature\n","c9581812":"* Not bad but not good.","149045d5":"* Most of the dataset is 0\n* Although they are rare, there are values between 0 and 400.\n","404d197c":"# Outlier Detection\nIn this section I will drop the outliers, because you know, outliers can cause trouble. I am going to drop outliers using a handwritten function so let's start with defining the function.","0d946ee0":"# Simple Data Analyses\n\nIn this section I will examine each feature's value's distribution. In order to do this I am going to use distplots and count plots.","041df785":"# Detailed Data Analyses\nIn this section I am going to examine the correlations between the features. I am going to start with examining the correlation heatmap.","76d76cf7":"# Modeling\nIn this section I'll build the model using Keras library and after that I will fit it using our x_train and y_train.","10e631ed":"* Our frame is ready, let's fit it using our train arrays."}}