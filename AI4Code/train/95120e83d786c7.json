{"cell_type":{"e79a4867":"code","51f47f53":"code","cd8e16e1":"code","d9381b01":"code","be8e4de7":"code","cbf25810":"code","253c34a8":"code","23991eb6":"code","96d1e340":"code","b4aa9222":"code","e7c3b371":"code","f473abf4":"code","3e343726":"code","c7a1fb8c":"code","0e4fdbe8":"code","3c5e822f":"code","45686582":"markdown","19f4259e":"markdown","12187cf3":"markdown","951c25e2":"markdown","76508309":"markdown","b2013c75":"markdown","64a54fac":"markdown","5330d25d":"markdown","7003b43e":"markdown","39b14033":"markdown","e56e0cea":"markdown","f1268b3d":"markdown","b1cd5829":"markdown","14dcfa9e":"markdown","a938b6de":"markdown","b5bbefcc":"markdown"},"source":{"e79a4867":"import time\nimport copy\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\ntorch.manual_seed(17)","51f47f53":"transform = transforms.Compose([ \n    transforms.Resize((224, 224)), \n    transforms.ToTensor()\n])","cd8e16e1":"dataset = torchvision.datasets.ImageFolder('..\/input\/tiny-imagenet\/tiny-imagenet-200\/train', transform=transform)","d9381b01":"#split the data\ntrain_data, val_data, test_data = torch.utils.data.random_split(dataset, [80000, 10000, 10000])","be8e4de7":"batch_size = 32\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)","cbf25810":"from torchvision.utils import make_grid\n\nfor images, _ in train_loader:\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0)))\n    break","253c34a8":"class Inception(nn.Module):\n    \n    def __init__(self, in_channels=3, use_auxiliary=True, num_classes=1000):\n        super(Inception, self).__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n        \n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n        \n        self.dropout = nn.Dropout(0.4)\n        self.linear = nn.Linear(1024, num_classes)\n        \n        self.use_auxiliary = use_auxiliary\n        if use_auxiliary:\n            self.auxiliary4a = Auxiliary(512, num_classes)\n            self.auxiliary4d = Auxiliary(528, num_classes)\n        \n        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n    def forward(self, x):\n        y = None\n        z = None\n        \n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.maxpool(x)\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool(x)\n        \n        x = self.inception4a(x)\n        if self.training and self.use_auxiliary:\n            y = self.auxiliary4a(x)\n        \n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        if self.training and self.use_auxiliary:\n            z = self.auxiliary4d(x)\n        \n        x = self.inception4e(x)\n        x = self.maxpool(x)\n        \n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.dropout(x)\n        \n        x = self.linear(x)\n        \n        return x, y, z","23991eb6":"class ConvBlock(nn.Module):\n    \n    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))","96d1e340":"class InceptionBlock(nn.Module):\n    \n    def __init__(self, im_channels, num_1x1, num_3x3_red, num_3x3, num_5x5_red, num_5x5, num_pool_proj):\n        super(InceptionBlock, self).__init__()\n        \n        self.one_by_one = ConvBlock(im_channels, num_1x1, kernel_size=1)\n        \n        self.tree_by_three_red = ConvBlock(im_channels, num_3x3_red, kernel_size=1)  \n        self.tree_by_three = ConvBlock(num_3x3_red, num_3x3, kernel_size=3, padding=1)\n        \n        self.five_by_five_red = ConvBlock(im_channels, num_5x5_red, kernel_size=1)\n        self.five_by_five = ConvBlock(num_5x5_red, num_5x5, kernel_size=5, padding=2)\n        \n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n        self.pool_proj = ConvBlock(im_channels, num_pool_proj, kernel_size=1)\n         \n    def forward(self, x):\n        x1 = self.one_by_one(x)\n        \n        x2 = self.tree_by_three_red(x)\n        x2 = self.tree_by_three(x2)\n        \n        x3 = self.five_by_five_red(x)\n        x3 = self.five_by_five(x3)\n        \n        x4 = self.maxpool(x)\n        x4 = self.pool_proj(x4)\n        \n        x = torch.cat([x1, x2, x3, x4], 1)\n        return x","b4aa9222":"class Auxiliary(nn.Module):\n    \n    def __init__(self, in_channels, num_classes):\n        super(Auxiliary, self).__init__()\n        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n        self.conv1x1 = ConvBlock(in_channels, 128, kernel_size=1)\n        \n        self.fc1 = nn.Linear(2048, 1024)\n        self.fc2 = nn.Linear(1024, num_classes)\n        \n        self.dropout = nn.Dropout(0.7)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.avgpool(x)\n        x = self.conv1x1(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x","e7c3b371":"model = Inception()","f473abf4":"#define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","3e343726":"#move the model to the device\nmodel.to(device)\nnext(model.parameters()).is_cuda","c7a1fb8c":"#define everything we need for training\nepochs = 3 #50\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)","0e4fdbe8":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, use_auxiliary=True):\n    \n    since = time.time()\n    val_acc_history = []\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]: # Iterate over data\n                \n                inputs = inputs.to(device)\n\n                labels = labels.to(device)\n\n                optimizer.zero_grad() # Zero the parameter gradients\n\n                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n                    \n                    if phase == 'train': # Backward + optimize only if in training phase\n                        if use_auxiliary:\n                            outputs, aux1, aux2 = model(inputs)\n                            loss = criterion(outputs, labels) + 0.3 * criterion(aux1, labels) + 0.3 * criterion(aux2, labels)\n                        else:\n                            outputs, _, _ = model(inputs)\n                            loss = criterion(outputs, labels)\n                            \n                        _, preds = torch.max(outputs, 1)\n                        loss.backward()\n                        optimizer.step()\n                    \n                    if phase == 'val':\n                        outputs, _, _ = model(inputs)\n                        loss = criterion(outputs, labels)\n                        _, preds = torch.max(outputs, 1)\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            \n            if phase == 'val': # Adjust learning rate based on val loss\n                lr_scheduler.step(epoch_loss)\n                \n            epoch_acc = running_corrects.double() \/ len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","3c5e822f":"model, _ = train_model(model, {\"train\": train_loader, \"val\": val_loader}, criterion, optimizer, epochs)","45686582":"# Data preparation","19f4259e":"# Model","12187cf3":"Create the dataset and the DataLoaders to benefit from batching and shuffling","951c25e2":"    In this notebook we'll implement GoogLeNet with Inception blocks from scratch\n    using Pytorch\n    \n    We'll use a tiny version of ImageNet to experiment with\n    \n    The code is followed by some explanation\n    \n    Original article: https:\/\/arxiv.org\/pdf\/1409.4842.pdf","76508309":"Visualise training images","b2013c75":"With this implementation we can either use auxiliary classifiers during training (see the original article) or turn it off using *use_auxiliary* parameter.","64a54fac":"![Screenshot%202021-02-18%20at%2016.18.57.png](attachment:Screenshot%202021-02-18%20at%2016.18.57.png)","5330d25d":"![Screenshot%202021-02-17%20at%2010.39.10.png](attachment:Screenshot%202021-02-17%20at%2010.39.10.png)","7003b43e":"#### Building blocks for GoogLeNet model:\n1. Conv2d + BatchNorm2d + ReLU block class\n2. Inception block class\n3. Auxiliary classifier class\n4. Model class","39b14033":"Take a look at the training function. If *use_auxiliary=True*, during training we take into account predictions made by auxiliary classifiers - we add their weighted losses to the loss of the main classifier","e56e0cea":"Define the transformations we will apply to images:\n1. Resize the images so they match the size of images the architecture was developed for\n2. Convert PIL Images to tensors to process inside the network\n","f1268b3d":"    As you can see, the model is learning\n    \n    I hope this will be useful\n    If so, please, feel free to give it an upvote. Thanks!)\n    ","b1cd5829":"    Please upvote if this notebook was helpful to you. Thanks!","14dcfa9e":"The only noticable difference from the traditional convolutional layer here is that the input is divided to branches, each of which has own operations. After all the operations have been performed we concatenate the branches into one output tensor","a938b6de":"An auxiliary classifier is a classification block that stems from one of the intermediate layers. We take its predictions into account to help the network to propagate gradients through the more recent layers.","b5bbefcc":"# Training"}}