{"cell_type":{"40914730":"code","325b0b0f":"code","dc39508f":"code","b35e4b0e":"code","a8d8af46":"code","5cea1584":"code","f4b57a9e":"code","99ea77bf":"code","58ea75df":"code","c93375c4":"code","9144f233":"code","d61dbad0":"code","eea6a447":"code","b1130e05":"code","53e5e24b":"code","667d23a2":"code","8186fd82":"code","aeaed41c":"code","40fcfc9a":"code","8ed122dc":"code","d226f6c0":"markdown","c432374a":"markdown","3f2991b1":"markdown","68d1e66e":"markdown","b15a0113":"markdown","98750310":"markdown","d3c1b67b":"markdown","8393f81e":"markdown","5ca2bdab":"markdown","1581e84d":"markdown","e73ab905":"markdown","dd854a57":"markdown","5902dcde":"markdown","d1c3b028":"markdown","c9502818":"markdown","f597a146":"markdown","9703944d":"markdown"},"source":{"40914730":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","325b0b0f":"!pip install trimesh\nimport os\nimport glob\nimport trimesh\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom matplotlib import pyplot as plt\n\ntf.random.set_seed(1234)","dc39508f":"DATA_DIR = tf.keras.utils.get_file(\n    \"modelnet.zip\",\n    \"http:\/\/3dvision.princeton.edu\/projects\/2014\/3DShapeNets\/ModelNet10.zip\",\n    extract=True,\n)\nDATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")","b35e4b0e":"print(DATA_DIR)","a8d8af46":"print(os.listdir(DATA_DIR))","5cea1584":"print(os.listdir(DATA_DIR+\"\/monitor\"))","f4b57a9e":"# path = DATA_DIR+\"\/README.txt\"\n# open(path,'r').read()","99ea77bf":"mesh = trimesh.load(os.path.join(DATA_DIR, \"chair\/train\/chair_0010.off\"))\nmesh.show()","58ea75df":"points = mesh.sample(2048)\n\nfig = plt.figure(figsize=(5, 5))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(points[:, 0], points[:, 1], points[:, 2])\nax.set_axis_off()\nplt.show()","c93375c4":"def parse_dataset(num_points=2048):\n\n    train_points = []\n    train_labels = []\n    test_points = []\n    test_labels = []\n    class_map = {}\n    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n    print(folders)\n    for i, folder in enumerate(folders):\n        print(\"processing class: {}\".format(os.path.basename(folder)))\n        # store folder name with ID so we can retrieve later\n        class_map[i] = folder.split(\"\/\")[-1] # to get the name of the file\n        # gather all files\n        train_files = glob.glob(os.path.join(folder, \"train\/*\"))\n        test_files = glob.glob(os.path.join(folder, \"test\/*\"))\n     \n\n        for f in train_files:\n            train_points.append(trimesh.load(f).sample(num_points)) # from meshes to pointcloud\n            train_labels.append(i) # the id of the folder\n\n        for f in test_files:\n            test_points.append(trimesh.load(f).sample(num_points))\n            test_labels.append(i)\n\n    return (\n        np.array(train_points),\n        np.array(test_points),\n        np.array(train_labels),\n        np.array(test_labels),\n        class_map,\n    )","9144f233":"NUM_POINTS = 2048\nNUM_CLASSES = 10\nBATCH_SIZE = 32\n\ntrain_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n    NUM_POINTS\n)","d61dbad0":"print(CLASS_MAP)","eea6a447":"def augment(points, label):\n    # jitter points\n    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n    # shuffle points\n    points = tf.random.shuffle(points) \n    return points, label","b1130e05":"train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n\ntrain_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\ntest_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)","53e5e24b":"def conv_bn(x, filters):\n    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n    x = layers.BatchNormalization(momentum=0.0)(x)\n    return layers.Activation(\"relu\")(x)\n\n\ndef dense_bn(x, filters):\n    x = layers.Dense(filters)(x)\n    x = layers.BatchNormalization(momentum=0.0)(x)\n    return layers.Activation(\"relu\")(x)","667d23a2":"class OrthogonalRegularizer(keras.regularizers.Regularizer):\n    def __init__(self, num_features, l2reg=0.001):\n        self.num_features = num_features\n        self.l2reg = l2reg\n        self.eye = tf.eye(num_features)\n\n    def __call__(self, x):\n        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n        xxt = tf.tensordot(x, x, axes=(2, 2))\n        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))","8186fd82":"def tnet(inputs, num_features):\n\n    # Initalise bias as the indentity matrix\n    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n    reg = OrthogonalRegularizer(num_features)\n\n    x = conv_bn(inputs, 32)\n    x = conv_bn(x, 64)\n    x = conv_bn(x, 512)\n    x = layers.GlobalMaxPooling1D()(x)\n    x = dense_bn(x, 256)\n    x = dense_bn(x, 128)\n    x = layers.Dense(\n        num_features * num_features,\n        kernel_initializer=\"zeros\",\n        bias_initializer=bias,\n        activity_regularizer=reg,\n    )(x)\n    feat_T = layers.Reshape((num_features, num_features))(x)\n    # Apply affine transformation to input features\n    return layers.Dot(axes=(2, 1))([inputs, feat_T])","aeaed41c":"inputs = keras.Input(shape=(NUM_POINTS, 3))\n\nx = tnet(inputs, 3)\nx = conv_bn(x, 32)\nx = conv_bn(x, 32)\nx = tnet(x, 32)\nx = conv_bn(x, 32)\nx = conv_bn(x, 64)\nx = conv_bn(x, 512)\nx = layers.GlobalMaxPooling1D()(x)\nx = dense_bn(x, 256)\nx = layers.Dropout(0.3)(x)\nx = dense_bn(x, 128)\nx = layers.Dropout(0.3)(x)\n\noutputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\nmodel.summary()","40fcfc9a":"model.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[\"sparse_categorical_accuracy\"],\n)\n\nmodel.fit(train_dataset, epochs=20, validation_data=test_dataset)","8ed122dc":"data = test_dataset.take(1)\n\npoints, labels = list(data)[0]\npoints = points[:8, ...]\nlabels = labels[:8, ...]\n\n# run test data through model\npreds = model.predict(points)\npreds = tf.math.argmax(preds, -1)\n\npoints = points.numpy()\n\n# plot points with predicted class and label\nfig = plt.figure(figsize=(15, 10))\nfor i in range(8):\n    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n    ax.set_title(\n        \"pred: {:}, label: {:}\".format(\n            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n        )\n    )\n    ax.set_axis_off()\nplt.show()","d226f6c0":"# Build Model\nEach convolution and fully-connected layer (with exception for end layers) consits of :\n* Convolution \/ Dense -> \n* Batch Normalization -> \n* ReLU Activation.","c432374a":"We can then define a general function to build T-net layers.","3f2991b1":"Point cloud is an important type of geometric data structure. this is an exemple of how you can build your own module ","68d1e66e":" PointNet consists of two core components. The primary MLP network, and the transformer net (T-net). The T-net aims to learn an affine transformation matrix by its own mini network. The T-net is used twice. The first time to transform the input features (n, 3) into a canonical representation. The second is an affine transformation for alignment in feature space (n, 3). As per the original paper we constrain the transformation to be close to an orthogonal matrix ** (i.e. ||X*X^T - I|| = 0).**","b15a0113":"# PointNet Classification and segmentation Network\nin this section, we gonna just use the classification network;","98750310":"**in this section, we try to create a map contains labels with the names of objects:**\n* 0 : monitor\n* 1 : bathtub\n* 2 : table\n* 3 : dresser\n* 4 : night_stand \n* 5 : safa\n* 6 : bed \n* 7 : toilet \n* 8 : chair\n* 9 : desk","d3c1b67b":"The main network can be then implemented in the same manner where the t-net mini models can be dropped in a layers in the graph. Here we replicate the network architecture published in the original paper but with half the number of weights at each layer as we are using the smaller 10 class ModelNet dataset.","8393f81e":"**The folder ModelNet10 contains :**\n* file README  with a brief description\n* 10 files, each one contains a train folder and another one for testing\n* train and test contains files with .off extension ","5ca2bdab":"![pointnetedited1.jpg](attachment:91883a11-dee0-4e43-9126-b33620029c80.jpg)","1581e84d":"In the real cases studies, the data collected by sensors or other methodes can not be that perfect, for these, we need to add some noise and some disordering. So we create a augmentation function **to jitter** and **shuffle** the train dataset.","e73ab905":"We gonna work with PointCloud, for this we need to convert our data from meshes to point\nfor these, we gonne choose a number fix of points to generate","dd854a57":"**Trimesh** is a pure Python (2.7-3.4+) library for loading and using triangular meshes with an emphasis on watertight surfaces.","5902dcde":"Object detection a very important problem in computer vision. Because the variety and complexity of data representations.This was just an exemple of how can build our model using keras. i hope you like it","d1c3b028":"Given that PointNet consumes raw point cloud data, it was necessary to develop an architecture that conformed to the unique properties of point sets. Among these, the authors emphasize:\n* **Permutation** (Order) Invariance: given the unstructured nature of point cloud data, a scan made up of N points has N! permutations. The subsequent data processing must be invariant to the different representations.\n* **Transformation Invariance**: classification and segmentation outputs should be unchanged if the object undergoes certain transformations, including rotation and translation.\n* **Point Interactions**: the interaction between neighboring points often carries useful information (i.e., a single point should not be treated in isolation). Whereas classification need only make use of global features, segmentation must be able to leverage local point features along with global point features.","c9502818":"#  Setup","f597a146":"* **You can find the originale code in this**  [link](http:\/\/keras.io\/examples\/vision\/pointnet\/)\n* **You can find the originale article by Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas in this** [link](http:\/\/arxiv.org\/abs\/1612.00593)","9703944d":"Testing the model"}}