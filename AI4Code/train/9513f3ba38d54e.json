{"cell_type":{"088062c7":"code","e26dd4b6":"code","d16cd8c4":"code","a4b799cb":"code","058742bd":"code","7c1ce9e5":"code","1611effb":"code","893c1a70":"code","ef6e744a":"code","2423c1db":"code","89634f2a":"code","9ab3553d":"code","a6c23e5d":"code","150d1ade":"code","03f9dfe8":"code","bb04adaa":"code","9e5b7578":"code","a944bd78":"code","1264c24c":"code","cb83d9cd":"markdown","3179caf4":"markdown","ec4a09ab":"markdown","ed028ca6":"markdown","c795f93e":"markdown","af828a5c":"markdown","4ffc538e":"markdown","c0c9b138":"markdown","1c11e2f6":"markdown","7c3d7470":"markdown","8a3d715f":"markdown","643f75e2":"markdown","9e825ce2":"markdown","bb5664ad":"markdown"},"source":{"088062c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport time\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e26dd4b6":"# Opening file, reading, eliminating whitespaces, and splitting by '\\n', which in turn creates list\nlabels = open('..\/input\/yolo-coco-data\/coco.names').read().strip().split('\\n')  # list of names\n\n# # Check point\n# print(labels)","d16cd8c4":"# Defining paths to the weights and configuration file with model of Neural Network\nweights_path = '..\/input\/yolo-coco-data\/yolov3.weights'\nconfiguration_path = '..\/input\/yolo-coco-data\/yolov3.cfg'\n\n# Setting minimum probability to eliminate weak predictions\nprobability_minimum = 0.5\n\n# Setting threshold for non maximum suppression\nthreshold = 0.3","a4b799cb":"network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n\n# Getting names of all layers\nlayers_names_all = network.getLayerNames()  # list of layers' names\n\n# # Check point\n# print(layers_names_all)","058742bd":"# Getting only output layers' names that we need from YOLO algorithm\nlayers_names_output = [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]  # list of layers' names\n\n# Check point\nprint(layers_names_output)  # ['yolo_82', 'yolo_94', 'yolo_106']","7c1ce9e5":"# Our image initially is in RGB format\n# But now we open it in BGR format as function 'cv2.imread' opens it so\nimage_input = cv2.imread('..\/input\/cusersmarildownloadsstrongjpg\/strong.jpg')\n\n# Getting image shape\nimage_input_shape = image_input.shape\n\n# Check point\nprint(image_input_shape)  # tuple of (917, 1222, 3)","1611effb":"# Showing RGB image but firstly converting it from BGR format\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","893c1a70":"# The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob\n# from input image after mean subtraction, normalizing, and RB channels swapping\n# Resulted shape has number of images, number of channels, width and height\n# E.G.: blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n# Link: https:\/\/www.pyimagesearch.com\/2017\/11\/06\/deep-learning-opencvs-blobfromimage-works\/\nblob = cv2.dnn.blobFromImage(image_input, 1 \/ 255.0, (416, 416), swapRB=True, crop=False)\n\n# Check point\nprint(image_input.shape)  # (917, 1222, 3)\nprint(blob.shape)  # (1, 3, 416, 416)","ef6e744a":"# Check point\n# Slicing blob and transposing to make channels come at the end\nblob_to_show = blob[0, :, :, :].transpose(1, 2, 0)\nprint(blob_to_show.shape)  # (416, 416, 3)\n\n# Showing 'blob_to_show'\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (5.0, 5.0)\nplt.imshow(blob_to_show)\nplt.show()","2423c1db":"# Calculating at the same time, needed time for forward pass\nnetwork.setInput(blob)  # setting blob as input to the network\nstart = time.time()\noutput_from_network = network.forward(layers_names_output)\nend = time.time()\n\n# Showing spent time for forward pass\nprint('YOLO v3 took {:.5f} seconds'.format(end - start))","89634f2a":"# Check point\nprint(type(output_from_network))  # <class 'list'>\nprint(type(output_from_network[0]))  # <class 'numpy.ndarray'>","9ab3553d":"# Seed the generator - every time we run the code it will generate by the same rules\n# In this way we can keep specific colour the same for every class\nnp.random.seed(42)\n# randint(low, high=None, size=None, dtype='l')\ncolours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n\n# Check point\nprint(colours.shape)  # (80, 3)\nprint(colours[0])  # [102 220 225]","a6c23e5d":"# Preparing lists for detected bounding boxes, obtained confidences and class's number\nbounding_boxes = []\nconfidences = []\nclass_numbers = []","150d1ade":"# Getting spacial dimension of input image\nh, w = image_input_shape[:2]  # Slicing from tuple only first two elements\n\n# Check point\nprint(h, w)  # 917 1222","03f9dfe8":"for result in output_from_network:\n    # Going through all detections from current output layer\n    for detection in result:\n        # Getting class for current object\n        scores = detection[5:]\n        class_current = np.argmax(scores)\n\n        # Getting confidence (probability) for current object\n        confidence_current = scores[class_current]\n\n        # Eliminating weak predictions by minimum probability\n        if confidence_current > probability_minimum:\n            # Scaling bounding box coordinates to the initial image size\n            # YOLO data format keeps center of detected box and its width and height\n            # That is why we can just elementwise multiply them to the width and height of the image\n            box_current = detection[0:4] * np.array([w, h, w, h])\n\n            # From current box with YOLO format getting top left corner coordinates\n            # that are x_min and y_min\n            x_center, y_center, box_width, box_height = box_current.astype('int')\n            x_min = int(x_center - (box_width \/ 2))\n            y_min = int(y_center - (box_height \/ 2))\n\n            # Adding results into prepared lists\n            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n            confidences.append(float(confidence_current))\n            class_numbers.append(class_current)","bb04adaa":"# It is needed to make sure the data type of the boxes is 'int'\n# and the type of the confidences is 'float'\n# https:\/\/github.com\/opencv\/opencv\/issues\/12789\nresults = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n\n# Check point\n# Showing labels of the detected objects\nfor i in range(len(class_numbers)):\n    print(labels[int(class_numbers[i])])\n\n# Saving found labels\nwith open('found_labels.txt', 'w') as f:\n    for i in range(len(class_numbers)):\n        f.write(labels[int(class_numbers[i])])","9e5b7578":"# Checking if there is at least one detected object\nif len(results) > 0:\n    # Going through indexes of results\n    for i in results.flatten():\n        # Getting current bounding box coordinates\n        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n\n        # Preparing colour for current bounding box\n        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n\n        # Drawing bounding box on the original image\n        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n                      colour_box_current, 5)\n\n        # Preparing text with label and confidence for current bounding box\n        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n\n        # Putting text with label and confidence on the original image\n        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n                    1.5, colour_box_current, 5)","a944bd78":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","1264c24c":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#2B3A67','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks Valentyn Sichkar for your script, @mpwolke was Here.' )","cb83d9cd":"#Drawing bounding boxes and labels","3179caf4":"#Codes by Valentyn Sichkar  https:\/\/www.kaggle.com\/valentynsichkar\/yolo-v3-with-opencv\/notebook","ec4a09ab":"#Going through all output layers after feed forward and answer from network","ed028ca6":"#Coronavirus: Tales of solidarity from China's virus-hit Wuhan - Wuhan Jiayou\"\n\n\nAs the number of coronavirus infections continues to grow, millions of people have gone into lockdown in Wuhan - the centre of the outbreak - to try to stop the virus spreading. But in this time of isolation some people are determined to raise each others' spirits.\n\nThe neighbours who spread cheer\n\nThe deadly outbreak comes as China celebrates one of the most important dates in its calendar - Lunar New Year.\n\nImagine Christmas and Thanksgiving all rolled into one - typically a time filled with lots of cheer. For many, it's the only chance in a year they have to meet up with their family and exchange gifts of food and money.\n\nIn Wuhan people have been encouraged to stay home to minimise the spread of the virus. But residents in a block of flats found a small way to cheer each other up.\n\nVideos circulating on social media show people shouting \"Wuhan jiayou\" out of their windows- roughly translated to \"Stay strong Wuhan\" or \"Keep on going Wuhan\".\nhttps:\/\/www.bbc.com\/news\/world-asia-china-51276496","c795f93e":"![](https:\/\/isc.artez.nl\/wp-content\/uploads\/2020\/03\/82118041_861953280923630_3695950724077715456_n.jpg)https:\/\/isc.artez.nl\/events\/invitation-to-sister-city-programme-arnhem-wuhan\/","af828a5c":"#Loading input image from file","4ffc538e":"#Showing RGB image with bounding boxes and labels","c0c9b138":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTUV8XJKI2JaipXz3wjwn3XZXxgsBlBimQW6w&usqp=CAU)liberationnews.org","1c11e2f6":"#Implementing non maximum suppression of given boxes and corresponding scores","7c3d7470":"#Getting blob from input image","8a3d715f":"#Loading trained YOLO Objects Detector with the help of 'dnn' library from OpenCV","643f75e2":"#Implementing forward pass with our blob and only through output layers","9e825ce2":"#Colours for representing every detected object","bb5664ad":"#\u2018Wuhan stay strong\u2019: city lockdown captured in craft beer - AFP\nhttps:\/\/www.youtube.com\/watch?v=Y-0DdxvrFsU\nWhen the coronavirus emerged in Wuhan and the Chinese city went into a strict 76-day lockdown, Wang Fan resolved to commemorate the turbulent period in the way he knew best -- through beer."}}