{"cell_type":{"b4b1096a":"code","dac641d8":"code","e33dde62":"code","639654c4":"code","b64cdee9":"code","626227c6":"code","2a84e547":"code","3b1989d8":"code","cf684ca7":"code","0edaa8d0":"code","69e42fe8":"code","b022848e":"code","a655a861":"code","d1950317":"code","e4003dbe":"code","bbbc8e70":"code","2d56f7f0":"code","0bef4ffd":"code","27aec413":"code","fa40642e":"code","df8e0259":"markdown","b343d237":"markdown","75167e76":"markdown","6ad10063":"markdown","f337bf5e":"markdown","43482565":"markdown","d58ebd23":"markdown","6bcc6331":"markdown","8fd5213c":"markdown","6afc63a9":"markdown","3a891f6d":"markdown","fb0f3a50":"markdown","fe6d825b":"markdown","47fe92bc":"markdown","0a63a60d":"markdown","81e0e112":"markdown","d58c77bb":"markdown","e08b1dcb":"markdown","d9a20506":"markdown","757f09a9":"markdown","a468de67":"markdown","758b9883":"markdown","1f983cac":"markdown","c4b4e42b":"markdown","f333d671":"markdown","aee84c75":"markdown"},"source":{"b4b1096a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dac641d8":"mu, sigma = 0, 0.1 # Mean and standard deviation\ns = np.random.normal(mu, sigma, size=10000)\ncount, bins, ignored = plt.hist(s, 30, density=True)\nplt.title(\"Normal Distribution\", fontsize=16)\nplt.show()","e33dde62":"s = np.random.uniform(-1,0,1000)\nprint(f'Mean of Sample: {s.mean()}')\ncount, bins, ignored = plt.hist(s, 15, density=True)\nplt.title(\"Uniform Distribution\", fontsize=16)\nplt.show()","639654c4":"s = np.random.standard_cauchy(1000000)\ns = s[(s>-25) & (s<25)]  # truncate distribution so it plots well\nplt.hist(s, bins=100, density=True)\nplt.title(\"Cauchy Distribution\", fontsize=16)\nplt.show()","b64cdee9":"# t Distribution with df = 1\ns = np.random.standard_t(df =1, size=100000)\ns = s[np.where(abs(s) < 5)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"t Distribution (df=1)\", fontsize=16)\nplt.show()","626227c6":"# dfnum: between group degrees of freedom\n# dfden: within groups degrees of freedom\n# F Distribution with dfnum=1, dfden=1\ns = np.random.f(dfnum=1, dfden=1, size=10000)\ns = s[np.where(abs(s) < 5)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"F Distribution (dfnum=1, dfden=1)\", fontsize=16)\nplt.show()","2a84e547":"# Chi Square Distribution with df = 1\ns = np.random.chisquare(df=1, size=10000)\ns = s[np.where(abs(s) < 20)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"Chi Square Distribution (df=1)\", fontsize=16)\nplt.show()","3b1989d8":"# Exponential distribution with lamda=1\ns = np.random.exponential(scale=1.0, size=10000)\nh = plt.hist(s, bins=1000, density=True)\nplt.title(\"Exponential Distribution\", fontsize=16)\nplt.show()","cf684ca7":"# Weibull Distribution with gamma = 0.5\ns = np.random.weibull(a=0.5, size=10000)\ns = s[np.where(abs(s) < 5)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"Weibull Distribution (gamma=0.5)\", fontsize=16)\nplt.show()","0edaa8d0":"#  LogNormal Distribution with sigma = 0.5\ns = np.random.lognormal(mean=0.0, sigma=0.5, size=10000)\ns = s[np.where(abs(s) < 5)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"LogNormal Distribution (sigma=1)\", fontsize=16)\nplt.show()","69e42fe8":"from scipy.stats import fatiguelife\n# fatiguelife Distribution with gamma = 0.5\nx = np.linspace(fatiguelife.ppf(0.01, c=0.5), fatiguelife.ppf(0.99, c=0.5), 100)\nplt.plot(x, fatiguelife.pdf(x, c=0.5), 'b-', lw=2, alpha=0.6, label='fatiguelife pdf')\nplt.title(\"fatiguelife Distribution (gamma=0.5)\", fontsize=16)\nplt.show()","b022848e":"# Gamma Distribution with gamma = 0.5\ns = np.random.gamma(shape=0.5, scale=1.0, size=10000)\ns = s[np.where(abs(s) < 10)]\nh = plt.hist(s, bins=100, density=True)\nplt.title(\"Gamma Distribution (gamma=0.5)\", fontsize=16)\nplt.show()","a655a861":"loc, scale = 0., 1.\ns = np.random.laplace(loc, scale, 10000)\ncount, bins, ignored = plt.hist(s, 30, density=True)\nplt.title(\"Laplace Distribution\", fontsize=16)\nplt.show()","d1950317":"from scipy.stats import powernorm\n# Power Normal Distribution with p = 0.5\nx = np.linspace(powernorm.ppf(0.01, c=0.5),powernorm.ppf(0.99, c=0.5), 100)\nplt.plot(x, powernorm.pdf(x, c=0.5), 'b-', lw=2, alpha=0.6, label='powernorm pdf')\nplt.title(\"Power Normal Distribution (p=0.5)\", fontsize=16)\nplt.show()","e4003dbe":"from scipy.stats import powerlognorm\n# Powerlog Normal Distribution with p = 0.5\nx = np.linspace(powerlognorm.ppf(0.01, c=0.5, s=1), powerlognorm.ppf(0.99, c=0.5, s=1), 100)\nx = x[np.where(np.abs(x) < 5)]\nplt.plot(x, powerlognorm.pdf(x, c=0.5, s=1), 'b-', lw=2, alpha=0.6)\nplt.title(\"Powerlog Normal Distribution (p=0.5)\", fontsize=16)\nplt.show()","bbbc8e70":"from scipy.stats import tukeylambda\n# tukeylambda Distribution with lambda = 0.5\nlam = -1\nx = np.linspace(tukeylambda.ppf(0.01, lam), tukeylambda.ppf(0.99, lam), 100)\nplt.plot(x, tukeylambda.pdf(x, lam), 'b-', lw=2, alpha=0.6)\nplt.title(\"Tukey Lambda Distribution (lambda=-1)\", fontsize=16)\nplt.show()","2d56f7f0":"mu, beta = 0, 0.1 # location and scale\ns = np.random.gumbel(mu, beta, 1000)\nimport matplotlib.pyplot as plt\ncount, bins, ignored = plt.hist(s, 30, density=True)\nplt.title(\"Gumbel Distribution\", fontsize=16)\nplt.show()","0bef4ffd":"# Beta Distribution with (alpha=0.5, beta=0.5)\ns = np.random.beta(a=0.5, b=0.5, size=10000)\nplt.hist(s, bins=1000, density=True)\nplt.title(\"Beta Distribution (alpha=0.5, beta=0.5)\", fontsize=16)\nplt.show()","27aec413":"# Binomial Distribution with (n=100, p=0.1)\nn, p = 100, .1  # number of trials, probability of each trial\ns = np.random.binomial(n, p, 10000)\nh = plt.hist(s, bins=20, density=True)\nplt.title(\"Binomial Distribution (n=100, p=0.1)\", fontsize=16)\nplt.show()","fa40642e":"# Poisson Distribution with (lambda = 5)\ns = np.random.poisson(lam=5, size=100000)\nh = plt.hist(s, bins=20, density=True)\nplt.title(\"Poisson Distribution (lambda = 5)\", fontsize=16)\nplt.show()","df8e0259":"For more details, please refer the blog post here: https:\/\/apedatascientist.com\/2021\/05\/27\/probability-distributions\/","b343d237":"# 15. Tukey Lambda Distribution\n\n<p>The most common use of this distribution is to generate a Tukey-Lambda PPCC plot of a data set. Based on the ppcc plot, an appropriate model for the data is suggested. For example, if the maximum correlation occurs for a value of \u03bb at or near 0.14, then the data can be modeled with a normal distribution. Values of \u03bb less than this imply a heavy-tailed distribution (with -1 approximating a Cauchy). That is, as the optimal value of \u03bb goes from 0.14 to -1, increasingly heavy tails are implied. Similarly, as the optimal value of \u03bb becomes greater than 0.14, shorter tails are implied.\n\nAs the Tukey-Lambda distribution is a symmetric distribution, the use of the Tukey-Lambda PPCC plot to determine a reasonable distribution to model the data only applies to symmetric distributions. A histogram of the data should provide evidence as to whether the data can be reasonably modeled with a symmetric distribution.<\/p>","75167e76":"# Continouous Distributions","6ad10063":"# Discrete Distributions","f337bf5e":"# 3. Cauchy Distribution\n\n<p>The Cauchy distribution is important as an example of a pathological case. Cauchy distributions look similar to a normal distribution. However, they have much heavier tails. When studying hypothesis tests that assume normality, seeing how the tests perform on data from a Cauchy distribution is a good indicator of how sensitive the tests are to heavy-tail departures from normality. Likewise, it is a good check for robust techniques that are designed to work well under a wide variety of distributional assumptions.\n\nThe mean and standard deviation of the Cauchy distribution are undefined. The practical meaning of this is that collecting 1,000 data points gives no more accurate an estimate of the mean and standard deviation than does a single point.<\/p>","43482565":"# 9. Lognormal Distribution\n\n<p>The lognormal distribution is used extensively in reliability applications to model failure times. The lognormal and Weibull distributions are probably the most commonly used distributions in reliability applications.<\/p>","d58ebd23":"# 2. Uniform Distribution\n\n<p>The uniform distribution defines equal probability over a given range for a continuous distribution. For this reason, it is important as a reference distribution. One of the most important applications of the uniform distribution is in the generation of random numbers. That is, almost all random number generators generate random numbers on the (0,1) interval. For other distributions, some transformation is applied to the uniform random numbers.<\/p>","6bcc6331":"# Probability Distribution\n\n<p>In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events (subsets of the sample space). A probability distribution is a function that describes the likelihood of obtaining the possible values that a random variable can assume. In other words, the values of the variable vary based on the underlying probability distribution.\n\nSuppose you pick a random sample and measure the heights of the subjects. As you measure heights, you can create a distribution of heights. This type of distribution is useful when you need to know which outcomes are most likely, the spread of potential values, and the likelihood of different results.\n\nThere are two types of distributions: Continuous and Discrete. This file lists how to simulate them in a python environment.<\/p>","8fd5213c":"<p>A discrete probability distribution is the probability distribution of a random variable that can take on only a countable number of values. In the case where the range of values is countably infinite, these values have to decline to zero fast enough for the probabilities to add up to 1<\/p>","6afc63a9":"# 10. Birnbaum-Saunders (Fatigue Life)Distribution\n\n<p>The Birnbaum-Saunders distribution is used extensively in reliability applications to model failure times.<\/p>","3a891f6d":"# 8. Weibull Distribution\n\n<p>The Weibull distribution is used extensively in reliability applications to model failure times.<\/p>","fb0f3a50":"# 16. Extreme Value Type I Distribution\n\n<p>Some common applications are:\n\nThe GEV distribution is widely used in the treatment of \u201ctail risks\u201d in fields ranging from insurance to finance. In the latter case, it has been considered as a means of assessing various financial risks via metrics such as Value at Risk.\n    \nIn hydrology the GEV distribution is applied to extreme events such as annual maximum one-day rainfalls and river discharges. The blue picture, made with CumFreq, illustrates an example of fitting the GEV distribution to ranked annually maximum one-day rainfalls showing also the 90% confidence belt based on the binomial distribution. The rainfall data are represented by plotting positions as part of the cumulative frequency analysis.<\/p>","fe6d825b":"<p>The binomial is a type of distribution that has two possible outcomes (the prefix \u201cbi\u201d means two, or twice). For example, a coin toss has only two possible outcomes: heads or tails and taking a test could have two possible outcomes: pass or fail. A Binomial Distribution shows either (S)uccess or (F)ailure.<\/p>","47fe92bc":"# 11. Gamma Distribution\n\n<p>The gamma distribution can be used a range of disciplines including queuing models, climatology, and financial services. Examples of events that may be modeled by gamma distribution include:\n\nThe amount of rainfall accumulated in a reservoir.\nThe size of loan defaults or aggregate insurance claims.<\/p>","0a63a60d":"# 7. Exponential Distribution\n\n<p>The exponential distribution is primarily used in reliability applications. The exponential distribution is used to model data with a constant failure rate (indicated by the hazard plot which is simply equal to a constant).<\/p>","81e0e112":"# 12. Double Exponential (Laplace) Distribution\n\n<p>The Laplacian distribution has been used in speech recognition to model priors on DFT coefficients and in JPEG image compression to model AC coefficients generated by a DCT.\n\nThe addition of noise drawn from a Laplacian distribution, with scaling parameter appropriate to a function\u2019s sensitivity, to the output of a statistical database query is the most common means to provide differential privacy in statistical databases.\n    \nIn regression analysis, the least absolute deviations estimate arises as the maximum likelihood estimate if the errors have a Laplace distribution.\n    \nIn hydrology the Laplace distribution is applied to extreme events such as annual maximum one-day rainfalls and river discharges. The blue picture, made with CumFreq, illustrates an example of fitting the Laplace distribution to ranked annually maximum one-day rainfalls showing also the 90% confidence belt based on the binomial distribution. The rainfall data are represented by plotting positions as part of the cumulative frequency analysis.<\/p>","d58c77bb":"# 18. Binomial Distribution","e08b1dcb":"# 19. Poisson Distribution\n\n<p>Applications of the Poisson distribution can be found in many fields including:\n\nTelecommunication example: telephone calls arriving in a system.\n    \nAstronomy example: photons arriving at a telescope.\n    \nChemistry example: the molar mass distribution of a living polymerization.<\/p>","d9a20506":"# 4. t Distribution\n\n<p>The t distribution is used in many cases for the critical regions for hypothesis tests and in determining confidence intervals. The most common example is testing if data are consistent with the assumed process mean.<\/p>","757f09a9":"# 14. Powerlog Normal Distribution","a468de67":"# 1. Normal Distribution\n\n<p>The normal distribution is probably the most important distribution in statistics. In many classical statistical tests are based on the assumption that the data follow a normal distribution. This assumption should be tested before applying these tests. In modeling applications, such as linear and non-linear regression, the error term is often assumed to follow a normal distribution with fixed location and scale. The normal distribution is used to find significance levels in many hypothesis tests and confidence intervals.<\/p>","758b9883":"# 17. Beta Distribution\n\n<p>The beta distribution has an important application in the theory of order statistics. A basic result is that the distribution of the kth smallest of a sample of size n from a continuous uniform distribution has a beta distribution.\n    \nIn standard logic, propositions are considered to be either true or false. In contradistinction, subjective logic assumes that humans cannot determine with absolute certainty whether a proposition about the real world is absolutely true or false. In subjective logic the posteriori probability estimates of binary events can be represented by beta distributions.\n    \nThe beta distribution can be used to model events which are constrained to take place within an interval defined by a minimum and maximum value. For this reason, the beta distribution \u2014 along with the triangular distribution \u2014 is used extensively in PERT, critical path method (CPM), Joint Cost Schedule Modeling (JCSM) and other project management\/control systems to describe the time to completion and the cost of a task. In project management, shorthand computations are widely used to estimate the mean and standard deviation of the beta distribution<\/p>","1f983cac":"A continuous probability distribution is a probability distribution whose support is an uncountable set, such as an interval in the real line.[5] They are uniquely characterized by a cumulative distribution function that can be used to calculate the probability for each subset of the support.","c4b4e42b":"# 6. Chi square Distribution\n\n<p>The chi-square distribution is used in many cases for the critical regions for hypothesis tests and in determining confidence intervals. Two common examples are the chi-square test for independence in an RxC contingency table and the chi-square test to determine if the standard deviation of a population is equal to a pre-specified value.<\/p>","f333d671":"# 13. Power Normal Distribution\n\n<p>This family of distributions can be used to model values that may be normally distributed, or that may be either right-skewed or left-skewed relative to the normal distribution. The skew normal distribution is another distribution that is useful for modeling deviations from normality due to skew. Other distributions used to model skewed data include the gamma, lognormal, and Weibull distributions, but these do not include the normal distributions as special cases.<\/p>","aee84c75":"# 5. F Distribution\n\n<p>The F distribution is used in many cases for the critical regions for hypothesis tests and in determining confidence intervals. Two common examples are the analysis of variance and the F test to determine if the variances of two populations are equal.<\/p>"}}