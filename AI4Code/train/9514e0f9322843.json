{"cell_type":{"60c16a84":"code","d41d2735":"code","66c1e5b2":"code","683ad8db":"code","c94574c9":"code","8008e11d":"code","620466db":"code","ce7788c1":"code","72f08a75":"code","780bfded":"code","8e1d1b2e":"code","fddadde3":"code","d9942531":"code","0c97130e":"code","190feff2":"code","258a39cc":"code","9649de85":"code","a4e632ff":"code","10c7cbc4":"code","b8335939":"code","1588fb7b":"code","7065482e":"code","dc298539":"code","5bb295ce":"code","727f768d":"code","887bf9fc":"code","dd1748f9":"code","7560200a":"code","dd91e523":"code","1389aa57":"code","54e6ce8d":"code","f090eb88":"code","c2132d5d":"code","8dd95db2":"code","5ea122ff":"code","cef89043":"code","f97815d2":"code","78663803":"code","d61df331":"code","ad7b10c4":"code","151047fb":"code","2b14e628":"code","89c40c14":"code","a695e734":"markdown","c0d133bd":"markdown","3f47683a":"markdown","5762a4a4":"markdown","d91546c4":"markdown","8bd5a6b8":"markdown","f51676b0":"markdown","b7cc20aa":"markdown","e63589ef":"markdown","cccd0619":"markdown","c6a3d346":"markdown","6e3ace27":"markdown","6de2c5b8":"markdown"},"source":{"60c16a84":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","d41d2735":"data=pd.read_csv('..\/input\/restaurant-reviews\/Restaurant_Reviews.tsv',delimiter='\\t')","66c1e5b2":"data.head()","683ad8db":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","c94574c9":"sample=re.sub('[^a-zA-Z]',' ',data['Review'][0])\nsample","8008e11d":"sample=sample.lower()\nsample","620466db":"sample=sample.split()\nsample","ce7788c1":"ps=PorterStemmer\nsample=[word  for word in sample if not word in set(stopwords.words('english'))]\nsample","72f08a75":"data.shape[0]","780bfded":"NewReview=[]\nfor i in range (0,data.shape[0]):\n    review=re.sub('[^a-zA-Z]',' ',data['Review'][i])\n    review=review.lower()\n    review=review.split()\n    ps=PorterStemmer()  #Stemming:  Stemming is a rudimentary rule-based process of stripping the suffixes (\u201cing\u201d, \u201cly\u201d, \u201ces\u201d, \u201cs\u201d etc) from a word.\n    all_stopword=stopwords.words('english')\n    all_stopword.remove('not') #this will remove 'not from stopwords as it is requried for negative review'\n    review=[ps.stem(word) for word in review if not word in set(all_stopword)]\n    review=' '.join(review)\n    NewReview.append(review)","8e1d1b2e":"NewReview[0]","fddadde3":"from sklearn.feature_extraction.text import CountVectorizer","d9942531":"cv=CountVectorizer()","0c97130e":"x=cv.fit_transform(NewReview).toarray()\ny=data.iloc[:,-1].values","190feff2":"vector= pd.DataFrame(x, columns=cv.get_feature_names())\nvector","258a39cc":"from sklearn.model_selection import train_test_split as tts","9649de85":"x_train,x_test,y_train,y_test=tts(x,y,test_size=0.20,random_state=0)","a4e632ff":"x_train.shape ,x_test.shape","10c7cbc4":"from sklearn.naive_bayes import GaussianNB","b8335939":"NB=GaussianNB()\nNB.fit(x_train,y_train)\ny_pred= NB.predict(x_test)","1588fb7b":"from sklearn.metrics import accuracy_score , plot_confusion_matrix","7065482e":"accuracy_score(y_test,y_pred)","dc298539":"plot_confusion_matrix(NB , x_test,y_test)","5bb295ce":"from sklearn.model_selection import cross_val_score","727f768d":"cvs=cross_val_score(NB , x,y , cv=5, scoring='accuracy')\ncvs.mean()","887bf9fc":"from sklearn.ensemble import RandomForestClassifier as RFC","dd1748f9":"classifier= RFC(n_estimators=50,max_depth=5,oob_score=True,n_jobs=-1,random_state=0)\nclassifier.fit(x_train,y_train)\ny_pred = classifier.predict(x_test)","7560200a":"accuracy_score(y_test,y_pred)","dd91e523":"from sklearn.model_selection import GridSearchCV","1389aa57":"classifier_1=RFC(n_jobs=-1,random_state=0)","54e6ce8d":"parmeter={\n    'n_estimators':[5,10,25,50,70,100,150],\n    'max_depth':[2,5,10,15,50,100,125],\n    'min_samples_leaf':[2,5,7,50,100,200]\n}","f090eb88":"%%time\ngrid_search=GridSearchCV(estimator=classifier_1,\n                        param_grid=parmeter,\n                        cv=5, n_jobs=-1, scoring='accuracy')","c2132d5d":"%%time\ngrid_search.fit(x_train,y_train)","8dd95db2":"best_estimator=grid_search.best_estimator_\nbest_estimator","5ea122ff":"grid_search.best_score_","cef89043":"best_estimator.fit(x_train,y_train)\ny_pred=best_estimator.predict(x_test)","f97815d2":"accuracy_score(y_test,y_pred)","78663803":"plot_confusion_matrix(best_estimator,x_test,y_test)","d61df331":"from sklearn.linear_model import LogisticRegression","ad7b10c4":"LR=LogisticRegression()\nLR.fit(x_train,y_train)\ny_pred=LR.predict(x_test)","151047fb":"accuracy_score(y_test,y_pred)","2b14e628":"plot_confusion_matrix(LR,x_test,y_test)","89c40c14":"score=cross_val_score(LR,x,y,cv=5 ,scoring='accuracy')\nscore.mean()","a695e734":"## Fitting the Model","c0d133bd":"### Fitting Model Using LogisticReression","3f47683a":"so here as per problem statment we need to dectect the restaurant review is positive or neative . So we will use the NLP to slove this problem","5762a4a4":"As we can see it remove the ... part from review and replace it with space .\nNow we will conver the all text in samll alphabate","d91546c4":"## Cleaning the Data\n\nFirst i will do all step of clening process on first review only show all the output to understant all the step tahn we will do thsi for all dataset","8bd5a6b8":"A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and the word order. It is called a \u201cbag\u201d of words because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.","f51676b0":"### 1. Fitting the Naive base model","b7cc20aa":"### Tunning the parmeter for RandomForest","e63589ef":"### 2. Fitting Data Using RandomForest","cccd0619":"First we need to remove all the unnessary charater from reviews for eg. queation mark , comma ,number ect. we want only alphabate to dectect the review is positive or not","c6a3d346":"Now we need to remove all the unnessary words from review like  AND , I , IF , This ects . So we need to use Nature Langauge Tool kit we will  import thiss library and remove all this word . So we need to import stopwords ","6e3ace27":"### Now we will do all this process on all data set using for loop","6de2c5b8":"## Create a Bag of Word Model"}}