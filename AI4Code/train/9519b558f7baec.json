{"cell_type":{"19ba4c56":"code","db1ceb55":"code","7dadd0d2":"code","66111420":"code","78cc5c0f":"code","7c004dd4":"code","65774366":"code","bc42996f":"code","280cc92a":"code","e775284d":"code","d44ffa6c":"code","404f48c4":"code","aa5aee03":"code","c11ef150":"code","c9a9bfe0":"code","b89e8eb7":"code","598a9b25":"code","c73d635f":"code","dd06efe8":"code","9e37747a":"code","95544b04":"markdown","87213ee7":"markdown"},"source":{"19ba4c56":"import gc\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgbm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error","db1ceb55":"X = pd.read_csv('..\/input\/andrews-new-stuff\/train_features.csv')\nX_test = pd.read_csv('..\/input\/andrews-new-stuff\/test_features.csv')\ny = pd.read_csv('..\/input\/andrews-new-stuff\/y.csv')\nsubmission = pd.read_csv('..\/input\/andrews-new-stuff\/submission.csv')\n\nX['target'] = y.target\nX_test['target'] = -1","7dadd0d2":"x = pd.qcut(X.target, 7, labels=[0, 1, 2, 3, 4, 5, 6])","66111420":"for a in [0, 1, 2, 3, 4, 5]:\n    print(a,X.target[x==a].min(),X.target[x==a].max())","78cc5c0f":"X.head()","7c004dd4":"X_test.head()","65774366":"submission.head()","bc42996f":"lgbm_params =  {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 100,\n    \"feature_fraction\": .5,\n    \"bagging_fraction\": .5,\n    #'bagging_freq': 4,\n    \"max_depth\": -1,\n    \"reg_alpha\": 0.3,\n    \"reg_lambda\": 0.1,\n    \"min_child_weight\":10,\n    \"n_jobs\":4\n}","280cc92a":"feats = X.columns[:-1]","e775284d":"# bestparams = {}\n# for i in [0, 1, 2, 3, 4, 5]:\n#     lgtrain = lgbm.Dataset(X[feats],x>i)\n#     lgb_cv = lgbm.cv(\n#         params = lgbm_params,\n#         train_set = lgtrain,\n#         num_boost_round=2000,\n#         stratified=False,\n#         nfold = 5,\n#         verbose_eval=0,\n#         seed = 42,\n#         early_stopping_rounds=75)\n\n#     optimal_rounds = np.argmin(lgb_cv['binary_logloss-mean'])\n#     best_cv_score = min(lgb_cv['binary_logloss-mean'])\n#     bestparams[i] = (optimal_rounds,best_cv_score)\n#     del lgtrain\n#     gc.collect()\n# bestparams","d44ffa6c":"bestparams = {0: (343, 0.33300775159479323),\n             1: (377, 0.3937832899637623),\n             2: (381, 0.43248276195861485),\n             3: (368, 0.4567765830007994),\n             4: (279, 0.4364333328398183),\n             5: (301, 0.3130615907253661)}","404f48c4":"folds = KFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],6))\nsub_preds = np.zeros((X_test.shape[0],6))","aa5aee03":"for i in [0, 1, 2, 3, 4, 5]:\n    optimal_rounds, best_cv_score = bestparams[i]\n    print(i, optimal_rounds, best_cv_score)\n    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n        print(n_fold)\n        trn_x, trn_y = X[feats].iloc[trn_idx], x[trn_idx]>i\n        val_x, val_y = X[feats].iloc[val_idx], x[val_idx]>i\n        \n        clf = lgbm.train(lgbm_params,\n                         lgbm.Dataset(trn_x,trn_y),\n                         num_boost_round = optimal_rounds + 1,\n                         verbose_eval=200)\n\n        oof_preds[val_idx,i] = clf.predict(val_x, num_iteration=optimal_rounds + 1)\n        sub_preds[:,i] += clf.predict(X_test[feats], num_iteration=optimal_rounds + 1) \/ folds.n_splits\n\n        del clf\n        del trn_x, trn_y, val_x, val_y\n        gc.collect()","c11ef150":"off_preds_withbias = np.hstack([oof_preds,np.ones(shape=(oof_preds.shape[0],1))])\nsub_preds_withbias = np.hstack([sub_preds,np.ones(shape=(sub_preds.shape[0],1))])","c9a9bfe0":"params = np.linalg.lstsq(off_preds_withbias, y.target,rcond=-1)[0]","b89e8eb7":"params","598a9b25":"trainpreds = np.dot(off_preds_withbias,params)\nprint(mean_absolute_error(y.target,trainpreds))","c73d635f":"testpreds = np.dot(sub_preds_withbias,params)\nsub = pd.DataFrame({'seg_id':submission.seg_id, 'time_to_failure':testpreds})\nsub.to_csv('cut.csv',index=False)","dd06efe8":"sub.time_to_failure.min()","9e37747a":"sub.time_to_failure.max()","95544b04":"A different way to do this problem is to use cuts, train a bunch of binary classifiers and then feed them into linalg or scipy optimize.  Note this is not optimized; I just slapped it together for learning! ;)","87213ee7":"Use the block below - kernels are slow so I am giving you the \"best\" params"}}