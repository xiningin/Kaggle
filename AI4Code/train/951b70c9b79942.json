{"cell_type":{"65cb3099":"code","0abdd303":"code","1c6afd8a":"code","52c43268":"code","23ac215c":"code","037851a9":"code","a53a3c3a":"code","737f49d9":"markdown","c8ccad71":"markdown","eb1b6840":"markdown","bd7296fa":"markdown","a22e55e1":"markdown","e45a54a3":"markdown","8eb6cb1e":"markdown"},"source":{"65cb3099":"from sklearn import datasets\nfrom sklearn import preprocessing\nfrom keras.utils import to_categorical\n\n\n# Load and transform the data.\niris = datasets.load_iris()\niris_target_onehot = to_categorical(iris.target)\nX = preprocessing.scale(iris.data)\nY = iris_target_onehot","0abdd303":"def build_iris_model(num_hidden_layers = 1, \n                     x_dim = 4, \n                     num_neurons = 64, \n                     my_optimizer = \"adam\"):\n    \"\"\"\n    This function returns a feed-forward neural network, as\n    defined in the parameters.\n    \"\"\"\n    model = Sequential()\n    model.add(Dense(num_neurons, \n                 input_dim = x_dim, \n                 activation = \"relu\"))\n    \n    # Add specified number of hidden layers.\n    for i in range(num_hidden_layers):        \n        model.add(Dense(num_neurons, \n                        activation = \"relu\"))\n    \n    model.add(Dense(3, activation = \"softmax\"))\n    \n    # Compile the model according to the selected optimizer function.\n    # Using categorical cross entropy because we are classifying.\n    model.compile(loss = \"categorical_crossentropy\", \n               optimizer = my_optimizer, \n               metrics = [\"accuracy\"])\n    return model","1c6afd8a":"from sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, \n                                                    Y, \n                                                    test_size = 0.4, \n                                                    random_state = 0)\n\n# Train the model.\nmodel = build_iris_model()\nmodel.fit(X_train, \n          Y_train, \n          validation_split = 0.25, \n          epochs = 150, \n          batch_size = 10, \n          verbose = 0)","52c43268":"import numpy as np\n\nclass1_sample = np.reshape(X_train[0, :], (1, 4))\nprint(\"Sample data for class 1: \" + str(class1_sample))\nclass0_sample = np.reshape(X_train[50, :], (1, 4))\nprint(\"Sample data for class 0: \" + str(class0_sample))\n\n\nprint(\"\\n\\nThe first sample should yield class 1: \" + str(model.predict_classes(class1_sample)))\nprint(\"The second sample should yield class 0: \" + str(model.predict_classes(class0_sample)))","23ac215c":"import tensorflowjs as tfjs\n\n# Modify as needed.\nTFJS_MODEL_PATH = \"\/tmp\/irismodel-tfjs\"\n\n# Save the model in TF's Layer format.\ntfjs.converters.save_keras_model(model, TFJS_MODEL_PATH)","037851a9":"!ls -la \/tmp\/irismodel-tfjs","a53a3c3a":"%%javascript\nrequirejs.config({\n    paths: { \n        'tf': ['\/\/cdn.jsdelivr.net\/npm\/@tensorflow\/tfjs@0.14.1\/dist\/tf.min'], \n    },\n});\n\nrequire(['tf'], function(tf) {\n    async function load_and_predict() {\n        \/\/ This is where we are loading the model from. \n        \/\/ Could also be Google cloud storage or an Amazon S3 bucket.\n        const MODEL_URL = \"https:\/\/raw.githubusercontent.com\/bwv988\/keras-tensorflowjs-tests\/master\/model\/model.json\";\n  \n        console.log(\"Loading pre-trained model...\")\n        const model = await tf.loadModel(MODEL_URL);\n        console.log(\"Model successfully loaded.\")\n        \n        \/\/ This the first training example which is of class 1.\n        const class1_test = tf.tensor([\n          [0.18982966, 0.80065426, 0.42156442, 0.52764485]\n        ]);\n        \n        \/\/ This is another training example of class 0.\n        const class0_test = tf.tensor([\n          [-1.02184904,  0.33784833, -1.45500381, -1.31297673]\n        ]);\n        \n        \/\/ Contruct the output.\n        \/\/ FIXME: This is a bit crude ;)\n        const p1 = model.predict(class1_test);\n        const p2 = model.predict(class0_test);\n        \n        let res_str = `\n        <strong>Predictions:<\/strong>\n        <br\/>\n        <br\/>\n        Predicted class probabilities for class 1 training example:\n        `;\n        \n        res_str += p1;\n        \n        res_str += `\n        <br\/>\n        Predicted class probabilities for class 0 training example:\n        `\n        res_str += p2;\n        \n        \/\/ Append output to cell.\n        element.html(res_str);\n        \n    }\n    \n    load_and_predict();\n    return {}\n});","737f49d9":"### Saving the model\n\nSo far so good, nothing particularly fancy happening yet. Now we need to save the model.\n\nOut of the box, Keras supports the HDF5 model format. However, for TensorFlow.js we need to convert into TensorFlow's Layers format. This can be achieved with a utility function within the `tensorflowjs` package.\n\n**Note** For the next line to work, the `tensorflowjs` package needs to be installed. The procedure depends on where you're running this notebook.\n\n* Python: `pip install tensorflowjs`\n* Kaggle: Add a custom package.\n","c8ccad71":"### Training the model\n\nNext, we'll fit the model to the training data (60% of the data).\n\n**Note**: The data splitting isn't really necessary here, as I'm not doing any validation after.\n\nJust leaving it in for the inevitable copy-and-paste :)","eb1b6840":"# Keras and TensorFlow.js Interoperability\n\nRalph Schlosser, 16\/12\/2018, <http:\/\/warpbreaks.io>\n\nGit: https:\/\/github.com\/bwv988\/keras-tensorflowjs-tests\n\n## Introduction\nWith the release of TensorFlow.js earlier in 2018 (https:\/\/js.tensorflow.org\/), it is now possible to train and run Machine Learning models directly in a web browser and NodeJS-based applications. TensorFlow.js implements much of TensorFlow's proven API and thus opens up interesting possibilities to augment web applications with Machine Learning capabilities.\n\nThis short notebook demonstrates a very simple workflow:\n\n* Train a model using Keras and Python.\n* Save the trained model.\n* Load the finished model into TensorFlow.js \/ Javascript and make predictions.\n\nAs always, a picture says more than a thousand words, so below is a very detailed and highly technical diagram of this workflow:\n\n![Workflow](https:\/\/github.com\/bwv988\/keras-tensorflowjs-tests\/raw\/master\/assets\/workflow.PNG)\n\nTo demonstrate the last part I'll make use of Jupyter's fantastic `%%javascript` cell magic.\n\n\n## Demo: Train offline, predict online\nMany real-world ML problems require complex neural network architectures, the training of which, while now feasible, wouldn't be very practical to do in a browser. This is especially valid for mobile applications.\n\nA far more common use case, however, would be to fetch a pre-trained model which was build e.g. on a GPU cluster in order to then make predictions. \n\nIn the case of a neural networks, training the model entails establishing the weights, which is typically orders of magnitudes more expensive in terms of CPU compared to just applying the trained weights to make predictions, based on new data.\n\n## Part 1: Offline Model Training\n\nFor this demonstration, I'll use the classical **Iris flower** dataset. The goal here is to predict the type (class) of flower based on four different measurements in cm taken from 150 flowers. The dataset is build into the `sklearn` package.\n\n### Data loading and preparation","bd7296fa":"In production, there would be a step to publish this model to a cloud storage provider, like Amazon S3, or Google Cloud Storage. But as this is just a demo, I'm skipping this step.\n\n\n## Part 2: Online Model Loading and Predictions\n\nNow, we'll load the pre-trained model into Javascript and make predictions.\n\nI'm repeating the validation step from before, only this time the prediction code is in Javascript and we load the model from a URL using TensorFlow.js.\n\nA few notes on the below code cell:\n\n* Jupyter's `%%javascript` \"cell magic\" is used for fun and profit so as to embedd the Javascript pieces. Obviously for a real application, we'd separate out the code bits into a module and use Yarn or NPM to load the TensorFlow.js library.\n\n* The computation results are just the raw class probabilities. The highest probability corresponds to the predicted class.","a22e55e1":"### Defining the model\n\nFor this multi-class classification problem, we'll be setting up a simple feed-forward neural network. \n\n**Note**: In this very simple case it would be perfectly OK to define and train the model in the browser. But I wanted something that runs quickly and I wouldn't have to wait for an hour for the results to be complete. :)","e45a54a3":"### Testing the model\n\nWe can now convince ourselves that the model predicts well on the training data, as expected.","8eb6cb1e":"## Summary\n\nAs we can see, it's fairly simple to load pre-trained models in TensorFlow.js. This also shows that Keras, Tensorflow, Python and Javascript play a long quiet nicely and enable ML developers to seamlessly connect different execution domains.\n\n## References and Links\n\n* TensorFlow.js homepage: https:\/\/js.tensorflow.org\/\n* Introduction post on Medium: https:\/\/medium.com\/tensorflow\/introducing-tensorflow-js-machine-learning-in-javascript-bf3eab376db\n* Jupyter embracing modern web standards: https:\/\/jupyter-notebook.readthedocs.io\/en\/stable\/examples\/Notebook\/JavaScript%20Notebook%20Extensions.html"}}