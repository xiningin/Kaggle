{"cell_type":{"c62f58f2":"code","3c2ce5d5":"code","3fc2d179":"code","e6639946":"code","5c596375":"code","6f8494b2":"code","7a17a35c":"code","c3bcbe06":"code","31705b96":"code","4e0bec16":"code","507b388d":"code","0f5f6589":"code","a071c223":"code","fcecc2dd":"code","1bfa36b3":"code","5e6d83ed":"code","a62a0ffa":"code","873a28d7":"code","9cb69481":"code","2d6e2f84":"code","1789c263":"code","dcc66557":"code","f924d2f4":"code","b3f07a46":"code","c08ae329":"code","27081699":"code","3aa91cbe":"code","4c61b9fc":"code","79b6889b":"code","6a9c7442":"code","18e77a96":"code","f920522a":"code","d112ef11":"code","0b01a966":"markdown","6518a5a2":"markdown","6b556300":"markdown","630b8b2a":"markdown","28a87ff9":"markdown","74cfc7fb":"markdown","7476b99a":"markdown","207b071f":"markdown","e6dde8f8":"markdown","9429e91c":"markdown","32ec72ed":"markdown","264fa621":"markdown","2af22c63":"markdown","fb72cd21":"markdown","c138db00":"markdown","fac68ab4":"markdown","426f9c4b":"markdown","f4bc5b68":"markdown","50ebb683":"markdown","c27ed017":"markdown","903001d7":"markdown","d433228a":"markdown","46795ea7":"markdown","40be2bbe":"markdown","cfd6c19a":"markdown","0aebedc9":"markdown","6f58eeef":"markdown","7b28ebc0":"markdown","5db8ee62":"markdown","674badb2":"markdown","b9c7a74e":"markdown","ccf122eb":"markdown","bc31890e":"markdown","e4498273":"markdown","ae33c649":"markdown"},"source":{"c62f58f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport scipy.stats as stats # z-scores\nimport matplotlib.pyplot as plt # graph plotting\nimport seaborn as sns # matplotlib addon\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None\nnp.seterr(divide='ignore', invalid='ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c2ce5d5":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","3fc2d179":"load_graphs = True","e6639946":"training_data = pd.read_csv(\"..\/input\/cap-4611-spring-21-assignment-1\/train.csv\")\ntraining_data","5c596375":"test_data = pd.read_csv(\"..\/input\/cap-4611-spring-21-assignment-1\/test.csv\")\ntest_data","6f8494b2":"sample_submission_data = pd.read_csv(\"..\/input\/cap-4611-spring-21-assignment-1\/sample_submission.csv\")\nsample_submission_data","7a17a35c":"training_data.describe()","c3bcbe06":"training_data.info()","31705b96":"training_data.isna().values.any()","4e0bec16":"training_data.isnull().values.any()","507b388d":"# Get a histograph of all features, scan them and check for features that are not normally distributed.\nif load_graphs:\n    fig, axes = plt.subplots(97, figsize=(10, 600))\n\n    for i in range(len(training_data.columns)):\n        sns.histplot(training_data[training_data.columns[i]], ax=axes[i], bins=50);","0f5f6589":"# Split into target and data.\ntrn_cpy = training_data.copy()\nX = trn_cpy.iloc[:, 2:]\ny = trn_cpy.iloc[:, 1]\n\n# Remove ID's from test data.\ntest_cpy = test_data.copy()\nX_test_data = test_cpy.iloc[:, 1:]\n\n# Get the z-scores of each element in the data set in correspondence with their column.\nzscores = stats.zscore(X)\n# The elements that are outside 3 standard deviations.\noutliers = abs((zscores > 3).all(axis=1))\n\nprint(\"outliers: \", len(X[outliers]))","a071c223":"# Features that do not need to be normalized. I would get NaN if these were attempted to be normalized. Either a problem with my code or the fact these are binary.\nexclude_features = [\n    \"one if net income was negative for the last two year zero otherwise\", \n    \"one if total liabilities exceeds total assets zero otherwise\"\n]\n\n\n# Normalize training data.\n# X_exclude = X.drop(columns=exclude_features)\n# X[X_exclude.columns] = (X[X_exclude.columns] - X[X_exclude.columns].min()) \/ (X[X_exclude.columns].max() - X[X_exclude.columns].min())\n\n# Normalize assignment test data.\n# X_test_data_exclude = X_test_data.drop(columns=exclude_features)\n# X_test_data[X_test_data_exclude.columns] = (X_test_data[X_test_data_exclude.columns] - X_test_data[X_test_data_exclude.columns].min()) \/ (X_test_data[X_test_data_exclude.columns].max() - X_test_data[X_test_data_exclude.columns].min())\n\n# Split data into testing and training data.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)","fcecc2dd":"# Decision tree hyperparameters and model building.\nparams_dtc = {'max_depth':[3,4,5,6,7,8,9], 'min_samples_leaf':[0.05,0.1,0.15], 'max_features':[0.2,0.4,0.6,0.8]}\ndtc = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), param_grid=params_dtc, verbose=1, scoring='accuracy', cv=5, n_jobs=-1)\ndtc.fit(X_train, y_train)","1bfa36b3":"best_dtc = dtc.best_estimator_\ndtc.best_estimator_","5e6d83ed":"dtc.best_params_","a62a0ffa":"dtc.best_score_","873a28d7":"# Make the prediction and create a submission dataframe.\nprediction = best_dtc.predict_proba(X_test_data)[:, 1]\nsubmission = pd.DataFrame({'id':test_data['id'],'Bankrupt':prediction})\n\n# Save the submission.\nfilename = 'ChaseChambliss_Assignment1_DTC.csv'\nsubmission.to_csv(filename,index=False)\nsubmission","9cb69481":"y_dtc_pred = best_dtc.predict_proba(X_test)[:, 1]","2d6e2f84":"roc_auc_score(y_test, y_dtc_pred)","1789c263":"plot_roc_curve(estimator=best_dtc, X=X_test, y=y_test)\nplt.show()","dcc66557":"f1_score(y_test, y_dtc_pred.round())","f924d2f4":"accuracy_score(y_test, y_dtc_pred.round())","b3f07a46":"# Random forest hyperparameters and model building.\nparams_rfc = {'class_weight':['balanced','balanced_subsample'], 'max_depth':[4,5,6,7], 'n_estimators':[100,250,400]}\nrfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=params_rfc, scoring='accuracy', verbose=1, cv=5, n_jobs=-1)\nrfc.fit(X_train, y_train)","c08ae329":"best_rfc = rfc.best_estimator_\nrfc.best_estimator_","27081699":"rfc.best_params_","3aa91cbe":"rfc.best_score_","4c61b9fc":"# Make the prediction and create a submission dataframe.\nprediction = best_rfc.predict_proba(X_test_data)[:, 1]\nsubmission = pd.DataFrame({'id':test_data['id'],'Bankrupt':prediction})\n\n# Save the submission.\nfilename = 'ChaseChambliss_Assignment1_RFC.csv'\nsubmission.to_csv(filename,index=False)\nsubmission","79b6889b":"y_rfc_pred = best_rfc.predict_proba(X_test)[:, 1]","6a9c7442":"roc_auc_score(y_test, y_rfc_pred)","18e77a96":"plot_roc_curve(estimator=best_rfc, X=X_test, y=y_test)\nplt.show()","f920522a":"f1_score(y_test, y_rfc_pred.round())","d112ef11":"accuracy_score(y_test, y_rfc_pred.round())","0b01a966":"**ROC AUC score**\n\nROC AUC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. And when AUC is 0.5, it means the model has no class separation capacity whatsoever.","6518a5a2":"**Sample submission data in order to ensure proper formatting of predictions.**","6b556300":"**Decision Tree best estimator:**","630b8b2a":"# 10. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your random forest model","28a87ff9":"**Decision Tree best parameters:**","74cfc7fb":"# 2. You must check for missing values within the training data","7476b99a":"**F1 Score**\n\nBEST F1 Score: 0.761904761904762","207b071f":"**Random Forest best estimator:**","e6dde8f8":"# 5. If the training data contains outliers, you must describe and implement an approach to handle those outliers","9429e91c":"The best model that I created was the Random Forest model, which beat the submission with a score of 0.93543. The generated target vector was made in section 9 at the very bottom.","32ec72ed":"# 3. If the training data contains missing values, you must describe and implement an approach to handle those missing values","264fa621":"# 6. You must determine whether or not you will implement normalization or standardization, and explain your decision","2af22c63":"I tried implementing normalization, which I thought would only scale the data and not affect anything but either my implementation was wrong or it was detrimental to my model. I ended up removing normalization and saw an immediate jump from low 0.91's to high 0.92's. Normalization shouldn't have any real benefit for tree classifiers so taking it out seemed to be the best choice. I left the code in below for which I attempted to do normalization.","fb72cd21":"**Random Forest best parameters:**","c138db00":"# 1. Load data from the provided CSV files","fac68ab4":"**Making the Decision Tree prediction and saving it to a CSV file:**","426f9c4b":"# 9. You must build and train a random forest model on the training data","f4bc5b68":"**F1 Score**\n\nThe F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. ","50ebb683":"**Making the random forest prediction and saving it to a CSV file:**","c27ed017":"# 7. You must build and train a decision tree model on the training data","903001d7":"# 0. Load libraries and setup input","d433228a":"# 11. You must select the best model that you are able to generate and use that model to predict the target vector for the test data","46795ea7":"**ROC AUC score**\n\nBEST ROC AUC score was 0.9821673525377229","40be2bbe":"# 8. You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your decision tree model","cfd6c19a":"**Accuracy Score**\n\nIn multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.","0aebedc9":"**Training data from \"train.csv\".**","6f58eeef":"As we can see with our data, none of it is null or missing. All data fields have corresponding entries. No special approach needed.","7b28ebc0":"The training data does not contain any extraneous outliers. The method in which I attempted to find the outliers is to get the z-scores of the values inside each column and check if any value was outside 3 standard deviations. This usually works well on data that is standardly distributed, but since no outliers were found we're safe to assume that a good model can be predicted from the training set. For my next assignments I will switch to a box plot for visualizations in order to get a better view of the median, quartiles, and min\/maxes, as I realized during this assignment that histograms don't illustrate a whole lot besides just an overall view.","5db8ee62":"**Accuracy Score**\n\nBEST Accuracy Score: 0.9707602339181286","674badb2":"**Decision Tree best score:**","b9c7a74e":"The results below are from my submission that passed the benchmark.","ccf122eb":"**Random Forest best score:**","bc31890e":"**Test data from \"test.csv\".**","e4498273":"**The scores you see below are my best scores for Decision Trees as I spent most my time working on the Random Forest model.**\n\nroc_auc = 0.91255\n\nf1 = 0.0\n\naccuracy = 0.94736","ae33c649":"# 4. You must check for outliers within the training data"}}