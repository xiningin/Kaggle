{"cell_type":{"75864bfb":"code","728570bd":"code","5fa44b74":"code","2788d210":"code","f577b6ee":"code","623bacad":"code","a320175f":"code","f62d5ddd":"code","088edd95":"code","841960ab":"code","78d51d21":"code","8f2c8c19":"code","6f7ab254":"code","e1d7ce6a":"code","4b615f82":"code","d35bec37":"code","e90f52d3":"code","72305dc1":"code","9392f80f":"code","b0c0abd5":"code","6526bea8":"code","bdb383ca":"code","3aff9d05":"code","bd2f980b":"code","b3c057ae":"code","5420453d":"code","f6e3e595":"code","2d965eae":"code","75cbf720":"markdown","731d1fe8":"markdown","7c0a7c13":"markdown","27c26c2b":"markdown","5b91eddb":"markdown","4813107a":"markdown","8e4ad850":"markdown","94b4e733":"markdown","1cd43cf2":"markdown","d3cb636c":"markdown","ffcff8ef":"markdown","0bc7d6bb":"markdown","4a8e9cad":"markdown","84f85902":"markdown","592d7171":"markdown"},"source":{"75864bfb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","728570bd":"import pandas as pd\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom pandas_profiling import ProfileReport","5fa44b74":"df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv'\n)\n#pd.set_option('display.max_colwidth', None)\npd.set_option('display.max_columns', None)\ndf.head()","2788d210":"df.info()","f577b6ee":"report = ProfileReport(df, title='Profiling Kaggle Survey 2020', minimal=True)","623bacad":"report","a320175f":"pd.set_option('display.max_rows', None)\ndf.isna().sum()","f62d5ddd":"df.columns.values","088edd95":"# working with columns: Q1, Q2, Q3, Q6, Q7, Q8, Q9, Q10, Q14, Q17, Q18, Q19\ndf = df.drop(['Q4','Q5','Q11', 'Q12_Part_1',\n       'Q12_Part_2', 'Q12_Part_3', 'Q12_OTHER', 'Q13','Q15', \n       'Q16_Part_1','Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5',\n       'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9',\n       'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13',\n       'Q16_Part_14', 'Q16_Part_15', 'Q16_OTHER','Q20',\n       'Q21', 'Q22', 'Q23_Part_1', 'Q23_Part_2', 'Q23_Part_3',\n       'Q23_Part_4', 'Q23_Part_5', 'Q23_Part_6', 'Q23_Part_7',\n       'Q23_OTHER', 'Q24', 'Q25', 'Q26_A_Part_1', 'Q26_A_Part_2',\n       'Q26_A_Part_3', 'Q26_A_Part_4', 'Q26_A_Part_5', 'Q26_A_Part_6',\n       'Q26_A_Part_7', 'Q26_A_Part_8', 'Q26_A_Part_9', 'Q26_A_Part_10',\n       'Q26_A_Part_11', 'Q26_A_OTHER', 'Q27_A_Part_1', 'Q27_A_Part_2',\n       'Q27_A_Part_3', 'Q27_A_Part_4', 'Q27_A_Part_5', 'Q27_A_Part_6',\n       'Q27_A_Part_7', 'Q27_A_Part_8', 'Q27_A_Part_9', 'Q27_A_Part_10',\n       'Q27_A_Part_11', 'Q27_A_OTHER', 'Q28_A_Part_1', 'Q28_A_Part_2',\n       'Q28_A_Part_3', 'Q28_A_Part_4', 'Q28_A_Part_5', 'Q28_A_Part_6',\n       'Q28_A_Part_7', 'Q28_A_Part_8', 'Q28_A_Part_9', 'Q28_A_Part_10',\n       'Q28_A_OTHER', 'Q29_A_Part_1', 'Q29_A_Part_2', 'Q29_A_Part_3',\n       'Q29_A_Part_4', 'Q29_A_Part_5', 'Q29_A_Part_6', 'Q29_A_Part_7',\n       'Q29_A_Part_8', 'Q29_A_Part_9', 'Q29_A_Part_10', 'Q29_A_Part_11',\n       'Q29_A_Part_12', 'Q29_A_Part_13', 'Q29_A_Part_14', 'Q29_A_Part_15',\n       'Q29_A_Part_16', 'Q29_A_Part_17', 'Q29_A_OTHER', 'Q30',\n       'Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4',\n       'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8',\n       'Q31_A_Part_9', 'Q31_A_Part_10', 'Q31_A_Part_11', 'Q31_A_Part_12',\n       'Q31_A_Part_13', 'Q31_A_Part_14', 'Q31_A_OTHER', 'Q32',\n       'Q33_A_Part_1', 'Q33_A_Part_2', 'Q33_A_Part_3', 'Q33_A_Part_4',\n       'Q33_A_Part_5', 'Q33_A_Part_6', 'Q33_A_Part_7', 'Q33_A_OTHER',\n       'Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4',\n       'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8',\n       'Q34_A_Part_9', 'Q34_A_Part_10', 'Q34_A_Part_11', 'Q34_A_OTHER',\n       'Q35_A_Part_1', 'Q35_A_Part_2', 'Q35_A_Part_3', 'Q35_A_Part_4',\n       'Q35_A_Part_5', 'Q35_A_Part_6', 'Q35_A_Part_7', 'Q35_A_Part_8',\n       'Q35_A_Part_9', 'Q35_A_Part_10', 'Q35_A_OTHER', 'Q36_Part_1',\n       'Q36_Part_2', 'Q36_Part_3', 'Q36_Part_4', 'Q36_Part_5',\n       'Q36_Part_6', 'Q36_Part_7', 'Q36_Part_8', 'Q36_Part_9',\n       'Q36_OTHER', 'Q37_Part_1', 'Q37_Part_2', 'Q37_Part_3',\n       'Q37_Part_4', 'Q37_Part_5', 'Q37_Part_6', 'Q37_Part_7',\n       'Q37_Part_8', 'Q37_Part_9', 'Q37_Part_10', 'Q37_Part_11',\n       'Q37_OTHER', 'Q38', 'Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3',\n       'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6', 'Q39_Part_7',\n       'Q39_Part_8', 'Q39_Part_9', 'Q39_Part_10', 'Q39_Part_11',\n       'Q39_OTHER', 'Q26_B_Part_1', 'Q26_B_Part_2', 'Q26_B_Part_3',\n       'Q26_B_Part_4', 'Q26_B_Part_5', 'Q26_B_Part_6', 'Q26_B_Part_7',\n       'Q26_B_Part_8', 'Q26_B_Part_9', 'Q26_B_Part_10', 'Q26_B_Part_11',\n       'Q26_B_OTHER', 'Q27_B_Part_1', 'Q27_B_Part_2', 'Q27_B_Part_3',\n       'Q27_B_Part_4', 'Q27_B_Part_5', 'Q27_B_Part_6', 'Q27_B_Part_7',\n       'Q27_B_Part_8', 'Q27_B_Part_9', 'Q27_B_Part_10', 'Q27_B_Part_11',\n       'Q27_B_OTHER', 'Q28_B_Part_1', 'Q28_B_Part_2', 'Q28_B_Part_3',\n       'Q28_B_Part_4', 'Q28_B_Part_5', 'Q28_B_Part_6', 'Q28_B_Part_7',\n       'Q28_B_Part_8', 'Q28_B_Part_9', 'Q28_B_Part_10', 'Q28_B_OTHER',\n       'Q29_B_Part_1', 'Q29_B_Part_2', 'Q29_B_Part_3', 'Q29_B_Part_4',\n       'Q29_B_Part_5', 'Q29_B_Part_6', 'Q29_B_Part_7', 'Q29_B_Part_8',\n       'Q29_B_Part_9', 'Q29_B_Part_10', 'Q29_B_Part_11', 'Q29_B_Part_12',\n       'Q29_B_Part_13', 'Q29_B_Part_14', 'Q29_B_Part_15', 'Q29_B_Part_16',\n       'Q29_B_Part_17', 'Q29_B_OTHER', 'Q31_B_Part_1', 'Q31_B_Part_2',\n       'Q31_B_Part_3', 'Q31_B_Part_4', 'Q31_B_Part_5', 'Q31_B_Part_6',\n       'Q31_B_Part_7', 'Q31_B_Part_8', 'Q31_B_Part_9', 'Q31_B_Part_10',\n       'Q31_B_Part_11', 'Q31_B_Part_12', 'Q31_B_Part_13', 'Q31_B_Part_14',\n       'Q31_B_OTHER', 'Q33_B_Part_1', 'Q33_B_Part_2', 'Q33_B_Part_3',\n       'Q33_B_Part_4', 'Q33_B_Part_5', 'Q33_B_Part_6', 'Q33_B_Part_7',\n       'Q33_B_OTHER', 'Q34_B_Part_1', 'Q34_B_Part_2', 'Q34_B_Part_3',\n       'Q34_B_Part_4', 'Q34_B_Part_5', 'Q34_B_Part_6', 'Q34_B_Part_7',\n       'Q34_B_Part_8', 'Q34_B_Part_9', 'Q34_B_Part_10', 'Q34_B_Part_11',\n       'Q34_B_OTHER', 'Q35_B_Part_1', 'Q35_B_Part_2', 'Q35_B_Part_3',\n       'Q35_B_Part_4', 'Q35_B_Part_5', 'Q35_B_Part_6', 'Q35_B_Part_7',\n       'Q35_B_Part_8', 'Q35_B_Part_9', 'Q35_B_Part_10', 'Q35_B_OTHER'], axis=1)","841960ab":"df.columns","78d51d21":"df.head()","8f2c8c19":"df = df.drop(df.index[0])\ndf = df.drop(columns=df.columns[0])","6f7ab254":"c = ['Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', 'Q7_Part_5','Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9', 'Q7_Part_10','Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER']\ndf['Q7'] = df[c].apply(lambda x : '_'.join(x.dropna().astype(str)), axis=1)\n       \nc = ['Q9_Part_1', 'Q9_Part_2','Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7','Q9_Part_8', 'Q9_Part_9', 'Q9_Part_10', 'Q9_Part_11', 'Q9_OTHER']\ndf['Q9'] = df[c].apply(lambda x: '_'.join(x.dropna().astype(str)), axis=1)\n\nc = ['Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5','Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10','Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13', 'Q10_OTHER']\ndf['Q10'] = df[c].apply(lambda x: '_'.join(x.dropna().astype(str)), axis=1)\n       \nc = ['Q14_Part_1','Q14_Part_2', 'Q14_Part_3', 'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6','Q14_Part_7', 'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11','Q14_OTHER']\ndf['Q14'] = df[c].apply(lambda x : '_'.join(x.dropna().astype(str)), axis=1)\n\nc = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4','Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\ndf['Q17'] = df[c].apply(lambda x: '_'.join(x.dropna().astype(str)), axis=1)\n                \nc = ['Q18_Part_1', 'Q18_Part_2','Q18_Part_3', 'Q18_Part_4', 'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER']\ndf['Q18'] = df[c].apply(lambda x: '_'.join(x.dropna().astype(str)), axis=1)\n\nc =['Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4', 'Q19_Part_5','Q19_OTHER']\ndf['Q19'] = df[c].apply(lambda x: '_'.join(x.dropna().astype(str)), axis=1)","e1d7ce6a":"#Drop the old columns\ndf = df.drop(['Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', 'Q7_Part_5',\n       'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9', 'Q7_Part_10',\n       'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER','Q9_Part_1', 'Q9_Part_2',\n       'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7',\n       'Q9_Part_8', 'Q9_Part_9', 'Q9_Part_10', 'Q9_Part_11', 'Q9_OTHER',\n        'Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5',\n       'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10',\n       'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13', 'Q10_OTHER','Q14_Part_1',\n       'Q14_Part_2', 'Q14_Part_3', 'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6',\n       'Q14_Part_7', 'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11',\n       'Q14_OTHER','Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4',\n       'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9',\n       'Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER','Q18_Part_1', 'Q18_Part_2',\n       'Q18_Part_3', 'Q18_Part_4', 'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER',\n       'Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4', 'Q19_Part_5',\n       'Q19_OTHER'],axis=1)","4b615f82":"# Explode columns\ndf.Q7 = df.Q7.str.split('_').explode('Q7')\ndf.Q9 = df.Q9.str.split('_').explode('Q9')\ndf.Q10 = df.Q10.str.split('_').explode('Q10')\ndf.Q14 = df.Q14.str.split('_').explode('Q14')\ndf.Q17 = df.Q17.str.split('_').explode('Q17')\ndf.Q18 = df.Q18.str.split('_').explode('Q18')\ndf.Q19 = df.Q19.str.split('_').explode('Q19')","d35bec37":"df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)","e90f52d3":"df['Q6'] = df['Q6'].fillna(df['Q6'].mode()[0])\ndf['Q8'] = df['Q8'].fillna(df['Q8'].mode()[0])","72305dc1":"# Stacked Bar Chart with gender and age\n\nq = df.groupby(['Q1', 'Q2']).size().reset_index(name='Quantity')\nq = q.rename(columns={'Q1':'Age', 'Q2':'Gender',})\n\nfig = px.bar(q, x='Age', y='Quantity',color='Gender', title='Age by Gender Correlation', height=500)\nfig.show()","9392f80f":"# Gender and country Q2 and Q3\nq = df.groupby(['Q2','Q3']).agg({'Q1':'count'}).reset_index()\nq.columns=['Q2', 'Q3', 'counts']\nfig = px.sunburst(q, path=['Q2','Q3'], values='counts', title='Gender and Country correlation',height=600, color='counts',\n                  color_continuous_scale=px.colors.sequential.Blues)\nfig.show()","b0c0abd5":"q = df['Q6'].value_counts()\n\nfig = px.bar(x=q.index,  y=q.values, title='Writing code experience', labels={'x': 'Experience','y': 'Quantity'}, height=500)\nfig.show()","6526bea8":"q = df.groupby(['Q6', 'Q8']).agg({'Q1': 'count'}).reset_index()\nq.columns = ['Q6', 'Q8', 'counts']\nq = q.rename(columns={'Q6':'Experience', 'Q8':'Language'})\n\nfig = px.bar(q, x='Experience', y='counts', color='Language',title='Recommended language by experience', height=500)\nfig.update_layout(barmode='group')\nfig.show()","bdb383ca":"# Compare Q7 and Q8\n# Q7 - programming language use in regular basis\n# Q8 - programming language recommend\n\nq = df.groupby(['Q7', 'Q8']).agg({'Q1': 'count'}).reset_index()\nq.columns = ['Q7', 'Q8', 'counts']\nq = q.rename(columns={'Q7':'Daily use', 'Q8':'Recommended'})\n\nfig = px.bar(q, x='Recommended', y='counts', color='Daily use',title='Recommended language - Daily use  Correlation')\nfig.update_layout(barmode='group')\nfig.show()","3aff9d05":"# Q9 - Which IDE do you use\nq = df.Q9.value_counts()\nfig = px.bar(q, x=q.index, y=q.values, title='Most popular IDE', labels=({'x':'IDE', 'y':'Values'}))\nfig.show()","bd2f980b":"# Q10 - Which hosted notebook products do you use\nq = df['Q10'].value_counts()\nfig = px.bar(q, x=q.index, y=q.values, title='Most used hosted notebooks', )\nfig.show()","b3c057ae":"# Q14 - Data visualization library\nq = df['Q14'].value_counts()\nfig = px.pie(q, values=q.values, names=q.index, title='Most used data visualization library')\nfig.update_traces(textposition='inside')\nfig.show()","5420453d":"#Q17 - ML algorithms \nq = df.Q17.value_counts()\nfig = px.pie(q, values=q.values, names=q.index, title='Most used ML algorithms')\nfig.update_traces(textposition='inside')\nfig.show()","f6e3e595":"# Q18 - CV methods \nq = df.Q18.value_counts()\nfig = px.pie(q, values=q.values, names=q.index, title='Most used CV methods', height=600)\nfig.update_traces(textposition='inside')\nfig.show()","2d965eae":"# Q19 - NLP methods\nq = df.Q19.value_counts()\nfig = px.pie(q, values=q.values, names=q.index, title='Most used NLP methods')\nfig.update_traces(textposition='inside')\nfig.show()\n","75cbf720":"This is my first notebook and the main idea of it is to apply EDA ideas and work on data visualization.\n\nFeel free to comment and drop some nice tips! I'm here to learn.\n","731d1fe8":"Let's check how many missing cells are in the dataset","7c0a7c13":"### Drop columns we won't work with","27c26c2b":"#### Explode values from new columns","5b91eddb":"# Data Cleaning\n","4813107a":"After analyzing what columns have missing parts and organizing them in topics it became easier to see what columns I want to work in my analysis.\n\n* Show Q1, Q2, and Q3 and analyze them;\n\n* Compare Q6 and Q8 to show what's the most recommended programming language users recommend;\n* Compare Q7 and Q8 to see what users most recommend and what users most use\n\n* Q9 and Q10 to show what is more popular among users\n\n* Q14 to visualize which data shows more often, same procedure with Q17, Q18, and Q19;\n","8e4ad850":"# Kaggle Data Analysis ","94b4e733":"#### Join the columns","1cd43cf2":"#### Columns we are going to work","d3cb636c":"As we can see the only cells with non-missing values are `Q1 to Q3`, which corresponds to `age`, `gender`, and `country`. \n\n\nThe missing values are in:\n* `Q4`: Formal education\n* `Q5`: Current role\n* `Q6`: Years programming\n* `Q7`: What programming language do you use (divided into 13 parts)\n* `Q8`: What programming language would you recommend \n* `Q9`: Which IDE do you use (divided into 12 parts)\n* `Q10`: Which hosted notebook products do you use (divided into 14 parts)\n* `Q11`: What kind of computing platform do you use in data science projects\n* `Q12`: Which type of hardware do you use (divided into 4 parts)\n* `Q13`: How many times have you used a TPU\n* `Q14`: What data visualization libraries do you use (divided into 12 parts)\n* `Q15`: For how many years you've been using machine learning methods\n* `Q16`: What machine learning frameworks do you use (divided into 16 parts)\n* `Q17`: ML algorithms do you use (divided into 12 parts)\n* `Q18`: CV methods do you use (divided into 7 parts)\n* `Q19`: NLP methods do you use (divided into 6)\n\nQuestions about workplace:\n\n* `Q20`: Size of the company that you work\n* `Q21`: How many employees work with data science in your workplace\n* `Q22`: Do your workplace implements ML methods\n* `Q23`: Activities that is an important step in your job (divided into 8 parts)\n* `Q24`: How much are you paid in a year \n\nQuestions about services and tools:\n\n* `Q25`: How much you've invested in ML, Cloud Services in the past 5 years\n* `Q26`: What Cloud Computing services do you use (divided into 12 parts)\n* `Q27`: What Cloud Computing products do you use (divided into 12 parts)\n* `Q28`: What ML products do you use (divided into 11 parts)\n* `Q29`: What Big Data products do you use (divided into 18 parts)\n* `Q30`: What Big Data products do you use most\n* `Q31`: What BI tools do you use (divided into 15 parts)\n* `Q32`: What BI tools do you use the most\n* `Q33`: Do you use any automated ML tools? (divided into 8 parts)\n* `Q34`: What automate ML tools do you use regularly (divided into 12 parts)\n* `Q35`: Do you use any tools to help manage ML experiments? (divided into 11 parts)\n* `Q36`: Where do you share your data analysis or ML applications? (divided into 10 parts)\n* `Q37`: What platforms have you completed ML courses (divided into 12 parts)\n* `Q38`: What are the primary tools do you use to analyze data\n* `Q39`: Favorite media sources that report on DS topics (divided into 12 parts)\n\nQuestions about future:\n\n* `Q26_B`: Cloud Computing platform you hope to become more familiar into 2 years (divided into 12 parts)\n* `Q27_B`: Cloud Computing products you hope to become more familiar into 2 years (divided into 12 parts)\n* `Q28_B`: ML products you hope to become more familiar into 2 years (divided into 11 parts)\n* `Q29_B`: Big Data products you hope to become more famliar into 2 years (divided into 18 parts)\n* `Q31_B`: BI tools you hope to become more familiar into 2 years (divided into 15 parts)\n*  `Q33_B`: Categories of automating ML tools you hope to become familiar into 2 years (divided into 8 parts)\n* `Q34_B`: Specific automated ML tools you hope to become more familiar into 2 years (divided into 12 parts)\n* `Q35_B`: Managing ML experiments tools you hope to become more familiar into 2 years (divided into 11 parts)","ffcff8ef":"#### Drop 1st row and 1st column","0bc7d6bb":"# Data visualization","4a8e9cad":"#### Replace empty cells with NaN","84f85902":"### Join columns","592d7171":"#### Fix Q6 and Q8 missing values"}}