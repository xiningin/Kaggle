{"cell_type":{"e3d6be7f":"code","04dab19f":"code","ed6903b2":"code","ead4d8a3":"code","4669e402":"code","4f334dec":"code","2cdba90d":"code","5d4d5287":"code","15f9f3d6":"code","7bafd32b":"code","05fd9bd9":"code","b06c0f93":"code","7f1b7cc2":"code","b2519912":"code","b88c27ef":"code","7feb4504":"code","6746e65c":"code","3f2e260c":"code","779e57df":"code","d3b09938":"code","58ab7329":"code","d37a0602":"code","26a2d5a2":"code","d5648e61":"code","9a4e203f":"code","c2e3f72f":"code","44fdd2d0":"code","1bcc92d7":"code","0d2e9a97":"code","4a1c6196":"code","07c6a93f":"code","7ccb8b09":"code","f7351a17":"code","a168bfc6":"code","02f56331":"code","96157d20":"code","15285b0b":"code","303ec795":"code","fcb94f81":"code","9d93797b":"code","cd27a529":"code","cca483af":"code","395865d1":"code","05a1d3e7":"code","d7264003":"code","7e65d832":"code","ab5266f5":"code","9dfd64ae":"code","a03dda10":"code","83fcdb8c":"code","3b5d2833":"code","c088ea76":"code","75e6038b":"code","15b38705":"code","14433054":"code","1effe653":"code","23f02d18":"code","740a5bc8":"code","f45ec9d3":"code","4f716ec4":"code","52fcfaa8":"code","27e94f9c":"code","7357de52":"code","a83bbe2f":"code","3265fa37":"code","24ecce94":"code","898e8211":"code","008eb2c9":"code","d3e7ab91":"code","27e2c6df":"code","d3576890":"code","974c7c3e":"code","52aafd99":"code","2b4cd33f":"code","ff8bd5a3":"code","3186721e":"code","6531dd3f":"code","b05132cc":"code","03474df2":"code","52a9d3f2":"code","479fdcdb":"code","85680f26":"code","a827a9bb":"code","2e7b0489":"code","79399b0f":"code","269c3004":"code","f1171feb":"code","6a597a97":"code","43cd02cf":"code","1de4212c":"code","e0699f5f":"code","da4f4fae":"code","aeb0e78f":"code","6595f38d":"code","99f9a3f3":"code","8dfbd7b2":"code","83348358":"code","a77ba84a":"code","16dfdab8":"code","15c5a531":"code","ed173f5a":"code","d4ba28af":"code","f434bdd0":"code","e9ea079b":"code","3034104c":"code","6b35f731":"code","ebce1534":"code","59a8f74f":"code","fa424a9b":"code","a488e930":"code","6f6932a4":"code","0ccdef03":"code","81c8b7dd":"code","481b99ce":"code","be18b7b6":"code","21187be8":"code","9e0fb31a":"markdown"},"source":{"e3d6be7f":"import pandas as pd\nimport glob\nfrom fastai.vision import *\nimport os","04dab19f":"path = '..\/input\/severstal-steel-defect-detection\/'","ed6903b2":"path_train = '..\/input\/severstal-steel-defect-detection\/train_images\/'","ead4d8a3":"path_test = '..\/input\/severstal-steel-defect-detection\/test_images\/'","4669e402":"df = pd.read_csv(path + 'train.csv')","4f334dec":"df = df[:100]","2cdba90d":"df.head()","5d4d5287":"hist = df['ClassId'].hist(bins=4)","15f9f3d6":"df_2 = df.groupby(['ImageId']).agg({'ClassId': lambda x: list(x),'EncodedPixels': lambda x: list(x)})","7bafd32b":"df_2.head()","05fd9bd9":"df_2['ImageId'] = df_2.index","b06c0f93":"df_2.head()","7f1b7cc2":"df_2 = df_2.reset_index(drop=True)","b2519912":"df_2.head()","b88c27ef":"df.columns.tolist()","7feb4504":"df_2 = df_2[['ImageId', 'ClassId', 'EncodedPixels']]","6746e65c":"df_2.head()","3f2e260c":"def func(x, y):\n    a = ['','','','']\n    for i, j in zip(x, y):\n        a[i-1] = j\n        \n    return a      \n","779e57df":"df_2['EncodedPixels'] = df_2.apply(lambda x: func(x['ClassId'], x['EncodedPixels']), axis=1)","d3b09938":"df_2.head(10)","58ab7329":"img = open_image(path_train + df_2['ImageId'][5])\nimg.show(figsize=(20,10))\nprint(img.size)","d37a0602":"def rle_decode_3(mask_rle:str, shape=(256, 1600))->NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n    starts -= 1    # \u041e\u0442\u043d\u0438\u043c\u0430\u0435\u043c \u043e\u0442 \u0432\u0441\u0435\u0445 \u0441\u0442\u0430\u0440\u0442\u043e\u0432\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 1 \u0442.\u043a. \u0438\u043d\u0434\u0435\u043a\u0441\u0430\u0446\u0438\u044f \u0441 0.\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint)\n    for a, b in zip(starts, ends): img[a:b] = 1\n    img = img.reshape(shape, order='F')\n    return img","26a2d5a2":"def open_mask_rle_2(mask_rle:str, shape=(256, 1600))->ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode_3(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(-1, shape[0], shape[1])\n    #return ImageSegment(x)\n    return x","d5648e61":"def rle_encode_3(img:NPArrayMask, shape=(256, 1600))->str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(order='F') , [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","9a4e203f":"df_2['EncodedPixels'][1]","c2e3f72f":"rle_decode_3(df_2['EncodedPixels'][1][2])","44fdd2d0":"ImageSegment(open_mask_rle_2(df_2['EncodedPixels'][1][2]))","1bcc92d7":"mask = rle_decode_3(df_2['EncodedPixels'][1][2])","0d2e9a97":"type(mask)","4a1c6196":"rle_encode_3(mask)","07c6a93f":"fn = path_train + df_2['ImageId'][5]\nimg = open_image(fn)\nimg","7ccb8b09":"mask = open_mask_rle_2(df_2['EncodedPixels'].iloc[5][3])\nImageSegment(mask)","f7351a17":"mask = open_mask_rle_2(df_2['EncodedPixels'].iloc[5][2])\nImageSegment(mask)","a168bfc6":"df_2[df_2['ImageId'] == 'db4867ee8.jpg']","02f56331":"df_2['EncodedPixels'].iloc[40]","96157d20":"df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels'].item()","15285b0b":"for i in df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels']:\n    print(i)","303ec795":"#fn = path_train + df_2.index['db4867ee8.jpg']\nfn = path_train + '000f6bf48.jpg'\n#print(fn)\nimg = open_image(fn)\nshape = img.shape[-2:]\n#print(shape)\n#img = open_image(fn)\nfinal_mask = torch.zeros((1, *shape))\n#for i, rle in enumerate(df_2['EncodedPixels'].iloc[5]):\n#for i, rle in enumerate(df_2['EncodedPixels'].loc['db4867ee8.jpg']):  \nfor i, rle in enumerate(df_2[df_2['ImageId'] == '000f6bf48.jpg']['EncodedPixels'].item()):\n    #print(rle)\n    if isinstance(rle, str):\n        mask = open_mask_rle_2(rle)\n        #print(mask.shape)\n        final_mask += (i + 1) * mask\n#mask = open_mask_rle_2(df_train['EncodedPixels'].iloc[0])\nfinal_mask_2 = ImageSegment(final_mask)\n_,axs = plt.subplots(3,1, figsize=(20,10))\nimg.show(ax=axs[0], title='no mask')\nimg.show(ax=axs[1], y=final_mask_2, title='masked')\nfinal_mask_2.show(ax=axs[2], title='mask only', alpha=1.)","fcb94f81":"def get_y_fn(fn):\n    #print(fn)\n    #fn = fn.replace(path_train, '')\n    x = df_train[df_train['ImageId'] == fn]['EncodedPixels'].item()\n    #print('!')\n    return open_mask_rle_2(x)","9d93797b":"def get_y_fn_mcl(fn):\n    #print(fn)\n    final_mask = torch.zeros((1, 256, 1600))\n    for i, rle in enumerate(df_2[df_2['ImageId'] == fn]['EncodedPixels'].item()):\n    #for i, rle in enumerate(df_2['EncodedPixels'].loc[fn]):    \n        if isinstance(rle, str):\n            mask = open_mask_rle_2(rle)\n            #print('mask=', mask.shape)\n            final_mask += (i + 1) * mask\n    return ImageSegment(final_mask)","cd27a529":"get_y_fn_mcl('000f6bf48.jpg')","cca483af":"class SegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): return get_y_fn_mcl(fn)\n    \nclass SegmentationItemList(SegmentationItemList):\n    _label_cls = SegmentationLabelList","395865d1":"path_train","05a1d3e7":"df_2.head()","d7264003":"train_list = (SegmentationItemList\n                .from_df(df_2, path_train))","7e65d832":"#codes = ['0','1']\ntrain_list = (SegmentationItemList\n                .from_df(df_2, path_train)\n                .split_by_rand_pct()\n                .label_from_df(cols='ImageId', label_cls=SegmentationLabelList, classes=[0, 1, 2, 3, 4])\n                #.transform(get_transforms(), size=256,resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                .transform(get_transforms(), size=(128, 800),resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                #.transform(get_transforms(flip_vert=True), tfm_y=True)\n                .databunch(bs=10, num_workers=10))","ab5266f5":"type(train_list)","9dfd64ae":"train_list.show_batch(rows=3, figsize=(20,10))","a03dda10":"def dice_func(input, target):\n    smooth = 0\n    input = input[:,1,:,:]\n    iflat = input.flatten().float()\n    tflat = target.flatten().float()\n    intersection = (iflat * tflat).sum()\n    return ((2. * intersection + smooth) \/\n              (iflat.sum() + tflat.sum() + smooth))\n\ndef dice(input:Tensor, targs:Tensor, iou:bool=False)->Rank0Tensor:\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n,-1)\n    targs = targs.view(n,-1)\n    intersect = (input * targs).sum().float()\n    union = (input+targs).sum().float()\n    if not iou: return (2. * intersect \/ union if union > 0 else union.new([1.]).squeeze())\n    else: return intersect \/ (union-intersect+1.0)","83fcdb8c":"#learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir=\"\/tmp\/model\/\")","3b5d2833":"learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir='\/kaggle\/working\/models')","c088ea76":"lr_find(learn)","75e6038b":"learn.recorder.plot()","15b38705":"learn.fit_one_cycle(10,max_lr = 1e-2)    # 40","14433054":"lr_find(learn)\nlearn.recorder.plot()","1effe653":"learn.fit_one_cycle(20,max_lr = slice(1e-3,1e-2))    # 40","23f02d18":"learn.unfreeze()","740a5bc8":"learn.fit_one_cycle(20, max_lr = 1e-3)","f45ec9d3":"#learn.unfreeze()","4f716ec4":"learn.fit_one_cycle(20, max_lr = 1e-4) ","52fcfaa8":"#learn.fit_one_cycle(20, max_lr = 1e-4)","27e94f9c":"#learn.fit_one_cycle(20, max_lr = 1e-5)","7357de52":"#learn.save('stage-1')\n#learn.export(\"\/kaggle\/working\/steel-1.pkl\")","a83bbe2f":"learn.save('trained_model_1')\nlearn.export(\"\/kaggle\/working\/trained_model_1.pkl\")","3265fa37":"learn = load_learner('\/kaggle\/working\/', 'trained_model_1.pkl')","24ecce94":"learn = unet_learner(train_list, models.resnet18, pretrained=False, metrics=[dice], wd=1e-3, model_dir='\/kaggle\/working\/models')","898e8211":"learn = learn.load(\"trained_model_1\")","008eb2c9":"learn.fit_one_cycle(10,max_lr = 1e-5)    # 40","d3e7ab91":"learn.recorder.plot_lr(show_moms=True)","27e2c6df":"learn.recorder.plot_losses()","d3576890":"learn.recorder.plot_metrics()","974c7c3e":"learn.show_results()","52aafd99":"learn.lr_find()\nlearn.recorder.plot()","2b4cd33f":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))","ff8bd5a3":"submit.sort_values(by=['ImageId'])","3186721e":"submit.head()","6531dd3f":"learn.model.cuda()","b05132cc":"files = os.listdir(path=path_test)","03474df2":"#a = learn.predict(open_image(path_test + '86c1f219f.jpg'))[1].data.numpy()\na = rle_decode_3(df_2['EncodedPixels'][1][2])\nb = a.flatten(order='F')\nd = {1: '', 2: '', 3: '', 4: ''}\nfor start, count in zip (rle_encode_3(a).split(' ')[::2], rle_encode_3(a).split(' ')[1::2]):\n    #print(start)\n    #print(b[int(start)-1])\n    d[b[int(start)-1]] += str(start) + ' ' +  str(count) + ' '\nd","52a9d3f2":"d[3] = '294661 251 294917 251 295173 251 295429 251 295685 251 295941 251 296197 251 296453 251 296709 251 296965 251 297221 251 297477 251'","479fdcdb":"d","85680f26":"img_name = '86c1f219f.jpg'","a827a9bb":"sub_list = []\nfor i in d:\n    sub_list += [[img_name, i, d[i]]]\nsub_list","2e7b0489":"sub_list = []\nfor img_name in files:\n    #print(img_name)\n    pred = learn.predict(open_image(path_test + img_name))[1].data.numpy()\n    print(Imagese)\n    #print(pred)\n    pred_fl = pred.flatten(order='F')\n    rle_enc = rle_encode_3(pred).split(' ')\n    #print(rle_enc)\n    d = {1: '', 2: '', 3: '', 4: ''}\n    for start, count in zip (rle_enc[::2], rle_enc[1::2]):\n        #print(start)\n        #print(pred_fl[int(start)-1])\n        d[pred_fl[int(start)-1]] += str(start) + ' ' +  str(count) + ' '\n        \n    for i in d:\n        sub_list += [[img_name, i, d[i]]]\n","79399b0f":"df_2['EncodedPixels'].iloc[0]","269c3004":"df_2['EncodedPixels'].iloc[0][0]","f1171feb":"pred = rle_decode_3(df_2['EncodedPixels'].iloc[0][0])","6a597a97":"pred_fl = pred.flatten(order='F')","43cd02cf":"rle_enc = rle_encode_3(pred).split(' ')\nrle_enc","1de4212c":"d = {1: '', 2: '', 3: '', 4: ''}\nfor start, count in zip (rle_enc[::2], rle_enc[1::2]):\n    print(start)\n    print(pred_fl[int(start)-1])\n    d[pred_fl[int(start)-1]] += str(start) + ' ' +  str(count) + ' '","e0699f5f":"d","da4f4fae":"pred = learn.predict(open_image(path_test + '289d347d9.jpg'))[1].data.numpy()\npred_fl = pred.flatten(order='F')\nrle_enc = rle_encode_3(pred).split(' ')\n","aeb0e78f":"rle_enc","6595f38d":"rle_enc","99f9a3f3":"pred_fl[55153+5]","8dfbd7b2":"pred_fl[2740-1]","83348358":"pred_fl[2616-1]","a77ba84a":"sub_list","16dfdab8":"submission_df = pd.DataFrame(sub_list, columns=['ImageId', 'EncodedPixels', 'ClassId'])\nsubmission_df.head()","15c5a531":"d","ed173f5a":"b = np.where(a != 0)","d4ba28af":"b","f434bdd0":"a[0][38][612]","e9ea079b":"test_count = len(files)\nresults = []","3034104c":"def run_length(label_vec):\n    encode_list = encode(label_vec)\n    index = 1\n    class_dict = {}\n    for i in encode_list:\n        if i[1] != len(codes)-1:\n            if i[1] not in class_dict.keys():\n                class_dict[i[1]] = []\n            class_dict[i[1]] = class_dict[i[1]] + [index, i[0]]\n        index += i[0]\n    return class_dict","6b35f731":"from itertools import groupby","ebce1534":"def encode(input_string):\n    return [(len(list(g)), k) for k,g in groupby(input_string)]","59a8f74f":"codes = ['0','1','2','3', '4'] ","fa424a9b":"learn.model.cuda()","a488e930":"from tqdm import tqdm","6f6932a4":"for i, img in tqdm(enumerate(files)):\n    img_name = img\n    pred = learn.predict(open_image(path_test + img))[1].data.numpy().flatten()\n    class_dict = run_length(pred)\n    print(class_dict)\n","0ccdef03":"for i, img in tqdm(enumerate(files)):\n    img_name = img\n    pred = learn.predict(open_image(path_test + img))[1].data.numpy().flatten()\n    class_dict = run_length(pred)\n    if len(class_dict) == 0:\n        for i in range(4):\n            results.append([img_name+ \"_\" + str(i+1), ''])\n    else:\n        for key, val in class_dict.items():\n            results.append([img_name + \"_\" + str(key+1), \" \".join(map(str, val))])\n        for i in range(4):\n            if i not in class_dict.keys():\n                results.append([img_name + \"_\" + str(i+1), ''])\n        \n        \n    if i%20==0:\n        print(\"\\r{}\/{}\".format(i, test_count), end=\"\")","81c8b7dd":"results","481b99ce":"files = list(path_test.glob(\"**\/*.jpg\"))","be18b7b6":"def get_predictions(path_test, learn):\n    # predicts = get_predictions(path_test, learn)\n    learn.model.cuda()\n    files = list(path_test.glob(\"**\/*.jpg\"))    #<---------- HERE\n    test_count = len(files)\n    results = []\n    for i, img in enumerate(files):\n        img_name = img.stem + '.jpg'\n        pred = learn.predict(open_image(img))[1].data.numpy().flatten()\n        class_dict = run_length(pred)\n        if len(class_dict) == 0:\n            for i in range(4):\n                results.append([img_name+ \"_\" + str(i+1), ''])\n        else:\n            for key, val in class_dict.items():\n                results.append([img_name + \"_\" + str(key+1), \" \".join(map(str, val))])\n            for i in range(4):\n                if i not in class_dict.keys():\n                    results.append([img_name + \"_\" + str(i+1), ''])\n        \n        \n        if i%20==0:\n            print(\"\\r{}\/{}\".format(i, test_count), end=\"\")\n    return results    \n\nsub_list = get_predictions(path_test, learn)","21187be8":"test_list = (SegmentationItemList\n                .from_df(df_2, path_train)\n                .split_by_rand_pct()\n                .label_from_df(cols='ImageId', label_cls=SegmentationLabelList, classes=[0, 1, 2, 3, 4])\n                .transform(get_transforms(), size=256,resize_method=ResizeMethod.SQUISH, tfm_y=True)\n                #.transform(get_transforms(flip_vert=True), tfm_y=True)\n                .databunch(bs=10, num_workers=10))","9e0fb31a":"\u041c\u0430\u0441\u043a\u0438 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438(train_images) \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u044b(Run Lenght Encode \u0438\u043b\u0438 RLE) - \"\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u043b\u0438\u043d\u044b \u043f\u0440\u043e\u0431\u0435\u0433\u0430 \u043e\u0442 \u043f\u0438\u043a\u0441\u0435\u043b\u044f\". \u0414\u0430\u043d\u043d\u0430\u044f \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u043a\u0430 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0434\u0432\u0430 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f: \u043f\u0435\u0440\u0432\u043e\u0435 -\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u0430\u044f \u043f\u043e\u0437\u0438\u0446\u0438\u044f(\u043d\u043e\u043c\u0435\u0440 \u043f\u0438\u043a\u0441\u0435\u043b\u044f); \u0432\u0442\u043e\u0440\u043e\u0435 - \u0434\u043b\u0438\u043d\u0430 \u043f\u0440\u043e\u0431\u0435\u0433\u0430 \u043e\u0442 \u044d\u0442\u043e\u0433\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u044f. \n\u041f\u0438\u043a\u0441\u0435\u043b\u0438 \u043d\u0443\u043c\u0435\u0440\u0443\u044e\u0442\u0441\u044f \u0441\u0432\u0435\u0440\u0445\u0443 \u0432\u043d\u0438\u0437, \u0437\u0430\u0442\u0435\u043c \u0441\u043b\u0435\u0432\u0430 \u043d\u0430\u043f\u0440\u0430\u0432\u043e: 1 - \u043f\u0438\u043a\u0441\u0435\u043b\u044c (1,1), 2 - \u043f\u0438\u043a\u0441\u0435\u043b\u044c (2,1) \u0438 \u0442. \u0434. \n\u041f\u0440\u0438\u043c\u0435\u0440\u044b:\n\u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u00ab1 3\u00bb \u043f\u043e\u0434\u0440\u0430\u0437\u0443\u043c\u0435\u0432\u0430\u044e\u0442 \u043d\u0430\u0447\u0430\u043b\u043e \u043f\u0440\u043e\u0431\u0435\u0433\u0430 \u0441 \u043f\u0438\u043a\u0441\u0435\u043b\u044f (1,1)(\u0432\u043a\u043b\u044e\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e), \u0434\u043b\u0438\u043d\u043e\u044e 3 \u043f\u0438\u043a\u0441\u0435\u043b\u044f, \u0442\u043e \u0435\u0441\u0442\u044c \u043f\u0438\u043a\u0441\u0435\u043b\u0438(1,1); (1,2); (1,3).\n\n\u0423\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u00ab1 3 10 5\u00bb \u043f\u043e\u0434\u0440\u0430\u0437\u0443\u043c\u0435\u0432\u0430\u0435\u0442, \u0447\u0442\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0438 1,2,3,10,11,12,13,14 \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u044b \u0432 \u043c\u0430\u0441\u043a\u0443. \n\n\u0420\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 256(\u0432\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u044c) * 1600(\u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u044c)\n\n\u0414\u043b\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f 29102 5:\n\u0441\u0442\u0430\u0440\u0442\u043e\u0432\u0430\u044f \u043f\u043e\u0437\u0438\u0446\u0438\u044f \u043d\u0430 \u043f\u0438\u043a\u0441\u0435\u043b\u0435: \n\u0441\u043c\u0435\u0449\u0435\u043d\u043d\u043e\u043c\u0443 \u0432\u043f\u0440\u0430\u0432\u043e \u043f\u043e \u043d\u0430\u0448\u0435\u043c\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044e \u043d\u0430 29102 \/\/ 256 = 113 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439\n\u0441\u043c\u0435\u0449\u0435\u043d\u043d\u043e\u043c\u0443 \u0432\u043d\u0438\u0437 \u043d\u0430 29102 % 256 = 174 \u043f\u0438\u043a\u0441\u0435\u043b\u044f.\n\u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0437\u0438\u0446\u0438\u044e \u0441 \u0438\u043d\u0434\u0435\u043a\u0441\u0430\u043c\u0438 (173, 113), \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c, \u0447\u0442\u043e \u0438\u043d\u0434\u0435\u043a\u0441\u0430\u0446\u0438\u044f \u0443 \u043d\u0430\u0441 \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f \u0441 0.\n\u0414\u0430\u043b\u0435\u0435 \u0441\u043e \u0441\u0442\u0430\u0440\u0442\u043e\u0432\u043e\u0439 \u043f\u043e\u0437\u0438\u0446\u0438\u0438 \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u043c \u0432 \u043d\u0430\u0448\u0443 \u043c\u0430\u0441\u043a\u0443 \u0435\u0449\u0451 4 \u043f\u0438\u043a\u0441\u0435\u043b\u044f \u0432\u043d\u0438\u0437, \u0438\u0442\u043e\u0433\u043e 5 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439: \n(173, 112); (174, 112); (175, 112); (176, 112); (177, 112)"}}