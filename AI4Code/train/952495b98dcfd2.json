{"cell_type":{"f40e72e1":"code","912e8e9c":"code","82430bfd":"code","b0b6d16d":"code","6f9e7457":"code","a2c750f6":"code","6d770e9e":"code","698d0322":"code","d38e8f0f":"code","cab5994a":"code","4bbbd63a":"code","7c5f4948":"code","de950511":"code","75546cf3":"code","d8e66ed3":"code","680bea71":"code","073720e9":"code","ed93bf51":"code","37d77796":"code","656ae31a":"code","6c6dd8b6":"code","67cb69ff":"code","dc150d23":"code","3570ec9a":"markdown","75b040b2":"markdown","dc69ee95":"markdown","082700de":"markdown","3d65bc84":"markdown","a4b744f5":"markdown","6dafcc6e":"markdown","2e00d71b":"markdown","d815c415":"markdown","e7bd0a34":"markdown","e6aa7487":"markdown","a67c14a8":"markdown","4ac70ef4":"markdown","3f9f3c71":"markdown","d9035a61":"markdown","0e4f4873":"markdown","fb2a609c":"markdown","ee33669e":"markdown","265a4e79":"markdown","9072d373":"markdown","a7e426e6":"markdown","37662f71":"markdown"},"source":{"f40e72e1":"import pandas as pd\nimport numpy as np\ncolumns = ['user_id', 'item_id', 'rating', 'timestamp']\nmovie_length = pd.read_csv('..\/input\/ratings.dat', header = 0, \\\n                           names = columns, sep = '::', engine = 'python')\nmovie_length = movie_length.sort_values(['user_id', 'item_id'])\nmovie_length.head()","912e8e9c":"print('Data movie length shape: %s'%str(movie_length.shape))\nprint('No customers: %s'%str(np.unique(movie_length.iloc[:, 0]).shape[0]))\nprint('No movies: %s'%str(np.unique(movie_length.iloc[:, 1]).shape[0]))","82430bfd":"movie_length['user_id'].value_counts().describe()","b0b6d16d":"import matplotlib.pyplot as plt\n%matplotlib inline\nmovie_length[['user_id', 'item_id']].groupby(['user_id']).count().\\\nhist(bins = 20, figsize = (12, 8))\nplt.title('Distribution of no ratings by each customer')\nplt.xlabel('No ratings')\nplt.ylabel('No customers')","6f9e7457":"movie_length['item_id'].value_counts().describe()","a2c750f6":"movie_length[['user_id', 'item_id']].groupby(['item_id']).count().\\\nhist(bins = 20, figsize = (12, 8))\nplt.title('Distribution of no ratings per each movie')\nplt.xlabel('No ratings')\nplt.ylabel('No movies')","6d770e9e":"#declare split_rate for train\/total ratings\nsplit_rate = 2\/3\n\ndef split_train_test(dataset):\n    gb = dataset.groupby('user_id')\n    ls = [gb.get_group(x) for x in gb.groups]\n    items = [x for x in gb.groups]\n    index_size = [{'i': i, 'index':gb.groups[i], 'size':len(gb.groups[i])} for i in items]\n    index_train = pd.Int64Index([])\n    index_test = pd.Int64Index([])\n    for x in index_size:\n        np.random.shuffle(x['index'].values)\n        le = int(x['size']*split_rate)\n        index_train = index_train.append(x['index'][:le])\n        index_test = index_test.append(x['index'][le:])\n    train = dataset.iloc[index_train].values\n    test = dataset.iloc[index_test].values\n    #minus id to 1 to index start from 0\n    train[:, 0] -= 1\n    train[:, 1] -= 1\n    test[:, 0] -= 1\n    test[:, 1] -= 1\n    return train, test\n\ntrain, test = split_train_test(movie_length)","698d0322":"n_users = np.max(train[:, 0] + 1) #plus one because index start from 0\nn_items = np.max(train[:, 1] + 1)\nn_ratings = train.shape[0]\nprint('N user dimesion: %s'%n_users)\nprint('M item dimesion: %s'%n_items)\nprint('S Number of rating: %s'%n_ratings)\nK = 2\ntheta = 0.75\nlamda = 0.2\n#Inititalize random matrix according to Gauss distribution\nI = np.random.randn(n_items, K)\nU = np.random.randn(K, n_users)","d38e8f0f":"import scipy.sparse as sparse\n#Rating matrix\nY = np.zeros(shape = (n_items, n_users))\nprint('Y utility matrix shape: %s'%str(Y.shape))\nY = sparse.coo_matrix((train[:, 2], (train[:, 1], train[:, 0])),\\\n                      shape = (n_items, n_users), dtype = np.float).toarray()","cab5994a":"R = sparse.coo_matrix((np.ones((n_ratings,)), (train[:, 1], train[:, 0])),\\\n                      shape = (n_items, n_users)).toarray()","4bbbd63a":"def standardize_Y(Y):\n    sum_rating = Y.sum(axis = 0)\n    u_rating = np.count_nonzero(Y, axis = 0)\n    u_mean = sum_rating\/u_rating\n    for n in range(n_users):\n        for m in range(n_items):\n            if Y[m, n] != 0:\n                Y[m, n] -= u_mean[n]\n    return Y, u_mean\n\nY_stad, u_mean = standardize_Y(Y)","7c5f4948":"def updateU(U):\n    for n in range(n_users):\n    # Matrix items include all items is rated by user n\n        i_rated = np.where(Y_stad[:, n] != 0)[0] #item's index rated by n\n        In = I[i_rated, :]\n        if In.shape[0] == 0:\n            U[:, n] = 0\n        else: \n            s = In.shape[0]\n            u_n = U[:, n]\n            y_n = Y_stad[i_rated, n]\n            grad = -1\/s * np.dot(In.T,(y_n-np.dot(In, u_n))) + lamda*u_n\n            U[:, n] -= theta*grad\n    return U","de950511":"def updateI(I):\n    for m in range(n_items):\n    # Matrix users who rated into item m\n        i_rated = np.where(Y_stad[m, :] != 0)[0] #user's index rated into m\n        Um = U[:, i_rated]\n        if Um.shape[1] == 0: \n            I[m, :] = 0\n        else:\n            s = Um.shape[1]\n            i_m = I[m, :]\n            y_m = Y_stad[m, i_rated]\n            grad = -1\/s * np.dot(y_m - np.dot(i_m, Um), Um.T) + lamda*i_m\n            I[m, :] -= theta*grad\n    return I","75546cf3":"def pred(U, I):\n    #predict utility matrix base on formula Y_hat = I.U\n    Y_hat = np.dot(I, U)\n    #invert to forecast values by plus user's mean ratings\n    for n in range(n_users):\n        Y_hat[:, n] += u_mean[n]\n    #convert to interger values because of rating is integer\n    Y_hat = Y_hat.astype(np.int32) \n    #replace values > 5 by 5 and values < 1 by 1\n    Y_hat[Y_hat > 5] = 5\n    Y_hat[Y_hat < 1] = 1\n    return Y_hat\n\ndef pred_train_test(Y_hat, R):\n    #replace values have not yet rated by 0 \n    Y_pred = Y_hat.copy()\n    Y_pred[R == 0] = 0\n    return Y_pred","d8e66ed3":"def loss(Y, Y_hat):\n    error = Y-Y_hat\n    loss_value = 1\/(2*n_ratings)*np.linalg.norm(error, 'fro')**2 + \\\n    lamda\/2*(np.linalg.norm(I, 'fro')**2 + np.linalg.norm(U, 'fro')**2)\n    return loss_value","680bea71":"Y_test = sparse.coo_matrix((test[:, 2], (test[:, 1], test[:, 0])), \\\n                           shape = (n_items, n_users), dtype = np.float).toarray()\nR_test = sparse.coo_matrix((np.ones(test.shape[0]), (test[:, 1], test[:, 0])), \\\n                           shape = (n_items, n_users), dtype = np.float).toarray()","073720e9":"import math\ndef RMSE(Y_test, Y_pred):\n    error = Y_test - Y_pred\n    n_ratings = test.shape[0]\n    rmse = math.sqrt(np.linalg.norm(error, 'fro')**2\/n_ratings)\n    return rmse","ed93bf51":"def fit(Umatrix, Imatrix, Ytrain, Ytest, n_iter, log_iter):\n    for i in range(n_iter):\n        #update U and I\n        Umatrix = updateU(Umatrix)\n        Imatrix = updateI(Imatrix)\n        #calculate Y_hat\n        Y_hat = pred(Umatrix, Imatrix)\n        #calculate Y_hat_train by replace non ratings by 0\n        Y_pred_train = pred_train_test(Y_hat, R)\n        #calculate loss function\n        loss_value = loss(Ytrain, Y_pred_train)\n        #calculate Y_pred on test dataset\n        Y_pred_test = pred_train_test(Y_hat, R_test)\n        #calculate RMSE\n        rmse = RMSE(Ytest, Y_pred_test)\n        if i % log_iter == 0:\n            print('Iteration: {}; RMSE: {}; Loss value: {}'.format(i, rmse, loss_value))\n    return Y_hat, Y_pred_test   \n# Y_hat, Y_pred = fit(Umatrix = U, Imatrix = I, Ytrain = Y, Ytest = Y_test, n_iter = 100, log_iter = 10)","37d77796":"class Data(object):\n    \"\"\"\n    This class used to manage data.\n    Two arguments:\n    dataset: pandas data frame include user_id, item_id and rating\n    split_rate: number train ratings\/ total ratings\n    \"\"\"\n    def __init__(self, dataset, split_rate):\n        self.dataset = dataset\n        self.split_rate = split_rate\n        self.train, self.test = self.split_train_test(self.dataset)\n        self.n_users = np.max(self.train[:, 0] + 1) #plus one because index start from 0\n        self.n_items = np.max(self.train[:, 1] + 1)\n        self.Ytrain, self.Rtrain = self.utility_matrix(self.train)\n        self.Ytest , self.Rtest  = self.utility_matrix(self.test)\n        self.Ystad,  self.u_mean = self.standardize_Y(self.Ytrain)\n        self.n_ratings = self.train.shape[0]\n        \n    def split_train_test(self, dataset):\n        \"split train and test\"\n        gb = dataset.groupby('user_id')\n        ls = [gb.get_group(x) for x in gb.groups]\n        items = [x for x in gb.groups]\n        index_size = [{'i': i, 'index':gb.groups[i], 'size':len(gb.groups[i])} for i in items]\n        index_train = pd.Int64Index([])\n        index_test = pd.Int64Index([])\n        for x in index_size:\n            np.random.shuffle(x['index'].values)\n            le = int(x['size']*self.split_rate)\n            index_train = index_train.append(x['index'][:le])\n            index_test = index_test.append(x['index'][le:])\n        train = dataset.iloc[index_train].values\n        test = dataset.iloc[index_test].values\n        #minus id to 1 to index start from 0\n        train[:, 0] -= 1\n        train[:, 1] -= 1\n        test[:, 0] -= 1\n        test[:, 1] -= 1\n        return train, test\n    \n    def utility_matrix(self, data_mtx):\n        \"create Y and R matrix\"\n        Y = np.zeros(shape = (self.n_items, self.n_users))\n        Y = sparse.coo_matrix((data_mtx[:, 2], (data_mtx[:, 1], data_mtx[:, 0])), \\\n                              shape = (self.n_items, self.n_users), dtype = np.float).toarray()\n        R = sparse.coo_matrix((np.ones((data_mtx.shape[0],)), (data_mtx[:, 1], data_mtx[:, 0])), \\\n                              shape = (self.n_items, self.n_users)).toarray()\n        return Y, R\n    \n    def standardize_Y(self, Y):\n        \"standard data to mean ratings of each user = 0\"\n        sum_rating = Y.sum(axis = 0)\n        u_rating = np.count_nonzero(Y, axis = 0)\n        u_mean = sum_rating\/u_rating\n        for n in range(self.n_users):\n            for m in range(self.n_items):\n                if Y[m, n] != 0:\n                    Y[m, n] -= u_mean[n]\n        return Y, u_mean","656ae31a":"class Model():\n    \"\"\"\n    This class manage update U and I matrix, predict and evaluate error\n    Four arguments:\n    data: instance from Data class which supplies the data for model\n    theta: learning rate\n    lamda: regularization parameter\n    K: number of latent factors\n    \"\"\"\n    def __init__(self, data, theta, lamda, K):\n        self.data = data\n        self.theta = theta\n        self.lamda = lamda\n        self.K = K\n        self.I = np.random.randn(data.n_items, K)\n        self.U = np.random.randn(K, data.n_users)\n        \n               \n    def updateU(self):\n        for n in range(self.data.n_users):\n        # Matrix items include all items is rated by user n\n            i_rated = np.where(self.data.Ystad[:, n] != 0)[0] #item's index rated by n\n            In = self.I[i_rated, :]\n            if In.shape[0] == 0:\n                self.U[:, n] = 0\n            else: \n                s = In.shape[0]\n                u_n = self.U[:, n]\n                y_n = self.data.Ystad[i_rated, n]\n                grad = -1\/s * np.dot(In.T,(y_n-np.dot(In, u_n))) + self.lamda*u_n\n                self.U[:, n] -= self.theta*grad\n         \n    def updateI(self):\n        for m in range(self.data.n_items):\n        # Matrix users who rated into item m\n            i_rated = np.where(self.data.Ystad[m, :] != 0)[0] #user's index rated into m\n            Um = self.U[:, i_rated]\n            if Um.shape[1] == 0: \n                self.I[m, :] = 0\n            else:\n                s = Um.shape[1]\n                i_m = self.I[m, :]\n                y_m = self.data.Ystad[m, i_rated]\n                grad = -1\/s * np.dot(y_m - np.dot(i_m, Um), Um.T) + self.lamda*i_m\n                self.I[m, :] -= self.theta*grad\n    \n    def pred(self, I, U):\n        #predict utility matrix base on formula Yhat = I.U\n        Yhat = np.dot(I, U)\n        #invert to forecast values by plus user's mean ratings\n        for n in range(self.data.n_users):\n            Yhat[:, n] += self.data.u_mean[n]\n        #convert to interger values because of rating is integer\n        Yhat = Yhat.astype(np.int32) \n        #replace values > 5 by 5 and values < 1 by 1\n        Yhat[Yhat > 5] = 5\n        Yhat[Yhat < 1] = 1\n        return Yhat\n\n    def pred_train_test(self, Yhat, R):\n        #replace values have not yet rated by 0 \n        Y_pred = Yhat.copy()\n        Y_pred[R == 0] = 0\n        return Y_pred\n    \n    def loss(self, Y, Yhat):\n        error = Y-Yhat\n        n_ratings = np.sum(Y != 0)\n        loss_value = 1\/(2*n_ratings)*np.linalg.norm(error, 'fro')**2 +\\\n        self.lamda\/2*(np.linalg.norm(self.I, 'fro')**2 + \\\n                 np.linalg.norm(self.U, 'fro')**2)\n        return loss_value\n    \n    def RMSE(self, Y, Yhat):\n        error = Y - Yhat\n        n_ratings = np.sum(Y != 0)\n        rmse = math.sqrt(np.linalg.norm(error, 'fro')**2\/n_ratings)\n        return rmse","6c6dd8b6":"class MF():\n    \"\"\"\n    This class used to manage model and data\n    Two main arguments:\n    data: control the data\n    model: control the functions which execute model\n    \"\"\"\n    def __init__(self, data, model, n_iter, print_log_iter):\n        self.data = data\n        self.model = model\n        self.n_iter = n_iter\n        self.print_log_iter = print_log_iter\n        self.Y_pred_train = None\n        self.Y_pred_test = None\n        self.Yhat = None\n        \n    def fit(self):\n        for i in range(self.n_iter):\n            #update U and I\n            self.model.updateU()\n            self.model.updateI()\n            #calculate Y_hat\n            self.Yhat = self.model.pred(self.model.I, self.model.U)\n            #calculate Y_pred_train by replace non ratings by 0\n            self.Y_pred_train = self.model.pred_train_test(self.Yhat, self.data.Rtrain)\n            self.Y_pred_test  = self.model.pred_train_test(self.Yhat, self.data.Rtest)\n            if i % self.print_log_iter == 0:\n                print('Iteration: {}; RMSE: {}; Loss value: {}'.\\\n                      format(i, self.model.RMSE(self.data.Ytest, self.Y_pred_test),\\\n                             self.model.loss(self.data.Ytrain, self.Y_pred_train)))\n                \n    def recommend_for_user(self, user_id, k_neighbors):\n        recm = np.concatenate((np.arange(1, self.Y_pred_test.shape[0]+1).reshape(-1, 1), \\\n                               self.Y_pred_test[:, user_id - 1].reshape(-1, 1)), axis = 1)\n        recm.sort(axis = 0)\n        print('Top %s item_id recommended to user_id %s: %s'%\\\n              (k_neighbors, user_id, str(recm[-k_neighbors:, 0])))","67cb69ff":"data = Data(dataset = movie_length, split_rate = 2\/3)\nmodel = Model(data = data, theta = 0.75, lamda = 0.1, K = 3)\nmf = MF(data = data, model = model, n_iter = 100, print_log_iter = 10)\nmf.fit()","dc150d23":"mf.recommend_for_user(user_id = 200, k_neighbors = 10)","3570ec9a":"### 2.2.3. X\u00e2y d\u1ef1ng h\u00e0m loss function v\u1edbi bias\n\nCh\u00fang ta nh\u1eadn th\u1ea5y r\u1eb1ng trong m\u00f4 h\u00ecnh \u01b0\u1edbc l\u01b0\u1ee3ng lu\u00f4n lu\u00f4n t\u1ed3n t\u1ea1i sai s\u1ed1 kh\u00f4ng \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch b\u1edfi c\u00e1c nh\u00e2n t\u1ed1 \u1ea9n. Ch\u1eb3ng h\u1ea1n nh\u01b0 trong t\u00ecnh hu\u1ed1ng m\u1ed9t user kh\u00e1 kh\u00f3 t\u00ednh \u0111\u00e3 rating cao m\u1ed9t b\u1ed9 phim ch\u1ec9 b\u1edfi v\u00ec c\u1ea3m th\u1ea5y nh\u1eefng user kh\u00e1c c\u0169ng \u0111\u00e3 rating cao b\u1ed9 phim \u0111\u00f3 ho\u1eb7c ch\u1ec9 \u1edf user quan t\u00e2m \u0111\u1ebfn m\u1ed9t kh\u00eda c\u1ea1nh r\u1ea5t nh\u1ecf c\u1ee7a phim nh\u01b0 c\u00f3 di\u1ec5n vi\u00ean y\u00eau th\u00edch, c\u00e2u n\u00f3i y\u00eau th\u00edch hay b\u00e0i h\u00e1t \u1ea5n t\u01b0\u1ee3ng,... V\u00e0 m\u1ed9t \u0111i\u1ec1u hi\u1ec3n nhi\u00ean l\u00e0 nh\u1eefng y\u1ebfu t\u1ed1 n\u00e0y kh\u00f4ng th\u1ec3 \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c. Do \u0111\u00f3 n\u1ebfu ta \u0111\u01b0a th\u00eam m\u1ed9t *nh\u00e2n t\u1ed1 ch\u1ec7ch* (bias) \u0111\u1ed1i v\u1edbi m\u1ed7i m\u1ed9t d\u1ef1 \u0111o\u00e1n c\u1ee7a ng\u01b0\u1eddi d\u00f9ng l\u00ean m\u1ed9t b\u1ed9 phim s\u1ebd l\u00e0m cho m\u00f4 h\u00ecnh d\u1ef1 b\u00e1o s\u00e1t h\u01a1n. Nh\u00e2n t\u1ed1 ch\u1ec7ch c\u00f3 th\u1ec3 xu\u1ea5t ph\u00e1t t\u1eeb c\u1ea3 2 ph\u00eda user ho\u1eb7c item. Ta coi $b_m$ l\u00e0 nh\u00e2n t\u1ed1 ch\u1ec7ch xu\u1ea5t ph\u00e1t t\u1eeb item th\u1ee9 m \u0111\u1ea1i di\u1ec7n cho nh\u1eefng \u1ea3nh h\u01b0\u1edfng l\u00ean rating m\u00e0 c\u00e1c features c\u1ee7a item m kh\u00f4ng gi\u1ea3i th\u00edch \u0111\u01b0\u1ee3c v\u00e0 $d_n$ l\u00e0 nh\u00e2n t\u1ed1 ch\u1ec7ch xu\u1ea5t ph\u00e1t t\u1eeb user th\u1ee9 n \u0111\u1ea1i di\u1ec7n cho nh\u1eefng \u1ea3nh h\u01b0\u1edfng kh\u00f4ng gi\u1ea3i th\u00edch \u0111\u01b0\u1ee3c t\u1eeb c\u00e1c features c\u1ee7a user n. $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$ v\u00e0 $\\mathbf{d} \\in \\mathbb{R}^{1 \\times n}$ l\u1ea7n l\u01b0\u1ee3t l\u00e0 c\u00e1c vector c\u1ed9t v\u00e0 d\u00f2ng c\u1ee7a nh\u00e2n t\u1ed1 ch\u1ec7ch xu\u1ea5t ph\u00e1t t\u1eeb item v\u00e0 user. Khi \u0111\u00f3 h\u00e0m `loss function` s\u1ebd c\u00f3 d\u1ea1ng:\n\n$$\\mathcal{L(\\mathbf{I}, \\mathbf{U}, \\mathbf{b}, \\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{I}||_{F}^2+||\\mathbf{U}||_{F}^2+|\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nN\u1ebfu coi ma tr\u1eadn $\\mathbf{I}$ c\u1ed1 \u0111\u1ecbnh b\u00e0i to\u00e1n t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u1edbi t\u1ed1i \u01b0u h\u00e0m `loss function` c\u00f3 d\u1ea1ng:\n\n$$\\mathcal{L(\\mathbf{U},\\mathbf{b},\\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{U}||_{F}^2+||\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nX\u00e9t t\u1ea1i user n gi\u00e1 tr\u1ecb c\u1ee7a h\u00e0m loss function l\u00e0:\n$$\\begin{eqnarray}\\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n}) & = & \\frac{1}{2s}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{u_n}||^2+||\\mathbf{\\hat{b}_n}||^2) \\\\\n& = & \\frac{1}{2s}||\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n)||_F^2+\\frac{\\lambda}{2}(||\\mathbf{u_n}||^2+||\\mathbf{\\hat{b}_n}||^2)\n\\end{eqnarray}$$ \n\n\u1ede \u0111\u00e2y ta s\u1eed d\u1ee5ng k\u00ed hi\u1ec7u $\\mathbb{1}(d_n)$ \u0111\u1ec3 bi\u1ec3u di\u1ec5n cho vector c\u1ed9t g\u1ed3m to\u00e0n b\u1ed9 c\u00e1c gi\u00e1 tr\u1ecb c\u1ed9t \u0111\u1ec1u b\u1eb1ng nhau v\u00e0 b\u1eb1ng $d_n$\n\n\u0110\u1ea1o h\u00e0m t\u1ea1i user n theo vector $\\mathbf{u_n}$:\n\n$$\\frac{\\partial \\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n})}{\\partial \\mathbf{u_n}} = \\frac{-1}{s} \\mathbf{\\hat{I}_n}^{T}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{u_n}\n$$ \n\n\u0110\u1ea1o h\u00e0m t\u1ea1i user n theo vector $\\mathbf{\\hat{b}_n}$:\n\n$$\\frac{\\partial \\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n})}{\\partial \\mathbf{\\hat{b}_n}} = \\frac{-1}{s}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{\\hat{b}_n}\n$$ \n\nC\u00f4ng th\u1ee9c c\u1eadp nh\u1eadt *gradient descent* \u0111\u1ed1i v\u1edbi:\n\n* vector $\\mathbf{u}_n$:\n\n$$\\mathbf{u_n}' = \\mathbf{u_n} - \\theta(-\\frac{1}{s}\\mathbf{\\hat{I}_n}^{T}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{u_n})$$\n\n* vector $\\mathbf{\\hat{b}_n}$:\n\n$$\\mathbf{\\hat{b}_n}' = \\mathbf{\\hat{b}_n} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{\\hat{b}_n})$$\n\nT\u01b0\u01a1ng t\u1ef1 cho tr\u01b0\u1eddng h\u1ee3p ma tr\u1eadn $\\mathbf{U}$ c\u1ed1 \u0111\u1ecbnh:\n\n$$\\mathcal{L(\\mathbf{I},\\mathbf{b}, \\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{I}||_{F}^2+||\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nX\u00e9t t\u1ea1i item m gi\u00e1 tr\u1ecb c\u1ee7a h\u00e0m loss function l\u00e0:\n$$\\begin{eqnarray}\\mathcal{L}(\\mathbf{i_m}, \\mathbf{\\hat{d}_m}) & = & \\frac{1}{2s}\\sum_{n: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{i_m}||^2+||\\mathbf{\\hat{d}_m}||^2) \\\\\n& = & \\frac{1}{2s}||\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m}||_F^2+\\frac{\\lambda}{2}(||\\mathbf{i_m}||^2+||\\mathbf{\\hat{d}_m}||^2)\n\\end{eqnarray}$$ \n\nC\u00f4ng th\u1ee9c c\u1eadp nh\u1eadt *gradient descent* \u0111\u1ed1i v\u1edbi:\n\n* vector $\\mathbf{i}_m$:\n\n$$\\mathbf{i_m}' = \\mathbf{i_m} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m})\\mathbf{\\hat{U}_m}^T+\\lambda \\mathbf{i_m})$$\n\n* vector $\\mathbf{\\hat{d}_m}$:\n\n$$\\mathbf{\\hat{d}_m}' = \\mathbf{\\hat{d}_m} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m})+\\lambda \\mathbf{\\hat{d}_m})$$\n\nNh\u01b0 v\u1eady trong tr\u01b0\u1eddng h\u1ee3p h\u00e0m s\u1ed1 loss function c\u00f3 th\u00eam nh\u00e2n t\u1ed1 ch\u1ec7ch ta c\u0169ng s\u1eed d\u1ee5ng ph\u01b0\u01a1ng tr\u00ecnh `gradient descent` \u0111\u1ec3 c\u1eadp nh\u1eadt nghi\u1ec7m t\u1ed1i \u01b0u. Tuy nhi\u00ean ta s\u1ebd c\u00f3 th\u00eam c\u1eadp nh\u1eadt nghi\u1ec7m cho c\u00e1c nh\u00e2n t\u1ed1 ch\u1ec7ch v\u00e0 gi\u00e1 tr\u1ecb h\u00e0m loss function s\u1ebd ch\u1ecbu \u1ea3nh h\u01b0\u1edfng t\u1eeb c\u00e1c nh\u00e2n t\u1ed1 ch\u1ec7ch. B\u1ea1n \u0111\u1ecdc quan t\u00e2m \u0111\u1ebfn k\u1ebft qu\u1ea3 c\u1ee7a thu\u1eadt to\u00e1n n\u00e0y c\u00f3 th\u1ec3 tham kh\u1ea3o [code](https:\/\/www.kaggle.com\/phamdinhkhanh\/matrix-factorization-movie-len-1m-with-bias?scriptVersionId=6262032) \u0111\u01b0\u1ee3c t\u00f4i vi\u1ebft s\u1eb5n.","75b040b2":"## 2.3. T\u00e0i li\u1ec7u tham kh\u1ea3o\n\n1. [Recommendation System - Stanford](http:\/\/infolab.stanford.edu\/~ullman\/mmds\/ch9.pdf)\n2. [Collaborative Filtering Youtube - Stanford](https:\/\/www.youtube.com\/watch?v=h9gpufJFF-0&t=436s)\n3. [Recommendation System - Machine Learning - Andrew Ng](https:\/\/www.youtube.com\/watch?v=YW2b8La2ICo)\n4. [Matrix Factorization - Machine Learning C\u01a1 B\u1ea3n - Tiep Huu Vu](https:\/\/machinelearningcoban.com\/2017\/05\/31\/matrixfactorization\/)\n5. [Matrix Factorization techniques for recommender systems](https:\/\/datajobs.com\/data-science-repo\/Recommender-Systems-%5BNetflix%5D.pdf)\n6. [Learning from Incomplete Ratings Using Non-negative Matrix Factorization](https:\/\/archive.siam.org\/meetings\/sdm06\/proceedings\/059zhangs2.pdf)\n7. [Matrix Factorization - Albert Au Yeung](http:\/\/www.albertauyeung.com\/post\/python-matrix-factorization\/)\n8. [Algorithms for Non-negative Matrix Factorization - Daniel D.Lee and H. Sebastian Seung](http:\/\/hebb.mit.edu\/people\/seung\/papers\/nmfconverge.pdf)","dc69ee95":"Nh\u00ecn v\u00e0o ph\u00e2n b\u1ed1 c\u1ee7a s\u1ed1 l\u01b0\u1ee3ng user theo m\u1ee9c \u0111\u1ed9 rating ta c\u00f3 th\u1ec3 th\u1ea5y m\u1eabu c\u1ee7a ch\u00fang ta c\u00f3 hi\u1ec7n t\u01b0\u1ee3ng kh\u00f4ng c\u00e2n b\u1eb1ng khi c\u00f3 nhi\u1ec1u user rating r\u1ea5t \u00edt v\u00e0 nhi\u1ec1u user rating nhi\u1ec1u h\u01a1n. Tuy nhi\u00ean \u0111\u00e2y kh\u00f4ng ph\u1ea3i l\u00e0 b\u00e0i to\u00e1n classification n\u00ean vi\u1ec7c m\u1eabu c\u00f3 k\u00edch th\u01b0\u1edbc m\u1ea5t c\u00e2n b\u1eb1ng c\u0169ng kh\u00f4ng \u1ea3nh h\u01b0\u1edfng t\u1edbi m\u1ee9c \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a thu\u1eadt to\u00e1n. H\u01a1n n\u1eefa thu\u1eadt to\u00e1n `matrix factorization` x\u00e2y d\u1ef1ng h\u00e0m loss function ri\u00eang l\u1ebb cho t\u1eebng user n\u00eau vi\u1ec7c user n\u00e0y rating bao nhi\u00eau s\u1ea3n ph\u1ea9m kh\u00f4ng \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn k\u1ebft qu\u1ea3 d\u1ef1 b\u00e1o rating c\u1ee7a user kh\u00e1c. Ho\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 ta c\u0169ng th\u1ed1ng k\u00ea \u0111\u01b0\u1ee3c s\u1ed1 l\u01b0\u1ee3ng c\u00e1c user rating \u0111\u1ed1i v\u1edbi t\u1eebng b\u1ed9 phim.","082700de":"K\u00edch th\u01b0\u1edbc c\u00e1c d\u1eef li\u1ec7u v\u00e0 s\u1ed1 l\u01b0\u1ee3ng users, items","3d65bc84":"**X\u00e2y d\u1ef1ng h\u00e0m t\u00ednh RMSE:**\n\nSau khi t\u00ednh \u0111\u01b0\u1ee3c ma tr\u1eadn d\u1ef1 b\u00e1o $\\mathbf{\\hat{Y}}$ tr\u00ean t\u1eadp test k\u1ebft h\u1ee3p v\u1edbi ma tr\u1eadn ti\u1ec7n \u00edch $\\mathbf{Y}$ c\u1ee7a t\u1eadp test \u0111\u00e3 bi\u1ebft ta s\u1ebd t\u00ednh \u0111\u01b0\u1ee3c *RMSE* tr\u00ean t\u1eadp test nh\u01b0 sau:","a4b744f5":"\u0110\u1ec3 thu\u1eadt to\u00e1n `gradient descent` h\u1ed9i t\u1ee5 nhanh h\u01a1n ch\u00fang ta c\u1ea7n chu\u1ea9n h\u00f3a ma tr\u1eadn $\\mathbf{Y}$ v\u1ec1 gi\u00e1 tr\u1ecb k\u00ec v\u1ecdng b\u1eb1ng 0 b\u1eb1ng c\u00e1ch tr\u1eeb \u0111i m\u1ed7i gi\u00e1 tr\u1ecb rating trong vector rating c\u1ee7a m\u1ed9t user v\u1edbi trung b\u00ecnh c\u1ee7a vector rating \u0111\u00f3.","6dafcc6e":"Th\u1ed1ng k\u00ea m\u00f4 t\u1ea3 s\u1ed1 t\u1ea7n su\u1ea5t rating c\u1ee7a c\u00e1c users:","2e00d71b":"**X\u00e2y d\u1ef1ng h\u00e0m loss function:**\n\nH\u00e0m loss function \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng d\u1ef1a tr\u00ean c\u00f4ng th\u1ee9c *(1.4.1)* nh\u01b0 sau:","d815c415":"M\u1ed9t v\u00e0i \u0111\u00e1nh gi\u00e1:\n* S\u1ed1 l\u1ea7n 1 b\u1ed9 phim \u0111\u01b0\u1ee3c rating \u00edt nh\u1ea5t l\u00e0 1 l\u1ea7n.\n* S\u1ed1 l\u1ea7n 1 b\u1ed9 phim \u0111\u01b0\u1ee3c rating nhi\u1ec1u nh\u1ea5t l\u00e0 3428 l\u1ea7n.\n* M\u1ee9c \u0111\u1ed9 rating ph\u1ed5 bi\u1ebfn c\u1ee7a m\u1ed9t b\u1ed9 phim l\u00e0 t\u1eeb 33 \u0111\u1ebfn 123 l\u1ea7n.\n\n## 2.2. Thu\u1eadt to\u00e1n matrix factorization\n\n### 2.2.1. C\u00e1c h\u00e0m trong thu\u1eadt to\u00e1n\n\n\u0110\u1ea7u ti\u00ean ta s\u1ebd ti\u1ebfn h\u00e0nh chia m\u1eabu train v\u00e0 test theo t\u1ef7 l\u1ec7 sao cho s\u1ed1 l\u01b0\u1ee3ng rating trong t\u1eadp train chi\u1ebfm 2\/3 s\u1ed1 l\u01b0\u1ee3ng c\u00e1c l\u01b0\u1ee3t rating. C\u00e1ch chia m\u1eabu h\u1ee3p l\u00fd nh\u1ea5t l\u00e0 \u0111\u1ea3m b\u1ea3o t\u1ef7 l\u1ec7 s\u1ed1 l\u01b0\u1ee3ng ratings xu\u1ea5t hi\u1ec7n trong t\u1eadp train \u0111\u1ed1i v\u1edbi s\u1ed1 l\u01b0\u1ee3ng ratings xu\u1ea5t hi\u1ec7n trong t\u1eadp test c\u1ee7a c\u00f9ng m\u1ed9t user l\u00e0 b\u1eb1ng nhau. C\u00e1ch chia n\u00e0y \u0111\u1ea3m b\u1ea3o s\u1ef1 c\u00f4ng b\u1eb1ng \u0111\u1ed1i v\u1edbi c\u00e1c user khi kh\u00f4ng c\u00f3 user n\u00e0o c\u00f3 qu\u00e1 nhi\u1ec1u d\u1eef li\u1ec7u train v\u00e0 d\u1eef li\u1ec7u test \u00edt ho\u1eb7c d\u1eef li\u1ec7u train qu\u00e1 \u00edt nh\u01b0ng d\u1eef li\u1ec7u test l\u1ea1i qu\u00e1 nhi\u1ec1u. Gi\u00e1 tr\u1ecb \u0111\u01b0\u1ee3c d\u1ef1 b\u00e1o t\u1eeb m\u00f4 h\u00ecnh m\u00e0 d\u1eef li\u1ec7u train qu\u00e1 \u00edt s\u1ebd th\u01b0\u1eddng kh\u00f4ng chu\u1ea9n x\u00e1c v\u00e0 l\u00e0m sai l\u1ec7ch k\u1ebft qu\u1ea3 ki\u1ec3m tra sai s\u1ed1 tr\u00ean test. ","e7bd0a34":"**X\u00e2y d\u1ef1ng v\u00f2ng l\u1eb7p t\u1ed1i \u01b0u ch\u00ednh:**\n    \nSau khi \u0111\u00e3 thi\u1ebft k\u1ebf \u0111\u01b0\u1ee3c c\u00e1c h\u00e0m t\u00ednh to\u00e1n *loss function, RMSE* v\u00e0 c\u00e1c h\u00e0m t\u1ed1i \u01b0u *gradient descent* ta s\u1ebd ti\u1ebfn h\u00e0nh x\u00e2y d\u1ef1ng v\u00f2ng l\u1eb7p t\u1ed1i \u01b0u \u0111\u1ec3 c\u1eadp nh\u1eadt c\u00e1c ma tr\u1eadn $\\mathbf{U}$ v\u00e0 $\\mathbf{I}$ v\u00e0 \u0111\u00e1nh gi\u00e1 hi\u1ec7u qu\u1ea3 c\u1ee7a m\u1ed7i b\u01b0\u1edbc l\u1eb7p th\u00f4ng qua gi\u00e1 tr\u1ecb c\u1ee7a *loss function* v\u00e0 *RMSE*.","e6aa7487":"## 1. Gi\u1edbi thi\u1ec7u v\u1ec1 ph\u01b0\u01a1ng ph\u00e1p Recommendation system\n### 1. 1. T\u1ea7m quan tr\u1ecdng c\u1ee7a recommendation system\nTrong cu\u1ed9c s\u1ed1ng h\u00e0ng ng\u00e0y ch\u00fang ta th\u01b0\u1eddng th\u1ea5y nh\u1eefng t\u00ecnh hu\u1ed1ng kh\u00e1 t\u00ecnh c\u1edd khi c\u00e1c h\u1ec7 th\u1ed1ng l\u1edbn c\u00f3 kh\u1ea3 n\u0103ng \u0111\u1ecdc v\u00e0 hi\u1ec3u s\u1edf th\u00edch c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u00e0 hi\u1ec7n th\u1ecb nh\u1eefng th\u00f4ng tin m\u00e0 ng\u01b0\u1eddi d\u00f9ng quan t\u00e2m r\u1ea5t chu\u1ea9n x\u00e1c. Ch\u1eb3ng h\u1ea1n nh\u01b0:\n\n* Facebook c\u00f3 kh\u1ea3 n\u0103ng hi\u1ec3n th\u1ecb tr\u00ean newfeed nh\u1eefng tr\u1ea1ng th\u00e1i c\u1ee7a nh\u1eefng ng\u01b0\u1eddi m\u00e0 b\u1ea1n quan t\u00e2m.\n* Youtube c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng nh\u1ea3y sang nh\u1eefng video m\u00e0 b\u1ea1n c\u00f3 kh\u1ea3 n\u0103ng y\u00eau th\u00edch d\u1ef1a tr\u00ean nh\u1eefng g\u00ec m\u00e0 b\u1ea1n \u0111ang xem.\n* Amazon c\u00f3 th\u1ec3 \u0111\u01b0a ra nh\u1eefng cu\u1ed1n s\u00e1ch c\u00f9ng lo\u1ea1i v\u1edbi nh\u1eefng cu\u1ed1n s\u00e1ch m\u00e0 b\u1ea1n \u0111\u00e3 mua ho\u1eb7c rating cao.\n* Google c\u00f3 th\u1ec3 \u0111\u01b0a qu\u1ea3ng c\u00e1o v\u1ec1 m\u1ed9t \u0111\u1ed3 v\u1eadt ph\u00f9 h\u1ee3p v\u1edbi nh\u1eefng g\u00ec b\u1ea1n t\u00ecm ki\u1ebfm g\u1ea7n \u0111\u00e2y.\n\nN\u1ebfu kh\u00f4ng c\u00f3 c\u00e1c thu\u1eadt to\u00e1n recommendation, tr\u1ea3i nghi\u1ec7m ng\u01b0\u1eddi d\u00f9ng s\u1ebd k\u00e9m h\u01a1n v\u00ec th\u00f4ng tin m\u00e0 h\u1ecd th\u1ef1c s\u1ef1 quan t\u00e2m kh\u00f4ng \u0111\u01b0\u1ee3c \u0111\u01b0a ra \u0111\u00fang th\u1eddi \u0111i\u1ec3m trong khi th\u00f4ng tin kh\u00f4ng c\u1ea7n thi\u1ebft \u0111\u01b0\u1ee3c \u0111\u01b0a ra nhi\u1ec1u h\u01a1n. H\u1eadu qu\u1ea3 l\u00e0 ng\u01b0\u1eddi d\u00f9ng c\u1ea3m th\u1ea5y b\u1ecb l\u00e0m phi\u1ec1n v\u00e0 nhi\u1ec5u lo\u1ea1n th\u00f4ng tin. Trong l\u0129nh v\u1ef1c marketing h\u1ec7 th\u1ed1ng recommendation l\u1ea1i c\u00e0ng tr\u1edf n\u00ean quan tr\u1ecdng. M\u1ed7i s\u1ea3n ph\u1ea9m \u0111\u01b0\u1ee3c \u0111\u01b0a \u0111\u1ebfn \u0111\u00fang ng\u01b0\u1eddi ti\u00eau d\u00f9ng c\u00f3 nhu c\u1ea7u s\u1ebd l\u00e0m t\u0103ng doanh thu, gi\u1ea3m chi ph\u00ed th\u1eddi gian, chi ph\u00ed qu\u1ea3ng c\u00e1o v\u00e0 gi\u00fap ng\u01b0\u1eddi ti\u00eau d\u00f9ng s\u1edf h\u1eefu \u0111\u01b0\u1ee3c th\u1ee9 m\u00ecnh c\u1ea7n. Trong l\u0129nh v\u1ef1c gi\u1ea3i tr\u00ed nh\u01b0 video, game, truy\u1ec7n online,... ng\u01b0\u1eddi d\u00f9ng s\u1ebd \u0111\u1ea1t \u0111\u1ed9 h\u00e0i l\u00f2ng cao khi t\u00ecm \u0111\u01b0\u1ee3c \u0111\u00fang lo\u1ea1i h\u00ecnh gi\u1ea3i tr\u00ed y\u00eau th\u00edch d\u1ec5 d\u00e0ng. D\u00f9 ch\u1ec9 ra \u0111\u1eddi trong 10 n\u0103m tr\u1edf l\u1ea1i \u0111\u00e2y, song h\u00e0nh c\u00f9ng th\u1eddi k\u00ec b\u00f9ng n\u1ed5 internet nh\u01b0ng c\u00f3 th\u1ec3 n\u00f3i `recommendation system` l\u00e0 m\u1ed9t l\u0129nh v\u1ef1c nghi\u00ean c\u1ee9u s\u00f4i \u0111\u1ed9ng. N\u00f3 \u0111\u00e3 t\u1ea1o ra m\u1ed9t cu\u1ed9c c\u00e1ch m\u1ea1ng thay \u0111\u1ed5i h\u00e0nh vi mua s\u1eafm, h\u00e0nh vi gi\u1ea3i tr\u00ed, chi\u1ebfn l\u01b0\u1ee3c kinh doanh,... tr\u00ean to\u00e0n c\u1ea7u. H\u00e0ng tr\u0103m tri\u1ec7u c\u00e1c h\u1ed9 kinh doanh nh\u1ecf l\u1ebb \u0111ang h\u01b0\u1edfng l\u1ee3i t\u1eeb n\u00f3 th\u00f4ng qua khai th\u00e1c ngu\u1ed3n kh\u00e1ch h\u00e0ng v\u00f4 t\u1eadn t\u1eeb t\u00e0i nguy\u00ean m\u1ea1ng v\u00e0 bi\u1ebfn k\u00eanh b\u00e1n h\u00e0ng n\u00e0y thay th\u1ebf c\u00e1c k\u00eanh truy\u1ec1n th\u1ed1ng. L\u0129nh v\u1ef1c n\u00e0y \u0111\u1ed3ng th\u1eddi l\u00e0 ch\u00eca kh\u00f3a m\u1ea5u ch\u1ed1t gi\u00fap c\u00e1c c\u00f4ng ty c\u00f4ng ngh\u1ec7 Google, Facebook, Amazon, Microsoft,... tr\u1edf th\u00e0nh nh\u1eefng t\u1eadp \u0111o\u00e0nh h\u00e0ng \u0111\u1ea7u th\u1ec3 gi\u1edbi. Ch\u00ednh v\u00ec th\u1ebf `recommendation system` lu\u00f4n \u0111\u01b0\u1ee3c c\u00e1c c\u00f4ng ty kinh doanh tr\u00ean n\u1ec1n t\u1ea3ng online \u0111\u1ea7u t\u01b0 nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n \u0111\u1ec3 t\u1ea1o ra m\u1ed9t h\u1ec7 th\u1ed1ng th\u00f4ng minh nh\u1eb1m n\u00e2ng cao tr\u1ea3i nghi\u1ec7m kh\u00e1ch h\u00e0ng v\u00e0 t\u1ed1i \u01b0u h\u00f3a ngu\u1ed3n t\u00e0i nguy\u00ean.\n\n### 1.2. Ph\u01b0\u01a1ng ph\u00e1p recommendation\n\nB\u00ean tr\u00ean ch\u00fang ta \u0111\u00e3 bi\u1ebft vai tr\u00f2 c\u1ee7a `recommendation system` \u0111\u1ed1i v\u1edbi vi\u1ec7c ph\u00e1t tri\u1ec3n c\u1ee7a l\u0129nh v\u1ef1c internet v\u00e0 kinh doanh online. Tuy nhi\u00ean th\u1ef1c s\u1ef1 b\u00e0i to\u00e1n `recommendation system` l\u00e0 g\u00ec? C\u01a1 s\u1edf c\u1ee7a ph\u01b0\u01a1ng ph\u00e1p `recommendation system` ra sao ch\u00fang ta v\u1eabn ch\u01b0a th\u1ef1c s\u1ef1 hi\u1ec3u r\u00f5. Theo \u0111\u1ecbnh ngh\u0129a t\u1eeb wikipedia th\u00ec `recommendation system` l\u00e0 m\u1ed9t nh\u00e1nh nh\u1ecf c\u1ee7a l\u0129nh v\u1ef1c *h\u1ec7 th\u1ed1ng chi\u1ebft l\u1ecdc th\u00f4ng tin* (information filtering system) \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 d\u1ef1 b\u00e1o m\u1ee9c \u0111\u1ed9 y\u00eau th\u00edch th\u00f4ng qua rating c\u1ee7a m\u1ed9t ng\u01b0\u1eddi d\u00f9ng (user) cho m\u1ed9t s\u1ea3n ph\u1ea9m (item). \u0110\u1ec3 \u0111\u01b0a ra \u0111\u01b0\u1ee3c s\u1ea3n ph\u1ea9m ph\u00f9 h\u1ee3p nh\u1ea5t \u0111\u1ebfn ng\u01b0\u1eddi d\u00f9ng \u0111\u00f2i h\u1ecfi c\u00e1c h\u1ec7 th\u1ed1ng ph\u1ea3i d\u1ef1a tr\u00ean th\u00f4ng tin \u0111\u00e3 rating c\u1ee7a s\u1ea3n ph\u1ea9m, th\u00f4ng tin ng\u01b0\u1eddi d\u00f9ng, th\u00f4ng tin v\u1ec1 s\u1ea3n ph\u1ea9m \u0111\u1ec3 x\u00e2y d\u1ef1ng thu\u1eadt to\u00e1n t\u1ed1i \u01b0u. D\u1ef1a tr\u00ean h\u00e0m loss function \u0111\u1ec3 t\u00ednh ra sai s\u1ed1 d\u1ef1 b\u00e1o c\u1ee7a thu\u1eadt to\u00e1n v\u00e0 t\u00ecm ra m\u1ed9t ph\u01b0\u01a1ng ph\u00e1p c\u00f3 m\u1ee9c \u0111\u1ed9 d\u1ef1 b\u00e1o chu\u1ea9n x\u00e1c nh\u1ea5t. C\u00f3 r\u1ea5t nhi\u1ec1u c\u00e1c thu\u1eadt to\u00e1n kh\u00e1c nhau \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong `recommendation system` nh\u01b0ng v\u1ec1 c\u01a1 b\u1ea3n ch\u00fang bao g\u1ed3m 2 ph\u01b0\u01a1ng ph\u00e1p ch\u00ednh: `Collaborative filtering` v\u00e0 `Content based filtering`. \u0110i\u1ec3m kh\u00e1c bi\u1ec7t c\u01a1 b\u1ea3n gi\u1eefa 2 ph\u01b0\u01a1ng ph\u00e1p n\u00e0y l\u00e0:\n\n* Collaborative filtering: D\u1ef1a tr\u00ean m\u1ed1i quan h\u1ec7 t\u01b0\u01a1ng quan v\u1ec1 m\u1eb7t h\u00e0nh vi ti\u00eau d\u00f9ng ho\u1eb7c \u0111\u1eb7c tr\u01b0ng s\u1ea3n ph\u1ea9m \u0111\u1ec3 t\u00ecm ra c\u00e1c users ho\u1eb7c items c\u00f3 chung \u0111\u1eb7c t\u00ednh, s\u1edf th\u00edch. T\u1eeb \u0111\u00f3 d\u1ef1a tr\u00ean nh\u1eefng th\u00f4ng tin m\u00e0 nh\u00f3m ng\u01b0\u1eddi d\u00f9ng ho\u1eb7c s\u1ea3n ph\u1ea9m li\u00ean quan g\u1ea7n nh\u1ea5t \u0111\u00e3 rating \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 s\u1ea3n ph\u1ea9m m\u00e0 m\u1ed9t ng\u01b0\u1eddi d\u00f9ng c\u1ee5 th\u1ec3 ch\u01b0a rating. Tuy nhi\u00ean nh\u01b0\u1ee3c \u0111i\u1ec3m c\u1ee7a thu\u1eadt to\u00e1n n\u00e0y l\u00e0 \u0111\u01b0a ra d\u1ef1 b\u00e1o v\u1ec1 rating m\u00e0 kh\u00f4ng ho\u00e0n to\u00e0n hi\u1ec3u v\u1ec1 user, item m\u00e0 ho\u00e0n to\u00e0n d\u1ef1a tr\u00ean quan s\u00e1t v\u1ec1 m\u1ee9c \u0111\u1ed9 t\u01b0\u01a1ng \u0111\u01b0\u01a1ng gi\u1eefa c\u00e1c nh\u00f3m users, items \u0111\u1ec3 d\u1ef1 b\u00e1o. Thu\u1eadt to\u00e1n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong c\u00e1c b\u00e0i to\u00e1n n\u00e0y ch\u1ee7 y\u1ebfu l\u00e0 k-nearest neighbor \u0111\u1ec3 t\u00ecm ra nh\u00f3m t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u00e0 ma tr\u1eadn h\u1ec7 s\u1ed1 t\u01b0\u01a1ng quan \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 \u0111o l\u01b0\u1eddng m\u1ee9c \u0111\u1ed9 g\u1ea7n g\u0169i v\u1ec1 m\u1eb7t h\u00e0nh vi hay \u0111\u1eb7c t\u00ednh \u0111\u1ec3 ph\u00e2n nh\u00f3m.\n\n* Content based filtering: D\u1ef1a tr\u00ean nh\u1eefng th\u00f4ng tin v\u00e0 n\u1ed9i dung li\u00ean quan \u0111\u1ebfn s\u1ea3n ph\u1ea9m nh\u01b0 nh\u00e0 s\u1ea3n xu\u1ea5t, th\u1ec3 lo\u1ea1i, n\u0103m s\u1ea3n xu\u1ea5t, c\u00f4ng d\u1ee5ng, \u0111\u1eb7c t\u00ednh,... ho\u1eb7c d\u1ef1a tr\u00ean th\u00f4ng tin c\u1ee7a ng\u01b0\u1eddi d\u00f9ng nh\u01b0 gi\u1edbi t\u00ednh, \u0111\u1ed9 tu\u1ed1i, ng\u00e0nh ngh\u1ec1,... \u0111\u1ec3 \u0111\u01b0a ra d\u1ef1 b\u00e1o v\u1ec1 rating c\u1ee7a ng\u01b0\u1eddi \u0111\u1ed1i v\u1edbi s\u1ea3n ph\u1ea9m \u0111\u00f3. Thu\u1eadt to\u00e1n n\u00e0y ch\u1ec9 \u0111\u01a1n thu\u1ea7n l\u00e0 c\u00e1c ph\u01b0\u01a1ng tr\u00ecnh h\u1ed3i qui gi\u1eefa c\u00e1c chi\u1ec1u \u0111\u1eb7c t\u00ednh c\u1ee7a s\u1ea3n ph\u1ea9m ho\u1eb7c ng\u01b0\u1eddi d\u00f9ng \u0111\u1ed1i v\u1edbi \u0111i\u1ec3m rating m\u00e0 kh\u00f4ng t\u1eadn d\u1ee5ng \u0111\u01b0\u1ee3c t\u01b0\u01a1ng quan v\u1ec1 m\u1eb7t h\u00e0nh vi gi\u1eefa nh\u1eefng nh\u00f3m ng\u01b0\u1eddi d\u00f9ng hay \u0111\u1eb7c tr\u01b0ng s\u1ea3n ph\u1ea9m nh\u01b0 `Collaborative filtering`. Trong th\u1ef1c t\u1ebf h\u00e0nh vi c\u1ee7a ng\u01b0\u1eddi d\u00f9ng l\u1ea1i cho th\u1ea5y r\u1ea5t gi\u1ed1ng nhau n\u1ebfu thu\u1ed9c c\u00f9ng m\u1ed9t nh\u00f3m ch\u1eb3ng h\u1ea1n nh\u01b0 c\u00e1c nh\u00f3m nh\u1ea1c thi\u1ec1n, nh\u1ea1c v\u00e0ng, nh\u1ea1c tr\u1ebb, nh\u1ea1c thi\u1ebfu nhi s\u1ebd ph\u00f9 h\u1ee3p v\u1edbi ng\u01b0\u1eddi gi\u00e0, ng\u01b0\u1eddi trung ni\u00ean, ng\u01b0\u1eddi tr\u1ebb, thi\u1ebfu nhi. Kh\u00f4ng xem x\u00e9t \u0111\u01b0\u1ee3c c\u00e1c y\u1ebfu t\u1ed1 t\u01b0\u01a1ng quan theo nh\u00f3m l\u00e0 m\u1ed9t h\u1ea1n ch\u1ebf l\u1edbn c\u1ee7a content based filtering.\n\n\nM\u1ed7i thu\u1eadt to\u00e1n \u0111\u1ec1u c\u00f3 \u01b0u, nh\u01b0\u1ee3c \u0111i\u1ec3m kh\u00e1c nhau v\u00e0 m\u1ee9c \u0111\u1ed9 hi\u1ec7u qu\u1ea3 trong d\u1ef1 b\u00e1o m\u1ee9c \u0111\u1ed9 y\u00eau th\u00edch c\u00e1c c\u1eb7p (user, item) (*ng\u01b0\u1eddi d\u00f9ng, s\u1ea3n ph\u1ea9m*) c\u0169ng kh\u00e1c nhau t\u00f9y thu\u1ed9c v\u00e0o t\u1eadp d\u1eef li\u1ec7u. Nh\u01b0ng c\u00e1c thu\u1eadt to\u00e1n \u0111\u1ec1u c\u00f3 \u0111i\u1ec3m chung \u0111\u00f3 l\u00e0 s\u1eed d\u1ee5ng d\u1eef li\u1ec7u m\u00e0 ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 rating \u0111\u1ed1i v\u1edbi c\u00e1c s\u1ea3n ph\u1ea9m \u0111\u1ec3 l\u00e0m c\u01a1 s\u1edf d\u1ef1 b\u00e1o rating cho c\u00e1c s\u1ea3n ph\u1ea9m ch\u01b0a \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1. Vi\u1ec7c n\u00e0y c\u0169ng gi\u1ed1ng nh\u01b0 ch\u00fang ta ch\u01a1i tr\u00f2 ch\u01a1i \u0111i\u1ec1n s\u1ed1 v\u00e0o *ma tr\u1eadn ti\u1ec7n \u00edch* (utility matrix). M\u1ed9t chi\u1ec1u c\u1ee7a ma tr\u1eadn \u1ee9ng v\u1edbi users v\u00e0 chi\u1ec1u c\u00f2n l\u1ea1i \u1ee9ng v\u1edbi items. C\u00e1c \u00f4 tr\u00ean ma tr\u1eadn th\u1ec3 hi\u1ec7n gi\u00e1 tr\u1ecb rating c\u1ee7a user t\u01b0\u01a1ng \u1ee9ng l\u00ean item. Nh\u01b0 v\u1eady s\u1ebd c\u00f3 nh\u1eefng \u00f4 \u0111\u00e3 \u0111\u01b0\u1ee3c rating b\u1edfi ng\u01b0\u1eddi d\u00f9ng v\u00e0 c\u00e1c \u00f4 c\u00f2n l\u1ea1i ch\u01b0a \u0111\u01b0\u1ee3c rating. Qu\u00e1 tr\u00ecnh gi\u1ea3i b\u00e0i to\u00e1n c\u0169ng gi\u1ed1ng nh\u01b0 vi\u1ec7c ch\u00fang ta \u0111i gi\u1ea3i ma tr\u1eadn t\u1ea1i nh\u1eefng \u00f4 c\u00f2n thi\u1ebfu sao cho sai s\u1ed1 cu\u1ed1i c\u00f9ng gi\u1eefa d\u1ef1 b\u00e1o v\u00e0 th\u1ef1c t\u1ebf l\u00e0 nh\u1ecf nh\u1ea5t. \n\n### 1.3. Gi\u1edbi thi\u1ec7u thu\u1eadt to\u00e1n matrix factorization\n\n\nTrong thu\u1eadt to\u00e1n matrix factorization ch\u00fang ta gi\u1ea3 \u0111\u1ecbnh \u0111\u1eb7c tr\u01b0ng c\u1ee7a item \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n qua ma tr\u1eadn $\\mathbf{I}$ v\u00e0 h\u00e0nh vi c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n qua ma tr\u1eadn $\\mathbf{U}$. V\u1edbi m\u1ed7i d\u00f2ng c\u1ee7a ma tr\u1eadn $\\mathbf{I}$ l\u00e0 m\u1ed9t \u0111\u1eb7c tr\u01b0ng \u1ea9n (*latent feature*) c\u1ee7a s\u1ea3n ph\u1ea9m v\u00e0 m\u1ed7i c\u1ed9t c\u1ee7a $\\mathbf{U}$ l\u00e0 m\u1ee9c \u0111\u1ed9 y\u00eau th\u00edch c\u1ee7a m\u1ed9t ng\u01b0\u1eddi d\u00f9ng \u0111\u1ed1i v\u1edbi \u0111\u1eb7c tr\u01b0ng \u1ea9n t\u01b0\u01a1ng \u1ee9ng. C\u00e1c \u0111\u1eb7c tr\u01b0ng \u1ea9n n\u00e0y c\u00f3 th\u1ec3 coi nh\u01b0 nh\u1eefng nh\u00e2n t\u1ed1 ch\u00ednh \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb nhi\u1ec1u th\u00f4ng tin li\u00ean quan \u0111\u1ebfn s\u1ea3n ph\u1ea9m t\u01b0\u01a1ng t\u1ef1 nh\u01b0 th\u00e0nh ph\u1ea7n ch\u00ednh trong ph\u00e9p ph\u00e2n t\u00edch th\u00e0nh ph\u1ea7n ch\u00ednh `PCA`. \u0110\u1eb7c tr\u01b0ng c\u1ee7a s\u1ea3n ph\u1ea9m th\u1ee9 m \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n qua vector d\u00f2ng $\\mathbf{i_m}$ v\u00e0 h\u00e0nh vi c\u1ee7a ng\u01b0\u1eddi d\u00f9ng th\u1ee9 n \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n qua vector c\u1ed9t $\\mathbf{u_n}$. Khi \u0111\u00f3 gi\u00e1 tr\u1ecb d\u1ef1 b\u00e1o m\u1ee9c \u0111\u1ed9 y\u00eau th\u00edch c\u1ee7a m\u1ed9t ng\u01b0\u1eddi d\u00f9ng n l\u00ean m\u1ed9t s\u1ea3n ph\u1ea9m m s\u1ebd l\u00e0 t\u00edch c\u1ee7a 2 vector $\\mathbf{i_m}$ v\u00e0 $\\mathbf{u_n}$:\n\\begin{equation*}\ny_{mn} = \\mathbf{i_m} \\mathbf{u_n}\n\\end{equation*}\n\n\u01b0\u1edbc l\u01b0\u1ee3ng c\u1ee7a ma tr\u1eadn ti\u1ec7n \u00edch $\\mathbf{\\hat{Y}}$ s\u1ebd \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n theo c\u00e1c ma tr\u1eadn h\u00e0nh vi $\\mathbf{I}$ v\u00e0 ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng $\\mathbf{U}$ nh\u01b0 sau:\n\n\\begin{equation*}\n\\mathbf{\\hat{Y}} \\approx \\left[ \\begin{matrix}\n\\mathbf{i}_1\\mathbf{u}_1 & \\mathbf{i}_1\\mathbf{u}_2 & \\dots & \\mathbf{i}_1 \\mathbf{u}_N\\\\\n\\mathbf{i}_2\\mathbf{u}_1 & \\mathbf{i}_2\\mathbf{u}_2 & \\dots & \\mathbf{i}_2 \\mathbf{u}_N\\\\\n\\dots & \\dots & \\ddots & \\dots \\\\\n\\mathbf{i}_M\\mathbf{u}_1 & \\mathbf{i}_M\\mathbf{u}_2 & \\dots & \\mathbf{i}_M \\mathbf{u}_N\\\\\n\\end{matrix} \\right]\n = \\left[ \\begin{matrix}\n\\mathbf{i}_1 \\\\\n\\mathbf{i}_2 \\\\\n\\dots \\\\\n\\mathbf{i}_M \\\\\n\\end{matrix} \\right]\n\\left[ \\begin{matrix}\n\\mathbf{u}_1 & \\mathbf{u}_2 & \\dots & \\mathbf{u}_N\n\\end{matrix} \\right] = \\mathbf{IU}\n\\end{equation*}\n\n\n### 1.4. Thu\u1eadt to\u00e1n gradient descent\n\nGi\u1ea3 s\u1eed r\u1eb1ng ch\u00fang ta \u0111\u00e3 c\u00f3 th\u00f4ng tin v\u1ec1 c\u00e1c ma tr\u1eadn $\\mathbf{U}$ v\u00e0 $\\mathbf{I}$ \u0111i\u1ec1u ch\u00fang ta c\u1ea7n th\u1ef1c hi\u1ec7n b\u00e2y gi\u1edd l\u00e0 coi c\u00e1c d\u00f2ng c\u1ee7a m\u1ed7i $\\mathbf{I}$ l\u00e0 m\u1ed9t item profile v\u00e0 m\u1ed7i c\u1ed9t c\u1ee7a $\\mathbf{U}$ l\u00e0 m\u1ed9t user profile. Gi\u1ea3 s\u1eed $\\mathbf{I} \\in \\mathbb{R}^{M \\times K}$, $\\mathbf{U} \\in \\mathbb{R}^{K \\times N}$, $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$. Th\u00f4ng th\u01b0\u1eddng ta s\u1ebd ch\u1ecdn s\u1ed1 \u0111\u1eb7c tr\u01b0ng \u1ea9n nh\u1ecf h\u01a1n s\u1ed1 l\u01b0\u1ee3ng s\u1ea3n ph\u1ea9m v\u00e0 ng\u01b0\u1eddi d\u00f9ng. Khi \u0111\u00f3 Y s\u1ebd \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n d\u01b0\u1edbi d\u1ea1ng t\u00edch c\u1ee7a 2 ma tr\u1eadn c\u00f3 rank nh\u1ecf h\u01a1n (*Low-rank Matrix factorization*):\n\n\\begin{aligned}\\hat{\\mathbf{Y}} = \\mathbf{I}\\mathbf{U}\\end{aligned}\n\nH\u00e0m loss function c\u1ee7a thu\u1eadt to\u00e1n ch\u00ednh l\u00e0 chu\u1ea9n [Frobenius norm](http:\/\/mathworld.wolfram.com\/FrobeniusNorm.html) v\u1ec1 \u0111\u1ed9 l\u1ec7ch gi\u1eefa $\\mathbf{Y}$ v\u00e0 $\\mathbf{\\hat{Y}}$ nh\u01b0 sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I},\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2\n\\end{aligned}\n\n\u0110\u1ec3 tr\u00e1nh hi\u1ec7n t\u01b0\u1ee3ng overfiting [h\u1ec7 s\u1ed1 hi\u1ec7u ch\u1ec9nh b\u1eadc 2](https:\/\/towardsdatascience.com\/l1-and-l2-regularization-methods-ce25e7fc831c) (*l2 - reguralization*) \u0111\u01b0\u1ee3c \u0111\u01b0a th\u00eam v\u00e0o:\n\n\\begin{equation*}\n\\mathcal{L(\\mathbf{I},\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_1}{2}||\\mathbf{I}||_{F}^2 + \\frac{\\lambda_2}{2}||\\mathbf{U}||_{F}^2             \\tag{1.4.1}\n\\end{equation*}\n\nN\u1ebfu coi $\\mathbf{U}$ c\u1ed1 \u0111\u1ecbnh v\u00e0 c\u1ea7n t\u1ed1i \u01b0u $\\mathbf{I}$. B\u00e0i to\u00e1n `Matrix factorization` s\u1ebd t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u1edbi t\u1ed1i \u01b0u h\u00e0m loss function:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_1}{2}||\\mathbf{I}||_{F}^2\n\\end{aligned}\n\nN\u1ebfu coi $\\mathbf{I}$ c\u1ed1 \u0111\u1ecbnh v\u00e0 c\u1ea7n t\u1ed1i \u01b0u $\\mathbf{U}$. H\u00e0m loss function s\u1ebd c\u00f3 d\u1ea1ng:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_2}{2}||\\mathbf{U}||_{F}^2\n\\end{aligned}\n\nTa nh\u1eadn th\u1ea5y h\u00e0m loss function \u0111\u1ec1u l\u00e0 nh\u1eefng h\u00e0m l\u1ed3i. Vi\u1ec7c t\u00ecm nghi\u1ec7m t\u1ed1i \u01b0u c\u00f3 th\u1ec3 d\u1ef1a tr\u00ean b\u00e0i to\u00e1n t\u1ed1i \u01b0u l\u1ed3i b\u1eadc 2 (*Quadratic Programming*) ho\u1eb7c c\u00e1ch \u0111\u01a1n gi\u1ea3n h\u01a1n l\u00e0 th\u00f4ng qua thu\u1eadt to\u00e1n `gradient descent`. Ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n `Stochastic gradient descent` \u0111\u1ec3 c\u1eadp nh\u1eadt l\u1ea7n l\u01b0\u1ee3t t\u1eebng \u0111i\u1ec3m d\u1eef li\u1ec7u tr\u00ean to\u00e0n b\u1ed9 d\u1eef li\u1ec7u, sau \u0111\u00f3 l\u1eb7p l\u1ea1i qu\u00e1 tr\u00ecnh n\u00e0y. \u0110\u1ed1i v\u1edbi tr\u01b0\u1eddng h\u1ee3p ma tr\u1eadn s\u1ea3n ph\u1ea9m ($\\mathbf{I}$) c\u1ed1 \u0111\u1ecbnh, ta s\u1ebd c\u1ea7n c\u1eadp nh\u1eadt ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng ($\\mathbf{U}$) theo ph\u01b0\u01a1ng gradient descent. M\u1ed7i m\u1ed9t l\u01b0\u1ee3t c\u1eadp nh\u1eadt, m\u1ed9t ng\u01b0\u1eddi d\u00f9ng u \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn. D\u1ef1a tr\u00ean th\u00f4ng tin v\u1ec1 nh\u1eefng s\u1ea3n ph\u1ea9m m\u00e0 ng\u01b0\u1eddi d\u00f9ng u \u0111\u00e3 rating. Vector gradient descent \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n \u0111\u1ec3 c\u1eadp nh\u1eadt gi\u00e1 tr\u1ecb c\u1ee7a vector $\\mathbf{u}$ t\u01b0\u01a1ng \u1ee9ng. Qu\u00e1 tr\u00ecnh n\u00e0y ti\u1ebfp t\u1ee5c cho \u0111\u1ebfn khi to\u00e0n b\u1ed9 c\u00e1c vector users \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt. T\u01b0\u01a1ng t\u1ef1 nh\u01b0 v\u1eady \u0111\u1ed1i v\u1edbi tr\u01b0\u1eddng h\u1ee3p c\u1ed1 \u0111\u1ecbnh ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng c\u1ed1 \u0111\u1ecbnh v\u00e0 c\u1eadp nh\u1eadt ma tr\u1eadn s\u1ea3n ph\u1ea9m. \n\n**T\u1ed1i \u01b0u ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng:**\n\n\u0110\u1ec3 \u0111\u01a1n gi\u1ea3n h\u00f3a qu\u00e1 tr\u00ecnh t\u00ednh to\u00e1n, ta c\u00f3 th\u1ec3 bi\u1ec3u di\u1ec5n h\u00e0m loss function theo t\u1ed5ng loss function c\u1ee7a t\u1eebng user nh\u01b0 sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n)^2+\\frac{\\lambda_1}{2} ||\\mathbf{U}||_{F}^2\n\\end{aligned}\n\nTrong \u0111\u00f3 $r_{mn}$ l\u00e0 ph\u1ea7n t\u1eed thu\u1ed9c ma tr\u1eadn rating $R \\in \\mathbb{R}^{M \\times N}$ c\u00f3 gi\u00e1 tr\u1ecb 0 ho\u1eb7c 1. $r_{mn} = 1$ \u0111\u00e1nh d\u1ea5u s\u1ea3n ph\u1ea9m m \u0111\u00e3 \u0111\u01b0\u1ee3c rating b\u1edfi user n v\u00e0 b\u1eb1ng 0 trong tr\u01b0\u1eddng h\u1ee3p ch\u01b0a \u0111\u01b0\u1ee3c rating. \u0110i\u1ec1u ki\u1ec7n $r_{mn} = 1$ trong h\u00e0m loss function l\u00e0 \u0111\u1ec3 l\u1ecdc ra nh\u1eefng s\u1ea3n ph\u1ea9m \u0111\u00e3 \u0111\u01b0\u1ee3c rating b\u1edfi user n. Khi \u0111\u00f3 n\u1ebfu coi $\\hat{\\mathbf{I}}_n$ l\u00e0 ma tr\u1eadn c\u00e1c s\u1ea3n ph\u1ea9m \u0111\u00e3 \u0111\u01b0\u1ee3c rating c\u1ee7a user n v\u00e0 $\\hat{y}_n$ l\u00e0 vector k\u1ebft qu\u1ea3 rating t\u01b0\u01a1ng \u1ee9ng th\u00ec h\u00e0m loss function \u0111\u1ed1i v\u1edbi user n \u0111\u01b0\u1ee3c vi\u1ebft g\u1ecdn nh\u01b0 sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U}| user = n)} = \\frac{1}{2s}\\sum_{m: r_{mn} = 1}(y_{mn} - \\mathbf{i_m} . \\mathbf{u_n})^2 + \\frac{\\lambda_1}{2}||\\mathbf{u_n}||^2 = \\frac{1}{2s}||\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}||^2 + \\frac{\\lambda_1}{2}||\\mathbf{u_n}||^2\n\\end{aligned}\n\n\u0110\u1ea1o h\u00e0m c\u1ee7a n\u00f3 t\u01b0\u01a1ng \u1ee9ng:\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L(\\mathbf{U}| user = n)}}{\\partial \\mathbf{u_n}} = -\\frac{1}{s}\\hat{\\mathbf{I}}_n^{T}\\space (\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}) + \\lambda_1\\mathbf{u_n}\n\\end{aligned}\n\nC\u00f4ng th\u1ee9c c\u1eadp nh\u1eadt nghi\u1ec7m cho m\u1ed7i c\u1ed9t c\u1ee7a ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng:\n\n\\begin{aligned}\n\\mathbf{u'_n} = \\mathbf{u_n} - \\theta (-\\frac{1}{s}\\hat{\\mathbf{I}}_m^{T}\\space (\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}) + \\lambda_1\\mathbf{u_n})\n\\end{aligned}\n\n**T\u1ed1i \u01b0u ma tr\u1eadn s\u1ea3n ph\u1ea9m:**\n\nHo\u00e0n to\u00e0n t\u01b0\u01a1ng t\u1ef1 ta c\u0169ng c\u00f3 \u0111\u1ed1i v\u1edbi ma tr\u1eadn s\u1ea3n ph\u1ea9m, h\u00e0m loss function \u0111\u1ed1i v\u1edbi item = m:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I}| item = m)} = \\frac{1}{2s}\\sum_{n: r_{mn} = 1}(y_{mn} - \\mathbf{i_m} . \\mathbf{u_n})^2 + \\frac{\\lambda_1}{2}||\\mathbf{i_m}||^2 = \\frac{1}{2s}||\\mathbf{\\hat{y}_m}-\\mathbf{i_m}.\\hat{\\mathbf{U}}_m||^2 + \\frac{\\lambda_1}{2}||\\mathbf{i_m}||^2\n\\end{aligned}\n\n\u0110\u1ea1o h\u00e0m t\u01b0\u01a1ng \u1ee9ng \u0111\u1ed1i v\u1edbi m\u1ed7i item s\u1ebd l\u00e0:\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L(\\mathbf{I}| item = m)}}{\\partial \\mathbf{i_m}} = -\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_m}. \\hat{\\mathbf{U}}_m)\\hat{\\mathbf{U}}_m^{T} + \\lambda_1\\mathbf{i_m}\n\\end{aligned}\n\nC\u00f4ng th\u1ee9c c\u1eadp nh\u1eadt nghi\u1ec7m cho m\u1ed7i d\u00f2ng c\u1ee7a ma tr\u1eadn s\u1ea3n ph\u1ea9m:\n\n\\begin{aligned}\n\\mathbf{i'_m} = \\mathbf{i_m} - \\theta (-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_m}. \\hat{\\mathbf{U}}_m)\\hat{\\mathbf{U}}_m^{T} + \\lambda_1\\mathbf{i_m})\n\\end{aligned}\n\n## 2. X\u00e2y d\u1ef1ng code thu\u1eadt to\u00e1n\n\n### 2.1. Th\u1ef1c h\u00e0nh tr\u00ean b\u1ed9 d\u1eef li\u1ec7u movie length 1M\n\nCh\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n ph\u01b0\u01a1ng ph\u00e1p `matrix factorization` tr\u00ean b\u1ed9 d\u1eef li\u1ec7u [Movie length 1M](http:\/\/files.grouplens.org\/datasets\/movielens\/ml-1m.zip) g\u1ed3m 1 tri\u1ec7u c\u00e1c l\u01b0\u1ee3t ratings cho kho\u1ea3ng 4000 b\u1ed9 phim \u0111\u01b0\u1ee3c thu th\u1eadp t\u1eeb 6000 ng\u01b0\u1eddi d\u00f9ng. \u0110\u1ec3 ti\u1ec7n ph\u00f9 h\u1ee3p v\u1edbi thu\u1eadt to\u00e1n \u0111\u00e3 x\u00e2y d\u1ef1ng, c\u00e1c x\u1eed l\u00fd d\u1eef li\u1ec7u s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean ma tr\u1eadn. Load d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o nh\u01b0 sau:","a67c14a8":"**Thu\u1eadt to\u00e1n gradient descent cho ma tr\u1eadn s\u1ea3n ph\u1ea9m:**","4ac70ef4":"**X\u00e2y d\u1ef1ng h\u00e0m d\u1ef1 b\u00e1o ma tr\u1eadn $\\mathbf{Y}$:**\n\nD\u1ef1a tr\u00ean ma tr\u1eadn $\\mathbf{U}$ v\u00e0 $\\mathbf{I}$ ta c\u00f3 th\u1ec3 t\u00ednh to\u00e1n ma tr\u1eadn d\u1ef1 b\u00e1o c\u1ee7a $\\mathbf{Y}$ l\u00e0 $\\mathbf{\\hat{Y}}$ theo c\u00f4ng th\u1ee9c *(1.4.0)* v\u00e0 x\u00e2y d\u1ef1ng \u0111\u01b0\u1ee3c h\u00e0m *pred()*. C\u00e1c k\u1ebft qu\u1ea3 d\u1ef1 b\u00e1o c\u1ea7n \u0111\u01b0\u1ee3c chuy\u1ec3n h\u00f3a ng\u01b0\u1ee3c l\u1ea1i rating b\u1eb1ng c\u00e1ch c\u1ed9ng th\u00eam trung b\u00ecnh rating c\u1ee7a m\u1ed7i user v\u00e0o c\u00e1c gi\u00e1 tr\u1ecb ratings thu\u1ed9c c\u00f9ng 1 user. M\u1ed9t s\u1ed1 k\u1ebft qu\u1ea3 s\u1ebd v\u01b0\u1ee3t qu\u00e1 mi\u1ec1n gi\u00e1 tr\u1ecb c\u1ee7a rating l\u00e0 [1, 5] v\u00e0 khi \u0111\u00f3 s\u1ebd \u0111\u01b0\u1ee3c g\u00e1n l\u1ea1i v\u1ec1 2 \u0111\u1ea7u m\u00fat 1 ho\u1eb7c 5. Ma tr\u1eadn thu \u0111\u01b0\u1ee3c s\u1ebd th\u1ecfa m\u00e3n t\u1ea1i m\u1ed9t \u00f4 c\u1ee7a $\\mathbf{\\hat{Y}}$ l\u00e0 k\u1ebft qu\u1ea3 d\u1ef1 b\u00e1o rating c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u1ed1i v\u1edbi s\u1ea3n ph\u1ea9m t\u01b0\u01a1ng \u1ee9ng. Do ta ch\u1ec9 c\u1ea7n \u0111\u00e1nh gi\u00e1 tr\u1eadn $\\mathbf{Y}$ tr\u00ean nh\u1eefng c\u1eb7p (user,item) \u0111\u00e3 \u0111\u01b0\u1ee3c rating n\u00ean trong h\u00e0m *pred_train_test()* ta c\u1ea7n d\u1ef1a v\u00e0o ma tr\u1eadn rating $\\mathbf{R}$ \u0111\u1ec3 thay th\u1ebf nh\u1eefng v\u1ecb tr\u00ed ch\u01b0a \u0111\u01b0\u1ee3c rating b\u1eb1ng 0. L\u00fd do h\u00e0m s\u1ed1 n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u00ean l\u00e0 *pred_train_test()* \u0111\u00f3 l\u00e0 ch\u00fang ta c\u0169ng c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n t\u01b0\u01a1ng t\u1ef1 cho t\u1eadp test khi thay th\u1ebf gi\u00e1 tr\u1ecb ch\u01b0a rating b\u1eb1ng 0.","3f9f3c71":"### 2.2.2. X\u00e2y d\u1ef1ng class MF\n\nD\u1ef1a tr\u00ean c\u00e1c h\u00e0m \u0111\u00e3 x\u1eed l\u00fd \u1edf *(2.2.1)* ta s\u1ebd thi\u1ebft k\u1ebf class MF c\u00f3 ch\u1ee9c n\u0103ng x\u1eed l\u00fd d\u1eef li\u1ec7u, fiting model, \u0111\u00e1nh gi\u00e1 k\u1ebft qu\u1ea3 model v\u00e0 \u0111\u01b0a ra c\u00e1c recommend cho kh\u00e1ch h\u00e0ng v\u1ec1 s\u1ea3n ph\u1ea9m nh\u01b0 sau:\n\n**Class Data x\u1eed l\u00fd d\u1eef li\u1ec7u:**","d9035a61":"**Class model x\u00e2y d\u1ef1ng v\u00e0 \u0111\u00e1nh gi\u00e1 model:**","0e4f4873":"**X\u00e2y d\u1ef1ng class MF qu\u1ea3n l\u00fd model v\u00e0 data:**","fb2a609c":"Kh\u00f4ng ph\u1ea3i ho\u00e0n to\u00e0n c\u00e1c gi\u00e1 tr\u1ecb tr\u00ean ma tr\u1eadn $\\mathbf{Y}$ \u0111\u1ec1u \u0111\u01b0\u1ee3c rating. V\u00ec v\u1eady ma tr\u1eadn $\\mathbf{R}$ \u0111\u01b0\u1ee3c t\u1ea1o ra nh\u1eb1m \u0111\u00e1nh d\u1ea5u c\u00e1c v\u1ecb tr\u00ed \u0111\u01b0\u1ee3c rating c\u1ee7a $\\mathbf{Y}$ b\u1eb1ng gi\u00e1 tr\u1ecb 1 v\u00e0 ch\u01b0a \u0111\u01b0\u1ee3c rating b\u1eb1ng 0.","ee33669e":"**Ti\u1ebfn h\u00e0nh x\u00e2y d\u1ef1ng thu\u1eadt to\u00e1n:**\n\nC\u00e1c bi\u1ebfn ch\u00ednh cho thu\u1eadt to\u00e1n d\u1eef b\u00e1o bao g\u1ed3m:\n* n_users: S\u1ed1 l\u01b0\u1ee3ng user (ch\u00ednh l\u00e0 $N$ trong thu\u1eadt to\u00e1n).\n* n_items: S\u1ed1 l\u01b0\u1ee3ng item (ch\u00ednh l\u00e0 $M$ trong thu\u1eadt to\u00e1n).\n* K: S\u1ed1 l\u01b0\u1ee3ng nh\u00e2n t\u1ed1 \u1ea9n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng (gi\u00e1 tr\u1ecb $K$ trong thu\u1eadt to\u00e1n). \n* theta: Tham s\u1ed1 $\\theta$ \u0111\u1ec3 c\u1eadp nh\u1eadt h\u1ec7 s\u1ed1 trong thu\u1eadt to\u00e1n gradient descent.\n* split_rate: T\u1ef7 l\u1ec7 chia m\u1eabu train\/test.\n* lamda: Tham s\u1ed1 hi\u1ec7u ch\u1ec9nh c\u1ee7a th\u00e0nh ph\u1ea7n hi\u1ec7u ch\u1ec9nh `l2 - regularization` (\u0110\u1ec3 \u0111\u01a1n gi\u1ea3n thi\u1ebft l\u1eadp $\\lambda_1 = \\lambda_2$).\n* I: Ma tr\u1eadn s\u1ea3n ph\u1ea9m.\n* U: Ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng.\n\nL\u01b0u \u00fd r\u1eb1ng c\u00e1c ma tr\u1eadn $\\mathbf{I}, \\mathbf{U}$ \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng d\u1ef1a tr\u00ean c\u00e1c *nh\u00e2n t\u1ed1 \u1ea9n* (latent feature) n\u00ean ban \u0111\u1ea7u ta ch\u01b0a x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c c\u00e1c nh\u00e2n t\u1ed1 n\u00e0y v\u00e0 ph\u1ea3i kh\u1edfi t\u1ea1o gi\u00e1 tr\u1ecb ng\u1eabu nhi\u00ean cho ch\u00fang. S\u1ed1 l\u01b0\u1ee3ng nh\u00e2n t\u1ed1 \u1ea9n $K$ l\u00e0 m\u1ed9t gi\u00e1 tr\u1ecb t\u00f9y \u00fd ta c\u00f3 th\u1ec3 l\u1ef1a ch\u1ecdn. Theo [Matrix Factorization For Recommendation System](https:\/\/datajobs.com\/data-science-repo\/Recommender-Systems-%5BNetflix%5D.pdf) th\u00ec khi s\u1ed1 l\u01b0\u1ee3ng nh\u00e2n t\u1ed1 \u1ea9n c\u00e0ng nhi\u1ec1u thu\u1eadt to\u00e1n c\u00e0ng ch\u00ednh x\u00e1c h\u01a1n nh\u01b0ng c\u0169ng l\u00e0m gia t\u0103ng chi ph\u00ed t\u00ednh to\u00e1n.  \u0110\u1ed3ng th\u1eddi nh\u1eefng m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng d\u1ef1a tr\u00ean nh\u00e2n t\u1ed1 \u1ea9n \u0111\u00e3 \u0111\u01b0\u1ee3c tinh luy\u1ec7n \u0111\u1ec3 c\u00f3 m\u1ee9c \u0111\u1ed9 kh\u00e1c bi\u1ec7t l\u1edbn c\u0169ng \u0111\u01b0a ra k\u1ebft qu\u1ea3 ch\u00ednh x\u00e1c h\u01a1n c\u00e1c vi\u1ec7c t\u1ea1o ra c\u00e1c nh\u00e2n t\u1ed1 \u1ea9n ng\u1eabu nhi\u00ean. ","265a4e79":"Sau khi chu\u1ea9n h\u00f3a ma tr\u1eadn $\\mathbf{Y}$ th\u00ec ph\u1ea7n quan tr\u1ecdng nh\u1ea5t l\u00e0 \u00e1p d\u1ee5ng thu\u1eadt to\u00e1n `gradient descent` \u0111\u1ec3 t\u1ed1i \u01b0u h\u00f3a c\u00e1c h\u1ec7 s\u1ed1 c\u1ee7a ma tr\u1eadn $\\mathbf{U}, \\mathbf{I}$. D\u1ef1a tr\u00ean l\u00fd thuy\u1ebft v\u1ec1 thu\u1eadt to\u00e1n \u0111\u00e3 x\u00e2y d\u1ef1ng \u1edf m\u1ee5c **1.4** \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c h\u00e0m s\u1ed1 update ma tr\u1eadn:\n\n**Thu\u1eadt to\u00e1n gradient descent cho ma tr\u1eadn ng\u01b0\u1eddi d\u00f9ng:**","9072d373":"* B\u00ecnh qu\u00e2n m\u1ed9t user rate t\u1ed5ng c\u1ed9ng 165 b\u1ed9 phim. \n* User th\u1ea5p nh\u1ea5t rate 20 b\u1ed9 phim v\u00e0 user nhi\u1ec1u nh\u1ea5t rate 2314 b\u1ed9 phim. \n* Kho\u1ea3ng s\u1ed1 l\u01b0\u1ee3ng b\u1ed9 phim rating ph\u1ed5 bi\u1ebfn c\u1ee7a m\u1ed9t user l\u00e0 t\u1eeb 44 b\u1ed9 t\u1edbi 208 b\u1ed9 phim (chi\u1ebfm 50%).","a7e426e6":"S\u1eed d\u1ee5ng ma tr\u1eadn $\\mathbf{\\hat{Y}}$ \u0111\u1ec3 d\u1ef1 b\u00e1o tr\u00ean t\u1eadp test","37662f71":"Ta nh\u1eadn th\u1ea5y k\u1ebft qu\u1ea3 c\u1ee7a h\u00e0m `loss function` v\u00e0 `RMSE` gi\u1ea3m d\u1ea7n sau c\u00e1c v\u00f2ng l\u1eb7p. \u0110i\u1ec1u \u0111\u00f3 cho th\u1ea5y thu\u1eadt to\u00e1n `gradient descent` \u0111\u00e3 ph\u00e1t huy t\u00e1c d\u1ee5ng trong vi\u1ec7c l\u00e0m gi\u1ea3m sai s\u1ed1 d\u1ef1 b\u00e1o. Tuy nhi\u00ean \u0111\u00f4i khi ch\u00fang ta s\u1ebd g\u1eb7p t\u00ecnh hu\u1ed1ng `loss function` v\u00e0 `RMSE` t\u0103ng d\u1ea7n. C\u00f3 nhi\u1ec1u nguy\u00ean nh\u00e2n d\u1eabn t\u1edbi \u0111i\u1ec1u n\u00e0y ch\u1eb3ng h\u1ea1n nh\u01b0 h\u1ec7 s\u1ed1 `learning rate` v\u00e0 `regularization` \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp qu\u00e1 cao l\u00e0m thu\u1eadt to\u00e1n nh\u1ea3y ra kh\u1ecfi c\u1ef1c tr\u1ecb to\u00e0n c\u1ee5c ho\u1eb7c c\u0169ng c\u00f3 th\u1ec3 c\u00e1c `loss function` ch\u1ec9 t\u0103ng t\u1ea1m th\u1eddi v\u00e0 gi\u1ea3m sau \u0111\u00f3 \u0111\u1ec3 nghi\u1ec7m di chuy\u1ec3n qua \u0111i\u1ec3m c\u1ef1c tr\u1ecb \u0111\u1ecba ph\u01b0\u01a1ng. \u0110\u1ed1i v\u1edbi kh\u1ea3 n\u0103ng 1 ch\u00fang ta c\u1ea7n \u0111i\u1ec1u ch\u1ec9nh l\u1ea1i c\u00e1c h\u1ec7 s\u1ed1 `learning rate` v\u00e0 `regularization` \u0111\u1ec3 thu\u1eadt to\u00e1n di chuy\u1ec3n \u0111\u00fang h\u01b0\u1edbng t\u1edbi nghi\u1ec7m t\u1ed1i \u01b0u. Kh\u1ea3 n\u0103ng th\u1ee9 2 kh\u00f4ng qu\u00e1 nghi\u00eam tr\u1ecdng b\u1edfi thu\u1eadt to\u00e1n c\u00f3 th\u1ec3 di chuy\u1ec3n t\u1edbi nghi\u1ec7m t\u1ed1i \u01b0u ngay sau \u0111\u00f3.\n\nRecommend 10 s\u1ea3n ph\u1ea9m ti\u1ec1m n\u0103ng nh\u1ea5t cho user_id = 200:"}}