{"cell_type":{"3cc572ae":"code","a9e8c4b2":"code","a5765351":"code","2b10a890":"code","5a6a74c1":"code","30b02989":"code","b58327ba":"code","57849f17":"code","b32c34e3":"code","13e0a9e7":"markdown","ed4671b6":"markdown","b8b2cd71":"markdown","558d8bb0":"markdown","88a09165":"markdown","340552e4":"markdown","64ab914d":"markdown","f29e4cf1":"markdown"},"source":{"3cc572ae":"import pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\n\nmovie = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nrating = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\n\n\nmovie=movie[~movie[\"title\"].duplicated()]\nrating=rating[~rating.duplicated()]\n\ndf = movie.merge(rating,how=\"left\",on=\"movieId\")\ndf.head()","a9e8c4b2":"# Let's take a look to dataframe.....\n\ndf.shape\n\n# Total movie count\ndf[\"title\"].nunique() \n\n# Rating quantity\ndf[\"title\"].value_counts().head()  ","a5765351":"# Make dataframe more understandable...\"\n\nrating_counts = pd.DataFrame(df[\"title\"].value_counts())\n\nrare_movies = rating_counts[rating_counts[\"title\"] < 9000].index \n\ncommon_movies = df[~df[\"title\"].isin(rare_movies)] \n\ncommon_movies.head()","2b10a890":"# Creating user-movie dataframe...\n\nuser_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"],values=\"rating\")\n\nuser_movie_df.shape\nuser_movie_df.head(10)\nuser_movie_df.columns\nlen(user_movie_df.columns)","5a6a74c1":"# We picked one random user to following.\nrandom_user = user_movie_df[user_movie_df.index == 108170.0]","30b02989":"# Clear Na values and creating new list except values which had cleared\nmovies_watched = random_user.columns[random_user.notna().any().tolist()]\n\n# Watched movies count\nlen(movies_watched)","b58327ba":"movies_watched_df = user_movie_df[movies_watched]\nmovies_watched_df.head()\n\n# People counts that watched min 1 same movie with user\nmovies_watched_df.shape \n\n # How many movies have users watched?\nuser_movie_count = movies_watched_df.T.notnull().sum()\n\nuser_movie_count = user_movie_count.reset_index()\n\n# Change columns names\nuser_movie_count.columns = [\"userId\", \"movie_count\"]\n\n# Reviewing movies that same with random user watched upper than 20.\nuser_movie_count[user_movie_count[\"movie_count\"] > 20].sort_values(\"movie_count\", ascending=False).head(10)\n\n# Users who watched same movies 60 percent\na=len(movies_watched)*60\/100           \nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > a][\"userId\"]\n\n# ID's who watched same movies\nusers_same_movies.count()","57849f17":"# concat movies lists users watched and random user\nfinal_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies)],random_user[movies_watched]])\n\n# rewieving final_df\nfinal_df.head()\nfinal_df.shape\nfinal_df.T.corr()\n\n# creating pivot table with using correlation method except duplicates\n# we can see correlation between movies.\ncorr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()\n\n# editing dataframe\ncorr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\ncorr_df.index.names = ['user_id_1', 'user_id_2']\ncorr_df = corr_df.reset_index()\ncorr_df.sort_values(by=\"corr\",ascending=False)\n\n\n# determining top users which has like movie patterns 60 percent\ntop_users = corr_df[(corr_df[\"user_id_1\"] == 108170) & (corr_df[\"corr\"] >= 0.60)][[\"user_id_2\", \"corr\"]]. \\\n    reset_index(drop=True)\n\n#reviewing top users and creating new dataframe\ntop_users = top_users.sort_values(by='corr', ascending=False)\n\n# editing dataframe and change column names\ntop_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n\n# import main folder for merge and display MovieId and rating informations.\nrating = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\n\n# see top users ratings to movies\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\ntop_users_ratings = top_users_ratings[top_users_ratings[\"userId\"] != 108170]\ntop_users_ratings.head(10)","b32c34e3":"# weighted average score calculation\n# cause we've done here is creating new variable to represent mixture of correlation and rating score\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\ntop_users_ratings.head()\n\n\n# we grouped top_users_ratings dataframe by movieId and values are averaged weighted rating scores\nrecommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\nrecommendation_df = recommendation_df.reset_index()\n\nrecommendation_df.head()\nrecommendation_df.shape\nrecommendation_df[[\"movieId\"]].nunique()\n\n# Recommend movies\n# If weighted rating score is bigger than 3.3 than movies are available to recommend.\nmovies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 3.3].sort_values(\"weighted_rating\", ascending=False)\nmovies_to_be_recommend.shape\n\n# Get title information from main dataset.\nmovie = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nmovies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]])[\"title\"].head()","13e0a9e7":"**DETERMINING USERS WHICH HAVE SIMILAR PATTERN WITH USER TO BE RECOMMEND**","ed4671b6":"**IMPORT LIBRARIES**","b8b2cd71":"**DETERMINE MOVIES THAT WATCHED FOR NEW USER TO RECOMMEND**","558d8bb0":"**GET USER DATA AND ID THAT WATCHED SAME MOVIES WITH RANDOM USER**","88a09165":"**GENERAL EXPLORATION FOR DATASET**","340552e4":"**PICKED ONE RANDOM USER**","64ab914d":"**WEIGHTED AVERAGE RECOMMENDATION SCORE CALCULATION AND RECOMMEND MOVIES**","f29e4cf1":"# HYBRID RECOMMENDATION"}}