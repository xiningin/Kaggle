{"cell_type":{"1637df9a":"code","ef8903b7":"code","29d9a8ce":"code","2cd74d5c":"code","771effad":"code","1a57e9a4":"code","4ba5be1b":"code","82d939a4":"code","96c6fc07":"code","466ac41d":"code","96f8a691":"code","f09f33bf":"code","8b48abd9":"code","3f2d5a41":"code","9cba7278":"code","6f4ff2c5":"code","7550af0c":"code","18622056":"code","e4eead4d":"code","868a77a3":"code","d2733ac5":"code","ff10d98a":"code","4b645483":"code","321ec9d9":"code","d33f8c5b":"code","ba1c7b9a":"code","673709e9":"code","83c2ceab":"code","d6dc8836":"code","7894fc25":"code","2b0e7812":"code","3853d676":"code","1eefd7a6":"code","fccbe9af":"code","75a5b0c5":"code","914472af":"code","15a5c68e":"code","4269c8a8":"markdown","cec7ca93":"markdown","90fb8b3e":"markdown","45d51119":"markdown","78bb0bf0":"markdown","2f5340c0":"markdown","43fae438":"markdown","1f423f55":"markdown","405476c6":"markdown","554226c3":"markdown","e771125c":"markdown","79f3c45f":"markdown","4d3938a1":"markdown","4b2cdbc6":"markdown","2828cc37":"markdown","dda3d624":"markdown","eb25a55d":"markdown","30dc9914":"markdown","5f945300":"markdown","0230032e":"markdown","e74c28b4":"markdown","7756f1fc":"markdown","dc4590dd":"markdown","cf4a22b2":"markdown","3c97adb2":"markdown","b1ecd373":"markdown","67d41ef4":"markdown","6c90fdeb":"markdown","8bed2d27":"markdown","ff19bca3":"markdown","9cdf8a95":"markdown","022115d1":"markdown","4cc44a51":"markdown","b46dfc8a":"markdown","76ba07c9":"markdown","fb03d971":"markdown","dbb5c9f5":"markdown","66b39a5d":"markdown"},"source":{"1637df9a":"# all imports\nimport numpy as np #linear algebra\nimport pandas as pd # data processing I\/O\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import wordpunct_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\nimport re\n\nimport matplotlib.pyplot as plt #plots\n%matplotlib inline\nimport seaborn as sns#advanced plots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")#ignore warnings\n\nfrom tqdm import tqdm\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport collections","ef8903b7":"tr_var = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_variants', sep=',')\ntr_var.head()","29d9a8ce":"tr_text = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_text', sep='\\|\\|',engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)\ntr_text.head(1)","2cd74d5c":"tr_var.describe(include='all')","771effad":"tr_text.describe(include='all')","1a57e9a4":"print('Is there any null values in training variants:', tr_var.isnull().values.any())\nprint('Is there any null values in training text:', tr_text.isnull().values.any())","4ba5be1b":"print(\"get indexes of null values in all training text\")\nprint(tr_text.loc[tr_text.isnull().any(axis=1)])","82d939a4":"plt.figure(figsize=(12,8))\nplt.title(\"classes distribution: training Data\")\n#(1-9 the class this genetic mutation has been classified on)\nsns.countplot(x=\"Class\", data=tr_var)\nplt.xlabel(\"Classes\")\nplt.show()","96c6fc07":"plt.figure(figsize=(12,8))\nplt.title(\"classes distribution: training Data\")\n#(1-9 the class this genetic mutation has been classified on)\nsns.countplot(x=\"Gene\", data=tr_var)\nplt.xlabel(\"Classes\")\nplt.show()","466ac41d":"plt.figure(figsize=(12,8))\nplt.title('frequency dist of gene')\nsns.distplot(sorted(tr_var[\"Gene\"].value_counts().tolist(), reverse=True), hist = False, kde_kws=dict(cumulative=True))\nplt.xlabel('Gene')\nplt.grid()\nplt.minorticks_on()\nplt.grid(b=True, which='minor', color='r', linestyle='--')\nplt.show()","96f8a691":"tr_var[\"Gene\"].value_counts()[:20]","f09f33bf":"def selectTopGene(top):\n  tmp_list = tr_var[\"Gene\"].value_counts()[:top].index.tolist()\n  tmp_df = tr_var[tr_var['Gene'].isin(tmp_list)]\n  #print(tmp_df)\n  return tmp_df","8b48abd9":"def drawClassVsTopGeneFacet(top):\n  tmp_df = selectTopGene(top)\n  fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(18,15))\n  for i in range(3):\n    for j in range(3):\n      tmp_df_1 = tmp_df[tmp_df['Class'] == ((i*3+j)+1)].groupby('Gene').size().reset_index(name='counts')\n      tmp_df_1 = tmp_df_1.sort_values('counts', ascending=False)\n      tmp_df_top_7 = tmp_df_1[:]\n      axs[i][j].set_title('for Class ' + str((i*3+j)+1))\n      plt.sca(axs[i][j])\n      plt.xticks(rotation=30)\n      sns.barplot(x=\"Gene\", y=\"counts\", data=tmp_df_top_7, ax=axs[i][j])","3f2d5a41":"drawClassVsTopGeneFacet(20)","9cba7278":"tr_text.columns","6f4ff2c5":"print(tr_text['TEXT'].iloc[0])","7550af0c":"print(tr_text['TEXT'].iloc[1])","18622056":"def plotWordCloud():\n  combText = tr_text['TEXT'].agg(lambda x: ' '.join(x.dropna()))\n  wordcloud = WordCloud().generate(combText)\n  # Display the generated image:\n  print(\"word cloud for text \")\n  plt.figure(figsize=(12,8))\n  plt.imshow(wordcloud, interpolation='bilinear')\n  plt.axis(\"off\")\n  plt.show()","e4eead4d":"plotWordCloud()","868a77a3":"stop_words = set(stopwords.words('english'))\nps = PorterStemmer()\nstemmer = SnowballStemmer(\"english\")","d2733ac5":"def removeStopWords(sentence):\n  sentence = sentence.replace('\\\\r', ' ')\n  sentence = sentence.replace('\\\\\"', ' ')\n  sentence = sentence.replace('\\\\n', ' ')\n  sentence = re.sub('\\(.*?\\)', ' ', sentence)\n  sentence = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n  list_of_words = [i.lower() for i in wordpunct_tokenize(sentence) if i.lower() not in stop_words]\n  list_of_words = [stemmer.stem(i.lower()) for i in list_of_words if stemmer.stem(i.lower()) not in stop_words]\n  sentence = ' '.join(list_of_words).lower().strip()\n\n  return sentence\n","ff10d98a":"stop_words.update(['line', 'fig','figure', 'author','find',\n                   'et', 'al', 'evaluate', 'show', 'demonstrate', 'conclusion', 'study', 'analysis', 'method'])","4b645483":"def preProcessText():\n  tmp_sen = []\n  for i in tqdm(tr_text['TEXT']):\n    i = removeStopWords(i)\n    tmp_sen.append(i)\n  \n  tr_text['TEXT'] = tmp_sen","321ec9d9":"tr_text = tr_text.replace(np.nan, '', regex=True)\npreProcessText()\nplotWordCloud()","d33f8c5b":"df = tr_var.join(other=tr_text.set_index('ID'), on='ID')\ndf.head()","ba1c7b9a":"def jaccard_similarity(document1, document2):\n  intersection = set(document1).intersection(set(document2))\n  union = set(document1).union(set(document2))\n  return len(intersection)\/len(set(union))","673709e9":"#https:\/\/stackoverflow.com\/a\/17841321\ntmp_df = df.groupby('Class')['TEXT'].agg(lambda col: ' '.join(col)).reset_index()","83c2ceab":"tmp_df.head()","d6dc8836":"similarity = np.zeros((9, 9))\ndef calculateSimilrity():\n  for i in tqdm(tmp_df[\"Class\"].values):\n    for j in tmp_df[\"Class\"].values:\n     if(i < j):\n       sim = jaccard_similarity(tmp_df['TEXT'].iloc[i - 1].split(), tmp_df['TEXT'].iloc[j - 1].split())\n       similarity[i - 1][j - 1] = sim\n       similarity[j - 1][i - 1] = sim\n","7894fc25":"calculateSimilrity()","2b0e7812":"#https:\/\/stackoverflow.com\/a\/58165593\n#https:\/\/indianaiproduction.com\/seaborn-heatmap\/\nplt.figure(figsize=(12, 8))\nup_matrix = np.triu(similarity)\nax = sns.heatmap(similarity, xticklabels=range(1,10), yticklabels=range(1,10), annot=True, mask=up_matrix)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","3853d676":"def calculateTF(document):\n  tmp_tfs = dict()\n  words = document.split()\n  len_doc = len(words)\n  for word in words:\n    if word in tmp_tfs:\n      tmp_tfs[word] += 1\n    else:\n      tmp_tfs[word] = 1\n  \n  for word in tmp_tfs:\n    tmp_tfs[word] = tmp_tfs[word] \/ len_doc\n  return tmp_tfs","1eefd7a6":"def calculateIDF(documents):\n  vectorizer = TfidfVectorizer()\n  X = vectorizer.fit_transform(documents)\n  tmp_dct = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_ ))\n  return tmp_dct","fccbe9af":"def calculateTfIdf(documents):\n  tmp_tfIdf = dict()\n  tmp_idfs = calculateIDF(documents)\n  count = 0\n  for i in documents:\n    tmp_tfs = calculateTF(i)\n    tmp_dict = dict()\n    for j in set(i.split()):\n      try:\n        tmp_dict[j] = tmp_idfs[j] * tmp_tfs[j]\n      except:\n        continue\n    tmp_tfIdf[count] = tmp_dict\n    count += 1\n  return tmp_tfIdf","75a5b0c5":"tfIdfs = calculateTfIdf(df['TEXT'].values)","914472af":"sorted(tfIdfs[0].items(), key=lambda kv: kv[1])[:2]","15a5c68e":"plt.figure(figsize=(12,15))\nplt.title(\"word frequency for each class\")\nfor i in tqdm(range(9)):\n  tmp_arr = sorted(tfIdfs[i].items(), key=lambda kv: kv[1], reverse=True)[:10]\n  plt.subplot(3, 3, (i + 1))\n  plt.title('class ' + str(i + 1))\n  tfidfseries = pd.Series(data=[p[1] for p in tmp_arr],name='TFIDF')\n  names = pd.Series(data=[p[0] for p in tmp_arr], name='Words')\n  frame = {'words': names, 'tfidfs': tfidfseries}\n  tmp_df_tfidf = pd.DataFrame(frame)\n  plt.xticks(rotation=30)\n  ax = sns.barplot(x='words', y=\"tfidfs\", data=tmp_df_tfidf)\n\nplt.show()","4269c8a8":"**let's look at most frequent genes (top 20)vs Classes**","cec7ca93":"### 3.3.Combine Text document with variant documet","90fb8b3e":"### 2.1. Number of Classes","45d51119":"# EDA of Personalised Medicine: Redefining Cancer Treatment","78bb0bf0":"- 8 and 9 are most similar in terms of jaccard similarity\n- followed by (6,5),(5,3),(4,1),(7,2)","2f5340c0":"### 2.2. Gene ","43fae438":"- 20 types of genes constitutes the 80% total counts\n- 50 types of genes constitute 87.5% of total counts\n\nlet's find out what are these top 20 genes","1f423f55":"- wild, type, cells, expressing, kinase, domain,breast, cancer, activity, supplementary, et, al, line, aminoe, acid, Figure, missense, mutation, tyrosine, gene etc are most frequent words.\n- Here, In this particular problem, we are trying predict the class and hence it is  common sensical to have our features to as much dissimilar as possible, and hence I think it good idea to remove such repeating words.\n\n\nlet's do little preprocessing of text by removing some stop words and special characters","405476c6":"- Top five genes are super dominant with BRCA1 leading the list","554226c3":"- we can observe that few classes are super dominant\n\nlet's try to understand things little better by viewing frequency distribution plot","e771125c":"**Here the goal is to analyse the text and try to extract some features from them**","79f3c45f":"- It was given that text plays crusial role in predicting the class.\n\n**Let's look at few text fields to get the abstract idea of how the text looks like**","4d3938a1":"**Workflow of classifying genetic mutations**\n-  molecular pathologist selects a list of genetic variations of interest that he\/she want to analyze\n- The molecular pathologist searches for evidence in the medical literature that somehow are relevant to the genetic variations of interest\n- Finally this molecular pathologist spends a huge amount of time analyzing the evidence related to each of the variations to classify them\n\nOur goal here is to replace step 3 by a machine learning model. The molecular pathologist will still have to decide which variations are of interest, and also collect the relevant evidence for them. But the last step, which is also the most time consuming, will be fully automated","4b2cdbc6":"**About**\n- There are 9 different genetic mutations that we can classify upon\n- GENE VALUES: The gene where a mutation is located\n- VARIARION: The amino acid change for the mutation\n- TEXT: The clinical evidance used to classify these mutations\n- In the given data `A Gene and Variation pair is unique`[refer here](https:\/\/www.kaggle.com\/c\/msk-redefining-cancer-treatment\/discussion\/35336#197792)\n- Once sequenced, a cancer tumor can have thousands of genetic mutations. But the challenge is distinguishing the mutations that contribute to tumor growth (drivers) from the neutral mutations (passengers).Currently this interpretation of genetic mutations is being done manually. This is a very time-consuming task where a clinical pathologist has to manually review and classify every single genetic mutation based on evidence from text-based clinical literature.\n- more about genetic mutations, [refer here](https:\/\/www.youtube.com\/watch?v=qxXRKVompI8)","2828cc37":"- Given Train dataset is unbalanced\n- Class 7 is the most dominating one\n- Class 8, 9, 3 are relatively very small","dda3d624":"### 3.4. Jaccard Similarity between documents","eb25a55d":"## 4.0. Text Analysis","30dc9914":"### 4.5. Let's view tf-idf of word importance per Class","5f945300":"- There are multiple abstracts of different research papers involved in each text field.\n- Just like any other scientific papers, it involves references to other papers (ex: (1), (2)), references to figures, ex: (fig: 2), short forms and full forms in braces. I think the usefullness of such words or texts is limited, however my knowledge is limited.\n- There are words like CDK10, EBF (witho out paranthesis),which, I think are refering to a particular process or a particular thing in medical terminology, I think they are going to play crusial role in predicting Classes","0230032e":"**Q: Why we are given empty values in text data?What is the best thing to do in such cenarios?**\n\n**Answer:** The empty values might add robustness to the data, but it is given that analysing text is important for prediction of class and hence, for now I decide that, It is good idea to leave such rows with empty text data. This assumption might change in future, as we analyse more features.","e74c28b4":"- As we know from the summary we have total 264 different genes.\n\nlet's view the rough picture of frequency of these genes","7756f1fc":"## 1.0. About","dc4590dd":"### 2.3. Variation of Mutation","cf4a22b2":"- TFIDF values are giving different picture than jaccard similarity\n- There are lot of common words between class 6 and 7 in top ifidf values and yer the jaccard similarity shows 6 and 7 are siginificantly different ones.","3c97adb2":"### 3.2. Text Preprocessing: remove stopwords","b1ecd373":"- there are roughly 1920 unique text fields\n- The most repeated one beeing repeated 53 times","67d41ef4":"### 1.5. Summary of Dataset","6c90fdeb":"### 3.1. Word Cloud of All text docs:\n to understand the frequent words","8bed2d27":"- There are 264 unique Genes\n- There are 2996 unique Variations of mutations\n- Total 3321 rows","ff19bca3":"\n- For Class 8 and 9 EGFR, ERBB2 and TP53 are the most dominating ones\n- EGFR is dominating in class 8, 7, 2\n- TP53 is most dominating in 1, 9\n- BRCA1 is dominating in class 3 and 5\n- PTEN is dominating in class 4\n- For Class 8 and 9 top 20 Genes appeared only once, it suggests class 8 and 9 are most dissimilar from others or from the total counts of class 8 and 9 are severly underrepresented","9cdf8a95":"**Question:** Is it good Idea to identify and remove most common words in documens, so that we have best dissimilar set of documents for each class?","022115d1":"## 2.0. Univariant Analysis","4cc44a51":"- From the summary of the data we can say that there are total 2996 unique variations\n- It was given that total 3321 rows exist and combination of gene and variation is unique\n- It means many variations only appeared once in the entire train dataset","b46dfc8a":"### 1.1. All imports","76ba07c9":"### 1.6. Finding null values","fb03d971":"### 3.1. Gene vs Class","dbb5c9f5":"## 3.0. Bivariant Analysis: Interaction between features","66b39a5d":"### 1.4. Basic analysis"}}