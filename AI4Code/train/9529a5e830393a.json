{"cell_type":{"2f2d2682":"code","c2048d6d":"code","8ba229d6":"code","3141ba94":"code","b7c4e566":"code","87a97fd2":"code","4b3e51c0":"code","955ed7ea":"code","9521fb73":"code","31fe6518":"code","3e29db65":"code","7d13e8e6":"code","36b89cfd":"code","aa5f545c":"code","619c7997":"code","0acfe8ba":"code","0040613f":"code","06652512":"code","ac8ff191":"code","0edac0e7":"code","b2b68fca":"code","86d78cf4":"code","d5397641":"code","bf24b7ac":"code","8a931bbd":"code","582a8464":"code","f5a0d9ef":"markdown","a1a32bcb":"markdown","136e55b6":"markdown","bbba0bab":"markdown","9236903e":"markdown","3d11c719":"markdown","8cfdadc0":"markdown","f621ca70":"markdown","fde245da":"markdown","dc456744":"markdown"},"source":{"2f2d2682":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2048d6d":"import tensorflow as tf\nimport os\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nfrom skimage.io import imread,imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt","8ba229d6":"# importing required modules \nfrom zipfile import ZipFile \n  \n# specifying the zip file name \nfile_name = \"..\/input\/data-science-bowl-2018\/stage1_train.zip\"\n  \n# opening the zip file in READ mode \nwith ZipFile(file_name, 'r') as zip: \n    # printing all the contents of the zip file \n     \n  \n    # extracting all the files \n    print('Extracting all the files now...') \n    zip.extractall(\"stage1_train\") \n    print('Done!') ","3141ba94":"# importing required modules \nfrom zipfile import ZipFile \n  \n# specifying the zip file name \nfile_name = \"..\/input\/data-science-bowl-2018\/stage1_test.zip\"\n  \n# opening the zip file in READ mode \nwith ZipFile(file_name, 'r') as zip: \n    # printing all the contents of the zip file \n     \n  \n    # extracting all the files \n    print('Extracting all the files now...') \n    zip.extractall(\"stage1_test\") \n    print('Done!') ","b7c4e566":"TRAIN_PATH=\"stage1_train\/\"\nTEST_PATH='stage1_test\/'","87a97fd2":"train_ids=next(os.walk(TRAIN_PATH))[1]\ntest_ids=next(os.walk(TEST_PATH))[1]\nprint(len(train_ids))","4b3e51c0":"IMG_HEIGHT=128\nIMG_WIDTH=128\nIMG_CHANNELS=3","955ed7ea":"X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nprint('Resizing training images and masks')\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n    path = TRAIN_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img  #Fill empty X_train with values from img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)  \n            \n    Y_train[n] = mask   \n\n# test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Resizing test images') \nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","9521fb73":"image_x=random.randint(0,len(train_ids))\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(Y_train[image_x]))\n\nplt.show()","31fe6518":"seed=42\nnp.random.seed=seed","3e29db65":"\n#Build the model\ninputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = tf.keras.layers.Lambda(lambda x: x \/ 255)(inputs)\n\n#Contraction path\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n \nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n \nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n \nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n#Expansive path \nu6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n \nu7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n \nu8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n \nu9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis=3)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n \noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\nmodelu = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodelu.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodelu.summary()\n","7d13e8e6":"#callbacks\ncallbacks=[tf.keras.callbacks.EarlyStopping(patience=2,monitor='val_loss'),\n           tf.keras.callbacks.TensorBoard(log_dir='logs')]","36b89cfd":"results=model.fit(X_train,Y_train,validation_split=0.1,batch_size=16,epochs=30,callbacks=callbacks)","aa5f545c":"predict_test=model.predict(X_test,verbose=1)","619c7997":"predict_test_t=(predict_test>0.5).astype(np.uint8)","0acfe8ba":"imshow(X_test[1])\nplt.show()\nimshow(np.mean(predict_test_t[1], axis=2))\nplt.show()","0040613f":"imshow(X_test[2])\nplt.show()\nimshow(np.mean(predict_test_t[2], axis=2))\nplt.show()","06652512":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import *\n\ndef squeeze_excite_block(inputs, ratio=8):\n    init = inputs\n    channel_axis = -1\n    filters = init.shape[channel_axis]\n    se_shape = (1, 1, filters)\n\n    se = GlobalAveragePooling2D()(init)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters \/\/ ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n\n    x = Multiply()([init, se])\n    return x\n\ndef conv_block(inputs, filters):\n    x = inputs\n\n    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = squeeze_excite_block(x)\n\n    return x\n\ndef encoder1(inputs):\n    skip_connections = []\n\n    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n    for name in names:\n        skip_connections.append(model.get_layer(name).output)\n\n    output = model.get_layer(\"block5_conv4\").output\n    return output, skip_connections\n\ndef decoder1(inputs, skip_connections):\n    num_filters = [256, 128, 64, 32]\n    skip_connections.reverse()\n    x = inputs\n\n    for i, f in enumerate(num_filters):\n        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n        x = Concatenate()([x, skip_connections[i]])\n        x = conv_block(x, f)\n\n    return x\n\ndef encoder2(inputs):\n    num_filters = [32, 64, 128, 256]\n    skip_connections = []\n    x = inputs\n\n    for i, f in enumerate(num_filters):\n        x = conv_block(x, f)\n        skip_connections.append(x)\n        x = MaxPool2D((2, 2))(x)\n\n    return x, skip_connections\n\ndef decoder2(inputs, skip_1, skip_2):\n    num_filters = [256, 128, 64, 32]\n    skip_2.reverse()\n    x = inputs\n\n    for i, f in enumerate(num_filters):\n        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n        x = Concatenate()([x, skip_1[i], skip_2[i]])\n        x = conv_block(x, f)\n\n    return x\n\ndef output_block(inputs):\n    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n    x = Activation('sigmoid')(x)\n    return x\n\ndef Upsample(tensor, size):\n    \"\"\"Bilinear upsampling\"\"\"\n    def _upsample(x, size):\n        return tf.image.resize(images=x, size=size)\n    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n\ndef ASPP(x, filter):\n    shape = x.shape\n\n    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n    y1 = BatchNormalization()(y1)\n    y1 = Activation(\"relu\")(y1)\n    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n\n    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n    y2 = BatchNormalization()(y2)\n    y2 = Activation(\"relu\")(y2)\n\n    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n    y3 = BatchNormalization()(y3)\n    y3 = Activation(\"relu\")(y3)\n\n    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n    y4 = BatchNormalization()(y4)\n    y4 = Activation(\"relu\")(y4)\n\n    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n    y5 = BatchNormalization()(y5)\n    y5 = Activation(\"relu\")(y5)\n\n    y = Concatenate()([y1, y2, y3, y4, y5])\n\n    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n    y = BatchNormalization()(y)\n    y = Activation(\"relu\")(y)\n\n    return y\n\ndef build_model(shape):\n    inputs = Input(shape)\n    x, skip_1 = encoder1(inputs)\n    x = ASPP(x, 64)\n    x = decoder1(x, skip_1)\n    outputs1 = output_block(x)\n\n    x = inputs * outputs1\n\n    x, skip_2 = encoder2(x)\n    x = ASPP(x, 64)\n    x = decoder2(x, skip_1, skip_2)\n    outputs2 = output_block(x)\n    outputs = Concatenate()([outputs1, outputs2])\n\n    model = Model(inputs, outputs)\n    return model","ac8ff191":"model = build_model((128, 128, 3))\nmodel.summary()","0edac0e7":"model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\ncallbacks=[tf.keras.callbacks.EarlyStopping(patience=5,monitor='val_loss'),\n           tf.keras.callbacks.TensorBoard(log_dir='logs')]","b2b68fca":"results=model.fit(X_train,Y_train,validation_split=0.1,batch_size=16,epochs=30,callbacks=callbacks)","86d78cf4":"predict_test=model.predict(X_test,verbose=1)","d5397641":"predict_test_t=(predict_test>0.5).astype(np.uint8)","bf24b7ac":"X_test.shape\npredict_test_t.shape","8a931bbd":"plt.imshow(X_test[1])\nplt.show()\nplt.imshow(np.mean(predict_test_t[1], axis=2))\nplt.show()","582a8464":"imshow(X_test[2])\nplt.show()\nimshow(np.mean(predict_test_t[2], axis=2))\nplt.show()","f5a0d9ef":"## Unzipping the files","a1a32bcb":"## Building a U-Net","136e55b6":"![image.png](attachment:image.png)","bbba0bab":"## Having a look at our training images and the segmented images related to it respectively","9236903e":"## Applying the segmentation on the test images using our trained model.","3d11c719":"## Building a Double Unet","8cfdadc0":"## Performing preprocessing, Loading the data, and Getting data ready for our model","f621ca70":"## Training the model","fde245da":"### Introduction:\nU-Net is a convolutional neural network that was developed for biomedical image segmentation at the Computer Science Department of the University of Freiburg, Germany. The network is based on the fully convolutional network and its architecture was modified and extended to work with fewer training images and to yield more precise segmentations. Segmentation of a 512 \u00d7 512 image takes less than a second on a modern GPU.\n\nThe U-Net architecture stems from the so-called \u201cfully convolutional network\u201d first proposed by Long and Shelhamer.\n\nThe main idea is to supplement a usual contracting network by successive layers, where pooling operations are replaced by upsampling operators. Hence these layers increase the resolution of the output. What's more, a successive convolutional layer can then learn to assemble a precise output based on this information.\n\nOne important modification in U-Net is that there are a large number of feature channels in the upsampling part, which allow the network to propagate context information to higher resolution layers. As a consequence, the expansive path is more or less symmetric to the contracting part, and yields a u-shaped architecture. The network only uses the valid part of each convolution without any fully connected layers. To predict the pixels in the border region of the image, the missing context is extrapolated by mirroring the input image. This tiling strategy is important to apply the network to large images, since otherwise the resolution would be limited by the GPU memory.\n\nSource: https:\/\/en.wikipedia.org\/wiki\/U-Net","dc456744":"## Importing important libraries"}}