{"cell_type":{"413c2131":"code","af39bd27":"code","b8d9b2c7":"code","8fc7bf56":"code","8b544eab":"code","2f33a593":"code","c6c00cc7":"code","15efe9f7":"code","647c31a6":"code","4cbd406a":"code","221552e8":"code","b09d04eb":"code","aafc3bf5":"code","fed0539b":"code","2bb71f93":"code","d8bd45cb":"code","12e038b2":"markdown","65cf7891":"markdown","e281c1aa":"markdown","5630361c":"markdown","c00bf96c":"markdown","ea02fc63":"markdown","b6915a8b":"markdown","df856cf7":"markdown"},"source":{"413c2131":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af39bd27":"from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nfrom keras.preprocessing import sequence\nfrom sklearn.model_selection import train_test_split\nimport collections\nimport matplotlib.pyplot as plt\nimport nltk\nimport os\nfrom sklearn.feature_extraction.text import CountVectorizer","b8d9b2c7":"train = pd.read_csv(\"\/kaggle\/input\/umich-si650-nlp\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/umich-si650-nlp\/test.csv\")","8fc7bf56":"x_train =train['sentence']\ny_train =train['label']","8b544eab":"vectorizer = CountVectorizer()\nx_train = vectorizer.fit_transform(train.sentence)\nx_test = vectorizer.transform(test.sentence)","2f33a593":"word_freq = pd.DataFrame({'Word': vectorizer.get_feature_names(), 'Count': x_train.toarray().sum(axis=0)})\nword_freq['Frequency'] = word_freq['Count'] \/ word_freq['Count'].sum()\n\nword_freq_sort = word_freq.sort_values(by='Frequency', ascending=False)\nword_freq_sort.head(10)","c6c00cc7":"maxlen = 0\nword_freqs = collections.Counter()\nnum_recs = 0","15efe9f7":"f = open(\"\/kaggle\/input\/umich-si650-nlp\/train.csv\", \"rb\")\nfor line in f:\n    sentence = str(line).split(\",\")[0]\n    words = nltk.word_tokenize(sentence.encode().decode(\"ascii\", \"ignore\").lower())\n    if len(words) > maxlen:\n        maxlen = len(words)\n    for word in words:\n        word_freqs[word] += 1\n    num_recs += 1\nf.close()\nprint(\"Max number of words in a sentence: \", maxlen)\nprint(\"Number of unqiue words: \", len(word_freqs))","647c31a6":"MAX_FEATURES = 1500\nMAX_SENTENCE_LENGTH = 40\nvocab_size = min(MAX_FEATURES, len(word_freqs)) + 2\nword2index = {x[0]: i+2 for i, x in enumerate(word_freqs.most_common(MAX_FEATURES))}\nword2index[\"PAD\"] = 0\nword2index[\"UNK\"] = 1\nindex2word = {v:k for k, v in word2index.items()}","4cbd406a":"X = np.empty((num_recs, ), dtype=list)\nXt = []\ny = np.zeros((num_recs, ))\ni = 0\n\nf = open(\"\/kaggle\/input\/umich-si650-nlp\/train.csv\", \"r\")\nnext(f)\nfixed = []\nfor line in f:\n    line_arr = line.split(\",\")\n    if len(line_arr) > 2:\n        line_arr[:len(line_arr)-1] = [\"\".join(line_arr[:len(line_arr)-1])]\n        fixed.append(line_arr)\n    else:\n        fixed.append(line_arr)\n\nfor fline in fixed:\n        sentence = fline[0]\n        label = int(fline[1])\n        words = nltk.word_tokenize(sentence.encode().decode(\"ascii\", \"ignore\").lower())\n        seqs = []\n        for word in words:\n            if word in word2index:\n                seqs.append(word2index[word])\n            else:\n                seqs.append(word2index[\"UNK\"])\n        X[i] = seqs\n        y[i] = int(label)\n        i += 1\nf.close()\n\n# Convert every occurence of None to an empty list\n\nfor i in range(0,X.shape[0]):\n    if X[i] == None:\n        X[i] = ()\n\nX = sequence.pad_sequences(X, maxlen=MAX_SENTENCE_LENGTH)\n","221552e8":"# Get shape of X\nX.shape","b09d04eb":"# Splitting our data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)","aafc3bf5":"EMBEDDING_SIZE = 128\nHIDDEN_LAYER_SIZE = 64\nBATCH_SIZE = 32\nNUM_EPOCHS = 10\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=MAX_SENTENCE_LENGTH))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(HIDDEN_LAYER_SIZE, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n","fed0539b":"history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(X_test, Y_test))","2bb71f93":"# Plot loss and accuracy values over time\nplt.subplot(211)\nplt.title(\"Accuracy\")\nplt.plot(history.history[\"accuracy\"], color=\"g\", label=\"Train\")\nplt.plot(history.history[\"val_accuracy\"], color=\"b\", label=\"Validation\")\nplt.legend(loc=\"best\")\n\nplt.subplot(212)\nplt.title(\"Loss\")\nplt.plot(history.history[\"loss\"], color=\"g\", label=\"Train\")\nplt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\nplt.legend(loc=\"best\")\n\nplt.tight_layout()\nplt.show()","d8bd45cb":"score, acc = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)\nprint(\"Test score: %.3f, accuracy: %.3f\" % (score, acc))\n\nfor i in range(5):\n    idx = np.random.randint(len(X_test))\n    xtest = X_test[idx].reshape(1, 40)\n    ylabel = Y_test[idx]\n    ypred = model.predict(xtest)[0][0]\n    sent = \" \".join([index2word[x] for x in xtest[0].tolist() if x != 0])\n    print(\"%.0f - %d - %s\" % (ypred, ylabel, sent))","12e038b2":"**Getting the number of unique words and number of words in a sentence**","65cf7891":"**Model Evaluation**","e281c1aa":"**Create our model**","5630361c":"**Training the model**","c00bf96c":"**Our Imports**","ea02fc63":"**Get the count and frequency of each word**","b6915a8b":"**Convert our input sentences to word index sequences then pad them to \"MAX_SENTENCE_LENGTH\" words.**","df856cf7":"**Read our train and test data**"}}