{"cell_type":{"dd6a00ab":"code","eb49c595":"code","95911e69":"code","ed906f9e":"code","51399e39":"code","9465b321":"code","4b11c6a9":"code","01c888f3":"code","8b4c021d":"code","643579de":"code","6de4f121":"code","9eba8857":"code","6cd4dc8b":"code","36352945":"code","17ce62fe":"code","688e91be":"code","5d14edbf":"code","b287af77":"code","d5cc2e2b":"code","9e2f2c39":"code","00eccc0b":"code","4e84fbf0":"code","e7d282b4":"code","3e50bf44":"code","3d937713":"code","edb7b721":"markdown","6999894d":"markdown","fa5b02be":"markdown","0608b448":"markdown","4f862c0d":"markdown","7068686a":"markdown","9c77d20f":"markdown","5a5f919d":"markdown","811dd9db":"markdown","eab89b46":"markdown","bff6fbb3":"markdown","0eb0eb40":"markdown","7b032efd":"markdown","322fd9b2":"markdown","0f63763d":"markdown","4456adc1":"markdown","8524417e":"markdown","0b48f299":"markdown","85ef3241":"markdown","9ba2da86":"markdown","d678677f":"markdown","529e8c89":"markdown","070a4669":"markdown","a0d0d284":"markdown","af6b38aa":"markdown"},"source":{"dd6a00ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb49c595":"pip install pycaret[full]","95911e69":"import pandas as pd\nimport numpy as np","ed906f9e":"data=pd.read_csv('\/kaggle\/input\/10k-snapchat-reviews\/Snapchat_app_store_reviews.csv')\n\ndata.head()","51399e39":"data = data.sample(1000, random_state=786).reset_index(drop=True)\ndata.shape","9465b321":"from pycaret.nlp import *","4b11c6a9":"SnapC_1 = setup(data = data, target = 'review', session_id = 123)","01c888f3":"text_list = list(data['review'])\ntype(text_list)","8b4c021d":"SnapC_1_list = setup(data = text_list, session_id = 123)","643579de":"lda = create_model('lda')","6de4f121":"print(lda)","9eba8857":"lda_results = assign_model(lda)\nlda_results.head()","6cd4dc8b":"lda2 = create_model('lda', num_topics = 6, multi_core = True)","36352945":"print(lda2)","17ce62fe":"lda_results = assign_model(lda)\nlda_results.head()","688e91be":"plot_model()","5d14edbf":"plot_model(plot = 'bigram')","b287af77":"plot_model(lda, plot = 'frequency', topic_num = 'Topic 1')","d5cc2e2b":"plot_model(lda, plot = 'topic_distribution')","9e2f2c39":"plot_model(lda, plot = 'tsne')","00eccc0b":"plot_model(lda, plot = 'umap')","4e84fbf0":"evaluate_model(lda)","e7d282b4":"save_model(lda,'Final LDA Model 03Jun2021')","3e50bf44":"saved_lda = load_model('Final LDA Model 03Jun2021')","3d937713":"print(saved_lda)","edb7b721":"**What is Topic Model?**\nIn machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. ","6999894d":"**Installing the PyCaret library**","fa5b02be":"# Let's Evaluate the Model","0608b448":"**Installing other important libraries**","4f862c0d":"# Saving the model","7068686a":"# Getting Started","9c77d20f":"<img src= \"https:\/\/github.com\/skappal7\/Sunil_Kappal_Portfolio\/blob\/main\/Images\/SnapChat%20Review%20Analysis.png?raw=true\" alt =\"SnapChat Analysis\" style='width: 1200px;'>","5a5f919d":"# Let's Create a Topic Model","811dd9db":"# Uniform Manifold Approximation and Projection Plot","eab89b46":"**Let's sample the data**","bff6fbb3":"**convert 'review' column of dataset into list format**","0eb0eb40":"# T-distributed Stochastic Neighbor Embedding (t-SNE)","7b032efd":"This tutorial cum analysis assumes that you are new to PyCaret and looking to perform some basic Natural Language Processing using pycaret.nlp Module.\n\nThis tutorial will help you to understand:\n\n- **Getting Data:** How to import data from PyCaret repository?\n- **Setting up Environment:** How to setup environment in PyCaret and perform critical text pre-processing tasks?\n- **Create Model:** How to create a topic model?\n- **Assign Model:** How to assign documents\/text to topics using a trained model?\n- **Plot Model:** How to analyze topic models \/ overall corpus using various plots?\n- **Save \/ Load Model:** How to save \/ load model for future use?","322fd9b2":"# Loading the Model","0f63763d":"**What is t-SNE?**\n\nT-distributed Stochastic Neighbor Embedding (t-SNE) is a nonlinear dimensionality reduction technique well-suited for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions.","4456adc1":"# Top 100 Bigrams on Reviews","8524417e":"**What is Uniform Manifold Approximation and Projection ?**\n\nUMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimensionality reduction. It is similar to tSNE and PCA in its purpose as all of them are techniques to reduce dimensionality for 2d\/3d projections. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology.","0b48f299":"# Topic Distribution","85ef3241":"Once the setup is succesfully executed it prints the information grid with the following information:\n\n- session_id : A pseduo-random number distributed as a seed in all functions for later reproducibility. If no session_id is passed, a random number is automatically generated that is distributed to all functions. In this experiment session_id is set as 123 for later reproducibility.\n- Documents : Number of documents (or samples in dataset if dataframe is passed).\n- Vocab Size : Size of vocabulary in the corpus after applying all text pre-processing such as removal of stopwords, bigram\/trigram extraction, lemmatization etc.\n\n**Notice that all text pre-processing steps are performed automatically when you execute setup().**\n\nThese steps are imperative to perform any NLP experiment. setup() \n\n*Source: PyCaret*","9ba2da86":"Creating a topic model in PyCaret is simple. A topic model is created using create_model() function which takes one mandatory parameter i.e. name of model as a string. This function returns a trained model object. There are 5 topic models available in PyCaret. see the docstring of create_model() for complete list of models. See an example below where we create Latent Dirichlet Allocation (LDA) model:","d678677f":"# Frequency Distribution of Topic 1","529e8c89":"# What this notebook is all about?","070a4669":"#  Frequency Distribution of Reviews","a0d0d284":"**Let's get the data!**","af6b38aa":"# Let's get the NLP fired up\ud83d\ude80"}}