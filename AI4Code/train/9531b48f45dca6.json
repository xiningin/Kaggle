{"cell_type":{"5a3ad9ba":"code","aa9b7803":"code","169b937a":"code","25d5a94a":"code","009ab478":"code","4f4db377":"code","7e4b908f":"code","7d533736":"code","d86a9ee7":"code","6c877de0":"code","f558d444":"code","2afd0a9b":"code","1baac0c4":"code","980598ce":"code","3489211d":"code","7cf52d09":"code","bdffd4b0":"code","8ce37c56":"code","1abe9aff":"code","9ae85ee6":"code","48d85947":"code","8a247fe4":"code","5e7a1be8":"code","f0a7925a":"code","e7e0b846":"code","62a6b2d6":"code","f40df1a8":"markdown","1ebde84c":"markdown","f2b37ee5":"markdown","8f245245":"markdown","0779c2f2":"markdown","b175477a":"markdown","603e7054":"markdown","ae2d015d":"markdown","6be52515":"markdown","bdd7c9d3":"markdown","058d836b":"markdown","024e21c0":"markdown","aa02cc5d":"markdown","a6f7b187":"markdown","39a908ac":"markdown","23487fdf":"markdown","5fd5fb16":"markdown"},"source":{"5a3ad9ba":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aa9b7803":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as snb","169b937a":"# read csv\ndf = pd.read_csv(\"\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","25d5a94a":"df.head()","009ab478":"df.isnull().sum() # checking missing values","4f4db377":"# get test preparation course values count\ndf['test preparation course'].value_counts()\n","7e4b908f":"mapping = {\"none\" : 0, \"completed\" : 1}\ndf['test preparation course'] = df['test preparation course'].map(mapping)\ndf.head()","7d533736":"import seaborn as sns\nsns.pairplot(df,hue='test preparation course',palette='Set1')","d86a9ee7":"df = pd.get_dummies(df, columns = ['gender', 'race\/ethnicity', 'parental level of education', 'lunch'],drop_first = True)","6c877de0":"df.head()","f558d444":"X= df.drop(\"test preparation course\", axis = 1)\ny = df[\"test preparation course\"]","2afd0a9b":"# split train test data set\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)","1baac0c4":"from sklearn.ensemble import RandomForestClassifier\nRandomForest = RandomForestClassifier(n_estimators = 100, max_features= 10) ","980598ce":"RandomForest.fit(X_Train, y_Train) ","3489211d":"RandomForest.score(X_Train, y_Train)","7cf52d09":"RandomForest.score(X_Test, y_Test)","bdffd4b0":"predictions = RandomForest.predict(X_Test)","8ce37c56":"from sklearn.metrics import classification_report\nprint(classification_report(y_Test,predictions))","1abe9aff":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_Test,predictions)\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); ","9ae85ee6":"n_features = X.shape[1]\nplt.barh(range(n_features),RandomForest.feature_importances_)\nplt.yticks(np.arange(n_features),df.columns[1:])","48d85947":"df.head()","8a247fe4":"df.columns","5e7a1be8":"df[\"mean_grade\"] = (df[\"math score\"] + df[\"reading score\"] + df[\"writing score\"]) \/ 3","f0a7925a":"df[\"math score_squared\"] = df[\"math score\"] * df[\"math score\"]\ndf[\"reading score_squared\"] = df[\"reading score\"] * df[\"reading score\"]\ndf[\"writing score_squared\"] = df[\"writing score\"] * df[\"writing score\"]","e7e0b846":"df.columns","62a6b2d6":"#X= df[['math score', 'reading score','writing score', 'gender_male','mean_grade', 'math score_squared', 'reading score_squared','writing score_squared']]\nX = df.drop(\"test preparation course\", 1)\ny = df[\"test preparation course\"]\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n# split train test data set\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression() \nmodel.fit(X_Train, y_Train) \nprint (model.score(X_Train, y_Train))\nprint (model.score(X_Test, y_Test))","f40df1a8":"* score of the testing data \n","1ebde84c":"**Fit X_Train and y_Train**","f2b37ee5":"1. # Another approach - Logistic Regression and polynomial features","8f245245":"* Turn categorical values of the target into number","0779c2f2":"Looks like the model is not able to generalise very well on unseen data. Let's investigate more evaluation metrics","b175477a":"* classification report of your true labels y_test compared to the predictions","603e7054":"* Read top few rows from the file using the head() method of Pandas.","ae2d015d":"# Categorical data","6be52515":"* score of the training data ","bdd7c9d3":"## Random Forest Classifier","058d836b":"* Check missing values\n* .<code>isnull()<\/code> and <code>sum()<\/code> is used to find whether there are any missing values in the CSV file.","024e21c0":"* plot the pairplot graph of the original dataset using the target 'test preparation course' as the hue of the graph\n","aa02cc5d":"* explore the target","a6f7b187":"# create X and y\n    ","39a908ac":"<p>A random forest is* a meta estimator* that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.<\/p>\n\n<code>n_estimators<\/code> <i>integer, optional (default=10)<\/i>  The number of trees in the forest.<br\/>\n\n","23487fdf":"# Predict Using Random Forest Classifier\n\n\nWe are using scikit-learn Random Forest Classifier to predict, if a particular student has already completed **test preparation course** .\n\n* so given how well they did in the course, we predict if they did the preparation course before doing the course.","5fd5fb16":"# Split train and test "}}