{"cell_type":{"f55024c8":"code","e47cbcb8":"code","5eb64f6e":"code","cc4d0dd6":"code","e2756db5":"code","fa8d1e1d":"code","965762db":"code","2d8227ce":"code","a00a4a6e":"code","51db9dfd":"code","2d9172c0":"code","7b661467":"code","172b5488":"code","fa29a95e":"code","92d17978":"code","ea68a85c":"code","410ea9b4":"code","8ee93eb7":"code","84858d64":"code","f98dbb4f":"code","85400c85":"code","ab9753fd":"code","d3c8b155":"code","024c1971":"code","4ca5a018":"code","6f2d3ef6":"code","9e8a6204":"code","4da36b4f":"code","0bdfe163":"code","953497e7":"markdown","a51f9185":"markdown","e07ad710":"markdown","75117b40":"markdown","d5cc5019":"markdown","5f79cd03":"markdown","3e754ab1":"markdown","a0c9de65":"markdown","e8266e20":"markdown","b2d48e21":"markdown","aa65e892":"markdown","e8f0e754":"markdown","8408d3a8":"markdown","0694cd05":"markdown","86a93668":"markdown","4b2a906b":"markdown","44e581f4":"markdown","ca1b5316":"markdown","89129a54":"markdown","cc281b19":"markdown","16dbf678":"markdown","af566208":"markdown"},"source":{"f55024c8":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e47cbcb8":"data= pd.read_csv(\"..\/input\/neet-tweets-dataset\/neet_data.csv\")","5eb64f6e":"data.head()","cc4d0dd6":"data.tail()","e2756db5":"data.sample(5)","fa8d1e1d":"print(\"Shape of the dataset : \", data.shape)","965762db":"print(\"Column Names : \\n\"+'-'*25)\nprint(data.columns)","2d8227ce":"print(\"Unique values in every column \\n\"+'-'*25)\nfor i in data.columns:\n    print(\"\\t\"+i+\" = \",len(set(data[i])))","a00a4a6e":"data.describe()","51db9dfd":"data.info()","2d9172c0":"data.isnull().sum()","7b661467":"nullCount = ((data.isna().sum() \/ data.shape[0])* 100).reset_index().rename(columns = {\"index\": \"Columns\", 0: \"missing value percentage\"})\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Missing Value percentage\",fontsize=18)\nsns.heatmap(data.isna(),ax=axes[0])\nsns.barplot(nullCount['Columns'],nullCount['missing value percentage'],ax=axes[1])\nplt.xticks(rotation=90)\nplt.show()","172b5488":"# replace nan of user_location with INDIA\ndata['user_location'].fillna('India',inplace=True)\n# replace nan of user_description with NO DESCRIPTION\ndata['user_description'].fillna('No Description',inplace=True)\n#check for all null values\ndata.isnull().sum()","fa29a95e":"data.boxplot()\nplt.xticks(rotation=90)\nplt.show()","92d17978":"# splitting date and time\ndf = data\ndate=[]\ntime=[]\nfor i in data['created_at']:\n    date.append(i.split(' ')[0])\n    time.append(i.split(' ')[1])\ndf['created_on']=date\ndf['created_at']=time\ndf.head(3)","ea68a85c":"try:\n    data.drop('user_url',axis=1,inplace=True)\nexcept:\n    print(\"URL dropped\")","410ea9b4":"hashtags = []\nhashtags_count = []\nperson_tags = []\nperson_tags_count = []\nfor sen in data['tweet']:\n    hashes = []\n    tags = []\n    sen_list = sen.split(' ')\n    for word in sen_list:\n        if len(word)>1:\n            if word[0]=='#':\n                hashes.append(word)\n            if word[0]=='@':\n                tags.append(word)\n    hashtags.append(tuple(hashes))#converted to tuple as tuple is a hashable object\n    person_tags.append(tuple(tags))\n    hashtags_count.append(len(hashes))\n    person_tags_count.append(len(tags))\n      \nlen(person_tags),len(hashtags),len(hashtags_count),len(person_tags_count)","8ee93eb7":"df['tagged_persons'] = tuple(person_tags)\ndf['hashtags'] = tuple(hashtags)\ndf['hashtags_count'] = hashtags_count\ndf['tagged_persons_count'] = person_tags_count\ndf.head(5)","84858d64":"print(\"Our dataset has {} persons tagged\".format(df['tagged_persons_count'].sum()))\nprint(\"In our dataset users used {} hashtags \".format(df['hashtags_count'].sum()))","f98dbb4f":"df = df[[ 'user_id', 'user_name','user_description', 'user_follower_count', 'user_friends_count',\n              'user_location', 'user_verified', 'tweet', 'length_of_tweet', 'retweet_count', 'source',\n              'created_at',  'created_on', 'tagged_persons', 'hashtags', 'hashtags_count',\n              'tagged_persons_count']]","85400c85":"df.head(3)","ab9753fd":"print(\"The new shape of our Data is : \",df.shape)","d3c8b155":"hashData = df.hashtags.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Trending Hashtags Used\",fontsize=18)\nsns.barplot(data = hashData , y='index',x='hashtags')\nplt.show()","024c1971":"tagData = df.tagged_persons.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Most Tagged Persons\",fontsize=18)\nsns.barplot(data = tagData , y='index',x='tagged_persons')\nplt.show()","4ca5a018":"df = data.user_location.value_counts()[:3].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Most Common Locations \",fontsize=18)\nsns.lineplot(x=df[\"index\"], y = df[\"user_location\"],ax=axes[1]) \nsns.barplot(y=df[\"index\"], x = df[\"user_location\"],ax=axes[0]) \nplt.xticks(rotation=90)\nplt.show()","6f2d3ef6":"fig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Verified Users \",fontsize=18)\nexplode = (0.4, 0)\nsns.countplot(data[\"user_verified\"],ax=axes[1])\ndata['user_verified'].value_counts().plot.pie(explode=explode,shadow=True, startangle=90,ax=axes[0])\nplt.show()","9e8a6204":"retweeted=[]\nfor i in data.retweet_count:\n    if i>0:\n        retweeted.append('Retweeted')\n    else:\n        retweeted.append('Not Retweeted')\n\nretweeted=pd.Series(retweeted)\nuniq = data.retweet_count.unique()\nuniq","4da36b4f":"fig,axes = plt.subplots(1,2,figsize=(15,5))\nplt.suptitle(\" Retweeted Counts \",fontsize=18)\nretweeted.value_counts().plot.pie(explode=(0.2,0),shadow=True, startangle=90,ax=axes[0])\nplt.pie(data.retweet_count.value_counts(),startangle=30, shadow=True)\nplt.show()","0bdfe163":"df = data.source.value_counts()[:7].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Common Sources Used by Users \",fontsize=18)\nsns.barplot(y=df[\"index\"], x = df[\"source\"],ax=axes[0]) \nsns.lineplot(x=df[\"index\"], y = df[\"source\"],ax=axes[1]) \nplt.xticks(rotation=90)\nplt.show()","953497e7":"# 2. Read Files & Basic insights","a51f9185":"## If You Like The Kernel Do Not Forget To Upvote And Add your Comments. \n# THANK YOU :D","e07ad710":"# 3. Preprocessing & Analysis","75117b40":"## 2.2 Basic Insights","d5cc5019":"## 3.2 Imputation And Arranging","5f79cd03":"# Overview \n\n## Dataset consists of 14 columns :\n\n* 'id': Id of the tweet posted\n* 'created_at': Date and Time of the tweet posted\n* 'retweet_count': Count of how many times the same tweet is re-tweeted.\n* 'source': From which platform the tweet was posted\n* 'user_id': Id of the user posting the tweet\n* 'user_name': Name of the user posting the tweet\n* 'user_description': Description of the user posting the tweet\n* 'userfollowercount': Count of how many followers does the user have\n* 'userfriendscount': Count of how many friends does the user have\n* 'user_location': Location from where the user posted the tweet\n* 'user_verified': Is the user verified by Twitter or not\n* 'user_url': URL of the user's profile\n* 'tweet': Tweet posted by user\n* 'lengthoftweet': The total length of the tweet posted by the user ( words ).\n\n## Steps I used in this kernel :\n> ### 1.Import libraries\n> ### 2.Read Files & Basic insights\n> ### 3.Preprocessing And Analysis\n> ### 4.Data Visualization\n> ### 5.Conclusion","3e754ab1":"### Inference :-\n#### Most of the users are from India and preffered not to provide more detail about their location. ","a0c9de65":"# 5. CONCLUSION\n*  The data do not have much outliers.\n*  Users prefer to leave their descriptive information as the data has a lot of missing values in some columns(descriptive columns)\n*  Most of the users are from India and a few from other countries too.\n*  Most of the users posting on #NEET are not verified by Twitter.\n*  People prefer posting from Android devices followed by Twitter Web App and then the rest applications.\n*  The tweets posted has 203 persons tagged and users used 62 hashtags. \n*  Most tagged person is @neet_gill and most used hashtag is NEET.","e8266e20":"### References: \n#### https:\/\/www.kaggle.com\/sudarshanpatil\/ipl-tweets-eda\n#### https:\/\/seaborn.pydata.org\/     ,     https:\/\/towardsdatascience.com\/exploratory-data-analysis-in-python-c9a77dfa39ce","b2d48e21":"# 1. Import Libraries","aa65e892":"#### Lets drop user_url as it has many missing values and also not very useful","e8f0e754":"* Last 5 Rows","8408d3a8":"* So we do not have much outliers in our data.","0694cd05":"* First 5 Rows","86a93668":"* Random 5 Rows","4b2a906b":"# 4. Data Visualization ","44e581f4":"### Inference :- \n#### Very few users who are posting on #NEET are verified by Twitter.  ","ca1b5316":"* Now lets have a look on hashtags and the persons tagged in the tweet.","89129a54":"### INFERENCE : \n#### user_url(\\~61%) has the most number of missing values followed by user_location(\\~36%) and user_description(\\~19%)","cc281b19":"## 3.1 Clearing Null Values","16dbf678":"### Inference :-\n#### A major part of sources of posting tweet is from Android followed by Twitter Web App and then the rest.\n","af566208":"## 2.1 Read CSV Files "}}