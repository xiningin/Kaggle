{"cell_type":{"762406cc":"code","3ce2004e":"code","a1684e21":"code","b9a2471d":"code","60468cc9":"code","92c07516":"code","e03a2a8f":"code","b4b22842":"code","d02b7b37":"code","ab74ca6b":"code","e110f141":"code","ea9ab020":"code","b34027c2":"code","d27741d2":"code","b9bdb839":"code","4344586f":"code","ffc6eb1d":"code","15857bf3":"code","1bffc842":"code","1b863df4":"code","7b3ebf71":"code","b25385b4":"code","925e1e80":"code","6763d167":"code","23b2f5b1":"code","959284d9":"code","ac17798e":"markdown","899a9394":"markdown","4e99afbd":"markdown","faff1fa5":"markdown","c7cc5598":"markdown","a036c4b9":"markdown","0915feb7":"markdown","be07af97":"markdown","eff6687f":"markdown","efd34af0":"markdown","8b3716d3":"markdown"},"source":{"762406cc":"!pip install -U yarl","3ce2004e":"import os\nimport yarl\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom collections import Counter\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt","a1684e21":"count_f = 0\nframes = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in sorted(filenames):\n        if filename.endswith('.tsv'):\n            fname = os.path.join(dirname, filename)\n            df = pd.read_csv(fname, sep='\\t')\n            frames.append(df)\n            print(\"%4i\"%count_f, \"|\", \"%6i\"%len(df), fname.split('\/')[-1])\n            count_f+=1","b9a2471d":"DATA = pd.concat(frames)\nlen(DATA)","60468cc9":"DATA.sample(n=min(len(DATA),5))","92c07516":"exclude_urls = ['reddit.','redd.','youtube','youtu.','twitter','facebook','fb','google.','.mp3','.pdf','\/r\/','imgur.']\nexclude_urls","e03a2a8f":"submission_datetime = []\nurl_hosts = []\nfor created_utc, url in DATA[['created_utc','url']].values.tolist():\n    datetime = dt.datetime.fromtimestamp(int(created_utc))\n    submission_datetime.append(datetime)\n    try:\n        S = set([x in url for x in exclude_urls])\n        if len(S)==1 and not True in S:\n            url = yarl.URL(url)\n            url_hosts.append(url.host)\n    except:\n        print(url)\nprint(len(submission_datetime), len(url_hosts), min(submission_datetime), max(submission_datetime), sep='\\n')","b4b22842":"TOP_N_URL_HOSTS = 25\n\nC = Counter(url_hosts)\nfor count_u, (url_host, count_host) in enumerate(sorted(C.items(), key=itemgetter(1), reverse=True)):\n    print(\"%6i\"%count_host, url_host)\n    if count_u>=TOP_N_URL_HOSTS:\n        break","d02b7b37":"DATA['date'] = DATA.apply(lambda row: dt.date.fromtimestamp(int(row.created_utc)), axis=1)","ab74ca6b":"D = DATA[['id','date']].groupby('date').count().sort_values('date', ascending=True)\nX, X_label, Y = [], [], []\nfor count_d, (date, count_id) in enumerate(zip(D.index, D.id)):\n    X.append(count_d)\n    Y.append(count_id)\n    X_label.append(date.strftime('%Y-%m-%d'))\nlen(X), len(Y), len(X_label)","e110f141":"[i for i in range(len(X_label))][::7]","ea9ab020":"plt.figure(figsize=(15,6))\nplt.scatter(X, Y)\nplt.plot(X, Y)\nfor w in [i for i in range(len(X_label))][::7]:\n    plt.vlines(w, min(Y)-0.1*max(Y), max(Y)+0.1*max(Y), color='k', alpha=0.25)\nplt.xticks([i for i in range(len(X_label))][::7], X_label[::7], rotation=60)\nplt.xlim(-1,len(X)+1)\nplt.ylim(0, max(Y)+0.1*max(Y))\nplt.title(\"News Articles submitted to \/r\/Coronavirus per Day\")\nplt.xlabel('date')\nplt.ylabel('submission count')\nplt.show()","b34027c2":"counts_per_hour_of_weekday = np.zeros((7,24)) # weekdays * hours in a day\nweekdays = dict()\nfor created_utc in DATA.created_utc.values.tolist():\n    current_datetime = dt.datetime.fromtimestamp(int(created_utc))\n    wd = current_datetime.weekday()\n    h = current_datetime.hour\n    counts_per_hour_of_weekday[wd,h]+=1\n    weekdays[wd] = current_datetime.strftime('%A')\nprint(counts_per_hour_of_weekday.shape)\nprint(weekdays)","d27741d2":"plt.figure(figsize=(14,6))\nplt.imshow(counts_per_hour_of_weekday)\nplt.yticks([k for k, v in weekdays.items()], [v for k, v in weekdays.items()])\nplt.xticks([i for i in range(counts_per_hour_of_weekday.shape[1])], [i for i in range(counts_per_hour_of_weekday.shape[1])])\nplt.ylabel('Day of the Week')\nplt.xlabel('Hour of the Day')\nplt.title('\/r\/Coronavirus submissions by hour of the day!')\nplt.show()","b9bdb839":"!git clone https:\/\/github.com\/COVIEWED\/coviewed_web_scraping","4344586f":"!pip install -r coviewed_web_scraping\/requirements.txt","ffc6eb1d":"#EXAMPLE_URL = DATA[['url']].sample(n=1).url.values.tolist()[0]\nEXAMPLE_URL = 'https:\/\/edition.cnn.com\/2020\/03\/04\/health\/debunking-coronavirus-myths-trnd\/'\nprint(EXAMPLE_URL)","15857bf3":"!echo {EXAMPLE_URL}","1bffc842":"!rm coviewed_web_scraping\/data\/*.txt","1b863df4":"!cd coviewed_web_scraping\/ && python3 src\/scrape.py -u={EXAMPLE_URL}","7b3ebf71":"!ls coviewed_web_scraping\/data\/*.txt","b25385b4":"data_path = 'coviewed_web_scraping\/data\/'\nfname = [f for f in os.listdir(data_path) if f.endswith('.txt')][0]\nwith open(os.path.join(data_path, fname), 'r') as my_file:\n    txt_data = my_file.readlines()\ntxt_data = [line.strip() for line in txt_data if line.strip()]\nlen(txt_data)","925e1e80":"article_url = txt_data[0]\nprint(article_url)\narticle_published_datetime = txt_data[1]\nprint(article_published_datetime)","6763d167":"article_title = txt_data[2]\nprint(article_title)","23b2f5b1":"article_text = \"\\n\\n\".join(txt_data[3:])\nprint(article_text)","959284d9":"print('List of claims from the article:', end='\\n\\n')\nfor row in article_text.splitlines():\n    if row.strip() and 'Myth:' in row:\n        print(row.strip()[len('Myth: '):])","ac17798e":"### What is the goal of Project [COVIEWED](https:\/\/www.coviewed.org\/)?\n\nProject [COVIEWED](https:\/\/www.coviewed.org\/)'s aim is to fight against misinformation on the web regarding the recent coronavirus pandemic \/ covid-19 outbreak. \n\nTo achieve this, we collect different types of claims from web sources with supporting or attacking evidence. \n\nThis information is used to train a machine learning classifier. \n\nOnce trained, we plan to release a browser extension that highlights potential true\/false claims on a web page to assist users in their information gathering process.","899a9394":"# Project Overview","4e99afbd":"---","faff1fa5":"---","c7cc5598":"---","a036c4b9":"### Organization\n\nWe have a public [Trello Board](https:\/\/trello.com\/invite\/b\/jk00CW3u\/9985740815b585156aaa22978a3067df\/project-coviewed) and our project is completely open source and available on [Github](https:\/\/github.com\/COVIEWED).","0915feb7":"---","be07af97":"# Top Domains by Submissions","eff6687f":"# Example: Load a News Article","efd34af0":"# First Look: Submission Data","8b3716d3":"# Plot Submission Count by Day"}}