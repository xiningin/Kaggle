{"cell_type":{"c0354797":"code","b9998f5f":"code","8aacda4e":"code","d1f7569e":"code","16c2c3ca":"code","8d61357c":"code","4edb0156":"code","06eb2617":"code","37ae5ace":"code","8f67d220":"code","c93305c2":"code","7572a0f0":"code","8ba5c554":"code","983c88b9":"code","48ae298c":"code","02a189fb":"code","917ab833":"code","bee9d2cc":"code","7e1f896d":"code","a1430938":"code","15197607":"code","158931f0":"code","105896f0":"code","274a4b09":"code","64f060aa":"code","01fd0471":"code","f82e8d19":"code","90592751":"code","b5350ce4":"code","30a0e291":"code","9dd957df":"code","678aea80":"code","16f29449":"code","84ba56c8":"code","6f6489f5":"code","184692c8":"code","6da60f70":"code","dbb8c87b":"code","174e82fc":"code","a5184ba7":"code","1c006b82":"code","3b2c52c7":"code","dbc104a8":"code","7ea98cc9":"code","16a41cf4":"code","2fa8df21":"code","70cdb908":"code","f1ad71fd":"code","dc6ad711":"code","5a1c39db":"code","867c6cab":"code","ad5d07b3":"code","76eb8f76":"code","197c7685":"code","7dae52d9":"code","5dbd05bc":"code","d287164c":"code","e3178916":"code","9026482f":"code","bb0f9bc0":"markdown","42c4b65c":"markdown","c57a9351":"markdown","496feab1":"markdown","a20444f5":"markdown","6832d028":"markdown","09430430":"markdown","7ca10141":"markdown","e9a651b4":"markdown","8cdaa605":"markdown"},"source":{"c0354797":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9998f5f":"cd \/kaggle\/input\/titanic\/","8aacda4e":"from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, LabelEncoder\nfrom pandas import get_dummies\nfrom sklearn import preprocessing\nfrom sklearn.svm import SVC\nimport scipy.optimize as opt\nimport pymc3 as pm\nimport pylab as pl\nimport numpy as np\nimport pandas as pd","d1f7569e":"%matplotlib inline","16c2c3ca":"t_train = pd.read_csv('train.csv')\ngender = pd.read_csv('gender_submission.csv')\nt_test_start = pd.read_csv('test.csv')\n#It seems that the names might be backwards ... maybe","8d61357c":"#I assum SibSp stands for Sibling-Spouse accompannying\n#Pclass and Fare are both proxies for wealth - it seems to me.\n#There could plausibly be a relationship between Survival and Cabin\n#I do not know how to read 'Ticket'\n#Survivorship Bias is inapplicable here because Survival is itself the question","4edb0156":"ohe = OneHotEncoder()\nlb = LabelBinarizer()\nle = LabelEncoder\n#gd = get_dummies()","06eb2617":"t_train.drop(columns={'PassengerId','Name','Cabin','Parch','Ticket','Embarked'}, inplace=True)","37ae5ace":"#Put this whole section into the posterior search space section\n#gender\n#t_train.rename({'PassengerId':'Id'}, inplace=True)\n#gender.rename({'PassengerId':'Id'}, inplace=True)\n#t_test = t_test_start.join(gender, lsuffix='Id', rsuffix='Id')\n#t_test.drop(columns={'PassengerIdId', 'Name', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'PassengerIdId'}, inplace=True)\n#t_test = pd.get_dummies(t_test, drop_first=True)\n#t_test.rename({'Sex_male':'Male'}, inplace=True)","8f67d220":"t_train = pd.get_dummies(t_train, drop_first=True)\nt_train.rename(columns={'Sex_male':'Sex'}, inplace=True)","c93305c2":"t_train.head()","7572a0f0":"#ax = t_train[t_train['Survived']== 4[0:50].plot(kind='scatter',x='Sex',y='Survived', color='Blue', label='died')];\n#t_train[t_train['Survived']== 20[0:50].plot(kind='scatter', x='Sex', y='Survived', color='Yellow', label='survived', ax=ax)];\n#plt.show()\n#error TypeError:'int' object is not subscriptable","8ba5c554":"formula = 'Survived ~ Sex + Pclass + Age + SibSp + Fare'","983c88b9":"#I am one-hundred percent positive that I need to change the priors \n#it keeps getting overloaded and crashing...maybe...","48ae298c":"# Context for the model - Shockling, it does not look like Uniform is here... which is a Maximum Ignorance Prior\n#I seems that Binomial is appropriate, since a\n#negative binomial models survivorship though doesn't it\n\n# Context for the model\nwith pm.Model() as normal_model:\n    \n    # The prior for the data likelihood is a Normal Distribution\n    family = pm.glm.families.Normal()\n    \n    # Creating the model requires a formula and data (and optionally a family)\n    pm.GLM.from_formula(formula, data = t_train, family = family)\n    \n    # Perform Markov Chain Monte Carlo sampling letting PyMC3 choose the algorithm\n    normal_trace = pm.sample(draws=500, chains = 2, tune = 500)","02a189fb":"# Context for the model - Shockling, it does not look like Uniform is here... which is a Maximum Ignorance Prior\n#I seems that Binomial is appropriate, since a\n#negative binomial models successes ..\n#It seemed like this was breaking because the posterior search was taking up too much memory...\n\n# Context for the model\nwith pm.Model() as normal_model:\n    \n    # The prior for the data likelihood is a Normal Distribution\n    family = pm.glm.families.Normal()\n    \n    # Creating the model requires a formula and data (and optionally a family)\n    pm.GLM.from_formula(formula, data = t_train, family = family)\n    \n    # Perform Markov Chain Monte Carlo sampling letting PyMC3 choose the algorithm\n    normal_trace = pm.sample(draws=2000, chains = 2, tune = 500)","917ab833":"#I am  a little surprised by how formula works","bee9d2cc":"#dir(pm.glm)  != dir(pm.GLM) \n#confused for a sec, not forever though","7e1f896d":"pm.traceplot(normal_trace)","a1430938":"pm.plot_posterior(normal_trace)","15197607":"pm.df_summary(normal_trace)","158931f0":"#titanic_testing.head()\n#gender.head()\n#reverse engineer the following ... ","105896f0":"# Examines the effect of changing a single variable\n# Takes in the name of the variable, the trace, and the data\ndef model_effect(query_var, trace, X):\n    \n    # Variables that do not change\n    steady_vars = list(X.columns)\n    steady_vars.remove(query_var)\n    \n    # Linear Model that estimates a grade based on the value of the query variable \n    # and one sample from the trace\n    def lm(value, sample):\n        \n        # Prediction is the estimate given a value of the query variable\n        prediction = sample['Intercept'] + sample[query_var] * value\n        \n        # Each non-query variable is assumed to be at the median value\n        for var in steady_vars:\n            \n            # Multiply the weight by the median value of the variable\n            prediction += sample[var] * X[var].median()\n        \n        return prediction\n    \n    figsize(6, 6)\n    \n    # Find the minimum and maximum values for the range of the query var\n    var_min = X[query_var].min()\n    var_max = X[query_var].max()\n    \n    # Plot the estimated grade versus the range of query variable\n    pm.plot_posterior_predictive_glm(trace, eval=np.linspace(var_min, var_max, 100), \n                                     lm=lm, samples=100, color='blue', \n                                     alpha = 0.4, lw = 2)\n    \n    # Plot formatting\n    plt.xlabel('%s' % query_var, size = 16)\n    plt.ylabel('Grade', size = 16)\n    plt.title(\"Posterior of Grade vs %s\" % query_var, size = 18)\n    plt.show()","274a4b09":"#plug, the degrees of relatedness into the original Survivor Equation to update its accuarcy","64f060aa":"###create an interactive section where in a user can figure out how likely tehy are to survive\n","01fd0471":"X_train = titanic_train[['Pclass', 'Sex', 'Age']]\ny_train = titanic_train[['Survived']]","f82e8d19":"X_train = gd(X_train, columns=['Sex'])","90592751":"X_train.drop(columns='Sex_female', inplace=True)\nX_train.rename(columns={'Sex_male':'Sex'}, inplace=True)","b5350ce4":"missing = X_train.isna().sum()\nprint(missing)","30a0e291":"X_train[['Age']].mean()","9dd957df":"X_train.fillna(value='26.7', inplace=True)","678aea80":"X_train.isin([np.inf, -np.inf]).sum()","16f29449":"y_train.isna().sum()\ny_train.isin([np.inf, -np.inf]).sum()","84ba56c8":"model = svc.fit(X_train, y)","6f6489f5":"titanic_testing.head()","184692c8":"X_test = titanic_testing[['Pclass', 'Sex', 'Age']]\ny_test = titanic_testing[['Survived']]","6da60f70":"X_test.head()","dbb8c87b":"X_test = gd(X_train, columns=['Sex'])","174e82fc":"X_test.head()\nX_test.drop(columns='Sex_0', inplace=True)\nX_test.rename(columns={'Sex_1':'Sex'}, inplace=True)","a5184ba7":"missing = X_test.isna().sum()\nprint(missing)","1c006b82":"X_test[['Age']].mean()","3b2c52c7":"X_test.fillna(value='26.7', inplace=True)","dbc104a8":"X_test.isin([np.inf, -np.inf]).sum()","7ea98cc9":"y_test.isna().sum()\ny_test.isin([np.inf, -np.inf]).sum()","16a41cf4":"y_hat = svc.predict(X_test)","2fa8df21":"'Visualizing Data is still very difficult for me'","70cdb908":"from sklearn.metrics import classification_report, confusion_matrix","f1ad71fd":"conf_mat = confusion_matrix(y_test, y_hat[:418])","dc6ad711":"np.set_printoptions(precision=4)","5a1c39db":"print(classification_report(y_test, y_hat[:418]))","867c6cab":"#According to the movie, class, Sex, age and Fare will be very strongly predictive of survival (sadly)\n#I can look and see if Cabin and\/or Ticket does - it don't know in advance\n# I do not know what Embarked, SibSp, Parch mean\n#PassengId will *not* affect survivorship","ad5d07b3":"#My code and designs still aren't eloquent but I am getting there.","76eb8f76":"#This is the first time that import all of these modules\n#I am seeing that they need to be reinstalled in each new Notebook\n%pip install ppscore \n#%pip install bamboolib\n#%pip install widgets\n#!pip install pandleau\n","197c7685":"import ppscore as pps","7dae52d9":"import seaborn as sns\ndf_matrix = pps.matrix(df)\nsns.heatmap(df_matrix, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)","5dbd05bc":"#My notebooks are requiring a very large amount of tinkering\n#I don't even remember what I was trying to do here\n#X_train = np.nan_to_num(X_train)\n#y_train = np.nan_to_num(y_train)\n#X_test = np.nan_to_num(X_test)\n#y_test = np.nan_to_num(y_test)\n\n#y_train = y_train.ravel()\n#y_test = y_test.ravel()","d287164c":"\"\"\"pps.score(df, \"x\", \"y\")\npps.matrx(df)\"\"\"","e3178916":"#Apparently this little bit of code is too tricky for me to reverse-engineer from online","9026482f":"\"\"\"df = pd.DataFrame()\n\ndf[\"x\"] = np.random.uniform(-2, 2, 1_000_000)\ndf[\"error\"] = np.random.uniform(-0.5, 0.5, 1_000_000)\ndf[\"y\"] = df[\"x\"] * df[\"x\"] + df[\"error\"]\"\"\"","bb0f9bc0":"Data Preparation","42c4b65c":"**Notebook Notes**","c57a9351":"It kept crashing so I narrowed down the parameters so it didn't have to do so super many computations.","496feab1":"**Visualize the Data**","a20444f5":"**Fit the Model**","6832d028":"**Confusion Matrix: Testing the Goodness of Fit**","09430430":"**Priors Clearly Stated**\n\nMy understanding was that the evacuation priority was strictly: wealthy women and children, poor women and children, wealthy men, poor men, faculty and staff","7ca10141":"**Show Resulting Posterior Probabilities**","e9a651b4":"Test the Goodness of Fit","8cdaa605":"The above is where I download the noted packages for the first time"}}