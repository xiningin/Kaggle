{"cell_type":{"045e4342":"code","3547b8f1":"code","2c10d1bf":"code","7c69adb2":"code","d4534f9f":"code","d3597fbd":"code","c50cde95":"code","9a5f8e77":"code","aa8612f2":"code","344f9e28":"code","b28bd531":"code","c4f828be":"code","18da37fa":"code","ce093795":"code","20f3d3c7":"code","25812200":"code","685aadef":"code","dba8e2df":"code","d4f8a252":"code","f256f2fa":"code","5e2f7c19":"code","2f9706d3":"code","68b7b962":"code","abc90652":"code","5a91f82b":"code","f2bd8ef1":"code","1872d1ac":"code","0047e58e":"code","c0ed4785":"code","5834c880":"code","6bab3f6c":"code","e875e914":"code","61652df1":"code","3a9c3d8d":"code","454bafdd":"code","5270a7a4":"code","c517c6f6":"code","2d172118":"code","3cfddff5":"code","27af46f5":"code","616763e4":"code","a5964b06":"code","dd349991":"code","195ae20a":"code","cad280ab":"code","eed50be0":"code","22953d47":"code","e76ed3d8":"code","4e7d62a3":"code","42716963":"code","67dfcb7f":"code","22c174e7":"code","f5dc84ab":"code","d7796faa":"code","6f8441e9":"code","ecdfd430":"code","7ad5ac79":"code","fe46f638":"markdown","5e928646":"markdown","d79759b4":"markdown","de55e91a":"markdown","0f06a17d":"markdown","205082b2":"markdown","86e21e04":"markdown","f1b02d2b":"markdown","21cdd110":"markdown","66915933":"markdown"},"source":{"045e4342":"# Importando as bibliotecas necess\u00e1rias para o c\u00f3digo\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC\nimport math\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\npd.options.mode.chained_assignment = None\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3547b8f1":"#Trazendo os dados de uma planilha csv extra\u00edda do banco de dados da For\u00e7a.\ndf = pd.read_csv(\"..\/input\/lotacao\/LOTACAO.csv\",sep=',',low_memory=False)\ndf","2c10d1bf":"df['orgcomandada'].nunique()\n","7c69adb2":"df['quadro'].nunique()\n","d4534f9f":"df = df[df.groupby('orgcomandada').orgcomandada.transform(len) > 1]","d3597fbd":"#verifica se os dados est\u00e3o equilibrados\ndf.temvaga.value_counts(normalize=True)","c50cde95":"sns.countplot(x = 'temvaga',data = df, palette = 'hls')\nplt.show()\nplt.savefig('count_plot')","9a5f8e77":"%matplotlib inline\npd.crosstab(df.orgcomandada,df.temvaga).plot(kind='bar')\nplt.title('Presen\u00e7a de vaga por tipo de organiza\u00e7\u00e3o')\nplt.xlabel('Organiza\u00e7\u00e3o')\nplt.ylabel('Vaga')\nplt.savefig('existe_vaga_om')","aa8612f2":"%matplotlib inline\npd.crosstab(df.ano,df.temvaga).plot(kind='bar')\nplt.title('Presen\u00e7a de vaga por ano')\nplt.xlabel('Ano')\nplt.ylabel('Vaga')\nplt.savefig('existe_vaga_om')","344f9e28":"%matplotlib inline\npd.crosstab(df.posto,df.temvaga).plot(kind='bar')\nplt.title('Presen\u00e7a de vaga por posto')\nplt.xlabel('Posto')\nplt.ylabel('Vaga')\nplt.savefig('existe_vaga_om')","b28bd531":"%matplotlib inline\npd.crosstab(df.quadro,df.temvaga).plot(kind='bar')\nplt.title('Presen\u00e7a de vaga por tipo de quadro')\nplt.xlabel('Quadro')\nplt.ylabel('Vaga')\nplt.savefig('existe_vaga_quadro')","c4f828be":"df.describe()","18da37fa":"df.dtypes","ce093795":"X, y = df.iloc[:,:-1], df.iloc[:,-1:]","20f3d3c7":"X","25812200":"y","685aadef":"data = df\ndata","dba8e2df":"cat_vars=['orgcomandada', 'quadro', 'posto']\nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(data[var], prefix=var)\n    data1=data.join(cat_list)\n    data=data1\ncat_vars=['orgcomandada', 'quadro', 'posto']\ndata_vars=data.columns.values.tolist()\nto_keep=[i for i in data_vars if i not in cat_vars]","d4f8a252":"data_final=data[to_keep]\ndata_final.columns.values","f256f2fa":"os_x = data_final.loc[:, data_final.columns != 'temvaga']\nos_y = data_final.loc[:, data_final.columns == 'temvaga']\nfrom imblearn.over_sampling import SMOTE\nos = SMOTE(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(os_x, os_y, test_size=0.3, random_state=0)\ncolumns = X_train.columns\nos_data_X,os_data_y=os.fit_sample(X_train, y_train)\nos_data_X = pd.DataFrame(data=os_data_X,columns=columns )\nos_data_y= pd.DataFrame(data=os_data_y,columns=['temvaga'])\n# we can Check the numbers of our data\nprint(\"length of oversampled data is \",len(os_data_X))\nprint(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['temvaga']==0]))\nprint(\"Number of subscription\",len(os_data_y[os_data_y['temvaga']==1]))\nprint(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['temvaga']==0])\/len(os_data_X))\nprint(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['temvaga']==1])\/len(os_data_X))","5e2f7c19":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nos_x=os_data_X\nos_y=os_data_y['temvaga']\nX_train, X_test, y_train, y_test = train_test_split(os_x, os_y, test_size=0.3, random_state=0)\nlogreg = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=500)\nlogreg.fit(X_train, y_train)","2f9706d3":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","68b7b962":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","abc90652":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","5a91f82b":"X_pre = pd.get_dummies(df.iloc[:,:-1],drop_first=True)\nX_pre","f2bd8ef1":"y = df.iloc[:,-1:]\ny = y.values.ravel()","1872d1ac":"from sklearn.tree import DecisionTreeClassifier, plot_tree","0047e58e":"from matplotlib import pyplot as plt\nfrom sklearn import tree\nclf = DecisionTreeClassifier(max_depth=3).fit(X_pre, y)\nfig, ax = plt.subplots(figsize=(30,10))\nout = tree.plot_tree(clf, filled=True, rounded = True, fontsize=20, feature_names=X_pre.columns)\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor('black')\n        arrow.set_linewidth(3)","c0ed4785":"X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size=0.3,\n                                                    random_state=42)","5834c880":"from sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier,     ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nrandom_state = 2\nclassifiers = [\n    GaussianNB(),\n    LogisticRegression(C=1, solver='lbfgs', multi_class='auto',max_iter=500),\n    KNeighborsClassifier(n_neighbors=3),\n    KNeighborsClassifier(n_neighbors=5),\n    DecisionTreeClassifier(random_state=3),\n    RandomForestClassifier(random_state=3),\n    AdaBoostClassifier(random_state=3),\n    ExtraTreesClassifier(random_state=3),\n    GradientBoostingClassifier(random_state=3),\n]\naccuracy_res = []\nalgorithm_res = []\nfor clf in classifiers:\n    # clf.fit(features_train, labels_train)\n    # Added ravel to convert column vector to 1d array\n    clf.fit(X_train, y_train.ravel())\n    name = clf.__class__.__name__\n\n    train_predictions = clf.predict(X_test)\n\n    accuracy = accuracy_score(y_test, train_predictions)\n    print(name, \"{:.4%}\".format(accuracy))\n    accuracy_res.append(accuracy)\n    algorithm_res.append(name)\n    print()\n\ny_pos = np.arange(len(algorithm_res))\nplt.barh(y_pos, accuracy_res, align='center', alpha=0.5)\nplt.yticks(y_pos, algorithm_res)\nplt.xlabel('Accuracy')\nplt.title('Algorithms')\nplt.show()","6bab3f6c":"import numpy as np\n(unique, counts) = np.unique(y_test, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\n\nprint(frequencies)","e875e914":"import numpy as np\n(unique, counts) = np.unique(y_train, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\n\nprint(frequencies)","61652df1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","3a9c3d8d":"enc = OneHotEncoder().fit(X)","454bafdd":"log_reg = LogisticRegression(random_state=0,max_iter=1000).fit(X=enc.transform(X_train), y=y_train)","5270a7a4":"log_reg.score(enc.transform(X_test), y_test)","c517c6f6":"from sklearn import metrics\nmetrics.f1_score(y_test, log_reg.predict(enc.transform(X_test)), average='weighted')","2d172118":"from sklearn.metrics import plot_confusion_matrix\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nfig, ax = plt.subplots(figsize=(7, 7))\nplot_confusion_matrix(log_reg, enc.transform(X_test), y_test,values_format='d', ax=ax)","3cfddff5":"X_pre = pd.get_dummies(df.iloc[:,:-1])\nX_pre","27af46f5":"X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size=0.3,\n                                                    random_state=42)","616763e4":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(\n    StandardScaler(), \n    LogisticRegression(solver='lbfgs', multi_class='auto', random_state=123,max_iter=500)\n)","a5964b06":"pipe.fit(X_train, y_train)","dd349991":"pipe.score(X_test, y_test)","195ae20a":"y = df.temvaga\nreg_log = LogisticRegression(solver='lbfgs', random_state=123,max_iter=500)\ncross_val_score(reg_log, X_pre, y, cv=5, scoring='accuracy').mean()","cad280ab":"X_train = X_train.reset_index(drop=True)\nX_train.T","eed50be0":"y_train","22953d47":"X_test = X_test.reset_index(drop=True)\nX_test.T","e76ed3d8":"y_test","4e7d62a3":"columns = X_pre.columns\ncolumns","42716963":"# Simulando dado manual de teste de predi\u00e7\u00e3o 1\nano = [2018]\norg = [1, 0, 0]\nquad = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\npost = [0, 0, 0, 0, 1]\ndata = np.concatenate ([ano,org,quad,post])\ndata","67dfcb7f":"new_test = pd.DataFrame(data,index=columns)\nnew_test = new_test.T\nnew_test","22c174e7":"pipe.predict(new_test)","f5dc84ab":"# Simulando dado manual de teste de predi\u00e7\u00e3o 2\nano = [2016]\norg = [0, 0, 1]\nquad = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\npost = [0, 0, 0, 1, 0]\ndata2 = np.concatenate ([ano,org,quad,post])\ndata2","d7796faa":"new_test2 = pd.DataFrame(data2,index=columns)\nnew_test2 = new_test2.T\nnew_test2","6f8441e9":"pipe.predict(new_test2)","ecdfd430":"# Teste de predi\u00e7\u00e3o com sample autom\u00e1tico \nnovo_X = X_test.sample(30, random_state=42)\nnovo_X = novo_X.reset_index(drop=True)\nnovo_X.T","7ad5ac79":"x = np\npipe.predict(novo_X)","fe46f638":"X_train.dtypes","5e928646":"**Coletando os dados novamente, para gerar a matriz de confus\u00e3o:**","d79759b4":"# Predi\u00e7\u00e3o de Vagas para Lota\u00e7\u00e3o de Pessoal","de55e91a":"- Distribui\u00e7\u00e3o dos servidores nos \u00f3rg\u00e3os do Comando da Aeron\u00e1utica a partir da Tabela de Lota\u00e7\u00e3o de Pessoal (TLP) \n- Limita os campos de organiza\u00e7\u00e3o, quadro e posto","0f06a17d":"**Utiliza o m\u00e9todo SMOTE para equilibrar os dados e a curva ROC para exibir a qualidade da classifica\u00e7\u00e3o**","205082b2":"**Comparando a acur\u00e1cia dos m\u00e9todos:**","86e21e04":"**Gerando a \u00e1rvore de decis\u00e3o e calculando a acur\u00e1cia dos m\u00e9todos:**","f1b02d2b":"**Agora concluindo com testes de predi\u00e7\u00e3o para novos valores:**","21cdd110":"**Coletando os dados novamente, fazendo testes com pipeline e cross validation:**","66915933":"**Tratando os dados n\u00e3o num\u00e9ricos via one hot encoding (get dummies).**"}}