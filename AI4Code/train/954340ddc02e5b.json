{"cell_type":{"8d0a31f6":"code","163741c6":"code","225004da":"code","639be2b7":"code","8af05e48":"code","4e54790e":"code","29c8770f":"code","4a41ff58":"code","411a5ed0":"code","3d1f9171":"code","00f79537":"code","592dd4fe":"code","5d5ec019":"code","ca8b88e5":"code","e190340c":"code","bbb6dbf0":"markdown","4cd1e43e":"markdown","321fd6c0":"markdown","cfb1c05e":"markdown","4a8d7b9f":"markdown","c109f306":"markdown","959fc4ed":"markdown","64fec6b4":"markdown","7bc66927":"markdown","0d5b4376":"markdown","c038480a":"markdown","dce7e342":"markdown","11be2f2f":"markdown","dc2b1681":"markdown","2bb19b8f":"markdown","4caed092":"markdown","6c986f30":"markdown","a91383cf":"markdown"},"source":{"8d0a31f6":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\n\nfrom sklearn.model_selection import LeaveOneOut\n\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import zero_one_loss\nfrom sklearn.metrics import make_scorer\n\nfrom collections import OrderedDict\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n","163741c6":"data = pd.read_csv(\"..\/input\/usp-pj01\/train_Iris.csv\") #Lendo dados de treino\n\ndata.drop(['Id'],axis = 1, inplace = True)\ndata1 = data.copy()\nprint(data.shape)\ndata.head()\n","225004da":"data.describe() #Estatisticas descritivas das vari\u00e1veis ","639be2b7":"corr = data.corr()\ncorr.style.background_gradient().set_precision(2)","8af05e48":"for i in (\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"):\n    plt.figure(figsize=(8, 8))\n    # mostra o boxplot\n    sns.boxplot(x=\"Species\", y=i, data=data)\n    plt.xlabel('Esp\u00e9cie', fontsize=18)\n    plt.ylabel(i.replace(\"Cm\", \"\"),fontsize=18)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show(True)","4e54790e":"import seaborn as sns\nsns.pairplot(data, hue='Species')\nplt.show()","29c8770f":"data = data.to_numpy()\nnrow,ncol = data.shape\ny = data[:,-1]\nX = data[:,0:ncol-1]\nscaler = MinMaxScaler(feature_range=(0, 1))\nX = scaler.fit_transform(X)","4a41ff58":"def frequency(vet): \n    freq = {}\n    for item in np.unique(np.array(vet)):\n         freq[item] = np.where(np.array(vet)==item)[0].shape[0]\n    return(freq) #retorna uma lista de dicion\u00e1rios com chave igual ao estado e valor igual a freq. absoluta\nfrequency(y) #calculando a frequ\u00eancia dos estados nessa caminhada","411a5ed0":"# Separando o array em componentes de input e output\n\nXm = X.copy()\nym = y.copy()\nacuracia , fbeta , loss , algoritmos  = [] , [] , [] , []\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 11\nseed = 11\n\n# LISTA DE MODELOS\nmodelos = [('SVCL', SVC(kernel='linear')),\n           ('SVCM', SVC(kernel='linear')),\n           ('KNN', KNeighborsClassifier()),\n           ('KNN', KNeighborsClassifier()),\n           ('NBG', GaussianNB()),\n           ('LRC', LogisticRegression()),\n           ('LDA', LinearDiscriminantAnalysis()),\n           ('RFC', RandomForestClassifier(n_jobs=-1))\n           ]\n\n## M\u00e9tricas Utilizadas\nscor = {'accuracy' : make_scorer(accuracy_score), \n        'fbeta' : make_scorer(fbeta_score,  average = 'weighted', beta = 0.5),\n        'zero_one_loss' : make_scorer(zero_one_loss , normalize = False , greater_is_better = True)}\n\n## Avaliando modelos com as m\u00e9tricas estipuladas\nfor nome, modelo in modelos:\n    kfold = KFold(n_splits = num_folds, \n                  random_state = seed,\n                  shuffle = True)\n    cv_results = cross_validate(estimator=modelo,\n                                          X = Xm,\n                                          y = ym,\n                                          cv = kfold,\n                                          scoring = scor)\n    \n    algoritmos.append(nome)\n    acuracia += [cv_results['test_accuracy']]\n    fbeta += [cv_results['test_fbeta']]\n    loss += [cv_results['test_zero_one_loss']]","3d1f9171":"# Boxblot\nfig, ([ax1, ax2, ax3]) = plt.subplots(1, 3,figsize=(15,5))\nax1.title.set_text('Acuracia')\nax2.title.set_text('F-Beta')\nax3.title.set_text('01 Loss')\nax1.boxplot(acuracia)\nax2.boxplot(fbeta)\nax3.boxplot(loss)\nax1.set_xticklabels(algoritmos)\nax2.set_xticklabels(algoritmos)\nax3.set_xticklabels(algoritmos)\n","00f79537":"# Dataframe\n\nam, fm, lm = [], [], []\nfor i in range(0,len(acuracia)):\n  am += [np.mean(acuracia[i])]\n  fm += [np.mean(fbeta[i])]\n  lm += [np.mean(loss[i])]\nmetricas = OrderedDict({'Acuracia': am,'F-Beta': fm,'01-Loss': lm})\ndf = pd.DataFrame(metricas , index = algoritmos )\ndf['Resultado'] = df['Acuracia'] + df['F-Beta'] -  df['01-Loss']\ndisplay(df.sort_values(by=['Resultado'], ascending=False))\n","592dd4fe":"def nested_cv(X, y, outer_folds, \n              inner_folds, model, \n              parameters):\n    \n    cv_outer = StratifiedKFold(n_splits = outer_folds, \n                               shuffle = True, \n                               random_state = 713)\n    acc = list()\n    i = 0\n    for train_i, test_i in cv_outer.split(X,y):\n\n        train_x, train_y = X[train_i], y[train_i]\n        test_x, test_y = X[test_i], y[test_i]\n\n        cv_inner = StratifiedKFold(n_splits=inner_folds, shuffle=True)\n\n        grid_search_cv = GridSearchCV(model, \n                                      parameters, \n                                      cv=cv_inner, \n                                      scoring='accuracy', \n                                      refit=True)\n        \n        result = grid_search_cv.fit(train_x, \n                                    train_y)\n        \n        best_params = result.best_params_ \n        best_model = result.best_estimator_  \n        pred_y = best_model.predict(test_x) \n        acc.append(accuracy_score(test_y, pred_y))\n\n    m_acc = np.mean(acc)\n    dp_acc = np.std(acc)\n    \n    return np.round(m_acc,3),np.round(dp_acc,3), best_params","5d5ec019":"#Ajuste do K-vizinhos\n\nN = 10\n\nouter_f = 5\ninner_f = 10\n\np_grid = {\"n_neighbors\":[x for x in range(5,12)],\"metric\":['euclidean','manhattan','chebyshev','minkowski']}\nmodel = KNeighborsClassifier()\n\nfor a in range(N):\n\n  m_acc,dp_acc,best_params = nested_cv(X,y,outer_f,inner_f,model,p_grid)\n  print(\"Acur\u00e1cia m\u00e9dia estimada:\", m_acc,\n        \"Desvio padr\u00e3o da Acur\u00e1cia:\", dp_acc,\n        \"Melhores par\u00e2metros:\", best_params)","ca8b88e5":"#Ajuste LDA\n\nN = 10\n\nouter_f = 5\ninner_f = 10\n\np_grid = {\"solver\":[\"svd\", \"lsqr\", \"eigen\"]}\nmodel = LinearDiscriminantAnalysis()\n\nfor a in range(N):\n\n  m_acc,dp_acc,best_params = nested_cv(X,y,outer_f,inner_f,model,p_grid)\n  print(\"Acur\u00e1cia m\u00e9dia estimada:\",m_acc,\n        \"Desvio padr\u00e3o da Acur\u00e1cia:\",dp_acc,\n        \"Melhores par\u00e2metros:\",best_params)\n","e190340c":"test = pd.read_csv(\"..\/input\/usp-pj01\/test_Iris.csv\") #Lendo dados de teste\ntest.head()\n\n#Separa o Id das plantas do teste para futuro envio no Kaggle.\ntest_id = test.Id\ntest.drop(\"Id\", axis = 1, inplace = True)\n\n#Mudar o nome das categorias para ficar do jeito que \u00e9 pedido na competi\u00e7\u00e3o\ndata1.replace({\"versicolor\": \"Iris-versicolor\", \n               \"setosa\": \"Iris-setosa\", \n               \"virginica\":\"Iris-virginica\"}, \n               inplace = True)\n\ny_train = data1.iloc[:, -1]\nX_train = data1.iloc[:, :-1]\n\nX_test = test.copy()\n\n\nmodel = LinearDiscriminantAnalysis(solver = 'svd')\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n#Gera um csv com as predi\u00e7\u00f5es feitas pelo modelo para o conjunto de teste\ntest_id = pd.DataFrame(data = {\"Id\": test_id, \n                               \"Category\": y_pred})\ntest_id.to_csv(\"resposta1.csv\", index = False)\n\ntest_id.head()","bbb6dbf0":"Temos correla\u00e7\u00f5es altas, maiores que 0.8 em tr\u00eas casos: Entre o comprimento da p\u00e9tala e da s\u00e9pala, entre a largura da p\u00e9tala e o comprimento da s\u00e9pala,e por fim a maior correla\u00e7\u00e3o de todas entre o comprimento e a largura da p\u00e9tala.","4cd1e43e":"### Libs & Data","321fd6c0":"As classes da base s\u00e3o levemente desbalanceadas, indicando que um uso de t\u00e9cnicas estratificadas s\u00e3o mais adequadas a essa situa\u00e7\u00e3o.","cfb1c05e":"O resultado obtido com os modelos:\n\n* SVM Linear\n\n* SVM RBF\n\n* \u00c1rvore de decis\u00e3o\n\n* Regress\u00e3o Log\u00edstica\n\n* Analise de discriminante linear\n\n* Floresta Aleat\u00f3ria\n","4a8d7b9f":"*Script abaixo \u00e9 um modelo de como salvar o arquivo pra submeter no kaggle*","c109f306":"Os classificadores escolhidos foram:\n\n* LDA\n\n* KNN ","959fc4ed":"Para o ajuste de hiperpar\u00e2metros do k-vizinhos usaremos o cross-validation aninhado ","64fec6b4":"Vamos executar a avalia\u00e7\u00e3o de alguns modelos no conjunto de dados segundo as m\u00e9tricas: acur\u00e1cia, f-beta e zero-one-loss:\n\n* Acuracia - meda a exatid\u00e3o do subconjunto, ou seja, o conjunto de r\u00f3tulos previsto para uma amostra deve corresponder exatamente ao conjunto correspondente de r\u00f3tulos desconhecidos. Para dados balanceados, \u00e9 uma \u00e9 aceit\u00e1vel.\n\n* F-Beta -  \u00e9 a m\u00e9dia harm\u00f4nica ponderada de precis\u00e3o e recall, em que este pode ser entendido como  a capacidade do classificador de encontrar todas as amostras positivas, aquele \u00e9 a capacidade do classificador de n\u00e3o rotular como positiva uma amostra negativa.. A pontua\u00e7\u00e3o de F-beta atinge oscila entre  0 (pior caso) e 1 (melhor caso). O par\u00e2metro beta determina o peso do recall na pontua\u00e7\u00e3o.\n\n* Zero-One-Loss - retorna a fra\u00e7\u00e3o de classifica\u00e7\u00f5es incorreta. A pontua\u00e7\u00e3o oscila entre 1 (pior caso) e 0 (melhor caso).\n","7bc66927":"Observando as estat\u00edsticas descritivas das 4 vari\u00e1veis da base, notamos que o comprimento da p\u00e9tala \u00e9 a caracter\u00edstica com maior vari\u00e2ncia, dessa forma ela \u00e9 a vari\u00e1vel com maior chance de separar as classes de uma forma mais n\u00edtida. \n","0d5b4376":"### K-vizinhos\n","c038480a":"## Pr\u00e9-processamento & Visualiza\u00e7\u00e3o dos Dados","dce7e342":"### An\u00e1lise de Discriminante Linear\n","11be2f2f":"## Previs\u00e3o \n\nComo notamos, o melhor hiperpar\u00e2metro descrito como \"*solver*\", para o classificador LDA, \u00e9 o svd, sendo assim utilizaremos o mesmo para a predi\u00e7\u00e3o final. \n\n","dc2b1681":"Para o ajuste de hiperpar\u00e2metro do LDA usaremos o cross-validation aninhado. Aquele que aparecer com maior frequ\u00eancia ser\u00e1 o utilizado para a classifica\u00e7\u00e3o.","2bb19b8f":"## Ajuste & Escolha dos melhores modelos classificadores","4caed092":"Observando os gr\u00e1ficos acima notamos que as esp\u00e9cies Versicolor e Virginica s\u00e3o muito parecidas entre s\u00ed de acordo com as 4 vari\u00e1veis presentes. Dando uma aten\u00e7\u00e3o para as vari\u00e1veis referentes a p\u00e9tala, obvservamos que a esp\u00e9cie Setosa possui uma boa separa\u00e7\u00e3o em rela\u00e7\u00e3o as outras classes, informa\u00e7\u00e3o que complementa a dita anteriormente.","6c986f30":"#Task 01 - Iris Dataset\n\nAndr\u00e9 Kenji - 10857057   \nDiego Giaretta - 10857040  \nDouglas Sudr\u00e9 - 10733820  \nJo\u00e3o Marcos - 10388176  \nRenan Barreto - 10734004  \n\n","a91383cf":"Nesta fun\u00e7\u00e3o definimos o cross-validation aninhado utilizado para medir o(s) melhor(es) hiperpar\u00e2metro(s) para os classificadores escolhidos com base na m\u00e9dia da m\u00e9trica \"*accuracy_score*\". Utilizamos a fun\u00e7\u00e3o \"*GridSearchCV*\" para escolhermos o(s) melhor(es) hiperpar\u00e2metro(s)."}}