{"cell_type":{"ee94d2dd":"code","9a1efa6d":"code","32d6780a":"code","79954d24":"code","1a887921":"code","1168de51":"code","84c55742":"code","44bc8981":"code","a6dcc592":"code","2b633611":"code","3a813959":"code","a71601a9":"code","e06dcc16":"code","e314edeb":"code","959b6dcc":"code","6838bc3a":"code","863f3c56":"code","cfee148f":"code","44a1df94":"code","6bf1640e":"code","d471e6bc":"code","2c92d9da":"code","73bc946b":"code","afe1eb0e":"code","db6c33d0":"code","3c854c95":"code","8d5f74b2":"code","a5474913":"code","bc34626f":"code","30449680":"code","126ca651":"code","879598a1":"code","3d861c64":"code","17a4b03b":"code","3ecfd8fe":"code","30e63f66":"code","e005b5ba":"code","447ee1fe":"code","feac7cde":"code","65394ad4":"code","afa61ab0":"code","b35b16ca":"code","513af6b1":"code","48fa2cf2":"code","c8f548f7":"code","dfc8ace3":"code","076fdc05":"markdown","42b8de75":"markdown","a8227016":"markdown","cb63dc8d":"markdown","cda0222b":"markdown","d3ca4d02":"markdown","2c0734c9":"markdown","8ed2bbce":"markdown","4bda05f5":"markdown","bca1c544":"markdown","f6ce9e5a":"markdown","4a74e17c":"markdown","dad375ea":"markdown","933e634b":"markdown","8f683d64":"markdown","d596fb2a":"markdown","24b324ea":"markdown","5bd8611f":"markdown","1a644266":"markdown","46787f57":"markdown","930937f7":"markdown","20b8913a":"markdown","ebcb0938":"markdown","2da1a0b6":"markdown","99820558":"markdown","62d6c574":"markdown","03def0ae":"markdown","4a85a0ab":"markdown","fd72ff8f":"markdown","d4f31066":"markdown"},"source":{"ee94d2dd":"%matplotlib inline\n\nimport os\nimport zipfile\nimport urllib\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\n\nimport qgrid\n\nFOOD_PATH = os.path.join(\"\/kaggle\/input\/fropenfoodfacts-2020-feature-engineered-data\/\")\nFOOD_TRANSFORMED_PATH_FILE = os.path.join(FOOD_PATH, \"fr.openfoodfacts.org.products_transformed.csv\")\n\nimport seaborn as sns\nsns.set()\n\nplt.rcParams[\"figure.figsize\"] = [16,9] # Taille par d\u00e9faut des figures de matplotlib\n\npd.set_option(\"display.max_columns\", 1000)\npd.set_option(\"display.max_rows\",1000)\n\n","9a1efa6d":"import pandas as pd\n\ndef load_food_data(csv_path=FOOD_TRANSFORMED_PATH_FILE):\n    return pd.read_csv(csv_path, sep=',', header=0, encoding='utf-8', low_memory=False)\n\n","32d6780a":"food = load_food_data()","79954d24":"food.head()","1a887921":"food.info()","1168de51":"scoring_features = ['nutrition_scoring', 'bio_scoring', 'no_ingredients_scoring',\n       'additives_nocive_scoring', 'energy_100g_scoring', 'salt_100g_scoring',\n       'sugars_100g_scoring', 'saturated-fat_100g_scoring',\n       'fiber_100g_scoring', 'proteins_100g_scoring', 'nova_scoring']\n\nquantity_features = ['energy_100g', 'sugars_100g', 'salt_100g', 'saturated-fat_100g', 'fiber_100g', 'proteins_100g' ]","84c55742":"food.info()","44bc8981":"food.describe()","a6dcc592":"food[scoring_features].hist(bins=5, figsize=(20,15))","2b633611":"plt.style.use('default')\n#On peut utiliser le code ci-dessous pour changer le style et la palette de couleurs :\n#print(plt.style.available)\n#plt.style.use('seaborn-ticks')\n#current_palette = sns.color_palette('hls', 4)\n\nfor scoring_feature in ['additives_nocive_scoring', 'sugars_100g_scoring', 'saturated-fat_100g_scoring', 'bio_scoring', 'no_ingredients_scoring']:\n        ax = food.groupby(scoring_feature)[[scoring_feature]].count().plot.pie(subplots=True, title=scoring_feature)\n        plt.gca().axes.get_yaxis().set_visible(False)\n        # On peut utiliser le code ci-dessous pour sp\u00e9cifier les couleurs une par une :\n        #food.groupby(scoring_feature)[[scoring_feature]].count().plot.pie(subplots=True, colors=['#2c73d2', '#0081cf', '#0089ba', '#008e9b', '#008f7a'])\n    \n    ","3a813959":"def log_convert(df, features_list_toconvert):\n    features_list_converted = []\n    for feature_name in features_list_toconvert:\n        df[feature_name + '_log'] = np.log10(df[df[feature_name] > 0][feature_name])\n        features_list_converted.append(feature_name + '_log')\n        \n    return(features_list_converted)","a71601a9":"plt.rcParams[\"figure.figsize\"] = [16,9]\nfood[quantity_features].hist(bins=50)\nplt.suptitle(\"Analyse univari\u00e9e des quantit\u00e9s\\nEchelle abscisses : proportion en grammes \/ 100g \\nEchelle ordonn\u00e9es : nombre d'aliments\")","e06dcc16":"features_list_log = log_convert(food, quantity_features)","e314edeb":"features_list_log","959b6dcc":"food[features_list_log].hist(bins=50)\nplt.suptitle(\"Analyse univari\u00e9e logarithmique des quantit\u00e9s\\nEchelle des abscisses logarithmique : -3=0.001, ..., 1 = 10, 2=100, 3=1000, ... en g \/ 100g\\nEchelle des ordonn\u00e9es : nombre d'aliments\")","6838bc3a":"food.describe()","863f3c56":"plt.figure(figsize=(16, 10))\n\nplt.axvline(np.log10(2345), 0, 1, color='red', label='\u00e0 gauche de la barre rouge : scoring \u00e9nergie > 1\\n\u00e0 droite de la barre rouge   : scoring \u00e9nergie = 1')\n# la valeur 2345 correspond au scoring \u00e9nergie = 1 (voir notebook de cleaning)\nplt.legend()\nplt.title(\"Distribution des proportions d'\u00e9nergie\")\nsns.distplot(food[food['energy_100g_log'].notnull()]['energy_100g_log'], kde=True, label='Densit\u00e9 de probabilit\u00e9', axlabel='energie pour 100g (\u00e9chelle logarithmique: 1 = 10, 2=100, 3=1000, ...)')\nplt.legend()","cfee148f":"plt.figure(figsize=(16, 10))\nplt.axvline(np.log10(1.575), 0, 1, color='red', label='\u00e0 gauche de la barre rouge : scoring sel > 1\\n\u00e0 droite de la barre rouge   : scoring sel = 1')\n# la valeur 1.575 correspond au scoring sel = 1 (voir notebook de cleaning)\nplt.legend()\nplt.title('Distribution des proportions de sel')\n\nsns.distplot(food[food['salt_100g_log'].notnull()]['salt_100g_log'], kde=True, label='Densit\u00e9 de probabilit\u00e9', axlabel='sel pour 100g (\u00e9chelle logarithmique: -3=0.001, ..., 1 = 10, 2=100, 3=1000, ...)')\nplt.legend()","44a1df94":"plt.figure(figsize=(16, 10))\nplt.axvline(np.log10(31), 0, 1, color='red', label='\u00e0 gauche de la barre rouge : scoring sucre > 1\\n\u00e0 droite de la barre rouge   : scoring sucre = 1')\n# la valeur 31 correspond au scoring sucre = 1 (voir notebook de cleaning)\nplt.legend()\nplt.title('Distribution des proportions de sucre')\nsns.distplot(food[food['sugars_100g_log'].notnull()]['sugars_100g_log'], kde=True, label='Densit\u00e9 de probabilit\u00e9', axlabel='sucre pour 100g (\u00e9chelle logarithmique: -3=0.001, ..., 1 = 10, 2=100, 3=1000, ...)')\nplt.legend()","6bf1640e":"corr_matrix = food.corr()","d471e6bc":"corr_matrix[quantity_features].loc[quantity_features]","2c92d9da":"plt.title('Corr\u00e9lation entre les proportions')\nsns.heatmap(corr_matrix[quantity_features].loc[quantity_features], \n        xticklabels=corr_matrix[quantity_features].loc[quantity_features].columns,\n        yticklabels=corr_matrix[quantity_features].loc[quantity_features].columns, cmap='coolwarm' ,center=0.20)","73bc946b":"corr_matrix[scoring_features].loc[scoring_features]","afe1eb0e":"plt.title('Corr\u00e9lation entre les scorings de qualit\u00e9 nutritionnelle')\nsns.heatmap(corr_matrix[scoring_features].loc[scoring_features], \n        xticklabels=corr_matrix[scoring_features].loc[scoring_features].columns,\n        yticklabels=corr_matrix[scoring_features].loc[scoring_features].columns, cmap='coolwarm', center=0.20)","db6c33d0":"X = \"bio_scoring\"\nY = \"nutrition_scoring\"\ndata = food\n\ncont = data[[X,Y]].pivot_table(index=X,columns=Y,aggfunc=len,margins=True,margins_name=\"Total\")\ncont","3c854c95":"tx = cont.loc[:,[\"Total\"]]\nty = cont.loc[[\"Total\"],:]\nn = len(data)\nindep = tx.dot(ty) \/ n\n\nc = cont.fillna(0) # On remplace les valeurs nulles par 0\nmeasure = (c-indep)**2\/indep\nxi_n = measure.sum().sum()\ntable = measure\/xi_n\n\nsns.heatmap(table.iloc[:-1,:-1],annot=c.iloc[:-1,:-1], linewidths=.5)\nplt.show()\n# Voir https:\/\/en.wikipedia.org\/wiki\/Correlation_and_dependence","8d5f74b2":"scatter_matrix(food[features_list_log], figsize=(16,16))\nplt.suptitle('Diagramme de dispersion des quantit\u00e9s')","a5474913":"from sklearn import decomposition\nfrom sklearn import preprocessing\n\n# Import `PCA` from `sklearn.decomposition`\nfrom sklearn.decomposition import PCA\n\n# Build the model\npca = PCA(n_components=2)\n\n# import de l'\u00e9chantillon\ndata = food\n\n# selection des colonnes \u00e0 prendre en compte dans l'ACP\ndata_pca = food[['nutrition_scoring', 'no_ingredients_scoring',\n       'additives_nocive_scoring', 'energy_100g_scoring', 'salt_100g_scoring',\n       'sugars_100g_scoring', 'saturated-fat_100g_scoring',\n       'fiber_100g_scoring', 'proteins_100g_scoring', 'bio_scoring']]\n\ndata_pca = data_pca.dropna()\n\nX = data_pca.values\nfeatures = data_pca.columns\n\n# Centrage et R\u00e9duction\nstd_scale = preprocessing.StandardScaler().fit(X)\nX_scaled = std_scale.transform(X)\n\n# Reduce the data, output is ndarray\nreduced_data = pca.fit_transform(X_scaled)\n\n# Inspect shape of the `reduced_data`\nprint(reduced_data.shape)\n\n# print out the reduced data\nprint(reduced_data)","bc34626f":"import matplotlib.pyplot as plt\nfrom matplotlib.collections import LineCollection\nimport numpy as np\nimport pandas as pd\nfrom scipy.cluster.hierarchy import dendrogram\n\ndef display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premi\u00e8res composantes\n        if d2 < n_comp:\n\n            # initialisation de la figure\n            fig, ax = plt.subplots(figsize=(16,16))\n\n            # d\u00e9termination des limites du graphique\n            if lims is not None :\n                xmin, xmax, ymin, ymax = lims\n            elif pcs.shape[1] < 30 :\n                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n            else :\n                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n\n            # affichage des fl\u00e8ches\n            # s'il y a plus de 30 fl\u00e8ches, on n'affiche pas le triangle \u00e0 leur extr\u00e9mit\u00e9\n            if pcs.shape[1] < 30 :\n                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n                   pcs[d1,:], pcs[d2,:], \n                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n                # (voir la doc : https:\/\/matplotlib.org\/api\/_as_gen\/matplotlib.pyplot.quiver.html)\n            else:\n                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n            \n            # affichage des noms des variables  \n            if labels is not None:  \n                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n            \n            # affichage du cercle\n            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n            plt.gca().add_artist(circle)\n\n            # d\u00e9finition des limites du graphique\n            plt.xlim(xmin, xmax)\n            plt.ylim(ymin, ymax)\n\n        \n            # affichage des lignes horizontales et verticales\n            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n\n            # nom des axes, avec le pourcentage d'inertie expliqu\u00e9\n            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Cercle des corr\u00e9lations (F{} et F{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n        \ndef display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, illustrative_var=None, illustrative_legend=None):\n    for d1,d2 in axis_ranks:\n        if d2 < n_comp:\n \n            # initialisation de la figure       \n            fig = plt.figure(figsize=(10,6))\n        \n            # affichage des points\n            if illustrative_var is None:\n                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)\n            else:\n                illustrative_var = np.array(illustrative_var)\n                for value in np.unique(illustrative_var):\n                    selected = np.where(illustrative_var == value)\n                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)\n                plt.legend()\n\n            # affichage des labels des points\n            if labels is not None:\n                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n                    plt.text(x, y, labels[i],\n                              fontsize='14', ha='center',va='center') \n                \n            # d\u00e9termination des limites du graphique\n            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) * 1.1\n            plt.xlim([-boundary,boundary])\n            plt.ylim([-boundary,boundary])\n        \n            # affichage des lignes horizontales et verticales\n            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n\n            # nom des axes, avec le pourcentage d'inertie expliqu\u00e9\n            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Projection des aliments (coloration : \"+illustrative_legend+\") (sur F{} et F{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n\ndef display_scree_plot(pca):\n    scree = pca.explained_variance_ratio_*100\n    plt.bar(np.arange(len(scree))+1, scree)\n    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n    plt.xlabel(\"rang de l'axe d'inertie\")\n    plt.ylabel(\"pourcentage d'inertie\")\n    plt.title(\"Eboulis des valeurs propres\")\n    plt.show(block=False)\n\ndef plot_dendrogram(Z, names):\n    plt.figure(figsize=(10,25))\n    plt.title('Hierarchical Clustering Dendrogram')\n    plt.xlabel('distance')\n    dendrogram(\n        Z,\n        labels = names,\n        orientation = \"left\",\n    )\nplt.show()","30449680":"\nfrom sklearn import decomposition\nfrom sklearn import preprocessing\n\n# Import `PCA` from `sklearn.decomposition`\nfrom sklearn.decomposition import PCA\n\n# Build the model\npca = PCA(n_components=2)\n\n# choix du nombre de composantes \u00e0 calculer\nn_comp = 6\n\n# import de l'\u00e9chantillon\ndata = food\n\n# selection des colonnes \u00e0 prendre en compte dans l'ACP\ndata_pca = food[['nutrition_scoring', 'no_ingredients_scoring',\n       'additives_nocive_scoring', 'energy_100g_scoring', 'salt_100g_scoring',\n       'sugars_100g_scoring', 'saturated-fat_100g_scoring',\n       'fiber_100g_scoring', 'proteins_100g_scoring', 'bio_scoring', 'nova_scoring']]\n\n# pr\u00e9paration des donn\u00e9es pour l'ACP\n#data_pca = data_pca.fillna(data_pca.mean()) # Il est fr\u00e9quent de remplacer les valeurs inconnues par la moyenne de la variable\ndata_pca = data_pca.dropna()\n\nX = data_pca.values\n#names = data[\"idCours\"] # ou data.index pour avoir les intitul\u00e9s\n\n#features = data.columns\nfeatures = data_pca.columns\n\n# Centrage et R\u00e9duction\nstd_scale = preprocessing.StandardScaler().fit(X)\nX_scaled = std_scale.transform(X)\n\n# Calcul des composantes principales\npca = decomposition.PCA(n_components=n_comp)\npca.fit(X_scaled)\n\n# Eboulis des valeurs propres\ndisplay_scree_plot(pca)\n\n# Cercle des corr\u00e9lations\npcs = pca.components_\n#plt.figure(figsize=(16,10))\nplt.rcParams[\"figure.figsize\"] = [16,9]\ndisplay_circles(pcs, n_comp, pca, [(0,1),(2,3),(4,5)], labels = np.array(features))\n\n\n# Projection des individus\nX_projected = pca.transform(X_scaled)\ndisplay_factorial_planes(X_projected, n_comp, pca, [(0,1),(2,3),(4,5)], illustrative_var=data_pca[['nutrition_scoring']].values[:,0], illustrative_legend='nutrition scoring')\n\n\nplt.show()\n\n","126ca651":"display_factorial_planes(X_projected, n_comp, pca, [(0,1),(2,3),(4,5)], illustrative_var=data_pca[['nova_scoring']].values[:,0], illustrative_legend='nova scoring')","879598a1":"display_factorial_planes(X_projected, n_comp, pca, [(0,1),(2,3),(4,5)], illustrative_var=data_pca[['no_ingredients_scoring']].values[:,0], illustrative_legend='no ingredients scoring')","3d861c64":"pcs[0]","17a4b03b":"data_pca","3ecfd8fe":"food_scoring_important = food[['code', 'product_name', 'image_url', 'main_category_fr', 'nutrition_scoring', 'no_ingredients_scoring', 'additives_nocive_scoring', 'bio_scoring']].dropna()","30e63f66":"food_scoring_important.shape","e005b5ba":"food_scoring_important = food[(food['nutrition_scoring'] == 5) & (food['additives_nocive_scoring'] == 5) & (food['bio_scoring'] == 5) & (food['no_ingredients_scoring'] == 5)]","447ee1fe":"food_scoring_important['main_category_fr'].value_counts().plot(kind='bar')","feac7cde":"food_scoring_important = food[(food_scoring_important['nutrition_scoring'] == 5) &  (food['bio_scoring'] == 5)]","65394ad4":"food_scoring_important['main_category_fr'].value_counts().plot(kind='bar')","afa61ab0":"food_scoring_important = food[(food['nutrition_scoring'] >= 5) & (food['bio_scoring'] >= 2)& (food['no_ingredients_scoring'] >= 4)]","b35b16ca":"food_scoring_important['main_category_fr'].value_counts().plot(kind='bar')","513af6b1":"food_scoring_important['main_category_fr'].value_counts()[:30]","48fa2cf2":"import plotly.express as px\n\n#from IPython.display import HTML, display\nfrom IPython.display import Image\n\n'''\nCette fonction n\u00e9cessite une variable globale \"scoring_features\"\nqui contient la liste des noms de colonnes du dataframe df \u00e0 afficher dans le radar plot\n'''\ndef display_products_radar_image(df):\n    max_products_display = 100\n    cnt = 0\n    \n    for i, j in df.iterrows(): \n        if (cnt > max_products_display):\n            print('Max products display reached')\n            break\n            \n        radar_values = df.loc[[i]][scoring_features].to_numpy()\n        #print(radar_values.tolist()[0])\n        radar_values[np.isnan(radar_values)] = 0\n        #print(radar_values.tolist()[0])\n        \n        df_radius = pd.DataFrame(dict(\n            r = radar_values.tolist()[0],\n            theta = scoring_features))\n\n        fig = px.line_polar(df_radius, r='r', theta='theta', line_close=True, width=600, height=400, title=df.loc[i]['product_name'])\n        \n        plt.figure(figsize=(10, 10))\n        \n        print('Produit: ')\n        fig.show()\n                \n        #print('Image du produit: ')  \n        image_url = df.loc[i]['image_url']\n                        \n        '''\n        if (type(image_url) == str):\n            print(f'image_url = <<{image_url}>>')\n            # Comment\u00e9 car ne fonctionne pas derri\u00e8re proxy BNP\n            \n            image_obj = Image(df.loc[i]['image_url'], width=100) \n            try:\n                display(image_obj)\n                \n            except:\n                print('Could not display image')\n        '''    \n                        \n        print('\\n\\n')\n        cnt +=1         \n\n\n","c8f548f7":"display_products_radar_image(food_scoring_important[food_scoring_important['main_category_fr'] == 'Viandes'].head(20))\n\n\n","dfc8ace3":"for cat_name in food_scoring_important['main_category_fr'].value_counts()[:10].iteritems():\n    print(f'5 bons produits dans la cat\u00e9gorie {cat_name[0]}')\n    \n    display_products_radar_image(food_scoring_important[food_scoring_important['main_category_fr'] == cat_name[0]].head(5))","076fdc05":"# R\u00e9duction dimensionnelle","42b8de75":"# Analyse univari\u00e9e de features quantitatives","a8227016":"# Analyse d'\u00e9chantillons d'ingr\u00e9dients obtenus apr\u00e8s application des scorings","cb63dc8d":"## Test khi 2 entre le scoring de nutrition et bio","cda0222b":"### => La vari\u00e9t\u00e9 des ingr\u00e9dients disponibles reste faible","d3ca4d02":"## Distribution des proportions de sel","2c0734c9":"## Si on ne conserve que les aliments ayant tous les scoring nutrition, additifs, bio, nombre d'ingr\u00e9dients, sup\u00e9rieurs \u00e0 5 :","8ed2bbce":"### Cat\u00e9gorie d'aliments \u00e0 proposer dans ce cas :","4bda05f5":"# fr.openfoodfacts 2020 : data and scoring features exploration\n\n## The goal of this note book is explore data, including scoring features that I created in the other notebook.\n## My scoring features end in _scoring : values are 5 for best and 1 for worst\n## You will see that I have my own scoring for number of ingredients (the more ingredients, the more transformed the food is) : no_ingredients_scoring.  I had featured this scoring with an old dataset where nova groups did not exist yet.  => I did not yet compare my no_ingredients_scoring with nova scoring. I just saw that correlation between the 2 is 57%\n\nno_ingredients_scoring_bins = [0, 3, 5, 7, 10, np.inf]  \nno_ingredients_scoring_labels = [5, 4, 3, 2, 1]\n\n## I also have a scoring for nocive additives :  value 1 = ingredient has at least 1 nocive additive,   and value 5 = no nocive additives\n### List of nocive additives I used  (constructed in my data cleaning notebook) :  ['e100', 'e101', 'e103','e104', 'e111', 'e124', 'e128', 'e131', 'e132', 'e133', 'e143', 'e171', 'e173', 'e199', 'e214', 'e215', 'e216', 'e217', 'e218', 'e219', 'e240', 'e249', 'e250', 'e251', 'e386', 'e620', 'e621','e622','e623','e624','e625', 'e924', 'e924a', 'e924b', 'e926', 'e950', 'e951', 'e952', 'e952i','e952ii','e952iii','e952iv']\n\n## Bio scoring meaning actually includes a little more than bio :  5 = french bio, 4 = european bio,  3 = bio non european non french, 2 = not bio, but made in france,  1 = neither bio, neither made in France\n\n## => **I know that I did not comprehensively explain everything, but feel free to ask my any question you have about this work, I will be happy to explain**\n\n## If you want to see raw data that allowed me to generate the file used as input of this notebook, and all the bins I used for scoring : see my other dataset and notebook : fropenfoodfacts data clean and engineering => https:\/\/www.kaggle.com\/franoisboyer\/fropenfoodfacts-data-clean-and-engineering\/edit\/run\/28658211\n\n## Note for english users:  this notebook is in French, since I initially did it for a training that is in French  (openclassrooms training)\n## I adaptated my work for new 2020 dataset that I downloaded on 12\/02\/2020 on openfoodfacts website.  But I did not translate it yet in English. If you want English translation, drop me a note, I'll do it with pleasure.","bca1c544":"## Si on ne conserve que les aliments ayant nutrition scoring >= 5, avec un scoring bio >= 2  (ce qui signifie au minimum des produits fran\u00e7ais, qu'ils soient bio ou non), et un scoring sur le nombre d'ingr\u00e9dients >= 2 (c'est \u00e0 dire pas plus de 10 ingr\u00e9dients pour \u00e9viter les produits transform\u00e9s) :","f6ce9e5a":"# Informations globales sur les donn\u00e9es","4a74e17c":"### => La vari\u00e9t\u00e9 des ingr\u00e9dients disponibles est un peu faible","dad375ea":"## Cercle des corr\u00e9lations et r\u00e9duction de dimensionalit\u00e9","933e634b":"### On voit que le scoring nutrition est bien corr\u00e9l\u00e9 aux variables sur lesquels porte ce scoring : graisses, sucres, \u00e9nergie, sel\n### no_ingredients et bio sont \u00e9galement corr\u00e9l\u00e9s aux autres variables, mais de fa\u00e7on plus faible (couleur bleu clair)\n### Le scoring nova est corr\u00e9l\u00e9 \u00e0 57% au scoring sur le nombre d'ingr\u00e9dients","8f683d64":"## Analyse univari\u00e9e logarithmique, pour mieux voir les r\u00e9partitions","d596fb2a":"# Analyse multivari\u00e9e : Corr\u00e9lation entre les donn\u00e9es","24b324ea":"## Distribution des proportions de sucre","5bd8611f":"### Cat\u00e9gorie d'aliments \u00e0 proposer dans ce cas :","1a644266":"### => La vari\u00e9t\u00e9 des ingr\u00e9dients disponibles est satisfaisante","46787f57":"# Anayse univari\u00e9e des features de scoring","930937f7":"### On d\u00e9finit un nouveau dataframe qui contiendra uniquement les features de scoring les plus importantes, et qui n'ont pas de valeurs NA :\nLes features de scoring sur les proportions\/100g ont \u00e9t\u00e9 enlev\u00e9es car elles sont couvertes par le nutrition score  ","20b8913a":"# Import des donn\u00e9es","ebcb0938":"# Affichage de fiches scoring des bons ingr\u00e9dients, avec images","2da1a0b6":"## Constats, parmi les produits qui contiennent les informations n\u00e9cessaire au scoring :\n* 1\/6 des produits comportent au moins 1 additif consid\u00e9r\u00e9 comme nocif (scoring 1)\n* La moiti\u00e9 des produits comportent plus de 4,5g de sucre \/100 (ils sont en dessous du scoring 5 pour le suc)\n* Un quart des produits comportent plus de 7g de graisses satur\u00e9es (scoring 1)\n* La moiti\u00e9 des produits ont plus de 7 ingr\u00e9dients\n(scoring 1 : > 10 ingr\u00e9dients, scoring 2 : > 7 ingr\u00e9dients)\n\nPour les valeurs associ\u00e9es aux diff\u00e9rents scoring on pourra se r\u00e9f\u00e9rer au notebook de cleaning","99820558":"## Focus sur les additifs, graisses, sucre, bio, et nombre d'ingr\u00e9dients :","62d6c574":"### Cat\u00e9gorie d'aliments \u00e0 proposer dans ce cas :","03def0ae":"## Repr\u00e9sentation des produits en 2 dimensions avec coloration nutrition score","4a85a0ab":"## Distribution des proportions d'\u00e9nergie\n### Dans les distributions ci-dessous, la barre verticale rouge d\u00e9limite les scorings tr\u00e8s mauvais","fd72ff8f":"## Diagramme de dispersion des quantit\u00e9s","d4f31066":"## Si on ne conserve que les aliments ayant nutrition scoring \u00e0 5 et bio scoring \u00e0 5, sans tenir compte du scoring sur le nombre d'ingr\u00e9dients  :\nNB : puisque le scoring bio \u00e0 5 implique dene pas avoir d'additif, on n'inclut pas les additifs nocifs dans ce cas"}}