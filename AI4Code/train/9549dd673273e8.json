{"cell_type":{"2b29cafb":"code","eb71d2f2":"code","b61b90d4":"code","eba2f4d2":"code","bf0782ee":"code","14094efd":"code","1bbf6450":"code","82fba4c5":"code","8d1b29cb":"code","24e69ce1":"code","5785d9e2":"code","a75eb0c2":"code","57667f69":"code","0efe31f8":"code","2bc5545e":"code","e141764c":"code","be73f5ec":"code","6e4af84e":"code","f88e5337":"code","cd05044a":"code","8a4ae80a":"code","15f37814":"code","72057cd8":"code","1b4ebbd5":"code","3ccad856":"code","15def315":"code","2f146c08":"code","ea5a9c5d":"code","ea924131":"code","b9552ac3":"markdown","6fd890b1":"markdown","37b79d86":"markdown","cc19cf84":"markdown","4e6656e1":"markdown","8ac133e5":"markdown","c7ee1994":"markdown","66eefc6f":"markdown","b0a31345":"markdown","2fe31456":"markdown","d1021e2e":"markdown","89132548":"markdown","d3a47dea":"markdown","41ac2c5e":"markdown"},"source":{"2b29cafb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')","eb71d2f2":"train = pd.read_csv('..\/input\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/test.csv', index_col='Id')","b61b90d4":"train.head()","eba2f4d2":"test.head()","bf0782ee":"missing = train.isnull().sum().sort_values(ascending=False)\nmissing= (missing[missing > 0] \/ train.shape[0])\nax = missing.round(3).plot.bar();\nax.set_title('% Missing values')\nvals = ax.get_yticks()\nax.set_yticklabels(['{:,.0%}'.format(x) for x in vals]);","14094efd":"plt.figure(figsize=(10,5));\ntrain.groupby('idhogar')['idhogar'].count().hist(bins=10);\nplt.title('Distribution of household size');\nplt.xlabel('Household size');","1bbf6450":"fig, (ax1, ax2) = plt.subplots(1, 2);\nsns.boxplot(x='Target', y='v2a1', data=train, ax=ax1);\nsns.boxplot(x='Target', y='v2a1', data=train[train.v2a1 < 2000000], ax=ax2);\nax1.set_title('With outlier');\nax2.set_title('Without outlier');\nax1.set_xlabel('Poverty level');\nax2.set_xlabel('Poverty level');\nax1.set_ylabel('Monthyl rent payment');\nax2.set_ylabel('');\nfig.suptitle('Distribution of monthly rent payment by poverty level', x=1, y=1, fontsize=16);\nfig.subplots_adjust(left=0.1, right=2, wspace=0.3);","82fba4c5":"train.groupby('Target')['v2a1'].median()","8d1b29cb":"train_by_hhid = train.groupby('idhogar')\nrm_by_id = train_by_hhid['Target', 'rooms'].first()\n\nplt.figure(figsize=(10, 5));\nsns.countplot(x='rooms', hue='Target', data=rm_by_id);\nplt.title('Distribution of rooms in house by poverty level');\nplt.xlabel('Number of rooms');","24e69ce1":"bathroom_by_id = train_by_hhid['Target', 'v14a', 'refrig'].first()\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nsns.countplot(x='v14a', hue='Target', data=bathroom_by_id, ax=ax1);\nsns.countplot(x='refrig', hue='Target', data=bathroom_by_id, ax=ax2);\nax1.set_xticklabels(['No', 'Yes']);\nax2.set_xticklabels(['No', 'Yes']);\nax1.set_xlabel('Has bathroom');\nax2.set_ylabel('Has Refrigerator');\nfig.subplots_adjust(left=0.1, right=2)\nfig.suptitle('Distribution of Bathrooms and Refrigerators by Poverty Level', x=1, y=1, fontsize=16);","5785d9e2":"fig, (ax1, ax2) = plt.subplots(1, 2);\nsns.boxplot(x='Target', y='meaneduc', data=train, ax=ax1);\nsns.violinplot(x='Target', y='meaneduc', data=train, ax=ax2);\n\nax1.set_xlabel('Poverty level');\nax2.set_xlabel('Poverty level');\nax1.set_ylabel('Mean years education');\nax2.set_ylabel('');\nfig.suptitle('Distribution of mean years education by poverty level', x=1, y=1, fontsize=16);\nfig.subplots_adjust(left=0.1, right=2, wspace=0.3);","a75eb0c2":"#outlier in test set which rez_esc is 99.0\ntest.loc[test['rez_esc'] == 99.0 , 'rez_esc'] = 5","57667f69":"# correct entries that were not delabeled as per discussion thread\nrelabel_cols = ['edjefe', 'edjefa', 'dependency']\n\ntrain[relabel_cols] = train[relabel_cols].replace({'yes':1, 'no':1}).astype(float)\ntest[relabel_cols] = test[relabel_cols].replace({'yes':1, 'no':1}).astype(float)","0efe31f8":"# set monthly rent payment to 0 where hh owns home\ntrain.loc[train.tipovivi1 == 1, 'v2a1'] = 0\ntest.loc[test.tipovivi1 == 1, 'v2a1'] = 0","2bc5545e":"# dictionary of columns and aggregation method\nagg_dict = {'escolari':np.sum, 'rez_esc':np.sum, 'age':np.sum, 'estadocivil1':np.sum}\n\n# group by household and apply aggregtion methods\ntrain_by_hh = train.groupby('idhogar').agg(agg_dict)\ntest_by_hh = test.groupby('idhogar').agg(agg_dict)\n\n# join household level data with individual level data\ntrain = train.join(train_by_hh, on='idhogar', rsuffix='_hh')\ntest = test.join(test_by_hh, on='idhogar', rsuffix='_hh')","e141764c":"# per capita monthly rent\ntrain['rent_per_cap'] = train['v2a1'] \/ train['tamhog']\ntest['rent_per_cap'] = test['v2a1'] \/ test['tamhog']\n\n# per capital tablets\ntrain['tab_per_cap'] = train['v18q'] \/ train['tamhog']\ntest['tab_per_cap'] = test['v18q'] \/ test['tamhog']\n\n# male-female ratio of hh\ntrain['mf_rat'] = train['r4h3'] \/ train['r4m3']\ntest['mf_rat'] = test['r4h3'] \/ test['r4m3']\n\ntrain['walls_roof_bad'] = train['epared1'] + train['eviv1']\ntest['walls_roof_bad'] = test['epared1'] + test['eviv1']\n\n# percent of hh under 12 years old\ntrain['child_perc'] = ( train['r4h1'] + train['r4m1'] ) \/ train['r4t3']\ntest['child_perc'] = ( test['r4h1'] + test['r4m1'] ) \/ test['r4t3']\n\n#share of children under 19 that are 12 or under\ntrain['young_perc'] = train['r4t1'] \/ train['hogar_nin']\ntest['young_perc'] = test['r4t1'] \/ test['hogar_nin']\n\n#number of children per adult\ntrain['child_per_adult'] = train['hogar_nin'] \/ train['hogar_adul']\ntest['child_per_adult'] = test['hogar_nin'] \/ test['hogar_adul']\n\n# number of 65+ as percent of total\ntrain['older_perc'] = train['hogar_mayor'] \/ train['tamviv']\ntest['older_perc'] = test['hogar_mayor'] \/ test['tamviv']\n\n# difference between number of poeple living in hh and hh members\ntrain['tamdiff'] = train['tamhog'] - train['tamviv']\ntest['tamdiff'] = test['tamhog'] - test['tamviv']\n\n## hh has computer and\/or television\ntrain['comp_tv'] = train['computer'] + train['television']\ntest['comp_tv'] = test['computer'] + test['television']","be73f5ec":"# replace NaNs in train and test data with -1\ntrain.fillna(-1, inplace=True)\ntest.fillna(-1, inplace=True)\n\ntrain.replace([np.inf, -np.inf], -1, inplace=True)\ntest.replace([np.inf, -np.inf], -1, inplace=True)","6e4af84e":"# Create the feature and target arrays for sklearn\nkeep_cols = [col for col in train.columns if col[:3] != 'SQB']\nkeep_cols = [col for col in keep_cols if col not in ['idhogar', 'agesq', 'Target']]\n\nX = train.loc[:, keep_cols].values\ny = train.Target.values\n\nX_test = test.loc[:, keep_cols].values","f88e5337":"gbm = GradientBoostingClassifier(n_estimators=100).fit(X,y)","cd05044a":"fi = pd.DataFrame({\n    'importance':gbm.feature_importances_.round(5)\n}, index=train.loc[:, keep_cols].columns)\n\nfi.sort_values('importance', ascending=False, inplace=True)\n\nfi.iloc[1:30, ].plot.bar(legend=None, figsize=(17,5));\nplt.title('Feature Importance');","8a4ae80a":"skf = StratifiedKFold(n_splits=3)\nskf.split(X, y)","15f37814":"logmod = LogisticRegression(class_weight='balanced')\n\nparam_grid = { 'C': [0.5, 1] }\n\nlog_grid = GridSearchCV(logmod, cv=skf, param_grid=param_grid, scoring='f1_macro')\nlog_grid.fit(X, y);","72057cd8":"print(log_grid.best_params_)\nprint(log_grid.best_score_)","1b4ebbd5":"params = {\n    'learning_rate': [0.01, 0.1],\n    'max_depth': [3, 4, 5, 6],\n    'n_estimators': [500, 1000],\n    'colsample_bytree':[0.5, 1],\n}","3ccad856":"lgb_mod = lgb.LGBMClassifier(class_weight='balanced')\n\nlgbm_grid = GridSearchCV(estimator=lgb_mod, cv=skf, param_grid=params, scoring='f1_macro', verbose=1, n_jobs=2)\nlgbm_grid.fit(X, y);","15def315":"print('Best lightgbm parameters: {}'.format(lgbm_grid.best_params_))\nprint('Best tuning score: {}'.format(lgbm_grid.best_score_))","2f146c08":"preds_log = log_grid.predict(X_test)\npreds_lgbm = lgbm_grid.predict(X_test)","ea5a9c5d":"# plot distribution of predictions from models\nplt.subplot(2, 2, 1)\nsns.countplot(y, color='red')\nplt.title('Distribution of Training Labels')\nplt.subplot(2, 2, 2)\nsns.countplot(preds_log, color='red')\nplt.title('Distribution of Logistic Predictions')\nplt.subplot(2, 2, 3)\nsns.countplot(preds_lgbm, color='red')\nplt.title('Distribution of LightGBM Predictions')\nplt.subplots_adjust(top=2, right=2)","ea924131":"# create final submission dataframe and write to csv\nsub_log = pd.DataFrame({'Id':test.index, 'Target':preds_log})\nsub_lgbm = pd.DataFrame({'Id':test.index, 'Target':preds_lgbm})\n\n#sub_log.to_csv('sub_log1.csv', index=False)\nsub_lgbm.to_csv('sub_lgbm1.csv', index=False)","b9552ac3":"Actually, poverty levels 2 and 3 have the same median monthly rent, at least in this particular sample of data.","6fd890b1":"It is not entirely clear from the boxplots, but it appears that the median monthly rent payment increases with poverty level. This makes sense as a higher numerical value for the poverty level actually indicates a lower level of poverty. Let's verify this by looking at the medians be poverty level:","37b79d86":"The next two variables - 'v14a' and 'refrig' - indicate whether the individual lives in a house with a bathroom or a refrigerator respectively. Let's take a look at the distribution of these across poverty types. ","cc19cf84":"## Modeling","4e6656e1":"The next variable in the data set, 'rooms', is the total number of rooms in the individual's house. Let's take a look at how rooms are distributed by poverty level. Since this is individual level data, not household level, we'll first need to group by the household id 'idhogar', otherwise, we will be double-counting. ","8ac133e5":"Let's move on to exploring some of the features. The data set has an id for each person as well as for each household. We can get the number of people by household by grouping by the household id ('idhogar') and getting a count. Here I do so and then plot a histogram:","c7ee1994":"Here we see that for poverty level 4 (non-vulnerable) the most common number of rooms is 5. There are also a significant number of non-vulnerable houses with 7-11 rooms. For poverty levels 1, 2, and 3 (moderate and vulnerable) the most common number of rooms is 4. In the homes with only 1 or 2 rooms, there are a significant number of households in each poverty level. This indicates that the number of rooms alone may not be great at discerning poverty levels in the lower extreme. ","66eefc6f":"## Feature Engineering","b0a31345":"Let's wrap up by running a quick GBM model to get the feature importances:","2fe31456":"I like to check for missing values in a data set before I start the exploratory analysis. A large number of missing values in a particular feature can sometimes lead to erroneous conclusions when looking at summary statistics. ","d1021e2e":"For now, let's just replace NaNs with -1. ","89132548":"Let's look at the first feature 'v2a1' or monthly rent payment. How is monthly rent distributed among the four poverty levels? Due to the presence of a possible outlier in in monthly rent payment, the box plots get squished vertically. I've plotted them with and without the outlier. ","d3a47dea":"Fortunately, only five of the features have any missing values in the training data. Of these only three have a large number of missing values. These are:\n* 'rez_esc' - year behind in schooling\n* 'v18q1' - owns a tablet\n* 'v2a1' - monthly rent payments\n\nBecause there are so many missing points in these features, we'd probably want to encode them somehow rather than attempt to impute them. The remaining two:\n* 'meaneduc' - average years of education for adults\n* 'SQBmeaned' - square of the mean years of education of adults\n\nonly have a few points missing, so we might try to impute them using the mean or median for example. ","41ac2c5e":"## Exploratory Analysis"}}