{"cell_type":{"efe1b4e2":"code","d9a58de1":"code","aa703e08":"code","7f85251d":"code","a4687417":"code","6261c7ce":"code","75b1b8aa":"code","a3a80a38":"code","2e6e031f":"code","c719f89d":"code","2f431bbb":"code","8d60d58f":"code","2b7d1336":"code","6d30d712":"code","bcb993a4":"code","3ef6c63b":"code","52db8c3d":"code","a67fb934":"code","d0b18ee4":"code","bac28514":"code","27e1b1c0":"code","8e23bbd0":"code","71e03924":"code","c677c87b":"code","933fb104":"code","57a6c084":"markdown","186549b1":"markdown","713c9c65":"markdown","12f75673":"markdown","4246f8c2":"markdown","d126c090":"markdown"},"source":{"efe1b4e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9a58de1":"#Extracting the dataset\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","aa703e08":"print(\"Number of training samples: \",len(train[\"Survived\"]))\nprint(\"Number of features: \",len(train.columns))\nprint(\"Number of Survivors: \",len(train[train[\"Survived\"]==1]))\nprint(\"Number of Non-Survivors: \",len(train[train[\"Survived\"]==0]))","7f85251d":"#Visualizing Age feature using histograms\nimport matplotlib.pyplot as plt\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==1][\"Age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 45,\"Survived = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==0][\"Age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 75,\"Survived = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","a4687417":"from sklearn.preprocessing import KBinsDiscretizer\n\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\ndiscretizer_age = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='kmeans')\nage_discretized = discretizer_age.fit_transform(train[[\"Age\"]])\nlen(age_discretized)\ndf_age = pd.DataFrame(age_discretized,columns=['Age'])\ndf_age.info()","6261c7ce":"#Visualizing ticket fare\nimport matplotlib.pyplot as plt\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==1][\"Fare\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of fare')\nplt.text(23, 45,\"Survived = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==0][\"Fare\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of fare')\nplt.text(23, 75,\"Survived = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","75b1b8aa":"#Visualizing Pclass\nimport seaborn as sns\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Pclass\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Pclass\", data=train[train[\"Survived\"]==0])","a3a80a38":"#Visualizing Sex feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Sex\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Sex\", data=train[train[\"Survived\"]==0])","2e6e031f":"#Visualizing Embarked feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Embarked\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Embarked\", data=train[train[\"Survived\"]==0])","c719f89d":"#Visualizing SibSp(# of siblings or spouses) and parch(# of parents or children)\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"SibSp\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"SibSp\", data=train[train[\"Survived\"]==0])","2f431bbb":"#Visualizing Parch(# of parents or siblings)\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Parch\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Parch\", data=train[train[\"Survived\"]==0])","8d60d58f":"#Combining Parch and SibSp and analyzing\n\ntrain[\"SibSpParCh\"] = train[\"SibSp\"] + train[\"Parch\"]\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"SibSpParCh\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"SibSpParCh\", data=train[train[\"Survived\"]==0])","2b7d1336":"train[\"Alone\"] = train[\"SibSpParCh\"] > 0","6d30d712":"#Visualizing Alone feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Alone\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Alone\", data=train[train[\"Survived\"]==0])","bcb993a4":"#Extracting title from the passenger name\n\ntitle = np.zeros((len(train[\"Name\"]),)).astype(str)\nfor i in range(len(train[\"Name\"])):\n    title[i] = train[\"Name\"][i].split(',')[1].split(' ')[1]\npd_title = pd.DataFrame(title,columns=['Title'])\ntrain = pd.concat([train,pd_title],axis=1)\nprint(train.Title.unique())\n\ntrain[\"Title\"].replace('Ms.','Miss.',inplace=True)\ntrain[\"Title\"].replace(['Don.', 'Rev.', 'Dr.', 'Mme.',  'Major.',\n 'Lady.', 'Sir.', 'Mlle.', 'Col.', 'Capt.', 'the', 'Jonkheer.'],'Other',inplace=True)\nprint(train.Title.unique())\ntrain[\"Title\"]\n\n#Visualizing\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Title\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Title\", data=train[train[\"Survived\"]==0])","3ef6c63b":"#Encoding the categoircal features\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncategorical_cols = [\"Embarked\",\"Sex\",\"Alone\",\"Title\"]\ntrain[categorical_cols] = train[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\ntrain.head()","52db8c3d":"features = [\"Pclass\",\"Embarked\",\"Sex\",\"Alone\",\"Fare\",\"Title\"]\nX_train = train[features]\nX_train = pd.concat([X_train,df_age],axis=1)\nY_train = train[\"Survived\"]\nX_train.info()\nX_train\n#np.any(np.isnan(X_train[\"Age\"]))","a67fb934":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\n\nsvm = SVC(C=1,kernel='rbf')\ngb = GradientBoostingClassifier(loss='exponential')\nlr = LogisticRegression()\ndecision_tree = DecisionTreeClassifier()\nrandom_forest = RandomForestClassifier(n_estimators=100)\nresult = cross_validate(gb,X_train_scaled,Y_train,scoring = ('accuracy','f1'), cv = 3, return_train_score=True)\n\nprint(\"Train Accuracy Score: \",result[\"train_accuracy\"].mean())\nprint(\"Test Accuracy Score: \",result[\"test_accuracy\"].mean())\nprint(\"Train F1 Score: \",result[\"train_f1\"].mean())\nprint(\"Test F1 Score: \",result[\"test_f1\"].mean())","d0b18ee4":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","bac28514":"test[\"SibSpParCh\"] = test[\"SibSp\"] + test[\"Parch\"]\ntest[\"Alone\"] = test[\"SibSpParCh\"] > 0","27e1b1c0":"title = np.zeros((len(test[\"Name\"]),)).astype(str)\nfor i in range(len(test[\"Name\"])):\n    title[i] = test[\"Name\"][i].split(',')[1].split(' ')[1]\npd_title = pd.DataFrame(title,columns=['Title'])\ntest = pd.concat([test,pd_title],axis=1)\nprint(test.Title.unique())\n\ntest[\"Title\"].replace('Ms.','Miss.',inplace=True)\ntest[\"Title\"].replace(['Col.' ,'Rev.', 'Dr.', 'Dona.'],'Other',inplace=True)\nprint(test.Title.unique())\ntest[\"Title\"]","8e23bbd0":"test[categorical_cols] = test[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\ntest.head(50)","71e03924":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].mean())\nX_test = test[features]\nage_discretized = discretizer_age.transform(test[[\"Age\"]])\nlen(age_discretized)\ndf_age = pd.DataFrame(age_discretized,columns=['Age'])\nX_test = pd.concat([X_test,df_age],axis=1)\nX_test.info()","c677c87b":"X_test_scaled = ss.transform(X_test)\nmodel = SVC(C=1.0,kernel='rbf').fit(X_train_scaled,Y_train)\nY_predict = model.predict(X_test_scaled)","933fb104":"submission_df = pd.DataFrame({'PassengerId' : test[\"PassengerId\"],'Survived' : Y_predict})\nsubmission = submission_df.to_csv('submission.csv',index=False)","57a6c084":"We can see that more people in Pclass 1 and 2 survived than people in Pclass 3. Hence Pclass can be used for classification between survivors and non-survivors.","186549b1":"Parch and SibSp does not give much information of survival or non-survival, but we can use it to find other features like if the passenger was alone or not. ","713c9c65":"Sex is an important categorical feature because more of female survived than male.","12f75673":"Most of the passengers embarked from port S. ","4246f8c2":"We can deduce that passengers having more than 4 siblings or spouses didn't survive. ","d126c090":"We can see that Alone passengers were more likely to survive than others."}}