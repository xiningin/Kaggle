{"cell_type":{"1a676010":"code","1ecdaa1e":"code","94c27f0b":"code","274d3401":"code","6920240a":"code","53d75154":"code","bace3572":"code","21992ba2":"code","b3e07cec":"code","04afad01":"code","b531a3e9":"code","bb0d3afa":"code","cd2915cd":"code","d250a703":"code","cd9da930":"code","2d3ca7fa":"code","bf57f772":"code","d0515540":"code","47217f99":"code","77aa1c6b":"code","7355bf9d":"code","6538013e":"code","96f39911":"code","ed61b4a6":"code","681bd492":"code","40602f45":"code","a06ac80b":"code","2e3d3759":"code","5643853b":"code","d8a666fe":"code","09525339":"code","11c55311":"markdown","51ee9793":"markdown","1a109457":"markdown","26aa722d":"markdown","deffb835":"markdown","22c31e20":"markdown","78cc3361":"markdown","96fee845":"markdown","786a2a21":"markdown","84535542":"markdown","665c6c7c":"markdown","e4b82949":"markdown","83d86759":"markdown","1e3e6a7d":"markdown"},"source":{"1a676010":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Modeling and Prediction\nfrom fbprophet import Prophet\nfrom sklearn.metrics import r2_score, mean_absolute_error\n\nimport warnings\nwarnings.simplefilter('ignore')","1ecdaa1e":"# Set parameters\nN = 30\nforecasting_period = 2  # in time_intervals\nindicator_names = ['PM2.5', 'PM10']\nindicator_name = indicator_names[0]\ntype_agg='mean' # 'mean' or 'max'\ntime_interval = 'D' # day\nQ = 14  # 2 weeks = 14 days","94c27f0b":"datetime_analysis = '2021-11-27'  # maximum value after 2021-11-16","274d3401":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","6920240a":"len(dataset_files)","53d75154":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","bace3572":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","21992ba2":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","b3e07cec":"df.info()","04afad01":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","b531a3e9":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","bb0d3afa":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample(time_interval).mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","cd2915cd":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","d250a703":"df2.info()","cd9da930":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","2d3ca7fa":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","bf57f772":"df.info()","d0515540":"df.describe()","47217f99":"# Selection data for interpolation\nif type_agg == 'mean':\n    data = df[df['ds']==datetime.datetime.fromisoformat(datetime_analysis)].reset_index(drop=True)\nelse:\n    #type_agg == 'max':\n    datetime_analysis = 'all time'\n    data = df.copy()\n    \nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","77aa1c6b":"number_steps_in_day = 24 if time_interval=='H' else 1","7355bf9d":"def get_data_for_prediction(df, id_station_name, num_last_data=30):\n    # Get data for given id_station_name with the last num_last_data data\n    #id_station_name = 'EcoCity_848'\n    df_i = df[df['id_station']==id_station_name]\n    df_i = df_i[(len(df_i)-num_last_data):].reset_index(drop=True)\n    display(df_i['value'].describe())\n    print(len(df_i))\n    return df_i","6538013e":"def plot_with_anomalies(df, cols_y_list, cols_y_list_name, dates_x, anomalous_dates, log_y=False):\n    # Thanks to https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality\n    # Draws a plot with title - the features cols_y_list (y) and dates_x (x) from the dataframe df\n    # and with vertical lines in the dates from the list anomalous_dates\n    # with the length between the minimum and maximum of feature cols_y_list[0]\n    # with log_y = False or True\n    # cols_y_list - dictionary of the names of cols from cols_y_list (keys - name of feature, value - it's name for the plot legend), \n    # name of cols_y_list[0] is the title of the all plot\n    \n    fig = px.line(df, x=dates_x, y=cols_y_list[0], title=cols_y_list_name[cols_y_list[0]], log_y=log_y, template='gridon',width=800, height=600)\n    y_max = df[cols_y_list[0]].max()\n    for i in range(len(cols_y_list)-1):\n        fig.add_trace(go.Scatter(x=df[dates_x], y=df[cols_y_list[i+1]], mode='lines', name=cols_y_list_name[cols_y_list[i+1]]))\n        max_i = df[cols_y_list[i+1]].max()\n        y_max = max_i if max_i > y_max else y_max\n    \n    y_min = min(df[cols_y_list[0]].min(),0)\n    for i in range(len(anomalous_dates)):\n        anomal_date = anomalous_dates[i]\n        #print(anomal_date, y_min, y_max)\n        fig.add_shape(dict(type=\"line\", x0=anomal_date, y0=y_min, x1=anomal_date, y1=y_max, line=dict(color=\"red\", width=1)))\n    fig.show()","96f39911":"def get_model_err(df, res, model, id_station_name, forecasting_period,\n                 Q_order, weekly_order, monthly_order, quarterly_order):\n    # Data prediction and score calculation\n    \n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n        \n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n    \n    # Calculation r2_score (accuracy of prediction for training data)\n    r2 = round(r2_score(df['y'], y_pred),2)\n    mae_err = round(mean_absolute_error(df['y'], y_pred),2)\n    \n    # Save results\n    if res.empty:\n        num = 0\n    else: num = len(res)\n    res.loc[num, 'id_station'] = id_station_name\n    res.loc[num, 'Q_order'] = Q_order\n    res.loc[num, 'weekly_order'] = weekly_order\n    res.loc[num, 'monthly_order'] = monthly_order\n    res.loc[num, 'quarterly_order'] = quarterly_order\n    res.loc[num, 'r2_score'] = r2\n    res.loc[num, 'mae'] = mae_err\n    print(id_station_name, Q_order, weekly_order, monthly_order, quarterly_order, r2, mae_err)\n    #display(res)\n    \n    # Draw plot of the values with forecasting data\n    #label_str = \" - \".join([id_station_name, indicator_name, str(Q_order), str(daily_order), str(weekly_order), str(quarterly_order), str(r2), str(mae_err)])\n    #figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n    \n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    #figure_component = model.plot_components(forecast)    \n\n    return res","ed61b4a6":"def Prophet_tuning(df, anomalous, number_steps_in_day, Q_order, weekly_order, monthly_order, quarterly_order):\n    # Prophet tuning\n\n    model = Prophet(daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=False, \n                    changepoint_range=1, changepoint_prior_scale = 0.5, \n                    holidays=anomalous, seasonality_mode = 'multiplicative')\n\n    if (weekly_order > 0):\n        model.add_seasonality(name='weekly', period=7*number_steps_in_day, \n                              fourier_order=weekly_order, mode = 'multiplicative')\\\n        \n    if (Q_order > 0):\n        model.add_seasonality(name='Q_days', period=Q, \n                              fourier_order=Q_order, mode = 'multiplicative')\n        \n    if (monthly_order > 0):\n        model.add_seasonality(name='monthly', period=1*number_steps_in_day, \n                              fourier_order=monthly_order, mode = 'multiplicative')\n\n    if (quarterly_order > 0):\n        model.add_seasonality(name='quarterly', period=365.25\/12*4*number_steps_in_day, \n                              fourier_order=quarterly_order, mode = 'multiplicative')\n    model.fit(df)\n\n    return model","681bd492":"def model_tuning(res, df, anomalous, id_station_name, number_steps_in_day, forecasting_period):\n    # Prophet model with parameters and structure tuning\n    \n    Q_order_from = -1\n    monthly_order_from = -1\n    weekly_order_from = -1\n    quarterly_order_from = -1\n    \n    Q_order_to = 0\n    monthly_order_to = 0\n    weekly_order_to = 0\n    quarterly_order_to = 0\n    \n    order_min = 3\n    order_max = 6\n    \n    if len(df)\/number_steps_in_day > 31*4*2:\n        # All data more 2 quarters\n        quarterly_order_from = order_min\n        quarterly_order_to = order_max\n\n    if len(df)\/number_steps_in_day > 7*2:\n        # All data more 2 weeks\n        weekly_order_from = order_min\n        weekly_order_to = order_max\n\n    if len(df)\/number_steps_in_day > 2:\n        # All data more 2 days\n        daily_order_from = order_min\n        daily_order_to = order_max        \n\n    if len(df) > 2*Q:\n        # All data more Q hours\n        Q_order_from = order_min\n        Q_order_to = order_max        \n\n    print(Q_order_from, daily_order_from, weekly_order_from, quarterly_order_from)\n    print(Q_order_to, daily_order_to, weekly_order_to, quarterly_order_to)\n\n    for i0 in range(weekly_order_to-weekly_order_from):\n        weekly_order = weekly_order_from + i0\n        \n        for i1 in range(Q_order_to-Q_order_from):\n            Q_order = Q_order_from + i1\n\n            for i2 in range(monthly_order_to-monthly_order_from):\n                monthly_order = monthly_order_from + i2\n\n                for i3 in range(quarterly_order_to-quarterly_order_from):\n                    quarterly_order = quarterly_order_from + i3\n\n                    print(Q_order, weekly_order, monthly_order, quarterly_order, Q_order)\n                    model = Prophet_tuning(df, anomalous, number_steps_in_day, Q_order, \n                                           weekly_order, monthly_order, quarterly_order)\n\n                    # Training err for prediction by the model                \n                    res = get_model_err(df, res, model, id_station_name, forecasting_period,\n                             Q_order, weekly_order, monthly_order, quarterly_order)\n    \n    #print('model_tuning')\n    #display(res)\n    return res","40602f45":"def prophet_pred(res, df, id_station_name, number_steps_in_day, threshold_min, forecasting_period):\n    \n    # Data preparation \n    df = df[['ds', 'value']].reset_index(drop=True)\n    df.columns = ['ds', 'y']\n    \n    # Get anomalous\n    df_abnorm = df[(df['y'] >= np.quantile(df['y'], threshold_min))]\n    anomalous_dates = df_abnorm['ds'].astype('str').tolist()\n    anomalous = pd.DataFrame({\n                              'holiday': 'anomalous',\n                              'ds': pd.to_datetime(anomalous_dates),\n                              'lower_window': 0,\n                              'upper_window': 0,\n                              'prior_scale': 20,\n                            })\n                            \n    plot_with_anomalies(df, [\"y\"], {\"y\" : f\"Anomalous dates with data of {indicator_name}\"}, 'ds', anomalous_dates, False)\n    \n    # Modeling and Visualization\n    # Model tuning\n    res = model_tuning(res, df, anomalous, id_station_name, number_steps_in_day, forecasting_period)\n    \n    # Resiults display \n    res_i = res[res['id_station']==id_station_name].sort_values(by=['mae'], ascending=True)\n    display(res_i)\n    \n    # Prediction with OPTIMAL parameters\n    model = Prophet_tuning(df, anomalous, number_steps_in_day, \n                           int(res_i.head(1)['Q_order']), \n                           int(res_i.head(1)['weekly_order']), \n                           int(res_i.head(1)['monthly_order']), \n                           int(res_i.head(1)['quarterly_order']))\n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n\n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n\n    # Draw plot of the values with forecasting data\n    label_str = \" - \".join([id_station_name, indicator_name])\n    figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n\n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    figure_component = model.plot_components(forecast)\n    \n    return res","a06ac80b":"id_station_list = df['id_station'].unique().tolist()\nid_station_list","2e3d3759":"for id_st in id_station_list:\n    df_i = df[df['id_station']==id_st]\n    df_i = df_i[(len(df_i)-10*24):]\n    print(id_st, int(len(df_i)\/number_steps_in_day))\n    df_i['value'].plot()\n    plt.show()\n    display(df_i.head(1))\n    display(df_i.tail(1))","5643853b":"# Staions with good series in November 2021\nid_station_best_list = ['EcoCity_337', 'EcoCity_848', 'EcoCity_1315']\n#id_station_best_list = ['EcoCity_337']\nid_station_best_list","d8a666fe":"%%time\nres = pd.DataFrame(columns = ['id_station', 'Q_order', 'weekly_order', 'monthly_order', 'quarterly_order', \n                              'r2_score', 'mae'])\nfor id_station_name in id_station_best_list:\n    print(id_station_name)\n    df1 = get_data_for_prediction(df, id_station_name, num_last_data=N)\n        \n    # The main calculation\n    res = prophet_pred(res, df1, id_station_name, number_steps_in_day, threshold_min=0.95, forecasting_period=forecasting_period)","09525339":"# Results display\nprint(f'Q_order = {Q}_days_order')\ndisplay(res)","11c55311":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Selection data for interpolation](#2.3)\n1. [Data prediction](#3)\n   - [Prediction functions](#3.1)\n   - [Selection parameters](#3.2)\n   - [Prediction results](#3.3)","51ee9793":"## Acknowledgements\n\n### Notebooks:\n* [Air Quality Station - Daily Forecasting - Prophet](https:\/\/www.kaggle.com\/vbmokin\/air-quality-station-daily-forecasting-prophet)\n* [Air Quality City - Stations data prediction](https:\/\/www.kaggle.com\/vbmokin\/air-quality-city-stations-data-prediction)\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","1a109457":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","26aa722d":"### 3.1. Prediction functions <a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","deffb835":"### 2.3 Selection data for interpolation<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","22c31e20":"## I plan to implement in the future:\n* Download today data from API (SaveEcoBot and Center for Hydrometeorology in Vinnytsia region)\n* Download of state (Center for Hydrometeorology in Vinnytsia region) monitoring data\n* Calculation AQI (Air Quality Index)\n* export optimal parameters of prediction model for each monitoring station to csv-file\n* export results to csv-files","78cc3361":"### 3.2. Selection parameters <a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","96fee845":"## 3. Data prediction<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","786a2a21":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","84535542":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","665c6c7c":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality in Vinnytsia city - Daily data forecasting:\n* Download of public (from SaveEcoBot and EcoCity) monitoring data\n* 2 indicators: PM2.5, PM10\n* prediction data in each monitoring station with tuning parameters\n* definition of average or maximum values for daily data","e4b82949":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","83d86759":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","1e3e6a7d":"### 3.3. Prediction results <a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}