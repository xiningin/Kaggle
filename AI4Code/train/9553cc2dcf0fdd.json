{"cell_type":{"0105616f":"code","fba25180":"code","2b5758fe":"code","5e956b93":"code","3865f3ab":"code","1d4ff9ca":"code","ca3ab9c7":"code","323b2fcd":"code","6a96df3c":"code","d81fd98d":"code","ccc72ee4":"code","b8728d3f":"code","b2e87714":"code","b88b5968":"code","75fc6dc1":"code","017b0c6e":"code","41a9ee5e":"code","616d57c9":"code","e92aa926":"code","fef852cb":"code","7a4f20d3":"code","54603088":"code","20893d78":"code","8c4f83b7":"code","cc23dcd0":"code","5b21cc3e":"code","1badcfe9":"code","0ee4eed0":"code","7e99e443":"code","928584f8":"markdown","31229ab8":"markdown","0b2a20db":"markdown","02d8ee49":"markdown"},"source":{"0105616f":"from fastai.vision.all import *\nimport gc","fba25180":"datapath = Path(\"\/kaggle\/input\/hubmap-kidney-segmentation\/\")","2b5758fe":"img_files = get_files(datapath\/'train', extensions=['.tiff'])\ntest_img_files = get_files(datapath\/'test', extensions=['.tiff'])","5e956b93":"trn_map = dict(zip(img_files.map(lambda o:o.name), ['train']*len(img_files)))\ntest_map = dict(zip(test_img_files.map(lambda o:o.name), ['test']*len(img_files)))\ntrn_test_map = {**trn_map, **test_map}","3865f3ab":"unique_ids = img_files.map(lambda o: o.stem.split(\"_\")[0]).unique(); unique_ids","1d4ff9ca":"train_df = pd.read_csv(datapath\/'train.csv')\nmeta_df = pd.read_csv(datapath\/'HuBMAP-20-dataset_information.csv')","ca3ab9c7":"meta_df['split'] = meta_df['image_file'].map(trn_test_map)","323b2fcd":"meta_df.sort_values('patient_number')","6a96df3c":"meta_df.groupby(['patient_number','image_file', 'split'])[['split']].count()","d81fd98d":"def enc2mask(encs, shape):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for m,enc in enumerate(encs):\n        if isinstance(enc,np.float) and np.isnan(enc): continue\n        s = enc.split()\n        for i in range(len(s)\/\/2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1 + m\n    return img.reshape(shape).T\n\ndef rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_grid(shape, window=1024, min_overlap=32):\n    \"\"\"\n        Return Array of size (N,4), where N - number of tiles,\n        2nd axis represente slices: x1,x2,y1,y2 \n    \"\"\"\n#     import pdb; pdb.set_trace()\n    x, y = shape\n    nx = x \/\/ (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    \n    ny = y \/\/ (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    \n    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n    \n    for i in range(nx):\n        for j in range(ny):\n            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx*ny,4)","ccc72ee4":"import rasterio\nfrom rasterio.windows import Window\nimport cv2\n\nWINDOW = 1536\nMIN_OVERLAP = 128\nNEW_SIZE = 512","b8728d3f":"# image datasets\nidentity = rasterio.Affine(1, 0, 0, 0, 1, 0)\nid2dataset = {_id : rasterio.open(datapath\/'train'\/f\"{_id}.tiff\", transform=identity) for _id in unique_ids}\n\n# image masks\nid2rle = dict(zip(train_df['id'], train_df['encoding']))\nid2mask = {_id:enc2mask([rle], id2dataset[_id].shape[::-1]) for _id,rle in id2rle.items()}\n\n# (dataset id, slices array)\nid_slices = []\nfor _id, dataset in id2dataset.items():\n    slices = make_grid(dataset.shape, window=WINDOW, min_overlap=MIN_OVERLAP)\n    id_slices += list(zip([_id]*len(slices), slices))","b2e87714":"plt.imshow(id2mask['2f6ecfcdf'][7000:8500, 15000:16500])","b88b5968":"image = id2dataset['2f6ecfcdf'].read([1,2,3], window=Window.from_slices((7000,8500), (15000,16500)))\nTensorImage(tensor(image)).show()","75fc6dc1":"id_slices[:10], len(id_slices)","017b0c6e":"# tfms\ndef read_tile(i, id_slices):\n    _id, (x1,x2,y1,y2) = id_slices[i]\n    image = id2dataset[_id].read([1,2,3], window=Window.from_slices((x1,x2),(y1,y2)))\n    image = np.moveaxis(image, 0, -1)\n    image = cv2.resize(image, (NEW_SIZE, NEW_SIZE),interpolation = cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    image = (image2tensor(image)\/255.)\n    return TensorImage(image)\n\n\ndef read_mask(i, id_slices):\n    _id, (x1,x2,y1,y2) = id_slices[i]\n    mask = id2mask[_id][x1:x2, y1:y2]\n    mask = cv2.resize(mask, (NEW_SIZE, NEW_SIZE), interpolation=cv2.INTER_NEAREST)\n    return TensorMask(mask)","41a9ee5e":"items = range(len(id_slices))\ndsets = Datasets(items, \n                 tfms=[[partial(read_tile, id_slices=id_slices)], \n                       [partial(read_mask, id_slices=id_slices)]]\n                )\nlen(dsets)","616d57c9":"dls = dsets.dataloaders(bs=4,     \n                        batch_tfms=[Dihedral(p=0.5), \n                            Rotate(p=0.5, max_deg=30), \n                            Brightness(p=0.5, max_lighting=0.3, batch=False)],\n                        splits=RandomSplitter(0.1)(items))","e92aa926":"xb,yb = dls.one_batch()","fef852cb":"xb.shape, yb.shape","7a4f20d3":"# https:\/\/github.com\/fastai\/fastai\/issues\/3041\ndef flatten_check(inp, targ):\n    \"Check that `out` and `targ` have the same number of elements and flatten them.\"\n    inp,targ = inp.contiguous().view(-1),targ.contiguous().view(-1)\n    test_eq(len(inp), len(targ))\n    return inp,targ\n    \nclass Dice(Metric):\n    \"Dice coefficient metric for binary target in segmentation\"\n    def __init__(self, thresh=0.5): store_attr()\n    def reset(self): self.inter,self.union = 0,0\n    def accumulate(self, learn):\n        pred,targ = flatten_check(learn.pred.sigmoid().squeeze(1)>self.thresh, learn.y)\n        pred, targ = TensorBase(pred), TensorBase(targ)\n        self.inter += (pred*targ).float().sum().item()\n        self.union += (pred+targ).float().sum().item()\n\n    @property\n    def value(self): return 2. * self.inter\/self.union if self.union > 0 else None","54603088":"loss_func = BCEWithLogitsLossFlat()","20893d78":"sqrmom=0.99\nmom=0.95\nbeta=0.\neps=1e-4\nopt_func = partial(ranger, mom=mom, sqr_mom=sqrmom, eps=eps, beta=beta)","8c4f83b7":"learner = unet_learner(dls,\n                       xresnet34,\n                       loss_func=loss_func,\n                       opt_func=opt_func,\n                       metrics=[Dice(thresh=0.5)], \n                       normalize=False, \n                       pretrained=False,\n                       n_out=1)\nlearner.to_native_fp16(); # little bit faster compared to fp_16() - thanks to ilovescience's experiments","cc23dcd0":"learner.fit_flat_cos(1)","5b21cc3e":"%debug","1badcfe9":"ds = rasterio.open(\"\/kaggle\/input\/hubmap-kidney-segmentation\/train\/cb2d976f4.tiff\")","0ee4eed0":"ds.read([1,2,3], window=((0,100), (0,100)))","7e99e443":"for FOLD in range(8):\n    dls = get_dls(FOLD)\n    learner = get_learner(dls)\n    learner.fit_flat_cos(30, lr=1e-3, cbs=[SaveModelCallback(\"dice\", fname=f'xresunet34_fold{FOLD}')])\n    del learner\n    gc.collect()","928584f8":"Here I preferred softmax since using argmax is easier than setting a threhsold after sigmoid. To my knowledge and the papers I have seen in medical domain says that ImageNet transfer learning help close to nothing, so I will ignore it here to keep things clean and simple.","31229ab8":"### Model","0b2a20db":"### Utils","02d8ee49":"### Datasets"}}