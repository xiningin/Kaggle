{"cell_type":{"ed0eed84":"code","4716ea42":"code","5c6faef1":"code","804a5ffe":"code","6af21ca9":"code","b1e6b58b":"code","decedd55":"code","47b911c2":"code","2b3da59f":"code","47067887":"code","deb760ed":"code","4822f371":"code","5caecf41":"code","8f756c94":"code","61db66b4":"code","3965dcea":"code","26b731b4":"code","32e73cc9":"code","671f91bd":"code","abaf4993":"code","ae1caeca":"markdown","5514a5f3":"markdown","28842460":"markdown","62ee9124":"markdown","4bdd4bd7":"markdown","f75b5293":"markdown","effe1789":"markdown","cf669c4d":"markdown","d8fffdb3":"markdown"},"source":{"ed0eed84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom pathlib import Path\nfrom xml.dom.minidom import parse\nfrom shutil import copyfile\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n    #    print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4716ea42":"!mkdir -p Dataset\/labels\n!mkdir -p Dataset\/images","5c6faef1":"classes = ['helmet','head','person']","804a5ffe":"def convert_annot(size , box):\n    x1 = int(box[0])\n    y1 = int(box[1])\n    x2 = int(box[2])\n    y2 = int(box[3])\n\n    dw = np.float32(1. \/ int(size[0]))\n    dh = np.float32(1. \/ int(size[1]))\n\n    w = x2 - x1\n    h = y2 - y1\n    x = x1 + (w \/ 2)\n    y = y1 + (h \/ 2)\n\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return [x, y, w, h]\n","6af21ca9":"def save_txt_file(img_jpg_file_name, size, img_box):\n    save_file_name = '\/kaggle\/working\/Dataset\/labels\/' +  img_jpg_file_name + '.txt'\n    print(save_file_name)\n    #file_path = open(save_file_name, \"a+\")\n    with open(save_file_name ,'a+') as file_path:\n        for box in img_box:\n\n            cls_num = classes.index(box[0])\n\n            new_box = convert_annot(size, box[1:])\n\n            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n\n        file_path.flush()\n        file_path.close()","b1e6b58b":"def get_xml_data(file_path, img_xml_file):\n    img_path = file_path + '\/' + img_xml_file + '.xml'\n    #print(img_path)\n\n    dom = parse(img_path)\n    root = dom.documentElement\n    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n    img_size = root.getElementsByTagName(\"size\")[0]\n    objects = root.getElementsByTagName(\"object\")\n    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n   \n    img_box = []\n    for box in objects:\n        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n        \n        img_jpg_file_name = img_xml_file + '.jpg'\n        img_box.append([cls_name, x1, y1, x2, y2])\n  \n\n    # test_dataset_box_feature(img_jpg_file_name, img_box)\n    save_txt_file(img_xml_file, [img_w, img_h], img_box)","decedd55":"!ls \/kaggle\/working\/Dataset\/labels","47b911c2":"files = os.listdir('\/kaggle\/input\/hard-hat-detection\/annotations')\nfor file in files:\n    print(\"file name: \", file)\n    file_xml = file.split(\".\")\n    print(file_xml[0])\n    get_xml_data('\/kaggle\/input\/hard-hat-detection\/annotations', file_xml[0])","2b3da59f":"from sklearn.model_selection import train_test_split\nimage_list = os.listdir('\/kaggle\/input\/hard-hat-detection\/images')\ntrain_list, test_list = train_test_split(image_list, test_size=0.2, random_state=42)\nval_list, test_list = train_test_split(test_list, test_size=0.5, random_state=42)\nprint('total =',len(image_list))\nprint('train :',len(train_list))\nprint('val   :',len(val_list))\nprint('test  :',len(test_list))","47067887":"def copy_data(file_list, img_labels_root, imgs_source, mode):\n\n    root_file = Path( '\/kaggle\/working\/Dataset\/images\/'+  mode)\n    if not root_file.exists():\n        print(f\"Path {root_file} does not exit\")\n        os.makedirs(root_file)\n\n    root_file = Path('\/kaggle\/working\/Dataset\/labels\/' + mode)\n    if not root_file.exists():\n        print(f\"Path {root_file} does not exit\")\n        os.makedirs(root_file)\n\n    for file in file_list:               \n        img_name = file.replace('.png', '')        \n        img_src_file = imgs_source + '\/' + img_name + '.png'        \n        label_src_file = img_labels_root + '\/' + img_name + '.txt'\n\n        #print(img_sor_file)\n        #print(label_sor_file)\n        # im = Image.open(rf\"{img_sor_file}\")\n        # im.show()\n\n        # Copy image\n        DICT_DIR = '\/kaggle\/working\/Dataset\/images\/'  + mode\n        img_dict_file = DICT_DIR + '\/' + img_name + '.png'\n\n        copyfile(img_src_file, img_dict_file)\n\n        # Copy label\n        DICT_DIR = '\/kaggle\/working\/Dataset\/labels\/' + mode\n        img_dict_file = DICT_DIR + '\/' + img_name + '.txt'\n        copyfile(label_src_file, img_dict_file)","deb760ed":"copy_data(train_list, '\/kaggle\/working\/Dataset\/labels', '\/kaggle\/input\/hard-hat-detection\/images', \"train\")\ncopy_data(val_list,   '\/kaggle\/working\/Dataset\/labels', '\/kaggle\/input\/hard-hat-detection\/images', \"val\")\ncopy_data(test_list,  '\/kaggle\/working\/Dataset\/labels', '\/kaggle\/input\/hard-hat-detection\/images', \"test\")","4822f371":"!ls \/kaggle\/working\/Dataset\/images","5caecf41":"!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd yolov5","8f756c94":"!ls ","61db66b4":"import yaml\n\ndict_file = {'train':'\/kaggle\/working\/Dataset\/images\/train' ,\n            'val': '\/kaggle\/working\/Dataset\/images\/val',\n            'nc' : '3',\n            'names' : ['helmet','head','person']}\n\nwith open('\/kaggle\/working\/yolov5\/data\/hard_head.yaml', 'w+') as file:\n    documents = yaml.dump(dict_file, file)","3965dcea":"!wandb disabled","26b731b4":"!python train.py --img 416 --batch 32 --epochs 30 --data data\/hard_head.yaml --cfg models\/yolov5s.yaml --weights yolov5s.pt","32e73cc9":"#!python detect.py --source \/kaggle\/working\/Dataset\/images\/test --img-size 416 --conf 0.4 --weights weights.pt \n!python detect.py --source \/kaggle\/working\/Dataset\/images\/test  --weights yolov5s.pt --conf 0.25","671f91bd":"# display detected images\nfrom IPython.display import Image","abaf4993":"from glob import glob\nimport matplotlib.pyplot as plt\ntestfiles = glob('runs\/detect\/exp3\/*')\n\nimg = plt.imread(testfiles[28]) \nplt.imshow(img)    \nplt.show","ae1caeca":"**create yaml file for configuration**","5514a5f3":"**Create directories to hold images and txt files for annotations (train , val ,test)**","28842460":"**calculate ancor points and hiegt width of bonding boxes**","62ee9124":"# Detect (predict)","4bdd4bd7":"# Train Net","f75b5293":"# split train val test","effe1789":"# Get YOLOv5 model","cf669c4d":"# Prepare Data for YOLOv5 Format","d8fffdb3":"**classes**"}}