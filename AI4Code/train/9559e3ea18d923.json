{"cell_type":{"0025c7df":"code","e584a5d9":"code","b60bd7a8":"code","d4c61cfa":"code","8dcd396a":"code","865e1980":"code","bb5ade07":"code","bbfc1f4e":"code","b7300901":"code","2107f1d0":"code","d0e1857d":"code","b85cc92e":"markdown","4a2159c3":"markdown","da927bc4":"markdown","401c0392":"markdown","4e0ea372":"markdown","b8febd61":"markdown","41b1ff87":"markdown","706b541f":"markdown","e0092ed1":"markdown","b6a2693e":"markdown","7279adde":"markdown"},"source":{"0025c7df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm \nimport pylab as py \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e584a5d9":"from sklearn.model_selection import train_test_split\n\ntrain_data = pd.read_csv('\/kaggle\/input\/cap-4611-spring-21-assignment-1\/train.csv').drop(columns=['id'])\ntest_data = pd.read_csv('\/kaggle\/input\/cap-4611-spring-21-assignment-1\/test.csv')\n\ntarget = ['Bankrupt']\nfeatures = [ x for x in train_data.columns if x not in target]\n\nX = train_data[features]\ny = train_data[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69, stratify=y)\n\ntrain_data.describe()","b60bd7a8":"train_data.dropna()\ntrain_data.isnull().values.any()","d4c61cfa":"train_data.loc[:, train_data.columns[train_data.max() <= 1].to_list()].boxplot(figsize=(20,10), rot = 90)","8dcd396a":"for feature in features:\n    sm.qqplot(train_data[feature], line ='45') \n    py.title(feature)\n    py.show()","865e1980":"# # using 3 std devs as an outlier\n# def isOutlier(mean, stdev, x) -> bool:\n#     cut_off = stdev * 3\n#     lower, upper = mean - cut_off, mean + cut_off\n    \n#     if(x < lower or x > upper):\n#         return True\n    \n#     return False\n\n\n\n# mean = train_data.mean()\n# stdev = train_data.std()\n\n# todrop = []\n\n# for row in X_train[features].iterrows():\n#     rowDict = row[1]\n#     out = 0\n    \n#     for feature in features:\n#         if(isOutlier(mean[feature], stdev[feature], rowDict[feature])):\n#             out += 1\n            \n    \n#     # if more than 1 features are outliers then remove data\n#     if(out > 1):\n#         todrop.append(row[0])\n        \n\n# X_train_filtered = X_train.drop(todrop)\n# y_train_filtered  = y_train.drop(todrop)\n\n# print(f\"Discarded {len(todrop)} ({100 * (1 - (len(X_train_filtered.index) \/ float(len(X_train.index)))):.2f}%) data points\")","bb5ade07":"# using 3 iqr as an outlier\ndef isOutlier(q25, q75, x) -> bool:\n    iqr = q75 - q25\n    cut_off = iqr * 4\n    lower, upper = q25 - cut_off, q75 + cut_off\n    \n    if(x < lower or x > upper):\n        return True\n    \n    return False\n\n\n\nq25 = train_data.quantile(q=0.25)\nq75 = train_data.quantile(q=0.75)\n\n# if the data has a range of 1 its likely a type of data where there are no outliers\nrange = train_data.max() - train_data.min()\n\ntodrop = []\n\nfor row in X_train[features].iterrows():\n    rowDict = row[1]\n    out = 0\n    \n    for feature in features:\n        if(range[feature] != 1 and isOutlier(q25[feature], q75[feature], rowDict[feature])):\n            out += 1\n            \n    \n    # if more than 8 features are outliers then remove data\n    if(out > 8):\n        todrop.append(row[0])\n        \n\nX_train_filtered = X_train.drop(todrop)\ny_train_filtered  = y_train.drop(todrop)\n\nprint(f\"Discarded {len(todrop)} ({100 * (1 - (len(X_train_filtered.index) \/ float(len(X_train.index)))):.2f}%) data points\")","bbfc1f4e":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(X_train_filtered)\n\n# transform training data\nnp_data = norm.transform(X_train_filtered)\nX_train_norm = pd.DataFrame(data=np_data, columns=features)","b7300901":"from sklearn.ensemble import RandomForestClassifier\n\nX_train_dummies = pd.get_dummies(X_train_norm)\n\nmodel = RandomForestClassifier(n_estimators = 50, max_depth = 10, criterion=\"entropy\", random_state = 1)\n\nmodel.fit(X_train_dummies, y_train_filtered.values.ravel())\n","2107f1d0":"from sklearn.metrics import roc_auc_score, roc_curve, f1_score\nfrom sklearn.model_selection import cross_val_score\n\n# transform testing data\nnp_data = norm.transform(X_test)\nX_test_norm = pd.DataFrame(data=np_data, columns=features)\n\nX_test_dummies = pd.get_dummies(X_test_norm)\npredictions = model.predict_proba(X_test_dummies)\n\npredictions = predictions[:,1]\n\nfig1, ax1 = plt.subplots()\nax1.set_title(\"Bruh\")\nax1.hist(predictions)\nplt.show()\n\nfpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_true = y_test, y_score = predictions)\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n\nrocAoc = roc_auc_score(y_true = y_test, y_score = predictions)\ncrossVal = cross_val_score(model, X_test, y_test.values.ravel()).mean()\nf1Score = f1_score(y_test, model.predict(X_test_dummies))\n\nprint(f\"ROC AOC: {rocAoc}\")\nprint(f\"Cross Val Score: {crossVal}\")\nprint(f\"F1 score: {f1Score}\")","d0e1857d":"np_data = norm.transform(test_data[features])\ntest_norm = pd.DataFrame(data=np_data, columns=features)\n\ntest_dummies = pd.get_dummies(test_norm)\n\n\ntest_predictions = model.predict_proba(test_dummies)\n\ntest_predictions = test_predictions[:,1]\n\noutput = pd.DataFrame({'id': test_data['id'], 'Bankrupt': test_predictions})\n\noutput.to_csv('my_submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")\n\n\nfig1, ax1 = plt.subplots()\nax1.set_title(\"Bruh\")\nax1.hist(test_predictions)\nplt.show()\n\n","b85cc92e":"# Analyzing and Cleaning The Input\n","4a2159c3":"# Testing the Model","da927bc4":"## Finding Outliers\n\nIf row has too many features fall outside of the standard deviation then discard data.","401c0392":"train_data.info() also confirms this but that output is ecessively long.","4e0ea372":"## Finding Missing Data\n","b8febd61":"A QQ plot can show if a distribution is normal.","41b1ff87":"# Building the Model","706b541f":"## Normalization vs Standardization\nFrom our previous anaysis we found our distribution to not be gaussian.\n\nStandardization works best with a normal disctribution, as such normazlization will likely be the best choice.","e0092ed1":"## Gausian Distribion\nDetermining if the distribution of data is gausian has important implications to the filtering of data.\n\n[[1](https:\/\/towardsdatascience.com\/6-ways-to-test-for-a-normal-distribution-which-one-to-use-9dcf47d8fa93)] \n[[2](https:\/\/www.analyticsvidhya.com\/blog\/2020\/04\/feature-scaling-machine-learning-normalization-standardization)]\n[[3](https:\/\/machinelearningmastery.com\/how-to-use-statistics-to-identify-outliers-in-data\/)]","b6a2693e":"# Outputting Final Submission\n","7279adde":"Based on these plots it seems like our model does not follow the normal distribution"}}