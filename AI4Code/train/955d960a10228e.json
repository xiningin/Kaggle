{"cell_type":{"56cb1b44":"code","20f6e89d":"code","4f0583a4":"code","c0ceb386":"code","48e66fb8":"code","bab0098f":"code","dcc865c5":"code","428b3c22":"code","4c01f0f8":"code","2758d518":"code","af2bccb0":"markdown","fc14f1f5":"markdown","24d0b3e8":"markdown","c2eabf25":"markdown","ad38f6f2":"markdown"},"source":{"56cb1b44":"import numpy as np \nimport matplotlib.pyplot as plt \nimport pandas as pd ","20f6e89d":"dataset = pd.read_csv('\/kaggle\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv')\ndataset","4f0583a4":"dataset.dropna(inplace = True)","c0ceb386":"X = dataset.iloc[:,:-1].values\nY = dataset.iloc[:,-1].values","48e66fb8":"from sklearn.model_selection import train_test_split\nX_train , X_test , Y_train , Y_test= train_test_split(X, Y, test_size = 0.2)","bab0098f":"from sklearn.preprocessing import StandardScaler, Normalizer\nnorm = Normalizer()\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","dcc865c5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nmethods = [norm, sc, None]\n\nbest_model = None\nbest_acc = 0\nfor method in methods:\n    if(method != None):\n        x_train = method.fit_transform(X_train)\n        x_test = method.transform(X_test)\n        if method is norm:\n            print(\"Using normalization:\")\n        else:\n            print(\"Using standardization:\")\n    else:\n        x_train = X_train\n        x_test = X_test\n        print(\"Not adjusting the data:\")\n    \n    model = LogisticRegression(random_state = 42, max_iter = 10000)\n    model.fit(x_train , Y_train)\n    Y_pred = model.predict(x_test)\n\n    from sklearn.metrics import confusion_matrix, accuracy_score\n    from sklearn.metrics import f1_score, recall_score, precision_score\n\n    cm = confusion_matrix(Y_pred, Y_test)\n    acc = accuracy_score(Y_pred, Y_test)\n    f1 = f1_score(Y_pred, Y_test)\n    recall = recall_score(Y_pred, Y_test)\n    precision = precision_score(Y_pred, Y_test)\n    print(\"\\tModel accuracy:\", acc)\n    print(\"\\tF1 score:\", f1)\n    print(\"\\tRecall:\", recall)\n    print(\"\\tPrecision:\", precision)\n    if best_acc < acc:\n        best_acc = acc\n        best_model = model","428b3c22":"print(\"Weights:\")\nprint(\"\\tB0 =\", best_model.intercept_[0])\nfor i, b in enumerate(best_model.coef_[0]):\n    print(\"\\tB{} ={}\".format(i+1, b))\n","4c01f0f8":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","2758d518":"import itertools\n\nplot_confusion_matrix(cm, [\"No risk of CHD\", \"Risk of CHD\"])","af2bccb0":"# Split the data to test and train","fc14f1f5":"# Normalize the data for both test and train","24d0b3e8":"# Confusion Matrix","c2eabf25":"# Create a model, predict and print the score","ad38f6f2":"# The last column is the target, the rest are features"}}