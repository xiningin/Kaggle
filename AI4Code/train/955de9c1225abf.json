{"cell_type":{"4f9309c8":"code","f5f1db4c":"code","12631306":"code","ed47ffb0":"code","111617e6":"code","3d3f91ee":"code","fb51907d":"code","9fa54937":"code","d473fb27":"code","920947e1":"code","a8582c62":"code","98aaf42c":"code","fc2ac43f":"code","043a9b1f":"code","f304c1f3":"code","c5955bc3":"code","a54b4fd9":"code","0a669044":"code","db45756f":"code","74b16f98":"code","0d7b66c6":"code","833dbbc9":"code","680eb42e":"code","49bbeb2c":"code","1f70eac8":"code","16c8c3a5":"code","cf374bdd":"code","533997c2":"code","de48e164":"code","28d4408d":"code","d35afd10":"code","af44dc8d":"code","26ce1259":"code","7da965d4":"code","532d406b":"markdown","0854d841":"markdown","1f7ea026":"markdown","88c816ae":"markdown","8286d26d":"markdown","f8ebe4ac":"markdown","810c8e71":"markdown","402c4b0f":"markdown","d4a8409f":"markdown","a7d142fd":"markdown","4f52597f":"markdown","c733b35b":"markdown","8da4d6a7":"markdown","2d4fe8b8":"markdown","915c986a":"markdown","96173282":"markdown","dba8e4f3":"markdown","197e5e18":"markdown","c1c93cca":"markdown","d227372a":"markdown","2c097ee6":"markdown","52606349":"markdown","889030ea":"markdown","1c84499a":"markdown"},"source":{"4f9309c8":"import tensorflow as tf                       # deep learning library\nimport numpy as np                            # for matrix operations\nimport matplotlib.pyplot as plt               # for visualization\n%matplotlib inline\n\n\n\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import plot_model\nfrom keras.preprocessing import image\n","f5f1db4c":"#create an array to access the class name based on label number.\nclass_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4',\n               'Class 5', 'Class 6', 'Class 7', 'Class 8','Class 9']\n\n","12631306":"from tensorflow.keras.datasets.cifar10 import load_data\n(x_train, y_train), (_, __) = load_data()","ed47ffb0":"print(\"There are \", len(x_train), \"images in the training dataset\")     # checking total number of images available in the training set","111617e6":"# Checking the shape of the training set\nx_train.shape","3d3f91ee":"# Checking the shape of a training image\nx_train[500].shape","fb51907d":"# Checking the label of the training image\ny_train[500]","9fa54937":"import pandas as pd\ntest_data = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/cifar_image_flattened_pixels.csv\")","d473fb27":"# checking total number of data points available in the X_test dataset\nprint(\"There are \", len(test_data), \"images in the test dataset\")     ","920947e1":"# Checking the shape of the X_test dataset\ntest_data.shape","a8582c62":"# Reshaping the shape of the X_test dataset to adapt them to the input of CNN\nnew_test_data = np.array(test_data).reshape(2000,32,32,3)","98aaf42c":"# Checking the shape of the reshaped X_test dataset\nnew_test_data.shape","fc2ac43f":"import random\nplt.figure(figsize=(15,15))\nfor i in range(25):\n  plt.subplot(5,5,i+1)\n  plt.xticks([])\n  plt.yticks([])\n  rand_no = random.randint(0,len(x_train))     \n  plt.imshow(x_train[rand_no])\n  plt.xlabel(class_names[np.int(y_train[rand_no])])","043a9b1f":"# Defining the CNN model\ndef create_model(learn_rate=0.01):\n  # Initialising the CNN\n  model = Sequential()\n\n  # 1 - Convolution\n  model.add(Conv2D(64,(3,3), padding='same', input_shape=(32, 32,3)))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # 2nd Convolution layer\n  model.add(Conv2D(128,(5,5), padding='same'))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # 3rd Convolution layer\n  model.add(Conv2D(256,(3,3), padding='same'))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # 4th Convolution layer\n  model.add(Conv2D(512,(3,3), padding='same'))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  # Flattening\n  model.add(Flatten())\n\n  # Fully connected layer 1st layer\n  model.add(Dense(128))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(Dropout(0.25))\n\n  # Fully connected layer 2nd layer\n  model.add(Dense(256))\n  model.add(BatchNormalization())\n  model.add(Activation('relu'))\n  model.add(Dropout(0.25))\n\n  # Add output layer\n  model.add(Dense(10, activation='softmax'))\n\n  # compile model\n  opt = RMSprop(learn_rate)\n  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n  return model\n\n","f304c1f3":"# creating the CNN model\nmodel_NT=create_model(learn_rate=0.001)\n\n# view model layers\nmodel_NT.summary()\n\nEPOCHS =30\ntrain_images_scaled = x_train \/ 255.\nes_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=True)\n\nhistory_NT = model_NT.fit(train_images_scaled, y_train,\n                    batch_size=32,\n                    callbacks=[es_callback], \n                    validation_split=0.2, epochs=EPOCHS,\n                    verbose=1)","c5955bc3":"import pandas as pd\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\nhistory_df = pd.DataFrame(history_NT.history)\nhistory_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\nhistory_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);","a54b4fd9":"test_images_scaled = new_test_data \/ 255.\npredictions_NT = np.argmax(model_NT.predict(test_images_scaled),axis=1)\npredictions_NT[:5]","0a669044":"# Showing the first five predicted images\nplt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  plt.xticks([])\n  plt.yticks([])   \n  plt.imshow(new_test_data[i])\n  plt.xlabel(class_names[predictions_NT[i]])","db45756f":"target_NT = predictions_NT.reshape(2000,1)\nprint(target_NT) \nres = pd.DataFrame(target_NT) \nres.columns = [\"predictions_NT\"]\n# To download the csv file locally\nfrom google.colab import files\nres.to_csv('prediction_results_NT.csv')         \nfiles.download('prediction_results_NT.csv')","74b16f98":"# import KerasClassifier class\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\n# define the hyperparameters grid to be validated\nlearn_rate=[0.001, 0.01,0.5]\nparam_grid = dict(learn_rate=learn_rate)\nmodel_GS = KerasClassifier(build_fn=create_model, verbose=1,epochs=30)\ngrid = GridSearchCV(estimator=model_GS, param_grid=param_grid, cv=2, n_jobs=-1)\n\n# run the GridSearchCV process\ngrid_result = grid.fit(x_train, y_train, verbose = 1)\n\n# print the results of the best model\nprint('Best params: ' + str(grid_result.best_params_))\n","0d7b66c6":"# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","833dbbc9":"# Creating the CNN model\nmodel_GS=create_model(learn_rate=grid_result.best_params_['learn_rate'])\nEPOCHS =30\nes_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=True)\ntrain_images_scaled = x_train \/ 255.\n\nhistory_GS = model_GS.fit(train_images_scaled, y_train,\n                    batch_size=32,\n                    callbacks=[es_callback],\n                    validation_split=0.1, epochs=EPOCHS,\n                    verbose=1)","680eb42e":"import pandas as pd\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\nhistory_df = pd.DataFrame(history_GS.history)\nhistory_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\nhistory_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);","49bbeb2c":"predictions_GS = np.argmax(model_GS.predict(test_images_scaled),axis=1)\npredictions_GS[:5]","1f70eac8":"plt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  plt.xticks([])\n  plt.yticks([])   \n  plt.imshow(new_test_data[i])\n  plt.xlabel(class_names[predictions_GS[i]])","16c8c3a5":"target_GS = predictions_GS.reshape(2000,1)\nprint(target_GS) \nres = pd.DataFrame(target_GS) \nres.columns = [\"predictions_GS\"]\n# To download the csv file locally\nfrom google.colab import files\nres.to_csv('prediction_results_GS.csv')         \nfiles.download('prediction_results_GS.csv')","cf374bdd":"# define input shape\nINPUT_SHAPE = (32, 32, 3)\n\n# get the VGG19 model\nvgg_layers = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, \n                                               input_shape=INPUT_SHAPE)\n\nvgg_layers.summary()\n\n","533997c2":"# fine-tune all the layers\nfor layer in vgg_layers.layers:\n    layer.trainable = True\n\n# check the trainable status of the individual layers\nfor layer in vgg_layers.layers:\n    print(layer, layer.trainable)\n\n","de48e164":"# define sequential model\nmodel_TL = Sequential()\n\n# Add the vgg convolutional base model\nmodel_TL.add(vgg_layers)\n\n# add flatten layer\nmodel_TL.add(Flatten())\n\n# add dense layers with some dropout\nmodel_TL.add(Dense(256, activation='relu'))\nmodel_TL.add(Dropout(rate=0.3))\nmodel_TL.add(Dense(256, activation='relu'))\nmodel_TL.add(Dropout(rate=0.3))\n\n# add output layer\nmodel_TL.add(Dense(10, activation='softmax'))\n\n# compile model\nmodel_TL.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\n# view model layers\nmodel_TL.summary()\n\n","28d4408d":"EPOCHS = 30\ntrain_images_3ch_scaled = x_train \/ 255.\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, \n                                               restore_best_weights=True,\n                                               verbose=1)\n\nhistory_TL = model_TL.fit(train_images_3ch_scaled, y_train,\n                    batch_size=32,\n                    callbacks=[es_callback], \n                    validation_split=0.2, epochs=EPOCHS,\n                    verbose=1)\n","d35afd10":"fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\nhistory_df = pd.DataFrame(history_TL.history)\nhistory_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\nhistory_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);","af44dc8d":"predictions_TL = np.argmax(model_TL.predict(test_images_scaled),axis=1)\npredictions_TL[:5]","26ce1259":"plt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  plt.xticks([])\n  plt.yticks([])   \n  plt.imshow(new_test_data[i])\n  plt.xlabel(class_names[predictions_TL[i]])","7da965d4":"target_TL = predictions_TL.reshape(2000,1)\nprint(target_TL) \nres = pd.DataFrame(target_TL) \nres.columns = [\"predictions_TL\"]\n# To download the csv file locally\nfrom google.colab import files\nres.to_csv('prediction_results_TL.csv')         \nfiles.download('prediction_results_TL.csv')","532d406b":"Model Training","0854d841":"##Prediction Using Hyperparameter Tuning (GridSearchCV)","1f7ea026":"Set Layers to Trainable to Enable Fine Tuning","88c816ae":"Plot Learning Curves","8286d26d":"Finding the Best Parameters ","f8ebe4ac":"Model Training","810c8e71":"\n\n\n## Prediction Using Transfer Learning","402c4b0f":"Predictions on Test Data","d4a8409f":"## Loading the Training Data","a7d142fd":"Predictions on Test Data","4f52597f":"## Loading the Testing Data","c733b35b":"Importing convolution layers from VGG19 Model","8da4d6a7":"Creating Prediction File for Submission","2d4fe8b8":"## Load Libraries","915c986a":"\nCreating the File for Submission","96173282":"## Prediction without Hyperparameter Tuning","dba8e4f3":"Creating the File for Submission","197e5e18":"\n## Define the CNN Model","c1c93cca":"Predictions on Test Data","d227372a":"Training the Model with Optimized Parameters","2c097ee6":"Plot Learning Curves","52606349":"Plot Learning Curves","889030ea":"## Viewing Some of the Training Images","1c84499a":"Build Dense Layers on Top of VGG19"}}