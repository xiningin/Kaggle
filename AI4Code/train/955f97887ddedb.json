{"cell_type":{"3f8637d8":"code","e0df9473":"code","39f2a97d":"code","c0b99cac":"code","01513fe0":"code","ea10289d":"code","61b78363":"code","729db311":"code","eb78d2a2":"code","7b79b018":"code","f2c51c20":"code","06c08a72":"code","e55dddd7":"code","e1314b4d":"code","fdc9a2c3":"code","49542f0c":"code","eb5213a3":"code","34526b04":"code","98490804":"code","f1a9c7dd":"code","7414ce1d":"code","0f0c0b64":"code","7642e5f7":"code","3dbc9605":"code","7914d24e":"code","80e085a1":"code","200019c3":"code","3f44b892":"code","5abd0486":"code","16307b9f":"code","4a441ad3":"code","8ef91407":"code","ea4d9bc4":"code","d33ba45a":"code","e48b5560":"code","8548c4d0":"code","9661a64e":"code","34a6a827":"markdown","734f02dc":"markdown","012d1466":"markdown","5c6e41ff":"markdown","d2f9a7fc":"markdown","0780c59f":"markdown","7f672723":"markdown","7fb251a4":"markdown","d08f07a2":"markdown","22e90718":"markdown","8bb31b40":"markdown","fd27c182":"markdown"},"source":{"3f8637d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0df9473":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import set_config\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate","39f2a97d":"df = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\ndf.head()","c0b99cac":"#Average student score\n\navg = df.iloc[:, 5:8].mean(axis = 1)","01513fe0":"df[\"Average Score\"] = round(avg, 1)\ndf.head()","ea10289d":"#Create grade group\n# 0-30.9 = Fail\n#40-49.9 = Pass\n#50-69.9 = Second Class Lower\n#70-79.9 = Second Class Upper\n#80-100 = First Class\n\n\ncriteria = (df[\"Average Score\"].between(0.0, 39.9), df[\"Average Score\"].between(40.0, 49.9),\n      df[\"Average Score\"].between(50.0, 69.9), df[\"Average Score\"].between(70.0, 79.9), df[\"Average Score\"].between(80.0, 100))\nvalues = [\"fail\", \"pass\", \"second class lower\", \"second class upper\", \"first class\"]","61b78363":"#Add grade column\ndf['Grade'] = np.select(criteria, values, 0)\ndf.head()","729db311":"#save new dataset to file\ndf.to_csv(\"Studentdataperformance2.csv\")","eb78d2a2":"df_f = df.drop([\"Average Score\", \"Grade\"], axis = 1)","7b79b018":"df_f.info()","f2c51c20":"#OneHotEncoder for categorical data\ncat_preprocessor = OneHotEncoder(handle_unknown = \"ignore\")\n\n#StandardScaler for Numerical data\nnum_preprocessor = StandardScaler()","06c08a72":"#use Dtype to select categorical features\nx_cat = df_f.select_dtypes(include = \"object\").columns\n#x_cat.head()\n\n#use Dtype to select numerical features\nx_num = df_f.select_dtypes(include = \"int64\").columns\n#x_num.head()","e55dddd7":"#create preprocessor\npreprocessor = ColumnTransformer([\n    ('one-hot-encoder', cat_preprocessor, x_cat),\n    ('standard-scaler', num_preprocessor, x_num)])","e1314b4d":"#Creatse instance of LogisticRegression\nlr_model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))","fdc9a2c3":"set_config(display='diagram')\nlr_model","49542f0c":"features = df_f.iloc[:, :8]\ntarget = df.iloc[:, -1]","eb5213a3":"x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=1 )","34526b04":"x_train.shape","98490804":"y_train.shape","f1a9c7dd":"mod = lr_model.fit(x_train, y_train)","7414ce1d":"pred = lr_model.predict(x_test)","0f0c0b64":"lr_model.score(x_test, y_test)","7642e5f7":"# evaluate predictions\naccuracy = accuracy_score(y_test, pred)\nprint('Accuracy: %.2f' % (accuracy*100))","3dbc9605":"#Evaluation with Cross Validation\n\ncv_lr = cross_validate(lr_model, features, target, cv=5)\ncv_lr","7914d24e":"scores = cv_lr[\"test_score\"]\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +\/- {scores.std():.3f}\")","80e085a1":"nb_model = make_pipeline(preprocessor, GaussianNB())","200019c3":"nb_model.fit(x_train, y_train)","3f44b892":"nb_pred = nb_model.predict(x_test)","5abd0486":"# evaluate predictions\naccuracy = accuracy_score(y_test, nb_pred)\nprint('Accuracy: %.2f' % (accuracy*100))","16307b9f":"#Evaluation with Cross Validation\n\ncv_nb = cross_validate(nb_model, features, target, cv=5)\ncv_nb","4a441ad3":"scores = cv_nb[\"test_score\"]\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +\/- {scores.std():.3f}\")","8ef91407":"sgd_model = make_pipeline(preprocessor, SGDClassifier(loss = \"modified_huber\", shuffle = True, random_state = 101))","ea4d9bc4":"sgd_model.fit(x_train, y_train)","d33ba45a":"sgd_pred = sgd_model.predict(x_test)","e48b5560":"# evaluate predictions\naccuracy = accuracy_score(y_test, sgd_pred)\nprint('Accuracy: %.2f' % (accuracy*100))","8548c4d0":"#Evaluation with Cross Validation Accuracy\n\ncv_sgd = cross_validate(sgd_model, features, target, cv=5)\ncv_sgd","9661a64e":"scores = cv_sgd[\"test_score\"]\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +\/- {scores.std():.3f}\")","34a6a827":"## Create Processing Pipeline","734f02dc":"## Split into Features and Target","012d1466":"## EDA","5c6e41ff":"## Create Processing Pipeline\nThis is done to automate processing, so we can pass our raw data into the model directly and it gets preprocessed in the background. ","d2f9a7fc":"# Stochastic Gradient Descent","0780c59f":"## Data Prep","7f672723":"# Load Dataset","7fb251a4":"I did a seperate notebook of the EDA for this data sometime ago, find linke [Here](https:\/\/www.kaggle.com\/raimiazeezbabatunde\/student-performance-eda\/notebook).\n\nPlease drop comments, suggestions and recommendations. Thanks ","d08f07a2":"## Split Train Test","22e90718":"# Na\u00efve Bayes","8bb31b40":"# Logistic Regression Model","fd27c182":"## Fit & Predict Model"}}