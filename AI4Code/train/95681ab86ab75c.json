{"cell_type":{"c9e12d52":"code","c7584e39":"code","af137d7e":"code","d5ccd141":"code","5aa12dd7":"code","517ecaad":"code","5d67b73a":"code","9b2ecadd":"code","fc89cbaa":"code","63af101e":"code","d4a47f61":"code","52665ae8":"code","87ad60b3":"code","77b11937":"code","56bd8385":"code","1fa33d7b":"code","ecddee51":"code","1f14b213":"code","85495062":"code","e40c1eae":"code","d0a63eaf":"code","dbc93b40":"code","e4fe3544":"code","d97e5fe4":"code","a0becc3a":"code","51b80276":"code","31af3f54":"code","7482ebf4":"code","081d3b48":"code","32cd713f":"code","50c88343":"code","02b74c0e":"code","267df3c6":"code","5552771b":"code","96b68d00":"code","6c64f769":"code","46a6cdc4":"markdown","cb147bb1":"markdown","0abc026b":"markdown","968c8cf9":"markdown","28509a6f":"markdown","0018dfad":"markdown","e41170fa":"markdown","76e6658a":"markdown","2a92e4cf":"markdown","b8ced7d8":"markdown","286f1613":"markdown","429b3cb1":"markdown","b2ad3079":"markdown","4b5ca3ea":"markdown","27a7dd0c":"markdown","61347a4f":"markdown","3049b4e7":"markdown","3808a764":"markdown","1693d6d0":"markdown","16ae1ffb":"markdown","e5cd63e9":"markdown","0e545876":"markdown","0ec685a5":"markdown","7ecee040":"markdown","744514a1":"markdown","4a07cb03":"markdown","6977ffa5":"markdown","d41cf094":"markdown","1c108c6e":"markdown","472625c9":"markdown","744a4db1":"markdown","4298a8eb":"markdown","dd874ead":"markdown","ba4b5756":"markdown"},"source":{"c9e12d52":"import warnings\nimport random\nimport os\nimport gc","c7584e39":"import pandas            as pd\nimport numpy             as np\nimport matplotlib.pyplot as plt \nimport seaborn           as sns\nimport joblib            as jb","af137d7e":"import pandas            as pd\nimport numpy             as np\nimport matplotlib.pyplot as plt \nimport seaborn           as sns\nimport joblib            as jb\nimport matplotlib.pyplot as plt","d5ccd141":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.preprocessing   import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn                 import metrics","5aa12dd7":"import xgboost               as xgb","517ecaad":"def jupyter_setting():\n    \n    %matplotlib inline\n      \n    #os.environ[\"WANDB_SILENT\"] = \"true\" \n    #plt.style.use('bmh') \n    #plt.rcParams['figure.figsize'] = [20,15]\n    #plt.rcParams['font.size']      = 13\n     \n    pd.options.display.max_columns = None\n    #pd.set_option('display.expand_frame_repr', False)\n\n    warnings.filterwarnings(action='ignore')\n    warnings.simplefilter('ignore')\n    warnings.filterwarnings('ignore')\n    #warnings.filterwarnings(category=UserWarning)\n    \n    pd.set_option('display.max_rows', 150)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.max_colwidth', None)\n\n    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n    #sns.palplot(sns.color_palette(icecream))\n    \n    return icecream\n\nicecream = jupyter_setting()\n\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n#warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# Colors\ndark_red = \"#b20710\"\nblack    = \"#221f1f\"\ngreen    = \"#009473\"\nmyred    = '#CD5C5C'\nmyblue   = '#6495ED'\nmygreen  = '#90EE90'\n\ncols= [myred, myblue,mygreen]","5d67b73a":"colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","9b2ecadd":"def missing_zero_values_table(df):\n        mis_val         = df.isnull().sum()\n        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n                                                     0 : 'Valores ausentes', \n                                                     1 : '% de valores totais'})\n        \n        mz_table['Tipo de dados'] = df.dtypes\n        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n                                     sort_values('% de valores totais', ascending=False)\n        \n        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n            \n        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n        \n        return mz_table.reset_index()","fc89cbaa":"def describe(df):\n    var = df.columns\n\n    # Medidas de tend\u00eancia central, m\u00e9dia e mediana \n    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n\n    # Dispens\u00e3o - str, min , max range skew, kurtosis\n    d1 = pd.DataFrame(df[var].apply(np.std)).T\n    d2 = pd.DataFrame(df[var].apply(min)).T\n    d3 = pd.DataFrame(df[var].apply(max)).T\n    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) \/ np.std(x) ))).T\n\n    # concatenete \n    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n    \n    return m","63af101e":"def graf_bar_churn(df, col, title, xlabel, ylabel, tol = 0):\n    \n    #ax    = df.groupby(['churn_cat'])['churn_cat'].count()\n    ax     = df    \n    colors = cols\n    \n    if tol == 0: \n        total  = sum(ax)\n        ax = (ax).plot(kind    ='bar',\n                   stacked = True,\n                    width = .5,\n                   rot     = 0,\n                   color   = colors)\n    else:\n        total  = tol     \n        \n        ax = (ax).plot(kind    ='bar',\n                       stacked = True,\n                       width = .5,\n                       rot     = 0,figsize = (10,6),\n                       color   = colors)\n\n    #ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n    \n    #y_fmt = tick.FormatStrFormatter('%.0f') \n    #ax.yaxis.set_major_formatter(y_fmt)\n\n    title   = title + ' \\n'\n    xlabel  = '\\n ' + xlabel \n    ylabel  = ylabel + ' \\n'\n    \n    ax.set_title(title  , fontsize=22)\n    ax.set_xlabel(xlabel, fontsize=13)\n    ax.set_ylabel(ylabel, fontsize=13)    \n\n    min = [0,23000000]\n    #ax.set_ylim(min)\n    \n    for i in ax.patches:\n        # get_width pulls left or right; get_y pushes up or down\n        width, height = i.get_width(), i.get_height()\n        x, y = i.get_xy()        \n        \n        ax.annotate(str(round((i.get_height() * 100.0 \/ total), 1) )+'%', \n                    (i.get_x()+.3*width, \n                     i.get_y()+.5*height),\n                     color   = 'white',\n                     weight = 'bold',\n                     size   = 14)","d4a47f61":"path = '\/content\/drive\/MyDrive\/kaggle\/07. Tabular Playground Series - Ago 2021\/'\npath = '..\/input\/tabular-playground-series-sep-2021\/'","52665ae8":"df_train_row  = pd.read_csv(path + 'train.csv', index_col='id')\ndf_test_row   = pd.read_csv(path + 'test.csv',index_col='id')\ndf_submission = pd.read_csv(path + 'sample_solution.csv')\n\ndf_train_row.shape, df_test_row.shape, df_submission.shape","87ad60b3":"df1_train = df_train_row.copy()\ndf1_test  = df_test_row.copy()","77b11937":"print('TREINO')\nprint('Number of Rows: {}'.format(df1_train.shape[0]))\nprint('Number of Columns: {}'.format(df1_train.shape[1]), end='\\n\\n')\n\nprint('TESTE')\nprint('Number of Rows: {}'.format(df1_test.shape[0]))\nprint('Number of Columns: {}'.format(df1_test.shape[1]))","56bd8385":"df1_train.info()","1fa33d7b":"df1_train.dtypes","ecddee51":"df1_test.info()","1f14b213":"df1_test.dtypes","85495062":"missing = missing_zero_values_table(df1_train)\nmissing[:].style.background_gradient(cmap='Reds')","e40c1eae":"missing = missing_zero_values_table(df1_test)\nmissing[:].style.background_gradient(cmap='Reds')","d0a63eaf":"df_num = df1_train.select_dtypes(np.number)\ndf_cat = df1_train.select_dtypes(exclude=[np.number])\n\ndf_num.shape, df_cat.shape\n\nprint('Temos {} vari\u00e1vies num\u00e9ricas e {} categ\u00f3ricas.'.format(df_num.shape[1], df_cat.shape[1]))","dbc93b40":"df_summary = describe(df1_train.select_dtypes(np.number).copy())\ndf_summary.sample(10)","e4fe3544":"df = df1_train.corr().round(5)\n\n# M\u00e1scara para ocultar a parte superior direita do gr\u00e1fico, pois \u00e9 uma duplicata\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# Making a plot\nplt.figure(figsize=(16,16))\nax = sns.heatmap(df, annot=False, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n\nax.set_title(\"Mapa de calor de correla\u00e7\u00e3o das vari\u00e1vel\", fontsize=17)\n\nplt.setp(ax.get_xticklabels(), \n         rotation      = 90, \n         ha            = \"right\",\n         rotation_mode = \"anchor\", \n         weight        = \"normal\")\n\nplt.setp(ax.get_yticklabels(), \n         weight        = \"normal\",\n         rotation_mode = \"anchor\", \n         rotation      = 0, \n         ha            = \"right\");","d97e5fe4":"df[(df[\"claim\"]>-0.001) & (df[\"claim\"]<0.001)][\"claim\"]","a0becc3a":"fig, ax = plt.subplots(figsize=(5, 5))\n\npie = ax.pie([len(df1_train), len(df1_test)],\n             labels   = [\"Train dataset\", \"Test dataset\"],\n             colors   = [\"salmon\", \"teal\"],\n             textprops= {\"fontsize\": 15},\n             autopct  = '%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Compara\u00e7\u00e3o de comprimento do conjunto de dados \\n\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","51b80276":"L    = len(df1_train.columns[0:60])\nnrow = int(np.ceil(L\/6))\nncol = 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\nfig.subplots_adjust(top=0.95)\ni = 1\n\nfor feature in df1_train.columns[0:60]:\n    \n    plt.subplot(nrow, ncol, i)\n    \n    ax = sns.kdeplot(df1_train[feature], shade=True, color='salmon',  alpha=0.5, label='train')\n    ax = sns.kdeplot(df1_test[feature], shade=True, color='teal',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    \n    i += 1\n    \nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","31af3f54":"# Reference: https:\/\/www.kaggle.com\/suharkov\/sep-2021-playground-eda-no-model-for-now\ndf_plot = ((df1_train - df1_train.min())\/(df1_train.max() - df1_train.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\n\nfor i, (x) in enumerate([(1,30), (30,60), (60,90), (90,120)]): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);","7482ebf4":"# Reference: https:\/\/www.kaggle.com\/suharkov\/sep-2021-playground-eda-no-model-for-now\ndf_plot = ((df1_test - df1_test.min())\/(df1_test.max() - df1_test.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\n\nfor i, (x) in enumerate([(1,30), (30,60), (60,90), (90,120)]): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);","081d3b48":"plt.figure(figsize=(8, 6))\nax = sns.countplot(x=df1_train['claim'], palette='viridis')\nax.set_title('Distribui\u00e7\u00e3o da vari\u00e1vel Clain', fontsize=20, y=1.05)\n\nsns.despine(right=True)\nsns.despine(offset=10, trim=True)","32cd713f":"L    = len(df1_train.columns[0:60])\nnrow = int(np.ceil(L\/6))\nncol = 6\ni    = 1\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\nfig.subplots_adjust(top=0.95)\n\nfor feature in df1_train.columns[0:60]:\n    \n    plt.subplot(nrow, ncol, i)\n    \n    ax = sns.kdeplot(df1_train[feature], \n                     shade    = True, \n                     palette  = 'viridis',  \n                     alpha    = 0.5, \n                     hue      = df1_train['claim'], \n                     multiple = \"stack\")\n    \n    plt.xlabel(feature, fontsize=9)\n    \n    i += 1\n    \nplt.suptitle('DistPlot: Vari\u00e1vel de treino vs target', fontsize=20)\nplt.show()","50c88343":"gc.collect()","02b74c0e":"X    = df1_train.drop('claim', axis=1)\ny    = df1_train['claim']\ncols = X.columns\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size    = 0.2,\n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 0)\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape ","267df3c6":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_train = pd.DataFrame(imputer.fit_transform(X_train),  columns=cols)\nX_valid = pd.DataFrame(imputer.fit_transform(X_valid),  columns=cols)\nX_test  = pd.DataFrame(imputer.fit_transform(df1_test),  columns=cols)","5552771b":"X_test.head()","96b68d00":"params = {'random_state': 0,\n          'predictor'   : 'gpu_predictor',\n          'tree_method' : 'gpu_hist',\n          'eval_metric' : 'auc'}\n\nmodel_baseline = xgb.XGBClassifier(**params)\n\nscalers = [None, StandardScaler(), RobustScaler(), MinMaxScaler(), \n           MaxAbsScaler(), QuantileTransformer(output_distribution='normal', random_state=0)]\n\nfor scaler in scalers: \n    \n    if scaler!=None:\n        X_train_s = scaler.fit_transform(X_train)\n        X_valid_s = scaler.fit_transform(X_valid)\n    else:\n        X_train_s = X_train\n        X_valid_s = X_valid\n                \n    model_baseline.fit(X_train_s, y_train, verbose = False)\n    y_hat = model_baseline.predict_proba(X_valid_s)[:, 1]\n    \n    fpr, tpr, thresholds = metrics.roc_curve(y_valid, y_hat)\n    \n    auc = metrics.auc(fpr, tpr)\n    print('Valida\u00e7ao AUC: {:2.5f} => {}'.format(auc, scaler))","6c64f769":"%%time\n\ngc.collect()\n\nscalers = [None, StandardScaler(), RobustScaler(), MinMaxScaler(), \n           MaxAbsScaler(), QuantileTransformer(output_distribution='normal', random_state=0)]\n\nfor scaler in scalers: \n\n    FOLDS               = 5\n    df_submission.claim = 0\n    auc                 = []\n    lloss               = []\n    f1                  = []\n\n    kfold               = KFold(n_splits = FOLDS, random_state = 0, shuffle = True)\n    \n    if scaler!=None:\n        X_ts = scaler.fit_transform(X_test.copy())\n    else:\n        X_ts = X_test.copy()\n\n    print('='*80)\n    print('Scaler: {}'.format(scaler))\n    print('='*80)\n\n    for i, (train_idx, test_idx) in enumerate(kfold.split(X_train)):\n\n        i+=1\n        \n        X_tr, y_tr = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        X_vl, y_vl = X_train.iloc[test_idx], y_train.iloc[test_idx]\n\n        # Scaler\n        if scaler!=None:    \n            X_tr = scaler.fit_transform(X_tr)\n            X_vl = scaler.fit_transform(X_vl)                \n\n        model = xgb.XGBClassifier(**params)\n\n        model.fit(X_tr, y_tr)\n\n        y_hat_prob = model.predict_proba(X_vl)[:, 1]\n        y_hat      = (y_hat_prob >.5).astype(int) \n        \n        fpr, tpr, thresholds = metrics.roc_curve(y_vl, y_hat_prob)\n                 \n        log_loss_     = metrics.log_loss(y_vl, y_hat_prob)                \n        f1_score_     = metrics.f1_score(y_vl, y_hat)        \n        auc_          = metrics.auc(fpr, tpr)    \n                \n        print('[Fold {}] AUC: {:.5f} - F1: {:.5f} - L. LOSS: {:.5f}'.format(i, auc_, f1_score_, log_loss_))\n\n        df_submission.claim += model.predict_proba(X_ts)[:, 1] \/ FOLDS\n\n        f1.append(f1_score_)\n        lloss.append(log_loss_)\n        auc.append(auc_)\n\n    auc_mean   = np.mean(auc)\n    auc_std    = np.std(auc)\n    lloss_mean = np.mean(lloss)\n    f1_mean    = np.mean(f1)\n    \n    print('-'*80)\n    print('[Mean Fold] AUC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - L. LOSS: {:.5f}'.format(auc_mean,\n                                                                                       auc_std,\n                                                                                       f1_mean, \n                                                                                       lloss_mean))\n    print('='*80)\n    print('')\n    \n    # Gerar o arquivo de submiss\u00e3o \n    name_file_submission = '001_xgb_submission_baseline_' + str(scaler).lower()[:4] + '.csv'\n    df_submission.to_csv(name_file_submission, index = False)\n    \n    #gc.collect()","46a6cdc4":"### 1.1.3. Tipo de Dados","cb147bb1":"Como podemos ver, a correla\u00e7\u00e3o est\u00e1 entre ~-0,05 e ~0,02, o que \u00e9 muito pequeno. Portanto, as vari\u00e1veis s\u00e3o fracamente correlacionados. \n\nExistem alguns recursos com correla\u00e7\u00e3o relativamente baixa com o valor alvo, mesmo em compara\u00e7\u00e3o com outros recursos, isso pode sugerir uma exclus\u00e3o dessas vari\u00e1veis.","0abc026b":"#### 1.2.2.1. Detec\u00e7\u00e3o de Outlier","968c8cf9":"O n\u00famero de pessoas que n\u00e3o reclamam e reclamam (0 e 1) \u00e9 quase igual a 480.404 e 477.515, respectivamente. Em termos de porcentagem, tanto as pessoas que afirmam quanto n\u00e3o afirmam ficam em torno de 50%, neste caso n\u00e3o precisamos tratamento para dados desbalanceados.","28509a6f":"#### 1.2.2.4. Vari\u00e1veis preditoras  vs Target.","0018dfad":"#### 1.2.2.3. Claim\nA vari\u00e1vel alvo tem um valor de 0 a 1 que indica pessoas que n\u00e3o reclamam e reclamam o seguro. Vamos verificar a distribui\u00e7\u00e3o da vari\u00e1vel de reclama\u00e7\u00e3o (claim).","e41170fa":"### 1.2.2. Distribui\u00e7\u00e3o","76e6658a":"Refer\u00eancia: https:\/\/www.kaggle.com\/desalegngeb\/sept-2021-tps-eda-model","2a92e4cf":"**`Nota:`**\n\nNa valida\u00e7\u00e3o cruzada que foi realizada, mostra que n\u00e3o fazer a normaliza\u00e7\u00e3o temos a melhor AUC, por\u00e9m abaixo podemos observar que a melhor scaler na submiss\u00e3o foi de 0.69320 com a StanderScaler, abaixo um resumo:    \n\n- AUC: 0.64631 => Sem normaliza\u00e7\u00e3o \n- AUC: 0.67258 => RobustScaler \n- AUC: `0.69320` => StanderScaler \n- AUC: 0.60872 => MinMaxScaler \n- AUC: 0.63037 => MaxAbsScaler ","b8ced7d8":"## 1.2. An\u00e1lise Gr\u00e1fica","286f1613":"`**NOTA:**`\n\n- O m\u00e1ximo de valor ausente em uma observa\u00e7\u00e3o \u00e9 14 e o mais baixo \u00e9 nenhum valor ausente.\nCuriosamente, a distribui\u00e7\u00e3o de valor ausente (base de linha) \u00e9 exatamente a mesma entre o conjunto de dados de treino e teste.\n\n- Embora haja cerca de 2% de valor ausente em cada recurso, h\u00e1 cerca de 38% das observa\u00e7\u00f5es (base de linha) que n\u00e3o tem valores ausentes.\n\n- No reverso, existem 62% das observa\u00e7\u00f5es com valor faltante.\n\n- 1 a 3 valores ausentes nas observa\u00e7\u00f5es a constituem cerca de 41% do total de observa\u00e7\u00f5es.","429b3cb1":"### 1.2.1. Correla\u00e7\u00e3o\nVamos examinar a correla\u00e7\u00e3o entre as vari\u00e1veis.","b2ad3079":"<div class=\"alert alert-info\" role=\"alert\">\n\nNa valida\u00e7\u00e3o cruzada obtivemos uma `AUC` de `0.77727` com um desvio padr\u00e3o de `0.00149` sem fazer o scaler, vamos gerar um arquivo para submiss\u00e3o. \n    \n    \n**Nota:**\n   \nNa valida\u00e7\u00e3o cruzada que foi realizada, mostra que n\u00e3o fazer a normaliza\u00e7\u00e3o temos a melhor AUC, por\u00e9m abaixo podemos observar que a melhor scaler na submiss\u00e3o foi de 0.69320 com a StanderScaler, abaixo um resumo:        \n- AUC: 0.64631 => Sem normaliza\u00e7\u00e3o \n- AUC: 0.67258 => RobustScaler \n- AUC: 0.69320 => StanderScaler \n- AUC: 0.60872 => MinMaxScaler \n- AUC: 0.63037 => MaxAbsScaler \n      \nAcrescentei na valida\u00e7\u00e3o o scaler QuantileTransformer que teve uma AUC de 0.72080, batendo o StanderScaler na valida\u00e7\u00e3o e o no kaggle com AUC de `0.74479` que \u00e9 melhor que a valida\u00e7\u00e3o realizada neste notebook.\n    ","4b5ca3ea":"# <div class=\"alert alert-success\">  2.0. Modelo Baseline XGB <\/div> \n\nNesta etapa, treinaremos nosso modelo XGBClassifier de linha de base simples. Existem valores ausentes em nossos dados. Vamos preench\u00ea-los com uma m\u00e9dia e dimensionar todos os dados.","27a7dd0c":"**`NOTA:`**\n\nAcima observamos que temos muitos outliers em ambos conjunto de dados, no processamento vamos trart\u00e1-los.","61347a4f":"# <div class=\"alert alert-success\">  1.0. EDA  <\/div> ","3049b4e7":"##### 1.2.2.1.2. Data Test","3808a764":"##### 1.2.2.1.1. Data Train ","1693d6d0":"Na valida\u00e7\u00e3o cruzada obtivemos uma `AUC` de `0.77727` com um desvio padr\u00e3o de `0.00149` sem fazer o scaler, vamos gerar um arquivo para submiss\u00e3o. ","16ae1ffb":"## 0.2. Fun\u00e7\u00f5es\nAqui centralizamos todas as fun\u00e7\u00f5es desenvolvidas durante o projeto para melhor organiza\u00e7\u00e3o do c\u00f3digo.","e5cd63e9":"### 1.1.2. Dimens\u00e3o do DataSet","0e545876":"## 0.3. Carregar Dados\nExistem 2 conjuntos de dados que s\u00e3o usados na an\u00e1lise, eles s\u00e3o o conjunto de dados de treinamento e de teste. O principal uso do conjunto de dados de treino \u00e9 treinar os modelos e us\u00e1-lo para prever o conjunto de dados de teste. \n\nEnquanto o arquivo de envio de amostra \u00e9 usado para informar os participantes sobre a inscri\u00e7\u00e3o prevista para a competi\u00e7\u00e3o. ","0ec685a5":"#### 1.2.2.1. Target\nVamos ver as ocorr\u00eancias de n\u00fameros individuais do conjunto de dados de treino.","7ecee040":"<h1 div class='alert alert-success'><center> TPS-Set: ponto de partida (EDA, linha de base)<\/center><\/h1>\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/26480\/logos\/header.png?t=2021-04-09-00-57-05)","744514a1":"Com scaler StandarScaler obtivemos uma AUC de `0.73511`, vamos fazer uma valida\u00e7\u00e3o cruzada com as normaliza\u00e7\u00f5es.","4a07cb03":"**NOTA:**\n\n- Os conjuntos de treinamento e teste t\u00eam aproximadamente as mesmas distribui\u00e7\u00f5es em termos de vari\u00e1veis;\n- Temos poucas vari\u00e1veis com distribui\u00e7\u00f5es normais;\n- A maioria das vari\u00e1veis tem distribui\u00e7\u00f5es distorcidas.\n\nPrecisamos pensar em como fazer tudo isso normalmente distribu\u00eddo se decidirmos usar modelos n\u00e3o baseados em \u00e1rvore.\n\n> A verifica\u00e7\u00e3o da correla\u00e7\u00e3o n\u00e3o revelou rela\u00e7\u00f5es significativas entre as caracter\u00edsticas (a maioria estava entre 0,02 e -0,05).\n","6977ffa5":"> ","d41cf094":"#### 1.1.6.1. Atributos Num\u00e9ricos","1c108c6e":"# <div class=\"alert alert-success\">  0. IMPORTA\u00c7\u00d5ES <\/div> \n","472625c9":"Refer\u00eancia: https:\/\/www.kaggle.com\/desalegngeb\/sept-2021-tps-eda-model","744a4db1":"### 1.1.6. Estat\u00edstica Descritiva\nAbaixo est\u00e3o as estat\u00edsticas b\u00e1sicas para cada vari\u00e1vel que cont\u00e9m informa\u00e7\u00f5es sobre contagem, m\u00e9dia, desvio padr\u00e3o, m\u00ednimo, 1\u00ba quartil, mediana, 3\u00ba quartil e m\u00e1ximo.","4298a8eb":"O n\u00famero de pessoas que n\u00e3o reclamam e reclamam (0 e 1) \u00e9 quase igual a 480.404 e 477.515, respectivamente. Em termos de porcentagem, tanto as pessoas que afirmam quanto n\u00e3o afirmam ficam em torno de 50%, neste caso n\u00e3o precisamos tratamento para dados desbalanceados. ","dd874ead":"### 1.1.4. Idenficar Vari\u00e1veis Ausentes (NA)\nVamos verificar os valores ausentes em cada vari\u00e1vel conjunto de treinono e teste.","ba4b5756":"# Descri\u00e7\u00e3o de dados\n\nPara esta competi\u00e7\u00e3o, voc\u00ea vai prever se um cliente fez uma reclama\u00e7\u00e3o sobre uma ap\u00f3lice de seguro. A verdade fundamental claimtem valor bin\u00e1rio, mas uma previs\u00e3o pode ser qualquer n\u00famero de 0.0 para 1.0, representando a probabilidade de uma reclama\u00e7\u00e3o. Os recursos neste conjunto de dados foram tornados an\u00f4nimos e podem conter valores ausentes.\narquivos\n\n- `train.csv`: os dados de treinamento com o alvo claimcoluna\n- `test.csv`: o conjunto de teste; voc\u00ea estar\u00e1 prevendo o claimpara cada linha neste arquivo\n- `sample_submission.csv`:  um arquivo de envio de amostra no formato correto\n"}}