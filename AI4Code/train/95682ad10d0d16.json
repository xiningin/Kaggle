{"cell_type":{"a7f26132":"code","04b43d0a":"code","a7d1761d":"code","926196a0":"code","39eed76e":"code","1fe0c283":"code","e2c91b2a":"code","852a6cf4":"code","8ba325ca":"code","b6be216a":"code","1117b30d":"code","29455e06":"code","4c84e90a":"code","91fb3265":"code","030b0b6e":"code","a5845883":"code","dc914c92":"code","147876e6":"code","1caff448":"code","a9412cea":"code","3bded6c2":"code","4dfb3797":"code","ff95e75c":"code","ee037c45":"code","398565a0":"markdown","f24788a9":"markdown","d14e064b":"markdown"},"source":{"a7f26132":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","04b43d0a":"df = pd.read_csv('..\/input\/Churn_Modelling.csv')\ndf.sample(10)","a7d1761d":"df.Geography = df.Geography.astype('category')\ndf.Gender = df.Gender.astype('category')\ndf.Exited = df.Exited.astype(bool)\ndf.HasCrCard = df.HasCrCard.astype(bool)\ndf.IsActiveMember = df.IsActiveMember.astype(bool)","926196a0":"df.dtypes","39eed76e":"(train_df, test_df) = train_test_split(df, train_size=0.7, shuffle=True, random_state=42)","1fe0c283":"test_df.describe()","e2c91b2a":"train_df.describe()","852a6cf4":"columns = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\nfig = plt.figure(figsize=(30, 5))\naxes = fig.subplots(1, len(columns))\n\nfor (column, ax) in zip(columns, axes):\n    exited = train_df[train_df.Exited]\n    not_exited = train_df[~train_df.Exited]\n    ax.hist(not_exited[column], label='Not Exited', bins=15)\n    ax.hist(exited[column], label='Exited', bins=15)\n    ax.set_title(f'Distribution of \"{column}\"')\n    \nfig.legend(labels=('Not Exited', 'Exited'), loc='upper center', ncol=2)","8ba325ca":"bar_width = 0.2\ncolumns = ['Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember']\nfig = plt.figure(figsize=(30, 7))\naxes = fig.subplots(1, len(columns))\n\nfor (column, ax) in zip(columns, axes):\n    counts = train_df[~train_df.Exited][column].value_counts()\n    x = counts.index.astype(int)\n    ax.bar(x - bar_width \/ 2, counts, width=bar_width, label='Not Exited')\n\n    counts = train_df[train_df.Exited][column].value_counts()\n    x = counts.index.astype(int)\n    ax.bar(x + bar_width \/ 2, counts, width=bar_width, label='Exited')\n    \n    ax.set_title(f'Counts for \"{column}\"')\n    \nfig.legend(labels=('Not Exited', 'Exited'), loc='upper center', ncol=2)","b6be216a":"bar_width = 0.2\ncolumns = ['Gender', 'Geography']\nfig = plt.figure(figsize=(30, 7))\naxes = fig.subplots(1, len(columns))\n\nfor (column, ax) in zip(columns, axes):\n    counts = train_df[~train_df.Exited][column].value_counts()\n    x = np.arange(len(counts.index))\n    ax.bar(x - bar_width \/ 2, counts, width=bar_width, label='Not Exited')\n\n    counts = train_df[train_df.Exited][column].value_counts()\n    x = np.arange(len(counts.index))\n    ax.bar(x + bar_width \/ 2, counts, width=bar_width, label='Exited')\n    \n    ax.set_title(f'Counts for \"{column}\"')\n    ax.set_xticklabels(counts.index)\n    ax.set_xticks(x)\n    \nfig.legend(labels=('Not Exited', 'Exited'), loc='upper center', ncol=2)","1117b30d":"def cdf(values, bins):\n    values = np.sort(values)\n    (counts, edges) = np.histogram(values, bins=bins)\n    probs = counts.cumsum() \/ counts.sum()\n    return (edges, probs)\n\ndef plot_cdf(values, bins, title, xlabel):\n    (edges, probs) = cdf(values, bins)\n    plt.plot(edges[:-1], probs)\n    plt.title(title)\n    plt.xlabel(xlabel)","29455e06":"values = train_df[train_df.Exited].Age.values\nplot_cdf(values, bins=20, title='CDF', xlabel='Age')\nvalues = train_df[~train_df.Exited].Age.values\nplot_cdf(values, bins=20, title='CDF', xlabel='Age')\nplt.legend(labels=('Exited', 'Not Exited'))","4c84e90a":"# Perform a Smirnov-Kolmogorov Test\n# https:\/\/www.statisticshowto.datasciencecentral.com\/kolmogorov-smirnov-test\/\n# Assumption: \"not exited\" is the target distribution\n# Null Hypothesis: \"Exited age\" comes from the same distribution as \"not exited age\" (the distributions are equal)\n# Alternative hypothesis: The distributions are different\n\nN = 100\n# alpha = 0.05\ncritial_value = 1.36 \/ np.sqrt(N)\n\nvalues = train_df[train_df.Exited].sample(N).Age.values\n(_, cdf_exited) = cdf(values, bins=20)\nvalues = train_df[~train_df.Exited].sample(N).Age.values\n(_, cdf_not_exited) = cdf(values, bins=20)\n\nD = np.max(cdf_not_exited - cdf_exited)\n\nif D > critial_value:\n    print(f'{D} > {critial_value} :: Reject the null hypothesis: the distributions are different')\nelse:\n    print(f'{D} <= {critial_value} :: Accept the null hypothesis: the distributions are equal')","91fb3265":"# Perform a Permutation Test\n# Reference: Think Stats, Chapter 9 - Hypothesis Testing, p. 121\n# The idea os this test is to compare two groups (g1 and g2)\n# Then we simulate N random differences\n# If g1 and g2 come from the same distribution, their difference should be in the 95% interval of the normal distribution\n# Null Hypothesis: \"Exited age\" comes from the same distribution as \"not exited age\" (the distributions are equal)\n# Alternative hypothesis: The distributions are different\nexited = train_df[train_df.Exited].Age.values\nnot_exited = train_df[~train_df.Exited].Age.values\ngroup_diff = exited.mean() - not_exited.mean()\n\nN = 1000\nn = len(exited)\npool = np.hstack((exited, not_exited))\ndiffs = []\nfor _ in range(N):\n    np.random.shuffle(pool)\n    g1 = pool[:n]\n    g2 = pool[n:]\n    diffs.append(g1.mean() - g2.mean())\n\ndiff_mean = np.mean(diffs)\ndiff_std = np.std(diffs)\nif diff_mean - 2 * diff_std <= group_diff <= diff_mean + 2 * diff_std:\n    print('Accept the null hypothesis: the distributions are equal')\nelse:\n    print('Reject the null hypothesis: the distributions are different')\n    \nplt.hist(diffs, bins=20)\nplt.axvline(group_diff)","030b0b6e":"columns = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'Exited']\nsns.pairplot(train_df[columns], hue=\"Exited\", plot_kws={'s': 10})","a5845883":"columns = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Gender']\ntemp_df = train_df.query('Exited == 1')[columns]\nsns.pairplot(temp_df, hue='Gender', plot_kws={'s': 10})","dc914c92":"columns = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Geography']\ntemp_df = train_df.query('Exited == 1')[columns]\nsns.pairplot(temp_df, hue='Geography', plot_kws={'s': 10})","147876e6":"fig = plt.figure(figsize=(30, 5))\naxes = fig.subplots(1, 3)\n\nfor (category, ax) in zip(train_df.Geography.cat.categories, axes):\n    temp_df = train_df.query(f'Geography == \"{category}\"')\n    ax.hist(temp_df.query('Exited == 0').Balance)\n    ax.hist(temp_df.query('Exited == 1').Balance)\n    ax.set_title(category)\n\nplt.legend(labels=('Not Exited', 'Exited'))","1caff448":"def prepare_data(df):\n    X = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']].values\n    y = df.Exited.values.astype(float)\n\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X = scaler.transform(X)\n\n    X_cats = df[['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']]\n    ohe = OneHotEncoder(sparse=False)\n    ohe.fit(X_cats)\n    X_cats = ohe.transform(X_cats)\n\n    X = np.hstack([X, X_cats])\n    return (X, y)","a9412cea":"(X, y) = prepare_data(train_df)","3bded6c2":"X_corr = np.hstack([X, y.reshape((-1, 1))])\ncorr = np.corrcoef(X_corr.T)\nfig = plt.figure(figsize=(20, 10))\nlabels = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary',\n          'Geography_1', 'Geography_2', 'Geography_3', 'Gender_1', 'Gender_2',\n          'HasCrCard_1', 'HasCrCard_2', 'IsActiveMember_1', 'IsActiveMember_2', 'Exited']\nsns.heatmap(data=corr, annot=True, xticklabels=labels, yticklabels=labels)","4dfb3797":"(X_test, y_test) = prepare_data(test_df)","ff95e75c":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=20, random_state=1)\nrfc.fit(X, y)\ny_hat = rfc.predict(X_test)\n\nprint('Precision', precision_score(y_test, y_hat))\nprint('Recall', recall_score(y_test, y_hat))\nprint('F1-score', f1_score(y_test, y_hat))\nsns.heatmap(data=confusion_matrix(y_test, y_hat), annot=True, fmt='5d')","ee037c45":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rfc, random_state=1)\nperm.fit(X_test, y_test)\n\neli5.show_weights(perm, feature_names=labels[:-1])","398565a0":"Splitting the dataset in train\/test to avoid using test data while making the analysis.","f24788a9":"## Verifying the distribution difference in Age","d14e064b":"Looking through the distribution of continuous variables.\n`EstimatedSalary` looks uniform for both people who churned and the ones that didn't.\nOnly `Age` seems to carry some difference between the two groups."}}