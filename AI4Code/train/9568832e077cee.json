{"cell_type":{"e5173c8a":"code","6c8a5b6e":"code","a26b65d9":"code","d2ab98d1":"code","fafaff58":"code","2986a7f8":"code","b9bea7a5":"code","ed1737f8":"code","85fcfd40":"code","9fbe9bd4":"code","ae09e40b":"code","e314b85f":"code","073eab00":"code","a3168c93":"code","68813083":"code","9b41354d":"code","3556bfeb":"code","ffc67c9c":"code","b738f9a9":"code","de759488":"code","b6538a13":"code","90b687d5":"code","7ecacc6c":"code","fda0484e":"code","61e866dc":"code","08abcd30":"code","47c49c32":"code","2beeb96c":"code","98b6273b":"code","a6f3d19c":"code","d2cf6787":"code","44de99a2":"code","d04f0e32":"code","db461813":"code","e7063daf":"code","46511749":"code","c3413a7d":"code","7f30e8ff":"code","191c8d45":"markdown","647b405e":"markdown","8ad01b4b":"markdown","aca13fc5":"markdown","ca22b96b":"markdown","0527fd55":"markdown","65e711cd":"markdown","3c7b748b":"markdown","a4008c12":"markdown","19dee4fd":"markdown","4d63dcaa":"markdown","403604af":"markdown","1479a909":"markdown","76dca531":"markdown","95a8f61f":"markdown","bb695c05":"markdown","abfac627":"markdown","a9d0024f":"markdown"},"source":{"e5173c8a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\npd.pandas.set_option('display.max_columns',None)\nsns.set(color_codes=True)","6c8a5b6e":"plt.rcParams['xtick.labelsize'] = 15.\nplt.rcParams['ytick.labelsize'] = 15.\nplt.rcParams['figure.figsize'] = [15.,8.]\nplt.rcParams['legend.fontsize'] = 13.\nplt.rcParams['axes.labelsize'] = 15.","a26b65d9":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain.head()","d2ab98d1":"train.shape","fafaff58":"train.info()","2986a7f8":"null_value = [feature for feature in train.columns if train[feature].isnull().sum()>1]\n\nfor feature in null_value:\n    print(feature, np.round(train[feature].isnull().mean(),4), '% of missing value')","b9bea7a5":"for feature in null_value:\n    data = train.copy()\n    \n    data[feature] =  np.where(data[feature].isnull(), 1,0)\n    \n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.xlabel(\"0 = Not Null, 1 = Null\")\n    plt.ylabel(\"SalePrice\")\n    plt.show()","ed1737f8":"numerical_feature = [feature for feature in train.columns if train[feature].dtype !='O']\nprint('Number Of Numerical Feature', len(numerical_feature))\ntrain[numerical_feature].head()","85fcfd40":"year_feature = [feature for feature in numerical_feature if 'Yr' in feature or 'Year' in feature]\nprint('Number of Year Feature', len(year_feature))\ntrain[year_feature].head()","9fbe9bd4":"train.groupby('YrSold')['SalePrice'].median().plot()\nplt.show()","ae09e40b":"# compare the difference between all year features with the sales price\nfor feature in year_feature:\n    if feature != 'YrSold':\n        data=  train.copy()\n        data[feature] = data['YrSold']-data[feature]\n        plt.scatter(data[feature], data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","e314b85f":"# Discreate feature\ndiscreate_feature =  [feature for feature in numerical_feature if len(train[feature].unique())<25 and feature not in year_feature+['Id']]\nprint('Number of Discreate Feature', len(discreate_feature))\ntrain[discreate_feature].head()\nfor feature in discreate_feature:\n    data = train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.ylabel('Sale Price')\n    plt.xticks(rotation=0)\n    plt.show()","073eab00":"# Contineous feature\ncontineous_feature = [feature for feature in numerical_feature if feature not in discreate_feature+year_feature+['Id']]\nprint('Number of Contineous Feature', len(contineous_feature))\ntrain[contineous_feature].head()\n","a3168c93":"for feature in contineous_feature:\n    data  = train.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.show()","68813083":"train[contineous_feature].skew()","9b41354d":"# logrithmic transformation\nfor feature in contineous_feature:\n    data = train.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data['SalePrice'] = np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('Sale Price')\n        plt.show()","3556bfeb":"for feature in contineous_feature:\n    data = train.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        sns.boxplot(data=data, x=feature)\n        plt.show()","ffc67c9c":"categorical_feature = [feature for feature in train.columns if train[feature].dtype =='O']\ntrain[categorical_feature].head()","b738f9a9":"# Finding category types in the categorical colmuns\nfor feature in categorical_feature:\n    print(f'The feature is {feature} and the number of categories are {len(train[feature].unique())}')","de759488":"for feature in categorical_feature:\n    data = train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Sale Price')\n    plt.show()","b6538a13":"categorial_nan = [feature for feature in train.columns if train[feature].isnull().sum()>1 and train[feature].dtypes=='O']\n\nfor feature in categorial_nan:\n    print(\"{}: {} % of missing value\".format(feature, np.round(train[feature].isnull().mean(),4)))","90b687d5":"#Filling nan \ndef replace_cat_nan(train, categorical_nan):\n    data = train.copy()\n    data[categorical_nan] = data[categorical_nan].fillna('Missing')\n    return data\ntrain = replace_cat_nan(train,categorial_nan)\ntrain[categorical_feature].isna().sum()","7ecacc6c":"numerical_nan = [feature for feature in numerical_feature if train[feature].isnull().sum()>1 and train[feature].dtypes !='O']\n\nfor feature in numerical_nan:\n    print(f'{feature}: {np.round(train[feature].isnull().mean(),4)} % missing value')","fda0484e":"# replacing numerical missing value\nfor feature in numerical_nan:\n    # as we have outliers in the numerical data we replace nan with median\n    median_value = train[feature].median()\n    \n   # make a new column in which 1 represent nan value and 0 represent not had nan value\n    train[feature+'nan'] = np.where(train[feature].isnull(),1,0)\n    train[feature].fillna(median_value, inplace=True)\n    \ntrain[numerical_nan].isna().sum()\n","61e866dc":"train.head(20)","08abcd30":"### Datetime feature\nfor feature in year_feature:\n    if feature != 'YrSold':\n        train[feature] = train['YrSold']-train[feature]","47c49c32":"train[year_feature].head()","2beeb96c":"train.head()","98b6273b":"numerical_feat = ['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']\n\nfor feature in numerical_feat:\n    train[feature] = np.log(train[feature])","a6f3d19c":"train.head()","d2cf6787":"train[categorical_feature].head()","44de99a2":"for feature in categorical_feature:\n    temp_cat = train.groupby(feature)['SalePrice'].count()\/len(train)\n    temp_df = temp_cat[temp_cat>0.01].index\n    train[feature] = np.where(train[feature].isin(temp_df), train[feature], 'rare_category')","d04f0e32":"train[50:100]","db461813":"from sklearn.preprocessing import LabelEncoder\nfor feature in categorical_feature:\n    le = LabelEncoder()\n    train[feature] = le.fit_transform(train[feature])","e7063daf":"train.head()","46511749":"from sklearn.preprocessing import MinMaxScaler\n\nfeature_scale  = [feature for feature in train.columns if feature not in ['Id', 'SalePrice']]\nscaler = MinMaxScaler()\ntrain[feature_scale] = scaler.fit_transform(train[feature_scale])","c3413a7d":"train.head()","7f30e8ff":"new_train = train.copy()\nnew_train.to_csv('new_train.csv', index=False)","191c8d45":"### Numerical Features","647b405e":"### since there are many missing values in the dataset, we have to see the relation of these to the target columns","8ad01b4b":"### Checking outliers","aca13fc5":"### Most of the columsn are in object data type, we will convert these id feature engineering ","ca22b96b":"## finding categorial feature nan value and filling it ","0527fd55":"### Checking relation between YrSold and SalePrice","65e711cd":"### SalePrice decrease with the incresing year","3c7b748b":"### Handling Rare categorical Categories\n### i.e we will remove the categorical feature that are present less than 1% of the observation","a4008c12":"### Finding null values","19dee4fd":"### Datetime Feature","4d63dcaa":"### Finding relationship between categorical feature and target value which is SalePrice","403604af":"### Neighborhood has hightest number of catgories ","1479a909":"### Performing Log Normal Distribution on numerical features","76dca531":"### Comment:\n* `LotFrontage, Alley, LotFrontage, MasVnrArea, Fence and MiscFeature missing values are having a relation with the SalePrice`","95a8f61f":"### Catgorical features","bb695c05":"### finding numerical nan value and filling it","abfac627":"### We have many outliers ","a9d0024f":"### Feature Scaling"}}