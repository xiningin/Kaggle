{"cell_type":{"faeb9321":"code","4999fee0":"code","bed9eef2":"code","6dd281f1":"code","b015f210":"code","a74e73e7":"code","940efa5a":"code","217f4510":"code","2984aa81":"code","4d34e42b":"code","9f934bf7":"code","20609ddc":"code","1b1789d6":"code","bb4e662f":"code","cac3d222":"code","8607a15a":"code","736dfc12":"code","e961989f":"code","66b49520":"code","2cb53757":"code","b3babc1b":"code","9ff2d08a":"code","8d365a85":"code","d0ff48aa":"code","cf5c008d":"code","8ab7f15c":"code","49572b73":"code","d1a0b1ec":"code","a1f4f565":"code","4f09f10c":"code","e9f37673":"markdown","16d68278":"markdown","bcdfd889":"markdown","66eb1399":"markdown","fe4dcb46":"markdown","68852898":"markdown","5b4e4d30":"markdown","49e77553":"markdown","bca9b1d2":"markdown","7400ec77":"markdown","1212047b":"markdown","d5cfecb1":"markdown"},"source":{"faeb9321":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport collections\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\n\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import make_scorer, precision_score, recall_score, classification_report, confusion_matrix\nfrom collections import Counter\nfrom sklearn.preprocessing import RobustScaler\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4999fee0":"%%time\ndataset = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndataset.columns = [x.lower().strip().replace(' ','_') for x in dataset.columns]","bed9eef2":"dataset.shape","6dd281f1":"# Data processing, metrics and modeling\nfrom sklearn.preprocessing import LabelEncoder\n#fill in mean for floats\nfor c in dataset.columns:\n    if dataset[c].dtype=='float16' or  dataset[c].dtype=='float32' or  dataset[c].dtype=='float64':\n        dataset[c].fillna(dataset[c].mean())\n\n#fill in -999 for categoricals\ndataset = dataset.fillna(-999)\n# Label Encoding\nfor f in dataset.columns:\n    if dataset[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(dataset[f].values))\n        dataset[f] = lbl.transform(list(dataset[f].values))\n        \nprint('Labelling done.')  ","b015f210":"cat_features = [i for i in dataset.columns if str(dataset[i].dtype) in ['object', 'category']]\nif len(cat_features) > 0:\n    dataset[cat_features] = dataset[cat_features].astype('category')\n\ndf = dataset.copy()\nfor i in cat_features:\n    df[i] = dataset[i].cat.codes\n\ndf.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]","a74e73e7":"y = df['sars_cov_2_exam_result'].copy()\nX = df.copy()\nX = X.drop(['patient_id', 'sars_cov_2_exam_result', \n                 'patient_addmited_to_regular_ward__1_yes__0_no_', \n                 'patient_addmited_to_semi_intensive_unit__1_yes__0_no_', \n                 'patient_addmited_to_intensive_care_unit__1_yes__0_no_'], axis=1)","940efa5a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2020)","217f4510":"# Invoke classifier\nclf = LogisticRegression()\n\n# Cross-validate on the train data\ntrain_cv = cross_val_score(X=X_train,y=y_train,estimator=clf,cv=3)\nprint(\"TRAIN GROUP\")\nprint(\"\\nCross-validation accuracy scores:\",train_cv)\nprint(\"Mean score:\",train_cv.mean())\n\n# Now predict on the test group\nprint(\"\\nTEST GROUP\")\ny_pred = clf.fit(X_train, y_train).predict(X_test)\nprint(\"\\nAccuracy score:\",clf.score(X_test,y_test))\n\n# Classification report\nprint('\\nClassification report:\\n')\nprint(classification_report(y_test, y_pred))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\nplt.show()","2984aa81":"# Invoke classifier\nclf = LogisticRegression()\n\n# Make a scoring callable from recall_score\nrecall = make_scorer(recall_score)\n\n# Cross-validate on the train data\ntrain_cv = cross_val_score(X=X_train,y=y_train,estimator=clf,scoring=recall,cv=3)\nprint(\"TRAIN GROUP\")\nprint(\"\\nCross-validation recall scores:\",train_cv)\nprint(\"Mean recall score:\",train_cv.mean())\n\n# Now predict on the test group\nprint(\"\\nTEST GROUP\")\ny_pred = clf.fit(X_train, y_train).predict(X_test)\nprint(\"\\nRecall:\",recall_score(y_test,y_pred))\n\n# Classification report\nprint('\\nClassification report:\\n')\nprint(classification_report(y_test, y_pred))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\nplt.show()","4d34e42b":"# Balancing Classes before checking for correlation\n\n# Join the train data\ntrain = X_train.join(y_train)\n\nprint('Data shape before balancing:',train.shape)\nprint('\\nCounts of Positive VS Negavive for COVID-19 in previous data:')\nprint(train['sars_cov_2_exam_result'].value_counts())\nprint('-'*40)\n\n# Oversample COVID-19 exams. Imblearn's ADASYN was built for class-imbalanced datasets\nX_bal, y_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(X_train,y_train)\n\n# Join X and y\nX_bal = pd.DataFrame(X_bal,columns=X_train.columns)\ny_bal = pd.DataFrame(y_bal,columns=['sars_cov_2_exam_result'])\nbalanced = X_bal.join(y_bal)\n\n\nprint('-'*40)\nprint('Data shape after balancing:',balanced.shape)\nprint('\\nCounts of Positive VS Negavive for COVID-19 in new data:')\nprint(balanced['sars_cov_2_exam_result'].value_counts())","9f934bf7":"# Removing Outliers from high-correlation features\nno_outliers=pd.DataFrame(balanced.copy())\n# Balanced DataFrame\nbal_corr = balanced.corr()\ncols = bal_corr.sars_cov_2_exam_result.index[:-1]\n\n# For each feature correlated with Class...\nfor col in cols:\n    # If absolute correlation value is more than X percent...\n    correlation = bal_corr.loc['sars_cov_2_exam_result',col]\n    if np.absolute(correlation) > 0.1:\n        \n        # Separate the classes of the high-correlation column\n        negative = no_outliers.loc[no_outliers.sars_cov_2_exam_result==0,col]\n        positive = no_outliers.loc[no_outliers.sars_cov_2_exam_result==1,col]\n\n        # Identify the 25th and 75th quartiles\n        all_values = no_outliers.loc[:,col]\n        q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n        # Get the inter quartile range\n        iqr = q75 - q25\n        # Smaller cutoffs will remove more outliers\n        cutoff = iqr * 7\n        # Set the bounds of the desired portion to keep\n        lower, upper = q25 - cutoff, q75 + cutoff\n        \n        # If positively correlated...\n        # Drop nonfrauds above upper bound, and COVID-19 Exams below lower bound\n        if correlation > 0: \n            no_outliers.drop(index=negative[negative>upper].index,inplace=True)\n            no_outliers.drop(index=positive[positive<lower].index,inplace=True)\n        \n        # If negatively correlated...\n        # Drop negative exams below lower bound, and posivite exams above upper bound\n        elif correlation < 0: \n            no_outliers.drop(index=negative[negative<lower].index,inplace=True)\n            no_outliers.drop(index=positive[positive>upper].index,inplace=True)\n        \nprint('\\nData shape before removing outliers:', balanced.shape)\nprint('\\nCounts of positive VS negative in previous data:')\nprint(balanced.sars_cov_2_exam_result.value_counts())\nprint('-'*40)\nprint('-'*40)\nprint('\\nData shape after removing outliers:', no_outliers.shape)\nprint('\\nCounts of positive VS negative in new data:')\nprint(no_outliers.sars_cov_2_exam_result.value_counts())","20609ddc":"# Feature Selection based on correlation with Class\nfeat_sel =pd.DataFrame(no_outliers.copy())\nprint('\\nData shape before feature selection:', feat_sel.shape)\nprint('\\nCounts of  positive VS negative before feature selection:')\nprint(feat_sel.sars_cov_2_exam_result.value_counts())\nprint('-'*40)\n# Correlation matrix after removing outliers\nnew_corr = feat_sel.corr()\nfor col in new_corr.sars_cov_2_exam_result.index[:-1]:\n    # Pick desired cutoff for dropping features. In absolute-value terms.\n    if np.absolute(new_corr.loc['sars_cov_2_exam_result',col]) < 0.1:\n        # Drop the feature if correlation is below cutoff\n        feat_sel.drop(columns=col,inplace=True)\n\nprint('-'*40)\nprint('\\nData shape after feature selection:', feat_sel.shape)\nprint('\\nCounts of  positive VS negative in new data:')\nprint(feat_sel.sars_cov_2_exam_result.value_counts())","1b1789d6":"# Undersample model for efficiency and balance classes.\n\nX_train = feat_sel.drop('sars_cov_2_exam_result',1)\ny_train = feat_sel.sars_cov_2_exam_result\n\n# After feature-selection, X_test needs to include only the same features as X_train\ncols = X_train.columns\nX_test = X_test[cols]\n\n# Undersample and balance classes\nX_train, y_train = RandomUnderSampler(sampling_strategy={1:3863,0:3863}).fit_resample(X_train,y_train)\n\nprint('\\nX_train shape after reduction:', X_train.shape)\nprint('\\nCounts of posivite VS negative in y_train:')\nprint(np.unique(y_train, return_counts=True))","bb4e662f":"# DataFrame to store classifier performance\nperformance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity'])","cac3d222":"# Load simple classifiers\nclassifiers = [SVC(max_iter=1000),LogisticRegression(),\n               DecisionTreeClassifier(),KNeighborsClassifier()]\n\n# Get a classification report from each algorithm\nfor clf in classifiers:    \n    # Heading\n    print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n    \n    # Cross-validate on the train data\n    print(\"TRAIN GROUP\")\n    train_cv = cross_val_score(X=X_train, y=y_train, \n                               estimator=clf, scoring=recall,cv=3)\n    print(\"\\nCross-validation recall scores:\",train_cv)\n    print(\"Mean recall score:\",train_cv.mean())\n\n    # Now predict on the test group\n    print(\"\\nTEST GROUP\")\n    y_pred = clf.fit(X_train, y_train).predict(X_test)\n    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n    \n    # Print confusion matrix\n    conf_matrix = confusion_matrix(y_test,y_pred)\n    sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n    plt.show()\n    \n    # Store results\n    performance.loc[clf.__class__.__name__+'_default',\n                    ['Train_Recall','Test_Recall','Test_Specificity']] = [\n        train_cv.mean(),\n        recall_score(y_test,y_pred),\n        conf_matrix[0,0]\/conf_matrix[0,:].sum() ]\n        \n        ","8607a15a":"# Scores obtained\nperformance","736dfc12":"# Parameters to optimize\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l2']\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l1','l2']\n}]\n\nclf = LogisticRegression(\n    n_jobs=-1, # Use all CPU\n    class_weight={0:0.1,1:1} # Prioritize frauds\n)\n\n# Load GridSearchCV\nsearch = GridSearchCV(\n    estimator=clf,\n    param_grid=params,\n    n_jobs=-1,\n    scoring=recall\n)\n\n# Train search object\nsearch.fit(X_train, y_train)\n\n# Heading\nprint('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n\n# Extract best estimator\nbest = search.best_estimator_\nprint('Best parameters: \\n\\n',search.best_params_,'\\n')\n\n# Cross-validate on the train data\nprint(\"TRAIN GROUP\")\ntrain_cv = cross_val_score(X=X_train, y=y_train, \n                           estimator=best, scoring=recall,cv=3)\nprint(\"\\nCross-validation recall scores:\",train_cv)\nprint(\"Mean recall score:\",train_cv.mean())\n\n# Now predict on the test group\nprint(\"\\nTEST GROUP\")\ny_pred = best.fit(X_train, y_train).predict(X_test)\nprint(\"\\nRecall:\",recall_score(y_test,y_pred))\n\n# Get classification report\nprint(classification_report(y_test, y_pred))\n\n# Print confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\nplt.show()\n    \n# Store results\nperformance.loc[clf.__class__.__name__+'_search',\n                ['Train_Recall','Test_Recall','Test_Specificity']] = [\n    train_cv.mean(),\n    recall_score(y_test,y_pred),\n    conf_matrix[0,0]\/conf_matrix[0,:].sum()\n]","e961989f":"performance","66b49520":"pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head()","2cb53757":"# Make a scoring function that improves specificity while identifying all posivite exams\ndef recall_optim(y_true, y_pred):\n    \n    conf_matrix = confusion_matrix(y_true, y_pred)\n    \n    # Recall will be worth a greater value than specificity\n    rec = recall_score(y_true, y_pred) * 0.8 \n    spe = conf_matrix[0,0]\/conf_matrix[0,:].sum() * 0.2 \n    \n    # Imperfect recalls will lose a penalty\n    # This means the best results will have perfect recalls and compete for specificity\n    if rec < 0.8:\n        rec -= 0.2\n    return rec + spe \n    \n# Create a scoring callable based on the scoring function\noptimize = make_scorer(recall_optim)","b3babc1b":"scores = []\nfor rec, spe in performance[['Test_Recall','Test_Specificity']].values:\n    rec = rec * 0.8\n    spe = spe * 0.2\n    if rec < 0.8:\n        rec -= 0.20\n    scores.append(rec + spe)\nperformance['Optimize'] = scores\ndisplay(performance)","9ff2d08a":"def score_optimization(params,clf):\n    # Load GridSearchCV\n    search = GridSearchCV(\n        estimator=clf,\n        param_grid=params,\n        n_jobs=-1,\n        scoring=optimize\n    )\n\n    # Train search object\n    search.fit(X_train, y_train)\n\n    # Heading\n    print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n\n    # Extract best estimator\n    best = search.best_estimator_\n    print('Best parameters: \\n\\n',search.best_params_,'\\n')\n\n    # Cross-validate on the train data\n    print(\"TRAIN GROUP\")\n    train_cv = cross_val_score(X=X_train, y=y_train, \n                               estimator=best, scoring=recall,cv=3)\n    print(\"\\nCross-validation recall scores:\",train_cv)\n    print(\"Mean recall score:\",train_cv.mean())\n\n    # Now predict on the test group\n    print(\"\\nTEST GROUP\")\n    y_pred = best.fit(X_train, y_train).predict(X_test)\n    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n\n    # Get classification report\n    print(classification_report(y_test, y_pred))\n\n    # Print confusion matrix\n    conf_matrix = confusion_matrix(y_test,y_pred)\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n    plt.show()\n\n    # Store results\n    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n        train_cv.mean(),\n        recall_score(y_test,y_pred),\n        conf_matrix[0,0]\/conf_matrix[0,:].sum(),\n        recall_optim(y_test,y_pred)\n    ]\n    # Look at the parameters for the top best scores\n    display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n    display(performance)","8d365a85":"# Parameters to optimize\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l2'],\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.5},{1:1,0:0.7}]\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l1','l2'],\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.5},{1:1,0:0.7}]\n}]\n\nclf = LogisticRegression(\n    n_jobs=-1 # Use all CPU\n)\n\nscore_optimization(clf=clf,params=params)","d0ff48aa":"# Parameters to optimize\nparams = {\n    'criterion':['gini','entropy'],\n    'max_features':[None,'sqrt'],\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.5},{1:1,0:0.7}]\n    }\n\nclf = DecisionTreeClassifier(\n)\n\nscore_optimization(clf=clf,params=params)","cf5c008d":"# Parameters to optimize\nparams = {\n    'kernel':['rbf','linear'],\n    'C': [0.3,0.5,0.7,1],\n    'gamma':['auto','scale'],\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.5},{1:1,0:0.7}]\n    }\n\n# classifier\nclf = SVC(\n    cache_size=3000,\n    max_iter=1000, # Limit processing time\n)\nscore_optimization(clf=clf,params=params)","8ab7f15c":"# Parameters to compare\nparams = {\n    \"n_neighbors\": list(range(2,6,1)), \n    'leaf_size': list(range(20,41,10)),\n    'algorithm': ['ball_tree','auto'],\n    'p': [1,2] # Regularization parameter. Equivalent to 'l1' or 'l2'\n}\n\n#  classifier\nclf = KNeighborsClassifier(\n    n_jobs=-1\n)\nscore_optimization(clf=clf,params=params)","49572b73":"# Parameters to compare\nparams = {\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}],\n    'sampling_strategy':['all','not majority','not minority']\n}\n\n# Implement the classifier\nclf = BalancedRandomForestClassifier(\n    criterion='entropy',\n    max_features=None,\n    n_jobs=-1\n)\nscore_optimization(clf=clf,params=params)","d1a0b1ec":"# Parameters to compare\nparams = {\n    'criterion':['entropy','gini'],\n    'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n}\n\n# Implement the classifier\nclf = RandomForestClassifier(\n    n_estimators=100,\n    max_features=None,\n    n_jobs=-1,\n)\n\nscore_optimization(clf=clf,params=params)","a1f4f565":"# Let's get the mean between test recall and test specificity\nperformance['Mean_RecSpe'] = (performance.Test_Recall+performance.Test_Specificity)\/2\nperformance","4f09f10c":"colors = [\"purple\", \"green\", \"orange\", \"magenta\",\"#CFC60E\",\"#0FBBAE\", \"#bf80ff\", \"#ff3399\", \"#ff1a1a\", \"#00b300\", \"#ff8000\"]\nrecall_ = performance.Test_Recall.to_dict() \n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Recall %\")\nplt.xlabel(\"Algorithms\")\nplt.xticks(rotation=45)\nsns.barplot(x=list(recall_.keys()), y=list(recall_.values()), palette=colors)\nplt.show()","e9f37673":"### Comparing Models","16d68278":"### Now add the optimized scores to the existing performance DataFrame","bcdfd889":"### End Notebook","66eb1399":"### Imblearn' BalancedRandomForest- Optimized","fe4dcb46":"### KNeighborsClassifier- Optimized","68852898":"### DecisionTreeClassifier- Optimized","5b4e4d30":"### Optimize Specificity while Maintaining Perfect Recall","49e77553":"### SKlearn' RandomForestClassifier- Optimized","bca9b1d2":"### Support Vector Classifier- Optimized","7400ec77":"### LogisticRegression- Optimized","1212047b":"### Acknowledgments: \n[Optimizing Imbalanced Classification](https:\/\/www.kaggle.com\/miguelniblock\/optimizing-imbalanced-classification-100-recall\/notebook) by @miguelniblock, [Growing RForest](https:\/\/www.kaggle.com\/palmbook\/growing-rforest-97-recall-and-100-precision) by @palmbook","d5cfecb1":"### Research Question\n- What is the best way to predict positive results? \n\n- Focus on reducing false negatives.\nVS\n\n- Focus on reducing false positives.\nVS\n\n- Focus on a custom balance?"}}