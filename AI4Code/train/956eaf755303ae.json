{"cell_type":{"ee03490c":"code","97313414":"code","6c0da094":"code","fa6c7771":"code","b0ce8d47":"code","673da5cb":"code","60c242c4":"code","67a6acbe":"code","74310c9e":"code","9a668de0":"code","03b850cb":"code","3130d83a":"code","b53758ba":"code","fa968b5f":"code","0556ab26":"code","981be815":"code","eb857008":"code","cba694c9":"code","b617c71b":"code","dd1345ba":"code","4a0df79e":"markdown","e8d332d0":"markdown","d597b0af":"markdown"},"source":{"ee03490c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97313414":"# Importing essential libraries\nimport cv2, glob, os\nfrom matplotlib import pyplot as plt\nfrom PIL import Image","6c0da094":"# Importing essential datasets\nBASE = '..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/'","fa6c7771":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/MONAI-logo-color.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Logo',fontsize=20),plt.show();","b0ce8d47":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/amp_training_a100.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Training Charts',fontsize=20),plt.show();","673da5cb":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/cache_dataset.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Cache',fontsize=20),plt.show();","60c242c4":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/dataset_progress.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Dataset progress',fontsize=20),plt.show();","67a6acbe":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/decollate_batch.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Decollate Batch',fontsize=20),plt.show();","74310c9e":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/deepgrow_scheme.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Deepgrow Scheme',fontsize=20),plt.show();","9a668de0":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/end_to_end.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai End-to-End',fontsize=20),plt.show();","03b850cb":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/gmm_feature_set_comparison_s.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Gmm Feature Set Comparisons',fontsize=20),plt.show();","3130d83a":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/invert_transforms.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Invert Transforms',fontsize=20),plt.show();","b53758ba":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/medical_transforms.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Medical Transforms',fontsize=20),plt.show();","fa968b5f":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/metrics_report.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Metrics Report',fontsize=20),plt.show();","0556ab26":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/models_ensemble.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Models Ensemble',fontsize=20),plt.show();","981be815":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/multi_transform_chains.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Multi Transform Chains',fontsize=20),plt.show();","eb857008":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/pathology.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Pathology ',fontsize=20),plt.show();","cba694c9":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/sliding_window.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Sliding Window',fontsize=20),plt.show();","b617c71b":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/unet-pipe.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Unet Pipe',fontsize=20),plt.show();","dd1345ba":"# Reading and understanding a single image\nimg = cv2.imread(\"..\/input\/monai-v060-deep-learning-in-healthcare-imaging\/docs\/images\/workflows.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(img, cmap = 'twilight'), plt.axis('off'), plt.title('Monai Workflows ',fontsize=20),plt.show();","4a0df79e":"\"The MONAI framework is the open-source foundation being created by Project MONAI. MONAI is a freely available, community-supported, PyTorch-based framework for deep learning in healthcare imaging. It provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.\"\n\n\"Project MONAI also includes MONAI Label, an intelligent open source image labeling and learning tool that helps researchers and clinicians collaborate, create annotated datasets, and build AI models in a standardized MONAI paradigm.\"\n\nhttps:\/\/monai.io\/\n\nhttps:\/\/github.com\/Project-MONAI\/tutorials","e8d332d0":"#I know that is Not what is expect to be made. Though I'll wait for anyone to work with Monai Dataset to learn.\n\nI'll read the tutorials to learn how to work with MONAI (Medical Open Network for AI).","d597b0af":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #7FFFD4;\"><b style=\"color:#006400;\">MONAI: Medical Open Network for AI<\/b><\/h1><\/center>"}}