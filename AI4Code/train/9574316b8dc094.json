{"cell_type":{"d5f9d11c":"code","801415fd":"code","03f98724":"code","e8d35f15":"code","8a4b9264":"code","b3b4cd26":"code","de2f41c5":"code","6d0ac41b":"code","4b2b5218":"code","d86962a7":"code","20ca19d1":"code","a742ec09":"code","e44223b9":"code","d6bc6191":"code","1921cf27":"code","ba50b26f":"code","88c6ab58":"code","26a121df":"code","aa7b3f5b":"code","f84d4533":"code","80daa34d":"code","8b942620":"code","2e270c9d":"code","b18a08e5":"code","507656dd":"code","f6af0609":"code","5633d3f9":"code","916e1bae":"code","d4810ee6":"code","18195fac":"code","05354c07":"code","a0362f26":"code","250bd243":"code","cfe7ee0c":"code","a3265d0d":"code","bc42af5d":"code","f72c5ef4":"code","6745b493":"code","85288166":"markdown","7a4d571b":"markdown","2bb10acd":"markdown","eacfede8":"markdown","7b13c3ef":"markdown","b64d34f6":"markdown"},"source":{"d5f9d11c":"# Install Rapids\nimport sys\n!cp ..\/input\/rapids\/rapids.0.18.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","801415fd":"# Install BERT\n!pip install ..\/input\/bertfortf2\/bert\/py-params-0.10.2\/py-params-0.10.2\n!pip install ..\/input\/bertfortf2\/bert\/params-flow-0.8.2\/params-flow-0.8.2\n!pip install ..\/input\/bertfortf2\/bert\/bert-for-tf2-0.14.9\/bert-for-tf2-0.14.9","03f98724":"# Imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport nltk\nimport cuml, cupy\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport bert\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nfrom tensorflow import keras\nfrom PIL import Image","e8d35f15":"# RESTRICT TENSORFLOW TO 8GB OF GPU RAM\n# SO THAT WE HAVE 8GB RAM FOR RAPIDS\nLIMIT = 8\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","8a4b9264":"# Configure if we are computing CV on train data or making submission on test data\nCOMPUTE_CV = True\n\n# If test size is > 3, configure for submission\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n\nif len(test) > 3:\n    COMPUTE_CV = False\n    del test","b3b4cd26":"# Load data\nif COMPUTE_CV:\n    # If we are computing CV, use train dataset\n    df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    \n    # Create dictionary of label groups (key) and posting IDs (values)\n    label_dict = df.groupby('label_group')['posting_id'].unique().to_dict()\n\n    # Create column of matching products\n    df['matches'] = df['label_group'].map(label_dict)\n    \nelse:\n    df = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')","de2f41c5":"# Create directory path to images\nif COMPUTE_CV:\n    image_dir = '..\/input\/shopee-product-matching\/train_images'\nelse:\n    image_dir = '..\/input\/shopee-product-matching\/test_images'","6d0ac41b":"# Import re-trained EfficientNetB4\nmodel = keras.models.load_model('..\/input\/efficientnetb4model8\/model_8')","4b2b5218":"# Set image size for EfficientNetB4 input\nim_size = 380\n\n# Set batch size\nbatch = 8\n\n# As the dataset is large, we will run the modelling in chunks\nchunk_size = 5000\nchunks = np.arange(np.ceil(len(df) \/ chunk_size))\n\n# Set image paths of all images\nimage_paths = image_dir + '\/' + df['image']","d86962a7":"# Create function to pre-process images\ndef process_image(image_file_path):\n    # Read and decode image from file path\n    image = tf.io.read_file(image_file_path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n\n    # Resize image\n    image = tf.image.resize(image, (im_size,im_size))\n\n    # Scale image vector\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image","20ca19d1":"# Create tensorflow dataset from image paths\ndef get_data(image_paths):\n    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n\n    # Process dataset with the image processing function created above. Set parallel calls to autotune\n    dataset = dataset.map(process_image, num_parallel_calls = tf.data.AUTOTUNE)\n\n    # Set batch size\n    dataset = dataset.batch(batch_size = batch)\n\n    # Set prefetch to autotune\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset","a742ec09":"# Generate image embeddings from EfficientNetB4 model in chunks\n# Initialize embeddings list\nembeddings = []\n\n# Iterate through chunks\nfor i in chunks:\n    # Start and end index\n    start = int(i * chunk_size)\n    end = int((i + 1) * chunk_size)\n\n    # Get image dataset\n    image_dataset = get_data(image_paths[start:end])\n\n    # Generate embeddings\n    chunk_embeddings = model.predict(image_dataset)\n\n    # Append to embeddings list\n    embeddings.append(chunk_embeddings)\n\n    # Print status\n    print(f'Chunk {i} completed')\n\nimage_embeddings = np.concatenate(embeddings)","e44223b9":"# Delete unused variables\ndel model\ndel image paths\ndel embeddings\ndel image_dataset\ndel chunk_embeddings\ngc.collect()","d6bc6191":"image_embeddings.shape","1921cf27":"# Create stop words\nstop_words = nltk.corpus.stopwords.words('english') + \\\n             nltk.corpus.stopwords.words('indonesian') + \\\n             [# Sales words:\n                'free', 'gift', 'give', 'get', 'ready', 'stock', 'stocks', 'stok',\n                'ori', 'original', 'official', 'new', 'latest',\n                'import', 'low', 'price', 'cheap', 'vip', 'discount', 'warranty',\n                'promo', 'promotion', 'buy', 'buyer', 'shop', 'shopper', 'shopping',\n                'bigsale', 'sale', 'sell', 'seller', 'resell', 'reseller',\n                'all', 'any', 'full', 'include', 'includes', 'inclusive', 'tax',\n    \n                # Units\n                'pieces', 'piece', 'pcs', 'pc', 'box', 'boxes', 'pack', 'packs', 'packet', 'packets', 'paket', 'package',\n                'set', 'sets', 'size', 'roll', 'rolls', 'sachet', 'sachets'\n                \n                # Dimensions\n                'ml', 'l', 'litre', 'liter', 'g', 'gr', 'gram', 'kg', 'kilo', 'kilogram',\n                'mm', 'cm', 'm', 'meter', 'metre', 'yard', 'inch', 'x',\n    \n                # Miscellaneous alphabets\n                'c', 'xe', 'f', 'b', 'v', 'xa',\n                \n                # Location words:\n                'shopee', 'indonesia', 'indonesian', 'indo', 'id', 'jakarta', 'local', 'lokal',\n    \n                # English descriptors:\n                'fashion', 'colour', 'color', 'design',\n                'plus', 'pro', 'mini', 'premium', 'pro', 'super', 'extra', 'big', 'small',\n                \n                # Indonesian descriptors:\n                'bpom', 'muat', 'cod', 'murah', 'isi', 'warna', 'pajak', 'garansi', 'beli', 'gratis',\n                'terbaru', 'harga', 'resmi',\n]\n\nstop_words = list(set(stop_words))","ba50b26f":"# Create function for generating tokens from titles\ndef process_tokens(title, stop_words, tokenizer):\n    words = tokenizer.tokenize(title.lower())\n    return ' '.join([word for word in words if word not in stop_words])","88c6ab58":"tokenizer = nltk.tokenize.RegexpTokenizer('[a-zA-Z0-9]+')\ntitle_tokens = df['title'].map(lambda x: process_tokens(x, stop_words, tokenizer)).to_numpy()","26a121df":"tvec = TfidfVectorizer()\ntfidf_embeddings = tvec.fit_transform(title_tokens)","aa7b3f5b":"tfidf_embeddings.shape","f84d4533":"def get_model(model_url, max_seq_length):\n    labse_layer = hub.KerasLayer(model_url, trainable=True)\n\n    # Define input.\n    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                             name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                         name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                          name=\"segment_ids\")\n\n    # LaBSE layer.\n    pooled_output,  _ = labse_layer([input_word_ids, input_mask, segment_ids])\n\n    # The embedding is l2 normalized.\n    pooled_output = tf.keras.layers.Lambda(\n          lambda x: tf.nn.l2_normalize(x, axis=1))(pooled_output)\n\n    # Define model.\n    return tf.keras.Model(\n            inputs=[input_word_ids, input_mask, segment_ids],\n            outputs=pooled_output), labse_layer","80daa34d":"max_seq_length = 64","8b942620":"labse_model, labse_layer = get_model(model_url=\"..\/input\/labse-1\", max_seq_length=max_seq_length)","2e270c9d":"vocab_file = labse_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = labse_layer.resolved_object.do_lower_case.numpy()\ntokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n\ndef create_input(input_strings, tokenizer, max_seq_length):\n    \n    input_ids_all, input_mask_all, segment_ids_all = [], [], []\n    for input_string in input_strings:\n        \n        # Tokenize input.\n        input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n        input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n        sequence_length = min(len(input_ids), max_seq_length)\n\n        # Padding or truncation.\n        if len(input_ids) >= max_seq_length:\n            input_ids = input_ids[:max_seq_length]\n        else:\n            input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n\n        input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n\n        input_ids_all.append(input_ids)\n        input_mask_all.append(input_mask)\n        segment_ids_all.append([0] * max_seq_length)\n\n    return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)","b18a08e5":"def encode(input_text):\n    input_ids, input_mask, segment_ids = create_input(input_text, tokenizer, max_seq_length)\n    return labse_model([input_ids, input_mask, segment_ids])","507656dd":"# As the dataset is large, we will run the embedding in chunks\nchunk_size = 2000\nchunks = np.arange(np.ceil(len(df) \/ chunk_size))","f6af0609":"# Generate text embeddings from LaBSE model in chunks for tokens set 2\n# Initialize embeddings list\nembeddings = []\n\n# Iterate through chunks\nfor i in chunks:\n    # Start and end index\n    start = int(i * chunk_size)\n    end = int((i + 1) * chunk_size)\n\n    # Get tokens\n    tokens = title_tokens[start:end]\n\n    # Generate embeddings\n    text_embeddings = encode(tokens)\n\n    # Append to embeddings list\n    embeddings.append(text_embeddings)\n\n    # Print status\n    print(f'Chunk {i} completed')\n\ntext_labse_embeddings = np.concatenate(embeddings)","5633d3f9":"# Delete unused variables\ndel labse_model\ndel labse_layer\ndel embeddings\ndel tokens\ndel title_tokens\ndel text_embeddings\ndel tokenizer\ndel vocab_file\ngc.collect()","916e1bae":"text_labse_embeddings.shape","d4810ee6":"combined_embeddings = np.concatenate((image_embeddings,text_labse_embeddings), axis=1)\nss = StandardScaler(with_mean=False)\ncombined_embeddings_scaled = ss.fit_transform(combined_embeddings)\ndel combined_embeddings","18195fac":"image_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\nimage_model.fit(image_embeddings)\nimage_distances, image_indices = image_model.kneighbors(image_embeddings)","05354c07":"tfidf_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\ntfidf_model.fit(tfidf_embeddings)\ntfidf_distances, tfidf_indices = tfidf_model.kneighbors(tfidf_embeddings)","a0362f26":"combined_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\ncombined_model.fit(combined_embeddings_scaled)\ncombined_distances, combined_indices = combined_model.kneighbors(combined_embeddings_scaled)","250bd243":"del image_model, tfidf_model, combined_model","cfe7ee0c":"# Create function to predict based on ratio of distances\ndef predict(df, image_distances, image_indices, tfidf_distances, tfidf_indices,\n            combined_distances, combined_indices, image_ratio, tfidf_ratio, combined_ratio):\n    \n    preds = []\n\n    for i in range(df.shape[0]):\n        \n        # Set thresholds based on ratios of average distances\n        image_threshold = image_ratio * np.mean(image_distances[i])\n        image_idx = image_indices[i][np.where(image_distances[i] <= image_threshold)]\n        image_ids = df['posting_id'].iloc[image_idx].values\n        \n        tfidf_threshold = tfidf_ratio * np.mean(tfidf_distances[i])\n        tfidf_idx = tfidf_indices[i][np.where(tfidf_distances[i] <= tfidf_threshold)]\n        tfidf_ids = df['posting_id'].iloc[tfidf_idx].values\n        \n        combined_threshold = combined_ratio * np.mean(combined_distances[i])\n        combined_idx = combined_indices[i][np.where(combined_distances[i] <= combined_threshold)]\n        combined_ids = df['posting_id'].iloc[combined_idx].values      \n        \n        preds.append(np.union1d(combined_ids, np.union1d(image_ids, tfidf_ids)))\n\n    return preds","a3265d0d":"image_ratio = 0.5\ntfidf_ratio = 0.5\ncombined_ratio = 0.7","bc42af5d":"preds = predict(df, image_distances, image_indices, tfidf_distances, tfidf_indices,\n                combined_distances, combined_indices, image_ratio, tfidf_ratio, combined_ratio)","f72c5ef4":"# Create function to score predictions based on actual matches\ndef scores(matches, preds):\n    result = []\n    for i in range(len(matches)):\n        n = len(np.intersect1d(matches[i], preds[i]))\n        score = 2*n \/ (len(matches[i]) + len(preds[i]))\n        result.append(score)\n    return result","6745b493":"if COMPUTE_CV:\n    matches = list(df['matches'].to_numpy())\n    print(f'Average combined score on train data: {np.mean(scores(matches, preds))}')\n    print('')\n    print('Saving dummy submission file')\n    dummy = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    dummy['matches'] = dummy['posting_id']\n    dummy[['posting_id','matches']].to_csv('submission.csv',index=False)\n    \nelse:\n    df['matches'] = preds\n    df['matches'] = df['matches'].map(lambda x: ' '.join(x))\n    df[['posting_id','matches']].to_csv('submission.csv',index=False)","85288166":"## Image Embeddings","7a4d571b":"## TF-IDF Embeddings","2bb10acd":"## Score \/ Submit","eacfede8":"## LaBSE Embeddings","7b13c3ef":"### Notebook references\n\n- https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700","b64d34f6":"## Make Predictions"}}