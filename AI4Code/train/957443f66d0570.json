{"cell_type":{"b87b2d31":"code","ae371fc9":"code","fc4b56be":"code","e3c953ff":"code","2201fdd8":"code","d14b5c02":"code","1a8bf5b6":"code","473fd376":"code","dcb8c727":"markdown","08246807":"markdown","bf734fb0":"markdown"},"source":{"b87b2d31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize']=20,10\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dropout,Dense\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae371fc9":"df=pd.read_csv(\"..\/input\/tata-set\/NSE-Tata-Global-Beverages-Limited.csv\")\ndf.head()","fc4b56be":"df[\"Date\"]=pd.to_datetime(df.Date,format=\"%Y-%m-%d\")\ndf.index=df['Date']\n\ndf.head()","e3c953ff":"df[\"Close\"].plot()","2201fdd8":"data=df.sort_index(ascending=True,axis=0)\nprint(data.head())\n\nnew_dataset=pd.DataFrame(index=range(0,len(df)),columns=['Date','Close'])\n\nfor i in range(0,len(data)):\n    new_dataset[\"Date\"][i]=data['Date'][i]\n    new_dataset[\"Close\"][i]=data[\"Close\"][i]","d14b5c02":"new_dataset.head()","1a8bf5b6":"new_dataset.index=new_dataset.Date\nnew_dataset.drop(\"Date\",axis='columns',inplace=True)\nfinal_dataset=new_dataset.values\nnew_dataset.head()","473fd376":"train_data=final_dataset[0:987]\nvalid_data=final_dataset[987:]\n\n# print(train_data)\n\nscaler=MinMaxScaler(feature_range=(0,1))\nscaled_data=scaler.fit_transform(final_dataset)\n\nx_train_data,y_train_data=[],[]\n\nfor i in range(60,len(train_data)):\n    x_train_data.append(scaled_data[i-60:i,0])\n    y_train_data.append(scaled_data[i,0])\n\nx_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\n\n# print(x_train_data.shape)\n# print(x_train_data)\n\nx_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1))\n\n# print(x_train_data)","dcb8c727":"# Creating a new dataset just for the Date and Close","08246807":"# Normalize the new filtered dataset:","bf734fb0":"**New Dataset:**"}}