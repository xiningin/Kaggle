{"cell_type":{"b4d96659":"code","ad422208":"code","6b94fe91":"code","f4f8b907":"code","0a9635b5":"code","737d34ea":"code","fdee5a8f":"code","328befa4":"code","6e87fd6d":"code","78b85f3b":"code","bfbd9b44":"code","1acfdf10":"code","3e652991":"code","eec9767a":"code","31a273e7":"code","fba55eaf":"code","1fbb8e34":"code","a4217ee4":"code","7cd1b3c3":"markdown","0e55c81f":"markdown","7461992e":"markdown","2be25dd4":"markdown","47cfc71d":"markdown","c08983b2":"markdown","102dcf6d":"markdown","8e15f8c7":"markdown","bda294b1":"markdown"},"source":{"b4d96659":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport altair as alt\nalt.renderers.enable('notebook')\nprint(os.listdir(\"..\/input\"))\nfrom IPython.display import HTML\n\n\n# The below is great for working but if you publish it, no charts show up.\n# The workaround in the next cell deals with this.\n#alt.renderers.enable('notebook')\n\nHTML(\"This code block contains import statements and setup.\")\n# Any results you write to the current directory are saved as output.","ad422208":"## Dont worry about the code in this block. This is just the setup for showing Altair graphs in Kaggle Notebooks\n\n\nfrom  altair.vega import v3\nimport json\nfrom IPython.display import HTML\n\n\nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))\n","6b94fe91":"#!pip install fbprophet","f4f8b907":"from fbprophet import Prophet\n\n#!mkdir -p dataset\n#!wget -c -b http:\/\/www-personal.umich.edu\/~mejn\/cp\/data\/sunspots.txt -P dataset\ndata = pd.read_excel('..\/input\/hcltech3\/HCL.xlsx', header=0, index_col=0, parse_dates=True, squeeze=True)","0a9635b5":"#!ls dataset\/","737d34ea":"# View the data as a table\ndata_as_frame = pd.DataFrame(data, columns=['HCL_Technologies', 'Day'])\ndata_as_frame.tail(10)","fdee5a8f":"data_as_frame['ds']=data_as_frame['Day'].astype(int)","328befa4":"data_as_frame.head()","6e87fd6d":" data_as_frame['time_stamp']=data_as_frame.apply(lambda x:(pd.Timestamp('01-01-2008')+pd.DateOffset(days = int(x['ds']))),axis=1)","78b85f3b":"#Cleaning the df, we only need two columns date time and the data\nclean_df=data_as_frame.drop(['Day','ds'],axis=1)","bfbd9b44":"clean_df.head()","1acfdf10":"render(alt.Chart(clean_df).mark_line(size=15, opacity=0.8, color = 'Orange').encode(\n        x='yearmonthdate(time_stamp):T',\n        y=alt.Y('HCL_Technologies', title='HCL_Technologies'),    \n        tooltip=['yearmonthdate(time_stamp)', 'HCL_Technologies']\n    ).interactive().properties(width=900, height=450,title='HCL_Technologies Stock Price')\\\n              .configure_title(fontSize=20))","3e652991":"## Prophet requires two columns, one is ds (the date time) and y (variable to be forecasted)\nclean_df.columns = ['y', 'ds']","eec9767a":"def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.99):\n    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n                seasonality_mode = 'multiplicative', \n                interval_width = interval_width,\n                changepoint_range = changepoint_range)\n    m = m.fit(dataframe)\n    \n    forecast = m.predict(dataframe)\n    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n    print('Displaying Prophet plot')\n    fig1 = m.plot(forecast)\n    return forecast\n    \npred = fit_predict_model(clean_df)\n","31a273e7":"def detect_anomalies(forecast):\n    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n    #forecast['fact'] = df['y']\n\n    forecasted['anomaly'] = 0\n    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n\n    #anomaly importances\n    forecasted['importance'] = 0\n    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n        (forecasted['fact'] - forecasted['yhat_upper'])\/forecast['fact']\n    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n        (forecasted['yhat_lower'] - forecasted['fact'])\/forecast['fact']\n    \n    return forecasted\n\npred = detect_anomalies(pred)","fba55eaf":"pred.head()","1fbb8e34":"pred[pred.anomaly == 1]","a4217ee4":"def plot_anomalies(forecasted):\n    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n    x=alt.X('ds:T',  title ='date'),\n    y='yhat_upper',\n    y2='yhat_lower',\n    tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive().properties(\n        title='Anomaly Detection'\n    )\n\n    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive()\n\n    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper'],\n        size = alt.Size( 'importance', legend=None)\n    ).interactive()\n\n    return render(alt.layer(interval, fact, anomalies)\\\n              .properties(width=870, height=450)\\\n              .configure_title(fontSize=20))\n              \nplot_anomalies(pred)","7cd1b3c3":"## Lets view the data in graphical format","0e55c81f":"### Converting the months column in format acceptable for Prophet, starting from 1749 ","7461992e":"# Preparing data for modelling in Prophet","2be25dd4":"# Getting the data","47cfc71d":"### Converting data to Pandas dataframe","c08983b2":"# Detecting Anomalies:\n* The light blue boundaries in the above graph are yhat_upper and yhat_lower.\n* If y value is greater than yhat_upper and less than yhat lower then it is an anomaly.\n* Also getting the importance of that anomaly based on its distance from yhat_upper and yhat_lower.","102dcf6d":"References:\n* http:\/\/www-personal.umich.edu\/~mejn\/cp\/programs.html\n* https:\/\/towardsdatascience.com\/anomaly-detection-time-series-4c661f6f165f\n* https:\/\/github.com\/altair-viz\/altair\/issues\/1270\n","8e15f8c7":"## Lets Predict","bda294b1":"# Plotting the anomalies for a better view"}}