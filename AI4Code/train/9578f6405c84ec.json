{"cell_type":{"5348ca2c":"code","45de0484":"code","3c4c740f":"code","1a8d1917":"code","4634df5d":"code","6a0886f4":"code","eec49952":"code","61088004":"code","960964b1":"code","d05493f5":"code","327ac516":"code","a8791d4c":"code","c712afd3":"code","31a7ba63":"code","7d2caea2":"code","7d355fd9":"code","4b804add":"code","dd172395":"code","02c24f69":"code","89b89685":"code","4e43aed6":"code","94fed779":"code","80b8200f":"code","ce3093cf":"code","303c781b":"code","31d6bc6d":"code","66f460dc":"code","5cb77e9e":"code","3a3136d9":"code","46d905d9":"markdown","f98377b5":"markdown","c223ebaf":"markdown","c1435b11":"markdown","4c5df402":"markdown","2f112da1":"markdown","63da2b00":"markdown","47797765":"markdown","9d1adf6e":"markdown","fb044c10":"markdown","a34f984a":"markdown","d8d57b0f":"markdown","8414353a":"markdown","24ac1d2a":"markdown","eac05aa4":"markdown","4cb75722":"markdown","67bbea7d":"markdown","fc2d7c79":"markdown","fbfb3fcb":"markdown","768fe8fb":"markdown","cedcd6f6":"markdown","36d0273f":"markdown","82c2156a":"markdown"},"source":{"5348ca2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","45de0484":"!pip install pycaret","3c4c740f":"from pycaret.classification import *","1a8d1917":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntrain.head()","4634df5d":"test = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\ntest.head()","6a0886f4":"sample_submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')\nsample_submission.head()","eec49952":"data = train.sample(frac=0.9, random_state=786)\ndata_unseen = train.drop(data.index)\n\ndata.reset_index(drop=True, inplace=True)\ndata_unseen.reset_index(drop=True, inplace=True)\n\nprint('Data for Modeling: ' + str(data.shape))\nprint('Unseen Data For Predictions: ' + str(data_unseen.shape))","61088004":"exp_mclf101 = setup(data = data, \n                    ignore_features = ['id'], \n                    numeric_features=['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n                                      'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n                                      'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n                                      'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n                                      'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n                                      'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n                                      'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n                                      'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n                                      'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n                                      'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49'],\n                 #   pca= True,\n                #    pca_method = 'incremental',\n                    fix_imbalance = True,\n                    data_split_stratify = True,\n                    fold_shuffle= True,\n                  #  use_gpu= True,\n                    target = 'target',\n                    silent = True,\n                    session_id=123)","960964b1":"# best = compare_models()\ntop3 = compare_models(exclude=['gbc'])","d05493f5":"lightgbm = create_model('lightgbm')","327ac516":"rf = create_model('rf')","a8791d4c":"catboost = create_model('catboost')","c712afd3":"et = create_model('et')","31a7ba63":"ada = create_model('ada')","7d2caea2":"#blender = blend_models(top3)\nblender = blend_models(estimator_list = [lightgbm,rf,et,ada,catboost],choose_better=True, optimize='F1', method = 'soft')","7d355fd9":"plot_model(blender, plot = 'auc')","4b804add":"plot_model(blender, plot = 'confusion_matrix')","dd172395":"plot_model(blender, plot = 'class_report')","02c24f69":"plot_model(blender, plot='boundary')","89b89685":"plot_model(blender, plot = 'error')","4e43aed6":"evaluate_model(blender)","94fed779":"predict_model(blender)","80b8200f":"final_blend = finalize_model(blender)","ce3093cf":"print(final_blend)","303c781b":"unseen_predictions = predict_model(final_blend, data=data_unseen)\nunseen_predictions.head()","31d6bc6d":"save_model(final_blend,'Final blend Model 07May2021')","66f460dc":"saved_final_blend = load_model('Final blend Model 07May2021')","5cb77e9e":"new_prediction = predict_model(saved_final_blend, raw_score=True, data=test)\nnew_prediction.head()","3a3136d9":"new_prediction.to_csv('submission1.csv', index= False)","46d905d9":"# \ud83d\ude80 Save model","f98377b5":"## Load training data","c223ebaf":"# \ud83d\ude80 Create Model pipeline","c1435b11":"# \ud83d\ude80 Import Libraries","4c5df402":"# \ud83d\ude80 Predict on full data","2f112da1":"# \ud83d\ude80 Load training and testing data","63da2b00":"## Load sample_subnmission file","47797765":"# \ud83d\ude80 Predict on unseen data","9d1adf6e":"# \ud83d\ude80 Spliting training data into train and test","fb044c10":"# \ud83d\ude80 Plot AUC curve","a34f984a":"# \ud83d\ude80 Blending different models","d8d57b0f":"# \ud83d\ude80 Plot class report","8414353a":"# \ud83d\ude80 Evaluate model","24ac1d2a":"# \ud83d\ude80 Submission","eac05aa4":"# \ud83d\ude80 Predicting on the prediction dataset","4cb75722":"# \ud83d\ude80 Plot error chart","67bbea7d":"# \ud83d\ude80 Plot Confusion matrix","fc2d7c79":"# \ud83d\ude80 Compare different models","fbfb3fcb":"# \ud83d\ude80 Plot boundry chart","768fe8fb":"# \ud83d\ude80 Finalize the model","cedcd6f6":"# \ud83d\ude80 Install Pycaret","36d0273f":"# \ud83d\ude80 Load Model","82c2156a":"## Load testing data"}}