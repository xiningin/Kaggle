{"cell_type":{"1b5fc6ba":"code","c8be08bc":"code","b854c711":"code","a16bd994":"code","b7c91e03":"code","ca98e87f":"code","2fd27d70":"code","8bd4e30d":"code","ea6869f3":"code","581b5c02":"code","63a6bcf9":"code","73ea5460":"code","5b737f48":"code","d8d64762":"code","967af44d":"code","e0b5efb6":"code","c10ebddd":"code","c1e7ccba":"code","d41ea260":"code","88d44b9f":"code","cfe44ec8":"code","04bfce4e":"code","15f8bbb9":"code","8a320772":"markdown","120e5e0b":"markdown","589bcf94":"markdown","8fb4fec4":"markdown","33046903":"markdown","6a48dec9":"markdown","958515da":"markdown","25fded54":"markdown","4fd7995f":"markdown","e350f03b":"markdown","9a8c129c":"markdown","e061356f":"markdown","2a7e3f96":"markdown","7c5deb50":"markdown","1ab04c1c":"markdown","373d8df7":"markdown","a626e4e9":"markdown","e375c6ad":"markdown","3bdb9747":"markdown","348dfdf8":"markdown","6c4db81b":"markdown","ec5353b0":"markdown","8fd284a9":"markdown"},"source":{"1b5fc6ba":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder #encode categoric data\nfrom sklearn.preprocessing import Normalizer #normalize numeric data\nfrom sklearn.model_selection import train_test_split #to split data\nfrom sklearn.neighbors import KNeighborsClassifier #our lovely classifier","c8be08bc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b854c711":"data = pd.read_csv('\/kaggle\/input\/adult-income-dataset\/adult.csv')","a16bd994":"data.head()","b7c91e03":"def object_cols(df):\n    return list(df.select_dtypes(include='object').columns)\n\ndef numerical_cols(df):\n    return list(df.select_dtypes(exclude='object').columns)","ca98e87f":"obj_col = object_cols(data)\nnum_col = numerical_cols(data)","2fd27d70":"obj_col","8bd4e30d":"num_col","ea6869f3":"le = LabelEncoder()\nnorm = Normalizer()","581b5c02":"#Label encoding\nfor col in obj_col:\n    data[col] = le.fit_transform(data[col])","63a6bcf9":"#Normalize\ndata[num_col] = norm.fit_transform(data[num_col])","73ea5460":"data.head()","5b737f48":"X = data.drop(['income'], axis = 1)\ny = data['income']","d8d64762":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)","967af44d":"knn = KNeighborsClassifier() #create a k-NN instance\nfit_knn = knn.fit(X_train, y_train) #fitting model by using \"fit\" method\ns_value = X_test[:1] #specific value to predict\nprint('Predicted class value is : {0}'.format(fit_knn.predict(s_value)))","e0b5efb6":"distance_matrix = fit_knn.kneighbors_graph(s_value, mode = \"distance\") #distance value matrix","c10ebddd":"ind = distance_matrix.nonzero() # indexes of non-zero elements\nind","c1e7ccba":"k_nearest_classes = [y_train.iloc[val[1]] for val in zip(*distance_matrix.nonzero())]\nk_nearest_classes","d41ea260":"print(fit_knn.predict_proba(s_value))","88d44b9f":"s_value","cfe44ec8":"dis = distance_matrix[distance_matrix.nonzero()] # non-zero distances\ndis","04bfce4e":"k_near = pd.DataFrame()\nfor val in zip(*distance_matrix.nonzero()):\n    k_near = k_near.append(X_train.iloc[val[1]], ignore_index = True)\nk_near","15f8bbb9":"fit_knn.score(X_test, y_test)","8a320772":"* Right now you may say \"What happened?\". Firstly we have created a k-NN instance by using the model from the sklearn. We did not set any value for any parameter hence it has been created by default parameters. After then we have used our \"train\" data to train our model. We have chosen a specific value from our test dataset and tried to predict the class of this value. But what really happened once we call the \"predict\" method? Try to imagine that you are a k-NN algorithm. You have tons of data in a plane. You exactly know the locations of these data and the classes of these data. One day a new instance is coming to your plane through \"predict\" method's passage. You know where to put this data by using the location values of this data. And also you know the distance between this data point and the other data points in your plane and the class values of the other data points in your plane. Can you assign a class value by using this information? Yes, you can and the way to assign class values is passing from the distances. Let's start by calling a method to see the distance to the closest top 5 data points.\n* \u015eimdi \"Ne oldu?\" diyebilirsiniz. \u00d6ncelikle sklearn'deki modeli kullanarak bir k-NN \u00f6rne\u011fi olu\u015fturduk. Herhangi bir parametre i\u00e7in herhangi bir de\u011fer belirlemedik, bu nedenle varsay\u0131lan parametrelerle olu\u015fturuldu. Daha sonra modelimizi e\u011fitmek i\u00e7in \"e\u011fitim\" verilerimizi kulland\u0131k. Test veri setimizden belirli bir de\u011fer se\u00e7tik ve bu de\u011ferin s\u0131n\u0131f\u0131n\u0131 tahmin etmeye \u00e7al\u0131\u015ft\u0131k. Ama \"predict\" metodunu \u00e7a\u011f\u0131rd\u0131\u011f\u0131m\u0131zda ger\u00e7ekten ne oldu? Bir k-NN algoritmas\u0131 oldu\u011funuzu hayal etmeye \u00e7al\u0131\u015f\u0131n. Bir d\u00fczlemde tonlarca veri var. Bu verilerin konumlar\u0131n\u0131 ve bu verilerin s\u0131n\u0131flar\u0131n\u0131 tam olarak biliyorsunuz. Bir g\u00fcn \"tahmin\" y\u00f6nteminin ge\u00e7itinden d\u00fczleme yeni bir \u00f6rnek geliyor. Bu \u00f6rne\u011fin konum de\u011ferlerini kullanarak bu \u00f6rne\u011fi nereye koyaca\u011f\u0131n\u0131z\u0131 bilirsiniz. Ayr\u0131ca bu veri noktas\u0131 ile d\u00fczleminizdeki di\u011fer veri noktalar\u0131 aras\u0131ndaki mesafeyi ve d\u00fczleminizdeki di\u011fer veri noktalar\u0131n\u0131n s\u0131n\u0131f de\u011ferlerini de biliyorsunuz. Bu bilgiyi kullanarak bir s\u0131n\u0131f de\u011feri atayabilir misiniz? Evet yapabilirsiniz ve s\u0131n\u0131f de\u011ferleri ataman\u0131n yolu mesafelerden ge\u00e7mektir. En yak\u0131n ilk 5 veri noktas\u0131na olan mesafeyi g\u00f6rmek i\u00e7in bir y\u00f6ntem \u00e7a\u011f\u0131rarak ba\u015flayal\u0131m.","120e5e0b":"* The sparse matrices have a method named \"nonzero\". This method returns the indices of the rows and the corresponding column values. In our example, the related column values are the indices of the samples in the y values which we have created from our dataframe. Let's create a list that contains class values of the instances to classify our data point.\n* Sparse matrislerin \"nonzero\" adl\u0131 bir metodu vard\u0131r. Bu metot, sat\u0131rlar\u0131n indekslerini ve kar\u015f\u0131l\u0131k gelen s\u00fctun de\u011ferlerini d\u00f6nd\u00fcr\u00fcr. \u00d6rne\u011fimizde ilgili s\u00fctun de\u011ferleri dataframe'den olu\u015fturdu\u011fumuz y de\u011ferlerindeki \u00f6rneklerin indeksleridir. Veri noktam\u0131z\u0131 s\u0131n\u0131fland\u0131rmak i\u00e7in \u00f6rneklerin s\u0131n\u0131f de\u011ferlerini i\u00e7eren bir liste olu\u015ftural\u0131m.","589bcf94":"# Chapter 1.2: Read Data and Preprocess <a class=\"anchor\" id=\"section_2_2\"><\/a>","8fb4fec4":"* Looks like we do have not any obstacle to train our k-NN algorithm. From now we will do too many things. Firstly we will fit a k-NN model by using default parameters. After then, we will use the \"predict\" method to see the class of a specific value. Then we will try to understand what really happened once we call the \"predict\" method by using some other methods. I know our way may look long but believe me it is not long. Let's start by \"training\" and \"predicting\" steps.\n* G\u00f6r\u00fcn\u00fc\u015fe g\u00f6re k-NN algoritmam\u0131z\u0131 e\u011fitmek i\u00e7in herhangi bir engelimiz yok. \u015eu andan itibaren \u00e7ok fazla \u015fey yapaca\u011f\u0131z. \u00d6ncelikle varsay\u0131lan parametreleri kullanarak bir k-NN modeli olu\u015fturaca\u011f\u0131z. Sonra, belirli bir de\u011ferin s\u0131n\u0131f\u0131n\u0131 g\u00f6rmek i\u00e7in \"predict\" y\u00f6ntemini kullanaca\u011f\u0131z. Daha sonra ba\u015fka y\u00f6ntemler kullanarak \"tahmin\" y\u00f6ntemini \u00e7a\u011f\u0131rd\u0131\u011f\u0131m\u0131zda ger\u00e7ekte ne oldu\u011funu anlamaya \u00e7al\u0131\u015faca\u011f\u0131z. Yolumuzun uzun g\u00f6r\u00fcnebilece\u011fini biliyorum ama inan\u0131n uzun de\u011fil. \"E\u011fitim\" ve \"tahmin etme\" ad\u0131mlar\u0131yla ba\u015flayal\u0131m.","33046903":"* The k-NN algorithm has a magical method which is \"kneighbors_graph\". This method allows you to see the distance between the given data and the train data for the k nearest neighbors. The data type of the output of this method is sparse matrix which is a special data structure in Python. This matrix contains information only if the value is valid (in our case if the value is one of the nearest five values) else the value is assigned as \"zero\". If you get the indices of the non-zero elements in our sparse matrix, you can find the indices of the k nearest neighbors of the given data point. Let's do it!\n* k-NN algoritmas\u0131 ad\u0131 \"kneighbors_graph\" olan sihirli bir metoda sahiptir. Bu y\u00f6ntem, en yak\u0131n k kom\u015fu i\u00e7in verilen veriler ile e\u011fitim verileri aras\u0131ndaki mesafeyi g\u00f6rmenizi sa\u011flar. Bu y\u00f6ntemin \u00e7\u0131kt\u0131s\u0131n\u0131n veri t\u00fcr\u00fc Python'da \u00f6zel bir veri yap\u0131s\u0131 olan sparse matristir. Bu matris, yaln\u0131zca de\u011fer ge\u00e7erliyse (bizim durumumuzda de\u011fer en yak\u0131n be\u015f de\u011ferden biriyse) bilgi i\u00e7erir, aksi takdirde de\u011fer \"s\u0131f\u0131r\" olarak atan\u0131r. Seyrek matrisimizde s\u0131f\u0131r olmayan elemanlar\u0131n indekslerini al\u0131rsan\u0131z, verilen veri noktas\u0131n\u0131n en yak\u0131n k kom\u015fusunun indekslerini bulabilirsiniz. Haydi Yapal\u0131m!","6a48dec9":"### Table of Contents\n\n* [Chapter 1](#section_2)\n    * [Section 1.1](#section_2_1)\n    * [Section 1.2](#section_2_2)\n* [Chapter 2](#section_3)\n    * [Section 2.1](#section_3_1)\n    * [Section 2.2](#section_3_2)\n* [Chapter 3](#section_4)  ","958515da":"# Chapter 1: Read and Preprocess Data <a class=\"anchor\" id=\"section_2\"><\/a>","25fded54":"* I suggest you try different k-NN models by using different parameters. You can check my blog posts about k-NN and sklearn which I explained all of the parameters, attributes, and methods of the k-NN algorithm by using the link https:\/\/medium.com\/@bcelalakyuz. Next week I will explain what is decision tree and how it is learning by using a dataset from Kaggle. If you have any questions about k-NN or about the other algorithms of the ML101 series, do not hesitate to reach me via comments, Kaggle mail, or via bcelalakyuz@gmail.com. I wish you a healthy and happy week until we see each other again.\n* Farkl\u0131 parametreler kullanarak farkl\u0131 k-NN modellerini denemenizi \u00f6neririm. k-NN algoritmas\u0131n\u0131n t\u00fcm parametrelerini, \u00f6zelliklerini ve y\u00f6ntemlerini anlatt\u0131\u011f\u0131m k-NN ve sklearn ile ilgili blog yaz\u0131lar\u0131ma https:\/\/medium.com\/@bcelalakyuz linkinden ula\u015fabilirsiniz. \u00d6n\u00fcm\u00fczdeki hafta karar a\u011fac\u0131n\u0131n ne oldu\u011funu ve nas\u0131l \u00f6\u011frendi\u011fini Kaggle'dan bir veri seti kullanarak a\u00e7\u0131klayaca\u011f\u0131m. k-NN veya ML101 serisinin di\u011fer algoritmalar\u0131 hakk\u0131nda herhangi bir sorunuz varsa, yorum, Kaggle mail veya bcelalakyuz@gmail.com arac\u0131l\u0131\u011f\u0131yla bana ula\u015fmaktan \u00e7ekinmeyin. Tekrar g\u00f6r\u00fc\u015fene kadar sa\u011fl\u0131kl\u0131 ve mutlu bir hafta dilerim.","4fd7995f":"# Chapter 2.1: Fit Model <a class=\"anchor\" id=\"section_3_1\"><\/a>","e350f03b":"* Now we know the class values of the 5 nearest neighbors. The class value of five of them is \"0\" and the rest is \"1\". So we can say that this data point belongs to the class \"0\" with a %100 probability. If there were two probabilities such as %60 to %40, we could say that this data point will be a \"0\" with a higher probability than \"1\". And this is what k-NN does to classify an instance. It creates a distance matrix that contains information about k nearest neighbors and by using this information it gets the nearest class values firstly. After then it uses these probability values to assign a class value to the given data point. Let's check that did we do everything right!\n* \u015eimdi en yak\u0131n 5 kom\u015funun s\u0131n\u0131f de\u011ferlerini biliyoruz. Be\u015f tanesinin s\u0131n\u0131f de\u011feri \"0\", geri kalan\u0131 \"1\"dir. Yani bu veri noktas\u0131n\u0131n %100 olas\u0131l\u0131kla \"0\" s\u0131n\u0131f\u0131na ait oldu\u011funu s\u00f6yleyebiliriz. %60 ile %40 gibi iki olas\u0131l\u0131k olsayd\u0131, bu veri noktas\u0131n\u0131n \"1\"den daha y\u00fcksek olas\u0131l\u0131kla \"0\" olaca\u011f\u0131n\u0131 s\u00f6yleyebiliriz. Ve bu, bir \u00f6rne\u011fi s\u0131n\u0131fland\u0131rmak i\u00e7in k-NN'nin yapt\u0131\u011f\u0131 \u015feydir. En yak\u0131n k kom\u015fu hakk\u0131nda bilgi i\u00e7eren bir uzakl\u0131k matrisi olu\u015fturur ve bu bilgiyi kullanarak ilk olarak en yak\u0131n s\u0131n\u0131f de\u011ferlerini al\u0131r. Daha sonra verilen veri noktas\u0131na bir s\u0131n\u0131f de\u011feri atamak i\u00e7in bu olas\u0131l\u0131k de\u011ferlerini kullan\u0131r. Her \u015feyi do\u011fru yap\u0131p yapmad\u0131\u011f\u0131m\u0131z\u0131 kontrol edelim!","9a8c129c":"* We have created a dataframe that contains only numeric values. Some of these values are encoded from categorical columns(obj_col) and some of them are normalized by using numerical columns(num_col). There may be better ways to preprocess this data but in this notebook, our aim is to learn what is k-NN algorithm hence we will stop our preprocessing phase right here and we will continue with the k-NN algorithm. \n* Yaln\u0131zca say\u0131sal de\u011ferler i\u00e7eren bir dataframe olu\u015fturduk. Bu de\u011ferlerin bir k\u0131sm\u0131 kategorik s\u00fctunlardan(obj_col) encode edildi ve bir k\u0131sm\u0131 say\u0131sal s\u00fctunlar(num_col) kullan\u0131larak normalize edilmi\u015ftir. Bu verileri \u00f6n i\u015flemenin daha iyi yollar\u0131 olabilir ama bu notebook'ta amac\u0131m\u0131z k-NN algoritmas\u0131n\u0131n ne oldu\u011funu \u00f6\u011frenmek oldu\u011fu i\u00e7in \u00f6n i\u015fleme a\u015famam\u0131z\u0131 burada durduraca\u011f\u0131z ve k-NN algoritmas\u0131 ile devam edece\u011fiz.","e061356f":"# Chapter 2: k-NN Algorithm with sklearn <a class=\"anchor\" id=\"section_3\"><\/a>","2a7e3f96":"* We are ready to fit a k-NN algorithm to classify the income level of a person. To do this we need train data and to obtain this we will use the train_test_split method of the sklearn. Our X data will be the all of the columns of the dataframe except the \"income\" column and the y data will be the \"income\" column just as you think. Let's create X and y data and apply train_test_split method.\n* Bir ki\u015finin gelir seviyesini s\u0131n\u0131fland\u0131rmak i\u00e7in bir k-NN algoritmas\u0131n\u0131 e\u011fitmeye haz\u0131r\u0131z. Bunu yapmak i\u00e7in e\u011fitim verilerine ihtiyac\u0131m\u0131z var ve bunu elde etmek i\u00e7in sklearn'in train_test_split y\u00f6ntemini kullanaca\u011f\u0131z. X verimiz, dataframe'deki \"income\" s\u00fctunu d\u0131\u015f\u0131ndaki t\u00fcm s\u00fctunlar\u0131 olacak ve y verisi, d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcn\u00fcz gibi \"income\" s\u00fctunu olacakt\u0131r. X ve y verilerini olu\u015ftural\u0131m ve train_test_split y\u00f6ntemini uygulayal\u0131m.","7c5deb50":"* As you can see we are predicting with an %82 accuracy score. This value may be good but we only tried one k-NN model in here. So there may be better k-NN models. So what is next?\n* G\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi %82 do\u011fruluk puan\u0131 ile tahmin yap\u0131yoruz. Bu de\u011fer iyi olabilir ama biz burada sadece bir k-NN modelini denedik. Yani daha iyi k-NN modelleri olabilir. Peki s\u0131rada ne var?","1ab04c1c":"# Chapter 1.1: Related Libraries <a class=\"anchor\" id=\"section_2_1\"><\/a>","373d8df7":"# ML101 - Algorithm 3: k-NN  <a class=\"anchor\" id=\"section_1\"><\/a>","a626e4e9":"* As you can see we have both categorical and numerical data types in our columns. In this notebook, I have made two simple preprocessing operations which are \"Encoding\" and \"Normalization\". To find out which column to encode or which column to normalize we need data types of all of the columns. I have used two methods to create two lists that contain the names of categoric and numeric columns. Let's define our methods and make preprocessing steps to make our data ready for the k-NN algorithm.\n* G\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi s\u00fctunlar\u0131m\u0131zda hem kategorik hem de say\u0131sal veri t\u00fcrleri var. Bu notebook'ta \"Encoding\" ve \"Normalization\" olmak \u00fczere iki basit \u00f6ni\u015fleme i\u015flemi yapt\u0131m. Hangi s\u00fctunun encode olaca\u011f\u0131n\u0131 veya hangi s\u00fctunun normalle\u015ftirilece\u011fini bulmak i\u00e7in t\u00fcm s\u00fctunlar\u0131n veri t\u00fcrlerine ihtiyac\u0131m\u0131z var. Kategorik ve say\u0131sal s\u00fctunlar\u0131n adlar\u0131n\u0131 i\u00e7eren iki liste olu\u015fturmak i\u00e7in iki method kulland\u0131m. Metotlar\u0131m\u0131z\u0131 tan\u0131mlayal\u0131m ve verilerimizi k-NN algoritmas\u0131na haz\u0131r hale getirmek i\u00e7in \u00f6n i\u015fleme ad\u0131mlar\u0131n\u0131 yapal\u0131m.","e375c6ad":"* Before we dive into the k-NN, we need data to train our model. In this notebook, I have used the dataset named \"Adult Income Dataset\". This dataset contains information such as education level, relationship status, race, etc. about a person and our aim is to try to classify the income level of this person as \">50k\" or \"<=50k\". Let's read our data and check the top 5 rows by using the \"head\" method of pandas to see what we have in our columns.\n* k-NN algoritmas\u0131na dalmadan \u00f6nce, modelimizi e\u011fitmek i\u00e7in verilere ihtiyac\u0131m\u0131z var. Bu notebook'ta \"Adult Income Dataset\" isimli veri setini kulland\u0131m. Bu veri seti bir ki\u015fi hakk\u0131nda e\u011fitim d\u00fczeyi, ili\u015fki durumu, \u0131rk vb. bilgileri i\u00e7ermektedir ve amac\u0131m\u0131z bu ki\u015finin gelir d\u00fczeyini \">50k\" veya \"<=50k\" olarak s\u0131n\u0131fland\u0131rmaya \u00e7al\u0131\u015fmakt\u0131r. S\u00fctunlar\u0131m\u0131zda ne oldu\u011funu g\u00f6rmek i\u00e7in verilerimizi okuyal\u0131m ve pandas k\u00fct\u00fcphanesinin \"head\" y\u00f6ntemini kullanarak ilk 5 sat\u0131r\u0131 kontrol edelim.","3bdb9747":"* Hello everyone with the third algorithm of our ML101 journey which is k-NN. I am your Instructor Data Scientist Burak Celal. Today we will cover a new classification algorithm by using an income dataset. We will try to classify the income level of a person by using data and the k-NN algorithm. If you are ready and excited as much as I let's start.\n* ML101 yolculu\u011fumuzun \u00fc\u00e7\u00fcnc\u00fc algoritmas\u0131 olan k-NN ile herkese merhaba. Ben E\u011fitmen Veri Bilimciniz Burak Celal. Bug\u00fcn bir gelir veri seti kullanarak yeni bir s\u0131n\u0131fland\u0131rma algoritmas\u0131n\u0131 ele alaca\u011f\u0131z. Verileri ve k-NN algoritmas\u0131n\u0131 kullanarak bir ki\u015finin gelir d\u00fczeyini s\u0131n\u0131fland\u0131rmaya \u00e7al\u0131\u015faca\u011f\u0131z. Haz\u0131rsan\u0131z ve benim kadar heyecanl\u0131ysan\u0131z ba\u015flayal\u0131m.","348dfdf8":"* Firstly we have printed the s_value to see the sample which we are working on it. Then, we have got the distance values from the sparse matrix by using the \"nonzero\" method. Finally, we have created a dataframe that contains only k nearest neighbors of the given data. This data point looks so similar to the neighbors. But what about the other ones? Let's see the mean accuracy score for our k-NN algorithm by using the \"score\" method of the k-NN algorithm.\n* \u00d6ncelikle \u00fczerinde \u00e7al\u0131\u015ft\u0131\u011f\u0131m\u0131z \u00f6rne\u011fi g\u00f6rmek i\u00e7in s_value de\u011ferini yazd\u0131rd\u0131k. Ard\u0131ndan, \"nonzero\" metodunu kullanarak sparse matristen uzakl\u0131k de\u011ferlerini elde ettik. Son olarak, verilen verinin yaln\u0131zca k en yak\u0131n kom\u015fusunu i\u00e7eren bir dataframe olu\u015fturduk. Bu veri noktas\u0131 kom\u015fular\u0131na \u00e7ok benziyor. Peki ya di\u011ferleri? k-NN algoritmas\u0131n\u0131n \"score\" metodunu kullanarak k-NN algoritmam\u0131z i\u00e7in ortalama do\u011fruluk puan\u0131n\u0131 g\u00f6relim.","6c4db81b":"# Chapter 2.2: What Happened Once We Call \"predict\"?  <a class=\"anchor\" id=\"section_3_2\"><\/a>","ec5353b0":"* The algorithm returns a 1x2 matrix that contains probability values of the classes. The sklearn, orders the given classes by lexicographic orders which means in our example the first column will refer to \"0\" and the second one will refer to \"1\". The float values in the cells refer to the probabilities of the classes. In our example, the given data point will belong to the class \"0\" with a probability of %100. Let's check the distance between this given sample and the 5 nearest neighbors.\n* Algoritma, s\u0131n\u0131flar\u0131n olas\u0131l\u0131k de\u011ferlerini i\u00e7eren 1x2'lik bir matris d\u00f6nd\u00fcr\u00fcr. Sklearn, verilen s\u0131n\u0131flar\u0131 s\u00f6zl\u00fck s\u0131ras\u0131na g\u00f6re s\u0131ralar, yani \u00f6rne\u011fimizde ilk s\u00fctun \"0\" ve ikinci s\u00fctun \"1\" anlam\u0131na gelir. H\u00fccrelerdeki float de\u011ferler, s\u0131n\u0131flar\u0131n olas\u0131l\u0131klar\u0131n\u0131 ifade eder. \u00d6rne\u011fimizde, verilen veri noktas\u0131 %100 olas\u0131l\u0131kla \"0\" s\u0131n\u0131f\u0131na ait olacakt\u0131r. Bu verilen \u00f6rnek ile en yak\u0131n 5 kom\u015fu aras\u0131ndaki mesafeyi kontrol edelim.","8fd284a9":"# Chapter 3: What is Next? <a class=\"anchor\" id=\"section_4\"><\/a>"}}