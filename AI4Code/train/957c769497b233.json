{"cell_type":{"1042c53e":"code","cb89ea22":"code","1df98aab":"code","94083316":"code","504a60ab":"code","64eb6c07":"code","67730d06":"code","c6eb07ac":"code","0b2e0ad6":"code","8d63e25a":"code","6e7b7df0":"code","766a2400":"code","c50420f7":"code","ac8c8222":"code","a0b49a37":"code","8e824875":"code","baeb5c20":"code","87e60ce6":"code","c2cdcd7a":"code","2b8ccb53":"code","1c1b860c":"code","91c1c1c2":"code","aa444cef":"code","3a28683d":"code","dc710bcb":"code","4c81ad67":"code","2bba6a70":"code","0187e2ec":"code","db829444":"code","480128f5":"code","27ff8ce2":"code","a8d2be1c":"code","4eeabe5c":"code","93f89f11":"code","31843245":"code","6642d39d":"code","0a069b78":"code","79a94d81":"code","8bd6b3ff":"code","7e5384e7":"code","79d9a31d":"code","215e3a0a":"code","2d24af61":"code","45b5531c":"code","41c578c2":"code","455ca3d1":"code","3162716c":"code","511c1799":"code","6bedb337":"code","c33bc1fb":"code","29c7fbc4":"code","5b83a02e":"code","adf48ddb":"code","f1fb596d":"code","e68df462":"code","8652c81c":"code","8814bfa6":"code","63718a55":"code","a9ff7f3c":"code","ff6d7440":"code","d5004975":"code","c9134bd3":"code","8b893279":"code","68dc99f0":"code","8fc677bd":"code","374dcf6b":"code","a573408a":"code","2bb3050f":"code","49aa0bc7":"code","e277e8ce":"code","6af1ac81":"code","03f41ef5":"code","b9fec87a":"code","c8818081":"code","1d8c4ce8":"code","d917db7a":"code","1466d5f8":"code","cc35429a":"code","b450d7ff":"code","74a85e91":"code","68f707db":"code","af1e6298":"code","4e4d924c":"code","b1bed82e":"code","08eef728":"code","da6b145f":"code","8ccf0973":"code","c221aaa7":"code","223d2995":"code","04a3a6f3":"code","7b3c7c05":"markdown","e22f939d":"markdown","d19ce04f":"markdown","7be3d47b":"markdown","23c9c004":"markdown","8e5e0d1e":"markdown","6138cf93":"markdown","00a75337":"markdown","09845f46":"markdown","4e7131ed":"markdown","f795ff86":"markdown","df5eb65a":"markdown","3184df94":"markdown","d13d9925":"markdown","0c2c495b":"markdown","ad8be434":"markdown","b9424b9b":"markdown","f4106fb9":"markdown","a1e98bc6":"markdown","5e591c66":"markdown","057b89ab":"markdown","51e8ad8e":"markdown"},"source":{"1042c53e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb89ea22":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# \u0414\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043c\u0430\u0442\u0440\u0438\u0446\u0430\u043c\u0438\nfrom scipy.sparse import csr_matrix, coo_matrix\n\n# \u041c\u0430\u0442\u0440\u0438\u0447\u043d\u0430\u044f \u0444\u0430\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f\nfrom implicit.als import AlternatingLeastSquares\nfrom implicit.nearest_neighbours import bm25_weight, tfidf_weight\nfrom implicit.bpr import BayesianPersonalizedRanking\nfrom implicit.nearest_neighbours import ItemItemRecommender  # \u043d\u0443\u0436\u0435\u043d \u0434\u043b\u044f \u043e\u0434\u043d\u043e\u0433\u043e \u0442\u0440\u044e\u043a\u0430\nfrom lightfm import LightFM\nfrom lightfm.evaluation import precision_at_k, recall_at_k\n\n# \u041c\u043e\u0434\u0435\u043b\u044c \u0432\u0442\u043e\u0440\u043e\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f\nfrom lightgbm import LGBMClassifier\n\n# \u0414\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b\nfrom implicit.nearest_neighbours import ItemItemRecommender, CosineRecommender, TFIDFRecommender, BM25Recommender","1df98aab":"# \u0414\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043c\u0430\u0442\u0440\u0438\u0446\u0430\u043c\u0438\nfrom scipy.sparse import csr_matrix\n\n# \u041c\u0430\u0442\u0440\u0438\u0447\u043d\u0430\u044f \u0444\u0430\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f\nfrom implicit.als import AlternatingLeastSquares\nfrom implicit.nearest_neighbours import ItemItemRecommender  # \u043d\u0443\u0436\u0435\u043d \u0434\u043b\u044f \u043e\u0434\u043d\u043e\u0433\u043e \u0442\u0440\u044e\u043a\u0430\nfrom implicit.nearest_neighbours import bm25_weight, tfidf_weight\n\n\nclass MainRecommender:\n    \"\"\"\u0420\u0435\u043a\u043e\u043c\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0438\u0437 ALS\n\n    Input\n    -----\n    user_item_matrix: pd.DataFrame\n        \u041c\u0430\u0442\u0440\u0438\u0446\u0430 \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0439 user-item\n    \"\"\"\n\n    def __init__(self, data, weighting=True):\n\n        # \u0422\u043e\u043f \u043f\u043e\u043a\u0443\u043f\u043e\u043a \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u044e\u0437\u0435\u0440\u0430\n        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999]\n\n        # \u0422\u043e\u043f \u043f\u043e\u043a\u0443\u043f\u043e\u043a \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443\n        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n        self.overall_top_purchases = self.overall_top_purchases[self.overall_top_purchases['item_id'] != 999999]\n        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n\n        self.user_item_matrix = self._prepare_matrix(data)  # pd.DataFrame\n        self.id_to_itemid, self.id_to_userid, \\\n            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n\n        if weighting:\n            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n\n        self.model = self.fit(self.user_item_matrix)\n        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n\n    @staticmethod\n    def _prepare_matrix(data):\n        \"\"\"\u0413\u043e\u0442\u043e\u0432\u0438\u0442 user-item \u043c\u0430\u0442\u0440\u0438\u0446\u0443\"\"\"\n        user_item_matrix = pd.pivot_table(data,\n                                          index='user_id', columns='item_id',\n                                          values='quantity',  # \u041c\u043e\u0436\u043d\u043e \u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0434\u0440\u0443\u0433\u0438\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b\n                                          aggfunc='count',\n                                          fill_value=0\n                                          )\n\n        user_item_matrix = user_item_matrix.astype(float)  # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit\n\n        return user_item_matrix\n\n    @staticmethod\n    def _prepare_dicts(user_item_matrix):\n        \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442 \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0441\u043b\u043e\u0432\u0430\u0440\u0438\"\"\"\n\n        userids = user_item_matrix.index.values\n        itemids = user_item_matrix.columns.values\n\n        matrix_userids = np.arange(len(userids))\n        matrix_itemids = np.arange(len(itemids))\n\n        id_to_itemid = dict(zip(matrix_itemids, itemids))\n        id_to_userid = dict(zip(matrix_userids, userids))\n\n        itemid_to_id = dict(zip(itemids, matrix_itemids))\n        userid_to_id = dict(zip(userids, matrix_userids))\n\n        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n\n    @staticmethod\n    def fit_own_recommender(user_item_matrix):\n        \"\"\"\u041e\u0431\u0443\u0447\u0430\u0435\u0442 \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u0442 \u0442\u043e\u0432\u0430\u0440\u044b, \u0441\u0440\u0435\u0434\u0438 \u0442\u043e\u0432\u0430\u0440\u043e\u0432, \u043a\u0443\u043f\u043b\u0435\u043d\u043d\u044b\u0445 \u044e\u0437\u0435\u0440\u043e\u043c\"\"\"\n\n        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n\n        return own_recommender\n\n    @staticmethod\n    def fit(user_item_matrix, n_factors=50, regularization=0.001, iterations=15, num_threads=4):\n        \"\"\"\u041e\u0431\u0443\u0447\u0430\u0435\u0442 ALS\"\"\"\n\n        model = AlternatingLeastSquares(factors=n_factors,\n                                        regularization=regularization,\n                                        iterations=iterations,\n                                        num_threads=num_threads)\n        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n\n        return model\n\n    def _update_dict(self, user_id):\n        \"\"\"\u0415\u0441\u043b\u0438 \u043f\u043e\u044f\u0432\u0438\u043b\u0441\u044f \u043d\u043e\u0432\u044b\u044e user \/ item, \u0442\u043e \u043d\u0443\u0436\u043d\u043e \u043e\u0431\u043d\u043e\u0432\u0438\u0442\u044c \u0441\u043b\u043e\u0432\u0430\u0440\u0438\"\"\"\n\n        if user_id not in self.userid_to_id.keys():\n\n            max_id = max(list(self.userid_to_id.values()))\n            max_id += 1\n\n            self.userid_to_id.update({user_id: max_id})\n            self.id_to_userid.update({max_id: user_id})\n\n    def _get_similar_item(self, item_id):\n        \"\"\"\u041d\u0430\u0445\u043e\u0434\u0438\u0442 \u0442\u043e\u0432\u0430\u0440, \u043f\u043e\u0445\u043e\u0436\u0438\u0439 \u043d\u0430 item_id\"\"\"\n        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)  # \u0422\u043e\u0432\u0430\u0440 \u043f\u043e\u0445\u043e\u0436 \u043d\u0430 \u0441\u0435\u0431\u044f -> \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c 2 \u0442\u043e\u0432\u0430\u0440\u0430\n        top_rec = recs[1][0]  # \u0418 \u0431\u0435\u0440\u0435\u043c \u0432\u0442\u043e\u0440\u043e\u0439 (\u043d\u0435 \u0442\u043e\u0432\u0430\u0440 \u0438\u0437 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u0430 \u043c\u0435\u0442\u043e\u0434\u0430)\n        return self.id_to_itemid[top_rec]\n\n    def _extend_with_top_popular(self, recommendations, N=5):\n        \"\"\"\u0415\u0441\u043b\u0438 \u043a\u043e\u043b-\u0432\u043e \u0440\u0435\u043a\u043e\u043c\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 < N, \u0442\u043e \u0434\u043e\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0438\u0445 \u0442\u043e\u043f-\u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u043c\u0438\"\"\"\n\n        if len(recommendations) < N:\n            recommendations.extend(self.overall_top_purchases[:N])\n            recommendations = recommendations[:N]\n\n        return recommendations\n\n    def _get_recommendations(self, user, model, N=5):\n        \"\"\"\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438 \u0447\u0435\u0440\u0435\u0437 \u0441\u0442\u0430\u0440\u0434\u0430\u0440\u0442\u043d\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 implicit\"\"\"\n\n        self._update_dict(user_id=user)\n        res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n                                        user_items=csr_matrix(self.user_item_matrix).tocsr(),\n                                        N=N,\n                                        filter_already_liked_items=False,\n                                        filter_items=[self.itemid_to_id[999999]],\n                                        recalculate_user=True)]\n\n        res = self._extend_with_top_popular(res, N=N)\n\n        assert len(res) == N, '\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 != {}'.format(N)\n        return res\n\n    def get_als_recommendations(self, user, N=5):\n        \"\"\"\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438 \u0447\u0435\u0440\u0435\u0437 \u0441\u0442\u0430\u0440\u0434\u0430\u0440\u0442\u043d\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 implicit\"\"\"\n\n        self._update_dict(user_id=user)\n        return self._get_recommendations(user, model=self.model, N=N)\n\n    def get_own_recommendations(self, user, N=5):\n        \"\"\"\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c \u0442\u043e\u0432\u0430\u0440\u044b \u0441\u0440\u0435\u0434\u0438 \u0442\u0435\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u044e\u0437\u0435\u0440 \u0443\u0436\u0435 \u043a\u0443\u043f\u0438\u043b\"\"\"\n\n        self._update_dict(user_id=user)\n        return self._get_recommendations(user, model=self.own_recommender, N=N)\n\n    def get_similar_items_recommendation(self, user, N=5):\n        \"\"\"\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c \u0442\u043e\u0432\u0430\u0440\u044b, \u043f\u043e\u0445\u043e\u0436\u0438\u0435 \u043d\u0430 \u0442\u043e\u043f-N \u043a\u0443\u043f\u043b\u0435\u043d\u043d\u044b\u0445 \u044e\u0437\u0435\u0440\u043e\u043c \u0442\u043e\u0432\u0430\u0440\u043e\u0432\"\"\"\n\n        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n\n        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n        res = self._extend_with_top_popular(res, N=N) \n\n        assert len(res) == N, '\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 != {}'.format(N)\n        return res\n\n    def get_similar_users_recommendation(self, user, N=5):\n        \"\"\"\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c \u0442\u043e\u043f-N \u0442\u043e\u0432\u0430\u0440\u043e\u0432, \u0441\u0440\u0435\u0434\u0438 \u043a\u0443\u043f\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u043e\u0445\u043e\u0436\u0438\u043c\u0438 \u044e\u0437\u0435\u0440\u0430\u043c\u0438\"\"\"\n\n        res = []\n\n        # \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u0442\u043e\u043f-N \u043f\u043e\u0445\u043e\u0436\u0438\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439\n        similar_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n        similar_users = [rec[0] for rec in similar_users]\n        similar_users = similar_users[1:]   # \u0443\u0434\u0430\u043b\u0438\u043c \u044e\u0437\u0435\u0440\u0430 \u0438\u0437 \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n\n        for user in similar_users:\n            res.extend(self.get_own_recommendations(user, N=1))\n\n        res = self._extend_with_top_popular(res, N=N)\n\n        assert len(res) == N, '\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 != {}'.format(N)\n        return res","94083316":"def prefilter_items(data, take_n_popular=5000, item_features=None):\n    # \u0423\u0431\u0435\u0440\u0435\u043c \u0441\u0430\u043c\u044b\u0435 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0442\u043e\u0432\u0430\u0440\u044b (\u0438\u0445 \u0438 \u0442\u0430\u043a \u043a\u0443\u043f\u044f\u0442)\n    popularity = data.groupby('item_id')['user_id'].nunique().reset_index() \/ data['user_id'].nunique()\n    popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n\n    top_popular = popularity[popularity['share_unique_users'] > 0.2].item_id.tolist()\n    data = data[~data['item_id'].isin(top_popular)]\n\n    # \u0423\u0431\u0435\u0440\u0435\u043c \u0441\u0430\u043c\u044b\u0435 \u041d\u0415 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0442\u043e\u0432\u0430\u0440\u044b (\u0438\u0445 \u0438 \u0442\u0430\u043a \u041d\u0415 \u043a\u0443\u043f\u044f\u0442)\n    top_notpopular = popularity[popularity['share_unique_users'] < 0.02].item_id.tolist()\n    data = data[~data['item_id'].isin(top_notpopular)]\n\n    # \u0423\u0431\u0435\u0440\u0435\u043c \u043d\u0435 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u044b\u0435 \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 (department)\n    if item_features is not None:\n        department_size = pd.DataFrame(item_features.\\\n                                        groupby('department')['item_id'].nunique().\\\n                                        sort_values(ascending=False)).reset_index()\n\n        department_size.columns = ['department', 'n_items']\n        rare_departments = department_size[department_size['n_items'] < 150].department.tolist()\n        items_in_rare_departments = item_features[item_features['department'].isin(rare_departments)].item_id.unique().tolist()\n\n        data = data[~data['item_id'].isin(items_in_rare_departments)]\n\n\n    # \u0423\u0431\u0435\u0440\u0435\u043c \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0434\u0435\u0448\u0435\u0432\u044b\u0435 \u0442\u043e\u0432\u0430\u0440\u044b (\u043d\u0430 \u043d\u0438\u0445 \u043d\u0435 \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c). 1 \u043f\u043e\u043a\u0443\u043f\u043a\u0430 \u0438\u0437 \u0440\u0430\u0441\u0441\u044b\u043b\u043e\u043a \u0441\u0442\u043e\u0438\u0442 60 \u0440\u0443\u0431.\n    data['price'] = data['sales_value'] \/ (np.maximum(data['quantity'], 1))\n    data = data[data['price'] > 2]\n\n    # \u0423\u0431\u0435\u0440\u0435\u043c \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0434\u043e\u0440\u043e\u0433\u0438\u0435 \u0442\u043e\u0432\u0430\u0440\u044bs\n    data = data[data['price'] < 50]\n\n    # \u0412\u043e\u0437\u044c\u043c\u0435\u043c \u0442\u043e\u043f \u043f\u043e \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u043e\u0441\u0442\u0438\n    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n    popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n\n    top = popularity.sort_values('n_sold', ascending=False).head(take_n_popular).item_id.tolist()\n    \n    # \u0417\u0430\u0432\u0435\u0434\u0435\u043c \u0444\u0438\u043a\u0442\u0438\u0432\u043d\u044b\u0439 item_id (\u0435\u0441\u043b\u0438 \u044e\u0437\u0435\u0440 \u043f\u043e\u043a\u0443\u043f\u0430\u043b \u0442\u043e\u0432\u0430\u0440\u044b \u0438\u0437 \u0442\u043e\u043f-5000, \u0442\u043e \u043e\u043d \"\u043a\u0443\u043f\u0438\u043b\" \u0442\u0430\u043a\u043e\u0439 \u0442\u043e\u0432\u0430\u0440)\n    data.loc[~data['item_id'].isin(top), 'item_id'] = 999999\n    \n    # ...\n\n    return data\n    \n\ndef postfilter(recommendations, item_info, N=5):\n    \"\"\"\u041f\u043e\u0441\u0442-\u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u044f \u0442\u043e\u0432\u0430\u0440\u043e\u0432\n    \n    Input\n    -----\n    recommendations: list\n        \u0420\u0430\u043d\u0436\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a item_id \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439\n    item_info: pd.DataFrame\n        \u0414\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u043e \u0442\u043e\u0432\u0430\u0440\u0430\u0445\n    \"\"\"\n    \n    # \u0423\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u044c\n#     recommendations = list(set(recommendations)) - \u043d\u0435\u0432\u0435\u0440\u043d\u043e! \u0442\u0430\u043a \u0442\u0435\u0440\u044f\u0435\u0442\u0441\u044f \u043f\u043e\u0440\u044f\u0434\u043e\u043a\n    unique_recommendations = []\n    [unique_recommendations.append(item) for item in recommendations if item not in unique_recommendations]\n    \n    # \u0420\u0430\u0437\u043d\u044b\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438\n    categories_used = []\n    final_recommendations = []\n    \n    CATEGORY_NAME = 'sub_commodity_desc'\n    for item in unique_recommendations:\n        category = item_features.loc[item_features['item_id'] == item, CATEGORY_NAME].values[0]\n        \n        if category not in categories_used:\n            final_recommendations.append(item)\n            \n        unique_recommendations.remove(item)\n        categories_used.append(category)\n    \n    n_rec = len(final_recommendations)\n    if n_rec < N:\n        final_recommendations.extend(unique_recommendations[:N - n_rec])\n    else:\n        final_recommendations = final_recommendations[:N]\n    \n    assert len(final_recommendations) == N, '\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 != {}'.format(N)\n    return final_recommendations","504a60ab":"def precision_at_k(recommended_list, bought_list, k=5):\n    \n    bought_list = np.array(bought_list)\n    recommended_list = np.array(recommended_list)\n    \n    bought_list = bought_list  # \u0422\u0443\u0442 \u043d\u0435\u0442 [:k] !!\n    recommended_list = recommended_list[:k]\n    \n    flags = np.isin(bought_list, recommended_list)\n    \n    precision = flags.sum() \/ len(recommended_list)\n    \n    \n    return precision","64eb6c07":"def ap_k(recommended_list, bought_list, k=5):\n    \n    bought_list = np.array(bought_list)\n    recommended_list = np.array(recommended_list)\n    \n    flags = np.isin(recommended_list, bought_list)\n    \n    if sum(flags) == 0:\n        return 0\n    \n    sum_ = 0\n    for i in range(1, k+1):\n        \n        if flags[i - 1] == True:\n            p_k = precision_at_k(recommended_list, bought_list, k=i)\n            \n            sum_ += p_k\n            \n    result = sum_ \/ min(len(recommended_list), k)\n    \n    return result","67730d06":"def map_k(recommended_list_list, bought_list_list, k=5):\n    \n    ap = list()\n    for i in range(len(recommended_list_list)):\n        ap.append(ap_k(recommended_list_list[i], bought_list_list[i], k=k))\n    \n    map_metric = np.mean(ap)\n    \n    return map_metric","c6eb07ac":"def ma_k_var2(predicted, actual, k=5):\n    return np.mean([ap_k(a,p,k) for a,p in zip(actual, predicted)])","0b2e0ad6":"data = pd.read_csv('\/kaggle\/input\/gb-recsys-project\/retail_train.csv')\nitem_features = pd.read_csv('\/kaggle\/input\/gb-recsys-project\/product.csv')\nuser_features = pd.read_csv('\/kaggle\/input\/gb-recsys-project\/hh_demographic.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/gb-recsys-project\/test_users.csv')\n\n# column processing\nitem_features.columns = [col.lower() for col in item_features.columns]\nuser_features.columns = [col.lower() for col in user_features.columns]\n\nitem_features.rename(columns={'product_id': 'item_id'}, inplace=True)\nuser_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n\n\n# \u0412\u0430\u0436\u043d\u0430 \u0441\u0445\u0435\u043c\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438!\n# -- \u0434\u0430\u0432\u043d\u0438\u0435 \u043f\u043e\u043a\u0443\u043f\u043a\u0438 -- | -- 6 \u043d\u0435\u0434\u0435\u043b\u044c -- | -- 3 \u043d\u0435\u0434\u0435\u043b\u044c -- \n# \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c \u0440\u0430\u0437\u043c\u0435\u0440 2-\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 (6 \u043d\u0435\u0434\u0435\u043b\u044c) --> learning curve (\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043c\u0435\u0442\u0440\u0438\u043a\u0438 recall@k \u043e\u0442 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430)\nval_lvl_1_size_weeks = 6\nval_lvl_2_size_weeks = 3\n\ndata_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\ndata_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n\ndata_train_lvl_2 = data_val_lvl_1.copy()  # \u0414\u043b\u044f \u043d\u0430\u0433\u043b\u044f\u0434\u043d\u043e\u0441\u0442\u0438. \u0414\u0430\u043b\u0435\u0435 \u043c\u044b \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f, \u0438 \u043e\u043d\u0438 \u0431\u0443\u0434\u0443\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c\u0441\u044f\ndata_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n\ndata_train_lvl_1.head(2)","8d63e25a":"users, items, interactions = data.user_id.nunique(), data.item_id.nunique(), data.shape[0]\n\nprint('# users: ', users) #\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0438\nprint('# items: ', items) #\u0442\u043e\u0432\u0430\u0440\u044b\nprint('# interactions: ', interactions) #\u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f","6e7b7df0":"# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c train-test split \u043f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u0430 \u043d\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e. \u0412\u043e\u0437\u044c\u043c\u0435\u043c \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 3 \u043d\u0435\u0434\u0435\u043b\u0438 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0442\u0435\u0441\u0442\u0430\ntest_size_weeks = 3\n\ndata_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\ndata_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]","766a2400":"data_train.shape[0], data_test.shape[0]","c50420f7":"result = data_test.groupby('user_id')['item_id'].unique().reset_index()\nresult.columns=['user_id', 'actual']\nresult.head(2)","ac8c8222":"test_users = result.shape[0]\nnew_test_users = len(set(data_test['user_id']) - set(data_train['user_id']))\n\nprint('\u0412 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430 \u0441\u0435\u0442\u0435 {} \u044e\u0437\u0435\u0440\u043e\u0432'.format(test_users))\nprint('\u0412 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430 \u0441\u0435\u0442\u0435 {} \u043d\u043e\u0432\u044b\u0445 \u044e\u0437\u0435\u0440\u043e\u0432'.format(new_test_users))","a0b49a37":"popularity = data.groupby('item_id')['user_id'].nunique().reset_index() \/ data['user_id'].nunique()\npopularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n\ntop_popular = popularity[popularity['share_unique_users'] > 0.3].item_id.tolist()\n","8e824875":"def popularity_recommendation(data, n=5):\n    \"\"\"\u0422\u043e\u043f-n \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0442\u043e\u0432\u0430\u0440\u043e\u0432\"\"\"\n    \n    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n    popular.sort_values('sales_value', ascending=False, inplace=True)\n    \n    recs = popular.head(n).item_id\n    \n    return recs.tolist()","baeb5c20":"%%time\n\n# \u041c\u043e\u0436\u043d\u043e \u0442\u0430\u043a \u0434\u0435\u043b\u0430\u0442\u044c, \u0442\u0430\u043a \u043a\u0430\u043a \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f \u043d\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043e\u0442 \u044e\u0437\u0435\u0440\u0430\npopular_recs = popularity_recommendation(data_train, n=5)\n\nresult['popular_recommendation'] = result['user_id'].apply(lambda x: popular_recs)\nresult.head(2)","87e60ce6":"n_items_before = data_train_lvl_1['item_id'].nunique()\n\ndata_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n\nn_items_after = data_train_lvl_1['item_id'].nunique()\nprint('Decreased # items from {} to {}'.format(n_items_before, n_items_after))","c2cdcd7a":"recommender = MainRecommender(data_train_lvl_1)","2b8ccb53":"recommender.get_als_recommendations(2375, N=5)","1c1b860c":"recommender.get_own_recommendations(2375, N=5)","91c1c1c2":"recommender.get_similar_items_recommendation(2375, N=5)","aa444cef":"recommender.get_similar_users_recommendation(2375, N=5)","3a28683d":"# \u0412 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430 \u0441\u0435\u0442\u0435\u0435\u0441\u0442\u044c \"\u0445\u043e\u043b\u043e\u0434\u043d\u044b\u0435\" \u043f\u043e\u043a\u0443\u043f\u0430\u0442\u0435\u043b\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u0430\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u043e\u0431\u0443\u0447\u0430\u043b\u0430\u0441\u044c\n# \u041d\u0430\u0439\u0434\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0442\u0430\u043a\u0438\u043c \u043f\u043e\u043a\u0443\u043f\u0430\u0442\u0435\u043b\u044f\u043c, \u0434\u043b\u044f \u043d\u0438\u0445 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0431\u0443\u0434\u0435\u043c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u043e\u0432\u0430\u0442\u044c \u0441\u0430\u043c\u044b\u0435 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0442\u043e\u0432\u0430\u0440\u044b\nlist_out = result.loc[~result.user_id.isin(data_train_lvl_1.user_id), 'user_id'].tolist()\nlist_out","dc710bcb":"def rule(x, y, model):\n    if model == 'als':\n        if x in y:\n            return list([840361, 1029743, 995242, 981760, 1082185])\n        else:\n            return recommender.get_als_recommendations(x, N=5)\n    elif model == 'own':\n        if x in y:\n            return list([840361, 1029743, 995242, 981760, 1082185])\n        else:\n            return recommender.get_own_recommendations(x, N=5)\n    elif model == 'similar_items':\n        if x in y:\n            return list([840361, 1029743, 995242, 981760, 1082185])\n        else:\n            return recommender.get_similar_items_recommendation(x, N=5)\n    elif model == 'similar_users':\n        if x in y:\n            return list([840361, 1029743, 995242, 981760, 1082185])\n        else:\n            return recommender.get_similar_users_recommendation(x, N=5)","4c81ad67":"result['als'] = result['user_id'].apply(lambda x: rule(x, list_out, model='als'))","2bba6a70":"result['own'] = result['user_id'].apply(lambda x: rule(x, list_out, model='own'))","0187e2ec":"result['similar_items'] = result['user_id'].apply(lambda x: rule(x, list_out, model='similar_items'))","db829444":"result.apply(lambda row: precision_at_k(row['als'], row['actual']), axis=1).mean() * 100","480128f5":"result.apply(lambda row: precision_at_k(row['own'], row['actual']), axis=1).mean() * 100","27ff8ce2":"result.apply(lambda row: precision_at_k(row['similar_items'], row['actual']), axis=1).mean() * 100","a8d2be1c":"result.head(2)","4eeabe5c":"# \u0414\u043b\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0434\u0430\u0442\u0430 \u0441\u0435\u0442\n# test_df['own'] = test_df['user_id'].apply(lambda x: rule(x, list_out, model='own'))","93f89f11":"# user_item_matrix = recommender.user_item_matrix\n# list_out = data_test.loc[~data_test.user_id.isin(data_train_lvl_1.user_id), 'user_id'].tolist()\n# for factors in [50]:\n#     recommender.fit(user_item_matrix, n_factors=factors, regularization=0.001, iterations=15, num_threads=4)\n#     result['als'] = result['user_id'].apply(lambda x: rule(x, list_out, model='als'))","31843245":"# result.apply(lambda row: precision_at_k(row['als'], row['actual']), axis=1).mean() * 100","6642d39d":"# -- \u0434\u0430\u0432\u043d\u0438\u0435 \u043f\u043e\u043a\u0443\u043f\u043a\u0438 -- | -- 6 \u043d\u0435\u0434\u0435\u043b\u044c -- | -- 3 \u043d\u0435\u0434\u0435\u043b\u044c --\n\nusers_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\nusers_lvl_2.columns = ['user_id']\n\n# \u041f\u043e\u043a\u0430 \u0442\u043e\u043b\u044c\u043a\u043e warm start\ntrain_users = data_train_lvl_1['user_id'].unique()\nusers_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n\nusers_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=50))\nusers_lvl_2.head(2)","0a069b78":"s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'item_id'\n\nusers_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\nusers_lvl_2['flag'] = 1\n\nusers_lvl_2.head(4)","79a94d81":"targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\ntargets_lvl_2['target'] = 1  # \u0442\u0443\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u043a\u0443\u043f\u043a\u0438 \n\ntargets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n\ntargets_lvl_2['target'].fillna(0, inplace= True)\ntargets_lvl_2.drop('flag', axis=1, inplace=True)\ntargets_lvl_2.head(2)","8bd6b3ff":"df = data_train.groupby('user_id')['item_id'].apply(list).reset_index()\nprint (df)","7e5384e7":"# \u0424\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439\n# result = [postfilter(recommendations, item_info=item_features, N=5) for recommendations in df['item_id']]","79d9a31d":"# n_items_before = data_train['item_id'].nunique()\n\n# data_train = prefilter_items(data_train, item_features=item_features)\n\n# n_items_after = data_train['item_id'].nunique()\n# print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))","215e3a0a":"# popularity = data_train.groupby('item_id')['quantity'].sum().reset_index()\n# popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n\n# popularity.head()","2d24af61":"# top_5000 = popularity.sort_values('n_sold', ascending=False).head(5000).item_id.tolist()","45b5531c":"# \u0417\u0430\u0432\u0435\u0434\u0435\u043c \u0444\u0438\u043a\u0442\u0438\u0432\u043d\u044b\u0439 item_id (\u0435\u0441\u043b\u0438 \u044e\u0437\u0435\u0440 \u043f\u043e\u043a\u0443\u043f\u0430\u043b \u0442\u043e\u0432\u0430\u0440\u044b \u0438\u0437 \u0442\u043e\u043f-5000, \u0442\u043e \u043e\u043d \"\u043a\u0443\u043f\u0438\u043b\" \u0442\u0430\u043a\u043e\u0439 \u0442\u043e\u0432\u0430\u0440)\n# data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999\n\nuser_item_matrix = pd.pivot_table(data_train, \n                                  index='user_id', columns='item_id', \n                                  values='quantity',\n                                  aggfunc='count', \n                                  fill_value=0\n                                 )\n\nuser_item_matrix[user_item_matrix > 0] = 1 # \u0442\u0430\u043a \u043a\u0430\u043a \u0432 \u0438\u0442\u043e\u0433\u0435 \u0445\u043e\u0442\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \nuser_item_matrix = user_item_matrix.astype(float) # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit\n\n# \u043f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 saprse matrix\nsparse_user_item = csr_matrix(user_item_matrix).tocsr()\n\nuser_item_matrix.head(3)","41c578c2":"userids = user_item_matrix.index.values\nitemids = user_item_matrix.columns.values\n\nmatrix_userids = np.arange(len(userids))\nmatrix_itemids = np.arange(len(itemids))\n\nid_to_itemid = dict(zip(matrix_itemids, itemids))\nid_to_userid = dict(zip(matrix_userids, userids))\n\nitemid_to_id = dict(zip(itemids, matrix_itemids))\nuserid_to_id = dict(zip(userids, matrix_userids))","455ca3d1":"%%time\n\nmodel = ItemItemRecommender(K=1, num_threads=4) # K - \u043a\u043e\u043b-\u0432\u043e \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439\n\nmodel.fit(csr_matrix(user_item_matrix).T.tocsr(), \n          show_progress=True)","3162716c":"%%time\n\nresult['own_purchases'] = result['user_id'].\\\n    apply(lambda x: [id_to_itemid[rec[0]] for rec in \n                    model.recommend(userid=userid_to_id[x], \n                                    user_items=sparse_user_item,   # \u043d\u0430 \u0432\u0445\u043e\u0434 user-item matrix\n                                    N=5, \n                                    filter_already_liked_items=False, \n                                    filter_items=None,\n                                    recalculate_user=False)])","511c1799":"result.head(5)","6bedb337":"def get_recommendations(user, model, N=5):\n    res = [id_to_itemid[rec[0]] for rec in \n                    model.recommend(userid=userid_to_id[user], \n                                    user_items=sparse_user_item,   # \u043d\u0430 \u0432\u0445\u043e\u0434 user-item matrix\n                                    N=N, \n                                    filter_already_liked_items=False, \n                                    filter_items=None, \n                                    recalculate_user=True)]\n    return res","c33bc1fb":"%%time\n\nmodel = AlternatingLeastSquares(factors=50, \n                                regularization=0.001,\n                                iterations=15, \n                                calculate_training_loss=True, \n                                num_threads=4)\n\nmodel.fit(csr_matrix(user_item_matrix).T.tocsr(),  # \u041d\u0430 \u0432\u0445\u043e\u0434 item-user matrix\n          show_progress=True)\n\nresult['als_var'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))","29c7fbc4":"user_item_matrix = tfidf_weight(user_item_matrix.T).T  # \u041f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a item-user \u043c\u0430\u0442\u0440\u0438\u0446\u0435 ! ","5b83a02e":"%%time\n\nmodel = AlternatingLeastSquares(factors=50, \n                                regularization=0.001,\n                                iterations=15, \n                                calculate_training_loss=True, \n                                num_threads=4)\n\nmodel.fit(csr_matrix(user_item_matrix).T.tocsr(),  # \u041d\u0430 \u0432\u0445\u043e\u0434 item-user matrix\n          show_progress=True)\n\nresult['als_tfidf'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))","adf48ddb":"# \u0417\u0430\u0432\u0435\u0434\u0435\u043c \u0444\u0438\u043a\u0442\u0438\u0432\u043d\u044b\u0439 item_id (\u0435\u0441\u043b\u0438 \u044e\u0437\u0435\u0440 \u043f\u043e\u043a\u0443\u043f\u0430\u043b \u0442\u043e\u0432\u0430\u0440\u044b \u0438\u0437 \u0442\u043e\u043f-5000, \u0442\u043e \u043e\u043d \"\u043a\u0443\u043f\u0438\u043b\" \u0442\u0430\u043a\u043e\u0439 \u0442\u043e\u0432\u0430\u0440)\n# data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999\n\nuser_item_matrix = pd.pivot_table(data_train, \n                                  index='user_id', columns='item_id', \n                                  values='quantity', # \u041c\u043e\u0436\u043d\u043e \u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442 \u044c\u0434\u0440\u0443\u0433\u0438\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b\n                                  aggfunc='count', \n                                  fill_value=0\n                                 )\n\nuser_item_matrix = user_item_matrix.astype(float) # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit\n\n# \u043f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 saprse matrix\nsparse_user_item = csr_matrix(user_item_matrix).tocsr()\n\nuser_item_matrix.head(3)","f1fb596d":"user_item_matrix = bm25_weight(user_item_matrix.T).T  # \u041f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a item-user \u043c\u0430\u0442\u0440\u0438\u0446\u0435 ! ","e68df462":"%%time\n\nmodel = AlternatingLeastSquares(factors=50, \n                                regularization=0.001,\n                                iterations=15, \n                                calculate_training_loss=True, \n                                num_threads=4) # K - \u043a\u043e\u043b-\u0432\u043e \u0431\u0438\u043b\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439\n\nmodel.fit(csr_matrix(user_item_matrix).T.tocsr(),  # \u041d\u0430 \u0432\u0445\u043e\u0434 item-user matrix\n          show_progress=True)\n\nresult['als_bm25'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))","8652c81c":"# n_items_before = data_train['item_id'].nunique()\n\n# data_train = prefilter_items(data_train, item_features=item_features)\n\n# n_items_after = data_train['item_id'].nunique()\n# print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))","8814bfa6":"# user_item_matrix = pd.pivot_table(data_train, \n#                                   index='user_id', columns='item_id', \n#                                   values='quantity', # \u041c\u043e\u0436\u043d\u043e \u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442 \u044c\u0434\u0440\u0443\u0433\u0438\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b\n#                                   aggfunc='count', \n#                                   fill_value=0\n#                                  )\n\n# user_item_matrix = user_item_matrix.astype(float) # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit\n\n# # \u043f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 saprse matrix\n# sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n\n# user_item_matrix.head(2)","63718a55":"# data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n# test_user_item_matrix = pd.pivot_table(data_test, \n#                                   index='user_id', columns='item_id', \n#                                   values='quantity', # \u041c\u043e\u0436\u043d\u043e \u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442 \u044c\u0434\u0440\u0443\u0433\u0438\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b\n#                                   aggfunc='count', \n#                                   fill_value=0\n#                                  )\n\n# test_user_item_matrix = user_item_matrix.astype(float) # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit","a9ff7f3c":"# userids = user_item_matrix.index.values\n# itemids = user_item_matrix.columns.values\n\n# matrix_userids = np.arange(len(userids))\n# matrix_itemids = np.arange(len(itemids))\n\n# id_to_itemid = dict(zip(matrix_itemids, itemids))\n# id_to_userid = dict(zip(matrix_userids, userids))\n\n# itemid_to_id = dict(zip(itemids, matrix_itemids))\n# userid_to_id = dict(zip(userids, matrix_userids))","ff6d7440":"# user_feat = pd.DataFrame(user_item_matrix.index)\n# user_feat = user_feat.merge(user_features, on='user_id', how='left')\n# user_feat.set_index('user_id', inplace=True)\n\n# item_feat = pd.DataFrame(user_item_matrix.columns)\n# item_feat = item_feat.merge(item_features, on='item_id', how='left')\n# item_feat.set_index('item_id', inplace=True)\n\n# user_feat.head(2)","d5004975":"# user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n# item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())","c9134bd3":"# user_feat_lightfm.head(2)","8b893279":"# model = LightFM(no_components=30,\n#                 loss='bpr', # 'warp'\n#                 learning_rate=0.05, \n#                 item_alpha=0.1, user_alpha=0.1, \n#                 random_state=42)\n\n# model.fit((sparse_user_item > 0) * 1,  # user-item matrix \u0438\u0437 0 \u0438 1\n#           sample_weight=coo_matrix(user_item_matrix),\n#           user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n#           item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n#           epochs=15, \n#           num_threads=4) ","68dc99f0":"# user_emb = model.get_user_representations(features=csr_matrix(user_feat_lightfm.values).tocsr())","8fc677bd":"# train_precision = precision_at_k(model, sparse_user_item, \n#                                  user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n#                                  item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n#                                  k=5).mean()\n\n# train_precision","374dcf6b":"result.head(2)","a573408a":"result.apply(lambda row: precision_at_k(row['popular_recommendation'], row['actual']), axis=1).mean() * 100","2bb3050f":"result.apply(lambda row: precision_at_k(row['own_purchases'], row['actual']), axis=1).mean() * 100","49aa0bc7":"result.apply(lambda row: precision_at_k(row['als_var'], row['actual']), axis=1).mean() * 100","e277e8ce":"result.apply(lambda row: precision_at_k(row['als_tfidf'], row['actual']), axis=1).mean() * 100","6af1ac81":"result.apply(lambda row: precision_at_k(row['als_bm25'], row['actual']), axis=1).mean() * 100","03f41ef5":"result.apply(lambda row: ap_k(row['popular_recommendation'], row['actual']), axis=1).mean() * 100","b9fec87a":"result.apply(lambda row: ap_k(row['own_purchases'], row['actual']), axis=1).mean() * 100","c8818081":"result.apply(lambda row: ap_k(row['als'], row['actual']), axis=1).mean() * 100","1d8c4ce8":"result.apply(lambda row: ap_k(row['als_tfidf'], row['actual']), axis=1).mean() * 100","d917db7a":"result.apply(lambda row: ap_k(row['als_bm25'], row['actual']), axis=1).mean() * 100","1466d5f8":"def transform_data_for_eval(dataset, rec_col, user_col='user_id'):\n    '''\n    Func for transforming recommendations into kaggle evaluation format\n\n    Parameters:\n    dataset (pd.DataFrame): Dataset with 2 required columns:\n        rec_col - column with recommendations should be iterable\n        user_col - columns with user id\n\n    rec_col (str): name of column in dataset with recommendations\n\n    user_col (str): name of column in dataset with user id\n\n    Returns:\n    pd.DataFrame: DataFrame in suitable format\n\n   '''\n    eval_dataset = dataset[[user_col, rec_col]].copy()\n    eval_dataset[rec_col] = eval_dataset[rec_col].apply(lambda x: ' '.join([str(i) for i in x]))\n    eval_dataset.rename(columns={\n        user_col: 'UserId',\n        rec_col: 'Predicted'\n    }, inplace=True)\n    return eval_dataset","cc35429a":"submit = pd.read_csv('\/kaggle\/input\/gb-recsys-project\/sample_submission.csv')\nsubmit.head()","b450d7ff":"def get_recommendations(user, model, N=5):\n    res = [id_to_itemid[rec[0]] for rec in \n                    model.recommend(userid=userid_to_id[user], \n                                    user_items=sparse_user_item,   # \u043d\u0430 \u0432\u0445\u043e\u0434 user-item matrix\n                                    N=N, \n                                    filter_already_liked_items=False, \n                                    filter_items=None, \n                                    recalculate_user=True)]\n    return res","74a85e91":"user_item_matrix = pd.pivot_table(data_train, \n                                  index='user_id', columns='item_id', \n                                  values='quantity',\n                                  aggfunc='count', \n                                  fill_value=0\n                                 )\n\nuser_item_matrix[user_item_matrix > 0] = 1 # \u0442\u0430\u043a \u043a\u0430\u043a \u0432 \u0438\u0442\u043e\u0433\u0435 \u0445\u043e\u0442\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \nuser_item_matrix = user_item_matrix.astype(float) # \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0439 \u0442\u0438\u043f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f implicit\n\n# \u043f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 saprse matrix\nsparse_user_item = csr_matrix(user_item_matrix).tocsr()","68f707db":"userids = user_item_matrix.index.values\nitemids = user_item_matrix.columns.values\n\nmatrix_userids = np.arange(len(userids))\nmatrix_itemids = np.arange(len(itemids))\n\nid_to_itemid = dict(zip(matrix_itemids, itemids))\nid_to_userid = dict(zip(matrix_userids, userids))\n\nitemid_to_id = dict(zip(itemids, matrix_itemids))\nuserid_to_id = dict(zip(userids, matrix_userids))","af1e6298":"%%time\n\nmodel = ItemItemRecommender(K=1, num_threads=4) # K - \u043a\u043e\u043b-\u0432\u043e \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439\n\nmodel.fit(csr_matrix(user_item_matrix).T.tocsr(), \n          show_progress=True)","4e4d924c":"model","b1bed82e":"list_out = test_df.loc[~test_df.user_id.isin(data_train.user_id), 'user_id'].tolist()\nlist_out","08eef728":"def rule(x, y):\n    if x in y:\n         return list([840361, 1029743, 995242, 981760, 1082185])\n    else:\n         return get_recommendations(x, model=model, N=5)","da6b145f":"test_df['own_purchases'] = test_df['user_id'].apply(lambda x: rule(x, list_out))","8ccf0973":"test_df.head(2)","c221aaa7":"sampl_df = transform_data_for_eval(test_df, rec_col='own_purchases', user_col='user_id')","223d2995":"sampl_df.head(2)","04a3a6f3":"sampl_df.to_csv('sample_test_submission.csv', index=False)","7b3c7c05":"# 1.4. BM25 \u0432\u0437\u0432\u0435\u0448\u0438\u0432\u0430\u043d\u0438\u0435","e22f939d":"# 1.2. Main Recommender","d19ce04f":"# \u0418\u0437\u043c\u0435\u0440\u0438\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e MAP@k (Mean Average Precision@k)  \n- \u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0432\u0437\u0432\u0435\u0448\u0435\u043d\u043d\u0443\u044e \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439","7be3d47b":"# \u0418\u0437\u043c\u0435\u0440\u0438\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e precision@5","23c9c004":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c 2-\u043e\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f \u043d\u0430 \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0445 \u043a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u0430\u0445","8e5e0d1e":"# Cross validation","6138cf93":"# \u042d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u0435\u0439 \u0434\u0440\u0443\u0433\u0438\u0445 \u043e\u043a\u0430\u0437\u0430\u043b\u0430\u0441\u044c \u0438\u0434\u0435\u044f \u043d\u0430\u0439\u0442\u0438 1 \u0431\u043b\u0438\u0436\u0430\u0448\u0435\u0433\u043e \u0441\u043e\u0441\u0435\u0434\u0430 \u0438 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u043e \u0442\u043e\u043f 5000, \u0435\u0435 \u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043c.","00a75337":"\u0414\u043b\u044f \u0443\u0434\u043e\u0431\u0441\u0442\u0432\u0430 \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043f\u043e\u0434\u0445\u043e\u0434\u044f\u0449\u0438\u0439 \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0444\u043e\u0440\u043c\u0430\u0442:","09845f46":"# 1.2. \u0412\u043e\u0437\u044c\u043c\u0435\u043c 1 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0431\u043b\u0438\u0437\u043a\u043e\u0433\u043e \u0441\u043e\u0441\u0435\u0434\u0430","4e7131ed":"### Train-test split","f795ff86":"# Open data and their transform","df5eb65a":"# 1.1 Popularity-based recommendation","3184df94":"# 8. \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435","d13d9925":"# Filters","0c2c495b":"# \u041a\u0443\u0440\u0441\u043e\u0432\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0442 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430 GeekBrains\n# \u0410\u0432\u0442\u043e\u0440: \u0415\u043b\u044c\u0446\u043e\u0432 \u0410\u0440\u0442\u0435\u043c \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447\n# \u041d\u0438\u043a \u043d\u0430 kaggle: virus_madison\n# \u0417\u0430\u0434\u0430\u043d\u0438\u0435 \u0434\u043b\u044f \u043a\u0443\u0440\u0441\u043e\u0432\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430\n# \u041c\u0435\u0442\u0440\u0438\u043a\u0430: MAP@5 - \u0441\u0440\u0435\u0434\u043d\u0435\u0432\u0437\u0432\u0435\u0448\u0435\u043d\u043d\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439\n\u0421\u0434\u0430\u0447\u0430 \u043f\u0440\u043e\u0435\u043a\u0442\u0430:\n\n\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430 - MAP@5. \u041f\u043e\u0440\u043e\u0433 \u0434\u043b\u044f \u0443c\u043f\u0435\u0448\u043d\u043e\u0439 \u0441\u0434\u0430\u0447\u0438 \u043f\u0440\u043e\u0435\u043a\u0442\u0430 - \u0431\u044d\u0439\u0437\u043b\u0430\u0439\u043d \u0432 \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434\u0435 (Most popular items baseline), \u0435\u0441\u043b\u0438 \u0432\u0430\u043c \u0443\u0434\u0430\u0441\u0442\u0441\u044f \u0435\u0433\u043e \u043e\u0431\u043e\u0439\u0442\u0438 \u0432\u044b \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u0437\u0430\u043a\u0440\u044b\u043b\u0438 \u043a\u0443\u0440\u0441.\n\n\u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u0440\u0430\u0437\u0431\u0438\u0442 \u043d\u0430 \u0434\u0432\u0435 \u0447\u0430\u0441\u0442\u0438 private\/public \u0432 \u0440\u0430\u0432\u043d\u044b\u0445 \u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u044f\u0445.\n\u0423\u0447\u0442\u0438\u0442\u0435 \u0447\u0442\u043e \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043c\u043e\u0433\u0443\u0442 \u043f\u043e\u043f\u0441\u0442\u0430\u0442\u044c\u0441\u044f \u043d\u043e\u0432\u044b\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0432\u0438\u0434\u0435\u043b\u0430 \u0432\u0430\u0448\u0430 \u043c\u043e\u0434\u0435\u043b\u044c (\u0434\u043b\u044f \u043a\u043e\u043b\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u043e\u0439 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u0438)\n\u041d\u0415 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u043d\u043e \u043a\u0440\u0430\u0439\u043d\u0435 \u0436\u0435\u043b\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c 2-\u0443\u0445 \u0443\u0440\u043e\u0432\u043d\u0435\u0432\u044b\u0435 \u0440\u0435\u043a\u043e\u043c\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0432 \u043f\u0440\u043e\u0435\u043a\u0442\u0435\n\u0412\u044b \u0441\u0434\u0430\u0435\u0442\u0435 \u043a\u043e\u0434 \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u0432\u0438\u0434\u0435 github \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u044f \u0438 \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0435 \u0441\u0432\u043e\u0439 \u043d\u0438\u043a \u0432 kaggle.\n\u0414\u0430\u043d\u043d\u044b\u0435\n\u0412\u0441\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u043a\u043e\u043c\u044b \u0432\u0430\u043c \u0438\u0437 \u0437\u0430\u043d\u044f\u0442\u0438\u0439:\n\n* hh_demographic.csv - \u0444\u0438\u0447\u0438 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439.\n* product.csv - \u0444\u0438\u0447\u0438 \u0442\u043e\u0432\u0430\u0440\u043e\u0432\u0430.\n* retail_train.csv - \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u0441 \u0442\u043e\u0432\u0430\u0440\u0430\u043c\u0438.\n* test_users.csv - \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f.\n* sample_submission.csv - \u043f\u0440\u0438\u043c\u0435\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u043d\u0430 kaggle \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n\n\u0414\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u0438\u0437 \u0444\u0430\u0439\u043b\u0430 test_users.csv.","ad8be434":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \u0441 \u043f\u043e\u043a\u0443\u043f\u043a\u0430\u043c\u0438 \u044e\u0437\u0435\u0440\u043e\u0432 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 (\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 3 \u043d\u0435\u0434\u0435\u043b\u0438)","b9424b9b":"# 1. \u0411\u0435\u0439\u0437\u043b\u0430\u0439\u043d\u044b","f4106fb9":"# Metrics","a1e98bc6":"# 1.0. Filter Items","5e591c66":"# 1.3. Alternating Least Squares (ALS)","057b89ab":"# Filter Items and model LFM","51e8ad8e":"# 1.3. TF-IDF \u0432\u0437\u0432\u0435\u0448\u0438\u0432\u0430\u043d\u0438\u0435"}}