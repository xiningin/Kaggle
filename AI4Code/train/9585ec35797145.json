{"cell_type":{"cc63adfd":"code","220b237e":"code","11dd7715":"code","a19e6df7":"code","7eb7a571":"code","4a927ed4":"code","89c58eb3":"code","7f8bf0e0":"code","a7128478":"code","c94c6f5d":"code","0e6dd712":"code","cd6adccb":"code","61fd62b7":"code","7bb01c22":"code","78476e1b":"code","18b4363a":"code","c0585260":"code","d43cf165":"code","88f0ff6c":"code","a6efec12":"code","48b92c2d":"code","979843b9":"code","84a7db08":"code","d8ce6661":"code","b7d6678f":"code","5fc65052":"code","0924200c":"code","6ab9fb1c":"markdown","333657aa":"markdown","dacd0f49":"markdown","74d952c3":"markdown","37425d47":"markdown","83e2e28f":"markdown","a900ac1b":"markdown","39d3e321":"markdown","1ea6b2e7":"markdown","c235c375":"markdown","6811a8f6":"markdown","7fb4905e":"markdown","e2c349d5":"markdown","095acded":"markdown","48a2bda1":"markdown","cc482c9c":"markdown","a4e2073c":"markdown","c87ec2ce":"markdown","1dec3233":"markdown","12e57882":"markdown"},"source":{"cc63adfd":"import numpy as np\nimport pandas as pd\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms as T\nfrom torchvision import models\nimport tqdm\n\nfrom sklearn.metrics import f1_score,roc_auc_score,accuracy_score,confusion_matrix","220b237e":"train_df=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_df=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","11dd7715":"def get_image(data_df,idx):\n    \"\"\"\n    gets the hand drawn digit image coresponding to the idx th row in data df\n    returns as a PIL RGB image\n    \"\"\"\n    return Image.fromarray(np.uint8(np.reshape(data_df.iloc[idx][data_df.columns[-784:]].to_numpy(),(28,28)))).convert('RGB')\n    ","a19e6df7":"class TrainDataSet(Dataset):\n    def __init__(self,data_df,transforms=T.ToTensor()):\n        \"\"\"\n        data_df: is the pandas dataframe containing all of the labels and images of the dataset\n        transforms: the transforms we should apply to each image, for now this will just be turning\n        each PIL image to a tensor\n        \"\"\"\n        self.data_df=data_df\n        self.transform=transforms\n        \n    def __len__(self):\n        return self.data_df.shape[0]\n    \n    def __getitem__(self,idx):\n        image=self.transform(get_image(self.data_df,idx))\n        label=torch.tensor(self.data_df.label.iloc[idx],dtype=torch.long)\n        return image,label","7eb7a571":"class TestDataSet(TrainDataSet):\n    def __getitem__(self,idx):\n        image=self.transform(get_image(self.data_df,idx))\n        return image","4a927ed4":"def create_model():\n    model = models.resnet18(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 10)\n    return model","89c58eb3":"transform=T.Compose([\n    T.Resize((256,256)),\n    T.ToTensor(),\n    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","7f8bf0e0":"def train_once(model,dataloader,criterion,optimizer,device):\n    \n    total_loss=0\n    n_total=0\n    criterion.reduction=\"sum\"\n\n    #set model to train\n    model.train()\n    for i,(images,labels) in enumerate(tqdm.tqdm(dataloader)):\n        #zero optimizer grad\n        optimizer.zero_grad()\n        #send data to gpu\n        images=images.to(device)\n        labels=labels.to(device)\n        \n        #forward pass through model\n        outputs=model(images)\n        #caculate loss\n        loss=criterion(outputs,labels)\n        \n        #update statistics\n        total_loss+=loss.item()\n        n_total+=labels.shape[0]\n        \n        #backward pass\n        loss.backward()\n        optimizer.step()\n        \n    return total_loss\/n_total","a7128478":"class Validation_Metrics(object):\n    def __init__(self,activation_func=nn.Softmax(dim=1)):\n        self.predictions=[]\n        self.labels=[]\n        self.activation_func=activation_func # activation function used to normalize model output\n        self.collapsed=False\n        \n    def update(self,model_outputs,labels):\n        \"\"\"\n        model_outputs: the unnormalized outputs from the model\n        labels: the correct labels for each prediction ie: 0, 4, 7 etc\n        \"\"\"\n        if not self.collapsed:\n            self.predictions.append(self.activation_func(model_outputs).detach())\n            self.labels.append(labels.detach())\n        else:\n            raise ValueError('Error, one cannot add further values to a logger once it has been collapsed')\n        \n    def collapse(self):\n        \"\"\"\n        collapese self.prediction and self.labels into \n        numpy arrays, happens in place\n        \"\"\"\n        if self.collapsed:\n            pass\n        else:\n            self.predictions=torch.cat(self.predictions).cpu().numpy()\n            self.labels=torch.cat(self.labels).cpu().numpy()\n            self.collapsed=True\n    \n    def Confusion_matrix(self):\n        \"\"\"\n        returns the confusion matrix where the \n        vertical indexs are the correct labels\n        and the horizontal indexs are the predicted labels\n        \"\"\"\n        self.collapse()\n        \n        Confusion_matrix=np.zeros(10,10)\n        pred=np.argmax(self.predictions,axis=1)\n        labels=self.labels\n        \n        return confusion_matrix(labels,pred)\n    \n    def AUC(self):\n        \"\"\"\n        returns a list of the auc scores for each label\n        \"\"\"\n        self.collapse()\n        \n        pred=self.predictions\n        labels=np.zeros(pred.shape)\n        labels[np.arange(label.shape[0]),self.labels]=1.0\n        \n        aucs = []\n        for i in range(labels.shape[1]):\n            aucs.append(roc_auc_score(labels[:, i], pred[:, i]))\n        return aucs\n    \n    def F1_score(self):\n        \n        self.collapse()\n        \n        pred=np.argmax(self.predictions,axis=1)\n        labels=self.labels\n        \n        return f1_score(labels, pred, average=None)\n    \n    def Accuracy(self):\n        self.collapse()\n        \n        pred=np.argmax(self.predictions,axis=1)\n        labels=self.labels\n        \n        return accuracy_score(labels, pred)\n        \n        ","c94c6f5d":"def val(model,dataloader,criterion,device):\n    total_loss=0\n    n_total=0\n    criterion.reduction=\"sum\"\n    Metrics=Validation_Metrics()\n    model.eval()\n    with torch.no_grad():\n        for images,labels in tqdm.tqdm(dataloader):\n\n            #send images and lables to device\n            images=images.to(device) \n            labels=labels.to(device)\n\n            #forward pass through data\n            outputs=model(images)\n            loss=criterion(outputs,labels)\n            Metrics.update(outputs,labels)\n            \n            #update statistics\n            total_loss+=loss.item()\n            n_total+=labels.shape[0]\n\n    \n    return total_loss\/n_total,Metrics\n    ","0e6dd712":"n_folds=5","cd6adccb":"train_df.insert(1,\"fold\",np.random.randint(1,n_folds+1,size=train_df.shape[0]))","61fd62b7":"def Get_Train_Val_Set(fold_i,transform=transform):\n    train_set=TrainDataSet(train_df[train_df.fold!=fold_i],transforms=transform)\n    test_set=TrainDataSet(train_df[train_df.fold==fold_i],transforms=transform)\n    return train_set, test_set","7bb01c22":"USE_CUDA = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if USE_CUDA else \"cpu\")","78476e1b":"criterion=nn.CrossEntropyLoss()\noptimizer_name=\"Adam\"\noptimizer_parameters={\"lr\":0.0001}\nepochs=1","18b4363a":"def create_optimizer(model,optimizer_name,optimizer_parameters):\n    if optimizer_name==\"SGD\":\n        return optim.SGD(model.parameters(),**optimizer_parameters)\n    elif optimizer_name==\"Adam\":\n        return optim.Adam(model.parameters(),**optimizer_parameters)","c0585260":"\nBest_val_accuracy=0\n\nfor fold in range(1,n_folds+1):\n    print(f\"Training fold {fold}\")\n    model=create_model()\n    model.to(device)\n    optimizer=create_optimizer(model,optimizer_name,optimizer_parameters)\n    \n    TrainSet,ValSet=Get_Train_Val_Set(fold)\n    \n    TrainLoader=DataLoader(TrainSet, batch_size=256)\n    ValLoader=DataLoader(ValSet, batch_size=1024)\n    \n    \n    for epoch in range(epochs):\n        train_loss=train_once(model,TrainLoader,criterion,optimizer,device)\n        print(f\"For epoch {epoch+1}, the Train Loss was: {train_loss}\")\n        val_loss,Metrics=val(model,ValLoader,criterion,device)\n        print(f\"The Val Loss was {val_loss}, and the val accuracy was {Metrics.Accuracy()}\")\n        if Metrics.Accuracy()>Best_val_accuracy:\n            print(\"New Best, saving\")\n            torch.save(model.state_dict(),f\"fold{fold}Best.pt\")\n    ","d43cf165":"optimizer=create_optimizer(model,optimizer,optimizer_parameters)\noptimizer","88f0ff6c":"model_outputs=torch.zeros((test_df.shape[0],10)).to(device)\nplot_every=1","a6efec12":"TestSet=TestDataSet(test_df,transforms=transform)","48b92c2d":"for fold in range(1,n_folds+1):\n    print(f\"Running on fold {fold}\")\n    model=create_model()\n    model.load_state_dict(torch.load(f\"fold{fold}Best.pt\"))\n    model.to(device)\n    model.eval()\n    \n    for i,image in enumerate(tqdm.tqdm(TestSet)):\n        image=torch.unsqueeze(image,0).to(device)\n        outputs=model(image)\n        model_outputs[i]+=outputs.detach()[0]","979843b9":"model_outputs","84a7db08":"submission_df=pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","d8ce6661":"submission_df[\"Label\"]=np.argmax(model_outputs.cpu().numpy(),1)","b7d6678f":"submission_df","5fc65052":"submission_df.to_csv(\"submission.csv\", index=False)","0924200c":"pd.read_csv(\"submission.csv\")","6ab9fb1c":"# Validation Function","333657aa":"# Cross Validation Training","dacd0f49":"# Creating A Model","74d952c3":"This will be a notebook for training a classifer for the MINST digit dataset. First we must import the requiste libraries, for this notebook I will be using pytorch to create and train the models. Instructions for installing pytorch are avalible on its website. ","37425d47":"## A helper function to get Train and Validation Dataset for Fold $i$","83e2e28f":"For this notebook, I will be using a resnet 18 model, modifying the final layer to output 10 outputs instead of 1000","a900ac1b":"# Train function","39d3e321":"## Writing A Helper Function\nThe images of each digit in the train and test subset are stored as a row in the train.csv and test.csv. In the train.csv there is an aditional column (the first column) for the correct digit label. We want to reshape this into a 28x28 image","1ea6b2e7":"## Training","c235c375":"## Config Parameters\nFor now we will be using Cross Entropy Loss, optimzing with a Adam optimizer with (`lr=0.01` and `momentum=0.9`), and training for two epochs","6811a8f6":"# MINST Digit Recognizer","7fb4905e":"### An Optimizer Creator Helper Function","e2c349d5":"## Constructing A Dataset\nPytorch provides a Dataset primitive that we can use to create a two custom datasets, one for the train and one for the test images. Within this dataset, we must implement two functions in adition to the `__init__` function, a `__len__` function that returns the length of the dataset, and a `__getitem__` function that gets the ith value in the dataset","095acded":"Now lets import the two csv files that form the dataset, the train csv and test csv","48a2bda1":"## Assign Data to partitions\nWe can assign each entry in train.csv (so train_df) to a fold by inserting a column right after the `label` column where the value for each entry is a random int in range `[1,n_folds]` ","cc482c9c":"For the `TestSet` Dataset, we can utilize what we already wrote for `TrainSet`, the only thing we will need to modify is the `__getitem__` function since there will be no labels for this dataset","a4e2073c":"# Cross Validation Helper Functions\nFor this notebook I will be using k fold cross validation to train k classifers. To do this, I will first divided the train dataset (ie: the train.csv) into $k$ partitions. Then I will train $k$ classifers, for the ith classifer, it will be trained on all partions execpt the ith partition which will be held out for validation. The final predictions for the test dataset will be an average of the $k$ classifers. For now the number of folds will be 5","c87ec2ce":"## Create a validation metric helper function\nThere are various ways to evaluate the performance of a classifer, such as Acuracy, F1 scores, AUC, etc. So we should create some helper functions to calculate these metrics. ","1dec3233":"Because the Resnet needs images with a size of at least `244 x 244`, we will need to construct a transfrom for the train and test dataset that resizes the image to `256 x 256` and turn these into pytorch tensors that we can feed into the model. While we are at, we might as well normalize all the images with `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]`.","12e57882":"# Create predictions for test dataset"}}