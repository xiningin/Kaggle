{"cell_type":{"fcded826":"code","33ef80b8":"code","bb52436c":"code","c1afe811":"code","e63fce76":"code","4a5315ac":"code","0c43a485":"code","5896573d":"code","b1b17c4a":"code","0dd13fee":"code","e4d816b6":"code","eb94b5b7":"code","4f8aca02":"code","0862afbe":"code","df5feddb":"code","226ccfbf":"code","81baab25":"code","ec083e18":"code","37a10d03":"code","54192b28":"code","6050c73c":"code","22e9f94d":"code","35db48e4":"code","cffc0a43":"code","06462beb":"code","8502c95d":"code","e51869f9":"code","56ae91cd":"code","2d4db449":"code","c9b4f0ee":"code","6f08e620":"code","17969e01":"code","c2acb13a":"code","7c1b5ab3":"code","f90ffd32":"code","d0e75fe0":"code","9d1cdeda":"code","e25a6896":"code","8f7c1bd5":"code","4fd71864":"code","53f0b6d7":"code","f816fcf6":"code","95a0b401":"code","49e08094":"code","5de30bea":"code","3b61dd13":"code","9d3e7ada":"code","69507a2e":"code","8f9517cb":"code","82da49aa":"code","2f27e2c3":"code","a8e9562d":"code","1e9c5e94":"code","097aafd0":"code","d20f0296":"code","84693e8d":"code","97e661a7":"code","bda4f345":"code","aede6ef7":"code","691eccdd":"code","10e5d01e":"code","29233437":"code","66dc5565":"code","4804bed4":"code","9d8aede3":"code","15e5c3ab":"code","0b36374a":"code","f5fcb445":"code","46b7f072":"code","cee64ed6":"code","c656ae27":"code","94d0c017":"code","ad88a3f3":"code","43674a3c":"code","4125acc5":"code","e2c0f8f2":"code","629b6dd5":"code","52c3aa15":"code","8fe91217":"code","deedd16a":"code","c0f623a8":"code","1d917af9":"code","66f88338":"code","fc22c0c2":"code","32811cfe":"code","3facea35":"code","d6e03f44":"code","d9655783":"code","8c3bf2c6":"code","0b2b8ce4":"code","fd3d4367":"code","1b92eb78":"code","2ccebe9c":"code","0ccaf0bd":"code","3e3e37e4":"code","562a7c7b":"code","a23f63ee":"code","b182d0dd":"code","8db0febf":"code","63462c45":"code","2ba3e580":"code","fdd259b4":"code","428d818b":"code","a78ce965":"code","6f1cb135":"code","c2f04b0f":"code","1918108c":"code","ea212a9a":"code","e4fd0174":"code","98e932e7":"code","fcb802a9":"code","217f5fae":"code","93317d38":"code","93daf38b":"code","45d37d4d":"code","83e4e9d6":"code","00db6d98":"code","93b11837":"code","748db367":"code","23d3db8c":"code","0809e46c":"code","2ce0a3e4":"code","3bcdc20b":"code","51520e85":"code","7e2ea224":"code","70256e25":"code","24b5dbdd":"code","a4048a4e":"code","11436889":"code","a023bf28":"code","59326983":"code","36851df0":"code","b55973c4":"code","e0485df8":"code","67e161fa":"code","8a995d4e":"code","dd9c7b9a":"code","476bf851":"code","2fb26292":"code","1df41885":"code","4260bade":"code","bf7ebfed":"code","5ad6d052":"code","71c506ce":"code","3cb593c8":"code","3ae31bb1":"code","6ee129b6":"code","98257183":"code","ab407bd4":"code","ad8cdc9d":"code","60f7c8cb":"code","6404cd94":"code","d4c5e075":"code","2b27142d":"code","9efa4668":"code","4709fefe":"code","4f9d0467":"code","aacb613e":"code","48f0ba45":"code","7c0302f4":"code","cfb9fc55":"code","cd1eb685":"code","9e53b387":"code","4b772cff":"code","7d94fdbd":"code","adbe438c":"code","7a505432":"code","dab7ac34":"code","b001f37c":"code","c1c6e455":"code","420115cc":"code","01c983a6":"code","69983ca0":"code","d5cfdc93":"code","044787da":"code","c27dfe5d":"code","7b4c7be2":"code","b5ef2d2e":"code","79015558":"code","fb7a538b":"code","9ef0c3f7":"code","dced2bcc":"code","c141efb3":"code","826a505d":"code","73fabf61":"code","e0f411c5":"code","efe38d2d":"code","3b9263ce":"code","ac9ccdbd":"code","f40d032b":"code","777093ca":"markdown","ca3995af":"markdown","680cec08":"markdown","8725f25f":"markdown","d5586326":"markdown","2b3c1598":"markdown","b7a275be":"markdown","ac532689":"markdown","5fe2030a":"markdown","41f23e46":"markdown","d2031a96":"markdown","6cbfc60e":"markdown","6bd4b41a":"markdown","7112dd75":"markdown","b13e08d2":"markdown","a5d7f329":"markdown","da87c305":"markdown","6101c18e":"markdown","720ed639":"markdown","13793a7c":"markdown","b884daa9":"markdown","4ce0eec2":"markdown","63e1b00b":"markdown","dd6487b0":"markdown","29115eec":"markdown","1c6f425a":"markdown","40b1724d":"markdown","db5639a1":"markdown","c8e54b05":"markdown","5f4a314e":"markdown","da04a1d2":"markdown","8ab3e87c":"markdown","2b708fe8":"markdown","2454edc6":"markdown","ef6775fe":"markdown","f2196d90":"markdown","297b394d":"markdown","0b6b3f2b":"markdown","60e913e3":"markdown","3230346b":"markdown","d544b33f":"markdown","60a2c49a":"markdown","fa737ce4":"markdown"},"source":{"fcded826":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\n%matplotlib inline","33ef80b8":"df = pd.read_csv(\"\/kaggle\/input\/italian-cultural-heritage-sample-data-20152018\/table2.csv\")","bb52436c":"df.head(10)","c1afe811":"df.info()","e63fce76":"df[\"Region\"] = df[\"Region\"].astype(\"category\")\ndf[\"Region\"] = df[\"Region\"].cat.codes\ndf.head()","4a5315ac":"df.shape","0c43a485":"df1 = df[['Year','Region','Euro']]","5896573d":"df1.head(10)","b1b17c4a":"df1.shape","0dd13fee":"from sklearn.model_selection import train_test_split\nX = df1.iloc[:, :-1].values\ny = df1.iloc[:, -1].values","e4d816b6":"x_train,x_test,y_train,y_test = train_test_split(X,y,random_state = 0,test_size = 0.2)","eb94b5b7":"x_train.shape","4f8aca02":"x_test.shape","0862afbe":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","df5feddb":"model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics","226ccfbf":"history = model.fit(x_train, y_train, epochs=30, batch_size=16, validation_data=(x_test, y_test))","81baab25":"[mse, mae] = model.evaluate(x_test, y_test) ","ec083e18":"model.summary()","37a10d03":"tf.keras.utils.plot_model(model)","54192b28":"ypred = model.predict(x_test)\nprint('Actual Euro = {} and Predicted Euro = {}'.format(y_test[1], ypred[1]))","6050c73c":"model.save('dnn1.h5')","22e9f94d":"# We create a fucntion to make it easy for multiple calls\ndef build_model():   \n    model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics\n    return model","35db48e4":"# Let us visit K-fold validation\nk = 4\nnum_val_samples = len(x_train) \/\/ k\nnum_epochs = 100\nall_scores = []\nfor i in range(k):\n    print('processing fold #%d' % i)\n    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples] \n    val_labels = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate( \n        [x_train[:i * num_val_samples],\n         x_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_labels = np.concatenate(\n        [y_train[:i * num_val_samples],\n         y_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    \nmodel = build_model() \nmodel.fit(partial_train_data, partial_train_labels, \n          epochs=num_epochs, batch_size=1, verbose=0)\nval_mse, val_mae = model.evaluate(val_data, val_labels, verbose=0) \nall_scores.append(val_mae)","cffc0a43":"print(all_scores)\nprint(np.mean(all_scores))","06462beb":"model = build_model() \nmodel.fit(x_train, y_train, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(x_test, y_test)\nprint(test_mse_score, test_mae_score)","8502c95d":"model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics","e51869f9":"history = model.fit(x_train, y_train, epochs=60, batch_size=16, validation_data=(x_test, y_test))","56ae91cd":"[mse, mae] = model.evaluate(x_test, y_test) ","2d4db449":"model.summary()","c9b4f0ee":"tf.keras.utils.plot_model(model)","6f08e620":"ypred = model.predict(x_test)\nprint('Actual Euro = {} and Predicted Euro = {}'.format(y_test[1], ypred[1]))","17969e01":"model.save('dnn2.h5')","c2acb13a":"# We create a fucntion to make it easy for multiple calls\ndef build_model():   \n    model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics\n    return model","7c1b5ab3":"# Let us visit K-fold validation\nk = 4\nnum_val_samples = len(x_train) \/\/ k\nnum_epochs = 100\nall_scores = []\nfor i in range(k):\n    print('processing fold #%d' % i)\n    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples] \n    val_labels = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate( \n        [x_train[:i * num_val_samples],\n         x_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_labels = np.concatenate(\n        [y_train[:i * num_val_samples],\n         y_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    \nmodel = build_model() \nmodel.fit(partial_train_data, partial_train_labels, \n          epochs=num_epochs, batch_size=1, verbose=0)\nval_mse, val_mae = model.evaluate(val_data, val_labels, verbose=0) \nall_scores.append(val_mae)","f90ffd32":"print(all_scores)\nprint(np.mean(all_scores))","d0e75fe0":"model = build_model() \nmodel.fit(x_train, y_train, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(x_test, y_test)\nprint(test_mse_score, test_mae_score)","9d1cdeda":"model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dense(2048, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics","e25a6896":"history = model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test))","8f7c1bd5":"[mse, mae] = model.evaluate(x_test, y_test) ","4fd71864":"model.summary()","53f0b6d7":"tf.keras.utils.plot_model(model)","f816fcf6":"ypred = model.predict(x_test)\nprint('Actual Euro = {} and Predicted Euro = {}'.format(y_test[1], ypred[1]))","95a0b401":"model.save('dnn3.h5')","49e08094":"# We create a fucntion to make it easy for multiple calls\ndef build_model():   \n    model = keras.Sequential([ \n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dense(2048, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # observe the loss and metrics\n    return model","5de30bea":"# Let us visit K-fold validation\nk = 4\nnum_val_samples = len(x_train) \/\/ k\nnum_epochs = 100\nall_scores = []\nfor i in range(k):\n    print('processing fold #%d' % i)\n    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples] \n    val_labels = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate( \n        [x_train[:i * num_val_samples],\n         x_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_labels = np.concatenate(\n        [y_train[:i * num_val_samples],\n         y_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    \nmodel = build_model() \nmodel.fit(partial_train_data, partial_train_labels, \n          epochs=num_epochs, batch_size=1, verbose=0)\nval_mse, val_mae = model.evaluate(val_data, val_labels, verbose=0) \nall_scores.append(val_mae)","3b61dd13":"print(all_scores)\nprint(np.mean(all_scores))","9d3e7ada":"model = build_model() \nmodel.fit(x_train, y_train, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(x_test, y_test)\nprint(test_mse_score, test_mae_score)","69507a2e":"import os, shutil\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","8f9517cb":"train_altar_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\/train_altar_dir\"\ntrain_glass_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\/train_glass_dir\"\ntest_altar_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\/test_altar_dir\"\ntest_glass_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\/test_glass_dir\"\nval_altar_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\/val_altar_dir\"\nval_glass_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\/val_glass_dir\"","82da49aa":"# Let us cross check\nprint('Training Altar images ={}'.format(len(os.listdir(train_altar_dir))),\n      '\\nTraining Glass images ={}'.format(len(os.listdir(train_glass_dir))),\n      '\\nValidation Altar images ={}'.format(len(os.listdir(val_altar_dir))),\n      '\\nValidation Glass images ={}'.format(len(os.listdir(val_glass_dir))),\n      '\\nTesting Altar images ={}'.format(len(os.listdir(test_altar_dir))),\n      '\\nTesting Glass images ={}'.format(len(os.listdir(test_glass_dir))),\n     )","2f27e2c3":"# View one image\nimport imageio\naltar_image_names = os.listdir(train_altar_dir)\naltar_img = imageio.imread(os.path.join(train_altar_dir, altar_image_names[5]))\nplt.imshow(altar_img)\n\nplt.figure()\n\nglass_image_names = os.listdir(train_glass_dir)\nglass_img = imageio.imread(os.path.join(train_glass_dir, glass_image_names[5]))\nplt.imshow(glass_img)","a8e9562d":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","1e9c5e94":"# Compiling the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","097aafd0":"tf.keras.utils.plot_model(model)","d20f0296":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\"\nval_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n","84693e8d":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","97e661a7":"history = model.fit(train_generator,\n                             epochs=20,\n                             validation_data=val_generator)","bda4f345":"model.save('model1.h5')","aede6ef7":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","691eccdd":"test_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)","10e5d01e":"model.evaluate(test_generator)","29233437":"test_img = test_generator[12][0][9]\ntest_img.shape","66dc5565":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 1 for glass and 0 for altar","4804bed4":"plt.imshow(test_img)","9d8aede3":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","15e5c3ab":"# Compiling the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","0b36374a":"tf.keras.utils.plot_model(model)","f5fcb445":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\"\nval_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n","46b7f072":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","cee64ed6":"history = model.fit(train_generator,\n                             epochs=20,\n                             validation_data=val_generator)","c656ae27":"model.save('model2.h5')","94d0c017":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","ad88a3f3":"test_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)","43674a3c":"model.evaluate(test_generator)","4125acc5":"test_img = test_generator[12][0][9]\ntest_img.shape","e2c0f8f2":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 1 for glass and 0 for altar","629b6dd5":"plt.imshow(test_img)","52c3aa15":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","8fe91217":"# Compiling the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","deedd16a":"tf.keras.utils.plot_model(model)","c0f623a8":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\"\nval_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n","1d917af9":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","66f88338":"history = model.fit(train_generator,\n                             epochs=20,\n                             validation_data=val_generator)","fc22c0c2":"model.save('model3.h5')","32811cfe":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","3facea35":"test_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)","d6e03f44":"model.evaluate(test_generator)","d9655783":"test_img = test_generator[12][0][9]\ntest_img.shape","8c3bf2c6":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 1 for glass and 0 for altar","0b2b8ce4":"plt.imshow(test_img)","fd3d4367":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","1b92eb78":"# Compiling the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","2ccebe9c":"tf.keras.utils.plot_model(model)","0ccaf0bd":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/train_dir\"\nval_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n","3e3e37e4":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","562a7c7b":"history = model.fit(train_generator,\n                             epochs=20,\n                             validation_data=val_generator)","a23f63ee":"model.save('model4.h5')","b182d0dd":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","8db0febf":"test_dir = \"\/kaggle\/input\/dlproj-altarandglass\/DLProject\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)","63462c45":"model.evaluate(test_generator)","2ba3e580":"test_img = test_generator[12][0][9]\ntest_img.shape","fdd259b4":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 1 for glass and 0 for altar","428d818b":"plt.imshow(test_img)","a78ce965":"import os, shutil\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","6f1cb135":"train_altar_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\/train_altar_dir\"\ntrain_glass_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\/train_glass_dir\"\ntrain_bt_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\/train_bt_dir\"\ntrain_col_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\/train_col_dir\"","c2f04b0f":"# View one image\nimport imageio\naltar_image_names = os.listdir(train_altar_dir)\naltar_img = imageio.imread(os.path.join(train_altar_dir, altar_image_names[5]))\nplt.imshow(altar_img)\n\nplt.figure()\n\nglass_image_names = os.listdir(train_glass_dir)\nglass_img = imageio.imread(os.path.join(train_glass_dir, glass_image_names[5]))\nplt.imshow(glass_img)\n\nplt.figure()\n\nbt_image_names = os.listdir(train_bt_dir)\nbt_img = imageio.imread(os.path.join(train_bt_dir, bt_image_names[5]))\nplt.imshow(bt_img)\n\nplt.figure()\n\ncol_image_names = os.listdir(train_col_dir)\ncol_img = imageio.imread(os.path.join(train_col_dir, col_image_names[5]))\nplt.imshow(col_img)","1918108c":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\nmodel.summary()","ea212a9a":"# Compiling the model\nmodel.compile(optimizer='rmsprop',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","e4fd0174":"tf.keras.utils.plot_model(model)","98e932e7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\"\nval_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n","fcb802a9":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","217f5fae":"history = model.fit(x = train_generator,\n                             epochs=10,\n                             validation_data=val_generator)","93317d38":"model.save('model5.h5')","93daf38b":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","45d37d4d":"test_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)","83e4e9d6":"model.evaluate(test_generator)","00db6d98":"test_img = test_generator[13][0][10]\ntest_img.shape","93b11837":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 0 for altar, 1 for bell tower, 2 for column, 4 for glass","748db367":"plt.imshow(test_img)","23d3db8c":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\nmodel.summary()","0809e46c":"# Compiling the model\nmodel.compile(optimizer='rmsprop',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","2ce0a3e4":"tf.keras.utils.plot_model(model)","3bcdc20b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\"\nval_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n","51520e85":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","7e2ea224":"history = model.fit(x = train_generator,\n                             epochs=10,\n                             validation_data=val_generator)","70256e25":"model.save('model6.h5')","24b5dbdd":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","a4048a4e":"test_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)","11436889":"model.evaluate(test_generator)","a023bf28":"test_img = test_generator[13][0][10]\ntest_img.shape","59326983":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 0 for altar, 1 for bell tower, 2 for column, 4 for glass","36851df0":"plt.imshow(test_img)","b55973c4":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((3, 3)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\nmodel.summary()","e0485df8":"# Compiling the model\nmodel.compile(optimizer='rmsprop',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","67e161fa":"tf.keras.utils.plot_model(model)","8a995d4e":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/train_dir\"\nval_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/val_dir\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)\n","dd9c7b9a":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","476bf851":"history = model.fit(x = train_generator,\n                             epochs=25,\n                             validation_data=val_generator)","2fb26292":"model.save('model7.h5')","1df41885":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","4260bade":"test_dir = \"\/kaggle\/input\/multiclass-cnn\/DLProject2\/test_dir\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='categorical'\n)","bf7ebfed":"model.evaluate(test_generator)","5ad6d052":"test_img = test_generator[13][0][10]\ntest_img.shape","71c506ce":"model.predict_classes(np.expand_dims(test_img, axis=0))\n# label 0 for altar, 1 for bell tower, 2 for column, 4 for glass","3cb593c8":"plt.imshow(test_img)","3ae31bb1":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, shutil\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dropout","6ee129b6":"test_gargoyle_dir = \"..\/input\/architecturecombination\/Combi\/Test\/Gargoyles\"\ntrain_gargoyle_dir = \"..\/input\/architecturecombination\/Combi\/Train\/Gargoyles\"\nval_gargoyle_dir = \"..\/input\/architecturecombination\/Combi\/Validation\/Gargoyle\"\ntest_BellTower_dir = \"..\/input\/architecturecombination\/Combi\/Test\/Bell_Tower\"\ntrain_BellTower_dir = \"..\/input\/architecturecombination\/Combi\/Train\/Bell_Tower\"\nval_BellTower_dir = \"..\/input\/architecturecombination\/Combi\/Validation\/Bell_Tower\"","98257183":"# Let us cross check\nprint('Training gargoyle images ={}'.format(len(os.listdir(train_gargoyle_dir))),\n      '\\nValidation gargoyle images ={}'.format(len(os.listdir(val_gargoyle_dir))),\n      '\\nTesting gargoyle images ={}'.format(len(os.listdir(test_gargoyle_dir))),\n     )\nprint('Training BellTower images ={}'.format(len(os.listdir(train_BellTower_dir))),\n      '\\nValidation BellTower images ={}'.format(len(os.listdir(val_BellTower_dir))),\n      '\\nTesting BellTower images ={}'.format(len(os.listdir(test_BellTower_dir))),\n     )","ab407bd4":"# View one image\nimport imageio\nBellTower_image_names = os.listdir(train_BellTower_dir)\nBellTower_img = imageio.imread(os.path.join(train_BellTower_dir, BellTower_image_names[105]))\nplt.imshow(BellTower_img)\n\nplt.figure()","ad8cdc9d":"# View one image\nimport imageio\ngargoyle_image_names = os.listdir(train_gargoyle_dir)\ngargoyle_img = imageio.imread(os.path.join(train_gargoyle_dir, gargoyle_image_names[105]))\nplt.imshow(gargoyle_img)\n\nplt.figure()","60f7c8cb":"dropout = 0.4","6404cd94":"model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32, 5, strides=2, input_shape=(150, 150, 3)),\n        tf.keras.layers.LeakyReLU(alpha=0.2),\n        tf.keras.layers.Dropout(dropout),\n        tf.keras.layers.Conv2D(64,5, strides=2, padding='same'),\n        tf.keras.layers.LeakyReLU(alpha=0.2),\n        tf.keras.layers.Dropout(dropout),\n        tf.keras.layers.Conv2D(128,5, strides=2, padding='same'),\n        tf.keras.layers.LeakyReLU(alpha=0.2),\n        tf.keras.layers.Dropout(dropout),\n        tf.keras.layers.Conv2D(256,5, strides=1, padding='same'),\n        tf.keras.layers.LeakyReLU(alpha=0.2),\n        tf.keras.layers.Dropout(dropout),\n\n        # Out: 1-dim probability\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(1),\n        tf.keras.layers.Activation('sigmoid')\n  ])","d4c5e075":"model.summary()","2b27142d":"dropout = 0.4\ndepth = 64+64+64+64\ndim = 19","9efa4668":"model2= tf.keras.models.Sequential([\n    tf.keras.layers.Dense(dim*dim*depth, input_dim=150),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Reshape((dim, dim, depth)),\n    tf.keras.layers.Dropout(dropout),\n    # In: dim x dim x depth\n    # Out: 2*dim x 2*dim x depth\/2\n    tf.keras.layers.UpSampling2D(),\n    tf.keras.layers.Conv2DTranspose(int(depth\/2), 5,strides=2, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.UpSampling2D(),\n    tf.keras.layers.Conv2DTranspose(int(depth\/4), 5, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv2DTranspose(int(depth\/8), 5, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv2D(3, 3, activation='tanh')\n    # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n    #tf.keras.layers.Conv2DTranspose(1, 5, padding='same'),\n    #tf.keras.layers.Activation('sigmoid')\n    #tf.keras.layers.Conv2D(3, 3, activation='tanh', padding='same')\n])","4709fefe":"'''latent_dim = 32\nheight = 32\nwidth = 32\nchannels = 3\ngenerator_input = keras.Input(shape=(latent_dim,))\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()'''","4f9d0467":"model2.summary()","aacb613e":"optimizer=tf.keras.optimizers.RMSprop(lr=0.0002, decay=6e-8)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])","48f0ba45":"optimizer=tf.keras.optimizers.RMSprop(lr=0.0002, decay=6e-8)\nmodel2.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])","7c0302f4":"optimizer = tf.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\nmodel3= tf.keras.models.Sequential([\n    tf.keras.layers.Dense(dim*dim*depth, input_dim=150),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Reshape((dim, dim, depth)),\n    tf.keras.layers.Dropout(dropout),\n    # In: dim x dim x depth\n    # Out: 2*dim x 2*dim x depth\/2\n    tf.keras.layers.UpSampling2D(),\n    tf.keras.layers.Conv2DTranspose(int(depth\/2), 5,strides=2, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.UpSampling2D(),\n    tf.keras.layers.Conv2DTranspose(int(depth\/4), 5, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv2DTranspose(int(depth\/8), 5, padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv2D(3, 3, activation='tanh'),\n    tf.keras.layers.Conv2D(32, 5, strides=2, input_shape=(150, 150, 3)),\n    tf.keras.layers.LeakyReLU(alpha=0.2),\n    tf.keras.layers.Dropout(dropout),\n    tf.keras.layers.Conv2D(64,5, strides=2, padding='same'),\n    tf.keras.layers.LeakyReLU(alpha=0.2),\n    tf.keras.layers.Dropout(dropout),\n    tf.keras.layers.Conv2D(128,5, strides=2, padding='same'),\n    tf.keras.layers.LeakyReLU(alpha=0.2),\n    tf.keras.layers.Dropout(dropout),\n    tf.keras.layers.Conv2D(256,5, strides=1, padding='same'),\n    tf.keras.layers.LeakyReLU(alpha=0.2),\n    tf.keras.layers.Dropout(dropout),\n\n    # Out: 1-dim probability\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1),\n    tf.keras.layers.Activation('sigmoid')\n])\nmodel3.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])","cfb9fc55":"model3.summary()","cd1eb685":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_dir = \"..\/input\/architecturecombination\/Combi\/Train\"\nval_dir = \"..\/input\/architecturecombination\/Combi\/Validation\"\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)\n\nval_generator = test_datagen.flow_from_directory(\nval_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'   \n)","9e53b387":"# Let us look at these outputs\nfor data_batch, labels_batch in train_generator:\n    print('Data batch shape =', data_batch.shape)\n    print('Labels batch shape =', labels_batch.shape)\n    break","4b772cff":"history = model.fit(train_generator,\n                             epochs=4,\n                             validation_data=val_generator)","7d94fdbd":"# Let us plot the loss and accuracy curves\nhistory_dict = history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","adbe438c":"test_dir = \"..\/input\/architecturecombination\/Combi\/Test\"\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary'\n)","7a505432":"model.evaluate(test_generator)","dab7ac34":"test_img = test_generator[12][0][9]\ntest_img.shape","b001f37c":"model.predict_classes(np.expand_dims(test_img, axis=0))","c1c6e455":"plt.imshow(test_img)","420115cc":"noise = np.random.uniform(-1.0, 1.0, size=[20, 100])","01c983a6":"x_train = data_batch[labels_batch.flatten() == 0]","69983ca0":"x_train = x_train.reshape(\n(x_train.shape[0],) +\n(150, 150, 3)).astype('float32') \/ 255.","d5cfdc93":"iterations = 10000\nbatch_size = 20\nlatent_dim = 150\nstart = 0\nfor step in range(iterations):\n    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))","044787da":"generated_images = model2.predict(random_latent_vectors)","c27dfe5d":"plt.imshow(generated_images[1]*255.)","7b4c7be2":"stop = start + 20\nreal_images = x_train[start: stop]","b5ef2d2e":"plt.imshow(real_images[1]*255.)","79015558":"combined_images = np.concatenate([generated_images, real_images])","fb7a538b":"labels = np.concatenate([np.ones((15, 1)),\nnp.zeros((15, 1))])\nlabels += 0.05 * np.random.random(labels.shape)","9ef0c3f7":"d_loss = model.train_on_batch(combined_images, labels)","dced2bcc":"d_loss","c141efb3":"random_latent_vectors = np.random.normal(size=(20,\n150))","826a505d":"misleading_targets = np.zeros((20, 1))","73fabf61":"a_loss = model3.train_on_batch(random_latent_vectors,\nmisleading_targets)","e0f411c5":"a_loss","efe38d2d":"start += 20\nif start > len(x_train) - batch_size:\n    start = 0\nif step % 100 == 0:\n    model3.save_weights('gan.h5')","3b9263ce":"print('discriminator loss:', d_loss)\nprint('adversarial loss:', a_loss)","ac9ccdbd":"plt.imshow(generated_images[19] * 255.,)","f40d032b":"plt.imshow(real_images[0] * 255.)","777093ca":"*Read the images from the respective directories <br>\nWe shall use ImageDataGenerator method*","ca3995af":"##### Reffering to a Kaggle Grandmaster Notebook for CNN Architecture.\nhttps:\/\/www.kaggle.com\/cdeotte\/how-to-choose-cnn-architecture-mnist\n\nWe create 4 Models. Alternating between L2 weight regularization and Batch Normalization.<br>\n    \n    Each Model, has 3 2D Convolution Layers, with 32, 64, and 128 filters of size 3x3.\n    Alternating Max layers to obtain the best element features.\n    One flatten layer to convert the output into a 1D array.\n    First Dense layer of 128 neurons.\n    With a dropout rate of 0.4 to prevent overfitting.\n    Second Dense layer of 1 neuron for Binary Classification, with activation sigmoid.\n\n1. Model 1 has no weight regularization and batch normalization.\n2. Model 2 has L2 weight regularization but no batch normalization.\n3. Model 3 has no weight regularization but has batch normalization.\n4. Model 4 has both L2 weight regularization and batch normalization.<br>\n\nFrom the 4 models we will compare the accuracy, loss, and average train time. ","680cec08":"Understandings,\n* Accuracy improves as more advanced features are added.\n* But Loss increases due to advanced features. \n    * Improve using transfer learning.\n    * Increase dataset, data augmentation.\n    * Increase epochs.\n    * Increase dropout.\n* Advanced features also allow for faster training time.\n\nShortcomings,\n* Models are not relatively small to justify weight regularization.\n* Model is trained on a small dataset. No data augmentation used.\n* Due to small dataset the difference between model metrics is negligible.\n\n---","8725f25f":"A discriminator that tells how real an image is, is basically a deep Convolutional Neural Network (CNN) as shown in Figure 1. For MNIST Dataset, the input is an image (28 pixel x 28 pixel x 1 channel). The sigmoid output is a scalar value of the probability of how real the image is (0.0 is certainly fake, 1.0 is certainly real, anything in between is a gray area). The difference from a typical CNN is the absence of max-pooling in between layers. Instead, a strided convolution is used for downsampling. The activation function used in each CNN layer is a leaky ReLU. A dropout between 0.4 and 0.7 between layers prevent over fitting and memorization.","d5586326":"*Training the model*","2b3c1598":"### Model 2","b7a275be":"### Model 3","ac532689":"---\n\n# Use Case 2","5fe2030a":"*Training the model*","41f23e46":"*Training the model*","d2031a96":"### Model 1","6cbfc60e":"### Discriminator model","6bd4b41a":"*Read the images from the respective directories <br>\nWe shall use ImageDataGenerator method*","7112dd75":"### Model 3","b13e08d2":"### Generator Model","a5d7f329":"*Read the images from the respective directories <br>\nWe shall use ImageDataGenerator method*","da87c305":"---\n\n# Use Case 4","6101c18e":"*Training the model*","720ed639":"We build Multiple DNN models to study the effect of the number of dense layers, epochs, and rmse","13793a7c":"# Group 11:\n*Historical Heritage*\n    \n1. Aniruddha Mavlankar (20030242011)\n2. Boris Raj Borgohain (20030242021)\n3. Kshitija Darekar (20030242037)\n4. Upamanyu Mukherjee (20030242070)\n\n**Use Cases**\n\n1. Deep Neural Network. (3 Models)\n2. Binary Classification. (4 Models)\n3. Multi Class Classification. (3 Models)\n4. Image Generation by GAN.","b884daa9":"*Read the images from the respective directories* <br>\n\n*We shall use ImageDataGenerator method*","4ce0eec2":"### Model 4","63e1b00b":"# Use Case 3","dd6487b0":"*Read the images from the respective directories* <br>\n\n*We shall use ImageDataGenerator method*","29115eec":"*Training the model*","1c6f425a":"### Model 2","40b1724d":"#### Results\n\n1. Model 1:\n        * Layers: 64,128,1\n        * Epochs: 30\n        * MAE: 6626139.5\n        * K-fold: 6625904\n        \n2. Model 2:\n        * Layers: 64,128,256,512,1\n        * Epochs: 60\n        * MAE: 6584476.5\n        * K-fold: 756559.52. \n        \n3. Model 3:\n        * Layers: 64,128,256,512,1024,2048,1\n        * Epochs: 100\n        * MAE: 15797561\n        * K-fold: 16942044\n        \n#### Conclusion\n\nAs we train the model for higher epochs, and add more dense layers the model score increases.","db5639a1":"### Discriminator","c8e54b05":"*Read the images from the respective directories <br>\nWe shall use ImageDataGenerator method*","5f4a314e":"We utilized GPU Accelerator for building and testing our models.<br>\n\n1. Model 1, No advanced features\n    * Accuracy: 0.9650\n    * Loss: 0.1036\n    * Average Train Time: 2.3s; 45.15 ms\/step\n<br>\n2. Model 2, Only L2 weight regularization\n    * Accuracy: 0.9575\n    * Loss: 0.1704\n    * Average Train Time: 2.05s; 41.5ms\/step\n<br>\n3. Model 3, Only batch normalization\n    * Accuracy: 0.9500\n    * Loss: 0.2681\n    * Average Train Time: 2.05s; 43.3ms\/step\n<br>\n4. Model 4, both L2 weight regularization and batch normalization\n    * Accuracy: 0.9675\n    * Loss: 0.2098\n    * Average Train Time: 2.05s; 44.8ms\/step","da04a1d2":"*Training the model*","8ab3e87c":"---\n\n# Use Case 1","2b708fe8":"### Model 3","2454edc6":"*Read the images from the respective directories* <br>\n\n*We shall use ImageDataGenerator method*","ef6775fe":"### Image Generator","f2196d90":"### Model 1","297b394d":"### Generator","0b6b3f2b":"---","60e913e3":"*Training the model*","3230346b":"### TRAINING","d544b33f":"### Adverserial Model","60a2c49a":"### Model 1","fa737ce4":"### Model 2"}}