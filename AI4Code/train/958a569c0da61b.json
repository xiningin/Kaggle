{"cell_type":{"ccd938ff":"code","0660aa8e":"code","4c06427a":"code","e8e5c434":"code","64fe2c7d":"code","73a050ad":"code","d6a35192":"code","9f181241":"code","b49e5ae6":"code","b0fc0af1":"code","5ad78a63":"code","900fc4b9":"code","68ec2d1b":"markdown","2563ee6c":"markdown","7c1343cf":"markdown","06e50d77":"markdown","6c901255":"markdown"},"source":{"ccd938ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0660aa8e":"data = pd.read_csv(\"\/kaggle\/input\/league-of-legends-diamond-ranked-games-10-min\/high_diamond_ranked_10min.csv\")","4c06427a":"data.head()","e8e5c434":"X = data.drop([\"gameId\",\"blueWins\"],axis=1)\ny = data[\"blueWins\"]","64fe2c7d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n\nfrom sklearn.metrics import classification_report","73a050ad":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\npred1=lr.predict(X_test)\nprint(classification_report(y_test,pred1))","d6a35192":"from  sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(X_train,y_train)\npred2 = model.predict(X_test)\nprint(classification_report(y_test,pred2))","9f181241":"from sklearn.neighbors import KNeighborsClassifier\nknnscore=[]\nfor i,k in enumerate(range(1,40)):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    knn.fit(X_train,y_train)\n    \n    knnscore.append(knn.score(X_test,y_test))","b49e5ae6":"knn = KNeighborsClassifier(1+knnscore.index(np.max(knnscore)))\nknn.fit(X_train,y_train)\npred3 = knn.predict(X_test)\nprint(classification_report(y_test,pred3))","b0fc0af1":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\npred4 = dt.predict(X_test)\nprint(classification_report(y_test,pred4))","5ad78a63":"from sklearn.ensemble import RandomForestClassifier\nrfcscore = []\nfor i,k  in enumerate(range(100,300,20)):\n    rfc = RandomForestClassifier(n_estimators=k)\n    rfc.fit(X_train,y_train)\n    rfcscore.append(rfc.score(X_test,y_test))","900fc4b9":"rfc = RandomForestClassifier(n_estimators=(1+rfcscore.index(np.max(rfcscore))))\nrfc.fit(X_train,y_train)\npred5= rfc.predict(X_test)\nprint(classification_report(y_test,pred5))\n\n","68ec2d1b":"# TreeClassifier","2563ee6c":"# ForestClassifier","7c1343cf":"# SVC","06e50d77":"# LogisticRegression","6c901255":"# KNN"}}