{"cell_type":{"73732ad1":"code","58bf4141":"code","ef7d056e":"code","52340fca":"code","6faaeb65":"code","5f45cc07":"code","4b567491":"code","0486d6af":"code","f74281cd":"code","635e86f2":"code","9bae4896":"code","80d49469":"code","5c401d61":"code","f21c52ea":"code","83a2ff35":"code","b5b9c039":"code","1ef0999d":"code","5147b530":"code","14c359ef":"code","893a55ed":"code","c9648e7d":"code","428e554a":"code","0a77f823":"code","ab54d3f5":"code","4a098a3d":"code","f87b51f7":"code","d54e8dd3":"code","541a2315":"code","ce3774ba":"code","9f72a439":"code","86547b93":"code","a436ebdc":"code","892739e9":"code","2a6ae785":"code","d41c4730":"code","ed538380":"code","f647a21b":"code","b1dc6569":"code","775e7294":"code","821a87d8":"code","2cdc0907":"code","836552bb":"code","ca031582":"code","7f55aff2":"code","b2d6f63d":"markdown"},"source":{"73732ad1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58bf4141":"test_features = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntrain_features = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')\n","ef7d056e":"import matplotlib.pyplot as plt\n%matplotlib inline","52340fca":"train_features.shape","6faaeb65":"train_features.head()","5f45cc07":"train_features.sig_id.nunique()","4b567491":"train_features.cp_type.value_counts()","0486d6af":"train_features.cp_time.value_counts()","f74281cd":"train_features.cp_dose.value_counts()","635e86f2":"train_targets_scored.head()","9bae4896":"train_targets_scored.sum()[1:].sort_values()","80d49469":"train_features[:1]","5c401d61":"gs = train_features[:1][[col for col in train_features.columns if 'g-' in col]].values.reshape(-1, 1)","f21c52ea":"plt.plot(gs)","83a2ff35":"plt.plot(sorted(gs))","b5b9c039":"# atrain_features[:1][[col for col in train_features.columns if 'g-' in col]].","1ef0999d":"train_features['g-0'].plot(kind='hist')","5147b530":"train_features['c-0'].plot(kind='hist')","14c359ef":"train_features = pd.concat([train_features, pd.get_dummies(train_features['cp_time'], prefix='cp_time')], axis=1)\ntrain_features = pd.concat([train_features, pd.get_dummies(train_features['cp_dose'], prefix='cp_dose')], axis=1)\ntrain_features = pd.concat([train_features, pd.get_dummies(train_features['cp_type'], prefix='cp_type')], axis=1)\ntrain_features = train_features.drop(['cp_type', 'cp_time', 'cp_dose'], axis=1)","893a55ed":"import torch\nimport pandas as pd\nimport torch.nn as nn\n\nclass MoADataset:\n    def __init__(self, dataset, targets):\n        self.dataset = dataset\n        self.targets = targets\n\n    def __len__(self):\n        return self.dataset.shape[0]\n\n    def __getitem__(self, item):\n        return {\n            \"x\": torch.tensor(self.dataset[item, :], dtype=torch.float),\n            \"y\": torch.tensor(self.targets[item, :], dtype=torch.float),\n        }","c9648e7d":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(num_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.3),\n            nn.PReLU(),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.3),\n            nn.PReLU(),\n            nn.Linear(1024, num_targets),\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","428e554a":"!pip install pytorch-lightning","0a77f823":"import pytorch_lightning as pl","ab54d3f5":"from sklearn.model_selection import train_test_split","4a098a3d":"class MoADataModule(pl.LightningDataModule):\n    def __init__(self, hparams, data, targets):\n        super().__init__()\n        self.hparams = hparams\n        self.data = data\n        self.targets = targets\n\n    def prepare_data(self):\n        pass\n\n    def setup(self, stage=None):\n\n        train_data, valid_data, train_targets, valid_targets = train_test_split(self.data, self.targets,\n                                                                                test_size=0.1, random_state=42)\n        self.train_dataset = MoADataset(dataset=train_data.iloc[:, 1:].values,\n                                         targets=train_targets.iloc[:, 1:].values)\n        self.valid_dataset = MoADataset(dataset=valid_data.iloc[:, 1:].values,\n                                         targets=valid_targets.iloc[:, 1:].values)\n\n    def train_dataloader(self):\n        train_loader = torch.utils.data.DataLoader(\n            self.train_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=True,\n        )\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = torch.utils.data.DataLoader(\n            self.valid_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=False,\n        )\n\n        return valid_loader\n\n    def test_dataloader(self):\n        return None","f87b51f7":"class LitMoA(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(LitMoA, self).__init__()\n        self.hparams = hparams\n        self.model = model\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n    def forward(self, x):\n        return self.model(x)\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                               patience=3, threshold=0.00001, mode=\"min\", verbose=True)\n        return ([optimizer],\n                [{'scheduler': scheduler, 'interval': 'epoch', 'monitor': 'valid_loss'}])\n    \n    def training_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        \n        logs = {'train_loss': loss}\n        \n        return {'loss': loss, 'log': logs, 'progress_bar': logs}\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'train_loss': avg_loss}\n        return {'log': logs, 'progress_bar': logs}\n\n    def validation_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        \n        logs = {'valid_loss': loss}\n        \n        return {'loss': loss, 'log': logs, 'progress_bar': logs}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'valid_loss': avg_loss}\n        return {'log': logs, 'progress_bar': logs}","d54e8dd3":"trainer = pl.Trainer(gpus=1,\n                    max_epochs=5,\n                    weights_summary='full')","541a2315":"net = Model(879, 206)\nmodel = LitMoA(hparams={}, model=net)\ndm = MoADataModule(hparams={}, data=train_features, targets=train_targets_scored)","ce3774ba":"trainer.fit(model, dm)","9f72a439":"test_features = pd.concat([test_features, pd.get_dummies(test_features['cp_time'], prefix='cp_time')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_dose'], prefix='cp_dose')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_type'], prefix='cp_type')], axis=1)\ntest_features = test_features.drop(['cp_type', 'cp_time', 'cp_dose'], axis=1)","86547b93":"import torch\nimport pandas as pd\nimport torch.nn as nn\n\nclass TestMoADataset:\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __len__(self):\n        return self.dataset.shape[0]\n\n    def __getitem__(self, item):\n        return {\n            \"x\": torch.tensor(self.dataset[item, :], dtype=torch.float),\n        }","a436ebdc":"test_dataset = TestMoADataset(dataset=test_features.iloc[:, 1:].values)","892739e9":"test_loader = torch.utils.data.DataLoader(\n            test_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=False,\n        )\n","2a6ae785":"predictions = np.zeros((test_features.shape[0], 206))\ninference_model = model.model\ninference_model.eval()\nfor ind, batch in enumerate(test_loader):\n    p = torch.sigmoid(inference_model(batch['x'])).detach().cpu().numpy()\n    predictions[ind * 1024:(ind + 1) * 1024] = p","d41c4730":"predictions","ed538380":"test_features1 = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ns = pd.DataFrame({'sig_id': test_features1['sig_id'].values})","f647a21b":"s","b1dc6569":"for col in train_targets_scored.columns[1:].tolist():\n    s[col] = 0","775e7294":"s.loc[:, train_targets_scored.columns[1:]] = predictions","821a87d8":"s.head()","2cdc0907":"test_features1.loc[test_features1['cp_type'] =='ctl_vehicle', 'sig_id']","836552bb":"s.loc[s['sig_id'].isin(test_features1.loc[test_features1['cp_type'] =='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] = 0","ca031582":"s.to_csv('submission.csv', index=False)","7f55aff2":"torch.save(model.model.state_dict(), 'model.pt')","b2d6f63d":"## Model"}}