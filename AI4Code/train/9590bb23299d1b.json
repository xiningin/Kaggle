{"cell_type":{"dc5f0749":"code","16e196f0":"code","8c89acef":"code","8a2bbef2":"code","bdeab19f":"code","dfe6195b":"code","78a75030":"code","40df8bfb":"code","d8c74489":"code","8b0e72db":"code","01baef10":"code","57beb02b":"code","c6b65a3a":"code","b23632ab":"code","fd09d71c":"code","38a6cb4c":"code","42308c00":"code","5257701f":"code","e8377afd":"code","bcb6b56d":"code","e5cb1ca2":"markdown","eaf33743":"markdown","03a92cf6":"markdown","764fa461":"markdown","74cc5fbf":"markdown","f4cb207b":"markdown","3341d52b":"markdown","915d0616":"markdown","8e1956c0":"markdown"},"source":{"dc5f0749":"from __future__ import (\n    absolute_import,\n    division,\n    print_function,\n    unicode_literals\n)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom six.moves import urllib","16e196f0":"import tensorflow as tf","8c89acef":"from sklearn.model_selection import train_test_split","8a2bbef2":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\").drop(\"Id\", axis=1)\ndf","bdeab19f":"df.hist()","dfe6195b":"df.Species.value_counts().plot(kind=\"barh\")","78a75030":"y = df.pop(\"Species\")","40df8bfb":"COLUMNS = list(df.keys())\nSPECIES = list(y.unique())","d8c74489":"SPECIES","8b0e72db":"train, test, y_train, y_test = train_test_split(df, y, train_size=0.7, test_size=0.3)","01baef10":"train.shape","57beb02b":"test.shape","c6b65a3a":"sp_encoding = {}\n\nfor (i, v) in enumerate(SPECIES):\n    sp_encoding[v] = i\n    \ny_train.replace(sp_encoding, inplace=True)\ny_test.replace(sp_encoding, inplace=True)","b23632ab":"def input_fn(features, labels, training=True, batch_size=256):\n    ds = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n    if training:\n        ds = ds.shuffle(1000).repeat()\n    return ds.batch(batch_size)","fd09d71c":"feature_columns = []\n\nfor column in COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(column))\n\nfeature_columns","38a6cb4c":"classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[30, 10], n_classes=len(SPECIES))","42308c00":"classifier.train(input_fn=lambda: input_fn(train, y_train, training=True), steps=5000)","5257701f":"result = classifier.evaluate(input_fn=lambda: input_fn(test, y_test, training=False))\nresult","e8377afd":"rev_sp_encoding= {}\n\nfor (i, v) in enumerate(SPECIES):\n    rev_sp_encoding[i] = v\n    \ny_test.replace(rev_sp_encoding, inplace=True)\n    \npd.concat([test.head(), y_test.head()], axis=1)","bcb6b56d":"def predict_fn(features, batch_size=256):\n    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n\npredictions = classifier.predict(input_fn=lambda: predict_fn(test.head()))\n\nfor pred_dict in predictions:\n    class_id = pred_dict['class_ids'][0]\n    probability = pred_dict['probabilities'][class_id]\n    print(\"Predicted: {} (Probability: {:.3f}%)\".format(SPECIES[class_id], 100 * probability))","e5cb1ca2":"## Training the Model","eaf33743":"## Input Function","03a92cf6":"## Import Dependencies","764fa461":"## Generate and Validate Predictions","74cc5fbf":"## Feature Columns","f4cb207b":"## Evaluating the Model","3341d52b":"## Building the Model","915d0616":"# Supervised Classification Algorithm","8e1956c0":"## Data"}}