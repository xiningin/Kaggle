{"cell_type":{"014a7eb5":"code","154afaac":"code","de7a96c2":"code","cd05e4c2":"code","11df0652":"code","e6f29358":"code","61220414":"code","e79d186f":"code","5d572303":"code","e1375114":"code","d6a94b2b":"code","a828ee71":"markdown","e7860288":"markdown","e6da5046":"markdown","0676f628":"markdown","99bc129d":"markdown","efdff068":"markdown"},"source":{"014a7eb5":"import csv\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport scipy","154afaac":"#Make a function to transform the .CSV to np.array\ndef get_data(filename):\n    \n    with open(filename) as training_file:\n        csv_reader = csv.reader(training_file, delimiter=',')\n        images_array = [] \n        labels_array = []\n        x = \"=\"\n        Y = \" \"\n        len=0\n        len = sum(1 for row in training_file) #obtain the len of file\n    with open(filename) as training_file:\n        csv_reader = csv.reader(training_file, delimiter=',')\n        for i, row in enumerate(csv_reader):\n            if i == 0:\n              #Ignore Headers\n              print(training_file)\n            else:\n                if i % 5000 == 0 or i == (len-1): # progress bar\n                    print(str(i)+\"\/\"+str(len-1))\n                    print(\"[\"+str(round(i\/1000)*x)+str(round(len\/1000-i\/1000)*Y)+\"]\")\n                    \n                labels_array.append(row[0]) #append labels\n                images_line = row[1:785]    #extract the pixels\n                image_line_split = np.array_split(images_line, 28) # transform to 28x28\n                images_array.append(image_line_split) # append the image \n        images = np.array(images_array).astype('float') \n        labels = np.array(labels_array).astype('float')\n    return images, labels\n\ndef get_test_data(filename):\n    with open(filename) as test_file:\n        csv_reader = csv.reader(test_file, delimiter=',')\n        images_array = []\n        x = \"=\"\n        Y = \" \"\n        len=0\n        len = sum(1 for row in test_file)\n    with open(filename) as test_file:\n        csv_reader = csv.reader(test_file, delimiter=',')\n        for i, row in enumerate(csv_reader):\n            if i == 0:\n              #Ignore Headers\n              print(test_file)\n            else:\n                if i % 5000 == 0 or i == (len-1):\n                    print(str(i)+\"\/\"+str(len-1))\n                    print(\"[\"+str(round(i\/1000)*x)+str(round(len\/1000-i\/1000)*Y)+\"]\")\n                #labels_array.append(row[0])\n                images_line = row[:784]\n                image_line_split = np.array_split(images_line, 28)\n                images_array.append(image_line_split)\n        images = np.array(images_array).astype('float')\n    return images\n\ntraining_images, training_labels = get_data('..\/input\/digit-recognizer\/train.csv')\ntesting_images = get_test_data('..\/input\/digit-recognizer\/test.csv')\n\n#get the shape of sets\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(testing_images.shape)\n","de7a96c2":"np.set_printoptions(linewidth=200) #Make sure that the tool bars are hidden \nprint(testing_images[90])","cd05e4c2":"training_images = np.expand_dims(training_images, axis=3)\ntesting_images = np.expand_dims(testing_images, axis=3)\ntesting_images = testing_images\/255.0  # normalize the data \n\n# Create an ImageDataGenerator and do Image Augmentation to improve the train dataset\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 \/ 255.00,   #Normalize the data \n    rotation_range=15,      #Image may be rotate\n    width_shift_range=0.1,  #Image may be offset\n    height_shift_range=0.1, #Image may be offset\n    #zoom_range=0.1,       #The image mantain the dimensions\n    #horizontal_flip=True, #The image is not flip\n    #fill_mode='nearest'   #\n)\n    \n# Keep These\nprint(training_images.shape)","11df0652":"# Define the model\n# you can see the efect of the layers in the end of notebook\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28,1)),\n    tf.keras.layers.MaxPooling2D(2, 2),  \n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n\n# Compile Model. \nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.999):\n            print(\"\\nReached 100% accuracy so cancelling training!\")\n            self.model.stop_training = True\ncallbacks = myCallback()\n\n# Train the Model\nhistory = model.fit(train_datagen.flow(training_images, training_labels, batch_size=32),\n                   steps_per_epoch=len(training_images) \/ 32,\n                   epochs=400,\n                   callbacks=[callbacks],\n                   )\n","e6f29358":"model.evaluate(training_images, training_labels)\n# Plot the chart for accuracy and loss\nimport matplotlib.pyplot as plt\nacc=history.history['accuracy']\nepochs = range(len(acc))\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()","61220414":"predictions = model.predict(testing_images) # make predictions\nprint(predictions[:3]) #show few predictions","e79d186f":"import io\npredictions_csv = io.open('Predictions.csv', 'w', encoding='utf-8') # create file\n\npredictions_csv.write('ImageId,Label' +'\\n') # write the headers\nfor i,pre in enumerate(predictions):\n    predictions_csv.write(str(i+1) + ',' + str(np.where(predictions[i] == predictions[i].max())[0][0])+'\\n')\npredictions_csv.close()","5d572303":"# Reload the testing images to visualize them\ntesting_images_v = get_test_data('..\/input\/digit-recognizer\/test.csv')","e1375114":"x  = 3  # Analize any image\nnp.set_printoptions(linewidth=200)\n\nfor x in range(0,100,20):\n    print(testing_images_v[x])\n    print(predictions[x])\n    print(\"The predict label is: \",np.where(predictions[x] == predictions[x].max())[0][0])","d6a94b2b":"import numpy as np\nimport random\nfrom   tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[:]]\n\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\n# Let's prepare a random input image of a cat or dog from the training set.\n\n\nimg = testing_images_v[10]  # this is a PIL image\n\nx   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\nx   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1\/255\nx \/= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n# -----------------------------------------------------------------------\n# Now let's display our representations\n# -----------------------------------------------------------------------\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv \/ maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n        x  = feature_map[0, :, :, i]\n        x -= x.mean()\n        x \/= x.std ()\n        x *=  64\n        x += 128\n        x  = np.clip(x, 0, 255).astype('uint8')\n        display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. \/ n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) ","a828ee71":"We can see that the predictions give the percentage for each label. With numpy we can obtain the max value and determine the most likely label. ","e7860288":"**Extract predictions using numpy**","e6da5046":"## Handwriting digit recognizer with Convolutional neural networks and augmentation","0676f628":"Showing an example of the data","99bc129d":"For more information of the layers, and the algorithms used visit the Keras documentation. ","efdff068":"The data for this notebook is available at: https:\/\/www.kaggle.com\/c\/digit-recognizer\/data\n\n"}}