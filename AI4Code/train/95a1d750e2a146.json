{"cell_type":{"2453ca3d":"code","9b314b58":"code","55c8c3e6":"code","6b53f0eb":"code","acab36af":"code","7acb3bee":"code","758307f9":"code","843ba557":"code","af712f8a":"code","fc050360":"code","c8831e78":"code","a0c8c709":"code","8c683d26":"markdown","de6efced":"markdown","12e6259f":"markdown","d4166fa5":"markdown","44708931":"markdown","6c8757e7":"markdown","86f0cf4d":"markdown","b96ef52a":"markdown","c6c8ed4a":"markdown","b4415b48":"markdown","0d2b2485":"markdown"},"source":{"2453ca3d":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy.special import expit, logit\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error, median_absolute_error\nfrom sklearn.model_selection import RepeatedKFold\n\nnp.random.seed(1)\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', None)\nsns.set_style('whitegrid')","9b314b58":"%%javascript\n$.getScript('https:\/\/kmahelona.github.io\/ipython_notebook_goodies\/ipython_notebook_toc.js')","55c8c3e6":"# import data\ndf = pd.read_pickle('..\/input\/nycschools2017\/schools2017.pkl')\nprint(df.shape[0], \"schools\")\n\n# drop schools with missing test data\ndf = df[df.loc[:, 'Mean Scale Score - ELA':'% Level 4 - Math'].notnull().all(axis=1)]\nprint(df.shape[0], \"schools after dropping missing test data\")\n\n# drop schools with missing attendance data\ndf = df[df['Percent of Students Chronically Absent'].notnull()]\nprint(df.shape[0], \"schools after dropping missing attendance data\")\n\n# schools with 0-5 SHSAT testers have this value set to NaN\napplicantsok = df['# SHSAT Testers'].notnull()\n\n# show head of data\nf2_columns = ['Latitude', 'Longitude', 'Economic Need Index',\n              'Mean Scale Score - ELA', 'Mean Scale Score - Math']\npct_columns = [c for c in df.columns if c.startswith('Percent')]\npct_columns += [c for c in df.columns if c.startswith('%')]\ndf.head().style. \\\n    format('{:.2f}', subset=f2_columns). \\\n    format('{:.1%}', subset=pct_columns)","6b53f0eb":"# data\nin_columns = [\n    'Charter School?',\n    'Percent Asian',\n    'Percent Black',\n    'Percent Hispanic',\n    'Percent Other',\n    'Percent English Language Learners',\n    'Percent Students with Disabilities',\n    'Economic Need Index',\n    'Percent of Students Chronically Absent',\n    \n    'Mean Scale Score - ELA',\n    '% Level 2 - ELA',\n    '% Level 3 - ELA',\n    '% Level 4 - ELA',\n    'Mean Scale Score - Math',\n    '% Level 2 - Math',\n    '% Level 3 - Math',\n    '% Level 4 - Math', \n]\ninputs = df[applicantsok][in_columns]\noutputs = logit(df[applicantsok]['% SHSAT Testers'])  # the logit will be explained later\n\n\n# cross-validation\ncv_results = []\nn_splits = 10\nn_repeats = 20\nfor n_components in range(1, inputs.shape[1] + 1):\n    mae_scores = []\n    mse_scores = []\n    \n    x = PCA(n_components).fit_transform(inputs)\n    x = pd.DataFrame(x, index=inputs.index, columns=[\"PC{}\".format(i) for i in range(1, n_components + 1)])\n    x['Constant'] = 1\n    y = outputs.copy()\n    \n\n    cv = RepeatedKFold(n_splits, n_repeats, random_state=1)    \n    for train, test in cv.split(x):\n        x_train = x.iloc[train]\n        x_test = x.iloc[test]\n        y_train = y.iloc[train]\n        y_test = y.iloc[test]\n        \n        model = sm.RLM(y_train, x_train, M=sm.robust.norms.HuberT())\n        results = model.fit()\n        predictions = model.predict(results.params, exog=x_test)\n        mae = median_absolute_error(y_test, predictions)\n        mse = mean_squared_error(y_test, predictions)\n        mae_scores.append(mae)\n        mse_scores.append(mse)\n        \n    mae_scores = np.array(mae_scores).reshape(n_repeats, n_splits).mean(axis=1)  # mean of each repeat\n    mse_scores = np.array(mse_scores).reshape(n_repeats, n_splits).mean(axis=1)  # mean of each repeat\n        \n    mae_mean = np.mean(mae_scores)\n    mae_std = np.std(mae_scores)\n    mse_mean = np.mean(mse_scores)\n    mse_std = np.std(mse_scores)\n    \n    cv_result = (n_components, mae_mean, mse_mean, mae_std, mse_std)\n    cv_results.append(cv_result)\n    \ndf_columns = ['n_components', 'mae__mean', 'mse__mean', 'mae__std', 'mse__std']\ncv_results_df = pd.DataFrame(cv_results, columns=df_columns)\ncv_results_df","acab36af":"# visualize results\n\ncvdf = cv_results_df  # code sugar\n\nplt.figure()\nplt.errorbar(cvdf.n_components, cvdf.mae__mean, cvdf.mae__std, marker='o', label='Median Absolute Error')\nplt.legend()\n\nplt.figure()\nplt.errorbar(cvdf.n_components, cvdf.mse__mean, cvdf.mse__std, marker='o', label='Mean Squared Error')\nplt.legend();","7acb3bee":"base_df = df[[  # explanatory variables\n    'Charter School?',\n    'Percent Asian',\n    'Percent Black',\n    'Percent Hispanic',\n    'Percent Other',\n    'Percent English Language Learners',\n    'Percent Students with Disabilities',\n    'Economic Need Index',\n    'Percent of Students Chronically Absent',\n    \n    'Mean Scale Score - ELA',\n    '% Level 2 - ELA',\n    '% Level 3 - ELA',\n    '% Level 4 - ELA',\n    'Mean Scale Score - Math',\n    '% Level 2 - Math',\n    '% Level 3 - Math',\n    '% Level 4 - Math',\n]]\n\n# transform the variables (apply the PCA)\nn_components = 8\npca = PCA(n_components)\ntransformed = pca.fit_transform(base_df)\ntransformed = pd.DataFrame(transformed, index=base_df.index, columns=[\"PC{}\".format(i+1) for i in range(n_components)])\n\n# add a constant column (needed for our model with statsmodels)\ninputs = transformed\ninputs.insert(0, 'Constant', 1.0)\ninputs.head()","758307f9":"# prepare inputs and outputs\ninputs_fit = inputs[applicantsok]\noutputs_fit = logit(df['% SHSAT Testers'][applicantsok])\ninputs_predict = inputs\n\n# fit the model\nmodel = sm.RLM(outputs_fit, inputs_fit, M=sm.robust.norms.HuberT())\nresults = model.fit()\n\n# make predictions\npredictions = model.predict(results.params, exog=inputs_predict)\npredictions = pd.Series(predictions, index=inputs_predict.index)\npredictions = expit(predictions)  # expit is the inverse of the logit\npredictions.name = 'Expected % of SHSAT Testers'","843ba557":"results.summary()","af712f8a":"_predictions = logit(predictions[applicantsok])  # values are in logit units\n_actual = logit(df['% SHSAT Testers'][applicantsok])  # values are in logit units\n\nxs = _predictions\nys = _actual - _predictions  # residual\n\nplt.figure(figsize=(12, 8))\nplt.plot(xs, ys, '.')\nplt.axhline(0.0, linestyle='--', color='gray')\nplt.xlim(-2.5, 2.5)\nplt.ylim(-3.5, 3.5)\nplt.title(\"Residual Plot (logit units)\")\nplt.xlabel(\"Fitted Values\")\nplt.ylabel(\"Residuals\");","fc050360":"mae = median_absolute_error(_actual, _predictions)\nmse = mean_squared_error(_actual, _predictions)\n\nprint(\"Median Absolute Error:\", mae)\nprint(\"Mean Squared Error:\", mse)","c8831e78":"xs = predictions[applicantsok]\nys = df['% SHSAT Testers'][applicantsok]\n\nfig, ax = plt.subplots(figsize=(12, 8))\nax.scatter(xs, ys, s=5)\nax.plot([0, 1], [0, 1], '--', c='gray')\nax.xaxis.set_major_formatter(plt.FuncFormatter(\"{:.0%}\".format))\nax.yaxis.set_major_formatter(plt.FuncFormatter(\"{:.0%}\".format))\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.set_title(\"Regression Results\")\nax.set_xlabel(\"Estimated Percentage of SHSAT Applicants\")\nax.set_ylabel(\"Actual Percentage of SHSAT Applicants\");","a0c8c709":"df_export = predictions.to_frame()\ndf_export.to_csv(\"expected_testers.csv\")\ndf_export.head()","8c683d26":"# Cross-validation\n\nTo choose the best amount of features, we will use cross-validation. It is a technique for splitting the dataset into training and test sets multiple times, making use of the data in an efficient way.\n\nThe cross-validation method used is a [repeated k-fold][1]. Explaining it is out of the scope of this kernel, but, let's just say it is one of the most recommended methods. It requires a lot of iterations, but, since our dataset is not big (comparing to today's \"big data\"), this is no problem.\n\nWe used the parameters `n_splits=10` and `n_repeats=20`.\n\n[1]: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold","de6efced":"<h1 id=\"tocheading\">Table of Contents<\/h1>\n<div id=\"toc\"><\/div>","12e6259f":"# Principal Component Analysis\n\nWe expect our data to have a lot of collinearity. That is, we expect variables to be very related to one another. This might cause problems when fitting a model.\n\nTo alleviate this problem, we use a technique called Principal Component Analysis (abbreviated PCA). This technique reduces the amount of features to an arbitrary number (that we can specify). The features generated are those that can best explain the original variables, making it a really nice approach.","d4166fa5":"# Fitting the model\n\nWe will use a very simple model. There are two gists, though:\n\n1. We are using it to *measure the application gap* in each school\n\n   This may seem not relevant to the model choice, but it is very, very important.\n\n   Say, of these two lines, which one do you think works best when predicting the gap between what is expected and what really occured?\n\n   ![](https:\/\/i.imgur.com\/DW4Rhcq.png)\n   ![](https:\/\/i.imgur.com\/MfDYwnP.png)\n\n  I'd say the second one, as it gives a nicer representation to points that are close to expected, and, predicts a big gap for points that are surely off.\n\n  The first line was generated using a standard regression and the second one was generated using a robust regression (we say robust because it is *robust to outliers*). The model that I'm gonna use is a robust one.\n\n2. The outcomes we are trying to predict are *probabilities*\n\n   Okay, they are actually the percentage of applicants at each school. But, can't we assume that this is the probability of each student at a certain school applying for the SHSAT? Although being a simplification, this is what we are gonna work upon. Being a model to predict probabilities, logistic regression is usually a better choice than linear regression. So, we use logistic regression<sup>1<\/sup>.\n   \n---\n\nIn the end, the model we are gonna is a *robust logistic regression*<sup>2<\/sup>. In the next cells I will fit it, predict with it and display some results.\n\n<sub>\n    1: I know, my logic is a little flawed. I will try improving on this area later.<br>\n    2: Actually, a robust linear regression with logits as outputs (transforming the model into a logistic regression)\n<\/sub>","44708931":"# Measuring the Applicants Gap in 2017\n\nLet's do something really simple, but in a really effective manner. That thing is: measuring the applicants gaps in 2017.\n\n![image of actual amount of applicants vs. expected amont of applicants][1]\n\nEach year, 8th graders from all over New York City take a test called SHSAT to see who will get access to the famous Specialized High Schools (SPHS). These Specialized High Schools are schools that receive great attention and provide a estimulating environment for students who have the desire to learn.\n\nProblem is, students that receive offers from SPHS are usually from a very specific demographic. Usually white or asian guys, mostly from the upper class, and from very small number of schools. This demographic characteristics are tightly linked to academic performance<sup><a href=\"https:\/\/steinhardt.nyu.edu\/scmsAdmin\/media\/users\/sg158\/PDFs\/Pathways_to_elite_education\/WorkingPaper_PathwaystoAnEliteEducation.pdf\">1<\/a><\/sup>, showing deeply ingrained questions that cannot be solved in a simple manner.\n\nWhat we can do, however, is target certain schools. PASSNYC is associated with a lot of organizations that provides services such as:\n\n- Test preparation\n- Afterschool activities\n- Mentoring\n- Community and student groups\n- Etc\n\nBut, what schools to target? Simple, we choose those with the biggest gap between the actual number of applicants and the number of applicants that would be expected given the school characteristics.\n\n... \n\nOkay, it's not as simple as this. But, what we do here can provide invaluable information in the process of choosing which schools to intervene. This kernel is aimed at providing a simple yet effective model with which the gap can be estimated.\n\n[1]: https:\/\/i.imgur.com\/W4gYk7M.png","6c8757e7":"The low `P>|z|` values indicates that the model is really good, the residual plot indicates a healthy fit and the model scores are what we expected, given the cross-validation results.\n\nBelow I make a plot for the less statistic-oriented folks. It compares the percentage of students that were expected to take SHSAT to the percentage of students that actually took SHSAT<sup>1<\/sup>.\n\n<sub>1: Schools from 0 to 5 test takers were not included.<\/sub>","86f0cf4d":"And it's done.","b96ef52a":"# Thanks\/Finishing remarks\n\nI'd like to thank everyone that took part in this challenge, know that every little thing that you did gave ideas and inspiration that kept me going. I'd like to thank Chris Crawford, that put this thing to work, and all the people at PASSNYC that are working together towards a great objective (especially those who took part in this competition). Also, thanks to my friend Zin, who helped me a lot, and to my parents, who had the great ear to listen to everything I say.\n\nI know this is past the deadline. If the modifications made are not considered valid, you can use the kernel versions as of August 7th (I was so rushed up).\n\nHere are my other kernels for this competition:\n\n- [Measuring the Applicants Gap (dropped schools)][1]: Same steps as this kernel, but for 14 schools which have some values missing\n- [Meaning\/Usage of Applicants Gap][2]: A down to earth explanation of what the gap actually means\n- [Gaps along the years][3]: Predicting the gaps for 2015 and 2016 and measuring their distance\n- [Objective\/Strategy formulation][4]: A view of the PASSNYC challenge as a whole\n\nAnd the whole project, on github:\n\n- https:\/\/github.com\/araraonline\/kag-passnyc\n\nCya!\n\n[1]: https:\/\/www.kaggle.com\/araraonline\/measuring-the-applicants-gap-dropped-schools\n[2]: https:\/\/www.kaggle.com\/araraonline\/meaning-usage-of-applicants-gap\n[3]: https:\/\/www.kaggle.com\/araraonline\/gaps-along-the-years\n[4]: https:\/\/www.kaggle.com\/araraonline\/objective-strategy-formulation","c6c8ed4a":"Personally, I believe this is a good fit and everyone on Kaggle should use it. Kidding! I mean, it might probably be of good use to PASSNYC. :)\n\nBelow I will export the predicted probabilities to a nicer format.","b4415b48":"# Little glimpse at the data\n\nThe crucial information for us is the amount of SHSAT applicants from each school. It can be found [here][1], and only includes students from 2017.\n\nThen, we assembled lots of data related to the students and the schools they attend. Information includes:\n\n- Percentage of each ethnicity in each school\n- Percentage of students with disabilities in each school\n- The Economic Need Index of each school (indicates the poverty of the students)\n- The distribution of grades for each school at the NYS Common Core tests<sup>1<\/sup>\n- Some other things\n\nBelow, you can see what I'm talking about more clearly.\n\n<sub>1: The grades a student can get are 1, 2, 3 or 4. We have the percentage of students in each grade and also the mean scale score of each school. The mean scale score of each school has been standardized, for an easier interpretation.<\/sub>\n\n[1]: https:\/\/data.cityofnewyork.us\/Education\/2017-2018-SHSAT-Admissions-Test-Offers-By-Sending-\/vsgi-eeb5\/","0d2b2485":"To choose the best number of features, we use both the Median Absolute Error and the Mean Squared Error. The first metric indicates how well the model is fitting overall, ignoring the weight of outliers<sup>1<\/sup>. The second metric, in contrast, is more sensitive to outliers, giving bigger importance to bigger errors.\n\nBased on the plots, we can see that 8 principal components is a good choice. It has the lowest Median Absolute Error and still keeps the Mean Squared Error at control.\n\nThis is gonna be the value used.\n\n<sub>1: A better explanation of how we should treat outliers is gonna be made in the modeling section<\/sub>"}}