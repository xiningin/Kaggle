{"cell_type":{"983e6527":"code","eca692bd":"code","857cebed":"code","e6fdbcfb":"code","595c0345":"code","f49ce1f7":"code","2e2a27c5":"code","d1242d32":"code","2ef28d8c":"code","7c041045":"code","80335ce5":"code","b9eefdb3":"code","2258cb21":"code","d504bd7e":"code","439a24d0":"code","1fadbf4e":"code","7ccdb1a2":"code","2e1339d4":"code","05baaa6e":"code","5ee6415a":"code","7af83431":"code","60d11b7c":"code","333aa81e":"code","27b9a440":"code","bb3acc80":"code","124ca2d0":"code","9bb2a452":"code","64dde577":"code","1895519b":"code","0c239c34":"code","3ea55c9d":"code","db174175":"code","4758f938":"code","9d5416f0":"code","139ebe8d":"code","97986c47":"code","60048be7":"code","e2ef1b29":"code","34622fb0":"code","8d37c17b":"code","bed7e610":"code","c1c13374":"code","6fbbfda9":"code","d8183f7d":"code","4dacb491":"code","b25daa89":"code","7df2fe57":"code","11112a69":"code","c5a0a403":"code","b987b9df":"code","50c44f72":"code","29e3052e":"code","cbea937e":"code","93e9e1fd":"code","e4c4adee":"code","5b074e41":"markdown","6ac2bdb3":"markdown","58aafc26":"markdown","c175e19c":"markdown","17e803cd":"markdown","d39c2887":"markdown","9ffe6712":"markdown","5e32911f":"markdown","dfc36db9":"markdown","bb5c83d7":"markdown"},"source":{"983e6527":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eca692bd":"sample_submission = pd.read_csv('..\/input\/mengary-revenue-prediction\/sampleSolution.csv')\ntrain = pd.read_csv('..\/input\/mengary-revenue-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/mengary-revenue-prediction\/test.csv')\n","857cebed":"train.head()","e6fdbcfb":"train['delivery date'] = pd.to_datetime(train['delivery date'])\ntrain['placement date'] = pd.to_datetime(train['placement date'])\ntrain['days'] = train['delivery date'] - train['placement date'] \ntrain['days'] = train['days'].dt.days.astype('int16')","595c0345":"c1 = (train['delivery date'] > train['placement date']) \n\nc1.value_counts()","f49ce1f7":"c2 = (test['delivery date'] != test['placement date'])   \n\nc2.value_counts()","2e2a27c5":"y_df = train['profit']\ntrain = train.drop(['delivery date','placement date','profit'],axis = 1)","d1242d32":"test['delivery date'] = pd.to_datetime(test['delivery date'])\ntest['placement date'] = pd.to_datetime(test['placement date'])\ntest['days'] = test['delivery date'] - test['placement date']\ntest['days'] = test['days'].dt.days.astype('int16')","2ef28d8c":"\ntest = test.drop(['delivery date','placement date'],axis = 1)","7c041045":"train","80335ce5":"test","b9eefdb3":"train['departure city'].value_counts()","2258cb21":"train['segment'].value_counts()","d504bd7e":"segment =  pd.get_dummies(train['segment'], drop_first= True)\n","439a24d0":"train['delivery type'].value_counts()","1fadbf4e":"delivery = pd.get_dummies(train['delivery type'],drop_first = True)","7ccdb1a2":"train['location'].value_counts()","2e1339d4":"location = pd.get_dummies(train['location'],drop_first = True)","05baaa6e":"train['class'].value_counts()","5ee6415a":"clas = pd.get_dummies(train['class'],drop_first = True)","7af83431":"train = train.drop(['location','class','segment','delivery type'],axis = 1)\ntrain = pd.concat([train,location,clas,segment,delivery], axis = 1)","60d11b7c":"train","333aa81e":"loc_t =  pd.get_dummies(test['location'], drop_first= True)\nclas_t =  pd.get_dummies(test['class'], drop_first= True)\nsegment_t =  pd.get_dummies(test['segment'], drop_first= True)\ndel_t =  pd.get_dummies(test['delivery type'], drop_first= True)\n\ntest = test.drop(['location','class','segment','delivery type'],axis = 1)\ntest = pd.concat([test,loc_t,clas_t,segment_t,del_t], axis = 1)\n","27b9a440":"test","bb3acc80":"city = pd.concat([train['departure city'],test['departure city']],axis = 0)\nsub = pd.concat([train['sub-class'],test['sub-class']],axis = 0)\nstate = pd.concat([train['departure state'],test['departure state']],axis = 0)\ncity = city.unique()\nsub = sub.unique()\nstate = state.unique()","124ca2d0":"print(str(len(city)) + \" \" + str(len(sub)) + \" \"+ str(len(state)))","9bb2a452":"test","64dde577":"X = train.iloc[:,1:].values\ny = y_df.iloc[:].values\nX_final = test.iloc[:,1:].values","1895519b":"len(state)","0c239c34":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ncity2 = le.fit_transform(city)\nsub2 = le.fit_transform(sub)\nstate2 = le.fit_transform(state)","3ea55c9d":"for i in range(6700):\n    for j in range(531):\n        if X[i,0] == city[j]:\n            X[i,0] = city2[j]\n        \nfor i in range(3294):\n    for j in range(531):\n        if X_final[i,0] == city[j]:\n            X_final[i,0] = city2[j]    ","db174175":"for i in range(6700):\n    for j in range(17):\n        if X[i,4] == sub[j]:\n            X[i,4] = sub2[j]\n        \nfor i in range(3294):\n    for j in range(17):\n        if X_final[i,4] == sub[j]:\n            X_final[i,4] = sub2[j] ","4758f938":"for i in range(6700):\n    for j in range(49):\n        if X[i,7] == state[j]:\n            X[i,7] = state2[j]\n        \nfor i in range(3294):\n    for j in range(49):\n        if X_final[i,7] == state[j]:\n            X_final[i,7] = state2[j] ","9d5416f0":"X","139ebe8d":"X_final","97986c47":"\n\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\nX_final = sc.transform(X_final)\n\n\n\n\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nmmsc = MinMaxScaler() \nX = mmsc.fit_transform(X) \nX_final = mmsc.transform(X_final) \n\n\n\n\nfrom sklearn.preprocessing import QuantileTransformer\nqt = QuantileTransformer()\nX = qt.fit_transform(X)\nX_final = qt.transform(X_final)\n\n\nfrom sklearn.preprocessing import RobustScaler\nrs = RobustScaler()\nX = rs.fit_transform(X)\nX_final = rs.transform(X_final)\n\n\n","60048be7":"(X[:])","e2ef1b29":"y","34622fb0":"# test classification dataset\nfrom sklearn.datasets import make_classification\n# summarize the dataset\nprint(X.shape, y.shape)\n\n\n","8d37c17b":"X","bed7e610":"# random forest for feature importance on a regression problem\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib import pyplot\n# define the model\nmodel = RandomForestRegressor()\n# fit the model\nmodel.fit(X, y)\n# get importance\nimportance = model.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","c1c13374":"from sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(X,y)\nprint(selection.feature_importances_)","6fbbfda9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","d8183f7d":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor()\nreg_rf.fit(X_train, y_train)","4dacb491":"y_pred = reg_rf.predict(X_test)","b25daa89":"q = reg_rf.score(X_train, y_train)\nprint(q)","7df2fe57":"reg_rf.score(X_test, y_test)","11112a69":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.distplot(y_test-y_pred)\nplt.show()","c5a0a403":"plt.scatter(y_test, y_pred, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","b987b9df":"test.shape","50c44f72":"y_prediction = reg_rf.predict(X_final)","29e3052e":"y_pred_df = pd.DataFrame(y_prediction, columns =['profit'])","cbea937e":"y_pred_df.shape","93e9e1fd":"sample_submission['profit'] = y_pred_df['profit']","e4c4adee":"sample_submission.to_csv('Solution.csv', index=False)","5b074e41":"# checking if all dates are same or not","6ac2bdb3":"# Playing with Hyper-parameters","58aafc26":"extra tree regressor","c175e19c":"# FINAL SUBMISSION","17e803cd":"# Manging Categorical instances","d39c2887":"# data pre-processing ... Feature Selection","9ffe6712":"# removing Predict case from Training data","5e32911f":"SAME FOR TEST DATA SET","dfc36db9":"# TRAINING THE MODEL","bb5c83d7":"# Reading Files"}}