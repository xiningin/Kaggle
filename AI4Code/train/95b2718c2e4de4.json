{"cell_type":{"aa9099ad":"code","2f31fae2":"code","343b5e5b":"code","7a5e3ab0":"code","ef6a48ed":"code","5c34175d":"code","2446a288":"code","00289922":"code","64b94b67":"code","fbe0c569":"code","83c13a22":"code","7b49b3d8":"code","7a832933":"markdown","b5ee5f21":"markdown","56ed30f8":"markdown"},"source":{"aa9099ad":"from IPython.display import Image\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras.models import Model","2f31fae2":"Image(\"..\/input\/simpleneuralnetworkarchitecture\/simple_neural_network_architecture_modifying_residual.png\")","343b5e5b":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\ntargets = pd.get_dummies(train['target'])","7a5e3ab0":"cce = tf.keras.losses.CategoricalCrossentropy()\ndef custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss","ef6a48ed":"es = tf.keras.callbacks.EarlyStopping(\n    monitor='val_custom_metric',\n    min_delta=1e-05,\n    patience=8,\n    verbose=0,\n    mode='min',\n    baseline=None,\n    restore_best_weights=True)\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_custom_metric',\n    factor=0.7,\n    patience=2,\n    verbose=0,\n    mode='min')","5c34175d":"def conv_model():\n\n    conv_inputs = layers.Input(shape=(75))\n    # Embedding layers\n    embed = layers.Embedding(\n        input_dim=354, \n        output_dim=7,\n        embeddings_regularizer='l2')(conv_inputs)\n    # Convolution layers\n    embed = layers.Conv1D(\n        12,\n        1,\n        activation='relu')(embed) \n    embed = layers.Flatten()(embed)\n    hidden = layers.Dropout(0.3)(embed)\n    # Residual blocks layers\n    hidden = tfa.layers.WeightNormalization(layers.Dense(\n        units=32,\n        activation='selu',\n        kernel_initializer=\"lecun_normal\"))(hidden)\n    drop1 = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden]))\n    hidden2 = tfa.layers.WeightNormalization(layers.Dense(\n        units=32,\n        activation='relu',\n        kernel_initializer=\"lecun_normal\"))(drop1) \n    drop2 = layers.Dropout(0.4)(layers.Concatenate()([hidden, hidden2]))\n    hidden3 = tfa.layers.WeightNormalization(layers.Dense(\n        units=32, \n        activation='elu',\n        kernel_initializer=\"lecun_normal\"))(drop2)\n    output = layers.Concatenate()([hidden2, hidden3])\n    # Final layer\n    conv_outputs = layers.Dense(\n        units=9, \n        activation='softmax',\n        kernel_initializer=\"lecun_normal\")(output)\n    # Model instantiation\n    model = Model(conv_inputs,conv_outputs)\n    return model","2446a288":"model = conv_model()\nmodel.summary()","00289922":"keras.utils.plot_model(\n    model,\n    show_shapes=True,\n    show_dtype=False,\n    rankdir='TB',\n    dpi=150)","64b94b67":"%%time\noof_NN = np.zeros((train.shape[0], 9))\npred_NN = np.zeros((test.shape[0], 9))\nN_FOLDS = 25\nSEED = 42\nEPOCH = 70\nskf = StratifiedKFold(\n    n_splits=N_FOLDS, \n    shuffle=True,\n    random_state=SEED)\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train, train.iloc[:, -1])):\n    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n    X_train = train.iloc[:, 1:-1].iloc[tr_idx]\n    y_train = targets.iloc[tr_idx]\n    X_test = train.iloc[:, 1:-1].iloc[ts_idx]\n    y_test = targets.iloc[ts_idx]\n    K.clear_session()\n    # NN CONV MODEL training\n    print(\"\\n-----Convolution model Training----\\n\")\n    model_conv = conv_model()\n    model_conv.compile(\n        loss='categorical_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n        metrics=custom_metric)\n    model_conv.fit(\n        X_train,\n        y_train,\n        batch_size=256,\n        epochs=EPOCH,\n        validation_data=(X_test, y_test),\n        callbacks=[es, plateau],\n        verbose=0)\n    # Convolution Model prediction\n    pred = model_conv.predict(X_test)\n    oof_NN[ts_idx] += pred\n    score_NN = log_loss(y_test, pred)\n    print(f\"\\nFOLD {fold} Score convolution model: {score_NN}\\n\")\n    pred_NN += model_conv.predict(test.iloc[:, 1:])\/N_FOLDS\nscore = log_loss(targets, oof_NN)\nprint(f\"\\n=== FINAL SCORE CONVOLUTION MODEL : {score}===\\n\")","fbe0c569":"pred_embedding = pred_NN","83c13a22":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nfor i in range(9):\n    submission[f'Class_{i+1}'] = pred_embedding[:, i]\nsubmission.to_csv(\"simple_neural_network_modified_skips_connections.csv\", index=False)","7b49b3d8":"!kaggle competitions submit -c tabular-playground-series-jun-2021 -f simple_neural_network_modified_skips_connections.csv -m \"Simple neural Network modifications\"","7a832933":"Original Notebook: https:\/\/www.kaggle.com\/pourchot\/simple-neural-network","b5ee5f21":"# Simple Neural Network - Modifications","56ed30f8":"In this notebook, we will evaluate the performance of a slightly modified version of  the Neural Network presented in the notebook https:\/\/www.kaggle.com\/pourchot\/simple-neural-network. Hyperparameters tuning did not improved the performance on the train set nor the estimated score on test set. We tried to modify the architecture, first by adding a second convolutional layer with the same parameters as the first one, second by adding another dense layer and residual connections before the softmax layer. None of these modifications improved the score. Finally, we manage to _slightly_ improved the estimated test score by modifying the residual connections. The skip connections are added between each dense layer, before the dropout. No connections are bypassing more than one layer (cf. picture)."}}