{"cell_type":{"cd3a6eb8":"code","b01b9cd3":"code","10b17cdd":"code","812f0398":"code","0b6dfc68":"code","ee79184a":"code","0549b8e5":"code","0dd60cc8":"code","98f0d2b1":"code","02f9ba2b":"code","db9b8920":"code","6d137453":"code","19404c68":"code","5ab5d9a4":"code","55121316":"code","8bc355e7":"code","0f89a589":"code","4b316705":"code","b5f6ed88":"code","8eae7ab5":"code","9845b80f":"code","8a958c52":"code","833d8612":"code","4b3533cd":"code","a1dfecaf":"code","55a42ac5":"code","a89773d4":"code","666aae15":"code","37a26fab":"code","e72b3b8d":"code","f1d4627e":"code","a1d4e959":"code","9cb731ab":"code","33c7566f":"code","37871c72":"code","aa9081c9":"code","41dae32c":"code","c97dceb6":"code","8d4fedc8":"code","cbb6a921":"code","774e8e55":"code","37b7f723":"code","7904ffa6":"code","ba35922d":"code","5b911d9d":"code","a72d97bb":"code","925d8b4c":"code","2058a412":"code","e49aa8dd":"code","712edb7b":"code","615c8cf0":"code","d7b2ca47":"code","82962087":"code","4cb86da3":"code","10c80015":"code","45ca3411":"code","e716e484":"code","f71e7ee9":"code","8d0aedfc":"code","48f8cc3d":"code","2c2f2c38":"code","f33234a8":"code","3ea8b4d4":"markdown","579bab8f":"markdown","fe9cdd43":"markdown","42636887":"markdown","29a49348":"markdown","31caf394":"markdown","45356553":"markdown","c3db01ae":"markdown","8a452bf3":"markdown","d3447aae":"markdown","0f0f60bb":"markdown","8a79f11c":"markdown","d9ac2f6a":"markdown","43ff1092":"markdown","1ffceed9":"markdown","c791598e":"markdown","c7e8bac8":"markdown","b42495f4":"markdown","51b0075a":"markdown","dca682e6":"markdown","cf416eab":"markdown","cef9d4f2":"markdown","390fc526":"markdown","85e3025c":"markdown","c0799e15":"markdown","fc94bfc1":"markdown","aa067806":"markdown","8232e8f3":"markdown","6785d291":"markdown","24dd63ba":"markdown","c9e78fef":"markdown","f0846581":"markdown","4fb6c164":"markdown","7cd6255f":"markdown","c6b987db":"markdown","5b33cb64":"markdown","58fcc2cb":"markdown","fa8b5c5d":"markdown"},"source":{"cd3a6eb8":"%config InlineBackend.figure_format = 'retina' # high resolution plotting\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport advertools as adv\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 280)\nadv.__version__","b01b9cd3":"tweets_users_df = pd.read_csv('..\/input\/justdoit_tweets_2018_09_07_2.csv', )\nprint(tweets_users_df.shape)\ntweets_users_df.head(3)","10b17cdd":"[x for x in dir(adv) if x.startswith('extract')]  # currently available extract functions","812f0398":"hashtag_summary = adv.extract_hashtags(tweets_users_df['tweet_full_text'])\nhashtag_summary.keys()","0b6dfc68":"hashtag_summary['overview']","ee79184a":"hashtag_summary['hashtags'][:10]","0549b8e5":"hashtag_summary['hashtags_flat'][:10]","0dd60cc8":"hashtag_summary['hashtag_counts'][:20]","98f0d2b1":"hashtag_summary['hashtag_freq'][:15]","02f9ba2b":"plt.figure(facecolor='#ebebeb', figsize=(11, 8))\nplt.bar([x[0] for x in hashtag_summary['hashtag_freq'][:15]],\n        [x[1] for x in hashtag_summary['hashtag_freq'][:15]])\nplt.title('Hashtag frequency', fontsize=18)\nplt.xlabel('Hashtags per tweet', fontsize=12)\nplt.ylabel('Number of tweets', fontsize=12)\nplt.xticks(range(16))\nplt.yticks(range(0, 2100, 100))\nplt.grid(alpha=0.5)\nplt.gca().set_frame_on(False)","db9b8920":"hashtag_summary['top_hashtags'][:10]","6d137453":"plt.figure(facecolor='#ebebeb', figsize=(8, 12))\nplt.barh([x[0] for x in hashtag_summary['top_hashtags'][2:][:30]][::-1],\n         [x[1] for x in hashtag_summary['top_hashtags'][2:][:30]][::-1])\nplt.title('Top Hashtags')\nplt.grid(alpha=0.5)\nplt.gca().set_frame_on(False)","19404c68":"emoji_summary = adv.extract_emoji(tweets_users_df['tweet_full_text'])\nemoji_summary.keys()","5ab5d9a4":"emoji_summary['overview']","55121316":"emoji_summary['emoji'][:20]","8bc355e7":"emoji_summary['emoji_text'][:20]","0f89a589":"emoji_summary['emoji_flat'][:10]","4b316705":"emoji_summary['emoji_flat_text'][:10]","b5f6ed88":"list(zip(emoji_summary['emoji_flat'][:10], emoji_summary['emoji_flat_text'][:10]))","8eae7ab5":"emoji_summary['emoji_counts'][:15]","9845b80f":"emoji_summary['emoji_freq'][:15]","8a958c52":"plt.figure(facecolor='#ebebeb', figsize=(8, 8))\nplt.bar([x[0] for x in emoji_summary['emoji_freq'][:15]],\n        [x[1] for x in emoji_summary['emoji_freq'][:15]])\nplt.title('Emoji frequency', fontsize=18)\nplt.xlabel('Emoji per tweet', fontsize=12)\nplt.ylabel('Number of tweets', fontsize=12)\nplt.grid(alpha=0.5)\nplt.gca().set_frame_on(False)","833d8612":"emoji_summary['top_emoji'][:20]","4b3533cd":"emoji_summary['top_emoji_text'][:20]","a1dfecaf":"plt.figure(facecolor='#ebebeb', figsize=(8, 8))\nplt.barh([x[0] for x in emoji_summary['top_emoji_text'][:20]][::-1],\n         [x[1] for x in emoji_summary['top_emoji_text'][:20]][::-1])\nplt.title('Top Emoji')\nplt.grid(alpha=0.5)\nplt.gca().set_frame_on(False)","55a42ac5":"mention_summary = adv.extract_mentions(tweets_users_df['tweet_full_text'])\nmention_summary.keys()","a89773d4":"mention_summary['overview']","666aae15":"mention_summary['mentions'][:15]","37a26fab":"mention_summary['mentions_flat'][:10]","e72b3b8d":"mention_summary['mention_counts'][:20]","f1d4627e":"mention_summary['mention_freq'][:15]","a1d4e959":"plt.figure(facecolor='#ebebeb', figsize=(8, 8))\nplt.bar([x[0] for x in mention_summary['mention_freq'][:15]],\n        [x[1] for x in mention_summary['mention_freq'][:15]])\nplt.title('Mention frequency', fontsize=18)\nplt.xlabel('Mention per tweet', fontsize=12)\nplt.ylabel('Number of tweets', fontsize=12)\nplt.xticks(range(15))\nplt.yticks(range(0, 2800, 200))\nplt.grid(alpha=0.5)\nplt.gca().set_frame_on(False)","9cb731ab":"mention_summary['top_mentions'][:10]","33c7566f":"plt.figure(facecolor='#ebebeb', figsize=(8, 8))\nplt.barh([x[0] for x in mention_summary['top_mentions'][:15]][::-1],\n         [x[1] for x in mention_summary['top_mentions'][:15]][::-1])\nplt.title('Top Mentions')\nplt.grid(alpha=0.5)\nplt.xticks(range(0, 1100, 100))\nplt.gca().set_frame_on(False)","37871c72":"question_summary = adv.extract_questions(tweets_users_df['tweet_full_text'])","aa9081c9":"question_summary.keys()","41dae32c":"question_summary['overview']","c97dceb6":"question_summary['question_mark_freq']","8d4fedc8":"question_summary['top_question_marks'] # this is more interesting if you have questions in different languages where different question marks are used.","cbb6a921":"[(i,x) for i, x in  enumerate(question_summary['question_text']) if x][:15]","774e8e55":"intense_summary = adv.extract_intense_words(tweets_users_df['tweet_full_text'], min_reps=3)","37b7f723":"intense_summary['overview']","7904ffa6":"intense_summary['top_intense_words'][:20]","ba35922d":"currency_summary = adv.extract_currency(tweets_users_df['tweet_full_text'])","5b911d9d":"currency_summary.keys()","a72d97bb":"currency_summary['overview']","925d8b4c":"currency_summary['top_currency_symbols']","2058a412":"[x for x in currency_summary['surrounding_text'] if x][:20]","e49aa8dd":"word_summary = adv.extract_words(tweets_users_df['tweet_full_text'], \n                                 words_to_extract=['sport', 'football', 'athlet',],\n                                 entire_words_only=False) # when set to False, it extracts the words and show how they appear within a larger word if any\n                                                          # if set to True, is only extracts the exact words specified only if they appear as entire words","712edb7b":"word_summary.keys()","615c8cf0":"word_summary['overview']","d7b2ca47":"word_summary['top_words'][:20]","82962087":"word_summary_politics = adv.extract_words(tweets_users_df['tweet_full_text'],\n                                          ['politic', 'polic', 'trump', 'donald'])","4cb86da3":"word_summary_politics['overview']","10c80015":"word_summary_politics['top_words'][:20]","45ca3411":"extracted_tweets =  (tweets_users_df[['tweet_full_text', 'user_screen_name', 'user_followers_count']]\n .assign(hashtags=hashtag_summary['hashtags'],\n         hashcounts=hashtag_summary['hashtag_counts'],\n         mentions=mention_summary['mentions'],\n         mention_count=mention_summary['mention_counts'],\n         emoji=emoji_summary['emoji'],\n         emoji_text=emoji_summary['emoji_text'],\n         emoji_count=emoji_summary['emoji_counts'],))\nextracted_tweets.head()","e716e484":"word_freq_hash = adv.word_frequency(extracted_tweets['hashtags'].str.join(' '), \n                                    extracted_tweets['user_followers_count'].fillna(0))\nword_freq_hash.head(10)\n","f71e7ee9":"extracted_tweets[extracted_tweets['hashtags'].str.join(' ').str.contains('drjanegoodall|itstrue',case=False)]","8d0aedfc":"word_freq_mention = adv.word_frequency(extracted_tweets['mentions'].str.join(' '), \n                                       extracted_tweets['user_followers_count'].fillna(0))\nword_freq_mention.head(10)\n","48f8cc3d":"word_freq_emoji = adv.word_frequency(extracted_tweets['emoji'].str.join(' '), \n                                       extracted_tweets['user_followers_count'].fillna(0))\nword_freq_emoji.head(10)\n","2c2f2c38":"[adv.emoji_dict.emoji_dict[k] for k in word_freq_emoji['word'][:10]]","f33234a8":"word_freq_emoji[:10].assign(emoji_text=[adv.emoji_dict.emoji_dict[k] for k in word_freq_emoji['word'][:10]])","3ea8b4d4":"# Extract entities from social media posts, using the `extract_` functions from advertools (a Python package for online marketing)\n\nWhen analyzing a set of social media posts it's helpful to categorize \/ summarize them in structured way. We will go through three functions to extract important entities from a set of tweets. \nThe main idea, is that although the post is technically a string of characters, some of those strings are not simply words, they have more importance (hashtags), need decoding (emoji), and show links to other users and posts (mentions). \n\nOnce you have extracted those entities and summarized them in a structured manner, you are in a better position to understand those posts. \n- **Hashtags:** Although these are strictly words, they are words that have been emphasized by the user who posted them. They also help group posts into threads \/ conversations so we can separate our dataset into sub-conversations where applicable.   \n- **Emoji:** More expressive and pictorial ways of saying something. Although you get to extract emoji from your dataset, you also get their decoded names as well, so they become almost like text and you can do text mining on those emoji. \nFor example, here is what you might get for each emoji after extracting them:  \n \ud83c\udfa5: movie camera  \n\ud83d\udd25: fire  \n\ud83c\udf6a: cookie  \n\ud83d\ude02: face with tears of joy  \n\ud83e\udd14: thinking face  \netc.   \n- **Mentions:** These are important in showing how \"conversational\" your set of posts are. It also gives a lot of context as to who are the most influential accounts in the set of posts, and how they relate to each other. If you are into network science \/ graph theory, mentions and hashtags will give you a great way to understand how the posts are related to each other. \n- **Currency:** Currency symbols in the text list together with surrounding text to give an idea\/context on how these symbols are used.\n- **Intense Words:** Words that have three or more characters repeated, showing an intense feeling\/opnion. Note that intense could be positive or negative.\n- **Questions:** Question marks, their names, and the question text that they appeared in.\n- **Arbitrary Words:** Any arbitrary words that you are interested in knowing about. ","579bab8f":"<a id='mentions'><\/a>\n## Mentions\n\nAgain, by now it should be familiar, and you will be able to guess the names of the keys and what they would produce. ","fe9cdd43":"Apparently, there are two tweets by two different accounts who have 2,896,006 and 1,057,047 followers, respectively.  \nThis is a very good example where you are able to extract hidden information in a data set. Had we not looked at the weighted frequency, we would have left out two tweets by users with 2.8M and 1.05M users, a massive amount of users. \nI'll leave it to you to explore further other findings in the table, and I'll close by getting the word frequency for mentions and emoji using the same technique. ","42636887":"## Outline\n\n* [Hashtags](#hashtags)\n* [Emoji](#emoji)\n* [Mentions](#mentions)\n* [Questions](#questions)\n* [Intense Words](#intense_words)\n* [Currency](#currency)\n* [Arbitrary Words](#words)\n* [Combine tweets & extracted entities](#combine)\n* [Absolute vs weighted word frequency](#abs_weighted)","29a49348":"13.2% of the tweets contained questions. ","31caf394":"Here are of some questions that were asked.","45356553":"Next, we take a look at the flattened list of hashtags. `hashtags_flat` is the name of this list and it basically is a single-dimensional list of all the available hashtags.   \nThis is convenient if you want to do aggregate analysis on the whole set of hashtags. ","c3db01ae":"Next, we can explore the extracted hashtags themselves. Here we are looking at the first ten.   \nAs you can see for each post we get a list of hashtags. We get an empty list wherever there are no hashtags in the tweet. ","8a452bf3":"It seems there isn't much of a surprise here. The accounts that were mentioned the most are the ones you would expect based on the above findings. In some cases the most used words (mentions in this case) are also the most used, on a weighted basis. \n\nLet's see how things are with emoji: ","d3447aae":"<a id='abs_weighted'><\/a>\n## Absolute vs Weighted Counts\n\nSo far we have counted the entities that we wanted and got the absolute count of each, in different formats and summaries.  \nWhat about how influential each of those entities was, and how much reach \/ engagement they generated?  \n\nLet's say ten people, each with 100 followers tweeted using the hashtag **#basketball** in their tweets.  \nTherefore those tweets are expected to potentially reach 10 x 100 = 1,000 people (not really that much because of follower overlap, and not everyone sees all tweets, but we will use this simplified assumption for now).  \nLet's also assume that only one person used the hashtag **#NFL** in these tweets. And let's also assume that this person has 20,000 followers. Then which hashtag reached more users?  \nObviously **#NFL** would reach more because, although only one person tweeted it, that one person had more followers than the ten others who tweeted **#basketball** combined.  \n\nSo, now we will take the same analysis to a new level, and by assigning a weight for each tweet. As mentioned above, we will use the number of followers as a weight for each tweet, which is a good proxy to how much reach it would generate.  \nYou can \/ should look at other weights as well. Maybe at the number of retweets, or favorites, which also show how much engagement was generated and subsequent reach.  \nWhy not multiply the number of followers by the number of retweets the tweet generated, to give an even better estimate on the reach of the tweet? It's up to you to decide what makes sense for your case.  \nFor now we will look at the number of followers as our main proxy. \n\n`advertools` has a special function for measuring the two types of word frequency (absolute and weighted), and we will take a look at that briefly here.  \nA full discussion of how this function was created and how it works can be found in my [tutorial on DataCamp discussing absolute vs weighted word frequency.](https:\/\/www.datacamp.com\/community\/tutorials\/absolute-weighted-word-frequency)\n\nBasically `word_frequency` takes two lists, a text list (the tweets' text and entities in our case), and a list of numbers describing our dataset (the number of followers in this case).   \nThe output shows both the absolute count, and the weighted count of each of our words (hashtags, emoji, mentions, in this case). \n\nLet's see what the top hashtags were in terms of weighted frequency: \n\n","0f0f60bb":"Here we get a better idea since we see how mentions are distributed.  \nAlthough we previously saw that there is almost one mention per tweet (on average), now we see that more than half the tweets didn't have any mentions in them.  \nThis is the additional view that is given by the `mention_freq` key.   \nVisualizing the above data: ","8a79f11c":"We start by preparing the environment by importing the relevant libraries, and setting some options: ","d9ac2f6a":"The first one is of course going to be #justdoit because this is what all tweets contain, but the second and fourth are surprising, because we don't see them anywhere in the lists above, and they both have an absolute frequency of 1 (they were used only once).  \nThis means that this one time where they were used they were tweeted by someone with a very large number of followers, and therefore, the tweet(s) containing these hashtags have achieved more reach than others, that have been tweeted more frequently.   \nLet's see who these tweets were tweeted by: ","43ff1092":"<a id='questions'><\/a>\n## Questions","1ffceed9":"Visualizing the frequencies to get a better overview of how they are distributed, we plot the top fifteen frequencies: ","c791598e":"It seems a quarter of tweets have people intensely expressing their feelings. ","c7e8bac8":"Visualizing the same data (excluding #justdoit and #nike): ","b42495f4":"<a id='combine'><\/a>\n## Combine tweets, usernames, followers counts, with extracted entities\n\nNow that we have extracted the entities that we want, we can now create a new DataFrame showing tweets, usernames, followers count, and the extracted entities:","51b0075a":"You are probably wonderig which are the top hashtags, and how popular they are.   \nThis is provided by the `top_hashtags` key.   \nAs mentioned above, it shouldn't be a surprise that #justdoit is the top one, and that #nike and #colinkaepernick are in the top positions as well.","dca682e6":"0.95 mentions per tweet hints that this might be a conversational set of tweets. Probably many people were mentioning others, replying to them, etc.   \nAlso, there are 1,631 unique mentions out of the total of 4,870 mentions, which seems that it's quite a diverse set of mentions.   \nLet's explore more and verify.","cf416eab":"We will see how this can be done using a set of 5,000 tweets. \n\n**Some background on those tweets: **\n\n- #JustDoIt: All tweets contain this hashtag.\n- The tweets happened on September 7, 2018, which is days after Nike announced its endorsement of Colin Kaepernick, and making him the face of their 30th anniversary of their JustDoIt campaign.\n- Kaepernick made a controversial decision not to stand up during the national anthem, as a protest to police brutality, a while back.\n- This has stirred a heated debate, and became a big national issue especially when [Donald Trump commented on it](https:\/\/www.youtube.com\/watch?v=oY3hpZVZ7pk)\n\nThis notebook is mainly for demonstrating how to use the `extract_` functions and structure the tweets in an easier way, and will not analyze the content much. By the way, the Twitter API provides you with those entities extracted with some meta data, so you don't need these functions in that case, but you may need in the following cases: \n- Many tweet datasets come as raw text and you will have to extract entities yourself\n- When you export tweets from your own account, the entities don't come extracted\n- This approach works for any kind of social media posts, where hashtags, mentions, and emoji have become near-universal in their use\n\n## [advertools](https:\/\/github.com\/eliasdabbas\/advertools)\n\nA Python package for online marketing productivity and analysis. You can learn more about it in the [GitHub repo](https:\/\/github.com\/eliasdabbas\/advertools), and it can easily be installed by running: \n\n`pip install advertools`","cef9d4f2":"The \"heavy check mark\" is probably people referring to Nike, which is similar to the Nike swoosh logo. You can easily filter those tweets and check to verify.   \nFire probably refers to people who are against Nike's decision to support Kaepernick, as there is a trend of people who are burning their Nike clothes \/ shoes in protest of Nike's decision.   \nYou can explore many of these things as you have them extracted and structured as if they were words. ","390fc526":"It seems we have two surprises here, where the monkey emoji reached more people (counting on a weighted basis) even though it was only used once. This is the same tweet we saw above with the top hashtag.   \nThe police officer is also another surprise, because it is ranked 9 on a weighted basis, even though it was only twice in this dataset of 5,000 tweets. Another example of hidden, important, and surprising information, that can be easily overlooked.\n\n`advertools` has a convenience dictionary to translate any emoji and provide you with the name of that emoji","85e3025c":"Almost 7% of the tweets contained any of the words that we specified. This indicates that this was not a very sports-oriented discussion.  \nBelow are the top words.","c0799e15":"The most general one to get a quick idea about the data is the `overview` key.  \nThis shows us how many posts we have, the total number of hashtags (or mentions, or emoji), the average number of hashtags per post, and the number of unique hashtags. \n","fc94bfc1":"It seems there isn't much talk about money, with 1.2% of the tweets containing currency symbols. Let's see what they are. ","aa067806":"The count of hashtags for each tweet is given by the `hashtag_counts` key.   \nLater, we will combine all these in one DataFrame and do further analysis on them.","8232e8f3":"<a id='hashtags'><\/a>\n## Hashtags\n\nLet's start by extracting the hashtags. You will see that all the functions for extracting entities, have a similar interface. \nOnce you   \n`import advertools as adv`  \nthen you can run `adv.extract_<tab>` and get the available options.\nThe output of these functions is a dictionary, the keys of which provide a different summary of the entities extracted. \nHere we will mainly deal with the tweet text itself from the column `tweets_users_df['tweet_full_text']`. You can do a similar analysis for users' profiles for example, because it is mainly text, and contains some of those entities.\nWe first define `hashtag_summary` and then explore the available keys of the resulting dictionary:","6785d291":"<a id='intense_words'><\/a>\n## Intense Words","24dd63ba":"We won't be using most of the columns here, but they are kept in the dataset in case you may have other ideas on analyzing other things in a different way. \n\nNote that all columns are prefixed with `tweet_` and `user_` to indicate columns that have data about the tweet itself, and data about the user who made that tweet. \nRemoving those prefixes would give you the original column names as provided by the Twitter API. ","c9e78fef":"Putting them side by side to get a better idea, and taking a look at the first ten: ","f0846581":"I hope you found this useful.   \nFeel free to fork, and experiment with the functions presented here, or running your own completely different analysis.   \nFeedback more than welcome [@eliasdabbas](https:\/\/twitter.com\/eliasdabbas)   \n[advertools GitHub repo](https:\/\/github.com\/eliasdabbas\/advertools)\n","4fb6c164":"Adding to the same DataFrame for easier reading: ","7cd6255f":"It is also interesting to know the frequency of using hashtags in this data set.   \nThe `hashtag_freq` key shows us the number of tweets containing 1, 2, 3, etc hashtags.  \nHere you will see that we have 2,058 tweets with one hashtag, 1,059 tweets with two hashtags, and so on.  \nNotice that there are no tweets with zero hashtags. This is unusual, but not surprising in this dataset, because by definition, we requested the tweets that contained a special hashtag, so they all include at least that hashtag. ","c6b987db":"<a id='words'><\/a>\n## Arbitrary Words\n\nHere we are approaching the data set with questions in mind. \"How much of this conversation is about sports, politics, Nike, Trump, Kaepernick?\" and so on.  \nThis is flexible, and you can come up with any set of words that you think could\/should be included.  \nIn cases where you are analyzing your own account for example, it should be easy to check how much on-topic you are. Knowing your industry, you would expect a certain percentage of your tweets to contain any of a set of words. Otherwise, you might be moving away from your target topics. ","5b33cb64":"<a id='emoji'><\/a>\n## Emoji\n\nYou will see that the `extract_emoji` function is pretty much the same as `extract_hashtags`. The only difference is that it has emoji both as images and their textual counterparts. ","58fcc2cb":"The function takes two optional parameters, `left_chars` and `right_chars`, where you can specify the number of characters to extract on either side of the currency symbol. This should give you an idea on what kind financial discussion is happening. Is there a price being discussed? Is it an economic disucssion? What currencies are discussed? etc. \n\nWatch out for Twitter's \"cashtag\". This is a special tag that starts with the dollar sign, and followed by company stock symbols, and other financial instruments. In the above list for example, you can see `$tsla` which is the stock symbol of Tesla. This is a special case with Twitter, and once you extract the surrounding text, you can see exactly what the topic is. ","fa8b5c5d":"<a id='currency'><\/a>\n## Currency Symbols"}}