{"cell_type":{"c49e34a1":"code","2231e1e2":"code","18720a77":"code","66df8eec":"code","8a5e84a3":"code","94dd8640":"code","57598257":"code","d5b7080a":"code","887ec32b":"code","2cae640d":"code","7fc4e1c1":"code","c56ab1c7":"code","58bf03a7":"code","51af6219":"code","b7be1d9d":"code","3279415c":"code","81531a11":"code","10e117ca":"code","9f38ceba":"code","3f67179e":"code","71157b85":"code","ebccc45a":"code","6c7f4bae":"code","bd27b011":"code","f7313e09":"code","15dc21c6":"code","57b7cd7e":"code","c012339a":"markdown","9f79fa9b":"markdown","93a399f6":"markdown","d8a995eb":"markdown","3a1e790e":"markdown","868ac39f":"markdown","05a66285":"markdown","0b8cb52e":"markdown","bdd87ccc":"markdown","a019ff04":"markdown","dfdb423b":"markdown","6ee7ca92":"markdown","6f5fea78":"markdown","007aeb1e":"markdown"},"source":{"c49e34a1":"import matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport cv2\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport itertools","2231e1e2":"def plot_img(pass_data,pass_label,fig_size,number,channel):\n    fig,ax=plt.subplots(figsize=fig_size,dpi=80)\n    for i,data in enumerate(pass_data[number[0]:number[1]]):\n        count=1\n        if channel==\"ALL\": \n            if data.shape[2]%5==0:\n                row,col=data.shape[2]\/\/5,5\n            else:\n                row,col=data.shape[2]\/\/5+1,5\n                \n            for x in range(0,data.shape[2]):\n                sub1 = plt.subplot(row,col,count)\n                sub1.imshow((data[:,:,x]*255).astype(np.uint8))\n                count+=1\n        elif channel>0:\n            if channel<5:\n                row,col=1,channel\n            elif channel%5:\n                row,col=data.shape[2]\/\/5,5\n            else:\n                row,col=data.shape[2]\/\/5+1,5\n          \n            for x in range(0,channel):                \n                sub1 = plt.subplot(row,col,count)\n                sub1.imshow((data[:,:,x]*255).astype(np.uint8))\n                count+=1\n        else:\n            sub1 = plt.subplot(5, 5,i+1)\n            sub1.imshow((data[:,:,:]))\n    fig.tight_layout()","18720a77":"DATA=[]\nSTR_LABEL=[]\nINT_LABEL=[]\nIMG_SIZE=150\nBATCH_SIZE=55\nMAX_TEST_ACC=0.0000001\nMAX_TRAIN_ACC=0.0000001\nDIFFRENCE=0\nEPOCH=150\nFLOWER_DIR='..\/input\/flowers\/flowers'","66df8eec":"for i,folder in enumerate(os.listdir(FLOWER_DIR)):    \n    d=0\n    for img in os.listdir(os.path.join(FLOWER_DIR,folder)):\n        temp=cv2.imread(os.path.join(FLOWER_DIR,folder,img))\n        try:\n            temp=cv2.resize(temp, (IMG_SIZE,IMG_SIZE))\n            if folder==\"dandelion\" and d%2==0:\n                DATA.append(cv2.cvtColor(temp,cv2.COLOR_BGR2RGB))\n                INT_LABEL.append(i)\n                d+=1\n            DATA.append(cv2.cvtColor(temp,cv2.COLOR_BGR2RGB))\n            INT_LABEL.append(i)\n        except Exception as e:\n            print(\"Corupted Images: \",os.path.join(FLOWER_DIR,folder,img))\n    STR_LABEL.append(folder)\n    print(folder+\" converted to \"+ str(i))","8a5e84a3":"DATA=np.array(DATA)\nINT_LABEL=np.array(INT_LABEL)\nindices=np.arange(INT_LABEL.shape[0])\nnp.random.shuffle(indices)\nDATA=DATA[indices]\/255\nINT_LABEL=INT_LABEL[indices]\nclasses=len(np.unique(INT_LABEL))","94dd8640":"INT_LABEL = keras.utils.to_categorical(INT_LABEL,classes)","57598257":"STR_LABEL","d5b7080a":"INT_LABEL.shape","887ec32b":"train_data,test_data,train_label,test_label=train_test_split(DATA, INT_LABEL, test_size=0.20, random_state=42)","2cae640d":"validation_data,test_data,validation_label,test_label=train_test_split(test_data, test_label, test_size=0.50, random_state=42)","7fc4e1c1":"plot_img(train_data,0,(10,10),[0,10],0)","c56ab1c7":"tf.reset_default_graph()\ndata_input=tf.placeholder(tf.float32,[None,150,150,3],name=\"data_input\")\nlabel_input=tf.placeholder(tf.float32,[None,classes],name=\"label_input\")","58bf03a7":"init_var=tf.contrib.layers.xavier_initializer()\nweight1=tf.Variable(init_var((5,5,3,16)),name=\"weight1\")\nweight2=tf.Variable(init_var((3,3,16,32)),name=\"weight2\")\nweight3=tf.Variable(init_var((3,3,32,64)),name=\"weight3\")\nweight4=tf.Variable(init_var((3,3,64,128)),name=\"weight4\")\nweight5=tf.Variable(init_var((3,3,128,256)),name=\"weight5\")\nweight6=tf.Variable(init_var((3,3,256,256)),name=\"weight6\")","51af6219":"convo1=tf.nn.conv2d(data_input,weight1,strides=[1,1,1,1],padding=\"SAME\",name=\"convo1\")\nbatch_norm1=tf.layers.batch_normalization(convo1,momentum=0.5,name=\"batch_norm1\")\nrelu1=tf.nn.relu(batch_norm1,name=\"relu1\")\nmaxpool1=tf.nn.max_pool(relu1,[1,3,3,1],[1,2,2,1],\"SAME\",name=\"maxpool1\")\n\nconvo2=tf.nn.conv2d(maxpool1,weight2,strides=[1,1,1,1],padding=\"VALID\",name=\"convo2\")\nbatch_norm2=tf.layers.batch_normalization(convo2,momentum=0.5,name=\"batch_norm2\")\nrelu2=tf.nn.relu(batch_norm2,name=\"relu2\")\nmaxpool2=tf.nn.max_pool(relu2,[1,2,2,1],[1,2,2,1],\"VALID\",name=\"maxpool2\")\n\nconvo3=tf.nn.conv2d(maxpool2,weight3,strides=[1,1,1,1],padding=\"VALID\",name=\"convo3\")\nbatch_norm3=tf.layers.batch_normalization(convo3,momentum=0.5,name=\"batch_norm3\")\nrelu3=tf.nn.relu(batch_norm3,name=\"relu3\")\n# drop1=tf.layers.dropout(relu3,rate=0.2)\nconvo4=tf.nn.conv2d(relu3,weight4,strides=[1,1,1,1],padding=\"VALID\",name=\"convo4\")\nbatch_norm4=tf.layers.batch_normalization(convo4,momentum=0.5,name=\"batch_norm4\")\nrelu4=tf.nn.relu(batch_norm4,name=\"relu4\")\nmaxpool3=tf.nn.max_pool(relu4,[1,2,2,1],[1,1,1,1],\"VALID\",name=\"maxpool3\")\n\nconvo5=tf.nn.conv2d(maxpool3,weight5,strides=[1,1,1,1],padding=\"VALID\",name=\"convo5\")\nbatch_norm5=tf.layers.batch_normalization(convo5,momentum=0.5,name=\"batch_norm5\")\nrelu5=tf.nn.relu(batch_norm5,name=\"relu5\")\nmaxpool4=tf.nn.max_pool(relu5,[1,2,2,1],[1,2,2,1],\"VALID\",name=\"maxpool4\")\nconvo6=tf.nn.conv2d(maxpool4,weight6,strides=[1,1,1,1],padding=\"VALID\",name=\"convo6\")\nbatch_norm6=tf.layers.batch_normalization(convo6,momentum=0.5,name=\"batch_norm6\")\nrelu6=tf.nn.relu(batch_norm6,name=\"relu6\")\n\nflat=tf.layers.flatten(relu6)\n# drop2=tf.layers.dropout(flat,rate=0.2)\ndense1=tf.layers.dense(flat,units=800,activation=\"relu\",kernel_initializer=tf.contrib.layers.xavier_initializer(),name=\"dense1\")\ndense2=tf.layers.dense(dense1,units=200,activation=\"relu\",kernel_initializer=tf.contrib.layers.xavier_initializer(),name=\"dense2\")\ndense3=tf.layers.dense(dense2,units=classes,kernel_initializer=tf.contrib.layers.xavier_initializer(),name=\"dense3\")","b7be1d9d":"final_pred=tf.nn.softmax(dense3, name=\"final_pred\")\ncross_entropy=tf.nn.softmax_cross_entropy_with_logits_v2(logits=dense3,labels=label_input)\ncost_op=tf.reduce_mean(cross_entropy)\ncorrect_prediction=tf.equal(tf.argmax(final_pred,1),tf.argmax(label_input,1))\naccurecy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\ngrad=tf.train.AdamOptimizer(0.0006).minimize(cost_op)","3279415c":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,# randomly flip images     \n)  \n\n\ndatagen.fit(train_data)\n\naug_img=datagen.flow(train_data,train_label, batch_size=BATCH_SIZE-10)","81531a11":"t_data,t_label=next(aug_img)\nplot_img(t_data,0,(40,40),[0,10],0)","10e117ca":"sess=tf.Session()\nsaver=tf.train.Saver()\nsess.run(tf.global_variables_initializer())\nfor epoch in range(EPOCH):\n    for b_num in range((train_data.shape[0]\/\/BATCH_SIZE)+1):\n        t_data,t_label=next(aug_img)\n        rand=np.random.randint(low=0,high=train_data.shape[0],size=10)\n        temp_data,temp_label=train_data[rand],train_label[rand]\n        t_data,t_label=np.vstack((t_data,temp_data)),np.vstack((t_label,temp_label))\n        val=sess.run([grad,cost_op,accurecy],feed_dict={data_input:t_data.astype(np.float32),label_input:t_label})\n    valid_op_acc=sess.run([cost_op,accurecy],feed_dict={data_input:validation_data,label_input:validation_label})\n    print(\"--------------------------------\")\n    print(\"Epoch             : \",epoch+1)\n    print(\"Train Loss        : \",val[1])\n    print(\"Test Loss         : \",valid_op_acc[0])\n    print(\"Train Accuracy    : \",val[2])\n    print(\"Test Accuracy     : \",valid_op_acc[1])       \n    print(\"--------------------------------\")\n    if val[2]-valid_op_acc[1]<DIFFRENCE or (MAX_TRAIN_ACC<val[2] and MAX_TEST_ACC<valid_op_acc[1]):\n        MAX_TEST_ACC=val[2]\n        MAX_TRAIN_ACC=valid_op_acc[1]\n        DIFFRENCE=val[2]-valid_op_acc[1]\n        saver.save(sess,\"flower_model_\"+str(epoch+1)+\"_\"+str(MAX_TEST_ACC))\n        print(\"======================================\")\n        print(\"============ MODEL SAVED =============\")\n        print(\"======================================\")","9f38ceba":"def plot_confusion_matrix(Pred_d, classes,title='Confusion Matrix'):   \n    plt.figure()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n    plt.imshow(Pred_d, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title(title)\n    plt.colorbar()\n    thresh_hold = Pred_d.max() \/ 2.\n    for i, j in itertools.product(range(Pred_d.shape[0]), range(Pred_d.shape[1])):\n        plt.text(j, i, Pred_d[i, j],horizontalalignment=\"center\",color=\"white\" if Pred_d[i, j] > thresh_hold else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","3f67179e":"test_pre=sess.run(final_pred,feed_dict={data_input:test_data})\npred_max=[STR_LABEL[np.argmax(x)] for x in test_pre]\nor_max=[STR_LABEL[np.argmax(x)] for x in test_label]\nmatrix = confusion_matrix(or_max, pred_max)","71157b85":"plot_confusion_matrix(matrix , classes=STR_LABEL)","ebccc45a":"## for predicting form a given image\ntest_img=cv2.imread(\"..\/input\/flowers\/flowers\/rose\/10503217854_e66a804309.jpg\")\ntest_img=cv2.resize(test_img, (IMG_SIZE,IMG_SIZE))","6c7f4bae":"test_img=np.array([cv2.cvtColor(test_img,cv2.COLOR_BGR2RGB)])","bd27b011":"test_img.shape","f7313e09":"plot_img(test_img,0,(10,10),[0,1],0)","15dc21c6":"pred_test=sess.run(final_pred,feed_dict={data_input:test_img.astype(np.float32)})","57b7cd7e":"STR_LABEL[np.argmax(pred_test)]","c012339a":"#### All the required imports[](http:\/\/)\ni am using keras just for data augmentation for better result","9f79fa9b":"#### A handy function to help me visualize images and diffrent channels through out the Convolution","93a399f6":"### Starting traing of the model with 150 epoch and batch size of 55 ","d8a995eb":"### Code for ploting confusion matrix","3a1e790e":"## A simple CNN architecture which sucessfully achived above 80% accurecy on train and test dataset ","868ac39f":"### Starting the stucture of of tensorflow model","05a66285":"### spliting the test data into validation and test","0b8cb52e":"### Ploting the augmented data","bdd87ccc":"### Augmenting data for better performace of the model","a019ff04":"### Data preprocessing for feeding into the model\n\n##### Converting to numpy array\n##### Shufflig of data\n##### Normalization\n##### Unique Classes","dfdb423b":"### Spliting the data into train and test","6ee7ca92":"#### Converting images to usable data format for our model\nThere are some courupted data in the deta set to avoid that i have used try catch ","6f5fea78":"### One Hot Encoding Of classes","007aeb1e":"### Visualizing train data"}}