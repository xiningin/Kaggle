{"cell_type":{"7edd7651":"code","e682bae4":"code","4a3f5b93":"code","4d436e82":"code","26a30a13":"code","757fb88f":"code","72f20149":"code","64370020":"code","7be8f135":"code","83cd59ef":"code","27f71c4d":"code","d10a57a2":"code","95a60067":"code","049da235":"code","ed07cba4":"code","f92076e9":"code","76185201":"code","ff6f7e42":"code","5158d8b2":"code","ec1028d5":"code","20f8e6ae":"code","ade5254b":"code","7396d341":"code","13f86580":"code","82ba0fdc":"code","2ab876e9":"markdown","f2844cfa":"markdown","754d47a9":"markdown","44964478":"markdown","f02f9438":"markdown","0c0b3a3e":"markdown","5bbbab57":"markdown","25f073c5":"markdown","81b5f28e":"markdown","11702336":"markdown","21f8fbc4":"markdown","e7ce21ee":"markdown","38963daa":"markdown","266a1586":"markdown","c7817bdc":"markdown","3ec570d4":"markdown","73ed4877":"markdown","cf0599ec":"markdown","e7eb6514":"markdown","4806aa04":"markdown","3e6dbbcc":"markdown","436f6923":"markdown","8c862fbd":"markdown","05361820":"markdown","436b071e":"markdown","1350a2a0":"markdown"},"source":{"7edd7651":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches","e682bae4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4a3f5b93":"train_df = pd.read_csv('..\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels = pd.read_csv('..\/input\/data-science-bowl-2019\/train_labels.csv')\ntest_df = pd.read_csv('..\/input\/data-science-bowl-2019\/test.csv')\nspecs_Df = pd.read_csv('..\/input\/data-science-bowl-2019\/specs.csv')","4d436e82":"train_df.shape","26a30a13":"train_df.isnull().sum()","757fb88f":"train_labels.head()   ","72f20149":"train_labels.title.unique()","64370020":"#temp=df.drop_duplicates('GameId', keep='last')\ntemp_df = train_labels.groupby([\"title\",\"accuracy_group\"])[\"accuracy_group\"].agg([\"count\"]).reset_index()\ntemp_df.columns = [\"title\",\"accuracy_group\", \"Count\"]\n#temp_df.Country = temp_df[temp_df.Country != 'United Kingdom']\n\nfig = px.scatter(temp_df, x=\"accuracy_group\", y=\"title\", color=\"accuracy_group\", size=\"Count\")\nlayout = go.Layout(\n    title=go.layout.Title(\n        text=\"Accuracy group in each Assesments\",\n        x=0.5\n    ),\n    font=dict(size=14),\n    width=800,\n    height=600,\n    showlegend=False\n)\nfig.update_layout(layout)\nfig.show()","7be8f135":"Accuracy=pd.DataFrame()\nAccuracy['Type']=train_labels.accuracy_group.value_counts().index\nAccuracy['Count']=train_labels.accuracy_group.value_counts().values\n\nimport plotly.offline as pyo\npy.init_notebook_mode(connected=True)\nfig = go.Figure(data=[go.Pie(labels=Accuracy['Type'], values=Accuracy['Count'],hole=0.2)])\nfig.show()","83cd59ef":"Success_Rate_1=pd.DataFrame()\nSuccess_Rate_2=pd.DataFrame()\nSuccess_Rate_3=pd.DataFrame()\nSuccess_Rate_4=pd.DataFrame()\nSuccess_Rate_5=pd.DataFrame()\nMushroom_Sorter=train_labels.loc[train_labels['title'] == 'Mushroom Sorter (Assessment)']\nSuccess_Rate_1['Type']=Mushroom_Sorter.num_correct.value_counts().index\nSuccess_Rate_1['Count']=Mushroom_Sorter.num_correct.value_counts().values\nBird_Measurer=train_labels.loc[train_labels['title'] ==  'Bird Measurer (Assessment)']\nSuccess_Rate_2['Type']=Bird_Measurer.num_correct.value_counts().index\nSuccess_Rate_2['Count']=Bird_Measurer.num_correct.value_counts().values\nCauldron_Filler=train_labels.loc[train_labels['title'] == 'Cauldron Filler (Assessment)']\nSuccess_Rate_3['Type']=Cauldron_Filler.num_correct.value_counts().index\nSuccess_Rate_3['Count']=Cauldron_Filler.num_correct.value_counts().values\nChest_Sorter=train_labels.loc[train_labels['title'] == 'Chest Sorter (Assessment)']\nSuccess_Rate_4['Type']=Chest_Sorter.num_correct.value_counts().index\nSuccess_Rate_4['Count']=Chest_Sorter.num_correct.value_counts().values\nCart_Balancer=train_labels.loc[train_labels['title'] == 'Cart Balancer (Assessment)']\nSuccess_Rate_5['Type']=Cart_Balancer.num_correct.value_counts().index\nSuccess_Rate_5['Count']=Cart_Balancer.num_correct.value_counts().values","27f71c4d":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nlabels = [0,1]\n\nfig = make_subplots(3, 2, specs=[[{'type':'domain'}, {'type':'domain'}],[{'type':'domain'}, {'type':'domain'}],[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=['Mushroom Sorter', 'Bird Measurer','Cauldron Filler','Chest Sorter','Cart Balancer'])\nfig.add_trace(go.Pie(labels=Success_Rate_1['Type'], values=Success_Rate_1['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 1, 1)\nfig.add_trace(go.Pie(labels=Success_Rate_2['Type'], values=Success_Rate_2['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 1, 2)\nfig.add_trace(go.Pie(labels=Success_Rate_3['Type'], values=Success_Rate_3['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 2, 1)\nfig.add_trace(go.Pie(labels=Success_Rate_4['Type'], values=Success_Rate_4['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 2, 2)\nfig.add_trace(go.Pie(labels=Success_Rate_5['Type'], values=Success_Rate_5['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 3, 1)\n\nfig.update_layout(title_text='Success Rate of Each Group')\nfig.show()","d10a57a2":"def reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n            \n            #Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n               NAlist.append(col)\n               df[col].fillna(-999,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] =df[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return df,NAlist","95a60067":"train_df,train_Na=reduce_mem_usage(train_df)","049da235":"import gc\ngc.collect()","ed07cba4":"test_df,test_Na=reduce_mem_usage(test_df)","f92076e9":"train_df.columns","76185201":"data={'Unique_event':[train_df.event_id.nunique()],\n      'Unique_gamesession':[train_df.game_session.nunique()],\n      'Unique_title':[train_df.title.nunique()]}\nCount_df=pd.DataFrame(data)\nCount_df","ff6f7e42":"# Format and make date \/ hour features\ntrain_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\ntrain_df['date'] = train_df['timestamp'].dt.date\ntrain_df['hour'] = train_df['timestamp'].dt.hour\ntrain_df['weekday_name'] = train_df['timestamp'].dt.weekday_name\n\n# Same for test\ntest_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\ntest_df['date'] = test_df['timestamp'].dt.date\ntest_df['hour'] = test_df['timestamp'].dt.hour\ntest_df['weekday_name'] = test_df['timestamp'].dt.weekday_name","5158d8b2":"train_df.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Date',\n                                                       color=\"blue\")\ntest_df.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Date'\n                                                      ,color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","ec1028d5":"train_df.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Hour',color=\"blue\")\ntest_df.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Hour',color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","20f8e6ae":"train_df.groupby('weekday_name')['event_id'].agg('count').T[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']].T.plot(figsize=(15, 3),title='Numer of Event Observations by Day of Week',color=\"blue\")\ntest_df.groupby('weekday_name')['event_id'].agg('count').T[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']].T.plot(figsize=(15, 3),title='Numer of Event Observations by Day of Week',color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","ade5254b":"Game=pd.DataFrame()\nGame['Type']=train_df.type.value_counts().index\nGame['Count']=train_df.type.value_counts().values\n\nimport plotly.offline as pyo\npy.init_notebook_mode(connected=True)\nfig = go.Figure(data=[go.Pie(labels=Game['Type'], values=Game['Count'],hole=0.2)])\nfig.show()","7396d341":"Game=pd.DataFrame()\nGame['Title']=train_df.title.value_counts().index\nGame['Count']=train_df.title.value_counts().values\n\nfig = px.bar(Game, x='Title', y='Count',\n             hover_data=['Count'], color='Count',\n             labels={'pop':'Total Number of game titles'}, height=400)\nfig.show()","13f86580":"avg_time=[]\ntype_=[]\nfor i in train_df.type.unique():\n    type_.append(i)\n    avg_time.append(train_df.loc[train_df['type'] ==i]['game_time'].mean())\n    \nAvg_Timeplayed=pd.DataFrame()\nAvg_Timeplayed['Type']=type_\nAvg_Timeplayed['Average']=avg_time\n\nfig = px.bar(Avg_Timeplayed, x='Type', y='Average',\n             hover_data=['Average'], color='Average',\n             labels={'pop':'Average time played on each types'}, height=400)\nfig.show()","82ba0fdc":"avg_time=[]\ntitle_=[]\nfor i in train_df.title.unique():\n    title_.append(i)\n    avg_time.append(train_df.loc[train_df['title'] ==i]['game_time'].mean())\n    \nAvg_Timeplayed=pd.DataFrame()\nAvg_Timeplayed['Title']=title_\nAvg_Timeplayed['Average']=avg_time\n\nfig = px.bar(Avg_Timeplayed, x='Title', y='Average',\n             hover_data=['Average'], color='Average',\n             labels={'pop':'Average time played on each titles'}, height=400)\nfig.show()","2ab876e9":"## About the Competition","f2844cfa":"**About this kernel**\n\n  This kernel acts as a starter kit. It gives all the essential Key insights on the data as well as modelling\n  \n**Key Takeaways**\n\n* Extensive EDA\n* Effective Story Telling\n* Creative Feature Engineering\n* Modelling\n* Ensembling","754d47a9":"**Distribtuion of Game Type**","44964478":"**Reducing Memory For test data**","f02f9438":"Now you may wonder what does the **accuracy_group** denotes. No worries as mentioned in the [data description](https:\/\/www.kaggle.com\/c\/data-science-bowl-2019\/data), They denote:\n\n**3**: the assessment was solved on the first attempt\n\n**2**: the assessment was solved on the second attempt\n\n**1**: the assessment was solved after 3 or more attempts\n\n**0**: the assessment was never solved","0c0b3a3e":"## Breaking the Train data to the Fullest!!","5bbbab57":"**Game Title VS Game Played Time**","25f073c5":"The size of the dataset is pretty big, so we are trying to make the dataset smaller without losing information.\n\nReason behind memory Reduction:\n\nInt16: 2 bytes\n\nInt32 and int: 4 bytes\n\nInt64 : 8 bytes\n\nThis is an example how different integer types are occupying the memory. In many cases it is not necessary to represent our integer as int64 and int32 it is just waste of memory. So I am trying to understand the necessaity of every numerical representation and try to convert the unnecessary higher numerical representation to lower one. In that, we can reduce the memory without losing the memory.","81b5f28e":"## Exploring the ground truth of each assesment","11702336":"**Distribution of Game Title**","21f8fbc4":"We are provided with the data for game analytics for the **PBS KIDS Measure Up!** app. In this app, children navigate a map and complete various levels, which may be activities, video clips, games, or assessments. Each assessment is designed to test a child's comprehension of a certain set of measurement-related skills. There are five assessments: \n                    * Bird Measurer\n                    * Cart Balancer\n                    * Cauldron Filler\n                    * Chest Sorter\n                    * Mshroom Sorter.\n\nThe intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt).","e7ce21ee":"**Success rate in each group**","38963daa":"** Reading the data**","266a1586":"**Most of the plots made here are interactive please feel free to hover over**","c7817bdc":"**Reducing Memory For training data**","3ec570d4":"**Timestamp**\n\nLet's explore the time stamp of the given data and try to find some useful information\n\nThis section was taken from ths amazing [kernel](https:\/\/www.kaggle.com\/robikscube\/2019-data-science-bowl-an-introduction). I just added a how the test and train data are in given timestamps.","73ed4877":"**This file demonstrates how to compute the ground truth for the assessments in the training set.**","cf0599ec":"## Effective Data Minification","e7eb6514":"**Game Type VS Game Played Time**","4806aa04":"**Loading the necessary Packages**","3e6dbbcc":"**Distribution of the Accuracy group**","436f6923":"**Important Figure's**\n\nOf total **113441042** records in train data there are, only\n\n1. **384** Unique events happened\n2. **303319** Unique Gamming Session\n3. **44** Uninque Game Titles","8c862fbd":"**Please upvote if you find this kernel useful**","05361820":"As I have mentioned, there are five assesments let's explore the ground truth of each assesment(sucess and failure rate)","436b071e":"**Simple Data Exploration**","1350a2a0":"**This kernel is under construction, Stay tuned for more updates**"}}