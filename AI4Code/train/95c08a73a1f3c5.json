{"cell_type":{"4d7dcef5":"code","27887eae":"code","340409d7":"code","51adcef3":"code","1dad1624":"code","9e1e5cbb":"code","c212e5ff":"code","8b75ac03":"code","70cbe1b1":"code","92065d9f":"code","0999dc55":"code","25f79425":"code","d4ccc306":"code","6e6aea19":"code","b03374dc":"code","17eb7d96":"markdown","24b5efc9":"markdown","ef390bbf":"markdown","d54cb794":"markdown","632a51f6":"markdown","55206a31":"markdown","b2deec74":"markdown","3106a6b4":"markdown","93c29dfa":"markdown","cf4db463":"markdown","ec190b5b":"markdown","8d47be06":"markdown"},"source":{"4d7dcef5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27887eae":"df=pd.read_csv(\"\/kaggle\/input\/hr-analytics\/HR_comma_sep.csv\")\ndf.head()","340409d7":"df.promotion_last_5years.value_counts()","51adcef3":"left_grp_mean=df.groupby('left').mean()\nleft_grp_mean","1dad1624":"X=df.groupby('left').get_group(1).salary.value_counts().index\nx=np.arange(len(X))\nplt.figure(figsize=(20,5))\nplt.bar(x+0.2,df.groupby('left').get_group(1).salary.value_counts().values,width=0.4,label='Resigned')\nplt.bar(x-0.2,df.groupby('left').get_group(0).salary.value_counts().values,width=0.4,label='Working')\nplt.xticks(x,X)\nplt.legend()\nplt.show()","9e1e5cbb":"X=df.groupby('left').get_group(1).Department.value_counts().index\nx=np.arange(len(X))\nplt.figure(figsize=(20,5))\nplt.bar(x+0.2,df.groupby('left').get_group(1).Department.value_counts().values,width=0.4,label='Resigned')\nplt.bar(x-0.2,df.groupby('left').get_group(0).Department.value_counts().values,width=0.4,label='Working')\nplt.xticks(x,X)\nplt.legend()\nplt.show()","c212e5ff":"model_df=df[['satisfaction_level','average_montly_hours','Work_accident','promotion_last_5years','salary']]\nmodel_df.head()","8b75ac03":"dummies=pd.get_dummies(df['salary'])\ndummies","70cbe1b1":"model_df=pd.concat([model_df,dummies],axis=1)\nmodel_df.head()","92065d9f":"model_df.drop(['salary','medium'],axis=1,inplace=True)\nmodel_df","0999dc55":"X=model_df\nY=df.left","25f79425":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.9)","d4ccc306":"from sklearn.linear_model import LogisticRegression\nreq=LogisticRegression()\nreq.fit(x_train,y_train)","6e6aea19":"req.predict(x_test)","b03374dc":"req.score(x_test,y_test)","17eb7d96":"> **lets quickly see the mean values for all the parameters grouped by whether they left or working**","24b5efc9":"> **Predincting Test Data**","ef390bbf":"> **Trainnig Model**","d54cb794":"> **Lets do a analysis on the salary of the employess lefted\/working**","632a51f6":"# So form the above Analysis we can conclude that the indepencent variables we can use for out Model will be:\n* satisfaction_level\n* average_montly_hours\n* Work_accident\n* promotion_last_5years\n* salary","55206a31":"> **Lets do encoding for the salary categories**","b2deec74":"# EDA of the Dataset","3106a6b4":"> **Department wise regined and working employees analysis**","93c29dfa":"**Now we will drop the 'medium' column for removing the encoding-trap and 'salary' columns as it's of no use now.**","cf4db463":"# Model Accuracy","ec190b5b":"# Lets Start Model Building","8d47be06":"> **Lets split the Dataset for training and Testing.**"}}