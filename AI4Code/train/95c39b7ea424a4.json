{"cell_type":{"d9d6bbb2":"code","94ee3d76":"code","744e3772":"code","2247974c":"code","cb41a380":"code","aa18e80f":"code","530efe64":"code","69f8c663":"code","69518ee5":"code","5a566154":"code","bb95e1e7":"code","c8843479":"code","4771e964":"code","f9e54b10":"code","1ae802af":"code","daf6c9a6":"code","81467b76":"code","5c8f0985":"code","1bdb5f13":"code","11be8a02":"code","336a70e7":"code","3b382343":"markdown","5e14ef11":"markdown"},"source":{"d9d6bbb2":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport shutil, os\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport cv2\nimport random\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nimport yaml\n\n# For running inference on the TF-Hub module.\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# For downloading the image.\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\n# For drawing onto the image.\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\n# For measuring the inference time.\nimport time","94ee3d76":"def display_image(image):\n  fig = plt.figure(figsize=(20, 15))\n  plt.grid(False)\n  plt.imshow(image)\n\n\ndef download_and_resize_image(url, new_width=256, new_height=256,\n                              display=False):\n  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n  response = urlopen(url)\n  image_data = response.read()\n  image_data = BytesIO(image_data)\n  pil_image = Image.open(image_data)\n  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n  pil_image_rgb = pil_image.convert(\"RGB\")\n  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n  print(\"Image downloaded to %s.\" % filename)\n  if display:\n    display_image(pil_image)\n  return filename\n\n\ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n  \"\"\"Adds a bounding box to an image.\"\"\"\n  draw = ImageDraw.Draw(image)\n  im_width, im_height = image.size\n  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                ymin * im_height, ymax * im_height)\n  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n             (left, top)],\n            width=thickness,\n            fill=color)\n\n  # If the total height of the display strings added to the top of the bounding\n  # box exceeds the top of the image, stack the strings below the bounding box\n  # instead of above.\n  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n  # Each display_str has a top and bottom margin of 0.05x.\n  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n  if top > total_display_str_height:\n    text_bottom = top\n  else:\n    text_bottom = top + total_display_str_height\n  # Reverse list and print from bottom to top.\n  for display_str in display_str_list[::-1]:\n    text_width, text_height = font.getsize(display_str)\n    margin = np.ceil(0.05 * text_height)\n    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                    (left + text_width, text_bottom)],\n                   fill=color)\n    draw.text((left + margin, text_bottom - text_height - margin),\n              display_str,\n              fill=\"black\",\n              font=font)\n    text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n  colors = list(ImageColor.colormap.values())\n\n  try:\n    font = ImageFont.truetype(\"\/usr\/share\/fonts\/truetype\/liberation\/LiberationSansNarrow-Regular.ttf\",\n                              25)\n  except IOError:\n    #print(\"Font not found, using default font.\")\n    font = ImageFont.load_default()\n\n  for i in range(min(boxes.shape[0], max_boxes)):\n    if scores[i] >= min_score:\n      ymin, xmin, ymax, xmax = tuple(boxes[i])\n      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                     int(100 * scores[i]))\n      color = colors[hash(class_names[i]) % len(colors)]\n      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n      draw_bounding_box_on_image(\n          image_pil,\n          ymin,\n          xmin,\n          ymax,\n          xmax,\n          color,\n          font,\n          display_str_list=[display_str])\n      np.copyto(image, np.array(image_pil))\n  return image","744e3772":"# By Heiko Gorski, Source: https:\/\/commons.wikimedia.org\/wiki\/File:Naxos_Taverna.jpg\nimage_url = \"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/60\/Naxos_Taverna.jpg\"  #@param\ndownloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)","2247974c":"module_handle = \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n# \"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\", \n# \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n\ndetector = hub.load(module_handle).signatures['default']","cb41a380":"def load_img(path):\n  img = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img, channels=3)\n  return img","aa18e80f":"def run_detector(detector, path):\n  img = load_img(path)\n\n  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n  #start_time = time.time()\n  result = detector(converted_img)\n  #end_time = time.time()\n\n  result = {key:value.numpy() for key,value in result.items()}\n\n  #print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n  #print(\"Inference time: \", end_time-start_time)\n\n  image_with_boxes = draw_boxes(\n      img.numpy(), result[\"detection_boxes\"],\n      result[\"detection_class_entities\"], result[\"detection_scores\"])\n\n  #display_image(image_with_boxes)\n  return image_with_boxes","530efe64":"image0=run_detector(detector, downloaded_image_path)\ndisplay_image(image0)","69f8c663":"# shutil.copytree, essential but can run only once\nif 'sample1' in os.listdir('\/kaggle\/working\/'):\n    print('exist1')\nelse:\n    shutil.copytree('\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/n02091244-Ibizan_hound', '\/kaggle\/working\/sample1')","69518ee5":"!mkdir sample2","5a566154":"data_dir='\/kaggle\/working\/sample1'\nfiles0=os.listdir(data_dir)\nprint(len(files0))\nN=list(range(len(files0)))\nrandom.seed(2021)\nrandom.shuffle(N)\nfiles=np.array(files0)","bb95e1e7":"data_dir2='\/kaggle\/working\/sample2'\nfor im in files[N[0:100]]:\n    path=os.path.join(data_dir,im)\n    image=run_detector(detector, path)\n    image2 = Image.fromarray(image)\n    image2.save(os.path.join(data_dir2,im))","c8843479":"#!rm -rf sample1","4771e964":"from matplotlib import animation, rc\nrc('animation', html='jshtml')","f9e54b10":"def create_animation(ims):\n    fig=plt.figure(figsize=(7,7))\n    #plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[5],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000)","1ae802af":"imgdir1 = data_dir2","daf6c9a6":"paths0=[]\nfor dirname, _, filenames in os.walk(imgdir1):\n    for filename in filenames:\n        paths0+=[os.path.join(dirname, filename)]     \npaths0[0:5]","81467b76":"paths1=[]\nfor item in paths0:\n    if item[-4:]=='.jpg':\n        paths1+=[item]\npaths1[0:5]","5c8f0985":"order=[]\nfor item in paths1:\n    order+=[int(item[0:-4].split('_')[-1])]\npaths2=pd.DataFrame(paths1)\npaths2[1]=order\npaths2.columns=['path','int']\npaths2=paths2.sort_values('int')\npaths3=paths2['path'].tolist()\npaths3[0:5]","1bdb5f13":"images0=[]\nfor i in tqdm(range(0,len(paths3),1)):\n    images0+=[cv2.imread(paths3[i])]","11be8a02":"print(len(images0))","336a70e7":"create_animation(np.array(images0))","3b382343":"# Object Detection TF-Hub\nhttps:\/\/github.com\/tensorflow\/hub\/blob\/master\/examples\/colab\/object_detection.ipynb","5e14ef11":"# Create animation"}}