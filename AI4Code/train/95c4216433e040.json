{"cell_type":{"6e93aac1":"code","7749caee":"code","71a5219b":"code","784bee7f":"code","696b3851":"code","2826eec4":"code","6b169b50":"code","0fd1e9a3":"code","af99ae82":"code","06268a1a":"code","110dc1a0":"code","e2982a93":"code","48657de7":"code","97ccf20e":"code","d59edce7":"code","2aa25a29":"code","0d8bf66e":"code","4a9131ea":"code","c01d96d2":"code","e8e03aa0":"code","fdb247a3":"code","13d543ca":"code","1ae754c3":"markdown","ab3d6501":"markdown","be14c607":"markdown","879a3fee":"markdown","e4211bce":"markdown","70e719fd":"markdown","7065e070":"markdown","d8419167":"markdown","202cf13d":"markdown"},"source":{"6e93aac1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7749caee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nfrom imblearn.over_sampling import SMOTE\nimport seaborn as sns\nimport scikitplot as skplt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n\n\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","71a5219b":"dataset = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\n#Explore data\ndataset = pd.DataFrame(dataset)\n","784bee7f":"dataset.info()\ndataset.drop(columns=['id']).describe()","696b3851":"#\u6258\u66fc\u00b7\u5eb7\u65af\u5766\u4e01\uff08Thoman Konstantin\uff09\u63d0\u4f9bhttps\uff1a\/\/www.kaggle.com\/thomaskonstantin\/analyzing-and-modeling-stroke-data\nDT_bmi_pipe = Pipeline( steps=[ \n                               ('scale',StandardScaler()),\n                               ('lr',DecisionTreeRegressor(random_state=42))\n                              ])\nX = dataset[['age','gender','bmi']].copy()\nX.gender = X.gender.replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\n\nMissing = X[X.bmi.isna()]\nX = X[~X.bmi.isna()]\nY = X.pop('bmi')\nDT_bmi_pipe.fit(X,Y)\npredicted_bmi = pd.Series(DT_bmi_pipe.predict(Missing[['age','gender']]),index=Missing.index)\ndataset.loc[Missing.index,'bmi'] = predicted_bmi\nprint('Missing values: ',sum(dataset.isnull().sum()))","2826eec4":"dataset.info()","6b169b50":"dataset = dataset.drop(columns=['id'])\nfor i in range(len(dataset.index)): #bmi\n    if dataset.iloc[i, 8] < 18.5:\n        dataset.iloc[i, 8] = 'Underweight'\n    elif dataset.iloc[i, 8] < 24.0 and dataset.iloc[i, 8] >= 18.5:\n        dataset.iloc[i, 8] = 'Normal weight'\n    elif dataset.iloc[i, 8] < 30.0 and dataset.iloc[i, 8] >= 24.0:\n        dataset.iloc[i, 8] = 'Overweight'\n    else:\n        dataset.iloc[i, 8] = 'Obese'\n\nfor i in range(len(dataset.index)):\n    if dataset.iloc[i, 7] < 100.0:\n        dataset.iloc[i, 7] = 'Normal'\n    elif dataset.iloc[i, 7] >= 100.0 and dataset.iloc[i, 7] < 125.0:\n        dataset.iloc[i, 7] = 'Prediabetes'\n    else:\n        dataset.iloc[i, 7] = 'Diabetes'","0fd1e9a3":"dataset.head()","af99ae82":"le = LabelEncoder()\n# dataset_fit = dataset.drop(columns=['age'])\ndataset_fit = dataset.apply(le.fit_transform)\n# dataset_fit.loc[:,'age'] = dataset['age']\ndataset_fit.head()","06268a1a":"import plotly.express as px\ncorr_num = dataset_fit.corr()\n# print(corr_num)\ncorr_matrix = pd.DataFrame(corr_num)\nstroke_corr = corr_num.loc[\"stroke\"]\nprint(\"stroke_corr \\n\",stroke_corr.sort_values())\npx.imshow(corr_matrix)","110dc1a0":"pd.DataFrame(dataset_fit)\ndataset_fit.describe()","e2982a93":"str_only = dataset_fit[dataset_fit['stroke'] == 1]\nno_str_only = dataset_fit[dataset_fit['stroke'] == 0]","48657de7":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(3, 2)\ngs.update(wspace=0.35, hspace=0.35)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1, 1])\nax4 = fig.add_subplot(gs[2, 0])\nax5 = fig.add_subplot(gs[2, 1])\n\nbackground_color = \"#ffffff\"\ncolor_y = '#0d7aff' #\u85cd\u4e2d\u98a8\ncolor_n = '#ffa230' #\u6a58\u7121\u4e2d\u98a8\nfig.patch.set_facecolor(background_color) \nax0.set_facecolor(background_color) \nax1.set_facecolor(background_color) \nax2.set_facecolor(background_color)\nax3.set_facecolor(background_color) \nax4.set_facecolor(background_color) \nax5.set_facecolor(background_color) \n\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    ax4.spines[s].set_visible(False)\n    ax5.spines[s].set_visible(False)\n\n## Age\n\ntemp_df = pd.DataFrame(str_only[\"age\"])\nno_temp_df = pd.DataFrame(no_str_only[\"age\"])\nsns.kdeplot(temp_df[\"age\"], ax=ax0,color=color_y, shade=True)\nsns.kdeplot(no_temp_df[\"age\"], ax=ax0, color=color_n, shade=True)\nax0.yaxis.set_major_locator(mtick.MultipleLocator(2))\nax0.set_ylabel('')    \nax0.set_xlabel('')\n\n# heart_disease\n\ntemp_df = pd.DataFrame(str_only[\"heart_disease\"].value_counts())\ntemp_df[\"Percentage\"] = temp_df[\"heart_disease\"].apply(lambda x: x\/sum(temp_df[\"heart_disease\"])*100)\nno_temp_df = pd.DataFrame(no_str_only[\"heart_disease\"].value_counts())\nno_temp_df[\"Percentage\"] = no_temp_df[\"heart_disease\"].apply(lambda x: x\/sum(no_temp_df[\"heart_disease\"])*100)\n\nx = np.arange(len(temp_df))\nax1.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nax1.bar(x, height=temp_df[\"Percentage\"], zorder=3, color=color_y, width=0.4)\nax1.bar(x+0.4, height=no_temp_df[\"Percentage\"], zorder=3, color=color_n, width=0.4)\nax1.set_xticks(x + 0.4 \/ 2)\nax1.set_xticklabels(['No History','History'])\nax1.yaxis.set_major_formatter(mtick.PercentFormatter())\nax1.yaxis.set_major_locator(mtick.MultipleLocator(20))\nfor i,j in zip([0, 1], temp_df[\"Percentage\"]):\n    ax1.annotate(f'{j:0.0f}%',xy=(i, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\nfor i,j in zip([0, 1], no_temp_df[\"Percentage\"]):\n    ax1.annotate(f'{j:0.0f}%',xy=(i+0.4, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\n    \n# hypertension\n\ntemp_df = pd.DataFrame(str_only[\"hypertension\"].value_counts())\ntemp_df[\"Percentage\"] = temp_df[\"hypertension\"].apply(lambda x: x\/sum(temp_df[\"hypertension\"])*100)\n\nno_temp_df = pd.DataFrame(no_str_only[\"hypertension\"].value_counts())\nno_temp_df[\"Percentage\"] = no_temp_df[\"hypertension\"].apply(lambda x: x\/sum(no_temp_df[\"hypertension\"])*100)\n\nx = np.arange(len(temp_df))\n\nax2.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nax2.bar(x, height=temp_df[\"Percentage\"], zorder=3, color=color_y, width=0.4)\nax2.bar(x+0.4, height=no_temp_df[\"Percentage\"], zorder=3, color=color_n, width=0.4)\nax2.set_xticks(x + 0.4 \/ 2)\nax2.set_xticklabels(['No History','History'])\nax2.yaxis.set_major_formatter(mtick.PercentFormatter())\nax2.yaxis.set_major_locator(mtick.MultipleLocator(20))\nfor i,j in zip([0, 1], temp_df[\"Percentage\"]):\n    ax2.annotate(f'{j:0.0f}%',xy=(i, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\n\nfor i,j in zip([0, 1], no_temp_df[\"Percentage\"]):\n    ax2.annotate(f'{j:0.0f}%',xy=(i+0.4, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\n\n# ever_married\ntemp_df = pd.DataFrame(str_only[\"ever_married\"].value_counts())\ntemp_df[\"Percentage\"] = temp_df[\"ever_married\"].apply(lambda x: x\/sum(temp_df[\"ever_married\"])*100)\n\nno_temp_df = pd.DataFrame(no_str_only[\"ever_married\"].value_counts())\nno_temp_df[\"Percentage\"] = no_temp_df[\"ever_married\"].apply(lambda x: x\/sum(no_temp_df[\"ever_married\"])*100)\n\nx = np.arange(len(temp_df))\n\n\nax3.grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nax3.bar(x, height=temp_df[\"Percentage\"], zorder=3, color=color_y, width=0.4)\nax3.bar(x+0.4, height=no_temp_df[\"Percentage\"], zorder=3, color=color_n, width=0.4)\nax3.set_xticks(x + 0.4 \/ 2)\nax3.set_xticklabels(['No Married','Married'])\nax3.yaxis.set_major_formatter(mtick.PercentFormatter())\nax3.yaxis.set_major_locator(mtick.MultipleLocator(10))\nfor i,j in zip([0, 1], temp_df[\"Percentage\"]):\n    ax3.annotate(f'{j:0.0f}%',xy=(i, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\nfor i,j in zip([0, 1], no_temp_df[\"Percentage\"]):\n    ax3.annotate(f'{j:0.0f}%',xy=(i+0.4, j\/2), color=background_color, horizontalalignment='center', verticalalignment='center')\n\n\n# smoking_status\ntemp_df = pd.DataFrame(str_only[\"smoking_status\"].value_counts())\ntemp_df[\"Percentage\"] = temp_df[\"smoking_status\"].apply(lambda x: x\/sum(temp_df[\"smoking_status\"])*100)\nno_temp_df = pd.DataFrame(no_str_only[\"smoking_status\"].value_counts())\nno_temp_df[\"Percentage\"] = no_temp_df[\"smoking_status\"].apply(lambda x: x\/sum(no_temp_df[\"smoking_status\"])*100)\n\n\nax4.barh(temp_df.index, temp_df['Percentage'], color=color_y, zorder=3, height=0.7)\nax4.barh(no_temp_df.index, no_temp_df['Percentage'], color=color_n, zorder=3, height=0.3)\nax4.xaxis.set_major_formatter(mtick.PercentFormatter())\nax4.xaxis.set_major_locator(mtick.MultipleLocator(10))\n\n\n# bmi\n\ntemp_df = pd.DataFrame(str_only[\"bmi\"].value_counts())\ntemp_df[\"Percentage\"] = temp_df[\"bmi\"].apply(lambda x: x\/sum(temp_df[\"bmi\"])*100)\nno_temp_df = pd.DataFrame(no_str_only[\"bmi\"].value_counts())\nno_temp_df[\"Percentage\"] = no_temp_df[\"bmi\"].apply(lambda x: x\/sum(no_temp_df[\"bmi\"])*100)\n\n\nax5.barh(temp_df.index, temp_df['Percentage'], color=color_y, zorder=3, height=0.7)\nax5.barh(no_temp_df.index, no_temp_df['Percentage'], color=color_n, zorder=3, height=0.3)\nax5.xaxis.set_major_formatter(mtick.PercentFormatter())\nax5.xaxis.set_major_locator(mtick.MultipleLocator(10))\n\n\n\n#text\n\nfont_size = 16\nfont_weight = 'bold'\nfont_family =  'Arial'\nax0.text(-22, 0.041, 'Age', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\nax1.text(-0.4, 110, 'Heart Disease', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\nax2.text(-0.4, 100, 'Hypertension', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\nax3.text(-0.4, 100, 'Ever Married', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\n\nax4.text(-3, 3.5, 'Smoking Status', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\n\nax5.text(-3, 3.5, 'bmi', fontsize=font_size ,fontweight=font_weight,fontfamily=font_family)\n\n\n\nplt.show()","97ccf20e":"dataset_fit['stroke'].value_counts()","d59edce7":"X  = dataset_fit[['age','heart_disease','hypertension','ever_married','smoking_status','bmi']]\ny = dataset_fit['stroke']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nsm = SMOTE()\nX_train_resh, y_train_resh = sm.fit_resample(X_train, y_train.ravel())\nX_test_resh, y_test_resh = sm.fit_resample(X_test, y_test.ravel())","2aa25a29":"svm_pipeline = Pipeline(steps = [('SVM',SVC(random_state=42))])\n\nrf_pipeline = Pipeline(steps = [('RF',RandomForestClassifier(random_state=42))])\n\nDT_pipeline = Pipeline(steps = [('DT',DecisionTreeClassifier(random_state=42))])\n\nXGB_pipeline = Pipeline(steps = [('XGB',XGBClassifier(random_state=42))])","0d8bf66e":"svm_pipeline_mean = cross_val_score(svm_pipeline,X_train_resh,y_train_resh,scoring='f1').mean()\n\nrf_pipeline_mean = cross_val_score(rf_pipeline,X_train_resh,y_train_resh,scoring='f1').mean()\n\nDT_pipeline_mean = cross_val_score(DT_pipeline,X_train_resh,y_train_resh,scoring='f1').mean()\n\nXGB_pipeline_mean = cross_val_score(XGB_pipeline,X_train_resh,y_train_resh,scoring='f1').mean()","4a9131ea":"svm_pipeline_mean_cv = cross_val_score(svm_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean()\n\nrf_pipeline_mean_cv = cross_val_score(rf_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean()\n\nDT_pipeline_mean_cv = cross_val_score(DT_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean()\n\nXGB_pipeline_mean_cv = cross_val_score(XGB_pipeline,X_train_resh,y_train_resh,cv=10,scoring='f1').mean()","c01d96d2":"print('Mean f1 scores:')\nprint('SVM mean :',svm_pipeline_mean)\nprint('Random Forest mean :',rf_pipeline_mean)\nprint('DecisionTreeClassifier mean :',DT_pipeline_mean)\nprint('XGBoost mean :',XGB_pipeline_mean)","e8e03aa0":"print('Mean f1 scores(After cv = 10):')\nprint('SVM mean :',svm_pipeline_mean_cv)\nprint('Random Forest mean :',rf_pipeline_mean_cv)\nprint('DecisionTreeClassifier mean :',DT_pipeline_mean_cv)\nprint('XGBoost mean :',XGB_pipeline_mean_cv)","fdb247a3":"n_estimators =[64,100,128]\nmax_features = ['auto',2,3,5,7]\nbootstrap = [True,False]\n\nparam_grid = {'n_estimators':n_estimators,\n             'max_features':max_features,\n             'bootstrap':bootstrap}\nrfc = RandomForestClassifier()\ngrid = GridSearchCV(rfc,param_grid)\n\ngrid.fit(X_train_resh, y_train_resh)\ngrid.best_params_","13d543ca":"rf4 = RandomForestClassifier(bootstrap = True, max_features = 'auto', n_estimators = 128)\nrf4.fit(X_train_resh, y_train_resh)\npredprob4 = rf4.predict(X_test)\nrf4_f10  = f1_score(y_test,predprob4)\nprint('RF mean :',rf4_f10)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,predprob4))","1ae754c3":"\u627e\u5c0b\u6700\u4f73\u53c3\u6578","ab3d6501":"# \u8cc7\u6599\u67e5\u770b","be14c607":"# \u8cc7\u6599\u7f3a\u5931","879a3fee":"\u4ea4\u53c9\u9a57\u8b4910\u6b21","e4211bce":"\u4ea4\u53c9\u9a57\u8b49","70e719fd":"# \u8a13\u7df4","7065e070":"\n\n# \u8a13\u7df4\u96c6\u5206\u5272","d8419167":"\u5f9e\u7de8\u865f\u7b2c8\u5217\u53ef\u4ee5\u770b\u51fabmi\u662f\u6709\u7f3a\u5c11\u8cc7\u6599\u7684\u72c0\u6cc1","202cf13d":"# Random Forest"}}