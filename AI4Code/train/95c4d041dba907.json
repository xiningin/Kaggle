{"cell_type":{"641c24b5":"code","68c3c97a":"code","d5dcb503":"code","5becf0f3":"code","c597d40b":"code","00a35674":"code","ceae73e4":"code","67f856a3":"code","313685e1":"code","c3d0c135":"code","82dad80c":"code","bbc091c2":"code","fff69c22":"code","747c7ddb":"code","cc138aee":"code","a0de4c5d":"code","b6e033cf":"code","b71f0538":"code","c9ab5ce3":"code","1424bf82":"code","c79c2a41":"code","eb85092e":"code","3c5f22ae":"code","602abab3":"code","993ff66a":"code","afdd3c46":"code","ccbc64d6":"code","dbd7fa31":"code","f036813b":"code","62e7ab53":"code","6c4cb2e0":"code","1fceb2ed":"code","050050bc":"code","b105fadf":"code","9e83a1c1":"code","8630f3ed":"code","aace0098":"code","3dc6d871":"code","17141924":"code","65f93d15":"code","2af92d0e":"code","1ea7d0f0":"code","eb05cbcc":"code","a56ae0da":"code","63e6f75b":"code","2d5699aa":"code","43e5f91a":"code","e9abb3a0":"code","ab8773a5":"code","2ecad7be":"code","a4bb92a0":"code","3ae45750":"code","7b3e4654":"code","4aea6505":"code","94d804ca":"code","796b69a5":"code","9864d126":"code","8a3d7e75":"code","dc7bda35":"code","9fa7e4c1":"code","d2919bb5":"code","66109d7f":"code","b53e6f52":"code","48ce710c":"code","8a9467b3":"code","dbaef6a0":"code","b613b313":"code","86c0a2c6":"code","75269879":"code","3775dc79":"code","19657ab4":"code","bfca1eef":"code","91221378":"code","3c42063d":"code","3fdf44bd":"code","4e7edc92":"code","65ea1aa9":"code","13f4a9e2":"code","9543a360":"code","a655bf8c":"code","2e721463":"code","7a2fe640":"code","736543db":"code","31ca8ab9":"code","fc5a9cce":"code","330cd8c0":"code","b51003d5":"code","c8da6897":"code","49049664":"code","c99644c2":"code","95ce8743":"code","a0171d16":"code","40300820":"code","2eca8f11":"code","ef517f99":"code","850c436a":"code","d7fa375a":"code","7f8a59e5":"code","e13c23a2":"code","8c20e55e":"code","560945bf":"code","b9242165":"markdown","dadd7f96":"markdown","d510d821":"markdown","adb005bf":"markdown","7556eb37":"markdown","00c9f428":"markdown","f6966256":"markdown","8c668210":"markdown","6ddb116c":"markdown","2d14032c":"markdown","e7d4dd03":"markdown","03eb4484":"markdown","5aab6d10":"markdown","29269533":"markdown","b8f3518f":"markdown","691d448f":"markdown","8b5899ea":"markdown","20a26161":"markdown","4e57ba78":"markdown","432276db":"markdown","5e4943a0":"markdown","984390fb":"markdown","666907bb":"markdown","0870c6e8":"markdown","877cae9d":"markdown","3cfc2ee7":"markdown","232c1dce":"markdown","56085f21":"markdown","781395f7":"markdown","c0a799d9":"markdown","a0054831":"markdown","a0277b8b":"markdown","ac4a8fd1":"markdown","e7fafec4":"markdown","f193f5c8":"markdown","90334920":"markdown","6f9cc9cd":"markdown","cd04667a":"markdown","9270b8d2":"markdown","a77f5474":"markdown","73e7e2ae":"markdown","48bc197d":"markdown","07632943":"markdown","d27b0466":"markdown","dc63838d":"markdown","9af76a68":"markdown","4427c87b":"markdown"},"source":{"641c24b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","68c3c97a":"data = pd.read_csv('..\/input\/2017.csv')\n","d5dcb503":"data.info()","5becf0f3":"data.columns=['Country','Happiness_Rank', 'Happiness_Score', 'Whisker_high',\n       'Whisker_low', 'Economy_GDP_per_Capita', 'Family',\n       'Health_Life_Expectancy', 'Freedom', 'Generosity',\n       'Trust_Government_Corruption', 'Dystopia_Residual']\ndata.corr()\n","c597d40b":"# correlation\nf,ax = plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot= True,linewidths= 5, fmt='.1f',ax=ax)\nplt.show()","00a35674":"data.Family.plot(kind='line',color='g',grid=True,label='Family',alpha=0.5,linewidth=1,linestyle=':')\ndata.Freedom.plot(color='r',grid=True,alpha=0.5,label='Freedom',linewidth=1,linestyle='-')  \nplt.legend()\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line Plot ')\nplt.show()","ceae73e4":"Scatter Plots","67f856a3":"plt.scatter(data.Family,data.Freedom,color='b',alpha=0.5)\nplt.xlabel('Family')\nplt.ylabel('Freedom')\nplt.title('Family Freedom Scatter Plot')\nplt.show()","313685e1":"data.plot(kind='scatter',x='Family',y='Freedom',color='r',alpha=0.5)\n\nplt.show()","c3d0c135":"data.columns","82dad80c":"data.Health_Life_Expectancy.plot(kind='hist',bins=50,figsize=(12,12))\nplt.show()\n","bbc091c2":"data.Health_Life_Expectancy.plot(kind='hist',bins=50,figsize=(12,12))\nplt.clf() # clears the method","fff69c22":"dictionary = {'galatasaray':'taffarel','fenerbah\u00e7e':'volkan','be\u015fikta\u015f':'r\u00fc\u015ft\u00fc','trabzonspor':'\u015fenol'}\n# print(dictionary)\nprint(dictionary.keys())\nprint(dictionary.values())","747c7ddb":"# changing the value\ndictionary['galatasaray']='muslera'\nprint(dictionary)\n# adding a new entry\ndictionary['juventus']='ronaldo'\nprint(dictionary)\n# remove entry\n#del dictionary['juventus']\nprint(dictionary)\nprint('trabzonspor' in dictionary)\n#dictionary.clear\n#print(dictionary)\n","cc138aee":"data = pd.read_csv('..\/input\/2017.csv')\n","a0de4c5d":"series = data['Economy..GDP.per.Capita.']\nprint(type(series))\ndf = data[['Economy..GDP.per.Capita.']]\nprint(type(df))","b6e033cf":"# comparison operator\nprint(3 > 1)\nprint(3!=1)\n# Boolean operators\nprint(True and False)\nprint(True and False and True and True and True and True)\nprint(True or False)\nprint(True and False and True and False or True)\n\n","b71f0538":"# 1-)Filtering pandas data frame\nx = data['Family']>1.3\ndata[x]","c9ab5ce3":"# 2-) Filtering pandas with logical_and or logical_or\ndata[np.logical_or(data['Family']>1.3,data['Happiness.Score']>7)]","1424bf82":"# also could be written as :\ndata[(data['Family']>1.5) | (data['Happiness.Score']>7)]","c79c2a41":"i = 0\nwhile i !=10:\n    print('i is :',i)\n    i = i + 1\nprint(i,' is equal to 10')","eb85092e":"liste = [1,2,3,4,5,6,7,8,9,10]\nfor a in liste:\n    print('a is :',a)\nprint('')\n\nfor index,values in enumerate(liste):\n    print(index,':',values)\nprint('')\n\ndictionary ={'gs':'muslera','fb':'volkan','bjk':'fabri'}\nprint(dictionary)\nfor keys,values in dictionary.items():\n    print(keys,':',values)\nprint('')\nfor index,values in data[['Family']][75:101].iterrows():\n    print(index,':',values)\n","3c5f22ae":"def tuble_ex():\n    \"\"\"return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)\n","602abab3":"x = 5  # global scope\ndef f():\n    x = 3   # local scope\n    return x\nprint(x)      # x = 5 global scope\nprint(f())    # x = 3 local scope","993ff66a":"# if there is no local scope\n# it uses global scope x\nx = 5\ndef f():\n    y = x*2\n    return y\nprint(f())\n","afdd3c46":"# if both does not exist built in scope is seached\nimport builtins\ndir(builtins)","ccbc64d6":"# nested function\ndef square():\n    \"\"\" return square of value\"\"\"\n    def add():\n        \"\"\" add two local variable\"\"\"\n        x = 2\n        y = 3\n        z = x+y\n        return z\n    return add()**2\nprint(square())\n","dbd7fa31":"# default arguments\ndef f(a,b=1,c=2):\n    y = a + b +c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nf(5,4,3)\n","f036813b":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\"print key and value of dictionary\"\"\"\n    for keys,values in kwargs.items():\n        print(keys,':',values)\nf(country='spain',capital='madrid',population=123456)\n\n","62e7ab53":"# lambda function\nsquare = lambda x: x**2  \nprint(square(4))\ntot = lambda x,y,z : x+y+z\nprint(tot(1,2,3))","6c4cb2e0":"number_list = [5,7,3,865,55]\ny = map(lambda x: x**3,number_list)\nprint(list(y))\n","1fceb2ed":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i**6+30 for i in num1]\nprint(num2)","050050bc":"# Conditionals on iterable\nnum1 = [3,13,21,65]\nnum2 = [i*18 if i<13 else i**2 if i>=13 and i<22 else i**(1\/2) for i in num1]\nprint(num2)","b105fadf":"mean_1 = sum(data.Health_Life_Expectancy)\/(len(data.Health_Life_Expectancy))\nprint(mean_1)\ndata['Health_Life_Expectancy_Level'] = ['high' if i >= mean_1 else 'low' for i in data.Health_Life_Expectancy] \ndata.loc[:200,['Health_Life_Expectancy_Level','Health_Life_Expectancy']]","9e83a1c1":"data = pd.read_csv('..\/input\/2017.csv')\ndata.head()","8630f3ed":"data.columns = ['Country','Happiness.Rank','Happiness.Score','Whisker.high','Whisker.low','Economy.GDP.per.Capita','Family','Health.Life.Expectancy','Freedom','Generosity','Trust.Government.Corruption','Dystopia.Residual']\ndata.columns","aace0098":"data.tail(10)","3dc6d871":"data.shape","17141924":"data.info()","65f93d15":"data.describe()","2af92d0e":"print(data['Happiness.Score'].value_counts(dropna=False)) # if there is non values that is also be counted","1ea7d0f0":"data.describe()","eb05cbcc":"data_new = data.head()\ndata_new","a56ae0da":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\ndata_new = data.tail(10)\nmelted = pd.melt(frame=data_new,id_vars='Country',value_vars=['Whisker.high','Whisker.low'])\nmelted","63e6f75b":"# Index is country\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Country',columns='variable',values='value')\n","2d5699aa":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row","43e5f91a":"data1 = data['Health.Life.Expectancy'].head()\ndata2 = data['Trust.Government.Corruption'].head()\nconc_data_col = pd.concat([data1,data2],axis=1)\nconc_data_col","e9abb3a0":"data.dtypes","ab8773a5":"data.info()","2ecad7be":"data['Family'].value_counts(dropna=False)","a4bb92a0":"data1 = data\ndata1['Family'].dropna(inplace=True)","3ae45750":"assert 1==1","7b3e4654":"data[\"Family\"].fillna('empty',inplace = True)\n","4aea6505":"assert  data['Family'].notnull().all()","94d804ca":"### dataframes from dictionary\ncountry = ['Turkey','Azerbeycan','Germany']\ncapital = ['Ankara','Bak\u00fc','Berlin']\nliste_row = ['Country','Capital']\nliste_col = [country,capital]\nzipped = list(zip(liste_row,liste_col))\ndictionary = dict(zipped)\ndf = pd.DataFrame(dictionary)\ndf","796b69a5":"# add new columns\ndf['Population'] = [200,100,150]\ndf\n","9864d126":"# broadcasting\ndf['Income']=0\ndf\n","8a3d7e75":"# plotting all data\ndata1 = data.loc[:,['Family','Health.Life.Expectancy','Generosity']]\ndata1.plot()\nplt.show()","dc7bda35":"# subplots\ndata1.plot(subplots=True)\nplt.show()","9fa7e4c1":"# scatter plot\ndata1.plot(kind='scatter',x='Family',y='Generosity')\nplt.show()","d2919bb5":"# hist plot\ndata1.plot(kind='hist',y='Family',bins=50,range=(0,155),normed=True)\nplt.show()","66109d7f":"# histogram subplot with non cumulative and cumulative \nfig,axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind='hist',y='Family',bins=50,range=(0,100),normed=True,ax=axes[0])\ndata1.plot(kind = \"hist\",y = \"Family\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt\n","b53e6f52":"data.describe()","48ce710c":"time_list = ['1992-03-08','1992-04-12']\nprint(type(time_list[1])) # as we can see date is string\n# however we want it to be datetime object\ndatatime_object = pd.to_datetime(time_list)\nprint(type(datatime_object))","8a9467b3":"# close warning\nimport warnings\nwarnings.filterwarnings('ignore')\n# lets practise\ndata2 = data.head()\ndate_list = ['1992-01-10','1992-02-10','1992-03-10','1993-03-15','1993-03-16']\ndate_datetime = pd.to_datetime(date_list)\ndata2['data'] = date_datetime\ndata2 = data2.set_index('data')\ndata2","dbaef6a0":"# Now we can select according to our date index\nprint(data2.loc['1993-03-16'])\nprint(data2.loc['1992-03-10':'1993-03-16'])","b613b313":"# We will use data2 that we create at previous part\ndata2.resample('A').mean() # resample about years","86c0a2c6":"data2.resample('M').mean() # resample about months\n# As you can see there are a lot of nan because data2 does not include all months","75269879":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample('M').first().interpolate('linear')","3775dc79":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","19657ab4":"# read data\ndata = pd.read_csv('..\/input\/2017.csv')\ndata = data.set_index('Country')\ndata.head()","bfca1eef":"# indexing using square brackets\ndata['Health..Life.Expectancy.'][153]","91221378":"# using column attribute and row label\ndata.Family[0]","3c42063d":"# using loc accessor\ndata.loc['Netherlands','Family']","3fdf44bd":"# Selecting only some columns\ndata[['Whisker.high','Whisker.low']]","4e7edc92":"# Difference between selecting columns: series and dataframes\nprint(type(data['Freedom'])) # series\nprint(type(data[['Freedom','Trust..Government.Corruption.']])) # DataFrame","65ea1aa9":"# Slicing and indexing series\ndata.loc['Australia':'Chile','Family':'Freedom']","13f4a9e2":"data.loc['Chile':'Australia':-1,'Family':'Freedom']","9543a360":"# From something to end\ndata.loc['Mali','Whisker.high':]","a655bf8c":"# Creating boolean series\nboolean = data.Family>1.5\ndata[boolean]","2e721463":"# Combining filters\nfirst_filter = data['Economy..GDP.per.Capita.']>1.3\nsecond_filter = data['Health..Life.Expectancy.']>0.85\ndata[first_filter & second_filter]","7a2fe640":"# Filtering column based others\ndata.Family[data.Generosity>0.5]","736543db":"# Plain python functions\ndef sum(x):\n    return x+5\ndata['Whisker.high'].apply(sum)\n    ","31ca8ab9":"# Or we can use lambda function\ndata['Whisker.high'].apply(lambda x:x+5)","fc5a9cce":"# Defining column using other columns\ndata['total_power'] = data['Happiness.Score']*data['Freedom']\ndata.head()","330cd8c0":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = 'Countries'\ndata.head()","b51003d5":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/2017.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","c8da6897":"# Setting index : Country is outer Happiness.Rank is inner index\ndata1 = data.set_index(['Country','Happiness.Rank'])\ndata1.head(100)\n# data1.loc[\"Iceland\",\"Family\"] # how to use indexes","49049664":"dic = {'treatment':['A','A','B','B'],'gender':['F','M','F','M'],'response':[10,45,5,9],'age':[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","c99644c2":"# pivoting\ndf.pivot(index='treatment',columns='gender',values='response')","95ce8743":"df1 = df.set_index(['treatment','gender'])\ndf1\n# lets unstack it","a0171d16":"# level determines indexes\ndf1.unstack(level=0)","40300820":"df1.unstack(level=1)","2eca8f11":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","ef517f99":"df","850c436a":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(frame=df,id_vars='treatment',value_vars=['response','age'])","d7fa375a":"df","7f8a59e5":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","e13c23a2":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","8c20e55e":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","560945bf":"df.info()","b9242165":"Dictionary","dadd7f96":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data\n","d510d821":"<a id=\"15\"><\/a> <br>\n### LIST COMPREHENS\u0130ON\n**One of the most important topic of this kernel**\n<br>We use list comprehension for data analysis often. c\n<br> list comprehension: collapse for loops for building lists into a single line\n<br>Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is  unnecessarily long. We can make it one line code that is list comprehension.","adb005bf":"<a id=\"16\"><\/a> <br>\n# 3.CLEANING DATA","7556eb37":"<a id=\"30\"><\/a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","00c9f428":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","f6966256":"<a id=\"9\"><\/a> <br>\n### SCOPE","8c668210":"# DATA SCIENTIST\n**In this tutorial, I only explain you what you need to be a data scientist neither more nor less.**\n\nData scientist need to have these skills:\n\n1. Basic Tools: Like python, R or SQL. You do not need to know everything. What you only need is to learn how to use **python**\n2. Basic Statistics: Like mean, median or standart deviation. If you know basic statistics, you can use **python** easily. \n3. Data Munging(datay\u0131 d\u00fczeltme): Working with messy and difficult data. Like a inconsistent date and string formatting. As you guess, **python** helps us.\n4. Data Visualization: Title is actually explanatory. We will visualize the data with **python** like matplot and seaborn libraries.\n5. Machine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using **python**.","6ddb116c":"<a id=\"1\"><\/a> <br>\n# 1. INTRODUCTION TO PYTHON","2d14032c":"Histogram is used like:","e7d4dd03":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","03eb4484":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing","5aab6d10":"<a id=\"8\"><\/a> <br>\n### USER DEFINED FUNCTION","29269533":"-global scope : defined in script\n-local scope : defined in a function\n-built in scope : names in predefined\nsuch as len,print","b8f3518f":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n","691d448f":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","8b5899ea":" OR Scatter plot is used like:","20a26161":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","4e57ba78":"Line Plot","432276db":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","5e4943a0":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)","984390fb":"While and For Loops","666907bb":"<a id=\"11\"><\/a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n* Default argument example:\n<br> def f(a, b=1):\n      \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example:\n<br> def f(*args):\n       \"\"\" *args can be one or more\"\"\"\n<br>def f(** kwargs)\n       \"\"\" **kwargs is a dictionary\"\"\"\n","0870c6e8":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","877cae9d":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting","3cfc2ee7":"Pandas\n","232c1dce":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","56085f21":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others","781395f7":"<a id=\"10\"><\/a> <br>\n### NESTED FUNCTION\n* function inside function.","c0a799d9":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","a0054831":"<a id=\"42\"><\/a> <br>\n### The End\n### Powered by Mehmet Salih \u00dcnal","a0277b8b":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end","ac4a8fd1":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool","e7fafec4":"Also, you can clear the histogram plot with:","f193f5c8":"Logic, Control flow and Filtering\n","90334920":"<a id=\"29\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","6f9cc9cd":"<a id=\"7\"><\/a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX","cd04667a":"<a id=\"13\"><\/a> <br>\n### ANONYMOUS FUNCT\u0130ON\nLike lambda function but it can take more than one arguments.\n* map(func,seq) : applies a function to all the items in a list\n","9270b8d2":"<a id=\"12\"><\/a> <br>\n### LAMBDA FUNCTION\nFaster way of writing function","a77f5474":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","73e7e2ae":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","48bc197d":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","07632943":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","d27b0466":"<a id=\"32\"><\/a> <br>\n# 5)MANIPULATING DATA FRAMES WITH PANDAS","dc63838d":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","9af76a68":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label\n","4427c87b":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."}}