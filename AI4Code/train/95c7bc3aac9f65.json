{"cell_type":{"c6717e73":"code","e934b663":"code","5a535cbd":"code","067236ab":"code","da820cb0":"code","53873420":"code","e6fdba27":"code","f83bc073":"code","a00ce8a7":"code","a827f39e":"code","4bef12d4":"code","f9402f34":"code","d6b9a96b":"code","dc7239e8":"code","ea0fbb13":"code","ce447092":"code","4cf7d23b":"code","3e02a298":"code","07aee321":"code","e542b25c":"code","7cd50a41":"code","9bb41228":"code","0a5067d1":"code","61b49591":"code","775edaaf":"code","5920441e":"code","16329393":"code","b55b739d":"code","0bde86ae":"code","f2e166e3":"code","e128e937":"code","5194fc3f":"code","78067ec4":"code","53fa0535":"code","b5504473":"code","cd576784":"code","f24e5128":"code","a0e34980":"code","afc7e6ce":"code","e525105f":"markdown","7a190abc":"markdown"},"source":{"c6717e73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e934b663":"\nfeatures = pd.read_csv(\"\/kaggle\/input\/walmart-sales-prediction\/features.csv\")\nstores = pd.read_csv(\"\/kaggle\/input\/walmart-sales-prediction\/stores.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/walmart-sales-prediction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/walmart-sales-prediction\/test.csv\")","5a535cbd":"print(\"Features shape is {}\".format(features.shape))\nprint(\"Stores shape is {}\".format(stores.shape))\nprint(\"Train shape is {}\".format(train.shape))\nprint(\"Test shape is {}\".format(test.shape))","067236ab":"train.head(3)","da820cb0":"test.head(3)","53873420":"features.head(3)","e6fdba27":"stores.head(3)","f83bc073":"train_df = train.merge(features,how=\"left\",on=['Store','Date','IsHoliday']).merge(stores,how='left',on='Store')","a00ce8a7":"print(train_df.head(3))\nprint(train_df.shape)","a827f39e":"test_df = test.merge(features,how=\"left\",on=['Store','Date','IsHoliday']).merge(stores,how='left',on='Store')","4bef12d4":"test_df","f9402f34":"train_df.info()","d6b9a96b":"test_df.info()","dc7239e8":"columns_name = train_df.columns\nsum_na = train_df.isna().sum()\nd = {\"Sum_Na\":sum_na,}\ndf_na = pd.DataFrame(d)\ndf_na['Percentage of Na'] = df_na['Sum_Na']\/421570*100\ndf_na","ea0fbb13":"train_df.fillna(0,inplace=True)","ce447092":"columns_name = train_df.columns\nsum_na = test_df.isna().sum()\nd = {\"Sum_Na\":sum_na,}\ndf_na = pd.DataFrame(d)\ndf_na['Percentage of Na'] = df_na['Sum_Na']\/421570*100\ndf_na","4cf7d23b":"test_df.describe().T","3e02a298":"test_df['IsHoliday'] = test_df['IsHoliday'].astype(\"int\")","07aee321":"values = {'MarkDown1':0,'MarkDown2':0,'MarkDown3':0,'MarkDown4':0,'CPI':176.96,'Unemployment':6.86}\ntest_df.fillna(value = values,inplace=True)","e542b25c":"train_df['IsHoliday'] = train_df['IsHoliday'].astype(\"int\")","7cd50a41":"#EDA\n# Compute the correlation matrix\ncorr = train_df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 13))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.8,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .2},annot=True)\n\n\n","9bb41228":"plt.figure(figsize=(20,5))\nsns.distplot(train_df['Weekly_Sales'], bins=40, kde=True, color='red')\nplt.title('Weekly_Sales distribution')\nplt.show()","0a5067d1":"plt.figure(figsize=(20,15))\nsns.boxplot(x='Weekly_Sales', y='IsHoliday', data=train_df, orient='h', palette='afmhot_r')  # Effect of IsHoliday on Weekly Sales\nplt.show()\n","61b49591":"plt.figure(figsize=(20,15))\ncols_outlier = train_df[['Weekly_Sales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature','MarkDown1', 'MarkDown2', 'MarkDown3',\n       'MarkDown4', 'MarkDown5', 'Unemployment']]\nfig, axes = plt.subplots(4,3,figsize=(18,12))\nfig.suptitle('Outliers in the numerical features',fontsize=18, color = '#06917e', x = 0.5, y = 1.05)\nindex = [(i,j) for i in range(4) for j in range(3)]\nindex_count=0\nfor col in cols_outlier.columns:\n    sns.boxplot(x=col, ax=axes[index[index_count]], data=train_df, palette='afmhot_r')\n    index_count += 1\n    plt.tight_layout()\nplt.show()","775edaaf":"fig, axes = plt.subplots(3,2,figsize=(18,12))\nax_index = [(i,j) for i in range(3) for j in range(2)]\nindex_number = 0\nfig.suptitle('Effect of various factors on Weekly Sales',fontsize=18, color = '#06917e', y = 1.05)\nfor i in ['Unemployment','IsHoliday','Size','CPI','Temperature','Fuel_Price']:\n    sns.scatterplot(x=i, y='Weekly_Sales', data=train_df, ax=axes[ax_index[index_number]])\n    index_number += 1\n    plt.tight_layout()","5920441e":"plt.figure(figsize=(20,15))\nsns.boxplot(x='Size', y='Type', data=train_df, palette='afmhot_r')\nplt.title('Size of the Store with respect to Type')\nplt.show()","16329393":"plt.figure(figsize=(20,15))\n#Average Sales per stores\navg_sales_per_store = train_df.groupby(by='Store')['Weekly_Sales'].mean()\nsns.barplot(x = avg_sales_per_store.index, y=avg_sales_per_store)\nplt.title('Average Sales per Store')\nplt.show()","b55b739d":"plt.figure(figsize=(20,15))\navg_sales_per_dept = train_df.groupby(by='Dept')['Weekly_Sales'].mean()\nsns.barplot(x = avg_sales_per_dept.index, y=avg_sales_per_dept)\nplt.title('Average Sales per Department')\nplt.xticks(rotation = 90)\nplt.show()","0bde86ae":"# Pipeline\n\n\npipeline = Pipeline(steps=[\n    ('One_Hot_Encoder',OneHotEncoder(drop='first')),\n    ('scaler',StandardScaler(with_mean=False)),\n    ('model',GradientBoostingRegressor())\n])\n","f2e166e3":"\ntrain_df.info()","e128e937":"test_df = test_df.drop('Date',axis=1)\ntest_df.info()","5194fc3f":"# Train Test Split\ntrain_df = pd.get_dummies(train_df)\ntest_df = pd.get_dummies(test_df)\nX = train_df.drop('Weekly_Sales',axis=1)\ny = train_df['Weekly_Sales']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","78067ec4":"params = {\n    'model__learning_rate' : [0.01,0.1],\n    'model__max_depth' : [3,5]\n}","53fa0535":"random_search = RandomizedSearchCV(pipeline,params,cv=3,n_jobs=-1,verbose = 2)\nrandom_search.fit(X_train,y_train)","b5504473":"y_pred = random_search.predict(X_test)","cd576784":"random_search.best_params_","f24e5128":"random_search_new =GradientBoostingRegressor(max_depth=5,learning_rate=0.1)\nrandom_search_new.fit(X_train,y_train)\n\ntrain_pred = random_search_new.predict(X_train)\ntest_pred = random_search_new.predict(X_test)","a0e34980":"print(\"RMSE of train is : {}\".format(np.sqrt(mean_squared_error(y_train,train_pred))))\nprint(\"RMSE of Test is : {}\".format(np.sqrt(mean_squared_error(y_test,test_pred))))","afc7e6ce":"feature_importance = random_search_new.feature_importances_\nfeature_imp = pd.DataFrame(sorted(zip(random_search_new.feature_importances_,X.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp[-10:-1].sort_values(by=\"Value\", ascending=False))\nplt.title('GBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","e525105f":"*Na Values are filled!*","7a190abc":"**Introduction**"}}