{"cell_type":{"ecbaca44":"code","79bc8292":"code","325ca5d2":"code","b050efd0":"code","1b4342fd":"code","8494dd7b":"code","588f74f0":"code","3127a02c":"code","c10e3c0d":"code","56f1f6aa":"code","88e308fa":"code","72621350":"code","9543144d":"code","33aec350":"code","a4fecd81":"code","0072fd8f":"code","9066b878":"code","ca38f45a":"code","b40bb51e":"code","a822c852":"code","428971b0":"code","bc5594f3":"code","b8f0dc44":"code","939d7c98":"code","37d02e38":"code","a8be6f7b":"code","c09d3f34":"code","dd3673e0":"code","f4549494":"code","2e10b25d":"code","c4d889df":"code","6288dbd3":"code","ddd45c7f":"code","4a304d2a":"code","16123ccf":"code","1fab3a65":"code","143f43c0":"code","33c82dc9":"code","9d31802a":"code","bd20e1ec":"code","c3ad994c":"code","928d8f1b":"code","d0565a7e":"code","43634912":"code","1794ed04":"code","cbe3c314":"code","320d0927":"code","ef86f781":"code","7da80aad":"code","f58084fb":"code","3f1cbe66":"code","af8667d2":"code","426071e2":"code","ce20cf7a":"code","d39a5db4":"code","bfd12b81":"code","0a4b7e84":"code","9f4733c0":"code","fe622a2d":"code","5c1a95e8":"code","c78dbb82":"code","a903044a":"code","5069203a":"code","926e1e1b":"code","c37557b1":"markdown","a8e3e6bd":"markdown","83abe940":"markdown","eaf487d3":"markdown","b8dce5ce":"markdown","2fb75662":"markdown","c4a5aec9":"markdown","951c3bbf":"markdown","80a2f9ac":"markdown","fa3a0e61":"markdown","20d77d70":"markdown","7f07715f":"markdown","d9ccadb3":"markdown","8e588a59":"markdown","fc4b5f05":"markdown","cff30b9d":"markdown","7b80bf71":"markdown","f69a1bd4":"markdown","6ac0d79d":"markdown","cdbe356a":"markdown","8b941453":"markdown","264ed0da":"markdown","393878a7":"markdown","7a356c4b":"markdown","3228297a":"markdown","e6f02aa8":"markdown","41701362":"markdown","beb69bfd":"markdown","f300ec63":"markdown","5adeb14b":"markdown","c1010bb5":"markdown","a7a1be65":"markdown","f3720706":"markdown","a72f3cfd":"markdown","b2785afe":"markdown"},"source":{"ecbaca44":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport plotly.express as px\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","79bc8292":"dataset = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndataset.head()","325ca5d2":"dataset.describe(include='all')","b050efd0":"dataset.isnull().sum()","1b4342fd":"data_1 = dataset.drop(['host_id', 'id', 'name', 'host_name', 'last_review'], axis =1)\ndata_1.head()","8494dd7b":"#Replacing Nan values in the reviews per month column with 0 because there was no review as there was also no value \n#recorded for the corresponding number of reviews. If there was a value in the number of reviews, then there would also \n#be a value for reviews_per_month\ndata_1['reviews_per_month'].fillna(0, inplace = True)\ndata_1.isnull().sum()","588f74f0":"data_1.columns","3127a02c":"#Rearranging the column so that price, the dependent variable would be at the last column\ndata_1 = data_1[['neighbourhood_group', 'neighbourhood', 'latitude', 'longitude',\n       'room_type', 'minimum_nights', 'number_of_reviews',\n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365', 'price']]","c10e3c0d":"data_1.describe(include='all')","56f1f6aa":"data_1['price'].skew()","88e308fa":"sns.boxplot(data_1['price'])","72621350":"data_1['minimum_nights'].skew()","9543144d":"sns.boxplot(data_1['minimum_nights'])","33aec350":"data_1['number_of_reviews'].skew()","a4fecd81":"data_1['reviews_per_month'].skew()","0072fd8f":"data_1['calculated_host_listings_count'].skew()","9066b878":"sns.boxplot(data_1['calculated_host_listings_count'])","ca38f45a":"data_1['availability_365'].skew()","b40bb51e":"data_1['latitude'].skew()","a822c852":"data_1['longitude'].skew()","428971b0":"data_2 = data_1.copy()\ndata_2['log_price'] = np.log(data_1['price']+1)\ndata_2.head()","bc5594f3":"data_2['log_price'].skew()","b8f0dc44":"sns.distplot(data_2['log_price'])","939d7c98":"#removing the extreme upper values\nq = data_2['minimum_nights'].quantile(0.99)\ndata_3 = data_2[data_2['minimum_nights']<q]","37d02e38":"#removing the extreme upper values\nq = data_3['calculated_host_listings_count'].quantile(0.95)\ndata_4 = data_3[data_3['calculated_host_listings_count']<q]","a8be6f7b":"data_4['minimum_nights'].skew()","c09d3f34":"data_4['calculated_host_listings_count'].skew()","dd3673e0":"data_4.describe(include='all')","f4549494":"neighbourhood_group = data_4.groupby(['neighbourhood_group']).agg({'neighbourhood_group':'count'})\n#renaming the aggregated column\nneighbourhood_group.columns = ['total_airbnb_listings']\nneighbourhood_group.sort_values(by=['total_airbnb_listings'], inplace = True, ascending = False)\nneighbourhood_group.reset_index(inplace=True)\nneighbourhood_group","2e10b25d":"curr_palette = sns.light_palette('navy',reverse=True)\nfig = plt.figure(figsize=(8,6))\nsns.barplot(x = 'neighbourhood_group', y = 'total_airbnb_listings', data = neighbourhood_group, palette = curr_palette)\nplt.xlabel('Neighbourhood Group', fontsize = 14)\nplt.ylabel('Total AirBnB Listings', fontsize = 14)\nplt.title('AirBnB Listings by Neighbourhood Group', fontsize = 18)\nplt.show()","c4d889df":"neighbourhood_top_10 = data_4[['neighbourhood_group','neighbourhood']].groupby(['neighbourhood_group',\n                                                                                'neighbourhood']).agg({'neighbourhood':'count'})\nneighbourhood_top_10.columns = ['total_airbnb_listings']\nneighbourhood_top_10.sort_values(by=['total_airbnb_listings'], inplace = True, ascending = False)\n#Getting the top 10 highest listings by neighbourhood\nneighbourhood_top_10 = neighbourhood_top_10.nlargest(10,'total_airbnb_listings')\nneighbourhood_top_10.reset_index(inplace=True)\nneighbourhood_top_10","6288dbd3":"fig = px.bar(neighbourhood_top_10, x= 'neighbourhood', y='total_airbnb_listings', \n             color='neighbourhood_group',\n             title='AirBnB Listings by Neighbourhood',\n             labels = {'neighbourhood':'Neighbourhood', 'total_airbnb_listings':'Total AirBnB Listings'},\n             hover_name='neighbourhood',\n             hover_data=['neighbourhood','neighbourhood_group','total_airbnb_listings'],\n             template='plotly_dark',\n             width = 800,\n             height = 400)\n\nfig.update_xaxes(categoryorder='total descending')\n#aligning the title position to center\nfig.update(layout = dict(title = dict(x = 0.5)))\n\nfig.show()","ddd45c7f":"airbnb_room_type = data_4[['neighbourhood_group','room_type']].groupby(['neighbourhood_group','room_type']\n                                                                             ).agg({'room_type':'count'})\nairbnb_room_type.columns = ['count_of_room_type']\nairbnb_room_type.reset_index(inplace=True)\nairbnb_room_type","4a304d2a":"fig = px.bar(airbnb_room_type, x= 'neighbourhood_group', y='count_of_room_type', \n             color='room_type',\n             title='AirBnB Room Type Distribution by Neighbourhood Groups',\n             labels = {'neighbourhood_group':'Neighbourhood Groups', 'count_of_room_type':'Count of Room Type'},\n             hover_name='neighbourhood_group',\n             hover_data=['neighbourhood_group','room_type','count_of_room_type'],\n             barmode='group',\n             template='plotly_dark',\n             width = 800,\n             height = 400)\n\n#fig.update_xaxes(categoryorder='total descending')\n#aligning the title position to center\nfig.update(layout = dict(title = dict(x = 0.5)))\n\nfig.show()","16123ccf":"#airbnb_avg_price = data_4[['neighbourhood_group','room_type']].groupby(['neighbourhood_group','room_type'])\nairbnb_avg_price = data_4[['neighbourhood_group','room_type','price']].groupby(['neighbourhood_group','room_type']\n                                                                              ).agg({'price':'mean'})\nairbnb_avg_price.columns = ['average_price']\nairbnb_avg_price.reset_index(inplace=True)\nairbnb_avg_price","1fab3a65":"fig = px.bar(airbnb_avg_price, x= 'neighbourhood_group', y='average_price', \n             color='room_type',\n             title='AirBnB Average Prices by Room Type Distribution',\n             labels = {'neighbourhood_group':'Neighbourhood Groups', 'average_price':'Average Price'},\n             hover_name='neighbourhood_group',\n             hover_data=['neighbourhood_group','room_type','average_price'],\n             barmode='group',\n             template='plotly_dark',\n             width = 800,\n             height = 400)\n\n#fig.update_xaxes(categoryorder='total descending')\n#aligning the title position to center\nfig.update(layout = dict(title = dict(x = 0.5)))\n\nfig.show()","143f43c0":"airbnb_data = data_4.copy()\nairbnb_data.drop(['neighbourhood','price'], axis=1, inplace=True)\nairbnb_data.head()","33c82dc9":"airbnb_data = pd.get_dummies(airbnb_data, drop_first = True)\nairbnb_data.head()","9d31802a":"airbnb_data.columns","bd20e1ec":"airbnb_data = airbnb_data[['latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365', 'neighbourhood_group_Brooklyn',\n       'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens',\n       'neighbourhood_group_Staten Island', 'room_type_Private room',\n       'room_type_Shared room', 'log_price']]","c3ad994c":"X= airbnb_data.drop(['log_price'], axis =1)\ny = airbnb_data['log_price']","928d8f1b":"lab_enc = LabelEncoder()\ny_enc = lab_enc.fit_transform(y)\n\nextra_tree_forest = ExtraTreesClassifier(n_estimators = 20)\nextra_tree_forest.fit(X,y_enc)\nfeature_importance = extra_tree_forest.feature_importances_\n\nplt.barh(X.columns, feature_importance)\nplt.xlabel('Feature Labels')\nplt.ylabel('Feature Importances')\nplt.title('Comparison of different features')\nplt.show()","d0565a7e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","43634912":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","1794ed04":"X_train.shape","cbe3c314":"lin_regressor = LinearRegression()\nlin_regressor.fit(X_train, y_train)\nlin_pred = lin_regressor.predict(X_test)\n\nn = X_train.shape[0]\np = X_train.shape[1]\nr2 = r2_score(y_test,lin_pred)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,lin_pred)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,lin_pred,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","320d0927":"svr_regressor = SVR(kernel = 'rbf')\nsvr_regressor.fit(X_train, y_train)\nsvr_pred = svr_regressor.predict(X_test)\n\nn = X_train.shape[0]\np = X_train.shape[1]\nr2 = r2_score(y_test,svr_pred)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,svr_pred)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,svr_pred,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","ef86f781":"dt_regressor = DecisionTreeRegressor(random_state = 0)\ndt_regressor.fit(X_train, y_train)\ndt_pred = dt_regressor.predict(X_test)\n\nn = X_train.shape[0]\np = X_train.shape[1]\nr2 = r2_score(y_test,dt_pred)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,dt_pred)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,dt_pred,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","7da80aad":"rf_regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nrf_regressor.fit(X_train, y_train)\nrf_pred = rf_regressor.predict(X_test)\n\nn = X_train.shape[0]\np = X_train.shape[1]\nr2 = r2_score(y_test,rf_pred)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,rf_pred)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,rf_pred,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","f58084fb":"xgb = XGBRegressor()\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\n\nn = X_train.shape[0]\np = X_train.shape[1]\nr2 = r2_score(y_test,xgb_pred)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,xgb_pred)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test,xgb_pred,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","3f1cbe66":"airbnb_data2 = airbnb_data.copy()\nto_drop = airbnb_data[['neighbourhood_group_Brooklyn', 'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens', \n                       'neighbourhood_group_Staten Island']]\nairbnb_data2.drop(to_drop, axis = 1, inplace=True)\nairbnb_data2.head()","af8667d2":"X2= airbnb_data2.drop(['log_price'], axis =1)\ny2 = airbnb_data2['log_price']","426071e2":"X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.3, random_state = 42)","ce20cf7a":"sc = StandardScaler()\nX_train2 = sc.fit_transform(X_train2)\nX_test2 = sc.transform(X_test2)","d39a5db4":"X_train2.shape","bfd12b81":"rf_regressor2 = RandomForestRegressor(n_estimators = 100, random_state = 0)\nrf_regressor2.fit(X_train2, y_train2)\nrf_pred2 = rf_regressor2.predict(X_test2)\n\nn = X_train2.shape[0]\np = X_train2.shape[1]\nr2 = r2_score(y_test2,rf_pred2)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test2,rf_pred2)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test2,rf_pred2,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","0a4b7e84":"xgb2 = XGBRegressor()\nxgb2.fit(X_train2, y_train2)\nxgb_pred2 = xgb2.predict(X_test2)\n\nn = X_train2.shape[0]\np = X_train2.shape[1]\nr2 = r2_score(y_test2,xgb_pred2)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test2,xgb_pred2)))\nprint('Root Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test2,xgb_pred2,squared=False)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","9f4733c0":"score_metric_1 = cross_val_score(estimator = xgb2, X = X_train2, y = y_train2, cv = 10,\n                               scoring =  'neg_mean_squared_error')\n\nprint(\"Mean Squared Error: {:.6f}\".format(np.abs(score_metric_1.mean()))) #taking the absolute of mse because  \n#cross_val_score returns anegative value of mse rather than a positive value.","fe622a2d":"score_metric_2 = cross_val_score(estimator = xgb2, X = X_train2, y = y_train2, cv = 10,\n                               scoring =  'r2')\n\nprint(\"R-Squared: {:.6f}\".format(np.abs(score_metric_2.mean())))","5c1a95e8":"#xgboost regressor parameters to be tuned\nparameters = {'n_estimators': range(50, 1000, 50),\n              'learning_rate': [0.01, 0.05, 0.1, 0.2],\n              'max_depth': range(3, 10, 3),\n              'min_child_weight': range(1, 10, 2),\n              'subsample': [0.6, 0.8, 1]}\n\nrandom_search = RandomizedSearchCV(estimator = xgb2,\n                           param_distributions = parameters,\n                           scoring = 'neg_mean_squared_error', #metric we want to use to measure the regression model\n                           cv = 10, #evaluated with 10 k cross fold\n                           random_state = 42,\n                           n_jobs = 1) \n\nrandom_search_ = random_search.fit(X_train2, y_train2)\nbest_mse = random_search_.best_score_\nbest_parameters = random_search_.best_params_\n\nprint(\"Best MSE: {:.6f}\".format(np.absolute(best_mse)))\nprint(\"Best Parameters:\", best_parameters)","c78dbb82":"xgb3 = XGBRegressor(subsample = 0.8, n_estimators = 700, min_child_weight = 5, max_depth = 6, learning_rate = 0.05)\nxgb3.fit(X_train2, y_train2)\nxgb_pred3 = xgb3.predict(X_test2)\n\nn = X_train2.shape[0]\np = X_train2.shape[1]\nr2 = r2_score(y_test2,xgb_pred3)\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    \nprint('Mean Squared Error: {:.6f}'.format(mean_squared_error(y_test2,xgb_pred3)))\nprint('R-Squared: {:.6f}'.format(r2))\nprint('Adjusted R-Squared: {:.6f}'.format(adjusted_r2))","a903044a":"predicted_values = pd.DataFrame(np.exp(xgb_pred3).round() , columns=['Prediction']) #taking np.exp because price was transformed to \n#log+1 and i have to transform it back to the normal values.\npredicted_values.head()","5069203a":"y_test2 = y_test2.reset_index(drop=True)","926e1e1b":"predicted_values['Actual'] = np.exp(y_test2) #taking np.exp because price was transformed to \n#log+1 and i have to transform it back to the normal values.\npredicted_values['Difference (Prediction - Actual)'] = (predicted_values['Prediction'] - predicted_values['Actual']).round()\npd.set_option('display.max_rows', None)\npredicted_values","c37557b1":"## Import Libraries","a8e3e6bd":"### Formula for Adjusted R^2\n\n$R^2_{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$","83abe940":"# Data Preprocessing","eaf487d3":"### RANDOM FOREST REGRESSION","b8dce5ce":"Taking the log+1 of price rather than log because price has a 0 values in the column. This is to achieve a normal distribution.","2fb75662":"The cross validation MSE and R-sqaured are similar to the scores of xgb2 which is the regression model with the highest adjusted r-quared and lowest mse.","c4a5aec9":"### XGBOOST REGRESSION","951c3bbf":"### LINEAR REGRESSION","80a2f9ac":"### DECISION TREE REGRESSION","fa3a0e61":"### XGBOOST REGRESSION","20d77d70":"From the graph above, neighbourhood groups have the least contribution. I will run two types of regression models; the first will include all the features above and the second will exclude the neighbourhood group.","7f07715f":"## Encoding categorical data","d9ccadb3":"Price, Minimum nights and Calculated host listings count have the highest skew","8e588a59":"After applying log+1 transformation on price and dropping extreme values for minimum nights and calculated host lstings count, their respective skews reduced significantly.","fc4b5f05":"## Exploratory Data Analysis","cff30b9d":"## Splitting the data","7b80bf71":"### RANDOM FOREST REGRESSION","f69a1bd4":"## Training the machine learning models with all the features","6ac0d79d":"## Applying Randomized Search to find the best parameters","cdbe356a":"### SVR","8b941453":"## K-Fold Cross Validation","264ed0da":"1. Import Libraries\n2. Exploring skewness and dealing with outliers\n3. Exploratory Data Analysis\n4. Encoding categorical data\n5. Examining Feature Importance\n6. Splitting the data\n7. Training machine learning models with all the features\n8. Training machine learning models without neighbourhood groups\n9. K-Fold cross validation\n10. Applying Randomized Search to find the best parameters","393878a7":"## Examining Feature Importance","7a356c4b":"The difference between the predicted and actual values varies a lot. Some predicted values are closer to actual values while some are not. This is due to the fact that Adjusted R-Squared was 0.596031. If the values were between 0.7 and 1, the predicted values would have been better. More variables would also be needed to make more accurate predictions.","3228297a":"Entire homes\/apts and private rooms have the highest distribution across the 5 neighbourhood groups.","e6f02aa8":"Dropping columns that are not relevant","41701362":"## Exploring Skewness and Dealing with Outliers","beb69bfd":"Brooklyn and Manhattan have the greatest number of airbnb listings.","f300ec63":"## Splitting the data","5adeb14b":"The top 10 neighbourhoods with the highest airbnb listings are distributed between Brooklyn and Manhattan which have the highest number of airbnb listings as seen in the previous visualization. Williamsburg and Bedford-Stuyvesant which were the top 2 neighbourhood are located in Brooklyn which had the highest airbnb listings.","c1010bb5":"Following the fact that entire homes\/apts and private homes have the highest distribution across the neighbourhood groups as seen in the previous visualization, the graph above shows that they also have the highest avearge prices. Across the 5 neighbourhood groups, entire homes\/apts have the highest average prices by far when compared to the other room types.","a7a1be65":"I will be using random forest and xgboost regression models because they had the lowest MSEs and the highest Adjusted R-Squared in the first type of regression that included neighbourhood group.","f3720706":"## Training the machine learning models without neighbourhood group","a72f3cfd":"X_train2 and y_train2 performed slightly better with the second type of regression models which excluded neighbourhood groups. Xgb2 had the lowest MSE and highest Adjusted R-Squared. I will be using XGBoost regression model in my price prediction.","b2785afe":"## Content"}}