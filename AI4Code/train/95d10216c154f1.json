{"cell_type":{"abbde859":"code","763596f4":"code","09787223":"code","624092d0":"code","b5e69043":"code","81ab8486":"code","08a83e83":"code","7e027d50":"code","24d36545":"code","264979ee":"code","ad731ca3":"code","714f5793":"code","220d2d46":"code","851bbfc6":"code","08926c51":"code","94171e31":"code","f1a09d3d":"code","f9aeadd4":"code","d0f90d58":"code","90e7e89a":"code","a8d1f886":"code","93252cf7":"code","44299caf":"code","86790fb7":"code","3154475e":"code","70daf0dd":"code","125edb8d":"code","ddacea09":"code","2dc382df":"code","69096d0c":"code","ba90c1c3":"markdown","c1a5a8ff":"markdown","f682649b":"markdown","297529e2":"markdown","f1087156":"markdown","f97b2038":"markdown","4ca5239c":"markdown","41eefb68":"markdown"},"source":{"abbde859":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn.datasets","763596f4":"from sklearn.datasets import load_iris\niris = load_iris()\niris","09787223":"#Create a concatenated dataframe\ndf = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])\ndf","624092d0":"X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\ndisplay(X.head())\nX.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\ndisplay(X.head())","b5e69043":"target = df['target']\ntarget.head()","81ab8486":"X.dropna(how='all', inplace=True)\nX.head()","08a83e83":"sns.scatterplot(x = X.sepal_length, y = X.sepal_width, style = df.target )","7e027d50":"from sklearn.preprocessing import scale\nx_train = scale(X)","24d36545":"#Find covariance matrix\ncovariancematrix = np.cov(x_train.T)\ncovariancematrix","264979ee":"eigenvalues, eigenvectors = np.linalg.eig(covariancematrix)\ndisplay(eigenvalues, eigenvectors)","ad731ca3":"#Alternatively, use Singular Value Decomposition (SVD)\neigenvec_svd, s, v = np.linalg.svd(x_train.T)\ndisplay(eigenvec_svd)","714f5793":"display(eigenvalues)","220d2d46":"variance_accounted = []\nfor i in eigenvalues:\n    va = (i\/(eigenvalues.sum())*100)\n    variance_accounted.append(va)\ndisplay(variance_accounted)","851bbfc6":"cumulative_variance = np.cumsum(variance_accounted)\ncumulative_variance","08926c51":"sns.lineplot(x = [1,2,3,4], y = cumulative_variance);\nplt.xlabel(\"No. of components\")\nplt.ylabel(\"Cumulative variance\")\nplt.title(\"Variance vs No. of components\")\nplt.show()","94171e31":"#Project data onto a lower dimensional plane\nproj_vector = (eigenvectors.T[:][:])[:2].T\nproj_vector","f1a09d3d":"x_pca = np.dot(x_train, proj_vector)","f9aeadd4":"#split the data set into train and test sets\nfrom sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(x_pca, target, test_size=0.2)","d0f90d58":"xtrain,xtest, ytrain, ytest = train_test_split(x_train, target, test_size=0.2)","90e7e89a":"from sklearn.linear_model import LogisticRegression","a8d1f886":"model_pca = LogisticRegression()\nmodel_pca.fit(xTrain, yTrain)","93252cf7":"y_pred = model_pca.predict(xTest)\ny_pred","44299caf":"model_original = LogisticRegression()\nmodel_original.fit(xtrain, ytrain)\ny_pred_original = model_original.predict(xtest)\ny_pred_original","86790fb7":"from sklearn.metrics import confusion_matrix\ncm_pca = confusion_matrix(y_pred, yTest)\ncm_pca","3154475e":"cm_original = confusion_matrix(y_pred_original, ytest)\ncm_original","70daf0dd":"#Confusion Matrix showing percentages\nprint('Confusion Matrix for values predicted after selecting 2 components using principle component analysis' ,sns.heatmap((cm_pca\/np.sum(cm_pca))*100, annot=True, cmap=\"GnBu\"))\n","125edb8d":"print('Confusion Matrix for values predicted using all 4 components from original standardised data', sns.heatmap((cm_original\/np.sum(cm_original))*100, annot = True, cmap=\"Blues\"))","ddacea09":"from sklearn.metrics import classification_report","2dc382df":"print('Classification Report for PCA data')\np = np.asarray(yTest)\np1 = pd.DataFrame(p, columns =['Actual'])\np2 = pd.DataFrame(y_pred, columns = ['Predictions_pca'])\npred = pd.concat([p1,p2], axis = 1)\nprint(classification_report(pred['Actual'], pred['Predictions_pca']))","69096d0c":"print('Classification Report for values predicted using all 4 components')\nq = np.asarray(ytest)\nq1 = pd.DataFrame(q, columns=['Actual'])\nq2 = pd.DataFrame(y_pred_original, columns=['Predictions_without_pca'])\npred_2 = pd.concat([q1,q2], axis=1)\nprint(classification_report(pred_2['Actual'], pred_2['Predictions_without_pca']))","ba90c1c3":"### Find Eigenvalues and Eigenvectors","c1a5a8ff":"# Predictions on the Iris Dataset ","f682649b":"#### Therefore, we select the first two components because they contribute the most to the variance","297529e2":"### Visualise","f1087156":"### Import libraries and data","f97b2038":"### Standardise the Data","4ca5239c":"### Making Predictions using LogisticRegression","41eefb68":"### Principle Components"}}