{"cell_type":{"d27afb25":"code","e2648e44":"code","c279bb21":"code","6e529d76":"code","070864f4":"code","5fd13a8d":"code","f52ca014":"code","fd524e9a":"code","827aba56":"code","0d2094a3":"code","b0c88c33":"code","48ee9e55":"code","02e23f04":"code","532ff16a":"code","cc6501e2":"code","2ebd08ae":"code","ff0768dc":"code","a60a2bac":"code","6870afa8":"code","86617bd4":"code","84742836":"code","f2bedaf8":"code","c9eb0110":"code","39b173cd":"code","2aa9c745":"code","b29d0100":"code","3345b9e4":"code","43a559b4":"code","2fa35204":"code","53ecb761":"markdown","89a0300a":"markdown","799cac0b":"markdown","f3ef6d00":"markdown","dfc9b8cb":"markdown","afd952f9":"markdown","04c268f9":"markdown","2d52e4b7":"markdown"},"source":{"d27afb25":"# Importing libraries\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","e2648e44":"# Importing dataset\ndataset = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","c279bb21":"# Preview data\ndataset.head()","6e529d76":"# Dataset dimensions - (rows, columns)\ndataset.shape","070864f4":"# Features data-type\ndataset.info()","5fd13a8d":"# Statistical summary\ndataset.describe().T","f52ca014":"# Count of null values\ndataset.isnull().sum()","fd524e9a":"# Outcome countplot\nsns.countplot(x = 'Outcome',data = dataset)","827aba56":"# Histogram of each feature\nimport itertools\n\ncol = dataset.columns[:8]\nplt.subplots(figsize = (20, 15))\nlength = len(col)\n\nfor i, j in itertools.zip_longest(col, range(length)):\n    plt.subplot((length\/2), 3, j + 1)\n    plt.subplots_adjust(wspace = 0.1,hspace = 0.5)\n    dataset[i].hist(bins = 20)\n    plt.title(i)\nplt.show()","0d2094a3":"# Pairplot \nsns.pairplot(data = dataset, hue = 'Outcome')\nplt.show()","b0c88c33":"# Heatmap\nsns.heatmap(dataset.corr(), annot = True)\nplt.show()","48ee9e55":"dataset_new = dataset","02e23f04":"# Replacing zero values with NaN\ndataset_new[[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]] = dataset_new[[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]].replace(0, np.NaN) ","532ff16a":"# Count of NaN\ndataset_new.isnull().sum()","cc6501e2":"# Replacing NaN with mean values\ndataset_new[\"Glucose\"].fillna(dataset_new[\"Glucose\"].mean(), inplace = True)\ndataset_new[\"BloodPressure\"].fillna(dataset_new[\"BloodPressure\"].mean(), inplace = True)\ndataset_new[\"SkinThickness\"].fillna(dataset_new[\"SkinThickness\"].mean(), inplace = True)\ndataset_new[\"Insulin\"].fillna(dataset_new[\"Insulin\"].mean(), inplace = True)\ndataset_new[\"BMI\"].fillna(dataset_new[\"BMI\"].mean(), inplace = True)","2ebd08ae":"# Statistical summary\ndataset_new.describe().T","ff0768dc":"# Feature scaling using MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ndataset_scaled = sc.fit_transform(dataset_new)","a60a2bac":"dataset_scaled = pd.DataFrame(dataset_scaled)","6870afa8":"# Selecting features - [Glucose, Insulin, BMI, Age]\nX = dataset_scaled.iloc[:, [1, 4, 5, 7]].values\nY = dataset_scaled.iloc[:, 8].values","86617bd4":"# Splitting X and Y\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, stratify = dataset_new['Outcome'] )","84742836":"# Checking dimensions\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"Y_test shape:\", Y_test.shape)","f2bedaf8":"# Logistic Regression Algorithm\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state = 42)\nlogreg.fit(X_train, Y_train)","c9eb0110":"# Plotting a graph for n_neighbors \nfrom sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\n\nX_axis = list(range(1, 31))\nacc = pd.Series()\nx = range(1,31)\n\nfor i in list(range(1, 31)):\n    knn_model = KNeighborsClassifier(n_neighbors = i) \n    knn_model.fit(X_train, Y_train)\n    prediction = knn_model.predict(X_test)\n    acc = acc.append(pd.Series(metrics.accuracy_score(prediction, Y_test)))\nplt.plot(X_axis, acc)\nplt.xticks(x)\nplt.title(\"Finding best value for n_estimators\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Accuracy\")\nplt.grid()\nplt.show()\nprint('Highest value: ',acc.values.max())","39b173cd":"# K nearest neighbors Algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 24, metric = 'minkowski', p = 2)\nknn.fit(X_train, Y_train)","2aa9c745":"# Random forest Algorithm\nfrom sklearn.ensemble import RandomForestClassifier\nranfor = RandomForestClassifier(n_estimators = 11, criterion = 'entropy', random_state = 42)\nranfor.fit(X_train, Y_train)","b29d0100":"# Making predictions on test dataset\nY_pred_logreg = logreg.predict(X_test)\nY_pred_knn = knn.predict(X_test)\nY_pred_ranfor = ranfor.predict(X_test)","3345b9e4":"# Evaluating using accuracy_score metric\nfrom sklearn.metrics import accuracy_score\naccuracy_logreg = accuracy_score(Y_test, Y_pred_logreg)\naccuracy_knn = accuracy_score(Y_test, Y_pred_knn)\naccuracy_ranfor = accuracy_score(Y_test, Y_pred_ranfor)","43a559b4":"# Accuracy on test set\nprint(\"Logistic Regression: \" + str(accuracy_logreg * 100))\nprint(\"K Nearest neighbors: \" + str(accuracy_knn * 100))\nprint(\"Random Forest: \" + str(accuracy_ranfor * 100))","2fa35204":"#From the above comparison, we can observe that K Nearest neighbors gets the highest accuracy of 78.57 %","53ecb761":"# Step 2: Data Visualization","89a0300a":"# Step 1: Descriptive Statistics","799cac0b":"## Observations:\n1. There are a total of 768 records and 9 features in the dataset.\n2. Each feature can be either of integer or float dataype.\n3. Some features like Glucose, Blood pressure , Insulin, BMI have zero values which represent missing data.\n4. There are zero NaN values in the dataset.\n5. In the outcome column, 1 represents diabetes positive and 0 represents diabetes negative.","f3ef6d00":"# Step 3: Data Preprocessing","dfc9b8cb":"# Step 4: Data Modelling","afd952f9":"# Step 5: Model Evaluation","04c268f9":"# Step 0: Import libraries and Dataset","2d52e4b7":"## Observations:\n1. The countplot tells us that the dataset is imbalanced, as number of patients who don't have diabetes is more than those who do.\n2. From the correaltion heatmap, we can see that there is a high correlation between Outcome and [Glucose,BMI,Age,Insulin]. We can select these features to accept input from the user and predict the outcome."}}