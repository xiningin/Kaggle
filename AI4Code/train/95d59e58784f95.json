{"cell_type":{"563a7ae5":"code","7a560376":"code","c4c50c79":"code","4ad19390":"code","1bab56ee":"code","098204e4":"code","6613e3ec":"code","1b1cf3b4":"code","9015dac4":"code","6ea63ecd":"code","5d3509a0":"code","fde7526f":"code","15f6a984":"code","3771449e":"code","ba72b716":"code","96c7e020":"code","11625636":"code","6852e43f":"code","efb758f8":"code","cbb74fb8":"code","36c81572":"code","bd9393a5":"code","35e0ea05":"code","dbcce0c9":"code","8c6c4cc6":"code","1b57ca33":"code","f1a32515":"markdown"},"source":{"563a7ae5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7a560376":"df=pd.read_csv('..\/input\/churn-modelling-dataset\/Churn_Modelling.csv')","c4c50c79":"df.head()","4ad19390":"df.info()","1bab56ee":"df.describe(include='all')","098204e4":"df.shape","6613e3ec":"x=df.iloc[:,3:13].values","1b1cf3b4":"print(x[0:5])","9015dac4":"y=df.iloc[:,13].values","6ea63ecd":"print(y[0:5])","5d3509a0":"# Encoding Categorical data\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nlabelencoder_X_1=LabelEncoder()\nx[:,1]=labelencoder_X_1.fit_transform(x[:,1])\nlabelencoder_X_2=LabelEncoder()\nx[:,2]=labelencoder_X_1.fit_transform(x[:,2])\nonehotencoder=OneHotEncoder(categorical_features=[1])\n\nx=onehotencoder.fit_transform(x).toarray()","fde7526f":"print(x[0])","15f6a984":"x=x[:,1:]","3771449e":"# Splitting datasets into training and testing test\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=365)","ba72b716":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)\n","96c7e020":"x_test","11625636":"# Part 2 Building the ANN\n# Importing Keras Library\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","6852e43f":"# Intializing the ANN\nclassifier=Sequential()","efb758f8":"# Adding the input and the first hidden layer\nclassifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11))","cbb74fb8":"# Adding the second hidden layer\nclassifier.add(Dense(output_dim=6,init='uniform',activation='relu'))","36c81572":"# Adding the output layer\nclassifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))","bd9393a5":"# Compiling the ANN\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","35e0ea05":"# Fitting the dataset into ANN\nclassifier.fit(x_train,y_train,batch_size=10,epochs=100)","dbcce0c9":"# Part 3 Prediction of the test data\ny_hat=classifier.predict(x_test)","8c6c4cc6":"y_hat=(y_hat>0.5)","1b57ca33":"from sklearn.metrics import confusion_matrix,accuracy_score\ncm=confusion_matrix(y_test,y_hat)\nprint(cm)\nac=accuracy_score(y_test,y_hat)\nprint(ac)","f1a32515":"Use our ANN model to predict if the customer with the following informations will leave the bank: \n\nGeography: France\n\nCredit Score: 600\n\nGender: Male\n\nAge: 40 years old\n\nTenure: 3 years\n\nBalance: $60000\n\nNumber of Products: 2\n\nDoes this customer have a credit card ? Yes\n\nIs this customer an Active Member: Yes\n\nEstimated Salary: $50000"}}