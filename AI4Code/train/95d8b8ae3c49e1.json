{"cell_type":{"5256ae0d":"code","57d9282d":"code","29fd6973":"code","d03740cf":"code","75e6d757":"code","7a0b8dc6":"code","64033caf":"code","f5e545a7":"code","f4108efd":"code","6ee0846e":"code","66946173":"code","3da705e1":"code","ecac5cd3":"code","21fe38c3":"code","1c9fdc6a":"code","7ca1dbfd":"code","70d7aa87":"code","89efbc95":"code","ba207f69":"code","81c1f3b3":"code","2172eda4":"code","83f18405":"code","4660742e":"markdown","8cac5a3b":"markdown","35786a61":"markdown","13f494b0":"markdown","0213090c":"markdown","f378e95e":"markdown","8b14c63d":"markdown","797e0328":"markdown","fb463351":"markdown","b0f1d39b":"markdown","af0b26e3":"markdown","4516dcc5":"markdown","4cbd20db":"markdown","b829dc8e":"markdown","4e6c53bf":"markdown","fec5d51e":"markdown","e09a61d0":"markdown","424b7b0a":"markdown","d7eca3c7":"markdown"},"source":{"5256ae0d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","57d9282d":"# load the data set in pandas\ndf = pd.read_csv(\"..\/input\/2012-18_officialBoxScore.csv\")","29fd6973":"df.shape","d03740cf":"pd.set_option('display.max_columns', 130) # we want to see all 119 columns in the output\ndf.head(6)","75e6d757":"df.tail(6)","7a0b8dc6":"df = df[[\"gmDate\",\"gmTime\", \"seasTyp\", \"teamAbbr\", \"teamRslt\", \"teamPTS\", \"teamFGA\", \"teamFGM\", \"teamFG%\", \n        \"team2PA\", \"team2PM\", \"team2P%\", \"team3PA\", \"team3PM\", \"team3P%\", \"teamFTA\", \"teamFTM\", \"teamFT%\", \"teamPPS\", \n        \"opptAbbr\", \"opptRslt\", \"opptPTS\", \"opptFGA\", \"opptFGM\", \"opptFG%\", \"oppt2PA\", \"oppt2PM\",\n        \"oppt2P%\", \"oppt3PA\", \"oppt3PM\", \"oppt3P%\", \"opptFTA\", \"opptFTM\", \"opptFT%\", \"opptPPS\"]]","64033caf":"df[\"gmDate\"] = pd.to_datetime(df[\"gmDate\"])\n#df.dtypes\ndf = df.sort_values(\"gmDate\")\n\ndf = df[df[\"gmDate\"]>\"2017-10-17\"]\n\ndf.head()\n\n# set the index new\ndf = df.reset_index(drop=True)\n\n#df.head()\n#df.tail()","f5e545a7":"df.seasTyp.unique()","f4108efd":"df = df.drop_duplicates()\ndf.shape","6ee0846e":"line_counter = 0\ndrop_list = []\n\nfor line_counter in range(0, len(df.index)):\n    for delete_line_counter in range(line_counter+1, len(df.index)):\n        # compare same date and teamAbbr must be the same as opptAbbr\n        if df.iloc[line_counter, 0] == df.iloc[delete_line_counter, 0] and df.iloc[line_counter, 3] == df.iloc[delete_line_counter, 19]:\n            drop_list.append(delete_line_counter)\n            break\n            \n            \n#print(drop_list)","66946173":"df = df.drop(df.index[drop_list])\ndf.shape\ndf.head(10)","3da705e1":"df.isnull().values.any()","ecac5cd3":"# sort values with the help of game date\ndf = df.sort_values(\"gmDate\")\n\n# set the index new\ndf = df.reset_index(drop=True)\n\ndf.head()","21fe38c3":"# which teams we have in the NBA 2018\/ 2019 season?\nteams = df.teamAbbr.unique()\nprint(teams)","1c9fdc6a":"# let's prepare the dictionaries before using them\n\ntwo_fga = {} # 2 point field goal attempts\nthree_fga = {} # 3 point field goal attempts\ntwo_pfg_perc = {} # 2 point field goal percentage\nthree_pfg_perc = {} # 3 point field goal percentage\n\n# set up the two_fga dictionary\nfor team in teams:\n    if team not in two_fga:\n        two_fga[team] = []\n\n# set up the three_fga dictionary\nfor team in teams:\n    if team not in three_fga:\n        three_fga[team] = []\n        \n# set up the two_pfg_perc dictionary\nfor team in teams:\n    if team not in two_pfg_perc:\n        two_pfg_perc[team] = []\n        \n# set up the three_pfg_perc dictionary\nfor team in teams:\n    if team not in three_pfg_perc:\n        three_pfg_perc[team] = []\n\n        \n# e.g. the two_fga dictionary contains all teams as the key with an empty list\nprint(two_fga)","7ca1dbfd":"df.shape # take a look how many lines\/ rows we have\n\nline_counter = 0\nk = 5 # number of games which we like to use for the average\n\nfor line_counter in range(0, len(df.index)):\n    first_team = df.loc[line_counter, \"teamAbbr\"]\n    second_team = df.loc[line_counter, \"opptAbbr\"]\n    if len(two_fga[first_team]) == k and len(two_fga[second_team]) == k:\n        # Prediction\n        # Points first team\n        pred_2P_first_team = np.mean(two_fga[first_team]) * np.mean(two_pfg_perc[first_team]) * 2\n        pred_3P_first_team = np.mean(three_fga[first_team]) * np.mean(three_pfg_perc[first_team]) * 3\n        pred_points_first_team = pred_2P_first_team + pred_3P_first_team # predicted points first team\n        df.loc[line_counter, \"teamPTSpred\"] = pred_points_first_team\n        # Points second team\n        pred_2P_second_team = np.mean(two_fga[second_team]) * np.mean(two_pfg_perc[second_team]) * 2\n        pred_3P_second_team = np.mean(three_fga[second_team]) * np.mean(three_pfg_perc[second_team]) * 3\n        pred_points_second_team = pred_2P_second_team + pred_3P_second_team # predicted points second team\n        df.loc[line_counter, \"opptPTSpred\"] = pred_points_second_team\n        # prediction right or wrong\n        if pred_points_first_team > pred_points_second_team and df.loc[line_counter, \"teamPTS\"] > df.loc[line_counter, \"opptPTS\"]:\n            df.loc[line_counter, \"predRslt\"] = 1\n        elif pred_points_first_team < pred_points_second_team and df.loc[line_counter, \"teamPTS\"] < df.loc[line_counter, \"opptPTS\"]:\n            df.loc[line_counter, \"predRslt\"] = 1\n        else:\n            df.loc[line_counter, \"predRslt\"] = 0\n        \n        # delete oldest entry for prediction\n        del two_fga[first_team][-1]\n        del three_fga[first_team][-1]\n        del two_pfg_perc[first_team][-1]\n        del three_pfg_perc[first_team][-1]\n        del two_fga[second_team][-1]\n        del three_fga[second_team][-1]\n        del two_pfg_perc[second_team][-1]\n        del three_pfg_perc[second_team][-1]\n    # collect data for average calculation\n    if len(two_fga[first_team]) < k:\n        # write data for first team\n        two_fga[first_team].append(df.loc[line_counter, \"team2PA\"])\n        three_fga[first_team].append(df.loc[line_counter, \"team3PA\"])\n        two_pfg_perc[first_team].append(df.loc[line_counter, \"team2P%\"])\n        three_pfg_perc[first_team].append(df.loc[line_counter, \"team3P%\"])\n    if len(two_fga[second_team]) < k:\n        # write data second_team\n        two_fga[second_team].append(df.loc[line_counter, \"oppt2PA\"])\n        three_fga[second_team].append(df.loc[line_counter, \"oppt3PA\"])\n        two_pfg_perc[second_team].append(df.loc[line_counter, \"oppt2P%\"])\n        three_pfg_perc[second_team].append(df.loc[line_counter, \"oppt3P%\"])        ","70d7aa87":"df.tail()","89efbc95":"df.isna().sum()","ba207f69":"number_learn = df[\"predRslt\"].isna().sum() # how many games we couldn't predict because of learning -> 79\nnumber_right = df[\"predRslt\"].sum() # how many games we predicted right\nrows = len(df.index)\nperc_right_pred = number_right \/ (rows - number_learn)\nprint(perc_right_pred)","81c1f3b3":"# load the standing data set in pandas\nstandings = pd.read_csv(\"..\/input\/2012-18_standings.csv\")","2172eda4":"standings.tail()","83f18405":"standings = standings[standings[\"stDate\"]==\"2018-04-11\"]\nstandings = standings.sort_values(by=\"gameWon\", ascending=False) # sorted by \"gameWon\" because the rank is per conference\n\ndisplay(standings)","4660742e":"we just keep a few columns which we use or could use in further investigations","8cac5a3b":"We can see in the last three columns the number of points we predicted for the \"team\" and the \"opponent\" and in the column \"predRslt\" whether our prediction of the winning team was right (=1) or wrong (=0)","35786a61":"# Prediction\n\nset the new index -> so that we can iterate through the dataset again (make sure that it is sorted for gmDate ascending)","13f494b0":"# First Look\n\nfirst look into the dataset and ideas and further evaluation","0213090c":"* transfer the column gmDate to a datetime data type. Then sort the column gmDate.  \n* We use in our analysis the season 2017\/2018\n* the Season started on 2017-10-18 with the Cavaliers vs. the Celtics and the regular season ended on 2018-04-11. We saw above that the end of our data frame already shows the expected end date. ","f378e95e":"Now we have all the redundant information caused by the referees deleted out of our data frame.  \n\n\nIn the next step we need to delete all the redundant information in the data frame which is caused by that for every game exists one row in the data where the home team is mentioned first and one row where the away team is mentioned first.  \n\nWe go through every row in the data set and check whether *game date = game date* and *team = opponent*. We store all double lines in a list and then delete them all.","8b14c63d":"we have 44.284 lines in the dataset and 119 features for our analysis","797e0328":"## Here we start actually the prediction.  \n**Concept:** We use the average 2 Point field goal attempts of the last 5 games and multiply them with the average of the 2 point field goal percentage of the last 5 games. Then we multiply with 2 to get the predicted 2 point field goals. Accordingly we will do this for the 3 point shots.","fb463351":"# Data set cleaning\n\nwhich points we have to clarify in this section:  \n* as you can see above we have 3 times the same line (the different officials are responsible that there are 3 lines). This is not important for our analysis. Therefore we will delete those lines\n* you can see above that additionally to the 3 lines corresponding to different officials there a 3 more lines where just the teamAbbr and opptAbbr is switched. We want one line in our data frame per game. We will delete those lines, too. ","b0f1d39b":"where are NAs? -> no missing values in our dataframe -> perfect","af0b26e3":"56% isn't that bad. Better than a coin flip ;)","4516dcc5":"so the last stadings reported are from the 2018-04-11 this was the ending of the regular season. So this is perfect. It is the date until we predicted the game outcomes. Let's concentrate on that date.","4cbd20db":"Below we see that in some rows our new created columns have a NA value. This happens because we need for every team 5 games to fill our dicitionaries with the data from the first games.","b829dc8e":"# Data set cleaning and game prediction\n\nThis is my first kernel. Therefore I still got to learn a lot of interesting things and please give me your feedback. Thank you for this very large data set to play with.  \n\n\nI want to predict the results of the NBA games in the 2017-2018 season. I will use a simple technique: the moving average. **_\"Offense wins games but defense wins championchips\"_** that's why we just take into account the regular season and predict the points which will be scored. To predict the scored points we will use the field goal attempts which a team fires on the basket per game and combine this number of shots with their field goal percentage for 2 and 3 point shots. With this prediction method we are able to predict with 56% the right winning team.  \n\n\nBefore we start predicting we have one important thing to do. The data set _\"2012-18_officialBoxScore.csv\"_ has **6 lines per game**. This is because both teams have for the same game a single line where they are named first and every game has 3 referees but the data set allows only one referee name per line. So this results in 2 x 3 (=6) lines per game in the data set. For the prediction we omit 5 lines per game so that we can work with one line per game.","4e6c53bf":"to be continued","fec5d51e":"Because we don't use the referees in our dataframe and already disregard the corresponding columns we now have a lot of lines in our dataset which are the same. We now delete them:  ","e09a61d0":"just check whether only season games are included. This should be the case as we selected the corresponding dates.","424b7b0a":"Now let's drop every line out of drop_list and show us the shape and the head of the dataframe. We can see the adjusted number of lines. Addtionally we now should a have the desired dataframe with one line per NBA game during the regular season.","d7eca3c7":"# Further investigation\n\nNow let's take one step further to see which teams got the most right predictions."}}