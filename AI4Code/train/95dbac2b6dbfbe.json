{"cell_type":{"b3bb8a05":"code","4f8e2a31":"code","82985e55":"code","ce3be639":"code","1d1a5d51":"code","a756985e":"code","ea3e42d8":"code","2fb34196":"code","71a62841":"code","1a3e2d41":"code","25975ea2":"code","a1c1bc2d":"code","4918b470":"code","940a30b3":"code","7bb18189":"code","5b667f82":"code","491099a2":"code","51a238eb":"code","33d0b499":"code","ee85c1b2":"code","5335096d":"code","2d9b8e7e":"code","b66fb642":"code","cd7fd5d3":"code","5e291c13":"code","9be65562":"code","13b71ee5":"code","4d07acd2":"code","97276ca3":"code","d77c6f51":"code","805ae554":"code","9b10992d":"code","530e949f":"code","cbf72ff2":"code","79d5ad65":"code","d42e55de":"code","1d26cd91":"code","b6c462d5":"code","0a64ddd1":"code","915505f1":"code","37cee529":"code","d4df5e71":"code","50fb4989":"code","3a705f43":"code","ace5fb00":"code","209bbc0f":"code","8e8a0323":"code","c6f2204a":"code","dbfd4548":"code","ef5ceb57":"code","2e4a78e4":"code","fa6dbf0d":"code","bf345779":"code","5ceda8f1":"code","8382f033":"code","02817d7c":"code","5b613398":"code","063aa9d3":"code","0104391b":"code","8e108486":"code","2f4968c3":"code","cf2e6d6d":"code","dff68113":"code","720289de":"markdown","fb76d8d9":"markdown","523afc92":"markdown","6c3e12b5":"markdown","b5256623":"markdown","fc01c670":"markdown","46172406":"markdown","8551696a":"markdown","9ffbbc68":"markdown","2a2cab4a":"markdown","be8ecc21":"markdown"},"source":{"b3bb8a05":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","4f8e2a31":"data = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")","82985e55":"data.tail()","ce3be639":"data.head()","1d1a5d51":"from sklearn.model_selection import train_test_split","a756985e":"features = data.iloc[:,[1,2,3,4]]\nlabels = data.iloc[:,5]","ea3e42d8":"X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=20)","2fb34196":"X_train.head()","71a62841":"y_train.head()","1a3e2d41":"X_test.head()","25975ea2":"y_test.head()","a1c1bc2d":"X_train.shape","4918b470":"y_train.shape","940a30b3":"data.shape","7bb18189":"y_test.shape","5b667f82":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","491099a2":"# Trying n=3\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train, y_train)","51a238eb":"# predictiion using my input\nneigh.predict(np.array([[5,3.2,6,6.5]]))","33d0b499":"prediction = neigh.predict(X_test)\naccuracy_score(prediction, y_test)","ee85c1b2":"# Trying now to know the best n\na_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(X_train,y_train)\n    prediction=model.predict(X_test)\n    a=a.append(pd.Series(accuracy_score(prediction,y_test)))\nplt.plot(a_index, a)\nplt.xticks(x)","5335096d":"#Trying n=7\nneigh = KNeighborsClassifier(n_neighbors=7)\nneigh.fit(X_train, y_train)\nprediction = neigh.predict(X_test)\naccuracy_score(prediction, y_test)","2d9b8e7e":"#Trying n=8\nneigh = KNeighborsClassifier(n_neighbors=7)\nneigh.fit(X_train, y_train)\nprediction = neigh.predict(X_test)\naccuracy_score(prediction, y_test)","b66fb642":"#Trying n=9\nneigh = KNeighborsClassifier(n_neighbors=9)\nneigh.fit(X_train, y_train)\nprediction = neigh.predict(X_test)\naccuracy_score(prediction, y_test)","cd7fd5d3":"#Trying n=10\nneigh = KNeighborsClassifier(n_neighbors=10)\nneigh.fit(X_train, y_train)\nprediction = neigh.predict(X_test)\naccuracy_score(prediction, y_test)","5e291c13":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\nf1_score(y_test, prediction, average=None)","9be65562":"plot_confusion_matrix(neigh, X_test, y_test) \n#normalize='all' returns ratios instead of actual numbers\nplt.show()","13b71ee5":"from sklearn.metrics import recall_score\nrecall_score(y_test, prediction, average=None)","4d07acd2":"from sklearn.metrics import precision_score\nprecision_score(y_test, prediction, average='weighted')","97276ca3":"from sklearn.linear_model import LogisticRegression","d77c6f51":"log_reg = LogisticRegression(max_iter=200)\nlog_reg.fit(X_train, y_train)\nprediction = log_reg.predict(X_test)","805ae554":"accuracy_score(y_test, prediction)","9b10992d":"plot_confusion_matrix(log_reg, X_test, y_test)","530e949f":"features_sepal = data.iloc[:,[1,2]]\nfeatures_petal = data.iloc[:,[3,4]]\nlabels = data.iloc[:,5]","cbf72ff2":"features_sepal.head()\nfeatures_sepal.shape","79d5ad65":"labels.head()\nlabels.shape","d42e55de":"X_train_sepal, X_test_sepal, y_train_sepal, y_test_sepal = train_test_split(features_sepal, labels, random_state=10)","1d26cd91":"X_train_sepal.head()\n#X_train_sepal.shape","b6c462d5":"y_train_sepal.head()","0a64ddd1":"# Trying now to know the best n\na_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(X_train_sepal,y_train_sepal)\n    prediction=model.predict(X_test_sepal)\n    a=a.append(pd.Series(accuracy_score(prediction,y_test_sepal)))\nplt.plot(a_index, a)\nplt.xticks(x)","915505f1":"neigh = KNeighborsClassifier(n_neighbors=7)\nneigh.fit(X_train_sepal, y_train_sepal)\nprediction_sepal = neigh.predict(X_test_sepal)\nprint(\"Accuracy_score: \",accuracy_score(prediction_sepal, y_test_sepal))","37cee529":"plot_confusion_matrix(neigh, X_train_sepal, y_train_sepal)","d4df5e71":"print(\"Precision: \",precision_score(y_test_sepal, prediction_sepal, average='weighted'))","50fb4989":"print(\"Recall: \",recall_score(y_test_sepal, prediction_sepal, average='weighted'))","3a705f43":"X_train_petal, X_test_petal, y_train_petal, y_test_petal = train_test_split(features_petal, labels, random_state=16)","ace5fb00":"#Trying now to know the best n\na_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(X_train_petal,y_train_petal)\n    prediction=model.predict(X_test_petal)\n    a=a.append(pd.Series(accuracy_score(prediction,y_test_petal)))\nplt.plot(a_index, a)\nplt.xticks(x)","209bbc0f":"neigh = KNeighborsClassifier(n_neighbors=2)\nneigh.fit(X_train_petal, y_train_petal)\nprediction_petal = neigh.predict(X_test_petal)\nprint(\"Accuracy_score: \",accuracy_score(prediction_petal, y_test_petal))","8e8a0323":"plot_confusion_matrix(neigh, X_train_petal, y_train_petal)","c6f2204a":"print(\"Precision: \",precision_score(y_test_petal, prediction_petal, average='weighted'))","dbfd4548":"print(\"Recall: \",recall_score(y_test_petal, prediction_petal, average='weighted'))","ef5ceb57":"setosa_labels = np.zeros((150,1))","2e4a78e4":"setosa_labels[1]\nsetosa_labels.shape[0]","fa6dbf0d":"labels","bf345779":"for i in range(0,setosa_labels.shape[0]):\n    if(labels[i] == \"Iris-setosa\"):\n        setosa_labels[i]=1","5ceda8f1":"X_train_setosa, X_test_setosa, y_train_setosa, y_test_setosa=train_test_split(features, setosa_labels, random_state=40)","8382f033":"#Trying now to know the best n\na_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=LogisticRegression(max_iter=200)\n    model.fit(X_train_setosa,y_train_setosa)\n    prediction_setosa=model.predict(X_test_setosa)\n    a=a.append(pd.Series(accuracy_score(prediction_setosa,y_test_setosa)))\nplt.plot(a_index, a)\nplt.xticks(x)","02817d7c":"plot_confusion_matrix(model, X_train_setosa, y_train_setosa, )","5b613398":"from sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import plot_roc_curve\n\nplot_precision_recall_curve(model, X_train_setosa, y_train_setosa)","063aa9d3":"plot_roc_curve(model, X_train_setosa, y_train_setosa)","0104391b":"from sklearn import svm","8e108486":"clf = svm.SVC()\nclf.fit(X_train_setosa, y_train_setosa)","2f4968c3":"plot_confusion_matrix(clf, X_train_setosa, y_train_setosa)","cf2e6d6d":"plot_confusion_matrix(clf, X_test_setosa, y_test_setosa)","dff68113":"plot_roc_curve(clf, X_test_setosa, y_test_setosa)","720289de":"## Do binary classification using LogisticRegression\n### I picked _Setosa_","fb76d8d9":"_____\n### Both KNeighborsClassifier and LogisticRegression managed to fit and predict perfectly. Now, let's split the data into 'Sepal' and 'Petal' to see the effect for each on the classification.","523afc92":"____","6c3e12b5":"## LogisticRegression","b5256623":"____","fc01c670":"### Petal only","46172406":"## Do Binary classification using Support Vector Machine (SVM) model\n### I will work also on setosa","8551696a":"## KNeighborsClassifier","9ffbbc68":"1. Do classify the data using 'Sepal' only\n2. Do classify the data using 'Pepal' only","2a2cab4a":"### Sepal only","be8ecc21":"# Iris Dataset"}}