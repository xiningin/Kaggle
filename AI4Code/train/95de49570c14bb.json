{"cell_type":{"7be1cc05":"code","134e2503":"code","a962aa51":"code","23645146":"code","75a98611":"code","ec505dc0":"code","7666cb15":"code","da897df8":"code","04b08f10":"code","8796f568":"markdown"},"source":{"7be1cc05":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import make_pipeline\nimport seaborn as sns","134e2503":"train_df = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample_df = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","a962aa51":"train_df.describe()","23645146":"train_df.isna().sum().describe()","75a98611":"X, y = train_df.iloc[:, 1:-1], train_df.iloc[:, -1]\nprint(X.shape, y.shape)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","ec505dc0":"results = []\nfor n_params in range(1, 100):\n    pipe = make_pipeline(\n        SimpleImputer(strategy='mean'),\n        StandardScaler(),\n        SelectKBest(f_classif, k=n_params),\n        LogisticRegression(random_state=33)\n    )\n    pipe.fit(X_train, y_train)\n    score = pipe.score(X_test, y_test)\n    results.append([n_params, score])","7666cb15":"sns.scatterplot(x=[i[0] for i in results], y=[i[1] for i in results])","da897df8":"n_params = 60\nmpipe = make_pipeline(\n    SimpleImputer(strategy='mean'),\n    StandardScaler(),\n    SelectKBest(f_classif, k=n_params),\n    MLPClassifier(random_state=33, early_stopping=True)\n)\npipe.fit(X_train, y_train)\nprint(f\"score for {n_params} best params: {pipe.score(X_test, y_test)}\")","04b08f10":"n_params = 60\npipe = make_pipeline(\n    SimpleImputer(strategy='mean'),\n    StandardScaler(),\n    SelectKBest(f_classif, k=n_params),\n    GradientBoostingClassifier(n_estimators=1000, learning_rate=0.001, max_depth=4, random_state=33)\n)\npipe.fit(X_train, y_train)\nprint(f\"score for {n_params} best params: {pipe.score(X_test, y_test)}\")","8796f568":"## EDA"}}