{"cell_type":{"b8b55c9c":"code","1fb7ef45":"code","d6449902":"code","4f524e95":"code","5e77b4cc":"code","2564a6a4":"code","74826ccc":"code","5663e346":"code","4d216827":"code","5fab7b6d":"code","df5fe999":"code","eed4bbd6":"code","1ed0f082":"code","3d8c7e8f":"code","50342414":"code","66e69e58":"code","bb7e2734":"code","17f41d26":"code","14f75ca8":"code","c702d179":"code","1b9fc98c":"code","90670db9":"code","5f93045a":"code","991d1078":"code","5b9dbc03":"code","151ad0ba":"code","b4ec3715":"code","4964e94c":"code","abd517a7":"code","e5fa75df":"code","278716d3":"code","8f92fb92":"code","0bc7eef1":"code","d47b2a49":"code","ef07f6a0":"code","e807744f":"code","774f5a9d":"code","a11fe191":"code","ad187caa":"code","5d670e4a":"code","73d9eb9e":"code","3ca0d129":"code","6697cd64":"code","7d21afcd":"code","cfcd5be5":"code","6725fd5e":"code","1d74d20f":"code","a6d0fcd8":"code","4ed2cc5c":"code","a7801886":"code","8f3a8894":"code","794a2b50":"code","fd8bdf77":"code","2a4aed40":"code","ea0d3247":"code","d3a29429":"code","9fef0ea9":"code","18dd8659":"code","b5e4eb9d":"code","821367f2":"code","8cb9b0c4":"code","1be566d5":"code","0b5ea4e8":"code","79d40f06":"code","a789705d":"code","a8555f3b":"code","a4abf0cb":"code","c0c03471":"code","8afead0c":"code","dbd06f1c":"code","f8625079":"code","063d4c66":"code","629c697f":"code","eb2a1283":"code","6e4aecc8":"code","e1fdca8c":"code","3a31c5eb":"code","fafd92c7":"markdown","b43b53d1":"markdown","cc4c49d2":"markdown","19b62c53":"markdown","be8f6318":"markdown","79cda333":"markdown","dc83ef65":"markdown","b7358909":"markdown","195b395e":"markdown","c003d994":"markdown","52a5ec55":"markdown","4c8afa44":"markdown","085d3217":"markdown","ce5bd201":"markdown","73597e81":"markdown","c2fddf51":"markdown","af3fb289":"markdown","35825d34":"markdown","8894c6d5":"markdown","22803787":"markdown","68764a98":"markdown","90f16bd1":"markdown","105d43ce":"markdown","8dff570c":"markdown","a159d62b":"markdown","99d983a9":"markdown","d070cfce":"markdown","96d95500":"markdown","b3c4bc8e":"markdown","ac947e37":"markdown","037febed":"markdown","007dc92a":"markdown","1842a032":"markdown","c56be871":"markdown","086851ee":"markdown","378dfe67":"markdown","1a62418c":"markdown","19904607":"markdown","43c848f8":"markdown","808852c1":"markdown","e78fd937":"markdown","beb1c714":"markdown"},"source":{"b8b55c9c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime # \u0440\u0430\u0431\u043e\u0442\u0430 \u0441 \u0434\u0430\u0442\u0430\u043c\u0438\nimport matplotlib.pyplot as plt # \u0433\u0440\u0430\u0444\u0438\u043a\u0438\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif # \u043e\u0446\u0435\u043d\u043a\u0430 \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\nfrom sklearn.linear_model import LogisticRegression # \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV # \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score # \u043c\u0435\u0442\u0440\u0438\u043a\u0438\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fb7ef45":"DATA_DIR = '\/kaggle\/input\/sf-scoring\/'\ndf_train = pd.read_csv(DATA_DIR +'\/train.csv')\ndf_test = pd.read_csv(DATA_DIR +'\/test.csv')\nsample_submission = pd.read_csv(DATA_DIR+'\/sample_submission.csv')","d6449902":"# \u0412\u0410\u0416\u041d\u041e! \u0434\u043b\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442 \u0432 \u043e\u0434\u0438\u043d \u0434\u0430\u0442\u0430\u0441\u0435\u0442\ndf_train['sample'] = 1 # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0440\u0435\u0439\u043d\ndf_test['sample'] = 0  # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0435\u0441\u0442\ndf_test['default'] = 0 # \u0432 \u0442\u0435\u0441\u0442\u0435 \u0443 \u043d\u0430\u0441 \u043d\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f default, \u043c\u044b \u0435\u0433\u043e \u0434\u043e\u043b\u0436\u043d\u044b \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043a\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c","4f524e95":"# \u041d\u0423\u0416\u041d\u041e \u0411\u041e\u041b\u042c\u0428\u0415 \u041a\u041e\u041b\u041e\u041d\u041e\u041a\npd.set_option('display.max_columns', None)","5e77b4cc":"data.info()","2564a6a4":"data.head()","74826ccc":"data.nunique(dropna=False)","5663e346":"data.isna().sum()","4d216827":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u0443\u044e \u0432\u0435\u0440\u0441\u0438\u044e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u043d\u0430 \u0432\u0441\u044f\u043a\u0438\u0439 \u0441\u043b\u0443\u0447\u0430\u0439\ndata_back = data.copy()","5fab7b6d":"# \u0447\u0442\u043e \u0442\u0430\u043c \u0441 \u0434\u0430\u0442\u043e\u0439?\ndata.app_date.head()","df5fe999":"# \u0434\u0430\u0442\u0443 \u043d\u0430\u0434\u043e \u0440\u0430\u0441\u043f\u0430\u0440\u0441\u0438\u0442\u044c \u0438 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u044c:\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))","eed4bbd6":"# \u043a\u0430\u043a\u0438\u0435 \u0433\u043e\u0434\u044b \u0435\u0441\u0442\u044c \u0432 \u0432\u044b\u0431\u043e\u0440\u043a\u0435?\ndata.app_date.dt.year.value_counts()","1ed0f082":"# \u043a\u0430\u043a\u0438\u0435 \u043c\u0435\u0441\u044f\u0446\u044b?\ndata.app_date.dt.month.value_counts()","3d8c7e8f":"# \u043e\u043a, \u0433\u043e\u0434 \u043c\u043e\u0436\u043d\u043e \u043e\u043f\u0443\u0441\u0442\u0438\u0442\u044c, \u0432\u044b\u0434\u0435\u043b\u0438\u043c \u0438\u0437 \u0434\u0430\u0442\u044b \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \"\u043c\u0435\u0441\u044f\u0446\", \"\u0434\u0435\u043d\u044c \u043d\u0435\u0434\u0435\u043b\u0438\", \"\u0434\u0435\u043d\u044c \u043c\u0435\u0441\u044f\u0446\u0430 \u043f\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0443\", \"\u0434\u0435\u043d\u044c \u0433\u043e\u0434\u0430 \u043f\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0443\"\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month","50342414":"# education:\ndata.education.value_counts()","66e69e58":"data.education.isna().sum()","bb7e2734":"data.sex.value_counts()","17f41d26":"data.age.hist()","14f75ca8":"# \u0430 \u0435\u0441\u043b\u0438 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u0442\u044c?\ndata.age.apply(lambda x: np.log(x)).hist()","c702d179":"data.car.value_counts()","1b9fc98c":"data.car_type.value_counts()","90670db9":"data.decline_app_cnt.value_counts()","5f93045a":"data.good_work.value_counts()","991d1078":"data.score_bki.hist()","5b9dbc03":"data.bki_request_cnt.value_counts()","151ad0ba":"data.region_rating.value_counts()","b4ec3715":"data.home_address.value_counts()","4964e94c":"data.work_address.value_counts()","abd517a7":"data.income.hist()","e5fa75df":"data.income.apply(lambda x: np.log(x)).hist()","278716d3":"data.sna.value_counts()","8f92fb92":"data.first_time.value_counts()","0bc7eef1":"data.foreign_passport.value_counts()","d47b2a49":"# \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043d\u0430\u0434\u043e \u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435:\ndf_train.default.value_counts()","ef07f6a0":"data.day_of_week.value_counts()","e807744f":"data.day_of_month.hist()","774f5a9d":"data.day_of_year.hist()","a11fe191":"data.month.value_counts()","ad187caa":"# \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nnum_cols = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_month', 'day_of_year']\nsns.heatmap(data[num_cols].corr().abs(), vmin=0, vmax=1)","5d670e4a":"data[num_cols].corr().abs()","73d9eb9e":"df_train['app_date'] = df_train.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndf_train['day_of_week'] = df_train.app_date.dt.day_of_week\ndf_train['day_of_month'] = df_train.app_date.dt.day\ndf_train['day_of_year'] = df_train.app_date.dt.day_of_year\ndf_train['month'] = df_train.app_date.dt.month\n\nimp_num = pd.Series(f_classif(df_train[num_cols], df_train['default'])[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","3ca0d129":"# education \u043f\u043e\u043a\u0430 \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u0441\u0430\u043c\u044b\u043c \u0447\u0430\u0441\u0442\u044b\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c\n# \u043f\u043e\u043a\u0430 \u0447\u0442\u043e \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u044d\u0442\u043e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0447\u0438\u0441\u043b\u0430\u043c\u0438, \u043a\u0430\u043a \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0439, \u043f\u043e\u0442\u043e\u043c \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0442\u044c \u0435\u0433\u043e \u043a\u0430\u043a \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\ndf_train.education.fillna('SCH', inplace=True)\nlabel_encoder = LabelEncoder()\ndf_train.education = label_encoder.fit_transform(df_train.education)\n\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\n# \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0442\u043e\u0436\u0435 \u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c\nfor column in bin_cols:\n    df_train[column] = label_encoder.fit_transform(df_train[column])\n# \u0438 \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0440\u0435\u0433\u0438\u043e\u043d\u0430 \u0442\u043e\u0436\u0435, \u0447\u0442\u043e\u0431\u044b \u043c\u0430\u0441\u0448\u0442\u0430\u0431 \u0443 \u0432\u0441\u0435\u0445 \u0431\u044b\u043b \u0435\u0434\u0438\u043d\u044b\u0439 (\u043d\u0435 \u0443\u0432\u0435\u0440\u0435\u043d, \u0432\u0440\u043e\u0434\u0435 \u0431\u044b \u044d\u0442\u043e \u043d\u0435 \u0432\u0430\u0436\u043d\u043e \u0432 \u0430\u0434\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\ndf_train.region_rating = label_encoder.fit_transform(df_train.region_rating)\n\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'day_of_week', 'month']","6697cd64":"df_train.head()","7d21afcd":"imp_cat = pd.Series(mutual_info_classif(df_train[bin_cols + cat_cols], df_train['default'],\n                                     discrete_features =True), index = bin_cols + cat_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')","cfcd5be5":"# \u0417\u0434\u0435\u0441\u044c \u0438 \u0434\u0430\u043b\u0435\u0435 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0451\u043c\u043a\u0438\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u0437\u0430\u043a\u043e\u043c\u0435\u043d\u0447\u0435\u043d\u044b, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0442\u0440\u0430\u0442\u0438\u0442\u044c \u0432\u0440\u0435\u043c\u044f \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e \u0443\u0436\u0435 \u0441\u0434\u0435\u043b\u0430\u043d\u043e\n\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\n\ndata.education.fillna('SCH', inplace=True)\n\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'day_of_week', 'month']\nnum_cols = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_month', 'day_of_year']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n\nfor column in ['age', 'income']:\n    data[column] = data[column].apply(lambda x: np.log(x))\n    \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","6725fd5e":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :49], train_data.iloc[:, 49])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","1d74d20f":"\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'day_of_week', 'month']\nnum_cols = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_month', 'day_of_year']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n\nfor column in ['age', 'income']:\n    data[column] = data[column].apply(lambda x: np.log(x))\n    \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","a6d0fcd8":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :49], train_data.iloc[:, 49])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","4ed2cc5c":"\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\ndata.drop(data[data.decline_app_cnt > 10].index, inplace=True)\ndata.drop(data[data.bki_request_cnt > 12].index, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'day_of_week', 'month']\nnum_cols = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_month', 'day_of_year']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n\nfor column in ['age', 'income']:\n    data[column] = data[column].apply(lambda x: np.log(x))\n    \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","a7801886":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :49], train_data.iloc[:, 49])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","8f3a8894":"\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\ndata.drop(['day_of_month', 'age', 'day_of_week', 'sex'], axis=1, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\nbin_cols = ['car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'month']\nnum_cols = ['decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_year']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n\nfor column in ['income']:\n    data[column] = data[column].apply(lambda x: np.log(x))\n    \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","794a2b50":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :39], train_data.iloc[:, 39])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","fd8bdf77":"\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\ndata.drop(['day_of_month', 'age', 'day_of_week', 'sex'], axis=1, inplace=True)\ndata.drop(['day_of_year', 'income', 'month', 'car', 'good_work'], axis=1, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\nbin_cols = ['car_type', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\nnum_cols = ['decline_app_cnt', 'score_bki', 'bki_request_cnt']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","2a4aed40":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :31], train_data.iloc[:, 31])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","ea0d3247":"\"\"\"data = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\ndata.drop(['day_of_month', 'age', 'day_of_week', 'sex'], axis=1, inplace=True)\ndata.drop(['day_of_year', 'income', 'month', 'car', 'good_work'], axis=1, inplace=True)\ndata.drop(['bki_request_cnt', 'car_type', 'foreign_passport'], axis=1, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\nnum_cols = ['decline_app_cnt', 'score_bki']\n\ndata = pd.get_dummies(data, columns=cat_cols)\n \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()\"\"\"","d3a29429":"\"\"\"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\ntrain_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :28], train_data.iloc[:, 28])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)\n\n\nmodel = LogisticRegression(penalty='l2', C=0.001, class_weight='balanced', dual=False, fit_intercept=True,\n                               intercept_scaling=1, l1_ratio=None, max_iter=1000, multi_class='auto', n_jobs=None,\n                               random_state=None, solver='newton-cg', tol=1e-05, verbose=0, warm_start=False)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)\"\"\"","9fef0ea9":"# \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0439 \u0432\u044b\u0448\u0435 \u043c\u0435\u0442\u043e\u0434 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445\ndata = data_back.copy()\n\ndata['app_date'] = data.app_date.apply(lambda x: datetime.strptime(x, '%d%b%Y'))\ndata['day_of_week'] = data.app_date.dt.day_of_week\ndata['day_of_month'] = data.app_date.dt.day\ndata['day_of_year'] = data.app_date.dt.day_of_year\ndata['month'] = data.app_date.dt.month\n\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)\n\ndata.education.fillna(method='bfill', inplace=True)\n\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time', 'day_of_week', 'month']\nnum_cols = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'day_of_month', 'day_of_year']\n\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n\ndata = pd.get_dummies(data, columns=cat_cols)\n\nfor column in ['age', 'income']:\n    data[column] = data[column].apply(lambda x: np.log(x))\n    \nfor column in num_cols:\n    mean = data[column].mean()\n    std = data[column].std()\n    data[column] = data[column].apply(lambda x: (x-mean)\/std)\n    \ndata.head()","18dd8659":"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)","b5e4eb9d":"#train_data[train_data.default==0].sex.count()","821367f2":"#train_data[train_data.default==1].sex.count()","8cb9b0c4":"#train_data = train_data[train_data.default == 0].sample(n=9372*5).append(train_data[train_data.default==1])","1be566d5":"#train_data[train_data.default==0].sex.count()","0b5ea4e8":"#train_data[train_data.default==1].sex.count()","79d40f06":"train_data['new_default'] = train_data['default']\ntrain_data.drop('default', axis=1, inplace=True)\ntrain_data.rename(columns={\"new_default\": \"default\"}, inplace=True)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\ntrain_indices, valid_indices = [split for split in sss.split(train_data.iloc[:, :28], train_data.iloc[:, 28])][0]\ntrain = train_data.iloc[train_indices]\nval = train_data.iloc[valid_indices]\n\ny_train = train['default'].values\nX_train = train.drop(['default'], axis=1)\n\ny_val = val['default'].values\nX_val = val.drop(['default'], axis=1)","a789705d":"# \u0441\u0435\u0442\u043a\u0430 \u0434\u043b\u044f \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\n\"\"\"param_grid = [\n        {'penalty': ['l1'],\n         'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n         'solver': ['liblinear'],\n         'class_weight': [None, 'balanced'],\n         'multi_class': ['auto', 'ovr'],\n         'max_iter': [500],\n         'tol': [1e-3]},\n        {'penalty': ['l2'],\n         'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n         'class_weight': [None, 'balanced'],\n         'multi_class': ['auto', 'ovr'],\n         'max_iter': [500],\n         'tol': [1e-3]},\n        {'penalty': ['none'],\n         'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n         'class_weight': [None, 'balanced'],\n         'multi_class': ['auto', 'ovr'],\n         'max_iter': [500],\n         'tol': [1e-3]},\n    ]\"\"\"","a8555f3b":"# \u043f\u043e\u0434\u0431\u043e\u0440 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u0438 GridSearchCV\n\"\"\"model = LogisticRegression()\ngridsearch = GridSearchCV(model, param_grid, scoring='f1', n_jobs=-1, cv=5)\ngridsearch.fit(X_train, y_train)\nmodel = gridsearch.best_estimator_\n\n##\u043f\u0435\u0447\u0430\u0442\u0430\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nbest_parameters = model.get_params()\nfor param_name in sorted(best_parameters.keys()):\n    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\"\"\"","a4abf0cb":"param_grid = [\n        {'penalty': ['l2'],\n         'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n         'solver': ['newton-cg'],\n         'class_weight': ['balanced'],\n         'multi_class': ['auto'],\n         'max_iter': [1000],\n         'tol': [1e-5]},\n    ]","c0c03471":"# \u043f\u043e\u0434\u0431\u043e\u0440 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u0438 GridSearchCV\nmodel = LogisticRegression()\ngridsearch = GridSearchCV(model, param_grid, scoring='f1', n_jobs=-1, cv=5)\ngridsearch.fit(X_train, y_train)\nmodel = gridsearch.best_estimator_\n\n##\u043f\u0435\u0447\u0430\u0442\u0430\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nbest_parameters = model.get_params()\nfor param_name in sorted(best_parameters.keys()):\n    print('\\t%s: %r' % (param_name, best_parameters[param_name]))","8afead0c":"model.fit(X_train, y_train)\ny_pred = model.predict(X_val)\n\nmatrix = confusion_matrix(y_val, y_pred)\ncreport = classification_report(y_val, y_pred)\nras = roc_auc_score(y_val, y_pred)\nprint(creport)\nprint(ras)","dbd06f1c":"threshold = 0\nmax_f1 = 0\npred_proba_df = pd.DataFrame(model.predict_proba(X_val)) # \u0440\u0430\u0441\u0441\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438\nthreshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u043e\u0440\u043e\u0433\u0438\nfor i in threshold_list:\n    print('\\n******** For i = {} ******'.format(i))\n    y_pred = pred_proba_df.applymap(lambda x: 1 if x>i else 0).values[:, 1] # \u043d\u0430\u0441 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u0435\u0442 \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u043d\u043e\u0441\u0442\u044c \u043a \u043a\u043b\u0430\u0441\u0441\u0443 1\n    test_f1_score = f1_score(y_val, y_pred, average='binary', pos_label=1) # \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0434\u043b\u044f \u043d\u0430\u0441 - f1\n    if test_f1_score > max_f1:\n        max_f1 = test_f1_score\n        threshold = i\n    print('Our testing f1 is {}'.format(test_f1_score))\n    print(confusion_matrix(y_val, y_pred))","f8625079":"threshold_list = [0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65] # \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u043e\u0440\u043e\u0433\u0438\nfor i in threshold_list:\n    print('\\n******** For i = {} ******'.format(i))\n    y_pred = pred_proba_df.applymap(lambda x: 1 if x>i else 0).values[:, 1] # \u043d\u0430\u0441 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u0435\u0442 \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u043d\u043e\u0441\u0442\u044c \u043a \u043a\u043b\u0430\u0441\u0441\u0443 1\n    test_f1_score = f1_score(y_val, y_pred, average='binary', pos_label=1) # \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0434\u043b\u044f \u043d\u0430\u0441 - f1\n    if test_f1_score > max_f1:\n        max_f1 = test_f1_score\n        threshold = i\n    print('Our testing f1 is {}'.format(test_f1_score))\n    print(confusion_matrix(y_val, y_pred))","063d4c66":"threshold","629c697f":"max_f1","eb2a1283":"y = train_data['default'].values\nX = train_data.drop(['default'], axis=1)\nmodel.fit(X, y)","6e4aecc8":"pred_proba_df = pd.DataFrame(model.predict_proba(test_data))\npredict_submission = pred_proba_df.applymap(lambda x: 1 if x>threshold else 0).values[:, 1]\nsample_submission['default'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","e1fdca8c":"!kaggle competitions submit -c sf-scoring -f submission.csv -m \"Aleksandr Sokolkin\"\n# !kaggle competitions submit your-competition-name -f submission.csv -m 'My submission message'","3a31c5eb":"%env KAGGLE_USERNAME=\"andyhide\"\n%env KAGGLE_KEY=\"2a202451f876002f4c7b8483929547a1\"","fafd92c7":"\u0421\u043d\u0430\u0447\u0430\u043b\u0430 day_of_month, age, day_of_week, sex","b43b53d1":"\u041a \u0441\u043e\u0436\u0430\u043b\u0435\u043d\u0438\u044e, \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u044d\u0442\u043e\u0442 \u043c\u0435\u0442\u043e\u0434 \u043f\u043e\u043a\u0430\u0437\u0430\u043b \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0443\u0445\u0443\u0434\u0448\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430","cc4c49d2":"\u0421\u0442\u0430\u043b\u043e \u0435\u0449\u0451 \u0445\u0443\u0436\u0435, \u043d\u043e \u043c\u044b \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0437 \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438","19b62c53":"\u0422\u0430\u043a \u0431\u043e\u043b\u044c\u0448\u0435 \u043f\u043e\u0445\u043e\u0436\u0435 \u043d\u0430 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435","be8f6318":"\u0422\u0443\u0442 \u0432\u0441\u0451 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e","79cda333":"**\u0412\u0435\u0440\u0441\u0438\u044f 1:**\n- \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0441\u0430\u043c\u044b\u043c \u0447\u0430\u0441\u0442\u044b\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c\n- \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u0435\u043c","dc83ef65":"\u0412\u0438\u0434\u0438\u043c 478 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432. \u041f\u043e\u0437\u0436\u0435 \u043f\u043e\u0434\u0443\u043c\u0430\u0435\u043c, \u043a\u0430\u043a \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438","b7358909":"\u041d\u0430 \u043c\u043e\u0439 \u0432\u0437\u0433\u043b\u044f\u0434, \u0437\u0434\u0435\u0441\u044c \u043d\u0435\u0442 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u0438 \u043d\u0435\u0432\u0435\u0440\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445. \u041f\u043e \u043c\u0435\u0436\u043a\u0432\u0430\u0440\u0442\u0438\u043b\u044c\u043d\u044b\u043c \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u044f\u043c \u043c\u043e\u0436\u043d\u043e, \u043a\u043e\u043d\u0435\u0447\u043d\u043e, \u0443\u0434\u0430\u043b\u0438\u0442\u044c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u043e\u0434\u0445\u043e\u0434\u044b.","195b395e":"\u0422\u043e\u0436\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u043e\u0434\u0445\u043e\u0434\u044b","c003d994":"\u041a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u044b \u043d\u0430 \u0432\u044b\u043b\u0435\u0442:\n- day_of_month, age\n- day_of_year, income\n- bki_request_cnt","52a5ec55":"**\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445**","4c8afa44":"**\u0412\u0435\u0440\u0441\u0438\u044f 4:**","085d3217":"\u042f \u043f\u0435\u0440\u0435\u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043b \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e 5 \u0440\u0430\u0437. \u0422\u0430\u043a\u043e\u0435 \u0432\u043f\u0435\u0447\u0430\u0442\u043b\u0435\u043d\u0438\u0435, \u0447\u0442\u043e \u0432\u0442\u043e\u0440\u043e\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u0447\u0443\u0442\u044c-\u0447\u0443\u0442\u044c \u043b\u0443\u0447\u0448\u0435.","ce5bd201":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0441\u043e\u0432\u0441\u0435\u043c \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u0442\u0430\u043f\u043e\u0432","73597e81":"\u0412\u044b\u0432\u043e\u0434 \u0442\u0430\u043a\u043e\u0439: \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u0442\u044c \u043d\u0435 \u0431\u0443\u0434\u0435\u043c, education \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u0441\u043e\u0441\u0435\u0434\u043d\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","c2fddf51":"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0441\u0442\u0430\u043b \u0447\u0443\u0442\u044c \u043f\u043e\u0445\u0443\u0436\u0435, \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0432 \u044d\u0442\u0438\u0445 \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u0445","af3fb289":"\u0422\u0435\u043f\u0435\u0440\u044c \u044f \u0445\u043e\u0447\u0443 \u0437\u0430\u043d\u044f\u0442\u044c\u0441\u044f \u0432\u044b\u0431\u043e\u0440\u043e\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u043c\u0435\u0442\u043e\u0434\u0430 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445.\n\u0421 \u0447\u0435\u043c \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0438\u0433\u0440\u0430\u0442\u044c:\n- \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0432 education\n- \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \"\u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\" \u0432 decline_app_cnt \u0438 bki_request_cnt\n- \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","35825d34":"\u041c\u043e\u0436\u043d\u043e \u043f\u043e\u0434\u043e\u0439\u0442\u0438 \u043a \u044d\u0442\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043a\u0430\u043a \u043a \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439 \u0438\u043b\u0438 \u043a\u0430\u043a \u043a \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u043e\u0439.","8894c6d5":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c \"\u043b\u0438\u0448\u043d\u0438\u0435\" \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0432 decline_app_cnt \u0438 bki_request_cnt","22803787":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u0442\u043e\u0447\u043d\u0438\u0442\u044c","68764a98":"\u0422\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c, \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0438 \u0441\u0430\u0431\u043c\u0438\u0442","90f16bd1":"\u041a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u044b \u043d\u0430 \u0432\u044b\u043b\u0435\u0442:\n- day_of_week, sex\n- month, car, good_work\n- car_type, foreign_passport","105d43ce":"\u0415\u0449\u0451 \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u0447\u0430\u0441\u0442\u044c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u043c 0, \u0447\u0442\u043e\u0431\u044b \u0438\u0441\u043f\u0440\u0430\u0432\u0438\u0442\u044c \u0434\u0438\u0441\u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u044e","8dff570c":"\u043e\u043a, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u043f\u043e\u0434\u0445\u043e\u0434:\n- \u0438\u0437\u043c\u0435\u043d\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 education - \u043d\u0435 \u0441\u0430\u043c\u044b\u043c \u0447\u0430\u0441\u0442\u044b\u043c, \u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u043c \u043f\u0435\u0440\u0435\u0434 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u043c","a159d62b":"\u0418\u0442\u043e\u0433\u043e, \u0432 \u043f\u043b\u0430\u043d\u0435 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043a\u0430\u043a\u0438\u0435 \u0443 \u043c\u0435\u043d\u044f \u0435\u0441\u0442\u044c \u0441\u043e\u043c\u043d\u0435\u043d\u0438\u044f:\n- \u043a\u0430\u043a \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 education? \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u043b\u0438\u0448\u043d\u0435\u0435?\n- \u043a\u0430\u043a\u0438\u0435 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0435 \u0431\u0440\u0430\u0442\u044c \u0438\u0437 \u0434\u0430\u0442\u044b \u043f\u043e\u0434\u0430\u0447\u0438 \u0437\u0430\u044f\u0432\u043a\u0438?\n- \u0434\u0435\u043b\u0430\u0442\u044c \u0447\u0442\u043e-\u0442\u043e \u0441 \"\u0432\u044b\u0431\u0440\u043e\u0441\u0430\u043c\u0438\" \u0432 decline_app_cnt \u0438 bki_request_cnt?","99d983a9":"\u0422\u0430\u043a \u043d\u0430\u043c\u043d\u043e\u0433\u043e \u043b\u0443\u0447\u0448\u0435","d070cfce":"**\u0412\u0435\u0440\u0441\u0438\u044f 5:**","96d95500":"\u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0442\u044c \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u043c\u0435\u0442\u043e\u0434\u044b \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0431\u0443\u0434\u0435\u043c \u043d\u0430 \u043e\u0434\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438. \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043c\u043e\u0434\u0435\u043b\u0438 \u0431\u044b\u043b\u0438 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u044b \u0437\u0430\u0440\u0430\u043d\u0435\u0435, \u043f\u043e\u043a\u0430 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0445.","b3c4bc8e":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0439 \u043f\u043e\u0440\u043e\u0433:","ac947e37":"**\u0412\u0435\u0440\u0441\u0438\u044f 2:**","037febed":"\u041e\u0442\u0431\u0440\u043e\u0441\u0438\u043c \u0435\u0449\u0451 day_of_year, income, month, car, good_work","007dc92a":"\u041b\u0443\u0447\u0448\u0435 \u043d\u0435 \u0441\u0442\u0430\u043b\u043e, \u043d\u043e \u043c\u044b \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0438\u043c","1842a032":"\u0412\u0438\u0434\u043d\u0430 \u0434\u0438\u0441\u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u044f, \u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0430\u0434\u043e \u0431\u0443\u0434\u0435\u0442 \u0441 \u0443\u0447\u0451\u0442\u043e\u043c \u044d\u0442\u043e\u0433\u043e","c56be871":"**\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438:**","086851ee":"\u041e\u043a, \u0432\u044b\u0431\u0440\u0430\u043d\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 newton-cg. \u041f\u0440\u043e\u0432\u0435\u0434\u0451\u043c \u043f\u043e\u0434\u0431\u043e\u0440 \u0435\u0449\u0451 \u0440\u0430\u0437, \u043d\u0430 \u044d\u0442\u043e\u0442 \u0440\u0430\u0437 \u0441 \u0434\u0440\u0443\u0433\u0438\u043c \u043f\u043e\u0440\u043e\u0433\u043e\u043c","378dfe67":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u0432\u043d\u0438\u043c\u0430\u0442\u0435\u043b\u044c\u043d\u0435\u0435","1a62418c":"**\u041d\u0430\u0447\u0438\u043d\u0430\u0435\u043c \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445**","19904607":"**\u0412\u0435\u0440\u0441\u0438\u044f 6:**","43c848f8":"\u041f\u043e\u0434\u0441\u043c\u043e\u0442\u0440\u0435\u043b \u0435\u0449\u0451 \u043f\u043e \u0430\u0434\u0440\u0435\u0441\u0443 https:\/\/stackoverflow.com\/questions\/28716241\/controlling-the-threshold-in-logistic-regression-in-scikit-learn \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0443 \u043f\u043e\u0440\u043e\u0433\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 - \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432\u044b\u0448\u0435 \u043f\u043e\u0440\u043e\u0433\u0430 \u043e\u0442\u043d\u043e\u0441\u0438\u043c \u043a \u043a\u043b\u0430\u0441\u0441\u0443 1, \u043d\u0438\u0436\u0435 - \u043a 0","808852c1":"**\u0412\u0435\u0440\u0441\u0438\u044f 3:**","e78fd937":"\u0415\u0441\u0442\u044c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438, \u043d\u043e \u043d\u0435 \u043d\u0430\u0441\u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0438\u043b\u044c\u043d\u044b\u0435, \u0447\u0442\u043e\u0431\u044b \u043e\u0442\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u043a\u0430\u043a\u0438\u0435-\u0442\u043e \u043a\u043e\u043b\u043e\u043d\u043a\u0438","beb1c714":"**\u0412\u044b\u0431\u043e\u0440 \u043c\u043e\u0434\u0435\u043b\u0438**"}}