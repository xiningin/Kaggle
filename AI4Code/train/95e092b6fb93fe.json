{"cell_type":{"b9551dd3":"code","03f0ed71":"code","5d9ccbb4":"code","ae759c53":"code","fe690918":"code","a6b960d3":"code","1f147b52":"code","19f1ba05":"code","96609f8c":"code","c7ac7f42":"code","e4befa0d":"code","e5567757":"code","3e0ca9f3":"code","7c100ed2":"code","063a39e3":"code","cead24d3":"code","4ec3980b":"code","f2310b23":"code","8cedc2ed":"code","6fdf15d7":"code","2a52a520":"code","d3d53f1b":"code","65224247":"code","ed01bbf4":"code","4c6feb24":"code","8a614c4f":"code","e63a5c0c":"code","7455fc67":"code","a6c4e243":"code","0f435bd7":"code","f5be31b2":"code","6adc50fd":"code","d0b5cdeb":"code","36bce1a8":"code","4728e2ac":"code","4d96cb36":"code","51ff9461":"code","63a24458":"code","de5469cd":"code","58d17f58":"markdown","53400b7c":"markdown","ca8b01e0":"markdown","323b0ed5":"markdown","6a346159":"markdown","19d1d26c":"markdown","573a90c8":"markdown"},"source":{"b9551dd3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03f0ed71":"from bs4 import BeautifulSoup\nfrom collections import Counter,defaultdict\nfrom gensim.models import Word2Vec,KeyedVectors\nimport gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport matplotlib\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly import tools\npy.init_notebook_mode(connected=True)\nimport re\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import PCA, TruncatedSVD,SparsePCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve,r2_score,recall_score,confusion_matrix,precision_recall_curve\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score,StratifiedKFold,KFold,StratifiedShuffleSplit,cross_val_predict\nfrom lightgbm import LGBMClassifier as lg\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import LSTM, Dense,Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D\nfrom keras.optimizers import Adam\nimport numpy as np  \nimport pandas as pd \nimport keras.backend as k\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional,GRU\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import plot_model\nfrom xgboost import XGBClassifier as xg\nfrom lightgbm import LGBMClassifier as lg\nimport string\nfrom unidecode import unidecode\nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n%matplotlib inline","5d9ccbb4":"train_df= pd.read_json(\"\/kaggle\/input\/github-bugs-prediction\/embold_train.json\").reset_index(drop=True)\ntest_df= pd.read_json(\"\/kaggle\/input\/github-bugs-prediction\/embold_test.json\").reset_index(drop=True)\ntrain_extra_df= pd.read_json(\"..\/input\/github-bugs-prediction\/embold_train_extra.json\").reset_index(drop=True)","ae759c53":"def fx(x):\n    return x['title'] + \" \" + x['body']   \ntrain_df['text']= train_df.apply(lambda x : fx(x),axis=1)\ntest_df['text']= test_df.apply(lambda x : fx(x),axis=1)","fe690918":"cList = {\n            \"i'm\": \"i am\",\n            \"you're\": \"you are\",\n            \"it's\": \"it is\",\n            \"we're\": \"we are\",\n            \"we'll\": \"we will\",\n            \"That's\":\"that is\",\n            \"haven't\":\"have not\",\n            \"let's\":\"let us\",\n            \"ain't\": \"am not \/ are not \/ is not \/ has not \/ have not\",\n            \"aren't\": \"are not \/ am not\",\n            \"can't\": \"cannot\",\n            \"can't've\": \"cannot have\",\n            \"'cause\": \"because\",\n            \"could've\": \"could have\",\n            \"couldn't\": \"could not\",\n            \"couldn't've\": \"could not have\",\n            \"didn't\": \"did not\",\n            \"doesn't\": \"does not\",\n            \"don't\": \"do not\",\n            \"hadn't\": \"had not\",\n            \"hadn't've\": \"had not have\",\n            \"hasn't\": \"has not\",\n            \"haven't\": \"have not\",\n            \"he'd\": \"he had \/ he would\",\n            \"he'd've\": \"he would have\",\n            \"he'll\": \"he shall \/ he will\",\n            \"he'll've\": \"he shall have \/ he will have\",\n            \"he's\": \"he has \/ he is\",\n            \"how'd\": \"how did\",\n            \"how'd'y\": \"how do you\",\n            \"how'll\": \"how will\",\n            \"how's\": \"how has \/ how is \/ how does\",\n            \"I'd\": \"I had \/ I would\",\n            \"I'd've\": \"I would have\",\n            \"I'll\": \"I shall \/ I will\",\n            \"I'll've\": \"I shall have \/ I will have\",\n            \"I'm\": \"I am\",\n            \"I've\": \"I have\",\n            \"isn't\": \"is not\",\n            \"it'd\": \"it had \/ it would\",\n            \"it'd've\": \"it would have\",\n            \"it'll\": \"it shall \/ it will\",\n            \"it'll've\": \"it shall have \/ it will have\",\n            \"it's\": \"it has \/ it is\",\n            \"let's\": \"let us\",\n            \"ma'am\": \"madam\",\n            \"mayn't\": \"may not\",\n            \"might've\": \"might have\",\n            \"mightn't\": \"might not\",\n            \"mightn't've\": \"might not have\",\n            \"must've\": \"must have\",\n            \"mustn't\": \"must not\",\n            \"mustn't've\": \"must not have\",\n            \"needn't\": \"need not\",\n            \"needn't've\": \"need not have\",\n            \"o'clock\": \"of the clock\",\n            \"oughtn't\": \"ought not\",\n            \"oughtn't've\": \"ought not have\",\n            \"shan't\": \"shall not\",\n            \"sha'n't\": \"shall not\",\n            \"shan't've\": \"shall not have\",\n            \"she'd\": \"she had \/ she would\",\n            \"she'd've\": \"she would have\",\n            \"she'll\": \"she shall \/ she will\",\n            \"she'll've\": \"she shall have \/ she will have\",\n            \"she's\": \"she has \/ she is\",\n            \"should've\": \"should have\",\n            \"shouldn't\": \"should not\",\n            \"shouldn't've\": \"should not have\",\n            \"so've\": \"so have\",\n            \"so's\": \"so as \/ so is\",\n            \"that'd\": \"that would \/ that had\",\n            \"that'd've\": \"that would have\",\n            \"that's\": \"that has \/ that is\",\n            \"there'd\": \"there had \/ there would\",\n            \"there'd've\": \"there would have\",\n            \"there's\": \"there has \/ there is\",\n            \"they'd\": \"they had \/ they would\",\n            \"they'd've\": \"they would have\",\n            \"they'll\": \"they shall \/ they will\",\n            \"they'll've\": \"they shall have \/ they will have\",\n            \"they're\": \"they are\",\n            \"they've\": \"they have\",\n            \"to've\": \"to have\",\n            \"wasn't\": \"was not\",\n            \"we'd\": \"we had \/ we would\",\n            \"we'd've\": \"we would have\",\n            \"we'll\": \"we will\",\n            \"we'll've\": \"we will have\",\n            \"we're\": \"we are\",\n            \"we've\": \"we have\",\n            \"weren't\": \"were not\",\n            \"what'll\": \"what shall \/ what will\",\n            \"what'll've\": \"what shall have \/ what will have\",\n            \"what're\": \"what are\",\n            \"what's\": \"what has \/ what is\",\n            \"what've\": \"what have\",\n            \"when's\": \"when has \/ when is\",\n            \"when've\": \"when have\",\n            \"where'd\": \"where did\",\n            \"where's\": \"where has \/ where is\",\n            \"where've\": \"where have\",\n            \"who'll\": \"who shall \/ who will\",\n            \"who'll've\": \"who shall have \/ who will have\",\n            \"who's\": \"who has \/ who is\",\n            \"who've\": \"who have\",\n            \"why's\": \"why has \/ why is\",\n            \"why've\": \"why have\",\n            \"will've\": \"will have\",\n            \"won't\": \"will not\",\n            \"won't've\": \"will not have\",\n            \"would've\": \"would have\",\n            \"wouldn't\": \"would not\",\n            \"wouldn't've\": \"would not have\",\n            \"y'all\": \"you all\",\n            \"y'all'd\": \"you all would\",\n            \"y'all'd've\": \"you all would have\",\n            \"y'all're\": \"you all are\",\n            \"y'all've\": \"you all have\",\n            \"you'd\": \"you had \/ you would\",\n            \"you'd've\": \"you would have\",\n            \"you'll\": \"you shall \/ you will\",\n            \"you'll've\": \"you shall have \/ you will have\",\n            \"you're\": \"you are\",\n            \"you've\": \"you have\"\n           }","a6b960d3":"c_re = re.compile('(%s)' % '|'.join(cList.keys()))\ndef expandContractions(text, c_re=c_re):\n    def replace(match):\n        return cList[match.group(0)]\n    return c_re.sub(replace, text)","1f147b52":"def remove_emoji(string):\n        emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n        return emoji_pattern.sub(r'', string) ","19f1ba05":"def remove_punctuations(data):\n    punct_tag=re.compile(r'[^\\w\\s]')\n    data=punct_tag.sub(r'',data)\n    return data","96609f8c":"def removeSpecialChars(data):\n    '''\n    Removes special characters which are specifically found in tweets.\n    '''\n    #Converts HTML tags to the characters they represent\n    soup = BeautifulSoup(data, \"html.parser\")\n    data = soup.get_text()\n\n    #Convert www.* or https?:\/\/* to empty strings\n    data = re.sub('((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))','',data)\n\n    #Convert @username to empty strings\n    data = re.sub('@[^\\s]+','',data)\n    \n    #remove org.apache. like texts\n    data =  re.sub('(\\w+\\.){2,}','',data)\n\n    #Remove additional white spaces\n    data = re.sub('[\\s]+', ' ', data)\n    \n    data = re.sub('\\.(?!$)', '', data)\n\n    #Replace #word with word\n    data = re.sub(r'#([^\\s]+)', r'\\1', data)\n\n    return data ","c7ac7f42":"def remove_nonenglish_charac(string):\n    return re.sub('\\W+','', string )","e4befa0d":"extra_punctuations = ['','.', '``', '...', '\\'s', '--', '-', 'n\\'t', '_', '\u2013','&']\nstopword_list = stopwords.words('english') + list(string.punctuation)+ extra_punctuations + ['u','the','us','say','that','he','me','she','get','rt','it','mt','via','not','and','let','so','say','dont','use','you']","e5567757":"def clean_text(data):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    stemmer = PorterStemmer() \n    tokenizer=TweetTokenizer()\n    data = unidecode(data)\n    data = expandContractions(data)\n    tokens = tokenizer.tokenize(data)\n    data = ' '.join([tok for tok in tokens if len(tok) > 2 if tok not in stopword_list and not tok.isdigit()])\n    data = re.sub('\\b\\w{,2}\\b', '', data)\n    data = re.sub(' +', ' ', data)\n    data = removeSpecialChars(data)\n    data = remove_emoji(data)\n    data= [stemmer.stem(w) for w in data.split()]\n    return ' '.join([wordnet_lemmatizer.lemmatize(word) for word in data])","3e0ca9f3":"train_df['text'] = train_df['text'].apply(lambda x: clean_text(x))","7c100ed2":"def Split_Data(df,col_name):\n    #Split the dataset into training and testing sets\n    df_y=df['label']\n    return train_test_split(df[col_name],df_y,test_size=0.3,random_state=42)","063a39e3":"def tokenize_data_with_padding(train_x,val_x):\n    tokenizer=Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(train_x))\n    train_x=tokenizer.texts_to_sequences(train_x)\n    val_x=tokenizer.texts_to_sequences(val_x)\n    train_x=pad_sequences(train_x,maxlen=maxlen)\n    val_x=pad_sequences(val_x,maxlen=maxlen)\n    print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n    print(\"Target training Values Shape\".format(),train_y.shape)\n    print(\"Padded and Tokenized Validation Sequence\".format(),val_x.shape)\n    print(\"Target validation Values Shape\".format(),val_y.shape)\n    return train_x,val_x,tokenizer","cead24d3":"train_x,val_x,train_y,val_y=Split_Data(train_df,'text')","4ec3980b":"maxlen=1000\nmax_features=5000 \nembed_size=300","f2310b23":"train_x, val_x, tokenized_data = tokenize_data_with_padding(train_x,val_x)","8cedc2ed":"def seq2seq_encoder_decoder(maxlen,max_features,embed_size):\n    \n    #Creating LSTM  encoder neural model with no pretrained embeddings\n    encoder_inp=Input(shape=(maxlen,))\n    encoder_embed=Embedding(max_features,embed_size,input_length=maxlen,trainable=True)(encoder_inp)\n    encoder_lstm_cell=LSTM(100,return_state='True')\n    encoder_outputs,encoder_state_lstm_h,encoder_state_lstm_c=encoder_lstm_cell(encoder_embed)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,input_length=maxlen,trainable=True)(decoder_inp)\n    decoder_lstm_cell=LSTM(100,return_state=True)\n    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[encoder_state_lstm_h,encoder_state_lstm_c])\n    decoder_dense_cell=Dense(16,activation='relu')\n    decoder_d_output=decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2=Dense(3,activation='softmax')\n    decoder_output=decoder_dense_cell2(decoder_d_output)\n    model=Model([encoder_inp,decoder_inp],decoder_output)\n    model.summary()\n    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    plot_model(\n    model,to_file=\"seq2seq_encoder_decoder_model.png\",\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96)\n    model.fit([train_x,train_x],train_y,batch_size=512,epochs=1,verbose=2)","6fdf15d7":"seq2seq_encoder_decoder(maxlen,max_features,embed_size)","2a52a520":"def del_obj(*objs):\n    for obj in objs:\n        del obj\n        gc.collect()","d3d53f1b":"def get_coefs(word,*arr): \n    return word, np.asarray(arr, dtype='float32')","65224247":"def create_Embedding_matrix(EMBEDDING_FILE,tokenizer):\n    # Create the dictionary of pretrained embedding\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n    \n    # prepared multidimentional dictionary\n    embeds = np.stack(embeddings_index.values())\n    emb_mean,emb_std = embeds.mean(), embeds.std()\n    embed_size = embeds.shape[1]\n    \n    # prepare a gausian distribution\n    word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix","ed01bbf4":"def seq2seq_encoder_decoder_with_embedding(maxlen,max_features,embed_size,embedding_matrix,emb_name):\n    #Creating LSTM  encoder neural model with pretrained embeddings\n    encoder_inp=Input(shape=(maxlen,))\n    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n    encoder_lstm_cell= LSTM(60, return_state=True)\n    encoder_outputs,encoder_state_lstm_h,encoder_state_lstm_c=encoder_lstm_cell(encoder_embed)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n    decoder_lstm_cell= LSTM(60,return_state=True)\n    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[encoder_state_lstm_h,encoder_state_lstm_c])\n    decoder_dense_cell=Dense(16,activation='relu')\n    decoder_d_output=decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2=Dense(3,activation='softmax')\n    decoder_output=decoder_dense_cell2(decoder_d_output)\n    model=Model([encoder_inp,decoder_inp],decoder_output)\n    model.summary()\n    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    plot_model(\n        model,to_file=emb_name,\n        show_shapes=True,\n        show_layer_names=True,\n        rankdir=\"TB\",\n        expand_nested=False,\n        dpi=96)\n\n    model.fit([train_x,train_x],train_y,batch_size=256,epochs=2,verbose=2)","4c6feb24":"golve_emd_file = '..\/input\/glove-global-vectors-for-word-representation\/glove.6B.50d.txt'\ngolve_emd_matrix = create_Embedding_matrix(golve_emd_file,tokenized_data)\nseq2seq_encoder_decoder_with_embedding(maxlen,max_features,len(golve_emd_matrix[0]),golve_emd_matrix,\"seq2seq_encoder_decoder_model_glovetext.png\")","8a614c4f":"del(golve_emd_matrix)","e63a5c0c":"def bidirectional_seq2seq_encoder_decoder_with_embdedding(bidire_model,maxlen,max_features,embed_size,embedding_matrix,emb_name):\n    #Creating LSTM  encoder neural model with no pretrained embeddings\n    encoder_inp=Input(shape=(maxlen,))\n    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n    encoder_lstm_cell=Bidirectional(bidire_model)\n    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c,encoder_state_blstm_h,encoder_state_blstm_c=encoder_lstm_cell(encoder_embed)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    encoded_states=[encoder_state_flstm_h,encoder_state_flstm_c,encoder_state_blstm_h,encoder_state_blstm_c]\n    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n    \n    decoder_lstm_cell=Bidirectional(bidire_model,merge_mode=\"concat\")\n    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n    \n    decoder_dense_cell=Dense(16,activation='relu')\n    decoder_d_output=decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2=Dense(3,activation='softmax')\n    decoder_output=decoder_dense_cell2(decoder_d_output)\n    model=Model([encoder_inp,decoder_inp],decoder_output)\n    model.summary() \n    model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n    plot_model(\n        model,to_file=emb_name,\n        show_shapes=True,\n        show_layer_names=True,\n        rankdir=\"TB\",\n        expand_nested=False,\n        dpi=96)\n    model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)","7455fc67":"fastetxt_Embedding_File = '..\/input\/fast-text-embeddings-without-subwords\/crawl-300d-2M.vec\/crawl-300d-2M.vec'\nfastetxt_emd_matrix = create_Embedding_matrix(fastetxt_Embedding_File,tokenized_data)\nbidirectional_seq2seq_encoder_decoder_with_embdedding(LSTM(60,return_state=True),maxlen,max_features,len(fastetxt_emd_matrix[0]),fastetxt_emd_matrix,\"seq2seq_encoder_decoder_model_fastetxt.png\")","a6c4e243":"def hybrid_bidirectional_seq2seq_encoder_decoder(model,maxlen,max_features,embed_size,embedding_matrix,emb_name):\n    \n    #Creating LSTM encoder neural model with pretrained embeddings\n    encoder_inp=Input(shape=(maxlen,))\n    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n    encoder_lstm_cell=Bidirectional(model,merge_mode='sum')\n    encoder_outputs,encoder_flstm_h,encoder_flstm_c,encoder_blstm_h,encoder_blstm_c=encoder_lstm_cell(encoder_embed)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    encoded_states=[encoder_flstm_h + encoder_blstm_h,encoder_flstm_c + encoder_blstm_c]\n    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n    \n    decoder_lstm_cell = model\n    # we can ignore the hidden state and cell state retuned output\n    decoder_outputs,_,_ = decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n    \n    decoder_dense_cell= Dense(16,activation='relu')\n    decoder_d_output = decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2 = Dense(3,activation='softmax')\n    decoder_output = decoder_dense_cell2(decoder_d_output)\n    model = Model([encoder_inp,decoder_inp],decoder_output)\n    model.summary()\n    model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n    plot_model(\n        model,to_file=emb_name,\n        show_shapes=True,\n        show_layer_names=True,\n        rankdir=\"TB\",\n        expand_nested=False,\n        dpi=96)\n    model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)","0f435bd7":"del(fastetxt_emd_matrix)\ngolve_emd_file = '..\/input\/glove-global-vectors-for-word-representation\/glove.6B.50d.txt'\ngolve_emd_matrix = create_Embedding_matrix(golve_emd_file,tokenized_data)\nhybrid_bidirectional_seq2seq_encoder_decoder(LSTM(60,return_state=True),maxlen,max_features,len(golve_emd_matrix[0]),golve_emd_matrix,\"hybrid_encoder_decoder_model_golve_emd.png\")","f5be31b2":"!pip install MiniAttention","6adc50fd":"import MiniAttention.MiniAttention as ma","d0b5cdeb":"def seq2seq_encoder_decoder_glove_bilstm_hybrid_attention(model,maxlen,max_features,embed_size,embedding_matrix,emb_name):\n    #Creating LSTM  encoder neural model with no pretrained embeddings\n    encoder_inp=Input(shape=(maxlen,))\n    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n    encoder_embed_attention=ma.MiniAttentionBlock(None,None,None,keras.regularizers.L2(l2=0.02),None,None,None,None,None)(encoder_embed)\n    encoder_lstm_cell=Bidirectional(model,merge_mode=\"sum\")\n    encoder_outputs,encoder_flstm_h,encoder_flstm_c,encoder_blstm_h,encoder_blstm_c = encoder_lstm_cell(encoder_embed_attention)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    encoded_states=[encoder_flstm_h + encoder_blstm_h,encoder_flstm_c + encoder_blstm_c]\n    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n    \n    decoder_lstm_cell = model\n    decoder_outputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n    \n    decoder_dense_cell = Dense(16,activation='relu')\n    decoder_d_output = decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2 = Dense(3,activation='softmax')\n    decoder_output = decoder_dense_cell2(decoder_d_output)\n    model = Model([encoder_inp,decoder_inp],decoder_output)         \n    model.summary()\n    model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n    plot_model(\n        model,to_file=emb_name,\n        show_shapes=True,\n        show_layer_names=True,\n        rankdir=\"TB\",\n        expand_nested=False,\n        dpi=96)\n    model.fit([train_x,train_x],train_y,batch_size=512,epochs=3,verbose=2)","36bce1a8":"seq2seq_encoder_decoder_glove_bilstm_hybrid_attention(LSTM(60,return_state=True),maxlen,max_features,len(golve_emd_matrix[0]),golve_emd_matrix,\"seq2seq_encoder_decoder_model_glovetext.png\")","4728e2ac":"class Bahadanu_Attention(tf.keras.layers.Layer):\n    def __init__(self,units):\n        super(Bahadanu_Attention,self).__init__()\n        self.units=units\n        self.Wq=tf.keras.layers.Dense(self.units)\n        self.Wk=tf.keras.layers.Dense(self.units)\n        self.Wv=tf.keras.layers.Dense(60)\n        \n    def call(self,q,v):\n        self.q=q\n        self.v=v\n        q_t=tf.expand_dims(self.q,1)\n        score=self.Wv(tf.nn.tanh(self.Wq(self.q)+self.Wk(self.v)))\n        attention_wts=tf.nn.softmax(score,axis=1)\n        context_vector=(attention_wts*self.v)\n        context_vector=tf.reduce_sum(context_vector,axis=1)\n        return context_vector,attention_wts","4d96cb36":"def seq2seq_encoder_decoder_glove_bilstm_hybrid_bahdanau(maxlen,max_features,embed_size,embedding_matrix,):\n    #Creating GRU encoder neural model with pretrained embeddings\n    encoder_inp = Input(shape=(maxlen,))\n    encoder_embed = Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n    encoder_gru_cell = GRU(60,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n    encoder_outputs,encoder_state_flstm_h =encoder_gru_cell(encoder_embed)\n    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n    #Creating GRU decoder model and feeding the output states of gru encoders\n    decoder_inp=Input(shape=(maxlen,))\n    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n    bahdanau_attention=Bahadanu_Attention(60)\n    \n    context_vector,attention_weights = bahdanau_attention(encoder_state_flstm_h,encoder_outputs)\n    decoder_gru_cell = GRU(60,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n    decoder_outputs,decoder_state_flstm_h= decoder_gru_cell(decoder_embed,initial_state=context_vector)\n    decoder_dense_cell= Dense(64,activation='relu')\n    decoder_outputs = tf.reshape(decoder_outputs, (-1, decoder_outputs.shape[2]))\n    decoder_d_output=decoder_dense_cell(decoder_outputs)\n    decoder_dense_cell2=Dense(3,activation='softmax')\n    decoder_output=decoder_dense_cell2(decoder_d_output)\n    model=Model([encoder_inp,decoder_inp],decoder_output)\n    model.summary()\n    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    plot_model(\n        model,to_file=\"seq2seq_encoder_decoder_model_glove_bilstm_bahdanau_attention.png\",\n        show_shapes=True,\n        show_layer_names=True,\n        rankdir=\"TB\",\n        expand_nested=False,\n        dpi=96)\n\n    model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)","51ff9461":"class Luong_Attention(tf.keras.layers.Layer):\n    def __init__(self,units):\n        super(Luong_Attention,self).__init__()\n        self.units=units\n        self.Wq=tf.keras.layers.Dense(self.units)\n        self.Wk=tf.keras.layers.Dense(self.units)\n        self.Wv=tf.keras.layers.Dense(60)\n        \n    def call(self,q,v):\n        self.q=q\n        self.v=v\n        q_t=tf.expand_dims(self.q,1)\n        score=(self.q)*(self.v)\n        attention_wts=tf.nn.softmax(score,axis=1)\n        context_vector=(attention_wts*self.v)\n        context_vector=tf.reduce_sum(context_vector,axis=1)\n        return context_vector,attention_wts\n    ","63a24458":"golve_emd_file = '..\/input\/glove-global-vectors-for-word-representation\/glove.6B.50d.txt'\ngolve_emd_matrix = create_Embedding_matrix(golve_emd_file,tokenized_data)\nseq2seq_encoder_decoder_glove_bilstm_hybrid_bahdanau(maxlen,max_features,len(golve_emd_matrix[0]),golve_emd_matrix,)","de5469cd":"seq2seq_encoder_decoder_glove_bilstm_hybrid_bahdanau(maxlen,max_features,len(golve_emd_matrix[0]),golve_emd_matrix,)","58d17f58":"## Basic seq2seq model without pretrained embedding","53400b7c":"![image.png](attachment:image.png)","ca8b01e0":"## Sed2Seq model with pretrained embedding matrix\n- Here I am applying pretrained static embedding (like Glove-embedding) to the seq2seq encoder decode model comprising of LSTM model.","323b0ed5":"## Hybrid Encoder Decoder With Attention\n- This section will comprise of Hybrid Encoder Decoder Architectures with variants of Attention Mechanisms. For an introduction attention refers to allowing certain neural weights to be focussed during training and this in turn assists in model performance.\n- In Sequence to Sequence models without attention, we process and predict the sentence sequentially. However, it is possible and highly probable that the prediction of a word from one language to another in NMT may depend on words before or after that specific word in the sentence.\n- It uses stacked recurrent neural networks on word level followed by attention model to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector. Then the same procedure applied to the derived sentence vectors which then generate a vector who conceives the meaning of the given document and that vector can be passed further for text classification. It uses stacked recurrent neural networks on word level followed by attention model to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector. Then the same procedure applied to the derived sentence vectors which then generate a vector who conceives the meaning of the given document and that vector can be passed further for text classification.\n![image.png](attachment:image.png)","6a346159":"## Hybrid Encoder Decoder Models\n\nThese types of encoder decoders allow different variants of RNNs (LSTM\/Bilstm) which acts as a variational circuit. Hybrid deccoder models generally have a compression decoder which implies that the decoder can be GRU\/LSTM while the encoder can be any Bidirectional version of that. This allows a smooth compression of the tensors by concatenating the hidden and cell state channels.","19d1d26c":"## Sequence to Sequence Model\n- Sequence-to-sequence learning (Seq2Seq) is about training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to French).\n- A sequence to sequence model aims to map a fixed-length input with a fixed-length output where the length of the input and output may differ.\n- For example, translating \u201cWhat are you doing today?\u201d from English to Chinese has input of 5 words and output of 7 symbols (\u4eca\u5929\u4f60\u5728\u505a\u4ec0\u9ebc\uff1f). Clearly, we can\u2019t use a regular LSTM network to map each word from the English sentence to the Chinese sentence.\n- In Sequence to Sequence models without attention, we process and predict the sentence sequentially\n![image.png](attachment:image.png)\n### Encoder\n- A stack of several recurrent units (LSTM or GRU cells for better performance) where each accepts a single element of the input sequence, collects information for that element and propagates it forward.\n- In question-answering problem, the input sequence is a collection of all words from the question. Each word is represented as x_i where i is the order of that word.\n### Encoder Vector\n- This is the final hidden state produced from the encoder part of the model. It is calculated using the formula above.\n- This vector aims to encapsulate the information for all input elements in order to help the decoder make accurate predictions.\n- It acts as the initial hidden state of the decoder part of the model.\n### Decoder\n- A stack of several recurrent units where each predicts an output y_t at a time step t.\n- Each recurrent unit accepts a hidden state from the previous unit and produces and output as well as its own hidden state.\n- In the question-answering problem, the output sequence is a collection of all words from the answer. Each word is represented as y_i where i is the order of that word.\n*************************************************************************************************************************************************************************\n- We calculate the outputs using the hidden state at the current time step together with the respective weight W(S). Softmax is used to create a probability vector which will help us determine the final output ","573a90c8":"- That return sequences return the hidden state output for each input time step.\n- That return state returns the hidden state output and cell state for the last input time step.\n- That return sequences and return state can be used at the same time."}}