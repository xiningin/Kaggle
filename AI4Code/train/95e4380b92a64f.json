{"cell_type":{"2f0dc31a":"code","15d59ba5":"code","22ef11bb":"code","426b6e30":"code","05607512":"code","cd0cd9a5":"code","2e9519f2":"code","8bf954e6":"code","bb3e0ef9":"code","0bcb26f1":"code","52721f0e":"code","f772a2ba":"code","65314bac":"code","d37cc4fb":"code","41cfa0c4":"code","b4e11561":"code","9bf6fbae":"code","4d35bcfc":"code","3929950b":"code","4ad41930":"code","f2159d84":"code","1fb7c91f":"code","071b97d3":"code","30cf46d3":"code","d204757b":"code","fd739e3c":"code","36735f0b":"code","cd847042":"code","41191800":"code","bf25adfa":"code","2918ff2c":"code","1a837a55":"code","0d3d82f0":"code","c8c219ee":"markdown","c5c562a8":"markdown","7dbdd7ca":"markdown","c979afba":"markdown"},"source":{"2f0dc31a":"import numpy as np \nimport pandas as pd \nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import randint\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.pipeline import Pipeline\nfrom copy import deepcopy\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn.svm import LinearSVC\nfrom sklearn import preprocessing\nfrom sklearn.svm import LinearSVC\nimport pandas as pd\nfrom scipy import stats\nfrom statsmodels.stats import weightstats as stests\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","15d59ba5":"train  = pd.read_csv('..\/input\/students-performance-in-exams\/StudentsPerformance.csv');","22ef11bb":"train.head()","426b6e30":"train.shape","05607512":"print(\"The number of traning examples(data points) = %i \" % train.shape[0])\nprint(\"The number of features = %i \" % train.shape[1])\n","cd0cd9a5":"train.info()\n","2e9519f2":"train.describe()\n\n","8bf954e6":"train.isnull()","bb3e0ef9":"train.isnull().sum()","0bcb26f1":"train['lunch'].isnull().sum()\n ","52721f0e":"duplicate = train[train.duplicated()]\nduplicate.size\n","f772a2ba":"train['total percentage'] = ((train['math score']+train['reading score']+train['writing score'])\/3).round(decimals=2)\n","65314bac":"train.head()\n","d37cc4fb":"train['total percentage'].value_counts(bins=2, sort=False)","41cfa0c4":"bins = [0,50,100]\nnames = ['Failed','Passed']\ntrain['status'] =  pd.cut(train['total percentage'], bins, labels=names)\ntrain","b4e11561":"NumberedGender = {'female':0,'male':1}\ntrain['gender']=train['gender'].map(NumberedGender)\ntrain['gender'] = pd.to_numeric(train['gender'])\ntrain.head()","9bf6fbae":"train['race\/ethnicity'].unique()","4d35bcfc":"NumberedRace = {'group A':0,'group B':1,'group C':2,'group D':3,'group E':4}\ntrain['race\/ethnicity']=train['race\/ethnicity'].map(NumberedRace)\ntrain['race\/ethnicity'] = pd.to_numeric(train['race\/ethnicity'])\ntrain.head()","3929950b":"plt.figure(figsize=(18,6))\nplt.subplot(1, 4, 1)\nfig = train.boxplot(column='math score')\nfig.set_title('')\nfig.set_ylabel('math score')\n \nplt.subplot(1, 4, 2)\nfig = train.boxplot(column='reading score')\nfig.set_title('')\nfig.set_ylabel('reading score')\n\nplt.subplot(1, 4, 3)\nfig = train.boxplot(column='writing score')\nfig.set_title('')\nfig.set_ylabel('writing score')\n\nplt.subplot(1, 4, 4)\nfig = train.boxplot(column='total percentage')\nfig.set_title('')\nfig.set_ylabel('total percentage')","4ad41930":"\ng = sns.displot(train[\"math score\"], color=\"c\", label=\"Skewness : %.2f\"%(train[\"math score\"].skew()))\ng = sns.displot(train[\"reading score\"], color=\"y\", label=\"Skewness : %.2f\"%(train[\"reading score\"].skew()))\ng = sns.displot(train[\"writing score\"], color=\"m\", label=\"Skewness : %.2f\"%(train[\"writing score\"].skew()))\ng = sns.displot(train[\"total percentage\"], color=\"g\", label=\"Skewness : %.2f\"%(train[\"total percentage\"].skew()))\n\n","f2159d84":"train.head()","1fb7c91f":"g = sns.displot(train[\"math score\"], color=\"c\", label=\"Skewness : %.2f\"%(train[\"math score\"].skew()))\ng = sns.displot(train[\"reading score\"], color=\"y\", label=\"Skewness : %.2f\"%(train[\"reading score\"].skew()))\ng = sns.displot(train[\"writing score\"], color=\"m\", label=\"Skewness : %.2f\"%(train[\"writing score\"].skew()))\ng = sns.displot(train[\"total percentage\"], color=\"g\", label=\"Skewness : %.2f\"%(train[\"total percentage\"].skew()))\n","071b97d3":"train.corr()","30cf46d3":"corr = train.corr()\nf, ax = plt.subplots(figsize=(20, 7))\ncmap = sns.diverging_palette(123, 10, as_cmap=True)\nsns.heatmap(corr,linewidths=.5, annot= True)","d204757b":"sns.pairplot(data=train[['gender','race\/ethnicity','total percentage']],\n             hue=\"total percentage\", dropna=True)","fd739e3c":"cleanup_nums = { \"status\": {\"Failed\": 0, \"Passed\": 1} }\ntrain.replace(cleanup_nums, inplace=True)\ntrain.head()","36735f0b":"target = train['status']","cd847042":"data = train[['gender','race\/ethnicity']]","41191800":"import random\n\nmale = train[train['gender'] == 1]\nfemale = train[train['gender'] == 0]\n\n## empty list for storing mean sample\nm_mean_samples = []\nf_mean_samples = []\n\nfor i in range(50):\n    m_mean_samples.append(np.mean(random.sample(list(male['status']),50,)))\n    f_mean_samples.append(np.mean(random.sample(list(female['status']),50,)))\n    \nttest,pval = stats.ttest_rel(m_mean_samples, f_mean_samples)\nprint('T-test: ',float(pval))\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\nztest ,pval1 = stests.ztest(m_mean_samples,f_mean_samples, value=0,alternative='two-sided')\nprint('Z-test: ',float(pval1))\nif pval1<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")","bf25adfa":"sns.barplot(x=train['gender'],y=train['status']);\n","2918ff2c":"GroupA = train[train['race\/ethnicity']==0]\nGroupB = train[train['race\/ethnicity']==1]\nGroupC = train[train['race\/ethnicity']==2]\nGroupD = train[train['race\/ethnicity']==3]\nGroupE = train[train['race\/ethnicity']==4]\ngA_mean_samples=[]\ngB_mean_samples=[]\ngC_mean_samples=[]\ngD_mean_samples=[]\ngE_mean_samples=[]\nfor i in range(50):\n    gA_mean_samples.append(np.mean(random.sample(list(GroupA['status']),50,)))\n    gB_mean_samples.append(np.mean(random.sample(list(GroupB['status']),50,)))\n    gC_mean_samples.append(np.mean(random.sample(list(GroupC['status']),50,)))\n    gD_mean_samples.append(np.mean(random.sample(list(GroupD['status']),50,)))\n    gE_mean_samples.append(np.mean(random.sample(list(GroupE['status']),50,)))    \nF, p = stats.f_oneway(gA_mean_samples, gB_mean_samples, gC_mean_samples,gD_mean_samples,gE_mean_samples)\nprint(\"p-value for significance is: \", p)\nif p<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n","1a837a55":"sns.barplot(x=train['race\/ethnicity'],y=train['status']);","0d3d82f0":"sns.barplot(x=train['race\/ethnicity'],y=train['status'],hue=train['gender']);","c8c219ee":"Hypothesis : There is no difference in the pass\/fail status between students Race\/Ethnicity\n","c5c562a8":"**NO Duplicates!******","7dbdd7ca":"Hypothesis : There is no difference in the pass\/fail status between students females and males.","c979afba":"**NO Null Values!\n**"}}