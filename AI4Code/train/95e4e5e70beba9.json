{"cell_type":{"82da4558":"code","7911aa28":"code","a0294a64":"code","37d9625b":"code","c22b95ca":"code","7deea1c4":"code","6acc5bb3":"code","46caed83":"code","e1f7b8d7":"code","50005191":"code","0dbbe9f9":"code","948d74c7":"code","92059da6":"code","9c153e84":"code","88f5ba07":"code","3e380877":"code","26880d13":"code","28bd3951":"code","ca8b7535":"code","97af8cb1":"code","d2df4c13":"code","ca317595":"code","a6a4ec74":"code","948fbee4":"code","a09df58d":"code","70137714":"code","9e2523db":"code","9e10961e":"code","086b7fba":"code","f13427e9":"code","15f4bbd9":"code","33873375":"code","8aaadcbc":"code","1ec075b9":"code","0c854feb":"code","8af1b452":"code","e2737fa0":"code","bec48e62":"code","2d2db5e9":"markdown","c7e8f7c8":"markdown","ec71a43a":"markdown","d3bbdc62":"markdown","82a39d6a":"markdown","f7171664":"markdown","cc083843":"markdown","2944b065":"markdown","946b72a2":"markdown"},"source":{"82da4558":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7911aa28":"# Importing libraries for data exploration and anlysis\nimport sklearn as sk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Model from SciKit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import feature_selection\nfrom sklearn.impute import SimpleImputer\n\n# Model Evaluations from SciKit Learn\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import precision_score\n\n\n# for displaying graph in the notebook\n%matplotlib inline","a0294a64":"#load data\ndf_job=pd.read_csv('\/kaggle\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv')\ndf_job.head(2)","37d9625b":"# Calculating NUll data\ndf_job.isna().sum()","c22b95ca":"#reviewing data structure\ndf_job.dtypes","7deea1c4":"# Filling the Categorical values with 'missing'\ndata_cat_imp=SimpleImputer(strategy=\"constant\",fill_value=\"Missing\")\ncat_imp_feature=[\"title\",\"location\",\"department\",\"salary_range\",\"company_profile\",\"description\",\"requirements\",\"benefits\",\n                 \"employment_type\",\"required_experience\",\"required_education\",\"industry\",\"function\"]\n\n# Filling the Numerical values through existing value\ndata_num_imp=SimpleImputer(strategy=\"constant\",fill_value=None)\nnum_imp_feature =[\"job_id\",\"telecommuting\",\"has_company_logo\",\"has_questions\",\"fraudulent\"]\n\n# Transforming into column\ndata_imp_trans=ColumnTransformer([(\"data_cat_imp\",data_cat_imp,cat_imp_feature),\n                                 (\"data_num_imp\",data_num_imp,num_imp_feature)])\n\n# Transforming and assigning the data\ntransformed_data=data_imp_trans.fit_transform(df_job)\ntransformed_data","6acc5bb3":"#Transforming the data into data frame\ndf_job_transformed_data=pd.DataFrame(transformed_data,\n                         columns=[\"title\",\"location\",\"department\",\"salary_range\",\"company_profile\",\"description\",\n                                  \"requirements\",\"benefits\", \"employment_type\",\"required_experience\",\"required_education\",\n                                  \"industry\",\"function\",\"job_id\",\"telecommuting\",\"has_company_logo\",\"has_questions\",\n                                  \"fraudulent\"])","46caed83":"#viewing transformed data\ndf_job_transformed_data.head(2)","e1f7b8d7":"# verify the NaN\/missing values\ndf_job_transformed_data.isna().sum()","50005191":"#reviewing the columns\ndf_job_transformed_data.columns","0dbbe9f9":"#random seed\nnp.random.seed(42)\n\n#data split into feature(X) and label(y)\nX_trans = df_job_transformed_data.drop(\"fraudulent\",axis=1)\ny_trans = df_job_transformed_data.fraudulent\ny_trans=y_trans.astype('int')\n\n#shape(row,column) of features and label\nX_trans.shape, y_trans.shape,X_trans.columns","948d74c7":"# Instantation of One Hot Encoder for categorical data tarnsformatio into Numeric \none_hot=OneHotEncoder()\nclf_trans=ColumnTransformer([(\"one_hot\",one_hot,cat_imp_feature)],remainder=\"passthrough\")\nX_trans_fin=clf_trans.fit_transform(X_trans)\nnp.array(X_trans_fin)","92059da6":"#splitting the data into train and test with 23% reserved for testing and 77% for training\nX_train,X_test,y_train,y_test=train_test_split(X_trans_fin,y_trans,test_size=0.23, random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","9c153e84":"#Lets fit the model\nnp.random.seed(42)\n\n#Applying Random Forest Classifier Model\nmodel_rfm=RandomForestClassifier()\n\n#fitting the data into model\nmodel_rfm.fit(X_train,y_train,sample_weight=None)","88f5ba07":"#scoring the Random Forest Classifier Model\nprint(f\"Fake Job Random Forest Model Accuracy : {model_rfm.score(X_test,y_test)*100:.2f}%\")","3e380877":"#predicting label data through Random Forest Classifier Model\ny_pred_rfm=model_rfm.predict(X_test)\ny_pred_rfm","26880d13":"#Applying Logistic Regression Classification Algorithm\nmodel_lrm=LogisticRegression(solver='liblinear')\n\n#fitting the data into model\nmodel_lrm.fit(X_train,y_train,sample_weight=None)","28bd3951":"#scoring the Logistic Regression Model\nprint(f\"Fake Job Logistic Regression Model Accuracy :{model_lrm.score(X_test,y_test)*100:.2f}%\")","ca8b7535":"#predicting label data through Random Forest Classifier Model\ny_pred_lrm=model_lrm.predict(X_test)\ny_pred_lrm","97af8cb1":"model_lrm.get_params()","d2df4c13":"#accuracy metrics of Random forest\nprint(f\"Accuracy Score ~ :{accuracy_score(y_test,y_pred_rfm)*100:.2f}%\")","ca317595":"#precision score of Random forest\nprint(f\"Precision Score~ :{precision_score(y_test,y_pred_rfm)*100:.2f}%\")","a6a4ec74":"#classification report\nprint(classification_report(y_test,y_pred_rfm))","948fbee4":"# Confusion Matrix - It's compare to the label model predict and the actual label it suppossed to predict, \n# its offer an ideal where the model is getting confused.\nrfm_data=confusion_matrix(y_test,y_pred_rfm)\nsns.set(font_scale=1)\nsns.heatmap(rfm_data, center=0,annot=True,cmap=\"YlGnBu\");\nplt.xlabel(\"Actual Label\")\nplt.ylabel(\"Predicted Label\");","a09df58d":"#accuracy metrics of logistic\nprint(f\"Accuracy Score ~ :{accuracy_score(y_test,y_pred_lrm)*100:.2f}%\")","70137714":"#precision score of logistic\nprint(f\"Precision Score~ :{precision_score(y_test,y_pred_lrm)*100:.2f}%\")","9e2523db":"#classification report\nprint(classification_report(y_test,y_pred_lrm))","9e10961e":"# Confusion Matrix - It's compare to the label model predict and the actual label it suppossed to predict, \n# its offer an ideal where the model is getting confused.\nlrm_data=confusion_matrix(y_test,y_pred_lrm)\nsns.set(font_scale=1)\nsns.heatmap(lrm_data, center=0,annot=True,cmap=\"YlOrBr\");\nplt.xlabel(\"Actual Label\")\nplt.ylabel(\"Predicted Label\");","086b7fba":"# optimal parameters using LogisticRegression() for classification\nrandom_grid = {\"C\": np.logspace(-4,4,20),\n               \"solver\" : [\"liblinear\"]\n               }\n\n#displaying the random grid parameters for the estimator ~ Logistic Regression\nrandom_grid","f13427e9":"%%time\n# Use the random grid to search for optomised hyperparameters for LogisticRegression()\nrf = LogisticRegression()\n\n# Random search of parameters, using 3 fold cross validation,and search across 2 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 10, cv = 3, verbose=True)\n\n# Fitting the RandomizedSearchCV model\nrf_random.fit(X_train, y_train)","15f4bbd9":"#Optimised parameters\nrf_random.best_params_","33873375":"# fitting the LogisticRegression() model with optimsed parameters\nmodel_lrm_ideal=LogisticRegression(C=545.5594781168514,\n                                   solver='liblinear',\n                                    verbose=True)\n#fitting the model\nmodel_lrm_ideal.fit(X_train,y_train)","8aaadcbc":"#scoring the ideal LogisticRegression() Model\nmodel_lrm_ideal.score(X_test,y_test)","1ec075b9":"#predicting data through LogisticRegression() Model\ny_pred_lrm_ideal=model_lrm_ideal.predict(X_test)\ny_pred_lrm_ideal","0c854feb":"#accuracy score of post optimization of LogisticRegression() Model\nprint(f\"Accuracy Score~ :{accuracy_score(y_test,y_pred_lrm_ideal)*100:.2f}%\")","8af1b452":"# formatting in the desired format\ndf_job_pred=pd.DataFrame()\ndf_job_pred[\"Actual Fraudulent\"]=y_test\ndf_job_pred[\"Predicted Fraudulent\"]=y_pred_rfm\ndf_job_pred.to_csv(\"\/kaggle\/working\/predict.csv\")","e2737fa0":"#creating dictory to map the column with optimal feature rating\nfeature_dict=dict(zip((df_job.columns),list(model_rfm.feature_importances_)))\nfeature_dict","bec48e62":"#Visulaization of Important features\nfeature_df=pd.DataFrame(feature_dict,index=[0])\nfeature_df.T.plot.line(title=\"EmploymentScamAegean Dataset - Feature Importance\",legend=False,color='orange');","2d2db5e9":"# Applying Metrics\n    * To quantifying the quality of predictions\n    * score measures how many labels the model got right out of the total number of predictions","c7e8f7c8":"# Logistic Regression","ec71a43a":"# Feature Importance Evaluations\n*Feature importance to assign a score to input features based on how useful they are in prediction.","d3bbdc62":"# Turnning Hyperparameters ~ LogisticRegression()\n *  The model needs to be tuned as ~91% corrected predicted values needs improvement\n *  RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution","82a39d6a":"# Selecting right Estimator or Aglorithm - Applying Classification Models","f7171664":"# Data Conversation - Encode Categorical Data {OneHotEncoder}\u00b6","cc083843":"# [Real or Fake] : Fake Job Description Prediction\n*  This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent.\n\n### Kaggle\n    * https:\/\/www.kaggle.com\/shivamb\/real-or-fake-fake-jobposting-prediction\n\n### Data Source \n     * Employment Scam Aegean Dataset \n\n### Execution Strategy  - An end-to-end Scikit-Learn worfklow\n     1. Getting the data ready\n     2. Handling NaN data and convert categorical data into Numeric\n     3. Choosing the right maching learning estimator\/aglorithm\/model for this problem\n     4. Fitting your chosen machine learning model to data and using it to make a prediction\n     5. Evaluting a machine learning model\n     6. Improving predictions through experimentation (hyperparameter tuning)\n     7. Feature Importance Evaluations","2944b065":"# Comparing Actual vs Predicted Fraudlent result","946b72a2":"# Data Conversation - Handling Missing Date {Sample Imputer}"}}