{"cell_type":{"9d45697a":"code","249d8138":"code","78eb42f0":"code","ce04be71":"code","3a290df4":"code","a2ade567":"code","0ce9af9b":"code","fbe881bb":"code","24b70dc2":"code","47fec21c":"code","6e682b42":"code","bb3f7617":"code","895784e7":"markdown","7ade8695":"markdown","927244f7":"markdown","c7bfd06c":"markdown","2fd40558":"markdown","36951b39":"markdown","201170d1":"markdown","4d2e037b":"markdown","d268d5d2":"markdown","a93ef5c8":"markdown","4cca958b":"markdown","b15363de":"markdown"},"source":{"9d45697a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap","249d8138":"dfTrain = pd.read_csv('..\/input\/UnclusteredData.csv')   #Training Dataset\ndfTrain.head()","78eb42f0":"pd.plotting.scatter_matrix(dfTrain, alpha=1, diagonal='hist',color='k')\nplt.show()","ce04be71":"def extractFeatures(df):\n    df_Features=df.iloc[:,0:2]\n    X=df_Features.values\n    Y=np.zeros((len(df_Features),1))       #All are assigned to K= 1 cluster\n    return X,Y","3a290df4":"X,Y=extractFeatures(dfTrain)","a2ade567":"cmap = ListedColormap(['black','magenta', 'red','green','orange']) \nplt.scatter(dfTrain.loc[:,['X1']].values,dfTrain.loc[:,['X2']].values, c=Y,cmap=cmap,marker=\"o\")\nplt.show()","0ce9af9b":"def initCentroids(X,K):\n    rand_indices = np.random.permutation(X.shape[0])\n    init_centroids = X[rand_indices[:K],:]\n    return init_centroids","fbe881bb":"def assignCentroids(X,centroids):    \n    K=centroids.shape[0]\n    #Assign index to each training set\n    Y=np.zeros((X.shape[0],1))\n    for i in range(len(X[:,0:1])): \n        Prev_Distance=np.linalg.norm( X[i,:]-centroids[0,:])\n        for j in range(1,K):\n            Current_Distance=np.linalg.norm( X[i,:]-centroids[j,:])\n            if(Current_Distance<=Prev_Distance):\n                Y[i]=j\n                Prev_Distance=Current_Distance\n    return Y","24b70dc2":"def updateNewCentroids(X,Y,K):    \n    centroids = np.zeros((K,X.shape[1]))\n    for j in range(0,K):\n        sumC=np.zeros((1,X.shape[1]))\n        countC=0\n        for i in range(len(X[:,0:1])): \n            if (Y[i]==j):\n                sumC=sumC+X[i,:]\n                countC=countC+1\n        if (countC!=0):\n            centroids[j,:]=(1\/countC)*sumC\n\n    return centroids","47fec21c":"K=5\ninit_centroids = initCentroids(X,K)\n\ncentroids=init_centroids    #start with Initial Centroid\ncentroidsHistory=[init_centroids]\nwhile True:\n    Y = assignCentroids(X,centroids)      #Assignment Step\n    newCentroids =updateNewCentroids(X,Y,K)   #Update New Centroids Step\n    if ((newCentroids==centroids).all()):\n        break\n    else:\n        centroids=newCentroids\n        centroidsHistory.append(newCentroids)\n\n","6e682b42":"plt.scatter(X[:,0:1],X[:,1:2],c=Y,cmap=cmap,marker=\".\")\n#plot Centroid History with line how centorids are moving\nfor i in range(K):\n    histCentroids=np.array( centroidsHistory)[:,i,:]\n    plt.plot(histCentroids[:,0:1],histCentroids[:,1:2],color='b',linestyle='dashed')\n    \n#Final Centroid\nplt.scatter(centroids[:,0:1],centroids[:,1:2],color='b',marker=\"o\",edgecolor='b')\nplt.title('K-mean (K='+str(K)+')')\nplt.show()\n","bb3f7617":"maxK=10\nmeanvalues=np.zeros((maxK))\nfor K in (range(1,maxK)):\n    rand_indices = np.random.permutation(X.shape[0])\n    init_centroids = X[rand_indices[:K],:]\n    centroids=init_centroids    #start with Initial Centroid\n    while True:\n        Y = assignCentroids(X,centroids)      #Assignment Step\n        newCentroids =updateNewCentroids(X,Y,K)   #Update New Centroids Step\n        if ((newCentroids==centroids).all()):\n            break\n        else:\n            centroids=newCentroids\n    ##############\n    meanvalues[K]=0\n    for i in range(K):\n        distanceValues=np.linalg.norm(X[np.where(Y==i)[0]]-centroids[i,:],axis=1)\n        meanvalues[K]=meanvalues[K]+np.mean(distanceValues)\/K\n \nplt.plot(range(1,maxK),meanvalues[1:maxK],color='b')     #Ignoring K=0 \nplt.ylabel('Avg Distance from Centroids')\nplt.xlabel('Values of K')\nplt.title(\"Elbow Method\")\nplt.show()","895784e7":"<h2>Extract Input Feature to <b>X <\/b>and Label <b>Y=0 (index of centroid)<\/b><\/h2>\n<h5>X=(X1 &amp; X2 in DS) and Y(Class in DS)   ","7ade8695":"<b>Step3: Update New Centroids<\/b>","927244f7":"<H1>Read Data from CSV","c7bfd06c":"<h1> K-Mean Algorithm","2fd40558":"<h1>K-Mean Clustering <\/h1>","36951b39":"<b>Step2: Assign Centroid to each data point<\/b> ","201170d1":"<h2>K-Mean Algorithm <\/h2>\n<p>The \u039a-means clustering algorithm uses iterative method to group data into K clusters.\n\n<p>Algorithm repeats below steps till centroids keep changing for the data points and stop it when there is no change hanppening in assigned centorids. \n\n<b>Step1: Choose K and pick initial centroids<\/b>\n  <p> Starts with K initial centroids, which can either be randomly generated or randomly selected from the data points. \n\n\n<b>Step2: Data Assignment<\/b> \n    <p>Group\/cluster all the data points by assigning either of K centroid based on distance normally Euclidean (L2 Norm).\n    \n\n<b>Step3: Update New Centroid<\/b>\n    <p>For each K centroid, Take average\/mean of all data points assigned to it and update it as new Centorid for Kth Cluster.\n    \n    \n    \n\n<P><h2>Distance Functions (Continuous Data) <\/h2>\n    <p>Ecludian Distance $=  \\displaystyle \\sqrt{\\sum _{i=1}^n (X_i- Y_i)^2}$\n      <p>Manhattan Distance$ =  \\displaystyle \\sum _{i=1}^n \\left|X_i- Y_i\\right|$\n  <p>Minikowski Distance$ =  \\displaystyle \\left[\\sum _{i=1}^n \\left|X_i- Y_i\\right|^q\\right]^{\\frac{-1}{q}}$\n  \n  <P><h2>Distance Function (Categorical Data) <\/h2>\n     <p>Hamming Distance$ =  \\displaystyle \\sum _{i=1}^n \\left|X_i- Y_i\\right|$ \n       <p>   $\\hspace{20mm}X = Y \\hspace{10mm} then \\hspace{10mm}  D = 0 $\n      <p>    $\\hspace{20mm}X \\neq Y \\hspace{10mm} then \\hspace{10mm} D = 1$\n  \n  <p><h2>Standardize\/ Normalize Data<\/h2>\nCalculating distance measures directly from the training set values could be biased in the case where variables have different measurement scales or there is a mixture of numerical and categorical variables. For example, if one variable is based on annual income in dollars, and the other is based on age in years then income will have a much higher influence on the distance calculated. One solution is to Normalize the training set using Min-Max or Mean-Std.Dev method.\n \n  <p> Standardization\n <p>$X =  \\displaystyle \\frac{X-X_{min}}{X_{max}-X_{min}}$\n  <p> Normalization\n <p>$X =  \\displaystyle \\frac{X-\\mu}{\\sigma}$   where  $\\mu$ is mean and $\\sigma$ is standard deviation\n  \n","4d2e037b":"<h1>Choosing Correct K (Elbow Method)<\/h1>\n<p>\ncompare  different values of K for the mean distance between data points and their cluster centroid.\n    Plot mean distance to the centroid as a function of K and choose K from the \"elbow point,\" where the rate of decrease sharply shifts.","d268d5d2":"<h5> Visualize Data","a93ef5c8":"<b>Plot the Graph","4cca958b":"<b>Step1: Choose K and pick initial centroids<\/b>","b15363de":"<b>Run Above Methods(Steps) iteratively"}}