{"cell_type":{"bfe312b2":"code","b6e10239":"code","d8f8ac40":"code","14f694ba":"code","535e2bcd":"code","c2ea92f5":"code","96546d00":"code","be3cb2db":"code","acfbf0ae":"code","3199f726":"code","f2436002":"code","9de477e3":"code","0e0998ee":"code","d88bc34a":"code","be11ca8c":"code","c49a51c0":"code","28763121":"code","16261838":"code","2627ac14":"code","43333f7d":"code","503aba40":"code","988fbb14":"code","97df42eb":"code","365f0b38":"code","09dd88c1":"code","97263626":"code","5b807569":"code","67208355":"code","1727c19e":"code","2ed49743":"code","4fc9ccdf":"code","eb209594":"code","f8cc68e6":"code","061bf973":"code","3a0d5e09":"code","515d6ff8":"code","534be399":"code","63a35e07":"code","7fba6513":"code","524431f3":"code","817223a9":"code","2e691810":"code","1c4b1615":"code","a16a0c31":"code","867031f5":"code","c227b42d":"code","6705c7fd":"code","db27f315":"code","341bc284":"code","52a72dc5":"code","f35ec736":"code","561038e5":"code","3aa395c3":"code","3cebad23":"code","c99db779":"code","4aa0bd36":"code","340da98e":"code","2fc0326b":"code","9f995ca8":"code","cccfd5b6":"code","cf851220":"code","3e0a240d":"code","4626a892":"code","f6a3fd46":"code","0b66ea37":"code","1b87b559":"code","ae3e7864":"code","f1348fd7":"code","9a6008dd":"code","1d4ca08f":"code","03881190":"code","c70856ce":"code","d1983391":"code","a7acbf8c":"code","b26cb56a":"code","53c44429":"code","781f77ff":"code","902ffa5e":"code","14c7f323":"code","dd01fff2":"code","c0b71d55":"code","6b69b152":"code","4a3d9f20":"code","029f7910":"code","86e9cca7":"code","27123bc9":"code","fd0b2231":"code","f9b0939f":"code","d800e311":"code","26ca6b79":"code","96eb5d8f":"markdown","0689a311":"markdown","f561c738":"markdown","f73cf95d":"markdown","e7be7073":"markdown","9f137d0c":"markdown","114b2f15":"markdown","d102d4a5":"markdown","c459b304":"markdown","37eda9cb":"markdown","1ae5296a":"markdown","c7e055c8":"markdown","73f90721":"markdown","48480212":"markdown","b4454605":"markdown","5fa10278":"markdown","e8f78060":"markdown","a8a59525":"markdown","c9f7b233":"markdown","d7b5572c":"markdown","80b1344a":"markdown","f338d3eb":"markdown","f02ccca7":"markdown","6d8d9ace":"markdown","04d7edc7":"markdown","b48ae8be":"markdown","8adc145f":"markdown","61eb27d5":"markdown","a8195b05":"markdown","a96d50b1":"markdown","2383bc3b":"markdown","8017e91f":"markdown","b49927a2":"markdown","07f874d4":"markdown","713c7e23":"markdown","090f1fe2":"markdown","c7e89970":"markdown","91baad82":"markdown","941892b6":"markdown","795abbe5":"markdown","906c8238":"markdown","522e7178":"markdown","482a0085":"markdown","fe9863ad":"markdown","4d726df2":"markdown","ae989737":"markdown","a5831d13":"markdown","204cf4c6":"markdown","56663c00":"markdown","b24cf6eb":"markdown","9991c12a":"markdown","12b0d0ed":"markdown","9f5092bc":"markdown","f59b64d1":"markdown","7b1bb187":"markdown","cec4fd3b":"markdown","2ec326da":"markdown","d2fca28a":"markdown","8eaafc81":"markdown","99804e48":"markdown","da96b1fc":"markdown"},"source":{"bfe312b2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b6e10239":"data = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","d8f8ac40":"data.describe","14f694ba":"data.head()","535e2bcd":"data.columns","c2ea92f5":"# target is the output and the final conclusion if a person has heart disease or not \ndata.target.value_counts()","96546d00":"!pip install pandas-profiling","be3cb2db":"from pandas_profiling import ProfileReport\nprof = ProfileReport(data)\nprof.to_file(output_file='output.html')","acfbf0ae":"prof","3199f726":"!pip install sweetviz","f2436002":"import sweetviz","9de477e3":"report = sweetviz.analyze(data)","0e0998ee":"#display the report\nreport.show_html('Heart_EDA.html')","d88bc34a":"ax = sns.countplot(x=\"cp\",hue=\"sex\", data=data)\nplt.title('Heart Disease count According To Chest Pain Type')\nplt.xlabel('Chest Pain Type')\nplt.ylabel('Count ')","be11ca8c":"fig_dims = (6,6)\nfig, ax = plt.subplots(figsize=fig_dims)\nax = sns.barplot(x=\"target\",y=\"trestbps\", hue=\"sex\", data=data)\nplt.title('Heart Disease Frequency According To resting blood pressure  ')\nplt.xlabel('Target : Disease or not ')\nplt.ylabel('trst beats per second ')","c49a51c0":"sns.catplot(x=\"target\", y=\"trestbps\", data=data, kind=\"box\")","28763121":"fig_dims = (6,6)\nfig, ax = plt.subplots(figsize=fig_dims)\nfig = sns.violinplot(x=data['target'], y=data['chol'])","16261838":"data.fbs.value_counts()","2627ac14":"sns.countplot(data=data, x=\"fbs\", hue=\"target\")\nplt.title('Heart Disease Frequency According To FBS')\nplt.xlabel('FBS - (Fasting Blood Sugar > 120 mg\/dl) (1 = true; 0 = false)')\nplt.xticks(rotation = 0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency of Disease or Not')\nplt.show()","43333f7d":"sequential_colors = sns.color_palette(\"PuRd\", 2)\nsns.palplot(sequential_colors)","503aba40":"sns.set_palette(sequential_colors)","988fbb14":"sns.countplot( x=data['restecg'], hue=data['target'])","97df42eb":"220-80\n","365f0b38":"sns.boxplot(y=data['thalach'], x=data['target'])","09dd88c1":"import plotly.express as px","97263626":"fig = px.scatter(data, x=\"thalach\", y=\"age\", color=\"target\")\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0=140,\n            y0=0,\n            x1=140,\n            y1=80,\n            line=dict(\n                color=\"RoyalBlue\",\n                width=3\n            )\n))\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0=190,\n            y0=0,\n            x1=190,\n            y1=80,\n            line=dict(\n                color=\"RoyalBlue\",\n                width=3\n            )\n))","5b807569":"sns.set_palette(\"Paired\")","67208355":"sns.violinplot(x=data[\"exang\"], y=data[\"target\"])","1727c19e":"sequential_colors = sns.color_palette(\"summer\", 2)\nsns.palplot(sequential_colors)\nsns.set_palette(sequential_colors)","2ed49743":"sns.barplot(x=data[\"target\"], y=data[\"oldpeak\"])","4fc9ccdf":"a = pd.get_dummies(data['cp'], prefix = \"cp\")\nb = pd.get_dummies(data['thal'], prefix = \"thal\")\nc = pd.get_dummies(data['slope'], prefix = \"slope\")\nd = pd.get_dummies(data['sex'], prefix = \"sex\")","eb209594":"updated_clms = [data, a,b,c,d]\ndata = pd.concat(updated_clms, axis=1)\ndata.head()","f8cc68e6":"data = data.drop(columns = ['cp','thal', 'slope', 'sex'])","061bf973":"from sklearn.preprocessing import StandardScaler\nstandardScaler = StandardScaler()\ncolumns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndata[columns_to_scale] = standardScaler.fit_transform(data[columns_to_scale])","3a0d5e09":"data.head()","515d6ff8":"y = data.target\ny","534be399":"# Just for demonstration purposes we will be implementing with all features\nX_important_features = data[['cp_1', 'cp_2','cp_3','thal_0','thal_1','thal_2','thal_3','slope_0','slope_1','slope_2']]","63a35e07":"# \nX = data.drop(['target'], axis = 1)","7fba6513":"from sklearn.model_selection import train_test_split","524431f3":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state=0)\n","817223a9":"#transpose matrices\nX_train = X_train.T\ny_train = y_train.T\nX_test = X_test.T\ny_test = y_test.T","2e691810":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train.T, y_train.T)","1c4b1615":"accuracies = {}\nacc = nb.score(X_test.T,y_test.T)*100\naccuracies['Naive Bayes'] = acc\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","a16a0c31":"y_pred=nb.predict(X_test.T)\ny_pred","867031f5":"precisions={}\nrecalls={}\nf1_scores={}","c227b42d":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score","6705c7fd":"cf_matrix = confusion_matrix(y_test.T, y_pred)\nprint(cf_matrix)","db27f315":"sns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","341bc284":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\ny_pred_proba = nb.predict_proba(X_test.T)\ny_true = y_test.T\nskplt.metrics.plot_roc_curve(y_true, y_pred_proba)\nplt.show()","52a72dc5":"#recall\nfrom sklearn.metrics import recall_score\nrecall = recall_score(y_test.T, y_pred)\nprint('Recall: %.3f' % recall)\n\nrecalls['Naive Bayes'] = recall","f35ec736":"# precision\nfrom sklearn.metrics import precision_score\nprecision = precision_score(y_test.T, y_pred)\nprint('Precision: %.3f' % precision)\n\nprecisions['Naive Bayes'] = precision","561038e5":"# fi score\nf1 = 2*((precision*recall)\/(precision+recall))\nf1_scores['Naive Bayes'] = f1\nprint(f1)","3aa395c3":"import pickle\nfilename = 'naive_bayes.h5'\npickle.dump(nb, open(filename, 'wb'))","3cebad23":"from sklearn.neighbors import KNeighborsClassifier","c99db779":"knn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\nknn.fit(X_train.T, y_train.T)\nprediction = knn.predict(X_test.T)\n","4aa0bd36":"print(\"{} NN Score: {:.2f}%\".format(2, knn.score(X_test.T, y_test.T)*100))","340da98e":"knn = KNeighborsClassifier(n_neighbors = 18)  # n_neighbors means k\nknn.fit(X_train.T, y_train.T)\nprediction = knn.predict(X_test.T)\nprint(\"{} NN Score: {:.2f}%\".format(2, knn.score(X_test.T, y_test.T)*100))","2fc0326b":"acc = knn.score(X_test.T,y_test.T)*100\naccuracies['KNN'] = acc\nprint(\"Accuracy of KNN: {:.2f}%\".format(acc))","9f995ca8":"y_pred=knn.predict(X_test.T)\ny_pred","cccfd5b6":"cf_matrix = confusion_matrix(y_test.T, y_pred)\n\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","cf851220":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\ny_pred_proba = knn.predict_proba(X_test.T)\ny_true = y_test.T\nskplt.metrics.plot_roc_curve(y_true, y_pred_proba)\nplt.show()","3e0a240d":"from sklearn.metrics import recall_score\nrecall = recall_score(y_test.T, y_pred)\nprint('Recall: %.3f' % recall)\nrecalls['KNN'] = recall","4626a892":"# precision\nfrom sklearn.metrics import precision_score\nprecision = precision_score(y_test.T, y_pred)\nprint('Precision: %.3f' % precision)\nprecisions['KNN'] = precision","f6a3fd46":"# fi score\nf1 =2*((precision*recall)\/(precision+recall))\nprint(\"F1 Score \",f1)\nf1_scores['KNN'] = f1","0b66ea37":"import pickle\nfilename = 'knn_model.sav'\npickle.dump(knn, open(filename, 'wb'))","1b87b559":"from sklearn.tree import DecisionTreeClassifier\n\n# Define model. Specify a number for random_state to ensure same results each run\ndt = DecisionTreeClassifier(random_state=1)\n\n# Fit model\ndt.fit(X_train.T, y_train.T)","ae3e7864":"acc = dt.score(X_test.T,y_test.T)*100\naccuracies['Decision Tree'] = acc\nprint(\"Accuracy of Decision Tree: {:.2f}%\".format(acc))","f1348fd7":"y_pred=dt.predict(X_test.T)\ny_pred","9a6008dd":"cf_matrix = confusion_matrix(y_test.T, y_pred)\n\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","1d4ca08f":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\ny_pred_proba = dt.predict_proba(X_test.T)\ny_true = y_test.T\nskplt.metrics.plot_roc_curve(y_true, y_pred_proba)\nplt.show()","03881190":"from sklearn.metrics import recall_score\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %.3f' % recall)\nrecalls['Decision Tree'] = recall","c70856ce":"# precision\nfrom sklearn.metrics import precision_score\nprecision = precision_score(y_test, y_pred, labels=[1,2], average='micro')\nprint('Precision: %.3f' % precision)\nprecisions['Decision Tree'] = precision","d1983391":"# fi score\nf1 = 2*((precision*recall)\/(precision+recall))\nprint(\"F1 Score \",f1)\nf1_scores['Decision Tree']= f1","a7acbf8c":"import pickle\nfilename = 'dt_model.sav'\npickle.dump(dt, open(filename, 'wb'))","b26cb56a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","53c44429":"rf = RandomForestClassifier(n_estimators=1,random_state=1)\nrf.fit(X_test.T,y_test.T)","781f77ff":"acc = rf.score(X_test.T,y_test.T)*100\naccuracies['Random Forest'] = acc\nprint(\"Accuracy of Random Forest: {:.2f}%\".format(acc))","902ffa5e":"y_pred=rf.predict(X_test.T)\ny_pred","14c7f323":"cf_matrix = confusion_matrix(y_test.T, y_pred)\n\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')","dd01fff2":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\ny_pred_proba = rf.predict_proba(X_test.T)\ny_true = y_test.T\nskplt.metrics.plot_roc_curve(y_true, y_pred_proba)\nplt.show()","c0b71d55":"from sklearn.metrics import recall_score\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %.3f' % recall)\nrecalls['Random Forest'] = recall","6b69b152":"# precision\nfrom sklearn.metrics import precision_score\nprecision = precision_score(y_test, y_pred, labels=[1,2], average='micro')\nprint('Precision: %.3f' % precision)\nprecisions['Random Forest'] = precision","4a3d9f20":"#f1 score\nf1 = 2*((precision*recall)\/(precision+recall))\nprint(\"F1 Score \",f1)\nf1_scores['Random Forest']= f1","029f7910":"import pickle\nfilename = 'rf_model.sav'\npickle.dump(rf, open(filename, 'wb'))","86e9cca7":"f1_scores","27123bc9":"y = accuracies.values()\nx = accuracies.keys()\nplt.bar(x,y)","fd0b2231":"recalls\nprecisions\nf1_scores","f9b0939f":"y = recalls.values()\nx = recalls.keys()\nplt.bar(x,y)","d800e311":"y = precisions.values()\nx = precisions.keys()\nplt.bar(x,y)","26ca6b79":"y = f1_scores.values()\nx = f1_scores.keys()\nplt.bar(x,y)","96eb5d8f":"# <span style=\"color:#E74C3C\"> Summary <\/span>\n###                     This Kernel presents the story of Predicting Heart Diseases in a super simplified yet interactive manner to spellbound the reader! The motive to the writter is to give a smooth ride of the machine learning pipeline with the best learning experience ever. So tighten up your seat belts and get grooving!!\n","0689a311":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Confusion Matrix<\/div>","f561c738":"# <a id=\"8\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> Recomendation \/ Future Works\ud83d\udcac <\/div><\/font><\/a>\n    A Quick Google search for the following topics might be of use to the readers \n    1. Research papers (https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5863635\/#:~:text=In%20this%20study%2C%20an%20effective,cholesterol%2C%20and%20obesity%20for%20prediction.)","f73cf95d":"# <font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> 3. Decision Tree <\/div><\/font>","e7be7073":"# <a id=\"5\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\">\u23ee\u23ed Data Processing<\/div><\/font><\/a>","9f137d0c":"# Precision","114b2f15":"# <a id=\"6\"><font size=\"5\"><div style=\"border-radius:10px;color:white;background-color:#FA8072;padding: 10px;\">\ud83e\udde0 Building the Model<\/div><\/font><\/a>","d102d4a5":"This shows people having heart disease usually tend to have a high max heart rate","c459b304":"### 3. Splitting the data into train test\n For comparing and testing the viability of our model we need to split the heart.csv file into test and train data so that we can have a clear picture of how well our model is peforming and the overfitting stats.\n \n ","37eda9cb":"So now that we have filtered out 4 features that will be most important for our model for this particular dataset we will manipulate them in order to add them to our ml model. theses features are:\n1. Age              -------------------------> Discrete Variable\n2. Sex              -------------------------> Nominal\/Categorical Variable\n3. Chest Pain Type  -------------------------> Ordinal Variable\n4. thalach          -------------------------> \nNow since age and sex attributes do not have \nCategorical variables :\n","1ae5296a":"most heart patient lies in the active thalach range.","c7e055c8":"# <span style=\"color:#E74C3C\"> 2.2 Resting heart Beat\u274c\n resting heart rate, the target is between 60 and 100 beats per minute (BPM)\n The heatmap density reveals that most cases ","73f90721":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Accuracy<\/div>","48480212":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Confusion Matrix<\/div>","b4454605":"# <a id=\"3\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> \ud83c\udfcb\ufe0f\u200d\u2640\ufe0fPower pact EDA in seconds<\/div><\/font><\/a>\n# <span style=\"color:#E74C3C\"> \ud83d\udc3cPandas Profiling <\/span>","5fa10278":"Our problem is a type of Binnary Classification and we need to figure out if the person is suffering from a heart disease or not","e8f78060":"# <a id=\"1\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> \ud83d\udcdc 1. Data Exploration <\/div> <\/font><\/a>\nThis is the first part of the kernel wherein we have explored the dataset given and made it avaliable for use.","a8a59525":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Confusion Matrix<\/div>","c9f7b233":"Since all the data values were present as described in the dataset description I didn't applied any pre processing steps for the dataset niether checked for NAN values.\n","d7b5572c":"# <a id=\"8\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> References\ud83d\udcac<\/div><\/font><\/a>\nI believe human mind is not self sufficient it needs the community to help it. Here are a few of the community gems\ud83d\udd39 that made it possible for me! \n\n1. [**Inspiration**](https:\/\/www.kaggle.com\/thedatabeast) \n2. [Machine Learning Mastery](https:\/\/machinelearningmastery.com\/classification-accuracy-is-not-enough-more-performance-measures-you-can-use\/)\n3. [Insights](https:\/\/www.kaggle.com\/cdabakoglu\/heart-disease-classifications-machine-learning)\n4. [Dataset](https:\/\/www.kaggle.com\/ronitf\/heart-disease-uci\\)\n5. [Format](https:\/\/matplotlib.org\/2.1.1\/api\/_as_gen\/matplotlib.pyplot.plot.html)\n6. [Style](https:\/\/www.kaggle.com\/shubhamksingh\/create-beautiful-notebooks-formatting-tutorial\/comments)\n7. [Design](https:\/\/www.kaggle.com\/chrisbow\/formatting-notebooks-with-markdown-tutorial) \n8. [Documentation](https:\/\/www.kaggle.com\/getting-started\/40799) \n9. [My_Previous_Kernel](https:\/\/www.kaggle.com\/bhanvimenghani\/folium-chai-eda)","80b1344a":"--------------------------------------------------------------------\n---------------------------------------------------------------------","f338d3eb":"# <span style=\"color:#E74C3C\">2.8 Oldpeak : ST depression induced by exercise relative to rest\u274c\nSTD is an important factor in determining a heart disease and a ","f02ccca7":"# <span style=\"color:#E74C3C\">2.3 Cholestrol\u274c\n## Choslestrol levels is alomst same for both plots hence non relevent\"\n","6d8d9ace":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc ROC Score<\/div>","04d7edc7":"--------------------------------------------\n-----------------------------------------","b48ae8be":"# <span style=\"color:#E74C3C\"> 2.4 Fasting Blood Sugar\nA fasting blood sugar level less than 100 mg\/dL (5.6 mmol\/L) is normal. A fasting blood sugar level from 100 to 125 mg\/dL (5.6 to 6.9 mmol\/L) is considered prediabetes. If it's 126 mg\/dL (7 mmol\/L) or higher on two separate tests, you have diabetes.","8adc145f":"# <span style=\"color:#E74C3C\"> \ud83c\udf67 Sweetviz <\/spam>","61eb27d5":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc ROC Score<\/div>","a8195b05":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc ROC Score<\/div>","a96d50b1":" resting blood pressure is not an important parameter rather misleading","2383bc3b":"# <a id=\"4\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> 2. Feature Engineering\ud83d\ude0e<\/div><\/font><\/a>\n### this is the second part of the kernel wherein relationship between each column of the dataset and 2 generalized attributes , in our case sex\u2705 and age\u2705 , is made to derive insights form the figures and find which feature is relatively more important for the model and will have a greater impact on the model accuracy and provide relevent predictions .","8017e91f":"Since we are not provided with the exact values of fbs the people have a detailed exploration can't be made but having fasting bs is a prooven fact of heart disease and an important parameter to judge the model it will be considered.","b49927a2":" ### <div class=\"alert alert-block alert-info\">\ud83d\udccc Accuracy","07f874d4":"# <span style=\"color:#E74C3C\"> 2.6 thalach : maximum heart rate achieved \u2705\nYou can calculate your maximum heart rate by subtracting your age from 220. For example, if you're 45 years old, subtract 45 from 220 to get a maximum heart rate of 175. This is the average maximum number of times your heart should beat per minute during exercise.","713c7e23":"# F1 Score","090f1fe2":"<img src=\"https:\/\/www.wthub.org\/wp-content\/uploads\/2019\/11\/heart_glow.gif\" height=\"500\" width=\"500\">","c7e89970":"# <span style=\"color:#E74C3C\"> 2.1 chest pain types : \u2705 <\/span>\n### It is essentially of 4 types and coded in the dataset as 0,1,2,3 .\n### The firat graph prescribes the relation between the 4 types of pains and most number of males and females suffer from type 0 chest pain while the 3rd kind of chest pain is least common. We can easily infer from the chart that type 0 and type 2 chest pains can be important in determining a heart disease.","91baad82":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Accuracy <\/div>","941892b6":"# <font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\">Heart Disease Prediction\u2764 <\/div> <\/font>","795abbe5":"# <span style=\"color:#E74C3C\"> 2.7 exang : exercise induced angina  \u274c","906c8238":"## <span style=\"color:#E74C3C\"> \ud83d\udccc Scalling \/ Normalization <\/span>","522e7178":"The below plot clearly prooves that people of the age 55-59 are most likely to have chest pains of types 0 and 2.\nPeople of the age 29 - 34 years are less likely to have chest pains. We can infer age and sex to be important factors along with chest pain types","482a0085":" ### <div class=\"alert alert-block alert-info\">\ud83d\udccc Confusion Matrix ","fe9863ad":"### <span style=\"color:\">1. Selecting The \"Prediction\" <\/span>\nWe are very sure of what we want to predict the target values hence:\n","4d726df2":"### <span style=\"color:#E74C3C\"> \ud83d\udd57 Approach <\/span>\n\n","ae989737":"# <a id=\"9\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> Comparing all the models <\/div><\/font><\/a>","a5831d13":"<img src =\"https:\/\/i.pinimg.com\/originals\/6b\/d3\/e9\/6bd3e97cbf5c7d873b75548d6515a6e0.gif\">","204cf4c6":" <font size=\"4\"><div style=\"border-radius:10px;color:white;background-color:#FA8072;padding: 10px;\"> 1. Naive Bayes<\/div><\/font>","56663c00":"# Recall","b24cf6eb":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc Accuracy<\/div>","9991c12a":"# <font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\">  2. KNN<\/div><\/font>","12b0d0ed":"# <span style=\"color:#E74C3C\"> 2.5 restecg : resting electrocardiographic result\u274c","9f5092bc":"Not much valuable inferences can be made over categorical values ","f59b64d1":"## <a id=\"2\"><font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> \ud83d\udccc2. Data Description : <\/div><\/font><\/a>\n2. sex : 1 - male , 0- female\n3. cp : chest pain type --> 1,2,3,0 (essentially of 4 types)\n4. trestbps:  resting blood pressure ---> integers\n5. chol : serum cholestoral --> int\n6. fbs : fasting blood sugar \n7. restecg : resting electrocardiographic result\n8. thalach : maximum heart rate achieved\n9. exang : exercise induced angina 1-Y ,0 - N\n10. Oldpeak  : ST depression induced by exercise relative to rest\n11. slope - the slope of the peak exercise ST segment\n12. ca - number of major vessels (0-3) colored by flourosopy\n13. thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. target : Actual values ie. have the disease(1) or not(0)","7b1bb187":"Although exercise induced Angima could be a valuable attribute but relative to the dataset people having exang do not face heart diesases and ppl not having exang go through heart diseases, so we drop this feature.","cec4fd3b":"# <font size=\"6\"><div style=\"border-radius:5px;color:white;background-color:#FA8072;\"> 4. Random Forest<\/div><\/font>","2ec326da":"### <div class=\"alert alert-block alert-info\"> \ud83d\udccc ROC scores","d2fca28a":"### 2. Selecting the \"Features\"\nSelecting the x attributes can be very daunting in case of multiple number of features in the dataset as a Data Scientist needs to be aware of what each column wants to convey and how much inpact will it have on the prediction and model accuracy, so that we can drop the less important features and simplify our problem.\nSo there are 2 ways to it :\n\n1. Include all Features\n2. Include only most impactful Features\n\nFor the simplicity of the project we would like to include all the features while the difference in incliuding important ones will be assigning a X var for them and repeting the same steps.\n","8eaafc81":"-------------------------------------\n------------------------------\n","99804e48":"The resting heart beat plot is also misleading and alost the same for the person who has a heart disease or not ","da96b1fc":"## <span style=\"color:#E74C3C\"> ML Pipeline Contents <\/span>\n > * [Data Exploration](#1) \n > * [Data Description](#2)\n > * [EDA](#3)\n > * [Feature Engineering](#4) \n > * [Data Processing](#5)\n > * [Methodology](#6)\n   > > * NAive Bayes\n   > > * KNN\n   > > * Decision Tree\n   > > * Random Forest\n > * [Metricies Evaluation ](#7)\n    >> * Accuracy \n    >> * Confusion Matrix\n    > >* ROC Score\n    >> * Recall \n    >> * Precision\n    >> * F1 score\n > * [Plot of all Metrices](#9)\n > * [References](#8)"}}