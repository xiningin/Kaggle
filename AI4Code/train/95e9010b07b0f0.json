{"cell_type":{"7db7056f":"code","2266a193":"code","d5b17561":"code","4943bccf":"code","79a477cf":"code","7c430f64":"code","4966756e":"code","e8a8ee29":"code","09661fbb":"code","ec721d88":"code","8a3bdc9b":"code","10436cdf":"code","600d8df5":"code","7f55cd0e":"code","e67b69a6":"code","eb86d3e3":"code","dbc9acc5":"code","f5ff3757":"markdown","a136cb5d":"markdown","ee739ddd":"markdown","beaa1721":"markdown","bf766f7a":"markdown","a826e974":"markdown","68d6eb99":"markdown"},"source":{"7db7056f":"# imports\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport torch.nn.functional as F\nprint(\"Cuda available :\",torch.cuda.is_available())\nprint(\"PyTorch Version: \",torch.__version__)","2266a193":"device = torch.device('cpu')\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nprint(f\"device is set to {device}\")","d5b17561":"import ipywidgets as widgets\nfrom ipywidgets import interact, interact_manual\n# interact with any fucntion usign paramenters","4943bccf":"@interact\ndef drawGraph(start = -10,end=10,num = 100):\n  line = np.linspace(start,end,num,dtype=np.float32)\n  plt.plot(line,np.sin(line),label='sin')\n  plt.plot(line,np.cos(line),label='cos')\n  plt.legend()\n  plt.show()","79a477cf":"# you can get the fucniton usage in ipynb\nnn.Linear??","7c430f64":"model = nn.Sequential(nn.Linear(1,1),\n#                       nn.ReLU()\n                     )\n\nlearningRate = 2\ncriterion = nn.MSELoss() \n\noptimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n# SGD and Adam\n\nmodel.to(device)","4966756e":"# user defined funtions\nW,B = 50,-200\n\ndef linearFunction(ar):\n    return W*ar+B\n\n# x_train = np.random.random(size=(100,1)).astype(np.float32)\nx_train = np.random.randint(-10,10,size=(100,1)).astype(np.float32)\ny_train = linearFunction(x_train)\n# print(x_train[0],y_train[0])\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()","e8a8ee29":"# initialize and train model\nstart =0\nepochs = start + 100\nepoch_interval = 10\nfor epoch in range(start,epochs+1):\n    # Converting inputs and labels to Variable\n    if torch.cuda.is_available():\n        inputs = Variable(torch.from_numpy(x_train).cuda())\n        labels = Variable(torch.from_numpy(y_train).cuda())\n    else:\n        inputs = Variable(torch.from_numpy(x_train))\n        labels = Variable(torch.from_numpy(y_train))\n    \n    # plot to tensorboard\n    \n    \n    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n    optimizer.zero_grad()\n\n    # get output from the model, given the inputs\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n    \n    if epoch%epoch_interval == 0:\n        writer.add_scalars('weight',{'model_weight':model[0].weight.data[0],'actual_weight':W},epoch)\n        writer.add_scalars('bias',{'model_bias':model[0].bias.data[0],'actual_bias':B},epoch)\n        print('epoch {}, loss {}'.format(epoch, loss.item()))","09661fbb":"# animation import\n\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\n\nfrom matplotlib import rc\nrc('animation', html='jshtml')\n# from IPython.display import HTML\n%matplotlib inline\n","ec721d88":"fig,ax = plt.subplots(1,2,figsize=(12,8))\n\n\nstart = -10\nend=10\nnum = 100\nloss_arr = []\n\ndef model_train_vis(w):\n    ax[0].clear()\n    if torch.cuda.is_available():\n        inputs = Variable(torch.from_numpy(x_train).cuda())\n        labels = Variable(torch.from_numpy(y_train).cuda())\n    else:\n        inputs = Variable(torch.from_numpy(x_train))\n        labels = Variable(torch.from_numpy(y_train))\n\n    # plot to tensorboard\n\n\n    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n    optimizer.zero_grad()\n\n    # get output from the model, given the inputs\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n    loss_arr.append(loss.item())\n    \n    line = torch.from_numpy(np.linspace(start,end,num,dtype=np.float32)).to(device)\n    preds = model(line.reshape(-1,1) ).detach()\n    \n    # plot graph\n    ax[0].plot(line.cpu().numpy(),preds.cpu().numpy(),\n           linewidth=3,label='model')\n    ax[0].plot(line.cpu().numpy(),linearFunction(line.cpu().numpy()),label='ground truth')\n    ax[0].set_title(\"Visualize\")\n    # plot loss\n    ax[1].plot(np.linspace(1,len(loss_arr),len(loss_arr)) ,loss_arr,'r+')\n    ax[1].set_title(\"Loss\")\n    ax[0].legend()\n    \n","8a3bdc9b":"\n# plotting the animation\nanim = animation.FuncAnimation(fig, model_train_vis, frames=100, blit=False)\nanim # generate a video file ","10436cdf":"model[0].weight.data[0]\n\n","600d8df5":"# using the hard way \n# run tensorboard in kaggle server. and operate using public url\n\n# download the files for ngrok\n# !wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n# !unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir .\/runs\/ --host 0.0.0.0 --port 6006 &\",\n                        \".\/ngrok http 6006 &\"\n                        ]]\n","7f55cd0e":"! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","e67b69a6":"from torch.utils.tensorboard import SummaryWriter\n\nwriter = SummaryWriter()\n# adding graph\na = torch.Tensor([[1],[4],[32]]).cuda()\nwriter.add_graph(model,a)\n# argument is the model and the inpur params\nwriter.close()\n\n! rm -r runs\n! mkdir runs\n","eb86d3e3":"r = 2\nfor i in range(100,500):\n    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i\/r),\n                                    'xcosx':i*np.cos(i\/r),\n                                    'tanx': np.tan(i\/r)}, i)\nwriter.close()","dbc9acc5":"# writer = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('loss new',np.random.randint(1,100),i)\n# writer.close()","f5ff3757":"# Predicting Math Functions - Part 1\n- y = mx+c\n- y = x^2\n- sin(x)\n- Cos(x)\n\n","a136cb5d":"# Normal Learning","ee739ddd":"## Important Links\n- Mathematics of deep learning\n  - https:\/\/towardsdatascience.com\/deep-learnings-mathematics-f52b3c4d2576\n- Machine learning simple math fucntions\n  - https:\/\/towardsdatascience.com\/can-machine-learning-model-simple-math-functions-d336cf3e2a78\n\n### Pytorch links\n- https:\/\/pytorch.org\/tutorials\/beginner\/ptcheat.html\n\n### interactive widget in jupyter\n- https:\/\/towardsdatascience.com\/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n\n- [NN learn sine function](https:\/\/stackoverflow.com\/questions\/46995209\/neural-network-toy-model-to-fit-sine-function-fails-whats-wrong)\n\n","beaa1721":"# This Notebook has a Walkthrough\n## Click the below link to watch the video\n\n# [Predicting Functions](http:\/\/https:\/\/youtu.be\/Ypp86VxRy8k)\n\n### If you found the content useful. Kindly give your feedback and consider giving a Thumbs up","bf766f7a":"# live visualization","a826e974":"* > # Setting up Tensorboard","68d6eb99":"## Tensorboard in Kaggle\n\nhttps:\/\/www.kaggle.com\/shivam1600\/tensorboard-on-kaggle\n\nhttps:\/\/pytorch.org\/docs\/stable\/tensorboard.html (pytorch tensorboard)"}}