{"cell_type":{"e54f0cd2":"code","b3d383b8":"code","1c35ba91":"code","0c9a5dbc":"code","e0c071ef":"code","8cf34b9d":"code","14cd4fd7":"code","de072125":"code","254d406c":"code","ac478787":"code","b2a55e31":"code","1ff49690":"code","fb102109":"code","209661d1":"code","d5194bea":"code","321e194f":"code","46661c85":"code","455af6b8":"code","eb274b7e":"code","d9ecc92e":"code","ed9060b4":"code","5240a910":"code","6fe0083a":"code","0cc33e9f":"code","ea44da18":"markdown","dfb81cdc":"markdown","dde372fc":"markdown","b9218200":"markdown","75abe1aa":"markdown","eefe55e5":"markdown","745c412e":"markdown","8f1e6bb5":"markdown","58dd685b":"markdown","c8e06624":"markdown","ba87ee04":"markdown","73181708":"markdown","4c341d62":"markdown","90e5c7f1":"markdown","75c0b98a":"markdown","7f404bfc":"markdown","4adced5a":"markdown","e555032f":"markdown","b3b32e11":"markdown","103da68e":"markdown","7abf60b5":"markdown","c46a6696":"markdown","12d04c28":"markdown","a5a0e809":"markdown","c9105826":"markdown","4c9e35f7":"markdown","8fcb8c8c":"markdown","aedbe9b7":"markdown","346ed690":"markdown","587583fb":"markdown","1ae8f655":"markdown","9121de65":"markdown"},"source":{"e54f0cd2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","b3d383b8":"data=pd.read_csv('..\/input\/dataset-of-letter-predictiontraintest\/train.csv')","1c35ba91":"data.head()","0c9a5dbc":"data.isnull().sum()","e0c071ef":"data['letter'].value_counts()","8cf34b9d":"data['letter'].value_counts().plot.bar()\nplt.plot()","14cd4fd7":"X=data.iloc[:,1:-1]\ny=data.iloc[:,0]\nprint(X.head())\nprint(y.head())","de072125":"X.shape,y.shape","254d406c":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","ac478787":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=245,criterion='entropy',random_state=0,min_samples_split=2)\n\nrfc.fit(X_train,y_train)","b2a55e31":"y_pred=rfc.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nac= accuracy_score(y_test,y_pred)\nprint('Accuracy is :',ac*100)","1ff49690":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='brute',n_neighbors =1 ,leaf_size=100,p=30)\nknn.fit(X_train, y_train)\n\nknn_predictions = knn.predict(X_test) \n\nacc=accuracy_score(y_test,knn_predictions)\nprint('Accuracy is :',acc*100)","fb102109":"from xgboost import XGBClassifier\nmodel = XGBClassifier(learning_rate=1.0)\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","209661d1":"from sklearn.svm import SVC\nmodel = SVC(kernel='rbf', C=1E01,tol=0.1)\nmodel.fit(X_train, y_train)\npredicted= model.predict(X_test)","d5194bea":"from sklearn.metrics import confusion_matrix,accuracy_score\naccuracy = accuracy_score(y_test, predicted)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))#97.28","321e194f":"df1=pd.read_csv('..\/input\/dataset-of-letter-predictiontraintest\/test.csv')","46661c85":"df1.head()","455af6b8":"X1=df1.iloc[:,:-1]\nprint(X1.head())\nX1.shape","eb274b7e":"rfc.fit(X,y)","d9ecc92e":"y_pred=rfc.predict(X1)\ny_pred","ed9060b4":"submission = pd.DataFrame(y_pred,index=df1.id,columns=['letter'])\nsubmission.to_csv('submissionr.csv')","5240a910":"model.fit(X,y)","6fe0083a":"y_pred=model.predict(X1)","0cc33e9f":"submission = pd.DataFrame(y_pred,index=df1.id,columns=['letter'])\nsubmission.to_csv('submissionsvm.csv')","ea44da18":"Checking whether the given dataset has null values or not by using isnull() .","dfb81cdc":"Viewing the first 5 rows of the test dataset","dde372fc":"### Importing the test dataset in to the dataFrame from the 'dataset-of-letter-predictiontraintest' folder","b9218200":"Viewing the first 5 rows of the data using head() function","75abe1aa":"Importing necessary Libraries","eefe55e5":"From the \" dataset-of-letter-predictiontraintest\"  folder we have train dataset and test dataset from which we load the dataset.\nIn the train dataset we use this data to train the data and fit the data with various classification algorithms and predict the test accuracy with each algorithm.","745c412e":"#### we have stored the new data by neglecting the column 'id' which is not useful for dependency of target variable.\n#### In the X variable we store the total dataset except the 'id' column.\n#### In the y variable we store only the target variable which is 'letter'","8f1e6bb5":"Plotting the bar graph to view the count of each letter","58dd685b":"### Splitting the data into target variable and independent variables by slicing","c8e06624":"# Test Predictions","ba87ee04":"# Classification Algorithms:","73181708":"### --> Fitting the model on total dataset, \n### --> Predicting the model on test data and \n### --> Creating a Submission file which contains predicted values of the test data","4c341d62":"### --> Fitting the model on total dataset, \n### --> Predicting the model on test data and \n### --> Creating a Submission file which contains predicted values of the test data","90e5c7f1":"### In the given dataset we have 'letter' as a target variable which has English alphabet and the remaining features are the independent variables which are used to predict the English Alphabet","75c0b98a":"## 3. XGBoost:","7f404bfc":"### --> Importing necessary packages of XGBClassifier to train the model,\n### --> Fitting the model on train data, \n### --> Predicting the model on test data and \n### --> Finding the accuracy of the test data.","4adced5a":"### --> Importing necessary packages of Support Vector Classifier to train the model,\n### --> Fitting the model on train data, \n### --> Predicting the model on test data and \n### --> Finding the accuracy of the test data.","e555032f":"## 4. Support Vector Classifier","b3b32e11":"## 2. KNN:","103da68e":"##  The main objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet.\n","7abf60b5":"### --> Importing necessary packages of KNN to train the model,\n### --> Fitting the model on train data, \n### --> Predicting the model on test data and \n### --> Finding the accuracy of the test data.","c46a6696":"Importing the dataset in to the dataframe","12d04c28":"## 1. Random_Forest_Classifier :","a5a0e809":"# Letter Recognition","c9105826":"Checking whether the target variable and independent variables has same number of rows","4c9e35f7":"Removing the unnecessary independent variables which are not useful in finding the target variable.","8fcb8c8c":"### --> Predicting the model on test data and \n### --> Finding the accuracy of the test data.","aedbe9b7":"### --> Importing necessary packages of RandomForest to train the model,\n### --> Fitting the model on train data, \n","346ed690":"# Conclusion:\n### From the above DataSet we have done the following process:\n1. loading the 'train' dataset.\n2. Partitioning the dataset into dependent variables and independent variables.\n3. Dividing the dependent and independent variable into train and test data so as to validate how well algorithms predicts the target values.\n4. Importing the packages of classification algorithms and fitting the model to train and predict the target variables.\n5. Calculating the accuracy for each classification algorithm.\n6. Loading the 'test' dataset.\n7. Feature engineering the dataset and fitting the total train data to specified algorithms.\n8. Predicting the model on test dataset.\n9. Storing the predicted values into the dataframe and creating a submission file by taking the predicted dataframe input to it.\n10. List of algorithms used and their predicted accuracy.\n\n                                                 **  Dataset  **\n        --------------------------------------------------------------------------------------                                           Train Data       |    TestData\n        --------------------------------------------------------------------------------------                    TrainData(80%Fit) | TestData(20%Predict) |\n        --------------------------------------------------------------------------------------\n        Algorithm used :                      |                   Accuracy      \n        -------------------------------------------------------------------------------------- \n        1. Random_Forest  |                              96.12 (2)    |      97.08\n        2. KNN            |                              94.56        |\n        3. XGBoost        |                              85.84        |\n        4. SVC            |                              97.28 (1)    |      98.33 ","587583fb":"## Dividing the training data and test data so as to validate how well our algorithm is predicting to the unknown test data from the 'train' dataset(20%-testdata)","1ae8f655":"## 1. Random Forest Classifier:","9121de65":"## 2. Support_Vector_Classifier :"}}