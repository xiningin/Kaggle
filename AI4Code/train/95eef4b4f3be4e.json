{"cell_type":{"cff59c9a":"code","f615084e":"code","864d7639":"code","36b124b2":"code","592d18a6":"code","4ca520bc":"code","e9bd0b37":"code","cb5c7eb8":"code","59e8ecbb":"code","617d26b6":"code","dd079bb9":"code","4f78cffc":"code","5cdf6326":"code","2a67d0fd":"code","1b5ebf6c":"code","128c4427":"code","6a371346":"code","5ea37d5c":"code","4ccb032d":"code","6c905202":"code","ff032267":"code","62b24913":"code","53e415ef":"code","29694285":"code","fb71a148":"code","6966dc04":"code","bb3ef76a":"code","70b66b7b":"code","7878fc72":"code","8fa96e0a":"code","276a988c":"code","081651d7":"code","f0dbdf70":"code","87d93fbe":"code","4b1d170b":"code","c2f42f35":"code","be2191c1":"code","aca363d2":"code","30e3b472":"code","3cda41cb":"code","d3dde0fa":"code","8f18ef7e":"markdown","8d807b20":"markdown","fe053e52":"markdown","b43b038d":"markdown","a8817dd1":"markdown","e4610cc1":"markdown","fa470225":"markdown","04229d89":"markdown","e8e59982":"markdown","5b8b4c92":"markdown","c3b91ae3":"markdown","3b3b2340":"markdown","5e8ae18d":"markdown","914d784d":"markdown","1624b97f":"markdown","9496ab01":"markdown","86e884ad":"markdown","5b985963":"markdown","cb76b244":"markdown","2cb223a5":"markdown"},"source":{"cff59c9a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","f615084e":"df_water = pd.read_csv(\"..\/input\/drinking-water-probability\/drinking_water_potability.csv\")\ndf_water.shape","864d7639":"df_water.isnull().sum()","36b124b2":"print(df_water['ph'].min(),\" to \",df_water['ph'].max())\n\nsns.distplot(df_water['ph'])","592d18a6":"print(f\"Mean = {df_water['ph'].mean()} median = {df_water['ph'].median()}\")\n","4ca520bc":"df_water['ph'] = df_water['ph'].fillna(df_water['ph'].mean())\ndf_water['ph'].isnull().sum()","e9bd0b37":"df_water.info()","cb5c7eb8":"sns.distplot(df_water['Sulfate'])","59e8ecbb":"sulfate = df_water['Sulfate'].mean()\ndf_water['Sulfate']= df_water['Sulfate'].fillna(sulfate)","617d26b6":"sns.distplot(df_water['Trihalomethanes'])","dd079bb9":"print(f\"mean = {df_water['Trihalomethanes'].mean()}, median = {df_water['Trihalomethanes'].median()}\")","4f78cffc":"df_water['Trihalomethanes'] = df_water['Trihalomethanes'].fillna(df_water['Trihalomethanes'].median())","5cdf6326":"df_water.isnull().sum()","2a67d0fd":"columns = [x for x in df_water.columns if x != 'Potability']\nplt.figure(figsize=(20,20))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    sns.boxplot(data=df_water,x = 'Potability' ,y= columns[i],showfliers=False)","1b5ebf6c":"\ndef get_percentiles(df,columns,target,label):\n    res = {}\n    df_a = df[df[target] == label] \n    #print(df_a)\n    for col in columns:\n        x = np.quantile(df_a[col],0.25)\n        y = np.quantile(df_a[col],0.5)\n        z = np.quantile(df_a[col],0.75)\n        res[col] = [x,y,z]\n    df_res = pd.DataFrame(res,index=[\"Q1\",\"Q2\",\"Q3\"])\n    return df_res\n        \n    \n#### Calling the above function for potable\nget_percentiles(df_water,columns,'Potability',1)","128c4427":"#### Calling the above function for non potable\nget_percentiles(df_water,columns,'Potability',0)","6a371346":"plt.figure(figsize=(20,20))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    y_0 = df_water.loc[df_water['Potability'] == 0,columns[i]].min()\n    y_1 = df_water.loc[df_water['Potability'] == 1,columns[i]].min()\n    plt.bar([0,1],[y_0,y_1],color=['#ff0000','#00ff00'])\n    plt.xlabel(\"Potability\")\n    plt.ylabel('Min of {0}'.format(columns[i]))\n    plt.xticks([0,1])\n","5ea37d5c":"plt.figure(figsize=(20,20))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    y_0 = df_water.loc[df_water['Potability'] == 0,columns[i]].max()\n    y_1 = df_water.loc[df_water['Potability'] == 1,columns[i]].max()\n    plt.bar([0,1],[y_0,y_1],color=['#ff0000','#00ff00'])\n    plt.xlabel(\"Potability\")\n    plt.ylabel('Min of {0}'.format(columns[i]))\n    plt.xticks([0,1])\n","4ccb032d":"sns.pairplot(data=df_water)","6c905202":"def treat_outliers(df,columns,target,label):\n    for c in columns:\n        q1 = np.quantile(df.loc[df[target] == label,c],0.25)\n        q3 = np.quantile(df.loc[df[target] == label,c],0.75)\n        df.loc[df[target] == label,c] = df.loc[df[target] == label,c].apply(lambda x: q1 if x<q1 else x)\n        df.loc[df[target] == label,c] = df.loc[df[target] == label,c].apply(lambda x: q3 if x>q3 else x)\n        ","ff032267":"treat_outliers(df_water,columns,'Potability',1)","62b24913":"plt.figure(figsize=(10,10))\nsns.heatmap(df_water.corr(),annot=True)","53e415ef":"import statsmodels.api as sm\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier","29694285":"X_train, X_test, y_train, y_test = train_test_split(df_water[[c for c in df_water.columns if c != 'Potability']],df_water['Potability'],train_size = 0.7,random_state = 1)","fb71a148":"sc = StandardScaler()\nX_train[X_train.columns] = sc.fit_transform(X_train)\nX_test[X_test.columns] = sc.transform(X_test)","6966dc04":"from imblearn.over_sampling import SMOTE\n\nX_train, y_train = SMOTE(random_state=1,n_jobs=-1).fit_resample(X_train,y_train)","bb3ef76a":"X_train_sm = sm.add_constant(X_train)\nlm = sm.GLM(y_train,X_train_sm,family=sm.families.Binomial()).fit()\nlm.summary()","70b66b7b":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef vif(data):\n    res = pd.DataFrame()\n    res['Feature'] = data.columns\n    res['VIF'] = [variance_inflation_factor(data.values,i) for i in range(data.shape[1])]\n    return res\n\nvif(X_train_sm)","7878fc72":"## Add constant to x test\nX_test_sm = sm.add_constant(X_test)\ny_train_pred = lm.predict(X_train_sm)\n\n","8fa96e0a":"from sklearn.metrics import confusion_matrix\n\ndef tp_fp(cf):\n    fp = cf[0,1]\/(cf[0,0] + cf[0,1])\n    tp = cf[1,1]\/(cf[1,0] + cf[1,1])\n    return fp,tp\n\n\ndef plot_roc(data,truth):\n    cutoff = [0.001*i for i in range(1,1000)]\n    x = []\n    y = []\n    for c in cutoff:\n        #print(data)\n        data_temp = data.apply(lambda x: 1 if x>=c else 0)\n        cf = confusion_matrix(truth,data_temp)\n        x.append(tp_fp(cf)[0])\n        y.append(tp_fp(cf)[1])\n    plt.plot(x,y)","276a988c":"plot_roc(y_train_pred,y_train)","081651d7":"from sklearn.metrics import roc_curve\nfp,tp,_ = roc_curve(y_train,y_train_pred)\nplt.plot(fp,tp)","f0dbdf70":"y_test_pred = lm.predict(X_test_sm).apply(lambda x: 1 if x>= 0.5 else 0)\n\ncf = confusion_matrix(y_test,y_test_pred)\nacc = (cf[0,0] + cf[1,1])\/(cf[0,0] + cf[0,1] + cf[1,1] +cf[1,0])\ntpr = cf[1,1]\/(cf[1,0] + cf[1,1])\nprint(f\"tpr = {tpr} accuracy = {acc}\")","87d93fbe":"dt = DecisionTreeClassifier(random_state=1)\nparams = {\n    \"min_samples_split\": [10,20,100],\n    \"max_depth\": [5,10,50],\n    \"min_samples_leaf\": [10,20,50],\n    \"max_leaf_nodes\": [10,20,100]\n}\n\ndt_grid = GridSearchCV(estimator=dt,param_grid=params,cv=5,scoring='balanced_accuracy',verbose=10,n_jobs = -1).fit(X_train,y_train)","4b1d170b":"dt = dt_grid.best_estimator_\ny_train_pred = dt.predict(X_train)\nprint(confusion_matrix(y_train_pred,y_train))","c2f42f35":"y_test_pred = dt.predict(X_test)\nprint(confusion_matrix(y_test_pred,y_test))\n\ncf = confusion_matrix(y_test_pred,y_test)\n\n#### get metrics\ndef metrics(cf):\n    acc = (cf[0,0] + cf[1,1])\/(cf[0,0]+ cf[0,1] + cf[1,0] + cf[1,1])\n    recall = (cf[1,1])\/(cf[1,0] + cf[1,1])\n    specificty = (cf[0,0])\/(cf[0,0] + cf[0,1])\n    print(\"accuracy = {0}\\n\\nSensitivity(TPR) = {1}\\n\\nSpecificity = {2}\".format(acc,recall,specificty))\n    \nmetrics(cf)","be2191c1":"rf = RandomForestClassifier(random_state=1)\nparams = {\n    \"min_samples_split\": [10,20,100],\n    \"max_depth\": [5,10,50],\n    \"min_samples_leaf\": [10,20,50],\n    \"max_leaf_nodes\": [10,20,100],\n    \"max_features\": [9,5]\n}\n\nrf_grid = GridSearchCV(estimator=rf,param_grid=params,cv=5,scoring='balanced_accuracy',verbose=10,n_jobs = -1).fit(X_train,y_train)","aca363d2":"rf = rf_grid.best_estimator_\n\ny_train_pred = rf.predict(X_train)\nconfusion_matrix(y_train,y_train_pred)","30e3b472":"\ny_test_pred = rf.predict(X_test)\ncf = confusion_matrix(y_test,y_test_pred)\nmetrics(cf)","3cda41cb":"gb = GradientBoostingClassifier(random_state=1)\nparam_grid = {\n    \"max_depth\": [3,5],\n    \"min_samples_split\": [10,20, 50],\n    \"min_samples_leaf\": [30,50],\n    \"n_estimators\": [50,100],\n    \"learning_rate\": [0.01, 0.05, 0.1]\n}\n\ncv = GridSearchCV(estimator=gb, param_grid=param_grid,cv=5,scoring='balanced_accuracy',verbose=10,n_jobs=-1).fit(X_train,y_train)","d3dde0fa":"gb = cv.best_estimator_\n\ny_train_pred = gb.predict(X_train)\ncf = confusion_matrix(y_train,y_train_pred)\n\nprint(cf)\nacc = (cf[0,0] + cf[1,1])\/np.sum(cf)\nrecall = (cf[1,1])\/(cf[1,1] + cf[1,0])\nspec = (cf[0,0])\/(cf[0,1] + cf[0,0])\nprint(f\"Accuracy = {acc} Recall = {recall} Specificity = {spec}\")","8f18ef7e":"### The missing values are treated and data is prepared\n\n## Step 2: EDA","8d807b20":"## Let us plot the ROC curve to finalize the cutoff","fe053e52":"## not able to find best threshold\nlets take 0.5","b43b038d":"### If not required we can analyze by skipping","a8817dd1":"#### Lets see the distribution of ph.\n- It should be between 0 - 14","e4610cc1":"### The differences are not visible on plots\n- Let us check 25th,50th  and 75th percentle\n- This would help in understanding","fa470225":"### Let us do cleaning for ph\n- missing values = 7 for ph as per above analysis\n- Even median will be 7 because 7 lies in between 0 and 14(middle value 50 %ile)\n- For normal distributed data mean, median mode coincides","04229d89":"## Now check for trihalomethanes","e8e59982":"## There are differences observed \n- Here still water with ph = 12 is labelled as potable \"Which is a serious outlier\"\n- We will have to treat it","5b8b4c92":"### All the models from tree families gave 99 % accuracy","c3b91ae3":"## Scaling the input features","3b3b2340":"### Model doing a good job on train data. Lets evaluate on test data","5e8ae18d":"###  Lets check for null values","914d784d":"### Vif is less which is good \n- We will use the model for predictions","1624b97f":"### We will treat missing value with median\n- mean will also work as the distribution is normal","9496ab01":"### Decision tree did a great job \n- Good results can cause overfitting in future because we have not evaluated on actual data\n- Let us try Random forest","86e884ad":"#### Letus do outlier treatment for the data which is labelled as potable `1`\n- Large outliers are possible for water which is unfit for drinking\n- Thats why doing outier treatment on water which is potable","5b985963":"### Its nicely normally distributed\n- The center (mean) should be 7\n- Justification: <b>Water is neutral in nature so pH is ideally close to 7<\/b>","cb76b244":"## Random forest too gave good results","2cb223a5":"### Let us check the min and max"}}