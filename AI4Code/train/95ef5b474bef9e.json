{"cell_type":{"b08b1b67":"code","d7247171":"code","0bd13cd1":"code","0350559e":"code","52d36de0":"code","0e2b5699":"code","f5f67826":"code","e95cd091":"code","77634bed":"code","f5ac662d":"code","4e0e3228":"code","285f8879":"code","e76e2830":"markdown","ee231e29":"markdown","62fc3c35":"markdown","3af941af":"markdown"},"source":{"b08b1b67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7247171":"%%capture\n!pip install pycaret[full]","0bd13cd1":"import pandas as pd\nimport numpy as np \nfrom pycaret.regression import *","0350559e":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv',index_col='row_id')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv',index_col='row_id')","52d36de0":"def pre_process(df):\n    \n    df['date'] = pd.to_datetime(df['date'])\n    df['week']= df['date'].dt.week\n    df['year'] = 'Y'+df['date'].dt.year.astype(str)\n    df['quarter'] = 'Q'+df['date'].dt.quarter.astype(str)\n    df['day'] = df['date'].dt.day\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df.loc[(df.date.dt.is_leap_year) & (df.dayofyear >= 60),'dayofyear'] -= 1\n    df['weekend'] = df['date'].dt.weekday >=5\n    df['weekday'] = 'WD' + df['date'].dt.weekday.astype(str)\n    df.drop(columns=['date'],inplace=True)   \n\npre_process(train)\npre_process(test)","0e2b5699":"train.info(), test.info()","f5f67826":"# Credit to https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting\/discussion\/36414\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","e95cd091":"reg = setup(data = train,\n            target = 'num_sold',\n            normalize=True,\n            normalize_method='robust',\n            transform_target = True,\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            create_clusters = False,\n            use_gpu = True,\n            silent = True,\n            fold=10,\n            n_jobs = -1)","77634bed":"add_metric('SMAPE', 'SMAPE', SMAPE, greater_is_better = False)\ntop =compare_models(sort = 'SMAPE',n_select = 3, include = ['catboost','lightgbm','xgboost'])","f5ac662d":"blend = blend_models(top)\npredict_model(blend)","4e0e3228":"final_blend = finalize_model(blend)\npredict_model(final_blend)","285f8879":"preds = predict_model(final_blend, data=test)\nsub = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\nsub.to_csv('submission.csv', index = False)\nprint(sub.head(),sub.describe())","e76e2830":"#### Did it work?\nThe notebook goes together with the EDA notebook, which visualizes the various seasonal effects and the differences in growth rate. Scikit-learn doesn't offer SMAPE as a loss function. As a workaround, I'm training for Huber loss with a transformed target, apply a correction factor, and we'll see how far we'll get.\n\nThe transformed target for the regression is the log of the sales numbers.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\nWhat else do you think you can try as part of this approach?\nLook at a notebook which presents feature engineering (based on the insights of this EDA) and a linear model which makes use of the features.","ee231e29":"**I Hope you find this notebook useful , Good Luck!**","62fc3c35":"#### What are you trying to do in this notebook?\nFor this challenge, we will be predicting a full year worth of sales for three items at two stores located in three different countries. This dataset is completely fictional, but contains many effects you see in real-world data, e.g., weekend and holiday effect, seasonality, etc. The dataset is small enough to allow us to try numerous different modeling approaches.\n\n#### Why are you trying it?\nThere are two (fictitious) independent store chains selling Kaggle merchandise that want to become the official outlet for all things Kaggle. we want to figure out which of the store chains(KaggleMart or KaggleRama) would have the best sales going forward.\n\n**Files**\n\n- train.csv - the training set, which includes the sales data for each date-country-store-item combination.\n- test.csv - the test set; your task is to predict the corresponding item sales for each date-country-store-item combination. Note the Public leaderboard is scored on the first quarter of the test year, and the Private on the remaining.\n- sample_submission.csv - a sample submission file in the correct format.","3af941af":"All credit goes to - https:\/\/www.kaggle.com\/bernhardklinger\/tps-jan-2022 "}}