{"cell_type":{"7edc8f9c":"code","8a51b090":"code","c07b1ecd":"code","d74c9147":"code","4f777fbe":"code","cd046fed":"code","f6e687a7":"code","3d3df95f":"code","74f69891":"markdown","90b61c21":"markdown","9fe6f67e":"markdown","9a09982e":"markdown","d56e5974":"markdown","6c178904":"markdown"},"source":{"7edc8f9c":"import numpy as np\nimport pandas as pd\nimport os\nimport sqlite3\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVR\nfrom numpy.random import choice\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set(style=\"whitegrid\")\n","8a51b090":"class ImpNaNs:\n    def __init__(self,path,tb):\n        self.path = path\n        self.tb = tb\n    def Read_data(self):\n    \n        \"\"\"REDING THE DATA FROM SQLITE\"\"\"\n        \n        self.conn = sqlite3.connect(self.path)\n        self.q = f'SELECT * FROM {self.tb}'\n        self.df = pd.read_sql(self.q,self.conn)\n        return self.df\n    \n    \"\"\"MAKING MISSING VALUES FOR THE GIVEN COLUMN AND % OF NaNs\"\"\"\n    \n    def Random_nan(self,mcol,r=0.5):\n        self.col = mcol\n        self.m = ['nan']*int(r*self.df.shape[0])\n        self.new_x = self.df[self.col][:]\n        for idx,value in zip(choice(range(len(self.df)),size=len( self.m),replace=False), self.m):\n            self.new_x[idx] = value\n            self.df[self.col] = self.new_x\n        return self.df\n        \"\"\"PREPARING THE DATA AND PREDICTING NaNS\"\"\"\n    def Predict_NaN(self,miss_df,clf):\n        self.miss_df = miss_df\n        self.dfnan = self.miss_df[self.miss_df.isnull().any(1)]\n        self.dfnan = self.dfnan.drop(['Id','Species',self.col],axis=1)\n        self.new_df = self.miss_df.dropna()\n        self.y = self.new_df.pop(self.col)\n        self.X = self.new_df.drop(['Id','Species'],axis=1)\n         \n        if clf == 'Kmeans':\n            self.clf = KMeans(n_clusters=3, random_state=1)\n            self.clf.fit(self.X)\n            self.p = self.clf.predict(self.dfnan)\n        elif clf == 'SVM':\n            self.clf = LinearSVR(max_iter=300)\n            self.clf.fit(self.X,self.y)\n            self.p = self.clf.predict(self.dfnan)\n        self.dfnan[self.col] = list(self.p)\n        for i in self.dfnan.index:\n            for j in self.miss_df.index:\n                if i == j:\n                    self.miss_df[self.col][j] = self.dfnan[self.col][i]\n                        \n\n                    \n        return self.miss_df\n            \n            ","c07b1ecd":"path = '\/kaggle\/input\/iris\/database.sqlite'\ndata = ImpNaNs(path,'Iris')\nd = data.Read_data()\norige = d.copy()","d74c9147":"df = data.Random_nan(mcol='PetalWidthCm',r=0.1)\ndf.isna().sum()","4f777fbe":"dkmns = data.Predict_NaN(clf='Kmeans',miss_df=df)","cd046fed":"fig ,axs = plt.subplots(1,2,figsize=(12,4),sharex=True)\n\nsns.scatterplot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", hue = 'Species',\n                     data=dkmns,ax = axs[0]).set_title('K-MEAN')\nsns.scatterplot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", hue = 'Species',\n                     data=orige,ax = axs[1]).set_title('ORIGINAL DATA')\nplt.show() ","f6e687a7":"data = ImpNaNs(path,'Iris')\nd = data.Read_data()\norige = d.copy()\ndf = data.Random_nan(mcol='PetalWidthCm',r=0.1)\ndsvm = data.Predict_NaN(clf='SVM',miss_df=df)","3d3df95f":"fig ,axs = plt.subplots(1,2,figsize=(12,4),sharex=True)\n\nsns.scatterplot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", hue = 'Species',\n                     data=dsvm,ax = axs[0]).set_title('SVM')\nsns.scatterplot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", hue = 'Species',\n                     data=orige,ax = axs[1]).set_title('ORIGINAL DATA')\nplt.show()  ","74f69891":"<h5>2-Read the data from database.sqlite.<\/5>","90b61c21":"There are 15 missing values\n<h5>4- Predict NaNs using KMeans.<\/h5>","9fe6f67e":"We see 4 values badly predicted with K-Means.\n<h5>5. Finally Predict NaNs using SVM.<\/5>","9a09982e":"# How to perfectly impute missing values \n    In this kernal we will see how to perfectly impute NaNs by coumparing between unsupervised Machine Learing (K-Means) and supervised one (Sepport Vector Machine). And we are going to follow the steps below:\n    \n    1- Import required libraries.\n    \n    2- Read the data from database.sqlite.\n    \n    3- Make 10% of the target column NaNs.\n    \n    4- Predict NaNs using KMeans.\n    \n    5. Finally Predict NaNs using SVM\n So let's get it srated !!!!\n \n <h5> 1-Import required libraries.<\/5>.","d56e5974":"<h4>Great!!! Sepport Vector Machine predicted almost perfectly NaNs as we can see. So, what do you think of this technique? <\/h4> ","6c178904":"<h5>3- Make 10% of PetalWidthCm column NaNs<\/h5>"}}