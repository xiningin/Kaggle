{"cell_type":{"48caeee0":"code","ce83a1e0":"code","40c4ad75":"code","c057b1a7":"code","6f70133d":"code","fd4aecf6":"code","06b4cbe7":"code","7c1f5932":"code","4e329b86":"code","c7d75c85":"code","8b277152":"code","05425841":"code","1ff45a56":"code","4f993071":"code","77c2414d":"code","32811121":"code","915c3f51":"code","a193acdb":"code","9b325da5":"code","b3879b26":"code","ebb961cf":"code","90928cbc":"code","e38c890d":"code","25b3df5e":"code","e9d40df3":"code","33d2532a":"code","f1d772a3":"code","120ce8a7":"code","5f8ee93b":"code","8c583b90":"code","4acbfde8":"code","6d2e1fa8":"code","ec146fc9":"code","c959268e":"code","8cc07f5b":"code","33c7b381":"code","de77ba6d":"code","e4357d89":"code","9834b8db":"code","80a0113e":"code","64211595":"code","88d647ac":"code","bddc0fa9":"code","930ad620":"code","5486c7fe":"code","99f58c74":"code","bbfc933a":"code","7b0823ab":"code","b6bd8b8d":"code","c849d90d":"code","b11c6bb4":"code","80260f7a":"code","b0827f8c":"code","af4e950b":"code","80eb293f":"code","896d6d84":"code","91417546":"code","81c3d491":"code","3f0f1c72":"code","fc1b2fd2":"code","d5ce4cc3":"code","25e380cc":"code","06e14eb3":"code","63e8ec14":"code","95eb6ce3":"code","49076325":"code","09cf22b7":"code","bc009f48":"code","4a947ae0":"code","84916a62":"code","6971337f":"code","d9cd836a":"code","03341de9":"code","f2df8556":"code","2ebc4b7f":"code","0447cd86":"code","074b9668":"code","ab386b0a":"code","713996f9":"code","2e8bf3a3":"code","68b77141":"code","34caa214":"code","7f5cc0f9":"code","5c40f144":"code","76ab3100":"code","5f4c68d0":"code","9e87fd3b":"code","024d19e2":"code","021c3bfc":"code","b133ed8d":"code","75c44c02":"code","97b419b1":"code","da2a982e":"code","7e99cf44":"code","f0d46311":"code","cfcb2017":"code","4331317b":"code","d4dfebd1":"code","16789c35":"code","209a9d1f":"code","5bd9c3af":"code","76d6d7e5":"code","48c49712":"code","3cd01df5":"code","a4938367":"markdown","30515175":"markdown","14c08eb6":"markdown","152e4d7d":"markdown","cb545b3b":"markdown","ea402f43":"markdown","427179a4":"markdown","e626a438":"markdown","692f411b":"markdown","f1010f8b":"markdown","16721580":"markdown","959418dc":"markdown","fe3a4c4f":"markdown","55a5fb75":"markdown","4a1ddb6b":"markdown","97c2a897":"markdown","a97f5851":"markdown","10859ca9":"markdown","a9902ad7":"markdown","7357e9df":"markdown","215f6a33":"markdown","efee8ad4":"markdown","206f689d":"markdown","5b6fcbf7":"markdown","bb97715c":"markdown","881d5f44":"markdown","787d3b9f":"markdown","ea77bd30":"markdown","ce4d322c":"markdown","6015c9d2":"markdown","ed8308d6":"markdown","79177513":"markdown","5aa6610f":"markdown","ee0461c3":"markdown","0dea5a3e":"markdown","172334ce":"markdown"},"source":{"48caeee0":"from typing import List, Union, Dict, Optional, Tuple\nfrom datetime import datetime\nfrom os.path import join as pjoin\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport pandas_profiling","ce83a1e0":"DATA_PATH = '..\/input\/lab56a-regression-problem'\nADDITIONAL_DATA_PATH = '..\/input\/flight-problem-additional-data'","40c4ad75":"train = pd.read_csv(pjoin(DATA_PATH, 'train.csv'))\ntest = pd.read_csv(pjoin(DATA_PATH, 'test.csv'))","c057b1a7":"renamings = {\n    '\u0414\u0430\u0442\u0430 \u0440\u0435\u0439\u0441\u0430': 'date',\n    '\u0420\u0435\u0439\u0441': 'flight',\n    '\u0410\/\u041f \u043e\u0442\u043f\u0440\u0430\u0432\u043b': 'from',\n    '\u0410\/\u041f \u043f\u0440\u0438\u0431\u044b\u0442': 'to',\n    '\u041d\u043e\u043c\u0435\u0440 \u0412\u0421': 'aircraft',\n    '\u0412\u0440\u0435\u043c\u044f \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043f\u043e \u0440\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u044e': 'departure_scheduled',\n    '\u0412\u0440\u0435\u043c\u044f \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435': 'departure_actual',\n    '\u0412\u0440\u0435\u043c\u044f \u043f\u0440\u0438\u0431\u044b\u0442\u0438\u044f \u043f\u043e \u0440\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u044e': 'arrival_scheduled',\n    '\u0412\u0440\u0435\u043c\u044f \u043f\u0440\u0438\u0431\u044b\u0442\u0438\u044f \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435': 'arrival_actual',\n    '1 \u041a\u0417 \u041a\u043e\u0434': 'delay_code',\n    '\u0417\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0432 \u043c\u0438\u043d\u0443\u0442\u0430\u0445': 'delay',\n}\n\ntrain.rename(columns=renamings, inplace=True)\ntest.rename(columns=renamings, inplace=True)","6f70133d":"dtypes = {\n    'flight': str,\n    'aircraft': str,\n    'date': 'datetime64[ns]',\n    'departure_scheduled': 'datetime64[ns]',\n    'arrival_scheduled': 'datetime64[ns]',\n}\ntest = test.astype(dtypes)\n\ndtypes.update({\n    'departure_actual': 'datetime64[ns]',\n    'arrival_actual': 'datetime64[ns]',\n})\ntrain = train.astype(dtypes)\n","fd4aecf6":"train.shape, test.shape","06b4cbe7":"train.info()","7c1f5932":"test.info()","4e329b86":"train.head()","c7d75c85":"test.head()","8b277152":"train.describe()","05425841":"train.describe(include='object')","1ff45a56":"test.describe(include='object')","4f993071":"train.describe(include='datetime')","77c2414d":"test.describe(include='datetime')","32811121":"def get_df_memory_usage_in_mb(df):\n    return df.memory_usage(index=True, deep=True).sum() \/\/ 2**20\n\ndef get_csr_memory_usage_in_mb(csr):\n    return (csr.data.nbytes + csr.indptr.nbytes + csr.indices.nbytes) \/\/ 2**20","915c3f51":"def get_cat_features(X: pd.DataFrame) -> List[str]:\n    return X.columns[X.dtypes == 'O'].tolist()","a193acdb":"def label_distplots(values, labels, kde=True, hist=True, bins=None):\n    for label in labels.unique():\n        sns.distplot(values[labels == label], kde=kde, hist=hist, label=f'Label = {label}', norm_hist=True, bins=bins)\n    plt.legend();\n    \ndef crosstab_by_mask(df: pd.DataFrame, y: pd.Series, feature: str, mask):\n    subset = df[mask]\n    subset_y = y[mask]\n    return pd.crosstab(subset[feature], y)","9b325da5":"def get_figsize():\n    return plt.rcParams['figure.figsize'].copy()\n\n\ndef set_figsize(width, height):\n    plt.rcParams['figure.figsize'] = width, height\n\n    \nclass PltResizer:\n    def __init__(self, new_size: tuple):\n        self._new_size = new_size\n        self._old_size = None\n        \n    def __enter__(self):\n        self._old_size = get_figsize()\n        set_figsize(*self._new_size)\n        \n    def __exit__(self, *args):\n        set_figsize(*self._old_size)\n        \n        \ndef change_figsize(width, height) -> PltResizer:\n    return PltResizer((width, height))","b3879b26":"y = train['delay']\nsns.distplot(y)","ebb961cf":"sns.distplot(y[(y > 0) & (y < 50)], kde=False, bins=49)","90928cbc":"mins_in_day = 60 * 24\ny.max(), mins_in_day  # \"delay\" always less than one day","e38c890d":"y.quantile(0.999)","25b3df5e":"real_delay = (train['departure_actual'] - train['departure_scheduled']).dt.total_seconds() \/\/ 60\nprint(real_delay.max())\nincorrect_delays = train[real_delay > train['delay']]\nprint(incorrect_delays.shape)\nincorrect_delays.head()","e9d40df3":"# drop such rows\ntrain = train[real_delay <= train['delay']]\ntrain.shape","33d2532a":"y = train['delay']","f1d772a3":"y_binned = y.copy()\ny_binned[y == 0] = 'zero'\ny_binned[y > 0] = 'small'\ny_binned[y > 10] = 'medium'\ny_binned[y > 60] = 'big'","120ce8a7":"y_binned.value_counts()","5f8ee93b":"full = pd.concat([train, test], sort=False)","8c583b90":"full.shape","4acbfde8":"get_df_memory_usage_in_mb(train), get_df_memory_usage_in_mb(test)","6d2e1fa8":"counts = full['from'].value_counts()\ncounts","ec146fc9":"counts = full['to'].value_counts()\ncounts","c959268e":"no_svo = full.loc[(full['from'] != 'SVO') & (full['to'] != 'SVO')]\nprint(no_svo.shape)\nno_svo.head()","8cc07f5b":"year = (full['date'] - datetime(2000, 1, 1)).dt.days \/ 365 + 2000\nsns.distplot(year)","33c7b381":"train['date'].min(), train['date'].max()","de77ba6d":"test['date'].min(), test['date'].max()","e4357d89":"with change_figsize(12, 6):\n    year = (train['date'] - datetime(2000, 1, 1)).dt.days \/ 365 + 2000\n    label_distplots(year, y_binned, kde=True, hist=True, bins=80)","9834b8db":"counts = train['aircraft'].value_counts()","80a0113e":"counts","64211595":"plt.bar(counts.index, counts.values)","88d647ac":"with change_figsize(12, 5):\n    mask = train['aircraft'].isin(counts[:30].index)\n    crosstab_by_mask(train, y_binned, 'aircraft', mask).plot(kind='bar')","bddc0fa9":"with change_figsize(12, 5):\n    mask = train['aircraft'].isin(counts[-30:].index)\n    crosstab_by_mask(train, y_binned, 'aircraft', mask).plot(kind='bar')","930ad620":"with change_figsize(12, 5):\n    mask = train['aircraft'].isin(train.sample(n=30, random_state=2)['aircraft'].values)\n    crosstab_by_mask(train, y_binned, 'aircraft', mask).plot(kind='bar')","5486c7fe":"counts = train['flight'].value_counts()\ncounts","99f58c74":"plt.bar(counts.index, counts.values)","bbfc933a":"with change_figsize(12, 5):\n    mask = train['flight'].isin(counts[:30].index)\n    crosstab_by_mask(train, y_binned, 'flight', mask).plot(kind='bar')","7b0823ab":"train['delay_code'].isnull().sum() \/ len(train)","b6bd8b8d":"counts = train['delay_code'].value_counts()","c849d90d":"counts.to_frame().iloc[:30, :].plot(kind='bar')","b11c6bb4":"with change_figsize(12, 5):\n    mask = train['delay_code'].isin(counts[:30].index)\n    crosstab_by_mask(train, y_binned, 'delay_code', mask).plot(kind='bar')","80260f7a":"delay_code_agg = train.groupby('delay_code')['delay'].agg(['mean', 'max', 'count'])","b0827f8c":"delay_code_agg.sort_values('max', ascending=False).head(10)","af4e950b":"delay_code_agg.sort_values('count', ascending=False).head(10)","80eb293f":"flight_time = (full['arrival_scheduled'] - full['departure_scheduled']).dt.total_seconds() \/ 3600\nsns.distplot(flight_time, kde=False)","896d6d84":"with change_figsize(12, 5):\n    flight_time = (train['arrival_scheduled'] - train['departure_scheduled']).dt.total_seconds() \/ 3600\n    label_distplots(flight_time, y_binned, hist=False)","91417546":"from scipy  import sparse\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, SCORERS, make_scorer\n\n\nfrom sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, VotingRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\nimport shap\nshap.initjs()","81c3d491":"def label_encode(\n    X: pd.DataFrame, \n    encoders: Optional[Dict[str, LabelEncoder]] = None,\n    fit_only: bool = False,\n) -> Tuple[pd.DataFrame, Dict[str, LabelEncoder]]:\n\n    X = X.copy()\n    encoders = encoders or {}\n    for col in get_cat_features(X):\n        if col not in encoders:\n            encoder = LabelEncoder().fit(X[col])\n            encoders[col] = encoder\n        else:\n            encoder = encoders[col]\n        if not fit_only:\n            X[col] = encoder.transform(X[col])\n    return X, encoders\n\n\ndef one_hot_encode(\n    X: pd.DataFrame, \n    encoders: Optional[Dict[str, OneHotEncoder]] = None,\n    fit_only: bool = False,\n) -> Tuple[sparse.csr_matrix, Dict[str, OneHotEncoder], List['str']]:\n    cat_features = get_cat_features(X)\n    feature_matrices = []\n    encoders = encoders or {}\n    columns = []\n    for col in X.columns:\n        if col in cat_features:\n            if col not in encoders:\n                encoder = OneHotEncoder().fit(X[[col]])\n                encoders[col] = encoder\n            else:\n                encoder = encoders[col]\n            if not fit_only:\n                feature_matrix = encoder.transform(X[[col]])\n            columns += [f'{col}::{val}' for val in encoder.categories_[0]]\n        else:\n            if not fit_only:\n                feature_matrix = sparse.csr_matrix((\n                    X[col].values, \n                    (\n                        np.arange(X.shape[0], dtype=int), \n                        np.zeros(X.shape[0], dtype=int),\n                    ),\n                ))\n            columns.append(col)\n        if not fit_only:\n            feature_matrices.append(feature_matrix)\n    if not fit_only:\n        features = sparse.hstack(feature_matrices, format='csr')\n    else:\n        features = X.copy()\n    return features, encoders, columns\n\n\n# def scale(\n#     X: sparse.csr_matrix, \n#     scaler: Optional[StandardScaler] = None,\n# ) -> Tuple[np.ndarray, StandardScaler]:\n#     scaler = scaler or StandardScaler()\n#     X_scaled = scaler.fit_transform(X.toarray())\n#     return X_scaled, scaler","3f0f1c72":"def calc_metrics(\n    y_true: Union[np.ndarray, pd.Series], \n    pred: Union[np.ndarray, pd.Series], \n) -> Dict[str, float]:\n    res = {}\n    res['mse'] = mean_squared_error(y_true, pred)\n    res['mae'] = mean_absolute_error(y_true, pred)\n    res['rmse'] = np.sqrt(mean_squared_error(y_true, pred))\n    return res\n\n\ndef get_feature_importances(est, columns):\n    return pd.DataFrame({\n        'column': columns,\n        'importance': est.feature_importances_,\n    }).sort_values('importance', ascending=False)\n\n\ndef get_feature_coefficients(est, columns, sort_by_abs=True):\n    coeffs = pd.DataFrame({\n        'column': columns,\n        'coef': est.coef_,\n    })\n    coeffs['coef_abs'] = coeffs['coef'].abs()\n    if sort_by_abs:\n        sort_column = 'coef_abs'\n    else:\n        sort_column = 'coef'\n    return coeffs.sort_values(sort_column, ascending=False)\n\n\ndef represent_cv_results(gscv):\n    cv_results = pd.DataFrame(gscv.cv_results_)\n    res = cv_results[['params', 'mean_fit_time', 'mean_train_score', 'mean_test_score']] \\\n        .sort_values('mean_test_score', ascending=False)\n    return res","fc1b2fd2":"def cut_not_popular_inplace(X, feature, n=None, frac=None, min_counts=None, default_value=''):       \n    counts = X[feature].value_counts()\n    if n is not None:\n        valid_values = counts[:n].index\n    elif frac is not None:\n        n = int(frac * len(counts))\n        valid_values = counts[:n].index\n    elif min_counts is not None:\n        valid_values = counts[counts.values >= min_counts].index\n    else:\n        raise ValueError()\n    X.loc[~X[feature].isin(valid_values), feature] = default_value","d5ce4cc3":"MIN_DATE = full['date'].min()\nMIN_DATE","25e380cc":"def add_datetime_features(X):\n    X = X.copy()\n    \n    X['days_from_min'] = (X['date'] - MIN_DATE).dt.days\n    \n    X['year'] = X['date'].dt.year\n    X['month'] = X['date'].dt.month\n    X['day'] = X['date'].dt.day\n    X['dayofweek'] = X['date'].dt.dayofweek\n    X['dayofyear'] = X['date'].dt.dayofyear\n    X['hour'] = X['departure_scheduled'].dt.hour\n    X['minute'] = X['departure_scheduled'].dt.minute\n    \n    return X\n\n\ndef add_holiday_feature(X):\n    X = X.copy()\n    \n    holidays = pd.read_csv(pjoin(ADDITIONAL_DATA_PATH, 'holidays.csv'))\n    \n    all_dates = pd.date_range('2016-01-01', '2016-12-31', freq='D')\n    all_dates = pd.DataFrame({\n        'month': all_dates.month, \n        'day': all_dates.day,\n        'is_holiday': 1,\n    })\n    \n    all_dates_holiday = pd.merge(\n        all_dates,\n        holidays,\n        on=['month', 'day'],\n        how='left',\n    )\n    all_dates_holiday['is_holiday'] = all_dates_holiday['is_holiday'].fillna(0)\n\n    is_holiday = all_dates_holiday['is_holiday'].copy()\n    for shift in [-3, -2, -1, 1, 2, 3]:\n        all_dates_holiday['is_holiday'] += is_holiday.shift(shift, fill_value=0) \/ abs(shift)\n    all_dates_holiday.iloc[-3:, -1] += np.array([1\/3, 1\/2, 1])  # simple hack\n    \n    X = pd.merge(\n        X,\n        all_dates_holiday,\n        on=['month', 'day'],\n    )\n    \n    return X\n\n    \ndef add_places(X):\n    codes = pd.read_csv(pjoin(ADDITIONAL_DATA_PATH, 'airport_codes.csv'))\n    codes.drop(columns=['city'], inplace=True)\n    X = pd.merge(\n        X,\n        codes,\n        left_on='from',\n        right_on='code',\n        how='left',\n    )\n    X = pd.merge(\n        X,\n        codes,\n        left_on='to',\n        right_on='code',\n        how='left',\n        suffixes=('_from', '_to')\n    )\n    X.drop(columns=['code_from', 'code_to', 'airport_from', 'airport_to'], inplace=True)\n    \n    for col in ['country_from', 'country_to']:\n        X[col] = X[col].fillna('')\n    \n    return X\n\n    \ndef add_weather(X):\n    weather = pd.read_csv(pjoin(ADDITIONAL_DATA_PATH, 'forecast_cleared.csv'), parse_dates=['date_time'])\n    \n    weather = weather.reindex(\n        columns=[\n            'airport',\n            'date_time',\n            'temperature',\n            'relative_humidity',\n            'wind_speed',\n            'precipitation',\n            'visibility',\n            'snow_depth',\n        ]        \n    )\n    X = pd.merge(\n        X,\n        weather,\n        left_on=['from', 'date'],\n        right_on=['airport', 'date_time'],\n        how='left',\n    )\n    X.drop(columns=['airport', 'date_time'], inplace=True)\n    X = pd.merge(\n        X,\n        weather,\n        left_on=['to', 'date'],\n        right_on=['airport', 'date_time'],\n        how='left',\n        suffixes=('_from', '_to'),\n    )\n    X.drop(columns=['airport', 'date_time'], inplace=True)\n    \n    for col in X.columns:\n        if '_'.join(col.split('_')[:-1]) in weather.columns:\n            X[col] = X[col].fillna(X[col].mean())\n            \n    return X\n    \n    \ndef add_info_from_last_flight(X: pd.DataFrame):\n    X = X.sort_values(['aircraft', 'departure_scheduled'])\n    \n    last_flight_aircraft = X['aircraft'].shift(1)\n    is_same_aircraft = last_flight_aircraft == X['aircraft']\n    \n    last_flight_arrival = X['arrival_scheduled'].shift(1, fill_value=pd.to_datetime(X['arrival_scheduled'].iat[0]))\n    time_from_last_flight = (X['departure_scheduled'] - last_flight_arrival).dt.total_seconds() \/\/ 60\n    time_from_last_flight[~is_same_aircraft] = time_from_last_flight.mean()\n    X['time_from_last_flight'] = time_from_last_flight\n    \n    last_fligh_arrival_actual = X['arrival_actual'].shift(1, fill_value=pd.to_datetime(X['arrival_actual'].iat[0]))\n    last_flight_delay = (last_fligh_arrival_actual - last_flight_arrival).dt.total_seconds() \/\/ 60\n    last_flight_delay[~is_same_aircraft] = last_flight_delay.mean()\n    X['last_flight_delay'] = last_flight_delay.fillna(last_flight_delay.mean())\n    \n    return X\n    \n    \ndef add_time_from_prev_svo_event(X: pd.DataFrame):\n    X = X.copy()\n    \n    departure_from_svo = X.loc[X['from'] == 'SVO', 'departure_scheduled'].values\n    arrival_to_svo = X.loc[X['to'] == 'SVO', 'arrival_scheduled'].values\n    all_svo_events = np.concatenate((departure_from_svo, arrival_to_svo))\n    all_svo_events.sort()\n    \n    from_svo_mask = X['from'] == 'SVO'\n    \n    current_time_idx = np.searchsorted(\n        all_svo_events, \n        X.loc[from_svo_mask, 'departure_scheduled'].values, \n        side='left',\n    )\n    prev_time_idx = np.maximum(current_time_idx - 1, 0)\n    prev_time = all_svo_events[prev_time_idx]\n    \n    X['time_from_prev_svo_event'] = -1\n    X.loc[from_svo_mask, 'time_from_prev_svo_event'] = (\n        X.loc[from_svo_mask, 'departure_scheduled'] - \n        prev_time\n    ).dt.total_seconds() \/\/ 60\n    \n    return X\n\n\ndef add_cat_features_statistics(X):\n    X = X.copy()\n    \n    cat_features = ['from', 'to', 'aircraft', 'flight']\n    \n    for feature in cat_features:\n        for agg_fun in ['mean']:\n            agg_values = X.groupby(by=feature)['delay'].transform(agg_fun)\n            X[f'{feature}_{agg_fun}_delay'] = agg_values.fillna(agg_values.mean())\n        \n    return X\n    \n    \ndef extract_features(df: pd.DataFrame):\n    X = df.copy()\n\n    X = add_datetime_features(X)\n\n    X = add_holiday_feature(X)\n\n    X['flight_time'] = (X['arrival_scheduled'] - X['departure_scheduled']).dt.total_seconds() \/\/ 3600\n\n    X = add_places(X)\n    X['is_domestic'] = (X['country_from'] == X['country_to']).astype(int)\n    X.drop(columns=['country_from', 'country_to'], inplace=True)\n     \n    X = add_weather(X)\n\n    X = add_info_from_last_flight(X)\n    X['is_time_from_last_flight_less_than_30'] = (X['time_from_last_flight'] < 30).astype(int)\n    X['is_time_from_last_flight_less_than_60'] = (X['time_from_last_flight'] < 60).astype(int)\n    X['is_time_from_last_flight_less_than_90'] = (X['time_from_last_flight'] < 90).astype(int)\n    X['time_from_last_flight_actual'] = X['time_from_last_flight'] - X['last_flight_delay']\n    X.drop(columns=['time_from_last_flight'], inplace=True)\n    \n    X = add_time_from_prev_svo_event(X)\n    \n    cut_not_popular_inplace(X, 'flight', min_counts=30)\n    cut_not_popular_inplace(X, 'aircraft', min_counts=100)\n    cut_not_popular_inplace(X, 'from', min_counts=20)\n    cut_not_popular_inplace(X, 'to', min_counts=20)\n    X = add_cat_features_statistics(X)\n    X.drop(columns=['aircraft', 'from', 'to', 'flight'], inplace=True)\n    \n\n    X.drop(columns=['date', 'departure_scheduled', 'arrival_scheduled'], inplace=True)\n    X.drop(columns=['departure_actual', 'arrival_actual', 'delay_code'], inplace=True)\n    \n    return X","06e14eb3":"%%time\nfull_features = extract_features(full)\nprint(full_features.shape)","63e8ec14":"get_df_memory_usage_in_mb(full_features)","95eb6ce3":"get_cat_features(full_features)","49076325":"%%time\nis_train = full_features['delay'].notnull()\n\nX_train = full_features.loc[is_train]\ny_train = X_train['delay']\nX_train.drop(columns=['id', 'delay'], inplace=True)\n\nX_test = full_features.loc[~is_train]\nX_test_id = X_test['id']\nX_test.drop(columns=['id', 'delay'], inplace=True)\n\nprint('Size: ', get_df_memory_usage_in_mb(X_train) + get_df_memory_usage_in_mb(X_test))","09cf22b7":"%%time\n_, label_encoders = label_encode(full_features, fit_only=True)\nX_train_le, _ = label_encode(X_train, label_encoders)\nX_test_le, _ = label_encode(X_test, label_encoders)\nprint('Size: ', get_df_memory_usage_in_mb(X_train_le) + get_df_memory_usage_in_mb(X_test_le))","bc009f48":"%%time\n_, one_hot_encoders, _ = one_hot_encode(full_features, fit_only=True)\nX_train_ohe, _, ohe_columns = one_hot_encode(X_train, one_hot_encoders)\nX_test_ohe, _, _ = one_hot_encode(X_test, one_hot_encoders)\nprint('Train shape: ', X_train_ohe.shape)\nprint('Test shape: ', X_test_ohe.shape)\nprint('Size: ', get_csr_memory_usage_in_mb(X_train_ohe) + get_csr_memory_usage_in_mb(X_test_ohe))","4a947ae0":"def rmse_score(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef custom_score(y, y_pred):\n    y_pred = y_pred.copy()\n    y_pred[y_pred < 0] = 0\n    return rmse_score(y, y_pred)\n\ncustom_scorer = make_scorer(custom_score, greater_is_better=False)","84916a62":"lr = LinearRegression()\ngscv_lr = GridSearchCV(\n    estimator=lr,\n    param_grid={'normalize': [True, False]},\n    scoring=custom_scorer,\n    n_jobs=2,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_lr.fit(X_train_ohe, y_train);","6971337f":"represent_cv_results(gscv_lr)","d9cd836a":"rg = Ridge(random_state=1, max_iter=200)\ngscv_rg = GridSearchCV(\n    estimator=rg,\n    param_grid={'alpha': [1]},\n    scoring=custom_scorer,\n    n_jobs=2,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_rg.fit(X_train_ohe, y_train);","03341de9":"represent_cv_results(gscv_rg)","f2df8556":"rg_reg = gscv_rg.best_estimator_","2ebc4b7f":"get_feature_coefficients(rg_reg, ohe_columns).head(20)","0447cd86":"dt = DecisionTreeRegressor(\n    max_leaf_nodes=100, \n    random_state=1,\n    max_features=None,\n    min_impurity_decrease=0.01\n)\ngscv_dt = GridSearchCV(\n    estimator=dt,\n    param_grid={'max_depth': [7], 'min_samples_leaf': [500], 'min_samples_split': [500]},\n    scoring=custom_scorer,\n    n_jobs=2,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_dt.fit(X_train_le, y_train);","074b9668":"represent_cv_results(gscv_dt)","ab386b0a":"dt_reg = gscv_dt.best_estimator_","713996f9":"get_feature_importances(dt_reg, X_train_le.columns)","2e8bf3a3":"tree = dt_reg.tree_\nthr = pd.DataFrame({'feat': tree.feature, 'thr': tree.threshold})\nthr.query('feat != -2', inplace=True)\nthr.insert(1, 'col', X_train_le.columns[thr['feat']])\nthr","68b77141":"cb = CatBoostRegressor(\n    cat_features=get_cat_features(X_train),\n    eval_metric='RMSE',\n    random_seed=2,\n    nan_mode='Forbidden',\n    task_type='CPU',\n    verbose=False,\n)\n\n\ngscv_cb = GridSearchCV(\n    estimator=cb,\n    param_grid={\n        'n_estimators': [50, 100], \n        'max_depth': [3, 4, 5],\n        \n    },\n    scoring=custom_scorer,\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n\n)\n\ngscv_cb.fit(X_train_le, y_train);","34caa214":"represent_cv_results(gscv_cb)","7f5cc0f9":"cb_reg = gscv_cb.best_estimator_\nget_feature_importances(cb_reg, X_train_le.columns)","5c40f144":"pred_test = cb_reg.predict(X_test_le)\nres = pd.DataFrame({\n    'id': X_test_id.astype(int),\n    '\u0417\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0432 \u043c\u0438\u043d\u0443\u0442\u0430\u0445': pred_test,\n}).sort_values('id')\nres.to_csv('res_catboost_5_100.csv', index=False)","76ab3100":"pred = cb_reg.predict(X_train_le)","5f4c68d0":"custom_score(y_train, pred)","9e87fd3b":"pd.set_option('display.max_columns', 100)","024d19e2":"compare = pd.DataFrame({'true': y_train, 'pred': pred, 'diff': y_train - pred})\ncompare.head()","021c3bfc":"sns.distplot(compare['diff'], kde=False)","b133ed8d":"bad_pred = compare[compare['diff'].abs() > 200]\nbad_pred.shape","75c44c02":"bad_pred.head()","97b419b1":"i = 308886\nrow = X_train.loc[i:i, :]\nrow","da2a982e":"train[train['departure_scheduled'] == datetime(row['year'], row['month'], row['day'], row['hour'], row['minute'])]","7e99cf44":"sample = X_train_le.sample(n=20000)\n\ncb_explainer = shap.TreeExplainer(cb_reg)\ncb_shap_values = cb_explainer.shap_values(sample)","f0d46311":"# See feature impacts\n\nshap.summary_plot(cb_shap_values, sample)","cfcb2017":"# See mean feature importances\n\nshap.summary_plot(cb_shap_values, sample, plot_type=\"bar\")","4331317b":"rf = LGBMRegressor(\n    boosting='rf',\n    num_leaves=50,\n    learning_rate=0.1,\n    random_state=1,\n    n_jobs=-3,\n    metric=\"rmse\",\n    bagging_freq=1,\n    bagging_fraction=0.5,\n)\ngscv_rf = GridSearchCV(\n    estimator=rf,\n    param_grid={'max_depth': [6], 'n_estimators': [500]},\n    scoring=custom_scorer,\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\n\ngscv_rf.fit(X_train_le, y_train);","d4dfebd1":"represent_cv_results(gscv_rf)","16789c35":"rf_reg = gscv_rf.best_estimator_","209a9d1f":"get_feature_importances(rf_reg, X_train_le.columns)","5bd9c3af":"pred_test = rf_reg.predict(X_test_le)\nres = pd.DataFrame({\n    'id': X_test_id.astype(int),\n    '\u0417\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0432 \u043c\u0438\u043d\u0443\u0442\u0430\u0445': pred_test,\n}).sort_values('id')\nres.to_csv('res_lgbm_rf_6_500.csv', index=False)","76d6d7e5":"sample = X_train_le.sample(n=20000)\nrf_explainer = shap.TreeExplainer(rf_reg)\nrf_shap_values = rf_explainer.shap_values(sample)","48c49712":"shap.summary_plot(rf_shap_values, sample)","3cd01df5":"shap.summary_plot(rf_shap_values, sample, plot_type='bar')","a4938367":"### Bin target","30515175":"## Explore features distribution","14c08eb6":"### Aircrafts","152e4d7d":"### Ridge","cb545b3b":"### Airports","ea402f43":"### Gradient boosting","427179a4":"## Extract features","e626a438":"#### Explain features","692f411b":"# Prepare airport codes\ncodes = pd.read_csv(pjoin(DATA_PATH, 'aiport_codes.txt'), header=None, names=['name', 'country', 'city'])\nr = codes['name'].str.split('\u2014', 1, expand=True)\ncodes.insert(0, 'airport', r[1])\ncodes.insert(0, 'code', r[0])\ncodes.drop(columns='name', inplace=True)\nfor col in codes.columns:\n    codes[col] = codes[col].str.strip()\ncodes.to_csv(pjoin(DATA_PATH, 'airport_codes.csv'), index=False)","f1010f8b":"### Some helpful functions","16721580":"### Some helpful functions","959418dc":"# Prepare additional data","fe3a4c4f":"# drop rows with very big delay (outliers)\ntrain = train.loc[train['delay'] <= y.quantile(0.999)]\ntrain.shape","55a5fb75":"### Flights","4a1ddb6b":"## Make scorer","97c2a897":"# Prepare forecast\nforecast = pd.read_csv(pjoin(DATA_PATH, 'forcast_full_data.csv'))\nprint(forecast.shape)\nfc = forecast.drop(columns=[\n    'Unnamed: 0',\n    'Address',\n    'Minimum Temperature',\n    'Maximum Temperature',\n    'Resolved Address',\n    'Address.1',\n    'Name',\n    'Info',\n    'The geographic location of UAE Dubai could not be found',\n    'The geographic location of Kazakhstan Kzyl-Orda could not be found',\n    'Heat Index',\n    'Weather Type',\n    'Latitude',\n    'Longitude',\n])\n\nfor col in ['Wind Gust', 'Snow Depth']:\n    fc[col] = fc[col].fillna(0)\n    \nfor col in fc.columns[fc.dtypes != 'object']:\n    fc[col] = fc[col].fillna(fc[col].mean())\n    \nfc['Date time'] = fc['Date time'].str.split(expand=True)[0]\nfc['Date time'] = pd.to_datetime(fc['Date time'], format='%m\/%d\/%Y')\n\nfc.rename(columns={'code': 'airport'}, inplace=True)\nfc.rename(columns={col: col.lower().replace(' ', '_') for col in fc.columns}, inplace=True)\nfc.drop_duplicates(['date_time', 'airport'], inplace=True)\nprint(fc.shape)\n\nfc.to_csv(pjoin(DATA_PATH, 'forecast_cleared.csv'), index=False)","a97f5851":"### Delay codes","10859ca9":"#### Get model explanation by shap","a9902ad7":"### Incorrect delays","7357e9df":"# Explore data","215f6a33":"### Linear regression","efee8ad4":"#### Prepare features","206f689d":"### Flight time","5b6fcbf7":"## Try different models","bb97715c":"## Make full dataset","881d5f44":"### Random forest","787d3b9f":"pandas_profiling.ProfileReport(train.sample(n=10000))","ea77bd30":"# If actual time is given\ndef get_delay(df):\n    time_diff = (df['departure_actual'] - df['departure_scheduled'])\n    diff_mins = time_diff.dt.total_seconds() \/\/ 60\n    diff_days = time_diff.dt.total_seconds() \/\/ (60 * 60 * 24)\n\n    diff_days[diff_days < 0] = 0\n    diff_mins -= diff_days * 24 * 60\n    diff_mins[diff_mins < 0] = 0\n\n    return diff_mins","ce4d322c":"# Get basic data info","6015c9d2":"### Distribution","ed8308d6":"#### Transform data","79177513":"## Target","5aa6610f":"### Dates","ee0461c3":"#### Represent results","0dea5a3e":"### Decision tree","172334ce":"# Build model"}}