{"cell_type":{"8dd547f8":"code","51e346ee":"code","26dba2d6":"code","c68d27b1":"code","2595bbd3":"code","47dc91f6":"code","1002245a":"code","f9a599ee":"code","ff2387fe":"code","d82df7fe":"code","5639764d":"code","e86387b4":"code","b82634da":"code","c23f3ffd":"code","c750621a":"code","f0689550":"code","db1bfc6b":"markdown","57644218":"markdown","69778f8e":"markdown","5e1fd8d3":"markdown","5e5751c8":"markdown","f71dedd5":"markdown","f6aeda67":"markdown","ff99a6f7":"markdown","6980b12e":"markdown","de2a59b7":"markdown","9cca2c03":"markdown"},"source":{"8dd547f8":"import os\nimport sys\nsys.path.append(os.path.abspath('..\/input\/efficientnet\/efficientnet-master\/efficientnet-master\/'))\n\nimport pandas as pd\nimport os.path\n\n# image directory path\n#..\/input\/aptos-train-dataset\/aptos-train-images\/aptos-train-images\/\n\n#original data : ..\/input\/aptos2019-blindness-detection\nTRAIN_DATA_PATH = \"..\/input\/aptos2019-blindness-detection\"\nTEST_DATA_PATH = \"..\/input\/aptos2019-blindness-detection\"\nPREPROCESSED_IMAGE_PATH = \".\/preprocessed\"\nMODEL_PATH = \".\/models\"\nMODEL_FILE_NAME = \"effnet_b3_single.h5\"\n\nTRAIN_CSV_FILE_PATH = os.path.join(TRAIN_DATA_PATH, \"train.csv\")\nTRAIN_IMAGE_FILE_PATH = \"..\/input\/aptos2019-blindness-detection\/train_images\"\n\nTEST_CSV_FILE_PATH = \"..\/input\/aptos2019-blindness-detection\/test.csv\"\nTEST_IMAGE_FILE_PATH = \"..\/input\/aptos2019-blindness-detection\/test_images\"\n\n\"\"\"\n\uc804\uccb4 \ucee4\ub110\uc774 \uc81c\ub300\ub85c \ub3cc\uc544\uae30\ub294\uc9c0 \ud655\uc778\ud560 \ub54c \uc0ac\uc6a9\ud55c\ub2e4.\nsubmission\uc774 \uc815\uc0c1\uc801\uc73c\ub85c \uc9c4\ud589\ub418\ub294\uc9c0\uae4c\uc9c0 \ud559\uc778\n\"\"\"\nCHECK_KERNEL_VALID = False\n\nIMG_WIDTH = 456\nIMG_HEIGHT = 456\nIMG_CHANNELS = 3\n\nBATCH_SIZE = 4\n\nNUM_FOLDS = 6\n\nEPOCHS = 30\nif CHECK_KERNEL_VALID:\n    EPOCHS = 1\n\nGENERATE_WEIGHTS = True # weight\ub97c \uc0c8\ub85c \uc0dd\uc131\ud55c\ub2e4.\n\nTRAIN_OVER_PRETRAINED = True # \uae30\uc874\uc758 weight\uc5d0 \ucd94\uac00 train\ud55c\ub2e4.\n\nRESCALE_DN = 128.0","51e346ee":"from pathlib import Path\nimport shutil\n\nif os.path.exists(MODEL_PATH) == False:\n    Path(MODEL_PATH).mkdir(parents=True, exist_ok=True)\n    \n\n# weight\ub97c \uc0dd\uc131\ud558\ub824\ub294 \ubaa9\uc801\uc774 \uc544\ub2c8\uba74 weight\ud30c\uc77c\uc744 \ubbf8\ub9ac \ubcf5\uc0ac\ud574 \ub454\ub2e4.\n\npre_models_path = \"..\/input\/aptos-data-files\"\n\npre_model_filepath = os.path.join(pre_models_path, \"effnet_b3_single.h5\")\n\nif os.path.exists(pre_models_path):\n    for fname in os.listdir(pre_models_path):\n        filepath = os.path.join(pre_models_path, fname)        \n        if os.path.isfile(filepath):\n            if GENERATE_WEIGHTS == True and TRAIN_OVER_PRETRAINED == False:\n                if fname.find(\"h5\") > 0:\n                    continue\n            destfilepath = os.path.join(MODEL_PATH, fname)\n            print(\"Copy File \", filepath, \" >>> \", destfilepath)\n            shutil.copy(filepath, destfilepath)","26dba2d6":"df_train = pd.read_csv(TRAIN_CSV_FILE_PATH)\ndf_train['id_code'] = df_train['id_code'] + \".png\"\ndf_test = pd.read_csv(TEST_CSV_FILE_PATH)\ndf_train.head()","c68d27b1":"df_test.head()","2595bbd3":"import cv2\n#from PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nn = 3\n\nfix, ax = plt.subplots(n, n, figsize = (16, 16))\naxidx = 0\n\ndf_sample = df_train.sample(n * n)\nfor idx, row in df_sample.iterrows():\n    imgpath = os.path.join(TRAIN_IMAGE_FILE_PATH, row['id_code'])\n    \n    im = cv2.imread(imgpath)\n    # Note : In the case of color images, the decoded images will have the channels stored in B G R order.\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # RGB\ub85c \ubc14\uafd4\uc8fc\uc9c0 \uc54a\uc73c\uba74 \uc774\ubbf8\uc9c0\uac00 \ud30c\ub797\uac8c \ub098\uc628\ub2e4.\n\n    ax[int(axidx \/ n)][axidx % n].imshow(im)\n    axidx += 1","47dc91f6":"import numpy as np\n\ndef crop_image_from_gray(img, tol=7):\n    \"\"\"\n    Applies masks to the orignal image and \n    returns the a preprocessed image with \n    3 channels\n    \n    (img > tolerance) \ub85c mask\ub97c \uc0dd\uc131\ud558\uace0 np.any()\ub97c \uc0ac\uc6a9\ud574\uc11c\n    merge\ub418\ub294 \uac12\ub4e4 \uc911 valid\ud55c \uac12\uc774 \uc788\ub294 \uc904\uc740 np.ix_()\ub85c \uace8\ub77c\ub0c4\n        -> False\uc778 \uc904\uc740 \ubaa8\ub450 \uc81c\uac70\ub428\n    \"\"\"\n    # If for some reason we only have two channels\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    # If we have a normal RGB images\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\ndef preprocess_image(image, sigmaX=10):\n    \"\"\"\n    The whole preprocessing pipeline:\n    1. Read in image\n    2. Apply masks\n    3. Resize image to desired size\n    4. Add Gaussian noise to increase Robustness\n    \"\"\"\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #RGB colorspace\ub85c g\ubcc0\uacbd\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n    # cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) \n    #image = cv2.addWeighted (image, 4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n    \n    '''\n    cv2.addWeighted() : Calculates the weighted sum of two arrays.\n    \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc5d0 \ube14\ub7ec\ucc98\ub9ac\ub41c \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc5d0 \uc74c\uc218 \uac00\uc911\uce58\ub97c \uc900 \uac83\uc744 \ub354\ud574\uc11c \uc724\uacfd\uc744 \uac15\uc870\n    (gamma\ub85c contrast\ub97c \uc90c)\n    '''\n    image = cv2.addWeighted (image, 4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, gamma=128)\n    return image","1002245a":"fix, ax = plt.subplots(n, n, figsize = (20, 20))\n\naxidx = 0    \nfor idx, row in df_sample.iterrows():\n    filename = row['id_code']\n    imgpath = os.path.join(TRAIN_IMAGE_FILE_PATH, filename)\n    im = preprocess_image(cv2.imread(imgpath))\n    ax[int(axidx \/ (n))][axidx % n].imshow(im)\n    ax[int(axidx \/ (n))][axidx % n].set_title(row['id_code'])\n    axidx += 1\n    ","f9a599ee":"def get_preds_and_labels(model, generator):\n    \"\"\"\n    Get predictions and labels from the generator\n    \"\"\"\n    preds = []\n    labels = []\n    for _ in range(int(np.ceil(generator.samples \/ BATCH_SIZE))):\n        x, y = next(generator)\n        preds.append(model.predict(x))\n        labels.append(y)\n    # Flatten list of numpy arrays\n    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()\n\n","ff2387fe":"from sklearn.metrics import cohen_kappa_score\n\nfrom keras.callbacks import Callback\n\nclass Metrics(Callback):\n    \"\"\"\n    A custom Keras callback for saving the best model\n    according to the Quadratic Weighted Kappa (QWK) metric\n    \"\"\"\n    def __init__(self, model, val_generator, model_save_filepath):\n        self.model = model\n        self.val_generator = val_generator\n        self.model_save_filepath = model_save_filepath\n        \n    def on_train_begin(self, logs={}):\n        \"\"\"\n        Initialize list of QWK scores on validation data\n        \"\"\"\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        \"\"\"\n        Gets QWK score on the validation data\n        \"\"\"\n        # Get predictions and convert to integers\n        y_pred, labels = get_preds_and_labels(self.model, self.val_generator)\n        y_pred = np.rint(y_pred).astype(np.uint8).clip(0, 4)\n        # We can use sklearns implementation of QWK straight out of the box\n        # as long as we specify weights as 'quadratic'\n        _val_kappa = cohen_kappa_score(labels, y_pred, weights='quadratic') # QWK \ubc29\ubc95\uc744 \uc0ac\uc6a9\n        self.val_kappas.append(_val_kappa)\n        print(f\"val_kappa: {round(_val_kappa, 4)}\")\n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save(self.model_save_filepath)\n        return","d82df7fe":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\ndef get_callbacks(model, val_generator, model_save_filepath):\n    # Monitor MSE to avoid overfitting and save best model\n    es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=12)\n    # factor : \ubcc0\uacbd \uc2dc multiplier\n    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4,\n                           verbose=1, mode='auto', min_delta=0.0001)\n    km = Metrics(model, val_generator, model_save_filepath)\n    return [es, lr, km]","5639764d":"def get_total_batch(num_samples, batch_size):    \n    if (num_samples % batch_size) > 0 :\n        return (num_samples \/\/ batch_size) + 1\n    else :\n        return num_samples \/\/ batch_size","e86387b4":"from keras import backend as K\nfrom keras.activations import elu\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n\nfrom efficientnet import EfficientNetB3\n\n\ndef build_model_effnet_b3(load_weights = True):\n    \"\"\"\n    A custom implementation of EfficientNetB5\n    for the APTOS 2019 competition\n    (Regression)\n    \"\"\"\n    \n    # Load in EfficientNetB5\n    effnet_b3 = EfficientNetB3(weights=None,\n                        include_top=False,\n                        input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n    if load_weights == True:\n        effnet_b3.load_weights('..\/input\/efficientnet-keras-weights-b0b5\/efficientnet-b3_imagenet_1000_notop.h5')\n    \n    model = Sequential()\n    model.add(effnet_b3)\n    model.add(GlobalAveragePooling2D()) # \uac01\uac01\uc758 \ucc44\ub110\uc744 \ud3c9\uade0\ud574\uc11c \ubcc0\ud658\ud568. \ubc14\ub85c FC\ub85c \ubcc0\uacbd\ub41c\ub2e4.\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation=elu))\n    model.add(Dense(1, activation=\"linear\")) # 0~4\uae4c\uc9c0 \ub2e8\uacc4\uc801 \uc99d\uac10\uac12\uc774 \ucd9c\ub825\uc774\ubbc0\ub85c activation\uc740 \uc120\ud615\uc73c\ub85c \ud55c\ub2e4.\n    model.compile(loss='mse',\n                  optimizer=Adam(lr=0.00005), \n                  metrics=['mse', 'acc'])\n    print(model.summary())\n    return model\n\n\ndef get_model(load_weight):\n    return build_model_effnet_b3(load_weight)\n    \ndef get_pretrained_model(model_filepath):\n    #model_filepath = os.path.join(MODEL_PATH, MODEL_FILE_NAME)\n    model = get_model(load_weight = False)\n    model.load_weights(model_filepath)\n    return model\n    ","b82634da":"from keras.backend import clear_session\nimport gc\n\n# Reset Keras Session\ndef clear_memory():\n    clear_session()\n    for i in range(20):\n        gc.collect()  ","c23f3ffd":"import os\nimport gc\nimport psutil \n\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\ndef train_single():    \n    model_save_filepath = os.path.join(MODEL_PATH, MODEL_FILE_NAME)\n    \n    model = None\n    if TRAIN_OVER_PRETRAINED:\n        print(\"train with existing weight :\", pre_model_filepath)\n        model = get_pretrained_model(pre_model_filepath) # \uc774\uc804\uc5d0 \ud6c8\ub828\ud55c weight\ub85c \ucd08\uae30\ud654\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c\ub2e4.\n    else:\n        model = get_model() # imageNet weight\ub85c \ucd08\uae30\ud654\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c\ub2e4.\n    \n    # Add Image augmentation to our generator\n    train_datagen = ImageDataGenerator(rescale = 1.\/RESCALE_DN,\n                                       preprocessing_function=preprocess_image, \n                                       rotation_range=360,\n                                       horizontal_flip=True,\n                                       validation_split=0.15,\n                                       vertical_flip=True)\n    \n\n    # Use the dataframe to define train and validation generators\n    train_generator = train_datagen.flow_from_dataframe(df_train,\n                                                        x_col='id_code', \n                                                        y_col='diagnosis',\n                                                        directory = TRAIN_IMAGE_FILE_PATH,\n                                                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                        batch_size=BATCH_SIZE,\n                                                        class_mode='other',\n                                                        subset='training')\n\n    val_generator = train_datagen.flow_from_dataframe(df_train,\n                                                      x_col='id_code',\n                                                      y_col='diagnosis',\n                                                      directory = TRAIN_IMAGE_FILE_PATH,\n                                                      target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                      batch_size=BATCH_SIZE,\n                                                      class_mode='other',\n                                                      subset='validation')\n    \n    if TRAIN_OVER_PRETRAINED == False:\n        if GENERATE_WEIGHTS == True:\n            if os.path.exists(model_save_filepath) == True:\n                os.remove(model_save_filepath)\n\n        # skip if weight file exists and not use pre-trained\n        if os.path.exists(model_save_filepath) == True:\n            print(\">>>>>>>>>>\", model_save_filepath, \" already trained... skip!\")\n            return\n\n    train_steps = get_total_batch(train_generator.samples, BATCH_SIZE)\n    val_steps = get_total_batch(val_generator.samples, BATCH_SIZE)\n    print(\"Steps : train=\", train_steps, \" validation=\", val_steps)\n\n    # make callbacks\n    callbacks = get_callbacks(model=model, val_generator=val_generator, model_save_filepath=model_save_filepath)\n\n    # First training phase (train top layer)\n    model.fit_generator(train_generator,\n                        steps_per_epoch = train_steps,\n                        epochs = EPOCHS,\n                        validation_data = val_generator,\n                        validation_steps = val_steps,\n                        callbacks = callbacks)\n    \ndef train_models():\n    clear_memory()\n\n    train_single()\n\n    # clear used memory\n    clear_memory()\n            \n\n\ntrain_models()","c750621a":"import numpy as np\nimport scipy as sp\nfrom functools import partial\n\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa score\n    \n    regression \uac12\uc73c\ub85c \ub098\uc628 \uc2e4\uc218\uac12\uc744 \uc815\uc218\ub85c \ubcc0\uacbd.\n    label\uacfc \ube44\uad50\ud558\uc5ec  \uae30\uc900\uac12(coef)\uc774 fit \ub41c\ub2e4.\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to using current coefficients\n        \n        \ud604\uc7ac coef\ub85c rounding\ud55c \uac12\uc744 label\uacfc\uc758 cohen kappa score \uacc4\uc0b0\ud55c\ub2e4.\n        loss\ud568\uc218\ub85c \uc0ac\uc6a9\ud560 \uac83\uc774\ubbc0\ub85c \uc74c\uc218\ub85c \ub9ac\ud134\ud574\uc900\ub2e4.\n        (\uac12\uc774 \uc88b\uc544\uc9c8\uc218\ub85d \uc74c\uc218\uac00 \ucee4\uc9c4\ub2e4->loss\uac00 \uc904\uc5b4\ub4e0\ub2e4.)\n        \"\"\"\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        # scipy\ub97c \uc774\uc6a9 initial_coef\uac12\uc744 \ucd5c\uc801\ud654\ud55c\ub2e4.\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \"\"\"\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","f0689550":"clear_memory()\n\n\"\"\"\ntrain \ub370\uc774\ud130\ub85c \ucd5c\uc801\ud654\ub41c OptimizedRounder\ub97c \uc5bb\ub294\ub2e4.\n\"\"\"\ndf_train = pd.read_csv(TRAIN_CSV_FILE_PATH)\ndf_train['id_code'] = df_train['id_code'] + \".png\"\n\nval_datagen = ImageDataGenerator(rescale = 1.\/RESCALE_DN,\n                                 preprocessing_function=preprocess_image)\n\nval_generator = val_datagen.flow_from_dataframe(df_train,\n                                                x_col='id_code',\n                                                y_col='diagnosis',\n                                                directory = TRAIN_IMAGE_FILE_PATH,\n                                                target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                batch_size=BATCH_SIZE,\n                                                class_mode='other')\n\n\nmodel_save_filepath = os.path.join(MODEL_PATH, MODEL_FILE_NAME)    \n\nmodel = get_pretrained_model(model_save_filepath)        \n\ny_val_preds, val_labels = get_preds_and_labels(model, val_generator)\noptR = OptimizedRounder()\noptR.fit(y_val_preds, val_labels)\ncoefficients = optR.coefficients()\n\n\nclear_memory()\n\n\ndef make_submission():\n\n    # Place holder for diagnosis column\n    test_df = pd.read_csv(TEST_CSV_FILE_PATH)\n    test_df['id_code'] = test_df['id_code'] + \".png\" # \ud655\uc7a5\uc790 \uba85\uc774 \uc5c6\uc73c\ubbc0\ub85c \ucd94\uac00\ud574\uc57c \ud55c\ub2e4.\n    \n    test_df['diagnosis'] = np.zeros(test_df.shape[0]) \n    # For preprocessing test images\n    \n    datagen = ImageDataGenerator(rescale = 1.\/RESCALE_DN,\n                                 preprocessing_function=preprocess_image)\n    \n    test_generator = datagen.flow_from_dataframe(\n                                            test_df, \n                                            x_col='id_code',\n                                            y_col='diagnosis',\n                                            directory=TEST_IMAGE_FILE_PATH,\n                                            target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                            batch_size=BATCH_SIZE,\n                                            class_mode='other',\n                                            shuffle=False)\n\n    model = get_pretrained_model(model_save_filepath)\n\n    y_test, _ = get_preds_and_labels(model, test_generator)\n    \n    steps = get_total_batch(test_df.shape[0], BATCH_SIZE)\n    y_test = model.predict_generator(generator = test_generator,\n                                           steps = steps,\n                                           verbose = 0)\n    \n    y_test = optR.predict(y_test, coefficients).astype(np.uint8)\n\n    test_df['diagnosis'] = y_test\n    # Remove .png from ids\n    test_df['id_code'] = test_df['id_code'].str.replace(r'.png$', '')\n    test_df.to_csv('submission.csv', index=False)\n\nmake_submission()\nclear_memory()","db1bfc6b":"# APTOS 2019 Blindness Detection - EfficientNet B3 \n\n\ud574\ub2f9 competition\uc740 \ubaa8\ub378\uc774 \uc548\uad6c \uc774\ubbf8\uc9c0\uc5d0 \ub530\ub978 \ub2f9\ub1e8\ubcd1\uc131 \ub9dd\ub9c9\uc99d \uc99d\uc0c1\uc758 \ub2e8\uacc4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\ub294\uac00\ub97c \ud3c9\uac00\ud569\ub2c8\ub2e4. <br>\n\uc81c\ucd9c\ub418\ub294 submission\uc740 quadratic weight kappa\ub97c \ud1b5\ud574 \ud3c9\uac00\ub429\ub2c8\ub2e4.\n\n\ub2e4\uc74c \ucee4\ub110\uc744 base\ub85c \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4 : <br>\nhttps:\/\/www.kaggle.com\/carlolepelaars\/efficientnetb5-with-keras-aptos-2019\/data","57644218":"## Evaluation\n\ncompetition\uc758 submission \ud3c9\uac00\ub294 QWK(Quadratic Weighted Kappa) \uac12\uc73c\ub85c \uc774\ub8e8\uc5b4\uc9c4\ub2e4.\n\n### Cohen's Kappa\n\ub450 \uc5f0\uad6c\uc790\uac00 \uc5bc\ub9c8\ub098 \ub3d9\uc77c\ud55c \uacb0\uacfc\ub97c \ub0b4\ub193\ub294\uc9c0\ub97c \uc218\uce58\ud654\ud558\ub294 \ubc29\ubc95\uc774\ub2e4. \ub450 \uc5f0\uad6c\uc790 \uac04 \uc77c\uce58\ud55c \uacb0\uacfc \uc911\uc5d0\uc11c \uc6b0\uc5f0\ud788 \uc77c\uce58\ud560 \uac00\ub2a5\uc131\ub97c \uc81c\uc678\ud558\uace0, \uc2e4\uc81c\ub85c \ud3c9\uac00\uac00 \uc77c\uce58\ud55c \uacb0\uacfc\uac00 \uc5b4\ub290 \uc815\ub3c4\uc778\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uc774\ub2e4.<br>\nnominal(category\uac04 \uac70\ub9ac\uac00 \uac19\uc740)\ud55c \ubc94\uc8fc\uc5d0 \uc0ac\uc6a9\ub41c\ub2e4.\n\n### Cohen's weighted Kappa\nCohen's Kappa\uc640\ub294 \ub2e4\ub974\uac8c, ordinal(\uc21c\uc11c\uac00 \uc788\ub294, \uc608\ub97c \ub4e4\uc5b4 \uad00\uc808\uc5fc\uc758 5 \ub2e8\uacc4(1:\uc5c6\uc74c, 2:\uacbd\uc99d ... 5:\uc2ec\uac01) \ub4f1\uc744 \ud45c\ud604 \uc2dc) \ubcc0\uc218\ub97c \ub300\uc0c1\uc73c\ub85c \ud560 \uacbd\uc6b0\uc5d0\ub294 Cohen's weighted Kappa\ub97c \uc0ac\uc6a9\ud55c\ub2e4. <br>\n\uc21c\uc11c(\ub610\ub294 \ub2e8\uacc4)\uac00 \uc788\ub294 \ubcc0\uc218\ub97c \ud310\ub2e8\ud558\ubbc0\ub85c \ubc94\uc8fc(\uce74\ud14c\uace0\ub9ac)\uac04 \uac70\ub9ac\ub294 \uc11c\ub85c \ub2e4\ub974\uace0, \ub450 \uc5f0\uad6c\uc790\uac04 \uacb0\uacfc\uac00 \ub2e4\ub97c \uacbd\uc6b0\uc5d0\ub3c4 \ub2e4\ub984\uc758 \ud06c\uae30\uc5d0 \uac00\uc911\uce58 \ucc28\uc774\uac00 \uc788\uc744 \uac83\uc774\ub2e4.<br>\n\uc774\ub7f0 \uc2dd\uc73c\ub85c \uac01\uac01 \ub2e4\ub978 \ube44\uc911(weight)\ub97c \ub450\uc5b4 \ubd88\uc77c\uce58 \uc815\ub3c4\ub97c \ud3c9\uac00\ud558\ub294 \uac83\uc774\ub2e4.\n\n\uac01 \ubc94\uc8fc\uac04 \ucc28\uc774\uc5d0 \ube44\uc911\uc744 \ubd80\uc5ec\ud558\ub294 \ubc29\ubc95\uc73c\ub85c\ub294 \uac12\uc758 \ucc28\uc774\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\ub294 linear \ubc29\ubc95\uacfc, \uc81c\uacf1\ud574\uc11c \uc0ac\uc6a9\ud558\ub294 quadratic \ubc29\ubc95\uc774 \uc788\ub2e4.<br>\n","69778f8e":"#### OptimizedRounder\npredict \ucd9c\ub825\uc774 \uc5b4\ub290 \uce74\ud14c\uace0\ub9ac\uc5d0 \ud3ec\ud568\ub418\ub294\uc9c0 \ud310\ubcc4\ud558\ub294 \uacbd\uacc4\uac12\uc744 scipy \ucd5c\uc801\ud654\ub85c \ucd5c\uc801\ud654 \ud55c\ub2e4.","5e1fd8d3":"## Submission","5e5751c8":"EfficientNetB3\uc744 base\ub85c \ud558\uace0, \ucd9c\ub825\uc740 linear\ub85c \ubf51\ub294\ub2e4.<br>\noutput\uc774 nomial\ud558\uae30 \ub54c\ubb38\uc5d0 linear\ub85c \ucd9c\ub825\ud558\uace0 loss\ub294 MSE\ub85c \ud55c\ub2e4.","f71dedd5":"## Metrics","f6aeda67":"\uc0c1\uc218 \uc815\uc758","ff99a6f7":"QWK\uac00 \uac1c\uc120\ub418\ub294 \uacbd\uc6b0 \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294 custom callback\uc744 \uc815\uc758\ud574\uc11c train\uc2dc \uc0ac\uc6a9\ud55c\ub2e4.\n\n> **sklearn.metrics.cohen_kappa_score(y1, y2, labels=None, weights=None, sample_weight=None)**\n\nCohen\u2019s kappa: a statistic that measures inter-annotator agreement.\n\n","6980b12e":"### callbacks\n\nGenerator\ub97c \uc0ac\uc6a9\ud574\uc11c \uacc4\uc18d train\ud558\ubbc0\ub85c, \ub354 \uc774\uc0c1 loss \uac1c\uc120\uc774 \ub418\uc9c0 \uc54a\uc744 \ub54c \uba48\ucd94\ub3c4\ub85d EarlyStopping, \uc77c\uc815 epoch\uc774\uc0c1 \uac1c\uc120\uc774 \uc548\ub418\uba74 learning rate\ub97c \uc904\uc5ec\ub098\uac00\ub294 ReduceLROnPlateau, \uc774\uc804\uc5d0 \uc120\uc5b8\ud55c Metrics\ub97c \uc0ac\uc6a9\ud55c\ub2e4.","de2a59b7":"## Preprocessing\n\n\ub2e4\uc74c \ubc29\ubc95\uc744 \ud1b5\ud574 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc2dc\uc2e0\uacbd \ubc0f \ubb38\uc81c\uac00 \ub420 \uc218 \uc788\ub294 \ubd80\ubd84\ub4e4\uc774 \ud070 contrast\ub97c \uac00\uc838\uc11c \ub69c\ub837\uc774 \ubcf4\uc774\ub3c4\ub85d \ucc98\ub9ac.<br>\n\n1. \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc704\/\uc544\ub798\uc758 \uac80\uc740 \ubd80\ubd84\uc744 crop\ud558\uc5ec \uc81c\uac70\ud568\n2. \uacbd\uacc4\ub97c \uac15\uc870\n3. \ubc1d\uae30\ub97c \ub192\uc784","9cca2c03":"## Modeling"}}