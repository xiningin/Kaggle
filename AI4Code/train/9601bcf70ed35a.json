{"cell_type":{"fb071e87":"code","c8c70634":"code","5be02386":"code","3bbcc8b4":"code","ccf29385":"code","72c8b9d4":"code","7a494c59":"code","23f1d1d9":"code","c09b0251":"code","e0b05d1a":"code","0639b91b":"code","f0fb2bb4":"code","1cdfb84a":"code","1037edca":"code","55ff01d7":"code","c6b3fb5e":"code","eac34bb8":"markdown","61dafd49":"markdown","216fccc4":"markdown","bcd20695":"markdown","ea897cea":"markdown","e9d68b94":"markdown","d633ede1":"markdown","1c4950ce":"markdown","88d132ad":"markdown","59540b9d":"markdown","93f96826":"markdown","f435a0fa":"markdown","444d084f":"markdown"},"source":{"fb071e87":"import os\nimport ast\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom keras import optimizers\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n%matplotlib inline","c8c70634":"def drawing_to_np(drawing, shape=(28, 28)):\n    # evaluates the drawing array\n    drawing = eval(drawing)\n    fig, ax = plt.subplots()\n    for x,y in drawing:\n        ax.plot(x, y, marker='.')\n        ax.axis('off')        \n    fig.canvas.draw()\n    # Close figure so it won't get displayed while transforming the set\n    plt.close(fig)\n    # Convert images to numpy array\n    np_drawing = np.array(fig.canvas.renderer._renderer)\n    # Take only one channel\n    np_drawing =np_drawing[:, :, 1]    \n    # Normalize data\n    np_drawing = np_drawing \/ 255.\n    return cv2.resize(np_drawing, shape) # Resize array\n\n\ndef plot_metrics_primary(acc, val_acc, loss, val_loss):\n    fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', figsize=(20,7))\n\n    ax1.plot(acc, label='Train Accuracy')\n    ax1.plot(val_acc, label='Validation accuracy')\n    ax1.legend(loc='best')\n    ax1.set_title('Accuracy')\n\n    ax2.plot(loss, label='Train loss')\n    ax2.plot(val_loss, label='Validation loss')\n    ax2.legend(loc='best')\n    ax2.set_title('Loss')\n\n    plt.xlabel('Epochs')\n    \n    \ndef plot_confusion_matrix(cnf_matrix, labels): \n    cnf_matrix_norm = cnf_matrix.astype('float') \/ cnf_matrix.sum(axis=1)[:, np.newaxis]\n    df_cm = pd.DataFrame(cnf_matrix_norm, index=labels, columns=labels)\n    plt.figure(figsize=(20,7))\n    sns.heatmap(df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\n    plt.show()","5be02386":"TRAIN_PATH = '..\/input\/train_simplified\/'\nTEST_PATH = '..\/input\/test_simplified.csv'\nSUBMISSION_NAME = 'submission.csv'\n\ntrain = pd.DataFrame()\nfor file in os.listdir(TRAIN_PATH)[:5]:\n    train = train.append(pd.read_csv(TRAIN_PATH + file, usecols=[1, 5], nrows=2000))\n# Shuffle data\ntrain = shuffle(train, random_state=123)\ntest = pd.read_csv(TEST_PATH, usecols=[0, 2], nrows=100)","3bbcc8b4":"# Model parameters\nBATCH_SIZE = 64\nEPOCHS = 60\nLEARNING_RATE = 0.001\nN_CLASSES = train['word'].nunique()\nHEIGHT = 28\nWIDTH = 28\nCHANNEL = 1","ccf29385":"print('Train set shape: ', train.shape)\nprint('Train set features: %s' % train.columns.values)\nprint('Train number of label categories: %s' % N_CLASSES)\ntrain.head()","72c8b9d4":"#Fixing labels.\ntrain['word'] = train['word'].replace(' ', '_', regex=True)\n# Get labels and one-hot encode them.\nclasses_names = train['word'].unique()\nlabels = pd.get_dummies(train['word']).values\ntrain.drop(['word'], axis=1, inplace=True)\n# Transform drawing into numpy arrays\ntrain['drawing_np'] = train['drawing'].apply(drawing_to_np)\n# Reshape arrays\ntrain_drawings = np.asarray([x.reshape(HEIGHT, WIDTH, CHANNEL) for x in train['drawing_np'].values])","7a494c59":"train.head()","23f1d1d9":"x_train, x_val, y_train, y_val = train_test_split(train_drawings, labels, test_size=0.1, random_state=1)","c09b0251":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(5,5),padding='Same', activation='relu', input_shape=(HEIGHT, WIDTH, CHANNEL)))\nmodel.add(Conv2D(32, kernel_size=(5,5),padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3,3),padding='Same', activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3,3),padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(N_CLASSES, activation = \"softmax\"))\n\noptimizer = optimizers.adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=optimizer , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","e0b05d1a":"print('Dataset size: %s' % train.shape[0])\nprint('Epochs: %s' % EPOCHS)\nprint('Learning rate: %s' % LEARNING_RATE)\nprint('Batch size: %s' % BATCH_SIZE)\nprint('Input dimension: (%s, %s, %s)' % (HEIGHT, WIDTH, CHANNEL))\n\nmodel.summary()","0639b91b":"history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_val, y_val))","f0fb2bb4":"plot_metrics_primary(history.history['acc'], history.history['val_acc'], history.history['loss'], history.history['val_loss'])","1cdfb84a":"cnf_matrix = confusion_matrix(np.argmax(y_val, axis=1), model.predict_classes(x_val))\nplot_confusion_matrix(cnf_matrix, classes_names)","1037edca":"# Transform drawing into numpy arrays.\ntest['drawing_np'] = test['drawing'].apply(drawing_to_np)\n# Reshape arrays.\ntest_drawings = np.asarray([x.reshape(HEIGHT, WIDTH, CHANNEL) for x in test['drawing_np'].values])","55ff01d7":"predictions = model.predict(test_drawings)\ntop_3_predictions = np.asarray([np.argpartition(pred, -3)[-3:] for pred in predictions])\ntop_3_predictions = ['%s %s %s' % (classes_names[pred[0]], classes_names[pred[1]], classes_names[pred[2]]) for pred in top_3_predictions]\ntest['word'] = top_3_predictions","c6b3fb5e":"submission = test[['key_id', 'word']]\nsubmission.to_csv(SUBMISSION_NAME, index=False)\nsubmission.head(10)","eac34bb8":"### Auxiliar functions","61dafd49":"<h2><center> Quick, Draw! Doodle Recognition Challenge & CNNs<\/center> <\/h2>\n\n### Let's see how CNNS the already proven model to image classification peforms in this challenge.\n\nThis is just a demonstration that's why im not using all the categories from the train set.","216fccc4":"### Process test","bcd20695":"### Let's take a look at the raw data","ea897cea":"### Load data","e9d68b94":"### Pre process","d633ede1":"### Model","1c4950ce":"### Split data in train and validation (90% ~ 10%)","88d132ad":"Let's take a look at our model loss and accuracy training and validation graph.","59540b9d":"Finally let's predict the test data and output our predictions.","93f96826":"A good way to evaluate a classification model is to take a look at the model confusion matrix, this way we can have a better insight on what our model is getting right and what not.","f435a0fa":"### Dependencies","444d084f":"### Parameters"}}