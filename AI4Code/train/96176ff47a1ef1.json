{"cell_type":{"aeddad23":"code","89fb6a51":"code","857122a2":"code","d8a4c3a9":"code","56bb2e20":"code","86dcbd9e":"code","a9e33531":"code","aed0778b":"code","67d92fe2":"code","dc253ebf":"code","fd94741f":"code","6b980303":"code","9b1873e0":"code","d98c488b":"code","b46ca968":"code","a16fd16e":"code","5c1ce26c":"markdown","51caa9ab":"markdown"},"source":{"aeddad23":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89fb6a51":"# Python Project Template\n# 1. Prepare Problem\n# a) Load libraries\n# b) Load dataset\n\n# 2. Summarize Data\n# a) Descriptive statistics\n# b) Data visualizations\n\n# 3. Prepare Data\n# a) Data Cleaning\n# b) Feature Selection\n# c) Data Transforms\n\n# 4. Evaluate Algorithms\n# a) Split-out validation dataset\n# b) Test options and evaluation metric\n# c) Spot Check Algorithms\n# d) Compare Algorithms\n\n# 5. Improve Accuracy\n# a) Algorithm Tuning\n# b) Ensembles\n\n# 6. Finalize Model\n# a) Predictions on validation dataset\n# b) Create standalone model on entire training dataset\n# c) Save model for later use","857122a2":"# Load libraries\nfrom pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n","d8a4c3a9":"names = {'SepalLengthCm': 'sepal_length',\n         'SepalWidthCm':'sepal_width',\n         'PetalLengthCm':'petal_length',\n         'PetalWidthCm':'petal_width',\n         'Species':'class'}\niris = pd.read_csv('..\/input\/iris\/Iris.csv')\niris.rename(columns=names, inplace=True)\niris.drop(iris.columns[0], axis=1, inplace=True)\niris.head(5)","56bb2e20":"iris.info()","86dcbd9e":"iris.isnull().sum()","a9e33531":"iris.describe()","aed0778b":"iris.shape","67d92fe2":"iris.groupby('class').size()","dc253ebf":"iris.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)","fd94741f":"iris.hist()","6b980303":"scatter_matrix(iris)","9b1873e0":"# Split-out validation dataset\narray = iris.values\nX = array[:,0:4]\nY = array[:,4]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)","d98c488b":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed,shuffle=True)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n","b46ca968":"fig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","a16fd16e":"knn = KNeighborsClassifier()\nknn.fit(X_train, Y_train)\npredictions = knn.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","5c1ce26c":"## In this tutorial we are going to work through a small machine learning project end-to-end.\n## Here is an overview of what we are going to cover:\n1. Loading the dataset.\n2. Summarizing the dataset.\n3. Visualizing the dataset.\n4. Evaluating some algorithms.\n5. Making some predictions.","51caa9ab":"## This section presents a project template that you can use to work through machine learning problems in Python end-to-end\n"}}