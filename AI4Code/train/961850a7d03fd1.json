{"cell_type":{"fa7e5012":"code","14f79181":"code","57bb18fb":"code","4d38d56a":"code","0c2fc34e":"code","d6a711fd":"code","c3b42bc3":"code","7f466366":"code","d4fb6795":"code","fe01332c":"code","e8e6a2b5":"code","417638f0":"code","cff08f18":"code","e9aac10f":"code","a4a0ab64":"code","66a1d86c":"code","36af47c6":"code","d07b137d":"code","0dd6e5b0":"code","b887608e":"markdown","f3491335":"markdown","1caaf425":"markdown","cb530707":"markdown"},"source":{"fa7e5012":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_validate\n\nimport optuna\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","14f79181":"pip install feature-engine","57bb18fb":"from feature_engine.encoding import OneHotEncoder\nfrom feature_engine.encoding import OrdinalEncoder\nfrom feature_engine.encoding import CountFrequencyEncoder\nfrom feature_engine.encoding import MeanEncoder\nfrom feature_engine.encoding import PRatioEncoder\nfrom feature_engine.encoding import WoEEncoder\nfrom feature_engine.imputation import CategoricalImputer\nfrom feature_engine.imputation import MeanMedianImputer","4d38d56a":"df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\nX_train = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket'], axis=1)\ny_train = df['Survived']\n\nX_test_id = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')['PassengerId']\nX_test = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv').drop(\n    columns=['PassengerId', 'Name', 'Ticket'], axis=1)\nsub_sample = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')","0c2fc34e":"X_train['Cabin'] = X_train['Cabin'].str[0]\nX_test['Cabin'] = X_test['Cabin'].str[0]","d6a711fd":"X_test.head()","c3b42bc3":"X_train.isnull().mean()","7f466366":"pre_pipe = Pipeline([\n\n    ('median_imputer', MeanMedianImputer(imputation_method='median',\n                                         variables=['Age', 'Fare'])),\n    \n    ('missing_imputer', CategoricalImputer(variables=['Cabin'])),\n    \n    ('mode_imputer', CategoricalImputer(imputation_method='frequent',\n                                        variables=['Embarked'])),\n\n    ])","d4fb6795":"pre_pipe.fit(X_train, y_train)","fe01332c":"X_train = pre_pipe.transform(X_train)\nX_test = pre_pipe.transform(X_test)","e8e6a2b5":"oh_enc = OneHotEncoder(top_categories=None, variables=['Sex', 'Cabin', 'Embarked'], drop_last=True).fit(X_train)\nig_enc = OrdinalEncoder(encoding_method='arbitrary', variables=['Sex', 'Cabin', 'Embarked']).fit(X_train)\nod_enc = OrdinalEncoder(encoding_method='ordered', variables=['Sex', 'Cabin', 'Embarked']).fit(X_train, y_train)\nfq_enc = CountFrequencyEncoder(encoding_method='frequency', variables=['Sex', 'Cabin', 'Embarked']).fit(X_train)\nme_enc = MeanEncoder(variables=['Sex', 'Cabin', 'Embarked']).fit(X_train, y_train)\npr_enc = PRatioEncoder(encoding_method='ratio', variables=['Sex', 'Cabin', 'Embarked']).fit(X_train, y_train)\nwe_enc = WoEEncoder(variables=['Sex', 'Cabin', 'Embarked']).fit(X_train, y_train)","417638f0":"def run_logistic_cv(X_train, y_train):\n    kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1234)\n    model = LogisticRegression(max_iter=1000)\n    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n    return scores['test_score'].mean()","cff08f18":"print('Accuracy Comparison')\nprint('One Hot Encoding: ' + str(run_logistic_cv(oh_enc.transform(X_train), y_train)))\nprint('Integer Encoding: ' + str(run_logistic_cv(ig_enc.transform(X_train), y_train)))\nprint('Ordered Integer Encoding: ' + str(run_logistic_cv(od_enc.transform(X_train), y_train)))\nprint('Frequency Encoding: ' + str(run_logistic_cv(fq_enc.transform(X_train), y_train)))\nprint('Mean Encoding: ' + str(run_logistic_cv(me_enc.transform(X_train), y_train)))\nprint('Probability Ratio Encoding: ' + str(run_logistic_cv(pr_enc.transform(X_train), y_train)))\nprint('Weight of Evidence: ' + str(run_logistic_cv(we_enc.transform(X_train), y_train)))","e9aac10f":"def objective(trial):\n    \n    param_grid_lr = {\n        'C' : trial.suggest_int(\"C\", 1, 100),\n        \"random_state\": 0\n    }\n\n    model = LogisticRegression(**param_grid_lr, max_iter=1000)\n    \n    kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n    scores = cross_validate(model, X=oh_enc.transform(X_train), y=y_train, cv=kf)\n    return scores['test_score'].mean()","a4a0ab64":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=10)\nprint(study.best_params)\nprint(study.best_value)\nlr_best_param = study.best_params","66a1d86c":"optuna.visualization.plot_optimization_history(study)","36af47c6":"model = LogisticRegression(**lr_best_param, max_iter=1000)  \nmodel.fit(oh_enc.transform(X_train), y_train)\ny_test_pred = model.predict(oh_enc.transform(X_test))","d07b137d":"sub = pd.DataFrame(y_test_pred, index=X_test_id).reset_index().rename(columns={0: 'Survived'})\nsub.to_csv('optuna_lm.csv', index=False)","0dd6e5b0":"sub","b887608e":"### Categorical Valiable Encoding \n* **One Hot Encoding**: Suitable for linear models\n* **Integer\/Ordinal\/Label Encoding**: Not suitable for linear models (Work well enough for tree based models)\n* **Ordered Ordinal Encoding**: Can be useful for linear models (Monotonic relationship between categories and target. But may lead to overfitting)\n* **Frequency Encoding**: Not suitable for linear models  (Work well enough for tree based models)\n* **Mean Encoding**: Can be useful for linear models (Monotonic relationship between categories and target. But may lead to overfitting)\n* **Probability Ratio Encoding**: Can be useful for linear models (Monotonic relationship between categories and target. But may lead to overfitting)\n* **Weight of Evidence**: Can be useful for linear models (Monotonic relationship between categories and target. It orders categories on logistic scale which is natural for logistic regression. But may lead to overfitting)","f3491335":"### Missing Data Imputation\n* Cabin: Most of the data are missing values.\n    * Fill missing values with 'Missing' to capture the importance of missingness\n* Age, Fare, Embarked: The percentage of missing values is small\n    * Fill median for Age, Fare and mode for Embarked to capture the randomness of their missing","1caaf425":"### Parameter Tuning","cb530707":"### One Hot Encoding is the best for the accuracy"}}