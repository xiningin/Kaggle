{"cell_type":{"9e074746":"code","452574c7":"code","2a080b68":"code","9b7ade3e":"code","bde9ec0e":"code","24e7a6bf":"code","494a3106":"code","99191d47":"code","7daf5193":"code","220a1248":"code","7b00aca8":"code","f8edbeba":"code","668561ec":"code","2c1c3a5e":"code","79ca02d9":"code","fd17abde":"code","3c2d6584":"code","d98eb74a":"code","d7a76f64":"code","d293c324":"code","17a98f22":"code","95241d37":"code","99791f34":"code","fe11ea92":"code","4ffdb1b2":"code","bef281d0":"code","78c4bb9f":"code","3c90aab3":"code","2664f91e":"markdown","75f6a45c":"markdown","c48d2f6c":"markdown","3fed74e3":"markdown","76e3497f":"markdown","2c86590c":"markdown","a55630b5":"markdown","bbba19d5":"markdown","22d5a2db":"markdown","f99fa9da":"markdown","c982632f":"markdown","123bc5a9":"markdown","6c988f73":"markdown","cd75e44c":"markdown","fdc7ac97":"markdown","9cb7f1ce":"markdown"},"source":{"9e074746":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","452574c7":"dataset = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","2a080b68":"dataset.describe()","9b7ade3e":"corr = dataset.corr()","bde9ec0e":"corr","24e7a6bf":"sns.heatmap(corr)","494a3106":"corr['output']","99191d47":"sns.distplot(dataset['chol'])","7daf5193":"sns.distplot(dataset['fbs'])","220a1248":"dataset.drop(['fbs', 'chol'], axis = 1, inplace = True)","7b00aca8":"dataset","f8edbeba":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","668561ec":"X","2c1c3a5e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","79ca02d9":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","fd17abde":"from sklearn.linear_model import LogisticRegression\nclassifier_lr = LogisticRegression(random_state = 0)\nclassifier_lr.fit(X_train, y_train)\ny_pred_lr = classifier_lr.predict(X_test)","3c2d6584":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm_lr = confusion_matrix(y_test, y_pred_lr)\nprint(cm_lr)\naccuracy_score(y_test, y_pred_lr)","d98eb74a":"from sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski', p = 2)\nclassifier_knn.fit(X_train, y_train)\ny_pred_knn = classifier_knn.predict(X_test)\n","d7a76f64":"cm_knn = confusion_matrix(y_test, y_pred_knn)\nprint(cm_knn)\naccuracy_score(y_test, y_pred_knn)","d293c324":"from sklearn.svm import SVC\nclassifier_svm = SVC(kernel = 'rbf', random_state = 0)\nclassifier_svm.fit(X_train, y_train)\ny_pred_svm = classifier_svm.predict(X_test)\n","17a98f22":"cm_svm = confusion_matrix(y_test, y_pred_svm)\nprint(cm_svm)\naccuracy_score(y_test, y_pred_svm)","95241d37":"from sklearn.naive_bayes import GaussianNB\nclassifier_nb = GaussianNB()\nclassifier_nb.fit(X_train, y_train)\ny_pred_nb = classifier_nb.predict(X_test)\n","99791f34":"cm_nb = confusion_matrix(y_test, y_pred_nb)\nprint(cm_nb)\naccuracy_score(y_test, y_pred_nb)","fe11ea92":"from sklearn.tree import DecisionTreeClassifier\nclassifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier_dt.fit(X_train, y_train)\ny_pred_dt = classifier_dt.predict(X_test)\n","4ffdb1b2":"cm_dt = confusion_matrix(y_test, y_pred_dt)\nprint(cm_dt)\naccuracy_score(y_test, y_pred_dt)","bef281d0":"from sklearn.ensemble import RandomForestClassifier\nclassifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier_rf.fit(X_train, y_train)\ny_pred_rf = classifier_rf.predict(X_test)","78c4bb9f":"cm_rf = confusion_matrix(y_test, y_pred_rf)\nprint(cm_rf)\naccuracy_score(y_test, y_pred_rf)","3c90aab3":"x_axis = ['Logistic reg', 'KNN', 'SVM', 'Naiive Bayes', 'Descision tree', 'Random forest']\ny_axis = [accuracy_score(y_test, y_pred_lr)*100, accuracy_score(y_test, y_pred_knn)*100, accuracy_score(y_test, y_pred_svm)*100, accuracy_score(y_test, y_pred_nb)*100, accuracy_score(y_test, y_pred_dt)*100, accuracy_score(y_test, y_pred_rf)*100]\nplt.bar(x_axis, y_axis)\nplt.title('Comparision of accuracy of each model')\nplt.xlabel('Models')\nplt.ylabel('% Accuracy')","2664f91e":"## Importing the libraries","75f6a45c":"## Splitting the dataset into the Training set and Test set","c48d2f6c":"## Feature Scaling","3fed74e3":"# Naiive Bayes","76e3497f":"# Kernel SVM","2c86590c":"# Comparision of models","a55630b5":"# KNN","bbba19d5":"# Logistic Regression","22d5a2db":"##Data Preprocessing","f99fa9da":"**Since fbs and chol have the least effect hence they will be removed**\n\n","c982632f":"# Random Forest","123bc5a9":"## Importing the dataset","6c988f73":"# Decision Tree","cd75e44c":"Thanks!","fdc7ac97":"Hence KNN is the most accurate","9cb7f1ce":"## Training the Logistic Regression model on the Training set"}}