{"cell_type":{"38ee1285":"code","ef0d18ba":"code","82e009bb":"code","6f00930c":"code","082858e7":"code","1ef47fdc":"code","ddaabb1a":"code","e313cae7":"code","7c233bb5":"code","881fbd37":"code","1acd2119":"code","b0b0dc30":"code","b353122e":"code","6193e29a":"code","30809a74":"code","67be018f":"code","cf774ac1":"code","fd750dd2":"code","61651d6d":"code","27148ff9":"code","250b34b7":"code","80a15376":"code","a1c0353d":"code","1360281b":"code","d0c43e8a":"code","a65a9eb5":"code","f7d12cd1":"code","700ea2ad":"code","5e90752f":"code","dfa4a2ca":"code","f10a280c":"code","840b7b5c":"code","d4050680":"code","17aca0a4":"code","80c36446":"code","0758d488":"code","9e17f5ac":"code","7891576e":"code","194d44f1":"code","13073061":"code","ad8c2012":"code","ff440708":"markdown","59a34bb5":"markdown","f2cd4b40":"markdown","594382a4":"markdown"},"source":{"38ee1285":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        \n\n# Any results you write to the current directory are saved as output.","ef0d18ba":"from pprint import pprint","82e009bb":"import librosa\nimport cv2\nfrom librosa.display import specshow\nimport csv\nfrom IPython.display import Audio\nimport json","6f00930c":"filee = pd.read_csv(\"\/kaggle\/input\/environmental-sound-classification-50\/esc50.csv\")\nfilee","082858e7":"import multiprocessing\n\nmultiprocessing.cpu_count()","1ef47fdc":"import random","ddaabb1a":"import IPython.display as ipd\nsound = librosa.load('\/kaggle\/input\/environmental-sound-classification-50\/audio\/audio\/16000\/1-101336-A-30.wav', sr=16000)\nnoise = np.zeros(sound[0].shape, dtype='float32')\nnoise += np.random.randn(len(sound[0]))\ndata_noise = sound[0]+(random.uniform(0.003, 0.0135)*noise)\nlibrosa.output.write_wav(\"noise_add.wav\", data_noise, sound[1])\nipd.Audio('noise_add.wav')\n","e313cae7":"def hi():\n    if True:\n        return 2,3\nhi()","7c233bb5":"ipd.Audio('\/kaggle\/input\/environmental-sound-classification-50\/audio\/audio\/16000\/1-101336-A-30.wav')","881fbd37":"a = [2, 3, 5]\nclass aaaa:\n    def __init__(self, aa):\n        self.aaa = aa\n    def addd(self, b):\n        \n        self.aaa.append(b)\nplant = aaaa(a)\nplant.addd(5)\na","1acd2119":"import matplotlib.pyplot as plt\npath = \"\/kaggle\/input\/environmental-sound-classification-50\/audio\/audio\/16000\/\"\n\nX = []\ny = []\n\nclass AudioAugment():\n    def __init__(self, dataPath, Xx, yy, dataFile=None):\n        self.dataPath = dataPath\n        self.dataFile = dataFile\n        self.X = Xx\n        self.y = yy\n    def addNoise(self, path=None, data=None):\n        if self.X and self.y:\n            data = [self.X, self.y]\n        if path and data:\n            print(\"put only one\")\n        elif path and self.dataFile.empty:\n            print(\"No data file to read from\")\n            return False\n        elif path and self.dataFile.any().any():\n            for idx, s in enumerate(self.dataFile['filename']):\n                print(str((idx\/len(self.dataFile['filename']))*100) + \"%\")\n                sound = librosa.load(self.dataPath+f\"{self.dataFile['filename'][idx]}\", sr=16000)\n                noise = np.zeros(sound[0].shape, dtype='float32')\n                noise += np.random.randn(len(sound[0]))\n                for i in range(4):\n                    data_noise = sound[0]+(random.uniform(0.003, 0.0138)*noise)\n                    self.X.append(data_noise)\n                    self.y.append(self.dataFile['target'][idx])\n            return self.X, self.y\n        elif data:\n            for idx, s in enumerate(data[0]):\n                print(str((idx\/len(data[0]))*100) + \"%\")\n                noise = np.zeros(data[0][idx].shape, dtype='float32')\n                noise += np.random.randn(len(data[0][idx]))\n                for i in range(2):\n                    data_noise = s+(random.uniform(0.003, 0.0135)*noise)\n                    self.X.append(data_noise)\n                    self.y.append(data[1][idx])\n        else:\n            print(\"no sound data\/files to use\")\n    def arrFiles(self):\n        global X\n        global y\n        for s in range(0, len(filee['filename'])):\n            print(str((s\/len(filee['filename']))*100) + \"%\")\n            sound = librosa.load(path+f\"{filee['filename'][s]}\", sr=16000)\n            sp = 0.9\n            n_steps = -2\n            for i in range(0, 3):\n                exec(f\"a{i} = librosa.effects.time_stretch(sound[0], sp)\")\n                exec(f\"a{i} = librosa.util.fix_length(a{i}, 80000)\")\n        #         exec(f\"print(librosa.get_duration(a{i}))\")\n                exec(f\"X.append(a{i})\")\n        #         a = f\"{sp}\"[:5]\n        #         exec(f\"librosa.output.write_wav('\/kaggle\/working\/{filee['filename'][s]}_{a}_stretch', a{i}, sound[1])\")\n                exec(f\"y.append(filee['target'][s])\")\n                sp += 0.1\n            for j in range(0, 5):\n                exec(f\"b{i} = librosa.effects.pitch_shift(sound[0], sr=sound[1], n_steps=n_steps)\")\n                exec(f\"b{i} = librosa.util.fix_length(b{i}, 80000)\")\n                exec(f\"X.append(b{i})\")\n        #         b = f\"{n_steps}\"[:5]\n        #         exec(f\"librosa.output.write_wav('\/kaggle\/working\/{filee['filename'][s]}_{b}_pitch', b{i}, sound[1])\")\n                exec(f\"y.append(filee['target'][s])\")\n                n_steps += 1\n\n\n\n        #         exec(f\"y.append(filee['target'][s])\")\n        return 0\naa = AudioAugment(path, X, y, dataFile=filee)\n\n# arrFiles()\n# print(X)\n# print(y)\n\n\n        \n# #     print(filee['filename'][s],\" \", filee['target'][s], \" \", filee['category'][s])\n# #     soundSpec = librosa.feature.melspectrogram(sound[0], sr=sound[1])\n# #     X.append(soundSpec)\n# #     y.append(filee['target'][s])\n# #     os.system(\"cls\")\n    \n# #     specPic = specshow(soundSpec, x_axis='time', y_axis='mel', sr=sound[1])\n# #     plt.show()\n","b0b0dc30":"# aa.arrFiles()","b353122e":"aa.addNoise(path=path)","6193e29a":"# X = np.array(X, dtype='float16')\n# y = np.array(y, dtype='float16')","30809a74":"# local_vars = list(locals().items())\n# sizes = []\n# for var, obj in local_vars:\n#     sizes.append(getsizeof(obj))\n# #     print(var, getsizeof(obj))\n# sumSize = sum(sizes)\n# print(sumSize)\n    \n","67be018f":"# import matplotlib.pyplot as plt\n# path = \"\/kaggle\/input\/environmental-sound-classification-50\/audio\/audio\/16000\/\"\n\n# X = []\n# y = []\n# #testing loader\n# # for row in filee['filename']:\n# #     print(row)\n\n# @jit(forceobj=True)\n# def arrFiles():\n#     global X\n#     global y\n#     for s in range(0, len(filee['filename'])):\n#         print(str((s\/len(filee['filename']))*100) + \"%\")\n#         sound = librosa.load(path+str(filee['filename'][s]), sr=16000)\n#         sp = 0.9\n#         n_steps = -2\n#         for i in range(0, 3):\n#             exec(\"a\"+str(i)+\" = librosa.effects.time_stretch(sound[0], sp)\")\n#             exec(\"a\"+str(i)+\" = librosa.util.fix_length(a\"+str(i)+\", 80000)\")\n#     #         exec(f\"print(librosa.get_duration(a{i}))\")\n#             exec(\"X.append(a\"+str(i)+\")\")\n#     #         a = f\"{sp}\"[:5]\n#     #         exec(f\"librosa.output.write_wav('\/kaggle\/working\/{filee['filename'][s]}_{a}_stretch', a{i}, sound[1])\")\n#             exec(\"y.append(filee['target'][s])\")\n#             sp += 0.1\n#         for j in range(0, 5):\n#             exec(\"b\"+str(i)+\" = librosa.effects.pitch_shift(sound[0], sr=sound[1], n_steps=n_steps)\")\n#             exec(\"b\"+str(i)+\" = librosa.util.fix_length(b\"+str(i)+\", 80000)\")\n#             exec(\"X.append(b\"+str(i)+\")\")\n#     #         b = f\"{n_steps}\"[:5]\n#     #         exec(f\"librosa.output.write_wav('\/kaggle\/working\/{filee['filename'][s]}_{b}_pitch', b{i}, sound[1])\")\n#             exec(\"y.append(filee['target'][s])\")\n#             n_steps += 1\n        \n    \n\n#     #         exec(f\"y.append(filee['target'][s])\")\n#     return 0\n\n# arrFiles()\n# X = np.array(X)\n# y = np.array(y)\n        \n        \n# #     print(filee['filename'][s],\" \", filee['target'][s], \" \", filee['category'][s])\n# #     soundSpec = librosa.feature.melspectrogram(sound[0], sr=sound[1])\n# #     X.append(soundSpec)\n# #     y.append(filee['target'][s])\n# #     os.system(\"cls\")\n    \n# #     specPic = specshow(soundSpec, x_axis='time', y_axis='mel', sr=sound[1])\n# #     plt.show()\n    ","cf774ac1":"# pprint(X.shape)\n# pprint(y.shape)\n# print(len(X))\n","fd750dd2":"# X_img = []\n# def convertToSpec(xx):\n#     global X_img\n    \n#     for idx, sou in enumerate(xx):\n#         print(str((idx\/len(xx))*100) + \"%\")\n#         soundSpec = librosa.feature.melspectrogram(sou, sr=16000)\n#         X_img.append(soundSpec)\n        \n# convertToSpec(X)\n# X_img = np.array(X_img)\n# print(X_img.shape)","61651d6d":"X_img_Noise = []\ndef convertToSpec(xx):\n    global X_img_Noise\n    \n    for idx, sou in enumerate(xx):\n        print(str((idx\/len(xx))*100) + \"%\")\n        soundSpec = librosa.feature.melspectrogram(sou, sr=16000)\n        X_img_Noise.append(soundSpec)\n        \nconvertToSpec(X)\nX_img_Noise = np.array(X_img_Noise)\nprint(X_img_Noise.shape)","27148ff9":"# #save to disk for re-use\n# import pickle\n# with open('X_img.pickle', 'wb') as ff:\n#     pickle.dump(X_img, ff)\n# with open('y.pickle', 'wb') as f:\n#     pickle.dump(y, f)","250b34b7":"#save to disk for re-use\nimport pickle\nwith open('X_img_Noise.pickle', 'wb') as ff:\n    pickle.dump(X_img_Noise, ff)\nwith open('y_Noise.pickle', 'wb') as f:\n    pickle.dump(y, f)","80a15376":"# X_img.shape","a1c0353d":"# import pickle\n# with open('\/kaggle\/input\/x-img123\/X_img.pickle', 'rb') as filee:\n#     X_img = pickle.load(filee)\n# with open('\/kaggle\/input\/x-img123\/y.pickle', 'rb') as filee2:\n#     y = pickle.load(filee2)","1360281b":"# X_img = X_img.reshape((X_img.shape[0], X_img.shape[1], X_img.shape[2], 1))\n# X_img = X_img\/255\n# X_train = X_img[:round(len(X_img)*0.98),:]\n# X_test = X_img[round(len(X_img)*0.98):,:]\n# y_train = y[:round(len(X_img)*0.98)]\n# y_test = y[round(len(X_img)*0.98):]\n# print(X_train.shape, X_test.shape)\n# print(y_train.shape, y_test.shape)","d0c43e8a":"# from tensorflow.keras.utils import to_categorical\n# y = to_categorical(y, num_classes=50)\n# y_train = to_categorical(y_train, num_classes=50)\n# y_test = to_categorical(y_test, num_classes=50)\n# # pprint(y_train)\n# print(y_train.shape)","a65a9eb5":"# from tensorflow.keras.utils import to_categorical\n# from keras.models import Model\n# from keras.callbacks import ModelCheckpoint\n# from keras.layers import Dense, Conv2D, MaxPooling2D, AveragePooling2D, Input, Flatten, Dropout\n\n# filepath = \"model5.hdf5\"\n# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n# callbacks_list = [checkpoint]\n\n# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n\n# inputs = Input(shape=(X_train.shape[1], X_train.shape[2], 1))\n# # conv2 = Conv2D(24, (5,5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu')(inputs)\n\n# conv = Conv2D(64, (3, 4), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu')(inputs)\n# maxPool = MaxPooling2D((2, 2))(conv)\n# drop = Dropout(0.25)(maxPool)\n\n# conv1 = Conv2D(128, (3, 3), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu')(drop)\n# maxPool1 = MaxPooling2D((3, 3))(conv1)\n# drop1 = Dropout(0.3)(maxPool1)\n\n# conv2 = Conv2D(512, (3, 3), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu')(drop1)\n# maxPool2 = MaxPooling2D((3, 3))(conv2)\n# drop2 = Dropout(0.4)(maxPool2)\n\n# conv3 = Conv2D(800, (3, 3), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu')(drop2)\n# maxPool3 = MaxPooling2D((2, 2))(conv3)\n# drop3 = Dropout(0.5)(maxPool3)\n\n# flat1 = Flatten()(drop3)\n\n# l1 = Dense(128, activation='relu')(flat1)\n# drop4 = Dropout(0.6)(l1)\n\n# outputs = Dense(50, activation='softmax')(drop4)\n\n# model = Model(inputs=inputs, outputs=outputs)\n\n# flat1 = Flatten()(drop3)\n\n# l1 = Dense(128, activation='relu', kernel_regularizer='l2')(flat1)\n# drop4 = Dropout(0.65)(l1)\n\n# outputs = Dense(50, activation='softmax')(drop4)\n\n# model = Model(inputs=inputs, outputs=outputs)","f7d12cd1":"# model.compile(\n#     optimizer='adam',\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy'])","700ea2ad":"# model.summary()","5e90752f":"# history = model.fit(\n#     X_train,\n#     y_train,\n#     batch_size=128,\n#     epochs=60,\n#     shuffle=True,\n#     callbacks=callbacks_list,\n#     validation_data=(X_test, y_test))","dfa4a2ca":"# from keras.models import load_model\n# for filee in os.listdir(\"\/kaggle\/input\/models\/\"):\n#     exec(str(filee)[:-5] + \" = load_model('\/kaggle\/input\/models\/\" + str(filee) + \"')\")\n# #     print(str(filee)[:-5] + \" = load_model('\/kaggle\/input\/models\/\" + str(filee) + \"')\")","f10a280c":"# sound = librosa.load(path+f\"{filee['filename'][1]}\", sr=16000)\n# Audio(sound[0], rate=16000)","840b7b5c":"# a = [[[\"a\",1], [\"a1\",11]],[[\"b\",2], [\"b1\", 22]],[[\"c\",3], [\"c1\",33]],[[\"d\",4], [\"d1\",44]]]\n# for idx, i in enumerate(a[0]):\n#     print(a[0][idx], a[1][idx], a[2][idx], a[3][idx])\n# b = [[a[0][idx], a[1][idx], a[2][idx], a[3][idx]] for idx, i in enumerate(a[0])]\n# print(b)","d4050680":"# def metaData(*model, X_img=None, y=None, X_train=None, X_test=None, trainMode=True):\n#     preds = []\n#     if trainMode==True:\n#         for idx, mod in enumerate(model):\n#             pred = mod.predict(X_train)\n#             print(f'mod{idx} = {pred}')\n#             preds.append(pred)\n#         newData = [[preds[0][idx], preds[1][idx], preds[2][idx], preds[3][idx]] for idx, y in enumerate(preds[0])]\n#         return newData\n#     else:\n#         for idx, mod in enumerate(model):\n#             pred = mod.predict(X_test)\n#             print(f'mod{idx} = {pred}')\n#             preds.append(pred)\n#         newData = [[preds[0][idx], preds[1][idx], preds[2][idx], preds[3][idx]] for idx, y in enumerate(preds[0])]\n#         return newData\n        \n# newData = metaData(model, model2, model4, model5,\n#             X_img=X_img, y=y, X_train=X_train,\n#             X_test=X_test, trainMode=True)\n# newTest = metaData(model, model2, model4, model5,\n#             X_img=X_img, y=y, X_train=X_train,\n#             X_test=X_test, trainMode=False)","17aca0a4":"# newData = np.array(newData, dtype='float32')\n# newData = newData.reshape(newData.shape[0], newData.shape[1], newData.shape[2], 1)\n# newTest = np.array(newTest, dtype='float32')\n# newTest = newTest.reshape(newTest.shape[0], newTest.shape[1], newTest.shape[2], 1)\n# print(newData.shape)\n# print(newTest.shape)","80c36446":"# from keras.models import Model\n# from keras.callbacks import ModelCheckpoint\n# from keras.layers import Dense, Input, Flatten, Dropout","0758d488":"# def metaNetwork(data):\n#     inputs = Input(shape=(data.shape[1], data.shape[2], data.shape[3]))\n#     flatter = Flatten()(inputs)\n#     dense = Dense(2048, activation='relu')(flatter)\n#     drop = Dropout(0.4)(dense)\n#     dense2 = Dense(1024, activation='relu')(drop)\n#     drop2 = Dropout(0.8)(dense2)\n#     out = Dense(50, activation='softmax')(drop2)\n    \n#     metaModel = Model(inputs=inputs, outputs=out)\n#     return metaModel\n\n# meta = metaNetwork(newData)\n\n    ","9e17f5ac":"# meta.compile(\n#     optimizer='adam',\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy'])","7891576e":"# meta.summary()","194d44f1":"# filepath = \"metaModel.hdf5\"\n# checkpoint2 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n# callbacks_list = [checkpoint2]\n# metaHistory = meta.fit(\n#     newData,\n#     y_train,\n#     batch_size=128,\n#     epochs=60,\n#     shuffle=True,\n#     callbacks=callbacks_list,\n#     validation_data=(newTest, y_test))","13073061":"# !tar chvfz notebook.tar.gz model2.hdf5  #for downloading","ad8c2012":"\n# for numb, file in enumerate(os.listdir()): #for clearing working directory\n#     try:\n#         os.remove(file)\n#     except IsADirectoryError:\n#         continue","ff440708":"# **LOADING GENERATED MODELS**","59a34bb5":"# **USING GENERATED MODELS**","f2cd4b40":"# **UTILITIES**","594382a4":"# BUIDING MODEL"}}