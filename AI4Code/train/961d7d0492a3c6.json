{"cell_type":{"c5c89840":"code","cbf1b3e8":"code","d3088794":"code","bfdb3c16":"code","4239977c":"code","97a38d71":"code","2d487776":"code","9f9816cb":"code","ef564bfe":"code","bc803498":"code","d259b5e3":"markdown","c1a06b20":"markdown","e51498b8":"markdown","0baf94ff":"markdown","fc0a32bc":"markdown","89141581":"markdown","128e6192":"markdown","01210f8f":"markdown","e51032f2":"markdown"},"source":{"c5c89840":"import os\nimport pathlib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","cbf1b3e8":"# Load CSV with filepaths and labels\nsports_df = pd.read_csv('..\/input\/sportsdataset\/sports-dataset\/sports.csv')\n# Check the number of classes\nlen(np.unique(sports_df.labels))","d3088794":"# Plot class distribution\nclass_counts = sports_df.labels.value_counts()\nfig, axs = plt.subplots()\nfig.set_size_inches(24, 8)\nfig.suptitle('Class Distribution', fontsize=24)\nsns.countplot(x=sports_df.labels)\naxs.tick_params(labelrotation=90)\nplt.show()","bfdb3c16":"# Select 12 random classes and visualize a sample\nclasses = np.random.choice(np.unique(sports_df.labels), size=12)\nfig, axs = plt.subplots(2, 6)\nfig.set_size_inches(24, 8)\nfig.suptitle('Sample Visualization', fontsize=24)\naxs = axs.flatten()\n# Iterate over classes and load a random image of that class\nfor i,c in enumerate(classes):\n    img_path = '..\/input\/sportsdataset\/sports-dataset\/' + np.random.choice(sports_df[sports_df['labels']==c].filepaths)\n    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    axs[i].imshow(img)\n    axs[i].set(title=c)\nplt.show()","4239977c":"train_path = '..\/input\/sportsdataset\/sports-dataset\/train'\nBATCH_SIZE = 64\n\ntrain_datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.2, height_shift_range=0.2,\n                                   horizontal_flip=True, validation_split=0.3)\nval_datagen = ImageDataGenerator(validation_split=0.3)\n\ntrain_data = train_datagen.flow_from_directory(train_path, target_size=(224, 224), color_mode='rgb', batch_size=BATCH_SIZE, \n                                               class_mode='categorical', shuffle=True, subset='training') \nval_data = val_datagen.flow_from_directory(train_path, target_size=(224, 224), color_mode='rgb', batch_size=BATCH_SIZE, \n                                           class_mode='categorical', shuffle=False, subset='validation')","97a38d71":"# Create Input Layer\ninput_layer = keras.layers.Input(shape=(224,224,3))\n\n# Add ResNet50 model and the corresconding preprocessing layer\npreprocess_layer = keras.applications.resnet50.preprocess_input(input_layer)\ntransfer_net = keras.applications.ResNet50(weights='imagenet', input_tensor=preprocess_layer, include_top=False)\n\n# Fix the weights of the ResNet Model\ntransfer_net.trainable = False\n\n# Flatten the output of the transfer net and add Dropout + Classifier layers\nflatten_layer = keras.layers.Flatten()(transfer_net.output)\ndropout_layer = keras.layers.Dropout(rate=0.5)(flatten_layer)\nclf_layer = keras.layers.Dense(units=100, activation=keras.activations.softmax)(dropout_layer)\n\n# Create the final Keras model using input and final output layer\nmodel = keras.Model(name='Sports-Model', inputs=[input_layer], outputs=[clf_layer])\n\n# Compile the model and print summary\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\nmodel.summary()","2d487776":"early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, min_delta=0.001)\nhistory = model.fit(train_data, validation_data=val_data, epochs=100, callbacks=[early_stopping])","9f9816cb":"# Plot the training history\nfig, axs = plt.subplots(2)\nfig.suptitle('Trainings History', fontsize=24)\nfig.set_size_inches(24,8)\nfor i, param in enumerate(['loss', 'accuracy']):\n    axs[i].plot(history.epoch, history.history[param], label=f'train_{param}')\n    axs[i].plot(history.epoch, history.history[f'val_{param}'], label=f'val_{param}')\n    axs[i].legend()\n    axs[i].set(xlabel='Epoch', ylabel=param.title(), xlim=(0, np.max(history.epoch)-1))\nplt.show()","ef564bfe":"class_lookup = pd.read_csv('..\/input\/sportsdataset\/sports-dataset\/class_dict.csv', index_col='class_index')\n\n# Set the path to the test folder and fetch test files\ntest_path = '..\/input\/sportsdataset\/sports-dataset\/images to predict\/'\ntest_files = os.listdir(test_path)\n\n# Create plots\nfig, axs = plt.subplots(1,6)\nfig.set_size_inches(24,5)\nfig.suptitle('Prediction of Test Images', fontsize=24)\naxs = axs.flatten()\n\n# Iterate over test images and predict each of them\nfor i, test_file in enumerate(test_files):\n    img_path = test_path + test_file\n    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    pred = class_lookup.at[np.argmax(model.predict(img.reshape(1,224,224,3))), 'class']\n    axs[i].imshow(img)\n    axs[i].set(title=f'Prediction - {pred.title()}')\nplt.show()","bc803498":"# Select some random samples of the training data and let the model predict them\nclasses = np.random.choice(np.unique(sports_df.labels), size=18)\nfig, axs = plt.subplots(3, 6)\nfig.set_size_inches(24, 12)\nfig.suptitle('Evaluation of Model Predictions', fontsize=24)\naxs = axs.flatten()\n\n# Iterate over classes and load a random image of that class\nfor i,c in enumerate(classes):\n    img_path = '..\/input\/sportsdataset\/sports-dataset\/' + np.random.choice(sports_df[sports_df['labels']==c].filepaths)\n    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    pred = class_lookup.at[np.argmax(model.predict(img.reshape(1,224,224,3))), 'class']\n    axs[i].imshow(img)\n    axs[i].set(title=f'Prediction - {pred.title()}')\nplt.show()","d259b5e3":"## Summary\nOverall, the set goal was achieved and a model was successfully trained using transfer learning to recognize the sport based on incoming image data. In order to really evaluate the performance of the model, the next step would be to collect more new images of the sports and predict them from the model. ","c1a06b20":"## Import the required libraries\nBefore the actual work on the data can begin, the packages required for this must be imported. In this case, these are basic packages such as `os` and `pathlib`, `Matplotlib` and `Seaborn` for data visualization, and `TensorFlow` and `Keras` for data processing and training of the model.","e51498b8":"# Sport Image Classification using Transfer Learning\nBased on the given dataset, a model is to be trained using transfer learning to recognize the sport based on the image. This notebook contains the following steps which build on each other:\n\n1. Explore the data\n2. Prepare the data\n3. Create the model\n4. Train the model\n5. Evaluate the model\n\nAlong the individual chapters, it is explained which steps are carried out and why they are important. In the end, the most important findings are presented in a short summary.\n\n**Objective:** Transfer learning is used to train a model that recognizes which sport it is based on a picture.","0baf94ff":"### **Learnings**\n- The dataset contains 100 different classes\n- The distribution of classes is roughly balanced, with Sky Surfing having significantly fewer samples than other classes\n- The images all have the same resolution of 224x224 pixels","fc0a32bc":"## 1. Explore the Data\nThe purpose of data exploration is to get an overview of the data set and, if necessary, to uncover characteristics that can influence the data processing and later the training of the models. The code blocks below answer the following questions, among others:\n\n- How many different classes can be found?\n- What is the distribution of the data among the individual classes?\n- Do the images have additional order units and in which form are they available?\n- How do individual samples look visualized?\n\n**Objective of the section:** To provide an overview of the data set and generate initial insights that will be useful in the next steps.","89141581":"## 2. Prepare the Data\nAfter data exploration, the next step is to prepare the data for training the models and put it into a suitable form for this purpose. In this case, the dataset contains image data, so it is transformed into a TensorFlow dataset using the `ImageDataGenerator` from TensorFlow. Here, 30% of the data is used to validate the training, and the remaining 70% is used to train the model. \nThe training data is always slightly modified via data augmentation to avoid overfitting. Especially in transfer learning with large networks, it can otherwise happen very quickly that models do not extract the real features of a class, but learn all individual images by heart and can thus achieve a high score on the training data - but not on unknown test data. Data augmentation uses the following parameters:\n\n- **rotation_range** - Randomly rotate images left or right up to 15 degrees\n- **width_shift_range & height_shift_range** - Random shifting of the image to the left and right and\/or up and down\n- **horizontal_flip** - Random horizontal flipping of the images\n\nThe images are loaded directly in the size 224x224 pixels with three color channels, since this is the common input form for neural networks in the context of image classification. The labels are encoded as categorical values and are accordingly available as a one-hot-encoded tensor.\n\n**Objective of the section:** To bring the data into a suitable form for the transfer learning task.","128e6192":"## 5. Evaluate the model\nThe last step is to verify that the training of the model was successful and that truly universal features of the individual classes were extracted. Therefore, the following two tests are performed:\n\n1. First, the test images available in the dataset are used to make predictions on completely new images to test the model. However, it is important to note that of the eight available images, a large number belong to the basketball class.\n\n2. In order to evaluate the performance of the model on different classes, images are again loaded from the training data and fed into the model for prediction. The model has already seen these images in the training, but due to the data augmentation always in a slightly different form. Thus, it can be checked once again whether the model has learned general features or simply images.\n\n**Objective of the section:** To validate the training went well and the model learning overall features of the classes.","01210f8f":"## 3. Create the Model\nThe next step is to create a TensorFlow model that will later process and classify the images. As already mentioned, transfer learning will be used. This term refers to the use of pre-trained models that are then adapted to one's own problem. \nIn this case the pre-trained model is the ResNet50 architecture (more information here) with weights based on the ImageNet dataset. To ensure that the data is in the correct form before it is fed into the pre-trained model, an appropriate pre-process layer is inserted - this transforms the incoming data into the correct form (including standardization and order of color channels).\nFurther layers are then connected to the ResNet model to further process and finally classify the outgoing data (Dense Layer with 100 neurons and Softmax activation function).\n\nFinally, the model is compiled: The Optimizer Adam is used as well as Categorical Crossentropy as Loss and Accuracy as Metric.\n\n**Objective of the section:** To create a trainable Keras Model including a pretrained ResNet50 model.","e51032f2":"## 4. Train the Model\nSubsequently, the model can be trained based on the created training and validation datasets. Only the weights of the last layer are adjusted and optimized, since the `transfer_net.trainable = False` statement in the previous code block fixed the weights within the ResNet.\n\nIn addition to the data augmentation on the training data, EarlyStopping is used to prevent the overfitting of the model and to abort the training if the accuracy on the validation data does not improve further in the course of 5 epochs.\n\n**Objective of the section:** To train the created model that it can subsequently make general predictions well."}}