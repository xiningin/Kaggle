{"cell_type":{"32bf8e66":"code","4dfed063":"code","0444c050":"code","fa740e2f":"code","d91bb124":"code","2c438e5e":"code","9778bfcd":"code","8d744d3e":"code","4805b9f8":"code","a08d44fa":"code","e53050ad":"code","117092f0":"code","05dcc821":"code","39965695":"code","f233e253":"code","b0460283":"code","615368ce":"code","1252f325":"code","e930ce7b":"markdown","1f8fdba0":"markdown","5ee9f6b7":"markdown","eabdd918":"markdown","a413a60a":"markdown","328dc86b":"markdown","ffac1092":"markdown","b8e31bf3":"markdown","1a8cc6c3":"markdown","85b45f81":"markdown","eeca1a73":"markdown","56b9d370":"markdown","901ad00d":"markdown","8f48eef5":"markdown"},"source":{"32bf8e66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4dfed063":"# Import Libraries\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom decimal import Decimal\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings('ignore')","0444c050":"# Load the data\nball_by_ball_data = pd.read_csv(\"..\/input\/ipl-complete-dataset-20082020\/IPL Ball-by-Ball 2008-2020.csv\")\nmatch_data = pd.read_csv(\"..\/input\/ipl-complete-dataset-20082020\/IPL Matches 2008-2020.csv\")","fa740e2f":"match_data.head()","d91bb124":"# Plot the wins distribution\nplt.figure(figsize=(12,8))\nsns.countplot(data=match_data, x='winner', order = list(match_data['winner'].value_counts().index))\nplt.xticks(rotation=-90)\nplt.show()","2c438e5e":"# Rename Rising Pune Supergiant as Rising Pune Supergiants\nmatch_data['team1'] = match_data['team1'].apply(lambda x : 'Rising Pune Supergiants' if x == 'Rising Pune Supergiant' else x)\nmatch_data['team2'] = match_data['team2'].apply(lambda x : 'Rising Pune Supergiants' if x == 'Rising Pune Supergiant' else x)\nmatch_data['winner'] = match_data['winner'].apply(lambda x : 'Rising Pune Supergiants' if x == 'Rising Pune Supergiant' else x)\nmatch_data['toss_winner'] = match_data['toss_winner'].apply(lambda x : 'Rising Pune Supergiants' if x == 'Rising Pune Supergiant' else x)","9778bfcd":"match_data['winner'].value_counts()","8d744d3e":"# Lets calculate the winning probability of each team\n\ndef winning_probability(team):\n    \n    '''\n    Note: Here, I am considering the winning probability as the ratio of number of matches won by a team to the number of matches played.\n    '''\n    \n    # Extract the data for the given team\n    team_data = match_data[(match_data['team1'] == team) | (match_data['team2'] == team)]\n\n    # Calculate the total number of matches played, won and lost\n    total_matches_played = team_data.shape[0]\n    total_matches_won = team_data[team_data['winner'] == team].shape[0]\n    total_matches_lost = team_data[team_data['winner'] != team].shape[0]\n\n    # Calculate the winning and losing probability\n    \n    '''\n    Here, the winning and losing probabilities is taken as follows:\n    \n    Winning Probability = Total Matches Won\/ Total Matches Playes\n    Losing Probability = Total Matches Lost\/ Total Matches Played \n    '''\n    winning_probability = total_matches_won\/total_matches_played\n    losing_probability = total_matches_lost\/total_matches_played\n     \n    # Print the results for the given team\n    print(\"Winning Probability for {} is {:.3f}\".format(team, winning_probability))\n    print(\"Losing Probability for {} is {:.3f}\".format(team, losing_probability))\n\n    print()\n    return winning_probability, losing_probability","4805b9f8":"# Function to compute the Probability Mass Function of a Binomila Distribution\n\ndef compute_binomial_probability(x, n, p):\n    \n    '''\n    x = Number of events\n    n = Total number of trials\n    p = Winning probability(success)\n    '''\n    \n    PMF = (math.factorial(n)*math.pow(p, x)*math.pow((1-p), (n-x)))\/(math.factorial(x)*math.factorial(n-x))\n    return PMF\n\n# Function to plot the Binomial Distribution\ndef plot_binomial_distribution(team, n, p):\n    \n    '''\n    n = Total Number of Trials\n    p = Success Probability\n    '''\n    \n    probabilities = list(map(lambda x: compute_binomial_probability(x, n, p), range(0, n+1)))\n    max_probability = max(probabilities)\n    max_matches_won = probabilities.index(max_probability) + 1\n    plt.style.use('seaborn')\n    plt.bar(list(range(0, n+1)), probabilities)\n    plt.xticks(np.arange(1, n+1, 2))\n    plt.title(team)\n    plt.xlabel(\"Number of Matches\")\n    plt.ylabel(\"Probability\")\n    \n    return max_matches_won","a08d44fa":"# Calculate the Winning and Losing Probability Distribution for each team and plot the binomial distributions for 50 Matches\n\nIPL_teams = match_data['team1'].unique().tolist()\n\n# Dictionary to store the winning and losing probabilities for a given team\nwinning_probability_map = {}\nlosing_probability_map = {}\n\nfor team in IPL_teams:\n    team_win_prob, team_lose_prob = winning_probability(team)\n    winning_probability_map[team] = team_win_prob\n    losing_probability_map[team] = team_lose_prob","e53050ad":"# Plot the distribution for 50 matches\nmax_team_matches = {}\nn = 20\nplt.figure(figsize=(20, 40))\nfor i, team in enumerate(IPL_teams):\n    plt.subplot(7, 2, i+1)\n    max_team_matches[team] = plot_binomial_distribution(team, n, winning_probability_map[team])","117092f0":"# Plot the teams with matches\nsorted_matches_team = dict([(team[0], max_team_matches[team[0]]) for team in sorted(max_team_matches.items(), key = lambda x : x[1])])\nplt.barh(y=list(sorted_matches_team.keys()), width=list(sorted_matches_team.values()))\nplt.xlabel(\"Number of Matches\")\nplt.ylabel(\"IPL Teams\")\nplt.show()","05dcc821":"# Poisson Distribution is a special case of Binomial Theorem, or we can say a limiting case of Binomial theorem. When number of trials are tending to inifinte and the success probability is small. Such Events are called Rare Events\ndata_binom = stats.poisson.rvs(mu=4, size=10000)\nax = sns.distplot(data_binom,\n                  kde=True,\n                  color='green',\n                  hist_kws={\"linewidth\": 25,'alpha':1})\nax.set(xlabel='Poisson', ylabel='Frequency')\nplt.show()","39965695":"# Using Scipy to generate Normal Distribution\nrandom_var = stats.norm.rvs(size=1000, random_state=3)\n\n# plot the normal distribution (Bell Shaped Curve)\nsns.distplot(random_var)\nplt.show()","f233e253":"# Proof\nmu = random_var.mean()\nsigma = random_var.std()\n\n# Compute intervals on the basis of first, second and third standard deviations\n\n# 1. First Std dev\nfirst_std_1 = mu + sigma\nfirst_std_2 = mu - sigma\n\n# 2. Second Std dev\nsecond_std_1 = mu + 2*sigma\nsecond_std_2 = mu - 2*sigma\n\n# 3. Third Std dev\nthird_std_1 = mu + 3*sigma\nthird_std_2 = mu - 3*sigma\n\n# Separate the data into 3 parts i.e within the first, second and third deviations\n\ndata_1 = random_var[(random_var < first_std_1) & (random_var > first_std_2)]\ndata_2 = random_var[(random_var < second_std_1) & (random_var > second_std_2)]\ndata_3 = random_var[(random_var < third_std_1) & (random_var > third_std_2)]\n\n# Print the %age of data in the variables data_1,data_2 and data_3\nprint(\"Percentage of data between first standard deviations {} %\".format(data_1.shape[0]*100\/random_var.shape[0]))\nprint(\"Percentage of data between second standard deviations {} %\".format(data_2.shape[0]*100\/random_var.shape[0]))\nprint(\"Percentage of data between third standard deviations {} %\".format(data_3.shape[0]*100\/random_var.shape[0]))","b0460283":"# Plot the emperical rule\nfigure, ax = plt.subplots(1,1, figsize=(15,8))\nsns.kdeplot(random_var, ax=ax)\nax.axvline(first_std_1, linestyle= 'dashed', c = 'green', alpha=0.5, label='First Standard Deviation')\nax.axvline(first_std_2, linestyle= 'dashed', c = 'green', alpha=0.5)\nax.axvline(second_std_1, linestyle= 'dashed', c = 'orange', alpha=0.5, label='Second Standard Deviation')\nax.axvline(second_std_2, linestyle= 'dashed', c = 'orange', alpha=0.5)\nax.axvline(third_std_1, linestyle= 'dashed', c = 'red', alpha=0.5, label='Third Standard Deviation')\nax.axvline(third_std_2, linestyle= 'dashed', c = 'red', alpha=0.5)\nplt.legend(loc='best')\nplt.title(\"Gaussian Distribution Emperical Rule\")\nplt.show()","615368ce":"exp_dist = stats.expon.rvs(size=1000)\nplt.hist(exp_dist)\nplt.show()","1252f325":"fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n\nqq_plot_1 = stats.probplot(exp_dist, dist='expon', plot=ax[0])\nqq_plot_2 = stats.probplot(exp_dist, dist='norm', plot=ax[1])\nax[0].set_title(\"QQ Plot for Exponential Distribution\")\nax[1].set_title(\"QQ Plot for Normal Distribution\")\nplt.show()","e930ce7b":"<p style= \"font-size : 20px ; color : Crimson\">I hope you found this notebook helpful. Please do give me a feedback in the comment section and do upvote it if you liked it. Thanks!!","1f8fdba0":"# Normal Distribution","5ee9f6b7":"<p style = \"color : red ; font-size : 20px\"> In this notebook, I discuss the following topics:\n\n* Binomial Distribution\n* Poisson Distribution\n* Normal Distribution\n* Exponential Distribution\n* How to confirm the distribution of a variable. \n","eabdd918":"# Probablity Distributions\n\n**In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events (subsets of the sample space).**\n\n**For instance, if X is used to denote the outcome of a coin toss (\"the experiment\"), then the probability distribution of X would take the value 0.5 (1 in 2 or 1\/2) for X = heads, and 0.5 for X = tails (assuming that the coin is fair). Examples of random phenomena include the weather conditions at some future date, the height of a randomly selected person, the fraction of male students in a school, the results of a survey to be conducted, etc.**\n\n**Source:** https:\/\/en.wikipedia.org\/wiki\/Probability_distribution","a413a60a":"* From the above QQ Plots we can understand how to understand and confirm the distributions of varibales.\n* The first QQ plot confirms that the probability distribution is Exponential.\n* The second QQ plot confirms that the probability distirbution is not Normal.","328dc86b":"**In probability theory, Exponential Distribution describes the waiting time in a Poisson process. For example, How long until lighting strikes your city? The key assumption here is, The waiting time is independent of the time you have already waited.**\n\n**The Probability Distribution Function of an exponential distribution is given as:**\n\n![image.png](attachment:038aa14a-f501-460a-ad60-eac8ffc3d2ac.png)","ffac1092":"# Exponential Distribution","b8e31bf3":"**The Normal (Gaussian) Distribution is a type of Continuous Probability Distribution of a Real-Values Random Variable. If the mean of the distribution is $\\mu$ and the standard deviation of the distribution is $\\sigma$ then the Probability Density Function of the Normal Distribution is given by:**\n\n![image.png](attachment:844a5b6b-b443-4ea5-a9b5-8a95a10e9fc1.png)","1a8cc6c3":"**If the Mean $\\mu$ is 1 and the Standard Deviation $\\sigma$ is 0 then the Normal Distribution is called Standard Normal Distribution.**\n\n**Some of the Real Life examples where Normal Distribution is observed are:**\n\n* Height of People in the world\n* Income Distribution in a economy\n* Shoe sizes\n* Student Performances(marks)\n* Birth Weight of children","85b45f81":"## How to confirm the distribution of a variable?\n\n### QQ Plot\n\n**In statistics, a Q\u2013Q (quantile-quantile) plot is a probability plot, which is a graphical method for comparing two probability distributions by plotting their quantiles against each other. First, the set of intervals for the quantiles is chosen. A point (x, y) on the plot corresponds to one of the quantiles of the second distribution (y-coordinate) plotted against the same quantile of the first distribution (x-coordinate). Thus the line is a parametric curve with the parameter which is the number of the interval for the quantile.**","eeca1a73":"# Binomial Distribution\n\n**The binomial distribution is used when there are exactly two mutually exclusive outcomes of a trial. These outcomes are appropriately labeled \"success\" and \"failure\". The binomial distribution is used to obtain the probability of observing x successes in N trials, with the probability of success on a single trial denoted by p. The binomial distribution assumes that p is fixed for all trials.**\n\n**Binomial distributions must also meet the following three criteria:**\n\n* The number of observations or trials is fixed. In other words, you can only figure out the probability of something happening if you do it a certain number of times. This is common sense\u2014if you toss a coin once, your probability of getting a tails is 50%. If you toss a coin a 20 times, your probability of getting a tails is very, very close to 100%.\n\n* Each observation or trial is independent. In other words, none of your trials have an effect on the probability of the next trial.\n\n* The probability of success (tails, heads, fail or pass) is exactly the same from one trial to another.","56b9d370":"# Poisson Distribution","901ad00d":"# Emperical Rule\n\nThere are several reasons that Normal Distribution is so popular, one because it is one of the most common distributions observed in real world. Second, requires the least math, lol and third, because of the Emperical Rule. The Emperical Rule tells us what percentage of data will lie between certain intervals. It can be stated as follows:\n\n1. 67% of the data lies between first standard deviation.\n2. 95% of the data lies between second standard deviation.\n3. 99.7% of the data lies between third standard deviation.","8f48eef5":"# PMF of Binomial Distribution is given by:\n\n![image.png](attachment:ba95a1c4-0fb4-4f9e-8d32-a5e5e4d165d8.png)"}}