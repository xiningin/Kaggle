{"cell_type":{"3cff9091":"code","64204cbd":"code","88f3121a":"code","8b69454f":"code","0acbef27":"code","3b416a36":"code","3092aeea":"code","3f0e6ab3":"code","ae57334f":"code","1e2f6a87":"code","25b11de3":"code","608f3795":"code","1864a1b2":"code","dac589f8":"code","cb75fc05":"code","0764883a":"code","2d42f33b":"code","c71f690d":"code","0ea7aa6f":"code","9eae5413":"code","05c7d59a":"code","5a3e2bb5":"code","e012c346":"code","0e1b8a50":"code","d7d4fd68":"code","4acc31a0":"code","036ccb38":"code","173ac9e9":"code","bc6292e9":"code","a4322d02":"code","7a54e250":"code","010f6d47":"code","d13f99e7":"code","cea4260d":"code","79fbabc3":"code","e09e380c":"code","9d57ae16":"code","77765a77":"code","ddc248b1":"markdown","cd00f13f":"markdown","2be72269":"markdown","db880835":"markdown","f0ddbf55":"markdown","386e9d1d":"markdown","3938aa03":"markdown","54756ea4":"markdown","aafd3d30":"markdown","8124238d":"markdown"},"source":{"3cff9091":"# Loading Libraries\nimport torch \nimport torch.nn as nn\nimport torchvision \nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nimport numpy as np\nimport matplotlib.pyplot as plt","64204cbd":"# Model to device\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","88f3121a":"transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(0.2),\n                                transforms.ToTensor(),\n                                transforms.Resize((80,80))\n                               ])\n\ndataset = torchvision.datasets.ImageFolder(root = '..\/input\/flowers-recognition\/flowers\/flowers',\n                                           transform = transform)\nprint(\"No of Classes: \", len(dataset.classes))\n\ntrain, val = torch.utils.data.random_split(dataset, [3000, 1323])\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train,\n                                           batch_size = 32, \n                                           shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(dataset = val,\n                                         batch_size = 32, \n                                         shuffle = True)\n","8b69454f":"examples = enumerate(val_loader)\nbatch_idx, (example_data, example_targets) = next(examples)\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nfor i in range(6):\n  plt.subplot(2,3,i+1)\n  plt.tight_layout()\n  plt.imshow(example_data[i].numpy().transpose())\n  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n  plt.xticks([])\n  plt.yticks([])","0acbef27":"Accuracies = []","3b416a36":"class ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer5 = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.fc1 = nn.Linear(2*2*1024, 256)\n        self.fc2 = nn.Linear(256, 512)\n        self.fc3 = nn.Linear(512, 5)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc1(out)\n        out = F.dropout(out, training=self.training)\n        out = self.fc2(out)\n        out = F.dropout(out, training=self.training)\n        out = self.fc3(out)\n        return F.log_softmax(out,dim=1)\n","3092aeea":"model = ConvNet().to(device)","3f0e6ab3":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","ae57334f":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\n\nfor epoch in range(40):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    model.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = model(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    model.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = model(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","1e2f6a87":"plt.plot(range(40),Loss)\nplt.plot(range(40),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","25b11de3":"plt.plot(range(40),Acc)\nplt.plot(range(40),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","608f3795":"# Test the model\n\nmodel.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = model(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n        \n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))\n","1864a1b2":"transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(0.2),\n                                transforms.ToTensor(),\n                                transforms.Resize((224,224))\n                               ])\n\ndataset = torchvision.datasets.ImageFolder(root = '..\/input\/flowers-recognition\/flowers\/flowers',\n                                           transform = transform)\nprint(\"No of Classes: \", len(dataset.classes))\n\ntrain, val = torch.utils.data.random_split(dataset, [3000, 1323])\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train,\n                                           batch_size = 32, \n                                           shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(dataset = val,\n                                         batch_size = 32, \n                                         shuffle = True)\n","dac589f8":"alexnet = torchvision.models.alexnet(pretrained=True)","cb75fc05":"alexnet","0764883a":"alexnet.classifier[6].out_features = 5\nfor param in alexnet.features.parameters(): \n    param.requires_grad = False\n\nalexnet = alexnet.cuda()","2d42f33b":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)","c71f690d":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(20):\n  acc = 0\n  val_acc = 0\n\n  for i, (images, labels) in enumerate(train_loader):\n    alexnet.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = alexnet(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    alexnet.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = alexnet(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  \n\n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","0ea7aa6f":"plt.plot(range(20),Loss)\nplt.plot(range(20),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","9eae5413":"plt.plot(range(20),Acc)\nplt.plot(range(20),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","05c7d59a":"# Test the model\n\nalexnet.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = alexnet(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))\n","5a3e2bb5":"vgg = torchvision.models.vgg19(pretrained=True)","e012c346":"vgg","0e1b8a50":"vgg.classifier[6].out_features = 5\nfor param in vgg.features.parameters(): \n    param.requires_grad = False\n\nvgg = vgg.cuda()","d7d4fd68":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg.parameters(), lr=0.001)","4acc31a0":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(20):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    vgg.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    vgg.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","036ccb38":"plt.plot(range(20),Loss)\nplt.plot(range(20),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","173ac9e9":"plt.plot(range(20),Acc)\nplt.plot(range(20),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","bc6292e9":"# Test the model\n\nvgg.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = vgg(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))\n","a4322d02":"resnet = torchvision.models.resnet34(pretrained=True)","7a54e250":"resnet","010f6d47":"ftr = resnet.fc.in_features\nresnet.fc = nn.Linear(ftr, 5)\n\nresnet = resnet.cuda()","d13f99e7":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)","cea4260d":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(10):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    resnet.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    resnet.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","79fbabc3":"plt.plot(range(10),Loss)\nplt.plot(range(10),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","e09e380c":"plt.plot(range(10),Acc)\nplt.plot(range(10),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","9d57ae16":"# Test the model\n\nmodel.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = resnet(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))\n","77765a77":"# Comparision of Accuracies of different models\n\nplt.plot(range(4), Accuracies, color='green', linestyle='dashed', linewidth = 3, \n         marker='o', markerfacecolor='blue', markersize=12) \nplt.ylabel('Acc')\nplt.xlabel('Models')\nplt.title(\"Accuracies\")\nplt.xticks(range(4), ['Custom CNN', 'Alexnet', 'Vgg19', 'Resnet34'])\nplt.show()","ddc248b1":"### Resnet 34","cd00f13f":"## Transfer Learning ","2be72269":"# FLOWER CLASSIFICATION\n\n> Comparision between accuracies of different models.\n>\n> Model Used:\n+ Custom CNN\n+ Pretrained Alexnet\n+ Pretrained Vgg 19\n+ Pretrained Resnet 34","db880835":"********************","f0ddbf55":"************************","386e9d1d":"*******************","3938aa03":"### Alexnet","54756ea4":"### VGG 19","aafd3d30":"## Custom CNN","8124238d":"*************"}}