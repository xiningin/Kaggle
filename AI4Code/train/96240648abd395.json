{"cell_type":{"aa6e2f66":"code","8fc6db3a":"code","d1713f1b":"code","5959c6aa":"code","52487748":"code","8319d76f":"code","9d053d56":"code","77c8c0ea":"code","2dde2569":"code","d14e5aa1":"code","a87a1d5b":"code","bb637919":"code","c192781a":"code","2bee8ad8":"code","9f160c3a":"code","e9fb3ec1":"code","a4e4d41a":"code","ba616903":"code","de7f3a60":"code","2e807aa7":"code","f87fc1f8":"code","50413216":"code","f131eace":"code","10aa2de7":"code","22fd4cb8":"code","2f72a8d1":"code","d0c6f4e8":"code","3f124f7d":"code","68241c1f":"code","3218a7c1":"code","c5dd3041":"code","60bfbd72":"code","432d4cd3":"code","6600126d":"code","6f553d67":"code","6280a276":"code","859364b3":"code","39a42982":"code","bd0d42ab":"markdown","bc951aad":"markdown","aef99c01":"markdown","65eb63d9":"markdown","fa1afbf9":"markdown"},"source":{"aa6e2f66":"!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","8fc6db3a":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","d1713f1b":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom PIL import Image\nimport time\nfrom tqdm.notebook import tqdm\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.utils as xu\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, random_split, DataLoader\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","5959c6aa":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/'\nTRAIN_DIR = DATA_DIR + \"\/\" + \"train\"\nTEST_DIR = DATA_DIR + \"\/\" + \"test\"\nTRAIN_CSV = DATA_DIR +\"\/\" + \"train.csv\"","52487748":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()\n","8319d76f":"labels = {\n  0: 'Mitochondria',\n  1: 'Nuclear bodies',\n  2: 'Nucleoli',\n  3: 'Golgi apparatus',\n  4: 'Nucleoplasm',\n  5: 'Nucleoli fibrillar center',\n  6: 'Cytosol',\n  7: 'Plasma membrane',\n  8: 'Centrosome',\n  9: 'Nuclear speckles'\n}","9d053d56":"def encode_labels(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target","77c8c0ea":"def decode_labels(target, thresh=0.5, return_label=False):\n    result = []\n    for i, tgt in enumerate(target):\n        if tgt > thresh:\n            if return_label:\n                result.append(str(i) + \":\" + labels[i] + \"\/\")\n            else:\n                result.append(str(i))     \n    return result","2dde2569":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","d14e5aa1":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.losses =[]\n        self.F1 =[]\n        self.its = []\n\n    def append(self, loss, F1, it):\n        self.losses.append(loss)\n        self.F1.append(F1)\n        self.its.append(it)","a87a1d5b":"def save_checkpoint(model, is_best, filename='data\/checkpoint.pth'):\n    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n    if is_best:\n        xm.save(model.state_dict(), filename)  # save checkpoint\n    else:\n        print (\"=> Validation Accuracy did not improve\")","bb637919":"def load_checkpoint(model, filename = 'data\/checkpoint.pth'):\n    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n    names = set(model.state_dict().keys())\n    for n in list(sd.keys()):\n        if n not in names and n+'_raw' in names:\n            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n            del sd[n]\n    model.load_state_dict(sd)","c192781a":"class ProteinDataset(nn.Module):\n        def __init__(self, root_dir, label_df, transforms=None):\n            assert(os.path.exists(root_dir))\n            self.root_dir = root_dir\n            self.label_df = label_df\n            self.transforms = transforms\n\n        def __len__(self):\n            return len(self.label_df)\n\n        def __getitem__(self, idx):\n            row = self.label_df.loc[idx]\n            img_id, label = row['Image'], row['Label']\n            img = Image.open(self.root_dir + \"\/\" + str(img_id) + \".png\")\n            if self.transforms:\n                img = self.transforms(img)\n            return img, encode_labels(label)","2bee8ad8":"mean = [0.0793, 0.0530, 0.0545]\nstd = [0.1290, 0.0886, 0.1376]","9f160c3a":"normalize = transforms.Normalize(mean=mean, std=std)","e9fb3ec1":"train_stats = AvgStats()\ntest_stats = AvgStats()","a4e4d41a":"def get_model():\n    model = models.resnet34(pretrained=True)\n    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10)\n    for param in model.parameters():\n        param.require_grad = True\n    return model","ba616903":"# Only instantiate model weights once in memory.\nSERIAL_EXEC = xmp.MpSerialExecutor()\nWRAPPED_MODEL = xmp.MpModelWrapper(get_model())","de7f3a60":"def fit(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    \n    bs = flags['bs']\n    epochs = flags['epochs']\n    seed = flags['seed']\n\n    set_seed(seed)\n\n    val_pct = 0.10\n\n    msk = np.random.rand(len(train_df)) < (1- val_pct)\n\n    train_split_df = train_df[msk].reset_index()\n    val_split_df = train_df[~msk].reset_index()\n\n    def F_score(output, label, threshold=0.5, beta=1, eps=1e-12):\n        beta2 = beta**2\n\n        y_pred = torch.ge(output.float(), threshold).float()\n        y_true = label.float()\n\n        true_positive = (y_pred * y_true).sum(dim=1)\n        precision = true_positive.div(y_pred.sum(dim=1).add(eps))\n        recall = true_positive.div(y_true.sum(dim=1).add(eps))\n\n        return torch.mean(\n            (precision*recall).\n            div(precision.mul(beta2) + recall + eps).\n            mul(1 + beta2))\n\n    \n\n    def get_dataset():\n        train_tf = transforms.Compose([\n            transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n            transforms.RandomHorizontalFlip(), \n            transforms.RandomRotation(10),\n            transforms.ToTensor(),\n            normalize\n        ])\n\n        valid_tf = transforms.Compose([\n            transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n            transforms.ToTensor(),\n            normalize\n        ])\n\n        train_ds = ProteinDataset(TRAIN_DIR, train_split_df, train_tf)\n        valid_ds = ProteinDataset(TRAIN_DIR, val_split_df, valid_tf)\n        return train_ds, valid_ds\n\n    train_ds, valid_ds = SERIAL_EXEC.run(get_dataset)\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_ds,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True\n    )\n\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_ds,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False)\n\n    train_loader = DataLoader(train_ds, bs, sampler=train_sampler, num_workers=1, pin_memory=True)\n    valid_loader = DataLoader(valid_ds, bs, sampler=valid_sampler, num_workers=1, pin_memory=True)\n\n    device = xm.xla_device()\n    model = WRAPPED_MODEL.to(device)\n\n    criterion = nn.BCELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2*xm.xrt_world_size(), momentum=0.9, weight_decay=5e-4)\n\n    def train(epoch, model, loader, optimizer, criterion):\n        tracker = xm.RateTracker()\n        model.train()\n        running_loss = 0.\n        running_F1 = 0.\n        start_time = time.time()\n        #t = tqdm(loader, leave=False, total=len(loader))\n\n        for i, (ip, tgt) in enumerate(loader):\n            optimizer.zero_grad()\n            #ip, tgt = ip.to(device), tgt.to(device)                                    \n            output = torch.sigmoid(model(ip))\n            loss = criterion(output, tgt)\n            running_loss += loss.item()\n            \n            # compute gradient and do SGD step\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n            xm.optimizer_step(optimizer)\n\n            # Append outputs\n            running_F1 += F_score(output, tgt)\n\n        trn_time = time.time() - start_time        \n        trn_F1 = running_F1\/len(loader)\n        trn_losses = running_loss\/len(loader)\n        return trn_F1, trn_losses, trn_time\n\n    def test(model, loader, criterion):\n        with torch.no_grad():\n            model.eval()\n            running_loss = 0.\n            running_F1 = 0.\n            start_time = time.time()\n            #t = tqdm(loader, leave=False, total=len(loader))\n\n            for i, (ip, tgt) in enumerate(loader):\n                #ip, tgt = ip.to(device), tgt.to(device)\n                output = torch.sigmoid(model(ip))\n                loss = criterion(output, tgt)\n                running_loss += loss.item()\n                running_F1 += F_score(output, tgt)\n\n            val_time = time.time() - start_time\n            F1_score = running_F1\/len(loader)\n            val_F1 = F1_score\n            val_losses = running_loss\/len(loader)\n            return val_F1, val_losses, val_time\n\n    best_F1 = 0\n    sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n    for j in range(1, epochs+1):\n        para_loader = pl.ParallelLoader(train_loader, [device])\n        trn_F1, trn_losses, trn_time = train(j, model, para_loader.per_device_loader(device), optimizer, criterion)\n        train_stats.append(trn_losses, trn_F1, trn_time)\n        para_loader = pl.ParallelLoader(valid_loader, [device])\n        val_F1, val_losses, val_time = test(model, para_loader.per_device_loader(device), criterion)\n        test_stats.append(val_losses, val_F1, val_time)\n        if val_F1 > best_F1:\n            save_checkpoint(model, True, '.\/best_model.pth')\n        sched.step()\n        print(\"Epoch::{}, Trn_loss::{:06.8f}, Val_loss::{:06.8f}, Trn_F1::{:06.8f}, Val_F1::{:06.8f}\"\n            .format(j, trn_losses, val_losses, trn_F1, val_F1))","2e807aa7":"flags = dict()","f87fc1f8":"flags['epochs'] = 15\nflags['bs'] = 16\nflags['seed'] = 7","50413216":"xmp.spawn(fit, args=(flags,), nprocs=8, start_method='fork')","f131eace":"def predict(loader, device):\n    with torch.no_grad():\n        torch.cuda.empty_cache()\n        model.eval()\n        preds = []\n        t = tqdm(loader, leave=False, total=len(loader))\n        for i, (ip, _) in enumerate(t):\n            ip = ip.to(device)\n            output = torch.sigmoid(model(ip))\n            preds.append(output.cpu().detach())\n        preds = torch.cat(preds)\n        return [\" \".join(decode_labels(pred)) for pred in preds]","10aa2de7":"TEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'","22fd4cb8":"test_df = pd.read_csv(TEST_CSV)","2f72a8d1":"test_tf = transforms.Compose([\n    transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n    transforms.ToTensor(),\n    normalize\n])","d0c6f4e8":"test_ds = ProteinDataset(TEST_DIR, test_df, test_tf)","3f124f7d":"device = xm.xla_device()","68241c1f":"model = WRAPPED_MODEL.to(device)","3218a7c1":"load_checkpoint(model, '.\/best_model.pth')","c5dd3041":"test_loader = DataLoader(test_ds, 32, num_workers=4, pin_memory=True)","60bfbd72":"preds = predict(test_loader, device)","432d4cd3":"preds","6600126d":"len(preds), len(test_df)","6f553d67":"sub_df = pd.read_csv(TEST_CSV)","6280a276":"sub_df['Label'] = preds","859364b3":"sub_df.head()","39a42982":"sub_df.to_csv('submission.csv', index=False)","bd0d42ab":"# Global Variables","bc951aad":"PyTorch\/XLA is a Python package that uses the XLA deep learning compiler to connect the PyTorch deep learning framework and Cloud TPUs.\n\nLet's download nightly build for xla.","aef99c01":"# CSV Loader and Helper Functions","65eb63d9":"# Model Fit","fa1afbf9":"# Model"}}