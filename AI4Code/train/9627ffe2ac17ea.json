{"cell_type":{"4be98145":"code","4d3e2a51":"code","3c72c34e":"code","621a864c":"code","ce75e5fc":"code","8ffadb8b":"code","01f3b0cf":"code","681c3908":"code","7d2b2920":"code","556b77cb":"code","ac818cd0":"code","1cbf5070":"code","e919d881":"code","fec45e65":"code","da8491bd":"code","298e42a6":"markdown","2ed53d8b":"markdown","7e06dbee":"markdown"},"source":{"4be98145":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4d3e2a51":"data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv',usecols=['id','text','target'])\ndata.head()","3c72c34e":"from sklearn import preprocessing\nfrom keras.layers import Input,Dense,Embedding,LSTM,Dropout,Activation\nfrom keras.layers import Bidirectional,GlobalMaxPool1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","621a864c":"data.text.values","ce75e5fc":"embedded_size = 100\nmax_features = 10000\nmaxlen = 100","8ffadb8b":"test = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ntest_X = test.text.values","01f3b0cf":"from sklearn.model_selection import train_test_split\ntrain_df ,val_df = train_test_split(data,test_size = 0.1 , random_state = 43)\ntrain_X = train_df.text.values\nval_X = val_df.text.values","681c3908":"tokenizer = Tokenizer(num_words = max_features)\ntokenizer.fit_on_texts(list(train_X))\ntrain_X = tokenizer.texts_to_sequences(train_X)\nval_X = tokenizer.texts_to_sequences(val_X)\ntest_X = tokenizer.texts_to_sequences(test_X)\n","7d2b2920":"train_X = pad_sequences(train_X, maxlen=maxlen)\nval_X = pad_sequences(val_X, maxlen=maxlen)\ntest_X = pad_sequences(test_X, maxlen=maxlen)","556b77cb":"train_y = train_df.target.values\nval_y = val_df.target.values","ac818cd0":"from keras.models import Model\n\ninp = Input(shape = (maxlen,))\nx = Embedding(max_features,embedded_size)(inp)\nx = Bidirectional(LSTM(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16,activation='relu')(x)\nx = Dropout(0.1)(x)\nx = Dense(1,activation = 'sigmoid')(x)\nmodel = Model(inputs = inp,outputs = x)\nmodel.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n\nprint(model.summary())","1cbf5070":"model.fit(train_X, train_y, batch_size=512, epochs=10, validation_data=(val_X, val_y))","e919d881":"preds = model.predict([test_X],batch_size = 1024,verbose = 1)","fec45e65":"predictions = (preds > 0.5).astype(int)\npredictions = np.ndarray.flatten(predictions)","da8491bd":"sub2= pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\nsub2['target'] = predictions\nsub2.to_csv(\"submission3.csv\", index=False)\nsub2.head()","298e42a6":"Thanks to LazyProgrammer \n\n**Pls Upvote if you got to know something new today.**\n\n**Keep Learning** ** ;)  **","2ed53d8b":"You can also use GRU ","7e06dbee":"This is a Kernel Done with **LSTM** no pretrained embeddings its for those who want to  get started with predictive model for NLP task \nVersion 1 of this kernel https:\/\/www.kaggle.com\/omfuke123\/lstm-no-pretrained-model?scriptVersionId=27708815 consist of predictive model with **LogisticRegression** Go and checkout that too so you will get some idea."}}