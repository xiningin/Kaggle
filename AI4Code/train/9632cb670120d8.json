{"cell_type":{"3e41c9ec":"code","3fc859ff":"code","edb9ceca":"code","b9090a3b":"code","960b4f9f":"code","3141661c":"code","adcdfba6":"code","d34c7e1c":"code","c63f963f":"code","3a52a2e4":"code","e1a7cf41":"code","102c7ceb":"code","ea409797":"code","9363e839":"code","31ec0b6b":"code","3f958cbf":"code","c4e2c87b":"code","c11cb60a":"code","00a7ab6b":"code","db9ee43b":"code","b32cc617":"code","eda389a0":"code","70e1192f":"code","6843005f":"code","8f4156ba":"code","6e7b14af":"code","0de5b68d":"code","34e3a3ad":"code","c8e05e15":"code","f224cc98":"code","47768891":"code","6dc50e6f":"code","d6b0e14e":"code","cdf00414":"code","d5fa1d2d":"code","a888bb75":"code","dfc0e4fb":"code","5b306536":"markdown","494138c2":"markdown","13b8c08c":"markdown","9b040aa0":"markdown","69b4e4ac":"markdown","d8e15142":"markdown","4964b879":"markdown","b37a5689":"markdown","a1ec4b3e":"markdown","4c7aab9c":"markdown","ff95d4d1":"markdown","adf82680":"markdown","60f318bf":"markdown","8f9913d4":"markdown","e3ebb36b":"markdown","a3646583":"markdown","1df2ed82":"markdown","9b5e9865":"markdown","5b975773":"markdown","dfdfa5b1":"markdown","c0cfd6dd":"markdown","f19ddeee":"markdown","9f574472":"markdown","3a1a6dd7":"markdown","5a134fe1":"markdown","9e2a6b47":"markdown","56fea62c":"markdown","80749bd7":"markdown","603f609a":"markdown","b9e2ef08":"markdown","10a4079b":"markdown","0a825287":"markdown","75987753":"markdown","d9a0d289":"markdown","e4adbc26":"markdown","0a3db035":"markdown","9f3f6fc3":"markdown","de80386c":"markdown","e358553f":"markdown","e3afe721":"markdown","90af4202":"markdown","8a3c6afd":"markdown"},"source":{"3e41c9ec":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#core imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3fc859ff":"#load dataset and assign it to a variable\nvehicles=pd.read_csv(\"..\/input\/vehicle-dataset-from-cardekho\/car data.csv\")","edb9ceca":"#use the 'head' method to show the first five rows of the table as well as their names. \nvehicles.head() ","b9090a3b":"vehicles.info()","960b4f9f":"vehicles.isnull().sum()","3141661c":"vehicles.describe()","adcdfba6":"sns.barplot(x='Owner',y='Selling_Price',data=vehicles,palette='spring')","d34c7e1c":"sns.barplot(x='Transmission',y='Selling_Price',data=vehicles,palette='spring')","c63f963f":"sns.barplot(x='Fuel_Type',y='Selling_Price',data=vehicles,palette='spring')","3a52a2e4":"sns.barplot(x='Seller_Type',y='Selling_Price',data=vehicles,palette='spring')","e1a7cf41":"plt.figure(figsize=(10,10))\nsns.lmplot(x='Kms_Driven',y='Selling_Price',data=vehicles)","102c7ceb":"plt.figure(figsize=(10,10))\nsns.lmplot(x='Present_Price',y='Selling_Price',data=vehicles)","ea409797":"#creating a new column 'Vehicle_Age' and storing the age of the vehicles to establish a direct relationship between the age and selling price\nvehicles['Vehicle_Age']=2020- vehicles['Year']\n\n#check out the newly added column\nvehicles.head(10)","9363e839":"plt.figure(figsize=(10,10))\nsns.regplot(x='Vehicle_Age',y='Selling_Price',data=vehicles)","31ec0b6b":"#using Pandas' built in function 'get_dummies()' to swiftly map the categorical values to integers like (0\/1\/2\/3....)\nvehicles=pd.get_dummies(vehicles,columns=['Fuel_Type','Transmission','Seller_Type'],drop_first=True)\n\n#dropping the Year column since it becomes redundant and irrelevant after Vehicle_Age column\nvehicles.drop(columns=['Year'],inplace=True)\n\n#check out the dataset with new changes\nvehicles.head()","3f958cbf":"sns.pairplot(vehicles)","c4e2c87b":"correlations = vehicles.corr()\n\nindx=correlations.index\nplt.figure(figsize=(26,22))\nsns.heatmap(vehicles[indx].corr(),annot=True,cmap=\"YlGnBu\")\n","c11cb60a":"# We're splitting up our data set into groups called 'train' and 'test'\nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(0)\nvehicles_train,vehicles_test = train_test_split(vehicles, test_size=0.3, random_state=100)\n\n# We'll perform feature scaling to ensure normalization of the data within a particular range.\n#Sometimes, it also helps in speeding up the calculations in an algorithm.\nfrom sklearn.preprocessing import StandardScaler\n\nscaler= StandardScaler()\n\n#features we need to scale are assigned as a list.\nvar=['Selling_Price','Present_Price','Kms_Driven','Vehicle_Age']\n\n#scaling the training data(fitting the parameters and transforming the values)\nvehicles_train[var]=scaler.fit_transform(vehicles_train[var])\n\n#transforming the test data.We avoid fitting the values to prevent data leakage!\nvehicles_test[var]=scaler.transform(vehicles_test[var])\n\n#We will toss out the Car_Name column from training and test data because it only has text info that the linear regression model can't use!\n\nX_test=vehicles_test.drop(columns=['Car_Name','Selling_Price'],axis=1)\ny_test=vehicles_test['Selling_Price']\n\nX_train=vehicles_train.drop(columns=['Car_Name','Selling_Price'],axis=1)\ny_train=vehicles_train['Selling_Price']","00a7ab6b":"from sklearn.linear_model import LinearRegression\n\nlm=LinearRegression()\n\nlm.fit(X_train,y_train)","db9ee43b":"# print the intercept of best-fit line\nprint(lm.intercept_)","b32cc617":"# temp here stores the numerical columns from the vehicles dataset that influence the prediction\ntemp=vehicles.drop(columns=['Car_Name','Selling_Price'])\n\ncoeff_df = pd.DataFrame(lm.coef_,temp.columns,columns=['Coefficient'])\ncoeff_df ","eda389a0":"predictions=lm.predict(X_test)\n\n\nfig = plt.figure()\n# Plot-label\nfig.suptitle('y_test vs predictions')\n\n#X-label\nplt.xlabel('y_test')\n\n# Y-label\nplt.ylabel('predcitions')\nplt.scatter(y_test,predictions)","70e1192f":"fig=plt.figure(figsize=(8,8))\n  \nsns.distplot((y_test-predictions),bins=20)\n\n#Plot Label\nfig.suptitle('Residual Analysis', fontsize = 20)           ","6843005f":"from sklearn import metrics\n\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","8f4156ba":"R2 = metrics.r2_score(y_test,predictions)\nR2","6e7b14af":"# Import xgboost ensemble model\nimport xgboost\n\n#core import for hyperparamter tuning\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#creates a xgbRegressor object\nregressor=xgboost.XGBRegressor()\n","0de5b68d":"#Hyperparamter_Tuning\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","34e3a3ad":"# Set up the random search with 5-fold cross validation\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=parameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 3,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)\n\n#train on the RandomSearchCv object to get best estimators\nrandom_cv.fit(X_train,y_train)","c8e05e15":"#getting the best estimators\nrandom_cv.best_estimator_","f224cc98":"#getting the best params\nrandom_cv.best_params_","47768891":"# reinitializing the regressor object with the best probable estimators\nregressor=xgboost.XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=5,\n             min_child_weight=2, missing=np.nan, monotone_constraints='()',\n             n_estimators=1100, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","6dc50e6f":"# fitting the xgbRegressor on our training data\nregressor.fit(X_train,y_train)","d6b0e14e":"# fetching the predictions on our test data\npredictions2=regressor.predict(X_test)","cdf00414":"fig = plt.figure()\n# Plot-label\nfig.suptitle('y_test vs predictions(XGBRegressor)')\n\n#X-label\nplt.xlabel('y_test')\n\n# Y-label\nplt.ylabel('predcitions2')\nplt.scatter(y_test,predictions2)","d5fa1d2d":"fig=plt.figure(figsize=(8,8))\n  \nsns.distplot((y_test-predictions2),bins=20)\n\n#Plot Label\nfig.suptitle('Residual Analysis', fontsize = 20)           ","a888bb75":"print('MAE:', metrics.mean_absolute_error(y_test, predictions2))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions2))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions2)))","dfc0e4fb":"R2 = metrics.r2_score(y_test,predictions2)\nR2","5b306536":"**Visualizing the relationship between Target Variable[Selling price] against Kms Driven,Present_Price and Vehicle age :**\n## 1. Kms Driven","494138c2":"## 4. Seller Type\nLet's get an idea of the selling price for a vehicle sold by a Dealer vs Individual!","13b8c08c":"**Above is a concise summary of our dataframe printing columns' data-type,index data-type and number of non-null values !**","9b040aa0":"**It seems the selling price decreases overall for older\/ageing vehicles!**","69b4e4ac":"## 3. Vehicle Age","d8e15142":"# Training our Linear Regression Model\n\nLet's now begin to train out regression model! We will need to first split up our data into an vehicles_train array that contains the part of dataset used for training data, and a vehicles_test array used for test data.","4964b879":"**Looking at the above 5 rows of data we need to develop an understanding of every column to efficiently continue exploring the dataset further.\nWe need to have a clear understanding of every feature defined in the data-set and what it is trying to convey!**","b37a5689":"### Core Imports","a1ec4b3e":"**Selling Price tends to increase gradually with an increase in the Present Price of the vehicle.**","4c7aab9c":"**Visualizing the categorical data :**\n## 1. Owner Type\nLet's examine the selling price based on the type of owner","ff95d4d1":"## Exploratory Data Analysis(EDA)\nLet's create some simple plots to check out the data!","adf82680":"## Check out the Data\n**We will run some exploratory analysis on our cardekho dataset now that it is loaded in the vehicles variable.We would check for the shape of the dataset, any missing or null values and will try to find out the correlation amongst the dataset features.\nLet's Begin!**","60f318bf":"## Feature Engineering\nWe shall convert categorical features to numeric type!","8f9913d4":"## 2. Present Price","e3ebb36b":"**We have a beautiful analysis of our numerical columns which gives us the count,mean,std and other such values to have a clear idea of the values in our dataset. Helps in scaling!**","a3646583":"**The selling price is found to be higher for vehicles with less kms covered under the belt!**","1df2ed82":"**Diesel Engine Vehicles are found to have the highest selling price amongst Petrol and CNG engine vehicles**","9b5e9865":"## 4. Predictions from our Model\nLet's grab predictions off our test set and see how well it did!","5b975773":"## Imports\n\n\n1. Let's get our environment ready with the libraries we'll need and then import the relevant ones beforehand!\n2. Pandas is one of the most widely used python libraries in data science. It provides high-performance, easy to use structures and data analysis tools.\n3. Matplotlib is a plotting library for the Python programming language\n4. Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.","dfdfa5b1":"# Thank You\n\n* This is my first Kaggle Notebook. Please do point out any irregularities if found ! \n* Don't forget to leave your valuable feedback in the comments below.Thank You!","c0cfd6dd":"**We can see tha automatic vehicles are found to have a large resale value in the market compared to manual transmission.**","f19ddeee":"## Understanding and Visualizing Correlations amongst the features","9f574472":"## 1. Train Test Split","3a1a6dd7":"## 2. Transmission Type\nLet's examine the selling price for manual and automatic vehicles! ","5a134fe1":"**It seems that the vehicles belonging to owner 0 have the highest selling price**","9e2a6b47":"## 3. Model Evaluation\nLet's evaluate the model by checking out it's coefficients and how we can interpret them.[](http:\/\/)","56fea62c":"## 6. Conclusions\n\n* Present price of a car directly influences Selling Price prediction. Both are highly correlated and here directly proportional to each other.\n* Resale value of Automatic vehicle is more than that of a Manual vehicle.\n* Car age is effecting negatively as the Selling Price decreases for an older car.\n* Resale value of cars with Fuel type Diesel is higher.\n\n### XGBRegressor performs considerably better than Linear Regression with a R2 score of 0.85 compared to .8316.","80749bd7":"## Correlation HeatMap","603f609a":"**Dealers can sell vehicles at a higher selling price than a general individual. No surprises at all !**","b9e2ef08":"* The pair plot technique allows us to visualize distributions of individual numerical features, as well as correlations\/relationships between numerical features. \n* Selling price seems to be considerably correlated with the Present Price feature.","10a4079b":"### Tuning and Training the Model","0a825287":"# Vehicle-Price-PredictorOnCarDekho\n\n## Introduction\n**The objective of this kernel is to use an example of vehicles and help reach a good r2 score using basic regression model upon various Data.viz techniques.**\n\n**Hence,for instance, we get data from the car website CarDekho.com, filled with information on a wide variety of cars, including their selling price and present price. We realize that we can use this data to make sure we get a good deal on a new car. In particular, we can figure out exactly how much one should pay for a specific type of car. \nNow Comes the Linear Regression to our rescue!**\n\n**Linear Regression is a method for discovering the relationship between two variables in the dataset, such as price of the car and the year it was made. Data Scientists rely on this method for solving a wide range of problems, especially when it comes to prediction.**\n\n1. I have used a simplified Linear Regression model with sufficient data analysis and feature engineering to reach the desired r2 score of [.831].\n2. Do keep monitoring this kernel for future versions,improvements and to check the implementation of some newer and advanced regression models !\n3. Do UpVote the Notebook if you find it helpful !\n\n## About the dataset\n**This dataset contains information about used cars listed on www.cardekho.com\nThis data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.\nThe columns in the given dataset is as follows:**\n* Car_Name\n* Year\n* Selling_Price\n* Present_Price\n* Kms_Driven\n* Fuel_Type\n* Seller_Type\n* Transmission\n* Owner","75987753":"## 5. Regression Evaluation Metrics\nHere are three common evaluation metrics for regression problems:\n\n**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n\n$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n\n**Mean Squared Error** (MSE) is the mean of the squared errors:\n\n$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n\n**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n\n$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n\nComparing these metrics:\n\n- **MAE** is the easiest to understand, because it's the average error.\n- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n\nAll of these are **loss functions**, because we want to minimize them.","d9a0d289":"**Residual Histogram**","e4adbc26":"## 2. Creating and Training the Model\n\n- Using Linear Regression Method","0a3db035":"### XGBRegressor() Model Evaluation and Predictions","9f3f6fc3":"# Update:Implementing Advanced Regression(XGBoost Regression) ","de80386c":"**Looking at the result of the above query it seems clear we have no missing\/null values in our dataset!**","e358553f":"## 3. Fuel Type\nLet's examine the selling price based on different types of engine fuel!","e3afe721":"* Fuel attribute is now divided into two new attributes where '01' denotes Petrol, '10' denotes Diesel and '00' denotes CNG.\n* Transmission attribute is mapped to Transmission_Manual where '1' denotes Manual and '0' Automatic.\n* Seller_Type attribute is mapped to Seller_Type_Individual where '1' denotes Seller_Type_Dealer  and '0' Seller_Type_Individual.\n","90af4202":"### Interpreting the coefficients:\n\n**For numerical features:**\n* Holding all other features fixed, a 1 unit increase in Present_Price is associated with an increase of 0.742.\n* Holding all other features fixed, a 1 unit increase in Kms_Driven is associated with a decrease of .0411.\n* Holding all other features fixed, a 1 unit increase in Vehicle_Age means decrease in 0.22764.","8a3c6afd":"## Fetching the Data\n**Using Pandas to load the dataset into this notebook. Using pandas we can read our datafile (car data.csv) with the line below. Data-set loaded will be assigned to the variable vehicles.**"}}