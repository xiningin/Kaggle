{"cell_type":{"4bfbcb17":"code","949302c6":"code","737e8ddb":"code","8f7cd9ba":"code","28043aa6":"code","80f7156b":"code","9ec4881d":"code","45c80a39":"code","6f6a27e0":"code","40b9fce3":"code","e5b2aa2c":"code","a1636d90":"code","31eb3e68":"code","52aa6de3":"code","75f2e91f":"code","ad13cc2b":"code","fb08a6f7":"code","3167944b":"code","e3b430b8":"code","32a3075a":"code","3ab094a0":"code","f3136622":"code","071eb8f7":"code","93280047":"code","23a740b3":"code","fd5c16d9":"code","e1849adc":"code","8888d4d7":"markdown","d627b83a":"markdown","dbe03234":"markdown","9950bd9e":"markdown","fe1e2c2f":"markdown","c885d3c7":"markdown"},"source":{"4bfbcb17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","949302c6":"import tensorflow as tf\nfrom tensorflow.keras import layers as L\n\nfrom matplotlib import pyplot as plt","737e8ddb":"train_df = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/test.csv\")\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/sample_submission.csv\")","8f7cd9ba":"train_df.head(2)","28043aa6":"start_features = [f for f in train_df.columns if \"start\" in f]\nstop_features = [f for f in train_df.columns if \"stop\" in f]\n\nfeatures_in = stop_features+[\"delta\"]","80f7156b":"idx = 3\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nfig.suptitle(f'Delta: {train_df.loc[idx, \"delta\"]}')\nax1.imshow(1-(train_df.loc[idx, start_features].values).reshape(25, 25), cmap=\"gray\")\nax1.set_title(\"Start Setting\")\nax2.imshow(1-(train_df.loc[idx, stop_features].values).reshape(25, 25), cmap=\"gray\")\nax2.set_title(\"Stop Setting\")","9ec4881d":"@tf.function\ndef _features_to_img(features):\n    \n    return tf.cast(features, tf.float32)\n\nclass LifeSet(tf.keras.utils.Sequence):\n\n    def __init__(self, df:pd.DataFrame, is_train:bool, batch_size:int=32):\n        self.df = df\n        self.is_train=is_train\n        self.batch_size = batch_size\n        \n        if is_train:\n            self.stop = df.loc[:, stop_features].values.reshape(-1, 25, 25, 1)\n            self.start = df.loc[:, start_features].values.reshape(-1, 25, 25, 1)\n            self.delta = df.loc[:, \"delta\"]\n            \n        else:\n            self.stop = df.loc[:, stop_features].values.reshape(-1, 25, 25, 1)\n            self.delta = df.loc[:, \"delta\"]\n\n    def __len__(self):\n        return len(self.df)\n    \n\n    def __getitem__(self, idx):\n        \n        print(idx)\n        \n        if self.is_train:\n            \n            batch_x = self.stop[idx*self.batch_size:(idx+1)*self.batch_size]\n            deltas = self.delta[idx*self.batch_size:(idx+1)*self.batch_size]\n            batch_y = self.start[idx*self.batch_size:(idx+1)*self.batch_size]\n\n            return [deltas, _features_to_img(batch_x)], _features_to_img(batch_y)\n        \n        else:\n            \n            batch_x = self.stop[idx*self.batch_size:(idx+1)*self.batch_size]\n            deltas = self.delta[idx*self.batch_size:(idx+1)*self.batch_size]\n            \n            return {\n                \"delta\":deltas,\n                \"stop\":_features_to_img(batch_x)\n            }","45c80a39":"bs=1 #Setting Batch size to 1 as the model involves a loop over delta\ntrain_set = LifeSet(train_df, is_train=True, batch_size=bs)\ntest_set = LifeSet(test_df, is_train=False, batch_size=bs)","6f6a27e0":"tr_data = next(iter(train_set))\ntst_data = next(iter(test_set))","40b9fce3":"tr_df = tf.data.Dataset.from_tensor_slices((\n    (train_df[\"delta\"].values, train_df[stop_features].values.reshape(-1, 25, 25, 1).astype(float)), \n    train_df[start_features].values.reshape(-1, 25, 25, 1).astype(float)))\n\ntr_df = tr_df.batch(128)\n\n","e5b2aa2c":"tst_df = tf.data.Dataset.from_tensor_slices((\n    (test_df[\"delta\"].values, test_df[stop_features].values.reshape(-1, 25, 25, 1).astype(float)), ))\n\ntst_df = tst_df.batch(128)","a1636d90":"tst_df","31eb3e68":"class LifeModel(tf.keras.Model):\n    \n    def __init__(self):\n        super(LifeModel, self).__init__()\n        \n        \n        self.encoder = L.Conv2D(32, kernel_size=(3,3), padding=\"SAME\")\n        self.memory = tf.keras.models.Sequential([\n            L.Conv2D(128, kernel_size=(3,3), padding=\"SAME\"),\n            L.BatchNormalization(),\n            L.ReLU(),\n            \n            L.Conv2D(32, kernel_size=(3,3), padding=\"SAME\"),\n            L.BatchNormalization(),\n            L.ReLU(),\n        ])\n        self.decoder = L.Conv2D(1, kernel_size=(3,3), padding=\"SAME\")\n        \n    def call(self, inputs):\n        \n        #print(inputs)\n        \n        delta = inputs[0]\n        stop_state = inputs[1]\n        \n        print(tf.reshape(delta, (-1,1)))\n        \n        x = self.encoder(stop_state-0.5)\n        x = tf.nn.relu(x)\n        \n        print(x.shape)\n        \n        #TODO: make this custom for each delta in a batch. \n        #Maybe a custom train_step in keras  model\n        for i in range(tf.reduce_max(delta)):\n            x += self.memory(x)\n        \n        x = self.decoder(x)\n        #x = tf.nn.relu(x)\n        x = tf.math.sigmoid(x)\n        \n        return x","52aa6de3":"model = LifeModel()\nmodel.compile(loss=\"bce\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n\n#ps = model(tr_data[0])\n#ps.shape","75f2e91f":"model.fit(tr_df, epochs=50)","ad13cc2b":"tr_data = next(iter(tr_df))","fb08a6f7":"ps = model(tr_data[0])","3167944b":"ps.shape","e3b430b8":"idx = 5\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3)\nfig.suptitle(\"Delta: \"+str(tr_data[0][0][idx]))\n\nax1.imshow(1-(tr_data[0][1][idx].numpy().reshape(25, 25)), cmap=\"gray\")\nax1.set_title(\"Stop Setting\")\n\nax2.imshow(1-(tr_data[1][idx].numpy().reshape(25, 25)), cmap=\"gray\")\nax2.set_title(\"Start Setting\")\n\nax3.imshow(1-(ps[idx]>=0.5).numpy().reshape(25, 25), cmap=\"gray\")\nax3.set_title(\"Predicted Setting\")","32a3075a":"ps = model.predict(tst_df, verbose=1)\nplt.imshow(1-(ps[0]>=0.5).reshape(25, 25), cmap=\"gray\")","3ab094a0":"test_df","f3136622":"THRESH = 0.5\n\nps_=(ps>=THRESH).astype(int).reshape(test_df.shape[0], -1)","071eb8f7":"ps_.shape","93280047":"sample_submission","23a740b3":"sub = test_df[[\"id\"]].copy()\ntmp = pd.DataFrame(ps_, columns=start_features)\nsub = sub.join(tmp)","fd5c16d9":"sub.head()","e1849adc":"sub.to_csv(\"submission.csv\", index=False)","8888d4d7":"### Let's plot a sample","d627b83a":"### Generating output","dbe03234":"### Why CNNs?\n\nthe fundamental of this problem deals with surrounding blocks. Kernels in CNNs are better suited for this task as they can sense the changes in surrounding blocks. => less filters with added sense of sequences.\n\n### Adding a sense of Seqence to the Network\n\nMaybe combine CNN+LSTM or something new","9950bd9e":"Something like CNN+Sequences or Auto-regressive CNNs with final target","fe1e2c2f":"#### Keras dataset Sequence","c885d3c7":"### Let's take some samples"}}