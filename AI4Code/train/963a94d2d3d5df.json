{"cell_type":{"1a3ce984":"code","aa799712":"code","4bec83c0":"code","d79443c6":"code","878f39fc":"code","5b47887d":"code","7fca0d72":"code","c3af4811":"code","49ff83ef":"code","8cbb74c0":"code","a40c1049":"code","7afa3f6c":"code","124dccf0":"code","93545f91":"code","72a22009":"code","7186feb3":"code","6319906a":"code","30aafb9b":"markdown"},"source":{"1a3ce984":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa799712":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.info()","4bec83c0":"train_df.info()","d79443c6":"train_df.describe()","878f39fc":"train_df.head(5)","5b47887d":"# See what is the order of surviving classes\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","7fca0d72":"# See which gender survive more\ntrain_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","c3af4811":"def predict_survival(df):\n    # Drop'PassengerId','Name'and 'Ticket' Features\n    df=df.drop(['PassengerId','Name','Ticket'],axis=1)\n    \n    #Split data to numerical\n    df_numeric = df.select_dtypes(exclude = ['object']) #numerical only\n    df_numeric = df_numeric.fillna(df_numeric.median())\n    \n    #Split data to catgrical\n    df_cat = df.select_dtypes(include = ['object']) #categorical only\n    df_cat = df_cat.fillna(\"zero\")\n    for col in df_cat.columns:\n        df_cat[col] = LabelEncoder().fit_transform(df_cat[col])  \n\n    df_total = pd.concat([df_cat, df_numeric] , axis=1)\n    return df_total","49ff83ef":"final_df=predict_survival(train_df)\nfinal_df.head()","8cbb74c0":"ID=test_df['PassengerId']\nfinal_test=predict_survival(test_df)\nfinal_test.info()","a40c1049":"X_train = final_df.drop(\"Survived\", axis=1)\nY_train = final_df[\"Survived\"]","7afa3f6c":"print(X_train.info())\nX_train.head()","124dccf0":"# Using LogisticRegression Model\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, Y_train)\n#Y_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","93545f91":"# Support Vector Machines Model\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\n#Y_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","72a22009":"# Using KNN Model\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\n#Y_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","7186feb3":"# Using Random Forest Model\n\nrandom_forest = RandomForestClassifier(n_estimators=90)\nrandom_forest.fit(X_train, Y_train)\n#Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","6319906a":"final_y_test = random_forest.predict(final_test) \noutput = pd.DataFrame({'PassengerId': ID,\n                       'Survived': final_y_test})\noutput.to_csv('submission.csv', index=False)","30aafb9b":"From what I see from the steps above:\n*     Categorical Features: Survived, Sex and Embarked.\n*     Ordinal Features: Pclass.\n*     Continous: Age, Fare.\n*     Discrete: SibSp, Parch."}}