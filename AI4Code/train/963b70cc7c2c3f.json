{"cell_type":{"1d5cfd2d":"code","3c05c902":"code","460a200a":"code","168b4052":"code","e945f49a":"code","a163827b":"code","4d89b836":"code","829d40be":"code","e1258e36":"code","d7ab568b":"code","3afe3d92":"code","f536daf1":"code","9b8cfb8c":"code","5ce58762":"code","74d0d35a":"code","03f765b6":"code","8b215e1c":"code","d6c38325":"code","1359a751":"code","792606d1":"code","2ca92cb4":"code","d2a6dd47":"code","d08d2a38":"code","26263eb6":"code","14b04a2f":"code","bcc66bfb":"code","c16cae9a":"markdown"},"source":{"1d5cfd2d":"%run ..\/input\/python-recipes\/cidhtml.py\nidhtml('Code Modules, Functions, & Classes')","3c05c902":"import warnings; warnings.filterwarnings('ignore')\nimport pandas as pd,numpy as np\nimport h5py,imageio,os,torch,pylab as pl\nimport tensorflow_hub as th,tensorflow as tf\nimport tensorflow.keras.layers as tkl\nimport tensorflow.keras.callbacks as tkc\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image as tkimg\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom torchvision import transforms,utils,models\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom PIL import Image\ndev=torch.device('cuda:0' \\\nif torch.cuda.is_available() else 'cpu')\nfrom IPython.core.magic import register_line_magic\nprint('tensorflow version:',tf.__version__)","460a200a":"def images2array(files_path,img_size,grayscale=False):\n    files_list=sorted(os.listdir(files_path))\n    n,img_array=len(files_list),[]\n    for i in range(n):\n        if i%round(.1*n)==0:\n            print('=>',end='',flush=True)\n        img_path=files_path+files_list[i]\n        if (img_path[-4:]=='.png'):\n            img=tkimg.load_img(\n                img_path,grayscale=grayscale,\n                target_size=(img_size,img_size))\n        img=tkimg.img_to_array(np.squeeze(img))\n        img=np.expand_dims(img,axis=0)\/255\n        img_array.append(img)\n    return np.array(np.vstack(img_array),dtype='float32')\nclass HorseBreedsData(tds):\n    def __init__(self,csv_path,img_dir,transform=None):\n        df=pd.read_csv(csv_path,index_col=0)\n        self.img_dir=img_dir\n        self.csv_path=csv_path\n        self.img_paths=df['path']\n        self.y=df['label'].values\n        self.transform=transform\n    def __getitem__(self,index):\n        img=Image.open(os.path\\\n        .join(self.img_dir,self.img_paths[index]))\n        img=img.convert('RGB')\n        if self.transform is not None: \n            img=self.transform(img)\n        lbl=self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","168b4052":"@register_line_magic\ndef display_examples(data):\n    for images,labels in dataloaders[data]:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,3)\n        fig=pl.figure(figsize=(9,3))\n        for i in range(n,n+4):\n            ax=fig.add_subplot(1,4,i-n+1,\\\n            xticks=[],yticks=[],title=names[labels[i].item()])\n            ax.imshow(np.transpose(images[i],(1,2,0)))\n        pl.tight_layout(); pl.show()    \n        break\n@register_line_magic\ndef display_predict(data):\n    if data=='test': x=x_test; y=y_test\n    if data=='valid': x=x_valid; y=y_valid \n    kmodel.load_weights(fweights)\n    y_predict=kmodel.predict_classes(x)\n    fig=pl.figure(figsize=(9,8))\n    randch=np.random.choice(\n        x.shape[0],size=6,replace=False)\n    for i,idx in enumerate(randch):\n        ax=fig.add_subplot(2,3,i+1,xticks=[],yticks=[])\n        ax.imshow(np.squeeze(x[idx]))\n        pred_idx=y_predict[idx]; true_idx=y[idx]\n        ti='{} \\n({})'.format(\n            names[pred_idx],names[true_idx])\n        ax.set_title(ti,\\\n        color=('darkblue' if pred_idx==true_idx else 'darkred'))\n    pl.tight_layout(); pl.show()\ndef show_image(img):\n    img=utils.make_grid(img)\n    npimg=img.numpy(); tr=(1,2,0)\n    pl.figure(figsize=(9,3))\n    pl.imshow(np.transpose(npimg,tr))\n    pl.xticks([]); pl.tight_layout(); pl.show()","e945f49a":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev).long()\n        logits=model(features)\n        _,pred_labels=torch.max(logits,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100\ndef epoch_loss(model,data_loader):\n    model.eval()\n    curr_loss,num_examples=0.,0\n    with torch.no_grad():\n        for features,targets in data_loader:\n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=model(features)\n            loss=tnnf.cross_entropy(logits,targets,\n                                    reduction='sum')\n            num_examples+=targets.size(0)\n            curr_loss+=loss\n        return curr_loss\/num_examples\ndef keras_history_plot(fit_history,fig_size,color='darkblue'):\n    keys=list(fit_history.history.keys())\n    list_history=[fit_history.history[keys[i]] \n                  for i in range(len(keys))]\n    dfkeys=pd.DataFrame(list_history).T\n    dfkeys.columns=keys\n    fig=pl.figure(figsize=(fig_size,fig_size))\n    ax1=fig.add_subplot(2,1,1)\n    dfkeys.iloc[:,[0,2]].plot(\n        ax=ax1,color=['slategray',color],grid=True)\n    ax2=fig.add_subplot(2,1,2)\n    dfkeys.iloc[:,[1,3]].plot(\n        ax=ax2,color=['slategray',color],grid=True)\n    pl.tight_layout(); pl.show()","a163827b":"idhtml('Data Loaders')","4d89b836":"img_path='..\/input\/horse-breeds\/'; img_size=160\nnames=['Akhal-Teke','Appaloosa','Orlov Trotter',\n       'Vladimir Heavy Draft','Percheron',\n       'Arabian','Friesian']\nflist=sorted(os.listdir(img_path))\nlabels=[int(el[:2])-1 for el in flist]\nlabels=np.array(labels,dtype='int32')\nimages=images2array(img_path,img_size)\nN=labels.shape[0]; n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(12).shuffle(shuffle_ids)\nimages,labels=images[shuffle_ids],labels[shuffle_ids]\nx_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]\ny_test,y_valid,y_train=labels[:n],labels[n:2*n],labels[2*n:]\npd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],\n              [x_train.dtype,x_valid.dtype,x_test.dtype],\n              [y_train.shape,y_valid.shape,y_test.shape],\n              [y_train.dtype,y_valid.dtype,y_test.dtype]],               \n             columns=['train','valid','test'])","829d40be":"train_csv,valid_csv,test_csv=\\\n'train.csv','valid_csv','test.csv'\nimg_path2='..\/input'; img_size2=64\nfiles=[os.path.relpath(os.path.join(dirpath,fn),img_path2) \\\nfor (dirpath,dirnames,filenames) in os.walk(img_path2) \\\nfor fn in filenames if fn.endswith('.png')]\nd={'label':[],'breed':[],'file':[],'path':[]}\nfor f in files:\n    _,fn=f.split('\/')\n    label=int(fn[:2])-1; breed=names[label]        \n    d['label'].append(label)\n    d['breed'].append(breed)\n    d['file'].append(fn)\n    d['path'].append(f)\ndf=pd.DataFrame.from_dict(d)\nnp.random.seed(123)\nids=np.random.rand(len(df))<.8\ndf_train=df[ids]; df_test=df[~ids]\ndf_train.set_index('file',inplace=True)\ndf_train.to_csv(train_csv)\ndf_test.set_index('file',inplace=True)\ndf_test[:df_test.shape[0]\/\/2].to_csv(test_csv)\ndf_test[df_test.shape[0]\/\/2:].to_csv(valid_csv)\nnum_classes=np.unique(df['label'].values).shape[0]\nprint([num_classes,len(files)]); df_test.head()","e1258e36":"batch_size=16; num_workers=4; grayscale=False\ntrans=transforms\\\n.Compose([transforms.Resize((img_size2,img_size2)),\n          transforms.ToTensor()])\ntrain=HorseBreedsData(\n    csv_path=train_csv,img_dir=img_path2,transform=trans)\ntest=HorseBreedsData(\n    csv_path=test_csv,img_dir=img_path2,transform=trans)\nvalid=HorseBreedsData(\n    csv_path=valid_csv,img_dir=img_path2,transform=trans)\ndataloaders={'train':tdl(dataset=train,batch_size=batch_size,\n                         shuffle=True,num_workers=num_workers),\n             'test':tdl(dataset=test,batch_size=batch_size,\n                        shuffle=True,num_workers=num_workers),\n             'valid':tdl(dataset=valid,batch_size=batch_size,\n                         shuffle=True,num_workers=num_workers)}","d7ab568b":"%display_examples valid","3afe3d92":"idhtml('Classifiers')","f536daf1":"def premodel(pix,den,mh,lbl,activ,loss):\n    model=Sequential([\n        tkl.Input((pix,pix,3),name='input'),\n        th.KerasLayer(mh,trainable=True),\n        tkl.Flatten(),\n        tkl.Dense(den,activation='relu'),\n        tkl.Dropout(rate=.25),\n        tkl.Dense(512,activation='relu'),\n        tkl.Dropout(rate=.25),\n        tkl.Dense(lbl,activation=activ)])\n    model.compile(\n        optimizer='adam',metrics=['accuracy'],loss=loss)\n    return model\ndef cb(fw):\n    early_stopping=tkc.EarlyStopping(\n        monitor='val_loss',patience=20,verbose=2)\n    checkpointer=tkc.ModelCheckpoint(\n        filepath=fw,save_best_only=True,verbose=2,\n        save_weights_only=True,monitor='val_accuracy',mode='max')\n    lr_reduction=tkc.ReduceLROnPlateau(\n        monitor='val_loss',verbose=2,patience=5,factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]","9b8cfb8c":"fweights='\/checkpoints'\nhandle_base='mobilenet_v2_100_160'\nmhandle='https:\/\/tfhub.dev\/google\/imagenet\/'+\\\n        '{}\/classification\/4'.format(handle_base)\nkmodel=premodel(img_size,4096,mhandle,7,'softmax',\n                'sparse_categorical_crossentropy')\nhistory=kmodel.fit(\n    x=x_train,y=y_train,batch_size=32,epochs=50,\n    callbacks=cb(fweights),validation_data=(x_valid,y_valid))","5ce58762":"keras_history_plot(history,9)","74d0d35a":"kmodel.load_weights(fweights)\nkmodel.evaluate(x_test,y_test,verbose=0)","03f765b6":"%display_predict test","8b215e1c":"def kmodel(leaky_alpha):\n    model=Sequential()\n    model.add(tkl.Conv2D(\n        32,(5,5),padding='same', \n        input_shape=(img_size,img_size,3)))\n    model.add(tkl.LeakyReLU(alpha=leaky_alpha))    \n    model.add(tkl.MaxPooling2D(pool_size=(2,2)))\n    model.add(tkl.Dropout(.25))\n    model.add(tkl.Conv2D(196,(5,5)))\n    model.add(tkl.LeakyReLU(alpha=leaky_alpha))    \n    model.add(tkl.MaxPooling2D(pool_size=(2,2)))\n    model.add(tkl.Dropout(.25))   \n    model.add(tkl.GlobalMaxPooling2D())     \n    model.add(tkl.Dense(1024))\n    model.add(tkl.LeakyReLU(alpha=leaky_alpha))\n    model.add(tkl.Dropout(.5))     \n    model.add(tkl.Dense(7))\n    model.add(tkl.Activation('softmax'))   \n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',metrics=['accuracy'])   \n    return model\nkmodel=kmodel(.02)","d6c38325":"history=kmodel.fit(\n    x_train,y_train,epochs=200,batch_size=64,\n    validation_data=(x_valid,y_valid),\n    verbose=2,callbacks=cb(fweights))","1359a751":"keras_history_plot(history,9)","792606d1":"kmodel.load_weights(fweights)\nkmodel.evaluate(x_test,y_test,verbose=0)","2ca92cb4":"%display_predict test","d2a6dd47":"tmodel=models.vgg16(pretrained=True)\nfor param in tmodel.parameters():\n    param.requires_grad=False\ntmodel.classifier[3].requires_grad=True\ntmodel.classifier[6]=tnn.Sequential(\n    tnn.Linear(4096,512),tnn.ReLU(),\n    tnn.Dropout(.5),tnn.Linear(512,num_classes))\ntmodel=tmodel.to(dev)\noptimizer=torch.optim.Adam(tmodel.parameters())","d08d2a38":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        tmodel.train()\n        for batch_ids,(features,targets) \\\n        in enumerate(dataloaders['train']):        \n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=tmodel(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%10:\n                print ('Epoch: %03d\/%03d | Batch: %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids,\n                         len(dataloaders['train']),cost))\n        tmodel.eval()\n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d'%(epoch+1,epochs))\n            print('train acc\/loss: %.2f%%\/%.2f valid acc\/loss: %.2f%%\/%.2f'%\\\n                  (model_acc(tmodel,dataloaders['train']),\n                   epoch_loss(tmodel,dataloaders['train']),\n                   model_acc(tmodel,dataloaders['valid']),\n                   epoch_loss(tmodel,dataloaders['valid'])))","26263eb6":"%train_run 11","14b04a2f":"tmodel.eval()\nwith torch.set_grad_enabled(False):\n    print('train acc: %.2f%% || test acc: %.2f%%'%\\\n          (model_acc(tmodel,dataloaders['train']),\n           model_acc(tmodel,dataloaders['test'])))","bcc66bfb":"with torch.no_grad():\n    for i,(images,labels) in enumerate(dataloaders['test']):\n        show_image(images[:3])\n        print('\\ntrue labels: \\n',\n              ''.join('%24s'%names[labels[j]] for j in range(3)))\n        images=images.to(dev)\n        labels=labels.to(dev)\n        outputs=tmodel(images)\n        _,preds=torch.max(outputs,int(1))\n        print('\\npredictions: \\n',\n             ''.join('%24s'%names[preds[j]] for j in range(3)))\n        if i==1: break","c16cae9a":"[\ud83c\udf10 Google Colaboratory Variant](https:\/\/colab.research.google.com\/drive\/1uB1PuT_uNGM2tv88ZDkIj6Dhi_Rf91PA)"}}