{"cell_type":{"5122a08a":"code","7a18b970":"code","7298bfbc":"code","b1914b57":"code","ae985ae2":"code","eda7eb0e":"code","ea1e9ccc":"code","c2c24175":"code","98ec51f8":"code","24eb47b5":"code","b9dd3e94":"code","edccd709":"code","b778ae0e":"code","cfafb904":"code","f4d235b6":"code","6f49726b":"code","eed33eb3":"code","24a2750e":"code","985b8250":"code","635e9ec7":"code","c95b3703":"code","93284d60":"code","56b09c3a":"code","43360a90":"code","36123bc7":"code","f912cfc3":"code","c4f6d3fa":"code","72c9f569":"markdown"},"source":{"5122a08a":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier as xgb\nfrom lightgbm import LGBMClassifier as lgb\nfrom catboost import CatBoostClassifier as cbc\nfrom tpot import TPOTClassifier","7a18b970":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')","7298bfbc":"train.head()","b1914b57":"test.head()","ae985ae2":"train.describe()","eda7eb0e":"test.describe()","ea1e9ccc":"train.info()","c2c24175":"test.info()","98ec51f8":"train.isnull().sum()","24eb47b5":"test.isnull().sum()","b9dd3e94":"train['target'].unique()","edccd709":"fig, ax = plt.subplots(figsize=(10, 6))\nsns.countplot(data = train, x = 'target')","b778ae0e":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'])\\\n                            .background_gradient(subset=['std'])\\\n                            .background_gradient(subset=['min'])\\\n                            .background_gradient(subset=['50%'])\n#This cell belongs to Kaustubh B Bhargav (@kaustubh93)","cfafb904":"encoder = LabelEncoder()\nencoder.fit(train['target'])\ntrain1 = train\ntrain['target'] = encoder.fit_transform(train['target'])\n    \ntrain1.head(10)\n#Cambiamos las clases de [1-8] a [0-7]","f4d235b6":"scaler = StandardScaler()","6f49726b":"X = train.drop(['target', 'id'], axis = 1)\ny = train['target']\ntest = test.drop(['id'], axis = 1)\n\nX = scaler.fit_transform(X)\ntest = scaler.transform(test)","eed33eb3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","24a2750e":"model = RandomForestClassifier()  \nmodel.fit(X_train,y_train)\ny_preds = model.predict_proba(X_test)\nlog_loss1 = log_loss(y_test, y_preds)\nlog_loss1","985b8250":"model2 = cbc()\n\nmodel2.fit(X_train, y_train, verbose = False)\ny_preds2 = model.predict_proba(X_test)\nlog_loss2 = log_loss(y_test, y_preds2)\nlog_loss2","635e9ec7":"model3 = xgb()\n\nmodel3.fit(X_train, y_train)\ny_preds3 = model3.predict_proba(X_test)\nlog_loss3 = log_loss(y_test, y_preds3)\nlog_loss3","c95b3703":"model4 = lgb()\n\nmodel4.fit(X_train, y_train)\ny_preds4 = model4.predict_proba(X_test)\nlog_loss4 = log_loss(y_test, y_preds4)\nlog_loss4","93284d60":"# I tried run this part, but I have been waiting 4 hours and dont see the end\n\n# import h2o\n# from h2o.automl import H2OAutoML\n# h2o.init()\n\n# # Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n# train = h2o.import_file(\"..\/input\/tabular-playground-series-jun-2021\/train.csv\")\n# test = h2o.import_file(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\n\n# x = train.columns\n# y = 'target'\n# x.remove(y)\n\n# aml = H2OAutoML(max_models = 20, seed = 1)\n# aml.train(x = x, y = 'target', training_frame = train)\n\n# # View the AutoML Leaderboard\n# lb = aml.leaderboard\n# lb.head(rows = lb.nrows)  # Print all rows instead of default (10 rows)\n# preds = aml.leader.predict(test)\n# lb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')\n# lb","56b09c3a":"# Running this part, I obtain: 1.9927355643445277\n\n# def objective(trial, data = X, target = y):\n#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n#     model = RandomForestClassifier()  \n#     model.fit(X_train,y_train)\n\n#     y_preds = model.predict_proba(X_test)\n\n\n#     log_loss1 = log_loss(y_test, y_preds)\n\n#     return log_loss1\n\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(objective, n_trials = 100)","43360a90":"# tpot = TPOTClassifier(generations = 1, random_state = 42, verbosity = 1)\n# tpot.fit(X_train, y_train)\n# print(tpot.score(X_test, y_test))","36123bc7":"modelfinal = lgb(boosting_type = 'gbdt', objective = 'binary', num_leaves = 150,\n                 learning_rate = 0.005, n_estimators = 1000, max_depth = 300,\n                 reg_lambda = 0.05)\n\nmodelfinal.fit(X_train, y_train)\ny_predsfinal = modelfinal.predict_proba(X_test)\nlog_lossfinal = log_loss(y_test, y_predsfinal)\nlog_lossfinal","f912cfc3":"sample_submission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\ntest_pred = modelfinal.predict_proba(test)\nsubmission = pd.DataFrame(test_pred, \n                          columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\nsubmission['id'] = sample_submission['id']\nsubmission.head()","c4f6d3fa":"submission.to_csv('submision.csv', index = False)","72c9f569":"# Tabular Playground Serires Junio 2021\n\nPara esta edicion de Tabular se nos pide hacer una clasificaci\u00f3n para evaluar las distintas clases de un dataset con mas de 70 caracteristicas. Para ello, como viene siendo costumbre, empezaremos con una exploracion de datos para limpiar los mismos de ser necesario, despues se muestran los datos por pantalla para observar su distribuicion, tras esto, comparamos los distintos modelos seleccionados y elegimos el que nos da mejor resultado de base, en este modelo seleccionado tocamos los hiperparametros para obtener un mejor resultado que con el modelo al desnudo. Por ultimo, subimos los resultados a la competicion."}}