{"cell_type":{"52a7b454":"code","73fd024a":"code","25f85bd9":"code","43fe813b":"code","a0b47bbd":"code","b9651c9f":"code","0e9336a1":"code","beeaa374":"markdown","dc1465b1":"markdown","5534b91a":"markdown","4edb74c5":"markdown","1ce3cc8f":"markdown","f94443e7":"markdown","1e91cbdb":"markdown"},"source":{"52a7b454":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import model_selection\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n","73fd024a":"df_train = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")","25f85bd9":"df_train.shape","43fe813b":"df_train.head(20)","a0b47bbd":"df_train[\"kfold\"] = -1","b9651c9f":"kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n    df_train.loc[valid_indicies, \"kfold\"] = fold","0e9336a1":"df_train.to_csv(\"train_folds.csv\", index=False)","beeaa374":"This code block will include all necessary libraries i.e. numpy , panda, and sklearn","dc1465b1":"Here we will add new column \"kfold\" and initialize it to -1","5534b91a":"Now asign value to kfold using for loop like 0,1,2,3,4,0,1,2,3,4................","4edb74c5":"In below code block we will read the data from --> ..\/input\/30-days-of-ml\/train.csv","1ce3cc8f":"Save the file in train_folds.csv","f94443e7":"We will be using train_folds.csv file for our further training and validating and we are going to run this notebook only **once**.","1e91cbdb":"This note book is for creating folds in our training dataset. Here we will split our data into 5 fold using KFold by passing n_split = 5 as parameter. By this method we will be able to train our model in different subset of data and then we can validate our data from remaining set of data\n"}}