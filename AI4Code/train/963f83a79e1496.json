{"cell_type":{"e4828d31":"code","f2ec8420":"code","b2cfe91d":"code","8ae65a0f":"code","00100155":"code","2ff0a534":"code","90228ea9":"code","162a2c28":"code","ab7dcb58":"code","0cd7ca48":"code","b18e13b2":"code","39dfa451":"code","20eb7351":"code","5891a8da":"code","23a18670":"code","ff1ea431":"code","75578561":"code","09bb7f30":"code","cc3c979f":"code","6699bdad":"markdown","0ae098bd":"markdown","aec07b4e":"markdown","1c1737b6":"markdown","f47af058":"markdown","874ef46d":"markdown","47f9ec67":"markdown","c0dea1ce":"markdown","04651a9b":"markdown","277cf871":"markdown","d1f24b25":"markdown","fb3ef5f8":"markdown","8133f870":"markdown"},"source":{"e4828d31":"!pip install pycausalimpact","f2ec8420":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport causalimpact","b2cfe91d":"np.random.seed(seed=42)","8ae65a0f":"rossman_train_df = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv', parse_dates=['Date']);\n\nrossman_train_df.sample(10)","00100155":"rossman_train_df['StoreName'] = 'Store_'+('000'+rossman_train_df.Store.astype(str)).str[-4:]\n\nexperimental_store = 603\n\npre_period = [pd.Timestamp(2014,5,1), pd.Timestamp(2015,4,30)]\npost_period = [pd.Timestamp(2015,5,1), pd.Timestamp(2015,7,31)]\n\nrossman_train_df['Intervention'] = np.where(rossman_train_df.Date >= post_period[0], 'Pre Intervention', 'Post Intervention')","2ff0a534":"target = rossman_train_df[rossman_train_df.Store == experimental_store].groupby('Date')[['Sales']].mean()\n\nrelative_effect = 0.1\n\nnoise = np.random.randn(len(target))\/20\n\nnp.random.rand(len(target))\n\ntarget['target']        = target.Sales\n\ntarget['target_plus_5'] = np.where(target.index <= pre_period[1], \n                                      target.Sales, \n                                      target.Sales*(1.05+noise))\n\ntarget['target_minus_5'] = np.where(target.index <= pre_period[1], \n                                      target.Sales, \n                                      target.Sales*(0.95+noise))\n\ntarget['target_plus_10'] = np.where(target.index <= pre_period[1], \n                                      target.Sales, \n                                      target.Sales*(1.1+noise))\n\ntarget['target_minus_10'] = np.where(target.index <= pre_period[1], \n                                      target.Sales, \n                                      target.Sales*(0.9+noise))","90228ea9":"n_regressors = 25\nregression_stores = sorted(rossman_train_df[rossman_train_df.Store != experimental_store].Store.unique())\nidxs = list(np.random.choice(list(range(len(regression_stores))),n_regressors))\nregression_stores = [regression_stores[idx] for idx in idxs]","162a2c28":"pivoted_df = pd.pivot_table(rossman_train_df[rossman_train_df.Store.isin([experimental_store, *regression_stores])], index='Date', values= ['Sales', 'Open', 'Promo', 'SchoolHoliday'], columns = ['StoreName'])","ab7dcb58":"pivoted_df.columns = [f'{c[0]}_{c[1]}' for c in pivoted_df.columns]","0cd7ca48":"\nplt.figure(figsize=(30,5))\n\n\npre_filter  = (pivoted_df.index >= pd.Timestamp(2015,4,1)) & (pivoted_df.index <= pre_period[1])\npost_filter = (pivoted_df.index >= pre_period[1])\npre_post_filter = (pivoted_df.index >= pd.Timestamp(2015,4,1))\n\nanother_store_sales = f'Sales_Store_{regression_stores[0]:04}'\n\n\nax = plt.gca()\nax.plot(pivoted_df[pre_post_filter][pivoted_df.Sales_Store_0603 > 0].Sales_Store_0603, ls='--', c='red', label='original sales without intervention')\nax.plot(target[pre_post_filter][target.target_plus_10 > 0].target_plus_10, ls='-', c='red', label='sales plus noisy 10%')\nax.plot(pivoted_df[pre_post_filter][pivoted_df[another_store_sales] > 0][another_store_sales], ls='-', c='blue', label='another store')\n\nax.legend()\n\nax.axvline(pre_period[1], c='black', ls='--')","b18e13b2":"did_df = rossman_train_df[(rossman_train_df.Store==experimental_store)|(rossman_train_df.Store.isin(regression_stores))].copy()\n\n\ndid_df.Sales        = np.where( (did_df.Date >= pre_period[1])\n                                &(did_df.Store==experimental_store), \n                                  did_df.Sales*(1.1+np.random.randn(len(did_df))\/20), \n                                  did_df.Sales)\n\ndid_df.Sales  = did_df.Sales\/did_df.Sales.mean()\n\ndid_df.Intervention = np.where((did_df.Date > pre_period[1]) & (did_df.Store==experimental_store), 1, 0)\ndid_df = did_df[['DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Intervention', 'StoreName']]\n\nimport statsmodels.formula.api as smf \nimport statsmodels.api as sm  \n\nmodel = smf.ols(formula = \"Sales ~ Open + Promo + StateHoliday + SchoolHoliday + Intervention + StoreName\", data = did_df).fit()\nprint(model.summary())\n\n","39dfa451":"did_df = rossman_train_df[(rossman_train_df.Store==experimental_store)|(rossman_train_df.Store.isin(regression_stores))].copy()\n\ndid_df.Sales  = did_df.Sales\/did_df.Sales.mean()\n\ndid_df.Intervention = np.where((did_df.Date > pre_period[1]) & (did_df.Store==experimental_store), 1, 0)\ndid_df = did_df[['DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Intervention', 'StoreName']]\n\nimport statsmodels.formula.api as smf \nimport statsmodels.api as sm  \n\nmodel = smf.ols(formula = \"Sales ~ Open + Promo + StateHoliday + SchoolHoliday + Intervention + StoreName\", data = did_df).fit()\nprint(model.summary())\n\n","20eb7351":"low_sd_cols = pivoted_df.columns[pivoted_df.std()<0.1]","5891a8da":"data = pivoted_df[['Sales_Store_0603', *[c for c in pivoted_df.columns if c not in ['Sales_Store_0603', *low_sd_cols]]]].fillna(0)\n\nci_orig = causalimpact.CausalImpact(data, pre_period, post_period, nseasons=[{'period': 7, 'harmonics': 2}], prior_level_sd=0.01)\n\nci_orig.plot()","23a18670":"print(ci_orig.summary())","ff1ea431":"data = pivoted_df[['Sales_Store_0603', *[c for c in pivoted_df.columns if c not in ['Sales_Store_0603', *low_sd_cols]]]].fillna(0)\n\ndata['Sales_Store_0603'] = target['target_plus_5']\n\nci_plus_5 = causalimpact.CausalImpact(data, pre_period, post_period, nseasons=[{'period': 7, 'harmonics': 2}])\n\nci_plus_5.plot()","75578561":"print(ci_plus_5.summary())","09bb7f30":"data = pivoted_df[['Sales_Store_0603', *[c for c in pivoted_df.columns if c not in ['Sales_Store_0603', *low_sd_cols]]]].fillna(0)\n\ndata['Sales_Store_0603'] = target['target_minus_10']\n\nci_minus_10 = causalimpact.CausalImpact(data, pre_period, post_period, nseasons=[{'period': 7, 'harmonics': 2}])\n\nci_minus_10.plot()","cc3c979f":"print(ci_minus_10.summary())","6699bdad":"![image.png](attachment:image.png)","0ae098bd":"\n# Bayesian Structural Time-Series\n\n\n- Local Linear Trend Model\n    - like an intercept but time variable\n    - unobserved\n    - observed - level\n    - unobserved - 'level'\n\n\n- Seasonal component\n    - indicator variables\n\n\n- Contemporaneous Regressors\n    - static coefficients","aec07b4e":"### Difference in Differences Regression","1c1737b6":"### Quick Demo of Causal Impact on Rossman Sales Dataset","f47af058":"## Add some hypothetical results from 'interventions'","874ef46d":"BY KAY H. BRODERSEN, FABIAN GALLUSSER, JIM KOEHLER,\nNICOLAS REMY AND STEVEN L. SCOTT\nGoogle, Inc.\n\nAn important problem in econometrics and marketing is to infer the\ncausal impact that a designed market intervention has exerted on an outcome metric over time. This paper proposes to infer causal impact on the\nbasis of a diffusion-regression state-space model that predicts the counterfactual market response in a synthetic control that would have occurred had\nno intervention taken place. In contrast to classical difference-in-differences\nschemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple\nsources of variation, including local trends, seasonality and the time-varying\ninfluence of contemporaneous covariates. Using a Markov chain Monte Carlo\nalgorithm for posterior inference, we illustrate the statistical properties of our\napproach on simulated data. We then demonstrate its practical utility by estimating the causal effect of an online advertising campaign on search-related\nsite visits. We discuss the strengths and limitations of state-space models in\nenabling causal attribution in those settings where a randomised experiment\nis unavailable. The CausalImpact R package provides an implementation of\nour approach.\n\nGoogle Research Paper:\nhttps:\/\/research.google\/pubs\/pub41854\/\n\nOriginal Google R library:\nhttps:\/\/github.com\/google\/CausalImpact\n\nPython port of Google library:\nhttps:\/\/github.com\/dafiti\/causalimpact\n\n## The main ideas\n\n1. Synthetic Control\n    - Compared with the 'blunt instrument' of an average statistic for a control group\n\n\n2. Bayesian Structural Time Series\n    - general\n    - flexible (e.g. time varying regression parameters)\n    - modular\n    - strong structural assumptions allow for causal conclusions\n    - MCMC estimation of posterior gives better confidence estimations\n\n![image.png](attachment:image.png)\n\n","47f9ec67":"# Some Greek\n![image.png](attachment:image.png)","c0dea1ce":"### Testing for synthetically generated impact","04651a9b":"### Pivot data so that Regressors are in columns[](http:\/\/)","277cf871":"![image.png](attachment:image.png)","d1f24b25":"## A-A testing","fb3ef5f8":"### Choose some stores at random as regressors","8133f870":"## Read in Rossman training dataset"}}