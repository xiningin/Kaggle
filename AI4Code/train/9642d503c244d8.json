{"cell_type":{"dfba6f0e":"code","759bfd02":"code","29ec5dc6":"code","36d690f6":"code","64ca8004":"code","5f45c7a1":"code","c390c2ea":"code","526c93c5":"code","60b027a4":"code","22673fbc":"code","ee5c3ff1":"code","f927efd0":"code","065e3031":"code","bf93069b":"code","25c9e746":"code","2eac9fa5":"code","f31c79f9":"code","71f94273":"code","470f15e1":"code","5e18d1c4":"code","0b253449":"code","86720d39":"code","54cdcb83":"code","b4aa33dc":"code","31372d40":"code","c3f7fed9":"code","c6fc2a3c":"code","495c8aa9":"code","ebe803fb":"code","025fe292":"code","58172ca5":"code","b7d42845":"code","d672e728":"code","d0d053bf":"code","b8f915df":"code","01cd0a4b":"code","8b522d73":"code","8746bc40":"code","49bcab30":"code","07aa225c":"code","be000794":"code","19a600c5":"code","5bbb3f38":"code","1ce42b0f":"code","4ef8f1b6":"code","10d3482f":"code","1798aa94":"code","9a163ace":"code","a42112d6":"code","2eca370b":"code","4e9b716e":"code","7a044ff4":"code","b10ebde9":"code","708d4742":"markdown","f9373b3b":"markdown","40d0fb50":"markdown","c16f7817":"markdown","18c0d202":"markdown","e9cb55b2":"markdown","1ed1344f":"markdown","c28aac88":"markdown","1282d240":"markdown","705fb23f":"markdown","6777c479":"markdown","2753c37d":"markdown","939ad4ac":"markdown","f9881bc9":"markdown","b32c620b":"markdown","6176c280":"markdown","91bd454e":"markdown","823a2f51":"markdown","69d782fc":"markdown","151a5c77":"markdown","bf51b71b":"markdown","bcf4948e":"markdown","c625526a":"markdown","a13fd3e4":"markdown","fc5d379e":"markdown","02cb264e":"markdown","f841bc62":"markdown","56031187":"markdown","6df5c56c":"markdown","9883a696":"markdown","90221fd7":"markdown","1b060d3b":"markdown","7bcbe8cd":"markdown","cc5f8be8":"markdown","29ac7018":"markdown","2ca1e639":"markdown","89d32a9a":"markdown","c8b9a4e1":"markdown","e330d187":"markdown","a0991a96":"markdown","d2fa33e5":"markdown","5a9ad9b7":"markdown","336be54b":"markdown","076386db":"markdown","2a9fd8b2":"markdown","690aaa54":"markdown","c8950c32":"markdown","bc29be11":"markdown","d8e9df45":"markdown","02bc314a":"markdown","e2023fea":"markdown","cb938eca":"markdown","d809138b":"markdown","6270c68b":"markdown","0c98b48d":"markdown"},"source":{"dfba6f0e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom statsmodels.graphics.mosaicplot import mosaic\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.feature_selection import mutual_info_classif\nimport itertools\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import PolynomialFeatures\nimport json\nfrom sklearn.tree import DecisionTreeClassifier\nopt=False\n# baseline \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u0438\u0437 SF Scoring Model \u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u043d\u0430 \u043a\u0443\u0440\u0441\u0435","759bfd02":"def plot_cmatrix(model, X, y, title=None, **kwargs):\n    disp = plot_confusion_matrix(model, X_test, y_test, **kwargs)\n    disp.ax_.set_ylabel('\u0418\u0441\u0442\u0438\u043d\u043d\u044b\u0439 \u043a\u043b\u0430\u0441\u0441')\n    disp.ax_.set_xlabel('\u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0439 \u043a\u043b\u0430\u0441\u0441')\n    if title:\n        disp.ax_.set_title(title)\n        \ndef plot_grid(nplots, max_cols=2, figsize=(800\/72, 600\/72)):\n    ncols = min(nplots, max_cols)\n    nrows = (nplots \/\/ ncols) + min(1, (nplots % ncols))\n    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize, constrained_layout=True)\n    if nrows == 1:\n        return axs\n    return [axs[index \/\/ ncols, index % ncols] for index in range(nplots)]\n\ndef plot_correlation_matrix(corr, annot=False):\n    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n    cmap=sns.diverging_palette(220, 20, as_cmap=True)\n    sns.heatmap(corr, annot=annot, fmt='.2f', mask=mask,\n                cmap=cmap, vmax=1, vmin=-1, square=True, \n                linewidths=.5, cbar_kws={\"shrink\": .5})\n    \ndef prepare_space(df, num_features, bin_features, cat_features, target):\n    X_num = StandardScaler().fit_transform(df[num_features].values)\n    X_bin = df[bin_features].values\n    X_cat = OneHotEncoder(sparse=False).fit_transform(df[cat_features].values)\n    X = np.hstack([X_num, X_bin, X_cat])\n    Y = df[target].values\n    return X, Y\n\ndef plot_roc_curve(y_true, y_score):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    auc = roc_auc_score(y_true, y_score)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.4f)' % auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \ndef test_model_roc_cm(X_test,y_test):\n    proba = model.predict_proba(X_test)[:, 1]\n    plot_roc_curve(y_test, proba)\n\n    axs = plot_grid(2, figsize=(800\/72, 300\/72))\n    plot_cmatrix(model, X_test, y_test, title='\u0410\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f', display_labels=['0', '1'], ax=axs[0]);\n    plot_cmatrix(model, X_test, y_test, title='\u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f', \n                 normalize='pred', display_labels=['0', '1'], ax=axs[1]);\n    \n    \ndef hyper_estimator(X_train,y_train,fit=\"f1\"):\n    estimator = LogisticRegression(random_state=RANDOM_SEED, max_iter=200)\n\n    param_grid = [\n        {\n            'penalty': ['l1'],\n            'solver': ['liblinear', 'saga'],\n            'class_weight':['none', 'balanced'], \n            'multi_class': ['auto','ovr'],\n        },\n        {\n            'penalty': ['l2'],\n            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n            'class_weight':['none', 'balanced'], \n            'multi_class': ['auto','ovr'],\n        },\n        {\n            'penalty': ['elasticnet'],\n            'solver': ['saga'],\n            'class_weight':['none', 'balanced'], \n            'multi_class': ['auto','ovr'],\n        },\n        {\n            'penalty': ['none'],\n            'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n            'class_weight':['none', 'balanced'], \n            'multi_class': ['auto','ovr'],\n        },\n    ]\n\n    gs = GridSearchCV(estimator, param_grid, n_jobs=-1, scoring=fit, cv=5).fit(X_train, y_train)\n    return gs","29ec5dc6":"DATASETS_LOC = '\/kaggle\/input\/sf-dst-scoring'\nRANDOM_SEED = 61\n\ntrain = pd.read_csv(f'{DATASETS_LOC}\/train.csv')\ntrain.insert(0, '_test', False) # label train data with 0 in _test\n\ntest = pd.read_csv(f'{DATASETS_LOC}\/test.csv')\ntest.insert(0, '_test', True)# label test data with 1 in _test\n\ndata = pd.concat([train, test], ignore_index=True)\n# num of unique values, first 10 unique values, null values count, type\ndata.agg({'nunique', lambda s: s.unique()[:10]})\\\n    .append(pd.Series(data.isnull().sum(), name='null'))\\\n    .append(pd.Series(data.dtypes, name='dtype'))\\\n    .transpose()","36d690f6":"data.education.value_counts()","64ca8004":"# \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0441\u0442\u043d\u043e \u0441\u0447\u0438\u0442\u0430\u0442\u044c, \u0447\u0442\u043e \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\n# data.education.fillna('WOE', inplace=True)\n# \u043d\u043e \u0441\u043a\u043e\u0440\u0435\u0435 \u0432\u0441\u0435\u0433\u043e \u0443 \u043b\u044e\u0434\u0435\u0439 \u0435\u0441\u0442\u044c \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u0448\u043a\u043e\u043b\u044c\u043d\u043e\u0435 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u043e\u0436\u043d\u043e \u0437\u0430\u043c\u0435\u043d\u044f\u0442\u044c \u0438\u043c, \u0447\u0442\u043e\u0431\u044b \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c \u043a\u043e\u043b\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\ndata.education.fillna('SCH', inplace=True) # \u044d\u0442\u0430 \u0437\u0430\u043c\u0435\u043d\u0430 \u0434\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0438\u0439 \u0441\u043a\u043e\u0440\u0438\u043d\u0433 \u0438 \u043f\u0440\u043e\u0444\u0438\u0442","5f45c7a1":"# \u0412\u0437\u0433\u043b\u044f\u043d\u0435\u043c \u043f\u043e\u0431\u043b\u0438\u0436\u0435 \u043d\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a app_date\nprint(data.app_date.head(5))\n\n# \u0421\u043a\u043e\u043d\u0432\u0435\u0442\u0438\u0440\u0443\u0435\u043c \u0432 \u0431\u043e\u043b\u0435\u0435 \u0443\u0434\u043e\u0431\u043d\u044b\u0439 \u0444\u043e\u0440\u043c\u0430\u0442 \u0434\u0430\u0442\u044b\ndata.app_date = pd.to_datetime(data.app_date)\nprint(data.app_date.head(5))\n\n# \u041d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 app_date \u0434\u0435\u043b\u0430\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\ncurrent_date = pd.to_datetime('01JAN2021')\n# \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u043d\u0435\u0439, \u043f\u0440\u043e\u0448\u0435\u0434\u0448\u0438\u0445 \u0441\u043e \u0434\u043d\u044f \u043f\u043e\u0434\u0430\u0447\u0438 \u0437\u0430\u044f\u0432\u043a\u0438\ndata['days'] = (current_date - data.app_date).dt.days\nprint(data.days.head(5))","c390c2ea":"target = 'default'\nbin_features = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_features = ['education', 'home_address', 'work_address', 'sna', 'first_time', 'region_rating']\nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income',\"days\"]\n# \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0435\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0435\nset(data.columns)-set(bin_features)-set(cat_features)-set(num_features)-set([target])","526c93c5":"for column, ax in zip(num_features, plot_grid(len(num_features))):\n    data[column].plot(kind='hist', ax=ax, title=column)\n    ax.set_ylabel(None)","60b027a4":"data.income = data.income.transform(np.log)","22673fbc":"# optional!\nfor column in set(num_features)-set([\"score_bki\",\"income\"]):\n    data[column] = (data[column]+1).transform(np.log)","ee5c3ff1":"for column, ax in zip(num_features, plot_grid(len(num_features))):\n    data[column].plot(kind='hist', ax=ax, title=column)\n    ax.set_ylabel(None)","f927efd0":"corr = data[~data._test][num_features + [target]].corr()\nplot_correlation_matrix(corr, annot=True)","065e3031":"F, _ = f_classif(data[~data._test][num_features], data[~data._test][target])\npd.Series(F, index=num_features).sort_values(ascending=False).plot(kind='bar');","bf93069b":"for feature, ax in zip(cat_features, plot_grid(len(cat_features))):\n    mosaic(data[~data._test], [feature, target], ax=ax, title=feature);","25c9e746":"for feature, ax in zip(bin_features, plot_grid(len(bin_features))):\n    mosaic(data[~data._test], [feature, target], ax=ax, title=feature);","2eac9fa5":"# \u0442\u043e\u043b\u044c\u043a\u043e 1 \u043e\u0440\u0434\u0438\u043d\u0430\u043b\u044c\u043d\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e\nordinal_enc = OrdinalEncoder(categories=[['WOE', 'SCH', 'GRD', 'UGR', 'PGR', 'ACD'],])\ndata[['education',]] = ordinal_enc.fit_transform(data[['education',]])\n\n# num_labele = dict(enumerate([\"N.A.\",\"SCH\", \"UGR\",\"GRD\",\"PGR\",\"ACD\"]))\n# labele_num = {value:key for key, value in num_labele.items()}\n# data[\"education\"]=data[\"education\"].apply(lambda x: labele_num[x])\n\n\n# \u0432\u0441\u0435 \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435\nlabel_encoder = LabelEncoder()\nfor column in bin_features:\n    data[column] = label_encoder.fit_transform(data[column])","f31c79f9":"mi = mutual_info_classif(data[~data._test][cat_features+bin_features], data[~data._test][target], discrete_features=True)\npd.Series(mi, index=cat_features+bin_features).sort_values(ascending=False).plot(kind='bar');","71f94273":"X, Y = prepare_space(data[~data._test], num_features, bin_features, cat_features, target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)","470f15e1":"model = LogisticRegression(random_state=RANDOM_SEED, solver='liblinear').fit(X_train, y_train)\ntest_model_roc_cm(X_test,y_test)","5e18d1c4":"if opt:# set True if want to optimize hyperparameters\n    gs = hyper_estimator(X_train,y_train)\n    param = gs.best_estimator_.get_params()\nelse:\n    param = {'C': 1.0,\n    'class_weight': 'balanced',\n    'dual': False,\n    'fit_intercept': True,\n    'intercept_scaling': 1,\n    'l1_ratio': None,\n    'max_iter': 200,\n    'multi_class': 'auto',\n    'n_jobs': None,\n    'penalty': 'l2',\n    'random_state': 61,\n    'solver': 'lbfgs',\n    'tol': 0.0001,\n    'verbose': 0,\n    'warm_start': False} \n    \nwith open('best_basic_hyperparam.json', 'w') as fp:\n    json.dump(param, fp)","0b253449":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0442\u0435\u0441\u0442, \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nwith open('best_basic_hyperparam.json', 'r') as fp:\n    params = json.load(fp)\n    \nmodel = LogisticRegression(**params).fit(X_train, y_train)\ntest_model_roc_cm(X_test,y_test)","86720d39":"if opt:# set True if want to optimize hyperparameters\n    with open('best_basic_hyperparam.json', 'r') as fp:\n        params = json.load(fp)\n\n    params.pop(\"C\")\n    params.pop(\"max_iter\")\n    params.pop(\"random_state\")\n    params.pop(\"penalty\")\n\n    # \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0442\u0438\u043f\u044b \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    penalty = ['l1', 'l2',\"elasticnet\"]\n    C = np.linspace(50, 100, 100) # \u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    hyperparameters = dict(C=C, penalty=penalty) # \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n\n    estimator = LogisticRegression(random_state=RANDOM_SEED, max_iter=400, **params)\n    gs = GridSearchCV(estimator, hyperparameters, n_jobs=-1, scoring='f1', cv=5).fit(X_train, y_train) \n    param = gs.best_estimator_.get_params()\n\nelse:\n    param = {'C': 63.63636363636364,\n    'class_weight': 'balanced',\n    'dual': False,\n    'fit_intercept': True,\n    'intercept_scaling': 1,\n    'l1_ratio': None,\n    'max_iter': 400,\n    'multi_class': 'auto',\n    'n_jobs': None,\n    'penalty': 'l2',\n    'random_state': 61,\n    'solver': 'lbfgs',\n    'tol': 0.0001,\n    'verbose': 0,\n    'warm_start': False}\n    \n    \nwith open('best_basic_hyperparam_CP.json', 'w') as fp:\n    json.dump(param, fp)","54cdcb83":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0442\u0435\u0441\u0442, \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nwith open('best_basic_hyperparam_CP.json', 'r') as fp:\n    params = json.load(fp)\n    \nmodel = LogisticRegression(**params).fit(X_train, y_train)\ntest_model_roc_cm(X_test,y_test)","b4aa33dc":"with open('best_basic_hyperparam.json', 'r') as fp:\n    params = json.load(fp)\nparams[\"max_iter\"]=2000\n\nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income',\"days\"]\nresults_polinome2=pd.DataFrame(data=None, columns=None)\n\nL =2\nfor subset in itertools.combinations(num_features, L):\n    col1 = subset[0]\n    col2 = subset[1]\n\n    new_features = [\"1\", col1, col2, col1+\"^2\", col1+\"*\"+col2, col2+\"^2\"]\n    new_features\n    pf = PolynomialFeatures(2)\n    poly_features = pf.fit_transform(data[[col1, col2]])\n\n    df_temp=pd.DataFrame(poly_features,columns=new_features)\n\n    data0 = pd.concat([data, df_temp[new_features[3:]]], axis=1)\n    num_features0=num_features+new_features[3:]\n\n    X, Y = prepare_space(data0[~data0._test], num_features0, bin_features, cat_features, target)\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n\n    model = LogisticRegression(**params).fit(X_train, y_train)\n    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    cm = confusion_matrix(y_test, model.predict(X_test))\n    display('ROC curve (area = %0.4f)' % auc)\n    col = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\n\n    cm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\n    results_polinome2 = results_polinome2.append(pd.DataFrame(data=[[\"baseline_best_hyper\",\"P2_2:\"+col1+\"^\"+col2,\n                                                           None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                          columns=col), ignore_index=True)\n        \ndisplay(display(results_polinome2.sort_values(by=['ROC'],ascending=False)))","31372d40":"with open('best_basic_hyperparam.json', 'r') as fp:\n    params = json.load(fp)\nwith open('best_basic_hyperparam_CP.json', 'r') as fp:\n    params2 = json.load(fp)\nparams[\"max_iter\"]=2000\nparams2[\"max_iter\"]=2000\n    \nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'days']\nresults_polinome2all=pd.DataFrame(data=None, columns=None)\n\npf = PolynomialFeatures(2)\npoly_features = pf.fit_transform(data[num_features])\nnew_features=[\"A\"+str(k) for k in range(0,np.shape(poly_features)[1])]\n\ndf_temp=pd.DataFrame(poly_features,columns=new_features)\nnew_features = new_features[len(num_features)+1:]\n\ndata_P2all = pd.concat([data, df_temp[new_features]], axis=1)\nnum_features_P2all=num_features+new_features\n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, \n                     target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n\nmodel_1 = LogisticRegression(**params).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_1.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_1.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome2all = results_polinome2all.append(pd.DataFrame(data=[[\"baseline_optbasichyper\",\n                                                                       \"Polinome2:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\nmodel_2 = LogisticRegression(**params2).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_2.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_2.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome2all = results_polinome2all.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                                                       \"Polinome2:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\n\nmodel_P2all1 = model_1\nmodel_P2all2 = model_2\ndisplay(results_polinome2all)","c3f7fed9":"with open('best_basic_hyperparam.json', 'r') as fp:\n    params = json.load(fp)\nwith open('best_basic_hyperparam_CP.json', 'r') as fp:\n    params2 = json.load(fp)\nparams[\"max_iter\"]=5000\nparams2[\"max_iter\"]=5000\n\nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'days']\nresults_polinome3all=pd.DataFrame(data=None, columns=None)\n\npf = PolynomialFeatures(3)\npoly_features = pf.fit_transform(data[num_features])\nnew_features=[\"A\"+str(k) for k in range(0,np.shape(poly_features)[1])]\n\ndf_temp=pd.DataFrame(poly_features,columns=new_features)\nnew_features = new_features[len(num_features)+1:]\n\ndata_P3all = pd.concat([data, df_temp[new_features]], axis=1)\nnum_features_P3all=num_features+new_features\n\nX, Y = prepare_space(data_P3all[~data_P3all._test], num_features_P3all, bin_features, cat_features,\n                     target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n\nmodel_1 = LogisticRegression(**params).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_1.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_1.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome3all = results_polinome3all.append(pd.DataFrame(data=[[\"baseline_optbasichyper\",\n                                                                       \"Polinome3:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\nmodel_2 = LogisticRegression(**params2).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_2.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_2.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome3all = results_polinome3all.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                                                       \"Polinome3:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\n\nmodel_P3all1 = model_1\nmodel_P3all2 = model_2\ndisplay(results_polinome3all)","c6fc2a3c":"X, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, \n                     target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)","495c8aa9":"if opt:# set True if want to optimize hyperparameters\n    gs = hyper_estimator(X_train,y_train)\n    param = gs.best_estimator_.get_params()\n\nelse:\n    param = {'C': 1.0,\n    'class_weight': 'balanced',\n    'dual': False,\n    'fit_intercept': True,\n    'intercept_scaling': 1,\n    'l1_ratio': None,\n    'max_iter': 200,\n    'multi_class': 'auto',\n    'n_jobs': None,\n    'penalty': 'none',\n    'random_state': 61,\n    'solver': 'newton-cg',\n    'tol': 0.0001,\n    'verbose': 0,\n    'warm_start': False} \n    \nwith open('best_basic_hyperparamP2all.json', 'w') as fp:\n    json.dump(param, fp)","ebe803fb":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0442\u0435\u0441\u0442, \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nwith open('best_basic_hyperparamP2all.json', 'r') as fp:\n    params = json.load(fp)\n    \nmodel = LogisticRegression(**params).fit(X_train, y_train)\ntest_model_roc_cm(X_test,y_test)","025fe292":"if opt:# set True if want to optimize hyperparameters\n    with open('best_basic_hyperparamP2all.json', 'r') as fp:\n        params = json.load(fp)\n\n    params.pop(\"C\")\n    params.pop(\"max_iter\")\n    params.pop(\"random_state\")\n    params.pop(\"penalty\")\n\n    # \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0442\u0438\u043f\u044b \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    penalty = ['l1', 'l2',\"elasticnet\"]\n    C = np.linspace(1, 5000, 100) # \u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    hyperparameters = dict(C=C, penalty=penalty) # \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n\n    estimator = LogisticRegression(random_state=RANDOM_SEED, max_iter=400, **params)\n    gs = GridSearchCV(estimator, hyperparameters, n_jobs=-1, scoring='f1', cv=5).fit(X_train, y_train) \n    param = gs.best_estimator_.get_params()\n\nelse:\n    param = {'C': 1111.888888888889,\n 'class_weight': 'balanced',\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1,\n 'l1_ratio': None,\n 'max_iter': 400,\n 'multi_class': 'auto',\n 'n_jobs': None,\n 'penalty': 'l2',\n 'random_state': 61,\n 'solver': 'newton-cg',\n 'tol': 0.0001,\n 'verbose': 0,\n 'warm_start': False}\n    \nwith open('best_basic_hyperparamP2all_CP.json', 'w') as fp:\n    json.dump(param, fp)","58172ca5":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0442\u0435\u0441\u0442, \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\nwith open('best_basic_hyperparamP2all_CP.json', 'r') as fp:\n    params = json.load(fp)\n    \nmodel = LogisticRegression(**params).fit(X_train, y_train)\ntest_model_roc_cm(X_test,y_test)\n","b7d42845":"with open('best_basic_hyperparamP2all.json', 'r') as fp:\n    params = json.load(fp)\nwith open('best_basic_hyperparamP2all_CP.json', 'r') as fp:\n    params2 = json.load(fp)\nparams[\"max_iter\"]=2000\nparams2[\"max_iter\"]=2000\n\nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'days']\nresults_polinome3all=pd.DataFrame(data=None, columns=None)\n\npf = PolynomialFeatures(3)\npoly_features = pf.fit_transform(data[num_features])\nnew_features=[\"A\"+str(k) for k in range(0,np.shape(poly_features)[1])]\n\ndf_temp=pd.DataFrame(poly_features,columns=new_features)\nnew_features = new_features[len(num_features)+1:]\n\ndata_P3all = pd.concat([data, df_temp[new_features]], axis=1)\nnum_features_P3all=num_features+new_features\n\nX, Y = prepare_space(data_P3all[~data_P3all._test], num_features_P3all, bin_features, cat_features,\n                     target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n\nmodel_1 = LogisticRegression(**params).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_1.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_1.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome3all = results_polinome3all.append(pd.DataFrame(data=[[\"baseline_optbasichyper\",\n                                                                       \"Polynome3:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\nmodel_2 = LogisticRegression(**params2).fit(X_train, y_train)\n\nauc = roc_auc_score(y_test, model_2.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model_2.predict(X_test))\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_polinome3all = results_polinome3all.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                                                       \"Polynome3:all6\",\n                                                       None,auc,cm_line[0],cm_line[1],cm_line[2],\n                                                                       cm_line[3]]], \n                                      columns=col), ignore_index=True)\n\n\n\nmodel_P3all1 = model_1\nmodel_P3all2 = model_2\ndisplay(results_polinome3all)","d672e728":"X, Y = prepare_space(data0[~data0._test], num_features0, bin_features, cat_features, target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n# model = LogisticRegression(random_state=RANDOM_SEED, solver='liblinear').fit(X_train, y_train)\nmodel = LogisticRegression(**params).fit(X_train, y_train)\nproba = model.predict_proba(X_test)[:, 1]\ntest_model_roc_cm(X_test,y_test)\n\n0.7335, 8690, 1231, 4236, 603","d0d053bf":"col = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\nresults_SSS=pd.DataFrame(data=None,columns=col)   \n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, target)\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)#RANDOM_SEED\ntrain_indices, test_indices = [split for split in sss.split(X, Y)][0]\nX_train,y_train = X[train_indices],Y[train_indices]\nX_test,y_test = X[test_indices],Y[test_indices]\n\n\nwith open('best_basic_hyperparamP2all.json', 'r') as fp:\n    params = json.load(fp)\nmodel = LogisticRegression(**params).fit(X_train, y_train)\nauc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model.predict(X_test))\n\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_SSS = results_SSS.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",\"SSS\",\n                                                           None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                          columns=col), ignore_index=True)\n\nmodel_SSS1 = model\n\nwith open('best_basic_hyperparamP2all_CP.json', 'r') as fp:\n    params2 = json.load(fp)# k-fold   \nmodel = LogisticRegression(**params2).fit(X_train, y_train)\nauc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\ncm = confusion_matrix(y_test, model.predict(X_test))\n\ncm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\nresults_SSS = results_SSS.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all_CP\",\"SSS\",\n                                                           None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                          columns=col), ignore_index=True)  \n\nmodel_SSS2 = model\n    \ndisplay(results_SSS)   ","b8f915df":"col = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\nresults_SSS=pd.DataFrame(data=None,columns=col)   \n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, target)\n\nfor random_S in range(0,10):\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=random_S)\n    train_indices, test_indices = [split for split in sss.split(X, Y)][0]\n\n    X_train,y_train = X[train_indices],Y[train_indices]\n    X_test,y_test = X[test_indices],Y[test_indices]\n\n\n    with open('best_basic_hyperparamP2all.json', 'r') as fp:\n        params = json.load(fp)\n    model = LogisticRegression(**params).fit(X_train, y_train)\n    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    cm = confusion_matrix(y_test, model.predict(X_test))\n\n    cm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\n    results_SSS = results_SSS.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",f\"SSS {random_S}\",\n                                                               None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                              columns=col), ignore_index=True)\n\n    with open('best_basic_hyperparamP2all_CP.json', 'r') as fp:\n        params2 = json.load(fp)# k-fold   \n    model = LogisticRegression(**params2).fit(X_train, y_train)\n    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    cm = confusion_matrix(y_test, model.predict(X_test))\n\n    cm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\n    results_SSS = results_SSS.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all_CP\",f\"SSS {random_S}\",\n                                                               None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                              columns=col), ignore_index=True) \n\ndisplay(results_SSS)   \nresults_SSS.loc[results_SSS[\"ROC\"].max()==results_SSS[\"ROC\"]]","01cd0a4b":"with open('best_basic_hyperparamP2all.json', 'r') as fp:\n    params = json.load(fp)\nwith open('best_basic_hyperparamP2all_CP.json', 'r') as fp:\n    params2 = json.load(fp)# k-fold\n\n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, target)\nkf = KFold(n_splits=5, shuffle=False)\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\nresults_kFold=pd.DataFrame(data=None,columns=col)\n\nresults_kFold2=pd.DataFrame(data=None,columns=col)\n\nindex = 0\nfor train_indices, test_indices in kf.split(X):\n    index+=1\n    print(\"itteration\",index,\"out of\",kf.n_splits)\n    X_train,y_train = X[train_indices],Y[train_indices]\n    X_test,y_test = X[test_indices],Y[test_indices]\n    \n    model = LogisticRegression(**params).fit(X_train, y_train)\n    \n    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    cm = confusion_matrix(y_test, model.predict(X_test))\n    \n    cm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\n    results_kFold = results_kFold.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",f\"kFold index {index:.0f}\",\n                                                               None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                              columns=col), ignore_index=True)\n\n    model = LogisticRegression(**params2).fit(X_train, y_train)\n    \n    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    cm = confusion_matrix(y_test, model.predict(X_test))\n    \n    cm_line = [cm[k][l] for k,l in [[0,0],[1,1],[0,1],[1,0]]]\n    results_kFold2 = results_kFold2.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2allCP\",f\"kFold index {index:.0f}\",\n                                                               None,auc,cm_line[0],cm_line[1],cm_line[2],cm_line[3]]], \n                                              columns=col), ignore_index=True)\n\n    \n    \ndisplay(results_kFold)\ndisplay(results_kFold2)","8b522d73":"display(f\"ROC_hyper1 = {results_kFold.ROC.mean():.6f} +- {results_kFold.ROC.std():.6f}\")\ndisplay(f\"ROC_hyper2 = {results_kFold2.ROC.mean():.6f} +- {results_kFold2.ROC.std():.6f}\")","8746bc40":"# P6all with hyp opt for P2all\n# model = model_P3all1\n# model = model_P3all1\n# S, _ = prepare_space(data_P3all[data_P3all._test], num_features_P3all, bin_features, cat_features, target)","49bcab30":"col = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, target)\n\nwith open('best_basic_hyperparamP2all.json', 'r') as fp:\n    params = json.load(fp)\nmodel = LogisticRegression(**params).fit(X, Y)\n\nmodel_P2allF = model","07aa225c":"#P2all, be sure that right model was tested\n# \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0438\u0439 roc_auc \u0438 profit\n# model = model_P2all1\n# model = model_P2all2\n# model = model_SSS1 # higherst roc_auc!\n# model = model_SSS2\nmodel = model_P2allF\nS, _ = prepare_space(data_P2all[data_P2all._test], num_features_P2all, bin_features, cat_features, target)","be000794":"# data without polinomes \n# S, _ = prepare_space(data[data._test], num_features, bin_features, cat_features, target)","19a600c5":"predict_submission = model.predict_proba(S)[:,1]\n\nsample_submission = data[data._test][['client_id', target]]\nsample_submission[target] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)","5bbb3f38":"# \u044d\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0435, \u0438 \u043f\u043e\u043c\u043e\u0433\u0430\u043b\u0438 \u043d\u0430\u0439\u0442\u0438 \u0431\u043e\u043b\u0435\u0435 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u043f\u043e\u0441\u043e\u0431 \u0440\u0435\u0448\u0435\u043d\u0438\u044f,\n# \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0433\u0443\u0442 \u0440\u0430\u0441\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0441 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u043c\u0438 \u0441\u0435\u0439\u0447\u0430\u0441 \u043f\u0440\u0438 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u0445  \n\ncol = [\"description_model\",\"modifications\",\"public_score\",\"ROC\",\"TN_00\",\"TP_11\",\"FP_01\",\"FN_10\"]\nresults=pd.DataFrame(data=None, columns=col)\nresults = results.append(pd.DataFrame(data=[[\"divine knowledge\",None,1,1,12926,1834,0,0]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline\",    None,         \n                                             0.73196,0.732,12876,37,50,1797]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",None,\n                                             0.73196,0.732,8658,1224,4268,610]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline\",\"log(age)\",            \n                                             None,0.7318,12876,37,50,1797]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline\",\"log(num_features)\",\n                                             0.73335,0.7329,12876,39,50,1795]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\"log(num_features)\",\n                                             0.73317,0.7329,8668,1226,4258,608]], \n                                      columns=col), ignore_index=True)\n\n\nresults = results.append(pd.DataFrame(data=[[\"baseline\",\"log(num_features)_Poly all num\", \n                                             None,0.733729,12874,35,52,1799]], \n                                      columns=col), ignore_index=True)\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\"log(num_features)_Poly all num\", \n                                             0.73416,0.733737,8654,1237,4272,597]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam2\",\"log(num_features)_Poly all num\", \n                                             0.73412,0.733747,8682,1230,4244,604]], \n                                      columns=col), ignore_index=True)\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\n                                             \"log(num_features)_Poly all num StratifiedShuffleSplit\", \n                                             0.73320,0.7249, 8553, 1230, 4333, 644]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\n                                             \"log(num_features)_Poly all num edu_nan2SCH\", \n                                             0.73401,0.7335, 8690, 1231, 4236, 603]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\n                                             \"log(num_features)_Poly6 all num edu_nan2SCH:all\",\n                                             0.73470,0.735008,8749,1222,4177,612]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam\",\n                                             \"log(num_features)_Polinome2:all6 edu_nan2SCH:all\",\n                                             0.73822,0.738243,8709,1230,4217,604]], \n                                      columns=col), ignore_index=True)\n\n\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam_auc\",\n                                             \"log(num_features)_Polinome2:all6 edu_nan2SCH:all\",\n                                             None,0.738404,12872,48,54,1786]], \n                                      columns=col), ignore_index=True)\n\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_best_hyperparam2_auc\",\n                                             \"log(num_features)_Polinome2:all6 edu_nan2SCH:all\",\n                                             0.73832,0.738478,12873,48,53,1786]], \n                                      columns=col), ignore_index=True)\n\n# this data are definately from the current version document\nresults = results.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all_CP\",\n                                              \"best_basic_hyperparamP2all_CP\", \n                                              0.73805, 0.7383, 8702, 1231, 4224, 603]], \n                                      columns=col), ignore_index=True)  \nresults = results.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",\n                                             \"best_basic_hyperparamP2all\",\n                                             0.73822,0.7382, 8709,1230,4217,604]], \n                                      columns=col), ignore_index=True)     \n\nresults = results.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",\n                                             \"Polinome3:all6\",\n                                             0.73799,0.737044,8715,1220,4211,614]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                             \"Polinome3:all6\",\n                                             0.73821,0.737376,8708,1225,4218,609]], \n                                      columns=col), ignore_index=True)\n \n    \nresults = results.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",\n                                             \"SSS\",\n                                             0.73832,0.737206,8674,1256,4212,618]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                             \"SSS\",\n                                             0.73815,0.737079,8684,1252,4202,622]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"best_basic_hyperparamP2all\",\n                                             \"SSS6\",\n                                             0.73809,0.747101,8600,1326,4286,548]], \n                                      columns=col), ignore_index=True)\n\nresults = results.append(pd.DataFrame(data=[[\"baseline_optbasichyperCP\",\n                                             \"SSS6\",\n                                             0.73791,0.747161,8589,1327,4297,547]], \n                                      columns=col), ignore_index=True)\n\n\n# \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0433\u0440\u0443\u0431\u0443\u044e \u043e\u0446\u0435\u043d\u043a\u0443 \u043f\u0440\u0438\u0431\u044b\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0435\u0434\u043f\u0440\u0438\u044f\u0442\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c \u043c\u043e\u0434\u0435\u043b\u044f\u043c\n# \u0434\u043e\u043f\u0443\u0441\u0442\u0438\u043c, \u0447\u0442\u043e \u0432\u0441\u0435 \u0437\u0430\u0435\u043c\u044b \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0435\n# \u043f\u0440\u0438\u0431\u044b\u043b\u044c \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u043e\u0442 \u0432\u0441\u0435\u0445 \u043e\u0434\u043e\u0431\u0440\u0435\u043d\u043d\u044b\u0445 \u043a\u043b\u0438\u0435\u043d\u0442\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u0435\u0440\u043d\u0443\u0442 \u0437\u0430\u0435\u043c 0.1 \u043e\u0442 \u044d\u0442\u043e\u0439 \u0441\u0443\u043c\u043c\u044b\n# \u0443\u0431\u044b\u0442\u043e\u043a \u043e\u0442 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u0440\u0435\u0434\u0438\u0442\u0430 0.5 \u043e\u0442 \u044d\u0442\u043e\u0439 \u0441\u0443\u043c\u043c\u044b\n\nprofit = 0.1 \nloss_default = 0.5\n\nresults[\"profit\"]=profit*results[\"TN_00\"]-loss_default*results[\"FN_10\"]\nresults[\"profit%\"]=results[\"profit\"]\/results.iloc[0][\"profit\"]\nresults[\"profit_loss\"]=results[\"profit\"]-results.iloc[0][\"profit\"]\ndisplay(results.sort_values(by=['public_score'],ascending=False))\n","1ce42b0f":">>> # Split iris data in train and test data\n>>> # A random permutation, to split the data randomly\n>>> np.random.seed(0)\n>>> indices = np.random.permutation(len(iris_X))\n>>> iris_X_train = iris_X[indices[:-10]]\n>>> iris_y_train = iris_y[indices[:-10]]\n>>> iris_X_test = iris_X[indices[-10:]]\n>>> iris_y_test = iris_y[indices[-10:]]\n>>> # Create and fit a nearest-neighbor classifier\n>>> from sklearn.neighbors import KNeighborsClassifier\n>>> knn = KNeighborsClassifier()\n>>> knn.fit(iris_X_train, iris_y_train)\nKNeighborsClassifier()\n>>> knn.predict(iris_X_test)\narray([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])\n>>> iris_y_test\narray([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])","4ef8f1b6":"https:\/\/scikit-learn.org\/stable\/auto_examples\/svm\/plot_iris_svc.html#sphx-glr-auto-examples-svm-plot-iris-svc-py","10d3482f":">>> from sklearn import svm\n>>> svc = svm.SVC(kernel='linear')\n>>> svc.fit(iris_X_train, iris_y_train)\nSVC(kernel='linear')","1798aa94":">>> svc = svm.SVC(kernel='linear')","9a163ace":">>> svc = svm.SVC(kernel='poly',\n...               degree=3)\n>>> # degree: polynomial degree","a42112d6":">>> svc = svm.SVC(kernel='rbf')\n>>> # gamma: inverse of size of\n>>> # radial kernel","2eca370b":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(classifier, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))\n\n# horizontal 0.5 0.5 is random","4e9b716e":"X, Y = prepare_space(data[~data._test], num_features, bin_features, cat_features, target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n# roc auc 0.7367, with logistic regression, basic\nmodel = DecisionTreeClassifier(criterion='gini',  splitter='random',\n                               min_samples_split = 8,\n                               min_samples_leaf = 4,max_leaf_nodes = None,\n                               random_state=RANDOM_SEED, max_depth=8,) #max_depth=4,max_features =20, entropy, gini,\nmodel.fit(X_train, y_train)\n\ntest_model_roc_cm(X_test,y_test)","7a044ff4":"num_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income', 'days']\nresults_polinome2all=pd.DataFrame(data=None, columns=None)\n\npf = PolynomialFeatures(2)\npoly_features = pf.fit_transform(data[num_features])\nnew_features=[\"A\"+str(k) for k in range(0,np.shape(poly_features)[1])]\n\ndf_temp=pd.DataFrame(poly_features,columns=new_features)\nnew_features = new_features[len(num_features)+1:]\n\ndata_P2all = pd.concat([data, df_temp[new_features]], axis=1)\nnum_features_P2all=num_features+new_features\n\nX, Y = prepare_space(data_P2all[~data_P2all._test], num_features_P2all, bin_features, cat_features, \n                     target)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=RANDOM_SEED)\n\nmodel = DecisionTreeClassifier(criterion='gini',  splitter='best',\n                               min_samples_split = 10,\n                               min_samples_leaf = 4,max_leaf_nodes = None,\n                               random_state=RANDOM_SEED, max_depth=9,max_features =40,) #max_depth=4,max_features =20, entropy, gini,\nmodel.fit(X_train, y_train)\n\ntest_model_roc_cm(X_test,y_test)","b10ebde9":"random forest","708d4742":"\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043e\u043f\u044f\u0442\u044c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u0442\u0435\u043f\u0435\u0440\u044c, \u0434\u043b\u044f \u0441\u043b\u0443\u0447\u0430\u044f, \u043a\u043e\u0433\u0434\u0430 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b \u0432\u0442\u043e\u0440\u043e\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438, \u0447\u0442\u043e \u0434\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442","f9373b3b":"\u041e\u0447\u0435\u0432\u0438\u0434\u043d\u044b\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 education, \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u0438\u0445 \u043d\u0430 WOE \u0438\u043b\u0438 SCH","40d0fb50":"\u041e\u0446\u0435\u043d\u0438\u043c \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u0440\u0430\u0431\u043e\u0447\u0435\u0439 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0435 ROC.\n\u041f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u043d\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043d\u0435\u043f\u043b\u043e\u0445\u043e\u0439, \u043d\u043e \u0432\u0435\u0440\u043d\u0435\u043c\u0441\u044f \u0432 \u043f\u0440\u0435\u0434\u043c\u0435\u0442\u043d\u0443\u044e \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u0438 \u0432\u0437\u0433\u043b\u044f\u043d\u0435\u043c \u043d\u0430 \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0441\u043e\u043f\u0440\u044f\u0436\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u043e\u0446\u0435\u043d\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","c16f7817":"# \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b \u0434\u043e 3\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u043e\u0442 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445","18c0d202":"Linear kernel\u00b6","e9cb55b2":"Reading this\nhttps:\/\/scikit-learn.org\/stable\/tutorial\/statistical_inference\/supervised_learning.html\n","1ed1344f":"# Decision Tree \u043d\u0435 \u043f\u0440\u0438\u043d\u0435\u0441\u043b\u043e \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0434\u0430\u044e\u0449\u0435\u0433\u043e\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u043d\u0430 \u0442\u0435\u0445 \u0436\u0435 \u0434\u0430\u043d\u043d\u044b\u0445, \u043b\u0443\u0447\u0448\u0438\u0439 roc auc 0.7, \u0447\u0442\u043e \u0443\u0441\u0442\u0443\u043f\u0430\u0435\u0442 logreg \u043d\u0430 0.04. (\u0413\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0432\u0430\u0440\u044c\u0438\u0440\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u0432\u0440\u0443\u0447\u043d\u0443\u044e)","c28aac88":"\u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 P2all, \u0442\u0430\u043a \u043a\u0430\u043a \u044d\u0442\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0442 \u0441\u0438\u0441\u0442\u0435\u043c\u0443, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u043b\u0438\u0436\u0435 \u043a \u0441\u0438\u0441\u0442\u0435\u043c\u0435 \u0441 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0430\u043c\u0438 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u043e\u0433\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0430","1282d240":"Bootstrap aggregation, bagging\nRANDOM SUBSPACES (RSS)","705fb23f":"# \u041f\u0443\u0431\u043b\u0438\u043a\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","6777c479":"# \u0412\u0441\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","2753c37d":"# \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b \u0434\u043e 3\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u043e\u0442 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445","939ad4ac":"## \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","f9881bc9":"RBF kernel (Radial Basis Function)","b32c620b":"\u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 \u0433\u0440\u0443\u043f\u043f\u044b","6176c280":"\u043a\u0430\u043a \u0432\u0438\u0434\u043d\u043e, \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u044c \u043d\u0435 \u0440\u0430\u0441\u0442\u0435\u0442. \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u0431\u0440\u0430\u0442\u044c \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043a\u043e\u043a\u0438\u0435 \u043f\u043e\u0440\u044f\u0434\u043a\u0438, \u0438\u043b\u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u0438 \u044d\u0442\u0438\u0445 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432. ","91bd454e":"\u041f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 roa_auc \u043d\u0435 \u0443\u043b\u0443\u0447\u0448\u0438\u043b\u0430\u0441\u044c, \u0438 \u043c\u044b \u0432\u0441\u0435 \u0436\u0435 \u043f\u0440\u0438\u0448\u043b\u0438 \u043a \u043a\u043e\u043c\u043f\u0440\u043e\u043c\u0438\u0441\u0441\u0443: \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043b\u0438 \u0434\u043e\u043b\u044e \u0440\u0438\u0441\u043a\u0430 \u043f\u043e \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u043c \u043a\u0440\u0435\u0434\u0438\u0442\u0430\u043c \u0437\u0430 \u0441\u0447\u0435\u0442 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u044f \u043b\u043e\u0436\u043d\u043e-\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0438\u0441\u0445\u043e\u0434\u043e\u0432.","823a2f51":"# \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432","69d782fc":"train_test_split","151a5c77":"## \u043f\u043e\u043f\u0430\u0440\u043d\u043e \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b 2\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u043e\u0442 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445","bf51b71b":"\u041f\u043e\u0432\u0430\u0440\u044c\u0438\u0440\u0443\u0435\u043c \u0421 \u0438 penalty ","bcf4948e":"\u0417\u0430\u043c\u0435\u0442\u043d\u0430 \u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0434\u043e\u043b\u044f (12%) \u043b\u043e\u0436\u043d\u043e-\u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\n\n1797 (\u0438\u043b\u0438 12%) \u043b\u043e\u0436\u043d\u043e-\u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 - \u044d\u0442\u043e \u0442\u0435 \u043a\u043b\u0438\u0435\u043d\u0442\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0432\u044b\u0434\u0430\u0442\u044c \u043a\u0440\u0435\u0434\u0438\u0442, \u043d\u043e \u043e\u043d\u0438 \u0435\u0433\u043e \u043d\u0435 \u0432\u0435\u0440\u043d\u0443\u043b\u0438. \u042d\u0442\u043e \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u0442 \u043a **\u043f\u0440\u044f\u043c\u044b\u043c \u0440\u0430\u0441\u0445\u043e\u0434\u0430\u043c**.\n\n50 (\u0438\u043b\u0438 57%) \u043b\u043e\u0436\u043d\u043e-\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 - \u044d\u0442\u043e \u0442\u0435 \u043a\u043b\u0438\u0435\u043d\u0442\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043d\u0435 \u0432\u044b\u0434\u0430\u0432\u0430\u0442\u044c \u043a\u0440\u0435\u0434\u0438\u0442, \u043d\u043e \u043e\u043d\u0438 \u0435\u0433\u043e \u0432\u0435\u0440\u043d\u0443\u043b\u0438. \u042d\u0442\u043e \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u0442 \u043a **\u043d\u0435\u0434\u043e\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043f\u0440\u0438\u0431\u044b\u043b\u0438**.\n\n","c625526a":"\u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u0438","a13fd3e4":"# \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 **\u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445** \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","fc5d379e":"\u041d\u043e \u043f\u0440\u0435\u0436\u0434\u0435 \u0447\u0435\u043c \u0438\u0434\u0442\u0438 \u043d\u0430 \u043a\u043e\u043c\u043f\u0440\u043e\u043c\u0438\u0441\u0441 \u0432 \u0432\u044b\u0431\u043e\u0440\u0435 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0449\u0435\u0433\u043e \u043a\u043b\u0430\u0441\u0441 \u043f\u043e\u0440\u043e\u0433\u0430 \u0434\u043b\u044f \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0439, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u0443\u0442\u0435\u043c \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438.","02cb264e":"StratifiedShuffleSplit","f841bc62":"\u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u0430\u0440\u044b \u0443\u043b\u0443\u0447\u0448\u0430\u044e\u0442 \u0441\u043a\u043e\u0440\u0438\u043d\u0433 \u0438 \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043e\u0448\u0438\u0431\u043e\u043a, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u043e\u0436\u043d\u043e \u0432\u0437\u044f\u0442\u044c \u0434\u043b\u044f \u043f\u0440\u043e\u0441\u0442\u043e\u0442\u044b \u0432\u0441\u0435 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b \u0432\u0442\u043e\u0440\u043e\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438","56031187":"# \u0422\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u0442\u0438\u043f\u044b \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","6df5c56c":"PCA","9883a696":"Stacked Generalization https:\/\/machinelearningmastery.com\/stacking-ensemble-machine-learning-with-python\/","90221fd7":"Try after NY","1b060d3b":"# \u0410\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u043a\u043b\u0430\u0434\u043d\u0443\u044e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0430\u043a\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","7bcbe8cd":"# \u0420\u0435\u0437\u0443\u043b\u0442\u0430\u0442\u044b (\u0447\u0442\u043e \u0431\u044b\u043b\u043e \u043f\u0440\u043e\u0434\u0435\u043b\u0430\u043d\u043e)\n1. \u0412 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u0442 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438, \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435. \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u043e, \u0447\u0442\u043e \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u043d\u0430 SCH, \u0447\u0435\u043c \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u043d\u043e\u0432\u0443\u044e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044e (\u0431\u0435\u0437 \u043e\u0431\u0440). \n2. \u0414\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0434\u0430\u0442\u0435 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0430\u0446\u0438\u0438 \u0437\u0430\u044f\u0432\u043a\u0438 \u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043a\u0440\u0435\u0434\u0438\u0442\u0430 \u0431\u044b\u043b\u0438 \u043f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043d\u044b \u0432 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f (\u0432 \u0435\u0434\u0438\u043d\u0438\u0446\u0430\u0445 \"\u0434\u0435\u043d\u044c\"). \n3. \u0412\u0441\u0435 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u044b\u043b\u0438 \u0434\u043e \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u0430 2\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u043f\u0435\u0440\u0435\u043c\u043d\u043e\u0436\u0435\u043d\u044b \u0438 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b \u0432 \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0435\u043d\u0438\u0435.  \n4. \u0411\u044b\u043b\u0438 \u043f\u043e\u043f\u044b\u0442\u043a\u0438 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u043e\u0432 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u043e\u0433\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0430, \u043d\u043e \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432 \u044d\u0442\u043e \u043d\u0435 \u043f\u0440\u0438\u043d\u0435\u0441\u043b\u043e.\n5. \u0412\u0441\u0435 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0431\u044b\u043b\u0438 \u043b\u043e\u0433\u043e\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u044b, \u0447\u0442\u043e \u0441\u0434\u0435\u043b\u0430\u043b\u043e \u0438\u0445 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0431\u043e\u043b\u0435\u0435 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0438 \u0443\u043b\u0443\u0447\u0448\u0435\u043b\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435.\n6. \u0412 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0435\u0441\u0442\u044c \u0432\u044b\u0431\u0440\u043e\u0441\u044b (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043e\u0447\u0435\u043d\u044c \u0432\u044b\u0441\u043e\u043a\u0438\u0435 \u0434\u043e\u0445\u043e\u0434\u044b), \u043d\u043e \u0441 \u043d\u0438\u043c\u0438 \u0440\u0435\u0448\u0435\u043d\u043e \u0431\u044b\u043b\u043e \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u0435\u043b\u0430\u0442\u044c. \n7. \u0421\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u043b \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044e \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (2 \u043c\u0430\u0441\u0441\u0438\u0432\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u043b\u0438\u0441\u044c \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e) \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u044e f1 \u0438 roc_auc. f1 \u0434\u0430\u0435\u0442 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0443\u044e \u043f\u0440\u0438\u0431\u044b\u043b\u044c (\u0441\u043c. \u0434\u0430\u043b\u0435\u0435), \u0430 roc_auc \u043f\u043e\u0432\u044b\u0448\u0430\u0435\u0442 \u0441\u043a\u043e\u0440\u0438\u043d\u0433 (\u044d\u0442\u043e\u0442 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0432 \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434\u0435).\n8. roc_auc, confusion_matrix \u0438 public leader board scoring, \u0430 \u0442\u0430\u043a\u0436\u0435 \u043a\u043e\u0440\u043e\u0442\u043a\u043e\u0435 \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u044b \u0432 df=results \u0432 \u043a\u043e\u043d\u0446\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430. \u0422\u0430\u043c \u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u0435\u0441\u043b\u0438 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043d\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c, \u0438\u043b\u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f roc_auc, \u0442\u043e f1 \u0431\u0443\u0434\u0435\u0442 \u043d\u0438\u0437\u043a\u0438\u043c, \u0442\u0430\u043a\u0436\u0435 \u043a\u0430\u043a \u0438 \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u0430\u0433\u0430\u0435\u043c\u0430\u044f \u0432\u044b\u0440\u0443\u0447\u043a\u0430 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438. \u042d\u0442\u043e \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 \u0438\u0437-\u0437\u0430 \u0431\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u043a\u043e\u043b\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043b\u043e\u0436\u043d\u043e-\u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 (\u0432\u044b\u0434\u0430\u0447\u0430 \u0437\u0430\u0432\u0435\u0434\u043e\u043c\u043e \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0445-\u043a\u0440\u0435\u0434\u0438\u0442\u043e\u0432).\n9. \u0412\u044b\u0432\u043e\u0434, roc_auc \u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440, \u043d\u043e f1 \u043b\u0443\u0447\u0448\u0435 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0435\u0442 \u043f\u043e\u0442\u0440\u0435\u0431\u043d\u043e\u0441\u0442\u0438 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438, \u0430 \u043b\u0443\u0447\u0448\u0435 \u0432\u0432\u0435\u0441\u0442\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0442\u0438\u043f\u0430 profit.\n10. \u041f\u0440\u043e\u0431\u043e\u0432\u0430\u043b \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0438\u043f\u044b \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445: train_test_split, KFold, StratifiedShuffleSplit, \u043e\u043d\u0438 \u0432\u0441\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u043b\u0438 \u043f\u043e\u0445\u043e\u0436\u0438\u0435 \u043d\u0430 train_test_split \u043c\u0435\u0442\u0440\u0438\u043a\u0438.\n11. \u041b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0430 Kaggle LeaderBoard \u043e\u0442 20210211, 11 \u043c\u0435\u0441\u0442\u043e Andrey Pravdivtsev \u0441\u043a\u043e\u0440\u0438\u043d\u0433 0.73832.\n\n\n# \u0427\u0442\u043e \u0435\u0449\u0435 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0431\u044b \u0441\u0434\u0435\u043b\u0430\u0442\u044c?\n1. \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u043e\u0431\u0440\u0430\u0442\u043d\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b \u043e\u0442 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445,  \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 1\/days, \u0438 \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043d\u0430 \u0438\u0445 \u043e\u0441\u0432\u043d\u043e\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435.\n2. \u041f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u043a\u043b\u0430\u0434 \u043e\u0442 \u0443\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u0432 \u0434\u0430\u043d\u043d\u044b\u0445. \n3. \u041f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c oversampling\/undersampling.\n4. \u0414\u0440\u0443\u0433\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438, \u043e\u0442\u043b\u0438\u0447\u043d\u044b\u0435 \u043e\u0442 LogisticRegression\n5. \u0411\u043e\u043b\u0435\u0435 \u0430\u043a\u043a\u0443\u0440\u0430\u0442\u043d\u043e \u043f\u0435\u0440\u0435\u043f\u0438\u0441\u0430\u0442\u044c \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0434\u043b\u044f \u043f\u0443\u0431\u043b\u0438\u043a\u0430\u0446\u0438\u0438, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0441 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432. \n\n\n","cc5f8be8":"# \u0421\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","29ac7018":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0435\u0439, \u043a\u0430\u043a \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u043e\u0441\u0442\u044b\u043c \u0438 \u0431\u044b\u0441\u0442\u0440\u044b\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.","2ca1e639":"\u041e\u0431\u0440\u0430\u0442\u0438\u043c \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e \u0431\u043e\u043b\u044c\u0448\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u043c\u0435\u044e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u0439 \u0438 \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0431\u044e\u0440\u043e \u043a\u0440\u0435\u0434\u0438\u043d\u0442\u043d\u044b\u0445 \u0438\u0441\u0442\u043e\u0440\u0438\u0439.","89d32a9a":"\u041c\u0435\u0442\u0440\u0438\u043a\u0438, \u0438 \u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u043e\u0448\u0438\u0431\u043e\u043a \u0441\u043e\u0432\u043f\u043e\u0434\u0430\u044e\u0442 \u0432 \u043f\u0440\u0435\u0434\u0435\u043b\u0430\u0445 \u043f\u043e\u0433\u0440\u0435\u0448\u043d\u043e\u0441\u0442\u0438 \u0441 \u043e\u0431\u044b\u0447\u043d\u043e\u0439 \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043c\u043e\u0436\u043d\u043e \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u043e\u0439 ","c8b9a4e1":"Polynomial kernel","e330d187":"Precision-recall curve\nhttps:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_precision_recall.html","a0991a96":"KNN (k nearest neighbors) classification example:","d2fa33e5":"\u0421\u0432\u044f\u0437\u044c \u0441 \u0441\u043e\u0442\u0440\u0443\u0434\u043d\u0438\u043a\u0430\u043c\u0438 \u0431\u0430\u043d\u043a\u0430, \u0430 \u0442\u0430\u043a\u0436\u0435, \u043f\u043e-\u0432\u0438\u0434\u0438\u043c\u043e\u043c\u0443, \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0436\u0438\u0437\u043d\u0438 \u0432 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0438 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430 \u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442 \u0431\u043e\u043b\u044c\u0448\u0435\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u043d\u0430 \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e.\n\n\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043a \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044e \u0432 \u043c\u043e\u0434\u0435\u043b\u0438: \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435.","5a9ad9b7":"\u0412 \u0441\u0432\u044f\u0437\u0438 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0441 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u0442\u043e\u0436\u0435 \u043d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u044f\u0432\u043d\u044b\u0445 \u0437\u0430\u043a\u043e\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0435\u0439.\n\u0415\u0441\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u043b\u0430\u0431\u044b\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440\n1. \u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0437\u0430\u0433\u0440\u0430\u043d \u043f\u0430\u0441\u0441\u043f\u043e\u0440\u0442\u0430 \u044d\u0442\u043e +\n2. \u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f \u044d\u0442\u043e +\n3. \u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0430\u0434\u0440\u0435\u0441, \u0434\u043e\u043c\u0430\u0448\u043d\u0438\u0439 \u0430\u0434\u0440\u0435\u0441 \u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0442. \u0438 \u0442.\u0434.\n\n\u041e\u0446\u0435\u043d\u0438\u043c \u0442\u0435\u043f\u0435\u0440\u044c \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u044d\u0442\u0438\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0431\u043e\u043b\u0435\u0435 \u043a\u043e\u043b\u043b\u0438\u0447\u0435\u0442\u0441\u0432\u0435\u043d\u043d\u043e.\n\n**\u041f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.**","336be54b":"# \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u043d\u044b\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a","076386db":"## \u0432\u0441\u0435 \u043f\u043e\u043b\u0438\u043d\u043e\u043c\u044b 2\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u043e\u0442 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445","2a9fd8b2":"\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u043e\u0445\u043e\u0434\u0430 \u0438\u043c\u0435\u0435\u0442 \"\u0434\u043b\u0438\u043d\u043d\u044b\u0439 \u0445\u0432\u043e\u0441\u0442\" \u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u043c\u0430\u0441\u0448\u0442\u0430\u0431 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438.","690aaa54":"\u041f\u043e\u0432\u0430\u0440\u044c\u0438\u0440\u0443\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f","c8950c32":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0442\u0435\u043f\u0435\u0440\u044c \u043d\u0430 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0441 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439","bc29be11":"# \u0442\u0435\u0441\u0442 \u0441 \u0431\u0430\u0437\u043e\u0432\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438","d8e9df45":"Support vector machines (SVMs)","02bc314a":"Decision Tree with polynome of the second order","e2023fea":"\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0438\u0437 \u0430\u043d\u043a\u0435\u0442\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u043e\u0432 (train.csv and test.csv):\n\n* client_id - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u043a\u043b\u0438\u0435\u043d\u0442\u0430,\n* education - \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f,\n* sex - \u043f\u043e\u043b \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430,\n* age - \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430,\n* car - \u0444\u043b\u0430\u0433 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f,\n* car_type - \u0444\u043b\u0430\u0433 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f \u0438\u043d\u043e\u043c\u0430\u0440\u043a\u0438,\n* decline_app_cnt - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u043e\u0448\u043b\u044b\u0445 \u0437\u0430\u044f\u0432\u043e\u043a,\n* good_work - \u0444\u043b\u0430\u0433 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \"\u0445\u043e\u0440\u043e\u0448\u0435\u0439\" \u0440\u0430\u0431\u043e\u0442\u044b,\n* bki_request_cnt - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 \u0432 \u0411\u041a\u0418,\n* home_address - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0437\u0430\u0442\u043e\u0440 \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u0430\u0434\u0440\u0435\u0441\u0430,\n* work_address - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0437\u0430\u0442\u043e\u0440 \u0440\u0430\u0431\u043e\u0447\u0435\u0433\u043e \u0430\u0434\u0440\u0435\u0441\u0430,\n* income - \u0434\u043e\u0445\u043e\u0434 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430,\n* foreign_passport - \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0437\u0430\u0433\u0440\u0430\u043d\u043f\u0430\u0441\u043f\u043e\u0440\u0442\u0430,\n* sna - \u0441\u0432\u044f\u0437\u044c \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430 \u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430\u043c\u0438 \u0431\u0430\u043d\u043a\u0430,\n* first_time - \u0434\u0430\u0432\u043d\u043e\u0441\u0442\u044c \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043e \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0435,\n* score_bki - \u0441\u043a\u043e\u0440\u0438\u043d\u0433\u043e\u0432\u044b\u0439 \u0431\u0430\u043b\u043b \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c \u0438\u0437 \u0411\u041a\u0418,\n* region_rating - \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0440\u0435\u0433\u0438\u043e\u043d\u0430,\n* app_date - \u0434\u0430\u0442\u0430 \u043f\u043e\u0434\u0430\u0447\u0438 \u0437\u0430\u044f\u0432\u043a\u0438,\n* default - \u0444\u043b\u0430\u0433 \u0434\u0435\u0444\u043e\u043b\u0442\u0430 \u043f\u043e \u043a\u0440\u0435\u0434\u0438\u0442\u0443.","cb938eca":"\u041d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043e\u0442\u043a\u0430\u0437\u043e\u0432, \u0447\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u043e\u0431\u044a\u044f\u0441\u043d\u044f\u0442\u044c\u0441\u044f \u0441\u0430\u043c\u0438\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u043c \u0432\u044b\u0434\u0430\u0447\u0438 \u043a\u0440\u0435\u0434\u0438\u0442\u043e\u0432. \u041d\u043e \u0432 \u0446\u0435\u043b\u043e\u043c \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0441\u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u044b \u0441\u043b\u0430\u0431\u043e.\n\n\u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0442\u0435\u043f\u0435\u0440\u044c \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.","d809138b":"StratifiedShuffleSplit \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u044c \u043c\u0435\u0442\u043e\u0434\u0430, \u043d\u043e \u0432\u0441\u0435 \u0435\u0449\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043e\u0442 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f\n\u041f\u0440\u0438 \u0438\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u043e\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438 (random seed = RANDOM_SEED) \u0434\u0430\u0435\u0442 \u043d\u0430\u0438\u0432\u044b\u0441\u0448\u0438\u0439 roc auc!","6270c68b":"\u0432\u0430\u0440\u044c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u0442 roc auc \u0432 \u043f\u0440\u0435\u0434\u0435\u043b\u0430\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e 0.01, \u0447\u0442\u043e \u0431\u0443\u0434\u0435\u0442 \u0442\u0430\u043a\u0436\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u043d\u043e \u043d\u0438\u0436\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f kFold \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435. \u041c\u043e\u0434\u0435\u043b\u044c \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u0430, \u043d\u043e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043d\u0435 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e. \u0412\u043e\u0437\u044c\u043c\u0435\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u0432 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0435 \u043e\u0442 0 \u0434\u043e 10, \u043a\u0430\u043a \u0431\u044b\u043b\u043e \u043f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043e \u0442\u0443\u0442 \u0438 \u043f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0430 \u043f\u0430\u0431\u0438\u043b\u043a \u0431\u043e\u0440\u0434\u0435.\n\n\u0412 \u0442\u0435\u0441\u0442\u0435 \u044d\u0442\u043e \u0434\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u043d\u043e \u043d\u0430 \u043f\u0430\u0431\u043b\u0438\u043a \u0431\u043e\u0440\u0434\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0443\u0445\u0443\u0434\u0448\u0430\u0435\u0442\u0441\u044f. \u041e\u0441\u0442\u0430\u0432\u0438\u043c \u0438\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435","0c98b48d":"'app_date', 'client_id' \u0434\u0430\u043d\u043d\u044b\u0435 \u0432\u0440\u043e\u0434\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u044b \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430, \u043d\u043e \u0432\u0430\u0436\u043d\u044b \u0434\u043b\u044f \u0431\u0430\u043d\u043a\u0430"}}