{"cell_type":{"3a241b62":"code","2567c024":"code","ff8e7f98":"code","ecaee54b":"code","cffee151":"code","7c463c24":"code","1d4c014f":"code","b363ebed":"code","a628e25d":"code","cb756378":"code","951aa0f9":"code","d0e783d1":"code","e5ab6526":"code","4b0aa01d":"code","ac05f8dd":"code","f394c5a4":"code","75f10f3e":"code","15859799":"code","59ab0b68":"markdown","5c9353ac":"markdown","c1cd262a":"markdown","6b27a70f":"markdown","65b54b13":"markdown"},"source":{"3a241b62":"#importing necessary libraries\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Input,Conv2D,Activation,Dense,Lambda,Flatten,Embedding,PReLU,BatchNormalization,Dropout,MaxPooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy, mean_squared_error,sparse_categorical_crossentropy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler, TensorBoard, EarlyStopping, ModelCheckpoint","2567c024":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nprint(train.shape)\ntrain.head()","ff8e7f98":"test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nprint(test.shape)\ntest.head()","ecaee54b":"train=train.to_numpy()\ntest =test.to_numpy()","cffee151":"X_train = train[:,1:] # all pixel values\ny_train = train[:,0] # only labels i.e targets digits\nX_test  = test\n\n\nn_rows = X_train.shape[0]\nn_cols = X_train.shape[1]\nmean = 0.3\nstddev = 0.1\nnoise = np.random.normal(mean, stddev, (n_rows, n_cols))\n# creating the noisy test data by adding X_test with noise\n#X_train = X_train+ noise","7c463c24":"#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)","1d4c014f":"# one hot encoding the labels\n\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","b363ebed":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()\n# fix random seed for reproducibility\nseed = 42\nnp.random.seed(seed)\n\nfrom sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","a628e25d":"inputs=Input((28,28,1))\nx=Conv2D(32,(3,3),kernel_initializer='he_uniform')(inputs)\nx=BatchNormalization()(x)\nx=PReLU()(x)\n#x=Dropout(0.5)(x)\n\nx=Conv2D(32,(3,3),kernel_initializer='he_uniform')(x)\nx=BatchNormalization()(x)\nx=PReLU()(x)\n#x=Dropout(0.5)(x)\n\nx=Conv2D(64,(3,3),kernel_initializer='he_uniform')(x)\nx=BatchNormalization()(x)\nx=PReLU()(x)\n#x=Dropout(0.5)(x)\n\nx=Conv2D(64,(3,3),kernel_initializer='he_uniform')(x)\nx=BatchNormalization()(x)\nx=PReLU()(x)\nx=MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n#x=Dropout(0.5)(x)\n\nx=Conv2D(128,(3,3),kernel_initializer='he_uniform')(x)\nx=BatchNormalization()(x)\nx=PReLU()(x)\nx=MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n#x=Dropout(0.5)(x)\n\nx=Conv2D(128,(3,3),kernel_initializer='he_uniform')(x)\nx=BatchNormalization()(x)\nx=PReLU()(x)\n#x=Dropout(0.5)(x)\n\n#x=Flatten()(x)\nx=GlobalAveragePooling2D()(x)\nx=Dense(64)(x)\nout1=PReLU(name=\"out1\")(x)\n\nout2=Dense(10,activation=\"softmax\")(out1)\n\nmodel=Model(inputs,out2)\nmodel.summary()","cb756378":"model.compile(loss=categorical_crossentropy,\n              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n              metrics=['accuracy'])\n\nlr_reducer = ReduceLROnPlateau('val_accuracy', factor=0.08, patience=3, verbose=1, mode='auto')\ntensorboard = TensorBoard(log_dir='.\/logs')\nearly_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=8, verbose=1, mode='auto')\n\nmodel.fit(X_train,y_train,batch_size=32,epochs=100,verbose=1,validation_data=(X_val,y_val),\n         shuffle=True,\n          callbacks=[lr_reducer, tensorboard, early_stopper] )\n                    ","951aa0f9":"#for layer in model.layers:\n#    layer.trainable = False\n#new_model= Sequential()\n#for layer in model.layers[:-1]: #just exclude the last two layers from base_model\n#    new_model.add(layer)\n#new_model.summary()","d0e783d1":"#x3_train=new_model.predict(X_train)\n#x3_test =new_model.predict(X_test)\n#x3_val =new_model.predict(X_val)\n#y3_train=np.argmax(y_train, axis=1)\n#y3_val=np.argmax(y_val, axis=1)\n\n\n","e5ab6526":"#from sklearn.metrics import accuracy_score,hinge_loss\n#from sklearn.ensemble import RandomForestClassifier\n#clf=RandomForestClassifier()\n#hystory=clf.fit(x3_train, y3_train)\n##y_pred = clf.predict(x3_test)\n#y_pred = clf.predict(x3_val)\n#print(\"Accuracy:\",accuracy_score(y3_val, y_pred))","4b0aa01d":"predictions = model.predict(X_test,batch_size=64)\nimage_id = range(1, predictions.shape[0] + 1)","ac05f8dd":"pred = [np.argmax(i) for i in predictions]","f394c5a4":"sample = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsample.head()","75f10f3e":"submission = pd.DataFrame({'ImageId': image_id, 'Label': pred})\nsubmission.to_csv('digit_recognizer_submission', index=False)\n","15859799":"submission.head()","59ab0b68":"## Simple Model","5c9353ac":"# Model Designing","c1cd262a":"# Standardization","6b27a70f":"In this notebook i'll try to build a simple Digit Recognizer model with the help of neural network since i'm a beginner","65b54b13":"# Importing the dataset"}}