{"cell_type":{"83d6054d":"code","80da0dcb":"code","f7772adc":"code","6e183ebb":"code","ca952201":"code","e8cf980f":"code","f61e34f0":"code","6bbb7311":"code","9ac03b51":"code","6b6a00f4":"code","3ea091f1":"code","555ac50e":"code","1cbdf77c":"code","46278755":"code","5715b060":"code","4d10b5bb":"code","cb0b227d":"code","f19163f7":"code","c8a12bb2":"code","2171cec1":"code","1b9aed13":"code","b4f23b27":"code","893e4668":"code","895c0fa3":"code","366573eb":"code","25a8a329":"code","795fbcea":"code","540c492d":"code","99f30605":"code","2c7c192d":"code","a6099142":"code","4ba51e58":"markdown","bef550ae":"markdown","aed013c0":"markdown","8fca5b8f":"markdown","54b2e335":"markdown","b32b2adb":"markdown","35ed3648":"markdown"},"source":{"83d6054d":"import numpy as np\nimport pandas as pd\nimport PIL\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\nfrom tensorflow.keras.preprocessing import image","80da0dcb":"key_points_data_path = \"..\/input\/celeba-dataset\/list_landmarks_align_celeba.csv\"\nimages_data_path = \"..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\"\nimages_data_size = 10000 #because dataset is huge\n\n# original image dimension\nx_org = 178\ny_org = 218\n\n#new image dimension\nx_ = 100\nimage_size_ratio = x_org\/y_org\ny_ = int(image_size_ratio*x_)\n\noriginal_image_size = (x_org,y_org)\nnew_image_size = (x_,y_)\n","f7772adc":"df_org = pd.read_csv(key_points_data_path)\ndf = df_org[:images_data_size]","6e183ebb":"images_data = list()\nfor idx in range(df.shape[0]):\n    path = \"{}\/{}\".format(str(images_data_path),str(df.iloc[idx].image_id))\n    image = PIL.Image.open(path).resize(new_image_size)\n    image_array = np.asarray(image)\/255\n    images_data.append(image_array)\nimages_data = np.array(images_data)","ca952201":"plt.imshow(images_data[500])","e8cf980f":"print(\"Images Data Arrays Shape: \",images_data.shape)\nprint(\"Key Points Data Shape:\", df.shape)","f61e34f0":"df.isnull().sum()","6bbb7311":"df.head(5)","9ac03b51":"df.describe()","6b6a00f4":"# function to read images based on index\n\"\"\"\nThis functions is for converting images to arrays to deal with it in the model.\nInput:  index of the image that we want to convert to array\n        size of the image that we want for the array of the image\n        path of the images data to get the image\nOutput: the image array as numpy array\n    \"\"\"\ndef image_array(index, size=new_image_size, path=images_data_path):\n    # to get the path based on index\n    path = \"{}\/{}\".format(str(path),str(df.iloc[index].image_id))\n    \n    # to read the image\n    image = PIL.Image.open(path).resize(size)\n    image_array = np.asarray(image)\n    \n    return image_array","3ea091f1":"# fuction to get a list of all key points of the face\ndef image_key_points_list(index, df=df):\n    # box dictionary\n    points_list = [df.iloc[index].lefteye_x,\n                   df.iloc[index].lefteye_y,\n                   df.iloc[index].righteye_x,\n                   df.iloc[index].righteye_y,\n                   df.iloc[index].nose_x,\n                   df.iloc[index].nose_y,\n                   df.iloc[index].leftmouth_x,\n                   df.iloc[index].leftmouth_y,\n                   df.iloc[index].rightmouth_x,\n                   df.iloc[index].rightmouth_y]\n    \n    return points_list\n","555ac50e":"#function to plot the image with green box around the faces\ndef plotting_image_with_box(index,df=df,size = original_image_size):\n    test_image  = image_array(index,size)\n    points_list = image_key_points_list(index,df)\n    le_x, le_y, re_x, re_y = points_list[0], points_list[1], points_list[2], points_list[3]\n    n_x, n_y = points_list[4], points_list[5]\n    lm_x, lm_y, rm_x, rm_y = points_list[6], points_list[7], points_list[8], points_list[9]\n    fig,ax = plt.subplots()\n    ax.imshow(test_image) #plot the image\n    ax.plot([le_x,re_x,n_x,lm_x,rm_x],[le_y,re_y,n_y,lm_y,rm_y],'bo-')#plot points on face","1cbdf77c":"plotting_image_with_box(50)","46278755":"plotting_image_with_box(100)","5715b060":"plotting_image_with_box(5000)","4d10b5bb":"df_new = df.copy()","cb0b227d":"# function for updating key points for a new size\ndef rescale_key_points(oldsize=original_image_size,newsize=new_image_size):\n    x_axis_old = oldsize[0]\n    y_axis_old = oldsize[1]\n\n    x_axis_new = newsize[0]\n    y_axis_new = newsize[1]\n\n    x_ratio = x_axis_new \/ x_axis_old\n    y_ratio = y_axis_new \/ y_axis_old\n    \n    keypoints_x = ['lefteye_x', 'righteye_x', 'nose_x', 'leftmouth_x', 'rightmouth_x']\n    keypoints_y = ['lefteye_y', 'righteye_y', 'nose_y', 'leftmouth_y', 'rightmouth_y']\n    \n    df_new[keypoints_x] = (df_new[keypoints_x] * x_ratio).astype('int')\n    df_new[keypoints_y] = (df_new[keypoints_y] * y_ratio).astype('int')\n    \n    return 0\nrescale_key_points()\n\ndf_new.head()","f19163f7":"images = images_data # list of array of images\nlabels = df  # dataframe of image features","c8a12bb2":"train_images,test_images,train_labels,test_labels = train_test_split(images,labels,test_size=0.3,random_state=45)","2171cec1":"y_test=test_labels.drop([\"image_id\"],axis=1)\ny_train=train_labels.drop([\"image_id\"],axis=1)\n\nX_test=test_images\nX_train=train_images\nprint(\"Samples in Training Data:\",len(X_train))","1b9aed13":"X_test, X_val, y_test, y_val=train_test_split(X_test, y_test,test_size=0.5,random_state=42)\nprint(\"Samples in Validation Data:\",len(X_val))\nprint(\"Samples in Test Data:\",len(X_test))","b4f23b27":"x_ = new_image_size[0]\ny_ = new_image_size[1]\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=8,kernel_size=(3,3),padding = 'same',activation = 'relu',input_shape=(y_,x_,3)))\nmodel.add(Conv2D(filters=8, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding = 'same',activation = 'relu'))\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='relu'))","893e4668":"model.summary()","895c0fa3":"model.compile(optimizer = \"rmsprop\",loss='mean_squared_error',metrics = ['mae'])","366573eb":"training_process = model.fit(X_train,y_train,epochs = 50,validation_data = (X_val,y_val),batch_size=4,shuffle = True)","25a8a329":"model.evaluate(X_test,y_test)","795fbcea":"def predictions_test_model(index):\n    img = tf.keras.preprocessing.image.load_img(\"{}\/0{}.jpg\".format(images_data_path, index),target_size=(y_,x_,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = img\/255\n    points_list = model.predict(img.reshape(1,y_,x_,3)).astype('int')[0]\n    \n    # converting key points values to the original size\n    x_ratio = 0.55 * (original_image_size[0] \/ new_image_size[0])\n    y_ratio = 0.39 * (original_image_size[1] \/ new_image_size[1])\n    points_list[0] = int(points_list[0] * x_ratio)\n    points_list[2] = int(points_list[2] * x_ratio)\n    points_list[4] = int(points_list[4] * x_ratio)\n    points_list[6] = int(points_list[6] * x_ratio)\n    points_list[8] = int(points_list[8] * x_ratio)\n    \n    points_list[1] = int(points_list[1] * y_ratio)\n    points_list[3] = int(points_list[3] * y_ratio)\n    points_list[5] = int(points_list[5] * y_ratio)\n    points_list[7] = int(points_list[7] * y_ratio)\n    points_list[9] = int(points_list[9] * y_ratio)\n    \n    return points_list","540c492d":"def test_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='bo-'):\n    img = tf.keras.preprocessing.image.load_img(\"{}\/0{}.jpg\".format(images_data_path, index),target_size=(y_org,x_org,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    test_image = img\/255\n    \n    # predictions of key points on the face\n    if pred_or_actual == 'pred':\n        points_list = predictions_test_model(index)        # this for predections of the model\n    elif pred_or_actual == 'actual':\n        points_list = image_key_points_list(index)   # this for the actual labels of the test data\n    \n    # face points\n    le_x, le_y, re_x, re_y = points_list[0], points_list[1], points_list[2], points_list[3]\n    n_x, n_y = points_list[4], points_list[5]\n    lm_x, lm_y, rm_x, rm_y = points_list[6], points_list[7], points_list[8], points_list[9]\n     # Create figure and axes\n    fig, ax = plt.subplots()\n    # plot the image\n    ax.imshow(test_image)\n    # plot the points on the face\n    ax.plot([le_x,re_x,n_x,lm_x,rm_x], [le_y,re_y,n_y,lm_y,rm_y], pointsColor)","99f30605":"index = 95000\ntest_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='mo-')","2c7c192d":"index = 50000\ntest_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='mo-')","a6099142":"index = 51024\ntest_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='mo-')","4ba51e58":"Plotting a Sample Image ","bef550ae":"**Converting Images into an array**","aed013c0":"**Building the CNN based Deep Learning Model**","8fca5b8f":"**Loading the key Points**","54b2e335":"Preparing the data for our Deep Learning","b32b2adb":"**Further splitting the test data into validation and test data**","35ed3648":"Reading Images"}}