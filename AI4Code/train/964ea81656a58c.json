{"cell_type":{"6fce80bb":"code","b1cc76db":"code","9ac588bc":"code","2934822a":"code","b93ea2ab":"code","4e0303c3":"code","f97e0e93":"code","7bfd6c8b":"code","6d9568f4":"code","a47a80c0":"code","439998a6":"code","f00a4a04":"code","013ee56e":"code","24fdeee4":"code","d1eeae4c":"code","751c541f":"code","af008fb1":"code","87f0f79b":"code","41b771d0":"code","437024ae":"code","c148964c":"code","5d59c3e4":"code","37a29742":"code","1d1995c7":"markdown","d59bf89a":"markdown","a2e630a7":"markdown","727932ee":"markdown","acf7307d":"markdown","6ef2a127":"markdown","3f79358e":"markdown","5847388f":"markdown","e8c45b9c":"markdown","1747bdc0":"markdown","7dbf05bd":"markdown","7bf6273b":"markdown","07766b00":"markdown","d2215a9d":"markdown","84e8f2a4":"markdown"},"source":{"6fce80bb":"!rm -rf \/kaggle\/working\/*","b1cc76db":"import os\n\npath = '\/kaggle\/input\/face-mask-detection\/'\nannotations_path = path + 'annotations\/'\nimages_path = path + 'images\/'\n\nannotations_files = [something for something in os.listdir(annotations_path) if not os.path.isdir(annotations_path + something)]\nimages_files = [something for something in os.listdir(images_path) if not os.path.isdir(images_path + something)]\nannotations_files[:5], images_files[:5]","9ac588bc":"import re\n\nannotations_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\nimages_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\nannotations_files[:5], images_files[:5]","2934822a":"pwd = !pwd # ['\/kaggle\/working']\npwd = pwd[0] + '\/'\n\ndataset_path = pwd + 'datasets\/facemask\/'\nif not os.path.isdir(dataset_path):\n    !mkdir -p {dataset_path}\n\nnew_images_path = dataset_path + 'images\/'\nnew_labels_path = dataset_path + 'labels\/'\n\nif not os.path.isdir(new_images_path):\n    !cp -rf {images_path} {dataset_path}\nif not os.path.isdir(new_labels_path):\n    !mkdir -p {new_labels_path}\n!ls {dataset_path}","b93ea2ab":"def get_yolo_format(pic_width, pic_height, x_min, y_min, x_max, y_max):\n    x_center = (x_max + x_min) \/ (2 * pic_width)\n    y_center = (y_max + y_min) \/ (2 * pic_height)\n    width = (x_max - x_min) \/ pic_width\n    height = (y_max - y_min) \/ pic_height\n    return x_center, y_center, width, height","4e0303c3":"import xml.etree.ElementTree as ET\n\nlabels = ['with_mask', 'mask_weared_incorrect', 'without_mask']\ninfos = [] # used <5. Compare images>\n\nfor annotations_file in annotations_files:\n    label_file_name = annotations_file.split('.')[0] + '.txt'\n    with open(new_labels_path + label_file_name, 'w') as label_file:\n        root = ET.parse(annotations_path + annotations_file)\n        pic_width = int(root.find('size').findtext('width'))\n        pic_height = int(root.find('size').findtext('height'))\n        info = [pic_width, pic_height]\n        for obj in root.findall('object'):\n            box_info = []\n            class_name = obj.findtext('name')\n            x_min = int(obj.find('bndbox').findtext('xmin'))\n            y_min = int(obj.find('bndbox').findtext('ymin'))\n            x_max = int(obj.find('bndbox').findtext('xmax'))\n            y_max = int(obj.find('bndbox').findtext('ymax'))\n            info.append([labels.index(class_name), x_min, y_min, x_max, y_max])\n            yolo_format = get_yolo_format(pic_width, pic_height, x_min, y_min, x_max, y_max)\n            label_file.write(str(labels.index(class_name)) + ' ' + ' '.join(map(str, yolo_format)) + '\\n')\n        infos.append(info)\n        label_file.flush()","f97e0e93":"labels_files = [something for something in os.listdir(new_labels_path) if not os.path.isdir(new_labels_path + something)]\nlabels_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))","7bfd6c8b":"!cat {new_labels_path}{labels_files[0]}","6d9568f4":"from sklearn.model_selection import train_test_split\n\nshow_count = 5 # used <5. Compare images>\nimages_train, images_else, labels_train, labels_else = train_test_split(images_files, labels_files, test_size = 0.2)\nimages_val, images_test, labels_val, labels_test = train_test_split(images_else, labels_else, test_size = show_count \/ len(images_else))\n\nlen(images_train), len(images_val), len(images_test)","a47a80c0":"sub_directories = ['train\/', 'val\/', 'test\/']\nfor sub_directory in sub_directories:\n    if not os.path.isdir(new_images_path + sub_directory):\n        !mkdir {new_images_path}{sub_directory}\n    if not os.path.isdir(new_labels_path + sub_directory):\n        !mkdir {new_labels_path}{sub_directory}\n        \n# move from all data to train\n!mv {new_images_path}{images_files[0].split('.')[0][:-1]}* {new_images_path}train\n!mv {new_labels_path}{labels_files[0].split('.')[0][:-1]}* {new_labels_path}train","439998a6":"def move_data(source_directory, source_files, target_directory):\n    for source_file in source_files:\n        !mv {source_directory}{source_file} {target_directory}{source_file}","f00a4a04":"# Move from train to validation and test\n\nimages_files_list = [images_val, images_test]\nlabels_files_list = [labels_val, labels_test]\n\nfor images_files, labels_files, sub_directory in zip(images_files_list, labels_files_list, sub_directories[1:]):\n    move_data(new_images_path + sub_directories[0], images_files, new_images_path + sub_directory)\n    move_data(new_labels_path + sub_directories[0], labels_files, new_labels_path + sub_directory)","013ee56e":"import yaml\n\nyaml_file = pwd + 'config.yaml'\n\nyaml_data = dict(\n    path = new_images_path,\n    train = (new_images_path + sub_directories[0])[:-1],\n    val = (new_images_path + sub_directories[1])[:-1],\n    nc = len(labels),\n    names = labels\n)\n\nwith open(yaml_file, 'w') as f:\n    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)","24fdeee4":"%%writefile {yaml_file}\n\npath: \/kaggle\/working\/datasets\/facemask\/images\/\ntrain: \/kaggle\/working\/datasets\/facemask\/images\/train\nval: \/kaggle\/working\/datasets\/facemask\/images\/val\nnc: 3\nnames: ['with_mask', 'mask_weared_incorrect', 'without_mask']","d1eeae4c":"!cat \/kaggle\/working\/config.yaml","751c541f":"yolo_path = pwd + 'yolov5\/'\nif not os.path.isdir(yolo_path):\n    !git clone https:\/\/github.com\/ultralytics\/yolov5.git\n!pip3 install -qr {yolo_path}requirements.txt","af008fb1":"import torch\n\nmodel_name = 'yolov5l'\nimage_size = 640\nbatch_size = 16\nepochs = 10\ndevice = '0' if torch.cuda.is_available() else 'cpu'\nsaved_model_name = 'best.pt'\n\n# for test\nconfidence_threshold = 0.25 # Threshold of object inference\niou_threshold = 0.45 # Threshold of remove overlapping boxes\n\ndevice","87f0f79b":"!python3 {yolo_path}train.py --weights {model_name}.pt \\\n        --cfg {yolo_path}models\/{model_name}.yaml --data {yaml_file} \\\n        --hyp {yolo_path}data\/hyps\/hyp.scratch.yaml --epochs {epochs} --batch-size {batch_size} \\\n        --img-size {image_size} --device {device}","41b771d0":"saved_model = pwd + 'runs\/train\/exp\/weights\/' + saved_model_name\nsubmission_path = pwd + 'submission\/'\nif not os.path.isdir(submission_path):\n    !mkdir {submission_path}\n!mv {saved_model} {submission_path}{saved_model_name}\n!rm -rf {pwd}runs\/train\/*\n!ls {submission_path}","437024ae":"!python3 {yolo_path}detect.py --weights {submission_path}{saved_model_name} \\\n        --source {new_images_path + sub_directories[2]} --img-size {image_size} \\\n        --conf-thres {confidence_threshold} --iou-thres {iou_threshold} --device {device} \\\n        --hide-labels --hide-conf","c148964c":"!mv {pwd}runs\/detect\/exp\/* {submission_path}\n!rm -rf {pwd}runs\/detect\/*\npredict_images = [something for something in os.listdir(submission_path) if not os.path.isdir(submission_path + something) and something.endswith('.png')]\npredict_images.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\npredict_images","5d59c3e4":"import matplotlib.pyplot as plt\n\n# Colors in the same order as yolov5 (yolov5\/utils\/plots.py -> colors)\ncolors = ['#FF3838', '#FF9D97', '#FF701F']\n\nfor c, l in zip(colors, labels):\n    plt.plot(0, 0, c, label = l)\nplt.legend(fontsize = 20, loc = 'center', frameon = False)\nplt.axis('off')\nplt.show()","37a29742":"import random\nimport matplotlib\nimport matplotlib.image as mpimg\n\npredict_show_list = random.sample(predict_images, show_count)\n\nrow = show_count\ncol = 2\nfigure = plt.figure(figsize = (5 * row, 13 * col))\n\nfor r, image_name in zip(range(row), predict_images):\n    for c in range(col):\n        if c == 0:   # Predict image\n            image_path = submission_path\n            title = 'Predict'\n        elif c == 1: # Answer image\n            image_path = images_path\n            title = 'Answer'\n        ax = figure.add_subplot(row, col, r * col + c + 1)\n        ax.imshow(mpimg.imread(image_path + image_name))\n        if c == 1:   # Draw rectangle for answer image.\n            for box in infos[int(re.sub('[^0-9]', '', image_name))][2:]:\n                l, x1, y1, x2, y2 = box\n                ax.add_patch(matplotlib.patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth = 5, color = colors[l], fill = False))\n        ax.set_title(title, fontsize = 15)\n        ax.axis(\"off\")\nplt.show()","1d1995c7":"#### Split data","d59bf89a":"# Using YOLOv5\n\nReference https:\/\/github.com\/ultralytics\/yolov5","a2e630a7":"# 5. Compare images","727932ee":"# 2. Model","acf7307d":"#### Save model weight","6ef2a127":"#### Sort by number","3f79358e":"#### Initialize variables for train and test","5847388f":"#### Make Directories\n\n- datasets\n  - (My dataset directory)\n    - annotations <-- **not essential**\n    - images\n    - labels <-- **will make it.**\n\nreference: https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data#3-organize-directories","e8c45b9c":"#### Make label files","1747bdc0":"#### (Another method) or write yaml file","7dbf05bd":"# 3. Train","7bf6273b":"#### Move data","07766b00":"# 1. Data Preprocessing","d2215a9d":"#### Create yaml file","84e8f2a4":"# 4. Test"}}