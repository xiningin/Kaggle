{"cell_type":{"75628f88":"code","cd2a8b4b":"code","6a3b3787":"code","01304946":"code","391a8763":"code","21b249e9":"markdown","0211426d":"markdown","c1041d91":"markdown","53cb6391":"markdown","183d353d":"markdown","7e855d18":"markdown"},"source":{"75628f88":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier","cd2a8b4b":"data = pd.read_csv('\/kaggle\/input\/breastcancerdataset\/BRCA.csv')\ndata = data.dropna()\ndata = data.drop([data.columns[i] for i in range(8,15)], axis=1)\ndata = data.drop('Patient_ID', axis=1)","6a3b3787":"le = LabelEncoder()\n# Transform categorical data\ndata['Patient_Status'] = le.fit_transform(data['Patient_Status']) \ndata['Gender'] = le.fit_transform(data['Gender'].astype(str))\nX,Y = data.iloc[:,:-1], data.iloc[:,-1] # Extract features and labels\nX_dummies = X.copy() # Copy of the features with \"dummied\" categorical data for one kind of feature\nX_dummies = pd.get_dummies(X_dummies, prefix=['Tumour_Stage']) # Get dummies for a categorical data\nX['Tumour_Stage'] = le.fit_transform(X['Tumour_Stage'].astype(str)) # Transform categorical data\n# Split into training and testing sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.151, random_state=42)\nX_dummies_train, X_dummies_test, Y_dummies_train, Y_dummies_test = train_test_split(X_dummies, Y, test_size=0.151, random_state=42)","01304946":"## Train models\nlog_reg = LogisticRegression(max_iter = 7777)\nlog_reg.fit(X_train, Y_train)\ntree = DecisionTreeClassifier()\ntree.fit(X_train, Y_train)\n\n## Train models with dummies\nlog_reg_dummies = LogisticRegression(max_iter = 7777)\nlog_reg_dummies.fit(X_dummies_train, Y_dummies_train)\ntree_dummies = DecisionTreeClassifier()\ntree_dummies.fit(X_dummies_train, Y_dummies_train)","391a8763":"## Evalueate models\nlog_reg_acc = 100*log_reg.score(X_test, Y_test)\ntree_acc = 100*tree.score(X_test, Y_test)\nlog_reg_acc_dummies = 100*log_reg_dummies.score(X_dummies_test, Y_dummies_test)\ntree_acc_dummies = 100*tree_dummies.score(X_dummies_test, Y_dummies_test)\n\nprint(\"Logistic Regression: {:.4f}%\".format(log_reg_acc))\nprint(\"Decision Tree Classifier: {:.4f}%\".format(tree_acc))\nprint(\"Logistic Regression with dummies: {:.4f}%\".format(log_reg_acc_dummies))\nprint(\"Decision Tree Classifier with dummies: {:.4f}%\".format(tree_acc_dummies))","21b249e9":"# **Training the model**","0211426d":"# **Conclusion**\nAs far as my knowledge and experience in ML is spreading - this dataset is a candidate for regression classifications as I can see. I used only 2 kind of model algorithms to predict the desired label from the data and as much as my experience, as I said earlier, in ML, data science and statistics is spreading - I achieved 83% for the Logistic Regression model I used, among the others. Concerns, corrections, criticism, tips and tricks, leave them all in the comments.","c1041d91":"# **Data preprocessing**","53cb6391":"# **Evaluate the models**","183d353d":"# **Importing libraries**","7e855d18":"# **Loading data**"}}