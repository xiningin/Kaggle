{"cell_type":{"78daf9fb":"code","c06b62ec":"code","da26ed5e":"code","81729913":"code","78531d45":"code","0862eea4":"code","c001333b":"code","45b96ebe":"code","e899b5ab":"code","b62c07be":"code","5b2ecddb":"code","f9e1dfda":"code","83cc22d4":"code","c4c31742":"code","a0620524":"code","d3f8faaa":"code","123bebfc":"code","1edf5848":"code","ea34349a":"code","15cbecf8":"code","a9522005":"code","36c0e00e":"code","8e150abc":"code","df3d8fc7":"code","a22a76d5":"code","a9e8dd0f":"markdown","6bad3fe3":"markdown","16f8b003":"markdown"},"source":{"78daf9fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c06b62ec":"import pandas as pd\nimport re \nimport en_core_web_lg\nnlp = en_core_web_lg.load()\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix","da26ed5e":"train = pd.read_csv('\/kaggle\/input\/spooky-author-identification\/train.zip')\ntest = pd.read_csv('\/kaggle\/input\/spooky-author-identification\/test.zip')","81729913":"def string_cleanup(string):\n    string = str(string)\n    string = re.sub('[^A-Za-z0-9\\s]+', ' ', string)\n    string = re.sub('[^A-Za-z\\s]+', ' ', string)\n    string = re.sub('[\\s\\s]+', ' ', string)\n    string = string.strip()\n    return string.lower()\n\n\ndef remove_stop_spacy(x, spacy_nlp):\n    customize_stop_words = []\n\n    for w in customize_stop_words:\n        w = w.lower()\n        spacy_nlp.vocab[w].is_stop = True\n    x = x.lower()\n    doc = spacy_nlp(x)\n    tokens = []\n    for token in doc:\n        if not token.is_stop and len(str(token.text)) >1:\n            tokens.append(token.text)\n    return (' '.join(tokens))","78531d45":"train['clean_text'] = train['text'].apply(string_cleanup)\n\ntrain['no_stop'] = train['clean_text'].apply(lambda x:remove_stop_spacy(x, nlp))","0862eea4":"def get_count_of_pos(x, nlp):\n    try:\n        len_val = len((x).split())\n        noun_count = 0\n        propn_count = 0\n        verb_count = 0\n        adv_count = 0\n        adj_count = 0\n        doc = nlp(x)\n        for tok in doc:\n    #         print(tok, tok.pos_)\n            if tok.pos_ == 'NOUN':\n                noun_count = noun_count + 1\n            if tok.pos_ == 'PROPN':\n                propn_count = propn_count + 1\n            if tok.pos_ == 'VERB':\n                verb_count = verb_count + 1\n            if tok.pos_ == 'ADV':\n                adv_count = adv_count + 1\n            if tok.pos_ == 'ADJ':\n                adj_count = adj_count + 1 \n        return pd.Series([len_val, noun_count, propn_count, verb_count, adv_count, adj_count])\n    except(e):\n        print(x)","c001333b":"train[['word_count', 'noun_count', 'propn_count', 'verb_count', 'adv_count', 'adj_count']] = train['text'].apply(lambda x:get_count_of_pos(x, nlp))","45b96ebe":"train.groupby(['author'])['word_count'].agg('mean')","e899b5ab":"train.groupby(['author'])['noun_count'].agg('mean')","b62c07be":"train.groupby(['author'])['propn_count'].agg('mean')","5b2ecddb":"train.groupby(['author'])['verb_count'].agg('mean')\n","f9e1dfda":"train.groupby(['author'])['adv_count'].agg('mean')","83cc22d4":"train.groupby(['author'])['adj_count'].agg('mean')","c4c31742":"skf = StratifiedKFold(n_splits=5)","a0620524":"X = train[['propn_count', 'verb_count', 'no_stop', 'text']]\ny = train['author']","d3f8faaa":"for train_index, test_index in skf.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]","123bebfc":"# text and numeric classes that use sklearn base libaries\nclass TextTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transform text features\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None, *parg, **kwarg):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n    \nclass NumberTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transform numeric features\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]","1edf5848":"propn_count = Pipeline([\n                ('transformer', NumberTransformer(key='propn_count')),\n                ('standard_scalar', StandardScaler())\n                ])","ea34349a":"text = Pipeline([\n                ('transformer', TextTransformer(key='no_stop')),\n                ('vectorizer', TfidfVectorizer(ngram_range=(1,3)))\n                ])","15cbecf8":"features = FeatureUnion([('Text_Feature', text),\n                         ('propn_count', propn_count)\n                      ])","a9522005":"clf = LogisticRegression(random_state=0, multi_class = 'ovr', max_iter = 2000)\n","36c0e00e":"pipe = Pipeline([('features', features),\n                 ('clf',clf)                 \n                 ])","8e150abc":"pipe.fit(X_train, y_train)","df3d8fc7":"preds = pipe.predict(X_test)","a22a76d5":"accuracy_score(preds, y_test)","a9e8dd0f":"Alright, so we need to understand the basic fact that one easy way to identify the style of a particluar author is to first understand what kinf of Parts of Speech they are using on an average. If we can get these numbers, this will definitely add a lot of value to our model.\n\nExample - Few authors tend to have more characters in their novels which means their Proper noun count on an average will be high compared to others. Let's see if we can get some patterns.","6bad3fe3":"Although we tried everything we could to get the meta data details of the text, only proper noun is giving us some extra information as it indicates a definite pattern. Rest all can be ignored.","16f8b003":"This is great! As rightly predicted, The author 'MWS' does not have many characters in his books compared to the other author 'HPL'. This is a very valuable insight!"}}