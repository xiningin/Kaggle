{"cell_type":{"ad3d3941":"code","b450d006":"code","65354ed4":"code","af98acf5":"code","1d93c7db":"code","200954a6":"code","aa10273d":"code","ef58c583":"code","2994ee08":"code","aed3292b":"markdown","2596fc7e":"markdown","54bbc639":"markdown","ee2ae6a9":"markdown"},"source":{"ad3d3941":"import sys\n!cp ..\/input\/rapids\/rapids.0.13.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/\n","b450d006":"import cudf, cuml\nimport cupy as cp\nimport numpy as np\nimport pandas as pd\nimport os\nimport random, re, math, time\n\nrandom.seed(a=42)\nfrom os.path import join \n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom PIL import Image\n\nfrom cuml.manifold import TSNE, UMAP\n\nfrom tqdm import tqdm\nimport plotly.express as px","65354ed4":"BASEPATH = '..\/input'\nCOMPPATH = os.path.join(BASEPATH, 'siim-isic-melanoma-classification')\ndf_train = pd.read_csv(os.path.join(COMPPATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(COMPPATH, 'test.csv'))\ndf_sub = pd.read_csv(os.path.join(COMPPATH, 'sample_submission.csv'))\n\nTHUMBSPATH = os.path.join(BASEPATH, 'melanoma-extract-thumbs-32x32')\nthumbs_train = np.load(os.path.join(THUMBSPATH, 'thumbs_32x32_train.npy'))\nthumbs_test = np.load(os.path.join(THUMBSPATH, 'thumbs_32x32_test.npy'))\n\nSIZE = thumbs_train.shape[1]\n","af98acf5":"thumbs_all = np.concatenate([thumbs_train, thumbs_test])\n(n,y,x,b) = thumbs_all.shape\nflat_all = thumbs_all.reshape((n, y*x*b))\n\numapObj = UMAP(n_components=2, n_neighbors=100, min_dist=0.7)\nemb_all = umapObj.fit_transform(flat_all)\n\nemb_train = emb_all[:thumbs_train.shape[0]]\nemb_test = emb_all[thumbs_train.shape[0]:]","1d93c7db":"def draw_embedding(embedding, thumbs):\n    (n, w) = embedding.shape\n    if w > 32:\n        embedding = PCA(n_components=32).fit_transform(embedding)\n\n    if w > 2:\n        #embedding = TSNE(n_components=2, verbose=2,metric=\"cosine\").fit_transform(embedding)    \n        embedding = TSNE(n_components=2, verbose=2).fit_transform(embedding)    \n\n    x1, x2 = min(embedding[:,0]), max(embedding[:,0])\n    y1, y2 = min(embedding[:,1]), max(embedding[:,1])\n    \n    #s = np.std(embedding, axis=0)\n    #m = np.mean(embedding, axis=0)       \n    #embedding = (embedding-m) \/ s \/ 3\n    \n    embedding[:,0] = (embedding[:,0] - x1) \/ (x2-x1)\n    embedding[:,1] = (embedding[:,1] - y1) \/ (y2-y1)\n\n    (n, w) = embedding.shape\n    img = Image.new(mode='RGB', size=(3000, 3000))\n    for i in range(n):\n        img2 = Image.fromarray(thumbs[i])\n        x = math.floor(embedding[i,0]*(3000-SIZE))\n        y = 3000 - math.floor(embedding[i,1]*(3000-SIZE)) - SIZE\n        img.paste(img2, (x, y))\n\n    display(img)","200954a6":"draw_embedding(emb_all, thumbs_all)","aa10273d":"y_train = df_train[\"target\"].values\ny_train_str = np.array([str(i) for i in y_train])\nfig = px.scatter(x=emb_train[:,0], y=emb_train[:,1], color=y_train_str, size=y_train, render_mode=\"webgl\")\nfig.update_traces(marker=dict(size=2))\n\nfig.show()","ef58c583":"fig = px.scatter(x=emb_test[:,0], y=emb_test[:,1], render_mode=\"webgl\")\nfig.update_traces(marker=dict(size=2))\n\nfig.show()\n","2994ee08":"np.save('umap_emb_train.npy', emb_train)\nnp.save('umap_emb_test.npy', emb_test)","aed3292b":"## Test:","2596fc7e":"## Train:","54bbc639":"## All train and test images\n\nRight-click image and open it in new browser tab. Its a 3000x3000 pixel image ;-)","ee2ae6a9":"After embedding of low resolution 32x32 images into a 2D space using umap, a difference in the distributions of train and test appears.\nThere is a cluster of many similar images in the test set, that are not so frequent in the train data.\n\n![image.png](attachment:image.png)\n"}}