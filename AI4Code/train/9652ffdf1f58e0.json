{"cell_type":{"0c07d688":"code","3a64f6cb":"code","bd9f449d":"code","2d008d94":"code","226a4a99":"code","6374b6c2":"code","8b86fdf5":"code","b6eeabe1":"code","7faba189":"code","a74148f0":"code","6fec8c57":"code","09667bd6":"code","d7a50e83":"code","bda7d1e5":"code","e8678395":"code","da1d4e2d":"code","fe7b09dd":"code","73f2f48f":"code","3d4d1f6c":"code","5a55bc78":"markdown","2e4a2f77":"markdown","5c510d82":"markdown","4a708f44":"markdown","921bf84c":"markdown","2c9fde76":"markdown","ed06088e":"markdown","5ad0beb9":"markdown","7006e084":"markdown","2263f20a":"markdown","c5f83913":"markdown"},"source":{"0c07d688":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.utils import class_weight, shuffle\n\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint","3a64f6cb":"#foldernames = os.listdir('..\/input\/100-bird-species\/train')\nfoldernames = ['MOURNING DOVE', 'BROWN NOODY', 'DOWNY WOODPECKER', 'EMPEROR PENGUIN', 'WHITE TAILED TROPIC', 'OSPREY', 'HOUSE FINCH', 'AMERICAN COOT', 'GOLDEN PIPIT', 'PUFFIN']\ncategories = []\nfiles = []\ni = 0\nflag=0","bd9f449d":"for k, folder in enumerate(foldernames):\n    filenames = os.listdir(\"..\/input\/100-bird-species\/train\/\" + folder);\n    for file in filenames:\n        #files.append(\"..\/input\/100-bird-species\/test\/\" + folder + \"\/\" + file)\n        files.append(\"..\/input\/100-bird-species\/train\/\" + folder + \"\/\" + file)\n        #categories.append(k)\n        categories.append(k)\n     \n\ndf = pd.DataFrame({\n    'filename': files,\n    'category': categories\n})","2d008d94":"train_df = pd.DataFrame(columns=['filename', 'category'])\nfor i in range(70):\n    train_df = train_df.append(df[df.category == i].iloc[:500,:])\n\ntrain_df.head()\ntrain_df = train_df.reset_index(drop=True)\ntrain_df","226a4a99":"y = train_df['category']\nx = train_df['filename']\nx, y = shuffle(x, y, random_state=8)","6374b6c2":"def centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    row = (size[1] - img_size[0]) \/\/ 2\n    col = (size[0] - img_size[1]) \/\/ 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\nimages = []\nwith tqdm(total=len(train_df)) as pbar:\n    for i, file_path in enumerate(train_df.filename.values):\n        \n        img = cv2.imread(file_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if(img.shape[0] > img.shape[1]):\n            tile_size = (int(img.shape[1]*256\/img.shape[0]),256)\n        else:\n            tile_size = (256, int(img.shape[0]*256\/img.shape[1]))\n\n        img = centering_image(cv2.resize(img, dsize=tile_size))\n\n        img = img[16:240, 16:240]\n        images.append(img)\n        pbar.update(1)\n\nimages = np.array(images)","8b86fdf5":"img_rows, img_cols, img_channel = 224, 224, 3\nname_bird = []\nfor i in range(10):\n    path = train_df[train_df.category == i].values[2]\n    name_bird.append(path[0].split('\/')[-2]) ","b6eeabe1":"for a in range(10):\n    print(a,name_bird[a])","7faba189":"#can comment this and not run because of memory issue \nrows,cols = 2,5\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,20))\nfor i in range(10):\n    path = train_df[train_df.category == i].values[2]\n    axes[i\/\/cols, i%cols].set_title(name_bird[i])\n    axes[i\/\/cols, i%cols].imshow(images[train_df[train_df.filename == path[0]].index[0]])\n","a74148f0":"#dont run\n\ndata_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(images[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)\nval_split_num = int(round(0.2*len(y)))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255","6fec8c57":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(10, activation='softmax'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","09667bd6":"batch_size = 32\nepochs = 50\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc')]\n)","d7a50e83":"print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,history.history['accuracy'][epochs-1],history.history['val_accuracy'][epochs-1]))\ndef show_plots(history):\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss']\n    epochs = range(1, len(history['accuracy'])+1)\n    \n    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n    \n    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n    ax[0].set_title('Training & Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend(loc='best')\n    ax[0].grid(True)\n    \n    acc_vals = history['accuracy']\n    val_acc_vals = history['val_accuracy']\n\n    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n    ax[1].set_title('Training & Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend(loc='best')\n    ax[1].grid(True)\n    \n    plt.show()\n    plt.close()\n    \n    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals\nshow_plots(history.history)","bda7d1e5":"test_images =[]\nj = 40 \nfor i in range(10):\n    path = train_df[train_df.category == i].values[j]\n    a = images[train_df[train_df.filename == path[0]].index[0]]\n    img = np.array(a)\n    img = img[:, :, ::-1].copy() \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256\/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256\/img.shape[1]))\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    img = img[16:240, 16:240]\n    test_images.append(img)\n\ntest_images = np.array(test_images).reshape(-1,224,224,3)\nprediction = model.predict(test_images)\nanimals = name_bird\ni = 0\nfor pred in prediction:\n    path = train_df[train_df.category == i].values[2]\n    plt.imshow(test_images[i])\n    plt.show()\n    print('Actual  :', animals[i])\n    print('Predict :', animals[np.where(pred.max() == pred)[0][0]])\n    i += 1\n","e8678395":"import sklearn.metrics as metrics\nfrom sklearn.metrics import classification_report, confusion_matrix","da1d4e2d":"y_pred = np.argmax(prediction, axis=1)\n","fe7b09dd":"y_test = [0,1,2,3,4, 5 ,6, 7, 8 ,9]","73f2f48f":"confusion_matrix(y_test, y_pred)","3d4d1f6c":"model.save(\"Bird_Classification_VGG16.h5\")","5a55bc78":"Separating image and target name.","2e4a2f77":"Displaying the different categories of animals.","5c510d82":"Creating the classification model.","4a708f44":"Splitting the dataset into train and test.","921bf84c":"Training the model.","2c9fde76":"Importing the dataset.","ed06088e":"Testing the model.","5ad0beb9":"Renaming Images.","7006e084":"Resizing and Centering Images.","2263f20a":"Observing Loss and Accuracy of the Model","c5f83913":"Importing the required Libraries. "}}