{"cell_type":{"e13526ba":"code","3135d53d":"code","e5913225":"code","2fb7e9e2":"code","15bc6066":"code","7115febe":"code","5180797e":"code","d32bcdde":"code","a31b7e53":"code","b6eddb7f":"code","53f77484":"code","978e791a":"code","d73c3d5f":"code","851fbe69":"code","57a32777":"code","3049162b":"code","ba0075f3":"code","35362a44":"code","e86799ea":"code","65e9e8d5":"code","087f7cf7":"code","0462bbd0":"code","fde03804":"code","d03b94bb":"markdown","bea03597":"markdown","bcf3bd55":"markdown","f55c0732":"markdown","75da6922":"markdown","359df62a":"markdown","0145d9e6":"markdown","6244f8fa":"markdown","4b42b8b0":"markdown"},"source":{"e13526ba":"import tensorflow as tf\nimport numpy as np\nimport imageio\nimport glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow.keras as keras\nimport os \nimport PIL\nimport time\nimport pandas as pd\n\nfrom keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, Conv2D, Dropout, Flatten\nfrom keras import Sequential\nfrom IPython import display\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3135d53d":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","e5913225":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5)\/ 127.5\n\nBUFFER_SIZE = 60000\nBATCH_SIZE = 256\n\nX_train = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","2fb7e9e2":"def build_generator():\n  model = Sequential()\n  model.add(Dense(7*7*256, use_bias = False, input_shape=(100,)))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Reshape((7, 7, 256)))\n  assert model.output_shape == (None, 7, 7, 256)\n\n  model.add(Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n  assert model.output_shape == (None, 7, 7, 128)\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n  assert model.output_shape == (None, 14, 14, 64)\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh' ))\n  assert model.output_shape ==(None, 28, 28, 1)\n\n  return model","15bc6066":"gen = build_generator()\n\nnoise = tf.random.normal([1,100])\ngenerated_image = gen(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","7115febe":"def build_discriminator():\n  model = Sequential()\n  model.add(Conv2D(64, (5, 5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Flatten())\n  model.add(Dense(1))\n\n  return model","5180797e":"disc = build_discriminator()\ndecision = disc(generated_image)\n\nprint(decision)","d32bcdde":"bce = keras.losses.BinaryCrossentropy(from_logits=True)","a31b7e53":"def discriminator_loss(real_output, fake_output):\n  real_loss = bce(tf.ones_like(real_output), real_output)\n  fake_loss = bce(tf.zeros_like(fake_output), fake_output)\n  total_loss = real_loss + fake_loss\n\n  return total_loss","b6eddb7f":"def generator_loss(fake_output):\n  return bce(tf.ones_like(fake_output), fake_output)","53f77484":"gen_optimizer = keras.optimizers.Adam(1e-4)\ndis_optimizer = keras.optimizers.Adam(1e-4)","978e791a":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer = gen_optimizer,\n                                 discriminator_optimizer=dis_optimizer,\n                                 generator=gen,\n                                 discriminator=disc)","d73c3d5f":"epochs = 250\n\nnoise_dim = 100\n\nto_gen = 16\n\nseed = tf.random.normal([to_gen, noise_dim])","851fbe69":"@tf.function\ndef train_step(images):\n  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n    generated_images = gen(noise, training=True)\n\n    real_output = disc(images, training=True)\n    fake_output = disc(generated_images, training=True)\n\n    gen_loss = generator_loss(fake_output)\n    dis_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(dis_loss, disc.trainable_variables)\n\n    gen_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, disc.trainable_variables))\n\n","57a32777":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    display.clear_output(wait=True)\n    generate_and_save_images(gen, epoch +1, seed)\n\n    if(epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  display.clear_output(wait=True)\n  generate_and_save_images(gen, epochs, seed)","3049162b":"def generate_and_save_images(model, epoch, test_input):\n  \n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","ba0075f3":"train(X_train, epochs)","35362a44":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","e86799ea":"def display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","65e9e8d5":"display_image(epochs)","087f7cf7":"from PIL import Image\n\nframes = []\nimgs = glob.glob(\"*.png\")\nimgs.sort()\nfor i in imgs:\n    new_frame = Image.open(i)\n    frames.append(new_frame)\n\n \n\nframes[0].save('training.gif', format='GIF',\n               append_images=frames[1:],\n               save_all=True,\n               duration=100, loop=0)","0462bbd0":"from IPython.display import Image \nImage(open('training.gif','rb').read())","fde03804":"gen_image = gen(noise, training=False)\n\nplt.imshow(gen_image[0, :, :, 0], cmap='gray')","d03b94bb":"**Importing the required libraries and packages**","bea03597":"# Training the Model","bcf3bd55":"# Creating Train Function","f55c0732":"**Loading the Dataset and Processing it**","75da6922":"# Introduction","359df62a":"DC-GAN or Deep Convolution GANS, uses deep neural networks for Image generations.\n\nmore can be found [here](https:\/\/medium.com\/@jonathan_hui\/gan-dcgan-deep-convolutional-generative-adversarial-networks-df855c438f)","0145d9e6":"**Defining hyper-parameters**","6244f8fa":"# Building the Model","4b42b8b0":"# Creating Loss function, optimizer and checkpoints"}}