{"cell_type":{"311b98ad":"code","46b380af":"code","f916202a":"code","10253436":"code","abc59fc7":"code","c8116227":"code","cd65b294":"code","a8efacd1":"code","19cedaf1":"code","6b0758b0":"code","5d99cdd0":"code","3879863b":"code","d8b29287":"code","82aaa093":"code","5beaf0d7":"code","a99b971f":"code","f18ecf94":"code","e9812a6e":"code","01846d39":"code","7556bd3b":"code","8de2c5d0":"code","83b5b7bc":"markdown","4d0a73fe":"markdown","3a3671bb":"markdown","bc217b39":"markdown","09f2a89b":"markdown","1ca59d96":"markdown","42d3a702":"markdown","b6d12c03":"markdown","c7f5c4ef":"markdown"},"source":{"311b98ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46b380af":"dataset = pd.read_excel(\"\/kaggle\/input\/car-sales\/CarSales.xlsx\")\ndataset_backup = dataset.copy()","f916202a":"dataset.head()","10253436":"print(\"Shape of The Dataset\",\"\\nColumns : \" ,dataset.shape[1],\"\\nRows : \",dataset.shape[0])","abc59fc7":"dataset.isnull().sum()","c8116227":"dataset.drop(axis=0, index=dataset[dataset[\"Price\"].isnull()] \\\n             .index,inplace=True)","cd65b294":"dataset.info()","a8efacd1":"#Droping listing date\ndataset.drop(\"Listing Date\", axis = 1, inplace = True)","19cedaf1":"dataset.iloc[[1,3,5,9], :]","6b0758b0":"counter = 0\nabnormal = []\nfor value in dataset[\"Price\"].apply(lambda val : val[:-4].replace(\".\",\"\")):\n    counter +=1\n    if value.isdigit() == False:\n        abnormal.append(counter-1)\n\nprint(\"Number of Abnormal Price : \" ,len(abnormal))","5d99cdd0":"#Adjusting the number of max rows.\npd.options.display.max_rows = 1611#If you want to see all of the rows, you can activate this line.\ndataset_abnormal = dataset.iloc[abnormal,:]\ndataset_abnormal.head(10)","3879863b":"#Taking the last values\ndataset[\"Price\"] = dataset[\"Price\"].apply(lambda data : data[:-3].split(\" \")[0].replace(\".\",\"\") if \"\\r\\n\\r\\n\" in  data else data[:-3].replace(\".\",\"\") )\n\n#some values include usd or eur. I have to change these values to TL\ndef exchange(value):\n    if \"USD\" in value:\n        return str(int(value[:-3]) * 7.44)\n    elif \"EUR\" in value:\n        return str(int(value[:-3]) * 8.80) \n    else:\n        return value\ndataset[\"Price\"] = dataset[\"Price\"].apply(exchange)\ndataset.head(3) \n","d8b29287":"#Changing the data type of Price\ndataset[\"Price\"] = dataset[\"Price\"].astype(\"int\")","82aaa093":"# Checking how many abnormal values there are.\ncounter = 0\nindex_list = []\nfor i in dataset[\"Km\"]:\n    if type(i) != int and type(i) != float:\n        print(\"Index : \" + str(counter),len(str(i)))\n        index_list.append(counter)\n    counter += 1\nprint(\"Abnormal values : \",counter)","5beaf0d7":"dataset.iloc[index_list,:]","a99b971f":"abnormal_km = dataset.iloc[index_list,:]\ndataset = dataset.drop(axis = 0, index = abnormal_km.index)","f18ecf94":"#Changing the data type of Price\ndataset[\"Km\"] = dataset[\"Km\"].astype(\"int\")","e9812a6e":"# Features For Fiat Albea ( model : 2010 - 2013, Price : 35000 TL - 45000 TL)\nFiat_Albea = dataset.loc[(dataset[\"Model\"] >=2010) \\\n            & (dataset[\"Model\"]<=2013)\\\n            & (dataset[\"Car\"] == \"Fiat Albea Sole 1.3 Multijet Premio Plus\")\\\n            & (dataset[\"Price\"] >=35000) \\\n            & (dataset[\"Price\"] <=45000),:][\"Km\"].mean()\n# Features For Fiat Linea ( model : 2009 - 2011,  Price : 67000 TL - 71000 TL)\nFiat_Linea = dataset.loc[(dataset[\"Model\"] >=2009) \\\n            & (dataset[\"Model\"]<=2011)\\\n            & (dataset[\"Car\"] == \"Fiat Linea 1.3 Multijet Dynamic\")\\\n            & (dataset[\"Price\"] >= 67000) \\\n            & (dataset[\"Price\"] <= 71000),:][\"Km\"].mean()\n# Features For Hyundai Accent Era ( model : 2010 - 2013, Price : 60000 TL - 65000 TL)\nHyundai_Accent = dataset.loc[(dataset[\"Model\"] >=2010) \\\n            & (dataset[\"Model\"]<=2013)\\\n            & (dataset[\"Car\"] == \"Hyundai Accent Era 1.5 CRDi-VGT Team\")\\\n            & (dataset[\"Price\"] >= 60000) \\\n            & (dataset[\"Price\"] <= 65000),:][\"Km\"].mean()\n# Features For Opel Astra  ( model : 2010 - 2013,  Price : 98000 TL - 101000 TL)\nOpel_Astra = dataset.loc[(dataset[\"Model\"] >=2010) \\\n            & (dataset[\"Model\"]<=2013)\\\n            & (dataset[\"Car\"] == \"Opel Astra 1.6 Enjoy 111.Y\u0131l\")\\\n            & (dataset[\"Price\"] >= 98000) \\\n            & (dataset[\"Price\"] <= 101000),:][\"Km\"].mean()\n# Features For Peugeot 206 ( model : 2005 - 2007, Price : 57000 TL - 63000 TL)\nPeugeot_206 = dataset.loc[(dataset[\"Model\"] >=2004) \\\n            & (dataset[\"Model\"]<=2010)\\\n            & (dataset[\"Car\"] == \"Peugeot 206 1.4 HDi X-Design\")\\\n            & (dataset[\"Price\"] >= 30000) \\\n            & (dataset[\"Price\"] <= 50000),:][\"Km\"].mean()\n# Features For Renault Fluence ( model : 2013 - 2015, Price : 110000 TL - 115000 TL)\nRenault = dataset.loc[(dataset[\"Model\"] >=2013) \\\n            & (dataset[\"Model\"]<=2015)\\\n            & (dataset[\"Car\"] == \"Renault Fluence 1.5 dCi Touch Plus\")\\\n            & (dataset[\"Price\"] >= 110000) \\\n            & (dataset[\"Price\"] <= 115000),:][\"Km\"].mean()\n\n#Creating a series to add in the abnormal_km dataset\nkm = data=[str(round(Fiat_Albea)),str(round(Fiat_Linea)),str(round(Hyundai_Accent)),\n                     str(round(Opel_Astra)),str(round(Peugeot_206)),str(round(Renault))]\n\n#Adding in abnormal_km\nabnormal_km[\"Km\"] = km\n\n#Concatenating\ndataset = pd.concat([dataset, abnormal_km], ignore_index=True)","01846d39":"#Changing the data type of Price\ndataset[\"Km\"] = dataset[\"Km\"].astype(\"int\")","7556bd3b":"#Dividing dataset depends on car\nAlfa = [] ; Audi = [] ; BMW = [] ; Chevrolet = [] ; Citroen = [] ; Dacia = [] ; Fiat = [] ; Ford = [] ; Honda = []\nHyundai = [] ; Kia = [] ; Mazda = [] ; Mercedes = [] ; Opel = [] ; Peugeot = [] ; Renault = []\ncounter = 0\nfor value in dataset[\"Car\"]:\n    if \"Alfa Romeo\" in value:\n        Alfa.append(counter)\n    elif \"Audi\" in value:\n        Audi.append(counter)\n    elif \"BMW\" in value:\n        BMW.append(counter)\n    elif \"Chevrolet\" in value:\n        Chevrolet.append(counter)\n    elif \"Citroen\" in value:\n        Citroen.append(counter)\n    elif \"Dacia\" in value:\n        Dacia.append(counter)\n    elif \"Fiat\" in value:\n        Fiat.append(counter)\n    elif \"Ford\" in value:\n        Ford.append(counter) \n    elif \"Honda\" in value:\n        Honda.append(counter) \n    elif \"Hyundai\" in value:\n        Hyundai.append(counter)\n    elif \"Kia\" in value:\n        Kia.append(counter)\n    elif \"Mazda\" in value:\n        Mazda.append(counter)\n    elif \"Mercedes\" in value:\n        Mercedes.append(counter)\n    elif \"Opel\" in value:\n        Opel.append(counter)\n    elif \"Peugeot\" in value:\n        Peugeot.append(counter)\n    elif \"Renault\" in value:\n        Renault.append(counter)\n    \n    counter += 1","8de2c5d0":"Alfa_df = dataset.iloc[Alfa,:]\nAudi_df = dataset.iloc[Audi,:]\nBMW_df = dataset.iloc[BMW,:]\nChevrolet_df = dataset.iloc[Chevrolet,:]\nCitroen_df = dataset.iloc[Citroen,:]\nDacia_df = dataset.iloc[Dacia,:]\nFiat_df = dataset.iloc[Fiat,:]\nFord_df = dataset.iloc[Ford,:]\nHonda_df = dataset.iloc[Honda,:]\nBMW_df = dataset.iloc[BMW,:]\nHyundai_df = dataset.iloc[Hyundai,:]\nKia_df = dataset.iloc[Kia,:]\nMazda_df = dataset.iloc[Mazda,:]\nMercedes_df = dataset.iloc[Mercedes,:]\nOpel_df = dataset.iloc[Opel,:]\nPeugeot_df = dataset.iloc[Peugeot,:]\nRenault_df = dataset.iloc[Renault,:]","83b5b7bc":"**For the last step, I am going to prepare sub-datasets for each brand that the dataset includes**","4d0a73fe":"**I have noticed that I must change the type of Km, Price and there are the Listing Date as well as day, month, and year that represent the Listing Date so I can drop it.**","3a3671bb":"**The price column includes characters that represent the Turkish Lira. Before changing the string to an integer, I must get rid of this.**","bc217b39":"**Now I have a clean dataset except the color column and I was going to handle this column but I changed my mind. I am going to already divide the dataset depends on the Car on the next step. Therefore You can fill missing values after I will divide.**","09f2a89b":"**There are 1611 abnormal values that I have to adjust.**","1ca59d96":"# Data Cleansing\n\nI scraped it on website. The data includes some noisy values that was generated when I scraped. My goal is that get rid of these values and make easy people's data preparation steps.","42d3a702":"Let's drop the rows after assigning them to one variable. I will specify average of the rows can represent abnormal rows under the rules I will specify. Then I am going to assign these values instead of old ones.","b6d12c03":"Two columns have null values end the Price has one null value so I can drop this row.","c7f5c4ef":"Now I should check the Km column because it can include abnormal values that I need to handle."}}