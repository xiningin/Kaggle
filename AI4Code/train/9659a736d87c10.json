{"cell_type":{"a3442bd3":"code","ef0d9505":"code","3d024ac7":"code","805f4c74":"code","642c922e":"code","f576904f":"code","afe30731":"code","d6de211b":"code","d0515dab":"code","4d9ed798":"code","6dc2e082":"code","c09d5378":"code","b00e840b":"code","6c169f04":"code","527fb598":"code","147a9840":"code","8673bd6e":"code","0a46755a":"code","ebbae828":"code","feb58cda":"code","91d33157":"code","6dc86ef0":"code","04c92b9c":"code","b83c3021":"code","f004d355":"code","7d51cedd":"code","74b1cabe":"code","1db792b8":"code","86bedf5b":"code","9710d197":"code","21e021c6":"code","4097e455":"code","0c1cb0f3":"code","99c5b0fb":"code","5537bedd":"code","8cb1ee93":"code","a4ec4e3f":"code","ddd538d4":"code","5972bf17":"code","d8981b2d":"code","1925c9b6":"code","379764e6":"code","0856317c":"code","f548b663":"code","f1044e5b":"code","982c3327":"code","f8844ea8":"code","aa87775b":"code","4adfeb00":"code","9c9391f0":"code","b70fa721":"code","4a8bb1ca":"code","5ec71ad3":"code","bf7606f6":"code","28efed35":"code","ebf9a47a":"code","46e8820f":"markdown","55245d03":"markdown","08945490":"markdown","6d0f8868":"markdown","168e22d6":"markdown","0c7dad08":"markdown","f49584f8":"markdown","8a27571f":"markdown","74982b0b":"markdown","42f00341":"markdown","6d8a99be":"markdown","408212c1":"markdown","a84ce838":"markdown","e3bcc7b3":"markdown","68044941":"markdown","f699118b":"markdown","44ecada8":"markdown","1a0b3d21":"markdown","806213a1":"markdown","136e1bd1":"markdown","09128454":"markdown","5b877829":"markdown","0117cecb":"markdown","80e14756":"markdown","0b179dd2":"markdown","ca9f57aa":"markdown"},"source":{"a3442bd3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport statistics \nfrom datetime import datetime\nsns.set(style=\"darkgrid\")\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","ef0d9505":"df_org=pd.read_csv('\/kaggle\/input\/us-accidents\/US_Accidents_Dec19.csv')\ndf=df_org.sample(500000, random_state =21)","3d024ac7":"df.info()","805f4c74":"plt.figure(figsize=(20, 5))\nplt.title('Distribution of recordings per state')\nsns.countplot(x=df['State'], data=df)","642c922e":"plt.figure(figsize=(10, 4))\nplt.subplot(111)\nsns.distplot(df['Severity'])\nplt.title('Severity distribution as histogram')","f576904f":"plt.figure(figsize=(10, 4))\nplt.subplot(111)\nsns.distplot(df['Distance(mi)'])\nplt.title('Distance distribution as histogram')","afe30731":"bool_features=['Amenity',\n              'Bump',\n              'Crossing',\n              'Give_Way',\n              'Junction',\n              'No_Exit',\n              'Railway',\n              'Roundabout',\n              'Station',\n              'Stop',\n              'Traffic_Calming',\n              'Traffic_Signal',\n              'Turning_Loop']\n\nfor i in bool_features:\n    df_temp=df[i].copy()\n    df_temp[df_temp==False]=0\n    df_temp[df_temp==True]=1\n    df[i] = df_temp\n    ","d6de211b":"plt.figure(figsize=(20, 10))\nplt.subplot(431)\nsns.countplot(df['Amenity'])\nplt.title('Amenity')\nplt.xlabel('')\nplt.subplot(432)\nsns.countplot(df['Bump'])\nplt.title('Bump')\nplt.xlabel('')\nplt.subplot(433)\nsns.countplot(df['Crossing'])\nplt.title('Crossing')\nplt.xlabel('')\nplt.subplot(434)\nsns.countplot(df['Give_Way'])\nplt.title('Give_Way')\nplt.xlabel('')\nplt.subplot(435)\nsns.countplot(df['Junction'])\nplt.title('Junction')\nplt.xlabel('')\nplt.subplot(436)\nsns.countplot(df['No_Exit'])\nplt.title('No_Exit')\nplt.xlabel('')\nplt.subplot(437)\nsns.countplot(df['Railway'])\nplt.title('Railway')\nplt.xlabel('')\nplt.subplot(438)\nsns.countplot(df['Roundabout'])\nplt.title('Roundabout')\nplt.xlabel('')\nplt.subplot(439)\nsns.countplot(df['Station'])\nplt.title('Station')","d0515dab":"plt.figure(figsize=(20, 10))\nplt.subplot(431)\nsns.countplot(df['Stop'])\nplt.title('Stop')\nplt.xlabel('')\nplt.subplot(432)\nsns.countplot(df['Traffic_Calming'])\nplt.title('Traffic_Calming')\nplt.xlabel('')\nplt.subplot(433)\nsns.countplot(df['Traffic_Signal'])\nplt.title('Traffic_Signal')\nplt.xlabel('')\nplt.subplot(434)\nsns.countplot(df['Turning_Loop'])\nplt.title('Turning_Loop')\nplt.xlabel('')","4d9ed798":"weather_features=['Weather_Timestamp',\n                  'Temperature(F)',\n                  'Wind_Chill(F)',\n                  'Humidity(%)',\n                  'Pressure(in)',\n                  'Visibility(mi)',\n                  'Wind_Direction',\n                  'Wind_Speed(mph)',\n                  'Precipitation(in)',\n                  'Weather_Condition']\nprint('Types')  \nprint(df[weather_features].info())\nprint('\\n')\nprint('Count nan-values')\nprint(df[weather_features].isna().sum())","6dc2e082":"df['Wind_Direction'].unique()","c09d5378":"df['Wind_Direction']=df['Wind_Direction'].replace('E', 'East')\ndf['Wind_Direction']=df['Wind_Direction'].replace('N', 'North')\ndf['Wind_Direction']=df['Wind_Direction'].replace('W', 'West')\ndf['Wind_Direction']=df['Wind_Direction'].replace('S', 'South')\ndf['Wind_Direction']=df['Wind_Direction'].replace('CALM', 'Calm')","b00e840b":"df['Wind_Direction'].unique()","6c169f04":"factor_wd = pd.factorize(df['Wind_Direction'])\ndf['Wind_Direction'] = factor_wd[0]","527fb598":"df['Weather_Condition'].unique()","147a9840":"factor_wc = pd.factorize(df['Weather_Condition'])\ndf['Weather_Condition'] = factor_wc[0]","8673bd6e":"acc_features=['Temperature(F)',\n              'Wind_Chill(F)',\n              'Humidity(%)',\n              'Pressure(in)',\n              'Visibility(mi)',\n              'Wind_Speed(mph)',\n              'Precipitation(in)']\n\nfor feature in acc_features:\n    df[feature]=df[feature].fillna(df[feature].median())","0a46755a":"plt.figure(figsize=(20, 12))\nplt.subplot(341)\nsns.boxplot(x=df['Temperature(F)'])\nplt.title('Temperature(F)')\nplt.xlabel('')\nplt.subplot(342)\nsns.boxplot(x=df['Wind_Chill(F)'])\nplt.title('Wind_Chill(F)')\nplt.xlabel('')\nplt.subplot(343)\nsns.boxplot(x=df['Humidity(%)'])\nplt.title('Humidity(%)')\nplt.xlabel('')\nplt.subplot(344)\nsns.boxplot(x=df['Pressure(in)'])\nplt.title('Pressure(in)')\nplt.xlabel('')\nplt.subplot(345)\nsns.boxplot(x=df['Visibility(mi)'])\nplt.title('Visibility(mi)')\nplt.xlabel('')\nplt.subplot(346)\nsns.boxplot(x=df['Wind_Speed(mph)'])\nplt.title('Wind_Speed(mph)')\nplt.xlabel('')\nplt.subplot(347)\nsns.boxplot(x=df['Precipitation(in)'])\nplt.title('Precipitation(in)')\nplt.xlabel('')\n","ebbae828":"df=df[df['Wind_Speed(mph)'] <= 253]\ndf=df[df['Temperature(F)'] <= 134]","feb58cda":"plt.figure(figsize=(20, 12))\nplt.subplot(211)\ng=sns.countplot(x=df['Wind_Direction'])\nplt.title('Wind_Direction')\nplt.xlabel('')\nx_list=[]\nfor i in factor_wd[1]:\n    x_list.append(i)\ng.set_xticklabels(x_list)\nplt.subplot(212)\no=sns.countplot(df['Weather_Condition'])\nplt.title('Weather_Condition')\nplt.xlabel('')\nx_list=[]\nfor i in factor_wc[1]:\n    x_list.append(i)\no.set_xticklabels(x_list, size=10, rotation=90)\nplt.show()","91d33157":"df['Start_Time']=pd.to_datetime(df['Start_Time'])\ndf['End_Time']=pd.to_datetime(df['End_Time'])\ndf['Start_Time_weekday']=df['Start_Time'].dt.dayofweek\ndf['Start_Time_hour']=df['Start_Time'].dt.hour","6dc86ef0":"df['Timezone'].unique()","04c92b9c":"for row in df.index:\n    if df.loc[row,'Timezone']=='US\/Eastern':\n        df.loc[row,'Start_Time_hour']=df.loc[row,'Start_Time_hour']-1\n    elif df.loc[row,'Timezone']=='US\/Pacific':\n        df.loc[row,'Start_Time_hour']=df.loc[row,'Start_Time_hour']+2\n    elif df.loc[row,'Timezone']=='US\/Mountain':\n        df.loc[row,'Start_Time_hour']=df.loc[row,'Start_Time_hour']+1","b83c3021":"plt.figure(figsize=(20,8))\nplt.subplot(211)\nsns.distplot(df['Start_Time_weekday'])\nplt.title('Start_Time_weekday')\nplt.xlabel('')\nplt.subplot(212)\nsns.distplot(df['Start_Time_hour'])\nplt.title('Start_Time_hour')\nplt.xlabel('')","f004d355":"print('Number of records wth day')\nprint(df[df['Sunrise_Sunset']=='Day']['ID'].count())\nprint('Number of records wth night')\nprint(df[df['Sunrise_Sunset']=='Night']['ID'].count())\n\n# Filling the nans with day\n\ndf['Sunrise_Sunset']=df['Sunrise_Sunset'].fillna('Day')\nprint('nans left')\nprint(df['Sunrise_Sunset'].isna().sum())","7d51cedd":"df['Sunrise_Sunset']=df['Sunrise_Sunset'].replace('Day',0)\ndf['Sunrise_Sunset']=df['Sunrise_Sunset'].replace('Night',1)","74b1cabe":"plt.figure(figsize=(10, 6))\nplt.subplot(211)\ng=sns.countplot(x=df['Sunrise_Sunset'])\nplt.title('Sunrise_Sunset')\nplt.xlabel('')\ng.set_xticklabels(['Day','Night'])","1db792b8":"feat_columns=['State',\n              'Severity',\n              'Distance(mi)', \n              'Temperature(F)',\n              'Wind_Chill(F)',\n              'Humidity(%)',\n              'Wind_Direction',\n              'Weather_Condition',\n              'Visibility(mi)',\n              'Wind_Speed(mph)',\n              'Precipitation(in)',\n              'Start_Time_hour',\n              'Start_Time_weekday',\n              'Sunrise_Sunset',\n              'Amenity',\n              'Bump',\n              'Crossing',\n              'Give_Way',\n              'Junction',\n              'No_Exit',\n              'Railway',\n              'Roundabout',\n              'Station',\n              'Stop',\n              'Traffic_Calming',\n              'Traffic_Signal',\n              'Turning_Loop']\n\n# accident focused features \nfeatO_columns=['State',\n              'Severity',\n              'Distance(mi)',\n              'Start_Time_hour',\n              'Start_Time_weekday',\n              'Sunrise_Sunset',\n              'Weather_Condition',\n              'Amenity',\n              'Bump',\n              'Crossing',\n              'Give_Way',\n              'Junction',\n              'No_Exit',\n              'Railway',\n              'Roundabout',\n              'Station',\n              'Stop',\n              'Traffic_Calming',\n              'Traffic_Signal',\n              'Turning_Loop']\n\n\n\n\n# Last check    \ndf_feat=df[feat_columns]    \n#print(df_feat.isna().sum())\nprint(df_feat.isna().sum())\nprint(df_feat.info())\n","86bedf5b":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.externals import joblib\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","9710d197":"df_feat=df[feat_columns]","21e021c6":"# Convert state to numbers\nfactor = pd.factorize(df_feat['State'])\ndf_feat['State'] = factor[0]","4097e455":"df_feat['State'].unique()","0c1cb0f3":"#Splitting the data into independent and dependent variables\ntarget='State'\ny = df_feat[target]\nX = df_feat.drop(columns=target)","99c5b0fb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)","5537bedd":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","8cb1ee93":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n    lb = preprocessing.LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    print(roc_auc_score(y_test, y_pred, average=average))\n    return\n\ndef multiclass_f1_score(y_test, y_pred, average=\"weighted\"):\n    f1=f1_score(y_test, y_pred, average=average)\n    print(f1)\n    return\n    \ndef multiclass_classification_report(y_test, y_pred):\n    list=[]\n    for i in factor[1]:\n        list.append(i)\n    print(classification_report(y_test,y_pred,target_names=list))\n    return","a4ec4e3f":"classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)","ddd538d4":"definitions=factor[1]\nstate_num= len(definitions)\ny_pred = classifier.predict(X_test)","5972bf17":"feature_imp = pd.Series(classifier.feature_importances_,index=X.columns).sort_values(ascending=False)\n\nk=10\nsns.barplot(x=feature_imp[:10], y=feature_imp.index[:k])\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","d8981b2d":"print('ROC AUC Score')\nprint(multiclass_roc_auc_score(y_test, y_pred))\nprint('F1 Score')\nprint(multiclass_f1_score(y_test, y_pred))","1925c9b6":"list=[]\nfor i in factor[1]:\n    list.append(i)\n\nreport = classification_report(y_test, y_pred, output_dict=True, target_names=list)\ndf_report = pd.DataFrame(report).transpose()\ndf_report.to_csv('dataset_whole_report.csv')","379764e6":"df_feat=df[featO_columns]","0856317c":"factor = pd.factorize(df_feat['State'])\ndf_feat['State'] = factor[0]\ntarget='State'\ny = df_feat[target]\nX = df_feat.drop(columns=target)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","f548b663":"classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)","f1044e5b":"definitions=factor[1]\nstate_num= len(definitions)\ny_pred = classifier.predict(X_test)","982c3327":"feature_imp = pd.Series(classifier.feature_importances_,index=X.columns).sort_values(ascending=False)\n\nk=10\nsns.barplot(x=feature_imp[:10], y=feature_imp.index[:k])\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","f8844ea8":"print('ROC AUC Score')\nprint(multiclass_roc_auc_score(y_test, y_pred))\nprint('F1 Score')\nprint(multiclass_f1_score(y_test, y_pred))","aa87775b":"list=[]\nfor i in factor[1]:\n    list.append(i)\n\nreport = classification_report(y_test, y_pred, output_dict=True, target_names=list)\ndf_report = pd.DataFrame(report).transpose()\ndf_report.to_csv('dataset_acc_report.csv')","4adfeb00":"df_prop_state=pd.DataFrame(columns=['State','Count','Prop'])\ndf_prop_state","9c9391f0":"list_state=df['State'].unique()\nlist_state","b70fa721":"i=0\nfor state in list_state:\n    count=len(df[df['State']== state].index)\n    prop=count\/len(df.index)\n    df_prop_state.loc[i,'State']=state\n    df_prop_state.loc[i,'Count']=count\n    df_prop_state.loc[i,'Prop']=prop\n    i+=1","4a8bb1ca":"df_prop_state=df_prop_state.set_index('State')","5ec71ad3":"df_prop_state","bf7606f6":"df_report_whole=pd.read_csv('\/kaggle\/working\/dataset_whole_report.csv', index_col=0, header=0)\ndf_report_acc=pd.read_csv('\/kaggle\/working\/dataset_acc_report.csv', index_col=0, header=0)","28efed35":"df_report_whole=df_report_whole.rename(columns={'precision':'whole_df_precision'})\ndf_report_acc=df_report_acc.rename(columns={'precision':'acc_df_precision'})\ndf_compare = pd.concat([df_report_whole, df_report_acc,df_prop_state], axis=1, join='inner')\ndf_compare=df_compare[['whole_df_precision','acc_df_precision','Prop']]\ndf_compare['DELTA whole_df vs prop']=df_compare['whole_df_precision']-df_compare['Prop']\ndf_compare['DELTA acc vs prop']=df_compare['acc_df_precision']-df_compare['Prop']\ndf_compare","ebf9a47a":"df_compare['DELTA acc vs prop'].mean()","46e8820f":"Average improvement to benchmark model","55245d03":"# Prediction with accident focused dataset #","08945490":"# Dataset preparation #\n\nIn the problem statement is described the prediction of state by accident data. Taken all available features can cause a prediction of state for example by temperature (because California is hotter as Michigan) \u2013 but perhaps a hotter temperature can also be a risk factor for accidents. \nFor this reason two separate datasets will created for prediction model \u2013 one with all relevant features and a separate dataset with accident focused features. \n","6d0f8868":"**Weather features**\n\n* Weather Timestamp: Date\/time value for api-supported matching of weather dates\n* Temperature: Temperature as float-value\n* Wind_Chill: Temperature as float-value\n* Humidity: Humidity as float-value\n* Pressure: Pressure as float-value\n* Visibility: Visibility in miles as float-value\n* Wind_Direction: String value of wind direction, cleaned and converted as int \n* Wind_Speed: Wind speed as float-value\n* Precipitation: Amount of precipitation as float-value\n* Weather Condition: Description as string like \u201cmostly cloudy\u201d, converted as int\n\nData-Handling:\n* For missing values the median of the features will used\n* Outliners: Following outliners will not considered for prediction\n* Temperature > 134\u00b0F \u2013 134\u00b0F was the hottest recording ever in US \n* Wind speed > 253 \u2013 253mph was the highest wind speed ever recorded in the us \n* Pressure: The lowest barometric pressure ever recorded was 25.69.  In this dataset a lot of recordings have values below \u2013 the pressure feature will not used for prediction model\n","168e22d6":"**RandomForestClassifier**","0c7dad08":"**wind direction**\n\nCleaning data and factorising wind direction to numbers","f49584f8":"**Accident-focused features**\n\n* Severity: The severity of an accident is described as number between 1 to 4 with a mean value of 2.5 for all recordings","8a27571f":"# Conclusion\n\nStarted by the historical data of 3 million traffic accidents with more than 3 million individual fates I tried to predict the state of each traffic accident. After data exploration 26 features per record remained to understand the combination of risk factors per state. In two datasets with\/without geographical features, I tried different algorithms to predict the state. Compared to the benchmark model I improvement of 8,9% can achieved \u2013 in some states over 25%. \nWith this prediction it is now possible to learn from the historical data to identify and avoid traffic accident risks. Taken the numbers of Oregon with over 71tsd traffic accidents in this dataset it is now possible to understand the risk factors for 18tsd traffic accidents \u2013 and try to avoid more than 18tsd individual fates.   ","74982b0b":"**other weather features**\n\nThe continuous values will be taken to the ML-model. The null-values will be filled with median values","42f00341":"**RandomForestClassifier**","6d8a99be":"### Feature Overview ###\nFor a first overview output of the features","408212c1":"# Results discussion # \n\n## RCF-result: whole vs. accident focused dataset ##\n\nAs shown the best performance can achieve with the Random Forrest classifier. Below the top features of the prediction with whole dataset and accident-focused dataset is compared. By using all possible features the positive result is reasoned with for example \u201cPressure\u201d \u2013 which is probably not relevant as risk factor for accidents. In a closer look, the time a traffic accident happens is one state-dependent risk features. This feature with distance, weather Condition and weekday of the accident gives a state dependent feature set for prediction of accident.    \n\n## Results to benchmark model ##\n\nIn the following table in appendix the classification report for the RCF-prediction with the whole\/accident-focused dataset is used to compare the results with benchmark model. \nAs visible with the f1-score the prediction quality isn\u2019t direct related to the proportion in the dataset. For example Oregon achieved in the accident focused dataset a f1-score of 0,255 (2,4% proportion) compared to Illinoi with 0,127 (2,9% proportion).\nThis effect is also visible comparing the prediction results with the benchmark model. Using the whole dataset the prediction improves the result about 39%. The positive results decrease with the accident-focused dataset to about 8,9%. In this case some states performed over 25% better as the benchmark model on no states has a negative delta accident focused dataset vs. benchmark. \n","a84ce838":"**weather condition**\n\nCleaning data and factorising wind direction to numbers","e3bcc7b3":"**Geography features (target variable)**\n\nThe target value for the multilabel classification is imbalance - this have to be considered later in predicition","68044941":"**Sunrise \/ Twilight data**\n\nThe Sunrise\/Twilight data are categorical features if some nan and 0-values. The 4 columns are identical - taking only the Sunrise_Sunset column and removing the nan and 0-values with the median. Converting 0 to day and 1 to night","f699118b":"**Geography features (input variables)**\n\n* Start_Lat\/Start_Lng: starting point of accident, floating values of coordinates\n* End_Lat\/End_Lng: end point of accident, floating values of coordinates\n* Number\/State\/Street\/County\/Zipcode\/Country: address of the accident\u2019s location\n* Airport_Code: string value of nearest airport code\n\nThese features will not include in the prediction model because the state should not be predicted by address features.\n","44ecada8":"### Detail View","1a0b3d21":"# Prediction with whole dataset #","806213a1":"* Description: String of an description the accident occurs like \u201cTwo right lane blocked and right hand shoulder blocked due to accident on I-270 Northbound after I-55\u201d\n* multiple features like \"junction\",\"stopping\"... Boundary conditions of accident for example if there was a junction (0 for negative \/ 1 for positive)","136e1bd1":"The dataset contains a single entry for each accident with different features. The features can clustered in geography, accident-focused, weather, time\n\n**Geo-Features:**\n* Start_Lat                float64\n* Start_Lng                float64\n* End_Lat                  float64\n* End_Lng                  float64\n* Number                   float64\n* Street                   object\n* County                   object\n* State                    object\n* Zipcode                  object\n* Country                  object\n* Airport_Code             object\n\n**Accident-Features:**\n* Severity                 int64\n* Distance(mi)             float64\n* Description              object\n* Amenity                  bool\n* Bump                     bool\n* Crossing                 bool\n* Give_Way                 bool\n* Junction                 bool\n* No_Exit                  bool\n* Railway                  bool\n* Roundabout               bool\n* Station                  bool\n* Stop                     bool\n* Traffic_Calming          bool\n* Traffic_Signal           bool\n* Turning_Loop             bool\n\n**Weather-Condition:**\n* Weather_Timestamp        object\n* Temperature(F)           float64\n* Wind_Chill(F)            float64\n* Humidity(%)              float64\n* Pressure(in)             float64\n* Visibility(mi)           float64\n* Wind_Direction           object\n* Wind_Speed(mph)          float64\n* Precipitation(in)        float64\n* Weather_Condition        object\n\n**Time-Features:**\n* Start_Time               object\n* End_Time                 object\n* Timezone                 object\n* Sunrise_Sunset           object\n* Civil_Twilight           object\n* Nautical_Twilight        object\n* Astronomical_Twilight    object","09128454":"**Evaluation functions**","5b877829":"**Time features **\n\n* Start_Time\/ End Time: Date and Time of start\/end traffic accident\n* Timezone: Timezone in US in the categories Pacific\/Mountain\/Central\/Eastern. The Timezone values used for normalizing the additional feature Start_Time_hour\n* Start_Time_hour: Extracted as additional feature weekday of start hour \u2013 normalized of Central timezone (Pacific Time +2 \/ Mountain Time +1 \/ Eastern Time -1) \n* Start_Time_weekday: Extracted as additional feature weekday of start time\n","0117cecb":"# Benchmark model #\n\nAs benchmark the proportion will used for each state in database. ","80e14756":"* Distance(mi): Distance means the difference starting to end point of the accident. As visible in general nearly zero miles are recorded but some accidents have outliners","0b179dd2":"# EDA #\n\nFor memory and training-time-reasons a sample of 500.000 records will used ","ca9f57aa":"# Project Overview # \nThere were 33,654 fatal motor vehicle crashes in the United States in 2018 in which 36,560 deaths occurred  \u2013 this means every 15 minutes a traffic accidents happened. Every traffic accident is individual and cause personal fate. Nevertheless, risk factors increase the probability for a traffic accident. As visible at nhtsa  in US different risk factors per state cause a different risk level. So for example, the SUV proportion or the mix of urban areas influence the accident risk and severity. \n\n# Problem Statement # \n\nAs shown different risk factors cause the accident probability per state. Combining this facts and the idea of crime prediction leads to the prediction of country per traffic accident. With this prediction of risk factors per state individual measures can defined to reduce the local risk. For a country or state agency this can be a daily tool to understand early trends and fight against individual tragically fates.  "}}