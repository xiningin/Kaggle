{"cell_type":{"4e156be0":"code","cc414ca0":"code","843a3c71":"code","b4e79cbe":"code","350d11b1":"code","7dca0548":"code","8fb514a7":"code","77694b02":"code","fb8c12f5":"code","54d78bea":"code","24f29a20":"code","cfbf10e1":"code","732411c2":"code","a131c477":"code","9e85cdf8":"code","ff77c59a":"code","e9db0643":"code","147977cb":"code","99ed1f21":"code","130f099e":"code","84303980":"code","c0eb9495":"code","dabd8272":"code","5dc02c7f":"code","ff91d4a7":"code","3cbe189a":"code","80c1d01c":"code","5e0fd37b":"code","f95e8e75":"code","cdb39ed3":"code","773e53fb":"code","ac4da668":"code","f9f9b81c":"code","1b044745":"code","b9c32c9a":"code","afafb47d":"code","9158ed34":"code","5635d850":"markdown","850a168d":"markdown","ad479910":"markdown","b3358645":"markdown","f116b874":"markdown","77974eff":"markdown","c840e23d":"markdown","7023225a":"markdown","84a832a3":"markdown","cafe6185":"markdown","db73540b":"markdown","4885eac2":"markdown","d011afcc":"markdown","23822eb1":"markdown","0af75ee8":"markdown","b99cb8e3":"markdown","e4d850d0":"markdown","05d6b6b4":"markdown","4f1d542d":"markdown","facf06c1":"markdown","1c8a3a01":"markdown","634044c7":"markdown","15b55b07":"markdown","426b3387":"markdown","62292edc":"markdown","230b053d":"markdown","99f0a9c2":"markdown","96e56e8d":"markdown","b4bee2ba":"markdown","2527e691":"markdown","639bcb86":"markdown","db5f3f0c":"markdown","20f4ec13":"markdown"},"source":{"4e156be0":"import os\n\n# Pandas\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\n\n# Plotly\nimport plotly.graph_objects as go\n\n# Markdown print\nfrom IPython.display import Markdown, display\n\n# Sklearn split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n    \n# Functions\ndef printmd(string):\n    display(Markdown(string))\n\ndef mycatplot(data, name):\n    fig = go.Figure()\n    fig.add_traces([go.Bar(x=data.index, y=data.total, name=\"Total\", visible=False),\n                    go.Bar(x=data.index, y=data[\"<=50K\"], name=\"< $50K\"),\n                    go.Bar(x=data.index, y=data[\">50K\"], name=\"> $50K\"),\n                    go.Bar(x=data.index, y=data.less_ratio, name=\"< $50K\", visible=False),\n                    go.Bar(x=data.index, y=1 - data.less_ratio, name=\"> $50K\", visible=False)])\n    fig.update_layout(title=name, xaxis_title=name, yaxis_title=\"Count\", legend_title_text=\"Income\", showlegend=True, updatemenus=[\n        dict(type=\"buttons\", direction=\"right\", active=1, x=1, y=1.25, buttons=list([\n            dict(label=\"Total\", method=\"update\", args=[{\"visible\": [True, False, False, False, False]}, {\"barmode\": \"group\"}]),\n            dict(label=\"Per income\", method=\"update\", args=[{\"visible\": [False, True, True, False, False]}, {\"barmode\": \"group\"}]),\n            dict(label=\"Per income ratio\", method=\"update\", args=[{\"visible\": [False, False, False, True, True]}, {\"barmode\": \"stack\"}]),\n        ]))\n    ])\n    return fig\n\ndef mycatpivot(data, name):\n    res = data.pivot_table(index=name, columns=\"income\", values=\"age\", aggfunc=\"count\", fill_value=0)\n    res[\"total\"] = res[\"<=50K\"] + res[\">50K\"]\n    res[\"less_ratio\"] = (res[\"<=50K\"] \/ (res[\"<=50K\"] + res[\">50K\"])).round(2)\n    return res.sort_values(\"total\")","cc414ca0":"# Read the full dataset\ncensus = pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\", header=0, names=[\"age\", \"workclass\", \"final_weight\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital\", \"cap_loss\", \"work_hours\", \"country\", \"income\"])\n\n# Merge capital columns\ncensus.capital = census.capital - census.cap_loss\ncensus.drop(columns=[\"cap_loss\"], inplace=True)\n\n# Info\nprintmd(f\"The dataset is characterized by **{census.shape[0]}** rows and **{census.shape[1]}** features.\")\ncensus.head(10)","843a3c71":"printmd(\"### Duplicated rows\\n\\n\"\n        \"As you can see from the following table, there are some rows that are **duplicated**. All the duplicated rows appear only twice (except for one appearing three times). \"\n        \"Of course, the duplicated rows have been **removed** (keeping only one copy).\")\n\nif len(census[census.duplicated()]) != 0:\n    duplicated = census[census.duplicated(keep=False)].sort_values(by=list(census.columns)).pivot_table(index=list(census.columns), aggfunc=\"size\").reset_index(name=\"repetitions\")\n    census.drop_duplicates(ignore_index=True, inplace=True)\n    \nduplicated.head(len(duplicated))","b4e79cbe":"# Income\nprintmd(\"### Income\\n\\n\"\n        \"Income is our **binary target variable** that indicates whether a person makes over \\$50K per year or not. The first thing to notice is that the dataset is a little bit *unbalanced*: \"\n        f\"most of the records belong to the `<$50K` class ({census.income.value_counts()[0] * 100.0 \/ len(census):.2f}% -> baseline accuracy for the models).\")\n\n# Plot\nfig = go.Figure(go.Histogram(x=census.income[census.income == \"<=50K\"], name=\"< $50K\"))\nfig.add_trace(go.Histogram(x=census.income[census.income == \">50K\"], name=\"> $50K\"))\nfig.update_layout(title=\"Income\", xaxis_title=\"Income\", yaxis_title= \"Count\", legend_title_text=\"Income\", showlegend=True)\nfig.show()","350d11b1":"# Age\nprintmd(\"### Age\\n\\n\"\n        \"Age is a discrete *numerical* feature that indicates the age of the individuals. The boxplot shows that:\\n\"\n        \" - most of the individuals are less than 50 years old\\n\"\n        \" - older individuals tend to make more money\")\n\n# Plot\nfig = go.Figure()\nfig.add_traces([go.Box(x=census.age, name=\"Total\", visible=False),\n                go.Box(x=census.age[census.income == \"<=50K\"], name=\"< $50K\"),\n                go.Box(x=census.age[census.income == \">50K\"], name=\"> $50K\")])\nfig.update_layout(title=\"Age\", xaxis_title=\"Age\", yaxis_title= \"Income\", showlegend=False, updatemenus=[\n    dict(type=\"buttons\", direction=\"right\", active=1, x=1, y=1.25, buttons=list([\n        dict(label=\"Total\", method=\"update\", args=[{\"visible\": [True, False, False]}]),\n        dict(label=\"Per income\", method=\"update\", args=[{\"visible\": [False, True, True]}]),\n    ]))\n])\nfig.show()","7dca0548":"# Workclass\nworkclass = mycatpivot(census, \"workclass\")\n\nprintmd(\"### Workclass\\n\\n\"\n        \"Workclass is a *categorical* feature indicating the job sector of the individuals. The barplot shows that:\\n\"\n        f\" - most of the individuals work in the *Private* sector ({workclass.total.loc['Private'] * 100.0 \/ workclass.total.sum():.2f}%)\\n\"\n        f\" - for a lot of individuals the workclass is unknown *?* ({workclass.total.loc['?'] * 100.0 \/ workclass.total.sum():.2f}%) (addressed [here](#Workclass---Occupation))\\n\"\n        \" - the classes *Never-worked* and *Without-pay* count a very small amount of records and are all related to income `<$50K` (addressed [here](#Workclass---Occupation))\")\n\nmycatplot(workclass, \"Workclass\").show()","8fb514a7":"# Occupation\noccupation = mycatpivot(census, \"occupation\")\n\nprintmd(\"### Occupation\\n\\n\"\n        \"Occupation is a *categorical* feature indicating the specific occupation of the individual. The barplot shows that:\\n\"\n        \" - there is not a predominant occupation\\n\"\n        f\" - for a lot of individuals the occupation is unknown *?* ({occupation.total.loc['?'] * 100.0 \/ occupation.total.sum():.2f}%) (addressed [here](#Workclass---Occupation))\")\n\nmycatplot(occupation, \"Occupation\").show()","77694b02":"# Workclass - Occupation\nprintmd(\"### Workclass - Occupation\\n\\n\"\n        \"Analysing the features workclass and occupation together, it is possible to notice that:\\n\"\n        \" - both have unknown values (*?*) with almost a 1-to-1 relationship between them\\n\"\n        \" - the workclass classes *Never-worked* and *Without-pay* are always related to an income `<$50K` (addressed [here](#Outliers))\")\n\nworkclass_occupation = census.pivot_table(index=\"workclass\", columns=\"occupation\", values=\"age\", aggfunc=\"count\", fill_value=0)\nworkclass_occupation.head(len(workclass_occupation))","fb8c12f5":"# Education - Education num\neducation = mycatpivot(census, \"education\")\neducation[\"education_num\"] = census.pivot_table(index=\"education\", values=\"education_num\").sort_values(by=\"education_num\").education_num\neducation.sort_values(\"education_num\", inplace=True)\n\nprintmd(\"### Education - Education number\\n\\n\"\n        \"Education is a *categorical* feature indicating the heighest education achieved by the individuals. \"\n        \"Each education is associated with an ordinal number going from the lowest level of education to the heighest. The barplot shows that:\\n\"\n        \" - most individuals have at least an high-school degree\\n\"\n        \" - individuals with an higher level of education tend to make more money\")\n\nmycatplot(education, \"Education\").show()","54d78bea":"# Marital status\nmarital_status = mycatpivot(census, \"marital_status\")\n\nprintmd(\"### Marital status\\n\\n\"\n        \"Marital status is a *categorical* feature indicating the marital status of the individual. The barplot shows that:\\n\"\n        \" - married individuals tend to make more money\")\n\nmycatplot(marital_status, \"Marital status\").show()","24f29a20":"# Relationship\nrelationship = mycatpivot(census, \"relationship\")\n\nprintmd(\"### Relationship\\n\\n\"\n        \"Relationship is a *categorical* feature indicating the relationship status of the individual. As seen before, the barplot shows that:\\n\"\n        \" - married individuals tend to make more money\")\n\nmycatplot(relationship, \"Relationship\").show()","cfbf10e1":"# Marital status - Relationship\nprintmd(\"### Marital status - Relationship\\n\\n\"\n        \"Analysing marital status and relationship together, the most important thing to notice is that, if you are an husband or a wife, you of course are married. \"\n        \"On the other hand, if you are unmarried, you cannot be married. Also, notice how differentiating between husband and wife is redundant with the *Sex* feature.\")\nmarital_relationship = census.pivot_table(index=\"marital_status\", columns=\"relationship\", values=\"age\", aggfunc=\"count\", fill_value=0)\nmarital_relationship","732411c2":"# Race\nrace = mycatpivot(census, \"race\")\n\nprintmd(\"### Race\\n\\n\"\n        \"Race is a *categorical* feature indicating the race of the individual.\")\n\nmycatplot(race, \"Race\").show()","a131c477":"# Sex\nsex = mycatpivot(census, \"sex\")\n\nprintmd(\"### Sex\\n\\n\"\n        \"Sex is a *categorical* feature indicating the sex of the individual. The barplot shows that:\\n\"\n        \" - male individuals tend to make more money\")\n\nmycatplot(sex, \"Sex\").show()","9e85cdf8":"# Country\ncountry = mycatpivot(census, \"country\")\n\nprintmd(\"### Country\\n\\n\"\n        \"Country is a *categorical* feature indicating the country of the individual.\")\n\nmycatplot(country, \"Country\").show()","ff77c59a":"# Capital\nprintmd(\"### Capital\\n\\n\"\n        \"Capital gain and capital loss are *numerical* features that indicate how much an individual has gained or lost through investing. \"\n        \"For simplifying the data, I have reduced the two features to a single column that is the difference of the two. (There were no records with both loss and gain different than 0). \"\n        \" The distribution plot shows that:\\n\"\n        f\" - most of the individuals do not invest ({len(census.capital[census.capital == 0])*100.0\/len(census):.2f}%)\\n\"\n        \" - if you earn from investments, you tend to earn more\")\n\n# Plot\nfig = go.Figure()\nfig.add_traces([go.Box(x=census.capital[census.capital != 0], visible=False),\n                go.Box(x=census.capital[(census.income == \"<=50K\") & (census.capital != 0)], name=\"< $50K\"),\n                go.Box(x=census.capital[(census.income == \">50K\") & (census.capital != 0)], name=\"> $50K\")])\nfig.update_layout(title=\"Capital\", xaxis_title=\"Capital gain\", yaxis_title= \"Income\", showlegend=False, updatemenus=[\n    dict(type=\"buttons\", direction=\"right\", active=1, x=1, y=1.25, buttons=list([\n        dict(label=\"Total (!=0)\", method=\"update\", args=[{\"visible\": [True, False, False]}]),\n        dict(label=\"Per income (!=0)\", method=\"update\", args=[{\"visible\": [False, True, True]}]),\n    ]))\n])\nfig.show()","e9db0643":"# Work hours\nprintmd(\"### Work hours\\n\\n\"\n        \"Work hours is a *numerical* feature that indicates the number of work hours per week of the individuals. The distribution plot shows that:\\n\"\n        \" - most of the individuals work 40 hours per week (25% and 50% quartiles coincide on 40: at least 25% of the individauls work 40h\/week)\\n\"\n        \" - individuals that work more tend to make more money\")\n\n# Plot\nfig = go.Figure()\nfig.add_traces([go.Box(x=census.work_hours, name=\"Total\", boxpoints=False, visible=False),\n                go.Box(x=census.work_hours[census.income == \"<=50K\"], name=\"< $50K\", boxpoints=False),\n                go.Box(x=census.work_hours[census.income == \">50K\"], name=\"> $50K\", boxpoints=False)])\nfig.update_layout(title=\"Work hours\", xaxis_title=\"Work hours\", yaxis_title= \"Income\", showlegend=False, updatemenus=[\n    dict(type=\"buttons\", direction=\"right\", active=1, x=1, y=1.25, buttons=list([\n        dict(label=\"Total\", method=\"update\", args=[{\"visible\": [True, False, False]}]),\n        dict(label=\"Per income\", method=\"update\", args=[{\"visible\": [False, True, True]}]),\n    ]))\n])\nfig.show()","147977cb":"def clean(df):\n    # Cap\n    df.capital = df.capital - df.cap_loss\n    df.drop(columns=[\"cap_loss\"], inplace=True)\n\n    # Duplicates\n    df.drop_duplicates(ignore_index=True, inplace=True)\n\n    # No fnlwgt and only one education\n    df.drop(columns=[\"final_weight\", \"education\"], inplace=True)\n    df.rename(columns={\"education_num\": \"education\"}, inplace=True)\n\n    # No never-without workclass\n    df = df[~((df.workclass == \"Never-worked\") | (df.workclass == \"Without-pay\"))]\n    return df\n\ndef impute(df):\n    df.workclass = df.workclass.map(lambda x: \"Private\" if x == \"?\" else x)\n    df.occupation = df.occupation.map(lambda x: \"Other\" if x == \"?\" else x)\n    df.country = df.country.map(lambda x: \"United-States\" if x == \"?\" else x)\n    return df\n    \ndef drop(df):\n    return df[(df.workclass != \"?\") & (df.occupation != \"?\") & (df.country != \"?\")]\n\ndef binning(df):\n    df.workclass = df.workclass.map(lambda x: \"Private\" if x == \"Private\" else \"Gov\" if x in [\"Federal-gov\", \"Local-gov\", \"State-gov\"] else \"Self\")\n    df.marital_status = df.marital_status.map(lambda x: \"Single\" if x in [\"Widowed\", \"Divorced\", \"Never-married\"] else \"Married\")\n    df.relationship = df.relationship.map(lambda x: \"Spouse\" if x in [\"Husband\", \"Wife\"] else \"Other\" if x in [\"Unmarried\", \"Not-in-family\"] else \"Relative\")\n    df.race = df.race.map(lambda x: \"White\" if x == \"White\" else \"Other\")\n    df.country = df.country.map(lambda x: \"US\" if x == \"United-States\" else \"Other\")\n    return df\n\ndef discretize(df):\n    df.age = df.age \/\/ 10\n    df.work_hours = df.work_hours \/\/ 10\n    df.capital = df.capital.map(lambda x: -1 if x < 0 else 0 if x == 0 else 1)\n    return df\n\n# Read again the original dataset\ncensus = pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\", header=0, names=[\"age\", \"workclass\", \"final_weight\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital\", \"cap_loss\", \"work_hours\", \"country\", \"income\"])\ncensus_train, census_test = train_test_split(census, train_size=0.75, random_state=0, stratify=census.income)\n\n# Save original splits\nfolder = os.path.join(\"\/kaggle\/working\/original\")\nif not os.path.isdir(folder):\n    os.mkdir(folder)\ncensus_train.to_csv(\"\/kaggle\/working\/original\/train.csv\", index=False)\ncensus_test.to_csv(\"\/kaggle\/working\/original\/test.csv\", index=False)\n\ndatasets = {\n    \"clean\": {\"operations\": [clean]},\n    \"drop\": {\"operations\": [clean, drop]},\n    \"drop_bin\": {\"operations\": [clean, drop, binning]},\n    \"drop_discr\": {\"operations\": [clean, drop, discretize]},\n    \"drop_bin_discr\": {\"operations\": [clean, drop, binning, discretize]},\n    \"impute\": {\"operations\": [clean, impute]},\n    \"impute_bin\": {\"operations\": [clean, impute, binning]},\n    \"impute_discr\": {\"operations\": [clean, impute, discretize]},\n    \"impute_bin_discr\": {\"operations\": [clean, impute, binning, discretize]},\n}\n\n# Generation of datasets\nfor key in datasets:\n    temp_train = census_train.copy()\n    temp_test = census_test.copy()\n    for op in datasets[key][\"operations\"]:\n        temp_train = op(temp_train)\n        temp_test = op(temp_test)\n    folder = os.path.join(\"\/kaggle\/working\", key)\n    if not os.path.isdir(folder):\n        os.mkdir(folder)\n    scaler = StandardScaler().fit(temp_train[[\"age\", \"education\", \"capital\", \"work_hours\"]])\n    temp_train[[\"age\", \"education\", \"capital\", \"work_hours\"]] = scaler.transform(temp_train[[\"age\", \"education\", \"capital\", \"work_hours\"]])\n    temp_test[[\"age\", \"education\", \"capital\", \"work_hours\"]] = scaler.transform(temp_test[[\"age\", \"education\", \"capital\", \"work_hours\"]])\n    temp_train.to_csv(os.path.join(folder, \"train.csv\"), index=False)\n    temp_test.to_csv(os.path.join(folder, \"test.csv\"), index=False)","99ed1f21":"# Pandas\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\n\n# Numpy\nimport numpy as np\n\n# Plotly\nimport plotly.graph_objects as go\n\n# Scikit learn\nfrom sklearn import set_config\nset_config(display='diagram')\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_text\n\n# Functions\ndef train_and_test(datasets, classifier, param_grid, scoring='accuracy', n_jobs=-1, return_train_score=True):\n    model = {}\n    results = {}\n    \n    for key in datasets:\n        model[key] = {}\n        results[key] = {}\n        \n        # Grid search\n        model[key][\"model_ohe_grid\"] = GridSearchCV(classifier, param_grid, scoring=scoring, n_jobs=n_jobs, return_train_score=return_train_score).fit(datasets[key][\"X_train_ohe\"], datasets[key][\"Y_train\"])\n        model[key][\"model_le_grid\"] = GridSearchCV(classifier, param_grid, scoring=scoring, n_jobs=n_jobs, return_train_score=return_train_score).fit(datasets[key][\"X_train_le\"], datasets[key][\"Y_train\"])\n        model[key][\"model_ohe\"] = model[key][\"model_ohe_grid\"].best_estimator_\n        model[key][\"model_le\"] = model[key][\"model_le_grid\"].best_estimator_\n\n        # Test\n        results[key][\"ohe\"] = model[key]['model_ohe'].score(datasets[key]['X_test_ohe'], datasets[key]['Y_test'])\n        results[key][\"le\"] = model[key]['model_le'].score(datasets[key]['X_test_le'], datasets[key]['Y_test'])\n    \n    return model, results\n\ndef plot_results(results, title):\n    fig = go.Figure()\n    results = pd.DataFrame(results)\n    for col in results:\n        fig.add_traces(go.Bar(y=results.index, x=results[col], orientation=\"h\", name=col))\n    fig.update_layout(title=title, xaxis = dict(range=[0.5, 0.9]))\n    return fig \n\ndef acc_analysis(datasets, model_dict, param_name):\n    analysis = {param_name: [], 'enc': [], 'test': [], 'train': []}\n    for key in datasets:\n        for param in model_dict[key][\"model_ohe_grid\"].cv_results_[\"params\"]:\n            analysis[param_name].append(param[param_name])\n            analysis['enc'].append('ohe')\n            analysis['test'].append(model_dict[key][\"model_ohe_grid\"].cv_results_[\"mean_test_score\"][model_dict[key][\"model_ohe_grid\"].cv_results_[\"params\"].index(param)])\n            analysis['train'].append(model_dict[key][\"model_ohe_grid\"].cv_results_[\"mean_train_score\"][model_dict[key][\"model_ohe_grid\"].cv_results_[\"params\"].index(param)])\n        for param in model_dict[key][\"model_le_grid\"].cv_results_[\"params\"]:\n            analysis[param_name].append(param[param_name])\n            analysis['enc'].append('le')\n            analysis['test'].append(model_dict[key][\"model_le_grid\"].cv_results_[\"mean_test_score\"][model_dict[key][\"model_le_grid\"].cv_results_[\"params\"].index(param)])\n            analysis['train'].append(model_dict[key][\"model_le_grid\"].cv_results_[\"mean_train_score\"][model_dict[key][\"model_le_grid\"].cv_results_[\"params\"].index(param)])\n\n    analysis_train = pd.pivot_table(pd.DataFrame(analysis), index=param_name, columns=\"enc\", values=\"train\", aggfunc=np.mean)\n    analysis_test = pd.pivot_table(pd.DataFrame(analysis), index=param_name, columns=\"enc\", values=\"test\", aggfunc=np.mean)\n\n    fig = go.Figure()\n    for enc in analysis_train:\n        fig.add_traces(go.Scatter(x=analysis_train.index, y=analysis_train[enc], name=f\"Train - {enc}\"))\n\n    for enc in analysis_test:\n        fig.add_traces(go.Scatter(x=analysis_test.index, y=analysis_test[enc], name=f\"Test - {enc}\"))\n\n    return fig\n    \ndef my_print_tree(tree, feature_names):\n    print(export_text(tree, feature_names=feature_names))","130f099e":"# Read the datasets\ndatasets = {}\ndatasets_keys = [\"original\", \"clean\", \"drop\", \"drop_bin\", \"drop_discr\", \"drop_bin_discr\", \"impute\", \"impute_bin\", \"impute_discr\", \"impute_bin_discr\"]\n\n# Read and encode\nfor key in datasets_keys:\n    datasets[key] = {}\n    datasets[key][\"X_train\"] = pd.read_csv(f\"\/kaggle\/working\/{key}\/train.csv\")\n    datasets[key][\"X_test\"] = pd.read_csv(f\"\/kaggle\/working\/{key}\/test.csv\")\n    \n    # Save target variable as 0 \/ 1 codes\n    datasets[key][\"Y_train\"] = datasets[key][\"X_train\"].income.astype(\"category\").cat.codes\n    datasets[key][\"Y_test\"] = datasets[key][\"X_test\"].income.astype(\"category\").cat.codes\n    \n    # One Hot Encoding\n    datasets[key][\"X_train_ohe\"] = datasets[key][\"X_train\"].copy().drop(columns=[\"income\"])\n    datasets[key][\"X_test_ohe\"] = datasets[key][\"X_test\"].copy().drop(columns=[\"income\"])\n    for col in datasets[key][\"X_train_ohe\"].select_dtypes(\"object\").columns:\n        if len(datasets[key][\"X_train_ohe\"][col].unique()) == 2:\n            datasets[key][\"X_train_ohe\"][col] = datasets[key][\"X_train_ohe\"][col].astype(\"category\").cat.codes\n            datasets[key][\"X_test_ohe\"][col] = datasets[key][\"X_test_ohe\"][col].astype(\"category\").cat.codes\n    datasets[key][\"X_train_ohe\"] = pd.get_dummies(datasets[key][\"X_train_ohe\"])\n    datasets[key][\"X_test_ohe\"] = pd.get_dummies(datasets[key][\"X_test_ohe\"])\n    \n    # Label Encoding\n    datasets[key][\"X_train_le\"] = datasets[key][\"X_train\"].copy().drop(columns=[\"income\"])\n    datasets[key][\"X_test_le\"] = datasets[key][\"X_test\"].copy().drop(columns=[\"income\"])\n    for col in datasets[key][\"X_train_le\"].select_dtypes(\"object\").columns:\n        datasets[key][\"X_train_le\"][col] = datasets[key][\"X_train_le\"][col].astype(\"category\").cat.codes\n        datasets[key][\"X_test_le\"][col] = datasets[key][\"X_test_le\"][col].astype(\"category\").cat.codes\n    \n    del datasets[key][\"X_train\"]\n    del datasets[key][\"X_test\"]","84303980":"# Logistic Regression\nlogistic_regression, logistic_regression_results = train_and_test(\n    datasets,\n    LogisticRegression(max_iter=500),\n    [{'C': [0.001, 0.01, 0.1, 1, 2, 5, 10, 100, 1000], 'solver': ['liblinear', 'lbfgs']}]\n)","c0eb9495":"acc_analysis(datasets, logistic_regression, 'C').update_layout(xaxis_type=\"log\", xaxis_title=\"C\", yaxis_title=\"Balanced accuracy\", title=\"Logistic regression accuracy against C\")","dabd8272":"# Plot\nplot_results(logistic_regression_results, \"Logistic regression test accuracy\").show()\nprint(\"Best model:\")\nlogistic_regression[\"clean\"][\"model_ohe\"]","5dc02c7f":"# Linear Discriminant Analysis\nlda, lda_results = train_and_test(\n    datasets,\n    LinearDiscriminantAnalysis(),\n    [{'solver': ['svd']}]\n)","ff91d4a7":"# Plot\nplot_results(lda_results, \"Linear discriminant analysis test accuracy\").show()\nprint(\"Best model: (default params)\")\nlda[\"original\"][\"model_ohe\"]","3cbe189a":"# KNN\nknn, knn_results = train_and_test(\n    datasets,\n    KNeighborsClassifier(),\n    [{'n_neighbors': [3, 5, 7, 9, 13, 17, 21, 25, 30, 40]}]\n)","80c1d01c":"acc_analysis(datasets, knn, 'n_neighbors').update_layout(xaxis_title=\"K\", yaxis_title=\"Balanced accuracy\", title=\"K-Nearest Neighbors accuracy against K\")","5e0fd37b":"# Plot\nplot_results(knn_results, \"K-Nearest Neighbors test accuracy\").show()\nprint(\"Best model:\")\nknn[\"impute\"][\"model_ohe\"]","f95e8e75":"# Decision trees\ndt, dt_results = train_and_test(\n    datasets,\n    DecisionTreeClassifier(),\n    [{'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 5, 6, 8, 12, 15, 18, 22, 26]}]\n)","cdb39ed3":"acc_analysis(datasets, dt, 'max_depth').update_layout(xaxis_title=\"max_depth\", yaxis_title=\"Balanced accuracy\", title=\"Decision tree accuracy against max_depth\")","773e53fb":"# Plot\nplot_results(dt_results, \"Decision tree test accuracy\").show()\nprint(\"Best model:\")\ndt[\"impute_bin\"][\"model_le\"]","ac4da668":"# Random forest\nrf, rf_results = train_and_test(\n    datasets,\n    RandomForestClassifier(max_depth=8),\n    [{'n_estimators': [1, 10, 50, 100, 150], 'criterion': ['gini', 'entropy']}]\n)","f9f9b81c":"acc_analysis(datasets, rf, 'n_estimators').update_layout(xaxis_title=\"n_estimators\", yaxis_title=\"Balanced accuracy\", title=\"Random forest accuracy against n_estimators\")","1b044745":"# Plot\nplot_results(rf_results, \"Random forest test accuracy\").show()\nprint(\"Best model:\")\ndt[\"impute_bin\"][\"model_ohe\"]","b9c32c9a":"# Random forest depth\nrf_depth, rf_results_depth = train_and_test(\n    datasets,\n    RandomForestClassifier(n_estimators=100),\n    [{'max_depth': [1, 3, 6, 8, 12, 15], 'criterion': ['gini', 'entropy']}]\n)","afafb47d":"acc_analysis(datasets, rf_depth, \"max_depth\").update_layout(xaxis_title=\"max_depth\", yaxis_title=\"Balanced accuracy\", title=\"Random forest accuracy against max_depth\")","9158ed34":"# Plot\nplot_results(rf_results_depth, \"Random forest\").show()\nprint(\"Best model:\")\ndt[\"clean\"][\"model_le\"]","5635d850":"## Decision Trees\n\n<span id=\"dt-theory\" \/>\n\n### Theory recall\n\nDecision tree models stratify the predictors space into simpler regions in order to make predictions. The assigned class is simply the most probable inside that region.\n\nThe most difficult part is therefore the definition of the tree and the *split criterions*. The main idea behind the definition of a *split criterion* is to generate splits where there is a low *mixing* of class variables. Hence, we need to define a measure for this *mixing* and then generate all the splits recursively.\n\nOf course, the model stops when the level of *mixing* inside a branch is below a given threshold. In this way, the risk of overfitting is reduced. On the other hand, stopping too soon may result in underfitting.\n\nThe two most common measures of impurity are:\n\n- Gini index: $G(node)=1-\\sum\\limits_{k=1}^{K}p\\left(k|node\\right)^{2}$ which is a measure of total variance across the $K$ classes in the node\n- Cross-entropy: $D=-\\sum\\limits_{k=1}^{K}p\\left(k|node\\right)log\\left(p\\left(k|node\\right)\\right)$\n\nThe main advantages of this model are:\n\n- Simple and interpretable\n- Almost no need of data preparation (can handle categorical variables)\n\nOn the other hand, the main disadvantages are:\n\n- Can overfit pretty easily\n- Not very accurate with respect to other supervised models (however, despite decreasing the interpretability, aggregating trees can solve this problem; see [Random Forest](#Random-Forest))\n- Affected by unbalanced target classes\n\n<span id=\"dt-parameters\" \/>\n\n### Parameters\n\nWith the grid search, the following parameters have been optimized:\n\n- *criterion*: the split criterion used to measure the level of impurity of a split\n- *max_depth*: the maximum depth of the tree (to control overfitting)","850a168d":"<span id=\"lda-testing\" \/>\n\n### Testing\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","ad479910":"<span id=\"knn-testing\" \/>\n\n### Testing\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","b3358645":"## Future Work\n\nI think that achieving around 86,5% accuracy can be considered pretty good given the difficulty of dataset. Nonetheless, I am aware the there are multiple ways to maybe improve the current models. The following possibilities of improving the models are left for the future:\n\n- try different metrics to bettere evaluate the parameters\n- try other combinations of feature engineering and maybe also different techniques\n- try to implement a feature selection or dimensionality reduction algorithm","f116b874":"## Introduction\n\n### Reading the data\n\nIn the previous notebook, we generated different datasets according to the different strategies of feature engineering we are trying to compare. The only step we still haven't performed is encoding; therefore, we can now read the data and encode it using both a label encoder and a one hot encoder. In this step, Xs and ys has also been separated for the next phases.","77974eff":"<span id=\"knn-testing\" \/>\n\n### Testing\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","c840e23d":"<span id=\"logreg-testing\" \/>\n\n### Testing\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","7023225a":"## Linear Discriminant Analysis\n\n<span id=\"lda-theory\" \/>\n\n### Theory recall\n\n*Discriminant analysis* is a probabilistic model whose approach is to estimate the distribution of each feature in the dataset, and then compute the posterior probability of the target class exploiting the Bayes theorem (which makes the assumption of independent features). Therefore, the predictions are made looking to the feature with the highest density. Bayes recall:\n\n$$P\\left(Y=k|X=x\\right) = \\frac{P\\left(X=x|Y=k\\right)*P\\left(Y=k\\right)}{P\\left(X=x\\right)} = \\frac{\\pi_{k}*f_{k}\\left(x\\right)}{\\sum_{l=1}^{K}\\pi_{l}*f_{l}\\left(x\\right)}$$\n\nOn the right part of the equation $f_{k}\\left(x\\right)$ is the *density* of $x$ when the class is $k$ and $\\pi_{k}$ is the *marginal* probability of class $k$.\n\nWith multiple predictors like in our case, the model assumes that the input $X$ has a multivariate normal distribution, with distinct means and common covariance matrix; hence, the discriminant function has the form:\n\n$$\\delta_{k}\\left(x\\right) = x^{T}\\Sigma^{-1}\\mu_{k}-\\frac{1}{2}\\mu_{k}^{T}\\Sigma^{-1}\\mu_{k}+log\\left(\\pi_{k}\\right)$$\n\nTo an observation $x$ will be assigned the class with the largest *discriminant score*:\n\n$$\\delta_{k}\\left(x\\right) = x*\\frac{\\mu_{k}}{\\sigma^{2}} - \\frac{\\mu_{k}^{2}}{2\\sigma^{2}} + log\\left(\\pi_{k}\\right)$$\n\nLinear discriminant analysis parameters are estimated using the full likelihood function ($P\\left(X,y\\right)$ *generative learning*).\n\n<span id=\"lda-parameters\" \/>\n\n### Parameters\n\nNo parameters optimized with this model.","84a832a3":"<span id=\"dt-conclusions\" \/>\n\n### Conclusions\n\nAs we can see from the following plot:\n\n- since the decision trees can handle categorical features, the best performing datasets have been the label encoded ones\n- it is interesting how discretizing variables decreases the performance of the trees","cafe6185":"## Datasets generation\n\nTo feed the datasets into the models, there are two things that still need to be performed:\n\n- splitting the original dataset into train and test set\n- encode all the categorical variables\n\n### Splitting\n\nSince we are also comparing how the different feature engineering techniques affect the results, the split is performed only on the original dataset. In this way, the two splits are the same for all the generated datasets. Another thing to keep in mind is that our dataset is unbalanced (76% of `<$50K`): hence, it is appropriate to stratify the split (keep the proportion of the 2 classes in the 2 splits). I opted for a 3:1 split.\n\n### Encoding\n\nAs mentioned before, the models cannot work directly with categorical variables, therefore we need to encode them:\n\n- the first option is to One Hot Encode them: generate a binary column for each class of a categorical feature to indicate whether the row had that value or not.\n- the second option is to Label Encode them: assign a number to each class (this is not ideal because we are implicitly generating an order between the classes and also giving them different magnitude)\n\nI tried both options and compared the results.\n\n### Summary of the generated datasets\n\n- adult.csv: unmodified dataset\n\n**Preparation:**\n- **clean**: clean dataset (no duplicated rows, no fnlwgt, only the ordinal version of education, no never-worked and without-pay records, difference of capitals) (this is the base for the other datasets)\n\n**Missing values**\n\n*Must implement one or another*\n\n- **impute**: dataset with imputed missing values\n- **drop**: dataset with dropped missing values\n\n**Feature engineering**\n\n*Choose whether to implement or not*\n\n- **discr**: dataset with age, capital and work hours discretized\n- **bin**: dataset with binned features\n\n**Combinations**\n- **impute_discr**\n- **impute_bin**\n- **impute_bin_discr**\n- **drop_discr**\n- **drop_bin**\n- **drop_bin_discr**","db73540b":"# Adult Census Income - Classification\n\n## Table of Contents\n\n1. [Introduction](#Introduction)\n  - [Reading the data](#Reading-the-data)\n  - [Training and testing process](#Training-and-testing-process)\n2. [Logistic Regression](#Logistic-Regression)\n  - [Theory recall](#logreg-theory)\n  - [Parameters](#logreg-parameters)\n  - [Testing](#logreg-testing)\n  - [Conclusions](#logreg-conclusions)\n3. [Linear Discriminant Analysis](#Linear-Discriminant-Analysis)\n  - [Theory recall](#lda-theory)\n  - [Parameters](#lda-parameters)\n  - [Testing](#lda-testing)\n  - [Conclusions](#lda-conclusions)\n4. [K-Nearest Neighbors](#K-Nearest-Neighbors)\n  - [Theory recall](#knn-theory)\n  - [Parameters](#knn-parameters)\n  - [Testing](#knn-testing)\n  - [Conclusions](#knn-conclusions)\n5. [Decision Trees](#Decision-Trees)\n  - [Theory recall](#dt-theory)\n  - [Parameters](#dt-parameters)\n  - [Testing](#dt-testing)\n  - [Conclusions](#dt-conclusions)\n6. [Random Forest](#Random-Forest)\n  - [Theory recall](#rf-theory)\n  - [Parameters (trees)](#rf-parameters-trees)\n  - [Testing (trees)](#rf-testing-trees)\n  - [Parameters (depth)](#rf-parameters-depth)\n  - [Testing (depth)](#rf-testing-depth)\n  - [Conclusions](#rf-conclusions)\n7. [Future Work](#Future-Work)","4885eac2":"If we analyse how the accuracy evolves changing the *C* parameter, we can notice the following things:\n\n- when C is too small, the model underfits (too much regularization)\n- increasing C allows the model to be more accurate\n- if C is too big the test accuracy decreases a little bit (overfitting, because almost no regularization) (slightly noticeable in one hot encoding when the two curves diverge)","d011afcc":"<span id=\"rf-parameters-depth\" \/>\n\n### Parameters (depth)\n\nWe can now try to optimize the depth of the trees.","23822eb1":"<span id=\"rf-testing-trees\" \/>\n\n### Testing (trees)\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","0af75ee8":"## Data Preparation\n\n### Missing values\n\nThere are no null (`Nan`) values in the dataset. Nevertheless, we will see that there are some features that assume an **unknown** value (*?*).","b99cb8e3":"## Feature Engineering\n\nSince the dataset has a lot of features and most of them are categorical, we cannot expect models to work directly with the data we have, we need to perform some kind of *feature engineering* to simplify the structure of the data.\n\n<span id=\"Missing-values-2\"><\/span>\n\n### Missing values\n\nUntil now, I have only removed the duplicated rows, but there are other things that need to be analysed. To begin with, the unknown values (*?*) assumed by the features *Workclass*, *Occupation* and *Country* need to be removed; there are two ways to proceed:\n\n- **drop** the rows that contain an unknown value: this is sub-optimal because we are both dropping important information and reducing the size of the dataset\n- **impute** the missing values: this has been proven to be a good idea even if this process involves guessing the unknown value\n\nOne of the most common imputation techniques for categorical values is to impute the most frequent class. Nevertheless, when there is not a predominant class (as in occupation), a good solution is to create an *Other* class. The imputations that I have performed are:\n\n- impute *Private* for workclass\n- impute *Other* for occupation\n- impute *United-States* for country\n\nIn the case of workclass and occupation, it was also possible to think that *?* meant \"unemployed\" but there are some of these rows that are related to an income greater than \\\\$50K. Therefore I have rejected this hypothesis.\n\n### Outliers\n\nFrom the data exploration, no particular evidence of outliers has been detected. Nevertheless, I think that this is the right place to point out the following thing: the workclass feature contains two particular values *Never-worked* and *Without-pay*; these two values are always related to an income less than 50K but I would say that, for domain knowledge, they must *always* be related to 0 income. Therefore it doesn't make sense to have them in the dataset.\n\n### Transformation\n\nSince we can't perform the standard dimensionality reduction on one hot encoded variables, we can try to decrease the number of classes inside each categorical feature, so that the generated features are less numerous. This technique is called **binning**, and I have grouped together the following values:\n\n- *Workclass*:\n  - **Private**: [Private]\n  - **Gov**: [Federal-gov, Local-gov, State-gov]\n  - **Self**: [Self-emp-inc, Self-emp-not-inc]\n- *Marital status*:\n  - **Married**: [Married-AF-spouse, Married-civ-spouse, Married-spouse-absent, Separated]\n  - **Single**: [Widowed, Divorced, Never-married]\n- *Relationship*:\n  - **Spouse**: [Husband, Wife]\n  - **Relative**: [Own-child, Other-relative]\n  - **Other**: [Unmarried, Not-in-family]\n- *Race*:\n  - **White**: [White]\n  - **Other**: [Black, Asian-Pac-Islander, Other, Amer-Indian-Eskimo]\n- *Country*:\n  - **US**: [United-States]\n  - **Other**: [*All the others*]\n\nAnother possible technique for continuous variables like *Work hours* and *Age* is **discretization**: the continuous values are divided into ranges\/groups of values so that the resulting feature is an ordinal feature with few categorical values. Discretization helps to reduce noise and some kind of algorithms are more efficient. Specifically, I formed the following groups:\n\n- *Age*: ranges of 10 ([0,9], [10,19], ...)\n- *Work hours*: ranges of 10 ([0,9], [10,19], ...)\n\nAnother variable that may be discretized is *Capital*: most of the individuals in the dataset do not invest. Therefore, it may make sense to convert this variable into a categorical one:\n\n- 0 if the individual did not invest or if the result of his investments is zero\n- 1 if the investments brought to a gain\n- 2 if the investments brought to a loss\n\nThese three features have been scaled using a *StandardScaler*.\n\n### Selection\n\nOne last step that can be conducted, is to manually reduce the dimensionality of the dataset by selecting some features to train the model on (remember that using PCA is not optimal with one hot encoded variables). Of course, doing so requires domain knowledge; nevertheless, the data exploration has given us some ideas on which features may be good predictors for the target variable:\n\n- *Age*: as shown [here](#Age), older individuals tend to make more money\n- *Education*: as shown [here](#Education---Education-number), higher level of education often imply higher income\n- *Sex*: as shown [here](#Sex), male individuals tend to make more money than females\n- *Work hours*: as shown [here](#Work-hours), individuals that work more hours per week tend to make more money","e4d850d0":"<span id=\"logreg-conclusions\" \/>\n\n### Conclusions\n\nAs we can see from the previous plot:\n\n- the best model has achieved an accuracy of 84,5% on the *Clean* and *Impute* one-hot-encoded datasets\n- one-hot-encoded datasets have performed, on average, better than label encoded ones (as we sad before, label encoding creates a magnitude relationship between classes that does not represent reality, hence performes poorly)\n- the technique of imputing brought generally better results than dropping\n- binning and discretizing don't seem to improve the overall model performance with one hot encoding","05d6b6b4":"If we analyse how the accuracy evolves changing the *n_estimators* parameter, we can notice the following things:\n\n- using too few trees, the real potential of random forests is not exploited\n- when the number of trees increases, the effects of random forests start to be noticed","4f1d542d":"## Data Exploration","facf06c1":"<span id=\"rf-conclusions\" \/>\n\n### Conclusions\n\nThe Random Forest algorithm, with 8 maximum depth and 100 candidate tress, is the best model for the given dataset. In fact, it has achieved an accuracy of 86,5% on the test set using label encoding and imputation.","1c8a3a01":"<span id=\"lda-conclusions\" \/>\n\n### Conclusions\n\nAs we can see from the plot above:\n\n- the best model has achieved an accuracy of 84% on the *Original* one-hot-encoded dataset\n- as in logistic regression, on average, one hot encoding has performed better than label encoding","634044c7":"<span id=\"rf-testing-depth\" \/>\n\n### Testing (depth)\n\nTesting the best models of each *\\\"feature engineering type\\\"*, we obtain the accuracies reported in the plot below.","15b55b07":"## Random Forest\n\n<span id=\"rf-theory\" \/>\n\n### Theory recall\n\nRandom forest models are ensemble of decision trees: the main idea is to generate multiple decision trees and take as output the average of the output of all the trees. The tree algorithm of random forests is a little bit different: at each candidate split in the learning process, only a random subset of the features is selected (usually $\\sqrt p$ where $p$ is the number of predictors).\n\nThe main advantage of this algorithm is that the different trees are decorrelated, thus reducing the mean variance of the observed data.\n\n<span id=\"rf-parameters-trees\" \/>\n\n### Parameters (trees)\n\nTo begin with, I have looked for the best number of candidate trees using the best max_depth found with a single decision tree. Then, using the best number of trees, I have optimized the max depth of the trees. ","426b3387":"<span id=\"knn-conclusions\" \/>\n\n### Conclusions\n\nEven though our dataset has a lot of features, KNN managed to achieve good accuracies thanks to the sklearn implementation.","62292edc":"### Training and testing process\n\nThe general process that I have followed to find the best model for the given data is the following:\n\n- Load the data (already split into train and test sets in the previous notebook)\n- Encode all the splits (label encoder and one hot encoder to compare them)\n- Define different parameters to be tuned for each model\n- Conduct a **GridSearchCV** to find the best params for each kind of feature engineering dataset ('best' evaluated in terms of *accuracy*)\n- Evaluate the best models, on the test set, and compare the accuracies","230b053d":"## K-Nearest Neighbors\n\n<span id=\"knn-theory\" \/>\n\n### Theory recall\n\nKNN is a non-parametric model that exploits the available data to make predictions; specifically, after having defined a proper distance measure, the model looks at the $K$ *nearest* points and then assigns the class by majority voting. The main drawback of this model, apart from the infering slowness, is that highdimensional space is empty, therefore, with a lot of variables, we cannot expect the model to perform very well. The main advantage is that the model is the training data.\n\n<span id=\"knn-parameters\" \/>\n\n### Parameters\n\nThe only parameter to optimize is $K$.","99f0a9c2":"# Adult Census Income\n\n## Table of Contents\n\n1. [Description](#Description)\n    - [Features](#Features)\n2. [Data Preparation](#Data-Preparation)\n    - [Missing values](#Missing-values)\n    - [Duplicated rows](#Duplicated-rows)\n3. [Data Exploration](#Data-Exploration)\n    - [Income](#Income)\n    - [Age](#Age)\n    - [Workclass](#Workclass)\n    - [Occupation](#Occupation)\n    - [Workclass - Occupation](#Workclass---Occupation)\n    - [Education - Education number](#Education---Education-number)\n    - [Marital status](#Marital-status)\n    - [Relationship](#Relationship)\n    - [Marital status - Relationship](#Marital-status---Relationship)\n    - [Race](#Race)\n    - [Sex](#Sex)\n    - [Country](#Country)\n    - [Capital](#Capital)\n    - [Work hours](#Work-hours)\n4. [Feature Engineering](#Feature-Engineering)\n    - [Missing values](#Missing-values-2)\n    - [Outliers](#Outliers)\n    - [Transformation](#Transformation)\n    - [Selection](#Selection)\n5. [Datasets generation](#Datasets-generation)\n    - [Splitting](#Splitting)\n    - [Encoding](#Encoding)\n    - [Summary](#Summary-of-the-generated-datasets)","96e56e8d":"If we analyse how the accuracy evolves changing the *n_neighbors* parameter, we can notice the following things:\n\n- when K is too small the model overfits (lack of generalization because looking at too few points)\n- when K is too big the model underfits (not visible in our testing because not so big Ks used)","b4bee2ba":"If we analyse how the accuracy evolves changing the *max_depth* parameter, we can notice the following things:\n\n- when the parameter is too small, the tree underfits (only one split)\n- when the parameter is around 12, the accuracy on the test set is around his maximum\n- increasing too much the parameter makes the tree overfitting","2527e691":"If we analyse how the accuracy evolves changing the *max_depth* parameter, we can notice the following things:\n\n- when the parameter is too small, the tree underfits (only one split)\n- when the parameter is around 8, the accuracy on the test set is around his maximum\n- increasing too much the parameter makes the tree overfitting","639bcb86":"## Description\nThe *Adult Census Income* dataset has been extracted from the federal census database in 1994 by Barry Becker. It contains information about people and the prediction **task** is to determine whether they make over \\$50k a year (**Supervised** (binary) **classification problem**). The dataset can be found at the following link https:\/\/archive.ics.uci.edu\/ml\/datasets\/Census+Income.","db5f3f0c":"## Logistic Regression\n\n<span id=\"logreg-theory\" \/>\n\n### Theory recall\n\nSince our target variable is categorical with only two classes, linear regression doesn't work very well (because the generated output isn't between 0 and 1) and logistic regression is more appropriate; this algorithm, rather than modeling the response directly, it models the *probability* that the target variable belongs to a particular class:\n\n$$p(X) = \\frac{e^{\\left(\\beta_{0}+\\beta_{1}X\\right)}}{1+e^{\\left(\\beta_{0}+\\beta_{1}X\\right)}} = \\frac{1}{1+e^{-\\left(\\beta_{0}+\\beta_{1}X\\right)}}$$\n\nIf you look closely, you can see that this model is a linear function plugged into the sigmoid function (also called logistic function). In fact, the main difference between linear regression and logistic regression is that the output of the latter will always take values between 0 and 1: when the output is higher than 0.5, class 1 will be assigned, otherwise class 0 is assigned.\n\nManipulating the model equation, it is possible to obtain the *logit* transformation:\n\n$$log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_{0}+\\beta_{1}X$$\n\nThe regression coefficients are estimated maximizing a conditional ($P\\left(y|X\\right)$ *discriminative learning*) likelihood function: scikit learn's implementation minimizes the negative log likelihood function, which is a function called *cross-entropy*. Of course, with multiple predictors like in our case, the model is constructed on a linear combination of coefficients and predictors $\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\beta_{n}X_{n}$. (The likelihood function doesn't have a closed form; therefore an iterative process must be used.)\n\n<span id=\"logreg-parameters\" \/>\n\n### Parameters\n\nWith the grid search, the following parameters have been optimized:\n\n- *C*: this is the inverse of the regularization strength (sklearn models use regularization by default (better generalization))\n- *solver* (check documentation [here](https:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression))","20f4ec13":"### Features\n\nBelow you can find the description of the features.\n\n| Feature | Description | Variable type |\n| --- | --- | --- |\n| **[Age](#Age)** | Age of the individual | Numerical |\n| **[Workclass](#Workclass)** | Job sector of the individual | Categorical |\n| **[Final weight](#final-weight)** | Final weight calculated by the CPS<sup style=\"color: red; font-weight: bold\">1<\/sup> | Numerical |\n| **[Education](#Education---Education-number)** | Highest education of the individual | Categorical - ordinal |\\n\"\n| **[Education number](#Education---Education-number)** | Number corresponding to the education<sup style=\"color:red; font-weight: bold\">2<\/sup> | Numerical |\n| **[Marital Status](#Marital-status)** | Marital condition of the individual | Categorical |\n| **[Occupation](#Occupation)** | Job of the individual | Categorical |\n| **[Relationship](#Relationship)** | Social relationship of the individual | Categorical |\n| **[Race](#Race)** | Race of the individual | Categorical |\n| **[Sex](#Sex)** | Sex of the individual | Categorical |\n| **[Capital](#Capital)** | Investment gains or losses of the individual | Numerical |\n| **[Work hours](#Work-hours)** | Work hours per week | Numerical |\n| **[Country](#Country)** | Native country of the individual | Categorical |\n| **[Income](#Income)** (**target**) | Income of the individual | Categorical |\n\n><sup style=\"color:red; font-weight: bold\">1<\/sup> <span style=\"font-size: 12px\">The weights on the Current Population Survey (CPS) files are controlled to independent estimates of the civilian noninstitutional population of the US. These are prepared monthly for us by Population Division here at the Census Bureau.<\/span>\n\n><sup style=\"color:red; font-weight: bold\">2<\/sup> <span style=\"font-size: 12px\">The relationship between the *education* and the *education number* is reported [here](#Education---Education-number).<\/span>"}}